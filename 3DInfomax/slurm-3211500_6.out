>>> Starting run for dataset: tox21
Running SCAFF configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.6.yml --seed 6 --device cuda:0
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.8/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.8_5_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.8
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6935000
[Epoch 1; Iter    60/  209] train: loss: 0.6934997
[Epoch 1; Iter    90/  209] train: loss: 0.6924404
[Epoch 1; Iter   120/  209] train: loss: 0.6926443
[Epoch 1; Iter   150/  209] train: loss: 0.6922327
[Epoch 1; Iter   180/  209] train: loss: 0.6927152
[Epoch 1] ogbg-moltox21: 0.490475 val loss: 0.692548
[Epoch 1] ogbg-moltox21: 0.494033 test loss: 0.692184
[Epoch 2; Iter     1/  209] train: loss: 0.6921802
[Epoch 2; Iter    31/  209] train: loss: 0.6923270
[Epoch 2; Iter    61/  209] train: loss: 0.6910958
[Epoch 2; Iter    91/  209] train: loss: 0.6913828
[Epoch 2; Iter   121/  209] train: loss: 0.6921211
[Epoch 2; Iter   151/  209] train: loss: 0.6910291
[Epoch 2; Iter   181/  209] train: loss: 0.6916206
[Epoch 2] ogbg-moltox21: 0.506982 val loss: 0.691542
[Epoch 2] ogbg-moltox21: 0.509767 test loss: 0.691192
[Epoch 3; Iter     2/  209] train: loss: 0.6906205
[Epoch 3; Iter    32/  209] train: loss: 0.6911997
[Epoch 3; Iter    62/  209] train: loss: 0.6894030
[Epoch 3; Iter    92/  209] train: loss: 0.6889070
[Epoch 3; Iter   122/  209] train: loss: 0.6894379
[Epoch 3; Iter   152/  209] train: loss: 0.6884426
[Epoch 3; Iter   182/  209] train: loss: 0.6887284
[Epoch 3] ogbg-moltox21: 0.511182 val loss: 0.688336
[Epoch 3] ogbg-moltox21: 0.513031 test loss: 0.688034
[Epoch 4; Iter     3/  209] train: loss: 0.6883829
[Epoch 4; Iter    33/  209] train: loss: 0.6870602
[Epoch 4; Iter    63/  209] train: loss: 0.6870600
[Epoch 4; Iter    93/  209] train: loss: 0.6809585
[Epoch 4; Iter   123/  209] train: loss: 0.6605290
[Epoch 4; Iter   153/  209] train: loss: 0.6211150
[Epoch 4; Iter   183/  209] train: loss: 0.5876521
[Epoch 4] ogbg-moltox21: 0.650967 val loss: 0.606922
[Epoch 4] ogbg-moltox21: 0.612556 test loss: 0.607140
[Epoch 5; Iter     4/  209] train: loss: 0.5355811
[Epoch 5; Iter    34/  209] train: loss: 0.4575257
[Epoch 5; Iter    64/  209] train: loss: 0.4091032
[Epoch 5; Iter    94/  209] train: loss: 0.3488182
[Epoch 5; Iter   124/  209] train: loss: 0.2986700
[Epoch 5; Iter   154/  209] train: loss: 0.3078350
[Epoch 5; Iter   184/  209] train: loss: 0.2434679
[Epoch 5] ogbg-moltox21: 0.679864 val loss: 0.338978
[Epoch 5] ogbg-moltox21: 0.672128 test loss: 0.358333
[Epoch 6; Iter     5/  209] train: loss: 0.2869124
[Epoch 6; Iter    35/  209] train: loss: 0.2332048
[Epoch 6; Iter    65/  209] train: loss: 0.2347133
[Epoch 6; Iter    95/  209] train: loss: 0.1569710
[Epoch 6; Iter   125/  209] train: loss: 0.2627946
[Epoch 6; Iter   155/  209] train: loss: 0.2092782
[Epoch 6; Iter   185/  209] train: loss: 0.1913173
[Epoch 6] ogbg-moltox21: 0.729896 val loss: 0.278798
[Epoch 6] ogbg-moltox21: 0.687021 test loss: 0.286484
[Epoch 7; Iter     6/  209] train: loss: 0.1679536
[Epoch 7; Iter    36/  209] train: loss: 0.1432186
[Epoch 7; Iter    66/  209] train: loss: 0.2124151
[Epoch 7; Iter    96/  209] train: loss: 0.2250246
[Epoch 7; Iter   126/  209] train: loss: 0.3150901
[Epoch 7; Iter   156/  209] train: loss: 0.1730801
[Epoch 7; Iter   186/  209] train: loss: 0.1667174
[Epoch 7] ogbg-moltox21: 0.699902 val loss: 0.283235
[Epoch 7] ogbg-moltox21: 0.717605 test loss: 0.330008
[Epoch 8; Iter     7/  209] train: loss: 0.2480955
[Epoch 8; Iter    37/  209] train: loss: 0.1551000
[Epoch 8; Iter    67/  209] train: loss: 0.1445927
[Epoch 8; Iter    97/  209] train: loss: 0.1757970
[Epoch 8; Iter   127/  209] train: loss: 0.2329522
[Epoch 8; Iter   157/  209] train: loss: 0.1171339
[Epoch 8; Iter   187/  209] train: loss: 0.3333687
[Epoch 8] ogbg-moltox21: 0.695121 val loss: 0.309004
[Epoch 8] ogbg-moltox21: 0.686000 test loss: 0.315037
[Epoch 9; Iter     8/  209] train: loss: 0.2018809
[Epoch 9; Iter    38/  209] train: loss: 0.2131432
[Epoch 9; Iter    68/  209] train: loss: 0.0897853
[Epoch 9; Iter    98/  209] train: loss: 0.1733015
[Epoch 9; Iter   128/  209] train: loss: 0.2108233
[Epoch 9; Iter   158/  209] train: loss: 0.1568851
[Epoch 9; Iter   188/  209] train: loss: 0.2345962
[Epoch 9] ogbg-moltox21: 0.753426 val loss: 0.269877
[Epoch 9] ogbg-moltox21: 0.713678 test loss: 0.278965
[Epoch 10; Iter     9/  209] train: loss: 0.1564507
[Epoch 10; Iter    39/  209] train: loss: 0.2529419
[Epoch 10; Iter    69/  209] train: loss: 0.2697673
[Epoch 10; Iter    99/  209] train: loss: 0.1559577
[Epoch 10; Iter   129/  209] train: loss: 0.1672792
[Epoch 10; Iter   159/  209] train: loss: 0.2779737
[Epoch 10; Iter   189/  209] train: loss: 0.1793253
[Epoch 10] ogbg-moltox21: 0.744166 val loss: 0.282757
[Epoch 10] ogbg-moltox21: 0.717842 test loss: 0.282123
[Epoch 11; Iter    10/  209] train: loss: 0.1846191
[Epoch 11; Iter    40/  209] train: loss: 0.1853628
[Epoch 11; Iter    70/  209] train: loss: 0.1412971
[Epoch 11; Iter   100/  209] train: loss: 0.1830225
[Epoch 11; Iter   130/  209] train: loss: 0.1928449
[Epoch 11; Iter   160/  209] train: loss: 0.2100331
[Epoch 11; Iter   190/  209] train: loss: 0.1724558
[Epoch 11] ogbg-moltox21: 0.758815 val loss: 0.308099
[Epoch 11] ogbg-moltox21: 0.748145 test loss: 0.284080
[Epoch 12; Iter    11/  209] train: loss: 0.2268444
[Epoch 12; Iter    41/  209] train: loss: 0.2291555
[Epoch 12; Iter    71/  209] train: loss: 0.2044812
[Epoch 12; Iter   101/  209] train: loss: 0.1297937
[Epoch 12; Iter   131/  209] train: loss: 0.2249489
[Epoch 12; Iter   161/  209] train: loss: 0.2205947
[Epoch 12; Iter   191/  209] train: loss: 0.2209993
[Epoch 12] ogbg-moltox21: 0.743198 val loss: 0.289840
[Epoch 12] ogbg-moltox21: 0.732530 test loss: 0.298069
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.8/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.8_6_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.8
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6932449
[Epoch 1; Iter    60/  209] train: loss: 0.6922231
[Epoch 1; Iter    90/  209] train: loss: 0.6921970
[Epoch 1; Iter   120/  209] train: loss: 0.6930904
[Epoch 1; Iter   150/  209] train: loss: 0.6929813
[Epoch 1; Iter   180/  209] train: loss: 0.6921134
[Epoch 1] ogbg-moltox21: 0.481710 val loss: 0.693622
[Epoch 1] ogbg-moltox21: 0.493910 test loss: 0.693320
[Epoch 2; Iter     1/  209] train: loss: 0.6922827
[Epoch 2; Iter    31/  209] train: loss: 0.6925003
[Epoch 2; Iter    61/  209] train: loss: 0.6922155
[Epoch 2; Iter    91/  209] train: loss: 0.6921775
[Epoch 2; Iter   121/  209] train: loss: 0.6919969
[Epoch 2; Iter   151/  209] train: loss: 0.6914183
[Epoch 2; Iter   181/  209] train: loss: 0.6913604
[Epoch 2] ogbg-moltox21: 0.487506 val loss: 0.692123
[Epoch 2] ogbg-moltox21: 0.500858 test loss: 0.691781
[Epoch 3; Iter     2/  209] train: loss: 0.6907048
[Epoch 3; Iter    32/  209] train: loss: 0.6902463
[Epoch 3; Iter    62/  209] train: loss: 0.6904027
[Epoch 3; Iter    92/  209] train: loss: 0.6908488
[Epoch 3; Iter   122/  209] train: loss: 0.6898955
[Epoch 3; Iter   152/  209] train: loss: 0.6899803
[Epoch 3; Iter   182/  209] train: loss: 0.6888211
[Epoch 3] ogbg-moltox21: 0.488077 val loss: 0.689920
[Epoch 3] ogbg-moltox21: 0.501033 test loss: 0.689636
[Epoch 4; Iter     3/  209] train: loss: 0.6882789
[Epoch 4; Iter    33/  209] train: loss: 0.6875144
[Epoch 4; Iter    63/  209] train: loss: 0.6871979
[Epoch 4; Iter    93/  209] train: loss: 0.6829287
[Epoch 4; Iter   123/  209] train: loss: 0.6621528
[Epoch 4; Iter   153/  209] train: loss: 0.6271290
[Epoch 4; Iter   183/  209] train: loss: 0.6246628
[Epoch 4] ogbg-moltox21: 0.647692 val loss: 0.709811
[Epoch 4] ogbg-moltox21: 0.632076 test loss: 0.714946
[Epoch 5; Iter     4/  209] train: loss: 0.5432002
[Epoch 5; Iter    34/  209] train: loss: 0.4670600
[Epoch 5; Iter    64/  209] train: loss: 0.4256207
[Epoch 5; Iter    94/  209] train: loss: 0.4030154
[Epoch 5; Iter   124/  209] train: loss: 0.3536979
[Epoch 5; Iter   154/  209] train: loss: 0.2730349
[Epoch 5; Iter   184/  209] train: loss: 0.2287936
[Epoch 5] ogbg-moltox21: 0.693944 val loss: 0.303085
[Epoch 5] ogbg-moltox21: 0.672874 test loss: 0.307824
[Epoch 6; Iter     5/  209] train: loss: 0.2074737
[Epoch 6; Iter    35/  209] train: loss: 0.1730112
[Epoch 6; Iter    65/  209] train: loss: 0.2004821
[Epoch 6; Iter    95/  209] train: loss: 0.2034770
[Epoch 6; Iter   125/  209] train: loss: 0.1522286
[Epoch 6; Iter   155/  209] train: loss: 0.2051427
[Epoch 6; Iter   185/  209] train: loss: 0.1820004
[Epoch 6] ogbg-moltox21: 0.721936 val loss: 0.276197
[Epoch 6] ogbg-moltox21: 0.694135 test loss: 0.276000
[Epoch 7; Iter     6/  209] train: loss: 0.1739761
[Epoch 7; Iter    36/  209] train: loss: 0.2257688
[Epoch 7; Iter    66/  209] train: loss: 0.1367073
[Epoch 7; Iter    96/  209] train: loss: 0.2402528
[Epoch 7; Iter   126/  209] train: loss: 0.1547014
[Epoch 7; Iter   156/  209] train: loss: 0.2371144
[Epoch 7; Iter   186/  209] train: loss: 0.2214632
[Epoch 7] ogbg-moltox21: 0.746060 val loss: 0.270953
[Epoch 7] ogbg-moltox21: 0.722897 test loss: 0.287963
[Epoch 8; Iter     7/  209] train: loss: 0.1896205
[Epoch 8; Iter    37/  209] train: loss: 0.2406794
[Epoch 8; Iter    67/  209] train: loss: 0.1541151
[Epoch 8; Iter    97/  209] train: loss: 0.2095990
[Epoch 8; Iter   127/  209] train: loss: 0.2673352
[Epoch 8; Iter   157/  209] train: loss: 0.1697390
[Epoch 8; Iter   187/  209] train: loss: 0.2183379
[Epoch 8] ogbg-moltox21: 0.736203 val loss: 0.281771
[Epoch 8] ogbg-moltox21: 0.716159 test loss: 0.300188
[Epoch 9; Iter     8/  209] train: loss: 0.2489040
[Epoch 9; Iter    38/  209] train: loss: 0.1695343
[Epoch 9; Iter    68/  209] train: loss: 0.1789196
[Epoch 9; Iter    98/  209] train: loss: 0.2465649
[Epoch 9; Iter   128/  209] train: loss: 0.2145098
[Epoch 9; Iter   158/  209] train: loss: 0.1486310
[Epoch 9; Iter   188/  209] train: loss: 0.1422819
[Epoch 9] ogbg-moltox21: 0.740994 val loss: 0.270884
[Epoch 9] ogbg-moltox21: 0.728035 test loss: 0.283517
[Epoch 10; Iter     9/  209] train: loss: 0.2020264
[Epoch 10; Iter    39/  209] train: loss: 0.1692345
[Epoch 10; Iter    69/  209] train: loss: 0.1868353
[Epoch 10; Iter    99/  209] train: loss: 0.1411684
[Epoch 10; Iter   129/  209] train: loss: 0.1516981
[Epoch 10; Iter   159/  209] train: loss: 0.1102360
[Epoch 10; Iter   189/  209] train: loss: 0.1558127
[Epoch 10] ogbg-moltox21: 0.760134 val loss: 0.268128
[Epoch 10] ogbg-moltox21: 0.736091 test loss: 0.294787
[Epoch 11; Iter    10/  209] train: loss: 0.2163654
[Epoch 11; Iter    40/  209] train: loss: 0.1989475
[Epoch 11; Iter    70/  209] train: loss: 0.1969191
[Epoch 11; Iter   100/  209] train: loss: 0.2552060
[Epoch 11; Iter   130/  209] train: loss: 0.1641027
[Epoch 11; Iter   160/  209] train: loss: 0.1766207
[Epoch 11; Iter   190/  209] train: loss: 0.1515393
[Epoch 11] ogbg-moltox21: 0.764465 val loss: 0.303107
[Epoch 11] ogbg-moltox21: 0.733896 test loss: 0.300073
[Epoch 12; Iter    11/  209] train: loss: 0.1074247
[Epoch 12; Iter    41/  209] train: loss: 0.2719890
[Epoch 12; Iter    71/  209] train: loss: 0.1637659
[Epoch 12; Iter   101/  209] train: loss: 0.1927920
[Epoch 12; Iter   131/  209] train: loss: 0.2161928
[Epoch 12; Iter   161/  209] train: loss: 0.1895045
[Epoch 12; Iter   191/  209] train: loss: 0.1360310
[Epoch 12] ogbg-moltox21: 0.779652 val loss: 0.257270
[Epoch 12] ogbg-moltox21: 0.761811 test loss: 0.264941
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.7/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.7_5_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.7
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6927366
[Epoch 1; Iter    60/  183] train: loss: 0.6931052
[Epoch 1; Iter    90/  183] train: loss: 0.6925203
[Epoch 1; Iter   120/  183] train: loss: 0.6922455
[Epoch 1; Iter   150/  183] train: loss: 0.6924355
[Epoch 1; Iter   180/  183] train: loss: 0.6929777
[Epoch 1] ogbg-moltox21: 0.505359 val loss: 0.692428
[Epoch 1] ogbg-moltox21: 0.491538 test loss: 0.692818
[Epoch 2; Iter    27/  183] train: loss: 0.6928447
[Epoch 2; Iter    57/  183] train: loss: 0.6919684
[Epoch 2; Iter    87/  183] train: loss: 0.6925305
[Epoch 2; Iter   117/  183] train: loss: 0.6918361
[Epoch 2; Iter   147/  183] train: loss: 0.6916010
[Epoch 2; Iter   177/  183] train: loss: 0.6916383
[Epoch 2] ogbg-moltox21: 0.518014 val loss: 0.691321
[Epoch 2] ogbg-moltox21: 0.502473 test loss: 0.691736
[Epoch 3; Iter    24/  183] train: loss: 0.6902749
[Epoch 3; Iter    54/  183] train: loss: 0.6905949
[Epoch 3; Iter    84/  183] train: loss: 0.6900356
[Epoch 3; Iter   114/  183] train: loss: 0.6898178
[Epoch 3; Iter   144/  183] train: loss: 0.6896641
[Epoch 3; Iter   174/  183] train: loss: 0.6885415
[Epoch 3] ogbg-moltox21: 0.519776 val loss: 0.689411
[Epoch 3] ogbg-moltox21: 0.504107 test loss: 0.689851
[Epoch 4; Iter    21/  183] train: loss: 0.6886555
[Epoch 4; Iter    51/  183] train: loss: 0.6882555
[Epoch 4; Iter    81/  183] train: loss: 0.6875207
[Epoch 4; Iter   111/  183] train: loss: 0.6881062
[Epoch 4; Iter   141/  183] train: loss: 0.6859993
[Epoch 4; Iter   171/  183] train: loss: 0.6807963
[Epoch 4] ogbg-moltox21: 0.657459 val loss: 0.694397
[Epoch 4] ogbg-moltox21: 0.630432 test loss: 0.695760
[Epoch 5; Iter    18/  183] train: loss: 0.6622695
[Epoch 5; Iter    48/  183] train: loss: 0.6268331
[Epoch 5; Iter    78/  183] train: loss: 0.5758833
[Epoch 5; Iter   108/  183] train: loss: 0.5466326
[Epoch 5; Iter   138/  183] train: loss: 0.4827510
[Epoch 5; Iter   168/  183] train: loss: 0.4270214
[Epoch 5] ogbg-moltox21: 0.640639 val loss: 0.611718
[Epoch 5] ogbg-moltox21: 0.617007 test loss: 0.612736
[Epoch 6; Iter    15/  183] train: loss: 0.3701220
[Epoch 6; Iter    45/  183] train: loss: 0.3486212
[Epoch 6; Iter    75/  183] train: loss: 0.3199619
[Epoch 6; Iter   105/  183] train: loss: 0.2315532
[Epoch 6; Iter   135/  183] train: loss: 0.1820244
[Epoch 6; Iter   165/  183] train: loss: 0.1793960
[Epoch 6] ogbg-moltox21: 0.701472 val loss: 0.302677
[Epoch 6] ogbg-moltox21: 0.692944 test loss: 0.305621
[Epoch 7; Iter    12/  183] train: loss: 0.2215450
[Epoch 7; Iter    42/  183] train: loss: 0.2333786
[Epoch 7; Iter    72/  183] train: loss: 0.1855495
[Epoch 7; Iter   102/  183] train: loss: 0.2144570
[Epoch 7; Iter   132/  183] train: loss: 0.1374612
[Epoch 7; Iter   162/  183] train: loss: 0.1794565
[Epoch 7] ogbg-moltox21: 0.675769 val loss: 0.310168
[Epoch 7] ogbg-moltox21: 0.661546 test loss: 0.311259
[Epoch 8; Iter     9/  183] train: loss: 0.2965232
[Epoch 8; Iter    39/  183] train: loss: 0.2306871
[Epoch 8; Iter    69/  183] train: loss: 0.1983174
[Epoch 8; Iter    99/  183] train: loss: 0.1890394
[Epoch 8; Iter   129/  183] train: loss: 0.2484853
[Epoch 8; Iter   159/  183] train: loss: 0.1627337
[Epoch 8] ogbg-moltox21: 0.705558 val loss: 0.342952
[Epoch 8] ogbg-moltox21: 0.694285 test loss: 0.857376
[Epoch 9; Iter     6/  183] train: loss: 0.1150786
[Epoch 9; Iter    36/  183] train: loss: 0.1482239
[Epoch 9; Iter    66/  183] train: loss: 0.2098855
[Epoch 9; Iter    96/  183] train: loss: 0.1530758
[Epoch 9; Iter   126/  183] train: loss: 0.1569971
[Epoch 9; Iter   156/  183] train: loss: 0.1693201
[Epoch 9] ogbg-moltox21: 0.688995 val loss: 0.501354
[Epoch 9] ogbg-moltox21: 0.670336 test loss: 0.568101
[Epoch 10; Iter     3/  183] train: loss: 0.1848072
[Epoch 10; Iter    33/  183] train: loss: 0.2404192
[Epoch 10; Iter    63/  183] train: loss: 0.1910460
[Epoch 10; Iter    93/  183] train: loss: 0.1996215
[Epoch 10; Iter   123/  183] train: loss: 0.2130913
[Epoch 10; Iter   153/  183] train: loss: 0.1142214
[Epoch 10; Iter   183/  183] train: loss: 0.2114196
[Epoch 10] ogbg-moltox21: 0.566630 val loss: 7.971295
[Epoch 10] ogbg-moltox21: 0.565989 test loss: 10.370563
[Epoch 11; Iter    30/  183] train: loss: 0.1405842
[Epoch 11; Iter    60/  183] train: loss: 0.2459240
[Epoch 11; Iter    90/  183] train: loss: 0.1911796
[Epoch 11; Iter   120/  183] train: loss: 0.1686297
[Epoch 11; Iter   150/  183] train: loss: 0.2098269
[Epoch 11; Iter   180/  183] train: loss: 0.2492452
[Epoch 11] ogbg-moltox21: 0.738757 val loss: 0.283799
[Epoch 11] ogbg-moltox21: 0.722739 test loss: 0.294659
[Epoch 12; Iter    27/  183] train: loss: 0.1184745
[Epoch 12; Iter    57/  183] train: loss: 0.2194065
[Epoch 12; Iter    87/  183] train: loss: 0.0862041
[Epoch 12; Iter   117/  183] train: loss: 0.1707714
[Epoch 12; Iter   147/  183] train: loss: 0.1742006
[Epoch 12; Iter   177/  183] train: loss: 0.1874041
[Epoch 12] ogbg-moltox21: 0.746299 val loss: 0.270670
[Epoch 12] ogbg-moltox21: 0.742300 test loss: 0.273842
[Epoch 13; Iter    24/  183] train: loss: 0.0739295
[Epoch 13; Iter    54/  183] train: loss: 0.3058996
[Epoch 13; Iter    84/  183] train: loss: 0.2001946
[Epoch 13; Iter   114/  183] train: loss: 0.1456088
[Epoch 13; Iter   144/  183] train: loss: 0.1640140
[Epoch 13; Iter   174/  183] train: loss: 0.1481169
[Epoch 13] ogbg-moltox21: 0.724744 val loss: 0.298304
[Epoch 13] ogbg-moltox21: 0.721143 test loss: 0.310912
[Epoch 14; Iter    21/  183] train: loss: 0.0974484
[Epoch 14; Iter    51/  183] train: loss: 0.1994850
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.8/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.8_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.8
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6928516
[Epoch 1; Iter    60/  209] train: loss: 0.6939425
[Epoch 1; Iter    90/  209] train: loss: 0.6934603
[Epoch 1; Iter   120/  209] train: loss: 0.6926699
[Epoch 1; Iter   150/  209] train: loss: 0.6927113
[Epoch 1; Iter   180/  209] train: loss: 0.6924809
[Epoch 1] ogbg-moltox21: 0.495667 val loss: 0.693900
[Epoch 1] ogbg-moltox21: 0.507305 test loss: 0.693594
[Epoch 2; Iter     1/  209] train: loss: 0.6923747
[Epoch 2; Iter    31/  209] train: loss: 0.6923139
[Epoch 2; Iter    61/  209] train: loss: 0.6920390
[Epoch 2; Iter    91/  209] train: loss: 0.6928610
[Epoch 2; Iter   121/  209] train: loss: 0.6918319
[Epoch 2; Iter   151/  209] train: loss: 0.6910652
[Epoch 2; Iter   181/  209] train: loss: 0.6913953
[Epoch 2] ogbg-moltox21: 0.497703 val loss: 0.692414
[Epoch 2] ogbg-moltox21: 0.512625 test loss: 0.692174
[Epoch 3; Iter     2/  209] train: loss: 0.6912024
[Epoch 3; Iter    32/  209] train: loss: 0.6910614
[Epoch 3; Iter    62/  209] train: loss: 0.6897131
[Epoch 3; Iter    92/  209] train: loss: 0.6908472
[Epoch 3; Iter   122/  209] train: loss: 0.6891449
[Epoch 3; Iter   152/  209] train: loss: 0.6887643
[Epoch 3; Iter   182/  209] train: loss: 0.6888374
[Epoch 3] ogbg-moltox21: 0.499587 val loss: 0.690214
[Epoch 3] ogbg-moltox21: 0.518203 test loss: 0.689960
[Epoch 4; Iter     3/  209] train: loss: 0.6881841
[Epoch 4; Iter    33/  209] train: loss: 0.6879690
[Epoch 4; Iter    63/  209] train: loss: 0.6876869
[Epoch 4; Iter    93/  209] train: loss: 0.6818220
[Epoch 4; Iter   123/  209] train: loss: 0.6596898
[Epoch 4; Iter   153/  209] train: loss: 0.6276786
[Epoch 4; Iter   183/  209] train: loss: 0.5862048
[Epoch 4] ogbg-moltox21: 0.651892 val loss: 0.611918
[Epoch 4] ogbg-moltox21: 0.627802 test loss: 0.616279
[Epoch 5; Iter     4/  209] train: loss: 0.5315864
[Epoch 5; Iter    34/  209] train: loss: 0.4694417
[Epoch 5; Iter    64/  209] train: loss: 0.4365920
[Epoch 5; Iter    94/  209] train: loss: 0.3598737
[Epoch 5; Iter   124/  209] train: loss: 0.3939059
[Epoch 5; Iter   154/  209] train: loss: 0.2372530
[Epoch 5; Iter   184/  209] train: loss: 0.2239011
[Epoch 5] ogbg-moltox21: 0.720024 val loss: 0.339546
[Epoch 5] ogbg-moltox21: 0.685929 test loss: 0.345709
[Epoch 6; Iter     5/  209] train: loss: 0.2121143
[Epoch 6; Iter    35/  209] train: loss: 0.2113283
[Epoch 6; Iter    65/  209] train: loss: 0.2068388
[Epoch 6; Iter    95/  209] train: loss: 0.2250608
[Epoch 6; Iter   125/  209] train: loss: 0.3158578
[Epoch 6; Iter   155/  209] train: loss: 0.2475005
[Epoch 6; Iter   185/  209] train: loss: 0.2488229
[Epoch 6] ogbg-moltox21: 0.728877 val loss: 0.267888
[Epoch 6] ogbg-moltox21: 0.692453 test loss: 0.274134
[Epoch 7; Iter     6/  209] train: loss: 0.3154205
[Epoch 7; Iter    36/  209] train: loss: 0.1874325
[Epoch 7; Iter    66/  209] train: loss: 0.2584361
[Epoch 7; Iter    96/  209] train: loss: 0.2144861
[Epoch 7; Iter   126/  209] train: loss: 0.1842881
[Epoch 7; Iter   156/  209] train: loss: 0.2028817
[Epoch 7; Iter   186/  209] train: loss: 0.1842183
[Epoch 7] ogbg-moltox21: 0.718826 val loss: 0.332907
[Epoch 7] ogbg-moltox21: 0.706558 test loss: 0.328834
[Epoch 8; Iter     7/  209] train: loss: 0.1413521
[Epoch 8; Iter    37/  209] train: loss: 0.2335095
[Epoch 8; Iter    67/  209] train: loss: 0.3007532
[Epoch 8; Iter    97/  209] train: loss: 0.1799202
[Epoch 8; Iter   127/  209] train: loss: 0.2783245
[Epoch 8; Iter   157/  209] train: loss: 0.1566897
[Epoch 8; Iter   187/  209] train: loss: 0.2381880
[Epoch 8] ogbg-moltox21: 0.723602 val loss: 0.834066
[Epoch 8] ogbg-moltox21: 0.711571 test loss: 1.327356
[Epoch 9; Iter     8/  209] train: loss: 0.2649817
[Epoch 9; Iter    38/  209] train: loss: 0.1528104
[Epoch 9; Iter    68/  209] train: loss: 0.2128237
[Epoch 9; Iter    98/  209] train: loss: 0.1941969
[Epoch 9; Iter   128/  209] train: loss: 0.1710821
[Epoch 9; Iter   158/  209] train: loss: 0.1829640
[Epoch 9; Iter   188/  209] train: loss: 0.2385077
[Epoch 9] ogbg-moltox21: 0.774669 val loss: 0.257569
[Epoch 9] ogbg-moltox21: 0.743761 test loss: 0.272928
[Epoch 10; Iter     9/  209] train: loss: 0.2198078
[Epoch 10; Iter    39/  209] train: loss: 0.2136081
[Epoch 10; Iter    69/  209] train: loss: 0.2296368
[Epoch 10; Iter    99/  209] train: loss: 0.1961957
[Epoch 10; Iter   129/  209] train: loss: 0.2224602
[Epoch 10; Iter   159/  209] train: loss: 0.1446618
[Epoch 10; Iter   189/  209] train: loss: 0.2071220
[Epoch 10] ogbg-moltox21: 0.775180 val loss: 0.326478
[Epoch 10] ogbg-moltox21: 0.740165 test loss: 0.301637
[Epoch 11; Iter    10/  209] train: loss: 0.2098134
[Epoch 11; Iter    40/  209] train: loss: 0.1441910
[Epoch 11; Iter    70/  209] train: loss: 0.1668993
[Epoch 11; Iter   100/  209] train: loss: 0.3183248
[Epoch 11; Iter   130/  209] train: loss: 0.1848980
[Epoch 11; Iter   160/  209] train: loss: 0.1918905
[Epoch 11; Iter   190/  209] train: loss: 0.1592862
[Epoch 11] ogbg-moltox21: 0.758375 val loss: 0.281910
[Epoch 11] ogbg-moltox21: 0.739650 test loss: 0.295975
[Epoch 12; Iter    11/  209] train: loss: 0.1636686
[Epoch 12; Iter    41/  209] train: loss: 0.1050219
[Epoch 12; Iter    71/  209] train: loss: 0.3287420
[Epoch 12; Iter   101/  209] train: loss: 0.1634038
[Epoch 12; Iter   131/  209] train: loss: 0.1904328
[Epoch 12; Iter   161/  209] train: loss: 0.1647995
[Epoch 12; Iter   191/  209] train: loss: 0.1007492
[Epoch 12] ogbg-moltox21: 0.782145 val loss: 0.268886
[Epoch 12] ogbg-moltox21: 0.753476 test loss: 0.279887
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.7/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.7_6_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.7
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6933026
[Epoch 1; Iter    60/  183] train: loss: 0.6929880
[Epoch 1; Iter    90/  183] train: loss: 0.6933627
[Epoch 1; Iter   120/  183] train: loss: 0.6929072
[Epoch 1; Iter   150/  183] train: loss: 0.6930168
[Epoch 1; Iter   180/  183] train: loss: 0.6929741
[Epoch 1] ogbg-moltox21: 0.471563 val loss: 0.693174
[Epoch 1] ogbg-moltox21: 0.484989 test loss: 0.693316
[Epoch 2; Iter    27/  183] train: loss: 0.6925304
[Epoch 2; Iter    57/  183] train: loss: 0.6917347
[Epoch 2; Iter    87/  183] train: loss: 0.6919380
[Epoch 2; Iter   117/  183] train: loss: 0.6916853
[Epoch 2; Iter   147/  183] train: loss: 0.6922153
[Epoch 2; Iter   177/  183] train: loss: 0.6920374
[Epoch 2] ogbg-moltox21: 0.474077 val loss: 0.692447
[Epoch 2] ogbg-moltox21: 0.486122 test loss: 0.692548
[Epoch 3; Iter    24/  183] train: loss: 0.6907925
[Epoch 3; Iter    54/  183] train: loss: 0.6913546
[Epoch 3; Iter    84/  183] train: loss: 0.6906760
[Epoch 3; Iter   114/  183] train: loss: 0.6907027
[Epoch 3; Iter   144/  183] train: loss: 0.6899837
[Epoch 3; Iter   174/  183] train: loss: 0.6901270
[Epoch 3] ogbg-moltox21: 0.474549 val loss: 0.690585
[Epoch 3] ogbg-moltox21: 0.488943 test loss: 0.690700
[Epoch 4; Iter    21/  183] train: loss: 0.6891026
[Epoch 4; Iter    51/  183] train: loss: 0.6887291
[Epoch 4; Iter    81/  183] train: loss: 0.6885061
[Epoch 4; Iter   111/  183] train: loss: 0.6874236
[Epoch 4; Iter   141/  183] train: loss: 0.6875811
[Epoch 4; Iter   171/  183] train: loss: 0.6815986
[Epoch 4] ogbg-moltox21: 0.640143 val loss: 0.708205
[Epoch 4] ogbg-moltox21: 0.622796 test loss: 0.709031
[Epoch 5; Iter    18/  183] train: loss: 0.6566587
[Epoch 5; Iter    48/  183] train: loss: 0.6207938
[Epoch 5; Iter    78/  183] train: loss: 0.6010041
[Epoch 5; Iter   108/  183] train: loss: 0.5438080
[Epoch 5; Iter   138/  183] train: loss: 0.4769348
[Epoch 5; Iter   168/  183] train: loss: 0.4201183
[Epoch 5] ogbg-moltox21: 0.688198 val loss: 0.494682
[Epoch 5] ogbg-moltox21: 0.675494 test loss: 0.497126
[Epoch 6; Iter    15/  183] train: loss: 0.4081561
[Epoch 6; Iter    45/  183] train: loss: 0.3275993
[Epoch 6; Iter    75/  183] train: loss: 0.2623769
[Epoch 6; Iter   105/  183] train: loss: 0.2510753
[Epoch 6; Iter   135/  183] train: loss: 0.2094869
[Epoch 6; Iter   165/  183] train: loss: 0.2083476
[Epoch 6] ogbg-moltox21: 0.658273 val loss: 0.294456
[Epoch 6] ogbg-moltox21: 0.672468 test loss: 0.285894
[Epoch 7; Iter    12/  183] train: loss: 0.2409717
[Epoch 7; Iter    42/  183] train: loss: 0.1504571
[Epoch 7; Iter    72/  183] train: loss: 0.1649346
[Epoch 7; Iter   102/  183] train: loss: 0.1619474
[Epoch 7; Iter   132/  183] train: loss: 0.1348611
[Epoch 7; Iter   162/  183] train: loss: 0.1399916
[Epoch 7] ogbg-moltox21: 0.659380 val loss: 0.317072
[Epoch 7] ogbg-moltox21: 0.686098 test loss: 0.297628
[Epoch 8; Iter     9/  183] train: loss: 0.1949112
[Epoch 8; Iter    39/  183] train: loss: 0.2899175
[Epoch 8; Iter    69/  183] train: loss: 0.2225665
[Epoch 8; Iter    99/  183] train: loss: 0.1518450
[Epoch 8; Iter   129/  183] train: loss: 0.1368438
[Epoch 8; Iter   159/  183] train: loss: 0.2601412
[Epoch 8] ogbg-moltox21: 0.679566 val loss: 0.308818
[Epoch 8] ogbg-moltox21: 0.661838 test loss: 0.310136
[Epoch 9; Iter     6/  183] train: loss: 0.2858284
[Epoch 9; Iter    36/  183] train: loss: 0.2026042
[Epoch 9; Iter    66/  183] train: loss: 0.2303525
[Epoch 9; Iter    96/  183] train: loss: 0.1180646
[Epoch 9; Iter   126/  183] train: loss: 0.2203494
[Epoch 9; Iter   156/  183] train: loss: 0.1810141
[Epoch 9] ogbg-moltox21: 0.710169 val loss: 0.484031
[Epoch 9] ogbg-moltox21: 0.725327 test loss: 0.547496
[Epoch 10; Iter     3/  183] train: loss: 0.1580284
[Epoch 10; Iter    33/  183] train: loss: 0.1371965
[Epoch 10; Iter    63/  183] train: loss: 0.1610755
[Epoch 10; Iter    93/  183] train: loss: 0.1264541
[Epoch 10; Iter   123/  183] train: loss: 0.1960360
[Epoch 10; Iter   153/  183] train: loss: 0.1577472
[Epoch 10; Iter   183/  183] train: loss: 0.1342408
[Epoch 10] ogbg-moltox21: 0.710954 val loss: 0.289231
[Epoch 10] ogbg-moltox21: 0.716556 test loss: 0.294933
[Epoch 11; Iter    30/  183] train: loss: 0.1370316
[Epoch 11; Iter    60/  183] train: loss: 0.2983136
[Epoch 11; Iter    90/  183] train: loss: 0.1510168
[Epoch 11; Iter   120/  183] train: loss: 0.1476297
[Epoch 11; Iter   150/  183] train: loss: 0.1980872
[Epoch 11; Iter   180/  183] train: loss: 0.1928075
[Epoch 11] ogbg-moltox21: 0.737235 val loss: 0.303511
[Epoch 11] ogbg-moltox21: 0.741145 test loss: 0.363086
[Epoch 12; Iter    27/  183] train: loss: 0.1726264
[Epoch 12; Iter    57/  183] train: loss: 0.2108934
[Epoch 12; Iter    87/  183] train: loss: 0.2019107
[Epoch 12; Iter   117/  183] train: loss: 0.1608350
[Epoch 12; Iter   147/  183] train: loss: 0.1544914
[Epoch 12; Iter   177/  183] train: loss: 0.1669201
[Epoch 12] ogbg-moltox21: 0.745200 val loss: 0.300576
[Epoch 12] ogbg-moltox21: 0.731879 test loss: 0.302496
[Epoch 13; Iter    24/  183] train: loss: 0.2080938
[Epoch 13; Iter    54/  183] train: loss: 0.1726668
[Epoch 13; Iter    84/  183] train: loss: 0.2166340
[Epoch 13; Iter   114/  183] train: loss: 0.1903477
[Epoch 13; Iter   144/  183] train: loss: 0.1467908
[Epoch 13; Iter   174/  183] train: loss: 0.1861812
[Epoch 13] ogbg-moltox21: 0.732393 val loss: 0.414519
[Epoch 13] ogbg-moltox21: 0.736715 test loss: 0.670979
[Epoch 14; Iter    21/  183] train: loss: 0.0919861
[Epoch 14; Iter    51/  183] train: loss: 0.1747449
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.7/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.7_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.7
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6927258
[Epoch 1; Iter    60/  183] train: loss: 0.6944173
[Epoch 1; Iter    90/  183] train: loss: 0.6942227
[Epoch 1; Iter   120/  183] train: loss: 0.6930807
[Epoch 1; Iter   150/  183] train: loss: 0.6926470
[Epoch 1; Iter   180/  183] train: loss: 0.6930988
[Epoch 1] ogbg-moltox21: 0.501860 val loss: 0.694223
[Epoch 1] ogbg-moltox21: 0.506038 test loss: 0.693984
[Epoch 2; Iter    27/  183] train: loss: 0.6924172
[Epoch 2; Iter    57/  183] train: loss: 0.6917782
[Epoch 2; Iter    87/  183] train: loss: 0.6920602
[Epoch 2; Iter   117/  183] train: loss: 0.6918229
[Epoch 2; Iter   147/  183] train: loss: 0.6914951
[Epoch 2; Iter   177/  183] train: loss: 0.6911109
[Epoch 2] ogbg-moltox21: 0.505257 val loss: 0.692740
[Epoch 2] ogbg-moltox21: 0.508264 test loss: 0.692515
[Epoch 3; Iter    24/  183] train: loss: 0.6915864
[Epoch 3; Iter    54/  183] train: loss: 0.6912974
[Epoch 3; Iter    84/  183] train: loss: 0.6906317
[Epoch 3; Iter   114/  183] train: loss: 0.6893620
[Epoch 3; Iter   144/  183] train: loss: 0.6899208
[Epoch 3; Iter   174/  183] train: loss: 0.6894726
[Epoch 3] ogbg-moltox21: 0.505775 val loss: 0.691066
[Epoch 3] ogbg-moltox21: 0.516681 test loss: 0.690833
[Epoch 4; Iter    21/  183] train: loss: 0.6888275
[Epoch 4; Iter    51/  183] train: loss: 0.6886176
[Epoch 4; Iter    81/  183] train: loss: 0.6874396
[Epoch 4; Iter   111/  183] train: loss: 0.6891739
[Epoch 4; Iter   141/  183] train: loss: 0.6869333
[Epoch 4; Iter   171/  183] train: loss: 0.6823773
[Epoch 4] ogbg-moltox21: 0.648476 val loss: 0.703058
[Epoch 4] ogbg-moltox21: 0.631009 test loss: 0.703548
[Epoch 5; Iter    18/  183] train: loss: 0.6614925
[Epoch 5; Iter    48/  183] train: loss: 0.6201836
[Epoch 5; Iter    78/  183] train: loss: 0.5748700
[Epoch 5; Iter   108/  183] train: loss: 0.5252291
[Epoch 5; Iter   138/  183] train: loss: 0.4665752
[Epoch 5; Iter   168/  183] train: loss: 0.4138476
[Epoch 5] ogbg-moltox21: 0.685179 val loss: 0.536922
[Epoch 5] ogbg-moltox21: 0.654563 test loss: 0.544727
[Epoch 6; Iter    15/  183] train: loss: 0.3611845
[Epoch 6; Iter    45/  183] train: loss: 0.2959747
[Epoch 6; Iter    75/  183] train: loss: 0.3016899
[Epoch 6; Iter   105/  183] train: loss: 0.2268926
[Epoch 6; Iter   135/  183] train: loss: 0.2050648
[Epoch 6; Iter   165/  183] train: loss: 0.2071925
[Epoch 6] ogbg-moltox21: 0.678987 val loss: 0.339855
[Epoch 6] ogbg-moltox21: 0.674447 test loss: 0.337845
[Epoch 7; Iter    12/  183] train: loss: 0.2025042
[Epoch 7; Iter    42/  183] train: loss: 0.1614015
[Epoch 7; Iter    72/  183] train: loss: 0.2101490
[Epoch 7; Iter   102/  183] train: loss: 0.2120565
[Epoch 7; Iter   132/  183] train: loss: 0.1928112
[Epoch 7; Iter   162/  183] train: loss: 0.1544469
[Epoch 7] ogbg-moltox21: 0.686198 val loss: 0.472876
[Epoch 7] ogbg-moltox21: 0.683168 test loss: 0.538300
[Epoch 8; Iter     9/  183] train: loss: 0.1527681
[Epoch 8; Iter    39/  183] train: loss: 0.1398339
[Epoch 8; Iter    69/  183] train: loss: 0.1496891
[Epoch 8; Iter    99/  183] train: loss: 0.1850842
[Epoch 8; Iter   129/  183] train: loss: 0.1314116
[Epoch 8; Iter   159/  183] train: loss: 0.1993543
[Epoch 8] ogbg-moltox21: 0.700905 val loss: 0.397331
[Epoch 8] ogbg-moltox21: 0.706959 test loss: 0.431823
[Epoch 9; Iter     6/  183] train: loss: 0.1449730
[Epoch 9; Iter    36/  183] train: loss: 0.1994843
[Epoch 9; Iter    66/  183] train: loss: 0.1840834
[Epoch 9; Iter    96/  183] train: loss: 0.1376176
[Epoch 9; Iter   126/  183] train: loss: 0.1485698
[Epoch 9; Iter   156/  183] train: loss: 0.2874452
[Epoch 9] ogbg-moltox21: 0.731916 val loss: 0.293962
[Epoch 9] ogbg-moltox21: 0.724341 test loss: 0.302957
[Epoch 10; Iter     3/  183] train: loss: 0.2238525
[Epoch 10; Iter    33/  183] train: loss: 0.1937579
[Epoch 10; Iter    63/  183] train: loss: 0.2223197
[Epoch 10; Iter    93/  183] train: loss: 0.2270183
[Epoch 10; Iter   123/  183] train: loss: 0.2235584
[Epoch 10; Iter   153/  183] train: loss: 0.2163194
[Epoch 10; Iter   183/  183] train: loss: 0.1305997
[Epoch 10] ogbg-moltox21: 0.727219 val loss: 0.326408
[Epoch 10] ogbg-moltox21: 0.728479 test loss: 0.311027
[Epoch 11; Iter    30/  183] train: loss: 0.1632757
[Epoch 11; Iter    60/  183] train: loss: 0.2140538
[Epoch 11; Iter    90/  183] train: loss: 0.2080434
[Epoch 11; Iter   120/  183] train: loss: 0.1563046
[Epoch 11; Iter   150/  183] train: loss: 0.1640357
[Epoch 11; Iter   180/  183] train: loss: 0.1926506
[Epoch 11] ogbg-moltox21: 0.690042 val loss: 0.518973
[Epoch 11] ogbg-moltox21: 0.697544 test loss: 0.481130
[Epoch 12; Iter    27/  183] train: loss: 0.1903981
[Epoch 12; Iter    57/  183] train: loss: 0.2209678
[Epoch 12; Iter    87/  183] train: loss: 0.2269255
[Epoch 12; Iter   117/  183] train: loss: 0.2205827
[Epoch 12; Iter   147/  183] train: loss: 0.1466186
[Epoch 12; Iter   177/  183] train: loss: 0.2024038
[Epoch 12] ogbg-moltox21: 0.719847 val loss: 0.402513
[Epoch 12] ogbg-moltox21: 0.729428 test loss: 0.456329
[Epoch 13; Iter    24/  183] train: loss: 0.2143434
[Epoch 13; Iter    54/  183] train: loss: 0.1810873
[Epoch 13; Iter    84/  183] train: loss: 0.1492524
[Epoch 13; Iter   114/  183] train: loss: 0.1506767
[Epoch 13; Iter   144/  183] train: loss: 0.2414044
[Epoch 13; Iter   174/  183] train: loss: 0.1228373
[Epoch 13] ogbg-moltox21: 0.745628 val loss: 0.342409
[Epoch 13] ogbg-moltox21: 0.734475 test loss: 0.428498
[Epoch 14; Iter    21/  183] train: loss: 0.1429613
[Epoch 14; Iter    51/  183] train: loss: 0.1571773
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.6/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.6_6_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.6
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6927919
[Epoch 1; Iter    60/  157] train: loss: 0.6936274
[Epoch 1; Iter    90/  157] train: loss: 0.6933993
[Epoch 1; Iter   120/  157] train: loss: 0.6927335
[Epoch 1; Iter   150/  157] train: loss: 0.6931396
[Epoch 1] ogbg-moltox21: 0.479527 val loss: 0.693365
[Epoch 1] ogbg-moltox21: 0.483248 test loss: 0.693805
[Epoch 2; Iter    23/  157] train: loss: 0.6931740
[Epoch 2; Iter    53/  157] train: loss: 0.6924652
[Epoch 2; Iter    83/  157] train: loss: 0.6923708
[Epoch 2; Iter   113/  157] train: loss: 0.6922411
[Epoch 2; Iter   143/  157] train: loss: 0.6915721
[Epoch 2] ogbg-moltox21: 0.477915 val loss: 0.692498
[Epoch 2] ogbg-moltox21: 0.485642 test loss: 0.692974
[Epoch 3; Iter    16/  157] train: loss: 0.6909312
[Epoch 3; Iter    46/  157] train: loss: 0.6913432
[Epoch 3; Iter    76/  157] train: loss: 0.6912347
[Epoch 3; Iter   106/  157] train: loss: 0.6912262
[Epoch 3; Iter   136/  157] train: loss: 0.6910821
[Epoch 3] ogbg-moltox21: 0.493219 val loss: 0.690893
[Epoch 3] ogbg-moltox21: 0.493576 test loss: 0.691502
[Epoch 4; Iter     9/  157] train: loss: 0.6901622
[Epoch 4; Iter    39/  157] train: loss: 0.6903241
[Epoch 4; Iter    69/  157] train: loss: 0.6893077
[Epoch 4; Iter    99/  157] train: loss: 0.6890737
[Epoch 4; Iter   129/  157] train: loss: 0.6881886
[Epoch 4] ogbg-moltox21: 0.495836 val loss: 0.689674
[Epoch 4] ogbg-moltox21: 0.498810 test loss: 0.690389
[Epoch 5; Iter     2/  157] train: loss: 0.6876086
[Epoch 5; Iter    32/  157] train: loss: 0.6878297
[Epoch 5; Iter    62/  157] train: loss: 0.6869021
[Epoch 5; Iter    92/  157] train: loss: 0.6813771
[Epoch 5; Iter   122/  157] train: loss: 0.6626423
[Epoch 5; Iter   152/  157] train: loss: 0.6143538
[Epoch 5] ogbg-moltox21: 0.681003 val loss: 0.817558
[Epoch 5] ogbg-moltox21: 0.625378 test loss: 0.873876
[Epoch 6; Iter    25/  157] train: loss: 0.5764580
[Epoch 6; Iter    55/  157] train: loss: 0.5647669
[Epoch 6; Iter    85/  157] train: loss: 0.4656437
[Epoch 6; Iter   115/  157] train: loss: 0.4203030
[Epoch 6; Iter   145/  157] train: loss: 0.3500685
[Epoch 6] ogbg-moltox21: 0.699256 val loss: 0.488085
[Epoch 6] ogbg-moltox21: 0.648661 test loss: 0.526968
[Epoch 7; Iter    18/  157] train: loss: 0.2923263
[Epoch 7; Iter    48/  157] train: loss: 0.2520595
[Epoch 7; Iter    78/  157] train: loss: 0.2250402
[Epoch 7; Iter   108/  157] train: loss: 0.2295376
[Epoch 7; Iter   138/  157] train: loss: 0.2011124
[Epoch 7] ogbg-moltox21: 0.726468 val loss: 0.372635
[Epoch 7] ogbg-moltox21: 0.689632 test loss: 0.429699
[Epoch 8; Iter    11/  157] train: loss: 0.1673418
[Epoch 8; Iter    41/  157] train: loss: 0.1547354
[Epoch 8; Iter    71/  157] train: loss: 0.2467469
[Epoch 8; Iter   101/  157] train: loss: 0.1658699
[Epoch 8; Iter   131/  157] train: loss: 0.1781615
[Epoch 8] ogbg-moltox21: 0.701752 val loss: 0.340473
[Epoch 8] ogbg-moltox21: 0.670753 test loss: 0.381750
[Epoch 9; Iter     4/  157] train: loss: 0.1424621
[Epoch 9; Iter    34/  157] train: loss: 0.2024451
[Epoch 9; Iter    64/  157] train: loss: 0.1775579
[Epoch 9; Iter    94/  157] train: loss: 0.2651748
[Epoch 9; Iter   124/  157] train: loss: 0.2283482
[Epoch 9; Iter   154/  157] train: loss: 0.2150947
[Epoch 9] ogbg-moltox21: 0.709060 val loss: 0.365305
[Epoch 9] ogbg-moltox21: 0.684844 test loss: 0.396301
[Epoch 10; Iter    27/  157] train: loss: 0.2204378
[Epoch 10; Iter    57/  157] train: loss: 0.2077276
[Epoch 10; Iter    87/  157] train: loss: 0.1170352
[Epoch 10; Iter   117/  157] train: loss: 0.1534792
[Epoch 10; Iter   147/  157] train: loss: 0.1668061
[Epoch 10] ogbg-moltox21: 0.711515 val loss: 0.331690
[Epoch 10] ogbg-moltox21: 0.713281 test loss: 0.351555
[Epoch 11; Iter    20/  157] train: loss: 0.1546746
[Epoch 11; Iter    50/  157] train: loss: 0.1106423
[Epoch 11; Iter    80/  157] train: loss: 0.1606725
[Epoch 11; Iter   110/  157] train: loss: 0.1957902
[Epoch 11; Iter   140/  157] train: loss: 0.2458789
[Epoch 11] ogbg-moltox21: 0.614455 val loss: 0.395506
[Epoch 11] ogbg-moltox21: 0.589862 test loss: 0.445236
[Epoch 12; Iter    13/  157] train: loss: 0.2568806
[Epoch 12; Iter    43/  157] train: loss: 0.1515694
[Epoch 12; Iter    73/  157] train: loss: 0.2450770
[Epoch 12; Iter   103/  157] train: loss: 0.2101586
[Epoch 12; Iter   133/  157] train: loss: 0.1824543
[Epoch 12] ogbg-moltox21: 0.636002 val loss: 0.610612
[Epoch 12] ogbg-moltox21: 0.606336 test loss: 0.732816
[Epoch 13; Iter     6/  157] train: loss: 0.1312577
[Epoch 13; Iter    36/  157] train: loss: 0.1483064
[Epoch 13; Iter    66/  157] train: loss: 0.1504729
[Epoch 13; Iter    96/  157] train: loss: 0.1738814
[Epoch 13; Iter   126/  157] train: loss: 0.1852086
[Epoch 13; Iter   156/  157] train: loss: 0.2519793
[Epoch 13] ogbg-moltox21: 0.743703 val loss: 0.328301
[Epoch 13] ogbg-moltox21: 0.709926 test loss: 0.368780
[Epoch 14; Iter    29/  157] train: loss: 0.1498838
[Epoch 14; Iter    59/  157] train: loss: 0.2163590
[Epoch 14; Iter    89/  157] train: loss: 0.1890983
[Epoch 14; Iter   119/  157] train: loss: 0.0994387
[Epoch 14; Iter   149/  157] train: loss: 0.1416669
[Epoch 14] ogbg-moltox21: 0.767851 val loss: 0.324966
[Epoch 14] ogbg-moltox21: 0.730228 test loss: 0.374999
[Epoch 15; Iter    22/  157] train: loss: 0.1064688
[Epoch 15; Iter    52/  157] train: loss: 0.0951053
[Epoch 15; Iter    82/  157] train: loss: 0.1136050
[Epoch 15; Iter   112/  157] train: loss: 0.1733731
[Epoch 15; Iter   142/  157] train: loss: 0.1529528
[Epoch 15] ogbg-moltox21: 0.742000 val loss: 0.404601
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.6/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.6_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.6
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6935869
[Epoch 1; Iter    60/  157] train: loss: 0.6933795
[Epoch 1; Iter    90/  157] train: loss: 0.6928865
[Epoch 1; Iter   120/  157] train: loss: 0.6923899
[Epoch 1; Iter   150/  157] train: loss: 0.6938124
[Epoch 1] ogbg-moltox21: 0.503367 val loss: 0.693967
[Epoch 1] ogbg-moltox21: 0.490299 test loss: 0.694062
[Epoch 2; Iter    23/  157] train: loss: 0.6927534
[Epoch 2; Iter    53/  157] train: loss: 0.6929327
[Epoch 2; Iter    83/  157] train: loss: 0.6919321
[Epoch 2; Iter   113/  157] train: loss: 0.6926829
[Epoch 2; Iter   143/  157] train: loss: 0.6918592
[Epoch 2] ogbg-moltox21: 0.507142 val loss: 0.693381
[Epoch 2] ogbg-moltox21: 0.493190 test loss: 0.693538
[Epoch 3; Iter    16/  157] train: loss: 0.6918214
[Epoch 3; Iter    46/  157] train: loss: 0.6913821
[Epoch 3; Iter    76/  157] train: loss: 0.6910625
[Epoch 3; Iter   106/  157] train: loss: 0.6913471
[Epoch 3; Iter   136/  157] train: loss: 0.6908400
[Epoch 3] ogbg-moltox21: 0.509438 val loss: 0.692016
[Epoch 3] ogbg-moltox21: 0.495573 test loss: 0.692218
[Epoch 4; Iter     9/  157] train: loss: 0.6901263
[Epoch 4; Iter    39/  157] train: loss: 0.6908483
[Epoch 4; Iter    69/  157] train: loss: 0.6898451
[Epoch 4; Iter    99/  157] train: loss: 0.6887249
[Epoch 4; Iter   129/  157] train: loss: 0.6890079
[Epoch 4] ogbg-moltox21: 0.512193 val loss: 0.690043
[Epoch 4] ogbg-moltox21: 0.497700 test loss: 0.690214
[Epoch 5; Iter     2/  157] train: loss: 0.6889088
[Epoch 5; Iter    32/  157] train: loss: 0.6882439
[Epoch 5; Iter    62/  157] train: loss: 0.6870272
[Epoch 5; Iter    92/  157] train: loss: 0.6818449
[Epoch 5; Iter   122/  157] train: loss: 0.6643252
[Epoch 5; Iter   152/  157] train: loss: 0.6102820
[Epoch 5] ogbg-moltox21: 0.683388 val loss: 0.839232
[Epoch 5] ogbg-moltox21: 0.637587 test loss: 0.891187
[Epoch 6; Iter    25/  157] train: loss: 0.5737785
[Epoch 6; Iter    55/  157] train: loss: 0.5305687
[Epoch 6; Iter    85/  157] train: loss: 0.4622174
[Epoch 6; Iter   115/  157] train: loss: 0.4113726
[Epoch 6; Iter   145/  157] train: loss: 0.3503784
[Epoch 6] ogbg-moltox21: 0.665926 val loss: 0.588029
[Epoch 6] ogbg-moltox21: 0.623645 test loss: 0.640361
[Epoch 7; Iter    18/  157] train: loss: 0.3325559
[Epoch 7; Iter    48/  157] train: loss: 0.2731344
[Epoch 7; Iter    78/  157] train: loss: 0.2432563
[Epoch 7; Iter   108/  157] train: loss: 0.2026284
[Epoch 7; Iter   138/  157] train: loss: 0.1791761
[Epoch 7] ogbg-moltox21: 0.721146 val loss: 0.333407
[Epoch 7] ogbg-moltox21: 0.693873 test loss: 0.366734
[Epoch 8; Iter    11/  157] train: loss: 0.2406441
[Epoch 8; Iter    41/  157] train: loss: 0.2061344
[Epoch 8; Iter    71/  157] train: loss: 0.1608321
[Epoch 8; Iter   101/  157] train: loss: 0.1734566
[Epoch 8; Iter   131/  157] train: loss: 0.1252213
[Epoch 8] ogbg-moltox21: 0.711394 val loss: 0.308711
[Epoch 8] ogbg-moltox21: 0.692780 test loss: 0.324601
[Epoch 9; Iter     4/  157] train: loss: 0.2287312
[Epoch 9; Iter    34/  157] train: loss: 0.2094205
[Epoch 9; Iter    64/  157] train: loss: 0.2189377
[Epoch 9; Iter    94/  157] train: loss: 0.1682260
[Epoch 9; Iter   124/  157] train: loss: 0.2022927
[Epoch 9; Iter   154/  157] train: loss: 0.1516631
[Epoch 9] ogbg-moltox21: 0.733391 val loss: 0.361149
[Epoch 9] ogbg-moltox21: 0.689364 test loss: 0.481265
[Epoch 10; Iter    27/  157] train: loss: 0.1474603
[Epoch 10; Iter    57/  157] train: loss: 0.1752240
[Epoch 10; Iter    87/  157] train: loss: 0.1307669
[Epoch 10; Iter   117/  157] train: loss: 0.2296987
[Epoch 10; Iter   147/  157] train: loss: 0.2960084
[Epoch 10] ogbg-moltox21: 0.728461 val loss: 0.366906
[Epoch 10] ogbg-moltox21: 0.697582 test loss: 0.403682
[Epoch 11; Iter    20/  157] train: loss: 0.1698497
[Epoch 11; Iter    50/  157] train: loss: 0.2170356
[Epoch 11; Iter    80/  157] train: loss: 0.1776660
[Epoch 11; Iter   110/  157] train: loss: 0.1820350
[Epoch 11; Iter   140/  157] train: loss: 0.1424558
[Epoch 11] ogbg-moltox21: 0.721474 val loss: 0.603386
[Epoch 11] ogbg-moltox21: 0.715447 test loss: 0.656299
[Epoch 12; Iter    13/  157] train: loss: 0.1963800
[Epoch 12; Iter    43/  157] train: loss: 0.1850133
[Epoch 12; Iter    73/  157] train: loss: 0.1672270
[Epoch 12; Iter   103/  157] train: loss: 0.1087422
[Epoch 12; Iter   133/  157] train: loss: 0.2630967
[Epoch 12] ogbg-moltox21: 0.744306 val loss: 0.346893
[Epoch 12] ogbg-moltox21: 0.736939 test loss: 0.333327
[Epoch 13; Iter     6/  157] train: loss: 0.1584458
[Epoch 13; Iter    36/  157] train: loss: 0.2426578
[Epoch 13; Iter    66/  157] train: loss: 0.1414430
[Epoch 13; Iter    96/  157] train: loss: 0.1693661
[Epoch 13; Iter   126/  157] train: loss: 0.1154324
[Epoch 13; Iter   156/  157] train: loss: 0.2848168
[Epoch 13] ogbg-moltox21: 0.746904 val loss: 0.380355
[Epoch 13] ogbg-moltox21: 0.721431 test loss: 0.420785
[Epoch 14; Iter    29/  157] train: loss: 0.2369514
[Epoch 14; Iter    59/  157] train: loss: 0.1052525
[Epoch 14; Iter    89/  157] train: loss: 0.1817717
[Epoch 14; Iter   119/  157] train: loss: 0.2305371
[Epoch 14; Iter   149/  157] train: loss: 0.1677157
[Epoch 14] ogbg-moltox21: 0.744833 val loss: 0.349946
[Epoch 14] ogbg-moltox21: 0.717875 test loss: 0.402590
[Epoch 15; Iter    22/  157] train: loss: 0.1193673
[Epoch 15; Iter    52/  157] train: loss: 0.2032515
[Epoch 15; Iter    82/  157] train: loss: 0.1612928
[Epoch 15; Iter   112/  157] train: loss: 0.1277296
[Epoch 15; Iter   142/  157] train: loss: 0.1579390
[Epoch 15] ogbg-moltox21: 0.752683 val loss: 0.384030
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/tox21/scaff/train_prop=0.6/PNA_ogbg-moltox21_3DInfomax_tox21_scaff=0.6_5_26-05_09-18-14
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/tox21/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_scaff=0.6
logdir: runs/split/3DInfomax/tox21/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6932456
[Epoch 1; Iter    60/  157] train: loss: 0.6937904
[Epoch 1; Iter    90/  157] train: loss: 0.6930777
[Epoch 1; Iter   120/  157] train: loss: 0.6928831
[Epoch 1; Iter   150/  157] train: loss: 0.6924276
[Epoch 1] ogbg-moltox21: 0.500553 val loss: 0.692513
[Epoch 1] ogbg-moltox21: 0.488167 test loss: 0.692611
[Epoch 2; Iter    23/  157] train: loss: 0.6929017
[Epoch 2; Iter    53/  157] train: loss: 0.6919211
[Epoch 2; Iter    83/  157] train: loss: 0.6913384
[Epoch 2; Iter   113/  157] train: loss: 0.6919161
[Epoch 2; Iter   143/  157] train: loss: 0.6921139
[Epoch 2] ogbg-moltox21: 0.511279 val loss: 0.692509
[Epoch 2] ogbg-moltox21: 0.497005 test loss: 0.692818
[Epoch 3; Iter    16/  157] train: loss: 0.6913130
[Epoch 3; Iter    46/  157] train: loss: 0.6906444
[Epoch 3; Iter    76/  157] train: loss: 0.6909876
[Epoch 3; Iter   106/  157] train: loss: 0.6913267
[Epoch 3; Iter   136/  157] train: loss: 0.6911860
[Epoch 3] ogbg-moltox21: 0.510967 val loss: 0.690655
[Epoch 3] ogbg-moltox21: 0.497603 test loss: 0.690944
[Epoch 4; Iter     9/  157] train: loss: 0.6904830
[Epoch 4; Iter    39/  157] train: loss: 0.6893141
[Epoch 4; Iter    69/  157] train: loss: 0.6887919
[Epoch 4; Iter    99/  157] train: loss: 0.6883051
[Epoch 4; Iter   129/  157] train: loss: 0.6877561
[Epoch 4] ogbg-moltox21: 0.513850 val loss: 0.688265
[Epoch 4] ogbg-moltox21: 0.507844 test loss: 0.688452
[Epoch 5; Iter     2/  157] train: loss: 0.6872124
[Epoch 5; Iter    32/  157] train: loss: 0.6870278
[Epoch 5; Iter    62/  157] train: loss: 0.6865226
[Epoch 5; Iter    92/  157] train: loss: 0.6818340
[Epoch 5; Iter   122/  157] train: loss: 0.6556494
[Epoch 5; Iter   152/  157] train: loss: 0.6212098
[Epoch 5] ogbg-moltox21: 0.697664 val loss: 0.751555
[Epoch 5] ogbg-moltox21: 0.637036 test loss: 0.783573
[Epoch 6; Iter    25/  157] train: loss: 0.5707669
[Epoch 6; Iter    55/  157] train: loss: 0.5149180
[Epoch 6; Iter    85/  157] train: loss: 0.4607497
[Epoch 6; Iter   115/  157] train: loss: 0.3959119
[Epoch 6; Iter   145/  157] train: loss: 0.3546930
[Epoch 6] ogbg-moltox21: 0.657860 val loss: 0.470293
[Epoch 6] ogbg-moltox21: 0.628400 test loss: 0.510765
[Epoch 7; Iter    18/  157] train: loss: 0.3129572
[Epoch 7; Iter    48/  157] train: loss: 0.2875459
[Epoch 7; Iter    78/  157] train: loss: 0.2825538
[Epoch 7; Iter   108/  157] train: loss: 0.2706775
[Epoch 7; Iter   138/  157] train: loss: 0.1885232
[Epoch 7] ogbg-moltox21: 0.708605 val loss: 0.311058
[Epoch 7] ogbg-moltox21: 0.684262 test loss: 0.321517
[Epoch 8; Iter    11/  157] train: loss: 0.2282389
[Epoch 8; Iter    41/  157] train: loss: 0.1467413
[Epoch 8; Iter    71/  157] train: loss: 0.1972416
[Epoch 8; Iter   101/  157] train: loss: 0.3238743
[Epoch 8; Iter   131/  157] train: loss: 0.2355503
[Epoch 8] ogbg-moltox21: 0.700256 val loss: 0.314570
[Epoch 8] ogbg-moltox21: 0.660331 test loss: 0.353017
[Epoch 9; Iter     4/  157] train: loss: 0.1865994
[Epoch 9; Iter    34/  157] train: loss: 0.2200383
[Epoch 9; Iter    64/  157] train: loss: 0.1839212
[Epoch 9; Iter    94/  157] train: loss: 0.2358002
[Epoch 9; Iter   124/  157] train: loss: 0.1648687
[Epoch 9; Iter   154/  157] train: loss: 0.1708074
[Epoch 9] ogbg-moltox21: 0.721904 val loss: 0.282692
[Epoch 9] ogbg-moltox21: 0.683787 test loss: 0.325393
[Epoch 10; Iter    27/  157] train: loss: 0.1057285
[Epoch 10; Iter    57/  157] train: loss: 0.1302399
[Epoch 10; Iter    87/  157] train: loss: 0.1470044
[Epoch 10; Iter   117/  157] train: loss: 0.1355594
[Epoch 10; Iter   147/  157] train: loss: 0.1455409
[Epoch 10] ogbg-moltox21: 0.720432 val loss: 0.448614
[Epoch 10] ogbg-moltox21: 0.710677 test loss: 0.665990
[Epoch 11; Iter    20/  157] train: loss: 0.1164461
[Epoch 11; Iter    50/  157] train: loss: 0.1632909
[Epoch 11; Iter    80/  157] train: loss: 0.1680098
[Epoch 11; Iter   110/  157] train: loss: 0.1601523
[Epoch 11; Iter   140/  157] train: loss: 0.2688116
[Epoch 11] ogbg-moltox21: 0.677852 val loss: 0.874924
[Epoch 11] ogbg-moltox21: 0.674095 test loss: 2.602977
[Epoch 12; Iter    13/  157] train: loss: 0.2415781
[Epoch 12; Iter    43/  157] train: loss: 0.2420262
[Epoch 12; Iter    73/  157] train: loss: 0.1536923
[Epoch 12; Iter   103/  157] train: loss: 0.1578499
[Epoch 12; Iter   133/  157] train: loss: 0.1708155
[Epoch 12] ogbg-moltox21: 0.709985 val loss: 1.124135
[Epoch 12] ogbg-moltox21: 0.693669 test loss: 0.545894
[Epoch 13; Iter     6/  157] train: loss: 0.1813216
[Epoch 13; Iter    36/  157] train: loss: 0.2346092
[Epoch 13; Iter    66/  157] train: loss: 0.1942846
[Epoch 13; Iter    96/  157] train: loss: 0.2075715
[Epoch 13; Iter   126/  157] train: loss: 0.2965798
[Epoch 13; Iter   156/  157] train: loss: 0.1818288
[Epoch 13] ogbg-moltox21: 0.725751 val loss: 0.344625
[Epoch 13] ogbg-moltox21: 0.719555 test loss: 0.593526
[Epoch 14; Iter    29/  157] train: loss: 0.1945723
[Epoch 14; Iter    59/  157] train: loss: 0.1191479
[Epoch 14; Iter    89/  157] train: loss: 0.1477425
[Epoch 14; Iter   119/  157] train: loss: 0.1837256
[Epoch 14; Iter   149/  157] train: loss: 0.1451879
[Epoch 14] ogbg-moltox21: 0.749723 val loss: 0.287095
[Epoch 14] ogbg-moltox21: 0.729758 test loss: 0.380342
[Epoch 15; Iter    22/  157] train: loss: 0.1325965
[Epoch 15; Iter    52/  157] train: loss: 0.1216435
[Epoch 15; Iter    82/  157] train: loss: 0.1685018
[Epoch 15; Iter   112/  157] train: loss: 0.1375961
[Epoch 15; Iter   142/  157] train: loss: 0.2770973
[Epoch 15] ogbg-moltox21: 0.734327 val loss: 0.297793
[Epoch 13; Iter    12/  209] train: loss: 0.1915499
[Epoch 13; Iter    42/  209] train: loss: 0.1588907
[Epoch 13; Iter    72/  209] train: loss: 0.2558746
[Epoch 13; Iter   102/  209] train: loss: 0.1587985
[Epoch 13; Iter   132/  209] train: loss: 0.2585378
[Epoch 13; Iter   162/  209] train: loss: 0.2583131
[Epoch 13; Iter   192/  209] train: loss: 0.2114233
[Epoch 13] ogbg-moltox21: 0.766869 val loss: 0.311556
[Epoch 13] ogbg-moltox21: 0.761802 test loss: 0.302288
[Epoch 14; Iter    13/  209] train: loss: 0.2055697
[Epoch 14; Iter    43/  209] train: loss: 0.1894646
[Epoch 14; Iter    73/  209] train: loss: 0.2003746
[Epoch 14; Iter   103/  209] train: loss: 0.1966029
[Epoch 14; Iter   133/  209] train: loss: 0.2381682
[Epoch 14; Iter   163/  209] train: loss: 0.1968673
[Epoch 14; Iter   193/  209] train: loss: 0.1927383
[Epoch 14] ogbg-moltox21: 0.767681 val loss: 0.250588
[Epoch 14] ogbg-moltox21: 0.737776 test loss: 0.264220
[Epoch 15; Iter    14/  209] train: loss: 0.1724426
[Epoch 15; Iter    44/  209] train: loss: 0.2441220
[Epoch 15; Iter    74/  209] train: loss: 0.1638725
[Epoch 15; Iter   104/  209] train: loss: 0.2308681
[Epoch 15; Iter   134/  209] train: loss: 0.1599440
[Epoch 15; Iter   164/  209] train: loss: 0.1718310
[Epoch 15; Iter   194/  209] train: loss: 0.2147460
[Epoch 15] ogbg-moltox21: 0.772007 val loss: 0.254011
[Epoch 15] ogbg-moltox21: 0.724989 test loss: 0.266683
[Epoch 16; Iter    15/  209] train: loss: 0.2116715
[Epoch 16; Iter    45/  209] train: loss: 0.1579032
[Epoch 16; Iter    75/  209] train: loss: 0.2108358
[Epoch 16; Iter   105/  209] train: loss: 0.1667347
[Epoch 16; Iter   135/  209] train: loss: 0.2036210
[Epoch 16; Iter   165/  209] train: loss: 0.1887251
[Epoch 16; Iter   195/  209] train: loss: 0.1871645
[Epoch 16] ogbg-moltox21: 0.782598 val loss: 0.253519
[Epoch 16] ogbg-moltox21: 0.764465 test loss: 0.264309
[Epoch 17; Iter    16/  209] train: loss: 0.1627696
[Epoch 17; Iter    46/  209] train: loss: 0.1373264
[Epoch 17; Iter    76/  209] train: loss: 0.1238074
[Epoch 17; Iter   106/  209] train: loss: 0.1854312
[Epoch 17; Iter   136/  209] train: loss: 0.1389485
[Epoch 17; Iter   166/  209] train: loss: 0.1648755
[Epoch 17; Iter   196/  209] train: loss: 0.1319323
[Epoch 17] ogbg-moltox21: 0.770582 val loss: 0.257500
[Epoch 17] ogbg-moltox21: 0.721059 test loss: 0.281635
[Epoch 18; Iter    17/  209] train: loss: 0.1105968
[Epoch 18; Iter    47/  209] train: loss: 0.2047583
[Epoch 18; Iter    77/  209] train: loss: 0.2651394
[Epoch 18; Iter   107/  209] train: loss: 0.2347575
[Epoch 18; Iter   137/  209] train: loss: 0.1612289
[Epoch 18; Iter   167/  209] train: loss: 0.1510506
[Epoch 18; Iter   197/  209] train: loss: 0.1173746
[Epoch 18] ogbg-moltox21: 0.786924 val loss: 0.240131
[Epoch 18] ogbg-moltox21: 0.752589 test loss: 0.258261
[Epoch 19; Iter    18/  209] train: loss: 0.2792657
[Epoch 19; Iter    48/  209] train: loss: 0.1602571
[Epoch 19; Iter    78/  209] train: loss: 0.1425528
[Epoch 19; Iter   108/  209] train: loss: 0.1429106
[Epoch 19; Iter   138/  209] train: loss: 0.1215284
[Epoch 19; Iter   168/  209] train: loss: 0.1875431
[Epoch 19; Iter   198/  209] train: loss: 0.3225737
[Epoch 19] ogbg-moltox21: 0.779353 val loss: 0.254069
[Epoch 19] ogbg-moltox21: 0.716592 test loss: 0.313630
[Epoch 20; Iter    19/  209] train: loss: 0.2198901
[Epoch 20; Iter    49/  209] train: loss: 0.2404140
[Epoch 20; Iter    79/  209] train: loss: 0.1053156
[Epoch 20; Iter   109/  209] train: loss: 0.1316309
[Epoch 20; Iter   139/  209] train: loss: 0.2392606
[Epoch 20; Iter   169/  209] train: loss: 0.2369007
[Epoch 20; Iter   199/  209] train: loss: 0.1157360
[Epoch 20] ogbg-moltox21: 0.783064 val loss: 0.241886
[Epoch 20] ogbg-moltox21: 0.741243 test loss: 0.308017
[Epoch 21; Iter    20/  209] train: loss: 0.1375722
[Epoch 21; Iter    50/  209] train: loss: 0.2157315
[Epoch 21; Iter    80/  209] train: loss: 0.1736442
[Epoch 21; Iter   110/  209] train: loss: 0.0935943
[Epoch 21; Iter   140/  209] train: loss: 0.2168415
[Epoch 21; Iter   170/  209] train: loss: 0.3462657
[Epoch 21; Iter   200/  209] train: loss: 0.1637320
[Epoch 21] ogbg-moltox21: 0.792698 val loss: 0.239590
[Epoch 21] ogbg-moltox21: 0.750712 test loss: 0.259191
[Epoch 22; Iter    21/  209] train: loss: 0.1429019
[Epoch 22; Iter    51/  209] train: loss: 0.0790258
[Epoch 22; Iter    81/  209] train: loss: 0.1256689
[Epoch 22; Iter   111/  209] train: loss: 0.1182405
[Epoch 22; Iter   141/  209] train: loss: 0.1669538
[Epoch 22; Iter   171/  209] train: loss: 0.1234417
[Epoch 22; Iter   201/  209] train: loss: 0.1104693
[Epoch 22] ogbg-moltox21: 0.788093 val loss: 0.362511
[Epoch 22] ogbg-moltox21: 0.745480 test loss: 0.601093
[Epoch 23; Iter    22/  209] train: loss: 0.1906327
[Epoch 23; Iter    52/  209] train: loss: 0.1827843
[Epoch 23; Iter    82/  209] train: loss: 0.1481054
[Epoch 23; Iter   112/  209] train: loss: 0.1513643
[Epoch 23; Iter   142/  209] train: loss: 0.1661910
[Epoch 23; Iter   172/  209] train: loss: 0.1430021
[Epoch 23; Iter   202/  209] train: loss: 0.1446400
[Epoch 23] ogbg-moltox21: 0.778734 val loss: 0.315858
[Epoch 23] ogbg-moltox21: 0.746263 test loss: 0.387006
[Epoch 24; Iter    23/  209] train: loss: 0.2322216
[Epoch 24; Iter    53/  209] train: loss: 0.1132566
[Epoch 24; Iter    83/  209] train: loss: 0.1850208
[Epoch 24; Iter   113/  209] train: loss: 0.1349326
[Epoch 24; Iter   143/  209] train: loss: 0.1039607
[Epoch 24; Iter   173/  209] train: loss: 0.1195965
[Epoch 24; Iter   203/  209] train: loss: 0.1855408
[Epoch 24] ogbg-moltox21: 0.765429 val loss: 0.300640
[Epoch 24] ogbg-moltox21: 0.744839 test loss: 0.266604
[Epoch 25; Iter    24/  209] train: loss: 0.1090068
[Epoch 25; Iter    54/  209] train: loss: 0.2350933
[Epoch 25; Iter    84/  209] train: loss: 0.1283211
[Epoch 25; Iter   114/  209] train: loss: 0.1719978
[Epoch 25; Iter   144/  209] train: loss: 0.1465671
[Epoch 25; Iter   174/  209] train: loss: 0.1682697
[Epoch 25; Iter   204/  209] train: loss: 0.2364862
[Epoch 25] ogbg-moltox21: 0.802798 val loss: 0.252566
[Epoch 25] ogbg-moltox21: 0.765662 test loss: 0.459477
[Epoch 26; Iter    25/  209] train: loss: 0.1772695
[Epoch 26; Iter    55/  209] train: loss: 0.2083990
[Epoch 26; Iter    85/  209] train: loss: 0.1954297
[Epoch 26; Iter   115/  209] train: loss: 0.0863715
[Epoch 26; Iter   145/  209] train: loss: 0.1771716
[Epoch 26; Iter   175/  209] train: loss: 0.1016210
[Epoch 26; Iter   205/  209] train: loss: 0.1877722
[Epoch 26] ogbg-moltox21: 0.748325 val loss: 0.341597
[Epoch 26] ogbg-moltox21: 0.746249 test loss: 0.422151
[Epoch 27; Iter    26/  209] train: loss: 0.1157297
[Epoch 27; Iter    56/  209] train: loss: 0.2677121
[Epoch 27; Iter    86/  209] train: loss: 0.1925311
[Epoch 27; Iter   116/  209] train: loss: 0.1606163
[Epoch 27; Iter   146/  209] train: loss: 0.1392119
[Epoch 27; Iter   176/  209] train: loss: 0.1100091
[Epoch 27; Iter   206/  209] train: loss: 0.1524364
[Epoch 27] ogbg-moltox21: 0.797228 val loss: 0.273510
[Epoch 27] ogbg-moltox21: 0.753011 test loss: 0.273662
[Epoch 28; Iter    27/  209] train: loss: 0.1297970
[Epoch 28; Iter    57/  209] train: loss: 0.1349903
[Epoch 28; Iter    87/  209] train: loss: 0.1575696
[Epoch 28; Iter   117/  209] train: loss: 0.1388616
[Epoch 28; Iter   147/  209] train: loss: 0.1631629
[Epoch 28; Iter   177/  209] train: loss: 0.1658467
[Epoch 28; Iter   207/  209] train: loss: 0.1458129
[Epoch 28] ogbg-moltox21: 0.800901 val loss: 0.474788
[Epoch 28] ogbg-moltox21: 0.761816 test loss: 0.582771
[Epoch 29; Iter    28/  209] train: loss: 0.1430161
[Epoch 29; Iter    58/  209] train: loss: 0.1302029
[Epoch 29; Iter    88/  209] train: loss: 0.1428556
[Epoch 29; Iter   118/  209] train: loss: 0.2153343
[Epoch 29; Iter   148/  209] train: loss: 0.1548311
[Epoch 29; Iter   178/  209] train: loss: 0.1060283
[Epoch 29; Iter   208/  209] train: loss: 0.1016422
[Epoch 29] ogbg-moltox21: 0.792619 val loss: 0.252173
[Epoch 29] ogbg-moltox21: 0.750614 test loss: 0.268792
[Epoch 30; Iter    29/  209] train: loss: 0.1531183
[Epoch 30; Iter    59/  209] train: loss: 0.1199527
[Epoch 13; Iter    12/  209] train: loss: 0.2026837
[Epoch 13; Iter    42/  209] train: loss: 0.2004283
[Epoch 13; Iter    72/  209] train: loss: 0.2077805
[Epoch 13; Iter   102/  209] train: loss: 0.1941006
[Epoch 13; Iter   132/  209] train: loss: 0.1361867
[Epoch 13; Iter   162/  209] train: loss: 0.1980552
[Epoch 13; Iter   192/  209] train: loss: 0.1630481
[Epoch 13] ogbg-moltox21: 0.789138 val loss: 0.254794
[Epoch 13] ogbg-moltox21: 0.767797 test loss: 0.263295
[Epoch 14; Iter    13/  209] train: loss: 0.1761113
[Epoch 14; Iter    43/  209] train: loss: 0.1837884
[Epoch 14; Iter    73/  209] train: loss: 0.2080765
[Epoch 14; Iter   103/  209] train: loss: 0.1417364
[Epoch 14; Iter   133/  209] train: loss: 0.1894808
[Epoch 14; Iter   163/  209] train: loss: 0.1487305
[Epoch 14; Iter   193/  209] train: loss: 0.2516316
[Epoch 14] ogbg-moltox21: 0.779255 val loss: 0.254280
[Epoch 14] ogbg-moltox21: 0.753527 test loss: 0.270525
[Epoch 15; Iter    14/  209] train: loss: 0.1977573
[Epoch 15; Iter    44/  209] train: loss: 0.1656194
[Epoch 15; Iter    74/  209] train: loss: 0.1474119
[Epoch 15; Iter   104/  209] train: loss: 0.2448124
[Epoch 15; Iter   134/  209] train: loss: 0.1350482
[Epoch 15; Iter   164/  209] train: loss: 0.1486418
[Epoch 15; Iter   194/  209] train: loss: 0.1415280
[Epoch 15] ogbg-moltox21: 0.780457 val loss: 0.246195
[Epoch 15] ogbg-moltox21: 0.753968 test loss: 0.261692
[Epoch 16; Iter    15/  209] train: loss: 0.1289420
[Epoch 16; Iter    45/  209] train: loss: 0.1978219
[Epoch 16; Iter    75/  209] train: loss: 0.2109323
[Epoch 16; Iter   105/  209] train: loss: 0.2416237
[Epoch 16; Iter   135/  209] train: loss: 0.1813131
[Epoch 16; Iter   165/  209] train: loss: 0.1259966
[Epoch 16; Iter   195/  209] train: loss: 0.1533394
[Epoch 16] ogbg-moltox21: 0.757222 val loss: 0.390265
[Epoch 16] ogbg-moltox21: 0.749064 test loss: 0.321897
[Epoch 17; Iter    16/  209] train: loss: 0.2112451
[Epoch 17; Iter    46/  209] train: loss: 0.2205538
[Epoch 17; Iter    76/  209] train: loss: 0.1461298
[Epoch 17; Iter   106/  209] train: loss: 0.2323968
[Epoch 17; Iter   136/  209] train: loss: 0.0905054
[Epoch 17; Iter   166/  209] train: loss: 0.1611687
[Epoch 17; Iter   196/  209] train: loss: 0.2227669
[Epoch 17] ogbg-moltox21: 0.774188 val loss: 0.256451
[Epoch 17] ogbg-moltox21: 0.761673 test loss: 0.263238
[Epoch 18; Iter    17/  209] train: loss: 0.1683785
[Epoch 18; Iter    47/  209] train: loss: 0.1289781
[Epoch 18; Iter    77/  209] train: loss: 0.1890959
[Epoch 18; Iter   107/  209] train: loss: 0.2411420
[Epoch 18; Iter   137/  209] train: loss: 0.1255701
[Epoch 18; Iter   167/  209] train: loss: 0.1287817
[Epoch 18; Iter   197/  209] train: loss: 0.1221676
[Epoch 18] ogbg-moltox21: 0.789133 val loss: 0.252484
[Epoch 18] ogbg-moltox21: 0.768374 test loss: 0.255413
[Epoch 19; Iter    18/  209] train: loss: 0.1602592
[Epoch 19; Iter    48/  209] train: loss: 0.1151796
[Epoch 19; Iter    78/  209] train: loss: 0.2069001
[Epoch 19; Iter   108/  209] train: loss: 0.1698368
[Epoch 19; Iter   138/  209] train: loss: 0.2005076
[Epoch 19; Iter   168/  209] train: loss: 0.1887495
[Epoch 19; Iter   198/  209] train: loss: 0.1233623
[Epoch 19] ogbg-moltox21: 0.771926 val loss: 0.252980
[Epoch 19] ogbg-moltox21: 0.752353 test loss: 0.267691
[Epoch 20; Iter    19/  209] train: loss: 0.2052587
[Epoch 20; Iter    49/  209] train: loss: 0.1393034
[Epoch 20; Iter    79/  209] train: loss: 0.1260033
[Epoch 20; Iter   109/  209] train: loss: 0.1111094
[Epoch 20; Iter   139/  209] train: loss: 0.1556537
[Epoch 20; Iter   169/  209] train: loss: 0.1670530
[Epoch 20; Iter   199/  209] train: loss: 0.1853373
[Epoch 20] ogbg-moltox21: 0.745126 val loss: 6.756600
[Epoch 20] ogbg-moltox21: 0.709196 test loss: 10.215853
[Epoch 21; Iter    20/  209] train: loss: 0.1716333
[Epoch 21; Iter    50/  209] train: loss: 0.1896371
[Epoch 21; Iter    80/  209] train: loss: 0.1482409
[Epoch 21; Iter   110/  209] train: loss: 0.3301058
[Epoch 21; Iter   140/  209] train: loss: 0.2137285
[Epoch 21; Iter   170/  209] train: loss: 0.2327706
[Epoch 21; Iter   200/  209] train: loss: 0.1749491
[Epoch 21] ogbg-moltox21: 0.762292 val loss: 0.331764
[Epoch 21] ogbg-moltox21: 0.754109 test loss: 0.268725
[Epoch 22; Iter    21/  209] train: loss: 0.1128617
[Epoch 22; Iter    51/  209] train: loss: 0.2020413
[Epoch 22; Iter    81/  209] train: loss: 0.1559841
[Epoch 22; Iter   111/  209] train: loss: 0.2485913
[Epoch 22; Iter   141/  209] train: loss: 0.1496225
[Epoch 22; Iter   171/  209] train: loss: 0.1889114
[Epoch 22; Iter   201/  209] train: loss: 0.1712902
[Epoch 22] ogbg-moltox21: 0.766272 val loss: 0.257871
[Epoch 22] ogbg-moltox21: 0.769651 test loss: 0.263625
[Epoch 23; Iter    22/  209] train: loss: 0.1170966
[Epoch 23; Iter    52/  209] train: loss: 0.1250966
[Epoch 23; Iter    82/  209] train: loss: 0.1410317
[Epoch 23; Iter   112/  209] train: loss: 0.1685647
[Epoch 23; Iter   142/  209] train: loss: 0.1759900
[Epoch 23; Iter   172/  209] train: loss: 0.1770945
[Epoch 23; Iter   202/  209] train: loss: 0.1533449
[Epoch 23] ogbg-moltox21: 0.783671 val loss: 0.342063
[Epoch 23] ogbg-moltox21: 0.766520 test loss: 0.266089
[Epoch 24; Iter    23/  209] train: loss: 0.1502088
[Epoch 24; Iter    53/  209] train: loss: 0.1814473
[Epoch 24; Iter    83/  209] train: loss: 0.1705346
[Epoch 24; Iter   113/  209] train: loss: 0.1324525
[Epoch 24; Iter   143/  209] train: loss: 0.1609215
[Epoch 24; Iter   173/  209] train: loss: 0.1283130
[Epoch 24; Iter   203/  209] train: loss: 0.2331255
[Epoch 24] ogbg-moltox21: 0.776212 val loss: 0.257652
[Epoch 24] ogbg-moltox21: 0.769428 test loss: 0.267165
[Epoch 25; Iter    24/  209] train: loss: 0.1334804
[Epoch 25; Iter    54/  209] train: loss: 0.1042264
[Epoch 25; Iter    84/  209] train: loss: 0.1090382
[Epoch 25; Iter   114/  209] train: loss: 0.1780601
[Epoch 25; Iter   144/  209] train: loss: 0.2071529
[Epoch 25; Iter   174/  209] train: loss: 0.1341391
[Epoch 25; Iter   204/  209] train: loss: 0.1394172
[Epoch 25] ogbg-moltox21: 0.782059 val loss: 0.256288
[Epoch 25] ogbg-moltox21: 0.757817 test loss: 0.275996
[Epoch 26; Iter    25/  209] train: loss: 0.1653140
[Epoch 26; Iter    55/  209] train: loss: 0.1844482
[Epoch 26; Iter    85/  209] train: loss: 0.2406104
[Epoch 26; Iter   115/  209] train: loss: 0.1643656
[Epoch 26; Iter   145/  209] train: loss: 0.1481245
[Epoch 26; Iter   175/  209] train: loss: 0.1480331
[Epoch 26; Iter   205/  209] train: loss: 0.1207211
[Epoch 26] ogbg-moltox21: 0.793523 val loss: 0.244893
[Epoch 26] ogbg-moltox21: 0.769467 test loss: 0.253467
[Epoch 27; Iter    26/  209] train: loss: 0.1837681
[Epoch 27; Iter    56/  209] train: loss: 0.0938246
[Epoch 27; Iter    86/  209] train: loss: 0.1842989
[Epoch 27; Iter   116/  209] train: loss: 0.1296470
[Epoch 27; Iter   146/  209] train: loss: 0.1889105
[Epoch 27; Iter   176/  209] train: loss: 0.2262062
[Epoch 27; Iter   206/  209] train: loss: 0.1651178
[Epoch 27] ogbg-moltox21: 0.788633 val loss: 0.281015
[Epoch 27] ogbg-moltox21: 0.778472 test loss: 0.283550
[Epoch 28; Iter    27/  209] train: loss: 0.1229409
[Epoch 28; Iter    57/  209] train: loss: 0.2504776
[Epoch 28; Iter    87/  209] train: loss: 0.1810915
[Epoch 28; Iter   117/  209] train: loss: 0.1356050
[Epoch 28; Iter   147/  209] train: loss: 0.1910928
[Epoch 28; Iter   177/  209] train: loss: 0.2018705
[Epoch 28; Iter   207/  209] train: loss: 0.1189778
[Epoch 28] ogbg-moltox21: 0.778608 val loss: 0.249382
[Epoch 28] ogbg-moltox21: 0.765609 test loss: 0.263527
[Epoch 29; Iter    28/  209] train: loss: 0.1247688
[Epoch 29; Iter    58/  209] train: loss: 0.1583707
[Epoch 29; Iter    88/  209] train: loss: 0.1346188
[Epoch 29; Iter   118/  209] train: loss: 0.2018729
[Epoch 29; Iter   148/  209] train: loss: 0.1171234
[Epoch 29; Iter   178/  209] train: loss: 0.0905327
[Epoch 29; Iter   208/  209] train: loss: 0.1168251
[Epoch 29] ogbg-moltox21: 0.780830 val loss: 0.272500
[Epoch 29] ogbg-moltox21: 0.764595 test loss: 0.279380
[Epoch 30; Iter    29/  209] train: loss: 0.1409276
[Epoch 30; Iter    59/  209] train: loss: 0.1393445
[Epoch 13; Iter    12/  209] train: loss: 0.1664009
[Epoch 13; Iter    42/  209] train: loss: 0.1768149
[Epoch 13; Iter    72/  209] train: loss: 0.1706357
[Epoch 13; Iter   102/  209] train: loss: 0.1983036
[Epoch 13; Iter   132/  209] train: loss: 0.1643123
[Epoch 13; Iter   162/  209] train: loss: 0.2409581
[Epoch 13; Iter   192/  209] train: loss: 0.1845134
[Epoch 13] ogbg-moltox21: 0.785104 val loss: 0.269725
[Epoch 13] ogbg-moltox21: 0.748566 test loss: 0.278054
[Epoch 14; Iter    13/  209] train: loss: 0.1119437
[Epoch 14; Iter    43/  209] train: loss: 0.1661776
[Epoch 14; Iter    73/  209] train: loss: 0.1463092
[Epoch 14; Iter   103/  209] train: loss: 0.2387900
[Epoch 14; Iter   133/  209] train: loss: 0.2014128
[Epoch 14; Iter   163/  209] train: loss: 0.1994091
[Epoch 14; Iter   193/  209] train: loss: 0.1833921
[Epoch 14] ogbg-moltox21: 0.772798 val loss: 0.269709
[Epoch 14] ogbg-moltox21: 0.744901 test loss: 0.279320
[Epoch 15; Iter    14/  209] train: loss: 0.1076501
[Epoch 15; Iter    44/  209] train: loss: 0.1545193
[Epoch 15; Iter    74/  209] train: loss: 0.2008856
[Epoch 15; Iter   104/  209] train: loss: 0.1292979
[Epoch 15; Iter   134/  209] train: loss: 0.1373713
[Epoch 15; Iter   164/  209] train: loss: 0.1344055
[Epoch 15; Iter   194/  209] train: loss: 0.1525825
[Epoch 15] ogbg-moltox21: 0.788245 val loss: 0.259461
[Epoch 15] ogbg-moltox21: 0.745503 test loss: 0.296929
[Epoch 16; Iter    15/  209] train: loss: 0.1299750
[Epoch 16; Iter    45/  209] train: loss: 0.1525165
[Epoch 16; Iter    75/  209] train: loss: 0.2825558
[Epoch 16; Iter   105/  209] train: loss: 0.2480458
[Epoch 16; Iter   135/  209] train: loss: 0.2477940
[Epoch 16; Iter   165/  209] train: loss: 0.3123989
[Epoch 16; Iter   195/  209] train: loss: 0.1856287
[Epoch 16] ogbg-moltox21: 0.793859 val loss: 0.242615
[Epoch 16] ogbg-moltox21: 0.757035 test loss: 0.526830
[Epoch 17; Iter    16/  209] train: loss: 0.1704676
[Epoch 17; Iter    46/  209] train: loss: 0.1956867
[Epoch 17; Iter    76/  209] train: loss: 0.2252668
[Epoch 17; Iter   106/  209] train: loss: 0.1885942
[Epoch 17; Iter   136/  209] train: loss: 0.3232979
[Epoch 17; Iter   166/  209] train: loss: 0.1764563
[Epoch 17; Iter   196/  209] train: loss: 0.1698593
[Epoch 17] ogbg-moltox21: 0.788990 val loss: 0.247433
[Epoch 17] ogbg-moltox21: 0.766207 test loss: 0.258263
[Epoch 18; Iter    17/  209] train: loss: 0.1281067
[Epoch 18; Iter    47/  209] train: loss: 0.1403704
[Epoch 18; Iter    77/  209] train: loss: 0.2025942
[Epoch 18; Iter   107/  209] train: loss: 0.1622903
[Epoch 18; Iter   137/  209] train: loss: 0.1033838
[Epoch 18; Iter   167/  209] train: loss: 0.1330321
[Epoch 18; Iter   197/  209] train: loss: 0.1701036
[Epoch 18] ogbg-moltox21: 0.787512 val loss: 0.249328
[Epoch 18] ogbg-moltox21: 0.754633 test loss: 0.264006
[Epoch 19; Iter    18/  209] train: loss: 0.1405715
[Epoch 19; Iter    48/  209] train: loss: 0.1023673
[Epoch 19; Iter    78/  209] train: loss: 0.2740725
[Epoch 19; Iter   108/  209] train: loss: 0.1637860
[Epoch 19; Iter   138/  209] train: loss: 0.1777387
[Epoch 19; Iter   168/  209] train: loss: 0.1610694
[Epoch 19; Iter   198/  209] train: loss: 0.2366554
[Epoch 19] ogbg-moltox21: 0.779374 val loss: 0.254898
[Epoch 19] ogbg-moltox21: 0.754404 test loss: 0.267101
[Epoch 20; Iter    19/  209] train: loss: 0.1987384
[Epoch 20; Iter    49/  209] train: loss: 0.1245422
[Epoch 20; Iter    79/  209] train: loss: 0.1412989
[Epoch 20; Iter   109/  209] train: loss: 0.1712552
[Epoch 20; Iter   139/  209] train: loss: 0.1302655
[Epoch 20; Iter   169/  209] train: loss: 0.2041108
[Epoch 20; Iter   199/  209] train: loss: 0.2390357
[Epoch 20] ogbg-moltox21: 0.789246 val loss: 0.402799
[Epoch 20] ogbg-moltox21: 0.757593 test loss: 0.265431
[Epoch 21; Iter    20/  209] train: loss: 0.1550400
[Epoch 21; Iter    50/  209] train: loss: 0.2047142
[Epoch 21; Iter    80/  209] train: loss: 0.1390753
[Epoch 21; Iter   110/  209] train: loss: 0.1807554
[Epoch 21; Iter   140/  209] train: loss: 0.0986692
[Epoch 21; Iter   170/  209] train: loss: 0.1348207
[Epoch 21; Iter   200/  209] train: loss: 0.1253603
[Epoch 21] ogbg-moltox21: 0.777549 val loss: 0.263930
[Epoch 21] ogbg-moltox21: 0.754672 test loss: 0.267468
[Epoch 22; Iter    21/  209] train: loss: 0.1931304
[Epoch 22; Iter    51/  209] train: loss: 0.1734806
[Epoch 22; Iter    81/  209] train: loss: 0.1011434
[Epoch 22; Iter   111/  209] train: loss: 0.1563295
[Epoch 22; Iter   141/  209] train: loss: 0.1337877
[Epoch 22; Iter   171/  209] train: loss: 0.2187941
[Epoch 22; Iter   201/  209] train: loss: 0.1979954
[Epoch 22] ogbg-moltox21: 0.763584 val loss: 0.434316
[Epoch 22] ogbg-moltox21: 0.734743 test loss: 0.312526
[Epoch 23; Iter    22/  209] train: loss: 0.1208480
[Epoch 23; Iter    52/  209] train: loss: 0.1886700
[Epoch 23; Iter    82/  209] train: loss: 0.1552888
[Epoch 23; Iter   112/  209] train: loss: 0.1364015
[Epoch 23; Iter   142/  209] train: loss: 0.1524216
[Epoch 23; Iter   172/  209] train: loss: 0.1659966
[Epoch 23; Iter   202/  209] train: loss: 0.1868891
[Epoch 23] ogbg-moltox21: 0.774239 val loss: 0.332404
[Epoch 23] ogbg-moltox21: 0.755233 test loss: 0.273792
[Epoch 24; Iter    23/  209] train: loss: 0.1771682
[Epoch 24; Iter    53/  209] train: loss: 0.2015077
[Epoch 24; Iter    83/  209] train: loss: 0.2316206
[Epoch 24; Iter   113/  209] train: loss: 0.1269543
[Epoch 24; Iter   143/  209] train: loss: 0.1494063
[Epoch 24; Iter   173/  209] train: loss: 0.1187859
[Epoch 24; Iter   203/  209] train: loss: 0.1850448
[Epoch 24] ogbg-moltox21: 0.803563 val loss: 0.244876
[Epoch 24] ogbg-moltox21: 0.770381 test loss: 0.258107
[Epoch 25; Iter    24/  209] train: loss: 0.1724570
[Epoch 25; Iter    54/  209] train: loss: 0.2213420
[Epoch 25; Iter    84/  209] train: loss: 0.1092851
[Epoch 25; Iter   114/  209] train: loss: 0.2069641
[Epoch 25; Iter   144/  209] train: loss: 0.1040337
[Epoch 25; Iter   174/  209] train: loss: 0.1949662
[Epoch 25; Iter   204/  209] train: loss: 0.0932980
[Epoch 25] ogbg-moltox21: 0.790490 val loss: 0.253421
[Epoch 25] ogbg-moltox21: 0.749054 test loss: 0.280681
[Epoch 26; Iter    25/  209] train: loss: 0.1032288
[Epoch 26; Iter    55/  209] train: loss: 0.1403297
[Epoch 26; Iter    85/  209] train: loss: 0.1822429
[Epoch 26; Iter   115/  209] train: loss: 0.1246437
[Epoch 26; Iter   145/  209] train: loss: 0.1298117
[Epoch 26; Iter   175/  209] train: loss: 0.1363839
[Epoch 26; Iter   205/  209] train: loss: 0.2380681
[Epoch 26] ogbg-moltox21: 0.779037 val loss: 0.305175
[Epoch 26] ogbg-moltox21: 0.753169 test loss: 0.273052
[Epoch 27; Iter    26/  209] train: loss: 0.1254846
[Epoch 27; Iter    56/  209] train: loss: 0.0978472
[Epoch 27; Iter    86/  209] train: loss: 0.1425016
[Epoch 27; Iter   116/  209] train: loss: 0.1871232
[Epoch 27; Iter   146/  209] train: loss: 0.1199301
[Epoch 27; Iter   176/  209] train: loss: 0.2033842
[Epoch 27; Iter   206/  209] train: loss: 0.1901055
[Epoch 27] ogbg-moltox21: 0.782727 val loss: 0.258962
[Epoch 27] ogbg-moltox21: 0.755180 test loss: 0.267287
[Epoch 28; Iter    27/  209] train: loss: 0.2177520
[Epoch 28; Iter    57/  209] train: loss: 0.0708459
[Epoch 28; Iter    87/  209] train: loss: 0.1821787
[Epoch 28; Iter   117/  209] train: loss: 0.1764898
[Epoch 28; Iter   147/  209] train: loss: 0.2148360
[Epoch 28; Iter   177/  209] train: loss: 0.1874714
[Epoch 28; Iter   207/  209] train: loss: 0.1063147
[Epoch 28] ogbg-moltox21: 0.714835 val loss: 0.363215
[Epoch 28] ogbg-moltox21: 0.706466 test loss: 0.521546
[Epoch 29; Iter    28/  209] train: loss: 0.1732407
[Epoch 29; Iter    58/  209] train: loss: 0.1735139
[Epoch 29; Iter    88/  209] train: loss: 0.1981833
[Epoch 29; Iter   118/  209] train: loss: 0.1297255
[Epoch 29; Iter   148/  209] train: loss: 0.2318529
[Epoch 29; Iter   178/  209] train: loss: 0.1641372
[Epoch 29; Iter   208/  209] train: loss: 0.2237125
[Epoch 29] ogbg-moltox21: 0.786568 val loss: 0.254723
[Epoch 29] ogbg-moltox21: 0.763608 test loss: 0.331661
[Epoch 30; Iter    29/  209] train: loss: 0.1486101
[Epoch 30; Iter    59/  209] train: loss: 0.2059595
[Epoch 14; Iter    81/  183] train: loss: 0.1761212
[Epoch 14; Iter   111/  183] train: loss: 0.2103808
[Epoch 14; Iter   141/  183] train: loss: 0.1559134
[Epoch 14; Iter   171/  183] train: loss: 0.1740284
[Epoch 14] ogbg-moltox21: 0.754037 val loss: 0.277891
[Epoch 14] ogbg-moltox21: 0.753792 test loss: 0.280321
[Epoch 15; Iter    18/  183] train: loss: 0.1492177
[Epoch 15; Iter    48/  183] train: loss: 0.2159540
[Epoch 15; Iter    78/  183] train: loss: 0.1717541
[Epoch 15; Iter   108/  183] train: loss: 0.1058262
[Epoch 15; Iter   138/  183] train: loss: 0.1726915
[Epoch 15; Iter   168/  183] train: loss: 0.1986125
[Epoch 15] ogbg-moltox21: 0.758470 val loss: 0.289681
[Epoch 15] ogbg-moltox21: 0.736649 test loss: 0.311920
[Epoch 16; Iter    15/  183] train: loss: 0.1366670
[Epoch 16; Iter    45/  183] train: loss: 0.1710070
[Epoch 16; Iter    75/  183] train: loss: 0.1309317
[Epoch 16; Iter   105/  183] train: loss: 0.1237957
[Epoch 16; Iter   135/  183] train: loss: 0.1540821
[Epoch 16; Iter   165/  183] train: loss: 0.1585056
[Epoch 16] ogbg-moltox21: 0.760055 val loss: 0.297758
[Epoch 16] ogbg-moltox21: 0.742722 test loss: 0.313235
[Epoch 17; Iter    12/  183] train: loss: 0.2349956
[Epoch 17; Iter    42/  183] train: loss: 0.1254842
[Epoch 17; Iter    72/  183] train: loss: 0.1323304
[Epoch 17; Iter   102/  183] train: loss: 0.1702305
[Epoch 17; Iter   132/  183] train: loss: 0.1978334
[Epoch 17; Iter   162/  183] train: loss: 0.1341852
[Epoch 17] ogbg-moltox21: 0.759559 val loss: 0.286640
[Epoch 17] ogbg-moltox21: 0.749835 test loss: 0.292011
[Epoch 18; Iter     9/  183] train: loss: 0.1477230
[Epoch 18; Iter    39/  183] train: loss: 0.1140628
[Epoch 18; Iter    69/  183] train: loss: 0.1034260
[Epoch 18; Iter    99/  183] train: loss: 0.1703284
[Epoch 18; Iter   129/  183] train: loss: 0.1005740
[Epoch 18; Iter   159/  183] train: loss: 0.1264483
[Epoch 18] ogbg-moltox21: 0.750119 val loss: 0.279340
[Epoch 18] ogbg-moltox21: 0.754406 test loss: 0.272441
[Epoch 19; Iter     6/  183] train: loss: 0.1546485
[Epoch 19; Iter    36/  183] train: loss: 0.1431911
[Epoch 19; Iter    66/  183] train: loss: 0.2043657
[Epoch 19; Iter    96/  183] train: loss: 0.1373279
[Epoch 19; Iter   126/  183] train: loss: 0.2569207
[Epoch 19; Iter   156/  183] train: loss: 0.1337474
[Epoch 19] ogbg-moltox21: 0.762978 val loss: 0.278580
[Epoch 19] ogbg-moltox21: 0.741043 test loss: 0.293773
[Epoch 20; Iter     3/  183] train: loss: 0.1497749
[Epoch 20; Iter    33/  183] train: loss: 0.2928303
[Epoch 20; Iter    63/  183] train: loss: 0.2711470
[Epoch 20; Iter    93/  183] train: loss: 0.1606849
[Epoch 20; Iter   123/  183] train: loss: 0.1720944
[Epoch 20; Iter   153/  183] train: loss: 0.2599616
[Epoch 20; Iter   183/  183] train: loss: 0.1299327
[Epoch 20] ogbg-moltox21: 0.763332 val loss: 0.276338
[Epoch 20] ogbg-moltox21: 0.743026 test loss: 0.284056
[Epoch 21; Iter    30/  183] train: loss: 0.1557689
[Epoch 21; Iter    60/  183] train: loss: 0.2483104
[Epoch 21; Iter    90/  183] train: loss: 0.2253741
[Epoch 21; Iter   120/  183] train: loss: 0.1132232
[Epoch 21; Iter   150/  183] train: loss: 0.1332657
[Epoch 21; Iter   180/  183] train: loss: 0.0953105
[Epoch 21] ogbg-moltox21: 0.743230 val loss: 0.296498
[Epoch 21] ogbg-moltox21: 0.723998 test loss: 0.303975
[Epoch 22; Iter    27/  183] train: loss: 0.1720909
[Epoch 22; Iter    57/  183] train: loss: 0.2192026
[Epoch 22; Iter    87/  183] train: loss: 0.1399537
[Epoch 22; Iter   117/  183] train: loss: 0.1573697
[Epoch 22; Iter   147/  183] train: loss: 0.1406464
[Epoch 22; Iter   177/  183] train: loss: 0.1434456
[Epoch 22] ogbg-moltox21: 0.763699 val loss: 0.266248
[Epoch 22] ogbg-moltox21: 0.743418 test loss: 0.278814
[Epoch 23; Iter    24/  183] train: loss: 0.1367818
[Epoch 23; Iter    54/  183] train: loss: 0.1665035
[Epoch 23; Iter    84/  183] train: loss: 0.1607102
[Epoch 23; Iter   114/  183] train: loss: 0.1590827
[Epoch 23; Iter   144/  183] train: loss: 0.1986919
[Epoch 23; Iter   174/  183] train: loss: 0.1852582
[Epoch 23] ogbg-moltox21: 0.755503 val loss: 0.281424
[Epoch 23] ogbg-moltox21: 0.744337 test loss: 0.288055
[Epoch 24; Iter    21/  183] train: loss: 0.1063929
[Epoch 24; Iter    51/  183] train: loss: 0.1796819
[Epoch 24; Iter    81/  183] train: loss: 0.1230510
[Epoch 24; Iter   111/  183] train: loss: 0.1320957
[Epoch 24; Iter   141/  183] train: loss: 0.1503853
[Epoch 24; Iter   171/  183] train: loss: 0.1351711
[Epoch 24] ogbg-moltox21: 0.770269 val loss: 0.275010
[Epoch 24] ogbg-moltox21: 0.757308 test loss: 0.288035
[Epoch 25; Iter    18/  183] train: loss: 0.0779220
[Epoch 25; Iter    48/  183] train: loss: 0.0987303
[Epoch 25; Iter    78/  183] train: loss: 0.1897144
[Epoch 25; Iter   108/  183] train: loss: 0.1007683
[Epoch 25; Iter   138/  183] train: loss: 0.1456879
[Epoch 25; Iter   168/  183] train: loss: 0.1404225
[Epoch 25] ogbg-moltox21: 0.772097 val loss: 0.267014
[Epoch 25] ogbg-moltox21: 0.749006 test loss: 0.277386
[Epoch 26; Iter    15/  183] train: loss: 0.1147058
[Epoch 26; Iter    45/  183] train: loss: 0.1652081
[Epoch 26; Iter    75/  183] train: loss: 0.1381916
[Epoch 26; Iter   105/  183] train: loss: 0.1507353
[Epoch 26; Iter   135/  183] train: loss: 0.2380551
[Epoch 26; Iter   165/  183] train: loss: 0.2439570
[Epoch 26] ogbg-moltox21: 0.750176 val loss: 0.285523
[Epoch 26] ogbg-moltox21: 0.740479 test loss: 0.284633
[Epoch 27; Iter    12/  183] train: loss: 0.1618797
[Epoch 27; Iter    42/  183] train: loss: 0.2369832
[Epoch 27; Iter    72/  183] train: loss: 0.0905321
[Epoch 27; Iter   102/  183] train: loss: 0.1254954
[Epoch 27; Iter   132/  183] train: loss: 0.1713012
[Epoch 27; Iter   162/  183] train: loss: 0.1780097
[Epoch 27] ogbg-moltox21: 0.728079 val loss: 0.285766
[Epoch 27] ogbg-moltox21: 0.714681 test loss: 0.294965
[Epoch 28; Iter     9/  183] train: loss: 0.1328595
[Epoch 28; Iter    39/  183] train: loss: 0.1606728
[Epoch 28; Iter    69/  183] train: loss: 0.1802659
[Epoch 28; Iter    99/  183] train: loss: 0.2490344
[Epoch 28; Iter   129/  183] train: loss: 0.1188178
[Epoch 28; Iter   159/  183] train: loss: 0.1606058
[Epoch 28] ogbg-moltox21: 0.749957 val loss: 0.277525
[Epoch 28] ogbg-moltox21: 0.733640 test loss: 0.290465
[Epoch 29; Iter     6/  183] train: loss: 0.1701297
[Epoch 29; Iter    36/  183] train: loss: 0.1783225
[Epoch 29; Iter    66/  183] train: loss: 0.1332653
[Epoch 29; Iter    96/  183] train: loss: 0.1219524
[Epoch 29; Iter   126/  183] train: loss: 0.0973461
[Epoch 29; Iter   156/  183] train: loss: 0.1242871
[Epoch 29] ogbg-moltox21: 0.768023 val loss: 0.262222
[Epoch 29] ogbg-moltox21: 0.730739 test loss: 0.278631
[Epoch 30; Iter     3/  183] train: loss: 0.2217699
[Epoch 30; Iter    33/  183] train: loss: 0.1136155
[Epoch 30; Iter    63/  183] train: loss: 0.1077452
[Epoch 30; Iter    93/  183] train: loss: 0.1111421
[Epoch 30; Iter   123/  183] train: loss: 0.1224233
[Epoch 30; Iter   153/  183] train: loss: 0.1517186
[Epoch 30; Iter   183/  183] train: loss: 0.1778850
[Epoch 30] ogbg-moltox21: 0.778225 val loss: 0.260596
[Epoch 30] ogbg-moltox21: 0.738250 test loss: 0.275216
[Epoch 31; Iter    30/  183] train: loss: 0.1599043
[Epoch 31; Iter    60/  183] train: loss: 0.1089803
[Epoch 31; Iter    90/  183] train: loss: 0.1136520
[Epoch 31; Iter   120/  183] train: loss: 0.1402973
[Epoch 31; Iter   150/  183] train: loss: 0.2212794
[Epoch 31; Iter   180/  183] train: loss: 0.1719120
[Epoch 31] ogbg-moltox21: 0.784974 val loss: 0.258887
[Epoch 31] ogbg-moltox21: 0.759240 test loss: 0.272545
[Epoch 32; Iter    27/  183] train: loss: 0.1471477
[Epoch 32; Iter    57/  183] train: loss: 0.1146356
[Epoch 32; Iter    87/  183] train: loss: 0.1243290
[Epoch 32; Iter   117/  183] train: loss: 0.1470477
[Epoch 32; Iter   147/  183] train: loss: 0.0967832
[Epoch 32; Iter   177/  183] train: loss: 0.1622027
[Epoch 32] ogbg-moltox21: 0.776661 val loss: 0.260266
[Epoch 32] ogbg-moltox21: 0.759203 test loss: 0.273908
[Epoch 33; Iter    24/  183] train: loss: 0.1830631
[Epoch 33; Iter    54/  183] train: loss: 0.1284872
[Epoch 33; Iter    84/  183] train: loss: 0.1227449
[Epoch 14; Iter    81/  183] train: loss: 0.1815647
[Epoch 14; Iter   111/  183] train: loss: 0.2071105
[Epoch 14; Iter   141/  183] train: loss: 0.1780249
[Epoch 14; Iter   171/  183] train: loss: 0.2354972
[Epoch 14] ogbg-moltox21: 0.711487 val loss: 0.286031
[Epoch 14] ogbg-moltox21: 0.711389 test loss: 0.289802
[Epoch 15; Iter    18/  183] train: loss: 0.1409667
[Epoch 15; Iter    48/  183] train: loss: 0.2130291
[Epoch 15; Iter    78/  183] train: loss: 0.1233539
[Epoch 15; Iter   108/  183] train: loss: 0.1373785
[Epoch 15; Iter   138/  183] train: loss: 0.0982995
[Epoch 15; Iter   168/  183] train: loss: 0.1403793
[Epoch 15] ogbg-moltox21: 0.738511 val loss: 0.276369
[Epoch 15] ogbg-moltox21: 0.734752 test loss: 0.278344
[Epoch 16; Iter    15/  183] train: loss: 0.1533883
[Epoch 16; Iter    45/  183] train: loss: 0.1658524
[Epoch 16; Iter    75/  183] train: loss: 0.1416620
[Epoch 16; Iter   105/  183] train: loss: 0.1743645
[Epoch 16; Iter   135/  183] train: loss: 0.1263720
[Epoch 16; Iter   165/  183] train: loss: 0.1855377
[Epoch 16] ogbg-moltox21: 0.758298 val loss: 0.274880
[Epoch 16] ogbg-moltox21: 0.745336 test loss: 0.283880
[Epoch 17; Iter    12/  183] train: loss: 0.2523952
[Epoch 17; Iter    42/  183] train: loss: 0.2015780
[Epoch 17; Iter    72/  183] train: loss: 0.1689227
[Epoch 17; Iter   102/  183] train: loss: 0.1379238
[Epoch 17; Iter   132/  183] train: loss: 0.1273094
[Epoch 17; Iter   162/  183] train: loss: 0.0987870
[Epoch 17] ogbg-moltox21: 0.745059 val loss: 0.286065
[Epoch 17] ogbg-moltox21: 0.739920 test loss: 0.288921
[Epoch 18; Iter     9/  183] train: loss: 0.1528356
[Epoch 18; Iter    39/  183] train: loss: 0.1991728
[Epoch 18; Iter    69/  183] train: loss: 0.1461639
[Epoch 18; Iter    99/  183] train: loss: 0.1772538
[Epoch 18; Iter   129/  183] train: loss: 0.1014863
[Epoch 18; Iter   159/  183] train: loss: 0.1746608
[Epoch 18] ogbg-moltox21: 0.755339 val loss: 0.287882
[Epoch 18] ogbg-moltox21: 0.745001 test loss: 0.296682
[Epoch 19; Iter     6/  183] train: loss: 0.1033356
[Epoch 19; Iter    36/  183] train: loss: 0.1606048
[Epoch 19; Iter    66/  183] train: loss: 0.1119411
[Epoch 19; Iter    96/  183] train: loss: 0.1856270
[Epoch 19; Iter   126/  183] train: loss: 0.1049067
[Epoch 19; Iter   156/  183] train: loss: 0.1368247
[Epoch 19] ogbg-moltox21: 0.715388 val loss: 0.336734
[Epoch 19] ogbg-moltox21: 0.717232 test loss: 0.335918
[Epoch 20; Iter     3/  183] train: loss: 0.1218809
[Epoch 20; Iter    33/  183] train: loss: 0.1987599
[Epoch 20; Iter    63/  183] train: loss: 0.1189108
[Epoch 20; Iter    93/  183] train: loss: 0.2741475
[Epoch 20; Iter   123/  183] train: loss: 0.1916619
[Epoch 20; Iter   153/  183] train: loss: 0.1579190
[Epoch 20; Iter   183/  183] train: loss: 0.1304352
[Epoch 20] ogbg-moltox21: 0.760579 val loss: 0.296133
[Epoch 20] ogbg-moltox21: 0.744184 test loss: 0.305719
[Epoch 21; Iter    30/  183] train: loss: 0.0889326
[Epoch 21; Iter    60/  183] train: loss: 0.1748498
[Epoch 21; Iter    90/  183] train: loss: 0.1665819
[Epoch 21; Iter   120/  183] train: loss: 0.1354279
[Epoch 21; Iter   150/  183] train: loss: 0.1507913
[Epoch 21; Iter   180/  183] train: loss: 0.0954433
[Epoch 21] ogbg-moltox21: 0.762032 val loss: 0.296955
[Epoch 21] ogbg-moltox21: 0.741992 test loss: 0.312282
[Epoch 22; Iter    27/  183] train: loss: 0.1439623
[Epoch 22; Iter    57/  183] train: loss: 0.1375859
[Epoch 22; Iter    87/  183] train: loss: 0.1335569
[Epoch 22; Iter   117/  183] train: loss: 0.1222598
[Epoch 22; Iter   147/  183] train: loss: 0.1668563
[Epoch 22; Iter   177/  183] train: loss: 0.1153065
[Epoch 22] ogbg-moltox21: 0.759935 val loss: 0.281896
[Epoch 22] ogbg-moltox21: 0.736211 test loss: 0.294243
[Epoch 23; Iter    24/  183] train: loss: 0.1989443
[Epoch 23; Iter    54/  183] train: loss: 0.1899813
[Epoch 23; Iter    84/  183] train: loss: 0.1813130
[Epoch 23; Iter   114/  183] train: loss: 0.2228198
[Epoch 23; Iter   144/  183] train: loss: 0.1314849
[Epoch 23; Iter   174/  183] train: loss: 0.0836365
[Epoch 23] ogbg-moltox21: 0.748477 val loss: 0.284948
[Epoch 23] ogbg-moltox21: 0.728375 test loss: 0.291352
[Epoch 24; Iter    21/  183] train: loss: 0.1356652
[Epoch 24; Iter    51/  183] train: loss: 0.1499136
[Epoch 24; Iter    81/  183] train: loss: 0.0758703
[Epoch 24; Iter   111/  183] train: loss: 0.1866680
[Epoch 24; Iter   141/  183] train: loss: 0.2005247
[Epoch 24; Iter   171/  183] train: loss: 0.1002713
[Epoch 24] ogbg-moltox21: 0.765568 val loss: 0.286649
[Epoch 24] ogbg-moltox21: 0.736391 test loss: 0.302259
[Epoch 25; Iter    18/  183] train: loss: 0.2028231
[Epoch 25; Iter    48/  183] train: loss: 0.1733811
[Epoch 25; Iter    78/  183] train: loss: 0.1170331
[Epoch 25; Iter   108/  183] train: loss: 0.1124663
[Epoch 25; Iter   138/  183] train: loss: 0.0950355
[Epoch 25; Iter   168/  183] train: loss: 0.1210718
[Epoch 25] ogbg-moltox21: 0.754059 val loss: 0.301119
[Epoch 25] ogbg-moltox21: 0.737067 test loss: 0.301172
[Epoch 26; Iter    15/  183] train: loss: 0.1172601
[Epoch 26; Iter    45/  183] train: loss: 0.0802335
[Epoch 26; Iter    75/  183] train: loss: 0.1047512
[Epoch 26; Iter   105/  183] train: loss: 0.1514592
[Epoch 26; Iter   135/  183] train: loss: 0.1733066
[Epoch 26; Iter   165/  183] train: loss: 0.1358144
[Epoch 26] ogbg-moltox21: 0.761402 val loss: 0.456348
[Epoch 26] ogbg-moltox21: 0.727948 test loss: 0.399420
[Epoch 27; Iter    12/  183] train: loss: 0.1358251
[Epoch 27; Iter    42/  183] train: loss: 0.1322456
[Epoch 27; Iter    72/  183] train: loss: 0.1618416
[Epoch 27; Iter   102/  183] train: loss: 0.1398567
[Epoch 27; Iter   132/  183] train: loss: 0.0960656
[Epoch 27; Iter   162/  183] train: loss: 0.0861525
[Epoch 27] ogbg-moltox21: 0.771919 val loss: 0.409699
[Epoch 27] ogbg-moltox21: 0.739937 test loss: 0.365048
[Epoch 28; Iter     9/  183] train: loss: 0.1394140
[Epoch 28; Iter    39/  183] train: loss: 0.1346686
[Epoch 28; Iter    69/  183] train: loss: 0.1248931
[Epoch 28; Iter    99/  183] train: loss: 0.2246362
[Epoch 28; Iter   129/  183] train: loss: 0.1462175
[Epoch 28; Iter   159/  183] train: loss: 0.1567948
[Epoch 28] ogbg-moltox21: 0.754070 val loss: 0.339099
[Epoch 28] ogbg-moltox21: 0.740784 test loss: 0.296301
[Epoch 29; Iter     6/  183] train: loss: 0.1214757
[Epoch 29; Iter    36/  183] train: loss: 0.1589839
[Epoch 29; Iter    66/  183] train: loss: 0.1290080
[Epoch 29; Iter    96/  183] train: loss: 0.3008813
[Epoch 29; Iter   126/  183] train: loss: 0.1623243
[Epoch 29; Iter   156/  183] train: loss: 0.1755727
[Epoch 29] ogbg-moltox21: 0.765287 val loss: 0.323661
[Epoch 29] ogbg-moltox21: 0.744735 test loss: 0.287821
[Epoch 30; Iter     3/  183] train: loss: 0.1226944
[Epoch 30; Iter    33/  183] train: loss: 0.1197914
[Epoch 30; Iter    63/  183] train: loss: 0.0961208
[Epoch 30; Iter    93/  183] train: loss: 0.1269654
[Epoch 30; Iter   123/  183] train: loss: 0.1228693
[Epoch 30; Iter   153/  183] train: loss: 0.1790483
[Epoch 30; Iter   183/  183] train: loss: 0.0964589
[Epoch 30] ogbg-moltox21: 0.756932 val loss: 0.330515
[Epoch 30] ogbg-moltox21: 0.731912 test loss: 0.294816
[Epoch 31; Iter    30/  183] train: loss: 0.1366817
[Epoch 31; Iter    60/  183] train: loss: 0.2038114
[Epoch 31; Iter    90/  183] train: loss: 0.1116191
[Epoch 31; Iter   120/  183] train: loss: 0.2525662
[Epoch 31; Iter   150/  183] train: loss: 0.2478124
[Epoch 31; Iter   180/  183] train: loss: 0.1665529
[Epoch 31] ogbg-moltox21: 0.759711 val loss: 0.285517
[Epoch 31] ogbg-moltox21: 0.735200 test loss: 0.298912
[Epoch 32; Iter    27/  183] train: loss: 0.1117972
[Epoch 32; Iter    57/  183] train: loss: 0.0815591
[Epoch 32; Iter    87/  183] train: loss: 0.1930289
[Epoch 32; Iter   117/  183] train: loss: 0.2416733
[Epoch 32; Iter   147/  183] train: loss: 0.1808175
[Epoch 32; Iter   177/  183] train: loss: 0.1552141
[Epoch 32] ogbg-moltox21: 0.769899 val loss: 0.286178
[Epoch 32] ogbg-moltox21: 0.736100 test loss: 0.289138
[Epoch 33; Iter    24/  183] train: loss: 0.1637424
[Epoch 33; Iter    54/  183] train: loss: 0.0770811
[Epoch 33; Iter    84/  183] train: loss: 0.1035381
[Epoch 14; Iter    81/  183] train: loss: 0.1799000
[Epoch 14; Iter   111/  183] train: loss: 0.2663793
[Epoch 14; Iter   141/  183] train: loss: 0.2595178
[Epoch 14; Iter   171/  183] train: loss: 0.1335924
[Epoch 14] ogbg-moltox21: 0.759286 val loss: 0.300283
[Epoch 14] ogbg-moltox21: 0.737904 test loss: 0.440605
[Epoch 15; Iter    18/  183] train: loss: 0.1806597
[Epoch 15; Iter    48/  183] train: loss: 0.1768771
[Epoch 15; Iter    78/  183] train: loss: 0.1664846
[Epoch 15; Iter   108/  183] train: loss: 0.1423898
[Epoch 15; Iter   138/  183] train: loss: 0.1357173
[Epoch 15; Iter   168/  183] train: loss: 0.2361901
[Epoch 15] ogbg-moltox21: 0.739565 val loss: 0.311027
[Epoch 15] ogbg-moltox21: 0.730381 test loss: 0.382791
[Epoch 16; Iter    15/  183] train: loss: 0.2481087
[Epoch 16; Iter    45/  183] train: loss: 0.2055851
[Epoch 16; Iter    75/  183] train: loss: 0.1598182
[Epoch 16; Iter   105/  183] train: loss: 0.2481390
[Epoch 16; Iter   135/  183] train: loss: 0.2556618
[Epoch 16; Iter   165/  183] train: loss: 0.1689945
[Epoch 16] ogbg-moltox21: 0.751123 val loss: 0.320232
[Epoch 16] ogbg-moltox21: 0.735349 test loss: 0.444148
[Epoch 17; Iter    12/  183] train: loss: 0.1102483
[Epoch 17; Iter    42/  183] train: loss: 0.0967175
[Epoch 17; Iter    72/  183] train: loss: 0.1309845
[Epoch 17; Iter   102/  183] train: loss: 0.2074731
[Epoch 17; Iter   132/  183] train: loss: 0.2030242
[Epoch 17; Iter   162/  183] train: loss: 0.1139662
[Epoch 17] ogbg-moltox21: 0.740846 val loss: 0.540491
[Epoch 17] ogbg-moltox21: 0.731776 test loss: 0.757691
[Epoch 18; Iter     9/  183] train: loss: 0.2369962
[Epoch 18; Iter    39/  183] train: loss: 0.2429406
[Epoch 18; Iter    69/  183] train: loss: 0.1576999
[Epoch 18; Iter    99/  183] train: loss: 0.1387770
[Epoch 18; Iter   129/  183] train: loss: 0.1185193
[Epoch 18; Iter   159/  183] train: loss: 0.1264932
[Epoch 18] ogbg-moltox21: 0.750946 val loss: 0.294045
[Epoch 18] ogbg-moltox21: 0.743725 test loss: 0.300174
[Epoch 19; Iter     6/  183] train: loss: 0.1697536
[Epoch 19; Iter    36/  183] train: loss: 0.1492934
[Epoch 19; Iter    66/  183] train: loss: 0.1654793
[Epoch 19; Iter    96/  183] train: loss: 0.1541228
[Epoch 19; Iter   126/  183] train: loss: 0.1602673
[Epoch 19; Iter   156/  183] train: loss: 0.1926723
[Epoch 19] ogbg-moltox21: 0.752594 val loss: 0.303622
[Epoch 19] ogbg-moltox21: 0.725238 test loss: 0.308885
[Epoch 20; Iter     3/  183] train: loss: 0.1528415
[Epoch 20; Iter    33/  183] train: loss: 0.1337604
[Epoch 20; Iter    63/  183] train: loss: 0.1181930
[Epoch 20; Iter    93/  183] train: loss: 0.1145219
[Epoch 20; Iter   123/  183] train: loss: 0.2720848
[Epoch 20; Iter   153/  183] train: loss: 0.1101849
[Epoch 20; Iter   183/  183] train: loss: 0.1823677
[Epoch 20] ogbg-moltox21: 0.763369 val loss: 0.294226
[Epoch 20] ogbg-moltox21: 0.748124 test loss: 0.306189
[Epoch 21; Iter    30/  183] train: loss: 0.1618293
[Epoch 21; Iter    60/  183] train: loss: 0.0987907
[Epoch 21; Iter    90/  183] train: loss: 0.1452726
[Epoch 21; Iter   120/  183] train: loss: 0.1059212
[Epoch 21; Iter   150/  183] train: loss: 0.2303070
[Epoch 21; Iter   180/  183] train: loss: 0.1551342
[Epoch 21] ogbg-moltox21: 0.762923 val loss: 0.303582
[Epoch 21] ogbg-moltox21: 0.747959 test loss: 0.311444
[Epoch 22; Iter    27/  183] train: loss: 0.2493750
[Epoch 22; Iter    57/  183] train: loss: 0.0901887
[Epoch 22; Iter    87/  183] train: loss: 0.1171160
[Epoch 22; Iter   117/  183] train: loss: 0.1495977
[Epoch 22; Iter   147/  183] train: loss: 0.1459921
[Epoch 22; Iter   177/  183] train: loss: 0.2444657
[Epoch 22] ogbg-moltox21: 0.727095 val loss: 0.298016
[Epoch 22] ogbg-moltox21: 0.726078 test loss: 0.302351
[Epoch 23; Iter    24/  183] train: loss: 0.1296615
[Epoch 23; Iter    54/  183] train: loss: 0.1246817
[Epoch 23; Iter    84/  183] train: loss: 0.1283890
[Epoch 23; Iter   114/  183] train: loss: 0.1439138
[Epoch 23; Iter   144/  183] train: loss: 0.2122649
[Epoch 23; Iter   174/  183] train: loss: 0.0890773
[Epoch 23] ogbg-moltox21: 0.750414 val loss: 0.307413
[Epoch 23] ogbg-moltox21: 0.743919 test loss: 0.285043
[Epoch 24; Iter    21/  183] train: loss: 0.1687479
[Epoch 24; Iter    51/  183] train: loss: 0.0709693
[Epoch 24; Iter    81/  183] train: loss: 0.1176040
[Epoch 24; Iter   111/  183] train: loss: 0.1226138
[Epoch 24; Iter   141/  183] train: loss: 0.1301643
[Epoch 24; Iter   171/  183] train: loss: 0.1319063
[Epoch 24] ogbg-moltox21: 0.759732 val loss: 0.273878
[Epoch 24] ogbg-moltox21: 0.738564 test loss: 0.285994
[Epoch 25; Iter    18/  183] train: loss: 0.2662964
[Epoch 25; Iter    48/  183] train: loss: 0.1084447
[Epoch 25; Iter    78/  183] train: loss: 0.0980151
[Epoch 25; Iter   108/  183] train: loss: 0.1532606
[Epoch 25; Iter   138/  183] train: loss: 0.1747006
[Epoch 25; Iter   168/  183] train: loss: 0.1872105
[Epoch 25] ogbg-moltox21: 0.760280 val loss: 0.289191
[Epoch 25] ogbg-moltox21: 0.744943 test loss: 0.305040
[Epoch 26; Iter    15/  183] train: loss: 0.2786850
[Epoch 26; Iter    45/  183] train: loss: 0.1569284
[Epoch 26; Iter    75/  183] train: loss: 0.1428006
[Epoch 26; Iter   105/  183] train: loss: 0.1506812
[Epoch 26; Iter   135/  183] train: loss: 0.1173324
[Epoch 26; Iter   165/  183] train: loss: 0.1514605
[Epoch 26] ogbg-moltox21: 0.768187 val loss: 0.282641
[Epoch 26] ogbg-moltox21: 0.739535 test loss: 0.302815
[Epoch 27; Iter    12/  183] train: loss: 0.1688030
[Epoch 27; Iter    42/  183] train: loss: 0.1184267
[Epoch 27; Iter    72/  183] train: loss: 0.1304362
[Epoch 27; Iter   102/  183] train: loss: 0.1568983
[Epoch 27; Iter   132/  183] train: loss: 0.1348855
[Epoch 27; Iter   162/  183] train: loss: 0.1811814
[Epoch 27] ogbg-moltox21: 0.750232 val loss: 0.293812
[Epoch 27] ogbg-moltox21: 0.735131 test loss: 0.308538
[Epoch 28; Iter     9/  183] train: loss: 0.0768776
[Epoch 28; Iter    39/  183] train: loss: 0.1634179
[Epoch 28; Iter    69/  183] train: loss: 0.0903079
[Epoch 28; Iter    99/  183] train: loss: 0.1192422
[Epoch 28; Iter   129/  183] train: loss: 0.2967821
[Epoch 28; Iter   159/  183] train: loss: 0.1639901
[Epoch 28] ogbg-moltox21: 0.760263 val loss: 0.284256
[Epoch 28] ogbg-moltox21: 0.737771 test loss: 0.337200
[Epoch 29; Iter     6/  183] train: loss: 0.1037100
[Epoch 29; Iter    36/  183] train: loss: 0.1365969
[Epoch 29; Iter    66/  183] train: loss: 0.1815379
[Epoch 29; Iter    96/  183] train: loss: 0.1330121
[Epoch 29; Iter   126/  183] train: loss: 0.1341390
[Epoch 29; Iter   156/  183] train: loss: 0.2986561
[Epoch 29] ogbg-moltox21: 0.735255 val loss: 0.348499
[Epoch 29] ogbg-moltox21: 0.717519 test loss: 0.413207
[Epoch 30; Iter     3/  183] train: loss: 0.2474769
[Epoch 30; Iter    33/  183] train: loss: 0.1539281
[Epoch 30; Iter    63/  183] train: loss: 0.2440356
[Epoch 30; Iter    93/  183] train: loss: 0.2099644
[Epoch 30; Iter   123/  183] train: loss: 0.1438828
[Epoch 30; Iter   153/  183] train: loss: 0.2458074
[Epoch 30; Iter   183/  183] train: loss: 0.1613199
[Epoch 30] ogbg-moltox21: 0.766083 val loss: 0.278624
[Epoch 30] ogbg-moltox21: 0.742142 test loss: 0.288135
[Epoch 31; Iter    30/  183] train: loss: 0.2037619
[Epoch 31; Iter    60/  183] train: loss: 0.2069250
[Epoch 31; Iter    90/  183] train: loss: 0.1119205
[Epoch 31; Iter   120/  183] train: loss: 0.1894336
[Epoch 31; Iter   150/  183] train: loss: 0.1394394
[Epoch 31; Iter   180/  183] train: loss: 0.1753392
[Epoch 31] ogbg-moltox21: 0.756171 val loss: 0.274375
[Epoch 31] ogbg-moltox21: 0.749676 test loss: 0.282529
[Epoch 32; Iter    27/  183] train: loss: 0.1100539
[Epoch 32; Iter    57/  183] train: loss: 0.1218072
[Epoch 32; Iter    87/  183] train: loss: 0.1719344
[Epoch 32; Iter   117/  183] train: loss: 0.1215307
[Epoch 32; Iter   147/  183] train: loss: 0.1270043
[Epoch 32; Iter   177/  183] train: loss: 0.1960515
[Epoch 32] ogbg-moltox21: 0.771918 val loss: 0.289055
[Epoch 32] ogbg-moltox21: 0.752456 test loss: 0.299264
[Epoch 33; Iter    24/  183] train: loss: 0.1651496
[Epoch 33; Iter    54/  183] train: loss: 0.1376584
[Epoch 33; Iter    84/  183] train: loss: 0.1990083
[Epoch 15] ogbg-moltox21: 0.711471 test loss: 0.469829
[Epoch 16; Iter    15/  157] train: loss: 0.1607845
[Epoch 16; Iter    45/  157] train: loss: 0.1681446
[Epoch 16; Iter    75/  157] train: loss: 0.1776249
[Epoch 16; Iter   105/  157] train: loss: 0.0850306
[Epoch 16; Iter   135/  157] train: loss: 0.1160523
[Epoch 16] ogbg-moltox21: 0.774911 val loss: 0.322697
[Epoch 16] ogbg-moltox21: 0.744827 test loss: 0.348225
[Epoch 17; Iter     8/  157] train: loss: 0.1633411
[Epoch 17; Iter    38/  157] train: loss: 0.1517964
[Epoch 17; Iter    68/  157] train: loss: 0.1207769
[Epoch 17; Iter    98/  157] train: loss: 0.1692839
[Epoch 17; Iter   128/  157] train: loss: 0.1822010
[Epoch 17] ogbg-moltox21: 0.765018 val loss: 0.416029
[Epoch 17] ogbg-moltox21: 0.727306 test loss: 0.498305
[Epoch 18; Iter     1/  157] train: loss: 0.1647294
[Epoch 18; Iter    31/  157] train: loss: 0.1182683
[Epoch 18; Iter    61/  157] train: loss: 0.1018341
[Epoch 18; Iter    91/  157] train: loss: 0.1132809
[Epoch 18; Iter   121/  157] train: loss: 0.0993105
[Epoch 18; Iter   151/  157] train: loss: 0.1097765
[Epoch 18] ogbg-moltox21: 0.747583 val loss: 0.355904
[Epoch 18] ogbg-moltox21: 0.713493 test loss: 0.407791
[Epoch 19; Iter    24/  157] train: loss: 0.1640721
[Epoch 19; Iter    54/  157] train: loss: 0.1215378
[Epoch 19; Iter    84/  157] train: loss: 0.2714081
[Epoch 19; Iter   114/  157] train: loss: 0.1851299
[Epoch 19; Iter   144/  157] train: loss: 0.1190411
[Epoch 19] ogbg-moltox21: 0.760470 val loss: 0.404723
[Epoch 19] ogbg-moltox21: 0.726290 test loss: 0.446550
[Epoch 20; Iter    17/  157] train: loss: 0.1256841
[Epoch 20; Iter    47/  157] train: loss: 0.2004835
[Epoch 20; Iter    77/  157] train: loss: 0.1366755
[Epoch 20; Iter   107/  157] train: loss: 0.1495527
[Epoch 20; Iter   137/  157] train: loss: 0.1405715
[Epoch 20] ogbg-moltox21: 0.742099 val loss: 0.383285
[Epoch 20] ogbg-moltox21: 0.718923 test loss: 0.441136
[Epoch 21; Iter    10/  157] train: loss: 0.1516683
[Epoch 21; Iter    40/  157] train: loss: 0.1499127
[Epoch 21; Iter    70/  157] train: loss: 0.1780723
[Epoch 21; Iter   100/  157] train: loss: 0.1807879
[Epoch 21; Iter   130/  157] train: loss: 0.1455605
[Epoch 21] ogbg-moltox21: 0.755620 val loss: 0.329549
[Epoch 21] ogbg-moltox21: 0.736989 test loss: 0.360958
[Epoch 22; Iter     3/  157] train: loss: 0.2523194
[Epoch 22; Iter    33/  157] train: loss: 0.1046466
[Epoch 22; Iter    63/  157] train: loss: 0.2251324
[Epoch 22; Iter    93/  157] train: loss: 0.1257183
[Epoch 22; Iter   123/  157] train: loss: 0.1022625
[Epoch 22; Iter   153/  157] train: loss: 0.0933399
[Epoch 22] ogbg-moltox21: 0.744959 val loss: 0.360439
[Epoch 22] ogbg-moltox21: 0.716177 test loss: 0.390775
[Epoch 23; Iter    26/  157] train: loss: 0.1506618
[Epoch 23; Iter    56/  157] train: loss: 0.1204233
[Epoch 23; Iter    86/  157] train: loss: 0.1224746
[Epoch 23; Iter   116/  157] train: loss: 0.1695794
[Epoch 23; Iter   146/  157] train: loss: 0.2197486
[Epoch 23] ogbg-moltox21: 0.765623 val loss: 0.363229
[Epoch 23] ogbg-moltox21: 0.743447 test loss: 0.392053
[Epoch 24; Iter    19/  157] train: loss: 0.1456586
[Epoch 24; Iter    49/  157] train: loss: 0.1811563
[Epoch 24; Iter    79/  157] train: loss: 0.1327735
[Epoch 24; Iter   109/  157] train: loss: 0.1523106
[Epoch 24; Iter   139/  157] train: loss: 0.1749897
[Epoch 24] ogbg-moltox21: 0.709210 val loss: 0.419308
[Epoch 24] ogbg-moltox21: 0.675598 test loss: 0.481536
[Epoch 25; Iter    12/  157] train: loss: 0.1188995
[Epoch 25; Iter    42/  157] train: loss: 0.1162869
[Epoch 25; Iter    72/  157] train: loss: 0.1343331
[Epoch 25; Iter   102/  157] train: loss: 0.0633987
[Epoch 25; Iter   132/  157] train: loss: 0.1584971
[Epoch 25] ogbg-moltox21: 0.757358 val loss: 0.407764
[Epoch 25] ogbg-moltox21: 0.734856 test loss: 0.492727
[Epoch 26; Iter     5/  157] train: loss: 0.0935154
[Epoch 26; Iter    35/  157] train: loss: 0.1682627
[Epoch 26; Iter    65/  157] train: loss: 0.2038507
[Epoch 26; Iter    95/  157] train: loss: 0.1571422
[Epoch 26; Iter   125/  157] train: loss: 0.1094413
[Epoch 26; Iter   155/  157] train: loss: 0.1082400
[Epoch 26] ogbg-moltox21: 0.766713 val loss: 0.451775
[Epoch 26] ogbg-moltox21: 0.744384 test loss: 0.776176
[Epoch 27; Iter    28/  157] train: loss: 0.1444369
[Epoch 27; Iter    58/  157] train: loss: 0.2044935
[Epoch 27; Iter    88/  157] train: loss: 0.2304691
[Epoch 27; Iter   118/  157] train: loss: 0.1224254
[Epoch 27; Iter   148/  157] train: loss: 0.1247497
[Epoch 27] ogbg-moltox21: 0.751579 val loss: 0.382351
[Epoch 27] ogbg-moltox21: 0.723960 test loss: 0.419076
[Epoch 28; Iter    21/  157] train: loss: 0.0995882
[Epoch 28; Iter    51/  157] train: loss: 0.2087537
[Epoch 28; Iter    81/  157] train: loss: 0.1601607
[Epoch 28; Iter   111/  157] train: loss: 0.1911827
[Epoch 28; Iter   141/  157] train: loss: 0.1035165
[Epoch 28] ogbg-moltox21: 0.753392 val loss: 0.430028
[Epoch 28] ogbg-moltox21: 0.729406 test loss: 0.366520
[Epoch 29; Iter    14/  157] train: loss: 0.1210802
[Epoch 29; Iter    44/  157] train: loss: 0.1326212
[Epoch 29; Iter    74/  157] train: loss: 0.1621680
[Epoch 29; Iter   104/  157] train: loss: 0.0916782
[Epoch 29; Iter   134/  157] train: loss: 0.1516009
[Epoch 29] ogbg-moltox21: 0.764133 val loss: 0.480742
[Epoch 29] ogbg-moltox21: 0.744913 test loss: 0.374960
[Epoch 30; Iter     7/  157] train: loss: 0.1002689
[Epoch 30; Iter    37/  157] train: loss: 0.2394231
[Epoch 30; Iter    67/  157] train: loss: 0.1474622
[Epoch 30; Iter    97/  157] train: loss: 0.1365357
[Epoch 30; Iter   127/  157] train: loss: 0.1015497
[Epoch 30; Iter   157/  157] train: loss: 0.0846370
[Epoch 30] ogbg-moltox21: 0.765850 val loss: 0.379340
[Epoch 30] ogbg-moltox21: 0.742832 test loss: 0.386347
[Epoch 31; Iter    30/  157] train: loss: 0.1662597
[Epoch 31; Iter    60/  157] train: loss: 0.1085905
[Epoch 31; Iter    90/  157] train: loss: 0.1679085
[Epoch 31; Iter   120/  157] train: loss: 0.1116380
[Epoch 31; Iter   150/  157] train: loss: 0.1363463
[Epoch 31] ogbg-moltox21: 0.760166 val loss: 0.444003
[Epoch 31] ogbg-moltox21: 0.739634 test loss: 0.379522
[Epoch 32; Iter    23/  157] train: loss: 0.1649480
[Epoch 32; Iter    53/  157] train: loss: 0.0550629
[Epoch 32; Iter    83/  157] train: loss: 0.1336151
[Epoch 32; Iter   113/  157] train: loss: 0.2095239
[Epoch 32; Iter   143/  157] train: loss: 0.1564729
[Epoch 32] ogbg-moltox21: 0.760229 val loss: 0.345763
[Epoch 32] ogbg-moltox21: 0.739773 test loss: 0.334694
[Epoch 33; Iter    16/  157] train: loss: 0.1200801
[Epoch 33; Iter    46/  157] train: loss: 0.1613564
[Epoch 33; Iter    76/  157] train: loss: 0.1529209
[Epoch 33; Iter   106/  157] train: loss: 0.0693287
[Epoch 33; Iter   136/  157] train: loss: 0.1339331
[Epoch 33] ogbg-moltox21: 0.772184 val loss: 0.350720
[Epoch 33] ogbg-moltox21: 0.739779 test loss: 0.389606
[Epoch 34; Iter     9/  157] train: loss: 0.0808723
[Epoch 34; Iter    39/  157] train: loss: 0.0852159
[Epoch 34; Iter    69/  157] train: loss: 0.1294971
[Epoch 34; Iter    99/  157] train: loss: 0.1535988
[Epoch 34; Iter   129/  157] train: loss: 0.1897897
[Epoch 34] ogbg-moltox21: 0.769239 val loss: 0.337028
[Epoch 34] ogbg-moltox21: 0.731707 test loss: 0.372891
[Epoch 35; Iter     2/  157] train: loss: 0.2045792
[Epoch 35; Iter    32/  157] train: loss: 0.1666673
[Epoch 35; Iter    62/  157] train: loss: 0.0955405
[Epoch 35; Iter    92/  157] train: loss: 0.1146390
[Epoch 35; Iter   122/  157] train: loss: 0.1349571
[Epoch 35; Iter   152/  157] train: loss: 0.1431383
[Epoch 35] ogbg-moltox21: 0.758404 val loss: 0.415586
[Epoch 35] ogbg-moltox21: 0.724783 test loss: 0.349004
[Epoch 36; Iter    25/  157] train: loss: 0.0742863
[Epoch 36; Iter    55/  157] train: loss: 0.1042556
[Epoch 36; Iter    85/  157] train: loss: 0.0477523
[Epoch 36; Iter   115/  157] train: loss: 0.0746072
[Epoch 36; Iter   145/  157] train: loss: 0.1073507
[Epoch 36] ogbg-moltox21: 0.767132 val loss: 0.436966
[Epoch 36] ogbg-moltox21: 0.732052 test loss: 0.357416
[Epoch 37; Iter    18/  157] train: loss: 0.0877728
[Epoch 37; Iter    48/  157] train: loss: 0.1724400
[Epoch 15] ogbg-moltox21: 0.726912 test loss: 0.344017
[Epoch 16; Iter    15/  157] train: loss: 0.1818315
[Epoch 16; Iter    45/  157] train: loss: 0.1359220
[Epoch 16; Iter    75/  157] train: loss: 0.0802739
[Epoch 16; Iter   105/  157] train: loss: 0.1476039
[Epoch 16; Iter   135/  157] train: loss: 0.1667410
[Epoch 16] ogbg-moltox21: 0.748280 val loss: 0.336612
[Epoch 16] ogbg-moltox21: 0.736744 test loss: 0.442590
[Epoch 17; Iter     8/  157] train: loss: 0.1256834
[Epoch 17; Iter    38/  157] train: loss: 0.2160289
[Epoch 17; Iter    68/  157] train: loss: 0.1087165
[Epoch 17; Iter    98/  157] train: loss: 0.1299345
[Epoch 17; Iter   128/  157] train: loss: 0.1514533
[Epoch 17] ogbg-moltox21: 0.742398 val loss: 0.318066
[Epoch 17] ogbg-moltox21: 0.718873 test loss: 0.483363
[Epoch 18; Iter     1/  157] train: loss: 0.1217423
[Epoch 18; Iter    31/  157] train: loss: 0.1411824
[Epoch 18; Iter    61/  157] train: loss: 0.1702156
[Epoch 18; Iter    91/  157] train: loss: 0.1546487
[Epoch 18; Iter   121/  157] train: loss: 0.1005844
[Epoch 18; Iter   151/  157] train: loss: 0.2295284
[Epoch 18] ogbg-moltox21: 0.752912 val loss: 0.335185
[Epoch 18] ogbg-moltox21: 0.742457 test loss: 0.455855
[Epoch 19; Iter    24/  157] train: loss: 0.1697084
[Epoch 19; Iter    54/  157] train: loss: 0.2514489
[Epoch 19; Iter    84/  157] train: loss: 0.1658221
[Epoch 19; Iter   114/  157] train: loss: 0.2070183
[Epoch 19; Iter   144/  157] train: loss: 0.0885783
[Epoch 19] ogbg-moltox21: 0.739655 val loss: 0.560822
[Epoch 19] ogbg-moltox21: 0.717162 test loss: 0.798011
[Epoch 20; Iter    17/  157] train: loss: 0.1780059
[Epoch 20; Iter    47/  157] train: loss: 0.1014614
[Epoch 20; Iter    77/  157] train: loss: 0.1713428
[Epoch 20; Iter   107/  157] train: loss: 0.1392708
[Epoch 20; Iter   137/  157] train: loss: 0.1697264
[Epoch 20] ogbg-moltox21: 0.731715 val loss: 0.319322
[Epoch 20] ogbg-moltox21: 0.725613 test loss: 0.803853
[Epoch 21; Iter    10/  157] train: loss: 0.1153890
[Epoch 21; Iter    40/  157] train: loss: 0.2036932
[Epoch 21; Iter    70/  157] train: loss: 0.1893936
[Epoch 21; Iter   100/  157] train: loss: 0.1504836
[Epoch 21; Iter   130/  157] train: loss: 0.1694268
[Epoch 21] ogbg-moltox21: 0.753953 val loss: 0.495730
[Epoch 21] ogbg-moltox21: 0.745020 test loss: 0.702747
[Epoch 22; Iter     3/  157] train: loss: 0.1412394
[Epoch 22; Iter    33/  157] train: loss: 0.2089805
[Epoch 22; Iter    63/  157] train: loss: 0.1762197
[Epoch 22; Iter    93/  157] train: loss: 0.1306659
[Epoch 22; Iter   123/  157] train: loss: 0.1267596
[Epoch 22; Iter   153/  157] train: loss: 0.1637019
[Epoch 22] ogbg-moltox21: 0.774389 val loss: 0.848270
[Epoch 22] ogbg-moltox21: 0.743050 test loss: 0.801141
[Epoch 23; Iter    26/  157] train: loss: 0.1930833
[Epoch 23; Iter    56/  157] train: loss: 0.1155598
[Epoch 23; Iter    86/  157] train: loss: 0.1286536
[Epoch 23; Iter   116/  157] train: loss: 0.2181160
[Epoch 23; Iter   146/  157] train: loss: 0.0952429
[Epoch 23] ogbg-moltox21: 0.752831 val loss: 0.297016
[Epoch 23] ogbg-moltox21: 0.721415 test loss: 0.319587
[Epoch 24; Iter    19/  157] train: loss: 0.1440990
[Epoch 24; Iter    49/  157] train: loss: 0.1125348
[Epoch 24; Iter    79/  157] train: loss: 0.1490589
[Epoch 24; Iter   109/  157] train: loss: 0.0923862
[Epoch 24; Iter   139/  157] train: loss: 0.1877732
[Epoch 24] ogbg-moltox21: 0.762664 val loss: 0.332250
[Epoch 24] ogbg-moltox21: 0.741841 test loss: 0.356439
[Epoch 25; Iter    12/  157] train: loss: 0.1278541
[Epoch 25; Iter    42/  157] train: loss: 0.1610123
[Epoch 25; Iter    72/  157] train: loss: 0.2532161
[Epoch 25; Iter   102/  157] train: loss: 0.2056202
[Epoch 25; Iter   132/  157] train: loss: 0.1561853
[Epoch 25] ogbg-moltox21: 0.766556 val loss: 0.331059
[Epoch 25] ogbg-moltox21: 0.742626 test loss: 0.359135
[Epoch 26; Iter     5/  157] train: loss: 0.1680838
[Epoch 26; Iter    35/  157] train: loss: 0.1887022
[Epoch 26; Iter    65/  157] train: loss: 0.1276580
[Epoch 26; Iter    95/  157] train: loss: 0.1373409
[Epoch 26; Iter   125/  157] train: loss: 0.2751366
[Epoch 26; Iter   155/  157] train: loss: 0.1705844
[Epoch 26] ogbg-moltox21: 0.765254 val loss: 0.287641
[Epoch 26] ogbg-moltox21: 0.753781 test loss: 0.299112
[Epoch 27; Iter    28/  157] train: loss: 0.1528862
[Epoch 27; Iter    58/  157] train: loss: 0.1117825
[Epoch 27; Iter    88/  157] train: loss: 0.1148130
[Epoch 27; Iter   118/  157] train: loss: 0.2000317
[Epoch 27; Iter   148/  157] train: loss: 0.2228069
[Epoch 27] ogbg-moltox21: 0.558770 val loss: 24.590789
[Epoch 27] ogbg-moltox21: 0.601963 test loss: 25.329978
[Epoch 28; Iter    21/  157] train: loss: 0.2174094
[Epoch 28; Iter    51/  157] train: loss: 0.3466675
[Epoch 28; Iter    81/  157] train: loss: 0.1493700
[Epoch 28; Iter   111/  157] train: loss: 0.1660682
[Epoch 28; Iter   141/  157] train: loss: 0.2279460
[Epoch 28] ogbg-moltox21: 0.751078 val loss: 0.382110
[Epoch 28] ogbg-moltox21: 0.726055 test loss: 0.775042
[Epoch 29; Iter    14/  157] train: loss: 0.1740625
[Epoch 29; Iter    44/  157] train: loss: 0.1727770
[Epoch 29; Iter    74/  157] train: loss: 0.2034878
[Epoch 29; Iter   104/  157] train: loss: 0.1687929
[Epoch 29; Iter   134/  157] train: loss: 0.1536001
[Epoch 29] ogbg-moltox21: 0.753942 val loss: 0.432907
[Epoch 29] ogbg-moltox21: 0.738525 test loss: 0.408234
[Epoch 30; Iter     7/  157] train: loss: 0.1623601
[Epoch 30; Iter    37/  157] train: loss: 0.1555811
[Epoch 30; Iter    67/  157] train: loss: 0.1544727
[Epoch 30; Iter    97/  157] train: loss: 0.1721720
[Epoch 30; Iter   127/  157] train: loss: 0.1631864
[Epoch 30; Iter   157/  157] train: loss: 0.2076920
[Epoch 30] ogbg-moltox21: 0.750930 val loss: 0.495922
[Epoch 30] ogbg-moltox21: 0.748530 test loss: 0.384261
[Epoch 31; Iter    30/  157] train: loss: 0.1809320
[Epoch 31; Iter    60/  157] train: loss: 0.0973516
[Epoch 31; Iter    90/  157] train: loss: 0.1687247
[Epoch 31; Iter   120/  157] train: loss: 0.1625144
[Epoch 31; Iter   150/  157] train: loss: 0.1587413
[Epoch 31] ogbg-moltox21: 0.754762 val loss: 0.919179
[Epoch 31] ogbg-moltox21: 0.742448 test loss: 0.675321
[Epoch 32; Iter    23/  157] train: loss: 0.1516760
[Epoch 32; Iter    53/  157] train: loss: 0.1212842
[Epoch 32; Iter    83/  157] train: loss: 0.2311391
[Epoch 32; Iter   113/  157] train: loss: 0.1740615
[Epoch 32; Iter   143/  157] train: loss: 0.2234824
[Epoch 32] ogbg-moltox21: 0.720006 val loss: 0.346639
[Epoch 32] ogbg-moltox21: 0.707144 test loss: 0.376419
[Epoch 33; Iter    16/  157] train: loss: 0.1543309
[Epoch 33; Iter    46/  157] train: loss: 0.1305805
[Epoch 33; Iter    76/  157] train: loss: 0.1781819
[Epoch 33; Iter   106/  157] train: loss: 0.1733391
[Epoch 33; Iter   136/  157] train: loss: 0.1750796
[Epoch 33] ogbg-moltox21: 0.768067 val loss: 0.351851
[Epoch 33] ogbg-moltox21: 0.743866 test loss: 0.462082
[Epoch 34; Iter     9/  157] train: loss: 0.1412344
[Epoch 34; Iter    39/  157] train: loss: 0.1824160
[Epoch 34; Iter    69/  157] train: loss: 0.1415894
[Epoch 34; Iter    99/  157] train: loss: 0.1922279
[Epoch 34; Iter   129/  157] train: loss: 0.1091772
[Epoch 34] ogbg-moltox21: 0.765125 val loss: 0.298829
[Epoch 34] ogbg-moltox21: 0.739038 test loss: 0.437120
[Epoch 35; Iter     2/  157] train: loss: 0.1207889
[Epoch 35; Iter    32/  157] train: loss: 0.1724237
[Epoch 35; Iter    62/  157] train: loss: 0.1368746
[Epoch 35; Iter    92/  157] train: loss: 0.1589078
[Epoch 35; Iter   122/  157] train: loss: 0.1373326
[Epoch 35; Iter   152/  157] train: loss: 0.1621177
[Epoch 35] ogbg-moltox21: 0.773445 val loss: 0.502884
[Epoch 35] ogbg-moltox21: 0.748524 test loss: 0.897048
[Epoch 36; Iter    25/  157] train: loss: 0.1597898
[Epoch 36; Iter    55/  157] train: loss: 0.1102979
[Epoch 36; Iter    85/  157] train: loss: 0.1306394
[Epoch 36; Iter   115/  157] train: loss: 0.1516525
[Epoch 36; Iter   145/  157] train: loss: 0.1218845
[Epoch 36] ogbg-moltox21: 0.755899 val loss: 0.443553
[Epoch 36] ogbg-moltox21: 0.740412 test loss: 0.428649
[Epoch 37; Iter    18/  157] train: loss: 0.1501547
[Epoch 37; Iter    48/  157] train: loss: 0.1435346
[Epoch 15] ogbg-moltox21: 0.727184 test loss: 0.564758
[Epoch 16; Iter    15/  157] train: loss: 0.1238295
[Epoch 16; Iter    45/  157] train: loss: 0.1935969
[Epoch 16; Iter    75/  157] train: loss: 0.1147065
[Epoch 16; Iter   105/  157] train: loss: 0.1450954
[Epoch 16; Iter   135/  157] train: loss: 0.1270977
[Epoch 16] ogbg-moltox21: 0.764511 val loss: 0.344278
[Epoch 16] ogbg-moltox21: 0.736817 test loss: 0.401204
[Epoch 17; Iter     8/  157] train: loss: 0.2206751
[Epoch 17; Iter    38/  157] train: loss: 0.1119864
[Epoch 17; Iter    68/  157] train: loss: 0.1166132
[Epoch 17; Iter    98/  157] train: loss: 0.1276098
[Epoch 17; Iter   128/  157] train: loss: 0.1614000
[Epoch 17] ogbg-moltox21: 0.772974 val loss: 0.328432
[Epoch 17] ogbg-moltox21: 0.751692 test loss: 0.385371
[Epoch 18; Iter     1/  157] train: loss: 0.1950516
[Epoch 18; Iter    31/  157] train: loss: 0.1585667
[Epoch 18; Iter    61/  157] train: loss: 0.1294080
[Epoch 18; Iter    91/  157] train: loss: 0.1097750
[Epoch 18; Iter   121/  157] train: loss: 0.0772715
[Epoch 18; Iter   151/  157] train: loss: 0.2096128
[Epoch 18] ogbg-moltox21: 0.761435 val loss: 0.386126
[Epoch 18] ogbg-moltox21: 0.724927 test loss: 0.484793
[Epoch 19; Iter    24/  157] train: loss: 0.1914383
[Epoch 19; Iter    54/  157] train: loss: 0.1662954
[Epoch 19; Iter    84/  157] train: loss: 0.1191499
[Epoch 19; Iter   114/  157] train: loss: 0.2021830
[Epoch 19; Iter   144/  157] train: loss: 0.2175786
[Epoch 19] ogbg-moltox21: 0.744835 val loss: 0.421534
[Epoch 19] ogbg-moltox21: 0.730846 test loss: 0.388181
[Epoch 20; Iter    17/  157] train: loss: 0.1569745
[Epoch 20; Iter    47/  157] train: loss: 0.1338213
[Epoch 20; Iter    77/  157] train: loss: 0.1625210
[Epoch 20; Iter   107/  157] train: loss: 0.1437079
[Epoch 20; Iter   137/  157] train: loss: 0.1199037
[Epoch 20] ogbg-moltox21: 0.745997 val loss: 0.357208
[Epoch 20] ogbg-moltox21: 0.733999 test loss: 0.604185
[Epoch 21; Iter    10/  157] train: loss: 0.1581835
[Epoch 21; Iter    40/  157] train: loss: 0.1211520
[Epoch 21; Iter    70/  157] train: loss: 0.1671951
[Epoch 21; Iter   100/  157] train: loss: 0.1298718
[Epoch 21; Iter   130/  157] train: loss: 0.0897685
[Epoch 21] ogbg-moltox21: 0.736853 val loss: 0.397502
[Epoch 21] ogbg-moltox21: 0.730185 test loss: 0.425370
[Epoch 22; Iter     3/  157] train: loss: 0.2212104
[Epoch 22; Iter    33/  157] train: loss: 0.0917683
[Epoch 22; Iter    63/  157] train: loss: 0.1280431
[Epoch 22; Iter    93/  157] train: loss: 0.1625548
[Epoch 22; Iter   123/  157] train: loss: 0.1195645
[Epoch 22; Iter   153/  157] train: loss: 0.1325866
[Epoch 22] ogbg-moltox21: 0.751183 val loss: 0.323705
[Epoch 22] ogbg-moltox21: 0.731431 test loss: 0.354227
[Epoch 23; Iter    26/  157] train: loss: 0.1740870
[Epoch 23; Iter    56/  157] train: loss: 0.0692630
[Epoch 23; Iter    86/  157] train: loss: 0.1083562
[Epoch 23; Iter   116/  157] train: loss: 0.1965417
[Epoch 23; Iter   146/  157] train: loss: 0.0878069
[Epoch 23] ogbg-moltox21: 0.748333 val loss: 0.383690
[Epoch 23] ogbg-moltox21: 0.737041 test loss: 0.503212
[Epoch 24; Iter    19/  157] train: loss: 0.0902606
[Epoch 24; Iter    49/  157] train: loss: 0.1136728
[Epoch 24; Iter    79/  157] train: loss: 0.1791838
[Epoch 24; Iter   109/  157] train: loss: 0.1199845
[Epoch 24; Iter   139/  157] train: loss: 0.1576920
[Epoch 24] ogbg-moltox21: 0.773695 val loss: 0.336368
[Epoch 24] ogbg-moltox21: 0.732128 test loss: 0.510882
[Epoch 25; Iter    12/  157] train: loss: 0.1480530
[Epoch 25; Iter    42/  157] train: loss: 0.1773838
[Epoch 25; Iter    72/  157] train: loss: 0.1047658
[Epoch 25; Iter   102/  157] train: loss: 0.1226278
[Epoch 25; Iter   132/  157] train: loss: 0.2346350
[Epoch 25] ogbg-moltox21: 0.770778 val loss: 0.314834
[Epoch 25] ogbg-moltox21: 0.743893 test loss: 0.363176
[Epoch 26; Iter     5/  157] train: loss: 0.1985908
[Epoch 26; Iter    35/  157] train: loss: 0.1602177
[Epoch 26; Iter    65/  157] train: loss: 0.1876242
[Epoch 26; Iter    95/  157] train: loss: 0.1066701
[Epoch 26; Iter   125/  157] train: loss: 0.1369835
[Epoch 26; Iter   155/  157] train: loss: 0.0953854
[Epoch 26] ogbg-moltox21: 0.773678 val loss: 0.407238
[Epoch 26] ogbg-moltox21: 0.732198 test loss: 0.660757
[Epoch 27; Iter    28/  157] train: loss: 0.1648583
[Epoch 27; Iter    58/  157] train: loss: 0.1296047
[Epoch 27; Iter    88/  157] train: loss: 0.0832682
[Epoch 27; Iter   118/  157] train: loss: 0.1667267
[Epoch 27; Iter   148/  157] train: loss: 0.1842729
[Epoch 27] ogbg-moltox21: 0.776159 val loss: 0.343806
[Epoch 27] ogbg-moltox21: 0.749085 test loss: 0.403692
[Epoch 28; Iter    21/  157] train: loss: 0.1964478
[Epoch 28; Iter    51/  157] train: loss: 0.1587637
[Epoch 28; Iter    81/  157] train: loss: 0.1531435
[Epoch 28; Iter   111/  157] train: loss: 0.1183372
[Epoch 28; Iter   141/  157] train: loss: 0.1311395
[Epoch 28] ogbg-moltox21: 0.767897 val loss: 0.312204
[Epoch 28] ogbg-moltox21: 0.742992 test loss: 0.330565
[Epoch 29; Iter    14/  157] train: loss: 0.1282629
[Epoch 29; Iter    44/  157] train: loss: 0.1162909
[Epoch 29; Iter    74/  157] train: loss: 0.1102839
[Epoch 29; Iter   104/  157] train: loss: 0.1065357
[Epoch 29; Iter   134/  157] train: loss: 0.1173491
[Epoch 29] ogbg-moltox21: 0.748674 val loss: 0.350342
[Epoch 29] ogbg-moltox21: 0.727987 test loss: 0.344592
[Epoch 30; Iter     7/  157] train: loss: 0.1614187
[Epoch 30; Iter    37/  157] train: loss: 0.1207877
[Epoch 30; Iter    67/  157] train: loss: 0.1088586
[Epoch 30; Iter    97/  157] train: loss: 0.1410722
[Epoch 30; Iter   127/  157] train: loss: 0.0864596
[Epoch 30; Iter   157/  157] train: loss: 0.1781416
[Epoch 30] ogbg-moltox21: 0.782760 val loss: 0.297521
[Epoch 30] ogbg-moltox21: 0.753891 test loss: 0.329016
[Epoch 31; Iter    30/  157] train: loss: 0.2128724
[Epoch 31; Iter    60/  157] train: loss: 0.0732951
[Epoch 31; Iter    90/  157] train: loss: 0.1217990
[Epoch 31; Iter   120/  157] train: loss: 0.1211294
[Epoch 31; Iter   150/  157] train: loss: 0.1177422
[Epoch 31] ogbg-moltox21: 0.765254 val loss: 0.349997
[Epoch 31] ogbg-moltox21: 0.745344 test loss: 0.381990
[Epoch 32; Iter    23/  157] train: loss: 0.1085772
[Epoch 32; Iter    53/  157] train: loss: 0.0965013
[Epoch 32; Iter    83/  157] train: loss: 0.1859881
[Epoch 32; Iter   113/  157] train: loss: 0.1450973
[Epoch 32; Iter   143/  157] train: loss: 0.1936027
[Epoch 32] ogbg-moltox21: 0.734327 val loss: 0.377083
[Epoch 32] ogbg-moltox21: 0.736593 test loss: 0.364224
[Epoch 33; Iter    16/  157] train: loss: 0.1392863
[Epoch 33; Iter    46/  157] train: loss: 0.1268336
[Epoch 33; Iter    76/  157] train: loss: 0.0960440
[Epoch 33; Iter   106/  157] train: loss: 0.1684629
[Epoch 33; Iter   136/  157] train: loss: 0.1691106
[Epoch 33] ogbg-moltox21: 0.763976 val loss: 0.324668
[Epoch 33] ogbg-moltox21: 0.742901 test loss: 0.459983
[Epoch 34; Iter     9/  157] train: loss: 0.1455917
[Epoch 34; Iter    39/  157] train: loss: 0.0828323
[Epoch 34; Iter    69/  157] train: loss: 0.1285285
[Epoch 34; Iter    99/  157] train: loss: 0.1345290
[Epoch 34; Iter   129/  157] train: loss: 0.0979068
[Epoch 34] ogbg-moltox21: 0.779390 val loss: 0.314035
[Epoch 34] ogbg-moltox21: 0.742435 test loss: 0.414299
[Epoch 35; Iter     2/  157] train: loss: 0.1265761
[Epoch 35; Iter    32/  157] train: loss: 0.1009175
[Epoch 35; Iter    62/  157] train: loss: 0.1265071
[Epoch 35; Iter    92/  157] train: loss: 0.0912831
[Epoch 35; Iter   122/  157] train: loss: 0.1218212
[Epoch 35; Iter   152/  157] train: loss: 0.1129699
[Epoch 35] ogbg-moltox21: 0.750375 val loss: 0.362456
[Epoch 35] ogbg-moltox21: 0.732511 test loss: 0.467626
[Epoch 36; Iter    25/  157] train: loss: 0.1648232
[Epoch 36; Iter    55/  157] train: loss: 0.1725840
[Epoch 36; Iter    85/  157] train: loss: 0.1168621
[Epoch 36; Iter   115/  157] train: loss: 0.1303103
[Epoch 36; Iter   145/  157] train: loss: 0.1141341
[Epoch 36] ogbg-moltox21: 0.766588 val loss: 0.322326
[Epoch 36] ogbg-moltox21: 0.743734 test loss: 0.418607
[Epoch 37; Iter    18/  157] train: loss: 0.1289853
[Epoch 37; Iter    48/  157] train: loss: 0.1434561
[Epoch 30; Iter    89/  209] train: loss: 0.1204173
[Epoch 30; Iter   119/  209] train: loss: 0.1419739
[Epoch 30; Iter   149/  209] train: loss: 0.2194537
[Epoch 30; Iter   179/  209] train: loss: 0.1085536
[Epoch 30; Iter   209/  209] train: loss: 0.2381056
[Epoch 30] ogbg-moltox21: 0.795233 val loss: 0.244098
[Epoch 30] ogbg-moltox21: 0.756496 test loss: 0.261037
[Epoch 31; Iter    30/  209] train: loss: 0.1524133
[Epoch 31; Iter    60/  209] train: loss: 0.1606376
[Epoch 31; Iter    90/  209] train: loss: 0.2105624
[Epoch 31; Iter   120/  209] train: loss: 0.1301809
[Epoch 31; Iter   150/  209] train: loss: 0.1217491
[Epoch 31; Iter   180/  209] train: loss: 0.1948434
[Epoch 31] ogbg-moltox21: 0.795399 val loss: 0.253900
[Epoch 31] ogbg-moltox21: 0.766261 test loss: 0.262712
[Epoch 32; Iter     1/  209] train: loss: 0.2157509
[Epoch 32; Iter    31/  209] train: loss: 0.1249959
[Epoch 32; Iter    61/  209] train: loss: 0.0781138
[Epoch 32; Iter    91/  209] train: loss: 0.1751385
[Epoch 32; Iter   121/  209] train: loss: 0.1756974
[Epoch 32; Iter   151/  209] train: loss: 0.2235030
[Epoch 32; Iter   181/  209] train: loss: 0.2164711
[Epoch 32] ogbg-moltox21: 0.795814 val loss: 0.258637
[Epoch 32] ogbg-moltox21: 0.759158 test loss: 0.268931
[Epoch 33; Iter     2/  209] train: loss: 0.1097361
[Epoch 33; Iter    32/  209] train: loss: 0.1055334
[Epoch 33; Iter    62/  209] train: loss: 0.1109224
[Epoch 33; Iter    92/  209] train: loss: 0.1182641
[Epoch 33; Iter   122/  209] train: loss: 0.1391183
[Epoch 33; Iter   152/  209] train: loss: 0.2003550
[Epoch 33; Iter   182/  209] train: loss: 0.2151695
[Epoch 33] ogbg-moltox21: 0.800515 val loss: 0.254591
[Epoch 33] ogbg-moltox21: 0.758199 test loss: 0.269087
[Epoch 34; Iter     3/  209] train: loss: 0.1177004
[Epoch 34; Iter    33/  209] train: loss: 0.1614226
[Epoch 34; Iter    63/  209] train: loss: 0.1665599
[Epoch 34; Iter    93/  209] train: loss: 0.0809343
[Epoch 34; Iter   123/  209] train: loss: 0.1656024
[Epoch 34; Iter   153/  209] train: loss: 0.1067091
[Epoch 34; Iter   183/  209] train: loss: 0.1270581
[Epoch 34] ogbg-moltox21: 0.801955 val loss: 0.260056
[Epoch 34] ogbg-moltox21: 0.763159 test loss: 0.271463
[Epoch 35; Iter     4/  209] train: loss: 0.1394024
[Epoch 35; Iter    34/  209] train: loss: 0.1145413
[Epoch 35; Iter    64/  209] train: loss: 0.1654917
[Epoch 35; Iter    94/  209] train: loss: 0.1615178
[Epoch 35; Iter   124/  209] train: loss: 0.2123194
[Epoch 35; Iter   154/  209] train: loss: 0.1494731
[Epoch 35; Iter   184/  209] train: loss: 0.1404962
[Epoch 35] ogbg-moltox21: 0.802050 val loss: 0.247197
[Epoch 35] ogbg-moltox21: 0.761460 test loss: 0.267744
[Epoch 36; Iter     5/  209] train: loss: 0.1664784
[Epoch 36; Iter    35/  209] train: loss: 0.0867794
[Epoch 36; Iter    65/  209] train: loss: 0.1908026
[Epoch 36; Iter    95/  209] train: loss: 0.1169301
[Epoch 36; Iter   125/  209] train: loss: 0.2110276
[Epoch 36; Iter   155/  209] train: loss: 0.1210045
[Epoch 36; Iter   185/  209] train: loss: 0.1601318
[Epoch 36] ogbg-moltox21: 0.800887 val loss: 0.245227
[Epoch 36] ogbg-moltox21: 0.764107 test loss: 0.263121
[Epoch 37; Iter     6/  209] train: loss: 0.0703395
[Epoch 37; Iter    36/  209] train: loss: 0.1461039
[Epoch 37; Iter    66/  209] train: loss: 0.1376460
[Epoch 37; Iter    96/  209] train: loss: 0.1608360
[Epoch 37; Iter   126/  209] train: loss: 0.0900518
[Epoch 37; Iter   156/  209] train: loss: 0.0930106
[Epoch 37; Iter   186/  209] train: loss: 0.1430732
[Epoch 37] ogbg-moltox21: 0.798271 val loss: 0.257366
[Epoch 37] ogbg-moltox21: 0.752519 test loss: 0.278101
[Epoch 38; Iter     7/  209] train: loss: 0.1131406
[Epoch 38; Iter    37/  209] train: loss: 0.1482811
[Epoch 38; Iter    67/  209] train: loss: 0.1078248
[Epoch 38; Iter    97/  209] train: loss: 0.1315212
[Epoch 38; Iter   127/  209] train: loss: 0.1495704
[Epoch 38; Iter   157/  209] train: loss: 0.1380313
[Epoch 38; Iter   187/  209] train: loss: 0.1235580
[Epoch 38] ogbg-moltox21: 0.789778 val loss: 0.253612
[Epoch 38] ogbg-moltox21: 0.761734 test loss: 0.258860
[Epoch 39; Iter     8/  209] train: loss: 0.1586883
[Epoch 39; Iter    38/  209] train: loss: 0.1554378
[Epoch 39; Iter    68/  209] train: loss: 0.1486297
[Epoch 39; Iter    98/  209] train: loss: 0.1310804
[Epoch 39; Iter   128/  209] train: loss: 0.0976393
[Epoch 39; Iter   158/  209] train: loss: 0.1142752
[Epoch 39; Iter   188/  209] train: loss: 0.0819035
[Epoch 39] ogbg-moltox21: 0.809249 val loss: 0.245658
[Epoch 39] ogbg-moltox21: 0.767423 test loss: 0.264803
[Epoch 40; Iter     9/  209] train: loss: 0.1430342
[Epoch 40; Iter    39/  209] train: loss: 0.2707099
[Epoch 40; Iter    69/  209] train: loss: 0.1001311
[Epoch 40; Iter    99/  209] train: loss: 0.1114974
[Epoch 40; Iter   129/  209] train: loss: 0.1281460
[Epoch 40; Iter   159/  209] train: loss: 0.1049683
[Epoch 40; Iter   189/  209] train: loss: 0.1522688
[Epoch 40] ogbg-moltox21: 0.805946 val loss: 0.249144
[Epoch 40] ogbg-moltox21: 0.759830 test loss: 0.265754
[Epoch 41; Iter    10/  209] train: loss: 0.1078770
[Epoch 41; Iter    40/  209] train: loss: 0.0673764
[Epoch 41; Iter    70/  209] train: loss: 0.0822587
[Epoch 41; Iter   100/  209] train: loss: 0.1183977
[Epoch 41; Iter   130/  209] train: loss: 0.1549635
[Epoch 41; Iter   160/  209] train: loss: 0.1525814
[Epoch 41; Iter   190/  209] train: loss: 0.1144472
[Epoch 41] ogbg-moltox21: 0.803308 val loss: 0.257006
[Epoch 41] ogbg-moltox21: 0.764284 test loss: 0.272053
[Epoch 42; Iter    11/  209] train: loss: 0.1080480
[Epoch 42; Iter    41/  209] train: loss: 0.1090001
[Epoch 42; Iter    71/  209] train: loss: 0.0954808
[Epoch 42; Iter   101/  209] train: loss: 0.0918555
[Epoch 42; Iter   131/  209] train: loss: 0.1514790
[Epoch 42; Iter   161/  209] train: loss: 0.0820281
[Epoch 42; Iter   191/  209] train: loss: 0.1165310
[Epoch 42] ogbg-moltox21: 0.808308 val loss: 0.247644
[Epoch 42] ogbg-moltox21: 0.763568 test loss: 0.271819
[Epoch 43; Iter    12/  209] train: loss: 0.1453538
[Epoch 43; Iter    42/  209] train: loss: 0.1292921
[Epoch 43; Iter    72/  209] train: loss: 0.1239843
[Epoch 43; Iter   102/  209] train: loss: 0.1546214
[Epoch 43; Iter   132/  209] train: loss: 0.1183863
[Epoch 43; Iter   162/  209] train: loss: 0.0960794
[Epoch 43; Iter   192/  209] train: loss: 0.1082964
[Epoch 43] ogbg-moltox21: 0.795056 val loss: 0.265824
[Epoch 43] ogbg-moltox21: 0.758642 test loss: 0.280813
[Epoch 44; Iter    13/  209] train: loss: 0.1170053
[Epoch 44; Iter    43/  209] train: loss: 0.1333231
[Epoch 44; Iter    73/  209] train: loss: 0.1176167
[Epoch 44; Iter   103/  209] train: loss: 0.0984744
[Epoch 44; Iter   133/  209] train: loss: 0.1273596
[Epoch 44; Iter   163/  209] train: loss: 0.1241008
[Epoch 44; Iter   193/  209] train: loss: 0.0834578
[Epoch 44] ogbg-moltox21: 0.799894 val loss: 0.246147
[Epoch 44] ogbg-moltox21: 0.771610 test loss: 0.265029
[Epoch 45; Iter    14/  209] train: loss: 0.1321460
[Epoch 45; Iter    44/  209] train: loss: 0.1252438
[Epoch 45; Iter    74/  209] train: loss: 0.1343251
[Epoch 45; Iter   104/  209] train: loss: 0.1300775
[Epoch 45; Iter   134/  209] train: loss: 0.1655403
[Epoch 45; Iter   164/  209] train: loss: 0.0900006
[Epoch 45; Iter   194/  209] train: loss: 0.1256823
[Epoch 45] ogbg-moltox21: 0.798946 val loss: 0.255461
[Epoch 45] ogbg-moltox21: 0.758238 test loss: 0.270695
[Epoch 46; Iter    15/  209] train: loss: 0.0772272
[Epoch 46; Iter    45/  209] train: loss: 0.1368243
[Epoch 46; Iter    75/  209] train: loss: 0.1696783
[Epoch 46; Iter   105/  209] train: loss: 0.1304964
[Epoch 46; Iter   135/  209] train: loss: 0.1416209
[Epoch 46; Iter   165/  209] train: loss: 0.0510870
[Epoch 46; Iter   195/  209] train: loss: 0.0960709
[Epoch 46] ogbg-moltox21: 0.792237 val loss: 0.256002
[Epoch 46] ogbg-moltox21: 0.766449 test loss: 0.273352
[Epoch 47; Iter    16/  209] train: loss: 0.0915676
[Epoch 47; Iter    46/  209] train: loss: 0.1069432
[Epoch 47; Iter    76/  209] train: loss: 0.1190269
[Epoch 47; Iter   106/  209] train: loss: 0.1703613
[Epoch 47; Iter   136/  209] train: loss: 0.1063238
[Epoch 30; Iter    89/  209] train: loss: 0.1320810
[Epoch 30; Iter   119/  209] train: loss: 0.1729730
[Epoch 30; Iter   149/  209] train: loss: 0.1474979
[Epoch 30; Iter   179/  209] train: loss: 0.2091695
[Epoch 30; Iter   209/  209] train: loss: 0.1083488
[Epoch 30] ogbg-moltox21: 0.796150 val loss: 0.257675
[Epoch 30] ogbg-moltox21: 0.769876 test loss: 0.265098
[Epoch 31; Iter    30/  209] train: loss: 0.1125555
[Epoch 31; Iter    60/  209] train: loss: 0.1163426
[Epoch 31; Iter    90/  209] train: loss: 0.1409950
[Epoch 31; Iter   120/  209] train: loss: 0.1090296
[Epoch 31; Iter   150/  209] train: loss: 0.1370054
[Epoch 31; Iter   180/  209] train: loss: 0.2103376
[Epoch 31] ogbg-moltox21: 0.801628 val loss: 0.244811
[Epoch 31] ogbg-moltox21: 0.768740 test loss: 0.257637
[Epoch 32; Iter     1/  209] train: loss: 0.1785053
[Epoch 32; Iter    31/  209] train: loss: 0.0991422
[Epoch 32; Iter    61/  209] train: loss: 0.1832959
[Epoch 32; Iter    91/  209] train: loss: 0.1422776
[Epoch 32; Iter   121/  209] train: loss: 0.1830986
[Epoch 32; Iter   151/  209] train: loss: 0.1824194
[Epoch 32; Iter   181/  209] train: loss: 0.2722828
[Epoch 32] ogbg-moltox21: 0.778666 val loss: 0.253336
[Epoch 32] ogbg-moltox21: 0.755735 test loss: 0.262849
[Epoch 33; Iter     2/  209] train: loss: 0.1469774
[Epoch 33; Iter    32/  209] train: loss: 0.1115150
[Epoch 33; Iter    62/  209] train: loss: 0.1485025
[Epoch 33; Iter    92/  209] train: loss: 0.1713972
[Epoch 33; Iter   122/  209] train: loss: 0.0871587
[Epoch 33; Iter   152/  209] train: loss: 0.1194141
[Epoch 33; Iter   182/  209] train: loss: 0.1336934
[Epoch 33] ogbg-moltox21: 0.786868 val loss: 0.251538
[Epoch 33] ogbg-moltox21: 0.757128 test loss: 0.263162
[Epoch 34; Iter     3/  209] train: loss: 0.0782073
[Epoch 34; Iter    33/  209] train: loss: 0.1350100
[Epoch 34; Iter    63/  209] train: loss: 0.1477365
[Epoch 34; Iter    93/  209] train: loss: 0.1763377
[Epoch 34; Iter   123/  209] train: loss: 0.1170688
[Epoch 34; Iter   153/  209] train: loss: 0.1557883
[Epoch 34; Iter   183/  209] train: loss: 0.1048502
[Epoch 34] ogbg-moltox21: 0.785372 val loss: 0.275906
[Epoch 34] ogbg-moltox21: 0.761979 test loss: 0.275694
[Epoch 35; Iter     4/  209] train: loss: 0.1826273
[Epoch 35; Iter    34/  209] train: loss: 0.1607029
[Epoch 35; Iter    64/  209] train: loss: 0.1637430
[Epoch 35; Iter    94/  209] train: loss: 0.1403685
[Epoch 35; Iter   124/  209] train: loss: 0.1444352
[Epoch 35; Iter   154/  209] train: loss: 0.1254308
[Epoch 35; Iter   184/  209] train: loss: 0.2159191
[Epoch 35] ogbg-moltox21: 0.798326 val loss: 0.260314
[Epoch 35] ogbg-moltox21: 0.778305 test loss: 0.261202
[Epoch 36; Iter     5/  209] train: loss: 0.1465441
[Epoch 36; Iter    35/  209] train: loss: 0.1783909
[Epoch 36; Iter    65/  209] train: loss: 0.1305365
[Epoch 36; Iter    95/  209] train: loss: 0.1613137
[Epoch 36; Iter   125/  209] train: loss: 0.1833999
[Epoch 36; Iter   155/  209] train: loss: 0.1168930
[Epoch 36; Iter   185/  209] train: loss: 0.1512466
[Epoch 36] ogbg-moltox21: 0.800886 val loss: 0.268175
[Epoch 36] ogbg-moltox21: 0.769663 test loss: 0.268327
[Epoch 37; Iter     6/  209] train: loss: 0.1380917
[Epoch 37; Iter    36/  209] train: loss: 0.1654715
[Epoch 37; Iter    66/  209] train: loss: 0.1706330
[Epoch 37; Iter    96/  209] train: loss: 0.1253484
[Epoch 37; Iter   126/  209] train: loss: 0.1508552
[Epoch 37; Iter   156/  209] train: loss: 0.1361828
[Epoch 37; Iter   186/  209] train: loss: 0.1383245
[Epoch 37] ogbg-moltox21: 0.799678 val loss: 0.265469
[Epoch 37] ogbg-moltox21: 0.769252 test loss: 0.269004
[Epoch 38; Iter     7/  209] train: loss: 0.2093567
[Epoch 38; Iter    37/  209] train: loss: 0.1750972
[Epoch 38; Iter    67/  209] train: loss: 0.1062661
[Epoch 38; Iter    97/  209] train: loss: 0.1494904
[Epoch 38; Iter   127/  209] train: loss: 0.1066030
[Epoch 38; Iter   157/  209] train: loss: 0.1310335
[Epoch 38; Iter   187/  209] train: loss: 0.1229035
[Epoch 38] ogbg-moltox21: 0.790641 val loss: 0.260164
[Epoch 38] ogbg-moltox21: 0.772824 test loss: 0.269440
[Epoch 39; Iter     8/  209] train: loss: 0.1353601
[Epoch 39; Iter    38/  209] train: loss: 0.1362585
[Epoch 39; Iter    68/  209] train: loss: 0.1428386
[Epoch 39; Iter    98/  209] train: loss: 0.1309032
[Epoch 39; Iter   128/  209] train: loss: 0.1288854
[Epoch 39; Iter   158/  209] train: loss: 0.1438386
[Epoch 39; Iter   188/  209] train: loss: 0.1182626
[Epoch 39] ogbg-moltox21: 0.787253 val loss: 0.262271
[Epoch 39] ogbg-moltox21: 0.768143 test loss: 0.271242
[Epoch 40; Iter     9/  209] train: loss: 0.0977171
[Epoch 40; Iter    39/  209] train: loss: 0.0873072
[Epoch 40; Iter    69/  209] train: loss: 0.1378120
[Epoch 40; Iter    99/  209] train: loss: 0.1702583
[Epoch 40; Iter   129/  209] train: loss: 0.0768892
[Epoch 40; Iter   159/  209] train: loss: 0.1124522
[Epoch 40; Iter   189/  209] train: loss: 0.1804189
[Epoch 40] ogbg-moltox21: 0.782568 val loss: 0.254757
[Epoch 40] ogbg-moltox21: 0.757037 test loss: 0.264535
[Epoch 41; Iter    10/  209] train: loss: 0.1088021
[Epoch 41; Iter    40/  209] train: loss: 0.1558058
[Epoch 41; Iter    70/  209] train: loss: 0.1407717
[Epoch 41; Iter   100/  209] train: loss: 0.1932145
[Epoch 41; Iter   130/  209] train: loss: 0.1316403
[Epoch 41; Iter   160/  209] train: loss: 0.1420288
[Epoch 41; Iter   190/  209] train: loss: 0.0997520
[Epoch 41] ogbg-moltox21: 0.788939 val loss: 0.254650
[Epoch 41] ogbg-moltox21: 0.770024 test loss: 0.264758
[Epoch 42; Iter    11/  209] train: loss: 0.1348405
[Epoch 42; Iter    41/  209] train: loss: 0.0893852
[Epoch 42; Iter    71/  209] train: loss: 0.1017821
[Epoch 42; Iter   101/  209] train: loss: 0.1740012
[Epoch 42; Iter   131/  209] train: loss: 0.1620812
[Epoch 42; Iter   161/  209] train: loss: 0.0984027
[Epoch 42; Iter   191/  209] train: loss: 0.0578358
[Epoch 42] ogbg-moltox21: 0.795501 val loss: 0.256781
[Epoch 42] ogbg-moltox21: 0.768134 test loss: 0.263353
[Epoch 43; Iter    12/  209] train: loss: 0.1251548
[Epoch 43; Iter    42/  209] train: loss: 0.0973286
[Epoch 43; Iter    72/  209] train: loss: 0.2027794
[Epoch 43; Iter   102/  209] train: loss: 0.1671536
[Epoch 43; Iter   132/  209] train: loss: 0.1422686
[Epoch 43; Iter   162/  209] train: loss: 0.1010774
[Epoch 43; Iter   192/  209] train: loss: 0.0752254
[Epoch 43] ogbg-moltox21: 0.782166 val loss: 0.257746
[Epoch 43] ogbg-moltox21: 0.760088 test loss: 0.263935
[Epoch 44; Iter    13/  209] train: loss: 0.0982410
[Epoch 44; Iter    43/  209] train: loss: 0.0742933
[Epoch 44; Iter    73/  209] train: loss: 0.0819034
[Epoch 44; Iter   103/  209] train: loss: 0.2178338
[Epoch 44; Iter   133/  209] train: loss: 0.1485482
[Epoch 44; Iter   163/  209] train: loss: 0.0979978
[Epoch 44; Iter   193/  209] train: loss: 0.1116183
[Epoch 44] ogbg-moltox21: 0.792468 val loss: 0.266802
[Epoch 44] ogbg-moltox21: 0.764979 test loss: 0.271766
[Epoch 45; Iter    14/  209] train: loss: 0.1146995
[Epoch 45; Iter    44/  209] train: loss: 0.1146479
[Epoch 45; Iter    74/  209] train: loss: 0.0937052
[Epoch 45; Iter   104/  209] train: loss: 0.1167490
[Epoch 45; Iter   134/  209] train: loss: 0.1552395
[Epoch 45; Iter   164/  209] train: loss: 0.1091603
[Epoch 45; Iter   194/  209] train: loss: 0.1549355
[Epoch 45] ogbg-moltox21: 0.780138 val loss: 0.264979
[Epoch 45] ogbg-moltox21: 0.754580 test loss: 0.273154
[Epoch 46; Iter    15/  209] train: loss: 0.0804512
[Epoch 46; Iter    45/  209] train: loss: 0.1435557
[Epoch 46; Iter    75/  209] train: loss: 0.1025366
[Epoch 46; Iter   105/  209] train: loss: 0.0895266
[Epoch 46; Iter   135/  209] train: loss: 0.1514718
[Epoch 46; Iter   165/  209] train: loss: 0.0765125
[Epoch 46; Iter   195/  209] train: loss: 0.1556156
[Epoch 46] ogbg-moltox21: 0.791402 val loss: 0.262466
[Epoch 46] ogbg-moltox21: 0.761253 test loss: 0.272336
[Epoch 47; Iter    16/  209] train: loss: 0.0971622
[Epoch 47; Iter    46/  209] train: loss: 0.0912149
[Epoch 47; Iter    76/  209] train: loss: 0.1094168
[Epoch 47; Iter   106/  209] train: loss: 0.0811718
[Epoch 47; Iter   136/  209] train: loss: 0.1338756
[Epoch 30; Iter    89/  209] train: loss: 0.1999587
[Epoch 30; Iter   119/  209] train: loss: 0.1268248
[Epoch 30; Iter   149/  209] train: loss: 0.1844657
[Epoch 30; Iter   179/  209] train: loss: 0.1421059
[Epoch 30; Iter   209/  209] train: loss: 0.1182746
[Epoch 30] ogbg-moltox21: 0.793153 val loss: 0.386534
[Epoch 30] ogbg-moltox21: 0.762371 test loss: 0.562893
[Epoch 31; Iter    30/  209] train: loss: 0.1740611
[Epoch 31; Iter    60/  209] train: loss: 0.1537438
[Epoch 31; Iter    90/  209] train: loss: 0.0907548
[Epoch 31; Iter   120/  209] train: loss: 0.1350664
[Epoch 31; Iter   150/  209] train: loss: 0.1527109
[Epoch 31; Iter   180/  209] train: loss: 0.1553471
[Epoch 31] ogbg-moltox21: 0.785174 val loss: 0.261340
[Epoch 31] ogbg-moltox21: 0.766557 test loss: 0.261246
[Epoch 32; Iter     1/  209] train: loss: 0.1603509
[Epoch 32; Iter    31/  209] train: loss: 0.1959824
[Epoch 32; Iter    61/  209] train: loss: 0.1335172
[Epoch 32; Iter    91/  209] train: loss: 0.0848356
[Epoch 32; Iter   121/  209] train: loss: 0.1411153
[Epoch 32; Iter   151/  209] train: loss: 0.1062479
[Epoch 32; Iter   181/  209] train: loss: 0.1528759
[Epoch 32] ogbg-moltox21: 0.792187 val loss: 0.255646
[Epoch 32] ogbg-moltox21: 0.755009 test loss: 0.265731
[Epoch 33; Iter     2/  209] train: loss: 0.1467638
[Epoch 33; Iter    32/  209] train: loss: 0.1812045
[Epoch 33; Iter    62/  209] train: loss: 0.2115936
[Epoch 33; Iter    92/  209] train: loss: 0.1873205
[Epoch 33; Iter   122/  209] train: loss: 0.1907643
[Epoch 33; Iter   152/  209] train: loss: 0.1363278
[Epoch 33; Iter   182/  209] train: loss: 0.1257116
[Epoch 33] ogbg-moltox21: 0.779375 val loss: 0.253306
[Epoch 33] ogbg-moltox21: 0.752388 test loss: 0.271906
[Epoch 34; Iter     3/  209] train: loss: 0.1517875
[Epoch 34; Iter    33/  209] train: loss: 0.1675731
[Epoch 34; Iter    63/  209] train: loss: 0.1366692
[Epoch 34; Iter    93/  209] train: loss: 0.1699630
[Epoch 34; Iter   123/  209] train: loss: 0.1259988
[Epoch 34; Iter   153/  209] train: loss: 0.2675959
[Epoch 34; Iter   183/  209] train: loss: 0.0868953
[Epoch 34] ogbg-moltox21: 0.788121 val loss: 0.276028
[Epoch 34] ogbg-moltox21: 0.764672 test loss: 0.275517
[Epoch 35; Iter     4/  209] train: loss: 0.1725863
[Epoch 35; Iter    34/  209] train: loss: 0.1098200
[Epoch 35; Iter    64/  209] train: loss: 0.1494507
[Epoch 35; Iter    94/  209] train: loss: 0.1088970
[Epoch 35; Iter   124/  209] train: loss: 0.2822323
[Epoch 35; Iter   154/  209] train: loss: 0.1993953
[Epoch 35; Iter   184/  209] train: loss: 0.1839733
[Epoch 35] ogbg-moltox21: 0.796894 val loss: 0.256991
[Epoch 35] ogbg-moltox21: 0.773550 test loss: 0.271175
[Epoch 36; Iter     5/  209] train: loss: 0.1296431
[Epoch 36; Iter    35/  209] train: loss: 0.0912747
[Epoch 36; Iter    65/  209] train: loss: 0.1012250
[Epoch 36; Iter    95/  209] train: loss: 0.1521622
[Epoch 36; Iter   125/  209] train: loss: 0.1923140
[Epoch 36; Iter   155/  209] train: loss: 0.1539738
[Epoch 36; Iter   185/  209] train: loss: 0.1070589
[Epoch 36] ogbg-moltox21: 0.793794 val loss: 0.267839
[Epoch 36] ogbg-moltox21: 0.773685 test loss: 0.275824
[Epoch 37; Iter     6/  209] train: loss: 0.1104745
[Epoch 37; Iter    36/  209] train: loss: 0.1961766
[Epoch 37; Iter    66/  209] train: loss: 0.1292772
[Epoch 37; Iter    96/  209] train: loss: 0.1254405
[Epoch 37; Iter   126/  209] train: loss: 0.1492761
[Epoch 37; Iter   156/  209] train: loss: 0.1675043
[Epoch 37; Iter   186/  209] train: loss: 0.1593946
[Epoch 37] ogbg-moltox21: 0.770047 val loss: 0.263280
[Epoch 37] ogbg-moltox21: 0.746880 test loss: 0.302319
[Epoch 38; Iter     7/  209] train: loss: 0.1238986
[Epoch 38; Iter    37/  209] train: loss: 0.1151932
[Epoch 38; Iter    67/  209] train: loss: 0.0862154
[Epoch 38; Iter    97/  209] train: loss: 0.1577760
[Epoch 38; Iter   127/  209] train: loss: 0.2117364
[Epoch 38; Iter   157/  209] train: loss: 0.1484505
[Epoch 38; Iter   187/  209] train: loss: 0.2244484
[Epoch 38] ogbg-moltox21: 0.783528 val loss: 0.256903
[Epoch 38] ogbg-moltox21: 0.766396 test loss: 0.366273
[Epoch 39; Iter     8/  209] train: loss: 0.1090484
[Epoch 39; Iter    38/  209] train: loss: 0.1025916
[Epoch 39; Iter    68/  209] train: loss: 0.1082255
[Epoch 39; Iter    98/  209] train: loss: 0.1511852
[Epoch 39; Iter   128/  209] train: loss: 0.2111702
[Epoch 39; Iter   158/  209] train: loss: 0.1375753
[Epoch 39; Iter   188/  209] train: loss: 0.0920881
[Epoch 39] ogbg-moltox21: 0.795365 val loss: 0.256113
[Epoch 39] ogbg-moltox21: 0.750781 test loss: 0.312694
[Epoch 40; Iter     9/  209] train: loss: 0.1592321
[Epoch 40; Iter    39/  209] train: loss: 0.1546017
[Epoch 40; Iter    69/  209] train: loss: 0.1719134
[Epoch 40; Iter    99/  209] train: loss: 0.1668362
[Epoch 40; Iter   129/  209] train: loss: 0.0957161
[Epoch 40; Iter   159/  209] train: loss: 0.1618549
[Epoch 40; Iter   189/  209] train: loss: 0.1833157
[Epoch 40] ogbg-moltox21: 0.778362 val loss: 0.271745
[Epoch 40] ogbg-moltox21: 0.746227 test loss: 0.287300
[Epoch 41; Iter    10/  209] train: loss: 0.0892794
[Epoch 41; Iter    40/  209] train: loss: 0.1695425
[Epoch 41; Iter    70/  209] train: loss: 0.0587480
[Epoch 41; Iter   100/  209] train: loss: 0.1215818
[Epoch 41; Iter   130/  209] train: loss: 0.2570735
[Epoch 41; Iter   160/  209] train: loss: 0.1705706
[Epoch 41; Iter   190/  209] train: loss: 0.1946035
[Epoch 41] ogbg-moltox21: 0.794438 val loss: 0.268273
[Epoch 41] ogbg-moltox21: 0.772473 test loss: 0.279384
[Epoch 42; Iter    11/  209] train: loss: 0.1291750
[Epoch 42; Iter    41/  209] train: loss: 0.1224529
[Epoch 42; Iter    71/  209] train: loss: 0.1741104
[Epoch 42; Iter   101/  209] train: loss: 0.1420413
[Epoch 42; Iter   131/  209] train: loss: 0.1365377
[Epoch 42; Iter   161/  209] train: loss: 0.1847786
[Epoch 42; Iter   191/  209] train: loss: 0.1410648
[Epoch 42] ogbg-moltox21: 0.792436 val loss: 0.283371
[Epoch 42] ogbg-moltox21: 0.755858 test loss: 0.412176
[Epoch 43; Iter    12/  209] train: loss: 0.1123845
[Epoch 43; Iter    42/  209] train: loss: 0.1356168
[Epoch 43; Iter    72/  209] train: loss: 0.1287207
[Epoch 43; Iter   102/  209] train: loss: 0.1407801
[Epoch 43; Iter   132/  209] train: loss: 0.1282926
[Epoch 43; Iter   162/  209] train: loss: 0.0879235
[Epoch 43; Iter   192/  209] train: loss: 0.1071140
[Epoch 43] ogbg-moltox21: 0.795837 val loss: 0.256293
[Epoch 43] ogbg-moltox21: 0.758111 test loss: 0.270603
[Epoch 44; Iter    13/  209] train: loss: 0.1268871
[Epoch 44; Iter    43/  209] train: loss: 0.1314069
[Epoch 44; Iter    73/  209] train: loss: 0.0972936
[Epoch 44; Iter   103/  209] train: loss: 0.1728244
[Epoch 44; Iter   133/  209] train: loss: 0.1620009
[Epoch 44; Iter   163/  209] train: loss: 0.1435442
[Epoch 44; Iter   193/  209] train: loss: 0.1309266
[Epoch 44] ogbg-moltox21: 0.791703 val loss: 0.265221
[Epoch 44] ogbg-moltox21: 0.763290 test loss: 0.275774
[Epoch 45; Iter    14/  209] train: loss: 0.1428110
[Epoch 45; Iter    44/  209] train: loss: 0.1635941
[Epoch 45; Iter    74/  209] train: loss: 0.1457061
[Epoch 45; Iter   104/  209] train: loss: 0.1214491
[Epoch 45; Iter   134/  209] train: loss: 0.0791123
[Epoch 45; Iter   164/  209] train: loss: 0.1251635
[Epoch 45; Iter   194/  209] train: loss: 0.1109561
[Epoch 45] ogbg-moltox21: 0.794795 val loss: 0.259634
[Epoch 45] ogbg-moltox21: 0.763816 test loss: 0.277011
[Epoch 46; Iter    15/  209] train: loss: 0.1243407
[Epoch 46; Iter    45/  209] train: loss: 0.1340013
[Epoch 46; Iter    75/  209] train: loss: 0.1588737
[Epoch 46; Iter   105/  209] train: loss: 0.1352152
[Epoch 46; Iter   135/  209] train: loss: 0.1799640
[Epoch 46; Iter   165/  209] train: loss: 0.2140256
[Epoch 46; Iter   195/  209] train: loss: 0.1555436
[Epoch 46] ogbg-moltox21: 0.772560 val loss: 0.266706
[Epoch 46] ogbg-moltox21: 0.746971 test loss: 0.285686
[Epoch 47; Iter    16/  209] train: loss: 0.1088448
[Epoch 47; Iter    46/  209] train: loss: 0.0960998
[Epoch 47; Iter    76/  209] train: loss: 0.2061103
[Epoch 47; Iter   106/  209] train: loss: 0.1550465
[Epoch 47; Iter   136/  209] train: loss: 0.1636711
[Epoch 33; Iter   114/  183] train: loss: 0.1989050
[Epoch 33; Iter   144/  183] train: loss: 0.0937260
[Epoch 33; Iter   174/  183] train: loss: 0.1621443
[Epoch 33] ogbg-moltox21: 0.759038 val loss: 0.272056
[Epoch 33] ogbg-moltox21: 0.740282 test loss: 0.282243
[Epoch 34; Iter    21/  183] train: loss: 0.1360055
[Epoch 34; Iter    51/  183] train: loss: 0.1716637
[Epoch 34; Iter    81/  183] train: loss: 0.1325719
[Epoch 34; Iter   111/  183] train: loss: 0.2276597
[Epoch 34; Iter   141/  183] train: loss: 0.2108939
[Epoch 34; Iter   171/  183] train: loss: 0.1936649
[Epoch 34] ogbg-moltox21: 0.758637 val loss: 0.275429
[Epoch 34] ogbg-moltox21: 0.736691 test loss: 0.275299
[Epoch 35; Iter    18/  183] train: loss: 0.1810943
[Epoch 35; Iter    48/  183] train: loss: 0.1800205
[Epoch 35; Iter    78/  183] train: loss: 0.1495682
[Epoch 35; Iter   108/  183] train: loss: 0.1849253
[Epoch 35; Iter   138/  183] train: loss: 0.1086052
[Epoch 35; Iter   168/  183] train: loss: 0.1226295
[Epoch 35] ogbg-moltox21: 0.783263 val loss: 0.263756
[Epoch 35] ogbg-moltox21: 0.747190 test loss: 0.272469
[Epoch 36; Iter    15/  183] train: loss: 0.1721293
[Epoch 36; Iter    45/  183] train: loss: 0.1126383
[Epoch 36; Iter    75/  183] train: loss: 0.1435912
[Epoch 36; Iter   105/  183] train: loss: 0.1501235
[Epoch 36; Iter   135/  183] train: loss: 0.1210846
[Epoch 36; Iter   165/  183] train: loss: 0.0990197
[Epoch 36] ogbg-moltox21: 0.776180 val loss: 0.260843
[Epoch 36] ogbg-moltox21: 0.742959 test loss: 0.276642
[Epoch 37; Iter    12/  183] train: loss: 0.1323422
[Epoch 37; Iter    42/  183] train: loss: 0.1134923
[Epoch 37; Iter    72/  183] train: loss: 0.1470610
[Epoch 37; Iter   102/  183] train: loss: 0.1003605
[Epoch 37; Iter   132/  183] train: loss: 0.1229597
[Epoch 37; Iter   162/  183] train: loss: 0.0998891
[Epoch 37] ogbg-moltox21: 0.785833 val loss: 0.258735
[Epoch 37] ogbg-moltox21: 0.753853 test loss: 0.272577
[Epoch 38; Iter     9/  183] train: loss: 0.1560713
[Epoch 38; Iter    39/  183] train: loss: 0.1596562
[Epoch 38; Iter    69/  183] train: loss: 0.1158124
[Epoch 38; Iter    99/  183] train: loss: 0.1326051
[Epoch 38; Iter   129/  183] train: loss: 0.0763724
[Epoch 38; Iter   159/  183] train: loss: 0.1486188
[Epoch 38] ogbg-moltox21: 0.788738 val loss: 0.258315
[Epoch 38] ogbg-moltox21: 0.754566 test loss: 0.273334
[Epoch 39; Iter     6/  183] train: loss: 0.1666909
[Epoch 39; Iter    36/  183] train: loss: 0.1339324
[Epoch 39; Iter    66/  183] train: loss: 0.1390713
[Epoch 39; Iter    96/  183] train: loss: 0.1027251
[Epoch 39; Iter   126/  183] train: loss: 0.1251678
[Epoch 39; Iter   156/  183] train: loss: 0.1957368
[Epoch 39] ogbg-moltox21: 0.780886 val loss: 0.258367
[Epoch 39] ogbg-moltox21: 0.752663 test loss: 0.270590
[Epoch 40; Iter     3/  183] train: loss: 0.1640534
[Epoch 40; Iter    33/  183] train: loss: 0.0830461
[Epoch 40; Iter    63/  183] train: loss: 0.1018729
[Epoch 40; Iter    93/  183] train: loss: 0.1258565
[Epoch 40; Iter   123/  183] train: loss: 0.2158246
[Epoch 40; Iter   153/  183] train: loss: 0.1296130
[Epoch 40; Iter   183/  183] train: loss: 0.0726221
[Epoch 40] ogbg-moltox21: 0.779666 val loss: 0.265661
[Epoch 40] ogbg-moltox21: 0.749251 test loss: 0.279251
[Epoch 41; Iter    30/  183] train: loss: 0.1677759
[Epoch 41; Iter    60/  183] train: loss: 0.1302769
[Epoch 41; Iter    90/  183] train: loss: 0.0903532
[Epoch 41; Iter   120/  183] train: loss: 0.1659853
[Epoch 41; Iter   150/  183] train: loss: 0.1201941
[Epoch 41; Iter   180/  183] train: loss: 0.0988566
[Epoch 41] ogbg-moltox21: 0.782641 val loss: 0.262612
[Epoch 41] ogbg-moltox21: 0.744879 test loss: 0.282930
[Epoch 42; Iter    27/  183] train: loss: 0.2025530
[Epoch 42; Iter    57/  183] train: loss: 0.2011026
[Epoch 42; Iter    87/  183] train: loss: 0.1113049
[Epoch 42; Iter   117/  183] train: loss: 0.0902993
[Epoch 42; Iter   147/  183] train: loss: 0.1150312
[Epoch 42; Iter   177/  183] train: loss: 0.1400298
[Epoch 42] ogbg-moltox21: 0.768351 val loss: 0.273180
[Epoch 42] ogbg-moltox21: 0.737888 test loss: 0.287550
[Epoch 43; Iter    24/  183] train: loss: 0.0929371
[Epoch 43; Iter    54/  183] train: loss: 0.1650873
[Epoch 43; Iter    84/  183] train: loss: 0.1514052
[Epoch 43; Iter   114/  183] train: loss: 0.0915833
[Epoch 43; Iter   144/  183] train: loss: 0.0823939
[Epoch 43; Iter   174/  183] train: loss: 0.0936563
[Epoch 43] ogbg-moltox21: 0.768809 val loss: 0.276422
[Epoch 43] ogbg-moltox21: 0.738673 test loss: 0.292120
[Epoch 44; Iter    21/  183] train: loss: 0.1687351
[Epoch 44; Iter    51/  183] train: loss: 0.1607539
[Epoch 44; Iter    81/  183] train: loss: 0.1454539
[Epoch 44; Iter   111/  183] train: loss: 0.1214257
[Epoch 44; Iter   141/  183] train: loss: 0.1143914
[Epoch 44; Iter   171/  183] train: loss: 0.1700105
[Epoch 44] ogbg-moltox21: 0.773632 val loss: 0.274934
[Epoch 44] ogbg-moltox21: 0.746280 test loss: 0.296193
[Epoch 45; Iter    18/  183] train: loss: 0.1452087
[Epoch 45; Iter    48/  183] train: loss: 0.0739715
[Epoch 45; Iter    78/  183] train: loss: 0.1288560
[Epoch 45; Iter   108/  183] train: loss: 0.0907933
[Epoch 45; Iter   138/  183] train: loss: 0.0774168
[Epoch 45; Iter   168/  183] train: loss: 0.1623978
[Epoch 45] ogbg-moltox21: 0.766888 val loss: 0.281513
[Epoch 45] ogbg-moltox21: 0.745430 test loss: 0.291690
[Epoch 46; Iter    15/  183] train: loss: 0.0927626
[Epoch 46; Iter    45/  183] train: loss: 0.0908870
[Epoch 46; Iter    75/  183] train: loss: 0.1144632
[Epoch 46; Iter   105/  183] train: loss: 0.0658060
[Epoch 46; Iter   135/  183] train: loss: 0.0729962
[Epoch 46; Iter   165/  183] train: loss: 0.1013181
[Epoch 46] ogbg-moltox21: 0.775173 val loss: 0.272889
[Epoch 46] ogbg-moltox21: 0.741472 test loss: 0.292349
[Epoch 47; Iter    12/  183] train: loss: 0.1155109
[Epoch 47; Iter    42/  183] train: loss: 0.1140818
[Epoch 47; Iter    72/  183] train: loss: 0.0692335
[Epoch 47; Iter   102/  183] train: loss: 0.1231385
[Epoch 47; Iter   132/  183] train: loss: 0.0967844
[Epoch 47; Iter   162/  183] train: loss: 0.0990414
[Epoch 47] ogbg-moltox21: 0.776684 val loss: 0.277748
[Epoch 47] ogbg-moltox21: 0.739970 test loss: 0.302669
[Epoch 48; Iter     9/  183] train: loss: 0.1385959
[Epoch 48; Iter    39/  183] train: loss: 0.0767242
[Epoch 48; Iter    69/  183] train: loss: 0.1238762
[Epoch 48; Iter    99/  183] train: loss: 0.0864786
[Epoch 48; Iter   129/  183] train: loss: 0.1018718
[Epoch 48; Iter   159/  183] train: loss: 0.1197193
[Epoch 48] ogbg-moltox21: 0.765455 val loss: 0.271116
[Epoch 48] ogbg-moltox21: 0.736485 test loss: 0.296258
[Epoch 49; Iter     6/  183] train: loss: 0.0818038
[Epoch 49; Iter    36/  183] train: loss: 0.1002569
[Epoch 49; Iter    66/  183] train: loss: 0.1000990
[Epoch 49; Iter    96/  183] train: loss: 0.0990070
[Epoch 49; Iter   126/  183] train: loss: 0.1469222
[Epoch 49; Iter   156/  183] train: loss: 0.1148766
[Epoch 49] ogbg-moltox21: 0.771540 val loss: 0.280616
[Epoch 49] ogbg-moltox21: 0.741465 test loss: 0.300999
[Epoch 50; Iter     3/  183] train: loss: 0.0537632
[Epoch 50; Iter    33/  183] train: loss: 0.0877197
[Epoch 50; Iter    63/  183] train: loss: 0.1079195
[Epoch 50; Iter    93/  183] train: loss: 0.0863163
[Epoch 50; Iter   123/  183] train: loss: 0.1632149
[Epoch 50; Iter   153/  183] train: loss: 0.0790478
[Epoch 50; Iter   183/  183] train: loss: 0.0839214
[Epoch 50] ogbg-moltox21: 0.778298 val loss: 0.274303
[Epoch 50] ogbg-moltox21: 0.745449 test loss: 0.308785
[Epoch 51; Iter    30/  183] train: loss: 0.1187876
[Epoch 51; Iter    60/  183] train: loss: 0.1115112
[Epoch 51; Iter    90/  183] train: loss: 0.2366707
[Epoch 51; Iter   120/  183] train: loss: 0.0925560
[Epoch 51; Iter   150/  183] train: loss: 0.1185300
[Epoch 51; Iter   180/  183] train: loss: 0.1089952
[Epoch 51] ogbg-moltox21: 0.762252 val loss: 0.304944
[Epoch 51] ogbg-moltox21: 0.740369 test loss: 0.322749
[Epoch 52; Iter    27/  183] train: loss: 0.0638287
[Epoch 52; Iter    57/  183] train: loss: 0.0851582
[Epoch 52; Iter    87/  183] train: loss: 0.0831253
[Epoch 52; Iter   117/  183] train: loss: 0.1026424
[Epoch 33; Iter   114/  183] train: loss: 0.1203473
[Epoch 33; Iter   144/  183] train: loss: 0.1451876
[Epoch 33; Iter   174/  183] train: loss: 0.1080457
[Epoch 33] ogbg-moltox21: 0.759641 val loss: 0.306029
[Epoch 33] ogbg-moltox21: 0.745618 test loss: 0.291225
[Epoch 34; Iter    21/  183] train: loss: 0.0799233
[Epoch 34; Iter    51/  183] train: loss: 0.0860255
[Epoch 34; Iter    81/  183] train: loss: 0.1045986
[Epoch 34; Iter   111/  183] train: loss: 0.1064245
[Epoch 34; Iter   141/  183] train: loss: 0.1336104
[Epoch 34; Iter   171/  183] train: loss: 0.1393127
[Epoch 34] ogbg-moltox21: 0.769916 val loss: 0.416791
[Epoch 34] ogbg-moltox21: 0.744934 test loss: 0.362153
[Epoch 35; Iter    18/  183] train: loss: 0.0980656
[Epoch 35; Iter    48/  183] train: loss: 0.1041425
[Epoch 35; Iter    78/  183] train: loss: 0.2482914
[Epoch 35; Iter   108/  183] train: loss: 0.1337036
[Epoch 35; Iter   138/  183] train: loss: 0.1124378
[Epoch 35; Iter   168/  183] train: loss: 0.1448140
[Epoch 35] ogbg-moltox21: 0.773092 val loss: 0.343098
[Epoch 35] ogbg-moltox21: 0.750387 test loss: 0.313145
[Epoch 36; Iter    15/  183] train: loss: 0.0640671
[Epoch 36; Iter    45/  183] train: loss: 0.1307976
[Epoch 36; Iter    75/  183] train: loss: 0.1325888
[Epoch 36; Iter   105/  183] train: loss: 0.1478243
[Epoch 36; Iter   135/  183] train: loss: 0.0860096
[Epoch 36; Iter   165/  183] train: loss: 0.1195138
[Epoch 36] ogbg-moltox21: 0.768114 val loss: 0.291659
[Epoch 36] ogbg-moltox21: 0.728384 test loss: 0.308949
[Epoch 37; Iter    12/  183] train: loss: 0.1381549
[Epoch 37; Iter    42/  183] train: loss: 0.0653123
[Epoch 37; Iter    72/  183] train: loss: 0.1604821
[Epoch 37; Iter   102/  183] train: loss: 0.1458570
[Epoch 37; Iter   132/  183] train: loss: 0.0979246
[Epoch 37; Iter   162/  183] train: loss: 0.0996580
[Epoch 37] ogbg-moltox21: 0.774192 val loss: 0.290739
[Epoch 37] ogbg-moltox21: 0.739911 test loss: 0.292638
[Epoch 38; Iter     9/  183] train: loss: 0.1397464
[Epoch 38; Iter    39/  183] train: loss: 0.1228660
[Epoch 38; Iter    69/  183] train: loss: 0.0988362
[Epoch 38; Iter    99/  183] train: loss: 0.0892276
[Epoch 38; Iter   129/  183] train: loss: 0.0708795
[Epoch 38; Iter   159/  183] train: loss: 0.1356846
[Epoch 38] ogbg-moltox21: 0.756224 val loss: 0.287849
[Epoch 38] ogbg-moltox21: 0.731277 test loss: 0.310172
[Epoch 39; Iter     6/  183] train: loss: 0.1392492
[Epoch 39; Iter    36/  183] train: loss: 0.1164479
[Epoch 39; Iter    66/  183] train: loss: 0.0916614
[Epoch 39; Iter    96/  183] train: loss: 0.0837163
[Epoch 39; Iter   126/  183] train: loss: 0.0898558
[Epoch 39; Iter   156/  183] train: loss: 0.1155426
[Epoch 39] ogbg-moltox21: 0.770188 val loss: 0.274404
[Epoch 39] ogbg-moltox21: 0.741719 test loss: 0.291438
[Epoch 40; Iter     3/  183] train: loss: 0.1316756
[Epoch 40; Iter    33/  183] train: loss: 0.0692302
[Epoch 40; Iter    63/  183] train: loss: 0.0643221
[Epoch 40; Iter    93/  183] train: loss: 0.1225403
[Epoch 40; Iter   123/  183] train: loss: 0.1542235
[Epoch 40; Iter   153/  183] train: loss: 0.0966287
[Epoch 40; Iter   183/  183] train: loss: 0.1310697
[Epoch 40] ogbg-moltox21: 0.764866 val loss: 0.328303
[Epoch 40] ogbg-moltox21: 0.733397 test loss: 0.306357
[Epoch 41; Iter    30/  183] train: loss: 0.1496880
[Epoch 41; Iter    60/  183] train: loss: 0.0636287
[Epoch 41; Iter    90/  183] train: loss: 0.0995623
[Epoch 41; Iter   120/  183] train: loss: 0.1209714
[Epoch 41; Iter   150/  183] train: loss: 0.2258339
[Epoch 41; Iter   180/  183] train: loss: 0.0904019
[Epoch 41] ogbg-moltox21: 0.753005 val loss: 0.291845
[Epoch 41] ogbg-moltox21: 0.734610 test loss: 0.300541
[Epoch 42; Iter    27/  183] train: loss: 0.0551783
[Epoch 42; Iter    57/  183] train: loss: 0.0839420
[Epoch 42; Iter    87/  183] train: loss: 0.1179497
[Epoch 42; Iter   117/  183] train: loss: 0.1244706
[Epoch 42; Iter   147/  183] train: loss: 0.0974564
[Epoch 42; Iter   177/  183] train: loss: 0.0937800
[Epoch 42] ogbg-moltox21: 0.769847 val loss: 0.317552
[Epoch 42] ogbg-moltox21: 0.736659 test loss: 0.312290
[Epoch 43; Iter    24/  183] train: loss: 0.1070823
[Epoch 43; Iter    54/  183] train: loss: 0.1222348
[Epoch 43; Iter    84/  183] train: loss: 0.1278390
[Epoch 43; Iter   114/  183] train: loss: 0.1125145
[Epoch 43; Iter   144/  183] train: loss: 0.1010994
[Epoch 43; Iter   174/  183] train: loss: 0.1022346
[Epoch 43] ogbg-moltox21: 0.761145 val loss: 0.312077
[Epoch 43] ogbg-moltox21: 0.736168 test loss: 0.328097
[Epoch 44; Iter    21/  183] train: loss: 0.1207402
[Epoch 44; Iter    51/  183] train: loss: 0.0934323
[Epoch 44; Iter    81/  183] train: loss: 0.1059701
[Epoch 44; Iter   111/  183] train: loss: 0.1159516
[Epoch 44; Iter   141/  183] train: loss: 0.1018442
[Epoch 44; Iter   171/  183] train: loss: 0.0912397
[Epoch 44] ogbg-moltox21: 0.760837 val loss: 0.365976
[Epoch 44] ogbg-moltox21: 0.735969 test loss: 0.321588
[Epoch 45; Iter    18/  183] train: loss: 0.1089197
[Epoch 45; Iter    48/  183] train: loss: 0.0869616
[Epoch 45; Iter    78/  183] train: loss: 0.1091589
[Epoch 45; Iter   108/  183] train: loss: 0.1289281
[Epoch 45; Iter   138/  183] train: loss: 0.1169150
[Epoch 45; Iter   168/  183] train: loss: 0.0742457
[Epoch 45] ogbg-moltox21: 0.756345 val loss: 0.306323
[Epoch 45] ogbg-moltox21: 0.733284 test loss: 0.313883
[Epoch 46; Iter    15/  183] train: loss: 0.0881120
[Epoch 46; Iter    45/  183] train: loss: 0.1558492
[Epoch 46; Iter    75/  183] train: loss: 0.1909275
[Epoch 46; Iter   105/  183] train: loss: 0.1200168
[Epoch 46; Iter   135/  183] train: loss: 0.1459450
[Epoch 46; Iter   165/  183] train: loss: 0.0874142
[Epoch 46] ogbg-moltox21: 0.751196 val loss: 0.311432
[Epoch 46] ogbg-moltox21: 0.735524 test loss: 0.312921
[Epoch 47; Iter    12/  183] train: loss: 0.1057847
[Epoch 47; Iter    42/  183] train: loss: 0.0902331
[Epoch 47; Iter    72/  183] train: loss: 0.1000077
[Epoch 47; Iter   102/  183] train: loss: 0.0959952
[Epoch 47; Iter   132/  183] train: loss: 0.1105132
[Epoch 47; Iter   162/  183] train: loss: 0.0611464
[Epoch 47] ogbg-moltox21: 0.750532 val loss: 0.417571
[Epoch 47] ogbg-moltox21: 0.728134 test loss: 0.356795
[Epoch 48; Iter     9/  183] train: loss: 0.0759038
[Epoch 48; Iter    39/  183] train: loss: 0.1324122
[Epoch 48; Iter    69/  183] train: loss: 0.1119794
[Epoch 48; Iter    99/  183] train: loss: 0.1025770
[Epoch 48; Iter   129/  183] train: loss: 0.1519566
[Epoch 48; Iter   159/  183] train: loss: 0.0630895
[Epoch 48] ogbg-moltox21: 0.760259 val loss: 0.306500
[Epoch 48] ogbg-moltox21: 0.741246 test loss: 0.317079
[Epoch 49; Iter     6/  183] train: loss: 0.0867818
[Epoch 49; Iter    36/  183] train: loss: 0.1177845
[Epoch 49; Iter    66/  183] train: loss: 0.0782938
[Epoch 49; Iter    96/  183] train: loss: 0.2063275
[Epoch 49; Iter   126/  183] train: loss: 0.1045423
[Epoch 49; Iter   156/  183] train: loss: 0.1559629
[Epoch 49] ogbg-moltox21: 0.759337 val loss: 0.362666
[Epoch 49] ogbg-moltox21: 0.734590 test loss: 0.326268
[Epoch 50; Iter     3/  183] train: loss: 0.1016112
[Epoch 50; Iter    33/  183] train: loss: 0.1140060
[Epoch 50; Iter    63/  183] train: loss: 0.0838356
[Epoch 50; Iter    93/  183] train: loss: 0.1277610
[Epoch 50; Iter   123/  183] train: loss: 0.0955912
[Epoch 50; Iter   153/  183] train: loss: 0.0782140
[Epoch 50; Iter   183/  183] train: loss: 0.1029323
[Epoch 50] ogbg-moltox21: 0.744170 val loss: 0.319068
[Epoch 50] ogbg-moltox21: 0.729046 test loss: 0.323510
[Epoch 51; Iter    30/  183] train: loss: 0.1165803
[Epoch 51; Iter    60/  183] train: loss: 0.0675227
[Epoch 51; Iter    90/  183] train: loss: 0.1148489
[Epoch 51; Iter   120/  183] train: loss: 0.0786699
[Epoch 51; Iter   150/  183] train: loss: 0.0954764
[Epoch 51; Iter   180/  183] train: loss: 0.0825926
[Epoch 51] ogbg-moltox21: 0.755214 val loss: 0.321357
[Epoch 51] ogbg-moltox21: 0.731509 test loss: 0.330399
[Epoch 52; Iter    27/  183] train: loss: 0.0618748
[Epoch 52; Iter    57/  183] train: loss: 0.0581547
[Epoch 52; Iter    87/  183] train: loss: 0.1353269
[Epoch 52; Iter   117/  183] train: loss: 0.0817535
[Epoch 33; Iter   114/  183] train: loss: 0.1555387
[Epoch 33; Iter   144/  183] train: loss: 0.1437770
[Epoch 33; Iter   174/  183] train: loss: 0.2366143
[Epoch 33] ogbg-moltox21: 0.770527 val loss: 0.292296
[Epoch 33] ogbg-moltox21: 0.745376 test loss: 0.343922
[Epoch 34; Iter    21/  183] train: loss: 0.1448006
[Epoch 34; Iter    51/  183] train: loss: 0.1715551
[Epoch 34; Iter    81/  183] train: loss: 0.1021970
[Epoch 34; Iter   111/  183] train: loss: 0.0931169
[Epoch 34; Iter   141/  183] train: loss: 0.1512100
[Epoch 34; Iter   171/  183] train: loss: 0.1479265
[Epoch 34] ogbg-moltox21: 0.765734 val loss: 0.275697
[Epoch 34] ogbg-moltox21: 0.748465 test loss: 0.403928
[Epoch 35; Iter    18/  183] train: loss: 0.1681933
[Epoch 35; Iter    48/  183] train: loss: 0.1407726
[Epoch 35; Iter    78/  183] train: loss: 0.1279658
[Epoch 35; Iter   108/  183] train: loss: 0.1622384
[Epoch 35; Iter   138/  183] train: loss: 0.1548382
[Epoch 35; Iter   168/  183] train: loss: 0.0564612
[Epoch 35] ogbg-moltox21: 0.762720 val loss: 0.345203
[Epoch 35] ogbg-moltox21: 0.751542 test loss: 0.391411
[Epoch 36; Iter    15/  183] train: loss: 0.1134254
[Epoch 36; Iter    45/  183] train: loss: 0.1695576
[Epoch 36; Iter    75/  183] train: loss: 0.1484603
[Epoch 36; Iter   105/  183] train: loss: 0.1147947
[Epoch 36; Iter   135/  183] train: loss: 0.1157213
[Epoch 36; Iter   165/  183] train: loss: 0.0879058
[Epoch 36] ogbg-moltox21: 0.773680 val loss: 0.288648
[Epoch 36] ogbg-moltox21: 0.754430 test loss: 0.353462
[Epoch 37; Iter    12/  183] train: loss: 0.1507022
[Epoch 37; Iter    42/  183] train: loss: 0.1168925
[Epoch 37; Iter    72/  183] train: loss: 0.0994973
[Epoch 37; Iter   102/  183] train: loss: 0.1049568
[Epoch 37; Iter   132/  183] train: loss: 0.1685050
[Epoch 37; Iter   162/  183] train: loss: 0.1493516
[Epoch 37] ogbg-moltox21: 0.764962 val loss: 0.283421
[Epoch 37] ogbg-moltox21: 0.744014 test loss: 0.288441
[Epoch 38; Iter     9/  183] train: loss: 0.1517005
[Epoch 38; Iter    39/  183] train: loss: 0.1083658
[Epoch 38; Iter    69/  183] train: loss: 0.1774346
[Epoch 38; Iter    99/  183] train: loss: 0.1409173
[Epoch 38; Iter   129/  183] train: loss: 0.0823176
[Epoch 38; Iter   159/  183] train: loss: 0.1065332
[Epoch 38] ogbg-moltox21: 0.767074 val loss: 0.281380
[Epoch 38] ogbg-moltox21: 0.746603 test loss: 0.296335
[Epoch 39; Iter     6/  183] train: loss: 0.1311165
[Epoch 39; Iter    36/  183] train: loss: 0.1277029
[Epoch 39; Iter    66/  183] train: loss: 0.1186127
[Epoch 39; Iter    96/  183] train: loss: 0.1221780
[Epoch 39; Iter   126/  183] train: loss: 0.1497087
[Epoch 39; Iter   156/  183] train: loss: 0.0928877
[Epoch 39] ogbg-moltox21: 0.763120 val loss: 0.353341
[Epoch 39] ogbg-moltox21: 0.735052 test loss: 0.686084
[Epoch 40; Iter     3/  183] train: loss: 0.1313245
[Epoch 40; Iter    33/  183] train: loss: 0.0898807
[Epoch 40; Iter    63/  183] train: loss: 0.1008669
[Epoch 40; Iter    93/  183] train: loss: 0.0948547
[Epoch 40; Iter   123/  183] train: loss: 0.0937565
[Epoch 40; Iter   153/  183] train: loss: 0.1456985
[Epoch 40; Iter   183/  183] train: loss: 0.0701697
[Epoch 40] ogbg-moltox21: 0.751848 val loss: 0.292913
[Epoch 40] ogbg-moltox21: 0.728222 test loss: 0.333268
[Epoch 41; Iter    30/  183] train: loss: 0.1791444
[Epoch 41; Iter    60/  183] train: loss: 0.1259407
[Epoch 41; Iter    90/  183] train: loss: 0.1235502
[Epoch 41; Iter   120/  183] train: loss: 0.1215329
[Epoch 41; Iter   150/  183] train: loss: 0.1599787
[Epoch 41; Iter   180/  183] train: loss: 0.0965286
[Epoch 41] ogbg-moltox21: 0.763444 val loss: 0.279803
[Epoch 41] ogbg-moltox21: 0.737074 test loss: 0.305358
[Epoch 42; Iter    27/  183] train: loss: 0.1118800
[Epoch 42; Iter    57/  183] train: loss: 0.1092656
[Epoch 42; Iter    87/  183] train: loss: 0.1225274
[Epoch 42; Iter   117/  183] train: loss: 0.1539928
[Epoch 42; Iter   147/  183] train: loss: 0.0716064
[Epoch 42; Iter   177/  183] train: loss: 0.1639060
[Epoch 42] ogbg-moltox21: 0.754769 val loss: 0.444690
[Epoch 42] ogbg-moltox21: 0.732413 test loss: 1.036230
[Epoch 43; Iter    24/  183] train: loss: 0.1277879
[Epoch 43; Iter    54/  183] train: loss: 0.0877543
[Epoch 43; Iter    84/  183] train: loss: 0.0949610
[Epoch 43; Iter   114/  183] train: loss: 0.1133142
[Epoch 43; Iter   144/  183] train: loss: 0.0802882
[Epoch 43; Iter   174/  183] train: loss: 0.0644043
[Epoch 43] ogbg-moltox21: 0.752641 val loss: 0.560172
[Epoch 43] ogbg-moltox21: 0.733268 test loss: 1.142723
[Epoch 44; Iter    21/  183] train: loss: 0.0939549
[Epoch 44; Iter    51/  183] train: loss: 0.1047228
[Epoch 44; Iter    81/  183] train: loss: 0.1643943
[Epoch 44; Iter   111/  183] train: loss: 0.1772059
[Epoch 44; Iter   141/  183] train: loss: 0.2006309
[Epoch 44; Iter   171/  183] train: loss: 0.1609060
[Epoch 44] ogbg-moltox21: 0.755948 val loss: 0.294828
[Epoch 44] ogbg-moltox21: 0.738887 test loss: 0.311453
[Epoch 45; Iter    18/  183] train: loss: 0.1686458
[Epoch 45; Iter    48/  183] train: loss: 0.2088179
[Epoch 45; Iter    78/  183] train: loss: 0.0805231
[Epoch 45; Iter   108/  183] train: loss: 0.1189948
[Epoch 45; Iter   138/  183] train: loss: 0.1021473
[Epoch 45; Iter   168/  183] train: loss: 0.1500605
[Epoch 45] ogbg-moltox21: 0.763585 val loss: 0.301701
[Epoch 45] ogbg-moltox21: 0.734887 test loss: 0.436314
[Epoch 46; Iter    15/  183] train: loss: 0.0634741
[Epoch 46; Iter    45/  183] train: loss: 0.0842682
[Epoch 46; Iter    75/  183] train: loss: 0.1364512
[Epoch 46; Iter   105/  183] train: loss: 0.1174227
[Epoch 46; Iter   135/  183] train: loss: 0.1363651
[Epoch 46; Iter   165/  183] train: loss: 0.1563276
[Epoch 46] ogbg-moltox21: 0.760404 val loss: 0.323614
[Epoch 46] ogbg-moltox21: 0.732755 test loss: 0.348354
[Epoch 47; Iter    12/  183] train: loss: 0.1225588
[Epoch 47; Iter    42/  183] train: loss: 0.1219823
[Epoch 47; Iter    72/  183] train: loss: 0.0857315
[Epoch 47; Iter   102/  183] train: loss: 0.1035671
[Epoch 47; Iter   132/  183] train: loss: 0.1601023
[Epoch 47; Iter   162/  183] train: loss: 0.1253169
[Epoch 47] ogbg-moltox21: 0.757448 val loss: 0.308871
[Epoch 47] ogbg-moltox21: 0.731113 test loss: 0.337298
[Epoch 48; Iter     9/  183] train: loss: 0.1510666
[Epoch 48; Iter    39/  183] train: loss: 0.1243027
[Epoch 48; Iter    69/  183] train: loss: 0.1009112
[Epoch 48; Iter    99/  183] train: loss: 0.1058194
[Epoch 48; Iter   129/  183] train: loss: 0.2429776
[Epoch 48; Iter   159/  183] train: loss: 0.1537124
[Epoch 48] ogbg-moltox21: 0.755060 val loss: 0.301046
[Epoch 48] ogbg-moltox21: 0.726227 test loss: 0.333632
[Epoch 49; Iter     6/  183] train: loss: 0.1081841
[Epoch 49; Iter    36/  183] train: loss: 0.1210959
[Epoch 49; Iter    66/  183] train: loss: 0.1075027
[Epoch 49; Iter    96/  183] train: loss: 0.0921056
[Epoch 49; Iter   126/  183] train: loss: 0.1118585
[Epoch 49; Iter   156/  183] train: loss: 0.1625788
[Epoch 49] ogbg-moltox21: 0.754225 val loss: 0.298785
[Epoch 49] ogbg-moltox21: 0.721446 test loss: 0.937272
[Epoch 50; Iter     3/  183] train: loss: 0.1074426
[Epoch 50; Iter    33/  183] train: loss: 0.1282690
[Epoch 50; Iter    63/  183] train: loss: 0.0952663
[Epoch 50; Iter    93/  183] train: loss: 0.0464080
[Epoch 50; Iter   123/  183] train: loss: 0.1025864
[Epoch 50; Iter   153/  183] train: loss: 0.1469625
[Epoch 50; Iter   183/  183] train: loss: 0.1383358
[Epoch 50] ogbg-moltox21: 0.751908 val loss: 0.304398
[Epoch 50] ogbg-moltox21: 0.735066 test loss: 0.330936
[Epoch 51; Iter    30/  183] train: loss: 0.0592439
[Epoch 51; Iter    60/  183] train: loss: 0.0866918
[Epoch 51; Iter    90/  183] train: loss: 0.1462475
[Epoch 51; Iter   120/  183] train: loss: 0.1108816
[Epoch 51; Iter   150/  183] train: loss: 0.1354769
[Epoch 51; Iter   180/  183] train: loss: 0.1788285
[Epoch 51] ogbg-moltox21: 0.739726 val loss: 0.300611
[Epoch 51] ogbg-moltox21: 0.716244 test loss: 0.357256
[Epoch 52; Iter    27/  183] train: loss: 0.1286541
[Epoch 52; Iter    57/  183] train: loss: 0.1256777
[Epoch 52; Iter    87/  183] train: loss: 0.0779993
[Epoch 52; Iter   117/  183] train: loss: 0.1675871
[Epoch 37; Iter    78/  157] train: loss: 0.1125873
[Epoch 37; Iter   108/  157] train: loss: 0.2248660
[Epoch 37; Iter   138/  157] train: loss: 0.1827431
[Epoch 37] ogbg-moltox21: 0.762435 val loss: 0.328469
[Epoch 37] ogbg-moltox21: 0.734483 test loss: 0.328300
[Epoch 38; Iter    11/  157] train: loss: 0.1720316
[Epoch 38; Iter    41/  157] train: loss: 0.0932491
[Epoch 38; Iter    71/  157] train: loss: 0.1006856
[Epoch 38; Iter   101/  157] train: loss: 0.1617791
[Epoch 38; Iter   131/  157] train: loss: 0.1876727
[Epoch 38] ogbg-moltox21: 0.750966 val loss: 0.355305
[Epoch 38] ogbg-moltox21: 0.739425 test loss: 0.343756
[Epoch 39; Iter     4/  157] train: loss: 0.1783004
[Epoch 39; Iter    34/  157] train: loss: 0.1561572
[Epoch 39; Iter    64/  157] train: loss: 0.1353878
[Epoch 39; Iter    94/  157] train: loss: 0.1605431
[Epoch 39; Iter   124/  157] train: loss: 0.1410692
[Epoch 39; Iter   154/  157] train: loss: 0.1469612
[Epoch 39] ogbg-moltox21: 0.769410 val loss: 0.463821
[Epoch 39] ogbg-moltox21: 0.733468 test loss: 0.345903
[Epoch 40; Iter    27/  157] train: loss: 0.1434368
[Epoch 40; Iter    57/  157] train: loss: 0.1370449
[Epoch 40; Iter    87/  157] train: loss: 0.1935076
[Epoch 40; Iter   117/  157] train: loss: 0.1757697
[Epoch 40; Iter   147/  157] train: loss: 0.1115001
[Epoch 40] ogbg-moltox21: 0.769213 val loss: 0.356558
[Epoch 40] ogbg-moltox21: 0.733745 test loss: 0.395181
[Epoch 41; Iter    20/  157] train: loss: 0.1147877
[Epoch 41; Iter    50/  157] train: loss: 0.0762775
[Epoch 41; Iter    80/  157] train: loss: 0.0589370
[Epoch 41; Iter   110/  157] train: loss: 0.1414351
[Epoch 41; Iter   140/  157] train: loss: 0.0893299
[Epoch 41] ogbg-moltox21: 0.760381 val loss: 0.452017
[Epoch 41] ogbg-moltox21: 0.727897 test loss: 0.347005
[Epoch 42; Iter    13/  157] train: loss: 0.1324285
[Epoch 42; Iter    43/  157] train: loss: 0.1132441
[Epoch 42; Iter    73/  157] train: loss: 0.1930104
[Epoch 42; Iter   103/  157] train: loss: 0.0850347
[Epoch 42; Iter   133/  157] train: loss: 0.1232034
[Epoch 42] ogbg-moltox21: 0.764178 val loss: 0.389008
[Epoch 42] ogbg-moltox21: 0.737490 test loss: 0.335653
[Epoch 43; Iter     6/  157] train: loss: 0.0902074
[Epoch 43; Iter    36/  157] train: loss: 0.1366975
[Epoch 43; Iter    66/  157] train: loss: 0.1096573
[Epoch 43; Iter    96/  157] train: loss: 0.1052143
[Epoch 43; Iter   126/  157] train: loss: 0.1569207
[Epoch 43; Iter   156/  157] train: loss: 0.1132905
[Epoch 43] ogbg-moltox21: 0.756165 val loss: 0.376324
[Epoch 43] ogbg-moltox21: 0.731112 test loss: 0.373522
[Epoch 44; Iter    29/  157] train: loss: 0.0905090
[Epoch 44; Iter    59/  157] train: loss: 0.1010521
[Epoch 44; Iter    89/  157] train: loss: 0.1690181
[Epoch 44; Iter   119/  157] train: loss: 0.1720538
[Epoch 44; Iter   149/  157] train: loss: 0.0815521
[Epoch 44] ogbg-moltox21: 0.752771 val loss: 0.422497
[Epoch 44] ogbg-moltox21: 0.730158 test loss: 0.366235
[Epoch 45; Iter    22/  157] train: loss: 0.1112473
[Epoch 45; Iter    52/  157] train: loss: 0.0882097
[Epoch 45; Iter    82/  157] train: loss: 0.0813920
[Epoch 45; Iter   112/  157] train: loss: 0.1384575
[Epoch 45; Iter   142/  157] train: loss: 0.0846825
[Epoch 45] ogbg-moltox21: 0.760396 val loss: 0.359456
[Epoch 45] ogbg-moltox21: 0.736392 test loss: 0.358154
[Epoch 46; Iter    15/  157] train: loss: 0.1231856
[Epoch 46; Iter    45/  157] train: loss: 0.0556344
[Epoch 46; Iter    75/  157] train: loss: 0.1254564
[Epoch 46; Iter   105/  157] train: loss: 0.0907631
[Epoch 46; Iter   135/  157] train: loss: 0.1093304
[Epoch 46] ogbg-moltox21: 0.756331 val loss: 0.443019
[Epoch 46] ogbg-moltox21: 0.734303 test loss: 0.385116
[Epoch 47; Iter     8/  157] train: loss: 0.1715567
[Epoch 47; Iter    38/  157] train: loss: 0.0935460
[Epoch 47; Iter    68/  157] train: loss: 0.1270236
[Epoch 47; Iter    98/  157] train: loss: 0.0786328
[Epoch 47; Iter   128/  157] train: loss: 0.0990198
[Epoch 47] ogbg-moltox21: 0.750801 val loss: 0.409497
[Epoch 47] ogbg-moltox21: 0.726680 test loss: 0.361545
[Epoch 48; Iter     1/  157] train: loss: 0.0871006
[Epoch 48; Iter    31/  157] train: loss: 0.0861807
[Epoch 48; Iter    61/  157] train: loss: 0.1087076
[Epoch 48; Iter    91/  157] train: loss: 0.0781660
[Epoch 48; Iter   121/  157] train: loss: 0.1354801
[Epoch 48; Iter   151/  157] train: loss: 0.0731494
[Epoch 48] ogbg-moltox21: 0.759781 val loss: 0.349957
[Epoch 48] ogbg-moltox21: 0.733602 test loss: 0.375188
[Epoch 49; Iter    24/  157] train: loss: 0.0995550
[Epoch 49; Iter    54/  157] train: loss: 0.0756852
[Epoch 49; Iter    84/  157] train: loss: 0.1162702
[Epoch 49; Iter   114/  157] train: loss: 0.0934607
[Epoch 49; Iter   144/  157] train: loss: 0.0625718
[Epoch 49] ogbg-moltox21: 0.756405 val loss: 0.432674
[Epoch 49] ogbg-moltox21: 0.733958 test loss: 0.354275
[Epoch 50; Iter    17/  157] train: loss: 0.0954908
[Epoch 50; Iter    47/  157] train: loss: 0.1076498
[Epoch 50; Iter    77/  157] train: loss: 0.1216674
[Epoch 50; Iter   107/  157] train: loss: 0.0969662
[Epoch 50; Iter   137/  157] train: loss: 0.1537774
[Epoch 50] ogbg-moltox21: 0.750025 val loss: 0.388383
[Epoch 50] ogbg-moltox21: 0.724693 test loss: 0.392143
[Epoch 51; Iter    10/  157] train: loss: 0.0975016
[Epoch 51; Iter    40/  157] train: loss: 0.0814571
[Epoch 51; Iter    70/  157] train: loss: 0.0935700
[Epoch 51; Iter   100/  157] train: loss: 0.0655358
[Epoch 51; Iter   130/  157] train: loss: 0.1517541
[Epoch 51] ogbg-moltox21: 0.750332 val loss: 0.371004
[Epoch 51] ogbg-moltox21: 0.723122 test loss: 0.388468
[Epoch 52; Iter     3/  157] train: loss: 0.1011389
[Epoch 52; Iter    33/  157] train: loss: 0.0793197
[Epoch 52; Iter    63/  157] train: loss: 0.0944343
[Epoch 52; Iter    93/  157] train: loss: 0.1320477
[Epoch 52; Iter   123/  157] train: loss: 0.1574545
[Epoch 52; Iter   153/  157] train: loss: 0.1187377
[Epoch 52] ogbg-moltox21: 0.749539 val loss: 0.409531
[Epoch 52] ogbg-moltox21: 0.720896 test loss: 0.363768
[Epoch 53; Iter    26/  157] train: loss: 0.2540980
[Epoch 53; Iter    56/  157] train: loss: 0.0606863
[Epoch 53; Iter    86/  157] train: loss: 0.1105184
[Epoch 53; Iter   116/  157] train: loss: 0.1262923
[Epoch 53; Iter   146/  157] train: loss: 0.0848610
[Epoch 53] ogbg-moltox21: 0.742352 val loss: 0.375368
[Epoch 53] ogbg-moltox21: 0.732353 test loss: 0.394450
[Epoch 54; Iter    19/  157] train: loss: 0.0931421
[Epoch 54; Iter    49/  157] train: loss: 0.1246327
[Epoch 54; Iter    79/  157] train: loss: 0.1324821
[Epoch 54; Iter   109/  157] train: loss: 0.1132816
[Epoch 54; Iter   139/  157] train: loss: 0.1003989
[Epoch 54] ogbg-moltox21: 0.746097 val loss: 0.478409
[Epoch 54] ogbg-moltox21: 0.726350 test loss: 0.376865
[Epoch 55; Iter    12/  157] train: loss: 0.1133430
[Epoch 55; Iter    42/  157] train: loss: 0.1475219
[Epoch 55; Iter    72/  157] train: loss: 0.0813947
[Epoch 55; Iter   102/  157] train: loss: 0.1268547
[Epoch 55; Iter   132/  157] train: loss: 0.0893010
[Epoch 55] ogbg-moltox21: 0.747698 val loss: 0.356833
[Epoch 55] ogbg-moltox21: 0.729908 test loss: 0.378666
[Epoch 56; Iter     5/  157] train: loss: 0.0683996
[Epoch 56; Iter    35/  157] train: loss: 0.1056599
[Epoch 56; Iter    65/  157] train: loss: 0.0959600
[Epoch 56; Iter    95/  157] train: loss: 0.0528730
[Epoch 56; Iter   125/  157] train: loss: 0.0682337
[Epoch 56; Iter   155/  157] train: loss: 0.1184076
[Epoch 56] ogbg-moltox21: 0.746130 val loss: 0.362748
[Epoch 56] ogbg-moltox21: 0.726196 test loss: 0.380805
[Epoch 57; Iter    28/  157] train: loss: 0.0812694
[Epoch 57; Iter    58/  157] train: loss: 0.1324275
[Epoch 57; Iter    88/  157] train: loss: 0.0745837
[Epoch 57; Iter   118/  157] train: loss: 0.1296197
[Epoch 57; Iter   148/  157] train: loss: 0.0806379
[Epoch 57] ogbg-moltox21: 0.742199 val loss: 0.376240
[Epoch 57] ogbg-moltox21: 0.725858 test loss: 0.396641
[Epoch 58; Iter    21/  157] train: loss: 0.1401902
[Epoch 58; Iter    51/  157] train: loss: 0.1033378
[Epoch 58; Iter    81/  157] train: loss: 0.0660457
[Epoch 58; Iter   111/  157] train: loss: 0.0534577
[Epoch 58; Iter   141/  157] train: loss: 0.0897879
[Epoch 37; Iter    78/  157] train: loss: 0.1731845
[Epoch 37; Iter   108/  157] train: loss: 0.1026224
[Epoch 37; Iter   138/  157] train: loss: 0.1255375
[Epoch 37] ogbg-moltox21: 0.757736 val loss: 0.292531
[Epoch 37] ogbg-moltox21: 0.730755 test loss: 0.316133
[Epoch 38; Iter    11/  157] train: loss: 0.0948938
[Epoch 38; Iter    41/  157] train: loss: 0.1609939
[Epoch 38; Iter    71/  157] train: loss: 0.0783061
[Epoch 38; Iter   101/  157] train: loss: 0.1313732
[Epoch 38; Iter   131/  157] train: loss: 0.2369621
[Epoch 38] ogbg-moltox21: 0.685952 val loss: 0.402961
[Epoch 38] ogbg-moltox21: 0.694168 test loss: 0.417211
[Epoch 39; Iter     4/  157] train: loss: 0.1734789
[Epoch 39; Iter    34/  157] train: loss: 0.1918625
[Epoch 39; Iter    64/  157] train: loss: 0.1779957
[Epoch 39; Iter    94/  157] train: loss: 0.1656194
[Epoch 39; Iter   124/  157] train: loss: 0.1536112
[Epoch 39; Iter   154/  157] train: loss: 0.1396908
[Epoch 39] ogbg-moltox21: 0.761360 val loss: 0.326872
[Epoch 39] ogbg-moltox21: 0.743422 test loss: 0.375345
[Epoch 40; Iter    27/  157] train: loss: 0.1234638
[Epoch 40; Iter    57/  157] train: loss: 0.1350604
[Epoch 40; Iter    87/  157] train: loss: 0.1234339
[Epoch 40; Iter   117/  157] train: loss: 0.2614468
[Epoch 40; Iter   147/  157] train: loss: 0.0908182
[Epoch 40] ogbg-moltox21: 0.765435 val loss: 0.317463
[Epoch 40] ogbg-moltox21: 0.749225 test loss: 0.375524
[Epoch 41; Iter    20/  157] train: loss: 0.2358552
[Epoch 41; Iter    50/  157] train: loss: 0.1326594
[Epoch 41; Iter    80/  157] train: loss: 0.1585843
[Epoch 41; Iter   110/  157] train: loss: 0.2187524
[Epoch 41; Iter   140/  157] train: loss: 0.0960858
[Epoch 41] ogbg-moltox21: 0.772379 val loss: 0.306984
[Epoch 41] ogbg-moltox21: 0.752815 test loss: 0.381828
[Epoch 42; Iter    13/  157] train: loss: 0.1369391
[Epoch 42; Iter    43/  157] train: loss: 0.1067844
[Epoch 42; Iter    73/  157] train: loss: 0.1126916
[Epoch 42; Iter   103/  157] train: loss: 0.1749834
[Epoch 42; Iter   133/  157] train: loss: 0.0875724
[Epoch 42] ogbg-moltox21: 0.770422 val loss: 0.343912
[Epoch 42] ogbg-moltox21: 0.758231 test loss: 0.633194
[Epoch 43; Iter     6/  157] train: loss: 0.1405242
[Epoch 43; Iter    36/  157] train: loss: 0.1185886
[Epoch 43; Iter    66/  157] train: loss: 0.1366789
[Epoch 43; Iter    96/  157] train: loss: 0.1404409
[Epoch 43; Iter   126/  157] train: loss: 0.1046940
[Epoch 43; Iter   156/  157] train: loss: 0.1406987
[Epoch 43] ogbg-moltox21: 0.765391 val loss: 0.304923
[Epoch 43] ogbg-moltox21: 0.753722 test loss: 0.322199
[Epoch 44; Iter    29/  157] train: loss: 0.1487644
[Epoch 44; Iter    59/  157] train: loss: 0.1671753
[Epoch 44; Iter    89/  157] train: loss: 0.1204040
[Epoch 44; Iter   119/  157] train: loss: 0.1112197
[Epoch 44; Iter   149/  157] train: loss: 0.1210965
[Epoch 44] ogbg-moltox21: 0.763845 val loss: 0.310160
[Epoch 44] ogbg-moltox21: 0.743753 test loss: 0.348244
[Epoch 45; Iter    22/  157] train: loss: 0.1173738
[Epoch 45; Iter    52/  157] train: loss: 0.1595661
[Epoch 45; Iter    82/  157] train: loss: 0.2606257
[Epoch 45; Iter   112/  157] train: loss: 0.1747278
[Epoch 45; Iter   142/  157] train: loss: 0.1709249
[Epoch 45] ogbg-moltox21: 0.768766 val loss: 0.371115
[Epoch 45] ogbg-moltox21: 0.740464 test loss: 0.424686
[Epoch 46; Iter    15/  157] train: loss: 0.1609034
[Epoch 46; Iter    45/  157] train: loss: 0.1583158
[Epoch 46; Iter    75/  157] train: loss: 0.1101816
[Epoch 46; Iter   105/  157] train: loss: 0.1239871
[Epoch 46; Iter   135/  157] train: loss: 0.1485809
[Epoch 46] ogbg-moltox21: 0.778035 val loss: 0.297741
[Epoch 46] ogbg-moltox21: 0.747506 test loss: 0.335338
[Epoch 47; Iter     8/  157] train: loss: 0.1536410
[Epoch 47; Iter    38/  157] train: loss: 0.1089925
[Epoch 47; Iter    68/  157] train: loss: 0.1085926
[Epoch 47; Iter    98/  157] train: loss: 0.1271195
[Epoch 47; Iter   128/  157] train: loss: 0.1586615
[Epoch 47] ogbg-moltox21: 0.765530 val loss: 0.321048
[Epoch 47] ogbg-moltox21: 0.746865 test loss: 0.342586
[Epoch 48; Iter     1/  157] train: loss: 0.1513108
[Epoch 48; Iter    31/  157] train: loss: 0.1735498
[Epoch 48; Iter    61/  157] train: loss: 0.2204389
[Epoch 48; Iter    91/  157] train: loss: 0.0915273
[Epoch 48; Iter   121/  157] train: loss: 0.1849521
[Epoch 48; Iter   151/  157] train: loss: 0.1516744
[Epoch 48] ogbg-moltox21: 0.775634 val loss: 0.309748
[Epoch 48] ogbg-moltox21: 0.749116 test loss: 0.353503
[Epoch 49; Iter    24/  157] train: loss: 0.0875245
[Epoch 49; Iter    54/  157] train: loss: 0.1497765
[Epoch 49; Iter    84/  157] train: loss: 0.1228926
[Epoch 49; Iter   114/  157] train: loss: 0.0973231
[Epoch 49; Iter   144/  157] train: loss: 0.1261694
[Epoch 49] ogbg-moltox21: 0.769502 val loss: 0.305362
[Epoch 49] ogbg-moltox21: 0.740654 test loss: 0.343431
[Epoch 50; Iter    17/  157] train: loss: 0.0572872
[Epoch 50; Iter    47/  157] train: loss: 0.1407589
[Epoch 50; Iter    77/  157] train: loss: 0.1231746
[Epoch 50; Iter   107/  157] train: loss: 0.1409170
[Epoch 50; Iter   137/  157] train: loss: 0.1413852
[Epoch 50] ogbg-moltox21: 0.749963 val loss: 0.381061
[Epoch 50] ogbg-moltox21: 0.735351 test loss: 0.392231
[Epoch 51; Iter    10/  157] train: loss: 0.1478657
[Epoch 51; Iter    40/  157] train: loss: 0.1031404
[Epoch 51; Iter    70/  157] train: loss: 0.1082569
[Epoch 51; Iter   100/  157] train: loss: 0.0775274
[Epoch 51; Iter   130/  157] train: loss: 0.2631372
[Epoch 51] ogbg-moltox21: 0.764981 val loss: 0.354358
[Epoch 51] ogbg-moltox21: 0.748570 test loss: 0.345050
[Epoch 52; Iter     3/  157] train: loss: 0.1271691
[Epoch 52; Iter    33/  157] train: loss: 0.0968934
[Epoch 52; Iter    63/  157] train: loss: 0.1567531
[Epoch 52; Iter    93/  157] train: loss: 0.1173910
[Epoch 52; Iter   123/  157] train: loss: 0.1729907
[Epoch 52; Iter   153/  157] train: loss: 0.1439987
[Epoch 52] ogbg-moltox21: 0.770480 val loss: 0.321283
[Epoch 52] ogbg-moltox21: 0.739084 test loss: 0.353470
[Epoch 53; Iter    26/  157] train: loss: 0.1157078
[Epoch 53; Iter    56/  157] train: loss: 0.1280022
[Epoch 53; Iter    86/  157] train: loss: 0.1069039
[Epoch 53; Iter   116/  157] train: loss: 0.1227091
[Epoch 53; Iter   146/  157] train: loss: 0.1245962
[Epoch 53] ogbg-moltox21: 0.774541 val loss: 0.525928
[Epoch 53] ogbg-moltox21: 0.750764 test loss: 0.452748
[Epoch 54; Iter    19/  157] train: loss: 0.1642375
[Epoch 54; Iter    49/  157] train: loss: 0.0774819
[Epoch 54; Iter    79/  157] train: loss: 0.1643252
[Epoch 54; Iter   109/  157] train: loss: 0.1442761
[Epoch 54; Iter   139/  157] train: loss: 0.1032043
[Epoch 54] ogbg-moltox21: 0.766346 val loss: 0.296331
[Epoch 54] ogbg-moltox21: 0.743606 test loss: 0.320678
[Epoch 55; Iter    12/  157] train: loss: 0.1482609
[Epoch 55; Iter    42/  157] train: loss: 0.1314972
[Epoch 55; Iter    72/  157] train: loss: 0.0885053
[Epoch 55; Iter   102/  157] train: loss: 0.0631998
[Epoch 55; Iter   132/  157] train: loss: 0.1297013
[Epoch 55] ogbg-moltox21: 0.762843 val loss: 0.331342
[Epoch 55] ogbg-moltox21: 0.739013 test loss: 0.358268
[Epoch 56; Iter     5/  157] train: loss: 0.0652363
[Epoch 56; Iter    35/  157] train: loss: 0.1180898
[Epoch 56; Iter    65/  157] train: loss: 0.0724671
[Epoch 56; Iter    95/  157] train: loss: 0.0998307
[Epoch 56; Iter   125/  157] train: loss: 0.1602267
[Epoch 56; Iter   155/  157] train: loss: 0.1507311
[Epoch 56] ogbg-moltox21: 0.760466 val loss: 0.422888
[Epoch 56] ogbg-moltox21: 0.739633 test loss: 0.325010
[Epoch 57; Iter    28/  157] train: loss: 0.1014504
[Epoch 57; Iter    58/  157] train: loss: 0.1124582
[Epoch 57; Iter    88/  157] train: loss: 0.0909601
[Epoch 57; Iter   118/  157] train: loss: 0.1184045
[Epoch 57; Iter   148/  157] train: loss: 0.1370336
[Epoch 57] ogbg-moltox21: 0.769452 val loss: 0.390451
[Epoch 57] ogbg-moltox21: 0.735180 test loss: 0.334460
[Epoch 58; Iter    21/  157] train: loss: 0.0951295
[Epoch 58; Iter    51/  157] train: loss: 0.1137507
[Epoch 58; Iter    81/  157] train: loss: 0.0725656
[Epoch 58; Iter   111/  157] train: loss: 0.0671750
[Epoch 58; Iter   141/  157] train: loss: 0.0814909
[Epoch 37; Iter    78/  157] train: loss: 0.1001002
[Epoch 37; Iter   108/  157] train: loss: 0.1523823
[Epoch 37; Iter   138/  157] train: loss: 0.0542333
[Epoch 37] ogbg-moltox21: 0.765119 val loss: 0.334115
[Epoch 37] ogbg-moltox21: 0.741160 test loss: 0.349648
[Epoch 38; Iter    11/  157] train: loss: 0.1922886
[Epoch 38; Iter    41/  157] train: loss: 0.1019571
[Epoch 38; Iter    71/  157] train: loss: 0.1427136
[Epoch 38; Iter   101/  157] train: loss: 0.1526192
[Epoch 38; Iter   131/  157] train: loss: 0.1573737
[Epoch 38] ogbg-moltox21: 0.772905 val loss: 0.347368
[Epoch 38] ogbg-moltox21: 0.742280 test loss: 0.355388
[Epoch 39; Iter     4/  157] train: loss: 0.1397556
[Epoch 39; Iter    34/  157] train: loss: 0.0834431
[Epoch 39; Iter    64/  157] train: loss: 0.1027318
[Epoch 39; Iter    94/  157] train: loss: 0.1542893
[Epoch 39; Iter   124/  157] train: loss: 0.1066927
[Epoch 39; Iter   154/  157] train: loss: 0.0988011
[Epoch 39] ogbg-moltox21: 0.765064 val loss: 0.360988
[Epoch 39] ogbg-moltox21: 0.749066 test loss: 0.374639
[Epoch 40; Iter    27/  157] train: loss: 0.1196893
[Epoch 40; Iter    57/  157] train: loss: 0.1195172
[Epoch 40; Iter    87/  157] train: loss: 0.0891775
[Epoch 40; Iter   117/  157] train: loss: 0.1120635
[Epoch 40; Iter   147/  157] train: loss: 0.0848400
[Epoch 40] ogbg-moltox21: 0.759893 val loss: 0.357891
[Epoch 40] ogbg-moltox21: 0.749715 test loss: 0.423964
[Epoch 41; Iter    20/  157] train: loss: 0.0883459
[Epoch 41; Iter    50/  157] train: loss: 0.0846839
[Epoch 41; Iter    80/  157] train: loss: 0.1234163
[Epoch 41; Iter   110/  157] train: loss: 0.1508057
[Epoch 41; Iter   140/  157] train: loss: 0.1972595
[Epoch 41] ogbg-moltox21: 0.775387 val loss: 0.344800
[Epoch 41] ogbg-moltox21: 0.746912 test loss: 0.399770
[Epoch 42; Iter    13/  157] train: loss: 0.0702676
[Epoch 42; Iter    43/  157] train: loss: 0.1057629
[Epoch 42; Iter    73/  157] train: loss: 0.0866966
[Epoch 42; Iter   103/  157] train: loss: 0.0931449
[Epoch 42; Iter   133/  157] train: loss: 0.0792298
[Epoch 42] ogbg-moltox21: 0.755174 val loss: 0.354258
[Epoch 42] ogbg-moltox21: 0.738753 test loss: 0.382467
[Epoch 43; Iter     6/  157] train: loss: 0.1098125
[Epoch 43; Iter    36/  157] train: loss: 0.1439015
[Epoch 43; Iter    66/  157] train: loss: 0.1402912
[Epoch 43; Iter    96/  157] train: loss: 0.1888487
[Epoch 43; Iter   126/  157] train: loss: 0.1027929
[Epoch 43; Iter   156/  157] train: loss: 0.1181102
[Epoch 43] ogbg-moltox21: 0.765886 val loss: 0.352734
[Epoch 43] ogbg-moltox21: 0.738184 test loss: 0.565059
[Epoch 44; Iter    29/  157] train: loss: 0.1028001
[Epoch 44; Iter    59/  157] train: loss: 0.1544227
[Epoch 44; Iter    89/  157] train: loss: 0.1057556
[Epoch 44; Iter   119/  157] train: loss: 0.1400359
[Epoch 44; Iter   149/  157] train: loss: 0.0881690
[Epoch 44] ogbg-moltox21: 0.759253 val loss: 0.318705
[Epoch 44] ogbg-moltox21: 0.747946 test loss: 0.336858
[Epoch 45; Iter    22/  157] train: loss: 0.0812036
[Epoch 45; Iter    52/  157] train: loss: 0.1010661
[Epoch 45; Iter    82/  157] train: loss: 0.1377835
[Epoch 45; Iter   112/  157] train: loss: 0.1084718
[Epoch 45; Iter   142/  157] train: loss: 0.0944744
[Epoch 45] ogbg-moltox21: 0.744215 val loss: 0.359283
[Epoch 45] ogbg-moltox21: 0.709012 test loss: 0.405702
[Epoch 46; Iter    15/  157] train: loss: 0.1134869
[Epoch 46; Iter    45/  157] train: loss: 0.1370364
[Epoch 46; Iter    75/  157] train: loss: 0.0951444
[Epoch 46; Iter   105/  157] train: loss: 0.1082913
[Epoch 46; Iter   135/  157] train: loss: 0.0869824
[Epoch 46] ogbg-moltox21: 0.771467 val loss: 0.366280
[Epoch 46] ogbg-moltox21: 0.746847 test loss: 0.540364
[Epoch 47; Iter     8/  157] train: loss: 0.1271169
[Epoch 47; Iter    38/  157] train: loss: 0.0483901
[Epoch 47; Iter    68/  157] train: loss: 0.2118188
[Epoch 47; Iter    98/  157] train: loss: 0.1029218
[Epoch 47; Iter   128/  157] train: loss: 0.0716016
[Epoch 47] ogbg-moltox21: 0.769441 val loss: 0.337719
[Epoch 47] ogbg-moltox21: 0.743252 test loss: 0.369702
[Epoch 48; Iter     1/  157] train: loss: 0.0801078
[Epoch 48; Iter    31/  157] train: loss: 0.1243810
[Epoch 48; Iter    61/  157] train: loss: 0.1107885
[Epoch 48; Iter    91/  157] train: loss: 0.1180005
[Epoch 48; Iter   121/  157] train: loss: 0.0973551
[Epoch 48; Iter   151/  157] train: loss: 0.0937829
[Epoch 48] ogbg-moltox21: 0.760810 val loss: 0.417390
[Epoch 48] ogbg-moltox21: 0.728910 test loss: 0.474106
[Epoch 49; Iter    24/  157] train: loss: 0.0926559
[Epoch 49; Iter    54/  157] train: loss: 0.1092614
[Epoch 49; Iter    84/  157] train: loss: 0.0650919
[Epoch 49; Iter   114/  157] train: loss: 0.1465719
[Epoch 49; Iter   144/  157] train: loss: 0.1050017
[Epoch 49] ogbg-moltox21: 0.750867 val loss: 0.575172
[Epoch 49] ogbg-moltox21: 0.726952 test loss: 0.519785
[Epoch 50; Iter    17/  157] train: loss: 0.0942854
[Epoch 50; Iter    47/  157] train: loss: 0.0845057
[Epoch 50; Iter    77/  157] train: loss: 0.0730771
[Epoch 50; Iter   107/  157] train: loss: 0.1174551
[Epoch 50; Iter   137/  157] train: loss: 0.1552650
[Epoch 50] ogbg-moltox21: 0.754404 val loss: 0.408425
[Epoch 50] ogbg-moltox21: 0.738843 test loss: 0.443607
[Epoch 51; Iter    10/  157] train: loss: 0.0933930
[Epoch 51; Iter    40/  157] train: loss: 0.0904978
[Epoch 51; Iter    70/  157] train: loss: 0.0983632
[Epoch 51; Iter   100/  157] train: loss: 0.1494192
[Epoch 51; Iter   130/  157] train: loss: 0.0797395
[Epoch 51] ogbg-moltox21: 0.752184 val loss: 1.893792
[Epoch 51] ogbg-moltox21: 0.726196 test loss: 1.823518
[Epoch 52; Iter     3/  157] train: loss: 0.0836311
[Epoch 52; Iter    33/  157] train: loss: 0.0741065
[Epoch 52; Iter    63/  157] train: loss: 0.0772447
[Epoch 52; Iter    93/  157] train: loss: 0.0796251
[Epoch 52; Iter   123/  157] train: loss: 0.0823048
[Epoch 52; Iter   153/  157] train: loss: 0.0824716
[Epoch 52] ogbg-moltox21: 0.765291 val loss: 0.424958
[Epoch 52] ogbg-moltox21: 0.739775 test loss: 0.523653
[Epoch 53; Iter    26/  157] train: loss: 0.1209968
[Epoch 53; Iter    56/  157] train: loss: 0.1172469
[Epoch 53; Iter    86/  157] train: loss: 0.0853299
[Epoch 53; Iter   116/  157] train: loss: 0.0962420
[Epoch 53; Iter   146/  157] train: loss: 0.1486701
[Epoch 53] ogbg-moltox21: 0.762918 val loss: 0.401453
[Epoch 53] ogbg-moltox21: 0.739525 test loss: 0.381318
[Epoch 54; Iter    19/  157] train: loss: 0.0509531
[Epoch 54; Iter    49/  157] train: loss: 0.0798738
[Epoch 54; Iter    79/  157] train: loss: 0.1189339
[Epoch 54; Iter   109/  157] train: loss: 0.0565604
[Epoch 54; Iter   139/  157] train: loss: 0.1081180
[Epoch 54] ogbg-moltox21: 0.758597 val loss: 0.581033
[Epoch 54] ogbg-moltox21: 0.743526 test loss: 0.491691
[Epoch 55; Iter    12/  157] train: loss: 0.1200821
[Epoch 55; Iter    42/  157] train: loss: 0.1212077
[Epoch 55; Iter    72/  157] train: loss: 0.0875558
[Epoch 55; Iter   102/  157] train: loss: 0.1134325
[Epoch 55; Iter   132/  157] train: loss: 0.1218586
[Epoch 55] ogbg-moltox21: 0.745708 val loss: 0.402870
[Epoch 55] ogbg-moltox21: 0.730410 test loss: 0.405947
[Epoch 56; Iter     5/  157] train: loss: 0.1160948
[Epoch 56; Iter    35/  157] train: loss: 0.0622133
[Epoch 56; Iter    65/  157] train: loss: 0.1153774
[Epoch 56; Iter    95/  157] train: loss: 0.0629244
[Epoch 56; Iter   125/  157] train: loss: 0.0943750
[Epoch 56; Iter   155/  157] train: loss: 0.0989720
[Epoch 56] ogbg-moltox21: 0.745722 val loss: 0.428422
[Epoch 56] ogbg-moltox21: 0.724809 test loss: 0.525502
[Epoch 57; Iter    28/  157] train: loss: 0.0484353
[Epoch 57; Iter    58/  157] train: loss: 0.0840946
[Epoch 57; Iter    88/  157] train: loss: 0.1037039
[Epoch 57; Iter   118/  157] train: loss: 0.0392494
[Epoch 57; Iter   148/  157] train: loss: 0.0784739
[Epoch 57] ogbg-moltox21: 0.733892 val loss: 0.486408
[Epoch 57] ogbg-moltox21: 0.716260 test loss: 0.465026
[Epoch 58; Iter    21/  157] train: loss: 0.0726663
[Epoch 58; Iter    51/  157] train: loss: 0.0481790
[Epoch 58; Iter    81/  157] train: loss: 0.1018947
[Epoch 58; Iter   111/  157] train: loss: 0.1175235
[Epoch 58; Iter   141/  157] train: loss: 0.0669853
[Epoch 47; Iter   166/  209] train: loss: 0.1243897
[Epoch 47; Iter   196/  209] train: loss: 0.0811872
[Epoch 47] ogbg-moltox21: 0.798601 val loss: 0.259009
[Epoch 47] ogbg-moltox21: 0.767482 test loss: 0.270622
[Epoch 48; Iter    17/  209] train: loss: 0.1541708
[Epoch 48; Iter    47/  209] train: loss: 0.1058247
[Epoch 48; Iter    77/  209] train: loss: 0.1319506
[Epoch 48; Iter   107/  209] train: loss: 0.1221631
[Epoch 48; Iter   137/  209] train: loss: 0.1612844
[Epoch 48; Iter   167/  209] train: loss: 0.1523402
[Epoch 48; Iter   197/  209] train: loss: 0.1138255
[Epoch 48] ogbg-moltox21: 0.798497 val loss: 0.263683
[Epoch 48] ogbg-moltox21: 0.766107 test loss: 0.286779
[Epoch 49; Iter    18/  209] train: loss: 0.1222242
[Epoch 49; Iter    48/  209] train: loss: 0.0787764
[Epoch 49; Iter    78/  209] train: loss: 0.1086031
[Epoch 49; Iter   108/  209] train: loss: 0.0967851
[Epoch 49; Iter   138/  209] train: loss: 0.1398135
[Epoch 49; Iter   168/  209] train: loss: 0.1364470
[Epoch 49; Iter   198/  209] train: loss: 0.1455736
[Epoch 49] ogbg-moltox21: 0.790942 val loss: 0.277484
[Epoch 49] ogbg-moltox21: 0.757443 test loss: 0.358676
[Epoch 50; Iter    19/  209] train: loss: 0.1707990
[Epoch 50; Iter    49/  209] train: loss: 0.0721245
[Epoch 50; Iter    79/  209] train: loss: 0.0908236
[Epoch 50; Iter   109/  209] train: loss: 0.1259214
[Epoch 50; Iter   139/  209] train: loss: 0.0968863
[Epoch 50; Iter   169/  209] train: loss: 0.0995896
[Epoch 50; Iter   199/  209] train: loss: 0.0655532
[Epoch 50] ogbg-moltox21: 0.796805 val loss: 0.262835
[Epoch 50] ogbg-moltox21: 0.767597 test loss: 0.274757
[Epoch 51; Iter    20/  209] train: loss: 0.1390812
[Epoch 51; Iter    50/  209] train: loss: 0.1037146
[Epoch 51; Iter    80/  209] train: loss: 0.0514783
[Epoch 51; Iter   110/  209] train: loss: 0.0832176
[Epoch 51; Iter   140/  209] train: loss: 0.1291745
[Epoch 51; Iter   170/  209] train: loss: 0.0948261
[Epoch 51; Iter   200/  209] train: loss: 0.1420506
[Epoch 51] ogbg-moltox21: 0.796489 val loss: 0.265225
[Epoch 51] ogbg-moltox21: 0.763942 test loss: 0.293681
[Epoch 52; Iter    21/  209] train: loss: 0.1106396
[Epoch 52; Iter    51/  209] train: loss: 0.1039524
[Epoch 52; Iter    81/  209] train: loss: 0.1295732
[Epoch 52; Iter   111/  209] train: loss: 0.1664970
[Epoch 52; Iter   141/  209] train: loss: 0.0943162
[Epoch 52; Iter   171/  209] train: loss: 0.0948092
[Epoch 52; Iter   201/  209] train: loss: 0.1135998
[Epoch 52] ogbg-moltox21: 0.778399 val loss: 0.270573
[Epoch 52] ogbg-moltox21: 0.758527 test loss: 0.283553
[Epoch 53; Iter    22/  209] train: loss: 0.1279944
[Epoch 53; Iter    52/  209] train: loss: 0.0938978
[Epoch 53; Iter    82/  209] train: loss: 0.1099330
[Epoch 53; Iter   112/  209] train: loss: 0.0854127
[Epoch 53; Iter   142/  209] train: loss: 0.0812265
[Epoch 53; Iter   172/  209] train: loss: 0.0979047
[Epoch 53; Iter   202/  209] train: loss: 0.1187062
[Epoch 53] ogbg-moltox21: 0.782699 val loss: 0.314621
[Epoch 53] ogbg-moltox21: 0.765229 test loss: 0.289486
[Epoch 54; Iter    23/  209] train: loss: 0.1129201
[Epoch 54; Iter    53/  209] train: loss: 0.1305842
[Epoch 54; Iter    83/  209] train: loss: 0.0798076
[Epoch 54; Iter   113/  209] train: loss: 0.1106729
[Epoch 54; Iter   143/  209] train: loss: 0.1099563
[Epoch 54; Iter   173/  209] train: loss: 0.1459756
[Epoch 54; Iter   203/  209] train: loss: 0.1228690
[Epoch 54] ogbg-moltox21: 0.786386 val loss: 0.287367
[Epoch 54] ogbg-moltox21: 0.774588 test loss: 0.286256
[Epoch 55; Iter    24/  209] train: loss: 0.0932780
[Epoch 55; Iter    54/  209] train: loss: 0.0908807
[Epoch 55; Iter    84/  209] train: loss: 0.1094837
[Epoch 55; Iter   114/  209] train: loss: 0.1276627
[Epoch 55; Iter   144/  209] train: loss: 0.1220869
[Epoch 55; Iter   174/  209] train: loss: 0.1013584
[Epoch 55; Iter   204/  209] train: loss: 0.0828454
[Epoch 55] ogbg-moltox21: 0.784456 val loss: 0.283855
[Epoch 55] ogbg-moltox21: 0.750944 test loss: 0.296469
[Epoch 56; Iter    25/  209] train: loss: 0.1258638
[Epoch 56; Iter    55/  209] train: loss: 0.1147828
[Epoch 56; Iter    85/  209] train: loss: 0.0989421
[Epoch 56; Iter   115/  209] train: loss: 0.1117755
[Epoch 56; Iter   145/  209] train: loss: 0.1502682
[Epoch 56; Iter   175/  209] train: loss: 0.1224366
[Epoch 56; Iter   205/  209] train: loss: 0.0887535
[Epoch 56] ogbg-moltox21: 0.782740 val loss: 0.295975
[Epoch 56] ogbg-moltox21: 0.770309 test loss: 0.291346
[Epoch 57; Iter    26/  209] train: loss: 0.1118730
[Epoch 57; Iter    56/  209] train: loss: 0.1284256
[Epoch 57; Iter    86/  209] train: loss: 0.1298066
[Epoch 57; Iter   116/  209] train: loss: 0.0448965
[Epoch 57; Iter   146/  209] train: loss: 0.0873142
[Epoch 57; Iter   176/  209] train: loss: 0.1404230
[Epoch 57; Iter   206/  209] train: loss: 0.1151642
[Epoch 57] ogbg-moltox21: 0.790441 val loss: 0.280875
[Epoch 57] ogbg-moltox21: 0.766083 test loss: 0.292926
[Epoch 58; Iter    27/  209] train: loss: 0.0741414
[Epoch 58; Iter    57/  209] train: loss: 0.0560715
[Epoch 58; Iter    87/  209] train: loss: 0.1157686
[Epoch 58; Iter   117/  209] train: loss: 0.0538563
[Epoch 58; Iter   147/  209] train: loss: 0.0883253
[Epoch 58; Iter   177/  209] train: loss: 0.0675106
[Epoch 58; Iter   207/  209] train: loss: 0.0969436
[Epoch 58] ogbg-moltox21: 0.785894 val loss: 0.283846
[Epoch 58] ogbg-moltox21: 0.753676 test loss: 0.304981
[Epoch 59; Iter    28/  209] train: loss: 0.1634469
[Epoch 59; Iter    58/  209] train: loss: 0.1413971
[Epoch 59; Iter    88/  209] train: loss: 0.1086905
[Epoch 59; Iter   118/  209] train: loss: 0.1033658
[Epoch 59; Iter   148/  209] train: loss: 0.1348151
[Epoch 59; Iter   178/  209] train: loss: 0.1567061
[Epoch 59; Iter   208/  209] train: loss: 0.1378403
[Epoch 59] ogbg-moltox21: 0.783742 val loss: 0.280763
[Epoch 59] ogbg-moltox21: 0.766703 test loss: 0.285868
[Epoch 60; Iter    29/  209] train: loss: 0.1072759
[Epoch 60; Iter    59/  209] train: loss: 0.0659015
[Epoch 60; Iter    89/  209] train: loss: 0.0723887
[Epoch 60; Iter   119/  209] train: loss: 0.0890527
[Epoch 60; Iter   149/  209] train: loss: 0.0850564
[Epoch 60; Iter   179/  209] train: loss: 0.0915745
[Epoch 60; Iter   209/  209] train: loss: 0.1856975
[Epoch 60] ogbg-moltox21: 0.778558 val loss: 0.292115
[Epoch 60] ogbg-moltox21: 0.762296 test loss: 0.298208
[Epoch 61; Iter    30/  209] train: loss: 0.1081515
[Epoch 61; Iter    60/  209] train: loss: 0.1025561
[Epoch 61; Iter    90/  209] train: loss: 0.0694212
[Epoch 61; Iter   120/  209] train: loss: 0.0954000
[Epoch 61; Iter   150/  209] train: loss: 0.1454753
[Epoch 61; Iter   180/  209] train: loss: 0.1151369
[Epoch 61] ogbg-moltox21: 0.784187 val loss: 0.313487
[Epoch 61] ogbg-moltox21: 0.747096 test loss: 0.323344
[Epoch 62; Iter     1/  209] train: loss: 0.0953506
[Epoch 62; Iter    31/  209] train: loss: 0.0856479
[Epoch 62; Iter    61/  209] train: loss: 0.0809186
[Epoch 62; Iter    91/  209] train: loss: 0.1372199
[Epoch 62; Iter   121/  209] train: loss: 0.0838313
[Epoch 62; Iter   151/  209] train: loss: 0.0972209
[Epoch 62; Iter   181/  209] train: loss: 0.1080956
[Epoch 62] ogbg-moltox21: 0.770526 val loss: 0.315985
[Epoch 62] ogbg-moltox21: 0.757061 test loss: 0.306095
[Epoch 63; Iter     2/  209] train: loss: 0.0976884
[Epoch 63; Iter    32/  209] train: loss: 0.2154663
[Epoch 63; Iter    62/  209] train: loss: 0.1096680
[Epoch 63; Iter    92/  209] train: loss: 0.0826681
[Epoch 63; Iter   122/  209] train: loss: 0.1189812
[Epoch 63; Iter   152/  209] train: loss: 0.1317291
[Epoch 63; Iter   182/  209] train: loss: 0.0536276
[Epoch 63] ogbg-moltox21: 0.781565 val loss: 0.315292
[Epoch 63] ogbg-moltox21: 0.754621 test loss: 0.313418
[Epoch 64; Iter     3/  209] train: loss: 0.0705342
[Epoch 64; Iter    33/  209] train: loss: 0.0810438
[Epoch 64; Iter    63/  209] train: loss: 0.0939649
[Epoch 64; Iter    93/  209] train: loss: 0.0780687
[Epoch 64; Iter   123/  209] train: loss: 0.1324997
[Epoch 64; Iter   153/  209] train: loss: 0.1459084
[Epoch 64; Iter   183/  209] train: loss: 0.1141538
[Epoch 64] ogbg-moltox21: 0.777494 val loss: 0.309766
[Epoch 47; Iter   166/  209] train: loss: 0.0669342
[Epoch 47; Iter   196/  209] train: loss: 0.1423058
[Epoch 47] ogbg-moltox21: 0.788641 val loss: 0.263679
[Epoch 47] ogbg-moltox21: 0.760830 test loss: 0.269970
[Epoch 48; Iter    17/  209] train: loss: 0.1872884
[Epoch 48; Iter    47/  209] train: loss: 0.1189507
[Epoch 48; Iter    77/  209] train: loss: 0.1547837
[Epoch 48; Iter   107/  209] train: loss: 0.1172754
[Epoch 48; Iter   137/  209] train: loss: 0.1554066
[Epoch 48; Iter   167/  209] train: loss: 0.1125740
[Epoch 48; Iter   197/  209] train: loss: 0.0983187
[Epoch 48] ogbg-moltox21: 0.795205 val loss: 0.270342
[Epoch 48] ogbg-moltox21: 0.764394 test loss: 0.279647
[Epoch 49; Iter    18/  209] train: loss: 0.1607754
[Epoch 49; Iter    48/  209] train: loss: 0.1496627
[Epoch 49; Iter    78/  209] train: loss: 0.0976699
[Epoch 49; Iter   108/  209] train: loss: 0.0740401
[Epoch 49; Iter   138/  209] train: loss: 0.1510715
[Epoch 49; Iter   168/  209] train: loss: 0.1452175
[Epoch 49; Iter   198/  209] train: loss: 0.1267440
[Epoch 49] ogbg-moltox21: 0.782114 val loss: 0.272920
[Epoch 49] ogbg-moltox21: 0.752234 test loss: 0.281790
[Epoch 50; Iter    19/  209] train: loss: 0.1128192
[Epoch 50; Iter    49/  209] train: loss: 0.0975714
[Epoch 50; Iter    79/  209] train: loss: 0.1732876
[Epoch 50; Iter   109/  209] train: loss: 0.1126382
[Epoch 50; Iter   139/  209] train: loss: 0.1163078
[Epoch 50; Iter   169/  209] train: loss: 0.1167553
[Epoch 50; Iter   199/  209] train: loss: 0.1722177
[Epoch 50] ogbg-moltox21: 0.785247 val loss: 0.272354
[Epoch 50] ogbg-moltox21: 0.759532 test loss: 0.283522
[Epoch 51; Iter    20/  209] train: loss: 0.1125665
[Epoch 51; Iter    50/  209] train: loss: 0.1008048
[Epoch 51; Iter    80/  209] train: loss: 0.0663911
[Epoch 51; Iter   110/  209] train: loss: 0.1206909
[Epoch 51; Iter   140/  209] train: loss: 0.1495709
[Epoch 51; Iter   170/  209] train: loss: 0.1237248
[Epoch 51; Iter   200/  209] train: loss: 0.0691361
[Epoch 51] ogbg-moltox21: 0.780444 val loss: 0.283641
[Epoch 51] ogbg-moltox21: 0.758489 test loss: 0.286509
[Epoch 52; Iter    21/  209] train: loss: 0.1570411
[Epoch 52; Iter    51/  209] train: loss: 0.0910038
[Epoch 52; Iter    81/  209] train: loss: 0.0827658
[Epoch 52; Iter   111/  209] train: loss: 0.1224343
[Epoch 52; Iter   141/  209] train: loss: 0.0930298
[Epoch 52; Iter   171/  209] train: loss: 0.1165056
[Epoch 52; Iter   201/  209] train: loss: 0.1787560
[Epoch 52] ogbg-moltox21: 0.780533 val loss: 0.291082
[Epoch 52] ogbg-moltox21: 0.761528 test loss: 0.297544
[Epoch 53; Iter    22/  209] train: loss: 0.0777380
[Epoch 53; Iter    52/  209] train: loss: 0.0856261
[Epoch 53; Iter    82/  209] train: loss: 0.1376890
[Epoch 53; Iter   112/  209] train: loss: 0.0813062
[Epoch 53; Iter   142/  209] train: loss: 0.0978242
[Epoch 53; Iter   172/  209] train: loss: 0.0977083
[Epoch 53; Iter   202/  209] train: loss: 0.1635687
[Epoch 53] ogbg-moltox21: 0.786922 val loss: 0.285294
[Epoch 53] ogbg-moltox21: 0.756210 test loss: 0.300170
[Epoch 54; Iter    23/  209] train: loss: 0.0860860
[Epoch 54; Iter    53/  209] train: loss: 0.0835316
[Epoch 54; Iter    83/  209] train: loss: 0.1050912
[Epoch 54; Iter   113/  209] train: loss: 0.1262030
[Epoch 54; Iter   143/  209] train: loss: 0.1534496
[Epoch 54; Iter   173/  209] train: loss: 0.1351745
[Epoch 54; Iter   203/  209] train: loss: 0.1018429
[Epoch 54] ogbg-moltox21: 0.791277 val loss: 0.284091
[Epoch 54] ogbg-moltox21: 0.744725 test loss: 0.293429
[Epoch 55; Iter    24/  209] train: loss: 0.0776473
[Epoch 55; Iter    54/  209] train: loss: 0.0693870
[Epoch 55; Iter    84/  209] train: loss: 0.0805297
[Epoch 55; Iter   114/  209] train: loss: 0.1053866
[Epoch 55; Iter   144/  209] train: loss: 0.0808597
[Epoch 55; Iter   174/  209] train: loss: 0.0940494
[Epoch 55; Iter   204/  209] train: loss: 0.0538796
[Epoch 55] ogbg-moltox21: 0.784705 val loss: 0.282270
[Epoch 55] ogbg-moltox21: 0.752079 test loss: 0.293109
[Epoch 56; Iter    25/  209] train: loss: 0.1312398
[Epoch 56; Iter    55/  209] train: loss: 0.0997563
[Epoch 56; Iter    85/  209] train: loss: 0.1118589
[Epoch 56; Iter   115/  209] train: loss: 0.0702927
[Epoch 56; Iter   145/  209] train: loss: 0.0635599
[Epoch 56; Iter   175/  209] train: loss: 0.1030335
[Epoch 56; Iter   205/  209] train: loss: 0.1074363
[Epoch 56] ogbg-moltox21: 0.779034 val loss: 0.299615
[Epoch 56] ogbg-moltox21: 0.752689 test loss: 0.304123
[Epoch 57; Iter    26/  209] train: loss: 0.0989144
[Epoch 57; Iter    56/  209] train: loss: 0.1194649
[Epoch 57; Iter    86/  209] train: loss: 0.1273465
[Epoch 57; Iter   116/  209] train: loss: 0.0865943
[Epoch 57; Iter   146/  209] train: loss: 0.1285059
[Epoch 57; Iter   176/  209] train: loss: 0.1014031
[Epoch 57; Iter   206/  209] train: loss: 0.1164769
[Epoch 57] ogbg-moltox21: 0.774575 val loss: 0.345024
[Epoch 57] ogbg-moltox21: 0.741912 test loss: 0.305659
[Epoch 58; Iter    27/  209] train: loss: 0.0857391
[Epoch 58; Iter    57/  209] train: loss: 0.0594820
[Epoch 58; Iter    87/  209] train: loss: 0.1112024
[Epoch 58; Iter   117/  209] train: loss: 0.1149326
[Epoch 58; Iter   147/  209] train: loss: 0.0921706
[Epoch 58; Iter   177/  209] train: loss: 0.0854350
[Epoch 58; Iter   207/  209] train: loss: 0.1036856
[Epoch 58] ogbg-moltox21: 0.767599 val loss: 0.315377
[Epoch 58] ogbg-moltox21: 0.756744 test loss: 0.318109
[Epoch 59; Iter    28/  209] train: loss: 0.1173682
[Epoch 59; Iter    58/  209] train: loss: 0.0653823
[Epoch 59; Iter    88/  209] train: loss: 0.1364868
[Epoch 59; Iter   118/  209] train: loss: 0.0692628
[Epoch 59; Iter   148/  209] train: loss: 0.1578849
[Epoch 59; Iter   178/  209] train: loss: 0.0966958
[Epoch 59; Iter   208/  209] train: loss: 0.0828214
[Epoch 59] ogbg-moltox21: 0.784676 val loss: 0.286304
[Epoch 59] ogbg-moltox21: 0.752932 test loss: 0.300195
[Epoch 60; Iter    29/  209] train: loss: 0.0889625
[Epoch 60; Iter    59/  209] train: loss: 0.0517478
[Epoch 60; Iter    89/  209] train: loss: 0.1014754
[Epoch 60; Iter   119/  209] train: loss: 0.1203776
[Epoch 60; Iter   149/  209] train: loss: 0.0792137
[Epoch 60; Iter   179/  209] train: loss: 0.0871789
[Epoch 60; Iter   209/  209] train: loss: 0.0878161
[Epoch 60] ogbg-moltox21: 0.779639 val loss: 0.295778
[Epoch 60] ogbg-moltox21: 0.749467 test loss: 0.316957
[Epoch 61; Iter    30/  209] train: loss: 0.0973361
[Epoch 61; Iter    60/  209] train: loss: 0.1004236
[Epoch 61; Iter    90/  209] train: loss: 0.1334098
[Epoch 61; Iter   120/  209] train: loss: 0.0844392
[Epoch 61; Iter   150/  209] train: loss: 0.1922644
[Epoch 61; Iter   180/  209] train: loss: 0.1588814
[Epoch 61] ogbg-moltox21: 0.773416 val loss: 0.294992
[Epoch 61] ogbg-moltox21: 0.739620 test loss: 0.317029
[Epoch 62; Iter     1/  209] train: loss: 0.1348692
[Epoch 62; Iter    31/  209] train: loss: 0.0682922
[Epoch 62; Iter    61/  209] train: loss: 0.0570754
[Epoch 62; Iter    91/  209] train: loss: 0.1049241
[Epoch 62; Iter   121/  209] train: loss: 0.0988072
[Epoch 62; Iter   151/  209] train: loss: 0.0546439
[Epoch 62; Iter   181/  209] train: loss: 0.0719569
[Epoch 62] ogbg-moltox21: 0.775541 val loss: 0.294813
[Epoch 62] ogbg-moltox21: 0.743776 test loss: 0.309957
[Epoch 63; Iter     2/  209] train: loss: 0.0779505
[Epoch 63; Iter    32/  209] train: loss: 0.1094166
[Epoch 63; Iter    62/  209] train: loss: 0.0875811
[Epoch 63; Iter    92/  209] train: loss: 0.0843287
[Epoch 63; Iter   122/  209] train: loss: 0.0618441
[Epoch 63; Iter   152/  209] train: loss: 0.0618399
[Epoch 63; Iter   182/  209] train: loss: 0.0851422
[Epoch 63] ogbg-moltox21: 0.786203 val loss: 0.299617
[Epoch 63] ogbg-moltox21: 0.751023 test loss: 0.316134
[Epoch 64; Iter     3/  209] train: loss: 0.1104052
[Epoch 64; Iter    33/  209] train: loss: 0.0952802
[Epoch 64; Iter    63/  209] train: loss: 0.0816713
[Epoch 64; Iter    93/  209] train: loss: 0.0791011
[Epoch 64; Iter   123/  209] train: loss: 0.1129719
[Epoch 64; Iter   153/  209] train: loss: 0.0962377
[Epoch 64; Iter   183/  209] train: loss: 0.1728267
[Epoch 64] ogbg-moltox21: 0.781756 val loss: 0.297649
[Epoch 47; Iter   166/  209] train: loss: 0.1126422
[Epoch 47; Iter   196/  209] train: loss: 0.1532067
[Epoch 47] ogbg-moltox21: 0.783104 val loss: 0.283347
[Epoch 47] ogbg-moltox21: 0.755340 test loss: 0.296488
[Epoch 48; Iter    17/  209] train: loss: 0.1412918
[Epoch 48; Iter    47/  209] train: loss: 0.1680510
[Epoch 48; Iter    77/  209] train: loss: 0.1217628
[Epoch 48; Iter   107/  209] train: loss: 0.0857228
[Epoch 48; Iter   137/  209] train: loss: 0.1777248
[Epoch 48; Iter   167/  209] train: loss: 0.1276756
[Epoch 48; Iter   197/  209] train: loss: 0.0798114
[Epoch 48] ogbg-moltox21: 0.782918 val loss: 0.348903
[Epoch 48] ogbg-moltox21: 0.758239 test loss: 0.293458
[Epoch 49; Iter    18/  209] train: loss: 0.1163987
[Epoch 49; Iter    48/  209] train: loss: 0.1043536
[Epoch 49; Iter    78/  209] train: loss: 0.1836807
[Epoch 49; Iter   108/  209] train: loss: 0.1820092
[Epoch 49; Iter   138/  209] train: loss: 0.1010529
[Epoch 49; Iter   168/  209] train: loss: 0.1183035
[Epoch 49; Iter   198/  209] train: loss: 0.1725412
[Epoch 49] ogbg-moltox21: 0.782448 val loss: 0.305412
[Epoch 49] ogbg-moltox21: 0.758099 test loss: 0.299612
[Epoch 50; Iter    19/  209] train: loss: 0.0930037
[Epoch 50; Iter    49/  209] train: loss: 0.1332659
[Epoch 50; Iter    79/  209] train: loss: 0.1101530
[Epoch 50; Iter   109/  209] train: loss: 0.1241733
[Epoch 50; Iter   139/  209] train: loss: 0.1542249
[Epoch 50; Iter   169/  209] train: loss: 0.1211063
[Epoch 50; Iter   199/  209] train: loss: 0.1385837
[Epoch 50] ogbg-moltox21: 0.788651 val loss: 0.279599
[Epoch 50] ogbg-moltox21: 0.755486 test loss: 0.287829
[Epoch 51; Iter    20/  209] train: loss: 0.1292503
[Epoch 51; Iter    50/  209] train: loss: 0.1701288
[Epoch 51; Iter    80/  209] train: loss: 0.1058183
[Epoch 51; Iter   110/  209] train: loss: 0.1405862
[Epoch 51; Iter   140/  209] train: loss: 0.1337059
[Epoch 51; Iter   170/  209] train: loss: 0.1334346
[Epoch 51; Iter   200/  209] train: loss: 0.1326044
[Epoch 51] ogbg-moltox21: 0.792268 val loss: 0.286493
[Epoch 51] ogbg-moltox21: 0.757990 test loss: 0.280406
[Epoch 52; Iter    21/  209] train: loss: 0.1040429
[Epoch 52; Iter    51/  209] train: loss: 0.1126939
[Epoch 52; Iter    81/  209] train: loss: 0.1375716
[Epoch 52; Iter   111/  209] train: loss: 0.1224193
[Epoch 52; Iter   141/  209] train: loss: 0.0877005
[Epoch 52; Iter   171/  209] train: loss: 0.1517229
[Epoch 52; Iter   201/  209] train: loss: 0.1082404
[Epoch 52] ogbg-moltox21: 0.788658 val loss: 0.289882
[Epoch 52] ogbg-moltox21: 0.749351 test loss: 0.312453
[Epoch 53; Iter    22/  209] train: loss: 0.1183146
[Epoch 53; Iter    52/  209] train: loss: 0.1601077
[Epoch 53; Iter    82/  209] train: loss: 0.0771690
[Epoch 53; Iter   112/  209] train: loss: 0.1779395
[Epoch 53; Iter   142/  209] train: loss: 0.1171665
[Epoch 53; Iter   172/  209] train: loss: 0.0814405
[Epoch 53; Iter   202/  209] train: loss: 0.1199171
[Epoch 53] ogbg-moltox21: 0.787391 val loss: 0.262150
[Epoch 53] ogbg-moltox21: 0.758977 test loss: 0.277565
[Epoch 54; Iter    23/  209] train: loss: 0.1590797
[Epoch 54; Iter    53/  209] train: loss: 0.0738350
[Epoch 54; Iter    83/  209] train: loss: 0.0851625
[Epoch 54; Iter   113/  209] train: loss: 0.0874013
[Epoch 54; Iter   143/  209] train: loss: 0.1880934
[Epoch 54; Iter   173/  209] train: loss: 0.1122243
[Epoch 54; Iter   203/  209] train: loss: 0.1671208
[Epoch 54] ogbg-moltox21: 0.798088 val loss: 0.287989
[Epoch 54] ogbg-moltox21: 0.763070 test loss: 0.312859
[Epoch 55; Iter    24/  209] train: loss: 0.1030033
[Epoch 55; Iter    54/  209] train: loss: 0.0858309
[Epoch 55; Iter    84/  209] train: loss: 0.1046812
[Epoch 55; Iter   114/  209] train: loss: 0.0724957
[Epoch 55; Iter   144/  209] train: loss: 0.1181027
[Epoch 55; Iter   174/  209] train: loss: 0.1625095
[Epoch 55; Iter   204/  209] train: loss: 0.0869107
[Epoch 55] ogbg-moltox21: 0.789886 val loss: 0.267016
[Epoch 55] ogbg-moltox21: 0.763869 test loss: 0.288510
[Epoch 56; Iter    25/  209] train: loss: 0.1643149
[Epoch 56; Iter    55/  209] train: loss: 0.1288126
[Epoch 56; Iter    85/  209] train: loss: 0.1315593
[Epoch 56; Iter   115/  209] train: loss: 0.0919407
[Epoch 56; Iter   145/  209] train: loss: 0.1012177
[Epoch 56; Iter   175/  209] train: loss: 0.0750228
[Epoch 56; Iter   205/  209] train: loss: 0.1066616
[Epoch 56] ogbg-moltox21: 0.796341 val loss: 0.267719
[Epoch 56] ogbg-moltox21: 0.761179 test loss: 0.292506
[Epoch 57; Iter    26/  209] train: loss: 0.0685624
[Epoch 57; Iter    56/  209] train: loss: 0.0941707
[Epoch 57; Iter    86/  209] train: loss: 0.1602194
[Epoch 57; Iter   116/  209] train: loss: 0.0872868
[Epoch 57; Iter   146/  209] train: loss: 0.1051802
[Epoch 57; Iter   176/  209] train: loss: 0.1043282
[Epoch 57; Iter   206/  209] train: loss: 0.1209697
[Epoch 57] ogbg-moltox21: 0.792461 val loss: 0.272446
[Epoch 57] ogbg-moltox21: 0.761543 test loss: 0.324425
[Epoch 58; Iter    27/  209] train: loss: 0.1179723
[Epoch 58; Iter    57/  209] train: loss: 0.0764171
[Epoch 58; Iter    87/  209] train: loss: 0.0831658
[Epoch 58; Iter   117/  209] train: loss: 0.0819018
[Epoch 58; Iter   147/  209] train: loss: 0.1052919
[Epoch 58; Iter   177/  209] train: loss: 0.0956414
[Epoch 58; Iter   207/  209] train: loss: 0.0870144
[Epoch 58] ogbg-moltox21: 0.786943 val loss: 0.274510
[Epoch 58] ogbg-moltox21: 0.755235 test loss: 0.298624
[Epoch 59; Iter    28/  209] train: loss: 0.0929984
[Epoch 59; Iter    58/  209] train: loss: 0.0941453
[Epoch 59; Iter    88/  209] train: loss: 0.1465131
[Epoch 59; Iter   118/  209] train: loss: 0.1475226
[Epoch 59; Iter   148/  209] train: loss: 0.1454126
[Epoch 59; Iter   178/  209] train: loss: 0.0842060
[Epoch 59; Iter   208/  209] train: loss: 0.1072739
[Epoch 59] ogbg-moltox21: 0.789923 val loss: 0.287611
[Epoch 59] ogbg-moltox21: 0.761181 test loss: 0.307779
[Epoch 60; Iter    29/  209] train: loss: 0.1565021
[Epoch 60; Iter    59/  209] train: loss: 0.1054137
[Epoch 60; Iter    89/  209] train: loss: 0.0923762
[Epoch 60; Iter   119/  209] train: loss: 0.1118852
[Epoch 60; Iter   149/  209] train: loss: 0.0990731
[Epoch 60; Iter   179/  209] train: loss: 0.1808824
[Epoch 60; Iter   209/  209] train: loss: 0.1233981
[Epoch 60] ogbg-moltox21: 0.781971 val loss: 0.290971
[Epoch 60] ogbg-moltox21: 0.762131 test loss: 0.314767
[Epoch 61; Iter    30/  209] train: loss: 0.0942582
[Epoch 61; Iter    60/  209] train: loss: 0.1119602
[Epoch 61; Iter    90/  209] train: loss: 0.1382268
[Epoch 61; Iter   120/  209] train: loss: 0.1115817
[Epoch 61; Iter   150/  209] train: loss: 0.0892753
[Epoch 61; Iter   180/  209] train: loss: 0.0879143
[Epoch 61] ogbg-moltox21: 0.785900 val loss: 0.279417
[Epoch 61] ogbg-moltox21: 0.756721 test loss: 0.302018
[Epoch 62; Iter     1/  209] train: loss: 0.0634828
[Epoch 62; Iter    31/  209] train: loss: 0.0770170
[Epoch 62; Iter    61/  209] train: loss: 0.1023501
[Epoch 62; Iter    91/  209] train: loss: 0.0896840
[Epoch 62; Iter   121/  209] train: loss: 0.1549148
[Epoch 62; Iter   151/  209] train: loss: 0.0658705
[Epoch 62; Iter   181/  209] train: loss: 0.1114300
[Epoch 62] ogbg-moltox21: 0.782575 val loss: 0.293610
[Epoch 62] ogbg-moltox21: 0.758508 test loss: 0.322352
[Epoch 63; Iter     2/  209] train: loss: 0.0998080
[Epoch 63; Iter    32/  209] train: loss: 0.1221006
[Epoch 63; Iter    62/  209] train: loss: 0.0964849
[Epoch 63; Iter    92/  209] train: loss: 0.0933932
[Epoch 63; Iter   122/  209] train: loss: 0.1008485
[Epoch 63; Iter   152/  209] train: loss: 0.0971621
[Epoch 63; Iter   182/  209] train: loss: 0.1009185
[Epoch 63] ogbg-moltox21: 0.784449 val loss: 0.304893
[Epoch 63] ogbg-moltox21: 0.755518 test loss: 0.337074
[Epoch 64; Iter     3/  209] train: loss: 0.0760167
[Epoch 64; Iter    33/  209] train: loss: 0.0894158
[Epoch 64; Iter    63/  209] train: loss: 0.1018244
[Epoch 64; Iter    93/  209] train: loss: 0.0911556
[Epoch 64; Iter   123/  209] train: loss: 0.1316850
[Epoch 64; Iter   153/  209] train: loss: 0.0880442
[Epoch 64; Iter   183/  209] train: loss: 0.1260646
[Epoch 64] ogbg-moltox21: 0.783430 val loss: 0.288796
[Epoch 52; Iter   147/  183] train: loss: 0.0695382
[Epoch 52; Iter   177/  183] train: loss: 0.0972763
[Epoch 52] ogbg-moltox21: 0.766566 val loss: 0.290602
[Epoch 52] ogbg-moltox21: 0.744026 test loss: 0.312416
[Epoch 53; Iter    24/  183] train: loss: 0.0725519
[Epoch 53; Iter    54/  183] train: loss: 0.0980017
[Epoch 53; Iter    84/  183] train: loss: 0.0788528
[Epoch 53; Iter   114/  183] train: loss: 0.1178906
[Epoch 53; Iter   144/  183] train: loss: 0.0588009
[Epoch 53; Iter   174/  183] train: loss: 0.1028979
[Epoch 53] ogbg-moltox21: 0.759705 val loss: 0.287098
[Epoch 53] ogbg-moltox21: 0.735150 test loss: 0.300965
[Epoch 54; Iter    21/  183] train: loss: 0.1091681
[Epoch 54; Iter    51/  183] train: loss: 0.1098129
[Epoch 54; Iter    81/  183] train: loss: 0.1151770
[Epoch 54; Iter   111/  183] train: loss: 0.1531083
[Epoch 54; Iter   141/  183] train: loss: 0.0713489
[Epoch 54; Iter   171/  183] train: loss: 0.1027643
[Epoch 54] ogbg-moltox21: 0.740471 val loss: 0.314714
[Epoch 54] ogbg-moltox21: 0.726636 test loss: 0.338422
[Epoch 55; Iter    18/  183] train: loss: 0.0797635
[Epoch 55; Iter    48/  183] train: loss: 0.1202901
[Epoch 55; Iter    78/  183] train: loss: 0.1430104
[Epoch 55; Iter   108/  183] train: loss: 0.1430773
[Epoch 55; Iter   138/  183] train: loss: 0.1233528
[Epoch 55; Iter   168/  183] train: loss: 0.1150008
[Epoch 55] ogbg-moltox21: 0.758947 val loss: 0.364884
[Epoch 55] ogbg-moltox21: 0.737749 test loss: 0.319063
[Epoch 56; Iter    15/  183] train: loss: 0.0749281
[Epoch 56; Iter    45/  183] train: loss: 0.0852944
[Epoch 56; Iter    75/  183] train: loss: 0.0371405
[Epoch 56; Iter   105/  183] train: loss: 0.1515632
[Epoch 56; Iter   135/  183] train: loss: 0.0755981
[Epoch 56; Iter   165/  183] train: loss: 0.0946097
[Epoch 56] ogbg-moltox21: 0.758216 val loss: 0.312223
[Epoch 56] ogbg-moltox21: 0.734490 test loss: 0.326698
[Epoch 57; Iter    12/  183] train: loss: 0.1105194
[Epoch 57; Iter    42/  183] train: loss: 0.1462969
[Epoch 57; Iter    72/  183] train: loss: 0.0872647
[Epoch 57; Iter   102/  183] train: loss: 0.0907752
[Epoch 57; Iter   132/  183] train: loss: 0.1322019
[Epoch 57; Iter   162/  183] train: loss: 0.1232329
[Epoch 57] ogbg-moltox21: 0.751333 val loss: 0.304166
[Epoch 57] ogbg-moltox21: 0.733416 test loss: 0.325703
[Epoch 58; Iter     9/  183] train: loss: 0.1140068
[Epoch 58; Iter    39/  183] train: loss: 0.1258138
[Epoch 58; Iter    69/  183] train: loss: 0.1018602
[Epoch 58; Iter    99/  183] train: loss: 0.0967777
[Epoch 58; Iter   129/  183] train: loss: 0.0887429
[Epoch 58; Iter   159/  183] train: loss: 0.1519738
[Epoch 58] ogbg-moltox21: 0.757691 val loss: 0.312065
[Epoch 58] ogbg-moltox21: 0.726730 test loss: 0.336459
[Epoch 59; Iter     6/  183] train: loss: 0.1401105
[Epoch 59; Iter    36/  183] train: loss: 0.1553665
[Epoch 59; Iter    66/  183] train: loss: 0.1231712
[Epoch 59; Iter    96/  183] train: loss: 0.0508278
[Epoch 59; Iter   126/  183] train: loss: 0.1517782
[Epoch 59; Iter   156/  183] train: loss: 0.1229806
[Epoch 59] ogbg-moltox21: 0.760272 val loss: 0.321496
[Epoch 59] ogbg-moltox21: 0.728143 test loss: 0.349391
[Epoch 60; Iter     3/  183] train: loss: 0.0594546
[Epoch 60; Iter    33/  183] train: loss: 0.1185985
[Epoch 60; Iter    63/  183] train: loss: 0.1115003
[Epoch 60; Iter    93/  183] train: loss: 0.0773826
[Epoch 60; Iter   123/  183] train: loss: 0.1187792
[Epoch 60; Iter   153/  183] train: loss: 0.1003797
[Epoch 60; Iter   183/  183] train: loss: 0.1368392
[Epoch 60] ogbg-moltox21: 0.760865 val loss: 0.319684
[Epoch 60] ogbg-moltox21: 0.729794 test loss: 0.356364
[Epoch 61; Iter    30/  183] train: loss: 0.1330994
[Epoch 61; Iter    60/  183] train: loss: 0.1214387
[Epoch 61; Iter    90/  183] train: loss: 0.0543893
[Epoch 61; Iter   120/  183] train: loss: 0.1100969
[Epoch 61; Iter   150/  183] train: loss: 0.0927393
[Epoch 61; Iter   180/  183] train: loss: 0.1026549
[Epoch 61] ogbg-moltox21: 0.759605 val loss: 0.312708
[Epoch 61] ogbg-moltox21: 0.739407 test loss: 0.333395
[Epoch 62; Iter    27/  183] train: loss: 0.0949114
[Epoch 62; Iter    57/  183] train: loss: 0.0881126
[Epoch 62; Iter    87/  183] train: loss: 0.0639632
[Epoch 62; Iter   117/  183] train: loss: 0.1091926
[Epoch 62; Iter   147/  183] train: loss: 0.1094167
[Epoch 62; Iter   177/  183] train: loss: 0.1098411
[Epoch 62] ogbg-moltox21: 0.756665 val loss: 0.315779
[Epoch 62] ogbg-moltox21: 0.730228 test loss: 0.351449
[Epoch 63; Iter    24/  183] train: loss: 0.0822406
[Epoch 63; Iter    54/  183] train: loss: 0.0776403
[Epoch 63; Iter    84/  183] train: loss: 0.1119265
[Epoch 63; Iter   114/  183] train: loss: 0.1032161
[Epoch 63; Iter   144/  183] train: loss: 0.0753083
[Epoch 63; Iter   174/  183] train: loss: 0.0903240
[Epoch 63] ogbg-moltox21: 0.750807 val loss: 0.307432
[Epoch 63] ogbg-moltox21: 0.730392 test loss: 0.331062
[Epoch 64; Iter    21/  183] train: loss: 0.1270085
[Epoch 64; Iter    51/  183] train: loss: 0.0866786
[Epoch 64; Iter    81/  183] train: loss: 0.0635089
[Epoch 64; Iter   111/  183] train: loss: 0.0621338
[Epoch 64; Iter   141/  183] train: loss: 0.1363044
[Epoch 64; Iter   171/  183] train: loss: 0.1049811
[Epoch 64] ogbg-moltox21: 0.759689 val loss: 0.318721
[Epoch 64] ogbg-moltox21: 0.733028 test loss: 0.347665
[Epoch 65; Iter    18/  183] train: loss: 0.0916650
[Epoch 65; Iter    48/  183] train: loss: 0.1071350
[Epoch 65; Iter    78/  183] train: loss: 0.0668464
[Epoch 65; Iter   108/  183] train: loss: 0.0485843
[Epoch 65; Iter   138/  183] train: loss: 0.0778002
[Epoch 65; Iter   168/  183] train: loss: 0.0660040
[Epoch 65] ogbg-moltox21: 0.754759 val loss: 0.324645
[Epoch 65] ogbg-moltox21: 0.735419 test loss: 0.350582
[Epoch 66; Iter    15/  183] train: loss: 0.0755137
[Epoch 66; Iter    45/  183] train: loss: 0.1342572
[Epoch 66; Iter    75/  183] train: loss: 0.1237551
[Epoch 66; Iter   105/  183] train: loss: 0.0631393
[Epoch 66; Iter   135/  183] train: loss: 0.0519882
[Epoch 66; Iter   165/  183] train: loss: 0.1050027
[Epoch 66] ogbg-moltox21: 0.747058 val loss: 0.320813
[Epoch 66] ogbg-moltox21: 0.725893 test loss: 0.345449
[Epoch 67; Iter    12/  183] train: loss: 0.1040981
[Epoch 67; Iter    42/  183] train: loss: 0.1293542
[Epoch 67; Iter    72/  183] train: loss: 0.0614842
[Epoch 67; Iter   102/  183] train: loss: 0.0534663
[Epoch 67; Iter   132/  183] train: loss: 0.0574032
[Epoch 67; Iter   162/  183] train: loss: 0.0680739
[Epoch 67] ogbg-moltox21: 0.753862 val loss: 0.322970
[Epoch 67] ogbg-moltox21: 0.731446 test loss: 0.350249
[Epoch 68; Iter     9/  183] train: loss: 0.1183980
[Epoch 68; Iter    39/  183] train: loss: 0.0798519
[Epoch 68; Iter    69/  183] train: loss: 0.1260103
[Epoch 68; Iter    99/  183] train: loss: 0.0742303
[Epoch 68; Iter   129/  183] train: loss: 0.0872686
[Epoch 68; Iter   159/  183] train: loss: 0.0888498
[Epoch 68] ogbg-moltox21: 0.761787 val loss: 0.323092
[Epoch 68] ogbg-moltox21: 0.739106 test loss: 0.354486
[Epoch 69; Iter     6/  183] train: loss: 0.0698420
[Epoch 69; Iter    36/  183] train: loss: 0.0740003
[Epoch 69; Iter    66/  183] train: loss: 0.0612177
[Epoch 69; Iter    96/  183] train: loss: 0.0497106
[Epoch 69; Iter   126/  183] train: loss: 0.1137159
[Epoch 69; Iter   156/  183] train: loss: 0.1001769
[Epoch 69] ogbg-moltox21: 0.753531 val loss: 0.335221
[Epoch 69] ogbg-moltox21: 0.735478 test loss: 0.358527
[Epoch 70; Iter     3/  183] train: loss: 0.0859626
[Epoch 70; Iter    33/  183] train: loss: 0.0684527
[Epoch 70; Iter    63/  183] train: loss: 0.0920316
[Epoch 70; Iter    93/  183] train: loss: 0.1206371
[Epoch 70; Iter   123/  183] train: loss: 0.0503932
[Epoch 70; Iter   153/  183] train: loss: 0.0664416
[Epoch 70; Iter   183/  183] train: loss: 0.0557212
[Epoch 70] ogbg-moltox21: 0.756777 val loss: 0.327709
[Epoch 70] ogbg-moltox21: 0.734046 test loss: 0.375218
[Epoch 71; Iter    30/  183] train: loss: 0.1538632
[Epoch 71; Iter    60/  183] train: loss: 0.0898235
[Epoch 71; Iter    90/  183] train: loss: 0.0800980
[Epoch 71; Iter   120/  183] train: loss: 0.0893190
[Epoch 71; Iter   150/  183] train: loss: 0.0739405
[Epoch 52; Iter   147/  183] train: loss: 0.0733149
[Epoch 52; Iter   177/  183] train: loss: 0.0741926
[Epoch 52] ogbg-moltox21: 0.748632 val loss: 0.324398
[Epoch 52] ogbg-moltox21: 0.731584 test loss: 0.339423
[Epoch 53; Iter    24/  183] train: loss: 0.0843356
[Epoch 53; Iter    54/  183] train: loss: 0.0717085
[Epoch 53; Iter    84/  183] train: loss: 0.0899520
[Epoch 53; Iter   114/  183] train: loss: 0.0905512
[Epoch 53; Iter   144/  183] train: loss: 0.0797748
[Epoch 53; Iter   174/  183] train: loss: 0.0943047
[Epoch 53] ogbg-moltox21: 0.750874 val loss: 0.329977
[Epoch 53] ogbg-moltox21: 0.722512 test loss: 0.349818
[Epoch 54; Iter    21/  183] train: loss: 0.0731787
[Epoch 54; Iter    51/  183] train: loss: 0.0875807
[Epoch 54; Iter    81/  183] train: loss: 0.0646165
[Epoch 54; Iter   111/  183] train: loss: 0.0762793
[Epoch 54; Iter   141/  183] train: loss: 0.1097690
[Epoch 54; Iter   171/  183] train: loss: 0.1244790
[Epoch 54] ogbg-moltox21: 0.746839 val loss: 0.335135
[Epoch 54] ogbg-moltox21: 0.729871 test loss: 0.328660
[Epoch 55; Iter    18/  183] train: loss: 0.1345020
[Epoch 55; Iter    48/  183] train: loss: 0.1011547
[Epoch 55; Iter    78/  183] train: loss: 0.1259882
[Epoch 55; Iter   108/  183] train: loss: 0.1065863
[Epoch 55; Iter   138/  183] train: loss: 0.0807032
[Epoch 55; Iter   168/  183] train: loss: 0.0552850
[Epoch 55] ogbg-moltox21: 0.752452 val loss: 0.341830
[Epoch 55] ogbg-moltox21: 0.737177 test loss: 0.347358
[Epoch 56; Iter    15/  183] train: loss: 0.1077645
[Epoch 56; Iter    45/  183] train: loss: 0.1049724
[Epoch 56; Iter    75/  183] train: loss: 0.0848256
[Epoch 56; Iter   105/  183] train: loss: 0.0796916
[Epoch 56; Iter   135/  183] train: loss: 0.0896031
[Epoch 56; Iter   165/  183] train: loss: 0.0838230
[Epoch 56] ogbg-moltox21: 0.753245 val loss: 0.329794
[Epoch 56] ogbg-moltox21: 0.727469 test loss: 0.344883
[Epoch 57; Iter    12/  183] train: loss: 0.0564889
[Epoch 57; Iter    42/  183] train: loss: 0.1017642
[Epoch 57; Iter    72/  183] train: loss: 0.0938147
[Epoch 57; Iter   102/  183] train: loss: 0.1087600
[Epoch 57; Iter   132/  183] train: loss: 0.0652278
[Epoch 57; Iter   162/  183] train: loss: 0.0600293
[Epoch 57] ogbg-moltox21: 0.750118 val loss: 0.335050
[Epoch 57] ogbg-moltox21: 0.739290 test loss: 0.350672
[Epoch 58; Iter     9/  183] train: loss: 0.0746875
[Epoch 58; Iter    39/  183] train: loss: 0.0578283
[Epoch 58; Iter    69/  183] train: loss: 0.0583094
[Epoch 58; Iter    99/  183] train: loss: 0.1072704
[Epoch 58; Iter   129/  183] train: loss: 0.0797775
[Epoch 58; Iter   159/  183] train: loss: 0.0711369
[Epoch 58] ogbg-moltox21: 0.751337 val loss: 0.329364
[Epoch 58] ogbg-moltox21: 0.738355 test loss: 0.339451
[Epoch 59; Iter     6/  183] train: loss: 0.0621702
[Epoch 59; Iter    36/  183] train: loss: 0.1050047
[Epoch 59; Iter    66/  183] train: loss: 0.0999181
[Epoch 59; Iter    96/  183] train: loss: 0.0941592
[Epoch 59; Iter   126/  183] train: loss: 0.0966416
[Epoch 59; Iter   156/  183] train: loss: 0.0979141
[Epoch 59] ogbg-moltox21: 0.741609 val loss: 0.342742
[Epoch 59] ogbg-moltox21: 0.720791 test loss: 0.355346
[Epoch 60; Iter     3/  183] train: loss: 0.0565927
[Epoch 60; Iter    33/  183] train: loss: 0.0650022
[Epoch 60; Iter    63/  183] train: loss: 0.0474775
[Epoch 60; Iter    93/  183] train: loss: 0.0698975
[Epoch 60; Iter   123/  183] train: loss: 0.0756386
[Epoch 60; Iter   153/  183] train: loss: 0.0544051
[Epoch 60; Iter   183/  183] train: loss: 0.0925038
[Epoch 60] ogbg-moltox21: 0.744955 val loss: 0.339764
[Epoch 60] ogbg-moltox21: 0.738415 test loss: 0.348026
[Epoch 61; Iter    30/  183] train: loss: 0.0779233
[Epoch 61; Iter    60/  183] train: loss: 0.0892711
[Epoch 61; Iter    90/  183] train: loss: 0.0736706
[Epoch 61; Iter   120/  183] train: loss: 0.1412525
[Epoch 61; Iter   150/  183] train: loss: 0.0376037
[Epoch 61; Iter   180/  183] train: loss: 0.0702756
[Epoch 61] ogbg-moltox21: 0.740511 val loss: 0.343587
[Epoch 61] ogbg-moltox21: 0.724166 test loss: 0.363087
[Epoch 62; Iter    27/  183] train: loss: 0.0866109
[Epoch 62; Iter    57/  183] train: loss: 0.1551781
[Epoch 62; Iter    87/  183] train: loss: 0.0692571
[Epoch 62; Iter   117/  183] train: loss: 0.0694848
[Epoch 62; Iter   147/  183] train: loss: 0.0900142
[Epoch 62; Iter   177/  183] train: loss: 0.0480303
[Epoch 62] ogbg-moltox21: 0.751634 val loss: 0.337666
[Epoch 62] ogbg-moltox21: 0.733327 test loss: 0.355607
[Epoch 63; Iter    24/  183] train: loss: 0.1020591
[Epoch 63; Iter    54/  183] train: loss: 0.0786150
[Epoch 63; Iter    84/  183] train: loss: 0.0832363
[Epoch 63; Iter   114/  183] train: loss: 0.0647202
[Epoch 63; Iter   144/  183] train: loss: 0.0684701
[Epoch 63; Iter   174/  183] train: loss: 0.0555366
[Epoch 63] ogbg-moltox21: 0.737645 val loss: 0.351418
[Epoch 63] ogbg-moltox21: 0.723529 test loss: 0.364749
[Epoch 64; Iter    21/  183] train: loss: 0.0739004
[Epoch 64; Iter    51/  183] train: loss: 0.1100185
[Epoch 64; Iter    81/  183] train: loss: 0.0592101
[Epoch 64; Iter   111/  183] train: loss: 0.0964582
[Epoch 64; Iter   141/  183] train: loss: 0.1509865
[Epoch 64; Iter   171/  183] train: loss: 0.0615303
[Epoch 64] ogbg-moltox21: 0.736300 val loss: 0.359657
[Epoch 64] ogbg-moltox21: 0.723491 test loss: 0.372120
[Epoch 65; Iter    18/  183] train: loss: 0.1139206
[Epoch 65; Iter    48/  183] train: loss: 0.0591783
[Epoch 65; Iter    78/  183] train: loss: 0.0865631
[Epoch 65; Iter   108/  183] train: loss: 0.0771579
[Epoch 65; Iter   138/  183] train: loss: 0.0335331
[Epoch 65; Iter   168/  183] train: loss: 0.0436648
[Epoch 65] ogbg-moltox21: 0.737675 val loss: 0.357891
[Epoch 65] ogbg-moltox21: 0.725699 test loss: 0.369383
[Epoch 66; Iter    15/  183] train: loss: 0.0746439
[Epoch 66; Iter    45/  183] train: loss: 0.0731663
[Epoch 66; Iter    75/  183] train: loss: 0.1197682
[Epoch 66; Iter   105/  183] train: loss: 0.0590764
[Epoch 66; Iter   135/  183] train: loss: 0.0624397
[Epoch 66; Iter   165/  183] train: loss: 0.0870204
[Epoch 66] ogbg-moltox21: 0.738922 val loss: 0.374416
[Epoch 66] ogbg-moltox21: 0.721215 test loss: 0.377681
[Epoch 67; Iter    12/  183] train: loss: 0.0811743
[Epoch 67; Iter    42/  183] train: loss: 0.0608011
[Epoch 67; Iter    72/  183] train: loss: 0.0509514
[Epoch 67; Iter   102/  183] train: loss: 0.0637091
[Epoch 67; Iter   132/  183] train: loss: 0.0841342
[Epoch 67; Iter   162/  183] train: loss: 0.0835399
[Epoch 67] ogbg-moltox21: 0.739216 val loss: 0.360814
[Epoch 67] ogbg-moltox21: 0.730167 test loss: 0.369876
[Epoch 68; Iter     9/  183] train: loss: 0.0342103
[Epoch 68; Iter    39/  183] train: loss: 0.0824865
[Epoch 68; Iter    69/  183] train: loss: 0.0551910
[Epoch 68; Iter    99/  183] train: loss: 0.0683790
[Epoch 68; Iter   129/  183] train: loss: 0.0957962
[Epoch 68; Iter   159/  183] train: loss: 0.0537372
[Epoch 68] ogbg-moltox21: 0.744540 val loss: 0.371611
[Epoch 68] ogbg-moltox21: 0.722320 test loss: 0.384903
[Epoch 69; Iter     6/  183] train: loss: 0.0424141
[Epoch 69; Iter    36/  183] train: loss: 0.0403319
[Epoch 69; Iter    66/  183] train: loss: 0.0765022
[Epoch 69; Iter    96/  183] train: loss: 0.0883334
[Epoch 69; Iter   126/  183] train: loss: 0.0998986
[Epoch 69; Iter   156/  183] train: loss: 0.0936385
[Epoch 69] ogbg-moltox21: 0.745972 val loss: 0.380405
[Epoch 69] ogbg-moltox21: 0.727217 test loss: 0.398278
[Epoch 70; Iter     3/  183] train: loss: 0.0423151
[Epoch 70; Iter    33/  183] train: loss: 0.0581861
[Epoch 70; Iter    63/  183] train: loss: 0.0442852
[Epoch 70; Iter    93/  183] train: loss: 0.0589282
[Epoch 70; Iter   123/  183] train: loss: 0.0925713
[Epoch 70; Iter   153/  183] train: loss: 0.0682498
[Epoch 70; Iter   183/  183] train: loss: 0.0913096
[Epoch 70] ogbg-moltox21: 0.743665 val loss: 0.373571
[Epoch 70] ogbg-moltox21: 0.728454 test loss: 0.387256
[Epoch 71; Iter    30/  183] train: loss: 0.0576713
[Epoch 71; Iter    60/  183] train: loss: 0.0538915
[Epoch 71; Iter    90/  183] train: loss: 0.0348457
[Epoch 71; Iter   120/  183] train: loss: 0.0463311
[Epoch 71; Iter   150/  183] train: loss: 0.0661271
[Epoch 52; Iter   147/  183] train: loss: 0.0977553
[Epoch 52; Iter   177/  183] train: loss: 0.1360929
[Epoch 52] ogbg-moltox21: 0.753327 val loss: 0.298154
[Epoch 52] ogbg-moltox21: 0.727289 test loss: 0.411751
[Epoch 53; Iter    24/  183] train: loss: 0.1362488
[Epoch 53; Iter    54/  183] train: loss: 0.1420573
[Epoch 53; Iter    84/  183] train: loss: 0.1169590
[Epoch 53; Iter   114/  183] train: loss: 0.0974015
[Epoch 53; Iter   144/  183] train: loss: 0.1427059
[Epoch 53; Iter   174/  183] train: loss: 0.0978110
[Epoch 53] ogbg-moltox21: 0.736987 val loss: 0.310060
[Epoch 53] ogbg-moltox21: 0.706388 test loss: 0.367055
[Epoch 54; Iter    21/  183] train: loss: 0.0733729
[Epoch 54; Iter    51/  183] train: loss: 0.1413544
[Epoch 54; Iter    81/  183] train: loss: 0.0881740
[Epoch 54; Iter   111/  183] train: loss: 0.1404119
[Epoch 54; Iter   141/  183] train: loss: 0.0707575
[Epoch 54; Iter   171/  183] train: loss: 0.0611806
[Epoch 54] ogbg-moltox21: 0.754223 val loss: 0.304375
[Epoch 54] ogbg-moltox21: 0.726776 test loss: 0.336208
[Epoch 55; Iter    18/  183] train: loss: 0.0971968
[Epoch 55; Iter    48/  183] train: loss: 0.1419127
[Epoch 55; Iter    78/  183] train: loss: 0.0680663
[Epoch 55; Iter   108/  183] train: loss: 0.1204998
[Epoch 55; Iter   138/  183] train: loss: 0.1471111
[Epoch 55; Iter   168/  183] train: loss: 0.1634749
[Epoch 55] ogbg-moltox21: 0.741556 val loss: 0.315610
[Epoch 55] ogbg-moltox21: 0.722586 test loss: 0.351127
[Epoch 56; Iter    15/  183] train: loss: 0.0806807
[Epoch 56; Iter    45/  183] train: loss: 0.1292395
[Epoch 56; Iter    75/  183] train: loss: 0.0484120
[Epoch 56; Iter   105/  183] train: loss: 0.0677763
[Epoch 56; Iter   135/  183] train: loss: 0.0878946
[Epoch 56; Iter   165/  183] train: loss: 0.0832656
[Epoch 56] ogbg-moltox21: 0.754702 val loss: 0.311585
[Epoch 56] ogbg-moltox21: 0.727931 test loss: 0.345876
[Epoch 57; Iter    12/  183] train: loss: 0.1302506
[Epoch 57; Iter    42/  183] train: loss: 0.0782368
[Epoch 57; Iter    72/  183] train: loss: 0.0887844
[Epoch 57; Iter   102/  183] train: loss: 0.0936780
[Epoch 57; Iter   132/  183] train: loss: 0.1316988
[Epoch 57; Iter   162/  183] train: loss: 0.1148498
[Epoch 57] ogbg-moltox21: 0.751397 val loss: 0.310609
[Epoch 57] ogbg-moltox21: 0.727444 test loss: 0.334399
[Epoch 58; Iter     9/  183] train: loss: 0.0872711
[Epoch 58; Iter    39/  183] train: loss: 0.1291502
[Epoch 58; Iter    69/  183] train: loss: 0.1011737
[Epoch 58; Iter    99/  183] train: loss: 0.0878605
[Epoch 58; Iter   129/  183] train: loss: 0.0850379
[Epoch 58; Iter   159/  183] train: loss: 0.0820439
[Epoch 58] ogbg-moltox21: 0.741049 val loss: 0.319732
[Epoch 58] ogbg-moltox21: 0.715804 test loss: 0.347562
[Epoch 59; Iter     6/  183] train: loss: 0.1030718
[Epoch 59; Iter    36/  183] train: loss: 0.1064118
[Epoch 59; Iter    66/  183] train: loss: 0.1479667
[Epoch 59; Iter    96/  183] train: loss: 0.0767942
[Epoch 59; Iter   126/  183] train: loss: 0.0688038
[Epoch 59; Iter   156/  183] train: loss: 0.0723712
[Epoch 59] ogbg-moltox21: 0.757029 val loss: 0.309078
[Epoch 59] ogbg-moltox21: 0.726290 test loss: 0.413749
[Epoch 60; Iter     3/  183] train: loss: 0.1087879
[Epoch 60; Iter    33/  183] train: loss: 0.1099514
[Epoch 60; Iter    63/  183] train: loss: 0.1128311
[Epoch 60; Iter    93/  183] train: loss: 0.1433074
[Epoch 60; Iter   123/  183] train: loss: 0.1077262
[Epoch 60; Iter   153/  183] train: loss: 0.1118368
[Epoch 60; Iter   183/  183] train: loss: 0.0896763
[Epoch 60] ogbg-moltox21: 0.755064 val loss: 0.340316
[Epoch 60] ogbg-moltox21: 0.725735 test loss: 0.554298
[Epoch 61; Iter    30/  183] train: loss: 0.0990995
[Epoch 61; Iter    60/  183] train: loss: 0.1080359
[Epoch 61; Iter    90/  183] train: loss: 0.0649418
[Epoch 61; Iter   120/  183] train: loss: 0.0617790
[Epoch 61; Iter   150/  183] train: loss: 0.1306198
[Epoch 61; Iter   180/  183] train: loss: 0.0669037
[Epoch 61] ogbg-moltox21: 0.748905 val loss: 0.313208
[Epoch 61] ogbg-moltox21: 0.721001 test loss: 0.383457
[Epoch 62; Iter    27/  183] train: loss: 0.0735477
[Epoch 62; Iter    57/  183] train: loss: 0.0660369
[Epoch 62; Iter    87/  183] train: loss: 0.0638447
[Epoch 62; Iter   117/  183] train: loss: 0.0532886
[Epoch 62; Iter   147/  183] train: loss: 0.0905107
[Epoch 62; Iter   177/  183] train: loss: 0.0968705
[Epoch 62] ogbg-moltox21: 0.754218 val loss: 0.332708
[Epoch 62] ogbg-moltox21: 0.723737 test loss: 0.408079
[Epoch 63; Iter    24/  183] train: loss: 0.0790813
[Epoch 63; Iter    54/  183] train: loss: 0.0928665
[Epoch 63; Iter    84/  183] train: loss: 0.1226026
[Epoch 63; Iter   114/  183] train: loss: 0.1385346
[Epoch 63; Iter   144/  183] train: loss: 0.0920280
[Epoch 63; Iter   174/  183] train: loss: 0.1236575
[Epoch 63] ogbg-moltox21: 0.748202 val loss: 0.331361
[Epoch 63] ogbg-moltox21: 0.724992 test loss: 0.386127
[Epoch 64; Iter    21/  183] train: loss: 0.0895140
[Epoch 64; Iter    51/  183] train: loss: 0.0690859
[Epoch 64; Iter    81/  183] train: loss: 0.1035387
[Epoch 64; Iter   111/  183] train: loss: 0.1394602
[Epoch 64; Iter   141/  183] train: loss: 0.0792085
[Epoch 64; Iter   171/  183] train: loss: 0.1532714
[Epoch 64] ogbg-moltox21: 0.747332 val loss: 0.323834
[Epoch 64] ogbg-moltox21: 0.710618 test loss: 0.379842
[Epoch 65; Iter    18/  183] train: loss: 0.0890686
[Epoch 65; Iter    48/  183] train: loss: 0.0825527
[Epoch 65; Iter    78/  183] train: loss: 0.0578753
[Epoch 65; Iter   108/  183] train: loss: 0.1028742
[Epoch 65; Iter   138/  183] train: loss: 0.0586987
[Epoch 65; Iter   168/  183] train: loss: 0.0504403
[Epoch 65] ogbg-moltox21: 0.746283 val loss: 0.337806
[Epoch 65] ogbg-moltox21: 0.716505 test loss: 0.386624
[Epoch 66; Iter    15/  183] train: loss: 0.0842053
[Epoch 66; Iter    45/  183] train: loss: 0.1210712
[Epoch 66; Iter    75/  183] train: loss: 0.0748031
[Epoch 66; Iter   105/  183] train: loss: 0.0934588
[Epoch 66; Iter   135/  183] train: loss: 0.1183370
[Epoch 66; Iter   165/  183] train: loss: 0.0890045
[Epoch 66] ogbg-moltox21: 0.751105 val loss: 0.318785
[Epoch 66] ogbg-moltox21: 0.717051 test loss: 0.414039
[Epoch 67; Iter    12/  183] train: loss: 0.0586453
[Epoch 67; Iter    42/  183] train: loss: 0.0632124
[Epoch 67; Iter    72/  183] train: loss: 0.0517504
[Epoch 67; Iter   102/  183] train: loss: 0.1146851
[Epoch 67; Iter   132/  183] train: loss: 0.0945711
[Epoch 67; Iter   162/  183] train: loss: 0.0937331
[Epoch 67] ogbg-moltox21: 0.742304 val loss: 0.324731
[Epoch 67] ogbg-moltox21: 0.709586 test loss: 0.536064
[Epoch 68; Iter     9/  183] train: loss: 0.0872673
[Epoch 68; Iter    39/  183] train: loss: 0.0682088
[Epoch 68; Iter    69/  183] train: loss: 0.1510215
[Epoch 68; Iter    99/  183] train: loss: 0.0594458
[Epoch 68; Iter   129/  183] train: loss: 0.0864626
[Epoch 68; Iter   159/  183] train: loss: 0.0740099
[Epoch 68] ogbg-moltox21: 0.745304 val loss: 0.339604
[Epoch 68] ogbg-moltox21: 0.717082 test loss: 0.444653
[Epoch 69; Iter     6/  183] train: loss: 0.0772998
[Epoch 69; Iter    36/  183] train: loss: 0.0647563
[Epoch 69; Iter    66/  183] train: loss: 0.0552303
[Epoch 69; Iter    96/  183] train: loss: 0.0688094
[Epoch 69; Iter   126/  183] train: loss: 0.0623804
[Epoch 69; Iter   156/  183] train: loss: 0.0904344
[Epoch 69] ogbg-moltox21: 0.743438 val loss: 0.347788
[Epoch 69] ogbg-moltox21: 0.717480 test loss: 0.418588
[Epoch 70; Iter     3/  183] train: loss: 0.0710085
[Epoch 70; Iter    33/  183] train: loss: 0.0810888
[Epoch 70; Iter    63/  183] train: loss: 0.1081576
[Epoch 70; Iter    93/  183] train: loss: 0.0503991
[Epoch 70; Iter   123/  183] train: loss: 0.1033332
[Epoch 70; Iter   153/  183] train: loss: 0.0852858
[Epoch 70; Iter   183/  183] train: loss: 0.1268699
[Epoch 70] ogbg-moltox21: 0.751624 val loss: 0.335569
[Epoch 70] ogbg-moltox21: 0.717312 test loss: 0.372208
[Epoch 71; Iter    30/  183] train: loss: 0.1476367
[Epoch 71; Iter    60/  183] train: loss: 0.1035679
[Epoch 71; Iter    90/  183] train: loss: 0.0672837
[Epoch 71; Iter   120/  183] train: loss: 0.0905865
[Epoch 71; Iter   150/  183] train: loss: 0.0637064
[Epoch 58] ogbg-moltox21: 0.741124 val loss: 0.385704
[Epoch 58] ogbg-moltox21: 0.713504 test loss: 0.404237
[Epoch 59; Iter    14/  157] train: loss: 0.0748610
[Epoch 59; Iter    44/  157] train: loss: 0.1476223
[Epoch 59; Iter    74/  157] train: loss: 0.1449664
[Epoch 59; Iter   104/  157] train: loss: 0.0959630
[Epoch 59; Iter   134/  157] train: loss: 0.0936790
[Epoch 59] ogbg-moltox21: 0.746196 val loss: 0.370801
[Epoch 59] ogbg-moltox21: 0.716682 test loss: 0.403198
[Epoch 60; Iter     7/  157] train: loss: 0.1038093
[Epoch 60; Iter    37/  157] train: loss: 0.0934325
[Epoch 60; Iter    67/  157] train: loss: 0.1043307
[Epoch 60; Iter    97/  157] train: loss: 0.0975428
[Epoch 60; Iter   127/  157] train: loss: 0.0706996
[Epoch 60; Iter   157/  157] train: loss: 0.1131173
[Epoch 60] ogbg-moltox21: 0.739599 val loss: 0.457102
[Epoch 60] ogbg-moltox21: 0.718400 test loss: 0.416097
[Epoch 61; Iter    30/  157] train: loss: 0.0805168
[Epoch 61; Iter    60/  157] train: loss: 0.0925221
[Epoch 61; Iter    90/  157] train: loss: 0.0503676
[Epoch 61; Iter   120/  157] train: loss: 0.1184190
[Epoch 61; Iter   150/  157] train: loss: 0.0778140
[Epoch 61] ogbg-moltox21: 0.735255 val loss: 0.440552
[Epoch 61] ogbg-moltox21: 0.720144 test loss: 0.444822
[Epoch 62; Iter    23/  157] train: loss: 0.1440272
[Epoch 62; Iter    53/  157] train: loss: 0.0442472
[Epoch 62; Iter    83/  157] train: loss: 0.1229210
[Epoch 62; Iter   113/  157] train: loss: 0.0700245
[Epoch 62; Iter   143/  157] train: loss: 0.0546237
[Epoch 62] ogbg-moltox21: 0.736562 val loss: 0.432142
[Epoch 62] ogbg-moltox21: 0.725178 test loss: 0.408457
[Epoch 63; Iter    16/  157] train: loss: 0.0877360
[Epoch 63; Iter    46/  157] train: loss: 0.0818064
[Epoch 63; Iter    76/  157] train: loss: 0.0599215
[Epoch 63; Iter   106/  157] train: loss: 0.0489860
[Epoch 63; Iter   136/  157] train: loss: 0.0863247
[Epoch 63] ogbg-moltox21: 0.732322 val loss: 0.454027
[Epoch 63] ogbg-moltox21: 0.706464 test loss: 0.412196
[Epoch 64; Iter     9/  157] train: loss: 0.0711395
[Epoch 64; Iter    39/  157] train: loss: 0.0513389
[Epoch 64; Iter    69/  157] train: loss: 0.1697669
[Epoch 64; Iter    99/  157] train: loss: 0.1243233
[Epoch 64; Iter   129/  157] train: loss: 0.0396626
[Epoch 64] ogbg-moltox21: 0.732873 val loss: 0.447075
[Epoch 64] ogbg-moltox21: 0.724679 test loss: 0.457348
[Epoch 65; Iter     2/  157] train: loss: 0.0821605
[Epoch 65; Iter    32/  157] train: loss: 0.0556693
[Epoch 65; Iter    62/  157] train: loss: 0.0730634
[Epoch 65; Iter    92/  157] train: loss: 0.1040942
[Epoch 65; Iter   122/  157] train: loss: 0.0834305
[Epoch 65; Iter   152/  157] train: loss: 0.1331110
[Epoch 65] ogbg-moltox21: 0.730921 val loss: 0.490104
[Epoch 65] ogbg-moltox21: 0.720378 test loss: 0.468841
[Epoch 66; Iter    25/  157] train: loss: 0.0785437
[Epoch 66; Iter    55/  157] train: loss: 0.0791208
[Epoch 66; Iter    85/  157] train: loss: 0.0757600
[Epoch 66; Iter   115/  157] train: loss: 0.0489270
[Epoch 66; Iter   145/  157] train: loss: 0.0524560
[Epoch 66] ogbg-moltox21: 0.726205 val loss: 1.300764
[Epoch 66] ogbg-moltox21: 0.710084 test loss: 1.375118
[Epoch 67; Iter    18/  157] train: loss: 0.0493800
[Epoch 67; Iter    48/  157] train: loss: 0.0619818
[Epoch 67; Iter    78/  157] train: loss: 0.1197981
[Epoch 67; Iter   108/  157] train: loss: 0.0799704
[Epoch 67; Iter   138/  157] train: loss: 0.1199113
[Epoch 67] ogbg-moltox21: 0.736367 val loss: 0.389788
[Epoch 67] ogbg-moltox21: 0.715879 test loss: 0.414546
[Epoch 68; Iter    11/  157] train: loss: 0.0643244
[Epoch 68; Iter    41/  157] train: loss: 0.0589115
[Epoch 68; Iter    71/  157] train: loss: 0.0863246
[Epoch 68; Iter   101/  157] train: loss: 0.0826749
[Epoch 68; Iter   131/  157] train: loss: 0.0677664
[Epoch 68] ogbg-moltox21: 0.718989 val loss: 0.434540
[Epoch 68] ogbg-moltox21: 0.705887 test loss: 0.452009
[Epoch 69; Iter     4/  157] train: loss: 0.0469181
[Epoch 69; Iter    34/  157] train: loss: 0.0652837
[Epoch 69; Iter    64/  157] train: loss: 0.0625586
[Epoch 69; Iter    94/  157] train: loss: 0.1106569
[Epoch 69; Iter   124/  157] train: loss: 0.0792840
[Epoch 69; Iter   154/  157] train: loss: 0.0699495
[Epoch 69] ogbg-moltox21: 0.720833 val loss: 0.417311
[Epoch 69] ogbg-moltox21: 0.709596 test loss: 0.435028
[Epoch 70; Iter    27/  157] train: loss: 0.0717991
[Epoch 70; Iter    57/  157] train: loss: 0.0578445
[Epoch 70; Iter    87/  157] train: loss: 0.0809248
[Epoch 70; Iter   117/  157] train: loss: 0.0768708
[Epoch 70; Iter   147/  157] train: loss: 0.0722773
[Epoch 70] ogbg-moltox21: 0.720839 val loss: 0.477109
[Epoch 70] ogbg-moltox21: 0.706832 test loss: 0.439957
[Epoch 71; Iter    20/  157] train: loss: 0.1283276
[Epoch 71; Iter    50/  157] train: loss: 0.0748537
[Epoch 71; Iter    80/  157] train: loss: 0.0383419
[Epoch 71; Iter   110/  157] train: loss: 0.0909401
[Epoch 71; Iter   140/  157] train: loss: 0.0528183
[Epoch 71] ogbg-moltox21: 0.723481 val loss: 0.507175
[Epoch 71] ogbg-moltox21: 0.715304 test loss: 0.490007
[Epoch 72; Iter    13/  157] train: loss: 0.0570945
[Epoch 72; Iter    43/  157] train: loss: 0.0590318
[Epoch 72; Iter    73/  157] train: loss: 0.0533300
[Epoch 72; Iter   103/  157] train: loss: 0.0813580
[Epoch 72; Iter   133/  157] train: loss: 0.1298850
[Epoch 72] ogbg-moltox21: 0.728679 val loss: 0.428272
[Epoch 72] ogbg-moltox21: 0.720365 test loss: 0.445682
[Epoch 73; Iter     6/  157] train: loss: 0.0775044
[Epoch 73; Iter    36/  157] train: loss: 0.0571864
[Epoch 73; Iter    66/  157] train: loss: 0.0436085
[Epoch 73; Iter    96/  157] train: loss: 0.0734639
[Epoch 73; Iter   126/  157] train: loss: 0.0532828
[Epoch 73; Iter   156/  157] train: loss: 0.0371890
[Epoch 73] ogbg-moltox21: 0.719680 val loss: 0.546412
[Epoch 73] ogbg-moltox21: 0.718438 test loss: 0.497879
[Epoch 74; Iter    29/  157] train: loss: 0.0310558
[Epoch 74; Iter    59/  157] train: loss: 0.0466390
[Epoch 74; Iter    89/  157] train: loss: 0.0342870
[Epoch 74; Iter   119/  157] train: loss: 0.0634766
[Epoch 74; Iter   149/  157] train: loss: 0.0564790
[Epoch 74] ogbg-moltox21: 0.715492 val loss: 0.525447
[Epoch 74] ogbg-moltox21: 0.709559 test loss: 0.498493
[Epoch 75; Iter    22/  157] train: loss: 0.0434742
[Epoch 75; Iter    52/  157] train: loss: 0.0436014
[Epoch 75; Iter    82/  157] train: loss: 0.0659059
[Epoch 75; Iter   112/  157] train: loss: 0.0825404
[Epoch 75; Iter   142/  157] train: loss: 0.0581304
[Epoch 75] ogbg-moltox21: 0.720987 val loss: 0.461313
[Epoch 75] ogbg-moltox21: 0.712160 test loss: 0.467441
[Epoch 76; Iter    15/  157] train: loss: 0.0326633
[Epoch 76; Iter    45/  157] train: loss: 0.0603575
[Epoch 76; Iter    75/  157] train: loss: 0.0769829
[Epoch 76; Iter   105/  157] train: loss: 0.0728284
[Epoch 76; Iter   135/  157] train: loss: 0.0766353
[Epoch 76] ogbg-moltox21: 0.716180 val loss: 0.520561
[Epoch 76] ogbg-moltox21: 0.707395 test loss: 0.486616
[Epoch 77; Iter     8/  157] train: loss: 0.0415709
[Epoch 77; Iter    38/  157] train: loss: 0.0619952
[Epoch 77; Iter    68/  157] train: loss: 0.0403840
[Epoch 77; Iter    98/  157] train: loss: 0.0385978
[Epoch 77; Iter   128/  157] train: loss: 0.0569987
[Epoch 77] ogbg-moltox21: 0.715856 val loss: 0.462747
[Epoch 77] ogbg-moltox21: 0.710355 test loss: 0.461872
[Epoch 78; Iter     1/  157] train: loss: 0.0483957
[Epoch 78; Iter    31/  157] train: loss: 0.0590100
[Epoch 78; Iter    61/  157] train: loss: 0.0560717
[Epoch 78; Iter    91/  157] train: loss: 0.0522473
[Epoch 78; Iter   121/  157] train: loss: 0.0737298
[Epoch 78; Iter   151/  157] train: loss: 0.0727323
[Epoch 78] ogbg-moltox21: 0.710623 val loss: 0.461384
[Epoch 78] ogbg-moltox21: 0.699666 test loss: 0.446236
[Epoch 79; Iter    24/  157] train: loss: 0.0730737
[Epoch 79; Iter    54/  157] train: loss: 0.0728999
[Epoch 79; Iter    84/  157] train: loss: 0.0652283
[Epoch 79; Iter   114/  157] train: loss: 0.0937322
[Epoch 79; Iter   144/  157] train: loss: 0.0855001
[Epoch 79] ogbg-moltox21: 0.709631 val loss: 0.512572
[Epoch 79] ogbg-moltox21: 0.704958 test loss: 0.477628
[Epoch 80; Iter    17/  157] train: loss: 0.0347184
[Epoch 58] ogbg-moltox21: 0.764994 val loss: 0.391357
[Epoch 58] ogbg-moltox21: 0.741863 test loss: 0.337693
[Epoch 59; Iter    14/  157] train: loss: 0.1298936
[Epoch 59; Iter    44/  157] train: loss: 0.1274895
[Epoch 59; Iter    74/  157] train: loss: 0.1331958
[Epoch 59; Iter   104/  157] train: loss: 0.1519071
[Epoch 59; Iter   134/  157] train: loss: 0.0733248
[Epoch 59] ogbg-moltox21: 0.763534 val loss: 0.310784
[Epoch 59] ogbg-moltox21: 0.739300 test loss: 0.330219
[Epoch 60; Iter     7/  157] train: loss: 0.0677228
[Epoch 60; Iter    37/  157] train: loss: 0.0893178
[Epoch 60; Iter    67/  157] train: loss: 0.1017255
[Epoch 60; Iter    97/  157] train: loss: 0.0853363
[Epoch 60; Iter   127/  157] train: loss: 0.0988163
[Epoch 60; Iter   157/  157] train: loss: 0.1140818
[Epoch 60] ogbg-moltox21: 0.758626 val loss: 0.344068
[Epoch 60] ogbg-moltox21: 0.733814 test loss: 0.368730
[Epoch 61; Iter    30/  157] train: loss: 0.0936645
[Epoch 61; Iter    60/  157] train: loss: 0.0513747
[Epoch 61; Iter    90/  157] train: loss: 0.1041983
[Epoch 61; Iter   120/  157] train: loss: 0.1238558
[Epoch 61; Iter   150/  157] train: loss: 0.1548321
[Epoch 61] ogbg-moltox21: 0.764955 val loss: 0.351387
[Epoch 61] ogbg-moltox21: 0.741892 test loss: 0.387034
[Epoch 62; Iter    23/  157] train: loss: 0.1122373
[Epoch 62; Iter    53/  157] train: loss: 0.1430985
[Epoch 62; Iter    83/  157] train: loss: 0.1732492
[Epoch 62; Iter   113/  157] train: loss: 0.0891502
[Epoch 62; Iter   143/  157] train: loss: 0.1099701
[Epoch 62] ogbg-moltox21: 0.750138 val loss: 0.320885
[Epoch 62] ogbg-moltox21: 0.731719 test loss: 0.343086
[Epoch 63; Iter    16/  157] train: loss: 0.0846340
[Epoch 63; Iter    46/  157] train: loss: 0.0816313
[Epoch 63; Iter    76/  157] train: loss: 0.1399396
[Epoch 63; Iter   106/  157] train: loss: 0.1509151
[Epoch 63; Iter   136/  157] train: loss: 0.0765765
[Epoch 63] ogbg-moltox21: 0.751190 val loss: 0.340903
[Epoch 63] ogbg-moltox21: 0.730355 test loss: 0.361895
[Epoch 64; Iter     9/  157] train: loss: 0.0838077
[Epoch 64; Iter    39/  157] train: loss: 0.0615883
[Epoch 64; Iter    69/  157] train: loss: 0.1095276
[Epoch 64; Iter    99/  157] train: loss: 0.1399740
[Epoch 64; Iter   129/  157] train: loss: 0.2152478
[Epoch 64] ogbg-moltox21: 0.759062 val loss: 0.320932
[Epoch 64] ogbg-moltox21: 0.728720 test loss: 0.358826
[Epoch 65; Iter     2/  157] train: loss: 0.1096104
[Epoch 65; Iter    32/  157] train: loss: 0.0704802
[Epoch 65; Iter    62/  157] train: loss: 0.0810464
[Epoch 65; Iter    92/  157] train: loss: 0.1188671
[Epoch 65; Iter   122/  157] train: loss: 0.0939169
[Epoch 65; Iter   152/  157] train: loss: 0.1222774
[Epoch 65] ogbg-moltox21: 0.750344 val loss: 0.323475
[Epoch 65] ogbg-moltox21: 0.724799 test loss: 0.353498
[Epoch 66; Iter    25/  157] train: loss: 0.0922874
[Epoch 66; Iter    55/  157] train: loss: 0.0581123
[Epoch 66; Iter    85/  157] train: loss: 0.1427101
[Epoch 66; Iter   115/  157] train: loss: 0.1357605
[Epoch 66; Iter   145/  157] train: loss: 0.1238979
[Epoch 66] ogbg-moltox21: 0.751527 val loss: 0.332053
[Epoch 66] ogbg-moltox21: 0.728012 test loss: 0.364441
[Epoch 67; Iter    18/  157] train: loss: 0.0892864
[Epoch 67; Iter    48/  157] train: loss: 0.0911834
[Epoch 67; Iter    78/  157] train: loss: 0.1052259
[Epoch 67; Iter   108/  157] train: loss: 0.0659681
[Epoch 67; Iter   138/  157] train: loss: 0.0848288
[Epoch 67] ogbg-moltox21: 0.760328 val loss: 0.376294
[Epoch 67] ogbg-moltox21: 0.734574 test loss: 0.423442
[Epoch 68; Iter    11/  157] train: loss: 0.1119856
[Epoch 68; Iter    41/  157] train: loss: 0.1428078
[Epoch 68; Iter    71/  157] train: loss: 0.1197009
[Epoch 68; Iter   101/  157] train: loss: 0.0678759
[Epoch 68; Iter   131/  157] train: loss: 0.0964875
[Epoch 68] ogbg-moltox21: 0.755915 val loss: 0.342894
[Epoch 68] ogbg-moltox21: 0.730256 test loss: 0.371317
[Epoch 69; Iter     4/  157] train: loss: 0.1074778
[Epoch 69; Iter    34/  157] train: loss: 0.1519045
[Epoch 69; Iter    64/  157] train: loss: 0.0614662
[Epoch 69; Iter    94/  157] train: loss: 0.1132917
[Epoch 69; Iter   124/  157] train: loss: 0.1287619
[Epoch 69; Iter   154/  157] train: loss: 0.1282406
[Epoch 69] ogbg-moltox21: 0.752228 val loss: 0.349533
[Epoch 69] ogbg-moltox21: 0.726923 test loss: 0.385302
[Epoch 70; Iter    27/  157] train: loss: 0.0814339
[Epoch 70; Iter    57/  157] train: loss: 0.0816585
[Epoch 70; Iter    87/  157] train: loss: 0.0564591
[Epoch 70; Iter   117/  157] train: loss: 0.0805518
[Epoch 70; Iter   147/  157] train: loss: 0.1912746
[Epoch 70] ogbg-moltox21: 0.756472 val loss: 0.332456
[Epoch 70] ogbg-moltox21: 0.729227 test loss: 0.360871
[Epoch 71; Iter    20/  157] train: loss: 0.1020737
[Epoch 71; Iter    50/  157] train: loss: 0.0667304
[Epoch 71; Iter    80/  157] train: loss: 0.0995953
[Epoch 71; Iter   110/  157] train: loss: 0.0880449
[Epoch 71; Iter   140/  157] train: loss: 0.0789813
[Epoch 71] ogbg-moltox21: 0.744707 val loss: 0.340474
[Epoch 71] ogbg-moltox21: 0.721493 test loss: 0.365356
[Epoch 72; Iter    13/  157] train: loss: 0.1313824
[Epoch 72; Iter    43/  157] train: loss: 0.0781964
[Epoch 72; Iter    73/  157] train: loss: 0.1439821
[Epoch 72; Iter   103/  157] train: loss: 0.0725233
[Epoch 72; Iter   133/  157] train: loss: 0.1085480
[Epoch 72] ogbg-moltox21: 0.751256 val loss: 0.351131
[Epoch 72] ogbg-moltox21: 0.721929 test loss: 0.384880
[Epoch 73; Iter     6/  157] train: loss: 0.0548043
[Epoch 73; Iter    36/  157] train: loss: 0.0933368
[Epoch 73; Iter    66/  157] train: loss: 0.1123830
[Epoch 73; Iter    96/  157] train: loss: 0.0503888
[Epoch 73; Iter   126/  157] train: loss: 0.1640157
[Epoch 73; Iter   156/  157] train: loss: 0.1506907
[Epoch 73] ogbg-moltox21: 0.748656 val loss: 0.328373
[Epoch 73] ogbg-moltox21: 0.727024 test loss: 0.354240
[Epoch 74; Iter    29/  157] train: loss: 0.0757056
[Epoch 74; Iter    59/  157] train: loss: 0.0841216
[Epoch 74; Iter    89/  157] train: loss: 0.1059844
[Epoch 74; Iter   119/  157] train: loss: 0.0963488
[Epoch 74; Iter   149/  157] train: loss: 0.0949016
[Epoch 74] ogbg-moltox21: 0.744581 val loss: 0.335297
[Epoch 74] ogbg-moltox21: 0.722008 test loss: 0.358066
[Epoch 75; Iter    22/  157] train: loss: 0.0565316
[Epoch 75; Iter    52/  157] train: loss: 0.0711251
[Epoch 75; Iter    82/  157] train: loss: 0.0931592
[Epoch 75; Iter   112/  157] train: loss: 0.0919747
[Epoch 75; Iter   142/  157] train: loss: 0.0786712
[Epoch 75] ogbg-moltox21: 0.748015 val loss: 0.373144
[Epoch 75] ogbg-moltox21: 0.725369 test loss: 0.410498
[Epoch 76; Iter    15/  157] train: loss: 0.0860045
[Epoch 76; Iter    45/  157] train: loss: 0.0568201
[Epoch 76; Iter    75/  157] train: loss: 0.0919215
[Epoch 76; Iter   105/  157] train: loss: 0.2027133
[Epoch 76; Iter   135/  157] train: loss: 0.1158298
[Epoch 76] ogbg-moltox21: 0.756217 val loss: 0.355456
[Epoch 76] ogbg-moltox21: 0.722707 test loss: 0.383836
[Epoch 77; Iter     8/  157] train: loss: 0.0775080
[Epoch 77; Iter    38/  157] train: loss: 0.0597974
[Epoch 77; Iter    68/  157] train: loss: 0.1117119
[Epoch 77; Iter    98/  157] train: loss: 0.0970770
[Epoch 77; Iter   128/  157] train: loss: 0.1012734
[Epoch 77] ogbg-moltox21: 0.752310 val loss: 0.343697
[Epoch 77] ogbg-moltox21: 0.726964 test loss: 0.370037
[Epoch 78; Iter     1/  157] train: loss: 0.1067739
[Epoch 78; Iter    31/  157] train: loss: 0.0932313
[Epoch 78; Iter    61/  157] train: loss: 0.1185740
[Epoch 78; Iter    91/  157] train: loss: 0.0972334
[Epoch 78; Iter   121/  157] train: loss: 0.0575469
[Epoch 78; Iter   151/  157] train: loss: 0.0927319
[Epoch 78] ogbg-moltox21: 0.739774 val loss: 0.350312
[Epoch 78] ogbg-moltox21: 0.709838 test loss: 0.396820
[Epoch 79; Iter    24/  157] train: loss: 0.0914400
[Epoch 79; Iter    54/  157] train: loss: 0.0851058
[Epoch 79; Iter    84/  157] train: loss: 0.0819755
[Epoch 79; Iter   114/  157] train: loss: 0.0859586
[Epoch 79; Iter   144/  157] train: loss: 0.1171754
[Epoch 79] ogbg-moltox21: 0.744998 val loss: 0.380505
[Epoch 79] ogbg-moltox21: 0.717220 test loss: 0.408358
[Epoch 80; Iter    17/  157] train: loss: 0.1066332
[Epoch 58] ogbg-moltox21: 0.752354 val loss: 0.536082
[Epoch 58] ogbg-moltox21: 0.722518 test loss: 0.984617
[Epoch 59; Iter    14/  157] train: loss: 0.0778302
[Epoch 59; Iter    44/  157] train: loss: 0.1129188
[Epoch 59; Iter    74/  157] train: loss: 0.0710931
[Epoch 59; Iter   104/  157] train: loss: 0.1103276
[Epoch 59; Iter   134/  157] train: loss: 0.1089520
[Epoch 59] ogbg-moltox21: 0.741179 val loss: 0.468624
[Epoch 59] ogbg-moltox21: 0.724644 test loss: 0.434623
[Epoch 60; Iter     7/  157] train: loss: 0.1091794
[Epoch 60; Iter    37/  157] train: loss: 0.0727573
[Epoch 60; Iter    67/  157] train: loss: 0.0681815
[Epoch 60; Iter    97/  157] train: loss: 0.0567876
[Epoch 60; Iter   127/  157] train: loss: 0.0797065
[Epoch 60; Iter   157/  157] train: loss: 0.1235338
[Epoch 60] ogbg-moltox21: 0.756965 val loss: 0.418730
[Epoch 60] ogbg-moltox21: 0.749449 test loss: 0.432486
[Epoch 61; Iter    30/  157] train: loss: 0.1093162
[Epoch 61; Iter    60/  157] train: loss: 0.0856261
[Epoch 61; Iter    90/  157] train: loss: 0.0625013
[Epoch 61; Iter   120/  157] train: loss: 0.0687493
[Epoch 61; Iter   150/  157] train: loss: 0.0897644
[Epoch 61] ogbg-moltox21: 0.741931 val loss: 0.606963
[Epoch 61] ogbg-moltox21: 0.725761 test loss: 0.482622
[Epoch 62; Iter    23/  157] train: loss: 0.1389955
[Epoch 62; Iter    53/  157] train: loss: 0.0882769
[Epoch 62; Iter    83/  157] train: loss: 0.1000267
[Epoch 62; Iter   113/  157] train: loss: 0.0930856
[Epoch 62; Iter   143/  157] train: loss: 0.1786413
[Epoch 62] ogbg-moltox21: 0.754310 val loss: 0.469815
[Epoch 62] ogbg-moltox21: 0.738821 test loss: 0.434536
[Epoch 63; Iter    16/  157] train: loss: 0.1242302
[Epoch 63; Iter    46/  157] train: loss: 0.0625311
[Epoch 63; Iter    76/  157] train: loss: 0.0808205
[Epoch 63; Iter   106/  157] train: loss: 0.0718893
[Epoch 63; Iter   136/  157] train: loss: 0.0573426
[Epoch 63] ogbg-moltox21: 0.744404 val loss: 0.572112
[Epoch 63] ogbg-moltox21: 0.735186 test loss: 0.481768
[Epoch 64; Iter     9/  157] train: loss: 0.0683475
[Epoch 64; Iter    39/  157] train: loss: 0.0612571
[Epoch 64; Iter    69/  157] train: loss: 0.1011749
[Epoch 64; Iter    99/  157] train: loss: 0.0762087
[Epoch 64; Iter   129/  157] train: loss: 0.0633552
[Epoch 64] ogbg-moltox21: 0.727437 val loss: 0.486275
[Epoch 64] ogbg-moltox21: 0.722880 test loss: 0.418923
[Epoch 65; Iter     2/  157] train: loss: 0.1248885
[Epoch 65; Iter    32/  157] train: loss: 0.0352688
[Epoch 65; Iter    62/  157] train: loss: 0.0789615
[Epoch 65; Iter    92/  157] train: loss: 0.1235556
[Epoch 65; Iter   122/  157] train: loss: 0.0923903
[Epoch 65; Iter   152/  157] train: loss: 0.1293999
[Epoch 65] ogbg-moltox21: 0.733490 val loss: 0.523014
[Epoch 65] ogbg-moltox21: 0.728576 test loss: 0.537825
[Epoch 66; Iter    25/  157] train: loss: 0.0888614
[Epoch 66; Iter    55/  157] train: loss: 0.0966636
[Epoch 66; Iter    85/  157] train: loss: 0.0923281
[Epoch 66; Iter   115/  157] train: loss: 0.1066454
[Epoch 66; Iter   145/  157] train: loss: 0.0690239
[Epoch 66] ogbg-moltox21: 0.736549 val loss: 0.509704
[Epoch 66] ogbg-moltox21: 0.727564 test loss: 0.925169
[Epoch 67; Iter    18/  157] train: loss: 0.0942568
[Epoch 67; Iter    48/  157] train: loss: 0.0925744
[Epoch 67; Iter    78/  157] train: loss: 0.0941872
[Epoch 67; Iter   108/  157] train: loss: 0.1411995
[Epoch 67; Iter   138/  157] train: loss: 0.1216098
[Epoch 67] ogbg-moltox21: 0.732342 val loss: 0.504867
[Epoch 67] ogbg-moltox21: 0.725214 test loss: 0.743499
[Epoch 68; Iter    11/  157] train: loss: 0.0808744
[Epoch 68; Iter    41/  157] train: loss: 0.0712775
[Epoch 68; Iter    71/  157] train: loss: 0.1007426
[Epoch 68; Iter   101/  157] train: loss: 0.0429711
[Epoch 68; Iter   131/  157] train: loss: 0.0948448
[Epoch 68] ogbg-moltox21: 0.747130 val loss: 0.360793
[Epoch 68] ogbg-moltox21: 0.734958 test loss: 0.382505
[Epoch 69; Iter     4/  157] train: loss: 0.0815777
[Epoch 69; Iter    34/  157] train: loss: 0.1391965
[Epoch 69; Iter    64/  157] train: loss: 0.0426716
[Epoch 69; Iter    94/  157] train: loss: 0.0606666
[Epoch 69; Iter   124/  157] train: loss: 0.1592574
[Epoch 69; Iter   154/  157] train: loss: 0.0709840
[Epoch 69] ogbg-moltox21: 0.748390 val loss: 0.469153
[Epoch 69] ogbg-moltox21: 0.733159 test loss: 0.446698
[Epoch 70; Iter    27/  157] train: loss: 0.0741112
[Epoch 70; Iter    57/  157] train: loss: 0.0819946
[Epoch 70; Iter    87/  157] train: loss: 0.0782930
[Epoch 70; Iter   117/  157] train: loss: 0.0895416
[Epoch 70; Iter   147/  157] train: loss: 0.1173924
[Epoch 70] ogbg-moltox21: 0.752214 val loss: 0.462667
[Epoch 70] ogbg-moltox21: 0.731956 test loss: 0.451233
[Epoch 71; Iter    20/  157] train: loss: 0.0676799
[Epoch 71; Iter    50/  157] train: loss: 0.0628198
[Epoch 71; Iter    80/  157] train: loss: 0.0749333
[Epoch 71; Iter   110/  157] train: loss: 0.1163460
[Epoch 71; Iter   140/  157] train: loss: 0.0963092
[Epoch 71] ogbg-moltox21: 0.741311 val loss: 0.585782
[Epoch 71] ogbg-moltox21: 0.726424 test loss: 0.477477
[Epoch 72; Iter    13/  157] train: loss: 0.0611454
[Epoch 72; Iter    43/  157] train: loss: 0.1316233
[Epoch 72; Iter    73/  157] train: loss: 0.0737506
[Epoch 72; Iter   103/  157] train: loss: 0.0809755
[Epoch 72; Iter   133/  157] train: loss: 0.0862656
[Epoch 72] ogbg-moltox21: 0.748090 val loss: 0.550739
[Epoch 72] ogbg-moltox21: 0.729204 test loss: 0.489892
[Epoch 73; Iter     6/  157] train: loss: 0.1043783
[Epoch 73; Iter    36/  157] train: loss: 0.0922237
[Epoch 73; Iter    66/  157] train: loss: 0.0656983
[Epoch 73; Iter    96/  157] train: loss: 0.0647584
[Epoch 73; Iter   126/  157] train: loss: 0.1463589
[Epoch 73; Iter   156/  157] train: loss: 0.0834521
[Epoch 73] ogbg-moltox21: 0.744213 val loss: 0.548994
[Epoch 73] ogbg-moltox21: 0.727602 test loss: 0.522599
[Epoch 74; Iter    29/  157] train: loss: 0.0471835
[Epoch 74; Iter    59/  157] train: loss: 0.0697986
[Epoch 74; Iter    89/  157] train: loss: 0.0552613
[Epoch 74; Iter   119/  157] train: loss: 0.1119093
[Epoch 74; Iter   149/  157] train: loss: 0.0609939
[Epoch 74] ogbg-moltox21: 0.757358 val loss: 0.403460
[Epoch 74] ogbg-moltox21: 0.739159 test loss: 0.424655
[Epoch 75; Iter    22/  157] train: loss: 0.1109082
[Epoch 75; Iter    52/  157] train: loss: 0.0585327
[Epoch 75; Iter    82/  157] train: loss: 0.0983905
[Epoch 75; Iter   112/  157] train: loss: 0.1318542
[Epoch 75; Iter   142/  157] train: loss: 0.0953177
[Epoch 75] ogbg-moltox21: 0.746403 val loss: 0.432235
[Epoch 75] ogbg-moltox21: 0.735672 test loss: 0.424295
[Epoch 76; Iter    15/  157] train: loss: 0.0839342
[Epoch 76; Iter    45/  157] train: loss: 0.0719727
[Epoch 76; Iter    75/  157] train: loss: 0.0597294
[Epoch 76; Iter   105/  157] train: loss: 0.0730978
[Epoch 76; Iter   135/  157] train: loss: 0.1252464
[Epoch 76] ogbg-moltox21: 0.729797 val loss: 0.597823
[Epoch 76] ogbg-moltox21: 0.721388 test loss: 0.561266
[Epoch 77; Iter     8/  157] train: loss: 0.0452094
[Epoch 77; Iter    38/  157] train: loss: 0.0764900
[Epoch 77; Iter    68/  157] train: loss: 0.0347642
[Epoch 77; Iter    98/  157] train: loss: 0.0801685
[Epoch 77; Iter   128/  157] train: loss: 0.0452711
[Epoch 77] ogbg-moltox21: 0.751182 val loss: 0.451181
[Epoch 77] ogbg-moltox21: 0.726717 test loss: 0.446417
[Epoch 78; Iter     1/  157] train: loss: 0.0542327
[Epoch 78; Iter    31/  157] train: loss: 0.0998859
[Epoch 78; Iter    61/  157] train: loss: 0.0705818
[Epoch 78; Iter    91/  157] train: loss: 0.0559517
[Epoch 78; Iter   121/  157] train: loss: 0.0494121
[Epoch 78; Iter   151/  157] train: loss: 0.0632186
[Epoch 78] ogbg-moltox21: 0.743443 val loss: 0.487279
[Epoch 78] ogbg-moltox21: 0.727427 test loss: 0.478268
[Epoch 79; Iter    24/  157] train: loss: 0.1032949
[Epoch 79; Iter    54/  157] train: loss: 0.0567988
[Epoch 79; Iter    84/  157] train: loss: 0.0696519
[Epoch 79; Iter   114/  157] train: loss: 0.0544000
[Epoch 79; Iter   144/  157] train: loss: 0.0702131
[Epoch 79] ogbg-moltox21: 0.731472 val loss: 0.551751
[Epoch 79] ogbg-moltox21: 0.721918 test loss: 0.511622
[Epoch 80; Iter    17/  157] train: loss: 0.0735582
[Epoch 64] ogbg-moltox21: 0.753986 test loss: 0.321485
[Epoch 65; Iter     4/  209] train: loss: 0.0851083
[Epoch 65; Iter    34/  209] train: loss: 0.1073760
[Epoch 65; Iter    64/  209] train: loss: 0.0790036
[Epoch 65; Iter    94/  209] train: loss: 0.1123076
[Epoch 65; Iter   124/  209] train: loss: 0.1434062
[Epoch 65; Iter   154/  209] train: loss: 0.0753722
[Epoch 65; Iter   184/  209] train: loss: 0.0739974
[Epoch 65] ogbg-moltox21: 0.777125 val loss: 0.295902
[Epoch 65] ogbg-moltox21: 0.757733 test loss: 0.299815
[Epoch 66; Iter     5/  209] train: loss: 0.0801793
[Epoch 66; Iter    35/  209] train: loss: 0.0751347
[Epoch 66; Iter    65/  209] train: loss: 0.0547967
[Epoch 66; Iter    95/  209] train: loss: 0.0614953
[Epoch 66; Iter   125/  209] train: loss: 0.1253160
[Epoch 66; Iter   155/  209] train: loss: 0.0978828
[Epoch 66; Iter   185/  209] train: loss: 0.0848620
[Epoch 66] ogbg-moltox21: 0.779883 val loss: 0.298955
[Epoch 66] ogbg-moltox21: 0.758307 test loss: 0.311526
[Epoch 67; Iter     6/  209] train: loss: 0.0741677
[Epoch 67; Iter    36/  209] train: loss: 0.0614038
[Epoch 67; Iter    66/  209] train: loss: 0.0604852
[Epoch 67; Iter    96/  209] train: loss: 0.0689015
[Epoch 67; Iter   126/  209] train: loss: 0.1038496
[Epoch 67; Iter   156/  209] train: loss: 0.1021091
[Epoch 67; Iter   186/  209] train: loss: 0.1068635
[Epoch 67] ogbg-moltox21: 0.784992 val loss: 0.297320
[Epoch 67] ogbg-moltox21: 0.752024 test loss: 0.318271
[Epoch 68; Iter     7/  209] train: loss: 0.0644144
[Epoch 68; Iter    37/  209] train: loss: 0.0641452
[Epoch 68; Iter    67/  209] train: loss: 0.0698412
[Epoch 68; Iter    97/  209] train: loss: 0.0998827
[Epoch 68; Iter   127/  209] train: loss: 0.0925141
[Epoch 68; Iter   157/  209] train: loss: 0.0849407
[Epoch 68; Iter   187/  209] train: loss: 0.0990420
[Epoch 68] ogbg-moltox21: 0.776457 val loss: 0.296456
[Epoch 68] ogbg-moltox21: 0.750780 test loss: 0.313841
[Epoch 69; Iter     8/  209] train: loss: 0.0947438
[Epoch 69; Iter    38/  209] train: loss: 0.0606919
[Epoch 69; Iter    68/  209] train: loss: 0.0653453
[Epoch 69; Iter    98/  209] train: loss: 0.0691927
[Epoch 69; Iter   128/  209] train: loss: 0.0736690
[Epoch 69; Iter   158/  209] train: loss: 0.1462208
[Epoch 69; Iter   188/  209] train: loss: 0.0765263
[Epoch 69] ogbg-moltox21: 0.773388 val loss: 0.309725
[Epoch 69] ogbg-moltox21: 0.753917 test loss: 0.317281
[Epoch 70; Iter     9/  209] train: loss: 0.0742044
[Epoch 70; Iter    39/  209] train: loss: 0.0701752
[Epoch 70; Iter    69/  209] train: loss: 0.0735204
[Epoch 70; Iter    99/  209] train: loss: 0.0534291
[Epoch 70; Iter   129/  209] train: loss: 0.1230675
[Epoch 70; Iter   159/  209] train: loss: 0.1395430
[Epoch 70; Iter   189/  209] train: loss: 0.0801755
[Epoch 70] ogbg-moltox21: 0.765861 val loss: 0.312980
[Epoch 70] ogbg-moltox21: 0.752750 test loss: 0.323700
[Epoch 71; Iter    10/  209] train: loss: 0.0680682
[Epoch 71; Iter    40/  209] train: loss: 0.0624463
[Epoch 71; Iter    70/  209] train: loss: 0.0808334
[Epoch 71; Iter   100/  209] train: loss: 0.0825435
[Epoch 71; Iter   130/  209] train: loss: 0.0966076
[Epoch 71; Iter   160/  209] train: loss: 0.0587488
[Epoch 71; Iter   190/  209] train: loss: 0.0713012
[Epoch 71] ogbg-moltox21: 0.771383 val loss: 0.311689
[Epoch 71] ogbg-moltox21: 0.748893 test loss: 0.322676
[Epoch 72; Iter    11/  209] train: loss: 0.1197074
[Epoch 72; Iter    41/  209] train: loss: 0.1005391
[Epoch 72; Iter    71/  209] train: loss: 0.1033603
[Epoch 72; Iter   101/  209] train: loss: 0.0720956
[Epoch 72; Iter   131/  209] train: loss: 0.1027052
[Epoch 72; Iter   161/  209] train: loss: 0.0703247
[Epoch 72; Iter   191/  209] train: loss: 0.0932074
[Epoch 72] ogbg-moltox21: 0.771152 val loss: 0.313547
[Epoch 72] ogbg-moltox21: 0.747636 test loss: 0.327505
[Epoch 73; Iter    12/  209] train: loss: 0.0678577
[Epoch 73; Iter    42/  209] train: loss: 0.0524275
[Epoch 73; Iter    72/  209] train: loss: 0.1021235
[Epoch 73; Iter   102/  209] train: loss: 0.0745447
[Epoch 73; Iter   132/  209] train: loss: 0.0934450
[Epoch 73; Iter   162/  209] train: loss: 0.1029195
[Epoch 73; Iter   192/  209] train: loss: 0.1456944
[Epoch 73] ogbg-moltox21: 0.772276 val loss: 0.306177
[Epoch 73] ogbg-moltox21: 0.746334 test loss: 0.336088
[Epoch 74; Iter    13/  209] train: loss: 0.0955140
[Epoch 74; Iter    43/  209] train: loss: 0.0968922
[Epoch 74; Iter    73/  209] train: loss: 0.1115793
[Epoch 74; Iter   103/  209] train: loss: 0.0526666
[Epoch 74; Iter   133/  209] train: loss: 0.1286353
[Epoch 74; Iter   163/  209] train: loss: 0.0808762
[Epoch 74; Iter   193/  209] train: loss: 0.1087183
[Epoch 74] ogbg-moltox21: 0.773152 val loss: 0.359367
[Epoch 74] ogbg-moltox21: 0.750296 test loss: 0.332239
[Epoch 75; Iter    14/  209] train: loss: 0.0442928
[Epoch 75; Iter    44/  209] train: loss: 0.0829443
[Epoch 75; Iter    74/  209] train: loss: 0.0702199
[Epoch 75; Iter   104/  209] train: loss: 0.0951208
[Epoch 75; Iter   134/  209] train: loss: 0.0543957
[Epoch 75; Iter   164/  209] train: loss: 0.1184462
[Epoch 75; Iter   194/  209] train: loss: 0.0557034
[Epoch 75] ogbg-moltox21: 0.776671 val loss: 0.314820
[Epoch 75] ogbg-moltox21: 0.748160 test loss: 0.338918
[Epoch 76; Iter    15/  209] train: loss: 0.0700704
[Epoch 76; Iter    45/  209] train: loss: 0.0629286
[Epoch 76; Iter    75/  209] train: loss: 0.0653791
[Epoch 76; Iter   105/  209] train: loss: 0.0641728
[Epoch 76; Iter   135/  209] train: loss: 0.1072505
[Epoch 76; Iter   165/  209] train: loss: 0.0399786
[Epoch 76; Iter   195/  209] train: loss: 0.0673227
[Epoch 76] ogbg-moltox21: 0.773353 val loss: 0.330720
[Epoch 76] ogbg-moltox21: 0.752475 test loss: 0.348818
[Epoch 77; Iter    16/  209] train: loss: 0.0914872
[Epoch 77; Iter    46/  209] train: loss: 0.0653108
[Epoch 77; Iter    76/  209] train: loss: 0.0375589
[Epoch 77; Iter   106/  209] train: loss: 0.0614994
[Epoch 77; Iter   136/  209] train: loss: 0.1112561
[Epoch 77; Iter   166/  209] train: loss: 0.0972584
[Epoch 77; Iter   196/  209] train: loss: 0.1247743
[Epoch 77] ogbg-moltox21: 0.770121 val loss: 0.323646
[Epoch 77] ogbg-moltox21: 0.744516 test loss: 0.345837
[Epoch 78; Iter    17/  209] train: loss: 0.0379409
[Epoch 78; Iter    47/  209] train: loss: 0.0462246
[Epoch 78; Iter    77/  209] train: loss: 0.0631084
[Epoch 78; Iter   107/  209] train: loss: 0.0488586
[Epoch 78; Iter   137/  209] train: loss: 0.0704405
[Epoch 78; Iter   167/  209] train: loss: 0.0865501
[Epoch 78; Iter   197/  209] train: loss: 0.0485206
[Epoch 78] ogbg-moltox21: 0.776031 val loss: 0.314138
[Epoch 78] ogbg-moltox21: 0.738249 test loss: 0.346869
[Epoch 79; Iter    18/  209] train: loss: 0.0567998
[Epoch 79; Iter    48/  209] train: loss: 0.0721185
[Epoch 79; Iter    78/  209] train: loss: 0.0888083
[Epoch 79; Iter   108/  209] train: loss: 0.0907130
[Epoch 79; Iter   138/  209] train: loss: 0.0337439
[Epoch 79; Iter   168/  209] train: loss: 0.0814042
[Epoch 79; Iter   198/  209] train: loss: 0.0416690
[Epoch 79] ogbg-moltox21: 0.775405 val loss: 0.324478
[Epoch 79] ogbg-moltox21: 0.749617 test loss: 0.349435
[Epoch 80; Iter    19/  209] train: loss: 0.0573672
[Epoch 80; Iter    49/  209] train: loss: 0.0933644
[Epoch 80; Iter    79/  209] train: loss: 0.0426591
[Epoch 80; Iter   109/  209] train: loss: 0.0806590
[Epoch 80; Iter   139/  209] train: loss: 0.0538825
[Epoch 80; Iter   169/  209] train: loss: 0.0847527
[Epoch 80; Iter   199/  209] train: loss: 0.1284278
[Epoch 80] ogbg-moltox21: 0.779506 val loss: 0.325263
[Epoch 80] ogbg-moltox21: 0.748549 test loss: 0.359040
[Epoch 81; Iter    20/  209] train: loss: 0.0838222
[Epoch 81; Iter    50/  209] train: loss: 0.0656685
[Epoch 81; Iter    80/  209] train: loss: 0.0727953
[Epoch 81; Iter   110/  209] train: loss: 0.0893077
[Epoch 81; Iter   140/  209] train: loss: 0.1365880
[Epoch 81; Iter   170/  209] train: loss: 0.0951798
[Epoch 81; Iter   200/  209] train: loss: 0.0689370
[Epoch 81] ogbg-moltox21: 0.778002 val loss: 0.326186
[Epoch 81] ogbg-moltox21: 0.747205 test loss: 0.360143
[Epoch 82; Iter    21/  209] train: loss: 0.0637704
[Epoch 64] ogbg-moltox21: 0.753112 test loss: 0.311363
[Epoch 65; Iter     4/  209] train: loss: 0.0960131
[Epoch 65; Iter    34/  209] train: loss: 0.1045480
[Epoch 65; Iter    64/  209] train: loss: 0.0714878
[Epoch 65; Iter    94/  209] train: loss: 0.0914494
[Epoch 65; Iter   124/  209] train: loss: 0.0925754
[Epoch 65; Iter   154/  209] train: loss: 0.0628711
[Epoch 65; Iter   184/  209] train: loss: 0.0826805
[Epoch 65] ogbg-moltox21: 0.778907 val loss: 0.310384
[Epoch 65] ogbg-moltox21: 0.750134 test loss: 0.324419
[Epoch 66; Iter     5/  209] train: loss: 0.0629853
[Epoch 66; Iter    35/  209] train: loss: 0.0950418
[Epoch 66; Iter    65/  209] train: loss: 0.0724791
[Epoch 66; Iter    95/  209] train: loss: 0.0852810
[Epoch 66; Iter   125/  209] train: loss: 0.0746669
[Epoch 66; Iter   155/  209] train: loss: 0.1057734
[Epoch 66; Iter   185/  209] train: loss: 0.0670452
[Epoch 66] ogbg-moltox21: 0.771043 val loss: 0.311252
[Epoch 66] ogbg-moltox21: 0.743546 test loss: 0.322599
[Epoch 67; Iter     6/  209] train: loss: 0.0598151
[Epoch 67; Iter    36/  209] train: loss: 0.0728120
[Epoch 67; Iter    66/  209] train: loss: 0.0794145
[Epoch 67; Iter    96/  209] train: loss: 0.0877473
[Epoch 67; Iter   126/  209] train: loss: 0.0512408
[Epoch 67; Iter   156/  209] train: loss: 0.0725415
[Epoch 67; Iter   186/  209] train: loss: 0.0806740
[Epoch 67] ogbg-moltox21: 0.771200 val loss: 0.308324
[Epoch 67] ogbg-moltox21: 0.740186 test loss: 0.330503
[Epoch 68; Iter     7/  209] train: loss: 0.0364423
[Epoch 68; Iter    37/  209] train: loss: 0.0461420
[Epoch 68; Iter    67/  209] train: loss: 0.1339448
[Epoch 68; Iter    97/  209] train: loss: 0.0578740
[Epoch 68; Iter   127/  209] train: loss: 0.0791202
[Epoch 68; Iter   157/  209] train: loss: 0.0807494
[Epoch 68; Iter   187/  209] train: loss: 0.0972925
[Epoch 68] ogbg-moltox21: 0.773589 val loss: 0.315888
[Epoch 68] ogbg-moltox21: 0.747366 test loss: 0.334024
[Epoch 69; Iter     8/  209] train: loss: 0.0850958
[Epoch 69; Iter    38/  209] train: loss: 0.0833408
[Epoch 69; Iter    68/  209] train: loss: 0.0452581
[Epoch 69; Iter    98/  209] train: loss: 0.0878155
[Epoch 69; Iter   128/  209] train: loss: 0.0896175
[Epoch 69; Iter   158/  209] train: loss: 0.0671339
[Epoch 69; Iter   188/  209] train: loss: 0.1242665
[Epoch 69] ogbg-moltox21: 0.780777 val loss: 0.316153
[Epoch 69] ogbg-moltox21: 0.743003 test loss: 0.338901
[Epoch 70; Iter     9/  209] train: loss: 0.0791132
[Epoch 70; Iter    39/  209] train: loss: 0.1132125
[Epoch 70; Iter    69/  209] train: loss: 0.1054993
[Epoch 70; Iter    99/  209] train: loss: 0.1065519
[Epoch 70; Iter   129/  209] train: loss: 0.0640960
[Epoch 70; Iter   159/  209] train: loss: 0.0977575
[Epoch 70; Iter   189/  209] train: loss: 0.0652383
[Epoch 70] ogbg-moltox21: 0.772136 val loss: 0.314864
[Epoch 70] ogbg-moltox21: 0.745018 test loss: 0.329180
[Epoch 71; Iter    10/  209] train: loss: 0.0632131
[Epoch 71; Iter    40/  209] train: loss: 0.0881408
[Epoch 71; Iter    70/  209] train: loss: 0.0612267
[Epoch 71; Iter   100/  209] train: loss: 0.0964087
[Epoch 71; Iter   130/  209] train: loss: 0.0668931
[Epoch 71; Iter   160/  209] train: loss: 0.0707947
[Epoch 71; Iter   190/  209] train: loss: 0.0989799
[Epoch 71] ogbg-moltox21: 0.763829 val loss: 0.330195
[Epoch 71] ogbg-moltox21: 0.743983 test loss: 0.333285
[Epoch 72; Iter    11/  209] train: loss: 0.0864859
[Epoch 72; Iter    41/  209] train: loss: 0.0850524
[Epoch 72; Iter    71/  209] train: loss: 0.0740921
[Epoch 72; Iter   101/  209] train: loss: 0.0677947
[Epoch 72; Iter   131/  209] train: loss: 0.0948203
[Epoch 72; Iter   161/  209] train: loss: 0.0944745
[Epoch 72; Iter   191/  209] train: loss: 0.0990493
[Epoch 72] ogbg-moltox21: 0.776999 val loss: 0.329539
[Epoch 72] ogbg-moltox21: 0.754865 test loss: 0.335281
[Epoch 73; Iter    12/  209] train: loss: 0.0665871
[Epoch 73; Iter    42/  209] train: loss: 0.0868123
[Epoch 73; Iter    72/  209] train: loss: 0.0899409
[Epoch 73; Iter   102/  209] train: loss: 0.0439828
[Epoch 73; Iter   132/  209] train: loss: 0.1145839
[Epoch 73; Iter   162/  209] train: loss: 0.0456806
[Epoch 73; Iter   192/  209] train: loss: 0.0626488
[Epoch 73] ogbg-moltox21: 0.765042 val loss: 0.336486
[Epoch 73] ogbg-moltox21: 0.739904 test loss: 0.352321
[Epoch 74; Iter    13/  209] train: loss: 0.0611536
[Epoch 74; Iter    43/  209] train: loss: 0.0730825
[Epoch 74; Iter    73/  209] train: loss: 0.1193229
[Epoch 74; Iter   103/  209] train: loss: 0.0769632
[Epoch 74; Iter   133/  209] train: loss: 0.0586927
[Epoch 74; Iter   163/  209] train: loss: 0.1410928
[Epoch 74; Iter   193/  209] train: loss: 0.1081171
[Epoch 74] ogbg-moltox21: 0.773144 val loss: 0.335207
[Epoch 74] ogbg-moltox21: 0.744350 test loss: 0.352419
[Epoch 75; Iter    14/  209] train: loss: 0.0588486
[Epoch 75; Iter    44/  209] train: loss: 0.0336919
[Epoch 75; Iter    74/  209] train: loss: 0.0808945
[Epoch 75; Iter   104/  209] train: loss: 0.1050887
[Epoch 75; Iter   134/  209] train: loss: 0.0775842
[Epoch 75; Iter   164/  209] train: loss: 0.0613370
[Epoch 75; Iter   194/  209] train: loss: 0.0531388
[Epoch 75] ogbg-moltox21: 0.768982 val loss: 0.342280
[Epoch 75] ogbg-moltox21: 0.738804 test loss: 0.355708
[Epoch 76; Iter    15/  209] train: loss: 0.0750609
[Epoch 76; Iter    45/  209] train: loss: 0.0875474
[Epoch 76; Iter    75/  209] train: loss: 0.0876674
[Epoch 76; Iter   105/  209] train: loss: 0.0943123
[Epoch 76; Iter   135/  209] train: loss: 0.0766146
[Epoch 76; Iter   165/  209] train: loss: 0.0982083
[Epoch 76; Iter   195/  209] train: loss: 0.0673497
[Epoch 76] ogbg-moltox21: 0.775018 val loss: 0.344134
[Epoch 76] ogbg-moltox21: 0.753714 test loss: 0.348389
[Epoch 77; Iter    16/  209] train: loss: 0.0371329
[Epoch 77; Iter    46/  209] train: loss: 0.0568530
[Epoch 77; Iter    76/  209] train: loss: 0.0555862
[Epoch 77; Iter   106/  209] train: loss: 0.0929193
[Epoch 77; Iter   136/  209] train: loss: 0.0695483
[Epoch 77; Iter   166/  209] train: loss: 0.1324176
[Epoch 77; Iter   196/  209] train: loss: 0.0404951
[Epoch 77] ogbg-moltox21: 0.771036 val loss: 0.337723
[Epoch 77] ogbg-moltox21: 0.738352 test loss: 0.357363
[Epoch 78; Iter    17/  209] train: loss: 0.1135935
[Epoch 78; Iter    47/  209] train: loss: 0.0750588
[Epoch 78; Iter    77/  209] train: loss: 0.1775908
[Epoch 78; Iter   107/  209] train: loss: 0.1126363
[Epoch 78; Iter   137/  209] train: loss: 0.0507310
[Epoch 78; Iter   167/  209] train: loss: 0.0557836
[Epoch 78; Iter   197/  209] train: loss: 0.0650073
[Epoch 78] ogbg-moltox21: 0.770403 val loss: 0.338229
[Epoch 78] ogbg-moltox21: 0.734931 test loss: 0.366569
[Epoch 79; Iter    18/  209] train: loss: 0.0674416
[Epoch 79; Iter    48/  209] train: loss: 0.0585711
[Epoch 79; Iter    78/  209] train: loss: 0.1288960
[Epoch 79; Iter   108/  209] train: loss: 0.0759890
[Epoch 79; Iter   138/  209] train: loss: 0.0948878
[Epoch 79; Iter   168/  209] train: loss: 0.0527988
[Epoch 79; Iter   198/  209] train: loss: 0.0419229
[Epoch 79] ogbg-moltox21: 0.770638 val loss: 0.349575
[Epoch 79] ogbg-moltox21: 0.744028 test loss: 0.361063
[Epoch 80; Iter    19/  209] train: loss: 0.0670098
[Epoch 80; Iter    49/  209] train: loss: 0.0360342
[Epoch 80; Iter    79/  209] train: loss: 0.1078306
[Epoch 80; Iter   109/  209] train: loss: 0.0689362
[Epoch 80; Iter   139/  209] train: loss: 0.0640965
[Epoch 80; Iter   169/  209] train: loss: 0.0505166
[Epoch 80; Iter   199/  209] train: loss: 0.0773699
[Epoch 80] ogbg-moltox21: 0.764863 val loss: 0.343190
[Epoch 80] ogbg-moltox21: 0.737281 test loss: 0.359245
[Epoch 81; Iter    20/  209] train: loss: 0.0532648
[Epoch 81; Iter    50/  209] train: loss: 0.0726461
[Epoch 81; Iter    80/  209] train: loss: 0.0549004
[Epoch 81; Iter   110/  209] train: loss: 0.0841360
[Epoch 81; Iter   140/  209] train: loss: 0.0720307
[Epoch 81; Iter   170/  209] train: loss: 0.0594341
[Epoch 81; Iter   200/  209] train: loss: 0.0908985
[Epoch 81] ogbg-moltox21: 0.774911 val loss: 0.352786
[Epoch 81] ogbg-moltox21: 0.749890 test loss: 0.361442
[Epoch 82; Iter    21/  209] train: loss: 0.0533611
[Epoch 64] ogbg-moltox21: 0.762878 test loss: 0.329154
[Epoch 65; Iter     4/  209] train: loss: 0.0876676
[Epoch 65; Iter    34/  209] train: loss: 0.0533851
[Epoch 65; Iter    64/  209] train: loss: 0.1085408
[Epoch 65; Iter    94/  209] train: loss: 0.1166426
[Epoch 65; Iter   124/  209] train: loss: 0.0994993
[Epoch 65; Iter   154/  209] train: loss: 0.1105837
[Epoch 65; Iter   184/  209] train: loss: 0.1574109
[Epoch 65] ogbg-moltox21: 0.791857 val loss: 0.289768
[Epoch 65] ogbg-moltox21: 0.770154 test loss: 0.304581
[Epoch 66; Iter     5/  209] train: loss: 0.0976887
[Epoch 66; Iter    35/  209] train: loss: 0.0688145
[Epoch 66; Iter    65/  209] train: loss: 0.0929772
[Epoch 66; Iter    95/  209] train: loss: 0.1104544
[Epoch 66; Iter   125/  209] train: loss: 0.0854599
[Epoch 66; Iter   155/  209] train: loss: 0.1148200
[Epoch 66; Iter   185/  209] train: loss: 0.0729828
[Epoch 66] ogbg-moltox21: 0.789776 val loss: 0.314331
[Epoch 66] ogbg-moltox21: 0.768433 test loss: 0.336009
[Epoch 67; Iter     6/  209] train: loss: 0.1276612
[Epoch 67; Iter    36/  209] train: loss: 0.1169187
[Epoch 67; Iter    66/  209] train: loss: 0.1024487
[Epoch 67; Iter    96/  209] train: loss: 0.0853754
[Epoch 67; Iter   126/  209] train: loss: 0.0629037
[Epoch 67; Iter   156/  209] train: loss: 0.0616601
[Epoch 67; Iter   186/  209] train: loss: 0.1032273
[Epoch 67] ogbg-moltox21: 0.772529 val loss: 0.311777
[Epoch 67] ogbg-moltox21: 0.755761 test loss: 0.341160
[Epoch 68; Iter     7/  209] train: loss: 0.0978469
[Epoch 68; Iter    37/  209] train: loss: 0.1196455
[Epoch 68; Iter    67/  209] train: loss: 0.1038800
[Epoch 68; Iter    97/  209] train: loss: 0.0766279
[Epoch 68; Iter   127/  209] train: loss: 0.0814271
[Epoch 68; Iter   157/  209] train: loss: 0.0812233
[Epoch 68; Iter   187/  209] train: loss: 0.0808386
[Epoch 68] ogbg-moltox21: 0.784717 val loss: 0.303788
[Epoch 68] ogbg-moltox21: 0.763636 test loss: 0.325640
[Epoch 69; Iter     8/  209] train: loss: 0.0692554
[Epoch 69; Iter    38/  209] train: loss: 0.0822425
[Epoch 69; Iter    68/  209] train: loss: 0.0947804
[Epoch 69; Iter    98/  209] train: loss: 0.0484078
[Epoch 69; Iter   128/  209] train: loss: 0.0846440
[Epoch 69; Iter   158/  209] train: loss: 0.0740408
[Epoch 69; Iter   188/  209] train: loss: 0.0969914
[Epoch 69] ogbg-moltox21: 0.785053 val loss: 0.311296
[Epoch 69] ogbg-moltox21: 0.762973 test loss: 0.351844
[Epoch 70; Iter     9/  209] train: loss: 0.0971735
[Epoch 70; Iter    39/  209] train: loss: 0.0543586
[Epoch 70; Iter    69/  209] train: loss: 0.1508559
[Epoch 70; Iter    99/  209] train: loss: 0.0950280
[Epoch 70; Iter   129/  209] train: loss: 0.0835445
[Epoch 70; Iter   159/  209] train: loss: 0.1137662
[Epoch 70; Iter   189/  209] train: loss: 0.0855434
[Epoch 70] ogbg-moltox21: 0.782770 val loss: 0.310704
[Epoch 70] ogbg-moltox21: 0.758290 test loss: 0.334284
[Epoch 71; Iter    10/  209] train: loss: 0.1067120
[Epoch 71; Iter    40/  209] train: loss: 0.1346852
[Epoch 71; Iter    70/  209] train: loss: 0.0910380
[Epoch 71; Iter   100/  209] train: loss: 0.1054801
[Epoch 71; Iter   130/  209] train: loss: 0.0668821
[Epoch 71; Iter   160/  209] train: loss: 0.0842039
[Epoch 71; Iter   190/  209] train: loss: 0.1028665
[Epoch 71] ogbg-moltox21: 0.773938 val loss: 0.329123
[Epoch 71] ogbg-moltox21: 0.751956 test loss: 0.344723
[Epoch 72; Iter    11/  209] train: loss: 0.1028675
[Epoch 72; Iter    41/  209] train: loss: 0.0997993
[Epoch 72; Iter    71/  209] train: loss: 0.1295131
[Epoch 72; Iter   101/  209] train: loss: 0.0498400
[Epoch 72; Iter   131/  209] train: loss: 0.1379991
[Epoch 72; Iter   161/  209] train: loss: 0.1110757
[Epoch 72; Iter   191/  209] train: loss: 0.0804431
[Epoch 72] ogbg-moltox21: 0.788264 val loss: 0.303811
[Epoch 72] ogbg-moltox21: 0.756124 test loss: 0.329928
[Epoch 73; Iter    12/  209] train: loss: 0.1063701
[Epoch 73; Iter    42/  209] train: loss: 0.0822141
[Epoch 73; Iter    72/  209] train: loss: 0.0647180
[Epoch 73; Iter   102/  209] train: loss: 0.0808459
[Epoch 73; Iter   132/  209] train: loss: 0.0943732
[Epoch 73; Iter   162/  209] train: loss: 0.0411324
[Epoch 73; Iter   192/  209] train: loss: 0.1082547
[Epoch 73] ogbg-moltox21: 0.787632 val loss: 0.311481
[Epoch 73] ogbg-moltox21: 0.751475 test loss: 0.338033
[Epoch 74; Iter    13/  209] train: loss: 0.0747336
[Epoch 74; Iter    43/  209] train: loss: 0.1165135
[Epoch 74; Iter    73/  209] train: loss: 0.0718365
[Epoch 74; Iter   103/  209] train: loss: 0.0758780
[Epoch 74; Iter   133/  209] train: loss: 0.0724778
[Epoch 74; Iter   163/  209] train: loss: 0.0716910
[Epoch 74; Iter   193/  209] train: loss: 0.0568324
[Epoch 74] ogbg-moltox21: 0.779897 val loss: 0.317970
[Epoch 74] ogbg-moltox21: 0.757217 test loss: 0.347887
[Epoch 75; Iter    14/  209] train: loss: 0.0723781
[Epoch 75; Iter    44/  209] train: loss: 0.1160218
[Epoch 75; Iter    74/  209] train: loss: 0.0788828
[Epoch 75; Iter   104/  209] train: loss: 0.0859119
[Epoch 75; Iter   134/  209] train: loss: 0.0714886
[Epoch 75; Iter   164/  209] train: loss: 0.0690724
[Epoch 75; Iter   194/  209] train: loss: 0.0890164
[Epoch 75] ogbg-moltox21: 0.780015 val loss: 0.320174
[Epoch 75] ogbg-moltox21: 0.747048 test loss: 0.355331
[Epoch 76; Iter    15/  209] train: loss: 0.1216413
[Epoch 76; Iter    45/  209] train: loss: 0.0381827
[Epoch 76; Iter    75/  209] train: loss: 0.0755039
[Epoch 76; Iter   105/  209] train: loss: 0.0579582
[Epoch 76; Iter   135/  209] train: loss: 0.0860677
[Epoch 76; Iter   165/  209] train: loss: 0.0680945
[Epoch 76; Iter   195/  209] train: loss: 0.0899091
[Epoch 76] ogbg-moltox21: 0.783731 val loss: 0.316872
[Epoch 76] ogbg-moltox21: 0.745719 test loss: 0.349861
[Epoch 77; Iter    16/  209] train: loss: 0.1262844
[Epoch 77; Iter    46/  209] train: loss: 0.1124486
[Epoch 77; Iter    76/  209] train: loss: 0.0636722
[Epoch 77; Iter   106/  209] train: loss: 0.0972203
[Epoch 77; Iter   136/  209] train: loss: 0.1059638
[Epoch 77; Iter   166/  209] train: loss: 0.0792864
[Epoch 77; Iter   196/  209] train: loss: 0.1003230
[Epoch 77] ogbg-moltox21: 0.787013 val loss: 0.315679
[Epoch 77] ogbg-moltox21: 0.749574 test loss: 0.346032
[Epoch 78; Iter    17/  209] train: loss: 0.0655155
[Epoch 78; Iter    47/  209] train: loss: 0.0697216
[Epoch 78; Iter    77/  209] train: loss: 0.0542312
[Epoch 78; Iter   107/  209] train: loss: 0.1101907
[Epoch 78; Iter   137/  209] train: loss: 0.0844877
[Epoch 78; Iter   167/  209] train: loss: 0.1525857
[Epoch 78; Iter   197/  209] train: loss: 0.0623070
[Epoch 78] ogbg-moltox21: 0.781482 val loss: 0.319710
[Epoch 78] ogbg-moltox21: 0.747421 test loss: 0.350539
[Epoch 79; Iter    18/  209] train: loss: 0.1196119
[Epoch 79; Iter    48/  209] train: loss: 0.0789447
[Epoch 79; Iter    78/  209] train: loss: 0.0464097
[Epoch 79; Iter   108/  209] train: loss: 0.0593127
[Epoch 79; Iter   138/  209] train: loss: 0.0684748
[Epoch 79; Iter   168/  209] train: loss: 0.0612471
[Epoch 79; Iter   198/  209] train: loss: 0.0606266
[Epoch 79] ogbg-moltox21: 0.777851 val loss: 0.339600
[Epoch 79] ogbg-moltox21: 0.750417 test loss: 0.361267
[Epoch 80; Iter    19/  209] train: loss: 0.1279083
[Epoch 80; Iter    49/  209] train: loss: 0.0623454
[Epoch 80; Iter    79/  209] train: loss: 0.0385110
[Epoch 80; Iter   109/  209] train: loss: 0.0675142
[Epoch 80; Iter   139/  209] train: loss: 0.0622901
[Epoch 80; Iter   169/  209] train: loss: 0.1285949
[Epoch 80; Iter   199/  209] train: loss: 0.0773609
[Epoch 80] ogbg-moltox21: 0.784381 val loss: 0.326887
[Epoch 80] ogbg-moltox21: 0.755302 test loss: 0.352691
[Epoch 81; Iter    20/  209] train: loss: 0.0632609
[Epoch 81; Iter    50/  209] train: loss: 0.0423690
[Epoch 81; Iter    80/  209] train: loss: 0.0860828
[Epoch 81; Iter   110/  209] train: loss: 0.0541719
[Epoch 81; Iter   140/  209] train: loss: 0.0806607
[Epoch 81; Iter   170/  209] train: loss: 0.0526838
[Epoch 81; Iter   200/  209] train: loss: 0.0841343
[Epoch 81] ogbg-moltox21: 0.783185 val loss: 0.337999
[Epoch 81] ogbg-moltox21: 0.748936 test loss: 0.365183
[Epoch 82; Iter    21/  209] train: loss: 0.0541052
[Epoch 71; Iter   180/  183] train: loss: 0.0869184
[Epoch 71] ogbg-moltox21: 0.751078 val loss: 0.338449
[Epoch 71] ogbg-moltox21: 0.725688 test loss: 0.382357
[Epoch 72; Iter    27/  183] train: loss: 0.1148571
[Epoch 72; Iter    57/  183] train: loss: 0.0513847
[Epoch 72; Iter    87/  183] train: loss: 0.0701159
[Epoch 72; Iter   117/  183] train: loss: 0.1632535
[Epoch 72; Iter   147/  183] train: loss: 0.0885343
[Epoch 72; Iter   177/  183] train: loss: 0.0644019
[Epoch 72] ogbg-moltox21: 0.751905 val loss: 0.341113
[Epoch 72] ogbg-moltox21: 0.727335 test loss: 0.373732
[Epoch 73; Iter    24/  183] train: loss: 0.1059480
[Epoch 73; Iter    54/  183] train: loss: 0.0783198
[Epoch 73; Iter    84/  183] train: loss: 0.0514132
[Epoch 73; Iter   114/  183] train: loss: 0.1008363
[Epoch 73; Iter   144/  183] train: loss: 0.0580450
[Epoch 73; Iter   174/  183] train: loss: 0.1118688
[Epoch 73] ogbg-moltox21: 0.755685 val loss: 0.342433
[Epoch 73] ogbg-moltox21: 0.727114 test loss: 0.374372
[Epoch 74; Iter    21/  183] train: loss: 0.0712192
[Epoch 74; Iter    51/  183] train: loss: 0.0605640
[Epoch 74; Iter    81/  183] train: loss: 0.0611462
[Epoch 74; Iter   111/  183] train: loss: 0.1668139
[Epoch 74; Iter   141/  183] train: loss: 0.0404643
[Epoch 74; Iter   171/  183] train: loss: 0.0736620
[Epoch 74] ogbg-moltox21: 0.749998 val loss: 0.338570
[Epoch 74] ogbg-moltox21: 0.725384 test loss: 0.366463
[Epoch 75; Iter    18/  183] train: loss: 0.0473155
[Epoch 75; Iter    48/  183] train: loss: 0.0796806
[Epoch 75; Iter    78/  183] train: loss: 0.0674545
[Epoch 75; Iter   108/  183] train: loss: 0.0671993
[Epoch 75; Iter   138/  183] train: loss: 0.0765137
[Epoch 75; Iter   168/  183] train: loss: 0.1393034
[Epoch 75] ogbg-moltox21: 0.747937 val loss: 0.341042
[Epoch 75] ogbg-moltox21: 0.726256 test loss: 0.370120
[Epoch 76; Iter    15/  183] train: loss: 0.0470051
[Epoch 76; Iter    45/  183] train: loss: 0.1295127
[Epoch 76; Iter    75/  183] train: loss: 0.0725639
[Epoch 76; Iter   105/  183] train: loss: 0.0625789
[Epoch 76; Iter   135/  183] train: loss: 0.0378961
[Epoch 76; Iter   165/  183] train: loss: 0.0604690
[Epoch 76] ogbg-moltox21: 0.750447 val loss: 0.339254
[Epoch 76] ogbg-moltox21: 0.721854 test loss: 0.380606
[Epoch 77; Iter    12/  183] train: loss: 0.0684283
[Epoch 77; Iter    42/  183] train: loss: 0.0779220
[Epoch 77; Iter    72/  183] train: loss: 0.0359736
[Epoch 77; Iter   102/  183] train: loss: 0.0771867
[Epoch 77; Iter   132/  183] train: loss: 0.1447170
[Epoch 77; Iter   162/  183] train: loss: 0.0569290
[Epoch 77] ogbg-moltox21: 0.750069 val loss: 0.353577
[Epoch 77] ogbg-moltox21: 0.725104 test loss: 0.384339
[Epoch 78; Iter     9/  183] train: loss: 0.0610904
[Epoch 78; Iter    39/  183] train: loss: 0.0454519
[Epoch 78; Iter    69/  183] train: loss: 0.0900645
[Epoch 78; Iter    99/  183] train: loss: 0.0400188
[Epoch 78; Iter   129/  183] train: loss: 0.0662830
[Epoch 78; Iter   159/  183] train: loss: 0.0390358
[Epoch 78] ogbg-moltox21: 0.743589 val loss: 0.365285
[Epoch 78] ogbg-moltox21: 0.721318 test loss: 0.398874
[Epoch 79; Iter     6/  183] train: loss: 0.0458864
[Epoch 79; Iter    36/  183] train: loss: 0.1013593
[Epoch 79; Iter    66/  183] train: loss: 0.0812662
[Epoch 79; Iter    96/  183] train: loss: 0.0752019
[Epoch 79; Iter   126/  183] train: loss: 0.0553394
[Epoch 79; Iter   156/  183] train: loss: 0.0615257
[Epoch 79] ogbg-moltox21: 0.745500 val loss: 0.359785
[Epoch 79] ogbg-moltox21: 0.719573 test loss: 0.398726
[Epoch 80; Iter     3/  183] train: loss: 0.0423150
[Epoch 80; Iter    33/  183] train: loss: 0.0716607
[Epoch 80; Iter    63/  183] train: loss: 0.0356126
[Epoch 80; Iter    93/  183] train: loss: 0.0603330
[Epoch 80; Iter   123/  183] train: loss: 0.0611371
[Epoch 80; Iter   153/  183] train: loss: 0.0659242
[Epoch 80; Iter   183/  183] train: loss: 0.0489086
[Epoch 80] ogbg-moltox21: 0.747031 val loss: 0.360496
[Epoch 80] ogbg-moltox21: 0.720594 test loss: 0.398414
[Epoch 81; Iter    30/  183] train: loss: 0.0483816
[Epoch 81; Iter    60/  183] train: loss: 0.0458535
[Epoch 81; Iter    90/  183] train: loss: 0.0597858
[Epoch 81; Iter   120/  183] train: loss: 0.0629712
[Epoch 81; Iter   150/  183] train: loss: 0.0547893
[Epoch 81; Iter   180/  183] train: loss: 0.1051711
[Epoch 81] ogbg-moltox21: 0.749906 val loss: 0.355909
[Epoch 81] ogbg-moltox21: 0.720043 test loss: 0.393793
[Epoch 82; Iter    27/  183] train: loss: 0.0378263
[Epoch 82; Iter    57/  183] train: loss: 0.0537185
[Epoch 82; Iter    87/  183] train: loss: 0.1090248
[Epoch 82; Iter   117/  183] train: loss: 0.0660258
[Epoch 82; Iter   147/  183] train: loss: 0.0473158
[Epoch 82; Iter   177/  183] train: loss: 0.0615195
[Epoch 82] ogbg-moltox21: 0.742667 val loss: 0.370025
[Epoch 82] ogbg-moltox21: 0.731468 test loss: 0.393049
[Epoch 83; Iter    24/  183] train: loss: 0.0585432
[Epoch 83; Iter    54/  183] train: loss: 0.0583819
[Epoch 83; Iter    84/  183] train: loss: 0.0668144
[Epoch 83; Iter   114/  183] train: loss: 0.1265402
[Epoch 83; Iter   144/  183] train: loss: 0.0538784
[Epoch 83; Iter   174/  183] train: loss: 0.0527672
[Epoch 83] ogbg-moltox21: 0.740257 val loss: 0.373108
[Epoch 83] ogbg-moltox21: 0.716205 test loss: 0.408883
[Epoch 84; Iter    21/  183] train: loss: 0.0448881
[Epoch 84; Iter    51/  183] train: loss: 0.0707332
[Epoch 84; Iter    81/  183] train: loss: 0.0911146
[Epoch 84; Iter   111/  183] train: loss: 0.0521569
[Epoch 84; Iter   141/  183] train: loss: 0.1056294
[Epoch 84; Iter   171/  183] train: loss: 0.1055097
[Epoch 84] ogbg-moltox21: 0.746389 val loss: 0.369363
[Epoch 84] ogbg-moltox21: 0.715979 test loss: 0.404810
[Epoch 85; Iter    18/  183] train: loss: 0.0562802
[Epoch 85; Iter    48/  183] train: loss: 0.0440597
[Epoch 85; Iter    78/  183] train: loss: 0.0599305
[Epoch 85; Iter   108/  183] train: loss: 0.0543507
[Epoch 85; Iter   138/  183] train: loss: 0.0572565
[Epoch 85; Iter   168/  183] train: loss: 0.0740686
[Epoch 85] ogbg-moltox21: 0.744399 val loss: 0.373970
[Epoch 85] ogbg-moltox21: 0.712731 test loss: 0.415946
[Epoch 86; Iter    15/  183] train: loss: 0.0382295
[Epoch 86; Iter    45/  183] train: loss: 0.0823103
[Epoch 86; Iter    75/  183] train: loss: 0.0596908
[Epoch 86; Iter   105/  183] train: loss: 0.1117923
[Epoch 86; Iter   135/  183] train: loss: 0.0741381
[Epoch 86; Iter   165/  183] train: loss: 0.0591189
[Epoch 86] ogbg-moltox21: 0.741163 val loss: 0.381014
[Epoch 86] ogbg-moltox21: 0.715012 test loss: 0.418509
[Epoch 87; Iter    12/  183] train: loss: 0.0572687
[Epoch 87; Iter    42/  183] train: loss: 0.0563191
[Epoch 87; Iter    72/  183] train: loss: 0.0704382
[Epoch 87; Iter   102/  183] train: loss: 0.0454663
[Epoch 87; Iter   132/  183] train: loss: 0.0689932
[Epoch 87; Iter   162/  183] train: loss: 0.0854801
[Epoch 87] ogbg-moltox21: 0.742781 val loss: 0.372380
[Epoch 87] ogbg-moltox21: 0.719942 test loss: 0.403549
[Epoch 88; Iter     9/  183] train: loss: 0.0856353
[Epoch 88; Iter    39/  183] train: loss: 0.0499958
[Epoch 88; Iter    69/  183] train: loss: 0.0589256
[Epoch 88; Iter    99/  183] train: loss: 0.0542847
[Epoch 88; Iter   129/  183] train: loss: 0.0791007
[Epoch 88; Iter   159/  183] train: loss: 0.0480736
[Epoch 88] ogbg-moltox21: 0.744782 val loss: 0.381459
[Epoch 88] ogbg-moltox21: 0.713677 test loss: 0.433626
[Epoch 89; Iter     6/  183] train: loss: 0.0443953
[Epoch 89; Iter    36/  183] train: loss: 0.0362292
[Epoch 89; Iter    66/  183] train: loss: 0.0415992
[Epoch 89; Iter    96/  183] train: loss: 0.0677522
[Epoch 89; Iter   126/  183] train: loss: 0.0572709
[Epoch 89; Iter   156/  183] train: loss: 0.0705356
[Epoch 89] ogbg-moltox21: 0.742337 val loss: 0.385260
[Epoch 89] ogbg-moltox21: 0.719260 test loss: 0.436611
[Epoch 90; Iter     3/  183] train: loss: 0.0837314
[Epoch 90; Iter    33/  183] train: loss: 0.0514523
[Epoch 90; Iter    63/  183] train: loss: 0.0889696
[Epoch 90; Iter    93/  183] train: loss: 0.0676796
[Epoch 90; Iter   123/  183] train: loss: 0.0500888
[Epoch 90; Iter   153/  183] train: loss: 0.0744057
[Epoch 90; Iter   183/  183] train: loss: 0.0404166
[Epoch 71; Iter   180/  183] train: loss: 0.1190140
[Epoch 71] ogbg-moltox21: 0.752068 val loss: 0.336543
[Epoch 71] ogbg-moltox21: 0.719122 test loss: 0.370929
[Epoch 72; Iter    27/  183] train: loss: 0.0462443
[Epoch 72; Iter    57/  183] train: loss: 0.1202196
[Epoch 72; Iter    87/  183] train: loss: 0.0829603
[Epoch 72; Iter   117/  183] train: loss: 0.0924898
[Epoch 72; Iter   147/  183] train: loss: 0.0905416
[Epoch 72; Iter   177/  183] train: loss: 0.0705659
[Epoch 72] ogbg-moltox21: 0.749632 val loss: 0.332548
[Epoch 72] ogbg-moltox21: 0.721025 test loss: 0.365562
[Epoch 73; Iter    24/  183] train: loss: 0.0604062
[Epoch 73; Iter    54/  183] train: loss: 0.0642266
[Epoch 73; Iter    84/  183] train: loss: 0.0758857
[Epoch 73; Iter   114/  183] train: loss: 0.0674644
[Epoch 73; Iter   144/  183] train: loss: 0.0643381
[Epoch 73; Iter   174/  183] train: loss: 0.0734812
[Epoch 73] ogbg-moltox21: 0.741323 val loss: 0.337751
[Epoch 73] ogbg-moltox21: 0.723009 test loss: 0.362440
[Epoch 74; Iter    21/  183] train: loss: 0.0826404
[Epoch 74; Iter    51/  183] train: loss: 0.0986938
[Epoch 74; Iter    81/  183] train: loss: 0.0799617
[Epoch 74; Iter   111/  183] train: loss: 0.0695559
[Epoch 74; Iter   141/  183] train: loss: 0.0595097
[Epoch 74; Iter   171/  183] train: loss: 0.0978206
[Epoch 74] ogbg-moltox21: 0.742103 val loss: 0.353357
[Epoch 74] ogbg-moltox21: 0.719791 test loss: 0.387452
[Epoch 75; Iter    18/  183] train: loss: 0.0782788
[Epoch 75; Iter    48/  183] train: loss: 0.0446754
[Epoch 75; Iter    78/  183] train: loss: 0.0362476
[Epoch 75; Iter   108/  183] train: loss: 0.0729897
[Epoch 75; Iter   138/  183] train: loss: 0.0803310
[Epoch 75; Iter   168/  183] train: loss: 0.0720328
[Epoch 75] ogbg-moltox21: 0.746589 val loss: 0.348007
[Epoch 75] ogbg-moltox21: 0.716660 test loss: 0.387898
[Epoch 76; Iter    15/  183] train: loss: 0.1606893
[Epoch 76; Iter    45/  183] train: loss: 0.0695898
[Epoch 76; Iter    75/  183] train: loss: 0.0848461
[Epoch 76; Iter   105/  183] train: loss: 0.0752520
[Epoch 76; Iter   135/  183] train: loss: 0.0446747
[Epoch 76; Iter   165/  183] train: loss: 0.1028783
[Epoch 76] ogbg-moltox21: 0.743437 val loss: 0.361751
[Epoch 76] ogbg-moltox21: 0.717064 test loss: 0.397562
[Epoch 77; Iter    12/  183] train: loss: 0.0754263
[Epoch 77; Iter    42/  183] train: loss: 0.0591679
[Epoch 77; Iter    72/  183] train: loss: 0.0880749
[Epoch 77; Iter   102/  183] train: loss: 0.0695887
[Epoch 77; Iter   132/  183] train: loss: 0.1224874
[Epoch 77; Iter   162/  183] train: loss: 0.0803501
[Epoch 77] ogbg-moltox21: 0.737184 val loss: 0.372459
[Epoch 77] ogbg-moltox21: 0.710477 test loss: 0.413566
[Epoch 78; Iter     9/  183] train: loss: 0.0473860
[Epoch 78; Iter    39/  183] train: loss: 0.1185052
[Epoch 78; Iter    69/  183] train: loss: 0.0325590
[Epoch 78; Iter    99/  183] train: loss: 0.0858235
[Epoch 78; Iter   129/  183] train: loss: 0.0683217
[Epoch 78; Iter   159/  183] train: loss: 0.0617054
[Epoch 78] ogbg-moltox21: 0.746506 val loss: 0.364129
[Epoch 78] ogbg-moltox21: 0.722298 test loss: 0.395562
[Epoch 79; Iter     6/  183] train: loss: 0.0569885
[Epoch 79; Iter    36/  183] train: loss: 0.0799726
[Epoch 79; Iter    66/  183] train: loss: 0.0889215
[Epoch 79; Iter    96/  183] train: loss: 0.0601281
[Epoch 79; Iter   126/  183] train: loss: 0.0674049
[Epoch 79; Iter   156/  183] train: loss: 0.0799639
[Epoch 79] ogbg-moltox21: 0.732878 val loss: 0.369127
[Epoch 79] ogbg-moltox21: 0.708574 test loss: 0.405158
[Epoch 80; Iter     3/  183] train: loss: 0.0440511
[Epoch 80; Iter    33/  183] train: loss: 0.0638946
[Epoch 80; Iter    63/  183] train: loss: 0.0746762
[Epoch 80; Iter    93/  183] train: loss: 0.0665717
[Epoch 80; Iter   123/  183] train: loss: 0.0705753
[Epoch 80; Iter   153/  183] train: loss: 0.1138239
[Epoch 80; Iter   183/  183] train: loss: 0.0654950
[Epoch 80] ogbg-moltox21: 0.741360 val loss: 0.386371
[Epoch 80] ogbg-moltox21: 0.713195 test loss: 0.428957
[Epoch 81; Iter    30/  183] train: loss: 0.0867895
[Epoch 81; Iter    60/  183] train: loss: 0.0337560
[Epoch 81; Iter    90/  183] train: loss: 0.0908544
[Epoch 81; Iter   120/  183] train: loss: 0.0768201
[Epoch 81; Iter   150/  183] train: loss: 0.0534476
[Epoch 81; Iter   180/  183] train: loss: 0.0719352
[Epoch 81] ogbg-moltox21: 0.739715 val loss: 0.377675
[Epoch 81] ogbg-moltox21: 0.715357 test loss: 0.411266
[Epoch 82; Iter    27/  183] train: loss: 0.1631787
[Epoch 82; Iter    57/  183] train: loss: 0.0422419
[Epoch 82; Iter    87/  183] train: loss: 0.0595817
[Epoch 82; Iter   117/  183] train: loss: 0.0926808
[Epoch 82; Iter   147/  183] train: loss: 0.0539859
[Epoch 82; Iter   177/  183] train: loss: 0.0415121
[Epoch 82] ogbg-moltox21: 0.739543 val loss: 0.372150
[Epoch 82] ogbg-moltox21: 0.713084 test loss: 0.458028
[Epoch 83; Iter    24/  183] train: loss: 0.0410290
[Epoch 83; Iter    54/  183] train: loss: 0.0644103
[Epoch 83; Iter    84/  183] train: loss: 0.0576357
[Epoch 83; Iter   114/  183] train: loss: 0.0792537
[Epoch 83; Iter   144/  183] train: loss: 0.0677061
[Epoch 83; Iter   174/  183] train: loss: 0.0509791
[Epoch 83] ogbg-moltox21: 0.737078 val loss: 0.376404
[Epoch 83] ogbg-moltox21: 0.712002 test loss: 0.424463
[Epoch 84; Iter    21/  183] train: loss: 0.1141423
[Epoch 84; Iter    51/  183] train: loss: 0.0776702
[Epoch 84; Iter    81/  183] train: loss: 0.0401887
[Epoch 84; Iter   111/  183] train: loss: 0.1210056
[Epoch 84; Iter   141/  183] train: loss: 0.0640436
[Epoch 84; Iter   171/  183] train: loss: 0.1425196
[Epoch 84] ogbg-moltox21: 0.741198 val loss: 0.391251
[Epoch 84] ogbg-moltox21: 0.720216 test loss: 0.416373
[Epoch 85; Iter    18/  183] train: loss: 0.0501967
[Epoch 85; Iter    48/  183] train: loss: 0.0445845
[Epoch 85; Iter    78/  183] train: loss: 0.0920463
[Epoch 85; Iter   108/  183] train: loss: 0.0567349
[Epoch 85; Iter   138/  183] train: loss: 0.0994435
[Epoch 85; Iter   168/  183] train: loss: 0.0488148
[Epoch 85] ogbg-moltox21: 0.729799 val loss: 0.403376
[Epoch 85] ogbg-moltox21: 0.713235 test loss: 0.555797
[Epoch 86; Iter    15/  183] train: loss: 0.0702174
[Epoch 86; Iter    45/  183] train: loss: 0.0668079
[Epoch 86; Iter    75/  183] train: loss: 0.0652582
[Epoch 86; Iter   105/  183] train: loss: 0.0537689
[Epoch 86; Iter   135/  183] train: loss: 0.0409929
[Epoch 86; Iter   165/  183] train: loss: 0.0562012
[Epoch 86] ogbg-moltox21: 0.735832 val loss: 0.384453
[Epoch 86] ogbg-moltox21: 0.709037 test loss: 0.458098
[Epoch 87; Iter    12/  183] train: loss: 0.0795209
[Epoch 87; Iter    42/  183] train: loss: 0.0831451
[Epoch 87; Iter    72/  183] train: loss: 0.0618303
[Epoch 87; Iter   102/  183] train: loss: 0.0746693
[Epoch 87; Iter   132/  183] train: loss: 0.0658903
[Epoch 87; Iter   162/  183] train: loss: 0.0633709
[Epoch 87] ogbg-moltox21: 0.740255 val loss: 0.399950
[Epoch 87] ogbg-moltox21: 0.715806 test loss: 0.513642
[Epoch 88; Iter     9/  183] train: loss: 0.0684197
[Epoch 88; Iter    39/  183] train: loss: 0.0819739
[Epoch 88; Iter    69/  183] train: loss: 0.0523860
[Epoch 88; Iter    99/  183] train: loss: 0.0290112
[Epoch 88; Iter   129/  183] train: loss: 0.0435608
[Epoch 88; Iter   159/  183] train: loss: 0.0517087
[Epoch 88] ogbg-moltox21: 0.736511 val loss: 0.403077
[Epoch 88] ogbg-moltox21: 0.711751 test loss: 0.516737
[Epoch 89; Iter     6/  183] train: loss: 0.0595396
[Epoch 89; Iter    36/  183] train: loss: 0.0684063
[Epoch 89; Iter    66/  183] train: loss: 0.0623679
[Epoch 89; Iter    96/  183] train: loss: 0.0397862
[Epoch 89; Iter   126/  183] train: loss: 0.0523516
[Epoch 89; Iter   156/  183] train: loss: 0.0672518
[Epoch 89] ogbg-moltox21: 0.737486 val loss: 0.390562
[Epoch 89] ogbg-moltox21: 0.715784 test loss: 0.469915
[Epoch 90; Iter     3/  183] train: loss: 0.0403979
[Epoch 90; Iter    33/  183] train: loss: 0.0472409
[Epoch 90; Iter    63/  183] train: loss: 0.0549421
[Epoch 90; Iter    93/  183] train: loss: 0.0562424
[Epoch 90; Iter   123/  183] train: loss: 0.0498549
[Epoch 90; Iter   153/  183] train: loss: 0.0938140
[Epoch 90; Iter   183/  183] train: loss: 0.1061009
[Epoch 71; Iter   180/  183] train: loss: 0.0966119
[Epoch 71] ogbg-moltox21: 0.737190 val loss: 0.388067
[Epoch 71] ogbg-moltox21: 0.723424 test loss: 0.405901
[Epoch 72; Iter    27/  183] train: loss: 0.0528507
[Epoch 72; Iter    57/  183] train: loss: 0.0846796
[Epoch 72; Iter    87/  183] train: loss: 0.1094322
[Epoch 72; Iter   117/  183] train: loss: 0.0552193
[Epoch 72; Iter   147/  183] train: loss: 0.0512652
[Epoch 72; Iter   177/  183] train: loss: 0.1211880
[Epoch 72] ogbg-moltox21: 0.737629 val loss: 0.386876
[Epoch 72] ogbg-moltox21: 0.721350 test loss: 0.404051
[Epoch 73; Iter    24/  183] train: loss: 0.0473477
[Epoch 73; Iter    54/  183] train: loss: 0.0739570
[Epoch 73; Iter    84/  183] train: loss: 0.1368900
[Epoch 73; Iter   114/  183] train: loss: 0.0570005
[Epoch 73; Iter   144/  183] train: loss: 0.0570283
[Epoch 73; Iter   174/  183] train: loss: 0.0644076
[Epoch 73] ogbg-moltox21: 0.743910 val loss: 0.380006
[Epoch 73] ogbg-moltox21: 0.725929 test loss: 0.399473
[Epoch 74; Iter    21/  183] train: loss: 0.0327525
[Epoch 74; Iter    51/  183] train: loss: 0.0620075
[Epoch 74; Iter    81/  183] train: loss: 0.0548806
[Epoch 74; Iter   111/  183] train: loss: 0.0401202
[Epoch 74; Iter   141/  183] train: loss: 0.0828848
[Epoch 74; Iter   171/  183] train: loss: 0.0685879
[Epoch 74] ogbg-moltox21: 0.742411 val loss: 0.386782
[Epoch 74] ogbg-moltox21: 0.727302 test loss: 0.399641
[Epoch 75; Iter    18/  183] train: loss: 0.0655295
[Epoch 75; Iter    48/  183] train: loss: 0.0428436
[Epoch 75; Iter    78/  183] train: loss: 0.0677861
[Epoch 75; Iter   108/  183] train: loss: 0.0401629
[Epoch 75; Iter   138/  183] train: loss: 0.0476730
[Epoch 75; Iter   168/  183] train: loss: 0.0514523
[Epoch 75] ogbg-moltox21: 0.740479 val loss: 0.386730
[Epoch 75] ogbg-moltox21: 0.726463 test loss: 0.403268
[Epoch 76; Iter    15/  183] train: loss: 0.0969963
[Epoch 76; Iter    45/  183] train: loss: 0.0675908
[Epoch 76; Iter    75/  183] train: loss: 0.0432133
[Epoch 76; Iter   105/  183] train: loss: 0.0527336
[Epoch 76; Iter   135/  183] train: loss: 0.0529732
[Epoch 76; Iter   165/  183] train: loss: 0.0564328
[Epoch 76] ogbg-moltox21: 0.737721 val loss: 0.393782
[Epoch 76] ogbg-moltox21: 0.723229 test loss: 0.414822
[Epoch 77; Iter    12/  183] train: loss: 0.0652005
[Epoch 77; Iter    42/  183] train: loss: 0.0679315
[Epoch 77; Iter    72/  183] train: loss: 0.0710501
[Epoch 77; Iter   102/  183] train: loss: 0.0584777
[Epoch 77; Iter   132/  183] train: loss: 0.0626126
[Epoch 77; Iter   162/  183] train: loss: 0.0476481
[Epoch 77] ogbg-moltox21: 0.736051 val loss: 0.405379
[Epoch 77] ogbg-moltox21: 0.721328 test loss: 0.412493
[Epoch 78; Iter     9/  183] train: loss: 0.0373486
[Epoch 78; Iter    39/  183] train: loss: 0.0564786
[Epoch 78; Iter    69/  183] train: loss: 0.0614591
[Epoch 78; Iter    99/  183] train: loss: 0.0780957
[Epoch 78; Iter   129/  183] train: loss: 0.0495306
[Epoch 78; Iter   159/  183] train: loss: 0.0597872
[Epoch 78] ogbg-moltox21: 0.740253 val loss: 0.431940
[Epoch 78] ogbg-moltox21: 0.725190 test loss: 0.424404
[Epoch 79; Iter     6/  183] train: loss: 0.0724593
[Epoch 79; Iter    36/  183] train: loss: 0.0561384
[Epoch 79; Iter    66/  183] train: loss: 0.0596602
[Epoch 79; Iter    96/  183] train: loss: 0.0358031
[Epoch 79; Iter   126/  183] train: loss: 0.0743148
[Epoch 79; Iter   156/  183] train: loss: 0.0405403
[Epoch 79] ogbg-moltox21: 0.736666 val loss: 0.408770
[Epoch 79] ogbg-moltox21: 0.726425 test loss: 0.412050
[Epoch 80; Iter     3/  183] train: loss: 0.0627632
[Epoch 80; Iter    33/  183] train: loss: 0.0493907
[Epoch 80; Iter    63/  183] train: loss: 0.0298361
[Epoch 80; Iter    93/  183] train: loss: 0.0583790
[Epoch 80; Iter   123/  183] train: loss: 0.0714199
[Epoch 80; Iter   153/  183] train: loss: 0.0249613
[Epoch 80; Iter   183/  183] train: loss: 0.1042441
[Epoch 80] ogbg-moltox21: 0.736379 val loss: 0.417237
[Epoch 80] ogbg-moltox21: 0.725290 test loss: 0.414082
[Epoch 81; Iter    30/  183] train: loss: 0.0408110
[Epoch 81; Iter    60/  183] train: loss: 0.1126755
[Epoch 81; Iter    90/  183] train: loss: 0.0928978
[Epoch 81; Iter   120/  183] train: loss: 0.0331739
[Epoch 81; Iter   150/  183] train: loss: 0.0499463
[Epoch 81; Iter   180/  183] train: loss: 0.0716433
[Epoch 81] ogbg-moltox21: 0.734986 val loss: 0.445295
[Epoch 81] ogbg-moltox21: 0.717646 test loss: 0.448900
[Epoch 82; Iter    27/  183] train: loss: 0.0375747
[Epoch 82; Iter    57/  183] train: loss: 0.0668655
[Epoch 82; Iter    87/  183] train: loss: 0.0644213
[Epoch 82; Iter   117/  183] train: loss: 0.0716496
[Epoch 82; Iter   147/  183] train: loss: 0.0292944
[Epoch 82; Iter   177/  183] train: loss: 0.0705225
[Epoch 82] ogbg-moltox21: 0.741563 val loss: 0.429305
[Epoch 82] ogbg-moltox21: 0.725096 test loss: 0.433023
[Epoch 83; Iter    24/  183] train: loss: 0.0470869
[Epoch 83; Iter    54/  183] train: loss: 0.1539295
[Epoch 83; Iter    84/  183] train: loss: 0.0511951
[Epoch 83; Iter   114/  183] train: loss: 0.0299703
[Epoch 83; Iter   144/  183] train: loss: 0.0606354
[Epoch 83; Iter   174/  183] train: loss: 0.0481629
[Epoch 83] ogbg-moltox21: 0.736380 val loss: 0.434605
[Epoch 83] ogbg-moltox21: 0.721852 test loss: 0.435189
[Epoch 84; Iter    21/  183] train: loss: 0.0524469
[Epoch 84; Iter    51/  183] train: loss: 0.0886346
[Epoch 84; Iter    81/  183] train: loss: 0.0855346
[Epoch 84; Iter   111/  183] train: loss: 0.0432011
[Epoch 84; Iter   141/  183] train: loss: 0.0771977
[Epoch 84; Iter   171/  183] train: loss: 0.0404044
[Epoch 84] ogbg-moltox21: 0.744261 val loss: 0.463933
[Epoch 84] ogbg-moltox21: 0.718473 test loss: 0.452920
[Epoch 85; Iter    18/  183] train: loss: 0.0490008
[Epoch 85; Iter    48/  183] train: loss: 0.0620287
[Epoch 85; Iter    78/  183] train: loss: 0.1288943
[Epoch 85; Iter   108/  183] train: loss: 0.0569822
[Epoch 85; Iter   138/  183] train: loss: 0.0473745
[Epoch 85; Iter   168/  183] train: loss: 0.0419333
[Epoch 85] ogbg-moltox21: 0.735355 val loss: 0.455834
[Epoch 85] ogbg-moltox21: 0.708201 test loss: 0.443770
[Epoch 86; Iter    15/  183] train: loss: 0.0636187
[Epoch 86; Iter    45/  183] train: loss: 0.0661422
[Epoch 86; Iter    75/  183] train: loss: 0.0475903
[Epoch 86; Iter   105/  183] train: loss: 0.0618187
[Epoch 86; Iter   135/  183] train: loss: 0.0674565
[Epoch 86; Iter   165/  183] train: loss: 0.0417702
[Epoch 86] ogbg-moltox21: 0.744015 val loss: 0.448895
[Epoch 86] ogbg-moltox21: 0.722695 test loss: 0.441230
[Epoch 87; Iter    12/  183] train: loss: 0.0569025
[Epoch 87; Iter    42/  183] train: loss: 0.0328295
[Epoch 87; Iter    72/  183] train: loss: 0.0426777
[Epoch 87; Iter   102/  183] train: loss: 0.0340448
[Epoch 87; Iter   132/  183] train: loss: 0.0532489
[Epoch 87; Iter   162/  183] train: loss: 0.0596898
[Epoch 87] ogbg-moltox21: 0.733026 val loss: 0.484370
[Epoch 87] ogbg-moltox21: 0.711428 test loss: 0.456845
[Epoch 88; Iter     9/  183] train: loss: 0.0460002
[Epoch 88; Iter    39/  183] train: loss: 0.0831970
[Epoch 88; Iter    69/  183] train: loss: 0.0912820
[Epoch 88; Iter    99/  183] train: loss: 0.0514836
[Epoch 88; Iter   129/  183] train: loss: 0.0556214
[Epoch 88; Iter   159/  183] train: loss: 0.0556145
[Epoch 88] ogbg-moltox21: 0.743714 val loss: 0.447211
[Epoch 88] ogbg-moltox21: 0.716692 test loss: 0.455184
[Epoch 89; Iter     6/  183] train: loss: 0.0593511
[Epoch 89; Iter    36/  183] train: loss: 0.0358697
[Epoch 89; Iter    66/  183] train: loss: 0.0319408
[Epoch 89; Iter    96/  183] train: loss: 0.0246228
[Epoch 89; Iter   126/  183] train: loss: 0.0906060
[Epoch 89; Iter   156/  183] train: loss: 0.0716468
[Epoch 89] ogbg-moltox21: 0.735957 val loss: 0.440587
[Epoch 89] ogbg-moltox21: 0.714343 test loss: 0.457495
[Epoch 90; Iter     3/  183] train: loss: 0.0245168
[Epoch 90; Iter    33/  183] train: loss: 0.0258525
[Epoch 90; Iter    63/  183] train: loss: 0.0553714
[Epoch 90; Iter    93/  183] train: loss: 0.0522427
[Epoch 90; Iter   123/  183] train: loss: 0.0233784
[Epoch 90; Iter   153/  183] train: loss: 0.1184805
[Epoch 90; Iter   183/  183] train: loss: 0.0823376
[Epoch 80; Iter    47/  157] train: loss: 0.0734300
[Epoch 80; Iter    77/  157] train: loss: 0.0314929
[Epoch 80; Iter   107/  157] train: loss: 0.0719149
[Epoch 80; Iter   137/  157] train: loss: 0.1632068
[Epoch 80] ogbg-moltox21: 0.709664 val loss: 0.470328
[Epoch 80] ogbg-moltox21: 0.703416 test loss: 0.468004
[Epoch 81; Iter    10/  157] train: loss: 0.0335971
[Epoch 81; Iter    40/  157] train: loss: 0.0347316
[Epoch 81; Iter    70/  157] train: loss: 0.0987114
[Epoch 81; Iter   100/  157] train: loss: 0.0441773
[Epoch 81; Iter   130/  157] train: loss: 0.1271343
[Epoch 81] ogbg-moltox21: 0.707362 val loss: 0.555246
[Epoch 81] ogbg-moltox21: 0.701456 test loss: 0.511777
[Epoch 82; Iter     3/  157] train: loss: 0.0604057
[Epoch 82; Iter    33/  157] train: loss: 0.0400068
[Epoch 82; Iter    63/  157] train: loss: 0.0492218
[Epoch 82; Iter    93/  157] train: loss: 0.0657272
[Epoch 82; Iter   123/  157] train: loss: 0.0484786
[Epoch 82; Iter   153/  157] train: loss: 0.0625937
[Epoch 82] ogbg-moltox21: 0.715056 val loss: 0.467325
[Epoch 82] ogbg-moltox21: 0.706915 test loss: 0.477111
[Epoch 83; Iter    26/  157] train: loss: 0.0759042
[Epoch 83; Iter    56/  157] train: loss: 0.0406205
[Epoch 83; Iter    86/  157] train: loss: 0.0513778
[Epoch 83; Iter   116/  157] train: loss: 0.0923396
[Epoch 83; Iter   146/  157] train: loss: 0.0555973
[Epoch 83] ogbg-moltox21: 0.702561 val loss: 0.502985
[Epoch 83] ogbg-moltox21: 0.699462 test loss: 0.482383
[Epoch 84; Iter    19/  157] train: loss: 0.0356372
[Epoch 84; Iter    49/  157] train: loss: 0.1269854
[Epoch 84; Iter    79/  157] train: loss: 0.0540582
[Epoch 84; Iter   109/  157] train: loss: 0.0449185
[Epoch 84; Iter   139/  157] train: loss: 0.0524344
[Epoch 84] ogbg-moltox21: 0.715398 val loss: 0.443395
[Epoch 84] ogbg-moltox21: 0.701595 test loss: 0.446263
[Epoch 85; Iter    12/  157] train: loss: 0.0592524
[Epoch 85; Iter    42/  157] train: loss: 0.0513073
[Epoch 85; Iter    72/  157] train: loss: 0.0667066
[Epoch 85; Iter   102/  157] train: loss: 0.0638858
[Epoch 85; Iter   132/  157] train: loss: 0.0478824
[Epoch 85] ogbg-moltox21: 0.712388 val loss: 0.513988
[Epoch 85] ogbg-moltox21: 0.702251 test loss: 0.488528
[Epoch 86; Iter     5/  157] train: loss: 0.0594731
[Epoch 86; Iter    35/  157] train: loss: 0.1146055
[Epoch 86; Iter    65/  157] train: loss: 0.0543575
[Epoch 86; Iter    95/  157] train: loss: 0.0564557
[Epoch 86; Iter   125/  157] train: loss: 0.0423050
[Epoch 86; Iter   155/  157] train: loss: 0.0713011
[Epoch 86] ogbg-moltox21: 0.701990 val loss: 0.489451
[Epoch 86] ogbg-moltox21: 0.696231 test loss: 0.492319
[Epoch 87; Iter    28/  157] train: loss: 0.0483435
[Epoch 87; Iter    58/  157] train: loss: 0.0484951
[Epoch 87; Iter    88/  157] train: loss: 0.0602771
[Epoch 87; Iter   118/  157] train: loss: 0.0928245
[Epoch 87; Iter   148/  157] train: loss: 0.0434491
[Epoch 87] ogbg-moltox21: 0.712095 val loss: 0.483185
[Epoch 87] ogbg-moltox21: 0.709785 test loss: 0.464145
[Epoch 88; Iter    21/  157] train: loss: 0.0482295
[Epoch 88; Iter    51/  157] train: loss: 0.0498442
[Epoch 88; Iter    81/  157] train: loss: 0.0682562
[Epoch 88; Iter   111/  157] train: loss: 0.0764189
[Epoch 88; Iter   141/  157] train: loss: 0.0327073
[Epoch 88] ogbg-moltox21: 0.706007 val loss: 0.527458
[Epoch 88] ogbg-moltox21: 0.703422 test loss: 0.495607
[Epoch 89; Iter    14/  157] train: loss: 0.0631782
[Epoch 89; Iter    44/  157] train: loss: 0.0725745
[Epoch 89; Iter    74/  157] train: loss: 0.0501947
[Epoch 89; Iter   104/  157] train: loss: 0.0508072
[Epoch 89; Iter   134/  157] train: loss: 0.0416059
[Epoch 89] ogbg-moltox21: 0.716516 val loss: 0.520401
[Epoch 89] ogbg-moltox21: 0.707572 test loss: 0.502480
[Epoch 90; Iter     7/  157] train: loss: 0.0465946
[Epoch 90; Iter    37/  157] train: loss: 0.0416594
[Epoch 90; Iter    67/  157] train: loss: 0.0639178
[Epoch 90; Iter    97/  157] train: loss: 0.0548586
[Epoch 90; Iter   127/  157] train: loss: 0.0541308
[Epoch 90; Iter   157/  157] train: loss: 0.0845813
[Epoch 90] ogbg-moltox21: 0.705178 val loss: 0.540679
[Epoch 90] ogbg-moltox21: 0.701306 test loss: 0.502234
[Epoch 91; Iter    30/  157] train: loss: 0.0465109
[Epoch 91; Iter    60/  157] train: loss: 0.0368819
[Epoch 91; Iter    90/  157] train: loss: 0.0347418
[Epoch 91; Iter   120/  157] train: loss: 0.0444877
[Epoch 91; Iter   150/  157] train: loss: 0.0532824
[Epoch 91] ogbg-moltox21: 0.706094 val loss: 0.610212
[Epoch 91] ogbg-moltox21: 0.700129 test loss: 0.509922
[Epoch 92; Iter    23/  157] train: loss: 0.0471244
[Epoch 92; Iter    53/  157] train: loss: 0.0607335
[Epoch 92; Iter    83/  157] train: loss: 0.0529200
[Epoch 92; Iter   113/  157] train: loss: 0.0432830
[Epoch 92; Iter   143/  157] train: loss: 0.0398865
[Epoch 92] ogbg-moltox21: 0.705054 val loss: 0.524570
[Epoch 92] ogbg-moltox21: 0.700655 test loss: 0.486613
[Epoch 93; Iter    16/  157] train: loss: 0.0468446
[Epoch 93; Iter    46/  157] train: loss: 0.0472008
[Epoch 93; Iter    76/  157] train: loss: 0.0228413
[Epoch 93; Iter   106/  157] train: loss: 0.0580336
[Epoch 93; Iter   136/  157] train: loss: 0.0366256
[Epoch 93] ogbg-moltox21: 0.707190 val loss: 0.571514
[Epoch 93] ogbg-moltox21: 0.705679 test loss: 0.528532
[Epoch 94; Iter     9/  157] train: loss: 0.0435453
[Epoch 94; Iter    39/  157] train: loss: 0.0326454
[Epoch 94; Iter    69/  157] train: loss: 0.0374725
[Epoch 94; Iter    99/  157] train: loss: 0.0629771
[Epoch 94; Iter   129/  157] train: loss: 0.0485665
[Epoch 94] ogbg-moltox21: 0.697118 val loss: 0.498394
[Epoch 94] ogbg-moltox21: 0.693276 test loss: 0.504816
[Epoch 95; Iter     2/  157] train: loss: 0.0489448
[Epoch 95; Iter    32/  157] train: loss: 0.0444618
[Epoch 95; Iter    62/  157] train: loss: 0.0456370
[Epoch 95; Iter    92/  157] train: loss: 0.0530100
[Epoch 95; Iter   122/  157] train: loss: 0.0571122
[Epoch 95; Iter   152/  157] train: loss: 0.0578407
[Epoch 95] ogbg-moltox21: 0.706623 val loss: 0.571457
[Epoch 95] ogbg-moltox21: 0.702161 test loss: 0.481085
[Epoch 96; Iter    25/  157] train: loss: 0.0479732
[Epoch 96; Iter    55/  157] train: loss: 0.0300828
[Epoch 96; Iter    85/  157] train: loss: 0.0389244
[Epoch 96; Iter   115/  157] train: loss: 0.0255126
[Epoch 96; Iter   145/  157] train: loss: 0.0605784
[Epoch 96] ogbg-moltox21: 0.704963 val loss: 0.543703
[Epoch 96] ogbg-moltox21: 0.697163 test loss: 0.502349
[Epoch 97; Iter    18/  157] train: loss: 0.0378663
[Epoch 97; Iter    48/  157] train: loss: 0.0700185
[Epoch 97; Iter    78/  157] train: loss: 0.0286162
[Epoch 97; Iter   108/  157] train: loss: 0.0390377
[Epoch 97; Iter   138/  157] train: loss: 0.0409376
[Epoch 97] ogbg-moltox21: 0.706167 val loss: 0.501809
[Epoch 97] ogbg-moltox21: 0.700531 test loss: 0.494457
[Epoch 98; Iter    11/  157] train: loss: 0.0389954
[Epoch 98; Iter    41/  157] train: loss: 0.0219711
[Epoch 98; Iter    71/  157] train: loss: 0.0181447
[Epoch 98; Iter   101/  157] train: loss: 0.0216861
[Epoch 98; Iter   131/  157] train: loss: 0.0257552
[Epoch 98] ogbg-moltox21: 0.692592 val loss: 0.497313
[Epoch 98] ogbg-moltox21: 0.689325 test loss: 0.499692
[Epoch 99; Iter     4/  157] train: loss: 0.0271541
[Epoch 99; Iter    34/  157] train: loss: 0.0222181
[Epoch 99; Iter    64/  157] train: loss: 0.0495420
[Epoch 99; Iter    94/  157] train: loss: 0.0353192
[Epoch 99; Iter   124/  157] train: loss: 0.0426319
[Epoch 99; Iter   154/  157] train: loss: 0.0364111
[Epoch 99] ogbg-moltox21: 0.698932 val loss: 0.565926
[Epoch 99] ogbg-moltox21: 0.693257 test loss: 0.516720
[Epoch 100; Iter    27/  157] train: loss: 0.0458374
[Epoch 100; Iter    57/  157] train: loss: 0.0341796
[Epoch 100; Iter    87/  157] train: loss: 0.0649240
[Epoch 100; Iter   117/  157] train: loss: 0.0327024
[Epoch 100; Iter   147/  157] train: loss: 0.0397619
[Epoch 100] ogbg-moltox21: 0.701192 val loss: 0.530006
[Epoch 100] ogbg-moltox21: 0.697796 test loss: 0.533715
[Epoch 101; Iter    20/  157] train: loss: 0.0675148
[Epoch 101; Iter    50/  157] train: loss: 0.0486071
[Epoch 101; Iter    80/  157] train: loss: 0.0508975
[Epoch 101; Iter   110/  157] train: loss: 0.0515294
[Epoch 80; Iter    47/  157] train: loss: 0.0809700
[Epoch 80; Iter    77/  157] train: loss: 0.0589436
[Epoch 80; Iter   107/  157] train: loss: 0.0737262
[Epoch 80; Iter   137/  157] train: loss: 0.0433174
[Epoch 80] ogbg-moltox21: 0.750214 val loss: 0.347153
[Epoch 80] ogbg-moltox21: 0.720741 test loss: 0.376832
[Epoch 81; Iter    10/  157] train: loss: 0.0910545
[Epoch 81; Iter    40/  157] train: loss: 0.0691878
[Epoch 81; Iter    70/  157] train: loss: 0.0802439
[Epoch 81; Iter   100/  157] train: loss: 0.0627645
[Epoch 81; Iter   130/  157] train: loss: 0.1071121
[Epoch 81] ogbg-moltox21: 0.742430 val loss: 0.360448
[Epoch 81] ogbg-moltox21: 0.717777 test loss: 0.385661
[Epoch 82; Iter     3/  157] train: loss: 0.0998257
[Epoch 82; Iter    33/  157] train: loss: 0.0598434
[Epoch 82; Iter    63/  157] train: loss: 0.1035461
[Epoch 82; Iter    93/  157] train: loss: 0.1097245
[Epoch 82; Iter   123/  157] train: loss: 0.0766068
[Epoch 82; Iter   153/  157] train: loss: 0.0882978
[Epoch 82] ogbg-moltox21: 0.749192 val loss: 0.360541
[Epoch 82] ogbg-moltox21: 0.722326 test loss: 0.395101
[Epoch 83; Iter    26/  157] train: loss: 0.0693138
[Epoch 83; Iter    56/  157] train: loss: 0.1298391
[Epoch 83; Iter    86/  157] train: loss: 0.0451338
[Epoch 83; Iter   116/  157] train: loss: 0.0897665
[Epoch 83; Iter   146/  157] train: loss: 0.0796023
[Epoch 83] ogbg-moltox21: 0.752275 val loss: 0.367145
[Epoch 83] ogbg-moltox21: 0.728072 test loss: 0.394388
[Epoch 84; Iter    19/  157] train: loss: 0.0497292
[Epoch 84; Iter    49/  157] train: loss: 0.0873473
[Epoch 84; Iter    79/  157] train: loss: 0.1066076
[Epoch 84; Iter   109/  157] train: loss: 0.0936930
[Epoch 84; Iter   139/  157] train: loss: 0.0566409
[Epoch 84] ogbg-moltox21: 0.747748 val loss: 0.377329
[Epoch 84] ogbg-moltox21: 0.725145 test loss: 0.405765
[Epoch 85; Iter    12/  157] train: loss: 0.0607530
[Epoch 85; Iter    42/  157] train: loss: 0.0540533
[Epoch 85; Iter    72/  157] train: loss: 0.1485864
[Epoch 85; Iter   102/  157] train: loss: 0.0660398
[Epoch 85; Iter   132/  157] train: loss: 0.0825804
[Epoch 85] ogbg-moltox21: 0.749397 val loss: 0.363915
[Epoch 85] ogbg-moltox21: 0.721602 test loss: 0.395569
[Epoch 86; Iter     5/  157] train: loss: 0.0889117
[Epoch 86; Iter    35/  157] train: loss: 0.0666787
[Epoch 86; Iter    65/  157] train: loss: 0.0909027
[Epoch 86; Iter    95/  157] train: loss: 0.0399101
[Epoch 86; Iter   125/  157] train: loss: 0.0534853
[Epoch 86; Iter   155/  157] train: loss: 0.0492341
[Epoch 86] ogbg-moltox21: 0.742243 val loss: 0.386897
[Epoch 86] ogbg-moltox21: 0.715461 test loss: 0.412598
[Epoch 87; Iter    28/  157] train: loss: 0.0729254
[Epoch 87; Iter    58/  157] train: loss: 0.0664712
[Epoch 87; Iter    88/  157] train: loss: 0.0419610
[Epoch 87; Iter   118/  157] train: loss: 0.0777074
[Epoch 87; Iter   148/  157] train: loss: 0.0817761
[Epoch 87] ogbg-moltox21: 0.743108 val loss: 0.371579
[Epoch 87] ogbg-moltox21: 0.718475 test loss: 0.404225
[Epoch 88; Iter    21/  157] train: loss: 0.0737282
[Epoch 88; Iter    51/  157] train: loss: 0.1221954
[Epoch 88; Iter    81/  157] train: loss: 0.0495702
[Epoch 88; Iter   111/  157] train: loss: 0.0749660
[Epoch 88; Iter   141/  157] train: loss: 0.1085600
[Epoch 88] ogbg-moltox21: 0.746205 val loss: 0.375012
[Epoch 88] ogbg-moltox21: 0.715973 test loss: 0.408474
[Epoch 89; Iter    14/  157] train: loss: 0.0483997
[Epoch 89; Iter    44/  157] train: loss: 0.1124436
[Epoch 89; Iter    74/  157] train: loss: 0.1167929
[Epoch 89; Iter   104/  157] train: loss: 0.0833150
[Epoch 89; Iter   134/  157] train: loss: 0.0816975
[Epoch 89] ogbg-moltox21: 0.737971 val loss: 0.390669
[Epoch 89] ogbg-moltox21: 0.714949 test loss: 0.413821
[Epoch 90; Iter     7/  157] train: loss: 0.0626530
[Epoch 90; Iter    37/  157] train: loss: 0.0516545
[Epoch 90; Iter    67/  157] train: loss: 0.0400430
[Epoch 90; Iter    97/  157] train: loss: 0.0577921
[Epoch 90; Iter   127/  157] train: loss: 0.0644149
[Epoch 90; Iter   157/  157] train: loss: 0.0392755
[Epoch 90] ogbg-moltox21: 0.736011 val loss: 0.391000
[Epoch 90] ogbg-moltox21: 0.714385 test loss: 0.417966
[Epoch 91; Iter    30/  157] train: loss: 0.0476930
[Epoch 91; Iter    60/  157] train: loss: 0.0795118
[Epoch 91; Iter    90/  157] train: loss: 0.0954733
[Epoch 91; Iter   120/  157] train: loss: 0.0794651
[Epoch 91; Iter   150/  157] train: loss: 0.1016060
[Epoch 91] ogbg-moltox21: 0.737387 val loss: 0.384522
[Epoch 91] ogbg-moltox21: 0.718248 test loss: 0.409439
[Epoch 92; Iter    23/  157] train: loss: 0.0541489
[Epoch 92; Iter    53/  157] train: loss: 0.0745120
[Epoch 92; Iter    83/  157] train: loss: 0.0768087
[Epoch 92; Iter   113/  157] train: loss: 0.0803239
[Epoch 92; Iter   143/  157] train: loss: 0.0848689
[Epoch 92] ogbg-moltox21: 0.739201 val loss: 0.382854
[Epoch 92] ogbg-moltox21: 0.721272 test loss: 0.412277
[Epoch 93; Iter    16/  157] train: loss: 0.0915509
[Epoch 93; Iter    46/  157] train: loss: 0.0841149
[Epoch 93; Iter    76/  157] train: loss: 0.0746148
[Epoch 93; Iter   106/  157] train: loss: 0.0736530
[Epoch 93; Iter   136/  157] train: loss: 0.1130556
[Epoch 93] ogbg-moltox21: 0.743753 val loss: 0.392516
[Epoch 93] ogbg-moltox21: 0.713878 test loss: 0.434643
[Epoch 94; Iter     9/  157] train: loss: 0.0815191
[Epoch 94; Iter    39/  157] train: loss: 0.0572308
[Epoch 94; Iter    69/  157] train: loss: 0.0558544
[Epoch 94; Iter    99/  157] train: loss: 0.0615434
[Epoch 94; Iter   129/  157] train: loss: 0.0724131
[Epoch 94] ogbg-moltox21: 0.737732 val loss: 0.400813
[Epoch 94] ogbg-moltox21: 0.713326 test loss: 0.436868
[Epoch 95; Iter     2/  157] train: loss: 0.0324436
[Epoch 95; Iter    32/  157] train: loss: 0.0695217
[Epoch 95; Iter    62/  157] train: loss: 0.0871948
[Epoch 95; Iter    92/  157] train: loss: 0.0520637
[Epoch 95; Iter   122/  157] train: loss: 0.0232387
[Epoch 95; Iter   152/  157] train: loss: 0.0441080
[Epoch 95] ogbg-moltox21: 0.742891 val loss: 0.399268
[Epoch 95] ogbg-moltox21: 0.721437 test loss: 0.434495
[Epoch 96; Iter    25/  157] train: loss: 0.0512864
[Epoch 96; Iter    55/  157] train: loss: 0.0520399
[Epoch 96; Iter    85/  157] train: loss: 0.0714037
[Epoch 96; Iter   115/  157] train: loss: 0.0341067
[Epoch 96; Iter   145/  157] train: loss: 0.0902800
[Epoch 96] ogbg-moltox21: 0.737838 val loss: 0.395963
[Epoch 96] ogbg-moltox21: 0.715122 test loss: 0.436830
[Epoch 97; Iter    18/  157] train: loss: 0.0604252
[Epoch 97; Iter    48/  157] train: loss: 0.0675796
[Epoch 97; Iter    78/  157] train: loss: 0.0916868
[Epoch 97; Iter   108/  157] train: loss: 0.0504736
[Epoch 97; Iter   138/  157] train: loss: 0.0610628
[Epoch 97] ogbg-moltox21: 0.738608 val loss: 0.398812
[Epoch 97] ogbg-moltox21: 0.715965 test loss: 0.436400
[Epoch 98; Iter    11/  157] train: loss: 0.0713508
[Epoch 98; Iter    41/  157] train: loss: 0.1120042
[Epoch 98; Iter    71/  157] train: loss: 0.0475335
[Epoch 98; Iter   101/  157] train: loss: 0.0895692
[Epoch 98; Iter   131/  157] train: loss: 0.0507380
[Epoch 98] ogbg-moltox21: 0.738390 val loss: 0.391487
[Epoch 98] ogbg-moltox21: 0.713233 test loss: 0.425574
[Epoch 99; Iter     4/  157] train: loss: 0.1016688
[Epoch 99; Iter    34/  157] train: loss: 0.0541314
[Epoch 99; Iter    64/  157] train: loss: 0.0861969
[Epoch 99; Iter    94/  157] train: loss: 0.0740990
[Epoch 99; Iter   124/  157] train: loss: 0.0696783
[Epoch 99; Iter   154/  157] train: loss: 0.0600701
[Epoch 99] ogbg-moltox21: 0.732537 val loss: 0.393872
[Epoch 99] ogbg-moltox21: 0.713105 test loss: 0.418378
[Epoch 100; Iter    27/  157] train: loss: 0.0838876
[Epoch 100; Iter    57/  157] train: loss: 0.0528192
[Epoch 100; Iter    87/  157] train: loss: 0.0987211
[Epoch 100; Iter   117/  157] train: loss: 0.0537966
[Epoch 100; Iter   147/  157] train: loss: 0.0456204
[Epoch 100] ogbg-moltox21: 0.724747 val loss: 0.406565
[Epoch 100] ogbg-moltox21: 0.705059 test loss: 0.432885
[Epoch 101; Iter    20/  157] train: loss: 0.0630919
[Epoch 101; Iter    50/  157] train: loss: 0.0729507
[Epoch 101; Iter    80/  157] train: loss: 0.0696475
[Epoch 101; Iter   110/  157] train: loss: 0.0451357
[Epoch 80; Iter    47/  157] train: loss: 0.0446039
[Epoch 80; Iter    77/  157] train: loss: 0.0733556
[Epoch 80; Iter   107/  157] train: loss: 0.0746580
[Epoch 80; Iter   137/  157] train: loss: 0.0726190
[Epoch 80] ogbg-moltox21: 0.723544 val loss: 0.443428
[Epoch 80] ogbg-moltox21: 0.722182 test loss: 0.432484
[Epoch 81; Iter    10/  157] train: loss: 0.0539425
[Epoch 81; Iter    40/  157] train: loss: 0.0515244
[Epoch 81; Iter    70/  157] train: loss: 0.0699108
[Epoch 81; Iter   100/  157] train: loss: 0.0898677
[Epoch 81; Iter   130/  157] train: loss: 0.0534350
[Epoch 81] ogbg-moltox21: 0.736629 val loss: 0.469102
[Epoch 81] ogbg-moltox21: 0.729972 test loss: 0.454036
[Epoch 82; Iter     3/  157] train: loss: 0.0379113
[Epoch 82; Iter    33/  157] train: loss: 0.0593093
[Epoch 82; Iter    63/  157] train: loss: 0.0784908
[Epoch 82; Iter    93/  157] train: loss: 0.0610524
[Epoch 82; Iter   123/  157] train: loss: 0.0757803
[Epoch 82; Iter   153/  157] train: loss: 0.1016752
[Epoch 82] ogbg-moltox21: 0.737568 val loss: 0.515262
[Epoch 82] ogbg-moltox21: 0.724892 test loss: 0.552938
[Epoch 83; Iter    26/  157] train: loss: 0.0507056
[Epoch 83; Iter    56/  157] train: loss: 0.0723798
[Epoch 83; Iter    86/  157] train: loss: 0.0638848
[Epoch 83; Iter   116/  157] train: loss: 0.0712365
[Epoch 83; Iter   146/  157] train: loss: 0.0603481
[Epoch 83] ogbg-moltox21: 0.741198 val loss: 0.482287
[Epoch 83] ogbg-moltox21: 0.723011 test loss: 0.454836
[Epoch 84; Iter    19/  157] train: loss: 0.0750820
[Epoch 84; Iter    49/  157] train: loss: 0.0634560
[Epoch 84; Iter    79/  157] train: loss: 0.1094116
[Epoch 84; Iter   109/  157] train: loss: 0.0984086
[Epoch 84; Iter   139/  157] train: loss: 0.0790036
[Epoch 84] ogbg-moltox21: 0.722665 val loss: 0.503939
[Epoch 84] ogbg-moltox21: 0.715316 test loss: 0.462808
[Epoch 85; Iter    12/  157] train: loss: 0.0473278
[Epoch 85; Iter    42/  157] train: loss: 0.0647468
[Epoch 85; Iter    72/  157] train: loss: 0.0564660
[Epoch 85; Iter   102/  157] train: loss: 0.0591036
[Epoch 85; Iter   132/  157] train: loss: 0.0487909
[Epoch 85] ogbg-moltox21: 0.721941 val loss: 0.604908
[Epoch 85] ogbg-moltox21: 0.706043 test loss: 0.564039
[Epoch 86; Iter     5/  157] train: loss: 0.0311840
[Epoch 86; Iter    35/  157] train: loss: 0.1226426
[Epoch 86; Iter    65/  157] train: loss: 0.1320615
[Epoch 86; Iter    95/  157] train: loss: 0.0593775
[Epoch 86; Iter   125/  157] train: loss: 0.0715863
[Epoch 86; Iter   155/  157] train: loss: 0.0832757
[Epoch 86] ogbg-moltox21: 0.743258 val loss: 0.479817
[Epoch 86] ogbg-moltox21: 0.727916 test loss: 0.453989
[Epoch 87; Iter    28/  157] train: loss: 0.0411134
[Epoch 87; Iter    58/  157] train: loss: 0.0841606
[Epoch 87; Iter    88/  157] train: loss: 0.1034098
[Epoch 87; Iter   118/  157] train: loss: 0.0701977
[Epoch 87; Iter   148/  157] train: loss: 0.0486890
[Epoch 87] ogbg-moltox21: 0.741860 val loss: 0.434045
[Epoch 87] ogbg-moltox21: 0.726210 test loss: 0.459450
[Epoch 88; Iter    21/  157] train: loss: 0.0582052
[Epoch 88; Iter    51/  157] train: loss: 0.1123081
[Epoch 88; Iter    81/  157] train: loss: 0.0691104
[Epoch 88; Iter   111/  157] train: loss: 0.0535874
[Epoch 88; Iter   141/  157] train: loss: 0.0514703
[Epoch 88] ogbg-moltox21: 0.727244 val loss: 0.459868
[Epoch 88] ogbg-moltox21: 0.722496 test loss: 0.509452
[Epoch 89; Iter    14/  157] train: loss: 0.0410513
[Epoch 89; Iter    44/  157] train: loss: 0.0615420
[Epoch 89; Iter    74/  157] train: loss: 0.0406978
[Epoch 89; Iter   104/  157] train: loss: 0.0450475
[Epoch 89; Iter   134/  157] train: loss: 0.0625945
[Epoch 89] ogbg-moltox21: 0.724463 val loss: 0.638237
[Epoch 89] ogbg-moltox21: 0.723231 test loss: 0.678087
[Epoch 90; Iter     7/  157] train: loss: 0.0507653
[Epoch 90; Iter    37/  157] train: loss: 0.0277889
[Epoch 90; Iter    67/  157] train: loss: 0.0637632
[Epoch 90; Iter    97/  157] train: loss: 0.0563452
[Epoch 90; Iter   127/  157] train: loss: 0.0604117
[Epoch 90; Iter   157/  157] train: loss: 0.1059211
[Epoch 90] ogbg-moltox21: 0.728765 val loss: 0.597894
[Epoch 90] ogbg-moltox21: 0.719752 test loss: 0.516037
[Epoch 91; Iter    30/  157] train: loss: 0.0814328
[Epoch 91; Iter    60/  157] train: loss: 0.0286944
[Epoch 91; Iter    90/  157] train: loss: 0.0434963
[Epoch 91; Iter   120/  157] train: loss: 0.0451783
[Epoch 91; Iter   150/  157] train: loss: 0.0695907
[Epoch 91] ogbg-moltox21: 0.733303 val loss: 0.577785
[Epoch 91] ogbg-moltox21: 0.720101 test loss: 0.628646
[Epoch 92; Iter    23/  157] train: loss: 0.0391664
[Epoch 92; Iter    53/  157] train: loss: 0.0590419
[Epoch 92; Iter    83/  157] train: loss: 0.0617063
[Epoch 92; Iter   113/  157] train: loss: 0.0499836
[Epoch 92; Iter   143/  157] train: loss: 0.0978191
[Epoch 92] ogbg-moltox21: 0.739485 val loss: 0.511182
[Epoch 92] ogbg-moltox21: 0.728541 test loss: 0.665121
[Epoch 93; Iter    16/  157] train: loss: 0.0555941
[Epoch 93; Iter    46/  157] train: loss: 0.0464624
[Epoch 93; Iter    76/  157] train: loss: 0.0874839
[Epoch 93; Iter   106/  157] train: loss: 0.0903889
[Epoch 93; Iter   136/  157] train: loss: 0.0836814
[Epoch 93] ogbg-moltox21: 0.727939 val loss: 0.593452
[Epoch 93] ogbg-moltox21: 0.722544 test loss: 0.544924
[Epoch 94; Iter     9/  157] train: loss: 0.0659265
[Epoch 94; Iter    39/  157] train: loss: 0.0570849
[Epoch 94; Iter    69/  157] train: loss: 0.0496794
[Epoch 94; Iter    99/  157] train: loss: 0.0562311
[Epoch 94; Iter   129/  157] train: loss: 0.0464272
[Epoch 94] ogbg-moltox21: 0.727986 val loss: 0.687944
[Epoch 94] ogbg-moltox21: 0.719701 test loss: 0.569985
[Epoch 95; Iter     2/  157] train: loss: 0.0531394
[Epoch 95; Iter    32/  157] train: loss: 0.0616752
[Epoch 95; Iter    62/  157] train: loss: 0.0329548
[Epoch 95; Iter    92/  157] train: loss: 0.0636522
[Epoch 95; Iter   122/  157] train: loss: 0.0803097
[Epoch 95; Iter   152/  157] train: loss: 0.0583237
[Epoch 95] ogbg-moltox21: 0.718578 val loss: 0.706970
[Epoch 95] ogbg-moltox21: 0.716959 test loss: 0.600814
[Epoch 96; Iter    25/  157] train: loss: 0.0396451
[Epoch 96; Iter    55/  157] train: loss: 0.0758079
[Epoch 96; Iter    85/  157] train: loss: 0.0412432
[Epoch 96; Iter   115/  157] train: loss: 0.0362294
[Epoch 96; Iter   145/  157] train: loss: 0.0868189
[Epoch 96] ogbg-moltox21: 0.718465 val loss: 0.844672
[Epoch 96] ogbg-moltox21: 0.712724 test loss: 0.741442
[Epoch 97; Iter    18/  157] train: loss: 0.0472336
[Epoch 97; Iter    48/  157] train: loss: 0.0461594
[Epoch 97; Iter    78/  157] train: loss: 0.0352325
[Epoch 97; Iter   108/  157] train: loss: 0.0473321
[Epoch 97; Iter   138/  157] train: loss: 0.1009781
[Epoch 97] ogbg-moltox21: 0.727854 val loss: 0.511775
[Epoch 97] ogbg-moltox21: 0.724314 test loss: 0.533029
[Epoch 98; Iter    11/  157] train: loss: 0.0571508
[Epoch 98; Iter    41/  157] train: loss: 0.0447333
[Epoch 98; Iter    71/  157] train: loss: 0.0468923
[Epoch 98; Iter   101/  157] train: loss: 0.0858327
[Epoch 98; Iter   131/  157] train: loss: 0.0415568
[Epoch 98] ogbg-moltox21: 0.716350 val loss: 0.619566
[Epoch 98] ogbg-moltox21: 0.712060 test loss: 0.584935
[Epoch 99; Iter     4/  157] train: loss: 0.0261891
[Epoch 99; Iter    34/  157] train: loss: 0.0624600
[Epoch 99; Iter    64/  157] train: loss: 0.0549812
[Epoch 99; Iter    94/  157] train: loss: 0.0723174
[Epoch 99; Iter   124/  157] train: loss: 0.0431522
[Epoch 99; Iter   154/  157] train: loss: 0.0845922
[Epoch 99] ogbg-moltox21: 0.730260 val loss: 0.705448
[Epoch 99] ogbg-moltox21: 0.726011 test loss: 0.607333
[Epoch 100; Iter    27/  157] train: loss: 0.0401434
[Epoch 100; Iter    57/  157] train: loss: 0.0764092
[Epoch 100; Iter    87/  157] train: loss: 0.1133360
[Epoch 100; Iter   117/  157] train: loss: 0.0543381
[Epoch 100; Iter   147/  157] train: loss: 0.0707485
[Epoch 100] ogbg-moltox21: 0.723228 val loss: 0.593072
[Epoch 100] ogbg-moltox21: 0.711434 test loss: 0.570906
[Epoch 101; Iter    20/  157] train: loss: 0.0525064
[Epoch 101; Iter    50/  157] train: loss: 0.0391304
[Epoch 101; Iter    80/  157] train: loss: 0.0524855
[Epoch 101; Iter   110/  157] train: loss: 0.0459833
[Epoch 82; Iter    51/  209] train: loss: 0.0607119
[Epoch 82; Iter    81/  209] train: loss: 0.0937667
[Epoch 82; Iter   111/  209] train: loss: 0.0498535
[Epoch 82; Iter   141/  209] train: loss: 0.0806178
[Epoch 82; Iter   171/  209] train: loss: 0.0400382
[Epoch 82; Iter   201/  209] train: loss: 0.0745664
[Epoch 82] ogbg-moltox21: 0.776167 val loss: 0.332091
[Epoch 82] ogbg-moltox21: 0.745444 test loss: 0.363552
[Epoch 83; Iter    22/  209] train: loss: 0.1146298
[Epoch 83; Iter    52/  209] train: loss: 0.1066949
[Epoch 83; Iter    82/  209] train: loss: 0.0498267
[Epoch 83; Iter   112/  209] train: loss: 0.0945858
[Epoch 83; Iter   142/  209] train: loss: 0.1320596
[Epoch 83; Iter   172/  209] train: loss: 0.0510944
[Epoch 83; Iter   202/  209] train: loss: 0.1114007
[Epoch 83] ogbg-moltox21: 0.767648 val loss: 0.336516
[Epoch 83] ogbg-moltox21: 0.740620 test loss: 0.372038
[Epoch 84; Iter    23/  209] train: loss: 0.0645582
[Epoch 84; Iter    53/  209] train: loss: 0.0694366
[Epoch 84; Iter    83/  209] train: loss: 0.0406319
[Epoch 84; Iter   113/  209] train: loss: 0.0637567
[Epoch 84; Iter   143/  209] train: loss: 0.0674310
[Epoch 84; Iter   173/  209] train: loss: 0.0802157
[Epoch 84; Iter   203/  209] train: loss: 0.0953280
[Epoch 84] ogbg-moltox21: 0.772195 val loss: 0.351245
[Epoch 84] ogbg-moltox21: 0.743978 test loss: 0.373607
[Epoch 85; Iter    24/  209] train: loss: 0.0698305
[Epoch 85; Iter    54/  209] train: loss: 0.1130340
[Epoch 85; Iter    84/  209] train: loss: 0.0427445
[Epoch 85; Iter   114/  209] train: loss: 0.0957022
[Epoch 85; Iter   144/  209] train: loss: 0.1224661
[Epoch 85; Iter   174/  209] train: loss: 0.0584086
[Epoch 85; Iter   204/  209] train: loss: 0.0809705
[Epoch 85] ogbg-moltox21: 0.758366 val loss: 0.370827
[Epoch 85] ogbg-moltox21: 0.735894 test loss: 0.373350
[Epoch 86; Iter    25/  209] train: loss: 0.0543099
[Epoch 86; Iter    55/  209] train: loss: 0.0555784
[Epoch 86; Iter    85/  209] train: loss: 0.0633931
[Epoch 86; Iter   115/  209] train: loss: 0.1043376
[Epoch 86; Iter   145/  209] train: loss: 0.0840130
[Epoch 86; Iter   175/  209] train: loss: 0.0594794
[Epoch 86; Iter   205/  209] train: loss: 0.0592076
[Epoch 86] ogbg-moltox21: 0.767061 val loss: 0.336233
[Epoch 86] ogbg-moltox21: 0.743331 test loss: 0.365407
[Epoch 87; Iter    26/  209] train: loss: 0.0513788
[Epoch 87; Iter    56/  209] train: loss: 0.0843977
[Epoch 87; Iter    86/  209] train: loss: 0.0693991
[Epoch 87; Iter   116/  209] train: loss: 0.1084885
[Epoch 87; Iter   146/  209] train: loss: 0.1194176
[Epoch 87; Iter   176/  209] train: loss: 0.0537857
[Epoch 87; Iter   206/  209] train: loss: 0.0865022
[Epoch 87] ogbg-moltox21: 0.769222 val loss: 0.343238
[Epoch 87] ogbg-moltox21: 0.745111 test loss: 0.372493
[Epoch 88; Iter    27/  209] train: loss: 0.0523143
[Epoch 88; Iter    57/  209] train: loss: 0.0841866
[Epoch 88; Iter    87/  209] train: loss: 0.0577386
[Epoch 88; Iter   117/  209] train: loss: 0.0620083
[Epoch 88; Iter   147/  209] train: loss: 0.0383492
[Epoch 88; Iter   177/  209] train: loss: 0.0691007
[Epoch 88; Iter   207/  209] train: loss: 0.0592235
[Epoch 88] ogbg-moltox21: 0.762884 val loss: 0.365887
[Epoch 88] ogbg-moltox21: 0.740312 test loss: 0.381353
[Epoch 89; Iter    28/  209] train: loss: 0.0568027
[Epoch 89; Iter    58/  209] train: loss: 0.0843323
[Epoch 89; Iter    88/  209] train: loss: 0.0900896
[Epoch 89; Iter   118/  209] train: loss: 0.0352355
[Epoch 89; Iter   148/  209] train: loss: 0.1004487
[Epoch 89; Iter   178/  209] train: loss: 0.0658912
[Epoch 89; Iter   208/  209] train: loss: 0.0682377
[Epoch 89] ogbg-moltox21: 0.765500 val loss: 0.361063
[Epoch 89] ogbg-moltox21: 0.742157 test loss: 0.386199
[Epoch 90; Iter    29/  209] train: loss: 0.0762652
[Epoch 90; Iter    59/  209] train: loss: 0.0634672
[Epoch 90; Iter    89/  209] train: loss: 0.0477194
[Epoch 90; Iter   119/  209] train: loss: 0.1398921
[Epoch 90; Iter   149/  209] train: loss: 0.0769481
[Epoch 90; Iter   179/  209] train: loss: 0.0727462
[Epoch 90; Iter   209/  209] train: loss: 0.0545895
[Epoch 90] ogbg-moltox21: 0.771307 val loss: 0.368391
[Epoch 90] ogbg-moltox21: 0.741015 test loss: 0.383547
[Epoch 91; Iter    30/  209] train: loss: 0.0647262
[Epoch 91; Iter    60/  209] train: loss: 0.0299293
[Epoch 91; Iter    90/  209] train: loss: 0.0605117
[Epoch 91; Iter   120/  209] train: loss: 0.0540143
[Epoch 91; Iter   150/  209] train: loss: 0.0865915
[Epoch 91; Iter   180/  209] train: loss: 0.0443935
[Epoch 91] ogbg-moltox21: 0.769930 val loss: 0.352497
[Epoch 91] ogbg-moltox21: 0.741016 test loss: 0.382282
[Epoch 92; Iter     1/  209] train: loss: 0.0446925
[Epoch 92; Iter    31/  209] train: loss: 0.0441054
[Epoch 92; Iter    61/  209] train: loss: 0.0311523
[Epoch 92; Iter    91/  209] train: loss: 0.0495296
[Epoch 92; Iter   121/  209] train: loss: 0.0495095
[Epoch 92; Iter   151/  209] train: loss: 0.0559593
[Epoch 92; Iter   181/  209] train: loss: 0.0296550
[Epoch 92] ogbg-moltox21: 0.766092 val loss: 0.348973
[Epoch 92] ogbg-moltox21: 0.739713 test loss: 0.382434
[Epoch 93; Iter     2/  209] train: loss: 0.0514903
[Epoch 93; Iter    32/  209] train: loss: 0.0799912
[Epoch 93; Iter    62/  209] train: loss: 0.0359667
[Epoch 93; Iter    92/  209] train: loss: 0.0636183
[Epoch 93; Iter   122/  209] train: loss: 0.0669898
[Epoch 93; Iter   152/  209] train: loss: 0.0518548
[Epoch 93; Iter   182/  209] train: loss: 0.0549644
[Epoch 93] ogbg-moltox21: 0.767894 val loss: 0.362291
[Epoch 93] ogbg-moltox21: 0.741564 test loss: 0.384669
[Epoch 94; Iter     3/  209] train: loss: 0.0344661
[Epoch 94; Iter    33/  209] train: loss: 0.0514467
[Epoch 94; Iter    63/  209] train: loss: 0.0365726
[Epoch 94; Iter    93/  209] train: loss: 0.0442360
[Epoch 94; Iter   123/  209] train: loss: 0.0788155
[Epoch 94; Iter   153/  209] train: loss: 0.0487974
[Epoch 94; Iter   183/  209] train: loss: 0.0352099
[Epoch 94] ogbg-moltox21: 0.767211 val loss: 0.362566
[Epoch 94] ogbg-moltox21: 0.735985 test loss: 0.394023
[Epoch 95; Iter     4/  209] train: loss: 0.0520797
[Epoch 95; Iter    34/  209] train: loss: 0.0442926
[Epoch 95; Iter    64/  209] train: loss: 0.0470714
[Epoch 95; Iter    94/  209] train: loss: 0.0696032
[Epoch 95; Iter   124/  209] train: loss: 0.0751566
[Epoch 95; Iter   154/  209] train: loss: 0.0784303
[Epoch 95; Iter   184/  209] train: loss: 0.0507999
[Epoch 95] ogbg-moltox21: 0.764797 val loss: 0.376962
[Epoch 95] ogbg-moltox21: 0.739687 test loss: 0.407055
[Epoch 96; Iter     5/  209] train: loss: 0.0618263
[Epoch 96; Iter    35/  209] train: loss: 0.0778123
[Epoch 96; Iter    65/  209] train: loss: 0.0744630
[Epoch 96; Iter    95/  209] train: loss: 0.0318206
[Epoch 96; Iter   125/  209] train: loss: 0.0717870
[Epoch 96; Iter   155/  209] train: loss: 0.0453985
[Epoch 96; Iter   185/  209] train: loss: 0.0587368
[Epoch 96] ogbg-moltox21: 0.762416 val loss: 0.370000
[Epoch 96] ogbg-moltox21: 0.738546 test loss: 0.406103
[Epoch 97; Iter     6/  209] train: loss: 0.0569874
[Epoch 97; Iter    36/  209] train: loss: 0.0840739
[Epoch 97; Iter    66/  209] train: loss: 0.0422719
[Epoch 97; Iter    96/  209] train: loss: 0.0453487
[Epoch 97; Iter   126/  209] train: loss: 0.0548819
[Epoch 97; Iter   156/  209] train: loss: 0.0400729
[Epoch 97; Iter   186/  209] train: loss: 0.0559256
[Epoch 97] ogbg-moltox21: 0.769240 val loss: 0.374905
[Epoch 97] ogbg-moltox21: 0.744182 test loss: 0.412765
[Epoch 98; Iter     7/  209] train: loss: 0.0716569
[Epoch 98; Iter    37/  209] train: loss: 0.0229689
[Epoch 98; Iter    67/  209] train: loss: 0.0955286
[Epoch 98; Iter    97/  209] train: loss: 0.0427059
[Epoch 98; Iter   127/  209] train: loss: 0.0631054
[Epoch 98; Iter   157/  209] train: loss: 0.0422629
[Epoch 98; Iter   187/  209] train: loss: 0.0695787
[Epoch 98] ogbg-moltox21: 0.764785 val loss: 0.364929
[Epoch 98] ogbg-moltox21: 0.738199 test loss: 0.406521
[Epoch 99; Iter     8/  209] train: loss: 0.0798317
[Epoch 99; Iter    38/  209] train: loss: 0.0529427
[Epoch 99; Iter    68/  209] train: loss: 0.0486561
[Epoch 99; Iter    98/  209] train: loss: 0.0324142
[Epoch 82; Iter    51/  209] train: loss: 0.0502712
[Epoch 82; Iter    81/  209] train: loss: 0.0484655
[Epoch 82; Iter   111/  209] train: loss: 0.1259073
[Epoch 82; Iter   141/  209] train: loss: 0.0534657
[Epoch 82; Iter   171/  209] train: loss: 0.0698525
[Epoch 82; Iter   201/  209] train: loss: 0.0639652
[Epoch 82] ogbg-moltox21: 0.787106 val loss: 0.338054
[Epoch 82] ogbg-moltox21: 0.752485 test loss: 0.364160
[Epoch 83; Iter    22/  209] train: loss: 0.0550122
[Epoch 83; Iter    52/  209] train: loss: 0.0984275
[Epoch 83; Iter    82/  209] train: loss: 0.0909302
[Epoch 83; Iter   112/  209] train: loss: 0.0899968
[Epoch 83; Iter   142/  209] train: loss: 0.0882139
[Epoch 83; Iter   172/  209] train: loss: 0.0582826
[Epoch 83; Iter   202/  209] train: loss: 0.0566499
[Epoch 83] ogbg-moltox21: 0.779190 val loss: 0.348564
[Epoch 83] ogbg-moltox21: 0.754891 test loss: 0.370211
[Epoch 84; Iter    23/  209] train: loss: 0.0564634
[Epoch 84; Iter    53/  209] train: loss: 0.0478552
[Epoch 84; Iter    83/  209] train: loss: 0.0529348
[Epoch 84; Iter   113/  209] train: loss: 0.1020792
[Epoch 84; Iter   143/  209] train: loss: 0.1021678
[Epoch 84; Iter   173/  209] train: loss: 0.0621192
[Epoch 84; Iter   203/  209] train: loss: 0.0546277
[Epoch 84] ogbg-moltox21: 0.768245 val loss: 0.356303
[Epoch 84] ogbg-moltox21: 0.746748 test loss: 0.377775
[Epoch 85; Iter    24/  209] train: loss: 0.0612920
[Epoch 85; Iter    54/  209] train: loss: 0.0674367
[Epoch 85; Iter    84/  209] train: loss: 0.0731685
[Epoch 85; Iter   114/  209] train: loss: 0.1122457
[Epoch 85; Iter   144/  209] train: loss: 0.0551918
[Epoch 85; Iter   174/  209] train: loss: 0.1078643
[Epoch 85; Iter   204/  209] train: loss: 0.0512313
[Epoch 85] ogbg-moltox21: 0.774035 val loss: 0.355289
[Epoch 85] ogbg-moltox21: 0.749801 test loss: 0.373705
[Epoch 86; Iter    25/  209] train: loss: 0.0806047
[Epoch 86; Iter    55/  209] train: loss: 0.0561106
[Epoch 86; Iter    85/  209] train: loss: 0.0918789
[Epoch 86; Iter   115/  209] train: loss: 0.0587851
[Epoch 86; Iter   145/  209] train: loss: 0.0480683
[Epoch 86; Iter   175/  209] train: loss: 0.0849073
[Epoch 86; Iter   205/  209] train: loss: 0.1213411
[Epoch 86] ogbg-moltox21: 0.770923 val loss: 0.362485
[Epoch 86] ogbg-moltox21: 0.750532 test loss: 0.375267
[Epoch 87; Iter    26/  209] train: loss: 0.0725334
[Epoch 87; Iter    56/  209] train: loss: 0.0558840
[Epoch 87; Iter    86/  209] train: loss: 0.0520872
[Epoch 87; Iter   116/  209] train: loss: 0.0614488
[Epoch 87; Iter   146/  209] train: loss: 0.0576574
[Epoch 87; Iter   176/  209] train: loss: 0.0416813
[Epoch 87; Iter   206/  209] train: loss: 0.0352522
[Epoch 87] ogbg-moltox21: 0.775863 val loss: 0.359732
[Epoch 87] ogbg-moltox21: 0.752489 test loss: 0.377731
[Epoch 88; Iter    27/  209] train: loss: 0.0547891
[Epoch 88; Iter    57/  209] train: loss: 0.0538891
[Epoch 88; Iter    87/  209] train: loss: 0.0484095
[Epoch 88; Iter   117/  209] train: loss: 0.0431312
[Epoch 88; Iter   147/  209] train: loss: 0.0515170
[Epoch 88; Iter   177/  209] train: loss: 0.0685053
[Epoch 88; Iter   207/  209] train: loss: 0.0534991
[Epoch 88] ogbg-moltox21: 0.776366 val loss: 0.359795
[Epoch 88] ogbg-moltox21: 0.752530 test loss: 0.383835
[Epoch 89; Iter    28/  209] train: loss: 0.0679292
[Epoch 89; Iter    58/  209] train: loss: 0.1041723
[Epoch 89; Iter    88/  209] train: loss: 0.0710921
[Epoch 89; Iter   118/  209] train: loss: 0.0377100
[Epoch 89; Iter   148/  209] train: loss: 0.0678481
[Epoch 89; Iter   178/  209] train: loss: 0.0809510
[Epoch 89; Iter   208/  209] train: loss: 0.0681125
[Epoch 89] ogbg-moltox21: 0.773749 val loss: 0.377906
[Epoch 89] ogbg-moltox21: 0.745052 test loss: 0.398469
[Epoch 90; Iter    29/  209] train: loss: 0.0493067
[Epoch 90; Iter    59/  209] train: loss: 0.0350613
[Epoch 90; Iter    89/  209] train: loss: 0.0609717
[Epoch 90; Iter   119/  209] train: loss: 0.0612183
[Epoch 90; Iter   149/  209] train: loss: 0.0564011
[Epoch 90; Iter   179/  209] train: loss: 0.0430981
[Epoch 90; Iter   209/  209] train: loss: 0.1021145
[Epoch 90] ogbg-moltox21: 0.774138 val loss: 0.363045
[Epoch 90] ogbg-moltox21: 0.749880 test loss: 0.385072
[Epoch 91; Iter    30/  209] train: loss: 0.0470725
[Epoch 91; Iter    60/  209] train: loss: 0.0274124
[Epoch 91; Iter    90/  209] train: loss: 0.0610156
[Epoch 91; Iter   120/  209] train: loss: 0.0444202
[Epoch 91; Iter   150/  209] train: loss: 0.0838846
[Epoch 91; Iter   180/  209] train: loss: 0.0367583
[Epoch 91] ogbg-moltox21: 0.771986 val loss: 0.368034
[Epoch 91] ogbg-moltox21: 0.749211 test loss: 0.388252
[Epoch 92; Iter     1/  209] train: loss: 0.0287301
[Epoch 92; Iter    31/  209] train: loss: 0.0532230
[Epoch 92; Iter    61/  209] train: loss: 0.0687340
[Epoch 92; Iter    91/  209] train: loss: 0.0684242
[Epoch 92; Iter   121/  209] train: loss: 0.0513534
[Epoch 92; Iter   151/  209] train: loss: 0.0556862
[Epoch 92; Iter   181/  209] train: loss: 0.0513300
[Epoch 92] ogbg-moltox21: 0.778537 val loss: 0.373715
[Epoch 92] ogbg-moltox21: 0.751237 test loss: 0.401887
[Epoch 93; Iter     2/  209] train: loss: 0.0931223
[Epoch 93; Iter    32/  209] train: loss: 0.0386766
[Epoch 93; Iter    62/  209] train: loss: 0.0651389
[Epoch 93; Iter    92/  209] train: loss: 0.0761375
[Epoch 93; Iter   122/  209] train: loss: 0.0571291
[Epoch 93; Iter   152/  209] train: loss: 0.0632558
[Epoch 93; Iter   182/  209] train: loss: 0.0526236
[Epoch 93] ogbg-moltox21: 0.774781 val loss: 0.364230
[Epoch 93] ogbg-moltox21: 0.752283 test loss: 0.384788
[Epoch 94; Iter     3/  209] train: loss: 0.0406466
[Epoch 94; Iter    33/  209] train: loss: 0.0601692
[Epoch 94; Iter    63/  209] train: loss: 0.0818933
[Epoch 94; Iter    93/  209] train: loss: 0.0704513
[Epoch 94; Iter   123/  209] train: loss: 0.0722404
[Epoch 94; Iter   153/  209] train: loss: 0.0496463
[Epoch 94; Iter   183/  209] train: loss: 0.0665351
[Epoch 94] ogbg-moltox21: 0.772803 val loss: 0.383277
[Epoch 94] ogbg-moltox21: 0.751717 test loss: 0.410552
[Epoch 95; Iter     4/  209] train: loss: 0.0414613
[Epoch 95; Iter    34/  209] train: loss: 0.1060914
[Epoch 95; Iter    64/  209] train: loss: 0.0666741
[Epoch 95; Iter    94/  209] train: loss: 0.0915118
[Epoch 95; Iter   124/  209] train: loss: 0.0454559
[Epoch 95; Iter   154/  209] train: loss: 0.0775257
[Epoch 95; Iter   184/  209] train: loss: 0.0593717
[Epoch 95] ogbg-moltox21: 0.768646 val loss: 0.391230
[Epoch 95] ogbg-moltox21: 0.751911 test loss: 0.407342
[Epoch 96; Iter     5/  209] train: loss: 0.0828091
[Epoch 96; Iter    35/  209] train: loss: 0.0402654
[Epoch 96; Iter    65/  209] train: loss: 0.0740027
[Epoch 96; Iter    95/  209] train: loss: 0.0455552
[Epoch 96; Iter   125/  209] train: loss: 0.0285929
[Epoch 96; Iter   155/  209] train: loss: 0.0489182
[Epoch 96; Iter   185/  209] train: loss: 0.0507308
[Epoch 96] ogbg-moltox21: 0.766765 val loss: 0.453149
[Epoch 96] ogbg-moltox21: 0.744809 test loss: 0.415129
[Epoch 97; Iter     6/  209] train: loss: 0.0786312
[Epoch 97; Iter    36/  209] train: loss: 0.0283619
[Epoch 97; Iter    66/  209] train: loss: 0.0772288
[Epoch 97; Iter    96/  209] train: loss: 0.0411280
[Epoch 97; Iter   126/  209] train: loss: 0.0697209
[Epoch 97; Iter   156/  209] train: loss: 0.0571836
[Epoch 97; Iter   186/  209] train: loss: 0.0414497
[Epoch 97] ogbg-moltox21: 0.768565 val loss: 0.384404
[Epoch 97] ogbg-moltox21: 0.750479 test loss: 0.398759
[Epoch 98; Iter     7/  209] train: loss: 0.0614370
[Epoch 98; Iter    37/  209] train: loss: 0.0361017
[Epoch 98; Iter    67/  209] train: loss: 0.0404174
[Epoch 98; Iter    97/  209] train: loss: 0.0844407
[Epoch 98; Iter   127/  209] train: loss: 0.0820674
[Epoch 98; Iter   157/  209] train: loss: 0.0507614
[Epoch 98; Iter   187/  209] train: loss: 0.0655814
[Epoch 98] ogbg-moltox21: 0.763316 val loss: 0.445670
[Epoch 98] ogbg-moltox21: 0.746856 test loss: 0.412230
[Epoch 99; Iter     8/  209] train: loss: 0.1165065
[Epoch 99; Iter    38/  209] train: loss: 0.0572145
[Epoch 99; Iter    68/  209] train: loss: 0.0859212
[Epoch 99; Iter    98/  209] train: loss: 0.1176453
[Epoch 82; Iter    51/  209] train: loss: 0.0618987
[Epoch 82; Iter    81/  209] train: loss: 0.0449341
[Epoch 82; Iter   111/  209] train: loss: 0.0579248
[Epoch 82; Iter   141/  209] train: loss: 0.0754915
[Epoch 82; Iter   171/  209] train: loss: 0.0814099
[Epoch 82; Iter   201/  209] train: loss: 0.1360220
[Epoch 82] ogbg-moltox21: 0.764469 val loss: 0.348750
[Epoch 82] ogbg-moltox21: 0.740565 test loss: 0.367007
[Epoch 83; Iter    22/  209] train: loss: 0.0766571
[Epoch 83; Iter    52/  209] train: loss: 0.0728367
[Epoch 83; Iter    82/  209] train: loss: 0.0704231
[Epoch 83; Iter   112/  209] train: loss: 0.0813056
[Epoch 83; Iter   142/  209] train: loss: 0.0775624
[Epoch 83; Iter   172/  209] train: loss: 0.0923902
[Epoch 83; Iter   202/  209] train: loss: 0.0775084
[Epoch 83] ogbg-moltox21: 0.763624 val loss: 0.357848
[Epoch 83] ogbg-moltox21: 0.738735 test loss: 0.367767
[Epoch 84; Iter    23/  209] train: loss: 0.0690965
[Epoch 84; Iter    53/  209] train: loss: 0.0519009
[Epoch 84; Iter    83/  209] train: loss: 0.0643766
[Epoch 84; Iter   113/  209] train: loss: 0.0388815
[Epoch 84; Iter   143/  209] train: loss: 0.0753230
[Epoch 84; Iter   173/  209] train: loss: 0.0447903
[Epoch 84; Iter   203/  209] train: loss: 0.0733171
[Epoch 84] ogbg-moltox21: 0.772089 val loss: 0.366735
[Epoch 84] ogbg-moltox21: 0.748239 test loss: 0.379405
[Epoch 85; Iter    24/  209] train: loss: 0.0571397
[Epoch 85; Iter    54/  209] train: loss: 0.1573037
[Epoch 85; Iter    84/  209] train: loss: 0.0291743
[Epoch 85; Iter   114/  209] train: loss: 0.0774560
[Epoch 85; Iter   144/  209] train: loss: 0.0571803
[Epoch 85; Iter   174/  209] train: loss: 0.0949503
[Epoch 85; Iter   204/  209] train: loss: 0.0451714
[Epoch 85] ogbg-moltox21: 0.770534 val loss: 0.366617
[Epoch 85] ogbg-moltox21: 0.747643 test loss: 0.380970
[Epoch 86; Iter    25/  209] train: loss: 0.0647896
[Epoch 86; Iter    55/  209] train: loss: 0.0672433
[Epoch 86; Iter    85/  209] train: loss: 0.0574534
[Epoch 86; Iter   115/  209] train: loss: 0.0574431
[Epoch 86; Iter   145/  209] train: loss: 0.1379589
[Epoch 86; Iter   175/  209] train: loss: 0.0850829
[Epoch 86; Iter   205/  209] train: loss: 0.0805109
[Epoch 86] ogbg-moltox21: 0.771565 val loss: 0.357364
[Epoch 86] ogbg-moltox21: 0.743744 test loss: 0.374504
[Epoch 87; Iter    26/  209] train: loss: 0.0566185
[Epoch 87; Iter    56/  209] train: loss: 0.0890467
[Epoch 87; Iter    86/  209] train: loss: 0.0673653
[Epoch 87; Iter   116/  209] train: loss: 0.0707916
[Epoch 87; Iter   146/  209] train: loss: 0.0529331
[Epoch 87; Iter   176/  209] train: loss: 0.0956231
[Epoch 87; Iter   206/  209] train: loss: 0.1049694
[Epoch 87] ogbg-moltox21: 0.761763 val loss: 0.369728
[Epoch 87] ogbg-moltox21: 0.740796 test loss: 0.385467
[Epoch 88; Iter    27/  209] train: loss: 0.0804161
[Epoch 88; Iter    57/  209] train: loss: 0.0639000
[Epoch 88; Iter    87/  209] train: loss: 0.0600735
[Epoch 88; Iter   117/  209] train: loss: 0.0499138
[Epoch 88; Iter   147/  209] train: loss: 0.0744136
[Epoch 88; Iter   177/  209] train: loss: 0.0719732
[Epoch 88; Iter   207/  209] train: loss: 0.0582153
[Epoch 88] ogbg-moltox21: 0.768913 val loss: 0.368550
[Epoch 88] ogbg-moltox21: 0.738169 test loss: 0.389707
[Epoch 89; Iter    28/  209] train: loss: 0.0523148
[Epoch 89; Iter    58/  209] train: loss: 0.0584561
[Epoch 89; Iter    88/  209] train: loss: 0.0636043
[Epoch 89; Iter   118/  209] train: loss: 0.0506947
[Epoch 89; Iter   148/  209] train: loss: 0.0414525
[Epoch 89; Iter   178/  209] train: loss: 0.0377832
[Epoch 89; Iter   208/  209] train: loss: 0.0281569
[Epoch 89] ogbg-moltox21: 0.762870 val loss: 0.373060
[Epoch 89] ogbg-moltox21: 0.737934 test loss: 0.384859
[Epoch 90; Iter    29/  209] train: loss: 0.0381060
[Epoch 90; Iter    59/  209] train: loss: 0.0502672
[Epoch 90; Iter    89/  209] train: loss: 0.0415649
[Epoch 90; Iter   119/  209] train: loss: 0.0533201
[Epoch 90; Iter   149/  209] train: loss: 0.0280693
[Epoch 90; Iter   179/  209] train: loss: 0.0461210
[Epoch 90; Iter   209/  209] train: loss: 0.0311677
[Epoch 90] ogbg-moltox21: 0.766373 val loss: 0.378081
[Epoch 90] ogbg-moltox21: 0.747540 test loss: 0.390263
[Epoch 91; Iter    30/  209] train: loss: 0.0899279
[Epoch 91; Iter    60/  209] train: loss: 0.0697690
[Epoch 91; Iter    90/  209] train: loss: 0.1138656
[Epoch 91; Iter   120/  209] train: loss: 0.0713744
[Epoch 91; Iter   150/  209] train: loss: 0.0590551
[Epoch 91; Iter   180/  209] train: loss: 0.0901183
[Epoch 91] ogbg-moltox21: 0.766474 val loss: 0.385154
[Epoch 91] ogbg-moltox21: 0.741149 test loss: 0.398550
[Epoch 92; Iter     1/  209] train: loss: 0.0452493
[Epoch 92; Iter    31/  209] train: loss: 0.0570361
[Epoch 92; Iter    61/  209] train: loss: 0.0448283
[Epoch 92; Iter    91/  209] train: loss: 0.0383940
[Epoch 92; Iter   121/  209] train: loss: 0.0677393
[Epoch 92; Iter   151/  209] train: loss: 0.0379466
[Epoch 92; Iter   181/  209] train: loss: 0.0451292
[Epoch 92] ogbg-moltox21: 0.768387 val loss: 0.375514
[Epoch 92] ogbg-moltox21: 0.740032 test loss: 0.394338
[Epoch 93; Iter     2/  209] train: loss: 0.0453069
[Epoch 93; Iter    32/  209] train: loss: 0.0762345
[Epoch 93; Iter    62/  209] train: loss: 0.0340750
[Epoch 93; Iter    92/  209] train: loss: 0.0592831
[Epoch 93; Iter   122/  209] train: loss: 0.0344887
[Epoch 93; Iter   152/  209] train: loss: 0.0450272
[Epoch 93; Iter   182/  209] train: loss: 0.0563840
[Epoch 93] ogbg-moltox21: 0.766559 val loss: 0.385737
[Epoch 93] ogbg-moltox21: 0.735757 test loss: 0.410944
[Epoch 94; Iter     3/  209] train: loss: 0.0287059
[Epoch 94; Iter    33/  209] train: loss: 0.0534897
[Epoch 94; Iter    63/  209] train: loss: 0.0250994
[Epoch 94; Iter    93/  209] train: loss: 0.0329187
[Epoch 94; Iter   123/  209] train: loss: 0.0426535
[Epoch 94; Iter   153/  209] train: loss: 0.0558720
[Epoch 94; Iter   183/  209] train: loss: 0.0815137
[Epoch 94] ogbg-moltox21: 0.768280 val loss: 0.376541
[Epoch 94] ogbg-moltox21: 0.733417 test loss: 0.398625
[Epoch 95; Iter     4/  209] train: loss: 0.0719737
[Epoch 95; Iter    34/  209] train: loss: 0.0535551
[Epoch 95; Iter    64/  209] train: loss: 0.0761621
[Epoch 95; Iter    94/  209] train: loss: 0.0382455
[Epoch 95; Iter   124/  209] train: loss: 0.0495303
[Epoch 95; Iter   154/  209] train: loss: 0.0389680
[Epoch 95; Iter   184/  209] train: loss: 0.0820463
[Epoch 95] ogbg-moltox21: 0.766751 val loss: 0.384135
[Epoch 95] ogbg-moltox21: 0.740928 test loss: 0.398758
[Epoch 96; Iter     5/  209] train: loss: 0.0424291
[Epoch 96; Iter    35/  209] train: loss: 0.0490628
[Epoch 96; Iter    65/  209] train: loss: 0.0476473
[Epoch 96; Iter    95/  209] train: loss: 0.0649900
[Epoch 96; Iter   125/  209] train: loss: 0.0463048
[Epoch 96; Iter   155/  209] train: loss: 0.0758410
[Epoch 96; Iter   185/  209] train: loss: 0.0695364
[Epoch 96] ogbg-moltox21: 0.769237 val loss: 0.378751
[Epoch 96] ogbg-moltox21: 0.734548 test loss: 0.407925
[Epoch 97; Iter     6/  209] train: loss: 0.0576056
[Epoch 97; Iter    36/  209] train: loss: 0.0556273
[Epoch 97; Iter    66/  209] train: loss: 0.0664008
[Epoch 97; Iter    96/  209] train: loss: 0.0410193
[Epoch 97; Iter   126/  209] train: loss: 0.0435159
[Epoch 97; Iter   156/  209] train: loss: 0.1048922
[Epoch 97; Iter   186/  209] train: loss: 0.0628123
[Epoch 97] ogbg-moltox21: 0.769056 val loss: 0.389096
[Epoch 97] ogbg-moltox21: 0.732666 test loss: 0.408378
[Epoch 98; Iter     7/  209] train: loss: 0.0439716
[Epoch 98; Iter    37/  209] train: loss: 0.0620586
[Epoch 98; Iter    67/  209] train: loss: 0.0385408
[Epoch 98; Iter    97/  209] train: loss: 0.0795239
[Epoch 98; Iter   127/  209] train: loss: 0.0518969
[Epoch 98; Iter   157/  209] train: loss: 0.0549812
[Epoch 98; Iter   187/  209] train: loss: 0.0711216
[Epoch 98] ogbg-moltox21: 0.762572 val loss: 0.396344
[Epoch 98] ogbg-moltox21: 0.730199 test loss: 0.418281
[Epoch 99; Iter     8/  209] train: loss: 0.0311178
[Epoch 99; Iter    38/  209] train: loss: 0.0231707
[Epoch 99; Iter    68/  209] train: loss: 0.0613881
[Epoch 99; Iter    98/  209] train: loss: 0.0502713
[Epoch 90] ogbg-moltox21: 0.743284 val loss: 0.390205
[Epoch 90] ogbg-moltox21: 0.717994 test loss: 0.430644
[Epoch 91; Iter    30/  183] train: loss: 0.0754637
[Epoch 91; Iter    60/  183] train: loss: 0.0553361
[Epoch 91; Iter    90/  183] train: loss: 0.0801844
[Epoch 91; Iter   120/  183] train: loss: 0.0478732
[Epoch 91; Iter   150/  183] train: loss: 0.0533102
[Epoch 91; Iter   180/  183] train: loss: 0.0471410
[Epoch 91] ogbg-moltox21: 0.738726 val loss: 0.390092
[Epoch 91] ogbg-moltox21: 0.708576 test loss: 0.435542
[Epoch 92; Iter    27/  183] train: loss: 0.0586099
[Epoch 92; Iter    57/  183] train: loss: 0.0464409
[Epoch 92; Iter    87/  183] train: loss: 0.0332480
[Epoch 92; Iter   117/  183] train: loss: 0.0274548
[Epoch 92; Iter   147/  183] train: loss: 0.1033718
[Epoch 92; Iter   177/  183] train: loss: 0.0510807
[Epoch 92] ogbg-moltox21: 0.738949 val loss: 0.388490
[Epoch 92] ogbg-moltox21: 0.710691 test loss: 0.428711
[Epoch 93; Iter    24/  183] train: loss: 0.0367063
[Epoch 93; Iter    54/  183] train: loss: 0.0928600
[Epoch 93; Iter    84/  183] train: loss: 0.0410122
[Epoch 93; Iter   114/  183] train: loss: 0.0607246
[Epoch 93; Iter   144/  183] train: loss: 0.0636958
[Epoch 93; Iter   174/  183] train: loss: 0.0600751
[Epoch 93] ogbg-moltox21: 0.735863 val loss: 0.396518
[Epoch 93] ogbg-moltox21: 0.705784 test loss: 0.442463
[Epoch 94; Iter    21/  183] train: loss: 0.0580822
[Epoch 94; Iter    51/  183] train: loss: 0.0951141
[Epoch 94; Iter    81/  183] train: loss: 0.0649486
[Epoch 94; Iter   111/  183] train: loss: 0.0451121
[Epoch 94; Iter   141/  183] train: loss: 0.0476466
[Epoch 94; Iter   171/  183] train: loss: 0.0452589
[Epoch 94] ogbg-moltox21: 0.740091 val loss: 0.388938
[Epoch 94] ogbg-moltox21: 0.717351 test loss: 0.424897
[Epoch 95; Iter    18/  183] train: loss: 0.0736220
[Epoch 95; Iter    48/  183] train: loss: 0.0637928
[Epoch 95; Iter    78/  183] train: loss: 0.0670956
[Epoch 95; Iter   108/  183] train: loss: 0.0511647
[Epoch 95; Iter   138/  183] train: loss: 0.0458987
[Epoch 95; Iter   168/  183] train: loss: 0.0814004
[Epoch 95] ogbg-moltox21: 0.739670 val loss: 0.404752
[Epoch 95] ogbg-moltox21: 0.709191 test loss: 0.490860
[Epoch 96; Iter    15/  183] train: loss: 0.0845976
[Epoch 96; Iter    45/  183] train: loss: 0.0490100
[Epoch 96; Iter    75/  183] train: loss: 0.0495443
[Epoch 96; Iter   105/  183] train: loss: 0.0480130
[Epoch 96; Iter   135/  183] train: loss: 0.0478870
[Epoch 96; Iter   165/  183] train: loss: 0.0457685
[Epoch 96] ogbg-moltox21: 0.734536 val loss: 0.405535
[Epoch 96] ogbg-moltox21: 0.708759 test loss: 0.474157
[Epoch 97; Iter    12/  183] train: loss: 0.0418965
[Epoch 97; Iter    42/  183] train: loss: 0.0896677
[Epoch 97; Iter    72/  183] train: loss: 0.0377885
[Epoch 97; Iter   102/  183] train: loss: 0.1119674
[Epoch 97; Iter   132/  183] train: loss: 0.0475731
[Epoch 97; Iter   162/  183] train: loss: 0.0469448
[Epoch 97] ogbg-moltox21: 0.736325 val loss: 0.403997
[Epoch 97] ogbg-moltox21: 0.712174 test loss: 0.443015
[Epoch 98; Iter     9/  183] train: loss: 0.0727472
[Epoch 98; Iter    39/  183] train: loss: 0.0748042
[Epoch 98; Iter    69/  183] train: loss: 0.0614829
[Epoch 98; Iter    99/  183] train: loss: 0.0719650
[Epoch 98; Iter   129/  183] train: loss: 0.0733871
[Epoch 98; Iter   159/  183] train: loss: 0.0751599
[Epoch 98] ogbg-moltox21: 0.740305 val loss: 0.401122
[Epoch 98] ogbg-moltox21: 0.716655 test loss: 0.439758
[Epoch 99; Iter     6/  183] train: loss: 0.0470392
[Epoch 99; Iter    36/  183] train: loss: 0.0611049
[Epoch 99; Iter    66/  183] train: loss: 0.0621603
[Epoch 99; Iter    96/  183] train: loss: 0.0719233
[Epoch 99; Iter   126/  183] train: loss: 0.0663171
[Epoch 99; Iter   156/  183] train: loss: 0.0470369
[Epoch 99] ogbg-moltox21: 0.734747 val loss: 0.407895
[Epoch 99] ogbg-moltox21: 0.707310 test loss: 0.457009
[Epoch 100; Iter     3/  183] train: loss: 0.0324341
[Epoch 100; Iter    33/  183] train: loss: 0.0349712
[Epoch 100; Iter    63/  183] train: loss: 0.0587168
[Epoch 100; Iter    93/  183] train: loss: 0.0501769
[Epoch 100; Iter   123/  183] train: loss: 0.0221175
[Epoch 100; Iter   153/  183] train: loss: 0.0459466
[Epoch 100; Iter   183/  183] train: loss: 0.0354497
[Epoch 100] ogbg-moltox21: 0.738003 val loss: 0.412203
[Epoch 100] ogbg-moltox21: 0.711348 test loss: 0.449334
[Epoch 101; Iter    30/  183] train: loss: 0.0435487
[Epoch 101; Iter    60/  183] train: loss: 0.0590974
[Epoch 101; Iter    90/  183] train: loss: 0.0553153
[Epoch 101; Iter   120/  183] train: loss: 0.0515314
[Epoch 101; Iter   150/  183] train: loss: 0.0692048
[Epoch 101; Iter   180/  183] train: loss: 0.0418013
[Epoch 101] ogbg-moltox21: 0.738806 val loss: 0.412602
[Epoch 101] ogbg-moltox21: 0.709376 test loss: 0.463032
[Epoch 102; Iter    27/  183] train: loss: 0.0684797
[Epoch 102; Iter    57/  183] train: loss: 0.0418933
[Epoch 102; Iter    87/  183] train: loss: 0.0426740
[Epoch 102; Iter   117/  183] train: loss: 0.0417335
[Epoch 102; Iter   147/  183] train: loss: 0.0714361
[Epoch 102; Iter   177/  183] train: loss: 0.0575351
[Epoch 102] ogbg-moltox21: 0.737927 val loss: 0.407705
[Epoch 102] ogbg-moltox21: 0.709729 test loss: 0.451164
[Epoch 103; Iter    24/  183] train: loss: 0.0497712
[Epoch 103; Iter    54/  183] train: loss: 0.0980719
[Epoch 103; Iter    84/  183] train: loss: 0.0416213
[Epoch 103; Iter   114/  183] train: loss: 0.0540929
[Epoch 103; Iter   144/  183] train: loss: 0.0340231
[Epoch 103; Iter   174/  183] train: loss: 0.0316318
[Epoch 103] ogbg-moltox21: 0.734603 val loss: 0.411260
[Epoch 103] ogbg-moltox21: 0.704539 test loss: 0.455808
[Epoch 104; Iter    21/  183] train: loss: 0.0531256
[Epoch 104; Iter    51/  183] train: loss: 0.0638646
[Epoch 104; Iter    81/  183] train: loss: 0.0403892
[Epoch 104; Iter   111/  183] train: loss: 0.0361434
[Epoch 104; Iter   141/  183] train: loss: 0.0840582
[Epoch 104; Iter   171/  183] train: loss: 0.0478628
[Epoch 104] ogbg-moltox21: 0.739046 val loss: 0.412131
[Epoch 104] ogbg-moltox21: 0.711912 test loss: 0.451996
[Epoch 105; Iter    18/  183] train: loss: 0.0776349
[Epoch 105; Iter    48/  183] train: loss: 0.0423834
[Epoch 105; Iter    78/  183] train: loss: 0.0610798
[Epoch 105; Iter   108/  183] train: loss: 0.0341905
[Epoch 105; Iter   138/  183] train: loss: 0.0400822
[Epoch 105; Iter   168/  183] train: loss: 0.0272953
[Epoch 105] ogbg-moltox21: 0.736724 val loss: 0.418526
[Epoch 105] ogbg-moltox21: 0.707997 test loss: 0.461369
[Epoch 106; Iter    15/  183] train: loss: 0.0971924
[Epoch 106; Iter    45/  183] train: loss: 0.0769779
[Epoch 106; Iter    75/  183] train: loss: 0.0389507
[Epoch 106; Iter   105/  183] train: loss: 0.0443259
[Epoch 106; Iter   135/  183] train: loss: 0.0439902
[Epoch 106; Iter   165/  183] train: loss: 0.0530498
[Epoch 106] ogbg-moltox21: 0.731125 val loss: 0.419714
[Epoch 106] ogbg-moltox21: 0.708217 test loss: 0.456161
[Epoch 107; Iter    12/  183] train: loss: 0.0382866
[Epoch 107; Iter    42/  183] train: loss: 0.0301447
[Epoch 107; Iter    72/  183] train: loss: 0.0592004
[Epoch 107; Iter   102/  183] train: loss: 0.0328892
[Epoch 107; Iter   132/  183] train: loss: 0.0629748
[Epoch 107; Iter   162/  183] train: loss: 0.0314650
[Epoch 107] ogbg-moltox21: 0.736658 val loss: 0.422138
[Epoch 107] ogbg-moltox21: 0.711211 test loss: 0.464431
[Epoch 108; Iter     9/  183] train: loss: 0.0434951
[Epoch 108; Iter    39/  183] train: loss: 0.0371224
[Epoch 108; Iter    69/  183] train: loss: 0.0363981
[Epoch 108; Iter    99/  183] train: loss: 0.0404796
[Epoch 108; Iter   129/  183] train: loss: 0.0336118
[Epoch 108; Iter   159/  183] train: loss: 0.0669237
[Epoch 108] ogbg-moltox21: 0.734959 val loss: 0.420185
[Epoch 108] ogbg-moltox21: 0.710640 test loss: 0.494180
[Epoch 109; Iter     6/  183] train: loss: 0.0638582
[Epoch 109; Iter    36/  183] train: loss: 0.0280511
[Epoch 109; Iter    66/  183] train: loss: 0.0476532
[Epoch 109; Iter    96/  183] train: loss: 0.0325808
[Epoch 109; Iter   126/  183] train: loss: 0.0511783
[Epoch 109; Iter   156/  183] train: loss: 0.0402455
[Epoch 109] ogbg-moltox21: 0.733957 val loss: 0.444455
[Epoch 90] ogbg-moltox21: 0.737684 val loss: 0.398236
[Epoch 90] ogbg-moltox21: 0.709997 test loss: 0.450358
[Epoch 91; Iter    30/  183] train: loss: 0.0433987
[Epoch 91; Iter    60/  183] train: loss: 0.0486041
[Epoch 91; Iter    90/  183] train: loss: 0.0527432
[Epoch 91; Iter   120/  183] train: loss: 0.0298222
[Epoch 91; Iter   150/  183] train: loss: 0.0641489
[Epoch 91; Iter   180/  183] train: loss: 0.0304663
[Epoch 91] ogbg-moltox21: 0.736052 val loss: 0.393505
[Epoch 91] ogbg-moltox21: 0.711282 test loss: 0.430190
[Epoch 92; Iter    27/  183] train: loss: 0.0553101
[Epoch 92; Iter    57/  183] train: loss: 0.0834320
[Epoch 92; Iter    87/  183] train: loss: 0.0717733
[Epoch 92; Iter   117/  183] train: loss: 0.0999626
[Epoch 92; Iter   147/  183] train: loss: 0.0566978
[Epoch 92; Iter   177/  183] train: loss: 0.0733011
[Epoch 92] ogbg-moltox21: 0.738594 val loss: 0.408996
[Epoch 92] ogbg-moltox21: 0.711261 test loss: 0.450695
[Epoch 93; Iter    24/  183] train: loss: 0.0477912
[Epoch 93; Iter    54/  183] train: loss: 0.0641280
[Epoch 93; Iter    84/  183] train: loss: 0.0484152
[Epoch 93; Iter   114/  183] train: loss: 0.0505571
[Epoch 93; Iter   144/  183] train: loss: 0.0480141
[Epoch 93; Iter   174/  183] train: loss: 0.0888445
[Epoch 93] ogbg-moltox21: 0.736882 val loss: 0.411415
[Epoch 93] ogbg-moltox21: 0.709717 test loss: 0.494023
[Epoch 94; Iter    21/  183] train: loss: 0.0726174
[Epoch 94; Iter    51/  183] train: loss: 0.0541685
[Epoch 94; Iter    81/  183] train: loss: 0.0462189
[Epoch 94; Iter   111/  183] train: loss: 0.0961536
[Epoch 94; Iter   141/  183] train: loss: 0.0714104
[Epoch 94; Iter   171/  183] train: loss: 0.0789571
[Epoch 94] ogbg-moltox21: 0.735987 val loss: 0.405404
[Epoch 94] ogbg-moltox21: 0.710948 test loss: 0.450675
[Epoch 95; Iter    18/  183] train: loss: 0.0360463
[Epoch 95; Iter    48/  183] train: loss: 0.0760136
[Epoch 95; Iter    78/  183] train: loss: 0.0988236
[Epoch 95; Iter   108/  183] train: loss: 0.0538534
[Epoch 95; Iter   138/  183] train: loss: 0.0759743
[Epoch 95; Iter   168/  183] train: loss: 0.0512107
[Epoch 95] ogbg-moltox21: 0.731742 val loss: 0.423958
[Epoch 95] ogbg-moltox21: 0.706651 test loss: 0.465510
[Epoch 96; Iter    15/  183] train: loss: 0.0515047
[Epoch 96; Iter    45/  183] train: loss: 0.0713911
[Epoch 96; Iter    75/  183] train: loss: 0.0567063
[Epoch 96; Iter   105/  183] train: loss: 0.0684714
[Epoch 96; Iter   135/  183] train: loss: 0.0349485
[Epoch 96; Iter   165/  183] train: loss: 0.0417596
[Epoch 96] ogbg-moltox21: 0.734016 val loss: 0.417934
[Epoch 96] ogbg-moltox21: 0.707041 test loss: 0.480463
[Epoch 97; Iter    12/  183] train: loss: 0.0593862
[Epoch 97; Iter    42/  183] train: loss: 0.0855580
[Epoch 97; Iter    72/  183] train: loss: 0.0466167
[Epoch 97; Iter   102/  183] train: loss: 0.0824364
[Epoch 97; Iter   132/  183] train: loss: 0.0769037
[Epoch 97; Iter   162/  183] train: loss: 0.0499188
[Epoch 97] ogbg-moltox21: 0.738906 val loss: 0.411482
[Epoch 97] ogbg-moltox21: 0.713027 test loss: 0.597985
[Epoch 98; Iter     9/  183] train: loss: 0.0784455
[Epoch 98; Iter    39/  183] train: loss: 0.0604059
[Epoch 98; Iter    69/  183] train: loss: 0.0635989
[Epoch 98; Iter    99/  183] train: loss: 0.0697411
[Epoch 98; Iter   129/  183] train: loss: 0.0301950
[Epoch 98; Iter   159/  183] train: loss: 0.0484720
[Epoch 98] ogbg-moltox21: 0.738958 val loss: 0.422466
[Epoch 98] ogbg-moltox21: 0.707699 test loss: 0.494743
[Epoch 99; Iter     6/  183] train: loss: 0.0448649
[Epoch 99; Iter    36/  183] train: loss: 0.0764328
[Epoch 99; Iter    66/  183] train: loss: 0.0401025
[Epoch 99; Iter    96/  183] train: loss: 0.0390341
[Epoch 99; Iter   126/  183] train: loss: 0.0403387
[Epoch 99; Iter   156/  183] train: loss: 0.0462827
[Epoch 99] ogbg-moltox21: 0.730073 val loss: 0.420904
[Epoch 99] ogbg-moltox21: 0.700814 test loss: 0.530838
[Epoch 100; Iter     3/  183] train: loss: 0.0351957
[Epoch 100; Iter    33/  183] train: loss: 0.0390383
[Epoch 100; Iter    63/  183] train: loss: 0.0461657
[Epoch 100; Iter    93/  183] train: loss: 0.0366529
[Epoch 100; Iter   123/  183] train: loss: 0.0944092
[Epoch 100; Iter   153/  183] train: loss: 0.0605770
[Epoch 100; Iter   183/  183] train: loss: 0.0718973
[Epoch 100] ogbg-moltox21: 0.738033 val loss: 0.418792
[Epoch 100] ogbg-moltox21: 0.708115 test loss: 0.584385
[Epoch 101; Iter    30/  183] train: loss: 0.0330554
[Epoch 101; Iter    60/  183] train: loss: 0.0486223
[Epoch 101; Iter    90/  183] train: loss: 0.0639792
[Epoch 101; Iter   120/  183] train: loss: 0.0457786
[Epoch 101; Iter   150/  183] train: loss: 0.0777653
[Epoch 101; Iter   180/  183] train: loss: 0.0569620
[Epoch 101] ogbg-moltox21: 0.738216 val loss: 0.432816
[Epoch 101] ogbg-moltox21: 0.705475 test loss: 0.565857
[Epoch 102; Iter    27/  183] train: loss: 0.0755069
[Epoch 102; Iter    57/  183] train: loss: 0.0520974
[Epoch 102; Iter    87/  183] train: loss: 0.0469571
[Epoch 102; Iter   117/  183] train: loss: 0.0738520
[Epoch 102; Iter   147/  183] train: loss: 0.0583490
[Epoch 102; Iter   177/  183] train: loss: 0.0763699
[Epoch 102] ogbg-moltox21: 0.738118 val loss: 0.434842
[Epoch 102] ogbg-moltox21: 0.710153 test loss: 0.603772
[Epoch 103; Iter    24/  183] train: loss: 0.0735821
[Epoch 103; Iter    54/  183] train: loss: 0.0623729
[Epoch 103; Iter    84/  183] train: loss: 0.0377320
[Epoch 103; Iter   114/  183] train: loss: 0.0342618
[Epoch 103; Iter   144/  183] train: loss: 0.0562709
[Epoch 103; Iter   174/  183] train: loss: 0.0472818
[Epoch 103] ogbg-moltox21: 0.739408 val loss: 0.415621
[Epoch 103] ogbg-moltox21: 0.706129 test loss: 0.527843
[Epoch 104; Iter    21/  183] train: loss: 0.0679248
[Epoch 104; Iter    51/  183] train: loss: 0.0679507
[Epoch 104; Iter    81/  183] train: loss: 0.0458899
[Epoch 104; Iter   111/  183] train: loss: 0.0289684
[Epoch 104; Iter   141/  183] train: loss: 0.0691215
[Epoch 104; Iter   171/  183] train: loss: 0.0799102
[Epoch 104] ogbg-moltox21: 0.734063 val loss: 0.441080
[Epoch 104] ogbg-moltox21: 0.706162 test loss: 0.583134
[Epoch 105; Iter    18/  183] train: loss: 0.0347081
[Epoch 105; Iter    48/  183] train: loss: 0.0484597
[Epoch 105; Iter    78/  183] train: loss: 0.0444013
[Epoch 105; Iter   108/  183] train: loss: 0.0595972
[Epoch 105; Iter   138/  183] train: loss: 0.0653419
[Epoch 105; Iter   168/  183] train: loss: 0.0511768
[Epoch 105] ogbg-moltox21: 0.732406 val loss: 0.429930
[Epoch 105] ogbg-moltox21: 0.704789 test loss: 0.541320
[Epoch 106; Iter    15/  183] train: loss: 0.0506215
[Epoch 106; Iter    45/  183] train: loss: 0.0526332
[Epoch 106; Iter    75/  183] train: loss: 0.0572821
[Epoch 106; Iter   105/  183] train: loss: 0.0754053
[Epoch 106; Iter   135/  183] train: loss: 0.0741533
[Epoch 106; Iter   165/  183] train: loss: 0.0486968
[Epoch 106] ogbg-moltox21: 0.739067 val loss: 0.429501
[Epoch 106] ogbg-moltox21: 0.714077 test loss: 0.608198
[Epoch 107; Iter    12/  183] train: loss: 0.0457325
[Epoch 107; Iter    42/  183] train: loss: 0.0356246
[Epoch 107; Iter    72/  183] train: loss: 0.0589461
[Epoch 107; Iter   102/  183] train: loss: 0.0349945
[Epoch 107; Iter   132/  183] train: loss: 0.0652481
[Epoch 107; Iter   162/  183] train: loss: 0.0334186
[Epoch 107] ogbg-moltox21: 0.734196 val loss: 0.437509
[Epoch 107] ogbg-moltox21: 0.713074 test loss: 0.662124
[Epoch 108; Iter     9/  183] train: loss: 0.0514206
[Epoch 108; Iter    39/  183] train: loss: 0.0394784
[Epoch 108; Iter    69/  183] train: loss: 0.0556311
[Epoch 108; Iter    99/  183] train: loss: 0.0772686
[Epoch 108; Iter   129/  183] train: loss: 0.0524706
[Epoch 108; Iter   159/  183] train: loss: 0.0377320
[Epoch 108] ogbg-moltox21: 0.732351 val loss: 0.450532
[Epoch 108] ogbg-moltox21: 0.704920 test loss: 0.547473
[Epoch 109; Iter     6/  183] train: loss: 0.0614409
[Epoch 109; Iter    36/  183] train: loss: 0.0490040
[Epoch 109; Iter    66/  183] train: loss: 0.0531672
[Epoch 109; Iter    96/  183] train: loss: 0.0440543
[Epoch 109; Iter   126/  183] train: loss: 0.0540133
[Epoch 109; Iter   156/  183] train: loss: 0.0438779
[Epoch 109] ogbg-moltox21: 0.732891 val loss: 0.431504
[Epoch 90] ogbg-moltox21: 0.741048 val loss: 0.442797
[Epoch 90] ogbg-moltox21: 0.718550 test loss: 0.444890
[Epoch 91; Iter    30/  183] train: loss: 0.0353403
[Epoch 91; Iter    60/  183] train: loss: 0.0351197
[Epoch 91; Iter    90/  183] train: loss: 0.0230927
[Epoch 91; Iter   120/  183] train: loss: 0.0698536
[Epoch 91; Iter   150/  183] train: loss: 0.0727071
[Epoch 91; Iter   180/  183] train: loss: 0.0551880
[Epoch 91] ogbg-moltox21: 0.746606 val loss: 0.451506
[Epoch 91] ogbg-moltox21: 0.719540 test loss: 0.448575
[Epoch 92; Iter    27/  183] train: loss: 0.0516579
[Epoch 92; Iter    57/  183] train: loss: 0.0294552
[Epoch 92; Iter    87/  183] train: loss: 0.0260051
[Epoch 92; Iter   117/  183] train: loss: 0.0500046
[Epoch 92; Iter   147/  183] train: loss: 0.0316970
[Epoch 92; Iter   177/  183] train: loss: 0.0326814
[Epoch 92] ogbg-moltox21: 0.743903 val loss: 0.431103
[Epoch 92] ogbg-moltox21: 0.717443 test loss: 0.459693
[Epoch 93; Iter    24/  183] train: loss: 0.1033550
[Epoch 93; Iter    54/  183] train: loss: 0.0424032
[Epoch 93; Iter    84/  183] train: loss: 0.0390003
[Epoch 93; Iter   114/  183] train: loss: 0.0425653
[Epoch 93; Iter   144/  183] train: loss: 0.0415693
[Epoch 93; Iter   174/  183] train: loss: 0.0561896
[Epoch 93] ogbg-moltox21: 0.739768 val loss: 0.458847
[Epoch 93] ogbg-moltox21: 0.715488 test loss: 0.466263
[Epoch 94; Iter    21/  183] train: loss: 0.0826183
[Epoch 94; Iter    51/  183] train: loss: 0.0489492
[Epoch 94; Iter    81/  183] train: loss: 0.0236310
[Epoch 94; Iter   111/  183] train: loss: 0.0365422
[Epoch 94; Iter   141/  183] train: loss: 0.0364337
[Epoch 94; Iter   171/  183] train: loss: 0.0484493
[Epoch 94] ogbg-moltox21: 0.744898 val loss: 0.478215
[Epoch 94] ogbg-moltox21: 0.719722 test loss: 0.466572
[Epoch 95; Iter    18/  183] train: loss: 0.0529751
[Epoch 95; Iter    48/  183] train: loss: 0.0386372
[Epoch 95; Iter    78/  183] train: loss: 0.0312568
[Epoch 95; Iter   108/  183] train: loss: 0.0428493
[Epoch 95; Iter   138/  183] train: loss: 0.0389346
[Epoch 95; Iter   168/  183] train: loss: 0.0491056
[Epoch 95] ogbg-moltox21: 0.740170 val loss: 0.475126
[Epoch 95] ogbg-moltox21: 0.716861 test loss: 0.468569
[Epoch 96; Iter    15/  183] train: loss: 0.0636474
[Epoch 96; Iter    45/  183] train: loss: 0.0554416
[Epoch 96; Iter    75/  183] train: loss: 0.0253856
[Epoch 96; Iter   105/  183] train: loss: 0.0329856
[Epoch 96; Iter   135/  183] train: loss: 0.0390180
[Epoch 96; Iter   165/  183] train: loss: 0.0496443
[Epoch 96] ogbg-moltox21: 0.736980 val loss: 0.447569
[Epoch 96] ogbg-moltox21: 0.714615 test loss: 0.458612
[Epoch 97; Iter    12/  183] train: loss: 0.0513072
[Epoch 97; Iter    42/  183] train: loss: 0.0437790
[Epoch 97; Iter    72/  183] train: loss: 0.0717019
[Epoch 97; Iter   102/  183] train: loss: 0.0279351
[Epoch 97; Iter   132/  183] train: loss: 0.0462880
[Epoch 97; Iter   162/  183] train: loss: 0.0459940
[Epoch 97] ogbg-moltox21: 0.737316 val loss: 0.477822
[Epoch 97] ogbg-moltox21: 0.715781 test loss: 0.469282
[Epoch 98; Iter     9/  183] train: loss: 0.0430607
[Epoch 98; Iter    39/  183] train: loss: 0.0146841
[Epoch 98; Iter    69/  183] train: loss: 0.0554325
[Epoch 98; Iter    99/  183] train: loss: 0.0347969
[Epoch 98; Iter   129/  183] train: loss: 0.0422496
[Epoch 98; Iter   159/  183] train: loss: 0.0174653
[Epoch 98] ogbg-moltox21: 0.737067 val loss: 0.491105
[Epoch 98] ogbg-moltox21: 0.714478 test loss: 0.488265
[Epoch 99; Iter     6/  183] train: loss: 0.0548929
[Epoch 99; Iter    36/  183] train: loss: 0.0285406
[Epoch 99; Iter    66/  183] train: loss: 0.0420540
[Epoch 99; Iter    96/  183] train: loss: 0.0627413
[Epoch 99; Iter   126/  183] train: loss: 0.0441094
[Epoch 99; Iter   156/  183] train: loss: 0.0264251
[Epoch 99] ogbg-moltox21: 0.736390 val loss: 0.504679
[Epoch 99] ogbg-moltox21: 0.714518 test loss: 0.491407
[Epoch 100; Iter     3/  183] train: loss: 0.0365220
[Epoch 100; Iter    33/  183] train: loss: 0.0669481
[Epoch 100; Iter    63/  183] train: loss: 0.0733889
[Epoch 100; Iter    93/  183] train: loss: 0.0357325
[Epoch 100; Iter   123/  183] train: loss: 0.0290520
[Epoch 100; Iter   153/  183] train: loss: 0.0403455
[Epoch 100; Iter   183/  183] train: loss: 0.0534788
[Epoch 100] ogbg-moltox21: 0.736026 val loss: 0.482644
[Epoch 100] ogbg-moltox21: 0.710571 test loss: 0.477036
[Epoch 101; Iter    30/  183] train: loss: 0.0395852
[Epoch 101; Iter    60/  183] train: loss: 0.0581729
[Epoch 101; Iter    90/  183] train: loss: 0.0360784
[Epoch 101; Iter   120/  183] train: loss: 0.0452109
[Epoch 101; Iter   150/  183] train: loss: 0.0403958
[Epoch 101; Iter   180/  183] train: loss: 0.0384823
[Epoch 101] ogbg-moltox21: 0.740969 val loss: 0.487867
[Epoch 101] ogbg-moltox21: 0.717155 test loss: 0.475410
[Epoch 102; Iter    27/  183] train: loss: 0.0174095
[Epoch 102; Iter    57/  183] train: loss: 0.0400342
[Epoch 102; Iter    87/  183] train: loss: 0.0169891
[Epoch 102; Iter   117/  183] train: loss: 0.0558980
[Epoch 102; Iter   147/  183] train: loss: 0.0414498
[Epoch 102; Iter   177/  183] train: loss: 0.0522096
[Epoch 102] ogbg-moltox21: 0.737304 val loss: 0.490245
[Epoch 102] ogbg-moltox21: 0.714117 test loss: 0.479232
[Epoch 103; Iter    24/  183] train: loss: 0.0221816
[Epoch 103; Iter    54/  183] train: loss: 0.0444255
[Epoch 103; Iter    84/  183] train: loss: 0.0565169
[Epoch 103; Iter   114/  183] train: loss: 0.0473878
[Epoch 103; Iter   144/  183] train: loss: 0.0350168
[Epoch 103; Iter   174/  183] train: loss: 0.0201822
[Epoch 103] ogbg-moltox21: 0.740259 val loss: 0.470324
[Epoch 103] ogbg-moltox21: 0.717934 test loss: 0.484786
[Epoch 104; Iter    21/  183] train: loss: 0.0390079
[Epoch 104; Iter    51/  183] train: loss: 0.0242024
[Epoch 104; Iter    81/  183] train: loss: 0.0521136
[Epoch 104; Iter   111/  183] train: loss: 0.0653516
[Epoch 104; Iter   141/  183] train: loss: 0.0744627
[Epoch 104; Iter   171/  183] train: loss: 0.0323940
[Epoch 104] ogbg-moltox21: 0.738222 val loss: 0.485122
[Epoch 104] ogbg-moltox21: 0.716760 test loss: 0.491334
[Epoch 105; Iter    18/  183] train: loss: 0.0416096
[Epoch 105; Iter    48/  183] train: loss: 0.0813615
[Epoch 105; Iter    78/  183] train: loss: 0.0398216
[Epoch 105; Iter   108/  183] train: loss: 0.0157793
[Epoch 105; Iter   138/  183] train: loss: 0.0421370
[Epoch 105; Iter   168/  183] train: loss: 0.0178639
[Epoch 105] ogbg-moltox21: 0.735709 val loss: 0.506960
[Epoch 105] ogbg-moltox21: 0.717739 test loss: 0.489373
[Epoch 106; Iter    15/  183] train: loss: 0.0295263
[Epoch 106; Iter    45/  183] train: loss: 0.0270892
[Epoch 106; Iter    75/  183] train: loss: 0.0314948
[Epoch 106; Iter   105/  183] train: loss: 0.0712307
[Epoch 106; Iter   135/  183] train: loss: 0.0342627
[Epoch 106; Iter   165/  183] train: loss: 0.0238519
[Epoch 106] ogbg-moltox21: 0.733793 val loss: 0.494849
[Epoch 106] ogbg-moltox21: 0.713746 test loss: 0.496021
[Epoch 107; Iter    12/  183] train: loss: 0.0294455
[Epoch 107; Iter    42/  183] train: loss: 0.0392683
[Epoch 107; Iter    72/  183] train: loss: 0.0882900
[Epoch 107; Iter   102/  183] train: loss: 0.0365148
[Epoch 107; Iter   132/  183] train: loss: 0.0326409
[Epoch 107; Iter   162/  183] train: loss: 0.0644213
[Epoch 107] ogbg-moltox21: 0.747409 val loss: 0.490471
[Epoch 107] ogbg-moltox21: 0.718276 test loss: 0.492344
[Epoch 108; Iter     9/  183] train: loss: 0.0167880
[Epoch 108; Iter    39/  183] train: loss: 0.0294416
[Epoch 108; Iter    69/  183] train: loss: 0.0479325
[Epoch 108; Iter    99/  183] train: loss: 0.0248795
[Epoch 108; Iter   129/  183] train: loss: 0.0443732
[Epoch 108; Iter   159/  183] train: loss: 0.0334292
[Epoch 108] ogbg-moltox21: 0.737008 val loss: 0.497190
[Epoch 108] ogbg-moltox21: 0.712633 test loss: 0.502204
[Epoch 109; Iter     6/  183] train: loss: 0.0354630
[Epoch 109; Iter    36/  183] train: loss: 0.0211627
[Epoch 109; Iter    66/  183] train: loss: 0.0230209
[Epoch 109; Iter    96/  183] train: loss: 0.0485818
[Epoch 109; Iter   126/  183] train: loss: 0.0237319
[Epoch 109; Iter   156/  183] train: loss: 0.0193788
[Epoch 109] ogbg-moltox21: 0.735478 val loss: 0.481426
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0824519
[Epoch 101] ogbg-moltox21: 0.703602 val loss: 0.513706
[Epoch 101] ogbg-moltox21: 0.696618 test loss: 0.521137
[Epoch 102; Iter    13/  157] train: loss: 0.0657665
[Epoch 102; Iter    43/  157] train: loss: 0.0449117
[Epoch 102; Iter    73/  157] train: loss: 0.0218012
[Epoch 102; Iter   103/  157] train: loss: 0.0330983
[Epoch 102; Iter   133/  157] train: loss: 0.0602818
[Epoch 102] ogbg-moltox21: 0.706726 val loss: 0.547209
[Epoch 102] ogbg-moltox21: 0.699373 test loss: 0.519730
[Epoch 103; Iter     6/  157] train: loss: 0.0369592
[Epoch 103; Iter    36/  157] train: loss: 0.0508904
[Epoch 103; Iter    66/  157] train: loss: 0.0424838
[Epoch 103; Iter    96/  157] train: loss: 0.0303214
[Epoch 103; Iter   126/  157] train: loss: 0.0325863
[Epoch 103; Iter   156/  157] train: loss: 0.0725128
[Epoch 103] ogbg-moltox21: 0.704748 val loss: 0.528150
[Epoch 103] ogbg-moltox21: 0.698476 test loss: 0.507396
[Epoch 104; Iter    29/  157] train: loss: 0.0256112
[Epoch 104; Iter    59/  157] train: loss: 0.0337431
[Epoch 104; Iter    89/  157] train: loss: 0.0379431
[Epoch 104; Iter   119/  157] train: loss: 0.0257859
[Epoch 104; Iter   149/  157] train: loss: 0.0248502
[Epoch 104] ogbg-moltox21: 0.696187 val loss: 0.565769
[Epoch 104] ogbg-moltox21: 0.691810 test loss: 0.549703
[Epoch 105; Iter    22/  157] train: loss: 0.0331708
[Epoch 105; Iter    52/  157] train: loss: 0.0574923
[Epoch 105; Iter    82/  157] train: loss: 0.0325572
[Epoch 105; Iter   112/  157] train: loss: 0.0340542
[Epoch 105; Iter   142/  157] train: loss: 0.0377221
[Epoch 105] ogbg-moltox21: 0.702109 val loss: 0.589605
[Epoch 105] ogbg-moltox21: 0.693269 test loss: 0.564947
[Epoch 106; Iter    15/  157] train: loss: 0.0514094
[Epoch 106; Iter    45/  157] train: loss: 0.0504420
[Epoch 106; Iter    75/  157] train: loss: 0.0317943
[Epoch 106; Iter   105/  157] train: loss: 0.0398597
[Epoch 106; Iter   135/  157] train: loss: 0.0595487
[Epoch 106] ogbg-moltox21: 0.695261 val loss: 0.530973
[Epoch 106] ogbg-moltox21: 0.690510 test loss: 0.542675
[Epoch 107; Iter     8/  157] train: loss: 0.0333322
[Epoch 107; Iter    38/  157] train: loss: 0.0308075
[Epoch 107; Iter    68/  157] train: loss: 0.0320979
[Epoch 107; Iter    98/  157] train: loss: 0.0461809
[Epoch 107; Iter   128/  157] train: loss: 0.0356091
[Epoch 107] ogbg-moltox21: 0.695252 val loss: 0.522010
[Epoch 107] ogbg-moltox21: 0.690943 test loss: 0.529632
[Epoch 108; Iter     1/  157] train: loss: 0.0476741
[Epoch 108; Iter    31/  157] train: loss: 0.0212443
[Epoch 108; Iter    61/  157] train: loss: 0.0234006
[Epoch 108; Iter    91/  157] train: loss: 0.0212111
[Epoch 108; Iter   121/  157] train: loss: 0.0786391
[Epoch 108; Iter   151/  157] train: loss: 0.0316217
[Epoch 108] ogbg-moltox21: 0.701124 val loss: 0.535896
[Epoch 108] ogbg-moltox21: 0.694471 test loss: 0.545143
[Epoch 109; Iter    24/  157] train: loss: 0.0468429
[Epoch 109; Iter    54/  157] train: loss: 0.0546359
[Epoch 109; Iter    84/  157] train: loss: 0.0574876
[Epoch 109; Iter   114/  157] train: loss: 0.0371324
[Epoch 109; Iter   144/  157] train: loss: 0.0436623
[Epoch 109] ogbg-moltox21: 0.696802 val loss: 0.580170
[Epoch 109] ogbg-moltox21: 0.692570 test loss: 0.611658
[Epoch 110; Iter    17/  157] train: loss: 0.0302284
[Epoch 110; Iter    47/  157] train: loss: 0.0354121
[Epoch 110; Iter    77/  157] train: loss: 0.0329713
[Epoch 110; Iter   107/  157] train: loss: 0.0657582
[Epoch 110; Iter   137/  157] train: loss: 0.0783644
[Epoch 110] ogbg-moltox21: 0.703630 val loss: 0.585842
[Epoch 110] ogbg-moltox21: 0.695784 test loss: 0.537238
[Epoch 111; Iter    10/  157] train: loss: 0.0118604
[Epoch 111; Iter    40/  157] train: loss: 0.0306188
[Epoch 111; Iter    70/  157] train: loss: 0.0381867
[Epoch 111; Iter   100/  157] train: loss: 0.0358991
[Epoch 111; Iter   130/  157] train: loss: 0.0369028
[Epoch 111] ogbg-moltox21: 0.695197 val loss: 0.533955
[Epoch 111] ogbg-moltox21: 0.686901 test loss: 0.548752
[Epoch 112; Iter     3/  157] train: loss: 0.0311645
[Epoch 112; Iter    33/  157] train: loss: 0.0524711
[Epoch 112; Iter    63/  157] train: loss: 0.0276572
[Epoch 112; Iter    93/  157] train: loss: 0.0527297
[Epoch 112; Iter   123/  157] train: loss: 0.0245521
[Epoch 112; Iter   153/  157] train: loss: 0.0415523
[Epoch 112] ogbg-moltox21: 0.701706 val loss: 0.607488
[Epoch 112] ogbg-moltox21: 0.693488 test loss: 0.549019
[Epoch 113; Iter    26/  157] train: loss: 0.0651760
[Epoch 113; Iter    56/  157] train: loss: 0.0292739
[Epoch 113; Iter    86/  157] train: loss: 0.0801042
[Epoch 113; Iter   116/  157] train: loss: 0.0230026
[Epoch 113; Iter   146/  157] train: loss: 0.0531246
[Epoch 113] ogbg-moltox21: 0.705795 val loss: 0.513600
[Epoch 113] ogbg-moltox21: 0.698514 test loss: 0.517574
[Epoch 114; Iter    19/  157] train: loss: 0.0343347
[Epoch 114; Iter    49/  157] train: loss: 0.0479018
[Epoch 114; Iter    79/  157] train: loss: 0.0434058
[Epoch 114; Iter   109/  157] train: loss: 0.0263918
[Epoch 114; Iter   139/  157] train: loss: 0.0212659
[Epoch 114] ogbg-moltox21: 0.705542 val loss: 0.542010
[Epoch 114] ogbg-moltox21: 0.696630 test loss: 0.538252
[Epoch 115; Iter    12/  157] train: loss: 0.0228864
[Epoch 115; Iter    42/  157] train: loss: 0.0348951
[Epoch 115; Iter    72/  157] train: loss: 0.0354004
[Epoch 115; Iter   102/  157] train: loss: 0.0600466
[Epoch 115; Iter   132/  157] train: loss: 0.0349288
[Epoch 115] ogbg-moltox21: 0.700793 val loss: 0.541633
[Epoch 115] ogbg-moltox21: 0.696521 test loss: 0.549025
[Epoch 116; Iter     5/  157] train: loss: 0.0205708
[Epoch 116; Iter    35/  157] train: loss: 0.0207439
[Epoch 116; Iter    65/  157] train: loss: 0.0278173
[Epoch 116; Iter    95/  157] train: loss: 0.0302499
[Epoch 116; Iter   125/  157] train: loss: 0.0396881
[Epoch 116; Iter   155/  157] train: loss: 0.0328014
[Epoch 116] ogbg-moltox21: 0.699426 val loss: 0.548719
[Epoch 116] ogbg-moltox21: 0.690053 test loss: 0.568209
[Epoch 117; Iter    28/  157] train: loss: 0.0387423
[Epoch 117; Iter    58/  157] train: loss: 0.1172845
[Epoch 117; Iter    88/  157] train: loss: 0.0644880
[Epoch 117; Iter   118/  157] train: loss: 0.0668492
[Epoch 117; Iter   148/  157] train: loss: 0.0453154
[Epoch 117] ogbg-moltox21: 0.701759 val loss: 0.538410
[Epoch 117] ogbg-moltox21: 0.693130 test loss: 0.543013
[Epoch 118; Iter    21/  157] train: loss: 0.0358628
[Epoch 118; Iter    51/  157] train: loss: 0.0441066
[Epoch 118; Iter    81/  157] train: loss: 0.0624908
[Epoch 118; Iter   111/  157] train: loss: 0.0325656
[Epoch 118; Iter   141/  157] train: loss: 0.0333678
[Epoch 118] ogbg-moltox21: 0.699304 val loss: 0.547171
[Epoch 118] ogbg-moltox21: 0.691207 test loss: 0.536683
[Epoch 119; Iter    14/  157] train: loss: 0.0286992
[Epoch 119; Iter    44/  157] train: loss: 0.0302339
[Epoch 119; Iter    74/  157] train: loss: 0.0307059
[Epoch 119; Iter   104/  157] train: loss: 0.0317041
[Epoch 119; Iter   134/  157] train: loss: 0.0330231
[Epoch 119] ogbg-moltox21: 0.701024 val loss: 0.596451
[Epoch 119] ogbg-moltox21: 0.689254 test loss: 0.540746
[Epoch 120; Iter     7/  157] train: loss: 0.0264144
[Epoch 120; Iter    37/  157] train: loss: 0.0470489
[Epoch 120; Iter    67/  157] train: loss: 0.0165127
[Epoch 120; Iter    97/  157] train: loss: 0.0343873
[Epoch 120; Iter   127/  157] train: loss: 0.0343988
[Epoch 120; Iter   157/  157] train: loss: 0.0592053
[Epoch 120] ogbg-moltox21: 0.696854 val loss: 0.571365
[Epoch 120] ogbg-moltox21: 0.693450 test loss: 0.571983
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 16.
Statistics on  val_best_checkpoint
mean_pred: -2.8984274864196777
std_pred: 2.2461130619049072
mean_targets: nan
std_targets: nan
prcauc: 0.2778506765334636
rocauc: 0.7749114393845867
ogbg-moltox21: 0.7749114393845867
OGBNanLabelBCEWithLogitsLoss: 0.32269697805058284
Statistics on  test
mean_pred: -2.741762638092041
std_pred: 2.3263754844665527
mean_targets: nan
std_targets: nan
prcauc: 0.2536002314930116
rocauc: 0.7448267865008665
ogbg-moltox21: 0.7448267865008665
OGBNanLabelBCEWithLogitsLoss: 0.348224854905088
Statistics on  train
mean_pred: -3.595249891281128
std_pred: 1.7175408601760864
mean_targets: nan
std_targets: nan
prcauc: 0.45255223587393534
rocauc: 0.8734666682408014
ogbg-moltox21: 0.8734666682408014
OGBNanLabelBCEWithLogitsLoss: 0.14985581496908407
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0724694
[Epoch 101] ogbg-moltox21: 0.730925 val loss: 0.412420
[Epoch 101] ogbg-moltox21: 0.706937 test loss: 0.445437
[Epoch 102; Iter    13/  157] train: loss: 0.0456598
[Epoch 102; Iter    43/  157] train: loss: 0.0713768
[Epoch 102; Iter    73/  157] train: loss: 0.0325389
[Epoch 102; Iter   103/  157] train: loss: 0.0981672
[Epoch 102; Iter   133/  157] train: loss: 0.0502818
[Epoch 102] ogbg-moltox21: 0.727614 val loss: 0.425566
[Epoch 102] ogbg-moltox21: 0.704547 test loss: 0.464772
[Epoch 103; Iter     6/  157] train: loss: 0.0422155
[Epoch 103; Iter    36/  157] train: loss: 0.0396970
[Epoch 103; Iter    66/  157] train: loss: 0.0618209
[Epoch 103; Iter    96/  157] train: loss: 0.0725454
[Epoch 103; Iter   126/  157] train: loss: 0.0793207
[Epoch 103; Iter   156/  157] train: loss: 0.0547670
[Epoch 103] ogbg-moltox21: 0.723581 val loss: 0.435330
[Epoch 103] ogbg-moltox21: 0.703838 test loss: 0.472326
[Epoch 104; Iter    29/  157] train: loss: 0.0883281
[Epoch 104; Iter    59/  157] train: loss: 0.0704003
[Epoch 104; Iter    89/  157] train: loss: 0.0518899
[Epoch 104; Iter   119/  157] train: loss: 0.0769877
[Epoch 104; Iter   149/  157] train: loss: 0.0403510
[Epoch 104] ogbg-moltox21: 0.732813 val loss: 0.415350
[Epoch 104] ogbg-moltox21: 0.712990 test loss: 0.446981
[Epoch 105; Iter    22/  157] train: loss: 0.0568719
[Epoch 105; Iter    52/  157] train: loss: 0.0990747
[Epoch 105; Iter    82/  157] train: loss: 0.0425670
[Epoch 105; Iter   112/  157] train: loss: 0.0353742
[Epoch 105; Iter   142/  157] train: loss: 0.0729670
[Epoch 105] ogbg-moltox21: 0.727477 val loss: 0.421582
[Epoch 105] ogbg-moltox21: 0.706494 test loss: 0.455564
[Epoch 106; Iter    15/  157] train: loss: 0.0645009
[Epoch 106; Iter    45/  157] train: loss: 0.0274484
[Epoch 106; Iter    75/  157] train: loss: 0.0390645
[Epoch 106; Iter   105/  157] train: loss: 0.0410859
[Epoch 106; Iter   135/  157] train: loss: 0.0357650
[Epoch 106] ogbg-moltox21: 0.733079 val loss: 0.412856
[Epoch 106] ogbg-moltox21: 0.712601 test loss: 0.438561
[Epoch 107; Iter     8/  157] train: loss: 0.0498311
[Epoch 107; Iter    38/  157] train: loss: 0.0797938
[Epoch 107; Iter    68/  157] train: loss: 0.0434542
[Epoch 107; Iter    98/  157] train: loss: 0.0426764
[Epoch 107; Iter   128/  157] train: loss: 0.0693017
[Epoch 107] ogbg-moltox21: 0.723932 val loss: 0.417174
[Epoch 107] ogbg-moltox21: 0.703412 test loss: 0.449521
[Epoch 108; Iter     1/  157] train: loss: 0.0418699
[Epoch 108; Iter    31/  157] train: loss: 0.0568891
[Epoch 108; Iter    61/  157] train: loss: 0.0655087
[Epoch 108; Iter    91/  157] train: loss: 0.0560886
[Epoch 108; Iter   121/  157] train: loss: 0.0514211
[Epoch 108; Iter   151/  157] train: loss: 0.0415478
[Epoch 108] ogbg-moltox21: 0.727934 val loss: 0.416147
[Epoch 108] ogbg-moltox21: 0.707658 test loss: 0.449236
[Epoch 109; Iter    24/  157] train: loss: 0.0369065
[Epoch 109; Iter    54/  157] train: loss: 0.1284018
[Epoch 109; Iter    84/  157] train: loss: 0.0677120
[Epoch 109; Iter   114/  157] train: loss: 0.0608954
[Epoch 109; Iter   144/  157] train: loss: 0.0591784
[Epoch 109] ogbg-moltox21: 0.733447 val loss: 0.418087
[Epoch 109] ogbg-moltox21: 0.709923 test loss: 0.453940
[Epoch 110; Iter    17/  157] train: loss: 0.0366199
[Epoch 110; Iter    47/  157] train: loss: 0.0518635
[Epoch 110; Iter    77/  157] train: loss: 0.0979971
[Epoch 110; Iter   107/  157] train: loss: 0.0853810
[Epoch 110; Iter   137/  157] train: loss: 0.0553561
[Epoch 110] ogbg-moltox21: 0.726608 val loss: 0.424162
[Epoch 110] ogbg-moltox21: 0.704619 test loss: 0.458945
[Epoch 111; Iter    10/  157] train: loss: 0.0548138
[Epoch 111; Iter    40/  157] train: loss: 0.0483520
[Epoch 111; Iter    70/  157] train: loss: 0.0591774
[Epoch 111; Iter   100/  157] train: loss: 0.0828746
[Epoch 111; Iter   130/  157] train: loss: 0.1398948
[Epoch 111] ogbg-moltox21: 0.725050 val loss: 0.421530
[Epoch 111] ogbg-moltox21: 0.704722 test loss: 0.456005
[Epoch 112; Iter     3/  157] train: loss: 0.0471490
[Epoch 112; Iter    33/  157] train: loss: 0.0388123
[Epoch 112; Iter    63/  157] train: loss: 0.0710268
[Epoch 112; Iter    93/  157] train: loss: 0.0613601
[Epoch 112; Iter   123/  157] train: loss: 0.0584235
[Epoch 112; Iter   153/  157] train: loss: 0.0548350
[Epoch 112] ogbg-moltox21: 0.726135 val loss: 0.434797
[Epoch 112] ogbg-moltox21: 0.709353 test loss: 0.464786
[Epoch 113; Iter    26/  157] train: loss: 0.0441739
[Epoch 113; Iter    56/  157] train: loss: 0.0399920
[Epoch 113; Iter    86/  157] train: loss: 0.1135271
[Epoch 113; Iter   116/  157] train: loss: 0.0838105
[Epoch 113; Iter   146/  157] train: loss: 0.0574882
[Epoch 113] ogbg-moltox21: 0.722635 val loss: 0.433257
[Epoch 113] ogbg-moltox21: 0.704612 test loss: 0.471685
[Epoch 114; Iter    19/  157] train: loss: 0.0432320
[Epoch 114; Iter    49/  157] train: loss: 0.0349993
[Epoch 114; Iter    79/  157] train: loss: 0.0436653
[Epoch 114; Iter   109/  157] train: loss: 0.0399123
[Epoch 114; Iter   139/  157] train: loss: 0.0544443
[Epoch 114] ogbg-moltox21: 0.723177 val loss: 0.433527
[Epoch 114] ogbg-moltox21: 0.701102 test loss: 0.474103
[Epoch 115; Iter    12/  157] train: loss: 0.0519684
[Epoch 115; Iter    42/  157] train: loss: 0.0580756
[Epoch 115; Iter    72/  157] train: loss: 0.0387290
[Epoch 115; Iter   102/  157] train: loss: 0.0590718
[Epoch 115; Iter   132/  157] train: loss: 0.0357726
[Epoch 115] ogbg-moltox21: 0.721760 val loss: 0.435715
[Epoch 115] ogbg-moltox21: 0.700600 test loss: 0.472582
[Epoch 116; Iter     5/  157] train: loss: 0.0346223
[Epoch 116; Iter    35/  157] train: loss: 0.0530943
[Epoch 116; Iter    65/  157] train: loss: 0.0448067
[Epoch 116; Iter    95/  157] train: loss: 0.0517483
[Epoch 116; Iter   125/  157] train: loss: 0.0403603
[Epoch 116; Iter   155/  157] train: loss: 0.0601072
[Epoch 116] ogbg-moltox21: 0.728498 val loss: 0.450342
[Epoch 116] ogbg-moltox21: 0.704890 test loss: 0.495090
[Epoch 117; Iter    28/  157] train: loss: 0.0529418
[Epoch 117; Iter    58/  157] train: loss: 0.0666202
[Epoch 117; Iter    88/  157] train: loss: 0.0543731
[Epoch 117; Iter   118/  157] train: loss: 0.0817155
[Epoch 117; Iter   148/  157] train: loss: 0.1008006
[Epoch 117] ogbg-moltox21: 0.722746 val loss: 0.447045
[Epoch 117] ogbg-moltox21: 0.703241 test loss: 0.492883
[Epoch 118; Iter    21/  157] train: loss: 0.0263217
[Epoch 118; Iter    51/  157] train: loss: 0.0462664
[Epoch 118; Iter    81/  157] train: loss: 0.0533388
[Epoch 118; Iter   111/  157] train: loss: 0.0532460
[Epoch 118; Iter   141/  157] train: loss: 0.0517108
[Epoch 118] ogbg-moltox21: 0.722887 val loss: 0.451322
[Epoch 118] ogbg-moltox21: 0.703232 test loss: 0.498257
[Epoch 119; Iter    14/  157] train: loss: 0.0370481
[Epoch 119; Iter    44/  157] train: loss: 0.0304717
[Epoch 119; Iter    74/  157] train: loss: 0.0263216
[Epoch 119; Iter   104/  157] train: loss: 0.0587351
[Epoch 119; Iter   134/  157] train: loss: 0.0478062
[Epoch 119] ogbg-moltox21: 0.728494 val loss: 0.434734
[Epoch 119] ogbg-moltox21: 0.703995 test loss: 0.480133
[Epoch 120; Iter     7/  157] train: loss: 0.0514737
[Epoch 120; Iter    37/  157] train: loss: 0.0949268
[Epoch 120; Iter    67/  157] train: loss: 0.0431918
[Epoch 120; Iter    97/  157] train: loss: 0.0784622
[Epoch 120; Iter   127/  157] train: loss: 0.0777546
[Epoch 120; Iter   157/  157] train: loss: 0.0731522
[Epoch 120] ogbg-moltox21: 0.725335 val loss: 0.441919
[Epoch 120] ogbg-moltox21: 0.704866 test loss: 0.484529
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: -3.3975741863250732
std_pred: 2.5185749530792236
mean_targets: nan
std_targets: nan
prcauc: 0.312975952111389
rocauc: 0.7780348479188374
ogbg-moltox21: 0.7780348479188374
OGBNanLabelBCEWithLogitsLoss: 0.2977409613020015
Statistics on  test
mean_pred: -3.292708158493042
std_pred: 2.586562395095825
mean_targets: nan
std_targets: nan
prcauc: 0.2736576173313311
rocauc: 0.7475059409126886
ogbg-moltox21: 0.7475059409126886
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0285372
[Epoch 101] ogbg-moltox21: 0.736548 val loss: 0.618224
[Epoch 101] ogbg-moltox21: 0.726514 test loss: 0.566253
[Epoch 102; Iter    13/  157] train: loss: 0.0378508
[Epoch 102; Iter    43/  157] train: loss: 0.1061444
[Epoch 102; Iter    73/  157] train: loss: 0.0594653
[Epoch 102; Iter   103/  157] train: loss: 0.0540319
[Epoch 102; Iter   133/  157] train: loss: 0.0500056
[Epoch 102] ogbg-moltox21: 0.734452 val loss: 0.767323
[Epoch 102] ogbg-moltox21: 0.718356 test loss: 0.927975
[Epoch 103; Iter     6/  157] train: loss: 0.0934379
[Epoch 103; Iter    36/  157] train: loss: 0.0400032
[Epoch 103; Iter    66/  157] train: loss: 0.0826208
[Epoch 103; Iter    96/  157] train: loss: 0.0888299
[Epoch 103; Iter   126/  157] train: loss: 0.0284325
[Epoch 103; Iter   156/  157] train: loss: 0.0742705
[Epoch 103] ogbg-moltox21: 0.714131 val loss: 0.636112
[Epoch 103] ogbg-moltox21: 0.708620 test loss: 0.610386
[Epoch 104; Iter    29/  157] train: loss: 0.0420980
[Epoch 104; Iter    59/  157] train: loss: 0.0370199
[Epoch 104; Iter    89/  157] train: loss: 0.0412509
[Epoch 104; Iter   119/  157] train: loss: 0.0588666
[Epoch 104; Iter   149/  157] train: loss: 0.0280354
[Epoch 104] ogbg-moltox21: 0.709430 val loss: 0.594593
[Epoch 104] ogbg-moltox21: 0.708631 test loss: 0.558103
[Epoch 105; Iter    22/  157] train: loss: 0.0345495
[Epoch 105; Iter    52/  157] train: loss: 0.0438046
[Epoch 105; Iter    82/  157] train: loss: 0.0716053
[Epoch 105; Iter   112/  157] train: loss: 0.0375982
[Epoch 105; Iter   142/  157] train: loss: 0.0838301
[Epoch 105] ogbg-moltox21: 0.724739 val loss: 0.745576
[Epoch 105] ogbg-moltox21: 0.716460 test loss: 0.719130
[Epoch 106; Iter    15/  157] train: loss: 0.0595589
[Epoch 106; Iter    45/  157] train: loss: 0.0660844
[Epoch 106; Iter    75/  157] train: loss: 0.0382145
[Epoch 106; Iter   105/  157] train: loss: 0.0426748
[Epoch 106; Iter   135/  157] train: loss: 0.0437633
[Epoch 106] ogbg-moltox21: 0.727144 val loss: 0.715385
[Epoch 106] ogbg-moltox21: 0.723622 test loss: 0.784736
[Epoch 107; Iter     8/  157] train: loss: 0.0492369
[Epoch 107; Iter    38/  157] train: loss: 0.0301645
[Epoch 107; Iter    68/  157] train: loss: 0.0356614
[Epoch 107; Iter    98/  157] train: loss: 0.0403758
[Epoch 107; Iter   128/  157] train: loss: 0.0202030
[Epoch 107] ogbg-moltox21: 0.733742 val loss: 0.628545
[Epoch 107] ogbg-moltox21: 0.727094 test loss: 0.540746
[Epoch 108; Iter     1/  157] train: loss: 0.0275158
[Epoch 108; Iter    31/  157] train: loss: 0.0427086
[Epoch 108; Iter    61/  157] train: loss: 0.0435255
[Epoch 108; Iter    91/  157] train: loss: 0.0421959
[Epoch 108; Iter   121/  157] train: loss: 0.1402580
[Epoch 108; Iter   151/  157] train: loss: 0.0540883
[Epoch 108] ogbg-moltox21: 0.717239 val loss: 0.589601
[Epoch 108] ogbg-moltox21: 0.728330 test loss: 0.550491
[Epoch 109; Iter    24/  157] train: loss: 0.0393083
[Epoch 109; Iter    54/  157] train: loss: 0.0215497
[Epoch 109; Iter    84/  157] train: loss: 0.0490456
[Epoch 109; Iter   114/  157] train: loss: 0.0327077
[Epoch 109; Iter   144/  157] train: loss: 0.0387833
[Epoch 109] ogbg-moltox21: 0.726554 val loss: 0.679939
[Epoch 109] ogbg-moltox21: 0.719061 test loss: 0.595446
[Epoch 110; Iter    17/  157] train: loss: 0.0799083
[Epoch 110; Iter    47/  157] train: loss: 0.0750760
[Epoch 110; Iter    77/  157] train: loss: 0.0196861
[Epoch 110; Iter   107/  157] train: loss: 0.0424306
[Epoch 110; Iter   137/  157] train: loss: 0.0313790
[Epoch 110] ogbg-moltox21: 0.714250 val loss: 0.776202
[Epoch 110] ogbg-moltox21: 0.712848 test loss: 0.812618
[Epoch 111; Iter    10/  157] train: loss: 0.0272226
[Epoch 111; Iter    40/  157] train: loss: 0.0246818
[Epoch 111; Iter    70/  157] train: loss: 0.0311356
[Epoch 111; Iter   100/  157] train: loss: 0.0451667
[Epoch 111; Iter   130/  157] train: loss: 0.0414487
[Epoch 111] ogbg-moltox21: 0.713912 val loss: 0.774211
[Epoch 111] ogbg-moltox21: 0.716484 test loss: 0.785176
[Epoch 112; Iter     3/  157] train: loss: 0.0127680
[Epoch 112; Iter    33/  157] train: loss: 0.0488994
[Epoch 112; Iter    63/  157] train: loss: 0.0444350
[Epoch 112; Iter    93/  157] train: loss: 0.0399795
[Epoch 112; Iter   123/  157] train: loss: 0.0474363
[Epoch 112; Iter   153/  157] train: loss: 0.0364959
[Epoch 112] ogbg-moltox21: 0.723553 val loss: 0.733628
[Epoch 112] ogbg-moltox21: 0.723095 test loss: 0.774901
[Epoch 113; Iter    26/  157] train: loss: 0.0399572
[Epoch 113; Iter    56/  157] train: loss: 0.0427168
[Epoch 113; Iter    86/  157] train: loss: 0.0320308
[Epoch 113; Iter   116/  157] train: loss: 0.0609507
[Epoch 113; Iter   146/  157] train: loss: 0.0375568
[Epoch 113] ogbg-moltox21: 0.721619 val loss: 0.689731
[Epoch 113] ogbg-moltox21: 0.720289 test loss: 0.647612
[Epoch 114; Iter    19/  157] train: loss: 0.0414116
[Epoch 114; Iter    49/  157] train: loss: 0.0235786
[Epoch 114; Iter    79/  157] train: loss: 0.0495451
[Epoch 114; Iter   109/  157] train: loss: 0.0516689
[Epoch 114; Iter   139/  157] train: loss: 0.0514585
[Epoch 114] ogbg-moltox21: 0.719468 val loss: 0.589798
[Epoch 114] ogbg-moltox21: 0.722465 test loss: 0.632720
[Epoch 115; Iter    12/  157] train: loss: 0.0327535
[Epoch 115; Iter    42/  157] train: loss: 0.0265474
[Epoch 115; Iter    72/  157] train: loss: 0.0367184
[Epoch 115; Iter   102/  157] train: loss: 0.0525534
[Epoch 115; Iter   132/  157] train: loss: 0.0313074
[Epoch 115] ogbg-moltox21: 0.725043 val loss: 0.590168
[Epoch 115] ogbg-moltox21: 0.721718 test loss: 0.602856
[Epoch 116; Iter     5/  157] train: loss: 0.0360941
[Epoch 116; Iter    35/  157] train: loss: 0.0282275
[Epoch 116; Iter    65/  157] train: loss: 0.0427770
[Epoch 116; Iter    95/  157] train: loss: 0.0953062
[Epoch 116; Iter   125/  157] train: loss: 0.0353742
[Epoch 116; Iter   155/  157] train: loss: 0.0331247
[Epoch 116] ogbg-moltox21: 0.727677 val loss: 0.558864
[Epoch 116] ogbg-moltox21: 0.722585 test loss: 0.578365
[Epoch 117; Iter    28/  157] train: loss: 0.0319702
[Epoch 117; Iter    58/  157] train: loss: 0.0271701
[Epoch 117; Iter    88/  157] train: loss: 0.0449641
[Epoch 117; Iter   118/  157] train: loss: 0.0253652
[Epoch 117; Iter   148/  157] train: loss: 0.0512711
[Epoch 117] ogbg-moltox21: 0.725879 val loss: 0.550802
[Epoch 117] ogbg-moltox21: 0.727176 test loss: 0.541520
[Epoch 118; Iter    21/  157] train: loss: 0.0440987
[Epoch 118; Iter    51/  157] train: loss: 0.0340975
[Epoch 118; Iter    81/  157] train: loss: 0.0707538
[Epoch 118; Iter   111/  157] train: loss: 0.0473683
[Epoch 118; Iter   141/  157] train: loss: 0.0432040
[Epoch 118] ogbg-moltox21: 0.718684 val loss: 0.592031
[Epoch 118] ogbg-moltox21: 0.722923 test loss: 0.584623
[Epoch 119; Iter    14/  157] train: loss: 0.0202311
[Epoch 119; Iter    44/  157] train: loss: 0.0487188
[Epoch 119; Iter    74/  157] train: loss: 0.0160644
[Epoch 119; Iter   104/  157] train: loss: 0.0426616
[Epoch 119; Iter   134/  157] train: loss: 0.0875316
[Epoch 119] ogbg-moltox21: 0.723426 val loss: 0.666025
[Epoch 119] ogbg-moltox21: 0.722097 test loss: 0.646465
[Epoch 120; Iter     7/  157] train: loss: 0.0406714
[Epoch 120; Iter    37/  157] train: loss: 0.0341065
[Epoch 120; Iter    67/  157] train: loss: 0.0448487
[Epoch 120; Iter    97/  157] train: loss: 0.0338623
[Epoch 120; Iter   127/  157] train: loss: 0.0715491
[Epoch 120; Iter   157/  157] train: loss: 0.0242885
[Epoch 120] ogbg-moltox21: 0.716210 val loss: 0.691348
[Epoch 120] ogbg-moltox21: 0.722056 test loss: 0.650112
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 30.
Statistics on  val_best_checkpoint
mean_pred: -3.281541109085083
std_pred: 2.457336902618408
mean_targets: nan
std_targets: nan
prcauc: 0.3105113535045478
rocauc: 0.7827601194464493
ogbg-moltox21: 0.7827601194464493
OGBNanLabelBCEWithLogitsLoss: 0.2975206642218356
Statistics on  test
mean_pred: -3.192478895187378
std_pred: 2.6187171936035156
mean_targets: nan
std_targets: nan
prcauc: 0.2737392765925904
rocauc: 0.7538907080630768
ogbg-moltox21: 0.7538907080630768
OGBNanLabelBCEWithLogitsLoss: 0.33533791094174925
Statistics on  train
mean_pred: -4.345818519592285
std_pred: 2.3576769828796387
mean_targets: nan
std_targets: nan
prcauc: 0.6195854684302596
rocauc: 0.920092983566748
ogbg-moltox21: 0.920092983566748
OGBNanLabelBCEWithLogitsLoss: 0.12835897386643538
OGBNanLabelBCEWithLogitsLoss: 0.32901555166210766
Statistics on  train
mean_pred: -4.226006031036377
std_pred: 2.255758285522461
mean_targets: nan
std_targets: nan
prcauc: 0.5993067312878163
rocauc: 0.9179290179994034
ogbg-moltox21: 0.9179290179994034
OGBNanLabelBCEWithLogitsLoss: 0.1305436386614089
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 99; Iter   128/  209] train: loss: 0.0357223
[Epoch 99; Iter   158/  209] train: loss: 0.0530077
[Epoch 99; Iter   188/  209] train: loss: 0.0555882
[Epoch 99] ogbg-moltox21: 0.759754 val loss: 0.365911
[Epoch 99] ogbg-moltox21: 0.733158 test loss: 0.405832
[Epoch 100; Iter     9/  209] train: loss: 0.0348370
[Epoch 100; Iter    39/  209] train: loss: 0.0653100
[Epoch 100; Iter    69/  209] train: loss: 0.0762680
[Epoch 100; Iter    99/  209] train: loss: 0.0382927
[Epoch 100; Iter   129/  209] train: loss: 0.0450824
[Epoch 100; Iter   159/  209] train: loss: 0.0395282
[Epoch 100; Iter   189/  209] train: loss: 0.0528373
[Epoch 100] ogbg-moltox21: 0.764712 val loss: 0.366492
[Epoch 100] ogbg-moltox21: 0.735252 test loss: 0.410084
[Epoch 101; Iter    10/  209] train: loss: 0.0721320
[Epoch 101; Iter    40/  209] train: loss: 0.0394876
[Epoch 101; Iter    70/  209] train: loss: 0.0441982
[Epoch 101; Iter   100/  209] train: loss: 0.0416623
[Epoch 101; Iter   130/  209] train: loss: 0.0458070
[Epoch 101; Iter   160/  209] train: loss: 0.0544141
[Epoch 101; Iter   190/  209] train: loss: 0.0667176
[Epoch 101] ogbg-moltox21: 0.765545 val loss: 0.367378
[Epoch 101] ogbg-moltox21: 0.737910 test loss: 0.407731
[Epoch 102; Iter    11/  209] train: loss: 0.0232990
[Epoch 102; Iter    41/  209] train: loss: 0.0781660
[Epoch 102; Iter    71/  209] train: loss: 0.0581962
[Epoch 102; Iter   101/  209] train: loss: 0.0707053
[Epoch 102; Iter   131/  209] train: loss: 0.0503544
[Epoch 102; Iter   161/  209] train: loss: 0.0660271
[Epoch 102; Iter   191/  209] train: loss: 0.0565958
[Epoch 102] ogbg-moltox21: 0.764279 val loss: 0.368216
[Epoch 102] ogbg-moltox21: 0.737586 test loss: 0.407658
[Epoch 103; Iter    12/  209] train: loss: 0.0499284
[Epoch 103; Iter    42/  209] train: loss: 0.0505579
[Epoch 103; Iter    72/  209] train: loss: 0.0538126
[Epoch 103; Iter   102/  209] train: loss: 0.0474095
[Epoch 103; Iter   132/  209] train: loss: 0.0529953
[Epoch 103; Iter   162/  209] train: loss: 0.0458966
[Epoch 103; Iter   192/  209] train: loss: 0.0770103
[Epoch 103] ogbg-moltox21: 0.761676 val loss: 0.368081
[Epoch 103] ogbg-moltox21: 0.733932 test loss: 0.414952
[Epoch 104; Iter    13/  209] train: loss: 0.0743702
[Epoch 104; Iter    43/  209] train: loss: 0.0456868
[Epoch 104; Iter    73/  209] train: loss: 0.0505409
[Epoch 104; Iter   103/  209] train: loss: 0.0503988
[Epoch 104; Iter   133/  209] train: loss: 0.0533989
[Epoch 104; Iter   163/  209] train: loss: 0.0845332
[Epoch 104; Iter   193/  209] train: loss: 0.0653475
[Epoch 104] ogbg-moltox21: 0.764118 val loss: 0.373357
[Epoch 104] ogbg-moltox21: 0.734091 test loss: 0.413528
[Epoch 105; Iter    14/  209] train: loss: 0.0367552
[Epoch 105; Iter    44/  209] train: loss: 0.0420498
[Epoch 105; Iter    74/  209] train: loss: 0.0559877
[Epoch 105; Iter   104/  209] train: loss: 0.0529018
[Epoch 105; Iter   134/  209] train: loss: 0.0235855
[Epoch 105; Iter   164/  209] train: loss: 0.0811111
[Epoch 105; Iter   194/  209] train: loss: 0.0434605
[Epoch 105] ogbg-moltox21: 0.761834 val loss: 0.371899
[Epoch 105] ogbg-moltox21: 0.734462 test loss: 0.421683
[Epoch 106; Iter    15/  209] train: loss: 0.0271738
[Epoch 106; Iter    45/  209] train: loss: 0.0412620
[Epoch 106; Iter    75/  209] train: loss: 0.0382544
[Epoch 106; Iter   105/  209] train: loss: 0.0526250
[Epoch 106; Iter   135/  209] train: loss: 0.0467312
[Epoch 106; Iter   165/  209] train: loss: 0.0373787
[Epoch 106; Iter   195/  209] train: loss: 0.0386221
[Epoch 106] ogbg-moltox21: 0.764679 val loss: 0.377075
[Epoch 106] ogbg-moltox21: 0.737593 test loss: 0.423785
[Epoch 107; Iter    16/  209] train: loss: 0.0569139
[Epoch 107; Iter    46/  209] train: loss: 0.0927784
[Epoch 107; Iter    76/  209] train: loss: 0.0617257
[Epoch 107; Iter   106/  209] train: loss: 0.0614799
[Epoch 107; Iter   136/  209] train: loss: 0.0618556
[Epoch 107; Iter   166/  209] train: loss: 0.0458307
[Epoch 107; Iter   196/  209] train: loss: 0.0621799
[Epoch 107] ogbg-moltox21: 0.763804 val loss: 0.379234
[Epoch 107] ogbg-moltox21: 0.735183 test loss: 0.426696
[Epoch 108; Iter    17/  209] train: loss: 0.0352169
[Epoch 108; Iter    47/  209] train: loss: 0.0428649
[Epoch 108; Iter    77/  209] train: loss: 0.0367027
[Epoch 108; Iter   107/  209] train: loss: 0.0615185
[Epoch 108; Iter   137/  209] train: loss: 0.0749551
[Epoch 108; Iter   167/  209] train: loss: 0.0431823
[Epoch 108; Iter   197/  209] train: loss: 0.0685259
[Epoch 108] ogbg-moltox21: 0.761335 val loss: 0.375873
[Epoch 108] ogbg-moltox21: 0.739290 test loss: 0.424339
[Epoch 109; Iter    18/  209] train: loss: 0.0297174
[Epoch 109; Iter    48/  209] train: loss: 0.0365344
[Epoch 109; Iter    78/  209] train: loss: 0.0411330
[Epoch 109; Iter   108/  209] train: loss: 0.0677684
[Epoch 109; Iter   138/  209] train: loss: 0.0555284
[Epoch 109; Iter   168/  209] train: loss: 0.0845424
[Epoch 109; Iter   198/  209] train: loss: 0.0391602
[Epoch 109] ogbg-moltox21: 0.761318 val loss: 0.376638
[Epoch 109] ogbg-moltox21: 0.735324 test loss: 0.423456
[Epoch 110; Iter    19/  209] train: loss: 0.0503217
[Epoch 110; Iter    49/  209] train: loss: 0.0549838
[Epoch 110; Iter    79/  209] train: loss: 0.0731716
[Epoch 110; Iter   109/  209] train: loss: 0.0417438
[Epoch 110; Iter   139/  209] train: loss: 0.0605260
[Epoch 110; Iter   169/  209] train: loss: 0.0604600
[Epoch 110; Iter   199/  209] train: loss: 0.0502813
[Epoch 110] ogbg-moltox21: 0.759955 val loss: 0.395117
[Epoch 110] ogbg-moltox21: 0.737792 test loss: 0.447630
[Epoch 111; Iter    20/  209] train: loss: 0.0544812
[Epoch 111; Iter    50/  209] train: loss: 0.0610055
[Epoch 111; Iter    80/  209] train: loss: 0.0403724
[Epoch 111; Iter   110/  209] train: loss: 0.0238261
[Epoch 111; Iter   140/  209] train: loss: 0.0821762
[Epoch 111; Iter   170/  209] train: loss: 0.0566673
[Epoch 111; Iter   200/  209] train: loss: 0.0519172
[Epoch 111] ogbg-moltox21: 0.760930 val loss: 0.386269
[Epoch 111] ogbg-moltox21: 0.740216 test loss: 0.425157
[Epoch 112; Iter    21/  209] train: loss: 0.0489333
[Epoch 112; Iter    51/  209] train: loss: 0.0842096
[Epoch 112; Iter    81/  209] train: loss: 0.0470129
[Epoch 112; Iter   111/  209] train: loss: 0.0461475
[Epoch 112; Iter   141/  209] train: loss: 0.0489509
[Epoch 112; Iter   171/  209] train: loss: 0.0572463
[Epoch 112; Iter   201/  209] train: loss: 0.0473540
[Epoch 112] ogbg-moltox21: 0.764401 val loss: 0.392562
[Epoch 112] ogbg-moltox21: 0.735063 test loss: 0.441351
[Epoch 113; Iter    22/  209] train: loss: 0.0303887
[Epoch 113; Iter    52/  209] train: loss: 0.0704770
[Epoch 113; Iter    82/  209] train: loss: 0.0588945
[Epoch 113; Iter   112/  209] train: loss: 0.0564188
[Epoch 113; Iter   142/  209] train: loss: 0.0633623
[Epoch 113; Iter   172/  209] train: loss: 0.0806832
[Epoch 113; Iter   202/  209] train: loss: 0.0501494
[Epoch 113] ogbg-moltox21: 0.755564 val loss: 0.394325
[Epoch 113] ogbg-moltox21: 0.735181 test loss: 0.432569
[Epoch 114; Iter    23/  209] train: loss: 0.0426242
[Epoch 114; Iter    53/  209] train: loss: 0.0299127
[Epoch 114; Iter    83/  209] train: loss: 0.0269559
[Epoch 114; Iter   113/  209] train: loss: 0.0612903
[Epoch 114; Iter   143/  209] train: loss: 0.0430266
[Epoch 114; Iter   173/  209] train: loss: 0.0475422
[Epoch 114; Iter   203/  209] train: loss: 0.0519904
[Epoch 114] ogbg-moltox21: 0.758369 val loss: 0.393303
[Epoch 114] ogbg-moltox21: 0.732585 test loss: 0.438141
[Epoch 115; Iter    24/  209] train: loss: 0.0702437
[Epoch 115; Iter    54/  209] train: loss: 0.0643229
[Epoch 115; Iter    84/  209] train: loss: 0.0463450
[Epoch 115; Iter   114/  209] train: loss: 0.0361290
[Epoch 115; Iter   144/  209] train: loss: 0.0432941
[Epoch 115; Iter   174/  209] train: loss: 0.0720131
[Epoch 115; Iter   204/  209] train: loss: 0.0505169
[Epoch 115] ogbg-moltox21: 0.754568 val loss: 0.400115
[Epoch 115] ogbg-moltox21: 0.731947 test loss: 0.445380
[Epoch 116; Iter    25/  209] train: loss: 0.1028220
[Epoch 116; Iter    55/  209] train: loss: 0.0438389
[Epoch 116; Iter    85/  209] train: loss: 0.0227952
[Epoch 116; Iter   115/  209] train: loss: 0.0440212
[Epoch 109] ogbg-moltox21: 0.715351 test loss: 0.491174
[Epoch 110; Iter     3/  183] train: loss: 0.0340421
[Epoch 110; Iter    33/  183] train: loss: 0.1020088
[Epoch 110; Iter    63/  183] train: loss: 0.0318724
[Epoch 110; Iter    93/  183] train: loss: 0.0561713
[Epoch 110; Iter   123/  183] train: loss: 0.0377800
[Epoch 110; Iter   153/  183] train: loss: 0.0670928
[Epoch 110; Iter   183/  183] train: loss: 0.0485807
[Epoch 110] ogbg-moltox21: 0.733173 val loss: 0.426543
[Epoch 110] ogbg-moltox21: 0.708263 test loss: 0.471277
[Epoch 111; Iter    30/  183] train: loss: 0.0612602
[Epoch 111; Iter    60/  183] train: loss: 0.0398729
[Epoch 111; Iter    90/  183] train: loss: 0.0383203
[Epoch 111; Iter   120/  183] train: loss: 0.0560029
[Epoch 111; Iter   150/  183] train: loss: 0.0312698
[Epoch 111; Iter   180/  183] train: loss: 0.0757626
[Epoch 111] ogbg-moltox21: 0.730159 val loss: 0.433648
[Epoch 111] ogbg-moltox21: 0.704318 test loss: 0.477551
[Epoch 112; Iter    27/  183] train: loss: 0.0479055
[Epoch 112; Iter    57/  183] train: loss: 0.0386180
[Epoch 112; Iter    87/  183] train: loss: 0.0550622
[Epoch 112; Iter   117/  183] train: loss: 0.0448060
[Epoch 112; Iter   147/  183] train: loss: 0.0321682
[Epoch 112; Iter   177/  183] train: loss: 0.0251158
[Epoch 112] ogbg-moltox21: 0.732779 val loss: 0.440762
[Epoch 112] ogbg-moltox21: 0.703117 test loss: 0.489388
[Epoch 113; Iter    24/  183] train: loss: 0.0793542
[Epoch 113; Iter    54/  183] train: loss: 0.0366823
[Epoch 113; Iter    84/  183] train: loss: 0.0509917
[Epoch 113; Iter   114/  183] train: loss: 0.0468982
[Epoch 113; Iter   144/  183] train: loss: 0.0660375
[Epoch 113; Iter   174/  183] train: loss: 0.0342675
[Epoch 113] ogbg-moltox21: 0.733231 val loss: 0.424814
[Epoch 113] ogbg-moltox21: 0.705193 test loss: 0.468377
[Epoch 114; Iter    21/  183] train: loss: 0.0372666
[Epoch 114; Iter    51/  183] train: loss: 0.0481589
[Epoch 114; Iter    81/  183] train: loss: 0.0443929
[Epoch 114; Iter   111/  183] train: loss: 0.0349522
[Epoch 114; Iter   141/  183] train: loss: 0.0648157
[Epoch 114; Iter   171/  183] train: loss: 0.0588431
[Epoch 114] ogbg-moltox21: 0.733012 val loss: 0.444494
[Epoch 114] ogbg-moltox21: 0.704447 test loss: 0.490169
[Epoch 115; Iter    18/  183] train: loss: 0.0399850
[Epoch 115; Iter    48/  183] train: loss: 0.0443322
[Epoch 115; Iter    78/  183] train: loss: 0.0340230
[Epoch 115; Iter   108/  183] train: loss: 0.0557285
[Epoch 115; Iter   138/  183] train: loss: 0.0224831
[Epoch 115; Iter   168/  183] train: loss: 0.0445772
[Epoch 115] ogbg-moltox21: 0.729900 val loss: 0.444302
[Epoch 115] ogbg-moltox21: 0.700253 test loss: 0.494052
[Epoch 116; Iter    15/  183] train: loss: 0.0263321
[Epoch 116; Iter    45/  183] train: loss: 0.0404071
[Epoch 116; Iter    75/  183] train: loss: 0.0606946
[Epoch 116; Iter   105/  183] train: loss: 0.0539475
[Epoch 116; Iter   135/  183] train: loss: 0.0319238
[Epoch 116; Iter   165/  183] train: loss: 0.0291323
[Epoch 116] ogbg-moltox21: 0.733267 val loss: 0.447258
[Epoch 116] ogbg-moltox21: 0.704283 test loss: 0.496454
[Epoch 117; Iter    12/  183] train: loss: 0.0290717
[Epoch 117; Iter    42/  183] train: loss: 0.0473899
[Epoch 117; Iter    72/  183] train: loss: 0.0474787
[Epoch 117; Iter   102/  183] train: loss: 0.0374031
[Epoch 117; Iter   132/  183] train: loss: 0.0761718
[Epoch 117; Iter   162/  183] train: loss: 0.0602754
[Epoch 117] ogbg-moltox21: 0.730348 val loss: 0.445650
[Epoch 117] ogbg-moltox21: 0.703789 test loss: 0.487750
[Epoch 118; Iter     9/  183] train: loss: 0.0268786
[Epoch 118; Iter    39/  183] train: loss: 0.0330411
[Epoch 118; Iter    69/  183] train: loss: 0.0327397
[Epoch 118; Iter    99/  183] train: loss: 0.0407686
[Epoch 118; Iter   129/  183] train: loss: 0.0367026
[Epoch 118; Iter   159/  183] train: loss: 0.0608903
[Epoch 118] ogbg-moltox21: 0.734066 val loss: 0.440100
[Epoch 118] ogbg-moltox21: 0.711491 test loss: 0.481517
[Epoch 119; Iter     6/  183] train: loss: 0.0377267
[Epoch 119; Iter    36/  183] train: loss: 0.0222999
[Epoch 119; Iter    66/  183] train: loss: 0.0485503
[Epoch 119; Iter    96/  183] train: loss: 0.0472843
[Epoch 119; Iter   126/  183] train: loss: 0.0540388
[Epoch 119; Iter   156/  183] train: loss: 0.0404564
[Epoch 119] ogbg-moltox21: 0.731457 val loss: 0.447626
[Epoch 119] ogbg-moltox21: 0.704578 test loss: 0.494396
[Epoch 120; Iter     3/  183] train: loss: 0.0469493
[Epoch 120; Iter    33/  183] train: loss: 0.0266631
[Epoch 120; Iter    63/  183] train: loss: 0.0465697
[Epoch 120; Iter    93/  183] train: loss: 0.0363424
[Epoch 120; Iter   123/  183] train: loss: 0.0415908
[Epoch 120; Iter   153/  183] train: loss: 0.0239129
[Epoch 120; Iter   183/  183] train: loss: 0.0351384
[Epoch 120] ogbg-moltox21: 0.730892 val loss: 0.450211
[Epoch 120] ogbg-moltox21: 0.703867 test loss: 0.498597
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 38.
Statistics on  val_best_checkpoint
mean_pred: -3.552175283432007
std_pred: 2.339171886444092
mean_targets: nan
std_targets: nan
prcauc: 0.36650660291864673
rocauc: 0.7887375723392713
ogbg-moltox21: 0.7887375723392713
OGBNanLabelBCEWithLogitsLoss: 0.25831495188176634
Statistics on  test
mean_pred: -3.570976734161377
std_pred: 2.4409279823303223
mean_targets: nan
std_targets: nan
prcauc: 0.352374623568742
rocauc: 0.7545656940258411
ogbg-moltox21: 0.7545656940258411
OGBNanLabelBCEWithLogitsLoss: 0.2733337853103876
Statistics on  train
mean_pred: -4.237390041351318
std_pred: 2.8417584896087646
mean_targets: nan
std_targets: nan
prcauc: 0.6790917535353106
rocauc: 0.9322444472975352
ogbg-moltox21: 0.9322444472975352
OGBNanLabelBCEWithLogitsLoss: 0.14035257428395945
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 99; Iter   128/  209] train: loss: 0.0422252
[Epoch 99; Iter   158/  209] train: loss: 0.0598856
[Epoch 99; Iter   188/  209] train: loss: 0.0763283
[Epoch 99] ogbg-moltox21: 0.769635 val loss: 0.393763
[Epoch 99] ogbg-moltox21: 0.750283 test loss: 0.418195
[Epoch 100; Iter     9/  209] train: loss: 0.0430598
[Epoch 100; Iter    39/  209] train: loss: 0.0532707
[Epoch 100; Iter    69/  209] train: loss: 0.0904819
[Epoch 100; Iter    99/  209] train: loss: 0.0473440
[Epoch 100; Iter   129/  209] train: loss: 0.0538159
[Epoch 100; Iter   159/  209] train: loss: 0.0849797
[Epoch 100; Iter   189/  209] train: loss: 0.0492275
[Epoch 100] ogbg-moltox21: 0.771935 val loss: 0.389311
[Epoch 100] ogbg-moltox21: 0.756846 test loss: 0.410103
[Epoch 101; Iter    10/  209] train: loss: 0.0449635
[Epoch 101; Iter    40/  209] train: loss: 0.0739472
[Epoch 101; Iter    70/  209] train: loss: 0.0491348
[Epoch 101; Iter   100/  209] train: loss: 0.0785540
[Epoch 101; Iter   130/  209] train: loss: 0.0448924
[Epoch 101; Iter   160/  209] train: loss: 0.0447485
[Epoch 101; Iter   190/  209] train: loss: 0.0430514
[Epoch 101] ogbg-moltox21: 0.768222 val loss: 0.396218
[Epoch 101] ogbg-moltox21: 0.749327 test loss: 0.420695
[Epoch 102; Iter    11/  209] train: loss: 0.0387093
[Epoch 102; Iter    41/  209] train: loss: 0.0610917
[Epoch 102; Iter    71/  209] train: loss: 0.0272073
[Epoch 102; Iter   101/  209] train: loss: 0.0427354
[Epoch 102; Iter   131/  209] train: loss: 0.0923425
[Epoch 102; Iter   161/  209] train: loss: 0.0863785
[Epoch 102; Iter   191/  209] train: loss: 0.0335162
[Epoch 102] ogbg-moltox21: 0.764315 val loss: 0.397190
[Epoch 102] ogbg-moltox21: 0.751960 test loss: 0.412753
[Epoch 103; Iter    12/  209] train: loss: 0.0491574
[Epoch 103; Iter    42/  209] train: loss: 0.0614981
[Epoch 103; Iter    72/  209] train: loss: 0.0496423
[Epoch 103; Iter   102/  209] train: loss: 0.0480793
[Epoch 103; Iter   132/  209] train: loss: 0.0677397
[Epoch 103; Iter   162/  209] train: loss: 0.0483793
[Epoch 103; Iter   192/  209] train: loss: 0.0575369
[Epoch 103] ogbg-moltox21: 0.761736 val loss: 1.018693
[Epoch 103] ogbg-moltox21: 0.751319 test loss: 0.408870
[Epoch 104; Iter    13/  209] train: loss: 0.0450139
[Epoch 104; Iter    43/  209] train: loss: 0.0625392
[Epoch 104; Iter    73/  209] train: loss: 0.0472152
[Epoch 104; Iter   103/  209] train: loss: 0.0447416
[Epoch 104; Iter   133/  209] train: loss: 0.0758424
[Epoch 104; Iter   163/  209] train: loss: 0.0467926
[Epoch 104; Iter   193/  209] train: loss: 0.0770178
[Epoch 104] ogbg-moltox21: 0.773518 val loss: 0.477855
[Epoch 104] ogbg-moltox21: 0.750437 test loss: 0.422820
[Epoch 105; Iter    14/  209] train: loss: 0.0383089
[Epoch 105; Iter    44/  209] train: loss: 0.0535987
[Epoch 105; Iter    74/  209] train: loss: 0.0480465
[Epoch 105; Iter   104/  209] train: loss: 0.0342565
[Epoch 105; Iter   134/  209] train: loss: 0.0494615
[Epoch 105; Iter   164/  209] train: loss: 0.0511273
[Epoch 105; Iter   194/  209] train: loss: 0.0327778
[Epoch 105] ogbg-moltox21: 0.765108 val loss: 0.407527
[Epoch 105] ogbg-moltox21: 0.747211 test loss: 0.421745
[Epoch 106; Iter    15/  209] train: loss: 0.0400211
[Epoch 106; Iter    45/  209] train: loss: 0.0460862
[Epoch 106; Iter    75/  209] train: loss: 0.0590138
[Epoch 106; Iter   105/  209] train: loss: 0.1056321
[Epoch 106; Iter   135/  209] train: loss: 0.0421450
[Epoch 106; Iter   165/  209] train: loss: 0.0574752
[Epoch 106; Iter   195/  209] train: loss: 0.0457006
[Epoch 106] ogbg-moltox21: 0.764220 val loss: 0.414066
[Epoch 106] ogbg-moltox21: 0.753435 test loss: 0.423346
[Epoch 107; Iter    16/  209] train: loss: 0.0530809
[Epoch 107; Iter    46/  209] train: loss: 0.0703427
[Epoch 107; Iter    76/  209] train: loss: 0.0294883
[Epoch 107; Iter   106/  209] train: loss: 0.0567525
[Epoch 107; Iter   136/  209] train: loss: 0.0650866
[Epoch 107; Iter   166/  209] train: loss: 0.0400370
[Epoch 107; Iter   196/  209] train: loss: 0.0376733
[Epoch 107] ogbg-moltox21: 0.765932 val loss: 0.458659
[Epoch 107] ogbg-moltox21: 0.751537 test loss: 0.425243
[Epoch 108; Iter    17/  209] train: loss: 0.0624394
[Epoch 108; Iter    47/  209] train: loss: 0.0391591
[Epoch 108; Iter    77/  209] train: loss: 0.0594673
[Epoch 108; Iter   107/  209] train: loss: 0.0583640
[Epoch 108; Iter   137/  209] train: loss: 0.0344473
[Epoch 108; Iter   167/  209] train: loss: 0.0599930
[Epoch 108; Iter   197/  209] train: loss: 0.0455084
[Epoch 108] ogbg-moltox21: 0.770784 val loss: 0.415613
[Epoch 108] ogbg-moltox21: 0.749487 test loss: 0.435710
[Epoch 109; Iter    18/  209] train: loss: 0.0780917
[Epoch 109; Iter    48/  209] train: loss: 0.0382983
[Epoch 109; Iter    78/  209] train: loss: 0.0309349
[Epoch 109; Iter   108/  209] train: loss: 0.0631758
[Epoch 109; Iter   138/  209] train: loss: 0.0586352
[Epoch 109; Iter   168/  209] train: loss: 0.0539554
[Epoch 109; Iter   198/  209] train: loss: 0.0414301
[Epoch 109] ogbg-moltox21: 0.763960 val loss: 0.412501
[Epoch 109] ogbg-moltox21: 0.750291 test loss: 0.430714
[Epoch 110; Iter    19/  209] train: loss: 0.0517359
[Epoch 110; Iter    49/  209] train: loss: 0.0446582
[Epoch 110; Iter    79/  209] train: loss: 0.0613782
[Epoch 110; Iter   109/  209] train: loss: 0.0485042
[Epoch 110; Iter   139/  209] train: loss: 0.0701417
[Epoch 110; Iter   169/  209] train: loss: 0.0290669
[Epoch 110; Iter   199/  209] train: loss: 0.0628970
[Epoch 110] ogbg-moltox21: 0.769075 val loss: 0.424003
[Epoch 110] ogbg-moltox21: 0.750605 test loss: 0.434412
[Epoch 111; Iter    20/  209] train: loss: 0.0609167
[Epoch 111; Iter    50/  209] train: loss: 0.0357492
[Epoch 111; Iter    80/  209] train: loss: 0.0316232
[Epoch 111; Iter   110/  209] train: loss: 0.0481338
[Epoch 111; Iter   140/  209] train: loss: 0.0293793
[Epoch 111; Iter   170/  209] train: loss: 0.0904852
[Epoch 111; Iter   200/  209] train: loss: 0.0257265
[Epoch 111] ogbg-moltox21: 0.768781 val loss: 0.898006
[Epoch 111] ogbg-moltox21: 0.750397 test loss: 0.438372
[Epoch 112; Iter    21/  209] train: loss: 0.0297678
[Epoch 112; Iter    51/  209] train: loss: 0.0464202
[Epoch 112; Iter    81/  209] train: loss: 0.0354692
[Epoch 112; Iter   111/  209] train: loss: 0.0566671
[Epoch 112; Iter   141/  209] train: loss: 0.0253659
[Epoch 112; Iter   171/  209] train: loss: 0.0406269
[Epoch 112; Iter   201/  209] train: loss: 0.0393580
[Epoch 112] ogbg-moltox21: 0.764384 val loss: 0.748466
[Epoch 112] ogbg-moltox21: 0.747785 test loss: 0.443145
[Epoch 113; Iter    22/  209] train: loss: 0.0957210
[Epoch 113; Iter    52/  209] train: loss: 0.0296597
[Epoch 113; Iter    82/  209] train: loss: 0.0936147
[Epoch 113; Iter   112/  209] train: loss: 0.0735023
[Epoch 113; Iter   142/  209] train: loss: 0.0505304
[Epoch 113; Iter   172/  209] train: loss: 0.0545228
[Epoch 113; Iter   202/  209] train: loss: 0.0382706
[Epoch 113] ogbg-moltox21: 0.767281 val loss: 0.423140
[Epoch 113] ogbg-moltox21: 0.747407 test loss: 0.444307
[Epoch 114; Iter    23/  209] train: loss: 0.0888485
[Epoch 114; Iter    53/  209] train: loss: 0.0285785
[Epoch 114; Iter    83/  209] train: loss: 0.0457475
[Epoch 114; Iter   113/  209] train: loss: 0.0282863
[Epoch 114; Iter   143/  209] train: loss: 0.0370389
[Epoch 114; Iter   173/  209] train: loss: 0.0335093
[Epoch 114; Iter   203/  209] train: loss: 0.0506069
[Epoch 114] ogbg-moltox21: 0.765436 val loss: 0.883401
[Epoch 114] ogbg-moltox21: 0.747277 test loss: 0.443718
[Epoch 115; Iter    24/  209] train: loss: 0.0437398
[Epoch 115; Iter    54/  209] train: loss: 0.0295948
[Epoch 115; Iter    84/  209] train: loss: 0.0772714
[Epoch 115; Iter   114/  209] train: loss: 0.0374028
[Epoch 115; Iter   144/  209] train: loss: 0.0372517
[Epoch 115; Iter   174/  209] train: loss: 0.0842457
[Epoch 115; Iter   204/  209] train: loss: 0.0196869
[Epoch 115] ogbg-moltox21: 0.766863 val loss: 0.431738
[Epoch 115] ogbg-moltox21: 0.751517 test loss: 0.451075
[Epoch 116; Iter    25/  209] train: loss: 0.0637510
[Epoch 116; Iter    55/  209] train: loss: 0.0417524
[Epoch 116; Iter    85/  209] train: loss: 0.0393624
[Epoch 116; Iter   115/  209] train: loss: 0.0482141
[Epoch 109] ogbg-moltox21: 0.703482 test loss: 0.649738
[Epoch 110; Iter     3/  183] train: loss: 0.0430355
[Epoch 110; Iter    33/  183] train: loss: 0.0819370
[Epoch 110; Iter    63/  183] train: loss: 0.0507959
[Epoch 110; Iter    93/  183] train: loss: 0.0342672
[Epoch 110; Iter   123/  183] train: loss: 0.0290414
[Epoch 110; Iter   153/  183] train: loss: 0.0320357
[Epoch 110; Iter   183/  183] train: loss: 0.0544863
[Epoch 110] ogbg-moltox21: 0.735082 val loss: 0.432397
[Epoch 110] ogbg-moltox21: 0.710555 test loss: 0.576492
[Epoch 111; Iter    30/  183] train: loss: 0.0359993
[Epoch 111; Iter    60/  183] train: loss: 0.0581900
[Epoch 111; Iter    90/  183] train: loss: 0.0590831
[Epoch 111; Iter   120/  183] train: loss: 0.0336251
[Epoch 111; Iter   150/  183] train: loss: 0.0537517
[Epoch 111; Iter   180/  183] train: loss: 0.0388052
[Epoch 111] ogbg-moltox21: 0.736123 val loss: 0.433080
[Epoch 111] ogbg-moltox21: 0.704959 test loss: 0.622999
[Epoch 112; Iter    27/  183] train: loss: 0.0578586
[Epoch 112; Iter    57/  183] train: loss: 0.0528990
[Epoch 112; Iter    87/  183] train: loss: 0.0502641
[Epoch 112; Iter   117/  183] train: loss: 0.0277637
[Epoch 112; Iter   147/  183] train: loss: 0.0661925
[Epoch 112; Iter   177/  183] train: loss: 0.0610892
[Epoch 112] ogbg-moltox21: 0.733787 val loss: 0.443527
[Epoch 112] ogbg-moltox21: 0.702794 test loss: 0.622105
[Epoch 113; Iter    24/  183] train: loss: 0.0780883
[Epoch 113; Iter    54/  183] train: loss: 0.0371747
[Epoch 113; Iter    84/  183] train: loss: 0.0334330
[Epoch 113; Iter   114/  183] train: loss: 0.0463292
[Epoch 113; Iter   144/  183] train: loss: 0.0407054
[Epoch 113; Iter   174/  183] train: loss: 0.0422366
[Epoch 113] ogbg-moltox21: 0.732731 val loss: 0.442518
[Epoch 113] ogbg-moltox21: 0.706089 test loss: 0.673054
[Epoch 114; Iter    21/  183] train: loss: 0.0594001
[Epoch 114; Iter    51/  183] train: loss: 0.0470212
[Epoch 114; Iter    81/  183] train: loss: 0.0429033
[Epoch 114; Iter   111/  183] train: loss: 0.0242147
[Epoch 114; Iter   141/  183] train: loss: 0.0529748
[Epoch 114; Iter   171/  183] train: loss: 0.0953224
[Epoch 114] ogbg-moltox21: 0.730466 val loss: 0.449825
[Epoch 114] ogbg-moltox21: 0.705824 test loss: 0.623506
[Epoch 115; Iter    18/  183] train: loss: 0.0322679
[Epoch 115; Iter    48/  183] train: loss: 0.0621586
[Epoch 115; Iter    78/  183] train: loss: 0.0368656
[Epoch 115; Iter   108/  183] train: loss: 0.0503214
[Epoch 115; Iter   138/  183] train: loss: 0.0617514
[Epoch 115; Iter   168/  183] train: loss: 0.0553883
[Epoch 115] ogbg-moltox21: 0.732539 val loss: 0.442634
[Epoch 115] ogbg-moltox21: 0.706841 test loss: 0.655644
[Epoch 116; Iter    15/  183] train: loss: 0.0334176
[Epoch 116; Iter    45/  183] train: loss: 0.0458670
[Epoch 116; Iter    75/  183] train: loss: 0.0612692
[Epoch 116; Iter   105/  183] train: loss: 0.0780131
[Epoch 116; Iter   135/  183] train: loss: 0.0491426
[Epoch 116; Iter   165/  183] train: loss: 0.0380790
[Epoch 116] ogbg-moltox21: 0.732738 val loss: 0.452540
[Epoch 116] ogbg-moltox21: 0.703945 test loss: 0.714409
[Epoch 117; Iter    12/  183] train: loss: 0.0473959
[Epoch 117; Iter    42/  183] train: loss: 0.0181295
[Epoch 117; Iter    72/  183] train: loss: 0.0349737
[Epoch 117; Iter   102/  183] train: loss: 0.0376072
[Epoch 117; Iter   132/  183] train: loss: 0.0478697
[Epoch 117; Iter   162/  183] train: loss: 0.0752619
[Epoch 117] ogbg-moltox21: 0.733359 val loss: 0.450168
[Epoch 117] ogbg-moltox21: 0.706942 test loss: 0.669480
[Epoch 118; Iter     9/  183] train: loss: 0.0655515
[Epoch 118; Iter    39/  183] train: loss: 0.0462971
[Epoch 118; Iter    69/  183] train: loss: 0.0311650
[Epoch 118; Iter    99/  183] train: loss: 0.0425517
[Epoch 118; Iter   129/  183] train: loss: 0.0627853
[Epoch 118; Iter   159/  183] train: loss: 0.0388783
[Epoch 118] ogbg-moltox21: 0.733743 val loss: 0.460470
[Epoch 118] ogbg-moltox21: 0.704605 test loss: 0.690714
[Epoch 119; Iter     6/  183] train: loss: 0.0349023
[Epoch 119; Iter    36/  183] train: loss: 0.0238686
[Epoch 119; Iter    66/  183] train: loss: 0.0287371
[Epoch 119; Iter    96/  183] train: loss: 0.0407008
[Epoch 119; Iter   126/  183] train: loss: 0.0609482
[Epoch 119; Iter   156/  183] train: loss: 0.0614201
[Epoch 119] ogbg-moltox21: 0.733385 val loss: 0.461381
[Epoch 119] ogbg-moltox21: 0.705400 test loss: 0.682915
[Epoch 120; Iter     3/  183] train: loss: 0.0476910
[Epoch 120; Iter    33/  183] train: loss: 0.0451079
[Epoch 120; Iter    63/  183] train: loss: 0.0313536
[Epoch 120; Iter    93/  183] train: loss: 0.0271415
[Epoch 120; Iter   123/  183] train: loss: 0.0348886
[Epoch 120; Iter   153/  183] train: loss: 0.0520417
[Epoch 120; Iter   183/  183] train: loss: 0.0269410
[Epoch 120] ogbg-moltox21: 0.735964 val loss: 0.450148
[Epoch 120] ogbg-moltox21: 0.706133 test loss: 0.660844
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 36.
Statistics on  val_best_checkpoint
mean_pred: -3.2423694133758545
std_pred: 2.3256444931030273
mean_targets: nan
std_targets: nan
prcauc: 0.3138763094346426
rocauc: 0.7736795984697106
ogbg-moltox21: 0.7736795984697106
OGBNanLabelBCEWithLogitsLoss: 0.2886484803631902
Statistics on  test
mean_pred: -3.1727893352508545
std_pred: 2.9783759117126465
mean_targets: nan
std_targets: nan
prcauc: 0.3116261330808557
rocauc: 0.7544295173448229
ogbg-moltox21: 0.7544295173448229
OGBNanLabelBCEWithLogitsLoss: 0.3534619796089828
Statistics on  train
mean_pred: -3.734694242477417
std_pred: 23.1566162109375
mean_targets: nan
std_targets: nan
prcauc: 0.562455369240845
rocauc: 0.9208071405956176
ogbg-moltox21: 0.9208071405956176
OGBNanLabelBCEWithLogitsLoss: 0.3798001122767808
[Epoch 99; Iter   128/  209] train: loss: 0.0639406
[Epoch 99; Iter   158/  209] train: loss: 0.0618955
[Epoch 99; Iter   188/  209] train: loss: 0.0346412
[Epoch 99] ogbg-moltox21: 0.763916 val loss: 0.397324
[Epoch 99] ogbg-moltox21: 0.734041 test loss: 0.415306
[Epoch 100; Iter     9/  209] train: loss: 0.0540571
[Epoch 100; Iter    39/  209] train: loss: 0.0671841
[Epoch 100; Iter    69/  209] train: loss: 0.0519816
[Epoch 100; Iter    99/  209] train: loss: 0.0820131
[Epoch 100; Iter   129/  209] train: loss: 0.0819688
[Epoch 100; Iter   159/  209] train: loss: 0.0627181
[Epoch 100; Iter   189/  209] train: loss: 0.0453008
[Epoch 100] ogbg-moltox21: 0.763177 val loss: 0.400458
[Epoch 100] ogbg-moltox21: 0.733166 test loss: 0.415816
[Epoch 101; Iter    10/  209] train: loss: 0.0329556
[Epoch 101; Iter    40/  209] train: loss: 0.0326241
[Epoch 101; Iter    70/  209] train: loss: 0.0494555
[Epoch 101; Iter   100/  209] train: loss: 0.0796773
[Epoch 101; Iter   130/  209] train: loss: 0.0520968
[Epoch 101; Iter   160/  209] train: loss: 0.0953428
[Epoch 101; Iter   190/  209] train: loss: 0.0559012
[Epoch 101] ogbg-moltox21: 0.760543 val loss: 0.396502
[Epoch 101] ogbg-moltox21: 0.729929 test loss: 0.410706
[Epoch 102; Iter    11/  209] train: loss: 0.0582722
[Epoch 102; Iter    41/  209] train: loss: 0.0378484
[Epoch 102; Iter    71/  209] train: loss: 0.0434637
[Epoch 102; Iter   101/  209] train: loss: 0.0269264
[Epoch 102; Iter   131/  209] train: loss: 0.0416908
[Epoch 102; Iter   161/  209] train: loss: 0.0757715
[Epoch 102; Iter   191/  209] train: loss: 0.0851650
[Epoch 102] ogbg-moltox21: 0.764148 val loss: 0.400815
[Epoch 102] ogbg-moltox21: 0.733118 test loss: 0.413862
[Epoch 103; Iter    12/  209] train: loss: 0.0243089
[Epoch 103; Iter    42/  209] train: loss: 0.0490319
[Epoch 103; Iter    72/  209] train: loss: 0.0338537
[Epoch 103; Iter   102/  209] train: loss: 0.0441107
[Epoch 103; Iter   132/  209] train: loss: 0.0887236
[Epoch 103; Iter   162/  209] train: loss: 0.1199201
[Epoch 103; Iter   192/  209] train: loss: 0.0446603
[Epoch 103] ogbg-moltox21: 0.766919 val loss: 0.400051
[Epoch 103] ogbg-moltox21: 0.732040 test loss: 0.422808
[Epoch 104; Iter    13/  209] train: loss: 0.0534504
[Epoch 104; Iter    43/  209] train: loss: 0.0475091
[Epoch 104; Iter    73/  209] train: loss: 0.0406959
[Epoch 104; Iter   103/  209] train: loss: 0.0805188
[Epoch 104; Iter   133/  209] train: loss: 0.0460962
[Epoch 104; Iter   163/  209] train: loss: 0.0612581
[Epoch 104; Iter   193/  209] train: loss: 0.0448681
[Epoch 104] ogbg-moltox21: 0.763665 val loss: 0.404213
[Epoch 104] ogbg-moltox21: 0.731649 test loss: 0.425064
[Epoch 105; Iter    14/  209] train: loss: 0.0349327
[Epoch 105; Iter    44/  209] train: loss: 0.0240448
[Epoch 105; Iter    74/  209] train: loss: 0.0326401
[Epoch 105; Iter   104/  209] train: loss: 0.0416791
[Epoch 105; Iter   134/  209] train: loss: 0.0343734
[Epoch 105; Iter   164/  209] train: loss: 0.0277482
[Epoch 105; Iter   194/  209] train: loss: 0.0254552
[Epoch 105] ogbg-moltox21: 0.766981 val loss: 0.404994
[Epoch 105] ogbg-moltox21: 0.740032 test loss: 0.421634
[Epoch 106; Iter    15/  209] train: loss: 0.0520605
[Epoch 106; Iter    45/  209] train: loss: 0.0554476
[Epoch 106; Iter    75/  209] train: loss: 0.0659989
[Epoch 106; Iter   105/  209] train: loss: 0.0572817
[Epoch 106; Iter   135/  209] train: loss: 0.0429615
[Epoch 106; Iter   165/  209] train: loss: 0.0503818
[Epoch 106; Iter   195/  209] train: loss: 0.0173906
[Epoch 106] ogbg-moltox21: 0.755645 val loss: 0.418847
[Epoch 106] ogbg-moltox21: 0.734140 test loss: 0.425220
[Epoch 107; Iter    16/  209] train: loss: 0.0383975
[Epoch 107; Iter    46/  209] train: loss: 0.0388285
[Epoch 107; Iter    76/  209] train: loss: 0.0976772
[Epoch 107; Iter   106/  209] train: loss: 0.0468682
[Epoch 107; Iter   136/  209] train: loss: 0.0274435
[Epoch 107; Iter   166/  209] train: loss: 0.0473426
[Epoch 107; Iter   196/  209] train: loss: 0.0447963
[Epoch 107] ogbg-moltox21: 0.760648 val loss: 0.407522
[Epoch 107] ogbg-moltox21: 0.730572 test loss: 0.425091
[Epoch 108; Iter    17/  209] train: loss: 0.0488719
[Epoch 108; Iter    47/  209] train: loss: 0.0838609
[Epoch 108; Iter    77/  209] train: loss: 0.0567240
[Epoch 108; Iter   107/  209] train: loss: 0.0903190
[Epoch 108; Iter   137/  209] train: loss: 0.0496091
[Epoch 108; Iter   167/  209] train: loss: 0.0297856
[Epoch 108; Iter   197/  209] train: loss: 0.0687082
[Epoch 108] ogbg-moltox21: 0.762941 val loss: 0.420104
[Epoch 108] ogbg-moltox21: 0.728736 test loss: 0.441269
[Epoch 109; Iter    18/  209] train: loss: 0.0263115
[Epoch 109; Iter    48/  209] train: loss: 0.0511953
[Epoch 109; Iter    78/  209] train: loss: 0.0321436
[Epoch 109; Iter   108/  209] train: loss: 0.0775512
[Epoch 109; Iter   138/  209] train: loss: 0.0383410
[Epoch 109; Iter   168/  209] train: loss: 0.0256768
[Epoch 109; Iter   198/  209] train: loss: 0.0292757
[Epoch 109] ogbg-moltox21: 0.762287 val loss: 0.422048
[Epoch 109] ogbg-moltox21: 0.734282 test loss: 0.436619
[Epoch 110; Iter    19/  209] train: loss: 0.0303146
[Epoch 110; Iter    49/  209] train: loss: 0.0671088
[Epoch 110; Iter    79/  209] train: loss: 0.0462032
[Epoch 110; Iter   109/  209] train: loss: 0.0477268
[Epoch 110; Iter   139/  209] train: loss: 0.0640828
[Epoch 110; Iter   169/  209] train: loss: 0.0449132
[Epoch 110; Iter   199/  209] train: loss: 0.0544959
[Epoch 110] ogbg-moltox21: 0.761972 val loss: 0.414810
[Epoch 110] ogbg-moltox21: 0.729922 test loss: 0.440462
[Epoch 111; Iter    20/  209] train: loss: 0.0524903
[Epoch 111; Iter    50/  209] train: loss: 0.0506231
[Epoch 111; Iter    80/  209] train: loss: 0.0464797
[Epoch 111; Iter   110/  209] train: loss: 0.0338288
[Epoch 111; Iter   140/  209] train: loss: 0.0336088
[Epoch 111; Iter   170/  209] train: loss: 0.0398238
[Epoch 111; Iter   200/  209] train: loss: 0.0382293
[Epoch 111] ogbg-moltox21: 0.764205 val loss: 0.414056
[Epoch 111] ogbg-moltox21: 0.724834 test loss: 0.438458
[Epoch 112; Iter    21/  209] train: loss: 0.0444940
[Epoch 112; Iter    51/  209] train: loss: 0.0337030
[Epoch 112; Iter    81/  209] train: loss: 0.0530829
[Epoch 112; Iter   111/  209] train: loss: 0.0397111
[Epoch 112; Iter   141/  209] train: loss: 0.0644203
[Epoch 112; Iter   171/  209] train: loss: 0.0447681
[Epoch 112; Iter   201/  209] train: loss: 0.0710638
[Epoch 112] ogbg-moltox21: 0.767595 val loss: 0.416976
[Epoch 112] ogbg-moltox21: 0.735032 test loss: 0.438912
[Epoch 113; Iter    22/  209] train: loss: 0.0703214
[Epoch 113; Iter    52/  209] train: loss: 0.0313136
[Epoch 113; Iter    82/  209] train: loss: 0.0381817
[Epoch 113; Iter   112/  209] train: loss: 0.0429131
[Epoch 113; Iter   142/  209] train: loss: 0.0437863
[Epoch 113; Iter   172/  209] train: loss: 0.0257128
[Epoch 113; Iter   202/  209] train: loss: 0.0617956
[Epoch 113] ogbg-moltox21: 0.762465 val loss: 0.423064
[Epoch 113] ogbg-moltox21: 0.727918 test loss: 0.438241
[Epoch 114; Iter    23/  209] train: loss: 0.0294993
[Epoch 114; Iter    53/  209] train: loss: 0.0668000
[Epoch 114; Iter    83/  209] train: loss: 0.0591454
[Epoch 114; Iter   113/  209] train: loss: 0.0455565
[Epoch 114; Iter   143/  209] train: loss: 0.0270174
[Epoch 114; Iter   173/  209] train: loss: 0.0217145
[Epoch 114; Iter   203/  209] train: loss: 0.0368815
[Epoch 114] ogbg-moltox21: 0.763281 val loss: 0.420558
[Epoch 114] ogbg-moltox21: 0.730052 test loss: 0.433704
[Epoch 115; Iter    24/  209] train: loss: 0.0349787
[Epoch 115; Iter    54/  209] train: loss: 0.0454402
[Epoch 115; Iter    84/  209] train: loss: 0.0427737
[Epoch 115; Iter   114/  209] train: loss: 0.0438981
[Epoch 115; Iter   144/  209] train: loss: 0.0479983
[Epoch 115; Iter   174/  209] train: loss: 0.0352915
[Epoch 115; Iter   204/  209] train: loss: 0.0630004
[Epoch 115] ogbg-moltox21: 0.763655 val loss: 0.424212
[Epoch 115] ogbg-moltox21: 0.730902 test loss: 0.442013
[Epoch 116; Iter    25/  209] train: loss: 0.0314214
[Epoch 116; Iter    55/  209] train: loss: 0.0349065
[Epoch 116; Iter    85/  209] train: loss: 0.0680505
[Epoch 116; Iter   115/  209] train: loss: 0.0398761
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 109] ogbg-moltox21: 0.711815 test loss: 0.504664
[Epoch 110; Iter     3/  183] train: loss: 0.0381659
[Epoch 110; Iter    33/  183] train: loss: 0.0195123
[Epoch 110; Iter    63/  183] train: loss: 0.0304163
[Epoch 110; Iter    93/  183] train: loss: 0.0558588
[Epoch 110; Iter   123/  183] train: loss: 0.0327622
[Epoch 110; Iter   153/  183] train: loss: 0.0398159
[Epoch 110; Iter   183/  183] train: loss: 0.0294450
[Epoch 110] ogbg-moltox21: 0.736762 val loss: 0.522107
[Epoch 110] ogbg-moltox21: 0.711048 test loss: 0.507635
[Epoch 111; Iter    30/  183] train: loss: 0.0249630
[Epoch 111; Iter    60/  183] train: loss: 0.0381228
[Epoch 111; Iter    90/  183] train: loss: 0.0304185
[Epoch 111; Iter   120/  183] train: loss: 0.0327925
[Epoch 111; Iter   150/  183] train: loss: 0.0489777
[Epoch 111; Iter   180/  183] train: loss: 0.0496329
[Epoch 111] ogbg-moltox21: 0.738416 val loss: 0.520212
[Epoch 111] ogbg-moltox21: 0.716355 test loss: 0.505904
[Epoch 112; Iter    27/  183] train: loss: 0.0490098
[Epoch 112; Iter    57/  183] train: loss: 0.0277522
[Epoch 112; Iter    87/  183] train: loss: 0.0420903
[Epoch 112; Iter   117/  183] train: loss: 0.0258725
[Epoch 112; Iter   147/  183] train: loss: 0.0210066
[Epoch 112; Iter   177/  183] train: loss: 0.0352636
[Epoch 112] ogbg-moltox21: 0.736140 val loss: 0.508190
[Epoch 112] ogbg-moltox21: 0.713802 test loss: 0.502802
[Epoch 113; Iter    24/  183] train: loss: 0.0349644
[Epoch 113; Iter    54/  183] train: loss: 0.0406284
[Epoch 113; Iter    84/  183] train: loss: 0.0337586
[Epoch 113; Iter   114/  183] train: loss: 0.0623308
[Epoch 113; Iter   144/  183] train: loss: 0.0236739
[Epoch 113; Iter   174/  183] train: loss: 0.0429566
[Epoch 113] ogbg-moltox21: 0.741287 val loss: 0.515087
[Epoch 113] ogbg-moltox21: 0.709951 test loss: 0.521880
[Epoch 114; Iter    21/  183] train: loss: 0.0386084
[Epoch 114; Iter    51/  183] train: loss: 0.0316749
[Epoch 114; Iter    81/  183] train: loss: 0.0411996
[Epoch 114; Iter   111/  183] train: loss: 0.0372098
[Epoch 114; Iter   141/  183] train: loss: 0.0323814
[Epoch 114; Iter   171/  183] train: loss: 0.0497864
[Epoch 114] ogbg-moltox21: 0.740539 val loss: 0.512977
[Epoch 114] ogbg-moltox21: 0.708753 test loss: 0.520724
[Epoch 115; Iter    18/  183] train: loss: 0.0328881
[Epoch 115; Iter    48/  183] train: loss: 0.0283717
[Epoch 115; Iter    78/  183] train: loss: 0.0470359
[Epoch 115; Iter   108/  183] train: loss: 0.0484856
[Epoch 115; Iter   138/  183] train: loss: 0.0484974
[Epoch 115; Iter   168/  183] train: loss: 0.0203071
[Epoch 115] ogbg-moltox21: 0.742754 val loss: 0.517398
[Epoch 115] ogbg-moltox21: 0.710951 test loss: 0.521765
[Epoch 116; Iter    15/  183] train: loss: 0.0317881
[Epoch 116; Iter    45/  183] train: loss: 0.0309171
[Epoch 116; Iter    75/  183] train: loss: 0.0284177
[Epoch 116; Iter   105/  183] train: loss: 0.0164396
[Epoch 116; Iter   135/  183] train: loss: 0.0222458
[Epoch 116; Iter   165/  183] train: loss: 0.0290838
[Epoch 116] ogbg-moltox21: 0.744830 val loss: 0.506008
[Epoch 116] ogbg-moltox21: 0.711894 test loss: 0.515930
[Epoch 117; Iter    12/  183] train: loss: 0.0316456
[Epoch 117; Iter    42/  183] train: loss: 0.0180049
[Epoch 117; Iter    72/  183] train: loss: 0.0275524
[Epoch 117; Iter   102/  183] train: loss: 0.0528680
[Epoch 117; Iter   132/  183] train: loss: 0.0394363
[Epoch 117; Iter   162/  183] train: loss: 0.0439352
[Epoch 117] ogbg-moltox21: 0.744546 val loss: 0.500738
[Epoch 117] ogbg-moltox21: 0.715563 test loss: 0.521439
[Epoch 118; Iter     9/  183] train: loss: 0.0469772
[Epoch 118; Iter    39/  183] train: loss: 0.0493269
[Epoch 118; Iter    69/  183] train: loss: 0.0448326
[Epoch 118; Iter    99/  183] train: loss: 0.0968103
[Epoch 118; Iter   129/  183] train: loss: 0.0228238
[Epoch 118; Iter   159/  183] train: loss: 0.0405761
[Epoch 118] ogbg-moltox21: 0.742164 val loss: 0.513632
[Epoch 118] ogbg-moltox21: 0.711701 test loss: 0.524353
[Epoch 119; Iter     6/  183] train: loss: 0.0533576
[Epoch 119; Iter    36/  183] train: loss: 0.0139003
[Epoch 119; Iter    66/  183] train: loss: 0.0254131
[Epoch 119; Iter    96/  183] train: loss: 0.0232686
[Epoch 119; Iter   126/  183] train: loss: 0.0337741
[Epoch 119; Iter   156/  183] train: loss: 0.0326581
[Epoch 119] ogbg-moltox21: 0.740756 val loss: 0.504313
[Epoch 119] ogbg-moltox21: 0.708500 test loss: 0.535340
[Epoch 120; Iter     3/  183] train: loss: 0.0478846
[Epoch 120; Iter    33/  183] train: loss: 0.0248393
[Epoch 120; Iter    63/  183] train: loss: 0.0303106
[Epoch 120; Iter    93/  183] train: loss: 0.0327876
[Epoch 120; Iter   123/  183] train: loss: 0.0198788
[Epoch 120; Iter   153/  183] train: loss: 0.0288390
[Epoch 120; Iter   183/  183] train: loss: 0.0263035
[Epoch 120] ogbg-moltox21: 0.742789 val loss: 0.511771
[Epoch 120] ogbg-moltox21: 0.710414 test loss: 0.524123
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 37.
Statistics on  val_best_checkpoint
mean_pred: -3.653071641921997
std_pred: 2.5647757053375244
mean_targets: nan
std_targets: nan
prcauc: 0.3498501552171533
rocauc: 0.7741921377956972
ogbg-moltox21: 0.7741921377956972
OGBNanLabelBCEWithLogitsLoss: 0.29073925465345385
Statistics on  test
mean_pred: -3.582507371902466
std_pred: 2.5512280464172363
mean_targets: nan
std_targets: nan
prcauc: 0.3539639615816533
rocauc: 0.7399105503447791
ogbg-moltox21: 0.7399105503447791
OGBNanLabelBCEWithLogitsLoss: 0.2926384719088674
Statistics on  train
mean_pred: -4.404784679412842
std_pred: 4.44890832901001
mean_targets: nan
std_targets: nan
prcauc: 0.7459059453026256
rocauc: 0.9483193170060046
ogbg-moltox21: 0.9483193170060046
OGBNanLabelBCEWithLogitsLoss: 0.11223390669933433
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0210264
[Epoch 116; Iter   175/  209] train: loss: 0.0877077
[Epoch 116; Iter   205/  209] train: loss: 0.0587427
[Epoch 116] ogbg-moltox21: 0.761393 val loss: 0.389907
[Epoch 116] ogbg-moltox21: 0.736802 test loss: 0.435826
[Epoch 117; Iter    26/  209] train: loss: 0.0384242
[Epoch 117; Iter    56/  209] train: loss: 0.0523009
[Epoch 117; Iter    86/  209] train: loss: 0.0377202
[Epoch 117; Iter   116/  209] train: loss: 0.0527302
[Epoch 117; Iter   146/  209] train: loss: 0.0700795
[Epoch 117; Iter   176/  209] train: loss: 0.0561811
[Epoch 117; Iter   206/  209] train: loss: 0.0422489
[Epoch 117] ogbg-moltox21: 0.761777 val loss: 0.396063
[Epoch 117] ogbg-moltox21: 0.733633 test loss: 0.448147
[Epoch 118; Iter    27/  209] train: loss: 0.0267544
[Epoch 118; Iter    57/  209] train: loss: 0.0428770
[Epoch 118; Iter    87/  209] train: loss: 0.0357015
[Epoch 118; Iter   117/  209] train: loss: 0.0535273
[Epoch 118; Iter   147/  209] train: loss: 0.0572555
[Epoch 118; Iter   177/  209] train: loss: 0.0343313
[Epoch 118; Iter   207/  209] train: loss: 0.0482823
[Epoch 118] ogbg-moltox21: 0.759417 val loss: 0.399518
[Epoch 118] ogbg-moltox21: 0.733994 test loss: 0.444107
[Epoch 119; Iter    28/  209] train: loss: 0.0678071
[Epoch 119; Iter    58/  209] train: loss: 0.0666819
[Epoch 119; Iter    88/  209] train: loss: 0.0231060
[Epoch 119; Iter   118/  209] train: loss: 0.1028353
[Epoch 119; Iter   148/  209] train: loss: 0.0450661
[Epoch 119; Iter   178/  209] train: loss: 0.0521469
[Epoch 119; Iter   208/  209] train: loss: 0.0482268
[Epoch 119] ogbg-moltox21: 0.757603 val loss: 0.402717
[Epoch 119] ogbg-moltox21: 0.732962 test loss: 0.446969
[Epoch 120; Iter    29/  209] train: loss: 0.0378957
[Epoch 120; Iter    59/  209] train: loss: 0.0463860
[Epoch 120; Iter    89/  209] train: loss: 0.0398174
[Epoch 120; Iter   119/  209] train: loss: 0.0606670
[Epoch 120; Iter   149/  209] train: loss: 0.0310194
[Epoch 120; Iter   179/  209] train: loss: 0.0661753
[Epoch 120; Iter   209/  209] train: loss: 0.0582654
[Epoch 120] ogbg-moltox21: 0.760121 val loss: 0.395765
[Epoch 120] ogbg-moltox21: 0.737167 test loss: 0.438223
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 39.
Statistics on  val_best_checkpoint
mean_pred: -3.3379666805267334
std_pred: 2.179953098297119
mean_targets: nan
std_targets: nan
prcauc: 0.4183943253332851
rocauc: 0.8092491750065854
ogbg-moltox21: 0.8092491750065854
OGBNanLabelBCEWithLogitsLoss: 0.2456575612779017
Statistics on  test
mean_pred: -3.3686962127685547
std_pred: 2.207005739212036
mean_targets: nan
std_targets: nan
prcauc: 0.37795359016023466
rocauc: 0.767422531465756
ogbg-moltox21: 0.767422531465756
OGBNanLabelBCEWithLogitsLoss: 0.26480337259946046
Statistics on  train
mean_pred: -4.100701332092285
std_pred: 2.407115936279297
mean_targets: nan
std_targets: nan
prcauc: 0.6993591526960218
rocauc: 0.9353546441334958
ogbg-moltox21: 0.9353546441334958
OGBNanLabelBCEWithLogitsLoss: 0.122319807525742
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0588885
[Epoch 116; Iter   175/  209] train: loss: 0.0242048
[Epoch 116; Iter   205/  209] train: loss: 0.0531161
[Epoch 116] ogbg-moltox21: 0.761789 val loss: 0.437251
[Epoch 116] ogbg-moltox21: 0.748836 test loss: 0.447255
[Epoch 117; Iter    26/  209] train: loss: 0.0324234
[Epoch 117; Iter    56/  209] train: loss: 0.0290179
[Epoch 117; Iter    86/  209] train: loss: 0.0267854
[Epoch 117; Iter   116/  209] train: loss: 0.0279835
[Epoch 117; Iter   146/  209] train: loss: 0.0361309
[Epoch 117; Iter   176/  209] train: loss: 0.0394637
[Epoch 117; Iter   206/  209] train: loss: 0.0364710
[Epoch 117] ogbg-moltox21: 0.762848 val loss: 0.426982
[Epoch 117] ogbg-moltox21: 0.750785 test loss: 0.444194
[Epoch 118; Iter    27/  209] train: loss: 0.0421744
[Epoch 118; Iter    57/  209] train: loss: 0.0317400
[Epoch 118; Iter    87/  209] train: loss: 0.0278706
[Epoch 118; Iter   117/  209] train: loss: 0.0363221
[Epoch 118; Iter   147/  209] train: loss: 0.0533550
[Epoch 118; Iter   177/  209] train: loss: 0.0423787
[Epoch 118; Iter   207/  209] train: loss: 0.0374306
[Epoch 118] ogbg-moltox21: 0.766086 val loss: 0.791941
[Epoch 118] ogbg-moltox21: 0.751026 test loss: 0.451198
[Epoch 119; Iter    28/  209] train: loss: 0.0426483
[Epoch 119; Iter    58/  209] train: loss: 0.0462749
[Epoch 119; Iter    88/  209] train: loss: 0.0393602
[Epoch 119; Iter   118/  209] train: loss: 0.0589323
[Epoch 119; Iter   148/  209] train: loss: 0.0249336
[Epoch 119; Iter   178/  209] train: loss: 0.0539846
[Epoch 119; Iter   208/  209] train: loss: 0.0391739
[Epoch 119] ogbg-moltox21: 0.769996 val loss: 0.439549
[Epoch 119] ogbg-moltox21: 0.752835 test loss: 0.452550
[Epoch 120; Iter    29/  209] train: loss: 0.0310600
[Epoch 120; Iter    59/  209] train: loss: 0.0294499
[Epoch 120; Iter    89/  209] train: loss: 0.0399349
[Epoch 120; Iter   119/  209] train: loss: 0.0357202
[Epoch 120; Iter   149/  209] train: loss: 0.0415772
[Epoch 120; Iter   179/  209] train: loss: 0.0302068
[Epoch 120; Iter   209/  209] train: loss: 0.0443929
[Epoch 120] ogbg-moltox21: 0.766286 val loss: 0.428423
[Epoch 120] ogbg-moltox21: 0.750707 test loss: 0.448138
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 24.
Statistics on  val_best_checkpoint
mean_pred: -2.948179006576538
std_pred: 1.8915326595306396
mean_targets: nan
std_targets: nan
prcauc: 0.3970385136458278
rocauc: 0.803562700233563
ogbg-moltox21: 0.803562700233563
OGBNanLabelBCEWithLogitsLoss: 0.24487620371359367
Statistics on  test
mean_pred: -2.9941015243530273
std_pred: 1.9267939329147339
mean_targets: nan
std_targets: nan
prcauc: 0.35363639576186795
rocauc: 0.7703809993071166
ogbg-moltox21: 0.7703809993071166
OGBNanLabelBCEWithLogitsLoss: 0.2581074949767854
Statistics on  train
mean_pred: -3.6707003116607666
std_pred: 2.42179536819458
mean_targets: nan
std_targets: nan
prcauc: 0.5183373871570797
rocauc: 0.8967044245114741
ogbg-moltox21: 0.8967044245114741
OGBNanLabelBCEWithLogitsLoss: 0.17208771473554332
[Epoch 116; Iter   145/  209] train: loss: 0.0504254
[Epoch 116; Iter   175/  209] train: loss: 0.0381224
[Epoch 116; Iter   205/  209] train: loss: 0.0663694
[Epoch 116] ogbg-moltox21: 0.763422 val loss: 0.424364
[Epoch 116] ogbg-moltox21: 0.729920 test loss: 0.440315
[Epoch 117; Iter    26/  209] train: loss: 0.0492392
[Epoch 117; Iter    56/  209] train: loss: 0.0288703
[Epoch 117; Iter    86/  209] train: loss: 0.0330359
[Epoch 117; Iter   116/  209] train: loss: 0.0452329
[Epoch 117; Iter   146/  209] train: loss: 0.0324480
[Epoch 117; Iter   176/  209] train: loss: 0.0319800
[Epoch 117; Iter   206/  209] train: loss: 0.0248275
[Epoch 117] ogbg-moltox21: 0.761014 val loss: 0.432002
[Epoch 117] ogbg-moltox21: 0.729194 test loss: 0.446047
[Epoch 118; Iter    27/  209] train: loss: 0.0232772
[Epoch 118; Iter    57/  209] train: loss: 0.0764409
[Epoch 118; Iter    87/  209] train: loss: 0.0526339
[Epoch 118; Iter   117/  209] train: loss: 0.0647612
[Epoch 118; Iter   147/  209] train: loss: 0.0254170
[Epoch 118; Iter   177/  209] train: loss: 0.0461976
[Epoch 118; Iter   207/  209] train: loss: 0.0282478
[Epoch 118] ogbg-moltox21: 0.759580 val loss: 0.432333
[Epoch 118] ogbg-moltox21: 0.729856 test loss: 0.447344
[Epoch 119; Iter    28/  209] train: loss: 0.0397599
[Epoch 119; Iter    58/  209] train: loss: 0.0512619
[Epoch 119; Iter    88/  209] train: loss: 0.0521097
[Epoch 119; Iter   118/  209] train: loss: 0.0267243
[Epoch 119; Iter   148/  209] train: loss: 0.0391775
[Epoch 119; Iter   178/  209] train: loss: 0.0353518
[Epoch 119; Iter   208/  209] train: loss: 0.0196089
[Epoch 119] ogbg-moltox21: 0.759262 val loss: 0.438657
[Epoch 119] ogbg-moltox21: 0.727638 test loss: 0.451168
[Epoch 120; Iter    29/  209] train: loss: 0.0598175
[Epoch 120; Iter    59/  209] train: loss: 0.0357998
[Epoch 120; Iter    89/  209] train: loss: 0.0553424
[Epoch 120; Iter   119/  209] train: loss: 0.0336775
[Epoch 120; Iter   149/  209] train: loss: 0.1289792
[Epoch 120; Iter   179/  209] train: loss: 0.0348281
[Epoch 120; Iter   209/  209] train: loss: 0.0529800
[Epoch 120] ogbg-moltox21: 0.761709 val loss: 0.434557
[Epoch 120] ogbg-moltox21: 0.729353 test loss: 0.453336
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 31.
Statistics on  val_best_checkpoint
mean_pred: -3.2537355422973633
std_pred: 2.0115697383880615
mean_targets: nan
std_targets: nan
prcauc: 0.3850520703121363
rocauc: 0.8016279833098808
ogbg-moltox21: 0.8016279833098808
OGBNanLabelBCEWithLogitsLoss: 0.2448113406146014
Statistics on  test
mean_pred: -3.289947748184204
std_pred: 2.058291435241699
mean_targets: nan
std_targets: nan
prcauc: 0.368797231634379
rocauc: 0.768739560157632
ogbg-moltox21: 0.768739560157632
OGBNanLabelBCEWithLogitsLoss: 0.25763670493055274
Statistics on  train
mean_pred: -3.7745683193206787
std_pred: 2.431647300720215
mean_targets: nan
std_targets: nan
prcauc: 0.5502872186817791
rocauc: 0.9088669063514603
ogbg-moltox21: 0.9088669063514603
OGBNanLabelBCEWithLogitsLoss: 0.17161466227621552
All runs completed.
