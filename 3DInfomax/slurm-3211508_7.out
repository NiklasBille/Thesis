>>> Starting run for dataset: toxcast
Running configs_static_noise_experiments/3DInfomax/toxcast/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/3DInfomax/toxcast/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/3DInfomax/toxcast/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/3DInfomax/toxcast/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.0/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.0_4_26-05_09-37-40
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.0
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931715
[Epoch 1; Iter    60/  229] train: loss: 0.6931896
[Epoch 1; Iter    90/  229] train: loss: 0.6931353
[Epoch 1; Iter   120/  229] train: loss: 0.6931071
[Epoch 1; Iter   150/  229] train: loss: 0.6931202
[Epoch 1; Iter   180/  229] train: loss: 0.6931241
[Epoch 1; Iter   210/  229] train: loss: 0.6931379
[Epoch 1] ogbg-moltoxcast: 0.504053 val loss: 0.693148
[Epoch 1] ogbg-moltoxcast: 0.500634 test loss: 0.693155
[Epoch 2; Iter    11/  229] train: loss: 0.6931756
[Epoch 2; Iter    41/  229] train: loss: 0.6931081
[Epoch 2; Iter    71/  229] train: loss: 0.6930705
[Epoch 2; Iter   101/  229] train: loss: 0.6930866
[Epoch 2; Iter   131/  229] train: loss: 0.6930298
[Epoch 2; Iter   161/  229] train: loss: 0.6930939
[Epoch 2; Iter   191/  229] train: loss: 0.6930686
[Epoch 2; Iter   221/  229] train: loss: 0.6930038
[Epoch 2] ogbg-moltoxcast: 0.503096 val loss: 0.693045
[Epoch 2] ogbg-moltoxcast: 0.499497 test loss: 0.693066
[Epoch 3; Iter    22/  229] train: loss: 0.6930162
[Epoch 3; Iter    52/  229] train: loss: 0.6930234
[Epoch 3; Iter    82/  229] train: loss: 0.6929821
[Epoch 3; Iter   112/  229] train: loss: 0.6929579
[Epoch 3; Iter   142/  229] train: loss: 0.6929533
[Epoch 3; Iter   172/  229] train: loss: 0.6929307
[Epoch 3; Iter   202/  229] train: loss: 0.6929398
[Epoch 3] ogbg-moltoxcast: 0.503084 val loss: 0.692872
[Epoch 3] ogbg-moltoxcast: 0.500348 test loss: 0.692905
[Epoch 4; Iter     3/  229] train: loss: 0.6928313
[Epoch 4; Iter    33/  229] train: loss: 0.6903687
[Epoch 4; Iter    63/  229] train: loss: 0.6758286
[Epoch 4; Iter    93/  229] train: loss: 0.6587858
[Epoch 4; Iter   123/  229] train: loss: 0.6129633
[Epoch 4; Iter   153/  229] train: loss: 0.5957923
[Epoch 4; Iter   183/  229] train: loss: 0.5264485
[Epoch 4; Iter   213/  229] train: loss: 0.4520765
[Epoch 4] ogbg-moltoxcast: 0.594532 val loss: 0.439000
[Epoch 4] ogbg-moltoxcast: 0.559944 test loss: 0.466451
[Epoch 5; Iter    14/  229] train: loss: 0.4362020
[Epoch 5; Iter    44/  229] train: loss: 0.3540535
[Epoch 5; Iter    74/  229] train: loss: 0.2867922
[Epoch 5; Iter   104/  229] train: loss: 0.3235494
[Epoch 5; Iter   134/  229] train: loss: 0.3178131
[Epoch 5; Iter   164/  229] train: loss: 0.2557105
[Epoch 5; Iter   194/  229] train: loss: 0.2501344
[Epoch 5; Iter   224/  229] train: loss: 0.1684435
[Epoch 5] ogbg-moltoxcast: 0.618959 val loss: 0.276367
[Epoch 5] ogbg-moltoxcast: 0.583531 test loss: 0.314204
[Epoch 6; Iter    25/  229] train: loss: 0.2574765
[Epoch 6; Iter    55/  229] train: loss: 0.2045357
[Epoch 6; Iter    85/  229] train: loss: 0.3053266
[Epoch 6; Iter   115/  229] train: loss: 0.2201587
[Epoch 6; Iter   145/  229] train: loss: 0.2130118
[Epoch 6; Iter   175/  229] train: loss: 0.1915605
[Epoch 6; Iter   205/  229] train: loss: 0.1833916
[Epoch 6] ogbg-moltoxcast: 0.624673 val loss: 0.267673
[Epoch 6] ogbg-moltoxcast: 0.616278 test loss: 0.299798
[Epoch 7; Iter     6/  229] train: loss: 0.1313613
[Epoch 7; Iter    36/  229] train: loss: 0.2326269
[Epoch 7; Iter    66/  229] train: loss: 0.2063138
[Epoch 7; Iter    96/  229] train: loss: 0.1924702
[Epoch 7; Iter   126/  229] train: loss: 0.2930489
[Epoch 7; Iter   156/  229] train: loss: 0.1820037
[Epoch 7; Iter   186/  229] train: loss: 0.3105771
[Epoch 7; Iter   216/  229] train: loss: 0.1878702
[Epoch 7] ogbg-moltoxcast: 0.636078 val loss: 0.270734
[Epoch 7] ogbg-moltoxcast: 0.601252 test loss: 0.310217
[Epoch 8; Iter    17/  229] train: loss: 0.1616474
[Epoch 8; Iter    47/  229] train: loss: 0.3220731
[Epoch 8; Iter    77/  229] train: loss: 0.1799117
[Epoch 8; Iter   107/  229] train: loss: 0.2549069
[Epoch 8; Iter   137/  229] train: loss: 0.1835513
[Epoch 8; Iter   167/  229] train: loss: 0.1670410
[Epoch 8; Iter   197/  229] train: loss: 0.2228290
[Epoch 8; Iter   227/  229] train: loss: 0.2108891
[Epoch 8] ogbg-moltoxcast: 0.639826 val loss: 0.269251
[Epoch 8] ogbg-moltoxcast: 0.619010 test loss: 0.311716
[Epoch 9; Iter    28/  229] train: loss: 0.1314045
[Epoch 9; Iter    58/  229] train: loss: 0.1288737
[Epoch 9; Iter    88/  229] train: loss: 0.2005192
[Epoch 9; Iter   118/  229] train: loss: 0.1108831
[Epoch 9; Iter   148/  229] train: loss: 0.2147911
[Epoch 9; Iter   178/  229] train: loss: 0.2144908
[Epoch 9; Iter   208/  229] train: loss: 0.1940026
[Epoch 9] ogbg-moltoxcast: 0.640634 val loss: 0.272069
[Epoch 9] ogbg-moltoxcast: 0.606122 test loss: 0.313973
[Epoch 10; Iter     9/  229] train: loss: 0.1464138
[Epoch 10; Iter    39/  229] train: loss: 0.1479093
[Epoch 10; Iter    69/  229] train: loss: 0.2476139
[Epoch 10; Iter    99/  229] train: loss: 0.2678275
[Epoch 10; Iter   129/  229] train: loss: 0.1654354
[Epoch 10; Iter   159/  229] train: loss: 0.2201822
[Epoch 10; Iter   189/  229] train: loss: 0.2289595
[Epoch 10; Iter   219/  229] train: loss: 0.2478369
[Epoch 10] ogbg-moltoxcast: 0.645162 val loss: 0.260854
[Epoch 10] ogbg-moltoxcast: 0.623797 test loss: 0.298926
[Epoch 11; Iter    20/  229] train: loss: 0.1640974
[Epoch 11; Iter    50/  229] train: loss: 0.1980154
[Epoch 11; Iter    80/  229] train: loss: 0.1749891
[Epoch 11; Iter   110/  229] train: loss: 0.1652089
[Epoch 11; Iter   140/  229] train: loss: 0.2630669
[Epoch 11; Iter   170/  229] train: loss: 0.2178090
[Epoch 11; Iter   200/  229] train: loss: 0.2766529
[Epoch 11] ogbg-moltoxcast: 0.666304 val loss: 0.259244
[Epoch 11] ogbg-moltoxcast: 0.621899 test loss: 0.307424
[Epoch 12; Iter     1/  229] train: loss: 0.1601509
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.0/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.0_5_26-05_09-37-41
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.0
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6930988
[Epoch 1; Iter    60/  229] train: loss: 0.6931993
[Epoch 1; Iter    90/  229] train: loss: 0.6931190
[Epoch 1; Iter   120/  229] train: loss: 0.6931419
[Epoch 1; Iter   150/  229] train: loss: 0.6931109
[Epoch 1; Iter   180/  229] train: loss: 0.6931548
[Epoch 1; Iter   210/  229] train: loss: 0.6931753
[Epoch 1] ogbg-moltoxcast: 0.501206 val loss: 0.693057
[Epoch 1] ogbg-moltoxcast: 0.509942 test loss: 0.693054
[Epoch 2; Iter    11/  229] train: loss: 0.6930524
[Epoch 2; Iter    41/  229] train: loss: 0.6930988
[Epoch 2; Iter    71/  229] train: loss: 0.6931013
[Epoch 2; Iter   101/  229] train: loss: 0.6930381
[Epoch 2; Iter   131/  229] train: loss: 0.6930550
[Epoch 2; Iter   161/  229] train: loss: 0.6929770
[Epoch 2; Iter   191/  229] train: loss: 0.6929557
[Epoch 2; Iter   221/  229] train: loss: 0.6929542
[Epoch 2] ogbg-moltoxcast: 0.503132 val loss: 0.692918
[Epoch 2] ogbg-moltoxcast: 0.510113 test loss: 0.692932
[Epoch 3; Iter    22/  229] train: loss: 0.6928390
[Epoch 3; Iter    52/  229] train: loss: 0.6928915
[Epoch 3; Iter    82/  229] train: loss: 0.6928974
[Epoch 3; Iter   112/  229] train: loss: 0.6928214
[Epoch 3; Iter   142/  229] train: loss: 0.6927980
[Epoch 3; Iter   172/  229] train: loss: 0.6927325
[Epoch 3; Iter   202/  229] train: loss: 0.6927986
[Epoch 3] ogbg-moltoxcast: 0.503337 val loss: 0.692694
[Epoch 3] ogbg-moltoxcast: 0.509008 test loss: 0.692728
[Epoch 4; Iter     3/  229] train: loss: 0.6928788
[Epoch 4; Iter    33/  229] train: loss: 0.6901041
[Epoch 4; Iter    63/  229] train: loss: 0.6744521
[Epoch 4; Iter    93/  229] train: loss: 0.6292068
[Epoch 4; Iter   123/  229] train: loss: 0.5908689
[Epoch 4; Iter   153/  229] train: loss: 0.5394905
[Epoch 4; Iter   183/  229] train: loss: 0.5012987
[Epoch 4; Iter   213/  229] train: loss: 0.4347972
[Epoch 4] ogbg-moltoxcast: 0.583533 val loss: 0.527340
[Epoch 4] ogbg-moltoxcast: 0.554626 test loss: 0.551154
[Epoch 5; Iter    14/  229] train: loss: 0.4106595
[Epoch 5; Iter    44/  229] train: loss: 0.3131006
[Epoch 5; Iter    74/  229] train: loss: 0.3435227
[Epoch 5; Iter   104/  229] train: loss: 0.2776832
[Epoch 5; Iter   134/  229] train: loss: 0.2531861
[Epoch 5; Iter   164/  229] train: loss: 0.2095482
[Epoch 5; Iter   194/  229] train: loss: 0.2280537
[Epoch 5; Iter   224/  229] train: loss: 0.1577146
[Epoch 5] ogbg-moltoxcast: 0.621260 val loss: 0.280607
[Epoch 5] ogbg-moltoxcast: 0.591398 test loss: 0.314749
[Epoch 6; Iter    25/  229] train: loss: 0.2844442
[Epoch 6; Iter    55/  229] train: loss: 0.1939869
[Epoch 6; Iter    85/  229] train: loss: 0.1760120
[Epoch 6; Iter   115/  229] train: loss: 0.1952102
[Epoch 6; Iter   145/  229] train: loss: 0.2557704
[Epoch 6; Iter   175/  229] train: loss: 0.2210647
[Epoch 6; Iter   205/  229] train: loss: 0.1912959
[Epoch 6] ogbg-moltoxcast: 0.619717 val loss: 0.330902
[Epoch 6] ogbg-moltoxcast: 0.605554 test loss: 0.305000
[Epoch 7; Iter     6/  229] train: loss: 0.1711201
[Epoch 7; Iter    36/  229] train: loss: 0.1449659
[Epoch 7; Iter    66/  229] train: loss: 0.2177381
[Epoch 7; Iter    96/  229] train: loss: 0.2375477
[Epoch 7; Iter   126/  229] train: loss: 0.2781695
[Epoch 7; Iter   156/  229] train: loss: 0.1683366
[Epoch 7; Iter   186/  229] train: loss: 0.3428908
[Epoch 7; Iter   216/  229] train: loss: 0.1975360
[Epoch 7] ogbg-moltoxcast: 0.583513 val loss: 0.271364
[Epoch 7] ogbg-moltoxcast: 0.584080 test loss: 0.310245
[Epoch 8; Iter    17/  229] train: loss: 0.2308771
[Epoch 8; Iter    47/  229] train: loss: 0.1677667
[Epoch 8; Iter    77/  229] train: loss: 0.1826683
[Epoch 8; Iter   107/  229] train: loss: 0.2006824
[Epoch 8; Iter   137/  229] train: loss: 0.2190251
[Epoch 8; Iter   167/  229] train: loss: 0.1483873
[Epoch 8; Iter   197/  229] train: loss: 0.1972670
[Epoch 8; Iter   227/  229] train: loss: 0.1463623
[Epoch 8] ogbg-moltoxcast: 0.649885 val loss: 0.270206
[Epoch 8] ogbg-moltoxcast: 0.606202 test loss: 0.304148
[Epoch 9; Iter    28/  229] train: loss: 0.1597957
[Epoch 9; Iter    58/  229] train: loss: 0.1899338
[Epoch 9; Iter    88/  229] train: loss: 0.2077401
[Epoch 9; Iter   118/  229] train: loss: 0.1617757
[Epoch 9; Iter   148/  229] train: loss: 0.2148169
[Epoch 9; Iter   178/  229] train: loss: 0.1884713
[Epoch 9; Iter   208/  229] train: loss: 0.1938856
[Epoch 9] ogbg-moltoxcast: 0.649697 val loss: 0.336409
[Epoch 9] ogbg-moltoxcast: 0.628366 test loss: 0.601700
[Epoch 10; Iter     9/  229] train: loss: 0.1439960
[Epoch 10; Iter    39/  229] train: loss: 0.1202352
[Epoch 10; Iter    69/  229] train: loss: 0.2384914
[Epoch 10; Iter    99/  229] train: loss: 0.1499597
[Epoch 10; Iter   129/  229] train: loss: 0.1635785
[Epoch 10; Iter   159/  229] train: loss: 0.1696745
[Epoch 10; Iter   189/  229] train: loss: 0.2720908
[Epoch 10; Iter   219/  229] train: loss: 0.1605616
[Epoch 10] ogbg-moltoxcast: 0.655417 val loss: 0.263601
[Epoch 10] ogbg-moltoxcast: 0.638149 test loss: 0.303696
[Epoch 11; Iter    20/  229] train: loss: 0.1702254
[Epoch 11; Iter    50/  229] train: loss: 0.1676452
[Epoch 11; Iter    80/  229] train: loss: 0.1864584
[Epoch 11; Iter   110/  229] train: loss: 0.1822253
[Epoch 11; Iter   140/  229] train: loss: 0.2158639
[Epoch 11; Iter   170/  229] train: loss: 0.1386620
[Epoch 11; Iter   200/  229] train: loss: 0.2066491
[Epoch 11] ogbg-moltoxcast: 0.668707 val loss: 0.270609
[Epoch 11] ogbg-moltoxcast: 0.639256 test loss: 0.324879
[Epoch 12; Iter     1/  229] train: loss: 0.2084816
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.0/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.0_6_26-05_09-37-41
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.0
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931990
[Epoch 1; Iter    60/  229] train: loss: 0.6931769
[Epoch 1; Iter    90/  229] train: loss: 0.6931234
[Epoch 1; Iter   120/  229] train: loss: 0.6931630
[Epoch 1; Iter   150/  229] train: loss: 0.6931223
[Epoch 1; Iter   180/  229] train: loss: 0.6931464
[Epoch 1; Iter   210/  229] train: loss: 0.6931865
[Epoch 1] ogbg-moltoxcast: 0.500342 val loss: 0.693128
[Epoch 1] ogbg-moltoxcast: 0.501094 test loss: 0.693198
[Epoch 2; Iter    11/  229] train: loss: 0.6931514
[Epoch 2; Iter    41/  229] train: loss: 0.6931424
[Epoch 2; Iter    71/  229] train: loss: 0.6931203
[Epoch 2; Iter   101/  229] train: loss: 0.6930810
[Epoch 2; Iter   131/  229] train: loss: 0.6931149
[Epoch 2; Iter   161/  229] train: loss: 0.6930590
[Epoch 2; Iter   191/  229] train: loss: 0.6930009
[Epoch 2; Iter   221/  229] train: loss: 0.6930940
[Epoch 2] ogbg-moltoxcast: 0.499315 val loss: 0.692992
[Epoch 2] ogbg-moltoxcast: 0.499730 test loss: 0.693070
[Epoch 3; Iter    22/  229] train: loss: 0.6930192
[Epoch 3; Iter    52/  229] train: loss: 0.6928627
[Epoch 3; Iter    82/  229] train: loss: 0.6930284
[Epoch 3; Iter   112/  229] train: loss: 0.6928737
[Epoch 3; Iter   142/  229] train: loss: 0.6929584
[Epoch 3; Iter   172/  229] train: loss: 0.6928675
[Epoch 3; Iter   202/  229] train: loss: 0.6928354
[Epoch 3] ogbg-moltoxcast: 0.500357 val loss: 0.692828
[Epoch 3] ogbg-moltoxcast: 0.499211 test loss: 0.692920
[Epoch 4; Iter     3/  229] train: loss: 0.6928297
[Epoch 4; Iter    33/  229] train: loss: 0.6893287
[Epoch 4; Iter    63/  229] train: loss: 0.6754724
[Epoch 4; Iter    93/  229] train: loss: 0.6367443
[Epoch 4; Iter   123/  229] train: loss: 0.6319019
[Epoch 4; Iter   153/  229] train: loss: 0.5503996
[Epoch 4; Iter   183/  229] train: loss: 0.5637560
[Epoch 4; Iter   213/  229] train: loss: 0.4364411
[Epoch 4] ogbg-moltoxcast: 0.587679 val loss: 0.533462
[Epoch 4] ogbg-moltoxcast: 0.548748 test loss: 0.552674
[Epoch 5; Iter    14/  229] train: loss: 0.4367556
[Epoch 5; Iter    44/  229] train: loss: 0.3703630
[Epoch 5; Iter    74/  229] train: loss: 0.3196850
[Epoch 5; Iter   104/  229] train: loss: 0.3113112
[Epoch 5; Iter   134/  229] train: loss: 0.2936954
[Epoch 5; Iter   164/  229] train: loss: 0.2523015
[Epoch 5; Iter   194/  229] train: loss: 0.2533822
[Epoch 5; Iter   224/  229] train: loss: 0.3194701
[Epoch 5] ogbg-moltoxcast: 0.608778 val loss: 0.276554
[Epoch 5] ogbg-moltoxcast: 0.591518 test loss: 0.312403
[Epoch 6; Iter    25/  229] train: loss: 0.3062823
[Epoch 6; Iter    55/  229] train: loss: 0.1831358
[Epoch 6; Iter    85/  229] train: loss: 0.2405998
[Epoch 6; Iter   115/  229] train: loss: 0.2379148
[Epoch 6; Iter   145/  229] train: loss: 0.2161494
[Epoch 6; Iter   175/  229] train: loss: 0.1743811
[Epoch 6; Iter   205/  229] train: loss: 0.1421014
[Epoch 6] ogbg-moltoxcast: 0.637210 val loss: 0.301821
[Epoch 6] ogbg-moltoxcast: 0.615930 test loss: 0.309482
[Epoch 7; Iter     6/  229] train: loss: 0.1714376
[Epoch 7; Iter    36/  229] train: loss: 0.1497109
[Epoch 7; Iter    66/  229] train: loss: 0.1932446
[Epoch 7; Iter    96/  229] train: loss: 0.2713951
[Epoch 7; Iter   126/  229] train: loss: 0.1875435
[Epoch 7; Iter   156/  229] train: loss: 0.2266914
[Epoch 7; Iter   186/  229] train: loss: 0.1966444
[Epoch 7; Iter   216/  229] train: loss: 0.1987741
[Epoch 7] ogbg-moltoxcast: 0.589783 val loss: 0.383740
[Epoch 7] ogbg-moltoxcast: 0.570603 test loss: 0.536004
[Epoch 8; Iter    17/  229] train: loss: 0.1576000
[Epoch 8; Iter    47/  229] train: loss: 0.1801026
[Epoch 8; Iter    77/  229] train: loss: 0.1677228
[Epoch 8; Iter   107/  229] train: loss: 0.2247710
[Epoch 8; Iter   137/  229] train: loss: 0.2426333
[Epoch 8; Iter   167/  229] train: loss: 0.1950423
[Epoch 8; Iter   197/  229] train: loss: 0.2389660
[Epoch 8; Iter   227/  229] train: loss: 0.3861101
[Epoch 8] ogbg-moltoxcast: 0.670779 val loss: 0.597964
[Epoch 8] ogbg-moltoxcast: 0.635102 test loss: 1.098664
[Epoch 9; Iter    28/  229] train: loss: 0.1615864
[Epoch 9; Iter    58/  229] train: loss: 0.1378249
[Epoch 9; Iter    88/  229] train: loss: 0.1690536
[Epoch 9; Iter   118/  229] train: loss: 0.2334437
[Epoch 9; Iter   148/  229] train: loss: 0.3078712
[Epoch 9; Iter   178/  229] train: loss: 0.1536472
[Epoch 9; Iter   208/  229] train: loss: 0.2403599
[Epoch 9] ogbg-moltoxcast: 0.676267 val loss: 0.261137
[Epoch 9] ogbg-moltoxcast: 0.623733 test loss: 0.477997
[Epoch 10; Iter     9/  229] train: loss: 0.2207012
[Epoch 10; Iter    39/  229] train: loss: 0.1760369
[Epoch 10; Iter    69/  229] train: loss: 0.1571287
[Epoch 10; Iter    99/  229] train: loss: 0.1119093
[Epoch 10; Iter   129/  229] train: loss: 0.1666767
[Epoch 10; Iter   159/  229] train: loss: 0.2315529
[Epoch 10; Iter   189/  229] train: loss: 0.1916263
[Epoch 10; Iter   219/  229] train: loss: 0.2319539
[Epoch 10] ogbg-moltoxcast: 0.662164 val loss: 0.267484
[Epoch 10] ogbg-moltoxcast: 0.619454 test loss: 0.326196
[Epoch 11; Iter    20/  229] train: loss: 0.1537399
[Epoch 11; Iter    50/  229] train: loss: 0.1873964
[Epoch 11; Iter    80/  229] train: loss: 0.1419551
[Epoch 11; Iter   110/  229] train: loss: 0.1329388
[Epoch 11; Iter   140/  229] train: loss: 0.2204871
[Epoch 11; Iter   170/  229] train: loss: 0.2857477
[Epoch 11; Iter   200/  229] train: loss: 0.1415604
[Epoch 11] ogbg-moltoxcast: 0.659300 val loss: 0.258260
[Epoch 11] ogbg-moltoxcast: 0.635099 test loss: 0.300422
[Epoch 12; Iter     1/  229] train: loss: 0.2017725
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.05/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.05_5_26-05_09-39-53
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.05
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6930846
[Epoch 1; Iter    60/  229] train: loss: 0.6932163
[Epoch 1; Iter    90/  229] train: loss: 0.6931151
[Epoch 1; Iter   120/  229] train: loss: 0.6931114
[Epoch 1; Iter   150/  229] train: loss: 0.6931079
[Epoch 1; Iter   180/  229] train: loss: 0.6931252
[Epoch 1; Iter   210/  229] train: loss: 0.6931430
[Epoch 1] ogbg-moltoxcast: 0.506980 val loss: 0.693108
[Epoch 1] ogbg-moltoxcast: 0.511987 test loss: 0.693099
[Epoch 2; Iter    11/  229] train: loss: 0.6930649
[Epoch 2; Iter    41/  229] train: loss: 0.6930853
[Epoch 2; Iter    71/  229] train: loss: 0.6930922
[Epoch 2; Iter   101/  229] train: loss: 0.6930208
[Epoch 2; Iter   131/  229] train: loss: 0.6930513
[Epoch 2; Iter   161/  229] train: loss: 0.6929774
[Epoch 2; Iter   191/  229] train: loss: 0.6929703
[Epoch 2; Iter   221/  229] train: loss: 0.6929227
[Epoch 2] ogbg-moltoxcast: 0.504236 val loss: 0.692974
[Epoch 2] ogbg-moltoxcast: 0.512161 test loss: 0.692980
[Epoch 3; Iter    22/  229] train: loss: 0.6928613
[Epoch 3; Iter    52/  229] train: loss: 0.6928928
[Epoch 3; Iter    82/  229] train: loss: 0.6928934
[Epoch 3; Iter   112/  229] train: loss: 0.6927817
[Epoch 3; Iter   142/  229] train: loss: 0.6928377
[Epoch 3; Iter   172/  229] train: loss: 0.6927853
[Epoch 3; Iter   202/  229] train: loss: 0.6928093
[Epoch 3] ogbg-moltoxcast: 0.505817 val loss: 0.692747
[Epoch 3] ogbg-moltoxcast: 0.510741 test loss: 0.692775
[Epoch 4; Iter     3/  229] train: loss: 0.6929051
[Epoch 4; Iter    33/  229] train: loss: 0.6900000
[Epoch 4; Iter    63/  229] train: loss: 0.6753187
[Epoch 4; Iter    93/  229] train: loss: 0.6300929
[Epoch 4; Iter   123/  229] train: loss: 0.5922675
[Epoch 4; Iter   153/  229] train: loss: 0.5529457
[Epoch 4; Iter   183/  229] train: loss: 0.4975493
[Epoch 4; Iter   213/  229] train: loss: 0.4434481
[Epoch 4] ogbg-moltoxcast: 0.586857 val loss: 0.512711
[Epoch 4] ogbg-moltoxcast: 0.552890 test loss: 0.533756
[Epoch 5; Iter    14/  229] train: loss: 0.4112934
[Epoch 5; Iter    44/  229] train: loss: 0.3192021
[Epoch 5; Iter    74/  229] train: loss: 0.3448634
[Epoch 5; Iter   104/  229] train: loss: 0.2820354
[Epoch 5; Iter   134/  229] train: loss: 0.2470165
[Epoch 5; Iter   164/  229] train: loss: 0.2138219
[Epoch 5; Iter   194/  229] train: loss: 0.2290738
[Epoch 5; Iter   224/  229] train: loss: 0.1590215
[Epoch 5] ogbg-moltoxcast: 0.622478 val loss: 0.283039
[Epoch 5] ogbg-moltoxcast: 0.604762 test loss: 0.316508
[Epoch 6; Iter    25/  229] train: loss: 0.2818095
[Epoch 6; Iter    55/  229] train: loss: 0.1997105
[Epoch 6; Iter    85/  229] train: loss: 0.1791465
[Epoch 6; Iter   115/  229] train: loss: 0.1972245
[Epoch 6; Iter   145/  229] train: loss: 0.2610034
[Epoch 6; Iter   175/  229] train: loss: 0.2175490
[Epoch 6; Iter   205/  229] train: loss: 0.1959874
[Epoch 6] ogbg-moltoxcast: 0.637173 val loss: 0.274901
[Epoch 6] ogbg-moltoxcast: 0.626247 test loss: 0.306844
[Epoch 7; Iter     6/  229] train: loss: 0.1733112
[Epoch 7; Iter    36/  229] train: loss: 0.1438661
[Epoch 7; Iter    66/  229] train: loss: 0.2422828
[Epoch 7; Iter    96/  229] train: loss: 0.2487001
[Epoch 7; Iter   126/  229] train: loss: 0.2589636
[Epoch 7; Iter   156/  229] train: loss: 0.1564174
[Epoch 7; Iter   186/  229] train: loss: 0.3453392
[Epoch 7; Iter   216/  229] train: loss: 0.1840551
[Epoch 7] ogbg-moltoxcast: 0.616967 val loss: 0.276079
[Epoch 7] ogbg-moltoxcast: 0.593103 test loss: 0.329412
[Epoch 8; Iter    17/  229] train: loss: 0.2407987
[Epoch 8; Iter    47/  229] train: loss: 0.1710144
[Epoch 8; Iter    77/  229] train: loss: 0.1836629
[Epoch 8; Iter   107/  229] train: loss: 0.2104454
[Epoch 8; Iter   137/  229] train: loss: 0.2613257
[Epoch 8; Iter   167/  229] train: loss: 0.1635418
[Epoch 8; Iter   197/  229] train: loss: 0.1962468
[Epoch 8; Iter   227/  229] train: loss: 0.1554762
[Epoch 8] ogbg-moltoxcast: 0.647572 val loss: 0.262160
[Epoch 8] ogbg-moltoxcast: 0.598879 test loss: 0.300693
[Epoch 9; Iter    28/  229] train: loss: 0.1641783
[Epoch 9; Iter    58/  229] train: loss: 0.2010980
[Epoch 9; Iter    88/  229] train: loss: 0.2110772
[Epoch 9; Iter   118/  229] train: loss: 0.1632270
[Epoch 9; Iter   148/  229] train: loss: 0.2238197
[Epoch 9; Iter   178/  229] train: loss: 0.1882784
[Epoch 9; Iter   208/  229] train: loss: 0.1910888
[Epoch 9] ogbg-moltoxcast: 0.655072 val loss: 0.272566
[Epoch 9] ogbg-moltoxcast: 0.625364 test loss: 0.309367
[Epoch 10; Iter     9/  229] train: loss: 0.1581851
[Epoch 10; Iter    39/  229] train: loss: 0.1153110
[Epoch 10; Iter    69/  229] train: loss: 0.2541219
[Epoch 10; Iter    99/  229] train: loss: 0.1628535
[Epoch 10; Iter   129/  229] train: loss: 0.1642978
[Epoch 10; Iter   159/  229] train: loss: 0.1654078
[Epoch 10; Iter   189/  229] train: loss: 0.2728175
[Epoch 10; Iter   219/  229] train: loss: 0.1713757
[Epoch 10] ogbg-moltoxcast: 0.644865 val loss: 0.270902
[Epoch 10] ogbg-moltoxcast: 0.625854 test loss: 0.305881
[Epoch 11; Iter    20/  229] train: loss: 0.1803662
[Epoch 11; Iter    50/  229] train: loss: 0.1677240
[Epoch 11; Iter    80/  229] train: loss: 0.1649198
[Epoch 11; Iter   110/  229] train: loss: 0.1884170
[Epoch 11; Iter   140/  229] train: loss: 0.2356480
[Epoch 11; Iter   170/  229] train: loss: 0.1302698
[Epoch 11; Iter   200/  229] train: loss: 0.2177838
[Epoch 11] ogbg-moltoxcast: 0.667857 val loss: 0.269957
[Epoch 11] ogbg-moltoxcast: 0.618196 test loss: 0.319704
[Epoch 12; Iter     1/  229] train: loss: 0.2158448
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.05/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.05_6_26-05_09-39-53
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.05
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6932778
[Epoch 1; Iter    60/  229] train: loss: 0.6932057
[Epoch 1; Iter    90/  229] train: loss: 0.6931524
[Epoch 1; Iter   120/  229] train: loss: 0.6931528
[Epoch 1; Iter   150/  229] train: loss: 0.6931279
[Epoch 1; Iter   180/  229] train: loss: 0.6931341
[Epoch 1; Iter   210/  229] train: loss: 0.6931431
[Epoch 1] ogbg-moltoxcast: 0.495720 val loss: 0.692969
[Epoch 1] ogbg-moltoxcast: 0.495653 test loss: 0.693021
[Epoch 2; Iter    11/  229] train: loss: 0.6931595
[Epoch 2; Iter    41/  229] train: loss: 0.6931573
[Epoch 2; Iter    71/  229] train: loss: 0.6931496
[Epoch 2; Iter   101/  229] train: loss: 0.6930642
[Epoch 2; Iter   131/  229] train: loss: 0.6930538
[Epoch 2; Iter   161/  229] train: loss: 0.6930624
[Epoch 2; Iter   191/  229] train: loss: 0.6930012
[Epoch 2; Iter   221/  229] train: loss: 0.6930616
[Epoch 2] ogbg-moltoxcast: 0.494412 val loss: 0.692843
[Epoch 2] ogbg-moltoxcast: 0.495688 test loss: 0.692905
[Epoch 3; Iter    22/  229] train: loss: 0.6929646
[Epoch 3; Iter    52/  229] train: loss: 0.6929024
[Epoch 3; Iter    82/  229] train: loss: 0.6930782
[Epoch 3; Iter   112/  229] train: loss: 0.6929438
[Epoch 3; Iter   142/  229] train: loss: 0.6929462
[Epoch 3; Iter   172/  229] train: loss: 0.6928180
[Epoch 3; Iter   202/  229] train: loss: 0.6928506
[Epoch 3] ogbg-moltoxcast: 0.495727 val loss: 0.692684
[Epoch 3] ogbg-moltoxcast: 0.496108 test loss: 0.692760
[Epoch 4; Iter     3/  229] train: loss: 0.6927921
[Epoch 4; Iter    33/  229] train: loss: 0.6892502
[Epoch 4; Iter    63/  229] train: loss: 0.6760275
[Epoch 4; Iter    93/  229] train: loss: 0.6362644
[Epoch 4; Iter   123/  229] train: loss: 0.6288342
[Epoch 4; Iter   153/  229] train: loss: 0.5463803
[Epoch 4; Iter   183/  229] train: loss: 0.5977332
[Epoch 4; Iter   213/  229] train: loss: 0.4528039
[Epoch 4] ogbg-moltoxcast: 0.602928 val loss: 0.521662
[Epoch 4] ogbg-moltoxcast: 0.557105 test loss: 0.549378
[Epoch 5; Iter    14/  229] train: loss: 0.4496872
[Epoch 5; Iter    44/  229] train: loss: 0.3619713
[Epoch 5; Iter    74/  229] train: loss: 0.3230772
[Epoch 5; Iter   104/  229] train: loss: 0.3105749
[Epoch 5; Iter   134/  229] train: loss: 0.2973355
[Epoch 5; Iter   164/  229] train: loss: 0.2454606
[Epoch 5; Iter   194/  229] train: loss: 0.2666782
[Epoch 5; Iter   224/  229] train: loss: 0.3171652
[Epoch 5] ogbg-moltoxcast: 0.611335 val loss: 0.274650
[Epoch 5] ogbg-moltoxcast: 0.593565 test loss: 0.322672
[Epoch 6; Iter    25/  229] train: loss: 0.3140289
[Epoch 6; Iter    55/  229] train: loss: 0.1830378
[Epoch 6; Iter    85/  229] train: loss: 0.2451281
[Epoch 6; Iter   115/  229] train: loss: 0.2524112
[Epoch 6; Iter   145/  229] train: loss: 0.2125705
[Epoch 6; Iter   175/  229] train: loss: 0.1838368
[Epoch 6; Iter   205/  229] train: loss: 0.1508477
[Epoch 6] ogbg-moltoxcast: 0.635059 val loss: 0.269351
[Epoch 6] ogbg-moltoxcast: 0.616502 test loss: 0.343848
[Epoch 7; Iter     6/  229] train: loss: 0.1705402
[Epoch 7; Iter    36/  229] train: loss: 0.1569475
[Epoch 7; Iter    66/  229] train: loss: 0.1991297
[Epoch 7; Iter    96/  229] train: loss: 0.2612190
[Epoch 7; Iter   126/  229] train: loss: 0.1955656
[Epoch 7; Iter   156/  229] train: loss: 0.2421917
[Epoch 7; Iter   186/  229] train: loss: 0.1959943
[Epoch 7; Iter   216/  229] train: loss: 0.1993075
[Epoch 7] ogbg-moltoxcast: 0.619633 val loss: 0.277844
[Epoch 7] ogbg-moltoxcast: 0.598115 test loss: 0.367989
[Epoch 8; Iter    17/  229] train: loss: 0.1625030
[Epoch 8; Iter    47/  229] train: loss: 0.1854183
[Epoch 8; Iter    77/  229] train: loss: 0.1684839
[Epoch 8; Iter   107/  229] train: loss: 0.2196241
[Epoch 8; Iter   137/  229] train: loss: 0.2404193
[Epoch 8; Iter   167/  229] train: loss: 0.2024318
[Epoch 8; Iter   197/  229] train: loss: 0.2332114
[Epoch 8; Iter   227/  229] train: loss: 0.3992321
[Epoch 8] ogbg-moltoxcast: 0.661453 val loss: 0.263400
[Epoch 8] ogbg-moltoxcast: 0.614573 test loss: 0.368500
[Epoch 9; Iter    28/  229] train: loss: 0.1637705
[Epoch 9; Iter    58/  229] train: loss: 0.1384625
[Epoch 9; Iter    88/  229] train: loss: 0.1868083
[Epoch 9; Iter   118/  229] train: loss: 0.2310271
[Epoch 9; Iter   148/  229] train: loss: 0.3057493
[Epoch 9; Iter   178/  229] train: loss: 0.1518794
[Epoch 9; Iter   208/  229] train: loss: 0.2607872
[Epoch 9] ogbg-moltoxcast: 0.655988 val loss: 0.270769
[Epoch 9] ogbg-moltoxcast: 0.625160 test loss: 0.309453
[Epoch 10; Iter     9/  229] train: loss: 0.2220121
[Epoch 10; Iter    39/  229] train: loss: 0.1922182
[Epoch 10; Iter    69/  229] train: loss: 0.1526028
[Epoch 10; Iter    99/  229] train: loss: 0.1146146
[Epoch 10; Iter   129/  229] train: loss: 0.1840159
[Epoch 10; Iter   159/  229] train: loss: 0.2486559
[Epoch 10; Iter   189/  229] train: loss: 0.2005979
[Epoch 10; Iter   219/  229] train: loss: 0.2285677
[Epoch 10] ogbg-moltoxcast: 0.651649 val loss: 0.263086
[Epoch 10] ogbg-moltoxcast: 0.623501 test loss: 0.306896
[Epoch 11; Iter    20/  229] train: loss: 0.1578595
[Epoch 11; Iter    50/  229] train: loss: 0.1847660
[Epoch 11; Iter    80/  229] train: loss: 0.1578047
[Epoch 11; Iter   110/  229] train: loss: 0.1224452
[Epoch 11; Iter   140/  229] train: loss: 0.2152083
[Epoch 11; Iter   170/  229] train: loss: 0.2887249
[Epoch 11; Iter   200/  229] train: loss: 0.1420863
[Epoch 11] ogbg-moltoxcast: 0.669133 val loss: 0.268373
[Epoch 11] ogbg-moltoxcast: 0.630044 test loss: 0.314837
[Epoch 12; Iter     1/  229] train: loss: 0.2268500
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.05/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.05_4_26-05_09-39-51
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.05
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931697
[Epoch 1; Iter    60/  229] train: loss: 0.6932039
[Epoch 1; Iter    90/  229] train: loss: 0.6931326
[Epoch 1; Iter   120/  229] train: loss: 0.6931375
[Epoch 1; Iter   150/  229] train: loss: 0.6931158
[Epoch 1; Iter   180/  229] train: loss: 0.6931309
[Epoch 1; Iter   210/  229] train: loss: 0.6931423
[Epoch 1] ogbg-moltoxcast: 0.497157 val loss: 0.693117
[Epoch 1] ogbg-moltoxcast: 0.500821 test loss: 0.693116
[Epoch 2; Iter    11/  229] train: loss: 0.6931588
[Epoch 2; Iter    41/  229] train: loss: 0.6930832
[Epoch 2; Iter    71/  229] train: loss: 0.6930627
[Epoch 2; Iter   101/  229] train: loss: 0.6930723
[Epoch 2; Iter   131/  229] train: loss: 0.6930347
[Epoch 2; Iter   161/  229] train: loss: 0.6931051
[Epoch 2; Iter   191/  229] train: loss: 0.6930641
[Epoch 2; Iter   221/  229] train: loss: 0.6930077
[Epoch 2] ogbg-moltoxcast: 0.495318 val loss: 0.693008
[Epoch 2] ogbg-moltoxcast: 0.499590 test loss: 0.693020
[Epoch 3; Iter    22/  229] train: loss: 0.6930690
[Epoch 3; Iter    52/  229] train: loss: 0.6930039
[Epoch 3; Iter    82/  229] train: loss: 0.6929442
[Epoch 3; Iter   112/  229] train: loss: 0.6929523
[Epoch 3; Iter   142/  229] train: loss: 0.6929263
[Epoch 3; Iter   172/  229] train: loss: 0.6928925
[Epoch 3; Iter   202/  229] train: loss: 0.6929229
[Epoch 3] ogbg-moltoxcast: 0.496543 val loss: 0.692857
[Epoch 3] ogbg-moltoxcast: 0.500854 test loss: 0.692879
[Epoch 4; Iter     3/  229] train: loss: 0.6928217
[Epoch 4; Iter    33/  229] train: loss: 0.6903039
[Epoch 4; Iter    63/  229] train: loss: 0.6783589
[Epoch 4; Iter    93/  229] train: loss: 0.6619617
[Epoch 4; Iter   123/  229] train: loss: 0.6126842
[Epoch 4; Iter   153/  229] train: loss: 0.5855728
[Epoch 4; Iter   183/  229] train: loss: 0.5284735
[Epoch 4; Iter   213/  229] train: loss: 0.4533756
[Epoch 4] ogbg-moltoxcast: 0.607321 val loss: 0.462021
[Epoch 4] ogbg-moltoxcast: 0.572154 test loss: 0.491281
[Epoch 5; Iter    14/  229] train: loss: 0.4322245
[Epoch 5; Iter    44/  229] train: loss: 0.3531272
[Epoch 5; Iter    74/  229] train: loss: 0.2886881
[Epoch 5; Iter   104/  229] train: loss: 0.3226929
[Epoch 5; Iter   134/  229] train: loss: 0.3116656
[Epoch 5; Iter   164/  229] train: loss: 0.2468886
[Epoch 5; Iter   194/  229] train: loss: 0.2462261
[Epoch 5; Iter   224/  229] train: loss: 0.1710888
[Epoch 5] ogbg-moltoxcast: 0.626195 val loss: 0.294824
[Epoch 5] ogbg-moltoxcast: 0.591990 test loss: 0.463871
[Epoch 6; Iter    25/  229] train: loss: 0.2598167
[Epoch 6; Iter    55/  229] train: loss: 0.2098801
[Epoch 6; Iter    85/  229] train: loss: 0.3162989
[Epoch 6; Iter   115/  229] train: loss: 0.2185023
[Epoch 6; Iter   145/  229] train: loss: 0.2203907
[Epoch 6; Iter   175/  229] train: loss: 0.1948181
[Epoch 6; Iter   205/  229] train: loss: 0.1862795
[Epoch 6] ogbg-moltoxcast: 0.634383 val loss: 0.275165
[Epoch 6] ogbg-moltoxcast: 0.614247 test loss: 0.468444
[Epoch 7; Iter     6/  229] train: loss: 0.1211883
[Epoch 7; Iter    36/  229] train: loss: 0.2335485
[Epoch 7; Iter    66/  229] train: loss: 0.2126552
[Epoch 7; Iter    96/  229] train: loss: 0.1771870
[Epoch 7; Iter   126/  229] train: loss: 0.2696652
[Epoch 7; Iter   156/  229] train: loss: 0.1885466
[Epoch 7; Iter   186/  229] train: loss: 0.2956288
[Epoch 7; Iter   216/  229] train: loss: 0.2121108
[Epoch 7] ogbg-moltoxcast: 0.623873 val loss: 0.294924
[Epoch 7] ogbg-moltoxcast: 0.585935 test loss: 0.396047
[Epoch 8; Iter    17/  229] train: loss: 0.1662415
[Epoch 8; Iter    47/  229] train: loss: 0.3135017
[Epoch 8; Iter    77/  229] train: loss: 0.1853459
[Epoch 8; Iter   107/  229] train: loss: 0.2388788
[Epoch 8; Iter   137/  229] train: loss: 0.1855705
[Epoch 8; Iter   167/  229] train: loss: 0.1731120
[Epoch 8; Iter   197/  229] train: loss: 0.2383949
[Epoch 8; Iter   227/  229] train: loss: 0.2123769
[Epoch 8] ogbg-moltoxcast: 0.655495 val loss: 0.278882
[Epoch 8] ogbg-moltoxcast: 0.615472 test loss: 0.431200
[Epoch 9; Iter    28/  229] train: loss: 0.1391412
[Epoch 9; Iter    58/  229] train: loss: 0.1295222
[Epoch 9; Iter    88/  229] train: loss: 0.2087207
[Epoch 9; Iter   118/  229] train: loss: 0.1126012
[Epoch 9; Iter   148/  229] train: loss: 0.2558886
[Epoch 9; Iter   178/  229] train: loss: 0.2045061
[Epoch 9; Iter   208/  229] train: loss: 0.1876888
[Epoch 9] ogbg-moltoxcast: 0.642627 val loss: 0.268999
[Epoch 9] ogbg-moltoxcast: 0.616286 test loss: 0.303484
[Epoch 10; Iter     9/  229] train: loss: 0.1497138
[Epoch 10; Iter    39/  229] train: loss: 0.1480719
[Epoch 10; Iter    69/  229] train: loss: 0.2500840
[Epoch 10; Iter    99/  229] train: loss: 0.2620054
[Epoch 10; Iter   129/  229] train: loss: 0.1776482
[Epoch 10; Iter   159/  229] train: loss: 0.2311424
[Epoch 10; Iter   189/  229] train: loss: 0.2308104
[Epoch 10; Iter   219/  229] train: loss: 0.2628571
[Epoch 10] ogbg-moltoxcast: 0.658870 val loss: 0.265062
[Epoch 10] ogbg-moltoxcast: 0.624871 test loss: 0.313002
[Epoch 11; Iter    20/  229] train: loss: 0.1669144
[Epoch 11; Iter    50/  229] train: loss: 0.1967112
[Epoch 11; Iter    80/  229] train: loss: 0.1641558
[Epoch 11; Iter   110/  229] train: loss: 0.1595835
[Epoch 11; Iter   140/  229] train: loss: 0.2684575
[Epoch 11; Iter   170/  229] train: loss: 0.2169311
[Epoch 11; Iter   200/  229] train: loss: 0.2816268
[Epoch 11] ogbg-moltoxcast: 0.651214 val loss: 0.258103
[Epoch 11] ogbg-moltoxcast: 0.614222 test loss: 0.303255
[Epoch 12; Iter     1/  229] train: loss: 0.1624372
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.1/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.1_6_26-05_09-40-18
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.1
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6932636
[Epoch 1; Iter    60/  229] train: loss: 0.6931638
[Epoch 1; Iter    90/  229] train: loss: 0.6931655
[Epoch 1; Iter   120/  229] train: loss: 0.6931537
[Epoch 1; Iter   150/  229] train: loss: 0.6931511
[Epoch 1; Iter   180/  229] train: loss: 0.6931421
[Epoch 1; Iter   210/  229] train: loss: 0.6930930
[Epoch 1] ogbg-moltoxcast: 0.495437 val loss: 0.692865
[Epoch 1] ogbg-moltoxcast: 0.494264 test loss: 0.692911
[Epoch 2; Iter    11/  229] train: loss: 0.6931643
[Epoch 2; Iter    41/  229] train: loss: 0.6931354
[Epoch 2; Iter    71/  229] train: loss: 0.6931031
[Epoch 2; Iter   101/  229] train: loss: 0.6930938
[Epoch 2; Iter   131/  229] train: loss: 0.6930922
[Epoch 2; Iter   161/  229] train: loss: 0.6930296
[Epoch 2; Iter   191/  229] train: loss: 0.6930317
[Epoch 2; Iter   221/  229] train: loss: 0.6930246
[Epoch 2] ogbg-moltoxcast: 0.494573 val loss: 0.692731
[Epoch 2] ogbg-moltoxcast: 0.494035 test loss: 0.692787
[Epoch 3; Iter    22/  229] train: loss: 0.6930662
[Epoch 3; Iter    52/  229] train: loss: 0.6928700
[Epoch 3; Iter    82/  229] train: loss: 0.6930354
[Epoch 3; Iter   112/  229] train: loss: 0.6929349
[Epoch 3; Iter   142/  229] train: loss: 0.6930054
[Epoch 3; Iter   172/  229] train: loss: 0.6928402
[Epoch 3; Iter   202/  229] train: loss: 0.6928301
[Epoch 3] ogbg-moltoxcast: 0.495526 val loss: 0.692572
[Epoch 3] ogbg-moltoxcast: 0.495707 test loss: 0.692639
[Epoch 4; Iter     3/  229] train: loss: 0.6928202
[Epoch 4; Iter    33/  229] train: loss: 0.6893116
[Epoch 4; Iter    63/  229] train: loss: 0.6749849
[Epoch 4; Iter    93/  229] train: loss: 0.6371176
[Epoch 4; Iter   123/  229] train: loss: 0.6383118
[Epoch 4; Iter   153/  229] train: loss: 0.5393400
[Epoch 4; Iter   183/  229] train: loss: 0.5634821
[Epoch 4; Iter   213/  229] train: loss: 0.4424679
[Epoch 4] ogbg-moltoxcast: 0.610974 val loss: 0.577741
[Epoch 4] ogbg-moltoxcast: 0.576340 test loss: 0.600444
[Epoch 5; Iter    14/  229] train: loss: 0.4420032
[Epoch 5; Iter    44/  229] train: loss: 0.3516459
[Epoch 5; Iter    74/  229] train: loss: 0.3239010
[Epoch 5; Iter   104/  229] train: loss: 0.3090635
[Epoch 5; Iter   134/  229] train: loss: 0.2927342
[Epoch 5; Iter   164/  229] train: loss: 0.2471558
[Epoch 5; Iter   194/  229] train: loss: 0.2639739
[Epoch 5; Iter   224/  229] train: loss: 0.3105842
[Epoch 5] ogbg-moltoxcast: 0.629494 val loss: 0.309502
[Epoch 5] ogbg-moltoxcast: 0.605534 test loss: 0.330272
[Epoch 6; Iter    25/  229] train: loss: 0.3165622
[Epoch 6; Iter    55/  229] train: loss: 0.1804307
[Epoch 6; Iter    85/  229] train: loss: 0.2476320
[Epoch 6; Iter   115/  229] train: loss: 0.2445545
[Epoch 6; Iter   145/  229] train: loss: 0.2098470
[Epoch 6; Iter   175/  229] train: loss: 0.1814199
[Epoch 6; Iter   205/  229] train: loss: 0.1503696
[Epoch 6] ogbg-moltoxcast: 0.639087 val loss: 0.303008
[Epoch 6] ogbg-moltoxcast: 0.616004 test loss: 0.327344
[Epoch 7; Iter     6/  229] train: loss: 0.1715193
[Epoch 7; Iter    36/  229] train: loss: 0.1606985
[Epoch 7; Iter    66/  229] train: loss: 0.2045166
[Epoch 7; Iter    96/  229] train: loss: 0.2767620
[Epoch 7; Iter   126/  229] train: loss: 0.2169655
[Epoch 7; Iter   156/  229] train: loss: 0.2379686
[Epoch 7; Iter   186/  229] train: loss: 0.1989815
[Epoch 7; Iter   216/  229] train: loss: 0.2006772
[Epoch 7] ogbg-moltoxcast: 0.619334 val loss: 0.384942
[Epoch 7] ogbg-moltoxcast: 0.603912 test loss: 0.450187
[Epoch 8; Iter    17/  229] train: loss: 0.1657772
[Epoch 8; Iter    47/  229] train: loss: 0.1873576
[Epoch 8; Iter    77/  229] train: loss: 0.1875990
[Epoch 8; Iter   107/  229] train: loss: 0.2297387
[Epoch 8; Iter   137/  229] train: loss: 0.2304568
[Epoch 8; Iter   167/  229] train: loss: 0.1996100
[Epoch 8; Iter   197/  229] train: loss: 0.2436075
[Epoch 8; Iter   227/  229] train: loss: 0.3896784
[Epoch 8] ogbg-moltoxcast: 0.640349 val loss: 0.375452
[Epoch 8] ogbg-moltoxcast: 0.604236 test loss: 0.720800
[Epoch 9; Iter    28/  229] train: loss: 0.1637832
[Epoch 9; Iter    58/  229] train: loss: 0.1425521
[Epoch 9; Iter    88/  229] train: loss: 0.1632387
[Epoch 9; Iter   118/  229] train: loss: 0.2525003
[Epoch 9; Iter   148/  229] train: loss: 0.3046738
[Epoch 9; Iter   178/  229] train: loss: 0.1558346
[Epoch 9; Iter   208/  229] train: loss: 0.2445403
[Epoch 9] ogbg-moltoxcast: 0.641488 val loss: 0.276644
[Epoch 9] ogbg-moltoxcast: 0.612559 test loss: 0.309821
[Epoch 10; Iter     9/  229] train: loss: 0.2219395
[Epoch 10; Iter    39/  229] train: loss: 0.1752361
[Epoch 10; Iter    69/  229] train: loss: 0.1481300
[Epoch 10; Iter    99/  229] train: loss: 0.1146186
[Epoch 10; Iter   129/  229] train: loss: 0.1780246
[Epoch 10; Iter   159/  229] train: loss: 0.2420168
[Epoch 10; Iter   189/  229] train: loss: 0.1921150
[Epoch 10; Iter   219/  229] train: loss: 0.2276944
[Epoch 10] ogbg-moltoxcast: 0.647369 val loss: 0.273616
[Epoch 10] ogbg-moltoxcast: 0.616166 test loss: 0.348646
[Epoch 11; Iter    20/  229] train: loss: 0.1501433
[Epoch 11; Iter    50/  229] train: loss: 0.1844803
[Epoch 11; Iter    80/  229] train: loss: 0.1552516
[Epoch 11; Iter   110/  229] train: loss: 0.1282854
[Epoch 11; Iter   140/  229] train: loss: 0.2214144
[Epoch 11; Iter   170/  229] train: loss: 0.2985473
[Epoch 11; Iter   200/  229] train: loss: 0.1488698
[Epoch 11] ogbg-moltoxcast: 0.652386 val loss: 0.285106
[Epoch 11] ogbg-moltoxcast: 0.604788 test loss: 0.376527
[Epoch 12; Iter     1/  229] train: loss: 0.2280935
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.1/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.1_5_26-05_09-40-17
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.1
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6930761
[Epoch 1; Iter    60/  229] train: loss: 0.6932036
[Epoch 1; Iter    90/  229] train: loss: 0.6930834
[Epoch 1; Iter   120/  229] train: loss: 0.6931856
[Epoch 1; Iter   150/  229] train: loss: 0.6930756
[Epoch 1; Iter   180/  229] train: loss: 0.6931220
[Epoch 1; Iter   210/  229] train: loss: 0.6931016
[Epoch 1] ogbg-moltoxcast: 0.509122 val loss: 0.693177
[Epoch 1] ogbg-moltoxcast: 0.509769 test loss: 0.693157
[Epoch 2; Iter    11/  229] train: loss: 0.6930825
[Epoch 2; Iter    41/  229] train: loss: 0.6931063
[Epoch 2; Iter    71/  229] train: loss: 0.6930997
[Epoch 2; Iter   101/  229] train: loss: 0.6930277
[Epoch 2; Iter   131/  229] train: loss: 0.6930144
[Epoch 2; Iter   161/  229] train: loss: 0.6929622
[Epoch 2; Iter   191/  229] train: loss: 0.6929717
[Epoch 2; Iter   221/  229] train: loss: 0.6929231
[Epoch 2] ogbg-moltoxcast: 0.506369 val loss: 0.693019
[Epoch 2] ogbg-moltoxcast: 0.510500 test loss: 0.693018
[Epoch 3; Iter    22/  229] train: loss: 0.6928821
[Epoch 3; Iter    52/  229] train: loss: 0.6928726
[Epoch 3; Iter    82/  229] train: loss: 0.6929443
[Epoch 3; Iter   112/  229] train: loss: 0.6928094
[Epoch 3; Iter   142/  229] train: loss: 0.6928306
[Epoch 3; Iter   172/  229] train: loss: 0.6927739
[Epoch 3; Iter   202/  229] train: loss: 0.6928119
[Epoch 3] ogbg-moltoxcast: 0.509257 val loss: 0.692816
[Epoch 3] ogbg-moltoxcast: 0.510239 test loss: 0.692835
[Epoch 4; Iter     3/  229] train: loss: 0.6928665
[Epoch 4; Iter    33/  229] train: loss: 0.6900644
[Epoch 4; Iter    63/  229] train: loss: 0.6745998
[Epoch 4; Iter    93/  229] train: loss: 0.6271089
[Epoch 4; Iter   123/  229] train: loss: 0.5865709
[Epoch 4; Iter   153/  229] train: loss: 0.5566016
[Epoch 4; Iter   183/  229] train: loss: 0.5024316
[Epoch 4; Iter   213/  229] train: loss: 0.4416526
[Epoch 4] ogbg-moltoxcast: 0.593109 val loss: 0.497815
[Epoch 4] ogbg-moltoxcast: 0.550047 test loss: 0.516246
[Epoch 5; Iter    14/  229] train: loss: 0.4098891
[Epoch 5; Iter    44/  229] train: loss: 0.3194866
[Epoch 5; Iter    74/  229] train: loss: 0.3386305
[Epoch 5; Iter   104/  229] train: loss: 0.2828014
[Epoch 5; Iter   134/  229] train: loss: 0.2548233
[Epoch 5; Iter   164/  229] train: loss: 0.2095830
[Epoch 5; Iter   194/  229] train: loss: 0.2282085
[Epoch 5; Iter   224/  229] train: loss: 0.1604513
[Epoch 5] ogbg-moltoxcast: 0.622046 val loss: 0.325310
[Epoch 5] ogbg-moltoxcast: 0.591186 test loss: 0.410293
[Epoch 6; Iter    25/  229] train: loss: 0.2882119
[Epoch 6; Iter    55/  229] train: loss: 0.2135706
[Epoch 6; Iter    85/  229] train: loss: 0.1840155
[Epoch 6; Iter   115/  229] train: loss: 0.2005226
[Epoch 6; Iter   145/  229] train: loss: 0.2662826
[Epoch 6; Iter   175/  229] train: loss: 0.2253502
[Epoch 6; Iter   205/  229] train: loss: 0.1941038
[Epoch 6] ogbg-moltoxcast: 0.626834 val loss: 0.295851
[Epoch 6] ogbg-moltoxcast: 0.595707 test loss: 0.381008
[Epoch 7; Iter     6/  229] train: loss: 0.1809055
[Epoch 7; Iter    36/  229] train: loss: 0.1464702
[Epoch 7; Iter    66/  229] train: loss: 0.2584019
[Epoch 7; Iter    96/  229] train: loss: 0.2412628
[Epoch 7; Iter   126/  229] train: loss: 0.2546038
[Epoch 7; Iter   156/  229] train: loss: 0.1592143
[Epoch 7; Iter   186/  229] train: loss: 0.3511144
[Epoch 7; Iter   216/  229] train: loss: 0.1929300
[Epoch 7] ogbg-moltoxcast: 0.609633 val loss: 0.281893
[Epoch 7] ogbg-moltoxcast: 0.577347 test loss: 0.372358
[Epoch 8; Iter    17/  229] train: loss: 0.2350378
[Epoch 8; Iter    47/  229] train: loss: 0.1689277
[Epoch 8; Iter    77/  229] train: loss: 0.1859584
[Epoch 8; Iter   107/  229] train: loss: 0.2088531
[Epoch 8; Iter   137/  229] train: loss: 0.2579054
[Epoch 8; Iter   167/  229] train: loss: 0.1571163
[Epoch 8; Iter   197/  229] train: loss: 0.2112064
[Epoch 8; Iter   227/  229] train: loss: 0.1496707
[Epoch 8] ogbg-moltoxcast: 0.638505 val loss: 0.261222
[Epoch 8] ogbg-moltoxcast: 0.607908 test loss: 0.295066
[Epoch 9; Iter    28/  229] train: loss: 0.1616192
[Epoch 9; Iter    58/  229] train: loss: 0.1870184
[Epoch 9; Iter    88/  229] train: loss: 0.1986519
[Epoch 9; Iter   118/  229] train: loss: 0.1701540
[Epoch 9; Iter   148/  229] train: loss: 0.2230826
[Epoch 9; Iter   178/  229] train: loss: 0.1913797
[Epoch 9; Iter   208/  229] train: loss: 0.1970783
[Epoch 9] ogbg-moltoxcast: 0.639621 val loss: 0.275400
[Epoch 9] ogbg-moltoxcast: 0.611055 test loss: 0.339787
[Epoch 10; Iter     9/  229] train: loss: 0.1518935
[Epoch 10; Iter    39/  229] train: loss: 0.1165395
[Epoch 10; Iter    69/  229] train: loss: 0.2724281
[Epoch 10; Iter    99/  229] train: loss: 0.1539872
[Epoch 10; Iter   129/  229] train: loss: 0.1873786
[Epoch 10; Iter   159/  229] train: loss: 0.1824482
[Epoch 10; Iter   189/  229] train: loss: 0.2673187
[Epoch 10; Iter   219/  229] train: loss: 0.1741802
[Epoch 10] ogbg-moltoxcast: 0.630221 val loss: 0.270610
[Epoch 10] ogbg-moltoxcast: 0.609676 test loss: 0.318633
[Epoch 11; Iter    20/  229] train: loss: 0.1723467
[Epoch 11; Iter    50/  229] train: loss: 0.1734900
[Epoch 11; Iter    80/  229] train: loss: 0.1757491
[Epoch 11; Iter   110/  229] train: loss: 0.1991046
[Epoch 11; Iter   140/  229] train: loss: 0.2215445
[Epoch 11; Iter   170/  229] train: loss: 0.1383086
[Epoch 11; Iter   200/  229] train: loss: 0.2198972
[Epoch 11] ogbg-moltoxcast: 0.657507 val loss: 0.392580
[Epoch 11] ogbg-moltoxcast: 0.611793 test loss: 0.388819
[Epoch 12; Iter     1/  229] train: loss: 0.2126722
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.1/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.1_4_26-05_09-40-17
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.1
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931642
[Epoch 1; Iter    60/  229] train: loss: 0.6931294
[Epoch 1; Iter    90/  229] train: loss: 0.6931387
[Epoch 1; Iter   120/  229] train: loss: 0.6930972
[Epoch 1; Iter   150/  229] train: loss: 0.6931245
[Epoch 1; Iter   180/  229] train: loss: 0.6931469
[Epoch 1; Iter   210/  229] train: loss: 0.6930938
[Epoch 1] ogbg-moltoxcast: 0.494936 val loss: 0.693104
[Epoch 1] ogbg-moltoxcast: 0.499528 test loss: 0.693102
[Epoch 2; Iter    11/  229] train: loss: 0.6931956
[Epoch 2; Iter    41/  229] train: loss: 0.6930962
[Epoch 2; Iter    71/  229] train: loss: 0.6930671
[Epoch 2; Iter   101/  229] train: loss: 0.6930253
[Epoch 2; Iter   131/  229] train: loss: 0.6930588
[Epoch 2; Iter   161/  229] train: loss: 0.6930643
[Epoch 2; Iter   191/  229] train: loss: 0.6930665
[Epoch 2; Iter   221/  229] train: loss: 0.6930227
[Epoch 2] ogbg-moltoxcast: 0.492990 val loss: 0.693012
[Epoch 2] ogbg-moltoxcast: 0.498725 test loss: 0.693019
[Epoch 3; Iter    22/  229] train: loss: 0.6930191
[Epoch 3; Iter    52/  229] train: loss: 0.6929867
[Epoch 3; Iter    82/  229] train: loss: 0.6929659
[Epoch 3; Iter   112/  229] train: loss: 0.6929873
[Epoch 3; Iter   142/  229] train: loss: 0.6929328
[Epoch 3; Iter   172/  229] train: loss: 0.6929027
[Epoch 3; Iter   202/  229] train: loss: 0.6929022
[Epoch 3] ogbg-moltoxcast: 0.493121 val loss: 0.692860
[Epoch 3] ogbg-moltoxcast: 0.500168 test loss: 0.692877
[Epoch 4; Iter     3/  229] train: loss: 0.6928341
[Epoch 4; Iter    33/  229] train: loss: 0.6903489
[Epoch 4; Iter    63/  229] train: loss: 0.6796366
[Epoch 4; Iter    93/  229] train: loss: 0.6521313
[Epoch 4; Iter   123/  229] train: loss: 0.6137441
[Epoch 4; Iter   153/  229] train: loss: 0.5805788
[Epoch 4; Iter   183/  229] train: loss: 0.5281991
[Epoch 4; Iter   213/  229] train: loss: 0.4535913
[Epoch 4] ogbg-moltoxcast: 0.562505 val loss: 0.419386
[Epoch 4] ogbg-moltoxcast: 0.523636 test loss: 0.466912
[Epoch 5; Iter    14/  229] train: loss: 0.4414363
[Epoch 5; Iter    44/  229] train: loss: 0.3549981
[Epoch 5; Iter    74/  229] train: loss: 0.3031003
[Epoch 5; Iter   104/  229] train: loss: 0.3275848
[Epoch 5; Iter   134/  229] train: loss: 0.3154882
[Epoch 5; Iter   164/  229] train: loss: 0.2496109
[Epoch 5; Iter   194/  229] train: loss: 0.2551035
[Epoch 5; Iter   224/  229] train: loss: 0.1728107
[Epoch 5] ogbg-moltoxcast: 0.626317 val loss: 0.287142
[Epoch 5] ogbg-moltoxcast: 0.582521 test loss: 0.345044
[Epoch 6; Iter    25/  229] train: loss: 0.2818389
[Epoch 6; Iter    55/  229] train: loss: 0.2085226
[Epoch 6; Iter    85/  229] train: loss: 0.3053327
[Epoch 6; Iter   115/  229] train: loss: 0.2223750
[Epoch 6; Iter   145/  229] train: loss: 0.2127486
[Epoch 6; Iter   175/  229] train: loss: 0.1920745
[Epoch 6; Iter   205/  229] train: loss: 0.1893960
[Epoch 6] ogbg-moltoxcast: 0.630413 val loss: 0.270246
[Epoch 6] ogbg-moltoxcast: 0.617618 test loss: 0.317474
[Epoch 7; Iter     6/  229] train: loss: 0.1267564
[Epoch 7; Iter    36/  229] train: loss: 0.2364422
[Epoch 7; Iter    66/  229] train: loss: 0.2375762
[Epoch 7; Iter    96/  229] train: loss: 0.1709976
[Epoch 7; Iter   126/  229] train: loss: 0.2798423
[Epoch 7; Iter   156/  229] train: loss: 0.1844656
[Epoch 7; Iter   186/  229] train: loss: 0.3204205
[Epoch 7; Iter   216/  229] train: loss: 0.1991661
[Epoch 7] ogbg-moltoxcast: 0.592581 val loss: 0.372567
[Epoch 7] ogbg-moltoxcast: 0.559100 test loss: 0.863675
[Epoch 8; Iter    17/  229] train: loss: 0.1496929
[Epoch 8; Iter    47/  229] train: loss: 0.3362595
[Epoch 8; Iter    77/  229] train: loss: 0.1823830
[Epoch 8; Iter   107/  229] train: loss: 0.2551982
[Epoch 8; Iter   137/  229] train: loss: 0.1966944
[Epoch 8; Iter   167/  229] train: loss: 0.1679687
[Epoch 8; Iter   197/  229] train: loss: 0.2303625
[Epoch 8; Iter   227/  229] train: loss: 0.2175667
[Epoch 8] ogbg-moltoxcast: 0.632695 val loss: 0.288397
[Epoch 8] ogbg-moltoxcast: 0.602807 test loss: 0.335605
[Epoch 9; Iter    28/  229] train: loss: 0.1400304
[Epoch 9; Iter    58/  229] train: loss: 0.1313525
[Epoch 9; Iter    88/  229] train: loss: 0.2076385
[Epoch 9; Iter   118/  229] train: loss: 0.1317981
[Epoch 9; Iter   148/  229] train: loss: 0.2286635
[Epoch 9; Iter   178/  229] train: loss: 0.2259018
[Epoch 9; Iter   208/  229] train: loss: 0.1914306
[Epoch 9] ogbg-moltoxcast: 0.634738 val loss: 1.558207
[Epoch 9] ogbg-moltoxcast: 0.607198 test loss: 1.750134
[Epoch 10; Iter     9/  229] train: loss: 0.1435414
[Epoch 10; Iter    39/  229] train: loss: 0.1522743
[Epoch 10; Iter    69/  229] train: loss: 0.2338291
[Epoch 10; Iter    99/  229] train: loss: 0.2744044
[Epoch 10; Iter   129/  229] train: loss: 0.1804523
[Epoch 10; Iter   159/  229] train: loss: 0.2165059
[Epoch 10; Iter   189/  229] train: loss: 0.2393846
[Epoch 10; Iter   219/  229] train: loss: 0.2631538
[Epoch 10] ogbg-moltoxcast: 0.643994 val loss: 0.287540
[Epoch 10] ogbg-moltoxcast: 0.618008 test loss: 0.388842
[Epoch 11; Iter    20/  229] train: loss: 0.1730451
[Epoch 11; Iter    50/  229] train: loss: 0.1948913
[Epoch 11; Iter    80/  229] train: loss: 0.1625260
[Epoch 11; Iter   110/  229] train: loss: 0.1780630
[Epoch 11; Iter   140/  229] train: loss: 0.2934652
[Epoch 11; Iter   170/  229] train: loss: 0.2133894
[Epoch 11; Iter   200/  229] train: loss: 0.2886394
[Epoch 11] ogbg-moltoxcast: 0.649804 val loss: 0.263775
[Epoch 11] ogbg-moltoxcast: 0.613780 test loss: 0.310372
[Epoch 12; Iter     1/  229] train: loss: 0.1653447
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.2/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.2_5_26-05_09-40-47
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.2
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6930898
[Epoch 1; Iter    60/  229] train: loss: 0.6932091
[Epoch 1; Iter    90/  229] train: loss: 0.6930879
[Epoch 1; Iter   120/  229] train: loss: 0.6931891
[Epoch 1; Iter   150/  229] train: loss: 0.6931442
[Epoch 1; Iter   180/  229] train: loss: 0.6931174
[Epoch 1; Iter   210/  229] train: loss: 0.6931403
[Epoch 1] ogbg-moltoxcast: 0.512150 val loss: 0.693254
[Epoch 1] ogbg-moltoxcast: 0.511313 test loss: 0.693251
[Epoch 2; Iter    11/  229] train: loss: 0.6930833
[Epoch 2; Iter    41/  229] train: loss: 0.6930203
[Epoch 2; Iter    71/  229] train: loss: 0.6930602
[Epoch 2; Iter   101/  229] train: loss: 0.6930355
[Epoch 2; Iter   131/  229] train: loss: 0.6930858
[Epoch 2; Iter   161/  229] train: loss: 0.6929817
[Epoch 2; Iter   191/  229] train: loss: 0.6929746
[Epoch 2; Iter   221/  229] train: loss: 0.6929891
[Epoch 2] ogbg-moltoxcast: 0.511177 val loss: 0.693136
[Epoch 2] ogbg-moltoxcast: 0.511704 test loss: 0.693149
[Epoch 3; Iter    22/  229] train: loss: 0.6928921
[Epoch 3; Iter    52/  229] train: loss: 0.6929045
[Epoch 3; Iter    82/  229] train: loss: 0.6928875
[Epoch 3; Iter   112/  229] train: loss: 0.6928362
[Epoch 3; Iter   142/  229] train: loss: 0.6928080
[Epoch 3; Iter   172/  229] train: loss: 0.6927269
[Epoch 3; Iter   202/  229] train: loss: 0.6928210
[Epoch 3] ogbg-moltoxcast: 0.512300 val loss: 0.692917
[Epoch 3] ogbg-moltoxcast: 0.511575 test loss: 0.692954
[Epoch 4; Iter     3/  229] train: loss: 0.6928771
[Epoch 4; Iter    33/  229] train: loss: 0.6898706
[Epoch 4; Iter    63/  229] train: loss: 0.6772799
[Epoch 4; Iter    93/  229] train: loss: 0.6322528
[Epoch 4; Iter   123/  229] train: loss: 0.6010303
[Epoch 4; Iter   153/  229] train: loss: 0.5528842
[Epoch 4; Iter   183/  229] train: loss: 0.5050625
[Epoch 4; Iter   213/  229] train: loss: 0.4522009
[Epoch 4] ogbg-moltoxcast: 0.567827 val loss: 0.551475
[Epoch 4] ogbg-moltoxcast: 0.534794 test loss: 0.608235
[Epoch 5; Iter    14/  229] train: loss: 0.4061593
[Epoch 5; Iter    44/  229] train: loss: 0.3201253
[Epoch 5; Iter    74/  229] train: loss: 0.3467987
[Epoch 5; Iter   104/  229] train: loss: 0.2815241
[Epoch 5; Iter   134/  229] train: loss: 0.2515265
[Epoch 5; Iter   164/  229] train: loss: 0.2095756
[Epoch 5; Iter   194/  229] train: loss: 0.2330058
[Epoch 5; Iter   224/  229] train: loss: 0.1652227
[Epoch 5] ogbg-moltoxcast: 0.615959 val loss: 0.501370
[Epoch 5] ogbg-moltoxcast: 0.588369 test loss: 0.653442
[Epoch 6; Iter    25/  229] train: loss: 0.3003629
[Epoch 6; Iter    55/  229] train: loss: 0.2201798
[Epoch 6; Iter    85/  229] train: loss: 0.1831839
[Epoch 6; Iter   115/  229] train: loss: 0.2004829
[Epoch 6; Iter   145/  229] train: loss: 0.2624023
[Epoch 6; Iter   175/  229] train: loss: 0.2162002
[Epoch 6; Iter   205/  229] train: loss: 0.1910457
[Epoch 6] ogbg-moltoxcast: 0.614261 val loss: 1.130019
[Epoch 6] ogbg-moltoxcast: 0.591587 test loss: 1.255923
[Epoch 7; Iter     6/  229] train: loss: 0.1782929
[Epoch 7; Iter    36/  229] train: loss: 0.1483146
[Epoch 7; Iter    66/  229] train: loss: 0.2680340
[Epoch 7; Iter    96/  229] train: loss: 0.2385304
[Epoch 7; Iter   126/  229] train: loss: 0.2673056
[Epoch 7; Iter   156/  229] train: loss: 0.1662552
[Epoch 7; Iter   186/  229] train: loss: 0.3667040
[Epoch 7; Iter   216/  229] train: loss: 0.1968042
[Epoch 7] ogbg-moltoxcast: 0.620830 val loss: 2.589905
[Epoch 7] ogbg-moltoxcast: 0.593441 test loss: 3.532771
[Epoch 8; Iter    17/  229] train: loss: 0.2362381
[Epoch 8; Iter    47/  229] train: loss: 0.1722063
[Epoch 8; Iter    77/  229] train: loss: 0.1786394
[Epoch 8; Iter   107/  229] train: loss: 0.2231485
[Epoch 8; Iter   137/  229] train: loss: 0.2521824
[Epoch 8; Iter   167/  229] train: loss: 0.1580080
[Epoch 8; Iter   197/  229] train: loss: 0.2089649
[Epoch 8; Iter   227/  229] train: loss: 0.1518818
[Epoch 8] ogbg-moltoxcast: 0.644420 val loss: 0.299917
[Epoch 8] ogbg-moltoxcast: 0.600487 test loss: 0.606360
[Epoch 9; Iter    28/  229] train: loss: 0.1634607
[Epoch 9; Iter    58/  229] train: loss: 0.1889063
[Epoch 9; Iter    88/  229] train: loss: 0.2167767
[Epoch 9; Iter   118/  229] train: loss: 0.1684774
[Epoch 9; Iter   148/  229] train: loss: 0.2208640
[Epoch 9; Iter   178/  229] train: loss: 0.2036654
[Epoch 9; Iter   208/  229] train: loss: 0.2026539
[Epoch 9] ogbg-moltoxcast: 0.645352 val loss: 0.408802
[Epoch 9] ogbg-moltoxcast: 0.615831 test loss: 0.430000
[Epoch 10; Iter     9/  229] train: loss: 0.1521956
[Epoch 10; Iter    39/  229] train: loss: 0.1184471
[Epoch 10; Iter    69/  229] train: loss: 0.2576713
[Epoch 10; Iter    99/  229] train: loss: 0.1548338
[Epoch 10; Iter   129/  229] train: loss: 0.1793272
[Epoch 10; Iter   159/  229] train: loss: 0.1763044
[Epoch 10; Iter   189/  229] train: loss: 0.2906250
[Epoch 10; Iter   219/  229] train: loss: 0.1774354
[Epoch 10] ogbg-moltoxcast: 0.654284 val loss: 0.796061
[Epoch 10] ogbg-moltoxcast: 0.625502 test loss: 5.902781
[Epoch 11; Iter    20/  229] train: loss: 0.1729988
[Epoch 11; Iter    50/  229] train: loss: 0.1704710
[Epoch 11; Iter    80/  229] train: loss: 0.1835666
[Epoch 11; Iter   110/  229] train: loss: 0.1967352
[Epoch 11; Iter   140/  229] train: loss: 0.2456651
[Epoch 11; Iter   170/  229] train: loss: 0.1454065
[Epoch 11; Iter   200/  229] train: loss: 0.2204778
[Epoch 11] ogbg-moltoxcast: 0.661166 val loss: 0.275798
[Epoch 11] ogbg-moltoxcast: 0.617766 test loss: 0.344128
[Epoch 12; Iter     1/  229] train: loss: 0.2135537
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.2/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.2_4_26-05_09-40-48
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.2
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931512
[Epoch 1; Iter    60/  229] train: loss: 0.6931740
[Epoch 1; Iter    90/  229] train: loss: 0.6931263
[Epoch 1; Iter   120/  229] train: loss: 0.6931029
[Epoch 1; Iter   150/  229] train: loss: 0.6930922
[Epoch 1; Iter   180/  229] train: loss: 0.6931509
[Epoch 1; Iter   210/  229] train: loss: 0.6931173
[Epoch 1] ogbg-moltoxcast: 0.493915 val loss: 0.693091
[Epoch 1] ogbg-moltoxcast: 0.497518 test loss: 0.693108
[Epoch 2; Iter    11/  229] train: loss: 0.6931688
[Epoch 2; Iter    41/  229] train: loss: 0.6931022
[Epoch 2; Iter    71/  229] train: loss: 0.6930978
[Epoch 2; Iter   101/  229] train: loss: 0.6931041
[Epoch 2; Iter   131/  229] train: loss: 0.6930493
[Epoch 2; Iter   161/  229] train: loss: 0.6930989
[Epoch 2; Iter   191/  229] train: loss: 0.6930026
[Epoch 2; Iter   221/  229] train: loss: 0.6930355
[Epoch 2] ogbg-moltoxcast: 0.494166 val loss: 0.693001
[Epoch 2] ogbg-moltoxcast: 0.497005 test loss: 0.693024
[Epoch 3; Iter    22/  229] train: loss: 0.6930113
[Epoch 3; Iter    52/  229] train: loss: 0.6929330
[Epoch 3; Iter    82/  229] train: loss: 0.6929160
[Epoch 3; Iter   112/  229] train: loss: 0.6930133
[Epoch 3; Iter   142/  229] train: loss: 0.6929370
[Epoch 3; Iter   172/  229] train: loss: 0.6929006
[Epoch 3; Iter   202/  229] train: loss: 0.6929451
[Epoch 3] ogbg-moltoxcast: 0.494753 val loss: 0.692890
[Epoch 3] ogbg-moltoxcast: 0.497792 test loss: 0.692920
[Epoch 4; Iter     3/  229] train: loss: 0.6928674
[Epoch 4; Iter    33/  229] train: loss: 0.6901327
[Epoch 4; Iter    63/  229] train: loss: 0.6763622
[Epoch 4; Iter    93/  229] train: loss: 0.6547334
[Epoch 4; Iter   123/  229] train: loss: 0.6200206
[Epoch 4; Iter   153/  229] train: loss: 0.5751812
[Epoch 4; Iter   183/  229] train: loss: 0.5301224
[Epoch 4; Iter   213/  229] train: loss: 0.4550050
[Epoch 4] ogbg-moltoxcast: 0.598916 val loss: 0.487046
[Epoch 4] ogbg-moltoxcast: 0.570719 test loss: 0.506527
[Epoch 5; Iter    14/  229] train: loss: 0.4473515
[Epoch 5; Iter    44/  229] train: loss: 0.3539008
[Epoch 5; Iter    74/  229] train: loss: 0.2931830
[Epoch 5; Iter   104/  229] train: loss: 0.3280061
[Epoch 5; Iter   134/  229] train: loss: 0.3175132
[Epoch 5; Iter   164/  229] train: loss: 0.2474534
[Epoch 5; Iter   194/  229] train: loss: 0.2538417
[Epoch 5; Iter   224/  229] train: loss: 0.1689784
[Epoch 5] ogbg-moltoxcast: 0.618216 val loss: 0.338522
[Epoch 5] ogbg-moltoxcast: 0.582389 test loss: 0.387592
[Epoch 6; Iter    25/  229] train: loss: 0.2663631
[Epoch 6; Iter    55/  229] train: loss: 0.2198281
[Epoch 6; Iter    85/  229] train: loss: 0.3233176
[Epoch 6; Iter   115/  229] train: loss: 0.2137286
[Epoch 6; Iter   145/  229] train: loss: 0.2088311
[Epoch 6; Iter   175/  229] train: loss: 0.1925980
[Epoch 6; Iter   205/  229] train: loss: 0.1814198
[Epoch 6] ogbg-moltoxcast: 0.625185 val loss: 0.402494
[Epoch 6] ogbg-moltoxcast: 0.590124 test loss: 0.473035
[Epoch 7; Iter     6/  229] train: loss: 0.1251666
[Epoch 7; Iter    36/  229] train: loss: 0.2348356
[Epoch 7; Iter    66/  229] train: loss: 0.2245542
[Epoch 7; Iter    96/  229] train: loss: 0.1737460
[Epoch 7; Iter   126/  229] train: loss: 0.2936292
[Epoch 7; Iter   156/  229] train: loss: 0.1947025
[Epoch 7; Iter   186/  229] train: loss: 0.3155802
[Epoch 7; Iter   216/  229] train: loss: 0.2129869
[Epoch 7] ogbg-moltoxcast: 0.650181 val loss: 0.324648
[Epoch 7] ogbg-moltoxcast: 0.584632 test loss: 0.471532
[Epoch 8; Iter    17/  229] train: loss: 0.1555278
[Epoch 8; Iter    47/  229] train: loss: 0.3184031
[Epoch 8; Iter    77/  229] train: loss: 0.1860556
[Epoch 8; Iter   107/  229] train: loss: 0.2617557
[Epoch 8; Iter   137/  229] train: loss: 0.2147253
[Epoch 8; Iter   167/  229] train: loss: 0.1770040
[Epoch 8; Iter   197/  229] train: loss: 0.2297986
[Epoch 8; Iter   227/  229] train: loss: 0.2245190
[Epoch 8] ogbg-moltoxcast: 0.635269 val loss: 0.280527
[Epoch 8] ogbg-moltoxcast: 0.572895 test loss: 0.333215
[Epoch 9; Iter    28/  229] train: loss: 0.1417362
[Epoch 9; Iter    58/  229] train: loss: 0.1279992
[Epoch 9; Iter    88/  229] train: loss: 0.2146058
[Epoch 9; Iter   118/  229] train: loss: 0.1201718
[Epoch 9; Iter   148/  229] train: loss: 0.2352801
[Epoch 9; Iter   178/  229] train: loss: 0.2257985
[Epoch 9; Iter   208/  229] train: loss: 0.1990021
[Epoch 9] ogbg-moltoxcast: 0.645510 val loss: 0.436124
[Epoch 9] ogbg-moltoxcast: 0.607372 test loss: 0.656534
[Epoch 10; Iter     9/  229] train: loss: 0.1499109
[Epoch 10; Iter    39/  229] train: loss: 0.1516103
[Epoch 10; Iter    69/  229] train: loss: 0.2408378
[Epoch 10; Iter    99/  229] train: loss: 0.2708723
[Epoch 10; Iter   129/  229] train: loss: 0.1934562
[Epoch 10; Iter   159/  229] train: loss: 0.2275153
[Epoch 10; Iter   189/  229] train: loss: 0.2587755
[Epoch 10; Iter   219/  229] train: loss: 0.2645624
[Epoch 10] ogbg-moltoxcast: 0.651062 val loss: 0.305942
[Epoch 10] ogbg-moltoxcast: 0.615895 test loss: 0.861237
[Epoch 11; Iter    20/  229] train: loss: 0.1836299
[Epoch 11; Iter    50/  229] train: loss: 0.2090605
[Epoch 11; Iter    80/  229] train: loss: 0.1637007
[Epoch 11; Iter   110/  229] train: loss: 0.1704158
[Epoch 11; Iter   140/  229] train: loss: 0.2938159
[Epoch 11; Iter   170/  229] train: loss: 0.2180390
[Epoch 11; Iter   200/  229] train: loss: 0.3123653
[Epoch 11] ogbg-moltoxcast: 0.666718 val loss: 1.831623
[Epoch 11] ogbg-moltoxcast: 0.606655 test loss: 9.608678
[Epoch 12; Iter     1/  229] train: loss: 0.1748113
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/toxcast/noise=0.2/PNA_ogbg-moltoxcast_3DInfomax_toxcast_static_noise=0.2_6_26-05_09-40-50
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/toxcast/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_toxcast_static_noise=0.2
logdir: runs/static_noise/3DInfomax/toxcast/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6932397
[Epoch 1; Iter    60/  229] train: loss: 0.6931506
[Epoch 1; Iter    90/  229] train: loss: 0.6931273
[Epoch 1; Iter   120/  229] train: loss: 0.6931461
[Epoch 1; Iter   150/  229] train: loss: 0.6931841
[Epoch 1; Iter   180/  229] train: loss: 0.6931612
[Epoch 1; Iter   210/  229] train: loss: 0.6931357
[Epoch 1] ogbg-moltoxcast: 0.494937 val loss: 0.692678
[Epoch 1] ogbg-moltoxcast: 0.494517 test loss: 0.692724
[Epoch 2; Iter    11/  229] train: loss: 0.6930690
[Epoch 2; Iter    41/  229] train: loss: 0.6931310
[Epoch 2; Iter    71/  229] train: loss: 0.6931490
[Epoch 2; Iter   101/  229] train: loss: 0.6930565
[Epoch 2; Iter   131/  229] train: loss: 0.6930178
[Epoch 2; Iter   161/  229] train: loss: 0.6930358
[Epoch 2; Iter   191/  229] train: loss: 0.6930960
[Epoch 2; Iter   221/  229] train: loss: 0.6930317
[Epoch 2] ogbg-moltoxcast: 0.496143 val loss: 0.692536
[Epoch 2] ogbg-moltoxcast: 0.494458 test loss: 0.692588
[Epoch 3; Iter    22/  229] train: loss: 0.6929902
[Epoch 3; Iter    52/  229] train: loss: 0.6929171
[Epoch 3; Iter    82/  229] train: loss: 0.6930191
[Epoch 3; Iter   112/  229] train: loss: 0.6929517
[Epoch 3; Iter   142/  229] train: loss: 0.6929589
[Epoch 3; Iter   172/  229] train: loss: 0.6928368
[Epoch 3; Iter   202/  229] train: loss: 0.6928107
[Epoch 3] ogbg-moltoxcast: 0.495371 val loss: 0.692371
[Epoch 3] ogbg-moltoxcast: 0.494229 test loss: 0.692440
[Epoch 4; Iter     3/  229] train: loss: 0.6928443
[Epoch 4; Iter    33/  229] train: loss: 0.6892827
[Epoch 4; Iter    63/  229] train: loss: 0.6767282
[Epoch 4; Iter    93/  229] train: loss: 0.6398520
[Epoch 4; Iter   123/  229] train: loss: 0.6366848
[Epoch 4; Iter   153/  229] train: loss: 0.5434572
[Epoch 4; Iter   183/  229] train: loss: 0.5850034
[Epoch 4; Iter   213/  229] train: loss: 0.4434326
[Epoch 4] ogbg-moltoxcast: 0.578858 val loss: 0.498934
[Epoch 4] ogbg-moltoxcast: 0.536874 test loss: 0.513593
[Epoch 5; Iter    14/  229] train: loss: 0.4442566
[Epoch 5; Iter    44/  229] train: loss: 0.3596772
[Epoch 5; Iter    74/  229] train: loss: 0.3207107
[Epoch 5; Iter   104/  229] train: loss: 0.3102847
[Epoch 5; Iter   134/  229] train: loss: 0.2993125
[Epoch 5; Iter   164/  229] train: loss: 0.2458812
[Epoch 5; Iter   194/  229] train: loss: 0.2593581
[Epoch 5; Iter   224/  229] train: loss: 0.3051887
[Epoch 5] ogbg-moltoxcast: 0.591674 val loss: 0.468847
[Epoch 5] ogbg-moltoxcast: 0.571449 test loss: 0.692971
[Epoch 6; Iter    25/  229] train: loss: 0.3154401
[Epoch 6; Iter    55/  229] train: loss: 0.1900881
[Epoch 6; Iter    85/  229] train: loss: 0.2562115
[Epoch 6; Iter   115/  229] train: loss: 0.2370567
[Epoch 6; Iter   145/  229] train: loss: 0.2148752
[Epoch 6; Iter   175/  229] train: loss: 0.1889822
[Epoch 6; Iter   205/  229] train: loss: 0.1458979
[Epoch 6] ogbg-moltoxcast: 0.603094 val loss: 0.448435
[Epoch 6] ogbg-moltoxcast: 0.585525 test loss: 0.681792
[Epoch 7; Iter     6/  229] train: loss: 0.1775964
[Epoch 7; Iter    36/  229] train: loss: 0.1614083
[Epoch 7; Iter    66/  229] train: loss: 0.1987347
[Epoch 7; Iter    96/  229] train: loss: 0.2656253
[Epoch 7; Iter   126/  229] train: loss: 0.2159200
[Epoch 7; Iter   156/  229] train: loss: 0.2584904
[Epoch 7; Iter   186/  229] train: loss: 0.2010545
[Epoch 7; Iter   216/  229] train: loss: 0.2036659
[Epoch 7] ogbg-moltoxcast: 0.587114 val loss: 0.496288
[Epoch 7] ogbg-moltoxcast: 0.540602 test loss: 0.756853
[Epoch 8; Iter    17/  229] train: loss: 0.1852341
[Epoch 8; Iter    47/  229] train: loss: 0.1927795
[Epoch 8; Iter    77/  229] train: loss: 0.1830957
[Epoch 8; Iter   107/  229] train: loss: 0.2352843
[Epoch 8; Iter   137/  229] train: loss: 0.2542520
[Epoch 8; Iter   167/  229] train: loss: 0.1914428
[Epoch 8; Iter   197/  229] train: loss: 0.2425734
[Epoch 8; Iter   227/  229] train: loss: 0.4079054
[Epoch 8] ogbg-moltoxcast: 0.628073 val loss: 0.268725
[Epoch 8] ogbg-moltoxcast: 0.600636 test loss: 0.357432
[Epoch 9; Iter    28/  229] train: loss: 0.1696190
[Epoch 9; Iter    58/  229] train: loss: 0.1399517
[Epoch 9; Iter    88/  229] train: loss: 0.1677422
[Epoch 9; Iter   118/  229] train: loss: 0.2515589
[Epoch 9; Iter   148/  229] train: loss: 0.3253416
[Epoch 9; Iter   178/  229] train: loss: 0.1621809
[Epoch 9; Iter   208/  229] train: loss: 0.2530596
[Epoch 9] ogbg-moltoxcast: 0.654050 val loss: 0.265958
[Epoch 9] ogbg-moltoxcast: 0.608741 test loss: 0.351848
[Epoch 10; Iter     9/  229] train: loss: 0.2276773
[Epoch 10; Iter    39/  229] train: loss: 0.1853076
[Epoch 10; Iter    69/  229] train: loss: 0.1511749
[Epoch 10; Iter    99/  229] train: loss: 0.1108665
[Epoch 10; Iter   129/  229] train: loss: 0.1852054
[Epoch 10; Iter   159/  229] train: loss: 0.2438738
[Epoch 10; Iter   189/  229] train: loss: 0.2020705
[Epoch 10; Iter   219/  229] train: loss: 0.2133891
[Epoch 10] ogbg-moltoxcast: 0.638370 val loss: 0.277028
[Epoch 10] ogbg-moltoxcast: 0.606408 test loss: 0.316988
[Epoch 11; Iter    20/  229] train: loss: 0.1634967
[Epoch 11; Iter    50/  229] train: loss: 0.1915509
[Epoch 11; Iter    80/  229] train: loss: 0.1593485
[Epoch 11; Iter   110/  229] train: loss: 0.1315601
[Epoch 11; Iter   140/  229] train: loss: 0.2228242
[Epoch 11; Iter   170/  229] train: loss: 0.3319044
[Epoch 11; Iter   200/  229] train: loss: 0.1563474
[Epoch 11] ogbg-moltoxcast: 0.644568 val loss: 0.288600
[Epoch 11] ogbg-moltoxcast: 0.613006 test loss: 0.602604
[Epoch 12; Iter     1/  229] train: loss: 0.2317644
[Epoch 12; Iter    31/  229] train: loss: 0.2259409
[Epoch 12; Iter    61/  229] train: loss: 0.2468244
[Epoch 12; Iter    91/  229] train: loss: 0.1490130
[Epoch 12; Iter   121/  229] train: loss: 0.1332869
[Epoch 12; Iter   151/  229] train: loss: 0.1536801
[Epoch 12; Iter   181/  229] train: loss: 0.1969708
[Epoch 12; Iter   211/  229] train: loss: 0.1263618
[Epoch 12] ogbg-moltoxcast: 0.665112 val loss: 0.278639
[Epoch 12] ogbg-moltoxcast: 0.622862 test loss: 0.330757
[Epoch 13; Iter    12/  229] train: loss: 0.1972000
[Epoch 13; Iter    42/  229] train: loss: 0.1969976
[Epoch 13; Iter    72/  229] train: loss: 0.1876937
[Epoch 13; Iter   102/  229] train: loss: 0.2116117
[Epoch 13; Iter   132/  229] train: loss: 0.2117506
[Epoch 13; Iter   162/  229] train: loss: 0.1974063
[Epoch 13; Iter   192/  229] train: loss: 0.1948309
[Epoch 13; Iter   222/  229] train: loss: 0.1338799
[Epoch 13] ogbg-moltoxcast: 0.676102 val loss: 0.256240
[Epoch 13] ogbg-moltoxcast: 0.628209 test loss: 0.307802
[Epoch 14; Iter    23/  229] train: loss: 0.2940134
[Epoch 14; Iter    53/  229] train: loss: 0.1447672
[Epoch 14; Iter    83/  229] train: loss: 0.1481030
[Epoch 14; Iter   113/  229] train: loss: 0.1966703
[Epoch 14; Iter   143/  229] train: loss: 0.1666085
[Epoch 14; Iter   173/  229] train: loss: 0.1638758
[Epoch 14; Iter   203/  229] train: loss: 0.1630087
[Epoch 14] ogbg-moltoxcast: 0.671257 val loss: 0.267496
[Epoch 14] ogbg-moltoxcast: 0.633130 test loss: 0.314955
[Epoch 15; Iter     4/  229] train: loss: 0.2653339
[Epoch 15; Iter    34/  229] train: loss: 0.1532028
[Epoch 15; Iter    64/  229] train: loss: 0.1259521
[Epoch 15; Iter    94/  229] train: loss: 0.2110462
[Epoch 15; Iter   124/  229] train: loss: 0.1605247
[Epoch 15; Iter   154/  229] train: loss: 0.2800440
[Epoch 15; Iter   184/  229] train: loss: 0.1977464
[Epoch 15; Iter   214/  229] train: loss: 0.1894349
[Epoch 15] ogbg-moltoxcast: 0.632544 val loss: 0.284470
[Epoch 15] ogbg-moltoxcast: 0.611949 test loss: 0.335319
[Epoch 16; Iter    15/  229] train: loss: 0.1332629
[Epoch 16; Iter    45/  229] train: loss: 0.2061350
[Epoch 16; Iter    75/  229] train: loss: 0.1835314
[Epoch 16; Iter   105/  229] train: loss: 0.2356787
[Epoch 16; Iter   135/  229] train: loss: 0.1242147
[Epoch 16; Iter   165/  229] train: loss: 0.1753382
[Epoch 16; Iter   195/  229] train: loss: 0.2369616
[Epoch 16; Iter   225/  229] train: loss: 0.1676530
[Epoch 16] ogbg-moltoxcast: 0.665512 val loss: 0.268512
[Epoch 16] ogbg-moltoxcast: 0.627268 test loss: 0.306561
[Epoch 17; Iter    26/  229] train: loss: 0.1466344
[Epoch 17; Iter    56/  229] train: loss: 0.1736590
[Epoch 17; Iter    86/  229] train: loss: 0.1049382
[Epoch 17; Iter   116/  229] train: loss: 0.1324440
[Epoch 17; Iter   146/  229] train: loss: 0.2242888
[Epoch 17; Iter   176/  229] train: loss: 0.1557377
[Epoch 17; Iter   206/  229] train: loss: 0.2081717
[Epoch 17] ogbg-moltoxcast: 0.675415 val loss: 0.266877
[Epoch 17] ogbg-moltoxcast: 0.635458 test loss: 0.314576
[Epoch 18; Iter     7/  229] train: loss: 0.2047416
[Epoch 18; Iter    37/  229] train: loss: 0.1950098
[Epoch 18; Iter    67/  229] train: loss: 0.1953664
[Epoch 18; Iter    97/  229] train: loss: 0.2997944
[Epoch 18; Iter   127/  229] train: loss: 0.1666284
[Epoch 18; Iter   157/  229] train: loss: 0.2010138
[Epoch 18; Iter   187/  229] train: loss: 0.2557477
[Epoch 18; Iter   217/  229] train: loss: 0.2200529
[Epoch 18] ogbg-moltoxcast: 0.669802 val loss: 0.270435
[Epoch 18] ogbg-moltoxcast: 0.640340 test loss: 0.313417
[Epoch 19; Iter    18/  229] train: loss: 0.1203215
[Epoch 19; Iter    48/  229] train: loss: 0.2340936
[Epoch 19; Iter    78/  229] train: loss: 0.2128677
[Epoch 19; Iter   108/  229] train: loss: 0.1723415
[Epoch 19; Iter   138/  229] train: loss: 0.1671607
[Epoch 19; Iter   168/  229] train: loss: 0.1612633
[Epoch 19; Iter   198/  229] train: loss: 0.2313958
[Epoch 19; Iter   228/  229] train: loss: 0.2708739
[Epoch 19] ogbg-moltoxcast: 0.688186 val loss: 0.262135
[Epoch 19] ogbg-moltoxcast: 0.638415 test loss: 0.308125
[Epoch 20; Iter    29/  229] train: loss: 0.1614868
[Epoch 20; Iter    59/  229] train: loss: 0.1301656
[Epoch 20; Iter    89/  229] train: loss: 0.2522598
[Epoch 20; Iter   119/  229] train: loss: 0.1563359
[Epoch 20; Iter   149/  229] train: loss: 0.2250908
[Epoch 20; Iter   179/  229] train: loss: 0.1816638
[Epoch 20; Iter   209/  229] train: loss: 0.1662381
[Epoch 20] ogbg-moltoxcast: 0.687063 val loss: 0.265977
[Epoch 20] ogbg-moltoxcast: 0.632840 test loss: 0.315978
[Epoch 21; Iter    10/  229] train: loss: 0.2006203
[Epoch 21; Iter    40/  229] train: loss: 0.2059520
[Epoch 21; Iter    70/  229] train: loss: 0.2177887
[Epoch 21; Iter   100/  229] train: loss: 0.1921322
[Epoch 21; Iter   130/  229] train: loss: 0.1879427
[Epoch 21; Iter   160/  229] train: loss: 0.1913296
[Epoch 21; Iter   190/  229] train: loss: 0.1889416
[Epoch 21; Iter   220/  229] train: loss: 0.1310178
[Epoch 21] ogbg-moltoxcast: 0.685542 val loss: 0.273645
[Epoch 21] ogbg-moltoxcast: 0.633634 test loss: 0.316403
[Epoch 22; Iter    21/  229] train: loss: 0.0937335
[Epoch 22; Iter    51/  229] train: loss: 0.1918570
[Epoch 22; Iter    81/  229] train: loss: 0.1086624
[Epoch 22; Iter   111/  229] train: loss: 0.2043797
[Epoch 22; Iter   141/  229] train: loss: 0.2702518
[Epoch 22; Iter   171/  229] train: loss: 0.1177543
[Epoch 22; Iter   201/  229] train: loss: 0.1647314
[Epoch 22] ogbg-moltoxcast: 0.688303 val loss: 0.261449
[Epoch 22] ogbg-moltoxcast: 0.646422 test loss: 0.302067
[Epoch 23; Iter     2/  229] train: loss: 0.2618893
[Epoch 23; Iter    32/  229] train: loss: 0.1162461
[Epoch 23; Iter    62/  229] train: loss: 0.1763877
[Epoch 23; Iter    92/  229] train: loss: 0.1731476
[Epoch 23; Iter   122/  229] train: loss: 0.1663335
[Epoch 23; Iter   152/  229] train: loss: 0.2661962
[Epoch 23; Iter   182/  229] train: loss: 0.1971963
[Epoch 23; Iter   212/  229] train: loss: 0.1583199
[Epoch 23] ogbg-moltoxcast: 0.695161 val loss: 0.266389
[Epoch 23] ogbg-moltoxcast: 0.641397 test loss: 0.310071
[Epoch 24; Iter    13/  229] train: loss: 0.1771690
[Epoch 24; Iter    43/  229] train: loss: 0.1589659
[Epoch 24; Iter    73/  229] train: loss: 0.1254360
[Epoch 24; Iter   103/  229] train: loss: 0.1325629
[Epoch 24; Iter   133/  229] train: loss: 0.2150407
[Epoch 24; Iter   163/  229] train: loss: 0.2105244
[Epoch 24; Iter   193/  229] train: loss: 0.1426483
[Epoch 24; Iter   223/  229] train: loss: 0.1559456
[Epoch 24] ogbg-moltoxcast: 0.678793 val loss: 0.260136
[Epoch 24] ogbg-moltoxcast: 0.640748 test loss: 0.307958
[Epoch 25; Iter    24/  229] train: loss: 0.2180635
[Epoch 25; Iter    54/  229] train: loss: 0.1622608
[Epoch 25; Iter    84/  229] train: loss: 0.2167718
[Epoch 25; Iter   114/  229] train: loss: 0.1772889
[Epoch 25; Iter   144/  229] train: loss: 0.1199590
[Epoch 25; Iter   174/  229] train: loss: 0.1334075
[Epoch 25; Iter   204/  229] train: loss: 0.1498148
[Epoch 25] ogbg-moltoxcast: 0.688123 val loss: 0.261772
[Epoch 25] ogbg-moltoxcast: 0.643353 test loss: 0.306314
[Epoch 26; Iter     5/  229] train: loss: 0.1363086
[Epoch 26; Iter    35/  229] train: loss: 0.2267193
[Epoch 26; Iter    65/  229] train: loss: 0.1982604
[Epoch 26; Iter    95/  229] train: loss: 0.1878112
[Epoch 26; Iter   125/  229] train: loss: 0.1449992
[Epoch 26; Iter   155/  229] train: loss: 0.1652646
[Epoch 26; Iter   185/  229] train: loss: 0.1518204
[Epoch 26; Iter   215/  229] train: loss: 0.1160936
[Epoch 26] ogbg-moltoxcast: 0.678382 val loss: 0.269870
[Epoch 26] ogbg-moltoxcast: 0.642731 test loss: 0.313405
[Epoch 27; Iter    16/  229] train: loss: 0.1580864
[Epoch 27; Iter    46/  229] train: loss: 0.1808731
[Epoch 27; Iter    76/  229] train: loss: 0.1286530
[Epoch 27; Iter   106/  229] train: loss: 0.1990049
[Epoch 27; Iter   136/  229] train: loss: 0.1797874
[Epoch 27; Iter   166/  229] train: loss: 0.1233155
[Epoch 27; Iter   196/  229] train: loss: 0.1343426
[Epoch 27; Iter   226/  229] train: loss: 0.1564057
[Epoch 27] ogbg-moltoxcast: 0.674945 val loss: 0.267401
[Epoch 27] ogbg-moltoxcast: 0.649106 test loss: 0.313706
[Epoch 12; Iter    31/  229] train: loss: 0.1849677
[Epoch 12; Iter    61/  229] train: loss: 0.1783941
[Epoch 12; Iter    91/  229] train: loss: 0.1753579
[Epoch 12; Iter   121/  229] train: loss: 0.3414398
[Epoch 12; Iter   151/  229] train: loss: 0.1969602
[Epoch 12; Iter   181/  229] train: loss: 0.2221962
[Epoch 12; Iter   211/  229] train: loss: 0.3298597
[Epoch 12] ogbg-moltoxcast: 0.655567 val loss: 0.284148
[Epoch 12] ogbg-moltoxcast: 0.624021 test loss: 0.335014
[Epoch 13; Iter    12/  229] train: loss: 0.2255565
[Epoch 13; Iter    42/  229] train: loss: 0.2264016
[Epoch 13; Iter    72/  229] train: loss: 0.1864501
[Epoch 13; Iter   102/  229] train: loss: 0.2105558
[Epoch 13; Iter   132/  229] train: loss: 0.1363105
[Epoch 13; Iter   162/  229] train: loss: 0.2317423
[Epoch 13; Iter   192/  229] train: loss: 0.1404140
[Epoch 13; Iter   222/  229] train: loss: 0.1913085
[Epoch 13] ogbg-moltoxcast: 0.682292 val loss: 0.257168
[Epoch 13] ogbg-moltoxcast: 0.635499 test loss: 0.306100
[Epoch 14; Iter    23/  229] train: loss: 0.1699772
[Epoch 14; Iter    53/  229] train: loss: 0.1586240
[Epoch 14; Iter    83/  229] train: loss: 0.1843005
[Epoch 14; Iter   113/  229] train: loss: 0.1499263
[Epoch 14; Iter   143/  229] train: loss: 0.2398722
[Epoch 14; Iter   173/  229] train: loss: 0.1250418
[Epoch 14; Iter   203/  229] train: loss: 0.1907337
[Epoch 14] ogbg-moltoxcast: 0.681965 val loss: 0.268011
[Epoch 14] ogbg-moltoxcast: 0.631488 test loss: 0.309421
[Epoch 15; Iter     4/  229] train: loss: 0.1476730
[Epoch 15; Iter    34/  229] train: loss: 0.2310151
[Epoch 15; Iter    64/  229] train: loss: 0.1893376
[Epoch 15; Iter    94/  229] train: loss: 0.1639043
[Epoch 15; Iter   124/  229] train: loss: 0.1343400
[Epoch 15; Iter   154/  229] train: loss: 0.1964341
[Epoch 15; Iter   184/  229] train: loss: 0.1754517
[Epoch 15; Iter   214/  229] train: loss: 0.1271142
[Epoch 15] ogbg-moltoxcast: 0.662862 val loss: 0.272350
[Epoch 15] ogbg-moltoxcast: 0.632226 test loss: 0.329404
[Epoch 16; Iter    15/  229] train: loss: 0.1856222
[Epoch 16; Iter    45/  229] train: loss: 0.1315894
[Epoch 16; Iter    75/  229] train: loss: 0.1777443
[Epoch 16; Iter   105/  229] train: loss: 0.1548282
[Epoch 16; Iter   135/  229] train: loss: 0.1817401
[Epoch 16; Iter   165/  229] train: loss: 0.1277844
[Epoch 16; Iter   195/  229] train: loss: 0.1746899
[Epoch 16; Iter   225/  229] train: loss: 0.2174491
[Epoch 16] ogbg-moltoxcast: 0.676063 val loss: 0.264573
[Epoch 16] ogbg-moltoxcast: 0.637553 test loss: 0.311095
[Epoch 17; Iter    26/  229] train: loss: 0.1645343
[Epoch 17; Iter    56/  229] train: loss: 0.1098695
[Epoch 17; Iter    86/  229] train: loss: 0.2365163
[Epoch 17; Iter   116/  229] train: loss: 0.2140009
[Epoch 17; Iter   146/  229] train: loss: 0.1799317
[Epoch 17; Iter   176/  229] train: loss: 0.2475363
[Epoch 17; Iter   206/  229] train: loss: 0.1511626
[Epoch 17] ogbg-moltoxcast: 0.683884 val loss: 0.265533
[Epoch 17] ogbg-moltoxcast: 0.642687 test loss: 0.317440
[Epoch 18; Iter     7/  229] train: loss: 0.1764107
[Epoch 18; Iter    37/  229] train: loss: 0.1843891
[Epoch 18; Iter    67/  229] train: loss: 0.1916483
[Epoch 18; Iter    97/  229] train: loss: 0.1482647
[Epoch 18; Iter   127/  229] train: loss: 0.1579159
[Epoch 18; Iter   157/  229] train: loss: 0.1740320
[Epoch 18; Iter   187/  229] train: loss: 0.1892687
[Epoch 18; Iter   217/  229] train: loss: 0.2345142
[Epoch 18] ogbg-moltoxcast: 0.669647 val loss: 0.267926
[Epoch 18] ogbg-moltoxcast: 0.648766 test loss: 0.324557
[Epoch 19; Iter    18/  229] train: loss: 0.1013455
[Epoch 19; Iter    48/  229] train: loss: 0.1796562
[Epoch 19; Iter    78/  229] train: loss: 0.1487630
[Epoch 19; Iter   108/  229] train: loss: 0.1410305
[Epoch 19; Iter   138/  229] train: loss: 0.1961462
[Epoch 19; Iter   168/  229] train: loss: 0.2167924
[Epoch 19; Iter   198/  229] train: loss: 0.1588954
[Epoch 19; Iter   228/  229] train: loss: 0.1875689
[Epoch 19] ogbg-moltoxcast: 0.672362 val loss: 0.271256
[Epoch 19] ogbg-moltoxcast: 0.645621 test loss: 0.312331
[Epoch 20; Iter    29/  229] train: loss: 0.1412811
[Epoch 20; Iter    59/  229] train: loss: 0.1687458
[Epoch 20; Iter    89/  229] train: loss: 0.2056319
[Epoch 20; Iter   119/  229] train: loss: 0.1385641
[Epoch 20; Iter   149/  229] train: loss: 0.1791582
[Epoch 20; Iter   179/  229] train: loss: 0.1831543
[Epoch 20; Iter   209/  229] train: loss: 0.1565167
[Epoch 20] ogbg-moltoxcast: 0.682888 val loss: 0.260982
[Epoch 20] ogbg-moltoxcast: 0.640897 test loss: 0.308872
[Epoch 21; Iter    10/  229] train: loss: 0.1784149
[Epoch 21; Iter    40/  229] train: loss: 0.1292283
[Epoch 21; Iter    70/  229] train: loss: 0.1933796
[Epoch 21; Iter   100/  229] train: loss: 0.1653578
[Epoch 21; Iter   130/  229] train: loss: 0.1928985
[Epoch 21; Iter   160/  229] train: loss: 0.1851531
[Epoch 21; Iter   190/  229] train: loss: 0.2126260
[Epoch 21; Iter   220/  229] train: loss: 0.1434683
[Epoch 21] ogbg-moltoxcast: 0.682425 val loss: 0.259295
[Epoch 21] ogbg-moltoxcast: 0.649836 test loss: 0.300703
[Epoch 22; Iter    21/  229] train: loss: 0.1199454
[Epoch 22; Iter    51/  229] train: loss: 0.2091868
[Epoch 22; Iter    81/  229] train: loss: 0.1276399
[Epoch 22; Iter   111/  229] train: loss: 0.1938021
[Epoch 22; Iter   141/  229] train: loss: 0.1450990
[Epoch 22; Iter   171/  229] train: loss: 0.1918834
[Epoch 22; Iter   201/  229] train: loss: 0.1239290
[Epoch 22] ogbg-moltoxcast: 0.680329 val loss: 0.261435
[Epoch 22] ogbg-moltoxcast: 0.649320 test loss: 0.303119
[Epoch 23; Iter     2/  229] train: loss: 0.1412976
[Epoch 23; Iter    32/  229] train: loss: 0.1567719
[Epoch 23; Iter    62/  229] train: loss: 0.1384812
[Epoch 23; Iter    92/  229] train: loss: 0.1160918
[Epoch 23; Iter   122/  229] train: loss: 0.1444488
[Epoch 23; Iter   152/  229] train: loss: 0.2353541
[Epoch 23; Iter   182/  229] train: loss: 0.1728660
[Epoch 23; Iter   212/  229] train: loss: 0.1403738
[Epoch 23] ogbg-moltoxcast: 0.678367 val loss: 0.265854
[Epoch 23] ogbg-moltoxcast: 0.644221 test loss: 0.312032
[Epoch 24; Iter    13/  229] train: loss: 0.1266348
[Epoch 24; Iter    43/  229] train: loss: 0.1767418
[Epoch 24; Iter    73/  229] train: loss: 0.1247478
[Epoch 24; Iter   103/  229] train: loss: 0.2281612
[Epoch 24; Iter   133/  229] train: loss: 0.1198679
[Epoch 24; Iter   163/  229] train: loss: 0.1342375
[Epoch 24; Iter   193/  229] train: loss: 0.1922915
[Epoch 24; Iter   223/  229] train: loss: 0.1454830
[Epoch 24] ogbg-moltoxcast: 0.681757 val loss: 0.269732
[Epoch 24] ogbg-moltoxcast: 0.646136 test loss: 0.324742
[Epoch 25; Iter    24/  229] train: loss: 0.0959842
[Epoch 25; Iter    54/  229] train: loss: 0.1053013
[Epoch 25; Iter    84/  229] train: loss: 0.1294712
[Epoch 25; Iter   114/  229] train: loss: 0.2237862
[Epoch 25; Iter   144/  229] train: loss: 0.1863400
[Epoch 25; Iter   174/  229] train: loss: 0.1421114
[Epoch 25; Iter   204/  229] train: loss: 0.1420346
[Epoch 25] ogbg-moltoxcast: 0.665787 val loss: 0.271511
[Epoch 25] ogbg-moltoxcast: 0.640048 test loss: 0.307810
[Epoch 26; Iter     5/  229] train: loss: 0.1653015
[Epoch 26; Iter    35/  229] train: loss: 0.1599616
[Epoch 26; Iter    65/  229] train: loss: 0.1587467
[Epoch 26; Iter    95/  229] train: loss: 0.1742804
[Epoch 26; Iter   125/  229] train: loss: 0.2045680
[Epoch 26; Iter   155/  229] train: loss: 0.1556685
[Epoch 26; Iter   185/  229] train: loss: 0.1191776
[Epoch 26; Iter   215/  229] train: loss: 0.1503556
[Epoch 26] ogbg-moltoxcast: 0.669311 val loss: 0.265798
[Epoch 26] ogbg-moltoxcast: 0.636367 test loss: 0.316213
[Epoch 27; Iter    16/  229] train: loss: 0.1124812
[Epoch 27; Iter    46/  229] train: loss: 0.1480183
[Epoch 27; Iter    76/  229] train: loss: 0.1399817
[Epoch 27; Iter   106/  229] train: loss: 0.0847349
[Epoch 27; Iter   136/  229] train: loss: 0.1877205
[Epoch 27; Iter   166/  229] train: loss: 0.1391136
[Epoch 27; Iter   196/  229] train: loss: 0.2032483
[Epoch 27; Iter   226/  229] train: loss: 0.1331260
[Epoch 27] ogbg-moltoxcast: 0.684145 val loss: 0.262693
[Epoch 27] ogbg-moltoxcast: 0.640415 test loss: 0.308479
[Epoch 12; Iter    31/  229] train: loss: 0.2083330
[Epoch 12; Iter    61/  229] train: loss: 0.1520710
[Epoch 12; Iter    91/  229] train: loss: 0.1969879
[Epoch 12; Iter   121/  229] train: loss: 0.2090858
[Epoch 12; Iter   151/  229] train: loss: 0.1192175
[Epoch 12; Iter   181/  229] train: loss: 0.2238795
[Epoch 12; Iter   211/  229] train: loss: 0.1846800
[Epoch 12] ogbg-moltoxcast: 0.656119 val loss: 0.280847
[Epoch 12] ogbg-moltoxcast: 0.631248 test loss: 0.308649
[Epoch 13; Iter    12/  229] train: loss: 0.1452190
[Epoch 13; Iter    42/  229] train: loss: 0.1428986
[Epoch 13; Iter    72/  229] train: loss: 0.1656467
[Epoch 13; Iter   102/  229] train: loss: 0.2604129
[Epoch 13; Iter   132/  229] train: loss: 0.2050357
[Epoch 13; Iter   162/  229] train: loss: 0.1631712
[Epoch 13; Iter   192/  229] train: loss: 0.1925039
[Epoch 13; Iter   222/  229] train: loss: 0.2374080
[Epoch 13] ogbg-moltoxcast: 0.658020 val loss: 0.263640
[Epoch 13] ogbg-moltoxcast: 0.624280 test loss: 0.303882
[Epoch 14; Iter    23/  229] train: loss: 0.1871872
[Epoch 14; Iter    53/  229] train: loss: 0.1844035
[Epoch 14; Iter    83/  229] train: loss: 0.2363664
[Epoch 14; Iter   113/  229] train: loss: 0.1734876
[Epoch 14; Iter   143/  229] train: loss: 0.1848611
[Epoch 14; Iter   173/  229] train: loss: 0.2091758
[Epoch 14; Iter   203/  229] train: loss: 0.1851641
[Epoch 14] ogbg-moltoxcast: 0.666869 val loss: 0.265550
[Epoch 14] ogbg-moltoxcast: 0.630396 test loss: 0.300789
[Epoch 15; Iter     4/  229] train: loss: 0.1751821
[Epoch 15; Iter    34/  229] train: loss: 0.1088412
[Epoch 15; Iter    64/  229] train: loss: 0.1804851
[Epoch 15; Iter    94/  229] train: loss: 0.2617483
[Epoch 15; Iter   124/  229] train: loss: 0.1637741
[Epoch 15; Iter   154/  229] train: loss: 0.1671691
[Epoch 15; Iter   184/  229] train: loss: 0.1643900
[Epoch 15; Iter   214/  229] train: loss: 0.2349121
[Epoch 15] ogbg-moltoxcast: 0.664473 val loss: 0.266161
[Epoch 15] ogbg-moltoxcast: 0.636032 test loss: 0.303753
[Epoch 16; Iter    15/  229] train: loss: 0.2777966
[Epoch 16; Iter    45/  229] train: loss: 0.1316955
[Epoch 16; Iter    75/  229] train: loss: 0.1239886
[Epoch 16; Iter   105/  229] train: loss: 0.1654672
[Epoch 16; Iter   135/  229] train: loss: 0.1605281
[Epoch 16; Iter   165/  229] train: loss: 0.1840797
[Epoch 16; Iter   195/  229] train: loss: 0.2044392
[Epoch 16; Iter   225/  229] train: loss: 0.1463937
[Epoch 16] ogbg-moltoxcast: 0.666174 val loss: 0.269566
[Epoch 16] ogbg-moltoxcast: 0.628112 test loss: 0.308970
[Epoch 17; Iter    26/  229] train: loss: 0.1622636
[Epoch 17; Iter    56/  229] train: loss: 0.2073553
[Epoch 17; Iter    86/  229] train: loss: 0.1485223
[Epoch 17; Iter   116/  229] train: loss: 0.1799359
[Epoch 17; Iter   146/  229] train: loss: 0.1720528
[Epoch 17; Iter   176/  229] train: loss: 0.2608626
[Epoch 17; Iter   206/  229] train: loss: 0.2069216
[Epoch 17] ogbg-moltoxcast: 0.675993 val loss: 0.262081
[Epoch 17] ogbg-moltoxcast: 0.648182 test loss: 0.321158
[Epoch 18; Iter     7/  229] train: loss: 0.1228092
[Epoch 18; Iter    37/  229] train: loss: 0.1763700
[Epoch 18; Iter    67/  229] train: loss: 0.1718571
[Epoch 18; Iter    97/  229] train: loss: 0.2708307
[Epoch 18; Iter   127/  229] train: loss: 0.1802891
[Epoch 18; Iter   157/  229] train: loss: 0.1953236
[Epoch 18; Iter   187/  229] train: loss: 0.1106760
[Epoch 18; Iter   217/  229] train: loss: 0.2036421
[Epoch 18] ogbg-moltoxcast: 0.664747 val loss: 0.264753
[Epoch 18] ogbg-moltoxcast: 0.634759 test loss: 0.306898
[Epoch 19; Iter    18/  229] train: loss: 0.2184885
[Epoch 19; Iter    48/  229] train: loss: 0.1797612
[Epoch 19; Iter    78/  229] train: loss: 0.1008901
[Epoch 19; Iter   108/  229] train: loss: 0.1552327
[Epoch 19; Iter   138/  229] train: loss: 0.1028803
[Epoch 19; Iter   168/  229] train: loss: 0.1919446
[Epoch 19; Iter   198/  229] train: loss: 0.1966355
[Epoch 19; Iter   228/  229] train: loss: 0.1461467
[Epoch 19] ogbg-moltoxcast: 0.658822 val loss: 0.266436
[Epoch 19] ogbg-moltoxcast: 0.636133 test loss: 0.312083
[Epoch 20; Iter    29/  229] train: loss: 0.1907030
[Epoch 20; Iter    59/  229] train: loss: 0.2059734
[Epoch 20; Iter    89/  229] train: loss: 0.1374617
[Epoch 20; Iter   119/  229] train: loss: 0.1576532
[Epoch 20; Iter   149/  229] train: loss: 0.2522022
[Epoch 20; Iter   179/  229] train: loss: 0.1204363
[Epoch 20; Iter   209/  229] train: loss: 0.1655042
[Epoch 20] ogbg-moltoxcast: 0.664332 val loss: 0.259889
[Epoch 20] ogbg-moltoxcast: 0.635892 test loss: 0.303475
[Epoch 21; Iter    10/  229] train: loss: 0.1892996
[Epoch 21; Iter    40/  229] train: loss: 0.1069886
[Epoch 21; Iter    70/  229] train: loss: 0.1917448
[Epoch 21; Iter   100/  229] train: loss: 0.2242167
[Epoch 21; Iter   130/  229] train: loss: 0.2033322
[Epoch 21; Iter   160/  229] train: loss: 0.1924749
[Epoch 21; Iter   190/  229] train: loss: 0.1437805
[Epoch 21; Iter   220/  229] train: loss: 0.1859429
[Epoch 21] ogbg-moltoxcast: 0.679422 val loss: 0.260063
[Epoch 21] ogbg-moltoxcast: 0.644592 test loss: 0.303804
[Epoch 22; Iter    21/  229] train: loss: 0.1510855
[Epoch 22; Iter    51/  229] train: loss: 0.1719234
[Epoch 22; Iter    81/  229] train: loss: 0.1491988
[Epoch 22; Iter   111/  229] train: loss: 0.1898743
[Epoch 22; Iter   141/  229] train: loss: 0.1388852
[Epoch 22; Iter   171/  229] train: loss: 0.1908502
[Epoch 22; Iter   201/  229] train: loss: 0.1499494
[Epoch 22] ogbg-moltoxcast: 0.653186 val loss: 0.263486
[Epoch 22] ogbg-moltoxcast: 0.644719 test loss: 0.301959
[Epoch 23; Iter     2/  229] train: loss: 0.1659037
[Epoch 23; Iter    32/  229] train: loss: 0.1227257
[Epoch 23; Iter    62/  229] train: loss: 0.0971306
[Epoch 23; Iter    92/  229] train: loss: 0.1100327
[Epoch 23; Iter   122/  229] train: loss: 0.1520478
[Epoch 23; Iter   152/  229] train: loss: 0.1082802
[Epoch 23; Iter   182/  229] train: loss: 0.1746457
[Epoch 23; Iter   212/  229] train: loss: 0.1908037
[Epoch 23] ogbg-moltoxcast: 0.674545 val loss: 0.259832
[Epoch 23] ogbg-moltoxcast: 0.648733 test loss: 0.301645
[Epoch 24; Iter    13/  229] train: loss: 0.1245887
[Epoch 24; Iter    43/  229] train: loss: 0.1979561
[Epoch 24; Iter    73/  229] train: loss: 0.1574587
[Epoch 24; Iter   103/  229] train: loss: 0.1715651
[Epoch 24; Iter   133/  229] train: loss: 0.2078677
[Epoch 24; Iter   163/  229] train: loss: 0.1773856
[Epoch 24; Iter   193/  229] train: loss: 0.1623924
[Epoch 24; Iter   223/  229] train: loss: 0.1204014
[Epoch 24] ogbg-moltoxcast: 0.658219 val loss: 0.276516
[Epoch 24] ogbg-moltoxcast: 0.639924 test loss: 0.318281
[Epoch 25; Iter    24/  229] train: loss: 0.1714387
[Epoch 25; Iter    54/  229] train: loss: 0.1818429
[Epoch 25; Iter    84/  229] train: loss: 0.1329351
[Epoch 25; Iter   114/  229] train: loss: 0.3023453
[Epoch 25; Iter   144/  229] train: loss: 0.1284163
[Epoch 25; Iter   174/  229] train: loss: 0.2283108
[Epoch 25; Iter   204/  229] train: loss: 0.1324599
[Epoch 25] ogbg-moltoxcast: 0.670814 val loss: 0.266272
[Epoch 25] ogbg-moltoxcast: 0.627392 test loss: 0.317799
[Epoch 26; Iter     5/  229] train: loss: 0.1341088
[Epoch 26; Iter    35/  229] train: loss: 0.1742219
[Epoch 26; Iter    65/  229] train: loss: 0.1111588
[Epoch 26; Iter    95/  229] train: loss: 0.1324312
[Epoch 26; Iter   125/  229] train: loss: 0.1583207
[Epoch 26; Iter   155/  229] train: loss: 0.1650590
[Epoch 26; Iter   185/  229] train: loss: 0.1580774
[Epoch 26; Iter   215/  229] train: loss: 0.1714119
[Epoch 26] ogbg-moltoxcast: 0.673102 val loss: 0.263796
[Epoch 26] ogbg-moltoxcast: 0.648838 test loss: 0.305468
[Epoch 27; Iter    16/  229] train: loss: 0.0733866
[Epoch 27; Iter    46/  229] train: loss: 0.1612580
[Epoch 27; Iter    76/  229] train: loss: 0.1393338
[Epoch 27; Iter   106/  229] train: loss: 0.1975377
[Epoch 27; Iter   136/  229] train: loss: 0.1575478
[Epoch 27; Iter   166/  229] train: loss: 0.2479843
[Epoch 27; Iter   196/  229] train: loss: 0.1789329
[Epoch 27; Iter   226/  229] train: loss: 0.1948267
[Epoch 27] ogbg-moltoxcast: 0.660590 val loss: 0.265008
[Epoch 27] ogbg-moltoxcast: 0.644571 test loss: 0.311320
[Epoch 12; Iter    31/  229] train: loss: 0.2307829
[Epoch 12; Iter    61/  229] train: loss: 0.2578849
[Epoch 12; Iter    91/  229] train: loss: 0.1485801
[Epoch 12; Iter   121/  229] train: loss: 0.1368227
[Epoch 12; Iter   151/  229] train: loss: 0.1665151
[Epoch 12; Iter   181/  229] train: loss: 0.2191679
[Epoch 12; Iter   211/  229] train: loss: 0.1298192
[Epoch 12] ogbg-moltoxcast: 0.654625 val loss: 0.312763
[Epoch 12] ogbg-moltoxcast: 0.628653 test loss: 0.683699
[Epoch 13; Iter    12/  229] train: loss: 0.1985973
[Epoch 13; Iter    42/  229] train: loss: 0.1932406
[Epoch 13; Iter    72/  229] train: loss: 0.1952000
[Epoch 13; Iter   102/  229] train: loss: 0.2143281
[Epoch 13; Iter   132/  229] train: loss: 0.2104724
[Epoch 13; Iter   162/  229] train: loss: 0.2155210
[Epoch 13; Iter   192/  229] train: loss: 0.2041783
[Epoch 13; Iter   222/  229] train: loss: 0.1350828
[Epoch 13] ogbg-moltoxcast: 0.664705 val loss: 0.564644
[Epoch 13] ogbg-moltoxcast: 0.632052 test loss: 1.852116
[Epoch 14; Iter    23/  229] train: loss: 0.2680421
[Epoch 14; Iter    53/  229] train: loss: 0.1433689
[Epoch 14; Iter    83/  229] train: loss: 0.1484165
[Epoch 14; Iter   113/  229] train: loss: 0.2038174
[Epoch 14; Iter   143/  229] train: loss: 0.1700287
[Epoch 14; Iter   173/  229] train: loss: 0.1735004
[Epoch 14; Iter   203/  229] train: loss: 0.1735913
[Epoch 14] ogbg-moltoxcast: 0.660606 val loss: 1.371856
[Epoch 14] ogbg-moltoxcast: 0.611400 test loss: 2.839104
[Epoch 15; Iter     4/  229] train: loss: 0.2867854
[Epoch 15; Iter    34/  229] train: loss: 0.1592446
[Epoch 15; Iter    64/  229] train: loss: 0.1291216
[Epoch 15; Iter    94/  229] train: loss: 0.2325318
[Epoch 15; Iter   124/  229] train: loss: 0.1622550
[Epoch 15; Iter   154/  229] train: loss: 0.2556012
[Epoch 15; Iter   184/  229] train: loss: 0.1952407
[Epoch 15; Iter   214/  229] train: loss: 0.1733046
[Epoch 15] ogbg-moltoxcast: 0.654545 val loss: 0.672418
[Epoch 15] ogbg-moltoxcast: 0.614053 test loss: 1.149335
[Epoch 16; Iter    15/  229] train: loss: 0.1389200
[Epoch 16; Iter    45/  229] train: loss: 0.2815194
[Epoch 16; Iter    75/  229] train: loss: 0.1944007
[Epoch 16; Iter   105/  229] train: loss: 0.1984897
[Epoch 16; Iter   135/  229] train: loss: 0.1611060
[Epoch 16; Iter   165/  229] train: loss: 0.1846884
[Epoch 16; Iter   195/  229] train: loss: 0.2281072
[Epoch 16; Iter   225/  229] train: loss: 0.1958748
[Epoch 16] ogbg-moltoxcast: 0.647096 val loss: 0.281975
[Epoch 16] ogbg-moltoxcast: 0.632231 test loss: 0.408176
[Epoch 17; Iter    26/  229] train: loss: 0.1407116
[Epoch 17; Iter    56/  229] train: loss: 0.1912121
[Epoch 17; Iter    86/  229] train: loss: 0.1122489
[Epoch 17; Iter   116/  229] train: loss: 0.1376920
[Epoch 17; Iter   146/  229] train: loss: 0.2221204
[Epoch 17; Iter   176/  229] train: loss: 0.1630443
[Epoch 17; Iter   206/  229] train: loss: 0.2018806
[Epoch 17] ogbg-moltoxcast: 0.670195 val loss: 0.668468
[Epoch 17] ogbg-moltoxcast: 0.629097 test loss: 3.141502
[Epoch 18; Iter     7/  229] train: loss: 0.1901225
[Epoch 18; Iter    37/  229] train: loss: 0.1893773
[Epoch 18; Iter    67/  229] train: loss: 0.1929787
[Epoch 18; Iter    97/  229] train: loss: 0.2674875
[Epoch 18; Iter   127/  229] train: loss: 0.1825990
[Epoch 18; Iter   157/  229] train: loss: 0.2127616
[Epoch 18; Iter   187/  229] train: loss: 0.2600634
[Epoch 18; Iter   217/  229] train: loss: 0.2258583
[Epoch 18] ogbg-moltoxcast: 0.653692 val loss: 0.305855
[Epoch 18] ogbg-moltoxcast: 0.631332 test loss: 0.471962
[Epoch 19; Iter    18/  229] train: loss: 0.1421648
[Epoch 19; Iter    48/  229] train: loss: 0.2333578
[Epoch 19; Iter    78/  229] train: loss: 0.2071632
[Epoch 19; Iter   108/  229] train: loss: 0.2047910
[Epoch 19; Iter   138/  229] train: loss: 0.1715677
[Epoch 19; Iter   168/  229] train: loss: 0.1571162
[Epoch 19; Iter   198/  229] train: loss: 0.2060286
[Epoch 19; Iter   228/  229] train: loss: 0.2669785
[Epoch 19] ogbg-moltoxcast: 0.670757 val loss: 0.579227
[Epoch 19] ogbg-moltoxcast: 0.633725 test loss: 2.793998
[Epoch 20; Iter    29/  229] train: loss: 0.1598752
[Epoch 20; Iter    59/  229] train: loss: 0.1416307
[Epoch 20; Iter    89/  229] train: loss: 0.2500903
[Epoch 20; Iter   119/  229] train: loss: 0.1534524
[Epoch 20; Iter   149/  229] train: loss: 0.2350591
[Epoch 20; Iter   179/  229] train: loss: 0.1591501
[Epoch 20; Iter   209/  229] train: loss: 0.1789337
[Epoch 20] ogbg-moltoxcast: 0.667915 val loss: 0.914516
[Epoch 20] ogbg-moltoxcast: 0.634676 test loss: 0.508299
[Epoch 21; Iter    10/  229] train: loss: 0.1988774
[Epoch 21; Iter    40/  229] train: loss: 0.2093966
[Epoch 21; Iter    70/  229] train: loss: 0.2222094
[Epoch 21; Iter   100/  229] train: loss: 0.1782779
[Epoch 21; Iter   130/  229] train: loss: 0.2000262
[Epoch 21; Iter   160/  229] train: loss: 0.1888745
[Epoch 21; Iter   190/  229] train: loss: 0.2230461
[Epoch 21; Iter   220/  229] train: loss: 0.1172432
[Epoch 21] ogbg-moltoxcast: 0.657777 val loss: 0.284501
[Epoch 21] ogbg-moltoxcast: 0.640270 test loss: 0.378332
[Epoch 22; Iter    21/  229] train: loss: 0.0952148
[Epoch 22; Iter    51/  229] train: loss: 0.2364298
[Epoch 22; Iter    81/  229] train: loss: 0.1363550
[Epoch 22; Iter   111/  229] train: loss: 0.2271138
[Epoch 22; Iter   141/  229] train: loss: 0.2383936
[Epoch 22; Iter   171/  229] train: loss: 0.1449869
[Epoch 22; Iter   201/  229] train: loss: 0.1653466
[Epoch 22] ogbg-moltoxcast: 0.678091 val loss: 0.538587
[Epoch 22] ogbg-moltoxcast: 0.642811 test loss: 2.668493
[Epoch 23; Iter     2/  229] train: loss: 0.2551245
[Epoch 23; Iter    32/  229] train: loss: 0.1270976
[Epoch 23; Iter    62/  229] train: loss: 0.1695011
[Epoch 23; Iter    92/  229] train: loss: 0.1497602
[Epoch 23; Iter   122/  229] train: loss: 0.1652389
[Epoch 23; Iter   152/  229] train: loss: 0.2948719
[Epoch 23; Iter   182/  229] train: loss: 0.1847100
[Epoch 23; Iter   212/  229] train: loss: 0.1514893
[Epoch 23] ogbg-moltoxcast: 0.666182 val loss: 0.724570
[Epoch 23] ogbg-moltoxcast: 0.636798 test loss: 3.756748
[Epoch 24; Iter    13/  229] train: loss: 0.1922952
[Epoch 24; Iter    43/  229] train: loss: 0.1543553
[Epoch 24; Iter    73/  229] train: loss: 0.1277811
[Epoch 24; Iter   103/  229] train: loss: 0.1420815
[Epoch 24; Iter   133/  229] train: loss: 0.2009341
[Epoch 24; Iter   163/  229] train: loss: 0.2191976
[Epoch 24; Iter   193/  229] train: loss: 0.1446019
[Epoch 24; Iter   223/  229] train: loss: 0.1694646
[Epoch 24] ogbg-moltoxcast: 0.662226 val loss: 1.051438
[Epoch 24] ogbg-moltoxcast: 0.635111 test loss: 3.496113
[Epoch 25; Iter    24/  229] train: loss: 0.2541139
[Epoch 25; Iter    54/  229] train: loss: 0.1762044
[Epoch 25; Iter    84/  229] train: loss: 0.2204278
[Epoch 25; Iter   114/  229] train: loss: 0.1809615
[Epoch 25; Iter   144/  229] train: loss: 0.1124282
[Epoch 25; Iter   174/  229] train: loss: 0.1567948
[Epoch 25; Iter   204/  229] train: loss: 0.1660572
[Epoch 25] ogbg-moltoxcast: 0.681901 val loss: 0.405619
[Epoch 25] ogbg-moltoxcast: 0.644876 test loss: 3.317177
[Epoch 26; Iter     5/  229] train: loss: 0.1392585
[Epoch 26; Iter    35/  229] train: loss: 0.2615208
[Epoch 26; Iter    65/  229] train: loss: 0.2059706
[Epoch 26; Iter    95/  229] train: loss: 0.1960043
[Epoch 26; Iter   125/  229] train: loss: 0.1493456
[Epoch 26; Iter   155/  229] train: loss: 0.1571439
[Epoch 26; Iter   185/  229] train: loss: 0.1639949
[Epoch 26; Iter   215/  229] train: loss: 0.1119412
[Epoch 26] ogbg-moltoxcast: 0.660056 val loss: 0.385884
[Epoch 26] ogbg-moltoxcast: 0.645328 test loss: 0.453055
[Epoch 27; Iter    16/  229] train: loss: 0.1753472
[Epoch 27; Iter    46/  229] train: loss: 0.1830052
[Epoch 27; Iter    76/  229] train: loss: 0.1444172
[Epoch 27; Iter   106/  229] train: loss: 0.1893491
[Epoch 27; Iter   136/  229] train: loss: 0.1946497
[Epoch 27; Iter   166/  229] train: loss: 0.1162521
[Epoch 27; Iter   196/  229] train: loss: 0.1330237
[Epoch 27; Iter   226/  229] train: loss: 0.1862054
[Epoch 27] ogbg-moltoxcast: 0.670310 val loss: 0.840883
[Epoch 27] ogbg-moltoxcast: 0.646329 test loss: 2.349349
[Epoch 12; Iter    31/  229] train: loss: 0.2168102
[Epoch 12; Iter    61/  229] train: loss: 0.2681032
[Epoch 12; Iter    91/  229] train: loss: 0.1567775
[Epoch 12; Iter   121/  229] train: loss: 0.1379983
[Epoch 12; Iter   151/  229] train: loss: 0.1548345
[Epoch 12; Iter   181/  229] train: loss: 0.1941655
[Epoch 12; Iter   211/  229] train: loss: 0.1445913
[Epoch 12] ogbg-moltoxcast: 0.659838 val loss: 1.986584
[Epoch 12] ogbg-moltoxcast: 0.624493 test loss: 2.728955
[Epoch 13; Iter    12/  229] train: loss: 0.2126297
[Epoch 13; Iter    42/  229] train: loss: 0.2036006
[Epoch 13; Iter    72/  229] train: loss: 0.1957562
[Epoch 13; Iter   102/  229] train: loss: 0.2164255
[Epoch 13; Iter   132/  229] train: loss: 0.2179216
[Epoch 13; Iter   162/  229] train: loss: 0.1945552
[Epoch 13; Iter   192/  229] train: loss: 0.2078627
[Epoch 13; Iter   222/  229] train: loss: 0.1461449
[Epoch 13] ogbg-moltoxcast: 0.670657 val loss: 0.553132
[Epoch 13] ogbg-moltoxcast: 0.622174 test loss: 1.131972
[Epoch 14; Iter    23/  229] train: loss: 0.2824520
[Epoch 14; Iter    53/  229] train: loss: 0.1435094
[Epoch 14; Iter    83/  229] train: loss: 0.1496097
[Epoch 14; Iter   113/  229] train: loss: 0.1905521
[Epoch 14; Iter   143/  229] train: loss: 0.1699810
[Epoch 14; Iter   173/  229] train: loss: 0.1949706
[Epoch 14; Iter   203/  229] train: loss: 0.1736886
[Epoch 14] ogbg-moltoxcast: 0.644657 val loss: 0.666715
[Epoch 14] ogbg-moltoxcast: 0.621316 test loss: 1.906379
[Epoch 15; Iter     4/  229] train: loss: 0.2874230
[Epoch 15; Iter    34/  229] train: loss: 0.1546872
[Epoch 15; Iter    64/  229] train: loss: 0.1257537
[Epoch 15; Iter    94/  229] train: loss: 0.2224496
[Epoch 15; Iter   124/  229] train: loss: 0.1655484
[Epoch 15; Iter   154/  229] train: loss: 0.2713752
[Epoch 15; Iter   184/  229] train: loss: 0.1981448
[Epoch 15; Iter   214/  229] train: loss: 0.1663520
[Epoch 15] ogbg-moltoxcast: 0.653176 val loss: 0.812002
[Epoch 15] ogbg-moltoxcast: 0.623617 test loss: 2.727719
[Epoch 16; Iter    15/  229] train: loss: 0.1248546
[Epoch 16; Iter    45/  229] train: loss: 0.1838641
[Epoch 16; Iter    75/  229] train: loss: 0.1638516
[Epoch 16; Iter   105/  229] train: loss: 0.2168796
[Epoch 16; Iter   135/  229] train: loss: 0.1284274
[Epoch 16; Iter   165/  229] train: loss: 0.1788187
[Epoch 16; Iter   195/  229] train: loss: 0.2194097
[Epoch 16; Iter   225/  229] train: loss: 0.1766638
[Epoch 16] ogbg-moltoxcast: 0.671240 val loss: 0.612900
[Epoch 16] ogbg-moltoxcast: 0.641845 test loss: 1.874475
[Epoch 17; Iter    26/  229] train: loss: 0.1338470
[Epoch 17; Iter    56/  229] train: loss: 0.1838047
[Epoch 17; Iter    86/  229] train: loss: 0.1009438
[Epoch 17; Iter   116/  229] train: loss: 0.1205042
[Epoch 17; Iter   146/  229] train: loss: 0.1886381
[Epoch 17; Iter   176/  229] train: loss: 0.1618954
[Epoch 17; Iter   206/  229] train: loss: 0.2065835
[Epoch 17] ogbg-moltoxcast: 0.669276 val loss: 1.414701
[Epoch 17] ogbg-moltoxcast: 0.632267 test loss: 3.838671
[Epoch 18; Iter     7/  229] train: loss: 0.1889810
[Epoch 18; Iter    37/  229] train: loss: 0.1865494
[Epoch 18; Iter    67/  229] train: loss: 0.1842080
[Epoch 18; Iter    97/  229] train: loss: 0.3064497
[Epoch 18; Iter   127/  229] train: loss: 0.1680629
[Epoch 18; Iter   157/  229] train: loss: 0.1799935
[Epoch 18; Iter   187/  229] train: loss: 0.2452433
[Epoch 18; Iter   217/  229] train: loss: 0.2119773
[Epoch 18] ogbg-moltoxcast: 0.639447 val loss: 0.706421
[Epoch 18] ogbg-moltoxcast: 0.638921 test loss: 2.027177
[Epoch 19; Iter    18/  229] train: loss: 0.1194276
[Epoch 19; Iter    48/  229] train: loss: 0.2256971
[Epoch 19; Iter    78/  229] train: loss: 0.2084434
[Epoch 19; Iter   108/  229] train: loss: 0.1718754
[Epoch 19; Iter   138/  229] train: loss: 0.1756078
[Epoch 19; Iter   168/  229] train: loss: 0.1523183
[Epoch 19; Iter   198/  229] train: loss: 0.2353667
[Epoch 19; Iter   228/  229] train: loss: 0.2556728
[Epoch 19] ogbg-moltoxcast: 0.648994 val loss: 0.342113
[Epoch 19] ogbg-moltoxcast: 0.633398 test loss: 0.571438
[Epoch 20; Iter    29/  229] train: loss: 0.1575751
[Epoch 20; Iter    59/  229] train: loss: 0.1295707
[Epoch 20; Iter    89/  229] train: loss: 0.2215448
[Epoch 20; Iter   119/  229] train: loss: 0.1358248
[Epoch 20; Iter   149/  229] train: loss: 0.2228181
[Epoch 20; Iter   179/  229] train: loss: 0.1788154
[Epoch 20; Iter   209/  229] train: loss: 0.1560541
[Epoch 20] ogbg-moltoxcast: 0.677133 val loss: 0.264261
[Epoch 20] ogbg-moltoxcast: 0.630350 test loss: 0.306813
[Epoch 21; Iter    10/  229] train: loss: 0.2037933
[Epoch 21; Iter    40/  229] train: loss: 0.2019669
[Epoch 21; Iter    70/  229] train: loss: 0.2154550
[Epoch 21; Iter   100/  229] train: loss: 0.2012681
[Epoch 21; Iter   130/  229] train: loss: 0.1760470
[Epoch 21; Iter   160/  229] train: loss: 0.1972878
[Epoch 21; Iter   190/  229] train: loss: 0.1713553
[Epoch 21; Iter   220/  229] train: loss: 0.1258984
[Epoch 21] ogbg-moltoxcast: 0.681485 val loss: 0.594042
[Epoch 21] ogbg-moltoxcast: 0.636672 test loss: 1.526906
[Epoch 22; Iter    21/  229] train: loss: 0.1005188
[Epoch 22; Iter    51/  229] train: loss: 0.2078141
[Epoch 22; Iter    81/  229] train: loss: 0.1153224
[Epoch 22; Iter   111/  229] train: loss: 0.1961839
[Epoch 22; Iter   141/  229] train: loss: 0.2351450
[Epoch 22; Iter   171/  229] train: loss: 0.1335279
[Epoch 22; Iter   201/  229] train: loss: 0.1538691
[Epoch 22] ogbg-moltoxcast: 0.682166 val loss: 0.537113
[Epoch 22] ogbg-moltoxcast: 0.645800 test loss: 1.326346
[Epoch 23; Iter     2/  229] train: loss: 0.2376325
[Epoch 23; Iter    32/  229] train: loss: 0.1094134
[Epoch 23; Iter    62/  229] train: loss: 0.1689958
[Epoch 23; Iter    92/  229] train: loss: 0.1654621
[Epoch 23; Iter   122/  229] train: loss: 0.1511553
[Epoch 23; Iter   152/  229] train: loss: 0.2867123
[Epoch 23; Iter   182/  229] train: loss: 0.1687156
[Epoch 23; Iter   212/  229] train: loss: 0.1332469
[Epoch 23] ogbg-moltoxcast: 0.672031 val loss: 0.294777
[Epoch 23] ogbg-moltoxcast: 0.656947 test loss: 0.459062
[Epoch 24; Iter    13/  229] train: loss: 0.1751943
[Epoch 24; Iter    43/  229] train: loss: 0.1525276
[Epoch 24; Iter    73/  229] train: loss: 0.1195431
[Epoch 24; Iter   103/  229] train: loss: 0.1405877
[Epoch 24; Iter   133/  229] train: loss: 0.2000715
[Epoch 24; Iter   163/  229] train: loss: 0.2128739
[Epoch 24; Iter   193/  229] train: loss: 0.1229232
[Epoch 24; Iter   223/  229] train: loss: 0.1527933
[Epoch 24] ogbg-moltoxcast: 0.662687 val loss: 0.320339
[Epoch 24] ogbg-moltoxcast: 0.649787 test loss: 0.494086
[Epoch 25; Iter    24/  229] train: loss: 0.2132933
[Epoch 25; Iter    54/  229] train: loss: 0.1651340
[Epoch 25; Iter    84/  229] train: loss: 0.2135121
[Epoch 25; Iter   114/  229] train: loss: 0.1781901
[Epoch 25; Iter   144/  229] train: loss: 0.1014938
[Epoch 25; Iter   174/  229] train: loss: 0.1408864
[Epoch 25; Iter   204/  229] train: loss: 0.1567609
[Epoch 25] ogbg-moltoxcast: 0.660824 val loss: 0.271146
[Epoch 25] ogbg-moltoxcast: 0.656805 test loss: 0.357906
[Epoch 26; Iter     5/  229] train: loss: 0.1342939
[Epoch 26; Iter    35/  229] train: loss: 0.2370200
[Epoch 26; Iter    65/  229] train: loss: 0.1809039
[Epoch 26; Iter    95/  229] train: loss: 0.1733859
[Epoch 26; Iter   125/  229] train: loss: 0.1683022
[Epoch 26; Iter   155/  229] train: loss: 0.1550651
[Epoch 26; Iter   185/  229] train: loss: 0.1559573
[Epoch 26; Iter   215/  229] train: loss: 0.1079503
[Epoch 26] ogbg-moltoxcast: 0.663416 val loss: 0.423291
[Epoch 26] ogbg-moltoxcast: 0.644855 test loss: 0.878663
[Epoch 27; Iter    16/  229] train: loss: 0.1623488
[Epoch 27; Iter    46/  229] train: loss: 0.1645273
[Epoch 27; Iter    76/  229] train: loss: 0.1297587
[Epoch 27; Iter   106/  229] train: loss: 0.1903664
[Epoch 27; Iter   136/  229] train: loss: 0.1882428
[Epoch 27; Iter   166/  229] train: loss: 0.1300220
[Epoch 27; Iter   196/  229] train: loss: 0.1312917
[Epoch 27; Iter   226/  229] train: loss: 0.1647767
[Epoch 27] ogbg-moltoxcast: 0.671928 val loss: 0.509200
[Epoch 27] ogbg-moltoxcast: 0.649575 test loss: 1.186848
[Epoch 12; Iter    31/  229] train: loss: 0.2115136
[Epoch 12; Iter    61/  229] train: loss: 0.1753102
[Epoch 12; Iter    91/  229] train: loss: 0.1587633
[Epoch 12; Iter   121/  229] train: loss: 0.3631904
[Epoch 12; Iter   151/  229] train: loss: 0.1971083
[Epoch 12; Iter   181/  229] train: loss: 0.2313827
[Epoch 12; Iter   211/  229] train: loss: 0.3354326
[Epoch 12] ogbg-moltoxcast: 0.661086 val loss: 0.266317
[Epoch 12] ogbg-moltoxcast: 0.626017 test loss: 0.307087
[Epoch 13; Iter    12/  229] train: loss: 0.2495683
[Epoch 13; Iter    42/  229] train: loss: 0.1960468
[Epoch 13; Iter    72/  229] train: loss: 0.1854369
[Epoch 13; Iter   102/  229] train: loss: 0.2044419
[Epoch 13; Iter   132/  229] train: loss: 0.1376149
[Epoch 13; Iter   162/  229] train: loss: 0.2463479
[Epoch 13; Iter   192/  229] train: loss: 0.1463031
[Epoch 13; Iter   222/  229] train: loss: 0.1833671
[Epoch 13] ogbg-moltoxcast: 0.654954 val loss: 0.327571
[Epoch 13] ogbg-moltoxcast: 0.591192 test loss: 0.477352
[Epoch 14; Iter    23/  229] train: loss: 0.1797088
[Epoch 14; Iter    53/  229] train: loss: 0.1504750
[Epoch 14; Iter    83/  229] train: loss: 0.1819592
[Epoch 14; Iter   113/  229] train: loss: 0.1505510
[Epoch 14; Iter   143/  229] train: loss: 0.2414489
[Epoch 14; Iter   173/  229] train: loss: 0.1261109
[Epoch 14; Iter   203/  229] train: loss: 0.1937442
[Epoch 14] ogbg-moltoxcast: 0.673191 val loss: 0.265734
[Epoch 14] ogbg-moltoxcast: 0.617639 test loss: 0.374777
[Epoch 15; Iter     4/  229] train: loss: 0.1585985
[Epoch 15; Iter    34/  229] train: loss: 0.2212234
[Epoch 15; Iter    64/  229] train: loss: 0.1901876
[Epoch 15; Iter    94/  229] train: loss: 0.1519025
[Epoch 15; Iter   124/  229] train: loss: 0.1334078
[Epoch 15; Iter   154/  229] train: loss: 0.2036906
[Epoch 15; Iter   184/  229] train: loss: 0.1647109
[Epoch 15; Iter   214/  229] train: loss: 0.1232535
[Epoch 15] ogbg-moltoxcast: 0.641557 val loss: 0.289254
[Epoch 15] ogbg-moltoxcast: 0.614512 test loss: 0.345436
[Epoch 16; Iter    15/  229] train: loss: 0.1793720
[Epoch 16; Iter    45/  229] train: loss: 0.1281969
[Epoch 16; Iter    75/  229] train: loss: 0.1709650
[Epoch 16; Iter   105/  229] train: loss: 0.1716606
[Epoch 16; Iter   135/  229] train: loss: 0.1797002
[Epoch 16; Iter   165/  229] train: loss: 0.1172901
[Epoch 16; Iter   195/  229] train: loss: 0.1822851
[Epoch 16; Iter   225/  229] train: loss: 0.2472733
[Epoch 16] ogbg-moltoxcast: 0.654982 val loss: 0.367894
[Epoch 16] ogbg-moltoxcast: 0.612777 test loss: 0.711489
[Epoch 17; Iter    26/  229] train: loss: 0.1776042
[Epoch 17; Iter    56/  229] train: loss: 0.1096224
[Epoch 17; Iter    86/  229] train: loss: 0.2404583
[Epoch 17; Iter   116/  229] train: loss: 0.2030248
[Epoch 17; Iter   146/  229] train: loss: 0.1699525
[Epoch 17; Iter   176/  229] train: loss: 0.2428661
[Epoch 17; Iter   206/  229] train: loss: 0.1437217
[Epoch 17] ogbg-moltoxcast: 0.678347 val loss: 0.263661
[Epoch 17] ogbg-moltoxcast: 0.635567 test loss: 0.319602
[Epoch 18; Iter     7/  229] train: loss: 0.1745650
[Epoch 18; Iter    37/  229] train: loss: 0.1884316
[Epoch 18; Iter    67/  229] train: loss: 0.1729289
[Epoch 18; Iter    97/  229] train: loss: 0.1275949
[Epoch 18; Iter   127/  229] train: loss: 0.1633937
[Epoch 18; Iter   157/  229] train: loss: 0.1710491
[Epoch 18; Iter   187/  229] train: loss: 0.1827538
[Epoch 18; Iter   217/  229] train: loss: 0.2391036
[Epoch 18] ogbg-moltoxcast: 0.653678 val loss: 0.269703
[Epoch 18] ogbg-moltoxcast: 0.638417 test loss: 0.317760
[Epoch 19; Iter    18/  229] train: loss: 0.1032946
[Epoch 19; Iter    48/  229] train: loss: 0.1517156
[Epoch 19; Iter    78/  229] train: loss: 0.1409062
[Epoch 19; Iter   108/  229] train: loss: 0.1426867
[Epoch 19; Iter   138/  229] train: loss: 0.1919143
[Epoch 19; Iter   168/  229] train: loss: 0.2263836
[Epoch 19; Iter   198/  229] train: loss: 0.1610171
[Epoch 19; Iter   228/  229] train: loss: 0.1861269
[Epoch 19] ogbg-moltoxcast: 0.653861 val loss: 0.273856
[Epoch 19] ogbg-moltoxcast: 0.634888 test loss: 0.317931
[Epoch 20; Iter    29/  229] train: loss: 0.1334319
[Epoch 20; Iter    59/  229] train: loss: 0.1851380
[Epoch 20; Iter    89/  229] train: loss: 0.2020425
[Epoch 20; Iter   119/  229] train: loss: 0.1269549
[Epoch 20; Iter   149/  229] train: loss: 0.1761615
[Epoch 20; Iter   179/  229] train: loss: 0.1882637
[Epoch 20; Iter   209/  229] train: loss: 0.1529880
[Epoch 20] ogbg-moltoxcast: 0.668035 val loss: 0.271856
[Epoch 20] ogbg-moltoxcast: 0.631653 test loss: 0.320787
[Epoch 21; Iter    10/  229] train: loss: 0.1994071
[Epoch 21; Iter    40/  229] train: loss: 0.1374406
[Epoch 21; Iter    70/  229] train: loss: 0.1904517
[Epoch 21; Iter   100/  229] train: loss: 0.1564701
[Epoch 21; Iter   130/  229] train: loss: 0.2001481
[Epoch 21; Iter   160/  229] train: loss: 0.1929842
[Epoch 21; Iter   190/  229] train: loss: 0.2047573
[Epoch 21; Iter   220/  229] train: loss: 0.1492856
[Epoch 21] ogbg-moltoxcast: 0.652196 val loss: 0.259547
[Epoch 21] ogbg-moltoxcast: 0.617919 test loss: 0.303868
[Epoch 22; Iter    21/  229] train: loss: 0.1094623
[Epoch 22; Iter    51/  229] train: loss: 0.2139214
[Epoch 22; Iter    81/  229] train: loss: 0.1455689
[Epoch 22; Iter   111/  229] train: loss: 0.2015209
[Epoch 22; Iter   141/  229] train: loss: 0.1764359
[Epoch 22; Iter   171/  229] train: loss: 0.2116546
[Epoch 22; Iter   201/  229] train: loss: 0.1014082
[Epoch 22] ogbg-moltoxcast: 0.676957 val loss: 0.260215
[Epoch 22] ogbg-moltoxcast: 0.632803 test loss: 0.305959
[Epoch 23; Iter     2/  229] train: loss: 0.1369136
[Epoch 23; Iter    32/  229] train: loss: 0.1655051
[Epoch 23; Iter    62/  229] train: loss: 0.1508217
[Epoch 23; Iter    92/  229] train: loss: 0.1335129
[Epoch 23; Iter   122/  229] train: loss: 0.1618713
[Epoch 23; Iter   152/  229] train: loss: 0.2424012
[Epoch 23; Iter   182/  229] train: loss: 0.1630329
[Epoch 23; Iter   212/  229] train: loss: 0.1450619
[Epoch 23] ogbg-moltoxcast: 0.674396 val loss: 0.269193
[Epoch 23] ogbg-moltoxcast: 0.641338 test loss: 0.310785
[Epoch 24; Iter    13/  229] train: loss: 0.1417019
[Epoch 24; Iter    43/  229] train: loss: 0.1997803
[Epoch 24; Iter    73/  229] train: loss: 0.1105564
[Epoch 24; Iter   103/  229] train: loss: 0.2286203
[Epoch 24; Iter   133/  229] train: loss: 0.1149166
[Epoch 24; Iter   163/  229] train: loss: 0.1387875
[Epoch 24; Iter   193/  229] train: loss: 0.1932001
[Epoch 24; Iter   223/  229] train: loss: 0.1321310
[Epoch 24] ogbg-moltoxcast: 0.655346 val loss: 0.275630
[Epoch 24] ogbg-moltoxcast: 0.638936 test loss: 0.321944
[Epoch 25; Iter    24/  229] train: loss: 0.1102103
[Epoch 25; Iter    54/  229] train: loss: 0.1056568
[Epoch 25; Iter    84/  229] train: loss: 0.1279592
[Epoch 25; Iter   114/  229] train: loss: 0.2275120
[Epoch 25; Iter   144/  229] train: loss: 0.1843004
[Epoch 25; Iter   174/  229] train: loss: 0.1293837
[Epoch 25; Iter   204/  229] train: loss: 0.1379716
[Epoch 25] ogbg-moltoxcast: 0.668464 val loss: 0.292290
[Epoch 25] ogbg-moltoxcast: 0.647392 test loss: 0.342498
[Epoch 26; Iter     5/  229] train: loss: 0.1536748
[Epoch 26; Iter    35/  229] train: loss: 0.1434057
[Epoch 26; Iter    65/  229] train: loss: 0.1664296
[Epoch 26; Iter    95/  229] train: loss: 0.1902113
[Epoch 26; Iter   125/  229] train: loss: 0.2099159
[Epoch 26; Iter   155/  229] train: loss: 0.1564785
[Epoch 26; Iter   185/  229] train: loss: 0.1130584
[Epoch 26; Iter   215/  229] train: loss: 0.1468562
[Epoch 26] ogbg-moltoxcast: 0.667926 val loss: 0.269583
[Epoch 26] ogbg-moltoxcast: 0.642537 test loss: 0.315097
[Epoch 27; Iter    16/  229] train: loss: 0.1119873
[Epoch 27; Iter    46/  229] train: loss: 0.1432168
[Epoch 27; Iter    76/  229] train: loss: 0.1382625
[Epoch 27; Iter   106/  229] train: loss: 0.0817287
[Epoch 27; Iter   136/  229] train: loss: 0.1883975
[Epoch 27; Iter   166/  229] train: loss: 0.1395248
[Epoch 27; Iter   196/  229] train: loss: 0.1963291
[Epoch 27; Iter   226/  229] train: loss: 0.1346796
[Epoch 27] ogbg-moltoxcast: 0.660953 val loss: 0.272986
[Epoch 27] ogbg-moltoxcast: 0.640722 test loss: 0.317714
[Epoch 12; Iter    31/  229] train: loss: 0.2153873
[Epoch 12; Iter    61/  229] train: loss: 0.1471527
[Epoch 12; Iter    91/  229] train: loss: 0.1978043
[Epoch 12; Iter   121/  229] train: loss: 0.2203024
[Epoch 12; Iter   151/  229] train: loss: 0.1133553
[Epoch 12; Iter   181/  229] train: loss: 0.2174402
[Epoch 12; Iter   211/  229] train: loss: 0.1942100
[Epoch 12] ogbg-moltoxcast: 0.669237 val loss: 0.344570
[Epoch 12] ogbg-moltoxcast: 0.627087 test loss: 0.467666
[Epoch 13; Iter    12/  229] train: loss: 0.1366870
[Epoch 13; Iter    42/  229] train: loss: 0.1340195
[Epoch 13; Iter    72/  229] train: loss: 0.1679420
[Epoch 13; Iter   102/  229] train: loss: 0.2509039
[Epoch 13; Iter   132/  229] train: loss: 0.2151652
[Epoch 13; Iter   162/  229] train: loss: 0.1631988
[Epoch 13; Iter   192/  229] train: loss: 0.1837862
[Epoch 13; Iter   222/  229] train: loss: 0.2165145
[Epoch 13] ogbg-moltoxcast: 0.664102 val loss: 0.329982
[Epoch 13] ogbg-moltoxcast: 0.633483 test loss: 0.366086
[Epoch 14; Iter    23/  229] train: loss: 0.1941782
[Epoch 14; Iter    53/  229] train: loss: 0.1872333
[Epoch 14; Iter    83/  229] train: loss: 0.2382022
[Epoch 14; Iter   113/  229] train: loss: 0.1917154
[Epoch 14; Iter   143/  229] train: loss: 0.1996638
[Epoch 14; Iter   173/  229] train: loss: 0.2066857
[Epoch 14; Iter   203/  229] train: loss: 0.1865219
[Epoch 14] ogbg-moltoxcast: 0.666222 val loss: 0.298944
[Epoch 14] ogbg-moltoxcast: 0.634946 test loss: 0.708771
[Epoch 15; Iter     4/  229] train: loss: 0.1744268
[Epoch 15; Iter    34/  229] train: loss: 0.1079252
[Epoch 15; Iter    64/  229] train: loss: 0.1703256
[Epoch 15; Iter    94/  229] train: loss: 0.2808888
[Epoch 15; Iter   124/  229] train: loss: 0.1631378
[Epoch 15; Iter   154/  229] train: loss: 0.1606287
[Epoch 15; Iter   184/  229] train: loss: 0.1634208
[Epoch 15; Iter   214/  229] train: loss: 0.2088999
[Epoch 15] ogbg-moltoxcast: 0.670619 val loss: 0.350233
[Epoch 15] ogbg-moltoxcast: 0.624860 test loss: 0.422165
[Epoch 16; Iter    15/  229] train: loss: 0.2529669
[Epoch 16; Iter    45/  229] train: loss: 0.1284645
[Epoch 16; Iter    75/  229] train: loss: 0.1227351
[Epoch 16; Iter   105/  229] train: loss: 0.1682424
[Epoch 16; Iter   135/  229] train: loss: 0.1690491
[Epoch 16; Iter   165/  229] train: loss: 0.1864442
[Epoch 16; Iter   195/  229] train: loss: 0.1996434
[Epoch 16; Iter   225/  229] train: loss: 0.1359652
[Epoch 16] ogbg-moltoxcast: 0.671209 val loss: 0.281509
[Epoch 16] ogbg-moltoxcast: 0.638592 test loss: 0.831192
[Epoch 17; Iter    26/  229] train: loss: 0.1586906
[Epoch 17; Iter    56/  229] train: loss: 0.1987412
[Epoch 17; Iter    86/  229] train: loss: 0.1520366
[Epoch 17; Iter   116/  229] train: loss: 0.1641065
[Epoch 17; Iter   146/  229] train: loss: 0.1734997
[Epoch 17; Iter   176/  229] train: loss: 0.2653022
[Epoch 17; Iter   206/  229] train: loss: 0.2000153
[Epoch 17] ogbg-moltoxcast: 0.664722 val loss: 0.309255
[Epoch 17] ogbg-moltoxcast: 0.642780 test loss: 1.228905
[Epoch 18; Iter     7/  229] train: loss: 0.1187885
[Epoch 18; Iter    37/  229] train: loss: 0.1797912
[Epoch 18; Iter    67/  229] train: loss: 0.1657483
[Epoch 18; Iter    97/  229] train: loss: 0.2795978
[Epoch 18; Iter   127/  229] train: loss: 0.1668636
[Epoch 18; Iter   157/  229] train: loss: 0.1830161
[Epoch 18; Iter   187/  229] train: loss: 0.1039288
[Epoch 18; Iter   217/  229] train: loss: 0.2212994
[Epoch 18] ogbg-moltoxcast: 0.656807 val loss: 0.372151
[Epoch 18] ogbg-moltoxcast: 0.637560 test loss: 0.634366
[Epoch 19; Iter    18/  229] train: loss: 0.2107507
[Epoch 19; Iter    48/  229] train: loss: 0.1762998
[Epoch 19; Iter    78/  229] train: loss: 0.0970675
[Epoch 19; Iter   108/  229] train: loss: 0.1480272
[Epoch 19; Iter   138/  229] train: loss: 0.1052503
[Epoch 19; Iter   168/  229] train: loss: 0.2091449
[Epoch 19; Iter   198/  229] train: loss: 0.2013623
[Epoch 19; Iter   228/  229] train: loss: 0.1415244
[Epoch 19] ogbg-moltoxcast: 0.651832 val loss: 0.878315
[Epoch 19] ogbg-moltoxcast: 0.641409 test loss: 0.438108
[Epoch 20; Iter    29/  229] train: loss: 0.1775966
[Epoch 20; Iter    59/  229] train: loss: 0.2135932
[Epoch 20; Iter    89/  229] train: loss: 0.1403020
[Epoch 20; Iter   119/  229] train: loss: 0.1579672
[Epoch 20; Iter   149/  229] train: loss: 0.2592626
[Epoch 20; Iter   179/  229] train: loss: 0.1112922
[Epoch 20; Iter   209/  229] train: loss: 0.1692880
[Epoch 20] ogbg-moltoxcast: 0.666956 val loss: 0.268790
[Epoch 20] ogbg-moltoxcast: 0.652995 test loss: 0.488243
[Epoch 21; Iter    10/  229] train: loss: 0.1852645
[Epoch 21; Iter    40/  229] train: loss: 0.1084528
[Epoch 21; Iter    70/  229] train: loss: 0.1981748
[Epoch 21; Iter   100/  229] train: loss: 0.1971339
[Epoch 21; Iter   130/  229] train: loss: 0.1863407
[Epoch 21; Iter   160/  229] train: loss: 0.1944701
[Epoch 21; Iter   190/  229] train: loss: 0.1636205
[Epoch 21; Iter   220/  229] train: loss: 0.2404665
[Epoch 21] ogbg-moltoxcast: 0.665869 val loss: 0.291110
[Epoch 21] ogbg-moltoxcast: 0.639583 test loss: 0.376417
[Epoch 22; Iter    21/  229] train: loss: 0.1689949
[Epoch 22; Iter    51/  229] train: loss: 0.1741722
[Epoch 22; Iter    81/  229] train: loss: 0.1475293
[Epoch 22; Iter   111/  229] train: loss: 0.1885176
[Epoch 22; Iter   141/  229] train: loss: 0.1367378
[Epoch 22; Iter   171/  229] train: loss: 0.1745907
[Epoch 22; Iter   201/  229] train: loss: 0.1456859
[Epoch 22] ogbg-moltoxcast: 0.650311 val loss: 0.261017
[Epoch 22] ogbg-moltoxcast: 0.654150 test loss: 0.298408
[Epoch 23; Iter     2/  229] train: loss: 0.1789696
[Epoch 23; Iter    32/  229] train: loss: 0.1251762
[Epoch 23; Iter    62/  229] train: loss: 0.0935774
[Epoch 23; Iter    92/  229] train: loss: 0.1143968
[Epoch 23; Iter   122/  229] train: loss: 0.1691651
[Epoch 23; Iter   152/  229] train: loss: 0.1068027
[Epoch 23; Iter   182/  229] train: loss: 0.1716898
[Epoch 23; Iter   212/  229] train: loss: 0.1759171
[Epoch 23] ogbg-moltoxcast: 0.658818 val loss: 0.347483
[Epoch 23] ogbg-moltoxcast: 0.641952 test loss: 0.432893
[Epoch 24; Iter    13/  229] train: loss: 0.1307539
[Epoch 24; Iter    43/  229] train: loss: 0.1988834
[Epoch 24; Iter    73/  229] train: loss: 0.1612865
[Epoch 24; Iter   103/  229] train: loss: 0.1738683
[Epoch 24; Iter   133/  229] train: loss: 0.2096427
[Epoch 24; Iter   163/  229] train: loss: 0.1668523
[Epoch 24; Iter   193/  229] train: loss: 0.1822416
[Epoch 24; Iter   223/  229] train: loss: 0.1318154
[Epoch 24] ogbg-moltoxcast: 0.674810 val loss: 0.281338
[Epoch 24] ogbg-moltoxcast: 0.640400 test loss: 0.331806
[Epoch 25; Iter    24/  229] train: loss: 0.1718610
[Epoch 25; Iter    54/  229] train: loss: 0.1736161
[Epoch 25; Iter    84/  229] train: loss: 0.1299680
[Epoch 25; Iter   114/  229] train: loss: 0.2793381
[Epoch 25; Iter   144/  229] train: loss: 0.1392117
[Epoch 25; Iter   174/  229] train: loss: 0.2120053
[Epoch 25; Iter   204/  229] train: loss: 0.1423834
[Epoch 25] ogbg-moltoxcast: 0.658328 val loss: 0.276827
[Epoch 25] ogbg-moltoxcast: 0.651715 test loss: 0.359441
[Epoch 26; Iter     5/  229] train: loss: 0.1378340
[Epoch 26; Iter    35/  229] train: loss: 0.1639928
[Epoch 26; Iter    65/  229] train: loss: 0.1384733
[Epoch 26; Iter    95/  229] train: loss: 0.1351594
[Epoch 26; Iter   125/  229] train: loss: 0.1582397
[Epoch 26; Iter   155/  229] train: loss: 0.1503565
[Epoch 26; Iter   185/  229] train: loss: 0.1587936
[Epoch 26; Iter   215/  229] train: loss: 0.1779777
[Epoch 26] ogbg-moltoxcast: 0.673335 val loss: 0.269746
[Epoch 26] ogbg-moltoxcast: 0.647955 test loss: 0.832490
[Epoch 27; Iter    16/  229] train: loss: 0.0763841
[Epoch 27; Iter    46/  229] train: loss: 0.1614723
[Epoch 27; Iter    76/  229] train: loss: 0.1196656
[Epoch 27; Iter   106/  229] train: loss: 0.1799842
[Epoch 27; Iter   136/  229] train: loss: 0.1521727
[Epoch 27; Iter   166/  229] train: loss: 0.2177970
[Epoch 27; Iter   196/  229] train: loss: 0.2041082
[Epoch 27; Iter   226/  229] train: loss: 0.1937717
[Epoch 27] ogbg-moltoxcast: 0.662239 val loss: 0.277480
[Epoch 27] ogbg-moltoxcast: 0.645480 test loss: 0.321442
[Epoch 12; Iter    31/  229] train: loss: 0.2199985
[Epoch 12; Iter    61/  229] train: loss: 0.1528524
[Epoch 12; Iter    91/  229] train: loss: 0.2037814
[Epoch 12; Iter   121/  229] train: loss: 0.2212773
[Epoch 12; Iter   151/  229] train: loss: 0.1224171
[Epoch 12; Iter   181/  229] train: loss: 0.2292736
[Epoch 12; Iter   211/  229] train: loss: 0.2029126
[Epoch 12] ogbg-moltoxcast: 0.656837 val loss: 0.947299
[Epoch 12] ogbg-moltoxcast: 0.615644 test loss: 0.972396
[Epoch 13; Iter    12/  229] train: loss: 0.1376872
[Epoch 13; Iter    42/  229] train: loss: 0.1485382
[Epoch 13; Iter    72/  229] train: loss: 0.1660386
[Epoch 13; Iter   102/  229] train: loss: 0.2530181
[Epoch 13; Iter   132/  229] train: loss: 0.2293434
[Epoch 13; Iter   162/  229] train: loss: 0.1785767
[Epoch 13; Iter   192/  229] train: loss: 0.1927830
[Epoch 13; Iter   222/  229] train: loss: 0.2309365
[Epoch 13] ogbg-moltoxcast: 0.659862 val loss: 0.293341
[Epoch 13] ogbg-moltoxcast: 0.622728 test loss: 1.412618
[Epoch 14; Iter    23/  229] train: loss: 0.2085312
[Epoch 14; Iter    53/  229] train: loss: 0.1953017
[Epoch 14; Iter    83/  229] train: loss: 0.2391559
[Epoch 14; Iter   113/  229] train: loss: 0.1785453
[Epoch 14; Iter   143/  229] train: loss: 0.2025688
[Epoch 14; Iter   173/  229] train: loss: 0.2217238
[Epoch 14; Iter   203/  229] train: loss: 0.1798092
[Epoch 14] ogbg-moltoxcast: 0.667028 val loss: 1.118286
[Epoch 14] ogbg-moltoxcast: 0.635022 test loss: 1.454046
[Epoch 15; Iter     4/  229] train: loss: 0.1623217
[Epoch 15; Iter    34/  229] train: loss: 0.1062069
[Epoch 15; Iter    64/  229] train: loss: 0.1826871
[Epoch 15; Iter    94/  229] train: loss: 0.2522564
[Epoch 15; Iter   124/  229] train: loss: 0.1539972
[Epoch 15; Iter   154/  229] train: loss: 0.1722849
[Epoch 15; Iter   184/  229] train: loss: 0.1644325
[Epoch 15; Iter   214/  229] train: loss: 0.2130744
[Epoch 15] ogbg-moltoxcast: 0.655270 val loss: 0.550389
[Epoch 15] ogbg-moltoxcast: 0.632466 test loss: 1.449619
[Epoch 16; Iter    15/  229] train: loss: 0.2811469
[Epoch 16; Iter    45/  229] train: loss: 0.1354701
[Epoch 16; Iter    75/  229] train: loss: 0.1235631
[Epoch 16; Iter   105/  229] train: loss: 0.1576913
[Epoch 16; Iter   135/  229] train: loss: 0.1539523
[Epoch 16; Iter   165/  229] train: loss: 0.1928213
[Epoch 16; Iter   195/  229] train: loss: 0.2281892
[Epoch 16; Iter   225/  229] train: loss: 0.1490124
[Epoch 16] ogbg-moltoxcast: 0.642682 val loss: 1.988682
[Epoch 16] ogbg-moltoxcast: 0.622862 test loss: 2.138651
[Epoch 17; Iter    26/  229] train: loss: 0.1603978
[Epoch 17; Iter    56/  229] train: loss: 0.2018013
[Epoch 17; Iter    86/  229] train: loss: 0.1453381
[Epoch 17; Iter   116/  229] train: loss: 0.1816366
[Epoch 17; Iter   146/  229] train: loss: 0.1787590
[Epoch 17; Iter   176/  229] train: loss: 0.2650883
[Epoch 17; Iter   206/  229] train: loss: 0.2124721
[Epoch 17] ogbg-moltoxcast: 0.658545 val loss: 0.496628
[Epoch 17] ogbg-moltoxcast: 0.630011 test loss: 1.387974
[Epoch 18; Iter     7/  229] train: loss: 0.1282365
[Epoch 18; Iter    37/  229] train: loss: 0.1725518
[Epoch 18; Iter    67/  229] train: loss: 0.1680373
[Epoch 18; Iter    97/  229] train: loss: 0.2971269
[Epoch 18; Iter   127/  229] train: loss: 0.1730578
[Epoch 18; Iter   157/  229] train: loss: 0.1985631
[Epoch 18; Iter   187/  229] train: loss: 0.1065304
[Epoch 18; Iter   217/  229] train: loss: 0.2167155
[Epoch 18] ogbg-moltoxcast: 0.660878 val loss: 0.471694
[Epoch 18] ogbg-moltoxcast: 0.619011 test loss: 0.520831
[Epoch 19; Iter    18/  229] train: loss: 0.2151244
[Epoch 19; Iter    48/  229] train: loss: 0.1835734
[Epoch 19; Iter    78/  229] train: loss: 0.0987562
[Epoch 19; Iter   108/  229] train: loss: 0.1694536
[Epoch 19; Iter   138/  229] train: loss: 0.1167931
[Epoch 19; Iter   168/  229] train: loss: 0.1960699
[Epoch 19; Iter   198/  229] train: loss: 0.2108808
[Epoch 19; Iter   228/  229] train: loss: 0.1460964
[Epoch 19] ogbg-moltoxcast: 0.640327 val loss: 0.774265
[Epoch 19] ogbg-moltoxcast: 0.629266 test loss: 2.153325
[Epoch 20; Iter    29/  229] train: loss: 0.1779923
[Epoch 20; Iter    59/  229] train: loss: 0.2103591
[Epoch 20; Iter    89/  229] train: loss: 0.1417177
[Epoch 20; Iter   119/  229] train: loss: 0.1676327
[Epoch 20; Iter   149/  229] train: loss: 0.2768115
[Epoch 20; Iter   179/  229] train: loss: 0.1152851
[Epoch 20; Iter   209/  229] train: loss: 0.1595448
[Epoch 20] ogbg-moltoxcast: 0.653814 val loss: 1.118739
[Epoch 20] ogbg-moltoxcast: 0.618588 test loss: 2.433752
[Epoch 21; Iter    10/  229] train: loss: 0.1873430
[Epoch 21; Iter    40/  229] train: loss: 0.1076937
[Epoch 21; Iter    70/  229] train: loss: 0.2056710
[Epoch 21; Iter   100/  229] train: loss: 0.2069027
[Epoch 21; Iter   130/  229] train: loss: 0.2093735
[Epoch 21; Iter   160/  229] train: loss: 0.2102122
[Epoch 21; Iter   190/  229] train: loss: 0.1522714
[Epoch 21; Iter   220/  229] train: loss: 0.2544196
[Epoch 21] ogbg-moltoxcast: 0.660420 val loss: 0.339635
[Epoch 21] ogbg-moltoxcast: 0.632905 test loss: 0.332829
[Epoch 22; Iter    21/  229] train: loss: 0.1870705
[Epoch 22; Iter    51/  229] train: loss: 0.1783285
[Epoch 22; Iter    81/  229] train: loss: 0.1497958
[Epoch 22; Iter   111/  229] train: loss: 0.2035384
[Epoch 22; Iter   141/  229] train: loss: 0.1590366
[Epoch 22; Iter   171/  229] train: loss: 0.1968801
[Epoch 22; Iter   201/  229] train: loss: 0.1777409
[Epoch 22] ogbg-moltoxcast: 0.660583 val loss: 1.088306
[Epoch 22] ogbg-moltoxcast: 0.627871 test loss: 0.764716
[Epoch 23; Iter     2/  229] train: loss: 0.2077114
[Epoch 23; Iter    32/  229] train: loss: 0.1311072
[Epoch 23; Iter    62/  229] train: loss: 0.1078640
[Epoch 23; Iter    92/  229] train: loss: 0.1080316
[Epoch 23; Iter   122/  229] train: loss: 0.1552023
[Epoch 23; Iter   152/  229] train: loss: 0.1132638
[Epoch 23; Iter   182/  229] train: loss: 0.2128231
[Epoch 23; Iter   212/  229] train: loss: 0.1786169
[Epoch 23] ogbg-moltoxcast: 0.653218 val loss: 0.415404
[Epoch 23] ogbg-moltoxcast: 0.633935 test loss: 0.345027
[Epoch 24; Iter    13/  229] train: loss: 0.1264211
[Epoch 24; Iter    43/  229] train: loss: 0.1972628
[Epoch 24; Iter    73/  229] train: loss: 0.1587117
[Epoch 24; Iter   103/  229] train: loss: 0.1981286
[Epoch 24; Iter   133/  229] train: loss: 0.2210717
[Epoch 24; Iter   163/  229] train: loss: 0.1773783
[Epoch 24; Iter   193/  229] train: loss: 0.1784695
[Epoch 24; Iter   223/  229] train: loss: 0.1300073
[Epoch 24] ogbg-moltoxcast: 0.645544 val loss: 0.389242
[Epoch 24] ogbg-moltoxcast: 0.630184 test loss: 0.358567
[Epoch 25; Iter    24/  229] train: loss: 0.1705056
[Epoch 25; Iter    54/  229] train: loss: 0.1711474
[Epoch 25; Iter    84/  229] train: loss: 0.1518861
[Epoch 25; Iter   114/  229] train: loss: 0.2611301
[Epoch 25; Iter   144/  229] train: loss: 0.1300618
[Epoch 25; Iter   174/  229] train: loss: 0.2120560
[Epoch 25; Iter   204/  229] train: loss: 0.1446526
[Epoch 25] ogbg-moltoxcast: 0.647015 val loss: 0.660099
[Epoch 25] ogbg-moltoxcast: 0.628339 test loss: 0.412390
[Epoch 26; Iter     5/  229] train: loss: 0.1415511
[Epoch 26; Iter    35/  229] train: loss: 0.1731502
[Epoch 26; Iter    65/  229] train: loss: 0.1389180
[Epoch 26; Iter    95/  229] train: loss: 0.1438863
[Epoch 26; Iter   125/  229] train: loss: 0.1684419
[Epoch 26; Iter   155/  229] train: loss: 0.1595630
[Epoch 26; Iter   185/  229] train: loss: 0.1509790
[Epoch 26; Iter   215/  229] train: loss: 0.1804534
[Epoch 26] ogbg-moltoxcast: 0.643456 val loss: 0.438585
[Epoch 26] ogbg-moltoxcast: 0.626967 test loss: 0.340504
[Epoch 27; Iter    16/  229] train: loss: 0.0865265
[Epoch 27; Iter    46/  229] train: loss: 0.1598746
[Epoch 27; Iter    76/  229] train: loss: 0.1277717
[Epoch 27; Iter   106/  229] train: loss: 0.1847956
[Epoch 27; Iter   136/  229] train: loss: 0.1506484
[Epoch 27; Iter   166/  229] train: loss: 0.2528238
[Epoch 27; Iter   196/  229] train: loss: 0.1924219
[Epoch 27; Iter   226/  229] train: loss: 0.1911971
[Epoch 27] ogbg-moltoxcast: 0.645395 val loss: 0.305069
[Epoch 27] ogbg-moltoxcast: 0.627672 test loss: 0.339852
[Epoch 12; Iter    31/  229] train: loss: 0.1818843
[Epoch 12; Iter    61/  229] train: loss: 0.1738797
[Epoch 12; Iter    91/  229] train: loss: 0.1723875
[Epoch 12; Iter   121/  229] train: loss: 0.3510886
[Epoch 12; Iter   151/  229] train: loss: 0.2094079
[Epoch 12; Iter   181/  229] train: loss: 0.2217168
[Epoch 12; Iter   211/  229] train: loss: 0.3367663
[Epoch 12] ogbg-moltoxcast: 0.651420 val loss: 0.313707
[Epoch 12] ogbg-moltoxcast: 0.614312 test loss: 0.363096
[Epoch 13; Iter    12/  229] train: loss: 0.2294275
[Epoch 13; Iter    42/  229] train: loss: 0.1907848
[Epoch 13; Iter    72/  229] train: loss: 0.2009282
[Epoch 13; Iter   102/  229] train: loss: 0.2300271
[Epoch 13; Iter   132/  229] train: loss: 0.1420937
[Epoch 13; Iter   162/  229] train: loss: 0.2460295
[Epoch 13; Iter   192/  229] train: loss: 0.1521235
[Epoch 13; Iter   222/  229] train: loss: 0.2010452
[Epoch 13] ogbg-moltoxcast: 0.657405 val loss: 0.263762
[Epoch 13] ogbg-moltoxcast: 0.622507 test loss: 0.299980
[Epoch 14; Iter    23/  229] train: loss: 0.2030153
[Epoch 14; Iter    53/  229] train: loss: 0.1502106
[Epoch 14; Iter    83/  229] train: loss: 0.1987604
[Epoch 14; Iter   113/  229] train: loss: 0.1424378
[Epoch 14; Iter   143/  229] train: loss: 0.2695041
[Epoch 14; Iter   173/  229] train: loss: 0.1412898
[Epoch 14; Iter   203/  229] train: loss: 0.1988074
[Epoch 14] ogbg-moltoxcast: 0.614691 val loss: 0.292795
[Epoch 14] ogbg-moltoxcast: 0.602363 test loss: 0.327800
[Epoch 15; Iter     4/  229] train: loss: 0.1726177
[Epoch 15; Iter    34/  229] train: loss: 0.2120762
[Epoch 15; Iter    64/  229] train: loss: 0.2192655
[Epoch 15; Iter    94/  229] train: loss: 0.1630666
[Epoch 15; Iter   124/  229] train: loss: 0.1354036
[Epoch 15; Iter   154/  229] train: loss: 0.2179424
[Epoch 15; Iter   184/  229] train: loss: 0.1882368
[Epoch 15; Iter   214/  229] train: loss: 0.1432086
[Epoch 15] ogbg-moltoxcast: 0.619686 val loss: 0.595060
[Epoch 15] ogbg-moltoxcast: 0.617494 test loss: 0.771471
[Epoch 16; Iter    15/  229] train: loss: 0.2250281
[Epoch 16; Iter    45/  229] train: loss: 0.1447780
[Epoch 16; Iter    75/  229] train: loss: 0.1811328
[Epoch 16; Iter   105/  229] train: loss: 0.1649967
[Epoch 16; Iter   135/  229] train: loss: 0.2161794
[Epoch 16; Iter   165/  229] train: loss: 0.1326215
[Epoch 16; Iter   195/  229] train: loss: 0.1794717
[Epoch 16; Iter   225/  229] train: loss: 0.2299288
[Epoch 16] ogbg-moltoxcast: 0.631309 val loss: 0.340058
[Epoch 16] ogbg-moltoxcast: 0.621412 test loss: 0.383293
[Epoch 17; Iter    26/  229] train: loss: 0.1774057
[Epoch 17; Iter    56/  229] train: loss: 0.1056494
[Epoch 17; Iter    86/  229] train: loss: 0.2382737
[Epoch 17; Iter   116/  229] train: loss: 0.2308963
[Epoch 17; Iter   146/  229] train: loss: 0.1776710
[Epoch 17; Iter   176/  229] train: loss: 0.2417842
[Epoch 17; Iter   206/  229] train: loss: 0.1408535
[Epoch 17] ogbg-moltoxcast: 0.653984 val loss: 0.293400
[Epoch 17] ogbg-moltoxcast: 0.629688 test loss: 0.344452
[Epoch 18; Iter     7/  229] train: loss: 0.1755705
[Epoch 18; Iter    37/  229] train: loss: 0.2043833
[Epoch 18; Iter    67/  229] train: loss: 0.1786165
[Epoch 18; Iter    97/  229] train: loss: 0.1424412
[Epoch 18; Iter   127/  229] train: loss: 0.1643721
[Epoch 18; Iter   157/  229] train: loss: 0.1590682
[Epoch 18; Iter   187/  229] train: loss: 0.2173051
[Epoch 18; Iter   217/  229] train: loss: 0.2199409
[Epoch 18] ogbg-moltoxcast: 0.637909 val loss: 0.309094
[Epoch 18] ogbg-moltoxcast: 0.632975 test loss: 0.360550
[Epoch 19; Iter    18/  229] train: loss: 0.0964459
[Epoch 19; Iter    48/  229] train: loss: 0.2099858
[Epoch 19; Iter    78/  229] train: loss: 0.1321091
[Epoch 19; Iter   108/  229] train: loss: 0.1550623
[Epoch 19; Iter   138/  229] train: loss: 0.1964589
[Epoch 19; Iter   168/  229] train: loss: 0.2586093
[Epoch 19; Iter   198/  229] train: loss: 0.1702579
[Epoch 19; Iter   228/  229] train: loss: 0.2016281
[Epoch 19] ogbg-moltoxcast: 0.661455 val loss: 0.337216
[Epoch 19] ogbg-moltoxcast: 0.626769 test loss: 0.406676
[Epoch 20; Iter    29/  229] train: loss: 0.1474779
[Epoch 20; Iter    59/  229] train: loss: 0.1908800
[Epoch 20; Iter    89/  229] train: loss: 0.2058933
[Epoch 20; Iter   119/  229] train: loss: 0.1208964
[Epoch 20; Iter   149/  229] train: loss: 0.1955968
[Epoch 20; Iter   179/  229] train: loss: 0.1887666
[Epoch 20; Iter   209/  229] train: loss: 0.1705535
[Epoch 20] ogbg-moltoxcast: 0.650728 val loss: 1.233221
[Epoch 20] ogbg-moltoxcast: 0.633907 test loss: 1.185608
[Epoch 21; Iter    10/  229] train: loss: 0.2147062
[Epoch 21; Iter    40/  229] train: loss: 0.1383375
[Epoch 21; Iter    70/  229] train: loss: 0.1904568
[Epoch 21; Iter   100/  229] train: loss: 0.1759115
[Epoch 21; Iter   130/  229] train: loss: 0.2101180
[Epoch 21; Iter   160/  229] train: loss: 0.1817911
[Epoch 21; Iter   190/  229] train: loss: 0.1967070
[Epoch 21; Iter   220/  229] train: loss: 0.1519137
[Epoch 21] ogbg-moltoxcast: 0.662460 val loss: 0.289649
[Epoch 21] ogbg-moltoxcast: 0.628317 test loss: 0.333559
[Epoch 22; Iter    21/  229] train: loss: 0.1255937
[Epoch 22; Iter    51/  229] train: loss: 0.2029041
[Epoch 22; Iter    81/  229] train: loss: 0.1363638
[Epoch 22; Iter   111/  229] train: loss: 0.1933116
[Epoch 22; Iter   141/  229] train: loss: 0.1457299
[Epoch 22; Iter   171/  229] train: loss: 0.1940125
[Epoch 22; Iter   201/  229] train: loss: 0.1291955
[Epoch 22] ogbg-moltoxcast: 0.653068 val loss: 4.185575
[Epoch 22] ogbg-moltoxcast: 0.623851 test loss: 3.872359
[Epoch 23; Iter     2/  229] train: loss: 0.1276285
[Epoch 23; Iter    32/  229] train: loss: 0.1633293
[Epoch 23; Iter    62/  229] train: loss: 0.1339697
[Epoch 23; Iter    92/  229] train: loss: 0.1270122
[Epoch 23; Iter   122/  229] train: loss: 0.1506164
[Epoch 23; Iter   152/  229] train: loss: 0.2231030
[Epoch 23; Iter   182/  229] train: loss: 0.1797271
[Epoch 23; Iter   212/  229] train: loss: 0.1438755
[Epoch 23] ogbg-moltoxcast: 0.646857 val loss: 0.367472
[Epoch 23] ogbg-moltoxcast: 0.628926 test loss: 0.416111
[Epoch 24; Iter    13/  229] train: loss: 0.1409029
[Epoch 24; Iter    43/  229] train: loss: 0.1834349
[Epoch 24; Iter    73/  229] train: loss: 0.1225637
[Epoch 24; Iter   103/  229] train: loss: 0.2231054
[Epoch 24; Iter   133/  229] train: loss: 0.1467576
[Epoch 24; Iter   163/  229] train: loss: 0.1408918
[Epoch 24; Iter   193/  229] train: loss: 0.1888075
[Epoch 24; Iter   223/  229] train: loss: 0.1350745
[Epoch 24] ogbg-moltoxcast: 0.624923 val loss: 0.821740
[Epoch 24] ogbg-moltoxcast: 0.628616 test loss: 0.828652
[Epoch 25; Iter    24/  229] train: loss: 0.1106083
[Epoch 25; Iter    54/  229] train: loss: 0.1061776
[Epoch 25; Iter    84/  229] train: loss: 0.1348070
[Epoch 25; Iter   114/  229] train: loss: 0.2291182
[Epoch 25; Iter   144/  229] train: loss: 0.1828364
[Epoch 25; Iter   174/  229] train: loss: 0.1324630
[Epoch 25; Iter   204/  229] train: loss: 0.1522758
[Epoch 25] ogbg-moltoxcast: 0.644973 val loss: 0.500515
[Epoch 25] ogbg-moltoxcast: 0.631123 test loss: 0.608385
[Epoch 26; Iter     5/  229] train: loss: 0.1599304
[Epoch 26; Iter    35/  229] train: loss: 0.1760016
[Epoch 26; Iter    65/  229] train: loss: 0.1645290
[Epoch 26; Iter    95/  229] train: loss: 0.1785656
[Epoch 26; Iter   125/  229] train: loss: 0.2177605
[Epoch 26; Iter   155/  229] train: loss: 0.1560533
[Epoch 26; Iter   185/  229] train: loss: 0.1514230
[Epoch 26; Iter   215/  229] train: loss: 0.1670640
[Epoch 26] ogbg-moltoxcast: 0.658162 val loss: 1.000028
[Epoch 26] ogbg-moltoxcast: 0.632818 test loss: 0.771207
[Epoch 27; Iter    16/  229] train: loss: 0.1139656
[Epoch 27; Iter    46/  229] train: loss: 0.1516003
[Epoch 27; Iter    76/  229] train: loss: 0.1484036
[Epoch 27; Iter   106/  229] train: loss: 0.0857355
[Epoch 27; Iter   136/  229] train: loss: 0.1840253
[Epoch 27; Iter   166/  229] train: loss: 0.1434130
[Epoch 27; Iter   196/  229] train: loss: 0.1983699
[Epoch 27; Iter   226/  229] train: loss: 0.1358779
[Epoch 27] ogbg-moltoxcast: 0.657365 val loss: 1.035779
[Epoch 27] ogbg-moltoxcast: 0.642467 test loss: 0.517066
[Epoch 12; Iter    31/  229] train: loss: 0.2118589
[Epoch 12; Iter    61/  229] train: loss: 0.1467315
[Epoch 12; Iter    91/  229] train: loss: 0.2005523
[Epoch 12; Iter   121/  229] train: loss: 0.2077833
[Epoch 12; Iter   151/  229] train: loss: 0.1265927
[Epoch 12; Iter   181/  229] train: loss: 0.2203169
[Epoch 12; Iter   211/  229] train: loss: 0.1862215
[Epoch 12] ogbg-moltoxcast: 0.675502 val loss: 0.375039
[Epoch 12] ogbg-moltoxcast: 0.645507 test loss: 0.348359
[Epoch 13; Iter    12/  229] train: loss: 0.1455438
[Epoch 13; Iter    42/  229] train: loss: 0.1321454
[Epoch 13; Iter    72/  229] train: loss: 0.1664638
[Epoch 13; Iter   102/  229] train: loss: 0.2591974
[Epoch 13; Iter   132/  229] train: loss: 0.2078002
[Epoch 13; Iter   162/  229] train: loss: 0.1437155
[Epoch 13; Iter   192/  229] train: loss: 0.1865539
[Epoch 13; Iter   222/  229] train: loss: 0.2233900
[Epoch 13] ogbg-moltoxcast: 0.653495 val loss: 0.339716
[Epoch 13] ogbg-moltoxcast: 0.642024 test loss: 0.332631
[Epoch 14; Iter    23/  229] train: loss: 0.1820682
[Epoch 14; Iter    53/  229] train: loss: 0.2162380
[Epoch 14; Iter    83/  229] train: loss: 0.2370409
[Epoch 14; Iter   113/  229] train: loss: 0.1735759
[Epoch 14; Iter   143/  229] train: loss: 0.1831619
[Epoch 14; Iter   173/  229] train: loss: 0.1924773
[Epoch 14; Iter   203/  229] train: loss: 0.1837923
[Epoch 14] ogbg-moltoxcast: 0.673511 val loss: 0.375411
[Epoch 14] ogbg-moltoxcast: 0.653034 test loss: 0.289623
[Epoch 15; Iter     4/  229] train: loss: 0.1730273
[Epoch 15; Iter    34/  229] train: loss: 0.1093547
[Epoch 15; Iter    64/  229] train: loss: 0.1607091
[Epoch 15; Iter    94/  229] train: loss: 0.2792548
[Epoch 15; Iter   124/  229] train: loss: 0.1580409
[Epoch 15; Iter   154/  229] train: loss: 0.1647048
[Epoch 15; Iter   184/  229] train: loss: 0.1573270
[Epoch 15; Iter   214/  229] train: loss: 0.2081334
[Epoch 15] ogbg-moltoxcast: 0.673343 val loss: 0.288070
[Epoch 15] ogbg-moltoxcast: 0.652850 test loss: 0.296245
[Epoch 16; Iter    15/  229] train: loss: 0.2500049
[Epoch 16; Iter    45/  229] train: loss: 0.1430530
[Epoch 16; Iter    75/  229] train: loss: 0.1191725
[Epoch 16; Iter   105/  229] train: loss: 0.1536439
[Epoch 16; Iter   135/  229] train: loss: 0.1573121
[Epoch 16; Iter   165/  229] train: loss: 0.1868204
[Epoch 16; Iter   195/  229] train: loss: 0.2152833
[Epoch 16; Iter   225/  229] train: loss: 0.1591581
[Epoch 16] ogbg-moltoxcast: 0.676597 val loss: 0.275748
[Epoch 16] ogbg-moltoxcast: 0.647454 test loss: 0.307052
[Epoch 17; Iter    26/  229] train: loss: 0.1532710
[Epoch 17; Iter    56/  229] train: loss: 0.2053413
[Epoch 17; Iter    86/  229] train: loss: 0.1609664
[Epoch 17; Iter   116/  229] train: loss: 0.1953726
[Epoch 17; Iter   146/  229] train: loss: 0.1767074
[Epoch 17; Iter   176/  229] train: loss: 0.2601382
[Epoch 17; Iter   206/  229] train: loss: 0.1931226
[Epoch 17] ogbg-moltoxcast: 0.683136 val loss: 0.423793
[Epoch 17] ogbg-moltoxcast: 0.675516 test loss: 0.294374
[Epoch 18; Iter     7/  229] train: loss: 0.1246155
[Epoch 18; Iter    37/  229] train: loss: 0.1741051
[Epoch 18; Iter    67/  229] train: loss: 0.1630815
[Epoch 18; Iter    97/  229] train: loss: 0.2773285
[Epoch 18; Iter   127/  229] train: loss: 0.1701397
[Epoch 18; Iter   157/  229] train: loss: 0.1671238
[Epoch 18; Iter   187/  229] train: loss: 0.0995727
[Epoch 18; Iter   217/  229] train: loss: 0.2183383
[Epoch 18] ogbg-moltoxcast: 0.687017 val loss: 0.252751
[Epoch 18] ogbg-moltoxcast: 0.661225 test loss: 0.299073
[Epoch 19; Iter    18/  229] train: loss: 0.2228177
[Epoch 19; Iter    48/  229] train: loss: 0.1803865
[Epoch 19; Iter    78/  229] train: loss: 0.0948842
[Epoch 19; Iter   108/  229] train: loss: 0.1523848
[Epoch 19; Iter   138/  229] train: loss: 0.1041345
[Epoch 19; Iter   168/  229] train: loss: 0.1968846
[Epoch 19; Iter   198/  229] train: loss: 0.2071229
[Epoch 19; Iter   228/  229] train: loss: 0.1410848
[Epoch 19] ogbg-moltoxcast: 0.698727 val loss: 0.249467
[Epoch 19] ogbg-moltoxcast: 0.659595 test loss: 0.334698
[Epoch 20; Iter    29/  229] train: loss: 0.1857728
[Epoch 20; Iter    59/  229] train: loss: 0.2147033
[Epoch 20; Iter    89/  229] train: loss: 0.1494665
[Epoch 20; Iter   119/  229] train: loss: 0.1616623
[Epoch 20; Iter   149/  229] train: loss: 0.2465791
[Epoch 20; Iter   179/  229] train: loss: 0.1092972
[Epoch 20; Iter   209/  229] train: loss: 0.1690019
[Epoch 20] ogbg-moltoxcast: 0.678588 val loss: 0.286607
[Epoch 20] ogbg-moltoxcast: 0.664151 test loss: 0.291989
[Epoch 21; Iter    10/  229] train: loss: 0.1989457
[Epoch 21; Iter    40/  229] train: loss: 0.1075507
[Epoch 21; Iter    70/  229] train: loss: 0.1959660
[Epoch 21; Iter   100/  229] train: loss: 0.2272790
[Epoch 21; Iter   130/  229] train: loss: 0.1883979
[Epoch 21; Iter   160/  229] train: loss: 0.1824367
[Epoch 21; Iter   190/  229] train: loss: 0.1474655
[Epoch 21; Iter   220/  229] train: loss: 0.1931077
[Epoch 21] ogbg-moltoxcast: 0.689788 val loss: 0.395609
[Epoch 21] ogbg-moltoxcast: 0.669131 test loss: 0.289434
[Epoch 22; Iter    21/  229] train: loss: 0.1659045
[Epoch 22; Iter    51/  229] train: loss: 0.1759109
[Epoch 22; Iter    81/  229] train: loss: 0.1528360
[Epoch 22; Iter   111/  229] train: loss: 0.2118071
[Epoch 22; Iter   141/  229] train: loss: 0.1469911
[Epoch 22; Iter   171/  229] train: loss: 0.1827427
[Epoch 22; Iter   201/  229] train: loss: 0.1562542
[Epoch 22] ogbg-moltoxcast: 0.680007 val loss: 0.281923
[Epoch 22] ogbg-moltoxcast: 0.665166 test loss: 0.298994
[Epoch 23; Iter     2/  229] train: loss: 0.1886830
[Epoch 23; Iter    32/  229] train: loss: 0.1189982
[Epoch 23; Iter    62/  229] train: loss: 0.0886116
[Epoch 23; Iter    92/  229] train: loss: 0.1095589
[Epoch 23; Iter   122/  229] train: loss: 0.1538980
[Epoch 23; Iter   152/  229] train: loss: 0.1060064
[Epoch 23; Iter   182/  229] train: loss: 0.1637954
[Epoch 23; Iter   212/  229] train: loss: 0.1918259
[Epoch 23] ogbg-moltoxcast: 0.686036 val loss: 0.384256
[Epoch 23] ogbg-moltoxcast: 0.668743 test loss: 0.289306
[Epoch 24; Iter    13/  229] train: loss: 0.1301392
[Epoch 24; Iter    43/  229] train: loss: 0.2069915
[Epoch 24; Iter    73/  229] train: loss: 0.1576980
[Epoch 24; Iter   103/  229] train: loss: 0.1983469
[Epoch 24; Iter   133/  229] train: loss: 0.2026091
[Epoch 24; Iter   163/  229] train: loss: 0.1970458
[Epoch 24; Iter   193/  229] train: loss: 0.1616729
[Epoch 24; Iter   223/  229] train: loss: 0.1369482
[Epoch 24] ogbg-moltoxcast: 0.688490 val loss: 0.276921
[Epoch 24] ogbg-moltoxcast: 0.664604 test loss: 0.367954
[Epoch 25; Iter    24/  229] train: loss: 0.1635925
[Epoch 25; Iter    54/  229] train: loss: 0.1872970
[Epoch 25; Iter    84/  229] train: loss: 0.1770814
[Epoch 25; Iter   114/  229] train: loss: 0.2910537
[Epoch 25; Iter   144/  229] train: loss: 0.1318561
[Epoch 25; Iter   174/  229] train: loss: 0.2089138
[Epoch 25; Iter   204/  229] train: loss: 0.1227358
[Epoch 25] ogbg-moltoxcast: 0.670668 val loss: 0.255500
[Epoch 25] ogbg-moltoxcast: 0.663458 test loss: 0.302111
[Epoch 26; Iter     5/  229] train: loss: 0.1477102
[Epoch 26; Iter    35/  229] train: loss: 0.1648618
[Epoch 26; Iter    65/  229] train: loss: 0.1208117
[Epoch 26; Iter    95/  229] train: loss: 0.1395408
[Epoch 26; Iter   125/  229] train: loss: 0.1718608
[Epoch 26; Iter   155/  229] train: loss: 0.1663467
[Epoch 26; Iter   185/  229] train: loss: 0.1524388
[Epoch 26; Iter   215/  229] train: loss: 0.1734725
[Epoch 26] ogbg-moltoxcast: 0.672190 val loss: 0.265311
[Epoch 26] ogbg-moltoxcast: 0.651414 test loss: 0.300554
[Epoch 27; Iter    16/  229] train: loss: 0.0755554
[Epoch 27; Iter    46/  229] train: loss: 0.1863478
[Epoch 27; Iter    76/  229] train: loss: 0.1288826
[Epoch 27; Iter   106/  229] train: loss: 0.1867319
[Epoch 27; Iter   136/  229] train: loss: 0.1656977
[Epoch 27; Iter   166/  229] train: loss: 0.2201071
[Epoch 27; Iter   196/  229] train: loss: 0.1891336
[Epoch 27; Iter   226/  229] train: loss: 0.1813248
[Epoch 27] ogbg-moltoxcast: 0.684364 val loss: 0.251612
[Epoch 27] ogbg-moltoxcast: 0.667423 test loss: 0.298689
[Epoch 12; Iter    31/  229] train: loss: 0.2335263
[Epoch 12; Iter    61/  229] train: loss: 0.2561061
[Epoch 12; Iter    91/  229] train: loss: 0.1438891
[Epoch 12; Iter   121/  229] train: loss: 0.1253368
[Epoch 12; Iter   151/  229] train: loss: 0.1526208
[Epoch 12; Iter   181/  229] train: loss: 0.1791225
[Epoch 12; Iter   211/  229] train: loss: 0.1295592
[Epoch 12] ogbg-moltoxcast: 0.669758 val loss: 0.251883
[Epoch 12] ogbg-moltoxcast: 0.648823 test loss: 0.293961
[Epoch 13; Iter    12/  229] train: loss: 0.1796040
[Epoch 13; Iter    42/  229] train: loss: 0.1976059
[Epoch 13; Iter    72/  229] train: loss: 0.1811148
[Epoch 13; Iter   102/  229] train: loss: 0.2110807
[Epoch 13; Iter   132/  229] train: loss: 0.1974685
[Epoch 13; Iter   162/  229] train: loss: 0.1918893
[Epoch 13; Iter   192/  229] train: loss: 0.1937756
[Epoch 13; Iter   222/  229] train: loss: 0.1289081
[Epoch 13] ogbg-moltoxcast: 0.676769 val loss: 0.258237
[Epoch 13] ogbg-moltoxcast: 0.648034 test loss: 0.301315
[Epoch 14; Iter    23/  229] train: loss: 0.2600629
[Epoch 14; Iter    53/  229] train: loss: 0.1414414
[Epoch 14; Iter    83/  229] train: loss: 0.1525834
[Epoch 14; Iter   113/  229] train: loss: 0.1635841
[Epoch 14; Iter   143/  229] train: loss: 0.1632823
[Epoch 14; Iter   173/  229] train: loss: 0.1603794
[Epoch 14; Iter   203/  229] train: loss: 0.1491567
[Epoch 14] ogbg-moltoxcast: 0.681188 val loss: 0.254633
[Epoch 14] ogbg-moltoxcast: 0.649839 test loss: 0.294190
[Epoch 15; Iter     4/  229] train: loss: 0.2700990
[Epoch 15; Iter    34/  229] train: loss: 0.1516345
[Epoch 15; Iter    64/  229] train: loss: 0.1279671
[Epoch 15; Iter    94/  229] train: loss: 0.2240714
[Epoch 15; Iter   124/  229] train: loss: 0.1502310
[Epoch 15; Iter   154/  229] train: loss: 0.2671205
[Epoch 15; Iter   184/  229] train: loss: 0.2021152
[Epoch 15; Iter   214/  229] train: loss: 0.1704889
[Epoch 15] ogbg-moltoxcast: 0.676135 val loss: 0.258574
[Epoch 15] ogbg-moltoxcast: 0.654149 test loss: 0.308233
[Epoch 16; Iter    15/  229] train: loss: 0.1198229
[Epoch 16; Iter    45/  229] train: loss: 0.1851993
[Epoch 16; Iter    75/  229] train: loss: 0.1611927
[Epoch 16; Iter   105/  229] train: loss: 0.2229148
[Epoch 16; Iter   135/  229] train: loss: 0.1241680
[Epoch 16; Iter   165/  229] train: loss: 0.1669296
[Epoch 16; Iter   195/  229] train: loss: 0.2044176
[Epoch 16; Iter   225/  229] train: loss: 0.1539141
[Epoch 16] ogbg-moltoxcast: 0.678782 val loss: 0.256439
[Epoch 16] ogbg-moltoxcast: 0.656771 test loss: 0.298601
[Epoch 17; Iter    26/  229] train: loss: 0.1245075
[Epoch 17; Iter    56/  229] train: loss: 0.1624744
[Epoch 17; Iter    86/  229] train: loss: 0.0944053
[Epoch 17; Iter   116/  229] train: loss: 0.1146617
[Epoch 17; Iter   146/  229] train: loss: 0.2134984
[Epoch 17; Iter   176/  229] train: loss: 0.1558056
[Epoch 17; Iter   206/  229] train: loss: 0.2054020
[Epoch 17] ogbg-moltoxcast: 0.681094 val loss: 0.251644
[Epoch 17] ogbg-moltoxcast: 0.656512 test loss: 0.296202
[Epoch 18; Iter     7/  229] train: loss: 0.1814273
[Epoch 18; Iter    37/  229] train: loss: 0.1944243
[Epoch 18; Iter    67/  229] train: loss: 0.2186399
[Epoch 18; Iter    97/  229] train: loss: 0.2949595
[Epoch 18; Iter   127/  229] train: loss: 0.1557896
[Epoch 18; Iter   157/  229] train: loss: 0.1874436
[Epoch 18; Iter   187/  229] train: loss: 0.2500891
[Epoch 18; Iter   217/  229] train: loss: 0.2120162
[Epoch 18] ogbg-moltoxcast: 0.675133 val loss: 0.253262
[Epoch 18] ogbg-moltoxcast: 0.672092 test loss: 0.294201
[Epoch 19; Iter    18/  229] train: loss: 0.1255296
[Epoch 19; Iter    48/  229] train: loss: 0.2135598
[Epoch 19; Iter    78/  229] train: loss: 0.1943118
[Epoch 19; Iter   108/  229] train: loss: 0.1668977
[Epoch 19; Iter   138/  229] train: loss: 0.1599129
[Epoch 19; Iter   168/  229] train: loss: 0.1483502
[Epoch 19; Iter   198/  229] train: loss: 0.2340676
[Epoch 19; Iter   228/  229] train: loss: 0.2621804
[Epoch 19] ogbg-moltoxcast: 0.682726 val loss: 0.253644
[Epoch 19] ogbg-moltoxcast: 0.657060 test loss: 0.310058
[Epoch 20; Iter    29/  229] train: loss: 0.1732492
[Epoch 20; Iter    59/  229] train: loss: 0.1331951
[Epoch 20; Iter    89/  229] train: loss: 0.2448409
[Epoch 20; Iter   119/  229] train: loss: 0.1329736
[Epoch 20; Iter   149/  229] train: loss: 0.2141422
[Epoch 20; Iter   179/  229] train: loss: 0.1800529
[Epoch 20; Iter   209/  229] train: loss: 0.1591575
[Epoch 20] ogbg-moltoxcast: 0.675974 val loss: 0.264199
[Epoch 20] ogbg-moltoxcast: 0.653822 test loss: 0.307080
[Epoch 21; Iter    10/  229] train: loss: 0.2214023
[Epoch 21; Iter    40/  229] train: loss: 0.1919970
[Epoch 21; Iter    70/  229] train: loss: 0.2069708
[Epoch 21; Iter   100/  229] train: loss: 0.1782589
[Epoch 21; Iter   130/  229] train: loss: 0.1992408
[Epoch 21; Iter   160/  229] train: loss: 0.1994733
[Epoch 21; Iter   190/  229] train: loss: 0.1753055
[Epoch 21; Iter   220/  229] train: loss: 0.1222336
[Epoch 21] ogbg-moltoxcast: 0.669916 val loss: 0.264413
[Epoch 21] ogbg-moltoxcast: 0.657279 test loss: 0.301014
[Epoch 22; Iter    21/  229] train: loss: 0.0951467
[Epoch 22; Iter    51/  229] train: loss: 0.1924822
[Epoch 22; Iter    81/  229] train: loss: 0.1076572
[Epoch 22; Iter   111/  229] train: loss: 0.1977032
[Epoch 22; Iter   141/  229] train: loss: 0.2453439
[Epoch 22; Iter   171/  229] train: loss: 0.1168542
[Epoch 22; Iter   201/  229] train: loss: 0.1733469
[Epoch 22] ogbg-moltoxcast: 0.688545 val loss: 0.256657
[Epoch 22] ogbg-moltoxcast: 0.663853 test loss: 0.300859
[Epoch 23; Iter     2/  229] train: loss: 0.2518626
[Epoch 23; Iter    32/  229] train: loss: 0.1435932
[Epoch 23; Iter    62/  229] train: loss: 0.1808889
[Epoch 23; Iter    92/  229] train: loss: 0.1482929
[Epoch 23; Iter   122/  229] train: loss: 0.1640840
[Epoch 23; Iter   152/  229] train: loss: 0.2731405
[Epoch 23; Iter   182/  229] train: loss: 0.2087274
[Epoch 23; Iter   212/  229] train: loss: 0.1750222
[Epoch 23] ogbg-moltoxcast: 0.683931 val loss: 0.246545
[Epoch 23] ogbg-moltoxcast: 0.670518 test loss: 0.301725
[Epoch 24; Iter    13/  229] train: loss: 0.1737010
[Epoch 24; Iter    43/  229] train: loss: 0.1499515
[Epoch 24; Iter    73/  229] train: loss: 0.1276971
[Epoch 24; Iter   103/  229] train: loss: 0.1286276
[Epoch 24; Iter   133/  229] train: loss: 0.2209936
[Epoch 24; Iter   163/  229] train: loss: 0.2137771
[Epoch 24; Iter   193/  229] train: loss: 0.1327551
[Epoch 24; Iter   223/  229] train: loss: 0.1653231
[Epoch 24] ogbg-moltoxcast: 0.687229 val loss: 0.249414
[Epoch 24] ogbg-moltoxcast: 0.668780 test loss: 0.297171
[Epoch 25; Iter    24/  229] train: loss: 0.2400003
[Epoch 25; Iter    54/  229] train: loss: 0.1727409
[Epoch 25; Iter    84/  229] train: loss: 0.2279033
[Epoch 25; Iter   114/  229] train: loss: 0.1919265
[Epoch 25; Iter   144/  229] train: loss: 0.1041986
[Epoch 25; Iter   174/  229] train: loss: 0.1442903
[Epoch 25; Iter   204/  229] train: loss: 0.1654949
[Epoch 25] ogbg-moltoxcast: 0.696444 val loss: 0.246964
[Epoch 25] ogbg-moltoxcast: 0.666105 test loss: 0.296021
[Epoch 26; Iter     5/  229] train: loss: 0.1414600
[Epoch 26; Iter    35/  229] train: loss: 0.2359726
[Epoch 26; Iter    65/  229] train: loss: 0.1959195
[Epoch 26; Iter    95/  229] train: loss: 0.1899955
[Epoch 26; Iter   125/  229] train: loss: 0.1505470
[Epoch 26; Iter   155/  229] train: loss: 0.1548911
[Epoch 26; Iter   185/  229] train: loss: 0.1514853
[Epoch 26; Iter   215/  229] train: loss: 0.1188160
[Epoch 26] ogbg-moltoxcast: 0.689516 val loss: 0.252039
[Epoch 26] ogbg-moltoxcast: 0.668191 test loss: 0.296765
[Epoch 27; Iter    16/  229] train: loss: 0.1674517
[Epoch 27; Iter    46/  229] train: loss: 0.1611902
[Epoch 27; Iter    76/  229] train: loss: 0.1319077
[Epoch 27; Iter   106/  229] train: loss: 0.2041671
[Epoch 27; Iter   136/  229] train: loss: 0.1946836
[Epoch 27; Iter   166/  229] train: loss: 0.1322130
[Epoch 27; Iter   196/  229] train: loss: 0.1331484
[Epoch 27; Iter   226/  229] train: loss: 0.1724955
[Epoch 27] ogbg-moltoxcast: 0.696608 val loss: 0.251798
[Epoch 27] ogbg-moltoxcast: 0.666318 test loss: 0.299696
[Epoch 12; Iter    31/  229] train: loss: 0.2007382
[Epoch 12; Iter    61/  229] train: loss: 0.1673197
[Epoch 12; Iter    91/  229] train: loss: 0.1543065
[Epoch 12; Iter   121/  229] train: loss: 0.3532020
[Epoch 12; Iter   151/  229] train: loss: 0.2008342
[Epoch 12; Iter   181/  229] train: loss: 0.2175816
[Epoch 12; Iter   211/  229] train: loss: 0.3208523
[Epoch 12] ogbg-moltoxcast: 0.675698 val loss: 0.258676
[Epoch 12] ogbg-moltoxcast: 0.644608 test loss: 0.385292
[Epoch 13; Iter    12/  229] train: loss: 0.2292189
[Epoch 13; Iter    42/  229] train: loss: 0.1812212
[Epoch 13; Iter    72/  229] train: loss: 0.1836475
[Epoch 13; Iter   102/  229] train: loss: 0.2250268
[Epoch 13; Iter   132/  229] train: loss: 0.1354567
[Epoch 13; Iter   162/  229] train: loss: 0.2290454
[Epoch 13; Iter   192/  229] train: loss: 0.1358550
[Epoch 13; Iter   222/  229] train: loss: 0.1864329
[Epoch 13] ogbg-moltoxcast: 0.683505 val loss: 0.257924
[Epoch 13] ogbg-moltoxcast: 0.629605 test loss: 0.382772
[Epoch 14; Iter    23/  229] train: loss: 0.1786875
[Epoch 14; Iter    53/  229] train: loss: 0.1477623
[Epoch 14; Iter    83/  229] train: loss: 0.1762610
[Epoch 14; Iter   113/  229] train: loss: 0.1487720
[Epoch 14; Iter   143/  229] train: loss: 0.2702462
[Epoch 14; Iter   173/  229] train: loss: 0.1277969
[Epoch 14; Iter   203/  229] train: loss: 0.1913571
[Epoch 14] ogbg-moltoxcast: 0.692302 val loss: 0.316794
[Epoch 14] ogbg-moltoxcast: 0.640922 test loss: 0.323408
[Epoch 15; Iter     4/  229] train: loss: 0.1615789
[Epoch 15; Iter    34/  229] train: loss: 0.2446562
[Epoch 15; Iter    64/  229] train: loss: 0.1900892
[Epoch 15; Iter    94/  229] train: loss: 0.1718556
[Epoch 15; Iter   124/  229] train: loss: 0.1359981
[Epoch 15; Iter   154/  229] train: loss: 0.2166224
[Epoch 15; Iter   184/  229] train: loss: 0.1660468
[Epoch 15; Iter   214/  229] train: loss: 0.1261993
[Epoch 15] ogbg-moltoxcast: 0.680261 val loss: 0.257235
[Epoch 15] ogbg-moltoxcast: 0.650821 test loss: 0.325449
[Epoch 16; Iter    15/  229] train: loss: 0.1999948
[Epoch 16; Iter    45/  229] train: loss: 0.1222343
[Epoch 16; Iter    75/  229] train: loss: 0.1735404
[Epoch 16; Iter   105/  229] train: loss: 0.1497072
[Epoch 16; Iter   135/  229] train: loss: 0.1718704
[Epoch 16; Iter   165/  229] train: loss: 0.1295434
[Epoch 16; Iter   195/  229] train: loss: 0.1568273
[Epoch 16; Iter   225/  229] train: loss: 0.2137468
[Epoch 16] ogbg-moltoxcast: 0.658569 val loss: 0.259151
[Epoch 16] ogbg-moltoxcast: 0.643344 test loss: 0.376373
[Epoch 17; Iter    26/  229] train: loss: 0.1628953
[Epoch 17; Iter    56/  229] train: loss: 0.1066003
[Epoch 17; Iter    86/  229] train: loss: 0.2319468
[Epoch 17; Iter   116/  229] train: loss: 0.2022229
[Epoch 17; Iter   146/  229] train: loss: 0.1779830
[Epoch 17; Iter   176/  229] train: loss: 0.2428921
[Epoch 17; Iter   206/  229] train: loss: 0.1462208
[Epoch 17] ogbg-moltoxcast: 0.679881 val loss: 0.246749
[Epoch 17] ogbg-moltoxcast: 0.641934 test loss: 0.289975
[Epoch 18; Iter     7/  229] train: loss: 0.1693438
[Epoch 18; Iter    37/  229] train: loss: 0.1917929
[Epoch 18; Iter    67/  229] train: loss: 0.1678631
[Epoch 18; Iter    97/  229] train: loss: 0.1335271
[Epoch 18; Iter   127/  229] train: loss: 0.1548674
[Epoch 18; Iter   157/  229] train: loss: 0.1894158
[Epoch 18; Iter   187/  229] train: loss: 0.1651431
[Epoch 18; Iter   217/  229] train: loss: 0.2454378
[Epoch 18] ogbg-moltoxcast: 0.674417 val loss: 0.252098
[Epoch 18] ogbg-moltoxcast: 0.657156 test loss: 0.298960
[Epoch 19; Iter    18/  229] train: loss: 0.1066049
[Epoch 19; Iter    48/  229] train: loss: 0.2101282
[Epoch 19; Iter    78/  229] train: loss: 0.1507247
[Epoch 19; Iter   108/  229] train: loss: 0.1581109
[Epoch 19; Iter   138/  229] train: loss: 0.1929882
[Epoch 19; Iter   168/  229] train: loss: 0.2536812
[Epoch 19; Iter   198/  229] train: loss: 0.1543634
[Epoch 19; Iter   228/  229] train: loss: 0.2020245
[Epoch 19] ogbg-moltoxcast: 0.680117 val loss: 0.256982
[Epoch 19] ogbg-moltoxcast: 0.661937 test loss: 0.296080
[Epoch 20; Iter    29/  229] train: loss: 0.1439648
[Epoch 20; Iter    59/  229] train: loss: 0.1585248
[Epoch 20; Iter    89/  229] train: loss: 0.1953825
[Epoch 20; Iter   119/  229] train: loss: 0.1218407
[Epoch 20; Iter   149/  229] train: loss: 0.1958628
[Epoch 20; Iter   179/  229] train: loss: 0.1844960
[Epoch 20; Iter   209/  229] train: loss: 0.1478062
[Epoch 20] ogbg-moltoxcast: 0.696914 val loss: 0.246250
[Epoch 20] ogbg-moltoxcast: 0.654863 test loss: 0.291469
[Epoch 21; Iter    10/  229] train: loss: 0.1930964
[Epoch 21; Iter    40/  229] train: loss: 0.1369815
[Epoch 21; Iter    70/  229] train: loss: 0.1852321
[Epoch 21; Iter   100/  229] train: loss: 0.1613900
[Epoch 21; Iter   130/  229] train: loss: 0.1942872
[Epoch 21; Iter   160/  229] train: loss: 0.1706649
[Epoch 21; Iter   190/  229] train: loss: 0.1856991
[Epoch 21; Iter   220/  229] train: loss: 0.1399449
[Epoch 21] ogbg-moltoxcast: 0.686991 val loss: 0.248634
[Epoch 21] ogbg-moltoxcast: 0.653416 test loss: 0.294079
[Epoch 22; Iter    21/  229] train: loss: 0.1123079
[Epoch 22; Iter    51/  229] train: loss: 0.2165178
[Epoch 22; Iter    81/  229] train: loss: 0.1338756
[Epoch 22; Iter   111/  229] train: loss: 0.1913882
[Epoch 22; Iter   141/  229] train: loss: 0.1594043
[Epoch 22; Iter   171/  229] train: loss: 0.2052035
[Epoch 22; Iter   201/  229] train: loss: 0.1579872
[Epoch 22] ogbg-moltoxcast: 0.697184 val loss: 0.249448
[Epoch 22] ogbg-moltoxcast: 0.661811 test loss: 0.289591
[Epoch 23; Iter     2/  229] train: loss: 0.1334273
[Epoch 23; Iter    32/  229] train: loss: 0.1577085
[Epoch 23; Iter    62/  229] train: loss: 0.1440805
[Epoch 23; Iter    92/  229] train: loss: 0.1158061
[Epoch 23; Iter   122/  229] train: loss: 0.1439263
[Epoch 23; Iter   152/  229] train: loss: 0.2291654
[Epoch 23; Iter   182/  229] train: loss: 0.1655005
[Epoch 23; Iter   212/  229] train: loss: 0.1375645
[Epoch 23] ogbg-moltoxcast: 0.685643 val loss: 0.258869
[Epoch 23] ogbg-moltoxcast: 0.652828 test loss: 0.308120
[Epoch 24; Iter    13/  229] train: loss: 0.1222173
[Epoch 24; Iter    43/  229] train: loss: 0.1986633
[Epoch 24; Iter    73/  229] train: loss: 0.1159442
[Epoch 24; Iter   103/  229] train: loss: 0.2629160
[Epoch 24; Iter   133/  229] train: loss: 0.1308785
[Epoch 24; Iter   163/  229] train: loss: 0.1334915
[Epoch 24; Iter   193/  229] train: loss: 0.1910657
[Epoch 24; Iter   223/  229] train: loss: 0.1303268
[Epoch 24] ogbg-moltoxcast: 0.688980 val loss: 0.251641
[Epoch 24] ogbg-moltoxcast: 0.659332 test loss: 0.300749
[Epoch 25; Iter    24/  229] train: loss: 0.1078549
[Epoch 25; Iter    54/  229] train: loss: 0.1101586
[Epoch 25; Iter    84/  229] train: loss: 0.1328299
[Epoch 25; Iter   114/  229] train: loss: 0.2342317
[Epoch 25; Iter   144/  229] train: loss: 0.1956033
[Epoch 25; Iter   174/  229] train: loss: 0.1461672
[Epoch 25; Iter   204/  229] train: loss: 0.1303619
[Epoch 25] ogbg-moltoxcast: 0.686738 val loss: 0.245506
[Epoch 25] ogbg-moltoxcast: 0.667460 test loss: 0.285432
[Epoch 26; Iter     5/  229] train: loss: 0.1585633
[Epoch 26; Iter    35/  229] train: loss: 0.1519640
[Epoch 26; Iter    65/  229] train: loss: 0.1979327
[Epoch 26; Iter    95/  229] train: loss: 0.1950569
[Epoch 26; Iter   125/  229] train: loss: 0.2068257
[Epoch 26; Iter   155/  229] train: loss: 0.1540111
[Epoch 26; Iter   185/  229] train: loss: 0.1125027
[Epoch 26; Iter   215/  229] train: loss: 0.1565053
[Epoch 26] ogbg-moltoxcast: 0.692879 val loss: 0.249147
[Epoch 26] ogbg-moltoxcast: 0.664104 test loss: 0.292657
[Epoch 27; Iter    16/  229] train: loss: 0.1144449
[Epoch 27; Iter    46/  229] train: loss: 0.1467837
[Epoch 27; Iter    76/  229] train: loss: 0.1460315
[Epoch 27; Iter   106/  229] train: loss: 0.0956502
[Epoch 27; Iter   136/  229] train: loss: 0.1848004
[Epoch 27; Iter   166/  229] train: loss: 0.1479623
[Epoch 27; Iter   196/  229] train: loss: 0.2187181
[Epoch 27; Iter   226/  229] train: loss: 0.1352014
[Epoch 27] ogbg-moltoxcast: 0.684415 val loss: 0.251368
[Epoch 27] ogbg-moltoxcast: 0.660984 test loss: 0.291569
[Epoch 28; Iter    27/  229] train: loss: 0.1816821
[Epoch 28; Iter    57/  229] train: loss: 0.1622715
[Epoch 28; Iter    87/  229] train: loss: 0.1525920
[Epoch 28; Iter   117/  229] train: loss: 0.1785577
[Epoch 28; Iter   147/  229] train: loss: 0.1857124
[Epoch 28; Iter   177/  229] train: loss: 0.1562256
[Epoch 28; Iter   207/  229] train: loss: 0.1921590
[Epoch 28] ogbg-moltoxcast: 0.678514 val loss: 0.271475
[Epoch 28] ogbg-moltoxcast: 0.650194 test loss: 0.314741
[Epoch 29; Iter     8/  229] train: loss: 0.1195321
[Epoch 29; Iter    38/  229] train: loss: 0.1272040
[Epoch 29; Iter    68/  229] train: loss: 0.1271695
[Epoch 29; Iter    98/  229] train: loss: 0.1869312
[Epoch 29; Iter   128/  229] train: loss: 0.1528252
[Epoch 29; Iter   158/  229] train: loss: 0.0972465
[Epoch 29; Iter   188/  229] train: loss: 0.1593121
[Epoch 29; Iter   218/  229] train: loss: 0.1377060
[Epoch 29] ogbg-moltoxcast: 0.653727 val loss: 0.266498
[Epoch 29] ogbg-moltoxcast: 0.624209 test loss: 0.312664
[Epoch 30; Iter    19/  229] train: loss: 0.1372519
[Epoch 30; Iter    49/  229] train: loss: 0.1877965
[Epoch 30; Iter    79/  229] train: loss: 0.1158803
[Epoch 30; Iter   109/  229] train: loss: 0.1937800
[Epoch 30; Iter   139/  229] train: loss: 0.1693337
[Epoch 30; Iter   169/  229] train: loss: 0.1700527
[Epoch 30; Iter   199/  229] train: loss: 0.1571817
[Epoch 30; Iter   229/  229] train: loss: 0.1868843
[Epoch 30] ogbg-moltoxcast: 0.678548 val loss: 0.278048
[Epoch 30] ogbg-moltoxcast: 0.639661 test loss: 0.319920
[Epoch 31; Iter    30/  229] train: loss: 0.2052773
[Epoch 31; Iter    60/  229] train: loss: 0.1830234
[Epoch 31; Iter    90/  229] train: loss: 0.1672811
[Epoch 31; Iter   120/  229] train: loss: 0.1489894
[Epoch 31; Iter   150/  229] train: loss: 0.1513734
[Epoch 31; Iter   180/  229] train: loss: 0.2314980
[Epoch 31; Iter   210/  229] train: loss: 0.1426726
[Epoch 31] ogbg-moltoxcast: 0.685724 val loss: 0.265772
[Epoch 31] ogbg-moltoxcast: 0.634324 test loss: 0.316903
[Epoch 32; Iter    11/  229] train: loss: 0.1457755
[Epoch 32; Iter    41/  229] train: loss: 0.1311013
[Epoch 32; Iter    71/  229] train: loss: 0.1566075
[Epoch 32; Iter   101/  229] train: loss: 0.1930667
[Epoch 32; Iter   131/  229] train: loss: 0.1153418
[Epoch 32; Iter   161/  229] train: loss: 0.1659732
[Epoch 32; Iter   191/  229] train: loss: 0.0993781
[Epoch 32; Iter   221/  229] train: loss: 0.1545412
[Epoch 32] ogbg-moltoxcast: 0.686137 val loss: 0.267479
[Epoch 32] ogbg-moltoxcast: 0.651992 test loss: 0.307105
[Epoch 33; Iter    22/  229] train: loss: 0.1103037
[Epoch 33; Iter    52/  229] train: loss: 0.1355315
[Epoch 33; Iter    82/  229] train: loss: 0.1323005
[Epoch 33; Iter   112/  229] train: loss: 0.1986618
[Epoch 33; Iter   142/  229] train: loss: 0.1061466
[Epoch 33; Iter   172/  229] train: loss: 0.1577496
[Epoch 33; Iter   202/  229] train: loss: 0.1027383
[Epoch 33] ogbg-moltoxcast: 0.687335 val loss: 0.320196
[Epoch 33] ogbg-moltoxcast: 0.645543 test loss: 0.316164
[Epoch 34; Iter     3/  229] train: loss: 0.1825607
[Epoch 34; Iter    33/  229] train: loss: 0.1575201
[Epoch 34; Iter    63/  229] train: loss: 0.1502560
[Epoch 34; Iter    93/  229] train: loss: 0.1611554
[Epoch 34; Iter   123/  229] train: loss: 0.1422953
[Epoch 34; Iter   153/  229] train: loss: 0.1345689
[Epoch 34; Iter   183/  229] train: loss: 0.1189971
[Epoch 34; Iter   213/  229] train: loss: 0.2042799
[Epoch 34] ogbg-moltoxcast: 0.685357 val loss: 0.281304
[Epoch 34] ogbg-moltoxcast: 0.644158 test loss: 0.329634
[Epoch 35; Iter    14/  229] train: loss: 0.0776388
[Epoch 35; Iter    44/  229] train: loss: 0.1492959
[Epoch 35; Iter    74/  229] train: loss: 0.1450613
[Epoch 35; Iter   104/  229] train: loss: 0.1924478
[Epoch 35; Iter   134/  229] train: loss: 0.1925189
[Epoch 35; Iter   164/  229] train: loss: 0.1634909
[Epoch 35; Iter   194/  229] train: loss: 0.1302711
[Epoch 35; Iter   224/  229] train: loss: 0.1350875
[Epoch 35] ogbg-moltoxcast: 0.678874 val loss: 0.275383
[Epoch 35] ogbg-moltoxcast: 0.637945 test loss: 0.318964
[Epoch 36; Iter    25/  229] train: loss: 0.1815014
[Epoch 36; Iter    55/  229] train: loss: 0.1686511
[Epoch 36; Iter    85/  229] train: loss: 0.1260087
[Epoch 36; Iter   115/  229] train: loss: 0.1099360
[Epoch 36; Iter   145/  229] train: loss: 0.1705794
[Epoch 36; Iter   175/  229] train: loss: 0.1631228
[Epoch 36; Iter   205/  229] train: loss: 0.1838530
[Epoch 36] ogbg-moltoxcast: 0.690024 val loss: 0.328566
[Epoch 36] ogbg-moltoxcast: 0.641332 test loss: 0.316412
[Epoch 37; Iter     6/  229] train: loss: 0.1141150
[Epoch 37; Iter    36/  229] train: loss: 0.0934980
[Epoch 37; Iter    66/  229] train: loss: 0.1412215
[Epoch 37; Iter    96/  229] train: loss: 0.1359406
[Epoch 37; Iter   126/  229] train: loss: 0.1321249
[Epoch 37; Iter   156/  229] train: loss: 0.1267412
[Epoch 37; Iter   186/  229] train: loss: 0.1312760
[Epoch 37; Iter   216/  229] train: loss: 0.1547473
[Epoch 37] ogbg-moltoxcast: 0.682648 val loss: 0.349006
[Epoch 37] ogbg-moltoxcast: 0.644641 test loss: 0.325595
[Epoch 38; Iter    17/  229] train: loss: 0.1796560
[Epoch 38; Iter    47/  229] train: loss: 0.1491680
[Epoch 38; Iter    77/  229] train: loss: 0.1245526
[Epoch 38; Iter   107/  229] train: loss: 0.1392269
[Epoch 38; Iter   137/  229] train: loss: 0.1661610
[Epoch 38; Iter   167/  229] train: loss: 0.1505657
[Epoch 38; Iter   197/  229] train: loss: 0.1508962
[Epoch 38; Iter   227/  229] train: loss: 0.1610436
[Epoch 38] ogbg-moltoxcast: 0.682024 val loss: 0.349342
[Epoch 38] ogbg-moltoxcast: 0.644126 test loss: 0.328261
[Epoch 39; Iter    28/  229] train: loss: 0.1747249
[Epoch 39; Iter    58/  229] train: loss: 0.1065934
[Epoch 39; Iter    88/  229] train: loss: 0.1196539
[Epoch 39; Iter   118/  229] train: loss: 0.2236217
[Epoch 39; Iter   148/  229] train: loss: 0.1403796
[Epoch 39; Iter   178/  229] train: loss: 0.1602667
[Epoch 39; Iter   208/  229] train: loss: 0.1834727
[Epoch 39] ogbg-moltoxcast: 0.680072 val loss: 0.498737
[Epoch 39] ogbg-moltoxcast: 0.644355 test loss: 0.346155
[Epoch 40; Iter     9/  229] train: loss: 0.1421711
[Epoch 40; Iter    39/  229] train: loss: 0.1162679
[Epoch 40; Iter    69/  229] train: loss: 0.1087684
[Epoch 40; Iter    99/  229] train: loss: 0.1704290
[Epoch 40; Iter   129/  229] train: loss: 0.1274820
[Epoch 40; Iter   159/  229] train: loss: 0.1258058
[Epoch 40; Iter   189/  229] train: loss: 0.1522122
[Epoch 40; Iter   219/  229] train: loss: 0.1991080
[Epoch 40] ogbg-moltoxcast: 0.688032 val loss: 0.572380
[Epoch 40] ogbg-moltoxcast: 0.648631 test loss: 0.381840
[Epoch 41; Iter    20/  229] train: loss: 0.1432944
[Epoch 41; Iter    50/  229] train: loss: 0.1154541
[Epoch 41; Iter    80/  229] train: loss: 0.0899084
[Epoch 41; Iter   110/  229] train: loss: 0.1061571
[Epoch 41; Iter   140/  229] train: loss: 0.1076667
[Epoch 41; Iter   170/  229] train: loss: 0.0999275
[Epoch 41; Iter   200/  229] train: loss: 0.1560136
[Epoch 41] ogbg-moltoxcast: 0.683692 val loss: 0.390657
[Epoch 41] ogbg-moltoxcast: 0.647926 test loss: 0.326847
[Epoch 42; Iter     1/  229] train: loss: 0.1727214
[Epoch 42; Iter    31/  229] train: loss: 0.1348156
[Epoch 42; Iter    61/  229] train: loss: 0.1686277
[Epoch 42; Iter    91/  229] train: loss: 0.1098775
[Epoch 42; Iter   121/  229] train: loss: 0.1580585
[Epoch 42; Iter   151/  229] train: loss: 0.1136726
[Epoch 42; Iter   181/  229] train: loss: 0.1465989
[Epoch 42; Iter   211/  229] train: loss: 0.1519658
[Epoch 42] ogbg-moltoxcast: 0.683505 val loss: 0.281677
[Epoch 42] ogbg-moltoxcast: 0.642556 test loss: 0.321999
[Epoch 43; Iter    12/  229] train: loss: 0.1658622
[Epoch 43; Iter    42/  229] train: loss: 0.1709003
[Epoch 43; Iter    72/  229] train: loss: 0.1534625
[Epoch 43; Iter   102/  229] train: loss: 0.1431532
[Epoch 43; Iter   132/  229] train: loss: 0.1095702
[Epoch 43; Iter   162/  229] train: loss: 0.1580716
[Epoch 43; Iter   192/  229] train: loss: 0.1059254
[Epoch 43; Iter   222/  229] train: loss: 0.1399607
[Epoch 43] ogbg-moltoxcast: 0.688120 val loss: 0.591789
[Epoch 43] ogbg-moltoxcast: 0.643929 test loss: 0.408561
[Epoch 28; Iter    27/  229] train: loss: 0.1976503
[Epoch 28; Iter    57/  229] train: loss: 0.2046912
[Epoch 28; Iter    87/  229] train: loss: 0.1504884
[Epoch 28; Iter   117/  229] train: loss: 0.2444439
[Epoch 28; Iter   147/  229] train: loss: 0.1340957
[Epoch 28; Iter   177/  229] train: loss: 0.1471433
[Epoch 28; Iter   207/  229] train: loss: 0.1910264
[Epoch 28] ogbg-moltoxcast: 0.673071 val loss: 0.268874
[Epoch 28] ogbg-moltoxcast: 0.653566 test loss: 0.320391
[Epoch 29; Iter     8/  229] train: loss: 0.2742758
[Epoch 29; Iter    38/  229] train: loss: 0.1787931
[Epoch 29; Iter    68/  229] train: loss: 0.2556057
[Epoch 29; Iter    98/  229] train: loss: 0.1505317
[Epoch 29; Iter   128/  229] train: loss: 0.1512349
[Epoch 29; Iter   158/  229] train: loss: 0.1977878
[Epoch 29; Iter   188/  229] train: loss: 0.1146306
[Epoch 29; Iter   218/  229] train: loss: 0.1803947
[Epoch 29] ogbg-moltoxcast: 0.684403 val loss: 0.263277
[Epoch 29] ogbg-moltoxcast: 0.648927 test loss: 0.309354
[Epoch 30; Iter    19/  229] train: loss: 0.1228941
[Epoch 30; Iter    49/  229] train: loss: 0.1210579
[Epoch 30; Iter    79/  229] train: loss: 0.2259359
[Epoch 30; Iter   109/  229] train: loss: 0.1390612
[Epoch 30; Iter   139/  229] train: loss: 0.1763784
[Epoch 30; Iter   169/  229] train: loss: 0.1932688
[Epoch 30; Iter   199/  229] train: loss: 0.1654420
[Epoch 30; Iter   229/  229] train: loss: 0.1523156
[Epoch 30] ogbg-moltoxcast: 0.678775 val loss: 0.265906
[Epoch 30] ogbg-moltoxcast: 0.648211 test loss: 0.313928
[Epoch 31; Iter    30/  229] train: loss: 0.0999783
[Epoch 31; Iter    60/  229] train: loss: 0.1341182
[Epoch 31; Iter    90/  229] train: loss: 0.1371220
[Epoch 31; Iter   120/  229] train: loss: 0.0686977
[Epoch 31; Iter   150/  229] train: loss: 0.1898338
[Epoch 31; Iter   180/  229] train: loss: 0.1421216
[Epoch 31; Iter   210/  229] train: loss: 0.1760526
[Epoch 31] ogbg-moltoxcast: 0.674432 val loss: 0.405626
[Epoch 31] ogbg-moltoxcast: 0.640954 test loss: 0.312912
[Epoch 32; Iter    11/  229] train: loss: 0.1666676
[Epoch 32; Iter    41/  229] train: loss: 0.1493539
[Epoch 32; Iter    71/  229] train: loss: 0.1453221
[Epoch 32; Iter   101/  229] train: loss: 0.1481541
[Epoch 32; Iter   131/  229] train: loss: 0.1924966
[Epoch 32; Iter   161/  229] train: loss: 0.1456137
[Epoch 32; Iter   191/  229] train: loss: 0.1267311
[Epoch 32; Iter   221/  229] train: loss: 0.0999537
[Epoch 32] ogbg-moltoxcast: 0.683669 val loss: 0.267085
[Epoch 32] ogbg-moltoxcast: 0.653731 test loss: 0.312639
[Epoch 33; Iter    22/  229] train: loss: 0.1478191
[Epoch 33; Iter    52/  229] train: loss: 0.1456724
[Epoch 33; Iter    82/  229] train: loss: 0.1536730
[Epoch 33; Iter   112/  229] train: loss: 0.1767033
[Epoch 33; Iter   142/  229] train: loss: 0.1617212
[Epoch 33; Iter   172/  229] train: loss: 0.1461417
[Epoch 33; Iter   202/  229] train: loss: 0.1726303
[Epoch 33] ogbg-moltoxcast: 0.679018 val loss: 0.275164
[Epoch 33] ogbg-moltoxcast: 0.647639 test loss: 0.319214
[Epoch 34; Iter     3/  229] train: loss: 0.1887034
[Epoch 34; Iter    33/  229] train: loss: 0.1305181
[Epoch 34; Iter    63/  229] train: loss: 0.1855674
[Epoch 34; Iter    93/  229] train: loss: 0.1652412
[Epoch 34; Iter   123/  229] train: loss: 0.1671242
[Epoch 34; Iter   153/  229] train: loss: 0.1344055
[Epoch 34; Iter   183/  229] train: loss: 0.1424312
[Epoch 34; Iter   213/  229] train: loss: 0.1731146
[Epoch 34] ogbg-moltoxcast: 0.670104 val loss: 0.269026
[Epoch 34] ogbg-moltoxcast: 0.649005 test loss: 0.313674
[Epoch 35; Iter    14/  229] train: loss: 0.1464217
[Epoch 35; Iter    44/  229] train: loss: 0.1212124
[Epoch 35; Iter    74/  229] train: loss: 0.1077862
[Epoch 35; Iter   104/  229] train: loss: 0.1484984
[Epoch 35; Iter   134/  229] train: loss: 0.1442866
[Epoch 35; Iter   164/  229] train: loss: 0.1363125
[Epoch 35; Iter   194/  229] train: loss: 0.1788361
[Epoch 35; Iter   224/  229] train: loss: 0.1537671
[Epoch 35] ogbg-moltoxcast: 0.683301 val loss: 0.272144
[Epoch 35] ogbg-moltoxcast: 0.648040 test loss: 0.317346
[Epoch 36; Iter    25/  229] train: loss: 0.1295277
[Epoch 36; Iter    55/  229] train: loss: 0.1532302
[Epoch 36; Iter    85/  229] train: loss: 0.1569206
[Epoch 36; Iter   115/  229] train: loss: 0.1325583
[Epoch 36; Iter   145/  229] train: loss: 0.1757754
[Epoch 36; Iter   175/  229] train: loss: 0.1223645
[Epoch 36; Iter   205/  229] train: loss: 0.1662911
[Epoch 36] ogbg-moltoxcast: 0.690862 val loss: 0.268484
[Epoch 36] ogbg-moltoxcast: 0.657923 test loss: 0.316764
[Epoch 37; Iter     6/  229] train: loss: 0.1445426
[Epoch 37; Iter    36/  229] train: loss: 0.1333445
[Epoch 37; Iter    66/  229] train: loss: 0.1996173
[Epoch 37; Iter    96/  229] train: loss: 0.1123809
[Epoch 37; Iter   126/  229] train: loss: 0.1348263
[Epoch 37; Iter   156/  229] train: loss: 0.1703577
[Epoch 37; Iter   186/  229] train: loss: 0.1483162
[Epoch 37; Iter   216/  229] train: loss: 0.1622654
[Epoch 37] ogbg-moltoxcast: 0.683663 val loss: 0.268079
[Epoch 37] ogbg-moltoxcast: 0.643835 test loss: 0.316615
[Epoch 38; Iter    17/  229] train: loss: 0.1234613
[Epoch 38; Iter    47/  229] train: loss: 0.1619328
[Epoch 38; Iter    77/  229] train: loss: 0.1115175
[Epoch 38; Iter   107/  229] train: loss: 0.1186930
[Epoch 38; Iter   137/  229] train: loss: 0.1469732
[Epoch 38; Iter   167/  229] train: loss: 0.1100090
[Epoch 38; Iter   197/  229] train: loss: 0.1469379
[Epoch 38; Iter   227/  229] train: loss: 0.1285731
[Epoch 38] ogbg-moltoxcast: 0.683803 val loss: 0.273146
[Epoch 38] ogbg-moltoxcast: 0.652805 test loss: 0.317023
[Epoch 39; Iter    28/  229] train: loss: 0.1714209
[Epoch 39; Iter    58/  229] train: loss: 0.1252442
[Epoch 39; Iter    88/  229] train: loss: 0.1453050
[Epoch 39; Iter   118/  229] train: loss: 0.1690934
[Epoch 39; Iter   148/  229] train: loss: 0.1416039
[Epoch 39; Iter   178/  229] train: loss: 0.1153255
[Epoch 39; Iter   208/  229] train: loss: 0.1202912
[Epoch 39] ogbg-moltoxcast: 0.683179 val loss: 0.277616
[Epoch 39] ogbg-moltoxcast: 0.652452 test loss: 0.315891
[Epoch 40; Iter     9/  229] train: loss: 0.1573763
[Epoch 40; Iter    39/  229] train: loss: 0.1166434
[Epoch 40; Iter    69/  229] train: loss: 0.1628752
[Epoch 40; Iter    99/  229] train: loss: 0.1177890
[Epoch 40; Iter   129/  229] train: loss: 0.1384493
[Epoch 40; Iter   159/  229] train: loss: 0.1352027
[Epoch 40; Iter   189/  229] train: loss: 0.1495975
[Epoch 40; Iter   219/  229] train: loss: 0.1447383
[Epoch 40] ogbg-moltoxcast: 0.690475 val loss: 0.276320
[Epoch 40] ogbg-moltoxcast: 0.654046 test loss: 0.319905
[Epoch 41; Iter    20/  229] train: loss: 0.1650785
[Epoch 41; Iter    50/  229] train: loss: 0.1207772
[Epoch 41; Iter    80/  229] train: loss: 0.2049519
[Epoch 41; Iter   110/  229] train: loss: 0.0676615
[Epoch 41; Iter   140/  229] train: loss: 0.1714067
[Epoch 41; Iter   170/  229] train: loss: 0.1753760
[Epoch 41; Iter   200/  229] train: loss: 0.1531600
[Epoch 41] ogbg-moltoxcast: 0.685959 val loss: 0.281889
[Epoch 41] ogbg-moltoxcast: 0.654581 test loss: 0.328102
[Epoch 42; Iter     1/  229] train: loss: 0.1465082
[Epoch 42; Iter    31/  229] train: loss: 0.1103373
[Epoch 42; Iter    61/  229] train: loss: 0.1234526
[Epoch 42; Iter    91/  229] train: loss: 0.1530711
[Epoch 42; Iter   121/  229] train: loss: 0.1565619
[Epoch 42; Iter   151/  229] train: loss: 0.1156542
[Epoch 42; Iter   181/  229] train: loss: 0.1438455
[Epoch 42; Iter   211/  229] train: loss: 0.1214371
[Epoch 42] ogbg-moltoxcast: 0.679497 val loss: 0.273147
[Epoch 42] ogbg-moltoxcast: 0.655059 test loss: 0.318639
[Epoch 43; Iter    12/  229] train: loss: 0.0866416
[Epoch 43; Iter    42/  229] train: loss: 0.1773847
[Epoch 43; Iter    72/  229] train: loss: 0.1294575
[Epoch 43; Iter   102/  229] train: loss: 0.1613799
[Epoch 43; Iter   132/  229] train: loss: 0.1120726
[Epoch 43; Iter   162/  229] train: loss: 0.0974968
[Epoch 43; Iter   192/  229] train: loss: 0.1651934
[Epoch 43; Iter   222/  229] train: loss: 0.1230579
[Epoch 43] ogbg-moltoxcast: 0.685332 val loss: 0.277891
[Epoch 43] ogbg-moltoxcast: 0.654317 test loss: 0.330385
[Epoch 28; Iter    27/  229] train: loss: 0.1840204
[Epoch 28; Iter    57/  229] train: loss: 0.1574480
[Epoch 28; Iter    87/  229] train: loss: 0.1636433
[Epoch 28; Iter   117/  229] train: loss: 0.2181935
[Epoch 28; Iter   147/  229] train: loss: 0.1729185
[Epoch 28; Iter   177/  229] train: loss: 0.1680036
[Epoch 28; Iter   207/  229] train: loss: 0.1729455
[Epoch 28] ogbg-moltoxcast: 0.687623 val loss: 0.261630
[Epoch 28] ogbg-moltoxcast: 0.646474 test loss: 0.306798
[Epoch 29; Iter     8/  229] train: loss: 0.1368236
[Epoch 29; Iter    38/  229] train: loss: 0.1343540
[Epoch 29; Iter    68/  229] train: loss: 0.2057285
[Epoch 29; Iter    98/  229] train: loss: 0.1961864
[Epoch 29; Iter   128/  229] train: loss: 0.2410110
[Epoch 29; Iter   158/  229] train: loss: 0.1626519
[Epoch 29; Iter   188/  229] train: loss: 0.2015209
[Epoch 29; Iter   218/  229] train: loss: 0.1470181
[Epoch 29] ogbg-moltoxcast: 0.686846 val loss: 0.261826
[Epoch 29] ogbg-moltoxcast: 0.646069 test loss: 0.307830
[Epoch 30; Iter    19/  229] train: loss: 0.1550692
[Epoch 30; Iter    49/  229] train: loss: 0.2149112
[Epoch 30; Iter    79/  229] train: loss: 0.1281371
[Epoch 30; Iter   109/  229] train: loss: 0.1204246
[Epoch 30; Iter   139/  229] train: loss: 0.1511871
[Epoch 30; Iter   169/  229] train: loss: 0.1576539
[Epoch 30; Iter   199/  229] train: loss: 0.1176943
[Epoch 30; Iter   229/  229] train: loss: 0.2467057
[Epoch 30] ogbg-moltoxcast: 0.691040 val loss: 0.257236
[Epoch 30] ogbg-moltoxcast: 0.651289 test loss: 0.309856
[Epoch 31; Iter    30/  229] train: loss: 0.1440014
[Epoch 31; Iter    60/  229] train: loss: 0.1439743
[Epoch 31; Iter    90/  229] train: loss: 0.1361685
[Epoch 31; Iter   120/  229] train: loss: 0.1066336
[Epoch 31; Iter   150/  229] train: loss: 0.1865497
[Epoch 31; Iter   180/  229] train: loss: 0.1392834
[Epoch 31; Iter   210/  229] train: loss: 0.0726560
[Epoch 31] ogbg-moltoxcast: 0.690919 val loss: 0.266016
[Epoch 31] ogbg-moltoxcast: 0.650679 test loss: 0.312450
[Epoch 32; Iter    11/  229] train: loss: 0.1654918
[Epoch 32; Iter    41/  229] train: loss: 0.1299020
[Epoch 32; Iter    71/  229] train: loss: 0.1164221
[Epoch 32; Iter   101/  229] train: loss: 0.1524369
[Epoch 32; Iter   131/  229] train: loss: 0.1420304
[Epoch 32; Iter   161/  229] train: loss: 0.1266709
[Epoch 32; Iter   191/  229] train: loss: 0.1637885
[Epoch 32; Iter   221/  229] train: loss: 0.1311764
[Epoch 32] ogbg-moltoxcast: 0.677116 val loss: 0.265584
[Epoch 32] ogbg-moltoxcast: 0.647494 test loss: 0.316740
[Epoch 33; Iter    22/  229] train: loss: 0.2005520
[Epoch 33; Iter    52/  229] train: loss: 0.1672338
[Epoch 33; Iter    82/  229] train: loss: 0.1380912
[Epoch 33; Iter   112/  229] train: loss: 0.1574654
[Epoch 33; Iter   142/  229] train: loss: 0.1533012
[Epoch 33; Iter   172/  229] train: loss: 0.1150223
[Epoch 33; Iter   202/  229] train: loss: 0.1342535
[Epoch 33] ogbg-moltoxcast: 0.669073 val loss: 0.275665
[Epoch 33] ogbg-moltoxcast: 0.643395 test loss: 0.324426
[Epoch 34; Iter     3/  229] train: loss: 0.1407805
[Epoch 34; Iter    33/  229] train: loss: 0.1973243
[Epoch 34; Iter    63/  229] train: loss: 0.1682918
[Epoch 34; Iter    93/  229] train: loss: 0.1840551
[Epoch 34; Iter   123/  229] train: loss: 0.1207734
[Epoch 34; Iter   153/  229] train: loss: 0.1270103
[Epoch 34; Iter   183/  229] train: loss: 0.1818487
[Epoch 34; Iter   213/  229] train: loss: 0.2006790
[Epoch 34] ogbg-moltoxcast: 0.680532 val loss: 0.273881
[Epoch 34] ogbg-moltoxcast: 0.630368 test loss: 0.328060
[Epoch 35; Iter    14/  229] train: loss: 0.1836767
[Epoch 35; Iter    44/  229] train: loss: 0.1271989
[Epoch 35; Iter    74/  229] train: loss: 0.1410109
[Epoch 35; Iter   104/  229] train: loss: 0.2567881
[Epoch 35; Iter   134/  229] train: loss: 0.1251885
[Epoch 35; Iter   164/  229] train: loss: 0.1500329
[Epoch 35; Iter   194/  229] train: loss: 0.1557721
[Epoch 35; Iter   224/  229] train: loss: 0.1426428
[Epoch 35] ogbg-moltoxcast: 0.686457 val loss: 0.257967
[Epoch 35] ogbg-moltoxcast: 0.645038 test loss: 0.316293
[Epoch 36; Iter    25/  229] train: loss: 0.1562884
[Epoch 36; Iter    55/  229] train: loss: 0.1711576
[Epoch 36; Iter    85/  229] train: loss: 0.1323622
[Epoch 36; Iter   115/  229] train: loss: 0.1359306
[Epoch 36; Iter   145/  229] train: loss: 0.1306580
[Epoch 36; Iter   175/  229] train: loss: 0.1370015
[Epoch 36; Iter   205/  229] train: loss: 0.1711958
[Epoch 36] ogbg-moltoxcast: 0.684749 val loss: 0.272323
[Epoch 36] ogbg-moltoxcast: 0.639136 test loss: 0.326403
[Epoch 37; Iter     6/  229] train: loss: 0.1668103
[Epoch 37; Iter    36/  229] train: loss: 0.2267554
[Epoch 37; Iter    66/  229] train: loss: 0.1319995
[Epoch 37; Iter    96/  229] train: loss: 0.1604015
[Epoch 37; Iter   126/  229] train: loss: 0.1370674
[Epoch 37; Iter   156/  229] train: loss: 0.1565222
[Epoch 37; Iter   186/  229] train: loss: 0.1106857
[Epoch 37; Iter   216/  229] train: loss: 0.1479528
[Epoch 37] ogbg-moltoxcast: 0.692904 val loss: 0.261862
[Epoch 37] ogbg-moltoxcast: 0.653683 test loss: 0.309814
[Epoch 38; Iter    17/  229] train: loss: 0.1750386
[Epoch 38; Iter    47/  229] train: loss: 0.1564481
[Epoch 38; Iter    77/  229] train: loss: 0.1434610
[Epoch 38; Iter   107/  229] train: loss: 0.1707762
[Epoch 38; Iter   137/  229] train: loss: 0.1209262
[Epoch 38; Iter   167/  229] train: loss: 0.1272894
[Epoch 38; Iter   197/  229] train: loss: 0.1762053
[Epoch 38; Iter   227/  229] train: loss: 0.1301929
[Epoch 38] ogbg-moltoxcast: 0.687885 val loss: 0.265651
[Epoch 38] ogbg-moltoxcast: 0.645991 test loss: 0.313300
[Epoch 39; Iter    28/  229] train: loss: 0.1849551
[Epoch 39; Iter    58/  229] train: loss: 0.1422236
[Epoch 39; Iter    88/  229] train: loss: 0.1573908
[Epoch 39; Iter   118/  229] train: loss: 0.2070936
[Epoch 39; Iter   148/  229] train: loss: 0.1453757
[Epoch 39; Iter   178/  229] train: loss: 0.1670798
[Epoch 39; Iter   208/  229] train: loss: 0.1436969
[Epoch 39] ogbg-moltoxcast: 0.686217 val loss: 0.261868
[Epoch 39] ogbg-moltoxcast: 0.638726 test loss: 0.323847
[Epoch 40; Iter     9/  229] train: loss: 0.1364387
[Epoch 40; Iter    39/  229] train: loss: 0.2073306
[Epoch 40; Iter    69/  229] train: loss: 0.1697438
[Epoch 40; Iter    99/  229] train: loss: 0.0774378
[Epoch 40; Iter   129/  229] train: loss: 0.1848857
[Epoch 40; Iter   159/  229] train: loss: 0.1206724
[Epoch 40; Iter   189/  229] train: loss: 0.1199203
[Epoch 40; Iter   219/  229] train: loss: 0.1743688
[Epoch 40] ogbg-moltoxcast: 0.686763 val loss: 0.267362
[Epoch 40] ogbg-moltoxcast: 0.648118 test loss: 0.318128
[Epoch 41; Iter    20/  229] train: loss: 0.1355612
[Epoch 41; Iter    50/  229] train: loss: 0.1738015
[Epoch 41; Iter    80/  229] train: loss: 0.1569445
[Epoch 41; Iter   110/  229] train: loss: 0.1815324
[Epoch 41; Iter   140/  229] train: loss: 0.1460290
[Epoch 41; Iter   170/  229] train: loss: 0.1226027
[Epoch 41; Iter   200/  229] train: loss: 0.1777587
[Epoch 41] ogbg-moltoxcast: 0.695930 val loss: 0.266424
[Epoch 41] ogbg-moltoxcast: 0.655993 test loss: 0.312431
[Epoch 42; Iter     1/  229] train: loss: 0.1887316
[Epoch 42; Iter    31/  229] train: loss: 0.1082999
[Epoch 42; Iter    61/  229] train: loss: 0.1099664
[Epoch 42; Iter    91/  229] train: loss: 0.1690103
[Epoch 42; Iter   121/  229] train: loss: 0.1082230
[Epoch 42; Iter   151/  229] train: loss: 0.1153193
[Epoch 42; Iter   181/  229] train: loss: 0.2225250
[Epoch 42; Iter   211/  229] train: loss: 0.1123526
[Epoch 42] ogbg-moltoxcast: 0.694730 val loss: 0.271064
[Epoch 42] ogbg-moltoxcast: 0.657104 test loss: 0.318075
[Epoch 43; Iter    12/  229] train: loss: 0.1240728
[Epoch 43; Iter    42/  229] train: loss: 0.1403893
[Epoch 43; Iter    72/  229] train: loss: 0.1841900
[Epoch 43; Iter   102/  229] train: loss: 0.1314828
[Epoch 43; Iter   132/  229] train: loss: 0.1337606
[Epoch 43; Iter   162/  229] train: loss: 0.1414096
[Epoch 43; Iter   192/  229] train: loss: 0.1334345
[Epoch 43; Iter   222/  229] train: loss: 0.1552878
[Epoch 43] ogbg-moltoxcast: 0.689114 val loss: 0.273866
[Epoch 43] ogbg-moltoxcast: 0.651749 test loss: 0.322454
[Epoch 28; Iter    27/  229] train: loss: 0.1858288
[Epoch 28; Iter    57/  229] train: loss: 0.1591846
[Epoch 28; Iter    87/  229] train: loss: 0.1690401
[Epoch 28; Iter   117/  229] train: loss: 0.2133878
[Epoch 28; Iter   147/  229] train: loss: 0.1703832
[Epoch 28; Iter   177/  229] train: loss: 0.1748169
[Epoch 28; Iter   207/  229] train: loss: 0.1897017
[Epoch 28] ogbg-moltoxcast: 0.669217 val loss: 0.298329
[Epoch 28] ogbg-moltoxcast: 0.636181 test loss: 0.722430
[Epoch 29; Iter     8/  229] train: loss: 0.1365986
[Epoch 29; Iter    38/  229] train: loss: 0.1313417
[Epoch 29; Iter    68/  229] train: loss: 0.2098143
[Epoch 29; Iter    98/  229] train: loss: 0.1994188
[Epoch 29; Iter   128/  229] train: loss: 0.2515725
[Epoch 29; Iter   158/  229] train: loss: 0.1596159
[Epoch 29; Iter   188/  229] train: loss: 0.2130806
[Epoch 29; Iter   218/  229] train: loss: 0.1515615
[Epoch 29] ogbg-moltoxcast: 0.676172 val loss: 0.282429
[Epoch 29] ogbg-moltoxcast: 0.638985 test loss: 0.356149
[Epoch 30; Iter    19/  229] train: loss: 0.1686729
[Epoch 30; Iter    49/  229] train: loss: 0.2276591
[Epoch 30; Iter    79/  229] train: loss: 0.1490519
[Epoch 30; Iter   109/  229] train: loss: 0.1191713
[Epoch 30; Iter   139/  229] train: loss: 0.1541116
[Epoch 30; Iter   169/  229] train: loss: 0.1714174
[Epoch 30; Iter   199/  229] train: loss: 0.1129678
[Epoch 30; Iter   229/  229] train: loss: 0.2507673
[Epoch 30] ogbg-moltoxcast: 0.661420 val loss: 0.275831
[Epoch 30] ogbg-moltoxcast: 0.639867 test loss: 0.374404
[Epoch 31; Iter    30/  229] train: loss: 0.1481132
[Epoch 31; Iter    60/  229] train: loss: 0.1635738
[Epoch 31; Iter    90/  229] train: loss: 0.1305392
[Epoch 31; Iter   120/  229] train: loss: 0.1155326
[Epoch 31; Iter   150/  229] train: loss: 0.1995355
[Epoch 31; Iter   180/  229] train: loss: 0.1425674
[Epoch 31; Iter   210/  229] train: loss: 0.0766635
[Epoch 31] ogbg-moltoxcast: 0.677736 val loss: 0.294908
[Epoch 31] ogbg-moltoxcast: 0.659263 test loss: 0.345250
[Epoch 32; Iter    11/  229] train: loss: 0.1755396
[Epoch 32; Iter    41/  229] train: loss: 0.1323576
[Epoch 32; Iter    71/  229] train: loss: 0.1172717
[Epoch 32; Iter   101/  229] train: loss: 0.1472420
[Epoch 32; Iter   131/  229] train: loss: 0.1460055
[Epoch 32; Iter   161/  229] train: loss: 0.1453494
[Epoch 32; Iter   191/  229] train: loss: 0.1701112
[Epoch 32; Iter   221/  229] train: loss: 0.1024519
[Epoch 32] ogbg-moltoxcast: 0.675785 val loss: 0.265164
[Epoch 32] ogbg-moltoxcast: 0.644155 test loss: 0.361882
[Epoch 33; Iter    22/  229] train: loss: 0.2056085
[Epoch 33; Iter    52/  229] train: loss: 0.1634859
[Epoch 33; Iter    82/  229] train: loss: 0.1550405
[Epoch 33; Iter   112/  229] train: loss: 0.1616721
[Epoch 33; Iter   142/  229] train: loss: 0.1693063
[Epoch 33; Iter   172/  229] train: loss: 0.1346849
[Epoch 33; Iter   202/  229] train: loss: 0.1167818
[Epoch 33] ogbg-moltoxcast: 0.671744 val loss: 0.311130
[Epoch 33] ogbg-moltoxcast: 0.656686 test loss: 0.432694
[Epoch 34; Iter     3/  229] train: loss: 0.1435600
[Epoch 34; Iter    33/  229] train: loss: 0.2076909
[Epoch 34; Iter    63/  229] train: loss: 0.1829682
[Epoch 34; Iter    93/  229] train: loss: 0.1772745
[Epoch 34; Iter   123/  229] train: loss: 0.1261681
[Epoch 34; Iter   153/  229] train: loss: 0.1321789
[Epoch 34; Iter   183/  229] train: loss: 0.1843700
[Epoch 34; Iter   213/  229] train: loss: 0.1768002
[Epoch 34] ogbg-moltoxcast: 0.679042 val loss: 0.300925
[Epoch 34] ogbg-moltoxcast: 0.641156 test loss: 0.641342
[Epoch 35; Iter    14/  229] train: loss: 0.1845748
[Epoch 35; Iter    44/  229] train: loss: 0.1351784
[Epoch 35; Iter    74/  229] train: loss: 0.1512823
[Epoch 35; Iter   104/  229] train: loss: 0.2753656
[Epoch 35; Iter   134/  229] train: loss: 0.1205739
[Epoch 35; Iter   164/  229] train: loss: 0.1539488
[Epoch 35; Iter   194/  229] train: loss: 0.1568907
[Epoch 35; Iter   224/  229] train: loss: 0.1351120
[Epoch 35] ogbg-moltoxcast: 0.682451 val loss: 0.299164
[Epoch 35] ogbg-moltoxcast: 0.652077 test loss: 0.520031
[Epoch 36; Iter    25/  229] train: loss: 0.1603075
[Epoch 36; Iter    55/  229] train: loss: 0.1679337
[Epoch 36; Iter    85/  229] train: loss: 0.1374132
[Epoch 36; Iter   115/  229] train: loss: 0.1329392
[Epoch 36; Iter   145/  229] train: loss: 0.1262257
[Epoch 36; Iter   175/  229] train: loss: 0.1410254
[Epoch 36; Iter   205/  229] train: loss: 0.1709663
[Epoch 36] ogbg-moltoxcast: 0.675131 val loss: 0.310744
[Epoch 36] ogbg-moltoxcast: 0.645866 test loss: 0.530470
[Epoch 37; Iter     6/  229] train: loss: 0.1714577
[Epoch 37; Iter    36/  229] train: loss: 0.2190436
[Epoch 37; Iter    66/  229] train: loss: 0.1341688
[Epoch 37; Iter    96/  229] train: loss: 0.1595881
[Epoch 37; Iter   126/  229] train: loss: 0.1386092
[Epoch 37; Iter   156/  229] train: loss: 0.1588621
[Epoch 37; Iter   186/  229] train: loss: 0.1143503
[Epoch 37; Iter   216/  229] train: loss: 0.1485061
[Epoch 37] ogbg-moltoxcast: 0.672549 val loss: 0.283441
[Epoch 37] ogbg-moltoxcast: 0.654882 test loss: 0.330250
[Epoch 38; Iter    17/  229] train: loss: 0.1879862
[Epoch 38; Iter    47/  229] train: loss: 0.1484326
[Epoch 38; Iter    77/  229] train: loss: 0.1422292
[Epoch 38; Iter   107/  229] train: loss: 0.1590498
[Epoch 38; Iter   137/  229] train: loss: 0.1141066
[Epoch 38; Iter   167/  229] train: loss: 0.1290865
[Epoch 38; Iter   197/  229] train: loss: 0.1811247
[Epoch 38; Iter   227/  229] train: loss: 0.1238866
[Epoch 38] ogbg-moltoxcast: 0.674761 val loss: 0.324461
[Epoch 38] ogbg-moltoxcast: 0.657160 test loss: 0.383199
[Epoch 39; Iter    28/  229] train: loss: 0.1777971
[Epoch 39; Iter    58/  229] train: loss: 0.1528116
[Epoch 39; Iter    88/  229] train: loss: 0.1770544
[Epoch 39; Iter   118/  229] train: loss: 0.2199555
[Epoch 39; Iter   148/  229] train: loss: 0.1501160
[Epoch 39; Iter   178/  229] train: loss: 0.1624818
[Epoch 39; Iter   208/  229] train: loss: 0.1556387
[Epoch 39] ogbg-moltoxcast: 0.671448 val loss: 0.288424
[Epoch 39] ogbg-moltoxcast: 0.647174 test loss: 0.654982
[Epoch 40; Iter     9/  229] train: loss: 0.1320058
[Epoch 40; Iter    39/  229] train: loss: 0.1986006
[Epoch 40; Iter    69/  229] train: loss: 0.1924763
[Epoch 40; Iter    99/  229] train: loss: 0.0764460
[Epoch 40; Iter   129/  229] train: loss: 0.1644770
[Epoch 40; Iter   159/  229] train: loss: 0.1170953
[Epoch 40; Iter   189/  229] train: loss: 0.1164523
[Epoch 40; Iter   219/  229] train: loss: 0.1768429
[Epoch 40] ogbg-moltoxcast: 0.682754 val loss: 0.265985
[Epoch 40] ogbg-moltoxcast: 0.653878 test loss: 0.410980
[Epoch 41; Iter    20/  229] train: loss: 0.1420869
[Epoch 41; Iter    50/  229] train: loss: 0.1765090
[Epoch 41; Iter    80/  229] train: loss: 0.1500689
[Epoch 41; Iter   110/  229] train: loss: 0.1800871
[Epoch 41; Iter   140/  229] train: loss: 0.1448543
[Epoch 41; Iter   170/  229] train: loss: 0.1292881
[Epoch 41; Iter   200/  229] train: loss: 0.1805396
[Epoch 41] ogbg-moltoxcast: 0.675764 val loss: 0.275717
[Epoch 41] ogbg-moltoxcast: 0.653166 test loss: 0.429289
[Epoch 42; Iter     1/  229] train: loss: 0.1912305
[Epoch 42; Iter    31/  229] train: loss: 0.1008799
[Epoch 42; Iter    61/  229] train: loss: 0.1198265
[Epoch 42; Iter    91/  229] train: loss: 0.1672830
[Epoch 42; Iter   121/  229] train: loss: 0.1092497
[Epoch 42; Iter   151/  229] train: loss: 0.1294323
[Epoch 42; Iter   181/  229] train: loss: 0.2155199
[Epoch 42; Iter   211/  229] train: loss: 0.1227507
[Epoch 42] ogbg-moltoxcast: 0.669219 val loss: 0.277590
[Epoch 42] ogbg-moltoxcast: 0.650716 test loss: 0.391822
[Epoch 43; Iter    12/  229] train: loss: 0.1330713
[Epoch 43; Iter    42/  229] train: loss: 0.1462417
[Epoch 43; Iter    72/  229] train: loss: 0.1836435
[Epoch 43; Iter   102/  229] train: loss: 0.1464069
[Epoch 43; Iter   132/  229] train: loss: 0.1408430
[Epoch 43; Iter   162/  229] train: loss: 0.1471504
[Epoch 43; Iter   192/  229] train: loss: 0.1411384
[Epoch 43; Iter   222/  229] train: loss: 0.1583129
[Epoch 43] ogbg-moltoxcast: 0.668731 val loss: 0.289567
[Epoch 43] ogbg-moltoxcast: 0.652536 test loss: 0.432740
[Epoch 28; Iter    27/  229] train: loss: 0.1766265
[Epoch 28; Iter    57/  229] train: loss: 0.1621196
[Epoch 28; Iter    87/  229] train: loss: 0.1566549
[Epoch 28; Iter   117/  229] train: loss: 0.2215008
[Epoch 28; Iter   147/  229] train: loss: 0.1659312
[Epoch 28; Iter   177/  229] train: loss: 0.1688490
[Epoch 28; Iter   207/  229] train: loss: 0.1834542
[Epoch 28] ogbg-moltoxcast: 0.674478 val loss: 0.280150
[Epoch 28] ogbg-moltoxcast: 0.649500 test loss: 0.434658
[Epoch 29; Iter     8/  229] train: loss: 0.1420361
[Epoch 29; Iter    38/  229] train: loss: 0.1329871
[Epoch 29; Iter    68/  229] train: loss: 0.1882826
[Epoch 29; Iter    98/  229] train: loss: 0.1828646
[Epoch 29; Iter   128/  229] train: loss: 0.2672805
[Epoch 29; Iter   158/  229] train: loss: 0.1465648
[Epoch 29; Iter   188/  229] train: loss: 0.2173341
[Epoch 29; Iter   218/  229] train: loss: 0.1392909
[Epoch 29] ogbg-moltoxcast: 0.673129 val loss: 0.292293
[Epoch 29] ogbg-moltoxcast: 0.658940 test loss: 0.318391
[Epoch 30; Iter    19/  229] train: loss: 0.1647398
[Epoch 30; Iter    49/  229] train: loss: 0.1923090
[Epoch 30; Iter    79/  229] train: loss: 0.1316743
[Epoch 30; Iter   109/  229] train: loss: 0.1332693
[Epoch 30; Iter   139/  229] train: loss: 0.1359795
[Epoch 30; Iter   169/  229] train: loss: 0.1576022
[Epoch 30; Iter   199/  229] train: loss: 0.1126637
[Epoch 30; Iter   229/  229] train: loss: 0.2182453
[Epoch 30] ogbg-moltoxcast: 0.669127 val loss: 0.280033
[Epoch 30] ogbg-moltoxcast: 0.658254 test loss: 0.317976
[Epoch 31; Iter    30/  229] train: loss: 0.1398733
[Epoch 31; Iter    60/  229] train: loss: 0.1433262
[Epoch 31; Iter    90/  229] train: loss: 0.1399762
[Epoch 31; Iter   120/  229] train: loss: 0.1056571
[Epoch 31; Iter   150/  229] train: loss: 0.1850754
[Epoch 31; Iter   180/  229] train: loss: 0.1328943
[Epoch 31; Iter   210/  229] train: loss: 0.0921162
[Epoch 31] ogbg-moltoxcast: 0.664627 val loss: 0.344869
[Epoch 31] ogbg-moltoxcast: 0.650924 test loss: 0.541353
[Epoch 32; Iter    11/  229] train: loss: 0.1927674
[Epoch 32; Iter    41/  229] train: loss: 0.1198494
[Epoch 32; Iter    71/  229] train: loss: 0.1113518
[Epoch 32; Iter   101/  229] train: loss: 0.1471943
[Epoch 32; Iter   131/  229] train: loss: 0.1379852
[Epoch 32; Iter   161/  229] train: loss: 0.1250128
[Epoch 32; Iter   191/  229] train: loss: 0.1655592
[Epoch 32; Iter   221/  229] train: loss: 0.1034521
[Epoch 32] ogbg-moltoxcast: 0.654836 val loss: 0.281127
[Epoch 32] ogbg-moltoxcast: 0.652787 test loss: 0.357485
[Epoch 33; Iter    22/  229] train: loss: 0.1749134
[Epoch 33; Iter    52/  229] train: loss: 0.1640052
[Epoch 33; Iter    82/  229] train: loss: 0.1404654
[Epoch 33; Iter   112/  229] train: loss: 0.1516794
[Epoch 33; Iter   142/  229] train: loss: 0.1482393
[Epoch 33; Iter   172/  229] train: loss: 0.1187770
[Epoch 33; Iter   202/  229] train: loss: 0.1113577
[Epoch 33] ogbg-moltoxcast: 0.676285 val loss: 0.276714
[Epoch 33] ogbg-moltoxcast: 0.663471 test loss: 0.317111
[Epoch 34; Iter     3/  229] train: loss: 0.1276003
[Epoch 34; Iter    33/  229] train: loss: 0.1899126
[Epoch 34; Iter    63/  229] train: loss: 0.1663421
[Epoch 34; Iter    93/  229] train: loss: 0.1869188
[Epoch 34; Iter   123/  229] train: loss: 0.1206279
[Epoch 34; Iter   153/  229] train: loss: 0.1249098
[Epoch 34; Iter   183/  229] train: loss: 0.1758834
[Epoch 34; Iter   213/  229] train: loss: 0.1745705
[Epoch 34] ogbg-moltoxcast: 0.681580 val loss: 0.557175
[Epoch 34] ogbg-moltoxcast: 0.654130 test loss: 1.320536
[Epoch 35; Iter    14/  229] train: loss: 0.1746575
[Epoch 35; Iter    44/  229] train: loss: 0.1213214
[Epoch 35; Iter    74/  229] train: loss: 0.1328019
[Epoch 35; Iter   104/  229] train: loss: 0.2705276
[Epoch 35; Iter   134/  229] train: loss: 0.1268080
[Epoch 35; Iter   164/  229] train: loss: 0.1439503
[Epoch 35; Iter   194/  229] train: loss: 0.1578790
[Epoch 35; Iter   224/  229] train: loss: 0.1438136
[Epoch 35] ogbg-moltoxcast: 0.674818 val loss: 0.319729
[Epoch 35] ogbg-moltoxcast: 0.655743 test loss: 0.517774
[Epoch 36; Iter    25/  229] train: loss: 0.1432555
[Epoch 36; Iter    55/  229] train: loss: 0.1859635
[Epoch 36; Iter    85/  229] train: loss: 0.1294509
[Epoch 36; Iter   115/  229] train: loss: 0.1301160
[Epoch 36; Iter   145/  229] train: loss: 0.1307386
[Epoch 36; Iter   175/  229] train: loss: 0.1385352
[Epoch 36; Iter   205/  229] train: loss: 0.1644468
[Epoch 36] ogbg-moltoxcast: 0.662386 val loss: 0.321376
[Epoch 36] ogbg-moltoxcast: 0.649434 test loss: 0.362305
[Epoch 37; Iter     6/  229] train: loss: 0.1496654
[Epoch 37; Iter    36/  229] train: loss: 0.2249580
[Epoch 37; Iter    66/  229] train: loss: 0.1263760
[Epoch 37; Iter    96/  229] train: loss: 0.1460855
[Epoch 37; Iter   126/  229] train: loss: 0.1323235
[Epoch 37; Iter   156/  229] train: loss: 0.1529561
[Epoch 37; Iter   186/  229] train: loss: 0.1004938
[Epoch 37; Iter   216/  229] train: loss: 0.1340255
[Epoch 37] ogbg-moltoxcast: 0.678483 val loss: 0.292201
[Epoch 37] ogbg-moltoxcast: 0.668282 test loss: 0.321343
[Epoch 38; Iter    17/  229] train: loss: 0.1743322
[Epoch 38; Iter    47/  229] train: loss: 0.1352793
[Epoch 38; Iter    77/  229] train: loss: 0.1345572
[Epoch 38; Iter   107/  229] train: loss: 0.1489243
[Epoch 38; Iter   137/  229] train: loss: 0.1189187
[Epoch 38; Iter   167/  229] train: loss: 0.1250923
[Epoch 38; Iter   197/  229] train: loss: 0.1687066
[Epoch 38; Iter   227/  229] train: loss: 0.1216531
[Epoch 38] ogbg-moltoxcast: 0.676697 val loss: 0.276329
[Epoch 38] ogbg-moltoxcast: 0.668451 test loss: 0.311806
[Epoch 39; Iter    28/  229] train: loss: 0.1642009
[Epoch 39; Iter    58/  229] train: loss: 0.1380784
[Epoch 39; Iter    88/  229] train: loss: 0.1523895
[Epoch 39; Iter   118/  229] train: loss: 0.1962695
[Epoch 39; Iter   148/  229] train: loss: 0.1443687
[Epoch 39; Iter   178/  229] train: loss: 0.1571449
[Epoch 39; Iter   208/  229] train: loss: 0.1384405
[Epoch 39] ogbg-moltoxcast: 0.679994 val loss: 0.467663
[Epoch 39] ogbg-moltoxcast: 0.661652 test loss: 0.979170
[Epoch 40; Iter     9/  229] train: loss: 0.1202715
[Epoch 40; Iter    39/  229] train: loss: 0.1816144
[Epoch 40; Iter    69/  229] train: loss: 0.1574209
[Epoch 40; Iter    99/  229] train: loss: 0.0769534
[Epoch 40; Iter   129/  229] train: loss: 0.1584330
[Epoch 40; Iter   159/  229] train: loss: 0.1066016
[Epoch 40; Iter   189/  229] train: loss: 0.1184967
[Epoch 40; Iter   219/  229] train: loss: 0.1623202
[Epoch 40] ogbg-moltoxcast: 0.672192 val loss: 0.406086
[Epoch 40] ogbg-moltoxcast: 0.660267 test loss: 0.734968
[Epoch 41; Iter    20/  229] train: loss: 0.1245684
[Epoch 41; Iter    50/  229] train: loss: 0.1754122
[Epoch 41; Iter    80/  229] train: loss: 0.1483241
[Epoch 41; Iter   110/  229] train: loss: 0.1685651
[Epoch 41; Iter   140/  229] train: loss: 0.1475416
[Epoch 41; Iter   170/  229] train: loss: 0.1177465
[Epoch 41; Iter   200/  229] train: loss: 0.1637791
[Epoch 41] ogbg-moltoxcast: 0.678867 val loss: 0.293286
[Epoch 41] ogbg-moltoxcast: 0.667659 test loss: 0.324938
[Epoch 42; Iter     1/  229] train: loss: 0.1750597
[Epoch 42; Iter    31/  229] train: loss: 0.1011539
[Epoch 42; Iter    61/  229] train: loss: 0.1111492
[Epoch 42; Iter    91/  229] train: loss: 0.1676778
[Epoch 42; Iter   121/  229] train: loss: 0.1041132
[Epoch 42; Iter   151/  229] train: loss: 0.1054289
[Epoch 42; Iter   181/  229] train: loss: 0.2165397
[Epoch 42; Iter   211/  229] train: loss: 0.1109151
[Epoch 42] ogbg-moltoxcast: 0.675458 val loss: 0.284059
[Epoch 42] ogbg-moltoxcast: 0.667250 test loss: 0.321092
[Epoch 43; Iter    12/  229] train: loss: 0.1220699
[Epoch 43; Iter    42/  229] train: loss: 0.1375289
[Epoch 43; Iter    72/  229] train: loss: 0.1830963
[Epoch 43; Iter   102/  229] train: loss: 0.1387026
[Epoch 43; Iter   132/  229] train: loss: 0.1356075
[Epoch 43; Iter   162/  229] train: loss: 0.1413546
[Epoch 43; Iter   192/  229] train: loss: 0.1302242
[Epoch 43; Iter   222/  229] train: loss: 0.1469784
[Epoch 43] ogbg-moltoxcast: 0.666301 val loss: 0.295035
[Epoch 43] ogbg-moltoxcast: 0.654938 test loss: 0.337504
[Epoch 28; Iter    27/  229] train: loss: 0.1898956
[Epoch 28; Iter    57/  229] train: loss: 0.2039544
[Epoch 28; Iter    87/  229] train: loss: 0.1598691
[Epoch 28; Iter   117/  229] train: loss: 0.2459184
[Epoch 28; Iter   147/  229] train: loss: 0.1381770
[Epoch 28; Iter   177/  229] train: loss: 0.1459161
[Epoch 28; Iter   207/  229] train: loss: 0.1936541
[Epoch 28] ogbg-moltoxcast: 0.662982 val loss: 0.287871
[Epoch 28] ogbg-moltoxcast: 0.646059 test loss: 0.339264
[Epoch 29; Iter     8/  229] train: loss: 0.2731168
[Epoch 29; Iter    38/  229] train: loss: 0.1907494
[Epoch 29; Iter    68/  229] train: loss: 0.2663596
[Epoch 29; Iter    98/  229] train: loss: 0.1322330
[Epoch 29; Iter   128/  229] train: loss: 0.1465630
[Epoch 29; Iter   158/  229] train: loss: 0.1940058
[Epoch 29; Iter   188/  229] train: loss: 0.1177519
[Epoch 29; Iter   218/  229] train: loss: 0.1656341
[Epoch 29] ogbg-moltoxcast: 0.675622 val loss: 0.285570
[Epoch 29] ogbg-moltoxcast: 0.649350 test loss: 0.335280
[Epoch 30; Iter    19/  229] train: loss: 0.1316162
[Epoch 30; Iter    49/  229] train: loss: 0.1301441
[Epoch 30; Iter    79/  229] train: loss: 0.2423285
[Epoch 30; Iter   109/  229] train: loss: 0.1350753
[Epoch 30; Iter   139/  229] train: loss: 0.1655401
[Epoch 30; Iter   169/  229] train: loss: 0.1744615
[Epoch 30; Iter   199/  229] train: loss: 0.1631024
[Epoch 30; Iter   229/  229] train: loss: 0.1482904
[Epoch 30] ogbg-moltoxcast: 0.668260 val loss: 0.281391
[Epoch 30] ogbg-moltoxcast: 0.646294 test loss: 0.326866
[Epoch 31; Iter    30/  229] train: loss: 0.0931506
[Epoch 31; Iter    60/  229] train: loss: 0.1381739
[Epoch 31; Iter    90/  229] train: loss: 0.1405740
[Epoch 31; Iter   120/  229] train: loss: 0.0711291
[Epoch 31; Iter   150/  229] train: loss: 0.1797113
[Epoch 31; Iter   180/  229] train: loss: 0.1425088
[Epoch 31; Iter   210/  229] train: loss: 0.1731397
[Epoch 31] ogbg-moltoxcast: 0.676041 val loss: 0.278382
[Epoch 31] ogbg-moltoxcast: 0.650576 test loss: 0.323932
[Epoch 32; Iter    11/  229] train: loss: 0.1929832
[Epoch 32; Iter    41/  229] train: loss: 0.1409101
[Epoch 32; Iter    71/  229] train: loss: 0.1456497
[Epoch 32; Iter   101/  229] train: loss: 0.1494534
[Epoch 32; Iter   131/  229] train: loss: 0.1983781
[Epoch 32; Iter   161/  229] train: loss: 0.1558783
[Epoch 32; Iter   191/  229] train: loss: 0.1205635
[Epoch 32; Iter   221/  229] train: loss: 0.1123060
[Epoch 32] ogbg-moltoxcast: 0.672584 val loss: 0.285401
[Epoch 32] ogbg-moltoxcast: 0.656679 test loss: 0.330197
[Epoch 33; Iter    22/  229] train: loss: 0.1504462
[Epoch 33; Iter    52/  229] train: loss: 0.1517380
[Epoch 33; Iter    82/  229] train: loss: 0.1475926
[Epoch 33; Iter   112/  229] train: loss: 0.1824894
[Epoch 33; Iter   142/  229] train: loss: 0.1627926
[Epoch 33; Iter   172/  229] train: loss: 0.1472959
[Epoch 33; Iter   202/  229] train: loss: 0.1656058
[Epoch 33] ogbg-moltoxcast: 0.685498 val loss: 0.268858
[Epoch 33] ogbg-moltoxcast: 0.647369 test loss: 0.318032
[Epoch 34; Iter     3/  229] train: loss: 0.1998282
[Epoch 34; Iter    33/  229] train: loss: 0.1301891
[Epoch 34; Iter    63/  229] train: loss: 0.1945875
[Epoch 34; Iter    93/  229] train: loss: 0.1697002
[Epoch 34; Iter   123/  229] train: loss: 0.1555901
[Epoch 34; Iter   153/  229] train: loss: 0.1308617
[Epoch 34; Iter   183/  229] train: loss: 0.1412466
[Epoch 34; Iter   213/  229] train: loss: 0.1591711
[Epoch 34] ogbg-moltoxcast: 0.670240 val loss: 0.277613
[Epoch 34] ogbg-moltoxcast: 0.642607 test loss: 0.350083
[Epoch 35; Iter    14/  229] train: loss: 0.1499464
[Epoch 35; Iter    44/  229] train: loss: 0.1202019
[Epoch 35; Iter    74/  229] train: loss: 0.1001251
[Epoch 35; Iter   104/  229] train: loss: 0.1478934
[Epoch 35; Iter   134/  229] train: loss: 0.1460758
[Epoch 35; Iter   164/  229] train: loss: 0.1301810
[Epoch 35; Iter   194/  229] train: loss: 0.1718047
[Epoch 35; Iter   224/  229] train: loss: 0.1486431
[Epoch 35] ogbg-moltoxcast: 0.678014 val loss: 0.279618
[Epoch 35] ogbg-moltoxcast: 0.649903 test loss: 0.333844
[Epoch 36; Iter    25/  229] train: loss: 0.1211667
[Epoch 36; Iter    55/  229] train: loss: 0.1539976
[Epoch 36; Iter    85/  229] train: loss: 0.1557364
[Epoch 36; Iter   115/  229] train: loss: 0.1096878
[Epoch 36; Iter   145/  229] train: loss: 0.1714900
[Epoch 36; Iter   175/  229] train: loss: 0.1194406
[Epoch 36; Iter   205/  229] train: loss: 0.1514625
[Epoch 36] ogbg-moltoxcast: 0.678626 val loss: 0.277459
[Epoch 36] ogbg-moltoxcast: 0.657673 test loss: 0.322476
[Epoch 37; Iter     6/  229] train: loss: 0.1382014
[Epoch 37; Iter    36/  229] train: loss: 0.1285530
[Epoch 37; Iter    66/  229] train: loss: 0.2118878
[Epoch 37; Iter    96/  229] train: loss: 0.1043162
[Epoch 37; Iter   126/  229] train: loss: 0.1395486
[Epoch 37; Iter   156/  229] train: loss: 0.1683359
[Epoch 37; Iter   186/  229] train: loss: 0.1476407
[Epoch 37; Iter   216/  229] train: loss: 0.1623881
[Epoch 37] ogbg-moltoxcast: 0.683911 val loss: 0.269775
[Epoch 37] ogbg-moltoxcast: 0.653467 test loss: 0.317224
[Epoch 38; Iter    17/  229] train: loss: 0.1237065
[Epoch 38; Iter    47/  229] train: loss: 0.1643940
[Epoch 38; Iter    77/  229] train: loss: 0.1210161
[Epoch 38; Iter   107/  229] train: loss: 0.1156541
[Epoch 38; Iter   137/  229] train: loss: 0.1498332
[Epoch 38; Iter   167/  229] train: loss: 0.1105464
[Epoch 38; Iter   197/  229] train: loss: 0.1462527
[Epoch 38; Iter   227/  229] train: loss: 0.1342697
[Epoch 38] ogbg-moltoxcast: 0.688516 val loss: 0.271612
[Epoch 38] ogbg-moltoxcast: 0.651114 test loss: 0.321133
[Epoch 39; Iter    28/  229] train: loss: 0.1631142
[Epoch 39; Iter    58/  229] train: loss: 0.1262790
[Epoch 39; Iter    88/  229] train: loss: 0.1410337
[Epoch 39; Iter   118/  229] train: loss: 0.1681133
[Epoch 39; Iter   148/  229] train: loss: 0.1516138
[Epoch 39; Iter   178/  229] train: loss: 0.1211402
[Epoch 39; Iter   208/  229] train: loss: 0.1195142
[Epoch 39] ogbg-moltoxcast: 0.678037 val loss: 0.285654
[Epoch 39] ogbg-moltoxcast: 0.652206 test loss: 0.368296
[Epoch 40; Iter     9/  229] train: loss: 0.1597875
[Epoch 40; Iter    39/  229] train: loss: 0.1198513
[Epoch 40; Iter    69/  229] train: loss: 0.1631046
[Epoch 40; Iter    99/  229] train: loss: 0.1137014
[Epoch 40; Iter   129/  229] train: loss: 0.1340104
[Epoch 40; Iter   159/  229] train: loss: 0.1336814
[Epoch 40; Iter   189/  229] train: loss: 0.1458513
[Epoch 40; Iter   219/  229] train: loss: 0.1354408
[Epoch 40] ogbg-moltoxcast: 0.679121 val loss: 0.283533
[Epoch 40] ogbg-moltoxcast: 0.654420 test loss: 0.328458
[Epoch 41; Iter    20/  229] train: loss: 0.1753567
[Epoch 41; Iter    50/  229] train: loss: 0.1161126
[Epoch 41; Iter    80/  229] train: loss: 0.2043200
[Epoch 41; Iter   110/  229] train: loss: 0.0653404
[Epoch 41; Iter   140/  229] train: loss: 0.1775761
[Epoch 41; Iter   170/  229] train: loss: 0.1719073
[Epoch 41; Iter   200/  229] train: loss: 0.1483461
[Epoch 41] ogbg-moltoxcast: 0.679778 val loss: 0.291206
[Epoch 41] ogbg-moltoxcast: 0.657767 test loss: 0.334673
[Epoch 42; Iter     1/  229] train: loss: 0.1450989
[Epoch 42; Iter    31/  229] train: loss: 0.1057773
[Epoch 42; Iter    61/  229] train: loss: 0.1206471
[Epoch 42; Iter    91/  229] train: loss: 0.1657570
[Epoch 42; Iter   121/  229] train: loss: 0.1624149
[Epoch 42; Iter   151/  229] train: loss: 0.1168959
[Epoch 42; Iter   181/  229] train: loss: 0.1342583
[Epoch 42; Iter   211/  229] train: loss: 0.1276132
[Epoch 42] ogbg-moltoxcast: 0.678438 val loss: 0.286348
[Epoch 42] ogbg-moltoxcast: 0.642409 test loss: 0.340953
[Epoch 43; Iter    12/  229] train: loss: 0.0892713
[Epoch 43; Iter    42/  229] train: loss: 0.1702616
[Epoch 43; Iter    72/  229] train: loss: 0.1360396
[Epoch 43; Iter   102/  229] train: loss: 0.1754005
[Epoch 43; Iter   132/  229] train: loss: 0.1201432
[Epoch 43; Iter   162/  229] train: loss: 0.1009390
[Epoch 43; Iter   192/  229] train: loss: 0.1634519
[Epoch 43; Iter   222/  229] train: loss: 0.1312810
[Epoch 43] ogbg-moltoxcast: 0.681637 val loss: 0.279012
[Epoch 43] ogbg-moltoxcast: 0.652127 test loss: 0.325638
[Epoch 28; Iter    27/  229] train: loss: 0.1765640
[Epoch 28; Iter    57/  229] train: loss: 0.1558576
[Epoch 28; Iter    87/  229] train: loss: 0.1557807
[Epoch 28; Iter   117/  229] train: loss: 0.1767153
[Epoch 28; Iter   147/  229] train: loss: 0.1782849
[Epoch 28; Iter   177/  229] train: loss: 0.1484945
[Epoch 28; Iter   207/  229] train: loss: 0.1684542
[Epoch 28] ogbg-moltoxcast: 0.667359 val loss: 0.284662
[Epoch 28] ogbg-moltoxcast: 0.637820 test loss: 0.336886
[Epoch 29; Iter     8/  229] train: loss: 0.1045493
[Epoch 29; Iter    38/  229] train: loss: 0.1166236
[Epoch 29; Iter    68/  229] train: loss: 0.1319461
[Epoch 29; Iter    98/  229] train: loss: 0.2006994
[Epoch 29; Iter   128/  229] train: loss: 0.1437141
[Epoch 29; Iter   158/  229] train: loss: 0.0985758
[Epoch 29; Iter   188/  229] train: loss: 0.1495163
[Epoch 29; Iter   218/  229] train: loss: 0.1350137
[Epoch 29] ogbg-moltoxcast: 0.657951 val loss: 0.322617
[Epoch 29] ogbg-moltoxcast: 0.652743 test loss: 0.316314
[Epoch 30; Iter    19/  229] train: loss: 0.1438856
[Epoch 30; Iter    49/  229] train: loss: 0.1879991
[Epoch 30; Iter    79/  229] train: loss: 0.1126333
[Epoch 30; Iter   109/  229] train: loss: 0.1828264
[Epoch 30; Iter   139/  229] train: loss: 0.1615216
[Epoch 30; Iter   169/  229] train: loss: 0.1766713
[Epoch 30; Iter   199/  229] train: loss: 0.1518553
[Epoch 30; Iter   229/  229] train: loss: 0.1806738
[Epoch 30] ogbg-moltoxcast: 0.672025 val loss: 0.287085
[Epoch 30] ogbg-moltoxcast: 0.657909 test loss: 0.341453
[Epoch 31; Iter    30/  229] train: loss: 0.1949029
[Epoch 31; Iter    60/  229] train: loss: 0.1859909
[Epoch 31; Iter    90/  229] train: loss: 0.1626363
[Epoch 31; Iter   120/  229] train: loss: 0.1493300
[Epoch 31; Iter   150/  229] train: loss: 0.1658506
[Epoch 31; Iter   180/  229] train: loss: 0.2348211
[Epoch 31; Iter   210/  229] train: loss: 0.1320780
[Epoch 31] ogbg-moltoxcast: 0.675372 val loss: 0.313198
[Epoch 31] ogbg-moltoxcast: 0.659710 test loss: 0.645651
[Epoch 32; Iter    11/  229] train: loss: 0.1369209
[Epoch 32; Iter    41/  229] train: loss: 0.1266145
[Epoch 32; Iter    71/  229] train: loss: 0.1689525
[Epoch 32; Iter   101/  229] train: loss: 0.2013225
[Epoch 32; Iter   131/  229] train: loss: 0.1189419
[Epoch 32; Iter   161/  229] train: loss: 0.1410859
[Epoch 32; Iter   191/  229] train: loss: 0.1032712
[Epoch 32; Iter   221/  229] train: loss: 0.1188523
[Epoch 32] ogbg-moltoxcast: 0.665043 val loss: 0.280146
[Epoch 32] ogbg-moltoxcast: 0.662646 test loss: 0.320033
[Epoch 33; Iter    22/  229] train: loss: 0.1097778
[Epoch 33; Iter    52/  229] train: loss: 0.1140382
[Epoch 33; Iter    82/  229] train: loss: 0.1392505
[Epoch 33; Iter   112/  229] train: loss: 0.1999839
[Epoch 33; Iter   142/  229] train: loss: 0.1330566
[Epoch 33; Iter   172/  229] train: loss: 0.1548868
[Epoch 33; Iter   202/  229] train: loss: 0.1025471
[Epoch 33] ogbg-moltoxcast: 0.660603 val loss: 0.340886
[Epoch 33] ogbg-moltoxcast: 0.661761 test loss: 0.327996
[Epoch 34; Iter     3/  229] train: loss: 0.1861860
[Epoch 34; Iter    33/  229] train: loss: 0.1534293
[Epoch 34; Iter    63/  229] train: loss: 0.1634853
[Epoch 34; Iter    93/  229] train: loss: 0.1668371
[Epoch 34; Iter   123/  229] train: loss: 0.1449642
[Epoch 34; Iter   153/  229] train: loss: 0.1355593
[Epoch 34; Iter   183/  229] train: loss: 0.1149810
[Epoch 34; Iter   213/  229] train: loss: 0.2224559
[Epoch 34] ogbg-moltoxcast: 0.663472 val loss: 0.303198
[Epoch 34] ogbg-moltoxcast: 0.665046 test loss: 0.321887
[Epoch 35; Iter    14/  229] train: loss: 0.0828601
[Epoch 35; Iter    44/  229] train: loss: 0.1418328
[Epoch 35; Iter    74/  229] train: loss: 0.1419268
[Epoch 35; Iter   104/  229] train: loss: 0.1828499
[Epoch 35; Iter   134/  229] train: loss: 0.1767267
[Epoch 35; Iter   164/  229] train: loss: 0.1622397
[Epoch 35; Iter   194/  229] train: loss: 0.1187735
[Epoch 35; Iter   224/  229] train: loss: 0.1245673
[Epoch 35] ogbg-moltoxcast: 0.670833 val loss: 0.314289
[Epoch 35] ogbg-moltoxcast: 0.662006 test loss: 0.319955
[Epoch 36; Iter    25/  229] train: loss: 0.1599915
[Epoch 36; Iter    55/  229] train: loss: 0.1639806
[Epoch 36; Iter    85/  229] train: loss: 0.1430807
[Epoch 36; Iter   115/  229] train: loss: 0.1088051
[Epoch 36; Iter   145/  229] train: loss: 0.1602236
[Epoch 36; Iter   175/  229] train: loss: 0.1745435
[Epoch 36; Iter   205/  229] train: loss: 0.1757901
[Epoch 36] ogbg-moltoxcast: 0.672556 val loss: 0.287784
[Epoch 36] ogbg-moltoxcast: 0.663771 test loss: 0.321001
[Epoch 37; Iter     6/  229] train: loss: 0.1156313
[Epoch 37; Iter    36/  229] train: loss: 0.0924421
[Epoch 37; Iter    66/  229] train: loss: 0.1432234
[Epoch 37; Iter    96/  229] train: loss: 0.1338626
[Epoch 37; Iter   126/  229] train: loss: 0.1228546
[Epoch 37; Iter   156/  229] train: loss: 0.1302247
[Epoch 37; Iter   186/  229] train: loss: 0.1424260
[Epoch 37; Iter   216/  229] train: loss: 0.1646890
[Epoch 37] ogbg-moltoxcast: 0.673001 val loss: 0.281606
[Epoch 37] ogbg-moltoxcast: 0.665247 test loss: 0.321835
[Epoch 38; Iter    17/  229] train: loss: 0.1866304
[Epoch 38; Iter    47/  229] train: loss: 0.1414495
[Epoch 38; Iter    77/  229] train: loss: 0.1232804
[Epoch 38; Iter   107/  229] train: loss: 0.1338039
[Epoch 38; Iter   137/  229] train: loss: 0.1635152
[Epoch 38; Iter   167/  229] train: loss: 0.1490007
[Epoch 38; Iter   197/  229] train: loss: 0.1496465
[Epoch 38; Iter   227/  229] train: loss: 0.1584256
[Epoch 38] ogbg-moltoxcast: 0.672510 val loss: 0.288376
[Epoch 38] ogbg-moltoxcast: 0.663348 test loss: 0.328741
[Epoch 39; Iter    28/  229] train: loss: 0.1772512
[Epoch 39; Iter    58/  229] train: loss: 0.1163213
[Epoch 39; Iter    88/  229] train: loss: 0.1163874
[Epoch 39; Iter   118/  229] train: loss: 0.2296619
[Epoch 39; Iter   148/  229] train: loss: 0.1451156
[Epoch 39; Iter   178/  229] train: loss: 0.1432251
[Epoch 39; Iter   208/  229] train: loss: 0.1786728
[Epoch 39] ogbg-moltoxcast: 0.660370 val loss: 0.281642
[Epoch 39] ogbg-moltoxcast: 0.658900 test loss: 0.324718
[Epoch 40; Iter     9/  229] train: loss: 0.1415655
[Epoch 40; Iter    39/  229] train: loss: 0.1178272
[Epoch 40; Iter    69/  229] train: loss: 0.1057728
[Epoch 40; Iter    99/  229] train: loss: 0.1741271
[Epoch 40; Iter   129/  229] train: loss: 0.1359008
[Epoch 40; Iter   159/  229] train: loss: 0.1251947
[Epoch 40; Iter   189/  229] train: loss: 0.1435592
[Epoch 40; Iter   219/  229] train: loss: 0.2018417
[Epoch 40] ogbg-moltoxcast: 0.677341 val loss: 0.285047
[Epoch 40] ogbg-moltoxcast: 0.665009 test loss: 0.326613
[Epoch 41; Iter    20/  229] train: loss: 0.1652659
[Epoch 41; Iter    50/  229] train: loss: 0.1163563
[Epoch 41; Iter    80/  229] train: loss: 0.0982607
[Epoch 41; Iter   110/  229] train: loss: 0.1011632
[Epoch 41; Iter   140/  229] train: loss: 0.1097546
[Epoch 41; Iter   170/  229] train: loss: 0.1075217
[Epoch 41; Iter   200/  229] train: loss: 0.1566451
[Epoch 41] ogbg-moltoxcast: 0.672921 val loss: 0.280929
[Epoch 41] ogbg-moltoxcast: 0.666581 test loss: 0.319771
[Epoch 42; Iter     1/  229] train: loss: 0.1635043
[Epoch 42; Iter    31/  229] train: loss: 0.1457774
[Epoch 42; Iter    61/  229] train: loss: 0.1710793
[Epoch 42; Iter    91/  229] train: loss: 0.1139178
[Epoch 42; Iter   121/  229] train: loss: 0.1663162
[Epoch 42; Iter   151/  229] train: loss: 0.1178503
[Epoch 42; Iter   181/  229] train: loss: 0.1403396
[Epoch 42; Iter   211/  229] train: loss: 0.1414844
[Epoch 42] ogbg-moltoxcast: 0.657074 val loss: 0.277198
[Epoch 42] ogbg-moltoxcast: 0.659959 test loss: 0.313927
[Epoch 43; Iter    12/  229] train: loss: 0.1750719
[Epoch 43; Iter    42/  229] train: loss: 0.1582702
[Epoch 43; Iter    72/  229] train: loss: 0.1549613
[Epoch 43; Iter   102/  229] train: loss: 0.1555004
[Epoch 43; Iter   132/  229] train: loss: 0.1144321
[Epoch 43; Iter   162/  229] train: loss: 0.1706849
[Epoch 43; Iter   192/  229] train: loss: 0.1085667
[Epoch 43; Iter   222/  229] train: loss: 0.1434012
[Epoch 43] ogbg-moltoxcast: 0.666975 val loss: 0.285952
[Epoch 43] ogbg-moltoxcast: 0.663653 test loss: 0.325489
[Epoch 28; Iter    27/  229] train: loss: 0.2098932
[Epoch 28; Iter    57/  229] train: loss: 0.1581919
[Epoch 28; Iter    87/  229] train: loss: 0.1667811
[Epoch 28; Iter   117/  229] train: loss: 0.1762628
[Epoch 28; Iter   147/  229] train: loss: 0.1836901
[Epoch 28; Iter   177/  229] train: loss: 0.1451720
[Epoch 28; Iter   207/  229] train: loss: 0.1985691
[Epoch 28] ogbg-moltoxcast: 0.644550 val loss: 0.766939
[Epoch 28] ogbg-moltoxcast: 0.619600 test loss: 0.379434
[Epoch 29; Iter     8/  229] train: loss: 0.1156434
[Epoch 29; Iter    38/  229] train: loss: 0.1295567
[Epoch 29; Iter    68/  229] train: loss: 0.1303169
[Epoch 29; Iter    98/  229] train: loss: 0.1996360
[Epoch 29; Iter   128/  229] train: loss: 0.1476859
[Epoch 29; Iter   158/  229] train: loss: 0.0943423
[Epoch 29; Iter   188/  229] train: loss: 0.1441446
[Epoch 29; Iter   218/  229] train: loss: 0.1340695
[Epoch 29] ogbg-moltoxcast: 0.643261 val loss: 0.729724
[Epoch 29] ogbg-moltoxcast: 0.632178 test loss: 0.329960
[Epoch 30; Iter    19/  229] train: loss: 0.1451873
[Epoch 30; Iter    49/  229] train: loss: 0.1956203
[Epoch 30; Iter    79/  229] train: loss: 0.1148527
[Epoch 30; Iter   109/  229] train: loss: 0.1942336
[Epoch 30; Iter   139/  229] train: loss: 0.1594809
[Epoch 30; Iter   169/  229] train: loss: 0.1750341
[Epoch 30; Iter   199/  229] train: loss: 0.1553939
[Epoch 30; Iter   229/  229] train: loss: 0.1854687
[Epoch 30] ogbg-moltoxcast: 0.650800 val loss: 0.349409
[Epoch 30] ogbg-moltoxcast: 0.630985 test loss: 0.938698
[Epoch 31; Iter    30/  229] train: loss: 0.2008799
[Epoch 31; Iter    60/  229] train: loss: 0.1918393
[Epoch 31; Iter    90/  229] train: loss: 0.1593877
[Epoch 31; Iter   120/  229] train: loss: 0.1599642
[Epoch 31; Iter   150/  229] train: loss: 0.1667413
[Epoch 31; Iter   180/  229] train: loss: 0.2641123
[Epoch 31; Iter   210/  229] train: loss: 0.1336077
[Epoch 31] ogbg-moltoxcast: 0.645458 val loss: 0.299384
[Epoch 31] ogbg-moltoxcast: 0.632612 test loss: 2.331406
[Epoch 32; Iter    11/  229] train: loss: 0.1391260
[Epoch 32; Iter    41/  229] train: loss: 0.1365072
[Epoch 32; Iter    71/  229] train: loss: 0.1930559
[Epoch 32; Iter   101/  229] train: loss: 0.2081136
[Epoch 32; Iter   131/  229] train: loss: 0.1099412
[Epoch 32; Iter   161/  229] train: loss: 0.1774984
[Epoch 32; Iter   191/  229] train: loss: 0.1205745
[Epoch 32; Iter   221/  229] train: loss: 0.1328752
[Epoch 32] ogbg-moltoxcast: 0.662734 val loss: 0.378234
[Epoch 32] ogbg-moltoxcast: 0.638030 test loss: 0.413517
[Epoch 33; Iter    22/  229] train: loss: 0.1131138
[Epoch 33; Iter    52/  229] train: loss: 0.1181641
[Epoch 33; Iter    82/  229] train: loss: 0.1581208
[Epoch 33; Iter   112/  229] train: loss: 0.1950244
[Epoch 33; Iter   142/  229] train: loss: 0.1256987
[Epoch 33; Iter   172/  229] train: loss: 0.1554718
[Epoch 33; Iter   202/  229] train: loss: 0.1047739
[Epoch 33] ogbg-moltoxcast: 0.653303 val loss: 0.363622
[Epoch 33] ogbg-moltoxcast: 0.639869 test loss: 2.414480
[Epoch 34; Iter     3/  229] train: loss: 0.1934843
[Epoch 34; Iter    33/  229] train: loss: 0.1628297
[Epoch 34; Iter    63/  229] train: loss: 0.1512750
[Epoch 34; Iter    93/  229] train: loss: 0.1635690
[Epoch 34; Iter   123/  229] train: loss: 0.1427811
[Epoch 34; Iter   153/  229] train: loss: 0.1324002
[Epoch 34; Iter   183/  229] train: loss: 0.1242979
[Epoch 34; Iter   213/  229] train: loss: 0.2103271
[Epoch 34] ogbg-moltoxcast: 0.646561 val loss: 0.421791
[Epoch 34] ogbg-moltoxcast: 0.640545 test loss: 1.226632
[Epoch 35; Iter    14/  229] train: loss: 0.0787908
[Epoch 35; Iter    44/  229] train: loss: 0.1718321
[Epoch 35; Iter    74/  229] train: loss: 0.1469448
[Epoch 35; Iter   104/  229] train: loss: 0.1846475
[Epoch 35; Iter   134/  229] train: loss: 0.1780062
[Epoch 35; Iter   164/  229] train: loss: 0.1633930
[Epoch 35; Iter   194/  229] train: loss: 0.1233947
[Epoch 35; Iter   224/  229] train: loss: 0.1450949
[Epoch 35] ogbg-moltoxcast: 0.641135 val loss: 0.860766
[Epoch 35] ogbg-moltoxcast: 0.642106 test loss: 0.622781
[Epoch 36; Iter    25/  229] train: loss: 0.1608938
[Epoch 36; Iter    55/  229] train: loss: 0.1643361
[Epoch 36; Iter    85/  229] train: loss: 0.1314891
[Epoch 36; Iter   115/  229] train: loss: 0.1182747
[Epoch 36; Iter   145/  229] train: loss: 0.1634041
[Epoch 36; Iter   175/  229] train: loss: 0.1749274
[Epoch 36; Iter   205/  229] train: loss: 0.1758819
[Epoch 36] ogbg-moltoxcast: 0.634133 val loss: 0.375738
[Epoch 36] ogbg-moltoxcast: 0.635580 test loss: 0.631998
[Epoch 37; Iter     6/  229] train: loss: 0.1199370
[Epoch 37; Iter    36/  229] train: loss: 0.0934655
[Epoch 37; Iter    66/  229] train: loss: 0.1450487
[Epoch 37; Iter    96/  229] train: loss: 0.1419659
[Epoch 37; Iter   126/  229] train: loss: 0.1276652
[Epoch 37; Iter   156/  229] train: loss: 0.1320526
[Epoch 37; Iter   186/  229] train: loss: 0.1450956
[Epoch 37; Iter   216/  229] train: loss: 0.1565866
[Epoch 37] ogbg-moltoxcast: 0.652826 val loss: 0.354805
[Epoch 37] ogbg-moltoxcast: 0.643045 test loss: 1.054833
[Epoch 38; Iter    17/  229] train: loss: 0.1929546
[Epoch 38; Iter    47/  229] train: loss: 0.1449999
[Epoch 38; Iter    77/  229] train: loss: 0.1253255
[Epoch 38; Iter   107/  229] train: loss: 0.1410518
[Epoch 38; Iter   137/  229] train: loss: 0.1661330
[Epoch 38; Iter   167/  229] train: loss: 0.1465609
[Epoch 38; Iter   197/  229] train: loss: 0.1524374
[Epoch 38; Iter   227/  229] train: loss: 0.1690477
[Epoch 38] ogbg-moltoxcast: 0.648740 val loss: 0.321328
[Epoch 38] ogbg-moltoxcast: 0.642109 test loss: 0.694938
[Epoch 39; Iter    28/  229] train: loss: 0.1768545
[Epoch 39; Iter    58/  229] train: loss: 0.1044146
[Epoch 39; Iter    88/  229] train: loss: 0.1185714
[Epoch 39; Iter   118/  229] train: loss: 0.2264418
[Epoch 39; Iter   148/  229] train: loss: 0.1452029
[Epoch 39; Iter   178/  229] train: loss: 0.1556552
[Epoch 39; Iter   208/  229] train: loss: 0.1883850
[Epoch 39] ogbg-moltoxcast: 0.656643 val loss: 0.352383
[Epoch 39] ogbg-moltoxcast: 0.643618 test loss: 1.292452
[Epoch 40; Iter     9/  229] train: loss: 0.1479628
[Epoch 40; Iter    39/  229] train: loss: 0.1146254
[Epoch 40; Iter    69/  229] train: loss: 0.1181171
[Epoch 40; Iter    99/  229] train: loss: 0.1746117
[Epoch 40; Iter   129/  229] train: loss: 0.1325939
[Epoch 40; Iter   159/  229] train: loss: 0.1265112
[Epoch 40; Iter   189/  229] train: loss: 0.1493525
[Epoch 40; Iter   219/  229] train: loss: 0.2041668
[Epoch 40] ogbg-moltoxcast: 0.642238 val loss: 0.316186
[Epoch 40] ogbg-moltoxcast: 0.647469 test loss: 1.848031
[Epoch 41; Iter    20/  229] train: loss: 0.1529897
[Epoch 41; Iter    50/  229] train: loss: 0.1252609
[Epoch 41; Iter    80/  229] train: loss: 0.0965417
[Epoch 41; Iter   110/  229] train: loss: 0.1036654
[Epoch 41; Iter   140/  229] train: loss: 0.1157627
[Epoch 41; Iter   170/  229] train: loss: 0.1088912
[Epoch 41; Iter   200/  229] train: loss: 0.1505951
[Epoch 41] ogbg-moltoxcast: 0.643165 val loss: 0.319545
[Epoch 41] ogbg-moltoxcast: 0.644830 test loss: 1.827368
[Epoch 42; Iter     1/  229] train: loss: 0.1648442
[Epoch 42; Iter    31/  229] train: loss: 0.1338724
[Epoch 42; Iter    61/  229] train: loss: 0.1777690
[Epoch 42; Iter    91/  229] train: loss: 0.1260689
[Epoch 42; Iter   121/  229] train: loss: 0.1763542
[Epoch 42; Iter   151/  229] train: loss: 0.1214937
[Epoch 42; Iter   181/  229] train: loss: 0.1440649
[Epoch 42; Iter   211/  229] train: loss: 0.1429433
[Epoch 42] ogbg-moltoxcast: 0.635849 val loss: 0.355474
[Epoch 42] ogbg-moltoxcast: 0.642552 test loss: 0.606291
[Epoch 43; Iter    12/  229] train: loss: 0.1735634
[Epoch 43; Iter    42/  229] train: loss: 0.1622268
[Epoch 43; Iter    72/  229] train: loss: 0.1594929
[Epoch 43; Iter   102/  229] train: loss: 0.1622040
[Epoch 43; Iter   132/  229] train: loss: 0.1221398
[Epoch 43; Iter   162/  229] train: loss: 0.1699308
[Epoch 43; Iter   192/  229] train: loss: 0.1097009
[Epoch 43; Iter   222/  229] train: loss: 0.1562020
[Epoch 43] ogbg-moltoxcast: 0.646156 val loss: 0.322252
[Epoch 43] ogbg-moltoxcast: 0.644479 test loss: 0.712378
[Epoch 28; Iter    27/  229] train: loss: 0.1937864
[Epoch 28; Iter    57/  229] train: loss: 0.1934125
[Epoch 28; Iter    87/  229] train: loss: 0.1563893
[Epoch 28; Iter   117/  229] train: loss: 0.2464441
[Epoch 28; Iter   147/  229] train: loss: 0.1367325
[Epoch 28; Iter   177/  229] train: loss: 0.1586965
[Epoch 28; Iter   207/  229] train: loss: 0.1905599
[Epoch 28] ogbg-moltoxcast: 0.641807 val loss: 3.328986
[Epoch 28] ogbg-moltoxcast: 0.626758 test loss: 3.446497
[Epoch 29; Iter     8/  229] train: loss: 0.2850310
[Epoch 29; Iter    38/  229] train: loss: 0.2035383
[Epoch 29; Iter    68/  229] train: loss: 0.2751143
[Epoch 29; Iter    98/  229] train: loss: 0.1291734
[Epoch 29; Iter   128/  229] train: loss: 0.1468963
[Epoch 29; Iter   158/  229] train: loss: 0.2041960
[Epoch 29; Iter   188/  229] train: loss: 0.1100684
[Epoch 29; Iter   218/  229] train: loss: 0.1666711
[Epoch 29] ogbg-moltoxcast: 0.641086 val loss: 0.593098
[Epoch 29] ogbg-moltoxcast: 0.634301 test loss: 0.491639
[Epoch 30; Iter    19/  229] train: loss: 0.1318502
[Epoch 30; Iter    49/  229] train: loss: 0.1267135
[Epoch 30; Iter    79/  229] train: loss: 0.2444350
[Epoch 30; Iter   109/  229] train: loss: 0.1488459
[Epoch 30; Iter   139/  229] train: loss: 0.1563180
[Epoch 30; Iter   169/  229] train: loss: 0.1838259
[Epoch 30; Iter   199/  229] train: loss: 0.1626488
[Epoch 30; Iter   229/  229] train: loss: 0.1571718
[Epoch 30] ogbg-moltoxcast: 0.621230 val loss: 0.363005
[Epoch 30] ogbg-moltoxcast: 0.628624 test loss: 0.396964
[Epoch 31; Iter    30/  229] train: loss: 0.1043752
[Epoch 31; Iter    60/  229] train: loss: 0.1428431
[Epoch 31; Iter    90/  229] train: loss: 0.1426336
[Epoch 31; Iter   120/  229] train: loss: 0.0688905
[Epoch 31; Iter   150/  229] train: loss: 0.1752685
[Epoch 31; Iter   180/  229] train: loss: 0.1367150
[Epoch 31; Iter   210/  229] train: loss: 0.1821903
[Epoch 31] ogbg-moltoxcast: 0.631853 val loss: 5.141248
[Epoch 31] ogbg-moltoxcast: 0.626466 test loss: 3.913894
[Epoch 32; Iter    11/  229] train: loss: 0.1682084
[Epoch 32; Iter    41/  229] train: loss: 0.1413141
[Epoch 32; Iter    71/  229] train: loss: 0.1463973
[Epoch 32; Iter   101/  229] train: loss: 0.1479505
[Epoch 32; Iter   131/  229] train: loss: 0.2010352
[Epoch 32; Iter   161/  229] train: loss: 0.1468746
[Epoch 32; Iter   191/  229] train: loss: 0.1226977
[Epoch 32; Iter   221/  229] train: loss: 0.1062298
[Epoch 32] ogbg-moltoxcast: 0.638086 val loss: 1.103427
[Epoch 32] ogbg-moltoxcast: 0.626074 test loss: 0.731903
[Epoch 33; Iter    22/  229] train: loss: 0.1559322
[Epoch 33; Iter    52/  229] train: loss: 0.1588570
[Epoch 33; Iter    82/  229] train: loss: 0.1524641
[Epoch 33; Iter   112/  229] train: loss: 0.1873363
[Epoch 33; Iter   142/  229] train: loss: 0.1766124
[Epoch 33; Iter   172/  229] train: loss: 0.1457337
[Epoch 33; Iter   202/  229] train: loss: 0.1524487
[Epoch 33] ogbg-moltoxcast: 0.633221 val loss: 1.275248
[Epoch 33] ogbg-moltoxcast: 0.630236 test loss: 0.612933
[Epoch 34; Iter     3/  229] train: loss: 0.1949668
[Epoch 34; Iter    33/  229] train: loss: 0.1444041
[Epoch 34; Iter    63/  229] train: loss: 0.1995140
[Epoch 34; Iter    93/  229] train: loss: 0.1595159
[Epoch 34; Iter   123/  229] train: loss: 0.1858273
[Epoch 34; Iter   153/  229] train: loss: 0.1392137
[Epoch 34; Iter   183/  229] train: loss: 0.1541479
[Epoch 34; Iter   213/  229] train: loss: 0.1616071
[Epoch 34] ogbg-moltoxcast: 0.625921 val loss: 4.188097
[Epoch 34] ogbg-moltoxcast: 0.635108 test loss: 2.553205
[Epoch 35; Iter    14/  229] train: loss: 0.1532334
[Epoch 35; Iter    44/  229] train: loss: 0.1324543
[Epoch 35; Iter    74/  229] train: loss: 0.1033924
[Epoch 35; Iter   104/  229] train: loss: 0.1780623
[Epoch 35; Iter   134/  229] train: loss: 0.1446396
[Epoch 35; Iter   164/  229] train: loss: 0.1455822
[Epoch 35; Iter   194/  229] train: loss: 0.1762858
[Epoch 35; Iter   224/  229] train: loss: 0.1606142
[Epoch 35] ogbg-moltoxcast: 0.635827 val loss: 1.204571
[Epoch 35] ogbg-moltoxcast: 0.628087 test loss: 0.844647
[Epoch 36; Iter    25/  229] train: loss: 0.1353344
[Epoch 36; Iter    55/  229] train: loss: 0.1711152
[Epoch 36; Iter    85/  229] train: loss: 0.1573952
[Epoch 36; Iter   115/  229] train: loss: 0.1116984
[Epoch 36; Iter   145/  229] train: loss: 0.1755192
[Epoch 36; Iter   175/  229] train: loss: 0.1305091
[Epoch 36; Iter   205/  229] train: loss: 0.1583647
[Epoch 36] ogbg-moltoxcast: 0.642546 val loss: 1.011236
[Epoch 36] ogbg-moltoxcast: 0.642068 test loss: 0.749185
[Epoch 37; Iter     6/  229] train: loss: 0.1454767
[Epoch 37; Iter    36/  229] train: loss: 0.1300604
[Epoch 37; Iter    66/  229] train: loss: 0.2274719
[Epoch 37; Iter    96/  229] train: loss: 0.1065843
[Epoch 37; Iter   126/  229] train: loss: 0.1447965
[Epoch 37; Iter   156/  229] train: loss: 0.1643164
[Epoch 37; Iter   186/  229] train: loss: 0.1664083
[Epoch 37; Iter   216/  229] train: loss: 0.1597158
[Epoch 37] ogbg-moltoxcast: 0.635387 val loss: 0.415787
[Epoch 37] ogbg-moltoxcast: 0.627852 test loss: 0.430004
[Epoch 38; Iter    17/  229] train: loss: 0.1287304
[Epoch 38; Iter    47/  229] train: loss: 0.1637654
[Epoch 38; Iter    77/  229] train: loss: 0.1240929
[Epoch 38; Iter   107/  229] train: loss: 0.1281314
[Epoch 38; Iter   137/  229] train: loss: 0.1495599
[Epoch 38; Iter   167/  229] train: loss: 0.1140575
[Epoch 38; Iter   197/  229] train: loss: 0.1532225
[Epoch 38; Iter   227/  229] train: loss: 0.1318358
[Epoch 38] ogbg-moltoxcast: 0.651778 val loss: 2.202498
[Epoch 38] ogbg-moltoxcast: 0.638807 test loss: 1.522639
[Epoch 39; Iter    28/  229] train: loss: 0.1754925
[Epoch 39; Iter    58/  229] train: loss: 0.1357669
[Epoch 39; Iter    88/  229] train: loss: 0.1470309
[Epoch 39; Iter   118/  229] train: loss: 0.1801387
[Epoch 39; Iter   148/  229] train: loss: 0.1522611
[Epoch 39; Iter   178/  229] train: loss: 0.1228353
[Epoch 39; Iter   208/  229] train: loss: 0.1219838
[Epoch 39] ogbg-moltoxcast: 0.643953 val loss: 0.385530
[Epoch 39] ogbg-moltoxcast: 0.627944 test loss: 0.390487
[Epoch 40; Iter     9/  229] train: loss: 0.1813723
[Epoch 40; Iter    39/  229] train: loss: 0.1359798
[Epoch 40; Iter    69/  229] train: loss: 0.1697150
[Epoch 40; Iter    99/  229] train: loss: 0.1355232
[Epoch 40; Iter   129/  229] train: loss: 0.1392566
[Epoch 40; Iter   159/  229] train: loss: 0.1414263
[Epoch 40; Iter   189/  229] train: loss: 0.1504765
[Epoch 40; Iter   219/  229] train: loss: 0.1417243
[Epoch 40] ogbg-moltoxcast: 0.647674 val loss: 0.331918
[Epoch 40] ogbg-moltoxcast: 0.628814 test loss: 0.391074
[Epoch 41; Iter    20/  229] train: loss: 0.1832292
[Epoch 41; Iter    50/  229] train: loss: 0.1319308
[Epoch 41; Iter    80/  229] train: loss: 0.2079755
[Epoch 41; Iter   110/  229] train: loss: 0.0774095
[Epoch 41; Iter   140/  229] train: loss: 0.1762662
[Epoch 41; Iter   170/  229] train: loss: 0.1971965
[Epoch 41; Iter   200/  229] train: loss: 0.1497680
[Epoch 41] ogbg-moltoxcast: 0.659967 val loss: 0.314087
[Epoch 41] ogbg-moltoxcast: 0.632553 test loss: 0.369194
[Epoch 42; Iter     1/  229] train: loss: 0.1478220
[Epoch 42; Iter    31/  229] train: loss: 0.1121253
[Epoch 42; Iter    61/  229] train: loss: 0.1225037
[Epoch 42; Iter    91/  229] train: loss: 0.1622046
[Epoch 42; Iter   121/  229] train: loss: 0.1666494
[Epoch 42; Iter   151/  229] train: loss: 0.1202387
[Epoch 42; Iter   181/  229] train: loss: 0.1462625
[Epoch 42; Iter   211/  229] train: loss: 0.1305110
[Epoch 42] ogbg-moltoxcast: 0.653534 val loss: 0.322860
[Epoch 42] ogbg-moltoxcast: 0.625642 test loss: 0.379667
[Epoch 43; Iter    12/  229] train: loss: 0.0851958
[Epoch 43; Iter    42/  229] train: loss: 0.1713997
[Epoch 43; Iter    72/  229] train: loss: 0.1263167
[Epoch 43; Iter   102/  229] train: loss: 0.1657890
[Epoch 43; Iter   132/  229] train: loss: 0.1176299
[Epoch 43; Iter   162/  229] train: loss: 0.0944185
[Epoch 43; Iter   192/  229] train: loss: 0.1708131
[Epoch 43; Iter   222/  229] train: loss: 0.1228742
[Epoch 43] ogbg-moltoxcast: 0.650194 val loss: 0.305479
[Epoch 43] ogbg-moltoxcast: 0.630011 test loss: 0.357657
[Epoch 28; Iter    27/  229] train: loss: 0.1925786
[Epoch 28; Iter    57/  229] train: loss: 0.1595028
[Epoch 28; Iter    87/  229] train: loss: 0.1800554
[Epoch 28; Iter   117/  229] train: loss: 0.2105516
[Epoch 28; Iter   147/  229] train: loss: 0.1822723
[Epoch 28; Iter   177/  229] train: loss: 0.1791518
[Epoch 28; Iter   207/  229] train: loss: 0.1925781
[Epoch 28] ogbg-moltoxcast: 0.684553 val loss: 0.259030
[Epoch 28] ogbg-moltoxcast: 0.653608 test loss: 0.363917
[Epoch 29; Iter     8/  229] train: loss: 0.1429334
[Epoch 29; Iter    38/  229] train: loss: 0.1437615
[Epoch 29; Iter    68/  229] train: loss: 0.2161614
[Epoch 29; Iter    98/  229] train: loss: 0.2025835
[Epoch 29; Iter   128/  229] train: loss: 0.2481279
[Epoch 29; Iter   158/  229] train: loss: 0.1660324
[Epoch 29; Iter   188/  229] train: loss: 0.2363467
[Epoch 29; Iter   218/  229] train: loss: 0.1465586
[Epoch 29] ogbg-moltoxcast: 0.698469 val loss: 0.254121
[Epoch 29] ogbg-moltoxcast: 0.650189 test loss: 0.307441
[Epoch 30; Iter    19/  229] train: loss: 0.1608950
[Epoch 30; Iter    49/  229] train: loss: 0.1969116
[Epoch 30; Iter    79/  229] train: loss: 0.1226632
[Epoch 30; Iter   109/  229] train: loss: 0.1326018
[Epoch 30; Iter   139/  229] train: loss: 0.1446076
[Epoch 30; Iter   169/  229] train: loss: 0.1511888
[Epoch 30; Iter   199/  229] train: loss: 0.1247353
[Epoch 30; Iter   229/  229] train: loss: 0.2397972
[Epoch 30] ogbg-moltoxcast: 0.700574 val loss: 0.254013
[Epoch 30] ogbg-moltoxcast: 0.660823 test loss: 0.327957
[Epoch 31; Iter    30/  229] train: loss: 0.1524153
[Epoch 31; Iter    60/  229] train: loss: 0.1648215
[Epoch 31; Iter    90/  229] train: loss: 0.1324331
[Epoch 31; Iter   120/  229] train: loss: 0.1061300
[Epoch 31; Iter   150/  229] train: loss: 0.2193903
[Epoch 31; Iter   180/  229] train: loss: 0.1447937
[Epoch 31; Iter   210/  229] train: loss: 0.0742751
[Epoch 31] ogbg-moltoxcast: 0.697360 val loss: 0.256777
[Epoch 31] ogbg-moltoxcast: 0.657457 test loss: 0.676623
[Epoch 32; Iter    11/  229] train: loss: 0.1755378
[Epoch 32; Iter    41/  229] train: loss: 0.1258533
[Epoch 32; Iter    71/  229] train: loss: 0.1098543
[Epoch 32; Iter   101/  229] train: loss: 0.1419703
[Epoch 32; Iter   131/  229] train: loss: 0.1656282
[Epoch 32; Iter   161/  229] train: loss: 0.1377203
[Epoch 32; Iter   191/  229] train: loss: 0.1608735
[Epoch 32; Iter   221/  229] train: loss: 0.1027992
[Epoch 32] ogbg-moltoxcast: 0.709292 val loss: 0.247067
[Epoch 32] ogbg-moltoxcast: 0.666236 test loss: 0.303336
[Epoch 33; Iter    22/  229] train: loss: 0.1957885
[Epoch 33; Iter    52/  229] train: loss: 0.1651648
[Epoch 33; Iter    82/  229] train: loss: 0.1596077
[Epoch 33; Iter   112/  229] train: loss: 0.1456908
[Epoch 33; Iter   142/  229] train: loss: 0.1558498
[Epoch 33; Iter   172/  229] train: loss: 0.1175703
[Epoch 33; Iter   202/  229] train: loss: 0.1267032
[Epoch 33] ogbg-moltoxcast: 0.702301 val loss: 0.252022
[Epoch 33] ogbg-moltoxcast: 0.662137 test loss: 0.360103
[Epoch 34; Iter     3/  229] train: loss: 0.1381051
[Epoch 34; Iter    33/  229] train: loss: 0.2097383
[Epoch 34; Iter    63/  229] train: loss: 0.1704188
[Epoch 34; Iter    93/  229] train: loss: 0.1946779
[Epoch 34; Iter   123/  229] train: loss: 0.1210318
[Epoch 34; Iter   153/  229] train: loss: 0.1254593
[Epoch 34; Iter   183/  229] train: loss: 0.1811996
[Epoch 34; Iter   213/  229] train: loss: 0.1864676
[Epoch 34] ogbg-moltoxcast: 0.696641 val loss: 0.259101
[Epoch 34] ogbg-moltoxcast: 0.663382 test loss: 0.306652
[Epoch 35; Iter    14/  229] train: loss: 0.1731301
[Epoch 35; Iter    44/  229] train: loss: 0.1325494
[Epoch 35; Iter    74/  229] train: loss: 0.1587889
[Epoch 35; Iter   104/  229] train: loss: 0.2859164
[Epoch 35; Iter   134/  229] train: loss: 0.1382793
[Epoch 35; Iter   164/  229] train: loss: 0.1638472
[Epoch 35; Iter   194/  229] train: loss: 0.1513724
[Epoch 35; Iter   224/  229] train: loss: 0.1326578
[Epoch 35] ogbg-moltoxcast: 0.692356 val loss: 0.254148
[Epoch 35] ogbg-moltoxcast: 0.662300 test loss: 0.334874
[Epoch 36; Iter    25/  229] train: loss: 0.1489340
[Epoch 36; Iter    55/  229] train: loss: 0.1811849
[Epoch 36; Iter    85/  229] train: loss: 0.1455876
[Epoch 36; Iter   115/  229] train: loss: 0.1224791
[Epoch 36; Iter   145/  229] train: loss: 0.1271771
[Epoch 36; Iter   175/  229] train: loss: 0.1363749
[Epoch 36; Iter   205/  229] train: loss: 0.1791421
[Epoch 36] ogbg-moltoxcast: 0.704920 val loss: 0.256072
[Epoch 36] ogbg-moltoxcast: 0.657872 test loss: 0.444895
[Epoch 37; Iter     6/  229] train: loss: 0.1558123
[Epoch 37; Iter    36/  229] train: loss: 0.2190409
[Epoch 37; Iter    66/  229] train: loss: 0.1351099
[Epoch 37; Iter    96/  229] train: loss: 0.1627539
[Epoch 37; Iter   126/  229] train: loss: 0.1355573
[Epoch 37; Iter   156/  229] train: loss: 0.1610435
[Epoch 37; Iter   186/  229] train: loss: 0.1156839
[Epoch 37; Iter   216/  229] train: loss: 0.1389119
[Epoch 37] ogbg-moltoxcast: 0.707058 val loss: 0.248334
[Epoch 37] ogbg-moltoxcast: 0.661654 test loss: 0.764672
[Epoch 38; Iter    17/  229] train: loss: 0.1749801
[Epoch 38; Iter    47/  229] train: loss: 0.1478483
[Epoch 38; Iter    77/  229] train: loss: 0.1395016
[Epoch 38; Iter   107/  229] train: loss: 0.1592984
[Epoch 38; Iter   137/  229] train: loss: 0.1198601
[Epoch 38; Iter   167/  229] train: loss: 0.1211964
[Epoch 38; Iter   197/  229] train: loss: 0.1942409
[Epoch 38; Iter   227/  229] train: loss: 0.1259851
[Epoch 38] ogbg-moltoxcast: 0.705648 val loss: 0.244387
[Epoch 38] ogbg-moltoxcast: 0.661154 test loss: 0.397628
[Epoch 39; Iter    28/  229] train: loss: 0.1733765
[Epoch 39; Iter    58/  229] train: loss: 0.1468811
[Epoch 39; Iter    88/  229] train: loss: 0.1492733
[Epoch 39; Iter   118/  229] train: loss: 0.1970173
[Epoch 39; Iter   148/  229] train: loss: 0.1517946
[Epoch 39; Iter   178/  229] train: loss: 0.1643281
[Epoch 39; Iter   208/  229] train: loss: 0.1558961
[Epoch 39] ogbg-moltoxcast: 0.703943 val loss: 0.249078
[Epoch 39] ogbg-moltoxcast: 0.667134 test loss: 0.647120
[Epoch 40; Iter     9/  229] train: loss: 0.1373290
[Epoch 40; Iter    39/  229] train: loss: 0.1916775
[Epoch 40; Iter    69/  229] train: loss: 0.1680588
[Epoch 40; Iter    99/  229] train: loss: 0.0845104
[Epoch 40; Iter   129/  229] train: loss: 0.1726379
[Epoch 40; Iter   159/  229] train: loss: 0.1111011
[Epoch 40; Iter   189/  229] train: loss: 0.1177795
[Epoch 40; Iter   219/  229] train: loss: 0.1661480
[Epoch 40] ogbg-moltoxcast: 0.704174 val loss: 0.252424
[Epoch 40] ogbg-moltoxcast: 0.660712 test loss: 0.403787
[Epoch 41; Iter    20/  229] train: loss: 0.1311546
[Epoch 41; Iter    50/  229] train: loss: 0.1675302
[Epoch 41; Iter    80/  229] train: loss: 0.1647170
[Epoch 41; Iter   110/  229] train: loss: 0.1752301
[Epoch 41; Iter   140/  229] train: loss: 0.1451851
[Epoch 41; Iter   170/  229] train: loss: 0.1321089
[Epoch 41; Iter   200/  229] train: loss: 0.1755046
[Epoch 41] ogbg-moltoxcast: 0.705373 val loss: 0.247146
[Epoch 41] ogbg-moltoxcast: 0.667655 test loss: 0.310026
[Epoch 42; Iter     1/  229] train: loss: 0.1893726
[Epoch 42; Iter    31/  229] train: loss: 0.1154804
[Epoch 42; Iter    61/  229] train: loss: 0.1242655
[Epoch 42; Iter    91/  229] train: loss: 0.1738638
[Epoch 42; Iter   121/  229] train: loss: 0.1230159
[Epoch 42; Iter   151/  229] train: loss: 0.1372776
[Epoch 42; Iter   181/  229] train: loss: 0.2454573
[Epoch 42; Iter   211/  229] train: loss: 0.1222537
[Epoch 42] ogbg-moltoxcast: 0.708702 val loss: 0.252773
[Epoch 42] ogbg-moltoxcast: 0.657834 test loss: 0.596618
[Epoch 43; Iter    12/  229] train: loss: 0.1338737
[Epoch 43; Iter    42/  229] train: loss: 0.1459155
[Epoch 43; Iter    72/  229] train: loss: 0.1951755
[Epoch 43; Iter   102/  229] train: loss: 0.1437195
[Epoch 43; Iter   132/  229] train: loss: 0.1309483
[Epoch 43; Iter   162/  229] train: loss: 0.1499796
[Epoch 43; Iter   192/  229] train: loss: 0.1712449
[Epoch 43; Iter   222/  229] train: loss: 0.1594795
[Epoch 43] ogbg-moltoxcast: 0.708289 val loss: 0.247027
[Epoch 43] ogbg-moltoxcast: 0.664654 test loss: 0.419051
[Epoch 28; Iter    27/  229] train: loss: 0.1790460
[Epoch 28; Iter    57/  229] train: loss: 0.1986490
[Epoch 28; Iter    87/  229] train: loss: 0.1602496
[Epoch 28; Iter   117/  229] train: loss: 0.2493118
[Epoch 28; Iter   147/  229] train: loss: 0.1444479
[Epoch 28; Iter   177/  229] train: loss: 0.1421567
[Epoch 28; Iter   207/  229] train: loss: 0.1872873
[Epoch 28] ogbg-moltoxcast: 0.691581 val loss: 0.250606
[Epoch 28] ogbg-moltoxcast: 0.662091 test loss: 0.293135
[Epoch 29; Iter     8/  229] train: loss: 0.2870984
[Epoch 29; Iter    38/  229] train: loss: 0.2045125
[Epoch 29; Iter    68/  229] train: loss: 0.3094443
[Epoch 29; Iter    98/  229] train: loss: 0.1583353
[Epoch 29; Iter   128/  229] train: loss: 0.1384906
[Epoch 29; Iter   158/  229] train: loss: 0.2032971
[Epoch 29; Iter   188/  229] train: loss: 0.1245771
[Epoch 29; Iter   218/  229] train: loss: 0.1727782
[Epoch 29] ogbg-moltoxcast: 0.694532 val loss: 0.247336
[Epoch 29] ogbg-moltoxcast: 0.665329 test loss: 0.293810
[Epoch 30; Iter    19/  229] train: loss: 0.1232011
[Epoch 30; Iter    49/  229] train: loss: 0.1250397
[Epoch 30; Iter    79/  229] train: loss: 0.2349822
[Epoch 30; Iter   109/  229] train: loss: 0.1455162
[Epoch 30; Iter   139/  229] train: loss: 0.1551632
[Epoch 30; Iter   169/  229] train: loss: 0.1904644
[Epoch 30; Iter   199/  229] train: loss: 0.1782329
[Epoch 30; Iter   229/  229] train: loss: 0.1499897
[Epoch 30] ogbg-moltoxcast: 0.696595 val loss: 0.251648
[Epoch 30] ogbg-moltoxcast: 0.665778 test loss: 0.296981
[Epoch 31; Iter    30/  229] train: loss: 0.0982737
[Epoch 31; Iter    60/  229] train: loss: 0.1396996
[Epoch 31; Iter    90/  229] train: loss: 0.1386452
[Epoch 31; Iter   120/  229] train: loss: 0.0723554
[Epoch 31; Iter   150/  229] train: loss: 0.1746413
[Epoch 31; Iter   180/  229] train: loss: 0.1514926
[Epoch 31; Iter   210/  229] train: loss: 0.1850777
[Epoch 31] ogbg-moltoxcast: 0.691662 val loss: 0.249360
[Epoch 31] ogbg-moltoxcast: 0.661277 test loss: 0.290987
[Epoch 32; Iter    11/  229] train: loss: 0.1700425
[Epoch 32; Iter    41/  229] train: loss: 0.1386934
[Epoch 32; Iter    71/  229] train: loss: 0.1388481
[Epoch 32; Iter   101/  229] train: loss: 0.1497203
[Epoch 32; Iter   131/  229] train: loss: 0.2235831
[Epoch 32; Iter   161/  229] train: loss: 0.1488180
[Epoch 32; Iter   191/  229] train: loss: 0.1327229
[Epoch 32; Iter   221/  229] train: loss: 0.1083281
[Epoch 32] ogbg-moltoxcast: 0.696934 val loss: 0.261527
[Epoch 32] ogbg-moltoxcast: 0.664597 test loss: 0.305524
[Epoch 33; Iter    22/  229] train: loss: 0.1565834
[Epoch 33; Iter    52/  229] train: loss: 0.1602587
[Epoch 33; Iter    82/  229] train: loss: 0.1540859
[Epoch 33; Iter   112/  229] train: loss: 0.1841396
[Epoch 33; Iter   142/  229] train: loss: 0.1612906
[Epoch 33; Iter   172/  229] train: loss: 0.1589728
[Epoch 33; Iter   202/  229] train: loss: 0.1570744
[Epoch 33] ogbg-moltoxcast: 0.684399 val loss: 0.250623
[Epoch 33] ogbg-moltoxcast: 0.672929 test loss: 0.291152
[Epoch 34; Iter     3/  229] train: loss: 0.1953977
[Epoch 34; Iter    33/  229] train: loss: 0.1509764
[Epoch 34; Iter    63/  229] train: loss: 0.1973323
[Epoch 34; Iter    93/  229] train: loss: 0.1799742
[Epoch 34; Iter   123/  229] train: loss: 0.1700823
[Epoch 34; Iter   153/  229] train: loss: 0.1337826
[Epoch 34; Iter   183/  229] train: loss: 0.1525400
[Epoch 34; Iter   213/  229] train: loss: 0.1860618
[Epoch 34] ogbg-moltoxcast: 0.689954 val loss: 0.249421
[Epoch 34] ogbg-moltoxcast: 0.671256 test loss: 0.290250
[Epoch 35; Iter    14/  229] train: loss: 0.1450029
[Epoch 35; Iter    44/  229] train: loss: 0.1189924
[Epoch 35; Iter    74/  229] train: loss: 0.1061334
[Epoch 35; Iter   104/  229] train: loss: 0.1636902
[Epoch 35; Iter   134/  229] train: loss: 0.1531298
[Epoch 35; Iter   164/  229] train: loss: 0.1503328
[Epoch 35; Iter   194/  229] train: loss: 0.1753497
[Epoch 35; Iter   224/  229] train: loss: 0.1501774
[Epoch 35] ogbg-moltoxcast: 0.686322 val loss: 0.248191
[Epoch 35] ogbg-moltoxcast: 0.667609 test loss: 0.291083
[Epoch 36; Iter    25/  229] train: loss: 0.1445355
[Epoch 36; Iter    55/  229] train: loss: 0.1663438
[Epoch 36; Iter    85/  229] train: loss: 0.1574570
[Epoch 36; Iter   115/  229] train: loss: 0.1195872
[Epoch 36; Iter   145/  229] train: loss: 0.1943477
[Epoch 36; Iter   175/  229] train: loss: 0.1261163
[Epoch 36; Iter   205/  229] train: loss: 0.1519021
[Epoch 36] ogbg-moltoxcast: 0.692499 val loss: 0.254015
[Epoch 36] ogbg-moltoxcast: 0.667079 test loss: 0.302758
[Epoch 37; Iter     6/  229] train: loss: 0.1529378
[Epoch 37; Iter    36/  229] train: loss: 0.1404096
[Epoch 37; Iter    66/  229] train: loss: 0.2377665
[Epoch 37; Iter    96/  229] train: loss: 0.1183988
[Epoch 37; Iter   126/  229] train: loss: 0.1700810
[Epoch 37; Iter   156/  229] train: loss: 0.1904110
[Epoch 37; Iter   186/  229] train: loss: 0.1885583
[Epoch 37; Iter   216/  229] train: loss: 0.1849855
[Epoch 37] ogbg-moltoxcast: 0.691795 val loss: 0.248591
[Epoch 37] ogbg-moltoxcast: 0.666991 test loss: 0.292364
[Epoch 38; Iter    17/  229] train: loss: 0.1392455
[Epoch 38; Iter    47/  229] train: loss: 0.1650255
[Epoch 38; Iter    77/  229] train: loss: 0.1256486
[Epoch 38; Iter   107/  229] train: loss: 0.1346839
[Epoch 38; Iter   137/  229] train: loss: 0.1742089
[Epoch 38; Iter   167/  229] train: loss: 0.1211724
[Epoch 38; Iter   197/  229] train: loss: 0.1594487
[Epoch 38; Iter   227/  229] train: loss: 0.1384096
[Epoch 38] ogbg-moltoxcast: 0.689068 val loss: 0.250929
[Epoch 38] ogbg-moltoxcast: 0.665988 test loss: 0.297780
[Epoch 39; Iter    28/  229] train: loss: 0.1861466
[Epoch 39; Iter    58/  229] train: loss: 0.1269662
[Epoch 39; Iter    88/  229] train: loss: 0.1543289
[Epoch 39; Iter   118/  229] train: loss: 0.2015901
[Epoch 39; Iter   148/  229] train: loss: 0.1713288
[Epoch 39; Iter   178/  229] train: loss: 0.1305706
[Epoch 39; Iter   208/  229] train: loss: 0.1360605
[Epoch 39] ogbg-moltoxcast: 0.684843 val loss: 0.250668
[Epoch 39] ogbg-moltoxcast: 0.666376 test loss: 0.291575
[Epoch 40; Iter     9/  229] train: loss: 0.1672038
[Epoch 40; Iter    39/  229] train: loss: 0.1274047
[Epoch 40; Iter    69/  229] train: loss: 0.1627624
[Epoch 40; Iter    99/  229] train: loss: 0.1218903
[Epoch 40; Iter   129/  229] train: loss: 0.1741276
[Epoch 40; Iter   159/  229] train: loss: 0.1396164
[Epoch 40; Iter   189/  229] train: loss: 0.1671051
[Epoch 40; Iter   219/  229] train: loss: 0.1407655
[Epoch 40] ogbg-moltoxcast: 0.685796 val loss: 0.251633
[Epoch 40] ogbg-moltoxcast: 0.662090 test loss: 0.303175
[Epoch 41; Iter    20/  229] train: loss: 0.1873267
[Epoch 41; Iter    50/  229] train: loss: 0.1310445
[Epoch 41; Iter    80/  229] train: loss: 0.2098837
[Epoch 41; Iter   110/  229] train: loss: 0.0722515
[Epoch 41; Iter   140/  229] train: loss: 0.1866476
[Epoch 41; Iter   170/  229] train: loss: 0.2077371
[Epoch 41; Iter   200/  229] train: loss: 0.1599756
[Epoch 41] ogbg-moltoxcast: 0.694633 val loss: 0.254139
[Epoch 41] ogbg-moltoxcast: 0.669849 test loss: 1.105596
[Epoch 42; Iter     1/  229] train: loss: 0.1692366
[Epoch 42; Iter    31/  229] train: loss: 0.1138185
[Epoch 42; Iter    61/  229] train: loss: 0.1220196
[Epoch 42; Iter    91/  229] train: loss: 0.1828826
[Epoch 42; Iter   121/  229] train: loss: 0.1912168
[Epoch 42; Iter   151/  229] train: loss: 0.1305746
[Epoch 42; Iter   181/  229] train: loss: 0.1453868
[Epoch 42; Iter   211/  229] train: loss: 0.1457099
[Epoch 42] ogbg-moltoxcast: 0.683275 val loss: 0.255963
[Epoch 42] ogbg-moltoxcast: 0.670448 test loss: 0.386390
[Epoch 43; Iter    12/  229] train: loss: 0.0914099
[Epoch 43; Iter    42/  229] train: loss: 0.1813908
[Epoch 43; Iter    72/  229] train: loss: 0.1343511
[Epoch 43; Iter   102/  229] train: loss: 0.1673117
[Epoch 43; Iter   132/  229] train: loss: 0.1175426
[Epoch 43; Iter   162/  229] train: loss: 0.1043368
[Epoch 43; Iter   192/  229] train: loss: 0.1670898
[Epoch 43; Iter   222/  229] train: loss: 0.1335157
[Epoch 43] ogbg-moltoxcast: 0.694624 val loss: 0.248835
[Epoch 43] ogbg-moltoxcast: 0.671253 test loss: 0.622946
[Epoch 28; Iter    27/  229] train: loss: 0.1855075
[Epoch 28; Iter    57/  229] train: loss: 0.1598896
[Epoch 28; Iter    87/  229] train: loss: 0.1749478
[Epoch 28; Iter   117/  229] train: loss: 0.1828023
[Epoch 28; Iter   147/  229] train: loss: 0.1821766
[Epoch 28; Iter   177/  229] train: loss: 0.1500360
[Epoch 28; Iter   207/  229] train: loss: 0.1711401
[Epoch 28] ogbg-moltoxcast: 0.685853 val loss: 0.248030
[Epoch 28] ogbg-moltoxcast: 0.664699 test loss: 0.295415
[Epoch 29; Iter     8/  229] train: loss: 0.1083306
[Epoch 29; Iter    38/  229] train: loss: 0.1384963
[Epoch 29; Iter    68/  229] train: loss: 0.1320235
[Epoch 29; Iter    98/  229] train: loss: 0.1805936
[Epoch 29; Iter   128/  229] train: loss: 0.1409564
[Epoch 29; Iter   158/  229] train: loss: 0.1064970
[Epoch 29; Iter   188/  229] train: loss: 0.1483300
[Epoch 29; Iter   218/  229] train: loss: 0.1336750
[Epoch 29] ogbg-moltoxcast: 0.672825 val loss: 0.250373
[Epoch 29] ogbg-moltoxcast: 0.661215 test loss: 0.296191
[Epoch 30; Iter    19/  229] train: loss: 0.1379382
[Epoch 30; Iter    49/  229] train: loss: 0.1925321
[Epoch 30; Iter    79/  229] train: loss: 0.1324834
[Epoch 30; Iter   109/  229] train: loss: 0.2169789
[Epoch 30; Iter   139/  229] train: loss: 0.1860103
[Epoch 30; Iter   169/  229] train: loss: 0.1832720
[Epoch 30; Iter   199/  229] train: loss: 0.1535371
[Epoch 30; Iter   229/  229] train: loss: 0.1808221
[Epoch 30] ogbg-moltoxcast: 0.691449 val loss: 0.256544
[Epoch 30] ogbg-moltoxcast: 0.666804 test loss: 0.303380
[Epoch 31; Iter    30/  229] train: loss: 0.2135554
[Epoch 31; Iter    60/  229] train: loss: 0.1782224
[Epoch 31; Iter    90/  229] train: loss: 0.1698233
[Epoch 31; Iter   120/  229] train: loss: 0.1696356
[Epoch 31; Iter   150/  229] train: loss: 0.1618139
[Epoch 31; Iter   180/  229] train: loss: 0.2339075
[Epoch 31; Iter   210/  229] train: loss: 0.1516824
[Epoch 31] ogbg-moltoxcast: 0.693651 val loss: 0.296237
[Epoch 31] ogbg-moltoxcast: 0.674519 test loss: 0.305618
[Epoch 32; Iter    11/  229] train: loss: 0.1417970
[Epoch 32; Iter    41/  229] train: loss: 0.1461168
[Epoch 32; Iter    71/  229] train: loss: 0.1730558
[Epoch 32; Iter   101/  229] train: loss: 0.2119187
[Epoch 32; Iter   131/  229] train: loss: 0.1171269
[Epoch 32; Iter   161/  229] train: loss: 0.1940539
[Epoch 32; Iter   191/  229] train: loss: 0.0996163
[Epoch 32; Iter   221/  229] train: loss: 0.1483048
[Epoch 32] ogbg-moltoxcast: 0.690600 val loss: 0.281336
[Epoch 32] ogbg-moltoxcast: 0.675464 test loss: 0.297517
[Epoch 33; Iter    22/  229] train: loss: 0.1204520
[Epoch 33; Iter    52/  229] train: loss: 0.1181248
[Epoch 33; Iter    82/  229] train: loss: 0.1400352
[Epoch 33; Iter   112/  229] train: loss: 0.1975360
[Epoch 33; Iter   142/  229] train: loss: 0.1117472
[Epoch 33; Iter   172/  229] train: loss: 0.1608855
[Epoch 33; Iter   202/  229] train: loss: 0.1119102
[Epoch 33] ogbg-moltoxcast: 0.686423 val loss: 0.253412
[Epoch 33] ogbg-moltoxcast: 0.672137 test loss: 0.298643
[Epoch 34; Iter     3/  229] train: loss: 0.1970259
[Epoch 34; Iter    33/  229] train: loss: 0.1649926
[Epoch 34; Iter    63/  229] train: loss: 0.1646804
[Epoch 34; Iter    93/  229] train: loss: 0.1619196
[Epoch 34; Iter   123/  229] train: loss: 0.1369142
[Epoch 34; Iter   153/  229] train: loss: 0.1296877
[Epoch 34; Iter   183/  229] train: loss: 0.1151156
[Epoch 34; Iter   213/  229] train: loss: 0.2323763
[Epoch 34] ogbg-moltoxcast: 0.687826 val loss: 0.298817
[Epoch 34] ogbg-moltoxcast: 0.657316 test loss: 0.304204
[Epoch 35; Iter    14/  229] train: loss: 0.0826665
[Epoch 35; Iter    44/  229] train: loss: 0.1580323
[Epoch 35; Iter    74/  229] train: loss: 0.1375480
[Epoch 35; Iter   104/  229] train: loss: 0.2199214
[Epoch 35; Iter   134/  229] train: loss: 0.2161713
[Epoch 35; Iter   164/  229] train: loss: 0.1577606
[Epoch 35; Iter   194/  229] train: loss: 0.1287750
[Epoch 35; Iter   224/  229] train: loss: 0.1280906
[Epoch 35] ogbg-moltoxcast: 0.701362 val loss: 0.263386
[Epoch 35] ogbg-moltoxcast: 0.671810 test loss: 0.303089
[Epoch 36; Iter    25/  229] train: loss: 0.1858377
[Epoch 36; Iter    55/  229] train: loss: 0.1810277
[Epoch 36; Iter    85/  229] train: loss: 0.1275243
[Epoch 36; Iter   115/  229] train: loss: 0.1171900
[Epoch 36; Iter   145/  229] train: loss: 0.1663174
[Epoch 36; Iter   175/  229] train: loss: 0.1687751
[Epoch 36; Iter   205/  229] train: loss: 0.1817003
[Epoch 36] ogbg-moltoxcast: 0.696123 val loss: 0.249593
[Epoch 36] ogbg-moltoxcast: 0.670771 test loss: 0.304263
[Epoch 37; Iter     6/  229] train: loss: 0.1219592
[Epoch 37; Iter    36/  229] train: loss: 0.0997235
[Epoch 37; Iter    66/  229] train: loss: 0.1363299
[Epoch 37; Iter    96/  229] train: loss: 0.1384143
[Epoch 37; Iter   126/  229] train: loss: 0.1314305
[Epoch 37; Iter   156/  229] train: loss: 0.1284504
[Epoch 37; Iter   186/  229] train: loss: 0.1606195
[Epoch 37; Iter   216/  229] train: loss: 0.1585929
[Epoch 37] ogbg-moltoxcast: 0.693393 val loss: 0.251957
[Epoch 37] ogbg-moltoxcast: 0.666778 test loss: 0.305447
[Epoch 38; Iter    17/  229] train: loss: 0.1897010
[Epoch 38; Iter    47/  229] train: loss: 0.1603931
[Epoch 38; Iter    77/  229] train: loss: 0.1326812
[Epoch 38; Iter   107/  229] train: loss: 0.1431563
[Epoch 38; Iter   137/  229] train: loss: 0.1798945
[Epoch 38; Iter   167/  229] train: loss: 0.1431915
[Epoch 38; Iter   197/  229] train: loss: 0.1580312
[Epoch 38; Iter   227/  229] train: loss: 0.1708863
[Epoch 38] ogbg-moltoxcast: 0.686255 val loss: 0.317839
[Epoch 38] ogbg-moltoxcast: 0.664559 test loss: 0.309724
[Epoch 39; Iter    28/  229] train: loss: 0.1879898
[Epoch 39; Iter    58/  229] train: loss: 0.1140220
[Epoch 39; Iter    88/  229] train: loss: 0.1266986
[Epoch 39; Iter   118/  229] train: loss: 0.2387316
[Epoch 39; Iter   148/  229] train: loss: 0.1413826
[Epoch 39; Iter   178/  229] train: loss: 0.1698583
[Epoch 39; Iter   208/  229] train: loss: 0.1891805
[Epoch 39] ogbg-moltoxcast: 0.698111 val loss: 0.244798
[Epoch 39] ogbg-moltoxcast: 0.675060 test loss: 0.302505
[Epoch 40; Iter     9/  229] train: loss: 0.1434652
[Epoch 40; Iter    39/  229] train: loss: 0.1272049
[Epoch 40; Iter    69/  229] train: loss: 0.1124617
[Epoch 40; Iter    99/  229] train: loss: 0.1782527
[Epoch 40; Iter   129/  229] train: loss: 0.1396888
[Epoch 40; Iter   159/  229] train: loss: 0.1349757
[Epoch 40; Iter   189/  229] train: loss: 0.1490623
[Epoch 40; Iter   219/  229] train: loss: 0.2024214
[Epoch 40] ogbg-moltoxcast: 0.695455 val loss: 0.256672
[Epoch 40] ogbg-moltoxcast: 0.665592 test loss: 0.309462
[Epoch 41; Iter    20/  229] train: loss: 0.1457418
[Epoch 41; Iter    50/  229] train: loss: 0.1187125
[Epoch 41; Iter    80/  229] train: loss: 0.0880024
[Epoch 41; Iter   110/  229] train: loss: 0.1058652
[Epoch 41; Iter   140/  229] train: loss: 0.1224957
[Epoch 41; Iter   170/  229] train: loss: 0.1014958
[Epoch 41; Iter   200/  229] train: loss: 0.1667781
[Epoch 41] ogbg-moltoxcast: 0.686850 val loss: 0.254595
[Epoch 41] ogbg-moltoxcast: 0.668022 test loss: 0.309091
[Epoch 42; Iter     1/  229] train: loss: 0.1849604
[Epoch 42; Iter    31/  229] train: loss: 0.1363837
[Epoch 42; Iter    61/  229] train: loss: 0.1778834
[Epoch 42; Iter    91/  229] train: loss: 0.1226527
[Epoch 42; Iter   121/  229] train: loss: 0.1779989
[Epoch 42; Iter   151/  229] train: loss: 0.1209562
[Epoch 42; Iter   181/  229] train: loss: 0.1381554
[Epoch 42; Iter   211/  229] train: loss: 0.1729339
[Epoch 42] ogbg-moltoxcast: 0.686341 val loss: 0.273298
[Epoch 42] ogbg-moltoxcast: 0.664200 test loss: 0.318468
[Epoch 43; Iter    12/  229] train: loss: 0.1806666
[Epoch 43; Iter    42/  229] train: loss: 0.1629197
[Epoch 43; Iter    72/  229] train: loss: 0.1769907
[Epoch 43; Iter   102/  229] train: loss: 0.1576435
[Epoch 43; Iter   132/  229] train: loss: 0.1200630
[Epoch 43; Iter   162/  229] train: loss: 0.1813323
[Epoch 43; Iter   192/  229] train: loss: 0.1086441
[Epoch 43; Iter   222/  229] train: loss: 0.1453402
[Epoch 43] ogbg-moltoxcast: 0.691405 val loss: 0.262435
[Epoch 43] ogbg-moltoxcast: 0.674789 test loss: 0.316845
[Epoch 44; Iter    23/  229] train: loss: 0.1757094
[Epoch 44; Iter    53/  229] train: loss: 0.0968421
[Epoch 44; Iter    83/  229] train: loss: 0.1470386
[Epoch 44; Iter   113/  229] train: loss: 0.0965460
[Epoch 44; Iter   143/  229] train: loss: 0.1489019
[Epoch 44; Iter   173/  229] train: loss: 0.1207559
[Epoch 44; Iter   203/  229] train: loss: 0.1372019
[Epoch 44] ogbg-moltoxcast: 0.680760 val loss: 0.271298
[Epoch 44] ogbg-moltoxcast: 0.654328 test loss: 0.323186
[Epoch 45; Iter     4/  229] train: loss: 0.1268091
[Epoch 45; Iter    34/  229] train: loss: 0.1409854
[Epoch 45; Iter    64/  229] train: loss: 0.1628686
[Epoch 45; Iter    94/  229] train: loss: 0.1191917
[Epoch 45; Iter   124/  229] train: loss: 0.1458101
[Epoch 45; Iter   154/  229] train: loss: 0.1305679
[Epoch 45; Iter   184/  229] train: loss: 0.1547913
[Epoch 45; Iter   214/  229] train: loss: 0.1506650
[Epoch 45] ogbg-moltoxcast: 0.673473 val loss: 0.275233
[Epoch 45] ogbg-moltoxcast: 0.652069 test loss: 0.320375
[Epoch 46; Iter    15/  229] train: loss: 0.1244893
[Epoch 46; Iter    45/  229] train: loss: 0.1469212
[Epoch 46; Iter    75/  229] train: loss: 0.1851793
[Epoch 46; Iter   105/  229] train: loss: 0.1509678
[Epoch 46; Iter   135/  229] train: loss: 0.1484473
[Epoch 46; Iter   165/  229] train: loss: 0.1194344
[Epoch 46; Iter   195/  229] train: loss: 0.1530387
[Epoch 46; Iter   225/  229] train: loss: 0.1482663
[Epoch 46] ogbg-moltoxcast: 0.677013 val loss: 0.287016
[Epoch 46] ogbg-moltoxcast: 0.642108 test loss: 0.339579
[Epoch 47; Iter    26/  229] train: loss: 0.1463527
[Epoch 47; Iter    56/  229] train: loss: 0.1597819
[Epoch 47; Iter    86/  229] train: loss: 0.1213638
[Epoch 47; Iter   116/  229] train: loss: 0.0943619
[Epoch 47; Iter   146/  229] train: loss: 0.1083348
[Epoch 47; Iter   176/  229] train: loss: 0.1566425
[Epoch 47; Iter   206/  229] train: loss: 0.1293608
[Epoch 47] ogbg-moltoxcast: 0.674036 val loss: 0.280463
[Epoch 47] ogbg-moltoxcast: 0.647062 test loss: 0.329818
[Epoch 48; Iter     7/  229] train: loss: 0.1147007
[Epoch 48; Iter    37/  229] train: loss: 0.1113118
[Epoch 48; Iter    67/  229] train: loss: 0.1380678
[Epoch 48; Iter    97/  229] train: loss: 0.1494463
[Epoch 48; Iter   127/  229] train: loss: 0.1602048
[Epoch 48; Iter   157/  229] train: loss: 0.1140232
[Epoch 48; Iter   187/  229] train: loss: 0.1848511
[Epoch 48; Iter   217/  229] train: loss: 0.1295260
[Epoch 48] ogbg-moltoxcast: 0.678550 val loss: 0.284982
[Epoch 48] ogbg-moltoxcast: 0.647468 test loss: 0.341415
[Epoch 49; Iter    18/  229] train: loss: 0.1745481
[Epoch 49; Iter    48/  229] train: loss: 0.1121742
[Epoch 49; Iter    78/  229] train: loss: 0.1813744
[Epoch 49; Iter   108/  229] train: loss: 0.1326084
[Epoch 49; Iter   138/  229] train: loss: 0.1540532
[Epoch 49; Iter   168/  229] train: loss: 0.1210098
[Epoch 49; Iter   198/  229] train: loss: 0.1498610
[Epoch 49; Iter   228/  229] train: loss: 0.1277246
[Epoch 49] ogbg-moltoxcast: 0.683487 val loss: 0.277125
[Epoch 49] ogbg-moltoxcast: 0.660848 test loss: 0.325877
[Epoch 50; Iter    29/  229] train: loss: 0.1656655
[Epoch 50; Iter    59/  229] train: loss: 0.1194322
[Epoch 50; Iter    89/  229] train: loss: 0.1546364
[Epoch 50; Iter   119/  229] train: loss: 0.1107770
[Epoch 50; Iter   149/  229] train: loss: 0.1577471
[Epoch 50; Iter   179/  229] train: loss: 0.1657875
[Epoch 50; Iter   209/  229] train: loss: 0.1963764
[Epoch 50] ogbg-moltoxcast: 0.683683 val loss: 0.280480
[Epoch 50] ogbg-moltoxcast: 0.658800 test loss: 0.328313
[Epoch 51; Iter    10/  229] train: loss: 0.1427957
[Epoch 51; Iter    40/  229] train: loss: 0.0986542
[Epoch 51; Iter    70/  229] train: loss: 0.1557932
[Epoch 51; Iter   100/  229] train: loss: 0.1414842
[Epoch 51; Iter   130/  229] train: loss: 0.1257734
[Epoch 51; Iter   160/  229] train: loss: 0.1094016
[Epoch 51; Iter   190/  229] train: loss: 0.1133723
[Epoch 51; Iter   220/  229] train: loss: 0.1447861
[Epoch 51] ogbg-moltoxcast: 0.684622 val loss: 0.326445
[Epoch 51] ogbg-moltoxcast: 0.652645 test loss: 0.329213
[Epoch 52; Iter    21/  229] train: loss: 0.1347604
[Epoch 52; Iter    51/  229] train: loss: 0.1185499
[Epoch 52; Iter    81/  229] train: loss: 0.1442009
[Epoch 52; Iter   111/  229] train: loss: 0.1117108
[Epoch 52; Iter   141/  229] train: loss: 0.1170052
[Epoch 52; Iter   171/  229] train: loss: 0.0792377
[Epoch 52; Iter   201/  229] train: loss: 0.1313780
[Epoch 52] ogbg-moltoxcast: 0.683014 val loss: 0.420374
[Epoch 52] ogbg-moltoxcast: 0.650447 test loss: 0.338681
[Epoch 53; Iter     2/  229] train: loss: 0.1089577
[Epoch 53; Iter    32/  229] train: loss: 0.0835131
[Epoch 53; Iter    62/  229] train: loss: 0.1224766
[Epoch 53; Iter    92/  229] train: loss: 0.1103314
[Epoch 53; Iter   122/  229] train: loss: 0.1012250
[Epoch 53; Iter   152/  229] train: loss: 0.1494404
[Epoch 53; Iter   182/  229] train: loss: 0.1310899
[Epoch 53; Iter   212/  229] train: loss: 0.1520657
[Epoch 53] ogbg-moltoxcast: 0.679543 val loss: 0.279152
[Epoch 53] ogbg-moltoxcast: 0.649536 test loss: 0.330027
[Epoch 54; Iter    13/  229] train: loss: 0.0860729
[Epoch 54; Iter    43/  229] train: loss: 0.0963443
[Epoch 54; Iter    73/  229] train: loss: 0.1043441
[Epoch 54; Iter   103/  229] train: loss: 0.1003913
[Epoch 54; Iter   133/  229] train: loss: 0.1189056
[Epoch 54; Iter   163/  229] train: loss: 0.1214984
[Epoch 54; Iter   193/  229] train: loss: 0.1437562
[Epoch 54; Iter   223/  229] train: loss: 0.1637784
[Epoch 54] ogbg-moltoxcast: 0.684270 val loss: 0.284777
[Epoch 54] ogbg-moltoxcast: 0.652609 test loss: 0.333528
[Epoch 55; Iter    24/  229] train: loss: 0.1512769
[Epoch 55; Iter    54/  229] train: loss: 0.1593409
[Epoch 55; Iter    84/  229] train: loss: 0.1123473
[Epoch 55; Iter   114/  229] train: loss: 0.1398744
[Epoch 55; Iter   144/  229] train: loss: 0.1276518
[Epoch 55; Iter   174/  229] train: loss: 0.1324128
[Epoch 55; Iter   204/  229] train: loss: 0.1486438
[Epoch 55] ogbg-moltoxcast: 0.681222 val loss: 0.284519
[Epoch 55] ogbg-moltoxcast: 0.646757 test loss: 0.338841
[Epoch 56; Iter     5/  229] train: loss: 0.1480272
[Epoch 56; Iter    35/  229] train: loss: 0.1074382
[Epoch 56; Iter    65/  229] train: loss: 0.1713537
[Epoch 56; Iter    95/  229] train: loss: 0.1303128
[Epoch 56; Iter   125/  229] train: loss: 0.1159174
[Epoch 56; Iter   155/  229] train: loss: 0.1362755
[Epoch 56; Iter   185/  229] train: loss: 0.1573722
[Epoch 56; Iter   215/  229] train: loss: 0.1087515
[Epoch 56] ogbg-moltoxcast: 0.678325 val loss: 0.305076
[Epoch 56] ogbg-moltoxcast: 0.646746 test loss: 0.330459
[Epoch 57; Iter    16/  229] train: loss: 0.1890336
[Epoch 57; Iter    46/  229] train: loss: 0.1314489
[Epoch 57; Iter    76/  229] train: loss: 0.0980584
[Epoch 57; Iter   106/  229] train: loss: 0.1624711
[Epoch 57; Iter   136/  229] train: loss: 0.1079814
[Epoch 57; Iter   166/  229] train: loss: 0.0862149
[Epoch 57; Iter   196/  229] train: loss: 0.1268844
[Epoch 57; Iter   226/  229] train: loss: 0.2091087
[Epoch 57] ogbg-moltoxcast: 0.684669 val loss: 0.410319
[Epoch 57] ogbg-moltoxcast: 0.653058 test loss: 0.337249
[Epoch 58; Iter    27/  229] train: loss: 0.1282015
[Epoch 58; Iter    57/  229] train: loss: 0.1523667
[Epoch 58; Iter    87/  229] train: loss: 0.1464096
[Epoch 58; Iter   117/  229] train: loss: 0.1460704
[Epoch 58; Iter   147/  229] train: loss: 0.1918338
[Epoch 58; Iter   177/  229] train: loss: 0.1927273
[Epoch 58; Iter   207/  229] train: loss: 0.1130031
[Epoch 58] ogbg-moltoxcast: 0.681456 val loss: 0.542984
[Epoch 58] ogbg-moltoxcast: 0.653142 test loss: 0.336453
[Epoch 59; Iter     8/  229] train: loss: 0.1263628
[Epoch 59; Iter    38/  229] train: loss: 0.1059470
[Epoch 59; Iter    68/  229] train: loss: 0.1225151
[Epoch 59; Iter    98/  229] train: loss: 0.1171372
[Epoch 59; Iter   128/  229] train: loss: 0.1142931
[Epoch 59; Iter   158/  229] train: loss: 0.1344378
[Epoch 59; Iter   188/  229] train: loss: 0.1130655
[Epoch 59; Iter   218/  229] train: loss: 0.1154247
[Epoch 59] ogbg-moltoxcast: 0.675640 val loss: 0.407230
[Epoch 59] ogbg-moltoxcast: 0.646049 test loss: 0.327613
[Epoch 44; Iter    23/  229] train: loss: 0.1959466
[Epoch 44; Iter    53/  229] train: loss: 0.0902850
[Epoch 44; Iter    83/  229] train: loss: 0.1338719
[Epoch 44; Iter   113/  229] train: loss: 0.1275969
[Epoch 44; Iter   143/  229] train: loss: 0.1876261
[Epoch 44; Iter   173/  229] train: loss: 0.1576934
[Epoch 44; Iter   203/  229] train: loss: 0.1431609
[Epoch 44] ogbg-moltoxcast: 0.686832 val loss: 0.679563
[Epoch 44] ogbg-moltoxcast: 0.643621 test loss: 0.455580
[Epoch 45; Iter     4/  229] train: loss: 0.1246644
[Epoch 45; Iter    34/  229] train: loss: 0.1229271
[Epoch 45; Iter    64/  229] train: loss: 0.1556975
[Epoch 45; Iter    94/  229] train: loss: 0.0951709
[Epoch 45; Iter   124/  229] train: loss: 0.1435563
[Epoch 45; Iter   154/  229] train: loss: 0.1243983
[Epoch 45; Iter   184/  229] train: loss: 0.1080079
[Epoch 45; Iter   214/  229] train: loss: 0.0972395
[Epoch 45] ogbg-moltoxcast: 0.686215 val loss: 0.453348
[Epoch 45] ogbg-moltoxcast: 0.644635 test loss: 0.346007
[Epoch 46; Iter    15/  229] train: loss: 0.1461780
[Epoch 46; Iter    45/  229] train: loss: 0.1697066
[Epoch 46; Iter    75/  229] train: loss: 0.1335406
[Epoch 46; Iter   105/  229] train: loss: 0.1683803
[Epoch 46; Iter   135/  229] train: loss: 0.1571625
[Epoch 46; Iter   165/  229] train: loss: 0.1323902
[Epoch 46; Iter   195/  229] train: loss: 0.1322085
[Epoch 46; Iter   225/  229] train: loss: 0.1380972
[Epoch 46] ogbg-moltoxcast: 0.685941 val loss: 0.348269
[Epoch 46] ogbg-moltoxcast: 0.651501 test loss: 0.335705
[Epoch 47; Iter    26/  229] train: loss: 0.1593253
[Epoch 47; Iter    56/  229] train: loss: 0.1580380
[Epoch 47; Iter    86/  229] train: loss: 0.1433973
[Epoch 47; Iter   116/  229] train: loss: 0.1283003
[Epoch 47; Iter   146/  229] train: loss: 0.1241020
[Epoch 47; Iter   176/  229] train: loss: 0.1032083
[Epoch 47; Iter   206/  229] train: loss: 0.1223966
[Epoch 47] ogbg-moltoxcast: 0.686710 val loss: 0.405351
[Epoch 47] ogbg-moltoxcast: 0.648074 test loss: 0.333021
[Epoch 48; Iter     7/  229] train: loss: 0.1477229
[Epoch 48; Iter    37/  229] train: loss: 0.1281752
[Epoch 48; Iter    67/  229] train: loss: 0.1211796
[Epoch 48; Iter    97/  229] train: loss: 0.1382368
[Epoch 48; Iter   127/  229] train: loss: 0.1399168
[Epoch 48; Iter   157/  229] train: loss: 0.0995025
[Epoch 48; Iter   187/  229] train: loss: 0.1420637
[Epoch 48; Iter   217/  229] train: loss: 0.1314648
[Epoch 48] ogbg-moltoxcast: 0.694641 val loss: 0.440586
[Epoch 48] ogbg-moltoxcast: 0.650865 test loss: 0.369314
[Epoch 49; Iter    18/  229] train: loss: 0.1534524
[Epoch 49; Iter    48/  229] train: loss: 0.1293843
[Epoch 49; Iter    78/  229] train: loss: 0.0886946
[Epoch 49; Iter   108/  229] train: loss: 0.1288106
[Epoch 49; Iter   138/  229] train: loss: 0.1188262
[Epoch 49; Iter   168/  229] train: loss: 0.1315742
[Epoch 49; Iter   198/  229] train: loss: 0.1366332
[Epoch 49; Iter   228/  229] train: loss: 0.1499183
[Epoch 49] ogbg-moltoxcast: 0.692040 val loss: 0.422210
[Epoch 49] ogbg-moltoxcast: 0.645769 test loss: 0.350483
[Epoch 50; Iter    29/  229] train: loss: 0.1098901
[Epoch 50; Iter    59/  229] train: loss: 0.1489377
[Epoch 50; Iter    89/  229] train: loss: 0.0806565
[Epoch 50; Iter   119/  229] train: loss: 0.1686200
[Epoch 50; Iter   149/  229] train: loss: 0.1331977
[Epoch 50; Iter   179/  229] train: loss: 0.1370387
[Epoch 50; Iter   209/  229] train: loss: 0.1061937
[Epoch 50] ogbg-moltoxcast: 0.691529 val loss: 0.342112
[Epoch 50] ogbg-moltoxcast: 0.647049 test loss: 0.332332
[Epoch 51; Iter    10/  229] train: loss: 0.1486773
[Epoch 51; Iter    40/  229] train: loss: 0.0999408
[Epoch 51; Iter    70/  229] train: loss: 0.1419846
[Epoch 51; Iter   100/  229] train: loss: 0.1464949
[Epoch 51; Iter   130/  229] train: loss: 0.1093165
[Epoch 51; Iter   160/  229] train: loss: 0.1073996
[Epoch 51; Iter   190/  229] train: loss: 0.1354884
[Epoch 51; Iter   220/  229] train: loss: 0.1527696
[Epoch 51] ogbg-moltoxcast: 0.692518 val loss: 0.420120
[Epoch 51] ogbg-moltoxcast: 0.654293 test loss: 0.337700
[Epoch 52; Iter    21/  229] train: loss: 0.1192601
[Epoch 52; Iter    51/  229] train: loss: 0.1387115
[Epoch 52; Iter    81/  229] train: loss: 0.1263409
[Epoch 52; Iter   111/  229] train: loss: 0.1779118
[Epoch 52; Iter   141/  229] train: loss: 0.1390005
[Epoch 52; Iter   171/  229] train: loss: 0.1481554
[Epoch 52; Iter   201/  229] train: loss: 0.1323448
[Epoch 52] ogbg-moltoxcast: 0.687073 val loss: 0.387280
[Epoch 52] ogbg-moltoxcast: 0.640815 test loss: 0.351746
[Epoch 53; Iter     2/  229] train: loss: 0.0962308
[Epoch 53; Iter    32/  229] train: loss: 0.1222689
[Epoch 53; Iter    62/  229] train: loss: 0.1404608
[Epoch 53; Iter    92/  229] train: loss: 0.1656527
[Epoch 53; Iter   122/  229] train: loss: 0.0812818
[Epoch 53; Iter   152/  229] train: loss: 0.1105912
[Epoch 53; Iter   182/  229] train: loss: 0.1222604
[Epoch 53; Iter   212/  229] train: loss: 0.1222160
[Epoch 53] ogbg-moltoxcast: 0.697795 val loss: 0.372568
[Epoch 53] ogbg-moltoxcast: 0.649922 test loss: 0.344081
[Epoch 54; Iter    13/  229] train: loss: 0.0836057
[Epoch 54; Iter    43/  229] train: loss: 0.1436762
[Epoch 54; Iter    73/  229] train: loss: 0.1164511
[Epoch 54; Iter   103/  229] train: loss: 0.1268409
[Epoch 54; Iter   133/  229] train: loss: 0.1434951
[Epoch 54; Iter   163/  229] train: loss: 0.1562525
[Epoch 54; Iter   193/  229] train: loss: 0.1514018
[Epoch 54; Iter   223/  229] train: loss: 0.1700387
[Epoch 54] ogbg-moltoxcast: 0.688645 val loss: 0.415128
[Epoch 54] ogbg-moltoxcast: 0.646871 test loss: 0.332174
[Epoch 55; Iter    24/  229] train: loss: 0.1657139
[Epoch 55; Iter    54/  229] train: loss: 0.1813294
[Epoch 55; Iter    84/  229] train: loss: 0.1012765
[Epoch 55; Iter   114/  229] train: loss: 0.1545190
[Epoch 55; Iter   144/  229] train: loss: 0.1467154
[Epoch 55; Iter   174/  229] train: loss: 0.1557436
[Epoch 55; Iter   204/  229] train: loss: 0.1053439
[Epoch 55] ogbg-moltoxcast: 0.682934 val loss: 0.387916
[Epoch 55] ogbg-moltoxcast: 0.636826 test loss: 0.340405
[Epoch 56; Iter     5/  229] train: loss: 0.1168317
[Epoch 56; Iter    35/  229] train: loss: 0.1380889
[Epoch 56; Iter    65/  229] train: loss: 0.1183071
[Epoch 56; Iter    95/  229] train: loss: 0.1452657
[Epoch 56; Iter   125/  229] train: loss: 0.0890978
[Epoch 56; Iter   155/  229] train: loss: 0.1029118
[Epoch 56; Iter   185/  229] train: loss: 0.1329806
[Epoch 56; Iter   215/  229] train: loss: 0.1317341
[Epoch 56] ogbg-moltoxcast: 0.700220 val loss: 0.434333
[Epoch 56] ogbg-moltoxcast: 0.641550 test loss: 0.352433
[Epoch 57; Iter    16/  229] train: loss: 0.1047911
[Epoch 57; Iter    46/  229] train: loss: 0.1075428
[Epoch 57; Iter    76/  229] train: loss: 0.1767808
[Epoch 57; Iter   106/  229] train: loss: 0.1528002
[Epoch 57; Iter   136/  229] train: loss: 0.1331282
[Epoch 57; Iter   166/  229] train: loss: 0.0939575
[Epoch 57; Iter   196/  229] train: loss: 0.1539524
[Epoch 57; Iter   226/  229] train: loss: 0.1914042
[Epoch 57] ogbg-moltoxcast: 0.700949 val loss: 0.429308
[Epoch 57] ogbg-moltoxcast: 0.640522 test loss: 0.339635
[Epoch 58; Iter    27/  229] train: loss: 0.1102245
[Epoch 58; Iter    57/  229] train: loss: 0.1019026
[Epoch 58; Iter    87/  229] train: loss: 0.1137839
[Epoch 58; Iter   117/  229] train: loss: 0.0979551
[Epoch 58; Iter   147/  229] train: loss: 0.1127968
[Epoch 58; Iter   177/  229] train: loss: 0.1648029
[Epoch 58; Iter   207/  229] train: loss: 0.1108111
[Epoch 58] ogbg-moltoxcast: 0.686640 val loss: 0.362085
[Epoch 58] ogbg-moltoxcast: 0.646977 test loss: 0.363979
[Epoch 59; Iter     8/  229] train: loss: 0.1163477
[Epoch 59; Iter    38/  229] train: loss: 0.1297047
[Epoch 59; Iter    68/  229] train: loss: 0.1081330
[Epoch 59; Iter    98/  229] train: loss: 0.1530258
[Epoch 59; Iter   128/  229] train: loss: 0.1572680
[Epoch 59; Iter   158/  229] train: loss: 0.1071767
[Epoch 59; Iter   188/  229] train: loss: 0.1359223
[Epoch 59; Iter   218/  229] train: loss: 0.1113523
[Epoch 59] ogbg-moltoxcast: 0.690436 val loss: 0.464998
[Epoch 59] ogbg-moltoxcast: 0.637837 test loss: 0.350927
[Epoch 44; Iter    23/  229] train: loss: 0.1206874
[Epoch 44; Iter    53/  229] train: loss: 0.1294228
[Epoch 44; Iter    83/  229] train: loss: 0.1397468
[Epoch 44; Iter   113/  229] train: loss: 0.1397214
[Epoch 44; Iter   143/  229] train: loss: 0.1552486
[Epoch 44; Iter   173/  229] train: loss: 0.1287783
[Epoch 44; Iter   203/  229] train: loss: 0.0920249
[Epoch 44] ogbg-moltoxcast: 0.673763 val loss: 0.285570
[Epoch 44] ogbg-moltoxcast: 0.648354 test loss: 0.515103
[Epoch 45; Iter     4/  229] train: loss: 0.1206904
[Epoch 45; Iter    34/  229] train: loss: 0.1641942
[Epoch 45; Iter    64/  229] train: loss: 0.1085352
[Epoch 45; Iter    94/  229] train: loss: 0.1534833
[Epoch 45; Iter   124/  229] train: loss: 0.1966649
[Epoch 45; Iter   154/  229] train: loss: 0.1505394
[Epoch 45; Iter   184/  229] train: loss: 0.1805526
[Epoch 45; Iter   214/  229] train: loss: 0.1365617
[Epoch 45] ogbg-moltoxcast: 0.666043 val loss: 0.292193
[Epoch 45] ogbg-moltoxcast: 0.644216 test loss: 0.495837
[Epoch 46; Iter    15/  229] train: loss: 0.1654005
[Epoch 46; Iter    45/  229] train: loss: 0.1769053
[Epoch 46; Iter    75/  229] train: loss: 0.2028803
[Epoch 46; Iter   105/  229] train: loss: 0.1339755
[Epoch 46; Iter   135/  229] train: loss: 0.1618805
[Epoch 46; Iter   165/  229] train: loss: 0.1215679
[Epoch 46; Iter   195/  229] train: loss: 0.1609227
[Epoch 46; Iter   225/  229] train: loss: 0.1153082
[Epoch 46] ogbg-moltoxcast: 0.665689 val loss: 0.285336
[Epoch 46] ogbg-moltoxcast: 0.651067 test loss: 0.434504
[Epoch 47; Iter    26/  229] train: loss: 0.1351768
[Epoch 47; Iter    56/  229] train: loss: 0.1476157
[Epoch 47; Iter    86/  229] train: loss: 0.1064475
[Epoch 47; Iter   116/  229] train: loss: 0.1519053
[Epoch 47; Iter   146/  229] train: loss: 0.1074042
[Epoch 47; Iter   176/  229] train: loss: 0.1376682
[Epoch 47; Iter   206/  229] train: loss: 0.1452927
[Epoch 47] ogbg-moltoxcast: 0.670210 val loss: 0.297591
[Epoch 47] ogbg-moltoxcast: 0.649868 test loss: 0.547619
[Epoch 48; Iter     7/  229] train: loss: 0.1826122
[Epoch 48; Iter    37/  229] train: loss: 0.1163811
[Epoch 48; Iter    67/  229] train: loss: 0.1641455
[Epoch 48; Iter    97/  229] train: loss: 0.1449447
[Epoch 48; Iter   127/  229] train: loss: 0.2041873
[Epoch 48; Iter   157/  229] train: loss: 0.1554550
[Epoch 48; Iter   187/  229] train: loss: 0.1529280
[Epoch 48; Iter   217/  229] train: loss: 0.1120702
[Epoch 48] ogbg-moltoxcast: 0.679725 val loss: 0.283980
[Epoch 48] ogbg-moltoxcast: 0.641114 test loss: 0.689244
[Epoch 49; Iter    18/  229] train: loss: 0.1265131
[Epoch 49; Iter    48/  229] train: loss: 0.1394911
[Epoch 49; Iter    78/  229] train: loss: 0.1106115
[Epoch 49; Iter   108/  229] train: loss: 0.1923570
[Epoch 49; Iter   138/  229] train: loss: 0.1495538
[Epoch 49; Iter   168/  229] train: loss: 0.1207791
[Epoch 49; Iter   198/  229] train: loss: 0.1658303
[Epoch 49; Iter   228/  229] train: loss: 0.1156334
[Epoch 49] ogbg-moltoxcast: 0.673278 val loss: 0.295826
[Epoch 49] ogbg-moltoxcast: 0.649096 test loss: 0.552419
[Epoch 50; Iter    29/  229] train: loss: 0.1385006
[Epoch 50; Iter    59/  229] train: loss: 0.1269136
[Epoch 50; Iter    89/  229] train: loss: 0.1021482
[Epoch 50; Iter   119/  229] train: loss: 0.1392398
[Epoch 50; Iter   149/  229] train: loss: 0.0983688
[Epoch 50; Iter   179/  229] train: loss: 0.1754249
[Epoch 50; Iter   209/  229] train: loss: 0.1190964
[Epoch 50] ogbg-moltoxcast: 0.667631 val loss: 0.293812
[Epoch 50] ogbg-moltoxcast: 0.639077 test loss: 0.480634
[Epoch 51; Iter    10/  229] train: loss: 0.1138802
[Epoch 51; Iter    40/  229] train: loss: 0.1391497
[Epoch 51; Iter    70/  229] train: loss: 0.1358677
[Epoch 51; Iter   100/  229] train: loss: 0.1389863
[Epoch 51; Iter   130/  229] train: loss: 0.1160824
[Epoch 51; Iter   160/  229] train: loss: 0.1154162
[Epoch 51; Iter   190/  229] train: loss: 0.1418315
[Epoch 51; Iter   220/  229] train: loss: 0.0838070
[Epoch 51] ogbg-moltoxcast: 0.672395 val loss: 0.289729
[Epoch 51] ogbg-moltoxcast: 0.631804 test loss: 0.519916
[Epoch 52; Iter    21/  229] train: loss: 0.2039730
[Epoch 52; Iter    51/  229] train: loss: 0.1597477
[Epoch 52; Iter    81/  229] train: loss: 0.1600594
[Epoch 52; Iter   111/  229] train: loss: 0.1276389
[Epoch 52; Iter   141/  229] train: loss: 0.1140712
[Epoch 52; Iter   171/  229] train: loss: 0.1588693
[Epoch 52; Iter   201/  229] train: loss: 0.1362345
[Epoch 52] ogbg-moltoxcast: 0.673895 val loss: 0.302995
[Epoch 52] ogbg-moltoxcast: 0.639234 test loss: 0.881368
[Epoch 53; Iter     2/  229] train: loss: 0.1253171
[Epoch 53; Iter    32/  229] train: loss: 0.1376705
[Epoch 53; Iter    62/  229] train: loss: 0.1400048
[Epoch 53; Iter    92/  229] train: loss: 0.1176870
[Epoch 53; Iter   122/  229] train: loss: 0.1634166
[Epoch 53; Iter   152/  229] train: loss: 0.1491929
[Epoch 53; Iter   182/  229] train: loss: 0.1346362
[Epoch 53; Iter   212/  229] train: loss: 0.1450066
[Epoch 53] ogbg-moltoxcast: 0.673924 val loss: 0.286700
[Epoch 53] ogbg-moltoxcast: 0.636330 test loss: 0.551084
[Epoch 54; Iter    13/  229] train: loss: 0.0897848
[Epoch 54; Iter    43/  229] train: loss: 0.1457304
[Epoch 54; Iter    73/  229] train: loss: 0.1092403
[Epoch 54; Iter   103/  229] train: loss: 0.1530010
[Epoch 54; Iter   133/  229] train: loss: 0.1685920
[Epoch 54; Iter   163/  229] train: loss: 0.1539208
[Epoch 54; Iter   193/  229] train: loss: 0.1974569
[Epoch 54; Iter   223/  229] train: loss: 0.1842553
[Epoch 54] ogbg-moltoxcast: 0.669094 val loss: 0.297265
[Epoch 54] ogbg-moltoxcast: 0.654367 test loss: 0.539370
[Epoch 55; Iter    24/  229] train: loss: 0.1251526
[Epoch 55; Iter    54/  229] train: loss: 0.1889104
[Epoch 55; Iter    84/  229] train: loss: 0.1379599
[Epoch 55; Iter   114/  229] train: loss: 0.1169529
[Epoch 55; Iter   144/  229] train: loss: 0.1203544
[Epoch 55; Iter   174/  229] train: loss: 0.1429393
[Epoch 55; Iter   204/  229] train: loss: 0.1006808
[Epoch 55] ogbg-moltoxcast: 0.664891 val loss: 0.313116
[Epoch 55] ogbg-moltoxcast: 0.650065 test loss: 0.479625
[Epoch 56; Iter     5/  229] train: loss: 0.1268705
[Epoch 56; Iter    35/  229] train: loss: 0.1256891
[Epoch 56; Iter    65/  229] train: loss: 0.1294083
[Epoch 56; Iter    95/  229] train: loss: 0.1193275
[Epoch 56; Iter   125/  229] train: loss: 0.1546207
[Epoch 56; Iter   155/  229] train: loss: 0.1329730
[Epoch 56; Iter   185/  229] train: loss: 0.1184032
[Epoch 56; Iter   215/  229] train: loss: 0.1394722
[Epoch 56] ogbg-moltoxcast: 0.667384 val loss: 0.306707
[Epoch 56] ogbg-moltoxcast: 0.638388 test loss: 0.799677
[Epoch 57; Iter    16/  229] train: loss: 0.1565572
[Epoch 57; Iter    46/  229] train: loss: 0.1399840
[Epoch 57; Iter    76/  229] train: loss: 0.1459731
[Epoch 57; Iter   106/  229] train: loss: 0.1029914
[Epoch 57; Iter   136/  229] train: loss: 0.1279293
[Epoch 57; Iter   166/  229] train: loss: 0.1139537
[Epoch 57; Iter   196/  229] train: loss: 0.1314809
[Epoch 57; Iter   226/  229] train: loss: 0.1540236
[Epoch 57] ogbg-moltoxcast: 0.656759 val loss: 0.298501
[Epoch 57] ogbg-moltoxcast: 0.638528 test loss: 0.524884
[Epoch 58; Iter    27/  229] train: loss: 0.1456045
[Epoch 58; Iter    57/  229] train: loss: 0.1468060
[Epoch 58; Iter    87/  229] train: loss: 0.1262594
[Epoch 58; Iter   117/  229] train: loss: 0.1153328
[Epoch 58; Iter   147/  229] train: loss: 0.1430304
[Epoch 58; Iter   177/  229] train: loss: 0.2072574
[Epoch 58; Iter   207/  229] train: loss: 0.1556367
[Epoch 58] ogbg-moltoxcast: 0.656656 val loss: 0.311232
[Epoch 58] ogbg-moltoxcast: 0.639734 test loss: 0.559380
[Epoch 59; Iter     8/  229] train: loss: 0.1076566
[Epoch 59; Iter    38/  229] train: loss: 0.1499234
[Epoch 59; Iter    68/  229] train: loss: 0.1065099
[Epoch 59; Iter    98/  229] train: loss: 0.1385845
[Epoch 59; Iter   128/  229] train: loss: 0.1615289
[Epoch 59; Iter   158/  229] train: loss: 0.1362632
[Epoch 59; Iter   188/  229] train: loss: 0.1089875
[Epoch 59; Iter   218/  229] train: loss: 0.1526364
[Epoch 59] ogbg-moltoxcast: 0.667080 val loss: 0.321210
[Epoch 59] ogbg-moltoxcast: 0.644912 test loss: 0.573067
[Epoch 44; Iter    23/  229] train: loss: 0.1146119
[Epoch 44; Iter    53/  229] train: loss: 0.1148126
[Epoch 44; Iter    83/  229] train: loss: 0.1290742
[Epoch 44; Iter   113/  229] train: loss: 0.1275878
[Epoch 44; Iter   143/  229] train: loss: 0.1395332
[Epoch 44; Iter   173/  229] train: loss: 0.1181124
[Epoch 44; Iter   203/  229] train: loss: 0.0866292
[Epoch 44] ogbg-moltoxcast: 0.695972 val loss: 0.273702
[Epoch 44] ogbg-moltoxcast: 0.658005 test loss: 0.320747
[Epoch 45; Iter     4/  229] train: loss: 0.1229907
[Epoch 45; Iter    34/  229] train: loss: 0.1565832
[Epoch 45; Iter    64/  229] train: loss: 0.1107565
[Epoch 45; Iter    94/  229] train: loss: 0.1445612
[Epoch 45; Iter   124/  229] train: loss: 0.1944971
[Epoch 45; Iter   154/  229] train: loss: 0.1406344
[Epoch 45; Iter   184/  229] train: loss: 0.1717898
[Epoch 45; Iter   214/  229] train: loss: 0.1285201
[Epoch 45] ogbg-moltoxcast: 0.686922 val loss: 0.271561
[Epoch 45] ogbg-moltoxcast: 0.647521 test loss: 0.326429
[Epoch 46; Iter    15/  229] train: loss: 0.1594451
[Epoch 46; Iter    45/  229] train: loss: 0.1619315
[Epoch 46; Iter    75/  229] train: loss: 0.2022983
[Epoch 46; Iter   105/  229] train: loss: 0.1220407
[Epoch 46; Iter   135/  229] train: loss: 0.1435817
[Epoch 46; Iter   165/  229] train: loss: 0.1098328
[Epoch 46; Iter   195/  229] train: loss: 0.1631781
[Epoch 46; Iter   225/  229] train: loss: 0.1089488
[Epoch 46] ogbg-moltoxcast: 0.687488 val loss: 0.274526
[Epoch 46] ogbg-moltoxcast: 0.649951 test loss: 0.331890
[Epoch 47; Iter    26/  229] train: loss: 0.1197112
[Epoch 47; Iter    56/  229] train: loss: 0.1375551
[Epoch 47; Iter    86/  229] train: loss: 0.1047443
[Epoch 47; Iter   116/  229] train: loss: 0.1411519
[Epoch 47; Iter   146/  229] train: loss: 0.1018185
[Epoch 47; Iter   176/  229] train: loss: 0.1374074
[Epoch 47; Iter   206/  229] train: loss: 0.1385072
[Epoch 47] ogbg-moltoxcast: 0.691978 val loss: 0.276886
[Epoch 47] ogbg-moltoxcast: 0.650842 test loss: 0.326917
[Epoch 48; Iter     7/  229] train: loss: 0.1637589
[Epoch 48; Iter    37/  229] train: loss: 0.1181473
[Epoch 48; Iter    67/  229] train: loss: 0.1648192
[Epoch 48; Iter    97/  229] train: loss: 0.1429565
[Epoch 48; Iter   127/  229] train: loss: 0.1986485
[Epoch 48; Iter   157/  229] train: loss: 0.1444212
[Epoch 48; Iter   187/  229] train: loss: 0.1460540
[Epoch 48; Iter   217/  229] train: loss: 0.0939790
[Epoch 48] ogbg-moltoxcast: 0.689596 val loss: 0.280675
[Epoch 48] ogbg-moltoxcast: 0.651755 test loss: 0.333425
[Epoch 49; Iter    18/  229] train: loss: 0.1222061
[Epoch 49; Iter    48/  229] train: loss: 0.1300905
[Epoch 49; Iter    78/  229] train: loss: 0.1038486
[Epoch 49; Iter   108/  229] train: loss: 0.2013168
[Epoch 49; Iter   138/  229] train: loss: 0.1370566
[Epoch 49; Iter   168/  229] train: loss: 0.1174231
[Epoch 49; Iter   198/  229] train: loss: 0.1622554
[Epoch 49; Iter   228/  229] train: loss: 0.1125887
[Epoch 49] ogbg-moltoxcast: 0.675051 val loss: 0.286975
[Epoch 49] ogbg-moltoxcast: 0.644769 test loss: 0.341895
[Epoch 50; Iter    29/  229] train: loss: 0.1314851
[Epoch 50; Iter    59/  229] train: loss: 0.1135650
[Epoch 50; Iter    89/  229] train: loss: 0.0986328
[Epoch 50; Iter   119/  229] train: loss: 0.1298405
[Epoch 50; Iter   149/  229] train: loss: 0.0957999
[Epoch 50; Iter   179/  229] train: loss: 0.1669708
[Epoch 50; Iter   209/  229] train: loss: 0.1155023
[Epoch 50] ogbg-moltoxcast: 0.680998 val loss: 0.282580
[Epoch 50] ogbg-moltoxcast: 0.653519 test loss: 0.331129
[Epoch 51; Iter    10/  229] train: loss: 0.1078966
[Epoch 51; Iter    40/  229] train: loss: 0.1279646
[Epoch 51; Iter    70/  229] train: loss: 0.1243434
[Epoch 51; Iter   100/  229] train: loss: 0.1280144
[Epoch 51; Iter   130/  229] train: loss: 0.1148378
[Epoch 51; Iter   160/  229] train: loss: 0.1105909
[Epoch 51; Iter   190/  229] train: loss: 0.1396864
[Epoch 51; Iter   220/  229] train: loss: 0.0868887
[Epoch 51] ogbg-moltoxcast: 0.690246 val loss: 0.287429
[Epoch 51] ogbg-moltoxcast: 0.652862 test loss: 0.341777
[Epoch 52; Iter    21/  229] train: loss: 0.1844423
[Epoch 52; Iter    51/  229] train: loss: 0.1492397
[Epoch 52; Iter    81/  229] train: loss: 0.1484453
[Epoch 52; Iter   111/  229] train: loss: 0.1350388
[Epoch 52; Iter   141/  229] train: loss: 0.1122477
[Epoch 52; Iter   171/  229] train: loss: 0.1531454
[Epoch 52; Iter   201/  229] train: loss: 0.1284895
[Epoch 52] ogbg-moltoxcast: 0.678297 val loss: 0.293519
[Epoch 52] ogbg-moltoxcast: 0.650071 test loss: 0.337606
[Epoch 53; Iter     2/  229] train: loss: 0.1193730
[Epoch 53; Iter    32/  229] train: loss: 0.1330571
[Epoch 53; Iter    62/  229] train: loss: 0.1366811
[Epoch 53; Iter    92/  229] train: loss: 0.1085262
[Epoch 53; Iter   122/  229] train: loss: 0.1510702
[Epoch 53; Iter   152/  229] train: loss: 0.1437014
[Epoch 53; Iter   182/  229] train: loss: 0.1297527
[Epoch 53; Iter   212/  229] train: loss: 0.1448207
[Epoch 53] ogbg-moltoxcast: 0.683381 val loss: 0.296005
[Epoch 53] ogbg-moltoxcast: 0.648826 test loss: 0.341252
[Epoch 54; Iter    13/  229] train: loss: 0.0812837
[Epoch 54; Iter    43/  229] train: loss: 0.1402324
[Epoch 54; Iter    73/  229] train: loss: 0.0978311
[Epoch 54; Iter   103/  229] train: loss: 0.1539328
[Epoch 54; Iter   133/  229] train: loss: 0.1664810
[Epoch 54; Iter   163/  229] train: loss: 0.1472943
[Epoch 54; Iter   193/  229] train: loss: 0.1921750
[Epoch 54; Iter   223/  229] train: loss: 0.1702292
[Epoch 54] ogbg-moltoxcast: 0.688886 val loss: 0.290172
[Epoch 54] ogbg-moltoxcast: 0.646634 test loss: 0.336053
[Epoch 55; Iter    24/  229] train: loss: 0.1215798
[Epoch 55; Iter    54/  229] train: loss: 0.1754407
[Epoch 55; Iter    84/  229] train: loss: 0.1410272
[Epoch 55; Iter   114/  229] train: loss: 0.1600625
[Epoch 55; Iter   144/  229] train: loss: 0.1218494
[Epoch 55; Iter   174/  229] train: loss: 0.1486388
[Epoch 55; Iter   204/  229] train: loss: 0.0934813
[Epoch 55] ogbg-moltoxcast: 0.682305 val loss: 0.293891
[Epoch 55] ogbg-moltoxcast: 0.650010 test loss: 0.340815
[Epoch 56; Iter     5/  229] train: loss: 0.1197220
[Epoch 56; Iter    35/  229] train: loss: 0.1219701
[Epoch 56; Iter    65/  229] train: loss: 0.1173041
[Epoch 56; Iter    95/  229] train: loss: 0.1098175
[Epoch 56; Iter   125/  229] train: loss: 0.1518471
[Epoch 56; Iter   155/  229] train: loss: 0.1283124
[Epoch 56; Iter   185/  229] train: loss: 0.1085483
[Epoch 56; Iter   215/  229] train: loss: 0.1427062
[Epoch 56] ogbg-moltoxcast: 0.686110 val loss: 0.286678
[Epoch 56] ogbg-moltoxcast: 0.648662 test loss: 0.337420
[Epoch 57; Iter    16/  229] train: loss: 0.1485457
[Epoch 57; Iter    46/  229] train: loss: 0.1283633
[Epoch 57; Iter    76/  229] train: loss: 0.1424675
[Epoch 57; Iter   106/  229] train: loss: 0.0972280
[Epoch 57; Iter   136/  229] train: loss: 0.1249995
[Epoch 57; Iter   166/  229] train: loss: 0.1152478
[Epoch 57; Iter   196/  229] train: loss: 0.1300483
[Epoch 57; Iter   226/  229] train: loss: 0.1496862
[Epoch 57] ogbg-moltoxcast: 0.680270 val loss: 0.287260
[Epoch 57] ogbg-moltoxcast: 0.651041 test loss: 0.338886
[Epoch 58; Iter    27/  229] train: loss: 0.1409983
[Epoch 58; Iter    57/  229] train: loss: 0.1475677
[Epoch 58; Iter    87/  229] train: loss: 0.1132227
[Epoch 58; Iter   117/  229] train: loss: 0.1101879
[Epoch 58; Iter   147/  229] train: loss: 0.1338108
[Epoch 58; Iter   177/  229] train: loss: 0.1956652
[Epoch 58; Iter   207/  229] train: loss: 0.1484087
[Epoch 58] ogbg-moltoxcast: 0.686757 val loss: 0.286308
[Epoch 58] ogbg-moltoxcast: 0.650035 test loss: 0.338530
[Epoch 59; Iter     8/  229] train: loss: 0.1047599
[Epoch 59; Iter    38/  229] train: loss: 0.1381695
[Epoch 59; Iter    68/  229] train: loss: 0.1090123
[Epoch 59; Iter    98/  229] train: loss: 0.1467457
[Epoch 59; Iter   128/  229] train: loss: 0.1594649
[Epoch 59; Iter   158/  229] train: loss: 0.1241515
[Epoch 59; Iter   188/  229] train: loss: 0.1005383
[Epoch 59; Iter   218/  229] train: loss: 0.1490745
[Epoch 59] ogbg-moltoxcast: 0.682527 val loss: 0.292074
[Epoch 59] ogbg-moltoxcast: 0.650129 test loss: 0.347313
[Epoch 44; Iter    23/  229] train: loss: 0.1121369
[Epoch 44; Iter    53/  229] train: loss: 0.1155210
[Epoch 44; Iter    83/  229] train: loss: 0.1279469
[Epoch 44; Iter   113/  229] train: loss: 0.1280165
[Epoch 44; Iter   143/  229] train: loss: 0.1404194
[Epoch 44; Iter   173/  229] train: loss: 0.1246145
[Epoch 44; Iter   203/  229] train: loss: 0.0824297
[Epoch 44] ogbg-moltoxcast: 0.677883 val loss: 0.289395
[Epoch 44] ogbg-moltoxcast: 0.670337 test loss: 0.323302
[Epoch 45; Iter     4/  229] train: loss: 0.1156805
[Epoch 45; Iter    34/  229] train: loss: 0.1592411
[Epoch 45; Iter    64/  229] train: loss: 0.1045727
[Epoch 45; Iter    94/  229] train: loss: 0.1479792
[Epoch 45; Iter   124/  229] train: loss: 0.1887705
[Epoch 45; Iter   154/  229] train: loss: 0.1382907
[Epoch 45; Iter   184/  229] train: loss: 0.1694627
[Epoch 45; Iter   214/  229] train: loss: 0.1308461
[Epoch 45] ogbg-moltoxcast: 0.670466 val loss: 0.352460
[Epoch 45] ogbg-moltoxcast: 0.662569 test loss: 0.532611
[Epoch 46; Iter    15/  229] train: loss: 0.1567766
[Epoch 46; Iter    45/  229] train: loss: 0.1691494
[Epoch 46; Iter    75/  229] train: loss: 0.1960226
[Epoch 46; Iter   105/  229] train: loss: 0.1202296
[Epoch 46; Iter   135/  229] train: loss: 0.1457876
[Epoch 46; Iter   165/  229] train: loss: 0.1130730
[Epoch 46; Iter   195/  229] train: loss: 0.1496421
[Epoch 46; Iter   225/  229] train: loss: 0.1066756
[Epoch 46] ogbg-moltoxcast: 0.670816 val loss: 0.296640
[Epoch 46] ogbg-moltoxcast: 0.658310 test loss: 0.330070
[Epoch 47; Iter    26/  229] train: loss: 0.1160927
[Epoch 47; Iter    56/  229] train: loss: 0.1391648
[Epoch 47; Iter    86/  229] train: loss: 0.1099562
[Epoch 47; Iter   116/  229] train: loss: 0.1357825
[Epoch 47; Iter   146/  229] train: loss: 0.0926591
[Epoch 47; Iter   176/  229] train: loss: 0.1273160
[Epoch 47; Iter   206/  229] train: loss: 0.1324812
[Epoch 47] ogbg-moltoxcast: 0.676973 val loss: 0.295725
[Epoch 47] ogbg-moltoxcast: 0.662968 test loss: 0.445923
[Epoch 48; Iter     7/  229] train: loss: 0.1678441
[Epoch 48; Iter    37/  229] train: loss: 0.1119461
[Epoch 48; Iter    67/  229] train: loss: 0.1573587
[Epoch 48; Iter    97/  229] train: loss: 0.1474237
[Epoch 48; Iter   127/  229] train: loss: 0.1946217
[Epoch 48; Iter   157/  229] train: loss: 0.1501273
[Epoch 48; Iter   187/  229] train: loss: 0.1421172
[Epoch 48; Iter   217/  229] train: loss: 0.0949364
[Epoch 48] ogbg-moltoxcast: 0.666465 val loss: 0.295775
[Epoch 48] ogbg-moltoxcast: 0.657621 test loss: 0.338351
[Epoch 49; Iter    18/  229] train: loss: 0.1132421
[Epoch 49; Iter    48/  229] train: loss: 0.1224461
[Epoch 49; Iter    78/  229] train: loss: 0.1033914
[Epoch 49; Iter   108/  229] train: loss: 0.2128091
[Epoch 49; Iter   138/  229] train: loss: 0.1412974
[Epoch 49; Iter   168/  229] train: loss: 0.1180292
[Epoch 49; Iter   198/  229] train: loss: 0.1631507
[Epoch 49; Iter   228/  229] train: loss: 0.1079859
[Epoch 49] ogbg-moltoxcast: 0.664708 val loss: 0.306306
[Epoch 49] ogbg-moltoxcast: 0.654625 test loss: 0.347840
[Epoch 50; Iter    29/  229] train: loss: 0.1245465
[Epoch 50; Iter    59/  229] train: loss: 0.1095725
[Epoch 50; Iter    89/  229] train: loss: 0.1039082
[Epoch 50; Iter   119/  229] train: loss: 0.1316227
[Epoch 50; Iter   149/  229] train: loss: 0.0905316
[Epoch 50; Iter   179/  229] train: loss: 0.1653694
[Epoch 50; Iter   209/  229] train: loss: 0.1150269
[Epoch 50] ogbg-moltoxcast: 0.668576 val loss: 0.303062
[Epoch 50] ogbg-moltoxcast: 0.662360 test loss: 0.341204
[Epoch 51; Iter    10/  229] train: loss: 0.1146262
[Epoch 51; Iter    40/  229] train: loss: 0.1425130
[Epoch 51; Iter    70/  229] train: loss: 0.1219954
[Epoch 51; Iter   100/  229] train: loss: 0.1286103
[Epoch 51; Iter   130/  229] train: loss: 0.1157128
[Epoch 51; Iter   160/  229] train: loss: 0.1123196
[Epoch 51; Iter   190/  229] train: loss: 0.1307427
[Epoch 51; Iter   220/  229] train: loss: 0.0752989
[Epoch 51] ogbg-moltoxcast: 0.669107 val loss: 0.296890
[Epoch 51] ogbg-moltoxcast: 0.659788 test loss: 0.341844
[Epoch 52; Iter    21/  229] train: loss: 0.1854133
[Epoch 52; Iter    51/  229] train: loss: 0.1453315
[Epoch 52; Iter    81/  229] train: loss: 0.1469400
[Epoch 52; Iter   111/  229] train: loss: 0.1276686
[Epoch 52; Iter   141/  229] train: loss: 0.1107324
[Epoch 52; Iter   171/  229] train: loss: 0.1540541
[Epoch 52; Iter   201/  229] train: loss: 0.1311270
[Epoch 52] ogbg-moltoxcast: 0.656034 val loss: 0.305361
[Epoch 52] ogbg-moltoxcast: 0.657732 test loss: 0.342018
[Epoch 53; Iter     2/  229] train: loss: 0.1091247
[Epoch 53; Iter    32/  229] train: loss: 0.1314129
[Epoch 53; Iter    62/  229] train: loss: 0.1303949
[Epoch 53; Iter    92/  229] train: loss: 0.1050794
[Epoch 53; Iter   122/  229] train: loss: 0.1600748
[Epoch 53; Iter   152/  229] train: loss: 0.1391438
[Epoch 53; Iter   182/  229] train: loss: 0.1265362
[Epoch 53; Iter   212/  229] train: loss: 0.1474717
[Epoch 53] ogbg-moltoxcast: 0.664444 val loss: 0.304203
[Epoch 53] ogbg-moltoxcast: 0.661242 test loss: 0.345048
[Epoch 54; Iter    13/  229] train: loss: 0.0826582
[Epoch 54; Iter    43/  229] train: loss: 0.1409168
[Epoch 54; Iter    73/  229] train: loss: 0.0978516
[Epoch 54; Iter   103/  229] train: loss: 0.1514734
[Epoch 54; Iter   133/  229] train: loss: 0.1611052
[Epoch 54; Iter   163/  229] train: loss: 0.1417771
[Epoch 54; Iter   193/  229] train: loss: 0.1904332
[Epoch 54; Iter   223/  229] train: loss: 0.1631638
[Epoch 54] ogbg-moltoxcast: 0.672960 val loss: 0.293503
[Epoch 54] ogbg-moltoxcast: 0.667766 test loss: 0.333799
[Epoch 55; Iter    24/  229] train: loss: 0.1188030
[Epoch 55; Iter    54/  229] train: loss: 0.1688838
[Epoch 55; Iter    84/  229] train: loss: 0.1349352
[Epoch 55; Iter   114/  229] train: loss: 0.1067785
[Epoch 55; Iter   144/  229] train: loss: 0.1275014
[Epoch 55; Iter   174/  229] train: loss: 0.1340097
[Epoch 55; Iter   204/  229] train: loss: 0.0873097
[Epoch 55] ogbg-moltoxcast: 0.659201 val loss: 0.305490
[Epoch 55] ogbg-moltoxcast: 0.658433 test loss: 0.344969
[Epoch 56; Iter     5/  229] train: loss: 0.1198794
[Epoch 56; Iter    35/  229] train: loss: 0.1221041
[Epoch 56; Iter    65/  229] train: loss: 0.1165594
[Epoch 56; Iter    95/  229] train: loss: 0.1131831
[Epoch 56; Iter   125/  229] train: loss: 0.1444620
[Epoch 56; Iter   155/  229] train: loss: 0.1254205
[Epoch 56; Iter   185/  229] train: loss: 0.1034983
[Epoch 56; Iter   215/  229] train: loss: 0.1262702
[Epoch 56] ogbg-moltoxcast: 0.676515 val loss: 0.307262
[Epoch 56] ogbg-moltoxcast: 0.665848 test loss: 0.352394
[Epoch 57; Iter    16/  229] train: loss: 0.1407632
[Epoch 57; Iter    46/  229] train: loss: 0.1371292
[Epoch 57; Iter    76/  229] train: loss: 0.1389838
[Epoch 57; Iter   106/  229] train: loss: 0.0912819
[Epoch 57; Iter   136/  229] train: loss: 0.1305699
[Epoch 57; Iter   166/  229] train: loss: 0.1085249
[Epoch 57; Iter   196/  229] train: loss: 0.1248235
[Epoch 57; Iter   226/  229] train: loss: 0.1460466
[Epoch 57] ogbg-moltoxcast: 0.670831 val loss: 0.301699
[Epoch 57] ogbg-moltoxcast: 0.656694 test loss: 0.354616
[Epoch 58; Iter    27/  229] train: loss: 0.1490706
[Epoch 58; Iter    57/  229] train: loss: 0.1477136
[Epoch 58; Iter    87/  229] train: loss: 0.1052848
[Epoch 58; Iter   117/  229] train: loss: 0.1076128
[Epoch 58; Iter   147/  229] train: loss: 0.1379546
[Epoch 58; Iter   177/  229] train: loss: 0.1950490
[Epoch 58; Iter   207/  229] train: loss: 0.1541348
[Epoch 58] ogbg-moltoxcast: 0.673434 val loss: 0.302591
[Epoch 58] ogbg-moltoxcast: 0.663397 test loss: 0.344782
[Epoch 59; Iter     8/  229] train: loss: 0.0997540
[Epoch 59; Iter    38/  229] train: loss: 0.1348424
[Epoch 59; Iter    68/  229] train: loss: 0.0984029
[Epoch 59; Iter    98/  229] train: loss: 0.1294164
[Epoch 59; Iter   128/  229] train: loss: 0.1470142
[Epoch 59; Iter   158/  229] train: loss: 0.1243683
[Epoch 59; Iter   188/  229] train: loss: 0.0964639
[Epoch 59; Iter   218/  229] train: loss: 0.1391460
[Epoch 59] ogbg-moltoxcast: 0.677317 val loss: 0.302360
[Epoch 59] ogbg-moltoxcast: 0.664722 test loss: 0.345605
[Epoch 44; Iter    23/  229] train: loss: 0.1775190
[Epoch 44; Iter    53/  229] train: loss: 0.0854098
[Epoch 44; Iter    83/  229] train: loss: 0.1597106
[Epoch 44; Iter   113/  229] train: loss: 0.0951254
[Epoch 44; Iter   143/  229] train: loss: 0.1429565
[Epoch 44; Iter   173/  229] train: loss: 0.1219737
[Epoch 44; Iter   203/  229] train: loss: 0.1476224
[Epoch 44] ogbg-moltoxcast: 0.670162 val loss: 0.277446
[Epoch 44] ogbg-moltoxcast: 0.645580 test loss: 0.325884
[Epoch 45; Iter     4/  229] train: loss: 0.1290679
[Epoch 45; Iter    34/  229] train: loss: 0.1193539
[Epoch 45; Iter    64/  229] train: loss: 0.1627655
[Epoch 45; Iter    94/  229] train: loss: 0.1202100
[Epoch 45; Iter   124/  229] train: loss: 0.1439795
[Epoch 45; Iter   154/  229] train: loss: 0.1256620
[Epoch 45; Iter   184/  229] train: loss: 0.1513508
[Epoch 45; Iter   214/  229] train: loss: 0.1473892
[Epoch 45] ogbg-moltoxcast: 0.675151 val loss: 0.283761
[Epoch 45] ogbg-moltoxcast: 0.651479 test loss: 0.333875
[Epoch 46; Iter    15/  229] train: loss: 0.1318561
[Epoch 46; Iter    45/  229] train: loss: 0.1515296
[Epoch 46; Iter    75/  229] train: loss: 0.1852208
[Epoch 46; Iter   105/  229] train: loss: 0.1454359
[Epoch 46; Iter   135/  229] train: loss: 0.1477116
[Epoch 46; Iter   165/  229] train: loss: 0.1264856
[Epoch 46; Iter   195/  229] train: loss: 0.1596154
[Epoch 46; Iter   225/  229] train: loss: 0.1563166
[Epoch 46] ogbg-moltoxcast: 0.680065 val loss: 0.287030
[Epoch 46] ogbg-moltoxcast: 0.643050 test loss: 0.362694
[Epoch 47; Iter    26/  229] train: loss: 0.1481677
[Epoch 47; Iter    56/  229] train: loss: 0.1655784
[Epoch 47; Iter    86/  229] train: loss: 0.1212473
[Epoch 47; Iter   116/  229] train: loss: 0.0862660
[Epoch 47; Iter   146/  229] train: loss: 0.1019980
[Epoch 47; Iter   176/  229] train: loss: 0.1539759
[Epoch 47; Iter   206/  229] train: loss: 0.1262047
[Epoch 47] ogbg-moltoxcast: 0.675191 val loss: 0.282674
[Epoch 47] ogbg-moltoxcast: 0.649452 test loss: 0.332947
[Epoch 48; Iter     7/  229] train: loss: 0.1152250
[Epoch 48; Iter    37/  229] train: loss: 0.1183769
[Epoch 48; Iter    67/  229] train: loss: 0.1338525
[Epoch 48; Iter    97/  229] train: loss: 0.1632618
[Epoch 48; Iter   127/  229] train: loss: 0.1624573
[Epoch 48; Iter   157/  229] train: loss: 0.1122815
[Epoch 48; Iter   187/  229] train: loss: 0.1906126
[Epoch 48; Iter   217/  229] train: loss: 0.1300297
[Epoch 48] ogbg-moltoxcast: 0.677525 val loss: 0.279641
[Epoch 48] ogbg-moltoxcast: 0.649698 test loss: 0.335699
[Epoch 49; Iter    18/  229] train: loss: 0.1672702
[Epoch 49; Iter    48/  229] train: loss: 0.1088519
[Epoch 49; Iter    78/  229] train: loss: 0.1841709
[Epoch 49; Iter   108/  229] train: loss: 0.1298355
[Epoch 49; Iter   138/  229] train: loss: 0.1477825
[Epoch 49; Iter   168/  229] train: loss: 0.1183258
[Epoch 49; Iter   198/  229] train: loss: 0.1378074
[Epoch 49; Iter   228/  229] train: loss: 0.1307258
[Epoch 49] ogbg-moltoxcast: 0.688723 val loss: 0.289479
[Epoch 49] ogbg-moltoxcast: 0.653863 test loss: 0.343341
[Epoch 50; Iter    29/  229] train: loss: 0.1577923
[Epoch 50; Iter    59/  229] train: loss: 0.1170689
[Epoch 50; Iter    89/  229] train: loss: 0.1637607
[Epoch 50; Iter   119/  229] train: loss: 0.1134422
[Epoch 50; Iter   149/  229] train: loss: 0.1624657
[Epoch 50; Iter   179/  229] train: loss: 0.1682779
[Epoch 50; Iter   209/  229] train: loss: 0.1902560
[Epoch 50] ogbg-moltoxcast: 0.675861 val loss: 0.285911
[Epoch 50] ogbg-moltoxcast: 0.647332 test loss: 0.340582
[Epoch 51; Iter    10/  229] train: loss: 0.1515977
[Epoch 51; Iter    40/  229] train: loss: 0.0965081
[Epoch 51; Iter    70/  229] train: loss: 0.1509116
[Epoch 51; Iter   100/  229] train: loss: 0.1413817
[Epoch 51; Iter   130/  229] train: loss: 0.1245659
[Epoch 51; Iter   160/  229] train: loss: 0.1074826
[Epoch 51; Iter   190/  229] train: loss: 0.1192778
[Epoch 51; Iter   220/  229] train: loss: 0.1535544
[Epoch 51] ogbg-moltoxcast: 0.682019 val loss: 0.293881
[Epoch 51] ogbg-moltoxcast: 0.654171 test loss: 0.344765
[Epoch 52; Iter    21/  229] train: loss: 0.1353216
[Epoch 52; Iter    51/  229] train: loss: 0.1276571
[Epoch 52; Iter    81/  229] train: loss: 0.1526449
[Epoch 52; Iter   111/  229] train: loss: 0.1156266
[Epoch 52; Iter   141/  229] train: loss: 0.1200271
[Epoch 52; Iter   171/  229] train: loss: 0.0820249
[Epoch 52; Iter   201/  229] train: loss: 0.1278821
[Epoch 52] ogbg-moltoxcast: 0.679020 val loss: 0.287745
[Epoch 52] ogbg-moltoxcast: 0.653287 test loss: 0.339581
[Epoch 53; Iter     2/  229] train: loss: 0.1133557
[Epoch 53; Iter    32/  229] train: loss: 0.0862106
[Epoch 53; Iter    62/  229] train: loss: 0.1246269
[Epoch 53; Iter    92/  229] train: loss: 0.1158704
[Epoch 53; Iter   122/  229] train: loss: 0.1039582
[Epoch 53; Iter   152/  229] train: loss: 0.1493553
[Epoch 53; Iter   182/  229] train: loss: 0.1353391
[Epoch 53; Iter   212/  229] train: loss: 0.1479876
[Epoch 53] ogbg-moltoxcast: 0.676178 val loss: 0.278502
[Epoch 53] ogbg-moltoxcast: 0.650381 test loss: 0.331597
[Epoch 54; Iter    13/  229] train: loss: 0.1002832
[Epoch 54; Iter    43/  229] train: loss: 0.0938756
[Epoch 54; Iter    73/  229] train: loss: 0.1083094
[Epoch 54; Iter   103/  229] train: loss: 0.0925774
[Epoch 54; Iter   133/  229] train: loss: 0.1190529
[Epoch 54; Iter   163/  229] train: loss: 0.1215065
[Epoch 54; Iter   193/  229] train: loss: 0.1638075
[Epoch 54; Iter   223/  229] train: loss: 0.1596453
[Epoch 54] ogbg-moltoxcast: 0.681240 val loss: 0.281191
[Epoch 54] ogbg-moltoxcast: 0.653961 test loss: 0.337692
[Epoch 55; Iter    24/  229] train: loss: 0.1483476
[Epoch 55; Iter    54/  229] train: loss: 0.1596712
[Epoch 55; Iter    84/  229] train: loss: 0.1150373
[Epoch 55; Iter   114/  229] train: loss: 0.1268287
[Epoch 55; Iter   144/  229] train: loss: 0.1322200
[Epoch 55; Iter   174/  229] train: loss: 0.1387958
[Epoch 55; Iter   204/  229] train: loss: 0.1525324
[Epoch 55] ogbg-moltoxcast: 0.675815 val loss: 0.287810
[Epoch 55] ogbg-moltoxcast: 0.652314 test loss: 0.341425
[Epoch 56; Iter     5/  229] train: loss: 0.1391125
[Epoch 56; Iter    35/  229] train: loss: 0.1025481
[Epoch 56; Iter    65/  229] train: loss: 0.1645536
[Epoch 56; Iter    95/  229] train: loss: 0.1329832
[Epoch 56; Iter   125/  229] train: loss: 0.1142488
[Epoch 56; Iter   155/  229] train: loss: 0.1422598
[Epoch 56; Iter   185/  229] train: loss: 0.1527504
[Epoch 56; Iter   215/  229] train: loss: 0.1120668
[Epoch 56] ogbg-moltoxcast: 0.677304 val loss: 0.294454
[Epoch 56] ogbg-moltoxcast: 0.647792 test loss: 0.353751
[Epoch 57; Iter    16/  229] train: loss: 0.1935176
[Epoch 57; Iter    46/  229] train: loss: 0.1362936
[Epoch 57; Iter    76/  229] train: loss: 0.1049711
[Epoch 57; Iter   106/  229] train: loss: 0.1532429
[Epoch 57; Iter   136/  229] train: loss: 0.1074025
[Epoch 57; Iter   166/  229] train: loss: 0.0841108
[Epoch 57; Iter   196/  229] train: loss: 0.1301758
[Epoch 57; Iter   226/  229] train: loss: 0.2030269
[Epoch 57] ogbg-moltoxcast: 0.679619 val loss: 0.296968
[Epoch 57] ogbg-moltoxcast: 0.651859 test loss: 0.344608
[Epoch 58; Iter    27/  229] train: loss: 0.1263934
[Epoch 58; Iter    57/  229] train: loss: 0.1450848
[Epoch 58; Iter    87/  229] train: loss: 0.1435152
[Epoch 58; Iter   117/  229] train: loss: 0.1389040
[Epoch 58; Iter   147/  229] train: loss: 0.1904254
[Epoch 58; Iter   177/  229] train: loss: 0.1936020
[Epoch 58; Iter   207/  229] train: loss: 0.1083968
[Epoch 58] ogbg-moltoxcast: 0.677636 val loss: 0.287511
[Epoch 58] ogbg-moltoxcast: 0.646778 test loss: 0.344696
[Epoch 59; Iter     8/  229] train: loss: 0.1307230
[Epoch 59; Iter    38/  229] train: loss: 0.1033085
[Epoch 59; Iter    68/  229] train: loss: 0.1218225
[Epoch 59; Iter    98/  229] train: loss: 0.1109163
[Epoch 59; Iter   128/  229] train: loss: 0.1184511
[Epoch 59; Iter   158/  229] train: loss: 0.1280341
[Epoch 59; Iter   188/  229] train: loss: 0.1195707
[Epoch 59; Iter   218/  229] train: loss: 0.1181583
[Epoch 59] ogbg-moltoxcast: 0.680639 val loss: 0.282289
[Epoch 59] ogbg-moltoxcast: 0.651283 test loss: 0.333127
[Epoch 44; Iter    23/  229] train: loss: 0.1943896
[Epoch 44; Iter    53/  229] train: loss: 0.0918996
[Epoch 44; Iter    83/  229] train: loss: 0.1309810
[Epoch 44; Iter   113/  229] train: loss: 0.1287149
[Epoch 44; Iter   143/  229] train: loss: 0.1826732
[Epoch 44; Iter   173/  229] train: loss: 0.1571319
[Epoch 44; Iter   203/  229] train: loss: 0.1450734
[Epoch 44] ogbg-moltoxcast: 0.662479 val loss: 0.287379
[Epoch 44] ogbg-moltoxcast: 0.661436 test loss: 0.330486
[Epoch 45; Iter     4/  229] train: loss: 0.1263036
[Epoch 45; Iter    34/  229] train: loss: 0.1260583
[Epoch 45; Iter    64/  229] train: loss: 0.1563216
[Epoch 45; Iter    94/  229] train: loss: 0.0927185
[Epoch 45; Iter   124/  229] train: loss: 0.1526054
[Epoch 45; Iter   154/  229] train: loss: 0.1259296
[Epoch 45; Iter   184/  229] train: loss: 0.1086789
[Epoch 45; Iter   214/  229] train: loss: 0.0878638
[Epoch 45] ogbg-moltoxcast: 0.663358 val loss: 0.293860
[Epoch 45] ogbg-moltoxcast: 0.657588 test loss: 0.334819
[Epoch 46; Iter    15/  229] train: loss: 0.1490771
[Epoch 46; Iter    45/  229] train: loss: 0.1747960
[Epoch 46; Iter    75/  229] train: loss: 0.1349917
[Epoch 46; Iter   105/  229] train: loss: 0.1739430
[Epoch 46; Iter   135/  229] train: loss: 0.1517330
[Epoch 46; Iter   165/  229] train: loss: 0.1393811
[Epoch 46; Iter   195/  229] train: loss: 0.1333664
[Epoch 46; Iter   225/  229] train: loss: 0.1445077
[Epoch 46] ogbg-moltoxcast: 0.672654 val loss: 0.282508
[Epoch 46] ogbg-moltoxcast: 0.660519 test loss: 0.325112
[Epoch 47; Iter    26/  229] train: loss: 0.1603241
[Epoch 47; Iter    56/  229] train: loss: 0.1575897
[Epoch 47; Iter    86/  229] train: loss: 0.1322508
[Epoch 47; Iter   116/  229] train: loss: 0.1213434
[Epoch 47; Iter   146/  229] train: loss: 0.1160415
[Epoch 47; Iter   176/  229] train: loss: 0.1017790
[Epoch 47; Iter   206/  229] train: loss: 0.1267998
[Epoch 47] ogbg-moltoxcast: 0.660433 val loss: 0.299085
[Epoch 47] ogbg-moltoxcast: 0.651762 test loss: 0.340893
[Epoch 48; Iter     7/  229] train: loss: 0.1422585
[Epoch 48; Iter    37/  229] train: loss: 0.1287550
[Epoch 48; Iter    67/  229] train: loss: 0.1262477
[Epoch 48; Iter    97/  229] train: loss: 0.1410040
[Epoch 48; Iter   127/  229] train: loss: 0.1461874
[Epoch 48; Iter   157/  229] train: loss: 0.1079099
[Epoch 48; Iter   187/  229] train: loss: 0.1421033
[Epoch 48; Iter   217/  229] train: loss: 0.1350112
[Epoch 48] ogbg-moltoxcast: 0.666541 val loss: 0.288272
[Epoch 48] ogbg-moltoxcast: 0.666886 test loss: 0.331081
[Epoch 49; Iter    18/  229] train: loss: 0.1573306
[Epoch 49; Iter    48/  229] train: loss: 0.1305384
[Epoch 49; Iter    78/  229] train: loss: 0.0875598
[Epoch 49; Iter   108/  229] train: loss: 0.1242492
[Epoch 49; Iter   138/  229] train: loss: 0.1175595
[Epoch 49; Iter   168/  229] train: loss: 0.1291548
[Epoch 49; Iter   198/  229] train: loss: 0.1290611
[Epoch 49; Iter   228/  229] train: loss: 0.1480415
[Epoch 49] ogbg-moltoxcast: 0.669848 val loss: 0.295267
[Epoch 49] ogbg-moltoxcast: 0.657443 test loss: 0.338642
[Epoch 50; Iter    29/  229] train: loss: 0.1148146
[Epoch 50; Iter    59/  229] train: loss: 0.1477481
[Epoch 50; Iter    89/  229] train: loss: 0.0866953
[Epoch 50; Iter   119/  229] train: loss: 0.1699933
[Epoch 50; Iter   149/  229] train: loss: 0.1267949
[Epoch 50; Iter   179/  229] train: loss: 0.1456269
[Epoch 50; Iter   209/  229] train: loss: 0.1032043
[Epoch 50] ogbg-moltoxcast: 0.671788 val loss: 0.288658
[Epoch 50] ogbg-moltoxcast: 0.647814 test loss: 0.338750
[Epoch 51; Iter    10/  229] train: loss: 0.1565694
[Epoch 51; Iter    40/  229] train: loss: 0.1026971
[Epoch 51; Iter    70/  229] train: loss: 0.1421032
[Epoch 51; Iter   100/  229] train: loss: 0.1471258
[Epoch 51; Iter   130/  229] train: loss: 0.1029458
[Epoch 51; Iter   160/  229] train: loss: 0.1102963
[Epoch 51; Iter   190/  229] train: loss: 0.1326911
[Epoch 51; Iter   220/  229] train: loss: 0.1637340
[Epoch 51] ogbg-moltoxcast: 0.663597 val loss: 0.295554
[Epoch 51] ogbg-moltoxcast: 0.661635 test loss: 0.338385
[Epoch 52; Iter    21/  229] train: loss: 0.1129678
[Epoch 52; Iter    51/  229] train: loss: 0.1480240
[Epoch 52; Iter    81/  229] train: loss: 0.1276766
[Epoch 52; Iter   111/  229] train: loss: 0.1850156
[Epoch 52; Iter   141/  229] train: loss: 0.1368578
[Epoch 52; Iter   171/  229] train: loss: 0.1517353
[Epoch 52; Iter   201/  229] train: loss: 0.1283627
[Epoch 52] ogbg-moltoxcast: 0.666645 val loss: 0.301448
[Epoch 52] ogbg-moltoxcast: 0.662704 test loss: 0.333317
[Epoch 53; Iter     2/  229] train: loss: 0.0895970
[Epoch 53; Iter    32/  229] train: loss: 0.1190432
[Epoch 53; Iter    62/  229] train: loss: 0.1391042
[Epoch 53; Iter    92/  229] train: loss: 0.1626153
[Epoch 53; Iter   122/  229] train: loss: 0.0818162
[Epoch 53; Iter   152/  229] train: loss: 0.1124884
[Epoch 53; Iter   182/  229] train: loss: 0.1239561
[Epoch 53; Iter   212/  229] train: loss: 0.1455801
[Epoch 53] ogbg-moltoxcast: 0.670317 val loss: 0.288026
[Epoch 53] ogbg-moltoxcast: 0.655522 test loss: 0.324190
[Epoch 54; Iter    13/  229] train: loss: 0.0845939
[Epoch 54; Iter    43/  229] train: loss: 0.1403570
[Epoch 54; Iter    73/  229] train: loss: 0.1153472
[Epoch 54; Iter   103/  229] train: loss: 0.1253014
[Epoch 54; Iter   133/  229] train: loss: 0.1344310
[Epoch 54; Iter   163/  229] train: loss: 0.1541118
[Epoch 54; Iter   193/  229] train: loss: 0.1468700
[Epoch 54; Iter   223/  229] train: loss: 0.1630707
[Epoch 54] ogbg-moltoxcast: 0.664385 val loss: 0.304688
[Epoch 54] ogbg-moltoxcast: 0.661929 test loss: 0.341770
[Epoch 55; Iter    24/  229] train: loss: 0.1706341
[Epoch 55; Iter    54/  229] train: loss: 0.1733277
[Epoch 55; Iter    84/  229] train: loss: 0.0982534
[Epoch 55; Iter   114/  229] train: loss: 0.1631439
[Epoch 55; Iter   144/  229] train: loss: 0.1429021
[Epoch 55; Iter   174/  229] train: loss: 0.1678861
[Epoch 55; Iter   204/  229] train: loss: 0.1029381
[Epoch 55] ogbg-moltoxcast: 0.668065 val loss: 0.287595
[Epoch 55] ogbg-moltoxcast: 0.647880 test loss: 0.335098
[Epoch 56; Iter     5/  229] train: loss: 0.1074943
[Epoch 56; Iter    35/  229] train: loss: 0.1297418
[Epoch 56; Iter    65/  229] train: loss: 0.1168766
[Epoch 56; Iter    95/  229] train: loss: 0.1393089
[Epoch 56; Iter   125/  229] train: loss: 0.0953993
[Epoch 56; Iter   155/  229] train: loss: 0.1020595
[Epoch 56; Iter   185/  229] train: loss: 0.1372575
[Epoch 56; Iter   215/  229] train: loss: 0.1318079
[Epoch 56] ogbg-moltoxcast: 0.673000 val loss: 0.290790
[Epoch 56] ogbg-moltoxcast: 0.655217 test loss: 0.337544
[Epoch 57; Iter    16/  229] train: loss: 0.1046283
[Epoch 57; Iter    46/  229] train: loss: 0.1183863
[Epoch 57; Iter    76/  229] train: loss: 0.1776310
[Epoch 57; Iter   106/  229] train: loss: 0.1484300
[Epoch 57; Iter   136/  229] train: loss: 0.1378734
[Epoch 57; Iter   166/  229] train: loss: 0.0957908
[Epoch 57; Iter   196/  229] train: loss: 0.1553161
[Epoch 57; Iter   226/  229] train: loss: 0.1845544
[Epoch 57] ogbg-moltoxcast: 0.670838 val loss: 0.288496
[Epoch 57] ogbg-moltoxcast: 0.650613 test loss: 0.338048
[Epoch 58; Iter    27/  229] train: loss: 0.1063122
[Epoch 58; Iter    57/  229] train: loss: 0.1001279
[Epoch 58; Iter    87/  229] train: loss: 0.1155635
[Epoch 58; Iter   117/  229] train: loss: 0.0976725
[Epoch 58; Iter   147/  229] train: loss: 0.1153164
[Epoch 58; Iter   177/  229] train: loss: 0.1612619
[Epoch 58; Iter   207/  229] train: loss: 0.1105068
[Epoch 58] ogbg-moltoxcast: 0.673842 val loss: 0.286086
[Epoch 58] ogbg-moltoxcast: 0.653564 test loss: 0.334488
[Epoch 59; Iter     8/  229] train: loss: 0.1098348
[Epoch 59; Iter    38/  229] train: loss: 0.1228858
[Epoch 59; Iter    68/  229] train: loss: 0.1168456
[Epoch 59; Iter    98/  229] train: loss: 0.1620133
[Epoch 59; Iter   128/  229] train: loss: 0.1516306
[Epoch 59; Iter   158/  229] train: loss: 0.1046527
[Epoch 59; Iter   188/  229] train: loss: 0.1105620
[Epoch 59; Iter   218/  229] train: loss: 0.1134345
[Epoch 59] ogbg-moltoxcast: 0.658843 val loss: 0.304773
[Epoch 59] ogbg-moltoxcast: 0.651341 test loss: 0.344025
[Epoch 44; Iter    23/  229] train: loss: 0.2004798
[Epoch 44; Iter    53/  229] train: loss: 0.0968832
[Epoch 44; Iter    83/  229] train: loss: 0.1364044
[Epoch 44; Iter   113/  229] train: loss: 0.1342423
[Epoch 44; Iter   143/  229] train: loss: 0.1896646
[Epoch 44; Iter   173/  229] train: loss: 0.1746519
[Epoch 44; Iter   203/  229] train: loss: 0.1395761
[Epoch 44] ogbg-moltoxcast: 0.634618 val loss: 0.314083
[Epoch 44] ogbg-moltoxcast: 0.644514 test loss: 1.444339
[Epoch 45; Iter     4/  229] train: loss: 0.1194181
[Epoch 45; Iter    34/  229] train: loss: 0.1318282
[Epoch 45; Iter    64/  229] train: loss: 0.1625183
[Epoch 45; Iter    94/  229] train: loss: 0.0940597
[Epoch 45; Iter   124/  229] train: loss: 0.1439386
[Epoch 45; Iter   154/  229] train: loss: 0.1156079
[Epoch 45; Iter   184/  229] train: loss: 0.1163771
[Epoch 45; Iter   214/  229] train: loss: 0.0918790
[Epoch 45] ogbg-moltoxcast: 0.642619 val loss: 0.331808
[Epoch 45] ogbg-moltoxcast: 0.641831 test loss: 1.748580
[Epoch 46; Iter    15/  229] train: loss: 0.1812072
[Epoch 46; Iter    45/  229] train: loss: 0.1814130
[Epoch 46; Iter    75/  229] train: loss: 0.1382138
[Epoch 46; Iter   105/  229] train: loss: 0.1795268
[Epoch 46; Iter   135/  229] train: loss: 0.1478873
[Epoch 46; Iter   165/  229] train: loss: 0.1394341
[Epoch 46; Iter   195/  229] train: loss: 0.1385166
[Epoch 46; Iter   225/  229] train: loss: 0.1518459
[Epoch 46] ogbg-moltoxcast: 0.627762 val loss: 0.341182
[Epoch 46] ogbg-moltoxcast: 0.633266 test loss: 0.441384
[Epoch 47; Iter    26/  229] train: loss: 0.1687329
[Epoch 47; Iter    56/  229] train: loss: 0.1626195
[Epoch 47; Iter    86/  229] train: loss: 0.1398973
[Epoch 47; Iter   116/  229] train: loss: 0.1390037
[Epoch 47; Iter   146/  229] train: loss: 0.1277594
[Epoch 47; Iter   176/  229] train: loss: 0.1019992
[Epoch 47; Iter   206/  229] train: loss: 0.1234835
[Epoch 47] ogbg-moltoxcast: 0.650482 val loss: 0.333944
[Epoch 47] ogbg-moltoxcast: 0.641283 test loss: 1.422097
[Epoch 48; Iter     7/  229] train: loss: 0.1484322
[Epoch 48; Iter    37/  229] train: loss: 0.1369998
[Epoch 48; Iter    67/  229] train: loss: 0.1263482
[Epoch 48; Iter    97/  229] train: loss: 0.1453005
[Epoch 48; Iter   127/  229] train: loss: 0.1387269
[Epoch 48; Iter   157/  229] train: loss: 0.1043886
[Epoch 48; Iter   187/  229] train: loss: 0.1529985
[Epoch 48; Iter   217/  229] train: loss: 0.1453486
[Epoch 48] ogbg-moltoxcast: 0.631767 val loss: 0.329235
[Epoch 48] ogbg-moltoxcast: 0.643478 test loss: 1.449099
[Epoch 49; Iter    18/  229] train: loss: 0.1562522
[Epoch 49; Iter    48/  229] train: loss: 0.1359953
[Epoch 49; Iter    78/  229] train: loss: 0.0892999
[Epoch 49; Iter   108/  229] train: loss: 0.1319516
[Epoch 49; Iter   138/  229] train: loss: 0.1165358
[Epoch 49; Iter   168/  229] train: loss: 0.1318999
[Epoch 49; Iter   198/  229] train: loss: 0.1399947
[Epoch 49; Iter   228/  229] train: loss: 0.1410841
[Epoch 49] ogbg-moltoxcast: 0.644216 val loss: 0.314227
[Epoch 49] ogbg-moltoxcast: 0.638847 test loss: 0.461997
[Epoch 50; Iter    29/  229] train: loss: 0.1116371
[Epoch 50; Iter    59/  229] train: loss: 0.1468367
[Epoch 50; Iter    89/  229] train: loss: 0.0892010
[Epoch 50; Iter   119/  229] train: loss: 0.1875327
[Epoch 50; Iter   149/  229] train: loss: 0.1318039
[Epoch 50; Iter   179/  229] train: loss: 0.1425728
[Epoch 50; Iter   209/  229] train: loss: 0.1128704
[Epoch 50] ogbg-moltoxcast: 0.634579 val loss: 0.311848
[Epoch 50] ogbg-moltoxcast: 0.640540 test loss: 1.330334
[Epoch 51; Iter    10/  229] train: loss: 0.1520378
[Epoch 51; Iter    40/  229] train: loss: 0.1028516
[Epoch 51; Iter    70/  229] train: loss: 0.1450637
[Epoch 51; Iter   100/  229] train: loss: 0.1513868
[Epoch 51; Iter   130/  229] train: loss: 0.1132725
[Epoch 51; Iter   160/  229] train: loss: 0.1181973
[Epoch 51; Iter   190/  229] train: loss: 0.1384939
[Epoch 51; Iter   220/  229] train: loss: 0.1695300
[Epoch 51] ogbg-moltoxcast: 0.636360 val loss: 0.323929
[Epoch 51] ogbg-moltoxcast: 0.634700 test loss: 2.665805
[Epoch 52; Iter    21/  229] train: loss: 0.1151995
[Epoch 52; Iter    51/  229] train: loss: 0.1410838
[Epoch 52; Iter    81/  229] train: loss: 0.1216480
[Epoch 52; Iter   111/  229] train: loss: 0.1839968
[Epoch 52; Iter   141/  229] train: loss: 0.1438595
[Epoch 52; Iter   171/  229] train: loss: 0.1514080
[Epoch 52; Iter   201/  229] train: loss: 0.1222280
[Epoch 52] ogbg-moltoxcast: 0.643656 val loss: 0.346793
[Epoch 52] ogbg-moltoxcast: 0.638444 test loss: 1.102294
[Epoch 53; Iter     2/  229] train: loss: 0.0940729
[Epoch 53; Iter    32/  229] train: loss: 0.1254743
[Epoch 53; Iter    62/  229] train: loss: 0.1425789
[Epoch 53; Iter    92/  229] train: loss: 0.1581962
[Epoch 53; Iter   122/  229] train: loss: 0.0883411
[Epoch 53; Iter   152/  229] train: loss: 0.1147676
[Epoch 53; Iter   182/  229] train: loss: 0.1238246
[Epoch 53; Iter   212/  229] train: loss: 0.1406717
[Epoch 53] ogbg-moltoxcast: 0.636352 val loss: 0.316848
[Epoch 53] ogbg-moltoxcast: 0.638820 test loss: 1.183576
[Epoch 54; Iter    13/  229] train: loss: 0.0839984
[Epoch 54; Iter    43/  229] train: loss: 0.1436775
[Epoch 54; Iter    73/  229] train: loss: 0.1261531
[Epoch 54; Iter   103/  229] train: loss: 0.1451837
[Epoch 54; Iter   133/  229] train: loss: 0.1254087
[Epoch 54; Iter   163/  229] train: loss: 0.1592024
[Epoch 54; Iter   193/  229] train: loss: 0.1570121
[Epoch 54; Iter   223/  229] train: loss: 0.1810143
[Epoch 54] ogbg-moltoxcast: 0.640041 val loss: 0.337299
[Epoch 54] ogbg-moltoxcast: 0.641099 test loss: 0.369780
[Epoch 55; Iter    24/  229] train: loss: 0.1739789
[Epoch 55; Iter    54/  229] train: loss: 0.1768484
[Epoch 55; Iter    84/  229] train: loss: 0.0989027
[Epoch 55; Iter   114/  229] train: loss: 0.1615146
[Epoch 55; Iter   144/  229] train: loss: 0.1457563
[Epoch 55; Iter   174/  229] train: loss: 0.1634171
[Epoch 55; Iter   204/  229] train: loss: 0.1065786
[Epoch 55] ogbg-moltoxcast: 0.642745 val loss: 0.334911
[Epoch 55] ogbg-moltoxcast: 0.644501 test loss: 0.912584
[Epoch 56; Iter     5/  229] train: loss: 0.1041380
[Epoch 56; Iter    35/  229] train: loss: 0.1394587
[Epoch 56; Iter    65/  229] train: loss: 0.1166033
[Epoch 56; Iter    95/  229] train: loss: 0.1404008
[Epoch 56; Iter   125/  229] train: loss: 0.0974646
[Epoch 56; Iter   155/  229] train: loss: 0.1078732
[Epoch 56; Iter   185/  229] train: loss: 0.1340499
[Epoch 56; Iter   215/  229] train: loss: 0.1361420
[Epoch 56] ogbg-moltoxcast: 0.642643 val loss: 0.361147
[Epoch 56] ogbg-moltoxcast: 0.642115 test loss: 0.454822
[Epoch 57; Iter    16/  229] train: loss: 0.1155574
[Epoch 57; Iter    46/  229] train: loss: 0.1167950
[Epoch 57; Iter    76/  229] train: loss: 0.1775521
[Epoch 57; Iter   106/  229] train: loss: 0.1592737
[Epoch 57; Iter   136/  229] train: loss: 0.1263938
[Epoch 57; Iter   166/  229] train: loss: 0.0983093
[Epoch 57; Iter   196/  229] train: loss: 0.1511190
[Epoch 57; Iter   226/  229] train: loss: 0.1875930
[Epoch 57] ogbg-moltoxcast: 0.642609 val loss: 0.327771
[Epoch 57] ogbg-moltoxcast: 0.637222 test loss: 0.708295
[Epoch 58; Iter    27/  229] train: loss: 0.1062335
[Epoch 58; Iter    57/  229] train: loss: 0.0975267
[Epoch 58; Iter    87/  229] train: loss: 0.1144608
[Epoch 58; Iter   117/  229] train: loss: 0.1018984
[Epoch 58; Iter   147/  229] train: loss: 0.1180340
[Epoch 58; Iter   177/  229] train: loss: 0.1634190
[Epoch 58; Iter   207/  229] train: loss: 0.1205963
[Epoch 58] ogbg-moltoxcast: 0.638115 val loss: 0.330263
[Epoch 58] ogbg-moltoxcast: 0.633475 test loss: 0.930566
[Epoch 59; Iter     8/  229] train: loss: 0.1142022
[Epoch 59; Iter    38/  229] train: loss: 0.1222962
[Epoch 59; Iter    68/  229] train: loss: 0.1098767
[Epoch 59; Iter    98/  229] train: loss: 0.1592746
[Epoch 59; Iter   128/  229] train: loss: 0.1588014
[Epoch 59; Iter   158/  229] train: loss: 0.1018755
[Epoch 59; Iter   188/  229] train: loss: 0.1212764
[Epoch 59; Iter   218/  229] train: loss: 0.1161389
[Epoch 59] ogbg-moltoxcast: 0.637406 val loss: 0.341085
[Epoch 59] ogbg-moltoxcast: 0.637488 test loss: 0.537008
[Epoch 44; Iter    23/  229] train: loss: 0.1782200
[Epoch 44; Iter    53/  229] train: loss: 0.0859760
[Epoch 44; Iter    83/  229] train: loss: 0.1464431
[Epoch 44; Iter   113/  229] train: loss: 0.0964963
[Epoch 44; Iter   143/  229] train: loss: 0.1422430
[Epoch 44; Iter   173/  229] train: loss: 0.1210059
[Epoch 44; Iter   203/  229] train: loss: 0.1437735
[Epoch 44] ogbg-moltoxcast: 0.655112 val loss: 0.317395
[Epoch 44] ogbg-moltoxcast: 0.627904 test loss: 0.372539
[Epoch 45; Iter     4/  229] train: loss: 0.1215673
[Epoch 45; Iter    34/  229] train: loss: 0.1253520
[Epoch 45; Iter    64/  229] train: loss: 0.1607973
[Epoch 45; Iter    94/  229] train: loss: 0.1154955
[Epoch 45; Iter   124/  229] train: loss: 0.1504046
[Epoch 45; Iter   154/  229] train: loss: 0.1244089
[Epoch 45; Iter   184/  229] train: loss: 0.1524018
[Epoch 45; Iter   214/  229] train: loss: 0.1503588
[Epoch 45] ogbg-moltoxcast: 0.654617 val loss: 0.304628
[Epoch 45] ogbg-moltoxcast: 0.630469 test loss: 0.352013
[Epoch 46; Iter    15/  229] train: loss: 0.1365077
[Epoch 46; Iter    45/  229] train: loss: 0.1627825
[Epoch 46; Iter    75/  229] train: loss: 0.1812842
[Epoch 46; Iter   105/  229] train: loss: 0.1522628
[Epoch 46; Iter   135/  229] train: loss: 0.1481789
[Epoch 46; Iter   165/  229] train: loss: 0.1331376
[Epoch 46; Iter   195/  229] train: loss: 0.1511867
[Epoch 46; Iter   225/  229] train: loss: 0.1630616
[Epoch 46] ogbg-moltoxcast: 0.648864 val loss: 0.306782
[Epoch 46] ogbg-moltoxcast: 0.629281 test loss: 0.353790
[Epoch 47; Iter    26/  229] train: loss: 0.1510975
[Epoch 47; Iter    56/  229] train: loss: 0.1569012
[Epoch 47; Iter    86/  229] train: loss: 0.1240683
[Epoch 47; Iter   116/  229] train: loss: 0.0810884
[Epoch 47; Iter   146/  229] train: loss: 0.1057474
[Epoch 47; Iter   176/  229] train: loss: 0.1544770
[Epoch 47; Iter   206/  229] train: loss: 0.1248915
[Epoch 47] ogbg-moltoxcast: 0.655489 val loss: 0.305779
[Epoch 47] ogbg-moltoxcast: 0.634734 test loss: 0.348578
[Epoch 48; Iter     7/  229] train: loss: 0.1134453
[Epoch 48; Iter    37/  229] train: loss: 0.1148403
[Epoch 48; Iter    67/  229] train: loss: 0.1364098
[Epoch 48; Iter    97/  229] train: loss: 0.1560515
[Epoch 48; Iter   127/  229] train: loss: 0.1574307
[Epoch 48; Iter   157/  229] train: loss: 0.1116190
[Epoch 48; Iter   187/  229] train: loss: 0.1832442
[Epoch 48; Iter   217/  229] train: loss: 0.1354955
[Epoch 48] ogbg-moltoxcast: 0.648673 val loss: 0.314945
[Epoch 48] ogbg-moltoxcast: 0.626937 test loss: 0.359097
[Epoch 49; Iter    18/  229] train: loss: 0.1754839
[Epoch 49; Iter    48/  229] train: loss: 0.1105356
[Epoch 49; Iter    78/  229] train: loss: 0.1934508
[Epoch 49; Iter   108/  229] train: loss: 0.1298223
[Epoch 49; Iter   138/  229] train: loss: 0.1466147
[Epoch 49; Iter   168/  229] train: loss: 0.1318373
[Epoch 49; Iter   198/  229] train: loss: 0.1399190
[Epoch 49; Iter   228/  229] train: loss: 0.1398997
[Epoch 49] ogbg-moltoxcast: 0.650010 val loss: 0.303237
[Epoch 49] ogbg-moltoxcast: 0.631361 test loss: 0.348852
[Epoch 50; Iter    29/  229] train: loss: 0.1536976
[Epoch 50; Iter    59/  229] train: loss: 0.1216977
[Epoch 50; Iter    89/  229] train: loss: 0.1580868
[Epoch 50; Iter   119/  229] train: loss: 0.1115253
[Epoch 50; Iter   149/  229] train: loss: 0.1619651
[Epoch 50; Iter   179/  229] train: loss: 0.1676533
[Epoch 50; Iter   209/  229] train: loss: 0.1882179
[Epoch 50] ogbg-moltoxcast: 0.650461 val loss: 0.309019
[Epoch 50] ogbg-moltoxcast: 0.628643 test loss: 0.362051
[Epoch 51; Iter    10/  229] train: loss: 0.1467382
[Epoch 51; Iter    40/  229] train: loss: 0.1005699
[Epoch 51; Iter    70/  229] train: loss: 0.1534630
[Epoch 51; Iter   100/  229] train: loss: 0.1392071
[Epoch 51; Iter   130/  229] train: loss: 0.1253923
[Epoch 51; Iter   160/  229] train: loss: 0.1219324
[Epoch 51; Iter   190/  229] train: loss: 0.1124140
[Epoch 51; Iter   220/  229] train: loss: 0.1574043
[Epoch 51] ogbg-moltoxcast: 0.658498 val loss: 0.313500
[Epoch 51] ogbg-moltoxcast: 0.632949 test loss: 0.366034
[Epoch 52; Iter    21/  229] train: loss: 0.1501731
[Epoch 52; Iter    51/  229] train: loss: 0.1196667
[Epoch 52; Iter    81/  229] train: loss: 0.1444304
[Epoch 52; Iter   111/  229] train: loss: 0.1146747
[Epoch 52; Iter   141/  229] train: loss: 0.1170880
[Epoch 52; Iter   171/  229] train: loss: 0.0847097
[Epoch 52; Iter   201/  229] train: loss: 0.1187089
[Epoch 52] ogbg-moltoxcast: 0.641875 val loss: 0.321152
[Epoch 52] ogbg-moltoxcast: 0.622465 test loss: 0.373025
[Epoch 53; Iter     2/  229] train: loss: 0.1073554
[Epoch 53; Iter    32/  229] train: loss: 0.0925935
[Epoch 53; Iter    62/  229] train: loss: 0.1242997
[Epoch 53; Iter    92/  229] train: loss: 0.1125284
[Epoch 53; Iter   122/  229] train: loss: 0.1008166
[Epoch 53; Iter   152/  229] train: loss: 0.1484917
[Epoch 53; Iter   182/  229] train: loss: 0.1337062
[Epoch 53; Iter   212/  229] train: loss: 0.1442202
[Epoch 53] ogbg-moltoxcast: 0.647768 val loss: 0.313619
[Epoch 53] ogbg-moltoxcast: 0.630996 test loss: 0.368578
[Epoch 54; Iter    13/  229] train: loss: 0.0900748
[Epoch 54; Iter    43/  229] train: loss: 0.0981393
[Epoch 54; Iter    73/  229] train: loss: 0.1084531
[Epoch 54; Iter   103/  229] train: loss: 0.1009608
[Epoch 54; Iter   133/  229] train: loss: 0.1215870
[Epoch 54; Iter   163/  229] train: loss: 0.1269109
[Epoch 54; Iter   193/  229] train: loss: 0.1528065
[Epoch 54; Iter   223/  229] train: loss: 0.1588161
[Epoch 54] ogbg-moltoxcast: 0.653746 val loss: 0.308131
[Epoch 54] ogbg-moltoxcast: 0.628256 test loss: 0.361962
[Epoch 55; Iter    24/  229] train: loss: 0.1525838
[Epoch 55; Iter    54/  229] train: loss: 0.1552107
[Epoch 55; Iter    84/  229] train: loss: 0.1196010
[Epoch 55; Iter   114/  229] train: loss: 0.1265842
[Epoch 55; Iter   144/  229] train: loss: 0.1340232
[Epoch 55; Iter   174/  229] train: loss: 0.1327977
[Epoch 55; Iter   204/  229] train: loss: 0.1504086
[Epoch 55] ogbg-moltoxcast: 0.656749 val loss: 0.303369
[Epoch 55] ogbg-moltoxcast: 0.633958 test loss: 0.350688
[Epoch 56; Iter     5/  229] train: loss: 0.1417426
[Epoch 56; Iter    35/  229] train: loss: 0.1035860
[Epoch 56; Iter    65/  229] train: loss: 0.1740803
[Epoch 56; Iter    95/  229] train: loss: 0.1327044
[Epoch 56; Iter   125/  229] train: loss: 0.1182901
[Epoch 56; Iter   155/  229] train: loss: 0.1305013
[Epoch 56; Iter   185/  229] train: loss: 0.1543705
[Epoch 56; Iter   215/  229] train: loss: 0.1092840
[Epoch 56] ogbg-moltoxcast: 0.664560 val loss: 0.300984
[Epoch 56] ogbg-moltoxcast: 0.629296 test loss: 0.356414
[Epoch 57; Iter    16/  229] train: loss: 0.1920228
[Epoch 57; Iter    46/  229] train: loss: 0.1348166
[Epoch 57; Iter    76/  229] train: loss: 0.1037833
[Epoch 57; Iter   106/  229] train: loss: 0.1410676
[Epoch 57; Iter   136/  229] train: loss: 0.1130053
[Epoch 57; Iter   166/  229] train: loss: 0.0894649
[Epoch 57; Iter   196/  229] train: loss: 0.1321530
[Epoch 57; Iter   226/  229] train: loss: 0.2035634
[Epoch 57] ogbg-moltoxcast: 0.654152 val loss: 0.316719
[Epoch 57] ogbg-moltoxcast: 0.633280 test loss: 0.368096
[Epoch 58; Iter    27/  229] train: loss: 0.1309267
[Epoch 58; Iter    57/  229] train: loss: 0.1453815
[Epoch 58; Iter    87/  229] train: loss: 0.1316005
[Epoch 58; Iter   117/  229] train: loss: 0.1460139
[Epoch 58; Iter   147/  229] train: loss: 0.1783292
[Epoch 58; Iter   177/  229] train: loss: 0.1857132
[Epoch 58; Iter   207/  229] train: loss: 0.1234109
[Epoch 58] ogbg-moltoxcast: 0.648111 val loss: 0.304699
[Epoch 58] ogbg-moltoxcast: 0.620715 test loss: 0.353790
[Epoch 59; Iter     8/  229] train: loss: 0.1319253
[Epoch 59; Iter    38/  229] train: loss: 0.1054176
[Epoch 59; Iter    68/  229] train: loss: 0.1157584
[Epoch 59; Iter    98/  229] train: loss: 0.1143149
[Epoch 59; Iter   128/  229] train: loss: 0.1221494
[Epoch 59; Iter   158/  229] train: loss: 0.1270587
[Epoch 59; Iter   188/  229] train: loss: 0.1089452
[Epoch 59; Iter   218/  229] train: loss: 0.1229485
[Epoch 59] ogbg-moltoxcast: 0.638198 val loss: 0.313597
[Epoch 59] ogbg-moltoxcast: 0.615376 test loss: 0.361181
[Epoch 44; Iter    23/  229] train: loss: 0.1123303
[Epoch 44; Iter    53/  229] train: loss: 0.1210035
[Epoch 44; Iter    83/  229] train: loss: 0.1259242
[Epoch 44; Iter   113/  229] train: loss: 0.1270293
[Epoch 44; Iter   143/  229] train: loss: 0.1420903
[Epoch 44; Iter   173/  229] train: loss: 0.1375053
[Epoch 44; Iter   203/  229] train: loss: 0.0878360
[Epoch 44] ogbg-moltoxcast: 0.705429 val loss: 0.252700
[Epoch 44] ogbg-moltoxcast: 0.673082 test loss: 0.502259
[Epoch 45; Iter     4/  229] train: loss: 0.1218942
[Epoch 45; Iter    34/  229] train: loss: 0.1589136
[Epoch 45; Iter    64/  229] train: loss: 0.1072425
[Epoch 45; Iter    94/  229] train: loss: 0.1660531
[Epoch 45; Iter   124/  229] train: loss: 0.2057233
[Epoch 45; Iter   154/  229] train: loss: 0.1425097
[Epoch 45; Iter   184/  229] train: loss: 0.1825354
[Epoch 45; Iter   214/  229] train: loss: 0.1353815
[Epoch 45] ogbg-moltoxcast: 0.703304 val loss: 0.253786
[Epoch 45] ogbg-moltoxcast: 0.664219 test loss: 0.458941
[Epoch 46; Iter    15/  229] train: loss: 0.1650475
[Epoch 46; Iter    45/  229] train: loss: 0.1751006
[Epoch 46; Iter    75/  229] train: loss: 0.1950061
[Epoch 46; Iter   105/  229] train: loss: 0.1269898
[Epoch 46; Iter   135/  229] train: loss: 0.1541665
[Epoch 46; Iter   165/  229] train: loss: 0.1083480
[Epoch 46; Iter   195/  229] train: loss: 0.1606539
[Epoch 46; Iter   225/  229] train: loss: 0.1175481
[Epoch 46] ogbg-moltoxcast: 0.696982 val loss: 0.259385
[Epoch 46] ogbg-moltoxcast: 0.669326 test loss: 0.484177
[Epoch 47; Iter    26/  229] train: loss: 0.1247457
[Epoch 47; Iter    56/  229] train: loss: 0.1429607
[Epoch 47; Iter    86/  229] train: loss: 0.1110494
[Epoch 47; Iter   116/  229] train: loss: 0.1469483
[Epoch 47; Iter   146/  229] train: loss: 0.1100663
[Epoch 47; Iter   176/  229] train: loss: 0.1373704
[Epoch 47; Iter   206/  229] train: loss: 0.1618945
[Epoch 47] ogbg-moltoxcast: 0.696051 val loss: 0.261485
[Epoch 47] ogbg-moltoxcast: 0.664527 test loss: 0.527320
[Epoch 48; Iter     7/  229] train: loss: 0.1856919
[Epoch 48; Iter    37/  229] train: loss: 0.1180905
[Epoch 48; Iter    67/  229] train: loss: 0.1735233
[Epoch 48; Iter    97/  229] train: loss: 0.1499248
[Epoch 48; Iter   127/  229] train: loss: 0.2178590
[Epoch 48; Iter   157/  229] train: loss: 0.1583561
[Epoch 48; Iter   187/  229] train: loss: 0.1510170
[Epoch 48; Iter   217/  229] train: loss: 0.1019757
[Epoch 48] ogbg-moltoxcast: 0.708849 val loss: 0.255084
[Epoch 48] ogbg-moltoxcast: 0.671420 test loss: 0.435481
[Epoch 49; Iter    18/  229] train: loss: 0.1343421
[Epoch 49; Iter    48/  229] train: loss: 0.1327264
[Epoch 49; Iter    78/  229] train: loss: 0.1091292
[Epoch 49; Iter   108/  229] train: loss: 0.2653774
[Epoch 49; Iter   138/  229] train: loss: 0.1390121
[Epoch 49; Iter   168/  229] train: loss: 0.1162476
[Epoch 49; Iter   198/  229] train: loss: 0.1641736
[Epoch 49; Iter   228/  229] train: loss: 0.1115878
[Epoch 49] ogbg-moltoxcast: 0.705306 val loss: 0.252989
[Epoch 49] ogbg-moltoxcast: 0.662964 test loss: 0.381344
[Epoch 50; Iter    29/  229] train: loss: 0.1277355
[Epoch 50; Iter    59/  229] train: loss: 0.1147359
[Epoch 50; Iter    89/  229] train: loss: 0.1033860
[Epoch 50; Iter   119/  229] train: loss: 0.1360527
[Epoch 50; Iter   149/  229] train: loss: 0.1056459
[Epoch 50; Iter   179/  229] train: loss: 0.1727440
[Epoch 50; Iter   209/  229] train: loss: 0.1215593
[Epoch 50] ogbg-moltoxcast: 0.699816 val loss: 0.258641
[Epoch 50] ogbg-moltoxcast: 0.664828 test loss: 0.380686
[Epoch 51; Iter    10/  229] train: loss: 0.1108524
[Epoch 51; Iter    40/  229] train: loss: 0.1390020
[Epoch 51; Iter    70/  229] train: loss: 0.1300679
[Epoch 51; Iter   100/  229] train: loss: 0.1345446
[Epoch 51; Iter   130/  229] train: loss: 0.1160828
[Epoch 51; Iter   160/  229] train: loss: 0.1268274
[Epoch 51; Iter   190/  229] train: loss: 0.1386392
[Epoch 51; Iter   220/  229] train: loss: 0.0916795
[Epoch 51] ogbg-moltoxcast: 0.699290 val loss: 0.260049
[Epoch 51] ogbg-moltoxcast: 0.667167 test loss: 0.416024
[Epoch 52; Iter    21/  229] train: loss: 0.1932610
[Epoch 52; Iter    51/  229] train: loss: 0.1458805
[Epoch 52; Iter    81/  229] train: loss: 0.1608481
[Epoch 52; Iter   111/  229] train: loss: 0.1317167
[Epoch 52; Iter   141/  229] train: loss: 0.1127878
[Epoch 52; Iter   171/  229] train: loss: 0.1602206
[Epoch 52; Iter   201/  229] train: loss: 0.1441847
[Epoch 52] ogbg-moltoxcast: 0.696034 val loss: 0.254848
[Epoch 52] ogbg-moltoxcast: 0.670679 test loss: 0.364385
[Epoch 53; Iter     2/  229] train: loss: 0.1198471
[Epoch 53; Iter    32/  229] train: loss: 0.1420175
[Epoch 53; Iter    62/  229] train: loss: 0.1449426
[Epoch 53; Iter    92/  229] train: loss: 0.1155688
[Epoch 53; Iter   122/  229] train: loss: 0.1597206
[Epoch 53; Iter   152/  229] train: loss: 0.1545125
[Epoch 53; Iter   182/  229] train: loss: 0.1394321
[Epoch 53; Iter   212/  229] train: loss: 0.1661325
[Epoch 53] ogbg-moltoxcast: 0.698209 val loss: 0.255991
[Epoch 53] ogbg-moltoxcast: 0.661058 test loss: 0.637928
[Epoch 54; Iter    13/  229] train: loss: 0.0877364
[Epoch 54; Iter    43/  229] train: loss: 0.1416303
[Epoch 54; Iter    73/  229] train: loss: 0.1034669
[Epoch 54; Iter   103/  229] train: loss: 0.1564030
[Epoch 54; Iter   133/  229] train: loss: 0.1745578
[Epoch 54; Iter   163/  229] train: loss: 0.1725564
[Epoch 54; Iter   193/  229] train: loss: 0.1964550
[Epoch 54; Iter   223/  229] train: loss: 0.1899232
[Epoch 54] ogbg-moltoxcast: 0.694584 val loss: 0.251255
[Epoch 54] ogbg-moltoxcast: 0.662185 test loss: 0.424622
[Epoch 55; Iter    24/  229] train: loss: 0.1257832
[Epoch 55; Iter    54/  229] train: loss: 0.1809217
[Epoch 55; Iter    84/  229] train: loss: 0.1335083
[Epoch 55; Iter   114/  229] train: loss: 0.1264865
[Epoch 55; Iter   144/  229] train: loss: 0.1315909
[Epoch 55; Iter   174/  229] train: loss: 0.1454550
[Epoch 55; Iter   204/  229] train: loss: 0.0911184
[Epoch 55] ogbg-moltoxcast: 0.691855 val loss: 0.269963
[Epoch 55] ogbg-moltoxcast: 0.661263 test loss: 0.546877
[Epoch 56; Iter     5/  229] train: loss: 0.1375457
[Epoch 56; Iter    35/  229] train: loss: 0.1232678
[Epoch 56; Iter    65/  229] train: loss: 0.1147866
[Epoch 56; Iter    95/  229] train: loss: 0.1142300
[Epoch 56; Iter   125/  229] train: loss: 0.1527572
[Epoch 56; Iter   155/  229] train: loss: 0.1356679
[Epoch 56; Iter   185/  229] train: loss: 0.1424558
[Epoch 56; Iter   215/  229] train: loss: 0.1340842
[Epoch 56] ogbg-moltoxcast: 0.693318 val loss: 0.267269
[Epoch 56] ogbg-moltoxcast: 0.661538 test loss: 0.391923
[Epoch 57; Iter    16/  229] train: loss: 0.1490760
[Epoch 57; Iter    46/  229] train: loss: 0.1144811
[Epoch 57; Iter    76/  229] train: loss: 0.1541462
[Epoch 57; Iter   106/  229] train: loss: 0.1088014
[Epoch 57; Iter   136/  229] train: loss: 0.1229801
[Epoch 57; Iter   166/  229] train: loss: 0.1295734
[Epoch 57; Iter   196/  229] train: loss: 0.1466262
[Epoch 57; Iter   226/  229] train: loss: 0.1547676
[Epoch 57] ogbg-moltoxcast: 0.702661 val loss: 0.261785
[Epoch 57] ogbg-moltoxcast: 0.658082 test loss: 0.330792
[Epoch 58; Iter    27/  229] train: loss: 0.1528757
[Epoch 58; Iter    57/  229] train: loss: 0.1492877
[Epoch 58; Iter    87/  229] train: loss: 0.1127641
[Epoch 58; Iter   117/  229] train: loss: 0.1129559
[Epoch 58; Iter   147/  229] train: loss: 0.1445134
[Epoch 58; Iter   177/  229] train: loss: 0.2055900
[Epoch 58; Iter   207/  229] train: loss: 0.1540873
[Epoch 58] ogbg-moltoxcast: 0.703561 val loss: 0.260691
[Epoch 58] ogbg-moltoxcast: 0.664441 test loss: 0.412440
[Epoch 59; Iter     8/  229] train: loss: 0.1135763
[Epoch 59; Iter    38/  229] train: loss: 0.1492689
[Epoch 59; Iter    68/  229] train: loss: 0.1098963
[Epoch 59; Iter    98/  229] train: loss: 0.1518555
[Epoch 59; Iter   128/  229] train: loss: 0.1529997
[Epoch 59; Iter   158/  229] train: loss: 0.1305115
[Epoch 59; Iter   188/  229] train: loss: 0.1068003
[Epoch 59; Iter   218/  229] train: loss: 0.1775779
[Epoch 59] ogbg-moltoxcast: 0.692431 val loss: 0.262233
[Epoch 59] ogbg-moltoxcast: 0.659982 test loss: 0.484243
[Epoch 44; Iter    23/  229] train: loss: 0.2024272
[Epoch 44; Iter    53/  229] train: loss: 0.0935960
[Epoch 44; Iter    83/  229] train: loss: 0.1399722
[Epoch 44; Iter   113/  229] train: loss: 0.1331251
[Epoch 44; Iter   143/  229] train: loss: 0.1836324
[Epoch 44; Iter   173/  229] train: loss: 0.1924439
[Epoch 44; Iter   203/  229] train: loss: 0.1436955
[Epoch 44] ogbg-moltoxcast: 0.690610 val loss: 0.255974
[Epoch 44] ogbg-moltoxcast: 0.662126 test loss: 0.313458
[Epoch 45; Iter     4/  229] train: loss: 0.1292220
[Epoch 45; Iter    34/  229] train: loss: 0.1247926
[Epoch 45; Iter    64/  229] train: loss: 0.1679946
[Epoch 45; Iter    94/  229] train: loss: 0.1064766
[Epoch 45; Iter   124/  229] train: loss: 0.1571608
[Epoch 45; Iter   154/  229] train: loss: 0.1292481
[Epoch 45; Iter   184/  229] train: loss: 0.1160372
[Epoch 45; Iter   214/  229] train: loss: 0.1026854
[Epoch 45] ogbg-moltoxcast: 0.687078 val loss: 0.256658
[Epoch 45] ogbg-moltoxcast: 0.660393 test loss: 0.313392
[Epoch 46; Iter    15/  229] train: loss: 0.1797510
[Epoch 46; Iter    45/  229] train: loss: 0.1904905
[Epoch 46; Iter    75/  229] train: loss: 0.1345359
[Epoch 46; Iter   105/  229] train: loss: 0.1833178
[Epoch 46; Iter   135/  229] train: loss: 0.1685269
[Epoch 46; Iter   165/  229] train: loss: 0.1404244
[Epoch 46; Iter   195/  229] train: loss: 0.1568916
[Epoch 46; Iter   225/  229] train: loss: 0.1558651
[Epoch 46] ogbg-moltoxcast: 0.690805 val loss: 0.260710
[Epoch 46] ogbg-moltoxcast: 0.663953 test loss: 0.326314
[Epoch 47; Iter    26/  229] train: loss: 0.1597084
[Epoch 47; Iter    56/  229] train: loss: 0.1623590
[Epoch 47; Iter    86/  229] train: loss: 0.1528548
[Epoch 47; Iter   116/  229] train: loss: 0.1292478
[Epoch 47; Iter   146/  229] train: loss: 0.1287019
[Epoch 47; Iter   176/  229] train: loss: 0.1073935
[Epoch 47; Iter   206/  229] train: loss: 0.1285604
[Epoch 47] ogbg-moltoxcast: 0.688581 val loss: 0.265320
[Epoch 47] ogbg-moltoxcast: 0.667952 test loss: 0.316818
[Epoch 48; Iter     7/  229] train: loss: 0.1675615
[Epoch 48; Iter    37/  229] train: loss: 0.1348593
[Epoch 48; Iter    67/  229] train: loss: 0.1222495
[Epoch 48; Iter    97/  229] train: loss: 0.1472065
[Epoch 48; Iter   127/  229] train: loss: 0.1552047
[Epoch 48; Iter   157/  229] train: loss: 0.1215137
[Epoch 48; Iter   187/  229] train: loss: 0.1574955
[Epoch 48; Iter   217/  229] train: loss: 0.1414225
[Epoch 48] ogbg-moltoxcast: 0.695559 val loss: 0.259605
[Epoch 48] ogbg-moltoxcast: 0.666732 test loss: 0.315968
[Epoch 49; Iter    18/  229] train: loss: 0.1577211
[Epoch 49; Iter    48/  229] train: loss: 0.1450423
[Epoch 49; Iter    78/  229] train: loss: 0.0926313
[Epoch 49; Iter   108/  229] train: loss: 0.1322452
[Epoch 49; Iter   138/  229] train: loss: 0.1253738
[Epoch 49; Iter   168/  229] train: loss: 0.1410504
[Epoch 49; Iter   198/  229] train: loss: 0.1539551
[Epoch 49; Iter   228/  229] train: loss: 0.1590019
[Epoch 49] ogbg-moltoxcast: 0.700162 val loss: 0.263926
[Epoch 49] ogbg-moltoxcast: 0.666636 test loss: 0.328840
[Epoch 50; Iter    29/  229] train: loss: 0.1119598
[Epoch 50; Iter    59/  229] train: loss: 0.1487122
[Epoch 50; Iter    89/  229] train: loss: 0.0814970
[Epoch 50; Iter   119/  229] train: loss: 0.1775964
[Epoch 50; Iter   149/  229] train: loss: 0.1370545
[Epoch 50; Iter   179/  229] train: loss: 0.1329087
[Epoch 50; Iter   209/  229] train: loss: 0.1149244
[Epoch 50] ogbg-moltoxcast: 0.688389 val loss: 0.257856
[Epoch 50] ogbg-moltoxcast: 0.666993 test loss: 0.317374
[Epoch 51; Iter    10/  229] train: loss: 0.1632353
[Epoch 51; Iter    40/  229] train: loss: 0.1044531
[Epoch 51; Iter    70/  229] train: loss: 0.1622415
[Epoch 51; Iter   100/  229] train: loss: 0.1651646
[Epoch 51; Iter   130/  229] train: loss: 0.1166638
[Epoch 51; Iter   160/  229] train: loss: 0.1156843
[Epoch 51; Iter   190/  229] train: loss: 0.1421680
[Epoch 51; Iter   220/  229] train: loss: 0.1643930
[Epoch 51] ogbg-moltoxcast: 0.690903 val loss: 0.259162
[Epoch 51] ogbg-moltoxcast: 0.664234 test loss: 0.324118
[Epoch 52; Iter    21/  229] train: loss: 0.1388944
[Epoch 52; Iter    51/  229] train: loss: 0.1551399
[Epoch 52; Iter    81/  229] train: loss: 0.1246506
[Epoch 52; Iter   111/  229] train: loss: 0.1862890
[Epoch 52; Iter   141/  229] train: loss: 0.1478611
[Epoch 52; Iter   171/  229] train: loss: 0.1678051
[Epoch 52; Iter   201/  229] train: loss: 0.1349944
[Epoch 52] ogbg-moltoxcast: 0.690683 val loss: 0.271223
[Epoch 52] ogbg-moltoxcast: 0.666782 test loss: 0.326167
[Epoch 53; Iter     2/  229] train: loss: 0.0919144
[Epoch 53; Iter    32/  229] train: loss: 0.1276449
[Epoch 53; Iter    62/  229] train: loss: 0.1416850
[Epoch 53; Iter    92/  229] train: loss: 0.1893394
[Epoch 53; Iter   122/  229] train: loss: 0.0952373
[Epoch 53; Iter   152/  229] train: loss: 0.1200866
[Epoch 53; Iter   182/  229] train: loss: 0.1339296
[Epoch 53; Iter   212/  229] train: loss: 0.1190953
[Epoch 53] ogbg-moltoxcast: 0.687942 val loss: 0.268220
[Epoch 53] ogbg-moltoxcast: 0.663064 test loss: 0.325362
[Epoch 54; Iter    13/  229] train: loss: 0.0848577
[Epoch 54; Iter    43/  229] train: loss: 0.1607537
[Epoch 54; Iter    73/  229] train: loss: 0.1189907
[Epoch 54; Iter   103/  229] train: loss: 0.1283818
[Epoch 54; Iter   133/  229] train: loss: 0.1427297
[Epoch 54; Iter   163/  229] train: loss: 0.1709823
[Epoch 54; Iter   193/  229] train: loss: 0.1564913
[Epoch 54; Iter   223/  229] train: loss: 0.1657722
[Epoch 54] ogbg-moltoxcast: 0.699692 val loss: 0.263342
[Epoch 54] ogbg-moltoxcast: 0.667041 test loss: 0.327742
[Epoch 55; Iter    24/  229] train: loss: 0.1906286
[Epoch 55; Iter    54/  229] train: loss: 0.1933802
[Epoch 55; Iter    84/  229] train: loss: 0.1063599
[Epoch 55; Iter   114/  229] train: loss: 0.1879022
[Epoch 55; Iter   144/  229] train: loss: 0.1614139
[Epoch 55; Iter   174/  229] train: loss: 0.1673428
[Epoch 55; Iter   204/  229] train: loss: 0.1086097
[Epoch 55] ogbg-moltoxcast: 0.687732 val loss: 0.261925
[Epoch 55] ogbg-moltoxcast: 0.666856 test loss: 0.319289
[Epoch 56; Iter     5/  229] train: loss: 0.1179126
[Epoch 56; Iter    35/  229] train: loss: 0.1481559
[Epoch 56; Iter    65/  229] train: loss: 0.1321439
[Epoch 56; Iter    95/  229] train: loss: 0.1336938
[Epoch 56; Iter   125/  229] train: loss: 0.0934900
[Epoch 56; Iter   155/  229] train: loss: 0.1162054
[Epoch 56; Iter   185/  229] train: loss: 0.1405246
[Epoch 56; Iter   215/  229] train: loss: 0.1354382
[Epoch 56] ogbg-moltoxcast: 0.696044 val loss: 0.259441
[Epoch 56] ogbg-moltoxcast: 0.660201 test loss: 0.337942
[Epoch 57; Iter    16/  229] train: loss: 0.1149134
[Epoch 57; Iter    46/  229] train: loss: 0.1171896
[Epoch 57; Iter    76/  229] train: loss: 0.1870612
[Epoch 57; Iter   106/  229] train: loss: 0.1522208
[Epoch 57; Iter   136/  229] train: loss: 0.1371303
[Epoch 57; Iter   166/  229] train: loss: 0.1047602
[Epoch 57; Iter   196/  229] train: loss: 0.1682969
[Epoch 57; Iter   226/  229] train: loss: 0.1898647
[Epoch 57] ogbg-moltoxcast: 0.699432 val loss: 0.263906
[Epoch 57] ogbg-moltoxcast: 0.665014 test loss: 0.416052
[Epoch 58; Iter    27/  229] train: loss: 0.1133788
[Epoch 58; Iter    57/  229] train: loss: 0.1013357
[Epoch 58; Iter    87/  229] train: loss: 0.1221114
[Epoch 58; Iter   117/  229] train: loss: 0.1062656
[Epoch 58; Iter   147/  229] train: loss: 0.1365677
[Epoch 58; Iter   177/  229] train: loss: 0.1726350
[Epoch 58; Iter   207/  229] train: loss: 0.1227789
[Epoch 58] ogbg-moltoxcast: 0.684409 val loss: 0.263218
[Epoch 58] ogbg-moltoxcast: 0.658822 test loss: 0.330532
[Epoch 59; Iter     8/  229] train: loss: 0.1236497
[Epoch 59; Iter    38/  229] train: loss: 0.1360795
[Epoch 59; Iter    68/  229] train: loss: 0.1191841
[Epoch 59; Iter    98/  229] train: loss: 0.1713986
[Epoch 59; Iter   128/  229] train: loss: 0.1648114
[Epoch 59; Iter   158/  229] train: loss: 0.1205565
[Epoch 59; Iter   188/  229] train: loss: 0.1295499
[Epoch 59; Iter   218/  229] train: loss: 0.1142327
[Epoch 59] ogbg-moltoxcast: 0.691561 val loss: 0.262509
[Epoch 59] ogbg-moltoxcast: 0.665132 test loss: 0.330515
[Epoch 44; Iter    23/  229] train: loss: 0.1791002
[Epoch 44; Iter    53/  229] train: loss: 0.1107022
[Epoch 44; Iter    83/  229] train: loss: 0.1522142
[Epoch 44; Iter   113/  229] train: loss: 0.0949176
[Epoch 44; Iter   143/  229] train: loss: 0.1433580
[Epoch 44; Iter   173/  229] train: loss: 0.1250710
[Epoch 44; Iter   203/  229] train: loss: 0.1447780
[Epoch 44] ogbg-moltoxcast: 0.697657 val loss: 0.246804
[Epoch 44] ogbg-moltoxcast: 0.667518 test loss: 0.686567
[Epoch 45; Iter     4/  229] train: loss: 0.1184669
[Epoch 45; Iter    34/  229] train: loss: 0.1209145
[Epoch 45; Iter    64/  229] train: loss: 0.1632782
[Epoch 45; Iter    94/  229] train: loss: 0.1181754
[Epoch 45; Iter   124/  229] train: loss: 0.1430256
[Epoch 45; Iter   154/  229] train: loss: 0.1288806
[Epoch 45; Iter   184/  229] train: loss: 0.1584612
[Epoch 45; Iter   214/  229] train: loss: 0.1547520
[Epoch 45] ogbg-moltoxcast: 0.692858 val loss: 0.253663
[Epoch 45] ogbg-moltoxcast: 0.669456 test loss: 0.487239
[Epoch 46; Iter    15/  229] train: loss: 0.1295178
[Epoch 46; Iter    45/  229] train: loss: 0.1485665
[Epoch 46; Iter    75/  229] train: loss: 0.1938541
[Epoch 46; Iter   105/  229] train: loss: 0.1466680
[Epoch 46; Iter   135/  229] train: loss: 0.1464661
[Epoch 46; Iter   165/  229] train: loss: 0.1303964
[Epoch 46; Iter   195/  229] train: loss: 0.1475601
[Epoch 46; Iter   225/  229] train: loss: 0.1565688
[Epoch 46] ogbg-moltoxcast: 0.691879 val loss: 0.252750
[Epoch 46] ogbg-moltoxcast: 0.665890 test loss: 0.521864
[Epoch 47; Iter    26/  229] train: loss: 0.1518242
[Epoch 47; Iter    56/  229] train: loss: 0.1566202
[Epoch 47; Iter    86/  229] train: loss: 0.1308439
[Epoch 47; Iter   116/  229] train: loss: 0.0953083
[Epoch 47; Iter   146/  229] train: loss: 0.1253033
[Epoch 47; Iter   176/  229] train: loss: 0.1568027
[Epoch 47; Iter   206/  229] train: loss: 0.1361268
[Epoch 47] ogbg-moltoxcast: 0.695338 val loss: 0.253233
[Epoch 47] ogbg-moltoxcast: 0.661839 test loss: 0.305616
[Epoch 48; Iter     7/  229] train: loss: 0.1175816
[Epoch 48; Iter    37/  229] train: loss: 0.1221079
[Epoch 48; Iter    67/  229] train: loss: 0.1453349
[Epoch 48; Iter    97/  229] train: loss: 0.1665476
[Epoch 48; Iter   127/  229] train: loss: 0.1600605
[Epoch 48; Iter   157/  229] train: loss: 0.1116599
[Epoch 48; Iter   187/  229] train: loss: 0.1875800
[Epoch 48; Iter   217/  229] train: loss: 0.1439140
[Epoch 48] ogbg-moltoxcast: 0.689268 val loss: 0.271221
[Epoch 48] ogbg-moltoxcast: 0.660930 test loss: 0.375195
[Epoch 49; Iter    18/  229] train: loss: 0.1785034
[Epoch 49; Iter    48/  229] train: loss: 0.1145172
[Epoch 49; Iter    78/  229] train: loss: 0.1836678
[Epoch 49; Iter   108/  229] train: loss: 0.1357104
[Epoch 49; Iter   138/  229] train: loss: 0.1771442
[Epoch 49; Iter   168/  229] train: loss: 0.1204861
[Epoch 49; Iter   198/  229] train: loss: 0.1458541
[Epoch 49; Iter   228/  229] train: loss: 0.1341928
[Epoch 49] ogbg-moltoxcast: 0.695274 val loss: 0.256901
[Epoch 49] ogbg-moltoxcast: 0.668070 test loss: 0.308216
[Epoch 50; Iter    29/  229] train: loss: 0.1582262
[Epoch 50; Iter    59/  229] train: loss: 0.1335657
[Epoch 50; Iter    89/  229] train: loss: 0.1622506
[Epoch 50; Iter   119/  229] train: loss: 0.1198618
[Epoch 50; Iter   149/  229] train: loss: 0.1620804
[Epoch 50; Iter   179/  229] train: loss: 0.1748853
[Epoch 50; Iter   209/  229] train: loss: 0.1921981
[Epoch 50] ogbg-moltoxcast: 0.686641 val loss: 0.254473
[Epoch 50] ogbg-moltoxcast: 0.669089 test loss: 0.304047
[Epoch 51; Iter    10/  229] train: loss: 0.1440641
[Epoch 51; Iter    40/  229] train: loss: 0.1008747
[Epoch 51; Iter    70/  229] train: loss: 0.1616855
[Epoch 51; Iter   100/  229] train: loss: 0.1479655
[Epoch 51; Iter   130/  229] train: loss: 0.1240890
[Epoch 51; Iter   160/  229] train: loss: 0.1119079
[Epoch 51; Iter   190/  229] train: loss: 0.1122495
[Epoch 51; Iter   220/  229] train: loss: 0.1609735
[Epoch 51] ogbg-moltoxcast: 0.693294 val loss: 0.250172
[Epoch 51] ogbg-moltoxcast: 0.661630 test loss: 0.305768
[Epoch 52; Iter    21/  229] train: loss: 0.1444761
[Epoch 52; Iter    51/  229] train: loss: 0.1396688
[Epoch 52; Iter    81/  229] train: loss: 0.1536615
[Epoch 52; Iter   111/  229] train: loss: 0.1183983
[Epoch 52; Iter   141/  229] train: loss: 0.1277084
[Epoch 52; Iter   171/  229] train: loss: 0.0862149
[Epoch 52; Iter   201/  229] train: loss: 0.1276479
[Epoch 52] ogbg-moltoxcast: 0.694172 val loss: 0.257646
[Epoch 52] ogbg-moltoxcast: 0.663372 test loss: 0.313235
[Epoch 53; Iter     2/  229] train: loss: 0.1076729
[Epoch 53; Iter    32/  229] train: loss: 0.0901919
[Epoch 53; Iter    62/  229] train: loss: 0.1287464
[Epoch 53; Iter    92/  229] train: loss: 0.1076525
[Epoch 53; Iter   122/  229] train: loss: 0.1006750
[Epoch 53; Iter   152/  229] train: loss: 0.1527351
[Epoch 53; Iter   182/  229] train: loss: 0.1317712
[Epoch 53; Iter   212/  229] train: loss: 0.1518115
[Epoch 53] ogbg-moltoxcast: 0.686842 val loss: 0.259411
[Epoch 53] ogbg-moltoxcast: 0.663549 test loss: 0.310494
[Epoch 54; Iter    13/  229] train: loss: 0.0951837
[Epoch 54; Iter    43/  229] train: loss: 0.1050995
[Epoch 54; Iter    73/  229] train: loss: 0.1108566
[Epoch 54; Iter   103/  229] train: loss: 0.1018848
[Epoch 54; Iter   133/  229] train: loss: 0.1148023
[Epoch 54; Iter   163/  229] train: loss: 0.1269765
[Epoch 54; Iter   193/  229] train: loss: 0.1575610
[Epoch 54; Iter   223/  229] train: loss: 0.1700579
[Epoch 54] ogbg-moltoxcast: 0.681899 val loss: 0.265972
[Epoch 54] ogbg-moltoxcast: 0.659637 test loss: 0.316145
[Epoch 55; Iter    24/  229] train: loss: 0.1661241
[Epoch 55; Iter    54/  229] train: loss: 0.1574782
[Epoch 55; Iter    84/  229] train: loss: 0.1227632
[Epoch 55; Iter   114/  229] train: loss: 0.1333293
[Epoch 55; Iter   144/  229] train: loss: 0.1343172
[Epoch 55; Iter   174/  229] train: loss: 0.1401025
[Epoch 55; Iter   204/  229] train: loss: 0.1618001
[Epoch 55] ogbg-moltoxcast: 0.688653 val loss: 0.259729
[Epoch 55] ogbg-moltoxcast: 0.661731 test loss: 0.310012
[Epoch 56; Iter     5/  229] train: loss: 0.1426630
[Epoch 56; Iter    35/  229] train: loss: 0.1088578
[Epoch 56; Iter    65/  229] train: loss: 0.1847078
[Epoch 56; Iter    95/  229] train: loss: 0.1322597
[Epoch 56; Iter   125/  229] train: loss: 0.1378444
[Epoch 56; Iter   155/  229] train: loss: 0.1446277
[Epoch 56; Iter   185/  229] train: loss: 0.1643006
[Epoch 56; Iter   215/  229] train: loss: 0.1191485
[Epoch 56] ogbg-moltoxcast: 0.691519 val loss: 0.266318
[Epoch 56] ogbg-moltoxcast: 0.665388 test loss: 0.317797
[Epoch 57; Iter    16/  229] train: loss: 0.2162948
[Epoch 57; Iter    46/  229] train: loss: 0.1314263
[Epoch 57; Iter    76/  229] train: loss: 0.1051785
[Epoch 57; Iter   106/  229] train: loss: 0.1558141
[Epoch 57; Iter   136/  229] train: loss: 0.1135354
[Epoch 57; Iter   166/  229] train: loss: 0.0930768
[Epoch 57; Iter   196/  229] train: loss: 0.1393746
[Epoch 57; Iter   226/  229] train: loss: 0.2072682
[Epoch 57] ogbg-moltoxcast: 0.687384 val loss: 0.263555
[Epoch 57] ogbg-moltoxcast: 0.656534 test loss: 0.311264
[Epoch 58; Iter    27/  229] train: loss: 0.1436257
[Epoch 58; Iter    57/  229] train: loss: 0.1546088
[Epoch 58; Iter    87/  229] train: loss: 0.1352113
[Epoch 58; Iter   117/  229] train: loss: 0.1474544
[Epoch 58; Iter   147/  229] train: loss: 0.1947463
[Epoch 58; Iter   177/  229] train: loss: 0.1973221
[Epoch 58; Iter   207/  229] train: loss: 0.1269834
[Epoch 58] ogbg-moltoxcast: 0.679508 val loss: 0.260957
[Epoch 58] ogbg-moltoxcast: 0.663125 test loss: 0.317543
[Epoch 59; Iter     8/  229] train: loss: 0.1369350
[Epoch 59; Iter    38/  229] train: loss: 0.1151389
[Epoch 59; Iter    68/  229] train: loss: 0.1302811
[Epoch 59; Iter    98/  229] train: loss: 0.1078759
[Epoch 59; Iter   128/  229] train: loss: 0.1206573
[Epoch 59; Iter   158/  229] train: loss: 0.1319760
[Epoch 59; Iter   188/  229] train: loss: 0.1309283
[Epoch 59; Iter   218/  229] train: loss: 0.1297205
[Epoch 59] ogbg-moltoxcast: 0.687369 val loss: 0.259958
[Epoch 59] ogbg-moltoxcast: 0.666969 test loss: 0.310356
[Epoch 60; Iter    19/  229] train: loss: 0.0992195
[Epoch 60; Iter    49/  229] train: loss: 0.1242221
[Epoch 60; Iter    79/  229] train: loss: 0.1622748
[Epoch 60; Iter   109/  229] train: loss: 0.1143519
[Epoch 60; Iter   139/  229] train: loss: 0.1371055
[Epoch 60; Iter   169/  229] train: loss: 0.0970360
[Epoch 60; Iter   199/  229] train: loss: 0.1557163
[Epoch 60; Iter   229/  229] train: loss: 0.1355872
[Epoch 60] ogbg-moltoxcast: 0.678569 val loss: 0.280321
[Epoch 60] ogbg-moltoxcast: 0.643353 test loss: 0.336479
[Epoch 61; Iter    30/  229] train: loss: 0.1436103
[Epoch 61; Iter    60/  229] train: loss: 0.1598272
[Epoch 61; Iter    90/  229] train: loss: 0.1708707
[Epoch 61; Iter   120/  229] train: loss: 0.1515847
[Epoch 61; Iter   150/  229] train: loss: 0.1441626
[Epoch 61; Iter   180/  229] train: loss: 0.1517194
[Epoch 61; Iter   210/  229] train: loss: 0.0876792
[Epoch 61] ogbg-moltoxcast: 0.682071 val loss: 0.284924
[Epoch 61] ogbg-moltoxcast: 0.651760 test loss: 0.338136
[Epoch 62; Iter    11/  229] train: loss: 0.0931606
[Epoch 62; Iter    41/  229] train: loss: 0.1772130
[Epoch 62; Iter    71/  229] train: loss: 0.1365019
[Epoch 62; Iter   101/  229] train: loss: 0.1273341
[Epoch 62; Iter   131/  229] train: loss: 0.1693684
[Epoch 62; Iter   161/  229] train: loss: 0.1147522
[Epoch 62; Iter   191/  229] train: loss: 0.1382815
[Epoch 62; Iter   221/  229] train: loss: 0.1544839
[Epoch 62] ogbg-moltoxcast: 0.675952 val loss: 0.466059
[Epoch 62] ogbg-moltoxcast: 0.648703 test loss: 0.349591
[Epoch 63; Iter    22/  229] train: loss: 0.1373459
[Epoch 63; Iter    52/  229] train: loss: 0.0809079
[Epoch 63; Iter    82/  229] train: loss: 0.0891863
[Epoch 63; Iter   112/  229] train: loss: 0.0946301
[Epoch 63; Iter   142/  229] train: loss: 0.1637620
[Epoch 63; Iter   172/  229] train: loss: 0.1687110
[Epoch 63; Iter   202/  229] train: loss: 0.1109043
[Epoch 63] ogbg-moltoxcast: 0.669991 val loss: 0.406529
[Epoch 63] ogbg-moltoxcast: 0.645338 test loss: 0.336200
[Epoch 64; Iter     3/  229] train: loss: 0.0768692
[Epoch 64; Iter    33/  229] train: loss: 0.1265965
[Epoch 64; Iter    63/  229] train: loss: 0.1327911
[Epoch 64; Iter    93/  229] train: loss: 0.1100886
[Epoch 64; Iter   123/  229] train: loss: 0.1109876
[Epoch 64; Iter   153/  229] train: loss: 0.1044642
[Epoch 64; Iter   183/  229] train: loss: 0.1039422
[Epoch 64; Iter   213/  229] train: loss: 0.1436295
[Epoch 64] ogbg-moltoxcast: 0.675421 val loss: 0.469627
[Epoch 64] ogbg-moltoxcast: 0.647603 test loss: 0.335422
[Epoch 65; Iter    14/  229] train: loss: 0.1372850
[Epoch 65; Iter    44/  229] train: loss: 0.1397647
[Epoch 65; Iter    74/  229] train: loss: 0.1226998
[Epoch 65; Iter   104/  229] train: loss: 0.1513738
[Epoch 65; Iter   134/  229] train: loss: 0.1190625
[Epoch 65; Iter   164/  229] train: loss: 0.1414851
[Epoch 65; Iter   194/  229] train: loss: 0.1020001
[Epoch 65; Iter   224/  229] train: loss: 0.1411567
[Epoch 65] ogbg-moltoxcast: 0.674894 val loss: 0.553033
[Epoch 65] ogbg-moltoxcast: 0.643378 test loss: 0.344028
[Epoch 66; Iter    25/  229] train: loss: 0.1138570
[Epoch 66; Iter    55/  229] train: loss: 0.1539962
[Epoch 66; Iter    85/  229] train: loss: 0.1278232
[Epoch 66; Iter   115/  229] train: loss: 0.1019211
[Epoch 66; Iter   145/  229] train: loss: 0.1013761
[Epoch 66; Iter   175/  229] train: loss: 0.1325779
[Epoch 66; Iter   205/  229] train: loss: 0.1111458
[Epoch 66] ogbg-moltoxcast: 0.677863 val loss: 0.425312
[Epoch 66] ogbg-moltoxcast: 0.646898 test loss: 0.338232
[Epoch 67; Iter     6/  229] train: loss: 0.1280702
[Epoch 67; Iter    36/  229] train: loss: 0.1610261
[Epoch 67; Iter    66/  229] train: loss: 0.1015510
[Epoch 67; Iter    96/  229] train: loss: 0.1594439
[Epoch 67; Iter   126/  229] train: loss: 0.1036997
[Epoch 67; Iter   156/  229] train: loss: 0.0983363
[Epoch 67; Iter   186/  229] train: loss: 0.1031296
[Epoch 67; Iter   216/  229] train: loss: 0.0950934
[Epoch 67] ogbg-moltoxcast: 0.671663 val loss: 0.398704
[Epoch 67] ogbg-moltoxcast: 0.650416 test loss: 0.342039
[Epoch 68; Iter    17/  229] train: loss: 0.1600222
[Epoch 68; Iter    47/  229] train: loss: 0.1159004
[Epoch 68; Iter    77/  229] train: loss: 0.1108213
[Epoch 68; Iter   107/  229] train: loss: 0.1519986
[Epoch 68; Iter   137/  229] train: loss: 0.1039586
[Epoch 68; Iter   167/  229] train: loss: 0.0958906
[Epoch 68; Iter   197/  229] train: loss: 0.1431663
[Epoch 68; Iter   227/  229] train: loss: 0.1347443
[Epoch 68] ogbg-moltoxcast: 0.675278 val loss: 0.516809
[Epoch 68] ogbg-moltoxcast: 0.647079 test loss: 0.344830
[Epoch 69; Iter    28/  229] train: loss: 0.1284442
[Epoch 69; Iter    58/  229] train: loss: 0.0815435
[Epoch 69; Iter    88/  229] train: loss: 0.1071300
[Epoch 69; Iter   118/  229] train: loss: 0.1116115
[Epoch 69; Iter   148/  229] train: loss: 0.0889598
[Epoch 69; Iter   178/  229] train: loss: 0.1824797
[Epoch 69; Iter   208/  229] train: loss: 0.1150211
[Epoch 69] ogbg-moltoxcast: 0.675016 val loss: 0.406007
[Epoch 69] ogbg-moltoxcast: 0.647999 test loss: 0.335889
[Epoch 70; Iter     9/  229] train: loss: 0.1013094
[Epoch 70; Iter    39/  229] train: loss: 0.1385099
[Epoch 70; Iter    69/  229] train: loss: 0.1226814
[Epoch 70; Iter    99/  229] train: loss: 0.1619985
[Epoch 70; Iter   129/  229] train: loss: 0.1073712
[Epoch 70; Iter   159/  229] train: loss: 0.1425667
[Epoch 70; Iter   189/  229] train: loss: 0.1596346
[Epoch 70; Iter   219/  229] train: loss: 0.1497087
[Epoch 70] ogbg-moltoxcast: 0.667841 val loss: 0.534714
[Epoch 70] ogbg-moltoxcast: 0.647117 test loss: 0.341958
[Epoch 71; Iter    20/  229] train: loss: 0.1044937
[Epoch 71; Iter    50/  229] train: loss: 0.0942192
[Epoch 71; Iter    80/  229] train: loss: 0.1280078
[Epoch 71; Iter   110/  229] train: loss: 0.1194936
[Epoch 71; Iter   140/  229] train: loss: 0.0969519
[Epoch 71; Iter   170/  229] train: loss: 0.1317223
[Epoch 71; Iter   200/  229] train: loss: 0.1117916
[Epoch 71] ogbg-moltoxcast: 0.676076 val loss: 0.529168
[Epoch 71] ogbg-moltoxcast: 0.646336 test loss: 0.347579
[Epoch 72; Iter     1/  229] train: loss: 0.0832551
[Epoch 72; Iter    31/  229] train: loss: 0.0923608
[Epoch 72; Iter    61/  229] train: loss: 0.1173467
[Epoch 72; Iter    91/  229] train: loss: 0.1249819
[Epoch 72; Iter   121/  229] train: loss: 0.1122979
[Epoch 72; Iter   151/  229] train: loss: 0.1380140
[Epoch 72; Iter   181/  229] train: loss: 0.0933928
[Epoch 72; Iter   211/  229] train: loss: 0.1276872
[Epoch 72] ogbg-moltoxcast: 0.677362 val loss: 0.521597
[Epoch 72] ogbg-moltoxcast: 0.652257 test loss: 0.339111
[Epoch 73; Iter    12/  229] train: loss: 0.1573159
[Epoch 73; Iter    42/  229] train: loss: 0.1107759
[Epoch 73; Iter    72/  229] train: loss: 0.0930271
[Epoch 73; Iter   102/  229] train: loss: 0.1228041
[Epoch 73; Iter   132/  229] train: loss: 0.1610796
[Epoch 73; Iter   162/  229] train: loss: 0.1288578
[Epoch 73; Iter   192/  229] train: loss: 0.1183054
[Epoch 73; Iter   222/  229] train: loss: 0.1280462
[Epoch 73] ogbg-moltoxcast: 0.672508 val loss: 0.418394
[Epoch 73] ogbg-moltoxcast: 0.646273 test loss: 0.344599
[Epoch 74; Iter    23/  229] train: loss: 0.0904799
[Epoch 74; Iter    53/  229] train: loss: 0.1778701
[Epoch 74; Iter    83/  229] train: loss: 0.0947013
[Epoch 74; Iter   113/  229] train: loss: 0.1267057
[Epoch 74; Iter   143/  229] train: loss: 0.1531859
[Epoch 74; Iter   173/  229] train: loss: 0.0827264
[Epoch 74; Iter   203/  229] train: loss: 0.0981460
[Epoch 74] ogbg-moltoxcast: 0.672731 val loss: 0.546259
[Epoch 74] ogbg-moltoxcast: 0.643300 test loss: 0.343994
[Epoch 75; Iter     4/  229] train: loss: 0.0836757
[Epoch 75; Iter    34/  229] train: loss: 0.1454717
[Epoch 75; Iter    64/  229] train: loss: 0.0923482
[Epoch 75; Iter    94/  229] train: loss: 0.1402069
[Epoch 75; Iter   124/  229] train: loss: 0.1449780
[Epoch 75; Iter   154/  229] train: loss: 0.0993732
[Epoch 75; Iter   184/  229] train: loss: 0.1301143
[Epoch 75; Iter   214/  229] train: loss: 0.1012812
[Epoch 75] ogbg-moltoxcast: 0.669210 val loss: 0.428088
[Epoch 75] ogbg-moltoxcast: 0.648760 test loss: 0.342243
[Epoch 60; Iter    19/  229] train: loss: 0.1095516
[Epoch 60; Iter    49/  229] train: loss: 0.1075519
[Epoch 60; Iter    79/  229] train: loss: 0.1962748
[Epoch 60; Iter   109/  229] train: loss: 0.1989493
[Epoch 60; Iter   139/  229] train: loss: 0.1587596
[Epoch 60; Iter   169/  229] train: loss: 0.1279801
[Epoch 60; Iter   199/  229] train: loss: 0.1615880
[Epoch 60; Iter   229/  229] train: loss: 0.1362024
[Epoch 60] ogbg-moltoxcast: 0.685281 val loss: 0.498414
[Epoch 60] ogbg-moltoxcast: 0.640774 test loss: 0.373945
[Epoch 61; Iter    30/  229] train: loss: 0.1345429
[Epoch 61; Iter    60/  229] train: loss: 0.1399824
[Epoch 61; Iter    90/  229] train: loss: 0.0813065
[Epoch 61; Iter   120/  229] train: loss: 0.0837689
[Epoch 61; Iter   150/  229] train: loss: 0.1581788
[Epoch 61; Iter   180/  229] train: loss: 0.0999967
[Epoch 61; Iter   210/  229] train: loss: 0.1047118
[Epoch 61] ogbg-moltoxcast: 0.702660 val loss: 0.401152
[Epoch 61] ogbg-moltoxcast: 0.649619 test loss: 0.385359
[Epoch 62; Iter    11/  229] train: loss: 0.1073016
[Epoch 62; Iter    41/  229] train: loss: 0.1264902
[Epoch 62; Iter    71/  229] train: loss: 0.0928958
[Epoch 62; Iter   101/  229] train: loss: 0.1140424
[Epoch 62; Iter   131/  229] train: loss: 0.0965609
[Epoch 62; Iter   161/  229] train: loss: 0.1171599
[Epoch 62; Iter   191/  229] train: loss: 0.1104811
[Epoch 62; Iter   221/  229] train: loss: 0.1236828
[Epoch 62] ogbg-moltoxcast: 0.699149 val loss: 0.365144
[Epoch 62] ogbg-moltoxcast: 0.647805 test loss: 0.353826
[Epoch 63; Iter    22/  229] train: loss: 0.1568794
[Epoch 63; Iter    52/  229] train: loss: 0.1440511
[Epoch 63; Iter    82/  229] train: loss: 0.0999393
[Epoch 63; Iter   112/  229] train: loss: 0.1211417
[Epoch 63; Iter   142/  229] train: loss: 0.1129266
[Epoch 63; Iter   172/  229] train: loss: 0.1540099
[Epoch 63; Iter   202/  229] train: loss: 0.0913736
[Epoch 63] ogbg-moltoxcast: 0.693711 val loss: 0.374622
[Epoch 63] ogbg-moltoxcast: 0.639575 test loss: 0.381112
[Epoch 64; Iter     3/  229] train: loss: 0.1888633
[Epoch 64; Iter    33/  229] train: loss: 0.1288417
[Epoch 64; Iter    63/  229] train: loss: 0.1706226
[Epoch 64; Iter    93/  229] train: loss: 0.1791315
[Epoch 64; Iter   123/  229] train: loss: 0.1404694
[Epoch 64; Iter   153/  229] train: loss: 0.1478012
[Epoch 64; Iter   183/  229] train: loss: 0.1585859
[Epoch 64; Iter   213/  229] train: loss: 0.1001819
[Epoch 64] ogbg-moltoxcast: 0.701478 val loss: 0.318548
[Epoch 64] ogbg-moltoxcast: 0.651760 test loss: 0.338489
[Epoch 65; Iter    14/  229] train: loss: 0.0983256
[Epoch 65; Iter    44/  229] train: loss: 0.1134932
[Epoch 65; Iter    74/  229] train: loss: 0.1268363
[Epoch 65; Iter   104/  229] train: loss: 0.1249511
[Epoch 65; Iter   134/  229] train: loss: 0.0922619
[Epoch 65; Iter   164/  229] train: loss: 0.1310064
[Epoch 65; Iter   194/  229] train: loss: 0.0945653
[Epoch 65; Iter   224/  229] train: loss: 0.1261391
[Epoch 65] ogbg-moltoxcast: 0.694850 val loss: 0.391179
[Epoch 65] ogbg-moltoxcast: 0.644511 test loss: 0.363330
[Epoch 66; Iter    25/  229] train: loss: 0.1124030
[Epoch 66; Iter    55/  229] train: loss: 0.1652640
[Epoch 66; Iter    85/  229] train: loss: 0.0961212
[Epoch 66; Iter   115/  229] train: loss: 0.1470627
[Epoch 66; Iter   145/  229] train: loss: 0.1121394
[Epoch 66; Iter   175/  229] train: loss: 0.0925444
[Epoch 66; Iter   205/  229] train: loss: 0.1515248
[Epoch 66] ogbg-moltoxcast: 0.704962 val loss: 0.362297
[Epoch 66] ogbg-moltoxcast: 0.646726 test loss: 0.369510
[Epoch 67; Iter     6/  229] train: loss: 0.0708107
[Epoch 67; Iter    36/  229] train: loss: 0.1096197
[Epoch 67; Iter    66/  229] train: loss: 0.1322300
[Epoch 67; Iter    96/  229] train: loss: 0.1106980
[Epoch 67; Iter   126/  229] train: loss: 0.1579882
[Epoch 67; Iter   156/  229] train: loss: 0.0928767
[Epoch 67; Iter   186/  229] train: loss: 0.1179178
[Epoch 67; Iter   216/  229] train: loss: 0.0888366
[Epoch 67] ogbg-moltoxcast: 0.698047 val loss: 0.368925
[Epoch 67] ogbg-moltoxcast: 0.649887 test loss: 0.367693
[Epoch 68; Iter    17/  229] train: loss: 0.1245404
[Epoch 68; Iter    47/  229] train: loss: 0.1280837
[Epoch 68; Iter    77/  229] train: loss: 0.1807246
[Epoch 68; Iter   107/  229] train: loss: 0.1145669
[Epoch 68; Iter   137/  229] train: loss: 0.1117748
[Epoch 68; Iter   167/  229] train: loss: 0.1374342
[Epoch 68; Iter   197/  229] train: loss: 0.1216464
[Epoch 68; Iter   227/  229] train: loss: 0.1253557
[Epoch 68] ogbg-moltoxcast: 0.698240 val loss: 0.389355
[Epoch 68] ogbg-moltoxcast: 0.648061 test loss: 0.378006
[Epoch 69; Iter    28/  229] train: loss: 0.1483184
[Epoch 69; Iter    58/  229] train: loss: 0.1397776
[Epoch 69; Iter    88/  229] train: loss: 0.1364563
[Epoch 69; Iter   118/  229] train: loss: 0.1684732
[Epoch 69; Iter   148/  229] train: loss: 0.1663115
[Epoch 69; Iter   178/  229] train: loss: 0.0916032
[Epoch 69; Iter   208/  229] train: loss: 0.1026054
[Epoch 69] ogbg-moltoxcast: 0.693816 val loss: 0.400519
[Epoch 69] ogbg-moltoxcast: 0.649237 test loss: 0.370345
[Epoch 70; Iter     9/  229] train: loss: 0.1467797
[Epoch 70; Iter    39/  229] train: loss: 0.1251341
[Epoch 70; Iter    69/  229] train: loss: 0.1261626
[Epoch 70; Iter    99/  229] train: loss: 0.1628581
[Epoch 70; Iter   129/  229] train: loss: 0.1403087
[Epoch 70; Iter   159/  229] train: loss: 0.1124965
[Epoch 70; Iter   189/  229] train: loss: 0.0968198
[Epoch 70; Iter   219/  229] train: loss: 0.1679210
[Epoch 70] ogbg-moltoxcast: 0.690452 val loss: 0.330103
[Epoch 70] ogbg-moltoxcast: 0.645523 test loss: 0.364779
[Epoch 71; Iter    20/  229] train: loss: 0.1246124
[Epoch 71; Iter    50/  229] train: loss: 0.0905190
[Epoch 71; Iter    80/  229] train: loss: 0.1506151
[Epoch 71; Iter   110/  229] train: loss: 0.1395694
[Epoch 71; Iter   140/  229] train: loss: 0.1307276
[Epoch 71; Iter   170/  229] train: loss: 0.1476170
[Epoch 71; Iter   200/  229] train: loss: 0.1221244
[Epoch 71] ogbg-moltoxcast: 0.698832 val loss: 0.303736
[Epoch 71] ogbg-moltoxcast: 0.644421 test loss: 0.347264
[Epoch 72; Iter     1/  229] train: loss: 0.1345772
[Epoch 72; Iter    31/  229] train: loss: 0.1269203
[Epoch 72; Iter    61/  229] train: loss: 0.1631198
[Epoch 72; Iter    91/  229] train: loss: 0.1024524
[Epoch 72; Iter   121/  229] train: loss: 0.0841238
[Epoch 72; Iter   151/  229] train: loss: 0.1427294
[Epoch 72; Iter   181/  229] train: loss: 0.1793227
[Epoch 72; Iter   211/  229] train: loss: 0.0890327
[Epoch 72] ogbg-moltoxcast: 0.695736 val loss: 0.359597
[Epoch 72] ogbg-moltoxcast: 0.642679 test loss: 0.362286
[Epoch 73; Iter    12/  229] train: loss: 0.1000331
[Epoch 73; Iter    42/  229] train: loss: 0.1308216
[Epoch 73; Iter    72/  229] train: loss: 0.1605079
[Epoch 73; Iter   102/  229] train: loss: 0.1324202
[Epoch 73; Iter   132/  229] train: loss: 0.1118425
[Epoch 73; Iter   162/  229] train: loss: 0.1322129
[Epoch 73; Iter   192/  229] train: loss: 0.0977003
[Epoch 73; Iter   222/  229] train: loss: 0.1186282
[Epoch 73] ogbg-moltoxcast: 0.689946 val loss: 0.353514
[Epoch 73] ogbg-moltoxcast: 0.639210 test loss: 0.364691
[Epoch 74; Iter    23/  229] train: loss: 0.0770248
[Epoch 74; Iter    53/  229] train: loss: 0.1285797
[Epoch 74; Iter    83/  229] train: loss: 0.1138012
[Epoch 74; Iter   113/  229] train: loss: 0.0941645
[Epoch 74; Iter   143/  229] train: loss: 0.1177242
[Epoch 74; Iter   173/  229] train: loss: 0.1232517
[Epoch 74; Iter   203/  229] train: loss: 0.1267239
[Epoch 74] ogbg-moltoxcast: 0.690839 val loss: 0.357745
[Epoch 74] ogbg-moltoxcast: 0.641922 test loss: 0.370444
[Epoch 75; Iter     4/  229] train: loss: 0.0841259
[Epoch 75; Iter    34/  229] train: loss: 0.1556455
[Epoch 75; Iter    64/  229] train: loss: 0.1731523
[Epoch 75; Iter    94/  229] train: loss: 0.1196912
[Epoch 75; Iter   124/  229] train: loss: 0.1290459
[Epoch 75; Iter   154/  229] train: loss: 0.1162047
[Epoch 75; Iter   184/  229] train: loss: 0.1664683
[Epoch 75; Iter   214/  229] train: loss: 0.1287358
[Epoch 75] ogbg-moltoxcast: 0.679460 val loss: 0.394581
[Epoch 75] ogbg-moltoxcast: 0.636664 test loss: 0.375468
[Epoch 60; Iter    19/  229] train: loss: 0.1715690
[Epoch 60; Iter    49/  229] train: loss: 0.1386514
[Epoch 60; Iter    79/  229] train: loss: 0.1157263
[Epoch 60; Iter   109/  229] train: loss: 0.1367929
[Epoch 60; Iter   139/  229] train: loss: 0.1357138
[Epoch 60; Iter   169/  229] train: loss: 0.1796944
[Epoch 60; Iter   199/  229] train: loss: 0.1026802
[Epoch 60; Iter   229/  229] train: loss: 0.1254373
[Epoch 60] ogbg-moltoxcast: 0.645125 val loss: 0.311298
[Epoch 60] ogbg-moltoxcast: 0.638204 test loss: 0.536217
[Epoch 61; Iter    30/  229] train: loss: 0.1295057
[Epoch 61; Iter    60/  229] train: loss: 0.1513295
[Epoch 61; Iter    90/  229] train: loss: 0.0984635
[Epoch 61; Iter   120/  229] train: loss: 0.1384148
[Epoch 61; Iter   150/  229] train: loss: 0.0978181
[Epoch 61; Iter   180/  229] train: loss: 0.1769006
[Epoch 61; Iter   210/  229] train: loss: 0.1137007
[Epoch 61] ogbg-moltoxcast: 0.655333 val loss: 0.305188
[Epoch 61] ogbg-moltoxcast: 0.635540 test loss: 0.538805
[Epoch 62; Iter    11/  229] train: loss: 0.1129770
[Epoch 62; Iter    41/  229] train: loss: 0.1729644
[Epoch 62; Iter    71/  229] train: loss: 0.1633853
[Epoch 62; Iter   101/  229] train: loss: 0.1841194
[Epoch 62; Iter   131/  229] train: loss: 0.1113114
[Epoch 62; Iter   161/  229] train: loss: 0.1291320
[Epoch 62; Iter   191/  229] train: loss: 0.0882112
[Epoch 62; Iter   221/  229] train: loss: 0.1872122
[Epoch 62] ogbg-moltoxcast: 0.658441 val loss: 0.311904
[Epoch 62] ogbg-moltoxcast: 0.637960 test loss: 0.616533
[Epoch 63; Iter    22/  229] train: loss: 0.1124541
[Epoch 63; Iter    52/  229] train: loss: 0.1173072
[Epoch 63; Iter    82/  229] train: loss: 0.0721229
[Epoch 63; Iter   112/  229] train: loss: 0.1291114
[Epoch 63; Iter   142/  229] train: loss: 0.1446050
[Epoch 63; Iter   172/  229] train: loss: 0.1748494
[Epoch 63; Iter   202/  229] train: loss: 0.1126499
[Epoch 63] ogbg-moltoxcast: 0.654060 val loss: 0.306055
[Epoch 63] ogbg-moltoxcast: 0.634488 test loss: 0.613945
[Epoch 64; Iter     3/  229] train: loss: 0.1392921
[Epoch 64; Iter    33/  229] train: loss: 0.1563408
[Epoch 64; Iter    63/  229] train: loss: 0.1286271
[Epoch 64; Iter    93/  229] train: loss: 0.1109073
[Epoch 64; Iter   123/  229] train: loss: 0.1421147
[Epoch 64; Iter   153/  229] train: loss: 0.1245195
[Epoch 64; Iter   183/  229] train: loss: 0.1784373
[Epoch 64; Iter   213/  229] train: loss: 0.1170976
[Epoch 64] ogbg-moltoxcast: 0.663294 val loss: 0.301145
[Epoch 64] ogbg-moltoxcast: 0.633147 test loss: 0.573116
[Epoch 65; Iter    14/  229] train: loss: 0.0943665
[Epoch 65; Iter    44/  229] train: loss: 0.1098922
[Epoch 65; Iter    74/  229] train: loss: 0.1004722
[Epoch 65; Iter   104/  229] train: loss: 0.1179685
[Epoch 65; Iter   134/  229] train: loss: 0.1729691
[Epoch 65; Iter   164/  229] train: loss: 0.1582067
[Epoch 65; Iter   194/  229] train: loss: 0.1269951
[Epoch 65; Iter   224/  229] train: loss: 0.1983670
[Epoch 65] ogbg-moltoxcast: 0.661401 val loss: 0.318379
[Epoch 65] ogbg-moltoxcast: 0.639159 test loss: 0.498230
[Epoch 66; Iter    25/  229] train: loss: 0.1105787
[Epoch 66; Iter    55/  229] train: loss: 0.1027838
[Epoch 66; Iter    85/  229] train: loss: 0.1419572
[Epoch 66; Iter   115/  229] train: loss: 0.1889038
[Epoch 66; Iter   145/  229] train: loss: 0.1143120
[Epoch 66; Iter   175/  229] train: loss: 0.1552303
[Epoch 66; Iter   205/  229] train: loss: 0.1531547
[Epoch 66] ogbg-moltoxcast: 0.642883 val loss: 0.312765
[Epoch 66] ogbg-moltoxcast: 0.633897 test loss: 0.553189
[Epoch 67; Iter     6/  229] train: loss: 0.1382039
[Epoch 67; Iter    36/  229] train: loss: 0.1546026
[Epoch 67; Iter    66/  229] train: loss: 0.1236853
[Epoch 67; Iter    96/  229] train: loss: 0.1195573
[Epoch 67; Iter   126/  229] train: loss: 0.1515995
[Epoch 67; Iter   156/  229] train: loss: 0.1531857
[Epoch 67; Iter   186/  229] train: loss: 0.1611850
[Epoch 67; Iter   216/  229] train: loss: 0.1304296
[Epoch 67] ogbg-moltoxcast: 0.652835 val loss: 0.300889
[Epoch 67] ogbg-moltoxcast: 0.637051 test loss: 0.578901
[Epoch 68; Iter    17/  229] train: loss: 0.1879722
[Epoch 68; Iter    47/  229] train: loss: 0.1114482
[Epoch 68; Iter    77/  229] train: loss: 0.1233822
[Epoch 68; Iter   107/  229] train: loss: 0.1279369
[Epoch 68; Iter   137/  229] train: loss: 0.1058580
[Epoch 68; Iter   167/  229] train: loss: 0.1116596
[Epoch 68; Iter   197/  229] train: loss: 0.1362166
[Epoch 68; Iter   227/  229] train: loss: 0.1281737
[Epoch 68] ogbg-moltoxcast: 0.654339 val loss: 0.295746
[Epoch 68] ogbg-moltoxcast: 0.635979 test loss: 0.485098
[Epoch 69; Iter    28/  229] train: loss: 0.1506169
[Epoch 69; Iter    58/  229] train: loss: 0.1886893
[Epoch 69; Iter    88/  229] train: loss: 0.0986900
[Epoch 69; Iter   118/  229] train: loss: 0.0913392
[Epoch 69; Iter   148/  229] train: loss: 0.1493815
[Epoch 69; Iter   178/  229] train: loss: 0.1543778
[Epoch 69; Iter   208/  229] train: loss: 0.0945306
[Epoch 69] ogbg-moltoxcast: 0.650527 val loss: 0.318167
[Epoch 69] ogbg-moltoxcast: 0.632241 test loss: 0.564904
[Epoch 70; Iter     9/  229] train: loss: 0.0967946
[Epoch 70; Iter    39/  229] train: loss: 0.1042152
[Epoch 70; Iter    69/  229] train: loss: 0.1205366
[Epoch 70; Iter    99/  229] train: loss: 0.1532277
[Epoch 70; Iter   129/  229] train: loss: 0.1265175
[Epoch 70; Iter   159/  229] train: loss: 0.1338135
[Epoch 70; Iter   189/  229] train: loss: 0.1487526
[Epoch 70; Iter   219/  229] train: loss: 0.1254888
[Epoch 70] ogbg-moltoxcast: 0.655805 val loss: 0.312132
[Epoch 70] ogbg-moltoxcast: 0.632500 test loss: 0.553590
[Epoch 71; Iter    20/  229] train: loss: 0.1476120
[Epoch 71; Iter    50/  229] train: loss: 0.1435949
[Epoch 71; Iter    80/  229] train: loss: 0.1057395
[Epoch 71; Iter   110/  229] train: loss: 0.1615712
[Epoch 71; Iter   140/  229] train: loss: 0.1280737
[Epoch 71; Iter   170/  229] train: loss: 0.0844778
[Epoch 71; Iter   200/  229] train: loss: 0.1156914
[Epoch 71] ogbg-moltoxcast: 0.656642 val loss: 0.321274
[Epoch 71] ogbg-moltoxcast: 0.636899 test loss: 0.589853
[Epoch 72; Iter     1/  229] train: loss: 0.1129003
[Epoch 72; Iter    31/  229] train: loss: 0.1710424
[Epoch 72; Iter    61/  229] train: loss: 0.1274497
[Epoch 72; Iter    91/  229] train: loss: 0.1493516
[Epoch 72; Iter   121/  229] train: loss: 0.1619485
[Epoch 72; Iter   151/  229] train: loss: 0.1701780
[Epoch 72; Iter   181/  229] train: loss: 0.1170315
[Epoch 72; Iter   211/  229] train: loss: 0.1358394
[Epoch 72] ogbg-moltoxcast: 0.651385 val loss: 0.307206
[Epoch 72] ogbg-moltoxcast: 0.636346 test loss: 0.558411
[Epoch 73; Iter    12/  229] train: loss: 0.1223256
[Epoch 73; Iter    42/  229] train: loss: 0.1743871
[Epoch 73; Iter    72/  229] train: loss: 0.1816864
[Epoch 73; Iter   102/  229] train: loss: 0.1123120
[Epoch 73; Iter   132/  229] train: loss: 0.1470753
[Epoch 73; Iter   162/  229] train: loss: 0.1376302
[Epoch 73; Iter   192/  229] train: loss: 0.1068482
[Epoch 73; Iter   222/  229] train: loss: 0.1280887
[Epoch 73] ogbg-moltoxcast: 0.659913 val loss: 0.306742
[Epoch 73] ogbg-moltoxcast: 0.633569 test loss: 0.481005
[Epoch 74; Iter    23/  229] train: loss: 0.1209200
[Epoch 74; Iter    53/  229] train: loss: 0.1157240
[Epoch 74; Iter    83/  229] train: loss: 0.0969414
[Epoch 74; Iter   113/  229] train: loss: 0.1141141
[Epoch 74; Iter   143/  229] train: loss: 0.1412229
[Epoch 74; Iter   173/  229] train: loss: 0.1054409
[Epoch 74; Iter   203/  229] train: loss: 0.1062569
[Epoch 74] ogbg-moltoxcast: 0.653542 val loss: 0.312400
[Epoch 74] ogbg-moltoxcast: 0.636152 test loss: 0.599315
[Epoch 75; Iter     4/  229] train: loss: 0.0952727
[Epoch 75; Iter    34/  229] train: loss: 0.1483665
[Epoch 75; Iter    64/  229] train: loss: 0.1462092
[Epoch 75; Iter    94/  229] train: loss: 0.1112575
[Epoch 75; Iter   124/  229] train: loss: 0.1255702
[Epoch 75; Iter   154/  229] train: loss: 0.1395338
[Epoch 75; Iter   184/  229] train: loss: 0.1364532
[Epoch 75; Iter   214/  229] train: loss: 0.1291853
[Epoch 75] ogbg-moltoxcast: 0.650507 val loss: 0.307768
[Epoch 75] ogbg-moltoxcast: 0.633940 test loss: 0.600333
[Epoch 60; Iter    19/  229] train: loss: 0.1444265
[Epoch 60; Iter    49/  229] train: loss: 0.1282335
[Epoch 60; Iter    79/  229] train: loss: 0.1058279
[Epoch 60; Iter   109/  229] train: loss: 0.1310565
[Epoch 60; Iter   139/  229] train: loss: 0.1275130
[Epoch 60; Iter   169/  229] train: loss: 0.1755211
[Epoch 60; Iter   199/  229] train: loss: 0.0983110
[Epoch 60; Iter   229/  229] train: loss: 0.1284961
[Epoch 60] ogbg-moltoxcast: 0.677542 val loss: 0.284066
[Epoch 60] ogbg-moltoxcast: 0.644143 test loss: 0.337075
[Epoch 61; Iter    30/  229] train: loss: 0.1257496
[Epoch 61; Iter    60/  229] train: loss: 0.1372745
[Epoch 61; Iter    90/  229] train: loss: 0.0872480
[Epoch 61; Iter   120/  229] train: loss: 0.1367693
[Epoch 61; Iter   150/  229] train: loss: 0.0979012
[Epoch 61; Iter   180/  229] train: loss: 0.1766282
[Epoch 61; Iter   210/  229] train: loss: 0.1111993
[Epoch 61] ogbg-moltoxcast: 0.685991 val loss: 0.295947
[Epoch 61] ogbg-moltoxcast: 0.644091 test loss: 0.348527
[Epoch 62; Iter    11/  229] train: loss: 0.1135527
[Epoch 62; Iter    41/  229] train: loss: 0.1617514
[Epoch 62; Iter    71/  229] train: loss: 0.1617215
[Epoch 62; Iter   101/  229] train: loss: 0.1805529
[Epoch 62; Iter   131/  229] train: loss: 0.1313293
[Epoch 62; Iter   161/  229] train: loss: 0.1216938
[Epoch 62; Iter   191/  229] train: loss: 0.0869246
[Epoch 62; Iter   221/  229] train: loss: 0.1851528
[Epoch 62] ogbg-moltoxcast: 0.683046 val loss: 0.288395
[Epoch 62] ogbg-moltoxcast: 0.647085 test loss: 0.341511
[Epoch 63; Iter    22/  229] train: loss: 0.0989337
[Epoch 63; Iter    52/  229] train: loss: 0.1273384
[Epoch 63; Iter    82/  229] train: loss: 0.0718256
[Epoch 63; Iter   112/  229] train: loss: 0.1287901
[Epoch 63; Iter   142/  229] train: loss: 0.1637442
[Epoch 63; Iter   172/  229] train: loss: 0.1716401
[Epoch 63; Iter   202/  229] train: loss: 0.1041133
[Epoch 63] ogbg-moltoxcast: 0.686646 val loss: 0.285466
[Epoch 63] ogbg-moltoxcast: 0.653481 test loss: 0.332549
[Epoch 64; Iter     3/  229] train: loss: 0.1304304
[Epoch 64; Iter    33/  229] train: loss: 0.1459718
[Epoch 64; Iter    63/  229] train: loss: 0.1170074
[Epoch 64; Iter    93/  229] train: loss: 0.1073894
[Epoch 64; Iter   123/  229] train: loss: 0.1376383
[Epoch 64; Iter   153/  229] train: loss: 0.1236250
[Epoch 64; Iter   183/  229] train: loss: 0.1811053
[Epoch 64; Iter   213/  229] train: loss: 0.1148589
[Epoch 64] ogbg-moltoxcast: 0.678991 val loss: 0.295558
[Epoch 64] ogbg-moltoxcast: 0.647708 test loss: 0.346009
[Epoch 65; Iter    14/  229] train: loss: 0.1010332
[Epoch 65; Iter    44/  229] train: loss: 0.1046183
[Epoch 65; Iter    74/  229] train: loss: 0.0986862
[Epoch 65; Iter   104/  229] train: loss: 0.1140461
[Epoch 65; Iter   134/  229] train: loss: 0.1799142
[Epoch 65; Iter   164/  229] train: loss: 0.1583630
[Epoch 65; Iter   194/  229] train: loss: 0.1367923
[Epoch 65; Iter   224/  229] train: loss: 0.1975292
[Epoch 65] ogbg-moltoxcast: 0.685257 val loss: 0.293929
[Epoch 65] ogbg-moltoxcast: 0.647156 test loss: 0.343126
[Epoch 66; Iter    25/  229] train: loss: 0.0928730
[Epoch 66; Iter    55/  229] train: loss: 0.1002660
[Epoch 66; Iter    85/  229] train: loss: 0.1438867
[Epoch 66; Iter   115/  229] train: loss: 0.1893213
[Epoch 66; Iter   145/  229] train: loss: 0.1121604
[Epoch 66; Iter   175/  229] train: loss: 0.1533192
[Epoch 66; Iter   205/  229] train: loss: 0.1577286
[Epoch 66] ogbg-moltoxcast: 0.675269 val loss: 0.301672
[Epoch 66] ogbg-moltoxcast: 0.644918 test loss: 0.343806
[Epoch 67; Iter     6/  229] train: loss: 0.1384034
[Epoch 67; Iter    36/  229] train: loss: 0.1541170
[Epoch 67; Iter    66/  229] train: loss: 0.1135324
[Epoch 67; Iter    96/  229] train: loss: 0.1192946
[Epoch 67; Iter   126/  229] train: loss: 0.1501067
[Epoch 67; Iter   156/  229] train: loss: 0.1624671
[Epoch 67; Iter   186/  229] train: loss: 0.1539324
[Epoch 67; Iter   216/  229] train: loss: 0.1266017
[Epoch 67] ogbg-moltoxcast: 0.683998 val loss: 0.303766
[Epoch 67] ogbg-moltoxcast: 0.652768 test loss: 0.345308
[Epoch 68; Iter    17/  229] train: loss: 0.1753392
[Epoch 68; Iter    47/  229] train: loss: 0.1099909
[Epoch 68; Iter    77/  229] train: loss: 0.1240351
[Epoch 68; Iter   107/  229] train: loss: 0.1196755
[Epoch 68; Iter   137/  229] train: loss: 0.1028863
[Epoch 68; Iter   167/  229] train: loss: 0.1006005
[Epoch 68; Iter   197/  229] train: loss: 0.1228576
[Epoch 68; Iter   227/  229] train: loss: 0.1103034
[Epoch 68] ogbg-moltoxcast: 0.684605 val loss: 0.290286
[Epoch 68] ogbg-moltoxcast: 0.650713 test loss: 0.337499
[Epoch 69; Iter    28/  229] train: loss: 0.1376974
[Epoch 69; Iter    58/  229] train: loss: 0.1727121
[Epoch 69; Iter    88/  229] train: loss: 0.0956160
[Epoch 69; Iter   118/  229] train: loss: 0.0838061
[Epoch 69; Iter   148/  229] train: loss: 0.1408653
[Epoch 69; Iter   178/  229] train: loss: 0.1498114
[Epoch 69; Iter   208/  229] train: loss: 0.0879758
[Epoch 69] ogbg-moltoxcast: 0.684656 val loss: 0.294234
[Epoch 69] ogbg-moltoxcast: 0.650884 test loss: 0.341241
[Epoch 70; Iter     9/  229] train: loss: 0.0894886
[Epoch 70; Iter    39/  229] train: loss: 0.1023221
[Epoch 70; Iter    69/  229] train: loss: 0.1131835
[Epoch 70; Iter    99/  229] train: loss: 0.1393191
[Epoch 70; Iter   129/  229] train: loss: 0.1255165
[Epoch 70; Iter   159/  229] train: loss: 0.1245836
[Epoch 70; Iter   189/  229] train: loss: 0.1384152
[Epoch 70; Iter   219/  229] train: loss: 0.1194120
[Epoch 70] ogbg-moltoxcast: 0.681742 val loss: 0.306471
[Epoch 70] ogbg-moltoxcast: 0.645874 test loss: 0.351584
[Epoch 71; Iter    20/  229] train: loss: 0.1271786
[Epoch 71; Iter    50/  229] train: loss: 0.1359891
[Epoch 71; Iter    80/  229] train: loss: 0.1029486
[Epoch 71; Iter   110/  229] train: loss: 0.1481142
[Epoch 71; Iter   140/  229] train: loss: 0.1150903
[Epoch 71; Iter   170/  229] train: loss: 0.0834846
[Epoch 71; Iter   200/  229] train: loss: 0.1171773
[Epoch 71] ogbg-moltoxcast: 0.677692 val loss: 0.301955
[Epoch 71] ogbg-moltoxcast: 0.645922 test loss: 0.349828
[Epoch 72; Iter     1/  229] train: loss: 0.1016681
[Epoch 72; Iter    31/  229] train: loss: 0.1581357
[Epoch 72; Iter    61/  229] train: loss: 0.1200391
[Epoch 72; Iter    91/  229] train: loss: 0.1324595
[Epoch 72; Iter   121/  229] train: loss: 0.1489585
[Epoch 72; Iter   151/  229] train: loss: 0.1654981
[Epoch 72; Iter   181/  229] train: loss: 0.1105106
[Epoch 72; Iter   211/  229] train: loss: 0.1222662
[Epoch 72] ogbg-moltoxcast: 0.678717 val loss: 0.300527
[Epoch 72] ogbg-moltoxcast: 0.643524 test loss: 0.346487
[Epoch 73; Iter    12/  229] train: loss: 0.1172892
[Epoch 73; Iter    42/  229] train: loss: 0.1675176
[Epoch 73; Iter    72/  229] train: loss: 0.1765602
[Epoch 73; Iter   102/  229] train: loss: 0.1028970
[Epoch 73; Iter   132/  229] train: loss: 0.1281332
[Epoch 73; Iter   162/  229] train: loss: 0.1306264
[Epoch 73; Iter   192/  229] train: loss: 0.0994470
[Epoch 73; Iter   222/  229] train: loss: 0.1203451
[Epoch 73] ogbg-moltoxcast: 0.679350 val loss: 0.300703
[Epoch 73] ogbg-moltoxcast: 0.646806 test loss: 0.344369
[Epoch 74; Iter    23/  229] train: loss: 0.1115508
[Epoch 74; Iter    53/  229] train: loss: 0.1132933
[Epoch 74; Iter    83/  229] train: loss: 0.0895083
[Epoch 74; Iter   113/  229] train: loss: 0.1125311
[Epoch 74; Iter   143/  229] train: loss: 0.1359531
[Epoch 74; Iter   173/  229] train: loss: 0.1064257
[Epoch 74; Iter   203/  229] train: loss: 0.0925571
[Epoch 74] ogbg-moltoxcast: 0.679058 val loss: 0.307330
[Epoch 74] ogbg-moltoxcast: 0.645618 test loss: 0.352162
[Epoch 75; Iter     4/  229] train: loss: 0.0900579
[Epoch 75; Iter    34/  229] train: loss: 0.1394762
[Epoch 75; Iter    64/  229] train: loss: 0.1325363
[Epoch 75; Iter    94/  229] train: loss: 0.1033339
[Epoch 75; Iter   124/  229] train: loss: 0.1244745
[Epoch 75; Iter   154/  229] train: loss: 0.1351436
[Epoch 75; Iter   184/  229] train: loss: 0.1194855
[Epoch 75; Iter   214/  229] train: loss: 0.1236165
[Epoch 75] ogbg-moltoxcast: 0.675407 val loss: 0.302942
[Epoch 75] ogbg-moltoxcast: 0.639782 test loss: 0.348879
[Epoch 60; Iter    19/  229] train: loss: 0.1415990
[Epoch 60; Iter    49/  229] train: loss: 0.1290946
[Epoch 60; Iter    79/  229] train: loss: 0.1088271
[Epoch 60; Iter   109/  229] train: loss: 0.1278007
[Epoch 60; Iter   139/  229] train: loss: 0.1203706
[Epoch 60; Iter   169/  229] train: loss: 0.1729440
[Epoch 60; Iter   199/  229] train: loss: 0.0932092
[Epoch 60; Iter   229/  229] train: loss: 0.1155369
[Epoch 60] ogbg-moltoxcast: 0.664636 val loss: 0.306419
[Epoch 60] ogbg-moltoxcast: 0.662285 test loss: 0.346805
[Epoch 61; Iter    30/  229] train: loss: 0.1137640
[Epoch 61; Iter    60/  229] train: loss: 0.1461554
[Epoch 61; Iter    90/  229] train: loss: 0.0854861
[Epoch 61; Iter   120/  229] train: loss: 0.1334518
[Epoch 61; Iter   150/  229] train: loss: 0.0913180
[Epoch 61; Iter   180/  229] train: loss: 0.1697232
[Epoch 61; Iter   210/  229] train: loss: 0.1161189
[Epoch 61] ogbg-moltoxcast: 0.663365 val loss: 0.306478
[Epoch 61] ogbg-moltoxcast: 0.664172 test loss: 0.343268
[Epoch 62; Iter    11/  229] train: loss: 0.1250455
[Epoch 62; Iter    41/  229] train: loss: 0.1620043
[Epoch 62; Iter    71/  229] train: loss: 0.1559889
[Epoch 62; Iter   101/  229] train: loss: 0.1766697
[Epoch 62; Iter   131/  229] train: loss: 0.1112975
[Epoch 62; Iter   161/  229] train: loss: 0.1137006
[Epoch 62; Iter   191/  229] train: loss: 0.0872916
[Epoch 62; Iter   221/  229] train: loss: 0.1780338
[Epoch 62] ogbg-moltoxcast: 0.666868 val loss: 0.312448
[Epoch 62] ogbg-moltoxcast: 0.661864 test loss: 0.347174
[Epoch 63; Iter    22/  229] train: loss: 0.1046403
[Epoch 63; Iter    52/  229] train: loss: 0.1212402
[Epoch 63; Iter    82/  229] train: loss: 0.0718213
[Epoch 63; Iter   112/  229] train: loss: 0.1206033
[Epoch 63; Iter   142/  229] train: loss: 0.1445647
[Epoch 63; Iter   172/  229] train: loss: 0.1586828
[Epoch 63; Iter   202/  229] train: loss: 0.1074803
[Epoch 63] ogbg-moltoxcast: 0.669082 val loss: 0.300857
[Epoch 63] ogbg-moltoxcast: 0.662792 test loss: 0.343224
[Epoch 64; Iter     3/  229] train: loss: 0.1327363
[Epoch 64; Iter    33/  229] train: loss: 0.1389005
[Epoch 64; Iter    63/  229] train: loss: 0.1089379
[Epoch 64; Iter    93/  229] train: loss: 0.1052398
[Epoch 64; Iter   123/  229] train: loss: 0.1321263
[Epoch 64; Iter   153/  229] train: loss: 0.1240302
[Epoch 64; Iter   183/  229] train: loss: 0.1655019
[Epoch 64; Iter   213/  229] train: loss: 0.1152986
[Epoch 64] ogbg-moltoxcast: 0.669984 val loss: 0.307171
[Epoch 64] ogbg-moltoxcast: 0.663231 test loss: 0.346893
[Epoch 65; Iter    14/  229] train: loss: 0.0922491
[Epoch 65; Iter    44/  229] train: loss: 0.0981648
[Epoch 65; Iter    74/  229] train: loss: 0.0950489
[Epoch 65; Iter   104/  229] train: loss: 0.1030686
[Epoch 65; Iter   134/  229] train: loss: 0.1587389
[Epoch 65; Iter   164/  229] train: loss: 0.1496159
[Epoch 65; Iter   194/  229] train: loss: 0.1249938
[Epoch 65; Iter   224/  229] train: loss: 0.1871750
[Epoch 65] ogbg-moltoxcast: 0.667968 val loss: 0.315774
[Epoch 65] ogbg-moltoxcast: 0.660361 test loss: 0.359203
[Epoch 66; Iter    25/  229] train: loss: 0.0935538
[Epoch 66; Iter    55/  229] train: loss: 0.0898086
[Epoch 66; Iter    85/  229] train: loss: 0.1412157
[Epoch 66; Iter   115/  229] train: loss: 0.1684639
[Epoch 66; Iter   145/  229] train: loss: 0.1066602
[Epoch 66; Iter   175/  229] train: loss: 0.1408327
[Epoch 66; Iter   205/  229] train: loss: 0.1544488
[Epoch 66] ogbg-moltoxcast: 0.670378 val loss: 0.309419
[Epoch 66] ogbg-moltoxcast: 0.658881 test loss: 0.354380
[Epoch 67; Iter     6/  229] train: loss: 0.1284597
[Epoch 67; Iter    36/  229] train: loss: 0.1422425
[Epoch 67; Iter    66/  229] train: loss: 0.1092657
[Epoch 67; Iter    96/  229] train: loss: 0.1084980
[Epoch 67; Iter   126/  229] train: loss: 0.1376447
[Epoch 67; Iter   156/  229] train: loss: 0.1496070
[Epoch 67; Iter   186/  229] train: loss: 0.1535781
[Epoch 67; Iter   216/  229] train: loss: 0.1196370
[Epoch 67] ogbg-moltoxcast: 0.668950 val loss: 0.305626
[Epoch 67] ogbg-moltoxcast: 0.662107 test loss: 0.352000
[Epoch 68; Iter    17/  229] train: loss: 0.1731193
[Epoch 68; Iter    47/  229] train: loss: 0.1016582
[Epoch 68; Iter    77/  229] train: loss: 0.1131672
[Epoch 68; Iter   107/  229] train: loss: 0.1238035
[Epoch 68; Iter   137/  229] train: loss: 0.0987769
[Epoch 68; Iter   167/  229] train: loss: 0.1005743
[Epoch 68; Iter   197/  229] train: loss: 0.1316144
[Epoch 68; Iter   227/  229] train: loss: 0.1147446
[Epoch 68] ogbg-moltoxcast: 0.670404 val loss: 0.304820
[Epoch 68] ogbg-moltoxcast: 0.658619 test loss: 0.350863
[Epoch 69; Iter    28/  229] train: loss: 0.1392901
[Epoch 69; Iter    58/  229] train: loss: 0.1673026
[Epoch 69; Iter    88/  229] train: loss: 0.0952647
[Epoch 69; Iter   118/  229] train: loss: 0.0857572
[Epoch 69; Iter   148/  229] train: loss: 0.1380326
[Epoch 69; Iter   178/  229] train: loss: 0.1425649
[Epoch 69; Iter   208/  229] train: loss: 0.0826450
[Epoch 69] ogbg-moltoxcast: 0.667484 val loss: 0.312384
[Epoch 69] ogbg-moltoxcast: 0.658675 test loss: 0.356174
[Epoch 70; Iter     9/  229] train: loss: 0.0901200
[Epoch 70; Iter    39/  229] train: loss: 0.1002350
[Epoch 70; Iter    69/  229] train: loss: 0.1114735
[Epoch 70; Iter    99/  229] train: loss: 0.1361943
[Epoch 70; Iter   129/  229] train: loss: 0.1240309
[Epoch 70; Iter   159/  229] train: loss: 0.1260249
[Epoch 70; Iter   189/  229] train: loss: 0.1380794
[Epoch 70; Iter   219/  229] train: loss: 0.1225643
[Epoch 70] ogbg-moltoxcast: 0.664457 val loss: 0.318193
[Epoch 70] ogbg-moltoxcast: 0.656697 test loss: 0.365142
[Epoch 71; Iter    20/  229] train: loss: 0.1340467
[Epoch 71; Iter    50/  229] train: loss: 0.1355873
[Epoch 71; Iter    80/  229] train: loss: 0.0997185
[Epoch 71; Iter   110/  229] train: loss: 0.1440393
[Epoch 71; Iter   140/  229] train: loss: 0.1162820
[Epoch 71; Iter   170/  229] train: loss: 0.0763550
[Epoch 71; Iter   200/  229] train: loss: 0.1164907
[Epoch 71] ogbg-moltoxcast: 0.661397 val loss: 0.314689
[Epoch 71] ogbg-moltoxcast: 0.658637 test loss: 0.357484
[Epoch 72; Iter     1/  229] train: loss: 0.1036415
[Epoch 72; Iter    31/  229] train: loss: 0.1571494
[Epoch 72; Iter    61/  229] train: loss: 0.1149824
[Epoch 72; Iter    91/  229] train: loss: 0.1299384
[Epoch 72; Iter   121/  229] train: loss: 0.1501869
[Epoch 72; Iter   151/  229] train: loss: 0.1589159
[Epoch 72; Iter   181/  229] train: loss: 0.1056914
[Epoch 72; Iter   211/  229] train: loss: 0.1247867
[Epoch 72] ogbg-moltoxcast: 0.664282 val loss: 0.308367
[Epoch 72] ogbg-moltoxcast: 0.659998 test loss: 0.352130
[Epoch 73; Iter    12/  229] train: loss: 0.1134812
[Epoch 73; Iter    42/  229] train: loss: 0.1583558
[Epoch 73; Iter    72/  229] train: loss: 0.1737646
[Epoch 73; Iter   102/  229] train: loss: 0.0972982
[Epoch 73; Iter   132/  229] train: loss: 0.1356982
[Epoch 73; Iter   162/  229] train: loss: 0.1312571
[Epoch 73; Iter   192/  229] train: loss: 0.1023283
[Epoch 73; Iter   222/  229] train: loss: 0.1190306
[Epoch 73] ogbg-moltoxcast: 0.666372 val loss: 0.312239
[Epoch 73] ogbg-moltoxcast: 0.663668 test loss: 0.354503
[Epoch 74; Iter    23/  229] train: loss: 0.1114457
[Epoch 74; Iter    53/  229] train: loss: 0.1065502
[Epoch 74; Iter    83/  229] train: loss: 0.0897983
[Epoch 74; Iter   113/  229] train: loss: 0.1092363
[Epoch 74; Iter   143/  229] train: loss: 0.1369319
[Epoch 74; Iter   173/  229] train: loss: 0.1031104
[Epoch 74; Iter   203/  229] train: loss: 0.0954176
[Epoch 74] ogbg-moltoxcast: 0.661144 val loss: 0.313371
[Epoch 74] ogbg-moltoxcast: 0.658834 test loss: 0.356297
[Epoch 75; Iter     4/  229] train: loss: 0.0907123
[Epoch 75; Iter    34/  229] train: loss: 0.1349606
[Epoch 75; Iter    64/  229] train: loss: 0.1309039
[Epoch 75; Iter    94/  229] train: loss: 0.1040715
[Epoch 75; Iter   124/  229] train: loss: 0.1271800
[Epoch 75; Iter   154/  229] train: loss: 0.1349117
[Epoch 75; Iter   184/  229] train: loss: 0.1202705
[Epoch 75; Iter   214/  229] train: loss: 0.1203547
[Epoch 75] ogbg-moltoxcast: 0.669234 val loss: 0.307359
[Epoch 75] ogbg-moltoxcast: 0.662785 test loss: 0.351518
[Epoch 60; Iter    19/  229] train: loss: 0.1088659
[Epoch 60; Iter    49/  229] train: loss: 0.1135476
[Epoch 60; Iter    79/  229] train: loss: 0.2033007
[Epoch 60; Iter   109/  229] train: loss: 0.2197911
[Epoch 60; Iter   139/  229] train: loss: 0.1523975
[Epoch 60; Iter   169/  229] train: loss: 0.1328586
[Epoch 60; Iter   199/  229] train: loss: 0.1634862
[Epoch 60; Iter   229/  229] train: loss: 0.1314239
[Epoch 60] ogbg-moltoxcast: 0.664477 val loss: 0.300848
[Epoch 60] ogbg-moltoxcast: 0.651853 test loss: 0.337684
[Epoch 61; Iter    30/  229] train: loss: 0.1294239
[Epoch 61; Iter    60/  229] train: loss: 0.1549362
[Epoch 61; Iter    90/  229] train: loss: 0.0839841
[Epoch 61; Iter   120/  229] train: loss: 0.0842827
[Epoch 61; Iter   150/  229] train: loss: 0.1516771
[Epoch 61; Iter   180/  229] train: loss: 0.0955549
[Epoch 61; Iter   210/  229] train: loss: 0.0980260
[Epoch 61] ogbg-moltoxcast: 0.663955 val loss: 0.294686
[Epoch 61] ogbg-moltoxcast: 0.651034 test loss: 0.345876
[Epoch 62; Iter    11/  229] train: loss: 0.1043207
[Epoch 62; Iter    41/  229] train: loss: 0.1273767
[Epoch 62; Iter    71/  229] train: loss: 0.1005101
[Epoch 62; Iter   101/  229] train: loss: 0.1146521
[Epoch 62; Iter   131/  229] train: loss: 0.1007357
[Epoch 62; Iter   161/  229] train: loss: 0.1169432
[Epoch 62; Iter   191/  229] train: loss: 0.1128004
[Epoch 62; Iter   221/  229] train: loss: 0.1220590
[Epoch 62] ogbg-moltoxcast: 0.654902 val loss: 0.295345
[Epoch 62] ogbg-moltoxcast: 0.646493 test loss: 0.344650
[Epoch 63; Iter    22/  229] train: loss: 0.1521054
[Epoch 63; Iter    52/  229] train: loss: 0.1480255
[Epoch 63; Iter    82/  229] train: loss: 0.0993104
[Epoch 63; Iter   112/  229] train: loss: 0.1164888
[Epoch 63; Iter   142/  229] train: loss: 0.1116639
[Epoch 63; Iter   172/  229] train: loss: 0.1557557
[Epoch 63; Iter   202/  229] train: loss: 0.0856868
[Epoch 63] ogbg-moltoxcast: 0.660224 val loss: 0.292833
[Epoch 63] ogbg-moltoxcast: 0.644320 test loss: 0.342524
[Epoch 64; Iter     3/  229] train: loss: 0.1968612
[Epoch 64; Iter    33/  229] train: loss: 0.1282155
[Epoch 64; Iter    63/  229] train: loss: 0.1677922
[Epoch 64; Iter    93/  229] train: loss: 0.1771557
[Epoch 64; Iter   123/  229] train: loss: 0.1418233
[Epoch 64; Iter   153/  229] train: loss: 0.1541406
[Epoch 64; Iter   183/  229] train: loss: 0.1690876
[Epoch 64; Iter   213/  229] train: loss: 0.0984859
[Epoch 64] ogbg-moltoxcast: 0.656497 val loss: 0.293666
[Epoch 64] ogbg-moltoxcast: 0.652508 test loss: 0.338927
[Epoch 65; Iter    14/  229] train: loss: 0.0946296
[Epoch 65; Iter    44/  229] train: loss: 0.1198148
[Epoch 65; Iter    74/  229] train: loss: 0.1209926
[Epoch 65; Iter   104/  229] train: loss: 0.1157111
[Epoch 65; Iter   134/  229] train: loss: 0.0894201
[Epoch 65; Iter   164/  229] train: loss: 0.1263285
[Epoch 65; Iter   194/  229] train: loss: 0.0958525
[Epoch 65; Iter   224/  229] train: loss: 0.1265154
[Epoch 65] ogbg-moltoxcast: 0.659898 val loss: 0.299447
[Epoch 65] ogbg-moltoxcast: 0.654498 test loss: 0.343410
[Epoch 66; Iter    25/  229] train: loss: 0.1131859
[Epoch 66; Iter    55/  229] train: loss: 0.1560271
[Epoch 66; Iter    85/  229] train: loss: 0.0957624
[Epoch 66; Iter   115/  229] train: loss: 0.1473075
[Epoch 66; Iter   145/  229] train: loss: 0.1103892
[Epoch 66; Iter   175/  229] train: loss: 0.0881159
[Epoch 66; Iter   205/  229] train: loss: 0.1533487
[Epoch 66] ogbg-moltoxcast: 0.660663 val loss: 0.295078
[Epoch 66] ogbg-moltoxcast: 0.653208 test loss: 0.342158
[Epoch 67; Iter     6/  229] train: loss: 0.0694798
[Epoch 67; Iter    36/  229] train: loss: 0.1053764
[Epoch 67; Iter    66/  229] train: loss: 0.1359967
[Epoch 67; Iter    96/  229] train: loss: 0.1048002
[Epoch 67; Iter   126/  229] train: loss: 0.1533090
[Epoch 67; Iter   156/  229] train: loss: 0.0972015
[Epoch 67; Iter   186/  229] train: loss: 0.1091355
[Epoch 67; Iter   216/  229] train: loss: 0.0950466
[Epoch 67] ogbg-moltoxcast: 0.662941 val loss: 0.296189
[Epoch 67] ogbg-moltoxcast: 0.651115 test loss: 0.347212
[Epoch 68; Iter    17/  229] train: loss: 0.1261570
[Epoch 68; Iter    47/  229] train: loss: 0.1307598
[Epoch 68; Iter    77/  229] train: loss: 0.1667656
[Epoch 68; Iter   107/  229] train: loss: 0.1158542
[Epoch 68; Iter   137/  229] train: loss: 0.1106835
[Epoch 68; Iter   167/  229] train: loss: 0.1428725
[Epoch 68; Iter   197/  229] train: loss: 0.1256457
[Epoch 68; Iter   227/  229] train: loss: 0.1277896
[Epoch 68] ogbg-moltoxcast: 0.655290 val loss: 0.306909
[Epoch 68] ogbg-moltoxcast: 0.648577 test loss: 0.355247
[Epoch 69; Iter    28/  229] train: loss: 0.1554140
[Epoch 69; Iter    58/  229] train: loss: 0.1466017
[Epoch 69; Iter    88/  229] train: loss: 0.1378509
[Epoch 69; Iter   118/  229] train: loss: 0.1650605
[Epoch 69; Iter   148/  229] train: loss: 0.1565085
[Epoch 69; Iter   178/  229] train: loss: 0.0901180
[Epoch 69; Iter   208/  229] train: loss: 0.1004530
[Epoch 69] ogbg-moltoxcast: 0.657427 val loss: 0.292856
[Epoch 69] ogbg-moltoxcast: 0.649481 test loss: 0.341822
[Epoch 70; Iter     9/  229] train: loss: 0.1485294
[Epoch 70; Iter    39/  229] train: loss: 0.1276958
[Epoch 70; Iter    69/  229] train: loss: 0.1253261
[Epoch 70; Iter    99/  229] train: loss: 0.1668353
[Epoch 70; Iter   129/  229] train: loss: 0.1393902
[Epoch 70; Iter   159/  229] train: loss: 0.1113755
[Epoch 70; Iter   189/  229] train: loss: 0.1023703
[Epoch 70; Iter   219/  229] train: loss: 0.1748322
[Epoch 70] ogbg-moltoxcast: 0.658873 val loss: 0.301594
[Epoch 70] ogbg-moltoxcast: 0.648593 test loss: 0.352472
[Epoch 71; Iter    20/  229] train: loss: 0.1248074
[Epoch 71; Iter    50/  229] train: loss: 0.0909214
[Epoch 71; Iter    80/  229] train: loss: 0.1472521
[Epoch 71; Iter   110/  229] train: loss: 0.1367577
[Epoch 71; Iter   140/  229] train: loss: 0.1312183
[Epoch 71; Iter   170/  229] train: loss: 0.1480346
[Epoch 71; Iter   200/  229] train: loss: 0.1184320
[Epoch 71] ogbg-moltoxcast: 0.659633 val loss: 0.294995
[Epoch 71] ogbg-moltoxcast: 0.645384 test loss: 0.344138
[Epoch 72; Iter     1/  229] train: loss: 0.1323385
[Epoch 72; Iter    31/  229] train: loss: 0.1308183
[Epoch 72; Iter    61/  229] train: loss: 0.1528432
[Epoch 72; Iter    91/  229] train: loss: 0.1000007
[Epoch 72; Iter   121/  229] train: loss: 0.0870757
[Epoch 72; Iter   151/  229] train: loss: 0.1451540
[Epoch 72; Iter   181/  229] train: loss: 0.1812411
[Epoch 72; Iter   211/  229] train: loss: 0.0903410
[Epoch 72] ogbg-moltoxcast: 0.662475 val loss: 0.298694
[Epoch 72] ogbg-moltoxcast: 0.648250 test loss: 0.348461
[Epoch 73; Iter    12/  229] train: loss: 0.0998259
[Epoch 73; Iter    42/  229] train: loss: 0.1329509
[Epoch 73; Iter    72/  229] train: loss: 0.1532020
[Epoch 73; Iter   102/  229] train: loss: 0.1412149
[Epoch 73; Iter   132/  229] train: loss: 0.1150660
[Epoch 73; Iter   162/  229] train: loss: 0.1300928
[Epoch 73; Iter   192/  229] train: loss: 0.0981392
[Epoch 73; Iter   222/  229] train: loss: 0.1155964
[Epoch 73] ogbg-moltoxcast: 0.653744 val loss: 0.305901
[Epoch 73] ogbg-moltoxcast: 0.650242 test loss: 0.354086
[Epoch 74; Iter    23/  229] train: loss: 0.0796445
[Epoch 74; Iter    53/  229] train: loss: 0.1282542
[Epoch 74; Iter    83/  229] train: loss: 0.1154691
[Epoch 74; Iter   113/  229] train: loss: 0.0915413
[Epoch 74; Iter   143/  229] train: loss: 0.1180568
[Epoch 74; Iter   173/  229] train: loss: 0.1242145
[Epoch 74; Iter   203/  229] train: loss: 0.1273902
[Epoch 74] ogbg-moltoxcast: 0.652286 val loss: 0.297344
[Epoch 74] ogbg-moltoxcast: 0.641401 test loss: 0.348802
[Epoch 75; Iter     4/  229] train: loss: 0.0810066
[Epoch 75; Iter    34/  229] train: loss: 0.1414817
[Epoch 75; Iter    64/  229] train: loss: 0.1667037
[Epoch 75; Iter    94/  229] train: loss: 0.1233000
[Epoch 75; Iter   124/  229] train: loss: 0.1238748
[Epoch 75; Iter   154/  229] train: loss: 0.1170731
[Epoch 75; Iter   184/  229] train: loss: 0.1671541
[Epoch 75; Iter   214/  229] train: loss: 0.1208092
[Epoch 75] ogbg-moltoxcast: 0.652479 val loss: 0.299050
[Epoch 75] ogbg-moltoxcast: 0.641302 test loss: 0.347868
[Epoch 60; Iter    19/  229] train: loss: 0.1020836
[Epoch 60; Iter    49/  229] train: loss: 0.1298151
[Epoch 60; Iter    79/  229] train: loss: 0.1609076
[Epoch 60; Iter   109/  229] train: loss: 0.1137698
[Epoch 60; Iter   139/  229] train: loss: 0.1320293
[Epoch 60; Iter   169/  229] train: loss: 0.0960020
[Epoch 60; Iter   199/  229] train: loss: 0.1672166
[Epoch 60; Iter   229/  229] train: loss: 0.1331454
[Epoch 60] ogbg-moltoxcast: 0.680695 val loss: 0.280936
[Epoch 60] ogbg-moltoxcast: 0.647753 test loss: 0.333796
[Epoch 61; Iter    30/  229] train: loss: 0.1480004
[Epoch 61; Iter    60/  229] train: loss: 0.1489177
[Epoch 61; Iter    90/  229] train: loss: 0.1690887
[Epoch 61; Iter   120/  229] train: loss: 0.1395971
[Epoch 61; Iter   150/  229] train: loss: 0.1385939
[Epoch 61; Iter   180/  229] train: loss: 0.1639291
[Epoch 61; Iter   210/  229] train: loss: 0.0883941
[Epoch 61] ogbg-moltoxcast: 0.686366 val loss: 0.285353
[Epoch 61] ogbg-moltoxcast: 0.650993 test loss: 0.342278
[Epoch 62; Iter    11/  229] train: loss: 0.0862740
[Epoch 62; Iter    41/  229] train: loss: 0.1756243
[Epoch 62; Iter    71/  229] train: loss: 0.1420739
[Epoch 62; Iter   101/  229] train: loss: 0.1343899
[Epoch 62; Iter   131/  229] train: loss: 0.1545028
[Epoch 62; Iter   161/  229] train: loss: 0.1195135
[Epoch 62; Iter   191/  229] train: loss: 0.1330574
[Epoch 62; Iter   221/  229] train: loss: 0.1480029
[Epoch 62] ogbg-moltoxcast: 0.682045 val loss: 0.294335
[Epoch 62] ogbg-moltoxcast: 0.649554 test loss: 0.350294
[Epoch 63; Iter    22/  229] train: loss: 0.1352723
[Epoch 63; Iter    52/  229] train: loss: 0.0801900
[Epoch 63; Iter    82/  229] train: loss: 0.0863360
[Epoch 63; Iter   112/  229] train: loss: 0.0904274
[Epoch 63; Iter   142/  229] train: loss: 0.1557912
[Epoch 63; Iter   172/  229] train: loss: 0.1696781
[Epoch 63; Iter   202/  229] train: loss: 0.1134245
[Epoch 63] ogbg-moltoxcast: 0.684243 val loss: 0.290105
[Epoch 63] ogbg-moltoxcast: 0.648437 test loss: 0.346892
[Epoch 64; Iter     3/  229] train: loss: 0.0788691
[Epoch 64; Iter    33/  229] train: loss: 0.1295394
[Epoch 64; Iter    63/  229] train: loss: 0.1291129
[Epoch 64; Iter    93/  229] train: loss: 0.1104761
[Epoch 64; Iter   123/  229] train: loss: 0.1118354
[Epoch 64; Iter   153/  229] train: loss: 0.1036648
[Epoch 64; Iter   183/  229] train: loss: 0.1037592
[Epoch 64; Iter   213/  229] train: loss: 0.1422530
[Epoch 64] ogbg-moltoxcast: 0.682995 val loss: 0.289942
[Epoch 64] ogbg-moltoxcast: 0.642443 test loss: 0.344945
[Epoch 65; Iter    14/  229] train: loss: 0.1396305
[Epoch 65; Iter    44/  229] train: loss: 0.1422164
[Epoch 65; Iter    74/  229] train: loss: 0.1272617
[Epoch 65; Iter   104/  229] train: loss: 0.1484042
[Epoch 65; Iter   134/  229] train: loss: 0.1194228
[Epoch 65; Iter   164/  229] train: loss: 0.1406352
[Epoch 65; Iter   194/  229] train: loss: 0.1015877
[Epoch 65; Iter   224/  229] train: loss: 0.1362401
[Epoch 65] ogbg-moltoxcast: 0.688812 val loss: 0.286203
[Epoch 65] ogbg-moltoxcast: 0.646924 test loss: 0.342195
[Epoch 66; Iter    25/  229] train: loss: 0.1157847
[Epoch 66; Iter    55/  229] train: loss: 0.1585838
[Epoch 66; Iter    85/  229] train: loss: 0.1273261
[Epoch 66; Iter   115/  229] train: loss: 0.1041451
[Epoch 66; Iter   145/  229] train: loss: 0.0998685
[Epoch 66; Iter   175/  229] train: loss: 0.1320286
[Epoch 66; Iter   205/  229] train: loss: 0.1073593
[Epoch 66] ogbg-moltoxcast: 0.681953 val loss: 0.290978
[Epoch 66] ogbg-moltoxcast: 0.643556 test loss: 0.349116
[Epoch 67; Iter     6/  229] train: loss: 0.1314187
[Epoch 67; Iter    36/  229] train: loss: 0.1573283
[Epoch 67; Iter    66/  229] train: loss: 0.1005030
[Epoch 67; Iter    96/  229] train: loss: 0.1611011
[Epoch 67; Iter   126/  229] train: loss: 0.1049873
[Epoch 67; Iter   156/  229] train: loss: 0.1023743
[Epoch 67; Iter   186/  229] train: loss: 0.1008141
[Epoch 67; Iter   216/  229] train: loss: 0.1011000
[Epoch 67] ogbg-moltoxcast: 0.680953 val loss: 0.291061
[Epoch 67] ogbg-moltoxcast: 0.644426 test loss: 0.348977
[Epoch 68; Iter    17/  229] train: loss: 0.1613744
[Epoch 68; Iter    47/  229] train: loss: 0.1094449
[Epoch 68; Iter    77/  229] train: loss: 0.1126618
[Epoch 68; Iter   107/  229] train: loss: 0.1494300
[Epoch 68; Iter   137/  229] train: loss: 0.1029141
[Epoch 68; Iter   167/  229] train: loss: 0.0989364
[Epoch 68; Iter   197/  229] train: loss: 0.1428139
[Epoch 68; Iter   227/  229] train: loss: 0.1367764
[Epoch 68] ogbg-moltoxcast: 0.677924 val loss: 0.303642
[Epoch 68] ogbg-moltoxcast: 0.649088 test loss: 0.348132
[Epoch 69; Iter    28/  229] train: loss: 0.1289592
[Epoch 69; Iter    58/  229] train: loss: 0.0858347
[Epoch 69; Iter    88/  229] train: loss: 0.1127075
[Epoch 69; Iter   118/  229] train: loss: 0.1168259
[Epoch 69; Iter   148/  229] train: loss: 0.0933591
[Epoch 69; Iter   178/  229] train: loss: 0.1815985
[Epoch 69; Iter   208/  229] train: loss: 0.1151909
[Epoch 69] ogbg-moltoxcast: 0.679228 val loss: 0.293608
[Epoch 69] ogbg-moltoxcast: 0.642967 test loss: 0.349686
[Epoch 70; Iter     9/  229] train: loss: 0.1030708
[Epoch 70; Iter    39/  229] train: loss: 0.1319225
[Epoch 70; Iter    69/  229] train: loss: 0.1291553
[Epoch 70; Iter    99/  229] train: loss: 0.1628121
[Epoch 70; Iter   129/  229] train: loss: 0.1013159
[Epoch 70; Iter   159/  229] train: loss: 0.1474769
[Epoch 70; Iter   189/  229] train: loss: 0.1564309
[Epoch 70; Iter   219/  229] train: loss: 0.1484186
[Epoch 70] ogbg-moltoxcast: 0.685660 val loss: 0.290688
[Epoch 70] ogbg-moltoxcast: 0.644666 test loss: 0.349259
[Epoch 71; Iter    20/  229] train: loss: 0.1050451
[Epoch 71; Iter    50/  229] train: loss: 0.0994977
[Epoch 71; Iter    80/  229] train: loss: 0.1326807
[Epoch 71; Iter   110/  229] train: loss: 0.1167109
[Epoch 71; Iter   140/  229] train: loss: 0.0970367
[Epoch 71; Iter   170/  229] train: loss: 0.1396946
[Epoch 71; Iter   200/  229] train: loss: 0.1076202
[Epoch 71] ogbg-moltoxcast: 0.682299 val loss: 0.294165
[Epoch 71] ogbg-moltoxcast: 0.643632 test loss: 0.353142
[Epoch 72; Iter     1/  229] train: loss: 0.0892113
[Epoch 72; Iter    31/  229] train: loss: 0.0931615
[Epoch 72; Iter    61/  229] train: loss: 0.1180442
[Epoch 72; Iter    91/  229] train: loss: 0.1240731
[Epoch 72; Iter   121/  229] train: loss: 0.1132897
[Epoch 72; Iter   151/  229] train: loss: 0.1374872
[Epoch 72; Iter   181/  229] train: loss: 0.0927644
[Epoch 72; Iter   211/  229] train: loss: 0.1298548
[Epoch 72] ogbg-moltoxcast: 0.680515 val loss: 0.300767
[Epoch 72] ogbg-moltoxcast: 0.643584 test loss: 0.355282
[Epoch 73; Iter    12/  229] train: loss: 0.1540978
[Epoch 73; Iter    42/  229] train: loss: 0.1084829
[Epoch 73; Iter    72/  229] train: loss: 0.0942573
[Epoch 73; Iter   102/  229] train: loss: 0.1273661
[Epoch 73; Iter   132/  229] train: loss: 0.1618104
[Epoch 73; Iter   162/  229] train: loss: 0.1319046
[Epoch 73; Iter   192/  229] train: loss: 0.1220640
[Epoch 73; Iter   222/  229] train: loss: 0.1290960
[Epoch 73] ogbg-moltoxcast: 0.675541 val loss: 0.289414
[Epoch 73] ogbg-moltoxcast: 0.636514 test loss: 0.347381
[Epoch 74; Iter    23/  229] train: loss: 0.0897433
[Epoch 74; Iter    53/  229] train: loss: 0.1716154
[Epoch 74; Iter    83/  229] train: loss: 0.0942403
[Epoch 74; Iter   113/  229] train: loss: 0.1317435
[Epoch 74; Iter   143/  229] train: loss: 0.1525770
[Epoch 74; Iter   173/  229] train: loss: 0.0826419
[Epoch 74; Iter   203/  229] train: loss: 0.0952076
[Epoch 74] ogbg-moltoxcast: 0.679459 val loss: 0.293699
[Epoch 74] ogbg-moltoxcast: 0.637941 test loss: 0.355143
[Epoch 75; Iter     4/  229] train: loss: 0.0863940
[Epoch 75; Iter    34/  229] train: loss: 0.1472600
[Epoch 75; Iter    64/  229] train: loss: 0.0917243
[Epoch 75; Iter    94/  229] train: loss: 0.1469110
[Epoch 75; Iter   124/  229] train: loss: 0.1359274
[Epoch 75; Iter   154/  229] train: loss: 0.1045051
[Epoch 75; Iter   184/  229] train: loss: 0.1351537
[Epoch 75; Iter   214/  229] train: loss: 0.1068693
[Epoch 75] ogbg-moltoxcast: 0.678543 val loss: 0.296354
[Epoch 75] ogbg-moltoxcast: 0.640118 test loss: 0.353724
[Epoch 60; Iter    19/  229] train: loss: 0.0990013
[Epoch 60; Iter    49/  229] train: loss: 0.1240423
[Epoch 60; Iter    79/  229] train: loss: 0.1553926
[Epoch 60; Iter   109/  229] train: loss: 0.1115133
[Epoch 60; Iter   139/  229] train: loss: 0.1273481
[Epoch 60; Iter   169/  229] train: loss: 0.0960571
[Epoch 60; Iter   199/  229] train: loss: 0.1750321
[Epoch 60; Iter   229/  229] train: loss: 0.1319152
[Epoch 60] ogbg-moltoxcast: 0.640525 val loss: 0.317265
[Epoch 60] ogbg-moltoxcast: 0.618560 test loss: 0.371138
[Epoch 61; Iter    30/  229] train: loss: 0.1477216
[Epoch 61; Iter    60/  229] train: loss: 0.1539827
[Epoch 61; Iter    90/  229] train: loss: 0.1754457
[Epoch 61; Iter   120/  229] train: loss: 0.1491692
[Epoch 61; Iter   150/  229] train: loss: 0.1432484
[Epoch 61; Iter   180/  229] train: loss: 0.1552760
[Epoch 61; Iter   210/  229] train: loss: 0.0921238
[Epoch 61] ogbg-moltoxcast: 0.656450 val loss: 0.315868
[Epoch 61] ogbg-moltoxcast: 0.627825 test loss: 0.368666
[Epoch 62; Iter    11/  229] train: loss: 0.0919489
[Epoch 62; Iter    41/  229] train: loss: 0.1875213
[Epoch 62; Iter    71/  229] train: loss: 0.1420209
[Epoch 62; Iter   101/  229] train: loss: 0.1398824
[Epoch 62; Iter   131/  229] train: loss: 0.1599585
[Epoch 62; Iter   161/  229] train: loss: 0.1175982
[Epoch 62; Iter   191/  229] train: loss: 0.1359853
[Epoch 62; Iter   221/  229] train: loss: 0.1551902
[Epoch 62] ogbg-moltoxcast: 0.654227 val loss: 0.309804
[Epoch 62] ogbg-moltoxcast: 0.628480 test loss: 0.359321
[Epoch 63; Iter    22/  229] train: loss: 0.1317045
[Epoch 63; Iter    52/  229] train: loss: 0.0836333
[Epoch 63; Iter    82/  229] train: loss: 0.0822684
[Epoch 63; Iter   112/  229] train: loss: 0.0914966
[Epoch 63; Iter   142/  229] train: loss: 0.1576881
[Epoch 63; Iter   172/  229] train: loss: 0.1814576
[Epoch 63; Iter   202/  229] train: loss: 0.1048179
[Epoch 63] ogbg-moltoxcast: 0.660644 val loss: 0.314125
[Epoch 63] ogbg-moltoxcast: 0.635268 test loss: 0.363371
[Epoch 64; Iter     3/  229] train: loss: 0.0793995
[Epoch 64; Iter    33/  229] train: loss: 0.1275134
[Epoch 64; Iter    63/  229] train: loss: 0.1426003
[Epoch 64; Iter    93/  229] train: loss: 0.1079287
[Epoch 64; Iter   123/  229] train: loss: 0.1136212
[Epoch 64; Iter   153/  229] train: loss: 0.1058943
[Epoch 64; Iter   183/  229] train: loss: 0.1057571
[Epoch 64; Iter   213/  229] train: loss: 0.1486235
[Epoch 64] ogbg-moltoxcast: 0.652496 val loss: 0.311722
[Epoch 64] ogbg-moltoxcast: 0.623366 test loss: 0.363613
[Epoch 65; Iter    14/  229] train: loss: 0.1406178
[Epoch 65; Iter    44/  229] train: loss: 0.1449714
[Epoch 65; Iter    74/  229] train: loss: 0.1283060
[Epoch 65; Iter   104/  229] train: loss: 0.1544741
[Epoch 65; Iter   134/  229] train: loss: 0.1198938
[Epoch 65; Iter   164/  229] train: loss: 0.1456921
[Epoch 65; Iter   194/  229] train: loss: 0.1034997
[Epoch 65; Iter   224/  229] train: loss: 0.1362489
[Epoch 65] ogbg-moltoxcast: 0.648568 val loss: 0.321140
[Epoch 65] ogbg-moltoxcast: 0.621947 test loss: 0.377724
[Epoch 66; Iter    25/  229] train: loss: 0.1151201
[Epoch 66; Iter    55/  229] train: loss: 0.1546002
[Epoch 66; Iter    85/  229] train: loss: 0.1337052
[Epoch 66; Iter   115/  229] train: loss: 0.1090468
[Epoch 66; Iter   145/  229] train: loss: 0.1051966
[Epoch 66; Iter   175/  229] train: loss: 0.1333404
[Epoch 66; Iter   205/  229] train: loss: 0.1147230
[Epoch 66] ogbg-moltoxcast: 0.657097 val loss: 0.312541
[Epoch 66] ogbg-moltoxcast: 0.630811 test loss: 0.365002
[Epoch 67; Iter     6/  229] train: loss: 0.1267940
[Epoch 67; Iter    36/  229] train: loss: 0.1613193
[Epoch 67; Iter    66/  229] train: loss: 0.0976634
[Epoch 67; Iter    96/  229] train: loss: 0.1664939
[Epoch 67; Iter   126/  229] train: loss: 0.1031307
[Epoch 67; Iter   156/  229] train: loss: 0.1039921
[Epoch 67; Iter   186/  229] train: loss: 0.1038006
[Epoch 67; Iter   216/  229] train: loss: 0.0938247
[Epoch 67] ogbg-moltoxcast: 0.648649 val loss: 0.311172
[Epoch 67] ogbg-moltoxcast: 0.631196 test loss: 0.363384
[Epoch 68; Iter    17/  229] train: loss: 0.1510602
[Epoch 68; Iter    47/  229] train: loss: 0.1094241
[Epoch 68; Iter    77/  229] train: loss: 0.1159379
[Epoch 68; Iter   107/  229] train: loss: 0.1447393
[Epoch 68; Iter   137/  229] train: loss: 0.1036259
[Epoch 68; Iter   167/  229] train: loss: 0.1019459
[Epoch 68; Iter   197/  229] train: loss: 0.1351358
[Epoch 68; Iter   227/  229] train: loss: 0.1364009
[Epoch 68] ogbg-moltoxcast: 0.651756 val loss: 0.309625
[Epoch 68] ogbg-moltoxcast: 0.629188 test loss: 0.361682
[Epoch 69; Iter    28/  229] train: loss: 0.1337048
[Epoch 69; Iter    58/  229] train: loss: 0.0818368
[Epoch 69; Iter    88/  229] train: loss: 0.1059785
[Epoch 69; Iter   118/  229] train: loss: 0.1102005
[Epoch 69; Iter   148/  229] train: loss: 0.0926968
[Epoch 69; Iter   178/  229] train: loss: 0.1798473
[Epoch 69; Iter   208/  229] train: loss: 0.1187056
[Epoch 69] ogbg-moltoxcast: 0.646086 val loss: 0.313612
[Epoch 69] ogbg-moltoxcast: 0.625598 test loss: 0.366739
[Epoch 70; Iter     9/  229] train: loss: 0.1030817
[Epoch 70; Iter    39/  229] train: loss: 0.1350439
[Epoch 70; Iter    69/  229] train: loss: 0.1215952
[Epoch 70; Iter    99/  229] train: loss: 0.1578155
[Epoch 70; Iter   129/  229] train: loss: 0.1051709
[Epoch 70; Iter   159/  229] train: loss: 0.1471078
[Epoch 70; Iter   189/  229] train: loss: 0.1647320
[Epoch 70; Iter   219/  229] train: loss: 0.1436420
[Epoch 70] ogbg-moltoxcast: 0.653686 val loss: 0.310242
[Epoch 70] ogbg-moltoxcast: 0.629170 test loss: 0.361018
[Epoch 71; Iter    20/  229] train: loss: 0.1037472
[Epoch 71; Iter    50/  229] train: loss: 0.0865672
[Epoch 71; Iter    80/  229] train: loss: 0.1173561
[Epoch 71; Iter   110/  229] train: loss: 0.1148378
[Epoch 71; Iter   140/  229] train: loss: 0.0889705
[Epoch 71; Iter   170/  229] train: loss: 0.1313706
[Epoch 71; Iter   200/  229] train: loss: 0.1146356
[Epoch 71] ogbg-moltoxcast: 0.660256 val loss: 0.317503
[Epoch 71] ogbg-moltoxcast: 0.631663 test loss: 0.373457
[Epoch 72; Iter     1/  229] train: loss: 0.0917273
[Epoch 72; Iter    31/  229] train: loss: 0.0960757
[Epoch 72; Iter    61/  229] train: loss: 0.1141525
[Epoch 72; Iter    91/  229] train: loss: 0.1195940
[Epoch 72; Iter   121/  229] train: loss: 0.1088517
[Epoch 72; Iter   151/  229] train: loss: 0.1321691
[Epoch 72; Iter   181/  229] train: loss: 0.0951097
[Epoch 72; Iter   211/  229] train: loss: 0.1279220
[Epoch 72] ogbg-moltoxcast: 0.660624 val loss: 0.317740
[Epoch 72] ogbg-moltoxcast: 0.634014 test loss: 0.371575
[Epoch 73; Iter    12/  229] train: loss: 0.1555109
[Epoch 73; Iter    42/  229] train: loss: 0.1042790
[Epoch 73; Iter    72/  229] train: loss: 0.0893034
[Epoch 73; Iter   102/  229] train: loss: 0.1217057
[Epoch 73; Iter   132/  229] train: loss: 0.1573153
[Epoch 73; Iter   162/  229] train: loss: 0.1290165
[Epoch 73; Iter   192/  229] train: loss: 0.1162895
[Epoch 73; Iter   222/  229] train: loss: 0.1276949
[Epoch 73] ogbg-moltoxcast: 0.653261 val loss: 0.316129
[Epoch 73] ogbg-moltoxcast: 0.629383 test loss: 0.370275
[Epoch 74; Iter    23/  229] train: loss: 0.0867729
[Epoch 74; Iter    53/  229] train: loss: 0.1710057
[Epoch 74; Iter    83/  229] train: loss: 0.0822073
[Epoch 74; Iter   113/  229] train: loss: 0.1226159
[Epoch 74; Iter   143/  229] train: loss: 0.1603766
[Epoch 74; Iter   173/  229] train: loss: 0.0840037
[Epoch 74; Iter   203/  229] train: loss: 0.0962510
[Epoch 74] ogbg-moltoxcast: 0.643036 val loss: 0.321493
[Epoch 74] ogbg-moltoxcast: 0.629227 test loss: 0.374539
[Epoch 75; Iter     4/  229] train: loss: 0.0870490
[Epoch 75; Iter    34/  229] train: loss: 0.1449354
[Epoch 75; Iter    64/  229] train: loss: 0.0968609
[Epoch 75; Iter    94/  229] train: loss: 0.1401827
[Epoch 75; Iter   124/  229] train: loss: 0.1377786
[Epoch 75; Iter   154/  229] train: loss: 0.1033714
[Epoch 75; Iter   184/  229] train: loss: 0.1255657
[Epoch 75; Iter   214/  229] train: loss: 0.0979282
[Epoch 75] ogbg-moltoxcast: 0.656711 val loss: 0.308748
[Epoch 75] ogbg-moltoxcast: 0.626391 test loss: 0.366914
[Epoch 60; Iter    19/  229] train: loss: 0.1070711
[Epoch 60; Iter    49/  229] train: loss: 0.1144436
[Epoch 60; Iter    79/  229] train: loss: 0.2084033
[Epoch 60; Iter   109/  229] train: loss: 0.2161599
[Epoch 60; Iter   139/  229] train: loss: 0.1570090
[Epoch 60; Iter   169/  229] train: loss: 0.1306108
[Epoch 60; Iter   199/  229] train: loss: 0.1753591
[Epoch 60; Iter   229/  229] train: loss: 0.1440835
[Epoch 60] ogbg-moltoxcast: 0.641581 val loss: 0.503870
[Epoch 60] ogbg-moltoxcast: 0.633920 test loss: 0.369646
[Epoch 61; Iter    30/  229] train: loss: 0.1386265
[Epoch 61; Iter    60/  229] train: loss: 0.1510735
[Epoch 61; Iter    90/  229] train: loss: 0.0915588
[Epoch 61; Iter   120/  229] train: loss: 0.0892059
[Epoch 61; Iter   150/  229] train: loss: 0.1750781
[Epoch 61; Iter   180/  229] train: loss: 0.1113352
[Epoch 61; Iter   210/  229] train: loss: 0.1041301
[Epoch 61] ogbg-moltoxcast: 0.644279 val loss: 0.340510
[Epoch 61] ogbg-moltoxcast: 0.626528 test loss: 1.191662
[Epoch 62; Iter    11/  229] train: loss: 0.1174265
[Epoch 62; Iter    41/  229] train: loss: 0.1340445
[Epoch 62; Iter    71/  229] train: loss: 0.1001086
[Epoch 62; Iter   101/  229] train: loss: 0.1172181
[Epoch 62; Iter   131/  229] train: loss: 0.1084012
[Epoch 62; Iter   161/  229] train: loss: 0.1275842
[Epoch 62; Iter   191/  229] train: loss: 0.1170641
[Epoch 62; Iter   221/  229] train: loss: 0.1284272
[Epoch 62] ogbg-moltoxcast: 0.647062 val loss: 0.324646
[Epoch 62] ogbg-moltoxcast: 0.640888 test loss: 0.867011
[Epoch 63; Iter    22/  229] train: loss: 0.1595015
[Epoch 63; Iter    52/  229] train: loss: 0.1574631
[Epoch 63; Iter    82/  229] train: loss: 0.0973424
[Epoch 63; Iter   112/  229] train: loss: 0.1288402
[Epoch 63; Iter   142/  229] train: loss: 0.1183108
[Epoch 63; Iter   172/  229] train: loss: 0.1665986
[Epoch 63; Iter   202/  229] train: loss: 0.0894325
[Epoch 63] ogbg-moltoxcast: 0.638301 val loss: 0.394611
[Epoch 63] ogbg-moltoxcast: 0.631556 test loss: 0.458120
[Epoch 64; Iter     3/  229] train: loss: 0.2008229
[Epoch 64; Iter    33/  229] train: loss: 0.1288080
[Epoch 64; Iter    63/  229] train: loss: 0.1818615
[Epoch 64; Iter    93/  229] train: loss: 0.1881446
[Epoch 64; Iter   123/  229] train: loss: 0.1440372
[Epoch 64; Iter   153/  229] train: loss: 0.1609407
[Epoch 64; Iter   183/  229] train: loss: 0.1791047
[Epoch 64; Iter   213/  229] train: loss: 0.1060341
[Epoch 64] ogbg-moltoxcast: 0.646119 val loss: 0.322593
[Epoch 64] ogbg-moltoxcast: 0.641814 test loss: 0.380121
[Epoch 65; Iter    14/  229] train: loss: 0.1104403
[Epoch 65; Iter    44/  229] train: loss: 0.1207790
[Epoch 65; Iter    74/  229] train: loss: 0.1216695
[Epoch 65; Iter   104/  229] train: loss: 0.1248507
[Epoch 65; Iter   134/  229] train: loss: 0.1023908
[Epoch 65; Iter   164/  229] train: loss: 0.1352692
[Epoch 65; Iter   194/  229] train: loss: 0.0982056
[Epoch 65; Iter   224/  229] train: loss: 0.1339314
[Epoch 65] ogbg-moltoxcast: 0.649473 val loss: 0.326880
[Epoch 65] ogbg-moltoxcast: 0.639754 test loss: 0.503059
[Epoch 66; Iter    25/  229] train: loss: 0.1197704
[Epoch 66; Iter    55/  229] train: loss: 0.1689693
[Epoch 66; Iter    85/  229] train: loss: 0.0996712
[Epoch 66; Iter   115/  229] train: loss: 0.1477879
[Epoch 66; Iter   145/  229] train: loss: 0.1144373
[Epoch 66; Iter   175/  229] train: loss: 0.0964830
[Epoch 66; Iter   205/  229] train: loss: 0.1539886
[Epoch 66] ogbg-moltoxcast: 0.644831 val loss: 0.547838
[Epoch 66] ogbg-moltoxcast: 0.632179 test loss: 1.100526
[Epoch 67; Iter     6/  229] train: loss: 0.0711966
[Epoch 67; Iter    36/  229] train: loss: 0.1215348
[Epoch 67; Iter    66/  229] train: loss: 0.1388160
[Epoch 67; Iter    96/  229] train: loss: 0.1119488
[Epoch 67; Iter   126/  229] train: loss: 0.1612159
[Epoch 67; Iter   156/  229] train: loss: 0.1063678
[Epoch 67; Iter   186/  229] train: loss: 0.1198878
[Epoch 67; Iter   216/  229] train: loss: 0.1004275
[Epoch 67] ogbg-moltoxcast: 0.645185 val loss: 0.463058
[Epoch 67] ogbg-moltoxcast: 0.633558 test loss: 0.844325
[Epoch 68; Iter    17/  229] train: loss: 0.1367373
[Epoch 68; Iter    47/  229] train: loss: 0.1327684
[Epoch 68; Iter    77/  229] train: loss: 0.1876326
[Epoch 68; Iter   107/  229] train: loss: 0.1275867
[Epoch 68; Iter   137/  229] train: loss: 0.1166374
[Epoch 68; Iter   167/  229] train: loss: 0.1437758
[Epoch 68; Iter   197/  229] train: loss: 0.1243634
[Epoch 68; Iter   227/  229] train: loss: 0.1349405
[Epoch 68] ogbg-moltoxcast: 0.648665 val loss: 0.338688
[Epoch 68] ogbg-moltoxcast: 0.637250 test loss: 1.140127
[Epoch 69; Iter    28/  229] train: loss: 0.1573348
[Epoch 69; Iter    58/  229] train: loss: 0.1524195
[Epoch 69; Iter    88/  229] train: loss: 0.1441427
[Epoch 69; Iter   118/  229] train: loss: 0.1762639
[Epoch 69; Iter   148/  229] train: loss: 0.1684050
[Epoch 69; Iter   178/  229] train: loss: 0.0951523
[Epoch 69; Iter   208/  229] train: loss: 0.1024086
[Epoch 69] ogbg-moltoxcast: 0.641722 val loss: 0.382258
[Epoch 69] ogbg-moltoxcast: 0.637406 test loss: 0.395697
[Epoch 70; Iter     9/  229] train: loss: 0.1509273
[Epoch 70; Iter    39/  229] train: loss: 0.1379241
[Epoch 70; Iter    69/  229] train: loss: 0.1327488
[Epoch 70; Iter    99/  229] train: loss: 0.1710053
[Epoch 70; Iter   129/  229] train: loss: 0.1444961
[Epoch 70; Iter   159/  229] train: loss: 0.1210804
[Epoch 70; Iter   189/  229] train: loss: 0.1036777
[Epoch 70; Iter   219/  229] train: loss: 0.1786147
[Epoch 70] ogbg-moltoxcast: 0.639017 val loss: 0.479605
[Epoch 70] ogbg-moltoxcast: 0.631149 test loss: 0.396531
[Epoch 71; Iter    20/  229] train: loss: 0.1268329
[Epoch 71; Iter    50/  229] train: loss: 0.0971169
[Epoch 71; Iter    80/  229] train: loss: 0.1614474
[Epoch 71; Iter   110/  229] train: loss: 0.1511861
[Epoch 71; Iter   140/  229] train: loss: 0.1366173
[Epoch 71; Iter   170/  229] train: loss: 0.1564538
[Epoch 71; Iter   200/  229] train: loss: 0.1236580
[Epoch 71] ogbg-moltoxcast: 0.636120 val loss: 0.433889
[Epoch 71] ogbg-moltoxcast: 0.629477 test loss: 0.387191
[Epoch 72; Iter     1/  229] train: loss: 0.1381955
[Epoch 72; Iter    31/  229] train: loss: 0.1306151
[Epoch 72; Iter    61/  229] train: loss: 0.1605689
[Epoch 72; Iter    91/  229] train: loss: 0.1076263
[Epoch 72; Iter   121/  229] train: loss: 0.0955809
[Epoch 72; Iter   151/  229] train: loss: 0.1541922
[Epoch 72; Iter   181/  229] train: loss: 0.1857282
[Epoch 72; Iter   211/  229] train: loss: 0.0920606
[Epoch 72] ogbg-moltoxcast: 0.635510 val loss: 0.527591
[Epoch 72] ogbg-moltoxcast: 0.629685 test loss: 1.679004
[Epoch 73; Iter    12/  229] train: loss: 0.1130435
[Epoch 73; Iter    42/  229] train: loss: 0.1357554
[Epoch 73; Iter    72/  229] train: loss: 0.1585755
[Epoch 73; Iter   102/  229] train: loss: 0.1409165
[Epoch 73; Iter   132/  229] train: loss: 0.1199974
[Epoch 73; Iter   162/  229] train: loss: 0.1350120
[Epoch 73; Iter   192/  229] train: loss: 0.0987820
[Epoch 73; Iter   222/  229] train: loss: 0.1093470
[Epoch 73] ogbg-moltoxcast: 0.645814 val loss: 0.444427
[Epoch 73] ogbg-moltoxcast: 0.635712 test loss: 0.756916
[Epoch 74; Iter    23/  229] train: loss: 0.0886386
[Epoch 74; Iter    53/  229] train: loss: 0.1334236
[Epoch 74; Iter    83/  229] train: loss: 0.1155420
[Epoch 74; Iter   113/  229] train: loss: 0.0935765
[Epoch 74; Iter   143/  229] train: loss: 0.1195348
[Epoch 74; Iter   173/  229] train: loss: 0.1227110
[Epoch 74; Iter   203/  229] train: loss: 0.1299548
[Epoch 74] ogbg-moltoxcast: 0.645777 val loss: 0.329341
[Epoch 74] ogbg-moltoxcast: 0.633802 test loss: 1.163043
[Epoch 75; Iter     4/  229] train: loss: 0.0855587
[Epoch 75; Iter    34/  229] train: loss: 0.1452330
[Epoch 75; Iter    64/  229] train: loss: 0.1807479
[Epoch 75; Iter    94/  229] train: loss: 0.1266253
[Epoch 75; Iter   124/  229] train: loss: 0.1310712
[Epoch 75; Iter   154/  229] train: loss: 0.1190242
[Epoch 75; Iter   184/  229] train: loss: 0.1719663
[Epoch 75; Iter   214/  229] train: loss: 0.1223523
[Epoch 75] ogbg-moltoxcast: 0.640486 val loss: 0.536322
[Epoch 75] ogbg-moltoxcast: 0.631120 test loss: 0.539289
[Epoch 60; Iter    19/  229] train: loss: 0.1542323
[Epoch 60; Iter    49/  229] train: loss: 0.1310938
[Epoch 60; Iter    79/  229] train: loss: 0.1052022
[Epoch 60; Iter   109/  229] train: loss: 0.1306812
[Epoch 60; Iter   139/  229] train: loss: 0.1342141
[Epoch 60; Iter   169/  229] train: loss: 0.1718327
[Epoch 60; Iter   199/  229] train: loss: 0.0967549
[Epoch 60; Iter   229/  229] train: loss: 0.1215161
[Epoch 60] ogbg-moltoxcast: 0.702493 val loss: 0.251080
[Epoch 60] ogbg-moltoxcast: 0.663453 test loss: 0.592989
[Epoch 61; Iter    30/  229] train: loss: 0.1313337
[Epoch 61; Iter    60/  229] train: loss: 0.1544064
[Epoch 61; Iter    90/  229] train: loss: 0.0978587
[Epoch 61; Iter   120/  229] train: loss: 0.1493787
[Epoch 61; Iter   150/  229] train: loss: 0.1015933
[Epoch 61; Iter   180/  229] train: loss: 0.1874299
[Epoch 61; Iter   210/  229] train: loss: 0.1207081
[Epoch 61] ogbg-moltoxcast: 0.696590 val loss: 0.260080
[Epoch 61] ogbg-moltoxcast: 0.658762 test loss: 0.513248
[Epoch 62; Iter    11/  229] train: loss: 0.1223164
[Epoch 62; Iter    41/  229] train: loss: 0.1745731
[Epoch 62; Iter    71/  229] train: loss: 0.1662116
[Epoch 62; Iter   101/  229] train: loss: 0.1889188
[Epoch 62; Iter   131/  229] train: loss: 0.1084678
[Epoch 62; Iter   161/  229] train: loss: 0.1255533
[Epoch 62; Iter   191/  229] train: loss: 0.0920681
[Epoch 62; Iter   221/  229] train: loss: 0.1883475
[Epoch 62] ogbg-moltoxcast: 0.700005 val loss: 0.258774
[Epoch 62] ogbg-moltoxcast: 0.669255 test loss: 0.457700
[Epoch 63; Iter    22/  229] train: loss: 0.1085509
[Epoch 63; Iter    52/  229] train: loss: 0.1234603
[Epoch 63; Iter    82/  229] train: loss: 0.0822503
[Epoch 63; Iter   112/  229] train: loss: 0.1302315
[Epoch 63; Iter   142/  229] train: loss: 0.1487306
[Epoch 63; Iter   172/  229] train: loss: 0.1741722
[Epoch 63; Iter   202/  229] train: loss: 0.1137511
[Epoch 63] ogbg-moltoxcast: 0.700823 val loss: 0.257929
[Epoch 63] ogbg-moltoxcast: 0.664582 test loss: 0.499298
[Epoch 64; Iter     3/  229] train: loss: 0.1464462
[Epoch 64; Iter    33/  229] train: loss: 0.1430602
[Epoch 64; Iter    63/  229] train: loss: 0.1171487
[Epoch 64; Iter    93/  229] train: loss: 0.1063663
[Epoch 64; Iter   123/  229] train: loss: 0.1470912
[Epoch 64; Iter   153/  229] train: loss: 0.1350906
[Epoch 64; Iter   183/  229] train: loss: 0.1782551
[Epoch 64; Iter   213/  229] train: loss: 0.1144996
[Epoch 64] ogbg-moltoxcast: 0.698057 val loss: 0.264981
[Epoch 64] ogbg-moltoxcast: 0.665097 test loss: 0.456242
[Epoch 65; Iter    14/  229] train: loss: 0.0941224
[Epoch 65; Iter    44/  229] train: loss: 0.1020027
[Epoch 65; Iter    74/  229] train: loss: 0.0989852
[Epoch 65; Iter   104/  229] train: loss: 0.1192819
[Epoch 65; Iter   134/  229] train: loss: 0.1812298
[Epoch 65; Iter   164/  229] train: loss: 0.1567906
[Epoch 65; Iter   194/  229] train: loss: 0.1266956
[Epoch 65; Iter   224/  229] train: loss: 0.2059927
[Epoch 65] ogbg-moltoxcast: 0.702921 val loss: 0.260532
[Epoch 65] ogbg-moltoxcast: 0.664260 test loss: 0.494835
[Epoch 66; Iter    25/  229] train: loss: 0.0978939
[Epoch 66; Iter    55/  229] train: loss: 0.0997615
[Epoch 66; Iter    85/  229] train: loss: 0.1425445
[Epoch 66; Iter   115/  229] train: loss: 0.1822572
[Epoch 66; Iter   145/  229] train: loss: 0.1209060
[Epoch 66; Iter   175/  229] train: loss: 0.1590258
[Epoch 66; Iter   205/  229] train: loss: 0.1624294
[Epoch 66] ogbg-moltoxcast: 0.696950 val loss: 0.261285
[Epoch 66] ogbg-moltoxcast: 0.660058 test loss: 0.496431
[Epoch 67; Iter     6/  229] train: loss: 0.1397914
[Epoch 67; Iter    36/  229] train: loss: 0.1514843
[Epoch 67; Iter    66/  229] train: loss: 0.1155730
[Epoch 67; Iter    96/  229] train: loss: 0.1225555
[Epoch 67; Iter   126/  229] train: loss: 0.1539034
[Epoch 67; Iter   156/  229] train: loss: 0.1554629
[Epoch 67; Iter   186/  229] train: loss: 0.1617815
[Epoch 67; Iter   216/  229] train: loss: 0.1342166
[Epoch 67] ogbg-moltoxcast: 0.703228 val loss: 0.261660
[Epoch 67] ogbg-moltoxcast: 0.667365 test loss: 0.564302
[Epoch 68; Iter    17/  229] train: loss: 0.1851913
[Epoch 68; Iter    47/  229] train: loss: 0.1187372
[Epoch 68; Iter    77/  229] train: loss: 0.1141812
[Epoch 68; Iter   107/  229] train: loss: 0.1223177
[Epoch 68; Iter   137/  229] train: loss: 0.1069556
[Epoch 68; Iter   167/  229] train: loss: 0.1135312
[Epoch 68; Iter   197/  229] train: loss: 0.1390160
[Epoch 68; Iter   227/  229] train: loss: 0.1260734
[Epoch 68] ogbg-moltoxcast: 0.699555 val loss: 0.260820
[Epoch 68] ogbg-moltoxcast: 0.663202 test loss: 0.624026
[Epoch 69; Iter    28/  229] train: loss: 0.1359747
[Epoch 69; Iter    58/  229] train: loss: 0.1765109
[Epoch 69; Iter    88/  229] train: loss: 0.0981701
[Epoch 69; Iter   118/  229] train: loss: 0.0892449
[Epoch 69; Iter   148/  229] train: loss: 0.1428292
[Epoch 69; Iter   178/  229] train: loss: 0.1619066
[Epoch 69; Iter   208/  229] train: loss: 0.0946649
[Epoch 69] ogbg-moltoxcast: 0.706159 val loss: 0.270451
[Epoch 69] ogbg-moltoxcast: 0.663240 test loss: 0.623713
[Epoch 70; Iter     9/  229] train: loss: 0.0997897
[Epoch 70; Iter    39/  229] train: loss: 0.1089624
[Epoch 70; Iter    69/  229] train: loss: 0.1261842
[Epoch 70; Iter    99/  229] train: loss: 0.1472033
[Epoch 70; Iter   129/  229] train: loss: 0.1302933
[Epoch 70; Iter   159/  229] train: loss: 0.1345295
[Epoch 70; Iter   189/  229] train: loss: 0.1394396
[Epoch 70; Iter   219/  229] train: loss: 0.1263137
[Epoch 70] ogbg-moltoxcast: 0.700080 val loss: 0.261709
[Epoch 70] ogbg-moltoxcast: 0.659237 test loss: 0.559763
[Epoch 71; Iter    20/  229] train: loss: 0.1439854
[Epoch 71; Iter    50/  229] train: loss: 0.1470306
[Epoch 71; Iter    80/  229] train: loss: 0.1012756
[Epoch 71; Iter   110/  229] train: loss: 0.1525462
[Epoch 71; Iter   140/  229] train: loss: 0.1213999
[Epoch 71; Iter   170/  229] train: loss: 0.0856995
[Epoch 71; Iter   200/  229] train: loss: 0.1232339
[Epoch 71] ogbg-moltoxcast: 0.703166 val loss: 0.262566
[Epoch 71] ogbg-moltoxcast: 0.668313 test loss: 0.597810
[Epoch 72; Iter     1/  229] train: loss: 0.1134679
[Epoch 72; Iter    31/  229] train: loss: 0.1749926
[Epoch 72; Iter    61/  229] train: loss: 0.1409515
[Epoch 72; Iter    91/  229] train: loss: 0.1402976
[Epoch 72; Iter   121/  229] train: loss: 0.1569306
[Epoch 72; Iter   151/  229] train: loss: 0.1709525
[Epoch 72; Iter   181/  229] train: loss: 0.1167839
[Epoch 72; Iter   211/  229] train: loss: 0.1286988
[Epoch 72] ogbg-moltoxcast: 0.701791 val loss: 0.265463
[Epoch 72] ogbg-moltoxcast: 0.664390 test loss: 0.613910
[Epoch 73; Iter    12/  229] train: loss: 0.1196199
[Epoch 73; Iter    42/  229] train: loss: 0.1601529
[Epoch 73; Iter    72/  229] train: loss: 0.1750733
[Epoch 73; Iter   102/  229] train: loss: 0.1130952
[Epoch 73; Iter   132/  229] train: loss: 0.1392693
[Epoch 73; Iter   162/  229] train: loss: 0.1342060
[Epoch 73; Iter   192/  229] train: loss: 0.1188826
[Epoch 73; Iter   222/  229] train: loss: 0.1261041
[Epoch 73] ogbg-moltoxcast: 0.702295 val loss: 0.266473
[Epoch 73] ogbg-moltoxcast: 0.664319 test loss: 0.398636
[Epoch 74; Iter    23/  229] train: loss: 0.1271460
[Epoch 74; Iter    53/  229] train: loss: 0.1141898
[Epoch 74; Iter    83/  229] train: loss: 0.0923075
[Epoch 74; Iter   113/  229] train: loss: 0.1136875
[Epoch 74; Iter   143/  229] train: loss: 0.1525585
[Epoch 74; Iter   173/  229] train: loss: 0.1055699
[Epoch 74; Iter   203/  229] train: loss: 0.0934357
[Epoch 74] ogbg-moltoxcast: 0.701270 val loss: 0.264389
[Epoch 74] ogbg-moltoxcast: 0.657050 test loss: 0.421286
[Epoch 75; Iter     4/  229] train: loss: 0.0937124
[Epoch 75; Iter    34/  229] train: loss: 0.1622307
[Epoch 75; Iter    64/  229] train: loss: 0.1347511
[Epoch 75; Iter    94/  229] train: loss: 0.1170115
[Epoch 75; Iter   124/  229] train: loss: 0.1226886
[Epoch 75; Iter   154/  229] train: loss: 0.1423039
[Epoch 75; Iter   184/  229] train: loss: 0.1236264
[Epoch 75; Iter   214/  229] train: loss: 0.1324188
[Epoch 75] ogbg-moltoxcast: 0.694260 val loss: 0.267605
[Epoch 75] ogbg-moltoxcast: 0.658653 test loss: 0.740202
[Epoch 76; Iter    15/  229] train: loss: 0.1093393
[Epoch 76; Iter    45/  229] train: loss: 0.1254620
[Epoch 76; Iter    75/  229] train: loss: 0.1439220
[Epoch 76; Iter   105/  229] train: loss: 0.0875248
[Epoch 76; Iter   135/  229] train: loss: 0.1915816
[Epoch 76; Iter   165/  229] train: loss: 0.1021739
[Epoch 76; Iter   195/  229] train: loss: 0.1220729
[Epoch 76; Iter   225/  229] train: loss: 0.1036251
[Epoch 76] ogbg-moltoxcast: 0.649335 val loss: 0.324601
[Epoch 76] ogbg-moltoxcast: 0.636214 test loss: 0.576841
[Epoch 77; Iter    26/  229] train: loss: 0.1424303
[Epoch 77; Iter    56/  229] train: loss: 0.1032668
[Epoch 77; Iter    86/  229] train: loss: 0.1990277
[Epoch 77; Iter   116/  229] train: loss: 0.1656375
[Epoch 77; Iter   146/  229] train: loss: 0.1310328
[Epoch 77; Iter   176/  229] train: loss: 0.1580168
[Epoch 77; Iter   206/  229] train: loss: 0.1425872
[Epoch 77] ogbg-moltoxcast: 0.646116 val loss: 0.312015
[Epoch 77] ogbg-moltoxcast: 0.631963 test loss: 0.514653
[Epoch 78; Iter     7/  229] train: loss: 0.1363449
[Epoch 78; Iter    37/  229] train: loss: 0.1386927
[Epoch 78; Iter    67/  229] train: loss: 0.1245185
[Epoch 78; Iter    97/  229] train: loss: 0.0936475
[Epoch 78; Iter   127/  229] train: loss: 0.1188035
[Epoch 78; Iter   157/  229] train: loss: 0.1120373
[Epoch 78; Iter   187/  229] train: loss: 0.1393946
[Epoch 78; Iter   217/  229] train: loss: 0.1491622
[Epoch 78] ogbg-moltoxcast: 0.651457 val loss: 0.314404
[Epoch 78] ogbg-moltoxcast: 0.636439 test loss: 0.572997
[Epoch 79; Iter    18/  229] train: loss: 0.1046106
[Epoch 79; Iter    48/  229] train: loss: 0.1477104
[Epoch 79; Iter    78/  229] train: loss: 0.1448026
[Epoch 79; Iter   108/  229] train: loss: 0.1490057
[Epoch 79; Iter   138/  229] train: loss: 0.1847396
[Epoch 79; Iter   168/  229] train: loss: 0.1642498
[Epoch 79; Iter   198/  229] train: loss: 0.1397980
[Epoch 79; Iter   228/  229] train: loss: 0.1457644
[Epoch 79] ogbg-moltoxcast: 0.647398 val loss: 0.306285
[Epoch 79] ogbg-moltoxcast: 0.634033 test loss: 0.463514
[Epoch 80; Iter    29/  229] train: loss: 0.1423213
[Epoch 80; Iter    59/  229] train: loss: 0.1221614
[Epoch 80; Iter    89/  229] train: loss: 0.1606771
[Epoch 80; Iter   119/  229] train: loss: 0.1216299
[Epoch 80; Iter   149/  229] train: loss: 0.1376607
[Epoch 80; Iter   179/  229] train: loss: 0.1402436
[Epoch 80; Iter   209/  229] train: loss: 0.1470651
[Epoch 80] ogbg-moltoxcast: 0.644987 val loss: 0.319613
[Epoch 80] ogbg-moltoxcast: 0.627462 test loss: 0.602877
[Epoch 81; Iter    10/  229] train: loss: 0.1068504
[Epoch 81; Iter    40/  229] train: loss: 0.1479859
[Epoch 81; Iter    70/  229] train: loss: 0.1489113
[Epoch 81; Iter   100/  229] train: loss: 0.0786017
[Epoch 81; Iter   130/  229] train: loss: 0.0972113
[Epoch 81; Iter   160/  229] train: loss: 0.1459255
[Epoch 81; Iter   190/  229] train: loss: 0.1332545
[Epoch 81; Iter   220/  229] train: loss: 0.1234055
[Epoch 81] ogbg-moltoxcast: 0.646562 val loss: 0.319600
[Epoch 81] ogbg-moltoxcast: 0.628581 test loss: 0.625749
[Epoch 82; Iter    21/  229] train: loss: 0.1438263
[Epoch 82; Iter    51/  229] train: loss: 0.1450969
[Epoch 82; Iter    81/  229] train: loss: 0.0999339
[Epoch 82; Iter   111/  229] train: loss: 0.0993565
[Epoch 82; Iter   141/  229] train: loss: 0.1426235
[Epoch 82; Iter   171/  229] train: loss: 0.1084870
[Epoch 82; Iter   201/  229] train: loss: 0.1500664
[Epoch 82] ogbg-moltoxcast: 0.644348 val loss: 0.324209
[Epoch 82] ogbg-moltoxcast: 0.631693 test loss: 0.628772
[Epoch 83; Iter     2/  229] train: loss: 0.1167328
[Epoch 83; Iter    32/  229] train: loss: 0.1174716
[Epoch 83; Iter    62/  229] train: loss: 0.0922043
[Epoch 83; Iter    92/  229] train: loss: 0.1605143
[Epoch 83; Iter   122/  229] train: loss: 0.1199181
[Epoch 83; Iter   152/  229] train: loss: 0.1473523
[Epoch 83; Iter   182/  229] train: loss: 0.1694813
[Epoch 83; Iter   212/  229] train: loss: 0.1178129
[Epoch 83] ogbg-moltoxcast: 0.650803 val loss: 0.326791
[Epoch 83] ogbg-moltoxcast: 0.637351 test loss: 0.521755
[Epoch 84; Iter    13/  229] train: loss: 0.1489465
[Epoch 84; Iter    43/  229] train: loss: 0.1298771
[Epoch 84; Iter    73/  229] train: loss: 0.1552689
[Epoch 84; Iter   103/  229] train: loss: 0.1036711
[Epoch 84; Iter   133/  229] train: loss: 0.1385021
[Epoch 84; Iter   163/  229] train: loss: 0.0920917
[Epoch 84; Iter   193/  229] train: loss: 0.1350954
[Epoch 84; Iter   223/  229] train: loss: 0.1082375
[Epoch 84] ogbg-moltoxcast: 0.652943 val loss: 0.327503
[Epoch 84] ogbg-moltoxcast: 0.635176 test loss: 0.764661
[Epoch 85; Iter    24/  229] train: loss: 0.1279655
[Epoch 85; Iter    54/  229] train: loss: 0.1115943
[Epoch 85; Iter    84/  229] train: loss: 0.1103274
[Epoch 85; Iter   114/  229] train: loss: 0.1037090
[Epoch 85; Iter   144/  229] train: loss: 0.1347243
[Epoch 85; Iter   174/  229] train: loss: 0.1474623
[Epoch 85; Iter   204/  229] train: loss: 0.1547738
[Epoch 85] ogbg-moltoxcast: 0.657213 val loss: 0.314448
[Epoch 85] ogbg-moltoxcast: 0.635822 test loss: 0.439038
[Epoch 86; Iter     5/  229] train: loss: 0.1833111
[Epoch 86; Iter    35/  229] train: loss: 0.1498137
[Epoch 86; Iter    65/  229] train: loss: 0.1260814
[Epoch 86; Iter    95/  229] train: loss: 0.1558157
[Epoch 86; Iter   125/  229] train: loss: 0.1257129
[Epoch 86; Iter   155/  229] train: loss: 0.1168533
[Epoch 86; Iter   185/  229] train: loss: 0.1436371
[Epoch 86; Iter   215/  229] train: loss: 0.1468224
[Epoch 86] ogbg-moltoxcast: 0.655220 val loss: 0.322449
[Epoch 86] ogbg-moltoxcast: 0.636490 test loss: 0.681354
[Epoch 87; Iter    16/  229] train: loss: 0.1172621
[Epoch 87; Iter    46/  229] train: loss: 0.1202110
[Epoch 87; Iter    76/  229] train: loss: 0.1072475
[Epoch 87; Iter   106/  229] train: loss: 0.1248408
[Epoch 87; Iter   136/  229] train: loss: 0.1316429
[Epoch 87; Iter   166/  229] train: loss: 0.1380162
[Epoch 87; Iter   196/  229] train: loss: 0.1353601
[Epoch 87; Iter   226/  229] train: loss: 0.1184636
[Epoch 87] ogbg-moltoxcast: 0.652011 val loss: 0.324899
[Epoch 87] ogbg-moltoxcast: 0.633008 test loss: 0.565792
[Epoch 88; Iter    27/  229] train: loss: 0.1966888
[Epoch 88; Iter    57/  229] train: loss: 0.1122404
[Epoch 88; Iter    87/  229] train: loss: 0.1125008
[Epoch 88; Iter   117/  229] train: loss: 0.1225584
[Epoch 88; Iter   147/  229] train: loss: 0.1023222
[Epoch 88; Iter   177/  229] train: loss: 0.1316256
[Epoch 88; Iter   207/  229] train: loss: 0.1258388
[Epoch 88] ogbg-moltoxcast: 0.648009 val loss: 0.322644
[Epoch 88] ogbg-moltoxcast: 0.635558 test loss: 0.452127
[Epoch 89; Iter     8/  229] train: loss: 0.1050680
[Epoch 89; Iter    38/  229] train: loss: 0.1017747
[Epoch 89; Iter    68/  229] train: loss: 0.1328197
[Epoch 89; Iter    98/  229] train: loss: 0.1022307
[Epoch 89; Iter   128/  229] train: loss: 0.1203627
[Epoch 89; Iter   158/  229] train: loss: 0.1323807
[Epoch 89; Iter   188/  229] train: loss: 0.1146290
[Epoch 89; Iter   218/  229] train: loss: 0.0954256
[Epoch 89] ogbg-moltoxcast: 0.650645 val loss: 0.330131
[Epoch 89] ogbg-moltoxcast: 0.636421 test loss: 0.531342
[Epoch 90; Iter    19/  229] train: loss: 0.1263790
[Epoch 90; Iter    49/  229] train: loss: 0.1555532
[Epoch 90; Iter    79/  229] train: loss: 0.1537670
[Epoch 90; Iter   109/  229] train: loss: 0.1688011
[Epoch 90; Iter   139/  229] train: loss: 0.1580652
[Epoch 90; Iter   169/  229] train: loss: 0.1213225
[Epoch 90; Iter   199/  229] train: loss: 0.0955094
[Epoch 90; Iter   229/  229] train: loss: 0.1258402
[Epoch 90] ogbg-moltoxcast: 0.650977 val loss: 0.325965
[Epoch 90] ogbg-moltoxcast: 0.631741 test loss: 0.528548
[Epoch 91; Iter    30/  229] train: loss: 0.1273738
[Epoch 91; Iter    60/  229] train: loss: 0.1050701
[Epoch 91; Iter    90/  229] train: loss: 0.1244431
[Epoch 91; Iter   120/  229] train: loss: 0.1038546
[Epoch 91; Iter   150/  229] train: loss: 0.1307835
[Epoch 91; Iter   180/  229] train: loss: 0.1282729
[Epoch 91; Iter   210/  229] train: loss: 0.1519695
[Epoch 91] ogbg-moltoxcast: 0.654950 val loss: 0.335609
[Epoch 91] ogbg-moltoxcast: 0.639438 test loss: 0.475687
[Epoch 60; Iter    19/  229] train: loss: 0.1119747
[Epoch 60; Iter    49/  229] train: loss: 0.1225258
[Epoch 60; Iter    79/  229] train: loss: 0.2034575
[Epoch 60; Iter   109/  229] train: loss: 0.2294214
[Epoch 60; Iter   139/  229] train: loss: 0.1596386
[Epoch 60; Iter   169/  229] train: loss: 0.1399772
[Epoch 60; Iter   199/  229] train: loss: 0.1800115
[Epoch 60; Iter   229/  229] train: loss: 0.1414906
[Epoch 60] ogbg-moltoxcast: 0.685178 val loss: 0.264054
[Epoch 60] ogbg-moltoxcast: 0.662314 test loss: 0.329977
[Epoch 61; Iter    30/  229] train: loss: 0.1441782
[Epoch 61; Iter    60/  229] train: loss: 0.1583206
[Epoch 61; Iter    90/  229] train: loss: 0.0874108
[Epoch 61; Iter   120/  229] train: loss: 0.0834687
[Epoch 61; Iter   150/  229] train: loss: 0.1608816
[Epoch 61; Iter   180/  229] train: loss: 0.1082566
[Epoch 61; Iter   210/  229] train: loss: 0.1117896
[Epoch 61] ogbg-moltoxcast: 0.696518 val loss: 0.263056
[Epoch 61] ogbg-moltoxcast: 0.666315 test loss: 0.328520
[Epoch 62; Iter    11/  229] train: loss: 0.1154613
[Epoch 62; Iter    41/  229] train: loss: 0.1439602
[Epoch 62; Iter    71/  229] train: loss: 0.0978562
[Epoch 62; Iter   101/  229] train: loss: 0.1142733
[Epoch 62; Iter   131/  229] train: loss: 0.1014301
[Epoch 62; Iter   161/  229] train: loss: 0.1231209
[Epoch 62; Iter   191/  229] train: loss: 0.1184041
[Epoch 62; Iter   221/  229] train: loss: 0.1262497
[Epoch 62] ogbg-moltoxcast: 0.696142 val loss: 0.288363
[Epoch 62] ogbg-moltoxcast: 0.664221 test loss: 0.381693
[Epoch 63; Iter    22/  229] train: loss: 0.1598996
[Epoch 63; Iter    52/  229] train: loss: 0.1533343
[Epoch 63; Iter    82/  229] train: loss: 0.1080234
[Epoch 63; Iter   112/  229] train: loss: 0.1348258
[Epoch 63; Iter   142/  229] train: loss: 0.1170248
[Epoch 63; Iter   172/  229] train: loss: 0.1697757
[Epoch 63; Iter   202/  229] train: loss: 0.0878157
[Epoch 63] ogbg-moltoxcast: 0.686500 val loss: 0.264511
[Epoch 63] ogbg-moltoxcast: 0.659501 test loss: 0.336547
[Epoch 64; Iter     3/  229] train: loss: 0.2037446
[Epoch 64; Iter    33/  229] train: loss: 0.1413174
[Epoch 64; Iter    63/  229] train: loss: 0.1765458
[Epoch 64; Iter    93/  229] train: loss: 0.1877593
[Epoch 64; Iter   123/  229] train: loss: 0.1544060
[Epoch 64; Iter   153/  229] train: loss: 0.1595870
[Epoch 64; Iter   183/  229] train: loss: 0.1708489
[Epoch 64; Iter   213/  229] train: loss: 0.1004611
[Epoch 64] ogbg-moltoxcast: 0.691753 val loss: 0.268756
[Epoch 64] ogbg-moltoxcast: 0.664136 test loss: 0.329959
[Epoch 65; Iter    14/  229] train: loss: 0.1058129
[Epoch 65; Iter    44/  229] train: loss: 0.1272512
[Epoch 65; Iter    74/  229] train: loss: 0.1286574
[Epoch 65; Iter   104/  229] train: loss: 0.1450304
[Epoch 65; Iter   134/  229] train: loss: 0.0971327
[Epoch 65; Iter   164/  229] train: loss: 0.1426886
[Epoch 65; Iter   194/  229] train: loss: 0.1037972
[Epoch 65; Iter   224/  229] train: loss: 0.1375312
[Epoch 65] ogbg-moltoxcast: 0.696254 val loss: 0.271869
[Epoch 65] ogbg-moltoxcast: 0.663077 test loss: 0.336812
[Epoch 66; Iter    25/  229] train: loss: 0.1250610
[Epoch 66; Iter    55/  229] train: loss: 0.1613565
[Epoch 66; Iter    85/  229] train: loss: 0.1000092
[Epoch 66; Iter   115/  229] train: loss: 0.1583545
[Epoch 66; Iter   145/  229] train: loss: 0.1126953
[Epoch 66; Iter   175/  229] train: loss: 0.1090591
[Epoch 66; Iter   205/  229] train: loss: 0.1584821
[Epoch 66] ogbg-moltoxcast: 0.693867 val loss: 0.271435
[Epoch 66] ogbg-moltoxcast: 0.664696 test loss: 0.338654
[Epoch 67; Iter     6/  229] train: loss: 0.0779336
[Epoch 67; Iter    36/  229] train: loss: 0.1168511
[Epoch 67; Iter    66/  229] train: loss: 0.1527141
[Epoch 67; Iter    96/  229] train: loss: 0.1153477
[Epoch 67; Iter   126/  229] train: loss: 0.1604919
[Epoch 67; Iter   156/  229] train: loss: 0.1128507
[Epoch 67; Iter   186/  229] train: loss: 0.1233111
[Epoch 67; Iter   216/  229] train: loss: 0.1076603
[Epoch 67] ogbg-moltoxcast: 0.693012 val loss: 0.271554
[Epoch 67] ogbg-moltoxcast: 0.662110 test loss: 0.373814
[Epoch 68; Iter    17/  229] train: loss: 0.1358141
[Epoch 68; Iter    47/  229] train: loss: 0.1352849
[Epoch 68; Iter    77/  229] train: loss: 0.1968662
[Epoch 68; Iter   107/  229] train: loss: 0.1243029
[Epoch 68; Iter   137/  229] train: loss: 0.1205506
[Epoch 68; Iter   167/  229] train: loss: 0.1485035
[Epoch 68; Iter   197/  229] train: loss: 0.1462125
[Epoch 68; Iter   227/  229] train: loss: 0.1407450
[Epoch 68] ogbg-moltoxcast: 0.690895 val loss: 0.275461
[Epoch 68] ogbg-moltoxcast: 0.661346 test loss: 0.354126
[Epoch 69; Iter    28/  229] train: loss: 0.1650994
[Epoch 69; Iter    58/  229] train: loss: 0.1499086
[Epoch 69; Iter    88/  229] train: loss: 0.1498950
[Epoch 69; Iter   118/  229] train: loss: 0.1944469
[Epoch 69; Iter   148/  229] train: loss: 0.1670500
[Epoch 69; Iter   178/  229] train: loss: 0.0964927
[Epoch 69; Iter   208/  229] train: loss: 0.1005937
[Epoch 69] ogbg-moltoxcast: 0.692831 val loss: 0.407599
[Epoch 69] ogbg-moltoxcast: 0.661262 test loss: 0.390721
[Epoch 70; Iter     9/  229] train: loss: 0.1582737
[Epoch 70; Iter    39/  229] train: loss: 0.1394164
[Epoch 70; Iter    69/  229] train: loss: 0.1326834
[Epoch 70; Iter    99/  229] train: loss: 0.1810748
[Epoch 70; Iter   129/  229] train: loss: 0.1401256
[Epoch 70; Iter   159/  229] train: loss: 0.1227886
[Epoch 70; Iter   189/  229] train: loss: 0.1222322
[Epoch 70; Iter   219/  229] train: loss: 0.1811301
[Epoch 70] ogbg-moltoxcast: 0.681762 val loss: 0.381222
[Epoch 70] ogbg-moltoxcast: 0.660367 test loss: 0.438437
[Epoch 71; Iter    20/  229] train: loss: 0.1322941
[Epoch 71; Iter    50/  229] train: loss: 0.1007069
[Epoch 71; Iter    80/  229] train: loss: 0.1531507
[Epoch 71; Iter   110/  229] train: loss: 0.1423987
[Epoch 71; Iter   140/  229] train: loss: 0.1340823
[Epoch 71; Iter   170/  229] train: loss: 0.1768515
[Epoch 71; Iter   200/  229] train: loss: 0.1458552
[Epoch 71] ogbg-moltoxcast: 0.692151 val loss: 0.294878
[Epoch 71] ogbg-moltoxcast: 0.659746 test loss: 0.377617
[Epoch 72; Iter     1/  229] train: loss: 0.1448610
[Epoch 72; Iter    31/  229] train: loss: 0.1341274
[Epoch 72; Iter    61/  229] train: loss: 0.1765406
[Epoch 72; Iter    91/  229] train: loss: 0.1046973
[Epoch 72; Iter   121/  229] train: loss: 0.0944695
[Epoch 72; Iter   151/  229] train: loss: 0.1551936
[Epoch 72; Iter   181/  229] train: loss: 0.1917780
[Epoch 72; Iter   211/  229] train: loss: 0.0990384
[Epoch 72] ogbg-moltoxcast: 0.687880 val loss: 0.448647
[Epoch 72] ogbg-moltoxcast: 0.661642 test loss: 0.390283
[Epoch 73; Iter    12/  229] train: loss: 0.1025853
[Epoch 73; Iter    42/  229] train: loss: 0.1433413
[Epoch 73; Iter    72/  229] train: loss: 0.1466885
[Epoch 73; Iter   102/  229] train: loss: 0.1387951
[Epoch 73; Iter   132/  229] train: loss: 0.1199259
[Epoch 73; Iter   162/  229] train: loss: 0.1365975
[Epoch 73; Iter   192/  229] train: loss: 0.1053217
[Epoch 73; Iter   222/  229] train: loss: 0.1235794
[Epoch 73] ogbg-moltoxcast: 0.682419 val loss: 0.270392
[Epoch 73] ogbg-moltoxcast: 0.657305 test loss: 0.342271
[Epoch 74; Iter    23/  229] train: loss: 0.0967902
[Epoch 74; Iter    53/  229] train: loss: 0.1506002
[Epoch 74; Iter    83/  229] train: loss: 0.1262255
[Epoch 74; Iter   113/  229] train: loss: 0.0982656
[Epoch 74; Iter   143/  229] train: loss: 0.1342710
[Epoch 74; Iter   173/  229] train: loss: 0.1406512
[Epoch 74; Iter   203/  229] train: loss: 0.1412755
[Epoch 74] ogbg-moltoxcast: 0.690690 val loss: 0.267792
[Epoch 74] ogbg-moltoxcast: 0.658682 test loss: 0.341558
[Epoch 75; Iter     4/  229] train: loss: 0.0902480
[Epoch 75; Iter    34/  229] train: loss: 0.1523512
[Epoch 75; Iter    64/  229] train: loss: 0.1878658
[Epoch 75; Iter    94/  229] train: loss: 0.1313857
[Epoch 75; Iter   124/  229] train: loss: 0.1317156
[Epoch 75; Iter   154/  229] train: loss: 0.1189958
[Epoch 75; Iter   184/  229] train: loss: 0.1780942
[Epoch 75; Iter   214/  229] train: loss: 0.1344871
[Epoch 75] ogbg-moltoxcast: 0.681633 val loss: 0.274282
[Epoch 75] ogbg-moltoxcast: 0.657068 test loss: 0.344265
[Epoch 76; Iter    15/  229] train: loss: 0.1459169
[Epoch 76; Iter    45/  229] train: loss: 0.1136276
[Epoch 76; Iter    75/  229] train: loss: 0.1853314
[Epoch 76; Iter   105/  229] train: loss: 0.1091530
[Epoch 76; Iter   135/  229] train: loss: 0.0955082
[Epoch 76; Iter   165/  229] train: loss: 0.1393426
[Epoch 76; Iter   195/  229] train: loss: 0.0764994
[Epoch 76; Iter   225/  229] train: loss: 0.1073956
[Epoch 76] ogbg-moltoxcast: 0.683224 val loss: 0.358444
[Epoch 76] ogbg-moltoxcast: 0.643883 test loss: 0.359260
[Epoch 77; Iter    26/  229] train: loss: 0.1273675
[Epoch 77; Iter    56/  229] train: loss: 0.1183804
[Epoch 77; Iter    86/  229] train: loss: 0.0914757
[Epoch 77; Iter   116/  229] train: loss: 0.1373114
[Epoch 77; Iter   146/  229] train: loss: 0.1095028
[Epoch 77; Iter   176/  229] train: loss: 0.1209586
[Epoch 77; Iter   206/  229] train: loss: 0.1474215
[Epoch 77] ogbg-moltoxcast: 0.687598 val loss: 0.359964
[Epoch 77] ogbg-moltoxcast: 0.646845 test loss: 0.368753
[Epoch 78; Iter     7/  229] train: loss: 0.1444381
[Epoch 78; Iter    37/  229] train: loss: 0.1279350
[Epoch 78; Iter    67/  229] train: loss: 0.0849988
[Epoch 78; Iter    97/  229] train: loss: 0.1373369
[Epoch 78; Iter   127/  229] train: loss: 0.1152146
[Epoch 78; Iter   157/  229] train: loss: 0.1109562
[Epoch 78; Iter   187/  229] train: loss: 0.1047629
[Epoch 78; Iter   217/  229] train: loss: 0.1116802
[Epoch 78] ogbg-moltoxcast: 0.695652 val loss: 0.358379
[Epoch 78] ogbg-moltoxcast: 0.651911 test loss: 0.356805
[Epoch 79; Iter    18/  229] train: loss: 0.0938401
[Epoch 79; Iter    48/  229] train: loss: 0.1138634
[Epoch 79; Iter    78/  229] train: loss: 0.0969718
[Epoch 79; Iter   108/  229] train: loss: 0.1246430
[Epoch 79; Iter   138/  229] train: loss: 0.1068665
[Epoch 79; Iter   168/  229] train: loss: 0.0776617
[Epoch 79; Iter   198/  229] train: loss: 0.0699958
[Epoch 79; Iter   228/  229] train: loss: 0.1463378
[Epoch 79] ogbg-moltoxcast: 0.696638 val loss: 0.353335
[Epoch 79] ogbg-moltoxcast: 0.644882 test loss: 0.368145
[Epoch 80; Iter    29/  229] train: loss: 0.1367659
[Epoch 80; Iter    59/  229] train: loss: 0.1033850
[Epoch 80; Iter    89/  229] train: loss: 0.0948563
[Epoch 80; Iter   119/  229] train: loss: 0.1381654
[Epoch 80; Iter   149/  229] train: loss: 0.1324706
[Epoch 80; Iter   179/  229] train: loss: 0.2203031
[Epoch 80; Iter   209/  229] train: loss: 0.1181590
[Epoch 80] ogbg-moltoxcast: 0.692288 val loss: 0.337643
[Epoch 80] ogbg-moltoxcast: 0.645753 test loss: 0.350191
[Epoch 81; Iter    10/  229] train: loss: 0.0847377
[Epoch 81; Iter    40/  229] train: loss: 0.1135099
[Epoch 81; Iter    70/  229] train: loss: 0.1516930
[Epoch 81; Iter   100/  229] train: loss: 0.1164305
[Epoch 81; Iter   130/  229] train: loss: 0.1014096
[Epoch 81; Iter   160/  229] train: loss: 0.1293315
[Epoch 81; Iter   190/  229] train: loss: 0.1669249
[Epoch 81; Iter   220/  229] train: loss: 0.0849524
[Epoch 81] ogbg-moltoxcast: 0.694623 val loss: 0.324202
[Epoch 81] ogbg-moltoxcast: 0.640878 test loss: 0.356437
[Epoch 82; Iter    21/  229] train: loss: 0.0685767
[Epoch 82; Iter    51/  229] train: loss: 0.1126444
[Epoch 82; Iter    81/  229] train: loss: 0.1019767
[Epoch 82; Iter   111/  229] train: loss: 0.0951410
[Epoch 82; Iter   141/  229] train: loss: 0.1455646
[Epoch 82; Iter   171/  229] train: loss: 0.1015816
[Epoch 82; Iter   201/  229] train: loss: 0.0911333
[Epoch 82] ogbg-moltoxcast: 0.689048 val loss: 0.309237
[Epoch 82] ogbg-moltoxcast: 0.645873 test loss: 0.354548
[Epoch 83; Iter     2/  229] train: loss: 0.0866465
[Epoch 83; Iter    32/  229] train: loss: 0.1490135
[Epoch 83; Iter    62/  229] train: loss: 0.1396988
[Epoch 83; Iter    92/  229] train: loss: 0.0896233
[Epoch 83; Iter   122/  229] train: loss: 0.1005940
[Epoch 83; Iter   152/  229] train: loss: 0.0908483
[Epoch 83; Iter   182/  229] train: loss: 0.1326923
[Epoch 83; Iter   212/  229] train: loss: 0.0805366
[Epoch 83] ogbg-moltoxcast: 0.689553 val loss: 0.311975
[Epoch 83] ogbg-moltoxcast: 0.647621 test loss: 0.363233
[Epoch 84; Iter    13/  229] train: loss: 0.1623580
[Epoch 84; Iter    43/  229] train: loss: 0.1268537
[Epoch 84; Iter    73/  229] train: loss: 0.1591615
[Epoch 84; Iter   103/  229] train: loss: 0.0874252
[Epoch 84; Iter   133/  229] train: loss: 0.0940646
[Epoch 84; Iter   163/  229] train: loss: 0.0888914
[Epoch 84; Iter   193/  229] train: loss: 0.1434221
[Epoch 84; Iter   223/  229] train: loss: 0.1146517
[Epoch 84] ogbg-moltoxcast: 0.687118 val loss: 0.324394
[Epoch 84] ogbg-moltoxcast: 0.642336 test loss: 0.353638
[Epoch 85; Iter    24/  229] train: loss: 0.0705751
[Epoch 85; Iter    54/  229] train: loss: 0.1267389
[Epoch 85; Iter    84/  229] train: loss: 0.1190424
[Epoch 85; Iter   114/  229] train: loss: 0.0799889
[Epoch 85; Iter   144/  229] train: loss: 0.1028488
[Epoch 85; Iter   174/  229] train: loss: 0.1368599
[Epoch 85; Iter   204/  229] train: loss: 0.1191163
[Epoch 85] ogbg-moltoxcast: 0.690138 val loss: 0.293782
[Epoch 85] ogbg-moltoxcast: 0.645658 test loss: 0.359873
[Epoch 86; Iter     5/  229] train: loss: 0.0841470
[Epoch 86; Iter    35/  229] train: loss: 0.1570359
[Epoch 86; Iter    65/  229] train: loss: 0.1451460
[Epoch 86; Iter    95/  229] train: loss: 0.1386617
[Epoch 86; Iter   125/  229] train: loss: 0.1029207
[Epoch 86; Iter   155/  229] train: loss: 0.1394581
[Epoch 86; Iter   185/  229] train: loss: 0.1588617
[Epoch 86; Iter   215/  229] train: loss: 0.1285501
[Epoch 86] ogbg-moltoxcast: 0.685439 val loss: 0.323850
[Epoch 86] ogbg-moltoxcast: 0.647227 test loss: 0.359123
[Epoch 87; Iter    16/  229] train: loss: 0.1253294
[Epoch 87; Iter    46/  229] train: loss: 0.1383251
[Epoch 87; Iter    76/  229] train: loss: 0.0748562
[Epoch 87; Iter   106/  229] train: loss: 0.0923410
[Epoch 87; Iter   136/  229] train: loss: 0.0944620
[Epoch 87; Iter   166/  229] train: loss: 0.1149364
[Epoch 87; Iter   196/  229] train: loss: 0.1596179
[Epoch 87; Iter   226/  229] train: loss: 0.1372564
[Epoch 87] ogbg-moltoxcast: 0.689955 val loss: 0.301438
[Epoch 87] ogbg-moltoxcast: 0.644674 test loss: 0.359619
[Epoch 88; Iter    27/  229] train: loss: 0.1019151
[Epoch 88; Iter    57/  229] train: loss: 0.0776973
[Epoch 88; Iter    87/  229] train: loss: 0.0923120
[Epoch 88; Iter   117/  229] train: loss: 0.1026152
[Epoch 88; Iter   147/  229] train: loss: 0.1182968
[Epoch 88; Iter   177/  229] train: loss: 0.0924809
[Epoch 88; Iter   207/  229] train: loss: 0.0967468
[Epoch 88] ogbg-moltoxcast: 0.688851 val loss: 0.335861
[Epoch 88] ogbg-moltoxcast: 0.646398 test loss: 0.374680
[Epoch 89; Iter     8/  229] train: loss: 0.1098071
[Epoch 89; Iter    38/  229] train: loss: 0.1251675
[Epoch 89; Iter    68/  229] train: loss: 0.1039459
[Epoch 89; Iter    98/  229] train: loss: 0.1273722
[Epoch 89; Iter   128/  229] train: loss: 0.1521500
[Epoch 89; Iter   158/  229] train: loss: 0.1073008
[Epoch 89; Iter   188/  229] train: loss: 0.0718932
[Epoch 89; Iter   218/  229] train: loss: 0.1176348
[Epoch 89] ogbg-moltoxcast: 0.685689 val loss: 0.344049
[Epoch 89] ogbg-moltoxcast: 0.642213 test loss: 0.368494
[Epoch 90; Iter    19/  229] train: loss: 0.0890900
[Epoch 90; Iter    49/  229] train: loss: 0.1010642
[Epoch 90; Iter    79/  229] train: loss: 0.0792626
[Epoch 90; Iter   109/  229] train: loss: 0.1063734
[Epoch 90; Iter   139/  229] train: loss: 0.1517074
[Epoch 90; Iter   169/  229] train: loss: 0.1428648
[Epoch 90; Iter   199/  229] train: loss: 0.1356162
[Epoch 90; Iter   229/  229] train: loss: 0.1561393
[Epoch 90] ogbg-moltoxcast: 0.687939 val loss: 0.324056
[Epoch 90] ogbg-moltoxcast: 0.648083 test loss: 0.354759
[Epoch 91; Iter    30/  229] train: loss: 0.0848392
[Epoch 91; Iter    60/  229] train: loss: 0.0956220
[Epoch 91; Iter    90/  229] train: loss: 0.1072099
[Epoch 91; Iter   120/  229] train: loss: 0.1173737
[Epoch 91; Iter   150/  229] train: loss: 0.0842822
[Epoch 91; Iter   180/  229] train: loss: 0.1396297
[Epoch 91; Iter   210/  229] train: loss: 0.1290011
[Epoch 91] ogbg-moltoxcast: 0.682929 val loss: 0.328292
[Epoch 91] ogbg-moltoxcast: 0.643061 test loss: 0.365304
[Epoch 76; Iter    15/  229] train: loss: 0.1082466
[Epoch 76; Iter    45/  229] train: loss: 0.1230514
[Epoch 76; Iter    75/  229] train: loss: 0.1350685
[Epoch 76; Iter   105/  229] train: loss: 0.1308533
[Epoch 76; Iter   135/  229] train: loss: 0.0948654
[Epoch 76; Iter   165/  229] train: loss: 0.1283643
[Epoch 76; Iter   195/  229] train: loss: 0.1145070
[Epoch 76; Iter   225/  229] train: loss: 0.1321473
[Epoch 76] ogbg-moltoxcast: 0.671155 val loss: 0.593061
[Epoch 76] ogbg-moltoxcast: 0.646014 test loss: 0.339179
[Epoch 77; Iter    26/  229] train: loss: 0.1096653
[Epoch 77; Iter    56/  229] train: loss: 0.1012650
[Epoch 77; Iter    86/  229] train: loss: 0.1713508
[Epoch 77; Iter   116/  229] train: loss: 0.1260253
[Epoch 77; Iter   146/  229] train: loss: 0.0995247
[Epoch 77; Iter   176/  229] train: loss: 0.1286243
[Epoch 77; Iter   206/  229] train: loss: 0.1350427
[Epoch 77] ogbg-moltoxcast: 0.677720 val loss: 0.514196
[Epoch 77] ogbg-moltoxcast: 0.652359 test loss: 0.348099
[Epoch 78; Iter     7/  229] train: loss: 0.1259759
[Epoch 78; Iter    37/  229] train: loss: 0.1072193
[Epoch 78; Iter    67/  229] train: loss: 0.0942138
[Epoch 78; Iter    97/  229] train: loss: 0.1150145
[Epoch 78; Iter   127/  229] train: loss: 0.1632036
[Epoch 78; Iter   157/  229] train: loss: 0.0980526
[Epoch 78; Iter   187/  229] train: loss: 0.1313557
[Epoch 78; Iter   217/  229] train: loss: 0.1154904
[Epoch 78] ogbg-moltoxcast: 0.670160 val loss: 0.455570
[Epoch 78] ogbg-moltoxcast: 0.647918 test loss: 0.345755
[Epoch 79; Iter    18/  229] train: loss: 0.1668715
[Epoch 79; Iter    48/  229] train: loss: 0.1368612
[Epoch 79; Iter    78/  229] train: loss: 0.1422542
[Epoch 79; Iter   108/  229] train: loss: 0.1318505
[Epoch 79; Iter   138/  229] train: loss: 0.1419160
[Epoch 79; Iter   168/  229] train: loss: 0.1364302
[Epoch 79; Iter   198/  229] train: loss: 0.0902537
[Epoch 79; Iter   228/  229] train: loss: 0.1336147
[Epoch 79] ogbg-moltoxcast: 0.668912 val loss: 0.505533
[Epoch 79] ogbg-moltoxcast: 0.640734 test loss: 0.351810
[Epoch 80; Iter    29/  229] train: loss: 0.1110488
[Epoch 80; Iter    59/  229] train: loss: 0.1048925
[Epoch 80; Iter    89/  229] train: loss: 0.1286200
[Epoch 80; Iter   119/  229] train: loss: 0.1175751
[Epoch 80; Iter   149/  229] train: loss: 0.1115744
[Epoch 80; Iter   179/  229] train: loss: 0.1076469
[Epoch 80; Iter   209/  229] train: loss: 0.1259080
[Epoch 80] ogbg-moltoxcast: 0.669198 val loss: 0.508640
[Epoch 80] ogbg-moltoxcast: 0.643206 test loss: 0.346513
[Epoch 81; Iter    10/  229] train: loss: 0.1225632
[Epoch 81; Iter    40/  229] train: loss: 0.1410480
[Epoch 81; Iter    70/  229] train: loss: 0.1218658
[Epoch 81; Iter   100/  229] train: loss: 0.1324263
[Epoch 81; Iter   130/  229] train: loss: 0.1458742
[Epoch 81; Iter   160/  229] train: loss: 0.1322709
[Epoch 81; Iter   190/  229] train: loss: 0.1202955
[Epoch 81; Iter   220/  229] train: loss: 0.0941698
[Epoch 81] ogbg-moltoxcast: 0.671669 val loss: 0.586937
[Epoch 81] ogbg-moltoxcast: 0.642819 test loss: 0.352877
[Epoch 82; Iter    21/  229] train: loss: 0.0881266
[Epoch 82; Iter    51/  229] train: loss: 0.1192104
[Epoch 82; Iter    81/  229] train: loss: 0.1280038
[Epoch 82; Iter   111/  229] train: loss: 0.1004488
[Epoch 82; Iter   141/  229] train: loss: 0.0954888
[Epoch 82; Iter   171/  229] train: loss: 0.1196277
[Epoch 82; Iter   201/  229] train: loss: 0.1146568
[Epoch 82] ogbg-moltoxcast: 0.668193 val loss: 0.462455
[Epoch 82] ogbg-moltoxcast: 0.644497 test loss: 0.354378
[Epoch 83; Iter     2/  229] train: loss: 0.1609400
[Epoch 83; Iter    32/  229] train: loss: 0.0964215
[Epoch 83; Iter    62/  229] train: loss: 0.1024256
[Epoch 83; Iter    92/  229] train: loss: 0.1241707
[Epoch 83; Iter   122/  229] train: loss: 0.1064163
[Epoch 83; Iter   152/  229] train: loss: 0.0932845
[Epoch 83; Iter   182/  229] train: loss: 0.0811304
[Epoch 83; Iter   212/  229] train: loss: 0.1500798
[Epoch 83] ogbg-moltoxcast: 0.667578 val loss: 0.422958
[Epoch 83] ogbg-moltoxcast: 0.641816 test loss: 0.347477
[Epoch 84; Iter    13/  229] train: loss: 0.1082268
[Epoch 84; Iter    43/  229] train: loss: 0.1077635
[Epoch 84; Iter    73/  229] train: loss: 0.0857106
[Epoch 84; Iter   103/  229] train: loss: 0.1077267
[Epoch 84; Iter   133/  229] train: loss: 0.0738951
[Epoch 84; Iter   163/  229] train: loss: 0.1084453
[Epoch 84; Iter   193/  229] train: loss: 0.1371498
[Epoch 84; Iter   223/  229] train: loss: 0.1016436
[Epoch 84] ogbg-moltoxcast: 0.664496 val loss: 0.494500
[Epoch 84] ogbg-moltoxcast: 0.644733 test loss: 0.349195
[Epoch 85; Iter    24/  229] train: loss: 0.1248324
[Epoch 85; Iter    54/  229] train: loss: 0.1134464
[Epoch 85; Iter    84/  229] train: loss: 0.1155123
[Epoch 85; Iter   114/  229] train: loss: 0.0876587
[Epoch 85; Iter   144/  229] train: loss: 0.1092857
[Epoch 85; Iter   174/  229] train: loss: 0.1732425
[Epoch 85; Iter   204/  229] train: loss: 0.1358783
[Epoch 85] ogbg-moltoxcast: 0.664115 val loss: 0.569676
[Epoch 85] ogbg-moltoxcast: 0.645193 test loss: 0.352363
[Epoch 86; Iter     5/  229] train: loss: 0.1014701
[Epoch 86; Iter    35/  229] train: loss: 0.1207410
[Epoch 86; Iter    65/  229] train: loss: 0.0754524
[Epoch 86; Iter    95/  229] train: loss: 0.1320960
[Epoch 86; Iter   125/  229] train: loss: 0.0737164
[Epoch 86; Iter   155/  229] train: loss: 0.1110995
[Epoch 86; Iter   185/  229] train: loss: 0.1094407
[Epoch 86; Iter   215/  229] train: loss: 0.1514746
[Epoch 86] ogbg-moltoxcast: 0.670551 val loss: 0.545331
[Epoch 86] ogbg-moltoxcast: 0.643868 test loss: 0.354087
[Epoch 87; Iter    16/  229] train: loss: 0.0798258
[Epoch 87; Iter    46/  229] train: loss: 0.0967930
[Epoch 87; Iter    76/  229] train: loss: 0.1338552
[Epoch 87; Iter   106/  229] train: loss: 0.1153668
[Epoch 87; Iter   136/  229] train: loss: 0.1792295
[Epoch 87; Iter   166/  229] train: loss: 0.1078469
[Epoch 87; Iter   196/  229] train: loss: 0.1147806
[Epoch 87; Iter   226/  229] train: loss: 0.0971916
[Epoch 87] ogbg-moltoxcast: 0.665058 val loss: 0.484436
[Epoch 87] ogbg-moltoxcast: 0.644055 test loss: 0.353340
[Epoch 88; Iter    27/  229] train: loss: 0.1164762
[Epoch 88; Iter    57/  229] train: loss: 0.1112000
[Epoch 88; Iter    87/  229] train: loss: 0.1077673
[Epoch 88; Iter   117/  229] train: loss: 0.1381202
[Epoch 88; Iter   147/  229] train: loss: 0.1138880
[Epoch 88; Iter   177/  229] train: loss: 0.1196345
[Epoch 88; Iter   207/  229] train: loss: 0.0922948
[Epoch 88] ogbg-moltoxcast: 0.666554 val loss: 0.526880
[Epoch 88] ogbg-moltoxcast: 0.642542 test loss: 0.348099
[Epoch 89; Iter     8/  229] train: loss: 0.1226343
[Epoch 89; Iter    38/  229] train: loss: 0.1350903
[Epoch 89; Iter    68/  229] train: loss: 0.1408234
[Epoch 89; Iter    98/  229] train: loss: 0.1096590
[Epoch 89; Iter   128/  229] train: loss: 0.1009124
[Epoch 89; Iter   158/  229] train: loss: 0.1010796
[Epoch 89; Iter   188/  229] train: loss: 0.0951438
[Epoch 89; Iter   218/  229] train: loss: 0.1307631
[Epoch 89] ogbg-moltoxcast: 0.665721 val loss: 0.412449
[Epoch 89] ogbg-moltoxcast: 0.642406 test loss: 0.353045
[Epoch 90; Iter    19/  229] train: loss: 0.1114738
[Epoch 90; Iter    49/  229] train: loss: 0.1122209
[Epoch 90; Iter    79/  229] train: loss: 0.1028968
[Epoch 90; Iter   109/  229] train: loss: 0.0809706
[Epoch 90; Iter   139/  229] train: loss: 0.0878326
[Epoch 90; Iter   169/  229] train: loss: 0.0948362
[Epoch 90; Iter   199/  229] train: loss: 0.1571315
[Epoch 90; Iter   229/  229] train: loss: 0.1273467
[Epoch 90] ogbg-moltoxcast: 0.664393 val loss: 0.527841
[Epoch 90] ogbg-moltoxcast: 0.642205 test loss: 0.354832
[Epoch 91; Iter    30/  229] train: loss: 0.1087184
[Epoch 91; Iter    60/  229] train: loss: 0.1305617
[Epoch 91; Iter    90/  229] train: loss: 0.1408110
[Epoch 91; Iter   120/  229] train: loss: 0.1038099
[Epoch 91; Iter   150/  229] train: loss: 0.1382240
[Epoch 91; Iter   180/  229] train: loss: 0.1679084
[Epoch 91; Iter   210/  229] train: loss: 0.1597150
[Epoch 91] ogbg-moltoxcast: 0.662685 val loss: 0.524878
[Epoch 91] ogbg-moltoxcast: 0.640197 test loss: 0.357950
[Epoch 76; Iter    15/  229] train: loss: 0.1018764
[Epoch 76; Iter    45/  229] train: loss: 0.1248431
[Epoch 76; Iter    75/  229] train: loss: 0.1330345
[Epoch 76; Iter   105/  229] train: loss: 0.0820253
[Epoch 76; Iter   135/  229] train: loss: 0.1737339
[Epoch 76; Iter   165/  229] train: loss: 0.0929536
[Epoch 76; Iter   195/  229] train: loss: 0.1121136
[Epoch 76; Iter   225/  229] train: loss: 0.0915532
[Epoch 76] ogbg-moltoxcast: 0.657241 val loss: 0.317999
[Epoch 76] ogbg-moltoxcast: 0.656807 test loss: 0.361557
[Epoch 77; Iter    26/  229] train: loss: 0.1318831
[Epoch 77; Iter    56/  229] train: loss: 0.0948069
[Epoch 77; Iter    86/  229] train: loss: 0.1950981
[Epoch 77; Iter   116/  229] train: loss: 0.1514281
[Epoch 77; Iter   146/  229] train: loss: 0.1285505
[Epoch 77; Iter   176/  229] train: loss: 0.1423227
[Epoch 77; Iter   206/  229] train: loss: 0.1326103
[Epoch 77] ogbg-moltoxcast: 0.661572 val loss: 0.316836
[Epoch 77] ogbg-moltoxcast: 0.659326 test loss: 0.360200
[Epoch 78; Iter     7/  229] train: loss: 0.1200068
[Epoch 78; Iter    37/  229] train: loss: 0.1214622
[Epoch 78; Iter    67/  229] train: loss: 0.1152454
[Epoch 78; Iter    97/  229] train: loss: 0.0832358
[Epoch 78; Iter   127/  229] train: loss: 0.1088448
[Epoch 78; Iter   157/  229] train: loss: 0.1130723
[Epoch 78; Iter   187/  229] train: loss: 0.1363284
[Epoch 78; Iter   217/  229] train: loss: 0.1339365
[Epoch 78] ogbg-moltoxcast: 0.660943 val loss: 0.325453
[Epoch 78] ogbg-moltoxcast: 0.655254 test loss: 0.369898
[Epoch 79; Iter    18/  229] train: loss: 0.0892423
[Epoch 79; Iter    48/  229] train: loss: 0.1312911
[Epoch 79; Iter    78/  229] train: loss: 0.1308775
[Epoch 79; Iter   108/  229] train: loss: 0.1327179
[Epoch 79; Iter   138/  229] train: loss: 0.1641473
[Epoch 79; Iter   168/  229] train: loss: 0.1593484
[Epoch 79; Iter   198/  229] train: loss: 0.1410293
[Epoch 79; Iter   228/  229] train: loss: 0.1437665
[Epoch 79] ogbg-moltoxcast: 0.665878 val loss: 0.314826
[Epoch 79] ogbg-moltoxcast: 0.656518 test loss: 0.361427
[Epoch 80; Iter    29/  229] train: loss: 0.1325338
[Epoch 80; Iter    59/  229] train: loss: 0.1098654
[Epoch 80; Iter    89/  229] train: loss: 0.1457785
[Epoch 80; Iter   119/  229] train: loss: 0.1081403
[Epoch 80; Iter   149/  229] train: loss: 0.1282877
[Epoch 80; Iter   179/  229] train: loss: 0.1345536
[Epoch 80; Iter   209/  229] train: loss: 0.1356738
[Epoch 80] ogbg-moltoxcast: 0.661787 val loss: 0.323171
[Epoch 80] ogbg-moltoxcast: 0.651781 test loss: 0.369326
[Epoch 81; Iter    10/  229] train: loss: 0.0955875
[Epoch 81; Iter    40/  229] train: loss: 0.1406315
[Epoch 81; Iter    70/  229] train: loss: 0.1299755
[Epoch 81; Iter   100/  229] train: loss: 0.0717136
[Epoch 81; Iter   130/  229] train: loss: 0.0888285
[Epoch 81; Iter   160/  229] train: loss: 0.1316622
[Epoch 81; Iter   190/  229] train: loss: 0.1268959
[Epoch 81; Iter   220/  229] train: loss: 0.1209034
[Epoch 81] ogbg-moltoxcast: 0.656047 val loss: 0.324769
[Epoch 81] ogbg-moltoxcast: 0.657029 test loss: 0.368465
[Epoch 82; Iter    21/  229] train: loss: 0.1287364
[Epoch 82; Iter    51/  229] train: loss: 0.1327274
[Epoch 82; Iter    81/  229] train: loss: 0.0931537
[Epoch 82; Iter   111/  229] train: loss: 0.1049773
[Epoch 82; Iter   141/  229] train: loss: 0.1362977
[Epoch 82; Iter   171/  229] train: loss: 0.0957493
[Epoch 82; Iter   201/  229] train: loss: 0.1357650
[Epoch 82] ogbg-moltoxcast: 0.655973 val loss: 0.319217
[Epoch 82] ogbg-moltoxcast: 0.656036 test loss: 0.367516
[Epoch 83; Iter     2/  229] train: loss: 0.1072162
[Epoch 83; Iter    32/  229] train: loss: 0.1034425
[Epoch 83; Iter    62/  229] train: loss: 0.0891618
[Epoch 83; Iter    92/  229] train: loss: 0.1448243
[Epoch 83; Iter   122/  229] train: loss: 0.1096331
[Epoch 83; Iter   152/  229] train: loss: 0.1461696
[Epoch 83; Iter   182/  229] train: loss: 0.1549737
[Epoch 83; Iter   212/  229] train: loss: 0.1117997
[Epoch 83] ogbg-moltoxcast: 0.656574 val loss: 0.326199
[Epoch 83] ogbg-moltoxcast: 0.652160 test loss: 0.370273
[Epoch 84; Iter    13/  229] train: loss: 0.1305965
[Epoch 84; Iter    43/  229] train: loss: 0.1150213
[Epoch 84; Iter    73/  229] train: loss: 0.1453909
[Epoch 84; Iter   103/  229] train: loss: 0.0993532
[Epoch 84; Iter   133/  229] train: loss: 0.1279891
[Epoch 84; Iter   163/  229] train: loss: 0.0828013
[Epoch 84; Iter   193/  229] train: loss: 0.1326210
[Epoch 84; Iter   223/  229] train: loss: 0.1033060
[Epoch 84] ogbg-moltoxcast: 0.662421 val loss: 0.318848
[Epoch 84] ogbg-moltoxcast: 0.660244 test loss: 0.362916
[Epoch 85; Iter    24/  229] train: loss: 0.1094713
[Epoch 85; Iter    54/  229] train: loss: 0.0964166
[Epoch 85; Iter    84/  229] train: loss: 0.1023561
[Epoch 85; Iter   114/  229] train: loss: 0.0961550
[Epoch 85; Iter   144/  229] train: loss: 0.1224991
[Epoch 85; Iter   174/  229] train: loss: 0.1343095
[Epoch 85; Iter   204/  229] train: loss: 0.1534540
[Epoch 85] ogbg-moltoxcast: 0.658948 val loss: 0.319420
[Epoch 85] ogbg-moltoxcast: 0.654990 test loss: 0.365869
[Epoch 86; Iter     5/  229] train: loss: 0.1614063
[Epoch 86; Iter    35/  229] train: loss: 0.1393772
[Epoch 86; Iter    65/  229] train: loss: 0.1186986
[Epoch 86; Iter    95/  229] train: loss: 0.1403152
[Epoch 86; Iter   125/  229] train: loss: 0.1130465
[Epoch 86; Iter   155/  229] train: loss: 0.1108502
[Epoch 86; Iter   185/  229] train: loss: 0.1283643
[Epoch 86; Iter   215/  229] train: loss: 0.1394171
[Epoch 86] ogbg-moltoxcast: 0.656245 val loss: 0.329679
[Epoch 86] ogbg-moltoxcast: 0.659855 test loss: 0.377744
[Epoch 87; Iter    16/  229] train: loss: 0.1008881
[Epoch 87; Iter    46/  229] train: loss: 0.1112043
[Epoch 87; Iter    76/  229] train: loss: 0.1011954
[Epoch 87; Iter   106/  229] train: loss: 0.1102611
[Epoch 87; Iter   136/  229] train: loss: 0.1211443
[Epoch 87; Iter   166/  229] train: loss: 0.1163958
[Epoch 87; Iter   196/  229] train: loss: 0.1239516
[Epoch 87; Iter   226/  229] train: loss: 0.1105272
[Epoch 87] ogbg-moltoxcast: 0.655227 val loss: 0.324952
[Epoch 87] ogbg-moltoxcast: 0.657791 test loss: 0.364531
[Epoch 88; Iter    27/  229] train: loss: 0.1802235
[Epoch 88; Iter    57/  229] train: loss: 0.1079518
[Epoch 88; Iter    87/  229] train: loss: 0.1052084
[Epoch 88; Iter   117/  229] train: loss: 0.1201932
[Epoch 88; Iter   147/  229] train: loss: 0.1032075
[Epoch 88; Iter   177/  229] train: loss: 0.1138304
[Epoch 88; Iter   207/  229] train: loss: 0.1190531
[Epoch 88] ogbg-moltoxcast: 0.655576 val loss: 0.325569
[Epoch 88] ogbg-moltoxcast: 0.652102 test loss: 0.368947
[Epoch 89; Iter     8/  229] train: loss: 0.0971850
[Epoch 89; Iter    38/  229] train: loss: 0.0999245
[Epoch 89; Iter    68/  229] train: loss: 0.1236044
[Epoch 89; Iter    98/  229] train: loss: 0.0948843
[Epoch 89; Iter   128/  229] train: loss: 0.1146638
[Epoch 89; Iter   158/  229] train: loss: 0.1142719
[Epoch 89; Iter   188/  229] train: loss: 0.0994211
[Epoch 89; Iter   218/  229] train: loss: 0.0900395
[Epoch 89] ogbg-moltoxcast: 0.660628 val loss: 0.322247
[Epoch 89] ogbg-moltoxcast: 0.654992 test loss: 0.368198
[Epoch 90; Iter    19/  229] train: loss: 0.1104693
[Epoch 90; Iter    49/  229] train: loss: 0.1396237
[Epoch 90; Iter    79/  229] train: loss: 0.1431117
[Epoch 90; Iter   109/  229] train: loss: 0.1541056
[Epoch 90; Iter   139/  229] train: loss: 0.1364727
[Epoch 90; Iter   169/  229] train: loss: 0.1155090
[Epoch 90; Iter   199/  229] train: loss: 0.0863901
[Epoch 90; Iter   229/  229] train: loss: 0.1094021
[Epoch 90] ogbg-moltoxcast: 0.654636 val loss: 0.325182
[Epoch 90] ogbg-moltoxcast: 0.654532 test loss: 0.371832
[Epoch 91; Iter    30/  229] train: loss: 0.1202778
[Epoch 91; Iter    60/  229] train: loss: 0.0949470
[Epoch 91; Iter    90/  229] train: loss: 0.1112324
[Epoch 91; Iter   120/  229] train: loss: 0.0965071
[Epoch 91; Iter   150/  229] train: loss: 0.1123678
[Epoch 91; Iter   180/  229] train: loss: 0.1258265
[Epoch 91; Iter   210/  229] train: loss: 0.1296636
[Epoch 91] ogbg-moltoxcast: 0.660879 val loss: 0.321223
[Epoch 91] ogbg-moltoxcast: 0.652739 test loss: 0.366824
[Epoch 60; Iter    19/  229] train: loss: 0.1052893
[Epoch 60; Iter    49/  229] train: loss: 0.1382830
[Epoch 60; Iter    79/  229] train: loss: 0.1715361
[Epoch 60; Iter   109/  229] train: loss: 0.1243260
[Epoch 60; Iter   139/  229] train: loss: 0.1453148
[Epoch 60; Iter   169/  229] train: loss: 0.1066597
[Epoch 60; Iter   199/  229] train: loss: 0.1706438
[Epoch 60; Iter   229/  229] train: loss: 0.1440695
[Epoch 60] ogbg-moltoxcast: 0.680676 val loss: 0.263891
[Epoch 60] ogbg-moltoxcast: 0.663686 test loss: 0.312992
[Epoch 61; Iter    30/  229] train: loss: 0.1546526
[Epoch 61; Iter    60/  229] train: loss: 0.1699293
[Epoch 61; Iter    90/  229] train: loss: 0.1679543
[Epoch 61; Iter   120/  229] train: loss: 0.1431461
[Epoch 61; Iter   150/  229] train: loss: 0.1540174
[Epoch 61; Iter   180/  229] train: loss: 0.1548989
[Epoch 61; Iter   210/  229] train: loss: 0.0964673
[Epoch 61] ogbg-moltoxcast: 0.690735 val loss: 0.258672
[Epoch 61] ogbg-moltoxcast: 0.653785 test loss: 0.317651
[Epoch 62; Iter    11/  229] train: loss: 0.0871723
[Epoch 62; Iter    41/  229] train: loss: 0.1904455
[Epoch 62; Iter    71/  229] train: loss: 0.1390020
[Epoch 62; Iter   101/  229] train: loss: 0.1347384
[Epoch 62; Iter   131/  229] train: loss: 0.1700384
[Epoch 62; Iter   161/  229] train: loss: 0.1265365
[Epoch 62; Iter   191/  229] train: loss: 0.1345536
[Epoch 62; Iter   221/  229] train: loss: 0.1538222
[Epoch 62] ogbg-moltoxcast: 0.687369 val loss: 0.262966
[Epoch 62] ogbg-moltoxcast: 0.659979 test loss: 0.317122
[Epoch 63; Iter    22/  229] train: loss: 0.1446202
[Epoch 63; Iter    52/  229] train: loss: 0.0920061
[Epoch 63; Iter    82/  229] train: loss: 0.0963764
[Epoch 63; Iter   112/  229] train: loss: 0.1042341
[Epoch 63; Iter   142/  229] train: loss: 0.1877607
[Epoch 63; Iter   172/  229] train: loss: 0.1734943
[Epoch 63; Iter   202/  229] train: loss: 0.1199587
[Epoch 63] ogbg-moltoxcast: 0.684739 val loss: 0.266703
[Epoch 63] ogbg-moltoxcast: 0.661704 test loss: 0.316623
[Epoch 64; Iter     3/  229] train: loss: 0.0878137
[Epoch 64; Iter    33/  229] train: loss: 0.1345836
[Epoch 64; Iter    63/  229] train: loss: 0.1493922
[Epoch 64; Iter    93/  229] train: loss: 0.1197392
[Epoch 64; Iter   123/  229] train: loss: 0.1215433
[Epoch 64; Iter   153/  229] train: loss: 0.1065945
[Epoch 64; Iter   183/  229] train: loss: 0.1069023
[Epoch 64; Iter   213/  229] train: loss: 0.1475694
[Epoch 64] ogbg-moltoxcast: 0.684447 val loss: 0.261863
[Epoch 64] ogbg-moltoxcast: 0.652373 test loss: 0.320612
[Epoch 65; Iter    14/  229] train: loss: 0.1518037
[Epoch 65; Iter    44/  229] train: loss: 0.1479393
[Epoch 65; Iter    74/  229] train: loss: 0.1273460
[Epoch 65; Iter   104/  229] train: loss: 0.1512254
[Epoch 65; Iter   134/  229] train: loss: 0.1198662
[Epoch 65; Iter   164/  229] train: loss: 0.1499154
[Epoch 65; Iter   194/  229] train: loss: 0.1108398
[Epoch 65; Iter   224/  229] train: loss: 0.1419921
[Epoch 65] ogbg-moltoxcast: 0.677513 val loss: 0.264688
[Epoch 65] ogbg-moltoxcast: 0.651260 test loss: 0.312984
[Epoch 66; Iter    25/  229] train: loss: 0.1232823
[Epoch 66; Iter    55/  229] train: loss: 0.1650721
[Epoch 66; Iter    85/  229] train: loss: 0.1481225
[Epoch 66; Iter   115/  229] train: loss: 0.1080192
[Epoch 66; Iter   145/  229] train: loss: 0.1146108
[Epoch 66; Iter   175/  229] train: loss: 0.1483571
[Epoch 66; Iter   205/  229] train: loss: 0.1124983
[Epoch 66] ogbg-moltoxcast: 0.677657 val loss: 0.267604
[Epoch 66] ogbg-moltoxcast: 0.654900 test loss: 0.322123
[Epoch 67; Iter     6/  229] train: loss: 0.1360413
[Epoch 67; Iter    36/  229] train: loss: 0.1603491
[Epoch 67; Iter    66/  229] train: loss: 0.1036206
[Epoch 67; Iter    96/  229] train: loss: 0.1741377
[Epoch 67; Iter   126/  229] train: loss: 0.1032191
[Epoch 67; Iter   156/  229] train: loss: 0.1129147
[Epoch 67; Iter   186/  229] train: loss: 0.1165991
[Epoch 67; Iter   216/  229] train: loss: 0.1048849
[Epoch 67] ogbg-moltoxcast: 0.680913 val loss: 0.265692
[Epoch 67] ogbg-moltoxcast: 0.657364 test loss: 0.317749
[Epoch 68; Iter    17/  229] train: loss: 0.1726883
[Epoch 68; Iter    47/  229] train: loss: 0.1119024
[Epoch 68; Iter    77/  229] train: loss: 0.1238806
[Epoch 68; Iter   107/  229] train: loss: 0.1617974
[Epoch 68; Iter   137/  229] train: loss: 0.1230146
[Epoch 68; Iter   167/  229] train: loss: 0.1153042
[Epoch 68; Iter   197/  229] train: loss: 0.1590849
[Epoch 68; Iter   227/  229] train: loss: 0.1473707
[Epoch 68] ogbg-moltoxcast: 0.676686 val loss: 0.265314
[Epoch 68] ogbg-moltoxcast: 0.650139 test loss: 0.322172
[Epoch 69; Iter    28/  229] train: loss: 0.1378272
[Epoch 69; Iter    58/  229] train: loss: 0.0974192
[Epoch 69; Iter    88/  229] train: loss: 0.1158581
[Epoch 69; Iter   118/  229] train: loss: 0.1109054
[Epoch 69; Iter   148/  229] train: loss: 0.0973588
[Epoch 69; Iter   178/  229] train: loss: 0.1876103
[Epoch 69; Iter   208/  229] train: loss: 0.1233593
[Epoch 69] ogbg-moltoxcast: 0.683183 val loss: 0.264373
[Epoch 69] ogbg-moltoxcast: 0.653301 test loss: 0.319730
[Epoch 70; Iter     9/  229] train: loss: 0.1180462
[Epoch 70; Iter    39/  229] train: loss: 0.1396370
[Epoch 70; Iter    69/  229] train: loss: 0.1292971
[Epoch 70; Iter    99/  229] train: loss: 0.1639905
[Epoch 70; Iter   129/  229] train: loss: 0.1205600
[Epoch 70; Iter   159/  229] train: loss: 0.1466064
[Epoch 70; Iter   189/  229] train: loss: 0.1774166
[Epoch 70; Iter   219/  229] train: loss: 0.1436445
[Epoch 70] ogbg-moltoxcast: 0.684787 val loss: 0.262492
[Epoch 70] ogbg-moltoxcast: 0.659257 test loss: 0.313200
[Epoch 71; Iter    20/  229] train: loss: 0.1090135
[Epoch 71; Iter    50/  229] train: loss: 0.1027311
[Epoch 71; Iter    80/  229] train: loss: 0.1332763
[Epoch 71; Iter   110/  229] train: loss: 0.1157025
[Epoch 71; Iter   140/  229] train: loss: 0.1001629
[Epoch 71; Iter   170/  229] train: loss: 0.1342543
[Epoch 71; Iter   200/  229] train: loss: 0.1211980
[Epoch 71] ogbg-moltoxcast: 0.680942 val loss: 0.265803
[Epoch 71] ogbg-moltoxcast: 0.655805 test loss: 0.319834
[Epoch 72; Iter     1/  229] train: loss: 0.0917563
[Epoch 72; Iter    31/  229] train: loss: 0.1001609
[Epoch 72; Iter    61/  229] train: loss: 0.1176942
[Epoch 72; Iter    91/  229] train: loss: 0.1304271
[Epoch 72; Iter   121/  229] train: loss: 0.1210254
[Epoch 72; Iter   151/  229] train: loss: 0.1403514
[Epoch 72; Iter   181/  229] train: loss: 0.1079917
[Epoch 72; Iter   211/  229] train: loss: 0.1340210
[Epoch 72] ogbg-moltoxcast: 0.687377 val loss: 0.268768
[Epoch 72] ogbg-moltoxcast: 0.655611 test loss: 0.324287
[Epoch 73; Iter    12/  229] train: loss: 0.1612344
[Epoch 73; Iter    42/  229] train: loss: 0.1152197
[Epoch 73; Iter    72/  229] train: loss: 0.0924409
[Epoch 73; Iter   102/  229] train: loss: 0.1313921
[Epoch 73; Iter   132/  229] train: loss: 0.1767948
[Epoch 73; Iter   162/  229] train: loss: 0.1339218
[Epoch 73; Iter   192/  229] train: loss: 0.1208854
[Epoch 73; Iter   222/  229] train: loss: 0.1408392
[Epoch 73] ogbg-moltoxcast: 0.679797 val loss: 0.266860
[Epoch 73] ogbg-moltoxcast: 0.655613 test loss: 0.318528
[Epoch 74; Iter    23/  229] train: loss: 0.0897734
[Epoch 74; Iter    53/  229] train: loss: 0.1869816
[Epoch 74; Iter    83/  229] train: loss: 0.0920560
[Epoch 74; Iter   113/  229] train: loss: 0.1502191
[Epoch 74; Iter   143/  229] train: loss: 0.1747283
[Epoch 74; Iter   173/  229] train: loss: 0.0872198
[Epoch 74; Iter   203/  229] train: loss: 0.1084594
[Epoch 74] ogbg-moltoxcast: 0.679357 val loss: 0.269375
[Epoch 74] ogbg-moltoxcast: 0.655834 test loss: 0.323506
[Epoch 75; Iter     4/  229] train: loss: 0.0929282
[Epoch 75; Iter    34/  229] train: loss: 0.1408789
[Epoch 75; Iter    64/  229] train: loss: 0.0998494
[Epoch 75; Iter    94/  229] train: loss: 0.1438004
[Epoch 75; Iter   124/  229] train: loss: 0.1480836
[Epoch 75; Iter   154/  229] train: loss: 0.1047398
[Epoch 75; Iter   184/  229] train: loss: 0.1340009
[Epoch 75; Iter   214/  229] train: loss: 0.1082161
[Epoch 75] ogbg-moltoxcast: 0.683029 val loss: 0.267563
[Epoch 75] ogbg-moltoxcast: 0.655354 test loss: 0.323486
[Epoch 76; Iter    15/  229] train: loss: 0.1045004
[Epoch 76; Iter    45/  229] train: loss: 0.1138204
[Epoch 76; Iter    75/  229] train: loss: 0.1401440
[Epoch 76; Iter   105/  229] train: loss: 0.0860192
[Epoch 76; Iter   135/  229] train: loss: 0.1799174
[Epoch 76; Iter   165/  229] train: loss: 0.1023909
[Epoch 76; Iter   195/  229] train: loss: 0.1085958
[Epoch 76; Iter   225/  229] train: loss: 0.0956113
[Epoch 76] ogbg-moltoxcast: 0.678802 val loss: 0.309873
[Epoch 76] ogbg-moltoxcast: 0.647245 test loss: 0.355420
[Epoch 77; Iter    26/  229] train: loss: 0.1411819
[Epoch 77; Iter    56/  229] train: loss: 0.1009881
[Epoch 77; Iter    86/  229] train: loss: 0.1883732
[Epoch 77; Iter   116/  229] train: loss: 0.1558105
[Epoch 77; Iter   146/  229] train: loss: 0.1224299
[Epoch 77; Iter   176/  229] train: loss: 0.1423899
[Epoch 77; Iter   206/  229] train: loss: 0.1393935
[Epoch 77] ogbg-moltoxcast: 0.672907 val loss: 0.311208
[Epoch 77] ogbg-moltoxcast: 0.644892 test loss: 0.354905
[Epoch 78; Iter     7/  229] train: loss: 0.1262109
[Epoch 78; Iter    37/  229] train: loss: 0.1247856
[Epoch 78; Iter    67/  229] train: loss: 0.1162370
[Epoch 78; Iter    97/  229] train: loss: 0.0859443
[Epoch 78; Iter   127/  229] train: loss: 0.1126663
[Epoch 78; Iter   157/  229] train: loss: 0.1115058
[Epoch 78; Iter   187/  229] train: loss: 0.1318414
[Epoch 78; Iter   217/  229] train: loss: 0.1412181
[Epoch 78] ogbg-moltoxcast: 0.681528 val loss: 0.310964
[Epoch 78] ogbg-moltoxcast: 0.648092 test loss: 0.353299
[Epoch 79; Iter    18/  229] train: loss: 0.0979386
[Epoch 79; Iter    48/  229] train: loss: 0.1341368
[Epoch 79; Iter    78/  229] train: loss: 0.1409670
[Epoch 79; Iter   108/  229] train: loss: 0.1422022
[Epoch 79; Iter   138/  229] train: loss: 0.1717307
[Epoch 79; Iter   168/  229] train: loss: 0.1562177
[Epoch 79; Iter   198/  229] train: loss: 0.1323448
[Epoch 79; Iter   228/  229] train: loss: 0.1381538
[Epoch 79] ogbg-moltoxcast: 0.679261 val loss: 0.307958
[Epoch 79] ogbg-moltoxcast: 0.649026 test loss: 0.348420
[Epoch 80; Iter    29/  229] train: loss: 0.1371307
[Epoch 80; Iter    59/  229] train: loss: 0.1162732
[Epoch 80; Iter    89/  229] train: loss: 0.1416131
[Epoch 80; Iter   119/  229] train: loss: 0.1183702
[Epoch 80; Iter   149/  229] train: loss: 0.1291592
[Epoch 80; Iter   179/  229] train: loss: 0.1332422
[Epoch 80; Iter   209/  229] train: loss: 0.1342928
[Epoch 80] ogbg-moltoxcast: 0.677331 val loss: 0.312444
[Epoch 80] ogbg-moltoxcast: 0.648408 test loss: 0.362517
[Epoch 81; Iter    10/  229] train: loss: 0.1055032
[Epoch 81; Iter    40/  229] train: loss: 0.1391735
[Epoch 81; Iter    70/  229] train: loss: 0.1368527
[Epoch 81; Iter   100/  229] train: loss: 0.0738748
[Epoch 81; Iter   130/  229] train: loss: 0.0881556
[Epoch 81; Iter   160/  229] train: loss: 0.1396954
[Epoch 81; Iter   190/  229] train: loss: 0.1222919
[Epoch 81; Iter   220/  229] train: loss: 0.1213812
[Epoch 81] ogbg-moltoxcast: 0.672708 val loss: 0.313488
[Epoch 81] ogbg-moltoxcast: 0.644124 test loss: 0.355104
[Epoch 82; Iter    21/  229] train: loss: 0.1335604
[Epoch 82; Iter    51/  229] train: loss: 0.1333849
[Epoch 82; Iter    81/  229] train: loss: 0.0945777
[Epoch 82; Iter   111/  229] train: loss: 0.0963471
[Epoch 82; Iter   141/  229] train: loss: 0.1335320
[Epoch 82; Iter   171/  229] train: loss: 0.0968323
[Epoch 82; Iter   201/  229] train: loss: 0.1326274
[Epoch 82] ogbg-moltoxcast: 0.675102 val loss: 0.314436
[Epoch 82] ogbg-moltoxcast: 0.645017 test loss: 0.359233
[Epoch 83; Iter     2/  229] train: loss: 0.1056947
[Epoch 83; Iter    32/  229] train: loss: 0.1071413
[Epoch 83; Iter    62/  229] train: loss: 0.0988755
[Epoch 83; Iter    92/  229] train: loss: 0.1490820
[Epoch 83; Iter   122/  229] train: loss: 0.1087910
[Epoch 83; Iter   152/  229] train: loss: 0.1480097
[Epoch 83; Iter   182/  229] train: loss: 0.1590302
[Epoch 83; Iter   212/  229] train: loss: 0.1083637
[Epoch 83] ogbg-moltoxcast: 0.669851 val loss: 0.308249
[Epoch 83] ogbg-moltoxcast: 0.643119 test loss: 0.353429
[Epoch 84; Iter    13/  229] train: loss: 0.1418433
[Epoch 84; Iter    43/  229] train: loss: 0.1193198
[Epoch 84; Iter    73/  229] train: loss: 0.1512748
[Epoch 84; Iter   103/  229] train: loss: 0.1051166
[Epoch 84; Iter   133/  229] train: loss: 0.1321961
[Epoch 84; Iter   163/  229] train: loss: 0.0865204
[Epoch 84; Iter   193/  229] train: loss: 0.1367798
[Epoch 84; Iter   223/  229] train: loss: 0.0956547
[Epoch 84] ogbg-moltoxcast: 0.677646 val loss: 0.315461
[Epoch 84] ogbg-moltoxcast: 0.643063 test loss: 0.365532
[Epoch 85; Iter    24/  229] train: loss: 0.1198548
[Epoch 85; Iter    54/  229] train: loss: 0.1027565
[Epoch 85; Iter    84/  229] train: loss: 0.1050505
[Epoch 85; Iter   114/  229] train: loss: 0.0977669
[Epoch 85; Iter   144/  229] train: loss: 0.1274191
[Epoch 85; Iter   174/  229] train: loss: 0.1399056
[Epoch 85; Iter   204/  229] train: loss: 0.1428527
[Epoch 85] ogbg-moltoxcast: 0.675607 val loss: 0.310188
[Epoch 85] ogbg-moltoxcast: 0.636966 test loss: 0.362368
[Epoch 86; Iter     5/  229] train: loss: 0.1639003
[Epoch 86; Iter    35/  229] train: loss: 0.1421414
[Epoch 86; Iter    65/  229] train: loss: 0.1137029
[Epoch 86; Iter    95/  229] train: loss: 0.1476359
[Epoch 86; Iter   125/  229] train: loss: 0.1267951
[Epoch 86; Iter   155/  229] train: loss: 0.1103240
[Epoch 86; Iter   185/  229] train: loss: 0.1318191
[Epoch 86; Iter   215/  229] train: loss: 0.1302896
[Epoch 86] ogbg-moltoxcast: 0.677780 val loss: 0.322677
[Epoch 86] ogbg-moltoxcast: 0.650008 test loss: 0.372763
[Epoch 87; Iter    16/  229] train: loss: 0.1045262
[Epoch 87; Iter    46/  229] train: loss: 0.1103191
[Epoch 87; Iter    76/  229] train: loss: 0.1047712
[Epoch 87; Iter   106/  229] train: loss: 0.1162756
[Epoch 87; Iter   136/  229] train: loss: 0.1233583
[Epoch 87; Iter   166/  229] train: loss: 0.1213373
[Epoch 87; Iter   196/  229] train: loss: 0.1241988
[Epoch 87; Iter   226/  229] train: loss: 0.1191874
[Epoch 87] ogbg-moltoxcast: 0.673076 val loss: 0.310414
[Epoch 87] ogbg-moltoxcast: 0.643138 test loss: 0.363455
[Epoch 88; Iter    27/  229] train: loss: 0.1731362
[Epoch 88; Iter    57/  229] train: loss: 0.1098977
[Epoch 88; Iter    87/  229] train: loss: 0.1035571
[Epoch 88; Iter   117/  229] train: loss: 0.1133761
[Epoch 88; Iter   147/  229] train: loss: 0.1006888
[Epoch 88; Iter   177/  229] train: loss: 0.1185113
[Epoch 88; Iter   207/  229] train: loss: 0.1157092
[Epoch 88] ogbg-moltoxcast: 0.671252 val loss: 0.306278
[Epoch 88] ogbg-moltoxcast: 0.640231 test loss: 0.354871
[Epoch 89; Iter     8/  229] train: loss: 0.1037268
[Epoch 89; Iter    38/  229] train: loss: 0.1039514
[Epoch 89; Iter    68/  229] train: loss: 0.1232139
[Epoch 89; Iter    98/  229] train: loss: 0.1002767
[Epoch 89; Iter   128/  229] train: loss: 0.1197404
[Epoch 89; Iter   158/  229] train: loss: 0.1198780
[Epoch 89; Iter   188/  229] train: loss: 0.1064282
[Epoch 89; Iter   218/  229] train: loss: 0.0864169
[Epoch 89] ogbg-moltoxcast: 0.670792 val loss: 0.317080
[Epoch 89] ogbg-moltoxcast: 0.641786 test loss: 0.365542
[Epoch 90; Iter    19/  229] train: loss: 0.1087797
[Epoch 90; Iter    49/  229] train: loss: 0.1483666
[Epoch 90; Iter    79/  229] train: loss: 0.1460901
[Epoch 90; Iter   109/  229] train: loss: 0.1562008
[Epoch 90; Iter   139/  229] train: loss: 0.1393212
[Epoch 90; Iter   169/  229] train: loss: 0.1174317
[Epoch 90; Iter   199/  229] train: loss: 0.0906915
[Epoch 90; Iter   229/  229] train: loss: 0.1146229
[Epoch 90] ogbg-moltoxcast: 0.672886 val loss: 0.308073
[Epoch 90] ogbg-moltoxcast: 0.641260 test loss: 0.359741
[Epoch 91; Iter    30/  229] train: loss: 0.1295431
[Epoch 91; Iter    60/  229] train: loss: 0.1005299
[Epoch 91; Iter    90/  229] train: loss: 0.1101760
[Epoch 91; Iter   120/  229] train: loss: 0.0955783
[Epoch 91; Iter   150/  229] train: loss: 0.1217238
[Epoch 91; Iter   180/  229] train: loss: 0.1257001
[Epoch 91; Iter   210/  229] train: loss: 0.1371218
[Epoch 91] ogbg-moltoxcast: 0.668192 val loss: 0.311203
[Epoch 91] ogbg-moltoxcast: 0.645502 test loss: 0.359214
[Epoch 76; Iter    15/  229] train: loss: 0.1496266
[Epoch 76; Iter    45/  229] train: loss: 0.1165746
[Epoch 76; Iter    75/  229] train: loss: 0.1963353
[Epoch 76; Iter   105/  229] train: loss: 0.1134502
[Epoch 76; Iter   135/  229] train: loss: 0.0858138
[Epoch 76; Iter   165/  229] train: loss: 0.1446913
[Epoch 76; Iter   195/  229] train: loss: 0.0777609
[Epoch 76; Iter   225/  229] train: loss: 0.1132214
[Epoch 76] ogbg-moltoxcast: 0.652227 val loss: 0.304900
[Epoch 76] ogbg-moltoxcast: 0.640858 test loss: 0.353697
[Epoch 77; Iter    26/  229] train: loss: 0.1247227
[Epoch 77; Iter    56/  229] train: loss: 0.1092438
[Epoch 77; Iter    86/  229] train: loss: 0.0903568
[Epoch 77; Iter   116/  229] train: loss: 0.1348398
[Epoch 77; Iter   146/  229] train: loss: 0.1125907
[Epoch 77; Iter   176/  229] train: loss: 0.1250996
[Epoch 77; Iter   206/  229] train: loss: 0.1443107
[Epoch 77] ogbg-moltoxcast: 0.651848 val loss: 0.303096
[Epoch 77] ogbg-moltoxcast: 0.643519 test loss: 0.355870
[Epoch 78; Iter     7/  229] train: loss: 0.1397351
[Epoch 78; Iter    37/  229] train: loss: 0.1280438
[Epoch 78; Iter    67/  229] train: loss: 0.0867310
[Epoch 78; Iter    97/  229] train: loss: 0.1363568
[Epoch 78; Iter   127/  229] train: loss: 0.1196909
[Epoch 78; Iter   157/  229] train: loss: 0.1053709
[Epoch 78; Iter   187/  229] train: loss: 0.1020911
[Epoch 78; Iter   217/  229] train: loss: 0.1155499
[Epoch 78] ogbg-moltoxcast: 0.657230 val loss: 0.312068
[Epoch 78] ogbg-moltoxcast: 0.645110 test loss: 0.370415
[Epoch 79; Iter    18/  229] train: loss: 0.0853734
[Epoch 79; Iter    48/  229] train: loss: 0.1108759
[Epoch 79; Iter    78/  229] train: loss: 0.0898220
[Epoch 79; Iter   108/  229] train: loss: 0.1249575
[Epoch 79; Iter   138/  229] train: loss: 0.1050915
[Epoch 79; Iter   168/  229] train: loss: 0.0778823
[Epoch 79; Iter   198/  229] train: loss: 0.0730493
[Epoch 79; Iter   228/  229] train: loss: 0.1508926
[Epoch 79] ogbg-moltoxcast: 0.653669 val loss: 0.306993
[Epoch 79] ogbg-moltoxcast: 0.641330 test loss: 0.363797
[Epoch 80; Iter    29/  229] train: loss: 0.1348194
[Epoch 80; Iter    59/  229] train: loss: 0.1036274
[Epoch 80; Iter    89/  229] train: loss: 0.0938318
[Epoch 80; Iter   119/  229] train: loss: 0.1413333
[Epoch 80; Iter   149/  229] train: loss: 0.1336184
[Epoch 80; Iter   179/  229] train: loss: 0.2264935
[Epoch 80; Iter   209/  229] train: loss: 0.1126760
[Epoch 80] ogbg-moltoxcast: 0.656414 val loss: 0.317401
[Epoch 80] ogbg-moltoxcast: 0.644954 test loss: 0.370164
[Epoch 81; Iter    10/  229] train: loss: 0.0796283
[Epoch 81; Iter    40/  229] train: loss: 0.1120650
[Epoch 81; Iter    70/  229] train: loss: 0.1520324
[Epoch 81; Iter   100/  229] train: loss: 0.1165276
[Epoch 81; Iter   130/  229] train: loss: 0.1024563
[Epoch 81; Iter   160/  229] train: loss: 0.1266278
[Epoch 81; Iter   190/  229] train: loss: 0.1585739
[Epoch 81; Iter   220/  229] train: loss: 0.0865441
[Epoch 81] ogbg-moltoxcast: 0.656393 val loss: 0.303808
[Epoch 81] ogbg-moltoxcast: 0.640430 test loss: 0.358589
[Epoch 82; Iter    21/  229] train: loss: 0.0643419
[Epoch 82; Iter    51/  229] train: loss: 0.1091520
[Epoch 82; Iter    81/  229] train: loss: 0.1049052
[Epoch 82; Iter   111/  229] train: loss: 0.0967800
[Epoch 82; Iter   141/  229] train: loss: 0.1453092
[Epoch 82; Iter   171/  229] train: loss: 0.0959513
[Epoch 82; Iter   201/  229] train: loss: 0.0803502
[Epoch 82] ogbg-moltoxcast: 0.651847 val loss: 0.311212
[Epoch 82] ogbg-moltoxcast: 0.643738 test loss: 0.361485
[Epoch 83; Iter     2/  229] train: loss: 0.0890851
[Epoch 83; Iter    32/  229] train: loss: 0.1572983
[Epoch 83; Iter    62/  229] train: loss: 0.1374819
[Epoch 83; Iter    92/  229] train: loss: 0.0974129
[Epoch 83; Iter   122/  229] train: loss: 0.1005720
[Epoch 83; Iter   152/  229] train: loss: 0.0935913
[Epoch 83; Iter   182/  229] train: loss: 0.1320736
[Epoch 83; Iter   212/  229] train: loss: 0.0759506
[Epoch 83] ogbg-moltoxcast: 0.651136 val loss: 0.314450
[Epoch 83] ogbg-moltoxcast: 0.645311 test loss: 0.367487
[Epoch 84; Iter    13/  229] train: loss: 0.1755618
[Epoch 84; Iter    43/  229] train: loss: 0.1291222
[Epoch 84; Iter    73/  229] train: loss: 0.1569900
[Epoch 84; Iter   103/  229] train: loss: 0.1015656
[Epoch 84; Iter   133/  229] train: loss: 0.0954460
[Epoch 84; Iter   163/  229] train: loss: 0.0867037
[Epoch 84; Iter   193/  229] train: loss: 0.1277733
[Epoch 84; Iter   223/  229] train: loss: 0.1086817
[Epoch 84] ogbg-moltoxcast: 0.648288 val loss: 0.305737
[Epoch 84] ogbg-moltoxcast: 0.638935 test loss: 0.362110
[Epoch 85; Iter    24/  229] train: loss: 0.0711485
[Epoch 85; Iter    54/  229] train: loss: 0.1237477
[Epoch 85; Iter    84/  229] train: loss: 0.1233089
[Epoch 85; Iter   114/  229] train: loss: 0.0827173
[Epoch 85; Iter   144/  229] train: loss: 0.1007844
[Epoch 85; Iter   174/  229] train: loss: 0.1302973
[Epoch 85; Iter   204/  229] train: loss: 0.1201587
[Epoch 85] ogbg-moltoxcast: 0.653861 val loss: 0.312463
[Epoch 85] ogbg-moltoxcast: 0.645594 test loss: 0.366457
[Epoch 86; Iter     5/  229] train: loss: 0.0865721
[Epoch 86; Iter    35/  229] train: loss: 0.1511947
[Epoch 86; Iter    65/  229] train: loss: 0.1416613
[Epoch 86; Iter    95/  229] train: loss: 0.1407605
[Epoch 86; Iter   125/  229] train: loss: 0.1006039
[Epoch 86; Iter   155/  229] train: loss: 0.1351290
[Epoch 86; Iter   185/  229] train: loss: 0.1521154
[Epoch 86; Iter   215/  229] train: loss: 0.1339763
[Epoch 86] ogbg-moltoxcast: 0.647748 val loss: 0.303944
[Epoch 86] ogbg-moltoxcast: 0.640325 test loss: 0.355502
[Epoch 87; Iter    16/  229] train: loss: 0.1233158
[Epoch 87; Iter    46/  229] train: loss: 0.1387484
[Epoch 87; Iter    76/  229] train: loss: 0.0743855
[Epoch 87; Iter   106/  229] train: loss: 0.0948669
[Epoch 87; Iter   136/  229] train: loss: 0.0949541
[Epoch 87; Iter   166/  229] train: loss: 0.1090039
[Epoch 87; Iter   196/  229] train: loss: 0.1601706
[Epoch 87; Iter   226/  229] train: loss: 0.1272748
[Epoch 87] ogbg-moltoxcast: 0.652537 val loss: 0.308611
[Epoch 87] ogbg-moltoxcast: 0.641072 test loss: 0.362835
[Epoch 88; Iter    27/  229] train: loss: 0.0982441
[Epoch 88; Iter    57/  229] train: loss: 0.0737256
[Epoch 88; Iter    87/  229] train: loss: 0.0905121
[Epoch 88; Iter   117/  229] train: loss: 0.1003208
[Epoch 88; Iter   147/  229] train: loss: 0.1203280
[Epoch 88; Iter   177/  229] train: loss: 0.0911892
[Epoch 88; Iter   207/  229] train: loss: 0.0939003
[Epoch 88] ogbg-moltoxcast: 0.651712 val loss: 0.305747
[Epoch 88] ogbg-moltoxcast: 0.642150 test loss: 0.357830
[Epoch 89; Iter     8/  229] train: loss: 0.1093711
[Epoch 89; Iter    38/  229] train: loss: 0.1295586
[Epoch 89; Iter    68/  229] train: loss: 0.1027316
[Epoch 89; Iter    98/  229] train: loss: 0.1298377
[Epoch 89; Iter   128/  229] train: loss: 0.1548819
[Epoch 89; Iter   158/  229] train: loss: 0.1115133
[Epoch 89; Iter   188/  229] train: loss: 0.0717058
[Epoch 89; Iter   218/  229] train: loss: 0.1134681
[Epoch 89] ogbg-moltoxcast: 0.645177 val loss: 0.315138
[Epoch 89] ogbg-moltoxcast: 0.643544 test loss: 0.365086
[Epoch 90; Iter    19/  229] train: loss: 0.0894482
[Epoch 90; Iter    49/  229] train: loss: 0.1035658
[Epoch 90; Iter    79/  229] train: loss: 0.0805598
[Epoch 90; Iter   109/  229] train: loss: 0.1061044
[Epoch 90; Iter   139/  229] train: loss: 0.1605474
[Epoch 90; Iter   169/  229] train: loss: 0.1372796
[Epoch 90; Iter   199/  229] train: loss: 0.1268145
[Epoch 90; Iter   229/  229] train: loss: 0.1555691
[Epoch 90] ogbg-moltoxcast: 0.644174 val loss: 0.312024
[Epoch 90] ogbg-moltoxcast: 0.640812 test loss: 0.364309
[Epoch 91; Iter    30/  229] train: loss: 0.0871019
[Epoch 91; Iter    60/  229] train: loss: 0.1024870
[Epoch 91; Iter    90/  229] train: loss: 0.1123317
[Epoch 91; Iter   120/  229] train: loss: 0.1201821
[Epoch 91; Iter   150/  229] train: loss: 0.0816832
[Epoch 91; Iter   180/  229] train: loss: 0.1385568
[Epoch 91; Iter   210/  229] train: loss: 0.1266098
[Epoch 91] ogbg-moltoxcast: 0.646444 val loss: 0.313227
[Epoch 91] ogbg-moltoxcast: 0.640828 test loss: 0.365035
[Epoch 76; Iter    15/  229] train: loss: 0.1115541
[Epoch 76; Iter    45/  229] train: loss: 0.1224144
[Epoch 76; Iter    75/  229] train: loss: 0.1354781
[Epoch 76; Iter   105/  229] train: loss: 0.1316409
[Epoch 76; Iter   135/  229] train: loss: 0.1010528
[Epoch 76; Iter   165/  229] train: loss: 0.1266296
[Epoch 76; Iter   195/  229] train: loss: 0.1137860
[Epoch 76; Iter   225/  229] train: loss: 0.1354051
[Epoch 76] ogbg-moltoxcast: 0.676549 val loss: 0.304453
[Epoch 76] ogbg-moltoxcast: 0.642280 test loss: 0.358830
[Epoch 77; Iter    26/  229] train: loss: 0.1139440
[Epoch 77; Iter    56/  229] train: loss: 0.0977163
[Epoch 77; Iter    86/  229] train: loss: 0.1606525
[Epoch 77; Iter   116/  229] train: loss: 0.1244829
[Epoch 77; Iter   146/  229] train: loss: 0.0995463
[Epoch 77; Iter   176/  229] train: loss: 0.1293578
[Epoch 77; Iter   206/  229] train: loss: 0.1453036
[Epoch 77] ogbg-moltoxcast: 0.682648 val loss: 0.316331
[Epoch 77] ogbg-moltoxcast: 0.645846 test loss: 0.365559
[Epoch 78; Iter     7/  229] train: loss: 0.1187434
[Epoch 78; Iter    37/  229] train: loss: 0.1050180
[Epoch 78; Iter    67/  229] train: loss: 0.0953784
[Epoch 78; Iter    97/  229] train: loss: 0.1135051
[Epoch 78; Iter   127/  229] train: loss: 0.1671598
[Epoch 78; Iter   157/  229] train: loss: 0.0943372
[Epoch 78; Iter   187/  229] train: loss: 0.1337501
[Epoch 78; Iter   217/  229] train: loss: 0.1078829
[Epoch 78] ogbg-moltoxcast: 0.680964 val loss: 0.296665
[Epoch 78] ogbg-moltoxcast: 0.640103 test loss: 0.358542
[Epoch 79; Iter    18/  229] train: loss: 0.1626468
[Epoch 79; Iter    48/  229] train: loss: 0.1427925
[Epoch 79; Iter    78/  229] train: loss: 0.1455120
[Epoch 79; Iter   108/  229] train: loss: 0.1313771
[Epoch 79; Iter   138/  229] train: loss: 0.1360376
[Epoch 79; Iter   168/  229] train: loss: 0.1352099
[Epoch 79; Iter   198/  229] train: loss: 0.0862095
[Epoch 79; Iter   228/  229] train: loss: 0.1387628
[Epoch 79] ogbg-moltoxcast: 0.678080 val loss: 0.312574
[Epoch 79] ogbg-moltoxcast: 0.638282 test loss: 0.365055
[Epoch 80; Iter    29/  229] train: loss: 0.1087956
[Epoch 80; Iter    59/  229] train: loss: 0.1097035
[Epoch 80; Iter    89/  229] train: loss: 0.1233953
[Epoch 80; Iter   119/  229] train: loss: 0.1113260
[Epoch 80; Iter   149/  229] train: loss: 0.1151875
[Epoch 80; Iter   179/  229] train: loss: 0.1152434
[Epoch 80; Iter   209/  229] train: loss: 0.1243345
[Epoch 80] ogbg-moltoxcast: 0.673822 val loss: 0.301005
[Epoch 80] ogbg-moltoxcast: 0.636148 test loss: 0.360589
[Epoch 81; Iter    10/  229] train: loss: 0.1100461
[Epoch 81; Iter    40/  229] train: loss: 0.1316256
[Epoch 81; Iter    70/  229] train: loss: 0.1179911
[Epoch 81; Iter   100/  229] train: loss: 0.1325539
[Epoch 81; Iter   130/  229] train: loss: 0.1422248
[Epoch 81; Iter   160/  229] train: loss: 0.1345674
[Epoch 81; Iter   190/  229] train: loss: 0.1243878
[Epoch 81; Iter   220/  229] train: loss: 0.0988201
[Epoch 81] ogbg-moltoxcast: 0.678038 val loss: 0.304832
[Epoch 81] ogbg-moltoxcast: 0.640135 test loss: 0.362099
[Epoch 82; Iter    21/  229] train: loss: 0.0908066
[Epoch 82; Iter    51/  229] train: loss: 0.1140794
[Epoch 82; Iter    81/  229] train: loss: 0.1202067
[Epoch 82; Iter   111/  229] train: loss: 0.1023151
[Epoch 82; Iter   141/  229] train: loss: 0.0989793
[Epoch 82; Iter   171/  229] train: loss: 0.1152039
[Epoch 82; Iter   201/  229] train: loss: 0.1225694
[Epoch 82] ogbg-moltoxcast: 0.675034 val loss: 0.313984
[Epoch 82] ogbg-moltoxcast: 0.637674 test loss: 0.371006
[Epoch 83; Iter     2/  229] train: loss: 0.1755018
[Epoch 83; Iter    32/  229] train: loss: 0.1020669
[Epoch 83; Iter    62/  229] train: loss: 0.1103884
[Epoch 83; Iter    92/  229] train: loss: 0.1288914
[Epoch 83; Iter   122/  229] train: loss: 0.1150730
[Epoch 83; Iter   152/  229] train: loss: 0.0881767
[Epoch 83; Iter   182/  229] train: loss: 0.0763560
[Epoch 83; Iter   212/  229] train: loss: 0.1503313
[Epoch 83] ogbg-moltoxcast: 0.671929 val loss: 0.315300
[Epoch 83] ogbg-moltoxcast: 0.639833 test loss: 0.360260
[Epoch 84; Iter    13/  229] train: loss: 0.1050922
[Epoch 84; Iter    43/  229] train: loss: 0.1105622
[Epoch 84; Iter    73/  229] train: loss: 0.0918203
[Epoch 84; Iter   103/  229] train: loss: 0.0985759
[Epoch 84; Iter   133/  229] train: loss: 0.0753196
[Epoch 84; Iter   163/  229] train: loss: 0.1079413
[Epoch 84; Iter   193/  229] train: loss: 0.1371027
[Epoch 84; Iter   223/  229] train: loss: 0.1022212
[Epoch 84] ogbg-moltoxcast: 0.669084 val loss: 0.309989
[Epoch 84] ogbg-moltoxcast: 0.639572 test loss: 0.363057
[Epoch 85; Iter    24/  229] train: loss: 0.1255652
[Epoch 85; Iter    54/  229] train: loss: 0.1171157
[Epoch 85; Iter    84/  229] train: loss: 0.1105512
[Epoch 85; Iter   114/  229] train: loss: 0.0899381
[Epoch 85; Iter   144/  229] train: loss: 0.1152447
[Epoch 85; Iter   174/  229] train: loss: 0.1737911
[Epoch 85; Iter   204/  229] train: loss: 0.1404999
[Epoch 85] ogbg-moltoxcast: 0.668871 val loss: 0.305317
[Epoch 85] ogbg-moltoxcast: 0.638560 test loss: 0.364284
[Epoch 86; Iter     5/  229] train: loss: 0.1063215
[Epoch 86; Iter    35/  229] train: loss: 0.1149354
[Epoch 86; Iter    65/  229] train: loss: 0.0761991
[Epoch 86; Iter    95/  229] train: loss: 0.1321075
[Epoch 86; Iter   125/  229] train: loss: 0.0718466
[Epoch 86; Iter   155/  229] train: loss: 0.1111407
[Epoch 86; Iter   185/  229] train: loss: 0.1162749
[Epoch 86; Iter   215/  229] train: loss: 0.1584663
[Epoch 86] ogbg-moltoxcast: 0.676544 val loss: 0.304723
[Epoch 86] ogbg-moltoxcast: 0.640067 test loss: 0.363139
[Epoch 87; Iter    16/  229] train: loss: 0.0759087
[Epoch 87; Iter    46/  229] train: loss: 0.0931701
[Epoch 87; Iter    76/  229] train: loss: 0.1403283
[Epoch 87; Iter   106/  229] train: loss: 0.1131287
[Epoch 87; Iter   136/  229] train: loss: 0.1760783
[Epoch 87; Iter   166/  229] train: loss: 0.1024864
[Epoch 87; Iter   196/  229] train: loss: 0.1159532
[Epoch 87; Iter   226/  229] train: loss: 0.0906750
[Epoch 87] ogbg-moltoxcast: 0.674331 val loss: 0.311148
[Epoch 87] ogbg-moltoxcast: 0.641357 test loss: 0.364791
[Epoch 88; Iter    27/  229] train: loss: 0.1111419
[Epoch 88; Iter    57/  229] train: loss: 0.1056857
[Epoch 88; Iter    87/  229] train: loss: 0.1090626
[Epoch 88; Iter   117/  229] train: loss: 0.1402411
[Epoch 88; Iter   147/  229] train: loss: 0.1207092
[Epoch 88; Iter   177/  229] train: loss: 0.1171962
[Epoch 88; Iter   207/  229] train: loss: 0.0914398
[Epoch 88] ogbg-moltoxcast: 0.673224 val loss: 0.314674
[Epoch 88] ogbg-moltoxcast: 0.641973 test loss: 0.361567
[Epoch 89; Iter     8/  229] train: loss: 0.1193576
[Epoch 89; Iter    38/  229] train: loss: 0.1383890
[Epoch 89; Iter    68/  229] train: loss: 0.1375268
[Epoch 89; Iter    98/  229] train: loss: 0.1064636
[Epoch 89; Iter   128/  229] train: loss: 0.1073876
[Epoch 89; Iter   158/  229] train: loss: 0.0989425
[Epoch 89; Iter   188/  229] train: loss: 0.0877259
[Epoch 89; Iter   218/  229] train: loss: 0.1250054
[Epoch 89] ogbg-moltoxcast: 0.672346 val loss: 0.312534
[Epoch 89] ogbg-moltoxcast: 0.639912 test loss: 0.368006
[Epoch 90; Iter    19/  229] train: loss: 0.1211942
[Epoch 90; Iter    49/  229] train: loss: 0.1061639
[Epoch 90; Iter    79/  229] train: loss: 0.1010422
[Epoch 90; Iter   109/  229] train: loss: 0.0817124
[Epoch 90; Iter   139/  229] train: loss: 0.0851992
[Epoch 90; Iter   169/  229] train: loss: 0.0874310
[Epoch 90; Iter   199/  229] train: loss: 0.1600002
[Epoch 90; Iter   229/  229] train: loss: 0.1169198
[Epoch 90] ogbg-moltoxcast: 0.672553 val loss: 0.313143
[Epoch 90] ogbg-moltoxcast: 0.637241 test loss: 0.368194
[Epoch 91; Iter    30/  229] train: loss: 0.1079405
[Epoch 91; Iter    60/  229] train: loss: 0.1258802
[Epoch 91; Iter    90/  229] train: loss: 0.1355488
[Epoch 91; Iter   120/  229] train: loss: 0.1015630
[Epoch 91; Iter   150/  229] train: loss: 0.1298818
[Epoch 91; Iter   180/  229] train: loss: 0.1590463
[Epoch 91; Iter   210/  229] train: loss: 0.1627836
[Epoch 91] ogbg-moltoxcast: 0.668347 val loss: 0.320847
[Epoch 91] ogbg-moltoxcast: 0.640406 test loss: 0.368661
[Epoch 76; Iter    15/  229] train: loss: 0.1490995
[Epoch 76; Iter    45/  229] train: loss: 0.1161961
[Epoch 76; Iter    75/  229] train: loss: 0.1926437
[Epoch 76; Iter   105/  229] train: loss: 0.1141839
[Epoch 76; Iter   135/  229] train: loss: 0.0906238
[Epoch 76; Iter   165/  229] train: loss: 0.1441063
[Epoch 76; Iter   195/  229] train: loss: 0.0805070
[Epoch 76; Iter   225/  229] train: loss: 0.1111924
[Epoch 76] ogbg-moltoxcast: 0.641162 val loss: 0.490787
[Epoch 76] ogbg-moltoxcast: 0.630121 test loss: 0.943277
[Epoch 77; Iter    26/  229] train: loss: 0.1278638
[Epoch 77; Iter    56/  229] train: loss: 0.1140944
[Epoch 77; Iter    86/  229] train: loss: 0.0966267
[Epoch 77; Iter   116/  229] train: loss: 0.1426731
[Epoch 77; Iter   146/  229] train: loss: 0.1102384
[Epoch 77; Iter   176/  229] train: loss: 0.1254912
[Epoch 77; Iter   206/  229] train: loss: 0.1370450
[Epoch 77] ogbg-moltoxcast: 0.643201 val loss: 0.566325
[Epoch 77] ogbg-moltoxcast: 0.628967 test loss: 0.718746
[Epoch 78; Iter     7/  229] train: loss: 0.1449713
[Epoch 78; Iter    37/  229] train: loss: 0.1297471
[Epoch 78; Iter    67/  229] train: loss: 0.0892997
[Epoch 78; Iter    97/  229] train: loss: 0.1442983
[Epoch 78; Iter   127/  229] train: loss: 0.1208320
[Epoch 78; Iter   157/  229] train: loss: 0.1069920
[Epoch 78; Iter   187/  229] train: loss: 0.1044848
[Epoch 78; Iter   217/  229] train: loss: 0.1149795
[Epoch 78] ogbg-moltoxcast: 0.639407 val loss: 0.422421
[Epoch 78] ogbg-moltoxcast: 0.627978 test loss: 0.641493
[Epoch 79; Iter    18/  229] train: loss: 0.0971256
[Epoch 79; Iter    48/  229] train: loss: 0.1202780
[Epoch 79; Iter    78/  229] train: loss: 0.1016848
[Epoch 79; Iter   108/  229] train: loss: 0.1237345
[Epoch 79; Iter   138/  229] train: loss: 0.1036815
[Epoch 79; Iter   168/  229] train: loss: 0.0799387
[Epoch 79; Iter   198/  229] train: loss: 0.0714351
[Epoch 79; Iter   228/  229] train: loss: 0.1465640
[Epoch 79] ogbg-moltoxcast: 0.641833 val loss: 0.348796
[Epoch 79] ogbg-moltoxcast: 0.629522 test loss: 0.784223
[Epoch 80; Iter    29/  229] train: loss: 0.1300185
[Epoch 80; Iter    59/  229] train: loss: 0.1084135
[Epoch 80; Iter    89/  229] train: loss: 0.0987436
[Epoch 80; Iter   119/  229] train: loss: 0.1431040
[Epoch 80; Iter   149/  229] train: loss: 0.1337726
[Epoch 80; Iter   179/  229] train: loss: 0.2310004
[Epoch 80; Iter   209/  229] train: loss: 0.1114695
[Epoch 80] ogbg-moltoxcast: 0.640575 val loss: 0.494957
[Epoch 80] ogbg-moltoxcast: 0.625964 test loss: 0.709504
[Epoch 81; Iter    10/  229] train: loss: 0.0808719
[Epoch 81; Iter    40/  229] train: loss: 0.1149386
[Epoch 81; Iter    70/  229] train: loss: 0.1558640
[Epoch 81; Iter   100/  229] train: loss: 0.1194341
[Epoch 81; Iter   130/  229] train: loss: 0.1055772
[Epoch 81; Iter   160/  229] train: loss: 0.1362980
[Epoch 81; Iter   190/  229] train: loss: 0.1563907
[Epoch 81; Iter   220/  229] train: loss: 0.0860396
[Epoch 81] ogbg-moltoxcast: 0.639232 val loss: 0.516754
[Epoch 81] ogbg-moltoxcast: 0.629643 test loss: 0.403773
[Epoch 82; Iter    21/  229] train: loss: 0.0712568
[Epoch 82; Iter    51/  229] train: loss: 0.1219263
[Epoch 82; Iter    81/  229] train: loss: 0.1120937
[Epoch 82; Iter   111/  229] train: loss: 0.0970523
[Epoch 82; Iter   141/  229] train: loss: 0.1493814
[Epoch 82; Iter   171/  229] train: loss: 0.0975316
[Epoch 82; Iter   201/  229] train: loss: 0.0888555
[Epoch 82] ogbg-moltoxcast: 0.636566 val loss: 0.453703
[Epoch 82] ogbg-moltoxcast: 0.628477 test loss: 0.766452
[Epoch 83; Iter     2/  229] train: loss: 0.0895239
[Epoch 83; Iter    32/  229] train: loss: 0.1535742
[Epoch 83; Iter    62/  229] train: loss: 0.1398364
[Epoch 83; Iter    92/  229] train: loss: 0.0937656
[Epoch 83; Iter   122/  229] train: loss: 0.1021602
[Epoch 83; Iter   152/  229] train: loss: 0.0931571
[Epoch 83; Iter   182/  229] train: loss: 0.1372509
[Epoch 83; Iter   212/  229] train: loss: 0.0849872
[Epoch 83] ogbg-moltoxcast: 0.636956 val loss: 0.367297
[Epoch 83] ogbg-moltoxcast: 0.627022 test loss: 0.957558
[Epoch 84; Iter    13/  229] train: loss: 0.1828878
[Epoch 84; Iter    43/  229] train: loss: 0.1330141
[Epoch 84; Iter    73/  229] train: loss: 0.1637061
[Epoch 84; Iter   103/  229] train: loss: 0.0928781
[Epoch 84; Iter   133/  229] train: loss: 0.0948621
[Epoch 84; Iter   163/  229] train: loss: 0.0920396
[Epoch 84; Iter   193/  229] train: loss: 0.1367105
[Epoch 84; Iter   223/  229] train: loss: 0.1096277
[Epoch 84] ogbg-moltoxcast: 0.634957 val loss: 0.441186
[Epoch 84] ogbg-moltoxcast: 0.624520 test loss: 1.403149
[Epoch 85; Iter    24/  229] train: loss: 0.0691705
[Epoch 85; Iter    54/  229] train: loss: 0.1201764
[Epoch 85; Iter    84/  229] train: loss: 0.1168156
[Epoch 85; Iter   114/  229] train: loss: 0.0867108
[Epoch 85; Iter   144/  229] train: loss: 0.1017907
[Epoch 85; Iter   174/  229] train: loss: 0.1331062
[Epoch 85; Iter   204/  229] train: loss: 0.1251559
[Epoch 85] ogbg-moltoxcast: 0.638218 val loss: 0.523857
[Epoch 85] ogbg-moltoxcast: 0.626066 test loss: 0.587397
[Epoch 86; Iter     5/  229] train: loss: 0.0882952
[Epoch 86; Iter    35/  229] train: loss: 0.1567956
[Epoch 86; Iter    65/  229] train: loss: 0.1523067
[Epoch 86; Iter    95/  229] train: loss: 0.1407717
[Epoch 86; Iter   125/  229] train: loss: 0.1043587
[Epoch 86; Iter   155/  229] train: loss: 0.1436148
[Epoch 86; Iter   185/  229] train: loss: 0.1556484
[Epoch 86; Iter   215/  229] train: loss: 0.1371409
[Epoch 86] ogbg-moltoxcast: 0.633004 val loss: 0.400771
[Epoch 86] ogbg-moltoxcast: 0.629328 test loss: 1.176421
[Epoch 87; Iter    16/  229] train: loss: 0.1228943
[Epoch 87; Iter    46/  229] train: loss: 0.1371349
[Epoch 87; Iter    76/  229] train: loss: 0.0740441
[Epoch 87; Iter   106/  229] train: loss: 0.0950908
[Epoch 87; Iter   136/  229] train: loss: 0.0962082
[Epoch 87; Iter   166/  229] train: loss: 0.1155879
[Epoch 87; Iter   196/  229] train: loss: 0.1600018
[Epoch 87; Iter   226/  229] train: loss: 0.1314601
[Epoch 87] ogbg-moltoxcast: 0.643863 val loss: 0.468580
[Epoch 87] ogbg-moltoxcast: 0.628124 test loss: 0.409324
[Epoch 88; Iter    27/  229] train: loss: 0.1002614
[Epoch 88; Iter    57/  229] train: loss: 0.0771377
[Epoch 88; Iter    87/  229] train: loss: 0.0864395
[Epoch 88; Iter   117/  229] train: loss: 0.1071092
[Epoch 88; Iter   147/  229] train: loss: 0.1226078
[Epoch 88; Iter   177/  229] train: loss: 0.0997232
[Epoch 88; Iter   207/  229] train: loss: 0.0954625
[Epoch 88] ogbg-moltoxcast: 0.644397 val loss: 0.458529
[Epoch 88] ogbg-moltoxcast: 0.628803 test loss: 1.260018
[Epoch 89; Iter     8/  229] train: loss: 0.1137993
[Epoch 89; Iter    38/  229] train: loss: 0.1420865
[Epoch 89; Iter    68/  229] train: loss: 0.1064853
[Epoch 89; Iter    98/  229] train: loss: 0.1312391
[Epoch 89; Iter   128/  229] train: loss: 0.1522997
[Epoch 89; Iter   158/  229] train: loss: 0.1107653
[Epoch 89; Iter   188/  229] train: loss: 0.0739377
[Epoch 89; Iter   218/  229] train: loss: 0.1227561
[Epoch 89] ogbg-moltoxcast: 0.637667 val loss: 0.350622
[Epoch 89] ogbg-moltoxcast: 0.626806 test loss: 0.403915
[Epoch 90; Iter    19/  229] train: loss: 0.0891568
[Epoch 90; Iter    49/  229] train: loss: 0.1029054
[Epoch 90; Iter    79/  229] train: loss: 0.0830496
[Epoch 90; Iter   109/  229] train: loss: 0.1086708
[Epoch 90; Iter   139/  229] train: loss: 0.1566300
[Epoch 90; Iter   169/  229] train: loss: 0.1390631
[Epoch 90; Iter   199/  229] train: loss: 0.1378865
[Epoch 90; Iter   229/  229] train: loss: 0.1569823
[Epoch 90] ogbg-moltoxcast: 0.634868 val loss: 0.357557
[Epoch 90] ogbg-moltoxcast: 0.625233 test loss: 0.855313
[Epoch 91; Iter    30/  229] train: loss: 0.0904149
[Epoch 91; Iter    60/  229] train: loss: 0.1070260
[Epoch 91; Iter    90/  229] train: loss: 0.1141303
[Epoch 91; Iter   120/  229] train: loss: 0.1208817
[Epoch 91; Iter   150/  229] train: loss: 0.0839547
[Epoch 91; Iter   180/  229] train: loss: 0.1430770
[Epoch 91; Iter   210/  229] train: loss: 0.1241242
[Epoch 91] ogbg-moltoxcast: 0.644120 val loss: 0.346180
[Epoch 91] ogbg-moltoxcast: 0.630465 test loss: 1.000822
[Epoch 76; Iter    15/  229] train: loss: 0.1143916
[Epoch 76; Iter    45/  229] train: loss: 0.1238911
[Epoch 76; Iter    75/  229] train: loss: 0.1340092
[Epoch 76; Iter   105/  229] train: loss: 0.1306155
[Epoch 76; Iter   135/  229] train: loss: 0.0978932
[Epoch 76; Iter   165/  229] train: loss: 0.1281113
[Epoch 76; Iter   195/  229] train: loss: 0.1109574
[Epoch 76; Iter   225/  229] train: loss: 0.1314231
[Epoch 76] ogbg-moltoxcast: 0.656596 val loss: 0.317745
[Epoch 76] ogbg-moltoxcast: 0.625287 test loss: 0.371881
[Epoch 77; Iter    26/  229] train: loss: 0.1028008
[Epoch 77; Iter    56/  229] train: loss: 0.1000071
[Epoch 77; Iter    86/  229] train: loss: 0.1579675
[Epoch 77; Iter   116/  229] train: loss: 0.1240840
[Epoch 77; Iter   146/  229] train: loss: 0.1005682
[Epoch 77; Iter   176/  229] train: loss: 0.1384251
[Epoch 77; Iter   206/  229] train: loss: 0.1333087
[Epoch 77] ogbg-moltoxcast: 0.652669 val loss: 0.323588
[Epoch 77] ogbg-moltoxcast: 0.630745 test loss: 0.375975
[Epoch 78; Iter     7/  229] train: loss: 0.1188914
[Epoch 78; Iter    37/  229] train: loss: 0.1035085
[Epoch 78; Iter    67/  229] train: loss: 0.0928806
[Epoch 78; Iter    97/  229] train: loss: 0.1162290
[Epoch 78; Iter   127/  229] train: loss: 0.1665952
[Epoch 78; Iter   157/  229] train: loss: 0.0923230
[Epoch 78; Iter   187/  229] train: loss: 0.1332881
[Epoch 78; Iter   217/  229] train: loss: 0.1088522
[Epoch 78] ogbg-moltoxcast: 0.649467 val loss: 0.324845
[Epoch 78] ogbg-moltoxcast: 0.622857 test loss: 0.380810
[Epoch 79; Iter    18/  229] train: loss: 0.1707565
[Epoch 79; Iter    48/  229] train: loss: 0.1365453
[Epoch 79; Iter    78/  229] train: loss: 0.1505507
[Epoch 79; Iter   108/  229] train: loss: 0.1259164
[Epoch 79; Iter   138/  229] train: loss: 0.1380049
[Epoch 79; Iter   168/  229] train: loss: 0.1319893
[Epoch 79; Iter   198/  229] train: loss: 0.0824714
[Epoch 79; Iter   228/  229] train: loss: 0.1306021
[Epoch 79] ogbg-moltoxcast: 0.650928 val loss: 0.322246
[Epoch 79] ogbg-moltoxcast: 0.624830 test loss: 0.379795
[Epoch 80; Iter    29/  229] train: loss: 0.1135016
[Epoch 80; Iter    59/  229] train: loss: 0.1105287
[Epoch 80; Iter    89/  229] train: loss: 0.1302433
[Epoch 80; Iter   119/  229] train: loss: 0.1075018
[Epoch 80; Iter   149/  229] train: loss: 0.1154684
[Epoch 80; Iter   179/  229] train: loss: 0.1146464
[Epoch 80; Iter   209/  229] train: loss: 0.1239290
[Epoch 80] ogbg-moltoxcast: 0.654585 val loss: 0.319132
[Epoch 80] ogbg-moltoxcast: 0.626560 test loss: 0.374276
[Epoch 81; Iter    10/  229] train: loss: 0.1157959
[Epoch 81; Iter    40/  229] train: loss: 0.1234724
[Epoch 81; Iter    70/  229] train: loss: 0.1160824
[Epoch 81; Iter   100/  229] train: loss: 0.1339495
[Epoch 81; Iter   130/  229] train: loss: 0.1423110
[Epoch 81; Iter   160/  229] train: loss: 0.1347267
[Epoch 81; Iter   190/  229] train: loss: 0.1209888
[Epoch 81; Iter   220/  229] train: loss: 0.0970471
[Epoch 81] ogbg-moltoxcast: 0.651316 val loss: 0.317260
[Epoch 81] ogbg-moltoxcast: 0.624965 test loss: 0.374054
[Epoch 82; Iter    21/  229] train: loss: 0.0895266
[Epoch 82; Iter    51/  229] train: loss: 0.1163578
[Epoch 82; Iter    81/  229] train: loss: 0.1161674
[Epoch 82; Iter   111/  229] train: loss: 0.0942214
[Epoch 82; Iter   141/  229] train: loss: 0.1006512
[Epoch 82; Iter   171/  229] train: loss: 0.1094267
[Epoch 82; Iter   201/  229] train: loss: 0.1143263
[Epoch 82] ogbg-moltoxcast: 0.655383 val loss: 0.318411
[Epoch 82] ogbg-moltoxcast: 0.629199 test loss: 0.375629
[Epoch 83; Iter     2/  229] train: loss: 0.1540806
[Epoch 83; Iter    32/  229] train: loss: 0.0963901
[Epoch 83; Iter    62/  229] train: loss: 0.1091757
[Epoch 83; Iter    92/  229] train: loss: 0.1196530
[Epoch 83; Iter   122/  229] train: loss: 0.1082282
[Epoch 83; Iter   152/  229] train: loss: 0.0917381
[Epoch 83; Iter   182/  229] train: loss: 0.0814729
[Epoch 83; Iter   212/  229] train: loss: 0.1520563
[Epoch 83] ogbg-moltoxcast: 0.650880 val loss: 0.318892
[Epoch 83] ogbg-moltoxcast: 0.621175 test loss: 0.376266
[Epoch 84; Iter    13/  229] train: loss: 0.1032126
[Epoch 84; Iter    43/  229] train: loss: 0.1100399
[Epoch 84; Iter    73/  229] train: loss: 0.0910630
[Epoch 84; Iter   103/  229] train: loss: 0.0974681
[Epoch 84; Iter   133/  229] train: loss: 0.0737589
[Epoch 84; Iter   163/  229] train: loss: 0.0999298
[Epoch 84; Iter   193/  229] train: loss: 0.1361811
[Epoch 84; Iter   223/  229] train: loss: 0.0967599
[Epoch 84] ogbg-moltoxcast: 0.653785 val loss: 0.323635
[Epoch 84] ogbg-moltoxcast: 0.627381 test loss: 0.377299
[Epoch 85; Iter    24/  229] train: loss: 0.1278598
[Epoch 85; Iter    54/  229] train: loss: 0.1085243
[Epoch 85; Iter    84/  229] train: loss: 0.1091181
[Epoch 85; Iter   114/  229] train: loss: 0.0802137
[Epoch 85; Iter   144/  229] train: loss: 0.1072655
[Epoch 85; Iter   174/  229] train: loss: 0.1721513
[Epoch 85; Iter   204/  229] train: loss: 0.1373253
[Epoch 85] ogbg-moltoxcast: 0.645165 val loss: 0.322959
[Epoch 85] ogbg-moltoxcast: 0.621075 test loss: 0.380759
[Epoch 86; Iter     5/  229] train: loss: 0.1031432
[Epoch 86; Iter    35/  229] train: loss: 0.1187897
[Epoch 86; Iter    65/  229] train: loss: 0.0743137
[Epoch 86; Iter    95/  229] train: loss: 0.1292869
[Epoch 86; Iter   125/  229] train: loss: 0.0698283
[Epoch 86; Iter   155/  229] train: loss: 0.1223077
[Epoch 86; Iter   185/  229] train: loss: 0.1107330
[Epoch 86; Iter   215/  229] train: loss: 0.1512720
[Epoch 86] ogbg-moltoxcast: 0.646739 val loss: 0.325269
[Epoch 86] ogbg-moltoxcast: 0.625969 test loss: 0.378998
[Epoch 87; Iter    16/  229] train: loss: 0.0775751
[Epoch 87; Iter    46/  229] train: loss: 0.0899419
[Epoch 87; Iter    76/  229] train: loss: 0.1344200
[Epoch 87; Iter   106/  229] train: loss: 0.1092520
[Epoch 87; Iter   136/  229] train: loss: 0.1739059
[Epoch 87; Iter   166/  229] train: loss: 0.1084208
[Epoch 87; Iter   196/  229] train: loss: 0.1142661
[Epoch 87; Iter   226/  229] train: loss: 0.0948037
[Epoch 87] ogbg-moltoxcast: 0.646552 val loss: 0.334288
[Epoch 87] ogbg-moltoxcast: 0.627133 test loss: 0.392222
[Epoch 88; Iter    27/  229] train: loss: 0.1108959
[Epoch 88; Iter    57/  229] train: loss: 0.1045388
[Epoch 88; Iter    87/  229] train: loss: 0.1081120
[Epoch 88; Iter   117/  229] train: loss: 0.1410719
[Epoch 88; Iter   147/  229] train: loss: 0.1165762
[Epoch 88; Iter   177/  229] train: loss: 0.1266106
[Epoch 88; Iter   207/  229] train: loss: 0.0927135
[Epoch 88] ogbg-moltoxcast: 0.648245 val loss: 0.324923
[Epoch 88] ogbg-moltoxcast: 0.624007 test loss: 0.377672
[Epoch 89; Iter     8/  229] train: loss: 0.1195194
[Epoch 89; Iter    38/  229] train: loss: 0.1380705
[Epoch 89; Iter    68/  229] train: loss: 0.1427433
[Epoch 89; Iter    98/  229] train: loss: 0.1081863
[Epoch 89; Iter   128/  229] train: loss: 0.0973170
[Epoch 89; Iter   158/  229] train: loss: 0.1062817
[Epoch 89; Iter   188/  229] train: loss: 0.0937871
[Epoch 89; Iter   218/  229] train: loss: 0.1291296
[Epoch 89] ogbg-moltoxcast: 0.655750 val loss: 0.319760
[Epoch 89] ogbg-moltoxcast: 0.624614 test loss: 0.381352
[Epoch 90; Iter    19/  229] train: loss: 0.1162905
[Epoch 90; Iter    49/  229] train: loss: 0.1151453
[Epoch 90; Iter    79/  229] train: loss: 0.0993703
[Epoch 90; Iter   109/  229] train: loss: 0.0799069
[Epoch 90; Iter   139/  229] train: loss: 0.0908241
[Epoch 90; Iter   169/  229] train: loss: 0.0929856
[Epoch 90; Iter   199/  229] train: loss: 0.1678527
[Epoch 90; Iter   229/  229] train: loss: 0.1282116
[Epoch 90] ogbg-moltoxcast: 0.647649 val loss: 0.329111
[Epoch 90] ogbg-moltoxcast: 0.623504 test loss: 0.384664
[Epoch 91; Iter    30/  229] train: loss: 0.1067703
[Epoch 91; Iter    60/  229] train: loss: 0.1260661
[Epoch 91; Iter    90/  229] train: loss: 0.1353117
[Epoch 91; Iter   120/  229] train: loss: 0.0959468
[Epoch 91; Iter   150/  229] train: loss: 0.1392056
[Epoch 91; Iter   180/  229] train: loss: 0.1544205
[Epoch 91; Iter   210/  229] train: loss: 0.1483341
[Epoch 91] ogbg-moltoxcast: 0.650631 val loss: 0.324036
[Epoch 91] ogbg-moltoxcast: 0.624545 test loss: 0.380907
[Epoch 92; Iter    11/  229] train: loss: 0.1251652
[Epoch 92; Iter    41/  229] train: loss: 0.1370914
[Epoch 92; Iter    71/  229] train: loss: 0.1254282
[Epoch 92; Iter   101/  229] train: loss: 0.1336514
[Epoch 92; Iter   131/  229] train: loss: 0.1254981
[Epoch 92; Iter   161/  229] train: loss: 0.0975111
[Epoch 92; Iter   191/  229] train: loss: 0.1179230
[Epoch 92; Iter   221/  229] train: loss: 0.1497386
[Epoch 92] ogbg-moltoxcast: 0.650295 val loss: 0.327685
[Epoch 92] ogbg-moltoxcast: 0.632190 test loss: 0.448480
[Epoch 93; Iter    22/  229] train: loss: 0.1082063
[Epoch 93; Iter    52/  229] train: loss: 0.1098759
[Epoch 93; Iter    82/  229] train: loss: 0.1636263
[Epoch 93; Iter   112/  229] train: loss: 0.1142862
[Epoch 93; Iter   142/  229] train: loss: 0.1232743
[Epoch 93; Iter   172/  229] train: loss: 0.1212732
[Epoch 93; Iter   202/  229] train: loss: 0.0925802
[Epoch 93] ogbg-moltoxcast: 0.644642 val loss: 0.325867
[Epoch 93] ogbg-moltoxcast: 0.627894 test loss: 0.521097
[Epoch 94; Iter     3/  229] train: loss: 0.1080694
[Epoch 94; Iter    33/  229] train: loss: 0.1163211
[Epoch 94; Iter    63/  229] train: loss: 0.1435708
[Epoch 94; Iter    93/  229] train: loss: 0.1084887
[Epoch 94; Iter   123/  229] train: loss: 0.1237497
[Epoch 94; Iter   153/  229] train: loss: 0.1697344
[Epoch 94; Iter   183/  229] train: loss: 0.1369609
[Epoch 94; Iter   213/  229] train: loss: 0.0932300
[Epoch 94] ogbg-moltoxcast: 0.647313 val loss: 0.322183
[Epoch 94] ogbg-moltoxcast: 0.627776 test loss: 0.508405
[Epoch 95; Iter    14/  229] train: loss: 0.1295569
[Epoch 95; Iter    44/  229] train: loss: 0.0949829
[Epoch 95; Iter    74/  229] train: loss: 0.1296551
[Epoch 95; Iter   104/  229] train: loss: 0.1318289
[Epoch 95; Iter   134/  229] train: loss: 0.0925586
[Epoch 95; Iter   164/  229] train: loss: 0.1164577
[Epoch 95; Iter   194/  229] train: loss: 0.1329353
[Epoch 95; Iter   224/  229] train: loss: 0.1468435
[Epoch 95] ogbg-moltoxcast: 0.648295 val loss: 0.345080
[Epoch 95] ogbg-moltoxcast: 0.628910 test loss: 0.541575
[Epoch 96; Iter    25/  229] train: loss: 0.1239440
[Epoch 96; Iter    55/  229] train: loss: 0.1113299
[Epoch 96; Iter    85/  229] train: loss: 0.0933865
[Epoch 96; Iter   115/  229] train: loss: 0.1505354
[Epoch 96; Iter   145/  229] train: loss: 0.1184539
[Epoch 96; Iter   175/  229] train: loss: 0.1077746
[Epoch 96; Iter   205/  229] train: loss: 0.1506040
[Epoch 96] ogbg-moltoxcast: 0.648724 val loss: 0.345863
[Epoch 96] ogbg-moltoxcast: 0.628197 test loss: 0.587799
[Epoch 97; Iter     6/  229] train: loss: 0.1284622
[Epoch 97; Iter    36/  229] train: loss: 0.1141942
[Epoch 97; Iter    66/  229] train: loss: 0.0837780
[Epoch 97; Iter    96/  229] train: loss: 0.0998446
[Epoch 97; Iter   126/  229] train: loss: 0.1312996
[Epoch 97; Iter   156/  229] train: loss: 0.1054090
[Epoch 97; Iter   186/  229] train: loss: 0.0913954
[Epoch 97; Iter   216/  229] train: loss: 0.1852140
[Epoch 97] ogbg-moltoxcast: 0.643044 val loss: 0.337891
[Epoch 97] ogbg-moltoxcast: 0.626175 test loss: 0.599480
[Epoch 98; Iter    17/  229] train: loss: 0.1177445
[Epoch 98; Iter    47/  229] train: loss: 0.1242126
[Epoch 98; Iter    77/  229] train: loss: 0.1382559
[Epoch 98; Iter   107/  229] train: loss: 0.0997102
[Epoch 98; Iter   137/  229] train: loss: 0.1274180
[Epoch 98; Iter   167/  229] train: loss: 0.1064592
[Epoch 98; Iter   197/  229] train: loss: 0.1020484
[Epoch 98; Iter   227/  229] train: loss: 0.1454251
[Epoch 98] ogbg-moltoxcast: 0.650442 val loss: 0.330498
[Epoch 98] ogbg-moltoxcast: 0.626293 test loss: 0.547276
[Epoch 99; Iter    28/  229] train: loss: 0.1222532
[Epoch 99; Iter    58/  229] train: loss: 0.1287770
[Epoch 99; Iter    88/  229] train: loss: 0.1156558
[Epoch 99; Iter   118/  229] train: loss: 0.1133328
[Epoch 99; Iter   148/  229] train: loss: 0.1818307
[Epoch 99; Iter   178/  229] train: loss: 0.1520891
[Epoch 99; Iter   208/  229] train: loss: 0.1270788
[Epoch 99] ogbg-moltoxcast: 0.642220 val loss: 0.325329
[Epoch 99] ogbg-moltoxcast: 0.624069 test loss: 0.552241
[Epoch 100; Iter     9/  229] train: loss: 0.0936198
[Epoch 100; Iter    39/  229] train: loss: 0.1244761
[Epoch 100; Iter    69/  229] train: loss: 0.1173800
[Epoch 100; Iter    99/  229] train: loss: 0.1109218
[Epoch 100; Iter   129/  229] train: loss: 0.1631912
[Epoch 100; Iter   159/  229] train: loss: 0.1205476
[Epoch 100; Iter   189/  229] train: loss: 0.1182699
[Epoch 100; Iter   219/  229] train: loss: 0.1109827
[Epoch 100] ogbg-moltoxcast: 0.645610 val loss: 0.334068
[Epoch 100] ogbg-moltoxcast: 0.627962 test loss: 0.606351
[Epoch 101; Iter    20/  229] train: loss: 0.1155661
[Epoch 101; Iter    50/  229] train: loss: 0.0919534
[Epoch 101; Iter    80/  229] train: loss: 0.1045191
[Epoch 101; Iter   110/  229] train: loss: 0.1144940
[Epoch 101; Iter   140/  229] train: loss: 0.0756723
[Epoch 101; Iter   170/  229] train: loss: 0.1325718
[Epoch 101; Iter   200/  229] train: loss: 0.1115337
[Epoch 101] ogbg-moltoxcast: 0.647110 val loss: 0.327943
[Epoch 101] ogbg-moltoxcast: 0.624050 test loss: 0.586458
[Epoch 102; Iter     1/  229] train: loss: 0.1182384
[Epoch 102; Iter    31/  229] train: loss: 0.0884089
[Epoch 102; Iter    61/  229] train: loss: 0.0905719
[Epoch 102; Iter    91/  229] train: loss: 0.1153167
[Epoch 102; Iter   121/  229] train: loss: 0.1093673
[Epoch 102; Iter   151/  229] train: loss: 0.1118072
[Epoch 102; Iter   181/  229] train: loss: 0.1255341
[Epoch 102; Iter   211/  229] train: loss: 0.1202342
[Epoch 102] ogbg-moltoxcast: 0.648056 val loss: 0.322814
[Epoch 102] ogbg-moltoxcast: 0.625244 test loss: 0.529905
[Epoch 103; Iter    12/  229] train: loss: 0.0769479
[Epoch 103; Iter    42/  229] train: loss: 0.1266283
[Epoch 103; Iter    72/  229] train: loss: 0.1189249
[Epoch 103; Iter   102/  229] train: loss: 0.1470738
[Epoch 103; Iter   132/  229] train: loss: 0.1139452
[Epoch 103; Iter   162/  229] train: loss: 0.1176693
[Epoch 103; Iter   192/  229] train: loss: 0.1460284
[Epoch 103; Iter   222/  229] train: loss: 0.1210079
[Epoch 103] ogbg-moltoxcast: 0.640644 val loss: 0.333193
[Epoch 103] ogbg-moltoxcast: 0.622057 test loss: 0.653240
[Epoch 104; Iter    23/  229] train: loss: 0.1155251
[Epoch 104; Iter    53/  229] train: loss: 0.1198313
[Epoch 104; Iter    83/  229] train: loss: 0.1031748
[Epoch 104; Iter   113/  229] train: loss: 0.1548053
[Epoch 104; Iter   143/  229] train: loss: 0.1101432
[Epoch 104; Iter   173/  229] train: loss: 0.1035487
[Epoch 104; Iter   203/  229] train: loss: 0.0931007
[Epoch 104] ogbg-moltoxcast: 0.641275 val loss: 0.345409
[Epoch 104] ogbg-moltoxcast: 0.625392 test loss: 0.601228
[Epoch 105; Iter     4/  229] train: loss: 0.1329586
[Epoch 105; Iter    34/  229] train: loss: 0.1031987
[Epoch 105; Iter    64/  229] train: loss: 0.0975700
[Epoch 105; Iter    94/  229] train: loss: 0.1164781
[Epoch 105; Iter   124/  229] train: loss: 0.1484586
[Epoch 105; Iter   154/  229] train: loss: 0.1151725
[Epoch 105; Iter   184/  229] train: loss: 0.1163202
[Epoch 105; Iter   214/  229] train: loss: 0.1208284
[Epoch 105] ogbg-moltoxcast: 0.641638 val loss: 0.336542
[Epoch 105] ogbg-moltoxcast: 0.624918 test loss: 0.550118
[Epoch 106; Iter    15/  229] train: loss: 0.1197030
[Epoch 106; Iter    45/  229] train: loss: 0.0969419
[Epoch 106; Iter    75/  229] train: loss: 0.1312993
[Epoch 106; Iter   105/  229] train: loss: 0.1027008
[Epoch 106; Iter   135/  229] train: loss: 0.1243628
[Epoch 106; Iter   165/  229] train: loss: 0.1362002
[Epoch 106; Iter   195/  229] train: loss: 0.1151233
[Epoch 106; Iter   225/  229] train: loss: 0.1262746
[Epoch 106] ogbg-moltoxcast: 0.641118 val loss: 0.343603
[Epoch 106] ogbg-moltoxcast: 0.627187 test loss: 0.545216
[Epoch 107; Iter    26/  229] train: loss: 0.1305582
[Epoch 107; Iter    56/  229] train: loss: 0.1191132
[Epoch 107; Iter    86/  229] train: loss: 0.1030963
[Epoch 107; Iter   116/  229] train: loss: 0.1044657
[Epoch 107; Iter   146/  229] train: loss: 0.0912432
[Epoch 107; Iter   176/  229] train: loss: 0.1430498
[Epoch 107; Iter   206/  229] train: loss: 0.0940335
[Epoch 107] ogbg-moltoxcast: 0.639353 val loss: 0.329516
[Epoch 92; Iter    11/  229] train: loss: 0.1239141
[Epoch 92; Iter    41/  229] train: loss: 0.1394776
[Epoch 92; Iter    71/  229] train: loss: 0.0904545
[Epoch 92; Iter   101/  229] train: loss: 0.1271980
[Epoch 92; Iter   131/  229] train: loss: 0.0936354
[Epoch 92; Iter   161/  229] train: loss: 0.1146460
[Epoch 92; Iter   191/  229] train: loss: 0.0940239
[Epoch 92; Iter   221/  229] train: loss: 0.1113053
[Epoch 92] ogbg-moltoxcast: 0.664943 val loss: 0.474740
[Epoch 92] ogbg-moltoxcast: 0.641544 test loss: 0.356692
[Epoch 93; Iter    22/  229] train: loss: 0.1229519
[Epoch 93; Iter    52/  229] train: loss: 0.1087090
[Epoch 93; Iter    82/  229] train: loss: 0.0735134
[Epoch 93; Iter   112/  229] train: loss: 0.1158557
[Epoch 93; Iter   142/  229] train: loss: 0.1337244
[Epoch 93; Iter   172/  229] train: loss: 0.1029870
[Epoch 93; Iter   202/  229] train: loss: 0.1022918
[Epoch 93] ogbg-moltoxcast: 0.668505 val loss: 0.505700
[Epoch 93] ogbg-moltoxcast: 0.640996 test loss: 0.358540
[Epoch 94; Iter     3/  229] train: loss: 0.1071361
[Epoch 94; Iter    33/  229] train: loss: 0.1252423
[Epoch 94; Iter    63/  229] train: loss: 0.0970446
[Epoch 94; Iter    93/  229] train: loss: 0.1488230
[Epoch 94; Iter   123/  229] train: loss: 0.1336782
[Epoch 94; Iter   153/  229] train: loss: 0.0770534
[Epoch 94; Iter   183/  229] train: loss: 0.0943720
[Epoch 94; Iter   213/  229] train: loss: 0.1087382
[Epoch 94] ogbg-moltoxcast: 0.666248 val loss: 0.529262
[Epoch 94] ogbg-moltoxcast: 0.639386 test loss: 0.358754
[Epoch 95; Iter    14/  229] train: loss: 0.1267660
[Epoch 95; Iter    44/  229] train: loss: 0.1146775
[Epoch 95; Iter    74/  229] train: loss: 0.1049929
[Epoch 95; Iter   104/  229] train: loss: 0.1001006
[Epoch 95; Iter   134/  229] train: loss: 0.0805021
[Epoch 95; Iter   164/  229] train: loss: 0.1340798
[Epoch 95; Iter   194/  229] train: loss: 0.1214302
[Epoch 95; Iter   224/  229] train: loss: 0.1092015
[Epoch 95] ogbg-moltoxcast: 0.666935 val loss: 0.542197
[Epoch 95] ogbg-moltoxcast: 0.639451 test loss: 0.353355
[Epoch 96; Iter    25/  229] train: loss: 0.1326341
[Epoch 96; Iter    55/  229] train: loss: 0.1037706
[Epoch 96; Iter    85/  229] train: loss: 0.1194139
[Epoch 96; Iter   115/  229] train: loss: 0.0847650
[Epoch 96; Iter   145/  229] train: loss: 0.1197137
[Epoch 96; Iter   175/  229] train: loss: 0.1033166
[Epoch 96; Iter   205/  229] train: loss: 0.1069240
[Epoch 96] ogbg-moltoxcast: 0.663602 val loss: 0.564787
[Epoch 96] ogbg-moltoxcast: 0.645714 test loss: 0.350607
[Epoch 97; Iter     6/  229] train: loss: 0.0623096
[Epoch 97; Iter    36/  229] train: loss: 0.1270280
[Epoch 97; Iter    66/  229] train: loss: 0.0792238
[Epoch 97; Iter    96/  229] train: loss: 0.1710513
[Epoch 97; Iter   126/  229] train: loss: 0.0876255
[Epoch 97; Iter   156/  229] train: loss: 0.0931906
[Epoch 97; Iter   186/  229] train: loss: 0.1187776
[Epoch 97; Iter   216/  229] train: loss: 0.0895504
[Epoch 97] ogbg-moltoxcast: 0.665301 val loss: 0.464804
[Epoch 97] ogbg-moltoxcast: 0.647694 test loss: 0.352308
[Epoch 98; Iter    17/  229] train: loss: 0.1609563
[Epoch 98; Iter    47/  229] train: loss: 0.1216197
[Epoch 98; Iter    77/  229] train: loss: 0.1332989
[Epoch 98; Iter   107/  229] train: loss: 0.1178567
[Epoch 98; Iter   137/  229] train: loss: 0.0935203
[Epoch 98; Iter   167/  229] train: loss: 0.0674651
[Epoch 98; Iter   197/  229] train: loss: 0.1007062
[Epoch 98; Iter   227/  229] train: loss: 0.1524965
[Epoch 98] ogbg-moltoxcast: 0.663006 val loss: 0.545399
[Epoch 98] ogbg-moltoxcast: 0.642109 test loss: 0.354156
[Epoch 99; Iter    28/  229] train: loss: 0.1403000
[Epoch 99; Iter    58/  229] train: loss: 0.0758682
[Epoch 99; Iter    88/  229] train: loss: 0.1192976
[Epoch 99; Iter   118/  229] train: loss: 0.1401799
[Epoch 99; Iter   148/  229] train: loss: 0.1399808
[Epoch 99; Iter   178/  229] train: loss: 0.1196933
[Epoch 99; Iter   208/  229] train: loss: 0.1214883
[Epoch 99] ogbg-moltoxcast: 0.666584 val loss: 0.538942
[Epoch 99] ogbg-moltoxcast: 0.641392 test loss: 0.357656
[Epoch 100; Iter     9/  229] train: loss: 0.0855338
[Epoch 100; Iter    39/  229] train: loss: 0.1329405
[Epoch 100; Iter    69/  229] train: loss: 0.1174546
[Epoch 100; Iter    99/  229] train: loss: 0.1015858
[Epoch 100; Iter   129/  229] train: loss: 0.1339954
[Epoch 100; Iter   159/  229] train: loss: 0.1222022
[Epoch 100; Iter   189/  229] train: loss: 0.1256596
[Epoch 100; Iter   219/  229] train: loss: 0.1922765
[Epoch 100] ogbg-moltoxcast: 0.672665 val loss: 0.483284
[Epoch 100] ogbg-moltoxcast: 0.646919 test loss: 0.356940
[Epoch 101; Iter    20/  229] train: loss: 0.1077527
[Epoch 101; Iter    50/  229] train: loss: 0.1253047
[Epoch 101; Iter    80/  229] train: loss: 0.0964121
[Epoch 101; Iter   110/  229] train: loss: 0.1221813
[Epoch 101; Iter   140/  229] train: loss: 0.1241822
[Epoch 101; Iter   170/  229] train: loss: 0.0939653
[Epoch 101; Iter   200/  229] train: loss: 0.1081044
[Epoch 101] ogbg-moltoxcast: 0.667317 val loss: 0.534961
[Epoch 101] ogbg-moltoxcast: 0.645223 test loss: 0.358093
[Epoch 102; Iter     1/  229] train: loss: 0.1222426
[Epoch 102; Iter    31/  229] train: loss: 0.0987427
[Epoch 102; Iter    61/  229] train: loss: 0.1351878
[Epoch 102; Iter    91/  229] train: loss: 0.1040780
[Epoch 102; Iter   121/  229] train: loss: 0.1023096
[Epoch 102; Iter   151/  229] train: loss: 0.1021165
[Epoch 102; Iter   181/  229] train: loss: 0.0906942
[Epoch 102; Iter   211/  229] train: loss: 0.1334619
[Epoch 102] ogbg-moltoxcast: 0.671549 val loss: 0.508107
[Epoch 102] ogbg-moltoxcast: 0.645164 test loss: 0.359440
[Epoch 103; Iter    12/  229] train: loss: 0.1063932
[Epoch 103; Iter    42/  229] train: loss: 0.1131504
[Epoch 103; Iter    72/  229] train: loss: 0.1090386
[Epoch 103; Iter   102/  229] train: loss: 0.1187748
[Epoch 103; Iter   132/  229] train: loss: 0.1058024
[Epoch 103; Iter   162/  229] train: loss: 0.1499889
[Epoch 103; Iter   192/  229] train: loss: 0.1054397
[Epoch 103; Iter   222/  229] train: loss: 0.1224386
[Epoch 103] ogbg-moltoxcast: 0.662598 val loss: 0.526861
[Epoch 103] ogbg-moltoxcast: 0.644351 test loss: 0.357826
[Epoch 104; Iter    23/  229] train: loss: 0.0996757
[Epoch 104; Iter    53/  229] train: loss: 0.0878601
[Epoch 104; Iter    83/  229] train: loss: 0.1079896
[Epoch 104; Iter   113/  229] train: loss: 0.1049045
[Epoch 104; Iter   143/  229] train: loss: 0.0872149
[Epoch 104; Iter   173/  229] train: loss: 0.0956300
[Epoch 104; Iter   203/  229] train: loss: 0.1224463
[Epoch 104] ogbg-moltoxcast: 0.669547 val loss: 0.495005
[Epoch 104] ogbg-moltoxcast: 0.641129 test loss: 0.360334
[Epoch 105; Iter     4/  229] train: loss: 0.1107869
[Epoch 105; Iter    34/  229] train: loss: 0.0955273
[Epoch 105; Iter    64/  229] train: loss: 0.1078769
[Epoch 105; Iter    94/  229] train: loss: 0.1197285
[Epoch 105; Iter   124/  229] train: loss: 0.0772889
[Epoch 105; Iter   154/  229] train: loss: 0.0912249
[Epoch 105; Iter   184/  229] train: loss: 0.1246309
[Epoch 105; Iter   214/  229] train: loss: 0.1262252
[Epoch 105] ogbg-moltoxcast: 0.669445 val loss: 0.573659
[Epoch 105] ogbg-moltoxcast: 0.643598 test loss: 0.363358
[Epoch 106; Iter    15/  229] train: loss: 0.0816083
[Epoch 106; Iter    45/  229] train: loss: 0.0804356
[Epoch 106; Iter    75/  229] train: loss: 0.0830309
[Epoch 106; Iter   105/  229] train: loss: 0.0893066
[Epoch 106; Iter   135/  229] train: loss: 0.1128646
[Epoch 106; Iter   165/  229] train: loss: 0.0870998
[Epoch 106; Iter   195/  229] train: loss: 0.1592514
[Epoch 106; Iter   225/  229] train: loss: 0.1414908
[Epoch 106] ogbg-moltoxcast: 0.662430 val loss: 0.553512
[Epoch 106] ogbg-moltoxcast: 0.640290 test loss: 0.361998
[Epoch 107; Iter    26/  229] train: loss: 0.0887231
[Epoch 107; Iter    56/  229] train: loss: 0.1084426
[Epoch 107; Iter    86/  229] train: loss: 0.1109027
[Epoch 107; Iter   116/  229] train: loss: 0.1297326
[Epoch 107; Iter   146/  229] train: loss: 0.1058497
[Epoch 107; Iter   176/  229] train: loss: 0.1396370
[Epoch 107; Iter   206/  229] train: loss: 0.1170568
[Epoch 107] ogbg-moltoxcast: 0.663847 val loss: 0.526491
[Epoch 92; Iter    11/  229] train: loss: 0.1066973
[Epoch 92; Iter    41/  229] train: loss: 0.1007703
[Epoch 92; Iter    71/  229] train: loss: 0.1260386
[Epoch 92; Iter   101/  229] train: loss: 0.0925872
[Epoch 92; Iter   131/  229] train: loss: 0.0897494
[Epoch 92; Iter   161/  229] train: loss: 0.0789169
[Epoch 92; Iter   191/  229] train: loss: 0.1053549
[Epoch 92; Iter   221/  229] train: loss: 0.1144710
[Epoch 92] ogbg-moltoxcast: 0.687444 val loss: 0.302927
[Epoch 92] ogbg-moltoxcast: 0.644392 test loss: 0.355292
[Epoch 93; Iter    22/  229] train: loss: 0.0790958
[Epoch 93; Iter    52/  229] train: loss: 0.0668401
[Epoch 93; Iter    82/  229] train: loss: 0.1077545
[Epoch 93; Iter   112/  229] train: loss: 0.1042990
[Epoch 93; Iter   142/  229] train: loss: 0.0936690
[Epoch 93; Iter   172/  229] train: loss: 0.1397969
[Epoch 93; Iter   202/  229] train: loss: 0.1097036
[Epoch 93] ogbg-moltoxcast: 0.688027 val loss: 0.326429
[Epoch 93] ogbg-moltoxcast: 0.643288 test loss: 0.364393
[Epoch 94; Iter     3/  229] train: loss: 0.1607480
[Epoch 94; Iter    33/  229] train: loss: 0.1304061
[Epoch 94; Iter    63/  229] train: loss: 0.1282883
[Epoch 94; Iter    93/  229] train: loss: 0.0795879
[Epoch 94; Iter   123/  229] train: loss: 0.0923741
[Epoch 94; Iter   153/  229] train: loss: 0.1033715
[Epoch 94; Iter   183/  229] train: loss: 0.1210568
[Epoch 94; Iter   213/  229] train: loss: 0.1618114
[Epoch 94] ogbg-moltoxcast: 0.684711 val loss: 0.338633
[Epoch 94] ogbg-moltoxcast: 0.643955 test loss: 0.363693
[Epoch 95; Iter    14/  229] train: loss: 0.1086292
[Epoch 95; Iter    44/  229] train: loss: 0.1161318
[Epoch 95; Iter    74/  229] train: loss: 0.1546709
[Epoch 95; Iter   104/  229] train: loss: 0.1117013
[Epoch 95; Iter   134/  229] train: loss: 0.1290895
[Epoch 95; Iter   164/  229] train: loss: 0.1025994
[Epoch 95; Iter   194/  229] train: loss: 0.0722044
[Epoch 95; Iter   224/  229] train: loss: 0.0983832
[Epoch 95] ogbg-moltoxcast: 0.686710 val loss: 0.302824
[Epoch 95] ogbg-moltoxcast: 0.646243 test loss: 0.358356
[Epoch 96; Iter    25/  229] train: loss: 0.1185394
[Epoch 96; Iter    55/  229] train: loss: 0.0610543
[Epoch 96; Iter    85/  229] train: loss: 0.1089124
[Epoch 96; Iter   115/  229] train: loss: 0.1304357
[Epoch 96; Iter   145/  229] train: loss: 0.1233330
[Epoch 96; Iter   175/  229] train: loss: 0.1269171
[Epoch 96; Iter   205/  229] train: loss: 0.1032574
[Epoch 96] ogbg-moltoxcast: 0.687771 val loss: 0.304876
[Epoch 96] ogbg-moltoxcast: 0.644883 test loss: 0.362297
[Epoch 97; Iter     6/  229] train: loss: 0.1186272
[Epoch 97; Iter    36/  229] train: loss: 0.0858622
[Epoch 97; Iter    66/  229] train: loss: 0.0921386
[Epoch 97; Iter    96/  229] train: loss: 0.0975001
[Epoch 97; Iter   126/  229] train: loss: 0.1140970
[Epoch 97; Iter   156/  229] train: loss: 0.1041249
[Epoch 97; Iter   186/  229] train: loss: 0.0868585
[Epoch 97; Iter   216/  229] train: loss: 0.1119654
[Epoch 97] ogbg-moltoxcast: 0.686997 val loss: 0.326747
[Epoch 97] ogbg-moltoxcast: 0.647294 test loss: 0.368708
[Epoch 98; Iter    17/  229] train: loss: 0.1256238
[Epoch 98; Iter    47/  229] train: loss: 0.1047653
[Epoch 98; Iter    77/  229] train: loss: 0.0875379
[Epoch 98; Iter   107/  229] train: loss: 0.0953438
[Epoch 98; Iter   137/  229] train: loss: 0.1015487
[Epoch 98; Iter   167/  229] train: loss: 0.1333831
[Epoch 98; Iter   197/  229] train: loss: 0.1358036
[Epoch 98; Iter   227/  229] train: loss: 0.1070126
[Epoch 98] ogbg-moltoxcast: 0.686364 val loss: 0.307612
[Epoch 98] ogbg-moltoxcast: 0.645650 test loss: 0.364704
[Epoch 99; Iter    28/  229] train: loss: 0.1210212
[Epoch 99; Iter    58/  229] train: loss: 0.1210593
[Epoch 99; Iter    88/  229] train: loss: 0.1295263
[Epoch 99; Iter   118/  229] train: loss: 0.1226902
[Epoch 99; Iter   148/  229] train: loss: 0.1337736
[Epoch 99; Iter   178/  229] train: loss: 0.1759238
[Epoch 99; Iter   208/  229] train: loss: 0.0590497
[Epoch 99] ogbg-moltoxcast: 0.684185 val loss: 0.358815
[Epoch 99] ogbg-moltoxcast: 0.642385 test loss: 0.378096
[Epoch 100; Iter     9/  229] train: loss: 0.0850974
[Epoch 100; Iter    39/  229] train: loss: 0.1119532
[Epoch 100; Iter    69/  229] train: loss: 0.0907577
[Epoch 100; Iter    99/  229] train: loss: 0.0950866
[Epoch 100; Iter   129/  229] train: loss: 0.1003867
[Epoch 100; Iter   159/  229] train: loss: 0.0922717
[Epoch 100; Iter   189/  229] train: loss: 0.1153660
[Epoch 100; Iter   219/  229] train: loss: 0.1057202
[Epoch 100] ogbg-moltoxcast: 0.688208 val loss: 0.342480
[Epoch 100] ogbg-moltoxcast: 0.645838 test loss: 0.367688
[Epoch 101; Iter    20/  229] train: loss: 0.1417551
[Epoch 101; Iter    50/  229] train: loss: 0.1049637
[Epoch 101; Iter    80/  229] train: loss: 0.0860506
[Epoch 101; Iter   110/  229] train: loss: 0.1078290
[Epoch 101; Iter   140/  229] train: loss: 0.1151331
[Epoch 101; Iter   170/  229] train: loss: 0.1098000
[Epoch 101; Iter   200/  229] train: loss: 0.1562931
[Epoch 101] ogbg-moltoxcast: 0.683328 val loss: 0.328470
[Epoch 101] ogbg-moltoxcast: 0.642971 test loss: 0.359703
[Epoch 102; Iter     1/  229] train: loss: 0.0982837
[Epoch 102; Iter    31/  229] train: loss: 0.1137110
[Epoch 102; Iter    61/  229] train: loss: 0.1544784
[Epoch 102; Iter    91/  229] train: loss: 0.1343210
[Epoch 102; Iter   121/  229] train: loss: 0.1174735
[Epoch 102; Iter   151/  229] train: loss: 0.1025922
[Epoch 102; Iter   181/  229] train: loss: 0.1471380
[Epoch 102; Iter   211/  229] train: loss: 0.1021735
[Epoch 102] ogbg-moltoxcast: 0.686543 val loss: 0.305648
[Epoch 102] ogbg-moltoxcast: 0.642768 test loss: 0.359721
[Epoch 103; Iter    12/  229] train: loss: 0.0918505
[Epoch 103; Iter    42/  229] train: loss: 0.1077808
[Epoch 103; Iter    72/  229] train: loss: 0.0933869
[Epoch 103; Iter   102/  229] train: loss: 0.1453061
[Epoch 103; Iter   132/  229] train: loss: 0.1290865
[Epoch 103; Iter   162/  229] train: loss: 0.0666240
[Epoch 103; Iter   192/  229] train: loss: 0.1082526
[Epoch 103; Iter   222/  229] train: loss: 0.1285289
[Epoch 103] ogbg-moltoxcast: 0.688755 val loss: 0.311700
[Epoch 103] ogbg-moltoxcast: 0.645365 test loss: 0.363282
[Epoch 104; Iter    23/  229] train: loss: 0.1113259
[Epoch 104; Iter    53/  229] train: loss: 0.0767113
[Epoch 104; Iter    83/  229] train: loss: 0.0969480
[Epoch 104; Iter   113/  229] train: loss: 0.1456072
[Epoch 104; Iter   143/  229] train: loss: 0.1327577
[Epoch 104; Iter   173/  229] train: loss: 0.1156203
[Epoch 104; Iter   203/  229] train: loss: 0.1021584
[Epoch 104] ogbg-moltoxcast: 0.685742 val loss: 0.320670
[Epoch 104] ogbg-moltoxcast: 0.642935 test loss: 0.360842
[Epoch 105; Iter     4/  229] train: loss: 0.0993919
[Epoch 105; Iter    34/  229] train: loss: 0.1030183
[Epoch 105; Iter    64/  229] train: loss: 0.1044602
[Epoch 105; Iter    94/  229] train: loss: 0.1051342
[Epoch 105; Iter   124/  229] train: loss: 0.1330163
[Epoch 105; Iter   154/  229] train: loss: 0.0973861
[Epoch 105; Iter   184/  229] train: loss: 0.0893790
[Epoch 105; Iter   214/  229] train: loss: 0.1265405
[Epoch 105] ogbg-moltoxcast: 0.682173 val loss: 0.324581
[Epoch 105] ogbg-moltoxcast: 0.644610 test loss: 0.362461
[Epoch 106; Iter    15/  229] train: loss: 0.0960405
[Epoch 106; Iter    45/  229] train: loss: 0.0897581
[Epoch 106; Iter    75/  229] train: loss: 0.1383954
[Epoch 106; Iter   105/  229] train: loss: 0.1205484
[Epoch 106; Iter   135/  229] train: loss: 0.1094153
[Epoch 106; Iter   165/  229] train: loss: 0.1289875
[Epoch 106; Iter   195/  229] train: loss: 0.1145722
[Epoch 106; Iter   225/  229] train: loss: 0.1208887
[Epoch 106] ogbg-moltoxcast: 0.688145 val loss: 0.327015
[Epoch 106] ogbg-moltoxcast: 0.643131 test loss: 0.369598
[Epoch 107; Iter    26/  229] train: loss: 0.0911548
[Epoch 107; Iter    56/  229] train: loss: 0.1043819
[Epoch 107; Iter    86/  229] train: loss: 0.0976469
[Epoch 107; Iter   116/  229] train: loss: 0.1015266
[Epoch 107; Iter   146/  229] train: loss: 0.0851621
[Epoch 107; Iter   176/  229] train: loss: 0.1083748
[Epoch 107; Iter   206/  229] train: loss: 0.1466627
[Epoch 107] ogbg-moltoxcast: 0.686350 val loss: 0.320941
[Epoch 92; Iter    11/  229] train: loss: 0.1179782
[Epoch 92; Iter    41/  229] train: loss: 0.1186876
[Epoch 92; Iter    71/  229] train: loss: 0.1132400
[Epoch 92; Iter   101/  229] train: loss: 0.1307736
[Epoch 92; Iter   131/  229] train: loss: 0.1211583
[Epoch 92; Iter   161/  229] train: loss: 0.0926970
[Epoch 92; Iter   191/  229] train: loss: 0.1078186
[Epoch 92; Iter   221/  229] train: loss: 0.1397548
[Epoch 92] ogbg-moltoxcast: 0.657105 val loss: 0.321504
[Epoch 92] ogbg-moltoxcast: 0.653960 test loss: 0.369315
[Epoch 93; Iter    22/  229] train: loss: 0.1039278
[Epoch 93; Iter    52/  229] train: loss: 0.1024430
[Epoch 93; Iter    82/  229] train: loss: 0.1580455
[Epoch 93; Iter   112/  229] train: loss: 0.1136728
[Epoch 93; Iter   142/  229] train: loss: 0.1122824
[Epoch 93; Iter   172/  229] train: loss: 0.1062549
[Epoch 93; Iter   202/  229] train: loss: 0.0888045
[Epoch 93] ogbg-moltoxcast: 0.654534 val loss: 0.334942
[Epoch 93] ogbg-moltoxcast: 0.651582 test loss: 0.386917
[Epoch 94; Iter     3/  229] train: loss: 0.1019088
[Epoch 94; Iter    33/  229] train: loss: 0.1125827
[Epoch 94; Iter    63/  229] train: loss: 0.1297678
[Epoch 94; Iter    93/  229] train: loss: 0.0986993
[Epoch 94; Iter   123/  229] train: loss: 0.1099010
[Epoch 94; Iter   153/  229] train: loss: 0.1673315
[Epoch 94; Iter   183/  229] train: loss: 0.1258555
[Epoch 94; Iter   213/  229] train: loss: 0.0873830
[Epoch 94] ogbg-moltoxcast: 0.654237 val loss: 0.328120
[Epoch 94] ogbg-moltoxcast: 0.655494 test loss: 0.374972
[Epoch 95; Iter    14/  229] train: loss: 0.1124900
[Epoch 95; Iter    44/  229] train: loss: 0.0864496
[Epoch 95; Iter    74/  229] train: loss: 0.1294526
[Epoch 95; Iter   104/  229] train: loss: 0.1189371
[Epoch 95; Iter   134/  229] train: loss: 0.0850336
[Epoch 95; Iter   164/  229] train: loss: 0.1075392
[Epoch 95; Iter   194/  229] train: loss: 0.1218322
[Epoch 95; Iter   224/  229] train: loss: 0.1416926
[Epoch 95] ogbg-moltoxcast: 0.657027 val loss: 0.325348
[Epoch 95] ogbg-moltoxcast: 0.655618 test loss: 0.371578
[Epoch 96; Iter    25/  229] train: loss: 0.1159763
[Epoch 96; Iter    55/  229] train: loss: 0.1001463
[Epoch 96; Iter    85/  229] train: loss: 0.0901234
[Epoch 96; Iter   115/  229] train: loss: 0.1377703
[Epoch 96; Iter   145/  229] train: loss: 0.1097069
[Epoch 96; Iter   175/  229] train: loss: 0.0918199
[Epoch 96; Iter   205/  229] train: loss: 0.1441343
[Epoch 96] ogbg-moltoxcast: 0.656226 val loss: 0.331935
[Epoch 96] ogbg-moltoxcast: 0.656454 test loss: 0.378079
[Epoch 97; Iter     6/  229] train: loss: 0.1225413
[Epoch 97; Iter    36/  229] train: loss: 0.0977453
[Epoch 97; Iter    66/  229] train: loss: 0.0780753
[Epoch 97; Iter    96/  229] train: loss: 0.0966361
[Epoch 97; Iter   126/  229] train: loss: 0.1188685
[Epoch 97; Iter   156/  229] train: loss: 0.0893631
[Epoch 97; Iter   186/  229] train: loss: 0.0843667
[Epoch 97; Iter   216/  229] train: loss: 0.1630916
[Epoch 97] ogbg-moltoxcast: 0.656691 val loss: 0.328969
[Epoch 97] ogbg-moltoxcast: 0.652339 test loss: 0.376050
[Epoch 98; Iter    17/  229] train: loss: 0.1078849
[Epoch 98; Iter    47/  229] train: loss: 0.1153801
[Epoch 98; Iter    77/  229] train: loss: 0.1218442
[Epoch 98; Iter   107/  229] train: loss: 0.0988502
[Epoch 98; Iter   137/  229] train: loss: 0.1241289
[Epoch 98; Iter   167/  229] train: loss: 0.0996704
[Epoch 98; Iter   197/  229] train: loss: 0.0985715
[Epoch 98; Iter   227/  229] train: loss: 0.1293527
[Epoch 98] ogbg-moltoxcast: 0.654751 val loss: 0.335740
[Epoch 98] ogbg-moltoxcast: 0.654927 test loss: 0.382331
[Epoch 99; Iter    28/  229] train: loss: 0.1048691
[Epoch 99; Iter    58/  229] train: loss: 0.1188721
[Epoch 99; Iter    88/  229] train: loss: 0.1136275
[Epoch 99; Iter   118/  229] train: loss: 0.1038646
[Epoch 99; Iter   148/  229] train: loss: 0.1673791
[Epoch 99; Iter   178/  229] train: loss: 0.1340245
[Epoch 99; Iter   208/  229] train: loss: 0.1158146
[Epoch 99] ogbg-moltoxcast: 0.654380 val loss: 0.327536
[Epoch 99] ogbg-moltoxcast: 0.652965 test loss: 0.375304
[Epoch 100; Iter     9/  229] train: loss: 0.0861931
[Epoch 100; Iter    39/  229] train: loss: 0.1254093
[Epoch 100; Iter    69/  229] train: loss: 0.1126242
[Epoch 100; Iter    99/  229] train: loss: 0.1028928
[Epoch 100; Iter   129/  229] train: loss: 0.1546386
[Epoch 100; Iter   159/  229] train: loss: 0.1113475
[Epoch 100; Iter   189/  229] train: loss: 0.1077567
[Epoch 100; Iter   219/  229] train: loss: 0.1040714
[Epoch 100] ogbg-moltoxcast: 0.655790 val loss: 0.330059
[Epoch 100] ogbg-moltoxcast: 0.654924 test loss: 0.379684
[Epoch 101; Iter    20/  229] train: loss: 0.1033349
[Epoch 101; Iter    50/  229] train: loss: 0.0906595
[Epoch 101; Iter    80/  229] train: loss: 0.0994439
[Epoch 101; Iter   110/  229] train: loss: 0.1162368
[Epoch 101; Iter   140/  229] train: loss: 0.0728872
[Epoch 101; Iter   170/  229] train: loss: 0.1301951
[Epoch 101; Iter   200/  229] train: loss: 0.0955013
[Epoch 101] ogbg-moltoxcast: 0.659498 val loss: 0.329245
[Epoch 101] ogbg-moltoxcast: 0.655725 test loss: 0.380225
[Epoch 102; Iter     1/  229] train: loss: 0.1114073
[Epoch 102; Iter    31/  229] train: loss: 0.0829038
[Epoch 102; Iter    61/  229] train: loss: 0.0811028
[Epoch 102; Iter    91/  229] train: loss: 0.1078128
[Epoch 102; Iter   121/  229] train: loss: 0.1059679
[Epoch 102; Iter   151/  229] train: loss: 0.1004632
[Epoch 102; Iter   181/  229] train: loss: 0.1190247
[Epoch 102; Iter   211/  229] train: loss: 0.1128787
[Epoch 102] ogbg-moltoxcast: 0.656137 val loss: 0.327499
[Epoch 102] ogbg-moltoxcast: 0.656570 test loss: 0.375686
[Epoch 103; Iter    12/  229] train: loss: 0.0746332
[Epoch 103; Iter    42/  229] train: loss: 0.1120853
[Epoch 103; Iter    72/  229] train: loss: 0.1090966
[Epoch 103; Iter   102/  229] train: loss: 0.1334016
[Epoch 103; Iter   132/  229] train: loss: 0.1089317
[Epoch 103; Iter   162/  229] train: loss: 0.1061894
[Epoch 103; Iter   192/  229] train: loss: 0.1316188
[Epoch 103; Iter   222/  229] train: loss: 0.1054657
[Epoch 103] ogbg-moltoxcast: 0.652834 val loss: 0.329343
[Epoch 103] ogbg-moltoxcast: 0.655586 test loss: 0.377849
[Epoch 104; Iter    23/  229] train: loss: 0.1095520
[Epoch 104; Iter    53/  229] train: loss: 0.1120241
[Epoch 104; Iter    83/  229] train: loss: 0.0914419
[Epoch 104; Iter   113/  229] train: loss: 0.1319277
[Epoch 104; Iter   143/  229] train: loss: 0.0988313
[Epoch 104; Iter   173/  229] train: loss: 0.0974182
[Epoch 104; Iter   203/  229] train: loss: 0.0808949
[Epoch 104] ogbg-moltoxcast: 0.650502 val loss: 0.326522
[Epoch 104] ogbg-moltoxcast: 0.654168 test loss: 0.374714
[Epoch 105; Iter     4/  229] train: loss: 0.1248835
[Epoch 105; Iter    34/  229] train: loss: 0.0983932
[Epoch 105; Iter    64/  229] train: loss: 0.0900551
[Epoch 105; Iter    94/  229] train: loss: 0.1026362
[Epoch 105; Iter   124/  229] train: loss: 0.1338827
[Epoch 105; Iter   154/  229] train: loss: 0.1008186
[Epoch 105; Iter   184/  229] train: loss: 0.0960013
[Epoch 105; Iter   214/  229] train: loss: 0.1119556
[Epoch 105] ogbg-moltoxcast: 0.652826 val loss: 0.330851
[Epoch 105] ogbg-moltoxcast: 0.653489 test loss: 0.378403
[Epoch 106; Iter    15/  229] train: loss: 0.1095919
[Epoch 106; Iter    45/  229] train: loss: 0.0907193
[Epoch 106; Iter    75/  229] train: loss: 0.1248484
[Epoch 106; Iter   105/  229] train: loss: 0.0942701
[Epoch 106; Iter   135/  229] train: loss: 0.1157764
[Epoch 106; Iter   165/  229] train: loss: 0.1260648
[Epoch 106; Iter   195/  229] train: loss: 0.1048060
[Epoch 106; Iter   225/  229] train: loss: 0.1102447
[Epoch 106] ogbg-moltoxcast: 0.648937 val loss: 0.336117
[Epoch 106] ogbg-moltoxcast: 0.648562 test loss: 0.386847
[Epoch 107; Iter    26/  229] train: loss: 0.1211179
[Epoch 107; Iter    56/  229] train: loss: 0.1026923
[Epoch 107; Iter    86/  229] train: loss: 0.0996562
[Epoch 107; Iter   116/  229] train: loss: 0.0990524
[Epoch 107; Iter   146/  229] train: loss: 0.0793746
[Epoch 107; Iter   176/  229] train: loss: 0.1358062
[Epoch 107; Iter   206/  229] train: loss: 0.0837418
[Epoch 107] ogbg-moltoxcast: 0.650803 val loss: 0.336311
[Epoch 92; Iter    11/  229] train: loss: 0.1196266
[Epoch 92; Iter    41/  229] train: loss: 0.1170216
[Epoch 92; Iter    71/  229] train: loss: 0.1118323
[Epoch 92; Iter   101/  229] train: loss: 0.1368972
[Epoch 92; Iter   131/  229] train: loss: 0.1187622
[Epoch 92; Iter   161/  229] train: loss: 0.1011862
[Epoch 92; Iter   191/  229] train: loss: 0.1074869
[Epoch 92; Iter   221/  229] train: loss: 0.1361958
[Epoch 92] ogbg-moltoxcast: 0.672563 val loss: 0.316188
[Epoch 92] ogbg-moltoxcast: 0.644166 test loss: 0.364948
[Epoch 93; Iter    22/  229] train: loss: 0.1032767
[Epoch 93; Iter    52/  229] train: loss: 0.1122209
[Epoch 93; Iter    82/  229] train: loss: 0.1520458
[Epoch 93; Iter   112/  229] train: loss: 0.1113176
[Epoch 93; Iter   142/  229] train: loss: 0.1166558
[Epoch 93; Iter   172/  229] train: loss: 0.1077593
[Epoch 93; Iter   202/  229] train: loss: 0.0849747
[Epoch 93] ogbg-moltoxcast: 0.670647 val loss: 0.328704
[Epoch 93] ogbg-moltoxcast: 0.642829 test loss: 0.378180
[Epoch 94; Iter     3/  229] train: loss: 0.1050582
[Epoch 94; Iter    33/  229] train: loss: 0.1146965
[Epoch 94; Iter    63/  229] train: loss: 0.1289196
[Epoch 94; Iter    93/  229] train: loss: 0.0996711
[Epoch 94; Iter   123/  229] train: loss: 0.1173035
[Epoch 94; Iter   153/  229] train: loss: 0.1673628
[Epoch 94; Iter   183/  229] train: loss: 0.1298657
[Epoch 94; Iter   213/  229] train: loss: 0.0858611
[Epoch 94] ogbg-moltoxcast: 0.671892 val loss: 0.318460
[Epoch 94] ogbg-moltoxcast: 0.641667 test loss: 0.368453
[Epoch 95; Iter    14/  229] train: loss: 0.1188696
[Epoch 95; Iter    44/  229] train: loss: 0.0900794
[Epoch 95; Iter    74/  229] train: loss: 0.1235936
[Epoch 95; Iter   104/  229] train: loss: 0.1263332
[Epoch 95; Iter   134/  229] train: loss: 0.0914336
[Epoch 95; Iter   164/  229] train: loss: 0.1079086
[Epoch 95; Iter   194/  229] train: loss: 0.1211702
[Epoch 95; Iter   224/  229] train: loss: 0.1413601
[Epoch 95] ogbg-moltoxcast: 0.670112 val loss: 0.317352
[Epoch 95] ogbg-moltoxcast: 0.641418 test loss: 0.363737
[Epoch 96; Iter    25/  229] train: loss: 0.1161952
[Epoch 96; Iter    55/  229] train: loss: 0.1041054
[Epoch 96; Iter    85/  229] train: loss: 0.0895084
[Epoch 96; Iter   115/  229] train: loss: 0.1405723
[Epoch 96; Iter   145/  229] train: loss: 0.1073503
[Epoch 96; Iter   175/  229] train: loss: 0.0932007
[Epoch 96; Iter   205/  229] train: loss: 0.1366881
[Epoch 96] ogbg-moltoxcast: 0.666894 val loss: 0.317381
[Epoch 96] ogbg-moltoxcast: 0.639164 test loss: 0.363169
[Epoch 97; Iter     6/  229] train: loss: 0.1163510
[Epoch 97; Iter    36/  229] train: loss: 0.1016229
[Epoch 97; Iter    66/  229] train: loss: 0.0779499
[Epoch 97; Iter    96/  229] train: loss: 0.0967898
[Epoch 97; Iter   126/  229] train: loss: 0.1117953
[Epoch 97; Iter   156/  229] train: loss: 0.0985236
[Epoch 97; Iter   186/  229] train: loss: 0.0874742
[Epoch 97; Iter   216/  229] train: loss: 0.1722042
[Epoch 97] ogbg-moltoxcast: 0.663578 val loss: 0.320027
[Epoch 97] ogbg-moltoxcast: 0.638650 test loss: 0.366516
[Epoch 98; Iter    17/  229] train: loss: 0.1156011
[Epoch 98; Iter    47/  229] train: loss: 0.1191896
[Epoch 98; Iter    77/  229] train: loss: 0.1202388
[Epoch 98; Iter   107/  229] train: loss: 0.0947282
[Epoch 98; Iter   137/  229] train: loss: 0.1301878
[Epoch 98; Iter   167/  229] train: loss: 0.1023654
[Epoch 98; Iter   197/  229] train: loss: 0.0950639
[Epoch 98; Iter   227/  229] train: loss: 0.1305517
[Epoch 98] ogbg-moltoxcast: 0.667881 val loss: 0.328556
[Epoch 98] ogbg-moltoxcast: 0.642024 test loss: 0.376225
[Epoch 99; Iter    28/  229] train: loss: 0.1153705
[Epoch 99; Iter    58/  229] train: loss: 0.1151054
[Epoch 99; Iter    88/  229] train: loss: 0.1098006
[Epoch 99; Iter   118/  229] train: loss: 0.0978651
[Epoch 99; Iter   148/  229] train: loss: 0.1625240
[Epoch 99; Iter   178/  229] train: loss: 0.1377413
[Epoch 99; Iter   208/  229] train: loss: 0.1225483
[Epoch 99] ogbg-moltoxcast: 0.663800 val loss: 0.314278
[Epoch 99] ogbg-moltoxcast: 0.638001 test loss: 0.362529
[Epoch 100; Iter     9/  229] train: loss: 0.0886164
[Epoch 100; Iter    39/  229] train: loss: 0.1329624
[Epoch 100; Iter    69/  229] train: loss: 0.1099776
[Epoch 100; Iter    99/  229] train: loss: 0.1056114
[Epoch 100; Iter   129/  229] train: loss: 0.1541146
[Epoch 100; Iter   159/  229] train: loss: 0.1129882
[Epoch 100; Iter   189/  229] train: loss: 0.1103229
[Epoch 100; Iter   219/  229] train: loss: 0.0977156
[Epoch 100] ogbg-moltoxcast: 0.667472 val loss: 0.313952
[Epoch 100] ogbg-moltoxcast: 0.643997 test loss: 0.364794
[Epoch 101; Iter    20/  229] train: loss: 0.1027141
[Epoch 101; Iter    50/  229] train: loss: 0.0876678
[Epoch 101; Iter    80/  229] train: loss: 0.0988991
[Epoch 101; Iter   110/  229] train: loss: 0.1137353
[Epoch 101; Iter   140/  229] train: loss: 0.0759124
[Epoch 101; Iter   170/  229] train: loss: 0.1270541
[Epoch 101; Iter   200/  229] train: loss: 0.0986975
[Epoch 101] ogbg-moltoxcast: 0.666108 val loss: 0.321883
[Epoch 101] ogbg-moltoxcast: 0.637436 test loss: 0.371850
[Epoch 102; Iter     1/  229] train: loss: 0.1127802
[Epoch 102; Iter    31/  229] train: loss: 0.0833964
[Epoch 102; Iter    61/  229] train: loss: 0.0867666
[Epoch 102; Iter    91/  229] train: loss: 0.1040531
[Epoch 102; Iter   121/  229] train: loss: 0.0990440
[Epoch 102; Iter   151/  229] train: loss: 0.1044577
[Epoch 102; Iter   181/  229] train: loss: 0.1226064
[Epoch 102; Iter   211/  229] train: loss: 0.1139907
[Epoch 102] ogbg-moltoxcast: 0.668567 val loss: 0.318066
[Epoch 102] ogbg-moltoxcast: 0.637659 test loss: 0.370423
[Epoch 103; Iter    12/  229] train: loss: 0.0725451
[Epoch 103; Iter    42/  229] train: loss: 0.1195226
[Epoch 103; Iter    72/  229] train: loss: 0.1089371
[Epoch 103; Iter   102/  229] train: loss: 0.1312375
[Epoch 103; Iter   132/  229] train: loss: 0.1057583
[Epoch 103; Iter   162/  229] train: loss: 0.1121698
[Epoch 103; Iter   192/  229] train: loss: 0.1314319
[Epoch 103; Iter   222/  229] train: loss: 0.1108859
[Epoch 103] ogbg-moltoxcast: 0.665922 val loss: 0.323533
[Epoch 103] ogbg-moltoxcast: 0.637845 test loss: 0.377196
[Epoch 104; Iter    23/  229] train: loss: 0.1099246
[Epoch 104; Iter    53/  229] train: loss: 0.1149054
[Epoch 104; Iter    83/  229] train: loss: 0.0931114
[Epoch 104; Iter   113/  229] train: loss: 0.1334300
[Epoch 104; Iter   143/  229] train: loss: 0.0981103
[Epoch 104; Iter   173/  229] train: loss: 0.0977514
[Epoch 104; Iter   203/  229] train: loss: 0.0833006
[Epoch 104] ogbg-moltoxcast: 0.669278 val loss: 0.325098
[Epoch 104] ogbg-moltoxcast: 0.640712 test loss: 0.370859
[Epoch 105; Iter     4/  229] train: loss: 0.1308573
[Epoch 105; Iter    34/  229] train: loss: 0.0962038
[Epoch 105; Iter    64/  229] train: loss: 0.0940395
[Epoch 105; Iter    94/  229] train: loss: 0.1049314
[Epoch 105; Iter   124/  229] train: loss: 0.1349902
[Epoch 105; Iter   154/  229] train: loss: 0.1095513
[Epoch 105; Iter   184/  229] train: loss: 0.1026739
[Epoch 105; Iter   214/  229] train: loss: 0.1084154
[Epoch 105] ogbg-moltoxcast: 0.665043 val loss: 0.324101
[Epoch 105] ogbg-moltoxcast: 0.637104 test loss: 0.370535
[Epoch 106; Iter    15/  229] train: loss: 0.1122041
[Epoch 106; Iter    45/  229] train: loss: 0.0855826
[Epoch 106; Iter    75/  229] train: loss: 0.1244428
[Epoch 106; Iter   105/  229] train: loss: 0.0998438
[Epoch 106; Iter   135/  229] train: loss: 0.1153454
[Epoch 106; Iter   165/  229] train: loss: 0.1286184
[Epoch 106; Iter   195/  229] train: loss: 0.1090044
[Epoch 106; Iter   225/  229] train: loss: 0.1159437
[Epoch 106] ogbg-moltoxcast: 0.666166 val loss: 0.325782
[Epoch 106] ogbg-moltoxcast: 0.638006 test loss: 0.371840
[Epoch 107; Iter    26/  229] train: loss: 0.1228438
[Epoch 107; Iter    56/  229] train: loss: 0.1068026
[Epoch 107; Iter    86/  229] train: loss: 0.0960336
[Epoch 107; Iter   116/  229] train: loss: 0.1055448
[Epoch 107; Iter   146/  229] train: loss: 0.0797216
[Epoch 107; Iter   176/  229] train: loss: 0.1291877
[Epoch 107; Iter   206/  229] train: loss: 0.0864166
[Epoch 107] ogbg-moltoxcast: 0.662314 val loss: 0.321485
[Epoch 92; Iter    11/  229] train: loss: 0.1061471
[Epoch 92; Iter    41/  229] train: loss: 0.0974443
[Epoch 92; Iter    71/  229] train: loss: 0.1255721
[Epoch 92; Iter   101/  229] train: loss: 0.0946968
[Epoch 92; Iter   131/  229] train: loss: 0.0808446
[Epoch 92; Iter   161/  229] train: loss: 0.0786937
[Epoch 92; Iter   191/  229] train: loss: 0.1049613
[Epoch 92; Iter   221/  229] train: loss: 0.1133661
[Epoch 92] ogbg-moltoxcast: 0.648088 val loss: 0.312363
[Epoch 92] ogbg-moltoxcast: 0.640997 test loss: 0.365625
[Epoch 93; Iter    22/  229] train: loss: 0.0802403
[Epoch 93; Iter    52/  229] train: loss: 0.0713110
[Epoch 93; Iter    82/  229] train: loss: 0.1048268
[Epoch 93; Iter   112/  229] train: loss: 0.1074980
[Epoch 93; Iter   142/  229] train: loss: 0.0944563
[Epoch 93; Iter   172/  229] train: loss: 0.1385018
[Epoch 93; Iter   202/  229] train: loss: 0.1053746
[Epoch 93] ogbg-moltoxcast: 0.647800 val loss: 0.311581
[Epoch 93] ogbg-moltoxcast: 0.644022 test loss: 0.362046
[Epoch 94; Iter     3/  229] train: loss: 0.1650993
[Epoch 94; Iter    33/  229] train: loss: 0.1315674
[Epoch 94; Iter    63/  229] train: loss: 0.1299247
[Epoch 94; Iter    93/  229] train: loss: 0.0747944
[Epoch 94; Iter   123/  229] train: loss: 0.0906224
[Epoch 94; Iter   153/  229] train: loss: 0.1024101
[Epoch 94; Iter   183/  229] train: loss: 0.1239211
[Epoch 94; Iter   213/  229] train: loss: 0.1484572
[Epoch 94] ogbg-moltoxcast: 0.648124 val loss: 0.314680
[Epoch 94] ogbg-moltoxcast: 0.637650 test loss: 0.369559
[Epoch 95; Iter    14/  229] train: loss: 0.1022605
[Epoch 95; Iter    44/  229] train: loss: 0.1161005
[Epoch 95; Iter    74/  229] train: loss: 0.1502427
[Epoch 95; Iter   104/  229] train: loss: 0.1119923
[Epoch 95; Iter   134/  229] train: loss: 0.1262673
[Epoch 95; Iter   164/  229] train: loss: 0.0988235
[Epoch 95; Iter   194/  229] train: loss: 0.0719834
[Epoch 95; Iter   224/  229] train: loss: 0.0969279
[Epoch 95] ogbg-moltoxcast: 0.648388 val loss: 0.310697
[Epoch 95] ogbg-moltoxcast: 0.639971 test loss: 0.363878
[Epoch 96; Iter    25/  229] train: loss: 0.1184606
[Epoch 96; Iter    55/  229] train: loss: 0.0635086
[Epoch 96; Iter    85/  229] train: loss: 0.1129201
[Epoch 96; Iter   115/  229] train: loss: 0.1266121
[Epoch 96; Iter   145/  229] train: loss: 0.1205152
[Epoch 96; Iter   175/  229] train: loss: 0.1296045
[Epoch 96; Iter   205/  229] train: loss: 0.1004921
[Epoch 96] ogbg-moltoxcast: 0.645976 val loss: 0.314544
[Epoch 96] ogbg-moltoxcast: 0.640254 test loss: 0.367981
[Epoch 97; Iter     6/  229] train: loss: 0.1080378
[Epoch 97; Iter    36/  229] train: loss: 0.0850072
[Epoch 97; Iter    66/  229] train: loss: 0.0923532
[Epoch 97; Iter    96/  229] train: loss: 0.0936532
[Epoch 97; Iter   126/  229] train: loss: 0.1192898
[Epoch 97; Iter   156/  229] train: loss: 0.1011834
[Epoch 97; Iter   186/  229] train: loss: 0.0812091
[Epoch 97; Iter   216/  229] train: loss: 0.1096255
[Epoch 97] ogbg-moltoxcast: 0.647890 val loss: 0.318361
[Epoch 97] ogbg-moltoxcast: 0.643729 test loss: 0.369345
[Epoch 98; Iter    17/  229] train: loss: 0.1203936
[Epoch 98; Iter    47/  229] train: loss: 0.1076416
[Epoch 98; Iter    77/  229] train: loss: 0.0921863
[Epoch 98; Iter   107/  229] train: loss: 0.0901902
[Epoch 98; Iter   137/  229] train: loss: 0.1009742
[Epoch 98; Iter   167/  229] train: loss: 0.1272908
[Epoch 98; Iter   197/  229] train: loss: 0.1372305
[Epoch 98; Iter   227/  229] train: loss: 0.1081058
[Epoch 98] ogbg-moltoxcast: 0.648030 val loss: 0.314990
[Epoch 98] ogbg-moltoxcast: 0.638601 test loss: 0.369339
[Epoch 99; Iter    28/  229] train: loss: 0.1212398
[Epoch 99; Iter    58/  229] train: loss: 0.1246488
[Epoch 99; Iter    88/  229] train: loss: 0.1250963
[Epoch 99; Iter   118/  229] train: loss: 0.1261271
[Epoch 99; Iter   148/  229] train: loss: 0.1357193
[Epoch 99; Iter   178/  229] train: loss: 0.1545556
[Epoch 99; Iter   208/  229] train: loss: 0.0532123
[Epoch 99] ogbg-moltoxcast: 0.639429 val loss: 0.308832
[Epoch 99] ogbg-moltoxcast: 0.640169 test loss: 0.357988
[Epoch 100; Iter     9/  229] train: loss: 0.0838249
[Epoch 100; Iter    39/  229] train: loss: 0.1065806
[Epoch 100; Iter    69/  229] train: loss: 0.0898947
[Epoch 100; Iter    99/  229] train: loss: 0.1003161
[Epoch 100; Iter   129/  229] train: loss: 0.1007026
[Epoch 100; Iter   159/  229] train: loss: 0.0889688
[Epoch 100; Iter   189/  229] train: loss: 0.1030235
[Epoch 100; Iter   219/  229] train: loss: 0.1013415
[Epoch 100] ogbg-moltoxcast: 0.644150 val loss: 0.316511
[Epoch 100] ogbg-moltoxcast: 0.642516 test loss: 0.366242
[Epoch 101; Iter    20/  229] train: loss: 0.1383419
[Epoch 101; Iter    50/  229] train: loss: 0.1066088
[Epoch 101; Iter    80/  229] train: loss: 0.0885366
[Epoch 101; Iter   110/  229] train: loss: 0.1085520
[Epoch 101; Iter   140/  229] train: loss: 0.1149097
[Epoch 101; Iter   170/  229] train: loss: 0.1049896
[Epoch 101; Iter   200/  229] train: loss: 0.1531395
[Epoch 101] ogbg-moltoxcast: 0.640264 val loss: 0.317835
[Epoch 101] ogbg-moltoxcast: 0.636501 test loss: 0.370466
[Epoch 102; Iter     1/  229] train: loss: 0.0913145
[Epoch 102; Iter    31/  229] train: loss: 0.1087196
[Epoch 102; Iter    61/  229] train: loss: 0.1571298
[Epoch 102; Iter    91/  229] train: loss: 0.1349786
[Epoch 102; Iter   121/  229] train: loss: 0.1153203
[Epoch 102; Iter   151/  229] train: loss: 0.1015317
[Epoch 102; Iter   181/  229] train: loss: 0.1429254
[Epoch 102; Iter   211/  229] train: loss: 0.1054723
[Epoch 102] ogbg-moltoxcast: 0.644149 val loss: 0.321473
[Epoch 102] ogbg-moltoxcast: 0.640277 test loss: 0.380300
[Epoch 103; Iter    12/  229] train: loss: 0.0944401
[Epoch 103; Iter    42/  229] train: loss: 0.1120767
[Epoch 103; Iter    72/  229] train: loss: 0.0909505
[Epoch 103; Iter   102/  229] train: loss: 0.1435125
[Epoch 103; Iter   132/  229] train: loss: 0.1328007
[Epoch 103; Iter   162/  229] train: loss: 0.0606760
[Epoch 103; Iter   192/  229] train: loss: 0.1123030
[Epoch 103; Iter   222/  229] train: loss: 0.1276037
[Epoch 103] ogbg-moltoxcast: 0.637463 val loss: 0.319311
[Epoch 103] ogbg-moltoxcast: 0.638919 test loss: 0.369928
[Epoch 104; Iter    23/  229] train: loss: 0.1140109
[Epoch 104; Iter    53/  229] train: loss: 0.0742352
[Epoch 104; Iter    83/  229] train: loss: 0.0973984
[Epoch 104; Iter   113/  229] train: loss: 0.1467301
[Epoch 104; Iter   143/  229] train: loss: 0.1334730
[Epoch 104; Iter   173/  229] train: loss: 0.1105355
[Epoch 104; Iter   203/  229] train: loss: 0.1029389
[Epoch 104] ogbg-moltoxcast: 0.645693 val loss: 0.315352
[Epoch 104] ogbg-moltoxcast: 0.640801 test loss: 0.368480
[Epoch 105; Iter     4/  229] train: loss: 0.0981094
[Epoch 105; Iter    34/  229] train: loss: 0.1030232
[Epoch 105; Iter    64/  229] train: loss: 0.1002896
[Epoch 105; Iter    94/  229] train: loss: 0.1037678
[Epoch 105; Iter   124/  229] train: loss: 0.1302265
[Epoch 105; Iter   154/  229] train: loss: 0.1002168
[Epoch 105; Iter   184/  229] train: loss: 0.0960130
[Epoch 105; Iter   214/  229] train: loss: 0.1252097
[Epoch 105] ogbg-moltoxcast: 0.640285 val loss: 0.315635
[Epoch 105] ogbg-moltoxcast: 0.635751 test loss: 0.369081
[Epoch 106; Iter    15/  229] train: loss: 0.0962944
[Epoch 106; Iter    45/  229] train: loss: 0.0880459
[Epoch 106; Iter    75/  229] train: loss: 0.1342068
[Epoch 106; Iter   105/  229] train: loss: 0.1245805
[Epoch 106; Iter   135/  229] train: loss: 0.1067558
[Epoch 106; Iter   165/  229] train: loss: 0.1258953
[Epoch 106; Iter   195/  229] train: loss: 0.1262246
[Epoch 106; Iter   225/  229] train: loss: 0.1179998
[Epoch 106] ogbg-moltoxcast: 0.644605 val loss: 0.321918
[Epoch 106] ogbg-moltoxcast: 0.641629 test loss: 0.373933
[Epoch 107; Iter    26/  229] train: loss: 0.0916543
[Epoch 107; Iter    56/  229] train: loss: 0.1068729
[Epoch 107; Iter    86/  229] train: loss: 0.0996098
[Epoch 107; Iter   116/  229] train: loss: 0.1057328
[Epoch 107; Iter   146/  229] train: loss: 0.0886137
[Epoch 107; Iter   176/  229] train: loss: 0.1101920
[Epoch 107; Iter   206/  229] train: loss: 0.1493073
[Epoch 107] ogbg-moltoxcast: 0.644956 val loss: 0.318052
[Epoch 92; Iter    11/  229] train: loss: 0.1221488
[Epoch 92; Iter    41/  229] train: loss: 0.1436940
[Epoch 92; Iter    71/  229] train: loss: 0.0899037
[Epoch 92; Iter   101/  229] train: loss: 0.1326269
[Epoch 92; Iter   131/  229] train: loss: 0.1047328
[Epoch 92; Iter   161/  229] train: loss: 0.1101413
[Epoch 92; Iter   191/  229] train: loss: 0.0985289
[Epoch 92; Iter   221/  229] train: loss: 0.1158651
[Epoch 92] ogbg-moltoxcast: 0.662644 val loss: 0.315773
[Epoch 92] ogbg-moltoxcast: 0.635587 test loss: 0.372334
[Epoch 93; Iter    22/  229] train: loss: 0.1183241
[Epoch 93; Iter    52/  229] train: loss: 0.1073974
[Epoch 93; Iter    82/  229] train: loss: 0.0728491
[Epoch 93; Iter   112/  229] train: loss: 0.1154604
[Epoch 93; Iter   142/  229] train: loss: 0.1343038
[Epoch 93; Iter   172/  229] train: loss: 0.1007957
[Epoch 93; Iter   202/  229] train: loss: 0.0981191
[Epoch 93] ogbg-moltoxcast: 0.673588 val loss: 0.314133
[Epoch 93] ogbg-moltoxcast: 0.640517 test loss: 0.367717
[Epoch 94; Iter     3/  229] train: loss: 0.1074701
[Epoch 94; Iter    33/  229] train: loss: 0.1210622
[Epoch 94; Iter    63/  229] train: loss: 0.0929161
[Epoch 94; Iter    93/  229] train: loss: 0.1551308
[Epoch 94; Iter   123/  229] train: loss: 0.1477892
[Epoch 94; Iter   153/  229] train: loss: 0.0724192
[Epoch 94; Iter   183/  229] train: loss: 0.0928307
[Epoch 94; Iter   213/  229] train: loss: 0.1125137
[Epoch 94] ogbg-moltoxcast: 0.669078 val loss: 0.315859
[Epoch 94] ogbg-moltoxcast: 0.639003 test loss: 0.368625
[Epoch 95; Iter    14/  229] train: loss: 0.1312760
[Epoch 95; Iter    44/  229] train: loss: 0.1152709
[Epoch 95; Iter    74/  229] train: loss: 0.1145251
[Epoch 95; Iter   104/  229] train: loss: 0.1003337
[Epoch 95; Iter   134/  229] train: loss: 0.0795179
[Epoch 95; Iter   164/  229] train: loss: 0.1399148
[Epoch 95; Iter   194/  229] train: loss: 0.1167011
[Epoch 95; Iter   224/  229] train: loss: 0.1130053
[Epoch 95] ogbg-moltoxcast: 0.668336 val loss: 0.313985
[Epoch 95] ogbg-moltoxcast: 0.639318 test loss: 0.365191
[Epoch 96; Iter    25/  229] train: loss: 0.1242763
[Epoch 96; Iter    55/  229] train: loss: 0.0992300
[Epoch 96; Iter    85/  229] train: loss: 0.1144609
[Epoch 96; Iter   115/  229] train: loss: 0.0847880
[Epoch 96; Iter   145/  229] train: loss: 0.1181876
[Epoch 96; Iter   175/  229] train: loss: 0.1076330
[Epoch 96; Iter   205/  229] train: loss: 0.1166803
[Epoch 96] ogbg-moltoxcast: 0.666715 val loss: 0.329162
[Epoch 96] ogbg-moltoxcast: 0.638217 test loss: 0.369395
[Epoch 97; Iter     6/  229] train: loss: 0.0649210
[Epoch 97; Iter    36/  229] train: loss: 0.1306908
[Epoch 97; Iter    66/  229] train: loss: 0.0762206
[Epoch 97; Iter    96/  229] train: loss: 0.1737450
[Epoch 97; Iter   126/  229] train: loss: 0.0840048
[Epoch 97; Iter   156/  229] train: loss: 0.0894727
[Epoch 97; Iter   186/  229] train: loss: 0.1169686
[Epoch 97; Iter   216/  229] train: loss: 0.0930018
[Epoch 97] ogbg-moltoxcast: 0.669695 val loss: 0.327041
[Epoch 97] ogbg-moltoxcast: 0.638962 test loss: 0.374634
[Epoch 98; Iter    17/  229] train: loss: 0.1435897
[Epoch 98; Iter    47/  229] train: loss: 0.1207333
[Epoch 98; Iter    77/  229] train: loss: 0.1402027
[Epoch 98; Iter   107/  229] train: loss: 0.1130796
[Epoch 98; Iter   137/  229] train: loss: 0.0971016
[Epoch 98; Iter   167/  229] train: loss: 0.0686181
[Epoch 98; Iter   197/  229] train: loss: 0.1083519
[Epoch 98; Iter   227/  229] train: loss: 0.1444133
[Epoch 98] ogbg-moltoxcast: 0.667142 val loss: 0.323961
[Epoch 98] ogbg-moltoxcast: 0.635465 test loss: 0.366649
[Epoch 99; Iter    28/  229] train: loss: 0.1349815
[Epoch 99; Iter    58/  229] train: loss: 0.0775440
[Epoch 99; Iter    88/  229] train: loss: 0.1144485
[Epoch 99; Iter   118/  229] train: loss: 0.1405169
[Epoch 99; Iter   148/  229] train: loss: 0.1356877
[Epoch 99; Iter   178/  229] train: loss: 0.1173187
[Epoch 99; Iter   208/  229] train: loss: 0.1284442
[Epoch 99] ogbg-moltoxcast: 0.668590 val loss: 0.328806
[Epoch 99] ogbg-moltoxcast: 0.638601 test loss: 0.368464
[Epoch 100; Iter     9/  229] train: loss: 0.0866009
[Epoch 100; Iter    39/  229] train: loss: 0.1306929
[Epoch 100; Iter    69/  229] train: loss: 0.1138723
[Epoch 100; Iter    99/  229] train: loss: 0.1060774
[Epoch 100; Iter   129/  229] train: loss: 0.1432912
[Epoch 100; Iter   159/  229] train: loss: 0.1148911
[Epoch 100; Iter   189/  229] train: loss: 0.1236384
[Epoch 100; Iter   219/  229] train: loss: 0.1873087
[Epoch 100] ogbg-moltoxcast: 0.668602 val loss: 0.328196
[Epoch 100] ogbg-moltoxcast: 0.638507 test loss: 0.376638
[Epoch 101; Iter    20/  229] train: loss: 0.1093049
[Epoch 101; Iter    50/  229] train: loss: 0.1197218
[Epoch 101; Iter    80/  229] train: loss: 0.0939326
[Epoch 101; Iter   110/  229] train: loss: 0.1200879
[Epoch 101; Iter   140/  229] train: loss: 0.1250147
[Epoch 101; Iter   170/  229] train: loss: 0.0936584
[Epoch 101; Iter   200/  229] train: loss: 0.1069125
[Epoch 101] ogbg-moltoxcast: 0.667079 val loss: 0.320746
[Epoch 101] ogbg-moltoxcast: 0.637503 test loss: 0.372440
[Epoch 102; Iter     1/  229] train: loss: 0.1208165
[Epoch 102; Iter    31/  229] train: loss: 0.0930089
[Epoch 102; Iter    61/  229] train: loss: 0.1371257
[Epoch 102; Iter    91/  229] train: loss: 0.1093936
[Epoch 102; Iter   121/  229] train: loss: 0.1037227
[Epoch 102; Iter   151/  229] train: loss: 0.0994865
[Epoch 102; Iter   181/  229] train: loss: 0.0945670
[Epoch 102; Iter   211/  229] train: loss: 0.1347227
[Epoch 102] ogbg-moltoxcast: 0.665834 val loss: 0.329378
[Epoch 102] ogbg-moltoxcast: 0.638170 test loss: 0.378094
[Epoch 103; Iter    12/  229] train: loss: 0.1069766
[Epoch 103; Iter    42/  229] train: loss: 0.1132279
[Epoch 103; Iter    72/  229] train: loss: 0.1132473
[Epoch 103; Iter   102/  229] train: loss: 0.1142707
[Epoch 103; Iter   132/  229] train: loss: 0.1067573
[Epoch 103; Iter   162/  229] train: loss: 0.1499782
[Epoch 103; Iter   192/  229] train: loss: 0.1068145
[Epoch 103; Iter   222/  229] train: loss: 0.1144141
[Epoch 103] ogbg-moltoxcast: 0.668697 val loss: 0.328917
[Epoch 103] ogbg-moltoxcast: 0.639660 test loss: 0.375393
[Epoch 104; Iter    23/  229] train: loss: 0.1045648
[Epoch 104; Iter    53/  229] train: loss: 0.0970562
[Epoch 104; Iter    83/  229] train: loss: 0.1109228
[Epoch 104; Iter   113/  229] train: loss: 0.0983508
[Epoch 104; Iter   143/  229] train: loss: 0.0842310
[Epoch 104; Iter   173/  229] train: loss: 0.1012630
[Epoch 104; Iter   203/  229] train: loss: 0.1242788
[Epoch 104] ogbg-moltoxcast: 0.672418 val loss: 0.330878
[Epoch 104] ogbg-moltoxcast: 0.637563 test loss: 0.373447
[Epoch 105; Iter     4/  229] train: loss: 0.1070701
[Epoch 105; Iter    34/  229] train: loss: 0.0912502
[Epoch 105; Iter    64/  229] train: loss: 0.0999862
[Epoch 105; Iter    94/  229] train: loss: 0.1151038
[Epoch 105; Iter   124/  229] train: loss: 0.0746273
[Epoch 105; Iter   154/  229] train: loss: 0.0923725
[Epoch 105; Iter   184/  229] train: loss: 0.1185331
[Epoch 105; Iter   214/  229] train: loss: 0.1246849
[Epoch 105] ogbg-moltoxcast: 0.663726 val loss: 0.333480
[Epoch 105] ogbg-moltoxcast: 0.636631 test loss: 0.376990
[Epoch 106; Iter    15/  229] train: loss: 0.0766510
[Epoch 106; Iter    45/  229] train: loss: 0.0818156
[Epoch 106; Iter    75/  229] train: loss: 0.0843061
[Epoch 106; Iter   105/  229] train: loss: 0.0961831
[Epoch 106; Iter   135/  229] train: loss: 0.1055993
[Epoch 106; Iter   165/  229] train: loss: 0.0965910
[Epoch 106; Iter   195/  229] train: loss: 0.1648459
[Epoch 106; Iter   225/  229] train: loss: 0.1404735
[Epoch 106] ogbg-moltoxcast: 0.670344 val loss: 0.324588
[Epoch 106] ogbg-moltoxcast: 0.636081 test loss: 0.376056
[Epoch 107; Iter    26/  229] train: loss: 0.0898439
[Epoch 107; Iter    56/  229] train: loss: 0.1142661
[Epoch 107; Iter    86/  229] train: loss: 0.1121857
[Epoch 107; Iter   116/  229] train: loss: 0.1284748
[Epoch 107; Iter   146/  229] train: loss: 0.1047683
[Epoch 107; Iter   176/  229] train: loss: 0.1396750
[Epoch 107; Iter   206/  229] train: loss: 0.1194891
[Epoch 107] ogbg-moltoxcast: 0.670537 val loss: 0.327876
[Epoch 76; Iter    15/  229] train: loss: 0.1118852
[Epoch 76; Iter    45/  229] train: loss: 0.1271188
[Epoch 76; Iter    75/  229] train: loss: 0.1357581
[Epoch 76; Iter   105/  229] train: loss: 0.0927877
[Epoch 76; Iter   135/  229] train: loss: 0.1792913
[Epoch 76; Iter   165/  229] train: loss: 0.1007014
[Epoch 76; Iter   195/  229] train: loss: 0.1184313
[Epoch 76; Iter   225/  229] train: loss: 0.1023809
[Epoch 76] ogbg-moltoxcast: 0.702961 val loss: 0.272379
[Epoch 76] ogbg-moltoxcast: 0.652260 test loss: 0.643793
[Epoch 77; Iter    26/  229] train: loss: 0.1426074
[Epoch 77; Iter    56/  229] train: loss: 0.1020672
[Epoch 77; Iter    86/  229] train: loss: 0.1977137
[Epoch 77; Iter   116/  229] train: loss: 0.1594800
[Epoch 77; Iter   146/  229] train: loss: 0.1357716
[Epoch 77; Iter   176/  229] train: loss: 0.1487202
[Epoch 77; Iter   206/  229] train: loss: 0.1577878
[Epoch 77] ogbg-moltoxcast: 0.702475 val loss: 0.267800
[Epoch 77] ogbg-moltoxcast: 0.655645 test loss: 0.355037
[Epoch 78; Iter     7/  229] train: loss: 0.1303145
[Epoch 78; Iter    37/  229] train: loss: 0.1209770
[Epoch 78; Iter    67/  229] train: loss: 0.1224688
[Epoch 78; Iter    97/  229] train: loss: 0.0932851
[Epoch 78; Iter   127/  229] train: loss: 0.1224918
[Epoch 78; Iter   157/  229] train: loss: 0.1139715
[Epoch 78; Iter   187/  229] train: loss: 0.1591884
[Epoch 78; Iter   217/  229] train: loss: 0.1476395
[Epoch 78] ogbg-moltoxcast: 0.699381 val loss: 0.271619
[Epoch 78] ogbg-moltoxcast: 0.649827 test loss: 0.428789
[Epoch 79; Iter    18/  229] train: loss: 0.1203049
[Epoch 79; Iter    48/  229] train: loss: 0.1330837
[Epoch 79; Iter    78/  229] train: loss: 0.1583391
[Epoch 79; Iter   108/  229] train: loss: 0.1620776
[Epoch 79; Iter   138/  229] train: loss: 0.1729651
[Epoch 79; Iter   168/  229] train: loss: 0.1588737
[Epoch 79; Iter   198/  229] train: loss: 0.1398601
[Epoch 79; Iter   228/  229] train: loss: 0.1372934
[Epoch 79] ogbg-moltoxcast: 0.698355 val loss: 0.268817
[Epoch 79] ogbg-moltoxcast: 0.655941 test loss: 0.586907
[Epoch 80; Iter    29/  229] train: loss: 0.1412157
[Epoch 80; Iter    59/  229] train: loss: 0.1346979
[Epoch 80; Iter    89/  229] train: loss: 0.1522589
[Epoch 80; Iter   119/  229] train: loss: 0.1205814
[Epoch 80; Iter   149/  229] train: loss: 0.1336537
[Epoch 80; Iter   179/  229] train: loss: 0.1459859
[Epoch 80; Iter   209/  229] train: loss: 0.1426712
[Epoch 80] ogbg-moltoxcast: 0.700311 val loss: 0.272236
[Epoch 80] ogbg-moltoxcast: 0.656923 test loss: 0.824631
[Epoch 81; Iter    10/  229] train: loss: 0.0995166
[Epoch 81; Iter    40/  229] train: loss: 0.1433766
[Epoch 81; Iter    70/  229] train: loss: 0.1419362
[Epoch 81; Iter   100/  229] train: loss: 0.0773886
[Epoch 81; Iter   130/  229] train: loss: 0.0926350
[Epoch 81; Iter   160/  229] train: loss: 0.1498210
[Epoch 81; Iter   190/  229] train: loss: 0.1322970
[Epoch 81; Iter   220/  229] train: loss: 0.1318002
[Epoch 81] ogbg-moltoxcast: 0.701890 val loss: 0.265256
[Epoch 81] ogbg-moltoxcast: 0.659241 test loss: 0.343017
[Epoch 82; Iter    21/  229] train: loss: 0.1455306
[Epoch 82; Iter    51/  229] train: loss: 0.1393759
[Epoch 82; Iter    81/  229] train: loss: 0.1035631
[Epoch 82; Iter   111/  229] train: loss: 0.0993392
[Epoch 82; Iter   141/  229] train: loss: 0.1430258
[Epoch 82; Iter   171/  229] train: loss: 0.1129306
[Epoch 82; Iter   201/  229] train: loss: 0.1448172
[Epoch 82] ogbg-moltoxcast: 0.706392 val loss: 0.267990
[Epoch 82] ogbg-moltoxcast: 0.665486 test loss: 0.334314
[Epoch 83; Iter     2/  229] train: loss: 0.1143824
[Epoch 83; Iter    32/  229] train: loss: 0.1176393
[Epoch 83; Iter    62/  229] train: loss: 0.0903726
[Epoch 83; Iter    92/  229] train: loss: 0.1576170
[Epoch 83; Iter   122/  229] train: loss: 0.1176828
[Epoch 83; Iter   152/  229] train: loss: 0.1556148
[Epoch 83; Iter   182/  229] train: loss: 0.1636814
[Epoch 83; Iter   212/  229] train: loss: 0.1232413
[Epoch 83] ogbg-moltoxcast: 0.699658 val loss: 0.268966
[Epoch 83] ogbg-moltoxcast: 0.665240 test loss: 0.333814
[Epoch 84; Iter    13/  229] train: loss: 0.1430044
[Epoch 84; Iter    43/  229] train: loss: 0.1257149
[Epoch 84; Iter    73/  229] train: loss: 0.1507265
[Epoch 84; Iter   103/  229] train: loss: 0.1081243
[Epoch 84; Iter   133/  229] train: loss: 0.1359213
[Epoch 84; Iter   163/  229] train: loss: 0.0910617
[Epoch 84; Iter   193/  229] train: loss: 0.1372401
[Epoch 84; Iter   223/  229] train: loss: 0.1058311
[Epoch 84] ogbg-moltoxcast: 0.698032 val loss: 0.276811
[Epoch 84] ogbg-moltoxcast: 0.651607 test loss: 0.349245
[Epoch 85; Iter    24/  229] train: loss: 0.1207024
[Epoch 85; Iter    54/  229] train: loss: 0.1069610
[Epoch 85; Iter    84/  229] train: loss: 0.1093680
[Epoch 85; Iter   114/  229] train: loss: 0.0983058
[Epoch 85; Iter   144/  229] train: loss: 0.1359516
[Epoch 85; Iter   174/  229] train: loss: 0.1421224
[Epoch 85; Iter   204/  229] train: loss: 0.1481471
[Epoch 85] ogbg-moltoxcast: 0.699846 val loss: 0.271144
[Epoch 85] ogbg-moltoxcast: 0.663230 test loss: 0.334278
[Epoch 86; Iter     5/  229] train: loss: 0.1755453
[Epoch 86; Iter    35/  229] train: loss: 0.1541865
[Epoch 86; Iter    65/  229] train: loss: 0.1252592
[Epoch 86; Iter    95/  229] train: loss: 0.1510932
[Epoch 86; Iter   125/  229] train: loss: 0.1278473
[Epoch 86; Iter   155/  229] train: loss: 0.1211921
[Epoch 86; Iter   185/  229] train: loss: 0.1354544
[Epoch 86; Iter   215/  229] train: loss: 0.1418975
[Epoch 86] ogbg-moltoxcast: 0.700355 val loss: 0.271738
[Epoch 86] ogbg-moltoxcast: 0.664949 test loss: 0.364220
[Epoch 87; Iter    16/  229] train: loss: 0.1171171
[Epoch 87; Iter    46/  229] train: loss: 0.1156031
[Epoch 87; Iter    76/  229] train: loss: 0.1085448
[Epoch 87; Iter   106/  229] train: loss: 0.1160100
[Epoch 87; Iter   136/  229] train: loss: 0.1269710
[Epoch 87; Iter   166/  229] train: loss: 0.1375933
[Epoch 87; Iter   196/  229] train: loss: 0.1378732
[Epoch 87; Iter   226/  229] train: loss: 0.1250590
[Epoch 87] ogbg-moltoxcast: 0.698760 val loss: 0.274528
[Epoch 87] ogbg-moltoxcast: 0.662861 test loss: 0.339643
[Epoch 88; Iter    27/  229] train: loss: 0.1809412
[Epoch 88; Iter    57/  229] train: loss: 0.1094280
[Epoch 88; Iter    87/  229] train: loss: 0.1118567
[Epoch 88; Iter   117/  229] train: loss: 0.1246099
[Epoch 88; Iter   147/  229] train: loss: 0.1055875
[Epoch 88; Iter   177/  229] train: loss: 0.1299812
[Epoch 88; Iter   207/  229] train: loss: 0.1273268
[Epoch 88] ogbg-moltoxcast: 0.695356 val loss: 0.274094
[Epoch 88] ogbg-moltoxcast: 0.661018 test loss: 0.337575
[Epoch 89; Iter     8/  229] train: loss: 0.1125461
[Epoch 89; Iter    38/  229] train: loss: 0.1066835
[Epoch 89; Iter    68/  229] train: loss: 0.1394695
[Epoch 89; Iter    98/  229] train: loss: 0.1011439
[Epoch 89; Iter   128/  229] train: loss: 0.1211206
[Epoch 89; Iter   158/  229] train: loss: 0.1247365
[Epoch 89; Iter   188/  229] train: loss: 0.1156010
[Epoch 89; Iter   218/  229] train: loss: 0.0975586
[Epoch 89] ogbg-moltoxcast: 0.698281 val loss: 0.278393
[Epoch 89] ogbg-moltoxcast: 0.662433 test loss: 0.342477
[Epoch 90; Iter    19/  229] train: loss: 0.1182172
[Epoch 90; Iter    49/  229] train: loss: 0.1574136
[Epoch 90; Iter    79/  229] train: loss: 0.1500582
[Epoch 90; Iter   109/  229] train: loss: 0.1684411
[Epoch 90; Iter   139/  229] train: loss: 0.1462765
[Epoch 90; Iter   169/  229] train: loss: 0.1308855
[Epoch 90; Iter   199/  229] train: loss: 0.0887470
[Epoch 90; Iter   229/  229] train: loss: 0.1217314
[Epoch 90] ogbg-moltoxcast: 0.694647 val loss: 0.271741
[Epoch 90] ogbg-moltoxcast: 0.662456 test loss: 0.334497
[Epoch 91; Iter    30/  229] train: loss: 0.1326642
[Epoch 91; Iter    60/  229] train: loss: 0.0973978
[Epoch 91; Iter    90/  229] train: loss: 0.1232337
[Epoch 91; Iter   120/  229] train: loss: 0.1038244
[Epoch 91; Iter   150/  229] train: loss: 0.1284190
[Epoch 91; Iter   180/  229] train: loss: 0.1291274
[Epoch 91; Iter   210/  229] train: loss: 0.1404429
[Epoch 91] ogbg-moltoxcast: 0.698050 val loss: 0.270471
[Epoch 91] ogbg-moltoxcast: 0.661062 test loss: 0.336717
[Epoch 92; Iter    11/  229] train: loss: 0.1147366
[Epoch 92; Iter    41/  229] train: loss: 0.1008351
[Epoch 92; Iter    71/  229] train: loss: 0.1232875
[Epoch 92; Iter   101/  229] train: loss: 0.0972947
[Epoch 92; Iter   131/  229] train: loss: 0.0866320
[Epoch 92; Iter   161/  229] train: loss: 0.0740172
[Epoch 92; Iter   191/  229] train: loss: 0.1054924
[Epoch 92; Iter   221/  229] train: loss: 0.1177898
[Epoch 92] ogbg-moltoxcast: 0.631615 val loss: 0.356189
[Epoch 92] ogbg-moltoxcast: 0.623381 test loss: 0.409436
[Epoch 93; Iter    22/  229] train: loss: 0.0805720
[Epoch 93; Iter    52/  229] train: loss: 0.0695541
[Epoch 93; Iter    82/  229] train: loss: 0.1053760
[Epoch 93; Iter   112/  229] train: loss: 0.1082771
[Epoch 93; Iter   142/  229] train: loss: 0.1028608
[Epoch 93; Iter   172/  229] train: loss: 0.1410601
[Epoch 93; Iter   202/  229] train: loss: 0.1125854
[Epoch 93] ogbg-moltoxcast: 0.635613 val loss: 0.361090
[Epoch 93] ogbg-moltoxcast: 0.622606 test loss: 0.418270
[Epoch 94; Iter     3/  229] train: loss: 0.1680151
[Epoch 94; Iter    33/  229] train: loss: 0.1388437
[Epoch 94; Iter    63/  229] train: loss: 0.1305570
[Epoch 94; Iter    93/  229] train: loss: 0.0825997
[Epoch 94; Iter   123/  229] train: loss: 0.0916818
[Epoch 94; Iter   153/  229] train: loss: 0.1025340
[Epoch 94; Iter   183/  229] train: loss: 0.1184131
[Epoch 94; Iter   213/  229] train: loss: 0.1633355
[Epoch 94] ogbg-moltoxcast: 0.633227 val loss: 0.361630
[Epoch 94] ogbg-moltoxcast: 0.622918 test loss: 0.412046
[Epoch 95; Iter    14/  229] train: loss: 0.1081536
[Epoch 95; Iter    44/  229] train: loss: 0.1194085
[Epoch 95; Iter    74/  229] train: loss: 0.1611927
[Epoch 95; Iter   104/  229] train: loss: 0.1112886
[Epoch 95; Iter   134/  229] train: loss: 0.1334966
[Epoch 95; Iter   164/  229] train: loss: 0.1041625
[Epoch 95; Iter   194/  229] train: loss: 0.0735441
[Epoch 95; Iter   224/  229] train: loss: 0.0935383
[Epoch 95] ogbg-moltoxcast: 0.636423 val loss: 0.363068
[Epoch 95] ogbg-moltoxcast: 0.622088 test loss: 1.022106
[Epoch 96; Iter    25/  229] train: loss: 0.1239201
[Epoch 96; Iter    55/  229] train: loss: 0.0639843
[Epoch 96; Iter    85/  229] train: loss: 0.1171048
[Epoch 96; Iter   115/  229] train: loss: 0.1333368
[Epoch 96; Iter   145/  229] train: loss: 0.1209958
[Epoch 96; Iter   175/  229] train: loss: 0.1307378
[Epoch 96; Iter   205/  229] train: loss: 0.1042010
[Epoch 96] ogbg-moltoxcast: 0.625735 val loss: 0.362742
[Epoch 96] ogbg-moltoxcast: 0.623779 test loss: 0.728652
[Epoch 97; Iter     6/  229] train: loss: 0.1131363
[Epoch 97; Iter    36/  229] train: loss: 0.0932349
[Epoch 97; Iter    66/  229] train: loss: 0.0980908
[Epoch 97; Iter    96/  229] train: loss: 0.0983504
[Epoch 97; Iter   126/  229] train: loss: 0.1241825
[Epoch 97; Iter   156/  229] train: loss: 0.1030728
[Epoch 97; Iter   186/  229] train: loss: 0.0798647
[Epoch 97; Iter   216/  229] train: loss: 0.1166632
[Epoch 97] ogbg-moltoxcast: 0.635275 val loss: 0.374116
[Epoch 97] ogbg-moltoxcast: 0.628355 test loss: 0.469320
[Epoch 98; Iter    17/  229] train: loss: 0.1246874
[Epoch 98; Iter    47/  229] train: loss: 0.1103275
[Epoch 98; Iter    77/  229] train: loss: 0.0876087
[Epoch 98; Iter   107/  229] train: loss: 0.0897335
[Epoch 98; Iter   137/  229] train: loss: 0.1066453
[Epoch 98; Iter   167/  229] train: loss: 0.1330157
[Epoch 98; Iter   197/  229] train: loss: 0.1410063
[Epoch 98; Iter   227/  229] train: loss: 0.1075690
[Epoch 98] ogbg-moltoxcast: 0.626867 val loss: 0.565082
[Epoch 98] ogbg-moltoxcast: 0.626762 test loss: 1.694518
[Epoch 99; Iter    28/  229] train: loss: 0.1259993
[Epoch 99; Iter    58/  229] train: loss: 0.1278837
[Epoch 99; Iter    88/  229] train: loss: 0.1279503
[Epoch 99; Iter   118/  229] train: loss: 0.1276614
[Epoch 99; Iter   148/  229] train: loss: 0.1473973
[Epoch 99; Iter   178/  229] train: loss: 0.1774598
[Epoch 99; Iter   208/  229] train: loss: 0.0539807
[Epoch 99] ogbg-moltoxcast: 0.621838 val loss: 0.447379
[Epoch 99] ogbg-moltoxcast: 0.625033 test loss: 0.424690
[Epoch 100; Iter     9/  229] train: loss: 0.0818512
[Epoch 100; Iter    39/  229] train: loss: 0.1286946
[Epoch 100; Iter    69/  229] train: loss: 0.0939772
[Epoch 100; Iter    99/  229] train: loss: 0.0920701
[Epoch 100; Iter   129/  229] train: loss: 0.1064170
[Epoch 100; Iter   159/  229] train: loss: 0.0903234
[Epoch 100; Iter   189/  229] train: loss: 0.1034678
[Epoch 100; Iter   219/  229] train: loss: 0.1035255
[Epoch 100] ogbg-moltoxcast: 0.628788 val loss: 0.370636
[Epoch 100] ogbg-moltoxcast: 0.626555 test loss: 0.815670
[Epoch 101; Iter    20/  229] train: loss: 0.1329315
[Epoch 101; Iter    50/  229] train: loss: 0.1063116
[Epoch 101; Iter    80/  229] train: loss: 0.0873098
[Epoch 101; Iter   110/  229] train: loss: 0.1081679
[Epoch 101; Iter   140/  229] train: loss: 0.1149969
[Epoch 101; Iter   170/  229] train: loss: 0.1097675
[Epoch 101; Iter   200/  229] train: loss: 0.1575465
[Epoch 101] ogbg-moltoxcast: 0.623793 val loss: 0.485492
[Epoch 101] ogbg-moltoxcast: 0.620819 test loss: 1.475696
[Epoch 102; Iter     1/  229] train: loss: 0.0992088
[Epoch 102; Iter    31/  229] train: loss: 0.1126184
[Epoch 102; Iter    61/  229] train: loss: 0.1592756
[Epoch 102; Iter    91/  229] train: loss: 0.1399148
[Epoch 102; Iter   121/  229] train: loss: 0.1190937
[Epoch 102; Iter   151/  229] train: loss: 0.1018062
[Epoch 102; Iter   181/  229] train: loss: 0.1535935
[Epoch 102; Iter   211/  229] train: loss: 0.1010681
[Epoch 102] ogbg-moltoxcast: 0.626032 val loss: 0.566437
[Epoch 102] ogbg-moltoxcast: 0.624502 test loss: 0.872519
[Epoch 103; Iter    12/  229] train: loss: 0.1024817
[Epoch 103; Iter    42/  229] train: loss: 0.1136400
[Epoch 103; Iter    72/  229] train: loss: 0.0925228
[Epoch 103; Iter   102/  229] train: loss: 0.1521769
[Epoch 103; Iter   132/  229] train: loss: 0.1327269
[Epoch 103; Iter   162/  229] train: loss: 0.0712154
[Epoch 103; Iter   192/  229] train: loss: 0.1070800
[Epoch 103; Iter   222/  229] train: loss: 0.1271070
[Epoch 103] ogbg-moltoxcast: 0.640361 val loss: 0.356298
[Epoch 103] ogbg-moltoxcast: 0.622473 test loss: 0.778951
[Epoch 104; Iter    23/  229] train: loss: 0.1079338
[Epoch 104; Iter    53/  229] train: loss: 0.0756887
[Epoch 104; Iter    83/  229] train: loss: 0.1011647
[Epoch 104; Iter   113/  229] train: loss: 0.1539953
[Epoch 104; Iter   143/  229] train: loss: 0.1350791
[Epoch 104; Iter   173/  229] train: loss: 0.1131817
[Epoch 104; Iter   203/  229] train: loss: 0.1074852
[Epoch 104] ogbg-moltoxcast: 0.635529 val loss: 0.550564
[Epoch 104] ogbg-moltoxcast: 0.624558 test loss: 1.146048
[Epoch 105; Iter     4/  229] train: loss: 0.0992936
[Epoch 105; Iter    34/  229] train: loss: 0.1090657
[Epoch 105; Iter    64/  229] train: loss: 0.1062586
[Epoch 105; Iter    94/  229] train: loss: 0.1007552
[Epoch 105; Iter   124/  229] train: loss: 0.1328880
[Epoch 105; Iter   154/  229] train: loss: 0.0937551
[Epoch 105; Iter   184/  229] train: loss: 0.0966918
[Epoch 105; Iter   214/  229] train: loss: 0.1305575
[Epoch 105] ogbg-moltoxcast: 0.623519 val loss: 0.630018
[Epoch 105] ogbg-moltoxcast: 0.621693 test loss: 1.153452
[Epoch 106; Iter    15/  229] train: loss: 0.1029079
[Epoch 106; Iter    45/  229] train: loss: 0.0920312
[Epoch 106; Iter    75/  229] train: loss: 0.1384065
[Epoch 106; Iter   105/  229] train: loss: 0.1300039
[Epoch 106; Iter   135/  229] train: loss: 0.1100195
[Epoch 106; Iter   165/  229] train: loss: 0.1422526
[Epoch 106; Iter   195/  229] train: loss: 0.1193320
[Epoch 106; Iter   225/  229] train: loss: 0.1230356
[Epoch 106] ogbg-moltoxcast: 0.641093 val loss: 0.362313
[Epoch 106] ogbg-moltoxcast: 0.625903 test loss: 1.022123
[Epoch 107; Iter    26/  229] train: loss: 0.0944977
[Epoch 107; Iter    56/  229] train: loss: 0.1071961
[Epoch 107; Iter    86/  229] train: loss: 0.1000392
[Epoch 107; Iter   116/  229] train: loss: 0.1035534
[Epoch 107; Iter   146/  229] train: loss: 0.0848855
[Epoch 107; Iter   176/  229] train: loss: 0.1071383
[Epoch 107; Iter   206/  229] train: loss: 0.1518965
[Epoch 107] ogbg-moltoxcast: 0.629219 val loss: 0.415097
[Epoch 92; Iter    11/  229] train: loss: 0.1202825
[Epoch 92; Iter    41/  229] train: loss: 0.1361451
[Epoch 92; Iter    71/  229] train: loss: 0.0892534
[Epoch 92; Iter   101/  229] train: loss: 0.1215869
[Epoch 92; Iter   131/  229] train: loss: 0.1063151
[Epoch 92; Iter   161/  229] train: loss: 0.1148960
[Epoch 92; Iter   191/  229] train: loss: 0.1028007
[Epoch 92; Iter   221/  229] train: loss: 0.1107454
[Epoch 92] ogbg-moltoxcast: 0.643840 val loss: 0.327993
[Epoch 92] ogbg-moltoxcast: 0.622112 test loss: 0.378367
[Epoch 93; Iter    22/  229] train: loss: 0.1189444
[Epoch 93; Iter    52/  229] train: loss: 0.1023328
[Epoch 93; Iter    82/  229] train: loss: 0.0720207
[Epoch 93; Iter   112/  229] train: loss: 0.1141865
[Epoch 93; Iter   142/  229] train: loss: 0.1332057
[Epoch 93; Iter   172/  229] train: loss: 0.1039185
[Epoch 93; Iter   202/  229] train: loss: 0.1053631
[Epoch 93] ogbg-moltoxcast: 0.649446 val loss: 0.330965
[Epoch 93] ogbg-moltoxcast: 0.627981 test loss: 0.387702
[Epoch 94; Iter     3/  229] train: loss: 0.0968528
[Epoch 94; Iter    33/  229] train: loss: 0.1150457
[Epoch 94; Iter    63/  229] train: loss: 0.0909551
[Epoch 94; Iter    93/  229] train: loss: 0.1475467
[Epoch 94; Iter   123/  229] train: loss: 0.1417071
[Epoch 94; Iter   153/  229] train: loss: 0.0745304
[Epoch 94; Iter   183/  229] train: loss: 0.0972386
[Epoch 94; Iter   213/  229] train: loss: 0.1066121
[Epoch 94] ogbg-moltoxcast: 0.651955 val loss: 0.327326
[Epoch 94] ogbg-moltoxcast: 0.626287 test loss: 0.381849
[Epoch 95; Iter    14/  229] train: loss: 0.1306777
[Epoch 95; Iter    44/  229] train: loss: 0.1104704
[Epoch 95; Iter    74/  229] train: loss: 0.1061717
[Epoch 95; Iter   104/  229] train: loss: 0.0948298
[Epoch 95; Iter   134/  229] train: loss: 0.0802446
[Epoch 95; Iter   164/  229] train: loss: 0.1410859
[Epoch 95; Iter   194/  229] train: loss: 0.1193604
[Epoch 95; Iter   224/  229] train: loss: 0.1108395
[Epoch 95] ogbg-moltoxcast: 0.651197 val loss: 0.326179
[Epoch 95] ogbg-moltoxcast: 0.625095 test loss: 0.381511
[Epoch 96; Iter    25/  229] train: loss: 0.1240210
[Epoch 96; Iter    55/  229] train: loss: 0.0978775
[Epoch 96; Iter    85/  229] train: loss: 0.1113693
[Epoch 96; Iter   115/  229] train: loss: 0.0832239
[Epoch 96; Iter   145/  229] train: loss: 0.1243827
[Epoch 96; Iter   175/  229] train: loss: 0.1027324
[Epoch 96; Iter   205/  229] train: loss: 0.1039359
[Epoch 96] ogbg-moltoxcast: 0.649083 val loss: 0.330610
[Epoch 96] ogbg-moltoxcast: 0.627479 test loss: 0.384805
[Epoch 97; Iter     6/  229] train: loss: 0.0644897
[Epoch 97; Iter    36/  229] train: loss: 0.1301626
[Epoch 97; Iter    66/  229] train: loss: 0.0782897
[Epoch 97; Iter    96/  229] train: loss: 0.1764542
[Epoch 97; Iter   126/  229] train: loss: 0.0844462
[Epoch 97; Iter   156/  229] train: loss: 0.0953658
[Epoch 97; Iter   186/  229] train: loss: 0.1064091
[Epoch 97; Iter   216/  229] train: loss: 0.0893713
[Epoch 97] ogbg-moltoxcast: 0.647814 val loss: 0.332343
[Epoch 97] ogbg-moltoxcast: 0.625263 test loss: 0.388831
[Epoch 98; Iter    17/  229] train: loss: 0.1539422
[Epoch 98; Iter    47/  229] train: loss: 0.1233678
[Epoch 98; Iter    77/  229] train: loss: 0.1394807
[Epoch 98; Iter   107/  229] train: loss: 0.1138452
[Epoch 98; Iter   137/  229] train: loss: 0.0935847
[Epoch 98; Iter   167/  229] train: loss: 0.0655250
[Epoch 98; Iter   197/  229] train: loss: 0.0992914
[Epoch 98; Iter   227/  229] train: loss: 0.1428521
[Epoch 98] ogbg-moltoxcast: 0.646692 val loss: 0.331362
[Epoch 98] ogbg-moltoxcast: 0.625933 test loss: 0.386928
[Epoch 99; Iter    28/  229] train: loss: 0.1341859
[Epoch 99; Iter    58/  229] train: loss: 0.0759891
[Epoch 99; Iter    88/  229] train: loss: 0.1133945
[Epoch 99; Iter   118/  229] train: loss: 0.1400479
[Epoch 99; Iter   148/  229] train: loss: 0.1270419
[Epoch 99; Iter   178/  229] train: loss: 0.1188347
[Epoch 99; Iter   208/  229] train: loss: 0.1260346
[Epoch 99] ogbg-moltoxcast: 0.647139 val loss: 0.335576
[Epoch 99] ogbg-moltoxcast: 0.624904 test loss: 0.394986
[Epoch 100; Iter     9/  229] train: loss: 0.0865944
[Epoch 100; Iter    39/  229] train: loss: 0.1263443
[Epoch 100; Iter    69/  229] train: loss: 0.1177257
[Epoch 100; Iter    99/  229] train: loss: 0.1022052
[Epoch 100; Iter   129/  229] train: loss: 0.1351055
[Epoch 100; Iter   159/  229] train: loss: 0.1241381
[Epoch 100; Iter   189/  229] train: loss: 0.1245029
[Epoch 100; Iter   219/  229] train: loss: 0.1884616
[Epoch 100] ogbg-moltoxcast: 0.650662 val loss: 0.332754
[Epoch 100] ogbg-moltoxcast: 0.627032 test loss: 0.386767
[Epoch 101; Iter    20/  229] train: loss: 0.1187817
[Epoch 101; Iter    50/  229] train: loss: 0.1173984
[Epoch 101; Iter    80/  229] train: loss: 0.0936184
[Epoch 101; Iter   110/  229] train: loss: 0.1248655
[Epoch 101; Iter   140/  229] train: loss: 0.1140507
[Epoch 101; Iter   170/  229] train: loss: 0.0993688
[Epoch 101; Iter   200/  229] train: loss: 0.1046549
[Epoch 101] ogbg-moltoxcast: 0.646961 val loss: 0.334448
[Epoch 101] ogbg-moltoxcast: 0.624185 test loss: 0.392058
[Epoch 102; Iter     1/  229] train: loss: 0.1171896
[Epoch 102; Iter    31/  229] train: loss: 0.0978406
[Epoch 102; Iter    61/  229] train: loss: 0.1324547
[Epoch 102; Iter    91/  229] train: loss: 0.1197092
[Epoch 102; Iter   121/  229] train: loss: 0.1109385
[Epoch 102; Iter   151/  229] train: loss: 0.0996162
[Epoch 102; Iter   181/  229] train: loss: 0.0852942
[Epoch 102; Iter   211/  229] train: loss: 0.1256999
[Epoch 102] ogbg-moltoxcast: 0.646070 val loss: 0.340401
[Epoch 102] ogbg-moltoxcast: 0.619842 test loss: 0.400040
[Epoch 103; Iter    12/  229] train: loss: 0.1070455
[Epoch 103; Iter    42/  229] train: loss: 0.1164692
[Epoch 103; Iter    72/  229] train: loss: 0.1052106
[Epoch 103; Iter   102/  229] train: loss: 0.1168825
[Epoch 103; Iter   132/  229] train: loss: 0.1095700
[Epoch 103; Iter   162/  229] train: loss: 0.1439708
[Epoch 103; Iter   192/  229] train: loss: 0.1072666
[Epoch 103; Iter   222/  229] train: loss: 0.1172892
[Epoch 103] ogbg-moltoxcast: 0.648415 val loss: 0.329598
[Epoch 103] ogbg-moltoxcast: 0.624943 test loss: 0.382650
[Epoch 104; Iter    23/  229] train: loss: 0.1004822
[Epoch 104; Iter    53/  229] train: loss: 0.1021419
[Epoch 104; Iter    83/  229] train: loss: 0.1037458
[Epoch 104; Iter   113/  229] train: loss: 0.0961031
[Epoch 104; Iter   143/  229] train: loss: 0.0880222
[Epoch 104; Iter   173/  229] train: loss: 0.0994604
[Epoch 104; Iter   203/  229] train: loss: 0.1203128
[Epoch 104] ogbg-moltoxcast: 0.647861 val loss: 0.335361
[Epoch 104] ogbg-moltoxcast: 0.625957 test loss: 0.390120
[Epoch 105; Iter     4/  229] train: loss: 0.1033571
[Epoch 105; Iter    34/  229] train: loss: 0.0885671
[Epoch 105; Iter    64/  229] train: loss: 0.1008054
[Epoch 105; Iter    94/  229] train: loss: 0.1128894
[Epoch 105; Iter   124/  229] train: loss: 0.0687732
[Epoch 105; Iter   154/  229] train: loss: 0.0887785
[Epoch 105; Iter   184/  229] train: loss: 0.1172602
[Epoch 105; Iter   214/  229] train: loss: 0.1203542
[Epoch 105] ogbg-moltoxcast: 0.646661 val loss: 0.334270
[Epoch 105] ogbg-moltoxcast: 0.624726 test loss: 0.388885
[Epoch 106; Iter    15/  229] train: loss: 0.0768924
[Epoch 106; Iter    45/  229] train: loss: 0.0793495
[Epoch 106; Iter    75/  229] train: loss: 0.0845702
[Epoch 106; Iter   105/  229] train: loss: 0.0857170
[Epoch 106; Iter   135/  229] train: loss: 0.1050139
[Epoch 106; Iter   165/  229] train: loss: 0.0933492
[Epoch 106; Iter   195/  229] train: loss: 0.1519494
[Epoch 106; Iter   225/  229] train: loss: 0.1398715
[Epoch 106] ogbg-moltoxcast: 0.642165 val loss: 0.334664
[Epoch 106] ogbg-moltoxcast: 0.625665 test loss: 0.389871
[Epoch 107; Iter    26/  229] train: loss: 0.0903200
[Epoch 107; Iter    56/  229] train: loss: 0.1125407
[Epoch 107; Iter    86/  229] train: loss: 0.1080013
[Epoch 107; Iter   116/  229] train: loss: 0.1228503
[Epoch 107; Iter   146/  229] train: loss: 0.1003440
[Epoch 107; Iter   176/  229] train: loss: 0.1387479
[Epoch 107; Iter   206/  229] train: loss: 0.1217958
[Epoch 107] ogbg-moltoxcast: 0.644797 val loss: 0.334755
[Epoch 76; Iter    15/  229] train: loss: 0.1591403
[Epoch 76; Iter    45/  229] train: loss: 0.1221368
[Epoch 76; Iter    75/  229] train: loss: 0.2052324
[Epoch 76; Iter   105/  229] train: loss: 0.1191099
[Epoch 76; Iter   135/  229] train: loss: 0.1021846
[Epoch 76; Iter   165/  229] train: loss: 0.1502329
[Epoch 76; Iter   195/  229] train: loss: 0.0845501
[Epoch 76; Iter   225/  229] train: loss: 0.1228068
[Epoch 76] ogbg-moltoxcast: 0.691042 val loss: 0.274956
[Epoch 76] ogbg-moltoxcast: 0.657686 test loss: 0.344309
[Epoch 77; Iter    26/  229] train: loss: 0.1368767
[Epoch 77; Iter    56/  229] train: loss: 0.1168119
[Epoch 77; Iter    86/  229] train: loss: 0.0972781
[Epoch 77; Iter   116/  229] train: loss: 0.1542259
[Epoch 77; Iter   146/  229] train: loss: 0.1159636
[Epoch 77; Iter   176/  229] train: loss: 0.1300671
[Epoch 77; Iter   206/  229] train: loss: 0.1538050
[Epoch 77] ogbg-moltoxcast: 0.688818 val loss: 0.271530
[Epoch 77] ogbg-moltoxcast: 0.659080 test loss: 0.345856
[Epoch 78; Iter     7/  229] train: loss: 0.1446424
[Epoch 78; Iter    37/  229] train: loss: 0.1393215
[Epoch 78; Iter    67/  229] train: loss: 0.0981677
[Epoch 78; Iter    97/  229] train: loss: 0.1513539
[Epoch 78; Iter   127/  229] train: loss: 0.1302273
[Epoch 78; Iter   157/  229] train: loss: 0.1133083
[Epoch 78; Iter   187/  229] train: loss: 0.1138042
[Epoch 78; Iter   217/  229] train: loss: 0.1150947
[Epoch 78] ogbg-moltoxcast: 0.687063 val loss: 0.279893
[Epoch 78] ogbg-moltoxcast: 0.658457 test loss: 0.346967
[Epoch 79; Iter    18/  229] train: loss: 0.0936840
[Epoch 79; Iter    48/  229] train: loss: 0.1312722
[Epoch 79; Iter    78/  229] train: loss: 0.0976777
[Epoch 79; Iter   108/  229] train: loss: 0.1312663
[Epoch 79; Iter   138/  229] train: loss: 0.1089966
[Epoch 79; Iter   168/  229] train: loss: 0.0845434
[Epoch 79; Iter   198/  229] train: loss: 0.0746638
[Epoch 79; Iter   228/  229] train: loss: 0.1610322
[Epoch 79] ogbg-moltoxcast: 0.683365 val loss: 0.278209
[Epoch 79] ogbg-moltoxcast: 0.651163 test loss: 0.350224
[Epoch 80; Iter    29/  229] train: loss: 0.1423945
[Epoch 80; Iter    59/  229] train: loss: 0.1148654
[Epoch 80; Iter    89/  229] train: loss: 0.1014051
[Epoch 80; Iter   119/  229] train: loss: 0.1428927
[Epoch 80; Iter   149/  229] train: loss: 0.1473071
[Epoch 80; Iter   179/  229] train: loss: 0.2388369
[Epoch 80; Iter   209/  229] train: loss: 0.1291369
[Epoch 80] ogbg-moltoxcast: 0.690647 val loss: 0.276261
[Epoch 80] ogbg-moltoxcast: 0.655594 test loss: 0.346096
[Epoch 81; Iter    10/  229] train: loss: 0.0889898
[Epoch 81; Iter    40/  229] train: loss: 0.1217370
[Epoch 81; Iter    70/  229] train: loss: 0.1546275
[Epoch 81; Iter   100/  229] train: loss: 0.1280941
[Epoch 81; Iter   130/  229] train: loss: 0.1101626
[Epoch 81; Iter   160/  229] train: loss: 0.1487417
[Epoch 81; Iter   190/  229] train: loss: 0.1703202
[Epoch 81; Iter   220/  229] train: loss: 0.0935772
[Epoch 81] ogbg-moltoxcast: 0.687765 val loss: 0.277390
[Epoch 81] ogbg-moltoxcast: 0.662960 test loss: 0.339307
[Epoch 82; Iter    21/  229] train: loss: 0.0695858
[Epoch 82; Iter    51/  229] train: loss: 0.1275556
[Epoch 82; Iter    81/  229] train: loss: 0.1136096
[Epoch 82; Iter   111/  229] train: loss: 0.1040103
[Epoch 82; Iter   141/  229] train: loss: 0.1522497
[Epoch 82; Iter   171/  229] train: loss: 0.1114586
[Epoch 82; Iter   201/  229] train: loss: 0.0929510
[Epoch 82] ogbg-moltoxcast: 0.686893 val loss: 0.280433
[Epoch 82] ogbg-moltoxcast: 0.660246 test loss: 0.344997
[Epoch 83; Iter     2/  229] train: loss: 0.0934188
[Epoch 83; Iter    32/  229] train: loss: 0.1548204
[Epoch 83; Iter    62/  229] train: loss: 0.1603989
[Epoch 83; Iter    92/  229] train: loss: 0.0999783
[Epoch 83; Iter   122/  229] train: loss: 0.1085229
[Epoch 83; Iter   152/  229] train: loss: 0.1014833
[Epoch 83; Iter   182/  229] train: loss: 0.1485527
[Epoch 83; Iter   212/  229] train: loss: 0.0847635
[Epoch 83] ogbg-moltoxcast: 0.681620 val loss: 0.280431
[Epoch 83] ogbg-moltoxcast: 0.655322 test loss: 0.351469
[Epoch 84; Iter    13/  229] train: loss: 0.1904245
[Epoch 84; Iter    43/  229] train: loss: 0.1346700
[Epoch 84; Iter    73/  229] train: loss: 0.1825027
[Epoch 84; Iter   103/  229] train: loss: 0.0987236
[Epoch 84; Iter   133/  229] train: loss: 0.1044594
[Epoch 84; Iter   163/  229] train: loss: 0.0909659
[Epoch 84; Iter   193/  229] train: loss: 0.1544612
[Epoch 84; Iter   223/  229] train: loss: 0.1314057
[Epoch 84] ogbg-moltoxcast: 0.684705 val loss: 0.279256
[Epoch 84] ogbg-moltoxcast: 0.652984 test loss: 0.352239
[Epoch 85; Iter    24/  229] train: loss: 0.0744242
[Epoch 85; Iter    54/  229] train: loss: 0.1285471
[Epoch 85; Iter    84/  229] train: loss: 0.1274362
[Epoch 85; Iter   114/  229] train: loss: 0.0863363
[Epoch 85; Iter   144/  229] train: loss: 0.1067813
[Epoch 85; Iter   174/  229] train: loss: 0.1482307
[Epoch 85; Iter   204/  229] train: loss: 0.1308206
[Epoch 85] ogbg-moltoxcast: 0.687148 val loss: 0.277349
[Epoch 85] ogbg-moltoxcast: 0.654894 test loss: 0.347218
[Epoch 86; Iter     5/  229] train: loss: 0.0952719
[Epoch 86; Iter    35/  229] train: loss: 0.1646080
[Epoch 86; Iter    65/  229] train: loss: 0.1466808
[Epoch 86; Iter    95/  229] train: loss: 0.1471272
[Epoch 86; Iter   125/  229] train: loss: 0.1113929
[Epoch 86; Iter   155/  229] train: loss: 0.1480480
[Epoch 86; Iter   185/  229] train: loss: 0.1738462
[Epoch 86; Iter   215/  229] train: loss: 0.1340940
[Epoch 86] ogbg-moltoxcast: 0.688960 val loss: 0.280751
[Epoch 86] ogbg-moltoxcast: 0.652050 test loss: 0.353020
[Epoch 87; Iter    16/  229] train: loss: 0.1311250
[Epoch 87; Iter    46/  229] train: loss: 0.1455969
[Epoch 87; Iter    76/  229] train: loss: 0.0797048
[Epoch 87; Iter   106/  229] train: loss: 0.0986052
[Epoch 87; Iter   136/  229] train: loss: 0.0997811
[Epoch 87; Iter   166/  229] train: loss: 0.1179620
[Epoch 87; Iter   196/  229] train: loss: 0.1652144
[Epoch 87; Iter   226/  229] train: loss: 0.1424360
[Epoch 87] ogbg-moltoxcast: 0.691305 val loss: 0.279223
[Epoch 87] ogbg-moltoxcast: 0.656510 test loss: 0.350115
[Epoch 88; Iter    27/  229] train: loss: 0.1068683
[Epoch 88; Iter    57/  229] train: loss: 0.0795169
[Epoch 88; Iter    87/  229] train: loss: 0.0996526
[Epoch 88; Iter   117/  229] train: loss: 0.1181063
[Epoch 88; Iter   147/  229] train: loss: 0.1375043
[Epoch 88; Iter   177/  229] train: loss: 0.1006973
[Epoch 88; Iter   207/  229] train: loss: 0.1148057
[Epoch 88] ogbg-moltoxcast: 0.688506 val loss: 0.281701
[Epoch 88] ogbg-moltoxcast: 0.656983 test loss: 0.352474
[Epoch 89; Iter     8/  229] train: loss: 0.1204951
[Epoch 89; Iter    38/  229] train: loss: 0.1368503
[Epoch 89; Iter    68/  229] train: loss: 0.1117419
[Epoch 89; Iter    98/  229] train: loss: 0.1321575
[Epoch 89; Iter   128/  229] train: loss: 0.1678845
[Epoch 89; Iter   158/  229] train: loss: 0.1207215
[Epoch 89; Iter   188/  229] train: loss: 0.0724169
[Epoch 89; Iter   218/  229] train: loss: 0.1256797
[Epoch 89] ogbg-moltoxcast: 0.685162 val loss: 0.279814
[Epoch 89] ogbg-moltoxcast: 0.654407 test loss: 0.352837
[Epoch 90; Iter    19/  229] train: loss: 0.0924297
[Epoch 90; Iter    49/  229] train: loss: 0.1049061
[Epoch 90; Iter    79/  229] train: loss: 0.0873945
[Epoch 90; Iter   109/  229] train: loss: 0.1137536
[Epoch 90; Iter   139/  229] train: loss: 0.1697378
[Epoch 90; Iter   169/  229] train: loss: 0.1522288
[Epoch 90; Iter   199/  229] train: loss: 0.1477569
[Epoch 90; Iter   229/  229] train: loss: 0.1629815
[Epoch 90] ogbg-moltoxcast: 0.688442 val loss: 0.278449
[Epoch 90] ogbg-moltoxcast: 0.656251 test loss: 0.348499
[Epoch 91; Iter    30/  229] train: loss: 0.0935340
[Epoch 91; Iter    60/  229] train: loss: 0.1158818
[Epoch 91; Iter    90/  229] train: loss: 0.1153236
[Epoch 91; Iter   120/  229] train: loss: 0.1288293
[Epoch 91; Iter   150/  229] train: loss: 0.0837887
[Epoch 91; Iter   180/  229] train: loss: 0.1499879
[Epoch 91; Iter   210/  229] train: loss: 0.1431995
[Epoch 91] ogbg-moltoxcast: 0.688043 val loss: 0.279007
[Epoch 91] ogbg-moltoxcast: 0.655024 test loss: 0.347979
[Epoch 76; Iter    15/  229] train: loss: 0.1151571
[Epoch 76; Iter    45/  229] train: loss: 0.1283423
[Epoch 76; Iter    75/  229] train: loss: 0.1417337
[Epoch 76; Iter   105/  229] train: loss: 0.1466343
[Epoch 76; Iter   135/  229] train: loss: 0.1000869
[Epoch 76; Iter   165/  229] train: loss: 0.1331076
[Epoch 76; Iter   195/  229] train: loss: 0.1243510
[Epoch 76; Iter   225/  229] train: loss: 0.1376567
[Epoch 76] ogbg-moltoxcast: 0.683843 val loss: 0.270130
[Epoch 76] ogbg-moltoxcast: 0.654010 test loss: 0.323323
[Epoch 77; Iter    26/  229] train: loss: 0.1265360
[Epoch 77; Iter    56/  229] train: loss: 0.1063200
[Epoch 77; Iter    86/  229] train: loss: 0.1803938
[Epoch 77; Iter   116/  229] train: loss: 0.1287435
[Epoch 77; Iter   146/  229] train: loss: 0.1123881
[Epoch 77; Iter   176/  229] train: loss: 0.1451810
[Epoch 77; Iter   206/  229] train: loss: 0.1393062
[Epoch 77] ogbg-moltoxcast: 0.678777 val loss: 0.273703
[Epoch 77] ogbg-moltoxcast: 0.649364 test loss: 0.328698
[Epoch 78; Iter     7/  229] train: loss: 0.1230371
[Epoch 78; Iter    37/  229] train: loss: 0.1096138
[Epoch 78; Iter    67/  229] train: loss: 0.0947607
[Epoch 78; Iter    97/  229] train: loss: 0.1286956
[Epoch 78; Iter   127/  229] train: loss: 0.1759204
[Epoch 78; Iter   157/  229] train: loss: 0.1084597
[Epoch 78; Iter   187/  229] train: loss: 0.1327952
[Epoch 78; Iter   217/  229] train: loss: 0.1108351
[Epoch 78] ogbg-moltoxcast: 0.677997 val loss: 0.272642
[Epoch 78] ogbg-moltoxcast: 0.650554 test loss: 0.328117
[Epoch 79; Iter    18/  229] train: loss: 0.1812875
[Epoch 79; Iter    48/  229] train: loss: 0.1384533
[Epoch 79; Iter    78/  229] train: loss: 0.1573519
[Epoch 79; Iter   108/  229] train: loss: 0.1452908
[Epoch 79; Iter   138/  229] train: loss: 0.1534475
[Epoch 79; Iter   168/  229] train: loss: 0.1405265
[Epoch 79; Iter   198/  229] train: loss: 0.0922265
[Epoch 79; Iter   228/  229] train: loss: 0.1473809
[Epoch 79] ogbg-moltoxcast: 0.675606 val loss: 0.274693
[Epoch 79] ogbg-moltoxcast: 0.647245 test loss: 0.331184
[Epoch 80; Iter    29/  229] train: loss: 0.1129396
[Epoch 80; Iter    59/  229] train: loss: 0.1119050
[Epoch 80; Iter    89/  229] train: loss: 0.1321395
[Epoch 80; Iter   119/  229] train: loss: 0.1140672
[Epoch 80; Iter   149/  229] train: loss: 0.1251972
[Epoch 80; Iter   179/  229] train: loss: 0.1245987
[Epoch 80; Iter   209/  229] train: loss: 0.1338363
[Epoch 80] ogbg-moltoxcast: 0.680542 val loss: 0.268853
[Epoch 80] ogbg-moltoxcast: 0.652345 test loss: 0.322547
[Epoch 81; Iter    10/  229] train: loss: 0.1279725
[Epoch 81; Iter    40/  229] train: loss: 0.1394478
[Epoch 81; Iter    70/  229] train: loss: 0.1345273
[Epoch 81; Iter   100/  229] train: loss: 0.1400827
[Epoch 81; Iter   130/  229] train: loss: 0.1488638
[Epoch 81; Iter   160/  229] train: loss: 0.1461283
[Epoch 81; Iter   190/  229] train: loss: 0.1368959
[Epoch 81; Iter   220/  229] train: loss: 0.1077044
[Epoch 81] ogbg-moltoxcast: 0.679927 val loss: 0.272395
[Epoch 81] ogbg-moltoxcast: 0.654265 test loss: 0.322861
[Epoch 82; Iter    21/  229] train: loss: 0.0905062
[Epoch 82; Iter    51/  229] train: loss: 0.1303954
[Epoch 82; Iter    81/  229] train: loss: 0.1403043
[Epoch 82; Iter   111/  229] train: loss: 0.1007099
[Epoch 82; Iter   141/  229] train: loss: 0.1024760
[Epoch 82; Iter   171/  229] train: loss: 0.1215543
[Epoch 82; Iter   201/  229] train: loss: 0.1197404
[Epoch 82] ogbg-moltoxcast: 0.676238 val loss: 0.273219
[Epoch 82] ogbg-moltoxcast: 0.649710 test loss: 0.327495
[Epoch 83; Iter     2/  229] train: loss: 0.1782888
[Epoch 83; Iter    32/  229] train: loss: 0.0946526
[Epoch 83; Iter    62/  229] train: loss: 0.1128557
[Epoch 83; Iter    92/  229] train: loss: 0.1360793
[Epoch 83; Iter   122/  229] train: loss: 0.1121998
[Epoch 83; Iter   152/  229] train: loss: 0.1049407
[Epoch 83; Iter   182/  229] train: loss: 0.0870176
[Epoch 83; Iter   212/  229] train: loss: 0.1611674
[Epoch 83] ogbg-moltoxcast: 0.681724 val loss: 0.272158
[Epoch 83] ogbg-moltoxcast: 0.652018 test loss: 0.327460
[Epoch 84; Iter    13/  229] train: loss: 0.1144210
[Epoch 84; Iter    43/  229] train: loss: 0.1148792
[Epoch 84; Iter    73/  229] train: loss: 0.0977819
[Epoch 84; Iter   103/  229] train: loss: 0.1140227
[Epoch 84; Iter   133/  229] train: loss: 0.0770107
[Epoch 84; Iter   163/  229] train: loss: 0.1140648
[Epoch 84; Iter   193/  229] train: loss: 0.1468832
[Epoch 84; Iter   223/  229] train: loss: 0.1064928
[Epoch 84] ogbg-moltoxcast: 0.676825 val loss: 0.276458
[Epoch 84] ogbg-moltoxcast: 0.654831 test loss: 0.325589
[Epoch 85; Iter    24/  229] train: loss: 0.1305324
[Epoch 85; Iter    54/  229] train: loss: 0.1166155
[Epoch 85; Iter    84/  229] train: loss: 0.1170349
[Epoch 85; Iter   114/  229] train: loss: 0.0925986
[Epoch 85; Iter   144/  229] train: loss: 0.1184323
[Epoch 85; Iter   174/  229] train: loss: 0.1693849
[Epoch 85; Iter   204/  229] train: loss: 0.1437136
[Epoch 85] ogbg-moltoxcast: 0.673991 val loss: 0.274568
[Epoch 85] ogbg-moltoxcast: 0.646673 test loss: 0.329811
[Epoch 86; Iter     5/  229] train: loss: 0.1086740
[Epoch 86; Iter    35/  229] train: loss: 0.1331170
[Epoch 86; Iter    65/  229] train: loss: 0.0781709
[Epoch 86; Iter    95/  229] train: loss: 0.1407747
[Epoch 86; Iter   125/  229] train: loss: 0.0833792
[Epoch 86; Iter   155/  229] train: loss: 0.1247793
[Epoch 86; Iter   185/  229] train: loss: 0.1178722
[Epoch 86; Iter   215/  229] train: loss: 0.1529627
[Epoch 86] ogbg-moltoxcast: 0.674177 val loss: 0.274295
[Epoch 86] ogbg-moltoxcast: 0.651588 test loss: 0.329340
[Epoch 87; Iter    16/  229] train: loss: 0.0869194
[Epoch 87; Iter    46/  229] train: loss: 0.1031726
[Epoch 87; Iter    76/  229] train: loss: 0.1340073
[Epoch 87; Iter   106/  229] train: loss: 0.1153333
[Epoch 87; Iter   136/  229] train: loss: 0.1859045
[Epoch 87; Iter   166/  229] train: loss: 0.1116052
[Epoch 87; Iter   196/  229] train: loss: 0.1219653
[Epoch 87; Iter   226/  229] train: loss: 0.0961392
[Epoch 87] ogbg-moltoxcast: 0.680464 val loss: 0.275305
[Epoch 87] ogbg-moltoxcast: 0.646318 test loss: 0.333262
[Epoch 88; Iter    27/  229] train: loss: 0.1316994
[Epoch 88; Iter    57/  229] train: loss: 0.1189736
[Epoch 88; Iter    87/  229] train: loss: 0.1196243
[Epoch 88; Iter   117/  229] train: loss: 0.1503918
[Epoch 88; Iter   147/  229] train: loss: 0.1257997
[Epoch 88; Iter   177/  229] train: loss: 0.1305791
[Epoch 88; Iter   207/  229] train: loss: 0.0952406
[Epoch 88] ogbg-moltoxcast: 0.680733 val loss: 0.272137
[Epoch 88] ogbg-moltoxcast: 0.651164 test loss: 0.326785
[Epoch 89; Iter     8/  229] train: loss: 0.1288529
[Epoch 89; Iter    38/  229] train: loss: 0.1464738
[Epoch 89; Iter    68/  229] train: loss: 0.1509837
[Epoch 89; Iter    98/  229] train: loss: 0.1076823
[Epoch 89; Iter   128/  229] train: loss: 0.1050572
[Epoch 89; Iter   158/  229] train: loss: 0.1082092
[Epoch 89; Iter   188/  229] train: loss: 0.0958544
[Epoch 89; Iter   218/  229] train: loss: 0.1430730
[Epoch 89] ogbg-moltoxcast: 0.682168 val loss: 0.273404
[Epoch 89] ogbg-moltoxcast: 0.652238 test loss: 0.327865
[Epoch 90; Iter    19/  229] train: loss: 0.1232965
[Epoch 90; Iter    49/  229] train: loss: 0.1157584
[Epoch 90; Iter    79/  229] train: loss: 0.1028298
[Epoch 90; Iter   109/  229] train: loss: 0.0868232
[Epoch 90; Iter   139/  229] train: loss: 0.0912908
[Epoch 90; Iter   169/  229] train: loss: 0.1152942
[Epoch 90; Iter   199/  229] train: loss: 0.1747612
[Epoch 90; Iter   229/  229] train: loss: 0.1323428
[Epoch 90] ogbg-moltoxcast: 0.676071 val loss: 0.276523
[Epoch 90] ogbg-moltoxcast: 0.651215 test loss: 0.330266
[Epoch 91; Iter    30/  229] train: loss: 0.1206705
[Epoch 91; Iter    60/  229] train: loss: 0.1470986
[Epoch 91; Iter    90/  229] train: loss: 0.1415262
[Epoch 91; Iter   120/  229] train: loss: 0.1152016
[Epoch 91; Iter   150/  229] train: loss: 0.1585384
[Epoch 91; Iter   180/  229] train: loss: 0.1747189
[Epoch 91; Iter   210/  229] train: loss: 0.1797763
[Epoch 91] ogbg-moltoxcast: 0.670873 val loss: 0.275664
[Epoch 91] ogbg-moltoxcast: 0.646185 test loss: 0.333897
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.626868 test loss: 0.510645
[Epoch 108; Iter     7/  229] train: loss: 0.1226713
[Epoch 108; Iter    37/  229] train: loss: 0.1541496
[Epoch 108; Iter    67/  229] train: loss: 0.1070595
[Epoch 108; Iter    97/  229] train: loss: 0.1225459
[Epoch 108; Iter   127/  229] train: loss: 0.1827379
[Epoch 108; Iter   157/  229] train: loss: 0.0938783
[Epoch 108; Iter   187/  229] train: loss: 0.0896134
[Epoch 108; Iter   217/  229] train: loss: 0.0927330
[Epoch 108] ogbg-moltoxcast: 0.643361 val loss: 0.344106
[Epoch 108] ogbg-moltoxcast: 0.625873 test loss: 0.479866
[Epoch 109; Iter    18/  229] train: loss: 0.1173481
[Epoch 109; Iter    48/  229] train: loss: 0.1179860
[Epoch 109; Iter    78/  229] train: loss: 0.1223200
[Epoch 109; Iter   108/  229] train: loss: 0.1427930
[Epoch 109; Iter   138/  229] train: loss: 0.1110233
[Epoch 109; Iter   168/  229] train: loss: 0.1390668
[Epoch 109; Iter   198/  229] train: loss: 0.1044851
[Epoch 109; Iter   228/  229] train: loss: 0.0879585
[Epoch 109] ogbg-moltoxcast: 0.641007 val loss: 0.330638
[Epoch 109] ogbg-moltoxcast: 0.624747 test loss: 0.528092
[Epoch 110; Iter    29/  229] train: loss: 0.0689507
[Epoch 110; Iter    59/  229] train: loss: 0.0886194
[Epoch 110; Iter    89/  229] train: loss: 0.0711674
[Epoch 110; Iter   119/  229] train: loss: 0.1202059
[Epoch 110; Iter   149/  229] train: loss: 0.0903950
[Epoch 110; Iter   179/  229] train: loss: 0.1545943
[Epoch 110; Iter   209/  229] train: loss: 0.0932468
[Epoch 110] ogbg-moltoxcast: 0.640554 val loss: 0.340688
[Epoch 110] ogbg-moltoxcast: 0.625090 test loss: 0.534363
[Epoch 111; Iter    10/  229] train: loss: 0.1306652
[Epoch 111; Iter    40/  229] train: loss: 0.0873456
[Epoch 111; Iter    70/  229] train: loss: 0.1035225
[Epoch 111; Iter   100/  229] train: loss: 0.1321971
[Epoch 111; Iter   130/  229] train: loss: 0.1005966
[Epoch 111; Iter   160/  229] train: loss: 0.1361649
[Epoch 111; Iter   190/  229] train: loss: 0.1139289
[Epoch 111; Iter   220/  229] train: loss: 0.0937009
[Epoch 111] ogbg-moltoxcast: 0.642195 val loss: 0.337924
[Epoch 111] ogbg-moltoxcast: 0.627643 test loss: 0.482370
[Epoch 112; Iter    21/  229] train: loss: 0.1188148
[Epoch 112; Iter    51/  229] train: loss: 0.0923706
[Epoch 112; Iter    81/  229] train: loss: 0.0865901
[Epoch 112; Iter   111/  229] train: loss: 0.1070678
[Epoch 112; Iter   141/  229] train: loss: 0.1071407
[Epoch 112; Iter   171/  229] train: loss: 0.1440322
[Epoch 112; Iter   201/  229] train: loss: 0.0838393
[Epoch 112] ogbg-moltoxcast: 0.643506 val loss: 0.343752
[Epoch 112] ogbg-moltoxcast: 0.627466 test loss: 0.604773
[Epoch 113; Iter     2/  229] train: loss: 0.1568734
[Epoch 113; Iter    32/  229] train: loss: 0.0949346
[Epoch 113; Iter    62/  229] train: loss: 0.1439646
[Epoch 113; Iter    92/  229] train: loss: 0.1046139
[Epoch 113; Iter   122/  229] train: loss: 0.1193291
[Epoch 113; Iter   152/  229] train: loss: 0.1052426
[Epoch 113; Iter   182/  229] train: loss: 0.1079578
[Epoch 113; Iter   212/  229] train: loss: 0.1737617
[Epoch 113] ogbg-moltoxcast: 0.642879 val loss: 0.345128
[Epoch 113] ogbg-moltoxcast: 0.626452 test loss: 0.533444
[Epoch 114; Iter    13/  229] train: loss: 0.0850653
[Epoch 114; Iter    43/  229] train: loss: 0.1351918
[Epoch 114; Iter    73/  229] train: loss: 0.1493835
[Epoch 114; Iter   103/  229] train: loss: 0.1035105
[Epoch 114; Iter   133/  229] train: loss: 0.1380174
[Epoch 114; Iter   163/  229] train: loss: 0.1378659
[Epoch 114; Iter   193/  229] train: loss: 0.1536694
[Epoch 114; Iter   223/  229] train: loss: 0.1060990
[Epoch 114] ogbg-moltoxcast: 0.641034 val loss: 0.342870
[Epoch 114] ogbg-moltoxcast: 0.625518 test loss: 0.555068
[Epoch 115; Iter    24/  229] train: loss: 0.0813848
[Epoch 115; Iter    54/  229] train: loss: 0.1134105
[Epoch 115; Iter    84/  229] train: loss: 0.1384746
[Epoch 115; Iter   114/  229] train: loss: 0.0865950
[Epoch 115; Iter   144/  229] train: loss: 0.1486087
[Epoch 115; Iter   174/  229] train: loss: 0.1095062
[Epoch 115; Iter   204/  229] train: loss: 0.0881427
[Epoch 115] ogbg-moltoxcast: 0.641808 val loss: 0.351313
[Epoch 115] ogbg-moltoxcast: 0.628052 test loss: 0.547776
[Epoch 116; Iter     5/  229] train: loss: 0.1682133
[Epoch 116; Iter    35/  229] train: loss: 0.1109189
[Epoch 116; Iter    65/  229] train: loss: 0.1149393
[Epoch 116; Iter    95/  229] train: loss: 0.1103225
[Epoch 116; Iter   125/  229] train: loss: 0.1226478
[Epoch 116; Iter   155/  229] train: loss: 0.1276489
[Epoch 116; Iter   185/  229] train: loss: 0.0918350
[Epoch 116; Iter   215/  229] train: loss: 0.0864958
[Epoch 116] ogbg-moltoxcast: 0.643249 val loss: 0.343112
[Epoch 116] ogbg-moltoxcast: 0.628985 test loss: 0.491631
[Epoch 117; Iter    16/  229] train: loss: 0.1155359
[Epoch 117; Iter    46/  229] train: loss: 0.1339286
[Epoch 117; Iter    76/  229] train: loss: 0.1090314
[Epoch 117; Iter   106/  229] train: loss: 0.1235730
[Epoch 117; Iter   136/  229] train: loss: 0.1230145
[Epoch 117; Iter   166/  229] train: loss: 0.0790762
[Epoch 117; Iter   196/  229] train: loss: 0.1146044
[Epoch 117; Iter   226/  229] train: loss: 0.1023651
[Epoch 117] ogbg-moltoxcast: 0.643326 val loss: 0.332827
[Epoch 117] ogbg-moltoxcast: 0.626947 test loss: 0.527726
[Epoch 118; Iter    27/  229] train: loss: 0.1117721
[Epoch 118; Iter    57/  229] train: loss: 0.0843180
[Epoch 118; Iter    87/  229] train: loss: 0.1164803
[Epoch 118; Iter   117/  229] train: loss: 0.0957372
[Epoch 118; Iter   147/  229] train: loss: 0.1030310
[Epoch 118; Iter   177/  229] train: loss: 0.1448711
[Epoch 118; Iter   207/  229] train: loss: 0.0894974
[Epoch 118] ogbg-moltoxcast: 0.643020 val loss: 0.341371
[Epoch 118] ogbg-moltoxcast: 0.627900 test loss: 0.481515
[Epoch 119; Iter     8/  229] train: loss: 0.0687079
[Epoch 119; Iter    38/  229] train: loss: 0.1015780
[Epoch 119; Iter    68/  229] train: loss: 0.1281935
[Epoch 119; Iter    98/  229] train: loss: 0.0917240
[Epoch 119; Iter   128/  229] train: loss: 0.1515745
[Epoch 119; Iter   158/  229] train: loss: 0.1288747
[Epoch 119; Iter   188/  229] train: loss: 0.1345988
[Epoch 119; Iter   218/  229] train: loss: 0.1768708
[Epoch 119] ogbg-moltoxcast: 0.642014 val loss: 0.344420
[Epoch 119] ogbg-moltoxcast: 0.624687 test loss: 0.577607
[Epoch 120; Iter    19/  229] train: loss: 0.0892474
[Epoch 120; Iter    49/  229] train: loss: 0.1202919
[Epoch 120; Iter    79/  229] train: loss: 0.0845143
[Epoch 120; Iter   109/  229] train: loss: 0.0697653
[Epoch 120; Iter   139/  229] train: loss: 0.1336233
[Epoch 120; Iter   169/  229] train: loss: 0.0841987
[Epoch 120; Iter   199/  229] train: loss: 0.0927756
[Epoch 120; Iter   229/  229] train: loss: 0.1100248
[Epoch 120] ogbg-moltoxcast: 0.636563 val loss: 0.359709
[Epoch 120] ogbg-moltoxcast: 0.624893 test loss: 0.554864
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 40.
Statistics on  val_best_checkpoint
mean_pred: -2.5136404037475586
std_pred: 5.0587286949157715
mean_targets: nan
std_targets: nan
prcauc: 0.38738472980652106
rocauc: 0.6827540956117308
ogbg-moltoxcast: 0.6827540956117308
OGBNanLabelBCEWithLogitsLoss: 0.26598487331949433
Statistics on  test
mean_pred: -2.5752367973327637
std_pred: 9.774468421936035
mean_targets: nan
std_targets: nan
prcauc: 0.3549034145893424
rocauc: 0.6538777118037041
ogbg-moltoxcast: 0.6538777118037041
OGBNanLabelBCEWithLogitsLoss: 0.4109804856366125
Statistics on  train
mean_pred: -2.995839834213257
std_pred: 2.6473488807678223
mean_targets: nan
std_targets: nan
prcauc: 0.5354956680125029
rocauc: 0.8576412973677905
ogbg-moltoxcast: 0.8576412973677905
OGBNanLabelBCEWithLogitsLoss: 0.1439379584776262
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.640553 test loss: 0.357078
[Epoch 108; Iter     7/  229] train: loss: 0.0957704
[Epoch 108; Iter    37/  229] train: loss: 0.1714775
[Epoch 108; Iter    67/  229] train: loss: 0.1206258
[Epoch 108; Iter    97/  229] train: loss: 0.1436693
[Epoch 108; Iter   127/  229] train: loss: 0.1152823
[Epoch 108; Iter   157/  229] train: loss: 0.1192616
[Epoch 108; Iter   187/  229] train: loss: 0.1141036
[Epoch 108; Iter   217/  229] train: loss: 0.1026151
[Epoch 108] ogbg-moltoxcast: 0.663293 val loss: 0.491815
[Epoch 108] ogbg-moltoxcast: 0.641867 test loss: 0.359111
[Epoch 109; Iter    18/  229] train: loss: 0.0900735
[Epoch 109; Iter    48/  229] train: loss: 0.1168439
[Epoch 109; Iter    78/  229] train: loss: 0.0861775
[Epoch 109; Iter   108/  229] train: loss: 0.1060278
[Epoch 109; Iter   138/  229] train: loss: 0.0661325
[Epoch 109; Iter   168/  229] train: loss: 0.1162819
[Epoch 109; Iter   198/  229] train: loss: 0.1057092
[Epoch 109; Iter   228/  229] train: loss: 0.1224223
[Epoch 109] ogbg-moltoxcast: 0.663482 val loss: 0.583336
[Epoch 109] ogbg-moltoxcast: 0.637960 test loss: 0.364834
[Epoch 110; Iter    29/  229] train: loss: 0.1264739
[Epoch 110; Iter    59/  229] train: loss: 0.1241392
[Epoch 110; Iter    89/  229] train: loss: 0.1249328
[Epoch 110; Iter   119/  229] train: loss: 0.1474462
[Epoch 110; Iter   149/  229] train: loss: 0.1387814
[Epoch 110; Iter   179/  229] train: loss: 0.1459300
[Epoch 110; Iter   209/  229] train: loss: 0.0952116
[Epoch 110] ogbg-moltoxcast: 0.665547 val loss: 0.505403
[Epoch 110] ogbg-moltoxcast: 0.640033 test loss: 0.363531
[Epoch 111; Iter    10/  229] train: loss: 0.0845629
[Epoch 111; Iter    40/  229] train: loss: 0.1208879
[Epoch 111; Iter    70/  229] train: loss: 0.1428427
[Epoch 111; Iter   100/  229] train: loss: 0.1044751
[Epoch 111; Iter   130/  229] train: loss: 0.1336499
[Epoch 111; Iter   160/  229] train: loss: 0.1611375
[Epoch 111; Iter   190/  229] train: loss: 0.0844202
[Epoch 111; Iter   220/  229] train: loss: 0.1050240
[Epoch 111] ogbg-moltoxcast: 0.664930 val loss: 0.535689
[Epoch 111] ogbg-moltoxcast: 0.639864 test loss: 0.362262
[Epoch 112; Iter    21/  229] train: loss: 0.0963190
[Epoch 112; Iter    51/  229] train: loss: 0.1151548
[Epoch 112; Iter    81/  229] train: loss: 0.0829275
[Epoch 112; Iter   111/  229] train: loss: 0.1018212
[Epoch 112; Iter   141/  229] train: loss: 0.1056423
[Epoch 112; Iter   171/  229] train: loss: 0.1139818
[Epoch 112; Iter   201/  229] train: loss: 0.0805547
[Epoch 112] ogbg-moltoxcast: 0.664196 val loss: 0.474887
[Epoch 112] ogbg-moltoxcast: 0.641807 test loss: 0.361254
[Epoch 113; Iter     2/  229] train: loss: 0.1335500
[Epoch 113; Iter    32/  229] train: loss: 0.1377167
[Epoch 113; Iter    62/  229] train: loss: 0.1155259
[Epoch 113; Iter    92/  229] train: loss: 0.1484216
[Epoch 113; Iter   122/  229] train: loss: 0.1610059
[Epoch 113; Iter   152/  229] train: loss: 0.1057276
[Epoch 113; Iter   182/  229] train: loss: 0.1065215
[Epoch 113; Iter   212/  229] train: loss: 0.0941959
[Epoch 113] ogbg-moltoxcast: 0.668472 val loss: 0.644544
[Epoch 113] ogbg-moltoxcast: 0.643324 test loss: 0.371905
[Epoch 114; Iter    13/  229] train: loss: 0.0717895
[Epoch 114; Iter    43/  229] train: loss: 0.1113994
[Epoch 114; Iter    73/  229] train: loss: 0.1043905
[Epoch 114; Iter   103/  229] train: loss: 0.1371861
[Epoch 114; Iter   133/  229] train: loss: 0.1116155
[Epoch 114; Iter   163/  229] train: loss: 0.0791400
[Epoch 114; Iter   193/  229] train: loss: 0.1221596
[Epoch 114; Iter   223/  229] train: loss: 0.0815650
[Epoch 114] ogbg-moltoxcast: 0.663693 val loss: 0.567564
[Epoch 114] ogbg-moltoxcast: 0.642126 test loss: 0.362264
[Epoch 115; Iter    24/  229] train: loss: 0.0780132
[Epoch 115; Iter    54/  229] train: loss: 0.1119792
[Epoch 115; Iter    84/  229] train: loss: 0.1075279
[Epoch 115; Iter   114/  229] train: loss: 0.0772761
[Epoch 115; Iter   144/  229] train: loss: 0.0697704
[Epoch 115; Iter   174/  229] train: loss: 0.1256380
[Epoch 115; Iter   204/  229] train: loss: 0.1409723
[Epoch 115] ogbg-moltoxcast: 0.663994 val loss: 0.540135
[Epoch 115] ogbg-moltoxcast: 0.641083 test loss: 0.361506
[Epoch 116; Iter     5/  229] train: loss: 0.1143195
[Epoch 116; Iter    35/  229] train: loss: 0.1064020
[Epoch 116; Iter    65/  229] train: loss: 0.0983939
[Epoch 116; Iter    95/  229] train: loss: 0.1411408
[Epoch 116; Iter   125/  229] train: loss: 0.0905950
[Epoch 116; Iter   155/  229] train: loss: 0.1542146
[Epoch 116; Iter   185/  229] train: loss: 0.0913032
[Epoch 116; Iter   215/  229] train: loss: 0.1296318
[Epoch 116] ogbg-moltoxcast: 0.665999 val loss: 0.595023
[Epoch 116] ogbg-moltoxcast: 0.641444 test loss: 0.360864
[Epoch 117; Iter    16/  229] train: loss: 0.0938240
[Epoch 117; Iter    46/  229] train: loss: 0.0834518
[Epoch 117; Iter    76/  229] train: loss: 0.0889836
[Epoch 117; Iter   106/  229] train: loss: 0.1001398
[Epoch 117; Iter   136/  229] train: loss: 0.1343043
[Epoch 117; Iter   166/  229] train: loss: 0.1195503
[Epoch 117; Iter   196/  229] train: loss: 0.1310893
[Epoch 117; Iter   226/  229] train: loss: 0.1131133
[Epoch 117] ogbg-moltoxcast: 0.661178 val loss: 0.564254
[Epoch 117] ogbg-moltoxcast: 0.638792 test loss: 0.358655
[Epoch 118; Iter    27/  229] train: loss: 0.0812766
[Epoch 118; Iter    57/  229] train: loss: 0.0950022
[Epoch 118; Iter    87/  229] train: loss: 0.1095567
[Epoch 118; Iter   117/  229] train: loss: 0.1036837
[Epoch 118; Iter   147/  229] train: loss: 0.1160895
[Epoch 118; Iter   177/  229] train: loss: 0.1298815
[Epoch 118; Iter   207/  229] train: loss: 0.1010808
[Epoch 118] ogbg-moltoxcast: 0.665004 val loss: 0.528352
[Epoch 118] ogbg-moltoxcast: 0.639598 test loss: 0.358505
[Epoch 119; Iter     8/  229] train: loss: 0.1079986
[Epoch 119; Iter    38/  229] train: loss: 0.0814483
[Epoch 119; Iter    68/  229] train: loss: 0.0994764
[Epoch 119; Iter    98/  229] train: loss: 0.1050168
[Epoch 119; Iter   128/  229] train: loss: 0.1185950
[Epoch 119; Iter   158/  229] train: loss: 0.1299584
[Epoch 119; Iter   188/  229] train: loss: 0.1012721
[Epoch 119; Iter   218/  229] train: loss: 0.0633996
[Epoch 119] ogbg-moltoxcast: 0.662950 val loss: 0.566261
[Epoch 119] ogbg-moltoxcast: 0.638020 test loss: 0.363043
[Epoch 120; Iter    19/  229] train: loss: 0.0938191
[Epoch 120; Iter    49/  229] train: loss: 0.1033513
[Epoch 120; Iter    79/  229] train: loss: 0.0992324
[Epoch 120; Iter   109/  229] train: loss: 0.1716915
[Epoch 120; Iter   139/  229] train: loss: 0.0995513
[Epoch 120; Iter   169/  229] train: loss: 0.0844002
[Epoch 120; Iter   199/  229] train: loss: 0.0708665
[Epoch 120; Iter   229/  229] train: loss: 0.1108415
[Epoch 120] ogbg-moltoxcast: 0.661797 val loss: 0.578457
[Epoch 120] ogbg-moltoxcast: 0.638003 test loss: 0.364885
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 36.
Statistics on  val_best_checkpoint
mean_pred: -2.5886783599853516
std_pred: 2.453258514404297
mean_targets: nan
std_targets: nan
prcauc: 0.3967746564374786
rocauc: 0.6908617092156957
ogbg-moltoxcast: 0.6908617092156957
OGBNanLabelBCEWithLogitsLoss: 0.26848434836700047
Statistics on  test
mean_pred: -2.3378541469573975
std_pred: 2.440279483795166
mean_targets: nan
std_targets: nan
prcauc: 0.361983686432449
rocauc: 0.6579232458876891
ogbg-moltoxcast: 0.6579232458876891
OGBNanLabelBCEWithLogitsLoss: 0.3167638095288441
Statistics on  train
mean_pred: -3.0725748538970947
std_pred: 2.436251401901245
mean_targets: nan
std_targets: nan
prcauc: 0.5520297589359681
rocauc: 0.8671344334693397
ogbg-moltoxcast: 0.8671344334693397
OGBNanLabelBCEWithLogitsLoss: 0.14323056001199905
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.650831 test loss: 0.385755
[Epoch 108; Iter     7/  229] train: loss: 0.1070844
[Epoch 108; Iter    37/  229] train: loss: 0.1446759
[Epoch 108; Iter    67/  229] train: loss: 0.1058722
[Epoch 108; Iter    97/  229] train: loss: 0.1135956
[Epoch 108; Iter   127/  229] train: loss: 0.1731144
[Epoch 108; Iter   157/  229] train: loss: 0.0919519
[Epoch 108; Iter   187/  229] train: loss: 0.0794574
[Epoch 108; Iter   217/  229] train: loss: 0.0853267
[Epoch 108] ogbg-moltoxcast: 0.652149 val loss: 0.334044
[Epoch 108] ogbg-moltoxcast: 0.652822 test loss: 0.381541
[Epoch 109; Iter    18/  229] train: loss: 0.1089165
[Epoch 109; Iter    48/  229] train: loss: 0.1172713
[Epoch 109; Iter    78/  229] train: loss: 0.1146815
[Epoch 109; Iter   108/  229] train: loss: 0.1317623
[Epoch 109; Iter   138/  229] train: loss: 0.1003069
[Epoch 109; Iter   168/  229] train: loss: 0.1332548
[Epoch 109; Iter   198/  229] train: loss: 0.0957111
[Epoch 109; Iter   228/  229] train: loss: 0.0806966
[Epoch 109] ogbg-moltoxcast: 0.649641 val loss: 0.334543
[Epoch 109] ogbg-moltoxcast: 0.650653 test loss: 0.381447
[Epoch 110; Iter    29/  229] train: loss: 0.0689079
[Epoch 110; Iter    59/  229] train: loss: 0.0820204
[Epoch 110; Iter    89/  229] train: loss: 0.0619471
[Epoch 110; Iter   119/  229] train: loss: 0.1187481
[Epoch 110; Iter   149/  229] train: loss: 0.0891706
[Epoch 110; Iter   179/  229] train: loss: 0.1437021
[Epoch 110; Iter   209/  229] train: loss: 0.0867692
[Epoch 110] ogbg-moltoxcast: 0.648539 val loss: 0.334671
[Epoch 110] ogbg-moltoxcast: 0.650808 test loss: 0.381886
[Epoch 111; Iter    10/  229] train: loss: 0.1173928
[Epoch 111; Iter    40/  229] train: loss: 0.0802505
[Epoch 111; Iter    70/  229] train: loss: 0.0945282
[Epoch 111; Iter   100/  229] train: loss: 0.1195882
[Epoch 111; Iter   130/  229] train: loss: 0.0958947
[Epoch 111; Iter   160/  229] train: loss: 0.1222583
[Epoch 111; Iter   190/  229] train: loss: 0.1041532
[Epoch 111; Iter   220/  229] train: loss: 0.0821165
[Epoch 111] ogbg-moltoxcast: 0.648430 val loss: 0.341544
[Epoch 111] ogbg-moltoxcast: 0.654763 test loss: 0.389748
[Epoch 112; Iter    21/  229] train: loss: 0.1065474
[Epoch 112; Iter    51/  229] train: loss: 0.0919675
[Epoch 112; Iter    81/  229] train: loss: 0.0803653
[Epoch 112; Iter   111/  229] train: loss: 0.0990678
[Epoch 112; Iter   141/  229] train: loss: 0.1025764
[Epoch 112; Iter   171/  229] train: loss: 0.1359078
[Epoch 112; Iter   201/  229] train: loss: 0.0798873
[Epoch 112] ogbg-moltoxcast: 0.648746 val loss: 0.344255
[Epoch 112] ogbg-moltoxcast: 0.651142 test loss: 0.396159
[Epoch 113; Iter     2/  229] train: loss: 0.1510426
[Epoch 113; Iter    32/  229] train: loss: 0.0906795
[Epoch 113; Iter    62/  229] train: loss: 0.1334178
[Epoch 113; Iter    92/  229] train: loss: 0.0956610
[Epoch 113; Iter   122/  229] train: loss: 0.1095831
[Epoch 113; Iter   152/  229] train: loss: 0.0927802
[Epoch 113; Iter   182/  229] train: loss: 0.0971851
[Epoch 113; Iter   212/  229] train: loss: 0.1663559
[Epoch 113] ogbg-moltoxcast: 0.654031 val loss: 0.338004
[Epoch 113] ogbg-moltoxcast: 0.652969 test loss: 0.385877
[Epoch 114; Iter    13/  229] train: loss: 0.0795212
[Epoch 114; Iter    43/  229] train: loss: 0.1168301
[Epoch 114; Iter    73/  229] train: loss: 0.1272757
[Epoch 114; Iter   103/  229] train: loss: 0.0964057
[Epoch 114; Iter   133/  229] train: loss: 0.1260746
[Epoch 114; Iter   163/  229] train: loss: 0.1189399
[Epoch 114; Iter   193/  229] train: loss: 0.1394727
[Epoch 114; Iter   223/  229] train: loss: 0.0961804
[Epoch 114] ogbg-moltoxcast: 0.651058 val loss: 0.338726
[Epoch 114] ogbg-moltoxcast: 0.649849 test loss: 0.389514
[Epoch 115; Iter    24/  229] train: loss: 0.0721309
[Epoch 115; Iter    54/  229] train: loss: 0.1072390
[Epoch 115; Iter    84/  229] train: loss: 0.1330228
[Epoch 115; Iter   114/  229] train: loss: 0.0794860
[Epoch 115; Iter   144/  229] train: loss: 0.1307428
[Epoch 115; Iter   174/  229] train: loss: 0.0933892
[Epoch 115; Iter   204/  229] train: loss: 0.0823528
[Epoch 115] ogbg-moltoxcast: 0.649878 val loss: 0.340394
[Epoch 115] ogbg-moltoxcast: 0.651201 test loss: 0.387742
[Epoch 116; Iter     5/  229] train: loss: 0.1487592
[Epoch 116; Iter    35/  229] train: loss: 0.1025123
[Epoch 116; Iter    65/  229] train: loss: 0.1038186
[Epoch 116; Iter    95/  229] train: loss: 0.0980725
[Epoch 116; Iter   125/  229] train: loss: 0.1096171
[Epoch 116; Iter   155/  229] train: loss: 0.1194704
[Epoch 116; Iter   185/  229] train: loss: 0.0803875
[Epoch 116; Iter   215/  229] train: loss: 0.0795860
[Epoch 116] ogbg-moltoxcast: 0.652492 val loss: 0.337775
[Epoch 116] ogbg-moltoxcast: 0.653447 test loss: 0.387339
[Epoch 117; Iter    16/  229] train: loss: 0.1089422
[Epoch 117; Iter    46/  229] train: loss: 0.1247598
[Epoch 117; Iter    76/  229] train: loss: 0.1037805
[Epoch 117; Iter   106/  229] train: loss: 0.1205239
[Epoch 117; Iter   136/  229] train: loss: 0.1215202
[Epoch 117; Iter   166/  229] train: loss: 0.0729359
[Epoch 117; Iter   196/  229] train: loss: 0.0993682
[Epoch 117; Iter   226/  229] train: loss: 0.0930368
[Epoch 117] ogbg-moltoxcast: 0.649026 val loss: 0.340590
[Epoch 117] ogbg-moltoxcast: 0.652465 test loss: 0.389872
[Epoch 118; Iter    27/  229] train: loss: 0.1021347
[Epoch 118; Iter    57/  229] train: loss: 0.0683678
[Epoch 118; Iter    87/  229] train: loss: 0.1045952
[Epoch 118; Iter   117/  229] train: loss: 0.0843699
[Epoch 118; Iter   147/  229] train: loss: 0.0971063
[Epoch 118; Iter   177/  229] train: loss: 0.1147447
[Epoch 118; Iter   207/  229] train: loss: 0.0815050
[Epoch 118] ogbg-moltoxcast: 0.647677 val loss: 0.338318
[Epoch 118] ogbg-moltoxcast: 0.651210 test loss: 0.385241
[Epoch 119; Iter     8/  229] train: loss: 0.0655830
[Epoch 119; Iter    38/  229] train: loss: 0.0942038
[Epoch 119; Iter    68/  229] train: loss: 0.1187182
[Epoch 119; Iter    98/  229] train: loss: 0.0820983
[Epoch 119; Iter   128/  229] train: loss: 0.1339607
[Epoch 119; Iter   158/  229] train: loss: 0.1119564
[Epoch 119; Iter   188/  229] train: loss: 0.1254640
[Epoch 119; Iter   218/  229] train: loss: 0.1594428
[Epoch 119] ogbg-moltoxcast: 0.649986 val loss: 0.342175
[Epoch 119] ogbg-moltoxcast: 0.652539 test loss: 0.389862
[Epoch 120; Iter    19/  229] train: loss: 0.0825573
[Epoch 120; Iter    49/  229] train: loss: 0.1153222
[Epoch 120; Iter    79/  229] train: loss: 0.0816384
[Epoch 120; Iter   109/  229] train: loss: 0.0655655
[Epoch 120; Iter   139/  229] train: loss: 0.1248705
[Epoch 120; Iter   169/  229] train: loss: 0.0832196
[Epoch 120; Iter   199/  229] train: loss: 0.0866326
[Epoch 120; Iter   229/  229] train: loss: 0.1022433
[Epoch 120] ogbg-moltoxcast: 0.647743 val loss: 0.344317
[Epoch 120] ogbg-moltoxcast: 0.653320 test loss: 0.391406
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 22.
Statistics on  val_best_checkpoint
mean_pred: -1.8922232389450073
std_pred: 7.334092140197754
mean_targets: nan
std_targets: nan
prcauc: 0.37368308897988756
rocauc: 0.682165875140043
ogbg-moltoxcast: 0.682165875140043
OGBNanLabelBCEWithLogitsLoss: 0.5371134080763521
Statistics on  test
mean_pred: -1.508431077003479
std_pred: 10.779000282287598
mean_targets: nan
std_targets: nan
prcauc: 0.3238191386544892
rocauc: 0.6457996050560093
ogbg-moltoxcast: 0.6457996050560093
OGBNanLabelBCEWithLogitsLoss: 1.3263460438826988
Statistics on  train
mean_pred: -2.693493366241455
std_pred: 2.5685343742370605
mean_targets: nan
std_targets: nan
prcauc: 0.48510774360520437
rocauc: 0.8236950797790533
ogbg-moltoxcast: 0.8236950797790533
OGBNanLabelBCEWithLogitsLoss: 0.1697665352748471
[Epoch 107] ogbg-moltoxcast: 0.639881 test loss: 0.372268
[Epoch 108; Iter     7/  229] train: loss: 0.1051708
[Epoch 108; Iter    37/  229] train: loss: 0.1456161
[Epoch 108; Iter    67/  229] train: loss: 0.1048685
[Epoch 108; Iter    97/  229] train: loss: 0.1119895
[Epoch 108; Iter   127/  229] train: loss: 0.1707400
[Epoch 108; Iter   157/  229] train: loss: 0.0974510
[Epoch 108; Iter   187/  229] train: loss: 0.0851584
[Epoch 108; Iter   217/  229] train: loss: 0.0876990
[Epoch 108] ogbg-moltoxcast: 0.668654 val loss: 0.321862
[Epoch 108] ogbg-moltoxcast: 0.641213 test loss: 0.372405
[Epoch 109; Iter    18/  229] train: loss: 0.1128963
[Epoch 109; Iter    48/  229] train: loss: 0.1179047
[Epoch 109; Iter    78/  229] train: loss: 0.1095884
[Epoch 109; Iter   108/  229] train: loss: 0.1336565
[Epoch 109; Iter   138/  229] train: loss: 0.1055345
[Epoch 109; Iter   168/  229] train: loss: 0.1415962
[Epoch 109; Iter   198/  229] train: loss: 0.0947918
[Epoch 109; Iter   228/  229] train: loss: 0.0767934
[Epoch 109] ogbg-moltoxcast: 0.667547 val loss: 0.327178
[Epoch 109] ogbg-moltoxcast: 0.638423 test loss: 0.377479
[Epoch 110; Iter    29/  229] train: loss: 0.0658811
[Epoch 110; Iter    59/  229] train: loss: 0.0850016
[Epoch 110; Iter    89/  229] train: loss: 0.0661533
[Epoch 110; Iter   119/  229] train: loss: 0.1173164
[Epoch 110; Iter   149/  229] train: loss: 0.0864849
[Epoch 110; Iter   179/  229] train: loss: 0.1491544
[Epoch 110; Iter   209/  229] train: loss: 0.0921011
[Epoch 110] ogbg-moltoxcast: 0.663105 val loss: 0.330655
[Epoch 110] ogbg-moltoxcast: 0.638953 test loss: 0.381054
[Epoch 111; Iter    10/  229] train: loss: 0.1210799
[Epoch 111; Iter    40/  229] train: loss: 0.0805065
[Epoch 111; Iter    70/  229] train: loss: 0.0997035
[Epoch 111; Iter   100/  229] train: loss: 0.1154463
[Epoch 111; Iter   130/  229] train: loss: 0.0984006
[Epoch 111; Iter   160/  229] train: loss: 0.1226502
[Epoch 111; Iter   190/  229] train: loss: 0.0981642
[Epoch 111; Iter   220/  229] train: loss: 0.0918197
[Epoch 111] ogbg-moltoxcast: 0.665525 val loss: 0.334173
[Epoch 111] ogbg-moltoxcast: 0.641219 test loss: 0.389530
[Epoch 112; Iter    21/  229] train: loss: 0.1181323
[Epoch 112; Iter    51/  229] train: loss: 0.0972956
[Epoch 112; Iter    81/  229] train: loss: 0.0754839
[Epoch 112; Iter   111/  229] train: loss: 0.1023622
[Epoch 112; Iter   141/  229] train: loss: 0.1010829
[Epoch 112; Iter   171/  229] train: loss: 0.1380203
[Epoch 112; Iter   201/  229] train: loss: 0.0844952
[Epoch 112] ogbg-moltoxcast: 0.666956 val loss: 0.331750
[Epoch 112] ogbg-moltoxcast: 0.640695 test loss: 0.385751
[Epoch 113; Iter     2/  229] train: loss: 0.1499531
[Epoch 113; Iter    32/  229] train: loss: 0.1029558
[Epoch 113; Iter    62/  229] train: loss: 0.1340563
[Epoch 113; Iter    92/  229] train: loss: 0.0935310
[Epoch 113; Iter   122/  229] train: loss: 0.1172934
[Epoch 113; Iter   152/  229] train: loss: 0.0971670
[Epoch 113; Iter   182/  229] train: loss: 0.1030328
[Epoch 113; Iter   212/  229] train: loss: 0.1615315
[Epoch 113] ogbg-moltoxcast: 0.664515 val loss: 0.325324
[Epoch 113] ogbg-moltoxcast: 0.636233 test loss: 0.379088
[Epoch 114; Iter    13/  229] train: loss: 0.0838739
[Epoch 114; Iter    43/  229] train: loss: 0.1199786
[Epoch 114; Iter    73/  229] train: loss: 0.1305514
[Epoch 114; Iter   103/  229] train: loss: 0.1042392
[Epoch 114; Iter   133/  229] train: loss: 0.1248146
[Epoch 114; Iter   163/  229] train: loss: 0.1298552
[Epoch 114; Iter   193/  229] train: loss: 0.1395369
[Epoch 114; Iter   223/  229] train: loss: 0.0977952
[Epoch 114] ogbg-moltoxcast: 0.665998 val loss: 0.330341
[Epoch 114] ogbg-moltoxcast: 0.638005 test loss: 0.382450
[Epoch 115; Iter    24/  229] train: loss: 0.0732543
[Epoch 115; Iter    54/  229] train: loss: 0.1101316
[Epoch 115; Iter    84/  229] train: loss: 0.1332835
[Epoch 115; Iter   114/  229] train: loss: 0.0810558
[Epoch 115; Iter   144/  229] train: loss: 0.1335411
[Epoch 115; Iter   174/  229] train: loss: 0.1019498
[Epoch 115; Iter   204/  229] train: loss: 0.0890791
[Epoch 115] ogbg-moltoxcast: 0.668313 val loss: 0.328426
[Epoch 115] ogbg-moltoxcast: 0.639336 test loss: 0.380444
[Epoch 116; Iter     5/  229] train: loss: 0.1481629
[Epoch 116; Iter    35/  229] train: loss: 0.1084741
[Epoch 116; Iter    65/  229] train: loss: 0.1054194
[Epoch 116; Iter    95/  229] train: loss: 0.1027241
[Epoch 116; Iter   125/  229] train: loss: 0.1200332
[Epoch 116; Iter   155/  229] train: loss: 0.1269072
[Epoch 116; Iter   185/  229] train: loss: 0.0819370
[Epoch 116; Iter   215/  229] train: loss: 0.0835554
[Epoch 116] ogbg-moltoxcast: 0.663454 val loss: 0.333581
[Epoch 116] ogbg-moltoxcast: 0.639679 test loss: 0.383075
[Epoch 117; Iter    16/  229] train: loss: 0.1103453
[Epoch 117; Iter    46/  229] train: loss: 0.1257537
[Epoch 117; Iter    76/  229] train: loss: 0.1033850
[Epoch 117; Iter   106/  229] train: loss: 0.1204724
[Epoch 117; Iter   136/  229] train: loss: 0.1186623
[Epoch 117; Iter   166/  229] train: loss: 0.0763079
[Epoch 117; Iter   196/  229] train: loss: 0.1077434
[Epoch 117; Iter   226/  229] train: loss: 0.0917464
[Epoch 117] ogbg-moltoxcast: 0.667827 val loss: 0.335389
[Epoch 117] ogbg-moltoxcast: 0.641865 test loss: 0.378511
[Epoch 118; Iter    27/  229] train: loss: 0.1037203
[Epoch 118; Iter    57/  229] train: loss: 0.0735013
[Epoch 118; Iter    87/  229] train: loss: 0.1045769
[Epoch 118; Iter   117/  229] train: loss: 0.0830010
[Epoch 118; Iter   147/  229] train: loss: 0.1005969
[Epoch 118; Iter   177/  229] train: loss: 0.1198048
[Epoch 118; Iter   207/  229] train: loss: 0.0899883
[Epoch 118] ogbg-moltoxcast: 0.664594 val loss: 0.338170
[Epoch 118] ogbg-moltoxcast: 0.639802 test loss: 0.378995
[Epoch 119; Iter     8/  229] train: loss: 0.0695030
[Epoch 119; Iter    38/  229] train: loss: 0.0897273
[Epoch 119; Iter    68/  229] train: loss: 0.1218469
[Epoch 119; Iter    98/  229] train: loss: 0.0818005
[Epoch 119; Iter   128/  229] train: loss: 0.1361560
[Epoch 119; Iter   158/  229] train: loss: 0.1147138
[Epoch 119; Iter   188/  229] train: loss: 0.1264662
[Epoch 119; Iter   218/  229] train: loss: 0.1617251
[Epoch 119] ogbg-moltoxcast: 0.667641 val loss: 0.331562
[Epoch 119] ogbg-moltoxcast: 0.638938 test loss: 0.380391
[Epoch 120; Iter    19/  229] train: loss: 0.0853959
[Epoch 120; Iter    49/  229] train: loss: 0.1129888
[Epoch 120; Iter    79/  229] train: loss: 0.0833062
[Epoch 120; Iter   109/  229] train: loss: 0.0677990
[Epoch 120; Iter   139/  229] train: loss: 0.1276539
[Epoch 120; Iter   169/  229] train: loss: 0.0800092
[Epoch 120; Iter   199/  229] train: loss: 0.0858746
[Epoch 120; Iter   229/  229] train: loss: 0.0990397
[Epoch 120] ogbg-moltoxcast: 0.665331 val loss: 0.335286
[Epoch 120] ogbg-moltoxcast: 0.641254 test loss: 0.384691
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 44.
Statistics on  val_best_checkpoint
mean_pred: -2.8624730110168457
std_pred: 3.557971477508545
mean_targets: nan
std_targets: nan
prcauc: 0.3904167657828861
rocauc: 0.6959716390476902
ogbg-moltoxcast: 0.6959716390476902
OGBNanLabelBCEWithLogitsLoss: 0.27370176130327684
Statistics on  test
mean_pred: -2.53169846534729
std_pred: 2.5606696605682373
mean_targets: nan
std_targets: nan
prcauc: 0.3577334629217275
rocauc: 0.6580053031938089
ogbg-moltoxcast: 0.6580053031938089
OGBNanLabelBCEWithLogitsLoss: 0.3207470754097248
Statistics on  train
mean_pred: -3.283773183822632
std_pred: 2.6994900703430176
mean_targets: nan
std_targets: nan
prcauc: 0.5933379208128795
rocauc: 0.8862855835974429
ogbg-moltoxcast: 0.8862855835974429
OGBNanLabelBCEWithLogitsLoss: 0.13427223105748148
[Epoch 107] ogbg-moltoxcast: 0.644622 test loss: 0.371151
[Epoch 108; Iter     7/  229] train: loss: 0.1207048
[Epoch 108; Iter    37/  229] train: loss: 0.1627569
[Epoch 108; Iter    67/  229] train: loss: 0.1225296
[Epoch 108; Iter    97/  229] train: loss: 0.0828127
[Epoch 108; Iter   127/  229] train: loss: 0.0961304
[Epoch 108; Iter   157/  229] train: loss: 0.0926987
[Epoch 108; Iter   187/  229] train: loss: 0.1173686
[Epoch 108; Iter   217/  229] train: loss: 0.1176042
[Epoch 108] ogbg-moltoxcast: 0.678753 val loss: 0.321669
[Epoch 108] ogbg-moltoxcast: 0.641464 test loss: 0.367653
[Epoch 109; Iter    18/  229] train: loss: 0.1131554
[Epoch 109; Iter    48/  229] train: loss: 0.1096586
[Epoch 109; Iter    78/  229] train: loss: 0.0737229
[Epoch 109; Iter   108/  229] train: loss: 0.1589722
[Epoch 109; Iter   138/  229] train: loss: 0.1661719
[Epoch 109; Iter   168/  229] train: loss: 0.1474734
[Epoch 109; Iter   198/  229] train: loss: 0.1019113
[Epoch 109; Iter   228/  229] train: loss: 0.1518697
[Epoch 109] ogbg-moltoxcast: 0.680993 val loss: 0.304433
[Epoch 109] ogbg-moltoxcast: 0.639166 test loss: 0.363985
[Epoch 110; Iter    29/  229] train: loss: 0.1038498
[Epoch 110; Iter    59/  229] train: loss: 0.1147296
[Epoch 110; Iter    89/  229] train: loss: 0.1769971
[Epoch 110; Iter   119/  229] train: loss: 0.1756478
[Epoch 110; Iter   149/  229] train: loss: 0.1112457
[Epoch 110; Iter   179/  229] train: loss: 0.1412437
[Epoch 110; Iter   209/  229] train: loss: 0.0975877
[Epoch 110] ogbg-moltoxcast: 0.681031 val loss: 0.315361
[Epoch 110] ogbg-moltoxcast: 0.646112 test loss: 0.360498
[Epoch 111; Iter    10/  229] train: loss: 0.1356771
[Epoch 111; Iter    40/  229] train: loss: 0.0792994
[Epoch 111; Iter    70/  229] train: loss: 0.0864726
[Epoch 111; Iter   100/  229] train: loss: 0.1083376
[Epoch 111; Iter   130/  229] train: loss: 0.1177974
[Epoch 111; Iter   160/  229] train: loss: 0.1125033
[Epoch 111; Iter   190/  229] train: loss: 0.1000926
[Epoch 111; Iter   220/  229] train: loss: 0.1221639
[Epoch 111] ogbg-moltoxcast: 0.680414 val loss: 0.322536
[Epoch 111] ogbg-moltoxcast: 0.643504 test loss: 0.364059
[Epoch 112; Iter    21/  229] train: loss: 0.0950967
[Epoch 112; Iter    51/  229] train: loss: 0.0894822
[Epoch 112; Iter    81/  229] train: loss: 0.1065407
[Epoch 112; Iter   111/  229] train: loss: 0.1222541
[Epoch 112; Iter   141/  229] train: loss: 0.1245300
[Epoch 112; Iter   171/  229] train: loss: 0.0898882
[Epoch 112; Iter   201/  229] train: loss: 0.1147528
[Epoch 112] ogbg-moltoxcast: 0.681303 val loss: 0.320565
[Epoch 112] ogbg-moltoxcast: 0.644332 test loss: 0.363334
[Epoch 113; Iter     2/  229] train: loss: 0.0502792
[Epoch 113; Iter    32/  229] train: loss: 0.0947128
[Epoch 113; Iter    62/  229] train: loss: 0.1158519
[Epoch 113; Iter    92/  229] train: loss: 0.1602375
[Epoch 113; Iter   122/  229] train: loss: 0.0716783
[Epoch 113; Iter   152/  229] train: loss: 0.1362289
[Epoch 113; Iter   182/  229] train: loss: 0.0935919
[Epoch 113; Iter   212/  229] train: loss: 0.1081273
[Epoch 113] ogbg-moltoxcast: 0.676302 val loss: 0.340504
[Epoch 113] ogbg-moltoxcast: 0.641782 test loss: 0.367231
[Epoch 114; Iter    13/  229] train: loss: 0.0928272
[Epoch 114; Iter    43/  229] train: loss: 0.0955600
[Epoch 114; Iter    73/  229] train: loss: 0.1071440
[Epoch 114; Iter   103/  229] train: loss: 0.0847607
[Epoch 114; Iter   133/  229] train: loss: 0.1164135
[Epoch 114; Iter   163/  229] train: loss: 0.0779522
[Epoch 114; Iter   193/  229] train: loss: 0.1064656
[Epoch 114; Iter   223/  229] train: loss: 0.0851242
[Epoch 114] ogbg-moltoxcast: 0.677684 val loss: 0.314789
[Epoch 114] ogbg-moltoxcast: 0.639238 test loss: 0.364235
[Epoch 115; Iter    24/  229] train: loss: 0.1025234
[Epoch 115; Iter    54/  229] train: loss: 0.1027558
[Epoch 115; Iter    84/  229] train: loss: 0.1404509
[Epoch 115; Iter   114/  229] train: loss: 0.1140700
[Epoch 115; Iter   144/  229] train: loss: 0.1044097
[Epoch 115; Iter   174/  229] train: loss: 0.0707404
[Epoch 115; Iter   204/  229] train: loss: 0.1370855
[Epoch 115] ogbg-moltoxcast: 0.679314 val loss: 0.321995
[Epoch 115] ogbg-moltoxcast: 0.641801 test loss: 0.363390
[Epoch 116; Iter     5/  229] train: loss: 0.1047461
[Epoch 116; Iter    35/  229] train: loss: 0.0868702
[Epoch 116; Iter    65/  229] train: loss: 0.1763601
[Epoch 116; Iter    95/  229] train: loss: 0.1125224
[Epoch 116; Iter   125/  229] train: loss: 0.1212264
[Epoch 116; Iter   155/  229] train: loss: 0.1248857
[Epoch 116; Iter   185/  229] train: loss: 0.1023929
[Epoch 116; Iter   215/  229] train: loss: 0.0900454
[Epoch 116] ogbg-moltoxcast: 0.677700 val loss: 0.324089
[Epoch 116] ogbg-moltoxcast: 0.641999 test loss: 0.367719
[Epoch 117; Iter    16/  229] train: loss: 0.1340577
[Epoch 117; Iter    46/  229] train: loss: 0.1394477
[Epoch 117; Iter    76/  229] train: loss: 0.0970452
[Epoch 117; Iter   106/  229] train: loss: 0.1300583
[Epoch 117; Iter   136/  229] train: loss: 0.0790667
[Epoch 117; Iter   166/  229] train: loss: 0.0650560
[Epoch 117; Iter   196/  229] train: loss: 0.1634705
[Epoch 117; Iter   226/  229] train: loss: 0.0865813
[Epoch 117] ogbg-moltoxcast: 0.678715 val loss: 0.316789
[Epoch 117] ogbg-moltoxcast: 0.643043 test loss: 0.366697
[Epoch 118; Iter    27/  229] train: loss: 0.0583590
[Epoch 118; Iter    57/  229] train: loss: 0.1036228
[Epoch 118; Iter    87/  229] train: loss: 0.0680570
[Epoch 118; Iter   117/  229] train: loss: 0.1234678
[Epoch 118; Iter   147/  229] train: loss: 0.1023555
[Epoch 118; Iter   177/  229] train: loss: 0.1153109
[Epoch 118; Iter   207/  229] train: loss: 0.1832526
[Epoch 118] ogbg-moltoxcast: 0.680824 val loss: 0.322963
[Epoch 118] ogbg-moltoxcast: 0.642389 test loss: 0.363795
[Epoch 119; Iter     8/  229] train: loss: 0.1244712
[Epoch 119; Iter    38/  229] train: loss: 0.0901748
[Epoch 119; Iter    68/  229] train: loss: 0.1278311
[Epoch 119; Iter    98/  229] train: loss: 0.0660211
[Epoch 119; Iter   128/  229] train: loss: 0.1028401
[Epoch 119; Iter   158/  229] train: loss: 0.1034444
[Epoch 119; Iter   188/  229] train: loss: 0.1415070
[Epoch 119; Iter   218/  229] train: loss: 0.1342949
[Epoch 119] ogbg-moltoxcast: 0.679663 val loss: 0.321376
[Epoch 119] ogbg-moltoxcast: 0.642775 test loss: 0.367289
[Epoch 120; Iter    19/  229] train: loss: 0.1011162
[Epoch 120; Iter    49/  229] train: loss: 0.1194862
[Epoch 120; Iter    79/  229] train: loss: 0.0889400
[Epoch 120; Iter   109/  229] train: loss: 0.1405239
[Epoch 120; Iter   139/  229] train: loss: 0.1174636
[Epoch 120; Iter   169/  229] train: loss: 0.1233331
[Epoch 120; Iter   199/  229] train: loss: 0.0865892
[Epoch 120; Iter   229/  229] train: loss: 0.1696389
[Epoch 120] ogbg-moltoxcast: 0.678586 val loss: 0.338029
[Epoch 120] ogbg-moltoxcast: 0.642522 test loss: 0.365390
[Epoch 121; Iter    30/  229] train: loss: 0.1248946
[Epoch 121; Iter    60/  229] train: loss: 0.1491549
[Epoch 121; Iter    90/  229] train: loss: 0.1391859
[Epoch 121; Iter   120/  229] train: loss: 0.0953178
[Epoch 121; Iter   150/  229] train: loss: 0.0939969
[Epoch 121; Iter   180/  229] train: loss: 0.1071395
[Epoch 121; Iter   210/  229] train: loss: 0.1355705
[Epoch 121] ogbg-moltoxcast: 0.679603 val loss: 0.312067
[Epoch 121] ogbg-moltoxcast: 0.642473 test loss: 0.360496
[Epoch 122; Iter    11/  229] train: loss: 0.1300432
[Epoch 122; Iter    41/  229] train: loss: 0.1187093
[Epoch 122; Iter    71/  229] train: loss: 0.1256867
[Epoch 122; Iter   101/  229] train: loss: 0.1014029
[Epoch 122; Iter   131/  229] train: loss: 0.0799468
[Epoch 122; Iter   161/  229] train: loss: 0.1107630
[Epoch 122; Iter   191/  229] train: loss: 0.1303328
[Epoch 122; Iter   221/  229] train: loss: 0.0837350
[Epoch 122] ogbg-moltoxcast: 0.678198 val loss: 0.326260
[Epoch 122] ogbg-moltoxcast: 0.640050 test loss: 0.365068
[Epoch 123; Iter    22/  229] train: loss: 0.1388668
[Epoch 123; Iter    52/  229] train: loss: 0.1483048
[Epoch 123; Iter    82/  229] train: loss: 0.1135729
[Epoch 123; Iter   112/  229] train: loss: 0.0705558
[Epoch 123; Iter   142/  229] train: loss: 0.1236558
[Epoch 107] ogbg-moltoxcast: 0.641096 test loss: 0.370514
[Epoch 108; Iter     7/  229] train: loss: 0.1219148
[Epoch 108; Iter    37/  229] train: loss: 0.1524516
[Epoch 108; Iter    67/  229] train: loss: 0.1201334
[Epoch 108; Iter    97/  229] train: loss: 0.0840753
[Epoch 108; Iter   127/  229] train: loss: 0.0951270
[Epoch 108; Iter   157/  229] train: loss: 0.0917500
[Epoch 108; Iter   187/  229] train: loss: 0.1158141
[Epoch 108; Iter   217/  229] train: loss: 0.1117615
[Epoch 108] ogbg-moltoxcast: 0.637272 val loss: 0.319084
[Epoch 108] ogbg-moltoxcast: 0.636234 test loss: 0.372073
[Epoch 109; Iter    18/  229] train: loss: 0.1080439
[Epoch 109; Iter    48/  229] train: loss: 0.1120597
[Epoch 109; Iter    78/  229] train: loss: 0.0800263
[Epoch 109; Iter   108/  229] train: loss: 0.1617578
[Epoch 109; Iter   138/  229] train: loss: 0.1667787
[Epoch 109; Iter   168/  229] train: loss: 0.1470644
[Epoch 109; Iter   198/  229] train: loss: 0.1034861
[Epoch 109; Iter   228/  229] train: loss: 0.1422065
[Epoch 109] ogbg-moltoxcast: 0.639863 val loss: 0.316075
[Epoch 109] ogbg-moltoxcast: 0.639466 test loss: 0.366682
[Epoch 110; Iter    29/  229] train: loss: 0.1031856
[Epoch 110; Iter    59/  229] train: loss: 0.1148964
[Epoch 110; Iter    89/  229] train: loss: 0.1736264
[Epoch 110; Iter   119/  229] train: loss: 0.1696967
[Epoch 110; Iter   149/  229] train: loss: 0.1041451
[Epoch 110; Iter   179/  229] train: loss: 0.1431829
[Epoch 110; Iter   209/  229] train: loss: 0.0948943
[Epoch 110] ogbg-moltoxcast: 0.637306 val loss: 0.320529
[Epoch 110] ogbg-moltoxcast: 0.637623 test loss: 0.369947
[Epoch 111; Iter    10/  229] train: loss: 0.1380091
[Epoch 111; Iter    40/  229] train: loss: 0.0826323
[Epoch 111; Iter    70/  229] train: loss: 0.0879266
[Epoch 111; Iter   100/  229] train: loss: 0.1050276
[Epoch 111; Iter   130/  229] train: loss: 0.1174892
[Epoch 111; Iter   160/  229] train: loss: 0.1116019
[Epoch 111; Iter   190/  229] train: loss: 0.0989628
[Epoch 111; Iter   220/  229] train: loss: 0.1296990
[Epoch 111] ogbg-moltoxcast: 0.640789 val loss: 0.320543
[Epoch 111] ogbg-moltoxcast: 0.638483 test loss: 0.373327
[Epoch 112; Iter    21/  229] train: loss: 0.0913673
[Epoch 112; Iter    51/  229] train: loss: 0.0955534
[Epoch 112; Iter    81/  229] train: loss: 0.1095494
[Epoch 112; Iter   111/  229] train: loss: 0.1174370
[Epoch 112; Iter   141/  229] train: loss: 0.1146932
[Epoch 112; Iter   171/  229] train: loss: 0.0973219
[Epoch 112; Iter   201/  229] train: loss: 0.1147608
[Epoch 112] ogbg-moltoxcast: 0.641357 val loss: 0.323782
[Epoch 112] ogbg-moltoxcast: 0.641933 test loss: 0.376878
[Epoch 113; Iter     2/  229] train: loss: 0.0465145
[Epoch 113; Iter    32/  229] train: loss: 0.0974608
[Epoch 113; Iter    62/  229] train: loss: 0.1156621
[Epoch 113; Iter    92/  229] train: loss: 0.1665634
[Epoch 113; Iter   122/  229] train: loss: 0.0639765
[Epoch 113; Iter   152/  229] train: loss: 0.1325529
[Epoch 113; Iter   182/  229] train: loss: 0.0959217
[Epoch 113; Iter   212/  229] train: loss: 0.1118988
[Epoch 113] ogbg-moltoxcast: 0.639902 val loss: 0.318751
[Epoch 113] ogbg-moltoxcast: 0.639115 test loss: 0.370664
[Epoch 114; Iter    13/  229] train: loss: 0.0991774
[Epoch 114; Iter    43/  229] train: loss: 0.0951128
[Epoch 114; Iter    73/  229] train: loss: 0.1052259
[Epoch 114; Iter   103/  229] train: loss: 0.0807883
[Epoch 114; Iter   133/  229] train: loss: 0.1169025
[Epoch 114; Iter   163/  229] train: loss: 0.0744571
[Epoch 114; Iter   193/  229] train: loss: 0.1102302
[Epoch 114; Iter   223/  229] train: loss: 0.0870685
[Epoch 114] ogbg-moltoxcast: 0.641025 val loss: 0.320996
[Epoch 114] ogbg-moltoxcast: 0.638114 test loss: 0.374755
[Epoch 115; Iter    24/  229] train: loss: 0.1037094
[Epoch 115; Iter    54/  229] train: loss: 0.0961477
[Epoch 115; Iter    84/  229] train: loss: 0.1408782
[Epoch 115; Iter   114/  229] train: loss: 0.1099006
[Epoch 115; Iter   144/  229] train: loss: 0.1055685
[Epoch 115; Iter   174/  229] train: loss: 0.0707351
[Epoch 115; Iter   204/  229] train: loss: 0.1365245
[Epoch 115] ogbg-moltoxcast: 0.640873 val loss: 0.319590
[Epoch 115] ogbg-moltoxcast: 0.639091 test loss: 0.370850
[Epoch 116; Iter     5/  229] train: loss: 0.1016182
[Epoch 116; Iter    35/  229] train: loss: 0.0857055
[Epoch 116; Iter    65/  229] train: loss: 0.1831026
[Epoch 116; Iter    95/  229] train: loss: 0.1087674
[Epoch 116; Iter   125/  229] train: loss: 0.1184281
[Epoch 116; Iter   155/  229] train: loss: 0.1332756
[Epoch 116; Iter   185/  229] train: loss: 0.1037424
[Epoch 116; Iter   215/  229] train: loss: 0.0897273
[Epoch 116] ogbg-moltoxcast: 0.641608 val loss: 0.320404
[Epoch 116] ogbg-moltoxcast: 0.638426 test loss: 0.373512
[Epoch 117; Iter    16/  229] train: loss: 0.1359792
[Epoch 117; Iter    46/  229] train: loss: 0.1450779
[Epoch 117; Iter    76/  229] train: loss: 0.0991867
[Epoch 117; Iter   106/  229] train: loss: 0.1293956
[Epoch 117; Iter   136/  229] train: loss: 0.0858251
[Epoch 117; Iter   166/  229] train: loss: 0.0637183
[Epoch 117; Iter   196/  229] train: loss: 0.1622782
[Epoch 117; Iter   226/  229] train: loss: 0.0867235
[Epoch 117] ogbg-moltoxcast: 0.642863 val loss: 0.326534
[Epoch 117] ogbg-moltoxcast: 0.639667 test loss: 0.379648
[Epoch 118; Iter    27/  229] train: loss: 0.0581890
[Epoch 118; Iter    57/  229] train: loss: 0.1068447
[Epoch 118; Iter    87/  229] train: loss: 0.0708662
[Epoch 118; Iter   117/  229] train: loss: 0.1264309
[Epoch 118; Iter   147/  229] train: loss: 0.1081704
[Epoch 118; Iter   177/  229] train: loss: 0.1108459
[Epoch 118; Iter   207/  229] train: loss: 0.1715311
[Epoch 118] ogbg-moltoxcast: 0.638726 val loss: 0.321698
[Epoch 118] ogbg-moltoxcast: 0.636850 test loss: 0.373165
[Epoch 119; Iter     8/  229] train: loss: 0.1262258
[Epoch 119; Iter    38/  229] train: loss: 0.0910422
[Epoch 119; Iter    68/  229] train: loss: 0.1258215
[Epoch 119; Iter    98/  229] train: loss: 0.0700229
[Epoch 119; Iter   128/  229] train: loss: 0.1091069
[Epoch 119; Iter   158/  229] train: loss: 0.1010254
[Epoch 119; Iter   188/  229] train: loss: 0.1403956
[Epoch 119; Iter   218/  229] train: loss: 0.1333834
[Epoch 119] ogbg-moltoxcast: 0.641314 val loss: 0.324140
[Epoch 119] ogbg-moltoxcast: 0.638303 test loss: 0.379076
[Epoch 120; Iter    19/  229] train: loss: 0.0971836
[Epoch 120; Iter    49/  229] train: loss: 0.1236022
[Epoch 120; Iter    79/  229] train: loss: 0.0911824
[Epoch 120; Iter   109/  229] train: loss: 0.1404921
[Epoch 120; Iter   139/  229] train: loss: 0.1188924
[Epoch 120; Iter   169/  229] train: loss: 0.1239537
[Epoch 120; Iter   199/  229] train: loss: 0.0856139
[Epoch 120; Iter   229/  229] train: loss: 0.1656258
[Epoch 120] ogbg-moltoxcast: 0.637984 val loss: 0.319351
[Epoch 120] ogbg-moltoxcast: 0.638415 test loss: 0.371251
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 40.
Statistics on  val_best_checkpoint
mean_pred: -2.952597141265869
std_pred: 2.579723834991455
mean_targets: nan
std_targets: nan
prcauc: 0.37975449255037275
rocauc: 0.6773410429638356
ogbg-moltoxcast: 0.6773410429638356
OGBNanLabelBCEWithLogitsLoss: 0.2850465548449549
Statistics on  test
mean_pred: -2.6750569343566895
std_pred: 2.5142457485198975
mean_targets: nan
std_targets: nan
prcauc: 0.36321822745593646
rocauc: 0.6650089801996167
ogbg-moltoxcast: 0.6650089801996167
OGBNanLabelBCEWithLogitsLoss: 0.32661300178231867
Statistics on  train
mean_pred: -3.4158401489257812
std_pred: 2.629371404647827
mean_targets: nan
std_targets: nan
prcauc: 0.5790033366308581
rocauc: 0.8794056336211001
ogbg-moltoxcast: 0.8794056336211001
OGBNanLabelBCEWithLogitsLoss: 0.13413146186994152
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.622081 test loss: 0.781620
[Epoch 108; Iter     7/  229] train: loss: 0.1213428
[Epoch 108; Iter    37/  229] train: loss: 0.1583909
[Epoch 108; Iter    67/  229] train: loss: 0.1236614
[Epoch 108; Iter    97/  229] train: loss: 0.0858060
[Epoch 108; Iter   127/  229] train: loss: 0.1028753
[Epoch 108; Iter   157/  229] train: loss: 0.0974917
[Epoch 108; Iter   187/  229] train: loss: 0.1211310
[Epoch 108; Iter   217/  229] train: loss: 0.1236898
[Epoch 108] ogbg-moltoxcast: 0.630501 val loss: 0.421015
[Epoch 108] ogbg-moltoxcast: 0.617921 test loss: 0.575923
[Epoch 109; Iter    18/  229] train: loss: 0.1149730
[Epoch 109; Iter    48/  229] train: loss: 0.1078079
[Epoch 109; Iter    78/  229] train: loss: 0.0777062
[Epoch 109; Iter   108/  229] train: loss: 0.1538837
[Epoch 109; Iter   138/  229] train: loss: 0.1875826
[Epoch 109; Iter   168/  229] train: loss: 0.1570618
[Epoch 109; Iter   198/  229] train: loss: 0.1008359
[Epoch 109; Iter   228/  229] train: loss: 0.1496075
[Epoch 109] ogbg-moltoxcast: 0.630071 val loss: 0.483566
[Epoch 109] ogbg-moltoxcast: 0.620658 test loss: 1.173287
[Epoch 110; Iter    29/  229] train: loss: 0.1110239
[Epoch 110; Iter    59/  229] train: loss: 0.1129683
[Epoch 110; Iter    89/  229] train: loss: 0.1687503
[Epoch 110; Iter   119/  229] train: loss: 0.1781640
[Epoch 110; Iter   149/  229] train: loss: 0.1076095
[Epoch 110; Iter   179/  229] train: loss: 0.1465600
[Epoch 110; Iter   209/  229] train: loss: 0.1003338
[Epoch 110] ogbg-moltoxcast: 0.637854 val loss: 0.376949
[Epoch 110] ogbg-moltoxcast: 0.619512 test loss: 0.415807
[Epoch 111; Iter    10/  229] train: loss: 0.1334372
[Epoch 111; Iter    40/  229] train: loss: 0.0794991
[Epoch 111; Iter    70/  229] train: loss: 0.0904107
[Epoch 111; Iter   100/  229] train: loss: 0.1060584
[Epoch 111; Iter   130/  229] train: loss: 0.1200114
[Epoch 111; Iter   160/  229] train: loss: 0.1123924
[Epoch 111; Iter   190/  229] train: loss: 0.1049053
[Epoch 111; Iter   220/  229] train: loss: 0.1261137
[Epoch 111] ogbg-moltoxcast: 0.623107 val loss: 0.469771
[Epoch 111] ogbg-moltoxcast: 0.621165 test loss: 0.553397
[Epoch 112; Iter    21/  229] train: loss: 0.0874174
[Epoch 112; Iter    51/  229] train: loss: 0.0901523
[Epoch 112; Iter    81/  229] train: loss: 0.1083075
[Epoch 112; Iter   111/  229] train: loss: 0.1265476
[Epoch 112; Iter   141/  229] train: loss: 0.1206897
[Epoch 112; Iter   171/  229] train: loss: 0.0952327
[Epoch 112; Iter   201/  229] train: loss: 0.1149177
[Epoch 112] ogbg-moltoxcast: 0.631056 val loss: 0.597933
[Epoch 112] ogbg-moltoxcast: 0.624799 test loss: 1.087855
[Epoch 113; Iter     2/  229] train: loss: 0.0502830
[Epoch 113; Iter    32/  229] train: loss: 0.0994075
[Epoch 113; Iter    62/  229] train: loss: 0.1178020
[Epoch 113; Iter    92/  229] train: loss: 0.1679120
[Epoch 113; Iter   122/  229] train: loss: 0.0670004
[Epoch 113; Iter   152/  229] train: loss: 0.1415323
[Epoch 113; Iter   182/  229] train: loss: 0.1027765
[Epoch 113; Iter   212/  229] train: loss: 0.1085963
[Epoch 113] ogbg-moltoxcast: 0.626820 val loss: 0.438051
[Epoch 113] ogbg-moltoxcast: 0.624135 test loss: 0.681105
[Epoch 114; Iter    13/  229] train: loss: 0.1000516
[Epoch 114; Iter    43/  229] train: loss: 0.0951368
[Epoch 114; Iter    73/  229] train: loss: 0.1188605
[Epoch 114; Iter   103/  229] train: loss: 0.0833977
[Epoch 114; Iter   133/  229] train: loss: 0.1184520
[Epoch 114; Iter   163/  229] train: loss: 0.0770853
[Epoch 114; Iter   193/  229] train: loss: 0.1034346
[Epoch 114; Iter   223/  229] train: loss: 0.0875609
[Epoch 114] ogbg-moltoxcast: 0.613615 val loss: 0.408949
[Epoch 114] ogbg-moltoxcast: 0.618995 test loss: 0.488384
[Epoch 115; Iter    24/  229] train: loss: 0.1077335
[Epoch 115; Iter    54/  229] train: loss: 0.0975770
[Epoch 115; Iter    84/  229] train: loss: 0.1471236
[Epoch 115; Iter   114/  229] train: loss: 0.1137055
[Epoch 115; Iter   144/  229] train: loss: 0.1028882
[Epoch 115; Iter   174/  229] train: loss: 0.0690814
[Epoch 115; Iter   204/  229] train: loss: 0.1466573
[Epoch 115] ogbg-moltoxcast: 0.630522 val loss: 0.453086
[Epoch 115] ogbg-moltoxcast: 0.623708 test loss: 0.923507
[Epoch 116; Iter     5/  229] train: loss: 0.1096093
[Epoch 116; Iter    35/  229] train: loss: 0.0842013
[Epoch 116; Iter    65/  229] train: loss: 0.1836139
[Epoch 116; Iter    95/  229] train: loss: 0.1084645
[Epoch 116; Iter   125/  229] train: loss: 0.1215594
[Epoch 116; Iter   155/  229] train: loss: 0.1260710
[Epoch 116; Iter   185/  229] train: loss: 0.1119092
[Epoch 116; Iter   215/  229] train: loss: 0.0928719
[Epoch 116] ogbg-moltoxcast: 0.629057 val loss: 0.503441
[Epoch 116] ogbg-moltoxcast: 0.621837 test loss: 0.815179
[Epoch 117; Iter    16/  229] train: loss: 0.1410791
[Epoch 117; Iter    46/  229] train: loss: 0.1471460
[Epoch 117; Iter    76/  229] train: loss: 0.1008525
[Epoch 117; Iter   106/  229] train: loss: 0.1378200
[Epoch 117; Iter   136/  229] train: loss: 0.0851935
[Epoch 117; Iter   166/  229] train: loss: 0.0640372
[Epoch 117; Iter   196/  229] train: loss: 0.1791658
[Epoch 117; Iter   226/  229] train: loss: 0.0856365
[Epoch 117] ogbg-moltoxcast: 0.632433 val loss: 0.641466
[Epoch 117] ogbg-moltoxcast: 0.622664 test loss: 0.766897
[Epoch 118; Iter    27/  229] train: loss: 0.0657264
[Epoch 118; Iter    57/  229] train: loss: 0.1133587
[Epoch 118; Iter    87/  229] train: loss: 0.0793189
[Epoch 118; Iter   117/  229] train: loss: 0.1312317
[Epoch 118; Iter   147/  229] train: loss: 0.1089605
[Epoch 118; Iter   177/  229] train: loss: 0.1191260
[Epoch 118; Iter   207/  229] train: loss: 0.1740153
[Epoch 118] ogbg-moltoxcast: 0.623317 val loss: 0.512548
[Epoch 118] ogbg-moltoxcast: 0.621037 test loss: 0.638688
[Epoch 119; Iter     8/  229] train: loss: 0.1283712
[Epoch 119; Iter    38/  229] train: loss: 0.0958070
[Epoch 119; Iter    68/  229] train: loss: 0.1292806
[Epoch 119; Iter    98/  229] train: loss: 0.0644799
[Epoch 119; Iter   128/  229] train: loss: 0.1093516
[Epoch 119; Iter   158/  229] train: loss: 0.1027839
[Epoch 119; Iter   188/  229] train: loss: 0.1486295
[Epoch 119; Iter   218/  229] train: loss: 0.1342709
[Epoch 119] ogbg-moltoxcast: 0.630693 val loss: 0.511448
[Epoch 119] ogbg-moltoxcast: 0.623829 test loss: 0.673992
[Epoch 120; Iter    19/  229] train: loss: 0.1052943
[Epoch 120; Iter    49/  229] train: loss: 0.1290553
[Epoch 120; Iter    79/  229] train: loss: 0.0903275
[Epoch 120; Iter   109/  229] train: loss: 0.1372069
[Epoch 120; Iter   139/  229] train: loss: 0.1247046
[Epoch 120; Iter   169/  229] train: loss: 0.1226737
[Epoch 120; Iter   199/  229] train: loss: 0.0883992
[Epoch 120; Iter   229/  229] train: loss: 0.1726199
[Epoch 120] ogbg-moltoxcast: 0.623486 val loss: 0.654072
[Epoch 120] ogbg-moltoxcast: 0.620945 test loss: 0.990946
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 14.
Statistics on  val_best_checkpoint
mean_pred: -1.9592214822769165
std_pred: 8.204873085021973
mean_targets: nan
std_targets: nan
prcauc: 0.35605956757354457
rocauc: 0.6670284144976634
ogbg-moltoxcast: 0.6670284144976634
OGBNanLabelBCEWithLogitsLoss: 1.1182859432080696
Statistics on  test
mean_pred: -1.407971739768982
std_pred: 14.525968551635742
mean_targets: nan
std_targets: nan
prcauc: 0.32245917296637705
rocauc: 0.6350220844035771
ogbg-moltoxcast: 0.6350220844035771
OGBNanLabelBCEWithLogitsLoss: 1.454045623027045
Statistics on  train
mean_pred: -2.4946231842041016
std_pred: 9.858614921569824
mean_targets: nan
std_targets: nan
prcauc: 0.40182175618209975
rocauc: 0.7682031980965188
ogbg-moltoxcast: 0.7682031980965188
OGBNanLabelBCEWithLogitsLoss: 0.24335008300027472
[Epoch 107] ogbg-moltoxcast: 0.622129 test loss: 0.395132
[Epoch 108; Iter     7/  229] train: loss: 0.0948339
[Epoch 108; Iter    37/  229] train: loss: 0.1711818
[Epoch 108; Iter    67/  229] train: loss: 0.1115879
[Epoch 108; Iter    97/  229] train: loss: 0.1372856
[Epoch 108; Iter   127/  229] train: loss: 0.1092216
[Epoch 108; Iter   157/  229] train: loss: 0.1176431
[Epoch 108; Iter   187/  229] train: loss: 0.1153726
[Epoch 108; Iter   217/  229] train: loss: 0.0981466
[Epoch 108] ogbg-moltoxcast: 0.643139 val loss: 0.336842
[Epoch 108] ogbg-moltoxcast: 0.621196 test loss: 0.394838
[Epoch 109; Iter    18/  229] train: loss: 0.0876785
[Epoch 109; Iter    48/  229] train: loss: 0.1176912
[Epoch 109; Iter    78/  229] train: loss: 0.0827241
[Epoch 109; Iter   108/  229] train: loss: 0.0993168
[Epoch 109; Iter   138/  229] train: loss: 0.0663520
[Epoch 109; Iter   168/  229] train: loss: 0.1196295
[Epoch 109; Iter   198/  229] train: loss: 0.1032131
[Epoch 109; Iter   228/  229] train: loss: 0.1257516
[Epoch 109] ogbg-moltoxcast: 0.645032 val loss: 0.340562
[Epoch 109] ogbg-moltoxcast: 0.622432 test loss: 0.399761
[Epoch 110; Iter    29/  229] train: loss: 0.1233506
[Epoch 110; Iter    59/  229] train: loss: 0.1252508
[Epoch 110; Iter    89/  229] train: loss: 0.1285965
[Epoch 110; Iter   119/  229] train: loss: 0.1475418
[Epoch 110; Iter   149/  229] train: loss: 0.1430666
[Epoch 110; Iter   179/  229] train: loss: 0.1416492
[Epoch 110; Iter   209/  229] train: loss: 0.0897970
[Epoch 110] ogbg-moltoxcast: 0.643659 val loss: 0.335947
[Epoch 110] ogbg-moltoxcast: 0.621487 test loss: 0.393485
[Epoch 111; Iter    10/  229] train: loss: 0.0854452
[Epoch 111; Iter    40/  229] train: loss: 0.1134182
[Epoch 111; Iter    70/  229] train: loss: 0.1380543
[Epoch 111; Iter   100/  229] train: loss: 0.1000938
[Epoch 111; Iter   130/  229] train: loss: 0.1293962
[Epoch 111; Iter   160/  229] train: loss: 0.1508546
[Epoch 111; Iter   190/  229] train: loss: 0.0859273
[Epoch 111; Iter   220/  229] train: loss: 0.1096556
[Epoch 111] ogbg-moltoxcast: 0.646718 val loss: 0.333974
[Epoch 111] ogbg-moltoxcast: 0.623339 test loss: 0.386410
[Epoch 112; Iter    21/  229] train: loss: 0.0948921
[Epoch 112; Iter    51/  229] train: loss: 0.1190993
[Epoch 112; Iter    81/  229] train: loss: 0.0822372
[Epoch 112; Iter   111/  229] train: loss: 0.1013011
[Epoch 112; Iter   141/  229] train: loss: 0.1063731
[Epoch 112; Iter   171/  229] train: loss: 0.1137550
[Epoch 112; Iter   201/  229] train: loss: 0.0804787
[Epoch 112] ogbg-moltoxcast: 0.645652 val loss: 0.338384
[Epoch 112] ogbg-moltoxcast: 0.622359 test loss: 0.396273
[Epoch 113; Iter     2/  229] train: loss: 0.1345325
[Epoch 113; Iter    32/  229] train: loss: 0.1364339
[Epoch 113; Iter    62/  229] train: loss: 0.1112639
[Epoch 113; Iter    92/  229] train: loss: 0.1375200
[Epoch 113; Iter   122/  229] train: loss: 0.1518206
[Epoch 113; Iter   152/  229] train: loss: 0.1091212
[Epoch 113; Iter   182/  229] train: loss: 0.1008415
[Epoch 113; Iter   212/  229] train: loss: 0.0958604
[Epoch 113] ogbg-moltoxcast: 0.651579 val loss: 0.343901
[Epoch 113] ogbg-moltoxcast: 0.624157 test loss: 0.399737
[Epoch 114; Iter    13/  229] train: loss: 0.0740322
[Epoch 114; Iter    43/  229] train: loss: 0.1126138
[Epoch 114; Iter    73/  229] train: loss: 0.1057494
[Epoch 114; Iter   103/  229] train: loss: 0.1283176
[Epoch 114; Iter   133/  229] train: loss: 0.1103970
[Epoch 114; Iter   163/  229] train: loss: 0.0787065
[Epoch 114; Iter   193/  229] train: loss: 0.1211871
[Epoch 114; Iter   223/  229] train: loss: 0.0797659
[Epoch 114] ogbg-moltoxcast: 0.647282 val loss: 0.340056
[Epoch 114] ogbg-moltoxcast: 0.623136 test loss: 0.398912
[Epoch 115; Iter    24/  229] train: loss: 0.0825109
[Epoch 115; Iter    54/  229] train: loss: 0.1044757
[Epoch 115; Iter    84/  229] train: loss: 0.1071897
[Epoch 115; Iter   114/  229] train: loss: 0.0856565
[Epoch 115; Iter   144/  229] train: loss: 0.0679417
[Epoch 115; Iter   174/  229] train: loss: 0.1247846
[Epoch 115; Iter   204/  229] train: loss: 0.1313480
[Epoch 115] ogbg-moltoxcast: 0.643814 val loss: 0.342939
[Epoch 115] ogbg-moltoxcast: 0.622798 test loss: 0.397353
[Epoch 116; Iter     5/  229] train: loss: 0.1142600
[Epoch 116; Iter    35/  229] train: loss: 0.1096117
[Epoch 116; Iter    65/  229] train: loss: 0.1008196
[Epoch 116; Iter    95/  229] train: loss: 0.1382855
[Epoch 116; Iter   125/  229] train: loss: 0.0870653
[Epoch 116; Iter   155/  229] train: loss: 0.1449889
[Epoch 116; Iter   185/  229] train: loss: 0.0837287
[Epoch 116; Iter   215/  229] train: loss: 0.1282490
[Epoch 116] ogbg-moltoxcast: 0.643335 val loss: 0.337583
[Epoch 116] ogbg-moltoxcast: 0.626622 test loss: 0.392970
[Epoch 117; Iter    16/  229] train: loss: 0.0942861
[Epoch 117; Iter    46/  229] train: loss: 0.0848329
[Epoch 117; Iter    76/  229] train: loss: 0.0851084
[Epoch 117; Iter   106/  229] train: loss: 0.1001440
[Epoch 117; Iter   136/  229] train: loss: 0.1294768
[Epoch 117; Iter   166/  229] train: loss: 0.1129643
[Epoch 117; Iter   196/  229] train: loss: 0.1298344
[Epoch 117; Iter   226/  229] train: loss: 0.1086587
[Epoch 117] ogbg-moltoxcast: 0.640900 val loss: 0.341924
[Epoch 117] ogbg-moltoxcast: 0.621120 test loss: 0.397782
[Epoch 118; Iter    27/  229] train: loss: 0.0824836
[Epoch 118; Iter    57/  229] train: loss: 0.0955163
[Epoch 118; Iter    87/  229] train: loss: 0.1074832
[Epoch 118; Iter   117/  229] train: loss: 0.1031910
[Epoch 118; Iter   147/  229] train: loss: 0.1080953
[Epoch 118; Iter   177/  229] train: loss: 0.1286366
[Epoch 118; Iter   207/  229] train: loss: 0.0978600
[Epoch 118] ogbg-moltoxcast: 0.639334 val loss: 0.340251
[Epoch 118] ogbg-moltoxcast: 0.619810 test loss: 0.396476
[Epoch 119; Iter     8/  229] train: loss: 0.1014722
[Epoch 119; Iter    38/  229] train: loss: 0.0787587
[Epoch 119; Iter    68/  229] train: loss: 0.0987073
[Epoch 119; Iter    98/  229] train: loss: 0.1064343
[Epoch 119; Iter   128/  229] train: loss: 0.1094764
[Epoch 119; Iter   158/  229] train: loss: 0.1215822
[Epoch 119; Iter   188/  229] train: loss: 0.1007402
[Epoch 119; Iter   218/  229] train: loss: 0.0656466
[Epoch 119] ogbg-moltoxcast: 0.641376 val loss: 0.339824
[Epoch 119] ogbg-moltoxcast: 0.620877 test loss: 0.396592
[Epoch 120; Iter    19/  229] train: loss: 0.0993466
[Epoch 120; Iter    49/  229] train: loss: 0.1032354
[Epoch 120; Iter    79/  229] train: loss: 0.0986477
[Epoch 120; Iter   109/  229] train: loss: 0.1696813
[Epoch 120; Iter   139/  229] train: loss: 0.0952867
[Epoch 120; Iter   169/  229] train: loss: 0.0857038
[Epoch 120; Iter   199/  229] train: loss: 0.0709715
[Epoch 120; Iter   229/  229] train: loss: 0.1073210
[Epoch 120] ogbg-moltoxcast: 0.642395 val loss: 0.342222
[Epoch 120] ogbg-moltoxcast: 0.621110 test loss: 0.401104
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 56.
Statistics on  val_best_checkpoint
mean_pred: -2.725796937942505
std_pred: 2.9370739459991455
mean_targets: nan
std_targets: nan
prcauc: 0.3643222928879547
rocauc: 0.664560193407549
ogbg-moltoxcast: 0.664560193407549
OGBNanLabelBCEWithLogitsLoss: 0.3009836057136799
Statistics on  test
mean_pred: -2.4588310718536377
std_pred: 2.933647394180298
mean_targets: nan
std_targets: nan
prcauc: 0.33809214861998294
rocauc: 0.6292958048366302
ogbg-moltoxcast: 0.6292958048366302
OGBNanLabelBCEWithLogitsLoss: 0.356414258480072
Statistics on  train
mean_pred: -3.4954371452331543
std_pred: 2.7624056339263916
mean_targets: nan
std_targets: nan
prcauc: 0.6171052821741906
rocauc: 0.8966204866260601
ogbg-moltoxcast: 0.8966204866260601
OGBNanLabelBCEWithLogitsLoss: 0.12647366735222038
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.2.yml --seed 4 --device cuda:3
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.2.yml --seed 5 --device cuda:3
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.2.yml --seed 6 --device cuda:3
All runs completed.
[Epoch 107] ogbg-moltoxcast: 0.636679 test loss: 0.373180
[Epoch 108; Iter     7/  229] train: loss: 0.0973659
[Epoch 108; Iter    37/  229] train: loss: 0.1774929
[Epoch 108; Iter    67/  229] train: loss: 0.1181063
[Epoch 108; Iter    97/  229] train: loss: 0.1435976
[Epoch 108; Iter   127/  229] train: loss: 0.1160871
[Epoch 108; Iter   157/  229] train: loss: 0.1159719
[Epoch 108; Iter   187/  229] train: loss: 0.1182587
[Epoch 108; Iter   217/  229] train: loss: 0.1058299
[Epoch 108] ogbg-moltoxcast: 0.667344 val loss: 0.334373
[Epoch 108] ogbg-moltoxcast: 0.637825 test loss: 0.380864
[Epoch 109; Iter    18/  229] train: loss: 0.0871107
[Epoch 109; Iter    48/  229] train: loss: 0.1175027
[Epoch 109; Iter    78/  229] train: loss: 0.0909299
[Epoch 109; Iter   108/  229] train: loss: 0.0985133
[Epoch 109; Iter   138/  229] train: loss: 0.0741783
[Epoch 109; Iter   168/  229] train: loss: 0.1195128
[Epoch 109; Iter   198/  229] train: loss: 0.1059686
[Epoch 109; Iter   228/  229] train: loss: 0.1259570
[Epoch 109] ogbg-moltoxcast: 0.665357 val loss: 0.332428
[Epoch 109] ogbg-moltoxcast: 0.637588 test loss: 0.375918
[Epoch 110; Iter    29/  229] train: loss: 0.1253157
[Epoch 110; Iter    59/  229] train: loss: 0.1287159
[Epoch 110; Iter    89/  229] train: loss: 0.1323463
[Epoch 110; Iter   119/  229] train: loss: 0.1489130
[Epoch 110; Iter   149/  229] train: loss: 0.1473229
[Epoch 110; Iter   179/  229] train: loss: 0.1437460
[Epoch 110; Iter   209/  229] train: loss: 0.0932156
[Epoch 110] ogbg-moltoxcast: 0.665536 val loss: 0.330418
[Epoch 110] ogbg-moltoxcast: 0.639711 test loss: 0.370019
[Epoch 111; Iter    10/  229] train: loss: 0.0827296
[Epoch 111; Iter    40/  229] train: loss: 0.1163404
[Epoch 111; Iter    70/  229] train: loss: 0.1450101
[Epoch 111; Iter   100/  229] train: loss: 0.1072227
[Epoch 111; Iter   130/  229] train: loss: 0.1271082
[Epoch 111; Iter   160/  229] train: loss: 0.1567003
[Epoch 111; Iter   190/  229] train: loss: 0.0848028
[Epoch 111; Iter   220/  229] train: loss: 0.1049225
[Epoch 111] ogbg-moltoxcast: 0.665361 val loss: 0.338690
[Epoch 111] ogbg-moltoxcast: 0.635964 test loss: 0.376450
[Epoch 112; Iter    21/  229] train: loss: 0.0995496
[Epoch 112; Iter    51/  229] train: loss: 0.1193907
[Epoch 112; Iter    81/  229] train: loss: 0.0826210
[Epoch 112; Iter   111/  229] train: loss: 0.1033468
[Epoch 112; Iter   141/  229] train: loss: 0.1046860
[Epoch 112; Iter   171/  229] train: loss: 0.1121765
[Epoch 112; Iter   201/  229] train: loss: 0.0803417
[Epoch 112] ogbg-moltoxcast: 0.667155 val loss: 0.331639
[Epoch 112] ogbg-moltoxcast: 0.634502 test loss: 0.378949
[Epoch 113; Iter     2/  229] train: loss: 0.1351913
[Epoch 113; Iter    32/  229] train: loss: 0.1380660
[Epoch 113; Iter    62/  229] train: loss: 0.1181984
[Epoch 113; Iter    92/  229] train: loss: 0.1469805
[Epoch 113; Iter   122/  229] train: loss: 0.1603246
[Epoch 113; Iter   152/  229] train: loss: 0.1106663
[Epoch 113; Iter   182/  229] train: loss: 0.1010190
[Epoch 113; Iter   212/  229] train: loss: 0.0960614
[Epoch 113] ogbg-moltoxcast: 0.669264 val loss: 0.339697
[Epoch 113] ogbg-moltoxcast: 0.639307 test loss: 0.380844
[Epoch 114; Iter    13/  229] train: loss: 0.0685601
[Epoch 114; Iter    43/  229] train: loss: 0.1089925
[Epoch 114; Iter    73/  229] train: loss: 0.1015900
[Epoch 114; Iter   103/  229] train: loss: 0.1317877
[Epoch 114; Iter   133/  229] train: loss: 0.1172500
[Epoch 114; Iter   163/  229] train: loss: 0.0811579
[Epoch 114; Iter   193/  229] train: loss: 0.1281945
[Epoch 114; Iter   223/  229] train: loss: 0.0796028
[Epoch 114] ogbg-moltoxcast: 0.663921 val loss: 0.339250
[Epoch 114] ogbg-moltoxcast: 0.634543 test loss: 0.383111
[Epoch 115; Iter    24/  229] train: loss: 0.0775968
[Epoch 115; Iter    54/  229] train: loss: 0.1115565
[Epoch 115; Iter    84/  229] train: loss: 0.1131757
[Epoch 115; Iter   114/  229] train: loss: 0.0785178
[Epoch 115; Iter   144/  229] train: loss: 0.0640946
[Epoch 115; Iter   174/  229] train: loss: 0.1217402
[Epoch 115; Iter   204/  229] train: loss: 0.1367827
[Epoch 115] ogbg-moltoxcast: 0.666166 val loss: 0.339190
[Epoch 115] ogbg-moltoxcast: 0.634846 test loss: 0.380133
[Epoch 116; Iter     5/  229] train: loss: 0.1130386
[Epoch 116; Iter    35/  229] train: loss: 0.1141017
[Epoch 116; Iter    65/  229] train: loss: 0.0996583
[Epoch 116; Iter    95/  229] train: loss: 0.1407408
[Epoch 116; Iter   125/  229] train: loss: 0.0868991
[Epoch 116; Iter   155/  229] train: loss: 0.1531374
[Epoch 116; Iter   185/  229] train: loss: 0.0891111
[Epoch 116; Iter   215/  229] train: loss: 0.1342496
[Epoch 116] ogbg-moltoxcast: 0.665779 val loss: 0.334271
[Epoch 116] ogbg-moltoxcast: 0.637335 test loss: 0.378662
[Epoch 117; Iter    16/  229] train: loss: 0.0934180
[Epoch 117; Iter    46/  229] train: loss: 0.0803237
[Epoch 117; Iter    76/  229] train: loss: 0.0855049
[Epoch 117; Iter   106/  229] train: loss: 0.0985208
[Epoch 117; Iter   136/  229] train: loss: 0.1312443
[Epoch 117; Iter   166/  229] train: loss: 0.1194689
[Epoch 117; Iter   196/  229] train: loss: 0.1366895
[Epoch 117; Iter   226/  229] train: loss: 0.1093076
[Epoch 117] ogbg-moltoxcast: 0.665087 val loss: 0.330796
[Epoch 117] ogbg-moltoxcast: 0.636153 test loss: 0.374912
[Epoch 118; Iter    27/  229] train: loss: 0.0784008
[Epoch 118; Iter    57/  229] train: loss: 0.0928823
[Epoch 118; Iter    87/  229] train: loss: 0.1081845
[Epoch 118; Iter   117/  229] train: loss: 0.1052869
[Epoch 118; Iter   147/  229] train: loss: 0.1112026
[Epoch 118; Iter   177/  229] train: loss: 0.1331611
[Epoch 118; Iter   207/  229] train: loss: 0.0982013
[Epoch 118] ogbg-moltoxcast: 0.665946 val loss: 0.331329
[Epoch 118] ogbg-moltoxcast: 0.636735 test loss: 0.374332
[Epoch 119; Iter     8/  229] train: loss: 0.0999019
[Epoch 119; Iter    38/  229] train: loss: 0.0813269
[Epoch 119; Iter    68/  229] train: loss: 0.0959553
[Epoch 119; Iter    98/  229] train: loss: 0.1049867
[Epoch 119; Iter   128/  229] train: loss: 0.1148734
[Epoch 119; Iter   158/  229] train: loss: 0.1307926
[Epoch 119; Iter   188/  229] train: loss: 0.1058354
[Epoch 119; Iter   218/  229] train: loss: 0.0611938
[Epoch 119] ogbg-moltoxcast: 0.667107 val loss: 0.337603
[Epoch 119] ogbg-moltoxcast: 0.635859 test loss: 0.376875
[Epoch 120; Iter    19/  229] train: loss: 0.0935381
[Epoch 120; Iter    49/  229] train: loss: 0.1032476
[Epoch 120; Iter    79/  229] train: loss: 0.0938198
[Epoch 120; Iter   109/  229] train: loss: 0.1781934
[Epoch 120; Iter   139/  229] train: loss: 0.0937322
[Epoch 120; Iter   169/  229] train: loss: 0.0870453
[Epoch 120; Iter   199/  229] train: loss: 0.0680377
[Epoch 120; Iter   229/  229] train: loss: 0.1123476
[Epoch 120] ogbg-moltoxcast: 0.666283 val loss: 0.331151
[Epoch 120] ogbg-moltoxcast: 0.636812 test loss: 0.375890
[Epoch 121; Iter    30/  229] train: loss: 0.0961396
[Epoch 121; Iter    60/  229] train: loss: 0.0863499
[Epoch 121; Iter    90/  229] train: loss: 0.1306654
[Epoch 121; Iter   120/  229] train: loss: 0.0896410
[Epoch 121; Iter   150/  229] train: loss: 0.2052250
[Epoch 121; Iter   180/  229] train: loss: 0.1031754
[Epoch 121; Iter   210/  229] train: loss: 0.1221960
[Epoch 121] ogbg-moltoxcast: 0.665364 val loss: 0.333050
[Epoch 121] ogbg-moltoxcast: 0.634620 test loss: 0.384572
[Epoch 122; Iter    11/  229] train: loss: 0.0745340
[Epoch 122; Iter    41/  229] train: loss: 0.1255721
[Epoch 122; Iter    71/  229] train: loss: 0.1362197
[Epoch 122; Iter   101/  229] train: loss: 0.1176419
[Epoch 122; Iter   131/  229] train: loss: 0.1208484
[Epoch 122; Iter   161/  229] train: loss: 0.1080162
[Epoch 122; Iter   191/  229] train: loss: 0.1413174
[Epoch 122; Iter   221/  229] train: loss: 0.0859433
[Epoch 122] ogbg-moltoxcast: 0.664640 val loss: 0.336802
[Epoch 122] ogbg-moltoxcast: 0.636999 test loss: 0.383044
[Epoch 123; Iter    22/  229] train: loss: 0.1109897
[Epoch 123; Iter    52/  229] train: loss: 0.0999587
[Epoch 123; Iter    82/  229] train: loss: 0.1037575
[Epoch 123; Iter   112/  229] train: loss: 0.1135560
[Epoch 123; Iter   142/  229] train: loss: 0.1153652
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 123; Iter   172/  229] train: loss: 0.0986568
[Epoch 123; Iter   202/  229] train: loss: 0.1039345
[Epoch 123] ogbg-moltoxcast: 0.678632 val loss: 0.328751
[Epoch 123] ogbg-moltoxcast: 0.643517 test loss: 0.363852
[Epoch 124; Iter     3/  229] train: loss: 0.1061364
[Epoch 124; Iter    33/  229] train: loss: 0.1417595
[Epoch 124; Iter    63/  229] train: loss: 0.0941841
[Epoch 124; Iter    93/  229] train: loss: 0.0982024
[Epoch 124; Iter   123/  229] train: loss: 0.0883906
[Epoch 124; Iter   153/  229] train: loss: 0.1496215
[Epoch 124; Iter   183/  229] train: loss: 0.1021488
[Epoch 124; Iter   213/  229] train: loss: 0.0975220
[Epoch 124] ogbg-moltoxcast: 0.678846 val loss: 0.310645
[Epoch 124] ogbg-moltoxcast: 0.641918 test loss: 0.368643
[Epoch 125; Iter    14/  229] train: loss: 0.0743530
[Epoch 125; Iter    44/  229] train: loss: 0.0563198
[Epoch 125; Iter    74/  229] train: loss: 0.1191535
[Epoch 125; Iter   104/  229] train: loss: 0.1400119
[Epoch 125; Iter   134/  229] train: loss: 0.1390398
[Epoch 125; Iter   164/  229] train: loss: 0.1118872
[Epoch 125; Iter   194/  229] train: loss: 0.1276802
[Epoch 125; Iter   224/  229] train: loss: 0.1146820
[Epoch 125] ogbg-moltoxcast: 0.682019 val loss: 0.310534
[Epoch 125] ogbg-moltoxcast: 0.643893 test loss: 0.365373
[Epoch 126; Iter    25/  229] train: loss: 0.1194351
[Epoch 126; Iter    55/  229] train: loss: 0.1285134
[Epoch 126; Iter    85/  229] train: loss: 0.0948766
[Epoch 126; Iter   115/  229] train: loss: 0.1292937
[Epoch 126; Iter   145/  229] train: loss: 0.1119196
[Epoch 126; Iter   175/  229] train: loss: 0.1347065
[Epoch 126; Iter   205/  229] train: loss: 0.1169570
[Epoch 126] ogbg-moltoxcast: 0.682686 val loss: 0.316908
[Epoch 126] ogbg-moltoxcast: 0.643425 test loss: 0.367277
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 126 epochs. Best model checkpoint was in epoch 66.
Statistics on  val_best_checkpoint
mean_pred: -3.5674049854278564
std_pred: 9.028000831604004
mean_targets: nan
std_targets: nan
prcauc: 0.40423551461224966
rocauc: 0.7049623505558441
ogbg-moltoxcast: 0.7049623505558441
OGBNanLabelBCEWithLogitsLoss: 0.3622966018216363
Statistics on  test
mean_pred: -3.1235640048980713
std_pred: 6.762199878692627
mean_targets: nan
std_targets: nan
prcauc: 0.34921146147795956
rocauc: 0.6467257819181246
ogbg-moltoxcast: 0.6467257819181246
OGBNanLabelBCEWithLogitsLoss: 0.3695095479488373
Statistics on  train
mean_pred: -3.78395676612854
std_pred: 2.9747021198272705
mean_targets: nan
std_targets: nan
prcauc: 0.6527357411499294
rocauc: 0.9118468618905686
ogbg-moltoxcast: 0.9118468618905686
OGBNanLabelBCEWithLogitsLoss: 0.11792583408964774
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.05.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.05.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.05.yml --seed 6 --device cuda:1
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 123; Iter   172/  229] train: loss: 0.1196784
[Epoch 123; Iter   202/  229] train: loss: 0.1243523
[Epoch 123] ogbg-moltoxcast: 0.663420 val loss: 0.336572
[Epoch 123] ogbg-moltoxcast: 0.634985 test loss: 0.386476
[Epoch 124; Iter     3/  229] train: loss: 0.0936531
[Epoch 124; Iter    33/  229] train: loss: 0.0788401
[Epoch 124; Iter    63/  229] train: loss: 0.1261753
[Epoch 124; Iter    93/  229] train: loss: 0.1699743
[Epoch 124; Iter   123/  229] train: loss: 0.0807087
[Epoch 124; Iter   153/  229] train: loss: 0.1176949
[Epoch 124; Iter   183/  229] train: loss: 0.1050992
[Epoch 124; Iter   213/  229] train: loss: 0.1323397
[Epoch 124] ogbg-moltoxcast: 0.663854 val loss: 0.338854
[Epoch 124] ogbg-moltoxcast: 0.636213 test loss: 0.381789
[Epoch 125; Iter    14/  229] train: loss: 0.0946138
[Epoch 125; Iter    44/  229] train: loss: 0.1388612
[Epoch 125; Iter    74/  229] train: loss: 0.1162807
[Epoch 125; Iter   104/  229] train: loss: 0.0941083
[Epoch 125; Iter   134/  229] train: loss: 0.1239519
[Epoch 125; Iter   164/  229] train: loss: 0.1109916
[Epoch 125; Iter   194/  229] train: loss: 0.1006044
[Epoch 125; Iter   224/  229] train: loss: 0.1126991
[Epoch 125] ogbg-moltoxcast: 0.663753 val loss: 0.331280
[Epoch 125] ogbg-moltoxcast: 0.636158 test loss: 0.381507
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 125 epochs. Best model checkpoint was in epoch 65.
Statistics on  val_best_checkpoint
mean_pred: -2.891116142272949
std_pred: 2.8272957801818848
mean_targets: nan
std_targets: nan
prcauc: 0.39436577239248294
rocauc: 0.6888118549133515
ogbg-moltoxcast: 0.6888118549133515
OGBNanLabelBCEWithLogitsLoss: 0.28620333558526534
Statistics on  test
mean_pred: -2.6403937339782715
std_pred: 2.818976402282715
mean_targets: nan
std_targets: nan
prcauc: 0.35917825864226927
rocauc: 0.6469237353483833
ogbg-moltoxcast: 0.6469237353483833
OGBNanLabelBCEWithLogitsLoss: 0.34219513216923025
Statistics on  train
mean_pred: -3.3300564289093018
std_pred: 2.9199001789093018
mean_targets: nan
std_targets: nan
prcauc: 0.6421931701723091
rocauc: 0.9069803946943196
ogbg-moltoxcast: 0.9069803946943196
OGBNanLabelBCEWithLogitsLoss: 0.12280903138448057
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.1.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.1.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.1.yml --seed 6 --device cuda:2
All runs completed.
[Epoch 92; Iter    11/  229] train: loss: 0.1292294
[Epoch 92; Iter    41/  229] train: loss: 0.1217996
[Epoch 92; Iter    71/  229] train: loss: 0.1165971
[Epoch 92; Iter   101/  229] train: loss: 0.1308777
[Epoch 92; Iter   131/  229] train: loss: 0.1256213
[Epoch 92; Iter   161/  229] train: loss: 0.0992934
[Epoch 92; Iter   191/  229] train: loss: 0.1210916
[Epoch 92; Iter   221/  229] train: loss: 0.1497909
[Epoch 92] ogbg-moltoxcast: 0.696858 val loss: 0.273744
[Epoch 92] ogbg-moltoxcast: 0.656875 test loss: 0.351118
[Epoch 93; Iter    22/  229] train: loss: 0.1074449
[Epoch 93; Iter    52/  229] train: loss: 0.1101982
[Epoch 93; Iter    82/  229] train: loss: 0.1647516
[Epoch 93; Iter   112/  229] train: loss: 0.1459069
[Epoch 93; Iter   142/  229] train: loss: 0.1202926
[Epoch 93; Iter   172/  229] train: loss: 0.1177341
[Epoch 93; Iter   202/  229] train: loss: 0.0934053
[Epoch 93] ogbg-moltoxcast: 0.695380 val loss: 0.279105
[Epoch 93] ogbg-moltoxcast: 0.654635 test loss: 0.349247
[Epoch 94; Iter     3/  229] train: loss: 0.1118335
[Epoch 94; Iter    33/  229] train: loss: 0.1171726
[Epoch 94; Iter    63/  229] train: loss: 0.1317889
[Epoch 94; Iter    93/  229] train: loss: 0.1112961
[Epoch 94; Iter   123/  229] train: loss: 0.1246783
[Epoch 94; Iter   153/  229] train: loss: 0.1907266
[Epoch 94; Iter   183/  229] train: loss: 0.1418182
[Epoch 94; Iter   213/  229] train: loss: 0.1046147
[Epoch 94] ogbg-moltoxcast: 0.698508 val loss: 0.276805
[Epoch 94] ogbg-moltoxcast: 0.660298 test loss: 0.345893
[Epoch 95; Iter    14/  229] train: loss: 0.1252926
[Epoch 95; Iter    44/  229] train: loss: 0.0963469
[Epoch 95; Iter    74/  229] train: loss: 0.1356076
[Epoch 95; Iter   104/  229] train: loss: 0.1327126
[Epoch 95; Iter   134/  229] train: loss: 0.0935210
[Epoch 95; Iter   164/  229] train: loss: 0.1122153
[Epoch 95; Iter   194/  229] train: loss: 0.1352840
[Epoch 95; Iter   224/  229] train: loss: 0.1489986
[Epoch 95] ogbg-moltoxcast: 0.697341 val loss: 0.279076
[Epoch 95] ogbg-moltoxcast: 0.660162 test loss: 0.342788
[Epoch 96; Iter    25/  229] train: loss: 0.1271013
[Epoch 96; Iter    55/  229] train: loss: 0.1098771
[Epoch 96; Iter    85/  229] train: loss: 0.0982753
[Epoch 96; Iter   115/  229] train: loss: 0.1451966
[Epoch 96; Iter   145/  229] train: loss: 0.1112264
[Epoch 96; Iter   175/  229] train: loss: 0.0945392
[Epoch 96; Iter   205/  229] train: loss: 0.1511129
[Epoch 96] ogbg-moltoxcast: 0.697155 val loss: 0.276000
[Epoch 96] ogbg-moltoxcast: 0.656811 test loss: 0.356574
[Epoch 97; Iter     6/  229] train: loss: 0.1268300
[Epoch 97; Iter    36/  229] train: loss: 0.1048533
[Epoch 97; Iter    66/  229] train: loss: 0.0884014
[Epoch 97; Iter    96/  229] train: loss: 0.0980792
[Epoch 97; Iter   126/  229] train: loss: 0.1274617
[Epoch 97; Iter   156/  229] train: loss: 0.1046612
[Epoch 97; Iter   186/  229] train: loss: 0.0979596
[Epoch 97; Iter   216/  229] train: loss: 0.1940637
[Epoch 97] ogbg-moltoxcast: 0.694454 val loss: 0.277427
[Epoch 97] ogbg-moltoxcast: 0.658643 test loss: 0.343222
[Epoch 98; Iter    17/  229] train: loss: 0.1241342
[Epoch 98; Iter    47/  229] train: loss: 0.1263150
[Epoch 98; Iter    77/  229] train: loss: 0.1251816
[Epoch 98; Iter   107/  229] train: loss: 0.1048472
[Epoch 98; Iter   137/  229] train: loss: 0.1554283
[Epoch 98; Iter   167/  229] train: loss: 0.1035106
[Epoch 98; Iter   197/  229] train: loss: 0.1085134
[Epoch 98; Iter   227/  229] train: loss: 0.1403935
[Epoch 98] ogbg-moltoxcast: 0.698509 val loss: 0.276734
[Epoch 98] ogbg-moltoxcast: 0.660846 test loss: 0.341685
[Epoch 99; Iter    28/  229] train: loss: 0.1300303
[Epoch 99; Iter    58/  229] train: loss: 0.1389899
[Epoch 99; Iter    88/  229] train: loss: 0.1168287
[Epoch 99; Iter   118/  229] train: loss: 0.1037012
[Epoch 99; Iter   148/  229] train: loss: 0.1957542
[Epoch 99; Iter   178/  229] train: loss: 0.1533561
[Epoch 99; Iter   208/  229] train: loss: 0.1239918
[Epoch 99] ogbg-moltoxcast: 0.697250 val loss: 0.274337
[Epoch 99] ogbg-moltoxcast: 0.661823 test loss: 0.340489
[Epoch 100; Iter     9/  229] train: loss: 0.0897937
[Epoch 100; Iter    39/  229] train: loss: 0.1362778
[Epoch 100; Iter    69/  229] train: loss: 0.1195849
[Epoch 100; Iter    99/  229] train: loss: 0.1131742
[Epoch 100; Iter   129/  229] train: loss: 0.1713758
[Epoch 100; Iter   159/  229] train: loss: 0.1240049
[Epoch 100; Iter   189/  229] train: loss: 0.1191873
[Epoch 100; Iter   219/  229] train: loss: 0.1165839
[Epoch 100] ogbg-moltoxcast: 0.698208 val loss: 0.278804
[Epoch 100] ogbg-moltoxcast: 0.663291 test loss: 0.343395
[Epoch 101; Iter    20/  229] train: loss: 0.1200845
[Epoch 101; Iter    50/  229] train: loss: 0.0953071
[Epoch 101; Iter    80/  229] train: loss: 0.1123767
[Epoch 101; Iter   110/  229] train: loss: 0.1219688
[Epoch 101; Iter   140/  229] train: loss: 0.0753057
[Epoch 101; Iter   170/  229] train: loss: 0.1277515
[Epoch 101; Iter   200/  229] train: loss: 0.1023848
[Epoch 101] ogbg-moltoxcast: 0.699500 val loss: 0.277094
[Epoch 101] ogbg-moltoxcast: 0.657860 test loss: 0.343886
[Epoch 102; Iter     1/  229] train: loss: 0.1338391
[Epoch 102; Iter    31/  229] train: loss: 0.0829448
[Epoch 102; Iter    61/  229] train: loss: 0.0889985
[Epoch 102; Iter    91/  229] train: loss: 0.1127202
[Epoch 102; Iter   121/  229] train: loss: 0.1149739
[Epoch 102; Iter   151/  229] train: loss: 0.1148907
[Epoch 102; Iter   181/  229] train: loss: 0.1201207
[Epoch 102; Iter   211/  229] train: loss: 0.1184935
[Epoch 102] ogbg-moltoxcast: 0.698984 val loss: 0.277711
[Epoch 102] ogbg-moltoxcast: 0.661524 test loss: 0.342663
[Epoch 103; Iter    12/  229] train: loss: 0.0811435
[Epoch 103; Iter    42/  229] train: loss: 0.1197675
[Epoch 103; Iter    72/  229] train: loss: 0.1259901
[Epoch 103; Iter   102/  229] train: loss: 0.1344966
[Epoch 103; Iter   132/  229] train: loss: 0.1185766
[Epoch 103; Iter   162/  229] train: loss: 0.1153123
[Epoch 103; Iter   192/  229] train: loss: 0.1375139
[Epoch 103; Iter   222/  229] train: loss: 0.1252893
[Epoch 103] ogbg-moltoxcast: 0.693877 val loss: 0.284432
[Epoch 103] ogbg-moltoxcast: 0.660840 test loss: 0.348813
[Epoch 104; Iter    23/  229] train: loss: 0.1121428
[Epoch 104; Iter    53/  229] train: loss: 0.1168635
[Epoch 104; Iter    83/  229] train: loss: 0.0966497
[Epoch 104; Iter   113/  229] train: loss: 0.1457310
[Epoch 104; Iter   143/  229] train: loss: 0.1126435
[Epoch 104; Iter   173/  229] train: loss: 0.1058182
[Epoch 104; Iter   203/  229] train: loss: 0.0994456
[Epoch 104] ogbg-moltoxcast: 0.696131 val loss: 0.278759
[Epoch 104] ogbg-moltoxcast: 0.659999 test loss: 0.345285
[Epoch 105; Iter     4/  229] train: loss: 0.1354399
[Epoch 105; Iter    34/  229] train: loss: 0.1122510
[Epoch 105; Iter    64/  229] train: loss: 0.0988998
[Epoch 105; Iter    94/  229] train: loss: 0.1118054
[Epoch 105; Iter   124/  229] train: loss: 0.1418675
[Epoch 105; Iter   154/  229] train: loss: 0.1136611
[Epoch 105; Iter   184/  229] train: loss: 0.1092121
[Epoch 105; Iter   214/  229] train: loss: 0.1079423
[Epoch 105] ogbg-moltoxcast: 0.698401 val loss: 0.276385
[Epoch 105] ogbg-moltoxcast: 0.660506 test loss: 0.343412
[Epoch 106; Iter    15/  229] train: loss: 0.1182580
[Epoch 106; Iter    45/  229] train: loss: 0.0964439
[Epoch 106; Iter    75/  229] train: loss: 0.1335349
[Epoch 106; Iter   105/  229] train: loss: 0.1133113
[Epoch 106; Iter   135/  229] train: loss: 0.1209641
[Epoch 106; Iter   165/  229] train: loss: 0.1368629
[Epoch 106; Iter   195/  229] train: loss: 0.1139708
[Epoch 106; Iter   225/  229] train: loss: 0.1269635
[Epoch 106] ogbg-moltoxcast: 0.695461 val loss: 0.277264
[Epoch 106] ogbg-moltoxcast: 0.653466 test loss: 0.344373
[Epoch 107; Iter    26/  229] train: loss: 0.1320250
[Epoch 107; Iter    56/  229] train: loss: 0.1172779
[Epoch 107; Iter    86/  229] train: loss: 0.1039138
[Epoch 107; Iter   116/  229] train: loss: 0.1036017
[Epoch 107; Iter   146/  229] train: loss: 0.0851003
[Epoch 107; Iter   176/  229] train: loss: 0.1340282
[Epoch 107; Iter   206/  229] train: loss: 0.0934973
[Epoch 107] ogbg-moltoxcast: 0.699680 val loss: 0.279455
[Epoch 92; Iter    11/  229] train: loss: 0.1187560
[Epoch 92; Iter    41/  229] train: loss: 0.1083223
[Epoch 92; Iter    71/  229] train: loss: 0.1271501
[Epoch 92; Iter   101/  229] train: loss: 0.1049524
[Epoch 92; Iter   131/  229] train: loss: 0.0908673
[Epoch 92; Iter   161/  229] train: loss: 0.0775348
[Epoch 92; Iter   191/  229] train: loss: 0.1054518
[Epoch 92; Iter   221/  229] train: loss: 0.1250457
[Epoch 92] ogbg-moltoxcast: 0.687975 val loss: 0.281624
[Epoch 92] ogbg-moltoxcast: 0.653814 test loss: 0.354392
[Epoch 93; Iter    22/  229] train: loss: 0.0858270
[Epoch 93; Iter    52/  229] train: loss: 0.0764178
[Epoch 93; Iter    82/  229] train: loss: 0.1104727
[Epoch 93; Iter   112/  229] train: loss: 0.1184279
[Epoch 93; Iter   142/  229] train: loss: 0.0947430
[Epoch 93; Iter   172/  229] train: loss: 0.1488714
[Epoch 93; Iter   202/  229] train: loss: 0.1205499
[Epoch 93] ogbg-moltoxcast: 0.689803 val loss: 0.280226
[Epoch 93] ogbg-moltoxcast: 0.650039 test loss: 0.353568
[Epoch 94; Iter     3/  229] train: loss: 0.1801305
[Epoch 94; Iter    33/  229] train: loss: 0.1550138
[Epoch 94; Iter    63/  229] train: loss: 0.1454501
[Epoch 94; Iter    93/  229] train: loss: 0.0816113
[Epoch 94; Iter   123/  229] train: loss: 0.1003719
[Epoch 94; Iter   153/  229] train: loss: 0.1179535
[Epoch 94; Iter   183/  229] train: loss: 0.1263321
[Epoch 94; Iter   213/  229] train: loss: 0.1569184
[Epoch 94] ogbg-moltoxcast: 0.681612 val loss: 0.283587
[Epoch 94] ogbg-moltoxcast: 0.652845 test loss: 0.351415
[Epoch 95; Iter    14/  229] train: loss: 0.1205516
[Epoch 95; Iter    44/  229] train: loss: 0.1258911
[Epoch 95; Iter    74/  229] train: loss: 0.1626422
[Epoch 95; Iter   104/  229] train: loss: 0.1205065
[Epoch 95; Iter   134/  229] train: loss: 0.1357758
[Epoch 95; Iter   164/  229] train: loss: 0.1032801
[Epoch 95; Iter   194/  229] train: loss: 0.0807499
[Epoch 95; Iter   224/  229] train: loss: 0.1182271
[Epoch 95] ogbg-moltoxcast: 0.689940 val loss: 0.280148
[Epoch 95] ogbg-moltoxcast: 0.650740 test loss: 0.354748
[Epoch 96; Iter    25/  229] train: loss: 0.1257520
[Epoch 96; Iter    55/  229] train: loss: 0.0626119
[Epoch 96; Iter    85/  229] train: loss: 0.1287304
[Epoch 96; Iter   115/  229] train: loss: 0.1421489
[Epoch 96; Iter   145/  229] train: loss: 0.1330744
[Epoch 96; Iter   175/  229] train: loss: 0.1357942
[Epoch 96; Iter   205/  229] train: loss: 0.1083229
[Epoch 96] ogbg-moltoxcast: 0.687390 val loss: 0.283075
[Epoch 96] ogbg-moltoxcast: 0.651912 test loss: 0.355423
[Epoch 97; Iter     6/  229] train: loss: 0.1168026
[Epoch 97; Iter    36/  229] train: loss: 0.0982032
[Epoch 97; Iter    66/  229] train: loss: 0.0993629
[Epoch 97; Iter    96/  229] train: loss: 0.1005053
[Epoch 97; Iter   126/  229] train: loss: 0.1368974
[Epoch 97; Iter   156/  229] train: loss: 0.1155998
[Epoch 97; Iter   186/  229] train: loss: 0.0894902
[Epoch 97; Iter   216/  229] train: loss: 0.1242502
[Epoch 97] ogbg-moltoxcast: 0.687281 val loss: 0.279917
[Epoch 97] ogbg-moltoxcast: 0.653492 test loss: 0.351600
[Epoch 98; Iter    17/  229] train: loss: 0.1256465
[Epoch 98; Iter    47/  229] train: loss: 0.1160738
[Epoch 98; Iter    77/  229] train: loss: 0.1003441
[Epoch 98; Iter   107/  229] train: loss: 0.1063578
[Epoch 98; Iter   137/  229] train: loss: 0.1102688
[Epoch 98; Iter   167/  229] train: loss: 0.1401103
[Epoch 98; Iter   197/  229] train: loss: 0.1430339
[Epoch 98; Iter   227/  229] train: loss: 0.1162082
[Epoch 98] ogbg-moltoxcast: 0.685714 val loss: 0.281041
[Epoch 98] ogbg-moltoxcast: 0.650095 test loss: 0.355155
[Epoch 99; Iter    28/  229] train: loss: 0.1362960
[Epoch 99; Iter    58/  229] train: loss: 0.1349351
[Epoch 99; Iter    88/  229] train: loss: 0.1526707
[Epoch 99; Iter   118/  229] train: loss: 0.1354601
[Epoch 99; Iter   148/  229] train: loss: 0.1380927
[Epoch 99; Iter   178/  229] train: loss: 0.1880792
[Epoch 99; Iter   208/  229] train: loss: 0.0595065
[Epoch 99] ogbg-moltoxcast: 0.687208 val loss: 0.283173
[Epoch 99] ogbg-moltoxcast: 0.651791 test loss: 0.354508
[Epoch 100; Iter     9/  229] train: loss: 0.0926916
[Epoch 100; Iter    39/  229] train: loss: 0.1129283
[Epoch 100; Iter    69/  229] train: loss: 0.0910338
[Epoch 100; Iter    99/  229] train: loss: 0.1042823
[Epoch 100; Iter   129/  229] train: loss: 0.1083554
[Epoch 100; Iter   159/  229] train: loss: 0.0997846
[Epoch 100; Iter   189/  229] train: loss: 0.1146813
[Epoch 100; Iter   219/  229] train: loss: 0.1092638
[Epoch 100] ogbg-moltoxcast: 0.687717 val loss: 0.286664
[Epoch 100] ogbg-moltoxcast: 0.654862 test loss: 0.358876
[Epoch 101; Iter    20/  229] train: loss: 0.1467869
[Epoch 101; Iter    50/  229] train: loss: 0.1130927
[Epoch 101; Iter    80/  229] train: loss: 0.0923104
[Epoch 101; Iter   110/  229] train: loss: 0.1141167
[Epoch 101; Iter   140/  229] train: loss: 0.1281588
[Epoch 101; Iter   170/  229] train: loss: 0.1181900
[Epoch 101; Iter   200/  229] train: loss: 0.1611459
[Epoch 101] ogbg-moltoxcast: 0.685723 val loss: 0.281134
[Epoch 101] ogbg-moltoxcast: 0.647766 test loss: 0.357932
[Epoch 102; Iter     1/  229] train: loss: 0.1015825
[Epoch 102; Iter    31/  229] train: loss: 0.1120223
[Epoch 102; Iter    61/  229] train: loss: 0.1630802
[Epoch 102; Iter    91/  229] train: loss: 0.1520686
[Epoch 102; Iter   121/  229] train: loss: 0.1271277
[Epoch 102; Iter   151/  229] train: loss: 0.1083720
[Epoch 102; Iter   181/  229] train: loss: 0.1612492
[Epoch 102; Iter   211/  229] train: loss: 0.1118623
[Epoch 102] ogbg-moltoxcast: 0.684656 val loss: 0.284447
[Epoch 102] ogbg-moltoxcast: 0.648591 test loss: 0.355419
[Epoch 103; Iter    12/  229] train: loss: 0.1008544
[Epoch 103; Iter    42/  229] train: loss: 0.1160339
[Epoch 103; Iter    72/  229] train: loss: 0.0947421
[Epoch 103; Iter   102/  229] train: loss: 0.1655592
[Epoch 103; Iter   132/  229] train: loss: 0.1478126
[Epoch 103; Iter   162/  229] train: loss: 0.0744369
[Epoch 103; Iter   192/  229] train: loss: 0.1246017
[Epoch 103; Iter   222/  229] train: loss: 0.1483020
[Epoch 103] ogbg-moltoxcast: 0.684532 val loss: 0.286259
[Epoch 103] ogbg-moltoxcast: 0.651813 test loss: 0.355733
[Epoch 104; Iter    23/  229] train: loss: 0.1208400
[Epoch 104; Iter    53/  229] train: loss: 0.0773816
[Epoch 104; Iter    83/  229] train: loss: 0.1090814
[Epoch 104; Iter   113/  229] train: loss: 0.1750838
[Epoch 104; Iter   143/  229] train: loss: 0.1399985
[Epoch 104; Iter   173/  229] train: loss: 0.1254979
[Epoch 104; Iter   203/  229] train: loss: 0.1128108
[Epoch 104] ogbg-moltoxcast: 0.684639 val loss: 0.282655
[Epoch 104] ogbg-moltoxcast: 0.650477 test loss: 0.355385
[Epoch 105; Iter     4/  229] train: loss: 0.1139829
[Epoch 105; Iter    34/  229] train: loss: 0.1104883
[Epoch 105; Iter    64/  229] train: loss: 0.1123291
[Epoch 105; Iter    94/  229] train: loss: 0.1132484
[Epoch 105; Iter   124/  229] train: loss: 0.1404185
[Epoch 105; Iter   154/  229] train: loss: 0.1000932
[Epoch 105; Iter   184/  229] train: loss: 0.1066381
[Epoch 105; Iter   214/  229] train: loss: 0.1340756
[Epoch 105] ogbg-moltoxcast: 0.685478 val loss: 0.285610
[Epoch 105] ogbg-moltoxcast: 0.648855 test loss: 0.360349
[Epoch 106; Iter    15/  229] train: loss: 0.1069446
[Epoch 106; Iter    45/  229] train: loss: 0.0980514
[Epoch 106; Iter    75/  229] train: loss: 0.1583915
[Epoch 106; Iter   105/  229] train: loss: 0.1349980
[Epoch 106; Iter   135/  229] train: loss: 0.1233341
[Epoch 106; Iter   165/  229] train: loss: 0.1350639
[Epoch 106; Iter   195/  229] train: loss: 0.1270922
[Epoch 106; Iter   225/  229] train: loss: 0.1252269
[Epoch 106] ogbg-moltoxcast: 0.684026 val loss: 0.285599
[Epoch 106] ogbg-moltoxcast: 0.645578 test loss: 0.361130
[Epoch 107; Iter    26/  229] train: loss: 0.0982574
[Epoch 107; Iter    56/  229] train: loss: 0.1094523
[Epoch 107; Iter    86/  229] train: loss: 0.1076241
[Epoch 107; Iter   116/  229] train: loss: 0.1167659
[Epoch 107; Iter   146/  229] train: loss: 0.0968785
[Epoch 107; Iter   176/  229] train: loss: 0.1119969
[Epoch 107; Iter   206/  229] train: loss: 0.1601965
[Epoch 107] ogbg-moltoxcast: 0.684408 val loss: 0.288222
[Epoch 92; Iter    11/  229] train: loss: 0.1343376
[Epoch 92; Iter    41/  229] train: loss: 0.1488078
[Epoch 92; Iter    71/  229] train: loss: 0.0998321
[Epoch 92; Iter   101/  229] train: loss: 0.1397156
[Epoch 92; Iter   131/  229] train: loss: 0.1029089
[Epoch 92; Iter   161/  229] train: loss: 0.1209492
[Epoch 92; Iter   191/  229] train: loss: 0.1100992
[Epoch 92; Iter   221/  229] train: loss: 0.1160488
[Epoch 92] ogbg-moltoxcast: 0.674236 val loss: 0.277983
[Epoch 92] ogbg-moltoxcast: 0.652017 test loss: 0.330460
[Epoch 93; Iter    22/  229] train: loss: 0.1291258
[Epoch 93; Iter    52/  229] train: loss: 0.1197693
[Epoch 93; Iter    82/  229] train: loss: 0.0794206
[Epoch 93; Iter   112/  229] train: loss: 0.1223762
[Epoch 93; Iter   142/  229] train: loss: 0.1485756
[Epoch 93; Iter   172/  229] train: loss: 0.1047859
[Epoch 93; Iter   202/  229] train: loss: 0.1086555
[Epoch 93] ogbg-moltoxcast: 0.677078 val loss: 0.276343
[Epoch 93] ogbg-moltoxcast: 0.650457 test loss: 0.332866
[Epoch 94; Iter     3/  229] train: loss: 0.1150509
[Epoch 94; Iter    33/  229] train: loss: 0.1267194
[Epoch 94; Iter    63/  229] train: loss: 0.1007092
[Epoch 94; Iter    93/  229] train: loss: 0.1639745
[Epoch 94; Iter   123/  229] train: loss: 0.1418233
[Epoch 94; Iter   153/  229] train: loss: 0.0831223
[Epoch 94; Iter   183/  229] train: loss: 0.0984886
[Epoch 94; Iter   213/  229] train: loss: 0.1093151
[Epoch 94] ogbg-moltoxcast: 0.671472 val loss: 0.279045
[Epoch 94] ogbg-moltoxcast: 0.645580 test loss: 0.332893
[Epoch 95; Iter    14/  229] train: loss: 0.1318354
[Epoch 95; Iter    44/  229] train: loss: 0.1238549
[Epoch 95; Iter    74/  229] train: loss: 0.1092536
[Epoch 95; Iter   104/  229] train: loss: 0.1025706
[Epoch 95; Iter   134/  229] train: loss: 0.0818360
[Epoch 95; Iter   164/  229] train: loss: 0.1456510
[Epoch 95; Iter   194/  229] train: loss: 0.1263645
[Epoch 95; Iter   224/  229] train: loss: 0.1133200
[Epoch 95] ogbg-moltoxcast: 0.675151 val loss: 0.279519
[Epoch 95] ogbg-moltoxcast: 0.651530 test loss: 0.330729
[Epoch 96; Iter    25/  229] train: loss: 0.1332174
[Epoch 96; Iter    55/  229] train: loss: 0.1213979
[Epoch 96; Iter    85/  229] train: loss: 0.1243257
[Epoch 96; Iter   115/  229] train: loss: 0.0975164
[Epoch 96; Iter   145/  229] train: loss: 0.1215164
[Epoch 96; Iter   175/  229] train: loss: 0.1081564
[Epoch 96; Iter   205/  229] train: loss: 0.1174897
[Epoch 96] ogbg-moltoxcast: 0.677136 val loss: 0.276421
[Epoch 96] ogbg-moltoxcast: 0.653364 test loss: 0.333792
[Epoch 97; Iter     6/  229] train: loss: 0.0740147
[Epoch 97; Iter    36/  229] train: loss: 0.1342587
[Epoch 97; Iter    66/  229] train: loss: 0.0983376
[Epoch 97; Iter    96/  229] train: loss: 0.1689702
[Epoch 97; Iter   126/  229] train: loss: 0.0919800
[Epoch 97; Iter   156/  229] train: loss: 0.0955745
[Epoch 97; Iter   186/  229] train: loss: 0.1192633
[Epoch 97; Iter   216/  229] train: loss: 0.0963531
[Epoch 97] ogbg-moltoxcast: 0.680207 val loss: 0.276447
[Epoch 97] ogbg-moltoxcast: 0.652296 test loss: 0.332253
[Epoch 98; Iter    17/  229] train: loss: 0.1776854
[Epoch 98; Iter    47/  229] train: loss: 0.1291455
[Epoch 98; Iter    77/  229] train: loss: 0.1400002
[Epoch 98; Iter   107/  229] train: loss: 0.1215900
[Epoch 98; Iter   137/  229] train: loss: 0.1000035
[Epoch 98; Iter   167/  229] train: loss: 0.0694948
[Epoch 98; Iter   197/  229] train: loss: 0.1109997
[Epoch 98; Iter   227/  229] train: loss: 0.1538204
[Epoch 98] ogbg-moltoxcast: 0.673415 val loss: 0.279635
[Epoch 98] ogbg-moltoxcast: 0.651171 test loss: 0.332961
[Epoch 99; Iter    28/  229] train: loss: 0.1431453
[Epoch 99; Iter    58/  229] train: loss: 0.0874426
[Epoch 99; Iter    88/  229] train: loss: 0.1198438
[Epoch 99; Iter   118/  229] train: loss: 0.1429842
[Epoch 99; Iter   148/  229] train: loss: 0.1617392
[Epoch 99; Iter   178/  229] train: loss: 0.1198614
[Epoch 99; Iter   208/  229] train: loss: 0.1315317
[Epoch 99] ogbg-moltoxcast: 0.678720 val loss: 0.278894
[Epoch 99] ogbg-moltoxcast: 0.653458 test loss: 0.333954
[Epoch 100; Iter     9/  229] train: loss: 0.0954384
[Epoch 100; Iter    39/  229] train: loss: 0.1378721
[Epoch 100; Iter    69/  229] train: loss: 0.1192183
[Epoch 100; Iter    99/  229] train: loss: 0.1078755
[Epoch 100; Iter   129/  229] train: loss: 0.1360901
[Epoch 100; Iter   159/  229] train: loss: 0.1196422
[Epoch 100; Iter   189/  229] train: loss: 0.1319164
[Epoch 100; Iter   219/  229] train: loss: 0.2074473
[Epoch 100] ogbg-moltoxcast: 0.678233 val loss: 0.280988
[Epoch 100] ogbg-moltoxcast: 0.653861 test loss: 0.335180
[Epoch 101; Iter    20/  229] train: loss: 0.1104443
[Epoch 101; Iter    50/  229] train: loss: 0.1270816
[Epoch 101; Iter    80/  229] train: loss: 0.1002885
[Epoch 101; Iter   110/  229] train: loss: 0.1416470
[Epoch 101; Iter   140/  229] train: loss: 0.1310685
[Epoch 101; Iter   170/  229] train: loss: 0.0981144
[Epoch 101; Iter   200/  229] train: loss: 0.1125111
[Epoch 101] ogbg-moltoxcast: 0.678647 val loss: 0.283661
[Epoch 101] ogbg-moltoxcast: 0.655443 test loss: 0.337416
[Epoch 102; Iter     1/  229] train: loss: 0.1285636
[Epoch 102; Iter    31/  229] train: loss: 0.1005315
[Epoch 102; Iter    61/  229] train: loss: 0.1450377
[Epoch 102; Iter    91/  229] train: loss: 0.1110113
[Epoch 102; Iter   121/  229] train: loss: 0.1071288
[Epoch 102; Iter   151/  229] train: loss: 0.1099132
[Epoch 102; Iter   181/  229] train: loss: 0.0937910
[Epoch 102; Iter   211/  229] train: loss: 0.1359316
[Epoch 102] ogbg-moltoxcast: 0.677565 val loss: 0.283097
[Epoch 102] ogbg-moltoxcast: 0.650440 test loss: 0.337269
[Epoch 103; Iter    12/  229] train: loss: 0.1084981
[Epoch 103; Iter    42/  229] train: loss: 0.1235829
[Epoch 103; Iter    72/  229] train: loss: 0.1105831
[Epoch 103; Iter   102/  229] train: loss: 0.1327784
[Epoch 103; Iter   132/  229] train: loss: 0.1035737
[Epoch 103; Iter   162/  229] train: loss: 0.1647682
[Epoch 103; Iter   192/  229] train: loss: 0.1112699
[Epoch 103; Iter   222/  229] train: loss: 0.1304161
[Epoch 103] ogbg-moltoxcast: 0.673402 val loss: 0.284103
[Epoch 103] ogbg-moltoxcast: 0.649747 test loss: 0.340163
[Epoch 104; Iter    23/  229] train: loss: 0.1076276
[Epoch 104; Iter    53/  229] train: loss: 0.0949390
[Epoch 104; Iter    83/  229] train: loss: 0.1174227
[Epoch 104; Iter   113/  229] train: loss: 0.0989882
[Epoch 104; Iter   143/  229] train: loss: 0.0895317
[Epoch 104; Iter   173/  229] train: loss: 0.1014163
[Epoch 104; Iter   203/  229] train: loss: 0.1345701
[Epoch 104] ogbg-moltoxcast: 0.677900 val loss: 0.282162
[Epoch 104] ogbg-moltoxcast: 0.651199 test loss: 0.340231
[Epoch 105; Iter     4/  229] train: loss: 0.1128015
[Epoch 105; Iter    34/  229] train: loss: 0.1002705
[Epoch 105; Iter    64/  229] train: loss: 0.1120539
[Epoch 105; Iter    94/  229] train: loss: 0.1147564
[Epoch 105; Iter   124/  229] train: loss: 0.0827798
[Epoch 105; Iter   154/  229] train: loss: 0.1031407
[Epoch 105; Iter   184/  229] train: loss: 0.1251205
[Epoch 105; Iter   214/  229] train: loss: 0.1382466
[Epoch 105] ogbg-moltoxcast: 0.679742 val loss: 0.286865
[Epoch 105] ogbg-moltoxcast: 0.652860 test loss: 0.342653
[Epoch 106; Iter    15/  229] train: loss: 0.0833461
[Epoch 106; Iter    45/  229] train: loss: 0.0869712
[Epoch 106; Iter    75/  229] train: loss: 0.1097369
[Epoch 106; Iter   105/  229] train: loss: 0.0960715
[Epoch 106; Iter   135/  229] train: loss: 0.1145002
[Epoch 106; Iter   165/  229] train: loss: 0.1020369
[Epoch 106; Iter   195/  229] train: loss: 0.1667242
[Epoch 106; Iter   225/  229] train: loss: 0.1341731
[Epoch 106] ogbg-moltoxcast: 0.676824 val loss: 0.284237
[Epoch 106] ogbg-moltoxcast: 0.652277 test loss: 0.338768
[Epoch 107; Iter    26/  229] train: loss: 0.0978217
[Epoch 107; Iter    56/  229] train: loss: 0.1169086
[Epoch 107; Iter    86/  229] train: loss: 0.1175827
[Epoch 107; Iter   116/  229] train: loss: 0.1275808
[Epoch 107; Iter   146/  229] train: loss: 0.1106245
[Epoch 107; Iter   176/  229] train: loss: 0.1559236
[Epoch 107; Iter   206/  229] train: loss: 0.1246511
[Epoch 107] ogbg-moltoxcast: 0.676298 val loss: 0.280204
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.656100 test loss: 0.349696
[Epoch 108; Iter     7/  229] train: loss: 0.1093826
[Epoch 108; Iter    37/  229] train: loss: 0.1545057
[Epoch 108; Iter    67/  229] train: loss: 0.1144582
[Epoch 108; Iter    97/  229] train: loss: 0.1260127
[Epoch 108; Iter   127/  229] train: loss: 0.1844225
[Epoch 108; Iter   157/  229] train: loss: 0.0932831
[Epoch 108; Iter   187/  229] train: loss: 0.0908078
[Epoch 108; Iter   217/  229] train: loss: 0.0975915
[Epoch 108] ogbg-moltoxcast: 0.694173 val loss: 0.281820
[Epoch 108] ogbg-moltoxcast: 0.657137 test loss: 0.349019
[Epoch 109; Iter    18/  229] train: loss: 0.1239836
[Epoch 109; Iter    48/  229] train: loss: 0.1197812
[Epoch 109; Iter    78/  229] train: loss: 0.1150939
[Epoch 109; Iter   108/  229] train: loss: 0.1421224
[Epoch 109; Iter   138/  229] train: loss: 0.1122934
[Epoch 109; Iter   168/  229] train: loss: 0.1406339
[Epoch 109; Iter   198/  229] train: loss: 0.1068403
[Epoch 109; Iter   228/  229] train: loss: 0.0812738
[Epoch 109] ogbg-moltoxcast: 0.687831 val loss: 0.281707
[Epoch 109] ogbg-moltoxcast: 0.656116 test loss: 0.347876
[Epoch 110; Iter    29/  229] train: loss: 0.0716366
[Epoch 110; Iter    59/  229] train: loss: 0.0878100
[Epoch 110; Iter    89/  229] train: loss: 0.0813315
[Epoch 110; Iter   119/  229] train: loss: 0.1226335
[Epoch 110; Iter   149/  229] train: loss: 0.0926206
[Epoch 110; Iter   179/  229] train: loss: 0.1556730
[Epoch 110; Iter   209/  229] train: loss: 0.0933196
[Epoch 110] ogbg-moltoxcast: 0.690002 val loss: 0.283472
[Epoch 110] ogbg-moltoxcast: 0.661304 test loss: 0.347495
[Epoch 111; Iter    10/  229] train: loss: 0.1298303
[Epoch 111; Iter    40/  229] train: loss: 0.0860884
[Epoch 111; Iter    70/  229] train: loss: 0.1024432
[Epoch 111; Iter   100/  229] train: loss: 0.1321451
[Epoch 111; Iter   130/  229] train: loss: 0.1062815
[Epoch 111; Iter   160/  229] train: loss: 0.1432560
[Epoch 111; Iter   190/  229] train: loss: 0.1075261
[Epoch 111; Iter   220/  229] train: loss: 0.1010944
[Epoch 111] ogbg-moltoxcast: 0.693433 val loss: 0.284304
[Epoch 111] ogbg-moltoxcast: 0.660315 test loss: 0.352119
[Epoch 112; Iter    21/  229] train: loss: 0.1171107
[Epoch 112; Iter    51/  229] train: loss: 0.1109782
[Epoch 112; Iter    81/  229] train: loss: 0.0879602
[Epoch 112; Iter   111/  229] train: loss: 0.1062869
[Epoch 112; Iter   141/  229] train: loss: 0.1080300
[Epoch 112; Iter   171/  229] train: loss: 0.1382726
[Epoch 112; Iter   201/  229] train: loss: 0.0934282
[Epoch 112] ogbg-moltoxcast: 0.695096 val loss: 0.284531
[Epoch 112] ogbg-moltoxcast: 0.660379 test loss: 0.349659
[Epoch 113; Iter     2/  229] train: loss: 0.1567269
[Epoch 113; Iter    32/  229] train: loss: 0.0917371
[Epoch 113; Iter    62/  229] train: loss: 0.1440369
[Epoch 113; Iter    92/  229] train: loss: 0.1065491
[Epoch 113; Iter   122/  229] train: loss: 0.1272752
[Epoch 113; Iter   152/  229] train: loss: 0.0947036
[Epoch 113; Iter   182/  229] train: loss: 0.1117293
[Epoch 113; Iter   212/  229] train: loss: 0.1695380
[Epoch 113] ogbg-moltoxcast: 0.693276 val loss: 0.284106
[Epoch 113] ogbg-moltoxcast: 0.660048 test loss: 0.348388
[Epoch 114; Iter    13/  229] train: loss: 0.0884683
[Epoch 114; Iter    43/  229] train: loss: 0.1271594
[Epoch 114; Iter    73/  229] train: loss: 0.1479566
[Epoch 114; Iter   103/  229] train: loss: 0.1074242
[Epoch 114; Iter   133/  229] train: loss: 0.1340284
[Epoch 114; Iter   163/  229] train: loss: 0.1286047
[Epoch 114; Iter   193/  229] train: loss: 0.1492399
[Epoch 114; Iter   223/  229] train: loss: 0.1114055
[Epoch 114] ogbg-moltoxcast: 0.694700 val loss: 0.279977
[Epoch 114] ogbg-moltoxcast: 0.656661 test loss: 0.347548
[Epoch 115; Iter    24/  229] train: loss: 0.0853916
[Epoch 115; Iter    54/  229] train: loss: 0.1147871
[Epoch 115; Iter    84/  229] train: loss: 0.1398143
[Epoch 115; Iter   114/  229] train: loss: 0.0858750
[Epoch 115; Iter   144/  229] train: loss: 0.1475741
[Epoch 115; Iter   174/  229] train: loss: 0.1036015
[Epoch 115; Iter   204/  229] train: loss: 0.0906309
[Epoch 115] ogbg-moltoxcast: 0.691846 val loss: 0.285877
[Epoch 115] ogbg-moltoxcast: 0.660485 test loss: 0.348524
[Epoch 116; Iter     5/  229] train: loss: 0.1548829
[Epoch 116; Iter    35/  229] train: loss: 0.1103596
[Epoch 116; Iter    65/  229] train: loss: 0.1065252
[Epoch 116; Iter    95/  229] train: loss: 0.1157200
[Epoch 116; Iter   125/  229] train: loss: 0.1205877
[Epoch 116; Iter   155/  229] train: loss: 0.1270905
[Epoch 116; Iter   185/  229] train: loss: 0.0870894
[Epoch 116; Iter   215/  229] train: loss: 0.0853482
[Epoch 116] ogbg-moltoxcast: 0.695856 val loss: 0.282429
[Epoch 116] ogbg-moltoxcast: 0.653863 test loss: 0.368675
[Epoch 117; Iter    16/  229] train: loss: 0.1208634
[Epoch 117; Iter    46/  229] train: loss: 0.1352323
[Epoch 117; Iter    76/  229] train: loss: 0.1096218
[Epoch 117; Iter   106/  229] train: loss: 0.1281855
[Epoch 117; Iter   136/  229] train: loss: 0.1227061
[Epoch 117; Iter   166/  229] train: loss: 0.0874000
[Epoch 117; Iter   196/  229] train: loss: 0.1074142
[Epoch 117; Iter   226/  229] train: loss: 0.1068795
[Epoch 117] ogbg-moltoxcast: 0.694041 val loss: 0.283338
[Epoch 117] ogbg-moltoxcast: 0.649012 test loss: 0.459380
[Epoch 118; Iter    27/  229] train: loss: 0.1096490
[Epoch 118; Iter    57/  229] train: loss: 0.0792564
[Epoch 118; Iter    87/  229] train: loss: 0.1171779
[Epoch 118; Iter   117/  229] train: loss: 0.0878875
[Epoch 118; Iter   147/  229] train: loss: 0.1059378
[Epoch 118; Iter   177/  229] train: loss: 0.1393209
[Epoch 118; Iter   207/  229] train: loss: 0.0976134
[Epoch 118] ogbg-moltoxcast: 0.695058 val loss: 0.284981
[Epoch 118] ogbg-moltoxcast: 0.654934 test loss: 0.353108
[Epoch 119; Iter     8/  229] train: loss: 0.0740592
[Epoch 119; Iter    38/  229] train: loss: 0.1042380
[Epoch 119; Iter    68/  229] train: loss: 0.1298449
[Epoch 119; Iter    98/  229] train: loss: 0.0868381
[Epoch 119; Iter   128/  229] train: loss: 0.1413154
[Epoch 119; Iter   158/  229] train: loss: 0.1282663
[Epoch 119; Iter   188/  229] train: loss: 0.1395167
[Epoch 119; Iter   218/  229] train: loss: 0.1773216
[Epoch 119] ogbg-moltoxcast: 0.696563 val loss: 0.286515
[Epoch 119] ogbg-moltoxcast: 0.660353 test loss: 0.351459
[Epoch 120; Iter    19/  229] train: loss: 0.0856374
[Epoch 120; Iter    49/  229] train: loss: 0.1159040
[Epoch 120; Iter    79/  229] train: loss: 0.0850993
[Epoch 120; Iter   109/  229] train: loss: 0.0689937
[Epoch 120; Iter   139/  229] train: loss: 0.1393282
[Epoch 120; Iter   169/  229] train: loss: 0.0867655
[Epoch 120; Iter   199/  229] train: loss: 0.0882579
[Epoch 120; Iter   229/  229] train: loss: 0.1035811
[Epoch 120] ogbg-moltoxcast: 0.695007 val loss: 0.283723
[Epoch 120] ogbg-moltoxcast: 0.660180 test loss: 0.346172
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 32.
Statistics on  val_best_checkpoint
mean_pred: -2.593364953994751
std_pred: 3.040371894836426
mean_targets: nan
std_targets: nan
prcauc: 0.41194904316014197
rocauc: 0.7092922869536786
ogbg-moltoxcast: 0.7092922869536786
OGBNanLabelBCEWithLogitsLoss: 0.247067391872406
Statistics on  test
mean_pred: -2.4286415576934814
std_pred: 4.93789529800415
mean_targets: nan
std_targets: nan
prcauc: 0.357652098028169
rocauc: 0.6662355235139678
ogbg-moltoxcast: 0.6662355235139678
OGBNanLabelBCEWithLogitsLoss: 0.3033360294226942
Statistics on  train
mean_pred: -2.9168319702148438
std_pred: 2.837611675262451
mean_targets: nan
std_targets: nan
prcauc: 0.521692586250905
rocauc: 0.8517365121345547
ogbg-moltoxcast: 0.8517365121345547
OGBNanLabelBCEWithLogitsLoss: 0.1625967767561367
[Epoch 107] ogbg-moltoxcast: 0.649823 test loss: 0.361441
[Epoch 108; Iter     7/  229] train: loss: 0.1295482
[Epoch 108; Iter    37/  229] train: loss: 0.1703346
[Epoch 108; Iter    67/  229] train: loss: 0.1289140
[Epoch 108; Iter    97/  229] train: loss: 0.0898151
[Epoch 108; Iter   127/  229] train: loss: 0.1037718
[Epoch 108; Iter   157/  229] train: loss: 0.1046155
[Epoch 108; Iter   187/  229] train: loss: 0.1257621
[Epoch 108; Iter   217/  229] train: loss: 0.1233439
[Epoch 108] ogbg-moltoxcast: 0.684184 val loss: 0.286079
[Epoch 108] ogbg-moltoxcast: 0.647392 test loss: 0.359154
[Epoch 109; Iter    18/  229] train: loss: 0.1189270
[Epoch 109; Iter    48/  229] train: loss: 0.1206146
[Epoch 109; Iter    78/  229] train: loss: 0.0748817
[Epoch 109; Iter   108/  229] train: loss: 0.1753489
[Epoch 109; Iter   138/  229] train: loss: 0.1856261
[Epoch 109; Iter   168/  229] train: loss: 0.1666553
[Epoch 109; Iter   198/  229] train: loss: 0.1097112
[Epoch 109; Iter   228/  229] train: loss: 0.1649202
[Epoch 109] ogbg-moltoxcast: 0.682343 val loss: 0.284668
[Epoch 109] ogbg-moltoxcast: 0.645623 test loss: 0.360136
[Epoch 110; Iter    29/  229] train: loss: 0.1101121
[Epoch 110; Iter    59/  229] train: loss: 0.1192386
[Epoch 110; Iter    89/  229] train: loss: 0.1912151
[Epoch 110; Iter   119/  229] train: loss: 0.1951673
[Epoch 110; Iter   149/  229] train: loss: 0.1250139
[Epoch 110; Iter   179/  229] train: loss: 0.1638096
[Epoch 110; Iter   209/  229] train: loss: 0.1062724
[Epoch 110] ogbg-moltoxcast: 0.681678 val loss: 0.286017
[Epoch 110] ogbg-moltoxcast: 0.645600 test loss: 0.368186
[Epoch 111; Iter    10/  229] train: loss: 0.1378860
[Epoch 111; Iter    40/  229] train: loss: 0.0877629
[Epoch 111; Iter    70/  229] train: loss: 0.0918862
[Epoch 111; Iter   100/  229] train: loss: 0.1174737
[Epoch 111; Iter   130/  229] train: loss: 0.1332206
[Epoch 111; Iter   160/  229] train: loss: 0.1242308
[Epoch 111; Iter   190/  229] train: loss: 0.1101197
[Epoch 111; Iter   220/  229] train: loss: 0.1354147
[Epoch 111] ogbg-moltoxcast: 0.680846 val loss: 0.287985
[Epoch 111] ogbg-moltoxcast: 0.646896 test loss: 0.365263
[Epoch 112; Iter    21/  229] train: loss: 0.0974706
[Epoch 112; Iter    51/  229] train: loss: 0.0976093
[Epoch 112; Iter    81/  229] train: loss: 0.1173530
[Epoch 112; Iter   111/  229] train: loss: 0.1304151
[Epoch 112; Iter   141/  229] train: loss: 0.1260408
[Epoch 112; Iter   171/  229] train: loss: 0.1019684
[Epoch 112; Iter   201/  229] train: loss: 0.1162441
[Epoch 112] ogbg-moltoxcast: 0.680856 val loss: 0.286571
[Epoch 112] ogbg-moltoxcast: 0.644480 test loss: 0.361047
[Epoch 113; Iter     2/  229] train: loss: 0.0580140
[Epoch 113; Iter    32/  229] train: loss: 0.1047760
[Epoch 113; Iter    62/  229] train: loss: 0.1245346
[Epoch 113; Iter    92/  229] train: loss: 0.1791042
[Epoch 113; Iter   122/  229] train: loss: 0.0698573
[Epoch 113; Iter   152/  229] train: loss: 0.1461161
[Epoch 113; Iter   182/  229] train: loss: 0.0989838
[Epoch 113; Iter   212/  229] train: loss: 0.1191552
[Epoch 113] ogbg-moltoxcast: 0.678899 val loss: 0.290246
[Epoch 113] ogbg-moltoxcast: 0.647959 test loss: 0.363980
[Epoch 114; Iter    13/  229] train: loss: 0.1124856
[Epoch 114; Iter    43/  229] train: loss: 0.1053168
[Epoch 114; Iter    73/  229] train: loss: 0.1128063
[Epoch 114; Iter   103/  229] train: loss: 0.1014392
[Epoch 114; Iter   133/  229] train: loss: 0.1367390
[Epoch 114; Iter   163/  229] train: loss: 0.0893710
[Epoch 114; Iter   193/  229] train: loss: 0.1090340
[Epoch 114; Iter   223/  229] train: loss: 0.0950943
[Epoch 114] ogbg-moltoxcast: 0.680011 val loss: 0.289264
[Epoch 114] ogbg-moltoxcast: 0.644371 test loss: 0.364448
[Epoch 115; Iter    24/  229] train: loss: 0.1101512
[Epoch 115; Iter    54/  229] train: loss: 0.1068343
[Epoch 115; Iter    84/  229] train: loss: 0.1477613
[Epoch 115; Iter   114/  229] train: loss: 0.1147432
[Epoch 115; Iter   144/  229] train: loss: 0.1211757
[Epoch 115; Iter   174/  229] train: loss: 0.0759022
[Epoch 115; Iter   204/  229] train: loss: 0.1420362
[Epoch 115] ogbg-moltoxcast: 0.678467 val loss: 0.289919
[Epoch 115] ogbg-moltoxcast: 0.644977 test loss: 0.366186
[Epoch 116; Iter     5/  229] train: loss: 0.1207002
[Epoch 116; Iter    35/  229] train: loss: 0.0951219
[Epoch 116; Iter    65/  229] train: loss: 0.2125710
[Epoch 116; Iter    95/  229] train: loss: 0.1144960
[Epoch 116; Iter   125/  229] train: loss: 0.1340651
[Epoch 116; Iter   155/  229] train: loss: 0.1383714
[Epoch 116; Iter   185/  229] train: loss: 0.1072424
[Epoch 116; Iter   215/  229] train: loss: 0.0997998
[Epoch 116] ogbg-moltoxcast: 0.681346 val loss: 0.297888
[Epoch 116] ogbg-moltoxcast: 0.648570 test loss: 0.363904
[Epoch 117; Iter    16/  229] train: loss: 0.1482317
[Epoch 117; Iter    46/  229] train: loss: 0.1592590
[Epoch 117; Iter    76/  229] train: loss: 0.1075210
[Epoch 117; Iter   106/  229] train: loss: 0.1432603
[Epoch 117; Iter   136/  229] train: loss: 0.0960932
[Epoch 117; Iter   166/  229] train: loss: 0.0665796
[Epoch 117; Iter   196/  229] train: loss: 0.1939565
[Epoch 117; Iter   226/  229] train: loss: 0.0951410
[Epoch 117] ogbg-moltoxcast: 0.680253 val loss: 0.313702
[Epoch 117] ogbg-moltoxcast: 0.648064 test loss: 0.365517
[Epoch 118; Iter    27/  229] train: loss: 0.0732477
[Epoch 118; Iter    57/  229] train: loss: 0.1162577
[Epoch 118; Iter    87/  229] train: loss: 0.0767014
[Epoch 118; Iter   117/  229] train: loss: 0.1324076
[Epoch 118; Iter   147/  229] train: loss: 0.1122084
[Epoch 118; Iter   177/  229] train: loss: 0.1210394
[Epoch 118; Iter   207/  229] train: loss: 0.1853324
[Epoch 118] ogbg-moltoxcast: 0.682714 val loss: 0.287313
[Epoch 118] ogbg-moltoxcast: 0.646297 test loss: 0.362547
[Epoch 119; Iter     8/  229] train: loss: 0.1325813
[Epoch 119; Iter    38/  229] train: loss: 0.0940929
[Epoch 119; Iter    68/  229] train: loss: 0.1391073
[Epoch 119; Iter    98/  229] train: loss: 0.0772763
[Epoch 119; Iter   128/  229] train: loss: 0.1150841
[Epoch 119; Iter   158/  229] train: loss: 0.0982311
[Epoch 119; Iter   188/  229] train: loss: 0.1587889
[Epoch 119; Iter   218/  229] train: loss: 0.1496623
[Epoch 119] ogbg-moltoxcast: 0.685849 val loss: 0.398717
[Epoch 119] ogbg-moltoxcast: 0.647147 test loss: 0.418213
[Epoch 120; Iter    19/  229] train: loss: 0.1174398
[Epoch 120; Iter    49/  229] train: loss: 0.1263184
[Epoch 120; Iter    79/  229] train: loss: 0.1016576
[Epoch 120; Iter   109/  229] train: loss: 0.1396154
[Epoch 120; Iter   139/  229] train: loss: 0.1309980
[Epoch 120; Iter   169/  229] train: loss: 0.1382586
[Epoch 120; Iter   199/  229] train: loss: 0.0969290
[Epoch 120; Iter   229/  229] train: loss: 0.1798895
[Epoch 120] ogbg-moltoxcast: 0.682604 val loss: 0.305485
[Epoch 120] ogbg-moltoxcast: 0.648078 test loss: 0.373314
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 35.
Statistics on  val_best_checkpoint
mean_pred: -2.435811758041382
std_pred: 2.7228522300720215
mean_targets: nan
std_targets: nan
prcauc: 0.41107659292810556
rocauc: 0.7013623065203907
ogbg-moltoxcast: 0.7013623065203907
OGBNanLabelBCEWithLogitsLoss: 0.26338551733000526
Statistics on  test
mean_pred: -2.2502336502075195
std_pred: 2.4846580028533936
mean_targets: nan
std_targets: nan
prcauc: 0.3642832961184139
rocauc: 0.6718100547041667
ogbg-moltoxcast: 0.6718100547041667
OGBNanLabelBCEWithLogitsLoss: 0.3030893386437975
Statistics on  train
mean_pred: -3.010913848876953
std_pred: 2.42403244972229
mean_targets: nan
std_targets: nan
prcauc: 0.549104838490988
rocauc: 0.8706602366535622
ogbg-moltoxcast: 0.8706602366535622
OGBNanLabelBCEWithLogitsLoss: 0.14844571193883513
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.650335 test loss: 0.338445
[Epoch 108; Iter     7/  229] train: loss: 0.1074460
[Epoch 108; Iter    37/  229] train: loss: 0.1820838
[Epoch 108; Iter    67/  229] train: loss: 0.1153267
[Epoch 108; Iter    97/  229] train: loss: 0.1553825
[Epoch 108; Iter   127/  229] train: loss: 0.1294846
[Epoch 108; Iter   157/  229] train: loss: 0.1201566
[Epoch 108; Iter   187/  229] train: loss: 0.1249817
[Epoch 108; Iter   217/  229] train: loss: 0.1081234
[Epoch 108] ogbg-moltoxcast: 0.677565 val loss: 0.284479
[Epoch 108] ogbg-moltoxcast: 0.652366 test loss: 0.340875
[Epoch 109; Iter    18/  229] train: loss: 0.0970332
[Epoch 109; Iter    48/  229] train: loss: 0.1249766
[Epoch 109; Iter    78/  229] train: loss: 0.0882727
[Epoch 109; Iter   108/  229] train: loss: 0.1154062
[Epoch 109; Iter   138/  229] train: loss: 0.0757624
[Epoch 109; Iter   168/  229] train: loss: 0.1252176
[Epoch 109; Iter   198/  229] train: loss: 0.1122961
[Epoch 109; Iter   228/  229] train: loss: 0.1320325
[Epoch 109] ogbg-moltoxcast: 0.671636 val loss: 0.284198
[Epoch 109] ogbg-moltoxcast: 0.652364 test loss: 0.337500
[Epoch 110; Iter    29/  229] train: loss: 0.1301693
[Epoch 110; Iter    59/  229] train: loss: 0.1306993
[Epoch 110; Iter    89/  229] train: loss: 0.1347765
[Epoch 110; Iter   119/  229] train: loss: 0.1564492
[Epoch 110; Iter   149/  229] train: loss: 0.1518348
[Epoch 110; Iter   179/  229] train: loss: 0.1462157
[Epoch 110; Iter   209/  229] train: loss: 0.0975783
[Epoch 110] ogbg-moltoxcast: 0.676106 val loss: 0.284170
[Epoch 110] ogbg-moltoxcast: 0.649344 test loss: 0.337437
[Epoch 111; Iter    10/  229] train: loss: 0.0892234
[Epoch 111; Iter    40/  229] train: loss: 0.1252337
[Epoch 111; Iter    70/  229] train: loss: 0.1493266
[Epoch 111; Iter   100/  229] train: loss: 0.1051901
[Epoch 111; Iter   130/  229] train: loss: 0.1313197
[Epoch 111; Iter   160/  229] train: loss: 0.1695821
[Epoch 111; Iter   190/  229] train: loss: 0.0927044
[Epoch 111; Iter   220/  229] train: loss: 0.1140180
[Epoch 111] ogbg-moltoxcast: 0.677866 val loss: 0.281934
[Epoch 111] ogbg-moltoxcast: 0.651410 test loss: 0.339070
[Epoch 112; Iter    21/  229] train: loss: 0.1078625
[Epoch 112; Iter    51/  229] train: loss: 0.1280213
[Epoch 112; Iter    81/  229] train: loss: 0.0799112
[Epoch 112; Iter   111/  229] train: loss: 0.1114427
[Epoch 112; Iter   141/  229] train: loss: 0.1128440
[Epoch 112; Iter   171/  229] train: loss: 0.1174840
[Epoch 112; Iter   201/  229] train: loss: 0.0914476
[Epoch 112] ogbg-moltoxcast: 0.678540 val loss: 0.283160
[Epoch 112] ogbg-moltoxcast: 0.651225 test loss: 0.337904
[Epoch 113; Iter     2/  229] train: loss: 0.1402586
[Epoch 113; Iter    32/  229] train: loss: 0.1421957
[Epoch 113; Iter    62/  229] train: loss: 0.1225803
[Epoch 113; Iter    92/  229] train: loss: 0.1439787
[Epoch 113; Iter   122/  229] train: loss: 0.1625514
[Epoch 113; Iter   152/  229] train: loss: 0.1119919
[Epoch 113; Iter   182/  229] train: loss: 0.1128788
[Epoch 113; Iter   212/  229] train: loss: 0.1057228
[Epoch 113] ogbg-moltoxcast: 0.685352 val loss: 0.288156
[Epoch 113] ogbg-moltoxcast: 0.654035 test loss: 0.340661
[Epoch 114; Iter    13/  229] train: loss: 0.0704573
[Epoch 114; Iter    43/  229] train: loss: 0.1209067
[Epoch 114; Iter    73/  229] train: loss: 0.1112037
[Epoch 114; Iter   103/  229] train: loss: 0.1423222
[Epoch 114; Iter   133/  229] train: loss: 0.1241141
[Epoch 114; Iter   163/  229] train: loss: 0.0897861
[Epoch 114; Iter   193/  229] train: loss: 0.1359558
[Epoch 114; Iter   223/  229] train: loss: 0.0859372
[Epoch 114] ogbg-moltoxcast: 0.678213 val loss: 0.285451
[Epoch 114] ogbg-moltoxcast: 0.651250 test loss: 0.342088
[Epoch 115; Iter    24/  229] train: loss: 0.0937245
[Epoch 115; Iter    54/  229] train: loss: 0.1281175
[Epoch 115; Iter    84/  229] train: loss: 0.1177669
[Epoch 115; Iter   114/  229] train: loss: 0.0781371
[Epoch 115; Iter   144/  229] train: loss: 0.0756657
[Epoch 115; Iter   174/  229] train: loss: 0.1323804
[Epoch 115; Iter   204/  229] train: loss: 0.1503330
[Epoch 115] ogbg-moltoxcast: 0.674829 val loss: 0.287812
[Epoch 115] ogbg-moltoxcast: 0.650552 test loss: 0.344274
[Epoch 116; Iter     5/  229] train: loss: 0.1246040
[Epoch 116; Iter    35/  229] train: loss: 0.1171412
[Epoch 116; Iter    65/  229] train: loss: 0.1081394
[Epoch 116; Iter    95/  229] train: loss: 0.1529792
[Epoch 116; Iter   125/  229] train: loss: 0.0926413
[Epoch 116; Iter   155/  229] train: loss: 0.1657045
[Epoch 116; Iter   185/  229] train: loss: 0.1000724
[Epoch 116; Iter   215/  229] train: loss: 0.1375865
[Epoch 116] ogbg-moltoxcast: 0.679656 val loss: 0.287813
[Epoch 116] ogbg-moltoxcast: 0.651628 test loss: 0.343298
[Epoch 117; Iter    16/  229] train: loss: 0.0998787
[Epoch 117; Iter    46/  229] train: loss: 0.0864745
[Epoch 117; Iter    76/  229] train: loss: 0.0921409
[Epoch 117; Iter   106/  229] train: loss: 0.1152746
[Epoch 117; Iter   136/  229] train: loss: 0.1438354
[Epoch 117; Iter   166/  229] train: loss: 0.1221551
[Epoch 117; Iter   196/  229] train: loss: 0.1459799
[Epoch 117; Iter   226/  229] train: loss: 0.1250599
[Epoch 117] ogbg-moltoxcast: 0.675120 val loss: 0.284201
[Epoch 117] ogbg-moltoxcast: 0.650077 test loss: 0.339606
[Epoch 118; Iter    27/  229] train: loss: 0.0881056
[Epoch 118; Iter    57/  229] train: loss: 0.1030974
[Epoch 118; Iter    87/  229] train: loss: 0.1171104
[Epoch 118; Iter   117/  229] train: loss: 0.1119182
[Epoch 118; Iter   147/  229] train: loss: 0.1226251
[Epoch 118; Iter   177/  229] train: loss: 0.1370755
[Epoch 118; Iter   207/  229] train: loss: 0.1025072
[Epoch 118] ogbg-moltoxcast: 0.681572 val loss: 0.285214
[Epoch 118] ogbg-moltoxcast: 0.651744 test loss: 0.342437
[Epoch 119; Iter     8/  229] train: loss: 0.1077856
[Epoch 119; Iter    38/  229] train: loss: 0.0894402
[Epoch 119; Iter    68/  229] train: loss: 0.1027510
[Epoch 119; Iter    98/  229] train: loss: 0.1121392
[Epoch 119; Iter   128/  229] train: loss: 0.1244608
[Epoch 119; Iter   158/  229] train: loss: 0.1376155
[Epoch 119; Iter   188/  229] train: loss: 0.1151968
[Epoch 119; Iter   218/  229] train: loss: 0.0725317
[Epoch 119] ogbg-moltoxcast: 0.675895 val loss: 0.286055
[Epoch 119] ogbg-moltoxcast: 0.648752 test loss: 0.341482
[Epoch 120; Iter    19/  229] train: loss: 0.1067829
[Epoch 120; Iter    49/  229] train: loss: 0.1056143
[Epoch 120; Iter    79/  229] train: loss: 0.1144412
[Epoch 120; Iter   109/  229] train: loss: 0.1879582
[Epoch 120; Iter   139/  229] train: loss: 0.1027813
[Epoch 120; Iter   169/  229] train: loss: 0.0930089
[Epoch 120; Iter   199/  229] train: loss: 0.0703086
[Epoch 120; Iter   229/  229] train: loss: 0.1226328
[Epoch 120] ogbg-moltoxcast: 0.672610 val loss: 0.286671
[Epoch 120] ogbg-moltoxcast: 0.649615 test loss: 0.339673
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 44.
Statistics on  val_best_checkpoint
mean_pred: -2.6632332801818848
std_pred: 2.494525194168091
mean_targets: nan
std_targets: nan
prcauc: 0.4183730866727941
rocauc: 0.6976572359946955
ogbg-moltoxcast: 0.6976572359946955
OGBNanLabelBCEWithLogitsLoss: 0.24680417416424588
Statistics on  test
mean_pred: -1.9630831480026245
std_pred: 17.21059799194336
mean_targets: nan
std_targets: nan
prcauc: 0.35976589523074026
rocauc: 0.667518444414898
ogbg-moltoxcast: 0.667518444414898
OGBNanLabelBCEWithLogitsLoss: 0.6865674200756796
Statistics on  train
mean_pred: -3.205219268798828
std_pred: 3.547107219696045
mean_targets: nan
std_targets: nan
prcauc: 0.5806601482727322
rocauc: 0.8827871558051926
ogbg-moltoxcast: 0.8827871558051926
OGBNanLabelBCEWithLogitsLoss: 0.15353279160620345
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.0.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.0.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/toxcast/noise=0.0.yml --seed 6 --device cuda:0
All runs completed.
