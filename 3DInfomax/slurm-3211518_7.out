>>> Starting run for dataset: toxcast
Running SCAFF configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.7.yml --seed 6 --device cuda:1
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.8/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.8_6_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.8
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931946
[Epoch 1; Iter    60/  229] train: loss: 0.6931317
[Epoch 1; Iter    90/  229] train: loss: 0.6931166
[Epoch 1; Iter   120/  229] train: loss: 0.6931515
[Epoch 1; Iter   150/  229] train: loss: 0.6931350
[Epoch 1; Iter   180/  229] train: loss: 0.6931351
[Epoch 1; Iter   210/  229] train: loss: 0.6931400
[Epoch 1] ogbg-moltoxcast: 0.506428 val loss: 0.693134
[Epoch 1] ogbg-moltoxcast: 0.500122 test loss: 0.693210
[Epoch 2; Iter    11/  229] train: loss: 0.6930764
[Epoch 2; Iter    41/  229] train: loss: 0.6930979
[Epoch 2; Iter    71/  229] train: loss: 0.6930750
[Epoch 2; Iter   101/  229] train: loss: 0.6931231
[Epoch 2; Iter   131/  229] train: loss: 0.6931165
[Epoch 2; Iter   161/  229] train: loss: 0.6930628
[Epoch 2; Iter   191/  229] train: loss: 0.6930342
[Epoch 2; Iter   221/  229] train: loss: 0.6929967
[Epoch 2] ogbg-moltoxcast: 0.508186 val loss: 0.692987
[Epoch 2] ogbg-moltoxcast: 0.499746 test loss: 0.693073
[Epoch 3; Iter    22/  229] train: loss: 0.6930100
[Epoch 3; Iter    52/  229] train: loss: 0.6929141
[Epoch 3; Iter    82/  229] train: loss: 0.6929750
[Epoch 3; Iter   112/  229] train: loss: 0.6929163
[Epoch 3; Iter   142/  229] train: loss: 0.6928487
[Epoch 3; Iter   172/  229] train: loss: 0.6928104
[Epoch 3; Iter   202/  229] train: loss: 0.6928424
[Epoch 3] ogbg-moltoxcast: 0.507964 val loss: 0.692838
[Epoch 3] ogbg-moltoxcast: 0.499086 test loss: 0.692943
[Epoch 4; Iter     3/  229] train: loss: 0.6928262
[Epoch 4; Iter    33/  229] train: loss: 0.6890059
[Epoch 4; Iter    63/  229] train: loss: 0.6729757
[Epoch 4; Iter    93/  229] train: loss: 0.6330649
[Epoch 4; Iter   123/  229] train: loss: 0.6335372
[Epoch 4; Iter   153/  229] train: loss: 0.5428810
[Epoch 4; Iter   183/  229] train: loss: 0.5619822
[Epoch 4; Iter   213/  229] train: loss: 0.4289413
[Epoch 4] ogbg-moltoxcast: 0.611094 val loss: 0.585912
[Epoch 4] ogbg-moltoxcast: 0.556231 test loss: 0.602667
[Epoch 5; Iter    14/  229] train: loss: 0.4436116
[Epoch 5; Iter    44/  229] train: loss: 0.3648249
[Epoch 5; Iter    74/  229] train: loss: 0.3163283
[Epoch 5; Iter   104/  229] train: loss: 0.3104354
[Epoch 5; Iter   134/  229] train: loss: 0.2983662
[Epoch 5; Iter   164/  229] train: loss: 0.2414715
[Epoch 5; Iter   194/  229] train: loss: 0.2677874
[Epoch 5; Iter   224/  229] train: loss: 0.3086970
[Epoch 5] ogbg-moltoxcast: 0.639199 val loss: 0.283510
[Epoch 5] ogbg-moltoxcast: 0.597066 test loss: 0.321721
[Epoch 6; Iter    25/  229] train: loss: 0.3131064
[Epoch 6; Iter    55/  229] train: loss: 0.1867107
[Epoch 6; Iter    85/  229] train: loss: 0.2428264
[Epoch 6; Iter   115/  229] train: loss: 0.2451224
[Epoch 6; Iter   145/  229] train: loss: 0.2104033
[Epoch 6; Iter   175/  229] train: loss: 0.1781444
[Epoch 6; Iter   205/  229] train: loss: 0.1489742
[Epoch 6] ogbg-moltoxcast: 0.653556 val loss: 0.267029
[Epoch 6] ogbg-moltoxcast: 0.617907 test loss: 0.306024
[Epoch 7; Iter     6/  229] train: loss: 0.1716107
[Epoch 7; Iter    36/  229] train: loss: 0.1573531
[Epoch 7; Iter    66/  229] train: loss: 0.2025119
[Epoch 7; Iter    96/  229] train: loss: 0.2826472
[Epoch 7; Iter   126/  229] train: loss: 0.1907786
[Epoch 7; Iter   156/  229] train: loss: 0.2559970
[Epoch 7; Iter   186/  229] train: loss: 0.1969710
[Epoch 7; Iter   216/  229] train: loss: 0.2081037
[Epoch 7] ogbg-moltoxcast: 0.648730 val loss: 0.267593
[Epoch 7] ogbg-moltoxcast: 0.610025 test loss: 0.315363
[Epoch 8; Iter    17/  229] train: loss: 0.1676529
[Epoch 8; Iter    47/  229] train: loss: 0.1817997
[Epoch 8; Iter    77/  229] train: loss: 0.1678946
[Epoch 8; Iter   107/  229] train: loss: 0.2156225
[Epoch 8; Iter   137/  229] train: loss: 0.2435556
[Epoch 8; Iter   167/  229] train: loss: 0.1913949
[Epoch 8; Iter   197/  229] train: loss: 0.2285268
[Epoch 8; Iter   227/  229] train: loss: 0.3828632
[Epoch 8] ogbg-moltoxcast: 0.647235 val loss: 0.273199
[Epoch 8] ogbg-moltoxcast: 0.629567 test loss: 0.637155
[Epoch 9; Iter    28/  229] train: loss: 0.1594361
[Epoch 9; Iter    58/  229] train: loss: 0.1408802
[Epoch 9; Iter    88/  229] train: loss: 0.1667695
[Epoch 9; Iter   118/  229] train: loss: 0.2456603
[Epoch 9; Iter   148/  229] train: loss: 0.3026704
[Epoch 9; Iter   178/  229] train: loss: 0.1541025
[Epoch 9; Iter   208/  229] train: loss: 0.2485811
[Epoch 9] ogbg-moltoxcast: 0.655678 val loss: 0.262582
[Epoch 9] ogbg-moltoxcast: 0.611638 test loss: 0.447777
[Epoch 10; Iter     9/  229] train: loss: 0.2244963
[Epoch 10; Iter    39/  229] train: loss: 0.2117465
[Epoch 10; Iter    69/  229] train: loss: 0.1520443
[Epoch 10; Iter    99/  229] train: loss: 0.1127748
[Epoch 10; Iter   129/  229] train: loss: 0.1633615
[Epoch 10; Iter   159/  229] train: loss: 0.2300606
[Epoch 10; Iter   189/  229] train: loss: 0.1964786
[Epoch 10; Iter   219/  229] train: loss: 0.2345305
[Epoch 10] ogbg-moltoxcast: 0.655163 val loss: 0.271532
[Epoch 10] ogbg-moltoxcast: 0.634549 test loss: 0.399538
[Epoch 11; Iter    20/  229] train: loss: 0.1561411
[Epoch 11; Iter    50/  229] train: loss: 0.1822135
[Epoch 11; Iter    80/  229] train: loss: 0.1609117
[Epoch 11; Iter   110/  229] train: loss: 0.1358081
[Epoch 11; Iter   140/  229] train: loss: 0.2255742
[Epoch 11; Iter   170/  229] train: loss: 0.2920725
[Epoch 11; Iter   200/  229] train: loss: 0.1451195
[Epoch 11] ogbg-moltoxcast: 0.646844 val loss: 0.329831
[Epoch 11] ogbg-moltoxcast: 0.633458 test loss: 0.589070
[Epoch 12; Iter     1/  229] train: loss: 0.2125261
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.8/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.8_5_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.8
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931581
[Epoch 1; Iter    60/  229] train: loss: 0.6931779
[Epoch 1; Iter    90/  229] train: loss: 0.6931946
[Epoch 1; Iter   120/  229] train: loss: 0.6931390
[Epoch 1; Iter   150/  229] train: loss: 0.6931357
[Epoch 1; Iter   180/  229] train: loss: 0.6930536
[Epoch 1; Iter   210/  229] train: loss: 0.6930958
[Epoch 1] ogbg-moltoxcast: 0.502406 val loss: 0.692998
[Epoch 1] ogbg-moltoxcast: 0.499999 test loss: 0.692976
[Epoch 2; Iter    11/  229] train: loss: 0.6931233
[Epoch 2; Iter    41/  229] train: loss: 0.6930510
[Epoch 2; Iter    71/  229] train: loss: 0.6930448
[Epoch 2; Iter   101/  229] train: loss: 0.6930963
[Epoch 2; Iter   131/  229] train: loss: 0.6930626
[Epoch 2; Iter   161/  229] train: loss: 0.6929995
[Epoch 2; Iter   191/  229] train: loss: 0.6930235
[Epoch 2; Iter   221/  229] train: loss: 0.6929896
[Epoch 2] ogbg-moltoxcast: 0.503114 val loss: 0.692854
[Epoch 2] ogbg-moltoxcast: 0.499710 test loss: 0.692842
[Epoch 3; Iter    22/  229] train: loss: 0.6929408
[Epoch 3; Iter    52/  229] train: loss: 0.6928868
[Epoch 3; Iter    82/  229] train: loss: 0.6929260
[Epoch 3; Iter   112/  229] train: loss: 0.6928506
[Epoch 3; Iter   142/  229] train: loss: 0.6928117
[Epoch 3; Iter   172/  229] train: loss: 0.6928121
[Epoch 3; Iter   202/  229] train: loss: 0.6928120
[Epoch 3] ogbg-moltoxcast: 0.503280 val loss: 0.692659
[Epoch 3] ogbg-moltoxcast: 0.499966 test loss: 0.692672
[Epoch 4; Iter     3/  229] train: loss: 0.6929179
[Epoch 4; Iter    33/  229] train: loss: 0.6894733
[Epoch 4; Iter    63/  229] train: loss: 0.6720691
[Epoch 4; Iter    93/  229] train: loss: 0.6215068
[Epoch 4; Iter   123/  229] train: loss: 0.5833986
[Epoch 4; Iter   153/  229] train: loss: 0.5374007
[Epoch 4; Iter   183/  229] train: loss: 0.4624019
[Epoch 4; Iter   213/  229] train: loss: 0.4295404
[Epoch 4] ogbg-moltoxcast: 0.584840 val loss: 0.501610
[Epoch 4] ogbg-moltoxcast: 0.532663 test loss: 0.517421
[Epoch 5; Iter    14/  229] train: loss: 0.3955096
[Epoch 5; Iter    44/  229] train: loss: 0.3139827
[Epoch 5; Iter    74/  229] train: loss: 0.3517908
[Epoch 5; Iter   104/  229] train: loss: 0.2779080
[Epoch 5; Iter   134/  229] train: loss: 0.2493790
[Epoch 5; Iter   164/  229] train: loss: 0.2137391
[Epoch 5; Iter   194/  229] train: loss: 0.2225495
[Epoch 5; Iter   224/  229] train: loss: 0.1596726
[Epoch 5] ogbg-moltoxcast: 0.625994 val loss: 0.289057
[Epoch 5] ogbg-moltoxcast: 0.591643 test loss: 0.322400
[Epoch 6; Iter    25/  229] train: loss: 0.2970202
[Epoch 6; Iter    55/  229] train: loss: 0.2079745
[Epoch 6; Iter    85/  229] train: loss: 0.1748263
[Epoch 6; Iter   115/  229] train: loss: 0.1899210
[Epoch 6; Iter   145/  229] train: loss: 0.2552728
[Epoch 6; Iter   175/  229] train: loss: 0.2190222
[Epoch 6; Iter   205/  229] train: loss: 0.1859222
[Epoch 6] ogbg-moltoxcast: 0.631785 val loss: 0.271893
[Epoch 6] ogbg-moltoxcast: 0.606728 test loss: 0.312389
[Epoch 7; Iter     6/  229] train: loss: 0.1682702
[Epoch 7; Iter    36/  229] train: loss: 0.1438351
[Epoch 7; Iter    66/  229] train: loss: 0.2374838
[Epoch 7; Iter    96/  229] train: loss: 0.2362249
[Epoch 7; Iter   126/  229] train: loss: 0.2664446
[Epoch 7; Iter   156/  229] train: loss: 0.1564862
[Epoch 7; Iter   186/  229] train: loss: 0.3335118
[Epoch 7; Iter   216/  229] train: loss: 0.1902444
[Epoch 7] ogbg-moltoxcast: 0.651241 val loss: 0.277010
[Epoch 7] ogbg-moltoxcast: 0.619195 test loss: 0.354018
[Epoch 8; Iter    17/  229] train: loss: 0.2519876
[Epoch 8; Iter    47/  229] train: loss: 0.1632340
[Epoch 8; Iter    77/  229] train: loss: 0.1800392
[Epoch 8; Iter   107/  229] train: loss: 0.2241964
[Epoch 8; Iter   137/  229] train: loss: 0.2418577
[Epoch 8; Iter   167/  229] train: loss: 0.1691551
[Epoch 8; Iter   197/  229] train: loss: 0.2088196
[Epoch 8; Iter   227/  229] train: loss: 0.1450208
[Epoch 8] ogbg-moltoxcast: 0.637507 val loss: 0.258218
[Epoch 8] ogbg-moltoxcast: 0.610220 test loss: 0.296153
[Epoch 9; Iter    28/  229] train: loss: 0.1609924
[Epoch 9; Iter    58/  229] train: loss: 0.2088433
[Epoch 9; Iter    88/  229] train: loss: 0.2081574
[Epoch 9; Iter   118/  229] train: loss: 0.1645087
[Epoch 9; Iter   148/  229] train: loss: 0.2311943
[Epoch 9; Iter   178/  229] train: loss: 0.1891322
[Epoch 9; Iter   208/  229] train: loss: 0.1932367
[Epoch 9] ogbg-moltoxcast: 0.601283 val loss: 0.298746
[Epoch 9] ogbg-moltoxcast: 0.605243 test loss: 0.356276
[Epoch 10; Iter     9/  229] train: loss: 0.1442986
[Epoch 10; Iter    39/  229] train: loss: 0.1130720
[Epoch 10; Iter    69/  229] train: loss: 0.2687366
[Epoch 10; Iter    99/  229] train: loss: 0.1594390
[Epoch 10; Iter   129/  229] train: loss: 0.1669736
[Epoch 10; Iter   159/  229] train: loss: 0.1769923
[Epoch 10; Iter   189/  229] train: loss: 0.2878028
[Epoch 10; Iter   219/  229] train: loss: 0.1731113
[Epoch 10] ogbg-moltoxcast: 0.665911 val loss: 0.259328
[Epoch 10] ogbg-moltoxcast: 0.633550 test loss: 0.301263
[Epoch 11; Iter    20/  229] train: loss: 0.1812049
[Epoch 11; Iter    50/  229] train: loss: 0.1751489
[Epoch 11; Iter    80/  229] train: loss: 0.1732610
[Epoch 11; Iter   110/  229] train: loss: 0.1874287
[Epoch 11; Iter   140/  229] train: loss: 0.2157427
[Epoch 11; Iter   170/  229] train: loss: 0.1574495
[Epoch 11; Iter   200/  229] train: loss: 0.2055921
[Epoch 11] ogbg-moltoxcast: 0.672745 val loss: 0.267468
[Epoch 11] ogbg-moltoxcast: 0.637238 test loss: 0.306246
[Epoch 12; Iter     1/  229] train: loss: 0.2067777
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.8/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.8_4_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.8
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931497
[Epoch 1; Iter    60/  229] train: loss: 0.6931714
[Epoch 1; Iter    90/  229] train: loss: 0.6931844
[Epoch 1; Iter   120/  229] train: loss: 0.6931431
[Epoch 1; Iter   150/  229] train: loss: 0.6931259
[Epoch 1; Iter   180/  229] train: loss: 0.6931096
[Epoch 1; Iter   210/  229] train: loss: 0.6930931
[Epoch 1] ogbg-moltoxcast: 0.495290 val loss: 0.693076
[Epoch 1] ogbg-moltoxcast: 0.496743 test loss: 0.693073
[Epoch 2; Iter    11/  229] train: loss: 0.6931412
[Epoch 2; Iter    41/  229] train: loss: 0.6930594
[Epoch 2; Iter    71/  229] train: loss: 0.6930700
[Epoch 2; Iter   101/  229] train: loss: 0.6931484
[Epoch 2; Iter   131/  229] train: loss: 0.6931148
[Epoch 2; Iter   161/  229] train: loss: 0.6930408
[Epoch 2; Iter   191/  229] train: loss: 0.6930220
[Epoch 2; Iter   221/  229] train: loss: 0.6929916
[Epoch 2] ogbg-moltoxcast: 0.496103 val loss: 0.692991
[Epoch 2] ogbg-moltoxcast: 0.497068 test loss: 0.693000
[Epoch 3; Iter    22/  229] train: loss: 0.6929821
[Epoch 3; Iter    52/  229] train: loss: 0.6929782
[Epoch 3; Iter    82/  229] train: loss: 0.6929922
[Epoch 3; Iter   112/  229] train: loss: 0.6929609
[Epoch 3; Iter   142/  229] train: loss: 0.6928953
[Epoch 3; Iter   172/  229] train: loss: 0.6928861
[Epoch 3; Iter   202/  229] train: loss: 0.6928747
[Epoch 3] ogbg-moltoxcast: 0.494515 val loss: 0.692828
[Epoch 3] ogbg-moltoxcast: 0.497311 test loss: 0.692854
[Epoch 4; Iter     3/  229] train: loss: 0.6929197
[Epoch 4; Iter    33/  229] train: loss: 0.6900464
[Epoch 4; Iter    63/  229] train: loss: 0.6738368
[Epoch 4; Iter    93/  229] train: loss: 0.6539524
[Epoch 4; Iter   123/  229] train: loss: 0.6121913
[Epoch 4; Iter   153/  229] train: loss: 0.5775990
[Epoch 4; Iter   183/  229] train: loss: 0.5166746
[Epoch 4; Iter   213/  229] train: loss: 0.4469429
[Epoch 4] ogbg-moltoxcast: 0.595498 val loss: 0.481272
[Epoch 4] ogbg-moltoxcast: 0.556060 test loss: 0.499907
[Epoch 5; Iter    14/  229] train: loss: 0.4213946
[Epoch 5; Iter    44/  229] train: loss: 0.3478724
[Epoch 5; Iter    74/  229] train: loss: 0.2868555
[Epoch 5; Iter   104/  229] train: loss: 0.3171404
[Epoch 5; Iter   134/  229] train: loss: 0.3228222
[Epoch 5; Iter   164/  229] train: loss: 0.2520163
[Epoch 5; Iter   194/  229] train: loss: 0.2550236
[Epoch 5; Iter   224/  229] train: loss: 0.1680996
[Epoch 5] ogbg-moltoxcast: 0.636365 val loss: 0.280028
[Epoch 5] ogbg-moltoxcast: 0.585944 test loss: 0.314591
[Epoch 6; Iter    25/  229] train: loss: 0.2597849
[Epoch 6; Iter    55/  229] train: loss: 0.2067361
[Epoch 6; Iter    85/  229] train: loss: 0.3019025
[Epoch 6; Iter   115/  229] train: loss: 0.2240948
[Epoch 6; Iter   145/  229] train: loss: 0.2003880
[Epoch 6; Iter   175/  229] train: loss: 0.1832266
[Epoch 6; Iter   205/  229] train: loss: 0.1764330
[Epoch 6] ogbg-moltoxcast: 0.657390 val loss: 0.262359
[Epoch 6] ogbg-moltoxcast: 0.618228 test loss: 0.299144
[Epoch 7; Iter     6/  229] train: loss: 0.1242949
[Epoch 7; Iter    36/  229] train: loss: 0.2334784
[Epoch 7; Iter    66/  229] train: loss: 0.2198029
[Epoch 7; Iter    96/  229] train: loss: 0.1846606
[Epoch 7; Iter   126/  229] train: loss: 0.2904757
[Epoch 7; Iter   156/  229] train: loss: 0.1761917
[Epoch 7; Iter   186/  229] train: loss: 0.3214080
[Epoch 7; Iter   216/  229] train: loss: 0.1975090
[Epoch 7] ogbg-moltoxcast: 0.642017 val loss: 0.270818
[Epoch 7] ogbg-moltoxcast: 0.595363 test loss: 0.315432
[Epoch 8; Iter    17/  229] train: loss: 0.1501595
[Epoch 8; Iter    47/  229] train: loss: 0.3101094
[Epoch 8; Iter    77/  229] train: loss: 0.1806228
[Epoch 8; Iter   107/  229] train: loss: 0.2607083
[Epoch 8; Iter   137/  229] train: loss: 0.1952269
[Epoch 8; Iter   167/  229] train: loss: 0.1692667
[Epoch 8; Iter   197/  229] train: loss: 0.2282378
[Epoch 8; Iter   227/  229] train: loss: 0.2127542
[Epoch 8] ogbg-moltoxcast: 0.646868 val loss: 0.263991
[Epoch 8] ogbg-moltoxcast: 0.614234 test loss: 0.304118
[Epoch 9; Iter    28/  229] train: loss: 0.1344221
[Epoch 9; Iter    58/  229] train: loss: 0.1329035
[Epoch 9; Iter    88/  229] train: loss: 0.2101739
[Epoch 9; Iter   118/  229] train: loss: 0.1155761
[Epoch 9; Iter   148/  229] train: loss: 0.2494125
[Epoch 9; Iter   178/  229] train: loss: 0.2278073
[Epoch 9; Iter   208/  229] train: loss: 0.1756353
[Epoch 9] ogbg-moltoxcast: 0.660623 val loss: 0.260824
[Epoch 9] ogbg-moltoxcast: 0.633628 test loss: 0.297956
[Epoch 10; Iter     9/  229] train: loss: 0.1464703
[Epoch 10; Iter    39/  229] train: loss: 0.1475478
[Epoch 10; Iter    69/  229] train: loss: 0.2261933
[Epoch 10; Iter    99/  229] train: loss: 0.2685210
[Epoch 10; Iter   129/  229] train: loss: 0.1717881
[Epoch 10; Iter   159/  229] train: loss: 0.2068834
[Epoch 10; Iter   189/  229] train: loss: 0.2400950
[Epoch 10; Iter   219/  229] train: loss: 0.2657329
[Epoch 10] ogbg-moltoxcast: 0.647911 val loss: 0.263234
[Epoch 10] ogbg-moltoxcast: 0.629747 test loss: 0.299039
[Epoch 11; Iter    20/  229] train: loss: 0.1642591
[Epoch 11; Iter    50/  229] train: loss: 0.1972732
[Epoch 11; Iter    80/  229] train: loss: 0.1729400
[Epoch 11; Iter   110/  229] train: loss: 0.1672244
[Epoch 11; Iter   140/  229] train: loss: 0.2610992
[Epoch 11; Iter   170/  229] train: loss: 0.2148610
[Epoch 11; Iter   200/  229] train: loss: 0.2833494
[Epoch 11] ogbg-moltoxcast: 0.655090 val loss: 0.256416
[Epoch 11] ogbg-moltoxcast: 0.637544 test loss: 0.294180
[Epoch 12; Iter     1/  229] train: loss: 0.1697549
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.7/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.7_6_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.7
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931752
[Epoch 1; Iter    60/  201] train: loss: 0.6931565
[Epoch 1; Iter    90/  201] train: loss: 0.6931267
[Epoch 1; Iter   120/  201] train: loss: 0.6931331
[Epoch 1; Iter   150/  201] train: loss: 0.6930910
[Epoch 1; Iter   180/  201] train: loss: 0.6930852
[Epoch 1] ogbg-moltoxcast: 0.501479 val loss: 0.693088
[Epoch 1] ogbg-moltoxcast: 0.505032 test loss: 0.693114
[Epoch 2; Iter     9/  201] train: loss: 0.6930718
[Epoch 2; Iter    39/  201] train: loss: 0.6931289
[Epoch 2; Iter    69/  201] train: loss: 0.6930729
[Epoch 2; Iter    99/  201] train: loss: 0.6931077
[Epoch 2; Iter   129/  201] train: loss: 0.6930671
[Epoch 2; Iter   159/  201] train: loss: 0.6930357
[Epoch 2; Iter   189/  201] train: loss: 0.6930410
[Epoch 2] ogbg-moltoxcast: 0.502042 val loss: 0.693011
[Epoch 2] ogbg-moltoxcast: 0.505108 test loss: 0.693041
[Epoch 3; Iter    18/  201] train: loss: 0.6929629
[Epoch 3; Iter    48/  201] train: loss: 0.6929358
[Epoch 3; Iter    78/  201] train: loss: 0.6929932
[Epoch 3; Iter   108/  201] train: loss: 0.6930074
[Epoch 3; Iter   138/  201] train: loss: 0.6929713
[Epoch 3; Iter   168/  201] train: loss: 0.6929646
[Epoch 3; Iter   198/  201] train: loss: 0.6928635
[Epoch 3] ogbg-moltoxcast: 0.501988 val loss: 0.692968
[Epoch 3] ogbg-moltoxcast: 0.505750 test loss: 0.693016
[Epoch 4; Iter    27/  201] train: loss: 0.6928504
[Epoch 4; Iter    57/  201] train: loss: 0.6928029
[Epoch 4; Iter    87/  201] train: loss: 0.6928223
[Epoch 4; Iter   117/  201] train: loss: 0.6892200
[Epoch 4; Iter   147/  201] train: loss: 0.6718765
[Epoch 4; Iter   177/  201] train: loss: 0.6396317
[Epoch 4] ogbg-moltoxcast: 0.589481 val loss: 0.845468
[Epoch 4] ogbg-moltoxcast: 0.548902 test loss: 0.867155
[Epoch 5; Iter     6/  201] train: loss: 0.5996794
[Epoch 5; Iter    36/  201] train: loss: 0.5360785
[Epoch 5; Iter    66/  201] train: loss: 0.5549142
[Epoch 5; Iter    96/  201] train: loss: 0.4554323
[Epoch 5; Iter   126/  201] train: loss: 0.3934679
[Epoch 5; Iter   156/  201] train: loss: 0.3750835
[Epoch 5; Iter   186/  201] train: loss: 0.2903076
[Epoch 5] ogbg-moltoxcast: 0.606278 val loss: 0.339901
[Epoch 5] ogbg-moltoxcast: 0.570234 test loss: 0.370139
[Epoch 6; Iter    15/  201] train: loss: 0.2328713
[Epoch 6; Iter    45/  201] train: loss: 0.2393056
[Epoch 6; Iter    75/  201] train: loss: 0.2044066
[Epoch 6; Iter   105/  201] train: loss: 0.1907526
[Epoch 6; Iter   135/  201] train: loss: 0.2368426
[Epoch 6; Iter   165/  201] train: loss: 0.2636032
[Epoch 6; Iter   195/  201] train: loss: 0.2142356
[Epoch 6] ogbg-moltoxcast: 0.633498 val loss: 0.264893
[Epoch 6] ogbg-moltoxcast: 0.590756 test loss: 0.299460
[Epoch 7; Iter    24/  201] train: loss: 0.1720559
[Epoch 7; Iter    54/  201] train: loss: 0.1518901
[Epoch 7; Iter    84/  201] train: loss: 0.2043067
[Epoch 7; Iter   114/  201] train: loss: 0.1875379
[Epoch 7; Iter   144/  201] train: loss: 0.2196993
[Epoch 7; Iter   174/  201] train: loss: 0.2319838
[Epoch 7] ogbg-moltoxcast: 0.633263 val loss: 0.268685
[Epoch 7] ogbg-moltoxcast: 0.609170 test loss: 0.304888
[Epoch 8; Iter     3/  201] train: loss: 0.2155738
[Epoch 8; Iter    33/  201] train: loss: 0.1442711
[Epoch 8; Iter    63/  201] train: loss: 0.3319829
[Epoch 8; Iter    93/  201] train: loss: 0.2165510
[Epoch 8; Iter   123/  201] train: loss: 0.1724153
[Epoch 8; Iter   153/  201] train: loss: 0.1190675
[Epoch 8; Iter   183/  201] train: loss: 0.2462971
[Epoch 8] ogbg-moltoxcast: 0.613759 val loss: 0.270947
[Epoch 8] ogbg-moltoxcast: 0.595829 test loss: 0.311921
[Epoch 9; Iter    12/  201] train: loss: 0.1355597
[Epoch 9; Iter    42/  201] train: loss: 0.1887088
[Epoch 9; Iter    72/  201] train: loss: 0.1808199
[Epoch 9; Iter   102/  201] train: loss: 0.2076936
[Epoch 9; Iter   132/  201] train: loss: 0.1800640
[Epoch 9; Iter   162/  201] train: loss: 0.1648707
[Epoch 9; Iter   192/  201] train: loss: 0.1596587
[Epoch 9] ogbg-moltoxcast: 0.618792 val loss: 0.265960
[Epoch 9] ogbg-moltoxcast: 0.617391 test loss: 0.297895
[Epoch 10; Iter    21/  201] train: loss: 0.1713680
[Epoch 10; Iter    51/  201] train: loss: 0.2035982
[Epoch 10; Iter    81/  201] train: loss: 0.2333419
[Epoch 10; Iter   111/  201] train: loss: 0.1489966
[Epoch 10; Iter   141/  201] train: loss: 0.2124023
[Epoch 10; Iter   171/  201] train: loss: 0.1297626
[Epoch 10; Iter   201/  201] train: loss: 0.0794879
[Epoch 10] ogbg-moltoxcast: 0.652261 val loss: 0.262542
[Epoch 10] ogbg-moltoxcast: 0.623499 test loss: 0.302073
[Epoch 11; Iter    30/  201] train: loss: 0.2297611
[Epoch 11; Iter    60/  201] train: loss: 0.1620771
[Epoch 11; Iter    90/  201] train: loss: 0.1350643
[Epoch 11; Iter   120/  201] train: loss: 0.2144228
[Epoch 11; Iter   150/  201] train: loss: 0.2114231
[Epoch 11; Iter   180/  201] train: loss: 0.2519114
[Epoch 11] ogbg-moltoxcast: 0.654631 val loss: 0.273813
[Epoch 11] ogbg-moltoxcast: 0.635269 test loss: 0.326147
[Epoch 12; Iter     9/  201] train: loss: 0.1911168
[Epoch 12; Iter    39/  201] train: loss: 0.2291534
[Epoch 12; Iter    69/  201] train: loss: 0.1569599
[Epoch 12; Iter    99/  201] train: loss: 0.1952681
[Epoch 12; Iter   129/  201] train: loss: 0.1875621
[Epoch 12; Iter   159/  201] train: loss: 0.2481352
[Epoch 12; Iter   189/  201] train: loss: 0.1240074
[Epoch 12] ogbg-moltoxcast: 0.648850 val loss: 0.278503
[Epoch 12] ogbg-moltoxcast: 0.627116 test loss: 0.338152
[Epoch 13; Iter    18/  201] train: loss: 0.2253049
[Epoch 13; Iter    48/  201] train: loss: 0.1905572
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.7/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.7_5_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.7
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931496
[Epoch 1; Iter    60/  201] train: loss: 0.6931607
[Epoch 1; Iter    90/  201] train: loss: 0.6931479
[Epoch 1; Iter   120/  201] train: loss: 0.6931822
[Epoch 1; Iter   150/  201] train: loss: 0.6932090
[Epoch 1; Iter   180/  201] train: loss: 0.6931303
[Epoch 1] ogbg-moltoxcast: 0.503922 val loss: 0.692992
[Epoch 1] ogbg-moltoxcast: 0.501722 test loss: 0.692982
[Epoch 2; Iter     9/  201] train: loss: 0.6930955
[Epoch 2; Iter    39/  201] train: loss: 0.6931201
[Epoch 2; Iter    69/  201] train: loss: 0.6931039
[Epoch 2; Iter    99/  201] train: loss: 0.6930931
[Epoch 2; Iter   129/  201] train: loss: 0.6930840
[Epoch 2; Iter   159/  201] train: loss: 0.6930745
[Epoch 2; Iter   189/  201] train: loss: 0.6929953
[Epoch 2] ogbg-moltoxcast: 0.504321 val loss: 0.692901
[Epoch 2] ogbg-moltoxcast: 0.500992 test loss: 0.692904
[Epoch 3; Iter    18/  201] train: loss: 0.6929591
[Epoch 3; Iter    48/  201] train: loss: 0.6929597
[Epoch 3; Iter    78/  201] train: loss: 0.6929199
[Epoch 3; Iter   108/  201] train: loss: 0.6929500
[Epoch 3; Iter   138/  201] train: loss: 0.6928267
[Epoch 3; Iter   168/  201] train: loss: 0.6927482
[Epoch 3; Iter   198/  201] train: loss: 0.6927767
[Epoch 3] ogbg-moltoxcast: 0.506644 val loss: 0.692785
[Epoch 3] ogbg-moltoxcast: 0.500035 test loss: 0.692806
[Epoch 4; Iter    27/  201] train: loss: 0.6927463
[Epoch 4; Iter    57/  201] train: loss: 0.6927769
[Epoch 4; Iter    87/  201] train: loss: 0.6927456
[Epoch 4; Iter   117/  201] train: loss: 0.6901658
[Epoch 4; Iter   147/  201] train: loss: 0.6682618
[Epoch 4; Iter   177/  201] train: loss: 0.6329003
[Epoch 4] ogbg-moltoxcast: 0.588749 val loss: 0.694347
[Epoch 4] ogbg-moltoxcast: 0.539594 test loss: 0.706667
[Epoch 5; Iter     6/  201] train: loss: 0.5992637
[Epoch 5; Iter    36/  201] train: loss: 0.5375719
[Epoch 5; Iter    66/  201] train: loss: 0.5044315
[Epoch 5; Iter    96/  201] train: loss: 0.4299706
[Epoch 5; Iter   126/  201] train: loss: 0.4173610
[Epoch 5; Iter   156/  201] train: loss: 0.3271319
[Epoch 5; Iter   186/  201] train: loss: 0.2649860
[Epoch 5] ogbg-moltoxcast: 0.595065 val loss: 0.348076
[Epoch 5] ogbg-moltoxcast: 0.556369 test loss: 0.391653
[Epoch 6; Iter    15/  201] train: loss: 0.2273289
[Epoch 6; Iter    45/  201] train: loss: 0.2423387
[Epoch 6; Iter    75/  201] train: loss: 0.1993056
[Epoch 6; Iter   105/  201] train: loss: 0.2075855
[Epoch 6; Iter   135/  201] train: loss: 0.1820988
[Epoch 6; Iter   165/  201] train: loss: 0.1763442
[Epoch 6; Iter   195/  201] train: loss: 0.2730641
[Epoch 6] ogbg-moltoxcast: 0.645484 val loss: 0.265853
[Epoch 6] ogbg-moltoxcast: 0.594560 test loss: 0.304787
[Epoch 7; Iter    24/  201] train: loss: 0.1734246
[Epoch 7; Iter    54/  201] train: loss: 0.2367882
[Epoch 7; Iter    84/  201] train: loss: 0.2476322
[Epoch 7; Iter   114/  201] train: loss: 0.2570729
[Epoch 7; Iter   144/  201] train: loss: 0.2613840
[Epoch 7; Iter   174/  201] train: loss: 0.1714389
[Epoch 7] ogbg-moltoxcast: 0.651871 val loss: 0.270262
[Epoch 7] ogbg-moltoxcast: 0.613235 test loss: 0.315119
[Epoch 8; Iter     3/  201] train: loss: 0.1935954
[Epoch 8; Iter    33/  201] train: loss: 0.1923045
[Epoch 8; Iter    63/  201] train: loss: 0.2697658
[Epoch 8; Iter    93/  201] train: loss: 0.2204461
[Epoch 8; Iter   123/  201] train: loss: 0.2164590
[Epoch 8; Iter   153/  201] train: loss: 0.1399016
[Epoch 8; Iter   183/  201] train: loss: 0.1398137
[Epoch 8] ogbg-moltoxcast: 0.642369 val loss: 0.261607
[Epoch 8] ogbg-moltoxcast: 0.621262 test loss: 0.293354
[Epoch 9; Iter    12/  201] train: loss: 0.1266377
[Epoch 9; Iter    42/  201] train: loss: 0.2849016
[Epoch 9; Iter    72/  201] train: loss: 0.2544283
[Epoch 9; Iter   102/  201] train: loss: 0.2374607
[Epoch 9; Iter   132/  201] train: loss: 0.1686105
[Epoch 9; Iter   162/  201] train: loss: 0.1901973
[Epoch 9; Iter   192/  201] train: loss: 0.1919325
[Epoch 9] ogbg-moltoxcast: 0.632822 val loss: 0.265820
[Epoch 9] ogbg-moltoxcast: 0.602151 test loss: 0.323200
[Epoch 10; Iter    21/  201] train: loss: 0.2211199
[Epoch 10; Iter    51/  201] train: loss: 0.1540994
[Epoch 10; Iter    81/  201] train: loss: 0.1559421
[Epoch 10; Iter   111/  201] train: loss: 0.1739060
[Epoch 10; Iter   141/  201] train: loss: 0.1448776
[Epoch 10; Iter   171/  201] train: loss: 0.2212767
[Epoch 10; Iter   201/  201] train: loss: 0.2670737
[Epoch 10] ogbg-moltoxcast: 0.658135 val loss: 0.268998
[Epoch 10] ogbg-moltoxcast: 0.625119 test loss: 0.310024
[Epoch 11; Iter    30/  201] train: loss: 0.2732173
[Epoch 11; Iter    60/  201] train: loss: 0.1835624
[Epoch 11; Iter    90/  201] train: loss: 0.1912943
[Epoch 11; Iter   120/  201] train: loss: 0.1066087
[Epoch 11; Iter   150/  201] train: loss: 0.1747405
[Epoch 11; Iter   180/  201] train: loss: 0.1500904
[Epoch 11] ogbg-moltoxcast: 0.644514 val loss: 0.264647
[Epoch 11] ogbg-moltoxcast: 0.633729 test loss: 0.302942
[Epoch 12; Iter     9/  201] train: loss: 0.1800050
[Epoch 12; Iter    39/  201] train: loss: 0.2108126
[Epoch 12; Iter    69/  201] train: loss: 0.1597778
[Epoch 12; Iter    99/  201] train: loss: 0.1249396
[Epoch 12; Iter   129/  201] train: loss: 0.1471969
[Epoch 12; Iter   159/  201] train: loss: 0.1809817
[Epoch 12; Iter   189/  201] train: loss: 0.1529514
[Epoch 12] ogbg-moltoxcast: 0.653686 val loss: 0.272725
[Epoch 12] ogbg-moltoxcast: 0.625112 test loss: 0.326451
[Epoch 13; Iter    18/  201] train: loss: 0.1542702
[Epoch 13; Iter    48/  201] train: loss: 0.1599507
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.7/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.7_4_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.7
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931525
[Epoch 1; Iter    60/  201] train: loss: 0.6932179
[Epoch 1; Iter    90/  201] train: loss: 0.6931480
[Epoch 1; Iter   120/  201] train: loss: 0.6931556
[Epoch 1; Iter   150/  201] train: loss: 0.6930797
[Epoch 1; Iter   180/  201] train: loss: 0.6931262
[Epoch 1] ogbg-moltoxcast: 0.497903 val loss: 0.693079
[Epoch 1] ogbg-moltoxcast: 0.498542 test loss: 0.693085
[Epoch 2; Iter     9/  201] train: loss: 0.6931091
[Epoch 2; Iter    39/  201] train: loss: 0.6930801
[Epoch 2; Iter    69/  201] train: loss: 0.6931018
[Epoch 2; Iter    99/  201] train: loss: 0.6930505
[Epoch 2; Iter   129/  201] train: loss: 0.6930972
[Epoch 2; Iter   159/  201] train: loss: 0.6930681
[Epoch 2; Iter   189/  201] train: loss: 0.6930535
[Epoch 2] ogbg-moltoxcast: 0.497717 val loss: 0.693010
[Epoch 2] ogbg-moltoxcast: 0.499409 test loss: 0.693017
[Epoch 3; Iter    18/  201] train: loss: 0.6930262
[Epoch 3; Iter    48/  201] train: loss: 0.6930099
[Epoch 3; Iter    78/  201] train: loss: 0.6930455
[Epoch 3; Iter   108/  201] train: loss: 0.6929576
[Epoch 3; Iter   138/  201] train: loss: 0.6929380
[Epoch 3; Iter   168/  201] train: loss: 0.6929398
[Epoch 3; Iter   198/  201] train: loss: 0.6929414
[Epoch 3] ogbg-moltoxcast: 0.498331 val loss: 0.692910
[Epoch 3] ogbg-moltoxcast: 0.499266 test loss: 0.692926
[Epoch 4; Iter    27/  201] train: loss: 0.6928924
[Epoch 4; Iter    57/  201] train: loss: 0.6928610
[Epoch 4; Iter    87/  201] train: loss: 0.6928225
[Epoch 4; Iter   117/  201] train: loss: 0.6898155
[Epoch 4; Iter   147/  201] train: loss: 0.6711754
[Epoch 4; Iter   177/  201] train: loss: 0.6460837
[Epoch 4] ogbg-moltoxcast: 0.590094 val loss: 0.778936
[Epoch 4] ogbg-moltoxcast: 0.557608 test loss: 0.802765
[Epoch 5; Iter     6/  201] train: loss: 0.6267019
[Epoch 5; Iter    36/  201] train: loss: 0.5804731
[Epoch 5; Iter    66/  201] train: loss: 0.5235378
[Epoch 5; Iter    96/  201] train: loss: 0.4736457
[Epoch 5; Iter   126/  201] train: loss: 0.3960684
[Epoch 5; Iter   156/  201] train: loss: 0.3161348
[Epoch 5; Iter   186/  201] train: loss: 0.3075832
[Epoch 5] ogbg-moltoxcast: 0.613898 val loss: 0.351514
[Epoch 5] ogbg-moltoxcast: 0.567883 test loss: 0.386412
[Epoch 6; Iter    15/  201] train: loss: 0.3290928
[Epoch 6; Iter    45/  201] train: loss: 0.3061614
[Epoch 6; Iter    75/  201] train: loss: 0.2498707
[Epoch 6; Iter   105/  201] train: loss: 0.3121412
[Epoch 6; Iter   135/  201] train: loss: 0.2510988
[Epoch 6; Iter   165/  201] train: loss: 0.3080216
[Epoch 6; Iter   195/  201] train: loss: 0.2599989
[Epoch 6] ogbg-moltoxcast: 0.636492 val loss: 0.278005
[Epoch 6] ogbg-moltoxcast: 0.594077 test loss: 0.312609
[Epoch 7; Iter    24/  201] train: loss: 0.1684502
[Epoch 7; Iter    54/  201] train: loss: 0.1532671
[Epoch 7; Iter    84/  201] train: loss: 0.1882364
[Epoch 7; Iter   114/  201] train: loss: 0.1495677
[Epoch 7; Iter   144/  201] train: loss: 0.2049345
[Epoch 7; Iter   174/  201] train: loss: 0.1825638
[Epoch 7] ogbg-moltoxcast: 0.651922 val loss: 0.260292
[Epoch 7] ogbg-moltoxcast: 0.619292 test loss: 0.296123
[Epoch 8; Iter     3/  201] train: loss: 0.1758666
[Epoch 8; Iter    33/  201] train: loss: 0.2375140
[Epoch 8; Iter    63/  201] train: loss: 0.3108995
[Epoch 8; Iter    93/  201] train: loss: 0.2228600
[Epoch 8; Iter   123/  201] train: loss: 0.1808507
[Epoch 8; Iter   153/  201] train: loss: 0.3095793
[Epoch 8; Iter   183/  201] train: loss: 0.2095107
[Epoch 8] ogbg-moltoxcast: 0.650102 val loss: 0.261008
[Epoch 8] ogbg-moltoxcast: 0.623139 test loss: 0.299837
[Epoch 9; Iter    12/  201] train: loss: 0.2285838
[Epoch 9; Iter    42/  201] train: loss: 0.2564039
[Epoch 9; Iter    72/  201] train: loss: 0.1292695
[Epoch 9; Iter   102/  201] train: loss: 0.2611439
[Epoch 9; Iter   132/  201] train: loss: 0.2273434
[Epoch 9; Iter   162/  201] train: loss: 0.2032702
[Epoch 9; Iter   192/  201] train: loss: 0.1467798
[Epoch 9] ogbg-moltoxcast: 0.656431 val loss: 0.257686
[Epoch 9] ogbg-moltoxcast: 0.629015 test loss: 0.317530
[Epoch 10; Iter    21/  201] train: loss: 0.0983161
[Epoch 10; Iter    51/  201] train: loss: 0.1887051
[Epoch 10; Iter    81/  201] train: loss: 0.1082870
[Epoch 10; Iter   111/  201] train: loss: 0.1994889
[Epoch 10; Iter   141/  201] train: loss: 0.1272238
[Epoch 10; Iter   171/  201] train: loss: 0.2229771
[Epoch 10; Iter   201/  201] train: loss: 0.1360634
[Epoch 10] ogbg-moltoxcast: 0.643137 val loss: 0.463527
[Epoch 10] ogbg-moltoxcast: 0.612966 test loss: 0.813808
[Epoch 11; Iter    30/  201] train: loss: 0.2092338
[Epoch 11; Iter    60/  201] train: loss: 0.1905399
[Epoch 11; Iter    90/  201] train: loss: 0.1727614
[Epoch 11; Iter   120/  201] train: loss: 0.1977796
[Epoch 11; Iter   150/  201] train: loss: 0.2084446
[Epoch 11; Iter   180/  201] train: loss: 0.1153344
[Epoch 11] ogbg-moltoxcast: 0.647753 val loss: 0.259974
[Epoch 11] ogbg-moltoxcast: 0.601356 test loss: 0.307550
[Epoch 12; Iter     9/  201] train: loss: 0.1768181
[Epoch 12; Iter    39/  201] train: loss: 0.2778435
[Epoch 12; Iter    69/  201] train: loss: 0.1820341
[Epoch 12; Iter    99/  201] train: loss: 0.1747159
[Epoch 12; Iter   129/  201] train: loss: 0.1342060
[Epoch 12; Iter   159/  201] train: loss: 0.1769286
[Epoch 12; Iter   189/  201] train: loss: 0.1645552
[Epoch 12] ogbg-moltoxcast: 0.661051 val loss: 0.256199
[Epoch 12] ogbg-moltoxcast: 0.643032 test loss: 0.292812
[Epoch 13; Iter    18/  201] train: loss: 0.1171339
[Epoch 13; Iter    48/  201] train: loss: 0.1739129
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.6/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.6_6_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.6
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931964
[Epoch 1; Iter    60/  172] train: loss: 0.6931013
[Epoch 1; Iter    90/  172] train: loss: 0.6931363
[Epoch 1; Iter   120/  172] train: loss: 0.6931720
[Epoch 1; Iter   150/  172] train: loss: 0.6931258
[Epoch 1] ogbg-moltoxcast: 0.498991 val loss: 0.693170
[Epoch 1] ogbg-moltoxcast: 0.505123 test loss: 0.693176
[Epoch 2; Iter     8/  172] train: loss: 0.6931237
[Epoch 2; Iter    38/  172] train: loss: 0.6931443
[Epoch 2; Iter    68/  172] train: loss: 0.6930588
[Epoch 2; Iter    98/  172] train: loss: 0.6930336
[Epoch 2; Iter   128/  172] train: loss: 0.6931142
[Epoch 2; Iter   158/  172] train: loss: 0.6930776
[Epoch 2] ogbg-moltoxcast: 0.498383 val loss: 0.693046
[Epoch 2] ogbg-moltoxcast: 0.505496 test loss: 0.693048
[Epoch 3; Iter    16/  172] train: loss: 0.6930501
[Epoch 3; Iter    46/  172] train: loss: 0.6930428
[Epoch 3; Iter    76/  172] train: loss: 0.6930398
[Epoch 3; Iter   106/  172] train: loss: 0.6929129
[Epoch 3; Iter   136/  172] train: loss: 0.6929462
[Epoch 3; Iter   166/  172] train: loss: 0.6929560
[Epoch 3] ogbg-moltoxcast: 0.498466 val loss: 0.693011
[Epoch 3] ogbg-moltoxcast: 0.505418 test loss: 0.693031
[Epoch 4; Iter    24/  172] train: loss: 0.6929238
[Epoch 4; Iter    54/  172] train: loss: 0.6929487
[Epoch 4; Iter    84/  172] train: loss: 0.6928962
[Epoch 4; Iter   114/  172] train: loss: 0.6928673
[Epoch 4; Iter   144/  172] train: loss: 0.6928794
[Epoch 4] ogbg-moltoxcast: 0.498573 val loss: 0.692894
[Epoch 4] ogbg-moltoxcast: 0.505902 test loss: 0.692923
[Epoch 5; Iter     2/  172] train: loss: 0.6928293
[Epoch 5; Iter    32/  172] train: loss: 0.6893734
[Epoch 5; Iter    62/  172] train: loss: 0.6705080
[Epoch 5; Iter    92/  172] train: loss: 0.6318710
[Epoch 5; Iter   122/  172] train: loss: 0.6230953
[Epoch 5; Iter   152/  172] train: loss: 0.5591416
[Epoch 5] ogbg-moltoxcast: 0.569259 val loss: 0.790545
[Epoch 5] ogbg-moltoxcast: 0.549130 test loss: 0.870445
[Epoch 6; Iter    10/  172] train: loss: 0.5000168
[Epoch 6; Iter    40/  172] train: loss: 0.4907867
[Epoch 6; Iter    70/  172] train: loss: 0.4146911
[Epoch 6; Iter   100/  172] train: loss: 0.3231906
[Epoch 6; Iter   130/  172] train: loss: 0.3298939
[Epoch 6; Iter   160/  172] train: loss: 0.2529688
[Epoch 6] ogbg-moltoxcast: 0.595834 val loss: 0.337829
[Epoch 6] ogbg-moltoxcast: 0.553867 test loss: 0.368843
[Epoch 7; Iter    18/  172] train: loss: 0.2264062
[Epoch 7; Iter    48/  172] train: loss: 0.2351702
[Epoch 7; Iter    78/  172] train: loss: 0.2007605
[Epoch 7; Iter   108/  172] train: loss: 0.2187365
[Epoch 7; Iter   138/  172] train: loss: 0.2442802
[Epoch 7; Iter   168/  172] train: loss: 0.1235182
[Epoch 7] ogbg-moltoxcast: 0.638373 val loss: 0.277088
[Epoch 7] ogbg-moltoxcast: 0.598510 test loss: 0.318614
[Epoch 8; Iter    26/  172] train: loss: 0.2229429
[Epoch 8; Iter    56/  172] train: loss: 0.1743428
[Epoch 8; Iter    86/  172] train: loss: 0.1120177
[Epoch 8; Iter   116/  172] train: loss: 0.1595534
[Epoch 8; Iter   146/  172] train: loss: 0.1676231
[Epoch 8] ogbg-moltoxcast: 0.633771 val loss: 0.286835
[Epoch 8] ogbg-moltoxcast: 0.600828 test loss: 0.340909
[Epoch 9; Iter     4/  172] train: loss: 0.3003255
[Epoch 9; Iter    34/  172] train: loss: 0.1225506
[Epoch 9; Iter    64/  172] train: loss: 0.1875441
[Epoch 9; Iter    94/  172] train: loss: 0.2345253
[Epoch 9; Iter   124/  172] train: loss: 0.1933506
[Epoch 9; Iter   154/  172] train: loss: 0.1689481
[Epoch 9] ogbg-moltoxcast: 0.632046 val loss: 0.274241
[Epoch 9] ogbg-moltoxcast: 0.607436 test loss: 0.318564
[Epoch 10; Iter    12/  172] train: loss: 0.2288784
[Epoch 10; Iter    42/  172] train: loss: 0.1902548
[Epoch 10; Iter    72/  172] train: loss: 0.2203960
[Epoch 10; Iter   102/  172] train: loss: 0.2775821
[Epoch 10; Iter   132/  172] train: loss: 0.1952550
[Epoch 10; Iter   162/  172] train: loss: 0.1535127
[Epoch 10] ogbg-moltoxcast: 0.623654 val loss: 0.280000
[Epoch 10] ogbg-moltoxcast: 0.603846 test loss: 0.328086
[Epoch 11; Iter    20/  172] train: loss: 0.2390647
[Epoch 11; Iter    50/  172] train: loss: 0.1612472
[Epoch 11; Iter    80/  172] train: loss: 0.1896134
[Epoch 11; Iter   110/  172] train: loss: 0.1546631
[Epoch 11; Iter   140/  172] train: loss: 0.2255079
[Epoch 11; Iter   170/  172] train: loss: 0.1514928
[Epoch 11] ogbg-moltoxcast: 0.615099 val loss: 0.307237
[Epoch 11] ogbg-moltoxcast: 0.595866 test loss: 0.354514
[Epoch 12; Iter    28/  172] train: loss: 0.2155376
[Epoch 12; Iter    58/  172] train: loss: 0.2690400
[Epoch 12; Iter    88/  172] train: loss: 0.1664121
[Epoch 12; Iter   118/  172] train: loss: 0.1501665
[Epoch 12; Iter   148/  172] train: loss: 0.1954968
[Epoch 12] ogbg-moltoxcast: 0.657042 val loss: 0.266764
[Epoch 12] ogbg-moltoxcast: 0.614895 test loss: 0.315740
[Epoch 13; Iter     6/  172] train: loss: 0.1997534
[Epoch 13; Iter    36/  172] train: loss: 0.2482779
[Epoch 13; Iter    66/  172] train: loss: 0.1863156
[Epoch 13; Iter    96/  172] train: loss: 0.1615413
[Epoch 13; Iter   126/  172] train: loss: 0.1494848
[Epoch 13; Iter   156/  172] train: loss: 0.1468084
[Epoch 13] ogbg-moltoxcast: 0.676357 val loss: 0.269639
[Epoch 13] ogbg-moltoxcast: 0.632886 test loss: 0.319881
[Epoch 14; Iter    14/  172] train: loss: 0.1320122
[Epoch 14; Iter    44/  172] train: loss: 0.1601496
[Epoch 14; Iter    74/  172] train: loss: 0.1665512
[Epoch 14; Iter   104/  172] train: loss: 0.1746393
[Epoch 14; Iter   134/  172] train: loss: 0.1534997
[Epoch 14; Iter   164/  172] train: loss: 0.2385955
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.6/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.6_5_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.6
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931977
[Epoch 1; Iter    60/  172] train: loss: 0.6931385
[Epoch 1; Iter    90/  172] train: loss: 0.6931643
[Epoch 1; Iter   120/  172] train: loss: 0.6930850
[Epoch 1; Iter   150/  172] train: loss: 0.6930875
[Epoch 1] ogbg-moltoxcast: 0.500101 val loss: 0.693003
[Epoch 1] ogbg-moltoxcast: 0.501035 test loss: 0.692983
[Epoch 2; Iter     8/  172] train: loss: 0.6931565
[Epoch 2; Iter    38/  172] train: loss: 0.6930835
[Epoch 2; Iter    68/  172] train: loss: 0.6930861
[Epoch 2; Iter    98/  172] train: loss: 0.6931214
[Epoch 2; Iter   128/  172] train: loss: 0.6930575
[Epoch 2; Iter   158/  172] train: loss: 0.6930960
[Epoch 2] ogbg-moltoxcast: 0.500208 val loss: 0.692913
[Epoch 2] ogbg-moltoxcast: 0.500719 test loss: 0.692900
[Epoch 3; Iter    16/  172] train: loss: 0.6930620
[Epoch 3; Iter    46/  172] train: loss: 0.6930257
[Epoch 3; Iter    76/  172] train: loss: 0.6930186
[Epoch 3; Iter   106/  172] train: loss: 0.6929737
[Epoch 3; Iter   136/  172] train: loss: 0.6930029
[Epoch 3; Iter   166/  172] train: loss: 0.6930100
[Epoch 3] ogbg-moltoxcast: 0.500760 val loss: 0.692805
[Epoch 3] ogbg-moltoxcast: 0.501003 test loss: 0.692796
[Epoch 4; Iter    24/  172] train: loss: 0.6928840
[Epoch 4; Iter    54/  172] train: loss: 0.6928999
[Epoch 4; Iter    84/  172] train: loss: 0.6928597
[Epoch 4; Iter   114/  172] train: loss: 0.6928247
[Epoch 4; Iter   144/  172] train: loss: 0.6928376
[Epoch 4] ogbg-moltoxcast: 0.501001 val loss: 0.692645
[Epoch 4] ogbg-moltoxcast: 0.501116 test loss: 0.692649
[Epoch 5; Iter     2/  172] train: loss: 0.6927728
[Epoch 5; Iter    32/  172] train: loss: 0.6891423
[Epoch 5; Iter    62/  172] train: loss: 0.6688976
[Epoch 5; Iter    92/  172] train: loss: 0.6444119
[Epoch 5; Iter   122/  172] train: loss: 0.6086126
[Epoch 5; Iter   152/  172] train: loss: 0.5741504
[Epoch 5] ogbg-moltoxcast: 0.593163 val loss: 0.753461
[Epoch 5] ogbg-moltoxcast: 0.569855 test loss: 0.828189
[Epoch 6; Iter    10/  172] train: loss: 0.4711062
[Epoch 6; Iter    40/  172] train: loss: 0.4486151
[Epoch 6; Iter    70/  172] train: loss: 0.3685791
[Epoch 6; Iter   100/  172] train: loss: 0.3627569
[Epoch 6; Iter   130/  172] train: loss: 0.3082427
[Epoch 6; Iter   160/  172] train: loss: 0.2407191
[Epoch 6] ogbg-moltoxcast: 0.617363 val loss: 0.320764
[Epoch 6] ogbg-moltoxcast: 0.575534 test loss: 0.354905
[Epoch 7; Iter    18/  172] train: loss: 0.2290836
[Epoch 7; Iter    48/  172] train: loss: 0.2474311
[Epoch 7; Iter    78/  172] train: loss: 0.2088737
[Epoch 7; Iter   108/  172] train: loss: 0.2606061
[Epoch 7; Iter   138/  172] train: loss: 0.1886728
[Epoch 7; Iter   168/  172] train: loss: 0.1467717
[Epoch 7] ogbg-moltoxcast: 0.622443 val loss: 0.284175
[Epoch 7] ogbg-moltoxcast: 0.591029 test loss: 0.324721
[Epoch 8; Iter    26/  172] train: loss: 0.1951577
[Epoch 8; Iter    56/  172] train: loss: 0.1403228
[Epoch 8; Iter    86/  172] train: loss: 0.1605740
[Epoch 8; Iter   116/  172] train: loss: 0.2911002
[Epoch 8; Iter   146/  172] train: loss: 0.1552531
[Epoch 8] ogbg-moltoxcast: 0.621519 val loss: 0.281000
[Epoch 8] ogbg-moltoxcast: 0.600979 test loss: 0.328126
[Epoch 9; Iter     4/  172] train: loss: 0.2078921
[Epoch 9; Iter    34/  172] train: loss: 0.2220455
[Epoch 9; Iter    64/  172] train: loss: 0.1449832
[Epoch 9; Iter    94/  172] train: loss: 0.2567557
[Epoch 9; Iter   124/  172] train: loss: 0.1941294
[Epoch 9; Iter   154/  172] train: loss: 0.2430442
[Epoch 9] ogbg-moltoxcast: 0.622249 val loss: 0.271897
[Epoch 9] ogbg-moltoxcast: 0.603976 test loss: 0.311876
[Epoch 10; Iter    12/  172] train: loss: 0.2369704
[Epoch 10; Iter    42/  172] train: loss: 0.2113727
[Epoch 10; Iter    72/  172] train: loss: 0.1984506
[Epoch 10; Iter   102/  172] train: loss: 0.2607291
[Epoch 10; Iter   132/  172] train: loss: 0.1660207
[Epoch 10; Iter   162/  172] train: loss: 0.1863314
[Epoch 10] ogbg-moltoxcast: 0.638366 val loss: 0.275862
[Epoch 10] ogbg-moltoxcast: 0.604028 test loss: 0.325513
[Epoch 11; Iter    20/  172] train: loss: 0.2450425
[Epoch 11; Iter    50/  172] train: loss: 0.1693426
[Epoch 11; Iter    80/  172] train: loss: 0.1906814
[Epoch 11; Iter   110/  172] train: loss: 0.1573628
[Epoch 11; Iter   140/  172] train: loss: 0.1808351
[Epoch 11; Iter   170/  172] train: loss: 0.2017192
[Epoch 11] ogbg-moltoxcast: 0.652198 val loss: 0.284956
[Epoch 11] ogbg-moltoxcast: 0.607843 test loss: 0.348680
[Epoch 12; Iter    28/  172] train: loss: 0.1313826
[Epoch 12; Iter    58/  172] train: loss: 0.2157181
[Epoch 12; Iter    88/  172] train: loss: 0.1187395
[Epoch 12; Iter   118/  172] train: loss: 0.1237009
[Epoch 12; Iter   148/  172] train: loss: 0.2208676
[Epoch 12] ogbg-moltoxcast: 0.625870 val loss: 0.276245
[Epoch 12] ogbg-moltoxcast: 0.605226 test loss: 0.317764
[Epoch 13; Iter     6/  172] train: loss: 0.1645748
[Epoch 13; Iter    36/  172] train: loss: 0.2642700
[Epoch 13; Iter    66/  172] train: loss: 0.2004360
[Epoch 13; Iter    96/  172] train: loss: 0.2191089
[Epoch 13; Iter   126/  172] train: loss: 0.1549000
[Epoch 13; Iter   156/  172] train: loss: 0.1279351
[Epoch 13] ogbg-moltoxcast: 0.665982 val loss: 0.262876
[Epoch 13] ogbg-moltoxcast: 0.625989 test loss: 0.308032
[Epoch 14; Iter    14/  172] train: loss: 0.1611396
[Epoch 14; Iter    44/  172] train: loss: 0.1875610
[Epoch 14; Iter    74/  172] train: loss: 0.1613921
[Epoch 14; Iter   104/  172] train: loss: 0.1769197
[Epoch 14; Iter   134/  172] train: loss: 0.1694619
[Epoch 14; Iter   164/  172] train: loss: 0.2111600
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/toxcast/scaff/train_prop=0.6/PNA_ogbg-moltoxcast_GraphCL_toxcast_scaff=0.6_4_26-05_10-06-11
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_scaff=0.6
logdir: runs/split/GraphCL/toxcast/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6932147
[Epoch 1; Iter    60/  172] train: loss: 0.6931595
[Epoch 1; Iter    90/  172] train: loss: 0.6930718
[Epoch 1; Iter   120/  172] train: loss: 0.6931674
[Epoch 1; Iter   150/  172] train: loss: 0.6931604
[Epoch 1] ogbg-moltoxcast: 0.500175 val loss: 0.693124
[Epoch 1] ogbg-moltoxcast: 0.497083 test loss: 0.693115
[Epoch 2; Iter     8/  172] train: loss: 0.6930826
[Epoch 2; Iter    38/  172] train: loss: 0.6930994
[Epoch 2; Iter    68/  172] train: loss: 0.6931323
[Epoch 2; Iter    98/  172] train: loss: 0.6931309
[Epoch 2; Iter   128/  172] train: loss: 0.6930395
[Epoch 2; Iter   158/  172] train: loss: 0.6931024
[Epoch 2] ogbg-moltoxcast: 0.500008 val loss: 0.693065
[Epoch 2] ogbg-moltoxcast: 0.497516 test loss: 0.693057
[Epoch 3; Iter    16/  172] train: loss: 0.6930259
[Epoch 3; Iter    46/  172] train: loss: 0.6930472
[Epoch 3; Iter    76/  172] train: loss: 0.6930681
[Epoch 3; Iter   106/  172] train: loss: 0.6930295
[Epoch 3; Iter   136/  172] train: loss: 0.6929925
[Epoch 3; Iter   166/  172] train: loss: 0.6929547
[Epoch 3] ogbg-moltoxcast: 0.500098 val loss: 0.692989
[Epoch 3] ogbg-moltoxcast: 0.497092 test loss: 0.692988
[Epoch 4; Iter    24/  172] train: loss: 0.6929799
[Epoch 4; Iter    54/  172] train: loss: 0.6929440
[Epoch 4; Iter    84/  172] train: loss: 0.6928633
[Epoch 4; Iter   114/  172] train: loss: 0.6929722
[Epoch 4; Iter   144/  172] train: loss: 0.6929056
[Epoch 4] ogbg-moltoxcast: 0.499702 val loss: 0.692848
[Epoch 4] ogbg-moltoxcast: 0.497146 test loss: 0.692844
[Epoch 5; Iter     2/  172] train: loss: 0.6928169
[Epoch 5; Iter    32/  172] train: loss: 0.6895931
[Epoch 5; Iter    62/  172] train: loss: 0.6704958
[Epoch 5; Iter    92/  172] train: loss: 0.6441014
[Epoch 5; Iter   122/  172] train: loss: 0.6168826
[Epoch 5; Iter   152/  172] train: loss: 0.5600573
[Epoch 5] ogbg-moltoxcast: 0.581278 val loss: 0.666820
[Epoch 5] ogbg-moltoxcast: 0.558318 test loss: 0.717167
[Epoch 6; Iter    10/  172] train: loss: 0.4913259
[Epoch 6; Iter    40/  172] train: loss: 0.4500909
[Epoch 6; Iter    70/  172] train: loss: 0.3953803
[Epoch 6; Iter   100/  172] train: loss: 0.3464210
[Epoch 6; Iter   130/  172] train: loss: 0.2756253
[Epoch 6; Iter   160/  172] train: loss: 0.2229949
[Epoch 6] ogbg-moltoxcast: 0.594519 val loss: 0.338182
[Epoch 6] ogbg-moltoxcast: 0.562397 test loss: 0.370871
[Epoch 7; Iter    18/  172] train: loss: 0.2569053
[Epoch 7; Iter    48/  172] train: loss: 0.2375906
[Epoch 7; Iter    78/  172] train: loss: 0.1716948
[Epoch 7; Iter   108/  172] train: loss: 0.3092316
[Epoch 7; Iter   138/  172] train: loss: 0.1854556
[Epoch 7; Iter   168/  172] train: loss: 0.2065119
[Epoch 7] ogbg-moltoxcast: 0.607528 val loss: 0.316073
[Epoch 7] ogbg-moltoxcast: 0.579879 test loss: 0.370433
[Epoch 8; Iter    26/  172] train: loss: 0.2127390
[Epoch 8; Iter    56/  172] train: loss: 0.1958650
[Epoch 8; Iter    86/  172] train: loss: 0.1856506
[Epoch 8; Iter   116/  172] train: loss: 0.1685110
[Epoch 8; Iter   146/  172] train: loss: 0.2735267
[Epoch 8] ogbg-moltoxcast: 0.628170 val loss: 0.278327
[Epoch 8] ogbg-moltoxcast: 0.589237 test loss: 0.324632
[Epoch 9; Iter     4/  172] train: loss: 0.1171731
[Epoch 9; Iter    34/  172] train: loss: 0.2434122
[Epoch 9; Iter    64/  172] train: loss: 0.1565314
[Epoch 9; Iter    94/  172] train: loss: 0.1702468
[Epoch 9; Iter   124/  172] train: loss: 0.2047853
[Epoch 9; Iter   154/  172] train: loss: 0.2283718
[Epoch 9] ogbg-moltoxcast: 0.627238 val loss: 0.290068
[Epoch 9] ogbg-moltoxcast: 0.582523 test loss: 0.355788
[Epoch 10; Iter    12/  172] train: loss: 0.1710878
[Epoch 10; Iter    42/  172] train: loss: 0.2384695
[Epoch 10; Iter    72/  172] train: loss: 0.2027016
[Epoch 10; Iter   102/  172] train: loss: 0.1573820
[Epoch 10; Iter   132/  172] train: loss: 0.2481829
[Epoch 10; Iter   162/  172] train: loss: 0.1701812
[Epoch 10] ogbg-moltoxcast: 0.653352 val loss: 0.285683
[Epoch 10] ogbg-moltoxcast: 0.612086 test loss: 0.487145
[Epoch 11; Iter    20/  172] train: loss: 0.1658185
[Epoch 11; Iter    50/  172] train: loss: 0.2058571
[Epoch 11; Iter    80/  172] train: loss: 0.1913502
[Epoch 11; Iter   110/  172] train: loss: 0.2251286
[Epoch 11; Iter   140/  172] train: loss: 0.2320077
[Epoch 11; Iter   170/  172] train: loss: 0.1319285
[Epoch 11] ogbg-moltoxcast: 0.646590 val loss: 0.489009
[Epoch 11] ogbg-moltoxcast: 0.601454 test loss: 1.008770
[Epoch 12; Iter    28/  172] train: loss: 0.1477254
[Epoch 12; Iter    58/  172] train: loss: 0.1338876
[Epoch 12; Iter    88/  172] train: loss: 0.2187630
[Epoch 12; Iter   118/  172] train: loss: 0.1890399
[Epoch 12; Iter   148/  172] train: loss: 0.2275471
[Epoch 12] ogbg-moltoxcast: 0.628814 val loss: 0.292083
[Epoch 12] ogbg-moltoxcast: 0.596824 test loss: 0.346328
[Epoch 13; Iter     6/  172] train: loss: 0.1989627
[Epoch 13; Iter    36/  172] train: loss: 0.1749489
[Epoch 13; Iter    66/  172] train: loss: 0.2052989
[Epoch 13; Iter    96/  172] train: loss: 0.1736345
[Epoch 13; Iter   126/  172] train: loss: 0.1060632
[Epoch 13; Iter   156/  172] train: loss: 0.1662567
[Epoch 13] ogbg-moltoxcast: 0.633893 val loss: 0.287080
[Epoch 13] ogbg-moltoxcast: 0.609188 test loss: 0.331062
[Epoch 14; Iter    14/  172] train: loss: 0.1535123
[Epoch 14; Iter    44/  172] train: loss: 0.1731124
[Epoch 14; Iter    74/  172] train: loss: 0.1615697
[Epoch 14; Iter   104/  172] train: loss: 0.1171483
[Epoch 14; Iter   134/  172] train: loss: 0.2502847
[Epoch 14; Iter   164/  172] train: loss: 0.1620925
[Epoch 12; Iter    31/  229] train: loss: 0.2031281
[Epoch 12; Iter    61/  229] train: loss: 0.1471766
[Epoch 12; Iter    91/  229] train: loss: 0.1920844
[Epoch 12; Iter   121/  229] train: loss: 0.2097706
[Epoch 12; Iter   151/  229] train: loss: 0.1225047
[Epoch 12; Iter   181/  229] train: loss: 0.2125894
[Epoch 12; Iter   211/  229] train: loss: 0.1899948
[Epoch 12] ogbg-moltoxcast: 0.686325 val loss: 0.250423
[Epoch 12] ogbg-moltoxcast: 0.652704 test loss: 0.290361
[Epoch 13; Iter    12/  229] train: loss: 0.1414850
[Epoch 13; Iter    42/  229] train: loss: 0.1331922
[Epoch 13; Iter    72/  229] train: loss: 0.1502374
[Epoch 13; Iter   102/  229] train: loss: 0.2535228
[Epoch 13; Iter   132/  229] train: loss: 0.1977923
[Epoch 13; Iter   162/  229] train: loss: 0.1461200
[Epoch 13; Iter   192/  229] train: loss: 0.1773746
[Epoch 13; Iter   222/  229] train: loss: 0.2143234
[Epoch 13] ogbg-moltoxcast: 0.671107 val loss: 0.267487
[Epoch 13] ogbg-moltoxcast: 0.638223 test loss: 0.312333
[Epoch 14; Iter    23/  229] train: loss: 0.1860651
[Epoch 14; Iter    53/  229] train: loss: 0.1954989
[Epoch 14; Iter    83/  229] train: loss: 0.2435721
[Epoch 14; Iter   113/  229] train: loss: 0.1685308
[Epoch 14; Iter   143/  229] train: loss: 0.1835873
[Epoch 14; Iter   173/  229] train: loss: 0.1954848
[Epoch 14; Iter   203/  229] train: loss: 0.1953439
[Epoch 14] ogbg-moltoxcast: 0.671789 val loss: 0.253585
[Epoch 14] ogbg-moltoxcast: 0.650863 test loss: 0.290018
[Epoch 15; Iter     4/  229] train: loss: 0.1972898
[Epoch 15; Iter    34/  229] train: loss: 0.1071968
[Epoch 15; Iter    64/  229] train: loss: 0.1467360
[Epoch 15; Iter    94/  229] train: loss: 0.2779123
[Epoch 15; Iter   124/  229] train: loss: 0.1454795
[Epoch 15; Iter   154/  229] train: loss: 0.1562332
[Epoch 15; Iter   184/  229] train: loss: 0.1535858
[Epoch 15; Iter   214/  229] train: loss: 0.2280031
[Epoch 15] ogbg-moltoxcast: 0.664409 val loss: 0.258796
[Epoch 15] ogbg-moltoxcast: 0.646099 test loss: 0.300706
[Epoch 16; Iter    15/  229] train: loss: 0.2621205
[Epoch 16; Iter    45/  229] train: loss: 0.1429835
[Epoch 16; Iter    75/  229] train: loss: 0.1283883
[Epoch 16; Iter   105/  229] train: loss: 0.1649528
[Epoch 16; Iter   135/  229] train: loss: 0.1660182
[Epoch 16; Iter   165/  229] train: loss: 0.1756967
[Epoch 16; Iter   195/  229] train: loss: 0.2203406
[Epoch 16; Iter   225/  229] train: loss: 0.1433184
[Epoch 16] ogbg-moltoxcast: 0.686647 val loss: 0.258550
[Epoch 16] ogbg-moltoxcast: 0.651018 test loss: 0.296055
[Epoch 17; Iter    26/  229] train: loss: 0.1644648
[Epoch 17; Iter    56/  229] train: loss: 0.1893532
[Epoch 17; Iter    86/  229] train: loss: 0.1661026
[Epoch 17; Iter   116/  229] train: loss: 0.2133585
[Epoch 17; Iter   146/  229] train: loss: 0.1732506
[Epoch 17; Iter   176/  229] train: loss: 0.2555714
[Epoch 17; Iter   206/  229] train: loss: 0.1918997
[Epoch 17] ogbg-moltoxcast: 0.663704 val loss: 0.256230
[Epoch 17] ogbg-moltoxcast: 0.659831 test loss: 0.290555
[Epoch 18; Iter     7/  229] train: loss: 0.1235988
[Epoch 18; Iter    37/  229] train: loss: 0.1733645
[Epoch 18; Iter    67/  229] train: loss: 0.1666220
[Epoch 18; Iter    97/  229] train: loss: 0.2662913
[Epoch 18; Iter   127/  229] train: loss: 0.1918034
[Epoch 18; Iter   157/  229] train: loss: 0.1628761
[Epoch 18; Iter   187/  229] train: loss: 0.1000528
[Epoch 18; Iter   217/  229] train: loss: 0.2255740
[Epoch 18] ogbg-moltoxcast: 0.681469 val loss: 0.252707
[Epoch 18] ogbg-moltoxcast: 0.650624 test loss: 0.299931
[Epoch 19; Iter    18/  229] train: loss: 0.2241743
[Epoch 19; Iter    48/  229] train: loss: 0.1799857
[Epoch 19; Iter    78/  229] train: loss: 0.0964426
[Epoch 19; Iter   108/  229] train: loss: 0.1543945
[Epoch 19; Iter   138/  229] train: loss: 0.1078008
[Epoch 19; Iter   168/  229] train: loss: 0.2119978
[Epoch 19; Iter   198/  229] train: loss: 0.2076660
[Epoch 19; Iter   228/  229] train: loss: 0.1527338
[Epoch 19] ogbg-moltoxcast: 0.688204 val loss: 0.261228
[Epoch 19] ogbg-moltoxcast: 0.650621 test loss: 0.316961
[Epoch 20; Iter    29/  229] train: loss: 0.1841306
[Epoch 20; Iter    59/  229] train: loss: 0.2238402
[Epoch 20; Iter    89/  229] train: loss: 0.1530993
[Epoch 20; Iter   119/  229] train: loss: 0.1550989
[Epoch 20; Iter   149/  229] train: loss: 0.2631868
[Epoch 20; Iter   179/  229] train: loss: 0.1067931
[Epoch 20; Iter   209/  229] train: loss: 0.1586499
[Epoch 20] ogbg-moltoxcast: 0.672676 val loss: 0.254327
[Epoch 20] ogbg-moltoxcast: 0.650180 test loss: 0.297033
[Epoch 21; Iter    10/  229] train: loss: 0.2034116
[Epoch 21; Iter    40/  229] train: loss: 0.1096021
[Epoch 21; Iter    70/  229] train: loss: 0.2052514
[Epoch 21; Iter   100/  229] train: loss: 0.2243803
[Epoch 21; Iter   130/  229] train: loss: 0.1872137
[Epoch 21; Iter   160/  229] train: loss: 0.1857046
[Epoch 21; Iter   190/  229] train: loss: 0.1382120
[Epoch 21; Iter   220/  229] train: loss: 0.1934041
[Epoch 21] ogbg-moltoxcast: 0.681606 val loss: 0.256393
[Epoch 21] ogbg-moltoxcast: 0.660652 test loss: 0.297870
[Epoch 22; Iter    21/  229] train: loss: 0.1609903
[Epoch 22; Iter    51/  229] train: loss: 0.1723742
[Epoch 22; Iter    81/  229] train: loss: 0.1641800
[Epoch 22; Iter   111/  229] train: loss: 0.2130216
[Epoch 22; Iter   141/  229] train: loss: 0.1608880
[Epoch 22; Iter   171/  229] train: loss: 0.1838827
[Epoch 22; Iter   201/  229] train: loss: 0.1494303
[Epoch 22] ogbg-moltoxcast: 0.692948 val loss: 0.246584
[Epoch 22] ogbg-moltoxcast: 0.654394 test loss: 0.292584
[Epoch 23; Iter     2/  229] train: loss: 0.1758936
[Epoch 23; Iter    32/  229] train: loss: 0.1222940
[Epoch 23; Iter    62/  229] train: loss: 0.0894228
[Epoch 23; Iter    92/  229] train: loss: 0.1092476
[Epoch 23; Iter   122/  229] train: loss: 0.1616814
[Epoch 23; Iter   152/  229] train: loss: 0.1065118
[Epoch 23; Iter   182/  229] train: loss: 0.1741840
[Epoch 23; Iter   212/  229] train: loss: 0.1956892
[Epoch 23] ogbg-moltoxcast: 0.685589 val loss: 0.248151
[Epoch 23] ogbg-moltoxcast: 0.661571 test loss: 0.291653
[Epoch 24; Iter    13/  229] train: loss: 0.1243139
[Epoch 24; Iter    43/  229] train: loss: 0.2081683
[Epoch 24; Iter    73/  229] train: loss: 0.1621563
[Epoch 24; Iter   103/  229] train: loss: 0.1812685
[Epoch 24; Iter   133/  229] train: loss: 0.2008556
[Epoch 24; Iter   163/  229] train: loss: 0.2031571
[Epoch 24; Iter   193/  229] train: loss: 0.1608237
[Epoch 24; Iter   223/  229] train: loss: 0.1303243
[Epoch 24] ogbg-moltoxcast: 0.694772 val loss: 0.249901
[Epoch 24] ogbg-moltoxcast: 0.663000 test loss: 0.293329
[Epoch 25; Iter    24/  229] train: loss: 0.1871662
[Epoch 25; Iter    54/  229] train: loss: 0.1833425
[Epoch 25; Iter    84/  229] train: loss: 0.1756150
[Epoch 25; Iter   114/  229] train: loss: 0.2920239
[Epoch 25; Iter   144/  229] train: loss: 0.1256569
[Epoch 25; Iter   174/  229] train: loss: 0.2040818
[Epoch 25; Iter   204/  229] train: loss: 0.1272948
[Epoch 25] ogbg-moltoxcast: 0.678285 val loss: 0.250861
[Epoch 25] ogbg-moltoxcast: 0.646854 test loss: 0.300108
[Epoch 26; Iter     5/  229] train: loss: 0.1445680
[Epoch 26; Iter    35/  229] train: loss: 0.1727083
[Epoch 26; Iter    65/  229] train: loss: 0.1363016
[Epoch 26; Iter    95/  229] train: loss: 0.1515927
[Epoch 26; Iter   125/  229] train: loss: 0.1593375
[Epoch 26; Iter   155/  229] train: loss: 0.1673769
[Epoch 26; Iter   185/  229] train: loss: 0.1607859
[Epoch 26; Iter   215/  229] train: loss: 0.1796100
[Epoch 26] ogbg-moltoxcast: 0.685968 val loss: 0.250851
[Epoch 26] ogbg-moltoxcast: 0.661590 test loss: 0.292664
[Epoch 27; Iter    16/  229] train: loss: 0.0794627
[Epoch 27; Iter    46/  229] train: loss: 0.1768448
[Epoch 27; Iter    76/  229] train: loss: 0.1290205
[Epoch 27; Iter   106/  229] train: loss: 0.1937108
[Epoch 27; Iter   136/  229] train: loss: 0.1687517
[Epoch 27; Iter   166/  229] train: loss: 0.2971437
[Epoch 27; Iter   196/  229] train: loss: 0.1950769
[Epoch 27; Iter   226/  229] train: loss: 0.1934619
[Epoch 27] ogbg-moltoxcast: 0.689831 val loss: 0.250736
[Epoch 27] ogbg-moltoxcast: 0.664529 test loss: 0.290499
[Epoch 12; Iter    31/  229] train: loss: 0.2080998
[Epoch 12; Iter    61/  229] train: loss: 0.1754972
[Epoch 12; Iter    91/  229] train: loss: 0.1588525
[Epoch 12; Iter   121/  229] train: loss: 0.3343519
[Epoch 12; Iter   151/  229] train: loss: 0.2134895
[Epoch 12; Iter   181/  229] train: loss: 0.2254194
[Epoch 12; Iter   211/  229] train: loss: 0.3303543
[Epoch 12] ogbg-moltoxcast: 0.638282 val loss: 0.269231
[Epoch 12] ogbg-moltoxcast: 0.614877 test loss: 0.306652
[Epoch 13; Iter    12/  229] train: loss: 0.2338797
[Epoch 13; Iter    42/  229] train: loss: 0.1896430
[Epoch 13; Iter    72/  229] train: loss: 0.2011543
[Epoch 13; Iter   102/  229] train: loss: 0.2187740
[Epoch 13; Iter   132/  229] train: loss: 0.1343291
[Epoch 13; Iter   162/  229] train: loss: 0.2382677
[Epoch 13; Iter   192/  229] train: loss: 0.1498409
[Epoch 13; Iter   222/  229] train: loss: 0.1869453
[Epoch 13] ogbg-moltoxcast: 0.677477 val loss: 0.252988
[Epoch 13] ogbg-moltoxcast: 0.622937 test loss: 0.303118
[Epoch 14; Iter    23/  229] train: loss: 0.1967467
[Epoch 14; Iter    53/  229] train: loss: 0.1439899
[Epoch 14; Iter    83/  229] train: loss: 0.1838527
[Epoch 14; Iter   113/  229] train: loss: 0.1431629
[Epoch 14; Iter   143/  229] train: loss: 0.2634815
[Epoch 14; Iter   173/  229] train: loss: 0.1305679
[Epoch 14; Iter   203/  229] train: loss: 0.1940115
[Epoch 14] ogbg-moltoxcast: 0.667502 val loss: 0.265423
[Epoch 14] ogbg-moltoxcast: 0.637832 test loss: 0.327665
[Epoch 15; Iter     4/  229] train: loss: 0.1647985
[Epoch 15; Iter    34/  229] train: loss: 0.2356035
[Epoch 15; Iter    64/  229] train: loss: 0.2041099
[Epoch 15; Iter    94/  229] train: loss: 0.1523726
[Epoch 15; Iter   124/  229] train: loss: 0.1380882
[Epoch 15; Iter   154/  229] train: loss: 0.1997935
[Epoch 15; Iter   184/  229] train: loss: 0.1773386
[Epoch 15; Iter   214/  229] train: loss: 0.1262966
[Epoch 15] ogbg-moltoxcast: 0.660432 val loss: 0.266416
[Epoch 15] ogbg-moltoxcast: 0.646706 test loss: 0.307855
[Epoch 16; Iter    15/  229] train: loss: 0.1986961
[Epoch 16; Iter    45/  229] train: loss: 0.1228503
[Epoch 16; Iter    75/  229] train: loss: 0.1731459
[Epoch 16; Iter   105/  229] train: loss: 0.1539764
[Epoch 16; Iter   135/  229] train: loss: 0.1828572
[Epoch 16; Iter   165/  229] train: loss: 0.1242533
[Epoch 16; Iter   195/  229] train: loss: 0.1556504
[Epoch 16; Iter   225/  229] train: loss: 0.2385768
[Epoch 16] ogbg-moltoxcast: 0.657208 val loss: 0.265919
[Epoch 16] ogbg-moltoxcast: 0.639020 test loss: 0.309037
[Epoch 17; Iter    26/  229] train: loss: 0.1704543
[Epoch 17; Iter    56/  229] train: loss: 0.1051925
[Epoch 17; Iter    86/  229] train: loss: 0.2293741
[Epoch 17; Iter   116/  229] train: loss: 0.2204001
[Epoch 17; Iter   146/  229] train: loss: 0.1685430
[Epoch 17; Iter   176/  229] train: loss: 0.2520857
[Epoch 17; Iter   206/  229] train: loss: 0.1424820
[Epoch 17] ogbg-moltoxcast: 0.675543 val loss: 0.255897
[Epoch 17] ogbg-moltoxcast: 0.641731 test loss: 0.427366
[Epoch 18; Iter     7/  229] train: loss: 0.1727945
[Epoch 18; Iter    37/  229] train: loss: 0.2088410
[Epoch 18; Iter    67/  229] train: loss: 0.1716194
[Epoch 18; Iter    97/  229] train: loss: 0.1422277
[Epoch 18; Iter   127/  229] train: loss: 0.1853539
[Epoch 18; Iter   157/  229] train: loss: 0.1777355
[Epoch 18; Iter   187/  229] train: loss: 0.1832815
[Epoch 18; Iter   217/  229] train: loss: 0.2452006
[Epoch 18] ogbg-moltoxcast: 0.667970 val loss: 0.251713
[Epoch 18] ogbg-moltoxcast: 0.644340 test loss: 0.300040
[Epoch 19; Iter    18/  229] train: loss: 0.1037812
[Epoch 19; Iter    48/  229] train: loss: 0.2299693
[Epoch 19; Iter    78/  229] train: loss: 0.1431653
[Epoch 19; Iter   108/  229] train: loss: 0.1578903
[Epoch 19; Iter   138/  229] train: loss: 0.1875356
[Epoch 19; Iter   168/  229] train: loss: 0.2497108
[Epoch 19; Iter   198/  229] train: loss: 0.1594004
[Epoch 19; Iter   228/  229] train: loss: 0.1786383
[Epoch 19] ogbg-moltoxcast: 0.681935 val loss: 0.253997
[Epoch 19] ogbg-moltoxcast: 0.646396 test loss: 0.319444
[Epoch 20; Iter    29/  229] train: loss: 0.1331606
[Epoch 20; Iter    59/  229] train: loss: 0.1588251
[Epoch 20; Iter    89/  229] train: loss: 0.2045101
[Epoch 20; Iter   119/  229] train: loss: 0.1259958
[Epoch 20; Iter   149/  229] train: loss: 0.2248960
[Epoch 20; Iter   179/  229] train: loss: 0.1888027
[Epoch 20; Iter   209/  229] train: loss: 0.1474017
[Epoch 20] ogbg-moltoxcast: 0.680366 val loss: 0.252502
[Epoch 20] ogbg-moltoxcast: 0.647769 test loss: 0.297535
[Epoch 21; Iter    10/  229] train: loss: 0.2031668
[Epoch 21; Iter    40/  229] train: loss: 0.1386229
[Epoch 21; Iter    70/  229] train: loss: 0.2046186
[Epoch 21; Iter   100/  229] train: loss: 0.1553094
[Epoch 21; Iter   130/  229] train: loss: 0.1917966
[Epoch 21; Iter   160/  229] train: loss: 0.1798319
[Epoch 21; Iter   190/  229] train: loss: 0.2009224
[Epoch 21; Iter   220/  229] train: loss: 0.1501229
[Epoch 21] ogbg-moltoxcast: 0.691472 val loss: 0.245858
[Epoch 21] ogbg-moltoxcast: 0.660199 test loss: 0.286703
[Epoch 22; Iter    21/  229] train: loss: 0.1029318
[Epoch 22; Iter    51/  229] train: loss: 0.2163651
[Epoch 22; Iter    81/  229] train: loss: 0.1331507
[Epoch 22; Iter   111/  229] train: loss: 0.2032978
[Epoch 22; Iter   141/  229] train: loss: 0.1590571
[Epoch 22; Iter   171/  229] train: loss: 0.2055008
[Epoch 22; Iter   201/  229] train: loss: 0.1359323
[Epoch 22] ogbg-moltoxcast: 0.677290 val loss: 0.249121
[Epoch 22] ogbg-moltoxcast: 0.657873 test loss: 0.287130
[Epoch 23; Iter     2/  229] train: loss: 0.1415881
[Epoch 23; Iter    32/  229] train: loss: 0.1556800
[Epoch 23; Iter    62/  229] train: loss: 0.1493983
[Epoch 23; Iter    92/  229] train: loss: 0.1250805
[Epoch 23; Iter   122/  229] train: loss: 0.1492372
[Epoch 23; Iter   152/  229] train: loss: 0.2418284
[Epoch 23; Iter   182/  229] train: loss: 0.1677327
[Epoch 23; Iter   212/  229] train: loss: 0.1364862
[Epoch 23] ogbg-moltoxcast: 0.682496 val loss: 0.259285
[Epoch 23] ogbg-moltoxcast: 0.656725 test loss: 0.301605
[Epoch 24; Iter    13/  229] train: loss: 0.1235118
[Epoch 24; Iter    43/  229] train: loss: 0.1952555
[Epoch 24; Iter    73/  229] train: loss: 0.1171175
[Epoch 24; Iter   103/  229] train: loss: 0.2572977
[Epoch 24; Iter   133/  229] train: loss: 0.1261259
[Epoch 24; Iter   163/  229] train: loss: 0.1383492
[Epoch 24; Iter   193/  229] train: loss: 0.1990776
[Epoch 24; Iter   223/  229] train: loss: 0.1363334
[Epoch 24] ogbg-moltoxcast: 0.680667 val loss: 0.256320
[Epoch 24] ogbg-moltoxcast: 0.660891 test loss: 0.300389
[Epoch 25; Iter    24/  229] train: loss: 0.1091809
[Epoch 25; Iter    54/  229] train: loss: 0.1095771
[Epoch 25; Iter    84/  229] train: loss: 0.1409508
[Epoch 25; Iter   114/  229] train: loss: 0.2294924
[Epoch 25; Iter   144/  229] train: loss: 0.1784180
[Epoch 25; Iter   174/  229] train: loss: 0.1422440
[Epoch 25; Iter   204/  229] train: loss: 0.1330562
[Epoch 25] ogbg-moltoxcast: 0.672448 val loss: 0.252057
[Epoch 25] ogbg-moltoxcast: 0.655930 test loss: 0.296026
[Epoch 26; Iter     5/  229] train: loss: 0.1612006
[Epoch 26; Iter    35/  229] train: loss: 0.1668557
[Epoch 26; Iter    65/  229] train: loss: 0.1828091
[Epoch 26; Iter    95/  229] train: loss: 0.1905977
[Epoch 26; Iter   125/  229] train: loss: 0.2004853
[Epoch 26; Iter   155/  229] train: loss: 0.1535290
[Epoch 26; Iter   185/  229] train: loss: 0.1164474
[Epoch 26; Iter   215/  229] train: loss: 0.1545770
[Epoch 26] ogbg-moltoxcast: 0.674547 val loss: 0.259272
[Epoch 26] ogbg-moltoxcast: 0.656683 test loss: 0.300069
[Epoch 27; Iter    16/  229] train: loss: 0.1272108
[Epoch 27; Iter    46/  229] train: loss: 0.1575035
[Epoch 27; Iter    76/  229] train: loss: 0.1481263
[Epoch 27; Iter   106/  229] train: loss: 0.0883177
[Epoch 27; Iter   136/  229] train: loss: 0.1813634
[Epoch 27; Iter   166/  229] train: loss: 0.1590221
[Epoch 27; Iter   196/  229] train: loss: 0.2088019
[Epoch 27; Iter   226/  229] train: loss: 0.1353835
[Epoch 27] ogbg-moltoxcast: 0.672392 val loss: 0.296909
[Epoch 27] ogbg-moltoxcast: 0.669750 test loss: 0.293892
[Epoch 12; Iter    31/  229] train: loss: 0.2377868
[Epoch 12; Iter    61/  229] train: loss: 0.2557354
[Epoch 12; Iter    91/  229] train: loss: 0.1506346
[Epoch 12; Iter   121/  229] train: loss: 0.1301379
[Epoch 12; Iter   151/  229] train: loss: 0.1629375
[Epoch 12; Iter   181/  229] train: loss: 0.2041616
[Epoch 12; Iter   211/  229] train: loss: 0.1397375
[Epoch 12] ogbg-moltoxcast: 0.670327 val loss: 0.264262
[Epoch 12] ogbg-moltoxcast: 0.646625 test loss: 0.302084
[Epoch 13; Iter    12/  229] train: loss: 0.1851023
[Epoch 13; Iter    42/  229] train: loss: 0.1906956
[Epoch 13; Iter    72/  229] train: loss: 0.1965116
[Epoch 13; Iter   102/  229] train: loss: 0.2033323
[Epoch 13; Iter   132/  229] train: loss: 0.2060351
[Epoch 13; Iter   162/  229] train: loss: 0.2093815
[Epoch 13; Iter   192/  229] train: loss: 0.2028843
[Epoch 13; Iter   222/  229] train: loss: 0.1479542
[Epoch 13] ogbg-moltoxcast: 0.675697 val loss: 0.255000
[Epoch 13] ogbg-moltoxcast: 0.633107 test loss: 0.293044
[Epoch 14; Iter    23/  229] train: loss: 0.2929289
[Epoch 14; Iter    53/  229] train: loss: 0.1499250
[Epoch 14; Iter    83/  229] train: loss: 0.1666876
[Epoch 14; Iter   113/  229] train: loss: 0.1813167
[Epoch 14; Iter   143/  229] train: loss: 0.1689522
[Epoch 14; Iter   173/  229] train: loss: 0.1585731
[Epoch 14; Iter   203/  229] train: loss: 0.1730179
[Epoch 14] ogbg-moltoxcast: 0.660476 val loss: 0.276127
[Epoch 14] ogbg-moltoxcast: 0.628526 test loss: 0.299183
[Epoch 15; Iter     4/  229] train: loss: 0.2877989
[Epoch 15; Iter    34/  229] train: loss: 0.1604621
[Epoch 15; Iter    64/  229] train: loss: 0.1235311
[Epoch 15; Iter    94/  229] train: loss: 0.2106937
[Epoch 15; Iter   124/  229] train: loss: 0.1564271
[Epoch 15; Iter   154/  229] train: loss: 0.2847158
[Epoch 15; Iter   184/  229] train: loss: 0.1904436
[Epoch 15; Iter   214/  229] train: loss: 0.1663140
[Epoch 15] ogbg-moltoxcast: 0.679583 val loss: 0.255443
[Epoch 15] ogbg-moltoxcast: 0.638748 test loss: 0.297396
[Epoch 16; Iter    15/  229] train: loss: 0.1287847
[Epoch 16; Iter    45/  229] train: loss: 0.2178437
[Epoch 16; Iter    75/  229] train: loss: 0.1689377
[Epoch 16; Iter   105/  229] train: loss: 0.2265918
[Epoch 16; Iter   135/  229] train: loss: 0.1322136
[Epoch 16; Iter   165/  229] train: loss: 0.1681122
[Epoch 16; Iter   195/  229] train: loss: 0.2111669
[Epoch 16; Iter   225/  229] train: loss: 0.1596265
[Epoch 16] ogbg-moltoxcast: 0.690708 val loss: 0.255590
[Epoch 16] ogbg-moltoxcast: 0.646017 test loss: 0.295528
[Epoch 17; Iter    26/  229] train: loss: 0.1277740
[Epoch 17; Iter    56/  229] train: loss: 0.1766459
[Epoch 17; Iter    86/  229] train: loss: 0.0968527
[Epoch 17; Iter   116/  229] train: loss: 0.1174762
[Epoch 17; Iter   146/  229] train: loss: 0.2103632
[Epoch 17; Iter   176/  229] train: loss: 0.1515434
[Epoch 17; Iter   206/  229] train: loss: 0.2067869
[Epoch 17] ogbg-moltoxcast: 0.609333 val loss: 0.378546
[Epoch 17] ogbg-moltoxcast: 0.565228 test loss: 0.629970
[Epoch 18; Iter     7/  229] train: loss: 0.1891208
[Epoch 18; Iter    37/  229] train: loss: 0.2003352
[Epoch 18; Iter    67/  229] train: loss: 0.2107930
[Epoch 18; Iter    97/  229] train: loss: 0.2661667
[Epoch 18; Iter   127/  229] train: loss: 0.1650536
[Epoch 18; Iter   157/  229] train: loss: 0.2353187
[Epoch 18; Iter   187/  229] train: loss: 0.2580735
[Epoch 18; Iter   217/  229] train: loss: 0.2327969
[Epoch 18] ogbg-moltoxcast: 0.682002 val loss: 0.255424
[Epoch 18] ogbg-moltoxcast: 0.648500 test loss: 0.292553
[Epoch 19; Iter    18/  229] train: loss: 0.1371127
[Epoch 19; Iter    48/  229] train: loss: 0.2220632
[Epoch 19; Iter    78/  229] train: loss: 0.2043255
[Epoch 19; Iter   108/  229] train: loss: 0.1776321
[Epoch 19; Iter   138/  229] train: loss: 0.1685790
[Epoch 19; Iter   168/  229] train: loss: 0.1633839
[Epoch 19; Iter   198/  229] train: loss: 0.2512575
[Epoch 19; Iter   228/  229] train: loss: 0.2722705
[Epoch 19] ogbg-moltoxcast: 0.679583 val loss: 0.260174
[Epoch 19] ogbg-moltoxcast: 0.637169 test loss: 0.313547
[Epoch 20; Iter    29/  229] train: loss: 0.1657472
[Epoch 20; Iter    59/  229] train: loss: 0.1335063
[Epoch 20; Iter    89/  229] train: loss: 0.2879204
[Epoch 20; Iter   119/  229] train: loss: 0.1332593
[Epoch 20; Iter   149/  229] train: loss: 0.2368798
[Epoch 20; Iter   179/  229] train: loss: 0.1668952
[Epoch 20; Iter   209/  229] train: loss: 0.1753789
[Epoch 20] ogbg-moltoxcast: 0.677861 val loss: 0.256620
[Epoch 20] ogbg-moltoxcast: 0.645787 test loss: 0.295353
[Epoch 21; Iter    10/  229] train: loss: 0.2059031
[Epoch 21; Iter    40/  229] train: loss: 0.1939177
[Epoch 21; Iter    70/  229] train: loss: 0.2280847
[Epoch 21; Iter   100/  229] train: loss: 0.1969553
[Epoch 21; Iter   130/  229] train: loss: 0.2041582
[Epoch 21; Iter   160/  229] train: loss: 0.2065812
[Epoch 21; Iter   190/  229] train: loss: 0.2014977
[Epoch 21; Iter   220/  229] train: loss: 0.1279668
[Epoch 21] ogbg-moltoxcast: 0.681650 val loss: 0.258554
[Epoch 21] ogbg-moltoxcast: 0.655214 test loss: 0.306824
[Epoch 22; Iter    21/  229] train: loss: 0.1076029
[Epoch 22; Iter    51/  229] train: loss: 0.1888464
[Epoch 22; Iter    81/  229] train: loss: 0.1123175
[Epoch 22; Iter   111/  229] train: loss: 0.2026468
[Epoch 22; Iter   141/  229] train: loss: 0.2517104
[Epoch 22; Iter   171/  229] train: loss: 0.1355799
[Epoch 22; Iter   201/  229] train: loss: 0.1713320
[Epoch 22] ogbg-moltoxcast: 0.682742 val loss: 0.251589
[Epoch 22] ogbg-moltoxcast: 0.654617 test loss: 0.295078
[Epoch 23; Iter     2/  229] train: loss: 0.2605505
[Epoch 23; Iter    32/  229] train: loss: 0.1428876
[Epoch 23; Iter    62/  229] train: loss: 0.1833377
[Epoch 23; Iter    92/  229] train: loss: 0.1475391
[Epoch 23; Iter   122/  229] train: loss: 0.1668058
[Epoch 23; Iter   152/  229] train: loss: 0.2721044
[Epoch 23; Iter   182/  229] train: loss: 0.1979425
[Epoch 23; Iter   212/  229] train: loss: 0.1533815
[Epoch 23] ogbg-moltoxcast: 0.693855 val loss: 0.247179
[Epoch 23] ogbg-moltoxcast: 0.650376 test loss: 0.288043
[Epoch 24; Iter    13/  229] train: loss: 0.1966377
[Epoch 24; Iter    43/  229] train: loss: 0.1568727
[Epoch 24; Iter    73/  229] train: loss: 0.1260994
[Epoch 24; Iter   103/  229] train: loss: 0.1335177
[Epoch 24; Iter   133/  229] train: loss: 0.2153109
[Epoch 24; Iter   163/  229] train: loss: 0.2192419
[Epoch 24; Iter   193/  229] train: loss: 0.1403451
[Epoch 24; Iter   223/  229] train: loss: 0.1685826
[Epoch 24] ogbg-moltoxcast: 0.694109 val loss: 0.249843
[Epoch 24] ogbg-moltoxcast: 0.652107 test loss: 0.288634
[Epoch 25; Iter    24/  229] train: loss: 0.2330799
[Epoch 25; Iter    54/  229] train: loss: 0.1792842
[Epoch 25; Iter    84/  229] train: loss: 0.2207408
[Epoch 25; Iter   114/  229] train: loss: 0.1886011
[Epoch 25; Iter   144/  229] train: loss: 0.1109354
[Epoch 25; Iter   174/  229] train: loss: 0.1440826
[Epoch 25; Iter   204/  229] train: loss: 0.1668478
[Epoch 25] ogbg-moltoxcast: 0.691969 val loss: 0.244713
[Epoch 25] ogbg-moltoxcast: 0.655077 test loss: 0.293490
[Epoch 26; Iter     5/  229] train: loss: 0.1438958
[Epoch 26; Iter    35/  229] train: loss: 0.2462792
[Epoch 26; Iter    65/  229] train: loss: 0.1972957
[Epoch 26; Iter    95/  229] train: loss: 0.1922986
[Epoch 26; Iter   125/  229] train: loss: 0.1533164
[Epoch 26; Iter   155/  229] train: loss: 0.1594002
[Epoch 26; Iter   185/  229] train: loss: 0.1657465
[Epoch 26; Iter   215/  229] train: loss: 0.1244173
[Epoch 26] ogbg-moltoxcast: 0.688174 val loss: 0.278261
[Epoch 26] ogbg-moltoxcast: 0.646877 test loss: 0.313378
[Epoch 27; Iter    16/  229] train: loss: 0.1732586
[Epoch 27; Iter    46/  229] train: loss: 0.1700571
[Epoch 27; Iter    76/  229] train: loss: 0.1382737
[Epoch 27; Iter   106/  229] train: loss: 0.2069728
[Epoch 27; Iter   136/  229] train: loss: 0.1889166
[Epoch 27; Iter   166/  229] train: loss: 0.1384098
[Epoch 27; Iter   196/  229] train: loss: 0.1351777
[Epoch 27; Iter   226/  229] train: loss: 0.1704977
[Epoch 27] ogbg-moltoxcast: 0.689062 val loss: 0.251617
[Epoch 27] ogbg-moltoxcast: 0.652961 test loss: 0.297738
[Epoch 13; Iter    78/  201] train: loss: 0.1946471
[Epoch 13; Iter   108/  201] train: loss: 0.2202398
[Epoch 13; Iter   138/  201] train: loss: 0.1912507
[Epoch 13; Iter   168/  201] train: loss: 0.2475572
[Epoch 13; Iter   198/  201] train: loss: 0.1629055
[Epoch 13] ogbg-moltoxcast: 0.656412 val loss: 0.260857
[Epoch 13] ogbg-moltoxcast: 0.649902 test loss: 0.301348
[Epoch 14; Iter    27/  201] train: loss: 0.1947330
[Epoch 14; Iter    57/  201] train: loss: 0.1475154
[Epoch 14; Iter    87/  201] train: loss: 0.2301161
[Epoch 14; Iter   117/  201] train: loss: 0.1534091
[Epoch 14; Iter   147/  201] train: loss: 0.1670801
[Epoch 14; Iter   177/  201] train: loss: 0.1674502
[Epoch 14] ogbg-moltoxcast: 0.643543 val loss: 0.264226
[Epoch 14] ogbg-moltoxcast: 0.617763 test loss: 0.324773
[Epoch 15; Iter     6/  201] train: loss: 0.1773473
[Epoch 15; Iter    36/  201] train: loss: 0.1437827
[Epoch 15; Iter    66/  201] train: loss: 0.1555063
[Epoch 15; Iter    96/  201] train: loss: 0.2104151
[Epoch 15; Iter   126/  201] train: loss: 0.2027320
[Epoch 15; Iter   156/  201] train: loss: 0.2111776
[Epoch 15; Iter   186/  201] train: loss: 0.1776576
[Epoch 15] ogbg-moltoxcast: 0.656592 val loss: 0.313674
[Epoch 15] ogbg-moltoxcast: 0.638147 test loss: 0.354244
[Epoch 16; Iter    15/  201] train: loss: 0.1905825
[Epoch 16; Iter    45/  201] train: loss: 0.1893445
[Epoch 16; Iter    75/  201] train: loss: 0.2353172
[Epoch 16; Iter   105/  201] train: loss: 0.2105111
[Epoch 16; Iter   135/  201] train: loss: 0.1409201
[Epoch 16; Iter   165/  201] train: loss: 0.1461054
[Epoch 16; Iter   195/  201] train: loss: 0.1908243
[Epoch 16] ogbg-moltoxcast: 0.647325 val loss: 0.267099
[Epoch 16] ogbg-moltoxcast: 0.643700 test loss: 0.301137
[Epoch 17; Iter    24/  201] train: loss: 0.2672898
[Epoch 17; Iter    54/  201] train: loss: 0.1490336
[Epoch 17; Iter    84/  201] train: loss: 0.1621171
[Epoch 17; Iter   114/  201] train: loss: 0.1235197
[Epoch 17; Iter   144/  201] train: loss: 0.1603795
[Epoch 17; Iter   174/  201] train: loss: 0.1572962
[Epoch 17] ogbg-moltoxcast: 0.666660 val loss: 0.261943
[Epoch 17] ogbg-moltoxcast: 0.646397 test loss: 0.297308
[Epoch 18; Iter     3/  201] train: loss: 0.1357318
[Epoch 18; Iter    33/  201] train: loss: 0.1609289
[Epoch 18; Iter    63/  201] train: loss: 0.1894890
[Epoch 18; Iter    93/  201] train: loss: 0.1161241
[Epoch 18; Iter   123/  201] train: loss: 0.1963938
[Epoch 18; Iter   153/  201] train: loss: 0.1833828
[Epoch 18; Iter   183/  201] train: loss: 0.2052551
[Epoch 18] ogbg-moltoxcast: 0.667806 val loss: 0.258582
[Epoch 18] ogbg-moltoxcast: 0.645702 test loss: 0.292340
[Epoch 19; Iter    12/  201] train: loss: 0.2402073
[Epoch 19; Iter    42/  201] train: loss: 0.2290330
[Epoch 19; Iter    72/  201] train: loss: 0.1808800
[Epoch 19; Iter   102/  201] train: loss: 0.1518463
[Epoch 19; Iter   132/  201] train: loss: 0.1303997
[Epoch 19; Iter   162/  201] train: loss: 0.2026420
[Epoch 19; Iter   192/  201] train: loss: 0.1885394
[Epoch 19] ogbg-moltoxcast: 0.668568 val loss: 0.256068
[Epoch 19] ogbg-moltoxcast: 0.652220 test loss: 0.292443
[Epoch 20; Iter    21/  201] train: loss: 0.2524933
[Epoch 20; Iter    51/  201] train: loss: 0.1777839
[Epoch 20; Iter    81/  201] train: loss: 0.1662553
[Epoch 20; Iter   111/  201] train: loss: 0.1149001
[Epoch 20; Iter   141/  201] train: loss: 0.1567654
[Epoch 20; Iter   171/  201] train: loss: 0.1740638
[Epoch 20; Iter   201/  201] train: loss: 0.0745689
[Epoch 20] ogbg-moltoxcast: 0.665021 val loss: 0.266053
[Epoch 20] ogbg-moltoxcast: 0.654074 test loss: 0.300803
[Epoch 21; Iter    30/  201] train: loss: 0.1620444
[Epoch 21; Iter    60/  201] train: loss: 0.1557654
[Epoch 21; Iter    90/  201] train: loss: 0.1570997
[Epoch 21; Iter   120/  201] train: loss: 0.1275701
[Epoch 21; Iter   150/  201] train: loss: 0.1848656
[Epoch 21; Iter   180/  201] train: loss: 0.1247789
[Epoch 21] ogbg-moltoxcast: 0.677064 val loss: 0.260946
[Epoch 21] ogbg-moltoxcast: 0.655709 test loss: 0.297103
[Epoch 22; Iter     9/  201] train: loss: 0.1908078
[Epoch 22; Iter    39/  201] train: loss: 0.1889664
[Epoch 22; Iter    69/  201] train: loss: 0.1077224
[Epoch 22; Iter    99/  201] train: loss: 0.2150777
[Epoch 22; Iter   129/  201] train: loss: 0.2221205
[Epoch 22; Iter   159/  201] train: loss: 0.1883079
[Epoch 22; Iter   189/  201] train: loss: 0.2054127
[Epoch 22] ogbg-moltoxcast: 0.673705 val loss: 0.260008
[Epoch 22] ogbg-moltoxcast: 0.661357 test loss: 0.292578
[Epoch 23; Iter    18/  201] train: loss: 0.1364692
[Epoch 23; Iter    48/  201] train: loss: 0.1680147
[Epoch 23; Iter    78/  201] train: loss: 0.1033836
[Epoch 23; Iter   108/  201] train: loss: 0.1551939
[Epoch 23; Iter   138/  201] train: loss: 0.1552498
[Epoch 23; Iter   168/  201] train: loss: 0.1442469
[Epoch 23; Iter   198/  201] train: loss: 0.1712694
[Epoch 23] ogbg-moltoxcast: 0.685454 val loss: 0.256004
[Epoch 23] ogbg-moltoxcast: 0.670284 test loss: 0.291499
[Epoch 24; Iter    27/  201] train: loss: 0.1498734
[Epoch 24; Iter    57/  201] train: loss: 0.1585967
[Epoch 24; Iter    87/  201] train: loss: 0.2031426
[Epoch 24; Iter   117/  201] train: loss: 0.1715320
[Epoch 24; Iter   147/  201] train: loss: 0.1627619
[Epoch 24; Iter   177/  201] train: loss: 0.2065917
[Epoch 24] ogbg-moltoxcast: 0.672291 val loss: 0.256030
[Epoch 24] ogbg-moltoxcast: 0.660684 test loss: 0.295236
[Epoch 25; Iter     6/  201] train: loss: 0.1432261
[Epoch 25; Iter    36/  201] train: loss: 0.2192508
[Epoch 25; Iter    66/  201] train: loss: 0.1525325
[Epoch 25; Iter    96/  201] train: loss: 0.1688380
[Epoch 25; Iter   126/  201] train: loss: 0.1440242
[Epoch 25; Iter   156/  201] train: loss: 0.1747990
[Epoch 25; Iter   186/  201] train: loss: 0.1374195
[Epoch 25] ogbg-moltoxcast: 0.667778 val loss: 0.270798
[Epoch 25] ogbg-moltoxcast: 0.653528 test loss: 0.307680
[Epoch 26; Iter    15/  201] train: loss: 0.1844410
[Epoch 26; Iter    45/  201] train: loss: 0.2315793
[Epoch 26; Iter    75/  201] train: loss: 0.1510207
[Epoch 26; Iter   105/  201] train: loss: 0.1494633
[Epoch 26; Iter   135/  201] train: loss: 0.1957621
[Epoch 26; Iter   165/  201] train: loss: 0.1472326
[Epoch 26; Iter   195/  201] train: loss: 0.1132064
[Epoch 26] ogbg-moltoxcast: 0.678251 val loss: 0.256997
[Epoch 26] ogbg-moltoxcast: 0.655679 test loss: 0.299923
[Epoch 27; Iter    24/  201] train: loss: 0.2008059
[Epoch 27; Iter    54/  201] train: loss: 0.1631317
[Epoch 27; Iter    84/  201] train: loss: 0.2158161
[Epoch 27; Iter   114/  201] train: loss: 0.1641705
[Epoch 27; Iter   144/  201] train: loss: 0.1723895
[Epoch 27; Iter   174/  201] train: loss: 0.2051809
[Epoch 27] ogbg-moltoxcast: 0.676963 val loss: 0.255320
[Epoch 27] ogbg-moltoxcast: 0.659399 test loss: 0.293505
[Epoch 28; Iter     3/  201] train: loss: 0.1471399
[Epoch 28; Iter    33/  201] train: loss: 0.1466402
[Epoch 28; Iter    63/  201] train: loss: 0.2191029
[Epoch 28; Iter    93/  201] train: loss: 0.1533907
[Epoch 28; Iter   123/  201] train: loss: 0.1820402
[Epoch 28; Iter   153/  201] train: loss: 0.1303230
[Epoch 28; Iter   183/  201] train: loss: 0.1460335
[Epoch 28] ogbg-moltoxcast: 0.682132 val loss: 0.254223
[Epoch 28] ogbg-moltoxcast: 0.668794 test loss: 0.296783
[Epoch 29; Iter    12/  201] train: loss: 0.1986955
[Epoch 29; Iter    42/  201] train: loss: 0.1233190
[Epoch 29; Iter    72/  201] train: loss: 0.2281698
[Epoch 29; Iter   102/  201] train: loss: 0.1553153
[Epoch 29; Iter   132/  201] train: loss: 0.1639609
[Epoch 29; Iter   162/  201] train: loss: 0.2372235
[Epoch 29; Iter   192/  201] train: loss: 0.1537554
[Epoch 29] ogbg-moltoxcast: 0.690104 val loss: 0.246840
[Epoch 29] ogbg-moltoxcast: 0.665502 test loss: 0.288708
[Epoch 30; Iter    21/  201] train: loss: 0.2117214
[Epoch 30; Iter    51/  201] train: loss: 0.1927954
[Epoch 30; Iter    81/  201] train: loss: 0.1188015
[Epoch 30; Iter   111/  201] train: loss: 0.1633431
[Epoch 30; Iter   141/  201] train: loss: 0.1166714
[Epoch 30; Iter   171/  201] train: loss: 0.1497343
[Epoch 30; Iter   201/  201] train: loss: 0.1327199
[Epoch 30] ogbg-moltoxcast: 0.675704 val loss: 0.265348
[Epoch 13; Iter    78/  201] train: loss: 0.1273482
[Epoch 13; Iter   108/  201] train: loss: 0.1460817
[Epoch 13; Iter   138/  201] train: loss: 0.1787969
[Epoch 13; Iter   168/  201] train: loss: 0.1824742
[Epoch 13; Iter   198/  201] train: loss: 0.1413541
[Epoch 13] ogbg-moltoxcast: 0.646115 val loss: 0.273913
[Epoch 13] ogbg-moltoxcast: 0.623981 test loss: 0.316489
[Epoch 14; Iter    27/  201] train: loss: 0.2269068
[Epoch 14; Iter    57/  201] train: loss: 0.2346610
[Epoch 14; Iter    87/  201] train: loss: 0.1558355
[Epoch 14; Iter   117/  201] train: loss: 0.1424706
[Epoch 14; Iter   147/  201] train: loss: 0.1977787
[Epoch 14; Iter   177/  201] train: loss: 0.1808084
[Epoch 14] ogbg-moltoxcast: 0.666028 val loss: 0.261239
[Epoch 14] ogbg-moltoxcast: 0.648013 test loss: 0.296130
[Epoch 15; Iter     6/  201] train: loss: 0.1786686
[Epoch 15; Iter    36/  201] train: loss: 0.2085291
[Epoch 15; Iter    66/  201] train: loss: 0.2414659
[Epoch 15; Iter    96/  201] train: loss: 0.2213897
[Epoch 15; Iter   126/  201] train: loss: 0.1603842
[Epoch 15; Iter   156/  201] train: loss: 0.1616219
[Epoch 15; Iter   186/  201] train: loss: 0.1796364
[Epoch 15] ogbg-moltoxcast: 0.650573 val loss: 0.278459
[Epoch 15] ogbg-moltoxcast: 0.632500 test loss: 0.319042
[Epoch 16; Iter    15/  201] train: loss: 0.1610364
[Epoch 16; Iter    45/  201] train: loss: 0.1485452
[Epoch 16; Iter    75/  201] train: loss: 0.1604030
[Epoch 16; Iter   105/  201] train: loss: 0.1182513
[Epoch 16; Iter   135/  201] train: loss: 0.1274326
[Epoch 16; Iter   165/  201] train: loss: 0.1994765
[Epoch 16; Iter   195/  201] train: loss: 0.1567835
[Epoch 16] ogbg-moltoxcast: 0.669292 val loss: 0.276517
[Epoch 16] ogbg-moltoxcast: 0.638294 test loss: 0.323883
[Epoch 17; Iter    24/  201] train: loss: 0.2232399
[Epoch 17; Iter    54/  201] train: loss: 0.1541700
[Epoch 17; Iter    84/  201] train: loss: 0.1208083
[Epoch 17; Iter   114/  201] train: loss: 0.2697107
[Epoch 17; Iter   144/  201] train: loss: 0.1554356
[Epoch 17; Iter   174/  201] train: loss: 0.1321405
[Epoch 17] ogbg-moltoxcast: 0.661659 val loss: 0.266873
[Epoch 17] ogbg-moltoxcast: 0.633463 test loss: 0.312668
[Epoch 18; Iter     3/  201] train: loss: 0.1611768
[Epoch 18; Iter    33/  201] train: loss: 0.1850744
[Epoch 18; Iter    63/  201] train: loss: 0.1317036
[Epoch 18; Iter    93/  201] train: loss: 0.1643767
[Epoch 18; Iter   123/  201] train: loss: 0.1176480
[Epoch 18; Iter   153/  201] train: loss: 0.1410256
[Epoch 18; Iter   183/  201] train: loss: 0.2142714
[Epoch 18] ogbg-moltoxcast: 0.664000 val loss: 0.258879
[Epoch 18] ogbg-moltoxcast: 0.636973 test loss: 0.297027
[Epoch 19; Iter    12/  201] train: loss: 0.1675793
[Epoch 19; Iter    42/  201] train: loss: 0.1603270
[Epoch 19; Iter    72/  201] train: loss: 0.1484280
[Epoch 19; Iter   102/  201] train: loss: 0.1195939
[Epoch 19; Iter   132/  201] train: loss: 0.2642049
[Epoch 19; Iter   162/  201] train: loss: 0.1628699
[Epoch 19; Iter   192/  201] train: loss: 0.2315225
[Epoch 19] ogbg-moltoxcast: 0.650618 val loss: 0.277614
[Epoch 19] ogbg-moltoxcast: 0.633291 test loss: 0.317534
[Epoch 20; Iter    21/  201] train: loss: 0.1766667
[Epoch 20; Iter    51/  201] train: loss: 0.1814312
[Epoch 20; Iter    81/  201] train: loss: 0.1528777
[Epoch 20; Iter   111/  201] train: loss: 0.2106820
[Epoch 20; Iter   141/  201] train: loss: 0.1990462
[Epoch 20; Iter   171/  201] train: loss: 0.2576739
[Epoch 20; Iter   201/  201] train: loss: 0.0686044
[Epoch 20] ogbg-moltoxcast: 0.656682 val loss: 0.270535
[Epoch 20] ogbg-moltoxcast: 0.643847 test loss: 0.305456
[Epoch 21; Iter    30/  201] train: loss: 0.1419965
[Epoch 21; Iter    60/  201] train: loss: 0.1144313
[Epoch 21; Iter    90/  201] train: loss: 0.1560306
[Epoch 21; Iter   120/  201] train: loss: 0.1712213
[Epoch 21; Iter   150/  201] train: loss: 0.1811952
[Epoch 21; Iter   180/  201] train: loss: 0.2273116
[Epoch 21] ogbg-moltoxcast: 0.666138 val loss: 0.261330
[Epoch 21] ogbg-moltoxcast: 0.644175 test loss: 0.302628
[Epoch 22; Iter     9/  201] train: loss: 0.1142823
[Epoch 22; Iter    39/  201] train: loss: 0.1742370
[Epoch 22; Iter    69/  201] train: loss: 0.1952095
[Epoch 22; Iter    99/  201] train: loss: 0.1372576
[Epoch 22; Iter   129/  201] train: loss: 0.2933425
[Epoch 22; Iter   159/  201] train: loss: 0.1816096
[Epoch 22; Iter   189/  201] train: loss: 0.1555071
[Epoch 22] ogbg-moltoxcast: 0.674335 val loss: 0.263338
[Epoch 22] ogbg-moltoxcast: 0.642055 test loss: 0.307785
[Epoch 23; Iter    18/  201] train: loss: 0.1909707
[Epoch 23; Iter    48/  201] train: loss: 0.1606000
[Epoch 23; Iter    78/  201] train: loss: 0.1969698
[Epoch 23; Iter   108/  201] train: loss: 0.2879363
[Epoch 23; Iter   138/  201] train: loss: 0.1600671
[Epoch 23; Iter   168/  201] train: loss: 0.1577565
[Epoch 23; Iter   198/  201] train: loss: 0.1860470
[Epoch 23] ogbg-moltoxcast: 0.664984 val loss: 0.281538
[Epoch 23] ogbg-moltoxcast: 0.642330 test loss: 0.324614
[Epoch 24; Iter    27/  201] train: loss: 0.1165172
[Epoch 24; Iter    57/  201] train: loss: 0.1163842
[Epoch 24; Iter    87/  201] train: loss: 0.2409573
[Epoch 24; Iter   117/  201] train: loss: 0.2187203
[Epoch 24; Iter   147/  201] train: loss: 0.1794241
[Epoch 24; Iter   177/  201] train: loss: 0.1575696
[Epoch 24] ogbg-moltoxcast: 0.664730 val loss: 0.269623
[Epoch 24] ogbg-moltoxcast: 0.643585 test loss: 0.509761
[Epoch 25; Iter     6/  201] train: loss: 0.1991227
[Epoch 25; Iter    36/  201] train: loss: 0.1399462
[Epoch 25; Iter    66/  201] train: loss: 0.2200907
[Epoch 25; Iter    96/  201] train: loss: 0.1482244
[Epoch 25; Iter   126/  201] train: loss: 0.1868775
[Epoch 25; Iter   156/  201] train: loss: 0.1442185
[Epoch 25; Iter   186/  201] train: loss: 0.1589123
[Epoch 25] ogbg-moltoxcast: 0.667240 val loss: 0.318743
[Epoch 25] ogbg-moltoxcast: 0.648925 test loss: 0.367931
[Epoch 26; Iter    15/  201] train: loss: 0.2333838
[Epoch 26; Iter    45/  201] train: loss: 0.1355764
[Epoch 26; Iter    75/  201] train: loss: 0.1991807
[Epoch 26; Iter   105/  201] train: loss: 0.2037004
[Epoch 26; Iter   135/  201] train: loss: 0.1711759
[Epoch 26; Iter   165/  201] train: loss: 0.1585769
[Epoch 26; Iter   195/  201] train: loss: 0.1504782
[Epoch 26] ogbg-moltoxcast: 0.677478 val loss: 0.261403
[Epoch 26] ogbg-moltoxcast: 0.663714 test loss: 0.307600
[Epoch 27; Iter    24/  201] train: loss: 0.1646706
[Epoch 27; Iter    54/  201] train: loss: 0.2528429
[Epoch 27; Iter    84/  201] train: loss: 0.1600992
[Epoch 27; Iter   114/  201] train: loss: 0.1402336
[Epoch 27; Iter   144/  201] train: loss: 0.1779158
[Epoch 27; Iter   174/  201] train: loss: 0.1703652
[Epoch 27] ogbg-moltoxcast: 0.682133 val loss: 0.258390
[Epoch 27] ogbg-moltoxcast: 0.657503 test loss: 0.327245
[Epoch 28; Iter     3/  201] train: loss: 0.1661773
[Epoch 28; Iter    33/  201] train: loss: 0.1586134
[Epoch 28; Iter    63/  201] train: loss: 0.1497691
[Epoch 28; Iter    93/  201] train: loss: 0.1286855
[Epoch 28; Iter   123/  201] train: loss: 0.1396101
[Epoch 28; Iter   153/  201] train: loss: 0.1321825
[Epoch 28; Iter   183/  201] train: loss: 0.1546152
[Epoch 28] ogbg-moltoxcast: 0.682651 val loss: 0.259645
[Epoch 28] ogbg-moltoxcast: 0.664464 test loss: 0.294873
[Epoch 29; Iter    12/  201] train: loss: 0.1671916
[Epoch 29; Iter    42/  201] train: loss: 0.1688880
[Epoch 29; Iter    72/  201] train: loss: 0.1188694
[Epoch 29; Iter   102/  201] train: loss: 0.2058161
[Epoch 29; Iter   132/  201] train: loss: 0.1619689
[Epoch 29; Iter   162/  201] train: loss: 0.1660667
[Epoch 29; Iter   192/  201] train: loss: 0.1603877
[Epoch 29] ogbg-moltoxcast: 0.681274 val loss: 0.281564
[Epoch 29] ogbg-moltoxcast: 0.656343 test loss: 0.306341
[Epoch 30; Iter    21/  201] train: loss: 0.1661911
[Epoch 30; Iter    51/  201] train: loss: 0.1819902
[Epoch 30; Iter    81/  201] train: loss: 0.1336695
[Epoch 30; Iter   111/  201] train: loss: 0.1980813
[Epoch 30; Iter   141/  201] train: loss: 0.1139212
[Epoch 30; Iter   171/  201] train: loss: 0.1829428
[Epoch 30; Iter   201/  201] train: loss: 0.1702783
[Epoch 30] ogbg-moltoxcast: 0.684282 val loss: 0.259493
[Epoch 13; Iter    78/  201] train: loss: 0.1607184
[Epoch 13; Iter   108/  201] train: loss: 0.2097755
[Epoch 13; Iter   138/  201] train: loss: 0.1940959
[Epoch 13; Iter   168/  201] train: loss: 0.2210403
[Epoch 13; Iter   198/  201] train: loss: 0.1520523
[Epoch 13] ogbg-moltoxcast: 0.661226 val loss: 0.257452
[Epoch 13] ogbg-moltoxcast: 0.647803 test loss: 0.293108
[Epoch 14; Iter    27/  201] train: loss: 0.2034091
[Epoch 14; Iter    57/  201] train: loss: 0.1592624
[Epoch 14; Iter    87/  201] train: loss: 0.1494115
[Epoch 14; Iter   117/  201] train: loss: 0.1185257
[Epoch 14; Iter   147/  201] train: loss: 0.1628672
[Epoch 14; Iter   177/  201] train: loss: 0.1648781
[Epoch 14] ogbg-moltoxcast: 0.655013 val loss: 0.280054
[Epoch 14] ogbg-moltoxcast: 0.642739 test loss: 0.322067
[Epoch 15; Iter     6/  201] train: loss: 0.1447849
[Epoch 15; Iter    36/  201] train: loss: 0.1591291
[Epoch 15; Iter    66/  201] train: loss: 0.1864191
[Epoch 15; Iter    96/  201] train: loss: 0.1572494
[Epoch 15; Iter   126/  201] train: loss: 0.1320264
[Epoch 15; Iter   156/  201] train: loss: 0.1124395
[Epoch 15; Iter   186/  201] train: loss: 0.1786079
[Epoch 15] ogbg-moltoxcast: 0.673796 val loss: 0.288981
[Epoch 15] ogbg-moltoxcast: 0.646487 test loss: 0.339192
[Epoch 16; Iter    15/  201] train: loss: 0.2146410
[Epoch 16; Iter    45/  201] train: loss: 0.1573996
[Epoch 16; Iter    75/  201] train: loss: 0.2614010
[Epoch 16; Iter   105/  201] train: loss: 0.1904546
[Epoch 16; Iter   135/  201] train: loss: 0.1741776
[Epoch 16; Iter   165/  201] train: loss: 0.2328666
[Epoch 16; Iter   195/  201] train: loss: 0.1448199
[Epoch 16] ogbg-moltoxcast: 0.668662 val loss: 0.258051
[Epoch 16] ogbg-moltoxcast: 0.656485 test loss: 0.292930
[Epoch 17; Iter    24/  201] train: loss: 0.1464777
[Epoch 17; Iter    54/  201] train: loss: 0.1694959
[Epoch 17; Iter    84/  201] train: loss: 0.2047722
[Epoch 17; Iter   114/  201] train: loss: 0.2006423
[Epoch 17; Iter   144/  201] train: loss: 0.1401659
[Epoch 17; Iter   174/  201] train: loss: 0.1794341
[Epoch 17] ogbg-moltoxcast: 0.674011 val loss: 0.258509
[Epoch 17] ogbg-moltoxcast: 0.650135 test loss: 0.295938
[Epoch 18; Iter     3/  201] train: loss: 0.1835905
[Epoch 18; Iter    33/  201] train: loss: 0.1896822
[Epoch 18; Iter    63/  201] train: loss: 0.2158156
[Epoch 18; Iter    93/  201] train: loss: 0.1504343
[Epoch 18; Iter   123/  201] train: loss: 0.1593110
[Epoch 18; Iter   153/  201] train: loss: 0.1505229
[Epoch 18; Iter   183/  201] train: loss: 0.1869368
[Epoch 18] ogbg-moltoxcast: 0.664015 val loss: 0.261792
[Epoch 18] ogbg-moltoxcast: 0.645166 test loss: 0.298762
[Epoch 19; Iter    12/  201] train: loss: 0.1644465
[Epoch 19; Iter    42/  201] train: loss: 0.2595121
[Epoch 19; Iter    72/  201] train: loss: 0.1603118
[Epoch 19; Iter   102/  201] train: loss: 0.2722093
[Epoch 19; Iter   132/  201] train: loss: 0.1732610
[Epoch 19; Iter   162/  201] train: loss: 0.1421487
[Epoch 19; Iter   192/  201] train: loss: 0.1931543
[Epoch 19] ogbg-moltoxcast: 0.679966 val loss: 0.271939
[Epoch 19] ogbg-moltoxcast: 0.657706 test loss: 0.323681
[Epoch 20; Iter    21/  201] train: loss: 0.1104009
[Epoch 20; Iter    51/  201] train: loss: 0.2110857
[Epoch 20; Iter    81/  201] train: loss: 0.1432777
[Epoch 20; Iter   111/  201] train: loss: 0.1896826
[Epoch 20; Iter   141/  201] train: loss: 0.1201957
[Epoch 20; Iter   171/  201] train: loss: 0.1888300
[Epoch 20; Iter   201/  201] train: loss: 0.0606698
[Epoch 20] ogbg-moltoxcast: 0.679531 val loss: 0.267154
[Epoch 20] ogbg-moltoxcast: 0.657484 test loss: 0.310645
[Epoch 21; Iter    30/  201] train: loss: 0.3089682
[Epoch 21; Iter    60/  201] train: loss: 0.2108445
[Epoch 21; Iter    90/  201] train: loss: 0.2136854
[Epoch 21; Iter   120/  201] train: loss: 0.1545737
[Epoch 21; Iter   150/  201] train: loss: 0.1395298
[Epoch 21; Iter   180/  201] train: loss: 0.1229298
[Epoch 21] ogbg-moltoxcast: 0.667984 val loss: 0.271681
[Epoch 21] ogbg-moltoxcast: 0.655956 test loss: 0.299389
[Epoch 22; Iter     9/  201] train: loss: 0.1122867
[Epoch 22; Iter    39/  201] train: loss: 0.1960548
[Epoch 22; Iter    69/  201] train: loss: 0.1249610
[Epoch 22; Iter    99/  201] train: loss: 0.1461410
[Epoch 22; Iter   129/  201] train: loss: 0.1295397
[Epoch 22; Iter   159/  201] train: loss: 0.1160704
[Epoch 22; Iter   189/  201] train: loss: 0.1461825
[Epoch 22] ogbg-moltoxcast: 0.674637 val loss: 0.265428
[Epoch 22] ogbg-moltoxcast: 0.656702 test loss: 0.305810
[Epoch 23; Iter    18/  201] train: loss: 0.2214260
[Epoch 23; Iter    48/  201] train: loss: 0.1767269
[Epoch 23; Iter    78/  201] train: loss: 0.1839730
[Epoch 23; Iter   108/  201] train: loss: 0.1167728
[Epoch 23; Iter   138/  201] train: loss: 0.1559145
[Epoch 23; Iter   168/  201] train: loss: 0.1601256
[Epoch 23; Iter   198/  201] train: loss: 0.1553407
[Epoch 23] ogbg-moltoxcast: 0.656632 val loss: 0.274326
[Epoch 23] ogbg-moltoxcast: 0.649990 test loss: 0.318763
[Epoch 24; Iter    27/  201] train: loss: 0.1651236
[Epoch 24; Iter    57/  201] train: loss: 0.1827056
[Epoch 24; Iter    87/  201] train: loss: 0.1345790
[Epoch 24; Iter   117/  201] train: loss: 0.1807624
[Epoch 24; Iter   147/  201] train: loss: 0.1761706
[Epoch 24; Iter   177/  201] train: loss: 0.1674929
[Epoch 24] ogbg-moltoxcast: 0.668179 val loss: 0.259634
[Epoch 24] ogbg-moltoxcast: 0.653436 test loss: 0.295794
[Epoch 25; Iter     6/  201] train: loss: 0.2045956
[Epoch 25; Iter    36/  201] train: loss: 0.1298064
[Epoch 25; Iter    66/  201] train: loss: 0.1489621
[Epoch 25; Iter    96/  201] train: loss: 0.1472445
[Epoch 25; Iter   126/  201] train: loss: 0.2063723
[Epoch 25; Iter   156/  201] train: loss: 0.2507931
[Epoch 25; Iter   186/  201] train: loss: 0.1090817
[Epoch 25] ogbg-moltoxcast: 0.651344 val loss: 0.267762
[Epoch 25] ogbg-moltoxcast: 0.654209 test loss: 0.297334
[Epoch 26; Iter    15/  201] train: loss: 0.1853554
[Epoch 26; Iter    45/  201] train: loss: 0.2020120
[Epoch 26; Iter    75/  201] train: loss: 0.1375055
[Epoch 26; Iter   105/  201] train: loss: 0.1519391
[Epoch 26; Iter   135/  201] train: loss: 0.1935134
[Epoch 26; Iter   165/  201] train: loss: 0.1976696
[Epoch 26; Iter   195/  201] train: loss: 0.1209753
[Epoch 26] ogbg-moltoxcast: 0.659904 val loss: 0.290920
[Epoch 26] ogbg-moltoxcast: 0.658554 test loss: 0.293761
[Epoch 27; Iter    24/  201] train: loss: 0.1364146
[Epoch 27; Iter    54/  201] train: loss: 0.1499901
[Epoch 27; Iter    84/  201] train: loss: 0.1655347
[Epoch 27; Iter   114/  201] train: loss: 0.1234411
[Epoch 27; Iter   144/  201] train: loss: 0.1725468
[Epoch 27; Iter   174/  201] train: loss: 0.1043488
[Epoch 27] ogbg-moltoxcast: 0.656989 val loss: 0.280541
[Epoch 27] ogbg-moltoxcast: 0.655597 test loss: 0.319835
[Epoch 28; Iter     3/  201] train: loss: 0.1492832
[Epoch 28; Iter    33/  201] train: loss: 0.2288684
[Epoch 28; Iter    63/  201] train: loss: 0.1741267
[Epoch 28; Iter    93/  201] train: loss: 0.1861553
[Epoch 28; Iter   123/  201] train: loss: 0.1414625
[Epoch 28; Iter   153/  201] train: loss: 0.1671608
[Epoch 28; Iter   183/  201] train: loss: 0.1314080
[Epoch 28] ogbg-moltoxcast: 0.665852 val loss: 0.256034
[Epoch 28] ogbg-moltoxcast: 0.663989 test loss: 0.288900
[Epoch 29; Iter    12/  201] train: loss: 0.1836898
[Epoch 29; Iter    42/  201] train: loss: 0.1154779
[Epoch 29; Iter    72/  201] train: loss: 0.1953685
[Epoch 29; Iter   102/  201] train: loss: 0.1894381
[Epoch 29; Iter   132/  201] train: loss: 0.1853586
[Epoch 29; Iter   162/  201] train: loss: 0.1922978
[Epoch 29; Iter   192/  201] train: loss: 0.1944792
[Epoch 29] ogbg-moltoxcast: 0.649147 val loss: 0.271619
[Epoch 29] ogbg-moltoxcast: 0.645381 test loss: 0.312623
[Epoch 30; Iter    21/  201] train: loss: 0.1818878
[Epoch 30; Iter    51/  201] train: loss: 0.2003029
[Epoch 30; Iter    81/  201] train: loss: 0.1846918
[Epoch 30; Iter   111/  201] train: loss: 0.1924524
[Epoch 30; Iter   141/  201] train: loss: 0.1698370
[Epoch 30; Iter   171/  201] train: loss: 0.2003464
[Epoch 30; Iter   201/  201] train: loss: 0.1152574
[Epoch 30] ogbg-moltoxcast: 0.677286 val loss: 0.257539
[Epoch 14] ogbg-moltoxcast: 0.664814 val loss: 0.270589
[Epoch 14] ogbg-moltoxcast: 0.625898 test loss: 0.326539
[Epoch 15; Iter    22/  172] train: loss: 0.1593164
[Epoch 15; Iter    52/  172] train: loss: 0.1445514
[Epoch 15; Iter    82/  172] train: loss: 0.2354005
[Epoch 15; Iter   112/  172] train: loss: 0.1468531
[Epoch 15; Iter   142/  172] train: loss: 0.1509136
[Epoch 15; Iter   172/  172] train: loss: 0.2469188
[Epoch 15] ogbg-moltoxcast: 0.662830 val loss: 0.284463
[Epoch 15] ogbg-moltoxcast: 0.627973 test loss: 0.374239
[Epoch 16; Iter    30/  172] train: loss: 0.2456352
[Epoch 16; Iter    60/  172] train: loss: 0.1583772
[Epoch 16; Iter    90/  172] train: loss: 0.1231883
[Epoch 16; Iter   120/  172] train: loss: 0.2255237
[Epoch 16; Iter   150/  172] train: loss: 0.1764158
[Epoch 16] ogbg-moltoxcast: 0.680539 val loss: 0.286975
[Epoch 16] ogbg-moltoxcast: 0.631756 test loss: 0.378438
[Epoch 17; Iter     8/  172] train: loss: 0.1717005
[Epoch 17; Iter    38/  172] train: loss: 0.1056863
[Epoch 17; Iter    68/  172] train: loss: 0.1763075
[Epoch 17; Iter    98/  172] train: loss: 0.1672193
[Epoch 17; Iter   128/  172] train: loss: 0.1658086
[Epoch 17; Iter   158/  172] train: loss: 0.1626621
[Epoch 17] ogbg-moltoxcast: 0.680006 val loss: 0.289537
[Epoch 17] ogbg-moltoxcast: 0.633970 test loss: 0.403098
[Epoch 18; Iter    16/  172] train: loss: 0.1111291
[Epoch 18; Iter    46/  172] train: loss: 0.1605725
[Epoch 18; Iter    76/  172] train: loss: 0.1389448
[Epoch 18; Iter   106/  172] train: loss: 0.1390524
[Epoch 18; Iter   136/  172] train: loss: 0.1463537
[Epoch 18; Iter   166/  172] train: loss: 0.0743993
[Epoch 18] ogbg-moltoxcast: 0.675576 val loss: 0.269305
[Epoch 18] ogbg-moltoxcast: 0.637299 test loss: 0.321703
[Epoch 19; Iter    24/  172] train: loss: 0.1347575
[Epoch 19; Iter    54/  172] train: loss: 0.1473739
[Epoch 19; Iter    84/  172] train: loss: 0.1622589
[Epoch 19; Iter   114/  172] train: loss: 0.1269666
[Epoch 19; Iter   144/  172] train: loss: 0.1552072
[Epoch 19] ogbg-moltoxcast: 0.672063 val loss: 0.263693
[Epoch 19] ogbg-moltoxcast: 0.635762 test loss: 0.308731
[Epoch 20; Iter     2/  172] train: loss: 0.1424008
[Epoch 20; Iter    32/  172] train: loss: 0.1911326
[Epoch 20; Iter    62/  172] train: loss: 0.1575170
[Epoch 20; Iter    92/  172] train: loss: 0.1220591
[Epoch 20; Iter   122/  172] train: loss: 0.2601425
[Epoch 20; Iter   152/  172] train: loss: 0.1554836
[Epoch 20] ogbg-moltoxcast: 0.672625 val loss: 0.300264
[Epoch 20] ogbg-moltoxcast: 0.635857 test loss: 0.376284
[Epoch 21; Iter    10/  172] train: loss: 0.1368774
[Epoch 21; Iter    40/  172] train: loss: 0.1110049
[Epoch 21; Iter    70/  172] train: loss: 0.1964511
[Epoch 21; Iter   100/  172] train: loss: 0.1840453
[Epoch 21; Iter   130/  172] train: loss: 0.1358805
[Epoch 21; Iter   160/  172] train: loss: 0.1231712
[Epoch 21] ogbg-moltoxcast: 0.678220 val loss: 0.263911
[Epoch 21] ogbg-moltoxcast: 0.645656 test loss: 0.313671
[Epoch 22; Iter    18/  172] train: loss: 0.1635851
[Epoch 22; Iter    48/  172] train: loss: 0.1874957
[Epoch 22; Iter    78/  172] train: loss: 0.0981819
[Epoch 22; Iter   108/  172] train: loss: 0.1765204
[Epoch 22; Iter   138/  172] train: loss: 0.1288451
[Epoch 22; Iter   168/  172] train: loss: 0.1897150
[Epoch 22] ogbg-moltoxcast: 0.684101 val loss: 0.261532
[Epoch 22] ogbg-moltoxcast: 0.642443 test loss: 0.309307
[Epoch 23; Iter    26/  172] train: loss: 0.1415857
[Epoch 23; Iter    56/  172] train: loss: 0.1830143
[Epoch 23; Iter    86/  172] train: loss: 0.1164235
[Epoch 23; Iter   116/  172] train: loss: 0.1278438
[Epoch 23; Iter   146/  172] train: loss: 0.1572512
[Epoch 23] ogbg-moltoxcast: 0.685280 val loss: 0.270003
[Epoch 23] ogbg-moltoxcast: 0.646849 test loss: 0.326658
[Epoch 24; Iter     4/  172] train: loss: 0.1931018
[Epoch 24; Iter    34/  172] train: loss: 0.1899282
[Epoch 24; Iter    64/  172] train: loss: 0.1603398
[Epoch 24; Iter    94/  172] train: loss: 0.1294317
[Epoch 24; Iter   124/  172] train: loss: 0.1628619
[Epoch 24; Iter   154/  172] train: loss: 0.1875476
[Epoch 24] ogbg-moltoxcast: 0.684656 val loss: 0.264588
[Epoch 24] ogbg-moltoxcast: 0.650431 test loss: 0.319692
[Epoch 25; Iter    12/  172] train: loss: 0.1391675
[Epoch 25; Iter    42/  172] train: loss: 0.1936239
[Epoch 25; Iter    72/  172] train: loss: 0.1791925
[Epoch 25; Iter   102/  172] train: loss: 0.2612486
[Epoch 25; Iter   132/  172] train: loss: 0.1773214
[Epoch 25; Iter   162/  172] train: loss: 0.0889373
[Epoch 25] ogbg-moltoxcast: 0.675675 val loss: 0.277084
[Epoch 25] ogbg-moltoxcast: 0.640729 test loss: 0.334097
[Epoch 26; Iter    20/  172] train: loss: 0.1905357
[Epoch 26; Iter    50/  172] train: loss: 0.1897330
[Epoch 26; Iter    80/  172] train: loss: 0.1488447
[Epoch 26; Iter   110/  172] train: loss: 0.1699293
[Epoch 26; Iter   140/  172] train: loss: 0.1566679
[Epoch 26; Iter   170/  172] train: loss: 0.1586876
[Epoch 26] ogbg-moltoxcast: 0.677891 val loss: 0.271282
[Epoch 26] ogbg-moltoxcast: 0.640770 test loss: 0.321867
[Epoch 27; Iter    28/  172] train: loss: 0.1309381
[Epoch 27; Iter    58/  172] train: loss: 0.1606967
[Epoch 27; Iter    88/  172] train: loss: 0.1471332
[Epoch 27; Iter   118/  172] train: loss: 0.0846036
[Epoch 27; Iter   148/  172] train: loss: 0.1407186
[Epoch 27] ogbg-moltoxcast: 0.665097 val loss: 0.344002
[Epoch 27] ogbg-moltoxcast: 0.627054 test loss: 0.394500
[Epoch 28; Iter     6/  172] train: loss: 0.1010283
[Epoch 28; Iter    36/  172] train: loss: 0.1189145
[Epoch 28; Iter    66/  172] train: loss: 0.1177458
[Epoch 28; Iter    96/  172] train: loss: 0.2008730
[Epoch 28; Iter   126/  172] train: loss: 0.1137108
[Epoch 28; Iter   156/  172] train: loss: 0.1456020
[Epoch 28] ogbg-moltoxcast: 0.656543 val loss: 0.283797
[Epoch 28] ogbg-moltoxcast: 0.627898 test loss: 0.329936
[Epoch 29; Iter    14/  172] train: loss: 0.1024060
[Epoch 29; Iter    44/  172] train: loss: 0.2138196
[Epoch 29; Iter    74/  172] train: loss: 0.1663717
[Epoch 29; Iter   104/  172] train: loss: 0.1581582
[Epoch 29; Iter   134/  172] train: loss: 0.1542674
[Epoch 29; Iter   164/  172] train: loss: 0.1245034
[Epoch 29] ogbg-moltoxcast: 0.676456 val loss: 0.277057
[Epoch 29] ogbg-moltoxcast: 0.631966 test loss: 0.330765
[Epoch 30; Iter    22/  172] train: loss: 0.1239344
[Epoch 30; Iter    52/  172] train: loss: 0.1410434
[Epoch 30; Iter    82/  172] train: loss: 0.1434284
[Epoch 30; Iter   112/  172] train: loss: 0.1657016
[Epoch 30; Iter   142/  172] train: loss: 0.1387146
[Epoch 30; Iter   172/  172] train: loss: 0.2126043
[Epoch 30] ogbg-moltoxcast: 0.657543 val loss: 0.277553
[Epoch 30] ogbg-moltoxcast: 0.627332 test loss: 0.340490
[Epoch 31; Iter    30/  172] train: loss: 0.1328090
[Epoch 31; Iter    60/  172] train: loss: 0.0987285
[Epoch 31; Iter    90/  172] train: loss: 0.1757499
[Epoch 31; Iter   120/  172] train: loss: 0.1193610
[Epoch 31; Iter   150/  172] train: loss: 0.1232501
[Epoch 31] ogbg-moltoxcast: 0.659222 val loss: 0.653350
[Epoch 31] ogbg-moltoxcast: 0.629545 test loss: 1.072025
[Epoch 32; Iter     8/  172] train: loss: 0.1798479
[Epoch 32; Iter    38/  172] train: loss: 0.1821450
[Epoch 32; Iter    68/  172] train: loss: 0.1449609
[Epoch 32; Iter    98/  172] train: loss: 0.1324516
[Epoch 32; Iter   128/  172] train: loss: 0.1269978
[Epoch 32; Iter   158/  172] train: loss: 0.1844360
[Epoch 32] ogbg-moltoxcast: 0.674752 val loss: 0.277364
[Epoch 32] ogbg-moltoxcast: 0.637377 test loss: 0.381428
[Epoch 33; Iter    16/  172] train: loss: 0.2064044
[Epoch 33; Iter    46/  172] train: loss: 0.1174779
[Epoch 33; Iter    76/  172] train: loss: 0.1492763
[Epoch 33; Iter   106/  172] train: loss: 0.1590283
[Epoch 33; Iter   136/  172] train: loss: 0.1233881
[Epoch 33; Iter   166/  172] train: loss: 0.1672133
[Epoch 33] ogbg-moltoxcast: 0.676628 val loss: 0.267444
[Epoch 33] ogbg-moltoxcast: 0.644868 test loss: 0.313081
[Epoch 34; Iter    24/  172] train: loss: 0.1583421
[Epoch 34; Iter    54/  172] train: loss: 0.1308308
[Epoch 34; Iter    84/  172] train: loss: 0.1924423
[Epoch 34; Iter   114/  172] train: loss: 0.1597495
[Epoch 34; Iter   144/  172] train: loss: 0.1264019
[Epoch 14] ogbg-moltoxcast: 0.655573 val loss: 0.276706
[Epoch 14] ogbg-moltoxcast: 0.617316 test loss: 0.527210
[Epoch 15; Iter    22/  172] train: loss: 0.1442617
[Epoch 15; Iter    52/  172] train: loss: 0.1080866
[Epoch 15; Iter    82/  172] train: loss: 0.1676832
[Epoch 15; Iter   112/  172] train: loss: 0.2140913
[Epoch 15; Iter   142/  172] train: loss: 0.1774297
[Epoch 15; Iter   172/  172] train: loss: 0.0984376
[Epoch 15] ogbg-moltoxcast: 0.677094 val loss: 0.267412
[Epoch 15] ogbg-moltoxcast: 0.638688 test loss: 0.467652
[Epoch 16; Iter    30/  172] train: loss: 0.2104933
[Epoch 16; Iter    60/  172] train: loss: 0.1178945
[Epoch 16; Iter    90/  172] train: loss: 0.2777169
[Epoch 16; Iter   120/  172] train: loss: 0.1479404
[Epoch 16; Iter   150/  172] train: loss: 0.2448336
[Epoch 16] ogbg-moltoxcast: 0.630012 val loss: 0.416532
[Epoch 16] ogbg-moltoxcast: 0.595602 test loss: 2.330994
[Epoch 17; Iter     8/  172] train: loss: 0.1731982
[Epoch 17; Iter    38/  172] train: loss: 0.1590378
[Epoch 17; Iter    68/  172] train: loss: 0.1540062
[Epoch 17; Iter    98/  172] train: loss: 0.2014354
[Epoch 17; Iter   128/  172] train: loss: 0.1724894
[Epoch 17; Iter   158/  172] train: loss: 0.1251558
[Epoch 17] ogbg-moltoxcast: 0.675137 val loss: 0.462478
[Epoch 17] ogbg-moltoxcast: 0.636127 test loss: 3.125170
[Epoch 18; Iter    16/  172] train: loss: 0.1130108
[Epoch 18; Iter    46/  172] train: loss: 0.1812379
[Epoch 18; Iter    76/  172] train: loss: 0.2659434
[Epoch 18; Iter   106/  172] train: loss: 0.1762302
[Epoch 18; Iter   136/  172] train: loss: 0.1614664
[Epoch 18; Iter   166/  172] train: loss: 0.2107850
[Epoch 18] ogbg-moltoxcast: 0.666505 val loss: 0.267681
[Epoch 18] ogbg-moltoxcast: 0.626553 test loss: 0.325526
[Epoch 19; Iter    24/  172] train: loss: 0.1050867
[Epoch 19; Iter    54/  172] train: loss: 0.1844299
[Epoch 19; Iter    84/  172] train: loss: 0.1902764
[Epoch 19; Iter   114/  172] train: loss: 0.0918484
[Epoch 19; Iter   144/  172] train: loss: 0.1544783
[Epoch 19] ogbg-moltoxcast: 0.664403 val loss: 0.299075
[Epoch 19] ogbg-moltoxcast: 0.627374 test loss: 0.424918
[Epoch 20; Iter     2/  172] train: loss: 0.1611831
[Epoch 20; Iter    32/  172] train: loss: 0.1635540
[Epoch 20; Iter    62/  172] train: loss: 0.1662072
[Epoch 20; Iter    92/  172] train: loss: 0.1348280
[Epoch 20; Iter   122/  172] train: loss: 0.1614468
[Epoch 20; Iter   152/  172] train: loss: 0.1608367
[Epoch 20] ogbg-moltoxcast: 0.678126 val loss: 0.370527
[Epoch 20] ogbg-moltoxcast: 0.634621 test loss: 0.371862
[Epoch 21; Iter    10/  172] train: loss: 0.1547977
[Epoch 21; Iter    40/  172] train: loss: 0.1439839
[Epoch 21; Iter    70/  172] train: loss: 0.1186985
[Epoch 21; Iter   100/  172] train: loss: 0.1719812
[Epoch 21; Iter   130/  172] train: loss: 0.1348989
[Epoch 21; Iter   160/  172] train: loss: 0.1014713
[Epoch 21] ogbg-moltoxcast: 0.675713 val loss: 0.892683
[Epoch 21] ogbg-moltoxcast: 0.625779 test loss: 2.181568
[Epoch 22; Iter    18/  172] train: loss: 0.1602656
[Epoch 22; Iter    48/  172] train: loss: 0.1587676
[Epoch 22; Iter    78/  172] train: loss: 0.1835436
[Epoch 22; Iter   108/  172] train: loss: 0.1990923
[Epoch 22; Iter   138/  172] train: loss: 0.1265883
[Epoch 22; Iter   168/  172] train: loss: 0.1199819
[Epoch 22] ogbg-moltoxcast: 0.682709 val loss: 0.324867
[Epoch 22] ogbg-moltoxcast: 0.644337 test loss: 0.343774
[Epoch 23; Iter    26/  172] train: loss: 0.1338521
[Epoch 23; Iter    56/  172] train: loss: 0.2202177
[Epoch 23; Iter    86/  172] train: loss: 0.1875505
[Epoch 23; Iter   116/  172] train: loss: 0.1445232
[Epoch 23; Iter   146/  172] train: loss: 0.1297702
[Epoch 23] ogbg-moltoxcast: 0.663838 val loss: 0.316807
[Epoch 23] ogbg-moltoxcast: 0.628882 test loss: 0.504911
[Epoch 24; Iter     4/  172] train: loss: 0.1353407
[Epoch 24; Iter    34/  172] train: loss: 0.1137277
[Epoch 24; Iter    64/  172] train: loss: 0.2067405
[Epoch 24; Iter    94/  172] train: loss: 0.1572700
[Epoch 24; Iter   124/  172] train: loss: 0.1752482
[Epoch 24; Iter   154/  172] train: loss: 0.0966735
[Epoch 24] ogbg-moltoxcast: 0.655062 val loss: 0.337072
[Epoch 24] ogbg-moltoxcast: 0.620206 test loss: 0.829474
[Epoch 25; Iter    12/  172] train: loss: 0.1326213
[Epoch 25; Iter    42/  172] train: loss: 0.1526893
[Epoch 25; Iter    72/  172] train: loss: 0.1682047
[Epoch 25; Iter   102/  172] train: loss: 0.1784814
[Epoch 25; Iter   132/  172] train: loss: 0.1745957
[Epoch 25; Iter   162/  172] train: loss: 0.1509606
[Epoch 25] ogbg-moltoxcast: 0.668426 val loss: 0.292114
[Epoch 25] ogbg-moltoxcast: 0.630441 test loss: 0.341273
[Epoch 26; Iter    20/  172] train: loss: 0.1223868
[Epoch 26; Iter    50/  172] train: loss: 0.1201879
[Epoch 26; Iter    80/  172] train: loss: 0.1706106
[Epoch 26; Iter   110/  172] train: loss: 0.0859838
[Epoch 26; Iter   140/  172] train: loss: 0.1227291
[Epoch 26; Iter   170/  172] train: loss: 0.1319619
[Epoch 26] ogbg-moltoxcast: 0.666257 val loss: 0.282606
[Epoch 26] ogbg-moltoxcast: 0.631572 test loss: 0.335219
[Epoch 27; Iter    28/  172] train: loss: 0.1597856
[Epoch 27; Iter    58/  172] train: loss: 0.1333072
[Epoch 27; Iter    88/  172] train: loss: 0.1886368
[Epoch 27; Iter   118/  172] train: loss: 0.1294568
[Epoch 27; Iter   148/  172] train: loss: 0.1323470
[Epoch 27] ogbg-moltoxcast: 0.665840 val loss: 0.270383
[Epoch 27] ogbg-moltoxcast: 0.630237 test loss: 0.345843
[Epoch 28; Iter     6/  172] train: loss: 0.1848122
[Epoch 28; Iter    36/  172] train: loss: 0.2113654
[Epoch 28; Iter    66/  172] train: loss: 0.2313514
[Epoch 28; Iter    96/  172] train: loss: 0.1896399
[Epoch 28; Iter   126/  172] train: loss: 0.1499271
[Epoch 28; Iter   156/  172] train: loss: 0.1597860
[Epoch 28] ogbg-moltoxcast: 0.671165 val loss: 0.276481
[Epoch 28] ogbg-moltoxcast: 0.628524 test loss: 0.331940
[Epoch 29; Iter    14/  172] train: loss: 0.1573723
[Epoch 29; Iter    44/  172] train: loss: 0.1320330
[Epoch 29; Iter    74/  172] train: loss: 0.1166737
[Epoch 29; Iter   104/  172] train: loss: 0.1782060
[Epoch 29; Iter   134/  172] train: loss: 0.1174593
[Epoch 29; Iter   164/  172] train: loss: 0.1237676
[Epoch 29] ogbg-moltoxcast: 0.665279 val loss: 0.282196
[Epoch 29] ogbg-moltoxcast: 0.622116 test loss: 0.338729
[Epoch 30; Iter    22/  172] train: loss: 0.1312639
[Epoch 30; Iter    52/  172] train: loss: 0.1561572
[Epoch 30; Iter    82/  172] train: loss: 0.1481718
[Epoch 30; Iter   112/  172] train: loss: 0.1335887
[Epoch 30; Iter   142/  172] train: loss: 0.1151402
[Epoch 30; Iter   172/  172] train: loss: 0.1365104
[Epoch 30] ogbg-moltoxcast: 0.679093 val loss: 0.268293
[Epoch 30] ogbg-moltoxcast: 0.641013 test loss: 0.312855
[Epoch 31; Iter    30/  172] train: loss: 0.2116763
[Epoch 31; Iter    60/  172] train: loss: 0.1881449
[Epoch 31; Iter    90/  172] train: loss: 0.1458830
[Epoch 31; Iter   120/  172] train: loss: 0.1285750
[Epoch 31; Iter   150/  172] train: loss: 0.1685279
[Epoch 31] ogbg-moltoxcast: 0.675920 val loss: 0.269812
[Epoch 31] ogbg-moltoxcast: 0.640948 test loss: 0.314564
[Epoch 32; Iter     8/  172] train: loss: 0.0932110
[Epoch 32; Iter    38/  172] train: loss: 0.1101304
[Epoch 32; Iter    68/  172] train: loss: 0.1481483
[Epoch 32; Iter    98/  172] train: loss: 0.1319001
[Epoch 32; Iter   128/  172] train: loss: 0.1279126
[Epoch 32; Iter   158/  172] train: loss: 0.1783385
[Epoch 32] ogbg-moltoxcast: 0.661378 val loss: 0.269067
[Epoch 32] ogbg-moltoxcast: 0.638173 test loss: 0.316493
[Epoch 33; Iter    16/  172] train: loss: 0.1384180
[Epoch 33; Iter    46/  172] train: loss: 0.1291657
[Epoch 33; Iter    76/  172] train: loss: 0.2477469
[Epoch 33; Iter   106/  172] train: loss: 0.0995952
[Epoch 33; Iter   136/  172] train: loss: 0.1556597
[Epoch 33; Iter   166/  172] train: loss: 0.1280757
[Epoch 33] ogbg-moltoxcast: 0.665200 val loss: 0.282355
[Epoch 33] ogbg-moltoxcast: 0.624084 test loss: 0.333681
[Epoch 34; Iter    24/  172] train: loss: 0.1517119
[Epoch 34; Iter    54/  172] train: loss: 0.1202534
[Epoch 34; Iter    84/  172] train: loss: 0.1504940
[Epoch 34; Iter   114/  172] train: loss: 0.1081545
[Epoch 34; Iter   144/  172] train: loss: 0.1092911
[Epoch 14] ogbg-moltoxcast: 0.662690 val loss: 0.268587
[Epoch 14] ogbg-moltoxcast: 0.622951 test loss: 0.323172
[Epoch 15; Iter    22/  172] train: loss: 0.1849107
[Epoch 15; Iter    52/  172] train: loss: 0.1375119
[Epoch 15; Iter    82/  172] train: loss: 0.1687879
[Epoch 15; Iter   112/  172] train: loss: 0.1469298
[Epoch 15; Iter   142/  172] train: loss: 0.2199604
[Epoch 15; Iter   172/  172] train: loss: 0.1239062
[Epoch 15] ogbg-moltoxcast: 0.670344 val loss: 0.266181
[Epoch 15] ogbg-moltoxcast: 0.625533 test loss: 0.377364
[Epoch 16; Iter    30/  172] train: loss: 0.2500485
[Epoch 16; Iter    60/  172] train: loss: 0.1582156
[Epoch 16; Iter    90/  172] train: loss: 0.0802645
[Epoch 16; Iter   120/  172] train: loss: 0.2032793
[Epoch 16; Iter   150/  172] train: loss: 0.1617839
[Epoch 16] ogbg-moltoxcast: 0.668450 val loss: 0.274369
[Epoch 16] ogbg-moltoxcast: 0.628221 test loss: 0.329848
[Epoch 17; Iter     8/  172] train: loss: 0.2843567
[Epoch 17; Iter    38/  172] train: loss: 0.1294088
[Epoch 17; Iter    68/  172] train: loss: 0.1049696
[Epoch 17; Iter    98/  172] train: loss: 0.1127530
[Epoch 17; Iter   128/  172] train: loss: 0.1930665
[Epoch 17; Iter   158/  172] train: loss: 0.1327086
[Epoch 17] ogbg-moltoxcast: 0.681463 val loss: 0.264304
[Epoch 17] ogbg-moltoxcast: 0.634711 test loss: 0.316750
[Epoch 18; Iter    16/  172] train: loss: 0.1685565
[Epoch 18; Iter    46/  172] train: loss: 0.1564709
[Epoch 18; Iter    76/  172] train: loss: 0.1686144
[Epoch 18; Iter   106/  172] train: loss: 0.1902286
[Epoch 18; Iter   136/  172] train: loss: 0.1281952
[Epoch 18; Iter   166/  172] train: loss: 0.1288618
[Epoch 18] ogbg-moltoxcast: 0.666383 val loss: 0.270091
[Epoch 18] ogbg-moltoxcast: 0.628786 test loss: 0.322229
[Epoch 19; Iter    24/  172] train: loss: 0.1861572
[Epoch 19; Iter    54/  172] train: loss: 0.1064050
[Epoch 19; Iter    84/  172] train: loss: 0.2351560
[Epoch 19; Iter   114/  172] train: loss: 0.0853808
[Epoch 19; Iter   144/  172] train: loss: 0.1724341
[Epoch 19] ogbg-moltoxcast: 0.675975 val loss: 0.263535
[Epoch 19] ogbg-moltoxcast: 0.634683 test loss: 0.415013
[Epoch 20; Iter     2/  172] train: loss: 0.1322133
[Epoch 20; Iter    32/  172] train: loss: 0.1833467
[Epoch 20; Iter    62/  172] train: loss: 0.1516515
[Epoch 20; Iter    92/  172] train: loss: 0.1852238
[Epoch 20; Iter   122/  172] train: loss: 0.2037318
[Epoch 20; Iter   152/  172] train: loss: 0.1504295
[Epoch 20] ogbg-moltoxcast: 0.669770 val loss: 0.267432
[Epoch 20] ogbg-moltoxcast: 0.629876 test loss: 0.313320
[Epoch 21; Iter    10/  172] train: loss: 0.1489785
[Epoch 21; Iter    40/  172] train: loss: 0.1977836
[Epoch 21; Iter    70/  172] train: loss: 0.1288726
[Epoch 21; Iter   100/  172] train: loss: 0.2253683
[Epoch 21; Iter   130/  172] train: loss: 0.2196535
[Epoch 21; Iter   160/  172] train: loss: 0.1200452
[Epoch 21] ogbg-moltoxcast: 0.662486 val loss: 0.268284
[Epoch 21] ogbg-moltoxcast: 0.619600 test loss: 0.369424
[Epoch 22; Iter    18/  172] train: loss: 0.1053446
[Epoch 22; Iter    48/  172] train: loss: 0.1912889
[Epoch 22; Iter    78/  172] train: loss: 0.0862273
[Epoch 22; Iter   108/  172] train: loss: 0.2026946
[Epoch 22; Iter   138/  172] train: loss: 0.1236968
[Epoch 22; Iter   168/  172] train: loss: 0.1658677
[Epoch 22] ogbg-moltoxcast: 0.673240 val loss: 0.262574
[Epoch 22] ogbg-moltoxcast: 0.626874 test loss: 0.318429
[Epoch 23; Iter    26/  172] train: loss: 0.1238511
[Epoch 23; Iter    56/  172] train: loss: 0.1219964
[Epoch 23; Iter    86/  172] train: loss: 0.1807030
[Epoch 23; Iter   116/  172] train: loss: 0.1700078
[Epoch 23; Iter   146/  172] train: loss: 0.1795936
[Epoch 23] ogbg-moltoxcast: 0.667943 val loss: 0.274469
[Epoch 23] ogbg-moltoxcast: 0.616896 test loss: 0.328924
[Epoch 24; Iter     4/  172] train: loss: 0.1286640
[Epoch 24; Iter    34/  172] train: loss: 0.2220648
[Epoch 24; Iter    64/  172] train: loss: 0.0919599
[Epoch 24; Iter    94/  172] train: loss: 0.1325789
[Epoch 24; Iter   124/  172] train: loss: 0.1542278
[Epoch 24; Iter   154/  172] train: loss: 0.1500610
[Epoch 24] ogbg-moltoxcast: 0.664852 val loss: 0.268704
[Epoch 24] ogbg-moltoxcast: 0.623789 test loss: 0.327023
[Epoch 25; Iter    12/  172] train: loss: 0.1034857
[Epoch 25; Iter    42/  172] train: loss: 0.2063590
[Epoch 25; Iter    72/  172] train: loss: 0.1713713
[Epoch 25; Iter   102/  172] train: loss: 0.1462618
[Epoch 25; Iter   132/  172] train: loss: 0.1766342
[Epoch 25; Iter   162/  172] train: loss: 0.2559546
[Epoch 25] ogbg-moltoxcast: 0.684700 val loss: 0.255078
[Epoch 25] ogbg-moltoxcast: 0.631123 test loss: 0.417304
[Epoch 26; Iter    20/  172] train: loss: 0.1976342
[Epoch 26; Iter    50/  172] train: loss: 0.1727280
[Epoch 26; Iter    80/  172] train: loss: 0.2036683
[Epoch 26; Iter   110/  172] train: loss: 0.1484931
[Epoch 26; Iter   140/  172] train: loss: 0.2446904
[Epoch 26; Iter   170/  172] train: loss: 0.1689014
[Epoch 26] ogbg-moltoxcast: 0.670786 val loss: 0.294235
[Epoch 26] ogbg-moltoxcast: 0.627365 test loss: 0.375565
[Epoch 27; Iter    28/  172] train: loss: 0.1633620
[Epoch 27; Iter    58/  172] train: loss: 0.1157172
[Epoch 27; Iter    88/  172] train: loss: 0.1416768
[Epoch 27; Iter   118/  172] train: loss: 0.1513658
[Epoch 27; Iter   148/  172] train: loss: 0.1897184
[Epoch 27] ogbg-moltoxcast: 0.671335 val loss: 0.262405
[Epoch 27] ogbg-moltoxcast: 0.629762 test loss: 0.318165
[Epoch 28; Iter     6/  172] train: loss: 0.1815695
[Epoch 28; Iter    36/  172] train: loss: 0.1192963
[Epoch 28; Iter    66/  172] train: loss: 0.1553132
[Epoch 28; Iter    96/  172] train: loss: 0.2391762
[Epoch 28; Iter   126/  172] train: loss: 0.1300852
[Epoch 28; Iter   156/  172] train: loss: 0.1104514
[Epoch 28] ogbg-moltoxcast: 0.670465 val loss: 0.264627
[Epoch 28] ogbg-moltoxcast: 0.626768 test loss: 0.349838
[Epoch 29; Iter    14/  172] train: loss: 0.0987543
[Epoch 29; Iter    44/  172] train: loss: 0.1201166
[Epoch 29; Iter    74/  172] train: loss: 0.1490518
[Epoch 29; Iter   104/  172] train: loss: 0.1463831
[Epoch 29; Iter   134/  172] train: loss: 0.1004766
[Epoch 29; Iter   164/  172] train: loss: 0.0939457
[Epoch 29] ogbg-moltoxcast: 0.642150 val loss: 0.326974
[Epoch 29] ogbg-moltoxcast: 0.615175 test loss: 0.642920
[Epoch 30; Iter    22/  172] train: loss: 0.1237875
[Epoch 30; Iter    52/  172] train: loss: 0.1344264
[Epoch 30; Iter    82/  172] train: loss: 0.1543438
[Epoch 30; Iter   112/  172] train: loss: 0.1227019
[Epoch 30; Iter   142/  172] train: loss: 0.1529206
[Epoch 30; Iter   172/  172] train: loss: 0.1445030
[Epoch 30] ogbg-moltoxcast: 0.675752 val loss: 0.258893
[Epoch 30] ogbg-moltoxcast: 0.633563 test loss: 0.318921
[Epoch 31; Iter    30/  172] train: loss: 0.1450057
[Epoch 31; Iter    60/  172] train: loss: 0.0960721
[Epoch 31; Iter    90/  172] train: loss: 0.1548651
[Epoch 31; Iter   120/  172] train: loss: 0.1216106
[Epoch 31; Iter   150/  172] train: loss: 0.1085702
[Epoch 31] ogbg-moltoxcast: 0.668373 val loss: 0.272215
[Epoch 31] ogbg-moltoxcast: 0.629756 test loss: 0.410495
[Epoch 32; Iter     8/  172] train: loss: 0.1751069
[Epoch 32; Iter    38/  172] train: loss: 0.1680954
[Epoch 32; Iter    68/  172] train: loss: 0.1414503
[Epoch 32; Iter    98/  172] train: loss: 0.1278711
[Epoch 32; Iter   128/  172] train: loss: 0.1212191
[Epoch 32; Iter   158/  172] train: loss: 0.1456516
[Epoch 32] ogbg-moltoxcast: 0.661834 val loss: 0.268540
[Epoch 32] ogbg-moltoxcast: 0.628313 test loss: 0.401452
[Epoch 33; Iter    16/  172] train: loss: 0.1118299
[Epoch 33; Iter    46/  172] train: loss: 0.1134029
[Epoch 33; Iter    76/  172] train: loss: 0.1652268
[Epoch 33; Iter   106/  172] train: loss: 0.2188397
[Epoch 33; Iter   136/  172] train: loss: 0.1443169
[Epoch 33; Iter   166/  172] train: loss: 0.1352632
[Epoch 33] ogbg-moltoxcast: 0.647795 val loss: 0.271736
[Epoch 33] ogbg-moltoxcast: 0.615142 test loss: 0.352985
[Epoch 34; Iter    24/  172] train: loss: 0.1143771
[Epoch 34; Iter    54/  172] train: loss: 0.2118245
[Epoch 34; Iter    84/  172] train: loss: 0.1131045
[Epoch 34; Iter   114/  172] train: loss: 0.1290000
[Epoch 34; Iter   144/  172] train: loss: 0.1730584
[Epoch 28; Iter    27/  229] train: loss: 0.1804906
[Epoch 28; Iter    57/  229] train: loss: 0.1677948
[Epoch 28; Iter    87/  229] train: loss: 0.1810977
[Epoch 28; Iter   117/  229] train: loss: 0.1916670
[Epoch 28; Iter   147/  229] train: loss: 0.1796816
[Epoch 28; Iter   177/  229] train: loss: 0.1507664
[Epoch 28; Iter   207/  229] train: loss: 0.1688792
[Epoch 28] ogbg-moltoxcast: 0.693720 val loss: 0.245627
[Epoch 28] ogbg-moltoxcast: 0.670616 test loss: 0.289120
[Epoch 29; Iter     8/  229] train: loss: 0.1141936
[Epoch 29; Iter    38/  229] train: loss: 0.1370973
[Epoch 29; Iter    68/  229] train: loss: 0.1412105
[Epoch 29; Iter    98/  229] train: loss: 0.1886519
[Epoch 29; Iter   128/  229] train: loss: 0.1427448
[Epoch 29; Iter   158/  229] train: loss: 0.0996458
[Epoch 29; Iter   188/  229] train: loss: 0.1513176
[Epoch 29; Iter   218/  229] train: loss: 0.1321684
[Epoch 29] ogbg-moltoxcast: 0.674414 val loss: 0.253715
[Epoch 29] ogbg-moltoxcast: 0.658744 test loss: 0.300962
[Epoch 30; Iter    19/  229] train: loss: 0.1397133
[Epoch 30; Iter    49/  229] train: loss: 0.1891928
[Epoch 30; Iter    79/  229] train: loss: 0.1381797
[Epoch 30; Iter   109/  229] train: loss: 0.2237042
[Epoch 30; Iter   139/  229] train: loss: 0.1776862
[Epoch 30; Iter   169/  229] train: loss: 0.1804734
[Epoch 30; Iter   199/  229] train: loss: 0.1526955
[Epoch 30; Iter   229/  229] train: loss: 0.1800812
[Epoch 30] ogbg-moltoxcast: 0.687671 val loss: 0.246365
[Epoch 30] ogbg-moltoxcast: 0.662047 test loss: 0.299589
[Epoch 31; Iter    30/  229] train: loss: 0.2195875
[Epoch 31; Iter    60/  229] train: loss: 0.1857907
[Epoch 31; Iter    90/  229] train: loss: 0.1765064
[Epoch 31; Iter   120/  229] train: loss: 0.1649299
[Epoch 31; Iter   150/  229] train: loss: 0.1610939
[Epoch 31; Iter   180/  229] train: loss: 0.2375444
[Epoch 31; Iter   210/  229] train: loss: 0.1503874
[Epoch 31] ogbg-moltoxcast: 0.687707 val loss: 0.250069
[Epoch 31] ogbg-moltoxcast: 0.659031 test loss: 0.296451
[Epoch 32; Iter    11/  229] train: loss: 0.1374040
[Epoch 32; Iter    41/  229] train: loss: 0.1309551
[Epoch 32; Iter    71/  229] train: loss: 0.1755384
[Epoch 32; Iter   101/  229] train: loss: 0.2074222
[Epoch 32; Iter   131/  229] train: loss: 0.1165391
[Epoch 32; Iter   161/  229] train: loss: 0.1800284
[Epoch 32; Iter   191/  229] train: loss: 0.0968977
[Epoch 32; Iter   221/  229] train: loss: 0.1438645
[Epoch 32] ogbg-moltoxcast: 0.693069 val loss: 0.251440
[Epoch 32] ogbg-moltoxcast: 0.666376 test loss: 0.296164
[Epoch 33; Iter    22/  229] train: loss: 0.1100311
[Epoch 33; Iter    52/  229] train: loss: 0.1243983
[Epoch 33; Iter    82/  229] train: loss: 0.1511376
[Epoch 33; Iter   112/  229] train: loss: 0.1896861
[Epoch 33; Iter   142/  229] train: loss: 0.1205849
[Epoch 33; Iter   172/  229] train: loss: 0.1602729
[Epoch 33; Iter   202/  229] train: loss: 0.1050409
[Epoch 33] ogbg-moltoxcast: 0.699719 val loss: 0.247337
[Epoch 33] ogbg-moltoxcast: 0.666397 test loss: 0.297464
[Epoch 34; Iter     3/  229] train: loss: 0.1857276
[Epoch 34; Iter    33/  229] train: loss: 0.1570891
[Epoch 34; Iter    63/  229] train: loss: 0.1533593
[Epoch 34; Iter    93/  229] train: loss: 0.1679578
[Epoch 34; Iter   123/  229] train: loss: 0.1415334
[Epoch 34; Iter   153/  229] train: loss: 0.1378734
[Epoch 34; Iter   183/  229] train: loss: 0.1149435
[Epoch 34; Iter   213/  229] train: loss: 0.2195612
[Epoch 34] ogbg-moltoxcast: 0.695269 val loss: 0.249867
[Epoch 34] ogbg-moltoxcast: 0.652044 test loss: 0.306107
[Epoch 35; Iter    14/  229] train: loss: 0.0802066
[Epoch 35; Iter    44/  229] train: loss: 0.1630746
[Epoch 35; Iter    74/  229] train: loss: 0.1495540
[Epoch 35; Iter   104/  229] train: loss: 0.2185297
[Epoch 35; Iter   134/  229] train: loss: 0.2105287
[Epoch 35; Iter   164/  229] train: loss: 0.1705889
[Epoch 35; Iter   194/  229] train: loss: 0.1232739
[Epoch 35; Iter   224/  229] train: loss: 0.1292361
[Epoch 35] ogbg-moltoxcast: 0.703177 val loss: 0.243088
[Epoch 35] ogbg-moltoxcast: 0.667376 test loss: 0.296923
[Epoch 36; Iter    25/  229] train: loss: 0.1877056
[Epoch 36; Iter    55/  229] train: loss: 0.1769383
[Epoch 36; Iter    85/  229] train: loss: 0.1353533
[Epoch 36; Iter   115/  229] train: loss: 0.1163262
[Epoch 36; Iter   145/  229] train: loss: 0.1683885
[Epoch 36; Iter   175/  229] train: loss: 0.1797391
[Epoch 36; Iter   205/  229] train: loss: 0.1821753
[Epoch 36] ogbg-moltoxcast: 0.706063 val loss: 0.241751
[Epoch 36] ogbg-moltoxcast: 0.672278 test loss: 0.293549
[Epoch 37; Iter     6/  229] train: loss: 0.1210583
[Epoch 37; Iter    36/  229] train: loss: 0.1065296
[Epoch 37; Iter    66/  229] train: loss: 0.1454109
[Epoch 37; Iter    96/  229] train: loss: 0.1408393
[Epoch 37; Iter   126/  229] train: loss: 0.1329903
[Epoch 37; Iter   156/  229] train: loss: 0.1374083
[Epoch 37; Iter   186/  229] train: loss: 0.1624172
[Epoch 37; Iter   216/  229] train: loss: 0.1588652
[Epoch 37] ogbg-moltoxcast: 0.709683 val loss: 0.244071
[Epoch 37] ogbg-moltoxcast: 0.669065 test loss: 0.304409
[Epoch 38; Iter    17/  229] train: loss: 0.1929893
[Epoch 38; Iter    47/  229] train: loss: 0.1576326
[Epoch 38; Iter    77/  229] train: loss: 0.1265544
[Epoch 38; Iter   107/  229] train: loss: 0.1527235
[Epoch 38; Iter   137/  229] train: loss: 0.1677513
[Epoch 38; Iter   167/  229] train: loss: 0.1489541
[Epoch 38; Iter   197/  229] train: loss: 0.1566027
[Epoch 38; Iter   227/  229] train: loss: 0.1631030
[Epoch 38] ogbg-moltoxcast: 0.693302 val loss: 0.248857
[Epoch 38] ogbg-moltoxcast: 0.664234 test loss: 0.302823
[Epoch 39; Iter    28/  229] train: loss: 0.2007020
[Epoch 39; Iter    58/  229] train: loss: 0.1063890
[Epoch 39; Iter    88/  229] train: loss: 0.1232864
[Epoch 39; Iter   118/  229] train: loss: 0.2280517
[Epoch 39; Iter   148/  229] train: loss: 0.1383274
[Epoch 39; Iter   178/  229] train: loss: 0.1698025
[Epoch 39; Iter   208/  229] train: loss: 0.1937408
[Epoch 39] ogbg-moltoxcast: 0.710829 val loss: 0.241499
[Epoch 39] ogbg-moltoxcast: 0.673035 test loss: 0.301794
[Epoch 40; Iter     9/  229] train: loss: 0.1402897
[Epoch 40; Iter    39/  229] train: loss: 0.1267117
[Epoch 40; Iter    69/  229] train: loss: 0.1084431
[Epoch 40; Iter    99/  229] train: loss: 0.1810246
[Epoch 40; Iter   129/  229] train: loss: 0.1417255
[Epoch 40; Iter   159/  229] train: loss: 0.1424425
[Epoch 40; Iter   189/  229] train: loss: 0.1537899
[Epoch 40; Iter   219/  229] train: loss: 0.2111025
[Epoch 40] ogbg-moltoxcast: 0.702986 val loss: 0.250187
[Epoch 40] ogbg-moltoxcast: 0.670273 test loss: 0.305517
[Epoch 41; Iter    20/  229] train: loss: 0.1554391
[Epoch 41; Iter    50/  229] train: loss: 0.1250298
[Epoch 41; Iter    80/  229] train: loss: 0.0880734
[Epoch 41; Iter   110/  229] train: loss: 0.1050289
[Epoch 41; Iter   140/  229] train: loss: 0.1148083
[Epoch 41; Iter   170/  229] train: loss: 0.1023075
[Epoch 41; Iter   200/  229] train: loss: 0.1632411
[Epoch 41] ogbg-moltoxcast: 0.694853 val loss: 0.248887
[Epoch 41] ogbg-moltoxcast: 0.667945 test loss: 0.304567
[Epoch 42; Iter     1/  229] train: loss: 0.1873815
[Epoch 42; Iter    31/  229] train: loss: 0.1516476
[Epoch 42; Iter    61/  229] train: loss: 0.1704703
[Epoch 42; Iter    91/  229] train: loss: 0.1283574
[Epoch 42; Iter   121/  229] train: loss: 0.1727035
[Epoch 42; Iter   151/  229] train: loss: 0.1156188
[Epoch 42; Iter   181/  229] train: loss: 0.1416802
[Epoch 42; Iter   211/  229] train: loss: 0.1732008
[Epoch 42] ogbg-moltoxcast: 0.699850 val loss: 0.248538
[Epoch 42] ogbg-moltoxcast: 0.668314 test loss: 0.303468
[Epoch 43; Iter    12/  229] train: loss: 0.1800794
[Epoch 43; Iter    42/  229] train: loss: 0.1564389
[Epoch 43; Iter    72/  229] train: loss: 0.1728386
[Epoch 43; Iter   102/  229] train: loss: 0.1535136
[Epoch 43; Iter   132/  229] train: loss: 0.1155936
[Epoch 43; Iter   162/  229] train: loss: 0.1805917
[Epoch 43; Iter   192/  229] train: loss: 0.1106549
[Epoch 43; Iter   222/  229] train: loss: 0.1460388
[Epoch 43] ogbg-moltoxcast: 0.708028 val loss: 0.253126
[Epoch 43] ogbg-moltoxcast: 0.672005 test loss: 0.306486
[Epoch 28; Iter    27/  229] train: loss: 0.1856921
[Epoch 28; Iter    57/  229] train: loss: 0.2030910
[Epoch 28; Iter    87/  229] train: loss: 0.1559065
[Epoch 28; Iter   117/  229] train: loss: 0.2542165
[Epoch 28; Iter   147/  229] train: loss: 0.1823002
[Epoch 28; Iter   177/  229] train: loss: 0.1515741
[Epoch 28; Iter   207/  229] train: loss: 0.1939169
[Epoch 28] ogbg-moltoxcast: 0.673018 val loss: 0.249662
[Epoch 28] ogbg-moltoxcast: 0.651823 test loss: 0.292238
[Epoch 29; Iter     8/  229] train: loss: 0.2720024
[Epoch 29; Iter    38/  229] train: loss: 0.2061773
[Epoch 29; Iter    68/  229] train: loss: 0.2946199
[Epoch 29; Iter    98/  229] train: loss: 0.1565517
[Epoch 29; Iter   128/  229] train: loss: 0.1477233
[Epoch 29; Iter   158/  229] train: loss: 0.2014819
[Epoch 29; Iter   188/  229] train: loss: 0.1268263
[Epoch 29; Iter   218/  229] train: loss: 0.1910850
[Epoch 29] ogbg-moltoxcast: 0.688257 val loss: 0.253094
[Epoch 29] ogbg-moltoxcast: 0.669380 test loss: 0.296466
[Epoch 30; Iter    19/  229] train: loss: 0.1241153
[Epoch 30; Iter    49/  229] train: loss: 0.1241478
[Epoch 30; Iter    79/  229] train: loss: 0.2370460
[Epoch 30; Iter   109/  229] train: loss: 0.1447555
[Epoch 30; Iter   139/  229] train: loss: 0.1772231
[Epoch 30; Iter   169/  229] train: loss: 0.1913823
[Epoch 30; Iter   199/  229] train: loss: 0.1708760
[Epoch 30; Iter   229/  229] train: loss: 0.1467449
[Epoch 30] ogbg-moltoxcast: 0.674394 val loss: 0.258365
[Epoch 30] ogbg-moltoxcast: 0.655853 test loss: 0.292224
[Epoch 31; Iter    30/  229] train: loss: 0.0926125
[Epoch 31; Iter    60/  229] train: loss: 0.1368621
[Epoch 31; Iter    90/  229] train: loss: 0.1438294
[Epoch 31; Iter   120/  229] train: loss: 0.0689224
[Epoch 31; Iter   150/  229] train: loss: 0.1810136
[Epoch 31; Iter   180/  229] train: loss: 0.1553413
[Epoch 31; Iter   210/  229] train: loss: 0.1901201
[Epoch 31] ogbg-moltoxcast: 0.676546 val loss: 0.282052
[Epoch 31] ogbg-moltoxcast: 0.641221 test loss: 0.329767
[Epoch 32; Iter    11/  229] train: loss: 0.2019366
[Epoch 32; Iter    41/  229] train: loss: 0.1779133
[Epoch 32; Iter    71/  229] train: loss: 0.1625519
[Epoch 32; Iter   101/  229] train: loss: 0.1539523
[Epoch 32; Iter   131/  229] train: loss: 0.2450758
[Epoch 32; Iter   161/  229] train: loss: 0.1513941
[Epoch 32; Iter   191/  229] train: loss: 0.1499531
[Epoch 32; Iter   221/  229] train: loss: 0.1058898
[Epoch 32] ogbg-moltoxcast: 0.684817 val loss: 0.261283
[Epoch 32] ogbg-moltoxcast: 0.656292 test loss: 0.298185
[Epoch 33; Iter    22/  229] train: loss: 0.1523441
[Epoch 33; Iter    52/  229] train: loss: 0.1602553
[Epoch 33; Iter    82/  229] train: loss: 0.1682498
[Epoch 33; Iter   112/  229] train: loss: 0.1925893
[Epoch 33; Iter   142/  229] train: loss: 0.1622968
[Epoch 33; Iter   172/  229] train: loss: 0.1540873
[Epoch 33; Iter   202/  229] train: loss: 0.1556899
[Epoch 33] ogbg-moltoxcast: 0.686671 val loss: 0.260686
[Epoch 33] ogbg-moltoxcast: 0.656828 test loss: 0.298959
[Epoch 34; Iter     3/  229] train: loss: 0.2022137
[Epoch 34; Iter    33/  229] train: loss: 0.1347714
[Epoch 34; Iter    63/  229] train: loss: 0.1965781
[Epoch 34; Iter    93/  229] train: loss: 0.1724370
[Epoch 34; Iter   123/  229] train: loss: 0.1633974
[Epoch 34; Iter   153/  229] train: loss: 0.1360705
[Epoch 34; Iter   183/  229] train: loss: 0.1450668
[Epoch 34; Iter   213/  229] train: loss: 0.1845978
[Epoch 34] ogbg-moltoxcast: 0.668712 val loss: 0.257128
[Epoch 34] ogbg-moltoxcast: 0.653355 test loss: 0.297772
[Epoch 35; Iter    14/  229] train: loss: 0.1477713
[Epoch 35; Iter    44/  229] train: loss: 0.1246685
[Epoch 35; Iter    74/  229] train: loss: 0.1044099
[Epoch 35; Iter   104/  229] train: loss: 0.1712612
[Epoch 35; Iter   134/  229] train: loss: 0.1508224
[Epoch 35; Iter   164/  229] train: loss: 0.1383554
[Epoch 35; Iter   194/  229] train: loss: 0.1832431
[Epoch 35; Iter   224/  229] train: loss: 0.1535958
[Epoch 35] ogbg-moltoxcast: 0.682493 val loss: 0.258486
[Epoch 35] ogbg-moltoxcast: 0.651317 test loss: 0.296317
[Epoch 36; Iter    25/  229] train: loss: 0.1573418
[Epoch 36; Iter    55/  229] train: loss: 0.1651306
[Epoch 36; Iter    85/  229] train: loss: 0.1569454
[Epoch 36; Iter   115/  229] train: loss: 0.1212999
[Epoch 36; Iter   145/  229] train: loss: 0.1885910
[Epoch 36; Iter   175/  229] train: loss: 0.1217951
[Epoch 36; Iter   205/  229] train: loss: 0.1597630
[Epoch 36] ogbg-moltoxcast: 0.687292 val loss: 0.253520
[Epoch 36] ogbg-moltoxcast: 0.661662 test loss: 0.297358
[Epoch 37; Iter     6/  229] train: loss: 0.1680611
[Epoch 37; Iter    36/  229] train: loss: 0.1434132
[Epoch 37; Iter    66/  229] train: loss: 0.2381792
[Epoch 37; Iter    96/  229] train: loss: 0.1214948
[Epoch 37; Iter   126/  229] train: loss: 0.1482205
[Epoch 37; Iter   156/  229] train: loss: 0.1704121
[Epoch 37; Iter   186/  229] train: loss: 0.1684789
[Epoch 37; Iter   216/  229] train: loss: 0.1706571
[Epoch 37] ogbg-moltoxcast: 0.686463 val loss: 0.247795
[Epoch 37] ogbg-moltoxcast: 0.651834 test loss: 0.299839
[Epoch 38; Iter    17/  229] train: loss: 0.1298230
[Epoch 38; Iter    47/  229] train: loss: 0.1714351
[Epoch 38; Iter    77/  229] train: loss: 0.1254000
[Epoch 38; Iter   107/  229] train: loss: 0.1292186
[Epoch 38; Iter   137/  229] train: loss: 0.1634227
[Epoch 38; Iter   167/  229] train: loss: 0.1352151
[Epoch 38; Iter   197/  229] train: loss: 0.1668819
[Epoch 38; Iter   227/  229] train: loss: 0.1367699
[Epoch 38] ogbg-moltoxcast: 0.689123 val loss: 0.258659
[Epoch 38] ogbg-moltoxcast: 0.656369 test loss: 0.298012
[Epoch 39; Iter    28/  229] train: loss: 0.1730765
[Epoch 39; Iter    58/  229] train: loss: 0.1227888
[Epoch 39; Iter    88/  229] train: loss: 0.1526801
[Epoch 39; Iter   118/  229] train: loss: 0.1846553
[Epoch 39; Iter   148/  229] train: loss: 0.1623298
[Epoch 39; Iter   178/  229] train: loss: 0.1306119
[Epoch 39; Iter   208/  229] train: loss: 0.1196766
[Epoch 39] ogbg-moltoxcast: 0.693870 val loss: 0.245251
[Epoch 39] ogbg-moltoxcast: 0.662297 test loss: 0.290929
[Epoch 40; Iter     9/  229] train: loss: 0.1619762
[Epoch 40; Iter    39/  229] train: loss: 0.1302041
[Epoch 40; Iter    69/  229] train: loss: 0.1746906
[Epoch 40; Iter    99/  229] train: loss: 0.1176807
[Epoch 40; Iter   129/  229] train: loss: 0.1842653
[Epoch 40; Iter   159/  229] train: loss: 0.1358513
[Epoch 40; Iter   189/  229] train: loss: 0.1628369
[Epoch 40; Iter   219/  229] train: loss: 0.1468215
[Epoch 40] ogbg-moltoxcast: 0.690822 val loss: 0.248176
[Epoch 40] ogbg-moltoxcast: 0.655257 test loss: 0.297546
[Epoch 41; Iter    20/  229] train: loss: 0.1782230
[Epoch 41; Iter    50/  229] train: loss: 0.1307581
[Epoch 41; Iter    80/  229] train: loss: 0.2104521
[Epoch 41; Iter   110/  229] train: loss: 0.0722584
[Epoch 41; Iter   140/  229] train: loss: 0.1787193
[Epoch 41; Iter   170/  229] train: loss: 0.1992550
[Epoch 41; Iter   200/  229] train: loss: 0.1521409
[Epoch 41] ogbg-moltoxcast: 0.692625 val loss: 0.254186
[Epoch 41] ogbg-moltoxcast: 0.663653 test loss: 0.300407
[Epoch 42; Iter     1/  229] train: loss: 0.1500375
[Epoch 42; Iter    31/  229] train: loss: 0.1214597
[Epoch 42; Iter    61/  229] train: loss: 0.1241102
[Epoch 42; Iter    91/  229] train: loss: 0.1858382
[Epoch 42; Iter   121/  229] train: loss: 0.1987613
[Epoch 42; Iter   151/  229] train: loss: 0.1203951
[Epoch 42; Iter   181/  229] train: loss: 0.1434333
[Epoch 42; Iter   211/  229] train: loss: 0.1268248
[Epoch 42] ogbg-moltoxcast: 0.681977 val loss: 0.253610
[Epoch 42] ogbg-moltoxcast: 0.664226 test loss: 0.297029
[Epoch 43; Iter    12/  229] train: loss: 0.0925457
[Epoch 43; Iter    42/  229] train: loss: 0.1792540
[Epoch 43; Iter    72/  229] train: loss: 0.1323097
[Epoch 43; Iter   102/  229] train: loss: 0.1727019
[Epoch 43; Iter   132/  229] train: loss: 0.1180943
[Epoch 43; Iter   162/  229] train: loss: 0.0995131
[Epoch 43; Iter   192/  229] train: loss: 0.1719520
[Epoch 43; Iter   222/  229] train: loss: 0.1353814
[Epoch 43] ogbg-moltoxcast: 0.685371 val loss: 0.247437
[Epoch 43] ogbg-moltoxcast: 0.662014 test loss: 0.298934
[Epoch 28; Iter    27/  229] train: loss: 0.1959793
[Epoch 28; Iter    57/  229] train: loss: 0.1622398
[Epoch 28; Iter    87/  229] train: loss: 0.1788285
[Epoch 28; Iter   117/  229] train: loss: 0.2261155
[Epoch 28; Iter   147/  229] train: loss: 0.1807061
[Epoch 28; Iter   177/  229] train: loss: 0.1974852
[Epoch 28; Iter   207/  229] train: loss: 0.1954296
[Epoch 28] ogbg-moltoxcast: 0.686831 val loss: 0.253417
[Epoch 28] ogbg-moltoxcast: 0.650171 test loss: 0.296605
[Epoch 29; Iter     8/  229] train: loss: 0.1460022
[Epoch 29; Iter    38/  229] train: loss: 0.1604516
[Epoch 29; Iter    68/  229] train: loss: 0.2128867
[Epoch 29; Iter    98/  229] train: loss: 0.2193058
[Epoch 29; Iter   128/  229] train: loss: 0.2608933
[Epoch 29; Iter   158/  229] train: loss: 0.1631743
[Epoch 29; Iter   188/  229] train: loss: 0.2175925
[Epoch 29; Iter   218/  229] train: loss: 0.1612574
[Epoch 29] ogbg-moltoxcast: 0.696259 val loss: 0.249906
[Epoch 29] ogbg-moltoxcast: 0.652858 test loss: 0.297244
[Epoch 30; Iter    19/  229] train: loss: 0.1726867
[Epoch 30; Iter    49/  229] train: loss: 0.2200778
[Epoch 30; Iter    79/  229] train: loss: 0.1304166
[Epoch 30; Iter   109/  229] train: loss: 0.1251259
[Epoch 30; Iter   139/  229] train: loss: 0.1464689
[Epoch 30; Iter   169/  229] train: loss: 0.1590269
[Epoch 30; Iter   199/  229] train: loss: 0.1286953
[Epoch 30; Iter   229/  229] train: loss: 0.2571579
[Epoch 30] ogbg-moltoxcast: 0.697020 val loss: 0.253617
[Epoch 30] ogbg-moltoxcast: 0.648405 test loss: 0.304539
[Epoch 31; Iter    30/  229] train: loss: 0.1488892
[Epoch 31; Iter    60/  229] train: loss: 0.1651564
[Epoch 31; Iter    90/  229] train: loss: 0.1634546
[Epoch 31; Iter   120/  229] train: loss: 0.1133380
[Epoch 31; Iter   150/  229] train: loss: 0.2100105
[Epoch 31; Iter   180/  229] train: loss: 0.1522098
[Epoch 31; Iter   210/  229] train: loss: 0.0752453
[Epoch 31] ogbg-moltoxcast: 0.694449 val loss: 0.254730
[Epoch 31] ogbg-moltoxcast: 0.656817 test loss: 0.304095
[Epoch 32; Iter    11/  229] train: loss: 0.1879049
[Epoch 32; Iter    41/  229] train: loss: 0.1271812
[Epoch 32; Iter    71/  229] train: loss: 0.1176183
[Epoch 32; Iter   101/  229] train: loss: 0.1480847
[Epoch 32; Iter   131/  229] train: loss: 0.1687411
[Epoch 32; Iter   161/  229] train: loss: 0.1564748
[Epoch 32; Iter   191/  229] train: loss: 0.1649015
[Epoch 32; Iter   221/  229] train: loss: 0.1108593
[Epoch 32] ogbg-moltoxcast: 0.684319 val loss: 0.250201
[Epoch 32] ogbg-moltoxcast: 0.643710 test loss: 0.299936
[Epoch 33; Iter    22/  229] train: loss: 0.2233648
[Epoch 33; Iter    52/  229] train: loss: 0.1733945
[Epoch 33; Iter    82/  229] train: loss: 0.1661218
[Epoch 33; Iter   112/  229] train: loss: 0.1483719
[Epoch 33; Iter   142/  229] train: loss: 0.1694000
[Epoch 33; Iter   172/  229] train: loss: 0.1149087
[Epoch 33; Iter   202/  229] train: loss: 0.1363325
[Epoch 33] ogbg-moltoxcast: 0.701142 val loss: 0.258938
[Epoch 33] ogbg-moltoxcast: 0.666253 test loss: 0.291717
[Epoch 34; Iter     3/  229] train: loss: 0.1337494
[Epoch 34; Iter    33/  229] train: loss: 0.2163477
[Epoch 34; Iter    63/  229] train: loss: 0.1690646
[Epoch 34; Iter    93/  229] train: loss: 0.1999548
[Epoch 34; Iter   123/  229] train: loss: 0.1384102
[Epoch 34; Iter   153/  229] train: loss: 0.1251322
[Epoch 34; Iter   183/  229] train: loss: 0.1766251
[Epoch 34; Iter   213/  229] train: loss: 0.1918631
[Epoch 34] ogbg-moltoxcast: 0.702336 val loss: 0.251734
[Epoch 34] ogbg-moltoxcast: 0.653429 test loss: 0.299668
[Epoch 35; Iter    14/  229] train: loss: 0.1828977
[Epoch 35; Iter    44/  229] train: loss: 0.1360049
[Epoch 35; Iter    74/  229] train: loss: 0.1687690
[Epoch 35; Iter   104/  229] train: loss: 0.2850485
[Epoch 35; Iter   134/  229] train: loss: 0.1305012
[Epoch 35; Iter   164/  229] train: loss: 0.1572755
[Epoch 35; Iter   194/  229] train: loss: 0.1445884
[Epoch 35; Iter   224/  229] train: loss: 0.1410698
[Epoch 35] ogbg-moltoxcast: 0.695400 val loss: 0.252359
[Epoch 35] ogbg-moltoxcast: 0.654935 test loss: 0.306385
[Epoch 36; Iter    25/  229] train: loss: 0.1634819
[Epoch 36; Iter    55/  229] train: loss: 0.1958353
[Epoch 36; Iter    85/  229] train: loss: 0.1349014
[Epoch 36; Iter   115/  229] train: loss: 0.1341814
[Epoch 36; Iter   145/  229] train: loss: 0.1275164
[Epoch 36; Iter   175/  229] train: loss: 0.1426063
[Epoch 36; Iter   205/  229] train: loss: 0.1734776
[Epoch 36] ogbg-moltoxcast: 0.698303 val loss: 0.252493
[Epoch 36] ogbg-moltoxcast: 0.659462 test loss: 0.307335
[Epoch 37; Iter     6/  229] train: loss: 0.1626164
[Epoch 37; Iter    36/  229] train: loss: 0.2212426
[Epoch 37; Iter    66/  229] train: loss: 0.1364330
[Epoch 37; Iter    96/  229] train: loss: 0.1732051
[Epoch 37; Iter   126/  229] train: loss: 0.1359060
[Epoch 37; Iter   156/  229] train: loss: 0.1635937
[Epoch 37; Iter   186/  229] train: loss: 0.1151219
[Epoch 37; Iter   216/  229] train: loss: 0.1449236
[Epoch 37] ogbg-moltoxcast: 0.696380 val loss: 0.250479
[Epoch 37] ogbg-moltoxcast: 0.656113 test loss: 0.304467
[Epoch 38; Iter    17/  229] train: loss: 0.1743572
[Epoch 38; Iter    47/  229] train: loss: 0.1566024
[Epoch 38; Iter    77/  229] train: loss: 0.1491607
[Epoch 38; Iter   107/  229] train: loss: 0.1541395
[Epoch 38; Iter   137/  229] train: loss: 0.1179104
[Epoch 38; Iter   167/  229] train: loss: 0.1298213
[Epoch 38; Iter   197/  229] train: loss: 0.1921939
[Epoch 38; Iter   227/  229] train: loss: 0.1358166
[Epoch 38] ogbg-moltoxcast: 0.700205 val loss: 0.247566
[Epoch 38] ogbg-moltoxcast: 0.659130 test loss: 0.294185
[Epoch 39; Iter    28/  229] train: loss: 0.1769650
[Epoch 39; Iter    58/  229] train: loss: 0.1488233
[Epoch 39; Iter    88/  229] train: loss: 0.1520748
[Epoch 39; Iter   118/  229] train: loss: 0.2141246
[Epoch 39; Iter   148/  229] train: loss: 0.1552882
[Epoch 39; Iter   178/  229] train: loss: 0.1772263
[Epoch 39; Iter   208/  229] train: loss: 0.1586387
[Epoch 39] ogbg-moltoxcast: 0.697263 val loss: 0.254426
[Epoch 39] ogbg-moltoxcast: 0.663782 test loss: 0.327186
[Epoch 40; Iter     9/  229] train: loss: 0.1357020
[Epoch 40; Iter    39/  229] train: loss: 0.2025067
[Epoch 40; Iter    69/  229] train: loss: 0.1673775
[Epoch 40; Iter    99/  229] train: loss: 0.0835987
[Epoch 40; Iter   129/  229] train: loss: 0.1820152
[Epoch 40; Iter   159/  229] train: loss: 0.1213848
[Epoch 40; Iter   189/  229] train: loss: 0.1164203
[Epoch 40; Iter   219/  229] train: loss: 0.1791365
[Epoch 40] ogbg-moltoxcast: 0.694937 val loss: 0.255561
[Epoch 40] ogbg-moltoxcast: 0.659008 test loss: 0.324226
[Epoch 41; Iter    20/  229] train: loss: 0.1362617
[Epoch 41; Iter    50/  229] train: loss: 0.1759953
[Epoch 41; Iter    80/  229] train: loss: 0.1871481
[Epoch 41; Iter   110/  229] train: loss: 0.1819727
[Epoch 41; Iter   140/  229] train: loss: 0.1590610
[Epoch 41; Iter   170/  229] train: loss: 0.1298469
[Epoch 41; Iter   200/  229] train: loss: 0.1890531
[Epoch 41] ogbg-moltoxcast: 0.698749 val loss: 0.247795
[Epoch 41] ogbg-moltoxcast: 0.664521 test loss: 0.301580
[Epoch 42; Iter     1/  229] train: loss: 0.2048857
[Epoch 42; Iter    31/  229] train: loss: 0.1096003
[Epoch 42; Iter    61/  229] train: loss: 0.1244426
[Epoch 42; Iter    91/  229] train: loss: 0.1840647
[Epoch 42; Iter   121/  229] train: loss: 0.1485376
[Epoch 42; Iter   151/  229] train: loss: 0.1330691
[Epoch 42; Iter   181/  229] train: loss: 0.2389257
[Epoch 42; Iter   211/  229] train: loss: 0.1207535
[Epoch 42] ogbg-moltoxcast: 0.692371 val loss: 0.254032
[Epoch 42] ogbg-moltoxcast: 0.657880 test loss: 0.316624
[Epoch 43; Iter    12/  229] train: loss: 0.1358000
[Epoch 43; Iter    42/  229] train: loss: 0.1464342
[Epoch 43; Iter    72/  229] train: loss: 0.1985695
[Epoch 43; Iter   102/  229] train: loss: 0.1491936
[Epoch 43; Iter   132/  229] train: loss: 0.1436464
[Epoch 43; Iter   162/  229] train: loss: 0.1481121
[Epoch 43; Iter   192/  229] train: loss: 0.1548614
[Epoch 43; Iter   222/  229] train: loss: 0.1703611
[Epoch 43] ogbg-moltoxcast: 0.691011 val loss: 0.259502
[Epoch 43] ogbg-moltoxcast: 0.665181 test loss: 0.302092
[Epoch 30] ogbg-moltoxcast: 0.658082 test loss: 0.311653
[Epoch 31; Iter    30/  201] train: loss: 0.1474678
[Epoch 31; Iter    60/  201] train: loss: 0.1775961
[Epoch 31; Iter    90/  201] train: loss: 0.2046604
[Epoch 31; Iter   120/  201] train: loss: 0.1559061
[Epoch 31; Iter   150/  201] train: loss: 0.1480246
[Epoch 31; Iter   180/  201] train: loss: 0.1551195
[Epoch 31] ogbg-moltoxcast: 0.690825 val loss: 0.250214
[Epoch 31] ogbg-moltoxcast: 0.670398 test loss: 0.290113
[Epoch 32; Iter     9/  201] train: loss: 0.1356339
[Epoch 32; Iter    39/  201] train: loss: 0.1567357
[Epoch 32; Iter    69/  201] train: loss: 0.2104442
[Epoch 32; Iter    99/  201] train: loss: 0.1879466
[Epoch 32; Iter   129/  201] train: loss: 0.1358910
[Epoch 32; Iter   159/  201] train: loss: 0.0972386
[Epoch 32; Iter   189/  201] train: loss: 0.0978516
[Epoch 32] ogbg-moltoxcast: 0.690813 val loss: 0.247799
[Epoch 32] ogbg-moltoxcast: 0.671132 test loss: 0.291783
[Epoch 33; Iter    18/  201] train: loss: 0.1649741
[Epoch 33; Iter    48/  201] train: loss: 0.1717193
[Epoch 33; Iter    78/  201] train: loss: 0.1409800
[Epoch 33; Iter   108/  201] train: loss: 0.0879086
[Epoch 33; Iter   138/  201] train: loss: 0.1551566
[Epoch 33; Iter   168/  201] train: loss: 0.1384730
[Epoch 33; Iter   198/  201] train: loss: 0.1661113
[Epoch 33] ogbg-moltoxcast: 0.689084 val loss: 0.252614
[Epoch 33] ogbg-moltoxcast: 0.670127 test loss: 0.288019
[Epoch 34; Iter    27/  201] train: loss: 0.1223800
[Epoch 34; Iter    57/  201] train: loss: 0.1404858
[Epoch 34; Iter    87/  201] train: loss: 0.1336140
[Epoch 34; Iter   117/  201] train: loss: 0.2023386
[Epoch 34; Iter   147/  201] train: loss: 0.1484938
[Epoch 34; Iter   177/  201] train: loss: 0.1062461
[Epoch 34] ogbg-moltoxcast: 0.696956 val loss: 0.248869
[Epoch 34] ogbg-moltoxcast: 0.672759 test loss: 0.287521
[Epoch 35; Iter     6/  201] train: loss: 0.1718650
[Epoch 35; Iter    36/  201] train: loss: 0.2082845
[Epoch 35; Iter    66/  201] train: loss: 0.1639812
[Epoch 35; Iter    96/  201] train: loss: 0.2417234
[Epoch 35; Iter   126/  201] train: loss: 0.1300631
[Epoch 35; Iter   156/  201] train: loss: 0.2051388
[Epoch 35; Iter   186/  201] train: loss: 0.1472597
[Epoch 35] ogbg-moltoxcast: 0.681101 val loss: 0.256156
[Epoch 35] ogbg-moltoxcast: 0.667704 test loss: 0.298713
[Epoch 36; Iter    15/  201] train: loss: 0.2100163
[Epoch 36; Iter    45/  201] train: loss: 0.1160779
[Epoch 36; Iter    75/  201] train: loss: 0.1038824
[Epoch 36; Iter   105/  201] train: loss: 0.1417568
[Epoch 36; Iter   135/  201] train: loss: 0.1289365
[Epoch 36; Iter   165/  201] train: loss: 0.1294048
[Epoch 36; Iter   195/  201] train: loss: 0.1234898
[Epoch 36] ogbg-moltoxcast: 0.689274 val loss: 0.254555
[Epoch 36] ogbg-moltoxcast: 0.676005 test loss: 0.291829
[Epoch 37; Iter    24/  201] train: loss: 0.1902327
[Epoch 37; Iter    54/  201] train: loss: 0.1617915
[Epoch 37; Iter    84/  201] train: loss: 0.1624796
[Epoch 37; Iter   114/  201] train: loss: 0.1391316
[Epoch 37; Iter   144/  201] train: loss: 0.1399933
[Epoch 37; Iter   174/  201] train: loss: 0.1568697
[Epoch 37] ogbg-moltoxcast: 0.690404 val loss: 0.254353
[Epoch 37] ogbg-moltoxcast: 0.678052 test loss: 0.296405
[Epoch 38; Iter     3/  201] train: loss: 0.1336357
[Epoch 38; Iter    33/  201] train: loss: 0.1640170
[Epoch 38; Iter    63/  201] train: loss: 0.1782593
[Epoch 38; Iter    93/  201] train: loss: 0.1341600
[Epoch 38; Iter   123/  201] train: loss: 0.1996773
[Epoch 38; Iter   153/  201] train: loss: 0.1258774
[Epoch 38; Iter   183/  201] train: loss: 0.0973163
[Epoch 38] ogbg-moltoxcast: 0.692492 val loss: 0.250932
[Epoch 38] ogbg-moltoxcast: 0.670653 test loss: 0.296839
[Epoch 39; Iter    12/  201] train: loss: 0.1973725
[Epoch 39; Iter    42/  201] train: loss: 0.1061697
[Epoch 39; Iter    72/  201] train: loss: 0.1793430
[Epoch 39; Iter   102/  201] train: loss: 0.1498609
[Epoch 39; Iter   132/  201] train: loss: 0.1497344
[Epoch 39; Iter   162/  201] train: loss: 0.1822604
[Epoch 39; Iter   192/  201] train: loss: 0.1459072
[Epoch 39] ogbg-moltoxcast: 0.692461 val loss: 0.254120
[Epoch 39] ogbg-moltoxcast: 0.669444 test loss: 0.306143
[Epoch 40; Iter    21/  201] train: loss: 0.0834187
[Epoch 40; Iter    51/  201] train: loss: 0.1282234
[Epoch 40; Iter    81/  201] train: loss: 0.1082579
[Epoch 40; Iter   111/  201] train: loss: 0.1381738
[Epoch 40; Iter   141/  201] train: loss: 0.1304630
[Epoch 40; Iter   171/  201] train: loss: 0.1364561
[Epoch 40; Iter   201/  201] train: loss: 0.0658819
[Epoch 40] ogbg-moltoxcast: 0.688970 val loss: 0.254430
[Epoch 40] ogbg-moltoxcast: 0.664029 test loss: 0.295650
[Epoch 41; Iter    30/  201] train: loss: 0.1489175
[Epoch 41; Iter    60/  201] train: loss: 0.1847870
[Epoch 41; Iter    90/  201] train: loss: 0.1571568
[Epoch 41; Iter   120/  201] train: loss: 0.1608104
[Epoch 41; Iter   150/  201] train: loss: 0.1947287
[Epoch 41; Iter   180/  201] train: loss: 0.1657884
[Epoch 41] ogbg-moltoxcast: 0.694051 val loss: 0.250290
[Epoch 41] ogbg-moltoxcast: 0.665686 test loss: 0.291802
[Epoch 42; Iter     9/  201] train: loss: 0.1914950
[Epoch 42; Iter    39/  201] train: loss: 0.1039671
[Epoch 42; Iter    69/  201] train: loss: 0.1229206
[Epoch 42; Iter    99/  201] train: loss: 0.1153323
[Epoch 42; Iter   129/  201] train: loss: 0.1506944
[Epoch 42; Iter   159/  201] train: loss: 0.1774663
[Epoch 42; Iter   189/  201] train: loss: 0.1177752
[Epoch 42] ogbg-moltoxcast: 0.690773 val loss: 0.255523
[Epoch 42] ogbg-moltoxcast: 0.665039 test loss: 0.297729
[Epoch 43; Iter    18/  201] train: loss: 0.1264751
[Epoch 43; Iter    48/  201] train: loss: 0.1195100
[Epoch 43; Iter    78/  201] train: loss: 0.1787374
[Epoch 43; Iter   108/  201] train: loss: 0.1743008
[Epoch 43; Iter   138/  201] train: loss: 0.1233857
[Epoch 43; Iter   168/  201] train: loss: 0.1555747
[Epoch 43; Iter   198/  201] train: loss: 0.1698968
[Epoch 43] ogbg-moltoxcast: 0.692290 val loss: 0.259963
[Epoch 43] ogbg-moltoxcast: 0.670363 test loss: 0.302372
[Epoch 44; Iter    27/  201] train: loss: 0.1140718
[Epoch 44; Iter    57/  201] train: loss: 0.1480128
[Epoch 44; Iter    87/  201] train: loss: 0.1621490
[Epoch 44; Iter   117/  201] train: loss: 0.1519705
[Epoch 44; Iter   147/  201] train: loss: 0.1467018
[Epoch 44; Iter   177/  201] train: loss: 0.1133604
[Epoch 44] ogbg-moltoxcast: 0.692912 val loss: 0.257004
[Epoch 44] ogbg-moltoxcast: 0.672451 test loss: 0.298798
[Epoch 45; Iter     6/  201] train: loss: 0.2336315
[Epoch 45; Iter    36/  201] train: loss: 0.1373969
[Epoch 45; Iter    66/  201] train: loss: 0.1468196
[Epoch 45; Iter    96/  201] train: loss: 0.1538662
[Epoch 45; Iter   126/  201] train: loss: 0.1265179
[Epoch 45; Iter   156/  201] train: loss: 0.1283341
[Epoch 45; Iter   186/  201] train: loss: 0.1337559
[Epoch 45] ogbg-moltoxcast: 0.685189 val loss: 0.260689
[Epoch 45] ogbg-moltoxcast: 0.664356 test loss: 0.305591
[Epoch 46; Iter    15/  201] train: loss: 0.1190516
[Epoch 46; Iter    45/  201] train: loss: 0.1086873
[Epoch 46; Iter    75/  201] train: loss: 0.1080545
[Epoch 46; Iter   105/  201] train: loss: 0.1881935
[Epoch 46; Iter   135/  201] train: loss: 0.1204154
[Epoch 46; Iter   165/  201] train: loss: 0.1424713
[Epoch 46; Iter   195/  201] train: loss: 0.1399684
[Epoch 46] ogbg-moltoxcast: 0.687878 val loss: 0.261414
[Epoch 46] ogbg-moltoxcast: 0.667545 test loss: 0.309459
[Epoch 47; Iter    24/  201] train: loss: 0.1847014
[Epoch 47; Iter    54/  201] train: loss: 0.1242978
[Epoch 47; Iter    84/  201] train: loss: 0.1752113
[Epoch 47; Iter   114/  201] train: loss: 0.1086784
[Epoch 47; Iter   144/  201] train: loss: 0.1799852
[Epoch 47; Iter   174/  201] train: loss: 0.1697251
[Epoch 47] ogbg-moltoxcast: 0.690444 val loss: 0.260311
[Epoch 47] ogbg-moltoxcast: 0.671455 test loss: 0.306884
[Epoch 48; Iter     3/  201] train: loss: 0.1705368
[Epoch 48; Iter    33/  201] train: loss: 0.1530175
[Epoch 48; Iter    63/  201] train: loss: 0.1267794
[Epoch 48; Iter    93/  201] train: loss: 0.1191840
[Epoch 48; Iter   123/  201] train: loss: 0.2039951
[Epoch 48; Iter   153/  201] train: loss: 0.1580029
[Epoch 30] ogbg-moltoxcast: 0.669310 test loss: 0.295948
[Epoch 31; Iter    30/  201] train: loss: 0.1240067
[Epoch 31; Iter    60/  201] train: loss: 0.1532748
[Epoch 31; Iter    90/  201] train: loss: 0.1305618
[Epoch 31; Iter   120/  201] train: loss: 0.1335674
[Epoch 31; Iter   150/  201] train: loss: 0.1855732
[Epoch 31; Iter   180/  201] train: loss: 0.1670519
[Epoch 31] ogbg-moltoxcast: 0.680576 val loss: 0.270625
[Epoch 31] ogbg-moltoxcast: 0.659810 test loss: 0.315074
[Epoch 32; Iter     9/  201] train: loss: 0.1641377
[Epoch 32; Iter    39/  201] train: loss: 0.1317826
[Epoch 32; Iter    69/  201] train: loss: 0.1248724
[Epoch 32; Iter    99/  201] train: loss: 0.1043471
[Epoch 32; Iter   129/  201] train: loss: 0.1889564
[Epoch 32; Iter   159/  201] train: loss: 0.1362475
[Epoch 32; Iter   189/  201] train: loss: 0.1420889
[Epoch 32] ogbg-moltoxcast: 0.686310 val loss: 0.254556
[Epoch 32] ogbg-moltoxcast: 0.663365 test loss: 0.296588
[Epoch 33; Iter    18/  201] train: loss: 0.1573148
[Epoch 33; Iter    48/  201] train: loss: 0.1434999
[Epoch 33; Iter    78/  201] train: loss: 0.1263898
[Epoch 33; Iter   108/  201] train: loss: 0.0952761
[Epoch 33; Iter   138/  201] train: loss: 0.1490465
[Epoch 33; Iter   168/  201] train: loss: 0.2069771
[Epoch 33; Iter   198/  201] train: loss: 0.1654004
[Epoch 33] ogbg-moltoxcast: 0.680732 val loss: 0.271181
[Epoch 33] ogbg-moltoxcast: 0.658542 test loss: 0.309614
[Epoch 34; Iter    27/  201] train: loss: 0.1640459
[Epoch 34; Iter    57/  201] train: loss: 0.1742272
[Epoch 34; Iter    87/  201] train: loss: 0.0939955
[Epoch 34; Iter   117/  201] train: loss: 0.1581264
[Epoch 34; Iter   147/  201] train: loss: 0.1960036
[Epoch 34; Iter   177/  201] train: loss: 0.1185548
[Epoch 34] ogbg-moltoxcast: 0.667716 val loss: 0.269335
[Epoch 34] ogbg-moltoxcast: 0.644728 test loss: 0.308908
[Epoch 35; Iter     6/  201] train: loss: 0.1783017
[Epoch 35; Iter    36/  201] train: loss: 0.1346135
[Epoch 35; Iter    66/  201] train: loss: 0.1431883
[Epoch 35; Iter    96/  201] train: loss: 0.1653644
[Epoch 35; Iter   126/  201] train: loss: 0.1440021
[Epoch 35; Iter   156/  201] train: loss: 0.1917751
[Epoch 35; Iter   186/  201] train: loss: 0.1126382
[Epoch 35] ogbg-moltoxcast: 0.681287 val loss: 0.262260
[Epoch 35] ogbg-moltoxcast: 0.662275 test loss: 0.301034
[Epoch 36; Iter    15/  201] train: loss: 0.1253888
[Epoch 36; Iter    45/  201] train: loss: 0.1999943
[Epoch 36; Iter    75/  201] train: loss: 0.2279862
[Epoch 36; Iter   105/  201] train: loss: 0.1605838
[Epoch 36; Iter   135/  201] train: loss: 0.1067546
[Epoch 36; Iter   165/  201] train: loss: 0.1281587
[Epoch 36; Iter   195/  201] train: loss: 0.1169786
[Epoch 36] ogbg-moltoxcast: 0.678617 val loss: 0.258116
[Epoch 36] ogbg-moltoxcast: 0.664830 test loss: 0.301284
[Epoch 37; Iter    24/  201] train: loss: 0.1516156
[Epoch 37; Iter    54/  201] train: loss: 0.1842364
[Epoch 37; Iter    84/  201] train: loss: 0.1254954
[Epoch 37; Iter   114/  201] train: loss: 0.1590905
[Epoch 37; Iter   144/  201] train: loss: 0.1513862
[Epoch 37; Iter   174/  201] train: loss: 0.1711786
[Epoch 37] ogbg-moltoxcast: 0.680273 val loss: 0.262201
[Epoch 37] ogbg-moltoxcast: 0.659241 test loss: 0.307320
[Epoch 38; Iter     3/  201] train: loss: 0.1753083
[Epoch 38; Iter    33/  201] train: loss: 0.1272679
[Epoch 38; Iter    63/  201] train: loss: 0.1373166
[Epoch 38; Iter    93/  201] train: loss: 0.1089318
[Epoch 38; Iter   123/  201] train: loss: 0.1041078
[Epoch 38; Iter   153/  201] train: loss: 0.0769932
[Epoch 38; Iter   183/  201] train: loss: 0.1515073
[Epoch 38] ogbg-moltoxcast: 0.683514 val loss: 0.259192
[Epoch 38] ogbg-moltoxcast: 0.667562 test loss: 0.296382
[Epoch 39; Iter    12/  201] train: loss: 0.1389839
[Epoch 39; Iter    42/  201] train: loss: 0.1282946
[Epoch 39; Iter    72/  201] train: loss: 0.1233996
[Epoch 39; Iter   102/  201] train: loss: 0.1089332
[Epoch 39; Iter   132/  201] train: loss: 0.1722081
[Epoch 39; Iter   162/  201] train: loss: 0.1777002
[Epoch 39; Iter   192/  201] train: loss: 0.1197665
[Epoch 39] ogbg-moltoxcast: 0.687931 val loss: 0.258914
[Epoch 39] ogbg-moltoxcast: 0.672049 test loss: 0.296574
[Epoch 40; Iter    21/  201] train: loss: 0.1286308
[Epoch 40; Iter    51/  201] train: loss: 0.1490328
[Epoch 40; Iter    81/  201] train: loss: 0.1883101
[Epoch 40; Iter   111/  201] train: loss: 0.1584471
[Epoch 40; Iter   141/  201] train: loss: 0.1701200
[Epoch 40; Iter   171/  201] train: loss: 0.1508982
[Epoch 40; Iter   201/  201] train: loss: 0.2255477
[Epoch 40] ogbg-moltoxcast: 0.687752 val loss: 0.258066
[Epoch 40] ogbg-moltoxcast: 0.666491 test loss: 0.297321
[Epoch 41; Iter    30/  201] train: loss: 0.1741071
[Epoch 41; Iter    60/  201] train: loss: 0.1207265
[Epoch 41; Iter    90/  201] train: loss: 0.1723858
[Epoch 41; Iter   120/  201] train: loss: 0.1283856
[Epoch 41; Iter   150/  201] train: loss: 0.1222135
[Epoch 41; Iter   180/  201] train: loss: 0.1540880
[Epoch 41] ogbg-moltoxcast: 0.685018 val loss: 0.261811
[Epoch 41] ogbg-moltoxcast: 0.663849 test loss: 0.300487
[Epoch 42; Iter     9/  201] train: loss: 0.1324921
[Epoch 42; Iter    39/  201] train: loss: 0.1542184
[Epoch 42; Iter    69/  201] train: loss: 0.1373886
[Epoch 42; Iter    99/  201] train: loss: 0.1410587
[Epoch 42; Iter   129/  201] train: loss: 0.1492312
[Epoch 42; Iter   159/  201] train: loss: 0.1411792
[Epoch 42; Iter   189/  201] train: loss: 0.1567256
[Epoch 42] ogbg-moltoxcast: 0.686577 val loss: 0.258273
[Epoch 42] ogbg-moltoxcast: 0.665379 test loss: 0.296476
[Epoch 43; Iter    18/  201] train: loss: 0.1367314
[Epoch 43; Iter    48/  201] train: loss: 0.1333342
[Epoch 43; Iter    78/  201] train: loss: 0.1393723
[Epoch 43; Iter   108/  201] train: loss: 0.1366660
[Epoch 43; Iter   138/  201] train: loss: 0.1148215
[Epoch 43; Iter   168/  201] train: loss: 0.1948851
[Epoch 43; Iter   198/  201] train: loss: 0.1137457
[Epoch 43] ogbg-moltoxcast: 0.682355 val loss: 0.264562
[Epoch 43] ogbg-moltoxcast: 0.660863 test loss: 0.308214
[Epoch 44; Iter    27/  201] train: loss: 0.1445316
[Epoch 44; Iter    57/  201] train: loss: 0.1578443
[Epoch 44; Iter    87/  201] train: loss: 0.1373686
[Epoch 44; Iter   117/  201] train: loss: 0.1597865
[Epoch 44; Iter   147/  201] train: loss: 0.0987832
[Epoch 44; Iter   177/  201] train: loss: 0.2015231
[Epoch 44] ogbg-moltoxcast: 0.677123 val loss: 0.260251
[Epoch 44] ogbg-moltoxcast: 0.660898 test loss: 0.301541
[Epoch 45; Iter     6/  201] train: loss: 0.1938768
[Epoch 45; Iter    36/  201] train: loss: 0.0630966
[Epoch 45; Iter    66/  201] train: loss: 0.1620343
[Epoch 45; Iter    96/  201] train: loss: 0.1833674
[Epoch 45; Iter   126/  201] train: loss: 0.1571849
[Epoch 45; Iter   156/  201] train: loss: 0.1164906
[Epoch 45; Iter   186/  201] train: loss: 0.2036861
[Epoch 45] ogbg-moltoxcast: 0.682873 val loss: 0.264947
[Epoch 45] ogbg-moltoxcast: 0.660794 test loss: 0.301945
[Epoch 46; Iter    15/  201] train: loss: 0.1623100
[Epoch 46; Iter    45/  201] train: loss: 0.1377081
[Epoch 46; Iter    75/  201] train: loss: 0.1738786
[Epoch 46; Iter   105/  201] train: loss: 0.1757470
[Epoch 46; Iter   135/  201] train: loss: 0.1832735
[Epoch 46; Iter   165/  201] train: loss: 0.1681706
[Epoch 46; Iter   195/  201] train: loss: 0.1702214
[Epoch 46] ogbg-moltoxcast: 0.688174 val loss: 0.258457
[Epoch 46] ogbg-moltoxcast: 0.669205 test loss: 0.298791
[Epoch 47; Iter    24/  201] train: loss: 0.1653675
[Epoch 47; Iter    54/  201] train: loss: 0.1199096
[Epoch 47; Iter    84/  201] train: loss: 0.1110414
[Epoch 47; Iter   114/  201] train: loss: 0.1113249
[Epoch 47; Iter   144/  201] train: loss: 0.1458178
[Epoch 47; Iter   174/  201] train: loss: 0.1719777
[Epoch 47] ogbg-moltoxcast: 0.681884 val loss: 0.259864
[Epoch 47] ogbg-moltoxcast: 0.667393 test loss: 0.294492
[Epoch 48; Iter     3/  201] train: loss: 0.1188352
[Epoch 48; Iter    33/  201] train: loss: 0.1210782
[Epoch 48; Iter    63/  201] train: loss: 0.1577441
[Epoch 48; Iter    93/  201] train: loss: 0.1323053
[Epoch 48; Iter   123/  201] train: loss: 0.1973455
[Epoch 48; Iter   153/  201] train: loss: 0.1545250
[Epoch 30] ogbg-moltoxcast: 0.656398 test loss: 0.301675
[Epoch 31; Iter    30/  201] train: loss: 0.1315749
[Epoch 31; Iter    60/  201] train: loss: 0.1570477
[Epoch 31; Iter    90/  201] train: loss: 0.1940986
[Epoch 31; Iter   120/  201] train: loss: 0.1436610
[Epoch 31; Iter   150/  201] train: loss: 0.1246334
[Epoch 31; Iter   180/  201] train: loss: 0.1917511
[Epoch 31] ogbg-moltoxcast: 0.671318 val loss: 0.258371
[Epoch 31] ogbg-moltoxcast: 0.653120 test loss: 0.299843
[Epoch 32; Iter     9/  201] train: loss: 0.1297061
[Epoch 32; Iter    39/  201] train: loss: 0.1139753
[Epoch 32; Iter    69/  201] train: loss: 0.1400242
[Epoch 32; Iter    99/  201] train: loss: 0.1571269
[Epoch 32; Iter   129/  201] train: loss: 0.1850985
[Epoch 32; Iter   159/  201] train: loss: 0.1417086
[Epoch 32; Iter   189/  201] train: loss: 0.1457371
[Epoch 32] ogbg-moltoxcast: 0.670301 val loss: 0.258953
[Epoch 32] ogbg-moltoxcast: 0.659547 test loss: 0.305112
[Epoch 33; Iter    18/  201] train: loss: 0.1478430
[Epoch 33; Iter    48/  201] train: loss: 0.1442352
[Epoch 33; Iter    78/  201] train: loss: 0.1698588
[Epoch 33; Iter   108/  201] train: loss: 0.1583237
[Epoch 33; Iter   138/  201] train: loss: 0.1006470
[Epoch 33; Iter   168/  201] train: loss: 0.1941170
[Epoch 33; Iter   198/  201] train: loss: 0.1442076
[Epoch 33] ogbg-moltoxcast: 0.658136 val loss: 0.265125
[Epoch 33] ogbg-moltoxcast: 0.655900 test loss: 0.303796
[Epoch 34; Iter    27/  201] train: loss: 0.1582981
[Epoch 34; Iter    57/  201] train: loss: 0.1752409
[Epoch 34; Iter    87/  201] train: loss: 0.2146975
[Epoch 34; Iter   117/  201] train: loss: 0.1109501
[Epoch 34; Iter   147/  201] train: loss: 0.1903298
[Epoch 34; Iter   177/  201] train: loss: 0.1049122
[Epoch 34] ogbg-moltoxcast: 0.667606 val loss: 0.257865
[Epoch 34] ogbg-moltoxcast: 0.663421 test loss: 0.291755
[Epoch 35; Iter     6/  201] train: loss: 0.1361494
[Epoch 35; Iter    36/  201] train: loss: 0.1443499
[Epoch 35; Iter    66/  201] train: loss: 0.2405132
[Epoch 35; Iter    96/  201] train: loss: 0.1163313
[Epoch 35; Iter   126/  201] train: loss: 0.1842631
[Epoch 35; Iter   156/  201] train: loss: 0.1110801
[Epoch 35; Iter   186/  201] train: loss: 0.1157069
[Epoch 35] ogbg-moltoxcast: 0.673794 val loss: 0.262919
[Epoch 35] ogbg-moltoxcast: 0.662841 test loss: 0.419432
[Epoch 36; Iter    15/  201] train: loss: 0.1881505
[Epoch 36; Iter    45/  201] train: loss: 0.1027261
[Epoch 36; Iter    75/  201] train: loss: 0.1485824
[Epoch 36; Iter   105/  201] train: loss: 0.1118778
[Epoch 36; Iter   135/  201] train: loss: 0.1348416
[Epoch 36; Iter   165/  201] train: loss: 0.1372797
[Epoch 36; Iter   195/  201] train: loss: 0.1000405
[Epoch 36] ogbg-moltoxcast: 0.668572 val loss: 0.262347
[Epoch 36] ogbg-moltoxcast: 0.663956 test loss: 0.301587
[Epoch 37; Iter    24/  201] train: loss: 0.1493040
[Epoch 37; Iter    54/  201] train: loss: 0.1201704
[Epoch 37; Iter    84/  201] train: loss: 0.1606179
[Epoch 37; Iter   114/  201] train: loss: 0.1328341
[Epoch 37; Iter   144/  201] train: loss: 0.1704177
[Epoch 37; Iter   174/  201] train: loss: 0.1384854
[Epoch 37] ogbg-moltoxcast: 0.674019 val loss: 0.258321
[Epoch 37] ogbg-moltoxcast: 0.666426 test loss: 0.309657
[Epoch 38; Iter     3/  201] train: loss: 0.1339283
[Epoch 38; Iter    33/  201] train: loss: 0.1313776
[Epoch 38; Iter    63/  201] train: loss: 0.1435779
[Epoch 38; Iter    93/  201] train: loss: 0.1415220
[Epoch 38; Iter   123/  201] train: loss: 0.1533094
[Epoch 38; Iter   153/  201] train: loss: 0.1915076
[Epoch 38; Iter   183/  201] train: loss: 0.1778411
[Epoch 38] ogbg-moltoxcast: 0.675530 val loss: 0.258014
[Epoch 38] ogbg-moltoxcast: 0.672203 test loss: 0.315952
[Epoch 39; Iter    12/  201] train: loss: 0.1375203
[Epoch 39; Iter    42/  201] train: loss: 0.1820486
[Epoch 39; Iter    72/  201] train: loss: 0.2519923
[Epoch 39; Iter   102/  201] train: loss: 0.1657871
[Epoch 39; Iter   132/  201] train: loss: 0.1357215
[Epoch 39; Iter   162/  201] train: loss: 0.2055290
[Epoch 39; Iter   192/  201] train: loss: 0.0998097
[Epoch 39] ogbg-moltoxcast: 0.667215 val loss: 0.264404
[Epoch 39] ogbg-moltoxcast: 0.654749 test loss: 0.333895
[Epoch 40; Iter    21/  201] train: loss: 0.1643626
[Epoch 40; Iter    51/  201] train: loss: 0.1143376
[Epoch 40; Iter    81/  201] train: loss: 0.1657867
[Epoch 40; Iter   111/  201] train: loss: 0.1198681
[Epoch 40; Iter   141/  201] train: loss: 0.1409734
[Epoch 40; Iter   171/  201] train: loss: 0.1402895
[Epoch 40; Iter   201/  201] train: loss: 0.3617228
[Epoch 40] ogbg-moltoxcast: 0.666970 val loss: 0.292104
[Epoch 40] ogbg-moltoxcast: 0.661859 test loss: 0.349434
[Epoch 41; Iter    30/  201] train: loss: 0.2082942
[Epoch 41; Iter    60/  201] train: loss: 0.2054681
[Epoch 41; Iter    90/  201] train: loss: 0.1032002
[Epoch 41; Iter   120/  201] train: loss: 0.1440697
[Epoch 41; Iter   150/  201] train: loss: 0.1238032
[Epoch 41; Iter   180/  201] train: loss: 0.1541663
[Epoch 41] ogbg-moltoxcast: 0.670591 val loss: 0.263345
[Epoch 41] ogbg-moltoxcast: 0.658355 test loss: 0.302118
[Epoch 42; Iter     9/  201] train: loss: 0.1378857
[Epoch 42; Iter    39/  201] train: loss: 0.1347488
[Epoch 42; Iter    69/  201] train: loss: 0.1797496
[Epoch 42; Iter    99/  201] train: loss: 0.0946595
[Epoch 42; Iter   129/  201] train: loss: 0.1279975
[Epoch 42; Iter   159/  201] train: loss: 0.1235359
[Epoch 42; Iter   189/  201] train: loss: 0.1751171
[Epoch 42] ogbg-moltoxcast: 0.676495 val loss: 0.267320
[Epoch 42] ogbg-moltoxcast: 0.669914 test loss: 0.318870
[Epoch 43; Iter    18/  201] train: loss: 0.1637680
[Epoch 43; Iter    48/  201] train: loss: 0.1468868
[Epoch 43; Iter    78/  201] train: loss: 0.1144813
[Epoch 43; Iter   108/  201] train: loss: 0.1357549
[Epoch 43; Iter   138/  201] train: loss: 0.1411168
[Epoch 43; Iter   168/  201] train: loss: 0.1085161
[Epoch 43; Iter   198/  201] train: loss: 0.1733469
[Epoch 43] ogbg-moltoxcast: 0.678788 val loss: 0.271666
[Epoch 43] ogbg-moltoxcast: 0.664654 test loss: 0.334177
[Epoch 44; Iter    27/  201] train: loss: 0.1081350
[Epoch 44; Iter    57/  201] train: loss: 0.1229023
[Epoch 44; Iter    87/  201] train: loss: 0.1543194
[Epoch 44; Iter   117/  201] train: loss: 0.1995407
[Epoch 44; Iter   147/  201] train: loss: 0.1543645
[Epoch 44; Iter   177/  201] train: loss: 0.1210596
[Epoch 44] ogbg-moltoxcast: 0.671407 val loss: 0.263115
[Epoch 44] ogbg-moltoxcast: 0.657941 test loss: 0.302866
[Epoch 45; Iter     6/  201] train: loss: 0.1846306
[Epoch 45; Iter    36/  201] train: loss: 0.1516818
[Epoch 45; Iter    66/  201] train: loss: 0.1184912
[Epoch 45; Iter    96/  201] train: loss: 0.2072370
[Epoch 45; Iter   126/  201] train: loss: 0.1523071
[Epoch 45; Iter   156/  201] train: loss: 0.1273672
[Epoch 45; Iter   186/  201] train: loss: 0.1573689
[Epoch 45] ogbg-moltoxcast: 0.669979 val loss: 0.335568
[Epoch 45] ogbg-moltoxcast: 0.655697 test loss: 0.597742
[Epoch 46; Iter    15/  201] train: loss: 0.1482102
[Epoch 46; Iter    45/  201] train: loss: 0.1179640
[Epoch 46; Iter    75/  201] train: loss: 0.1551590
[Epoch 46; Iter   105/  201] train: loss: 0.1731784
[Epoch 46; Iter   135/  201] train: loss: 0.1692183
[Epoch 46; Iter   165/  201] train: loss: 0.1550059
[Epoch 46; Iter   195/  201] train: loss: 0.1988294
[Epoch 46] ogbg-moltoxcast: 0.665309 val loss: 0.291456
[Epoch 46] ogbg-moltoxcast: 0.652370 test loss: 0.366410
[Epoch 47; Iter    24/  201] train: loss: 0.1543187
[Epoch 47; Iter    54/  201] train: loss: 0.1561306
[Epoch 47; Iter    84/  201] train: loss: 0.1499018
[Epoch 47; Iter   114/  201] train: loss: 0.1335598
[Epoch 47; Iter   144/  201] train: loss: 0.1378242
[Epoch 47; Iter   174/  201] train: loss: 0.1351014
[Epoch 47] ogbg-moltoxcast: 0.667694 val loss: 0.355466
[Epoch 47] ogbg-moltoxcast: 0.659363 test loss: 0.529396
[Epoch 48; Iter     3/  201] train: loss: 0.1041505
[Epoch 48; Iter    33/  201] train: loss: 0.1517368
[Epoch 48; Iter    63/  201] train: loss: 0.1053390
[Epoch 48; Iter    93/  201] train: loss: 0.1050354
[Epoch 48; Iter   123/  201] train: loss: 0.1520183
[Epoch 48; Iter   153/  201] train: loss: 0.1898239
[Epoch 34] ogbg-moltoxcast: 0.674870 val loss: 0.259462
[Epoch 34] ogbg-moltoxcast: 0.634370 test loss: 0.313295
[Epoch 35; Iter     2/  172] train: loss: 0.1881173
[Epoch 35; Iter    32/  172] train: loss: 0.1231983
[Epoch 35; Iter    62/  172] train: loss: 0.1648957
[Epoch 35; Iter    92/  172] train: loss: 0.1958441
[Epoch 35; Iter   122/  172] train: loss: 0.2210835
[Epoch 35; Iter   152/  172] train: loss: 0.2221198
[Epoch 35] ogbg-moltoxcast: 0.665552 val loss: 0.265311
[Epoch 35] ogbg-moltoxcast: 0.637772 test loss: 0.347380
[Epoch 36; Iter    10/  172] train: loss: 0.1088064
[Epoch 36; Iter    40/  172] train: loss: 0.1021273
[Epoch 36; Iter    70/  172] train: loss: 0.1413885
[Epoch 36; Iter   100/  172] train: loss: 0.1340262
[Epoch 36; Iter   130/  172] train: loss: 0.1870333
[Epoch 36; Iter   160/  172] train: loss: 0.1790794
[Epoch 36] ogbg-moltoxcast: 0.661436 val loss: 0.282833
[Epoch 36] ogbg-moltoxcast: 0.625752 test loss: 0.439385
[Epoch 37; Iter    18/  172] train: loss: 0.1562180
[Epoch 37; Iter    48/  172] train: loss: 0.1483738
[Epoch 37; Iter    78/  172] train: loss: 0.1374384
[Epoch 37; Iter   108/  172] train: loss: 0.2056359
[Epoch 37; Iter   138/  172] train: loss: 0.1377307
[Epoch 37; Iter   168/  172] train: loss: 0.1826747
[Epoch 37] ogbg-moltoxcast: 0.671270 val loss: 0.264787
[Epoch 37] ogbg-moltoxcast: 0.629906 test loss: 0.340545
[Epoch 38; Iter    26/  172] train: loss: 0.1389161
[Epoch 38; Iter    56/  172] train: loss: 0.1356371
[Epoch 38; Iter    86/  172] train: loss: 0.1320718
[Epoch 38; Iter   116/  172] train: loss: 0.1430888
[Epoch 38; Iter   146/  172] train: loss: 0.1859627
[Epoch 38] ogbg-moltoxcast: 0.668538 val loss: 0.263289
[Epoch 38] ogbg-moltoxcast: 0.632552 test loss: 0.334842
[Epoch 39; Iter     4/  172] train: loss: 0.1562746
[Epoch 39; Iter    34/  172] train: loss: 0.1154982
[Epoch 39; Iter    64/  172] train: loss: 0.1428332
[Epoch 39; Iter    94/  172] train: loss: 0.1532309
[Epoch 39; Iter   124/  172] train: loss: 0.1477548
[Epoch 39; Iter   154/  172] train: loss: 0.1026450
[Epoch 39] ogbg-moltoxcast: 0.662855 val loss: 0.265123
[Epoch 39] ogbg-moltoxcast: 0.626615 test loss: 0.317033
[Epoch 40; Iter    12/  172] train: loss: 0.1814106
[Epoch 40; Iter    42/  172] train: loss: 0.1423036
[Epoch 40; Iter    72/  172] train: loss: 0.1449937
[Epoch 40; Iter   102/  172] train: loss: 0.1554079
[Epoch 40; Iter   132/  172] train: loss: 0.1134982
[Epoch 40; Iter   162/  172] train: loss: 0.1345961
[Epoch 40] ogbg-moltoxcast: 0.667392 val loss: 0.267108
[Epoch 40] ogbg-moltoxcast: 0.628590 test loss: 0.321712
[Epoch 41; Iter    20/  172] train: loss: 0.1303653
[Epoch 41; Iter    50/  172] train: loss: 0.0883432
[Epoch 41; Iter    80/  172] train: loss: 0.1445674
[Epoch 41; Iter   110/  172] train: loss: 0.1224732
[Epoch 41; Iter   140/  172] train: loss: 0.1065143
[Epoch 41; Iter   170/  172] train: loss: 0.1375479
[Epoch 41] ogbg-moltoxcast: 0.668797 val loss: 0.259878
[Epoch 41] ogbg-moltoxcast: 0.629719 test loss: 0.308805
[Epoch 42; Iter    28/  172] train: loss: 0.0956784
[Epoch 42; Iter    58/  172] train: loss: 0.1739007
[Epoch 42; Iter    88/  172] train: loss: 0.1688317
[Epoch 42; Iter   118/  172] train: loss: 0.0949604
[Epoch 42; Iter   148/  172] train: loss: 0.1525922
[Epoch 42] ogbg-moltoxcast: 0.661452 val loss: 0.269068
[Epoch 42] ogbg-moltoxcast: 0.631355 test loss: 0.320050
[Epoch 43; Iter     6/  172] train: loss: 0.0948864
[Epoch 43; Iter    36/  172] train: loss: 0.1145143
[Epoch 43; Iter    66/  172] train: loss: 0.0869088
[Epoch 43; Iter    96/  172] train: loss: 0.0878296
[Epoch 43; Iter   126/  172] train: loss: 0.1253096
[Epoch 43; Iter   156/  172] train: loss: 0.1771425
[Epoch 43] ogbg-moltoxcast: 0.665992 val loss: 0.268417
[Epoch 43] ogbg-moltoxcast: 0.637099 test loss: 0.317744
[Epoch 44; Iter    14/  172] train: loss: 0.1181279
[Epoch 44; Iter    44/  172] train: loss: 0.2269389
[Epoch 44; Iter    74/  172] train: loss: 0.1208727
[Epoch 44; Iter   104/  172] train: loss: 0.1506889
[Epoch 44; Iter   134/  172] train: loss: 0.1466006
[Epoch 44; Iter   164/  172] train: loss: 0.1678854
[Epoch 44] ogbg-moltoxcast: 0.667295 val loss: 0.266392
[Epoch 44] ogbg-moltoxcast: 0.636200 test loss: 0.318413
[Epoch 45; Iter    22/  172] train: loss: 0.1590231
[Epoch 45; Iter    52/  172] train: loss: 0.1325636
[Epoch 45; Iter    82/  172] train: loss: 0.1842669
[Epoch 45; Iter   112/  172] train: loss: 0.1075756
[Epoch 45; Iter   142/  172] train: loss: 0.1524905
[Epoch 45; Iter   172/  172] train: loss: 0.0952299
[Epoch 45] ogbg-moltoxcast: 0.662507 val loss: 0.271194
[Epoch 45] ogbg-moltoxcast: 0.633752 test loss: 0.322702
[Epoch 46; Iter    30/  172] train: loss: 0.1159280
[Epoch 46; Iter    60/  172] train: loss: 0.0946214
[Epoch 46; Iter    90/  172] train: loss: 0.1437082
[Epoch 46; Iter   120/  172] train: loss: 0.1379656
[Epoch 46; Iter   150/  172] train: loss: 0.1145001
[Epoch 46] ogbg-moltoxcast: 0.658631 val loss: 0.271877
[Epoch 46] ogbg-moltoxcast: 0.632207 test loss: 0.325739
[Epoch 47; Iter     8/  172] train: loss: 0.1587652
[Epoch 47; Iter    38/  172] train: loss: 0.1528651
[Epoch 47; Iter    68/  172] train: loss: 0.0994398
[Epoch 47; Iter    98/  172] train: loss: 0.1243663
[Epoch 47; Iter   128/  172] train: loss: 0.1100089
[Epoch 47; Iter   158/  172] train: loss: 0.0960632
[Epoch 47] ogbg-moltoxcast: 0.659117 val loss: 0.270675
[Epoch 47] ogbg-moltoxcast: 0.627437 test loss: 0.320716
[Epoch 48; Iter    16/  172] train: loss: 0.1482439
[Epoch 48; Iter    46/  172] train: loss: 0.1746036
[Epoch 48; Iter    76/  172] train: loss: 0.0929705
[Epoch 48; Iter   106/  172] train: loss: 0.1202317
[Epoch 48; Iter   136/  172] train: loss: 0.1544410
[Epoch 48; Iter   166/  172] train: loss: 0.1418072
[Epoch 48] ogbg-moltoxcast: 0.657670 val loss: 0.275878
[Epoch 48] ogbg-moltoxcast: 0.629029 test loss: 0.330797
[Epoch 49; Iter    24/  172] train: loss: 0.1601118
[Epoch 49; Iter    54/  172] train: loss: 0.1400398
[Epoch 49; Iter    84/  172] train: loss: 0.1787242
[Epoch 49; Iter   114/  172] train: loss: 0.1315226
[Epoch 49; Iter   144/  172] train: loss: 0.1315391
[Epoch 49] ogbg-moltoxcast: 0.658025 val loss: 0.272339
[Epoch 49] ogbg-moltoxcast: 0.629131 test loss: 0.327351
[Epoch 50; Iter     2/  172] train: loss: 0.1661810
[Epoch 50; Iter    32/  172] train: loss: 0.0938108
[Epoch 50; Iter    62/  172] train: loss: 0.1293894
[Epoch 50; Iter    92/  172] train: loss: 0.1335112
[Epoch 50; Iter   122/  172] train: loss: 0.1938937
[Epoch 50; Iter   152/  172] train: loss: 0.1081959
[Epoch 50] ogbg-moltoxcast: 0.659577 val loss: 0.268930
[Epoch 50] ogbg-moltoxcast: 0.628294 test loss: 0.317619
[Epoch 51; Iter    10/  172] train: loss: 0.1367690
[Epoch 51; Iter    40/  172] train: loss: 0.1557286
[Epoch 51; Iter    70/  172] train: loss: 0.1339654
[Epoch 51; Iter   100/  172] train: loss: 0.1476950
[Epoch 51; Iter   130/  172] train: loss: 0.0680756
[Epoch 51; Iter   160/  172] train: loss: 0.1126504
[Epoch 51] ogbg-moltoxcast: 0.656817 val loss: 0.276057
[Epoch 51] ogbg-moltoxcast: 0.622367 test loss: 0.328023
[Epoch 52; Iter    18/  172] train: loss: 0.1143537
[Epoch 52; Iter    48/  172] train: loss: 0.1143280
[Epoch 52; Iter    78/  172] train: loss: 0.1795755
[Epoch 52; Iter   108/  172] train: loss: 0.1032822
[Epoch 52; Iter   138/  172] train: loss: 0.1672788
[Epoch 52; Iter   168/  172] train: loss: 0.1152654
[Epoch 52] ogbg-moltoxcast: 0.654928 val loss: 0.277699
[Epoch 52] ogbg-moltoxcast: 0.627810 test loss: 0.326216
[Epoch 53; Iter    26/  172] train: loss: 0.1536719
[Epoch 53; Iter    56/  172] train: loss: 0.1191013
[Epoch 53; Iter    86/  172] train: loss: 0.1344331
[Epoch 53; Iter   116/  172] train: loss: 0.1503026
[Epoch 53; Iter   146/  172] train: loss: 0.1216033
[Epoch 53] ogbg-moltoxcast: 0.657274 val loss: 0.276355
[Epoch 53] ogbg-moltoxcast: 0.621555 test loss: 0.332762
[Epoch 54; Iter     4/  172] train: loss: 0.1224882
[Epoch 54; Iter    34/  172] train: loss: 0.1283540
[Epoch 54; Iter    64/  172] train: loss: 0.0921558
[Epoch 54; Iter    94/  172] train: loss: 0.0892726
[Epoch 54; Iter   124/  172] train: loss: 0.1691940
[Epoch 34] ogbg-moltoxcast: 0.671287 val loss: 0.269475
[Epoch 34] ogbg-moltoxcast: 0.633042 test loss: 0.322972
[Epoch 35; Iter     2/  172] train: loss: 0.1087147
[Epoch 35; Iter    32/  172] train: loss: 0.1494864
[Epoch 35; Iter    62/  172] train: loss: 0.1105219
[Epoch 35; Iter    92/  172] train: loss: 0.1659597
[Epoch 35; Iter   122/  172] train: loss: 0.1098245
[Epoch 35; Iter   152/  172] train: loss: 0.1107249
[Epoch 35] ogbg-moltoxcast: 0.662456 val loss: 0.272357
[Epoch 35] ogbg-moltoxcast: 0.625365 test loss: 0.327397
[Epoch 36; Iter    10/  172] train: loss: 0.1494153
[Epoch 36; Iter    40/  172] train: loss: 0.1323490
[Epoch 36; Iter    70/  172] train: loss: 0.1468208
[Epoch 36; Iter   100/  172] train: loss: 0.2183442
[Epoch 36; Iter   130/  172] train: loss: 0.0886133
[Epoch 36; Iter   160/  172] train: loss: 0.1677290
[Epoch 36] ogbg-moltoxcast: 0.672586 val loss: 0.266827
[Epoch 36] ogbg-moltoxcast: 0.636587 test loss: 0.319840
[Epoch 37; Iter    18/  172] train: loss: 0.1306395
[Epoch 37; Iter    48/  172] train: loss: 0.1676349
[Epoch 37; Iter    78/  172] train: loss: 0.1178541
[Epoch 37; Iter   108/  172] train: loss: 0.1440824
[Epoch 37; Iter   138/  172] train: loss: 0.1597832
[Epoch 37; Iter   168/  172] train: loss: 0.1087347
[Epoch 37] ogbg-moltoxcast: 0.649037 val loss: 0.292816
[Epoch 37] ogbg-moltoxcast: 0.621725 test loss: 0.351003
[Epoch 38; Iter    26/  172] train: loss: 0.0835247
[Epoch 38; Iter    56/  172] train: loss: 0.1776148
[Epoch 38; Iter    86/  172] train: loss: 0.1134421
[Epoch 38; Iter   116/  172] train: loss: 0.1532844
[Epoch 38; Iter   146/  172] train: loss: 0.1290214
[Epoch 38] ogbg-moltoxcast: 0.668943 val loss: 0.265608
[Epoch 38] ogbg-moltoxcast: 0.637061 test loss: 0.313686
[Epoch 39; Iter     4/  172] train: loss: 0.0986614
[Epoch 39; Iter    34/  172] train: loss: 0.1109775
[Epoch 39; Iter    64/  172] train: loss: 0.1397774
[Epoch 39; Iter    94/  172] train: loss: 0.1380906
[Epoch 39; Iter   124/  172] train: loss: 0.1129827
[Epoch 39; Iter   154/  172] train: loss: 0.1311493
[Epoch 39] ogbg-moltoxcast: 0.673905 val loss: 0.269625
[Epoch 39] ogbg-moltoxcast: 0.639488 test loss: 0.320454
[Epoch 40; Iter    12/  172] train: loss: 0.1358027
[Epoch 40; Iter    42/  172] train: loss: 0.1640694
[Epoch 40; Iter    72/  172] train: loss: 0.1464133
[Epoch 40; Iter   102/  172] train: loss: 0.1274463
[Epoch 40; Iter   132/  172] train: loss: 0.1344649
[Epoch 40; Iter   162/  172] train: loss: 0.1040712
[Epoch 40] ogbg-moltoxcast: 0.666984 val loss: 0.270986
[Epoch 40] ogbg-moltoxcast: 0.630989 test loss: 0.320645
[Epoch 41; Iter    20/  172] train: loss: 0.1159053
[Epoch 41; Iter    50/  172] train: loss: 0.1454234
[Epoch 41; Iter    80/  172] train: loss: 0.1538596
[Epoch 41; Iter   110/  172] train: loss: 0.2315401
[Epoch 41; Iter   140/  172] train: loss: 0.1602643
[Epoch 41; Iter   170/  172] train: loss: 0.1041928
[Epoch 41] ogbg-moltoxcast: 0.665678 val loss: 0.273017
[Epoch 41] ogbg-moltoxcast: 0.637247 test loss: 0.320287
[Epoch 42; Iter    28/  172] train: loss: 0.0977870
[Epoch 42; Iter    58/  172] train: loss: 0.1165913
[Epoch 42; Iter    88/  172] train: loss: 0.1330445
[Epoch 42; Iter   118/  172] train: loss: 0.0967998
[Epoch 42; Iter   148/  172] train: loss: 0.1842380
[Epoch 42] ogbg-moltoxcast: 0.671870 val loss: 0.273965
[Epoch 42] ogbg-moltoxcast: 0.641179 test loss: 0.323396
[Epoch 43; Iter     6/  172] train: loss: 0.2163401
[Epoch 43; Iter    36/  172] train: loss: 0.0902200
[Epoch 43; Iter    66/  172] train: loss: 0.0648797
[Epoch 43; Iter    96/  172] train: loss: 0.0870732
[Epoch 43; Iter   126/  172] train: loss: 0.1666484
[Epoch 43; Iter   156/  172] train: loss: 0.1135820
[Epoch 43] ogbg-moltoxcast: 0.660268 val loss: 0.274895
[Epoch 43] ogbg-moltoxcast: 0.628862 test loss: 0.323766
[Epoch 44; Iter    14/  172] train: loss: 0.1200144
[Epoch 44; Iter    44/  172] train: loss: 0.1671647
[Epoch 44; Iter    74/  172] train: loss: 0.1588257
[Epoch 44; Iter   104/  172] train: loss: 0.0870844
[Epoch 44; Iter   134/  172] train: loss: 0.1135817
[Epoch 44; Iter   164/  172] train: loss: 0.1151444
[Epoch 44] ogbg-moltoxcast: 0.652723 val loss: 0.278059
[Epoch 44] ogbg-moltoxcast: 0.624320 test loss: 0.319245
[Epoch 45; Iter    22/  172] train: loss: 0.1263041
[Epoch 45; Iter    52/  172] train: loss: 0.1970410
[Epoch 45; Iter    82/  172] train: loss: 0.1562007
[Epoch 45; Iter   112/  172] train: loss: 0.1484653
[Epoch 45; Iter   142/  172] train: loss: 0.1605770
[Epoch 45; Iter   172/  172] train: loss: 0.1779989
[Epoch 45] ogbg-moltoxcast: 0.662203 val loss: 0.275162
[Epoch 45] ogbg-moltoxcast: 0.628072 test loss: 0.325664
[Epoch 46; Iter    30/  172] train: loss: 0.1576654
[Epoch 46; Iter    60/  172] train: loss: 0.1033247
[Epoch 46; Iter    90/  172] train: loss: 0.0964752
[Epoch 46; Iter   120/  172] train: loss: 0.1885362
[Epoch 46; Iter   150/  172] train: loss: 0.1547301
[Epoch 46] ogbg-moltoxcast: 0.670402 val loss: 0.271624
[Epoch 46] ogbg-moltoxcast: 0.636497 test loss: 0.318014
[Epoch 47; Iter     8/  172] train: loss: 0.1280708
[Epoch 47; Iter    38/  172] train: loss: 0.1343012
[Epoch 47; Iter    68/  172] train: loss: 0.1049130
[Epoch 47; Iter    98/  172] train: loss: 0.1014748
[Epoch 47; Iter   128/  172] train: loss: 0.1056105
[Epoch 47; Iter   158/  172] train: loss: 0.1378351
[Epoch 47] ogbg-moltoxcast: 0.669539 val loss: 0.274638
[Epoch 47] ogbg-moltoxcast: 0.637173 test loss: 0.325623
[Epoch 48; Iter    16/  172] train: loss: 0.0925844
[Epoch 48; Iter    46/  172] train: loss: 0.1118130
[Epoch 48; Iter    76/  172] train: loss: 0.1261319
[Epoch 48; Iter   106/  172] train: loss: 0.1611777
[Epoch 48; Iter   136/  172] train: loss: 0.0986670
[Epoch 48; Iter   166/  172] train: loss: 0.1327424
[Epoch 48] ogbg-moltoxcast: 0.667929 val loss: 0.274235
[Epoch 48] ogbg-moltoxcast: 0.633369 test loss: 0.325246
[Epoch 49; Iter    24/  172] train: loss: 0.0942769
[Epoch 49; Iter    54/  172] train: loss: 0.1416688
[Epoch 49; Iter    84/  172] train: loss: 0.0937385
[Epoch 49; Iter   114/  172] train: loss: 0.1573148
[Epoch 49; Iter   144/  172] train: loss: 0.1080686
[Epoch 49] ogbg-moltoxcast: 0.662247 val loss: 0.275049
[Epoch 49] ogbg-moltoxcast: 0.623391 test loss: 0.325701
[Epoch 50; Iter     2/  172] train: loss: 0.1178697
[Epoch 50; Iter    32/  172] train: loss: 0.1415681
[Epoch 50; Iter    62/  172] train: loss: 0.1412150
[Epoch 50; Iter    92/  172] train: loss: 0.1404630
[Epoch 50; Iter   122/  172] train: loss: 0.0965997
[Epoch 50; Iter   152/  172] train: loss: 0.1372210
[Epoch 50] ogbg-moltoxcast: 0.674340 val loss: 0.273450
[Epoch 50] ogbg-moltoxcast: 0.638520 test loss: 0.323909
[Epoch 51; Iter    10/  172] train: loss: 0.1042736
[Epoch 51; Iter    40/  172] train: loss: 0.1165140
[Epoch 51; Iter    70/  172] train: loss: 0.1371832
[Epoch 51; Iter   100/  172] train: loss: 0.1235056
[Epoch 51; Iter   130/  172] train: loss: 0.1676043
[Epoch 51; Iter   160/  172] train: loss: 0.1140203
[Epoch 51] ogbg-moltoxcast: 0.663696 val loss: 0.276972
[Epoch 51] ogbg-moltoxcast: 0.629724 test loss: 0.328928
[Epoch 52; Iter    18/  172] train: loss: 0.1375972
[Epoch 52; Iter    48/  172] train: loss: 0.0664093
[Epoch 52; Iter    78/  172] train: loss: 0.1071188
[Epoch 52; Iter   108/  172] train: loss: 0.1550430
[Epoch 52; Iter   138/  172] train: loss: 0.1292318
[Epoch 52; Iter   168/  172] train: loss: 0.1034438
[Epoch 52] ogbg-moltoxcast: 0.672735 val loss: 0.275613
[Epoch 52] ogbg-moltoxcast: 0.630254 test loss: 0.327607
[Epoch 53; Iter    26/  172] train: loss: 0.1272342
[Epoch 53; Iter    56/  172] train: loss: 0.1359157
[Epoch 53; Iter    86/  172] train: loss: 0.1574473
[Epoch 53; Iter   116/  172] train: loss: 0.0948464
[Epoch 53; Iter   146/  172] train: loss: 0.1532669
[Epoch 53] ogbg-moltoxcast: 0.662708 val loss: 0.281913
[Epoch 53] ogbg-moltoxcast: 0.627666 test loss: 0.331707
[Epoch 54; Iter     4/  172] train: loss: 0.1644858
[Epoch 54; Iter    34/  172] train: loss: 0.1133636
[Epoch 54; Iter    64/  172] train: loss: 0.1426677
[Epoch 54; Iter    94/  172] train: loss: 0.1585511
[Epoch 54; Iter   124/  172] train: loss: 0.1183262
[Epoch 34] ogbg-moltoxcast: 0.682199 val loss: 0.265005
[Epoch 34] ogbg-moltoxcast: 0.640240 test loss: 0.315938
[Epoch 35; Iter     2/  172] train: loss: 0.1811637
[Epoch 35; Iter    32/  172] train: loss: 0.1604499
[Epoch 35; Iter    62/  172] train: loss: 0.1333420
[Epoch 35; Iter    92/  172] train: loss: 0.1476433
[Epoch 35; Iter   122/  172] train: loss: 0.1036348
[Epoch 35; Iter   152/  172] train: loss: 0.1098578
[Epoch 35] ogbg-moltoxcast: 0.659315 val loss: 0.275267
[Epoch 35] ogbg-moltoxcast: 0.625902 test loss: 0.321243
[Epoch 36; Iter    10/  172] train: loss: 0.1725299
[Epoch 36; Iter    40/  172] train: loss: 0.1248290
[Epoch 36; Iter    70/  172] train: loss: 0.1040648
[Epoch 36; Iter   100/  172] train: loss: 0.1567696
[Epoch 36; Iter   130/  172] train: loss: 0.1273508
[Epoch 36; Iter   160/  172] train: loss: 0.1714470
[Epoch 36] ogbg-moltoxcast: 0.655737 val loss: 0.268901
[Epoch 36] ogbg-moltoxcast: 0.639703 test loss: 0.311263
[Epoch 37; Iter    18/  172] train: loss: 0.1223170
[Epoch 37; Iter    48/  172] train: loss: 0.1931507
[Epoch 37; Iter    78/  172] train: loss: 0.1594186
[Epoch 37; Iter   108/  172] train: loss: 0.1428655
[Epoch 37; Iter   138/  172] train: loss: 0.1459456
[Epoch 37; Iter   168/  172] train: loss: 0.0880187
[Epoch 37] ogbg-moltoxcast: 0.677198 val loss: 0.261282
[Epoch 37] ogbg-moltoxcast: 0.641785 test loss: 0.311962
[Epoch 38; Iter    26/  172] train: loss: 0.1270903
[Epoch 38; Iter    56/  172] train: loss: 0.1202286
[Epoch 38; Iter    86/  172] train: loss: 0.0956752
[Epoch 38; Iter   116/  172] train: loss: 0.1360088
[Epoch 38; Iter   146/  172] train: loss: 0.1565078
[Epoch 38] ogbg-moltoxcast: 0.672189 val loss: 0.260999
[Epoch 38] ogbg-moltoxcast: 0.636009 test loss: 0.308972
[Epoch 39; Iter     4/  172] train: loss: 0.1421999
[Epoch 39; Iter    34/  172] train: loss: 0.1364791
[Epoch 39; Iter    64/  172] train: loss: 0.1571302
[Epoch 39; Iter    94/  172] train: loss: 0.1249761
[Epoch 39; Iter   124/  172] train: loss: 0.1468967
[Epoch 39; Iter   154/  172] train: loss: 0.1115142
[Epoch 39] ogbg-moltoxcast: 0.671692 val loss: 0.265042
[Epoch 39] ogbg-moltoxcast: 0.637857 test loss: 0.311890
[Epoch 40; Iter    12/  172] train: loss: 0.1300392
[Epoch 40; Iter    42/  172] train: loss: 0.1104352
[Epoch 40; Iter    72/  172] train: loss: 0.1708840
[Epoch 40; Iter   102/  172] train: loss: 0.1440674
[Epoch 40; Iter   132/  172] train: loss: 0.1233859
[Epoch 40; Iter   162/  172] train: loss: 0.1264520
[Epoch 40] ogbg-moltoxcast: 0.674547 val loss: 0.263167
[Epoch 40] ogbg-moltoxcast: 0.640789 test loss: 0.312842
[Epoch 41; Iter    20/  172] train: loss: 0.1628424
[Epoch 41; Iter    50/  172] train: loss: 0.1393693
[Epoch 41; Iter    80/  172] train: loss: 0.1664101
[Epoch 41; Iter   110/  172] train: loss: 0.1477662
[Epoch 41; Iter   140/  172] train: loss: 0.1477909
[Epoch 41; Iter   170/  172] train: loss: 0.1564031
[Epoch 41] ogbg-moltoxcast: 0.676674 val loss: 0.264760
[Epoch 41] ogbg-moltoxcast: 0.638576 test loss: 0.310342
[Epoch 42; Iter    28/  172] train: loss: 0.1975609
[Epoch 42; Iter    58/  172] train: loss: 0.1665587
[Epoch 42; Iter    88/  172] train: loss: 0.1257114
[Epoch 42; Iter   118/  172] train: loss: 0.1757786
[Epoch 42; Iter   148/  172] train: loss: 0.1412563
[Epoch 42] ogbg-moltoxcast: 0.666308 val loss: 0.265975
[Epoch 42] ogbg-moltoxcast: 0.639035 test loss: 0.309415
[Epoch 43; Iter     6/  172] train: loss: 0.1402886
[Epoch 43; Iter    36/  172] train: loss: 0.1544397
[Epoch 43; Iter    66/  172] train: loss: 0.1295326
[Epoch 43; Iter    96/  172] train: loss: 0.1470391
[Epoch 43; Iter   126/  172] train: loss: 0.1521038
[Epoch 43; Iter   156/  172] train: loss: 0.1375238
[Epoch 43] ogbg-moltoxcast: 0.669703 val loss: 0.267101
[Epoch 43] ogbg-moltoxcast: 0.632148 test loss: 0.338467
[Epoch 44; Iter    14/  172] train: loss: 0.1173273
[Epoch 44; Iter    44/  172] train: loss: 0.1352991
[Epoch 44; Iter    74/  172] train: loss: 0.1171454
[Epoch 44; Iter   104/  172] train: loss: 0.1060600
[Epoch 44; Iter   134/  172] train: loss: 0.1537052
[Epoch 44; Iter   164/  172] train: loss: 0.1448387
[Epoch 44] ogbg-moltoxcast: 0.659243 val loss: 0.274135
[Epoch 44] ogbg-moltoxcast: 0.629674 test loss: 0.581568
[Epoch 45; Iter    22/  172] train: loss: 0.1221366
[Epoch 45; Iter    52/  172] train: loss: 0.1507524
[Epoch 45; Iter    82/  172] train: loss: 0.1327303
[Epoch 45; Iter   112/  172] train: loss: 0.1200357
[Epoch 45; Iter   142/  172] train: loss: 0.1192134
[Epoch 45; Iter   172/  172] train: loss: 0.1023019
[Epoch 45] ogbg-moltoxcast: 0.661722 val loss: 0.270528
[Epoch 45] ogbg-moltoxcast: 0.635974 test loss: 0.317326
[Epoch 46; Iter    30/  172] train: loss: 0.1681787
[Epoch 46; Iter    60/  172] train: loss: 0.1098036
[Epoch 46; Iter    90/  172] train: loss: 0.1025471
[Epoch 46; Iter   120/  172] train: loss: 0.1264403
[Epoch 46; Iter   150/  172] train: loss: 0.1265990
[Epoch 46] ogbg-moltoxcast: 0.668821 val loss: 0.276786
[Epoch 46] ogbg-moltoxcast: 0.623175 test loss: 0.329964
[Epoch 47; Iter     8/  172] train: loss: 0.0960957
[Epoch 47; Iter    38/  172] train: loss: 0.1105626
[Epoch 47; Iter    68/  172] train: loss: 0.1737389
[Epoch 47; Iter    98/  172] train: loss: 0.1207408
[Epoch 47; Iter   128/  172] train: loss: 0.1603127
[Epoch 47; Iter   158/  172] train: loss: 0.1418298
[Epoch 47] ogbg-moltoxcast: 0.663434 val loss: 0.272159
[Epoch 47] ogbg-moltoxcast: 0.629047 test loss: 0.319382
[Epoch 48; Iter    16/  172] train: loss: 0.1271382
[Epoch 48; Iter    46/  172] train: loss: 0.1639556
[Epoch 48; Iter    76/  172] train: loss: 0.1008637
[Epoch 48; Iter   106/  172] train: loss: 0.1937077
[Epoch 48; Iter   136/  172] train: loss: 0.1273508
[Epoch 48; Iter   166/  172] train: loss: 0.1134795
[Epoch 48] ogbg-moltoxcast: 0.663071 val loss: 0.275494
[Epoch 48] ogbg-moltoxcast: 0.630493 test loss: 0.392305
[Epoch 49; Iter    24/  172] train: loss: 0.1578284
[Epoch 49; Iter    54/  172] train: loss: 0.1972526
[Epoch 49; Iter    84/  172] train: loss: 0.1309431
[Epoch 49; Iter   114/  172] train: loss: 0.1423275
[Epoch 49; Iter   144/  172] train: loss: 0.1211976
[Epoch 49] ogbg-moltoxcast: 0.660148 val loss: 0.273882
[Epoch 49] ogbg-moltoxcast: 0.633528 test loss: 0.317177
[Epoch 50; Iter     2/  172] train: loss: 0.1480496
[Epoch 50; Iter    32/  172] train: loss: 0.0999400
[Epoch 50; Iter    62/  172] train: loss: 0.1401123
[Epoch 50; Iter    92/  172] train: loss: 0.1499498
[Epoch 50; Iter   122/  172] train: loss: 0.1205039
[Epoch 50; Iter   152/  172] train: loss: 0.1283395
[Epoch 50] ogbg-moltoxcast: 0.663760 val loss: 0.268386
[Epoch 50] ogbg-moltoxcast: 0.633006 test loss: 0.311497
[Epoch 51; Iter    10/  172] train: loss: 0.1578486
[Epoch 51; Iter    40/  172] train: loss: 0.1645830
[Epoch 51; Iter    70/  172] train: loss: 0.1146605
[Epoch 51; Iter   100/  172] train: loss: 0.1544452
[Epoch 51; Iter   130/  172] train: loss: 0.1524653
[Epoch 51; Iter   160/  172] train: loss: 0.1280661
[Epoch 51] ogbg-moltoxcast: 0.656306 val loss: 0.280462
[Epoch 51] ogbg-moltoxcast: 0.628501 test loss: 0.329586
[Epoch 52; Iter    18/  172] train: loss: 0.1170479
[Epoch 52; Iter    48/  172] train: loss: 0.1297531
[Epoch 52; Iter    78/  172] train: loss: 0.1429591
[Epoch 52; Iter   108/  172] train: loss: 0.1240212
[Epoch 52; Iter   138/  172] train: loss: 0.1380575
[Epoch 52; Iter   168/  172] train: loss: 0.1380472
[Epoch 52] ogbg-moltoxcast: 0.662937 val loss: 0.275733
[Epoch 52] ogbg-moltoxcast: 0.634575 test loss: 0.323332
[Epoch 53; Iter    26/  172] train: loss: 0.1278585
[Epoch 53; Iter    56/  172] train: loss: 0.0871178
[Epoch 53; Iter    86/  172] train: loss: 0.0828208
[Epoch 53; Iter   116/  172] train: loss: 0.1233469
[Epoch 53; Iter   146/  172] train: loss: 0.1269051
[Epoch 53] ogbg-moltoxcast: 0.657263 val loss: 0.278812
[Epoch 53] ogbg-moltoxcast: 0.629776 test loss: 0.327951
[Epoch 54; Iter     4/  172] train: loss: 0.1409912
[Epoch 54; Iter    34/  172] train: loss: 0.1136457
[Epoch 54; Iter    64/  172] train: loss: 0.1353444
[Epoch 54; Iter    94/  172] train: loss: 0.1908741
[Epoch 54; Iter   124/  172] train: loss: 0.1203682
[Epoch 44; Iter    23/  229] train: loss: 0.2264849
[Epoch 44; Iter    53/  229] train: loss: 0.0886771
[Epoch 44; Iter    83/  229] train: loss: 0.1390251
[Epoch 44; Iter   113/  229] train: loss: 0.1349181
[Epoch 44; Iter   143/  229] train: loss: 0.1792378
[Epoch 44; Iter   173/  229] train: loss: 0.1813403
[Epoch 44; Iter   203/  229] train: loss: 0.1456348
[Epoch 44] ogbg-moltoxcast: 0.705559 val loss: 0.245466
[Epoch 44] ogbg-moltoxcast: 0.666341 test loss: 0.306116
[Epoch 45; Iter     4/  229] train: loss: 0.1232257
[Epoch 45; Iter    34/  229] train: loss: 0.1231837
[Epoch 45; Iter    64/  229] train: loss: 0.1774980
[Epoch 45; Iter    94/  229] train: loss: 0.1012383
[Epoch 45; Iter   124/  229] train: loss: 0.1465953
[Epoch 45; Iter   154/  229] train: loss: 0.1291458
[Epoch 45; Iter   184/  229] train: loss: 0.1219420
[Epoch 45; Iter   214/  229] train: loss: 0.1104531
[Epoch 45] ogbg-moltoxcast: 0.704615 val loss: 0.247379
[Epoch 45] ogbg-moltoxcast: 0.671021 test loss: 0.307819
[Epoch 46; Iter    15/  229] train: loss: 0.1821057
[Epoch 46; Iter    45/  229] train: loss: 0.1924276
[Epoch 46; Iter    75/  229] train: loss: 0.1452564
[Epoch 46; Iter   105/  229] train: loss: 0.1902489
[Epoch 46; Iter   135/  229] train: loss: 0.1714316
[Epoch 46; Iter   165/  229] train: loss: 0.1479156
[Epoch 46; Iter   195/  229] train: loss: 0.1530933
[Epoch 46; Iter   225/  229] train: loss: 0.1574866
[Epoch 46] ogbg-moltoxcast: 0.716601 val loss: 0.251838
[Epoch 46] ogbg-moltoxcast: 0.668564 test loss: 0.318547
[Epoch 47; Iter    26/  229] train: loss: 0.1636443
[Epoch 47; Iter    56/  229] train: loss: 0.1707651
[Epoch 47; Iter    86/  229] train: loss: 0.1491275
[Epoch 47; Iter   116/  229] train: loss: 0.1297825
[Epoch 47; Iter   146/  229] train: loss: 0.1247748
[Epoch 47; Iter   176/  229] train: loss: 0.1116011
[Epoch 47; Iter   206/  229] train: loss: 0.1319237
[Epoch 47] ogbg-moltoxcast: 0.703550 val loss: 0.257762
[Epoch 47] ogbg-moltoxcast: 0.670302 test loss: 0.314986
[Epoch 48; Iter     7/  229] train: loss: 0.1540356
[Epoch 48; Iter    37/  229] train: loss: 0.1363062
[Epoch 48; Iter    67/  229] train: loss: 0.1215944
[Epoch 48; Iter    97/  229] train: loss: 0.1487880
[Epoch 48; Iter   127/  229] train: loss: 0.1480041
[Epoch 48; Iter   157/  229] train: loss: 0.1217473
[Epoch 48; Iter   187/  229] train: loss: 0.1528045
[Epoch 48; Iter   217/  229] train: loss: 0.1440135
[Epoch 48] ogbg-moltoxcast: 0.702789 val loss: 0.252574
[Epoch 48] ogbg-moltoxcast: 0.671333 test loss: 0.308870
[Epoch 49; Iter    18/  229] train: loss: 0.1653854
[Epoch 49; Iter    48/  229] train: loss: 0.1472142
[Epoch 49; Iter    78/  229] train: loss: 0.0897216
[Epoch 49; Iter   108/  229] train: loss: 0.1332829
[Epoch 49; Iter   138/  229] train: loss: 0.1278258
[Epoch 49; Iter   168/  229] train: loss: 0.1354849
[Epoch 49; Iter   198/  229] train: loss: 0.1466219
[Epoch 49; Iter   228/  229] train: loss: 0.1681656
[Epoch 49] ogbg-moltoxcast: 0.704880 val loss: 0.253895
[Epoch 49] ogbg-moltoxcast: 0.674955 test loss: 0.307377
[Epoch 50; Iter    29/  229] train: loss: 0.1128514
[Epoch 50; Iter    59/  229] train: loss: 0.1580453
[Epoch 50; Iter    89/  229] train: loss: 0.0847655
[Epoch 50; Iter   119/  229] train: loss: 0.1752099
[Epoch 50; Iter   149/  229] train: loss: 0.1431818
[Epoch 50; Iter   179/  229] train: loss: 0.1425008
[Epoch 50; Iter   209/  229] train: loss: 0.1178907
[Epoch 50] ogbg-moltoxcast: 0.697912 val loss: 0.251743
[Epoch 50] ogbg-moltoxcast: 0.663674 test loss: 0.306254
[Epoch 51; Iter    10/  229] train: loss: 0.1681324
[Epoch 51; Iter    40/  229] train: loss: 0.1074758
[Epoch 51; Iter    70/  229] train: loss: 0.1577649
[Epoch 51; Iter   100/  229] train: loss: 0.1703412
[Epoch 51; Iter   130/  229] train: loss: 0.1137150
[Epoch 51; Iter   160/  229] train: loss: 0.1147684
[Epoch 51; Iter   190/  229] train: loss: 0.1450088
[Epoch 51; Iter   220/  229] train: loss: 0.1603104
[Epoch 51] ogbg-moltoxcast: 0.705770 val loss: 0.249206
[Epoch 51] ogbg-moltoxcast: 0.675873 test loss: 0.302145
[Epoch 52; Iter    21/  229] train: loss: 0.1338279
[Epoch 52; Iter    51/  229] train: loss: 0.1601805
[Epoch 52; Iter    81/  229] train: loss: 0.1255042
[Epoch 52; Iter   111/  229] train: loss: 0.1902180
[Epoch 52; Iter   141/  229] train: loss: 0.1535891
[Epoch 52; Iter   171/  229] train: loss: 0.1724107
[Epoch 52; Iter   201/  229] train: loss: 0.1518135
[Epoch 52] ogbg-moltoxcast: 0.693831 val loss: 0.254669
[Epoch 52] ogbg-moltoxcast: 0.665864 test loss: 0.307921
[Epoch 53; Iter     2/  229] train: loss: 0.0997288
[Epoch 53; Iter    32/  229] train: loss: 0.1228001
[Epoch 53; Iter    62/  229] train: loss: 0.1482532
[Epoch 53; Iter    92/  229] train: loss: 0.1810121
[Epoch 53; Iter   122/  229] train: loss: 0.0987774
[Epoch 53; Iter   152/  229] train: loss: 0.1239230
[Epoch 53; Iter   182/  229] train: loss: 0.1384839
[Epoch 53; Iter   212/  229] train: loss: 0.1269152
[Epoch 53] ogbg-moltoxcast: 0.703958 val loss: 0.252785
[Epoch 53] ogbg-moltoxcast: 0.668591 test loss: 0.307035
[Epoch 54; Iter    13/  229] train: loss: 0.0871103
[Epoch 54; Iter    43/  229] train: loss: 0.1643041
[Epoch 54; Iter    73/  229] train: loss: 0.1188603
[Epoch 54; Iter   103/  229] train: loss: 0.1450619
[Epoch 54; Iter   133/  229] train: loss: 0.1586923
[Epoch 54; Iter   163/  229] train: loss: 0.1787100
[Epoch 54; Iter   193/  229] train: loss: 0.1572791
[Epoch 54; Iter   223/  229] train: loss: 0.1827616
[Epoch 54] ogbg-moltoxcast: 0.700767 val loss: 0.252091
[Epoch 54] ogbg-moltoxcast: 0.675351 test loss: 0.309961
[Epoch 55; Iter    24/  229] train: loss: 0.1793937
[Epoch 55; Iter    54/  229] train: loss: 0.1892455
[Epoch 55; Iter    84/  229] train: loss: 0.1121193
[Epoch 55; Iter   114/  229] train: loss: 0.1992428
[Epoch 55; Iter   144/  229] train: loss: 0.1766348
[Epoch 55; Iter   174/  229] train: loss: 0.1710216
[Epoch 55; Iter   204/  229] train: loss: 0.1057604
[Epoch 55] ogbg-moltoxcast: 0.699349 val loss: 0.253260
[Epoch 55] ogbg-moltoxcast: 0.662835 test loss: 0.309124
[Epoch 56; Iter     5/  229] train: loss: 0.1260610
[Epoch 56; Iter    35/  229] train: loss: 0.1441931
[Epoch 56; Iter    65/  229] train: loss: 0.1292225
[Epoch 56; Iter    95/  229] train: loss: 0.1394640
[Epoch 56; Iter   125/  229] train: loss: 0.0978814
[Epoch 56; Iter   155/  229] train: loss: 0.1073519
[Epoch 56; Iter   185/  229] train: loss: 0.1444837
[Epoch 56; Iter   215/  229] train: loss: 0.1415189
[Epoch 56] ogbg-moltoxcast: 0.709785 val loss: 0.249834
[Epoch 56] ogbg-moltoxcast: 0.662099 test loss: 0.313367
[Epoch 57; Iter    16/  229] train: loss: 0.1060757
[Epoch 57; Iter    46/  229] train: loss: 0.1183152
[Epoch 57; Iter    76/  229] train: loss: 0.1899498
[Epoch 57; Iter   106/  229] train: loss: 0.1603939
[Epoch 57; Iter   136/  229] train: loss: 0.1375384
[Epoch 57; Iter   166/  229] train: loss: 0.1127108
[Epoch 57; Iter   196/  229] train: loss: 0.1671257
[Epoch 57; Iter   226/  229] train: loss: 0.1956039
[Epoch 57] ogbg-moltoxcast: 0.709224 val loss: 0.251696
[Epoch 57] ogbg-moltoxcast: 0.668171 test loss: 0.316320
[Epoch 58; Iter    27/  229] train: loss: 0.1208176
[Epoch 58; Iter    57/  229] train: loss: 0.1067629
[Epoch 58; Iter    87/  229] train: loss: 0.1279798
[Epoch 58; Iter   117/  229] train: loss: 0.1006484
[Epoch 58; Iter   147/  229] train: loss: 0.1381811
[Epoch 58; Iter   177/  229] train: loss: 0.1651250
[Epoch 58; Iter   207/  229] train: loss: 0.1117299
[Epoch 58] ogbg-moltoxcast: 0.698846 val loss: 0.249670
[Epoch 58] ogbg-moltoxcast: 0.661016 test loss: 0.312062
[Epoch 59; Iter     8/  229] train: loss: 0.1249564
[Epoch 59; Iter    38/  229] train: loss: 0.1350152
[Epoch 59; Iter    68/  229] train: loss: 0.1161533
[Epoch 59; Iter    98/  229] train: loss: 0.1755823
[Epoch 59; Iter   128/  229] train: loss: 0.1596832
[Epoch 59; Iter   158/  229] train: loss: 0.1197142
[Epoch 59; Iter   188/  229] train: loss: 0.1309542
[Epoch 59; Iter   218/  229] train: loss: 0.1140565
[Epoch 59] ogbg-moltoxcast: 0.703307 val loss: 0.252697
[Epoch 59] ogbg-moltoxcast: 0.672537 test loss: 0.313717
[Epoch 44; Iter    23/  229] train: loss: 0.1843886
[Epoch 44; Iter    53/  229] train: loss: 0.1059363
[Epoch 44; Iter    83/  229] train: loss: 0.1530440
[Epoch 44; Iter   113/  229] train: loss: 0.0952458
[Epoch 44; Iter   143/  229] train: loss: 0.1496808
[Epoch 44; Iter   173/  229] train: loss: 0.1277926
[Epoch 44; Iter   203/  229] train: loss: 0.1495623
[Epoch 44] ogbg-moltoxcast: 0.691792 val loss: 0.252056
[Epoch 44] ogbg-moltoxcast: 0.662090 test loss: 0.301775
[Epoch 45; Iter     4/  229] train: loss: 0.1187527
[Epoch 45; Iter    34/  229] train: loss: 0.1272575
[Epoch 45; Iter    64/  229] train: loss: 0.1670236
[Epoch 45; Iter    94/  229] train: loss: 0.1284234
[Epoch 45; Iter   124/  229] train: loss: 0.1470515
[Epoch 45; Iter   154/  229] train: loss: 0.1368459
[Epoch 45; Iter   184/  229] train: loss: 0.1564129
[Epoch 45; Iter   214/  229] train: loss: 0.1558041
[Epoch 45] ogbg-moltoxcast: 0.687911 val loss: 0.250168
[Epoch 45] ogbg-moltoxcast: 0.660808 test loss: 0.298532
[Epoch 46; Iter    15/  229] train: loss: 0.1333483
[Epoch 46; Iter    45/  229] train: loss: 0.1586552
[Epoch 46; Iter    75/  229] train: loss: 0.2113491
[Epoch 46; Iter   105/  229] train: loss: 0.1531540
[Epoch 46; Iter   135/  229] train: loss: 0.1446548
[Epoch 46; Iter   165/  229] train: loss: 0.1264178
[Epoch 46; Iter   195/  229] train: loss: 0.1506032
[Epoch 46; Iter   225/  229] train: loss: 0.1625613
[Epoch 46] ogbg-moltoxcast: 0.672418 val loss: 0.255427
[Epoch 46] ogbg-moltoxcast: 0.654533 test loss: 0.305447
[Epoch 47; Iter    26/  229] train: loss: 0.1545801
[Epoch 47; Iter    56/  229] train: loss: 0.1572247
[Epoch 47; Iter    86/  229] train: loss: 0.1347034
[Epoch 47; Iter   116/  229] train: loss: 0.0953220
[Epoch 47; Iter   146/  229] train: loss: 0.1204580
[Epoch 47; Iter   176/  229] train: loss: 0.1615346
[Epoch 47; Iter   206/  229] train: loss: 0.1404316
[Epoch 47] ogbg-moltoxcast: 0.681591 val loss: 0.253592
[Epoch 47] ogbg-moltoxcast: 0.656752 test loss: 0.302161
[Epoch 48; Iter     7/  229] train: loss: 0.1227152
[Epoch 48; Iter    37/  229] train: loss: 0.1246189
[Epoch 48; Iter    67/  229] train: loss: 0.1489461
[Epoch 48; Iter    97/  229] train: loss: 0.1698775
[Epoch 48; Iter   127/  229] train: loss: 0.1644041
[Epoch 48; Iter   157/  229] train: loss: 0.1141821
[Epoch 48; Iter   187/  229] train: loss: 0.1896807
[Epoch 48; Iter   217/  229] train: loss: 0.1438832
[Epoch 48] ogbg-moltoxcast: 0.680042 val loss: 0.262632
[Epoch 48] ogbg-moltoxcast: 0.650015 test loss: 0.311660
[Epoch 49; Iter    18/  229] train: loss: 0.1780891
[Epoch 49; Iter    48/  229] train: loss: 0.1202103
[Epoch 49; Iter    78/  229] train: loss: 0.1792873
[Epoch 49; Iter   108/  229] train: loss: 0.1336836
[Epoch 49; Iter   138/  229] train: loss: 0.1723468
[Epoch 49; Iter   168/  229] train: loss: 0.1212621
[Epoch 49; Iter   198/  229] train: loss: 0.1412496
[Epoch 49; Iter   228/  229] train: loss: 0.1346210
[Epoch 49] ogbg-moltoxcast: 0.686184 val loss: 0.255014
[Epoch 49] ogbg-moltoxcast: 0.656298 test loss: 0.302779
[Epoch 50; Iter    29/  229] train: loss: 0.1626970
[Epoch 50; Iter    59/  229] train: loss: 0.1366295
[Epoch 50; Iter    89/  229] train: loss: 0.1627083
[Epoch 50; Iter   119/  229] train: loss: 0.1253844
[Epoch 50; Iter   149/  229] train: loss: 0.1616828
[Epoch 50; Iter   179/  229] train: loss: 0.1733536
[Epoch 50; Iter   209/  229] train: loss: 0.2014156
[Epoch 50] ogbg-moltoxcast: 0.686191 val loss: 0.252009
[Epoch 50] ogbg-moltoxcast: 0.654238 test loss: 0.307982
[Epoch 51; Iter    10/  229] train: loss: 0.1688887
[Epoch 51; Iter    40/  229] train: loss: 0.0997753
[Epoch 51; Iter    70/  229] train: loss: 0.1632632
[Epoch 51; Iter   100/  229] train: loss: 0.1613082
[Epoch 51; Iter   130/  229] train: loss: 0.1228642
[Epoch 51; Iter   160/  229] train: loss: 0.1191549
[Epoch 51; Iter   190/  229] train: loss: 0.1095177
[Epoch 51; Iter   220/  229] train: loss: 0.1656498
[Epoch 51] ogbg-moltoxcast: 0.687699 val loss: 0.253751
[Epoch 51] ogbg-moltoxcast: 0.657674 test loss: 0.304314
[Epoch 52; Iter    21/  229] train: loss: 0.1486205
[Epoch 52; Iter    51/  229] train: loss: 0.1379902
[Epoch 52; Iter    81/  229] train: loss: 0.1560814
[Epoch 52; Iter   111/  229] train: loss: 0.1173953
[Epoch 52; Iter   141/  229] train: loss: 0.1301934
[Epoch 52; Iter   171/  229] train: loss: 0.0837205
[Epoch 52; Iter   201/  229] train: loss: 0.1227874
[Epoch 52] ogbg-moltoxcast: 0.677381 val loss: 0.255802
[Epoch 52] ogbg-moltoxcast: 0.648658 test loss: 0.309222
[Epoch 53; Iter     2/  229] train: loss: 0.1097873
[Epoch 53; Iter    32/  229] train: loss: 0.0924182
[Epoch 53; Iter    62/  229] train: loss: 0.1338834
[Epoch 53; Iter    92/  229] train: loss: 0.1144331
[Epoch 53; Iter   122/  229] train: loss: 0.1056914
[Epoch 53; Iter   152/  229] train: loss: 0.1561530
[Epoch 53; Iter   182/  229] train: loss: 0.1354111
[Epoch 53; Iter   212/  229] train: loss: 0.1574510
[Epoch 53] ogbg-moltoxcast: 0.686299 val loss: 0.259923
[Epoch 53] ogbg-moltoxcast: 0.657916 test loss: 0.306868
[Epoch 54; Iter    13/  229] train: loss: 0.0936452
[Epoch 54; Iter    43/  229] train: loss: 0.0978789
[Epoch 54; Iter    73/  229] train: loss: 0.1252038
[Epoch 54; Iter   103/  229] train: loss: 0.1048040
[Epoch 54; Iter   133/  229] train: loss: 0.1206400
[Epoch 54; Iter   163/  229] train: loss: 0.1254055
[Epoch 54; Iter   193/  229] train: loss: 0.1554903
[Epoch 54; Iter   223/  229] train: loss: 0.1745140
[Epoch 54] ogbg-moltoxcast: 0.679546 val loss: 0.257372
[Epoch 54] ogbg-moltoxcast: 0.655042 test loss: 0.310916
[Epoch 55; Iter    24/  229] train: loss: 0.1682225
[Epoch 55; Iter    54/  229] train: loss: 0.1674983
[Epoch 55; Iter    84/  229] train: loss: 0.1290281
[Epoch 55; Iter   114/  229] train: loss: 0.1374671
[Epoch 55; Iter   144/  229] train: loss: 0.1421679
[Epoch 55; Iter   174/  229] train: loss: 0.1449495
[Epoch 55; Iter   204/  229] train: loss: 0.1676448
[Epoch 55] ogbg-moltoxcast: 0.689100 val loss: 0.252916
[Epoch 55] ogbg-moltoxcast: 0.652911 test loss: 0.311609
[Epoch 56; Iter     5/  229] train: loss: 0.1467443
[Epoch 56; Iter    35/  229] train: loss: 0.1023606
[Epoch 56; Iter    65/  229] train: loss: 0.1843311
[Epoch 56; Iter    95/  229] train: loss: 0.1348189
[Epoch 56; Iter   125/  229] train: loss: 0.1481176
[Epoch 56; Iter   155/  229] train: loss: 0.1409911
[Epoch 56; Iter   185/  229] train: loss: 0.1568080
[Epoch 56; Iter   215/  229] train: loss: 0.1214026
[Epoch 56] ogbg-moltoxcast: 0.689324 val loss: 0.278739
[Epoch 56] ogbg-moltoxcast: 0.659759 test loss: 0.309943
[Epoch 57; Iter    16/  229] train: loss: 0.1948642
[Epoch 57; Iter    46/  229] train: loss: 0.1349595
[Epoch 57; Iter    76/  229] train: loss: 0.1097557
[Epoch 57; Iter   106/  229] train: loss: 0.1570770
[Epoch 57; Iter   136/  229] train: loss: 0.1194018
[Epoch 57; Iter   166/  229] train: loss: 0.1009194
[Epoch 57; Iter   196/  229] train: loss: 0.1350736
[Epoch 57; Iter   226/  229] train: loss: 0.2185119
[Epoch 57] ogbg-moltoxcast: 0.686353 val loss: 0.255892
[Epoch 57] ogbg-moltoxcast: 0.655213 test loss: 0.312202
[Epoch 58; Iter    27/  229] train: loss: 0.1437173
[Epoch 58; Iter    57/  229] train: loss: 0.1589039
[Epoch 58; Iter    87/  229] train: loss: 0.1420552
[Epoch 58; Iter   117/  229] train: loss: 0.1437139
[Epoch 58; Iter   147/  229] train: loss: 0.2036111
[Epoch 58; Iter   177/  229] train: loss: 0.1999174
[Epoch 58; Iter   207/  229] train: loss: 0.1255480
[Epoch 58] ogbg-moltoxcast: 0.686098 val loss: 0.254165
[Epoch 58] ogbg-moltoxcast: 0.659209 test loss: 0.305029
[Epoch 59; Iter     8/  229] train: loss: 0.1361603
[Epoch 59; Iter    38/  229] train: loss: 0.1215909
[Epoch 59; Iter    68/  229] train: loss: 0.1277279
[Epoch 59; Iter    98/  229] train: loss: 0.1145828
[Epoch 59; Iter   128/  229] train: loss: 0.1230592
[Epoch 59; Iter   158/  229] train: loss: 0.1355696
[Epoch 59; Iter   188/  229] train: loss: 0.1268574
[Epoch 59; Iter   218/  229] train: loss: 0.1285722
[Epoch 59] ogbg-moltoxcast: 0.686859 val loss: 0.254872
[Epoch 59] ogbg-moltoxcast: 0.655724 test loss: 0.304923
[Epoch 44; Iter    23/  229] train: loss: 0.1172390
[Epoch 44; Iter    53/  229] train: loss: 0.1249169
[Epoch 44; Iter    83/  229] train: loss: 0.1368655
[Epoch 44; Iter   113/  229] train: loss: 0.1289664
[Epoch 44; Iter   143/  229] train: loss: 0.1443797
[Epoch 44; Iter   173/  229] train: loss: 0.1368084
[Epoch 44; Iter   203/  229] train: loss: 0.0897362
[Epoch 44] ogbg-moltoxcast: 0.695429 val loss: 0.342072
[Epoch 44] ogbg-moltoxcast: 0.664870 test loss: 0.309730
[Epoch 45; Iter     4/  229] train: loss: 0.1238546
[Epoch 45; Iter    34/  229] train: loss: 0.1602061
[Epoch 45; Iter    64/  229] train: loss: 0.1130783
[Epoch 45; Iter    94/  229] train: loss: 0.1715284
[Epoch 45; Iter   124/  229] train: loss: 0.2088538
[Epoch 45; Iter   154/  229] train: loss: 0.1444549
[Epoch 45; Iter   184/  229] train: loss: 0.1894329
[Epoch 45; Iter   214/  229] train: loss: 0.1442901
[Epoch 45] ogbg-moltoxcast: 0.692277 val loss: 0.254996
[Epoch 45] ogbg-moltoxcast: 0.655980 test loss: 0.308811
[Epoch 46; Iter    15/  229] train: loss: 0.1676051
[Epoch 46; Iter    45/  229] train: loss: 0.1738595
[Epoch 46; Iter    75/  229] train: loss: 0.2090591
[Epoch 46; Iter   105/  229] train: loss: 0.1243359
[Epoch 46; Iter   135/  229] train: loss: 0.1484008
[Epoch 46; Iter   165/  229] train: loss: 0.1161755
[Epoch 46; Iter   195/  229] train: loss: 0.1700980
[Epoch 46; Iter   225/  229] train: loss: 0.1177886
[Epoch 46] ogbg-moltoxcast: 0.686506 val loss: 0.454488
[Epoch 46] ogbg-moltoxcast: 0.659575 test loss: 0.306130
[Epoch 47; Iter    26/  229] train: loss: 0.1391372
[Epoch 47; Iter    56/  229] train: loss: 0.1543858
[Epoch 47; Iter    86/  229] train: loss: 0.1254813
[Epoch 47; Iter   116/  229] train: loss: 0.1549128
[Epoch 47; Iter   146/  229] train: loss: 0.1198560
[Epoch 47; Iter   176/  229] train: loss: 0.1436119
[Epoch 47; Iter   206/  229] train: loss: 0.1610626
[Epoch 47] ogbg-moltoxcast: 0.692915 val loss: 0.264290
[Epoch 47] ogbg-moltoxcast: 0.658782 test loss: 0.310696
[Epoch 48; Iter     7/  229] train: loss: 0.1789989
[Epoch 48; Iter    37/  229] train: loss: 0.1201017
[Epoch 48; Iter    67/  229] train: loss: 0.1843355
[Epoch 48; Iter    97/  229] train: loss: 0.1539391
[Epoch 48; Iter   127/  229] train: loss: 0.2083441
[Epoch 48; Iter   157/  229] train: loss: 0.1668931
[Epoch 48; Iter   187/  229] train: loss: 0.1573689
[Epoch 48; Iter   217/  229] train: loss: 0.1045992
[Epoch 48] ogbg-moltoxcast: 0.698117 val loss: 0.257069
[Epoch 48] ogbg-moltoxcast: 0.664854 test loss: 0.307197
[Epoch 49; Iter    18/  229] train: loss: 0.1436864
[Epoch 49; Iter    48/  229] train: loss: 0.1396096
[Epoch 49; Iter    78/  229] train: loss: 0.1075851
[Epoch 49; Iter   108/  229] train: loss: 0.2781485
[Epoch 49; Iter   138/  229] train: loss: 0.1440219
[Epoch 49; Iter   168/  229] train: loss: 0.1209903
[Epoch 49; Iter   198/  229] train: loss: 0.1692223
[Epoch 49; Iter   228/  229] train: loss: 0.1152378
[Epoch 49] ogbg-moltoxcast: 0.688466 val loss: 0.257908
[Epoch 49] ogbg-moltoxcast: 0.661031 test loss: 0.304687
[Epoch 50; Iter    29/  229] train: loss: 0.1325211
[Epoch 50; Iter    59/  229] train: loss: 0.1146823
[Epoch 50; Iter    89/  229] train: loss: 0.1063446
[Epoch 50; Iter   119/  229] train: loss: 0.1421195
[Epoch 50; Iter   149/  229] train: loss: 0.1089769
[Epoch 50; Iter   179/  229] train: loss: 0.1840346
[Epoch 50; Iter   209/  229] train: loss: 0.1307913
[Epoch 50] ogbg-moltoxcast: 0.693463 val loss: 0.289928
[Epoch 50] ogbg-moltoxcast: 0.656119 test loss: 0.309848
[Epoch 51; Iter    10/  229] train: loss: 0.1137224
[Epoch 51; Iter    40/  229] train: loss: 0.1386868
[Epoch 51; Iter    70/  229] train: loss: 0.1370265
[Epoch 51; Iter   100/  229] train: loss: 0.1360188
[Epoch 51; Iter   130/  229] train: loss: 0.1244949
[Epoch 51; Iter   160/  229] train: loss: 0.1352906
[Epoch 51; Iter   190/  229] train: loss: 0.1414012
[Epoch 51; Iter   220/  229] train: loss: 0.0846061
[Epoch 51] ogbg-moltoxcast: 0.697923 val loss: 0.266052
[Epoch 51] ogbg-moltoxcast: 0.663778 test loss: 0.313447
[Epoch 52; Iter    21/  229] train: loss: 0.1935452
[Epoch 52; Iter    51/  229] train: loss: 0.1562120
[Epoch 52; Iter    81/  229] train: loss: 0.1661614
[Epoch 52; Iter   111/  229] train: loss: 0.1306046
[Epoch 52; Iter   141/  229] train: loss: 0.1152466
[Epoch 52; Iter   171/  229] train: loss: 0.1673645
[Epoch 52; Iter   201/  229] train: loss: 0.1506793
[Epoch 52] ogbg-moltoxcast: 0.689289 val loss: 0.288155
[Epoch 52] ogbg-moltoxcast: 0.660807 test loss: 0.307696
[Epoch 53; Iter     2/  229] train: loss: 0.1279434
[Epoch 53; Iter    32/  229] train: loss: 0.1409747
[Epoch 53; Iter    62/  229] train: loss: 0.1524652
[Epoch 53; Iter    92/  229] train: loss: 0.1250079
[Epoch 53; Iter   122/  229] train: loss: 0.1628552
[Epoch 53; Iter   152/  229] train: loss: 0.1563886
[Epoch 53; Iter   182/  229] train: loss: 0.1496038
[Epoch 53; Iter   212/  229] train: loss: 0.1644041
[Epoch 53] ogbg-moltoxcast: 0.694525 val loss: 0.434415
[Epoch 53] ogbg-moltoxcast: 0.662637 test loss: 0.311826
[Epoch 54; Iter    13/  229] train: loss: 0.0852600
[Epoch 54; Iter    43/  229] train: loss: 0.1501544
[Epoch 54; Iter    73/  229] train: loss: 0.1084939
[Epoch 54; Iter   103/  229] train: loss: 0.1627064
[Epoch 54; Iter   133/  229] train: loss: 0.1851071
[Epoch 54; Iter   163/  229] train: loss: 0.1679776
[Epoch 54; Iter   193/  229] train: loss: 0.1994695
[Epoch 54; Iter   223/  229] train: loss: 0.1836877
[Epoch 54] ogbg-moltoxcast: 0.698068 val loss: 0.402663
[Epoch 54] ogbg-moltoxcast: 0.660303 test loss: 0.322528
[Epoch 55; Iter    24/  229] train: loss: 0.1241839
[Epoch 55; Iter    54/  229] train: loss: 0.1922415
[Epoch 55; Iter    84/  229] train: loss: 0.1377667
[Epoch 55; Iter   114/  229] train: loss: 0.1288301
[Epoch 55; Iter   144/  229] train: loss: 0.1216775
[Epoch 55; Iter   174/  229] train: loss: 0.1492995
[Epoch 55; Iter   204/  229] train: loss: 0.0913945
[Epoch 55] ogbg-moltoxcast: 0.690011 val loss: 0.285902
[Epoch 55] ogbg-moltoxcast: 0.661516 test loss: 0.321661
[Epoch 56; Iter     5/  229] train: loss: 0.1335356
[Epoch 56; Iter    35/  229] train: loss: 0.1314545
[Epoch 56; Iter    65/  229] train: loss: 0.1164966
[Epoch 56; Iter    95/  229] train: loss: 0.1152133
[Epoch 56; Iter   125/  229] train: loss: 0.1569395
[Epoch 56; Iter   155/  229] train: loss: 0.1393903
[Epoch 56; Iter   185/  229] train: loss: 0.1515275
[Epoch 56; Iter   215/  229] train: loss: 0.1458388
[Epoch 56] ogbg-moltoxcast: 0.679800 val loss: 0.389972
[Epoch 56] ogbg-moltoxcast: 0.651184 test loss: 0.320765
[Epoch 57; Iter    16/  229] train: loss: 0.1460956
[Epoch 57; Iter    46/  229] train: loss: 0.1300469
[Epoch 57; Iter    76/  229] train: loss: 0.1758826
[Epoch 57; Iter   106/  229] train: loss: 0.1061948
[Epoch 57; Iter   136/  229] train: loss: 0.1264298
[Epoch 57; Iter   166/  229] train: loss: 0.1313542
[Epoch 57; Iter   196/  229] train: loss: 0.1548224
[Epoch 57; Iter   226/  229] train: loss: 0.1554240
[Epoch 57] ogbg-moltoxcast: 0.698818 val loss: 0.327616
[Epoch 57] ogbg-moltoxcast: 0.656611 test loss: 0.315362
[Epoch 58; Iter    27/  229] train: loss: 0.1566981
[Epoch 58; Iter    57/  229] train: loss: 0.1521786
[Epoch 58; Iter    87/  229] train: loss: 0.1188799
[Epoch 58; Iter   117/  229] train: loss: 0.1081086
[Epoch 58; Iter   147/  229] train: loss: 0.1477635
[Epoch 58; Iter   177/  229] train: loss: 0.2050346
[Epoch 58; Iter   207/  229] train: loss: 0.1535331
[Epoch 58] ogbg-moltoxcast: 0.691600 val loss: 0.284354
[Epoch 58] ogbg-moltoxcast: 0.655306 test loss: 0.443723
[Epoch 59; Iter     8/  229] train: loss: 0.1140421
[Epoch 59; Iter    38/  229] train: loss: 0.1512967
[Epoch 59; Iter    68/  229] train: loss: 0.1013312
[Epoch 59; Iter    98/  229] train: loss: 0.1406204
[Epoch 59; Iter   128/  229] train: loss: 0.1631190
[Epoch 59; Iter   158/  229] train: loss: 0.1452794
[Epoch 59; Iter   188/  229] train: loss: 0.1141500
[Epoch 59; Iter   218/  229] train: loss: 0.1650154
[Epoch 59] ogbg-moltoxcast: 0.699854 val loss: 0.297188
[Epoch 59] ogbg-moltoxcast: 0.665285 test loss: 0.350583
[Epoch 48; Iter   183/  201] train: loss: 0.1354668
[Epoch 48] ogbg-moltoxcast: 0.682019 val loss: 0.265582
[Epoch 48] ogbg-moltoxcast: 0.665718 test loss: 0.302778
[Epoch 49; Iter    12/  201] train: loss: 0.1805226
[Epoch 49; Iter    42/  201] train: loss: 0.1066310
[Epoch 49; Iter    72/  201] train: loss: 0.2798155
[Epoch 49; Iter   102/  201] train: loss: 0.1177101
[Epoch 49; Iter   132/  201] train: loss: 0.1382042
[Epoch 49; Iter   162/  201] train: loss: 0.1177274
[Epoch 49; Iter   192/  201] train: loss: 0.1091941
[Epoch 49] ogbg-moltoxcast: 0.678312 val loss: 0.264416
[Epoch 49] ogbg-moltoxcast: 0.662340 test loss: 0.302758
[Epoch 50; Iter    21/  201] train: loss: 0.1258887
[Epoch 50; Iter    51/  201] train: loss: 0.1626764
[Epoch 50; Iter    81/  201] train: loss: 0.1207889
[Epoch 50; Iter   111/  201] train: loss: 0.1041753
[Epoch 50; Iter   141/  201] train: loss: 0.1002741
[Epoch 50; Iter   171/  201] train: loss: 0.1644851
[Epoch 50; Iter   201/  201] train: loss: 0.1719252
[Epoch 50] ogbg-moltoxcast: 0.683684 val loss: 0.264552
[Epoch 50] ogbg-moltoxcast: 0.664113 test loss: 0.304214
[Epoch 51; Iter    30/  201] train: loss: 0.2376637
[Epoch 51; Iter    60/  201] train: loss: 0.1340244
[Epoch 51; Iter    90/  201] train: loss: 0.1457932
[Epoch 51; Iter   120/  201] train: loss: 0.1160933
[Epoch 51; Iter   150/  201] train: loss: 0.1341688
[Epoch 51; Iter   180/  201] train: loss: 0.1701870
[Epoch 51] ogbg-moltoxcast: 0.683674 val loss: 0.264579
[Epoch 51] ogbg-moltoxcast: 0.662271 test loss: 0.305593
[Epoch 52; Iter     9/  201] train: loss: 0.1107154
[Epoch 52; Iter    39/  201] train: loss: 0.1106396
[Epoch 52; Iter    69/  201] train: loss: 0.1122109
[Epoch 52; Iter    99/  201] train: loss: 0.1142689
[Epoch 52; Iter   129/  201] train: loss: 0.1539195
[Epoch 52; Iter   159/  201] train: loss: 0.1071011
[Epoch 52; Iter   189/  201] train: loss: 0.1411963
[Epoch 52] ogbg-moltoxcast: 0.685860 val loss: 0.265626
[Epoch 52] ogbg-moltoxcast: 0.670293 test loss: 0.301021
[Epoch 53; Iter    18/  201] train: loss: 0.1541486
[Epoch 53; Iter    48/  201] train: loss: 0.1200693
[Epoch 53; Iter    78/  201] train: loss: 0.1750467
[Epoch 53; Iter   108/  201] train: loss: 0.1553298
[Epoch 53; Iter   138/  201] train: loss: 0.0910056
[Epoch 53; Iter   168/  201] train: loss: 0.1838575
[Epoch 53; Iter   198/  201] train: loss: 0.1063891
[Epoch 53] ogbg-moltoxcast: 0.688882 val loss: 0.269148
[Epoch 53] ogbg-moltoxcast: 0.664843 test loss: 0.313129
[Epoch 54; Iter    27/  201] train: loss: 0.1247130
[Epoch 54; Iter    57/  201] train: loss: 0.1788066
[Epoch 54; Iter    87/  201] train: loss: 0.1312232
[Epoch 54; Iter   117/  201] train: loss: 0.2029143
[Epoch 54; Iter   147/  201] train: loss: 0.1611508
[Epoch 54; Iter   177/  201] train: loss: 0.1074105
[Epoch 54] ogbg-moltoxcast: 0.679614 val loss: 0.265491
[Epoch 54] ogbg-moltoxcast: 0.660199 test loss: 0.302215
[Epoch 55; Iter     6/  201] train: loss: 0.1374105
[Epoch 55; Iter    36/  201] train: loss: 0.1493767
[Epoch 55; Iter    66/  201] train: loss: 0.1049801
[Epoch 55; Iter    96/  201] train: loss: 0.1207818
[Epoch 55; Iter   126/  201] train: loss: 0.1229734
[Epoch 55; Iter   156/  201] train: loss: 0.1024884
[Epoch 55; Iter   186/  201] train: loss: 0.1415240
[Epoch 55] ogbg-moltoxcast: 0.680582 val loss: 0.274399
[Epoch 55] ogbg-moltoxcast: 0.662009 test loss: 0.310904
[Epoch 56; Iter    15/  201] train: loss: 0.1658649
[Epoch 56; Iter    45/  201] train: loss: 0.1476893
[Epoch 56; Iter    75/  201] train: loss: 0.1505339
[Epoch 56; Iter   105/  201] train: loss: 0.1260777
[Epoch 56; Iter   135/  201] train: loss: 0.1246505
[Epoch 56; Iter   165/  201] train: loss: 0.1212181
[Epoch 56; Iter   195/  201] train: loss: 0.1372158
[Epoch 56] ogbg-moltoxcast: 0.677252 val loss: 0.279203
[Epoch 56] ogbg-moltoxcast: 0.666676 test loss: 0.316844
[Epoch 57; Iter    24/  201] train: loss: 0.1451828
[Epoch 57; Iter    54/  201] train: loss: 0.1609995
[Epoch 57; Iter    84/  201] train: loss: 0.1335457
[Epoch 57; Iter   114/  201] train: loss: 0.1215172
[Epoch 57; Iter   144/  201] train: loss: 0.1228061
[Epoch 57; Iter   174/  201] train: loss: 0.0938280
[Epoch 57] ogbg-moltoxcast: 0.686882 val loss: 0.266437
[Epoch 57] ogbg-moltoxcast: 0.667025 test loss: 0.303241
[Epoch 58; Iter     3/  201] train: loss: 0.1484942
[Epoch 58; Iter    33/  201] train: loss: 0.1255240
[Epoch 58; Iter    63/  201] train: loss: 0.1040827
[Epoch 58; Iter    93/  201] train: loss: 0.1635246
[Epoch 58; Iter   123/  201] train: loss: 0.1115031
[Epoch 58; Iter   153/  201] train: loss: 0.0934329
[Epoch 58; Iter   183/  201] train: loss: 0.2002096
[Epoch 58] ogbg-moltoxcast: 0.687704 val loss: 0.273410
[Epoch 58] ogbg-moltoxcast: 0.663996 test loss: 0.313224
[Epoch 59; Iter    12/  201] train: loss: 0.1328854
[Epoch 59; Iter    42/  201] train: loss: 0.1136574
[Epoch 59; Iter    72/  201] train: loss: 0.1903544
[Epoch 59; Iter   102/  201] train: loss: 0.1271002
[Epoch 59; Iter   132/  201] train: loss: 0.1407383
[Epoch 59; Iter   162/  201] train: loss: 0.1334593
[Epoch 59; Iter   192/  201] train: loss: 0.1315128
[Epoch 59] ogbg-moltoxcast: 0.684731 val loss: 0.276677
[Epoch 59] ogbg-moltoxcast: 0.667476 test loss: 0.312220
[Epoch 60; Iter    21/  201] train: loss: 0.1710823
[Epoch 60; Iter    51/  201] train: loss: 0.1120025
[Epoch 60; Iter    81/  201] train: loss: 0.1169834
[Epoch 60; Iter   111/  201] train: loss: 0.1531983
[Epoch 60; Iter   141/  201] train: loss: 0.1238352
[Epoch 60; Iter   171/  201] train: loss: 0.1427244
[Epoch 60; Iter   201/  201] train: loss: 0.0499407
[Epoch 60] ogbg-moltoxcast: 0.680642 val loss: 0.276124
[Epoch 60] ogbg-moltoxcast: 0.666277 test loss: 0.314187
[Epoch 61; Iter    30/  201] train: loss: 0.1143816
[Epoch 61; Iter    60/  201] train: loss: 0.1035884
[Epoch 61; Iter    90/  201] train: loss: 0.0972747
[Epoch 61; Iter   120/  201] train: loss: 0.1334800
[Epoch 61; Iter   150/  201] train: loss: 0.1021903
[Epoch 61; Iter   180/  201] train: loss: 0.1434877
[Epoch 61] ogbg-moltoxcast: 0.684834 val loss: 0.266733
[Epoch 61] ogbg-moltoxcast: 0.668425 test loss: 0.304839
[Epoch 62; Iter     9/  201] train: loss: 0.1009509
[Epoch 62; Iter    39/  201] train: loss: 0.1403639
[Epoch 62; Iter    69/  201] train: loss: 0.1096489
[Epoch 62; Iter    99/  201] train: loss: 0.1609974
[Epoch 62; Iter   129/  201] train: loss: 0.1313888
[Epoch 62; Iter   159/  201] train: loss: 0.1382073
[Epoch 62; Iter   189/  201] train: loss: 0.1140462
[Epoch 62] ogbg-moltoxcast: 0.684981 val loss: 0.266535
[Epoch 62] ogbg-moltoxcast: 0.667116 test loss: 0.306279
[Epoch 63; Iter    18/  201] train: loss: 0.1338085
[Epoch 63; Iter    48/  201] train: loss: 0.1373998
[Epoch 63; Iter    78/  201] train: loss: 0.1119765
[Epoch 63; Iter   108/  201] train: loss: 0.1174896
[Epoch 63; Iter   138/  201] train: loss: 0.1332467
[Epoch 63; Iter   168/  201] train: loss: 0.0961005
[Epoch 63; Iter   198/  201] train: loss: 0.1187451
[Epoch 63] ogbg-moltoxcast: 0.683441 val loss: 0.269427
[Epoch 63] ogbg-moltoxcast: 0.664173 test loss: 0.308708
[Epoch 64; Iter    27/  201] train: loss: 0.1309556
[Epoch 64; Iter    57/  201] train: loss: 0.1445463
[Epoch 64; Iter    87/  201] train: loss: 0.1096058
[Epoch 64; Iter   117/  201] train: loss: 0.1466843
[Epoch 64; Iter   147/  201] train: loss: 0.1369379
[Epoch 64; Iter   177/  201] train: loss: 0.1219512
[Epoch 64] ogbg-moltoxcast: 0.682285 val loss: 0.269195
[Epoch 64] ogbg-moltoxcast: 0.664614 test loss: 0.308088
[Epoch 65; Iter     6/  201] train: loss: 0.1173319
[Epoch 65; Iter    36/  201] train: loss: 0.1320911
[Epoch 65; Iter    66/  201] train: loss: 0.1371826
[Epoch 65; Iter    96/  201] train: loss: 0.1384249
[Epoch 65; Iter   126/  201] train: loss: 0.1103001
[Epoch 65; Iter   156/  201] train: loss: 0.1154822
[Epoch 65; Iter   186/  201] train: loss: 0.1282876
[Epoch 65] ogbg-moltoxcast: 0.681885 val loss: 0.269225
[Epoch 65] ogbg-moltoxcast: 0.661032 test loss: 0.310354
[Epoch 66; Iter    15/  201] train: loss: 0.1361681
[Epoch 66; Iter    45/  201] train: loss: 0.1519651
[Epoch 66; Iter    75/  201] train: loss: 0.1369888
[Epoch 48; Iter   183/  201] train: loss: 0.1148448
[Epoch 48] ogbg-moltoxcast: 0.670254 val loss: 0.275928
[Epoch 48] ogbg-moltoxcast: 0.662195 test loss: 0.318101
[Epoch 49; Iter    12/  201] train: loss: 0.1157674
[Epoch 49; Iter    42/  201] train: loss: 0.0985065
[Epoch 49; Iter    72/  201] train: loss: 0.1363226
[Epoch 49; Iter   102/  201] train: loss: 0.1347028
[Epoch 49; Iter   132/  201] train: loss: 0.1337234
[Epoch 49; Iter   162/  201] train: loss: 0.1246954
[Epoch 49; Iter   192/  201] train: loss: 0.1208492
[Epoch 49] ogbg-moltoxcast: 0.661623 val loss: 0.276085
[Epoch 49] ogbg-moltoxcast: 0.651033 test loss: 0.317333
[Epoch 50; Iter    21/  201] train: loss: 0.1709235
[Epoch 50; Iter    51/  201] train: loss: 0.1506776
[Epoch 50; Iter    81/  201] train: loss: 0.1239736
[Epoch 50; Iter   111/  201] train: loss: 0.1256908
[Epoch 50; Iter   141/  201] train: loss: 0.0815605
[Epoch 50; Iter   171/  201] train: loss: 0.1573721
[Epoch 50; Iter   201/  201] train: loss: 0.1351042
[Epoch 50] ogbg-moltoxcast: 0.667832 val loss: 0.354127
[Epoch 50] ogbg-moltoxcast: 0.651820 test loss: 0.549112
[Epoch 51; Iter    30/  201] train: loss: 0.1421144
[Epoch 51; Iter    60/  201] train: loss: 0.1774232
[Epoch 51; Iter    90/  201] train: loss: 0.1713029
[Epoch 51; Iter   120/  201] train: loss: 0.1617192
[Epoch 51; Iter   150/  201] train: loss: 0.1450196
[Epoch 51; Iter   180/  201] train: loss: 0.1002028
[Epoch 51] ogbg-moltoxcast: 0.669636 val loss: 0.274345
[Epoch 51] ogbg-moltoxcast: 0.661489 test loss: 0.316360
[Epoch 52; Iter     9/  201] train: loss: 0.1071533
[Epoch 52; Iter    39/  201] train: loss: 0.1458618
[Epoch 52; Iter    69/  201] train: loss: 0.1547690
[Epoch 52; Iter    99/  201] train: loss: 0.0986092
[Epoch 52; Iter   129/  201] train: loss: 0.1771133
[Epoch 52; Iter   159/  201] train: loss: 0.1552982
[Epoch 52; Iter   189/  201] train: loss: 0.1439797
[Epoch 52] ogbg-moltoxcast: 0.671369 val loss: 0.270953
[Epoch 52] ogbg-moltoxcast: 0.667447 test loss: 0.303039
[Epoch 53; Iter    18/  201] train: loss: 0.1145756
[Epoch 53; Iter    48/  201] train: loss: 0.1431642
[Epoch 53; Iter    78/  201] train: loss: 0.2098883
[Epoch 53; Iter   108/  201] train: loss: 0.1396702
[Epoch 53; Iter   138/  201] train: loss: 0.1812796
[Epoch 53; Iter   168/  201] train: loss: 0.1540259
[Epoch 53; Iter   198/  201] train: loss: 0.1498933
[Epoch 53] ogbg-moltoxcast: 0.673837 val loss: 0.265664
[Epoch 53] ogbg-moltoxcast: 0.662933 test loss: 0.307978
[Epoch 54; Iter    27/  201] train: loss: 0.1180340
[Epoch 54; Iter    57/  201] train: loss: 0.1257072
[Epoch 54; Iter    87/  201] train: loss: 0.1980290
[Epoch 54; Iter   117/  201] train: loss: 0.1619603
[Epoch 54; Iter   147/  201] train: loss: 0.0837409
[Epoch 54; Iter   177/  201] train: loss: 0.1378330
[Epoch 54] ogbg-moltoxcast: 0.673978 val loss: 0.278118
[Epoch 54] ogbg-moltoxcast: 0.660552 test loss: 0.333622
[Epoch 55; Iter     6/  201] train: loss: 0.1279632
[Epoch 55; Iter    36/  201] train: loss: 0.1693689
[Epoch 55; Iter    66/  201] train: loss: 0.1764457
[Epoch 55; Iter    96/  201] train: loss: 0.0827238
[Epoch 55; Iter   126/  201] train: loss: 0.1873846
[Epoch 55; Iter   156/  201] train: loss: 0.1820165
[Epoch 55; Iter   186/  201] train: loss: 0.1849723
[Epoch 55] ogbg-moltoxcast: 0.659658 val loss: 0.284981
[Epoch 55] ogbg-moltoxcast: 0.648541 test loss: 0.343260
[Epoch 56; Iter    15/  201] train: loss: 0.1351663
[Epoch 56; Iter    45/  201] train: loss: 0.1227881
[Epoch 56; Iter    75/  201] train: loss: 0.1686536
[Epoch 56; Iter   105/  201] train: loss: 0.1187902
[Epoch 56; Iter   135/  201] train: loss: 0.1259520
[Epoch 56; Iter   165/  201] train: loss: 0.1183413
[Epoch 56; Iter   195/  201] train: loss: 0.1757767
[Epoch 56] ogbg-moltoxcast: 0.676572 val loss: 0.311801
[Epoch 56] ogbg-moltoxcast: 0.669014 test loss: 0.492460
[Epoch 57; Iter    24/  201] train: loss: 0.1299515
[Epoch 57; Iter    54/  201] train: loss: 0.1076560
[Epoch 57; Iter    84/  201] train: loss: 0.1243002
[Epoch 57; Iter   114/  201] train: loss: 0.1025468
[Epoch 57; Iter   144/  201] train: loss: 0.0970701
[Epoch 57; Iter   174/  201] train: loss: 0.2044364
[Epoch 57] ogbg-moltoxcast: 0.671655 val loss: 0.264360
[Epoch 57] ogbg-moltoxcast: 0.656699 test loss: 0.314454
[Epoch 58; Iter     3/  201] train: loss: 0.1383075
[Epoch 58; Iter    33/  201] train: loss: 0.1320057
[Epoch 58; Iter    63/  201] train: loss: 0.1258105
[Epoch 58; Iter    93/  201] train: loss: 0.1962137
[Epoch 58; Iter   123/  201] train: loss: 0.1376226
[Epoch 58; Iter   153/  201] train: loss: 0.1269733
[Epoch 58; Iter   183/  201] train: loss: 0.1662655
[Epoch 58] ogbg-moltoxcast: 0.667272 val loss: 0.270940
[Epoch 58] ogbg-moltoxcast: 0.658586 test loss: 0.335598
[Epoch 59; Iter    12/  201] train: loss: 0.1198159
[Epoch 59; Iter    42/  201] train: loss: 0.1209684
[Epoch 59; Iter    72/  201] train: loss: 0.1148781
[Epoch 59; Iter   102/  201] train: loss: 0.1888785
[Epoch 59; Iter   132/  201] train: loss: 0.1448030
[Epoch 59; Iter   162/  201] train: loss: 0.1085695
[Epoch 59; Iter   192/  201] train: loss: 0.1197580
[Epoch 59] ogbg-moltoxcast: 0.667732 val loss: 0.268053
[Epoch 59] ogbg-moltoxcast: 0.661096 test loss: 0.301436
[Epoch 60; Iter    21/  201] train: loss: 0.1433642
[Epoch 60; Iter    51/  201] train: loss: 0.1555955
[Epoch 60; Iter    81/  201] train: loss: 0.1348977
[Epoch 60; Iter   111/  201] train: loss: 0.0883898
[Epoch 60; Iter   141/  201] train: loss: 0.1128024
[Epoch 60; Iter   171/  201] train: loss: 0.1582119
[Epoch 60; Iter   201/  201] train: loss: 0.8885165
[Epoch 60] ogbg-moltoxcast: 0.667766 val loss: 0.274876
[Epoch 60] ogbg-moltoxcast: 0.660894 test loss: 0.311309
[Epoch 61; Iter    30/  201] train: loss: 0.1710559
[Epoch 61; Iter    60/  201] train: loss: 0.1309628
[Epoch 61; Iter    90/  201] train: loss: 0.1417409
[Epoch 61; Iter   120/  201] train: loss: 0.1260380
[Epoch 61; Iter   150/  201] train: loss: 0.1554988
[Epoch 61; Iter   180/  201] train: loss: 0.1166093
[Epoch 61] ogbg-moltoxcast: 0.669188 val loss: 0.289037
[Epoch 61] ogbg-moltoxcast: 0.660289 test loss: 0.411404
[Epoch 62; Iter     9/  201] train: loss: 0.1255523
[Epoch 62; Iter    39/  201] train: loss: 0.1077546
[Epoch 62; Iter    69/  201] train: loss: 0.1347895
[Epoch 62; Iter    99/  201] train: loss: 0.1387172
[Epoch 62; Iter   129/  201] train: loss: 0.1754119
[Epoch 62; Iter   159/  201] train: loss: 0.1440283
[Epoch 62; Iter   189/  201] train: loss: 0.1256276
[Epoch 62] ogbg-moltoxcast: 0.673063 val loss: 0.271627
[Epoch 62] ogbg-moltoxcast: 0.662731 test loss: 0.382474
[Epoch 63; Iter    18/  201] train: loss: 0.0894967
[Epoch 63; Iter    48/  201] train: loss: 0.1291853
[Epoch 63; Iter    78/  201] train: loss: 0.1056341
[Epoch 63; Iter   108/  201] train: loss: 0.1590903
[Epoch 63; Iter   138/  201] train: loss: 0.1135518
[Epoch 63; Iter   168/  201] train: loss: 0.1287396
[Epoch 63; Iter   198/  201] train: loss: 0.1411601
[Epoch 63] ogbg-moltoxcast: 0.675174 val loss: 0.265179
[Epoch 63] ogbg-moltoxcast: 0.661372 test loss: 0.309445
[Epoch 64; Iter    27/  201] train: loss: 0.1342697
[Epoch 64; Iter    57/  201] train: loss: 0.1368189
[Epoch 64; Iter    87/  201] train: loss: 0.0914672
[Epoch 64; Iter   117/  201] train: loss: 0.0926467
[Epoch 64; Iter   147/  201] train: loss: 0.1428579
[Epoch 64; Iter   177/  201] train: loss: 0.1803864
[Epoch 64] ogbg-moltoxcast: 0.672524 val loss: 0.273606
[Epoch 64] ogbg-moltoxcast: 0.657274 test loss: 0.325700
[Epoch 65; Iter     6/  201] train: loss: 0.1030236
[Epoch 65; Iter    36/  201] train: loss: 0.1611693
[Epoch 65; Iter    66/  201] train: loss: 0.1586396
[Epoch 65; Iter    96/  201] train: loss: 0.1492573
[Epoch 65; Iter   126/  201] train: loss: 0.1051149
[Epoch 65; Iter   156/  201] train: loss: 0.1400468
[Epoch 65; Iter   186/  201] train: loss: 0.0985547
[Epoch 65] ogbg-moltoxcast: 0.670697 val loss: 0.276043
[Epoch 65] ogbg-moltoxcast: 0.653609 test loss: 0.377717
[Epoch 66; Iter    15/  201] train: loss: 0.1683456
[Epoch 66; Iter    45/  201] train: loss: 0.1633668
[Epoch 66; Iter    75/  201] train: loss: 0.1934002
[Epoch 48; Iter   183/  201] train: loss: 0.1474857
[Epoch 48] ogbg-moltoxcast: 0.689765 val loss: 0.256000
[Epoch 48] ogbg-moltoxcast: 0.662858 test loss: 0.302671
[Epoch 49; Iter    12/  201] train: loss: 0.1401502
[Epoch 49; Iter    42/  201] train: loss: 0.1208052
[Epoch 49; Iter    72/  201] train: loss: 0.1260624
[Epoch 49; Iter   102/  201] train: loss: 0.1429131
[Epoch 49; Iter   132/  201] train: loss: 0.1439090
[Epoch 49; Iter   162/  201] train: loss: 0.1757409
[Epoch 49; Iter   192/  201] train: loss: 0.1676337
[Epoch 49] ogbg-moltoxcast: 0.685899 val loss: 0.254676
[Epoch 49] ogbg-moltoxcast: 0.661227 test loss: 0.297834
[Epoch 50; Iter    21/  201] train: loss: 0.1584482
[Epoch 50; Iter    51/  201] train: loss: 0.1224098
[Epoch 50; Iter    81/  201] train: loss: 0.0833056
[Epoch 50; Iter   111/  201] train: loss: 0.0806693
[Epoch 50; Iter   141/  201] train: loss: 0.1287879
[Epoch 50; Iter   171/  201] train: loss: 0.1460571
[Epoch 50; Iter   201/  201] train: loss: 0.1271801
[Epoch 50] ogbg-moltoxcast: 0.681842 val loss: 0.263622
[Epoch 50] ogbg-moltoxcast: 0.661495 test loss: 0.307608
[Epoch 51; Iter    30/  201] train: loss: 0.1494805
[Epoch 51; Iter    60/  201] train: loss: 0.1699336
[Epoch 51; Iter    90/  201] train: loss: 0.1231703
[Epoch 51; Iter   120/  201] train: loss: 0.1209819
[Epoch 51; Iter   150/  201] train: loss: 0.1154836
[Epoch 51; Iter   180/  201] train: loss: 0.1659723
[Epoch 51] ogbg-moltoxcast: 0.680296 val loss: 0.255595
[Epoch 51] ogbg-moltoxcast: 0.655695 test loss: 0.302500
[Epoch 52; Iter     9/  201] train: loss: 0.2119330
[Epoch 52; Iter    39/  201] train: loss: 0.1486772
[Epoch 52; Iter    69/  201] train: loss: 0.1328061
[Epoch 52; Iter    99/  201] train: loss: 0.0714148
[Epoch 52; Iter   129/  201] train: loss: 0.1276044
[Epoch 52; Iter   159/  201] train: loss: 0.1252283
[Epoch 52; Iter   189/  201] train: loss: 0.1254356
[Epoch 52] ogbg-moltoxcast: 0.688470 val loss: 0.264751
[Epoch 52] ogbg-moltoxcast: 0.662225 test loss: 0.313873
[Epoch 53; Iter    18/  201] train: loss: 0.1516910
[Epoch 53; Iter    48/  201] train: loss: 0.1498397
[Epoch 53; Iter    78/  201] train: loss: 0.1051130
[Epoch 53; Iter   108/  201] train: loss: 0.0871644
[Epoch 53; Iter   138/  201] train: loss: 0.1291571
[Epoch 53; Iter   168/  201] train: loss: 0.1590759
[Epoch 53; Iter   198/  201] train: loss: 0.1633568
[Epoch 53] ogbg-moltoxcast: 0.693959 val loss: 0.257214
[Epoch 53] ogbg-moltoxcast: 0.666455 test loss: 0.306889
[Epoch 54; Iter    27/  201] train: loss: 0.1558161
[Epoch 54; Iter    57/  201] train: loss: 0.1230865
[Epoch 54; Iter    87/  201] train: loss: 0.1180999
[Epoch 54; Iter   117/  201] train: loss: 0.1740589
[Epoch 54; Iter   147/  201] train: loss: 0.1065903
[Epoch 54; Iter   177/  201] train: loss: 0.2611124
[Epoch 54] ogbg-moltoxcast: 0.684655 val loss: 0.260435
[Epoch 54] ogbg-moltoxcast: 0.659933 test loss: 0.307438
[Epoch 55; Iter     6/  201] train: loss: 0.1081571
[Epoch 55; Iter    36/  201] train: loss: 0.1563256
[Epoch 55; Iter    66/  201] train: loss: 0.1604433
[Epoch 55; Iter    96/  201] train: loss: 0.1844238
[Epoch 55; Iter   126/  201] train: loss: 0.1612661
[Epoch 55; Iter   156/  201] train: loss: 0.1172238
[Epoch 55; Iter   186/  201] train: loss: 0.1768681
[Epoch 55] ogbg-moltoxcast: 0.690892 val loss: 0.257365
[Epoch 55] ogbg-moltoxcast: 0.665067 test loss: 0.309706
[Epoch 56; Iter    15/  201] train: loss: 0.1148167
[Epoch 56; Iter    45/  201] train: loss: 0.1590908
[Epoch 56; Iter    75/  201] train: loss: 0.1056070
[Epoch 56; Iter   105/  201] train: loss: 0.1529876
[Epoch 56; Iter   135/  201] train: loss: 0.1482128
[Epoch 56; Iter   165/  201] train: loss: 0.2199752
[Epoch 56; Iter   195/  201] train: loss: 0.1866998
[Epoch 56] ogbg-moltoxcast: 0.691024 val loss: 0.257670
[Epoch 56] ogbg-moltoxcast: 0.662142 test loss: 0.306162
[Epoch 57; Iter    24/  201] train: loss: 0.1306885
[Epoch 57; Iter    54/  201] train: loss: 0.1610685
[Epoch 57; Iter    84/  201] train: loss: 0.1075453
[Epoch 57; Iter   114/  201] train: loss: 0.1214758
[Epoch 57; Iter   144/  201] train: loss: 0.1555338
[Epoch 57; Iter   174/  201] train: loss: 0.0885042
[Epoch 57] ogbg-moltoxcast: 0.691141 val loss: 0.264195
[Epoch 57] ogbg-moltoxcast: 0.661698 test loss: 0.315632
[Epoch 58; Iter     3/  201] train: loss: 0.1391029
[Epoch 58; Iter    33/  201] train: loss: 0.1123550
[Epoch 58; Iter    63/  201] train: loss: 0.1239583
[Epoch 58; Iter    93/  201] train: loss: 0.1711569
[Epoch 58; Iter   123/  201] train: loss: 0.0808515
[Epoch 58; Iter   153/  201] train: loss: 0.1704670
[Epoch 58; Iter   183/  201] train: loss: 0.1610195
[Epoch 58] ogbg-moltoxcast: 0.689636 val loss: 0.259972
[Epoch 58] ogbg-moltoxcast: 0.660430 test loss: 0.311942
[Epoch 59; Iter    12/  201] train: loss: 0.1639438
[Epoch 59; Iter    42/  201] train: loss: 0.1660887
[Epoch 59; Iter    72/  201] train: loss: 0.0899732
[Epoch 59; Iter   102/  201] train: loss: 0.1069449
[Epoch 59; Iter   132/  201] train: loss: 0.0913783
[Epoch 59; Iter   162/  201] train: loss: 0.1406350
[Epoch 59; Iter   192/  201] train: loss: 0.2023200
[Epoch 59] ogbg-moltoxcast: 0.691190 val loss: 0.262220
[Epoch 59] ogbg-moltoxcast: 0.666103 test loss: 0.310179
[Epoch 60; Iter    21/  201] train: loss: 0.1268147
[Epoch 60; Iter    51/  201] train: loss: 0.0741633
[Epoch 60; Iter    81/  201] train: loss: 0.1854749
[Epoch 60; Iter   111/  201] train: loss: 0.1113450
[Epoch 60; Iter   141/  201] train: loss: 0.1205847
[Epoch 60; Iter   171/  201] train: loss: 0.1144494
[Epoch 60; Iter   201/  201] train: loss: 0.0321987
[Epoch 60] ogbg-moltoxcast: 0.678463 val loss: 0.269306
[Epoch 60] ogbg-moltoxcast: 0.650727 test loss: 0.318885
[Epoch 61; Iter    30/  201] train: loss: 0.0645133
[Epoch 61; Iter    60/  201] train: loss: 0.0838085
[Epoch 61; Iter    90/  201] train: loss: 0.1341004
[Epoch 61; Iter   120/  201] train: loss: 0.1646339
[Epoch 61; Iter   150/  201] train: loss: 0.1712651
[Epoch 61; Iter   180/  201] train: loss: 0.1125687
[Epoch 61] ogbg-moltoxcast: 0.683583 val loss: 0.264958
[Epoch 61] ogbg-moltoxcast: 0.654893 test loss: 0.317142
[Epoch 62; Iter     9/  201] train: loss: 0.1375527
[Epoch 62; Iter    39/  201] train: loss: 0.1154796
[Epoch 62; Iter    69/  201] train: loss: 0.1278674
[Epoch 62; Iter    99/  201] train: loss: 0.1113626
[Epoch 62; Iter   129/  201] train: loss: 0.1158138
[Epoch 62; Iter   159/  201] train: loss: 0.1472778
[Epoch 62; Iter   189/  201] train: loss: 0.1227978
[Epoch 62] ogbg-moltoxcast: 0.685305 val loss: 0.260404
[Epoch 62] ogbg-moltoxcast: 0.653639 test loss: 0.311681
[Epoch 63; Iter    18/  201] train: loss: 0.1768632
[Epoch 63; Iter    48/  201] train: loss: 0.1364498
[Epoch 63; Iter    78/  201] train: loss: 0.1504994
[Epoch 63; Iter   108/  201] train: loss: 0.1776861
[Epoch 63; Iter   138/  201] train: loss: 0.1547395
[Epoch 63; Iter   168/  201] train: loss: 0.0988631
[Epoch 63; Iter   198/  201] train: loss: 0.2153131
[Epoch 63] ogbg-moltoxcast: 0.686796 val loss: 0.262173
[Epoch 63] ogbg-moltoxcast: 0.659871 test loss: 0.312629
[Epoch 64; Iter    27/  201] train: loss: 0.1386811
[Epoch 64; Iter    57/  201] train: loss: 0.1306863
[Epoch 64; Iter    87/  201] train: loss: 0.1011211
[Epoch 64; Iter   117/  201] train: loss: 0.1937129
[Epoch 64; Iter   147/  201] train: loss: 0.1096894
[Epoch 64; Iter   177/  201] train: loss: 0.1048829
[Epoch 64] ogbg-moltoxcast: 0.689731 val loss: 0.260464
[Epoch 64] ogbg-moltoxcast: 0.657761 test loss: 0.310283
[Epoch 65; Iter     6/  201] train: loss: 0.1508471
[Epoch 65; Iter    36/  201] train: loss: 0.1800582
[Epoch 65; Iter    66/  201] train: loss: 0.2126384
[Epoch 65; Iter    96/  201] train: loss: 0.1079043
[Epoch 65; Iter   126/  201] train: loss: 0.1216253
[Epoch 65; Iter   156/  201] train: loss: 0.1151622
[Epoch 65; Iter   186/  201] train: loss: 0.1108096
[Epoch 65] ogbg-moltoxcast: 0.686845 val loss: 0.262513
[Epoch 65] ogbg-moltoxcast: 0.660193 test loss: 0.309907
[Epoch 66; Iter    15/  201] train: loss: 0.0996220
[Epoch 66; Iter    45/  201] train: loss: 0.0900869
[Epoch 66; Iter    75/  201] train: loss: 0.1433426
[Epoch 54; Iter   154/  172] train: loss: 0.0961962
[Epoch 54] ogbg-moltoxcast: 0.655069 val loss: 0.276122
[Epoch 54] ogbg-moltoxcast: 0.624212 test loss: 0.327896
[Epoch 55; Iter    12/  172] train: loss: 0.0766531
[Epoch 55; Iter    42/  172] train: loss: 0.0755708
[Epoch 55; Iter    72/  172] train: loss: 0.1087237
[Epoch 55; Iter   102/  172] train: loss: 0.1644007
[Epoch 55; Iter   132/  172] train: loss: 0.0906634
[Epoch 55; Iter   162/  172] train: loss: 0.1858661
[Epoch 55] ogbg-moltoxcast: 0.650418 val loss: 0.275489
[Epoch 55] ogbg-moltoxcast: 0.625755 test loss: 0.327441
[Epoch 56; Iter    20/  172] train: loss: 0.1144641
[Epoch 56; Iter    50/  172] train: loss: 0.0983947
[Epoch 56; Iter    80/  172] train: loss: 0.1694347
[Epoch 56; Iter   110/  172] train: loss: 0.1268186
[Epoch 56; Iter   140/  172] train: loss: 0.1106598
[Epoch 56; Iter   170/  172] train: loss: 0.1307399
[Epoch 56] ogbg-moltoxcast: 0.651345 val loss: 0.279637
[Epoch 56] ogbg-moltoxcast: 0.623206 test loss: 0.332492
[Epoch 57; Iter    28/  172] train: loss: 0.1012460
[Epoch 57; Iter    58/  172] train: loss: 0.1124982
[Epoch 57; Iter    88/  172] train: loss: 0.1273155
[Epoch 57; Iter   118/  172] train: loss: 0.1695237
[Epoch 57; Iter   148/  172] train: loss: 0.0910526
[Epoch 57] ogbg-moltoxcast: 0.650280 val loss: 0.281245
[Epoch 57] ogbg-moltoxcast: 0.625223 test loss: 0.331211
[Epoch 58; Iter     6/  172] train: loss: 0.1177094
[Epoch 58; Iter    36/  172] train: loss: 0.0922556
[Epoch 58; Iter    66/  172] train: loss: 0.1608058
[Epoch 58; Iter    96/  172] train: loss: 0.1348606
[Epoch 58; Iter   126/  172] train: loss: 0.1164860
[Epoch 58; Iter   156/  172] train: loss: 0.1408711
[Epoch 58] ogbg-moltoxcast: 0.658053 val loss: 0.273141
[Epoch 58] ogbg-moltoxcast: 0.622087 test loss: 0.326382
[Epoch 59; Iter    14/  172] train: loss: 0.1014446
[Epoch 59; Iter    44/  172] train: loss: 0.0939268
[Epoch 59; Iter    74/  172] train: loss: 0.1059642
[Epoch 59; Iter   104/  172] train: loss: 0.0810644
[Epoch 59; Iter   134/  172] train: loss: 0.1245966
[Epoch 59; Iter   164/  172] train: loss: 0.0889174
[Epoch 59] ogbg-moltoxcast: 0.658915 val loss: 0.275097
[Epoch 59] ogbg-moltoxcast: 0.626472 test loss: 0.331023
[Epoch 60; Iter    22/  172] train: loss: 0.1560342
[Epoch 60; Iter    52/  172] train: loss: 0.1157429
[Epoch 60; Iter    82/  172] train: loss: 0.0869995
[Epoch 60; Iter   112/  172] train: loss: 0.1074890
[Epoch 60; Iter   142/  172] train: loss: 0.0911143
[Epoch 60; Iter   172/  172] train: loss: 0.1084041
[Epoch 60] ogbg-moltoxcast: 0.643626 val loss: 0.289048
[Epoch 60] ogbg-moltoxcast: 0.619631 test loss: 0.342291
[Epoch 61; Iter    30/  172] train: loss: 0.0915229
[Epoch 61; Iter    60/  172] train: loss: 0.1686515
[Epoch 61; Iter    90/  172] train: loss: 0.1225636
[Epoch 61; Iter   120/  172] train: loss: 0.1404472
[Epoch 61; Iter   150/  172] train: loss: 0.1367901
[Epoch 61] ogbg-moltoxcast: 0.647357 val loss: 0.285517
[Epoch 61] ogbg-moltoxcast: 0.625094 test loss: 0.336847
[Epoch 62; Iter     8/  172] train: loss: 0.0912855
[Epoch 62; Iter    38/  172] train: loss: 0.0946051
[Epoch 62; Iter    68/  172] train: loss: 0.1181542
[Epoch 62; Iter    98/  172] train: loss: 0.1105075
[Epoch 62; Iter   128/  172] train: loss: 0.1460669
[Epoch 62; Iter   158/  172] train: loss: 0.1071004
[Epoch 62] ogbg-moltoxcast: 0.639238 val loss: 0.285351
[Epoch 62] ogbg-moltoxcast: 0.621483 test loss: 0.335411
[Epoch 63; Iter    16/  172] train: loss: 0.1235767
[Epoch 63; Iter    46/  172] train: loss: 0.1290607
[Epoch 63; Iter    76/  172] train: loss: 0.1674288
[Epoch 63; Iter   106/  172] train: loss: 0.1387762
[Epoch 63; Iter   136/  172] train: loss: 0.0963106
[Epoch 63; Iter   166/  172] train: loss: 0.1085478
[Epoch 63] ogbg-moltoxcast: 0.651031 val loss: 0.291234
[Epoch 63] ogbg-moltoxcast: 0.621622 test loss: 0.350528
[Epoch 64; Iter    24/  172] train: loss: 0.1266566
[Epoch 64; Iter    54/  172] train: loss: 0.1593397
[Epoch 64; Iter    84/  172] train: loss: 0.0898165
[Epoch 64; Iter   114/  172] train: loss: 0.1213630
[Epoch 64; Iter   144/  172] train: loss: 0.1439378
[Epoch 64] ogbg-moltoxcast: 0.647574 val loss: 0.292863
[Epoch 64] ogbg-moltoxcast: 0.621760 test loss: 0.349029
[Epoch 65; Iter     2/  172] train: loss: 0.1365566
[Epoch 65; Iter    32/  172] train: loss: 0.1229867
[Epoch 65; Iter    62/  172] train: loss: 0.1259859
[Epoch 65; Iter    92/  172] train: loss: 0.1154476
[Epoch 65; Iter   122/  172] train: loss: 0.1448294
[Epoch 65; Iter   152/  172] train: loss: 0.1320044
[Epoch 65] ogbg-moltoxcast: 0.658793 val loss: 0.286832
[Epoch 65] ogbg-moltoxcast: 0.629554 test loss: 0.344911
[Epoch 66; Iter    10/  172] train: loss: 0.1511735
[Epoch 66; Iter    40/  172] train: loss: 0.1131720
[Epoch 66; Iter    70/  172] train: loss: 0.1145787
[Epoch 66; Iter   100/  172] train: loss: 0.0762893
[Epoch 66; Iter   130/  172] train: loss: 0.1095196
[Epoch 66; Iter   160/  172] train: loss: 0.1218772
[Epoch 66] ogbg-moltoxcast: 0.651864 val loss: 0.282307
[Epoch 66] ogbg-moltoxcast: 0.627152 test loss: 0.334057
[Epoch 67; Iter    18/  172] train: loss: 0.1354785
[Epoch 67; Iter    48/  172] train: loss: 0.1191275
[Epoch 67; Iter    78/  172] train: loss: 0.1353178
[Epoch 67; Iter   108/  172] train: loss: 0.1556312
[Epoch 67; Iter   138/  172] train: loss: 0.1408484
[Epoch 67; Iter   168/  172] train: loss: 0.0855403
[Epoch 67] ogbg-moltoxcast: 0.648123 val loss: 0.279697
[Epoch 67] ogbg-moltoxcast: 0.623705 test loss: 0.328416
[Epoch 68; Iter    26/  172] train: loss: 0.0924303
[Epoch 68; Iter    56/  172] train: loss: 0.0885956
[Epoch 68; Iter    86/  172] train: loss: 0.0951686
[Epoch 68; Iter   116/  172] train: loss: 0.0923573
[Epoch 68; Iter   146/  172] train: loss: 0.1389009
[Epoch 68] ogbg-moltoxcast: 0.653571 val loss: 0.284319
[Epoch 68] ogbg-moltoxcast: 0.625340 test loss: 0.337370
[Epoch 69; Iter     4/  172] train: loss: 0.0731605
[Epoch 69; Iter    34/  172] train: loss: 0.1126983
[Epoch 69; Iter    64/  172] train: loss: 0.1051105
[Epoch 69; Iter    94/  172] train: loss: 0.0859813
[Epoch 69; Iter   124/  172] train: loss: 0.1388489
[Epoch 69; Iter   154/  172] train: loss: 0.1279611
[Epoch 69] ogbg-moltoxcast: 0.650793 val loss: 0.280082
[Epoch 69] ogbg-moltoxcast: 0.623772 test loss: 0.331648
[Epoch 70; Iter    12/  172] train: loss: 0.1629242
[Epoch 70; Iter    42/  172] train: loss: 0.1022547
[Epoch 70; Iter    72/  172] train: loss: 0.0886871
[Epoch 70; Iter   102/  172] train: loss: 0.0953796
[Epoch 70; Iter   132/  172] train: loss: 0.1381956
[Epoch 70; Iter   162/  172] train: loss: 0.0895875
[Epoch 70] ogbg-moltoxcast: 0.655287 val loss: 0.287002
[Epoch 70] ogbg-moltoxcast: 0.625650 test loss: 0.342796
[Epoch 71; Iter    20/  172] train: loss: 0.1270837
[Epoch 71; Iter    50/  172] train: loss: 0.1163079
[Epoch 71; Iter    80/  172] train: loss: 0.1309589
[Epoch 71; Iter   110/  172] train: loss: 0.1129449
[Epoch 71; Iter   140/  172] train: loss: 0.1123867
[Epoch 71; Iter   170/  172] train: loss: 0.1493290
[Epoch 71] ogbg-moltoxcast: 0.648726 val loss: 0.290451
[Epoch 71] ogbg-moltoxcast: 0.623708 test loss: 0.344429
[Epoch 72; Iter    28/  172] train: loss: 0.1121500
[Epoch 72; Iter    58/  172] train: loss: 0.1230420
[Epoch 72; Iter    88/  172] train: loss: 0.1531073
[Epoch 72; Iter   118/  172] train: loss: 0.0861435
[Epoch 72; Iter   148/  172] train: loss: 0.1184951
[Epoch 72] ogbg-moltoxcast: 0.649813 val loss: 0.285324
[Epoch 72] ogbg-moltoxcast: 0.623167 test loss: 0.337979
[Epoch 73; Iter     6/  172] train: loss: 0.0812309
[Epoch 73; Iter    36/  172] train: loss: 0.0959224
[Epoch 73; Iter    66/  172] train: loss: 0.0997336
[Epoch 73; Iter    96/  172] train: loss: 0.0922344
[Epoch 73; Iter   126/  172] train: loss: 0.1549182
[Epoch 73; Iter   156/  172] train: loss: 0.1371832
[Epoch 73] ogbg-moltoxcast: 0.648437 val loss: 0.291405
[Epoch 73] ogbg-moltoxcast: 0.622225 test loss: 0.352401
[Epoch 74; Iter    14/  172] train: loss: 0.1213911
[Epoch 74; Iter    44/  172] train: loss: 0.0972609
[Epoch 74; Iter    74/  172] train: loss: 0.1145732
[Epoch 74; Iter   104/  172] train: loss: 0.1170254
[Epoch 54; Iter   154/  172] train: loss: 0.1297074
[Epoch 54] ogbg-moltoxcast: 0.664272 val loss: 0.287044
[Epoch 54] ogbg-moltoxcast: 0.636804 test loss: 0.341744
[Epoch 55; Iter    12/  172] train: loss: 0.1218860
[Epoch 55; Iter    42/  172] train: loss: 0.1286116
[Epoch 55; Iter    72/  172] train: loss: 0.1328413
[Epoch 55; Iter   102/  172] train: loss: 0.1382322
[Epoch 55; Iter   132/  172] train: loss: 0.1365769
[Epoch 55; Iter   162/  172] train: loss: 0.1439686
[Epoch 55] ogbg-moltoxcast: 0.668732 val loss: 0.277753
[Epoch 55] ogbg-moltoxcast: 0.638885 test loss: 0.325364
[Epoch 56; Iter    20/  172] train: loss: 0.0950689
[Epoch 56; Iter    50/  172] train: loss: 0.1373028
[Epoch 56; Iter    80/  172] train: loss: 0.1501132
[Epoch 56; Iter   110/  172] train: loss: 0.1383145
[Epoch 56; Iter   140/  172] train: loss: 0.1789056
[Epoch 56; Iter   170/  172] train: loss: 0.1556498
[Epoch 56] ogbg-moltoxcast: 0.655625 val loss: 0.278363
[Epoch 56] ogbg-moltoxcast: 0.629388 test loss: 0.324654
[Epoch 57; Iter    28/  172] train: loss: 0.0932733
[Epoch 57; Iter    58/  172] train: loss: 0.1073858
[Epoch 57; Iter    88/  172] train: loss: 0.2204195
[Epoch 57; Iter   118/  172] train: loss: 0.1715217
[Epoch 57; Iter   148/  172] train: loss: 0.0738829
[Epoch 57] ogbg-moltoxcast: 0.665532 val loss: 0.279649
[Epoch 57] ogbg-moltoxcast: 0.631551 test loss: 0.332089
[Epoch 58; Iter     6/  172] train: loss: 0.1195599
[Epoch 58; Iter    36/  172] train: loss: 0.0865840
[Epoch 58; Iter    66/  172] train: loss: 0.1313894
[Epoch 58; Iter    96/  172] train: loss: 0.1028772
[Epoch 58; Iter   126/  172] train: loss: 0.1532013
[Epoch 58; Iter   156/  172] train: loss: 0.1322492
[Epoch 58] ogbg-moltoxcast: 0.664063 val loss: 0.277970
[Epoch 58] ogbg-moltoxcast: 0.635492 test loss: 0.323017
[Epoch 59; Iter    14/  172] train: loss: 0.1720702
[Epoch 59; Iter    44/  172] train: loss: 0.0966109
[Epoch 59; Iter    74/  172] train: loss: 0.0990702
[Epoch 59; Iter   104/  172] train: loss: 0.1753223
[Epoch 59; Iter   134/  172] train: loss: 0.1272349
[Epoch 59; Iter   164/  172] train: loss: 0.1138886
[Epoch 59] ogbg-moltoxcast: 0.657363 val loss: 0.285670
[Epoch 59] ogbg-moltoxcast: 0.630098 test loss: 0.334591
[Epoch 60; Iter    22/  172] train: loss: 0.1615907
[Epoch 60; Iter    52/  172] train: loss: 0.1062291
[Epoch 60; Iter    82/  172] train: loss: 0.1341769
[Epoch 60; Iter   112/  172] train: loss: 0.1701455
[Epoch 60; Iter   142/  172] train: loss: 0.1812021
[Epoch 60; Iter   172/  172] train: loss: 0.1944723
[Epoch 60] ogbg-moltoxcast: 0.664002 val loss: 0.280490
[Epoch 60] ogbg-moltoxcast: 0.636140 test loss: 0.332966
[Epoch 61; Iter    30/  172] train: loss: 0.1444763
[Epoch 61; Iter    60/  172] train: loss: 0.1099209
[Epoch 61; Iter    90/  172] train: loss: 0.1174373
[Epoch 61; Iter   120/  172] train: loss: 0.1324793
[Epoch 61; Iter   150/  172] train: loss: 0.1524350
[Epoch 61] ogbg-moltoxcast: 0.650211 val loss: 0.281357
[Epoch 61] ogbg-moltoxcast: 0.631977 test loss: 0.324815
[Epoch 62; Iter     8/  172] train: loss: 0.1127703
[Epoch 62; Iter    38/  172] train: loss: 0.1359487
[Epoch 62; Iter    68/  172] train: loss: 0.1397911
[Epoch 62; Iter    98/  172] train: loss: 0.1279008
[Epoch 62; Iter   128/  172] train: loss: 0.1133987
[Epoch 62; Iter   158/  172] train: loss: 0.1613335
[Epoch 62] ogbg-moltoxcast: 0.650444 val loss: 0.285544
[Epoch 62] ogbg-moltoxcast: 0.630787 test loss: 0.333777
[Epoch 63; Iter    16/  172] train: loss: 0.1435811
[Epoch 63; Iter    46/  172] train: loss: 0.1419951
[Epoch 63; Iter    76/  172] train: loss: 0.1212055
[Epoch 63; Iter   106/  172] train: loss: 0.1117633
[Epoch 63; Iter   136/  172] train: loss: 0.1286421
[Epoch 63; Iter   166/  172] train: loss: 0.1074716
[Epoch 63] ogbg-moltoxcast: 0.659975 val loss: 0.287110
[Epoch 63] ogbg-moltoxcast: 0.633878 test loss: 0.340483
[Epoch 64; Iter    24/  172] train: loss: 0.1452348
[Epoch 64; Iter    54/  172] train: loss: 0.1280229
[Epoch 64; Iter    84/  172] train: loss: 0.1280881
[Epoch 64; Iter   114/  172] train: loss: 0.0901404
[Epoch 64; Iter   144/  172] train: loss: 0.0938579
[Epoch 64] ogbg-moltoxcast: 0.655221 val loss: 0.280409
[Epoch 64] ogbg-moltoxcast: 0.633006 test loss: 0.329803
[Epoch 65; Iter     2/  172] train: loss: 0.1276704
[Epoch 65; Iter    32/  172] train: loss: 0.1372365
[Epoch 65; Iter    62/  172] train: loss: 0.1327037
[Epoch 65; Iter    92/  172] train: loss: 0.1076541
[Epoch 65; Iter   122/  172] train: loss: 0.1175668
[Epoch 65; Iter   152/  172] train: loss: 0.1299805
[Epoch 65] ogbg-moltoxcast: 0.651247 val loss: 0.282606
[Epoch 65] ogbg-moltoxcast: 0.628002 test loss: 0.329181
[Epoch 66; Iter    10/  172] train: loss: 0.1052123
[Epoch 66; Iter    40/  172] train: loss: 0.1619049
[Epoch 66; Iter    70/  172] train: loss: 0.1316391
[Epoch 66; Iter   100/  172] train: loss: 0.1058891
[Epoch 66; Iter   130/  172] train: loss: 0.1170367
[Epoch 66; Iter   160/  172] train: loss: 0.1090598
[Epoch 66] ogbg-moltoxcast: 0.655443 val loss: 0.281945
[Epoch 66] ogbg-moltoxcast: 0.632661 test loss: 0.330031
[Epoch 67; Iter    18/  172] train: loss: 0.1410048
[Epoch 67; Iter    48/  172] train: loss: 0.1294814
[Epoch 67; Iter    78/  172] train: loss: 0.0940400
[Epoch 67; Iter   108/  172] train: loss: 0.0980278
[Epoch 67; Iter   138/  172] train: loss: 0.1278052
[Epoch 67; Iter   168/  172] train: loss: 0.1465467
[Epoch 67] ogbg-moltoxcast: 0.650632 val loss: 0.283800
[Epoch 67] ogbg-moltoxcast: 0.628569 test loss: 0.330762
[Epoch 68; Iter    26/  172] train: loss: 0.1036032
[Epoch 68; Iter    56/  172] train: loss: 0.0953799
[Epoch 68; Iter    86/  172] train: loss: 0.1314954
[Epoch 68; Iter   116/  172] train: loss: 0.1538204
[Epoch 68; Iter   146/  172] train: loss: 0.1074262
[Epoch 68] ogbg-moltoxcast: 0.654504 val loss: 0.282239
[Epoch 68] ogbg-moltoxcast: 0.633124 test loss: 0.330345
[Epoch 69; Iter     4/  172] train: loss: 0.1037324
[Epoch 69; Iter    34/  172] train: loss: 0.1001680
[Epoch 69; Iter    64/  172] train: loss: 0.0899884
[Epoch 69; Iter    94/  172] train: loss: 0.1216877
[Epoch 69; Iter   124/  172] train: loss: 0.1151669
[Epoch 69; Iter   154/  172] train: loss: 0.1127892
[Epoch 69] ogbg-moltoxcast: 0.650395 val loss: 0.289074
[Epoch 69] ogbg-moltoxcast: 0.627514 test loss: 0.338146
[Epoch 70; Iter    12/  172] train: loss: 0.1375869
[Epoch 70; Iter    42/  172] train: loss: 0.1269083
[Epoch 70; Iter    72/  172] train: loss: 0.1498655
[Epoch 70; Iter   102/  172] train: loss: 0.0940197
[Epoch 70; Iter   132/  172] train: loss: 0.0915785
[Epoch 70; Iter   162/  172] train: loss: 0.1843581
[Epoch 70] ogbg-moltoxcast: 0.645266 val loss: 0.289833
[Epoch 70] ogbg-moltoxcast: 0.625946 test loss: 0.337698
[Epoch 71; Iter    20/  172] train: loss: 0.1473217
[Epoch 71; Iter    50/  172] train: loss: 0.1800452
[Epoch 71; Iter    80/  172] train: loss: 0.1448935
[Epoch 71; Iter   110/  172] train: loss: 0.1180733
[Epoch 71; Iter   140/  172] train: loss: 0.1040833
[Epoch 71; Iter   170/  172] train: loss: 0.1359609
[Epoch 71] ogbg-moltoxcast: 0.654637 val loss: 0.284025
[Epoch 71] ogbg-moltoxcast: 0.635017 test loss: 0.333052
[Epoch 72; Iter    28/  172] train: loss: 0.0977092
[Epoch 72; Iter    58/  172] train: loss: 0.1170177
[Epoch 72; Iter    88/  172] train: loss: 0.1021292
[Epoch 72; Iter   118/  172] train: loss: 0.1065223
[Epoch 72; Iter   148/  172] train: loss: 0.0990767
[Epoch 72] ogbg-moltoxcast: 0.643324 val loss: 0.291619
[Epoch 72] ogbg-moltoxcast: 0.626418 test loss: 0.336288
[Epoch 73; Iter     6/  172] train: loss: 0.1942435
[Epoch 73; Iter    36/  172] train: loss: 0.1011682
[Epoch 73; Iter    66/  172] train: loss: 0.1357581
[Epoch 73; Iter    96/  172] train: loss: 0.1796773
[Epoch 73; Iter   126/  172] train: loss: 0.0906489
[Epoch 73; Iter   156/  172] train: loss: 0.1138531
[Epoch 73] ogbg-moltoxcast: 0.649149 val loss: 0.285645
[Epoch 73] ogbg-moltoxcast: 0.629637 test loss: 0.331943
[Epoch 74; Iter    14/  172] train: loss: 0.1545514
[Epoch 74; Iter    44/  172] train: loss: 0.0870030
[Epoch 74; Iter    74/  172] train: loss: 0.1683552
[Epoch 74; Iter   104/  172] train: loss: 0.0930432
[Epoch 54; Iter   154/  172] train: loss: 0.0932029
[Epoch 54] ogbg-moltoxcast: 0.662231 val loss: 0.275651
[Epoch 54] ogbg-moltoxcast: 0.625454 test loss: 0.325609
[Epoch 55; Iter    12/  172] train: loss: 0.1028641
[Epoch 55; Iter    42/  172] train: loss: 0.1651300
[Epoch 55; Iter    72/  172] train: loss: 0.0984397
[Epoch 55; Iter   102/  172] train: loss: 0.1849996
[Epoch 55; Iter   132/  172] train: loss: 0.1186449
[Epoch 55; Iter   162/  172] train: loss: 0.1345567
[Epoch 55] ogbg-moltoxcast: 0.656527 val loss: 0.280528
[Epoch 55] ogbg-moltoxcast: 0.621057 test loss: 0.332462
[Epoch 56; Iter    20/  172] train: loss: 0.1499475
[Epoch 56; Iter    50/  172] train: loss: 0.1528595
[Epoch 56; Iter    80/  172] train: loss: 0.1869424
[Epoch 56; Iter   110/  172] train: loss: 0.0831556
[Epoch 56; Iter   140/  172] train: loss: 0.1241919
[Epoch 56; Iter   170/  172] train: loss: 0.0947892
[Epoch 56] ogbg-moltoxcast: 0.660831 val loss: 0.282770
[Epoch 56] ogbg-moltoxcast: 0.627713 test loss: 0.419773
[Epoch 57; Iter    28/  172] train: loss: 0.1283218
[Epoch 57; Iter    58/  172] train: loss: 0.1486895
[Epoch 57; Iter    88/  172] train: loss: 0.1463690
[Epoch 57; Iter   118/  172] train: loss: 0.1512579
[Epoch 57; Iter   148/  172] train: loss: 0.1370915
[Epoch 57] ogbg-moltoxcast: 0.650607 val loss: 0.287417
[Epoch 57] ogbg-moltoxcast: 0.624254 test loss: 0.338582
[Epoch 58; Iter     6/  172] train: loss: 0.1363548
[Epoch 58; Iter    36/  172] train: loss: 0.1148533
[Epoch 58; Iter    66/  172] train: loss: 0.1425935
[Epoch 58; Iter    96/  172] train: loss: 0.1338086
[Epoch 58; Iter   126/  172] train: loss: 0.1747377
[Epoch 58; Iter   156/  172] train: loss: 0.1347714
[Epoch 58] ogbg-moltoxcast: 0.656495 val loss: 0.281786
[Epoch 58] ogbg-moltoxcast: 0.628807 test loss: 0.326773
[Epoch 59; Iter    14/  172] train: loss: 0.1211985
[Epoch 59; Iter    44/  172] train: loss: 0.0933328
[Epoch 59; Iter    74/  172] train: loss: 0.1342062
[Epoch 59; Iter   104/  172] train: loss: 0.1754910
[Epoch 59; Iter   134/  172] train: loss: 0.1332282
[Epoch 59; Iter   164/  172] train: loss: 0.1176845
[Epoch 59] ogbg-moltoxcast: 0.650011 val loss: 0.286561
[Epoch 59] ogbg-moltoxcast: 0.621736 test loss: 0.334886
[Epoch 60; Iter    22/  172] train: loss: 0.0885164
[Epoch 60; Iter    52/  172] train: loss: 0.1318083
[Epoch 60; Iter    82/  172] train: loss: 0.1821747
[Epoch 60; Iter   112/  172] train: loss: 0.1429152
[Epoch 60; Iter   142/  172] train: loss: 0.1316819
[Epoch 60; Iter   172/  172] train: loss: 0.1489941
[Epoch 60] ogbg-moltoxcast: 0.653238 val loss: 0.283945
[Epoch 60] ogbg-moltoxcast: 0.624230 test loss: 0.331884
[Epoch 61; Iter    30/  172] train: loss: 0.1064795
[Epoch 61; Iter    60/  172] train: loss: 0.1568866
[Epoch 61; Iter    90/  172] train: loss: 0.1274082
[Epoch 61; Iter   120/  172] train: loss: 0.0971961
[Epoch 61; Iter   150/  172] train: loss: 0.1721699
[Epoch 61] ogbg-moltoxcast: 0.660209 val loss: 0.288266
[Epoch 61] ogbg-moltoxcast: 0.624775 test loss: 0.343756
[Epoch 62; Iter     8/  172] train: loss: 0.1526695
[Epoch 62; Iter    38/  172] train: loss: 0.1362213
[Epoch 62; Iter    68/  172] train: loss: 0.1039656
[Epoch 62; Iter    98/  172] train: loss: 0.1241455
[Epoch 62; Iter   128/  172] train: loss: 0.1179411
[Epoch 62; Iter   158/  172] train: loss: 0.1839624
[Epoch 62] ogbg-moltoxcast: 0.660860 val loss: 0.275241
[Epoch 62] ogbg-moltoxcast: 0.623459 test loss: 0.323197
[Epoch 63; Iter    16/  172] train: loss: 0.1174591
[Epoch 63; Iter    46/  172] train: loss: 0.1495503
[Epoch 63; Iter    76/  172] train: loss: 0.0753914
[Epoch 63; Iter   106/  172] train: loss: 0.1136918
[Epoch 63; Iter   136/  172] train: loss: 0.1406624
[Epoch 63; Iter   166/  172] train: loss: 0.1139404
[Epoch 63] ogbg-moltoxcast: 0.652092 val loss: 0.287477
[Epoch 63] ogbg-moltoxcast: 0.619061 test loss: 0.336102
[Epoch 64; Iter    24/  172] train: loss: 0.0746535
[Epoch 64; Iter    54/  172] train: loss: 0.1676881
[Epoch 64; Iter    84/  172] train: loss: 0.1303730
[Epoch 64; Iter   114/  172] train: loss: 0.1327853
[Epoch 64; Iter   144/  172] train: loss: 0.1646883
[Epoch 64] ogbg-moltoxcast: 0.641922 val loss: 0.300934
[Epoch 64] ogbg-moltoxcast: 0.612904 test loss: 0.348556
[Epoch 65; Iter     2/  172] train: loss: 0.1368368
[Epoch 65; Iter    32/  172] train: loss: 0.1580375
[Epoch 65; Iter    62/  172] train: loss: 0.1407226
[Epoch 65; Iter    92/  172] train: loss: 0.1381052
[Epoch 65; Iter   122/  172] train: loss: 0.0985731
[Epoch 65; Iter   152/  172] train: loss: 0.1533507
[Epoch 65] ogbg-moltoxcast: 0.650374 val loss: 0.285282
[Epoch 65] ogbg-moltoxcast: 0.618139 test loss: 0.335756
[Epoch 66; Iter    10/  172] train: loss: 0.1272693
[Epoch 66; Iter    40/  172] train: loss: 0.1320587
[Epoch 66; Iter    70/  172] train: loss: 0.1167941
[Epoch 66; Iter   100/  172] train: loss: 0.0964902
[Epoch 66; Iter   130/  172] train: loss: 0.0967728
[Epoch 66; Iter   160/  172] train: loss: 0.1158183
[Epoch 66] ogbg-moltoxcast: 0.648984 val loss: 0.291003
[Epoch 66] ogbg-moltoxcast: 0.610823 test loss: 0.346595
[Epoch 67; Iter    18/  172] train: loss: 0.1184195
[Epoch 67; Iter    48/  172] train: loss: 0.1527465
[Epoch 67; Iter    78/  172] train: loss: 0.0879736
[Epoch 67; Iter   108/  172] train: loss: 0.1498535
[Epoch 67; Iter   138/  172] train: loss: 0.1364307
[Epoch 67; Iter   168/  172] train: loss: 0.1273884
[Epoch 67] ogbg-moltoxcast: 0.647350 val loss: 0.288601
[Epoch 67] ogbg-moltoxcast: 0.615699 test loss: 0.339987
[Epoch 68; Iter    26/  172] train: loss: 0.1032487
[Epoch 68; Iter    56/  172] train: loss: 0.1457504
[Epoch 68; Iter    86/  172] train: loss: 0.0847837
[Epoch 68; Iter   116/  172] train: loss: 0.1373562
[Epoch 68; Iter   146/  172] train: loss: 0.1176256
[Epoch 68] ogbg-moltoxcast: 0.650170 val loss: 0.290461
[Epoch 68] ogbg-moltoxcast: 0.616886 test loss: 0.342339
[Epoch 69; Iter     4/  172] train: loss: 0.1144346
[Epoch 69; Iter    34/  172] train: loss: 0.1121604
[Epoch 69; Iter    64/  172] train: loss: 0.0961227
[Epoch 69; Iter    94/  172] train: loss: 0.1184020
[Epoch 69; Iter   124/  172] train: loss: 0.1169771
[Epoch 69; Iter   154/  172] train: loss: 0.1716448
[Epoch 69] ogbg-moltoxcast: 0.647863 val loss: 0.296407
[Epoch 69] ogbg-moltoxcast: 0.615631 test loss: 0.347657
[Epoch 70; Iter    12/  172] train: loss: 0.1120668
[Epoch 70; Iter    42/  172] train: loss: 0.0826871
[Epoch 70; Iter    72/  172] train: loss: 0.1163470
[Epoch 70; Iter   102/  172] train: loss: 0.0976034
[Epoch 70; Iter   132/  172] train: loss: 0.0997305
[Epoch 70; Iter   162/  172] train: loss: 0.0898100
[Epoch 70] ogbg-moltoxcast: 0.646578 val loss: 0.290523
[Epoch 70] ogbg-moltoxcast: 0.618120 test loss: 0.339706
[Epoch 71; Iter    20/  172] train: loss: 0.1535154
[Epoch 71; Iter    50/  172] train: loss: 0.1375269
[Epoch 71; Iter    80/  172] train: loss: 0.0973854
[Epoch 71; Iter   110/  172] train: loss: 0.0964629
[Epoch 71; Iter   140/  172] train: loss: 0.1146248
[Epoch 71; Iter   170/  172] train: loss: 0.1302966
[Epoch 71] ogbg-moltoxcast: 0.651919 val loss: 0.295619
[Epoch 71] ogbg-moltoxcast: 0.622383 test loss: 0.343916
[Epoch 72; Iter    28/  172] train: loss: 0.1090827
[Epoch 72; Iter    58/  172] train: loss: 0.1591130
[Epoch 72; Iter    88/  172] train: loss: 0.1157568
[Epoch 72; Iter   118/  172] train: loss: 0.1214677
[Epoch 72; Iter   148/  172] train: loss: 0.1349236
[Epoch 72] ogbg-moltoxcast: 0.645907 val loss: 0.292124
[Epoch 72] ogbg-moltoxcast: 0.615499 test loss: 0.343084
[Epoch 73; Iter     6/  172] train: loss: 0.1039847
[Epoch 73; Iter    36/  172] train: loss: 0.0960429
[Epoch 73; Iter    66/  172] train: loss: 0.1318595
[Epoch 73; Iter    96/  172] train: loss: 0.1120151
[Epoch 73; Iter   126/  172] train: loss: 0.1396782
[Epoch 73; Iter   156/  172] train: loss: 0.1244838
[Epoch 73] ogbg-moltoxcast: 0.643521 val loss: 0.295973
[Epoch 73] ogbg-moltoxcast: 0.614008 test loss: 0.347831
[Epoch 74; Iter    14/  172] train: loss: 0.0840917
[Epoch 74; Iter    44/  172] train: loss: 0.1126676
[Epoch 74; Iter    74/  172] train: loss: 0.0954391
[Epoch 74; Iter   104/  172] train: loss: 0.1176724
[Epoch 60; Iter    19/  229] train: loss: 0.1022321
[Epoch 60; Iter    49/  229] train: loss: 0.1375059
[Epoch 60; Iter    79/  229] train: loss: 0.1597571
[Epoch 60; Iter   109/  229] train: loss: 0.1215078
[Epoch 60; Iter   139/  229] train: loss: 0.1484925
[Epoch 60; Iter   169/  229] train: loss: 0.1075711
[Epoch 60; Iter   199/  229] train: loss: 0.1652367
[Epoch 60; Iter   229/  229] train: loss: 0.1453305
[Epoch 60] ogbg-moltoxcast: 0.689111 val loss: 0.275649
[Epoch 60] ogbg-moltoxcast: 0.656092 test loss: 0.304127
[Epoch 61; Iter    30/  229] train: loss: 0.1494474
[Epoch 61; Iter    60/  229] train: loss: 0.1867144
[Epoch 61; Iter    90/  229] train: loss: 0.1810800
[Epoch 61; Iter   120/  229] train: loss: 0.1656921
[Epoch 61; Iter   150/  229] train: loss: 0.1697642
[Epoch 61; Iter   180/  229] train: loss: 0.1683509
[Epoch 61; Iter   210/  229] train: loss: 0.0972890
[Epoch 61] ogbg-moltoxcast: 0.684176 val loss: 0.256869
[Epoch 61] ogbg-moltoxcast: 0.659899 test loss: 0.312511
[Epoch 62; Iter    11/  229] train: loss: 0.0891549
[Epoch 62; Iter    41/  229] train: loss: 0.2130166
[Epoch 62; Iter    71/  229] train: loss: 0.1489145
[Epoch 62; Iter   101/  229] train: loss: 0.1383837
[Epoch 62; Iter   131/  229] train: loss: 0.1669133
[Epoch 62; Iter   161/  229] train: loss: 0.1307798
[Epoch 62; Iter   191/  229] train: loss: 0.1370053
[Epoch 62; Iter   221/  229] train: loss: 0.1563865
[Epoch 62] ogbg-moltoxcast: 0.678129 val loss: 0.260871
[Epoch 62] ogbg-moltoxcast: 0.654690 test loss: 0.311735
[Epoch 63; Iter    22/  229] train: loss: 0.1417505
[Epoch 63; Iter    52/  229] train: loss: 0.0967543
[Epoch 63; Iter    82/  229] train: loss: 0.1019763
[Epoch 63; Iter   112/  229] train: loss: 0.1032220
[Epoch 63; Iter   142/  229] train: loss: 0.2068200
[Epoch 63; Iter   172/  229] train: loss: 0.1779194
[Epoch 63; Iter   202/  229] train: loss: 0.1143710
[Epoch 63] ogbg-moltoxcast: 0.682561 val loss: 0.266277
[Epoch 63] ogbg-moltoxcast: 0.655594 test loss: 0.319006
[Epoch 64; Iter     3/  229] train: loss: 0.0879565
[Epoch 64; Iter    33/  229] train: loss: 0.1357278
[Epoch 64; Iter    63/  229] train: loss: 0.1453799
[Epoch 64; Iter    93/  229] train: loss: 0.1308145
[Epoch 64; Iter   123/  229] train: loss: 0.1214801
[Epoch 64; Iter   153/  229] train: loss: 0.1117688
[Epoch 64; Iter   183/  229] train: loss: 0.1122888
[Epoch 64; Iter   213/  229] train: loss: 0.1529602
[Epoch 64] ogbg-moltoxcast: 0.680007 val loss: 0.256487
[Epoch 64] ogbg-moltoxcast: 0.657541 test loss: 0.311226
[Epoch 65; Iter    14/  229] train: loss: 0.1591106
[Epoch 65; Iter    44/  229] train: loss: 0.1518547
[Epoch 65; Iter    74/  229] train: loss: 0.1329161
[Epoch 65; Iter   104/  229] train: loss: 0.1571363
[Epoch 65; Iter   134/  229] train: loss: 0.1352583
[Epoch 65; Iter   164/  229] train: loss: 0.1514453
[Epoch 65; Iter   194/  229] train: loss: 0.1070005
[Epoch 65; Iter   224/  229] train: loss: 0.1381272
[Epoch 65] ogbg-moltoxcast: 0.684852 val loss: 0.254547
[Epoch 65] ogbg-moltoxcast: 0.654198 test loss: 0.310216
[Epoch 66; Iter    25/  229] train: loss: 0.1281703
[Epoch 66; Iter    55/  229] train: loss: 0.1739730
[Epoch 66; Iter    85/  229] train: loss: 0.1421374
[Epoch 66; Iter   115/  229] train: loss: 0.1088876
[Epoch 66; Iter   145/  229] train: loss: 0.1072360
[Epoch 66; Iter   175/  229] train: loss: 0.1399460
[Epoch 66; Iter   205/  229] train: loss: 0.1124524
[Epoch 66] ogbg-moltoxcast: 0.685684 val loss: 0.259166
[Epoch 66] ogbg-moltoxcast: 0.656508 test loss: 0.313346
[Epoch 67; Iter     6/  229] train: loss: 0.1290088
[Epoch 67; Iter    36/  229] train: loss: 0.1683424
[Epoch 67; Iter    66/  229] train: loss: 0.1048797
[Epoch 67; Iter    96/  229] train: loss: 0.1675260
[Epoch 67; Iter   126/  229] train: loss: 0.1026081
[Epoch 67; Iter   156/  229] train: loss: 0.1077759
[Epoch 67; Iter   186/  229] train: loss: 0.1150608
[Epoch 67; Iter   216/  229] train: loss: 0.1025967
[Epoch 67] ogbg-moltoxcast: 0.678974 val loss: 0.261885
[Epoch 67] ogbg-moltoxcast: 0.655246 test loss: 0.316366
[Epoch 68; Iter    17/  229] train: loss: 0.1691435
[Epoch 68; Iter    47/  229] train: loss: 0.1243700
[Epoch 68; Iter    77/  229] train: loss: 0.1213830
[Epoch 68; Iter   107/  229] train: loss: 0.1642774
[Epoch 68; Iter   137/  229] train: loss: 0.1151263
[Epoch 68; Iter   167/  229] train: loss: 0.1108818
[Epoch 68; Iter   197/  229] train: loss: 0.1487078
[Epoch 68; Iter   227/  229] train: loss: 0.1477743
[Epoch 68] ogbg-moltoxcast: 0.688982 val loss: 0.259294
[Epoch 68] ogbg-moltoxcast: 0.655333 test loss: 0.314659
[Epoch 69; Iter    28/  229] train: loss: 0.1424959
[Epoch 69; Iter    58/  229] train: loss: 0.1054494
[Epoch 69; Iter    88/  229] train: loss: 0.1151464
[Epoch 69; Iter   118/  229] train: loss: 0.1195716
[Epoch 69; Iter   148/  229] train: loss: 0.1025848
[Epoch 69; Iter   178/  229] train: loss: 0.1887815
[Epoch 69; Iter   208/  229] train: loss: 0.1244397
[Epoch 69] ogbg-moltoxcast: 0.685582 val loss: 0.260519
[Epoch 69] ogbg-moltoxcast: 0.655582 test loss: 0.316679
[Epoch 70; Iter     9/  229] train: loss: 0.1082053
[Epoch 70; Iter    39/  229] train: loss: 0.1419025
[Epoch 70; Iter    69/  229] train: loss: 0.1384309
[Epoch 70; Iter    99/  229] train: loss: 0.1718381
[Epoch 70; Iter   129/  229] train: loss: 0.1158808
[Epoch 70; Iter   159/  229] train: loss: 0.1510746
[Epoch 70; Iter   189/  229] train: loss: 0.1767546
[Epoch 70; Iter   219/  229] train: loss: 0.1516947
[Epoch 70] ogbg-moltoxcast: 0.683285 val loss: 0.258649
[Epoch 70] ogbg-moltoxcast: 0.655405 test loss: 0.314692
[Epoch 71; Iter    20/  229] train: loss: 0.1088294
[Epoch 71; Iter    50/  229] train: loss: 0.1031811
[Epoch 71; Iter    80/  229] train: loss: 0.1451498
[Epoch 71; Iter   110/  229] train: loss: 0.1220371
[Epoch 71; Iter   140/  229] train: loss: 0.1034518
[Epoch 71; Iter   170/  229] train: loss: 0.1376594
[Epoch 71; Iter   200/  229] train: loss: 0.1267135
[Epoch 71] ogbg-moltoxcast: 0.682516 val loss: 0.259943
[Epoch 71] ogbg-moltoxcast: 0.655701 test loss: 0.315653
[Epoch 72; Iter     1/  229] train: loss: 0.1026868
[Epoch 72; Iter    31/  229] train: loss: 0.1003955
[Epoch 72; Iter    61/  229] train: loss: 0.1260341
[Epoch 72; Iter    91/  229] train: loss: 0.1389763
[Epoch 72; Iter   121/  229] train: loss: 0.1223308
[Epoch 72; Iter   151/  229] train: loss: 0.1504363
[Epoch 72; Iter   181/  229] train: loss: 0.1130560
[Epoch 72; Iter   211/  229] train: loss: 0.1322313
[Epoch 72] ogbg-moltoxcast: 0.688132 val loss: 0.260360
[Epoch 72] ogbg-moltoxcast: 0.659121 test loss: 0.316767
[Epoch 73; Iter    12/  229] train: loss: 0.1703646
[Epoch 73; Iter    42/  229] train: loss: 0.1124118
[Epoch 73; Iter    72/  229] train: loss: 0.0964869
[Epoch 73; Iter   102/  229] train: loss: 0.1426025
[Epoch 73; Iter   132/  229] train: loss: 0.1786963
[Epoch 73; Iter   162/  229] train: loss: 0.1357175
[Epoch 73; Iter   192/  229] train: loss: 0.1277319
[Epoch 73; Iter   222/  229] train: loss: 0.1380274
[Epoch 73] ogbg-moltoxcast: 0.685735 val loss: 0.260246
[Epoch 73] ogbg-moltoxcast: 0.656402 test loss: 0.316808
[Epoch 74; Iter    23/  229] train: loss: 0.0869801
[Epoch 74; Iter    53/  229] train: loss: 0.1854784
[Epoch 74; Iter    83/  229] train: loss: 0.0936158
[Epoch 74; Iter   113/  229] train: loss: 0.1537640
[Epoch 74; Iter   143/  229] train: loss: 0.1822363
[Epoch 74; Iter   173/  229] train: loss: 0.0861708
[Epoch 74; Iter   203/  229] train: loss: 0.1125527
[Epoch 74] ogbg-moltoxcast: 0.688582 val loss: 0.261269
[Epoch 74] ogbg-moltoxcast: 0.658463 test loss: 0.316538
[Epoch 75; Iter     4/  229] train: loss: 0.0946210
[Epoch 75; Iter    34/  229] train: loss: 0.1537311
[Epoch 75; Iter    64/  229] train: loss: 0.0990167
[Epoch 75; Iter    94/  229] train: loss: 0.1516079
[Epoch 75; Iter   124/  229] train: loss: 0.1555226
[Epoch 75; Iter   154/  229] train: loss: 0.1055367
[Epoch 75; Iter   184/  229] train: loss: 0.1424913
[Epoch 75; Iter   214/  229] train: loss: 0.1140783
[Epoch 75] ogbg-moltoxcast: 0.686408 val loss: 0.261751
[Epoch 75] ogbg-moltoxcast: 0.653681 test loss: 0.318163
[Epoch 60; Iter    19/  229] train: loss: 0.1099921
[Epoch 60; Iter    49/  229] train: loss: 0.1190412
[Epoch 60; Iter    79/  229] train: loss: 0.2128718
[Epoch 60; Iter   109/  229] train: loss: 0.2345738
[Epoch 60; Iter   139/  229] train: loss: 0.1665155
[Epoch 60; Iter   169/  229] train: loss: 0.1362116
[Epoch 60; Iter   199/  229] train: loss: 0.1879650
[Epoch 60; Iter   229/  229] train: loss: 0.1376235
[Epoch 60] ogbg-moltoxcast: 0.709020 val loss: 0.254708
[Epoch 60] ogbg-moltoxcast: 0.665184 test loss: 0.316016
[Epoch 61; Iter    30/  229] train: loss: 0.1490174
[Epoch 61; Iter    60/  229] train: loss: 0.1598053
[Epoch 61; Iter    90/  229] train: loss: 0.0900810
[Epoch 61; Iter   120/  229] train: loss: 0.0899123
[Epoch 61; Iter   150/  229] train: loss: 0.1511897
[Epoch 61; Iter   180/  229] train: loss: 0.1136535
[Epoch 61; Iter   210/  229] train: loss: 0.1086272
[Epoch 61] ogbg-moltoxcast: 0.707053 val loss: 0.253894
[Epoch 61] ogbg-moltoxcast: 0.665921 test loss: 0.317237
[Epoch 62; Iter    11/  229] train: loss: 0.1188066
[Epoch 62; Iter    41/  229] train: loss: 0.1444927
[Epoch 62; Iter    71/  229] train: loss: 0.1033047
[Epoch 62; Iter   101/  229] train: loss: 0.1157144
[Epoch 62; Iter   131/  229] train: loss: 0.1016669
[Epoch 62; Iter   161/  229] train: loss: 0.1278751
[Epoch 62; Iter   191/  229] train: loss: 0.1218869
[Epoch 62; Iter   221/  229] train: loss: 0.1223307
[Epoch 62] ogbg-moltoxcast: 0.710236 val loss: 0.249181
[Epoch 62] ogbg-moltoxcast: 0.664388 test loss: 0.310442
[Epoch 63; Iter    22/  229] train: loss: 0.1592142
[Epoch 63; Iter    52/  229] train: loss: 0.1497962
[Epoch 63; Iter    82/  229] train: loss: 0.1019524
[Epoch 63; Iter   112/  229] train: loss: 0.1354769
[Epoch 63; Iter   142/  229] train: loss: 0.1156632
[Epoch 63; Iter   172/  229] train: loss: 0.1698044
[Epoch 63; Iter   202/  229] train: loss: 0.0926142
[Epoch 63] ogbg-moltoxcast: 0.706435 val loss: 0.251204
[Epoch 63] ogbg-moltoxcast: 0.663080 test loss: 0.318888
[Epoch 64; Iter     3/  229] train: loss: 0.2212563
[Epoch 64; Iter    33/  229] train: loss: 0.1370540
[Epoch 64; Iter    63/  229] train: loss: 0.1878992
[Epoch 64; Iter    93/  229] train: loss: 0.2000694
[Epoch 64; Iter   123/  229] train: loss: 0.1518912
[Epoch 64; Iter   153/  229] train: loss: 0.1530811
[Epoch 64; Iter   183/  229] train: loss: 0.1791263
[Epoch 64; Iter   213/  229] train: loss: 0.1032433
[Epoch 64] ogbg-moltoxcast: 0.710158 val loss: 0.253874
[Epoch 64] ogbg-moltoxcast: 0.668651 test loss: 0.313856
[Epoch 65; Iter    14/  229] train: loss: 0.1094045
[Epoch 65; Iter    44/  229] train: loss: 0.1324168
[Epoch 65; Iter    74/  229] train: loss: 0.1289077
[Epoch 65; Iter   104/  229] train: loss: 0.1474789
[Epoch 65; Iter   134/  229] train: loss: 0.0979341
[Epoch 65; Iter   164/  229] train: loss: 0.1397663
[Epoch 65; Iter   194/  229] train: loss: 0.1026416
[Epoch 65; Iter   224/  229] train: loss: 0.1507098
[Epoch 65] ogbg-moltoxcast: 0.711195 val loss: 0.252135
[Epoch 65] ogbg-moltoxcast: 0.668156 test loss: 0.317867
[Epoch 66; Iter    25/  229] train: loss: 0.1284545
[Epoch 66; Iter    55/  229] train: loss: 0.1751517
[Epoch 66; Iter    85/  229] train: loss: 0.1013360
[Epoch 66; Iter   115/  229] train: loss: 0.1523867
[Epoch 66; Iter   145/  229] train: loss: 0.1167764
[Epoch 66; Iter   175/  229] train: loss: 0.1051149
[Epoch 66; Iter   205/  229] train: loss: 0.1582157
[Epoch 66] ogbg-moltoxcast: 0.710587 val loss: 0.255727
[Epoch 66] ogbg-moltoxcast: 0.666199 test loss: 0.315337
[Epoch 67; Iter     6/  229] train: loss: 0.0819014
[Epoch 67; Iter    36/  229] train: loss: 0.1116829
[Epoch 67; Iter    66/  229] train: loss: 0.1702456
[Epoch 67; Iter    96/  229] train: loss: 0.1232685
[Epoch 67; Iter   126/  229] train: loss: 0.1598234
[Epoch 67; Iter   156/  229] train: loss: 0.1083264
[Epoch 67; Iter   186/  229] train: loss: 0.1218300
[Epoch 67; Iter   216/  229] train: loss: 0.1087999
[Epoch 67] ogbg-moltoxcast: 0.708565 val loss: 0.254229
[Epoch 67] ogbg-moltoxcast: 0.662071 test loss: 0.317838
[Epoch 68; Iter    17/  229] train: loss: 0.1376919
[Epoch 68; Iter    47/  229] train: loss: 0.1308859
[Epoch 68; Iter    77/  229] train: loss: 0.2129191
[Epoch 68; Iter   107/  229] train: loss: 0.1231220
[Epoch 68; Iter   137/  229] train: loss: 0.1160984
[Epoch 68; Iter   167/  229] train: loss: 0.1513720
[Epoch 68; Iter   197/  229] train: loss: 0.1321580
[Epoch 68; Iter   227/  229] train: loss: 0.1404772
[Epoch 68] ogbg-moltoxcast: 0.706514 val loss: 0.257782
[Epoch 68] ogbg-moltoxcast: 0.665063 test loss: 0.319519
[Epoch 69; Iter    28/  229] train: loss: 0.1598435
[Epoch 69; Iter    58/  229] train: loss: 0.1583880
[Epoch 69; Iter    88/  229] train: loss: 0.1513832
[Epoch 69; Iter   118/  229] train: loss: 0.2002066
[Epoch 69; Iter   148/  229] train: loss: 0.1758639
[Epoch 69; Iter   178/  229] train: loss: 0.0987365
[Epoch 69; Iter   208/  229] train: loss: 0.1037118
[Epoch 69] ogbg-moltoxcast: 0.710941 val loss: 0.252735
[Epoch 69] ogbg-moltoxcast: 0.661164 test loss: 0.319428
[Epoch 70; Iter     9/  229] train: loss: 0.1602236
[Epoch 70; Iter    39/  229] train: loss: 0.1364197
[Epoch 70; Iter    69/  229] train: loss: 0.1358654
[Epoch 70; Iter    99/  229] train: loss: 0.1835765
[Epoch 70; Iter   129/  229] train: loss: 0.1582429
[Epoch 70; Iter   159/  229] train: loss: 0.1218165
[Epoch 70; Iter   189/  229] train: loss: 0.1165112
[Epoch 70; Iter   219/  229] train: loss: 0.1978544
[Epoch 70] ogbg-moltoxcast: 0.706338 val loss: 0.256794
[Epoch 70] ogbg-moltoxcast: 0.664108 test loss: 0.317509
[Epoch 71; Iter    20/  229] train: loss: 0.1313213
[Epoch 71; Iter    50/  229] train: loss: 0.1059954
[Epoch 71; Iter    80/  229] train: loss: 0.1516108
[Epoch 71; Iter   110/  229] train: loss: 0.1487679
[Epoch 71; Iter   140/  229] train: loss: 0.1394542
[Epoch 71; Iter   170/  229] train: loss: 0.1654184
[Epoch 71; Iter   200/  229] train: loss: 0.1404025
[Epoch 71] ogbg-moltoxcast: 0.700654 val loss: 0.257242
[Epoch 71] ogbg-moltoxcast: 0.661607 test loss: 0.319315
[Epoch 72; Iter     1/  229] train: loss: 0.1430777
[Epoch 72; Iter    31/  229] train: loss: 0.1409892
[Epoch 72; Iter    61/  229] train: loss: 0.1722557
[Epoch 72; Iter    91/  229] train: loss: 0.1064769
[Epoch 72; Iter   121/  229] train: loss: 0.0937792
[Epoch 72; Iter   151/  229] train: loss: 0.1548757
[Epoch 72; Iter   181/  229] train: loss: 0.1874063
[Epoch 72; Iter   211/  229] train: loss: 0.0971230
[Epoch 72] ogbg-moltoxcast: 0.703987 val loss: 0.258034
[Epoch 72] ogbg-moltoxcast: 0.667036 test loss: 0.320563
[Epoch 73; Iter    12/  229] train: loss: 0.1047672
[Epoch 73; Iter    42/  229] train: loss: 0.1423348
[Epoch 73; Iter    72/  229] train: loss: 0.1639055
[Epoch 73; Iter   102/  229] train: loss: 0.1429035
[Epoch 73; Iter   132/  229] train: loss: 0.1235258
[Epoch 73; Iter   162/  229] train: loss: 0.1455490
[Epoch 73; Iter   192/  229] train: loss: 0.1089184
[Epoch 73; Iter   222/  229] train: loss: 0.1255001
[Epoch 73] ogbg-moltoxcast: 0.703036 val loss: 0.255773
[Epoch 73] ogbg-moltoxcast: 0.659366 test loss: 0.317921
[Epoch 74; Iter    23/  229] train: loss: 0.0896057
[Epoch 74; Iter    53/  229] train: loss: 0.1419527
[Epoch 74; Iter    83/  229] train: loss: 0.1208485
[Epoch 74; Iter   113/  229] train: loss: 0.0960248
[Epoch 74; Iter   143/  229] train: loss: 0.1286596
[Epoch 74; Iter   173/  229] train: loss: 0.1419309
[Epoch 74; Iter   203/  229] train: loss: 0.1449791
[Epoch 74] ogbg-moltoxcast: 0.707118 val loss: 0.254444
[Epoch 74] ogbg-moltoxcast: 0.658387 test loss: 0.322066
[Epoch 75; Iter     4/  229] train: loss: 0.0917617
[Epoch 75; Iter    34/  229] train: loss: 0.1554049
[Epoch 75; Iter    64/  229] train: loss: 0.1788585
[Epoch 75; Iter    94/  229] train: loss: 0.1276556
[Epoch 75; Iter   124/  229] train: loss: 0.1319753
[Epoch 75; Iter   154/  229] train: loss: 0.1216711
[Epoch 75; Iter   184/  229] train: loss: 0.1838097
[Epoch 75; Iter   214/  229] train: loss: 0.1300469
[Epoch 75] ogbg-moltoxcast: 0.702045 val loss: 0.258537
[Epoch 75] ogbg-moltoxcast: 0.663171 test loss: 0.323518
[Epoch 60; Iter    19/  229] train: loss: 0.1616720
[Epoch 60; Iter    49/  229] train: loss: 0.1280204
[Epoch 60; Iter    79/  229] train: loss: 0.1117926
[Epoch 60; Iter   109/  229] train: loss: 0.1393614
[Epoch 60; Iter   139/  229] train: loss: 0.1369755
[Epoch 60; Iter   169/  229] train: loss: 0.1901086
[Epoch 60; Iter   199/  229] train: loss: 0.1060710
[Epoch 60; Iter   229/  229] train: loss: 0.1274733
[Epoch 60] ogbg-moltoxcast: 0.689530 val loss: 0.468651
[Epoch 60] ogbg-moltoxcast: 0.653481 test loss: 0.311923
[Epoch 61; Iter    30/  229] train: loss: 0.1299683
[Epoch 61; Iter    60/  229] train: loss: 0.1625297
[Epoch 61; Iter    90/  229] train: loss: 0.1128486
[Epoch 61; Iter   120/  229] train: loss: 0.1451839
[Epoch 61; Iter   150/  229] train: loss: 0.1143902
[Epoch 61; Iter   180/  229] train: loss: 0.1865575
[Epoch 61; Iter   210/  229] train: loss: 0.1209695
[Epoch 61] ogbg-moltoxcast: 0.688566 val loss: 0.402557
[Epoch 61] ogbg-moltoxcast: 0.656414 test loss: 0.405428
[Epoch 62; Iter    11/  229] train: loss: 0.1208001
[Epoch 62; Iter    41/  229] train: loss: 0.1785457
[Epoch 62; Iter    71/  229] train: loss: 0.1644529
[Epoch 62; Iter   101/  229] train: loss: 0.2004635
[Epoch 62; Iter   131/  229] train: loss: 0.1175773
[Epoch 62; Iter   161/  229] train: loss: 0.1322856
[Epoch 62; Iter   191/  229] train: loss: 0.0923383
[Epoch 62; Iter   221/  229] train: loss: 0.2018590
[Epoch 62] ogbg-moltoxcast: 0.693225 val loss: 0.334760
[Epoch 62] ogbg-moltoxcast: 0.664775 test loss: 0.312607
[Epoch 63; Iter    22/  229] train: loss: 0.1166462
[Epoch 63; Iter    52/  229] train: loss: 0.1267895
[Epoch 63; Iter    82/  229] train: loss: 0.0803822
[Epoch 63; Iter   112/  229] train: loss: 0.1289496
[Epoch 63; Iter   142/  229] train: loss: 0.1712644
[Epoch 63; Iter   172/  229] train: loss: 0.1823416
[Epoch 63; Iter   202/  229] train: loss: 0.1088022
[Epoch 63] ogbg-moltoxcast: 0.692879 val loss: 0.294562
[Epoch 63] ogbg-moltoxcast: 0.661466 test loss: 0.477927
[Epoch 64; Iter     3/  229] train: loss: 0.1455152
[Epoch 64; Iter    33/  229] train: loss: 0.1545881
[Epoch 64; Iter    63/  229] train: loss: 0.1237223
[Epoch 64; Iter    93/  229] train: loss: 0.1257102
[Epoch 64; Iter   123/  229] train: loss: 0.1440963
[Epoch 64; Iter   153/  229] train: loss: 0.1423707
[Epoch 64; Iter   183/  229] train: loss: 0.1785187
[Epoch 64; Iter   213/  229] train: loss: 0.1184471
[Epoch 64] ogbg-moltoxcast: 0.688562 val loss: 0.292632
[Epoch 64] ogbg-moltoxcast: 0.661953 test loss: 0.412567
[Epoch 65; Iter    14/  229] train: loss: 0.0963105
[Epoch 65; Iter    44/  229] train: loss: 0.1064496
[Epoch 65; Iter    74/  229] train: loss: 0.1042750
[Epoch 65; Iter   104/  229] train: loss: 0.1228904
[Epoch 65; Iter   134/  229] train: loss: 0.1941868
[Epoch 65; Iter   164/  229] train: loss: 0.1635873
[Epoch 65; Iter   194/  229] train: loss: 0.1344326
[Epoch 65; Iter   224/  229] train: loss: 0.2093440
[Epoch 65] ogbg-moltoxcast: 0.689668 val loss: 0.492953
[Epoch 65] ogbg-moltoxcast: 0.665031 test loss: 0.316347
[Epoch 66; Iter    25/  229] train: loss: 0.0979804
[Epoch 66; Iter    55/  229] train: loss: 0.1045582
[Epoch 66; Iter    85/  229] train: loss: 0.1571945
[Epoch 66; Iter   115/  229] train: loss: 0.1877884
[Epoch 66; Iter   145/  229] train: loss: 0.1336353
[Epoch 66; Iter   175/  229] train: loss: 0.1584464
[Epoch 66; Iter   205/  229] train: loss: 0.1717913
[Epoch 66] ogbg-moltoxcast: 0.691585 val loss: 0.533737
[Epoch 66] ogbg-moltoxcast: 0.659492 test loss: 0.320012
[Epoch 67; Iter     6/  229] train: loss: 0.1494506
[Epoch 67; Iter    36/  229] train: loss: 0.1631959
[Epoch 67; Iter    66/  229] train: loss: 0.1179583
[Epoch 67; Iter    96/  229] train: loss: 0.1223024
[Epoch 67; Iter   126/  229] train: loss: 0.1627429
[Epoch 67; Iter   156/  229] train: loss: 0.1645665
[Epoch 67; Iter   186/  229] train: loss: 0.1631514
[Epoch 67; Iter   216/  229] train: loss: 0.1484855
[Epoch 67] ogbg-moltoxcast: 0.689528 val loss: 0.275016
[Epoch 67] ogbg-moltoxcast: 0.663402 test loss: 0.324980
[Epoch 68; Iter    17/  229] train: loss: 0.1820945
[Epoch 68; Iter    47/  229] train: loss: 0.1164039
[Epoch 68; Iter    77/  229] train: loss: 0.1135365
[Epoch 68; Iter   107/  229] train: loss: 0.1256768
[Epoch 68; Iter   137/  229] train: loss: 0.1120321
[Epoch 68; Iter   167/  229] train: loss: 0.1127762
[Epoch 68; Iter   197/  229] train: loss: 0.1397020
[Epoch 68; Iter   227/  229] train: loss: 0.1304315
[Epoch 68] ogbg-moltoxcast: 0.688136 val loss: 0.470124
[Epoch 68] ogbg-moltoxcast: 0.661549 test loss: 0.320608
[Epoch 69; Iter    28/  229] train: loss: 0.1439070
[Epoch 69; Iter    58/  229] train: loss: 0.1756947
[Epoch 69; Iter    88/  229] train: loss: 0.1073293
[Epoch 69; Iter   118/  229] train: loss: 0.0957218
[Epoch 69; Iter   148/  229] train: loss: 0.1606136
[Epoch 69; Iter   178/  229] train: loss: 0.1690034
[Epoch 69; Iter   208/  229] train: loss: 0.1006888
[Epoch 69] ogbg-moltoxcast: 0.689047 val loss: 0.272027
[Epoch 69] ogbg-moltoxcast: 0.663649 test loss: 0.325686
[Epoch 70; Iter     9/  229] train: loss: 0.1034200
[Epoch 70; Iter    39/  229] train: loss: 0.1161763
[Epoch 70; Iter    69/  229] train: loss: 0.1262751
[Epoch 70; Iter    99/  229] train: loss: 0.1590945
[Epoch 70; Iter   129/  229] train: loss: 0.1310725
[Epoch 70; Iter   159/  229] train: loss: 0.1367787
[Epoch 70; Iter   189/  229] train: loss: 0.1520699
[Epoch 70; Iter   219/  229] train: loss: 0.1356734
[Epoch 70] ogbg-moltoxcast: 0.685546 val loss: 0.300816
[Epoch 70] ogbg-moltoxcast: 0.660883 test loss: 0.358634
[Epoch 71; Iter    20/  229] train: loss: 0.1495708
[Epoch 71; Iter    50/  229] train: loss: 0.1441018
[Epoch 71; Iter    80/  229] train: loss: 0.1045041
[Epoch 71; Iter   110/  229] train: loss: 0.1568082
[Epoch 71; Iter   140/  229] train: loss: 0.1292531
[Epoch 71; Iter   170/  229] train: loss: 0.0912827
[Epoch 71; Iter   200/  229] train: loss: 0.1236364
[Epoch 71] ogbg-moltoxcast: 0.690962 val loss: 0.271094
[Epoch 71] ogbg-moltoxcast: 0.663096 test loss: 0.322798
[Epoch 72; Iter     1/  229] train: loss: 0.1287326
[Epoch 72; Iter    31/  229] train: loss: 0.1780591
[Epoch 72; Iter    61/  229] train: loss: 0.1361951
[Epoch 72; Iter    91/  229] train: loss: 0.1504448
[Epoch 72; Iter   121/  229] train: loss: 0.1675638
[Epoch 72; Iter   151/  229] train: loss: 0.1800429
[Epoch 72; Iter   181/  229] train: loss: 0.1275600
[Epoch 72; Iter   211/  229] train: loss: 0.1434219
[Epoch 72] ogbg-moltoxcast: 0.686667 val loss: 0.438288
[Epoch 72] ogbg-moltoxcast: 0.661857 test loss: 0.325294
[Epoch 73; Iter    12/  229] train: loss: 0.1238235
[Epoch 73; Iter    42/  229] train: loss: 0.1823288
[Epoch 73; Iter    72/  229] train: loss: 0.1828760
[Epoch 73; Iter   102/  229] train: loss: 0.1313155
[Epoch 73; Iter   132/  229] train: loss: 0.1482026
[Epoch 73; Iter   162/  229] train: loss: 0.1398705
[Epoch 73; Iter   192/  229] train: loss: 0.1196356
[Epoch 73; Iter   222/  229] train: loss: 0.1299195
[Epoch 73] ogbg-moltoxcast: 0.685163 val loss: 0.282998
[Epoch 73] ogbg-moltoxcast: 0.659947 test loss: 0.318920
[Epoch 74; Iter    23/  229] train: loss: 0.1337802
[Epoch 74; Iter    53/  229] train: loss: 0.1277041
[Epoch 74; Iter    83/  229] train: loss: 0.0980101
[Epoch 74; Iter   113/  229] train: loss: 0.1164126
[Epoch 74; Iter   143/  229] train: loss: 0.1745712
[Epoch 74; Iter   173/  229] train: loss: 0.1092738
[Epoch 74; Iter   203/  229] train: loss: 0.0942929
[Epoch 74] ogbg-moltoxcast: 0.694734 val loss: 0.276469
[Epoch 74] ogbg-moltoxcast: 0.664006 test loss: 0.325323
[Epoch 75; Iter     4/  229] train: loss: 0.0985862
[Epoch 75; Iter    34/  229] train: loss: 0.1572416
[Epoch 75; Iter    64/  229] train: loss: 0.1462258
[Epoch 75; Iter    94/  229] train: loss: 0.1249043
[Epoch 75; Iter   124/  229] train: loss: 0.1354686
[Epoch 75; Iter   154/  229] train: loss: 0.1488487
[Epoch 75; Iter   184/  229] train: loss: 0.1367741
[Epoch 75; Iter   214/  229] train: loss: 0.1303393
[Epoch 75] ogbg-moltoxcast: 0.688211 val loss: 0.270529
[Epoch 75] ogbg-moltoxcast: 0.659320 test loss: 0.318418
[Epoch 66; Iter   105/  201] train: loss: 0.1500017
[Epoch 66; Iter   135/  201] train: loss: 0.1076351
[Epoch 66; Iter   165/  201] train: loss: 0.2184510
[Epoch 66; Iter   195/  201] train: loss: 0.1168996
[Epoch 66] ogbg-moltoxcast: 0.678589 val loss: 0.274612
[Epoch 66] ogbg-moltoxcast: 0.658143 test loss: 0.315074
[Epoch 67; Iter    24/  201] train: loss: 0.1321941
[Epoch 67; Iter    54/  201] train: loss: 0.1515903
[Epoch 67; Iter    84/  201] train: loss: 0.1542678
[Epoch 67; Iter   114/  201] train: loss: 0.1295748
[Epoch 67; Iter   144/  201] train: loss: 0.1653616
[Epoch 67; Iter   174/  201] train: loss: 0.0934845
[Epoch 67] ogbg-moltoxcast: 0.679918 val loss: 0.275087
[Epoch 67] ogbg-moltoxcast: 0.660110 test loss: 0.317782
[Epoch 68; Iter     3/  201] train: loss: 0.1158252
[Epoch 68; Iter    33/  201] train: loss: 0.1125217
[Epoch 68; Iter    63/  201] train: loss: 0.1173713
[Epoch 68; Iter    93/  201] train: loss: 0.1277731
[Epoch 68; Iter   123/  201] train: loss: 0.1266105
[Epoch 68; Iter   153/  201] train: loss: 0.1362299
[Epoch 68; Iter   183/  201] train: loss: 0.1283193
[Epoch 68] ogbg-moltoxcast: 0.677891 val loss: 0.272681
[Epoch 68] ogbg-moltoxcast: 0.666572 test loss: 0.311979
[Epoch 69; Iter    12/  201] train: loss: 0.1752288
[Epoch 69; Iter    42/  201] train: loss: 0.1024509
[Epoch 69; Iter    72/  201] train: loss: 0.1411173
[Epoch 69; Iter   102/  201] train: loss: 0.1130230
[Epoch 69; Iter   132/  201] train: loss: 0.1099567
[Epoch 69; Iter   162/  201] train: loss: 0.1319738
[Epoch 69; Iter   192/  201] train: loss: 0.0706242
[Epoch 69] ogbg-moltoxcast: 0.678970 val loss: 0.272629
[Epoch 69] ogbg-moltoxcast: 0.664585 test loss: 0.311819
[Epoch 70; Iter    21/  201] train: loss: 0.1243597
[Epoch 70; Iter    51/  201] train: loss: 0.1093098
[Epoch 70; Iter    81/  201] train: loss: 0.1222460
[Epoch 70; Iter   111/  201] train: loss: 0.0919007
[Epoch 70; Iter   141/  201] train: loss: 0.1703817
[Epoch 70; Iter   171/  201] train: loss: 0.1498687
[Epoch 70; Iter   201/  201] train: loss: 0.3237771
[Epoch 70] ogbg-moltoxcast: 0.673981 val loss: 0.281455
[Epoch 70] ogbg-moltoxcast: 0.663062 test loss: 0.316984
[Epoch 71; Iter    30/  201] train: loss: 0.1216490
[Epoch 71; Iter    60/  201] train: loss: 0.1143087
[Epoch 71; Iter    90/  201] train: loss: 0.1260107
[Epoch 71; Iter   120/  201] train: loss: 0.1096453
[Epoch 71; Iter   150/  201] train: loss: 0.1560124
[Epoch 71; Iter   180/  201] train: loss: 0.0764435
[Epoch 71] ogbg-moltoxcast: 0.678650 val loss: 0.272503
[Epoch 71] ogbg-moltoxcast: 0.662223 test loss: 0.311926
[Epoch 72; Iter     9/  201] train: loss: 0.1170651
[Epoch 72; Iter    39/  201] train: loss: 0.1126774
[Epoch 72; Iter    69/  201] train: loss: 0.1289560
[Epoch 72; Iter    99/  201] train: loss: 0.1087056
[Epoch 72; Iter   129/  201] train: loss: 0.1354505
[Epoch 72; Iter   159/  201] train: loss: 0.1736308
[Epoch 72; Iter   189/  201] train: loss: 0.1991993
[Epoch 72] ogbg-moltoxcast: 0.680548 val loss: 0.269926
[Epoch 72] ogbg-moltoxcast: 0.662719 test loss: 0.313019
[Epoch 73; Iter    18/  201] train: loss: 0.1295311
[Epoch 73; Iter    48/  201] train: loss: 0.1160936
[Epoch 73; Iter    78/  201] train: loss: 0.1202475
[Epoch 73; Iter   108/  201] train: loss: 0.0842590
[Epoch 73; Iter   138/  201] train: loss: 0.1049844
[Epoch 73; Iter   168/  201] train: loss: 0.1128988
[Epoch 73; Iter   198/  201] train: loss: 0.1034119
[Epoch 73] ogbg-moltoxcast: 0.671062 val loss: 0.283833
[Epoch 73] ogbg-moltoxcast: 0.653958 test loss: 0.326052
[Epoch 74; Iter    27/  201] train: loss: 0.1168939
[Epoch 74; Iter    57/  201] train: loss: 0.1113365
[Epoch 74; Iter    87/  201] train: loss: 0.1011922
[Epoch 74; Iter   117/  201] train: loss: 0.1576091
[Epoch 74; Iter   147/  201] train: loss: 0.1756811
[Epoch 74; Iter   177/  201] train: loss: 0.1025141
[Epoch 74] ogbg-moltoxcast: 0.676948 val loss: 0.273370
[Epoch 74] ogbg-moltoxcast: 0.660813 test loss: 0.311236
[Epoch 75; Iter     6/  201] train: loss: 0.0994444
[Epoch 75; Iter    36/  201] train: loss: 0.1074490
[Epoch 75; Iter    66/  201] train: loss: 0.1354006
[Epoch 75; Iter    96/  201] train: loss: 0.2089031
[Epoch 75; Iter   126/  201] train: loss: 0.1617394
[Epoch 75; Iter   156/  201] train: loss: 0.1630688
[Epoch 75; Iter   186/  201] train: loss: 0.1385558
[Epoch 75] ogbg-moltoxcast: 0.677415 val loss: 0.277593
[Epoch 75] ogbg-moltoxcast: 0.659604 test loss: 0.316860
[Epoch 76; Iter    15/  201] train: loss: 0.1831657
[Epoch 76; Iter    45/  201] train: loss: 0.1447312
[Epoch 76; Iter    75/  201] train: loss: 0.1221225
[Epoch 76; Iter   105/  201] train: loss: 0.1264232
[Epoch 76; Iter   135/  201] train: loss: 0.1573877
[Epoch 76; Iter   165/  201] train: loss: 0.0729262
[Epoch 76; Iter   195/  201] train: loss: 0.1355193
[Epoch 76] ogbg-moltoxcast: 0.676496 val loss: 0.272411
[Epoch 76] ogbg-moltoxcast: 0.658103 test loss: 0.310699
[Epoch 77; Iter    24/  201] train: loss: 0.1343385
[Epoch 77; Iter    54/  201] train: loss: 0.1385638
[Epoch 77; Iter    84/  201] train: loss: 0.1305892
[Epoch 77; Iter   114/  201] train: loss: 0.0873498
[Epoch 77; Iter   144/  201] train: loss: 0.1667001
[Epoch 77; Iter   174/  201] train: loss: 0.2024613
[Epoch 77] ogbg-moltoxcast: 0.672734 val loss: 0.273159
[Epoch 77] ogbg-moltoxcast: 0.660370 test loss: 0.314894
[Epoch 78; Iter     3/  201] train: loss: 0.1842804
[Epoch 78; Iter    33/  201] train: loss: 0.1277551
[Epoch 78; Iter    63/  201] train: loss: 0.1578983
[Epoch 78; Iter    93/  201] train: loss: 0.1196567
[Epoch 78; Iter   123/  201] train: loss: 0.1525951
[Epoch 78; Iter   153/  201] train: loss: 0.1038993
[Epoch 78; Iter   183/  201] train: loss: 0.1637665
[Epoch 78] ogbg-moltoxcast: 0.673460 val loss: 0.280611
[Epoch 78] ogbg-moltoxcast: 0.663165 test loss: 0.318419
[Epoch 79; Iter    12/  201] train: loss: 0.1893679
[Epoch 79; Iter    42/  201] train: loss: 0.1158363
[Epoch 79; Iter    72/  201] train: loss: 0.1213108
[Epoch 79; Iter   102/  201] train: loss: 0.1090079
[Epoch 79; Iter   132/  201] train: loss: 0.1121873
[Epoch 79; Iter   162/  201] train: loss: 0.2116833
[Epoch 79; Iter   192/  201] train: loss: 0.1250778
[Epoch 79] ogbg-moltoxcast: 0.676120 val loss: 0.278148
[Epoch 79] ogbg-moltoxcast: 0.663167 test loss: 0.317144
[Epoch 80; Iter    21/  201] train: loss: 0.1370436
[Epoch 80; Iter    51/  201] train: loss: 0.1331057
[Epoch 80; Iter    81/  201] train: loss: 0.0858242
[Epoch 80; Iter   111/  201] train: loss: 0.1769027
[Epoch 80; Iter   141/  201] train: loss: 0.1468423
[Epoch 80; Iter   171/  201] train: loss: 0.0937193
[Epoch 80; Iter   201/  201] train: loss: 0.1376674
[Epoch 80] ogbg-moltoxcast: 0.676128 val loss: 0.279943
[Epoch 80] ogbg-moltoxcast: 0.664738 test loss: 0.321374
[Epoch 81; Iter    30/  201] train: loss: 0.1393211
[Epoch 81; Iter    60/  201] train: loss: 0.1387451
[Epoch 81; Iter    90/  201] train: loss: 0.1540156
[Epoch 81; Iter   120/  201] train: loss: 0.0914677
[Epoch 81; Iter   150/  201] train: loss: 0.1111199
[Epoch 81; Iter   180/  201] train: loss: 0.1280139
[Epoch 81] ogbg-moltoxcast: 0.675515 val loss: 0.276741
[Epoch 81] ogbg-moltoxcast: 0.660445 test loss: 0.316818
[Epoch 82; Iter     9/  201] train: loss: 0.1468907
[Epoch 82; Iter    39/  201] train: loss: 0.1166349
[Epoch 82; Iter    69/  201] train: loss: 0.1264213
[Epoch 82; Iter    99/  201] train: loss: 0.1353363
[Epoch 82; Iter   129/  201] train: loss: 0.0684689
[Epoch 82; Iter   159/  201] train: loss: 0.1013340
[Epoch 82; Iter   189/  201] train: loss: 0.1378697
[Epoch 82] ogbg-moltoxcast: 0.675684 val loss: 0.276278
[Epoch 82] ogbg-moltoxcast: 0.660862 test loss: 0.316656
[Epoch 83; Iter    18/  201] train: loss: 0.0886606
[Epoch 83; Iter    48/  201] train: loss: 0.1271761
[Epoch 83; Iter    78/  201] train: loss: 0.1134535
[Epoch 83; Iter   108/  201] train: loss: 0.1464918
[Epoch 83; Iter   138/  201] train: loss: 0.1646592
[Epoch 83; Iter   168/  201] train: loss: 0.0931954
[Epoch 83; Iter   198/  201] train: loss: 0.1267265
[Epoch 83] ogbg-moltoxcast: 0.679419 val loss: 0.274474
[Epoch 83] ogbg-moltoxcast: 0.662177 test loss: 0.317811
[Epoch 66; Iter   105/  201] train: loss: 0.0787549
[Epoch 66; Iter   135/  201] train: loss: 0.1097404
[Epoch 66; Iter   165/  201] train: loss: 0.1228067
[Epoch 66; Iter   195/  201] train: loss: 0.1538197
[Epoch 66] ogbg-moltoxcast: 0.671161 val loss: 0.287778
[Epoch 66] ogbg-moltoxcast: 0.658963 test loss: 0.401429
[Epoch 67; Iter    24/  201] train: loss: 0.2014853
[Epoch 67; Iter    54/  201] train: loss: 0.1341327
[Epoch 67; Iter    84/  201] train: loss: 0.1238730
[Epoch 67; Iter   114/  201] train: loss: 0.0943358
[Epoch 67; Iter   144/  201] train: loss: 0.1112902
[Epoch 67; Iter   174/  201] train: loss: 0.0936296
[Epoch 67] ogbg-moltoxcast: 0.671906 val loss: 0.270116
[Epoch 67] ogbg-moltoxcast: 0.659444 test loss: 0.309122
[Epoch 68; Iter     3/  201] train: loss: 0.1339336
[Epoch 68; Iter    33/  201] train: loss: 0.1147935
[Epoch 68; Iter    63/  201] train: loss: 0.1394416
[Epoch 68; Iter    93/  201] train: loss: 0.1632846
[Epoch 68; Iter   123/  201] train: loss: 0.0779676
[Epoch 68; Iter   153/  201] train: loss: 0.1467222
[Epoch 68; Iter   183/  201] train: loss: 0.2118022
[Epoch 68] ogbg-moltoxcast: 0.670601 val loss: 0.278236
[Epoch 68] ogbg-moltoxcast: 0.659363 test loss: 0.367816
[Epoch 69; Iter    12/  201] train: loss: 0.0892886
[Epoch 69; Iter    42/  201] train: loss: 0.1440058
[Epoch 69; Iter    72/  201] train: loss: 0.1472454
[Epoch 69; Iter   102/  201] train: loss: 0.1473073
[Epoch 69; Iter   132/  201] train: loss: 0.1070689
[Epoch 69; Iter   162/  201] train: loss: 0.1399349
[Epoch 69; Iter   192/  201] train: loss: 0.0961221
[Epoch 69] ogbg-moltoxcast: 0.671277 val loss: 0.278714
[Epoch 69] ogbg-moltoxcast: 0.658524 test loss: 0.319370
[Epoch 70; Iter    21/  201] train: loss: 0.1511268
[Epoch 70; Iter    51/  201] train: loss: 0.1247366
[Epoch 70; Iter    81/  201] train: loss: 0.1253150
[Epoch 70; Iter   111/  201] train: loss: 0.1222250
[Epoch 70; Iter   141/  201] train: loss: 0.1366732
[Epoch 70; Iter   171/  201] train: loss: 0.1285127
[Epoch 70; Iter   201/  201] train: loss: 0.4394187
[Epoch 70] ogbg-moltoxcast: 0.669966 val loss: 0.270367
[Epoch 70] ogbg-moltoxcast: 0.659337 test loss: 0.363704
[Epoch 71; Iter    30/  201] train: loss: 0.0693895
[Epoch 71; Iter    60/  201] train: loss: 0.2190866
[Epoch 71; Iter    90/  201] train: loss: 0.1024680
[Epoch 71; Iter   120/  201] train: loss: 0.1290485
[Epoch 71; Iter   150/  201] train: loss: 0.1828834
[Epoch 71; Iter   180/  201] train: loss: 0.1666320
[Epoch 71] ogbg-moltoxcast: 0.670426 val loss: 0.281356
[Epoch 71] ogbg-moltoxcast: 0.657961 test loss: 0.327208
[Epoch 72; Iter     9/  201] train: loss: 0.2547759
[Epoch 72; Iter    39/  201] train: loss: 0.1223042
[Epoch 72; Iter    69/  201] train: loss: 0.1360990
[Epoch 72; Iter    99/  201] train: loss: 0.1144610
[Epoch 72; Iter   129/  201] train: loss: 0.1087708
[Epoch 72; Iter   159/  201] train: loss: 0.1286953
[Epoch 72; Iter   189/  201] train: loss: 0.1168494
[Epoch 72] ogbg-moltoxcast: 0.671887 val loss: 0.269041
[Epoch 72] ogbg-moltoxcast: 0.659431 test loss: 0.341354
[Epoch 73; Iter    18/  201] train: loss: 0.1318740
[Epoch 73; Iter    48/  201] train: loss: 0.0789144
[Epoch 73; Iter    78/  201] train: loss: 0.1297704
[Epoch 73; Iter   108/  201] train: loss: 0.1302927
[Epoch 73; Iter   138/  201] train: loss: 0.1569429
[Epoch 73; Iter   168/  201] train: loss: 0.1352899
[Epoch 73; Iter   198/  201] train: loss: 0.1351351
[Epoch 73] ogbg-moltoxcast: 0.671361 val loss: 0.296564
[Epoch 73] ogbg-moltoxcast: 0.659201 test loss: 0.412318
[Epoch 74; Iter    27/  201] train: loss: 0.0950923
[Epoch 74; Iter    57/  201] train: loss: 0.1497192
[Epoch 74; Iter    87/  201] train: loss: 0.1268357
[Epoch 74; Iter   117/  201] train: loss: 0.1183859
[Epoch 74; Iter   147/  201] train: loss: 0.1060163
[Epoch 74; Iter   177/  201] train: loss: 0.1357913
[Epoch 74] ogbg-moltoxcast: 0.668466 val loss: 0.271876
[Epoch 74] ogbg-moltoxcast: 0.659072 test loss: 0.354676
[Epoch 75; Iter     6/  201] train: loss: 0.1738042
[Epoch 75; Iter    36/  201] train: loss: 0.1656982
[Epoch 75; Iter    66/  201] train: loss: 0.1020946
[Epoch 75; Iter    96/  201] train: loss: 0.1116414
[Epoch 75; Iter   126/  201] train: loss: 0.1354538
[Epoch 75; Iter   156/  201] train: loss: 0.1316447
[Epoch 75; Iter   186/  201] train: loss: 0.1791776
[Epoch 75] ogbg-moltoxcast: 0.667315 val loss: 0.277221
[Epoch 75] ogbg-moltoxcast: 0.657621 test loss: 0.348491
[Epoch 76; Iter    15/  201] train: loss: 0.1442055
[Epoch 76; Iter    45/  201] train: loss: 0.2012734
[Epoch 76; Iter    75/  201] train: loss: 0.1662350
[Epoch 76; Iter   105/  201] train: loss: 0.1273210
[Epoch 76; Iter   135/  201] train: loss: 0.1317338
[Epoch 76; Iter   165/  201] train: loss: 0.1165819
[Epoch 76; Iter   195/  201] train: loss: 0.1092090
[Epoch 76] ogbg-moltoxcast: 0.670236 val loss: 0.275286
[Epoch 76] ogbg-moltoxcast: 0.654726 test loss: 0.395458
[Epoch 77; Iter    24/  201] train: loss: 0.1024114
[Epoch 77; Iter    54/  201] train: loss: 0.1148032
[Epoch 77; Iter    84/  201] train: loss: 0.1341895
[Epoch 77; Iter   114/  201] train: loss: 0.0966832
[Epoch 77; Iter   144/  201] train: loss: 0.1041158
[Epoch 77; Iter   174/  201] train: loss: 0.1235065
[Epoch 77] ogbg-moltoxcast: 0.667300 val loss: 0.275868
[Epoch 77] ogbg-moltoxcast: 0.652916 test loss: 0.372199
[Epoch 78; Iter     3/  201] train: loss: 0.1371147
[Epoch 78; Iter    33/  201] train: loss: 0.1883265
[Epoch 78; Iter    63/  201] train: loss: 0.1473188
[Epoch 78; Iter    93/  201] train: loss: 0.1164410
[Epoch 78; Iter   123/  201] train: loss: 0.1418512
[Epoch 78; Iter   153/  201] train: loss: 0.1106026
[Epoch 78; Iter   183/  201] train: loss: 0.1357265
[Epoch 78] ogbg-moltoxcast: 0.665072 val loss: 0.281046
[Epoch 78] ogbg-moltoxcast: 0.651289 test loss: 0.365370
[Epoch 79; Iter    12/  201] train: loss: 0.1161940
[Epoch 79; Iter    42/  201] train: loss: 0.1149820
[Epoch 79; Iter    72/  201] train: loss: 0.1556270
[Epoch 79; Iter   102/  201] train: loss: 0.1423961
[Epoch 79; Iter   132/  201] train: loss: 0.1090935
[Epoch 79; Iter   162/  201] train: loss: 0.1087154
[Epoch 79; Iter   192/  201] train: loss: 0.1171126
[Epoch 79] ogbg-moltoxcast: 0.660920 val loss: 0.278513
[Epoch 79] ogbg-moltoxcast: 0.651614 test loss: 0.364099
[Epoch 80; Iter    21/  201] train: loss: 0.1367227
[Epoch 80; Iter    51/  201] train: loss: 0.1118779
[Epoch 80; Iter    81/  201] train: loss: 0.1054752
[Epoch 80; Iter   111/  201] train: loss: 0.1112630
[Epoch 80; Iter   141/  201] train: loss: 0.1543239
[Epoch 80; Iter   171/  201] train: loss: 0.1305241
[Epoch 80; Iter   201/  201] train: loss: 0.1618891
[Epoch 80] ogbg-moltoxcast: 0.658393 val loss: 0.288356
[Epoch 80] ogbg-moltoxcast: 0.651906 test loss: 0.389749
[Epoch 81; Iter    30/  201] train: loss: 0.1229629
[Epoch 81; Iter    60/  201] train: loss: 0.1075672
[Epoch 81; Iter    90/  201] train: loss: 0.1184407
[Epoch 81; Iter   120/  201] train: loss: 0.1274710
[Epoch 81; Iter   150/  201] train: loss: 0.1096645
[Epoch 81; Iter   180/  201] train: loss: 0.1111040
[Epoch 81] ogbg-moltoxcast: 0.659712 val loss: 0.286141
[Epoch 81] ogbg-moltoxcast: 0.650419 test loss: 0.322542
[Epoch 82; Iter     9/  201] train: loss: 0.1010131
[Epoch 82; Iter    39/  201] train: loss: 0.0859495
[Epoch 82; Iter    69/  201] train: loss: 0.0935042
[Epoch 82; Iter    99/  201] train: loss: 0.0742956
[Epoch 82; Iter   129/  201] train: loss: 0.1776932
[Epoch 82; Iter   159/  201] train: loss: 0.1310562
[Epoch 82; Iter   189/  201] train: loss: 0.0862616
[Epoch 82] ogbg-moltoxcast: 0.670390 val loss: 0.279000
[Epoch 82] ogbg-moltoxcast: 0.660662 test loss: 0.316896
[Epoch 83; Iter    18/  201] train: loss: 0.1210995
[Epoch 83; Iter    48/  201] train: loss: 0.1336947
[Epoch 83; Iter    78/  201] train: loss: 0.1319249
[Epoch 83; Iter   108/  201] train: loss: 0.1243747
[Epoch 83; Iter   138/  201] train: loss: 0.1103446
[Epoch 83; Iter   168/  201] train: loss: 0.1946368
[Epoch 83; Iter   198/  201] train: loss: 0.1642872
[Epoch 83] ogbg-moltoxcast: 0.669830 val loss: 0.275772
[Epoch 83] ogbg-moltoxcast: 0.657252 test loss: 0.314549
[Epoch 66; Iter   105/  201] train: loss: 0.1425647
[Epoch 66; Iter   135/  201] train: loss: 0.1457865
[Epoch 66; Iter   165/  201] train: loss: 0.1097652
[Epoch 66; Iter   195/  201] train: loss: 0.1383101
[Epoch 66] ogbg-moltoxcast: 0.686796 val loss: 0.264376
[Epoch 66] ogbg-moltoxcast: 0.660696 test loss: 0.310377
[Epoch 67; Iter    24/  201] train: loss: 0.1282663
[Epoch 67; Iter    54/  201] train: loss: 0.1225341
[Epoch 67; Iter    84/  201] train: loss: 0.1291093
[Epoch 67; Iter   114/  201] train: loss: 0.1117098
[Epoch 67; Iter   144/  201] train: loss: 0.1159970
[Epoch 67; Iter   174/  201] train: loss: 0.1325287
[Epoch 67] ogbg-moltoxcast: 0.688766 val loss: 0.262243
[Epoch 67] ogbg-moltoxcast: 0.662368 test loss: 0.311447
[Epoch 68; Iter     3/  201] train: loss: 0.0841250
[Epoch 68; Iter    33/  201] train: loss: 0.1375660
[Epoch 68; Iter    63/  201] train: loss: 0.1256051
[Epoch 68; Iter    93/  201] train: loss: 0.1451026
[Epoch 68; Iter   123/  201] train: loss: 0.1067735
[Epoch 68; Iter   153/  201] train: loss: 0.1151951
[Epoch 68; Iter   183/  201] train: loss: 0.1451752
[Epoch 68] ogbg-moltoxcast: 0.680382 val loss: 0.265665
[Epoch 68] ogbg-moltoxcast: 0.656566 test loss: 0.315329
[Epoch 69; Iter    12/  201] train: loss: 0.1447062
[Epoch 69; Iter    42/  201] train: loss: 0.1576045
[Epoch 69; Iter    72/  201] train: loss: 0.1082801
[Epoch 69; Iter   102/  201] train: loss: 0.1188177
[Epoch 69; Iter   132/  201] train: loss: 0.1181698
[Epoch 69; Iter   162/  201] train: loss: 0.0995480
[Epoch 69; Iter   192/  201] train: loss: 0.1050686
[Epoch 69] ogbg-moltoxcast: 0.685842 val loss: 0.267980
[Epoch 69] ogbg-moltoxcast: 0.659264 test loss: 0.318728
[Epoch 70; Iter    21/  201] train: loss: 0.1237336
[Epoch 70; Iter    51/  201] train: loss: 0.1141198
[Epoch 70; Iter    81/  201] train: loss: 0.1048078
[Epoch 70; Iter   111/  201] train: loss: 0.1223281
[Epoch 70; Iter   141/  201] train: loss: 0.1919189
[Epoch 70; Iter   171/  201] train: loss: 0.1220989
[Epoch 70; Iter   201/  201] train: loss: 0.2556604
[Epoch 70] ogbg-moltoxcast: 0.685183 val loss: 0.265911
[Epoch 70] ogbg-moltoxcast: 0.660087 test loss: 0.316166
[Epoch 71; Iter    30/  201] train: loss: 0.1245544
[Epoch 71; Iter    60/  201] train: loss: 0.1060881
[Epoch 71; Iter    90/  201] train: loss: 0.1095398
[Epoch 71; Iter   120/  201] train: loss: 0.1334207
[Epoch 71; Iter   150/  201] train: loss: 0.1441531
[Epoch 71; Iter   180/  201] train: loss: 0.1542799
[Epoch 71] ogbg-moltoxcast: 0.687138 val loss: 0.263845
[Epoch 71] ogbg-moltoxcast: 0.656177 test loss: 0.317374
[Epoch 72; Iter     9/  201] train: loss: 0.1380891
[Epoch 72; Iter    39/  201] train: loss: 0.1163814
[Epoch 72; Iter    69/  201] train: loss: 0.1579458
[Epoch 72; Iter    99/  201] train: loss: 0.1320827
[Epoch 72; Iter   129/  201] train: loss: 0.1385170
[Epoch 72; Iter   159/  201] train: loss: 0.1131426
[Epoch 72; Iter   189/  201] train: loss: 0.0876690
[Epoch 72] ogbg-moltoxcast: 0.687992 val loss: 0.262906
[Epoch 72] ogbg-moltoxcast: 0.658015 test loss: 0.317312
[Epoch 73; Iter    18/  201] train: loss: 0.1418923
[Epoch 73; Iter    48/  201] train: loss: 0.1696945
[Epoch 73; Iter    78/  201] train: loss: 0.1178622
[Epoch 73; Iter   108/  201] train: loss: 0.1672359
[Epoch 73; Iter   138/  201] train: loss: 0.1070467
[Epoch 73; Iter   168/  201] train: loss: 0.1235876
[Epoch 73; Iter   198/  201] train: loss: 0.1418130
[Epoch 73] ogbg-moltoxcast: 0.683420 val loss: 0.268697
[Epoch 73] ogbg-moltoxcast: 0.657051 test loss: 0.319553
[Epoch 74; Iter    27/  201] train: loss: 0.1313016
[Epoch 74; Iter    57/  201] train: loss: 0.1003868
[Epoch 74; Iter    87/  201] train: loss: 0.1235432
[Epoch 74; Iter   117/  201] train: loss: 0.1536705
[Epoch 74; Iter   147/  201] train: loss: 0.1018592
[Epoch 74; Iter   177/  201] train: loss: 0.1285127
[Epoch 74] ogbg-moltoxcast: 0.685442 val loss: 0.264382
[Epoch 74] ogbg-moltoxcast: 0.653731 test loss: 0.317510
[Epoch 75; Iter     6/  201] train: loss: 0.1234498
[Epoch 75; Iter    36/  201] train: loss: 0.1369415
[Epoch 75; Iter    66/  201] train: loss: 0.1346424
[Epoch 75; Iter    96/  201] train: loss: 0.0968357
[Epoch 75; Iter   126/  201] train: loss: 0.0991022
[Epoch 75; Iter   156/  201] train: loss: 0.1321971
[Epoch 75; Iter   186/  201] train: loss: 0.0989158
[Epoch 75] ogbg-moltoxcast: 0.684481 val loss: 0.267840
[Epoch 75] ogbg-moltoxcast: 0.656646 test loss: 0.322912
[Epoch 76; Iter    15/  201] train: loss: 0.0897451
[Epoch 76; Iter    45/  201] train: loss: 0.1146213
[Epoch 76; Iter    75/  201] train: loss: 0.1334665
[Epoch 76; Iter   105/  201] train: loss: 0.1103248
[Epoch 76; Iter   135/  201] train: loss: 0.1183635
[Epoch 76; Iter   165/  201] train: loss: 0.0905356
[Epoch 76; Iter   195/  201] train: loss: 0.0960788
[Epoch 76] ogbg-moltoxcast: 0.680882 val loss: 0.268918
[Epoch 76] ogbg-moltoxcast: 0.652641 test loss: 0.317075
[Epoch 77; Iter    24/  201] train: loss: 0.1870433
[Epoch 77; Iter    54/  201] train: loss: 0.0999943
[Epoch 77; Iter    84/  201] train: loss: 0.1022854
[Epoch 77; Iter   114/  201] train: loss: 0.1201373
[Epoch 77; Iter   144/  201] train: loss: 0.1243997
[Epoch 77; Iter   174/  201] train: loss: 0.1353174
[Epoch 77] ogbg-moltoxcast: 0.682060 val loss: 0.271442
[Epoch 77] ogbg-moltoxcast: 0.652138 test loss: 0.326267
[Epoch 78; Iter     3/  201] train: loss: 0.1334437
[Epoch 78; Iter    33/  201] train: loss: 0.1266694
[Epoch 78; Iter    63/  201] train: loss: 0.1199519
[Epoch 78; Iter    93/  201] train: loss: 0.1157518
[Epoch 78; Iter   123/  201] train: loss: 0.1721521
[Epoch 78; Iter   153/  201] train: loss: 0.1133521
[Epoch 78; Iter   183/  201] train: loss: 0.1424949
[Epoch 78] ogbg-moltoxcast: 0.685201 val loss: 0.270640
[Epoch 78] ogbg-moltoxcast: 0.655365 test loss: 0.325461
[Epoch 79; Iter    12/  201] train: loss: 0.1094535
[Epoch 79; Iter    42/  201] train: loss: 0.0949846
[Epoch 79; Iter    72/  201] train: loss: 0.1454197
[Epoch 79; Iter   102/  201] train: loss: 0.0860143
[Epoch 79; Iter   132/  201] train: loss: 0.1702815
[Epoch 79; Iter   162/  201] train: loss: 0.1538430
[Epoch 79; Iter   192/  201] train: loss: 0.0931352
[Epoch 79] ogbg-moltoxcast: 0.676642 val loss: 0.276962
[Epoch 79] ogbg-moltoxcast: 0.653323 test loss: 0.330286
[Epoch 80; Iter    21/  201] train: loss: 0.1703759
[Epoch 80; Iter    51/  201] train: loss: 0.1402562
[Epoch 80; Iter    81/  201] train: loss: 0.1333021
[Epoch 80; Iter   111/  201] train: loss: 0.0866537
[Epoch 80; Iter   141/  201] train: loss: 0.1819530
[Epoch 80; Iter   171/  201] train: loss: 0.1050039
[Epoch 80; Iter   201/  201] train: loss: 0.5231491
[Epoch 80] ogbg-moltoxcast: 0.682157 val loss: 0.272371
[Epoch 80] ogbg-moltoxcast: 0.656862 test loss: 0.325469
[Epoch 81; Iter    30/  201] train: loss: 0.1991040
[Epoch 81; Iter    60/  201] train: loss: 0.1104038
[Epoch 81; Iter    90/  201] train: loss: 0.1082224
[Epoch 81; Iter   120/  201] train: loss: 0.1777833
[Epoch 81; Iter   150/  201] train: loss: 0.1320094
[Epoch 81; Iter   180/  201] train: loss: 0.1627817
[Epoch 81] ogbg-moltoxcast: 0.673577 val loss: 0.274587
[Epoch 81] ogbg-moltoxcast: 0.650878 test loss: 0.329942
[Epoch 82; Iter     9/  201] train: loss: 0.1490538
[Epoch 82; Iter    39/  201] train: loss: 0.1191360
[Epoch 82; Iter    69/  201] train: loss: 0.1061126
[Epoch 82; Iter    99/  201] train: loss: 0.1819617
[Epoch 82; Iter   129/  201] train: loss: 0.1176880
[Epoch 82; Iter   159/  201] train: loss: 0.1184417
[Epoch 82; Iter   189/  201] train: loss: 0.1266825
[Epoch 82] ogbg-moltoxcast: 0.676474 val loss: 0.275601
[Epoch 82] ogbg-moltoxcast: 0.651085 test loss: 0.332730
[Epoch 83; Iter    18/  201] train: loss: 0.1045893
[Epoch 83; Iter    48/  201] train: loss: 0.0919762
[Epoch 83; Iter    78/  201] train: loss: 0.1054272
[Epoch 83; Iter   108/  201] train: loss: 0.0969907
[Epoch 83; Iter   138/  201] train: loss: 0.1257088
[Epoch 83; Iter   168/  201] train: loss: 0.1735774
[Epoch 83; Iter   198/  201] train: loss: 0.1075578
[Epoch 83] ogbg-moltoxcast: 0.673781 val loss: 0.273958
[Epoch 83] ogbg-moltoxcast: 0.651424 test loss: 0.326409
[Epoch 74; Iter   134/  172] train: loss: 0.0834915
[Epoch 74; Iter   164/  172] train: loss: 0.1624629
[Epoch 74] ogbg-moltoxcast: 0.644835 val loss: 0.287161
[Epoch 74] ogbg-moltoxcast: 0.624889 test loss: 0.338621
[Epoch 75; Iter    22/  172] train: loss: 0.1393803
[Epoch 75; Iter    52/  172] train: loss: 0.1253412
[Epoch 75; Iter    82/  172] train: loss: 0.0786639
[Epoch 75; Iter   112/  172] train: loss: 0.1090061
[Epoch 75; Iter   142/  172] train: loss: 0.1140442
[Epoch 75; Iter   172/  172] train: loss: 0.1284369
[Epoch 75] ogbg-moltoxcast: 0.647481 val loss: 0.286198
[Epoch 75] ogbg-moltoxcast: 0.621745 test loss: 0.340408
[Epoch 76; Iter    30/  172] train: loss: 0.0921586
[Epoch 76; Iter    60/  172] train: loss: 0.0982183
[Epoch 76; Iter    90/  172] train: loss: 0.1599190
[Epoch 76; Iter   120/  172] train: loss: 0.1069441
[Epoch 76; Iter   150/  172] train: loss: 0.0929853
[Epoch 76] ogbg-moltoxcast: 0.647401 val loss: 0.289760
[Epoch 76] ogbg-moltoxcast: 0.622859 test loss: 0.345544
[Epoch 77; Iter     8/  172] train: loss: 0.1070553
[Epoch 77; Iter    38/  172] train: loss: 0.0893611
[Epoch 77; Iter    68/  172] train: loss: 0.1029357
[Epoch 77; Iter    98/  172] train: loss: 0.1387964
[Epoch 77; Iter   128/  172] train: loss: 0.0873072
[Epoch 77; Iter   158/  172] train: loss: 0.1162519
[Epoch 77] ogbg-moltoxcast: 0.650774 val loss: 0.288726
[Epoch 77] ogbg-moltoxcast: 0.624161 test loss: 0.346515
[Epoch 78; Iter    16/  172] train: loss: 0.0943109
[Epoch 78; Iter    46/  172] train: loss: 0.1301768
[Epoch 78; Iter    76/  172] train: loss: 0.0964810
[Epoch 78; Iter   106/  172] train: loss: 0.1142055
[Epoch 78; Iter   136/  172] train: loss: 0.1162665
[Epoch 78; Iter   166/  172] train: loss: 0.0782698
[Epoch 78] ogbg-moltoxcast: 0.646261 val loss: 0.295228
[Epoch 78] ogbg-moltoxcast: 0.622322 test loss: 0.351793
[Epoch 79; Iter    24/  172] train: loss: 0.1260973
[Epoch 79; Iter    54/  172] train: loss: 0.1267559
[Epoch 79; Iter    84/  172] train: loss: 0.1173354
[Epoch 79; Iter   114/  172] train: loss: 0.1198953
[Epoch 79; Iter   144/  172] train: loss: 0.1276752
[Epoch 79] ogbg-moltoxcast: 0.647297 val loss: 0.296769
[Epoch 79] ogbg-moltoxcast: 0.624174 test loss: 0.353868
[Epoch 80; Iter     2/  172] train: loss: 0.1628477
[Epoch 80; Iter    32/  172] train: loss: 0.1457319
[Epoch 80; Iter    62/  172] train: loss: 0.1277198
[Epoch 80; Iter    92/  172] train: loss: 0.0978799
[Epoch 80; Iter   122/  172] train: loss: 0.1300974
[Epoch 80; Iter   152/  172] train: loss: 0.1402333
[Epoch 80] ogbg-moltoxcast: 0.648030 val loss: 0.298018
[Epoch 80] ogbg-moltoxcast: 0.619962 test loss: 0.360402
[Epoch 81; Iter    10/  172] train: loss: 0.1517468
[Epoch 81; Iter    40/  172] train: loss: 0.1573744
[Epoch 81; Iter    70/  172] train: loss: 0.1351093
[Epoch 81; Iter   100/  172] train: loss: 0.1039326
[Epoch 81; Iter   130/  172] train: loss: 0.1000705
[Epoch 81; Iter   160/  172] train: loss: 0.0846177
[Epoch 81] ogbg-moltoxcast: 0.646477 val loss: 0.288606
[Epoch 81] ogbg-moltoxcast: 0.622644 test loss: 0.341719
[Epoch 82; Iter    18/  172] train: loss: 0.0765995
[Epoch 82; Iter    48/  172] train: loss: 0.1081411
[Epoch 82; Iter    78/  172] train: loss: 0.0915757
[Epoch 82; Iter   108/  172] train: loss: 0.1695387
[Epoch 82; Iter   138/  172] train: loss: 0.0935009
[Epoch 82; Iter   168/  172] train: loss: 0.1331785
[Epoch 82] ogbg-moltoxcast: 0.647604 val loss: 0.294372
[Epoch 82] ogbg-moltoxcast: 0.622509 test loss: 0.353956
[Epoch 83; Iter    26/  172] train: loss: 0.1175798
[Epoch 83; Iter    56/  172] train: loss: 0.1143687
[Epoch 83; Iter    86/  172] train: loss: 0.1279566
[Epoch 83; Iter   116/  172] train: loss: 0.1006910
[Epoch 83; Iter   146/  172] train: loss: 0.0711893
[Epoch 83] ogbg-moltoxcast: 0.647953 val loss: 0.295606
[Epoch 83] ogbg-moltoxcast: 0.621038 test loss: 0.355330
[Epoch 84; Iter     4/  172] train: loss: 0.1457152
[Epoch 84; Iter    34/  172] train: loss: 0.0865885
[Epoch 84; Iter    64/  172] train: loss: 0.0893343
[Epoch 84; Iter    94/  172] train: loss: 0.1095989
[Epoch 84; Iter   124/  172] train: loss: 0.1185201
[Epoch 84; Iter   154/  172] train: loss: 0.1387111
[Epoch 84] ogbg-moltoxcast: 0.650208 val loss: 0.291054
[Epoch 84] ogbg-moltoxcast: 0.622635 test loss: 0.350235
[Epoch 85; Iter    12/  172] train: loss: 0.0905145
[Epoch 85; Iter    42/  172] train: loss: 0.0952273
[Epoch 85; Iter    72/  172] train: loss: 0.1071200
[Epoch 85; Iter   102/  172] train: loss: 0.0991818
[Epoch 85; Iter   132/  172] train: loss: 0.1693836
[Epoch 85; Iter   162/  172] train: loss: 0.1291655
[Epoch 85] ogbg-moltoxcast: 0.645700 val loss: 0.297033
[Epoch 85] ogbg-moltoxcast: 0.622447 test loss: 0.356210
[Epoch 86; Iter    20/  172] train: loss: 0.0947354
[Epoch 86; Iter    50/  172] train: loss: 0.1135456
[Epoch 86; Iter    80/  172] train: loss: 0.1035847
[Epoch 86; Iter   110/  172] train: loss: 0.1017071
[Epoch 86; Iter   140/  172] train: loss: 0.1654015
[Epoch 86; Iter   170/  172] train: loss: 0.1130598
[Epoch 86] ogbg-moltoxcast: 0.650261 val loss: 0.291937
[Epoch 86] ogbg-moltoxcast: 0.626344 test loss: 0.349686
[Epoch 87; Iter    28/  172] train: loss: 0.1106882
[Epoch 87; Iter    58/  172] train: loss: 0.0876823
[Epoch 87; Iter    88/  172] train: loss: 0.0922975
[Epoch 87; Iter   118/  172] train: loss: 0.1080064
[Epoch 87; Iter   148/  172] train: loss: 0.0787729
[Epoch 87] ogbg-moltoxcast: 0.644090 val loss: 0.297104
[Epoch 87] ogbg-moltoxcast: 0.623213 test loss: 0.351245
[Epoch 88; Iter     6/  172] train: loss: 0.1454518
[Epoch 88; Iter    36/  172] train: loss: 0.1332675
[Epoch 88; Iter    66/  172] train: loss: 0.1123371
[Epoch 88; Iter    96/  172] train: loss: 0.1092722
[Epoch 88; Iter   126/  172] train: loss: 0.0806667
[Epoch 88; Iter   156/  172] train: loss: 0.1351796
[Epoch 88] ogbg-moltoxcast: 0.639388 val loss: 0.296022
[Epoch 88] ogbg-moltoxcast: 0.622908 test loss: 0.348834
[Epoch 89; Iter    14/  172] train: loss: 0.1087427
[Epoch 89; Iter    44/  172] train: loss: 0.1184831
[Epoch 89; Iter    74/  172] train: loss: 0.1135150
[Epoch 89; Iter   104/  172] train: loss: 0.1378662
[Epoch 89; Iter   134/  172] train: loss: 0.1111222
[Epoch 89; Iter   164/  172] train: loss: 0.1291487
[Epoch 89] ogbg-moltoxcast: 0.646664 val loss: 0.296975
[Epoch 89] ogbg-moltoxcast: 0.622856 test loss: 0.354846
[Epoch 90; Iter    22/  172] train: loss: 0.0962692
[Epoch 90; Iter    52/  172] train: loss: 0.1605262
[Epoch 90; Iter    82/  172] train: loss: 0.0759357
[Epoch 90; Iter   112/  172] train: loss: 0.0806231
[Epoch 90; Iter   142/  172] train: loss: 0.1402728
[Epoch 90; Iter   172/  172] train: loss: 0.1182022
[Epoch 90] ogbg-moltoxcast: 0.639823 val loss: 0.301339
[Epoch 90] ogbg-moltoxcast: 0.618348 test loss: 0.358439
[Epoch 91; Iter    30/  172] train: loss: 0.1048785
[Epoch 91; Iter    60/  172] train: loss: 0.0992671
[Epoch 91; Iter    90/  172] train: loss: 0.1283206
[Epoch 91; Iter   120/  172] train: loss: 0.1099975
[Epoch 91; Iter   150/  172] train: loss: 0.1313031
[Epoch 91] ogbg-moltoxcast: 0.642958 val loss: 0.298049
[Epoch 91] ogbg-moltoxcast: 0.617682 test loss: 0.358409
[Epoch 92; Iter     8/  172] train: loss: 0.1264872
[Epoch 92; Iter    38/  172] train: loss: 0.0798151
[Epoch 92; Iter    68/  172] train: loss: 0.1218458
[Epoch 92; Iter    98/  172] train: loss: 0.1064073
[Epoch 92; Iter   128/  172] train: loss: 0.1415379
[Epoch 92; Iter   158/  172] train: loss: 0.1399408
[Epoch 92] ogbg-moltoxcast: 0.642502 val loss: 0.304787
[Epoch 92] ogbg-moltoxcast: 0.617098 test loss: 0.364936
[Epoch 93; Iter    16/  172] train: loss: 0.1037131
[Epoch 93; Iter    46/  172] train: loss: 0.1424654
[Epoch 93; Iter    76/  172] train: loss: 0.1240794
[Epoch 93; Iter   106/  172] train: loss: 0.1137113
[Epoch 93; Iter   136/  172] train: loss: 0.1113972
[Epoch 93; Iter   166/  172] train: loss: 0.1174796
[Epoch 93] ogbg-moltoxcast: 0.642932 val loss: 0.295802
[Epoch 93] ogbg-moltoxcast: 0.620147 test loss: 0.352604
[Epoch 94; Iter    24/  172] train: loss: 0.1378160
[Epoch 94; Iter    54/  172] train: loss: 0.1154966
[Epoch 94; Iter    84/  172] train: loss: 0.1149053
[Epoch 74; Iter   134/  172] train: loss: 0.1674660
[Epoch 74; Iter   164/  172] train: loss: 0.1349057
[Epoch 74] ogbg-moltoxcast: 0.649969 val loss: 0.289705
[Epoch 74] ogbg-moltoxcast: 0.634655 test loss: 0.336164
[Epoch 75; Iter    22/  172] train: loss: 0.1347349
[Epoch 75; Iter    52/  172] train: loss: 0.1133984
[Epoch 75; Iter    82/  172] train: loss: 0.1058853
[Epoch 75; Iter   112/  172] train: loss: 0.0887651
[Epoch 75; Iter   142/  172] train: loss: 0.1273057
[Epoch 75; Iter   172/  172] train: loss: 0.1251351
[Epoch 75] ogbg-moltoxcast: 0.648177 val loss: 0.290576
[Epoch 75] ogbg-moltoxcast: 0.632311 test loss: 0.338593
[Epoch 76; Iter    30/  172] train: loss: 0.0903619
[Epoch 76; Iter    60/  172] train: loss: 0.1287048
[Epoch 76; Iter    90/  172] train: loss: 0.1012742
[Epoch 76; Iter   120/  172] train: loss: 0.1367221
[Epoch 76; Iter   150/  172] train: loss: 0.1282797
[Epoch 76] ogbg-moltoxcast: 0.649985 val loss: 0.290743
[Epoch 76] ogbg-moltoxcast: 0.633848 test loss: 0.340023
[Epoch 77; Iter     8/  172] train: loss: 0.1224256
[Epoch 77; Iter    38/  172] train: loss: 0.0832290
[Epoch 77; Iter    68/  172] train: loss: 0.1130927
[Epoch 77; Iter    98/  172] train: loss: 0.1669669
[Epoch 77; Iter   128/  172] train: loss: 0.0763611
[Epoch 77; Iter   158/  172] train: loss: 0.1122086
[Epoch 77] ogbg-moltoxcast: 0.644556 val loss: 0.294125
[Epoch 77] ogbg-moltoxcast: 0.624568 test loss: 0.344535
[Epoch 78; Iter    16/  172] train: loss: 0.1179207
[Epoch 78; Iter    46/  172] train: loss: 0.1095846
[Epoch 78; Iter    76/  172] train: loss: 0.1525823
[Epoch 78; Iter   106/  172] train: loss: 0.0854334
[Epoch 78; Iter   136/  172] train: loss: 0.1089406
[Epoch 78; Iter   166/  172] train: loss: 0.1054588
[Epoch 78] ogbg-moltoxcast: 0.644639 val loss: 0.291585
[Epoch 78] ogbg-moltoxcast: 0.630319 test loss: 0.335637
[Epoch 79; Iter    24/  172] train: loss: 0.1289691
[Epoch 79; Iter    54/  172] train: loss: 0.1426724
[Epoch 79; Iter    84/  172] train: loss: 0.1398989
[Epoch 79; Iter   114/  172] train: loss: 0.0803764
[Epoch 79; Iter   144/  172] train: loss: 0.1087052
[Epoch 79] ogbg-moltoxcast: 0.642930 val loss: 0.290983
[Epoch 79] ogbg-moltoxcast: 0.628958 test loss: 0.338575
[Epoch 80; Iter     2/  172] train: loss: 0.0799276
[Epoch 80; Iter    32/  172] train: loss: 0.1365412
[Epoch 80; Iter    62/  172] train: loss: 0.1182836
[Epoch 80; Iter    92/  172] train: loss: 0.1638039
[Epoch 80; Iter   122/  172] train: loss: 0.0824492
[Epoch 80; Iter   152/  172] train: loss: 0.1043586
[Epoch 80] ogbg-moltoxcast: 0.642843 val loss: 0.293100
[Epoch 80] ogbg-moltoxcast: 0.625171 test loss: 0.343539
[Epoch 81; Iter    10/  172] train: loss: 0.1801166
[Epoch 81; Iter    40/  172] train: loss: 0.1287535
[Epoch 81; Iter    70/  172] train: loss: 0.1030304
[Epoch 81; Iter   100/  172] train: loss: 0.1194543
[Epoch 81; Iter   130/  172] train: loss: 0.1235199
[Epoch 81; Iter   160/  172] train: loss: 0.1610695
[Epoch 81] ogbg-moltoxcast: 0.642109 val loss: 0.292586
[Epoch 81] ogbg-moltoxcast: 0.626116 test loss: 0.339862
[Epoch 82; Iter    18/  172] train: loss: 0.1046734
[Epoch 82; Iter    48/  172] train: loss: 0.0820363
[Epoch 82; Iter    78/  172] train: loss: 0.1709860
[Epoch 82; Iter   108/  172] train: loss: 0.1469014
[Epoch 82; Iter   138/  172] train: loss: 0.1451848
[Epoch 82; Iter   168/  172] train: loss: 0.1152893
[Epoch 82] ogbg-moltoxcast: 0.653601 val loss: 0.291241
[Epoch 82] ogbg-moltoxcast: 0.627910 test loss: 0.344796
[Epoch 83; Iter    26/  172] train: loss: 0.0851260
[Epoch 83; Iter    56/  172] train: loss: 0.1274888
[Epoch 83; Iter    86/  172] train: loss: 0.0733439
[Epoch 83; Iter   116/  172] train: loss: 0.1471399
[Epoch 83; Iter   146/  172] train: loss: 0.1406714
[Epoch 83] ogbg-moltoxcast: 0.642204 val loss: 0.292846
[Epoch 83] ogbg-moltoxcast: 0.623160 test loss: 0.341425
[Epoch 84; Iter     4/  172] train: loss: 0.1468718
[Epoch 84; Iter    34/  172] train: loss: 0.0833103
[Epoch 84; Iter    64/  172] train: loss: 0.1156946
[Epoch 84; Iter    94/  172] train: loss: 0.1165346
[Epoch 84; Iter   124/  172] train: loss: 0.1104060
[Epoch 84; Iter   154/  172] train: loss: 0.1408111
[Epoch 84] ogbg-moltoxcast: 0.649618 val loss: 0.291273
[Epoch 84] ogbg-moltoxcast: 0.629006 test loss: 0.341098
[Epoch 85; Iter    12/  172] train: loss: 0.2141109
[Epoch 85; Iter    42/  172] train: loss: 0.0905646
[Epoch 85; Iter    72/  172] train: loss: 0.1115097
[Epoch 85; Iter   102/  172] train: loss: 0.1230022
[Epoch 85; Iter   132/  172] train: loss: 0.1138968
[Epoch 85; Iter   162/  172] train: loss: 0.1102267
[Epoch 85] ogbg-moltoxcast: 0.645271 val loss: 0.294655
[Epoch 85] ogbg-moltoxcast: 0.625075 test loss: 0.343238
[Epoch 86; Iter    20/  172] train: loss: 0.1104577
[Epoch 86; Iter    50/  172] train: loss: 0.1321297
[Epoch 86; Iter    80/  172] train: loss: 0.1525305
[Epoch 86; Iter   110/  172] train: loss: 0.1301582
[Epoch 86; Iter   140/  172] train: loss: 0.1323444
[Epoch 86; Iter   170/  172] train: loss: 0.0796814
[Epoch 86] ogbg-moltoxcast: 0.642048 val loss: 0.297593
[Epoch 86] ogbg-moltoxcast: 0.623600 test loss: 0.344186
[Epoch 87; Iter    28/  172] train: loss: 0.1332429
[Epoch 87; Iter    58/  172] train: loss: 0.0924808
[Epoch 87; Iter    88/  172] train: loss: 0.0944776
[Epoch 87; Iter   118/  172] train: loss: 0.1478543
[Epoch 87; Iter   148/  172] train: loss: 0.1385698
[Epoch 87] ogbg-moltoxcast: 0.651033 val loss: 0.294342
[Epoch 87] ogbg-moltoxcast: 0.630706 test loss: 0.342709
[Epoch 88; Iter     6/  172] train: loss: 0.0971207
[Epoch 88; Iter    36/  172] train: loss: 0.0990159
[Epoch 88; Iter    66/  172] train: loss: 0.1121383
[Epoch 88; Iter    96/  172] train: loss: 0.1144624
[Epoch 88; Iter   126/  172] train: loss: 0.0757019
[Epoch 88; Iter   156/  172] train: loss: 0.1138495
[Epoch 88] ogbg-moltoxcast: 0.645200 val loss: 0.294949
[Epoch 88] ogbg-moltoxcast: 0.626219 test loss: 0.344951
[Epoch 89; Iter    14/  172] train: loss: 0.0820286
[Epoch 89; Iter    44/  172] train: loss: 0.0987350
[Epoch 89; Iter    74/  172] train: loss: 0.1000631
[Epoch 89; Iter   104/  172] train: loss: 0.0937331
[Epoch 89; Iter   134/  172] train: loss: 0.1436814
[Epoch 89; Iter   164/  172] train: loss: 0.0870322
[Epoch 89] ogbg-moltoxcast: 0.637849 val loss: 0.299898
[Epoch 89] ogbg-moltoxcast: 0.622812 test loss: 0.342915
[Epoch 90; Iter    22/  172] train: loss: 0.1509701
[Epoch 90; Iter    52/  172] train: loss: 0.0800001
[Epoch 90; Iter    82/  172] train: loss: 0.1227694
[Epoch 90; Iter   112/  172] train: loss: 0.1369908
[Epoch 90; Iter   142/  172] train: loss: 0.1063423
[Epoch 90; Iter   172/  172] train: loss: 0.0835081
[Epoch 90] ogbg-moltoxcast: 0.641278 val loss: 0.299332
[Epoch 90] ogbg-moltoxcast: 0.622890 test loss: 0.346896
[Epoch 91; Iter    30/  172] train: loss: 0.1149996
[Epoch 91; Iter    60/  172] train: loss: 0.1220454
[Epoch 91; Iter    90/  172] train: loss: 0.2091691
[Epoch 91; Iter   120/  172] train: loss: 0.1064464
[Epoch 91; Iter   150/  172] train: loss: 0.1099321
[Epoch 91] ogbg-moltoxcast: 0.640826 val loss: 0.296320
[Epoch 91] ogbg-moltoxcast: 0.622347 test loss: 0.341787
[Epoch 92; Iter     8/  172] train: loss: 0.1274098
[Epoch 92; Iter    38/  172] train: loss: 0.1063004
[Epoch 92; Iter    68/  172] train: loss: 0.1262401
[Epoch 92; Iter    98/  172] train: loss: 0.1017065
[Epoch 92; Iter   128/  172] train: loss: 0.1009751
[Epoch 92; Iter   158/  172] train: loss: 0.0994684
[Epoch 92] ogbg-moltoxcast: 0.642776 val loss: 0.298232
[Epoch 92] ogbg-moltoxcast: 0.625324 test loss: 0.344620
[Epoch 93; Iter    16/  172] train: loss: 0.1051418
[Epoch 93; Iter    46/  172] train: loss: 0.1470979
[Epoch 93; Iter    76/  172] train: loss: 0.1278121
[Epoch 93; Iter   106/  172] train: loss: 0.1181177
[Epoch 93; Iter   136/  172] train: loss: 0.0999484
[Epoch 93; Iter   166/  172] train: loss: 0.1700133
[Epoch 93] ogbg-moltoxcast: 0.643178 val loss: 0.298750
[Epoch 93] ogbg-moltoxcast: 0.624524 test loss: 0.346885
[Epoch 94; Iter    24/  172] train: loss: 0.0897793
[Epoch 94; Iter    54/  172] train: loss: 0.1342295
[Epoch 94; Iter    84/  172] train: loss: 0.1132921
[Epoch 74; Iter   134/  172] train: loss: 0.0845209
[Epoch 74; Iter   164/  172] train: loss: 0.1306817
[Epoch 74] ogbg-moltoxcast: 0.639300 val loss: 0.299018
[Epoch 74] ogbg-moltoxcast: 0.619619 test loss: 0.349741
[Epoch 75; Iter    22/  172] train: loss: 0.1345696
[Epoch 75; Iter    52/  172] train: loss: 0.1052817
[Epoch 75; Iter    82/  172] train: loss: 0.1158498
[Epoch 75; Iter   112/  172] train: loss: 0.0898515
[Epoch 75; Iter   142/  172] train: loss: 0.1293322
[Epoch 75; Iter   172/  172] train: loss: 0.1305593
[Epoch 75] ogbg-moltoxcast: 0.642249 val loss: 0.298341
[Epoch 75] ogbg-moltoxcast: 0.612885 test loss: 0.348361
[Epoch 76; Iter    30/  172] train: loss: 0.0899234
[Epoch 76; Iter    60/  172] train: loss: 0.0804482
[Epoch 76; Iter    90/  172] train: loss: 0.1464883
[Epoch 76; Iter   120/  172] train: loss: 0.0908785
[Epoch 76; Iter   150/  172] train: loss: 0.1397579
[Epoch 76] ogbg-moltoxcast: 0.652800 val loss: 0.293838
[Epoch 76] ogbg-moltoxcast: 0.618657 test loss: 0.346717
[Epoch 77; Iter     8/  172] train: loss: 0.1314318
[Epoch 77; Iter    38/  172] train: loss: 0.1157359
[Epoch 77; Iter    68/  172] train: loss: 0.1095536
[Epoch 77; Iter    98/  172] train: loss: 0.1273740
[Epoch 77; Iter   128/  172] train: loss: 0.0738396
[Epoch 77; Iter   158/  172] train: loss: 0.0971333
[Epoch 77] ogbg-moltoxcast: 0.643753 val loss: 0.297489
[Epoch 77] ogbg-moltoxcast: 0.609977 test loss: 0.350754
[Epoch 78; Iter    16/  172] train: loss: 0.1638402
[Epoch 78; Iter    46/  172] train: loss: 0.1869877
[Epoch 78; Iter    76/  172] train: loss: 0.1935739
[Epoch 78; Iter   106/  172] train: loss: 0.1037457
[Epoch 78; Iter   136/  172] train: loss: 0.1479417
[Epoch 78; Iter   166/  172] train: loss: 0.1769672
[Epoch 78] ogbg-moltoxcast: 0.647200 val loss: 0.307519
[Epoch 78] ogbg-moltoxcast: 0.615047 test loss: 0.358996
[Epoch 79; Iter    24/  172] train: loss: 0.1496802
[Epoch 79; Iter    54/  172] train: loss: 0.1136103
[Epoch 79; Iter    84/  172] train: loss: 0.1600796
[Epoch 79; Iter   114/  172] train: loss: 0.0830370
[Epoch 79; Iter   144/  172] train: loss: 0.1096643
[Epoch 79] ogbg-moltoxcast: 0.641356 val loss: 0.301167
[Epoch 79] ogbg-moltoxcast: 0.615468 test loss: 0.352901
[Epoch 80; Iter     2/  172] train: loss: 0.1255988
[Epoch 80; Iter    32/  172] train: loss: 0.1039163
[Epoch 80; Iter    62/  172] train: loss: 0.1752262
[Epoch 80; Iter    92/  172] train: loss: 0.1513026
[Epoch 80; Iter   122/  172] train: loss: 0.1290367
[Epoch 80; Iter   152/  172] train: loss: 0.1080079
[Epoch 80] ogbg-moltoxcast: 0.640798 val loss: 0.300980
[Epoch 80] ogbg-moltoxcast: 0.613671 test loss: 0.353346
[Epoch 81; Iter    10/  172] train: loss: 0.1257833
[Epoch 81; Iter    40/  172] train: loss: 0.1049548
[Epoch 81; Iter    70/  172] train: loss: 0.1508275
[Epoch 81; Iter   100/  172] train: loss: 0.1089453
[Epoch 81; Iter   130/  172] train: loss: 0.1643829
[Epoch 81; Iter   160/  172] train: loss: 0.0862958
[Epoch 81] ogbg-moltoxcast: 0.645660 val loss: 0.297008
[Epoch 81] ogbg-moltoxcast: 0.616437 test loss: 0.348189
[Epoch 82; Iter    18/  172] train: loss: 0.1094372
[Epoch 82; Iter    48/  172] train: loss: 0.1658127
[Epoch 82; Iter    78/  172] train: loss: 0.1355114
[Epoch 82; Iter   108/  172] train: loss: 0.1707233
[Epoch 82; Iter   138/  172] train: loss: 0.1212245
[Epoch 82; Iter   168/  172] train: loss: 0.0870479
[Epoch 82] ogbg-moltoxcast: 0.641215 val loss: 0.298341
[Epoch 82] ogbg-moltoxcast: 0.613990 test loss: 0.346117
[Epoch 83; Iter    26/  172] train: loss: 0.1268858
[Epoch 83; Iter    56/  172] train: loss: 0.0915444
[Epoch 83; Iter    86/  172] train: loss: 0.1206547
[Epoch 83; Iter   116/  172] train: loss: 0.1035871
[Epoch 83; Iter   146/  172] train: loss: 0.0872444
[Epoch 83] ogbg-moltoxcast: 0.643867 val loss: 0.296961
[Epoch 83] ogbg-moltoxcast: 0.614994 test loss: 0.346142
[Epoch 84; Iter     4/  172] train: loss: 0.1738008
[Epoch 84; Iter    34/  172] train: loss: 0.0972355
[Epoch 84; Iter    64/  172] train: loss: 0.1223367
[Epoch 84; Iter    94/  172] train: loss: 0.1094906
[Epoch 84; Iter   124/  172] train: loss: 0.0994381
[Epoch 84; Iter   154/  172] train: loss: 0.1157707
[Epoch 84] ogbg-moltoxcast: 0.639816 val loss: 0.301836
[Epoch 84] ogbg-moltoxcast: 0.612981 test loss: 0.351179
[Epoch 85; Iter    12/  172] train: loss: 0.1120215
[Epoch 85; Iter    42/  172] train: loss: 0.1414611
[Epoch 85; Iter    72/  172] train: loss: 0.1123137
[Epoch 85; Iter   102/  172] train: loss: 0.1114175
[Epoch 85; Iter   132/  172] train: loss: 0.1000074
[Epoch 85; Iter   162/  172] train: loss: 0.1310469
[Epoch 85] ogbg-moltoxcast: 0.637120 val loss: 0.301098
[Epoch 85] ogbg-moltoxcast: 0.609951 test loss: 0.353062
[Epoch 86; Iter    20/  172] train: loss: 0.1339529
[Epoch 86; Iter    50/  172] train: loss: 0.1175144
[Epoch 86; Iter    80/  172] train: loss: 0.1104716
[Epoch 86; Iter   110/  172] train: loss: 0.1063568
[Epoch 86; Iter   140/  172] train: loss: 0.0976940
[Epoch 86; Iter   170/  172] train: loss: 0.1223443
[Epoch 86] ogbg-moltoxcast: 0.640304 val loss: 0.303551
[Epoch 86] ogbg-moltoxcast: 0.611727 test loss: 0.353718
[Epoch 87; Iter    28/  172] train: loss: 0.0889755
[Epoch 87; Iter    58/  172] train: loss: 0.1301651
[Epoch 87; Iter    88/  172] train: loss: 0.1153738
[Epoch 87; Iter   118/  172] train: loss: 0.0748701
[Epoch 87; Iter   148/  172] train: loss: 0.1333122
[Epoch 87] ogbg-moltoxcast: 0.639699 val loss: 0.305655
[Epoch 87] ogbg-moltoxcast: 0.611737 test loss: 0.359143
[Epoch 88; Iter     6/  172] train: loss: 0.1389474
[Epoch 88; Iter    36/  172] train: loss: 0.1457821
[Epoch 88; Iter    66/  172] train: loss: 0.1843957
[Epoch 88; Iter    96/  172] train: loss: 0.0897223
[Epoch 88; Iter   126/  172] train: loss: 0.1250932
[Epoch 88; Iter   156/  172] train: loss: 0.1065281
[Epoch 88] ogbg-moltoxcast: 0.634528 val loss: 0.307458
[Epoch 88] ogbg-moltoxcast: 0.609706 test loss: 0.357698
[Epoch 89; Iter    14/  172] train: loss: 0.1327355
[Epoch 89; Iter    44/  172] train: loss: 0.1310596
[Epoch 89; Iter    74/  172] train: loss: 0.0874324
[Epoch 89; Iter   104/  172] train: loss: 0.1210743
[Epoch 89; Iter   134/  172] train: loss: 0.0936188
[Epoch 89; Iter   164/  172] train: loss: 0.1187963
[Epoch 89] ogbg-moltoxcast: 0.635511 val loss: 0.307233
[Epoch 89] ogbg-moltoxcast: 0.612573 test loss: 0.358540
[Epoch 90; Iter    22/  172] train: loss: 0.1536237
[Epoch 90; Iter    52/  172] train: loss: 0.1291511
[Epoch 90; Iter    82/  172] train: loss: 0.1353565
[Epoch 90; Iter   112/  172] train: loss: 0.1145187
[Epoch 90; Iter   142/  172] train: loss: 0.0981039
[Epoch 90; Iter   172/  172] train: loss: 0.1927418
[Epoch 90] ogbg-moltoxcast: 0.642115 val loss: 0.302555
[Epoch 90] ogbg-moltoxcast: 0.616169 test loss: 0.355202
[Epoch 91; Iter    30/  172] train: loss: 0.0570084
[Epoch 91; Iter    60/  172] train: loss: 0.1589973
[Epoch 91; Iter    90/  172] train: loss: 0.1117261
[Epoch 91; Iter   120/  172] train: loss: 0.1223789
[Epoch 91; Iter   150/  172] train: loss: 0.1158283
[Epoch 91] ogbg-moltoxcast: 0.642960 val loss: 0.300356
[Epoch 91] ogbg-moltoxcast: 0.617317 test loss: 0.351741
[Epoch 92; Iter     8/  172] train: loss: 0.1292899
[Epoch 92; Iter    38/  172] train: loss: 0.0917717
[Epoch 92; Iter    68/  172] train: loss: 0.0700738
[Epoch 92; Iter    98/  172] train: loss: 0.1098152
[Epoch 92; Iter   128/  172] train: loss: 0.1620860
[Epoch 92; Iter   158/  172] train: loss: 0.1442472
[Epoch 92] ogbg-moltoxcast: 0.641167 val loss: 0.303218
[Epoch 92] ogbg-moltoxcast: 0.614451 test loss: 0.353800
[Epoch 93; Iter    16/  172] train: loss: 0.1191053
[Epoch 93; Iter    46/  172] train: loss: 0.0635399
[Epoch 93; Iter    76/  172] train: loss: 0.1016750
[Epoch 93; Iter   106/  172] train: loss: 0.0901648
[Epoch 93; Iter   136/  172] train: loss: 0.1148121
[Epoch 93; Iter   166/  172] train: loss: 0.1148003
[Epoch 93] ogbg-moltoxcast: 0.643222 val loss: 0.299893
[Epoch 93] ogbg-moltoxcast: 0.613707 test loss: 0.352846
[Epoch 94; Iter    24/  172] train: loss: 0.1184030
[Epoch 94; Iter    54/  172] train: loss: 0.0772318
[Epoch 94; Iter    84/  172] train: loss: 0.1094732
[Epoch 76; Iter    15/  229] train: loss: 0.1216180
[Epoch 76; Iter    45/  229] train: loss: 0.1288901
[Epoch 76; Iter    75/  229] train: loss: 0.1514916
[Epoch 76; Iter   105/  229] train: loss: 0.1492043
[Epoch 76; Iter   135/  229] train: loss: 0.1049043
[Epoch 76; Iter   165/  229] train: loss: 0.1363911
[Epoch 76; Iter   195/  229] train: loss: 0.1198963
[Epoch 76; Iter   225/  229] train: loss: 0.1390109
[Epoch 76] ogbg-moltoxcast: 0.684518 val loss: 0.268221
[Epoch 76] ogbg-moltoxcast: 0.651821 test loss: 0.321320
[Epoch 77; Iter    26/  229] train: loss: 0.1266653
[Epoch 77; Iter    56/  229] train: loss: 0.1063505
[Epoch 77; Iter    86/  229] train: loss: 0.1846439
[Epoch 77; Iter   116/  229] train: loss: 0.1266039
[Epoch 77; Iter   146/  229] train: loss: 0.1139984
[Epoch 77; Iter   176/  229] train: loss: 0.1408268
[Epoch 77; Iter   206/  229] train: loss: 0.1384618
[Epoch 77] ogbg-moltoxcast: 0.679536 val loss: 0.273948
[Epoch 77] ogbg-moltoxcast: 0.655712 test loss: 0.315935
[Epoch 78; Iter     7/  229] train: loss: 0.1272261
[Epoch 78; Iter    37/  229] train: loss: 0.1094682
[Epoch 78; Iter    67/  229] train: loss: 0.1002041
[Epoch 78; Iter    97/  229] train: loss: 0.1275194
[Epoch 78; Iter   127/  229] train: loss: 0.1820403
[Epoch 78; Iter   157/  229] train: loss: 0.1077550
[Epoch 78; Iter   187/  229] train: loss: 0.1425039
[Epoch 78; Iter   217/  229] train: loss: 0.1115800
[Epoch 78] ogbg-moltoxcast: 0.683840 val loss: 0.264873
[Epoch 78] ogbg-moltoxcast: 0.655764 test loss: 0.322031
[Epoch 79; Iter    18/  229] train: loss: 0.1847904
[Epoch 79; Iter    48/  229] train: loss: 0.1391112
[Epoch 79; Iter    78/  229] train: loss: 0.1604730
[Epoch 79; Iter   108/  229] train: loss: 0.1411566
[Epoch 79; Iter   138/  229] train: loss: 0.1528254
[Epoch 79; Iter   168/  229] train: loss: 0.1441713
[Epoch 79; Iter   198/  229] train: loss: 0.0913823
[Epoch 79; Iter   228/  229] train: loss: 0.1524176
[Epoch 79] ogbg-moltoxcast: 0.684839 val loss: 0.264734
[Epoch 79] ogbg-moltoxcast: 0.652980 test loss: 0.319514
[Epoch 80; Iter    29/  229] train: loss: 0.1167567
[Epoch 80; Iter    59/  229] train: loss: 0.1138299
[Epoch 80; Iter    89/  229] train: loss: 0.1282360
[Epoch 80; Iter   119/  229] train: loss: 0.1190045
[Epoch 80; Iter   149/  229] train: loss: 0.1290339
[Epoch 80; Iter   179/  229] train: loss: 0.1232306
[Epoch 80; Iter   209/  229] train: loss: 0.1340028
[Epoch 80] ogbg-moltoxcast: 0.684997 val loss: 0.263222
[Epoch 80] ogbg-moltoxcast: 0.655121 test loss: 0.319630
[Epoch 81; Iter    10/  229] train: loss: 0.1278762
[Epoch 81; Iter    40/  229] train: loss: 0.1398017
[Epoch 81; Iter    70/  229] train: loss: 0.1460280
[Epoch 81; Iter   100/  229] train: loss: 0.1371437
[Epoch 81; Iter   130/  229] train: loss: 0.1546746
[Epoch 81; Iter   160/  229] train: loss: 0.1471887
[Epoch 81; Iter   190/  229] train: loss: 0.1447560
[Epoch 81; Iter   220/  229] train: loss: 0.1086786
[Epoch 81] ogbg-moltoxcast: 0.678650 val loss: 0.265647
[Epoch 81] ogbg-moltoxcast: 0.646572 test loss: 0.321958
[Epoch 82; Iter    21/  229] train: loss: 0.0950296
[Epoch 82; Iter    51/  229] train: loss: 0.1422373
[Epoch 82; Iter    81/  229] train: loss: 0.1527483
[Epoch 82; Iter   111/  229] train: loss: 0.1086005
[Epoch 82; Iter   141/  229] train: loss: 0.1053541
[Epoch 82; Iter   171/  229] train: loss: 0.1222141
[Epoch 82; Iter   201/  229] train: loss: 0.1242803
[Epoch 82] ogbg-moltoxcast: 0.683890 val loss: 0.264595
[Epoch 82] ogbg-moltoxcast: 0.655085 test loss: 0.320485
[Epoch 83; Iter     2/  229] train: loss: 0.1794982
[Epoch 83; Iter    32/  229] train: loss: 0.0980214
[Epoch 83; Iter    62/  229] train: loss: 0.1154779
[Epoch 83; Iter    92/  229] train: loss: 0.1311384
[Epoch 83; Iter   122/  229] train: loss: 0.1219626
[Epoch 83; Iter   152/  229] train: loss: 0.0972699
[Epoch 83; Iter   182/  229] train: loss: 0.0902971
[Epoch 83; Iter   212/  229] train: loss: 0.1723235
[Epoch 83] ogbg-moltoxcast: 0.688337 val loss: 0.265024
[Epoch 83] ogbg-moltoxcast: 0.651491 test loss: 0.329065
[Epoch 84; Iter    13/  229] train: loss: 0.1201708
[Epoch 84; Iter    43/  229] train: loss: 0.1170860
[Epoch 84; Iter    73/  229] train: loss: 0.0950276
[Epoch 84; Iter   103/  229] train: loss: 0.1117580
[Epoch 84; Iter   133/  229] train: loss: 0.0809785
[Epoch 84; Iter   163/  229] train: loss: 0.1181768
[Epoch 84; Iter   193/  229] train: loss: 0.1460819
[Epoch 84; Iter   223/  229] train: loss: 0.1139325
[Epoch 84] ogbg-moltoxcast: 0.686263 val loss: 0.265578
[Epoch 84] ogbg-moltoxcast: 0.657934 test loss: 0.318198
[Epoch 85; Iter    24/  229] train: loss: 0.1362413
[Epoch 85; Iter    54/  229] train: loss: 0.1229884
[Epoch 85; Iter    84/  229] train: loss: 0.1222193
[Epoch 85; Iter   114/  229] train: loss: 0.0900758
[Epoch 85; Iter   144/  229] train: loss: 0.1158310
[Epoch 85; Iter   174/  229] train: loss: 0.1787667
[Epoch 85; Iter   204/  229] train: loss: 0.1495861
[Epoch 85] ogbg-moltoxcast: 0.682663 val loss: 0.264648
[Epoch 85] ogbg-moltoxcast: 0.653698 test loss: 0.319798
[Epoch 86; Iter     5/  229] train: loss: 0.1186115
[Epoch 86; Iter    35/  229] train: loss: 0.1295498
[Epoch 86; Iter    65/  229] train: loss: 0.0812607
[Epoch 86; Iter    95/  229] train: loss: 0.1463448
[Epoch 86; Iter   125/  229] train: loss: 0.0805319
[Epoch 86; Iter   155/  229] train: loss: 0.1286198
[Epoch 86; Iter   185/  229] train: loss: 0.1211578
[Epoch 86; Iter   215/  229] train: loss: 0.1591930
[Epoch 86] ogbg-moltoxcast: 0.685425 val loss: 0.262346
[Epoch 86] ogbg-moltoxcast: 0.653080 test loss: 0.321230
[Epoch 87; Iter    16/  229] train: loss: 0.0928775
[Epoch 87; Iter    46/  229] train: loss: 0.1072511
[Epoch 87; Iter    76/  229] train: loss: 0.1330499
[Epoch 87; Iter   106/  229] train: loss: 0.1208631
[Epoch 87; Iter   136/  229] train: loss: 0.1921757
[Epoch 87; Iter   166/  229] train: loss: 0.1152816
[Epoch 87; Iter   196/  229] train: loss: 0.1304796
[Epoch 87; Iter   226/  229] train: loss: 0.1024855
[Epoch 87] ogbg-moltoxcast: 0.689048 val loss: 0.269700
[Epoch 87] ogbg-moltoxcast: 0.650051 test loss: 0.326313
[Epoch 88; Iter    27/  229] train: loss: 0.1431388
[Epoch 88; Iter    57/  229] train: loss: 0.1220671
[Epoch 88; Iter    87/  229] train: loss: 0.1197994
[Epoch 88; Iter   117/  229] train: loss: 0.1504543
[Epoch 88; Iter   147/  229] train: loss: 0.1254318
[Epoch 88; Iter   177/  229] train: loss: 0.1347061
[Epoch 88; Iter   207/  229] train: loss: 0.0998527
[Epoch 88] ogbg-moltoxcast: 0.686474 val loss: 0.265628
[Epoch 88] ogbg-moltoxcast: 0.648011 test loss: 0.326036
[Epoch 89; Iter     8/  229] train: loss: 0.1317554
[Epoch 89; Iter    38/  229] train: loss: 0.1517368
[Epoch 89; Iter    68/  229] train: loss: 0.1531472
[Epoch 89; Iter    98/  229] train: loss: 0.1084116
[Epoch 89; Iter   128/  229] train: loss: 0.1144412
[Epoch 89; Iter   158/  229] train: loss: 0.1110550
[Epoch 89; Iter   188/  229] train: loss: 0.0987934
[Epoch 89; Iter   218/  229] train: loss: 0.1378385
[Epoch 89] ogbg-moltoxcast: 0.688770 val loss: 0.263876
[Epoch 89] ogbg-moltoxcast: 0.649710 test loss: 0.326647
[Epoch 90; Iter    19/  229] train: loss: 0.1294434
[Epoch 90; Iter    49/  229] train: loss: 0.1195644
[Epoch 90; Iter    79/  229] train: loss: 0.1118243
[Epoch 90; Iter   109/  229] train: loss: 0.0889479
[Epoch 90; Iter   139/  229] train: loss: 0.0973006
[Epoch 90; Iter   169/  229] train: loss: 0.1120412
[Epoch 90; Iter   199/  229] train: loss: 0.1635708
[Epoch 90; Iter   229/  229] train: loss: 0.1397034
[Epoch 90] ogbg-moltoxcast: 0.687762 val loss: 0.278005
[Epoch 90] ogbg-moltoxcast: 0.648654 test loss: 0.328560
[Epoch 91; Iter    30/  229] train: loss: 0.1214487
[Epoch 91; Iter    60/  229] train: loss: 0.1542417
[Epoch 91; Iter    90/  229] train: loss: 0.1500910
[Epoch 91; Iter   120/  229] train: loss: 0.1252314
[Epoch 91; Iter   150/  229] train: loss: 0.1551823
[Epoch 91; Iter   180/  229] train: loss: 0.1799817
[Epoch 91; Iter   210/  229] train: loss: 0.1746101
[Epoch 91] ogbg-moltoxcast: 0.682090 val loss: 0.270330
[Epoch 91] ogbg-moltoxcast: 0.647642 test loss: 0.328795
[Epoch 76; Iter    15/  229] train: loss: 0.1516754
[Epoch 76; Iter    45/  229] train: loss: 0.1257138
[Epoch 76; Iter    75/  229] train: loss: 0.2110779
[Epoch 76; Iter   105/  229] train: loss: 0.1249380
[Epoch 76; Iter   135/  229] train: loss: 0.0989254
[Epoch 76; Iter   165/  229] train: loss: 0.1558437
[Epoch 76; Iter   195/  229] train: loss: 0.0833222
[Epoch 76; Iter   225/  229] train: loss: 0.1154949
[Epoch 76] ogbg-moltoxcast: 0.708182 val loss: 0.257546
[Epoch 76] ogbg-moltoxcast: 0.659775 test loss: 0.323984
[Epoch 77; Iter    26/  229] train: loss: 0.1413018
[Epoch 77; Iter    56/  229] train: loss: 0.1218678
[Epoch 77; Iter    86/  229] train: loss: 0.0941015
[Epoch 77; Iter   116/  229] train: loss: 0.1453373
[Epoch 77; Iter   146/  229] train: loss: 0.1159510
[Epoch 77; Iter   176/  229] train: loss: 0.1296290
[Epoch 77; Iter   206/  229] train: loss: 0.1566529
[Epoch 77] ogbg-moltoxcast: 0.706709 val loss: 0.255797
[Epoch 77] ogbg-moltoxcast: 0.657030 test loss: 0.326906
[Epoch 78; Iter     7/  229] train: loss: 0.1513007
[Epoch 78; Iter    37/  229] train: loss: 0.1377399
[Epoch 78; Iter    67/  229] train: loss: 0.0901005
[Epoch 78; Iter    97/  229] train: loss: 0.1395026
[Epoch 78; Iter   127/  229] train: loss: 0.1358119
[Epoch 78; Iter   157/  229] train: loss: 0.1122750
[Epoch 78; Iter   187/  229] train: loss: 0.1098109
[Epoch 78; Iter   217/  229] train: loss: 0.1148407
[Epoch 78] ogbg-moltoxcast: 0.710009 val loss: 0.259560
[Epoch 78] ogbg-moltoxcast: 0.660368 test loss: 0.329657
[Epoch 79; Iter    18/  229] train: loss: 0.0935964
[Epoch 79; Iter    48/  229] train: loss: 0.1324403
[Epoch 79; Iter    78/  229] train: loss: 0.1006164
[Epoch 79; Iter   108/  229] train: loss: 0.1407294
[Epoch 79; Iter   138/  229] train: loss: 0.1072971
[Epoch 79; Iter   168/  229] train: loss: 0.0877221
[Epoch 79; Iter   198/  229] train: loss: 0.0763857
[Epoch 79; Iter   228/  229] train: loss: 0.1702947
[Epoch 79] ogbg-moltoxcast: 0.702666 val loss: 0.261965
[Epoch 79] ogbg-moltoxcast: 0.656418 test loss: 0.328919
[Epoch 80; Iter    29/  229] train: loss: 0.1444027
[Epoch 80; Iter    59/  229] train: loss: 0.1213528
[Epoch 80; Iter    89/  229] train: loss: 0.1081954
[Epoch 80; Iter   119/  229] train: loss: 0.1478110
[Epoch 80; Iter   149/  229] train: loss: 0.1488797
[Epoch 80; Iter   179/  229] train: loss: 0.2449027
[Epoch 80; Iter   209/  229] train: loss: 0.1229551
[Epoch 80] ogbg-moltoxcast: 0.713091 val loss: 0.257301
[Epoch 80] ogbg-moltoxcast: 0.662219 test loss: 0.327097
[Epoch 81; Iter    10/  229] train: loss: 0.0883610
[Epoch 81; Iter    40/  229] train: loss: 0.1222015
[Epoch 81; Iter    70/  229] train: loss: 0.1584891
[Epoch 81; Iter   100/  229] train: loss: 0.1273149
[Epoch 81; Iter   130/  229] train: loss: 0.1201618
[Epoch 81; Iter   160/  229] train: loss: 0.1424432
[Epoch 81; Iter   190/  229] train: loss: 0.1720988
[Epoch 81; Iter   220/  229] train: loss: 0.1040593
[Epoch 81] ogbg-moltoxcast: 0.701794 val loss: 0.259513
[Epoch 81] ogbg-moltoxcast: 0.656985 test loss: 0.328161
[Epoch 82; Iter    21/  229] train: loss: 0.0793555
[Epoch 82; Iter    51/  229] train: loss: 0.1256465
[Epoch 82; Iter    81/  229] train: loss: 0.1133175
[Epoch 82; Iter   111/  229] train: loss: 0.1037869
[Epoch 82; Iter   141/  229] train: loss: 0.1597674
[Epoch 82; Iter   171/  229] train: loss: 0.1111415
[Epoch 82; Iter   201/  229] train: loss: 0.0982408
[Epoch 82] ogbg-moltoxcast: 0.702750 val loss: 0.262182
[Epoch 82] ogbg-moltoxcast: 0.653677 test loss: 0.328216
[Epoch 83; Iter     2/  229] train: loss: 0.0993621
[Epoch 83; Iter    32/  229] train: loss: 0.1641933
[Epoch 83; Iter    62/  229] train: loss: 0.1718207
[Epoch 83; Iter    92/  229] train: loss: 0.1057837
[Epoch 83; Iter   122/  229] train: loss: 0.1106265
[Epoch 83; Iter   152/  229] train: loss: 0.0991076
[Epoch 83; Iter   182/  229] train: loss: 0.1461372
[Epoch 83; Iter   212/  229] train: loss: 0.0893729
[Epoch 83] ogbg-moltoxcast: 0.696578 val loss: 0.263509
[Epoch 83] ogbg-moltoxcast: 0.655776 test loss: 0.328577
[Epoch 84; Iter    13/  229] train: loss: 0.1927166
[Epoch 84; Iter    43/  229] train: loss: 0.1447549
[Epoch 84; Iter    73/  229] train: loss: 0.1831507
[Epoch 84; Iter   103/  229] train: loss: 0.0966401
[Epoch 84; Iter   133/  229] train: loss: 0.1062583
[Epoch 84; Iter   163/  229] train: loss: 0.0973467
[Epoch 84; Iter   193/  229] train: loss: 0.1516183
[Epoch 84; Iter   223/  229] train: loss: 0.1351388
[Epoch 84] ogbg-moltoxcast: 0.707484 val loss: 0.257400
[Epoch 84] ogbg-moltoxcast: 0.661030 test loss: 0.330634
[Epoch 85; Iter    24/  229] train: loss: 0.0754881
[Epoch 85; Iter    54/  229] train: loss: 0.1435003
[Epoch 85; Iter    84/  229] train: loss: 0.1241552
[Epoch 85; Iter   114/  229] train: loss: 0.0869251
[Epoch 85; Iter   144/  229] train: loss: 0.1103687
[Epoch 85; Iter   174/  229] train: loss: 0.1441422
[Epoch 85; Iter   204/  229] train: loss: 0.1289707
[Epoch 85] ogbg-moltoxcast: 0.707270 val loss: 0.259207
[Epoch 85] ogbg-moltoxcast: 0.655321 test loss: 0.330886
[Epoch 86; Iter     5/  229] train: loss: 0.0943768
[Epoch 86; Iter    35/  229] train: loss: 0.1736055
[Epoch 86; Iter    65/  229] train: loss: 0.1549749
[Epoch 86; Iter    95/  229] train: loss: 0.1417799
[Epoch 86; Iter   125/  229] train: loss: 0.1116880
[Epoch 86; Iter   155/  229] train: loss: 0.1543038
[Epoch 86; Iter   185/  229] train: loss: 0.1660513
[Epoch 86; Iter   215/  229] train: loss: 0.1419515
[Epoch 86] ogbg-moltoxcast: 0.700854 val loss: 0.260491
[Epoch 86] ogbg-moltoxcast: 0.650628 test loss: 0.329986
[Epoch 87; Iter    16/  229] train: loss: 0.1343838
[Epoch 87; Iter    46/  229] train: loss: 0.1502700
[Epoch 87; Iter    76/  229] train: loss: 0.0776299
[Epoch 87; Iter   106/  229] train: loss: 0.1064354
[Epoch 87; Iter   136/  229] train: loss: 0.1041525
[Epoch 87; Iter   166/  229] train: loss: 0.1253902
[Epoch 87; Iter   196/  229] train: loss: 0.1725759
[Epoch 87; Iter   226/  229] train: loss: 0.1451691
[Epoch 87] ogbg-moltoxcast: 0.705459 val loss: 0.260009
[Epoch 87] ogbg-moltoxcast: 0.655134 test loss: 0.331588
[Epoch 88; Iter    27/  229] train: loss: 0.1120341
[Epoch 88; Iter    57/  229] train: loss: 0.0798438
[Epoch 88; Iter    87/  229] train: loss: 0.1107655
[Epoch 88; Iter   117/  229] train: loss: 0.1120161
[Epoch 88; Iter   147/  229] train: loss: 0.1372761
[Epoch 88; Iter   177/  229] train: loss: 0.0921308
[Epoch 88; Iter   207/  229] train: loss: 0.1143455
[Epoch 88] ogbg-moltoxcast: 0.702350 val loss: 0.261741
[Epoch 88] ogbg-moltoxcast: 0.656393 test loss: 0.326926
[Epoch 89; Iter     8/  229] train: loss: 0.1182712
[Epoch 89; Iter    38/  229] train: loss: 0.1436438
[Epoch 89; Iter    68/  229] train: loss: 0.1179347
[Epoch 89; Iter    98/  229] train: loss: 0.1448350
[Epoch 89; Iter   128/  229] train: loss: 0.1696409
[Epoch 89; Iter   158/  229] train: loss: 0.1217455
[Epoch 89; Iter   188/  229] train: loss: 0.0726266
[Epoch 89; Iter   218/  229] train: loss: 0.1317188
[Epoch 89] ogbg-moltoxcast: 0.704228 val loss: 0.260802
[Epoch 89] ogbg-moltoxcast: 0.653087 test loss: 0.333866
[Epoch 90; Iter    19/  229] train: loss: 0.1045841
[Epoch 90; Iter    49/  229] train: loss: 0.1068594
[Epoch 90; Iter    79/  229] train: loss: 0.0904519
[Epoch 90; Iter   109/  229] train: loss: 0.1159616
[Epoch 90; Iter   139/  229] train: loss: 0.1660443
[Epoch 90; Iter   169/  229] train: loss: 0.1589657
[Epoch 90; Iter   199/  229] train: loss: 0.1434389
[Epoch 90; Iter   229/  229] train: loss: 0.1654634
[Epoch 90] ogbg-moltoxcast: 0.705197 val loss: 0.261316
[Epoch 90] ogbg-moltoxcast: 0.652878 test loss: 0.332492
[Epoch 91; Iter    30/  229] train: loss: 0.0936314
[Epoch 91; Iter    60/  229] train: loss: 0.1174171
[Epoch 91; Iter    90/  229] train: loss: 0.1156662
[Epoch 91; Iter   120/  229] train: loss: 0.1327428
[Epoch 91; Iter   150/  229] train: loss: 0.0902285
[Epoch 91; Iter   180/  229] train: loss: 0.1557158
[Epoch 91; Iter   210/  229] train: loss: 0.1401102
[Epoch 91] ogbg-moltoxcast: 0.705242 val loss: 0.260983
[Epoch 91] ogbg-moltoxcast: 0.657092 test loss: 0.333122
[Epoch 76; Iter    15/  229] train: loss: 0.1186640
[Epoch 76; Iter    45/  229] train: loss: 0.1349458
[Epoch 76; Iter    75/  229] train: loss: 0.1459191
[Epoch 76; Iter   105/  229] train: loss: 0.0968128
[Epoch 76; Iter   135/  229] train: loss: 0.1879648
[Epoch 76; Iter   165/  229] train: loss: 0.1050539
[Epoch 76; Iter   195/  229] train: loss: 0.1339436
[Epoch 76; Iter   225/  229] train: loss: 0.1038949
[Epoch 76] ogbg-moltoxcast: 0.690059 val loss: 0.925041
[Epoch 76] ogbg-moltoxcast: 0.660176 test loss: 0.322863
[Epoch 77; Iter    26/  229] train: loss: 0.1567417
[Epoch 77; Iter    56/  229] train: loss: 0.1100883
[Epoch 77; Iter    86/  229] train: loss: 0.2034928
[Epoch 77; Iter   116/  229] train: loss: 0.1703392
[Epoch 77; Iter   146/  229] train: loss: 0.1425924
[Epoch 77; Iter   176/  229] train: loss: 0.1611566
[Epoch 77; Iter   206/  229] train: loss: 0.1495003
[Epoch 77] ogbg-moltoxcast: 0.693172 val loss: 0.267285
[Epoch 77] ogbg-moltoxcast: 0.658740 test loss: 0.319094
[Epoch 78; Iter     7/  229] train: loss: 0.1385339
[Epoch 78; Iter    37/  229] train: loss: 0.1368604
[Epoch 78; Iter    67/  229] train: loss: 0.1249177
[Epoch 78; Iter    97/  229] train: loss: 0.0954024
[Epoch 78; Iter   127/  229] train: loss: 0.1227423
[Epoch 78; Iter   157/  229] train: loss: 0.1236674
[Epoch 78; Iter   187/  229] train: loss: 0.1683469
[Epoch 78; Iter   217/  229] train: loss: 0.1486775
[Epoch 78] ogbg-moltoxcast: 0.691386 val loss: 0.270269
[Epoch 78] ogbg-moltoxcast: 0.659234 test loss: 0.321879
[Epoch 79; Iter    18/  229] train: loss: 0.1259206
[Epoch 79; Iter    48/  229] train: loss: 0.1386486
[Epoch 79; Iter    78/  229] train: loss: 0.1742998
[Epoch 79; Iter   108/  229] train: loss: 0.1647261
[Epoch 79; Iter   138/  229] train: loss: 0.1864935
[Epoch 79; Iter   168/  229] train: loss: 0.1645059
[Epoch 79; Iter   198/  229] train: loss: 0.1461007
[Epoch 79; Iter   228/  229] train: loss: 0.1672788
[Epoch 79] ogbg-moltoxcast: 0.689053 val loss: 0.268920
[Epoch 79] ogbg-moltoxcast: 0.663170 test loss: 0.316874
[Epoch 80; Iter    29/  229] train: loss: 0.1472985
[Epoch 80; Iter    59/  229] train: loss: 0.1401699
[Epoch 80; Iter    89/  229] train: loss: 0.1573776
[Epoch 80; Iter   119/  229] train: loss: 0.1187538
[Epoch 80; Iter   149/  229] train: loss: 0.1439054
[Epoch 80; Iter   179/  229] train: loss: 0.1532704
[Epoch 80; Iter   209/  229] train: loss: 0.1480061
[Epoch 80] ogbg-moltoxcast: 0.685897 val loss: 0.272773
[Epoch 80] ogbg-moltoxcast: 0.661194 test loss: 0.321743
[Epoch 81; Iter    10/  229] train: loss: 0.0992415
[Epoch 81; Iter    40/  229] train: loss: 0.1452856
[Epoch 81; Iter    70/  229] train: loss: 0.1430040
[Epoch 81; Iter   100/  229] train: loss: 0.0804935
[Epoch 81; Iter   130/  229] train: loss: 0.0917775
[Epoch 81; Iter   160/  229] train: loss: 0.1543238
[Epoch 81; Iter   190/  229] train: loss: 0.1395002
[Epoch 81; Iter   220/  229] train: loss: 0.1400438
[Epoch 81] ogbg-moltoxcast: 0.689797 val loss: 0.270157
[Epoch 81] ogbg-moltoxcast: 0.663343 test loss: 0.320140
[Epoch 82; Iter    21/  229] train: loss: 0.1389135
[Epoch 82; Iter    51/  229] train: loss: 0.1399201
[Epoch 82; Iter    81/  229] train: loss: 0.1045020
[Epoch 82; Iter   111/  229] train: loss: 0.1130289
[Epoch 82; Iter   141/  229] train: loss: 0.1408804
[Epoch 82; Iter   171/  229] train: loss: 0.1140222
[Epoch 82; Iter   201/  229] train: loss: 0.1438641
[Epoch 82] ogbg-moltoxcast: 0.688300 val loss: 0.272681
[Epoch 82] ogbg-moltoxcast: 0.664178 test loss: 0.320266
[Epoch 83; Iter     2/  229] train: loss: 0.1225699
[Epoch 83; Iter    32/  229] train: loss: 0.1216863
[Epoch 83; Iter    62/  229] train: loss: 0.0946094
[Epoch 83; Iter    92/  229] train: loss: 0.1629137
[Epoch 83; Iter   122/  229] train: loss: 0.1302183
[Epoch 83; Iter   152/  229] train: loss: 0.1477346
[Epoch 83; Iter   182/  229] train: loss: 0.1801952
[Epoch 83; Iter   212/  229] train: loss: 0.1213184
[Epoch 83] ogbg-moltoxcast: 0.693384 val loss: 0.268946
[Epoch 83] ogbg-moltoxcast: 0.661599 test loss: 0.320676
[Epoch 84; Iter    13/  229] train: loss: 0.1510578
[Epoch 84; Iter    43/  229] train: loss: 0.1252884
[Epoch 84; Iter    73/  229] train: loss: 0.1615339
[Epoch 84; Iter   103/  229] train: loss: 0.1207243
[Epoch 84; Iter   133/  229] train: loss: 0.1398383
[Epoch 84; Iter   163/  229] train: loss: 0.0939134
[Epoch 84; Iter   193/  229] train: loss: 0.1396157
[Epoch 84; Iter   223/  229] train: loss: 0.1073102
[Epoch 84] ogbg-moltoxcast: 0.690013 val loss: 0.277931
[Epoch 84] ogbg-moltoxcast: 0.660873 test loss: 0.327097
[Epoch 85; Iter    24/  229] train: loss: 0.1264033
[Epoch 85; Iter    54/  229] train: loss: 0.1133782
[Epoch 85; Iter    84/  229] train: loss: 0.1141270
[Epoch 85; Iter   114/  229] train: loss: 0.1032804
[Epoch 85; Iter   144/  229] train: loss: 0.1416849
[Epoch 85; Iter   174/  229] train: loss: 0.1460932
[Epoch 85; Iter   204/  229] train: loss: 0.1640097
[Epoch 85] ogbg-moltoxcast: 0.690005 val loss: 0.271110
[Epoch 85] ogbg-moltoxcast: 0.655467 test loss: 0.324481
[Epoch 86; Iter     5/  229] train: loss: 0.1885917
[Epoch 86; Iter    35/  229] train: loss: 0.1532487
[Epoch 86; Iter    65/  229] train: loss: 0.1338170
[Epoch 86; Iter    95/  229] train: loss: 0.1603418
[Epoch 86; Iter   125/  229] train: loss: 0.1350468
[Epoch 86; Iter   155/  229] train: loss: 0.1280380
[Epoch 86; Iter   185/  229] train: loss: 0.1456458
[Epoch 86; Iter   215/  229] train: loss: 0.1512364
[Epoch 86] ogbg-moltoxcast: 0.691523 val loss: 0.282047
[Epoch 86] ogbg-moltoxcast: 0.661957 test loss: 0.330338
[Epoch 87; Iter    16/  229] train: loss: 0.1186644
[Epoch 87; Iter    46/  229] train: loss: 0.1250103
[Epoch 87; Iter    76/  229] train: loss: 0.1116126
[Epoch 87; Iter   106/  229] train: loss: 0.1296953
[Epoch 87; Iter   136/  229] train: loss: 0.1365886
[Epoch 87; Iter   166/  229] train: loss: 0.1365872
[Epoch 87; Iter   196/  229] train: loss: 0.1326070
[Epoch 87; Iter   226/  229] train: loss: 0.1271867
[Epoch 87] ogbg-moltoxcast: 0.688302 val loss: 0.295851
[Epoch 87] ogbg-moltoxcast: 0.659744 test loss: 0.329724
[Epoch 88; Iter    27/  229] train: loss: 0.1894460
[Epoch 88; Iter    57/  229] train: loss: 0.1174178
[Epoch 88; Iter    87/  229] train: loss: 0.1153754
[Epoch 88; Iter   117/  229] train: loss: 0.1309561
[Epoch 88; Iter   147/  229] train: loss: 0.1096400
[Epoch 88; Iter   177/  229] train: loss: 0.1279887
[Epoch 88; Iter   207/  229] train: loss: 0.1421267
[Epoch 88] ogbg-moltoxcast: 0.688735 val loss: 0.298904
[Epoch 88] ogbg-moltoxcast: 0.656473 test loss: 0.327104
[Epoch 89; Iter     8/  229] train: loss: 0.1069630
[Epoch 89; Iter    38/  229] train: loss: 0.1140723
[Epoch 89; Iter    68/  229] train: loss: 0.1509909
[Epoch 89; Iter    98/  229] train: loss: 0.1169369
[Epoch 89; Iter   128/  229] train: loss: 0.1251385
[Epoch 89; Iter   158/  229] train: loss: 0.1308448
[Epoch 89; Iter   188/  229] train: loss: 0.1247196
[Epoch 89; Iter   218/  229] train: loss: 0.0973839
[Epoch 89] ogbg-moltoxcast: 0.688516 val loss: 0.281356
[Epoch 89] ogbg-moltoxcast: 0.660045 test loss: 0.336133
[Epoch 90; Iter    19/  229] train: loss: 0.1298024
[Epoch 90; Iter    49/  229] train: loss: 0.1660183
[Epoch 90; Iter    79/  229] train: loss: 0.1657084
[Epoch 90; Iter   109/  229] train: loss: 0.1766809
[Epoch 90; Iter   139/  229] train: loss: 0.1537526
[Epoch 90; Iter   169/  229] train: loss: 0.1377521
[Epoch 90; Iter   199/  229] train: loss: 0.1031968
[Epoch 90; Iter   229/  229] train: loss: 0.1230778
[Epoch 90] ogbg-moltoxcast: 0.684883 val loss: 0.274842
[Epoch 90] ogbg-moltoxcast: 0.657290 test loss: 0.324477
[Epoch 91; Iter    30/  229] train: loss: 0.1366888
[Epoch 91; Iter    60/  229] train: loss: 0.1025818
[Epoch 91; Iter    90/  229] train: loss: 0.1278075
[Epoch 91; Iter   120/  229] train: loss: 0.1087580
[Epoch 91; Iter   150/  229] train: loss: 0.1336156
[Epoch 91; Iter   180/  229] train: loss: 0.1324562
[Epoch 91; Iter   210/  229] train: loss: 0.1579621
[Epoch 91] ogbg-moltoxcast: 0.688359 val loss: 0.276922
[Epoch 91] ogbg-moltoxcast: 0.659456 test loss: 0.326593
[Epoch 84; Iter    27/  201] train: loss: 0.1012010
[Epoch 84; Iter    57/  201] train: loss: 0.1010555
[Epoch 84; Iter    87/  201] train: loss: 0.0919492
[Epoch 84; Iter   117/  201] train: loss: 0.0866476
[Epoch 84; Iter   147/  201] train: loss: 0.1182397
[Epoch 84; Iter   177/  201] train: loss: 0.1192622
[Epoch 84] ogbg-moltoxcast: 0.665160 val loss: 0.277586
[Epoch 84] ogbg-moltoxcast: 0.652801 test loss: 0.317492
[Epoch 85; Iter     6/  201] train: loss: 0.0765290
[Epoch 85; Iter    36/  201] train: loss: 0.1828099
[Epoch 85; Iter    66/  201] train: loss: 0.0934136
[Epoch 85; Iter    96/  201] train: loss: 0.0932678
[Epoch 85; Iter   126/  201] train: loss: 0.1708400
[Epoch 85; Iter   156/  201] train: loss: 0.1057439
[Epoch 85; Iter   186/  201] train: loss: 0.1420284
[Epoch 85] ogbg-moltoxcast: 0.662494 val loss: 0.288258
[Epoch 85] ogbg-moltoxcast: 0.654959 test loss: 0.328487
[Epoch 86; Iter    15/  201] train: loss: 0.1778437
[Epoch 86; Iter    45/  201] train: loss: 0.0903346
[Epoch 86; Iter    75/  201] train: loss: 0.1017543
[Epoch 86; Iter   105/  201] train: loss: 0.1192709
[Epoch 86; Iter   135/  201] train: loss: 0.1730426
[Epoch 86; Iter   165/  201] train: loss: 0.1341030
[Epoch 86; Iter   195/  201] train: loss: 0.1106671
[Epoch 86] ogbg-moltoxcast: 0.661437 val loss: 0.277146
[Epoch 86] ogbg-moltoxcast: 0.654329 test loss: 0.315560
[Epoch 87; Iter    24/  201] train: loss: 0.1377127
[Epoch 87; Iter    54/  201] train: loss: 0.1712676
[Epoch 87; Iter    84/  201] train: loss: 0.1182948
[Epoch 87; Iter   114/  201] train: loss: 0.1288170
[Epoch 87; Iter   144/  201] train: loss: 0.1731589
[Epoch 87; Iter   174/  201] train: loss: 0.1117701
[Epoch 87] ogbg-moltoxcast: 0.667102 val loss: 0.277860
[Epoch 87] ogbg-moltoxcast: 0.656993 test loss: 0.317042
[Epoch 88; Iter     3/  201] train: loss: 0.1051246
[Epoch 88; Iter    33/  201] train: loss: 0.1089456
[Epoch 88; Iter    63/  201] train: loss: 0.1216938
[Epoch 88; Iter    93/  201] train: loss: 0.1126753
[Epoch 88; Iter   123/  201] train: loss: 0.1229274
[Epoch 88; Iter   153/  201] train: loss: 0.0892092
[Epoch 88; Iter   183/  201] train: loss: 0.1178484
[Epoch 88] ogbg-moltoxcast: 0.660184 val loss: 0.289240
[Epoch 88] ogbg-moltoxcast: 0.653534 test loss: 0.329054
[Epoch 89; Iter    12/  201] train: loss: 0.1018930
[Epoch 89; Iter    42/  201] train: loss: 0.1201668
[Epoch 89; Iter    72/  201] train: loss: 0.0770053
[Epoch 89; Iter   102/  201] train: loss: 0.1259360
[Epoch 89; Iter   132/  201] train: loss: 0.1102297
[Epoch 89; Iter   162/  201] train: loss: 0.1068384
[Epoch 89; Iter   192/  201] train: loss: 0.1057899
[Epoch 89] ogbg-moltoxcast: 0.659302 val loss: 0.280217
[Epoch 89] ogbg-moltoxcast: 0.652088 test loss: 0.319253
[Epoch 90; Iter    21/  201] train: loss: 0.1632937
[Epoch 90; Iter    51/  201] train: loss: 0.1188997
[Epoch 90; Iter    81/  201] train: loss: 0.1475611
[Epoch 90; Iter   111/  201] train: loss: 0.1263627
[Epoch 90; Iter   141/  201] train: loss: 0.1271649
[Epoch 90; Iter   171/  201] train: loss: 0.1185837
[Epoch 90; Iter   201/  201] train: loss: 0.0602969
[Epoch 90] ogbg-moltoxcast: 0.669054 val loss: 0.279665
[Epoch 90] ogbg-moltoxcast: 0.658304 test loss: 0.318670
[Epoch 91; Iter    30/  201] train: loss: 0.1121183
[Epoch 91; Iter    60/  201] train: loss: 0.1039472
[Epoch 91; Iter    90/  201] train: loss: 0.1349668
[Epoch 91; Iter   120/  201] train: loss: 0.1050364
[Epoch 91; Iter   150/  201] train: loss: 0.1189118
[Epoch 91; Iter   180/  201] train: loss: 0.1191336
[Epoch 91] ogbg-moltoxcast: 0.661177 val loss: 0.282561
[Epoch 91] ogbg-moltoxcast: 0.652626 test loss: 0.321001
[Epoch 92; Iter     9/  201] train: loss: 0.1510718
[Epoch 92; Iter    39/  201] train: loss: 0.1435868
[Epoch 92; Iter    69/  201] train: loss: 0.1063765
[Epoch 92; Iter    99/  201] train: loss: 0.1883758
[Epoch 92; Iter   129/  201] train: loss: 0.1520480
[Epoch 92; Iter   159/  201] train: loss: 0.0856070
[Epoch 92; Iter   189/  201] train: loss: 0.1556067
[Epoch 92] ogbg-moltoxcast: 0.664987 val loss: 0.279944
[Epoch 92] ogbg-moltoxcast: 0.655687 test loss: 0.320164
[Epoch 93; Iter    18/  201] train: loss: 0.1093721
[Epoch 93; Iter    48/  201] train: loss: 0.1242910
[Epoch 93; Iter    78/  201] train: loss: 0.1052054
[Epoch 93; Iter   108/  201] train: loss: 0.1584729
[Epoch 93; Iter   138/  201] train: loss: 0.0940694
[Epoch 93; Iter   168/  201] train: loss: 0.1096282
[Epoch 93; Iter   198/  201] train: loss: 0.1178817
[Epoch 93] ogbg-moltoxcast: 0.665564 val loss: 0.285348
[Epoch 93] ogbg-moltoxcast: 0.657614 test loss: 0.323684
[Epoch 94; Iter    27/  201] train: loss: 0.1168666
[Epoch 94; Iter    57/  201] train: loss: 0.0890236
[Epoch 94; Iter    87/  201] train: loss: 0.1303333
[Epoch 94; Iter   117/  201] train: loss: 0.1548603
[Epoch 94; Iter   147/  201] train: loss: 0.1338670
[Epoch 94; Iter   177/  201] train: loss: 0.0807190
[Epoch 94] ogbg-moltoxcast: 0.665220 val loss: 0.279984
[Epoch 94] ogbg-moltoxcast: 0.655754 test loss: 0.321081
[Epoch 95; Iter     6/  201] train: loss: 0.1036405
[Epoch 95; Iter    36/  201] train: loss: 0.1384400
[Epoch 95; Iter    66/  201] train: loss: 0.0887693
[Epoch 95; Iter    96/  201] train: loss: 0.1546074
[Epoch 95; Iter   126/  201] train: loss: 0.1053765
[Epoch 95; Iter   156/  201] train: loss: 0.1337641
[Epoch 95; Iter   186/  201] train: loss: 0.1171891
[Epoch 95] ogbg-moltoxcast: 0.661747 val loss: 0.282150
[Epoch 95] ogbg-moltoxcast: 0.651886 test loss: 0.322259
[Epoch 96; Iter    15/  201] train: loss: 0.1378644
[Epoch 96; Iter    45/  201] train: loss: 0.1046736
[Epoch 96; Iter    75/  201] train: loss: 0.1386553
[Epoch 96; Iter   105/  201] train: loss: 0.1219404
[Epoch 96; Iter   135/  201] train: loss: 0.0880904
[Epoch 96; Iter   165/  201] train: loss: 0.1462545
[Epoch 96; Iter   195/  201] train: loss: 0.1448792
[Epoch 96] ogbg-moltoxcast: 0.667306 val loss: 0.277287
[Epoch 96] ogbg-moltoxcast: 0.655057 test loss: 0.319942
[Epoch 97; Iter    24/  201] train: loss: 0.1285400
[Epoch 97; Iter    54/  201] train: loss: 0.1345236
[Epoch 97; Iter    84/  201] train: loss: 0.1189195
[Epoch 97; Iter   114/  201] train: loss: 0.0985001
[Epoch 97; Iter   144/  201] train: loss: 0.1079461
[Epoch 97; Iter   174/  201] train: loss: 0.1219960
[Epoch 97] ogbg-moltoxcast: 0.662859 val loss: 0.285981
[Epoch 97] ogbg-moltoxcast: 0.655263 test loss: 0.327351
[Epoch 98; Iter     3/  201] train: loss: 0.1224888
[Epoch 98; Iter    33/  201] train: loss: 0.0737058
[Epoch 98; Iter    63/  201] train: loss: 0.0864016
[Epoch 98; Iter    93/  201] train: loss: 0.1300955
[Epoch 98; Iter   123/  201] train: loss: 0.1405988
[Epoch 98; Iter   153/  201] train: loss: 0.1276997
[Epoch 98; Iter   183/  201] train: loss: 0.1114227
[Epoch 98] ogbg-moltoxcast: 0.665413 val loss: 0.280205
[Epoch 98] ogbg-moltoxcast: 0.653956 test loss: 0.321397
[Epoch 99; Iter    12/  201] train: loss: 0.0940354
[Epoch 99; Iter    42/  201] train: loss: 0.1040299
[Epoch 99; Iter    72/  201] train: loss: 0.1277725
[Epoch 99; Iter   102/  201] train: loss: 0.1195483
[Epoch 99; Iter   132/  201] train: loss: 0.1335552
[Epoch 99; Iter   162/  201] train: loss: 0.1608170
[Epoch 99; Iter   192/  201] train: loss: 0.0880675
[Epoch 99] ogbg-moltoxcast: 0.661822 val loss: 0.286000
[Epoch 99] ogbg-moltoxcast: 0.654920 test loss: 0.326388
[Epoch 100; Iter    21/  201] train: loss: 0.1080410
[Epoch 100; Iter    51/  201] train: loss: 0.1421505
[Epoch 100; Iter    81/  201] train: loss: 0.0505440
[Epoch 100; Iter   111/  201] train: loss: 0.1126085
[Epoch 100; Iter   141/  201] train: loss: 0.0974928
[Epoch 100; Iter   171/  201] train: loss: 0.0862384
[Epoch 100; Iter   201/  201] train: loss: 0.2210451
[Epoch 100] ogbg-moltoxcast: 0.666402 val loss: 0.287467
[Epoch 100] ogbg-moltoxcast: 0.656273 test loss: 0.326402
[Epoch 101; Iter    30/  201] train: loss: 0.0873866
[Epoch 101; Iter    60/  201] train: loss: 0.0949359
[Epoch 101; Iter    90/  201] train: loss: 0.1551223
[Epoch 101; Iter   120/  201] train: loss: 0.1711133
[Epoch 101; Iter   150/  201] train: loss: 0.1252169
[Epoch 101; Iter   180/  201] train: loss: 0.1274257
[Epoch 84; Iter    27/  201] train: loss: 0.1342215
[Epoch 84; Iter    57/  201] train: loss: 0.1212978
[Epoch 84; Iter    87/  201] train: loss: 0.1396627
[Epoch 84; Iter   117/  201] train: loss: 0.1893528
[Epoch 84; Iter   147/  201] train: loss: 0.0965564
[Epoch 84; Iter   177/  201] train: loss: 0.1357439
[Epoch 84] ogbg-moltoxcast: 0.674295 val loss: 0.282251
[Epoch 84] ogbg-moltoxcast: 0.659441 test loss: 0.326039
[Epoch 85; Iter     6/  201] train: loss: 0.1271068
[Epoch 85; Iter    36/  201] train: loss: 0.1612056
[Epoch 85; Iter    66/  201] train: loss: 0.1269065
[Epoch 85; Iter    96/  201] train: loss: 0.1163355
[Epoch 85; Iter   126/  201] train: loss: 0.1345399
[Epoch 85; Iter   156/  201] train: loss: 0.1049511
[Epoch 85; Iter   186/  201] train: loss: 0.1213012
[Epoch 85] ogbg-moltoxcast: 0.676610 val loss: 0.275569
[Epoch 85] ogbg-moltoxcast: 0.659567 test loss: 0.316490
[Epoch 86; Iter    15/  201] train: loss: 0.0999051
[Epoch 86; Iter    45/  201] train: loss: 0.1313634
[Epoch 86; Iter    75/  201] train: loss: 0.0852141
[Epoch 86; Iter   105/  201] train: loss: 0.1266496
[Epoch 86; Iter   135/  201] train: loss: 0.1904097
[Epoch 86; Iter   165/  201] train: loss: 0.0955721
[Epoch 86; Iter   195/  201] train: loss: 0.0818368
[Epoch 86] ogbg-moltoxcast: 0.673781 val loss: 0.280374
[Epoch 86] ogbg-moltoxcast: 0.657913 test loss: 0.321893
[Epoch 87; Iter    24/  201] train: loss: 0.1036512
[Epoch 87; Iter    54/  201] train: loss: 0.1231928
[Epoch 87; Iter    84/  201] train: loss: 0.1555250
[Epoch 87; Iter   114/  201] train: loss: 0.1568236
[Epoch 87; Iter   144/  201] train: loss: 0.1044070
[Epoch 87; Iter   174/  201] train: loss: 0.0971401
[Epoch 87] ogbg-moltoxcast: 0.665833 val loss: 0.280533
[Epoch 87] ogbg-moltoxcast: 0.653430 test loss: 0.323818
[Epoch 88; Iter     3/  201] train: loss: 0.1127594
[Epoch 88; Iter    33/  201] train: loss: 0.1366679
[Epoch 88; Iter    63/  201] train: loss: 0.1367160
[Epoch 88; Iter    93/  201] train: loss: 0.1233116
[Epoch 88; Iter   123/  201] train: loss: 0.1312301
[Epoch 88; Iter   153/  201] train: loss: 0.1221329
[Epoch 88; Iter   183/  201] train: loss: 0.1164660
[Epoch 88] ogbg-moltoxcast: 0.672051 val loss: 0.278199
[Epoch 88] ogbg-moltoxcast: 0.654524 test loss: 0.320266
[Epoch 89; Iter    12/  201] train: loss: 0.1297571
[Epoch 89; Iter    42/  201] train: loss: 0.1389119
[Epoch 89; Iter    72/  201] train: loss: 0.1677935
[Epoch 89; Iter   102/  201] train: loss: 0.1406208
[Epoch 89; Iter   132/  201] train: loss: 0.1643351
[Epoch 89; Iter   162/  201] train: loss: 0.1134123
[Epoch 89; Iter   192/  201] train: loss: 0.1112202
[Epoch 89] ogbg-moltoxcast: 0.670319 val loss: 0.278401
[Epoch 89] ogbg-moltoxcast: 0.659987 test loss: 0.316854
[Epoch 90; Iter    21/  201] train: loss: 0.1816896
[Epoch 90; Iter    51/  201] train: loss: 0.0977261
[Epoch 90; Iter    81/  201] train: loss: 0.1132686
[Epoch 90; Iter   111/  201] train: loss: 0.1436384
[Epoch 90; Iter   141/  201] train: loss: 0.1399552
[Epoch 90; Iter   171/  201] train: loss: 0.1448698
[Epoch 90; Iter   201/  201] train: loss: 0.0419207
[Epoch 90] ogbg-moltoxcast: 0.673654 val loss: 0.278529
[Epoch 90] ogbg-moltoxcast: 0.658350 test loss: 0.319554
[Epoch 91; Iter    30/  201] train: loss: 0.1356756
[Epoch 91; Iter    60/  201] train: loss: 0.1069324
[Epoch 91; Iter    90/  201] train: loss: 0.1226293
[Epoch 91; Iter   120/  201] train: loss: 0.1047473
[Epoch 91; Iter   150/  201] train: loss: 0.1345884
[Epoch 91; Iter   180/  201] train: loss: 0.1081761
[Epoch 91] ogbg-moltoxcast: 0.670896 val loss: 0.283185
[Epoch 91] ogbg-moltoxcast: 0.657526 test loss: 0.321168
[Epoch 92; Iter     9/  201] train: loss: 0.1283128
[Epoch 92; Iter    39/  201] train: loss: 0.0727929
[Epoch 92; Iter    69/  201] train: loss: 0.1510837
[Epoch 92; Iter    99/  201] train: loss: 0.0857164
[Epoch 92; Iter   129/  201] train: loss: 0.1745162
[Epoch 92; Iter   159/  201] train: loss: 0.1435873
[Epoch 92; Iter   189/  201] train: loss: 0.1545757
[Epoch 92] ogbg-moltoxcast: 0.670055 val loss: 0.284774
[Epoch 92] ogbg-moltoxcast: 0.656520 test loss: 0.325657
[Epoch 93; Iter    18/  201] train: loss: 0.1426713
[Epoch 93; Iter    48/  201] train: loss: 0.1419317
[Epoch 93; Iter    78/  201] train: loss: 0.0986201
[Epoch 93; Iter   108/  201] train: loss: 0.1507237
[Epoch 93; Iter   138/  201] train: loss: 0.1497758
[Epoch 93; Iter   168/  201] train: loss: 0.1086868
[Epoch 93; Iter   198/  201] train: loss: 0.1142578
[Epoch 93] ogbg-moltoxcast: 0.672550 val loss: 0.280492
[Epoch 93] ogbg-moltoxcast: 0.659059 test loss: 0.322026
[Epoch 94; Iter    27/  201] train: loss: 0.1336133
[Epoch 94; Iter    57/  201] train: loss: 0.1135060
[Epoch 94; Iter    87/  201] train: loss: 0.1055683
[Epoch 94; Iter   117/  201] train: loss: 0.1307482
[Epoch 94; Iter   147/  201] train: loss: 0.1451481
[Epoch 94; Iter   177/  201] train: loss: 0.1614011
[Epoch 94] ogbg-moltoxcast: 0.671779 val loss: 0.283174
[Epoch 94] ogbg-moltoxcast: 0.659380 test loss: 0.324206
[Epoch 95; Iter     6/  201] train: loss: 0.1201132
[Epoch 95; Iter    36/  201] train: loss: 0.1449385
[Epoch 95; Iter    66/  201] train: loss: 0.1226573
[Epoch 95; Iter    96/  201] train: loss: 0.1720838
[Epoch 95; Iter   126/  201] train: loss: 0.1246158
[Epoch 95; Iter   156/  201] train: loss: 0.1298339
[Epoch 95; Iter   186/  201] train: loss: 0.1471923
[Epoch 95] ogbg-moltoxcast: 0.672964 val loss: 0.280629
[Epoch 95] ogbg-moltoxcast: 0.658503 test loss: 0.324918
[Epoch 96; Iter    15/  201] train: loss: 0.1444836
[Epoch 96; Iter    45/  201] train: loss: 0.1790379
[Epoch 96; Iter    75/  201] train: loss: 0.1052009
[Epoch 96; Iter   105/  201] train: loss: 0.1284949
[Epoch 96; Iter   135/  201] train: loss: 0.1347862
[Epoch 96; Iter   165/  201] train: loss: 0.1473755
[Epoch 96; Iter   195/  201] train: loss: 0.1066191
[Epoch 96] ogbg-moltoxcast: 0.672178 val loss: 0.280967
[Epoch 96] ogbg-moltoxcast: 0.656894 test loss: 0.325300
[Epoch 97; Iter    24/  201] train: loss: 0.1379867
[Epoch 97; Iter    54/  201] train: loss: 0.1089725
[Epoch 97; Iter    84/  201] train: loss: 0.1551459
[Epoch 97; Iter   114/  201] train: loss: 0.1173900
[Epoch 97; Iter   144/  201] train: loss: 0.1151371
[Epoch 97; Iter   174/  201] train: loss: 0.1214922
[Epoch 97] ogbg-moltoxcast: 0.672620 val loss: 0.281253
[Epoch 97] ogbg-moltoxcast: 0.654389 test loss: 0.325596
[Epoch 98; Iter     3/  201] train: loss: 0.1236491
[Epoch 98; Iter    33/  201] train: loss: 0.1204589
[Epoch 98; Iter    63/  201] train: loss: 0.1679140
[Epoch 98; Iter    93/  201] train: loss: 0.1420574
[Epoch 98; Iter   123/  201] train: loss: 0.0826291
[Epoch 98; Iter   153/  201] train: loss: 0.0687445
[Epoch 98; Iter   183/  201] train: loss: 0.0995378
[Epoch 98] ogbg-moltoxcast: 0.673367 val loss: 0.281007
[Epoch 98] ogbg-moltoxcast: 0.655684 test loss: 0.322973
[Epoch 99; Iter    12/  201] train: loss: 0.1321477
[Epoch 99; Iter    42/  201] train: loss: 0.1106620
[Epoch 99; Iter    72/  201] train: loss: 0.1122986
[Epoch 99; Iter   102/  201] train: loss: 0.0936417
[Epoch 99; Iter   132/  201] train: loss: 0.1177069
[Epoch 99; Iter   162/  201] train: loss: 0.0909620
[Epoch 99; Iter   192/  201] train: loss: 0.0876698
[Epoch 99] ogbg-moltoxcast: 0.671200 val loss: 0.281260
[Epoch 99] ogbg-moltoxcast: 0.654156 test loss: 0.324405
[Epoch 100; Iter    21/  201] train: loss: 0.1151616
[Epoch 100; Iter    51/  201] train: loss: 0.1160332
[Epoch 100; Iter    81/  201] train: loss: 0.1055248
[Epoch 100; Iter   111/  201] train: loss: 0.1412058
[Epoch 100; Iter   141/  201] train: loss: 0.0880794
[Epoch 100; Iter   171/  201] train: loss: 0.1659973
[Epoch 100; Iter   201/  201] train: loss: 0.0670476
[Epoch 100] ogbg-moltoxcast: 0.668411 val loss: 0.285335
[Epoch 100] ogbg-moltoxcast: 0.653135 test loss: 0.327872
[Epoch 101; Iter    30/  201] train: loss: 0.1503808
[Epoch 101; Iter    60/  201] train: loss: 0.1057363
[Epoch 101; Iter    90/  201] train: loss: 0.1132073
[Epoch 101; Iter   120/  201] train: loss: 0.0869798
[Epoch 101; Iter   150/  201] train: loss: 0.1518561
[Epoch 101; Iter   180/  201] train: loss: 0.1163094
[Epoch 84; Iter    27/  201] train: loss: 0.0879303
[Epoch 84; Iter    57/  201] train: loss: 0.1495744
[Epoch 84; Iter    87/  201] train: loss: 0.1821825
[Epoch 84; Iter   117/  201] train: loss: 0.1465249
[Epoch 84; Iter   147/  201] train: loss: 0.1472531
[Epoch 84; Iter   177/  201] train: loss: 0.1299004
[Epoch 84] ogbg-moltoxcast: 0.680338 val loss: 0.270659
[Epoch 84] ogbg-moltoxcast: 0.653294 test loss: 0.325788
[Epoch 85; Iter     6/  201] train: loss: 0.1631229
[Epoch 85; Iter    36/  201] train: loss: 0.0903282
[Epoch 85; Iter    66/  201] train: loss: 0.1366116
[Epoch 85; Iter    96/  201] train: loss: 0.1194924
[Epoch 85; Iter   126/  201] train: loss: 0.1207470
[Epoch 85; Iter   156/  201] train: loss: 0.1492703
[Epoch 85; Iter   186/  201] train: loss: 0.1498624
[Epoch 85] ogbg-moltoxcast: 0.678533 val loss: 0.270442
[Epoch 85] ogbg-moltoxcast: 0.647777 test loss: 0.327864
[Epoch 86; Iter    15/  201] train: loss: 0.1081384
[Epoch 86; Iter    45/  201] train: loss: 0.1613044
[Epoch 86; Iter    75/  201] train: loss: 0.1036085
[Epoch 86; Iter   105/  201] train: loss: 0.1327298
[Epoch 86; Iter   135/  201] train: loss: 0.1611121
[Epoch 86; Iter   165/  201] train: loss: 0.1217607
[Epoch 86; Iter   195/  201] train: loss: 0.1145352
[Epoch 86] ogbg-moltoxcast: 0.680760 val loss: 0.272298
[Epoch 86] ogbg-moltoxcast: 0.652145 test loss: 0.326261
[Epoch 87; Iter    24/  201] train: loss: 0.1160771
[Epoch 87; Iter    54/  201] train: loss: 0.1391697
[Epoch 87; Iter    84/  201] train: loss: 0.1266813
[Epoch 87; Iter   114/  201] train: loss: 0.1217604
[Epoch 87; Iter   144/  201] train: loss: 0.1149084
[Epoch 87; Iter   174/  201] train: loss: 0.1121326
[Epoch 87] ogbg-moltoxcast: 0.682128 val loss: 0.267367
[Epoch 87] ogbg-moltoxcast: 0.654133 test loss: 0.321169
[Epoch 88; Iter     3/  201] train: loss: 0.0876506
[Epoch 88; Iter    33/  201] train: loss: 0.1331147
[Epoch 88; Iter    63/  201] train: loss: 0.1266409
[Epoch 88; Iter    93/  201] train: loss: 0.1218050
[Epoch 88; Iter   123/  201] train: loss: 0.1114150
[Epoch 88; Iter   153/  201] train: loss: 0.1091566
[Epoch 88; Iter   183/  201] train: loss: 0.1318358
[Epoch 88] ogbg-moltoxcast: 0.679699 val loss: 0.269494
[Epoch 88] ogbg-moltoxcast: 0.647983 test loss: 0.324949
[Epoch 89; Iter    12/  201] train: loss: 0.0930047
[Epoch 89; Iter    42/  201] train: loss: 0.1296086
[Epoch 89; Iter    72/  201] train: loss: 0.1097102
[Epoch 89; Iter   102/  201] train: loss: 0.0945091
[Epoch 89; Iter   132/  201] train: loss: 0.0771321
[Epoch 89; Iter   162/  201] train: loss: 0.1536047
[Epoch 89; Iter   192/  201] train: loss: 0.0951051
[Epoch 89] ogbg-moltoxcast: 0.680712 val loss: 0.268848
[Epoch 89] ogbg-moltoxcast: 0.650940 test loss: 0.323221
[Epoch 90; Iter    21/  201] train: loss: 0.1336438
[Epoch 90; Iter    51/  201] train: loss: 0.1198572
[Epoch 90; Iter    81/  201] train: loss: 0.1204836
[Epoch 90; Iter   111/  201] train: loss: 0.1396710
[Epoch 90; Iter   141/  201] train: loss: 0.1258507
[Epoch 90; Iter   171/  201] train: loss: 0.0929567
[Epoch 90; Iter   201/  201] train: loss: 0.0207584
[Epoch 90] ogbg-moltoxcast: 0.680633 val loss: 0.270224
[Epoch 90] ogbg-moltoxcast: 0.650385 test loss: 0.326704
[Epoch 91; Iter    30/  201] train: loss: 0.1443544
[Epoch 91; Iter    60/  201] train: loss: 0.1064518
[Epoch 91; Iter    90/  201] train: loss: 0.1120523
[Epoch 91; Iter   120/  201] train: loss: 0.1198750
[Epoch 91; Iter   150/  201] train: loss: 0.0828221
[Epoch 91; Iter   180/  201] train: loss: 0.1392386
[Epoch 91] ogbg-moltoxcast: 0.681135 val loss: 0.271729
[Epoch 91] ogbg-moltoxcast: 0.655415 test loss: 0.324962
[Epoch 92; Iter     9/  201] train: loss: 0.0767005
[Epoch 92; Iter    39/  201] train: loss: 0.1069525
[Epoch 92; Iter    69/  201] train: loss: 0.1197534
[Epoch 92; Iter    99/  201] train: loss: 0.1191693
[Epoch 92; Iter   129/  201] train: loss: 0.1338370
[Epoch 92; Iter   159/  201] train: loss: 0.1006780
[Epoch 92; Iter   189/  201] train: loss: 0.1755205
[Epoch 92] ogbg-moltoxcast: 0.679750 val loss: 0.270848
[Epoch 92] ogbg-moltoxcast: 0.650477 test loss: 0.326602
[Epoch 93; Iter    18/  201] train: loss: 0.0884752
[Epoch 93; Iter    48/  201] train: loss: 0.1215354
[Epoch 93; Iter    78/  201] train: loss: 0.1314864
[Epoch 93; Iter   108/  201] train: loss: 0.1033885
[Epoch 93; Iter   138/  201] train: loss: 0.1060774
[Epoch 93; Iter   168/  201] train: loss: 0.1223560
[Epoch 93; Iter   198/  201] train: loss: 0.0989155
[Epoch 93] ogbg-moltoxcast: 0.678267 val loss: 0.274161
[Epoch 93] ogbg-moltoxcast: 0.649558 test loss: 0.330114
[Epoch 94; Iter    27/  201] train: loss: 0.1283695
[Epoch 94; Iter    57/  201] train: loss: 0.1131919
[Epoch 94; Iter    87/  201] train: loss: 0.1518564
[Epoch 94; Iter   117/  201] train: loss: 0.1123025
[Epoch 94; Iter   147/  201] train: loss: 0.1266038
[Epoch 94; Iter   177/  201] train: loss: 0.1173417
[Epoch 94] ogbg-moltoxcast: 0.681512 val loss: 0.269506
[Epoch 94] ogbg-moltoxcast: 0.652350 test loss: 0.326338
[Epoch 95; Iter     6/  201] train: loss: 0.1238488
[Epoch 95; Iter    36/  201] train: loss: 0.1181511
[Epoch 95; Iter    66/  201] train: loss: 0.1136023
[Epoch 95; Iter    96/  201] train: loss: 0.1277931
[Epoch 95; Iter   126/  201] train: loss: 0.0961460
[Epoch 95; Iter   156/  201] train: loss: 0.1219973
[Epoch 95; Iter   186/  201] train: loss: 0.1606838
[Epoch 95] ogbg-moltoxcast: 0.682982 val loss: 0.270280
[Epoch 95] ogbg-moltoxcast: 0.651780 test loss: 0.327884
[Epoch 96; Iter    15/  201] train: loss: 0.1744644
[Epoch 96; Iter    45/  201] train: loss: 0.1026455
[Epoch 96; Iter    75/  201] train: loss: 0.1409526
[Epoch 96; Iter   105/  201] train: loss: 0.0961267
[Epoch 96; Iter   135/  201] train: loss: 0.1383058
[Epoch 96; Iter   165/  201] train: loss: 0.1268187
[Epoch 96; Iter   195/  201] train: loss: 0.1098198
[Epoch 96] ogbg-moltoxcast: 0.678948 val loss: 0.270154
[Epoch 96] ogbg-moltoxcast: 0.650180 test loss: 0.326195
[Epoch 97; Iter    24/  201] train: loss: 0.1282437
[Epoch 97; Iter    54/  201] train: loss: 0.1526248
[Epoch 97; Iter    84/  201] train: loss: 0.1816481
[Epoch 97; Iter   114/  201] train: loss: 0.1130707
[Epoch 97; Iter   144/  201] train: loss: 0.1156656
[Epoch 97; Iter   174/  201] train: loss: 0.0966176
[Epoch 97] ogbg-moltoxcast: 0.681389 val loss: 0.276064
[Epoch 97] ogbg-moltoxcast: 0.654297 test loss: 0.333588
[Epoch 98; Iter     3/  201] train: loss: 0.0957900
[Epoch 98; Iter    33/  201] train: loss: 0.1275073
[Epoch 98; Iter    63/  201] train: loss: 0.0935599
[Epoch 98; Iter    93/  201] train: loss: 0.1277295
[Epoch 98; Iter   123/  201] train: loss: 0.1207211
[Epoch 98; Iter   153/  201] train: loss: 0.0942162
[Epoch 98; Iter   183/  201] train: loss: 0.1245969
[Epoch 98] ogbg-moltoxcast: 0.676077 val loss: 0.272715
[Epoch 98] ogbg-moltoxcast: 0.649310 test loss: 0.327181
[Epoch 99; Iter    12/  201] train: loss: 0.1731739
[Epoch 99; Iter    42/  201] train: loss: 0.1546947
[Epoch 99; Iter    72/  201] train: loss: 0.1593924
[Epoch 99; Iter   102/  201] train: loss: 0.1314325
[Epoch 99; Iter   132/  201] train: loss: 0.1412220
[Epoch 99; Iter   162/  201] train: loss: 0.0938850
[Epoch 99; Iter   192/  201] train: loss: 0.1270995
[Epoch 99] ogbg-moltoxcast: 0.678213 val loss: 0.270610
[Epoch 99] ogbg-moltoxcast: 0.650503 test loss: 0.327835
[Epoch 100; Iter    21/  201] train: loss: 0.1099272
[Epoch 100; Iter    51/  201] train: loss: 0.1285701
[Epoch 100; Iter    81/  201] train: loss: 0.0927071
[Epoch 100; Iter   111/  201] train: loss: 0.1477144
[Epoch 100; Iter   141/  201] train: loss: 0.1366716
[Epoch 100; Iter   171/  201] train: loss: 0.1153608
[Epoch 100; Iter   201/  201] train: loss: 0.1972771
[Epoch 100] ogbg-moltoxcast: 0.678046 val loss: 0.277459
[Epoch 100] ogbg-moltoxcast: 0.648974 test loss: 0.334223
[Epoch 101; Iter    30/  201] train: loss: 0.0792471
[Epoch 101; Iter    60/  201] train: loss: 0.1297356
[Epoch 101; Iter    90/  201] train: loss: 0.1056647
[Epoch 101; Iter   120/  201] train: loss: 0.1023442
[Epoch 101; Iter   150/  201] train: loss: 0.0843026
[Epoch 101; Iter   180/  201] train: loss: 0.1041057
[Epoch 94; Iter   114/  172] train: loss: 0.1874290
[Epoch 94; Iter   144/  172] train: loss: 0.1179895
[Epoch 94] ogbg-moltoxcast: 0.644097 val loss: 0.296836
[Epoch 94] ogbg-moltoxcast: 0.619886 test loss: 0.356083
[Epoch 95; Iter     2/  172] train: loss: 0.0854752
[Epoch 95; Iter    32/  172] train: loss: 0.1163274
[Epoch 95; Iter    62/  172] train: loss: 0.1271593
[Epoch 95; Iter    92/  172] train: loss: 0.1244695
[Epoch 95; Iter   122/  172] train: loss: 0.1028250
[Epoch 95; Iter   152/  172] train: loss: 0.1502218
[Epoch 95] ogbg-moltoxcast: 0.639211 val loss: 0.303213
[Epoch 95] ogbg-moltoxcast: 0.616828 test loss: 0.360794
[Epoch 96; Iter    10/  172] train: loss: 0.0934718
[Epoch 96; Iter    40/  172] train: loss: 0.1144061
[Epoch 96; Iter    70/  172] train: loss: 0.1280904
[Epoch 96; Iter   100/  172] train: loss: 0.1115414
[Epoch 96; Iter   130/  172] train: loss: 0.0894224
[Epoch 96; Iter   160/  172] train: loss: 0.0768520
[Epoch 96] ogbg-moltoxcast: 0.639552 val loss: 0.299782
[Epoch 96] ogbg-moltoxcast: 0.617490 test loss: 0.357799
[Epoch 97; Iter    18/  172] train: loss: 0.1251612
[Epoch 97; Iter    48/  172] train: loss: 0.1548163
[Epoch 97; Iter    78/  172] train: loss: 0.0846152
[Epoch 97; Iter   108/  172] train: loss: 0.1364525
[Epoch 97; Iter   138/  172] train: loss: 0.1049773
[Epoch 97; Iter   168/  172] train: loss: 0.0944088
[Epoch 97] ogbg-moltoxcast: 0.640353 val loss: 0.301865
[Epoch 97] ogbg-moltoxcast: 0.617506 test loss: 0.359341
[Epoch 98; Iter    26/  172] train: loss: 0.0862907
[Epoch 98; Iter    56/  172] train: loss: 0.1306396
[Epoch 98; Iter    86/  172] train: loss: 0.1059833
[Epoch 98; Iter   116/  172] train: loss: 0.1061959
[Epoch 98; Iter   146/  172] train: loss: 0.0696319
[Epoch 98] ogbg-moltoxcast: 0.639250 val loss: 0.304515
[Epoch 98] ogbg-moltoxcast: 0.618054 test loss: 0.363333
[Epoch 99; Iter     4/  172] train: loss: 0.1098752
[Epoch 99; Iter    34/  172] train: loss: 0.1001593
[Epoch 99; Iter    64/  172] train: loss: 0.1298980
[Epoch 99; Iter    94/  172] train: loss: 0.0766236
[Epoch 99; Iter   124/  172] train: loss: 0.1472441
[Epoch 99; Iter   154/  172] train: loss: 0.1090328
[Epoch 99] ogbg-moltoxcast: 0.644378 val loss: 0.301979
[Epoch 99] ogbg-moltoxcast: 0.623161 test loss: 0.360967
[Epoch 100; Iter    12/  172] train: loss: 0.1315686
[Epoch 100; Iter    42/  172] train: loss: 0.0840132
[Epoch 100; Iter    72/  172] train: loss: 0.0948729
[Epoch 100; Iter   102/  172] train: loss: 0.1135665
[Epoch 100; Iter   132/  172] train: loss: 0.1140654
[Epoch 100; Iter   162/  172] train: loss: 0.0984644
[Epoch 100] ogbg-moltoxcast: 0.640841 val loss: 0.302103
[Epoch 100] ogbg-moltoxcast: 0.621213 test loss: 0.357839
[Epoch 101; Iter    20/  172] train: loss: 0.0783190
[Epoch 101; Iter    50/  172] train: loss: 0.1453185
[Epoch 101; Iter    80/  172] train: loss: 0.0758367
[Epoch 101; Iter   110/  172] train: loss: 0.0930289
[Epoch 101; Iter   140/  172] train: loss: 0.1103424
[Epoch 101; Iter   170/  172] train: loss: 0.0979674
[Epoch 101] ogbg-moltoxcast: 0.640289 val loss: 0.302624
[Epoch 101] ogbg-moltoxcast: 0.619543 test loss: 0.360845
[Epoch 102; Iter    28/  172] train: loss: 0.1297837
[Epoch 102; Iter    58/  172] train: loss: 0.1195478
[Epoch 102; Iter    88/  172] train: loss: 0.1409278
[Epoch 102; Iter   118/  172] train: loss: 0.0667354
[Epoch 102; Iter   148/  172] train: loss: 0.1433276
[Epoch 102] ogbg-moltoxcast: 0.637924 val loss: 0.308258
[Epoch 102] ogbg-moltoxcast: 0.619323 test loss: 0.367230
[Epoch 103; Iter     6/  172] train: loss: 0.0807439
[Epoch 103; Iter    36/  172] train: loss: 0.1338148
[Epoch 103; Iter    66/  172] train: loss: 0.1036991
[Epoch 103; Iter    96/  172] train: loss: 0.0779742
[Epoch 103; Iter   126/  172] train: loss: 0.1058032
[Epoch 103; Iter   156/  172] train: loss: 0.0798116
[Epoch 103] ogbg-moltoxcast: 0.639858 val loss: 0.302625
[Epoch 103] ogbg-moltoxcast: 0.618238 test loss: 0.357336
[Epoch 104; Iter    14/  172] train: loss: 0.1130877
[Epoch 104; Iter    44/  172] train: loss: 0.0691908
[Epoch 104; Iter    74/  172] train: loss: 0.0901445
[Epoch 104; Iter   104/  172] train: loss: 0.1063842
[Epoch 104; Iter   134/  172] train: loss: 0.0783699
[Epoch 104; Iter   164/  172] train: loss: 0.0738306
[Epoch 104] ogbg-moltoxcast: 0.636138 val loss: 0.303364
[Epoch 104] ogbg-moltoxcast: 0.616934 test loss: 0.360126
[Epoch 105; Iter    22/  172] train: loss: 0.1140128
[Epoch 105; Iter    52/  172] train: loss: 0.0895197
[Epoch 105; Iter    82/  172] train: loss: 0.0923768
[Epoch 105; Iter   112/  172] train: loss: 0.1032638
[Epoch 105; Iter   142/  172] train: loss: 0.0975088
[Epoch 105; Iter   172/  172] train: loss: 0.1341226
[Epoch 105] ogbg-moltoxcast: 0.638256 val loss: 0.311564
[Epoch 105] ogbg-moltoxcast: 0.616786 test loss: 0.372737
[Epoch 106; Iter    30/  172] train: loss: 0.1118723
[Epoch 106; Iter    60/  172] train: loss: 0.1179639
[Epoch 106; Iter    90/  172] train: loss: 0.1301050
[Epoch 106; Iter   120/  172] train: loss: 0.1451052
[Epoch 106; Iter   150/  172] train: loss: 0.1394921
[Epoch 106] ogbg-moltoxcast: 0.639274 val loss: 0.308721
[Epoch 106] ogbg-moltoxcast: 0.617403 test loss: 0.369827
[Epoch 107; Iter     8/  172] train: loss: 0.1200458
[Epoch 107; Iter    38/  172] train: loss: 0.0859770
[Epoch 107; Iter    68/  172] train: loss: 0.1204689
[Epoch 107; Iter    98/  172] train: loss: 0.1183430
[Epoch 107; Iter   128/  172] train: loss: 0.1387755
[Epoch 107; Iter   158/  172] train: loss: 0.0650919
[Epoch 107] ogbg-moltoxcast: 0.637536 val loss: 0.308179
[Epoch 107] ogbg-moltoxcast: 0.615462 test loss: 0.366810
[Epoch 108; Iter    16/  172] train: loss: 0.1294191
[Epoch 108; Iter    46/  172] train: loss: 0.1040032
[Epoch 108; Iter    76/  172] train: loss: 0.0990788
[Epoch 108; Iter   106/  172] train: loss: 0.0941761
[Epoch 108; Iter   136/  172] train: loss: 0.1146691
[Epoch 108; Iter   166/  172] train: loss: 0.1166530
[Epoch 108] ogbg-moltoxcast: 0.637909 val loss: 0.315677
[Epoch 108] ogbg-moltoxcast: 0.615681 test loss: 0.377404
[Epoch 109; Iter    24/  172] train: loss: 0.0876974
[Epoch 109; Iter    54/  172] train: loss: 0.1084047
[Epoch 109; Iter    84/  172] train: loss: 0.1201215
[Epoch 109; Iter   114/  172] train: loss: 0.0775259
[Epoch 109; Iter   144/  172] train: loss: 0.1185339
[Epoch 109] ogbg-moltoxcast: 0.637315 val loss: 0.311117
[Epoch 109] ogbg-moltoxcast: 0.616011 test loss: 0.372729
[Epoch 110; Iter     2/  172] train: loss: 0.1048561
[Epoch 110; Iter    32/  172] train: loss: 0.0971045
[Epoch 110; Iter    62/  172] train: loss: 0.1135005
[Epoch 110; Iter    92/  172] train: loss: 0.0874941
[Epoch 110; Iter   122/  172] train: loss: 0.1017302
[Epoch 110; Iter   152/  172] train: loss: 0.0917093
[Epoch 110] ogbg-moltoxcast: 0.633592 val loss: 0.312056
[Epoch 110] ogbg-moltoxcast: 0.613718 test loss: 0.373770
[Epoch 111; Iter    10/  172] train: loss: 0.0865645
[Epoch 111; Iter    40/  172] train: loss: 0.1306921
[Epoch 111; Iter    70/  172] train: loss: 0.1115534
[Epoch 111; Iter   100/  172] train: loss: 0.1296020
[Epoch 111; Iter   130/  172] train: loss: 0.0997341
[Epoch 111; Iter   160/  172] train: loss: 0.1099338
[Epoch 111] ogbg-moltoxcast: 0.630188 val loss: 0.311082
[Epoch 111] ogbg-moltoxcast: 0.612404 test loss: 0.369594
[Epoch 112; Iter    18/  172] train: loss: 0.1140696
[Epoch 112; Iter    48/  172] train: loss: 0.1520719
[Epoch 112; Iter    78/  172] train: loss: 0.1134799
[Epoch 112; Iter   108/  172] train: loss: 0.1099745
[Epoch 112; Iter   138/  172] train: loss: 0.0844754
[Epoch 112; Iter   168/  172] train: loss: 0.1115918
[Epoch 112] ogbg-moltoxcast: 0.636789 val loss: 0.313752
[Epoch 112] ogbg-moltoxcast: 0.616388 test loss: 0.376329
[Epoch 113; Iter    26/  172] train: loss: 0.0954042
[Epoch 113; Iter    56/  172] train: loss: 0.0748640
[Epoch 113; Iter    86/  172] train: loss: 0.1170381
[Epoch 113; Iter   116/  172] train: loss: 0.1050391
[Epoch 113; Iter   146/  172] train: loss: 0.1606919
[Epoch 113] ogbg-moltoxcast: 0.638063 val loss: 0.311847
[Epoch 113] ogbg-moltoxcast: 0.613630 test loss: 0.375845
[Epoch 114; Iter     4/  172] train: loss: 0.1906860[Epoch 94; Iter   114/  172] train: loss: 0.1103879
[Epoch 94; Iter   144/  172] train: loss: 0.0860513
[Epoch 94] ogbg-moltoxcast: 0.634748 val loss: 0.302534
[Epoch 94] ogbg-moltoxcast: 0.617919 test loss: 0.349459
[Epoch 95; Iter     2/  172] train: loss: 0.0927165
[Epoch 95; Iter    32/  172] train: loss: 0.0767066
[Epoch 95; Iter    62/  172] train: loss: 0.1014347
[Epoch 95; Iter    92/  172] train: loss: 0.1667422
[Epoch 95; Iter   122/  172] train: loss: 0.1029981
[Epoch 95; Iter   152/  172] train: loss: 0.0945909
[Epoch 95] ogbg-moltoxcast: 0.632858 val loss: 0.302543
[Epoch 95] ogbg-moltoxcast: 0.619089 test loss: 0.348350
[Epoch 96; Iter    10/  172] train: loss: 0.1237684
[Epoch 96; Iter    40/  172] train: loss: 0.1173775
[Epoch 96; Iter    70/  172] train: loss: 0.1211109
[Epoch 96; Iter   100/  172] train: loss: 0.0862941
[Epoch 96; Iter   130/  172] train: loss: 0.1087303
[Epoch 96; Iter   160/  172] train: loss: 0.1310990
[Epoch 96] ogbg-moltoxcast: 0.636592 val loss: 0.302505
[Epoch 96] ogbg-moltoxcast: 0.622659 test loss: 0.348629
[Epoch 97; Iter    18/  172] train: loss: 0.1493681
[Epoch 97; Iter    48/  172] train: loss: 0.1161723
[Epoch 97; Iter    78/  172] train: loss: 0.1099021
[Epoch 97; Iter   108/  172] train: loss: 0.1320268
[Epoch 97; Iter   138/  172] train: loss: 0.1111014
[Epoch 97; Iter   168/  172] train: loss: 0.0996712
[Epoch 97] ogbg-moltoxcast: 0.634266 val loss: 0.306287
[Epoch 97] ogbg-moltoxcast: 0.621722 test loss: 0.356120
[Epoch 98; Iter    26/  172] train: loss: 0.0890614
[Epoch 98; Iter    56/  172] train: loss: 0.1125418
[Epoch 98; Iter    86/  172] train: loss: 0.1426911
[Epoch 98; Iter   116/  172] train: loss: 0.1208047
[Epoch 98; Iter   146/  172] train: loss: 0.1331219
[Epoch 98] ogbg-moltoxcast: 0.639041 val loss: 0.299476
[Epoch 98] ogbg-moltoxcast: 0.624124 test loss: 0.346028
[Epoch 99; Iter     4/  172] train: loss: 0.0972846
[Epoch 99; Iter    34/  172] train: loss: 0.1222816
[Epoch 99; Iter    64/  172] train: loss: 0.0916921
[Epoch 99; Iter    94/  172] train: loss: 0.1271885
[Epoch 99; Iter   124/  172] train: loss: 0.1284518
[Epoch 99; Iter   154/  172] train: loss: 0.1056899
[Epoch 99] ogbg-moltoxcast: 0.639452 val loss: 0.306380
[Epoch 99] ogbg-moltoxcast: 0.623631 test loss: 0.353295
[Epoch 100; Iter    12/  172] train: loss: 0.1212731
[Epoch 100; Iter    42/  172] train: loss: 0.1173616
[Epoch 100; Iter    72/  172] train: loss: 0.1227981
[Epoch 100; Iter   102/  172] train: loss: 0.1569785
[Epoch 100; Iter   132/  172] train: loss: 0.1058821
[Epoch 100; Iter   162/  172] train: loss: 0.0803086
[Epoch 100] ogbg-moltoxcast: 0.639681 val loss: 0.303898
[Epoch 100] ogbg-moltoxcast: 0.624166 test loss: 0.349341
[Epoch 101; Iter    20/  172] train: loss: 0.1660448
[Epoch 101; Iter    50/  172] train: loss: 0.1535739
[Epoch 101; Iter    80/  172] train: loss: 0.1014553
[Epoch 101; Iter   110/  172] train: loss: 0.1416509
[Epoch 101; Iter   140/  172] train: loss: 0.1054380
[Epoch 101; Iter   170/  172] train: loss: 0.0847646
[Epoch 101] ogbg-moltoxcast: 0.637108 val loss: 0.304072
[Epoch 101] ogbg-moltoxcast: 0.622906 test loss: 0.349995
[Epoch 102; Iter    28/  172] train: loss: 0.1202368
[Epoch 102; Iter    58/  172] train: loss: 0.0911960
[Epoch 102; Iter    88/  172] train: loss: 0.1205782
[Epoch 102; Iter   118/  172] train: loss: 0.1004828
[Epoch 102; Iter   148/  172] train: loss: 0.1158812
[Epoch 102] ogbg-moltoxcast: 0.635312 val loss: 0.311575
[Epoch 102] ogbg-moltoxcast: 0.620031 test loss: 0.360531
[Epoch 103; Iter     6/  172] train: loss: 0.1123745
[Epoch 103; Iter    36/  172] train: loss: 0.1302897
[Epoch 103; Iter    66/  172] train: loss: 0.1426800
[Epoch 103; Iter    96/  172] train: loss: 0.1033146
[Epoch 103; Iter   126/  172] train: loss: 0.1168956
[Epoch 103; Iter   156/  172] train: loss: 0.1435977
[Epoch 103] ogbg-moltoxcast: 0.638900 val loss: 0.301162
[Epoch 103] ogbg-moltoxcast: 0.621080 test loss: 0.348435
[Epoch 104; Iter    14/  172] train: loss: 0.1679301
[Epoch 104; Iter    44/  172] train: loss: 0.0837503
[Epoch 104; Iter    74/  172] train: loss: 0.1506632
[Epoch 104; Iter   104/  172] train: loss: 0.1168853
[Epoch 104; Iter   134/  172] train: loss: 0.1379137
[Epoch 104; Iter   164/  172] train: loss: 0.1295035
[Epoch 104] ogbg-moltoxcast: 0.637505 val loss: 0.308436
[Epoch 104] ogbg-moltoxcast: 0.618814 test loss: 0.357199
[Epoch 105; Iter    22/  172] train: loss: 0.0750799
[Epoch 105; Iter    52/  172] train: loss: 0.0880068
[Epoch 105; Iter    82/  172] train: loss: 0.1138526
[Epoch 105; Iter   112/  172] train: loss: 0.1146663
[Epoch 105; Iter   142/  172] train: loss: 0.1382229
[Epoch 105; Iter   172/  172] train: loss: 0.1917279
[Epoch 105] ogbg-moltoxcast: 0.638576 val loss: 0.309424
[Epoch 105] ogbg-moltoxcast: 0.621429 test loss: 0.358925
[Epoch 106; Iter    30/  172] train: loss: 0.1347382
[Epoch 106; Iter    60/  172] train: loss: 0.1214782
[Epoch 106; Iter    90/  172] train: loss: 0.1141487
[Epoch 106; Iter   120/  172] train: loss: 0.1044970
[Epoch 106; Iter   150/  172] train: loss: 0.0867151
[Epoch 106] ogbg-moltoxcast: 0.636745 val loss: 0.307831
[Epoch 106] ogbg-moltoxcast: 0.622022 test loss: 0.353921
[Epoch 107; Iter     8/  172] train: loss: 0.1048537
[Epoch 107; Iter    38/  172] train: loss: 0.0881333
[Epoch 107; Iter    68/  172] train: loss: 0.0831681
[Epoch 107; Iter    98/  172] train: loss: 0.1532035
[Epoch 107; Iter   128/  172] train: loss: 0.0931367
[Epoch 107; Iter   158/  172] train: loss: 0.1268363
[Epoch 107] ogbg-moltoxcast: 0.628473 val loss: 0.310370
[Epoch 107] ogbg-moltoxcast: 0.617177 test loss: 0.356926
[Epoch 108; Iter    16/  172] train: loss: 0.1456280
[Epoch 108; Iter    46/  172] train: loss: 0.1212768
[Epoch 108; Iter    76/  172] train: loss: 0.1118417
[Epoch 108; Iter   106/  172] train: loss: 0.1036276
[Epoch 108; Iter   136/  172] train: loss: 0.1249244
[Epoch 108; Iter   166/  172] train: loss: 0.1414382
[Epoch 108] ogbg-moltoxcast: 0.633615 val loss: 0.305912
[Epoch 108] ogbg-moltoxcast: 0.621102 test loss: 0.353264
[Epoch 109; Iter    24/  172] train: loss: 0.0991853
[Epoch 109; Iter    54/  172] train: loss: 0.1106907
[Epoch 109; Iter    84/  172] train: loss: 0.0786783
[Epoch 109; Iter   114/  172] train: loss: 0.1240814
[Epoch 109; Iter   144/  172] train: loss: 0.1151428
[Epoch 109] ogbg-moltoxcast: 0.634390 val loss: 0.310716
[Epoch 109] ogbg-moltoxcast: 0.619680 test loss: 0.359710
[Epoch 110; Iter     2/  172] train: loss: 0.1173771
[Epoch 110; Iter    32/  172] train: loss: 0.1170868
[Epoch 110; Iter    62/  172] train: loss: 0.1548252
[Epoch 110; Iter    92/  172] train: loss: 0.1074664
[Epoch 110; Iter   122/  172] train: loss: 0.1283237
[Epoch 110; Iter   152/  172] train: loss: 0.1381535
[Epoch 110] ogbg-moltoxcast: 0.631770 val loss: 0.308037
[Epoch 110] ogbg-moltoxcast: 0.619783 test loss: 0.353772
[Epoch 111; Iter    10/  172] train: loss: 0.1277890
[Epoch 111; Iter    40/  172] train: loss: 0.0705030
[Epoch 111; Iter    70/  172] train: loss: 0.1085012
[Epoch 111; Iter   100/  172] train: loss: 0.1322821
[Epoch 111; Iter   130/  172] train: loss: 0.0990168
[Epoch 111; Iter   160/  172] train: loss: 0.1564198
[Epoch 111] ogbg-moltoxcast: 0.634145 val loss: 0.308260
[Epoch 111] ogbg-moltoxcast: 0.621758 test loss: 0.350801
[Epoch 112; Iter    18/  172] train: loss: 0.1136767
[Epoch 112; Iter    48/  172] train: loss: 0.0889179
[Epoch 112; Iter    78/  172] train: loss: 0.1372426
[Epoch 112; Iter   108/  172] train: loss: 0.1216222
[Epoch 112; Iter   138/  172] train: loss: 0.0940416
[Epoch 112; Iter   168/  172] train: loss: 0.0776977
[Epoch 112] ogbg-moltoxcast: 0.634950 val loss: 0.310791
[Epoch 112] ogbg-moltoxcast: 0.622360 test loss: 0.357419
[Epoch 113; Iter    26/  172] train: loss: 0.1088732
[Epoch 113; Iter    56/  172] train: loss: 0.1021763
[Epoch 113; Iter    86/  172] train: loss: 0.0912555
[Epoch 113; Iter   116/  172] train: loss: 0.0931009
[Epoch 113; Iter   146/  172] train: loss: 0.1231157
[Epoch 113] ogbg-moltoxcast: 0.634520 val loss: 0.312526
[Epoch 113] ogbg-moltoxcast: 0.619312 test loss: 0.361167
[Epoch 114; Iter     4/  172] train: loss: 0.0810371[Epoch 92; Iter    11/  229] train: loss: 0.1342323
[Epoch 92; Iter    41/  229] train: loss: 0.1544301
[Epoch 92; Iter    71/  229] train: loss: 0.1006384
[Epoch 92; Iter   101/  229] train: loss: 0.1424629
[Epoch 92; Iter   131/  229] train: loss: 0.1081625
[Epoch 92; Iter   161/  229] train: loss: 0.1211308
[Epoch 92; Iter   191/  229] train: loss: 0.1100558
[Epoch 92; Iter   221/  229] train: loss: 0.1231325
[Epoch 92] ogbg-moltoxcast: 0.682333 val loss: 0.269794
[Epoch 92] ogbg-moltoxcast: 0.648796 test loss: 0.328273
[Epoch 93; Iter    22/  229] train: loss: 0.1284376
[Epoch 93; Iter    52/  229] train: loss: 0.1251028
[Epoch 93; Iter    82/  229] train: loss: 0.0758908
[Epoch 93; Iter   112/  229] train: loss: 0.1298141
[Epoch 93; Iter   142/  229] train: loss: 0.1437867
[Epoch 93; Iter   172/  229] train: loss: 0.1080212
[Epoch 93; Iter   202/  229] train: loss: 0.1152182
[Epoch 93] ogbg-moltoxcast: 0.688108 val loss: 0.265453
[Epoch 93] ogbg-moltoxcast: 0.650908 test loss: 0.326703
[Epoch 94; Iter     3/  229] train: loss: 0.1114050
[Epoch 94; Iter    33/  229] train: loss: 0.1273791
[Epoch 94; Iter    63/  229] train: loss: 0.0998584
[Epoch 94; Iter    93/  229] train: loss: 0.1623401
[Epoch 94; Iter   123/  229] train: loss: 0.1465322
[Epoch 94; Iter   153/  229] train: loss: 0.0844721
[Epoch 94; Iter   183/  229] train: loss: 0.1047101
[Epoch 94; Iter   213/  229] train: loss: 0.1149253
[Epoch 94] ogbg-moltoxcast: 0.681569 val loss: 0.267965
[Epoch 94] ogbg-moltoxcast: 0.647356 test loss: 0.327917
[Epoch 95; Iter    14/  229] train: loss: 0.1428372
[Epoch 95; Iter    44/  229] train: loss: 0.1243994
[Epoch 95; Iter    74/  229] train: loss: 0.1122666
[Epoch 95; Iter   104/  229] train: loss: 0.1038212
[Epoch 95; Iter   134/  229] train: loss: 0.0832589
[Epoch 95; Iter   164/  229] train: loss: 0.1581489
[Epoch 95; Iter   194/  229] train: loss: 0.1231931
[Epoch 95; Iter   224/  229] train: loss: 0.1190279
[Epoch 95] ogbg-moltoxcast: 0.682888 val loss: 0.266317
[Epoch 95] ogbg-moltoxcast: 0.650824 test loss: 0.326634
[Epoch 96; Iter    25/  229] train: loss: 0.1377470
[Epoch 96; Iter    55/  229] train: loss: 0.1180261
[Epoch 96; Iter    85/  229] train: loss: 0.1251802
[Epoch 96; Iter   115/  229] train: loss: 0.0969354
[Epoch 96; Iter   145/  229] train: loss: 0.1330419
[Epoch 96; Iter   175/  229] train: loss: 0.1140089
[Epoch 96; Iter   205/  229] train: loss: 0.1211245
[Epoch 96] ogbg-moltoxcast: 0.684028 val loss: 0.266953
[Epoch 96] ogbg-moltoxcast: 0.650053 test loss: 0.325988
[Epoch 97; Iter     6/  229] train: loss: 0.0746249
[Epoch 97; Iter    36/  229] train: loss: 0.1396063
[Epoch 97; Iter    66/  229] train: loss: 0.0988764
[Epoch 97; Iter    96/  229] train: loss: 0.1902051
[Epoch 97; Iter   126/  229] train: loss: 0.0965322
[Epoch 97; Iter   156/  229] train: loss: 0.1002775
[Epoch 97; Iter   186/  229] train: loss: 0.1225339
[Epoch 97; Iter   216/  229] train: loss: 0.0942437
[Epoch 97] ogbg-moltoxcast: 0.685063 val loss: 0.266238
[Epoch 97] ogbg-moltoxcast: 0.649969 test loss: 0.326400
[Epoch 98; Iter    17/  229] train: loss: 0.1722644
[Epoch 98; Iter    47/  229] train: loss: 0.1357222
[Epoch 98; Iter    77/  229] train: loss: 0.1450009
[Epoch 98; Iter   107/  229] train: loss: 0.1312566
[Epoch 98; Iter   137/  229] train: loss: 0.1025959
[Epoch 98; Iter   167/  229] train: loss: 0.0714899
[Epoch 98; Iter   197/  229] train: loss: 0.1130021
[Epoch 98; Iter   227/  229] train: loss: 0.1587896
[Epoch 98] ogbg-moltoxcast: 0.681728 val loss: 0.267727
[Epoch 98] ogbg-moltoxcast: 0.650246 test loss: 0.330445
[Epoch 99; Iter    28/  229] train: loss: 0.1478349
[Epoch 99; Iter    58/  229] train: loss: 0.0866061
[Epoch 99; Iter    88/  229] train: loss: 0.1232876
[Epoch 99; Iter   118/  229] train: loss: 0.1551297
[Epoch 99; Iter   148/  229] train: loss: 0.1551490
[Epoch 99; Iter   178/  229] train: loss: 0.1293203
[Epoch 99; Iter   208/  229] train: loss: 0.1414226
[Epoch 99] ogbg-moltoxcast: 0.685054 val loss: 0.267469
[Epoch 99] ogbg-moltoxcast: 0.651622 test loss: 0.327292
[Epoch 100; Iter     9/  229] train: loss: 0.0964044
[Epoch 100; Iter    39/  229] train: loss: 0.1447554
[Epoch 100; Iter    69/  229] train: loss: 0.1267432
[Epoch 100; Iter    99/  229] train: loss: 0.1162274
[Epoch 100; Iter   129/  229] train: loss: 0.1500066
[Epoch 100; Iter   159/  229] train: loss: 0.1329056
[Epoch 100; Iter   189/  229] train: loss: 0.1319558
[Epoch 100; Iter   219/  229] train: loss: 0.2224204
[Epoch 100] ogbg-moltoxcast: 0.681391 val loss: 0.272380
[Epoch 100] ogbg-moltoxcast: 0.652062 test loss: 0.331102
[Epoch 101; Iter    20/  229] train: loss: 0.1174413
[Epoch 101; Iter    50/  229] train: loss: 0.1322807
[Epoch 101; Iter    80/  229] train: loss: 0.1082356
[Epoch 101; Iter   110/  229] train: loss: 0.1374609
[Epoch 101; Iter   140/  229] train: loss: 0.1280813
[Epoch 101; Iter   170/  229] train: loss: 0.0963965
[Epoch 101; Iter   200/  229] train: loss: 0.1160036
[Epoch 101] ogbg-moltoxcast: 0.680087 val loss: 0.267967
[Epoch 101] ogbg-moltoxcast: 0.648257 test loss: 0.330849
[Epoch 102; Iter     1/  229] train: loss: 0.1294057
[Epoch 102; Iter    31/  229] train: loss: 0.1023010
[Epoch 102; Iter    61/  229] train: loss: 0.1453090
[Epoch 102; Iter    91/  229] train: loss: 0.1153494
[Epoch 102; Iter   121/  229] train: loss: 0.1076043
[Epoch 102; Iter   151/  229] train: loss: 0.1149648
[Epoch 102; Iter   181/  229] train: loss: 0.0936442
[Epoch 102; Iter   211/  229] train: loss: 0.1441154
[Epoch 102] ogbg-moltoxcast: 0.681074 val loss: 0.269328
[Epoch 102] ogbg-moltoxcast: 0.649486 test loss: 0.331056
[Epoch 103; Iter    12/  229] train: loss: 0.1110987
[Epoch 103; Iter    42/  229] train: loss: 0.1211185
[Epoch 103; Iter    72/  229] train: loss: 0.1166866
[Epoch 103; Iter   102/  229] train: loss: 0.1335644
[Epoch 103; Iter   132/  229] train: loss: 0.1073883
[Epoch 103; Iter   162/  229] train: loss: 0.1570200
[Epoch 103; Iter   192/  229] train: loss: 0.1120998
[Epoch 103; Iter   222/  229] train: loss: 0.1244377
[Epoch 103] ogbg-moltoxcast: 0.678793 val loss: 0.270911
[Epoch 103] ogbg-moltoxcast: 0.646441 test loss: 0.335055
[Epoch 104; Iter    23/  229] train: loss: 0.1110230
[Epoch 104; Iter    53/  229] train: loss: 0.1029358
[Epoch 104; Iter    83/  229] train: loss: 0.1251419
[Epoch 104; Iter   113/  229] train: loss: 0.1026774
[Epoch 104; Iter   143/  229] train: loss: 0.0902900
[Epoch 104; Iter   173/  229] train: loss: 0.1050157
[Epoch 104; Iter   203/  229] train: loss: 0.1347065
[Epoch 104] ogbg-moltoxcast: 0.684867 val loss: 0.269466
[Epoch 104] ogbg-moltoxcast: 0.648196 test loss: 0.332713
[Epoch 105; Iter     4/  229] train: loss: 0.1055964
[Epoch 105; Iter    34/  229] train: loss: 0.1024313
[Epoch 105; Iter    64/  229] train: loss: 0.1227168
[Epoch 105; Iter    94/  229] train: loss: 0.1230948
[Epoch 105; Iter   124/  229] train: loss: 0.0780398
[Epoch 105; Iter   154/  229] train: loss: 0.1079940
[Epoch 105; Iter   184/  229] train: loss: 0.1283722
[Epoch 105; Iter   214/  229] train: loss: 0.1475283
[Epoch 105] ogbg-moltoxcast: 0.680358 val loss: 0.282980
[Epoch 105] ogbg-moltoxcast: 0.648204 test loss: 0.340659
[Epoch 106; Iter    15/  229] train: loss: 0.0865475
[Epoch 106; Iter    45/  229] train: loss: 0.0904587
[Epoch 106; Iter    75/  229] train: loss: 0.1064900
[Epoch 106; Iter   105/  229] train: loss: 0.1018786
[Epoch 106; Iter   135/  229] train: loss: 0.1116620
[Epoch 106; Iter   165/  229] train: loss: 0.1067776
[Epoch 106; Iter   195/  229] train: loss: 0.1722133
[Epoch 106; Iter   225/  229] train: loss: 0.1398122
[Epoch 106] ogbg-moltoxcast: 0.679997 val loss: 0.272275
[Epoch 106] ogbg-moltoxcast: 0.646053 test loss: 0.336396
[Epoch 107; Iter    26/  229] train: loss: 0.0980274
[Epoch 107; Iter    56/  229] train: loss: 0.1252140
[Epoch 107; Iter    86/  229] train: loss: 0.1265721
[Epoch 107; Iter   116/  229] train: loss: 0.1350680
[Epoch 107; Iter   146/  229] train: loss: 0.1163329
[Epoch 107; Iter   176/  229] train: loss: 0.1632052
[Epoch 107; Iter   206/  229] train: loss: 0.1301666
[Epoch 107] ogbg-moltoxcast: 0.680821 val loss: 0.268575
[Epoch 94; Iter   114/  172] train: loss: 0.0912379
[Epoch 94; Iter   144/  172] train: loss: 0.1333349
[Epoch 94] ogbg-moltoxcast: 0.637342 val loss: 0.305491
[Epoch 94] ogbg-moltoxcast: 0.613004 test loss: 0.356785
[Epoch 95; Iter     2/  172] train: loss: 0.0952985
[Epoch 95; Iter    32/  172] train: loss: 0.0867008
[Epoch 95; Iter    62/  172] train: loss: 0.1360217
[Epoch 95; Iter    92/  172] train: loss: 0.1087451
[Epoch 95; Iter   122/  172] train: loss: 0.1471071
[Epoch 95; Iter   152/  172] train: loss: 0.0843901
[Epoch 95] ogbg-moltoxcast: 0.638427 val loss: 0.304226
[Epoch 95] ogbg-moltoxcast: 0.611571 test loss: 0.354301
[Epoch 96; Iter    10/  172] train: loss: 0.0829479
[Epoch 96; Iter    40/  172] train: loss: 0.1667280
[Epoch 96; Iter    70/  172] train: loss: 0.1048249
[Epoch 96; Iter   100/  172] train: loss: 0.1172089
[Epoch 96; Iter   130/  172] train: loss: 0.1041433
[Epoch 96; Iter   160/  172] train: loss: 0.0930294
[Epoch 96] ogbg-moltoxcast: 0.634210 val loss: 0.310906
[Epoch 96] ogbg-moltoxcast: 0.610647 test loss: 0.359647
[Epoch 97; Iter    18/  172] train: loss: 0.1669291
[Epoch 97; Iter    48/  172] train: loss: 0.1026253
[Epoch 97; Iter    78/  172] train: loss: 0.1265917
[Epoch 97; Iter   108/  172] train: loss: 0.0951525
[Epoch 97; Iter   138/  172] train: loss: 0.1163231
[Epoch 97; Iter   168/  172] train: loss: 0.1175765
[Epoch 97] ogbg-moltoxcast: 0.638298 val loss: 0.305419
[Epoch 97] ogbg-moltoxcast: 0.610627 test loss: 0.356280
[Epoch 98; Iter    26/  172] train: loss: 0.1352261
[Epoch 98; Iter    56/  172] train: loss: 0.1897185
[Epoch 98; Iter    86/  172] train: loss: 0.1349535
[Epoch 98; Iter   116/  172] train: loss: 0.1090498
[Epoch 98; Iter   146/  172] train: loss: 0.1401911
[Epoch 98] ogbg-moltoxcast: 0.642166 val loss: 0.302966
[Epoch 98] ogbg-moltoxcast: 0.612551 test loss: 0.356002
[Epoch 99; Iter     4/  172] train: loss: 0.0993236
[Epoch 99; Iter    34/  172] train: loss: 0.0754010
[Epoch 99; Iter    64/  172] train: loss: 0.1202914
[Epoch 99; Iter    94/  172] train: loss: 0.1089962
[Epoch 99; Iter   124/  172] train: loss: 0.0788803
[Epoch 99; Iter   154/  172] train: loss: 0.1141630
[Epoch 99] ogbg-moltoxcast: 0.636837 val loss: 0.307980
[Epoch 99] ogbg-moltoxcast: 0.608652 test loss: 0.362974
[Epoch 100; Iter    12/  172] train: loss: 0.1042204
[Epoch 100; Iter    42/  172] train: loss: 0.1516325
[Epoch 100; Iter    72/  172] train: loss: 0.0939833
[Epoch 100; Iter   102/  172] train: loss: 0.0891351
[Epoch 100; Iter   132/  172] train: loss: 0.1007040
[Epoch 100; Iter   162/  172] train: loss: 0.1070751
[Epoch 100] ogbg-moltoxcast: 0.636994 val loss: 0.311252
[Epoch 100] ogbg-moltoxcast: 0.610168 test loss: 0.363864
[Epoch 101; Iter    20/  172] train: loss: 0.1338680
[Epoch 101; Iter    50/  172] train: loss: 0.1176909
[Epoch 101; Iter    80/  172] train: loss: 0.1167153
[Epoch 101; Iter   110/  172] train: loss: 0.1232399
[Epoch 101; Iter   140/  172] train: loss: 0.1215375
[Epoch 101; Iter   170/  172] train: loss: 0.1139458
[Epoch 101] ogbg-moltoxcast: 0.636517 val loss: 0.309326
[Epoch 101] ogbg-moltoxcast: 0.608801 test loss: 0.362961
[Epoch 102; Iter    28/  172] train: loss: 0.1356085
[Epoch 102; Iter    58/  172] train: loss: 0.0979194
[Epoch 102; Iter    88/  172] train: loss: 0.1018050
[Epoch 102; Iter   118/  172] train: loss: 0.1164502
[Epoch 102; Iter   148/  172] train: loss: 0.1180617
[Epoch 102] ogbg-moltoxcast: 0.637239 val loss: 0.309140
[Epoch 102] ogbg-moltoxcast: 0.610042 test loss: 0.361695
[Epoch 103; Iter     6/  172] train: loss: 0.1251434
[Epoch 103; Iter    36/  172] train: loss: 0.1458763
[Epoch 103; Iter    66/  172] train: loss: 0.1570915
[Epoch 103; Iter    96/  172] train: loss: 0.0863855
[Epoch 103; Iter   126/  172] train: loss: 0.0738660
[Epoch 103; Iter   156/  172] train: loss: 0.0848805
[Epoch 103] ogbg-moltoxcast: 0.634198 val loss: 0.311617
[Epoch 103] ogbg-moltoxcast: 0.609180 test loss: 0.366137
[Epoch 104; Iter    14/  172] train: loss: 0.1073844
[Epoch 104; Iter    44/  172] train: loss: 0.1004259
[Epoch 104; Iter    74/  172] train: loss: 0.1293285
[Epoch 104; Iter   104/  172] train: loss: 0.0958765
[Epoch 104; Iter   134/  172] train: loss: 0.1429994
[Epoch 104; Iter   164/  172] train: loss: 0.0896924
[Epoch 104] ogbg-moltoxcast: 0.637531 val loss: 0.307090
[Epoch 104] ogbg-moltoxcast: 0.609097 test loss: 0.362749
[Epoch 105; Iter    22/  172] train: loss: 0.0934064
[Epoch 105; Iter    52/  172] train: loss: 0.1102926
[Epoch 105; Iter    82/  172] train: loss: 0.1228382
[Epoch 105; Iter   112/  172] train: loss: 0.1013692
[Epoch 105; Iter   142/  172] train: loss: 0.0969065
[Epoch 105; Iter   172/  172] train: loss: 0.1210357
[Epoch 105] ogbg-moltoxcast: 0.634487 val loss: 0.313395
[Epoch 105] ogbg-moltoxcast: 0.606559 test loss: 0.366869
[Epoch 106; Iter    30/  172] train: loss: 0.1729569
[Epoch 106; Iter    60/  172] train: loss: 0.1097444
[Epoch 106; Iter    90/  172] train: loss: 0.1025088
[Epoch 106; Iter   120/  172] train: loss: 0.1062731
[Epoch 106; Iter   150/  172] train: loss: 0.0953001
[Epoch 106] ogbg-moltoxcast: 0.634335 val loss: 0.314318
[Epoch 106] ogbg-moltoxcast: 0.608308 test loss: 0.368072
[Epoch 107; Iter     8/  172] train: loss: 0.1166339
[Epoch 107; Iter    38/  172] train: loss: 0.1147845
[Epoch 107; Iter    68/  172] train: loss: 0.1154655
[Epoch 107; Iter    98/  172] train: loss: 0.1750938
[Epoch 107; Iter   128/  172] train: loss: 0.1113172
[Epoch 107; Iter   158/  172] train: loss: 0.0951325
[Epoch 107] ogbg-moltoxcast: 0.636888 val loss: 0.317635
[Epoch 107] ogbg-moltoxcast: 0.609832 test loss: 0.373605
[Epoch 108; Iter    16/  172] train: loss: 0.1263501
[Epoch 108; Iter    46/  172] train: loss: 0.1247486
[Epoch 108; Iter    76/  172] train: loss: 0.1081332
[Epoch 108; Iter   106/  172] train: loss: 0.1259176
[Epoch 108; Iter   136/  172] train: loss: 0.0927067
[Epoch 108; Iter   166/  172] train: loss: 0.1009704
[Epoch 108] ogbg-moltoxcast: 0.638971 val loss: 0.310455
[Epoch 108] ogbg-moltoxcast: 0.610333 test loss: 0.367022
[Epoch 109; Iter    24/  172] train: loss: 0.1006546
[Epoch 109; Iter    54/  172] train: loss: 0.0792281
[Epoch 109; Iter    84/  172] train: loss: 0.0959927
[Epoch 109; Iter   114/  172] train: loss: 0.1353597
[Epoch 109; Iter   144/  172] train: loss: 0.1394871
[Epoch 109] ogbg-moltoxcast: 0.632682 val loss: 0.316618
[Epoch 109] ogbg-moltoxcast: 0.606368 test loss: 0.370559
[Epoch 110; Iter     2/  172] train: loss: 0.0991083
[Epoch 110; Iter    32/  172] train: loss: 0.1138697
[Epoch 110; Iter    62/  172] train: loss: 0.0772533
[Epoch 110; Iter    92/  172] train: loss: 0.0976135
[Epoch 110; Iter   122/  172] train: loss: 0.0827480
[Epoch 110; Iter   152/  172] train: loss: 0.1530045
[Epoch 110] ogbg-moltoxcast: 0.632121 val loss: 0.312054
[Epoch 110] ogbg-moltoxcast: 0.606524 test loss: 0.363063
[Epoch 111; Iter    10/  172] train: loss: 0.1421266
[Epoch 111; Iter    40/  172] train: loss: 0.1363370
[Epoch 111; Iter    70/  172] train: loss: 0.1431759
[Epoch 111; Iter   100/  172] train: loss: 0.0894112
[Epoch 111; Iter   130/  172] train: loss: 0.1206877
[Epoch 111; Iter   160/  172] train: loss: 0.1363439
[Epoch 111] ogbg-moltoxcast: 0.636708 val loss: 0.313770
[Epoch 111] ogbg-moltoxcast: 0.609889 test loss: 0.367613
[Epoch 112; Iter    18/  172] train: loss: 0.1155342
[Epoch 112; Iter    48/  172] train: loss: 0.1417864
[Epoch 112; Iter    78/  172] train: loss: 0.1498691
[Epoch 112; Iter   108/  172] train: loss: 0.0912428
[Epoch 112; Iter   138/  172] train: loss: 0.1156100
[Epoch 112; Iter   168/  172] train: loss: 0.1605173
[Epoch 112] ogbg-moltoxcast: 0.636146 val loss: 0.312998
[Epoch 112] ogbg-moltoxcast: 0.607300 test loss: 0.367456
[Epoch 113; Iter    26/  172] train: loss: 0.0979279
[Epoch 113; Iter    56/  172] train: loss: 0.0946866
[Epoch 113; Iter    86/  172] train: loss: 0.1247760
[Epoch 113; Iter   116/  172] train: loss: 0.1319664
[Epoch 113; Iter   146/  172] train: loss: 0.0824463
[Epoch 113] ogbg-moltoxcast: 0.632074 val loss: 0.314673
[Epoch 113] ogbg-moltoxcast: 0.605929 test loss: 0.367582
[Epoch 114; Iter     4/  172] train: loss: 0.1055034[Epoch 92; Iter    11/  229] train: loss: 0.1215817
[Epoch 92; Iter    41/  229] train: loss: 0.1110005
[Epoch 92; Iter    71/  229] train: loss: 0.1286909
[Epoch 92; Iter   101/  229] train: loss: 0.1107963
[Epoch 92; Iter   131/  229] train: loss: 0.0907227
[Epoch 92; Iter   161/  229] train: loss: 0.0822809
[Epoch 92; Iter   191/  229] train: loss: 0.1155337
[Epoch 92; Iter   221/  229] train: loss: 0.1340541
[Epoch 92] ogbg-moltoxcast: 0.701689 val loss: 0.260401
[Epoch 92] ogbg-moltoxcast: 0.648263 test loss: 0.335052
[Epoch 93; Iter    22/  229] train: loss: 0.0859868
[Epoch 93; Iter    52/  229] train: loss: 0.0739541
[Epoch 93; Iter    82/  229] train: loss: 0.1149496
[Epoch 93; Iter   112/  229] train: loss: 0.1206863
[Epoch 93; Iter   142/  229] train: loss: 0.0926079
[Epoch 93; Iter   172/  229] train: loss: 0.1565294
[Epoch 93; Iter   202/  229] train: loss: 0.1246251
[Epoch 93] ogbg-moltoxcast: 0.704750 val loss: 0.260837
[Epoch 93] ogbg-moltoxcast: 0.653684 test loss: 0.330671
[Epoch 94; Iter     3/  229] train: loss: 0.1779343
[Epoch 94; Iter    33/  229] train: loss: 0.1479226
[Epoch 94; Iter    63/  229] train: loss: 0.1392618
[Epoch 94; Iter    93/  229] train: loss: 0.0859756
[Epoch 94; Iter   123/  229] train: loss: 0.1029948
[Epoch 94; Iter   153/  229] train: loss: 0.1217883
[Epoch 94; Iter   183/  229] train: loss: 0.1340124
[Epoch 94; Iter   213/  229] train: loss: 0.1714856
[Epoch 94] ogbg-moltoxcast: 0.704147 val loss: 0.263004
[Epoch 94] ogbg-moltoxcast: 0.649772 test loss: 0.334383
[Epoch 95; Iter    14/  229] train: loss: 0.1201974
[Epoch 95; Iter    44/  229] train: loss: 0.1275265
[Epoch 95; Iter    74/  229] train: loss: 0.1659502
[Epoch 95; Iter   104/  229] train: loss: 0.1212714
[Epoch 95; Iter   134/  229] train: loss: 0.1347568
[Epoch 95; Iter   164/  229] train: loss: 0.1095356
[Epoch 95; Iter   194/  229] train: loss: 0.0822298
[Epoch 95; Iter   224/  229] train: loss: 0.1124914
[Epoch 95] ogbg-moltoxcast: 0.701325 val loss: 0.265584
[Epoch 95] ogbg-moltoxcast: 0.650802 test loss: 0.335896
[Epoch 96; Iter    25/  229] train: loss: 0.1324442
[Epoch 96; Iter    55/  229] train: loss: 0.0660788
[Epoch 96; Iter    85/  229] train: loss: 0.1348658
[Epoch 96; Iter   115/  229] train: loss: 0.1402254
[Epoch 96; Iter   145/  229] train: loss: 0.1317904
[Epoch 96; Iter   175/  229] train: loss: 0.1361515
[Epoch 96; Iter   205/  229] train: loss: 0.1103098
[Epoch 96] ogbg-moltoxcast: 0.701845 val loss: 0.264425
[Epoch 96] ogbg-moltoxcast: 0.653618 test loss: 0.335707
[Epoch 97; Iter     6/  229] train: loss: 0.1218729
[Epoch 97; Iter    36/  229] train: loss: 0.1051089
[Epoch 97; Iter    66/  229] train: loss: 0.1052361
[Epoch 97; Iter    96/  229] train: loss: 0.1035716
[Epoch 97; Iter   126/  229] train: loss: 0.1343102
[Epoch 97; Iter   156/  229] train: loss: 0.1212038
[Epoch 97; Iter   186/  229] train: loss: 0.0913790
[Epoch 97; Iter   216/  229] train: loss: 0.1268687
[Epoch 97] ogbg-moltoxcast: 0.704658 val loss: 0.260524
[Epoch 97] ogbg-moltoxcast: 0.654996 test loss: 0.330222
[Epoch 98; Iter    17/  229] train: loss: 0.1302670
[Epoch 98; Iter    47/  229] train: loss: 0.1277915
[Epoch 98; Iter    77/  229] train: loss: 0.0991056
[Epoch 98; Iter   107/  229] train: loss: 0.1093482
[Epoch 98; Iter   137/  229] train: loss: 0.1172713
[Epoch 98; Iter   167/  229] train: loss: 0.1420145
[Epoch 98; Iter   197/  229] train: loss: 0.1392667
[Epoch 98; Iter   227/  229] train: loss: 0.1170219
[Epoch 98] ogbg-moltoxcast: 0.701130 val loss: 0.262776
[Epoch 98] ogbg-moltoxcast: 0.648779 test loss: 0.337347
[Epoch 99; Iter    28/  229] train: loss: 0.1385375
[Epoch 99; Iter    58/  229] train: loss: 0.1439033
[Epoch 99; Iter    88/  229] train: loss: 0.1513686
[Epoch 99; Iter   118/  229] train: loss: 0.1459172
[Epoch 99; Iter   148/  229] train: loss: 0.1386673
[Epoch 99; Iter   178/  229] train: loss: 0.1842379
[Epoch 99; Iter   208/  229] train: loss: 0.0567780
[Epoch 99] ogbg-moltoxcast: 0.699597 val loss: 0.263515
[Epoch 99] ogbg-moltoxcast: 0.649273 test loss: 0.339167
[Epoch 100; Iter     9/  229] train: loss: 0.0918557
[Epoch 100; Iter    39/  229] train: loss: 0.1216659
[Epoch 100; Iter    69/  229] train: loss: 0.0961819
[Epoch 100; Iter    99/  229] train: loss: 0.1124067
[Epoch 100; Iter   129/  229] train: loss: 0.1081844
[Epoch 100; Iter   159/  229] train: loss: 0.1068273
[Epoch 100; Iter   189/  229] train: loss: 0.1231195
[Epoch 100; Iter   219/  229] train: loss: 0.1181607
[Epoch 100] ogbg-moltoxcast: 0.705475 val loss: 0.264587
[Epoch 100] ogbg-moltoxcast: 0.651373 test loss: 0.340601
[Epoch 101; Iter    20/  229] train: loss: 0.1564497
[Epoch 101; Iter    50/  229] train: loss: 0.1102807
[Epoch 101; Iter    80/  229] train: loss: 0.0910979
[Epoch 101; Iter   110/  229] train: loss: 0.1195149
[Epoch 101; Iter   140/  229] train: loss: 0.1271186
[Epoch 101; Iter   170/  229] train: loss: 0.1246814
[Epoch 101; Iter   200/  229] train: loss: 0.1649674
[Epoch 101] ogbg-moltoxcast: 0.700402 val loss: 0.265035
[Epoch 101] ogbg-moltoxcast: 0.650656 test loss: 0.337501
[Epoch 102; Iter     1/  229] train: loss: 0.1120063
[Epoch 102; Iter    31/  229] train: loss: 0.1135370
[Epoch 102; Iter    61/  229] train: loss: 0.1660599
[Epoch 102; Iter    91/  229] train: loss: 0.1501189
[Epoch 102; Iter   121/  229] train: loss: 0.1289636
[Epoch 102; Iter   151/  229] train: loss: 0.1095269
[Epoch 102; Iter   181/  229] train: loss: 0.1577696
[Epoch 102; Iter   211/  229] train: loss: 0.1066393
[Epoch 102] ogbg-moltoxcast: 0.700457 val loss: 0.265802
[Epoch 102] ogbg-moltoxcast: 0.652726 test loss: 0.337386
[Epoch 103; Iter    12/  229] train: loss: 0.1033954
[Epoch 103; Iter    42/  229] train: loss: 0.1252983
[Epoch 103; Iter    72/  229] train: loss: 0.0975505
[Epoch 103; Iter   102/  229] train: loss: 0.1605455
[Epoch 103; Iter   132/  229] train: loss: 0.1516217
[Epoch 103; Iter   162/  229] train: loss: 0.0691905
[Epoch 103; Iter   192/  229] train: loss: 0.1214377
[Epoch 103; Iter   222/  229] train: loss: 0.1487893
[Epoch 103] ogbg-moltoxcast: 0.707367 val loss: 0.264071
[Epoch 103] ogbg-moltoxcast: 0.653267 test loss: 0.339209
[Epoch 104; Iter    23/  229] train: loss: 0.1267692
[Epoch 104; Iter    53/  229] train: loss: 0.0785536
[Epoch 104; Iter    83/  229] train: loss: 0.1082481
[Epoch 104; Iter   113/  229] train: loss: 0.1579168
[Epoch 104; Iter   143/  229] train: loss: 0.1483052
[Epoch 104; Iter   173/  229] train: loss: 0.1228833
[Epoch 104; Iter   203/  229] train: loss: 0.1118977
[Epoch 104] ogbg-moltoxcast: 0.710572 val loss: 0.261716
[Epoch 104] ogbg-moltoxcast: 0.655655 test loss: 0.337793
[Epoch 105; Iter     4/  229] train: loss: 0.1099307
[Epoch 105; Iter    34/  229] train: loss: 0.1134430
[Epoch 105; Iter    64/  229] train: loss: 0.1149714
[Epoch 105; Iter    94/  229] train: loss: 0.1209591
[Epoch 105; Iter   124/  229] train: loss: 0.1414487
[Epoch 105; Iter   154/  229] train: loss: 0.1052879
[Epoch 105; Iter   184/  229] train: loss: 0.1069249
[Epoch 105; Iter   214/  229] train: loss: 0.1395632
[Epoch 105] ogbg-moltoxcast: 0.704778 val loss: 0.265829
[Epoch 105] ogbg-moltoxcast: 0.650307 test loss: 0.339119
[Epoch 106; Iter    15/  229] train: loss: 0.1091565
[Epoch 106; Iter    45/  229] train: loss: 0.1031104
[Epoch 106; Iter    75/  229] train: loss: 0.1617881
[Epoch 106; Iter   105/  229] train: loss: 0.1359720
[Epoch 106; Iter   135/  229] train: loss: 0.1256158
[Epoch 106; Iter   165/  229] train: loss: 0.1407288
[Epoch 106; Iter   195/  229] train: loss: 0.1238675
[Epoch 106; Iter   225/  229] train: loss: 0.1266895
[Epoch 106] ogbg-moltoxcast: 0.699082 val loss: 0.267072
[Epoch 106] ogbg-moltoxcast: 0.645347 test loss: 0.342448
[Epoch 107; Iter    26/  229] train: loss: 0.0990683
[Epoch 107; Iter    56/  229] train: loss: 0.1210468
[Epoch 107; Iter    86/  229] train: loss: 0.1067636
[Epoch 107; Iter   116/  229] train: loss: 0.1232405
[Epoch 107; Iter   146/  229] train: loss: 0.0989495
[Epoch 107; Iter   176/  229] train: loss: 0.1194299
[Epoch 107; Iter   206/  229] train: loss: 0.1644166
[Epoch 107] ogbg-moltoxcast: 0.702999 val loss: 0.266552
[Epoch 92; Iter    11/  229] train: loss: 0.1394813
[Epoch 92; Iter    41/  229] train: loss: 0.1295934
[Epoch 92; Iter    71/  229] train: loss: 0.1242096
[Epoch 92; Iter   101/  229] train: loss: 0.1414913
[Epoch 92; Iter   131/  229] train: loss: 0.1332017
[Epoch 92; Iter   161/  229] train: loss: 0.1136881
[Epoch 92; Iter   191/  229] train: loss: 0.1261385
[Epoch 92; Iter   221/  229] train: loss: 0.1688181
[Epoch 92] ogbg-moltoxcast: 0.685386 val loss: 0.278482
[Epoch 92] ogbg-moltoxcast: 0.655932 test loss: 0.330441
[Epoch 93; Iter    22/  229] train: loss: 0.1076056
[Epoch 93; Iter    52/  229] train: loss: 0.1159275
[Epoch 93; Iter    82/  229] train: loss: 0.1624494
[Epoch 93; Iter   112/  229] train: loss: 0.1419087
[Epoch 93; Iter   142/  229] train: loss: 0.1371424
[Epoch 93; Iter   172/  229] train: loss: 0.1209669
[Epoch 93; Iter   202/  229] train: loss: 0.0957408
[Epoch 93] ogbg-moltoxcast: 0.689757 val loss: 0.282334
[Epoch 93] ogbg-moltoxcast: 0.655748 test loss: 0.337253
[Epoch 94; Iter     3/  229] train: loss: 0.1168543
[Epoch 94; Iter    33/  229] train: loss: 0.1322263
[Epoch 94; Iter    63/  229] train: loss: 0.1392555
[Epoch 94; Iter    93/  229] train: loss: 0.1129008
[Epoch 94; Iter   123/  229] train: loss: 0.1299715
[Epoch 94; Iter   153/  229] train: loss: 0.1860798
[Epoch 94; Iter   183/  229] train: loss: 0.1422615
[Epoch 94; Iter   213/  229] train: loss: 0.1152101
[Epoch 94] ogbg-moltoxcast: 0.690773 val loss: 0.279010
[Epoch 94] ogbg-moltoxcast: 0.658983 test loss: 0.332565
[Epoch 95; Iter    14/  229] train: loss: 0.1282827
[Epoch 95; Iter    44/  229] train: loss: 0.0969125
[Epoch 95; Iter    74/  229] train: loss: 0.1526437
[Epoch 95; Iter   104/  229] train: loss: 0.1398512
[Epoch 95; Iter   134/  229] train: loss: 0.0934523
[Epoch 95; Iter   164/  229] train: loss: 0.1181266
[Epoch 95; Iter   194/  229] train: loss: 0.1370158
[Epoch 95; Iter   224/  229] train: loss: 0.1531451
[Epoch 95] ogbg-moltoxcast: 0.688314 val loss: 0.286950
[Epoch 95] ogbg-moltoxcast: 0.656519 test loss: 0.333009
[Epoch 96; Iter    25/  229] train: loss: 0.1371954
[Epoch 96; Iter    55/  229] train: loss: 0.1138640
[Epoch 96; Iter    85/  229] train: loss: 0.1036071
[Epoch 96; Iter   115/  229] train: loss: 0.1462739
[Epoch 96; Iter   145/  229] train: loss: 0.1243009
[Epoch 96; Iter   175/  229] train: loss: 0.1050793
[Epoch 96; Iter   205/  229] train: loss: 0.1574263
[Epoch 96] ogbg-moltoxcast: 0.689392 val loss: 0.280222
[Epoch 96] ogbg-moltoxcast: 0.659695 test loss: 0.330003
[Epoch 97; Iter     6/  229] train: loss: 0.1342092
[Epoch 97; Iter    36/  229] train: loss: 0.1125948
[Epoch 97; Iter    66/  229] train: loss: 0.0932702
[Epoch 97; Iter    96/  229] train: loss: 0.1136934
[Epoch 97; Iter   126/  229] train: loss: 0.1333958
[Epoch 97; Iter   156/  229] train: loss: 0.1022467
[Epoch 97; Iter   186/  229] train: loss: 0.1023790
[Epoch 97; Iter   216/  229] train: loss: 0.1979160
[Epoch 97] ogbg-moltoxcast: 0.685913 val loss: 0.278453
[Epoch 97] ogbg-moltoxcast: 0.655192 test loss: 0.326019
[Epoch 98; Iter    17/  229] train: loss: 0.1282804
[Epoch 98; Iter    47/  229] train: loss: 0.1342440
[Epoch 98; Iter    77/  229] train: loss: 0.1309703
[Epoch 98; Iter   107/  229] train: loss: 0.1113341
[Epoch 98; Iter   137/  229] train: loss: 0.1535191
[Epoch 98; Iter   167/  229] train: loss: 0.1123437
[Epoch 98; Iter   197/  229] train: loss: 0.1071781
[Epoch 98; Iter   227/  229] train: loss: 0.1500272
[Epoch 98] ogbg-moltoxcast: 0.689756 val loss: 0.285523
[Epoch 98] ogbg-moltoxcast: 0.660534 test loss: 0.330398
[Epoch 99; Iter    28/  229] train: loss: 0.1291005
[Epoch 99; Iter    58/  229] train: loss: 0.1472499
[Epoch 99; Iter    88/  229] train: loss: 0.1267715
[Epoch 99; Iter   118/  229] train: loss: 0.1132183
[Epoch 99; Iter   148/  229] train: loss: 0.1984173
[Epoch 99; Iter   178/  229] train: loss: 0.1561140
[Epoch 99; Iter   208/  229] train: loss: 0.1263324
[Epoch 99] ogbg-moltoxcast: 0.686115 val loss: 0.280465
[Epoch 99] ogbg-moltoxcast: 0.658002 test loss: 0.329585
[Epoch 100; Iter     9/  229] train: loss: 0.0965459
[Epoch 100; Iter    39/  229] train: loss: 0.1466550
[Epoch 100; Iter    69/  229] train: loss: 0.1310824
[Epoch 100; Iter    99/  229] train: loss: 0.1204809
[Epoch 100; Iter   129/  229] train: loss: 0.1895972
[Epoch 100; Iter   159/  229] train: loss: 0.1237721
[Epoch 100; Iter   189/  229] train: loss: 0.1259760
[Epoch 100; Iter   219/  229] train: loss: 0.1231671
[Epoch 100] ogbg-moltoxcast: 0.689458 val loss: 0.304839
[Epoch 100] ogbg-moltoxcast: 0.659759 test loss: 0.331548
[Epoch 101; Iter    20/  229] train: loss: 0.1239178
[Epoch 101; Iter    50/  229] train: loss: 0.1005156
[Epoch 101; Iter    80/  229] train: loss: 0.1197153
[Epoch 101; Iter   110/  229] train: loss: 0.1323996
[Epoch 101; Iter   140/  229] train: loss: 0.0799730
[Epoch 101; Iter   170/  229] train: loss: 0.1500799
[Epoch 101; Iter   200/  229] train: loss: 0.1117751
[Epoch 101] ogbg-moltoxcast: 0.690784 val loss: 0.278837
[Epoch 101] ogbg-moltoxcast: 0.660518 test loss: 0.329389
[Epoch 102; Iter     1/  229] train: loss: 0.1419910
[Epoch 102; Iter    31/  229] train: loss: 0.0867580
[Epoch 102; Iter    61/  229] train: loss: 0.0953417
[Epoch 102; Iter    91/  229] train: loss: 0.1187056
[Epoch 102; Iter   121/  229] train: loss: 0.1204888
[Epoch 102; Iter   151/  229] train: loss: 0.1265899
[Epoch 102; Iter   181/  229] train: loss: 0.1265869
[Epoch 102; Iter   211/  229] train: loss: 0.1239679
[Epoch 102] ogbg-moltoxcast: 0.688813 val loss: 0.282361
[Epoch 102] ogbg-moltoxcast: 0.660921 test loss: 0.327589
[Epoch 103; Iter    12/  229] train: loss: 0.0830843
[Epoch 103; Iter    42/  229] train: loss: 0.1245597
[Epoch 103; Iter    72/  229] train: loss: 0.1239095
[Epoch 103; Iter   102/  229] train: loss: 0.1408603
[Epoch 103; Iter   132/  229] train: loss: 0.1213029
[Epoch 103; Iter   162/  229] train: loss: 0.1216686
[Epoch 103; Iter   192/  229] train: loss: 0.1389141
[Epoch 103; Iter   222/  229] train: loss: 0.1366720
[Epoch 103] ogbg-moltoxcast: 0.687570 val loss: 0.293255
[Epoch 103] ogbg-moltoxcast: 0.657696 test loss: 0.332220
[Epoch 104; Iter    23/  229] train: loss: 0.1139650
[Epoch 104; Iter    53/  229] train: loss: 0.1249754
[Epoch 104; Iter    83/  229] train: loss: 0.1045161
[Epoch 104; Iter   113/  229] train: loss: 0.1546613
[Epoch 104; Iter   143/  229] train: loss: 0.1187653
[Epoch 104; Iter   173/  229] train: loss: 0.1106872
[Epoch 104; Iter   203/  229] train: loss: 0.1020841
[Epoch 104] ogbg-moltoxcast: 0.686975 val loss: 0.281750
[Epoch 104] ogbg-moltoxcast: 0.659557 test loss: 0.332323
[Epoch 105; Iter     4/  229] train: loss: 0.1396650
[Epoch 105; Iter    34/  229] train: loss: 0.1069453
[Epoch 105; Iter    64/  229] train: loss: 0.1088746
[Epoch 105; Iter    94/  229] train: loss: 0.1205534
[Epoch 105; Iter   124/  229] train: loss: 0.1480464
[Epoch 105; Iter   154/  229] train: loss: 0.1212566
[Epoch 105; Iter   184/  229] train: loss: 0.1190066
[Epoch 105; Iter   214/  229] train: loss: 0.1203057
[Epoch 105] ogbg-moltoxcast: 0.686893 val loss: 0.283977
[Epoch 105] ogbg-moltoxcast: 0.656959 test loss: 0.334942
[Epoch 106; Iter    15/  229] train: loss: 0.1227841
[Epoch 106; Iter    45/  229] train: loss: 0.0952062
[Epoch 106; Iter    75/  229] train: loss: 0.1401499
[Epoch 106; Iter   105/  229] train: loss: 0.1243555
[Epoch 106; Iter   135/  229] train: loss: 0.1280905
[Epoch 106; Iter   165/  229] train: loss: 0.1419910
[Epoch 106; Iter   195/  229] train: loss: 0.1224402
[Epoch 106; Iter   225/  229] train: loss: 0.1336744
[Epoch 106] ogbg-moltoxcast: 0.686896 val loss: 0.281554
[Epoch 106] ogbg-moltoxcast: 0.656587 test loss: 0.329513
[Epoch 107; Iter    26/  229] train: loss: 0.1358499
[Epoch 107; Iter    56/  229] train: loss: 0.1198923
[Epoch 107; Iter    86/  229] train: loss: 0.1131558
[Epoch 107; Iter   116/  229] train: loss: 0.1110876
[Epoch 107; Iter   146/  229] train: loss: 0.0916274
[Epoch 107; Iter   176/  229] train: loss: 0.1469638
[Epoch 107; Iter   206/  229] train: loss: 0.0957256
[Epoch 107] ogbg-moltoxcast: 0.689463 val loss: 0.282544
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)

[Epoch 114; Iter    34/  172] train: loss: 0.0779835
[Epoch 114; Iter    64/  172] train: loss: 0.0713559
[Epoch 114; Iter    94/  172] train: loss: 0.1048016
[Epoch 114; Iter   124/  172] train: loss: 0.0980089
[Epoch 114; Iter   154/  172] train: loss: 0.1326909
[Epoch 114] ogbg-moltoxcast: 0.641489 val loss: 0.312369
[Epoch 114] ogbg-moltoxcast: 0.619180 test loss: 0.375966
[Epoch 115; Iter    12/  172] train: loss: 0.1437337
[Epoch 115; Iter    42/  172] train: loss: 0.0860869
[Epoch 115; Iter    72/  172] train: loss: 0.1418141
[Epoch 115; Iter   102/  172] train: loss: 0.0967259
[Epoch 115; Iter   132/  172] train: loss: 0.1210322
[Epoch 115; Iter   162/  172] train: loss: 0.0724621
[Epoch 115] ogbg-moltoxcast: 0.636962 val loss: 0.313431
[Epoch 115] ogbg-moltoxcast: 0.617085 test loss: 0.372554
[Epoch 116; Iter    20/  172] train: loss: 0.1023644
[Epoch 116; Iter    50/  172] train: loss: 0.1641548
[Epoch 116; Iter    80/  172] train: loss: 0.1078659
[Epoch 116; Iter   110/  172] train: loss: 0.0807928
[Epoch 116; Iter   140/  172] train: loss: 0.1131327
[Epoch 116; Iter   170/  172] train: loss: 0.1234668
[Epoch 116] ogbg-moltoxcast: 0.632286 val loss: 0.312652
[Epoch 116] ogbg-moltoxcast: 0.617557 test loss: 0.371552
[Epoch 117; Iter    28/  172] train: loss: 0.0994584
[Epoch 117; Iter    58/  172] train: loss: 0.1154423
[Epoch 117; Iter    88/  172] train: loss: 0.1417900
[Epoch 117; Iter   118/  172] train: loss: 0.1013458
[Epoch 117; Iter   148/  172] train: loss: 0.0785449
[Epoch 117] ogbg-moltoxcast: 0.635107 val loss: 0.311166
[Epoch 117] ogbg-moltoxcast: 0.616225 test loss: 0.370049
[Epoch 118; Iter     6/  172] train: loss: 0.1430633
[Epoch 118; Iter    36/  172] train: loss: 0.1103963
[Epoch 118; Iter    66/  172] train: loss: 0.1243013
[Epoch 118; Iter    96/  172] train: loss: 0.1070001
[Epoch 118; Iter   126/  172] train: loss: 0.0598219
[Epoch 118; Iter   156/  172] train: loss: 0.1346691
[Epoch 118] ogbg-moltoxcast: 0.638671 val loss: 0.307151
[Epoch 118] ogbg-moltoxcast: 0.616291 test loss: 0.364877
[Epoch 119; Iter    14/  172] train: loss: 0.1097389
[Epoch 119; Iter    44/  172] train: loss: 0.1086583
[Epoch 119; Iter    74/  172] train: loss: 0.0821127
[Epoch 119; Iter   104/  172] train: loss: 0.0784088
[Epoch 119; Iter   134/  172] train: loss: 0.1119631
[Epoch 119; Iter   164/  172] train: loss: 0.0995254
[Epoch 119] ogbg-moltoxcast: 0.636466 val loss: 0.312143
[Epoch 119] ogbg-moltoxcast: 0.616715 test loss: 0.371881
[Epoch 120; Iter    22/  172] train: loss: 0.1469534
[Epoch 120; Iter    52/  172] train: loss: 0.1067236
[Epoch 120; Iter    82/  172] train: loss: 0.1179046
[Epoch 120; Iter   112/  172] train: loss: 0.1056077
[Epoch 120; Iter   142/  172] train: loss: 0.1021956
[Epoch 120; Iter   172/  172] train: loss: 0.0763444
[Epoch 120] ogbg-moltoxcast: 0.635365 val loss: 0.312577
[Epoch 120] ogbg-moltoxcast: 0.616232 test loss: 0.372902
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 25.
Statistics on  val_best_checkpoint
mean_pred: -2.417971134185791
std_pred: 2.3276546001434326
mean_targets: nan
std_targets: nan
prcauc: 0.37062017485548
rocauc: 0.6846996400328498
ogbg-moltoxcast: 0.6846996400328498
OGBNanLabelBCEWithLogitsLoss: 0.25507758031117506
Statistics on  test
mean_pred: -2.4196557998657227
std_pred: 10.768775939941406
mean_targets: nan
std_targets: nan
prcauc: 0.31916311960810445
rocauc: 0.6311227504954056
ogbg-moltoxcast: 0.6311227504954056
OGBNanLabelBCEWithLogitsLoss: 0.4173036117492051
Statistics on  train
mean_pred: -3.1416001319885254
std_pred: 2.1593194007873535
mean_targets: nan
std_targets: nan
prcauc: 0.4867839444701096
rocauc: 0.8329434906291721
ogbg-moltoxcast: 0.8329434906291721
OGBNanLabelBCEWithLogitsLoss: 0.15142991642879192
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)

[Epoch 114; Iter    34/  172] train: loss: 0.0989064
[Epoch 114; Iter    64/  172] train: loss: 0.0829189
[Epoch 114; Iter    94/  172] train: loss: 0.1191761
[Epoch 114; Iter   124/  172] train: loss: 0.1791799
[Epoch 114; Iter   154/  172] train: loss: 0.0957622
[Epoch 114] ogbg-moltoxcast: 0.634496 val loss: 0.306654
[Epoch 114] ogbg-moltoxcast: 0.620101 test loss: 0.352810
[Epoch 115; Iter    12/  172] train: loss: 0.1373375
[Epoch 115; Iter    42/  172] train: loss: 0.0949966
[Epoch 115; Iter    72/  172] train: loss: 0.0910384
[Epoch 115; Iter   102/  172] train: loss: 0.0880479
[Epoch 115; Iter   132/  172] train: loss: 0.1028503
[Epoch 115; Iter   162/  172] train: loss: 0.0934637
[Epoch 115] ogbg-moltoxcast: 0.633478 val loss: 0.312812
[Epoch 115] ogbg-moltoxcast: 0.619857 test loss: 0.359800
[Epoch 116; Iter    20/  172] train: loss: 0.0992532
[Epoch 116; Iter    50/  172] train: loss: 0.0894685
[Epoch 116; Iter    80/  172] train: loss: 0.0975514
[Epoch 116; Iter   110/  172] train: loss: 0.1167469
[Epoch 116; Iter   140/  172] train: loss: 0.1057655
[Epoch 116; Iter   170/  172] train: loss: 0.0992943
[Epoch 116] ogbg-moltoxcast: 0.635954 val loss: 0.310214
[Epoch 116] ogbg-moltoxcast: 0.621038 test loss: 0.356544
[Epoch 117; Iter    28/  172] train: loss: 0.0862310
[Epoch 117; Iter    58/  172] train: loss: 0.1173895
[Epoch 117; Iter    88/  172] train: loss: 0.1522504
[Epoch 117; Iter   118/  172] train: loss: 0.0936791
[Epoch 117; Iter   148/  172] train: loss: 0.1203131
[Epoch 117] ogbg-moltoxcast: 0.632049 val loss: 0.310023
[Epoch 117] ogbg-moltoxcast: 0.620191 test loss: 0.354897
[Epoch 118; Iter     6/  172] train: loss: 0.1049427
[Epoch 118; Iter    36/  172] train: loss: 0.1421840
[Epoch 118; Iter    66/  172] train: loss: 0.1008146
[Epoch 118; Iter    96/  172] train: loss: 0.0809166
[Epoch 118; Iter   126/  172] train: loss: 0.0852948
[Epoch 118; Iter   156/  172] train: loss: 0.1208945
[Epoch 118] ogbg-moltoxcast: 0.634803 val loss: 0.308749
[Epoch 118] ogbg-moltoxcast: 0.619929 test loss: 0.354496
[Epoch 119; Iter    14/  172] train: loss: 0.1200612
[Epoch 119; Iter    44/  172] train: loss: 0.0741412
[Epoch 119; Iter    74/  172] train: loss: 0.0943822
[Epoch 119; Iter   104/  172] train: loss: 0.1197405
[Epoch 119; Iter   134/  172] train: loss: 0.0872199
[Epoch 119; Iter   164/  172] train: loss: 0.0843862
[Epoch 119] ogbg-moltoxcast: 0.628907 val loss: 0.313726
[Epoch 119] ogbg-moltoxcast: 0.617528 test loss: 0.359151
[Epoch 120; Iter    22/  172] train: loss: 0.0984545
[Epoch 120; Iter    52/  172] train: loss: 0.1037864
[Epoch 120; Iter    82/  172] train: loss: 0.0859263
[Epoch 120; Iter   112/  172] train: loss: 0.0904663
[Epoch 120; Iter   142/  172] train: loss: 0.0976236
[Epoch 120; Iter   172/  172] train: loss: 0.0804860
[Epoch 120] ogbg-moltoxcast: 0.635207 val loss: 0.310395
[Epoch 120] ogbg-moltoxcast: 0.622429 test loss: 0.357518
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 22.
Statistics on  val_best_checkpoint
mean_pred: -2.947486639022827
std_pred: 10.977535247802734
mean_targets: nan
std_targets: nan
prcauc: 0.36364632165611255
rocauc: 0.6827085492117538
ogbg-moltoxcast: 0.6827085492117538
OGBNanLabelBCEWithLogitsLoss: 0.3248674233668837
Statistics on  test
mean_pred: -2.637200355529785
std_pred: 2.820180654525757
mean_targets: nan
std_targets: nan
prcauc: 0.3200109503027531
rocauc: 0.6443370856188833
ogbg-moltoxcast: 0.6443370856188833
OGBNanLabelBCEWithLogitsLoss: 0.34377384673932504
Statistics on  train
mean_pred: -3.0746333599090576
std_pred: 2.195788621902466
mean_targets: nan
std_targets: nan
prcauc: 0.45811229729460445
rocauc: 0.8140671092298386
ogbg-moltoxcast: 0.8140671092298386
OGBNanLabelBCEWithLogitsLoss: 0.16030841468032017
[Epoch 101] ogbg-moltoxcast: 0.664113 val loss: 0.279042
[Epoch 101] ogbg-moltoxcast: 0.654628 test loss: 0.317888
[Epoch 102; Iter     9/  201] train: loss: 0.1724823
[Epoch 102; Iter    39/  201] train: loss: 0.1277240
[Epoch 102; Iter    69/  201] train: loss: 0.1177779
[Epoch 102; Iter    99/  201] train: loss: 0.1546491
[Epoch 102; Iter   129/  201] train: loss: 0.1004804
[Epoch 102; Iter   159/  201] train: loss: 0.0948356
[Epoch 102; Iter   189/  201] train: loss: 0.1102199
[Epoch 102] ogbg-moltoxcast: 0.663050 val loss: 0.291413
[Epoch 102] ogbg-moltoxcast: 0.654018 test loss: 0.330135
[Epoch 103; Iter    18/  201] train: loss: 0.0999062
[Epoch 103; Iter    48/  201] train: loss: 0.1431264
[Epoch 103; Iter    78/  201] train: loss: 0.1092967
[Epoch 103; Iter   108/  201] train: loss: 0.1343915
[Epoch 103; Iter   138/  201] train: loss: 0.1027701
[Epoch 103; Iter   168/  201] train: loss: 0.1304364
[Epoch 103; Iter   198/  201] train: loss: 0.1107045
[Epoch 103] ogbg-moltoxcast: 0.663078 val loss: 0.286785
[Epoch 103] ogbg-moltoxcast: 0.653754 test loss: 0.327355
[Epoch 104; Iter    27/  201] train: loss: 0.1110829
[Epoch 104; Iter    57/  201] train: loss: 0.1853977
[Epoch 104; Iter    87/  201] train: loss: 0.1023222
[Epoch 104; Iter   117/  201] train: loss: 0.1026507
[Epoch 104; Iter   147/  201] train: loss: 0.1271758
[Epoch 104; Iter   177/  201] train: loss: 0.1142925
[Epoch 104] ogbg-moltoxcast: 0.662784 val loss: 0.290780
[Epoch 104] ogbg-moltoxcast: 0.650111 test loss: 0.333416
[Epoch 105; Iter     6/  201] train: loss: 0.1117323
[Epoch 105; Iter    36/  201] train: loss: 0.2454787
[Epoch 105; Iter    66/  201] train: loss: 0.1353408
[Epoch 105; Iter    96/  201] train: loss: 0.1151861
[Epoch 105; Iter   126/  201] train: loss: 0.1177281
[Epoch 105; Iter   156/  201] train: loss: 0.1133187
[Epoch 105; Iter   186/  201] train: loss: 0.0938442
[Epoch 105] ogbg-moltoxcast: 0.662029 val loss: 0.286225
[Epoch 105] ogbg-moltoxcast: 0.651541 test loss: 0.327291
[Epoch 106; Iter    15/  201] train: loss: 0.1369297
[Epoch 106; Iter    45/  201] train: loss: 0.1198450
[Epoch 106; Iter    75/  201] train: loss: 0.1027379
[Epoch 106; Iter   105/  201] train: loss: 0.1300817
[Epoch 106; Iter   135/  201] train: loss: 0.1249553
[Epoch 106; Iter   165/  201] train: loss: 0.0902440
[Epoch 106; Iter   195/  201] train: loss: 0.1001549
[Epoch 106] ogbg-moltoxcast: 0.660943 val loss: 0.294176
[Epoch 106] ogbg-moltoxcast: 0.652225 test loss: 0.336388
[Epoch 107; Iter    24/  201] train: loss: 0.1225272
[Epoch 107; Iter    54/  201] train: loss: 0.1062409
[Epoch 107; Iter    84/  201] train: loss: 0.1324811
[Epoch 107; Iter   114/  201] train: loss: 0.1019317
[Epoch 107; Iter   144/  201] train: loss: 0.1457268
[Epoch 107; Iter   174/  201] train: loss: 0.1258139
[Epoch 107] ogbg-moltoxcast: 0.661620 val loss: 0.286677
[Epoch 107] ogbg-moltoxcast: 0.654899 test loss: 0.325942
[Epoch 108; Iter     3/  201] train: loss: 0.1068038
[Epoch 108; Iter    33/  201] train: loss: 0.1095912
[Epoch 108; Iter    63/  201] train: loss: 0.1182812
[Epoch 108; Iter    93/  201] train: loss: 0.0928172
[Epoch 108; Iter   123/  201] train: loss: 0.0976704
[Epoch 108; Iter   153/  201] train: loss: 0.1095103
[Epoch 108; Iter   183/  201] train: loss: 0.1117128
[Epoch 108] ogbg-moltoxcast: 0.660566 val loss: 0.286531
[Epoch 108] ogbg-moltoxcast: 0.652722 test loss: 0.325834
[Epoch 109; Iter    12/  201] train: loss: 0.1160223
[Epoch 109; Iter    42/  201] train: loss: 0.1458984
[Epoch 109; Iter    72/  201] train: loss: 0.1022297
[Epoch 109; Iter   102/  201] train: loss: 0.1142616
[Epoch 109; Iter   132/  201] train: loss: 0.1136550
[Epoch 109; Iter   162/  201] train: loss: 0.1074581
[Epoch 109; Iter   192/  201] train: loss: 0.1316306
[Epoch 109] ogbg-moltoxcast: 0.662564 val loss: 0.293085
[Epoch 109] ogbg-moltoxcast: 0.656358 test loss: 0.331904
[Epoch 110; Iter    21/  201] train: loss: 0.1252809
[Epoch 110; Iter    51/  201] train: loss: 0.1008816
[Epoch 110; Iter    81/  201] train: loss: 0.1106263
[Epoch 110; Iter   111/  201] train: loss: 0.1167365
[Epoch 110; Iter   141/  201] train: loss: 0.1457665
[Epoch 110; Iter   171/  201] train: loss: 0.1080290
[Epoch 110; Iter   201/  201] train: loss: 0.0832990
[Epoch 110] ogbg-moltoxcast: 0.661349 val loss: 0.282905
[Epoch 110] ogbg-moltoxcast: 0.650413 test loss: 0.322743
[Epoch 111; Iter    30/  201] train: loss: 0.1223990
[Epoch 111; Iter    60/  201] train: loss: 0.1176979
[Epoch 111; Iter    90/  201] train: loss: 0.1113526
[Epoch 111; Iter   120/  201] train: loss: 0.1383991
[Epoch 111; Iter   150/  201] train: loss: 0.1221809
[Epoch 111; Iter   180/  201] train: loss: 0.1124039
[Epoch 111] ogbg-moltoxcast: 0.662985 val loss: 0.285260
[Epoch 111] ogbg-moltoxcast: 0.652959 test loss: 0.325919
[Epoch 112; Iter     9/  201] train: loss: 0.1163638
[Epoch 112; Iter    39/  201] train: loss: 0.1075788
[Epoch 112; Iter    69/  201] train: loss: 0.1459384
[Epoch 112; Iter    99/  201] train: loss: 0.1417406
[Epoch 112; Iter   129/  201] train: loss: 0.0911650
[Epoch 112; Iter   159/  201] train: loss: 0.1430902
[Epoch 112; Iter   189/  201] train: loss: 0.1287902
[Epoch 112] ogbg-moltoxcast: 0.664486 val loss: 0.289500
[Epoch 112] ogbg-moltoxcast: 0.655665 test loss: 0.329306
[Epoch 113; Iter    18/  201] train: loss: 0.1259542
[Epoch 113; Iter    48/  201] train: loss: 0.0946259
[Epoch 113; Iter    78/  201] train: loss: 0.1201518
[Epoch 113; Iter   108/  201] train: loss: 0.1112020
[Epoch 113; Iter   138/  201] train: loss: 0.1115144
[Epoch 113; Iter   168/  201] train: loss: 0.0999805
[Epoch 113; Iter   198/  201] train: loss: 0.0849177
[Epoch 113] ogbg-moltoxcast: 0.661776 val loss: 0.294136
[Epoch 113] ogbg-moltoxcast: 0.653933 test loss: 0.331541
[Epoch 114; Iter    27/  201] train: loss: 0.1101410
[Epoch 114; Iter    57/  201] train: loss: 0.1001553
[Epoch 114; Iter    87/  201] train: loss: 0.1130330
[Epoch 114; Iter   117/  201] train: loss: 0.1522095
[Epoch 114; Iter   147/  201] train: loss: 0.1083608
[Epoch 114; Iter   177/  201] train: loss: 0.1033532
[Epoch 114] ogbg-moltoxcast: 0.664929 val loss: 0.289826
[Epoch 114] ogbg-moltoxcast: 0.652943 test loss: 0.330704
[Epoch 115; Iter     6/  201] train: loss: 0.1334012
[Epoch 115; Iter    36/  201] train: loss: 0.0952279
[Epoch 115; Iter    66/  201] train: loss: 0.1301269
[Epoch 115; Iter    96/  201] train: loss: 0.1140130
[Epoch 115; Iter   126/  201] train: loss: 0.1217249
[Epoch 115; Iter   156/  201] train: loss: 0.1439977
[Epoch 115; Iter   186/  201] train: loss: 0.1190911
[Epoch 115] ogbg-moltoxcast: 0.665093 val loss: 0.299393
[Epoch 115] ogbg-moltoxcast: 0.654226 test loss: 0.338651
[Epoch 116; Iter    15/  201] train: loss: 0.0864948
[Epoch 116; Iter    45/  201] train: loss: 0.0798211
[Epoch 116; Iter    75/  201] train: loss: 0.1585903
[Epoch 116; Iter   105/  201] train: loss: 0.0888538
[Epoch 116; Iter   135/  201] train: loss: 0.1308489
[Epoch 116; Iter   165/  201] train: loss: 0.1235484
[Epoch 116; Iter   195/  201] train: loss: 0.1286352
[Epoch 116] ogbg-moltoxcast: 0.659797 val loss: 0.293445
[Epoch 116] ogbg-moltoxcast: 0.649189 test loss: 0.334565
[Epoch 117; Iter    24/  201] train: loss: 0.1182697
[Epoch 117; Iter    54/  201] train: loss: 0.0969367
[Epoch 117; Iter    84/  201] train: loss: 0.1121743
[Epoch 117; Iter   114/  201] train: loss: 0.1022271
[Epoch 117; Iter   144/  201] train: loss: 0.0933257
[Epoch 117; Iter   174/  201] train: loss: 0.1332749
[Epoch 117] ogbg-moltoxcast: 0.666306 val loss: 0.286432
[Epoch 117] ogbg-moltoxcast: 0.654919 test loss: 0.329209
[Epoch 118; Iter     3/  201] train: loss: 0.1404946
[Epoch 118; Iter    33/  201] train: loss: 0.1520117
[Epoch 118; Iter    63/  201] train: loss: 0.0836307
[Epoch 118; Iter    93/  201] train: loss: 0.1724168
[Epoch 118; Iter   123/  201] train: loss: 0.1016324
[Epoch 118; Iter   153/  201] train: loss: 0.1327096
[Epoch 118; Iter   183/  201] train: loss: 0.0849676
[Epoch 118] ogbg-moltoxcast: 0.663544 val loss: 0.284419
[Epoch 118] ogbg-moltoxcast: 0.652217 test loss: 0.325639
[Epoch 119; Iter    12/  201] train: loss: 0.1226653

[Epoch 114; Iter    34/  172] train: loss: 0.1476235
[Epoch 114; Iter    64/  172] train: loss: 0.1409558
[Epoch 114; Iter    94/  172] train: loss: 0.0814246
[Epoch 114; Iter   124/  172] train: loss: 0.1457743
[Epoch 114; Iter   154/  172] train: loss: 0.1091426
[Epoch 114] ogbg-moltoxcast: 0.636925 val loss: 0.314777
[Epoch 114] ogbg-moltoxcast: 0.610405 test loss: 0.366540
[Epoch 115; Iter    12/  172] train: loss: 0.0698421
[Epoch 115; Iter    42/  172] train: loss: 0.1266805
[Epoch 115; Iter    72/  172] train: loss: 0.1299591
[Epoch 115; Iter   102/  172] train: loss: 0.1190585
[Epoch 115; Iter   132/  172] train: loss: 0.1403889
[Epoch 115; Iter   162/  172] train: loss: 0.1058154
[Epoch 115] ogbg-moltoxcast: 0.637307 val loss: 0.314055
[Epoch 115] ogbg-moltoxcast: 0.609608 test loss: 0.369053
[Epoch 116; Iter    20/  172] train: loss: 0.1559281
[Epoch 116; Iter    50/  172] train: loss: 0.1349315
[Epoch 116; Iter    80/  172] train: loss: 0.1119074
[Epoch 116; Iter   110/  172] train: loss: 0.1454094
[Epoch 116; Iter   140/  172] train: loss: 0.1177310
[Epoch 116; Iter   170/  172] train: loss: 0.1191195
[Epoch 116] ogbg-moltoxcast: 0.637553 val loss: 0.314817
[Epoch 116] ogbg-moltoxcast: 0.609300 test loss: 0.371533
[Epoch 117; Iter    28/  172] train: loss: 0.1145825
[Epoch 117; Iter    58/  172] train: loss: 0.1100877
[Epoch 117; Iter    88/  172] train: loss: 0.1217961
[Epoch 117; Iter   118/  172] train: loss: 0.1278889
[Epoch 117; Iter   148/  172] train: loss: 0.0848063
[Epoch 117] ogbg-moltoxcast: 0.637055 val loss: 0.317432
[Epoch 117] ogbg-moltoxcast: 0.607951 test loss: 0.375988
[Epoch 118; Iter     6/  172] train: loss: 0.1312731
[Epoch 118; Iter    36/  172] train: loss: 0.1146595
[Epoch 118; Iter    66/  172] train: loss: 0.1382143
[Epoch 118; Iter    96/  172] train: loss: 0.0848746
[Epoch 118; Iter   126/  172] train: loss: 0.0942314
[Epoch 118; Iter   156/  172] train: loss: 0.1156969
[Epoch 118] ogbg-moltoxcast: 0.635109 val loss: 0.312238
[Epoch 118] ogbg-moltoxcast: 0.605425 test loss: 0.368374
[Epoch 119; Iter    14/  172] train: loss: 0.1385801
[Epoch 119; Iter    44/  172] train: loss: 0.0785204
[Epoch 119; Iter    74/  172] train: loss: 0.0861181
[Epoch 119; Iter   104/  172] train: loss: 0.0793564
[Epoch 119; Iter   134/  172] train: loss: 0.1072692
[Epoch 119; Iter   164/  172] train: loss: 0.1414192
[Epoch 119] ogbg-moltoxcast: 0.635955 val loss: 0.316156
[Epoch 119] ogbg-moltoxcast: 0.609385 test loss: 0.371232
[Epoch 120; Iter    22/  172] train: loss: 0.1303599
[Epoch 120; Iter    52/  172] train: loss: 0.0990195
[Epoch 120; Iter    82/  172] train: loss: 0.1294449
[Epoch 120; Iter   112/  172] train: loss: 0.0864826
[Epoch 120; Iter   142/  172] train: loss: 0.1178291
[Epoch 120; Iter   172/  172] train: loss: 0.1277014
[Epoch 120] ogbg-moltoxcast: 0.634299 val loss: 0.314730
[Epoch 120] ogbg-moltoxcast: 0.606491 test loss: 0.369630
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 23.
Statistics on  val_best_checkpoint
mean_pred: -2.1215431690216064
std_pred: 2.348653793334961
mean_targets: nan
std_targets: nan
prcauc: 0.37327360993367703
rocauc: 0.6852800885909854
ogbg-moltoxcast: 0.6852800885909854
OGBNanLabelBCEWithLogitsLoss: 0.2700028874236962
Statistics on  test
mean_pred: -1.9128670692443848
std_pred: 2.4484705924987793
mean_targets: nan
std_targets: nan
prcauc: 0.3257698676469497
rocauc: 0.6468490623635434
ogbg-moltoxcast: 0.6468490623635434
OGBNanLabelBCEWithLogitsLoss: 0.3266580657198511
Statistics on  train
mean_pred: -2.855304002761841
std_pred: 2.140216588973999
mean_targets: nan
std_targets: nan
prcauc: 0.4795720098583757
rocauc: 0.8338364390712727
ogbg-moltoxcast: 0.8338364390712727
OGBNanLabelBCEWithLogitsLoss: 0.15364184824013433
All runs completed.
[Epoch 101] ogbg-moltoxcast: 0.670033 val loss: 0.286774
[Epoch 101] ogbg-moltoxcast: 0.653701 test loss: 0.330182
[Epoch 102; Iter     9/  201] train: loss: 0.1112856
[Epoch 102; Iter    39/  201] train: loss: 0.1324737
[Epoch 102; Iter    69/  201] train: loss: 0.1710935
[Epoch 102; Iter    99/  201] train: loss: 0.1209474
[Epoch 102; Iter   129/  201] train: loss: 0.1524454
[Epoch 102; Iter   159/  201] train: loss: 0.1235173
[Epoch 102; Iter   189/  201] train: loss: 0.0975580
[Epoch 102] ogbg-moltoxcast: 0.673542 val loss: 0.283953
[Epoch 102] ogbg-moltoxcast: 0.650851 test loss: 0.332876
[Epoch 103; Iter    18/  201] train: loss: 0.0869666
[Epoch 103; Iter    48/  201] train: loss: 0.1194731
[Epoch 103; Iter    78/  201] train: loss: 0.1040906
[Epoch 103; Iter   108/  201] train: loss: 0.1228508
[Epoch 103; Iter   138/  201] train: loss: 0.0839278
[Epoch 103; Iter   168/  201] train: loss: 0.1416360
[Epoch 103; Iter   198/  201] train: loss: 0.1055580
[Epoch 103] ogbg-moltoxcast: 0.673092 val loss: 0.277989
[Epoch 103] ogbg-moltoxcast: 0.655962 test loss: 0.322381
[Epoch 104; Iter    27/  201] train: loss: 0.0877279
[Epoch 104; Iter    57/  201] train: loss: 0.1157178
[Epoch 104; Iter    87/  201] train: loss: 0.1058707
[Epoch 104; Iter   117/  201] train: loss: 0.0849327
[Epoch 104; Iter   147/  201] train: loss: 0.1394836
[Epoch 104; Iter   177/  201] train: loss: 0.1416079
[Epoch 104] ogbg-moltoxcast: 0.667783 val loss: 0.286626
[Epoch 104] ogbg-moltoxcast: 0.652256 test loss: 0.330835
[Epoch 105; Iter     6/  201] train: loss: 0.1484330
[Epoch 105; Iter    36/  201] train: loss: 0.1478559
[Epoch 105; Iter    66/  201] train: loss: 0.1051989
[Epoch 105; Iter    96/  201] train: loss: 0.1278367
[Epoch 105; Iter   126/  201] train: loss: 0.1283686
[Epoch 105; Iter   156/  201] train: loss: 0.0979901
[Epoch 105; Iter   186/  201] train: loss: 0.0835708
[Epoch 105] ogbg-moltoxcast: 0.670632 val loss: 0.282981
[Epoch 105] ogbg-moltoxcast: 0.649572 test loss: 0.325256
[Epoch 106; Iter    15/  201] train: loss: 0.0828691
[Epoch 106; Iter    45/  201] train: loss: 0.1074595
[Epoch 106; Iter    75/  201] train: loss: 0.1010492
[Epoch 106; Iter   105/  201] train: loss: 0.1238055
[Epoch 106; Iter   135/  201] train: loss: 0.0726593
[Epoch 106; Iter   165/  201] train: loss: 0.1344348
[Epoch 106; Iter   195/  201] train: loss: 0.1481470
[Epoch 106] ogbg-moltoxcast: 0.664110 val loss: 0.287004
[Epoch 106] ogbg-moltoxcast: 0.648234 test loss: 0.331640
[Epoch 107; Iter    24/  201] train: loss: 0.0856344
[Epoch 107; Iter    54/  201] train: loss: 0.1216222
[Epoch 107; Iter    84/  201] train: loss: 0.1268404
[Epoch 107; Iter   114/  201] train: loss: 0.1403184
[Epoch 107; Iter   144/  201] train: loss: 0.1379981
[Epoch 107; Iter   174/  201] train: loss: 0.1318755
[Epoch 107] ogbg-moltoxcast: 0.670293 val loss: 0.285416
[Epoch 107] ogbg-moltoxcast: 0.652533 test loss: 0.332001
[Epoch 108; Iter     3/  201] train: loss: 0.1085714
[Epoch 108; Iter    33/  201] train: loss: 0.1211792
[Epoch 108; Iter    63/  201] train: loss: 0.1283071
[Epoch 108; Iter    93/  201] train: loss: 0.1391630
[Epoch 108; Iter   123/  201] train: loss: 0.1837226
[Epoch 108; Iter   153/  201] train: loss: 0.1858424
[Epoch 108; Iter   183/  201] train: loss: 0.1167157
[Epoch 108] ogbg-moltoxcast: 0.671046 val loss: 0.285132
[Epoch 108] ogbg-moltoxcast: 0.656218 test loss: 0.329375
[Epoch 109; Iter    12/  201] train: loss: 0.1307056
[Epoch 109; Iter    42/  201] train: loss: 0.1048576
[Epoch 109; Iter    72/  201] train: loss: 0.1210286
[Epoch 109; Iter   102/  201] train: loss: 0.1279675
[Epoch 109; Iter   132/  201] train: loss: 0.1126445
[Epoch 109; Iter   162/  201] train: loss: 0.1438904
[Epoch 109; Iter   192/  201] train: loss: 0.1047106
[Epoch 109] ogbg-moltoxcast: 0.673134 val loss: 0.279515
[Epoch 109] ogbg-moltoxcast: 0.654743 test loss: 0.325661
[Epoch 110; Iter    21/  201] train: loss: 0.1788602
[Epoch 110; Iter    51/  201] train: loss: 0.0931401
[Epoch 110; Iter    81/  201] train: loss: 0.1395082
[Epoch 110; Iter   111/  201] train: loss: 0.1704147
[Epoch 110; Iter   141/  201] train: loss: 0.1020396
[Epoch 110; Iter   171/  201] train: loss: 0.1509923
[Epoch 110; Iter   201/  201] train: loss: 0.1185142
[Epoch 110] ogbg-moltoxcast: 0.671532 val loss: 0.281807
[Epoch 110] ogbg-moltoxcast: 0.653442 test loss: 0.325685
[Epoch 111; Iter    30/  201] train: loss: 0.1233844
[Epoch 111; Iter    60/  201] train: loss: 0.1113100
[Epoch 111; Iter    90/  201] train: loss: 0.1221284
[Epoch 111; Iter   120/  201] train: loss: 0.0974716
[Epoch 111; Iter   150/  201] train: loss: 0.0736591
[Epoch 111; Iter   180/  201] train: loss: 0.1059060
[Epoch 111] ogbg-moltoxcast: 0.666191 val loss: 0.286991
[Epoch 111] ogbg-moltoxcast: 0.650335 test loss: 0.333253
[Epoch 112; Iter     9/  201] train: loss: 0.1152926
[Epoch 112; Iter    39/  201] train: loss: 0.1271341
[Epoch 112; Iter    69/  201] train: loss: 0.1270831
[Epoch 112; Iter    99/  201] train: loss: 0.1344045
[Epoch 112; Iter   129/  201] train: loss: 0.1188987
[Epoch 112; Iter   159/  201] train: loss: 0.1471928
[Epoch 112; Iter   189/  201] train: loss: 0.0836073
[Epoch 112] ogbg-moltoxcast: 0.664773 val loss: 0.298066
[Epoch 112] ogbg-moltoxcast: 0.656592 test loss: 0.344991
[Epoch 113; Iter    18/  201] train: loss: 0.0996288
[Epoch 113; Iter    48/  201] train: loss: 0.1126450
[Epoch 113; Iter    78/  201] train: loss: 0.1559558
[Epoch 113; Iter   108/  201] train: loss: 0.1697713
[Epoch 113; Iter   138/  201] train: loss: 0.1183954
[Epoch 113; Iter   168/  201] train: loss: 0.0831800
[Epoch 113; Iter   198/  201] train: loss: 0.1203921
[Epoch 113] ogbg-moltoxcast: 0.672842 val loss: 0.283562
[Epoch 113] ogbg-moltoxcast: 0.653155 test loss: 0.326727
[Epoch 114; Iter    27/  201] train: loss: 0.1246159
[Epoch 114; Iter    57/  201] train: loss: 0.1240891
[Epoch 114; Iter    87/  201] train: loss: 0.1099010
[Epoch 114; Iter   117/  201] train: loss: 0.1542359
[Epoch 114; Iter   147/  201] train: loss: 0.1067638
[Epoch 114; Iter   177/  201] train: loss: 0.1135321
[Epoch 114] ogbg-moltoxcast: 0.671135 val loss: 0.285942
[Epoch 114] ogbg-moltoxcast: 0.652510 test loss: 0.333507
[Epoch 115; Iter     6/  201] train: loss: 0.0992846
[Epoch 115; Iter    36/  201] train: loss: 0.1852050
[Epoch 115; Iter    66/  201] train: loss: 0.1504268
[Epoch 115; Iter    96/  201] train: loss: 0.1043995
[Epoch 115; Iter   126/  201] train: loss: 0.1551022
[Epoch 115; Iter   156/  201] train: loss: 0.1110633
[Epoch 115; Iter   186/  201] train: loss: 0.1134926
[Epoch 115] ogbg-moltoxcast: 0.668641 val loss: 0.286993
[Epoch 115] ogbg-moltoxcast: 0.651578 test loss: 0.333976
[Epoch 116; Iter    15/  201] train: loss: 0.0852759
[Epoch 116; Iter    45/  201] train: loss: 0.1021840
[Epoch 116; Iter    75/  201] train: loss: 0.1099127
[Epoch 116; Iter   105/  201] train: loss: 0.1051046
[Epoch 116; Iter   135/  201] train: loss: 0.0968158
[Epoch 116; Iter   165/  201] train: loss: 0.1225640
[Epoch 116; Iter   195/  201] train: loss: 0.1687785
[Epoch 116] ogbg-moltoxcast: 0.666311 val loss: 0.290096
[Epoch 116] ogbg-moltoxcast: 0.651730 test loss: 0.336346
[Epoch 117; Iter    24/  201] train: loss: 0.1407286
[Epoch 117; Iter    54/  201] train: loss: 0.1320067
[Epoch 117; Iter    84/  201] train: loss: 0.0762376
[Epoch 117; Iter   114/  201] train: loss: 0.1208315
[Epoch 117; Iter   144/  201] train: loss: 0.1467908
[Epoch 117; Iter   174/  201] train: loss: 0.0902299
[Epoch 117] ogbg-moltoxcast: 0.666962 val loss: 0.287129
[Epoch 117] ogbg-moltoxcast: 0.650598 test loss: 0.332949
[Epoch 118; Iter     3/  201] train: loss: 0.1106816
[Epoch 118; Iter    33/  201] train: loss: 0.1520221
[Epoch 118; Iter    63/  201] train: loss: 0.1080294
[Epoch 118; Iter    93/  201] train: loss: 0.1078001
[Epoch 118; Iter   123/  201] train: loss: 0.1378047
[Epoch 118; Iter   153/  201] train: loss: 0.1132745
[Epoch 118; Iter   183/  201] train: loss: 0.2003869
[Epoch 118] ogbg-moltoxcast: 0.666683 val loss: 0.285756
[Epoch 118] ogbg-moltoxcast: 0.649355 test loss: 0.332306
[Epoch 119; Iter    12/  201] train: loss: 0.1483056
[Epoch 101] ogbg-moltoxcast: 0.676541 val loss: 0.272134
[Epoch 101] ogbg-moltoxcast: 0.647162 test loss: 0.329438
[Epoch 102; Iter     9/  201] train: loss: 0.1213021
[Epoch 102; Iter    39/  201] train: loss: 0.1204897
[Epoch 102; Iter    69/  201] train: loss: 0.0756416
[Epoch 102; Iter    99/  201] train: loss: 0.1478159
[Epoch 102; Iter   129/  201] train: loss: 0.1227973
[Epoch 102; Iter   159/  201] train: loss: 0.1293011
[Epoch 102; Iter   189/  201] train: loss: 0.1288472
[Epoch 102] ogbg-moltoxcast: 0.678369 val loss: 0.277132
[Epoch 102] ogbg-moltoxcast: 0.651069 test loss: 0.335369
[Epoch 103; Iter    18/  201] train: loss: 0.0832834
[Epoch 103; Iter    48/  201] train: loss: 0.1226442
[Epoch 103; Iter    78/  201] train: loss: 0.0896924
[Epoch 103; Iter   108/  201] train: loss: 0.1570624
[Epoch 103; Iter   138/  201] train: loss: 0.1174685
[Epoch 103; Iter   168/  201] train: loss: 0.1467871
[Epoch 103; Iter   198/  201] train: loss: 0.1486906
[Epoch 103] ogbg-moltoxcast: 0.675079 val loss: 0.279470
[Epoch 103] ogbg-moltoxcast: 0.651715 test loss: 0.331985
[Epoch 104; Iter    27/  201] train: loss: 0.1228829
[Epoch 104; Iter    57/  201] train: loss: 0.1445523
[Epoch 104; Iter    87/  201] train: loss: 0.1253850
[Epoch 104; Iter   117/  201] train: loss: 0.0978705
[Epoch 104; Iter   147/  201] train: loss: 0.1617652
[Epoch 104; Iter   177/  201] train: loss: 0.1210414
[Epoch 104] ogbg-moltoxcast: 0.673829 val loss: 0.284582
[Epoch 104] ogbg-moltoxcast: 0.652864 test loss: 0.335476
[Epoch 105; Iter     6/  201] train: loss: 0.1156726
[Epoch 105; Iter    36/  201] train: loss: 0.1080276
[Epoch 105; Iter    66/  201] train: loss: 0.1014088
[Epoch 105; Iter    96/  201] train: loss: 0.1001792
[Epoch 105; Iter   126/  201] train: loss: 0.1548236
[Epoch 105; Iter   156/  201] train: loss: 0.0667690
[Epoch 105; Iter   186/  201] train: loss: 0.1563595
[Epoch 105] ogbg-moltoxcast: 0.673872 val loss: 0.280217
[Epoch 105] ogbg-moltoxcast: 0.648638 test loss: 0.335394
[Epoch 106; Iter    15/  201] train: loss: 0.1483050
[Epoch 106; Iter    45/  201] train: loss: 0.0880153
[Epoch 106; Iter    75/  201] train: loss: 0.1038017
[Epoch 106; Iter   105/  201] train: loss: 0.1277677
[Epoch 106; Iter   135/  201] train: loss: 0.1239426
[Epoch 106; Iter   165/  201] train: loss: 0.1147389
[Epoch 106; Iter   195/  201] train: loss: 0.1458599
[Epoch 106] ogbg-moltoxcast: 0.673054 val loss: 0.283946
[Epoch 106] ogbg-moltoxcast: 0.648534 test loss: 0.339105
[Epoch 107; Iter    24/  201] train: loss: 0.0758525
[Epoch 107; Iter    54/  201] train: loss: 0.1135901
[Epoch 107; Iter    84/  201] train: loss: 0.1247622
[Epoch 107; Iter   114/  201] train: loss: 0.1707518
[Epoch 107; Iter   144/  201] train: loss: 0.1317683
[Epoch 107; Iter   174/  201] train: loss: 0.1242233
[Epoch 107] ogbg-moltoxcast: 0.679939 val loss: 0.274515
[Epoch 107] ogbg-moltoxcast: 0.652992 test loss: 0.331091
[Epoch 108; Iter     3/  201] train: loss: 0.0731026
[Epoch 108; Iter    33/  201] train: loss: 0.1226166
[Epoch 108; Iter    63/  201] train: loss: 0.1065636
[Epoch 108; Iter    93/  201] train: loss: 0.1095680
[Epoch 108; Iter   123/  201] train: loss: 0.0797768
[Epoch 108; Iter   153/  201] train: loss: 0.0927962
[Epoch 108; Iter   183/  201] train: loss: 0.1206828
[Epoch 108] ogbg-moltoxcast: 0.676213 val loss: 0.273917
[Epoch 108] ogbg-moltoxcast: 0.652302 test loss: 0.331133
[Epoch 109; Iter    12/  201] train: loss: 0.1130842
[Epoch 109; Iter    42/  201] train: loss: 0.1326340
[Epoch 109; Iter    72/  201] train: loss: 0.1226097
[Epoch 109; Iter   102/  201] train: loss: 0.0887739
[Epoch 109; Iter   132/  201] train: loss: 0.1005042
[Epoch 109; Iter   162/  201] train: loss: 0.1042640
[Epoch 109; Iter   192/  201] train: loss: 0.1138844
[Epoch 109] ogbg-moltoxcast: 0.671526 val loss: 0.287288
[Epoch 109] ogbg-moltoxcast: 0.649287 test loss: 0.344568
[Epoch 110; Iter    21/  201] train: loss: 0.1084505
[Epoch 110; Iter    51/  201] train: loss: 0.1175469
[Epoch 110; Iter    81/  201] train: loss: 0.1517128
[Epoch 110; Iter   111/  201] train: loss: 0.1149021
[Epoch 110; Iter   141/  201] train: loss: 0.1036366
[Epoch 110; Iter   171/  201] train: loss: 0.1246695
[Epoch 110; Iter   201/  201] train: loss: 0.3061703
[Epoch 110] ogbg-moltoxcast: 0.671981 val loss: 0.280257
[Epoch 110] ogbg-moltoxcast: 0.648692 test loss: 0.337058
[Epoch 111; Iter    30/  201] train: loss: 0.1051390
[Epoch 111; Iter    60/  201] train: loss: 0.0973076
[Epoch 111; Iter    90/  201] train: loss: 0.1304223
[Epoch 111; Iter   120/  201] train: loss: 0.1200731
[Epoch 111; Iter   150/  201] train: loss: 0.1133219
[Epoch 111; Iter   180/  201] train: loss: 0.0897036
[Epoch 111] ogbg-moltoxcast: 0.673055 val loss: 0.278810
[Epoch 111] ogbg-moltoxcast: 0.646880 test loss: 0.336146
[Epoch 112; Iter     9/  201] train: loss: 0.1141841
[Epoch 112; Iter    39/  201] train: loss: 0.1400331
[Epoch 112; Iter    69/  201] train: loss: 0.1118626
[Epoch 112; Iter    99/  201] train: loss: 0.0939381
[Epoch 112; Iter   129/  201] train: loss: 0.0849358
[Epoch 112; Iter   159/  201] train: loss: 0.1620384
[Epoch 112; Iter   189/  201] train: loss: 0.1283888
[Epoch 112] ogbg-moltoxcast: 0.672455 val loss: 0.279760
[Epoch 112] ogbg-moltoxcast: 0.645574 test loss: 0.336843
[Epoch 113; Iter    18/  201] train: loss: 0.1002625
[Epoch 113; Iter    48/  201] train: loss: 0.1002955
[Epoch 113; Iter    78/  201] train: loss: 0.1559920
[Epoch 113; Iter   108/  201] train: loss: 0.1331898
[Epoch 113; Iter   138/  201] train: loss: 0.1149106
[Epoch 113; Iter   168/  201] train: loss: 0.1389643
[Epoch 113; Iter   198/  201] train: loss: 0.1478007
[Epoch 113] ogbg-moltoxcast: 0.675802 val loss: 0.279268
[Epoch 113] ogbg-moltoxcast: 0.649014 test loss: 0.336898
[Epoch 114; Iter    27/  201] train: loss: 0.1483066
[Epoch 114; Iter    57/  201] train: loss: 0.1354425
[Epoch 114; Iter    87/  201] train: loss: 0.1131271
[Epoch 114; Iter   117/  201] train: loss: 0.1270444
[Epoch 114; Iter   147/  201] train: loss: 0.0839858
[Epoch 114; Iter   177/  201] train: loss: 0.1432219
[Epoch 114] ogbg-moltoxcast: 0.672548 val loss: 0.279501
[Epoch 114] ogbg-moltoxcast: 0.648105 test loss: 0.339026
[Epoch 115; Iter     6/  201] train: loss: 0.1148555
[Epoch 115; Iter    36/  201] train: loss: 0.1543196
[Epoch 115; Iter    66/  201] train: loss: 0.1135993
[Epoch 115; Iter    96/  201] train: loss: 0.1367147
[Epoch 115; Iter   126/  201] train: loss: 0.1866888
[Epoch 115; Iter   156/  201] train: loss: 0.0871540
[Epoch 115; Iter   186/  201] train: loss: 0.0904239
[Epoch 115] ogbg-moltoxcast: 0.675042 val loss: 0.282624
[Epoch 115] ogbg-moltoxcast: 0.652578 test loss: 0.338240
[Epoch 116; Iter    15/  201] train: loss: 0.1304548
[Epoch 116; Iter    45/  201] train: loss: 0.1006185
[Epoch 116; Iter    75/  201] train: loss: 0.0647255
[Epoch 116; Iter   105/  201] train: loss: 0.1119561
[Epoch 116; Iter   135/  201] train: loss: 0.1181777
[Epoch 116; Iter   165/  201] train: loss: 0.0809142
[Epoch 116; Iter   195/  201] train: loss: 0.1156486
[Epoch 116] ogbg-moltoxcast: 0.672683 val loss: 0.281213
[Epoch 116] ogbg-moltoxcast: 0.646219 test loss: 0.342096
[Epoch 117; Iter    24/  201] train: loss: 0.1260961
[Epoch 117; Iter    54/  201] train: loss: 0.1257378
[Epoch 117; Iter    84/  201] train: loss: 0.1813009
[Epoch 117; Iter   114/  201] train: loss: 0.1427942
[Epoch 117; Iter   144/  201] train: loss: 0.0813148
[Epoch 117; Iter   174/  201] train: loss: 0.1331959
[Epoch 117] ogbg-moltoxcast: 0.673089 val loss: 0.278513
[Epoch 117] ogbg-moltoxcast: 0.651693 test loss: 0.334461
[Epoch 118; Iter     3/  201] train: loss: 0.1056488
[Epoch 118; Iter    33/  201] train: loss: 0.1182696
[Epoch 118; Iter    63/  201] train: loss: 0.1060105
[Epoch 118; Iter    93/  201] train: loss: 0.0992778
[Epoch 118; Iter   123/  201] train: loss: 0.1448043
[Epoch 118; Iter   153/  201] train: loss: 0.1225043
[Epoch 118; Iter   183/  201] train: loss: 0.1158841
[Epoch 118] ogbg-moltoxcast: 0.674284 val loss: 0.278210
[Epoch 118] ogbg-moltoxcast: 0.649597 test loss: 0.335493
[Epoch 119; Iter    12/  201] train: loss: 0.1201005
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.1559696
[Epoch 119; Iter    72/  201] train: loss: 0.1440161
[Epoch 119; Iter   102/  201] train: loss: 0.2191351
[Epoch 119; Iter   132/  201] train: loss: 0.1627107
[Epoch 119; Iter   162/  201] train: loss: 0.1356807
[Epoch 119; Iter   192/  201] train: loss: 0.0965474
[Epoch 119] ogbg-moltoxcast: 0.664182 val loss: 0.290864
[Epoch 119] ogbg-moltoxcast: 0.653132 test loss: 0.331999
[Epoch 120; Iter    21/  201] train: loss: 0.1915116
[Epoch 120; Iter    51/  201] train: loss: 0.0992064
[Epoch 120; Iter    81/  201] train: loss: 0.1066396
[Epoch 120; Iter   111/  201] train: loss: 0.1165571
[Epoch 120; Iter   141/  201] train: loss: 0.0927590
[Epoch 120; Iter   171/  201] train: loss: 0.0893404
[Epoch 120; Iter   201/  201] train: loss: 0.1141085
[Epoch 120] ogbg-moltoxcast: 0.656788 val loss: 0.298602
[Epoch 120] ogbg-moltoxcast: 0.649642 test loss: 0.341479
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 19.
Statistics on  val_best_checkpoint
mean_pred: -1.8945326805114746
std_pred: 2.23121976852417
mean_targets: nan
std_targets: nan
prcauc: 0.3639733324783532
rocauc: 0.6799659482637843
ogbg-moltoxcast: 0.6799659482637843
OGBNanLabelBCEWithLogitsLoss: 0.27193898690301316
Statistics on  test
mean_pred: -1.6675180196762085
std_pred: 2.2804784774780273
mean_targets: nan
std_targets: nan
prcauc: 0.33339516909067185
rocauc: 0.6577055871244496
ogbg-moltoxcast: 0.6577055871244496
OGBNanLabelBCEWithLogitsLoss: 0.3236808811509332
Statistics on  train
mean_pred: -2.5289058685302734
std_pred: 3.1672351360321045
mean_targets: nan
std_targets: nan
prcauc: 0.4575572449532139
rocauc: 0.8160579062509707
ogbg-moltoxcast: 0.8160579062509707
OGBNanLabelBCEWithLogitsLoss: 0.1699443942871853
[Epoch 119; Iter    42/  201] train: loss: 0.1085383
[Epoch 119; Iter    72/  201] train: loss: 0.1084432
[Epoch 119; Iter   102/  201] train: loss: 0.1096058
[Epoch 119; Iter   132/  201] train: loss: 0.0763691
[Epoch 119; Iter   162/  201] train: loss: 0.1443084
[Epoch 119; Iter   192/  201] train: loss: 0.1021160
[Epoch 119] ogbg-moltoxcast: 0.671802 val loss: 0.286168
[Epoch 119] ogbg-moltoxcast: 0.651920 test loss: 0.332355
[Epoch 120; Iter    21/  201] train: loss: 0.0964129
[Epoch 120; Iter    51/  201] train: loss: 0.1344339
[Epoch 120; Iter    81/  201] train: loss: 0.0869427
[Epoch 120; Iter   111/  201] train: loss: 0.1080319
[Epoch 120; Iter   141/  201] train: loss: 0.1190411
[Epoch 120; Iter   171/  201] train: loss: 0.1211514
[Epoch 120; Iter   201/  201] train: loss: 0.0606610
[Epoch 120] ogbg-moltoxcast: 0.667161 val loss: 0.283289
[Epoch 120] ogbg-moltoxcast: 0.648579 test loss: 0.329568
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 53.
Statistics on  val_best_checkpoint
mean_pred: -2.751495361328125
std_pred: 2.7598912715911865
mean_targets: nan
std_targets: nan
prcauc: 0.38052215098231773
rocauc: 0.6888815748983486
ogbg-moltoxcast: 0.6888815748983486
OGBNanLabelBCEWithLogitsLoss: 0.2691477450520493
Statistics on  test
mean_pred: -2.508760929107666
std_pred: 2.794762372970581
mean_targets: nan
std_targets: nan
prcauc: 0.34989388666015103
rocauc: 0.6648429710593132
ogbg-moltoxcast: 0.6648429710593132
OGBNanLabelBCEWithLogitsLoss: 0.31312861380188967
Statistics on  train
mean_pred: -3.303194761276245
std_pred: 2.832570791244507
mean_targets: nan
std_targets: nan
prcauc: 0.5774466787748134
rocauc: 0.8816789591352016
ogbg-moltoxcast: 0.8816789591352016
OGBNanLabelBCEWithLogitsLoss: 0.13470998172884557
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.1471581
[Epoch 119; Iter    72/  201] train: loss: 0.1232058
[Epoch 119; Iter   102/  201] train: loss: 0.1363855
[Epoch 119; Iter   132/  201] train: loss: 0.0862893
[Epoch 119; Iter   162/  201] train: loss: 0.1280661
[Epoch 119; Iter   192/  201] train: loss: 0.1142544
[Epoch 119] ogbg-moltoxcast: 0.673085 val loss: 0.290496
[Epoch 119] ogbg-moltoxcast: 0.650192 test loss: 0.348570
[Epoch 120; Iter    21/  201] train: loss: 0.1586721
[Epoch 120; Iter    51/  201] train: loss: 0.0713029
[Epoch 120; Iter    81/  201] train: loss: 0.1173781
[Epoch 120; Iter   111/  201] train: loss: 0.1011339
[Epoch 120; Iter   141/  201] train: loss: 0.0931612
[Epoch 120; Iter   171/  201] train: loss: 0.1004903
[Epoch 120; Iter   201/  201] train: loss: 0.0303352
[Epoch 120] ogbg-moltoxcast: 0.671681 val loss: 0.278334
[Epoch 120] ogbg-moltoxcast: 0.645003 test loss: 0.337139
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 34.
Statistics on  val_best_checkpoint
mean_pred: -2.3178045749664307
std_pred: 2.36095929145813
mean_targets: nan
std_targets: nan
prcauc: 0.3742952364828121
rocauc: 0.696955665956611
ogbg-moltoxcast: 0.696955665956611
OGBNanLabelBCEWithLogitsLoss: 0.24886907533157704
Statistics on  test
mean_pred: -2.105170726776123
std_pred: 2.394437313079834
mean_targets: nan
std_targets: nan
prcauc: 0.34685573865146496
rocauc: 0.6727591177570289
ogbg-moltoxcast: 0.6727591177570289
OGBNanLabelBCEWithLogitsLoss: 0.2875212704719499
Statistics on  train
mean_pred: -3.033273935317993
std_pred: 2.7362051010131836
mean_targets: nan
std_targets: nan
prcauc: 0.523882214895298
rocauc: 0.857286094435547
ogbg-moltoxcast: 0.857286094435547
OGBNanLabelBCEWithLogitsLoss: 0.16031787366564595
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.644842 test loss: 0.331965
[Epoch 108; Iter     7/  229] train: loss: 0.1060706
[Epoch 108; Iter    37/  229] train: loss: 0.1850419
[Epoch 108; Iter    67/  229] train: loss: 0.1180436
[Epoch 108; Iter    97/  229] train: loss: 0.1614865
[Epoch 108; Iter   127/  229] train: loss: 0.1329097
[Epoch 108; Iter   157/  229] train: loss: 0.1303495
[Epoch 108; Iter   187/  229] train: loss: 0.1263914
[Epoch 108; Iter   217/  229] train: loss: 0.1121814
[Epoch 108] ogbg-moltoxcast: 0.683138 val loss: 0.273232
[Epoch 108] ogbg-moltoxcast: 0.645547 test loss: 0.335132
[Epoch 109; Iter    18/  229] train: loss: 0.1021111
[Epoch 109; Iter    48/  229] train: loss: 0.1247959
[Epoch 109; Iter    78/  229] train: loss: 0.0968249
[Epoch 109; Iter   108/  229] train: loss: 0.1163449
[Epoch 109; Iter   138/  229] train: loss: 0.0838683
[Epoch 109; Iter   168/  229] train: loss: 0.1329962
[Epoch 109; Iter   198/  229] train: loss: 0.1213929
[Epoch 109; Iter   228/  229] train: loss: 0.1328222
[Epoch 109] ogbg-moltoxcast: 0.674509 val loss: 0.270826
[Epoch 109] ogbg-moltoxcast: 0.646577 test loss: 0.331831
[Epoch 110; Iter    29/  229] train: loss: 0.1263885
[Epoch 110; Iter    59/  229] train: loss: 0.1340405
[Epoch 110; Iter    89/  229] train: loss: 0.1412487
[Epoch 110; Iter   119/  229] train: loss: 0.1734269
[Epoch 110; Iter   149/  229] train: loss: 0.1560347
[Epoch 110; Iter   179/  229] train: loss: 0.1513281
[Epoch 110; Iter   209/  229] train: loss: 0.0988901
[Epoch 110] ogbg-moltoxcast: 0.676409 val loss: 0.271543
[Epoch 110] ogbg-moltoxcast: 0.644407 test loss: 0.335505
[Epoch 111; Iter    10/  229] train: loss: 0.0898684
[Epoch 111; Iter    40/  229] train: loss: 0.1264901
[Epoch 111; Iter    70/  229] train: loss: 0.1447038
[Epoch 111; Iter   100/  229] train: loss: 0.1168144
[Epoch 111; Iter   130/  229] train: loss: 0.1370777
[Epoch 111; Iter   160/  229] train: loss: 0.1734084
[Epoch 111; Iter   190/  229] train: loss: 0.0964749
[Epoch 111; Iter   220/  229] train: loss: 0.1253756
[Epoch 111] ogbg-moltoxcast: 0.676980 val loss: 0.271844
[Epoch 111] ogbg-moltoxcast: 0.644985 test loss: 0.336339
[Epoch 112; Iter    21/  229] train: loss: 0.1103404
[Epoch 112; Iter    51/  229] train: loss: 0.1312860
[Epoch 112; Iter    81/  229] train: loss: 0.0806447
[Epoch 112; Iter   111/  229] train: loss: 0.1085491
[Epoch 112; Iter   141/  229] train: loss: 0.1137742
[Epoch 112; Iter   171/  229] train: loss: 0.1189720
[Epoch 112; Iter   201/  229] train: loss: 0.0913980
[Epoch 112] ogbg-moltoxcast: 0.677250 val loss: 0.271182
[Epoch 112] ogbg-moltoxcast: 0.643003 test loss: 0.337530
[Epoch 113; Iter     2/  229] train: loss: 0.1500899
[Epoch 113; Iter    32/  229] train: loss: 0.1485034
[Epoch 113; Iter    62/  229] train: loss: 0.1381436
[Epoch 113; Iter    92/  229] train: loss: 0.1497844
[Epoch 113; Iter   122/  229] train: loss: 0.1662286
[Epoch 113; Iter   152/  229] train: loss: 0.1187786
[Epoch 113; Iter   182/  229] train: loss: 0.1192420
[Epoch 113; Iter   212/  229] train: loss: 0.1050226
[Epoch 113] ogbg-moltoxcast: 0.680231 val loss: 0.276509
[Epoch 113] ogbg-moltoxcast: 0.644198 test loss: 0.340554
[Epoch 114; Iter    13/  229] train: loss: 0.0778209
[Epoch 114; Iter    43/  229] train: loss: 0.1324259
[Epoch 114; Iter    73/  229] train: loss: 0.1175748
[Epoch 114; Iter   103/  229] train: loss: 0.1438984
[Epoch 114; Iter   133/  229] train: loss: 0.1289580
[Epoch 114; Iter   163/  229] train: loss: 0.0903715
[Epoch 114; Iter   193/  229] train: loss: 0.1349676
[Epoch 114; Iter   223/  229] train: loss: 0.0859039
[Epoch 114] ogbg-moltoxcast: 0.675644 val loss: 0.272672
[Epoch 114] ogbg-moltoxcast: 0.645127 test loss: 0.338002
[Epoch 115; Iter    24/  229] train: loss: 0.0899402
[Epoch 115; Iter    54/  229] train: loss: 0.1327222
[Epoch 115; Iter    84/  229] train: loss: 0.1256109
[Epoch 115; Iter   114/  229] train: loss: 0.0778927
[Epoch 115; Iter   144/  229] train: loss: 0.0737963
[Epoch 115; Iter   174/  229] train: loss: 0.1467011
[Epoch 115; Iter   204/  229] train: loss: 0.1463928
[Epoch 115] ogbg-moltoxcast: 0.679847 val loss: 0.273731
[Epoch 115] ogbg-moltoxcast: 0.645336 test loss: 0.339688
[Epoch 116; Iter     5/  229] train: loss: 0.1376811
[Epoch 116; Iter    35/  229] train: loss: 0.1241938
[Epoch 116; Iter    65/  229] train: loss: 0.1092238
[Epoch 116; Iter    95/  229] train: loss: 0.1583974
[Epoch 116; Iter   125/  229] train: loss: 0.0890216
[Epoch 116; Iter   155/  229] train: loss: 0.1615390
[Epoch 116; Iter   185/  229] train: loss: 0.1017646
[Epoch 116; Iter   215/  229] train: loss: 0.1435822
[Epoch 116] ogbg-moltoxcast: 0.681907 val loss: 0.273214
[Epoch 116] ogbg-moltoxcast: 0.646072 test loss: 0.337981
[Epoch 117; Iter    16/  229] train: loss: 0.1040751
[Epoch 117; Iter    46/  229] train: loss: 0.0885497
[Epoch 117; Iter    76/  229] train: loss: 0.1007928
[Epoch 117; Iter   106/  229] train: loss: 0.1111341
[Epoch 117; Iter   136/  229] train: loss: 0.1515785
[Epoch 117; Iter   166/  229] train: loss: 0.1271232
[Epoch 117; Iter   196/  229] train: loss: 0.1449901
[Epoch 117; Iter   226/  229] train: loss: 0.1281128
[Epoch 117] ogbg-moltoxcast: 0.679709 val loss: 0.271721
[Epoch 117] ogbg-moltoxcast: 0.642895 test loss: 0.339169
[Epoch 118; Iter    27/  229] train: loss: 0.0927224
[Epoch 118; Iter    57/  229] train: loss: 0.1061606
[Epoch 118; Iter    87/  229] train: loss: 0.1299984
[Epoch 118; Iter   117/  229] train: loss: 0.1135403
[Epoch 118; Iter   147/  229] train: loss: 0.1243116
[Epoch 118; Iter   177/  229] train: loss: 0.1401345
[Epoch 118; Iter   207/  229] train: loss: 0.1046793
[Epoch 118] ogbg-moltoxcast: 0.677210 val loss: 0.274153
[Epoch 118] ogbg-moltoxcast: 0.643865 test loss: 0.339127
[Epoch 119; Iter     8/  229] train: loss: 0.1114368
[Epoch 119; Iter    38/  229] train: loss: 0.0917724
[Epoch 119; Iter    68/  229] train: loss: 0.1045437
[Epoch 119; Iter    98/  229] train: loss: 0.1152090
[Epoch 119; Iter   128/  229] train: loss: 0.1242362
[Epoch 119; Iter   158/  229] train: loss: 0.1436417
[Epoch 119; Iter   188/  229] train: loss: 0.1250473
[Epoch 119; Iter   218/  229] train: loss: 0.0736720
[Epoch 119] ogbg-moltoxcast: 0.679298 val loss: 0.273273
[Epoch 119] ogbg-moltoxcast: 0.642888 test loss: 0.339152
[Epoch 120; Iter    19/  229] train: loss: 0.1068746
[Epoch 120; Iter    49/  229] train: loss: 0.1076375
[Epoch 120; Iter    79/  229] train: loss: 0.1120271
[Epoch 120; Iter   109/  229] train: loss: 0.1895944
[Epoch 120; Iter   139/  229] train: loss: 0.1062229
[Epoch 120; Iter   169/  229] train: loss: 0.0966325
[Epoch 120; Iter   199/  229] train: loss: 0.0735734
[Epoch 120; Iter   229/  229] train: loss: 0.1269138
[Epoch 120] ogbg-moltoxcast: 0.678347 val loss: 0.271371
[Epoch 120] ogbg-moltoxcast: 0.643385 test loss: 0.338633
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 39.
Statistics on  val_best_checkpoint
mean_pred: -2.7057738304138184
std_pred: 2.4366655349731445
mean_targets: nan
std_targets: nan
prcauc: 0.4020098054783008
rocauc: 0.6938697926005558
ogbg-moltoxcast: 0.6938697926005558
OGBNanLabelBCEWithLogitsLoss: 0.2452512907570806
Statistics on  test
mean_pred: -2.4590647220611572
std_pred: 2.3936421871185303
mean_targets: nan
std_targets: nan
prcauc: 0.36826983193419177
rocauc: 0.6622965943820497
ogbg-moltoxcast: 0.6622965943820497
OGBNanLabelBCEWithLogitsLoss: 0.29092896447099487
Statistics on  train
mean_pred: -3.162705898284912
std_pred: 2.402132749557495
mean_targets: nan
std_targets: nan
prcauc: 0.55483341920846
rocauc: 0.8663463147529218
ogbg-moltoxcast: 0.8663463147529218
OGBNanLabelBCEWithLogitsLoss: 0.1459105522351494
[Epoch 107] ogbg-moltoxcast: 0.653205 test loss: 0.339651
[Epoch 108; Iter     7/  229] train: loss: 0.1362269
[Epoch 108; Iter    37/  229] train: loss: 0.1692741
[Epoch 108; Iter    67/  229] train: loss: 0.1312223
[Epoch 108; Iter    97/  229] train: loss: 0.0922830
[Epoch 108; Iter   127/  229] train: loss: 0.1157352
[Epoch 108; Iter   157/  229] train: loss: 0.1056473
[Epoch 108; Iter   187/  229] train: loss: 0.1274070
[Epoch 108; Iter   217/  229] train: loss: 0.1237063
[Epoch 108] ogbg-moltoxcast: 0.697707 val loss: 0.265995
[Epoch 108] ogbg-moltoxcast: 0.649822 test loss: 0.337841
[Epoch 109; Iter    18/  229] train: loss: 0.1250589
[Epoch 109; Iter    48/  229] train: loss: 0.1294975
[Epoch 109; Iter    78/  229] train: loss: 0.0830490
[Epoch 109; Iter   108/  229] train: loss: 0.1825874
[Epoch 109; Iter   138/  229] train: loss: 0.1843050
[Epoch 109; Iter   168/  229] train: loss: 0.1785925
[Epoch 109; Iter   198/  229] train: loss: 0.1106875
[Epoch 109; Iter   228/  229] train: loss: 0.1687803
[Epoch 109] ogbg-moltoxcast: 0.698991 val loss: 0.266644
[Epoch 109] ogbg-moltoxcast: 0.649101 test loss: 0.345472
[Epoch 110; Iter    29/  229] train: loss: 0.1162004
[Epoch 110; Iter    59/  229] train: loss: 0.1222666
[Epoch 110; Iter    89/  229] train: loss: 0.1879136
[Epoch 110; Iter   119/  229] train: loss: 0.1876076
[Epoch 110; Iter   149/  229] train: loss: 0.1251141
[Epoch 110; Iter   179/  229] train: loss: 0.1588785
[Epoch 110; Iter   209/  229] train: loss: 0.1042257
[Epoch 110] ogbg-moltoxcast: 0.702543 val loss: 0.264910
[Epoch 110] ogbg-moltoxcast: 0.650305 test loss: 0.342513
[Epoch 111; Iter    10/  229] train: loss: 0.1439061
[Epoch 111; Iter    40/  229] train: loss: 0.0938390
[Epoch 111; Iter    70/  229] train: loss: 0.0961121
[Epoch 111; Iter   100/  229] train: loss: 0.1183336
[Epoch 111; Iter   130/  229] train: loss: 0.1268781
[Epoch 111; Iter   160/  229] train: loss: 0.1280649
[Epoch 111; Iter   190/  229] train: loss: 0.1130376
[Epoch 111; Iter   220/  229] train: loss: 0.1418781
[Epoch 111] ogbg-moltoxcast: 0.697485 val loss: 0.269014
[Epoch 111] ogbg-moltoxcast: 0.648755 test loss: 0.345164
[Epoch 112; Iter    21/  229] train: loss: 0.1032806
[Epoch 112; Iter    51/  229] train: loss: 0.0937336
[Epoch 112; Iter    81/  229] train: loss: 0.1217559
[Epoch 112; Iter   111/  229] train: loss: 0.1239078
[Epoch 112; Iter   141/  229] train: loss: 0.1313616
[Epoch 112; Iter   171/  229] train: loss: 0.1038664
[Epoch 112; Iter   201/  229] train: loss: 0.1276551
[Epoch 112] ogbg-moltoxcast: 0.701515 val loss: 0.267784
[Epoch 112] ogbg-moltoxcast: 0.652706 test loss: 0.343748
[Epoch 113; Iter     2/  229] train: loss: 0.0602878
[Epoch 113; Iter    32/  229] train: loss: 0.1081497
[Epoch 113; Iter    62/  229] train: loss: 0.1314821
[Epoch 113; Iter    92/  229] train: loss: 0.1823218
[Epoch 113; Iter   122/  229] train: loss: 0.0745748
[Epoch 113; Iter   152/  229] train: loss: 0.1549773
[Epoch 113; Iter   182/  229] train: loss: 0.1030208
[Epoch 113; Iter   212/  229] train: loss: 0.1244705
[Epoch 113] ogbg-moltoxcast: 0.698221 val loss: 0.269251
[Epoch 113] ogbg-moltoxcast: 0.649070 test loss: 0.346277
[Epoch 114; Iter    13/  229] train: loss: 0.1097691
[Epoch 114; Iter    43/  229] train: loss: 0.1015043
[Epoch 114; Iter    73/  229] train: loss: 0.1141364
[Epoch 114; Iter   103/  229] train: loss: 0.0953723
[Epoch 114; Iter   133/  229] train: loss: 0.1315564
[Epoch 114; Iter   163/  229] train: loss: 0.0943159
[Epoch 114; Iter   193/  229] train: loss: 0.1149172
[Epoch 114; Iter   223/  229] train: loss: 0.0962419
[Epoch 114] ogbg-moltoxcast: 0.699284 val loss: 0.266891
[Epoch 114] ogbg-moltoxcast: 0.648499 test loss: 0.343548
[Epoch 115; Iter    24/  229] train: loss: 0.1160739
[Epoch 115; Iter    54/  229] train: loss: 0.1050304
[Epoch 115; Iter    84/  229] train: loss: 0.1562672
[Epoch 115; Iter   114/  229] train: loss: 0.1155900
[Epoch 115; Iter   144/  229] train: loss: 0.1159384
[Epoch 115; Iter   174/  229] train: loss: 0.0854741
[Epoch 115; Iter   204/  229] train: loss: 0.1421216
[Epoch 115] ogbg-moltoxcast: 0.696318 val loss: 0.267188
[Epoch 115] ogbg-moltoxcast: 0.648741 test loss: 0.343711
[Epoch 116; Iter     5/  229] train: loss: 0.1201729
[Epoch 116; Iter    35/  229] train: loss: 0.0976625
[Epoch 116; Iter    65/  229] train: loss: 0.2070557
[Epoch 116; Iter    95/  229] train: loss: 0.1132281
[Epoch 116; Iter   125/  229] train: loss: 0.1302086
[Epoch 116; Iter   155/  229] train: loss: 0.1387359
[Epoch 116; Iter   185/  229] train: loss: 0.1109364
[Epoch 116; Iter   215/  229] train: loss: 0.0978753
[Epoch 116] ogbg-moltoxcast: 0.698575 val loss: 0.269325
[Epoch 116] ogbg-moltoxcast: 0.651028 test loss: 0.340598
[Epoch 117; Iter    16/  229] train: loss: 0.1480966
[Epoch 117; Iter    46/  229] train: loss: 0.1557550
[Epoch 117; Iter    76/  229] train: loss: 0.1068913
[Epoch 117; Iter   106/  229] train: loss: 0.1508177
[Epoch 117; Iter   136/  229] train: loss: 0.0983735
[Epoch 117; Iter   166/  229] train: loss: 0.0698072
[Epoch 117; Iter   196/  229] train: loss: 0.1795204
[Epoch 117; Iter   226/  229] train: loss: 0.1012976
[Epoch 117] ogbg-moltoxcast: 0.698746 val loss: 0.271077
[Epoch 117] ogbg-moltoxcast: 0.650865 test loss: 0.346062
[Epoch 118; Iter    27/  229] train: loss: 0.0681702
[Epoch 118; Iter    57/  229] train: loss: 0.1099918
[Epoch 118; Iter    87/  229] train: loss: 0.0815185
[Epoch 118; Iter   117/  229] train: loss: 0.1356679
[Epoch 118; Iter   147/  229] train: loss: 0.1162262
[Epoch 118; Iter   177/  229] train: loss: 0.1205815
[Epoch 118; Iter   207/  229] train: loss: 0.1930025
[Epoch 118] ogbg-moltoxcast: 0.699971 val loss: 0.266669
[Epoch 118] ogbg-moltoxcast: 0.651126 test loss: 0.343341
[Epoch 119; Iter     8/  229] train: loss: 0.1410051
[Epoch 119; Iter    38/  229] train: loss: 0.0991396
[Epoch 119; Iter    68/  229] train: loss: 0.1367947
[Epoch 119; Iter    98/  229] train: loss: 0.0778540
[Epoch 119; Iter   128/  229] train: loss: 0.1161446
[Epoch 119; Iter   158/  229] train: loss: 0.1053039
[Epoch 119; Iter   188/  229] train: loss: 0.1546464
[Epoch 119; Iter   218/  229] train: loss: 0.1425093
[Epoch 119] ogbg-moltoxcast: 0.702996 val loss: 0.270162
[Epoch 119] ogbg-moltoxcast: 0.649548 test loss: 0.348951
[Epoch 120; Iter    19/  229] train: loss: 0.1198018
[Epoch 120; Iter    49/  229] train: loss: 0.1283962
[Epoch 120; Iter    79/  229] train: loss: 0.1043757
[Epoch 120; Iter   109/  229] train: loss: 0.1392220
[Epoch 120; Iter   139/  229] train: loss: 0.1385048
[Epoch 120; Iter   169/  229] train: loss: 0.1320587
[Epoch 120; Iter   199/  229] train: loss: 0.0922659
[Epoch 120; Iter   229/  229] train: loss: 0.1876520
[Epoch 120] ogbg-moltoxcast: 0.701819 val loss: 0.269781
[Epoch 120] ogbg-moltoxcast: 0.648696 test loss: 0.348066
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: -2.416414737701416
std_pred: 2.5998830795288086
mean_targets: nan
std_targets: nan
prcauc: 0.43193447007061425
rocauc: 0.7166011436399109
ogbg-moltoxcast: 0.7166011436399109
OGBNanLabelBCEWithLogitsLoss: 0.25183759218659896
Statistics on  test
mean_pred: -2.09997296333313
std_pred: 2.592548131942749
mean_targets: nan
std_targets: nan
prcauc: 0.36586217020055134
rocauc: 0.6685639728556221
ogbg-moltoxcast: 0.6685639728556221
OGBNanLabelBCEWithLogitsLoss: 0.31854702223991527
Statistics on  train
mean_pred: -3.074699878692627
std_pred: 2.600250005722046
mean_targets: nan
std_targets: nan
prcauc: 0.574371449797848
rocauc: 0.8780917907180967
ogbg-moltoxcast: 0.8780917907180967
OGBNanLabelBCEWithLogitsLoss: 0.1431685439493979
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.657176 test loss: 0.335368
[Epoch 108; Iter     7/  229] train: loss: 0.1207911
[Epoch 108; Iter    37/  229] train: loss: 0.1520306
[Epoch 108; Iter    67/  229] train: loss: 0.1201097
[Epoch 108; Iter    97/  229] train: loss: 0.1320766
[Epoch 108; Iter   127/  229] train: loss: 0.2071780
[Epoch 108; Iter   157/  229] train: loss: 0.1047032
[Epoch 108; Iter   187/  229] train: loss: 0.1069652
[Epoch 108; Iter   217/  229] train: loss: 0.0945871
[Epoch 108] ogbg-moltoxcast: 0.686271 val loss: 0.287035
[Epoch 108] ogbg-moltoxcast: 0.656057 test loss: 0.331771
[Epoch 109; Iter    18/  229] train: loss: 0.1281507
[Epoch 109; Iter    48/  229] train: loss: 0.1294060
[Epoch 109; Iter    78/  229] train: loss: 0.1220473
[Epoch 109; Iter   108/  229] train: loss: 0.1516809
[Epoch 109; Iter   138/  229] train: loss: 0.1192166
[Epoch 109; Iter   168/  229] train: loss: 0.1521774
[Epoch 109; Iter   198/  229] train: loss: 0.1217499
[Epoch 109; Iter   228/  229] train: loss: 0.0875807
[Epoch 109] ogbg-moltoxcast: 0.686927 val loss: 0.285022
[Epoch 109] ogbg-moltoxcast: 0.656139 test loss: 0.332347
[Epoch 110; Iter    29/  229] train: loss: 0.0814622
[Epoch 110; Iter    59/  229] train: loss: 0.0930246
[Epoch 110; Iter    89/  229] train: loss: 0.0764563
[Epoch 110; Iter   119/  229] train: loss: 0.1328083
[Epoch 110; Iter   149/  229] train: loss: 0.1044758
[Epoch 110; Iter   179/  229] train: loss: 0.1685258
[Epoch 110; Iter   209/  229] train: loss: 0.0940431
[Epoch 110] ogbg-moltoxcast: 0.686893 val loss: 0.287313
[Epoch 110] ogbg-moltoxcast: 0.657651 test loss: 0.335096
[Epoch 111; Iter    10/  229] train: loss: 0.1360738
[Epoch 111; Iter    40/  229] train: loss: 0.0927863
[Epoch 111; Iter    70/  229] train: loss: 0.1090493
[Epoch 111; Iter   100/  229] train: loss: 0.1365901
[Epoch 111; Iter   130/  229] train: loss: 0.1055307
[Epoch 111; Iter   160/  229] train: loss: 0.1499663
[Epoch 111; Iter   190/  229] train: loss: 0.1198304
[Epoch 111; Iter   220/  229] train: loss: 0.1034263
[Epoch 111] ogbg-moltoxcast: 0.689631 val loss: 0.292217
[Epoch 111] ogbg-moltoxcast: 0.656914 test loss: 0.340710
[Epoch 112; Iter    21/  229] train: loss: 0.1242186
[Epoch 112; Iter    51/  229] train: loss: 0.0911511
[Epoch 112; Iter    81/  229] train: loss: 0.0866688
[Epoch 112; Iter   111/  229] train: loss: 0.1140202
[Epoch 112; Iter   141/  229] train: loss: 0.1119169
[Epoch 112; Iter   171/  229] train: loss: 0.1449386
[Epoch 112; Iter   201/  229] train: loss: 0.1031761
[Epoch 112] ogbg-moltoxcast: 0.690551 val loss: 0.286248
[Epoch 112] ogbg-moltoxcast: 0.657318 test loss: 0.339363
[Epoch 113; Iter     2/  229] train: loss: 0.1589251
[Epoch 113; Iter    32/  229] train: loss: 0.1041778
[Epoch 113; Iter    62/  229] train: loss: 0.1533340
[Epoch 113; Iter    92/  229] train: loss: 0.1102261
[Epoch 113; Iter   122/  229] train: loss: 0.1329794
[Epoch 113; Iter   152/  229] train: loss: 0.1057439
[Epoch 113; Iter   182/  229] train: loss: 0.1143375
[Epoch 113; Iter   212/  229] train: loss: 0.1789971
[Epoch 113] ogbg-moltoxcast: 0.690988 val loss: 0.286033
[Epoch 113] ogbg-moltoxcast: 0.662105 test loss: 0.330830
[Epoch 114; Iter    13/  229] train: loss: 0.0966083
[Epoch 114; Iter    43/  229] train: loss: 0.1421606
[Epoch 114; Iter    73/  229] train: loss: 0.1545461
[Epoch 114; Iter   103/  229] train: loss: 0.1152197
[Epoch 114; Iter   133/  229] train: loss: 0.1408787
[Epoch 114; Iter   163/  229] train: loss: 0.1438129
[Epoch 114; Iter   193/  229] train: loss: 0.1537682
[Epoch 114; Iter   223/  229] train: loss: 0.1127988
[Epoch 114] ogbg-moltoxcast: 0.688041 val loss: 0.283502
[Epoch 114] ogbg-moltoxcast: 0.656826 test loss: 0.333001
[Epoch 115; Iter    24/  229] train: loss: 0.0916155
[Epoch 115; Iter    54/  229] train: loss: 0.1203042
[Epoch 115; Iter    84/  229] train: loss: 0.1452611
[Epoch 115; Iter   114/  229] train: loss: 0.0874324
[Epoch 115; Iter   144/  229] train: loss: 0.1535480
[Epoch 115; Iter   174/  229] train: loss: 0.1130102
[Epoch 115; Iter   204/  229] train: loss: 0.0909734
[Epoch 115] ogbg-moltoxcast: 0.689890 val loss: 0.286898
[Epoch 115] ogbg-moltoxcast: 0.659023 test loss: 0.335507
[Epoch 116; Iter     5/  229] train: loss: 0.1691233
[Epoch 116; Iter    35/  229] train: loss: 0.1182462
[Epoch 116; Iter    65/  229] train: loss: 0.1170111
[Epoch 116; Iter    95/  229] train: loss: 0.1154478
[Epoch 116; Iter   125/  229] train: loss: 0.1274779
[Epoch 116; Iter   155/  229] train: loss: 0.1345088
[Epoch 116; Iter   185/  229] train: loss: 0.0965797
[Epoch 116; Iter   215/  229] train: loss: 0.0862750
[Epoch 116] ogbg-moltoxcast: 0.689872 val loss: 0.287033
[Epoch 116] ogbg-moltoxcast: 0.658883 test loss: 0.334792
[Epoch 117; Iter    16/  229] train: loss: 0.1310332
[Epoch 117; Iter    46/  229] train: loss: 0.1436297
[Epoch 117; Iter    76/  229] train: loss: 0.1190599
[Epoch 117; Iter   106/  229] train: loss: 0.1282627
[Epoch 117; Iter   136/  229] train: loss: 0.1329931
[Epoch 117; Iter   166/  229] train: loss: 0.0898387
[Epoch 117; Iter   196/  229] train: loss: 0.1154626
[Epoch 117; Iter   226/  229] train: loss: 0.1136572
[Epoch 117] ogbg-moltoxcast: 0.686977 val loss: 0.294188
[Epoch 117] ogbg-moltoxcast: 0.655998 test loss: 0.335245
[Epoch 118; Iter    27/  229] train: loss: 0.1160182
[Epoch 118; Iter    57/  229] train: loss: 0.0856105
[Epoch 118; Iter    87/  229] train: loss: 0.1239390
[Epoch 118; Iter   117/  229] train: loss: 0.0878148
[Epoch 118; Iter   147/  229] train: loss: 0.1113181
[Epoch 118; Iter   177/  229] train: loss: 0.1454142
[Epoch 118; Iter   207/  229] train: loss: 0.1063351
[Epoch 118] ogbg-moltoxcast: 0.686918 val loss: 0.288948
[Epoch 118] ogbg-moltoxcast: 0.656221 test loss: 0.336875
[Epoch 119; Iter     8/  229] train: loss: 0.0821091
[Epoch 119; Iter    38/  229] train: loss: 0.1081907
[Epoch 119; Iter    68/  229] train: loss: 0.1364412
[Epoch 119; Iter    98/  229] train: loss: 0.0937872
[Epoch 119; Iter   128/  229] train: loss: 0.1535323
[Epoch 119; Iter   158/  229] train: loss: 0.1325100
[Epoch 119; Iter   188/  229] train: loss: 0.1437301
[Epoch 119; Iter   218/  229] train: loss: 0.1849701
[Epoch 119] ogbg-moltoxcast: 0.689265 val loss: 0.288213
[Epoch 119] ogbg-moltoxcast: 0.656619 test loss: 0.339511
[Epoch 120; Iter    19/  229] train: loss: 0.0944119
[Epoch 120; Iter    49/  229] train: loss: 0.1230481
[Epoch 120; Iter    79/  229] train: loss: 0.0892831
[Epoch 120; Iter   109/  229] train: loss: 0.0711335
[Epoch 120; Iter   139/  229] train: loss: 0.1398140
[Epoch 120; Iter   169/  229] train: loss: 0.0970680
[Epoch 120; Iter   199/  229] train: loss: 0.0960799
[Epoch 120; Iter   229/  229] train: loss: 0.1096054
[Epoch 120] ogbg-moltoxcast: 0.692259 val loss: 0.285132
[Epoch 120] ogbg-moltoxcast: 0.657248 test loss: 0.337509
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 34.
Statistics on  val_best_checkpoint
mean_pred: -2.4056639671325684
std_pred: 2.4655351638793945
mean_targets: nan
std_targets: nan
prcauc: 0.4026091836189579
rocauc: 0.7023357415079149
ogbg-moltoxcast: 0.7023357415079149
OGBNanLabelBCEWithLogitsLoss: 0.25173449619063015
Statistics on  test
mean_pred: -2.124009609222412
std_pred: 2.383417844772339
mean_targets: nan
std_targets: nan
prcauc: 0.3588069019508483
rocauc: 0.6534294366583111
ogbg-moltoxcast: 0.6534294366583111
OGBNanLabelBCEWithLogitsLoss: 0.29966756495936164
Statistics on  train
mean_pred: -3.0579323768615723
std_pred: 2.3847854137420654
mean_targets: nan
std_targets: nan
prcauc: 0.521837932515861
rocauc: 0.8479118295364787
ogbg-moltoxcast: 0.8479118295364787
OGBNanLabelBCEWithLogitsLoss: 0.15653427185970623
All runs completed.
