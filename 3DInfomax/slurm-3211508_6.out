>>> Starting run for dataset: tox21
Running configs_static_noise_experiments/3DInfomax/tox21/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/3DInfomax/tox21/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/3DInfomax/tox21/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/3DInfomax/tox21/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.0/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.0_5_26-05_09-18-24
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.0
logdir: runs/static_noise/3DInfomax/tox21/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6935000
[Epoch 1; Iter    60/  209] train: loss: 0.6934997
[Epoch 1; Iter    90/  209] train: loss: 0.6924404
[Epoch 1; Iter   120/  209] train: loss: 0.6926443
[Epoch 1; Iter   150/  209] train: loss: 0.6922327
[Epoch 1; Iter   180/  209] train: loss: 0.6927152
[Epoch 1] ogbg-moltox21: 0.490475 val loss: 0.692548
[Epoch 1] ogbg-moltox21: 0.494033 test loss: 0.692184
[Epoch 2; Iter     1/  209] train: loss: 0.6921802
[Epoch 2; Iter    31/  209] train: loss: 0.6923270
[Epoch 2; Iter    61/  209] train: loss: 0.6910958
[Epoch 2; Iter    91/  209] train: loss: 0.6913828
[Epoch 2; Iter   121/  209] train: loss: 0.6921211
[Epoch 2; Iter   151/  209] train: loss: 0.6910291
[Epoch 2; Iter   181/  209] train: loss: 0.6916206
[Epoch 2] ogbg-moltox21: 0.506982 val loss: 0.691542
[Epoch 2] ogbg-moltox21: 0.509767 test loss: 0.691192
[Epoch 3; Iter     2/  209] train: loss: 0.6906205
[Epoch 3; Iter    32/  209] train: loss: 0.6911997
[Epoch 3; Iter    62/  209] train: loss: 0.6894030
[Epoch 3; Iter    92/  209] train: loss: 0.6889070
[Epoch 3; Iter   122/  209] train: loss: 0.6894379
[Epoch 3; Iter   152/  209] train: loss: 0.6884426
[Epoch 3; Iter   182/  209] train: loss: 0.6887284
[Epoch 3] ogbg-moltox21: 0.511182 val loss: 0.688336
[Epoch 3] ogbg-moltox21: 0.513031 test loss: 0.688034
[Epoch 4; Iter     3/  209] train: loss: 0.6883829
[Epoch 4; Iter    33/  209] train: loss: 0.6870602
[Epoch 4; Iter    63/  209] train: loss: 0.6870600
[Epoch 4; Iter    93/  209] train: loss: 0.6809585
[Epoch 4; Iter   123/  209] train: loss: 0.6605290
[Epoch 4; Iter   153/  209] train: loss: 0.6211150
[Epoch 4; Iter   183/  209] train: loss: 0.5876521
[Epoch 4] ogbg-moltox21: 0.650967 val loss: 0.606922
[Epoch 4] ogbg-moltox21: 0.612556 test loss: 0.607140
[Epoch 5; Iter     4/  209] train: loss: 0.5355811
[Epoch 5; Iter    34/  209] train: loss: 0.4575257
[Epoch 5; Iter    64/  209] train: loss: 0.4091032
[Epoch 5; Iter    94/  209] train: loss: 0.3488182
[Epoch 5; Iter   124/  209] train: loss: 0.2986700
[Epoch 5; Iter   154/  209] train: loss: 0.3078350
[Epoch 5; Iter   184/  209] train: loss: 0.2434679
[Epoch 5] ogbg-moltox21: 0.679864 val loss: 0.338978
[Epoch 5] ogbg-moltox21: 0.672128 test loss: 0.358333
[Epoch 6; Iter     5/  209] train: loss: 0.2869124
[Epoch 6; Iter    35/  209] train: loss: 0.2332048
[Epoch 6; Iter    65/  209] train: loss: 0.2347133
[Epoch 6; Iter    95/  209] train: loss: 0.1569710
[Epoch 6; Iter   125/  209] train: loss: 0.2627946
[Epoch 6; Iter   155/  209] train: loss: 0.2092782
[Epoch 6; Iter   185/  209] train: loss: 0.1913173
[Epoch 6] ogbg-moltox21: 0.729896 val loss: 0.278798
[Epoch 6] ogbg-moltox21: 0.687021 test loss: 0.286484
[Epoch 7; Iter     6/  209] train: loss: 0.1679536
[Epoch 7; Iter    36/  209] train: loss: 0.1432186
[Epoch 7; Iter    66/  209] train: loss: 0.2124151
[Epoch 7; Iter    96/  209] train: loss: 0.2250246
[Epoch 7; Iter   126/  209] train: loss: 0.3150901
[Epoch 7; Iter   156/  209] train: loss: 0.1730801
[Epoch 7; Iter   186/  209] train: loss: 0.1667174
[Epoch 7] ogbg-moltox21: 0.699902 val loss: 0.283235
[Epoch 7] ogbg-moltox21: 0.717605 test loss: 0.330008
[Epoch 8; Iter     7/  209] train: loss: 0.2480955
[Epoch 8; Iter    37/  209] train: loss: 0.1551000
[Epoch 8; Iter    67/  209] train: loss: 0.1445927
[Epoch 8; Iter    97/  209] train: loss: 0.1757970
[Epoch 8; Iter   127/  209] train: loss: 0.2329522
[Epoch 8; Iter   157/  209] train: loss: 0.1171339
[Epoch 8; Iter   187/  209] train: loss: 0.3333687
[Epoch 8] ogbg-moltox21: 0.695121 val loss: 0.309004
[Epoch 8] ogbg-moltox21: 0.686000 test loss: 0.315037
[Epoch 9; Iter     8/  209] train: loss: 0.2018809
[Epoch 9; Iter    38/  209] train: loss: 0.2131432
[Epoch 9; Iter    68/  209] train: loss: 0.0897853
[Epoch 9; Iter    98/  209] train: loss: 0.1733015
[Epoch 9; Iter   128/  209] train: loss: 0.2108233
[Epoch 9; Iter   158/  209] train: loss: 0.1568851
[Epoch 9; Iter   188/  209] train: loss: 0.2345962
[Epoch 9] ogbg-moltox21: 0.753426 val loss: 0.269877
[Epoch 9] ogbg-moltox21: 0.713678 test loss: 0.278965
[Epoch 10; Iter     9/  209] train: loss: 0.1564507
[Epoch 10; Iter    39/  209] train: loss: 0.2529419
[Epoch 10; Iter    69/  209] train: loss: 0.2697673
[Epoch 10; Iter    99/  209] train: loss: 0.1559577
[Epoch 10; Iter   129/  209] train: loss: 0.1672792
[Epoch 10; Iter   159/  209] train: loss: 0.2779737
[Epoch 10; Iter   189/  209] train: loss: 0.1793253
[Epoch 10] ogbg-moltox21: 0.744166 val loss: 0.282757
[Epoch 10] ogbg-moltox21: 0.717842 test loss: 0.282123
[Epoch 11; Iter    10/  209] train: loss: 0.1846191
[Epoch 11; Iter    40/  209] train: loss: 0.1853628
[Epoch 11; Iter    70/  209] train: loss: 0.1412971
[Epoch 11; Iter   100/  209] train: loss: 0.1830225
[Epoch 11; Iter   130/  209] train: loss: 0.1928449
[Epoch 11; Iter   160/  209] train: loss: 0.2100331
[Epoch 11; Iter   190/  209] train: loss: 0.1724558
[Epoch 11] ogbg-moltox21: 0.758815 val loss: 0.308099
[Epoch 11] ogbg-moltox21: 0.748145 test loss: 0.284080
[Epoch 12; Iter    11/  209] train: loss: 0.2268444
[Epoch 12; Iter    41/  209] train: loss: 0.2291555
[Epoch 12; Iter    71/  209] train: loss: 0.2044812
[Epoch 12; Iter   101/  209] train: loss: 0.1297937
[Epoch 12; Iter   131/  209] train: loss: 0.2249489
[Epoch 12; Iter   161/  209] train: loss: 0.2205947
[Epoch 12; Iter   191/  209] train: loss: 0.2209993
[Epoch 12] ogbg-moltox21: 0.743198 val loss: 0.289840
[Epoch 12] ogbg-moltox21: 0.732530 test loss: 0.298069
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.05/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.05_5_26-05_09-20-24
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.05
logdir: runs/static_noise/3DInfomax/tox21/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6935714
[Epoch 1; Iter    60/  209] train: loss: 0.6933876
[Epoch 1; Iter    90/  209] train: loss: 0.6922631
[Epoch 1; Iter   120/  209] train: loss: 0.6927387
[Epoch 1; Iter   150/  209] train: loss: 0.6922523
[Epoch 1; Iter   180/  209] train: loss: 0.6931241
[Epoch 1] ogbg-moltox21: 0.469089 val loss: 0.692584
[Epoch 1] ogbg-moltox21: 0.474832 test loss: 0.692226
[Epoch 2; Iter     1/  209] train: loss: 0.6920186
[Epoch 2; Iter    31/  209] train: loss: 0.6923827
[Epoch 2; Iter    61/  209] train: loss: 0.6911966
[Epoch 2; Iter    91/  209] train: loss: 0.6916626
[Epoch 2; Iter   121/  209] train: loss: 0.6918349
[Epoch 2; Iter   151/  209] train: loss: 0.6912216
[Epoch 2; Iter   181/  209] train: loss: 0.6918514
[Epoch 2] ogbg-moltox21: 0.480669 val loss: 0.691423
[Epoch 2] ogbg-moltox21: 0.485512 test loss: 0.691048
[Epoch 3; Iter     2/  209] train: loss: 0.6909783
[Epoch 3; Iter    32/  209] train: loss: 0.6910396
[Epoch 3; Iter    62/  209] train: loss: 0.6894115
[Epoch 3; Iter    92/  209] train: loss: 0.6891693
[Epoch 3; Iter   122/  209] train: loss: 0.6895441
[Epoch 3; Iter   152/  209] train: loss: 0.6886187
[Epoch 3; Iter   182/  209] train: loss: 0.6884435
[Epoch 3] ogbg-moltox21: 0.485985 val loss: 0.688489
[Epoch 3] ogbg-moltox21: 0.488297 test loss: 0.688156
[Epoch 4; Iter     3/  209] train: loss: 0.6887167
[Epoch 4; Iter    33/  209] train: loss: 0.6871361
[Epoch 4; Iter    63/  209] train: loss: 0.6870967
[Epoch 4; Iter    93/  209] train: loss: 0.6811993
[Epoch 4; Iter   123/  209] train: loss: 0.6609331
[Epoch 4; Iter   153/  209] train: loss: 0.6209100
[Epoch 4; Iter   183/  209] train: loss: 0.6024314
[Epoch 4] ogbg-moltox21: 0.682951 val loss: 0.591449
[Epoch 4] ogbg-moltox21: 0.661471 test loss: 0.594212
[Epoch 5; Iter     4/  209] train: loss: 0.5380502
[Epoch 5; Iter    34/  209] train: loss: 0.4658088
[Epoch 5; Iter    64/  209] train: loss: 0.4201315
[Epoch 5; Iter    94/  209] train: loss: 0.3534733
[Epoch 5; Iter   124/  209] train: loss: 0.3189971
[Epoch 5; Iter   154/  209] train: loss: 0.3106117
[Epoch 5; Iter   184/  209] train: loss: 0.2499849
[Epoch 5] ogbg-moltox21: 0.667534 val loss: 0.387160
[Epoch 5] ogbg-moltox21: 0.659642 test loss: 0.356737
[Epoch 6; Iter     5/  209] train: loss: 0.3315591
[Epoch 6; Iter    35/  209] train: loss: 0.2309343
[Epoch 6; Iter    65/  209] train: loss: 0.2548326
[Epoch 6; Iter    95/  209] train: loss: 0.1666927
[Epoch 6; Iter   125/  209] train: loss: 0.2575080
[Epoch 6; Iter   155/  209] train: loss: 0.2224874
[Epoch 6; Iter   185/  209] train: loss: 0.2061224
[Epoch 6] ogbg-moltox21: 0.707821 val loss: 0.407611
[Epoch 6] ogbg-moltox21: 0.681794 test loss: 0.285204
[Epoch 7; Iter     6/  209] train: loss: 0.1698906
[Epoch 7; Iter    36/  209] train: loss: 0.1434489
[Epoch 7; Iter    66/  209] train: loss: 0.2075537
[Epoch 7; Iter    96/  209] train: loss: 0.2408555
[Epoch 7; Iter   126/  209] train: loss: 0.3306282
[Epoch 7; Iter   156/  209] train: loss: 0.1659134
[Epoch 7; Iter   186/  209] train: loss: 0.1832253
[Epoch 7] ogbg-moltox21: 0.609836 val loss: 0.513697
[Epoch 7] ogbg-moltox21: 0.636346 test loss: 0.324001
[Epoch 8; Iter     7/  209] train: loss: 0.2381649
[Epoch 8; Iter    37/  209] train: loss: 0.1674605
[Epoch 8; Iter    67/  209] train: loss: 0.1633367
[Epoch 8; Iter    97/  209] train: loss: 0.2138664
[Epoch 8; Iter   127/  209] train: loss: 0.2644151
[Epoch 8; Iter   157/  209] train: loss: 0.1201316
[Epoch 8; Iter   187/  209] train: loss: 0.3555259
[Epoch 8] ogbg-moltox21: 0.692336 val loss: 0.450514
[Epoch 8] ogbg-moltox21: 0.666256 test loss: 0.622253
[Epoch 9; Iter     8/  209] train: loss: 0.2096224
[Epoch 9; Iter    38/  209] train: loss: 0.2306681
[Epoch 9; Iter    68/  209] train: loss: 0.0960549
[Epoch 9; Iter    98/  209] train: loss: 0.1858253
[Epoch 9; Iter   128/  209] train: loss: 0.2215254
[Epoch 9; Iter   158/  209] train: loss: 0.1484020
[Epoch 9; Iter   188/  209] train: loss: 0.2596966
[Epoch 9] ogbg-moltox21: 0.758367 val loss: 1.304599
[Epoch 9] ogbg-moltox21: 0.738844 test loss: 2.406664
[Epoch 10; Iter     9/  209] train: loss: 0.1518293
[Epoch 10; Iter    39/  209] train: loss: 0.2277668
[Epoch 10; Iter    69/  209] train: loss: 0.2840600
[Epoch 10; Iter    99/  209] train: loss: 0.1655538
[Epoch 10; Iter   129/  209] train: loss: 0.1566357
[Epoch 10; Iter   159/  209] train: loss: 0.2351688
[Epoch 10; Iter   189/  209] train: loss: 0.2158183
[Epoch 10] ogbg-moltox21: 0.744567 val loss: 0.719500
[Epoch 10] ogbg-moltox21: 0.717852 test loss: 0.976474
[Epoch 11; Iter    10/  209] train: loss: 0.2052921
[Epoch 11; Iter    40/  209] train: loss: 0.2074488
[Epoch 11; Iter    70/  209] train: loss: 0.1375645
[Epoch 11; Iter   100/  209] train: loss: 0.1983304
[Epoch 11; Iter   130/  209] train: loss: 0.1863924
[Epoch 11; Iter   160/  209] train: loss: 0.2087902
[Epoch 11; Iter   190/  209] train: loss: 0.1807553
[Epoch 11] ogbg-moltox21: 0.756934 val loss: 0.263278
[Epoch 11] ogbg-moltox21: 0.720469 test loss: 0.308840
[Epoch 12; Iter    11/  209] train: loss: 0.1993188
[Epoch 12; Iter    41/  209] train: loss: 0.2341749
[Epoch 12; Iter    71/  209] train: loss: 0.2200509
[Epoch 12; Iter   101/  209] train: loss: 0.1530657
[Epoch 12; Iter   131/  209] train: loss: 0.2218014
[Epoch 12; Iter   161/  209] train: loss: 0.2428245
[Epoch 12; Iter   191/  209] train: loss: 0.2139420
[Epoch 12] ogbg-moltox21: 0.771165 val loss: 0.280127
[Epoch 12] ogbg-moltox21: 0.732647 test loss: 0.322056
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.0/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.0_6_26-05_09-18-24
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.0
logdir: runs/static_noise/3DInfomax/tox21/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6932449
[Epoch 1; Iter    60/  209] train: loss: 0.6922231
[Epoch 1; Iter    90/  209] train: loss: 0.6921970
[Epoch 1; Iter   120/  209] train: loss: 0.6930904
[Epoch 1; Iter   150/  209] train: loss: 0.6929813
[Epoch 1; Iter   180/  209] train: loss: 0.6921134
[Epoch 1] ogbg-moltox21: 0.481710 val loss: 0.693622
[Epoch 1] ogbg-moltox21: 0.493910 test loss: 0.693320
[Epoch 2; Iter     1/  209] train: loss: 0.6922827
[Epoch 2; Iter    31/  209] train: loss: 0.6925003
[Epoch 2; Iter    61/  209] train: loss: 0.6922155
[Epoch 2; Iter    91/  209] train: loss: 0.6921775
[Epoch 2; Iter   121/  209] train: loss: 0.6919969
[Epoch 2; Iter   151/  209] train: loss: 0.6914183
[Epoch 2; Iter   181/  209] train: loss: 0.6913604
[Epoch 2] ogbg-moltox21: 0.487506 val loss: 0.692123
[Epoch 2] ogbg-moltox21: 0.500858 test loss: 0.691781
[Epoch 3; Iter     2/  209] train: loss: 0.6907048
[Epoch 3; Iter    32/  209] train: loss: 0.6902463
[Epoch 3; Iter    62/  209] train: loss: 0.6904027
[Epoch 3; Iter    92/  209] train: loss: 0.6908488
[Epoch 3; Iter   122/  209] train: loss: 0.6898955
[Epoch 3; Iter   152/  209] train: loss: 0.6899803
[Epoch 3; Iter   182/  209] train: loss: 0.6888211
[Epoch 3] ogbg-moltox21: 0.488077 val loss: 0.689920
[Epoch 3] ogbg-moltox21: 0.501033 test loss: 0.689636
[Epoch 4; Iter     3/  209] train: loss: 0.6882789
[Epoch 4; Iter    33/  209] train: loss: 0.6875144
[Epoch 4; Iter    63/  209] train: loss: 0.6871979
[Epoch 4; Iter    93/  209] train: loss: 0.6829287
[Epoch 4; Iter   123/  209] train: loss: 0.6621528
[Epoch 4; Iter   153/  209] train: loss: 0.6271290
[Epoch 4; Iter   183/  209] train: loss: 0.6246628
[Epoch 4] ogbg-moltox21: 0.647692 val loss: 0.709811
[Epoch 4] ogbg-moltox21: 0.632076 test loss: 0.714946
[Epoch 5; Iter     4/  209] train: loss: 0.5432002
[Epoch 5; Iter    34/  209] train: loss: 0.4670600
[Epoch 5; Iter    64/  209] train: loss: 0.4256207
[Epoch 5; Iter    94/  209] train: loss: 0.4030154
[Epoch 5; Iter   124/  209] train: loss: 0.3536979
[Epoch 5; Iter   154/  209] train: loss: 0.2730349
[Epoch 5; Iter   184/  209] train: loss: 0.2287936
[Epoch 5] ogbg-moltox21: 0.693944 val loss: 0.303085
[Epoch 5] ogbg-moltox21: 0.672874 test loss: 0.307824
[Epoch 6; Iter     5/  209] train: loss: 0.2074737
[Epoch 6; Iter    35/  209] train: loss: 0.1730112
[Epoch 6; Iter    65/  209] train: loss: 0.2004821
[Epoch 6; Iter    95/  209] train: loss: 0.2034770
[Epoch 6; Iter   125/  209] train: loss: 0.1522286
[Epoch 6; Iter   155/  209] train: loss: 0.2051427
[Epoch 6; Iter   185/  209] train: loss: 0.1820004
[Epoch 6] ogbg-moltox21: 0.721936 val loss: 0.276197
[Epoch 6] ogbg-moltox21: 0.694135 test loss: 0.276000
[Epoch 7; Iter     6/  209] train: loss: 0.1739761
[Epoch 7; Iter    36/  209] train: loss: 0.2257688
[Epoch 7; Iter    66/  209] train: loss: 0.1367073
[Epoch 7; Iter    96/  209] train: loss: 0.2402528
[Epoch 7; Iter   126/  209] train: loss: 0.1547014
[Epoch 7; Iter   156/  209] train: loss: 0.2371144
[Epoch 7; Iter   186/  209] train: loss: 0.2214632
[Epoch 7] ogbg-moltox21: 0.746060 val loss: 0.270953
[Epoch 7] ogbg-moltox21: 0.722897 test loss: 0.287963
[Epoch 8; Iter     7/  209] train: loss: 0.1896205
[Epoch 8; Iter    37/  209] train: loss: 0.2406794
[Epoch 8; Iter    67/  209] train: loss: 0.1541151
[Epoch 8; Iter    97/  209] train: loss: 0.2095990
[Epoch 8; Iter   127/  209] train: loss: 0.2673352
[Epoch 8; Iter   157/  209] train: loss: 0.1697390
[Epoch 8; Iter   187/  209] train: loss: 0.2183379
[Epoch 8] ogbg-moltox21: 0.736203 val loss: 0.281771
[Epoch 8] ogbg-moltox21: 0.716159 test loss: 0.300188
[Epoch 9; Iter     8/  209] train: loss: 0.2489040
[Epoch 9; Iter    38/  209] train: loss: 0.1695343
[Epoch 9; Iter    68/  209] train: loss: 0.1789196
[Epoch 9; Iter    98/  209] train: loss: 0.2465649
[Epoch 9; Iter   128/  209] train: loss: 0.2145098
[Epoch 9; Iter   158/  209] train: loss: 0.1486310
[Epoch 9; Iter   188/  209] train: loss: 0.1422819
[Epoch 9] ogbg-moltox21: 0.740994 val loss: 0.270884
[Epoch 9] ogbg-moltox21: 0.728035 test loss: 0.283517
[Epoch 10; Iter     9/  209] train: loss: 0.2020264
[Epoch 10; Iter    39/  209] train: loss: 0.1692345
[Epoch 10; Iter    69/  209] train: loss: 0.1868353
[Epoch 10; Iter    99/  209] train: loss: 0.1411684
[Epoch 10; Iter   129/  209] train: loss: 0.1516981
[Epoch 10; Iter   159/  209] train: loss: 0.1102360
[Epoch 10; Iter   189/  209] train: loss: 0.1558127
[Epoch 10] ogbg-moltox21: 0.760134 val loss: 0.268128
[Epoch 10] ogbg-moltox21: 0.736091 test loss: 0.294787
[Epoch 11; Iter    10/  209] train: loss: 0.2163654
[Epoch 11; Iter    40/  209] train: loss: 0.1989475
[Epoch 11; Iter    70/  209] train: loss: 0.1969191
[Epoch 11; Iter   100/  209] train: loss: 0.2552060
[Epoch 11; Iter   130/  209] train: loss: 0.1641027
[Epoch 11; Iter   160/  209] train: loss: 0.1766207
[Epoch 11; Iter   190/  209] train: loss: 0.1515393
[Epoch 11] ogbg-moltox21: 0.764465 val loss: 0.303107
[Epoch 11] ogbg-moltox21: 0.733896 test loss: 0.300073
[Epoch 12; Iter    11/  209] train: loss: 0.1074247
[Epoch 12; Iter    41/  209] train: loss: 0.2719890
[Epoch 12; Iter    71/  209] train: loss: 0.1637659
[Epoch 12; Iter   101/  209] train: loss: 0.1927920
[Epoch 12; Iter   131/  209] train: loss: 0.2161928
[Epoch 12; Iter   161/  209] train: loss: 0.1895045
[Epoch 12; Iter   191/  209] train: loss: 0.1360310
[Epoch 12] ogbg-moltox21: 0.779652 val loss: 0.257270
[Epoch 12] ogbg-moltox21: 0.761811 test loss: 0.264941
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.05/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.05_4_26-05_09-20-25
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.05
logdir: runs/static_noise/3DInfomax/tox21/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6930844
[Epoch 1; Iter    60/  209] train: loss: 0.6940471
[Epoch 1; Iter    90/  209] train: loss: 0.6933421
[Epoch 1; Iter   120/  209] train: loss: 0.6927702
[Epoch 1; Iter   150/  209] train: loss: 0.6926225
[Epoch 1; Iter   180/  209] train: loss: 0.6922801
[Epoch 1] ogbg-moltox21: 0.507281 val loss: 0.694970
[Epoch 1] ogbg-moltox21: 0.512228 test loss: 0.694521
[Epoch 2; Iter     1/  209] train: loss: 0.6920732
[Epoch 2; Iter    31/  209] train: loss: 0.6924041
[Epoch 2; Iter    61/  209] train: loss: 0.6919584
[Epoch 2; Iter    91/  209] train: loss: 0.6929863
[Epoch 2; Iter   121/  209] train: loss: 0.6918859
[Epoch 2; Iter   151/  209] train: loss: 0.6909272
[Epoch 2; Iter   181/  209] train: loss: 0.6913933
[Epoch 2] ogbg-moltox21: 0.508784 val loss: 0.693742
[Epoch 2] ogbg-moltox21: 0.518248 test loss: 0.693332
[Epoch 3; Iter     2/  209] train: loss: 0.6909461
[Epoch 3; Iter    32/  209] train: loss: 0.6908293
[Epoch 3; Iter    62/  209] train: loss: 0.6896906
[Epoch 3; Iter    92/  209] train: loss: 0.6907187
[Epoch 3; Iter   122/  209] train: loss: 0.6896899
[Epoch 3; Iter   152/  209] train: loss: 0.6885920
[Epoch 3; Iter   182/  209] train: loss: 0.6888953
[Epoch 3] ogbg-moltox21: 0.510143 val loss: 0.691642
[Epoch 3] ogbg-moltox21: 0.525083 test loss: 0.691236
[Epoch 4; Iter     3/  209] train: loss: 0.6875611
[Epoch 4; Iter    33/  209] train: loss: 0.6882288
[Epoch 4; Iter    63/  209] train: loss: 0.6885610
[Epoch 4; Iter    93/  209] train: loss: 0.6822016
[Epoch 4; Iter   123/  209] train: loss: 0.6605549
[Epoch 4; Iter   153/  209] train: loss: 0.6324147
[Epoch 4; Iter   183/  209] train: loss: 0.5913068
[Epoch 4] ogbg-moltox21: 0.649253 val loss: 0.639032
[Epoch 4] ogbg-moltox21: 0.644822 test loss: 0.640803
[Epoch 5; Iter     4/  209] train: loss: 0.5386111
[Epoch 5; Iter    34/  209] train: loss: 0.4738334
[Epoch 5; Iter    64/  209] train: loss: 0.4400863
[Epoch 5; Iter    94/  209] train: loss: 0.3927496
[Epoch 5; Iter   124/  209] train: loss: 0.3988145
[Epoch 5; Iter   154/  209] train: loss: 0.2415975
[Epoch 5; Iter   184/  209] train: loss: 0.2327200
[Epoch 5] ogbg-moltox21: 0.680574 val loss: 0.425902
[Epoch 5] ogbg-moltox21: 0.667463 test loss: 0.464942
[Epoch 6; Iter     5/  209] train: loss: 0.2159115
[Epoch 6; Iter    35/  209] train: loss: 0.2181490
[Epoch 6; Iter    65/  209] train: loss: 0.2170353
[Epoch 6; Iter    95/  209] train: loss: 0.2291771
[Epoch 6; Iter   125/  209] train: loss: 0.3320256
[Epoch 6; Iter   155/  209] train: loss: 0.2502295
[Epoch 6; Iter   185/  209] train: loss: 0.2590933
[Epoch 6] ogbg-moltox21: 0.708182 val loss: 0.392204
[Epoch 6] ogbg-moltox21: 0.693086 test loss: 0.291696
[Epoch 7; Iter     6/  209] train: loss: 0.3151776
[Epoch 7; Iter    36/  209] train: loss: 0.2070126
[Epoch 7; Iter    66/  209] train: loss: 0.2599188
[Epoch 7; Iter    96/  209] train: loss: 0.2057231
[Epoch 7; Iter   126/  209] train: loss: 0.1890186
[Epoch 7; Iter   156/  209] train: loss: 0.2246183
[Epoch 7; Iter   186/  209] train: loss: 0.1934884
[Epoch 7] ogbg-moltox21: 0.705174 val loss: 0.601929
[Epoch 7] ogbg-moltox21: 0.705233 test loss: 0.516013
[Epoch 8; Iter     7/  209] train: loss: 0.1262254
[Epoch 8; Iter    37/  209] train: loss: 0.2357582
[Epoch 8; Iter    67/  209] train: loss: 0.3073703
[Epoch 8; Iter    97/  209] train: loss: 0.1823166
[Epoch 8; Iter   127/  209] train: loss: 0.2731279
[Epoch 8; Iter   157/  209] train: loss: 0.1563165
[Epoch 8; Iter   187/  209] train: loss: 0.2002727
[Epoch 8] ogbg-moltox21: 0.742637 val loss: 0.361322
[Epoch 8] ogbg-moltox21: 0.728645 test loss: 0.402437
[Epoch 9; Iter     8/  209] train: loss: 0.2630316
[Epoch 9; Iter    38/  209] train: loss: 0.1363096
[Epoch 9; Iter    68/  209] train: loss: 0.2379919
[Epoch 9; Iter    98/  209] train: loss: 0.1899644
[Epoch 9; Iter   128/  209] train: loss: 0.1873574
[Epoch 9; Iter   158/  209] train: loss: 0.2222675
[Epoch 9; Iter   188/  209] train: loss: 0.2348187
[Epoch 9] ogbg-moltox21: 0.688035 val loss: 0.405491
[Epoch 9] ogbg-moltox21: 0.701463 test loss: 0.425329
[Epoch 10; Iter     9/  209] train: loss: 0.2795154
[Epoch 10; Iter    39/  209] train: loss: 0.1989594
[Epoch 10; Iter    69/  209] train: loss: 0.2037332
[Epoch 10; Iter    99/  209] train: loss: 0.2098381
[Epoch 10; Iter   129/  209] train: loss: 0.2252700
[Epoch 10; Iter   159/  209] train: loss: 0.1591926
[Epoch 10; Iter   189/  209] train: loss: 0.2315135
[Epoch 10] ogbg-moltox21: 0.744439 val loss: 0.285311
[Epoch 10] ogbg-moltox21: 0.711901 test loss: 0.292022
[Epoch 11; Iter    10/  209] train: loss: 0.2176684
[Epoch 11; Iter    40/  209] train: loss: 0.1691309
[Epoch 11; Iter    70/  209] train: loss: 0.1998672
[Epoch 11; Iter   100/  209] train: loss: 0.3329733
[Epoch 11; Iter   130/  209] train: loss: 0.2028928
[Epoch 11; Iter   160/  209] train: loss: 0.2230076
[Epoch 11; Iter   190/  209] train: loss: 0.1732270
[Epoch 11] ogbg-moltox21: 0.755838 val loss: 0.268955
[Epoch 11] ogbg-moltox21: 0.718111 test loss: 0.283193
[Epoch 12; Iter    11/  209] train: loss: 0.1803343
[Epoch 12; Iter    41/  209] train: loss: 0.1061018
[Epoch 12; Iter    71/  209] train: loss: 0.3153378
[Epoch 12; Iter   101/  209] train: loss: 0.1704044
[Epoch 12; Iter   131/  209] train: loss: 0.1939180
[Epoch 12; Iter   161/  209] train: loss: 0.1707755
[Epoch 12; Iter   191/  209] train: loss: 0.1148221
[Epoch 12] ogbg-moltox21: 0.756769 val loss: 0.279906
[Epoch 12] ogbg-moltox21: 0.724080 test loss: 0.286879
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.0/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.0_4_26-05_09-18-24
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.0
logdir: runs/static_noise/3DInfomax/tox21/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6928516
[Epoch 1; Iter    60/  209] train: loss: 0.6939425
[Epoch 1; Iter    90/  209] train: loss: 0.6934603
[Epoch 1; Iter   120/  209] train: loss: 0.6926699
[Epoch 1; Iter   150/  209] train: loss: 0.6927113
[Epoch 1; Iter   180/  209] train: loss: 0.6924809
[Epoch 1] ogbg-moltox21: 0.495667 val loss: 0.693900
[Epoch 1] ogbg-moltox21: 0.507305 test loss: 0.693594
[Epoch 2; Iter     1/  209] train: loss: 0.6923747
[Epoch 2; Iter    31/  209] train: loss: 0.6923139
[Epoch 2; Iter    61/  209] train: loss: 0.6920390
[Epoch 2; Iter    91/  209] train: loss: 0.6928610
[Epoch 2; Iter   121/  209] train: loss: 0.6918319
[Epoch 2; Iter   151/  209] train: loss: 0.6910652
[Epoch 2; Iter   181/  209] train: loss: 0.6913953
[Epoch 2] ogbg-moltox21: 0.497703 val loss: 0.692414
[Epoch 2] ogbg-moltox21: 0.512625 test loss: 0.692174
[Epoch 3; Iter     2/  209] train: loss: 0.6912024
[Epoch 3; Iter    32/  209] train: loss: 0.6910614
[Epoch 3; Iter    62/  209] train: loss: 0.6897131
[Epoch 3; Iter    92/  209] train: loss: 0.6908472
[Epoch 3; Iter   122/  209] train: loss: 0.6891449
[Epoch 3; Iter   152/  209] train: loss: 0.6887643
[Epoch 3; Iter   182/  209] train: loss: 0.6888374
[Epoch 3] ogbg-moltox21: 0.499587 val loss: 0.690214
[Epoch 3] ogbg-moltox21: 0.518203 test loss: 0.689960
[Epoch 4; Iter     3/  209] train: loss: 0.6881841
[Epoch 4; Iter    33/  209] train: loss: 0.6879690
[Epoch 4; Iter    63/  209] train: loss: 0.6876869
[Epoch 4; Iter    93/  209] train: loss: 0.6818220
[Epoch 4; Iter   123/  209] train: loss: 0.6596898
[Epoch 4; Iter   153/  209] train: loss: 0.6276786
[Epoch 4; Iter   183/  209] train: loss: 0.5862048
[Epoch 4] ogbg-moltox21: 0.651892 val loss: 0.611918
[Epoch 4] ogbg-moltox21: 0.627802 test loss: 0.616279
[Epoch 5; Iter     4/  209] train: loss: 0.5315864
[Epoch 5; Iter    34/  209] train: loss: 0.4694417
[Epoch 5; Iter    64/  209] train: loss: 0.4365920
[Epoch 5; Iter    94/  209] train: loss: 0.3598737
[Epoch 5; Iter   124/  209] train: loss: 0.3939059
[Epoch 5; Iter   154/  209] train: loss: 0.2372530
[Epoch 5; Iter   184/  209] train: loss: 0.2239011
[Epoch 5] ogbg-moltox21: 0.720024 val loss: 0.339546
[Epoch 5] ogbg-moltox21: 0.685929 test loss: 0.345709
[Epoch 6; Iter     5/  209] train: loss: 0.2121143
[Epoch 6; Iter    35/  209] train: loss: 0.2113283
[Epoch 6; Iter    65/  209] train: loss: 0.2068388
[Epoch 6; Iter    95/  209] train: loss: 0.2250608
[Epoch 6; Iter   125/  209] train: loss: 0.3158578
[Epoch 6; Iter   155/  209] train: loss: 0.2475005
[Epoch 6; Iter   185/  209] train: loss: 0.2488229
[Epoch 6] ogbg-moltox21: 0.728877 val loss: 0.267888
[Epoch 6] ogbg-moltox21: 0.692453 test loss: 0.274134
[Epoch 7; Iter     6/  209] train: loss: 0.3154205
[Epoch 7; Iter    36/  209] train: loss: 0.1874325
[Epoch 7; Iter    66/  209] train: loss: 0.2584361
[Epoch 7; Iter    96/  209] train: loss: 0.2144861
[Epoch 7; Iter   126/  209] train: loss: 0.1842881
[Epoch 7; Iter   156/  209] train: loss: 0.2028817
[Epoch 7; Iter   186/  209] train: loss: 0.1842183
[Epoch 7] ogbg-moltox21: 0.718826 val loss: 0.332907
[Epoch 7] ogbg-moltox21: 0.706558 test loss: 0.328834
[Epoch 8; Iter     7/  209] train: loss: 0.1413521
[Epoch 8; Iter    37/  209] train: loss: 0.2335095
[Epoch 8; Iter    67/  209] train: loss: 0.3007532
[Epoch 8; Iter    97/  209] train: loss: 0.1799202
[Epoch 8; Iter   127/  209] train: loss: 0.2783245
[Epoch 8; Iter   157/  209] train: loss: 0.1566897
[Epoch 8; Iter   187/  209] train: loss: 0.2381880
[Epoch 8] ogbg-moltox21: 0.723602 val loss: 0.834066
[Epoch 8] ogbg-moltox21: 0.711571 test loss: 1.327356
[Epoch 9; Iter     8/  209] train: loss: 0.2649817
[Epoch 9; Iter    38/  209] train: loss: 0.1528104
[Epoch 9; Iter    68/  209] train: loss: 0.2128237
[Epoch 9; Iter    98/  209] train: loss: 0.1941969
[Epoch 9; Iter   128/  209] train: loss: 0.1710821
[Epoch 9; Iter   158/  209] train: loss: 0.1829640
[Epoch 9; Iter   188/  209] train: loss: 0.2385077
[Epoch 9] ogbg-moltox21: 0.774669 val loss: 0.257569
[Epoch 9] ogbg-moltox21: 0.743761 test loss: 0.272928
[Epoch 10; Iter     9/  209] train: loss: 0.2198078
[Epoch 10; Iter    39/  209] train: loss: 0.2136081
[Epoch 10; Iter    69/  209] train: loss: 0.2296368
[Epoch 10; Iter    99/  209] train: loss: 0.1961957
[Epoch 10; Iter   129/  209] train: loss: 0.2224602
[Epoch 10; Iter   159/  209] train: loss: 0.1446618
[Epoch 10; Iter   189/  209] train: loss: 0.2071220
[Epoch 10] ogbg-moltox21: 0.775180 val loss: 0.326478
[Epoch 10] ogbg-moltox21: 0.740165 test loss: 0.301637
[Epoch 11; Iter    10/  209] train: loss: 0.2098134
[Epoch 11; Iter    40/  209] train: loss: 0.1441910
[Epoch 11; Iter    70/  209] train: loss: 0.1668993
[Epoch 11; Iter   100/  209] train: loss: 0.3183248
[Epoch 11; Iter   130/  209] train: loss: 0.1848980
[Epoch 11; Iter   160/  209] train: loss: 0.1918905
[Epoch 11; Iter   190/  209] train: loss: 0.1592862
[Epoch 11] ogbg-moltox21: 0.758375 val loss: 0.281910
[Epoch 11] ogbg-moltox21: 0.739650 test loss: 0.295975
[Epoch 12; Iter    11/  209] train: loss: 0.1636686
[Epoch 12; Iter    41/  209] train: loss: 0.1050219
[Epoch 12; Iter    71/  209] train: loss: 0.3287420
[Epoch 12; Iter   101/  209] train: loss: 0.1634038
[Epoch 12; Iter   131/  209] train: loss: 0.1904328
[Epoch 12; Iter   161/  209] train: loss: 0.1647995
[Epoch 12; Iter   191/  209] train: loss: 0.1007492
[Epoch 12] ogbg-moltox21: 0.782145 val loss: 0.268886
[Epoch 12] ogbg-moltox21: 0.753476 test loss: 0.279887
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.1/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.1_4_26-05_09-20-48
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.1
logdir: runs/static_noise/3DInfomax/tox21/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6930936
[Epoch 1; Iter    60/  209] train: loss: 0.6937819
[Epoch 1; Iter    90/  209] train: loss: 0.6932151
[Epoch 1; Iter   120/  209] train: loss: 0.6929129
[Epoch 1; Iter   150/  209] train: loss: 0.6925246
[Epoch 1; Iter   180/  209] train: loss: 0.6926038
[Epoch 1] ogbg-moltox21: 0.503190 val loss: 0.695189
[Epoch 1] ogbg-moltox21: 0.516541 test loss: 0.694601
[Epoch 2; Iter     1/  209] train: loss: 0.6925247
[Epoch 2; Iter    31/  209] train: loss: 0.6924461
[Epoch 2; Iter    61/  209] train: loss: 0.6920838
[Epoch 2; Iter    91/  209] train: loss: 0.6924501
[Epoch 2; Iter   121/  209] train: loss: 0.6915026
[Epoch 2; Iter   151/  209] train: loss: 0.6913068
[Epoch 2; Iter   181/  209] train: loss: 0.6910283
[Epoch 2] ogbg-moltox21: 0.507798 val loss: 0.694337
[Epoch 2] ogbg-moltox21: 0.521005 test loss: 0.693719
[Epoch 3; Iter     2/  209] train: loss: 0.6912658
[Epoch 3; Iter    32/  209] train: loss: 0.6912186
[Epoch 3; Iter    62/  209] train: loss: 0.6892844
[Epoch 3; Iter    92/  209] train: loss: 0.6907782
[Epoch 3; Iter   122/  209] train: loss: 0.6898100
[Epoch 3; Iter   152/  209] train: loss: 0.6891069
[Epoch 3; Iter   182/  209] train: loss: 0.6891405
[Epoch 3] ogbg-moltox21: 0.509101 val loss: 0.692011
[Epoch 3] ogbg-moltox21: 0.530548 test loss: 0.691347
[Epoch 4; Iter     3/  209] train: loss: 0.6882030
[Epoch 4; Iter    33/  209] train: loss: 0.6881936
[Epoch 4; Iter    63/  209] train: loss: 0.6881223
[Epoch 4; Iter    93/  209] train: loss: 0.6821523
[Epoch 4; Iter   123/  209] train: loss: 0.6616391
[Epoch 4; Iter   153/  209] train: loss: 0.6290044
[Epoch 4; Iter   183/  209] train: loss: 0.5908782
[Epoch 4] ogbg-moltox21: 0.672099 val loss: 0.656354
[Epoch 4] ogbg-moltox21: 0.649280 test loss: 0.651147
[Epoch 5; Iter     4/  209] train: loss: 0.5381823
[Epoch 5; Iter    34/  209] train: loss: 0.4715624
[Epoch 5; Iter    64/  209] train: loss: 0.4395045
[Epoch 5; Iter    94/  209] train: loss: 0.3863164
[Epoch 5; Iter   124/  209] train: loss: 0.4040425
[Epoch 5; Iter   154/  209] train: loss: 0.2425038
[Epoch 5; Iter   184/  209] train: loss: 0.2414499
[Epoch 5] ogbg-moltox21: 0.697681 val loss: 0.529784
[Epoch 5] ogbg-moltox21: 0.697411 test loss: 0.546027
[Epoch 6; Iter     5/  209] train: loss: 0.2138949
[Epoch 6; Iter    35/  209] train: loss: 0.2250410
[Epoch 6; Iter    65/  209] train: loss: 0.2307524
[Epoch 6; Iter    95/  209] train: loss: 0.2366592
[Epoch 6; Iter   125/  209] train: loss: 0.3281835
[Epoch 6; Iter   155/  209] train: loss: 0.2490173
[Epoch 6; Iter   185/  209] train: loss: 0.2547587
[Epoch 6] ogbg-moltox21: 0.697014 val loss: 0.601977
[Epoch 6] ogbg-moltox21: 0.692899 test loss: 0.509136
[Epoch 7; Iter     6/  209] train: loss: 0.3246082
[Epoch 7; Iter    36/  209] train: loss: 0.2064835
[Epoch 7; Iter    66/  209] train: loss: 0.2579690
[Epoch 7; Iter    96/  209] train: loss: 0.2043574
[Epoch 7; Iter   126/  209] train: loss: 0.1940911
[Epoch 7; Iter   156/  209] train: loss: 0.2240935
[Epoch 7; Iter   186/  209] train: loss: 0.1896228
[Epoch 7] ogbg-moltox21: 0.718598 val loss: 0.476842
[Epoch 7] ogbg-moltox21: 0.703948 test loss: 0.379998
[Epoch 8; Iter     7/  209] train: loss: 0.1246079
[Epoch 8; Iter    37/  209] train: loss: 0.2199564
[Epoch 8; Iter    67/  209] train: loss: 0.3046059
[Epoch 8; Iter    97/  209] train: loss: 0.1899501
[Epoch 8; Iter   127/  209] train: loss: 0.2770908
[Epoch 8; Iter   157/  209] train: loss: 0.1694739
[Epoch 8; Iter   187/  209] train: loss: 0.1929937
[Epoch 8] ogbg-moltox21: 0.708539 val loss: 1.795316
[Epoch 8] ogbg-moltox21: 0.705721 test loss: 1.425804
[Epoch 9; Iter     8/  209] train: loss: 0.2674587
[Epoch 9; Iter    38/  209] train: loss: 0.1519915
[Epoch 9; Iter    68/  209] train: loss: 0.2498344
[Epoch 9; Iter    98/  209] train: loss: 0.2097633
[Epoch 9; Iter   128/  209] train: loss: 0.1849203
[Epoch 9; Iter   158/  209] train: loss: 0.1909932
[Epoch 9; Iter   188/  209] train: loss: 0.2325687
[Epoch 9] ogbg-moltox21: 0.751011 val loss: 0.375976
[Epoch 9] ogbg-moltox21: 0.729908 test loss: 0.510925
[Epoch 10; Iter     9/  209] train: loss: 0.2522738
[Epoch 10; Iter    39/  209] train: loss: 0.2021727
[Epoch 10; Iter    69/  209] train: loss: 0.2021540
[Epoch 10; Iter    99/  209] train: loss: 0.1949448
[Epoch 10; Iter   129/  209] train: loss: 0.2225711
[Epoch 10; Iter   159/  209] train: loss: 0.1756155
[Epoch 10; Iter   189/  209] train: loss: 0.2367618
[Epoch 10] ogbg-moltox21: 0.758141 val loss: 0.393731
[Epoch 10] ogbg-moltox21: 0.735640 test loss: 0.479031
[Epoch 11; Iter    10/  209] train: loss: 0.2081221
[Epoch 11; Iter    40/  209] train: loss: 0.1706754
[Epoch 11; Iter    70/  209] train: loss: 0.1874580
[Epoch 11; Iter   100/  209] train: loss: 0.3277174
[Epoch 11; Iter   130/  209] train: loss: 0.2000328
[Epoch 11; Iter   160/  209] train: loss: 0.2460571
[Epoch 11; Iter   190/  209] train: loss: 0.1633848
[Epoch 11] ogbg-moltox21: 0.726886 val loss: 0.298799
[Epoch 11] ogbg-moltox21: 0.713406 test loss: 0.302746
[Epoch 12; Iter    11/  209] train: loss: 0.1875799
[Epoch 12; Iter    41/  209] train: loss: 0.0946233
[Epoch 12; Iter    71/  209] train: loss: 0.3032030
[Epoch 12; Iter   101/  209] train: loss: 0.1841286
[Epoch 12; Iter   131/  209] train: loss: 0.1885041
[Epoch 12; Iter   161/  209] train: loss: 0.1759029
[Epoch 12; Iter   191/  209] train: loss: 0.1158809
[Epoch 12] ogbg-moltox21: 0.745722 val loss: 0.278504
[Epoch 12] ogbg-moltox21: 0.728132 test loss: 0.280205
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.05/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.05_6_26-05_09-20-25
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.05
logdir: runs/static_noise/3DInfomax/tox21/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6929629
[Epoch 1; Iter    60/  209] train: loss: 0.6925944
[Epoch 1; Iter    90/  209] train: loss: 0.6918793
[Epoch 1; Iter   120/  209] train: loss: 0.6927221
[Epoch 1; Iter   150/  209] train: loss: 0.6924546
[Epoch 1; Iter   180/  209] train: loss: 0.6922932
[Epoch 1] ogbg-moltox21: 0.481636 val loss: 0.693895
[Epoch 1] ogbg-moltox21: 0.491825 test loss: 0.693629
[Epoch 2; Iter     1/  209] train: loss: 0.6923167
[Epoch 2; Iter    31/  209] train: loss: 0.6924254
[Epoch 2; Iter    61/  209] train: loss: 0.6921196
[Epoch 2; Iter    91/  209] train: loss: 0.6919711
[Epoch 2; Iter   121/  209] train: loss: 0.6918997
[Epoch 2; Iter   151/  209] train: loss: 0.6911164
[Epoch 2; Iter   181/  209] train: loss: 0.6913764
[Epoch 2] ogbg-moltox21: 0.489044 val loss: 0.691960
[Epoch 2] ogbg-moltox21: 0.498991 test loss: 0.691657
[Epoch 3; Iter     2/  209] train: loss: 0.6908256
[Epoch 3; Iter    32/  209] train: loss: 0.6895339
[Epoch 3; Iter    62/  209] train: loss: 0.6909479
[Epoch 3; Iter    92/  209] train: loss: 0.6906089
[Epoch 3; Iter   122/  209] train: loss: 0.6900052
[Epoch 3; Iter   152/  209] train: loss: 0.6891996
[Epoch 3; Iter   182/  209] train: loss: 0.6888191
[Epoch 3] ogbg-moltox21: 0.492847 val loss: 0.689808
[Epoch 3] ogbg-moltox21: 0.502729 test loss: 0.689541
[Epoch 4; Iter     3/  209] train: loss: 0.6876016
[Epoch 4; Iter    33/  209] train: loss: 0.6879343
[Epoch 4; Iter    63/  209] train: loss: 0.6873501
[Epoch 4; Iter    93/  209] train: loss: 0.6834694
[Epoch 4; Iter   123/  209] train: loss: 0.6591497
[Epoch 4; Iter   153/  209] train: loss: 0.6288101
[Epoch 4; Iter   183/  209] train: loss: 0.6112331
[Epoch 4] ogbg-moltox21: 0.641476 val loss: 0.746243
[Epoch 4] ogbg-moltox21: 0.625877 test loss: 0.749749
[Epoch 5; Iter     4/  209] train: loss: 0.5413189
[Epoch 5; Iter    34/  209] train: loss: 0.4775932
[Epoch 5; Iter    64/  209] train: loss: 0.4334348
[Epoch 5; Iter    94/  209] train: loss: 0.4014533
[Epoch 5; Iter   124/  209] train: loss: 0.3473258
[Epoch 5; Iter   154/  209] train: loss: 0.2800767
[Epoch 5; Iter   184/  209] train: loss: 0.2396919
[Epoch 5] ogbg-moltox21: 0.718205 val loss: 0.316489
[Epoch 5] ogbg-moltox21: 0.701770 test loss: 0.311766
[Epoch 6; Iter     5/  209] train: loss: 0.2199581
[Epoch 6; Iter    35/  209] train: loss: 0.1666384
[Epoch 6; Iter    65/  209] train: loss: 0.2025549
[Epoch 6; Iter    95/  209] train: loss: 0.2015108
[Epoch 6; Iter   125/  209] train: loss: 0.1625958
[Epoch 6; Iter   155/  209] train: loss: 0.2187028
[Epoch 6; Iter   185/  209] train: loss: 0.1903260
[Epoch 6] ogbg-moltox21: 0.717219 val loss: 0.280754
[Epoch 6] ogbg-moltox21: 0.693504 test loss: 0.294396
[Epoch 7; Iter     6/  209] train: loss: 0.1710513
[Epoch 7; Iter    36/  209] train: loss: 0.2343653
[Epoch 7; Iter    66/  209] train: loss: 0.1651722
[Epoch 7; Iter    96/  209] train: loss: 0.2665967
[Epoch 7; Iter   126/  209] train: loss: 0.1703972
[Epoch 7; Iter   156/  209] train: loss: 0.2472087
[Epoch 7; Iter   186/  209] train: loss: 0.2301718
[Epoch 7] ogbg-moltox21: 0.702001 val loss: 0.531654
[Epoch 7] ogbg-moltox21: 0.691468 test loss: 0.659934
[Epoch 8; Iter     7/  209] train: loss: 0.1903589
[Epoch 8; Iter    37/  209] train: loss: 0.2308171
[Epoch 8; Iter    67/  209] train: loss: 0.1579218
[Epoch 8; Iter    97/  209] train: loss: 0.2271304
[Epoch 8; Iter   127/  209] train: loss: 0.2643709
[Epoch 8; Iter   157/  209] train: loss: 0.1730855
[Epoch 8; Iter   187/  209] train: loss: 0.2437115
[Epoch 8] ogbg-moltox21: 0.694167 val loss: 0.632344
[Epoch 8] ogbg-moltox21: 0.654099 test loss: 0.801716
[Epoch 9; Iter     8/  209] train: loss: 0.2338261
[Epoch 9; Iter    38/  209] train: loss: 0.1755629
[Epoch 9; Iter    68/  209] train: loss: 0.1734850
[Epoch 9; Iter    98/  209] train: loss: 0.2689438
[Epoch 9; Iter   128/  209] train: loss: 0.2282344
[Epoch 9; Iter   158/  209] train: loss: 0.1792756
[Epoch 9; Iter   188/  209] train: loss: 0.1766528
[Epoch 9] ogbg-moltox21: 0.705362 val loss: 0.432009
[Epoch 9] ogbg-moltox21: 0.701376 test loss: 0.454834
[Epoch 10; Iter     9/  209] train: loss: 0.2081209
[Epoch 10; Iter    39/  209] train: loss: 0.1985206
[Epoch 10; Iter    69/  209] train: loss: 0.1920882
[Epoch 10; Iter    99/  209] train: loss: 0.1554359
[Epoch 10; Iter   129/  209] train: loss: 0.1405185
[Epoch 10; Iter   159/  209] train: loss: 0.1196217
[Epoch 10; Iter   189/  209] train: loss: 0.1746055
[Epoch 10] ogbg-moltox21: 0.638662 val loss: 1.443535
[Epoch 10] ogbg-moltox21: 0.652490 test loss: 1.757622
[Epoch 11; Iter    10/  209] train: loss: 0.2208397
[Epoch 11; Iter    40/  209] train: loss: 0.2137790
[Epoch 11; Iter    70/  209] train: loss: 0.2298336
[Epoch 11; Iter   100/  209] train: loss: 0.2813523
[Epoch 11; Iter   130/  209] train: loss: 0.2319995
[Epoch 11; Iter   160/  209] train: loss: 0.2049147
[Epoch 11; Iter   190/  209] train: loss: 0.1493684
[Epoch 11] ogbg-moltox21: 0.728871 val loss: 0.294711
[Epoch 11] ogbg-moltox21: 0.704824 test loss: 0.304611
[Epoch 12; Iter    11/  209] train: loss: 0.1212794
[Epoch 12; Iter    41/  209] train: loss: 0.2862574
[Epoch 12; Iter    71/  209] train: loss: 0.1965739
[Epoch 12; Iter   101/  209] train: loss: 0.2055825
[Epoch 12; Iter   131/  209] train: loss: 0.2053539
[Epoch 12; Iter   161/  209] train: loss: 0.2142612
[Epoch 12; Iter   191/  209] train: loss: 0.1749258
[Epoch 12] ogbg-moltox21: 0.758890 val loss: 0.274433
[Epoch 12] ogbg-moltox21: 0.741745 test loss: 0.287787
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.1/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.1_6_26-05_09-20-50
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.1
logdir: runs/static_noise/3DInfomax/tox21/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6927984
[Epoch 1; Iter    60/  209] train: loss: 0.6925251
[Epoch 1; Iter    90/  209] train: loss: 0.6923130
[Epoch 1; Iter   120/  209] train: loss: 0.6933286
[Epoch 1; Iter   150/  209] train: loss: 0.6926631
[Epoch 1; Iter   180/  209] train: loss: 0.6925684
[Epoch 1] ogbg-moltox21: 0.490641 val loss: 0.694298
[Epoch 1] ogbg-moltox21: 0.492785 test loss: 0.694140
[Epoch 2; Iter     1/  209] train: loss: 0.6922970
[Epoch 2; Iter    31/  209] train: loss: 0.6923405
[Epoch 2; Iter    61/  209] train: loss: 0.6926140
[Epoch 2; Iter    91/  209] train: loss: 0.6922640
[Epoch 2; Iter   121/  209] train: loss: 0.6915530
[Epoch 2; Iter   151/  209] train: loss: 0.6913529
[Epoch 2; Iter   181/  209] train: loss: 0.6915599
[Epoch 2] ogbg-moltox21: 0.498261 val loss: 0.692002
[Epoch 2] ogbg-moltox21: 0.505234 test loss: 0.691732
[Epoch 3; Iter     2/  209] train: loss: 0.6906404
[Epoch 3; Iter    32/  209] train: loss: 0.6903687
[Epoch 3; Iter    62/  209] train: loss: 0.6906966
[Epoch 3; Iter    92/  209] train: loss: 0.6907074
[Epoch 3; Iter   122/  209] train: loss: 0.6898042
[Epoch 3; Iter   152/  209] train: loss: 0.6898038
[Epoch 3; Iter   182/  209] train: loss: 0.6882606
[Epoch 3] ogbg-moltox21: 0.497861 val loss: 0.690181
[Epoch 3] ogbg-moltox21: 0.501459 test loss: 0.690020
[Epoch 4; Iter     3/  209] train: loss: 0.6870417
[Epoch 4; Iter    33/  209] train: loss: 0.6880803
[Epoch 4; Iter    63/  209] train: loss: 0.6867715
[Epoch 4; Iter    93/  209] train: loss: 0.6838684
[Epoch 4; Iter   123/  209] train: loss: 0.6599978
[Epoch 4; Iter   153/  209] train: loss: 0.6289894
[Epoch 4; Iter   183/  209] train: loss: 0.6171597
[Epoch 4] ogbg-moltox21: 0.651316 val loss: 0.686363
[Epoch 4] ogbg-moltox21: 0.638073 test loss: 0.687907
[Epoch 5; Iter     4/  209] train: loss: 0.5508221
[Epoch 5; Iter    34/  209] train: loss: 0.4870223
[Epoch 5; Iter    64/  209] train: loss: 0.4347869
[Epoch 5; Iter    94/  209] train: loss: 0.4111985
[Epoch 5; Iter   124/  209] train: loss: 0.3498326
[Epoch 5; Iter   154/  209] train: loss: 0.2837550
[Epoch 5; Iter   184/  209] train: loss: 0.2372311
[Epoch 5] ogbg-moltox21: 0.699502 val loss: 0.538346
[Epoch 5] ogbg-moltox21: 0.688843 test loss: 0.475624
[Epoch 6; Iter     5/  209] train: loss: 0.2262186
[Epoch 6; Iter    35/  209] train: loss: 0.1665666
[Epoch 6; Iter    65/  209] train: loss: 0.2099870
[Epoch 6; Iter    95/  209] train: loss: 0.2109568
[Epoch 6; Iter   125/  209] train: loss: 0.1665227
[Epoch 6; Iter   155/  209] train: loss: 0.2202230
[Epoch 6; Iter   185/  209] train: loss: 0.1876535
[Epoch 6] ogbg-moltox21: 0.679088 val loss: 0.451680
[Epoch 6] ogbg-moltox21: 0.674986 test loss: 0.581308
[Epoch 7; Iter     6/  209] train: loss: 0.1723569
[Epoch 7; Iter    36/  209] train: loss: 0.2389444
[Epoch 7; Iter    66/  209] train: loss: 0.1709893
[Epoch 7; Iter    96/  209] train: loss: 0.2796284
[Epoch 7; Iter   126/  209] train: loss: 0.1913489
[Epoch 7; Iter   156/  209] train: loss: 0.2381376
[Epoch 7; Iter   186/  209] train: loss: 0.2356668
[Epoch 7] ogbg-moltox21: 0.704998 val loss: 2.666799
[Epoch 7] ogbg-moltox21: 0.703330 test loss: 3.072601
[Epoch 8; Iter     7/  209] train: loss: 0.1927502
[Epoch 8; Iter    37/  209] train: loss: 0.2389133
[Epoch 8; Iter    67/  209] train: loss: 0.1596349
[Epoch 8; Iter    97/  209] train: loss: 0.2318292
[Epoch 8; Iter   127/  209] train: loss: 0.2920374
[Epoch 8; Iter   157/  209] train: loss: 0.1750448
[Epoch 8; Iter   187/  209] train: loss: 0.2334453
[Epoch 8] ogbg-moltox21: 0.745786 val loss: 0.878138
[Epoch 8] ogbg-moltox21: 0.699644 test loss: 1.048923
[Epoch 9; Iter     8/  209] train: loss: 0.2387279
[Epoch 9; Iter    38/  209] train: loss: 0.1672754
[Epoch 9; Iter    68/  209] train: loss: 0.1846340
[Epoch 9; Iter    98/  209] train: loss: 0.2545855
[Epoch 9; Iter   128/  209] train: loss: 0.2064303
[Epoch 9; Iter   158/  209] train: loss: 0.1597867
[Epoch 9; Iter   188/  209] train: loss: 0.1549139
[Epoch 9] ogbg-moltox21: 0.753177 val loss: 1.047250
[Epoch 9] ogbg-moltox21: 0.705138 test loss: 1.926066
[Epoch 10; Iter     9/  209] train: loss: 0.2356520
[Epoch 10; Iter    39/  209] train: loss: 0.1756666
[Epoch 10; Iter    69/  209] train: loss: 0.2056729
[Epoch 10; Iter    99/  209] train: loss: 0.1502436
[Epoch 10; Iter   129/  209] train: loss: 0.1492040
[Epoch 10; Iter   159/  209] train: loss: 0.1098515
[Epoch 10; Iter   189/  209] train: loss: 0.1796560
[Epoch 10] ogbg-moltox21: 0.736382 val loss: 1.396930
[Epoch 10] ogbg-moltox21: 0.715611 test loss: 2.991109
[Epoch 11; Iter    10/  209] train: loss: 0.2316942
[Epoch 11; Iter    40/  209] train: loss: 0.2120705
[Epoch 11; Iter    70/  209] train: loss: 0.2079017
[Epoch 11; Iter   100/  209] train: loss: 0.2666579
[Epoch 11; Iter   130/  209] train: loss: 0.2064924
[Epoch 11; Iter   160/  209] train: loss: 0.1858727
[Epoch 11; Iter   190/  209] train: loss: 0.1741040
[Epoch 11] ogbg-moltox21: 0.746008 val loss: 0.402398
[Epoch 11] ogbg-moltox21: 0.714004 test loss: 0.547838
[Epoch 12; Iter    11/  209] train: loss: 0.1039229
[Epoch 12; Iter    41/  209] train: loss: 0.2819742
[Epoch 12; Iter    71/  209] train: loss: 0.1732507
[Epoch 12; Iter   101/  209] train: loss: 0.1873298
[Epoch 12; Iter   131/  209] train: loss: 0.2055344
[Epoch 12; Iter   161/  209] train: loss: 0.2283688
[Epoch 12; Iter   191/  209] train: loss: 0.1655002
[Epoch 12] ogbg-moltox21: 0.753592 val loss: 0.485737
[Epoch 12] ogbg-moltox21: 0.746556 test loss: 0.335947
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.1/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.1_5_26-05_09-20-50
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.1
logdir: runs/static_noise/3DInfomax/tox21/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6935356
[Epoch 1; Iter    60/  209] train: loss: 0.6929417
[Epoch 1; Iter    90/  209] train: loss: 0.6925978
[Epoch 1; Iter   120/  209] train: loss: 0.6923842
[Epoch 1; Iter   150/  209] train: loss: 0.6922449
[Epoch 1; Iter   180/  209] train: loss: 0.6934702
[Epoch 1] ogbg-moltox21: 0.463031 val loss: 0.692459
[Epoch 1] ogbg-moltox21: 0.461745 test loss: 0.692145
[Epoch 2; Iter     1/  209] train: loss: 0.6924150
[Epoch 2; Iter    31/  209] train: loss: 0.6923827
[Epoch 2; Iter    61/  209] train: loss: 0.6912388
[Epoch 2; Iter    91/  209] train: loss: 0.6918786
[Epoch 2; Iter   121/  209] train: loss: 0.6921480
[Epoch 2; Iter   151/  209] train: loss: 0.6915842
[Epoch 2; Iter   181/  209] train: loss: 0.6915062
[Epoch 2] ogbg-moltox21: 0.469050 val loss: 0.691205
[Epoch 2] ogbg-moltox21: 0.469913 test loss: 0.690859
[Epoch 3; Iter     2/  209] train: loss: 0.6906022
[Epoch 3; Iter    32/  209] train: loss: 0.6909218
[Epoch 3; Iter    62/  209] train: loss: 0.6893541
[Epoch 3; Iter    92/  209] train: loss: 0.6887823
[Epoch 3; Iter   122/  209] train: loss: 0.6895957
[Epoch 3; Iter   152/  209] train: loss: 0.6881186
[Epoch 3; Iter   182/  209] train: loss: 0.6878877
[Epoch 3] ogbg-moltox21: 0.477105 val loss: 0.688546
[Epoch 3] ogbg-moltox21: 0.474656 test loss: 0.688244
[Epoch 4; Iter     3/  209] train: loss: 0.6885374
[Epoch 4; Iter    33/  209] train: loss: 0.6871979
[Epoch 4; Iter    63/  209] train: loss: 0.6866620
[Epoch 4; Iter    93/  209] train: loss: 0.6809418
[Epoch 4; Iter   123/  209] train: loss: 0.6599492
[Epoch 4; Iter   153/  209] train: loss: 0.6230160
[Epoch 4; Iter   183/  209] train: loss: 0.6012461
[Epoch 4] ogbg-moltox21: 0.655482 val loss: 0.611549
[Epoch 4] ogbg-moltox21: 0.647103 test loss: 0.607681
[Epoch 5; Iter     4/  209] train: loss: 0.5373058
[Epoch 5; Iter    34/  209] train: loss: 0.4605927
[Epoch 5; Iter    64/  209] train: loss: 0.4264662
[Epoch 5; Iter    94/  209] train: loss: 0.3555440
[Epoch 5; Iter   124/  209] train: loss: 0.3128177
[Epoch 5; Iter   154/  209] train: loss: 0.3170739
[Epoch 5; Iter   184/  209] train: loss: 0.2537515
[Epoch 5] ogbg-moltox21: 0.698654 val loss: 0.424664
[Epoch 5] ogbg-moltox21: 0.677469 test loss: 0.431939
[Epoch 6; Iter     5/  209] train: loss: 0.3201577
[Epoch 6; Iter    35/  209] train: loss: 0.2471761
[Epoch 6; Iter    65/  209] train: loss: 0.2547733
[Epoch 6; Iter    95/  209] train: loss: 0.1691547
[Epoch 6; Iter   125/  209] train: loss: 0.2485800
[Epoch 6; Iter   155/  209] train: loss: 0.2362617
[Epoch 6; Iter   185/  209] train: loss: 0.1984199
[Epoch 6] ogbg-moltox21: 0.688068 val loss: 0.335613
[Epoch 6] ogbg-moltox21: 0.667153 test loss: 0.369443
[Epoch 7; Iter     6/  209] train: loss: 0.1630409
[Epoch 7; Iter    36/  209] train: loss: 0.1506927
[Epoch 7; Iter    66/  209] train: loss: 0.2122110
[Epoch 7; Iter    96/  209] train: loss: 0.2465687
[Epoch 7; Iter   126/  209] train: loss: 0.3245851
[Epoch 7; Iter   156/  209] train: loss: 0.1739272
[Epoch 7; Iter   186/  209] train: loss: 0.1853318
[Epoch 7] ogbg-moltox21: 0.671909 val loss: 0.297022
[Epoch 7] ogbg-moltox21: 0.672497 test loss: 0.298887
[Epoch 8; Iter     7/  209] train: loss: 0.2317822
[Epoch 8; Iter    37/  209] train: loss: 0.1561652
[Epoch 8; Iter    67/  209] train: loss: 0.1577469
[Epoch 8; Iter    97/  209] train: loss: 0.2104528
[Epoch 8; Iter   127/  209] train: loss: 0.2527861
[Epoch 8; Iter   157/  209] train: loss: 0.1230683
[Epoch 8; Iter   187/  209] train: loss: 0.3209329
[Epoch 8] ogbg-moltox21: 0.710110 val loss: 0.978749
[Epoch 8] ogbg-moltox21: 0.696646 test loss: 1.514046
[Epoch 9; Iter     8/  209] train: loss: 0.1928072
[Epoch 9; Iter    38/  209] train: loss: 0.2141496
[Epoch 9; Iter    68/  209] train: loss: 0.0963675
[Epoch 9; Iter    98/  209] train: loss: 0.1836852
[Epoch 9; Iter   128/  209] train: loss: 0.2183542
[Epoch 9; Iter   158/  209] train: loss: 0.1562956
[Epoch 9; Iter   188/  209] train: loss: 0.2205939
[Epoch 9] ogbg-moltox21: 0.729019 val loss: 0.275620
[Epoch 9] ogbg-moltox21: 0.694980 test loss: 0.282271
[Epoch 10; Iter     9/  209] train: loss: 0.1512212
[Epoch 10; Iter    39/  209] train: loss: 0.2403895
[Epoch 10; Iter    69/  209] train: loss: 0.2616905
[Epoch 10; Iter    99/  209] train: loss: 0.1612388
[Epoch 10; Iter   129/  209] train: loss: 0.1554622
[Epoch 10; Iter   159/  209] train: loss: 0.2286237
[Epoch 10; Iter   189/  209] train: loss: 0.1756463
[Epoch 10] ogbg-moltox21: 0.769794 val loss: 0.267452
[Epoch 10] ogbg-moltox21: 0.729636 test loss: 0.279098
[Epoch 11; Iter    10/  209] train: loss: 0.1825083
[Epoch 11; Iter    40/  209] train: loss: 0.1866903
[Epoch 11; Iter    70/  209] train: loss: 0.1399551
[Epoch 11; Iter   100/  209] train: loss: 0.1645878
[Epoch 11; Iter   130/  209] train: loss: 0.2008939
[Epoch 11; Iter   160/  209] train: loss: 0.1866331
[Epoch 11; Iter   190/  209] train: loss: 0.1844411
[Epoch 11] ogbg-moltox21: 0.759455 val loss: 0.271225
[Epoch 11] ogbg-moltox21: 0.734960 test loss: 0.284698
[Epoch 12; Iter    11/  209] train: loss: 0.1943178
[Epoch 12; Iter    41/  209] train: loss: 0.2106476
[Epoch 12; Iter    71/  209] train: loss: 0.2194684
[Epoch 12; Iter   101/  209] train: loss: 0.1312569
[Epoch 12; Iter   131/  209] train: loss: 0.2108305
[Epoch 12; Iter   161/  209] train: loss: 0.1970806
[Epoch 12; Iter   191/  209] train: loss: 0.2246216
[Epoch 12] ogbg-moltox21: 0.749365 val loss: 0.477232
[Epoch 12] ogbg-moltox21: 0.714161 test loss: 0.677984
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.2/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.2_4_26-05_09-21-16
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.2
logdir: runs/static_noise/3DInfomax/tox21/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6923885
[Epoch 1; Iter    60/  209] train: loss: 0.6936584
[Epoch 1; Iter    90/  209] train: loss: 0.6932673
[Epoch 1; Iter   120/  209] train: loss: 0.6929067
[Epoch 1; Iter   150/  209] train: loss: 0.6924925
[Epoch 1; Iter   180/  209] train: loss: 0.6925820
[Epoch 1] ogbg-moltox21: 0.492917 val loss: 0.695993
[Epoch 1] ogbg-moltox21: 0.516381 test loss: 0.695151
[Epoch 2; Iter     1/  209] train: loss: 0.6920633
[Epoch 2; Iter    31/  209] train: loss: 0.6925802
[Epoch 2; Iter    61/  209] train: loss: 0.6917838
[Epoch 2; Iter    91/  209] train: loss: 0.6919253
[Epoch 2; Iter   121/  209] train: loss: 0.6915863
[Epoch 2; Iter   151/  209] train: loss: 0.6920012
[Epoch 2; Iter   181/  209] train: loss: 0.6910434
[Epoch 2] ogbg-moltox21: 0.494804 val loss: 0.695049
[Epoch 2] ogbg-moltox21: 0.520334 test loss: 0.694151
[Epoch 3; Iter     2/  209] train: loss: 0.6911035
[Epoch 3; Iter    32/  209] train: loss: 0.6909794
[Epoch 3; Iter    62/  209] train: loss: 0.6896636
[Epoch 3; Iter    92/  209] train: loss: 0.6904374
[Epoch 3; Iter   122/  209] train: loss: 0.6897166
[Epoch 3; Iter   152/  209] train: loss: 0.6883680
[Epoch 3; Iter   182/  209] train: loss: 0.6883699
[Epoch 3] ogbg-moltox21: 0.494252 val loss: 0.693206
[Epoch 3] ogbg-moltox21: 0.523455 test loss: 0.692314
[Epoch 4; Iter     3/  209] train: loss: 0.6884207
[Epoch 4; Iter    33/  209] train: loss: 0.6879624
[Epoch 4; Iter    63/  209] train: loss: 0.6884332
[Epoch 4; Iter    93/  209] train: loss: 0.6822217
[Epoch 4; Iter   123/  209] train: loss: 0.6634438
[Epoch 4; Iter   153/  209] train: loss: 0.6361369
[Epoch 4; Iter   183/  209] train: loss: 0.5872302
[Epoch 4] ogbg-moltox21: 0.663576 val loss: 0.623243
[Epoch 4] ogbg-moltox21: 0.638300 test loss: 0.619585
[Epoch 5; Iter     4/  209] train: loss: 0.5367348
[Epoch 5; Iter    34/  209] train: loss: 0.4689777
[Epoch 5; Iter    64/  209] train: loss: 0.4372408
[Epoch 5; Iter    94/  209] train: loss: 0.3854051
[Epoch 5; Iter   124/  209] train: loss: 0.4072964
[Epoch 5; Iter   154/  209] train: loss: 0.2444019
[Epoch 5; Iter   184/  209] train: loss: 0.2283477
[Epoch 5] ogbg-moltox21: 0.638034 val loss: 0.442821
[Epoch 5] ogbg-moltox21: 0.645748 test loss: 0.397264
[Epoch 6; Iter     5/  209] train: loss: 0.2126102
[Epoch 6; Iter    35/  209] train: loss: 0.2346772
[Epoch 6; Iter    65/  209] train: loss: 0.2330586
[Epoch 6; Iter    95/  209] train: loss: 0.2348105
[Epoch 6; Iter   125/  209] train: loss: 0.3344202
[Epoch 6; Iter   155/  209] train: loss: 0.2553732
[Epoch 6; Iter   185/  209] train: loss: 0.2631616
[Epoch 6] ogbg-moltox21: 0.679689 val loss: 0.732922
[Epoch 6] ogbg-moltox21: 0.670049 test loss: 0.484587
[Epoch 7; Iter     6/  209] train: loss: 0.3331020
[Epoch 7; Iter    36/  209] train: loss: 0.2208612
[Epoch 7; Iter    66/  209] train: loss: 0.2400623
[Epoch 7; Iter    96/  209] train: loss: 0.2108468
[Epoch 7; Iter   126/  209] train: loss: 0.1998239
[Epoch 7; Iter   156/  209] train: loss: 0.2283355
[Epoch 7; Iter   186/  209] train: loss: 0.1924071
[Epoch 7] ogbg-moltox21: 0.655720 val loss: 1.951763
[Epoch 7] ogbg-moltox21: 0.642702 test loss: 1.665823
[Epoch 8; Iter     7/  209] train: loss: 0.1336621
[Epoch 8; Iter    37/  209] train: loss: 0.2242327
[Epoch 8; Iter    67/  209] train: loss: 0.2881016
[Epoch 8; Iter    97/  209] train: loss: 0.1918489
[Epoch 8; Iter   127/  209] train: loss: 0.2699790
[Epoch 8; Iter   157/  209] train: loss: 0.1792665
[Epoch 8; Iter   187/  209] train: loss: 0.2032894
[Epoch 8] ogbg-moltox21: 0.725914 val loss: 0.326616
[Epoch 8] ogbg-moltox21: 0.707501 test loss: 0.322152
[Epoch 9; Iter     8/  209] train: loss: 0.2772762
[Epoch 9; Iter    38/  209] train: loss: 0.1607275
[Epoch 9; Iter    68/  209] train: loss: 0.2570524
[Epoch 9; Iter    98/  209] train: loss: 0.2015611
[Epoch 9; Iter   128/  209] train: loss: 0.1834166
[Epoch 9; Iter   158/  209] train: loss: 0.1991144
[Epoch 9; Iter   188/  209] train: loss: 0.2337702
[Epoch 9] ogbg-moltox21: 0.739769 val loss: 0.354757
[Epoch 9] ogbg-moltox21: 0.701805 test loss: 0.370764
[Epoch 10; Iter     9/  209] train: loss: 0.2470512
[Epoch 10; Iter    39/  209] train: loss: 0.2061551
[Epoch 10; Iter    69/  209] train: loss: 0.2006350
[Epoch 10; Iter    99/  209] train: loss: 0.2032210
[Epoch 10; Iter   129/  209] train: loss: 0.2241928
[Epoch 10; Iter   159/  209] train: loss: 0.1630352
[Epoch 10; Iter   189/  209] train: loss: 0.2266231
[Epoch 10] ogbg-moltox21: 0.713188 val loss: 0.438157
[Epoch 10] ogbg-moltox21: 0.706369 test loss: 0.911365
[Epoch 11; Iter    10/  209] train: loss: 0.2055221
[Epoch 11; Iter    40/  209] train: loss: 0.1675498
[Epoch 11; Iter    70/  209] train: loss: 0.1818284
[Epoch 11; Iter   100/  209] train: loss: 0.3353120
[Epoch 11; Iter   130/  209] train: loss: 0.1990479
[Epoch 11; Iter   160/  209] train: loss: 0.2561346
[Epoch 11; Iter   190/  209] train: loss: 0.1749020
[Epoch 11] ogbg-moltox21: 0.754389 val loss: 0.305757
[Epoch 11] ogbg-moltox21: 0.693526 test loss: 0.413537
[Epoch 12; Iter    11/  209] train: loss: 0.1962418
[Epoch 12; Iter    41/  209] train: loss: 0.1076997
[Epoch 12; Iter    71/  209] train: loss: 0.3042381
[Epoch 12; Iter   101/  209] train: loss: 0.1776996
[Epoch 12; Iter   131/  209] train: loss: 0.2111315
[Epoch 12; Iter   161/  209] train: loss: 0.1775699
[Epoch 12; Iter   191/  209] train: loss: 0.1326761
[Epoch 12] ogbg-moltox21: 0.734180 val loss: 0.540386
[Epoch 12] ogbg-moltox21: 0.704655 test loss: 0.527296
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.2/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.2_6_26-05_09-21-08
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.2
logdir: runs/static_noise/3DInfomax/tox21/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6931930
[Epoch 1; Iter    60/  209] train: loss: 0.6927495
[Epoch 1; Iter    90/  209] train: loss: 0.6920761
[Epoch 1; Iter   120/  209] train: loss: 0.6932475
[Epoch 1; Iter   150/  209] train: loss: 0.6926106
[Epoch 1; Iter   180/  209] train: loss: 0.6921585
[Epoch 1] ogbg-moltox21: 0.494741 val loss: 0.694365
[Epoch 1] ogbg-moltox21: 0.485457 test loss: 0.694231
[Epoch 2; Iter     1/  209] train: loss: 0.6918170
[Epoch 2; Iter    31/  209] train: loss: 0.6924067
[Epoch 2; Iter    61/  209] train: loss: 0.6928442
[Epoch 2; Iter    91/  209] train: loss: 0.6921602
[Epoch 2; Iter   121/  209] train: loss: 0.6919066
[Epoch 2; Iter   151/  209] train: loss: 0.6912316
[Epoch 2; Iter   181/  209] train: loss: 0.6908056
[Epoch 2] ogbg-moltox21: 0.493769 val loss: 0.692036
[Epoch 2] ogbg-moltox21: 0.487845 test loss: 0.691838
[Epoch 3; Iter     2/  209] train: loss: 0.6906753
[Epoch 3; Iter    32/  209] train: loss: 0.6904809
[Epoch 3; Iter    62/  209] train: loss: 0.6904571
[Epoch 3; Iter    92/  209] train: loss: 0.6908609
[Epoch 3; Iter   122/  209] train: loss: 0.6897160
[Epoch 3; Iter   152/  209] train: loss: 0.6899306
[Epoch 3; Iter   182/  209] train: loss: 0.6885128
[Epoch 3] ogbg-moltox21: 0.497492 val loss: 0.690090
[Epoch 3] ogbg-moltox21: 0.489074 test loss: 0.689944
[Epoch 4; Iter     3/  209] train: loss: 0.6870858
[Epoch 4; Iter    33/  209] train: loss: 0.6881624
[Epoch 4; Iter    63/  209] train: loss: 0.6873323
[Epoch 4; Iter    93/  209] train: loss: 0.6835703
[Epoch 4; Iter   123/  209] train: loss: 0.6629352
[Epoch 4; Iter   153/  209] train: loss: 0.6308540
[Epoch 4; Iter   183/  209] train: loss: 0.6193014
[Epoch 4] ogbg-moltox21: 0.620505 val loss: 0.790494
[Epoch 4] ogbg-moltox21: 0.608429 test loss: 0.801083
[Epoch 5; Iter     4/  209] train: loss: 0.5595444
[Epoch 5; Iter    34/  209] train: loss: 0.4925205
[Epoch 5; Iter    64/  209] train: loss: 0.4441846
[Epoch 5; Iter    94/  209] train: loss: 0.4169403
[Epoch 5; Iter   124/  209] train: loss: 0.3535364
[Epoch 5; Iter   154/  209] train: loss: 0.2887124
[Epoch 5; Iter   184/  209] train: loss: 0.2395239
[Epoch 5] ogbg-moltox21: 0.663361 val loss: 0.334874
[Epoch 5] ogbg-moltox21: 0.664593 test loss: 0.334549
[Epoch 6; Iter     5/  209] train: loss: 0.2286313
[Epoch 6; Iter    35/  209] train: loss: 0.1640162
[Epoch 6; Iter    65/  209] train: loss: 0.2163479
[Epoch 6; Iter    95/  209] train: loss: 0.2010071
[Epoch 6; Iter   125/  209] train: loss: 0.1667071
[Epoch 6; Iter   155/  209] train: loss: 0.2143660
[Epoch 6; Iter   185/  209] train: loss: 0.1910190
[Epoch 6] ogbg-moltox21: 0.576804 val loss: 0.533158
[Epoch 6] ogbg-moltox21: 0.585011 test loss: 0.472859
[Epoch 7; Iter     6/  209] train: loss: 0.1901182
[Epoch 7; Iter    36/  209] train: loss: 0.2415909
[Epoch 7; Iter    66/  209] train: loss: 0.1782849
[Epoch 7; Iter    96/  209] train: loss: 0.2925436
[Epoch 7; Iter   126/  209] train: loss: 0.2061321
[Epoch 7; Iter   156/  209] train: loss: 0.2404580
[Epoch 7; Iter   186/  209] train: loss: 0.2413997
[Epoch 7] ogbg-moltox21: 0.673060 val loss: 0.586064
[Epoch 7] ogbg-moltox21: 0.685228 test loss: 0.467901
[Epoch 8; Iter     7/  209] train: loss: 0.2156062
[Epoch 8; Iter    37/  209] train: loss: 0.2303149
[Epoch 8; Iter    67/  209] train: loss: 0.1626231
[Epoch 8; Iter    97/  209] train: loss: 0.2545433
[Epoch 8; Iter   127/  209] train: loss: 0.2834341
[Epoch 8; Iter   157/  209] train: loss: 0.1664582
[Epoch 8; Iter   187/  209] train: loss: 0.2184104
[Epoch 8] ogbg-moltox21: 0.705879 val loss: 0.382763
[Epoch 8] ogbg-moltox21: 0.667837 test loss: 0.446950
[Epoch 9; Iter     8/  209] train: loss: 0.2518390
[Epoch 9; Iter    38/  209] train: loss: 0.1660723
[Epoch 9; Iter    68/  209] train: loss: 0.1660698
[Epoch 9; Iter    98/  209] train: loss: 0.2600600
[Epoch 9; Iter   128/  209] train: loss: 0.2140200
[Epoch 9; Iter   158/  209] train: loss: 0.1594999
[Epoch 9; Iter   188/  209] train: loss: 0.1541668
[Epoch 9] ogbg-moltox21: 0.745077 val loss: 0.317387
[Epoch 9] ogbg-moltox21: 0.699221 test loss: 0.578281
[Epoch 10; Iter     9/  209] train: loss: 0.2154996
[Epoch 10; Iter    39/  209] train: loss: 0.1776069
[Epoch 10; Iter    69/  209] train: loss: 0.1974728
[Epoch 10; Iter    99/  209] train: loss: 0.1546012
[Epoch 10; Iter   129/  209] train: loss: 0.1499750
[Epoch 10; Iter   159/  209] train: loss: 0.1203451
[Epoch 10; Iter   189/  209] train: loss: 0.1821817
[Epoch 10] ogbg-moltox21: 0.732836 val loss: 1.431230
[Epoch 10] ogbg-moltox21: 0.699905 test loss: 2.917162
[Epoch 11; Iter    10/  209] train: loss: 0.2232886
[Epoch 11; Iter    40/  209] train: loss: 0.1966255
[Epoch 11; Iter    70/  209] train: loss: 0.2141611
[Epoch 11; Iter   100/  209] train: loss: 0.2995809
[Epoch 11; Iter   130/  209] train: loss: 0.1975701
[Epoch 11; Iter   160/  209] train: loss: 0.1958130
[Epoch 11; Iter   190/  209] train: loss: 0.1459361
[Epoch 11] ogbg-moltox21: 0.748158 val loss: 1.564651
[Epoch 11] ogbg-moltox21: 0.704762 test loss: 3.758908
[Epoch 12; Iter    11/  209] train: loss: 0.1138065
[Epoch 12; Iter    41/  209] train: loss: 0.2785541
[Epoch 12; Iter    71/  209] train: loss: 0.1910308
[Epoch 12; Iter   101/  209] train: loss: 0.2149035
[Epoch 12; Iter   131/  209] train: loss: 0.1891042
[Epoch 12; Iter   161/  209] train: loss: 0.2030514
[Epoch 12; Iter   191/  209] train: loss: 0.1560822
[Epoch 12] ogbg-moltox21: 0.742349 val loss: 2.063254
[Epoch 12] ogbg-moltox21: 0.712545 test loss: 5.058246
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/tox21/noise=0.2/PNA_ogbg-moltox21_3DInfomax_tox21_static_noise=0.2_5_26-05_09-21-14
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/tox21/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_tox21_static_noise=0.2
logdir: runs/static_noise/3DInfomax/tox21/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6930403
[Epoch 1; Iter    60/  209] train: loss: 0.6929893
[Epoch 1; Iter    90/  209] train: loss: 0.6921263
[Epoch 1; Iter   120/  209] train: loss: 0.6924399
[Epoch 1; Iter   150/  209] train: loss: 0.6920660
[Epoch 1; Iter   180/  209] train: loss: 0.6927703
[Epoch 1] ogbg-moltox21: 0.453830 val loss: 0.692052
[Epoch 1] ogbg-moltox21: 0.457453 test loss: 0.691802
[Epoch 2; Iter     1/  209] train: loss: 0.6930611
[Epoch 2; Iter    31/  209] train: loss: 0.6925259
[Epoch 2; Iter    61/  209] train: loss: 0.6911439
[Epoch 2; Iter    91/  209] train: loss: 0.6921958
[Epoch 2; Iter   121/  209] train: loss: 0.6918908
[Epoch 2; Iter   151/  209] train: loss: 0.6910419
[Epoch 2; Iter   181/  209] train: loss: 0.6914037
[Epoch 2] ogbg-moltox21: 0.460745 val loss: 0.690431
[Epoch 2] ogbg-moltox21: 0.463831 test loss: 0.690134
[Epoch 3; Iter     2/  209] train: loss: 0.6906673
[Epoch 3; Iter    32/  209] train: loss: 0.6905086
[Epoch 3; Iter    62/  209] train: loss: 0.6896477
[Epoch 3; Iter    92/  209] train: loss: 0.6889021
[Epoch 3; Iter   122/  209] train: loss: 0.6895105
[Epoch 3; Iter   152/  209] train: loss: 0.6879232
[Epoch 3; Iter   182/  209] train: loss: 0.6885259
[Epoch 3] ogbg-moltox21: 0.465410 val loss: 0.688444
[Epoch 3] ogbg-moltox21: 0.472396 test loss: 0.688224
[Epoch 4; Iter     3/  209] train: loss: 0.6882154
[Epoch 4; Iter    33/  209] train: loss: 0.6874268
[Epoch 4; Iter    63/  209] train: loss: 0.6870650
[Epoch 4; Iter    93/  209] train: loss: 0.6807657
[Epoch 4; Iter   123/  209] train: loss: 0.6611568
[Epoch 4; Iter   153/  209] train: loss: 0.6269510
[Epoch 4; Iter   183/  209] train: loss: 0.6007909
[Epoch 4] ogbg-moltox21: 0.608561 val loss: 0.601409
[Epoch 4] ogbg-moltox21: 0.591839 test loss: 0.600377
[Epoch 5; Iter     4/  209] train: loss: 0.5351271
[Epoch 5; Iter    34/  209] train: loss: 0.4531001
[Epoch 5; Iter    64/  209] train: loss: 0.4139997
[Epoch 5; Iter    94/  209] train: loss: 0.3576479
[Epoch 5; Iter   124/  209] train: loss: 0.3117361
[Epoch 5; Iter   154/  209] train: loss: 0.3154799
[Epoch 5; Iter   184/  209] train: loss: 0.2647921
[Epoch 5] ogbg-moltox21: 0.686827 val loss: 0.309182
[Epoch 5] ogbg-moltox21: 0.657408 test loss: 0.316992
[Epoch 6; Iter     5/  209] train: loss: 0.3113294
[Epoch 6; Iter    35/  209] train: loss: 0.2448249
[Epoch 6; Iter    65/  209] train: loss: 0.2810394
[Epoch 6; Iter    95/  209] train: loss: 0.1662093
[Epoch 6; Iter   125/  209] train: loss: 0.2736608
[Epoch 6; Iter   155/  209] train: loss: 0.2275516
[Epoch 6; Iter   185/  209] train: loss: 0.1981990
[Epoch 6] ogbg-moltox21: 0.704901 val loss: 0.300828
[Epoch 6] ogbg-moltox21: 0.676158 test loss: 0.313619
[Epoch 7; Iter     6/  209] train: loss: 0.1822412
[Epoch 7; Iter    36/  209] train: loss: 0.1638262
[Epoch 7; Iter    66/  209] train: loss: 0.2169851
[Epoch 7; Iter    96/  209] train: loss: 0.2601163
[Epoch 7; Iter   126/  209] train: loss: 0.3224459
[Epoch 7; Iter   156/  209] train: loss: 0.2041800
[Epoch 7; Iter   186/  209] train: loss: 0.1790942
[Epoch 7] ogbg-moltox21: 0.661488 val loss: 0.332520
[Epoch 7] ogbg-moltox21: 0.650940 test loss: 0.334742
[Epoch 8; Iter     7/  209] train: loss: 0.2397397
[Epoch 8; Iter    37/  209] train: loss: 0.1699008
[Epoch 8; Iter    67/  209] train: loss: 0.1463660
[Epoch 8; Iter    97/  209] train: loss: 0.2078064
[Epoch 8; Iter   127/  209] train: loss: 0.2734722
[Epoch 8; Iter   157/  209] train: loss: 0.1261099
[Epoch 8; Iter   187/  209] train: loss: 0.3270714
[Epoch 8] ogbg-moltox21: 0.646152 val loss: 0.486636
[Epoch 8] ogbg-moltox21: 0.649540 test loss: 0.355346
[Epoch 9; Iter     8/  209] train: loss: 0.1943955
[Epoch 9; Iter    38/  209] train: loss: 0.2093904
[Epoch 9; Iter    68/  209] train: loss: 0.0861329
[Epoch 9; Iter    98/  209] train: loss: 0.1984948
[Epoch 9; Iter   128/  209] train: loss: 0.2166903
[Epoch 9; Iter   158/  209] train: loss: 0.1539988
[Epoch 9; Iter   188/  209] train: loss: 0.2415084
[Epoch 9] ogbg-moltox21: 0.672816 val loss: 0.335152
[Epoch 9] ogbg-moltox21: 0.649312 test loss: 0.304137
[Epoch 10; Iter     9/  209] train: loss: 0.1544135
[Epoch 10; Iter    39/  209] train: loss: 0.2499864
[Epoch 10; Iter    69/  209] train: loss: 0.2682425
[Epoch 10; Iter    99/  209] train: loss: 0.1721866
[Epoch 10; Iter   129/  209] train: loss: 0.1739043
[Epoch 10; Iter   159/  209] train: loss: 0.2365483
[Epoch 10; Iter   189/  209] train: loss: 0.1709201
[Epoch 10] ogbg-moltox21: 0.735970 val loss: 0.272451
[Epoch 10] ogbg-moltox21: 0.693582 test loss: 0.306960
[Epoch 11; Iter    10/  209] train: loss: 0.1871737
[Epoch 11; Iter    40/  209] train: loss: 0.1797336
[Epoch 11; Iter    70/  209] train: loss: 0.1378380
[Epoch 11; Iter   100/  209] train: loss: 0.1720389
[Epoch 11; Iter   130/  209] train: loss: 0.1787800
[Epoch 11; Iter   160/  209] train: loss: 0.2029094
[Epoch 11; Iter   190/  209] train: loss: 0.1918686
[Epoch 11] ogbg-moltox21: 0.740758 val loss: 0.420293
[Epoch 11] ogbg-moltox21: 0.712851 test loss: 0.336014
[Epoch 12; Iter    11/  209] train: loss: 0.1984655
[Epoch 12; Iter    41/  209] train: loss: 0.2093069
[Epoch 12; Iter    71/  209] train: loss: 0.2077245
[Epoch 12; Iter   101/  209] train: loss: 0.1342449
[Epoch 12; Iter   131/  209] train: loss: 0.2342933
[Epoch 12; Iter   161/  209] train: loss: 0.2337666
[Epoch 12; Iter   191/  209] train: loss: 0.2324530
[Epoch 12] ogbg-moltox21: 0.752237 val loss: 0.292714
[Epoch 12] ogbg-moltox21: 0.717407 test loss: 0.309120
[Epoch 13; Iter    12/  209] train: loss: 0.1781271
[Epoch 13; Iter    42/  209] train: loss: 0.1599696
[Epoch 13; Iter    72/  209] train: loss: 0.2577406
[Epoch 13; Iter   102/  209] train: loss: 0.1616392
[Epoch 13; Iter   132/  209] train: loss: 0.2706392
[Epoch 13; Iter   162/  209] train: loss: 0.2511570
[Epoch 13; Iter   192/  209] train: loss: 0.2001887
[Epoch 13] ogbg-moltox21: 0.777218 val loss: 0.436420
[Epoch 13] ogbg-moltox21: 0.745186 test loss: 0.614909
[Epoch 14; Iter    13/  209] train: loss: 0.1987840
[Epoch 14; Iter    43/  209] train: loss: 0.1651216
[Epoch 14; Iter    73/  209] train: loss: 0.2047916
[Epoch 14; Iter   103/  209] train: loss: 0.2023131
[Epoch 14; Iter   133/  209] train: loss: 0.2290404
[Epoch 14; Iter   163/  209] train: loss: 0.1871963
[Epoch 14; Iter   193/  209] train: loss: 0.1968748
[Epoch 14] ogbg-moltox21: 0.776981 val loss: 0.345324
[Epoch 14] ogbg-moltox21: 0.737922 test loss: 0.496754
[Epoch 15; Iter    14/  209] train: loss: 0.1811400
[Epoch 15; Iter    44/  209] train: loss: 0.2290406
[Epoch 15; Iter    74/  209] train: loss: 0.1670170
[Epoch 15; Iter   104/  209] train: loss: 0.2247504
[Epoch 15; Iter   134/  209] train: loss: 0.1658275
[Epoch 15; Iter   164/  209] train: loss: 0.1799370
[Epoch 15; Iter   194/  209] train: loss: 0.2046715
[Epoch 15] ogbg-moltox21: 0.792925 val loss: 0.259576
[Epoch 15] ogbg-moltox21: 0.734924 test loss: 0.282842
[Epoch 16; Iter    15/  209] train: loss: 0.2158896
[Epoch 16; Iter    45/  209] train: loss: 0.1648708
[Epoch 16; Iter    75/  209] train: loss: 0.1954008
[Epoch 16; Iter   105/  209] train: loss: 0.1604466
[Epoch 16; Iter   135/  209] train: loss: 0.1940635
[Epoch 16; Iter   165/  209] train: loss: 0.1818754
[Epoch 16; Iter   195/  209] train: loss: 0.2084084
[Epoch 16] ogbg-moltox21: 0.753828 val loss: 0.345388
[Epoch 16] ogbg-moltox21: 0.746480 test loss: 0.311421
[Epoch 17; Iter    16/  209] train: loss: 0.1690539
[Epoch 17; Iter    46/  209] train: loss: 0.1342655
[Epoch 17; Iter    76/  209] train: loss: 0.1429540
[Epoch 17; Iter   106/  209] train: loss: 0.2437407
[Epoch 17; Iter   136/  209] train: loss: 0.1409587
[Epoch 17; Iter   166/  209] train: loss: 0.1663447
[Epoch 17; Iter   196/  209] train: loss: 0.1440748
[Epoch 17] ogbg-moltox21: 0.757886 val loss: 0.267962
[Epoch 17] ogbg-moltox21: 0.745188 test loss: 0.285618
[Epoch 18; Iter    17/  209] train: loss: 0.1184956
[Epoch 18; Iter    47/  209] train: loss: 0.2048329
[Epoch 18; Iter    77/  209] train: loss: 0.2413612
[Epoch 18; Iter   107/  209] train: loss: 0.2567189
[Epoch 18; Iter   137/  209] train: loss: 0.1753068
[Epoch 18; Iter   167/  209] train: loss: 0.1404304
[Epoch 18; Iter   197/  209] train: loss: 0.1287782
[Epoch 18] ogbg-moltox21: 0.780662 val loss: 0.259467
[Epoch 18] ogbg-moltox21: 0.752159 test loss: 0.274053
[Epoch 19; Iter    18/  209] train: loss: 0.2730088
[Epoch 19; Iter    48/  209] train: loss: 0.1576954
[Epoch 19; Iter    78/  209] train: loss: 0.1383953
[Epoch 19; Iter   108/  209] train: loss: 0.1453713
[Epoch 19; Iter   138/  209] train: loss: 0.1273720
[Epoch 19; Iter   168/  209] train: loss: 0.1576077
[Epoch 19; Iter   198/  209] train: loss: 0.2865560
[Epoch 19] ogbg-moltox21: 0.773497 val loss: 0.264805
[Epoch 19] ogbg-moltox21: 0.749636 test loss: 0.280782
[Epoch 20; Iter    19/  209] train: loss: 0.1898531
[Epoch 20; Iter    49/  209] train: loss: 0.2273640
[Epoch 20; Iter    79/  209] train: loss: 0.1114463
[Epoch 20; Iter   109/  209] train: loss: 0.1145161
[Epoch 20; Iter   139/  209] train: loss: 0.2462796
[Epoch 20; Iter   169/  209] train: loss: 0.2478479
[Epoch 20; Iter   199/  209] train: loss: 0.1272597
[Epoch 20] ogbg-moltox21: 0.758458 val loss: 0.275792
[Epoch 20] ogbg-moltox21: 0.719624 test loss: 0.304633
[Epoch 21; Iter    20/  209] train: loss: 0.1657777
[Epoch 21; Iter    50/  209] train: loss: 0.2232633
[Epoch 21; Iter    80/  209] train: loss: 0.1939168
[Epoch 21; Iter   110/  209] train: loss: 0.1079702
[Epoch 21; Iter   140/  209] train: loss: 0.1945357
[Epoch 21; Iter   170/  209] train: loss: 0.3507361
[Epoch 21; Iter   200/  209] train: loss: 0.1721028
[Epoch 21] ogbg-moltox21: 0.782196 val loss: 0.253048
[Epoch 21] ogbg-moltox21: 0.733812 test loss: 0.336077
[Epoch 22; Iter    21/  209] train: loss: 0.1583199
[Epoch 22; Iter    51/  209] train: loss: 0.0797954
[Epoch 22; Iter    81/  209] train: loss: 0.1462163
[Epoch 22; Iter   111/  209] train: loss: 0.1134812
[Epoch 22; Iter   141/  209] train: loss: 0.1693637
[Epoch 22; Iter   171/  209] train: loss: 0.1107503
[Epoch 22; Iter   201/  209] train: loss: 0.1290297
[Epoch 22] ogbg-moltox21: 0.791545 val loss: 0.264418
[Epoch 22] ogbg-moltox21: 0.743906 test loss: 0.293037
[Epoch 23; Iter    22/  209] train: loss: 0.1752595
[Epoch 23; Iter    52/  209] train: loss: 0.1718347
[Epoch 23; Iter    82/  209] train: loss: 0.1428237
[Epoch 23; Iter   112/  209] train: loss: 0.1524062
[Epoch 23; Iter   142/  209] train: loss: 0.1523348
[Epoch 23; Iter   172/  209] train: loss: 0.1421066
[Epoch 23; Iter   202/  209] train: loss: 0.1339968
[Epoch 23] ogbg-moltox21: 0.779969 val loss: 0.334783
[Epoch 23] ogbg-moltox21: 0.751617 test loss: 0.425788
[Epoch 24; Iter    23/  209] train: loss: 0.2330345
[Epoch 24; Iter    53/  209] train: loss: 0.1225042
[Epoch 24; Iter    83/  209] train: loss: 0.2078469
[Epoch 24; Iter   113/  209] train: loss: 0.1265018
[Epoch 24; Iter   143/  209] train: loss: 0.0983022
[Epoch 24; Iter   173/  209] train: loss: 0.1433118
[Epoch 24; Iter   203/  209] train: loss: 0.1743923
[Epoch 24] ogbg-moltox21: 0.781972 val loss: 0.265743
[Epoch 24] ogbg-moltox21: 0.762306 test loss: 0.276205
[Epoch 25; Iter    24/  209] train: loss: 0.1021905
[Epoch 25; Iter    54/  209] train: loss: 0.2306119
[Epoch 25; Iter    84/  209] train: loss: 0.1354077
[Epoch 25; Iter   114/  209] train: loss: 0.1708229
[Epoch 25; Iter   144/  209] train: loss: 0.1313552
[Epoch 25; Iter   174/  209] train: loss: 0.1619780
[Epoch 25; Iter   204/  209] train: loss: 0.2213911
[Epoch 25] ogbg-moltox21: 0.785505 val loss: 0.466760
[Epoch 25] ogbg-moltox21: 0.760299 test loss: 0.344845
[Epoch 26; Iter    25/  209] train: loss: 0.1543653
[Epoch 26; Iter    55/  209] train: loss: 0.2343322
[Epoch 26; Iter    85/  209] train: loss: 0.1559357
[Epoch 26; Iter   115/  209] train: loss: 0.1066397
[Epoch 26; Iter   145/  209] train: loss: 0.1188139
[Epoch 26; Iter   175/  209] train: loss: 0.0999487
[Epoch 26; Iter   205/  209] train: loss: 0.1622604
[Epoch 26] ogbg-moltox21: 0.770433 val loss: 0.377952
[Epoch 26] ogbg-moltox21: 0.729052 test loss: 0.306617
[Epoch 27; Iter    26/  209] train: loss: 0.1351745
[Epoch 27; Iter    56/  209] train: loss: 0.2244845
[Epoch 27; Iter    86/  209] train: loss: 0.1663692
[Epoch 27; Iter   116/  209] train: loss: 0.1421735
[Epoch 27; Iter   146/  209] train: loss: 0.1299573
[Epoch 27; Iter   176/  209] train: loss: 0.1084098
[Epoch 27; Iter   206/  209] train: loss: 0.1487025
[Epoch 27] ogbg-moltox21: 0.789226 val loss: 0.263422
[Epoch 27] ogbg-moltox21: 0.743538 test loss: 0.283883
[Epoch 28; Iter    27/  209] train: loss: 0.1250816
[Epoch 28; Iter    57/  209] train: loss: 0.1186937
[Epoch 28; Iter    87/  209] train: loss: 0.1285221
[Epoch 28; Iter   117/  209] train: loss: 0.1459742
[Epoch 28; Iter   147/  209] train: loss: 0.1746561
[Epoch 28; Iter   177/  209] train: loss: 0.1333194
[Epoch 28; Iter   207/  209] train: loss: 0.1215887
[Epoch 28] ogbg-moltox21: 0.777220 val loss: 0.273243
[Epoch 28] ogbg-moltox21: 0.757774 test loss: 0.285771
[Epoch 29; Iter    28/  209] train: loss: 0.1198152
[Epoch 29; Iter    58/  209] train: loss: 0.1439364
[Epoch 29; Iter    88/  209] train: loss: 0.1776269
[Epoch 29; Iter   118/  209] train: loss: 0.1797037
[Epoch 29; Iter   148/  209] train: loss: 0.1378821
[Epoch 29; Iter   178/  209] train: loss: 0.1122578
[Epoch 29; Iter   208/  209] train: loss: 0.1221706
[Epoch 29] ogbg-moltox21: 0.767855 val loss: 0.336150
[Epoch 29] ogbg-moltox21: 0.734957 test loss: 0.285513
[Epoch 30; Iter    29/  209] train: loss: 0.1729304
[Epoch 30; Iter    59/  209] train: loss: 0.1235134
[Epoch 13; Iter    12/  209] train: loss: 0.2596010
[Epoch 13; Iter    42/  209] train: loss: 0.2079308
[Epoch 13; Iter    72/  209] train: loss: 0.2399378
[Epoch 13; Iter   102/  209] train: loss: 0.2053743
[Epoch 13; Iter   132/  209] train: loss: 0.1608073
[Epoch 13; Iter   162/  209] train: loss: 0.2239665
[Epoch 13; Iter   192/  209] train: loss: 0.1845507
[Epoch 13] ogbg-moltox21: 0.759998 val loss: 0.277761
[Epoch 13] ogbg-moltox21: 0.740245 test loss: 0.288258
[Epoch 14; Iter    13/  209] train: loss: 0.1876205
[Epoch 14; Iter    43/  209] train: loss: 0.2101592
[Epoch 14; Iter    73/  209] train: loss: 0.2102286
[Epoch 14; Iter   103/  209] train: loss: 0.1868054
[Epoch 14; Iter   133/  209] train: loss: 0.2128859
[Epoch 14; Iter   163/  209] train: loss: 0.1672191
[Epoch 14; Iter   193/  209] train: loss: 0.2462447
[Epoch 14] ogbg-moltox21: 0.769837 val loss: 0.278946
[Epoch 14] ogbg-moltox21: 0.741126 test loss: 0.296458
[Epoch 15; Iter    14/  209] train: loss: 0.2278628
[Epoch 15; Iter    44/  209] train: loss: 0.1832140
[Epoch 15; Iter    74/  209] train: loss: 0.1542040
[Epoch 15; Iter   104/  209] train: loss: 0.2381411
[Epoch 15; Iter   134/  209] train: loss: 0.1808701
[Epoch 15; Iter   164/  209] train: loss: 0.1574033
[Epoch 15; Iter   194/  209] train: loss: 0.1743126
[Epoch 15] ogbg-moltox21: 0.766788 val loss: 0.268933
[Epoch 15] ogbg-moltox21: 0.737259 test loss: 0.283157
[Epoch 16; Iter    15/  209] train: loss: 0.1539011
[Epoch 16; Iter    45/  209] train: loss: 0.2377604
[Epoch 16; Iter    75/  209] train: loss: 0.2254210
[Epoch 16; Iter   105/  209] train: loss: 0.2347215
[Epoch 16; Iter   135/  209] train: loss: 0.1986376
[Epoch 16; Iter   165/  209] train: loss: 0.1339158
[Epoch 16; Iter   195/  209] train: loss: 0.1771515
[Epoch 16] ogbg-moltox21: 0.743729 val loss: 0.287619
[Epoch 16] ogbg-moltox21: 0.718426 test loss: 0.299815
[Epoch 17; Iter    16/  209] train: loss: 0.2219961
[Epoch 17; Iter    46/  209] train: loss: 0.2243403
[Epoch 17; Iter    76/  209] train: loss: 0.1699426
[Epoch 17; Iter   106/  209] train: loss: 0.2383610
[Epoch 17; Iter   136/  209] train: loss: 0.1080699
[Epoch 17; Iter   166/  209] train: loss: 0.1860919
[Epoch 17; Iter   196/  209] train: loss: 0.1984695
[Epoch 17] ogbg-moltox21: 0.775076 val loss: 0.274092
[Epoch 17] ogbg-moltox21: 0.745905 test loss: 0.287941
[Epoch 18; Iter    17/  209] train: loss: 0.1702426
[Epoch 18; Iter    47/  209] train: loss: 0.1488370
[Epoch 18; Iter    77/  209] train: loss: 0.2203718
[Epoch 18; Iter   107/  209] train: loss: 0.2649950
[Epoch 18; Iter   137/  209] train: loss: 0.1338770
[Epoch 18; Iter   167/  209] train: loss: 0.1869733
[Epoch 18; Iter   197/  209] train: loss: 0.1441487
[Epoch 18] ogbg-moltox21: 0.771542 val loss: 0.273789
[Epoch 18] ogbg-moltox21: 0.741332 test loss: 0.285735
[Epoch 19; Iter    18/  209] train: loss: 0.1633381
[Epoch 19; Iter    48/  209] train: loss: 0.1342598
[Epoch 19; Iter    78/  209] train: loss: 0.1983834
[Epoch 19; Iter   108/  209] train: loss: 0.1950626
[Epoch 19; Iter   138/  209] train: loss: 0.2195230
[Epoch 19; Iter   168/  209] train: loss: 0.2058550
[Epoch 19; Iter   198/  209] train: loss: 0.1616932
[Epoch 19] ogbg-moltox21: 0.777760 val loss: 0.266684
[Epoch 19] ogbg-moltox21: 0.754700 test loss: 0.281845
[Epoch 20; Iter    19/  209] train: loss: 0.2234205
[Epoch 20; Iter    49/  209] train: loss: 0.1530850
[Epoch 20; Iter    79/  209] train: loss: 0.1690571
[Epoch 20; Iter   109/  209] train: loss: 0.1393037
[Epoch 20; Iter   139/  209] train: loss: 0.1748262
[Epoch 20; Iter   169/  209] train: loss: 0.2454130
[Epoch 20; Iter   199/  209] train: loss: 0.1896367
[Epoch 20] ogbg-moltox21: 0.758896 val loss: 0.266459
[Epoch 20] ogbg-moltox21: 0.737143 test loss: 0.276290
[Epoch 21; Iter    20/  209] train: loss: 0.1775525
[Epoch 21; Iter    50/  209] train: loss: 0.1969196
[Epoch 21; Iter    80/  209] train: loss: 0.1672257
[Epoch 21; Iter   110/  209] train: loss: 0.3285896
[Epoch 21; Iter   140/  209] train: loss: 0.1728105
[Epoch 21; Iter   170/  209] train: loss: 0.2033603
[Epoch 21; Iter   200/  209] train: loss: 0.1712983
[Epoch 21] ogbg-moltox21: 0.777950 val loss: 0.272821
[Epoch 21] ogbg-moltox21: 0.759597 test loss: 0.283114
[Epoch 22; Iter    21/  209] train: loss: 0.1020335
[Epoch 22; Iter    51/  209] train: loss: 0.2088321
[Epoch 22; Iter    81/  209] train: loss: 0.1493148
[Epoch 22; Iter   111/  209] train: loss: 0.2529562
[Epoch 22; Iter   141/  209] train: loss: 0.1546372
[Epoch 22; Iter   171/  209] train: loss: 0.2021273
[Epoch 22; Iter   201/  209] train: loss: 0.1930150
[Epoch 22] ogbg-moltox21: 0.768635 val loss: 0.274146
[Epoch 22] ogbg-moltox21: 0.736967 test loss: 0.289921
[Epoch 23; Iter    22/  209] train: loss: 0.1427891
[Epoch 23; Iter    52/  209] train: loss: 0.1304383
[Epoch 23; Iter    82/  209] train: loss: 0.1697984
[Epoch 23; Iter   112/  209] train: loss: 0.1834958
[Epoch 23; Iter   142/  209] train: loss: 0.2003628
[Epoch 23; Iter   172/  209] train: loss: 0.2043076
[Epoch 23; Iter   202/  209] train: loss: 0.1691639
[Epoch 23] ogbg-moltox21: 0.774749 val loss: 0.262175
[Epoch 23] ogbg-moltox21: 0.737033 test loss: 0.279126
[Epoch 24; Iter    23/  209] train: loss: 0.1547402
[Epoch 24; Iter    53/  209] train: loss: 0.1784237
[Epoch 24; Iter    83/  209] train: loss: 0.1739433
[Epoch 24; Iter   113/  209] train: loss: 0.1241435
[Epoch 24; Iter   143/  209] train: loss: 0.1555716
[Epoch 24; Iter   173/  209] train: loss: 0.1696485
[Epoch 24; Iter   203/  209] train: loss: 0.2050188
[Epoch 24] ogbg-moltox21: 0.792859 val loss: 0.269409
[Epoch 24] ogbg-moltox21: 0.765792 test loss: 0.283313
[Epoch 25; Iter    24/  209] train: loss: 0.1378056
[Epoch 25; Iter    54/  209] train: loss: 0.1094411
[Epoch 25; Iter    84/  209] train: loss: 0.1064129
[Epoch 25; Iter   114/  209] train: loss: 0.1638235
[Epoch 25; Iter   144/  209] train: loss: 0.2463302
[Epoch 25; Iter   174/  209] train: loss: 0.1650720
[Epoch 25; Iter   204/  209] train: loss: 0.1352723
[Epoch 25] ogbg-moltox21: 0.779679 val loss: 0.301831
[Epoch 25] ogbg-moltox21: 0.757629 test loss: 0.307160
[Epoch 26; Iter    25/  209] train: loss: 0.1207966
[Epoch 26; Iter    55/  209] train: loss: 0.2099087
[Epoch 26; Iter    85/  209] train: loss: 0.2579787
[Epoch 26; Iter   115/  209] train: loss: 0.1681597
[Epoch 26; Iter   145/  209] train: loss: 0.1645897
[Epoch 26; Iter   175/  209] train: loss: 0.1392494
[Epoch 26; Iter   205/  209] train: loss: 0.1258904
[Epoch 26] ogbg-moltox21: 0.784797 val loss: 0.272021
[Epoch 26] ogbg-moltox21: 0.764454 test loss: 0.280403
[Epoch 27; Iter    26/  209] train: loss: 0.1985444
[Epoch 27; Iter    56/  209] train: loss: 0.0994960
[Epoch 27; Iter    86/  209] train: loss: 0.1818177
[Epoch 27; Iter   116/  209] train: loss: 0.1511296
[Epoch 27; Iter   146/  209] train: loss: 0.1698301
[Epoch 27; Iter   176/  209] train: loss: 0.2255623
[Epoch 27; Iter   206/  209] train: loss: 0.1376812
[Epoch 27] ogbg-moltox21: 0.770870 val loss: 0.306657
[Epoch 27] ogbg-moltox21: 0.750309 test loss: 0.313675
[Epoch 28; Iter    27/  209] train: loss: 0.1071690
[Epoch 28; Iter    57/  209] train: loss: 0.2791804
[Epoch 28; Iter    87/  209] train: loss: 0.1889551
[Epoch 28; Iter   117/  209] train: loss: 0.1416057
[Epoch 28; Iter   147/  209] train: loss: 0.1967322
[Epoch 28; Iter   177/  209] train: loss: 0.2129674
[Epoch 28; Iter   207/  209] train: loss: 0.1323892
[Epoch 28] ogbg-moltox21: 0.782775 val loss: 0.287657
[Epoch 28] ogbg-moltox21: 0.757752 test loss: 0.295038
[Epoch 29; Iter    28/  209] train: loss: 0.1230122
[Epoch 29; Iter    58/  209] train: loss: 0.1487213
[Epoch 29; Iter    88/  209] train: loss: 0.1354920
[Epoch 29; Iter   118/  209] train: loss: 0.2016336
[Epoch 29; Iter   148/  209] train: loss: 0.1301159
[Epoch 29; Iter   178/  209] train: loss: 0.0928811
[Epoch 29; Iter   208/  209] train: loss: 0.1448684
[Epoch 29] ogbg-moltox21: 0.766779 val loss: 0.278764
[Epoch 29] ogbg-moltox21: 0.741980 test loss: 0.290162
[Epoch 30; Iter    29/  209] train: loss: 0.1524994
[Epoch 30; Iter    59/  209] train: loss: 0.1194336
[Epoch 13; Iter    12/  209] train: loss: 0.1817375
[Epoch 13; Iter    42/  209] train: loss: 0.1757565
[Epoch 13; Iter    72/  209] train: loss: 0.1779645
[Epoch 13; Iter   102/  209] train: loss: 0.2107757
[Epoch 13; Iter   132/  209] train: loss: 0.1666583
[Epoch 13; Iter   162/  209] train: loss: 0.2618632
[Epoch 13; Iter   192/  209] train: loss: 0.1975191
[Epoch 13] ogbg-moltox21: 0.776084 val loss: 0.277287
[Epoch 13] ogbg-moltox21: 0.726726 test loss: 0.350842
[Epoch 14; Iter    13/  209] train: loss: 0.1340235
[Epoch 14; Iter    43/  209] train: loss: 0.1783416
[Epoch 14; Iter    73/  209] train: loss: 0.1522778
[Epoch 14; Iter   103/  209] train: loss: 0.2681208
[Epoch 14; Iter   133/  209] train: loss: 0.1783097
[Epoch 14; Iter   163/  209] train: loss: 0.2204627
[Epoch 14; Iter   193/  209] train: loss: 0.2176898
[Epoch 14] ogbg-moltox21: 0.766733 val loss: 0.382322
[Epoch 14] ogbg-moltox21: 0.733330 test loss: 0.607026
[Epoch 15; Iter    14/  209] train: loss: 0.1257619
[Epoch 15; Iter    44/  209] train: loss: 0.1460808
[Epoch 15; Iter    74/  209] train: loss: 0.2162872
[Epoch 15; Iter   104/  209] train: loss: 0.1419505
[Epoch 15; Iter   134/  209] train: loss: 0.1408244
[Epoch 15; Iter   164/  209] train: loss: 0.1314238
[Epoch 15; Iter   194/  209] train: loss: 0.1484866
[Epoch 15] ogbg-moltox21: 0.671667 val loss: 2.364689
[Epoch 15] ogbg-moltox21: 0.628452 test loss: 3.309594
[Epoch 16; Iter    15/  209] train: loss: 0.1389714
[Epoch 16; Iter    45/  209] train: loss: 0.2048562
[Epoch 16; Iter    75/  209] train: loss: 0.2665538
[Epoch 16; Iter   105/  209] train: loss: 0.2919526
[Epoch 16; Iter   135/  209] train: loss: 0.2355866
[Epoch 16; Iter   165/  209] train: loss: 0.3211995
[Epoch 16; Iter   195/  209] train: loss: 0.2154303
[Epoch 16] ogbg-moltox21: 0.780322 val loss: 0.587192
[Epoch 16] ogbg-moltox21: 0.744994 test loss: 0.710926
[Epoch 17; Iter    16/  209] train: loss: 0.2015122
[Epoch 17; Iter    46/  209] train: loss: 0.2499106
[Epoch 17; Iter    76/  209] train: loss: 0.2326913
[Epoch 17; Iter   106/  209] train: loss: 0.2305357
[Epoch 17; Iter   136/  209] train: loss: 0.3087236
[Epoch 17; Iter   166/  209] train: loss: 0.2258489
[Epoch 17; Iter   196/  209] train: loss: 0.1878288
[Epoch 17] ogbg-moltox21: 0.770210 val loss: 0.324684
[Epoch 17] ogbg-moltox21: 0.733299 test loss: 0.844917
[Epoch 18; Iter    17/  209] train: loss: 0.1428773
[Epoch 18; Iter    47/  209] train: loss: 0.1342779
[Epoch 18; Iter    77/  209] train: loss: 0.2234448
[Epoch 18; Iter   107/  209] train: loss: 0.1637565
[Epoch 18; Iter   137/  209] train: loss: 0.1098214
[Epoch 18; Iter   167/  209] train: loss: 0.1774687
[Epoch 18; Iter   197/  209] train: loss: 0.1817298
[Epoch 18] ogbg-moltox21: 0.746114 val loss: 0.491685
[Epoch 18] ogbg-moltox21: 0.722623 test loss: 1.371609
[Epoch 19; Iter    18/  209] train: loss: 0.1643696
[Epoch 19; Iter    48/  209] train: loss: 0.1073968
[Epoch 19; Iter    78/  209] train: loss: 0.2655085
[Epoch 19; Iter   108/  209] train: loss: 0.1633568
[Epoch 19; Iter   138/  209] train: loss: 0.1898318
[Epoch 19; Iter   168/  209] train: loss: 0.1907776
[Epoch 19; Iter   198/  209] train: loss: 0.2592104
[Epoch 19] ogbg-moltox21: 0.765394 val loss: 0.262686
[Epoch 19] ogbg-moltox21: 0.745027 test loss: 0.281349
[Epoch 20; Iter    19/  209] train: loss: 0.1772022
[Epoch 20; Iter    49/  209] train: loss: 0.1373776
[Epoch 20; Iter    79/  209] train: loss: 0.1703034
[Epoch 20; Iter   109/  209] train: loss: 0.2011755
[Epoch 20; Iter   139/  209] train: loss: 0.1323961
[Epoch 20; Iter   169/  209] train: loss: 0.1933335
[Epoch 20; Iter   199/  209] train: loss: 0.2379933
[Epoch 20] ogbg-moltox21: 0.739808 val loss: 0.350992
[Epoch 20] ogbg-moltox21: 0.736800 test loss: 0.538698
[Epoch 21; Iter    20/  209] train: loss: 0.1578737
[Epoch 21; Iter    50/  209] train: loss: 0.1955517
[Epoch 21; Iter    80/  209] train: loss: 0.1588647
[Epoch 21; Iter   110/  209] train: loss: 0.1740914
[Epoch 21; Iter   140/  209] train: loss: 0.0981758
[Epoch 21; Iter   170/  209] train: loss: 0.1619803
[Epoch 21; Iter   200/  209] train: loss: 0.1151692
[Epoch 21] ogbg-moltox21: 0.758238 val loss: 0.329997
[Epoch 21] ogbg-moltox21: 0.735969 test loss: 0.402736
[Epoch 22; Iter    21/  209] train: loss: 0.2074493
[Epoch 22; Iter    51/  209] train: loss: 0.1908941
[Epoch 22; Iter    81/  209] train: loss: 0.1017078
[Epoch 22; Iter   111/  209] train: loss: 0.1353028
[Epoch 22; Iter   141/  209] train: loss: 0.1290907
[Epoch 22; Iter   171/  209] train: loss: 0.2023246
[Epoch 22; Iter   201/  209] train: loss: 0.1591188
[Epoch 22] ogbg-moltox21: 0.783865 val loss: 0.303120
[Epoch 22] ogbg-moltox21: 0.739515 test loss: 0.341870
[Epoch 23; Iter    22/  209] train: loss: 0.1288644
[Epoch 23; Iter    52/  209] train: loss: 0.2361092
[Epoch 23; Iter    82/  209] train: loss: 0.1510001
[Epoch 23; Iter   112/  209] train: loss: 0.1529457
[Epoch 23; Iter   142/  209] train: loss: 0.1378562
[Epoch 23; Iter   172/  209] train: loss: 0.1450761
[Epoch 23; Iter   202/  209] train: loss: 0.1901757
[Epoch 23] ogbg-moltox21: 0.766896 val loss: 0.268007
[Epoch 23] ogbg-moltox21: 0.722944 test loss: 0.286399
[Epoch 24; Iter    23/  209] train: loss: 0.1931138
[Epoch 24; Iter    53/  209] train: loss: 0.2022949
[Epoch 24; Iter    83/  209] train: loss: 0.2468258
[Epoch 24; Iter   113/  209] train: loss: 0.1263142
[Epoch 24; Iter   143/  209] train: loss: 0.1696722
[Epoch 24; Iter   173/  209] train: loss: 0.1234857
[Epoch 24; Iter   203/  209] train: loss: 0.1863834
[Epoch 24] ogbg-moltox21: 0.788206 val loss: 0.269794
[Epoch 24] ogbg-moltox21: 0.743635 test loss: 0.293031
[Epoch 25; Iter    24/  209] train: loss: 0.1896344
[Epoch 25; Iter    54/  209] train: loss: 0.2189965
[Epoch 25; Iter    84/  209] train: loss: 0.1251636
[Epoch 25; Iter   114/  209] train: loss: 0.1750174
[Epoch 25; Iter   144/  209] train: loss: 0.1068396
[Epoch 25; Iter   174/  209] train: loss: 0.2349547
[Epoch 25; Iter   204/  209] train: loss: 0.1231746
[Epoch 25] ogbg-moltox21: 0.779956 val loss: 0.265518
[Epoch 25] ogbg-moltox21: 0.732710 test loss: 0.328715
[Epoch 26; Iter    25/  209] train: loss: 0.1202030
[Epoch 26; Iter    55/  209] train: loss: 0.1416836
[Epoch 26; Iter    85/  209] train: loss: 0.1705546
[Epoch 26; Iter   115/  209] train: loss: 0.1356482
[Epoch 26; Iter   145/  209] train: loss: 0.1433331
[Epoch 26; Iter   175/  209] train: loss: 0.1280645
[Epoch 26; Iter   205/  209] train: loss: 0.3049729
[Epoch 26] ogbg-moltox21: 0.753790 val loss: 0.321865
[Epoch 26] ogbg-moltox21: 0.730689 test loss: 0.518792
[Epoch 27; Iter    26/  209] train: loss: 0.1251966
[Epoch 27; Iter    56/  209] train: loss: 0.1168378
[Epoch 27; Iter    86/  209] train: loss: 0.1668991
[Epoch 27; Iter   116/  209] train: loss: 0.2084929
[Epoch 27; Iter   146/  209] train: loss: 0.1379343
[Epoch 27; Iter   176/  209] train: loss: 0.2141598
[Epoch 27; Iter   206/  209] train: loss: 0.2134811
[Epoch 27] ogbg-moltox21: 0.797647 val loss: 0.269648
[Epoch 27] ogbg-moltox21: 0.739708 test loss: 0.323119
[Epoch 28; Iter    27/  209] train: loss: 0.2118249
[Epoch 28; Iter    57/  209] train: loss: 0.0873180
[Epoch 28; Iter    87/  209] train: loss: 0.1949676
[Epoch 28; Iter   117/  209] train: loss: 0.1814124
[Epoch 28; Iter   147/  209] train: loss: 0.2359079
[Epoch 28; Iter   177/  209] train: loss: 0.1627416
[Epoch 28; Iter   207/  209] train: loss: 0.0943339
[Epoch 28] ogbg-moltox21: 0.738247 val loss: 0.459236
[Epoch 28] ogbg-moltox21: 0.727497 test loss: 0.469794
[Epoch 29; Iter    28/  209] train: loss: 0.1608207
[Epoch 29; Iter    58/  209] train: loss: 0.1669291
[Epoch 29; Iter    88/  209] train: loss: 0.1614382
[Epoch 29; Iter   118/  209] train: loss: 0.1169460
[Epoch 29; Iter   148/  209] train: loss: 0.2093336
[Epoch 29; Iter   178/  209] train: loss: 0.1325523
[Epoch 29; Iter   208/  209] train: loss: 0.1938484
[Epoch 29] ogbg-moltox21: 0.754571 val loss: 0.326679
[Epoch 29] ogbg-moltox21: 0.736722 test loss: 0.488439
[Epoch 30; Iter    29/  209] train: loss: 0.1334665
[Epoch 30; Iter    59/  209] train: loss: 0.2022612
[Epoch 13; Iter    12/  209] train: loss: 0.1554478
[Epoch 13; Iter    42/  209] train: loss: 0.1519704
[Epoch 13; Iter    72/  209] train: loss: 0.1729280
[Epoch 13; Iter   102/  209] train: loss: 0.2035708
[Epoch 13; Iter   132/  209] train: loss: 0.1890055
[Epoch 13; Iter   162/  209] train: loss: 0.2613819
[Epoch 13; Iter   192/  209] train: loss: 0.1926855
[Epoch 13] ogbg-moltox21: 0.756024 val loss: 0.293899
[Epoch 13] ogbg-moltox21: 0.741094 test loss: 0.299697
[Epoch 14; Iter    13/  209] train: loss: 0.1083856
[Epoch 14; Iter    43/  209] train: loss: 0.1652105
[Epoch 14; Iter    73/  209] train: loss: 0.1399515
[Epoch 14; Iter   103/  209] train: loss: 0.2384089
[Epoch 14; Iter   133/  209] train: loss: 0.1711398
[Epoch 14; Iter   163/  209] train: loss: 0.2088372
[Epoch 14; Iter   193/  209] train: loss: 0.1904520
[Epoch 14] ogbg-moltox21: 0.758521 val loss: 0.290119
[Epoch 14] ogbg-moltox21: 0.732204 test loss: 1.822991
[Epoch 15; Iter    14/  209] train: loss: 0.1071772
[Epoch 15; Iter    44/  209] train: loss: 0.1442522
[Epoch 15; Iter    74/  209] train: loss: 0.1860517
[Epoch 15; Iter   104/  209] train: loss: 0.1470502
[Epoch 15; Iter   134/  209] train: loss: 0.1324734
[Epoch 15; Iter   164/  209] train: loss: 0.1447381
[Epoch 15; Iter   194/  209] train: loss: 0.1460413
[Epoch 15] ogbg-moltox21: 0.758078 val loss: 0.734404
[Epoch 15] ogbg-moltox21: 0.730052 test loss: 2.409511
[Epoch 16; Iter    15/  209] train: loss: 0.1278058
[Epoch 16; Iter    45/  209] train: loss: 0.1459987
[Epoch 16; Iter    75/  209] train: loss: 0.2474668
[Epoch 16; Iter   105/  209] train: loss: 0.2639391
[Epoch 16; Iter   135/  209] train: loss: 0.2367429
[Epoch 16; Iter   165/  209] train: loss: 0.2895337
[Epoch 16; Iter   195/  209] train: loss: 0.2105836
[Epoch 16] ogbg-moltox21: 0.768459 val loss: 0.267304
[Epoch 16] ogbg-moltox21: 0.737674 test loss: 0.532328
[Epoch 17; Iter    16/  209] train: loss: 0.1773623
[Epoch 17; Iter    46/  209] train: loss: 0.2187380
[Epoch 17; Iter    76/  209] train: loss: 0.2514883
[Epoch 17; Iter   106/  209] train: loss: 0.2157062
[Epoch 17; Iter   136/  209] train: loss: 0.3159760
[Epoch 17; Iter   166/  209] train: loss: 0.2208371
[Epoch 17; Iter   196/  209] train: loss: 0.1654883
[Epoch 17] ogbg-moltox21: 0.761478 val loss: 0.269681
[Epoch 17] ogbg-moltox21: 0.740331 test loss: 0.283043
[Epoch 18; Iter    17/  209] train: loss: 0.1322807
[Epoch 18; Iter    47/  209] train: loss: 0.1282749
[Epoch 18; Iter    77/  209] train: loss: 0.2323935
[Epoch 18; Iter   107/  209] train: loss: 0.1720974
[Epoch 18; Iter   137/  209] train: loss: 0.1340983
[Epoch 18; Iter   167/  209] train: loss: 0.1522677
[Epoch 18; Iter   197/  209] train: loss: 0.1832612
[Epoch 18] ogbg-moltox21: 0.775125 val loss: 0.271402
[Epoch 18] ogbg-moltox21: 0.738840 test loss: 0.283702
[Epoch 19; Iter    18/  209] train: loss: 0.1635652
[Epoch 19; Iter    48/  209] train: loss: 0.1264335
[Epoch 19; Iter    78/  209] train: loss: 0.2511977
[Epoch 19; Iter   108/  209] train: loss: 0.1177105
[Epoch 19; Iter   138/  209] train: loss: 0.1748286
[Epoch 19; Iter   168/  209] train: loss: 0.1699623
[Epoch 19; Iter   198/  209] train: loss: 0.2821835
[Epoch 19] ogbg-moltox21: 0.751036 val loss: 0.390695
[Epoch 19] ogbg-moltox21: 0.741207 test loss: 0.547866
[Epoch 20; Iter    19/  209] train: loss: 0.2039347
[Epoch 20; Iter    49/  209] train: loss: 0.1281303
[Epoch 20; Iter    79/  209] train: loss: 0.1452468
[Epoch 20; Iter   109/  209] train: loss: 0.1584456
[Epoch 20; Iter   139/  209] train: loss: 0.1483590
[Epoch 20; Iter   169/  209] train: loss: 0.1931224
[Epoch 20; Iter   199/  209] train: loss: 0.2149145
[Epoch 20] ogbg-moltox21: 0.769037 val loss: 0.281192
[Epoch 20] ogbg-moltox21: 0.736544 test loss: 0.297151
[Epoch 21; Iter    20/  209] train: loss: 0.1440115
[Epoch 21; Iter    50/  209] train: loss: 0.1909438
[Epoch 21; Iter    80/  209] train: loss: 0.1283233
[Epoch 21; Iter   110/  209] train: loss: 0.1984144
[Epoch 21; Iter   140/  209] train: loss: 0.0696769
[Epoch 21; Iter   170/  209] train: loss: 0.1447203
[Epoch 21; Iter   200/  209] train: loss: 0.0905759
[Epoch 21] ogbg-moltox21: 0.746648 val loss: 0.413432
[Epoch 21] ogbg-moltox21: 0.720823 test loss: 0.361355
[Epoch 22; Iter    21/  209] train: loss: 0.1802841
[Epoch 22; Iter    51/  209] train: loss: 0.1686427
[Epoch 22; Iter    81/  209] train: loss: 0.0786999
[Epoch 22; Iter   111/  209] train: loss: 0.1210822
[Epoch 22; Iter   141/  209] train: loss: 0.1084327
[Epoch 22; Iter   171/  209] train: loss: 0.2044699
[Epoch 22; Iter   201/  209] train: loss: 0.1727192
[Epoch 22] ogbg-moltox21: 0.771032 val loss: 0.326567
[Epoch 22] ogbg-moltox21: 0.734060 test loss: 0.447591
[Epoch 23; Iter    22/  209] train: loss: 0.1048532
[Epoch 23; Iter    52/  209] train: loss: 0.2014569
[Epoch 23; Iter    82/  209] train: loss: 0.1499889
[Epoch 23; Iter   112/  209] train: loss: 0.1482050
[Epoch 23; Iter   142/  209] train: loss: 0.1190391
[Epoch 23; Iter   172/  209] train: loss: 0.1708825
[Epoch 23; Iter   202/  209] train: loss: 0.2058265
[Epoch 23] ogbg-moltox21: 0.749167 val loss: 0.316133
[Epoch 23] ogbg-moltox21: 0.716709 test loss: 0.994376
[Epoch 24; Iter    23/  209] train: loss: 0.2143716
[Epoch 24; Iter    53/  209] train: loss: 0.1878965
[Epoch 24; Iter    83/  209] train: loss: 0.1905725
[Epoch 24; Iter   113/  209] train: loss: 0.1417219
[Epoch 24; Iter   143/  209] train: loss: 0.1487992
[Epoch 24; Iter   173/  209] train: loss: 0.1188046
[Epoch 24; Iter   203/  209] train: loss: 0.1812069
[Epoch 24] ogbg-moltox21: 0.754850 val loss: 0.317655
[Epoch 24] ogbg-moltox21: 0.751333 test loss: 1.135652
[Epoch 25; Iter    24/  209] train: loss: 0.1361322
[Epoch 25; Iter    54/  209] train: loss: 0.1753208
[Epoch 25; Iter    84/  209] train: loss: 0.1280229
[Epoch 25; Iter   114/  209] train: loss: 0.1793790
[Epoch 25; Iter   144/  209] train: loss: 0.1016816
[Epoch 25; Iter   174/  209] train: loss: 0.1918102
[Epoch 25; Iter   204/  209] train: loss: 0.1116178
[Epoch 25] ogbg-moltox21: 0.742756 val loss: 0.519919
[Epoch 25] ogbg-moltox21: 0.718186 test loss: 0.598907
[Epoch 26; Iter    25/  209] train: loss: 0.0703857
[Epoch 26; Iter    55/  209] train: loss: 0.1419554
[Epoch 26; Iter    85/  209] train: loss: 0.1477704
[Epoch 26; Iter   115/  209] train: loss: 0.1384684
[Epoch 26; Iter   145/  209] train: loss: 0.1433047
[Epoch 26; Iter   175/  209] train: loss: 0.1037848
[Epoch 26; Iter   205/  209] train: loss: 0.2330173
[Epoch 26] ogbg-moltox21: 0.739337 val loss: 0.368861
[Epoch 26] ogbg-moltox21: 0.727183 test loss: 0.346392
[Epoch 27; Iter    26/  209] train: loss: 0.0966949
[Epoch 27; Iter    56/  209] train: loss: 0.0945373
[Epoch 27; Iter    86/  209] train: loss: 0.1117354
[Epoch 27; Iter   116/  209] train: loss: 0.1959251
[Epoch 27; Iter   146/  209] train: loss: 0.1106479
[Epoch 27; Iter   176/  209] train: loss: 0.1114907
[Epoch 27; Iter   206/  209] train: loss: 0.1712075
[Epoch 27] ogbg-moltox21: 0.761347 val loss: 0.427999
[Epoch 27] ogbg-moltox21: 0.730210 test loss: 0.698296
[Epoch 28; Iter    27/  209] train: loss: 0.1908070
[Epoch 28; Iter    57/  209] train: loss: 0.0765923
[Epoch 28; Iter    87/  209] train: loss: 0.1864661
[Epoch 28; Iter   117/  209] train: loss: 0.1517021
[Epoch 28; Iter   147/  209] train: loss: 0.1854770
[Epoch 28; Iter   177/  209] train: loss: 0.1531564
[Epoch 28; Iter   207/  209] train: loss: 0.1019602
[Epoch 28] ogbg-moltox21: 0.742219 val loss: 0.649265
[Epoch 28] ogbg-moltox21: 0.724632 test loss: 0.572424
[Epoch 29; Iter    28/  209] train: loss: 0.1504474
[Epoch 29; Iter    58/  209] train: loss: 0.1177073
[Epoch 29; Iter    88/  209] train: loss: 0.1509375
[Epoch 29; Iter   118/  209] train: loss: 0.1079638
[Epoch 29; Iter   148/  209] train: loss: 0.2073525
[Epoch 29; Iter   178/  209] train: loss: 0.1174537
[Epoch 29; Iter   208/  209] train: loss: 0.1581137
[Epoch 29] ogbg-moltox21: 0.745350 val loss: 0.548027
[Epoch 29] ogbg-moltox21: 0.729349 test loss: 0.454093
[Epoch 30; Iter    29/  209] train: loss: 0.0778837
[Epoch 30; Iter    59/  209] train: loss: 0.1555197
[Epoch 13; Iter    12/  209] train: loss: 0.2550663
[Epoch 13; Iter    42/  209] train: loss: 0.2222065
[Epoch 13; Iter    72/  209] train: loss: 0.2253401
[Epoch 13; Iter   102/  209] train: loss: 0.1872569
[Epoch 13; Iter   132/  209] train: loss: 0.1390342
[Epoch 13; Iter   162/  209] train: loss: 0.1992384
[Epoch 13; Iter   192/  209] train: loss: 0.1839276
[Epoch 13] ogbg-moltox21: 0.749367 val loss: 1.099650
[Epoch 13] ogbg-moltox21: 0.733499 test loss: 0.751902
[Epoch 14; Iter    13/  209] train: loss: 0.1862448
[Epoch 14; Iter    43/  209] train: loss: 0.1831108
[Epoch 14; Iter    73/  209] train: loss: 0.2151389
[Epoch 14; Iter   103/  209] train: loss: 0.1506443
[Epoch 14; Iter   133/  209] train: loss: 0.2224305
[Epoch 14; Iter   163/  209] train: loss: 0.1596566
[Epoch 14; Iter   193/  209] train: loss: 0.2349367
[Epoch 14] ogbg-moltox21: 0.755358 val loss: 1.742750
[Epoch 14] ogbg-moltox21: 0.745335 test loss: 2.414728
[Epoch 15; Iter    14/  209] train: loss: 0.2083042
[Epoch 15; Iter    44/  209] train: loss: 0.1896655
[Epoch 15; Iter    74/  209] train: loss: 0.1407344
[Epoch 15; Iter   104/  209] train: loss: 0.2523830
[Epoch 15; Iter   134/  209] train: loss: 0.1522324
[Epoch 15; Iter   164/  209] train: loss: 0.1293270
[Epoch 15; Iter   194/  209] train: loss: 0.1485290
[Epoch 15] ogbg-moltox21: 0.759623 val loss: 0.398210
[Epoch 15] ogbg-moltox21: 0.721408 test loss: 0.445341
[Epoch 16; Iter    15/  209] train: loss: 0.1392676
[Epoch 16; Iter    45/  209] train: loss: 0.2153260
[Epoch 16; Iter    75/  209] train: loss: 0.2172699
[Epoch 16; Iter   105/  209] train: loss: 0.2165650
[Epoch 16; Iter   135/  209] train: loss: 0.1668195
[Epoch 16; Iter   165/  209] train: loss: 0.1382270
[Epoch 16; Iter   195/  209] train: loss: 0.1699210
[Epoch 16] ogbg-moltox21: 0.766174 val loss: 0.278255
[Epoch 16] ogbg-moltox21: 0.750030 test loss: 0.290721
[Epoch 17; Iter    16/  209] train: loss: 0.1830603
[Epoch 17; Iter    46/  209] train: loss: 0.2292767
[Epoch 17; Iter    76/  209] train: loss: 0.1506906
[Epoch 17; Iter   106/  209] train: loss: 0.2098934
[Epoch 17; Iter   136/  209] train: loss: 0.1033564
[Epoch 17; Iter   166/  209] train: loss: 0.1668240
[Epoch 17; Iter   196/  209] train: loss: 0.1933364
[Epoch 17] ogbg-moltox21: 0.753899 val loss: 1.101568
[Epoch 17] ogbg-moltox21: 0.721148 test loss: 1.089689
[Epoch 18; Iter    17/  209] train: loss: 0.1585097
[Epoch 18; Iter    47/  209] train: loss: 0.1470183
[Epoch 18; Iter    77/  209] train: loss: 0.1854277
[Epoch 18; Iter   107/  209] train: loss: 0.2463630
[Epoch 18; Iter   137/  209] train: loss: 0.1242214
[Epoch 18; Iter   167/  209] train: loss: 0.1572536
[Epoch 18; Iter   197/  209] train: loss: 0.1395523
[Epoch 18] ogbg-moltox21: 0.761971 val loss: 1.968473
[Epoch 18] ogbg-moltox21: 0.717457 test loss: 2.324439
[Epoch 19; Iter    18/  209] train: loss: 0.1643535
[Epoch 19; Iter    48/  209] train: loss: 0.1098092
[Epoch 19; Iter    78/  209] train: loss: 0.1907544
[Epoch 19; Iter   108/  209] train: loss: 0.1715477
[Epoch 19; Iter   138/  209] train: loss: 0.1993883
[Epoch 19; Iter   168/  209] train: loss: 0.1973723
[Epoch 19; Iter   198/  209] train: loss: 0.1475790
[Epoch 19] ogbg-moltox21: 0.776668 val loss: 0.279670
[Epoch 19] ogbg-moltox21: 0.727284 test loss: 0.440621
[Epoch 20; Iter    19/  209] train: loss: 0.1944493
[Epoch 20; Iter    49/  209] train: loss: 0.1406622
[Epoch 20; Iter    79/  209] train: loss: 0.1326984
[Epoch 20; Iter   109/  209] train: loss: 0.1256058
[Epoch 20; Iter   139/  209] train: loss: 0.1493213
[Epoch 20; Iter   169/  209] train: loss: 0.2009963
[Epoch 20; Iter   199/  209] train: loss: 0.1703524
[Epoch 20] ogbg-moltox21: 0.762951 val loss: 0.318626
[Epoch 20] ogbg-moltox21: 0.724123 test loss: 0.435934
[Epoch 21; Iter    20/  209] train: loss: 0.1756294
[Epoch 21; Iter    50/  209] train: loss: 0.1806313
[Epoch 21; Iter    80/  209] train: loss: 0.1327623
[Epoch 21; Iter   110/  209] train: loss: 0.3169505
[Epoch 21; Iter   140/  209] train: loss: 0.1765734
[Epoch 21; Iter   170/  209] train: loss: 0.1964755
[Epoch 21; Iter   200/  209] train: loss: 0.1590769
[Epoch 21] ogbg-moltox21: 0.777695 val loss: 0.277967
[Epoch 21] ogbg-moltox21: 0.744497 test loss: 0.312912
[Epoch 22; Iter    21/  209] train: loss: 0.0954155
[Epoch 22; Iter    51/  209] train: loss: 0.2026318
[Epoch 22; Iter    81/  209] train: loss: 0.1327736
[Epoch 22; Iter   111/  209] train: loss: 0.2047320
[Epoch 22; Iter   141/  209] train: loss: 0.1440727
[Epoch 22; Iter   171/  209] train: loss: 0.1891366
[Epoch 22; Iter   201/  209] train: loss: 0.1490757
[Epoch 22] ogbg-moltox21: 0.777038 val loss: 0.394720
[Epoch 22] ogbg-moltox21: 0.733592 test loss: 0.395904
[Epoch 23; Iter    22/  209] train: loss: 0.1244163
[Epoch 23; Iter    52/  209] train: loss: 0.1157757
[Epoch 23; Iter    82/  209] train: loss: 0.1515836
[Epoch 23; Iter   112/  209] train: loss: 0.1706175
[Epoch 23; Iter   142/  209] train: loss: 0.1226725
[Epoch 23; Iter   172/  209] train: loss: 0.1528357
[Epoch 23; Iter   202/  209] train: loss: 0.1560969
[Epoch 23] ogbg-moltox21: 0.755457 val loss: 0.334874
[Epoch 23] ogbg-moltox21: 0.714086 test loss: 0.507561
[Epoch 24; Iter    23/  209] train: loss: 0.1360938
[Epoch 24; Iter    53/  209] train: loss: 0.1601714
[Epoch 24; Iter    83/  209] train: loss: 0.1475057
[Epoch 24; Iter   113/  209] train: loss: 0.1208928
[Epoch 24; Iter   143/  209] train: loss: 0.1544051
[Epoch 24; Iter   173/  209] train: loss: 0.1294422
[Epoch 24; Iter   203/  209] train: loss: 0.1934122
[Epoch 24] ogbg-moltox21: 0.780268 val loss: 0.269329
[Epoch 24] ogbg-moltox21: 0.734063 test loss: 0.436286
[Epoch 25; Iter    24/  209] train: loss: 0.1276320
[Epoch 25; Iter    54/  209] train: loss: 0.0987770
[Epoch 25; Iter    84/  209] train: loss: 0.0927327
[Epoch 25; Iter   114/  209] train: loss: 0.1524512
[Epoch 25; Iter   144/  209] train: loss: 0.2359342
[Epoch 25; Iter   174/  209] train: loss: 0.1169056
[Epoch 25; Iter   204/  209] train: loss: 0.1260425
[Epoch 25] ogbg-moltox21: 0.778720 val loss: 0.390746
[Epoch 25] ogbg-moltox21: 0.732920 test loss: 0.366639
[Epoch 26; Iter    25/  209] train: loss: 0.1174713
[Epoch 26; Iter    55/  209] train: loss: 0.1613756
[Epoch 26; Iter    85/  209] train: loss: 0.2100157
[Epoch 26; Iter   115/  209] train: loss: 0.1469693
[Epoch 26; Iter   145/  209] train: loss: 0.1170662
[Epoch 26; Iter   175/  209] train: loss: 0.0948358
[Epoch 26; Iter   205/  209] train: loss: 0.1098955
[Epoch 26] ogbg-moltox21: 0.770671 val loss: 0.296778
[Epoch 26] ogbg-moltox21: 0.726275 test loss: 0.320268
[Epoch 27; Iter    26/  209] train: loss: 0.1710888
[Epoch 27; Iter    56/  209] train: loss: 0.0917861
[Epoch 27; Iter    86/  209] train: loss: 0.1540107
[Epoch 27; Iter   116/  209] train: loss: 0.1140269
[Epoch 27; Iter   146/  209] train: loss: 0.1391187
[Epoch 27; Iter   176/  209] train: loss: 0.1862043
[Epoch 27; Iter   206/  209] train: loss: 0.1448540
[Epoch 27] ogbg-moltox21: 0.760882 val loss: 0.321845
[Epoch 27] ogbg-moltox21: 0.728794 test loss: 0.370048
[Epoch 28; Iter    27/  209] train: loss: 0.0721665
[Epoch 28; Iter    57/  209] train: loss: 0.2067480
[Epoch 28; Iter    87/  209] train: loss: 0.1349189
[Epoch 28; Iter   117/  209] train: loss: 0.0958612
[Epoch 28; Iter   147/  209] train: loss: 0.1429996
[Epoch 28; Iter   177/  209] train: loss: 0.1576658
[Epoch 28; Iter   207/  209] train: loss: 0.1331424
[Epoch 28] ogbg-moltox21: 0.753203 val loss: 0.296053
[Epoch 28] ogbg-moltox21: 0.726154 test loss: 0.344202
[Epoch 29; Iter    28/  209] train: loss: 0.1194627
[Epoch 29; Iter    58/  209] train: loss: 0.1415281
[Epoch 29; Iter    88/  209] train: loss: 0.1310621
[Epoch 29; Iter   118/  209] train: loss: 0.1970469
[Epoch 29; Iter   148/  209] train: loss: 0.1091872
[Epoch 29; Iter   178/  209] train: loss: 0.0914327
[Epoch 29; Iter   208/  209] train: loss: 0.1371440
[Epoch 29] ogbg-moltox21: 0.765624 val loss: 0.303279
[Epoch 29] ogbg-moltox21: 0.726808 test loss: 0.449296
[Epoch 30; Iter    29/  209] train: loss: 0.1279238
[Epoch 30; Iter    59/  209] train: loss: 0.1086536
[Epoch 13; Iter    12/  209] train: loss: 0.1862242
[Epoch 13; Iter    42/  209] train: loss: 0.1601716
[Epoch 13; Iter    72/  209] train: loss: 0.2504444
[Epoch 13; Iter   102/  209] train: loss: 0.1389439
[Epoch 13; Iter   132/  209] train: loss: 0.2763953
[Epoch 13; Iter   162/  209] train: loss: 0.2501574
[Epoch 13; Iter   192/  209] train: loss: 0.1760552
[Epoch 13] ogbg-moltox21: 0.780478 val loss: 0.288366
[Epoch 13] ogbg-moltox21: 0.731764 test loss: 0.339737
[Epoch 14; Iter    13/  209] train: loss: 0.1942151
[Epoch 14; Iter    43/  209] train: loss: 0.1683469
[Epoch 14; Iter    73/  209] train: loss: 0.1846342
[Epoch 14; Iter   103/  209] train: loss: 0.1772080
[Epoch 14; Iter   133/  209] train: loss: 0.2475622
[Epoch 14; Iter   163/  209] train: loss: 0.1980546
[Epoch 14; Iter   193/  209] train: loss: 0.2181842
[Epoch 14] ogbg-moltox21: 0.745997 val loss: 0.416749
[Epoch 14] ogbg-moltox21: 0.704224 test loss: 0.544289
[Epoch 15; Iter    14/  209] train: loss: 0.1644514
[Epoch 15; Iter    44/  209] train: loss: 0.2112628
[Epoch 15; Iter    74/  209] train: loss: 0.1622575
[Epoch 15; Iter   104/  209] train: loss: 0.2492028
[Epoch 15; Iter   134/  209] train: loss: 0.1723293
[Epoch 15; Iter   164/  209] train: loss: 0.1727861
[Epoch 15; Iter   194/  209] train: loss: 0.2224817
[Epoch 15] ogbg-moltox21: 0.742629 val loss: 0.344538
[Epoch 15] ogbg-moltox21: 0.709331 test loss: 0.358871
[Epoch 16; Iter    15/  209] train: loss: 0.1815676
[Epoch 16; Iter    45/  209] train: loss: 0.1604624
[Epoch 16; Iter    75/  209] train: loss: 0.2138721
[Epoch 16; Iter   105/  209] train: loss: 0.1713731
[Epoch 16; Iter   135/  209] train: loss: 0.1869503
[Epoch 16; Iter   165/  209] train: loss: 0.1681178
[Epoch 16; Iter   195/  209] train: loss: 0.1762630
[Epoch 16] ogbg-moltox21: 0.747905 val loss: 0.606549
[Epoch 16] ogbg-moltox21: 0.725095 test loss: 0.864167
[Epoch 17; Iter    16/  209] train: loss: 0.1544627
[Epoch 17; Iter    46/  209] train: loss: 0.1436789
[Epoch 17; Iter    76/  209] train: loss: 0.1156712
[Epoch 17; Iter   106/  209] train: loss: 0.1802950
[Epoch 17; Iter   136/  209] train: loss: 0.1584796
[Epoch 17; Iter   166/  209] train: loss: 0.1610008
[Epoch 17; Iter   196/  209] train: loss: 0.1453554
[Epoch 17] ogbg-moltox21: 0.773300 val loss: 0.268021
[Epoch 17] ogbg-moltox21: 0.716753 test loss: 0.421278
[Epoch 18; Iter    17/  209] train: loss: 0.1009295
[Epoch 18; Iter    47/  209] train: loss: 0.1804680
[Epoch 18; Iter    77/  209] train: loss: 0.2293164
[Epoch 18; Iter   107/  209] train: loss: 0.2727708
[Epoch 18; Iter   137/  209] train: loss: 0.1512262
[Epoch 18; Iter   167/  209] train: loss: 0.1515558
[Epoch 18; Iter   197/  209] train: loss: 0.1119366
[Epoch 18] ogbg-moltox21: 0.774999 val loss: 0.271086
[Epoch 18] ogbg-moltox21: 0.732361 test loss: 0.288754
[Epoch 19; Iter    18/  209] train: loss: 0.2889134
[Epoch 19; Iter    48/  209] train: loss: 0.1390079
[Epoch 19; Iter    78/  209] train: loss: 0.1395212
[Epoch 19; Iter   108/  209] train: loss: 0.1636982
[Epoch 19; Iter   138/  209] train: loss: 0.1245197
[Epoch 19; Iter   168/  209] train: loss: 0.1711224
[Epoch 19; Iter   198/  209] train: loss: 0.2574644
[Epoch 19] ogbg-moltox21: 0.766720 val loss: 0.308454
[Epoch 19] ogbg-moltox21: 0.725883 test loss: 0.383378
[Epoch 20; Iter    19/  209] train: loss: 0.2059128
[Epoch 20; Iter    49/  209] train: loss: 0.2003144
[Epoch 20; Iter    79/  209] train: loss: 0.1105913
[Epoch 20; Iter   109/  209] train: loss: 0.1390618
[Epoch 20; Iter   139/  209] train: loss: 0.1727186
[Epoch 20; Iter   169/  209] train: loss: 0.2208828
[Epoch 20; Iter   199/  209] train: loss: 0.1251407
[Epoch 20] ogbg-moltox21: 0.770725 val loss: 0.278859
[Epoch 20] ogbg-moltox21: 0.720621 test loss: 0.330639
[Epoch 21; Iter    20/  209] train: loss: 0.1156491
[Epoch 21; Iter    50/  209] train: loss: 0.1959077
[Epoch 21; Iter    80/  209] train: loss: 0.1769933
[Epoch 21; Iter   110/  209] train: loss: 0.1042233
[Epoch 21; Iter   140/  209] train: loss: 0.1785672
[Epoch 21; Iter   170/  209] train: loss: 0.3313124
[Epoch 21; Iter   200/  209] train: loss: 0.1477601
[Epoch 21] ogbg-moltox21: 0.775352 val loss: 0.280096
[Epoch 21] ogbg-moltox21: 0.732016 test loss: 0.298624
[Epoch 22; Iter    21/  209] train: loss: 0.1543917
[Epoch 22; Iter    51/  209] train: loss: 0.0742368
[Epoch 22; Iter    81/  209] train: loss: 0.1141510
[Epoch 22; Iter   111/  209] train: loss: 0.1166174
[Epoch 22; Iter   141/  209] train: loss: 0.1597691
[Epoch 22; Iter   171/  209] train: loss: 0.1207872
[Epoch 22; Iter   201/  209] train: loss: 0.1109978
[Epoch 22] ogbg-moltox21: 0.776552 val loss: 0.285612
[Epoch 22] ogbg-moltox21: 0.732346 test loss: 0.301461
[Epoch 23; Iter    22/  209] train: loss: 0.1675450
[Epoch 23; Iter    52/  209] train: loss: 0.1809688
[Epoch 23; Iter    82/  209] train: loss: 0.1162942
[Epoch 23; Iter   112/  209] train: loss: 0.1458171
[Epoch 23; Iter   142/  209] train: loss: 0.1571533
[Epoch 23; Iter   172/  209] train: loss: 0.1383648
[Epoch 23; Iter   202/  209] train: loss: 0.1270155
[Epoch 23] ogbg-moltox21: 0.760667 val loss: 0.291944
[Epoch 23] ogbg-moltox21: 0.720762 test loss: 0.670437
[Epoch 24; Iter    23/  209] train: loss: 0.1898008
[Epoch 24; Iter    53/  209] train: loss: 0.0823515
[Epoch 24; Iter    83/  209] train: loss: 0.1762382
[Epoch 24; Iter   113/  209] train: loss: 0.1304479
[Epoch 24; Iter   143/  209] train: loss: 0.0956923
[Epoch 24; Iter   173/  209] train: loss: 0.1046872
[Epoch 24; Iter   203/  209] train: loss: 0.1625051
[Epoch 24] ogbg-moltox21: 0.770947 val loss: 0.279792
[Epoch 24] ogbg-moltox21: 0.724456 test loss: 0.297581
[Epoch 25; Iter    24/  209] train: loss: 0.1005372
[Epoch 25; Iter    54/  209] train: loss: 0.1867498
[Epoch 25; Iter    84/  209] train: loss: 0.0973395
[Epoch 25; Iter   114/  209] train: loss: 0.1618416
[Epoch 25; Iter   144/  209] train: loss: 0.1289887
[Epoch 25; Iter   174/  209] train: loss: 0.1378770
[Epoch 25; Iter   204/  209] train: loss: 0.2192043
[Epoch 25] ogbg-moltox21: 0.780348 val loss: 0.280345
[Epoch 25] ogbg-moltox21: 0.726048 test loss: 0.816201
[Epoch 26; Iter    25/  209] train: loss: 0.1491538
[Epoch 26; Iter    55/  209] train: loss: 0.2319618
[Epoch 26; Iter    85/  209] train: loss: 0.1422752
[Epoch 26; Iter   115/  209] train: loss: 0.0909736
[Epoch 26; Iter   145/  209] train: loss: 0.1007810
[Epoch 26; Iter   175/  209] train: loss: 0.0894409
[Epoch 26; Iter   205/  209] train: loss: 0.1515468
[Epoch 26] ogbg-moltox21: 0.758904 val loss: 0.316526
[Epoch 26] ogbg-moltox21: 0.714949 test loss: 0.541738
[Epoch 27; Iter    26/  209] train: loss: 0.1137413
[Epoch 27; Iter    56/  209] train: loss: 0.2087328
[Epoch 27; Iter    86/  209] train: loss: 0.1516419
[Epoch 27; Iter   116/  209] train: loss: 0.1476535
[Epoch 27; Iter   146/  209] train: loss: 0.1090573
[Epoch 27; Iter   176/  209] train: loss: 0.1271627
[Epoch 27; Iter   206/  209] train: loss: 0.1145585
[Epoch 27] ogbg-moltox21: 0.778389 val loss: 0.293614
[Epoch 27] ogbg-moltox21: 0.720300 test loss: 0.765219
[Epoch 28; Iter    27/  209] train: loss: 0.1138793
[Epoch 28; Iter    57/  209] train: loss: 0.1136471
[Epoch 28; Iter    87/  209] train: loss: 0.1430924
[Epoch 28; Iter   117/  209] train: loss: 0.1394549
[Epoch 28; Iter   147/  209] train: loss: 0.1650185
[Epoch 28; Iter   177/  209] train: loss: 0.1247040
[Epoch 28; Iter   207/  209] train: loss: 0.1172354
[Epoch 28] ogbg-moltox21: 0.759671 val loss: 0.371693
[Epoch 28] ogbg-moltox21: 0.721525 test loss: 0.777152
[Epoch 29; Iter    28/  209] train: loss: 0.1217372
[Epoch 29; Iter    58/  209] train: loss: 0.1305696
[Epoch 29; Iter    88/  209] train: loss: 0.1299775
[Epoch 29; Iter   118/  209] train: loss: 0.1847482
[Epoch 29; Iter   148/  209] train: loss: 0.1183789
[Epoch 29; Iter   178/  209] train: loss: 0.0890168
[Epoch 29; Iter   208/  209] train: loss: 0.0924548
[Epoch 29] ogbg-moltox21: 0.761904 val loss: 0.345936
[Epoch 29] ogbg-moltox21: 0.709496 test loss: 1.441816
[Epoch 30; Iter    29/  209] train: loss: 0.1243188
[Epoch 30; Iter    59/  209] train: loss: 0.1168533
[Epoch 13; Iter    12/  209] train: loss: 0.1581798
[Epoch 13; Iter    42/  209] train: loss: 0.1704076
[Epoch 13; Iter    72/  209] train: loss: 0.1732008
[Epoch 13; Iter   102/  209] train: loss: 0.1981002
[Epoch 13; Iter   132/  209] train: loss: 0.1622482
[Epoch 13; Iter   162/  209] train: loss: 0.2876914
[Epoch 13; Iter   192/  209] train: loss: 0.1918211
[Epoch 13] ogbg-moltox21: 0.746625 val loss: 0.299391
[Epoch 13] ogbg-moltox21: 0.711623 test loss: 0.431856
[Epoch 14; Iter    13/  209] train: loss: 0.1107748
[Epoch 14; Iter    43/  209] train: loss: 0.1938119
[Epoch 14; Iter    73/  209] train: loss: 0.1406177
[Epoch 14; Iter   103/  209] train: loss: 0.2581037
[Epoch 14; Iter   133/  209] train: loss: 0.1784767
[Epoch 14; Iter   163/  209] train: loss: 0.2215143
[Epoch 14; Iter   193/  209] train: loss: 0.1987340
[Epoch 14] ogbg-moltox21: 0.749381 val loss: 0.284918
[Epoch 14] ogbg-moltox21: 0.716846 test loss: 0.307872
[Epoch 15; Iter    14/  209] train: loss: 0.1224283
[Epoch 15; Iter    44/  209] train: loss: 0.1277461
[Epoch 15; Iter    74/  209] train: loss: 0.2009251
[Epoch 15; Iter   104/  209] train: loss: 0.1717725
[Epoch 15; Iter   134/  209] train: loss: 0.1385830
[Epoch 15; Iter   164/  209] train: loss: 0.1511918
[Epoch 15; Iter   194/  209] train: loss: 0.1726009
[Epoch 15] ogbg-moltox21: 0.755411 val loss: 0.285379
[Epoch 15] ogbg-moltox21: 0.715872 test loss: 0.308071
[Epoch 16; Iter    15/  209] train: loss: 0.1394158
[Epoch 16; Iter    45/  209] train: loss: 0.1713286
[Epoch 16; Iter    75/  209] train: loss: 0.2557858
[Epoch 16; Iter   105/  209] train: loss: 0.2645868
[Epoch 16; Iter   135/  209] train: loss: 0.2516896
[Epoch 16; Iter   165/  209] train: loss: 0.2922677
[Epoch 16; Iter   195/  209] train: loss: 0.2121416
[Epoch 16] ogbg-moltox21: 0.734528 val loss: 0.290413
[Epoch 16] ogbg-moltox21: 0.694029 test loss: 0.306813
[Epoch 17; Iter    16/  209] train: loss: 0.1825119
[Epoch 17; Iter    46/  209] train: loss: 0.2326733
[Epoch 17; Iter    76/  209] train: loss: 0.2402619
[Epoch 17; Iter   106/  209] train: loss: 0.1701303
[Epoch 17; Iter   136/  209] train: loss: 0.2952726
[Epoch 17; Iter   166/  209] train: loss: 0.2071152
[Epoch 17; Iter   196/  209] train: loss: 0.1674166
[Epoch 17] ogbg-moltox21: 0.746045 val loss: 0.280840
[Epoch 17] ogbg-moltox21: 0.700770 test loss: 0.551511
[Epoch 18; Iter    17/  209] train: loss: 0.1327487
[Epoch 18; Iter    47/  209] train: loss: 0.1437092
[Epoch 18; Iter    77/  209] train: loss: 0.2371162
[Epoch 18; Iter   107/  209] train: loss: 0.1628739
[Epoch 18; Iter   137/  209] train: loss: 0.1129502
[Epoch 18; Iter   167/  209] train: loss: 0.1617978
[Epoch 18; Iter   197/  209] train: loss: 0.2075880
[Epoch 18] ogbg-moltox21: 0.744684 val loss: 0.281693
[Epoch 18] ogbg-moltox21: 0.709070 test loss: 0.303079
[Epoch 19; Iter    18/  209] train: loss: 0.1336658
[Epoch 19; Iter    48/  209] train: loss: 0.1159119
[Epoch 19; Iter    78/  209] train: loss: 0.2017904
[Epoch 19; Iter   108/  209] train: loss: 0.1192594
[Epoch 19; Iter   138/  209] train: loss: 0.1795021
[Epoch 19; Iter   168/  209] train: loss: 0.1855762
[Epoch 19; Iter   198/  209] train: loss: 0.2761869
[Epoch 19] ogbg-moltox21: 0.740356 val loss: 0.347406
[Epoch 19] ogbg-moltox21: 0.713898 test loss: 0.391908
[Epoch 20; Iter    19/  209] train: loss: 0.1788968
[Epoch 20; Iter    49/  209] train: loss: 0.1052503
[Epoch 20; Iter    79/  209] train: loss: 0.1352458
[Epoch 20; Iter   109/  209] train: loss: 0.1768799
[Epoch 20; Iter   139/  209] train: loss: 0.1353324
[Epoch 20; Iter   169/  209] train: loss: 0.1784220
[Epoch 20; Iter   199/  209] train: loss: 0.2171247
[Epoch 20] ogbg-moltox21: 0.698036 val loss: 0.403509
[Epoch 20] ogbg-moltox21: 0.676968 test loss: 0.523990
[Epoch 21; Iter    20/  209] train: loss: 0.1880108
[Epoch 21; Iter    50/  209] train: loss: 0.1877907
[Epoch 21; Iter    80/  209] train: loss: 0.1611358
[Epoch 21; Iter   110/  209] train: loss: 0.1948812
[Epoch 21; Iter   140/  209] train: loss: 0.1021732
[Epoch 21; Iter   170/  209] train: loss: 0.1604288
[Epoch 21; Iter   200/  209] train: loss: 0.1032407
[Epoch 21] ogbg-moltox21: 0.706370 val loss: 0.704025
[Epoch 21] ogbg-moltox21: 0.696846 test loss: 1.667733
[Epoch 22; Iter    21/  209] train: loss: 0.1991242
[Epoch 22; Iter    51/  209] train: loss: 0.1724609
[Epoch 22; Iter    81/  209] train: loss: 0.0925404
[Epoch 22; Iter   111/  209] train: loss: 0.1666456
[Epoch 22; Iter   141/  209] train: loss: 0.1293019
[Epoch 22; Iter   171/  209] train: loss: 0.2126580
[Epoch 22; Iter   201/  209] train: loss: 0.1606200
[Epoch 22] ogbg-moltox21: 0.754425 val loss: 0.387315
[Epoch 22] ogbg-moltox21: 0.715152 test loss: 0.555771
[Epoch 23; Iter    22/  209] train: loss: 0.1063357
[Epoch 23; Iter    52/  209] train: loss: 0.1805583
[Epoch 23; Iter    82/  209] train: loss: 0.1516665
[Epoch 23; Iter   112/  209] train: loss: 0.1438042
[Epoch 23; Iter   142/  209] train: loss: 0.1295332
[Epoch 23; Iter   172/  209] train: loss: 0.1553051
[Epoch 23; Iter   202/  209] train: loss: 0.1965731
[Epoch 23] ogbg-moltox21: 0.689475 val loss: 0.622929
[Epoch 23] ogbg-moltox21: 0.680720 test loss: 1.031132
[Epoch 24; Iter    23/  209] train: loss: 0.2157966
[Epoch 24; Iter    53/  209] train: loss: 0.1410311
[Epoch 24; Iter    83/  209] train: loss: 0.2306662
[Epoch 24; Iter   113/  209] train: loss: 0.1301577
[Epoch 24; Iter   143/  209] train: loss: 0.1823531
[Epoch 24; Iter   173/  209] train: loss: 0.1439447
[Epoch 24; Iter   203/  209] train: loss: 0.1669437
[Epoch 24] ogbg-moltox21: 0.746467 val loss: 0.356766
[Epoch 24] ogbg-moltox21: 0.704185 test loss: 0.406407
[Epoch 25; Iter    24/  209] train: loss: 0.1507534
[Epoch 25; Iter    54/  209] train: loss: 0.1844916
[Epoch 25; Iter    84/  209] train: loss: 0.1195478
[Epoch 25; Iter   114/  209] train: loss: 0.1923599
[Epoch 25; Iter   144/  209] train: loss: 0.0993302
[Epoch 25; Iter   174/  209] train: loss: 0.1950220
[Epoch 25; Iter   204/  209] train: loss: 0.1083436
[Epoch 25] ogbg-moltox21: 0.716482 val loss: 0.360886
[Epoch 25] ogbg-moltox21: 0.702535 test loss: 0.486309
[Epoch 26; Iter    25/  209] train: loss: 0.0836329
[Epoch 26; Iter    55/  209] train: loss: 0.1357234
[Epoch 26; Iter    85/  209] train: loss: 0.1746282
[Epoch 26; Iter   115/  209] train: loss: 0.1076657
[Epoch 26; Iter   145/  209] train: loss: 0.1126840
[Epoch 26; Iter   175/  209] train: loss: 0.1046956
[Epoch 26; Iter   205/  209] train: loss: 0.2291676
[Epoch 26] ogbg-moltox21: 0.708904 val loss: 0.326558
[Epoch 26] ogbg-moltox21: 0.700605 test loss: 0.333545
[Epoch 27; Iter    26/  209] train: loss: 0.1095335
[Epoch 27; Iter    56/  209] train: loss: 0.0862617
[Epoch 27; Iter    86/  209] train: loss: 0.1350379
[Epoch 27; Iter   116/  209] train: loss: 0.1681007
[Epoch 27; Iter   146/  209] train: loss: 0.1261634
[Epoch 27; Iter   176/  209] train: loss: 0.1173092
[Epoch 27; Iter   206/  209] train: loss: 0.1706806
[Epoch 27] ogbg-moltox21: 0.730669 val loss: 0.311191
[Epoch 27] ogbg-moltox21: 0.718126 test loss: 0.325064
[Epoch 28; Iter    27/  209] train: loss: 0.1641594
[Epoch 28; Iter    57/  209] train: loss: 0.0754718
[Epoch 28; Iter    87/  209] train: loss: 0.1728452
[Epoch 28; Iter   117/  209] train: loss: 0.1548912
[Epoch 28; Iter   147/  209] train: loss: 0.2253932
[Epoch 28; Iter   177/  209] train: loss: 0.1620205
[Epoch 28; Iter   207/  209] train: loss: 0.0967602
[Epoch 28] ogbg-moltox21: 0.716733 val loss: 0.314591
[Epoch 28] ogbg-moltox21: 0.713894 test loss: 0.323572
[Epoch 29; Iter    28/  209] train: loss: 0.1242717
[Epoch 29; Iter    58/  209] train: loss: 0.1134721
[Epoch 29; Iter    88/  209] train: loss: 0.1387074
[Epoch 29; Iter   118/  209] train: loss: 0.1105633
[Epoch 29; Iter   148/  209] train: loss: 0.1922553
[Epoch 29; Iter   178/  209] train: loss: 0.1193226
[Epoch 29; Iter   208/  209] train: loss: 0.1490225
[Epoch 29] ogbg-moltox21: 0.706656 val loss: 0.315100
[Epoch 29] ogbg-moltox21: 0.706976 test loss: 0.321003
[Epoch 30; Iter    29/  209] train: loss: 0.0984314
[Epoch 30; Iter    59/  209] train: loss: 0.1688584
[Epoch 13; Iter    12/  209] train: loss: 0.1987449
[Epoch 13; Iter    42/  209] train: loss: 0.1626280
[Epoch 13; Iter    72/  209] train: loss: 0.2343775
[Epoch 13; Iter   102/  209] train: loss: 0.1818717
[Epoch 13; Iter   132/  209] train: loss: 0.2702585
[Epoch 13; Iter   162/  209] train: loss: 0.2643167
[Epoch 13; Iter   192/  209] train: loss: 0.1839339
[Epoch 13] ogbg-moltox21: 0.760158 val loss: 0.597841
[Epoch 13] ogbg-moltox21: 0.718813 test loss: 0.484280
[Epoch 14; Iter    13/  209] train: loss: 0.1957021
[Epoch 14; Iter    43/  209] train: loss: 0.1710403
[Epoch 14; Iter    73/  209] train: loss: 0.1914287
[Epoch 14; Iter   103/  209] train: loss: 0.1902479
[Epoch 14; Iter   133/  209] train: loss: 0.2436237
[Epoch 14; Iter   163/  209] train: loss: 0.2031309
[Epoch 14; Iter   193/  209] train: loss: 0.2250948
[Epoch 14] ogbg-moltox21: 0.743924 val loss: 0.271456
[Epoch 14] ogbg-moltox21: 0.680004 test loss: 0.289155
[Epoch 15; Iter    14/  209] train: loss: 0.1784499
[Epoch 15; Iter    44/  209] train: loss: 0.2564743
[Epoch 15; Iter    74/  209] train: loss: 0.1672481
[Epoch 15; Iter   104/  209] train: loss: 0.2343276
[Epoch 15; Iter   134/  209] train: loss: 0.1521838
[Epoch 15; Iter   164/  209] train: loss: 0.1869107
[Epoch 15; Iter   194/  209] train: loss: 0.2105180
[Epoch 15] ogbg-moltox21: 0.693063 val loss: 0.633367
[Epoch 15] ogbg-moltox21: 0.649970 test loss: 0.720484
[Epoch 16; Iter    15/  209] train: loss: 0.1834658
[Epoch 16; Iter    45/  209] train: loss: 0.1572600
[Epoch 16; Iter    75/  209] train: loss: 0.2135822
[Epoch 16; Iter   105/  209] train: loss: 0.1981716
[Epoch 16; Iter   135/  209] train: loss: 0.1910965
[Epoch 16; Iter   165/  209] train: loss: 0.1766740
[Epoch 16; Iter   195/  209] train: loss: 0.2057156
[Epoch 16] ogbg-moltox21: 0.709381 val loss: 0.571001
[Epoch 16] ogbg-moltox21: 0.685750 test loss: 0.481374
[Epoch 17; Iter    16/  209] train: loss: 0.1408131
[Epoch 17; Iter    46/  209] train: loss: 0.1490351
[Epoch 17; Iter    76/  209] train: loss: 0.1241583
[Epoch 17; Iter   106/  209] train: loss: 0.1797021
[Epoch 17; Iter   136/  209] train: loss: 0.1459169
[Epoch 17; Iter   166/  209] train: loss: 0.1623153
[Epoch 17; Iter   196/  209] train: loss: 0.1632130
[Epoch 17] ogbg-moltox21: 0.725886 val loss: 0.348546
[Epoch 17] ogbg-moltox21: 0.670100 test loss: 0.353685
[Epoch 18; Iter    17/  209] train: loss: 0.1012898
[Epoch 18; Iter    47/  209] train: loss: 0.1804528
[Epoch 18; Iter    77/  209] train: loss: 0.2587933
[Epoch 18; Iter   107/  209] train: loss: 0.3141982
[Epoch 18; Iter   137/  209] train: loss: 0.1698919
[Epoch 18; Iter   167/  209] train: loss: 0.1757385
[Epoch 18; Iter   197/  209] train: loss: 0.1169228
[Epoch 18] ogbg-moltox21: 0.724635 val loss: 0.411846
[Epoch 18] ogbg-moltox21: 0.703229 test loss: 0.291864
[Epoch 19; Iter    18/  209] train: loss: 0.3459764
[Epoch 19; Iter    48/  209] train: loss: 0.1737050
[Epoch 19; Iter    78/  209] train: loss: 0.1647837
[Epoch 19; Iter   108/  209] train: loss: 0.2541805
[Epoch 19; Iter   138/  209] train: loss: 0.1520495
[Epoch 19; Iter   168/  209] train: loss: 0.2430178
[Epoch 19; Iter   198/  209] train: loss: 0.2935475
[Epoch 19] ogbg-moltox21: 0.728672 val loss: 0.325358
[Epoch 19] ogbg-moltox21: 0.707961 test loss: 0.312731
[Epoch 20; Iter    19/  209] train: loss: 0.2243761
[Epoch 20; Iter    49/  209] train: loss: 0.2559662
[Epoch 20; Iter    79/  209] train: loss: 0.1284956
[Epoch 20; Iter   109/  209] train: loss: 0.1339607
[Epoch 20; Iter   139/  209] train: loss: 0.2157179
[Epoch 20; Iter   169/  209] train: loss: 0.2255300
[Epoch 20; Iter   199/  209] train: loss: 0.1420286
[Epoch 20] ogbg-moltox21: 0.700863 val loss: 0.455150
[Epoch 20] ogbg-moltox21: 0.684809 test loss: 0.391408
[Epoch 21; Iter    20/  209] train: loss: 0.1655171
[Epoch 21; Iter    50/  209] train: loss: 0.2278822
[Epoch 21; Iter    80/  209] train: loss: 0.2114692
[Epoch 21; Iter   110/  209] train: loss: 0.1198693
[Epoch 21; Iter   140/  209] train: loss: 0.2397544
[Epoch 21; Iter   170/  209] train: loss: 0.3684455
[Epoch 21; Iter   200/  209] train: loss: 0.1866888
[Epoch 21] ogbg-moltox21: 0.703465 val loss: 0.670753
[Epoch 21] ogbg-moltox21: 0.682197 test loss: 0.793363
[Epoch 22; Iter    21/  209] train: loss: 0.1455722
[Epoch 22; Iter    51/  209] train: loss: 0.0798847
[Epoch 22; Iter    81/  209] train: loss: 0.1426526
[Epoch 22; Iter   111/  209] train: loss: 0.1495157
[Epoch 22; Iter   141/  209] train: loss: 0.1767617
[Epoch 22; Iter   171/  209] train: loss: 0.1357826
[Epoch 22; Iter   201/  209] train: loss: 0.1129383
[Epoch 22] ogbg-moltox21: 0.656383 val loss: 0.394619
[Epoch 22] ogbg-moltox21: 0.633044 test loss: 0.410874
[Epoch 23; Iter    22/  209] train: loss: 0.1808695
[Epoch 23; Iter    52/  209] train: loss: 0.2016243
[Epoch 23; Iter    82/  209] train: loss: 0.1292103
[Epoch 23; Iter   112/  209] train: loss: 0.1481642
[Epoch 23; Iter   142/  209] train: loss: 0.2059030
[Epoch 23; Iter   172/  209] train: loss: 0.1451340
[Epoch 23; Iter   202/  209] train: loss: 0.1169076
[Epoch 23] ogbg-moltox21: 0.757301 val loss: 0.298713
[Epoch 23] ogbg-moltox21: 0.703210 test loss: 0.342728
[Epoch 24; Iter    23/  209] train: loss: 0.2112354
[Epoch 24; Iter    53/  209] train: loss: 0.1351545
[Epoch 24; Iter    83/  209] train: loss: 0.1906654
[Epoch 24; Iter   113/  209] train: loss: 0.1520671
[Epoch 24; Iter   143/  209] train: loss: 0.1047891
[Epoch 24; Iter   173/  209] train: loss: 0.1277123
[Epoch 24; Iter   203/  209] train: loss: 0.2201139
[Epoch 24] ogbg-moltox21: 0.719194 val loss: 0.343634
[Epoch 24] ogbg-moltox21: 0.685468 test loss: 0.360086
[Epoch 25; Iter    24/  209] train: loss: 0.1263564
[Epoch 25; Iter    54/  209] train: loss: 0.2438006
[Epoch 25; Iter    84/  209] train: loss: 0.1125813
[Epoch 25; Iter   114/  209] train: loss: 0.1682990
[Epoch 25; Iter   144/  209] train: loss: 0.1140846
[Epoch 25; Iter   174/  209] train: loss: 0.1597704
[Epoch 25; Iter   204/  209] train: loss: 0.2353738
[Epoch 25] ogbg-moltox21: 0.744400 val loss: 0.307318
[Epoch 25] ogbg-moltox21: 0.693387 test loss: 0.334100
[Epoch 26; Iter    25/  209] train: loss: 0.1608119
[Epoch 26; Iter    55/  209] train: loss: 0.2164040
[Epoch 26; Iter    85/  209] train: loss: 0.1699614
[Epoch 26; Iter   115/  209] train: loss: 0.1004732
[Epoch 26; Iter   145/  209] train: loss: 0.1358434
[Epoch 26; Iter   175/  209] train: loss: 0.1091850
[Epoch 26; Iter   205/  209] train: loss: 0.1679197
[Epoch 26] ogbg-moltox21: 0.723818 val loss: 0.331586
[Epoch 26] ogbg-moltox21: 0.675076 test loss: 0.354732
[Epoch 27; Iter    26/  209] train: loss: 0.1228267
[Epoch 27; Iter    56/  209] train: loss: 0.2403470
[Epoch 27; Iter    86/  209] train: loss: 0.1528697
[Epoch 27; Iter   116/  209] train: loss: 0.1454210
[Epoch 27; Iter   146/  209] train: loss: 0.1526884
[Epoch 27; Iter   176/  209] train: loss: 0.1224270
[Epoch 27; Iter   206/  209] train: loss: 0.1596130
[Epoch 27] ogbg-moltox21: 0.727551 val loss: 0.347134
[Epoch 27] ogbg-moltox21: 0.677341 test loss: 0.502337
[Epoch 28; Iter    27/  209] train: loss: 0.1171714
[Epoch 28; Iter    57/  209] train: loss: 0.1200049
[Epoch 28; Iter    87/  209] train: loss: 0.1358434
[Epoch 28; Iter   117/  209] train: loss: 0.1441392
[Epoch 28; Iter   147/  209] train: loss: 0.1685684
[Epoch 28; Iter   177/  209] train: loss: 0.1271611
[Epoch 28; Iter   207/  209] train: loss: 0.1330778
[Epoch 28] ogbg-moltox21: 0.731315 val loss: 0.332032
[Epoch 28] ogbg-moltox21: 0.694436 test loss: 0.372064
[Epoch 29; Iter    28/  209] train: loss: 0.1275950
[Epoch 29; Iter    58/  209] train: loss: 0.1316587
[Epoch 29; Iter    88/  209] train: loss: 0.1603770
[Epoch 29; Iter   118/  209] train: loss: 0.2072192
[Epoch 29; Iter   148/  209] train: loss: 0.1210320
[Epoch 29; Iter   178/  209] train: loss: 0.1157290
[Epoch 29; Iter   208/  209] train: loss: 0.1032063
[Epoch 29] ogbg-moltox21: 0.712936 val loss: 0.343441
[Epoch 29] ogbg-moltox21: 0.672972 test loss: 0.368879
[Epoch 30; Iter    29/  209] train: loss: 0.1394510
[Epoch 30; Iter    59/  209] train: loss: 0.1088935
[Epoch 13; Iter    12/  209] train: loss: 0.2504857
[Epoch 13; Iter    42/  209] train: loss: 0.2079647
[Epoch 13; Iter    72/  209] train: loss: 0.2297483
[Epoch 13; Iter   102/  209] train: loss: 0.1903830
[Epoch 13; Iter   132/  209] train: loss: 0.1537655
[Epoch 13; Iter   162/  209] train: loss: 0.1991598
[Epoch 13; Iter   192/  209] train: loss: 0.1582750
[Epoch 13] ogbg-moltox21: 0.721136 val loss: 4.861327
[Epoch 13] ogbg-moltox21: 0.698944 test loss: 8.887113
[Epoch 14; Iter    13/  209] train: loss: 0.1682427
[Epoch 14; Iter    43/  209] train: loss: 0.1805767
[Epoch 14; Iter    73/  209] train: loss: 0.2136508
[Epoch 14; Iter   103/  209] train: loss: 0.1672369
[Epoch 14; Iter   133/  209] train: loss: 0.2281295
[Epoch 14; Iter   163/  209] train: loss: 0.1564333
[Epoch 14; Iter   193/  209] train: loss: 0.2434039
[Epoch 14] ogbg-moltox21: 0.705711 val loss: 6.530120
[Epoch 14] ogbg-moltox21: 0.693351 test loss: 11.184322
[Epoch 15; Iter    14/  209] train: loss: 0.2139398
[Epoch 15; Iter    44/  209] train: loss: 0.1852852
[Epoch 15; Iter    74/  209] train: loss: 0.1558882
[Epoch 15; Iter   104/  209] train: loss: 0.2513244
[Epoch 15; Iter   134/  209] train: loss: 0.1883669
[Epoch 15; Iter   164/  209] train: loss: 0.1347545
[Epoch 15; Iter   194/  209] train: loss: 0.1867793
[Epoch 15] ogbg-moltox21: 0.744196 val loss: 0.576912
[Epoch 15] ogbg-moltox21: 0.708296 test loss: 1.198927
[Epoch 16; Iter    15/  209] train: loss: 0.1524492
[Epoch 16; Iter    45/  209] train: loss: 0.2097752
[Epoch 16; Iter    75/  209] train: loss: 0.2162120
[Epoch 16; Iter   105/  209] train: loss: 0.2207064
[Epoch 16; Iter   135/  209] train: loss: 0.1836152
[Epoch 16; Iter   165/  209] train: loss: 0.1282422
[Epoch 16; Iter   195/  209] train: loss: 0.1795267
[Epoch 16] ogbg-moltox21: 0.767882 val loss: 0.276779
[Epoch 16] ogbg-moltox21: 0.714420 test loss: 0.292393
[Epoch 17; Iter    16/  209] train: loss: 0.1939280
[Epoch 17; Iter    46/  209] train: loss: 0.2241316
[Epoch 17; Iter    76/  209] train: loss: 0.1909634
[Epoch 17; Iter   106/  209] train: loss: 0.2364653
[Epoch 17; Iter   136/  209] train: loss: 0.0936274
[Epoch 17; Iter   166/  209] train: loss: 0.1539320
[Epoch 17; Iter   196/  209] train: loss: 0.1903452
[Epoch 17] ogbg-moltox21: 0.755476 val loss: 0.324185
[Epoch 17] ogbg-moltox21: 0.709844 test loss: 0.398279
[Epoch 18; Iter    17/  209] train: loss: 0.1814669
[Epoch 18; Iter    47/  209] train: loss: 0.1453616
[Epoch 18; Iter    77/  209] train: loss: 0.1842025
[Epoch 18; Iter   107/  209] train: loss: 0.2365978
[Epoch 18; Iter   137/  209] train: loss: 0.1260887
[Epoch 18; Iter   167/  209] train: loss: 0.1670665
[Epoch 18; Iter   197/  209] train: loss: 0.1499568
[Epoch 18] ogbg-moltox21: 0.733681 val loss: 0.758826
[Epoch 18] ogbg-moltox21: 0.697992 test loss: 0.919235
[Epoch 19; Iter    18/  209] train: loss: 0.1682986
[Epoch 19; Iter    48/  209] train: loss: 0.1126541
[Epoch 19; Iter    78/  209] train: loss: 0.1835685
[Epoch 19; Iter   108/  209] train: loss: 0.1590717
[Epoch 19; Iter   138/  209] train: loss: 0.1900292
[Epoch 19; Iter   168/  209] train: loss: 0.1955565
[Epoch 19; Iter   198/  209] train: loss: 0.1389857
[Epoch 19] ogbg-moltox21: 0.736053 val loss: 0.828143
[Epoch 19] ogbg-moltox21: 0.692370 test loss: 1.347000
[Epoch 20; Iter    19/  209] train: loss: 0.1922005
[Epoch 20; Iter    49/  209] train: loss: 0.1428336
[Epoch 20; Iter    79/  209] train: loss: 0.1269596
[Epoch 20; Iter   109/  209] train: loss: 0.1304384
[Epoch 20; Iter   139/  209] train: loss: 0.1603492
[Epoch 20; Iter   169/  209] train: loss: 0.2017549
[Epoch 20; Iter   199/  209] train: loss: 0.1970231
[Epoch 20] ogbg-moltox21: 0.714630 val loss: 0.616330
[Epoch 20] ogbg-moltox21: 0.675790 test loss: 0.725132
[Epoch 21; Iter    20/  209] train: loss: 0.1583980
[Epoch 21; Iter    50/  209] train: loss: 0.1783039
[Epoch 21; Iter    80/  209] train: loss: 0.1396323
[Epoch 21; Iter   110/  209] train: loss: 0.3200134
[Epoch 21; Iter   140/  209] train: loss: 0.1598605
[Epoch 21; Iter   170/  209] train: loss: 0.1756033
[Epoch 21; Iter   200/  209] train: loss: 0.1728463
[Epoch 21] ogbg-moltox21: 0.753154 val loss: 0.319823
[Epoch 21] ogbg-moltox21: 0.704394 test loss: 0.474284
[Epoch 22; Iter    21/  209] train: loss: 0.1091493
[Epoch 22; Iter    51/  209] train: loss: 0.2071187
[Epoch 22; Iter    81/  209] train: loss: 0.1490376
[Epoch 22; Iter   111/  209] train: loss: 0.2214034
[Epoch 22; Iter   141/  209] train: loss: 0.1152563
[Epoch 22; Iter   171/  209] train: loss: 0.2168569
[Epoch 22; Iter   201/  209] train: loss: 0.1511049
[Epoch 22] ogbg-moltox21: 0.736166 val loss: 0.571040
[Epoch 22] ogbg-moltox21: 0.690313 test loss: 0.692363
[Epoch 23; Iter    22/  209] train: loss: 0.1190050
[Epoch 23; Iter    52/  209] train: loss: 0.1125370
[Epoch 23; Iter    82/  209] train: loss: 0.1560106
[Epoch 23; Iter   112/  209] train: loss: 0.1739895
[Epoch 23; Iter   142/  209] train: loss: 0.1372636
[Epoch 23; Iter   172/  209] train: loss: 0.1646322
[Epoch 23; Iter   202/  209] train: loss: 0.1363433
[Epoch 23] ogbg-moltox21: 0.736933 val loss: 0.540193
[Epoch 23] ogbg-moltox21: 0.688593 test loss: 0.558389
[Epoch 24; Iter    23/  209] train: loss: 0.1286076
[Epoch 24; Iter    53/  209] train: loss: 0.1515584
[Epoch 24; Iter    83/  209] train: loss: 0.1289672
[Epoch 24; Iter   113/  209] train: loss: 0.1167831
[Epoch 24; Iter   143/  209] train: loss: 0.1370410
[Epoch 24; Iter   173/  209] train: loss: 0.1290490
[Epoch 24; Iter   203/  209] train: loss: 0.1723841
[Epoch 24] ogbg-moltox21: 0.732719 val loss: 0.639246
[Epoch 24] ogbg-moltox21: 0.689907 test loss: 1.197859
[Epoch 25; Iter    24/  209] train: loss: 0.1079957
[Epoch 25; Iter    54/  209] train: loss: 0.1145217
[Epoch 25; Iter    84/  209] train: loss: 0.1000508
[Epoch 25; Iter   114/  209] train: loss: 0.1428106
[Epoch 25; Iter   144/  209] train: loss: 0.2173752
[Epoch 25; Iter   174/  209] train: loss: 0.1192295
[Epoch 25; Iter   204/  209] train: loss: 0.1291124
[Epoch 25] ogbg-moltox21: 0.755710 val loss: 0.731970
[Epoch 25] ogbg-moltox21: 0.699930 test loss: 1.155495
[Epoch 26; Iter    25/  209] train: loss: 0.1004305
[Epoch 26; Iter    55/  209] train: loss: 0.1850753
[Epoch 26; Iter    85/  209] train: loss: 0.1986488
[Epoch 26; Iter   115/  209] train: loss: 0.1258175
[Epoch 26; Iter   145/  209] train: loss: 0.1170735
[Epoch 26; Iter   175/  209] train: loss: 0.1156628
[Epoch 26; Iter   205/  209] train: loss: 0.1104940
[Epoch 26] ogbg-moltox21: 0.745798 val loss: 0.317334
[Epoch 26] ogbg-moltox21: 0.687651 test loss: 0.805477
[Epoch 27; Iter    26/  209] train: loss: 0.1615119
[Epoch 27; Iter    56/  209] train: loss: 0.0644726
[Epoch 27; Iter    86/  209] train: loss: 0.1529650
[Epoch 27; Iter   116/  209] train: loss: 0.1257867
[Epoch 27; Iter   146/  209] train: loss: 0.1409028
[Epoch 27; Iter   176/  209] train: loss: 0.1960517
[Epoch 27; Iter   206/  209] train: loss: 0.1436881
[Epoch 27] ogbg-moltox21: 0.765758 val loss: 0.353468
[Epoch 27] ogbg-moltox21: 0.701762 test loss: 0.512598
[Epoch 28; Iter    27/  209] train: loss: 0.0867617
[Epoch 28; Iter    57/  209] train: loss: 0.2196079
[Epoch 28; Iter    87/  209] train: loss: 0.1586842
[Epoch 28; Iter   117/  209] train: loss: 0.1021140
[Epoch 28; Iter   147/  209] train: loss: 0.1758246
[Epoch 28; Iter   177/  209] train: loss: 0.1720227
[Epoch 28; Iter   207/  209] train: loss: 0.0942797
[Epoch 28] ogbg-moltox21: 0.748783 val loss: 0.410624
[Epoch 28] ogbg-moltox21: 0.702552 test loss: 1.067967
[Epoch 29; Iter    28/  209] train: loss: 0.0984423
[Epoch 29; Iter    58/  209] train: loss: 0.1011435
[Epoch 29; Iter    88/  209] train: loss: 0.1189671
[Epoch 29; Iter   118/  209] train: loss: 0.1769821
[Epoch 29; Iter   148/  209] train: loss: 0.1147216
[Epoch 29; Iter   178/  209] train: loss: 0.0765191
[Epoch 29; Iter   208/  209] train: loss: 0.1180728
[Epoch 29] ogbg-moltox21: 0.754109 val loss: 0.325796
[Epoch 29] ogbg-moltox21: 0.699141 test loss: 0.414108
[Epoch 30; Iter    29/  209] train: loss: 0.1458214
[Epoch 30; Iter    59/  209] train: loss: 0.1079077
[Epoch 13; Iter    12/  209] train: loss: 0.1915499
[Epoch 13; Iter    42/  209] train: loss: 0.1588907
[Epoch 13; Iter    72/  209] train: loss: 0.2558746
[Epoch 13; Iter   102/  209] train: loss: 0.1587985
[Epoch 13; Iter   132/  209] train: loss: 0.2585378
[Epoch 13; Iter   162/  209] train: loss: 0.2583131
[Epoch 13; Iter   192/  209] train: loss: 0.2114233
[Epoch 13] ogbg-moltox21: 0.766869 val loss: 0.311556
[Epoch 13] ogbg-moltox21: 0.761802 test loss: 0.302288
[Epoch 14; Iter    13/  209] train: loss: 0.2055697
[Epoch 14; Iter    43/  209] train: loss: 0.1894646
[Epoch 14; Iter    73/  209] train: loss: 0.2003746
[Epoch 14; Iter   103/  209] train: loss: 0.1966029
[Epoch 14; Iter   133/  209] train: loss: 0.2381682
[Epoch 14; Iter   163/  209] train: loss: 0.1968673
[Epoch 14; Iter   193/  209] train: loss: 0.1927383
[Epoch 14] ogbg-moltox21: 0.767681 val loss: 0.250588
[Epoch 14] ogbg-moltox21: 0.737776 test loss: 0.264220
[Epoch 15; Iter    14/  209] train: loss: 0.1724426
[Epoch 15; Iter    44/  209] train: loss: 0.2441220
[Epoch 15; Iter    74/  209] train: loss: 0.1638725
[Epoch 15; Iter   104/  209] train: loss: 0.2308681
[Epoch 15; Iter   134/  209] train: loss: 0.1599440
[Epoch 15; Iter   164/  209] train: loss: 0.1718310
[Epoch 15; Iter   194/  209] train: loss: 0.2147460
[Epoch 15] ogbg-moltox21: 0.772007 val loss: 0.254011
[Epoch 15] ogbg-moltox21: 0.724989 test loss: 0.266683
[Epoch 16; Iter    15/  209] train: loss: 0.2116715
[Epoch 16; Iter    45/  209] train: loss: 0.1579032
[Epoch 16; Iter    75/  209] train: loss: 0.2108358
[Epoch 16; Iter   105/  209] train: loss: 0.1667347
[Epoch 16; Iter   135/  209] train: loss: 0.2036210
[Epoch 16; Iter   165/  209] train: loss: 0.1887251
[Epoch 16; Iter   195/  209] train: loss: 0.1871645
[Epoch 16] ogbg-moltox21: 0.782598 val loss: 0.253519
[Epoch 16] ogbg-moltox21: 0.764465 test loss: 0.264309
[Epoch 17; Iter    16/  209] train: loss: 0.1627696
[Epoch 17; Iter    46/  209] train: loss: 0.1373264
[Epoch 17; Iter    76/  209] train: loss: 0.1238074
[Epoch 17; Iter   106/  209] train: loss: 0.1854312
[Epoch 17; Iter   136/  209] train: loss: 0.1389485
[Epoch 17; Iter   166/  209] train: loss: 0.1648755
[Epoch 17; Iter   196/  209] train: loss: 0.1319323
[Epoch 17] ogbg-moltox21: 0.770582 val loss: 0.257500
[Epoch 17] ogbg-moltox21: 0.721059 test loss: 0.281635
[Epoch 18; Iter    17/  209] train: loss: 0.1105968
[Epoch 18; Iter    47/  209] train: loss: 0.2047583
[Epoch 18; Iter    77/  209] train: loss: 0.2651394
[Epoch 18; Iter   107/  209] train: loss: 0.2347575
[Epoch 18; Iter   137/  209] train: loss: 0.1612289
[Epoch 18; Iter   167/  209] train: loss: 0.1510506
[Epoch 18; Iter   197/  209] train: loss: 0.1173746
[Epoch 18] ogbg-moltox21: 0.786924 val loss: 0.240131
[Epoch 18] ogbg-moltox21: 0.752589 test loss: 0.258261
[Epoch 19; Iter    18/  209] train: loss: 0.2792657
[Epoch 19; Iter    48/  209] train: loss: 0.1602571
[Epoch 19; Iter    78/  209] train: loss: 0.1425528
[Epoch 19; Iter   108/  209] train: loss: 0.1429106
[Epoch 19; Iter   138/  209] train: loss: 0.1215284
[Epoch 19; Iter   168/  209] train: loss: 0.1875431
[Epoch 19; Iter   198/  209] train: loss: 0.3225737
[Epoch 19] ogbg-moltox21: 0.779353 val loss: 0.254069
[Epoch 19] ogbg-moltox21: 0.716592 test loss: 0.313630
[Epoch 20; Iter    19/  209] train: loss: 0.2198901
[Epoch 20; Iter    49/  209] train: loss: 0.2404140
[Epoch 20; Iter    79/  209] train: loss: 0.1053156
[Epoch 20; Iter   109/  209] train: loss: 0.1316309
[Epoch 20; Iter   139/  209] train: loss: 0.2392606
[Epoch 20; Iter   169/  209] train: loss: 0.2369007
[Epoch 20; Iter   199/  209] train: loss: 0.1157360
[Epoch 20] ogbg-moltox21: 0.783064 val loss: 0.241886
[Epoch 20] ogbg-moltox21: 0.741243 test loss: 0.308017
[Epoch 21; Iter    20/  209] train: loss: 0.1375722
[Epoch 21; Iter    50/  209] train: loss: 0.2157315
[Epoch 21; Iter    80/  209] train: loss: 0.1736442
[Epoch 21; Iter   110/  209] train: loss: 0.0935943
[Epoch 21; Iter   140/  209] train: loss: 0.2168415
[Epoch 21; Iter   170/  209] train: loss: 0.3462657
[Epoch 21; Iter   200/  209] train: loss: 0.1637320
[Epoch 21] ogbg-moltox21: 0.792698 val loss: 0.239590
[Epoch 21] ogbg-moltox21: 0.750712 test loss: 0.259191
[Epoch 22; Iter    21/  209] train: loss: 0.1429019
[Epoch 22; Iter    51/  209] train: loss: 0.0790258
[Epoch 22; Iter    81/  209] train: loss: 0.1256689
[Epoch 22; Iter   111/  209] train: loss: 0.1182405
[Epoch 22; Iter   141/  209] train: loss: 0.1669538
[Epoch 22; Iter   171/  209] train: loss: 0.1234417
[Epoch 22; Iter   201/  209] train: loss: 0.1104693
[Epoch 22] ogbg-moltox21: 0.788093 val loss: 0.362511
[Epoch 22] ogbg-moltox21: 0.745480 test loss: 0.601093
[Epoch 23; Iter    22/  209] train: loss: 0.1906327
[Epoch 23; Iter    52/  209] train: loss: 0.1827843
[Epoch 23; Iter    82/  209] train: loss: 0.1481054
[Epoch 23; Iter   112/  209] train: loss: 0.1513643
[Epoch 23; Iter   142/  209] train: loss: 0.1661910
[Epoch 23; Iter   172/  209] train: loss: 0.1430021
[Epoch 23; Iter   202/  209] train: loss: 0.1446400
[Epoch 23] ogbg-moltox21: 0.778734 val loss: 0.315858
[Epoch 23] ogbg-moltox21: 0.746263 test loss: 0.387006
[Epoch 24; Iter    23/  209] train: loss: 0.2322216
[Epoch 24; Iter    53/  209] train: loss: 0.1132566
[Epoch 24; Iter    83/  209] train: loss: 0.1850208
[Epoch 24; Iter   113/  209] train: loss: 0.1349326
[Epoch 24; Iter   143/  209] train: loss: 0.1039607
[Epoch 24; Iter   173/  209] train: loss: 0.1195965
[Epoch 24; Iter   203/  209] train: loss: 0.1855408
[Epoch 24] ogbg-moltox21: 0.765429 val loss: 0.300640
[Epoch 24] ogbg-moltox21: 0.744839 test loss: 0.266604
[Epoch 25; Iter    24/  209] train: loss: 0.1090068
[Epoch 25; Iter    54/  209] train: loss: 0.2350933
[Epoch 25; Iter    84/  209] train: loss: 0.1283211
[Epoch 25; Iter   114/  209] train: loss: 0.1719978
[Epoch 25; Iter   144/  209] train: loss: 0.1465671
[Epoch 25; Iter   174/  209] train: loss: 0.1682697
[Epoch 25; Iter   204/  209] train: loss: 0.2364862
[Epoch 25] ogbg-moltox21: 0.802798 val loss: 0.252566
[Epoch 25] ogbg-moltox21: 0.765662 test loss: 0.459477
[Epoch 26; Iter    25/  209] train: loss: 0.1772695
[Epoch 26; Iter    55/  209] train: loss: 0.2083990
[Epoch 26; Iter    85/  209] train: loss: 0.1954297
[Epoch 26; Iter   115/  209] train: loss: 0.0863715
[Epoch 26; Iter   145/  209] train: loss: 0.1771716
[Epoch 26; Iter   175/  209] train: loss: 0.1016210
[Epoch 26; Iter   205/  209] train: loss: 0.1877722
[Epoch 26] ogbg-moltox21: 0.748325 val loss: 0.341597
[Epoch 26] ogbg-moltox21: 0.746249 test loss: 0.422151
[Epoch 27; Iter    26/  209] train: loss: 0.1157297
[Epoch 27; Iter    56/  209] train: loss: 0.2677121
[Epoch 27; Iter    86/  209] train: loss: 0.1925311
[Epoch 27; Iter   116/  209] train: loss: 0.1606163
[Epoch 27; Iter   146/  209] train: loss: 0.1392119
[Epoch 27; Iter   176/  209] train: loss: 0.1100091
[Epoch 27; Iter   206/  209] train: loss: 0.1524364
[Epoch 27] ogbg-moltox21: 0.797228 val loss: 0.273510
[Epoch 27] ogbg-moltox21: 0.753011 test loss: 0.273662
[Epoch 28; Iter    27/  209] train: loss: 0.1297970
[Epoch 28; Iter    57/  209] train: loss: 0.1349903
[Epoch 28; Iter    87/  209] train: loss: 0.1575696
[Epoch 28; Iter   117/  209] train: loss: 0.1388616
[Epoch 28; Iter   147/  209] train: loss: 0.1631629
[Epoch 28; Iter   177/  209] train: loss: 0.1658467
[Epoch 28; Iter   207/  209] train: loss: 0.1458129
[Epoch 28] ogbg-moltox21: 0.800901 val loss: 0.474788
[Epoch 28] ogbg-moltox21: 0.761816 test loss: 0.582771
[Epoch 29; Iter    28/  209] train: loss: 0.1430161
[Epoch 29; Iter    58/  209] train: loss: 0.1302029
[Epoch 29; Iter    88/  209] train: loss: 0.1428556
[Epoch 29; Iter   118/  209] train: loss: 0.2153343
[Epoch 29; Iter   148/  209] train: loss: 0.1548311
[Epoch 29; Iter   178/  209] train: loss: 0.1060283
[Epoch 29; Iter   208/  209] train: loss: 0.1016422
[Epoch 29] ogbg-moltox21: 0.792619 val loss: 0.252173
[Epoch 29] ogbg-moltox21: 0.750614 test loss: 0.268792
[Epoch 30; Iter    29/  209] train: loss: 0.1531183
[Epoch 30; Iter    59/  209] train: loss: 0.1199527
[Epoch 13; Iter    12/  209] train: loss: 0.1664009
[Epoch 13; Iter    42/  209] train: loss: 0.1768149
[Epoch 13; Iter    72/  209] train: loss: 0.1706357
[Epoch 13; Iter   102/  209] train: loss: 0.1983036
[Epoch 13; Iter   132/  209] train: loss: 0.1643123
[Epoch 13; Iter   162/  209] train: loss: 0.2409581
[Epoch 13; Iter   192/  209] train: loss: 0.1845134
[Epoch 13] ogbg-moltox21: 0.785104 val loss: 0.269725
[Epoch 13] ogbg-moltox21: 0.748566 test loss: 0.278054
[Epoch 14; Iter    13/  209] train: loss: 0.1119437
[Epoch 14; Iter    43/  209] train: loss: 0.1661776
[Epoch 14; Iter    73/  209] train: loss: 0.1463092
[Epoch 14; Iter   103/  209] train: loss: 0.2387900
[Epoch 14; Iter   133/  209] train: loss: 0.2014128
[Epoch 14; Iter   163/  209] train: loss: 0.1994091
[Epoch 14; Iter   193/  209] train: loss: 0.1833921
[Epoch 14] ogbg-moltox21: 0.772798 val loss: 0.269709
[Epoch 14] ogbg-moltox21: 0.744901 test loss: 0.279320
[Epoch 15; Iter    14/  209] train: loss: 0.1076501
[Epoch 15; Iter    44/  209] train: loss: 0.1545193
[Epoch 15; Iter    74/  209] train: loss: 0.2008856
[Epoch 15; Iter   104/  209] train: loss: 0.1292979
[Epoch 15; Iter   134/  209] train: loss: 0.1373713
[Epoch 15; Iter   164/  209] train: loss: 0.1344055
[Epoch 15; Iter   194/  209] train: loss: 0.1525825
[Epoch 15] ogbg-moltox21: 0.788245 val loss: 0.259461
[Epoch 15] ogbg-moltox21: 0.745503 test loss: 0.296929
[Epoch 16; Iter    15/  209] train: loss: 0.1299750
[Epoch 16; Iter    45/  209] train: loss: 0.1525165
[Epoch 16; Iter    75/  209] train: loss: 0.2825558
[Epoch 16; Iter   105/  209] train: loss: 0.2480458
[Epoch 16; Iter   135/  209] train: loss: 0.2477940
[Epoch 16; Iter   165/  209] train: loss: 0.3123989
[Epoch 16; Iter   195/  209] train: loss: 0.1856287
[Epoch 16] ogbg-moltox21: 0.793859 val loss: 0.242615
[Epoch 16] ogbg-moltox21: 0.757035 test loss: 0.526830
[Epoch 17; Iter    16/  209] train: loss: 0.1704676
[Epoch 17; Iter    46/  209] train: loss: 0.1956867
[Epoch 17; Iter    76/  209] train: loss: 0.2252668
[Epoch 17; Iter   106/  209] train: loss: 0.1885942
[Epoch 17; Iter   136/  209] train: loss: 0.3232979
[Epoch 17; Iter   166/  209] train: loss: 0.1764563
[Epoch 17; Iter   196/  209] train: loss: 0.1698593
[Epoch 17] ogbg-moltox21: 0.788990 val loss: 0.247433
[Epoch 17] ogbg-moltox21: 0.766207 test loss: 0.258263
[Epoch 18; Iter    17/  209] train: loss: 0.1281067
[Epoch 18; Iter    47/  209] train: loss: 0.1403704
[Epoch 18; Iter    77/  209] train: loss: 0.2025942
[Epoch 18; Iter   107/  209] train: loss: 0.1622903
[Epoch 18; Iter   137/  209] train: loss: 0.1033838
[Epoch 18; Iter   167/  209] train: loss: 0.1330321
[Epoch 18; Iter   197/  209] train: loss: 0.1701036
[Epoch 18] ogbg-moltox21: 0.787512 val loss: 0.249328
[Epoch 18] ogbg-moltox21: 0.754633 test loss: 0.264006
[Epoch 19; Iter    18/  209] train: loss: 0.1405715
[Epoch 19; Iter    48/  209] train: loss: 0.1023673
[Epoch 19; Iter    78/  209] train: loss: 0.2740725
[Epoch 19; Iter   108/  209] train: loss: 0.1637860
[Epoch 19; Iter   138/  209] train: loss: 0.1777387
[Epoch 19; Iter   168/  209] train: loss: 0.1610694
[Epoch 19; Iter   198/  209] train: loss: 0.2366554
[Epoch 19] ogbg-moltox21: 0.779374 val loss: 0.254898
[Epoch 19] ogbg-moltox21: 0.754404 test loss: 0.267101
[Epoch 20; Iter    19/  209] train: loss: 0.1987384
[Epoch 20; Iter    49/  209] train: loss: 0.1245422
[Epoch 20; Iter    79/  209] train: loss: 0.1412989
[Epoch 20; Iter   109/  209] train: loss: 0.1712552
[Epoch 20; Iter   139/  209] train: loss: 0.1302655
[Epoch 20; Iter   169/  209] train: loss: 0.2041108
[Epoch 20; Iter   199/  209] train: loss: 0.2390357
[Epoch 20] ogbg-moltox21: 0.789246 val loss: 0.402799
[Epoch 20] ogbg-moltox21: 0.757593 test loss: 0.265431
[Epoch 21; Iter    20/  209] train: loss: 0.1550400
[Epoch 21; Iter    50/  209] train: loss: 0.2047142
[Epoch 21; Iter    80/  209] train: loss: 0.1390753
[Epoch 21; Iter   110/  209] train: loss: 0.1807554
[Epoch 21; Iter   140/  209] train: loss: 0.0986692
[Epoch 21; Iter   170/  209] train: loss: 0.1348207
[Epoch 21; Iter   200/  209] train: loss: 0.1253603
[Epoch 21] ogbg-moltox21: 0.777549 val loss: 0.263930
[Epoch 21] ogbg-moltox21: 0.754672 test loss: 0.267468
[Epoch 22; Iter    21/  209] train: loss: 0.1931304
[Epoch 22; Iter    51/  209] train: loss: 0.1734806
[Epoch 22; Iter    81/  209] train: loss: 0.1011434
[Epoch 22; Iter   111/  209] train: loss: 0.1563295
[Epoch 22; Iter   141/  209] train: loss: 0.1337877
[Epoch 22; Iter   171/  209] train: loss: 0.2187941
[Epoch 22; Iter   201/  209] train: loss: 0.1979954
[Epoch 22] ogbg-moltox21: 0.763584 val loss: 0.434316
[Epoch 22] ogbg-moltox21: 0.734743 test loss: 0.312526
[Epoch 23; Iter    22/  209] train: loss: 0.1208480
[Epoch 23; Iter    52/  209] train: loss: 0.1886700
[Epoch 23; Iter    82/  209] train: loss: 0.1552888
[Epoch 23; Iter   112/  209] train: loss: 0.1364015
[Epoch 23; Iter   142/  209] train: loss: 0.1524216
[Epoch 23; Iter   172/  209] train: loss: 0.1659966
[Epoch 23; Iter   202/  209] train: loss: 0.1868891
[Epoch 23] ogbg-moltox21: 0.774239 val loss: 0.332404
[Epoch 23] ogbg-moltox21: 0.755233 test loss: 0.273792
[Epoch 24; Iter    23/  209] train: loss: 0.1771682
[Epoch 24; Iter    53/  209] train: loss: 0.2015077
[Epoch 24; Iter    83/  209] train: loss: 0.2316206
[Epoch 24; Iter   113/  209] train: loss: 0.1269543
[Epoch 24; Iter   143/  209] train: loss: 0.1494063
[Epoch 24; Iter   173/  209] train: loss: 0.1187859
[Epoch 24; Iter   203/  209] train: loss: 0.1850448
[Epoch 24] ogbg-moltox21: 0.803563 val loss: 0.244876
[Epoch 24] ogbg-moltox21: 0.770381 test loss: 0.258107
[Epoch 25; Iter    24/  209] train: loss: 0.1724570
[Epoch 25; Iter    54/  209] train: loss: 0.2213420
[Epoch 25; Iter    84/  209] train: loss: 0.1092851
[Epoch 25; Iter   114/  209] train: loss: 0.2069641
[Epoch 25; Iter   144/  209] train: loss: 0.1040337
[Epoch 25; Iter   174/  209] train: loss: 0.1949662
[Epoch 25; Iter   204/  209] train: loss: 0.0932980
[Epoch 25] ogbg-moltox21: 0.790490 val loss: 0.253421
[Epoch 25] ogbg-moltox21: 0.749054 test loss: 0.280681
[Epoch 26; Iter    25/  209] train: loss: 0.1032288
[Epoch 26; Iter    55/  209] train: loss: 0.1403297
[Epoch 26; Iter    85/  209] train: loss: 0.1822429
[Epoch 26; Iter   115/  209] train: loss: 0.1246437
[Epoch 26; Iter   145/  209] train: loss: 0.1298117
[Epoch 26; Iter   175/  209] train: loss: 0.1363839
[Epoch 26; Iter   205/  209] train: loss: 0.2380681
[Epoch 26] ogbg-moltox21: 0.779037 val loss: 0.305175
[Epoch 26] ogbg-moltox21: 0.753169 test loss: 0.273052
[Epoch 27; Iter    26/  209] train: loss: 0.1254846
[Epoch 27; Iter    56/  209] train: loss: 0.0978472
[Epoch 27; Iter    86/  209] train: loss: 0.1425016
[Epoch 27; Iter   116/  209] train: loss: 0.1871232
[Epoch 27; Iter   146/  209] train: loss: 0.1199301
[Epoch 27; Iter   176/  209] train: loss: 0.2033842
[Epoch 27; Iter   206/  209] train: loss: 0.1901055
[Epoch 27] ogbg-moltox21: 0.782727 val loss: 0.258962
[Epoch 27] ogbg-moltox21: 0.755180 test loss: 0.267287
[Epoch 28; Iter    27/  209] train: loss: 0.2177520
[Epoch 28; Iter    57/  209] train: loss: 0.0708459
[Epoch 28; Iter    87/  209] train: loss: 0.1821787
[Epoch 28; Iter   117/  209] train: loss: 0.1764898
[Epoch 28; Iter   147/  209] train: loss: 0.2148360
[Epoch 28; Iter   177/  209] train: loss: 0.1874714
[Epoch 28; Iter   207/  209] train: loss: 0.1063147
[Epoch 28] ogbg-moltox21: 0.714835 val loss: 0.363215
[Epoch 28] ogbg-moltox21: 0.706466 test loss: 0.521546
[Epoch 29; Iter    28/  209] train: loss: 0.1732407
[Epoch 29; Iter    58/  209] train: loss: 0.1735139
[Epoch 29; Iter    88/  209] train: loss: 0.1981833
[Epoch 29; Iter   118/  209] train: loss: 0.1297255
[Epoch 29; Iter   148/  209] train: loss: 0.2318529
[Epoch 29; Iter   178/  209] train: loss: 0.1641372
[Epoch 29; Iter   208/  209] train: loss: 0.2237125
[Epoch 29] ogbg-moltox21: 0.786568 val loss: 0.254723
[Epoch 29] ogbg-moltox21: 0.763608 test loss: 0.331661
[Epoch 30; Iter    29/  209] train: loss: 0.1486101
[Epoch 30; Iter    59/  209] train: loss: 0.2059595
[Epoch 13; Iter    12/  209] train: loss: 0.2026837
[Epoch 13; Iter    42/  209] train: loss: 0.2004283
[Epoch 13; Iter    72/  209] train: loss: 0.2077805
[Epoch 13; Iter   102/  209] train: loss: 0.1941006
[Epoch 13; Iter   132/  209] train: loss: 0.1361867
[Epoch 13; Iter   162/  209] train: loss: 0.1980552
[Epoch 13; Iter   192/  209] train: loss: 0.1630481
[Epoch 13] ogbg-moltox21: 0.789138 val loss: 0.254794
[Epoch 13] ogbg-moltox21: 0.767797 test loss: 0.263295
[Epoch 14; Iter    13/  209] train: loss: 0.1761113
[Epoch 14; Iter    43/  209] train: loss: 0.1837884
[Epoch 14; Iter    73/  209] train: loss: 0.2080765
[Epoch 14; Iter   103/  209] train: loss: 0.1417364
[Epoch 14; Iter   133/  209] train: loss: 0.1894808
[Epoch 14; Iter   163/  209] train: loss: 0.1487305
[Epoch 14; Iter   193/  209] train: loss: 0.2516316
[Epoch 14] ogbg-moltox21: 0.779255 val loss: 0.254280
[Epoch 14] ogbg-moltox21: 0.753527 test loss: 0.270525
[Epoch 15; Iter    14/  209] train: loss: 0.1977573
[Epoch 15; Iter    44/  209] train: loss: 0.1656194
[Epoch 15; Iter    74/  209] train: loss: 0.1474119
[Epoch 15; Iter   104/  209] train: loss: 0.2448124
[Epoch 15; Iter   134/  209] train: loss: 0.1350482
[Epoch 15; Iter   164/  209] train: loss: 0.1486418
[Epoch 15; Iter   194/  209] train: loss: 0.1415280
[Epoch 15] ogbg-moltox21: 0.780457 val loss: 0.246195
[Epoch 15] ogbg-moltox21: 0.753968 test loss: 0.261692
[Epoch 16; Iter    15/  209] train: loss: 0.1289420
[Epoch 16; Iter    45/  209] train: loss: 0.1978219
[Epoch 16; Iter    75/  209] train: loss: 0.2109323
[Epoch 16; Iter   105/  209] train: loss: 0.2416237
[Epoch 16; Iter   135/  209] train: loss: 0.1813131
[Epoch 16; Iter   165/  209] train: loss: 0.1259966
[Epoch 16; Iter   195/  209] train: loss: 0.1533394
[Epoch 16] ogbg-moltox21: 0.757222 val loss: 0.390265
[Epoch 16] ogbg-moltox21: 0.749064 test loss: 0.321897
[Epoch 17; Iter    16/  209] train: loss: 0.2112451
[Epoch 17; Iter    46/  209] train: loss: 0.2205538
[Epoch 17; Iter    76/  209] train: loss: 0.1461298
[Epoch 17; Iter   106/  209] train: loss: 0.2323968
[Epoch 17; Iter   136/  209] train: loss: 0.0905054
[Epoch 17; Iter   166/  209] train: loss: 0.1611687
[Epoch 17; Iter   196/  209] train: loss: 0.2227669
[Epoch 17] ogbg-moltox21: 0.774188 val loss: 0.256451
[Epoch 17] ogbg-moltox21: 0.761673 test loss: 0.263238
[Epoch 18; Iter    17/  209] train: loss: 0.1683785
[Epoch 18; Iter    47/  209] train: loss: 0.1289781
[Epoch 18; Iter    77/  209] train: loss: 0.1890959
[Epoch 18; Iter   107/  209] train: loss: 0.2411420
[Epoch 18; Iter   137/  209] train: loss: 0.1255701
[Epoch 18; Iter   167/  209] train: loss: 0.1287817
[Epoch 18; Iter   197/  209] train: loss: 0.1221676
[Epoch 18] ogbg-moltox21: 0.789133 val loss: 0.252484
[Epoch 18] ogbg-moltox21: 0.768374 test loss: 0.255413
[Epoch 19; Iter    18/  209] train: loss: 0.1602592
[Epoch 19; Iter    48/  209] train: loss: 0.1151796
[Epoch 19; Iter    78/  209] train: loss: 0.2069001
[Epoch 19; Iter   108/  209] train: loss: 0.1698368
[Epoch 19; Iter   138/  209] train: loss: 0.2005076
[Epoch 19; Iter   168/  209] train: loss: 0.1887495
[Epoch 19; Iter   198/  209] train: loss: 0.1233623
[Epoch 19] ogbg-moltox21: 0.771926 val loss: 0.252980
[Epoch 19] ogbg-moltox21: 0.752353 test loss: 0.267691
[Epoch 20; Iter    19/  209] train: loss: 0.2052587
[Epoch 20; Iter    49/  209] train: loss: 0.1393034
[Epoch 20; Iter    79/  209] train: loss: 0.1260033
[Epoch 20; Iter   109/  209] train: loss: 0.1111094
[Epoch 20; Iter   139/  209] train: loss: 0.1556537
[Epoch 20; Iter   169/  209] train: loss: 0.1670530
[Epoch 20; Iter   199/  209] train: loss: 0.1853373
[Epoch 20] ogbg-moltox21: 0.745126 val loss: 6.756600
[Epoch 20] ogbg-moltox21: 0.709196 test loss: 10.215853
[Epoch 21; Iter    20/  209] train: loss: 0.1716333
[Epoch 21; Iter    50/  209] train: loss: 0.1896371
[Epoch 21; Iter    80/  209] train: loss: 0.1482409
[Epoch 21; Iter   110/  209] train: loss: 0.3301058
[Epoch 21; Iter   140/  209] train: loss: 0.2137285
[Epoch 21; Iter   170/  209] train: loss: 0.2327706
[Epoch 21; Iter   200/  209] train: loss: 0.1749491
[Epoch 21] ogbg-moltox21: 0.762292 val loss: 0.331764
[Epoch 21] ogbg-moltox21: 0.754109 test loss: 0.268725
[Epoch 22; Iter    21/  209] train: loss: 0.1128617
[Epoch 22; Iter    51/  209] train: loss: 0.2020413
[Epoch 22; Iter    81/  209] train: loss: 0.1559841
[Epoch 22; Iter   111/  209] train: loss: 0.2485913
[Epoch 22; Iter   141/  209] train: loss: 0.1496225
[Epoch 22; Iter   171/  209] train: loss: 0.1889114
[Epoch 22; Iter   201/  209] train: loss: 0.1712902
[Epoch 22] ogbg-moltox21: 0.766272 val loss: 0.257871
[Epoch 22] ogbg-moltox21: 0.769651 test loss: 0.263625
[Epoch 23; Iter    22/  209] train: loss: 0.1170966
[Epoch 23; Iter    52/  209] train: loss: 0.1250966
[Epoch 23; Iter    82/  209] train: loss: 0.1410317
[Epoch 23; Iter   112/  209] train: loss: 0.1685647
[Epoch 23; Iter   142/  209] train: loss: 0.1759900
[Epoch 23; Iter   172/  209] train: loss: 0.1770945
[Epoch 23; Iter   202/  209] train: loss: 0.1533449
[Epoch 23] ogbg-moltox21: 0.783671 val loss: 0.342063
[Epoch 23] ogbg-moltox21: 0.766520 test loss: 0.266089
[Epoch 24; Iter    23/  209] train: loss: 0.1502088
[Epoch 24; Iter    53/  209] train: loss: 0.1814473
[Epoch 24; Iter    83/  209] train: loss: 0.1705346
[Epoch 24; Iter   113/  209] train: loss: 0.1324525
[Epoch 24; Iter   143/  209] train: loss: 0.1609215
[Epoch 24; Iter   173/  209] train: loss: 0.1283130
[Epoch 24; Iter   203/  209] train: loss: 0.2331255
[Epoch 24] ogbg-moltox21: 0.776212 val loss: 0.257652
[Epoch 24] ogbg-moltox21: 0.769428 test loss: 0.267165
[Epoch 25; Iter    24/  209] train: loss: 0.1334804
[Epoch 25; Iter    54/  209] train: loss: 0.1042264
[Epoch 25; Iter    84/  209] train: loss: 0.1090382
[Epoch 25; Iter   114/  209] train: loss: 0.1780601
[Epoch 25; Iter   144/  209] train: loss: 0.2071529
[Epoch 25; Iter   174/  209] train: loss: 0.1341391
[Epoch 25; Iter   204/  209] train: loss: 0.1394172
[Epoch 25] ogbg-moltox21: 0.782059 val loss: 0.256288
[Epoch 25] ogbg-moltox21: 0.757817 test loss: 0.275996
[Epoch 26; Iter    25/  209] train: loss: 0.1653140
[Epoch 26; Iter    55/  209] train: loss: 0.1844482
[Epoch 26; Iter    85/  209] train: loss: 0.2406104
[Epoch 26; Iter   115/  209] train: loss: 0.1643656
[Epoch 26; Iter   145/  209] train: loss: 0.1481245
[Epoch 26; Iter   175/  209] train: loss: 0.1480331
[Epoch 26; Iter   205/  209] train: loss: 0.1207211
[Epoch 26] ogbg-moltox21: 0.793523 val loss: 0.244893
[Epoch 26] ogbg-moltox21: 0.769467 test loss: 0.253467
[Epoch 27; Iter    26/  209] train: loss: 0.1837681
[Epoch 27; Iter    56/  209] train: loss: 0.0938246
[Epoch 27; Iter    86/  209] train: loss: 0.1842989
[Epoch 27; Iter   116/  209] train: loss: 0.1296470
[Epoch 27; Iter   146/  209] train: loss: 0.1889105
[Epoch 27; Iter   176/  209] train: loss: 0.2262062
[Epoch 27; Iter   206/  209] train: loss: 0.1651178
[Epoch 27] ogbg-moltox21: 0.788633 val loss: 0.281015
[Epoch 27] ogbg-moltox21: 0.778472 test loss: 0.283550
[Epoch 28; Iter    27/  209] train: loss: 0.1229409
[Epoch 28; Iter    57/  209] train: loss: 0.2504776
[Epoch 28; Iter    87/  209] train: loss: 0.1810915
[Epoch 28; Iter   117/  209] train: loss: 0.1356050
[Epoch 28; Iter   147/  209] train: loss: 0.1910928
[Epoch 28; Iter   177/  209] train: loss: 0.2018705
[Epoch 28; Iter   207/  209] train: loss: 0.1189778
[Epoch 28] ogbg-moltox21: 0.778608 val loss: 0.249382
[Epoch 28] ogbg-moltox21: 0.765609 test loss: 0.263527
[Epoch 29; Iter    28/  209] train: loss: 0.1247688
[Epoch 29; Iter    58/  209] train: loss: 0.1583707
[Epoch 29; Iter    88/  209] train: loss: 0.1346188
[Epoch 29; Iter   118/  209] train: loss: 0.2018729
[Epoch 29; Iter   148/  209] train: loss: 0.1171234
[Epoch 29; Iter   178/  209] train: loss: 0.0905327
[Epoch 29; Iter   208/  209] train: loss: 0.1168251
[Epoch 29] ogbg-moltox21: 0.780830 val loss: 0.272500
[Epoch 29] ogbg-moltox21: 0.764595 test loss: 0.279380
[Epoch 30; Iter    29/  209] train: loss: 0.1409276
[Epoch 30; Iter    59/  209] train: loss: 0.1393445
[Epoch 30; Iter    89/  209] train: loss: 0.1443031
[Epoch 30; Iter   119/  209] train: loss: 0.1760457
[Epoch 30; Iter   149/  209] train: loss: 0.1380083
[Epoch 30; Iter   179/  209] train: loss: 0.2389659
[Epoch 30; Iter   209/  209] train: loss: 0.1114226
[Epoch 30] ogbg-moltox21: 0.790832 val loss: 0.274308
[Epoch 30] ogbg-moltox21: 0.771721 test loss: 0.286267
[Epoch 31; Iter    30/  209] train: loss: 0.1088713
[Epoch 31; Iter    60/  209] train: loss: 0.1189125
[Epoch 31; Iter    90/  209] train: loss: 0.1242560
[Epoch 31; Iter   120/  209] train: loss: 0.1182327
[Epoch 31; Iter   150/  209] train: loss: 0.1465901
[Epoch 31; Iter   180/  209] train: loss: 0.2001315
[Epoch 31] ogbg-moltox21: 0.785563 val loss: 0.286647
[Epoch 31] ogbg-moltox21: 0.761064 test loss: 0.301386
[Epoch 32; Iter     1/  209] train: loss: 0.1738515
[Epoch 32; Iter    31/  209] train: loss: 0.1155324
[Epoch 32; Iter    61/  209] train: loss: 0.1903838
[Epoch 32; Iter    91/  209] train: loss: 0.1478781
[Epoch 32; Iter   121/  209] train: loss: 0.1825680
[Epoch 32; Iter   151/  209] train: loss: 0.1639887
[Epoch 32; Iter   181/  209] train: loss: 0.2521614
[Epoch 32] ogbg-moltox21: 0.770540 val loss: 0.290115
[Epoch 32] ogbg-moltox21: 0.753795 test loss: 0.297683
[Epoch 33; Iter     2/  209] train: loss: 0.1049734
[Epoch 33; Iter    32/  209] train: loss: 0.1267395
[Epoch 33; Iter    62/  209] train: loss: 0.1253971
[Epoch 33; Iter    92/  209] train: loss: 0.1581281
[Epoch 33; Iter   122/  209] train: loss: 0.1035287
[Epoch 33; Iter   152/  209] train: loss: 0.1286905
[Epoch 33; Iter   182/  209] train: loss: 0.1292519
[Epoch 33] ogbg-moltox21: 0.784730 val loss: 0.266477
[Epoch 33] ogbg-moltox21: 0.759692 test loss: 0.289701
[Epoch 34; Iter     3/  209] train: loss: 0.1073602
[Epoch 34; Iter    33/  209] train: loss: 0.1308650
[Epoch 34; Iter    63/  209] train: loss: 0.1801710
[Epoch 34; Iter    93/  209] train: loss: 0.1680127
[Epoch 34; Iter   123/  209] train: loss: 0.1158666
[Epoch 34; Iter   153/  209] train: loss: 0.1495727
[Epoch 34; Iter   183/  209] train: loss: 0.1324619
[Epoch 34] ogbg-moltox21: 0.784741 val loss: 0.292046
[Epoch 34] ogbg-moltox21: 0.764293 test loss: 0.293063
[Epoch 35; Iter     4/  209] train: loss: 0.1570752
[Epoch 35; Iter    34/  209] train: loss: 0.1612246
[Epoch 35; Iter    64/  209] train: loss: 0.1683195
[Epoch 35; Iter    94/  209] train: loss: 0.1304699
[Epoch 35; Iter   124/  209] train: loss: 0.1330781
[Epoch 35; Iter   154/  209] train: loss: 0.1317714
[Epoch 35; Iter   184/  209] train: loss: 0.1795186
[Epoch 35] ogbg-moltox21: 0.771803 val loss: 0.307411
[Epoch 35] ogbg-moltox21: 0.748790 test loss: 0.361521
[Epoch 36; Iter     5/  209] train: loss: 0.1398757
[Epoch 36; Iter    35/  209] train: loss: 0.2071451
[Epoch 36; Iter    65/  209] train: loss: 0.1214813
[Epoch 36; Iter    95/  209] train: loss: 0.1739791
[Epoch 36; Iter   125/  209] train: loss: 0.1868227
[Epoch 36; Iter   155/  209] train: loss: 0.1438359
[Epoch 36; Iter   185/  209] train: loss: 0.1587866
[Epoch 36] ogbg-moltox21: 0.767806 val loss: 0.335840
[Epoch 36] ogbg-moltox21: 0.759940 test loss: 0.331873
[Epoch 37; Iter     6/  209] train: loss: 0.1365970
[Epoch 37; Iter    36/  209] train: loss: 0.1735049
[Epoch 37; Iter    66/  209] train: loss: 0.1570160
[Epoch 37; Iter    96/  209] train: loss: 0.1237988
[Epoch 37; Iter   126/  209] train: loss: 0.1376465
[Epoch 37; Iter   156/  209] train: loss: 0.1038293
[Epoch 37; Iter   186/  209] train: loss: 0.1373898
[Epoch 37] ogbg-moltox21: 0.777330 val loss: 0.290567
[Epoch 37] ogbg-moltox21: 0.760575 test loss: 0.297941
[Epoch 38; Iter     7/  209] train: loss: 0.2013419
[Epoch 38; Iter    37/  209] train: loss: 0.1583477
[Epoch 38; Iter    67/  209] train: loss: 0.1167073
[Epoch 38; Iter    97/  209] train: loss: 0.0907168
[Epoch 38; Iter   127/  209] train: loss: 0.0786969
[Epoch 38; Iter   157/  209] train: loss: 0.1074597
[Epoch 38; Iter   187/  209] train: loss: 0.0923672
[Epoch 38] ogbg-moltox21: 0.777635 val loss: 0.296263
[Epoch 38] ogbg-moltox21: 0.767830 test loss: 0.298798
[Epoch 39; Iter     8/  209] train: loss: 0.1049948
[Epoch 39; Iter    38/  209] train: loss: 0.0951033
[Epoch 39; Iter    68/  209] train: loss: 0.1242209
[Epoch 39; Iter    98/  209] train: loss: 0.1207261
[Epoch 39; Iter   128/  209] train: loss: 0.1013251
[Epoch 39; Iter   158/  209] train: loss: 0.1191339
[Epoch 39; Iter   188/  209] train: loss: 0.0952659
[Epoch 39] ogbg-moltox21: 0.780960 val loss: 0.294087
[Epoch 39] ogbg-moltox21: 0.764168 test loss: 0.302556
[Epoch 40; Iter     9/  209] train: loss: 0.0907476
[Epoch 40; Iter    39/  209] train: loss: 0.0913955
[Epoch 40; Iter    69/  209] train: loss: 0.1290524
[Epoch 40; Iter    99/  209] train: loss: 0.1450308
[Epoch 40; Iter   129/  209] train: loss: 0.0995263
[Epoch 40; Iter   159/  209] train: loss: 0.1110510
[Epoch 40; Iter   189/  209] train: loss: 0.1422472
[Epoch 40] ogbg-moltox21: 0.775243 val loss: 0.295095
[Epoch 40] ogbg-moltox21: 0.760592 test loss: 0.301292
[Epoch 41; Iter    10/  209] train: loss: 0.0975417
[Epoch 41; Iter    40/  209] train: loss: 0.1373686
[Epoch 41; Iter    70/  209] train: loss: 0.1084477
[Epoch 41; Iter   100/  209] train: loss: 0.1800384
[Epoch 41; Iter   130/  209] train: loss: 0.1281561
[Epoch 41; Iter   160/  209] train: loss: 0.1550482
[Epoch 41; Iter   190/  209] train: loss: 0.0870262
[Epoch 41] ogbg-moltox21: 0.779717 val loss: 0.293072
[Epoch 41] ogbg-moltox21: 0.766271 test loss: 0.300745
[Epoch 42; Iter    11/  209] train: loss: 0.1120297
[Epoch 42; Iter    41/  209] train: loss: 0.0774985
[Epoch 42; Iter    71/  209] train: loss: 0.0940386
[Epoch 42; Iter   101/  209] train: loss: 0.1658808
[Epoch 42; Iter   131/  209] train: loss: 0.1376452
[Epoch 42; Iter   161/  209] train: loss: 0.0919141
[Epoch 42; Iter   191/  209] train: loss: 0.0534354
[Epoch 42] ogbg-moltox21: 0.775542 val loss: 0.284452
[Epoch 42] ogbg-moltox21: 0.753208 test loss: 0.292919
[Epoch 43; Iter    12/  209] train: loss: 0.1020685
[Epoch 43; Iter    42/  209] train: loss: 0.0872296
[Epoch 43; Iter    72/  209] train: loss: 0.1502285
[Epoch 43; Iter   102/  209] train: loss: 0.1452412
[Epoch 43; Iter   132/  209] train: loss: 0.1396201
[Epoch 43; Iter   162/  209] train: loss: 0.0800489
[Epoch 43; Iter   192/  209] train: loss: 0.0834301
[Epoch 43] ogbg-moltox21: 0.778154 val loss: 0.288874
[Epoch 43] ogbg-moltox21: 0.755627 test loss: 0.301075
[Epoch 44; Iter    13/  209] train: loss: 0.0634792
[Epoch 44; Iter    43/  209] train: loss: 0.0679010
[Epoch 44; Iter    73/  209] train: loss: 0.0686248
[Epoch 44; Iter   103/  209] train: loss: 0.1822657
[Epoch 44; Iter   133/  209] train: loss: 0.1208691
[Epoch 44; Iter   163/  209] train: loss: 0.0972999
[Epoch 44; Iter   193/  209] train: loss: 0.1355395
[Epoch 44] ogbg-moltox21: 0.777038 val loss: 0.321159
[Epoch 44] ogbg-moltox21: 0.757989 test loss: 0.331501
[Epoch 45; Iter    14/  209] train: loss: 0.0931194
[Epoch 45; Iter    44/  209] train: loss: 0.1224418
[Epoch 45; Iter    74/  209] train: loss: 0.0968533
[Epoch 45; Iter   104/  209] train: loss: 0.0991904
[Epoch 45; Iter   134/  209] train: loss: 0.1192106
[Epoch 45; Iter   164/  209] train: loss: 0.1005902
[Epoch 45; Iter   194/  209] train: loss: 0.1228094
[Epoch 45] ogbg-moltox21: 0.776879 val loss: 0.331591
[Epoch 45] ogbg-moltox21: 0.758769 test loss: 0.327009
[Epoch 46; Iter    15/  209] train: loss: 0.0722239
[Epoch 46; Iter    45/  209] train: loss: 0.1355533
[Epoch 46; Iter    75/  209] train: loss: 0.0994627
[Epoch 46; Iter   105/  209] train: loss: 0.0792257
[Epoch 46; Iter   135/  209] train: loss: 0.1098984
[Epoch 46; Iter   165/  209] train: loss: 0.0881750
[Epoch 46; Iter   195/  209] train: loss: 0.1365958
[Epoch 46] ogbg-moltox21: 0.782560 val loss: 0.320111
[Epoch 46] ogbg-moltox21: 0.764246 test loss: 0.320605
[Epoch 47; Iter    16/  209] train: loss: 0.0839654
[Epoch 47; Iter    46/  209] train: loss: 0.0641246
[Epoch 47; Iter    76/  209] train: loss: 0.1054772
[Epoch 47; Iter   106/  209] train: loss: 0.0710012
[Epoch 47; Iter   136/  209] train: loss: 0.1203279
[Epoch 30; Iter    89/  209] train: loss: 0.1129137
[Epoch 30; Iter   119/  209] train: loss: 0.1111022
[Epoch 30; Iter   149/  209] train: loss: 0.1132682
[Epoch 30; Iter   179/  209] train: loss: 0.1235393
[Epoch 30; Iter   209/  209] train: loss: 0.0895606
[Epoch 30] ogbg-moltox21: 0.761552 val loss: 0.360131
[Epoch 30] ogbg-moltox21: 0.726297 test loss: 0.658249
[Epoch 31; Iter    30/  209] train: loss: 0.1112604
[Epoch 31; Iter    60/  209] train: loss: 0.1037565
[Epoch 31; Iter    90/  209] train: loss: 0.0768300
[Epoch 31; Iter   120/  209] train: loss: 0.1006011
[Epoch 31; Iter   150/  209] train: loss: 0.1413670
[Epoch 31; Iter   180/  209] train: loss: 0.1267706
[Epoch 31] ogbg-moltox21: 0.752498 val loss: 0.353619
[Epoch 31] ogbg-moltox21: 0.739285 test loss: 0.598047
[Epoch 32; Iter     1/  209] train: loss: 0.1488909
[Epoch 32; Iter    31/  209] train: loss: 0.1724261
[Epoch 32; Iter    61/  209] train: loss: 0.1073592
[Epoch 32; Iter    91/  209] train: loss: 0.0919613
[Epoch 32; Iter   121/  209] train: loss: 0.1078412
[Epoch 32; Iter   151/  209] train: loss: 0.0883311
[Epoch 32; Iter   181/  209] train: loss: 0.1305039
[Epoch 32] ogbg-moltox21: 0.735691 val loss: 0.379423
[Epoch 32] ogbg-moltox21: 0.724510 test loss: 0.353738
[Epoch 33; Iter     2/  209] train: loss: 0.1209832
[Epoch 33; Iter    32/  209] train: loss: 0.1399376
[Epoch 33; Iter    62/  209] train: loss: 0.1548854
[Epoch 33; Iter    92/  209] train: loss: 0.1315588
[Epoch 33; Iter   122/  209] train: loss: 0.1789946
[Epoch 33; Iter   152/  209] train: loss: 0.0757218
[Epoch 33; Iter   182/  209] train: loss: 0.1105701
[Epoch 33] ogbg-moltox21: 0.745668 val loss: 0.622207
[Epoch 33] ogbg-moltox21: 0.726900 test loss: 0.762576
[Epoch 34; Iter     3/  209] train: loss: 0.1351893
[Epoch 34; Iter    33/  209] train: loss: 0.1215043
[Epoch 34; Iter    63/  209] train: loss: 0.1037005
[Epoch 34; Iter    93/  209] train: loss: 0.1240626
[Epoch 34; Iter   123/  209] train: loss: 0.1136425
[Epoch 34; Iter   153/  209] train: loss: 0.1998319
[Epoch 34; Iter   183/  209] train: loss: 0.0749925
[Epoch 34] ogbg-moltox21: 0.750899 val loss: 0.318353
[Epoch 34] ogbg-moltox21: 0.727157 test loss: 0.329584
[Epoch 35; Iter     4/  209] train: loss: 0.1249545
[Epoch 35; Iter    34/  209] train: loss: 0.0971881
[Epoch 35; Iter    64/  209] train: loss: 0.1149399
[Epoch 35; Iter    94/  209] train: loss: 0.0827065
[Epoch 35; Iter   124/  209] train: loss: 0.2275842
[Epoch 35; Iter   154/  209] train: loss: 0.1552598
[Epoch 35; Iter   184/  209] train: loss: 0.1452208
[Epoch 35] ogbg-moltox21: 0.765552 val loss: 0.363111
[Epoch 35] ogbg-moltox21: 0.747531 test loss: 0.364760
[Epoch 36; Iter     5/  209] train: loss: 0.0962415
[Epoch 36; Iter    35/  209] train: loss: 0.0574267
[Epoch 36; Iter    65/  209] train: loss: 0.0793345
[Epoch 36; Iter    95/  209] train: loss: 0.1042469
[Epoch 36; Iter   125/  209] train: loss: 0.1238480
[Epoch 36; Iter   155/  209] train: loss: 0.1074764
[Epoch 36; Iter   185/  209] train: loss: 0.0851318
[Epoch 36] ogbg-moltox21: 0.754027 val loss: 0.359859
[Epoch 36] ogbg-moltox21: 0.731834 test loss: 0.500513
[Epoch 37; Iter     6/  209] train: loss: 0.0833999
[Epoch 37; Iter    36/  209] train: loss: 0.1442293
[Epoch 37; Iter    66/  209] train: loss: 0.0864222
[Epoch 37; Iter    96/  209] train: loss: 0.0853732
[Epoch 37; Iter   126/  209] train: loss: 0.0896025
[Epoch 37; Iter   156/  209] train: loss: 0.1218638
[Epoch 37; Iter   186/  209] train: loss: 0.1227921
[Epoch 37] ogbg-moltox21: 0.723299 val loss: 0.675126
[Epoch 37] ogbg-moltox21: 0.725069 test loss: 0.590709
[Epoch 38; Iter     7/  209] train: loss: 0.1144384
[Epoch 38; Iter    37/  209] train: loss: 0.0825274
[Epoch 38; Iter    67/  209] train: loss: 0.0701151
[Epoch 38; Iter    97/  209] train: loss: 0.1027402
[Epoch 38; Iter   127/  209] train: loss: 0.1549778
[Epoch 38; Iter   157/  209] train: loss: 0.1237990
[Epoch 38; Iter   187/  209] train: loss: 0.1938171
[Epoch 38] ogbg-moltox21: 0.741427 val loss: 0.340758
[Epoch 38] ogbg-moltox21: 0.720666 test loss: 0.339089
[Epoch 39; Iter     8/  209] train: loss: 0.0944630
[Epoch 39; Iter    38/  209] train: loss: 0.0798857
[Epoch 39; Iter    68/  209] train: loss: 0.1321623
[Epoch 39; Iter    98/  209] train: loss: 0.1337830
[Epoch 39; Iter   128/  209] train: loss: 0.2059684
[Epoch 39; Iter   158/  209] train: loss: 0.1002625
[Epoch 39; Iter   188/  209] train: loss: 0.0773791
[Epoch 39] ogbg-moltox21: 0.729281 val loss: 0.355980
[Epoch 39] ogbg-moltox21: 0.708369 test loss: 0.383612
[Epoch 40; Iter     9/  209] train: loss: 0.0831291
[Epoch 40; Iter    39/  209] train: loss: 0.1293027
[Epoch 40; Iter    69/  209] train: loss: 0.1224430
[Epoch 40; Iter    99/  209] train: loss: 0.0966964
[Epoch 40; Iter   129/  209] train: loss: 0.0985595
[Epoch 40; Iter   159/  209] train: loss: 0.1307893
[Epoch 40; Iter   189/  209] train: loss: 0.1594836
[Epoch 40] ogbg-moltox21: 0.746531 val loss: 0.421123
[Epoch 40] ogbg-moltox21: 0.736967 test loss: 0.415100
[Epoch 41; Iter    10/  209] train: loss: 0.0701451
[Epoch 41; Iter    40/  209] train: loss: 0.1186955
[Epoch 41; Iter    70/  209] train: loss: 0.0528508
[Epoch 41; Iter   100/  209] train: loss: 0.1126763
[Epoch 41; Iter   130/  209] train: loss: 0.1720214
[Epoch 41; Iter   160/  209] train: loss: 0.1432270
[Epoch 41; Iter   190/  209] train: loss: 0.1583877
[Epoch 41] ogbg-moltox21: 0.738193 val loss: 0.482876
[Epoch 41] ogbg-moltox21: 0.736735 test loss: 0.474551
[Epoch 42; Iter    11/  209] train: loss: 0.0900554
[Epoch 42; Iter    41/  209] train: loss: 0.0639641
[Epoch 42; Iter    71/  209] train: loss: 0.0937371
[Epoch 42; Iter   101/  209] train: loss: 0.0683136
[Epoch 42; Iter   131/  209] train: loss: 0.0647686
[Epoch 42; Iter   161/  209] train: loss: 0.1158506
[Epoch 42; Iter   191/  209] train: loss: 0.1006973
[Epoch 42] ogbg-moltox21: 0.758029 val loss: 0.365704
[Epoch 42] ogbg-moltox21: 0.734420 test loss: 0.343271
[Epoch 43; Iter    12/  209] train: loss: 0.0787576
[Epoch 43; Iter    42/  209] train: loss: 0.1051026
[Epoch 43; Iter    72/  209] train: loss: 0.0701084
[Epoch 43; Iter   102/  209] train: loss: 0.0894226
[Epoch 43; Iter   132/  209] train: loss: 0.0825573
[Epoch 43; Iter   162/  209] train: loss: 0.0436978
[Epoch 43; Iter   192/  209] train: loss: 0.0891346
[Epoch 43] ogbg-moltox21: 0.739548 val loss: 0.454057
[Epoch 43] ogbg-moltox21: 0.734503 test loss: 0.471179
[Epoch 44; Iter    13/  209] train: loss: 0.0671815
[Epoch 44; Iter    43/  209] train: loss: 0.0795852
[Epoch 44; Iter    73/  209] train: loss: 0.0688526
[Epoch 44; Iter   103/  209] train: loss: 0.1047678
[Epoch 44; Iter   133/  209] train: loss: 0.0993264
[Epoch 44; Iter   163/  209] train: loss: 0.0917032
[Epoch 44; Iter   193/  209] train: loss: 0.1235288
[Epoch 44] ogbg-moltox21: 0.739923 val loss: 0.366436
[Epoch 44] ogbg-moltox21: 0.724896 test loss: 0.416894
[Epoch 45; Iter    14/  209] train: loss: 0.1084275
[Epoch 45; Iter    44/  209] train: loss: 0.0616808
[Epoch 45; Iter    74/  209] train: loss: 0.1110132
[Epoch 45; Iter   104/  209] train: loss: 0.0747798
[Epoch 45; Iter   134/  209] train: loss: 0.0677476
[Epoch 45; Iter   164/  209] train: loss: 0.0585323
[Epoch 45; Iter   194/  209] train: loss: 0.0960527
[Epoch 45] ogbg-moltox21: 0.746859 val loss: 0.384651
[Epoch 45] ogbg-moltox21: 0.732882 test loss: 0.379788
[Epoch 46; Iter    15/  209] train: loss: 0.0463474
[Epoch 46; Iter    45/  209] train: loss: 0.0973177
[Epoch 46; Iter    75/  209] train: loss: 0.0820497
[Epoch 46; Iter   105/  209] train: loss: 0.0926505
[Epoch 46; Iter   135/  209] train: loss: 0.0743046
[Epoch 46; Iter   165/  209] train: loss: 0.1416921
[Epoch 46; Iter   195/  209] train: loss: 0.1102614
[Epoch 46] ogbg-moltox21: 0.745572 val loss: 0.437838
[Epoch 46] ogbg-moltox21: 0.714689 test loss: 0.450101
[Epoch 47; Iter    16/  209] train: loss: 0.0767026
[Epoch 47; Iter    46/  209] train: loss: 0.0567404
[Epoch 47; Iter    76/  209] train: loss: 0.1441977
[Epoch 47; Iter   106/  209] train: loss: 0.1190805
[Epoch 47; Iter   136/  209] train: loss: 0.0939318
[Epoch 30; Iter    89/  209] train: loss: 0.1440825
[Epoch 30; Iter   119/  209] train: loss: 0.1340001
[Epoch 30; Iter   149/  209] train: loss: 0.2405311
[Epoch 30; Iter   179/  209] train: loss: 0.1082080
[Epoch 30; Iter   209/  209] train: loss: 0.2336836
[Epoch 30] ogbg-moltox21: 0.774396 val loss: 0.576077
[Epoch 30] ogbg-moltox21: 0.740949 test loss: 0.288826
[Epoch 31; Iter    30/  209] train: loss: 0.1342842
[Epoch 31; Iter    60/  209] train: loss: 0.1455704
[Epoch 31; Iter    90/  209] train: loss: 0.1508160
[Epoch 31; Iter   120/  209] train: loss: 0.1077345
[Epoch 31; Iter   150/  209] train: loss: 0.1025783
[Epoch 31; Iter   180/  209] train: loss: 0.1888034
[Epoch 31] ogbg-moltox21: 0.777194 val loss: 0.528891
[Epoch 31] ogbg-moltox21: 0.753442 test loss: 0.349276
[Epoch 32; Iter     1/  209] train: loss: 0.2078717
[Epoch 32; Iter    31/  209] train: loss: 0.1303262
[Epoch 32; Iter    61/  209] train: loss: 0.0727285
[Epoch 32; Iter    91/  209] train: loss: 0.1539893
[Epoch 32; Iter   121/  209] train: loss: 0.1295739
[Epoch 32; Iter   151/  209] train: loss: 0.2247572
[Epoch 32; Iter   181/  209] train: loss: 0.1931178
[Epoch 32] ogbg-moltox21: 0.768379 val loss: 0.310574
[Epoch 32] ogbg-moltox21: 0.738576 test loss: 0.302759
[Epoch 33; Iter     2/  209] train: loss: 0.0932358
[Epoch 33; Iter    32/  209] train: loss: 0.0950222
[Epoch 33; Iter    62/  209] train: loss: 0.1280377
[Epoch 33; Iter    92/  209] train: loss: 0.1088227
[Epoch 33; Iter   122/  209] train: loss: 0.1119296
[Epoch 33; Iter   152/  209] train: loss: 0.1985132
[Epoch 33; Iter   182/  209] train: loss: 0.2286150
[Epoch 33] ogbg-moltox21: 0.782949 val loss: 0.265553
[Epoch 33] ogbg-moltox21: 0.740680 test loss: 0.294601
[Epoch 34; Iter     3/  209] train: loss: 0.0924987
[Epoch 34; Iter    33/  209] train: loss: 0.1374118
[Epoch 34; Iter    63/  209] train: loss: 0.1465839
[Epoch 34; Iter    93/  209] train: loss: 0.0843108
[Epoch 34; Iter   123/  209] train: loss: 0.1377172
[Epoch 34; Iter   153/  209] train: loss: 0.0851707
[Epoch 34; Iter   183/  209] train: loss: 0.1284280
[Epoch 34] ogbg-moltox21: 0.776641 val loss: 0.285469
[Epoch 34] ogbg-moltox21: 0.746848 test loss: 0.299799
[Epoch 35; Iter     4/  209] train: loss: 0.1387515
[Epoch 35; Iter    34/  209] train: loss: 0.0934538
[Epoch 35; Iter    64/  209] train: loss: 0.1402171
[Epoch 35; Iter    94/  209] train: loss: 0.1463359
[Epoch 35; Iter   124/  209] train: loss: 0.1591532
[Epoch 35; Iter   154/  209] train: loss: 0.1340988
[Epoch 35; Iter   184/  209] train: loss: 0.1289812
[Epoch 35] ogbg-moltox21: 0.766159 val loss: 0.276584
[Epoch 35] ogbg-moltox21: 0.740203 test loss: 0.287456
[Epoch 36; Iter     5/  209] train: loss: 0.1149110
[Epoch 36; Iter    35/  209] train: loss: 0.0769178
[Epoch 36; Iter    65/  209] train: loss: 0.1813109
[Epoch 36; Iter    95/  209] train: loss: 0.1053247
[Epoch 36; Iter   125/  209] train: loss: 0.1557670
[Epoch 36; Iter   155/  209] train: loss: 0.1080504
[Epoch 36; Iter   185/  209] train: loss: 0.1262061
[Epoch 36] ogbg-moltox21: 0.779009 val loss: 0.278872
[Epoch 36] ogbg-moltox21: 0.751820 test loss: 0.287007
[Epoch 37; Iter     6/  209] train: loss: 0.0723510
[Epoch 37; Iter    36/  209] train: loss: 0.1411653
[Epoch 37; Iter    66/  209] train: loss: 0.1136932
[Epoch 37; Iter    96/  209] train: loss: 0.1210379
[Epoch 37; Iter   126/  209] train: loss: 0.0764748
[Epoch 37; Iter   156/  209] train: loss: 0.0680707
[Epoch 37; Iter   186/  209] train: loss: 0.1092018
[Epoch 37] ogbg-moltox21: 0.763757 val loss: 0.302696
[Epoch 37] ogbg-moltox21: 0.749384 test loss: 0.299119
[Epoch 38; Iter     7/  209] train: loss: 0.1138192
[Epoch 38; Iter    37/  209] train: loss: 0.1163239
[Epoch 38; Iter    67/  209] train: loss: 0.0877941
[Epoch 38; Iter    97/  209] train: loss: 0.1179386
[Epoch 38; Iter   127/  209] train: loss: 0.1263422
[Epoch 38; Iter   157/  209] train: loss: 0.1040625
[Epoch 38; Iter   187/  209] train: loss: 0.0956871
[Epoch 38] ogbg-moltox21: 0.768709 val loss: 0.289292
[Epoch 38] ogbg-moltox21: 0.738682 test loss: 0.306593
[Epoch 39; Iter     8/  209] train: loss: 0.1035948
[Epoch 39; Iter    38/  209] train: loss: 0.1039801
[Epoch 39; Iter    68/  209] train: loss: 0.1017464
[Epoch 39; Iter    98/  209] train: loss: 0.1125966
[Epoch 39; Iter   128/  209] train: loss: 0.0816085
[Epoch 39; Iter   158/  209] train: loss: 0.0731524
[Epoch 39; Iter   188/  209] train: loss: 0.0905416
[Epoch 39] ogbg-moltox21: 0.766239 val loss: 0.300990
[Epoch 39] ogbg-moltox21: 0.739791 test loss: 0.308586
[Epoch 40; Iter     9/  209] train: loss: 0.1114302
[Epoch 40; Iter    39/  209] train: loss: 0.2811004
[Epoch 40; Iter    69/  209] train: loss: 0.1145990
[Epoch 40; Iter    99/  209] train: loss: 0.1042618
[Epoch 40; Iter   129/  209] train: loss: 0.0975637
[Epoch 40; Iter   159/  209] train: loss: 0.0994722
[Epoch 40; Iter   189/  209] train: loss: 0.0950379
[Epoch 40] ogbg-moltox21: 0.769449 val loss: 0.312569
[Epoch 40] ogbg-moltox21: 0.733989 test loss: 0.324976
[Epoch 41; Iter    10/  209] train: loss: 0.0768931
[Epoch 41; Iter    40/  209] train: loss: 0.0777335
[Epoch 41; Iter    70/  209] train: loss: 0.0828091
[Epoch 41; Iter   100/  209] train: loss: 0.0979408
[Epoch 41; Iter   130/  209] train: loss: 0.1303360
[Epoch 41; Iter   160/  209] train: loss: 0.1277851
[Epoch 41; Iter   190/  209] train: loss: 0.0967996
[Epoch 41] ogbg-moltox21: 0.766818 val loss: 0.311720
[Epoch 41] ogbg-moltox21: 0.739950 test loss: 0.319985
[Epoch 42; Iter    11/  209] train: loss: 0.0823869
[Epoch 42; Iter    41/  209] train: loss: 0.1016847
[Epoch 42; Iter    71/  209] train: loss: 0.0838128
[Epoch 42; Iter   101/  209] train: loss: 0.0893935
[Epoch 42; Iter   131/  209] train: loss: 0.1276988
[Epoch 42; Iter   161/  209] train: loss: 0.0606620
[Epoch 42; Iter   191/  209] train: loss: 0.1039209
[Epoch 42] ogbg-moltox21: 0.760841 val loss: 0.324150
[Epoch 42] ogbg-moltox21: 0.738105 test loss: 0.337568
[Epoch 43; Iter    12/  209] train: loss: 0.0986279
[Epoch 43; Iter    42/  209] train: loss: 0.0779617
[Epoch 43; Iter    72/  209] train: loss: 0.1045135
[Epoch 43; Iter   102/  209] train: loss: 0.1494683
[Epoch 43; Iter   132/  209] train: loss: 0.1174106
[Epoch 43; Iter   162/  209] train: loss: 0.0778005
[Epoch 43; Iter   192/  209] train: loss: 0.0760679
[Epoch 43] ogbg-moltox21: 0.755316 val loss: 0.325211
[Epoch 43] ogbg-moltox21: 0.731640 test loss: 0.330274
[Epoch 44; Iter    13/  209] train: loss: 0.0919936
[Epoch 44; Iter    43/  209] train: loss: 0.0965522
[Epoch 44; Iter    73/  209] train: loss: 0.0984601
[Epoch 44; Iter   103/  209] train: loss: 0.1008435
[Epoch 44; Iter   133/  209] train: loss: 0.0870776
[Epoch 44; Iter   163/  209] train: loss: 0.0891501
[Epoch 44; Iter   193/  209] train: loss: 0.0609371
[Epoch 44] ogbg-moltox21: 0.759694 val loss: 0.306442
[Epoch 44] ogbg-moltox21: 0.736150 test loss: 0.321331
[Epoch 45; Iter    14/  209] train: loss: 0.0999915
[Epoch 45; Iter    44/  209] train: loss: 0.0994417
[Epoch 45; Iter    74/  209] train: loss: 0.1118379
[Epoch 45; Iter   104/  209] train: loss: 0.0799592
[Epoch 45; Iter   134/  209] train: loss: 0.1242564
[Epoch 45; Iter   164/  209] train: loss: 0.0596591
[Epoch 45; Iter   194/  209] train: loss: 0.0760433
[Epoch 45] ogbg-moltox21: 0.766432 val loss: 0.324183
[Epoch 45] ogbg-moltox21: 0.739888 test loss: 0.334557
[Epoch 46; Iter    15/  209] train: loss: 0.0955201
[Epoch 46; Iter    45/  209] train: loss: 0.1133058
[Epoch 46; Iter    75/  209] train: loss: 0.1353492
[Epoch 46; Iter   105/  209] train: loss: 0.1092504
[Epoch 46; Iter   135/  209] train: loss: 0.1375168
[Epoch 46; Iter   165/  209] train: loss: 0.0674686
[Epoch 46; Iter   195/  209] train: loss: 0.0905286
[Epoch 46] ogbg-moltox21: 0.758971 val loss: 0.340809
[Epoch 46] ogbg-moltox21: 0.736249 test loss: 0.357916
[Epoch 47; Iter    16/  209] train: loss: 0.0738429
[Epoch 47; Iter    46/  209] train: loss: 0.0858712
[Epoch 47; Iter    76/  209] train: loss: 0.1138778
[Epoch 47; Iter   106/  209] train: loss: 0.1046760
[Epoch 47; Iter   136/  209] train: loss: 0.0853036
[Epoch 30; Iter    89/  209] train: loss: 0.1570919
[Epoch 30; Iter   119/  209] train: loss: 0.1064075
[Epoch 30; Iter   149/  209] train: loss: 0.1466966
[Epoch 30; Iter   179/  209] train: loss: 0.1276413
[Epoch 30; Iter   209/  209] train: loss: 0.1150122
[Epoch 30] ogbg-moltox21: 0.792027 val loss: 0.272033
[Epoch 30] ogbg-moltox21: 0.745549 test loss: 0.326304
[Epoch 31; Iter    30/  209] train: loss: 0.1673567
[Epoch 31; Iter    60/  209] train: loss: 0.1267754
[Epoch 31; Iter    90/  209] train: loss: 0.1037718
[Epoch 31; Iter   120/  209] train: loss: 0.1366482
[Epoch 31; Iter   150/  209] train: loss: 0.1583790
[Epoch 31; Iter   180/  209] train: loss: 0.1555878
[Epoch 31] ogbg-moltox21: 0.783352 val loss: 0.278057
[Epoch 31] ogbg-moltox21: 0.744552 test loss: 0.298917
[Epoch 32; Iter     1/  209] train: loss: 0.1594792
[Epoch 32; Iter    31/  209] train: loss: 0.1698561
[Epoch 32; Iter    61/  209] train: loss: 0.1147000
[Epoch 32; Iter    91/  209] train: loss: 0.0957817
[Epoch 32; Iter   121/  209] train: loss: 0.1358416
[Epoch 32; Iter   151/  209] train: loss: 0.1227209
[Epoch 32; Iter   181/  209] train: loss: 0.1386556
[Epoch 32] ogbg-moltox21: 0.769183 val loss: 0.318716
[Epoch 32] ogbg-moltox21: 0.728276 test loss: 0.356927
[Epoch 33; Iter     2/  209] train: loss: 0.1387804
[Epoch 33; Iter    32/  209] train: loss: 0.1807487
[Epoch 33; Iter    62/  209] train: loss: 0.2075423
[Epoch 33; Iter    92/  209] train: loss: 0.1580793
[Epoch 33; Iter   122/  209] train: loss: 0.1941096
[Epoch 33; Iter   152/  209] train: loss: 0.1280323
[Epoch 33; Iter   182/  209] train: loss: 0.1203174
[Epoch 33] ogbg-moltox21: 0.758653 val loss: 0.750219
[Epoch 33] ogbg-moltox21: 0.735010 test loss: 1.523257
[Epoch 34; Iter     3/  209] train: loss: 0.1642186
[Epoch 34; Iter    33/  209] train: loss: 0.1638323
[Epoch 34; Iter    63/  209] train: loss: 0.1333115
[Epoch 34; Iter    93/  209] train: loss: 0.1460435
[Epoch 34; Iter   123/  209] train: loss: 0.1356529
[Epoch 34; Iter   153/  209] train: loss: 0.2432373
[Epoch 34; Iter   183/  209] train: loss: 0.0852694
[Epoch 34] ogbg-moltox21: 0.780944 val loss: 0.362007
[Epoch 34] ogbg-moltox21: 0.737069 test loss: 0.530527
[Epoch 35; Iter     4/  209] train: loss: 0.1565851
[Epoch 35; Iter    34/  209] train: loss: 0.0944710
[Epoch 35; Iter    64/  209] train: loss: 0.1387840
[Epoch 35; Iter    94/  209] train: loss: 0.0872003
[Epoch 35; Iter   124/  209] train: loss: 0.2872619
[Epoch 35; Iter   154/  209] train: loss: 0.1680373
[Epoch 35; Iter   184/  209] train: loss: 0.1834836
[Epoch 35] ogbg-moltox21: 0.766049 val loss: 0.328764
[Epoch 35] ogbg-moltox21: 0.739964 test loss: 0.555832
[Epoch 36; Iter     5/  209] train: loss: 0.1402999
[Epoch 36; Iter    35/  209] train: loss: 0.0930727
[Epoch 36; Iter    65/  209] train: loss: 0.0888511
[Epoch 36; Iter    95/  209] train: loss: 0.1042382
[Epoch 36; Iter   125/  209] train: loss: 0.1493176
[Epoch 36; Iter   155/  209] train: loss: 0.1212007
[Epoch 36; Iter   185/  209] train: loss: 0.1218107
[Epoch 36] ogbg-moltox21: 0.793970 val loss: 0.287485
[Epoch 36] ogbg-moltox21: 0.747956 test loss: 0.319333
[Epoch 37; Iter     6/  209] train: loss: 0.1150788
[Epoch 37; Iter    36/  209] train: loss: 0.1894380
[Epoch 37; Iter    66/  209] train: loss: 0.1084447
[Epoch 37; Iter    96/  209] train: loss: 0.1126430
[Epoch 37; Iter   126/  209] train: loss: 0.1238447
[Epoch 37; Iter   156/  209] train: loss: 0.1479829
[Epoch 37; Iter   186/  209] train: loss: 0.1643203
[Epoch 37] ogbg-moltox21: 0.755496 val loss: 0.391675
[Epoch 37] ogbg-moltox21: 0.724542 test loss: 0.470176
[Epoch 38; Iter     7/  209] train: loss: 0.1259442
[Epoch 38; Iter    37/  209] train: loss: 0.1142340
[Epoch 38; Iter    67/  209] train: loss: 0.0920275
[Epoch 38; Iter    97/  209] train: loss: 0.1154630
[Epoch 38; Iter   127/  209] train: loss: 0.1679421
[Epoch 38; Iter   157/  209] train: loss: 0.1239022
[Epoch 38; Iter   187/  209] train: loss: 0.2052368
[Epoch 38] ogbg-moltox21: 0.773719 val loss: 0.323954
[Epoch 38] ogbg-moltox21: 0.733904 test loss: 0.350533
[Epoch 39; Iter     8/  209] train: loss: 0.0965473
[Epoch 39; Iter    38/  209] train: loss: 0.0852415
[Epoch 39; Iter    68/  209] train: loss: 0.1134906
[Epoch 39; Iter    98/  209] train: loss: 0.1116142
[Epoch 39; Iter   128/  209] train: loss: 0.2129277
[Epoch 39; Iter   158/  209] train: loss: 0.1098816
[Epoch 39; Iter   188/  209] train: loss: 0.0837894
[Epoch 39] ogbg-moltox21: 0.778845 val loss: 0.353653
[Epoch 39] ogbg-moltox21: 0.734958 test loss: 0.428846
[Epoch 40; Iter     9/  209] train: loss: 0.0976585
[Epoch 40; Iter    39/  209] train: loss: 0.1270492
[Epoch 40; Iter    69/  209] train: loss: 0.1672625
[Epoch 40; Iter    99/  209] train: loss: 0.1224321
[Epoch 40; Iter   129/  209] train: loss: 0.0960294
[Epoch 40; Iter   159/  209] train: loss: 0.1398555
[Epoch 40; Iter   189/  209] train: loss: 0.1690692
[Epoch 40] ogbg-moltox21: 0.765656 val loss: 0.323467
[Epoch 40] ogbg-moltox21: 0.728692 test loss: 0.325478
[Epoch 41; Iter    10/  209] train: loss: 0.0668863
[Epoch 41; Iter    40/  209] train: loss: 0.1698313
[Epoch 41; Iter    70/  209] train: loss: 0.0646914
[Epoch 41; Iter   100/  209] train: loss: 0.1340397
[Epoch 41; Iter   130/  209] train: loss: 0.1958452
[Epoch 41; Iter   160/  209] train: loss: 0.1635603
[Epoch 41; Iter   190/  209] train: loss: 0.2140803
[Epoch 41] ogbg-moltox21: 0.784412 val loss: 0.287783
[Epoch 41] ogbg-moltox21: 0.748813 test loss: 0.319607
[Epoch 42; Iter    11/  209] train: loss: 0.0900491
[Epoch 42; Iter    41/  209] train: loss: 0.0878249
[Epoch 42; Iter    71/  209] train: loss: 0.1380593
[Epoch 42; Iter   101/  209] train: loss: 0.0897408
[Epoch 42; Iter   131/  209] train: loss: 0.0824114
[Epoch 42; Iter   161/  209] train: loss: 0.1167605
[Epoch 42; Iter   191/  209] train: loss: 0.1143644
[Epoch 42] ogbg-moltox21: 0.776381 val loss: 0.296728
[Epoch 42] ogbg-moltox21: 0.724139 test loss: 0.332561
[Epoch 43; Iter    12/  209] train: loss: 0.0882955
[Epoch 43; Iter    42/  209] train: loss: 0.0883740
[Epoch 43; Iter    72/  209] train: loss: 0.0912545
[Epoch 43; Iter   102/  209] train: loss: 0.1006848
[Epoch 43; Iter   132/  209] train: loss: 0.0835541
[Epoch 43; Iter   162/  209] train: loss: 0.0542056
[Epoch 43; Iter   192/  209] train: loss: 0.0900863
[Epoch 43] ogbg-moltox21: 0.786419 val loss: 0.281695
[Epoch 43] ogbg-moltox21: 0.730694 test loss: 0.320640
[Epoch 44; Iter    13/  209] train: loss: 0.0679821
[Epoch 44; Iter    43/  209] train: loss: 0.1013812
[Epoch 44; Iter    73/  209] train: loss: 0.0610547
[Epoch 44; Iter   103/  209] train: loss: 0.1304667
[Epoch 44; Iter   133/  209] train: loss: 0.1156916
[Epoch 44; Iter   163/  209] train: loss: 0.1144937
[Epoch 44; Iter   193/  209] train: loss: 0.1160833
[Epoch 44] ogbg-moltox21: 0.780976 val loss: 0.311185
[Epoch 44] ogbg-moltox21: 0.737612 test loss: 0.344606
[Epoch 45; Iter    14/  209] train: loss: 0.0960789
[Epoch 45; Iter    44/  209] train: loss: 0.0818575
[Epoch 45; Iter    74/  209] train: loss: 0.1154518
[Epoch 45; Iter   104/  209] train: loss: 0.0867645
[Epoch 45; Iter   134/  209] train: loss: 0.0689653
[Epoch 45; Iter   164/  209] train: loss: 0.0653272
[Epoch 45; Iter   194/  209] train: loss: 0.0911231
[Epoch 45] ogbg-moltox21: 0.776954 val loss: 0.326175
[Epoch 45] ogbg-moltox21: 0.732666 test loss: 0.352798
[Epoch 46; Iter    15/  209] train: loss: 0.0719036
[Epoch 46; Iter    45/  209] train: loss: 0.0889380
[Epoch 46; Iter    75/  209] train: loss: 0.0941680
[Epoch 46; Iter   105/  209] train: loss: 0.1063221
[Epoch 46; Iter   135/  209] train: loss: 0.1105571
[Epoch 46; Iter   165/  209] train: loss: 0.1537216
[Epoch 46; Iter   195/  209] train: loss: 0.0999111
[Epoch 46] ogbg-moltox21: 0.770307 val loss: 0.342526
[Epoch 46] ogbg-moltox21: 0.720432 test loss: 0.370241
[Epoch 47; Iter    16/  209] train: loss: 0.0816505
[Epoch 47; Iter    46/  209] train: loss: 0.0636565
[Epoch 47; Iter    76/  209] train: loss: 0.1583678
[Epoch 47; Iter   106/  209] train: loss: 0.1365826
[Epoch 47; Iter   136/  209] train: loss: 0.1010532
[Epoch 30; Iter    89/  209] train: loss: 0.1232510
[Epoch 30; Iter   119/  209] train: loss: 0.1342958
[Epoch 30; Iter   149/  209] train: loss: 0.1336631
[Epoch 30; Iter   179/  209] train: loss: 0.2090707
[Epoch 30; Iter   209/  209] train: loss: 0.0998011
[Epoch 30] ogbg-moltox21: 0.774193 val loss: 0.324785
[Epoch 30] ogbg-moltox21: 0.734886 test loss: 0.443598
[Epoch 31; Iter    30/  209] train: loss: 0.0750450
[Epoch 31; Iter    60/  209] train: loss: 0.1013850
[Epoch 31; Iter    90/  209] train: loss: 0.0998039
[Epoch 31; Iter   120/  209] train: loss: 0.1129342
[Epoch 31; Iter   150/  209] train: loss: 0.1231548
[Epoch 31; Iter   180/  209] train: loss: 0.2247011
[Epoch 31] ogbg-moltox21: 0.761814 val loss: 0.355716
[Epoch 31] ogbg-moltox21: 0.722180 test loss: 0.411261
[Epoch 32; Iter     1/  209] train: loss: 0.1259285
[Epoch 32; Iter    31/  209] train: loss: 0.0803375
[Epoch 32; Iter    61/  209] train: loss: 0.1462995
[Epoch 32; Iter    91/  209] train: loss: 0.1241555
[Epoch 32; Iter   121/  209] train: loss: 0.1361402
[Epoch 32; Iter   151/  209] train: loss: 0.1141326
[Epoch 32; Iter   181/  209] train: loss: 0.1707457
[Epoch 32] ogbg-moltox21: 0.757357 val loss: 0.310911
[Epoch 32] ogbg-moltox21: 0.728954 test loss: 0.377667
[Epoch 33; Iter     2/  209] train: loss: 0.0929980
[Epoch 33; Iter    32/  209] train: loss: 0.1094574
[Epoch 33; Iter    62/  209] train: loss: 0.0857672
[Epoch 33; Iter    92/  209] train: loss: 0.1366694
[Epoch 33; Iter   122/  209] train: loss: 0.1096197
[Epoch 33; Iter   152/  209] train: loss: 0.1109469
[Epoch 33; Iter   182/  209] train: loss: 0.0961533
[Epoch 33] ogbg-moltox21: 0.771600 val loss: 0.319132
[Epoch 33] ogbg-moltox21: 0.739002 test loss: 0.389746
[Epoch 34; Iter     3/  209] train: loss: 0.0739766
[Epoch 34; Iter    33/  209] train: loss: 0.0803188
[Epoch 34; Iter    63/  209] train: loss: 0.1110311
[Epoch 34; Iter    93/  209] train: loss: 0.1506816
[Epoch 34; Iter   123/  209] train: loss: 0.1236107
[Epoch 34; Iter   153/  209] train: loss: 0.1183162
[Epoch 34; Iter   183/  209] train: loss: 0.0773989
[Epoch 34] ogbg-moltox21: 0.773113 val loss: 0.342123
[Epoch 34] ogbg-moltox21: 0.751168 test loss: 0.393719
[Epoch 35; Iter     4/  209] train: loss: 0.1324563
[Epoch 35; Iter    34/  209] train: loss: 0.1064004
[Epoch 35; Iter    64/  209] train: loss: 0.1043328
[Epoch 35; Iter    94/  209] train: loss: 0.1029337
[Epoch 35; Iter   124/  209] train: loss: 0.1158831
[Epoch 35; Iter   154/  209] train: loss: 0.0927960
[Epoch 35; Iter   184/  209] train: loss: 0.1555404
[Epoch 35] ogbg-moltox21: 0.750171 val loss: 0.386238
[Epoch 35] ogbg-moltox21: 0.724417 test loss: 0.523057
[Epoch 36; Iter     5/  209] train: loss: 0.1229308
[Epoch 36; Iter    35/  209] train: loss: 0.1494180
[Epoch 36; Iter    65/  209] train: loss: 0.0932971
[Epoch 36; Iter    95/  209] train: loss: 0.1337548
[Epoch 36; Iter   125/  209] train: loss: 0.1490658
[Epoch 36; Iter   155/  209] train: loss: 0.0944484
[Epoch 36; Iter   185/  209] train: loss: 0.1255371
[Epoch 36] ogbg-moltox21: 0.773210 val loss: 0.498539
[Epoch 36] ogbg-moltox21: 0.746788 test loss: 0.743942
[Epoch 37; Iter     6/  209] train: loss: 0.1080479
[Epoch 37; Iter    36/  209] train: loss: 0.1041563
[Epoch 37; Iter    66/  209] train: loss: 0.1487704
[Epoch 37; Iter    96/  209] train: loss: 0.0985018
[Epoch 37; Iter   126/  209] train: loss: 0.0996223
[Epoch 37; Iter   156/  209] train: loss: 0.0873256
[Epoch 37; Iter   186/  209] train: loss: 0.1035846
[Epoch 37] ogbg-moltox21: 0.763164 val loss: 0.335407
[Epoch 37] ogbg-moltox21: 0.733647 test loss: 0.356767
[Epoch 38; Iter     7/  209] train: loss: 0.1634693
[Epoch 38; Iter    37/  209] train: loss: 0.0999048
[Epoch 38; Iter    67/  209] train: loss: 0.0805606
[Epoch 38; Iter    97/  209] train: loss: 0.0611964
[Epoch 38; Iter   127/  209] train: loss: 0.0799318
[Epoch 38; Iter   157/  209] train: loss: 0.0970513
[Epoch 38; Iter   187/  209] train: loss: 0.0556373
[Epoch 38] ogbg-moltox21: 0.762024 val loss: 0.348227
[Epoch 38] ogbg-moltox21: 0.743410 test loss: 0.425389
[Epoch 39; Iter     8/  209] train: loss: 0.0772780
[Epoch 39; Iter    38/  209] train: loss: 0.0651835
[Epoch 39; Iter    68/  209] train: loss: 0.0782560
[Epoch 39; Iter    98/  209] train: loss: 0.0907541
[Epoch 39; Iter   128/  209] train: loss: 0.1082149
[Epoch 39; Iter   158/  209] train: loss: 0.0837505
[Epoch 39; Iter   188/  209] train: loss: 0.0585450
[Epoch 39] ogbg-moltox21: 0.753844 val loss: 0.363651
[Epoch 39] ogbg-moltox21: 0.742786 test loss: 0.474141
[Epoch 40; Iter     9/  209] train: loss: 0.0726268
[Epoch 40; Iter    39/  209] train: loss: 0.0502751
[Epoch 40; Iter    69/  209] train: loss: 0.0826814
[Epoch 40; Iter    99/  209] train: loss: 0.1041898
[Epoch 40; Iter   129/  209] train: loss: 0.0553547
[Epoch 40; Iter   159/  209] train: loss: 0.0754113
[Epoch 40; Iter   189/  209] train: loss: 0.0952992
[Epoch 40] ogbg-moltox21: 0.754601 val loss: 0.387424
[Epoch 40] ogbg-moltox21: 0.728831 test loss: 0.431870
[Epoch 41; Iter    10/  209] train: loss: 0.0602437
[Epoch 41; Iter    40/  209] train: loss: 0.1104466
[Epoch 41; Iter    70/  209] train: loss: 0.0845531
[Epoch 41; Iter   100/  209] train: loss: 0.1387648
[Epoch 41; Iter   130/  209] train: loss: 0.0997228
[Epoch 41; Iter   160/  209] train: loss: 0.0831719
[Epoch 41; Iter   190/  209] train: loss: 0.0553086
[Epoch 41] ogbg-moltox21: 0.742818 val loss: 0.370276
[Epoch 41] ogbg-moltox21: 0.725937 test loss: 0.480198
[Epoch 42; Iter    11/  209] train: loss: 0.0800416
[Epoch 42; Iter    41/  209] train: loss: 0.0571810
[Epoch 42; Iter    71/  209] train: loss: 0.0766127
[Epoch 42; Iter   101/  209] train: loss: 0.0821856
[Epoch 42; Iter   131/  209] train: loss: 0.0807480
[Epoch 42; Iter   161/  209] train: loss: 0.0393839
[Epoch 42; Iter   191/  209] train: loss: 0.0380540
[Epoch 42] ogbg-moltox21: 0.750961 val loss: 0.373751
[Epoch 42] ogbg-moltox21: 0.729158 test loss: 0.490671
[Epoch 43; Iter    12/  209] train: loss: 0.0964829
[Epoch 43; Iter    42/  209] train: loss: 0.0844534
[Epoch 43; Iter    72/  209] train: loss: 0.0903486
[Epoch 43; Iter   102/  209] train: loss: 0.0587041
[Epoch 43; Iter   132/  209] train: loss: 0.0920453
[Epoch 43; Iter   162/  209] train: loss: 0.0654822
[Epoch 43; Iter   192/  209] train: loss: 0.0439878
[Epoch 43] ogbg-moltox21: 0.759017 val loss: 0.382763
[Epoch 43] ogbg-moltox21: 0.733392 test loss: 0.434764
[Epoch 44; Iter    13/  209] train: loss: 0.0431445
[Epoch 44; Iter    43/  209] train: loss: 0.0450255
[Epoch 44; Iter    73/  209] train: loss: 0.0439819
[Epoch 44; Iter   103/  209] train: loss: 0.0900098
[Epoch 44; Iter   133/  209] train: loss: 0.0615340
[Epoch 44; Iter   163/  209] train: loss: 0.0633203
[Epoch 44; Iter   193/  209] train: loss: 0.0958942
[Epoch 44] ogbg-moltox21: 0.749254 val loss: 0.429125
[Epoch 44] ogbg-moltox21: 0.737919 test loss: 0.441961
[Epoch 45; Iter    14/  209] train: loss: 0.0563983
[Epoch 45; Iter    44/  209] train: loss: 0.0542950
[Epoch 45; Iter    74/  209] train: loss: 0.0390922
[Epoch 45; Iter   104/  209] train: loss: 0.0611319
[Epoch 45; Iter   134/  209] train: loss: 0.0940084
[Epoch 45; Iter   164/  209] train: loss: 0.0688014
[Epoch 45; Iter   194/  209] train: loss: 0.0806121
[Epoch 45] ogbg-moltox21: 0.763149 val loss: 0.409037
[Epoch 45] ogbg-moltox21: 0.740297 test loss: 0.430633
[Epoch 46; Iter    15/  209] train: loss: 0.0731472
[Epoch 46; Iter    45/  209] train: loss: 0.0497527
[Epoch 46; Iter    75/  209] train: loss: 0.0410576
[Epoch 46; Iter   105/  209] train: loss: 0.0528156
[Epoch 46; Iter   135/  209] train: loss: 0.0951408
[Epoch 46; Iter   165/  209] train: loss: 0.0543209
[Epoch 46; Iter   195/  209] train: loss: 0.0967206
[Epoch 46] ogbg-moltox21: 0.750932 val loss: 0.422938
[Epoch 46] ogbg-moltox21: 0.730902 test loss: 0.435089
[Epoch 47; Iter    16/  209] train: loss: 0.0416794
[Epoch 47; Iter    46/  209] train: loss: 0.0370231
[Epoch 47; Iter    76/  209] train: loss: 0.0537960
[Epoch 47; Iter   106/  209] train: loss: 0.0392487
[Epoch 47; Iter   136/  209] train: loss: 0.1066071
[Epoch 30; Iter    89/  209] train: loss: 0.1223430
[Epoch 30; Iter   119/  209] train: loss: 0.1428165
[Epoch 30; Iter   149/  209] train: loss: 0.2778444
[Epoch 30; Iter   179/  209] train: loss: 0.1300015
[Epoch 30; Iter   209/  209] train: loss: 0.2386498
[Epoch 30] ogbg-moltox21: 0.755439 val loss: 0.390924
[Epoch 30] ogbg-moltox21: 0.709799 test loss: 0.315148
[Epoch 31; Iter    30/  209] train: loss: 0.1800727
[Epoch 31; Iter    60/  209] train: loss: 0.1591248
[Epoch 31; Iter    90/  209] train: loss: 0.1741840
[Epoch 31; Iter   120/  209] train: loss: 0.1188183
[Epoch 31; Iter   150/  209] train: loss: 0.1079564
[Epoch 31; Iter   180/  209] train: loss: 0.1720093
[Epoch 31] ogbg-moltox21: 0.776198 val loss: 0.299330
[Epoch 31] ogbg-moltox21: 0.725208 test loss: 0.327783
[Epoch 32; Iter     1/  209] train: loss: 0.1840208
[Epoch 32; Iter    31/  209] train: loss: 0.1337129
[Epoch 32; Iter    61/  209] train: loss: 0.0841717
[Epoch 32; Iter    91/  209] train: loss: 0.1304729
[Epoch 32; Iter   121/  209] train: loss: 0.1429748
[Epoch 32; Iter   151/  209] train: loss: 0.1896987
[Epoch 32; Iter   181/  209] train: loss: 0.1697527
[Epoch 32] ogbg-moltox21: 0.758426 val loss: 0.304955
[Epoch 32] ogbg-moltox21: 0.713496 test loss: 0.323102
[Epoch 33; Iter     2/  209] train: loss: 0.0947459
[Epoch 33; Iter    32/  209] train: loss: 0.0940084
[Epoch 33; Iter    62/  209] train: loss: 0.1090890
[Epoch 33; Iter    92/  209] train: loss: 0.1028571
[Epoch 33; Iter   122/  209] train: loss: 0.1526298
[Epoch 33; Iter   152/  209] train: loss: 0.1872462
[Epoch 33; Iter   182/  209] train: loss: 0.2074466
[Epoch 33] ogbg-moltox21: 0.762692 val loss: 0.295733
[Epoch 33] ogbg-moltox21: 0.719363 test loss: 0.316933
[Epoch 34; Iter     3/  209] train: loss: 0.0792621
[Epoch 34; Iter    33/  209] train: loss: 0.1494135
[Epoch 34; Iter    63/  209] train: loss: 0.1336602
[Epoch 34; Iter    93/  209] train: loss: 0.0796501
[Epoch 34; Iter   123/  209] train: loss: 0.1174589
[Epoch 34; Iter   153/  209] train: loss: 0.0855835
[Epoch 34; Iter   183/  209] train: loss: 0.1098154
[Epoch 34] ogbg-moltox21: 0.765785 val loss: 0.347154
[Epoch 34] ogbg-moltox21: 0.718008 test loss: 0.364367
[Epoch 35; Iter     4/  209] train: loss: 0.1290059
[Epoch 35; Iter    34/  209] train: loss: 0.0897515
[Epoch 35; Iter    64/  209] train: loss: 0.1026872
[Epoch 35; Iter    94/  209] train: loss: 0.1494417
[Epoch 35; Iter   124/  209] train: loss: 0.1186168
[Epoch 35; Iter   154/  209] train: loss: 0.1401254
[Epoch 35; Iter   184/  209] train: loss: 0.1217383
[Epoch 35] ogbg-moltox21: 0.738467 val loss: 0.351122
[Epoch 35] ogbg-moltox21: 0.726124 test loss: 0.362543
[Epoch 36; Iter     5/  209] train: loss: 0.0984099
[Epoch 36; Iter    35/  209] train: loss: 0.0559422
[Epoch 36; Iter    65/  209] train: loss: 0.1807365
[Epoch 36; Iter    95/  209] train: loss: 0.0961774
[Epoch 36; Iter   125/  209] train: loss: 0.1328921
[Epoch 36; Iter   155/  209] train: loss: 0.0835582
[Epoch 36; Iter   185/  209] train: loss: 0.1109730
[Epoch 36] ogbg-moltox21: 0.755534 val loss: 0.353904
[Epoch 36] ogbg-moltox21: 0.720148 test loss: 0.359020
[Epoch 37; Iter     6/  209] train: loss: 0.0524894
[Epoch 37; Iter    36/  209] train: loss: 0.1073163
[Epoch 37; Iter    66/  209] train: loss: 0.0891477
[Epoch 37; Iter    96/  209] train: loss: 0.1107370
[Epoch 37; Iter   126/  209] train: loss: 0.0638766
[Epoch 37; Iter   156/  209] train: loss: 0.0639095
[Epoch 37; Iter   186/  209] train: loss: 0.0969908
[Epoch 37] ogbg-moltox21: 0.741434 val loss: 0.368825
[Epoch 37] ogbg-moltox21: 0.712943 test loss: 0.376548
[Epoch 38; Iter     7/  209] train: loss: 0.0936446
[Epoch 38; Iter    37/  209] train: loss: 0.0983150
[Epoch 38; Iter    67/  209] train: loss: 0.0664216
[Epoch 38; Iter    97/  209] train: loss: 0.0826116
[Epoch 38; Iter   127/  209] train: loss: 0.0902868
[Epoch 38; Iter   157/  209] train: loss: 0.0839396
[Epoch 38; Iter   187/  209] train: loss: 0.0886822
[Epoch 38] ogbg-moltox21: 0.745416 val loss: 0.383043
[Epoch 38] ogbg-moltox21: 0.712823 test loss: 0.411724
[Epoch 39; Iter     8/  209] train: loss: 0.0757926
[Epoch 39; Iter    38/  209] train: loss: 0.0861118
[Epoch 39; Iter    68/  209] train: loss: 0.0780962
[Epoch 39; Iter    98/  209] train: loss: 0.1062369
[Epoch 39; Iter   128/  209] train: loss: 0.0735172
[Epoch 39; Iter   158/  209] train: loss: 0.0690233
[Epoch 39; Iter   188/  209] train: loss: 0.0607159
[Epoch 39] ogbg-moltox21: 0.750475 val loss: 0.411225
[Epoch 39] ogbg-moltox21: 0.719096 test loss: 0.421197
[Epoch 40; Iter     9/  209] train: loss: 0.0896439
[Epoch 40; Iter    39/  209] train: loss: 0.2354131
[Epoch 40; Iter    69/  209] train: loss: 0.0819077
[Epoch 40; Iter    99/  209] train: loss: 0.0765004
[Epoch 40; Iter   129/  209] train: loss: 0.0830450
[Epoch 40; Iter   159/  209] train: loss: 0.0837196
[Epoch 40; Iter   189/  209] train: loss: 0.0699848
[Epoch 40] ogbg-moltox21: 0.755026 val loss: 0.360752
[Epoch 40] ogbg-moltox21: 0.715453 test loss: 0.374768
[Epoch 41; Iter    10/  209] train: loss: 0.0464790
[Epoch 41; Iter    40/  209] train: loss: 0.0560157
[Epoch 41; Iter    70/  209] train: loss: 0.0540386
[Epoch 41; Iter   100/  209] train: loss: 0.0766759
[Epoch 41; Iter   130/  209] train: loss: 0.0879241
[Epoch 41; Iter   160/  209] train: loss: 0.0867450
[Epoch 41; Iter   190/  209] train: loss: 0.0754607
[Epoch 41] ogbg-moltox21: 0.738155 val loss: 0.391691
[Epoch 41] ogbg-moltox21: 0.720909 test loss: 0.382243
[Epoch 42; Iter    11/  209] train: loss: 0.0813192
[Epoch 42; Iter    41/  209] train: loss: 0.0888900
[Epoch 42; Iter    71/  209] train: loss: 0.0611610
[Epoch 42; Iter   101/  209] train: loss: 0.0619859
[Epoch 42; Iter   131/  209] train: loss: 0.0950395
[Epoch 42; Iter   161/  209] train: loss: 0.0611679
[Epoch 42; Iter   191/  209] train: loss: 0.1005346
[Epoch 42] ogbg-moltox21: 0.746939 val loss: 0.407332
[Epoch 42] ogbg-moltox21: 0.705858 test loss: 0.424380
[Epoch 43; Iter    12/  209] train: loss: 0.0674947
[Epoch 43; Iter    42/  209] train: loss: 0.0618518
[Epoch 43; Iter    72/  209] train: loss: 0.0913827
[Epoch 43; Iter   102/  209] train: loss: 0.1022260
[Epoch 43; Iter   132/  209] train: loss: 0.0886964
[Epoch 43; Iter   162/  209] train: loss: 0.0568249
[Epoch 43; Iter   192/  209] train: loss: 0.0711065
[Epoch 43] ogbg-moltox21: 0.741342 val loss: 0.404350
[Epoch 43] ogbg-moltox21: 0.711431 test loss: 0.423935
[Epoch 44; Iter    13/  209] train: loss: 0.0987542
[Epoch 44; Iter    43/  209] train: loss: 0.0697236
[Epoch 44; Iter    73/  209] train: loss: 0.0815689
[Epoch 44; Iter   103/  209] train: loss: 0.0681592
[Epoch 44; Iter   133/  209] train: loss: 0.0725309
[Epoch 44; Iter   163/  209] train: loss: 0.0701906
[Epoch 44; Iter   193/  209] train: loss: 0.0447760
[Epoch 44] ogbg-moltox21: 0.742790 val loss: 0.364537
[Epoch 44] ogbg-moltox21: 0.716337 test loss: 0.395640
[Epoch 45; Iter    14/  209] train: loss: 0.0680900
[Epoch 45; Iter    44/  209] train: loss: 0.0612420
[Epoch 45; Iter    74/  209] train: loss: 0.0819296
[Epoch 45; Iter   104/  209] train: loss: 0.0643005
[Epoch 45; Iter   134/  209] train: loss: 0.1120480
[Epoch 45; Iter   164/  209] train: loss: 0.0657997
[Epoch 45; Iter   194/  209] train: loss: 0.0628342
[Epoch 45] ogbg-moltox21: 0.744612 val loss: 0.393115
[Epoch 45] ogbg-moltox21: 0.712056 test loss: 0.445996
[Epoch 46; Iter    15/  209] train: loss: 0.0478045
[Epoch 46; Iter    45/  209] train: loss: 0.0820402
[Epoch 46; Iter    75/  209] train: loss: 0.0871783
[Epoch 46; Iter   105/  209] train: loss: 0.0841695
[Epoch 46; Iter   135/  209] train: loss: 0.0975926
[Epoch 46; Iter   165/  209] train: loss: 0.0478899
[Epoch 46; Iter   195/  209] train: loss: 0.0715679
[Epoch 46] ogbg-moltox21: 0.736159 val loss: 0.410336
[Epoch 46] ogbg-moltox21: 0.719657 test loss: 0.410176
[Epoch 47; Iter    16/  209] train: loss: 0.0513572
[Epoch 47; Iter    46/  209] train: loss: 0.0549920
[Epoch 47; Iter    76/  209] train: loss: 0.0589335
[Epoch 47; Iter   106/  209] train: loss: 0.1154252
[Epoch 47; Iter   136/  209] train: loss: 0.0596595
[Epoch 30; Iter    89/  209] train: loss: 0.0880556
[Epoch 30; Iter   119/  209] train: loss: 0.0870568
[Epoch 30; Iter   149/  209] train: loss: 0.0998930
[Epoch 30; Iter   179/  209] train: loss: 0.0994349
[Epoch 30; Iter   209/  209] train: loss: 0.0816994
[Epoch 30] ogbg-moltox21: 0.711805 val loss: 0.344575
[Epoch 30] ogbg-moltox21: 0.710933 test loss: 0.359357
[Epoch 31; Iter    30/  209] train: loss: 0.1136516
[Epoch 31; Iter    60/  209] train: loss: 0.0790130
[Epoch 31; Iter    90/  209] train: loss: 0.0917181
[Epoch 31; Iter   120/  209] train: loss: 0.0826962
[Epoch 31; Iter   150/  209] train: loss: 0.1148071
[Epoch 31; Iter   180/  209] train: loss: 0.1359229
[Epoch 31] ogbg-moltox21: 0.729742 val loss: 0.326054
[Epoch 31] ogbg-moltox21: 0.719700 test loss: 0.340699
[Epoch 32; Iter     1/  209] train: loss: 0.1295183
[Epoch 32; Iter    31/  209] train: loss: 0.1464729
[Epoch 32; Iter    61/  209] train: loss: 0.0926478
[Epoch 32; Iter    91/  209] train: loss: 0.0721303
[Epoch 32; Iter   121/  209] train: loss: 0.0879578
[Epoch 32; Iter   151/  209] train: loss: 0.0956903
[Epoch 32; Iter   181/  209] train: loss: 0.1111399
[Epoch 32] ogbg-moltox21: 0.716406 val loss: 0.348599
[Epoch 32] ogbg-moltox21: 0.699539 test loss: 0.360319
[Epoch 33; Iter     2/  209] train: loss: 0.1144438
[Epoch 33; Iter    32/  209] train: loss: 0.1016871
[Epoch 33; Iter    62/  209] train: loss: 0.1442769
[Epoch 33; Iter    92/  209] train: loss: 0.1384451
[Epoch 33; Iter   122/  209] train: loss: 0.1417874
[Epoch 33; Iter   152/  209] train: loss: 0.0897869
[Epoch 33; Iter   182/  209] train: loss: 0.1155951
[Epoch 33] ogbg-moltox21: 0.716278 val loss: 0.342889
[Epoch 33] ogbg-moltox21: 0.719117 test loss: 0.349806
[Epoch 34; Iter     3/  209] train: loss: 0.1461809
[Epoch 34; Iter    33/  209] train: loss: 0.1404433
[Epoch 34; Iter    63/  209] train: loss: 0.1117187
[Epoch 34; Iter    93/  209] train: loss: 0.1087407
[Epoch 34; Iter   123/  209] train: loss: 0.1067133
[Epoch 34; Iter   153/  209] train: loss: 0.1870079
[Epoch 34; Iter   183/  209] train: loss: 0.0904901
[Epoch 34] ogbg-moltox21: 0.711136 val loss: 0.377446
[Epoch 34] ogbg-moltox21: 0.711906 test loss: 0.390501
[Epoch 35; Iter     4/  209] train: loss: 0.1315793
[Epoch 35; Iter    34/  209] train: loss: 0.1034309
[Epoch 35; Iter    64/  209] train: loss: 0.1008444
[Epoch 35; Iter    94/  209] train: loss: 0.0996761
[Epoch 35; Iter   124/  209] train: loss: 0.1966394
[Epoch 35; Iter   154/  209] train: loss: 0.1608791
[Epoch 35; Iter   184/  209] train: loss: 0.1697351
[Epoch 35] ogbg-moltox21: 0.723593 val loss: 0.346374
[Epoch 35] ogbg-moltox21: 0.713281 test loss: 0.364891
[Epoch 36; Iter     5/  209] train: loss: 0.1177286
[Epoch 36; Iter    35/  209] train: loss: 0.0977974
[Epoch 36; Iter    65/  209] train: loss: 0.0772844
[Epoch 36; Iter    95/  209] train: loss: 0.0931324
[Epoch 36; Iter   125/  209] train: loss: 0.1374132
[Epoch 36; Iter   155/  209] train: loss: 0.0860356
[Epoch 36; Iter   185/  209] train: loss: 0.0975840
[Epoch 36] ogbg-moltox21: 0.734533 val loss: 0.350982
[Epoch 36] ogbg-moltox21: 0.704462 test loss: 0.365470
[Epoch 37; Iter     6/  209] train: loss: 0.0771590
[Epoch 37; Iter    36/  209] train: loss: 0.1386953
[Epoch 37; Iter    66/  209] train: loss: 0.0999882
[Epoch 37; Iter    96/  209] train: loss: 0.0956753
[Epoch 37; Iter   126/  209] train: loss: 0.0789012
[Epoch 37; Iter   156/  209] train: loss: 0.0954885
[Epoch 37; Iter   186/  209] train: loss: 0.1262694
[Epoch 37] ogbg-moltox21: 0.698040 val loss: 0.386248
[Epoch 37] ogbg-moltox21: 0.698241 test loss: 0.391960
[Epoch 38; Iter     7/  209] train: loss: 0.1026790
[Epoch 38; Iter    37/  209] train: loss: 0.1008319
[Epoch 38; Iter    67/  209] train: loss: 0.0461721
[Epoch 38; Iter    97/  209] train: loss: 0.0844415
[Epoch 38; Iter   127/  209] train: loss: 0.1245310
[Epoch 38; Iter   157/  209] train: loss: 0.1172735
[Epoch 38; Iter   187/  209] train: loss: 0.1618373
[Epoch 38] ogbg-moltox21: 0.727719 val loss: 0.434268
[Epoch 38] ogbg-moltox21: 0.698393 test loss: 0.730435
[Epoch 39; Iter     8/  209] train: loss: 0.1013281
[Epoch 39; Iter    38/  209] train: loss: 0.0867246
[Epoch 39; Iter    68/  209] train: loss: 0.0873115
[Epoch 39; Iter    98/  209] train: loss: 0.0886274
[Epoch 39; Iter   128/  209] train: loss: 0.1685362
[Epoch 39; Iter   158/  209] train: loss: 0.0757621
[Epoch 39; Iter   188/  209] train: loss: 0.0685617
[Epoch 39] ogbg-moltox21: 0.707972 val loss: 0.390855
[Epoch 39] ogbg-moltox21: 0.700806 test loss: 0.395246
[Epoch 40; Iter     9/  209] train: loss: 0.0756570
[Epoch 40; Iter    39/  209] train: loss: 0.0840422
[Epoch 40; Iter    69/  209] train: loss: 0.1096547
[Epoch 40; Iter    99/  209] train: loss: 0.0928219
[Epoch 40; Iter   129/  209] train: loss: 0.0552541
[Epoch 40; Iter   159/  209] train: loss: 0.1040308
[Epoch 40; Iter   189/  209] train: loss: 0.1159993
[Epoch 40] ogbg-moltox21: 0.734362 val loss: 0.402672
[Epoch 40] ogbg-moltox21: 0.705492 test loss: 0.424955
[Epoch 41; Iter    10/  209] train: loss: 0.0615938
[Epoch 41; Iter    40/  209] train: loss: 0.0888471
[Epoch 41; Iter    70/  209] train: loss: 0.0611067
[Epoch 41; Iter   100/  209] train: loss: 0.1004859
[Epoch 41; Iter   130/  209] train: loss: 0.1746377
[Epoch 41; Iter   160/  209] train: loss: 0.0984965
[Epoch 41; Iter   190/  209] train: loss: 0.1248196
[Epoch 41] ogbg-moltox21: 0.724918 val loss: 0.395227
[Epoch 41] ogbg-moltox21: 0.717194 test loss: 0.399314
[Epoch 42; Iter    11/  209] train: loss: 0.0520304
[Epoch 42; Iter    41/  209] train: loss: 0.0611572
[Epoch 42; Iter    71/  209] train: loss: 0.0963806
[Epoch 42; Iter   101/  209] train: loss: 0.0589947
[Epoch 42; Iter   131/  209] train: loss: 0.0668750
[Epoch 42; Iter   161/  209] train: loss: 0.1254733
[Epoch 42; Iter   191/  209] train: loss: 0.1048521
[Epoch 42] ogbg-moltox21: 0.726291 val loss: 0.407033
[Epoch 42] ogbg-moltox21: 0.716231 test loss: 0.427177
[Epoch 43; Iter    12/  209] train: loss: 0.0826420
[Epoch 43; Iter    42/  209] train: loss: 0.0935148
[Epoch 43; Iter    72/  209] train: loss: 0.0932774
[Epoch 43; Iter   102/  209] train: loss: 0.0855477
[Epoch 43; Iter   132/  209] train: loss: 0.0575776
[Epoch 43; Iter   162/  209] train: loss: 0.0508008
[Epoch 43; Iter   192/  209] train: loss: 0.0810620
[Epoch 43] ogbg-moltox21: 0.737221 val loss: 0.390028
[Epoch 43] ogbg-moltox21: 0.715084 test loss: 0.422779
[Epoch 44; Iter    13/  209] train: loss: 0.0519739
[Epoch 44; Iter    43/  209] train: loss: 0.0775153
[Epoch 44; Iter    73/  209] train: loss: 0.0620152
[Epoch 44; Iter   103/  209] train: loss: 0.1100050
[Epoch 44; Iter   133/  209] train: loss: 0.1021347
[Epoch 44; Iter   163/  209] train: loss: 0.0959209
[Epoch 44; Iter   193/  209] train: loss: 0.0682522
[Epoch 44] ogbg-moltox21: 0.720828 val loss: 0.446986
[Epoch 44] ogbg-moltox21: 0.703549 test loss: 0.482789
[Epoch 45; Iter    14/  209] train: loss: 0.0630861
[Epoch 45; Iter    44/  209] train: loss: 0.0693836
[Epoch 45; Iter    74/  209] train: loss: 0.0970136
[Epoch 45; Iter   104/  209] train: loss: 0.0655803
[Epoch 45; Iter   134/  209] train: loss: 0.0421389
[Epoch 45; Iter   164/  209] train: loss: 0.0732207
[Epoch 45; Iter   194/  209] train: loss: 0.0738345
[Epoch 45] ogbg-moltox21: 0.701612 val loss: 0.482230
[Epoch 45] ogbg-moltox21: 0.708067 test loss: 0.500155
[Epoch 46; Iter    15/  209] train: loss: 0.0438384
[Epoch 46; Iter    45/  209] train: loss: 0.0770475
[Epoch 46; Iter    75/  209] train: loss: 0.0849330
[Epoch 46; Iter   105/  209] train: loss: 0.0795799
[Epoch 46; Iter   135/  209] train: loss: 0.1145085
[Epoch 46; Iter   165/  209] train: loss: 0.1364291
[Epoch 46; Iter   195/  209] train: loss: 0.0757121
[Epoch 46] ogbg-moltox21: 0.709333 val loss: 0.448209
[Epoch 46] ogbg-moltox21: 0.699700 test loss: 0.459045
[Epoch 47; Iter    16/  209] train: loss: 0.0558983
[Epoch 47; Iter    46/  209] train: loss: 0.0713678
[Epoch 47; Iter    76/  209] train: loss: 0.1086816
[Epoch 47; Iter   106/  209] train: loss: 0.0956668
[Epoch 47; Iter   136/  209] train: loss: 0.0906167
[Epoch 30; Iter    89/  209] train: loss: 0.1159430
[Epoch 30; Iter   119/  209] train: loss: 0.1280117
[Epoch 30; Iter   149/  209] train: loss: 0.0877938
[Epoch 30; Iter   179/  209] train: loss: 0.2021535
[Epoch 30; Iter   209/  209] train: loss: 0.0777204
[Epoch 30] ogbg-moltox21: 0.744345 val loss: 0.411308
[Epoch 30] ogbg-moltox21: 0.692530 test loss: 0.530403
[Epoch 31; Iter    30/  209] train: loss: 0.0756193
[Epoch 31; Iter    60/  209] train: loss: 0.1058981
[Epoch 31; Iter    90/  209] train: loss: 0.1055624
[Epoch 31; Iter   120/  209] train: loss: 0.1223184
[Epoch 31; Iter   150/  209] train: loss: 0.1333978
[Epoch 31; Iter   180/  209] train: loss: 0.1659981
[Epoch 31] ogbg-moltox21: 0.696093 val loss: 0.554699
[Epoch 31] ogbg-moltox21: 0.658258 test loss: 0.746886
[Epoch 32; Iter     1/  209] train: loss: 0.1343879
[Epoch 32; Iter    31/  209] train: loss: 0.0720357
[Epoch 32; Iter    61/  209] train: loss: 0.1658963
[Epoch 32; Iter    91/  209] train: loss: 0.1113137
[Epoch 32; Iter   121/  209] train: loss: 0.1230109
[Epoch 32; Iter   151/  209] train: loss: 0.1240730
[Epoch 32; Iter   181/  209] train: loss: 0.1599810
[Epoch 32] ogbg-moltox21: 0.738827 val loss: 0.346216
[Epoch 32] ogbg-moltox21: 0.671883 test loss: 0.631667
[Epoch 33; Iter     2/  209] train: loss: 0.0958329
[Epoch 33; Iter    32/  209] train: loss: 0.0968179
[Epoch 33; Iter    62/  209] train: loss: 0.0808559
[Epoch 33; Iter    92/  209] train: loss: 0.1312271
[Epoch 33; Iter   122/  209] train: loss: 0.1186199
[Epoch 33; Iter   152/  209] train: loss: 0.0827854
[Epoch 33; Iter   182/  209] train: loss: 0.0864558
[Epoch 33] ogbg-moltox21: 0.754883 val loss: 0.352168
[Epoch 33] ogbg-moltox21: 0.705762 test loss: 0.393701
[Epoch 34; Iter     3/  209] train: loss: 0.0667631
[Epoch 34; Iter    33/  209] train: loss: 0.0797702
[Epoch 34; Iter    63/  209] train: loss: 0.1152625
[Epoch 34; Iter    93/  209] train: loss: 0.1555619
[Epoch 34; Iter   123/  209] train: loss: 0.1150573
[Epoch 34; Iter   153/  209] train: loss: 0.1189063
[Epoch 34; Iter   183/  209] train: loss: 0.1148655
[Epoch 34] ogbg-moltox21: 0.700540 val loss: 0.795014
[Epoch 34] ogbg-moltox21: 0.674814 test loss: 1.025113
[Epoch 35; Iter     4/  209] train: loss: 0.1652457
[Epoch 35; Iter    34/  209] train: loss: 0.1097185
[Epoch 35; Iter    64/  209] train: loss: 0.1352487
[Epoch 35; Iter    94/  209] train: loss: 0.1261569
[Epoch 35; Iter   124/  209] train: loss: 0.1622897
[Epoch 35; Iter   154/  209] train: loss: 0.1044168
[Epoch 35; Iter   184/  209] train: loss: 0.1741465
[Epoch 35] ogbg-moltox21: 0.721270 val loss: 1.837519
[Epoch 35] ogbg-moltox21: 0.678047 test loss: 1.566967
[Epoch 36; Iter     5/  209] train: loss: 0.1166207
[Epoch 36; Iter    35/  209] train: loss: 0.1600939
[Epoch 36; Iter    65/  209] train: loss: 0.1115270
[Epoch 36; Iter    95/  209] train: loss: 0.1576235
[Epoch 36; Iter   125/  209] train: loss: 0.1417989
[Epoch 36; Iter   155/  209] train: loss: 0.1095194
[Epoch 36; Iter   185/  209] train: loss: 0.1229940
[Epoch 36] ogbg-moltox21: 0.731807 val loss: 1.178859
[Epoch 36] ogbg-moltox21: 0.694901 test loss: 0.865838
[Epoch 37; Iter     6/  209] train: loss: 0.0852059
[Epoch 37; Iter    36/  209] train: loss: 0.1025737
[Epoch 37; Iter    66/  209] train: loss: 0.1437483
[Epoch 37; Iter    96/  209] train: loss: 0.1006886
[Epoch 37; Iter   126/  209] train: loss: 0.1214612
[Epoch 37; Iter   156/  209] train: loss: 0.0837997
[Epoch 37; Iter   186/  209] train: loss: 0.1084408
[Epoch 37] ogbg-moltox21: 0.720686 val loss: 0.796799
[Epoch 37] ogbg-moltox21: 0.682816 test loss: 0.597671
[Epoch 38; Iter     7/  209] train: loss: 0.1533746
[Epoch 38; Iter    37/  209] train: loss: 0.1231946
[Epoch 38; Iter    67/  209] train: loss: 0.1110328
[Epoch 38; Iter    97/  209] train: loss: 0.0858719
[Epoch 38; Iter   127/  209] train: loss: 0.0798938
[Epoch 38; Iter   157/  209] train: loss: 0.1063578
[Epoch 38; Iter   187/  209] train: loss: 0.0682234
[Epoch 38] ogbg-moltox21: 0.733013 val loss: 0.810908
[Epoch 38] ogbg-moltox21: 0.695938 test loss: 0.732404
[Epoch 39; Iter     8/  209] train: loss: 0.1012327
[Epoch 39; Iter    38/  209] train: loss: 0.0714911
[Epoch 39; Iter    68/  209] train: loss: 0.0828572
[Epoch 39; Iter    98/  209] train: loss: 0.1140859
[Epoch 39; Iter   128/  209] train: loss: 0.0948570
[Epoch 39; Iter   158/  209] train: loss: 0.0769805
[Epoch 39; Iter   188/  209] train: loss: 0.0779288
[Epoch 39] ogbg-moltox21: 0.722132 val loss: 0.550163
[Epoch 39] ogbg-moltox21: 0.678749 test loss: 0.582201
[Epoch 40; Iter     9/  209] train: loss: 0.0862498
[Epoch 40; Iter    39/  209] train: loss: 0.0530515
[Epoch 40; Iter    69/  209] train: loss: 0.0756912
[Epoch 40; Iter    99/  209] train: loss: 0.0911255
[Epoch 40; Iter   129/  209] train: loss: 0.0646277
[Epoch 40; Iter   159/  209] train: loss: 0.0810964
[Epoch 40; Iter   189/  209] train: loss: 0.1144575
[Epoch 40] ogbg-moltox21: 0.745635 val loss: 0.765668
[Epoch 40] ogbg-moltox21: 0.705825 test loss: 0.631447
[Epoch 41; Iter    10/  209] train: loss: 0.0906514
[Epoch 41; Iter    40/  209] train: loss: 0.1184793
[Epoch 41; Iter    70/  209] train: loss: 0.0977359
[Epoch 41; Iter   100/  209] train: loss: 0.1342812
[Epoch 41; Iter   130/  209] train: loss: 0.0929095
[Epoch 41; Iter   160/  209] train: loss: 0.0735057
[Epoch 41; Iter   190/  209] train: loss: 0.0402910
[Epoch 41] ogbg-moltox21: 0.731304 val loss: 1.227261
[Epoch 41] ogbg-moltox21: 0.672634 test loss: 0.976612
[Epoch 42; Iter    11/  209] train: loss: 0.0907370
[Epoch 42; Iter    41/  209] train: loss: 0.0631314
[Epoch 42; Iter    71/  209] train: loss: 0.0860431
[Epoch 42; Iter   101/  209] train: loss: 0.0945995
[Epoch 42; Iter   131/  209] train: loss: 0.1247349
[Epoch 42; Iter   161/  209] train: loss: 0.0477980
[Epoch 42; Iter   191/  209] train: loss: 0.0384137
[Epoch 42] ogbg-moltox21: 0.738860 val loss: 0.531803
[Epoch 42] ogbg-moltox21: 0.683798 test loss: 0.580898
[Epoch 43; Iter    12/  209] train: loss: 0.0722701
[Epoch 43; Iter    42/  209] train: loss: 0.0819048
[Epoch 43; Iter    72/  209] train: loss: 0.0955094
[Epoch 43; Iter   102/  209] train: loss: 0.0800470
[Epoch 43; Iter   132/  209] train: loss: 0.0914255
[Epoch 43; Iter   162/  209] train: loss: 0.0789430
[Epoch 43; Iter   192/  209] train: loss: 0.0658030
[Epoch 43] ogbg-moltox21: 0.732168 val loss: 0.859788
[Epoch 43] ogbg-moltox21: 0.680229 test loss: 0.736964
[Epoch 44; Iter    13/  209] train: loss: 0.0475261
[Epoch 44; Iter    43/  209] train: loss: 0.0523926
[Epoch 44; Iter    73/  209] train: loss: 0.0376975
[Epoch 44; Iter   103/  209] train: loss: 0.1012095
[Epoch 44; Iter   133/  209] train: loss: 0.0790607
[Epoch 44; Iter   163/  209] train: loss: 0.0776504
[Epoch 44; Iter   193/  209] train: loss: 0.1207899
[Epoch 44] ogbg-moltox21: 0.735385 val loss: 0.754200
[Epoch 44] ogbg-moltox21: 0.686000 test loss: 0.655965
[Epoch 45; Iter    14/  209] train: loss: 0.0599983
[Epoch 45; Iter    44/  209] train: loss: 0.0592662
[Epoch 45; Iter    74/  209] train: loss: 0.0601768
[Epoch 45; Iter   104/  209] train: loss: 0.0863073
[Epoch 45; Iter   134/  209] train: loss: 0.1074722
[Epoch 45; Iter   164/  209] train: loss: 0.0882838
[Epoch 45; Iter   194/  209] train: loss: 0.0881303
[Epoch 45] ogbg-moltox21: 0.746813 val loss: 0.540374
[Epoch 45] ogbg-moltox21: 0.690199 test loss: 0.700583
[Epoch 46; Iter    15/  209] train: loss: 0.0801154
[Epoch 46; Iter    45/  209] train: loss: 0.1107580
[Epoch 46; Iter    75/  209] train: loss: 0.0436570
[Epoch 46; Iter   105/  209] train: loss: 0.0667236
[Epoch 46; Iter   135/  209] train: loss: 0.0721870
[Epoch 46; Iter   165/  209] train: loss: 0.0639034
[Epoch 46; Iter   195/  209] train: loss: 0.1207008
[Epoch 46] ogbg-moltox21: 0.728794 val loss: 0.438688
[Epoch 46] ogbg-moltox21: 0.684972 test loss: 0.541890
[Epoch 47; Iter    16/  209] train: loss: 0.0520001
[Epoch 47; Iter    46/  209] train: loss: 0.0476535
[Epoch 47; Iter    76/  209] train: loss: 0.0738780
[Epoch 47; Iter   106/  209] train: loss: 0.0351917
[Epoch 47; Iter   136/  209] train: loss: 0.1076994
[Epoch 30; Iter    89/  209] train: loss: 0.1411021
[Epoch 30; Iter   119/  209] train: loss: 0.1429692
[Epoch 30; Iter   149/  209] train: loss: 0.2202423
[Epoch 30; Iter   179/  209] train: loss: 0.1364075
[Epoch 30; Iter   209/  209] train: loss: 0.2331787
[Epoch 30] ogbg-moltox21: 0.710549 val loss: 0.351625
[Epoch 30] ogbg-moltox21: 0.661466 test loss: 0.373296
[Epoch 31; Iter    30/  209] train: loss: 0.1355788
[Epoch 31; Iter    60/  209] train: loss: 0.1473362
[Epoch 31; Iter    90/  209] train: loss: 0.1620787
[Epoch 31; Iter   120/  209] train: loss: 0.1099953
[Epoch 31; Iter   150/  209] train: loss: 0.1238843
[Epoch 31; Iter   180/  209] train: loss: 0.2090684
[Epoch 31] ogbg-moltox21: 0.687891 val loss: 0.389867
[Epoch 31] ogbg-moltox21: 0.646283 test loss: 0.421366
[Epoch 32; Iter     1/  209] train: loss: 0.2043949
[Epoch 32; Iter    31/  209] train: loss: 0.1313586
[Epoch 32; Iter    61/  209] train: loss: 0.0755384
[Epoch 32; Iter    91/  209] train: loss: 0.1785326
[Epoch 32; Iter   121/  209] train: loss: 0.1397228
[Epoch 32; Iter   151/  209] train: loss: 0.2201934
[Epoch 32; Iter   181/  209] train: loss: 0.1693076
[Epoch 32] ogbg-moltox21: 0.721917 val loss: 0.373416
[Epoch 32] ogbg-moltox21: 0.683645 test loss: 0.397030
[Epoch 33; Iter     2/  209] train: loss: 0.0941374
[Epoch 33; Iter    32/  209] train: loss: 0.0968672
[Epoch 33; Iter    62/  209] train: loss: 0.1307015
[Epoch 33; Iter    92/  209] train: loss: 0.1192033
[Epoch 33; Iter   122/  209] train: loss: 0.1277133
[Epoch 33; Iter   152/  209] train: loss: 0.2219966
[Epoch 33; Iter   182/  209] train: loss: 0.2015533
[Epoch 33] ogbg-moltox21: 0.684483 val loss: 0.382044
[Epoch 33] ogbg-moltox21: 0.648802 test loss: 0.408377
[Epoch 34; Iter     3/  209] train: loss: 0.0882502
[Epoch 34; Iter    33/  209] train: loss: 0.1592180
[Epoch 34; Iter    63/  209] train: loss: 0.1573637
[Epoch 34; Iter    93/  209] train: loss: 0.0819033
[Epoch 34; Iter   123/  209] train: loss: 0.1305030
[Epoch 34; Iter   153/  209] train: loss: 0.1136160
[Epoch 34; Iter   183/  209] train: loss: 0.1113277
[Epoch 34] ogbg-moltox21: 0.715293 val loss: 0.343775
[Epoch 34] ogbg-moltox21: 0.665201 test loss: 0.369568
[Epoch 35; Iter     4/  209] train: loss: 0.1471726
[Epoch 35; Iter    34/  209] train: loss: 0.1172962
[Epoch 35; Iter    64/  209] train: loss: 0.1315187
[Epoch 35; Iter    94/  209] train: loss: 0.1323169
[Epoch 35; Iter   124/  209] train: loss: 0.2674002
[Epoch 35; Iter   154/  209] train: loss: 0.1686242
[Epoch 35; Iter   184/  209] train: loss: 0.1876923
[Epoch 35] ogbg-moltox21: 0.700062 val loss: 3.849817
[Epoch 35] ogbg-moltox21: 0.637218 test loss: 3.363761
[Epoch 36; Iter     5/  209] train: loss: 0.1955520
[Epoch 36; Iter    35/  209] train: loss: 0.1160604
[Epoch 36; Iter    65/  209] train: loss: 0.2244791
[Epoch 36; Iter    95/  209] train: loss: 0.1312066
[Epoch 36; Iter   125/  209] train: loss: 0.2116243
[Epoch 36; Iter   155/  209] train: loss: 0.1414464
[Epoch 36; Iter   185/  209] train: loss: 0.1485224
[Epoch 36] ogbg-moltox21: 0.752966 val loss: 0.445786
[Epoch 36] ogbg-moltox21: 0.684752 test loss: 0.454316
[Epoch 37; Iter     6/  209] train: loss: 0.0811833
[Epoch 37; Iter    36/  209] train: loss: 0.1557718
[Epoch 37; Iter    66/  209] train: loss: 0.1219628
[Epoch 37; Iter    96/  209] train: loss: 0.1327688
[Epoch 37; Iter   126/  209] train: loss: 0.1117531
[Epoch 37; Iter   156/  209] train: loss: 0.0997919
[Epoch 37; Iter   186/  209] train: loss: 0.1373314
[Epoch 37] ogbg-moltox21: 0.723675 val loss: 0.448152
[Epoch 37] ogbg-moltox21: 0.671497 test loss: 0.727703
[Epoch 38; Iter     7/  209] train: loss: 0.1384643
[Epoch 38; Iter    37/  209] train: loss: 0.1338563
[Epoch 38; Iter    67/  209] train: loss: 0.1048962
[Epoch 38; Iter    97/  209] train: loss: 0.1244710
[Epoch 38; Iter   127/  209] train: loss: 0.1356667
[Epoch 38; Iter   157/  209] train: loss: 0.1348927
[Epoch 38; Iter   187/  209] train: loss: 0.1098792
[Epoch 38] ogbg-moltox21: 0.703206 val loss: 1.024866
[Epoch 38] ogbg-moltox21: 0.658765 test loss: 0.446298
[Epoch 39; Iter     8/  209] train: loss: 0.1171556
[Epoch 39; Iter    38/  209] train: loss: 0.1249579
[Epoch 39; Iter    68/  209] train: loss: 0.1245908
[Epoch 39; Iter    98/  209] train: loss: 0.1351172
[Epoch 39; Iter   128/  209] train: loss: 0.1082868
[Epoch 39; Iter   158/  209] train: loss: 0.0952091
[Epoch 39; Iter   188/  209] train: loss: 0.0937609
[Epoch 39] ogbg-moltox21: 0.705132 val loss: 0.384845
[Epoch 39] ogbg-moltox21: 0.653261 test loss: 0.409843
[Epoch 40; Iter     9/  209] train: loss: 0.1448464
[Epoch 40; Iter    39/  209] train: loss: 0.3087668
[Epoch 40; Iter    69/  209] train: loss: 0.1192013
[Epoch 40; Iter    99/  209] train: loss: 0.0913977
[Epoch 40; Iter   129/  209] train: loss: 0.1309642
[Epoch 40; Iter   159/  209] train: loss: 0.1143178
[Epoch 40; Iter   189/  209] train: loss: 0.1414064
[Epoch 40] ogbg-moltox21: 0.695774 val loss: 0.908072
[Epoch 40] ogbg-moltox21: 0.660999 test loss: 0.765832
[Epoch 41; Iter    10/  209] train: loss: 0.0820539
[Epoch 41; Iter    40/  209] train: loss: 0.0692731
[Epoch 41; Iter    70/  209] train: loss: 0.0855450
[Epoch 41; Iter   100/  209] train: loss: 0.1000518
[Epoch 41; Iter   130/  209] train: loss: 0.1397004
[Epoch 41; Iter   160/  209] train: loss: 0.1467762
[Epoch 41; Iter   190/  209] train: loss: 0.1228609
[Epoch 41] ogbg-moltox21: 0.691287 val loss: 0.481402
[Epoch 41] ogbg-moltox21: 0.647978 test loss: 0.657703
[Epoch 42; Iter    11/  209] train: loss: 0.0948900
[Epoch 42; Iter    41/  209] train: loss: 0.1453934
[Epoch 42; Iter    71/  209] train: loss: 0.0935408
[Epoch 42; Iter   101/  209] train: loss: 0.0828214
[Epoch 42; Iter   131/  209] train: loss: 0.1634469
[Epoch 42; Iter   161/  209] train: loss: 0.0819830
[Epoch 42; Iter   191/  209] train: loss: 0.1137623
[Epoch 42] ogbg-moltox21: 0.677986 val loss: 1.920040
[Epoch 42] ogbg-moltox21: 0.652373 test loss: 0.861978
[Epoch 43; Iter    12/  209] train: loss: 0.0884655
[Epoch 43; Iter    42/  209] train: loss: 0.0923011
[Epoch 43; Iter    72/  209] train: loss: 0.1175727
[Epoch 43; Iter   102/  209] train: loss: 0.1347483
[Epoch 43; Iter   132/  209] train: loss: 0.1329014
[Epoch 43; Iter   162/  209] train: loss: 0.0854614
[Epoch 43; Iter   192/  209] train: loss: 0.0947663
[Epoch 43] ogbg-moltox21: 0.688010 val loss: 0.956214
[Epoch 43] ogbg-moltox21: 0.656841 test loss: 0.623274
[Epoch 44; Iter    13/  209] train: loss: 0.1219908
[Epoch 44; Iter    43/  209] train: loss: 0.1015977
[Epoch 44; Iter    73/  209] train: loss: 0.1092539
[Epoch 44; Iter   103/  209] train: loss: 0.1142473
[Epoch 44; Iter   133/  209] train: loss: 0.0888460
[Epoch 44; Iter   163/  209] train: loss: 0.1134220
[Epoch 44; Iter   193/  209] train: loss: 0.0691578
[Epoch 44] ogbg-moltox21: 0.709980 val loss: 1.386755
[Epoch 44] ogbg-moltox21: 0.668039 test loss: 0.890006
[Epoch 45; Iter    14/  209] train: loss: 0.0948627
[Epoch 45; Iter    44/  209] train: loss: 0.1171115
[Epoch 45; Iter    74/  209] train: loss: 0.1232095
[Epoch 45; Iter   104/  209] train: loss: 0.1098651
[Epoch 45; Iter   134/  209] train: loss: 0.1646657
[Epoch 45; Iter   164/  209] train: loss: 0.0798896
[Epoch 45; Iter   194/  209] train: loss: 0.1059167
[Epoch 45] ogbg-moltox21: 0.706027 val loss: 0.475030
[Epoch 45] ogbg-moltox21: 0.657080 test loss: 0.440009
[Epoch 46; Iter    15/  209] train: loss: 0.0887663
[Epoch 46; Iter    45/  209] train: loss: 0.1118716
[Epoch 46; Iter    75/  209] train: loss: 0.1506976
[Epoch 46; Iter   105/  209] train: loss: 0.1534959
[Epoch 46; Iter   135/  209] train: loss: 0.1223357
[Epoch 46; Iter   165/  209] train: loss: 0.1092283
[Epoch 46; Iter   195/  209] train: loss: 0.1101094
[Epoch 46] ogbg-moltox21: 0.706591 val loss: 1.708077
[Epoch 46] ogbg-moltox21: 0.658745 test loss: 0.673671
[Epoch 47; Iter    16/  209] train: loss: 0.0880515
[Epoch 47; Iter    46/  209] train: loss: 0.0816891
[Epoch 47; Iter    76/  209] train: loss: 0.0941743
[Epoch 47; Iter   106/  209] train: loss: 0.1439903
[Epoch 47; Iter   136/  209] train: loss: 0.0938349
[Epoch 30; Iter    89/  209] train: loss: 0.1204173
[Epoch 30; Iter   119/  209] train: loss: 0.1419739
[Epoch 30; Iter   149/  209] train: loss: 0.2194537
[Epoch 30; Iter   179/  209] train: loss: 0.1085536
[Epoch 30; Iter   209/  209] train: loss: 0.2381056
[Epoch 30] ogbg-moltox21: 0.795233 val loss: 0.244098
[Epoch 30] ogbg-moltox21: 0.756496 test loss: 0.261037
[Epoch 31; Iter    30/  209] train: loss: 0.1524133
[Epoch 31; Iter    60/  209] train: loss: 0.1606376
[Epoch 31; Iter    90/  209] train: loss: 0.2105624
[Epoch 31; Iter   120/  209] train: loss: 0.1301809
[Epoch 31; Iter   150/  209] train: loss: 0.1217491
[Epoch 31; Iter   180/  209] train: loss: 0.1948434
[Epoch 31] ogbg-moltox21: 0.795399 val loss: 0.253900
[Epoch 31] ogbg-moltox21: 0.766261 test loss: 0.262712
[Epoch 32; Iter     1/  209] train: loss: 0.2157509
[Epoch 32; Iter    31/  209] train: loss: 0.1249959
[Epoch 32; Iter    61/  209] train: loss: 0.0781138
[Epoch 32; Iter    91/  209] train: loss: 0.1751385
[Epoch 32; Iter   121/  209] train: loss: 0.1756974
[Epoch 32; Iter   151/  209] train: loss: 0.2235030
[Epoch 32; Iter   181/  209] train: loss: 0.2164711
[Epoch 32] ogbg-moltox21: 0.795814 val loss: 0.258637
[Epoch 32] ogbg-moltox21: 0.759158 test loss: 0.268931
[Epoch 33; Iter     2/  209] train: loss: 0.1097361
[Epoch 33; Iter    32/  209] train: loss: 0.1055334
[Epoch 33; Iter    62/  209] train: loss: 0.1109224
[Epoch 33; Iter    92/  209] train: loss: 0.1182641
[Epoch 33; Iter   122/  209] train: loss: 0.1391183
[Epoch 33; Iter   152/  209] train: loss: 0.2003550
[Epoch 33; Iter   182/  209] train: loss: 0.2151695
[Epoch 33] ogbg-moltox21: 0.800515 val loss: 0.254591
[Epoch 33] ogbg-moltox21: 0.758199 test loss: 0.269087
[Epoch 34; Iter     3/  209] train: loss: 0.1177004
[Epoch 34; Iter    33/  209] train: loss: 0.1614226
[Epoch 34; Iter    63/  209] train: loss: 0.1665599
[Epoch 34; Iter    93/  209] train: loss: 0.0809343
[Epoch 34; Iter   123/  209] train: loss: 0.1656024
[Epoch 34; Iter   153/  209] train: loss: 0.1067091
[Epoch 34; Iter   183/  209] train: loss: 0.1270581
[Epoch 34] ogbg-moltox21: 0.801955 val loss: 0.260056
[Epoch 34] ogbg-moltox21: 0.763159 test loss: 0.271463
[Epoch 35; Iter     4/  209] train: loss: 0.1394024
[Epoch 35; Iter    34/  209] train: loss: 0.1145413
[Epoch 35; Iter    64/  209] train: loss: 0.1654917
[Epoch 35; Iter    94/  209] train: loss: 0.1615178
[Epoch 35; Iter   124/  209] train: loss: 0.2123194
[Epoch 35; Iter   154/  209] train: loss: 0.1494731
[Epoch 35; Iter   184/  209] train: loss: 0.1404962
[Epoch 35] ogbg-moltox21: 0.802050 val loss: 0.247197
[Epoch 35] ogbg-moltox21: 0.761460 test loss: 0.267744
[Epoch 36; Iter     5/  209] train: loss: 0.1664784
[Epoch 36; Iter    35/  209] train: loss: 0.0867794
[Epoch 36; Iter    65/  209] train: loss: 0.1908026
[Epoch 36; Iter    95/  209] train: loss: 0.1169301
[Epoch 36; Iter   125/  209] train: loss: 0.2110276
[Epoch 36; Iter   155/  209] train: loss: 0.1210045
[Epoch 36; Iter   185/  209] train: loss: 0.1601318
[Epoch 36] ogbg-moltox21: 0.800887 val loss: 0.245227
[Epoch 36] ogbg-moltox21: 0.764107 test loss: 0.263121
[Epoch 37; Iter     6/  209] train: loss: 0.0703395
[Epoch 37; Iter    36/  209] train: loss: 0.1461039
[Epoch 37; Iter    66/  209] train: loss: 0.1376460
[Epoch 37; Iter    96/  209] train: loss: 0.1608360
[Epoch 37; Iter   126/  209] train: loss: 0.0900518
[Epoch 37; Iter   156/  209] train: loss: 0.0930106
[Epoch 37; Iter   186/  209] train: loss: 0.1430732
[Epoch 37] ogbg-moltox21: 0.798271 val loss: 0.257366
[Epoch 37] ogbg-moltox21: 0.752519 test loss: 0.278101
[Epoch 38; Iter     7/  209] train: loss: 0.1131406
[Epoch 38; Iter    37/  209] train: loss: 0.1482811
[Epoch 38; Iter    67/  209] train: loss: 0.1078248
[Epoch 38; Iter    97/  209] train: loss: 0.1315212
[Epoch 38; Iter   127/  209] train: loss: 0.1495704
[Epoch 38; Iter   157/  209] train: loss: 0.1380313
[Epoch 38; Iter   187/  209] train: loss: 0.1235580
[Epoch 38] ogbg-moltox21: 0.789778 val loss: 0.253612
[Epoch 38] ogbg-moltox21: 0.761734 test loss: 0.258860
[Epoch 39; Iter     8/  209] train: loss: 0.1586883
[Epoch 39; Iter    38/  209] train: loss: 0.1554378
[Epoch 39; Iter    68/  209] train: loss: 0.1486297
[Epoch 39; Iter    98/  209] train: loss: 0.1310804
[Epoch 39; Iter   128/  209] train: loss: 0.0976393
[Epoch 39; Iter   158/  209] train: loss: 0.1142752
[Epoch 39; Iter   188/  209] train: loss: 0.0819035
[Epoch 39] ogbg-moltox21: 0.809249 val loss: 0.245658
[Epoch 39] ogbg-moltox21: 0.767423 test loss: 0.264803
[Epoch 40; Iter     9/  209] train: loss: 0.1430342
[Epoch 40; Iter    39/  209] train: loss: 0.2707099
[Epoch 40; Iter    69/  209] train: loss: 0.1001311
[Epoch 40; Iter    99/  209] train: loss: 0.1114974
[Epoch 40; Iter   129/  209] train: loss: 0.1281460
[Epoch 40; Iter   159/  209] train: loss: 0.1049683
[Epoch 40; Iter   189/  209] train: loss: 0.1522688
[Epoch 40] ogbg-moltox21: 0.805946 val loss: 0.249144
[Epoch 40] ogbg-moltox21: 0.759830 test loss: 0.265754
[Epoch 41; Iter    10/  209] train: loss: 0.1078770
[Epoch 41; Iter    40/  209] train: loss: 0.0673764
[Epoch 41; Iter    70/  209] train: loss: 0.0822587
[Epoch 41; Iter   100/  209] train: loss: 0.1183977
[Epoch 41; Iter   130/  209] train: loss: 0.1549635
[Epoch 41; Iter   160/  209] train: loss: 0.1525814
[Epoch 41; Iter   190/  209] train: loss: 0.1144472
[Epoch 41] ogbg-moltox21: 0.803308 val loss: 0.257006
[Epoch 41] ogbg-moltox21: 0.764284 test loss: 0.272053
[Epoch 42; Iter    11/  209] train: loss: 0.1080480
[Epoch 42; Iter    41/  209] train: loss: 0.1090001
[Epoch 42; Iter    71/  209] train: loss: 0.0954808
[Epoch 42; Iter   101/  209] train: loss: 0.0918555
[Epoch 42; Iter   131/  209] train: loss: 0.1514790
[Epoch 42; Iter   161/  209] train: loss: 0.0820281
[Epoch 42; Iter   191/  209] train: loss: 0.1165310
[Epoch 42] ogbg-moltox21: 0.808308 val loss: 0.247644
[Epoch 42] ogbg-moltox21: 0.763568 test loss: 0.271819
[Epoch 43; Iter    12/  209] train: loss: 0.1453538
[Epoch 43; Iter    42/  209] train: loss: 0.1292921
[Epoch 43; Iter    72/  209] train: loss: 0.1239843
[Epoch 43; Iter   102/  209] train: loss: 0.1546214
[Epoch 43; Iter   132/  209] train: loss: 0.1183863
[Epoch 43; Iter   162/  209] train: loss: 0.0960794
[Epoch 43; Iter   192/  209] train: loss: 0.1082964
[Epoch 43] ogbg-moltox21: 0.795056 val loss: 0.265824
[Epoch 43] ogbg-moltox21: 0.758642 test loss: 0.280813
[Epoch 44; Iter    13/  209] train: loss: 0.1170053
[Epoch 44; Iter    43/  209] train: loss: 0.1333231
[Epoch 44; Iter    73/  209] train: loss: 0.1176167
[Epoch 44; Iter   103/  209] train: loss: 0.0984744
[Epoch 44; Iter   133/  209] train: loss: 0.1273596
[Epoch 44; Iter   163/  209] train: loss: 0.1241008
[Epoch 44; Iter   193/  209] train: loss: 0.0834578
[Epoch 44] ogbg-moltox21: 0.799894 val loss: 0.246147
[Epoch 44] ogbg-moltox21: 0.771610 test loss: 0.265029
[Epoch 45; Iter    14/  209] train: loss: 0.1321460
[Epoch 45; Iter    44/  209] train: loss: 0.1252438
[Epoch 45; Iter    74/  209] train: loss: 0.1343251
[Epoch 45; Iter   104/  209] train: loss: 0.1300775
[Epoch 45; Iter   134/  209] train: loss: 0.1655403
[Epoch 45; Iter   164/  209] train: loss: 0.0900006
[Epoch 45; Iter   194/  209] train: loss: 0.1256823
[Epoch 45] ogbg-moltox21: 0.798946 val loss: 0.255461
[Epoch 45] ogbg-moltox21: 0.758238 test loss: 0.270695
[Epoch 46; Iter    15/  209] train: loss: 0.0772272
[Epoch 46; Iter    45/  209] train: loss: 0.1368243
[Epoch 46; Iter    75/  209] train: loss: 0.1696783
[Epoch 46; Iter   105/  209] train: loss: 0.1304964
[Epoch 46; Iter   135/  209] train: loss: 0.1416209
[Epoch 46; Iter   165/  209] train: loss: 0.0510870
[Epoch 46; Iter   195/  209] train: loss: 0.0960709
[Epoch 46] ogbg-moltox21: 0.792237 val loss: 0.256002
[Epoch 46] ogbg-moltox21: 0.766449 test loss: 0.273352
[Epoch 47; Iter    16/  209] train: loss: 0.0915676
[Epoch 47; Iter    46/  209] train: loss: 0.1069432
[Epoch 47; Iter    76/  209] train: loss: 0.1190269
[Epoch 47; Iter   106/  209] train: loss: 0.1703613
[Epoch 47; Iter   136/  209] train: loss: 0.1063238
[Epoch 30; Iter    89/  209] train: loss: 0.1999587
[Epoch 30; Iter   119/  209] train: loss: 0.1268248
[Epoch 30; Iter   149/  209] train: loss: 0.1844657
[Epoch 30; Iter   179/  209] train: loss: 0.1421059
[Epoch 30; Iter   209/  209] train: loss: 0.1182746
[Epoch 30] ogbg-moltox21: 0.793153 val loss: 0.386534
[Epoch 30] ogbg-moltox21: 0.762371 test loss: 0.562893
[Epoch 31; Iter    30/  209] train: loss: 0.1740611
[Epoch 31; Iter    60/  209] train: loss: 0.1537438
[Epoch 31; Iter    90/  209] train: loss: 0.0907548
[Epoch 31; Iter   120/  209] train: loss: 0.1350664
[Epoch 31; Iter   150/  209] train: loss: 0.1527109
[Epoch 31; Iter   180/  209] train: loss: 0.1553471
[Epoch 31] ogbg-moltox21: 0.785174 val loss: 0.261340
[Epoch 31] ogbg-moltox21: 0.766557 test loss: 0.261246
[Epoch 32; Iter     1/  209] train: loss: 0.1603509
[Epoch 32; Iter    31/  209] train: loss: 0.1959824
[Epoch 32; Iter    61/  209] train: loss: 0.1335172
[Epoch 32; Iter    91/  209] train: loss: 0.0848356
[Epoch 32; Iter   121/  209] train: loss: 0.1411153
[Epoch 32; Iter   151/  209] train: loss: 0.1062479
[Epoch 32; Iter   181/  209] train: loss: 0.1528759
[Epoch 32] ogbg-moltox21: 0.792187 val loss: 0.255646
[Epoch 32] ogbg-moltox21: 0.755009 test loss: 0.265731
[Epoch 33; Iter     2/  209] train: loss: 0.1467638
[Epoch 33; Iter    32/  209] train: loss: 0.1812045
[Epoch 33; Iter    62/  209] train: loss: 0.2115936
[Epoch 33; Iter    92/  209] train: loss: 0.1873205
[Epoch 33; Iter   122/  209] train: loss: 0.1907643
[Epoch 33; Iter   152/  209] train: loss: 0.1363278
[Epoch 33; Iter   182/  209] train: loss: 0.1257116
[Epoch 33] ogbg-moltox21: 0.779375 val loss: 0.253306
[Epoch 33] ogbg-moltox21: 0.752388 test loss: 0.271906
[Epoch 34; Iter     3/  209] train: loss: 0.1517875
[Epoch 34; Iter    33/  209] train: loss: 0.1675731
[Epoch 34; Iter    63/  209] train: loss: 0.1366692
[Epoch 34; Iter    93/  209] train: loss: 0.1699630
[Epoch 34; Iter   123/  209] train: loss: 0.1259988
[Epoch 34; Iter   153/  209] train: loss: 0.2675959
[Epoch 34; Iter   183/  209] train: loss: 0.0868953
[Epoch 34] ogbg-moltox21: 0.788121 val loss: 0.276028
[Epoch 34] ogbg-moltox21: 0.764672 test loss: 0.275517
[Epoch 35; Iter     4/  209] train: loss: 0.1725863
[Epoch 35; Iter    34/  209] train: loss: 0.1098200
[Epoch 35; Iter    64/  209] train: loss: 0.1494507
[Epoch 35; Iter    94/  209] train: loss: 0.1088970
[Epoch 35; Iter   124/  209] train: loss: 0.2822323
[Epoch 35; Iter   154/  209] train: loss: 0.1993953
[Epoch 35; Iter   184/  209] train: loss: 0.1839733
[Epoch 35] ogbg-moltox21: 0.796894 val loss: 0.256991
[Epoch 35] ogbg-moltox21: 0.773550 test loss: 0.271175
[Epoch 36; Iter     5/  209] train: loss: 0.1296431
[Epoch 36; Iter    35/  209] train: loss: 0.0912747
[Epoch 36; Iter    65/  209] train: loss: 0.1012250
[Epoch 36; Iter    95/  209] train: loss: 0.1521622
[Epoch 36; Iter   125/  209] train: loss: 0.1923140
[Epoch 36; Iter   155/  209] train: loss: 0.1539738
[Epoch 36; Iter   185/  209] train: loss: 0.1070589
[Epoch 36] ogbg-moltox21: 0.793794 val loss: 0.267839
[Epoch 36] ogbg-moltox21: 0.773685 test loss: 0.275824
[Epoch 37; Iter     6/  209] train: loss: 0.1104745
[Epoch 37; Iter    36/  209] train: loss: 0.1961766
[Epoch 37; Iter    66/  209] train: loss: 0.1292772
[Epoch 37; Iter    96/  209] train: loss: 0.1254405
[Epoch 37; Iter   126/  209] train: loss: 0.1492761
[Epoch 37; Iter   156/  209] train: loss: 0.1675043
[Epoch 37; Iter   186/  209] train: loss: 0.1593946
[Epoch 37] ogbg-moltox21: 0.770047 val loss: 0.263280
[Epoch 37] ogbg-moltox21: 0.746880 test loss: 0.302319
[Epoch 38; Iter     7/  209] train: loss: 0.1238986
[Epoch 38; Iter    37/  209] train: loss: 0.1151932
[Epoch 38; Iter    67/  209] train: loss: 0.0862154
[Epoch 38; Iter    97/  209] train: loss: 0.1577760
[Epoch 38; Iter   127/  209] train: loss: 0.2117364
[Epoch 38; Iter   157/  209] train: loss: 0.1484505
[Epoch 38; Iter   187/  209] train: loss: 0.2244484
[Epoch 38] ogbg-moltox21: 0.783528 val loss: 0.256903
[Epoch 38] ogbg-moltox21: 0.766396 test loss: 0.366273
[Epoch 39; Iter     8/  209] train: loss: 0.1090484
[Epoch 39; Iter    38/  209] train: loss: 0.1025916
[Epoch 39; Iter    68/  209] train: loss: 0.1082255
[Epoch 39; Iter    98/  209] train: loss: 0.1511852
[Epoch 39; Iter   128/  209] train: loss: 0.2111702
[Epoch 39; Iter   158/  209] train: loss: 0.1375753
[Epoch 39; Iter   188/  209] train: loss: 0.0920881
[Epoch 39] ogbg-moltox21: 0.795365 val loss: 0.256113
[Epoch 39] ogbg-moltox21: 0.750781 test loss: 0.312694
[Epoch 40; Iter     9/  209] train: loss: 0.1592321
[Epoch 40; Iter    39/  209] train: loss: 0.1546017
[Epoch 40; Iter    69/  209] train: loss: 0.1719134
[Epoch 40; Iter    99/  209] train: loss: 0.1668362
[Epoch 40; Iter   129/  209] train: loss: 0.0957161
[Epoch 40; Iter   159/  209] train: loss: 0.1618549
[Epoch 40; Iter   189/  209] train: loss: 0.1833157
[Epoch 40] ogbg-moltox21: 0.778362 val loss: 0.271745
[Epoch 40] ogbg-moltox21: 0.746227 test loss: 0.287300
[Epoch 41; Iter    10/  209] train: loss: 0.0892794
[Epoch 41; Iter    40/  209] train: loss: 0.1695425
[Epoch 41; Iter    70/  209] train: loss: 0.0587480
[Epoch 41; Iter   100/  209] train: loss: 0.1215818
[Epoch 41; Iter   130/  209] train: loss: 0.2570735
[Epoch 41; Iter   160/  209] train: loss: 0.1705706
[Epoch 41; Iter   190/  209] train: loss: 0.1946035
[Epoch 41] ogbg-moltox21: 0.794438 val loss: 0.268273
[Epoch 41] ogbg-moltox21: 0.772473 test loss: 0.279384
[Epoch 42; Iter    11/  209] train: loss: 0.1291750
[Epoch 42; Iter    41/  209] train: loss: 0.1224529
[Epoch 42; Iter    71/  209] train: loss: 0.1741104
[Epoch 42; Iter   101/  209] train: loss: 0.1420413
[Epoch 42; Iter   131/  209] train: loss: 0.1365377
[Epoch 42; Iter   161/  209] train: loss: 0.1847786
[Epoch 42; Iter   191/  209] train: loss: 0.1410648
[Epoch 42] ogbg-moltox21: 0.792436 val loss: 0.283371
[Epoch 42] ogbg-moltox21: 0.755858 test loss: 0.412176
[Epoch 43; Iter    12/  209] train: loss: 0.1123845
[Epoch 43; Iter    42/  209] train: loss: 0.1356168
[Epoch 43; Iter    72/  209] train: loss: 0.1287207
[Epoch 43; Iter   102/  209] train: loss: 0.1407801
[Epoch 43; Iter   132/  209] train: loss: 0.1282926
[Epoch 43; Iter   162/  209] train: loss: 0.0879235
[Epoch 43; Iter   192/  209] train: loss: 0.1071140
[Epoch 43] ogbg-moltox21: 0.795837 val loss: 0.256293
[Epoch 43] ogbg-moltox21: 0.758111 test loss: 0.270603
[Epoch 44; Iter    13/  209] train: loss: 0.1268871
[Epoch 44; Iter    43/  209] train: loss: 0.1314069
[Epoch 44; Iter    73/  209] train: loss: 0.0972936
[Epoch 44; Iter   103/  209] train: loss: 0.1728244
[Epoch 44; Iter   133/  209] train: loss: 0.1620009
[Epoch 44; Iter   163/  209] train: loss: 0.1435442
[Epoch 44; Iter   193/  209] train: loss: 0.1309266
[Epoch 44] ogbg-moltox21: 0.791703 val loss: 0.265221
[Epoch 44] ogbg-moltox21: 0.763290 test loss: 0.275774
[Epoch 45; Iter    14/  209] train: loss: 0.1428110
[Epoch 45; Iter    44/  209] train: loss: 0.1635941
[Epoch 45; Iter    74/  209] train: loss: 0.1457061
[Epoch 45; Iter   104/  209] train: loss: 0.1214491
[Epoch 45; Iter   134/  209] train: loss: 0.0791123
[Epoch 45; Iter   164/  209] train: loss: 0.1251635
[Epoch 45; Iter   194/  209] train: loss: 0.1109561
[Epoch 45] ogbg-moltox21: 0.794795 val loss: 0.259634
[Epoch 45] ogbg-moltox21: 0.763816 test loss: 0.277011
[Epoch 46; Iter    15/  209] train: loss: 0.1243407
[Epoch 46; Iter    45/  209] train: loss: 0.1340013
[Epoch 46; Iter    75/  209] train: loss: 0.1588737
[Epoch 46; Iter   105/  209] train: loss: 0.1352152
[Epoch 46; Iter   135/  209] train: loss: 0.1799640
[Epoch 46; Iter   165/  209] train: loss: 0.2140256
[Epoch 46; Iter   195/  209] train: loss: 0.1555436
[Epoch 46] ogbg-moltox21: 0.772560 val loss: 0.266706
[Epoch 46] ogbg-moltox21: 0.746971 test loss: 0.285686
[Epoch 47; Iter    16/  209] train: loss: 0.1088448
[Epoch 47; Iter    46/  209] train: loss: 0.0960998
[Epoch 47; Iter    76/  209] train: loss: 0.2061103
[Epoch 47; Iter   106/  209] train: loss: 0.1550465
[Epoch 47; Iter   136/  209] train: loss: 0.1636711
[Epoch 30; Iter    89/  209] train: loss: 0.1320810
[Epoch 30; Iter   119/  209] train: loss: 0.1729730
[Epoch 30; Iter   149/  209] train: loss: 0.1474979
[Epoch 30; Iter   179/  209] train: loss: 0.2091695
[Epoch 30; Iter   209/  209] train: loss: 0.1083488
[Epoch 30] ogbg-moltox21: 0.796150 val loss: 0.257675
[Epoch 30] ogbg-moltox21: 0.769876 test loss: 0.265098
[Epoch 31; Iter    30/  209] train: loss: 0.1125555
[Epoch 31; Iter    60/  209] train: loss: 0.1163426
[Epoch 31; Iter    90/  209] train: loss: 0.1409950
[Epoch 31; Iter   120/  209] train: loss: 0.1090296
[Epoch 31; Iter   150/  209] train: loss: 0.1370054
[Epoch 31; Iter   180/  209] train: loss: 0.2103376
[Epoch 31] ogbg-moltox21: 0.801628 val loss: 0.244811
[Epoch 31] ogbg-moltox21: 0.768740 test loss: 0.257637
[Epoch 32; Iter     1/  209] train: loss: 0.1785053
[Epoch 32; Iter    31/  209] train: loss: 0.0991422
[Epoch 32; Iter    61/  209] train: loss: 0.1832959
[Epoch 32; Iter    91/  209] train: loss: 0.1422776
[Epoch 32; Iter   121/  209] train: loss: 0.1830986
[Epoch 32; Iter   151/  209] train: loss: 0.1824194
[Epoch 32; Iter   181/  209] train: loss: 0.2722828
[Epoch 32] ogbg-moltox21: 0.778666 val loss: 0.253336
[Epoch 32] ogbg-moltox21: 0.755735 test loss: 0.262849
[Epoch 33; Iter     2/  209] train: loss: 0.1469774
[Epoch 33; Iter    32/  209] train: loss: 0.1115150
[Epoch 33; Iter    62/  209] train: loss: 0.1485025
[Epoch 33; Iter    92/  209] train: loss: 0.1713972
[Epoch 33; Iter   122/  209] train: loss: 0.0871587
[Epoch 33; Iter   152/  209] train: loss: 0.1194141
[Epoch 33; Iter   182/  209] train: loss: 0.1336934
[Epoch 33] ogbg-moltox21: 0.786868 val loss: 0.251538
[Epoch 33] ogbg-moltox21: 0.757128 test loss: 0.263162
[Epoch 34; Iter     3/  209] train: loss: 0.0782073
[Epoch 34; Iter    33/  209] train: loss: 0.1350100
[Epoch 34; Iter    63/  209] train: loss: 0.1477365
[Epoch 34; Iter    93/  209] train: loss: 0.1763377
[Epoch 34; Iter   123/  209] train: loss: 0.1170688
[Epoch 34; Iter   153/  209] train: loss: 0.1557883
[Epoch 34; Iter   183/  209] train: loss: 0.1048502
[Epoch 34] ogbg-moltox21: 0.785372 val loss: 0.275906
[Epoch 34] ogbg-moltox21: 0.761979 test loss: 0.275694
[Epoch 35; Iter     4/  209] train: loss: 0.1826273
[Epoch 35; Iter    34/  209] train: loss: 0.1607029
[Epoch 35; Iter    64/  209] train: loss: 0.1637430
[Epoch 35; Iter    94/  209] train: loss: 0.1403685
[Epoch 35; Iter   124/  209] train: loss: 0.1444352
[Epoch 35; Iter   154/  209] train: loss: 0.1254308
[Epoch 35; Iter   184/  209] train: loss: 0.2159191
[Epoch 35] ogbg-moltox21: 0.798326 val loss: 0.260314
[Epoch 35] ogbg-moltox21: 0.778305 test loss: 0.261202
[Epoch 36; Iter     5/  209] train: loss: 0.1465441
[Epoch 36; Iter    35/  209] train: loss: 0.1783909
[Epoch 36; Iter    65/  209] train: loss: 0.1305365
[Epoch 36; Iter    95/  209] train: loss: 0.1613137
[Epoch 36; Iter   125/  209] train: loss: 0.1833999
[Epoch 36; Iter   155/  209] train: loss: 0.1168930
[Epoch 36; Iter   185/  209] train: loss: 0.1512466
[Epoch 36] ogbg-moltox21: 0.800886 val loss: 0.268175
[Epoch 36] ogbg-moltox21: 0.769663 test loss: 0.268327
[Epoch 37; Iter     6/  209] train: loss: 0.1380917
[Epoch 37; Iter    36/  209] train: loss: 0.1654715
[Epoch 37; Iter    66/  209] train: loss: 0.1706330
[Epoch 37; Iter    96/  209] train: loss: 0.1253484
[Epoch 37; Iter   126/  209] train: loss: 0.1508552
[Epoch 37; Iter   156/  209] train: loss: 0.1361828
[Epoch 37; Iter   186/  209] train: loss: 0.1383245
[Epoch 37] ogbg-moltox21: 0.799678 val loss: 0.265469
[Epoch 37] ogbg-moltox21: 0.769252 test loss: 0.269004
[Epoch 38; Iter     7/  209] train: loss: 0.2093567
[Epoch 38; Iter    37/  209] train: loss: 0.1750972
[Epoch 38; Iter    67/  209] train: loss: 0.1062661
[Epoch 38; Iter    97/  209] train: loss: 0.1494904
[Epoch 38; Iter   127/  209] train: loss: 0.1066030
[Epoch 38; Iter   157/  209] train: loss: 0.1310335
[Epoch 38; Iter   187/  209] train: loss: 0.1229035
[Epoch 38] ogbg-moltox21: 0.790641 val loss: 0.260164
[Epoch 38] ogbg-moltox21: 0.772824 test loss: 0.269440
[Epoch 39; Iter     8/  209] train: loss: 0.1353601
[Epoch 39; Iter    38/  209] train: loss: 0.1362585
[Epoch 39; Iter    68/  209] train: loss: 0.1428386
[Epoch 39; Iter    98/  209] train: loss: 0.1309032
[Epoch 39; Iter   128/  209] train: loss: 0.1288854
[Epoch 39; Iter   158/  209] train: loss: 0.1438386
[Epoch 39; Iter   188/  209] train: loss: 0.1182626
[Epoch 39] ogbg-moltox21: 0.787253 val loss: 0.262271
[Epoch 39] ogbg-moltox21: 0.768143 test loss: 0.271242
[Epoch 40; Iter     9/  209] train: loss: 0.0977171
[Epoch 40; Iter    39/  209] train: loss: 0.0873072
[Epoch 40; Iter    69/  209] train: loss: 0.1378120
[Epoch 40; Iter    99/  209] train: loss: 0.1702583
[Epoch 40; Iter   129/  209] train: loss: 0.0768892
[Epoch 40; Iter   159/  209] train: loss: 0.1124522
[Epoch 40; Iter   189/  209] train: loss: 0.1804189
[Epoch 40] ogbg-moltox21: 0.782568 val loss: 0.254757
[Epoch 40] ogbg-moltox21: 0.757037 test loss: 0.264535
[Epoch 41; Iter    10/  209] train: loss: 0.1088021
[Epoch 41; Iter    40/  209] train: loss: 0.1558058
[Epoch 41; Iter    70/  209] train: loss: 0.1407717
[Epoch 41; Iter   100/  209] train: loss: 0.1932145
[Epoch 41; Iter   130/  209] train: loss: 0.1316403
[Epoch 41; Iter   160/  209] train: loss: 0.1420288
[Epoch 41; Iter   190/  209] train: loss: 0.0997520
[Epoch 41] ogbg-moltox21: 0.788939 val loss: 0.254650
[Epoch 41] ogbg-moltox21: 0.770024 test loss: 0.264758
[Epoch 42; Iter    11/  209] train: loss: 0.1348405
[Epoch 42; Iter    41/  209] train: loss: 0.0893852
[Epoch 42; Iter    71/  209] train: loss: 0.1017821
[Epoch 42; Iter   101/  209] train: loss: 0.1740012
[Epoch 42; Iter   131/  209] train: loss: 0.1620812
[Epoch 42; Iter   161/  209] train: loss: 0.0984027
[Epoch 42; Iter   191/  209] train: loss: 0.0578358
[Epoch 42] ogbg-moltox21: 0.795501 val loss: 0.256781
[Epoch 42] ogbg-moltox21: 0.768134 test loss: 0.263353
[Epoch 43; Iter    12/  209] train: loss: 0.1251548
[Epoch 43; Iter    42/  209] train: loss: 0.0973286
[Epoch 43; Iter    72/  209] train: loss: 0.2027794
[Epoch 43; Iter   102/  209] train: loss: 0.1671536
[Epoch 43; Iter   132/  209] train: loss: 0.1422686
[Epoch 43; Iter   162/  209] train: loss: 0.1010774
[Epoch 43; Iter   192/  209] train: loss: 0.0752254
[Epoch 43] ogbg-moltox21: 0.782166 val loss: 0.257746
[Epoch 43] ogbg-moltox21: 0.760088 test loss: 0.263935
[Epoch 44; Iter    13/  209] train: loss: 0.0982410
[Epoch 44; Iter    43/  209] train: loss: 0.0742933
[Epoch 44; Iter    73/  209] train: loss: 0.0819034
[Epoch 44; Iter   103/  209] train: loss: 0.2178338
[Epoch 44; Iter   133/  209] train: loss: 0.1485482
[Epoch 44; Iter   163/  209] train: loss: 0.0979978
[Epoch 44; Iter   193/  209] train: loss: 0.1116183
[Epoch 44] ogbg-moltox21: 0.792468 val loss: 0.266802
[Epoch 44] ogbg-moltox21: 0.764979 test loss: 0.271766
[Epoch 45; Iter    14/  209] train: loss: 0.1146995
[Epoch 45; Iter    44/  209] train: loss: 0.1146479
[Epoch 45; Iter    74/  209] train: loss: 0.0937052
[Epoch 45; Iter   104/  209] train: loss: 0.1167490
[Epoch 45; Iter   134/  209] train: loss: 0.1552395
[Epoch 45; Iter   164/  209] train: loss: 0.1091603
[Epoch 45; Iter   194/  209] train: loss: 0.1549355
[Epoch 45] ogbg-moltox21: 0.780138 val loss: 0.264979
[Epoch 45] ogbg-moltox21: 0.754580 test loss: 0.273154
[Epoch 46; Iter    15/  209] train: loss: 0.0804512
[Epoch 46; Iter    45/  209] train: loss: 0.1435557
[Epoch 46; Iter    75/  209] train: loss: 0.1025366
[Epoch 46; Iter   105/  209] train: loss: 0.0895266
[Epoch 46; Iter   135/  209] train: loss: 0.1514718
[Epoch 46; Iter   165/  209] train: loss: 0.0765125
[Epoch 46; Iter   195/  209] train: loss: 0.1556156
[Epoch 46] ogbg-moltox21: 0.791402 val loss: 0.262466
[Epoch 46] ogbg-moltox21: 0.761253 test loss: 0.272336
[Epoch 47; Iter    16/  209] train: loss: 0.0971622
[Epoch 47; Iter    46/  209] train: loss: 0.0912149
[Epoch 47; Iter    76/  209] train: loss: 0.1094168
[Epoch 47; Iter   106/  209] train: loss: 0.0811718
[Epoch 47; Iter   136/  209] train: loss: 0.1338756
[Epoch 47; Iter   166/  209] train: loss: 0.0813294
[Epoch 47; Iter   196/  209] train: loss: 0.0825705
[Epoch 47] ogbg-moltox21: 0.751791 val loss: 0.339698
[Epoch 47] ogbg-moltox21: 0.725667 test loss: 0.358529
[Epoch 48; Iter    17/  209] train: loss: 0.1028603
[Epoch 48; Iter    47/  209] train: loss: 0.0728278
[Epoch 48; Iter    77/  209] train: loss: 0.1067190
[Epoch 48; Iter   107/  209] train: loss: 0.0827937
[Epoch 48; Iter   137/  209] train: loss: 0.0774548
[Epoch 48; Iter   167/  209] train: loss: 0.0864041
[Epoch 48; Iter   197/  209] train: loss: 0.0720040
[Epoch 48] ogbg-moltox21: 0.760849 val loss: 0.336025
[Epoch 48] ogbg-moltox21: 0.731384 test loss: 0.352230
[Epoch 49; Iter    18/  209] train: loss: 0.0762472
[Epoch 49; Iter    48/  209] train: loss: 0.0644425
[Epoch 49; Iter    78/  209] train: loss: 0.0759244
[Epoch 49; Iter   108/  209] train: loss: 0.0487384
[Epoch 49; Iter   138/  209] train: loss: 0.0920137
[Epoch 49; Iter   168/  209] train: loss: 0.0986804
[Epoch 49; Iter   198/  209] train: loss: 0.0775587
[Epoch 49] ogbg-moltox21: 0.751395 val loss: 0.345170
[Epoch 49] ogbg-moltox21: 0.729188 test loss: 0.357835
[Epoch 50; Iter    19/  209] train: loss: 0.1524369
[Epoch 50; Iter    49/  209] train: loss: 0.0608425
[Epoch 50; Iter    79/  209] train: loss: 0.0864221
[Epoch 50; Iter   109/  209] train: loss: 0.0783037
[Epoch 50; Iter   139/  209] train: loss: 0.0733432
[Epoch 50; Iter   169/  209] train: loss: 0.0609354
[Epoch 50; Iter   199/  209] train: loss: 0.0407146
[Epoch 50] ogbg-moltox21: 0.758982 val loss: 0.357645
[Epoch 50] ogbg-moltox21: 0.740241 test loss: 0.363138
[Epoch 51; Iter    20/  209] train: loss: 0.0815753
[Epoch 51; Iter    50/  209] train: loss: 0.0723673
[Epoch 51; Iter    80/  209] train: loss: 0.0337613
[Epoch 51; Iter   110/  209] train: loss: 0.0593915
[Epoch 51; Iter   140/  209] train: loss: 0.0973645
[Epoch 51; Iter   170/  209] train: loss: 0.0632807
[Epoch 51; Iter   200/  209] train: loss: 0.0937971
[Epoch 51] ogbg-moltox21: 0.763423 val loss: 0.365235
[Epoch 51] ogbg-moltox21: 0.747097 test loss: 0.381524
[Epoch 52; Iter    21/  209] train: loss: 0.0781177
[Epoch 52; Iter    51/  209] train: loss: 0.0701262
[Epoch 52; Iter    81/  209] train: loss: 0.0876307
[Epoch 52; Iter   111/  209] train: loss: 0.1354627
[Epoch 52; Iter   141/  209] train: loss: 0.0821760
[Epoch 52; Iter   171/  209] train: loss: 0.0745588
[Epoch 52; Iter   201/  209] train: loss: 0.0745642
[Epoch 52] ogbg-moltox21: 0.762559 val loss: 0.360099
[Epoch 52] ogbg-moltox21: 0.742122 test loss: 0.371828
[Epoch 53; Iter    22/  209] train: loss: 0.0899309
[Epoch 53; Iter    52/  209] train: loss: 0.0708202
[Epoch 53; Iter    82/  209] train: loss: 0.1038784
[Epoch 53; Iter   112/  209] train: loss: 0.0686044
[Epoch 53; Iter   142/  209] train: loss: 0.0470134
[Epoch 53; Iter   172/  209] train: loss: 0.0650192
[Epoch 53; Iter   202/  209] train: loss: 0.0689854
[Epoch 53] ogbg-moltox21: 0.746203 val loss: 0.362016
[Epoch 53] ogbg-moltox21: 0.734827 test loss: 0.361735
[Epoch 54; Iter    23/  209] train: loss: 0.0561352
[Epoch 54; Iter    53/  209] train: loss: 0.0661210
[Epoch 54; Iter    83/  209] train: loss: 0.0581253
[Epoch 54; Iter   113/  209] train: loss: 0.0716382
[Epoch 54; Iter   143/  209] train: loss: 0.0870527
[Epoch 54; Iter   173/  209] train: loss: 0.1126953
[Epoch 54; Iter   203/  209] train: loss: 0.0749198
[Epoch 54] ogbg-moltox21: 0.756156 val loss: 0.357002
[Epoch 54] ogbg-moltox21: 0.737385 test loss: 0.358200
[Epoch 55; Iter    24/  209] train: loss: 0.0862026
[Epoch 55; Iter    54/  209] train: loss: 0.0929457
[Epoch 55; Iter    84/  209] train: loss: 0.0747009
[Epoch 55; Iter   114/  209] train: loss: 0.0820640
[Epoch 55; Iter   144/  209] train: loss: 0.0816438
[Epoch 55; Iter   174/  209] train: loss: 0.0688615
[Epoch 55; Iter   204/  209] train: loss: 0.0507456
[Epoch 55] ogbg-moltox21: 0.746239 val loss: 0.373614
[Epoch 55] ogbg-moltox21: 0.719227 test loss: 0.387567
[Epoch 56; Iter    25/  209] train: loss: 0.0739884
[Epoch 56; Iter    55/  209] train: loss: 0.0676768
[Epoch 56; Iter    85/  209] train: loss: 0.0615542
[Epoch 56; Iter   115/  209] train: loss: 0.0320070
[Epoch 56; Iter   145/  209] train: loss: 0.0924487
[Epoch 56; Iter   175/  209] train: loss: 0.0724591
[Epoch 56; Iter   205/  209] train: loss: 0.0600679
[Epoch 56] ogbg-moltox21: 0.753374 val loss: 0.380033
[Epoch 56] ogbg-moltox21: 0.731869 test loss: 0.379137
[Epoch 57; Iter    26/  209] train: loss: 0.0636938
[Epoch 57; Iter    56/  209] train: loss: 0.0715610
[Epoch 57; Iter    86/  209] train: loss: 0.1054642
[Epoch 57; Iter   116/  209] train: loss: 0.0411346
[Epoch 57; Iter   146/  209] train: loss: 0.0502517
[Epoch 57; Iter   176/  209] train: loss: 0.1015920
[Epoch 57; Iter   206/  209] train: loss: 0.0760749
[Epoch 57] ogbg-moltox21: 0.765668 val loss: 0.383398
[Epoch 57] ogbg-moltox21: 0.738979 test loss: 0.393886
[Epoch 58; Iter    27/  209] train: loss: 0.0379127
[Epoch 58; Iter    57/  209] train: loss: 0.0289412
[Epoch 58; Iter    87/  209] train: loss: 0.1031463
[Epoch 58; Iter   117/  209] train: loss: 0.0373812
[Epoch 58; Iter   147/  209] train: loss: 0.0416362
[Epoch 58; Iter   177/  209] train: loss: 0.0487404
[Epoch 58; Iter   207/  209] train: loss: 0.0506589
[Epoch 58] ogbg-moltox21: 0.759266 val loss: 0.406099
[Epoch 58] ogbg-moltox21: 0.732762 test loss: 0.412410
[Epoch 59; Iter    28/  209] train: loss: 0.0843759
[Epoch 59; Iter    58/  209] train: loss: 0.0849969
[Epoch 59; Iter    88/  209] train: loss: 0.0691089
[Epoch 59; Iter   118/  209] train: loss: 0.0546619
[Epoch 59; Iter   148/  209] train: loss: 0.0755992
[Epoch 59; Iter   178/  209] train: loss: 0.0798240
[Epoch 59; Iter   208/  209] train: loss: 0.1092382
[Epoch 59] ogbg-moltox21: 0.743033 val loss: 0.402603
[Epoch 59] ogbg-moltox21: 0.733960 test loss: 0.406045
[Epoch 60; Iter    29/  209] train: loss: 0.0471563
[Epoch 60; Iter    59/  209] train: loss: 0.0536348
[Epoch 60; Iter    89/  209] train: loss: 0.0428172
[Epoch 60; Iter   119/  209] train: loss: 0.0438435
[Epoch 60; Iter   149/  209] train: loss: 0.0496407
[Epoch 60; Iter   179/  209] train: loss: 0.0571438
[Epoch 60; Iter   209/  209] train: loss: 0.0826806
[Epoch 60] ogbg-moltox21: 0.747713 val loss: 0.420857
[Epoch 60] ogbg-moltox21: 0.732180 test loss: 0.433154
[Epoch 61; Iter    30/  209] train: loss: 0.0591573
[Epoch 61; Iter    60/  209] train: loss: 0.0598409
[Epoch 61; Iter    90/  209] train: loss: 0.0305554
[Epoch 61; Iter   120/  209] train: loss: 0.0420243
[Epoch 61; Iter   150/  209] train: loss: 0.0816301
[Epoch 61; Iter   180/  209] train: loss: 0.0703084
[Epoch 61] ogbg-moltox21: 0.758342 val loss: 0.410698
[Epoch 61] ogbg-moltox21: 0.741820 test loss: 0.399464
[Epoch 62; Iter     1/  209] train: loss: 0.0625601
[Epoch 62; Iter    31/  209] train: loss: 0.0597653
[Epoch 62; Iter    61/  209] train: loss: 0.0362931
[Epoch 62; Iter    91/  209] train: loss: 0.0554889
[Epoch 62; Iter   121/  209] train: loss: 0.0546727
[Epoch 62; Iter   151/  209] train: loss: 0.0817227
[Epoch 62; Iter   181/  209] train: loss: 0.0666649
[Epoch 62] ogbg-moltox21: 0.756718 val loss: 0.415453
[Epoch 62] ogbg-moltox21: 0.723810 test loss: 0.427961
[Epoch 63; Iter     2/  209] train: loss: 0.0713174
[Epoch 63; Iter    32/  209] train: loss: 0.1672255
[Epoch 63; Iter    62/  209] train: loss: 0.0593158
[Epoch 63; Iter    92/  209] train: loss: 0.0625310
[Epoch 63; Iter   122/  209] train: loss: 0.0649891
[Epoch 63; Iter   152/  209] train: loss: 0.0503766
[Epoch 63; Iter   182/  209] train: loss: 0.0482373
[Epoch 63] ogbg-moltox21: 0.751374 val loss: 0.441874
[Epoch 63] ogbg-moltox21: 0.742898 test loss: 0.425650
[Epoch 64; Iter     3/  209] train: loss: 0.0336983
[Epoch 64; Iter    33/  209] train: loss: 0.0473143
[Epoch 64; Iter    63/  209] train: loss: 0.0611790
[Epoch 64; Iter    93/  209] train: loss: 0.0616305
[Epoch 64; Iter   123/  209] train: loss: 0.0845184
[Epoch 64; Iter   153/  209] train: loss: 0.0865288
[Epoch 64; Iter   183/  209] train: loss: 0.0528306
[Epoch 64] ogbg-moltox21: 0.757430 val loss: 0.434912
[Epoch 47; Iter   166/  209] train: loss: 0.0555236
[Epoch 47; Iter   196/  209] train: loss: 0.0970749
[Epoch 47] ogbg-moltox21: 0.759778 val loss: 0.366806
[Epoch 47] ogbg-moltox21: 0.736074 test loss: 0.385035
[Epoch 48; Iter    17/  209] train: loss: 0.0604141
[Epoch 48; Iter    47/  209] train: loss: 0.1257690
[Epoch 48; Iter    77/  209] train: loss: 0.0586212
[Epoch 48; Iter   107/  209] train: loss: 0.0492439
[Epoch 48; Iter   137/  209] train: loss: 0.0861078
[Epoch 48; Iter   167/  209] train: loss: 0.0975728
[Epoch 48; Iter   197/  209] train: loss: 0.0396060
[Epoch 48] ogbg-moltox21: 0.753260 val loss: 0.436858
[Epoch 48] ogbg-moltox21: 0.736285 test loss: 0.428643
[Epoch 49; Iter    18/  209] train: loss: 0.0348371
[Epoch 49; Iter    48/  209] train: loss: 0.0692901
[Epoch 49; Iter    78/  209] train: loss: 0.0797529
[Epoch 49; Iter   108/  209] train: loss: 0.1042121
[Epoch 49; Iter   138/  209] train: loss: 0.0758195
[Epoch 49; Iter   168/  209] train: loss: 0.0731033
[Epoch 49; Iter   198/  209] train: loss: 0.0971572
[Epoch 49] ogbg-moltox21: 0.741760 val loss: 0.429979
[Epoch 49] ogbg-moltox21: 0.715036 test loss: 0.444859
[Epoch 50; Iter    19/  209] train: loss: 0.0409211
[Epoch 50; Iter    49/  209] train: loss: 0.0652519
[Epoch 50; Iter    79/  209] train: loss: 0.0616059
[Epoch 50; Iter   109/  209] train: loss: 0.0578862
[Epoch 50; Iter   139/  209] train: loss: 0.0784170
[Epoch 50; Iter   169/  209] train: loss: 0.0461141
[Epoch 50; Iter   199/  209] train: loss: 0.0927695
[Epoch 50] ogbg-moltox21: 0.751247 val loss: 0.459764
[Epoch 50] ogbg-moltox21: 0.723410 test loss: 0.488694
[Epoch 51; Iter    20/  209] train: loss: 0.0673456
[Epoch 51; Iter    50/  209] train: loss: 0.0561808
[Epoch 51; Iter    80/  209] train: loss: 0.0407103
[Epoch 51; Iter   110/  209] train: loss: 0.0620513
[Epoch 51; Iter   140/  209] train: loss: 0.0902773
[Epoch 51; Iter   170/  209] train: loss: 0.0822785
[Epoch 51; Iter   200/  209] train: loss: 0.1024774
[Epoch 51] ogbg-moltox21: 0.731038 val loss: 0.417585
[Epoch 51] ogbg-moltox21: 0.713320 test loss: 0.419914
[Epoch 52; Iter    21/  209] train: loss: 0.0373506
[Epoch 52; Iter    51/  209] train: loss: 0.0786930
[Epoch 52; Iter    81/  209] train: loss: 0.0555124
[Epoch 52; Iter   111/  209] train: loss: 0.0685479
[Epoch 52; Iter   141/  209] train: loss: 0.0387800
[Epoch 52; Iter   171/  209] train: loss: 0.0774009
[Epoch 52; Iter   201/  209] train: loss: 0.0620948
[Epoch 52] ogbg-moltox21: 0.726134 val loss: 0.406123
[Epoch 52] ogbg-moltox21: 0.721103 test loss: 0.417473
[Epoch 53; Iter    22/  209] train: loss: 0.0712941
[Epoch 53; Iter    52/  209] train: loss: 0.0927695
[Epoch 53; Iter    82/  209] train: loss: 0.0297646
[Epoch 53; Iter   112/  209] train: loss: 0.1094924
[Epoch 53; Iter   142/  209] train: loss: 0.0642624
[Epoch 53; Iter   172/  209] train: loss: 0.0437182
[Epoch 53; Iter   202/  209] train: loss: 0.0836272
[Epoch 53] ogbg-moltox21: 0.728996 val loss: 0.453790
[Epoch 53] ogbg-moltox21: 0.714509 test loss: 0.443670
[Epoch 54; Iter    23/  209] train: loss: 0.0765803
[Epoch 54; Iter    53/  209] train: loss: 0.0399779
[Epoch 54; Iter    83/  209] train: loss: 0.0517011
[Epoch 54; Iter   113/  209] train: loss: 0.0446595
[Epoch 54; Iter   143/  209] train: loss: 0.0905705
[Epoch 54; Iter   173/  209] train: loss: 0.0732899
[Epoch 54; Iter   203/  209] train: loss: 0.0649382
[Epoch 54] ogbg-moltox21: 0.756674 val loss: 0.448003
[Epoch 54] ogbg-moltox21: 0.726243 test loss: 0.459890
[Epoch 55; Iter    24/  209] train: loss: 0.0541165
[Epoch 55; Iter    54/  209] train: loss: 0.0497238
[Epoch 55; Iter    84/  209] train: loss: 0.0556231
[Epoch 55; Iter   114/  209] train: loss: 0.0671904
[Epoch 55; Iter   144/  209] train: loss: 0.0621316
[Epoch 55; Iter   174/  209] train: loss: 0.0526799
[Epoch 55; Iter   204/  209] train: loss: 0.0353530
[Epoch 55] ogbg-moltox21: 0.754760 val loss: 0.447235
[Epoch 55] ogbg-moltox21: 0.725578 test loss: 0.448369
[Epoch 56; Iter    25/  209] train: loss: 0.0793505
[Epoch 56; Iter    55/  209] train: loss: 0.0776806
[Epoch 56; Iter    85/  209] train: loss: 0.0544654
[Epoch 56; Iter   115/  209] train: loss: 0.0385472
[Epoch 56; Iter   145/  209] train: loss: 0.0503609
[Epoch 56; Iter   175/  209] train: loss: 0.0511954
[Epoch 56; Iter   205/  209] train: loss: 0.0744787
[Epoch 56] ogbg-moltox21: 0.751630 val loss: 0.449368
[Epoch 56] ogbg-moltox21: 0.725069 test loss: 0.468708
[Epoch 57; Iter    26/  209] train: loss: 0.0392911
[Epoch 57; Iter    56/  209] train: loss: 0.0526387
[Epoch 57; Iter    86/  209] train: loss: 0.0955157
[Epoch 57; Iter   116/  209] train: loss: 0.0642098
[Epoch 57; Iter   146/  209] train: loss: 0.0623747
[Epoch 57; Iter   176/  209] train: loss: 0.0431016
[Epoch 57; Iter   206/  209] train: loss: 0.0661683
[Epoch 57] ogbg-moltox21: 0.735371 val loss: 0.488371
[Epoch 57] ogbg-moltox21: 0.726103 test loss: 0.493517
[Epoch 58; Iter    27/  209] train: loss: 0.0450216
[Epoch 58; Iter    57/  209] train: loss: 0.0424156
[Epoch 58; Iter    87/  209] train: loss: 0.0618018
[Epoch 58; Iter   117/  209] train: loss: 0.0481872
[Epoch 58; Iter   147/  209] train: loss: 0.0692651
[Epoch 58; Iter   177/  209] train: loss: 0.0368859
[Epoch 58; Iter   207/  209] train: loss: 0.0447897
[Epoch 58] ogbg-moltox21: 0.745939 val loss: 0.460310
[Epoch 58] ogbg-moltox21: 0.716007 test loss: 0.534897
[Epoch 59; Iter    28/  209] train: loss: 0.0527251
[Epoch 59; Iter    58/  209] train: loss: 0.0494457
[Epoch 59; Iter    88/  209] train: loss: 0.0841244
[Epoch 59; Iter   118/  209] train: loss: 0.0586892
[Epoch 59; Iter   148/  209] train: loss: 0.0794341
[Epoch 59; Iter   178/  209] train: loss: 0.0402621
[Epoch 59; Iter   208/  209] train: loss: 0.0633539
[Epoch 59] ogbg-moltox21: 0.736013 val loss: 0.715194
[Epoch 59] ogbg-moltox21: 0.717118 test loss: 0.739127
[Epoch 60; Iter    29/  209] train: loss: 0.0595572
[Epoch 60; Iter    59/  209] train: loss: 0.0545280
[Epoch 60; Iter    89/  209] train: loss: 0.0423377
[Epoch 60; Iter   119/  209] train: loss: 0.0543610
[Epoch 60; Iter   149/  209] train: loss: 0.0553886
[Epoch 60; Iter   179/  209] train: loss: 0.1198711
[Epoch 60; Iter   209/  209] train: loss: 0.0557108
[Epoch 60] ogbg-moltox21: 0.720650 val loss: 0.519297
[Epoch 60] ogbg-moltox21: 0.716822 test loss: 0.599576
[Epoch 61; Iter    30/  209] train: loss: 0.0411955
[Epoch 61; Iter    60/  209] train: loss: 0.0459338
[Epoch 61; Iter    90/  209] train: loss: 0.0611794
[Epoch 61; Iter   120/  209] train: loss: 0.0513607
[Epoch 61; Iter   150/  209] train: loss: 0.0554362
[Epoch 61; Iter   180/  209] train: loss: 0.0519364
[Epoch 61] ogbg-moltox21: 0.718584 val loss: 0.528709
[Epoch 61] ogbg-moltox21: 0.702473 test loss: 0.533196
[Epoch 62; Iter     1/  209] train: loss: 0.0184545
[Epoch 62; Iter    31/  209] train: loss: 0.0443323
[Epoch 62; Iter    61/  209] train: loss: 0.0397711
[Epoch 62; Iter    91/  209] train: loss: 0.0462734
[Epoch 62; Iter   121/  209] train: loss: 0.0597390
[Epoch 62; Iter   151/  209] train: loss: 0.0368652
[Epoch 62; Iter   181/  209] train: loss: 0.0386640
[Epoch 62] ogbg-moltox21: 0.724904 val loss: 0.513512
[Epoch 62] ogbg-moltox21: 0.711406 test loss: 0.529957
[Epoch 63; Iter     2/  209] train: loss: 0.0319504
[Epoch 63; Iter    32/  209] train: loss: 0.0526810
[Epoch 63; Iter    62/  209] train: loss: 0.0482913
[Epoch 63; Iter    92/  209] train: loss: 0.0398644
[Epoch 63; Iter   122/  209] train: loss: 0.0498816
[Epoch 63; Iter   152/  209] train: loss: 0.0509523
[Epoch 63; Iter   182/  209] train: loss: 0.0726505
[Epoch 63] ogbg-moltox21: 0.727032 val loss: 0.596717
[Epoch 63] ogbg-moltox21: 0.699722 test loss: 0.694405
[Epoch 64; Iter     3/  209] train: loss: 0.0378879
[Epoch 64; Iter    33/  209] train: loss: 0.0520766
[Epoch 64; Iter    63/  209] train: loss: 0.0351162
[Epoch 64; Iter    93/  209] train: loss: 0.0405398
[Epoch 64; Iter   123/  209] train: loss: 0.0881648
[Epoch 64; Iter   153/  209] train: loss: 0.0485097
[Epoch 64; Iter   183/  209] train: loss: 0.0463616
[Epoch 64] ogbg-moltox21: 0.733027 val loss: 0.516786
[Epoch 47; Iter   166/  209] train: loss: 0.0676422
[Epoch 47; Iter   196/  209] train: loss: 0.0637967
[Epoch 47] ogbg-moltox21: 0.747347 val loss: 0.439067
[Epoch 47] ogbg-moltox21: 0.729845 test loss: 0.481404
[Epoch 48; Iter    17/  209] train: loss: 0.0480823
[Epoch 48; Iter    47/  209] train: loss: 0.0282975
[Epoch 48; Iter    77/  209] train: loss: 0.0653578
[Epoch 48; Iter   107/  209] train: loss: 0.0676790
[Epoch 48; Iter   137/  209] train: loss: 0.0811556
[Epoch 48; Iter   167/  209] train: loss: 0.0815798
[Epoch 48; Iter   197/  209] train: loss: 0.0582226
[Epoch 48] ogbg-moltox21: 0.733605 val loss: 0.417055
[Epoch 48] ogbg-moltox21: 0.726991 test loss: 0.438555
[Epoch 49; Iter    18/  209] train: loss: 0.0962841
[Epoch 49; Iter    48/  209] train: loss: 0.0830411
[Epoch 49; Iter    78/  209] train: loss: 0.0483090
[Epoch 49; Iter   108/  209] train: loss: 0.0281418
[Epoch 49; Iter   138/  209] train: loss: 0.0907030
[Epoch 49; Iter   168/  209] train: loss: 0.0667798
[Epoch 49; Iter   198/  209] train: loss: 0.0424841
[Epoch 49] ogbg-moltox21: 0.746462 val loss: 0.441778
[Epoch 49] ogbg-moltox21: 0.728971 test loss: 0.463153
[Epoch 50; Iter    19/  209] train: loss: 0.0468782
[Epoch 50; Iter    49/  209] train: loss: 0.0298085
[Epoch 50; Iter    79/  209] train: loss: 0.0530220
[Epoch 50; Iter   109/  209] train: loss: 0.0545023
[Epoch 50; Iter   139/  209] train: loss: 0.0552378
[Epoch 50; Iter   169/  209] train: loss: 0.0389885
[Epoch 50; Iter   199/  209] train: loss: 0.0640896
[Epoch 50] ogbg-moltox21: 0.739567 val loss: 0.438962
[Epoch 50] ogbg-moltox21: 0.721918 test loss: 0.475034
[Epoch 51; Iter    20/  209] train: loss: 0.0710520
[Epoch 51; Iter    50/  209] train: loss: 0.0369464
[Epoch 51; Iter    80/  209] train: loss: 0.0416716
[Epoch 51; Iter   110/  209] train: loss: 0.0589099
[Epoch 51; Iter   140/  209] train: loss: 0.0693136
[Epoch 51; Iter   170/  209] train: loss: 0.0384456
[Epoch 51; Iter   200/  209] train: loss: 0.0265278
[Epoch 51] ogbg-moltox21: 0.736502 val loss: 0.475154
[Epoch 51] ogbg-moltox21: 0.723793 test loss: 0.503533
[Epoch 52; Iter    21/  209] train: loss: 0.0856043
[Epoch 52; Iter    51/  209] train: loss: 0.0414691
[Epoch 52; Iter    81/  209] train: loss: 0.0329085
[Epoch 52; Iter   111/  209] train: loss: 0.0655438
[Epoch 52; Iter   141/  209] train: loss: 0.0344952
[Epoch 52; Iter   171/  209] train: loss: 0.0378482
[Epoch 52; Iter   201/  209] train: loss: 0.1092436
[Epoch 52] ogbg-moltox21: 0.743051 val loss: 0.499166
[Epoch 52] ogbg-moltox21: 0.728122 test loss: 0.529647
[Epoch 53; Iter    22/  209] train: loss: 0.0354540
[Epoch 53; Iter    52/  209] train: loss: 0.0351496
[Epoch 53; Iter    82/  209] train: loss: 0.0626296
[Epoch 53; Iter   112/  209] train: loss: 0.0348136
[Epoch 53; Iter   142/  209] train: loss: 0.0662054
[Epoch 53; Iter   172/  209] train: loss: 0.0637093
[Epoch 53; Iter   202/  209] train: loss: 0.1026874
[Epoch 53] ogbg-moltox21: 0.745535 val loss: 0.469661
[Epoch 53] ogbg-moltox21: 0.724091 test loss: 0.512731
[Epoch 54; Iter    23/  209] train: loss: 0.0500201
[Epoch 54; Iter    53/  209] train: loss: 0.0222357
[Epoch 54; Iter    83/  209] train: loss: 0.0410733
[Epoch 54; Iter   113/  209] train: loss: 0.0482843
[Epoch 54; Iter   143/  209] train: loss: 0.0574929
[Epoch 54; Iter   173/  209] train: loss: 0.0790445
[Epoch 54; Iter   203/  209] train: loss: 0.0510531
[Epoch 54] ogbg-moltox21: 0.747951 val loss: 0.459418
[Epoch 54] ogbg-moltox21: 0.713617 test loss: 0.510390
[Epoch 55; Iter    24/  209] train: loss: 0.0383140
[Epoch 55; Iter    54/  209] train: loss: 0.0358416
[Epoch 55; Iter    84/  209] train: loss: 0.0415018
[Epoch 55; Iter   114/  209] train: loss: 0.0523091
[Epoch 55; Iter   144/  209] train: loss: 0.0320216
[Epoch 55; Iter   174/  209] train: loss: 0.0269066
[Epoch 55; Iter   204/  209] train: loss: 0.0209060
[Epoch 55] ogbg-moltox21: 0.750505 val loss: 0.447990
[Epoch 55] ogbg-moltox21: 0.730811 test loss: 0.484478
[Epoch 56; Iter    25/  209] train: loss: 0.0621884
[Epoch 56; Iter    55/  209] train: loss: 0.0511226
[Epoch 56; Iter    85/  209] train: loss: 0.0303187
[Epoch 56; Iter   115/  209] train: loss: 0.0345982
[Epoch 56; Iter   145/  209] train: loss: 0.0235275
[Epoch 56; Iter   175/  209] train: loss: 0.0554465
[Epoch 56; Iter   205/  209] train: loss: 0.0578268
[Epoch 56] ogbg-moltox21: 0.747338 val loss: 0.476009
[Epoch 56] ogbg-moltox21: 0.721015 test loss: 0.531012
[Epoch 57; Iter    26/  209] train: loss: 0.0475943
[Epoch 57; Iter    56/  209] train: loss: 0.0760870
[Epoch 57; Iter    86/  209] train: loss: 0.0496664
[Epoch 57; Iter   116/  209] train: loss: 0.0352611
[Epoch 57; Iter   146/  209] train: loss: 0.0586473
[Epoch 57; Iter   176/  209] train: loss: 0.0326598
[Epoch 57; Iter   206/  209] train: loss: 0.0500749
[Epoch 57] ogbg-moltox21: 0.740013 val loss: 0.507841
[Epoch 57] ogbg-moltox21: 0.721123 test loss: 0.550287
[Epoch 58; Iter    27/  209] train: loss: 0.0195469
[Epoch 58; Iter    57/  209] train: loss: 0.0291051
[Epoch 58; Iter    87/  209] train: loss: 0.0280317
[Epoch 58; Iter   117/  209] train: loss: 0.0536030
[Epoch 58; Iter   147/  209] train: loss: 0.0391098
[Epoch 58; Iter   177/  209] train: loss: 0.0668220
[Epoch 58; Iter   207/  209] train: loss: 0.0345912
[Epoch 58] ogbg-moltox21: 0.740105 val loss: 0.492955
[Epoch 58] ogbg-moltox21: 0.720711 test loss: 0.532905
[Epoch 59; Iter    28/  209] train: loss: 0.0348987
[Epoch 59; Iter    58/  209] train: loss: 0.0332466
[Epoch 59; Iter    88/  209] train: loss: 0.0387182
[Epoch 59; Iter   118/  209] train: loss: 0.0241470
[Epoch 59; Iter   148/  209] train: loss: 0.0789956
[Epoch 59; Iter   178/  209] train: loss: 0.0488058
[Epoch 59; Iter   208/  209] train: loss: 0.0620483
[Epoch 59] ogbg-moltox21: 0.739212 val loss: 0.479690
[Epoch 59] ogbg-moltox21: 0.716896 test loss: 0.532410
[Epoch 60; Iter    29/  209] train: loss: 0.0286044
[Epoch 60; Iter    59/  209] train: loss: 0.0231633
[Epoch 60; Iter    89/  209] train: loss: 0.0524230
[Epoch 60; Iter   119/  209] train: loss: 0.0475501
[Epoch 60; Iter   149/  209] train: loss: 0.0231585
[Epoch 60; Iter   179/  209] train: loss: 0.0815973
[Epoch 60; Iter   209/  209] train: loss: 0.0472666
[Epoch 60] ogbg-moltox21: 0.739247 val loss: 0.509436
[Epoch 60] ogbg-moltox21: 0.716982 test loss: 0.569995
[Epoch 61; Iter    30/  209] train: loss: 0.0297629
[Epoch 61; Iter    60/  209] train: loss: 0.0367658
[Epoch 61; Iter    90/  209] train: loss: 0.0423509
[Epoch 61; Iter   120/  209] train: loss: 0.0282915
[Epoch 61; Iter   150/  209] train: loss: 0.0783006
[Epoch 61; Iter   180/  209] train: loss: 0.1161115
[Epoch 61] ogbg-moltox21: 0.737882 val loss: 0.512756
[Epoch 61] ogbg-moltox21: 0.724380 test loss: 0.565489
[Epoch 62; Iter     1/  209] train: loss: 0.0604517
[Epoch 62; Iter    31/  209] train: loss: 0.0320760
[Epoch 62; Iter    61/  209] train: loss: 0.0185423
[Epoch 62; Iter    91/  209] train: loss: 0.0623560
[Epoch 62; Iter   121/  209] train: loss: 0.0487777
[Epoch 62; Iter   151/  209] train: loss: 0.0254859
[Epoch 62; Iter   181/  209] train: loss: 0.0345363
[Epoch 62] ogbg-moltox21: 0.747619 val loss: 0.528903
[Epoch 62] ogbg-moltox21: 0.731254 test loss: 0.578654
[Epoch 63; Iter     2/  209] train: loss: 0.0198607
[Epoch 63; Iter    32/  209] train: loss: 0.0564743
[Epoch 63; Iter    62/  209] train: loss: 0.0269841
[Epoch 63; Iter    92/  209] train: loss: 0.0319962
[Epoch 63; Iter   122/  209] train: loss: 0.0160533
[Epoch 63; Iter   152/  209] train: loss: 0.0430331
[Epoch 63; Iter   182/  209] train: loss: 0.0357780
[Epoch 63] ogbg-moltox21: 0.738699 val loss: 0.532212
[Epoch 63] ogbg-moltox21: 0.722433 test loss: 0.589913
[Epoch 64; Iter     3/  209] train: loss: 0.0278529
[Epoch 64; Iter    33/  209] train: loss: 0.0269872
[Epoch 64; Iter    63/  209] train: loss: 0.0364264
[Epoch 64; Iter    93/  209] train: loss: 0.0340663
[Epoch 64; Iter   123/  209] train: loss: 0.0383507
[Epoch 64; Iter   153/  209] train: loss: 0.0508893
[Epoch 64; Iter   183/  209] train: loss: 0.1115535
[Epoch 64] ogbg-moltox21: 0.741431 val loss: 0.561639
[Epoch 47; Iter   166/  209] train: loss: 0.0621019
[Epoch 47; Iter   196/  209] train: loss: 0.1441939
[Epoch 47] ogbg-moltox21: 0.773351 val loss: 0.309604
[Epoch 47] ogbg-moltox21: 0.746566 test loss: 0.313476
[Epoch 48; Iter    17/  209] train: loss: 0.1377167
[Epoch 48; Iter    47/  209] train: loss: 0.0863108
[Epoch 48; Iter    77/  209] train: loss: 0.1182657
[Epoch 48; Iter   107/  209] train: loss: 0.1232505
[Epoch 48; Iter   137/  209] train: loss: 0.1457917
[Epoch 48; Iter   167/  209] train: loss: 0.0848980
[Epoch 48; Iter   197/  209] train: loss: 0.0948058
[Epoch 48] ogbg-moltox21: 0.762069 val loss: 0.315820
[Epoch 48] ogbg-moltox21: 0.745599 test loss: 0.318833
[Epoch 49; Iter    18/  209] train: loss: 0.1561164
[Epoch 49; Iter    48/  209] train: loss: 0.1201513
[Epoch 49; Iter    78/  209] train: loss: 0.0887039
[Epoch 49; Iter   108/  209] train: loss: 0.0761013
[Epoch 49; Iter   138/  209] train: loss: 0.1180111
[Epoch 49; Iter   168/  209] train: loss: 0.1213304
[Epoch 49; Iter   198/  209] train: loss: 0.1069907
[Epoch 49] ogbg-moltox21: 0.778757 val loss: 0.317494
[Epoch 49] ogbg-moltox21: 0.754131 test loss: 0.366946
[Epoch 50; Iter    19/  209] train: loss: 0.0911826
[Epoch 50; Iter    49/  209] train: loss: 0.0763173
[Epoch 50; Iter    79/  209] train: loss: 0.1033460
[Epoch 50; Iter   109/  209] train: loss: 0.0978850
[Epoch 50; Iter   139/  209] train: loss: 0.0935834
[Epoch 50; Iter   169/  209] train: loss: 0.0809423
[Epoch 50; Iter   199/  209] train: loss: 0.1233412
[Epoch 50] ogbg-moltox21: 0.761025 val loss: 0.321546
[Epoch 50] ogbg-moltox21: 0.741464 test loss: 0.322827
[Epoch 51; Iter    20/  209] train: loss: 0.1101912
[Epoch 51; Iter    50/  209] train: loss: 0.0830024
[Epoch 51; Iter    80/  209] train: loss: 0.0501026
[Epoch 51; Iter   110/  209] train: loss: 0.1132440
[Epoch 51; Iter   140/  209] train: loss: 0.1273523
[Epoch 51; Iter   170/  209] train: loss: 0.1220117
[Epoch 51; Iter   200/  209] train: loss: 0.0631884
[Epoch 51] ogbg-moltox21: 0.772050 val loss: 0.320578
[Epoch 51] ogbg-moltox21: 0.744278 test loss: 0.323069
[Epoch 52; Iter    21/  209] train: loss: 0.1372400
[Epoch 52; Iter    51/  209] train: loss: 0.0689613
[Epoch 52; Iter    81/  209] train: loss: 0.0737462
[Epoch 52; Iter   111/  209] train: loss: 0.0977127
[Epoch 52; Iter   141/  209] train: loss: 0.0480762
[Epoch 52; Iter   171/  209] train: loss: 0.0727624
[Epoch 52; Iter   201/  209] train: loss: 0.1332362
[Epoch 52] ogbg-moltox21: 0.771816 val loss: 0.321738
[Epoch 52] ogbg-moltox21: 0.754378 test loss: 0.325412
[Epoch 53; Iter    22/  209] train: loss: 0.0758633
[Epoch 53; Iter    52/  209] train: loss: 0.0660720
[Epoch 53; Iter    82/  209] train: loss: 0.0945472
[Epoch 53; Iter   112/  209] train: loss: 0.0732186
[Epoch 53; Iter   142/  209] train: loss: 0.0973667
[Epoch 53; Iter   172/  209] train: loss: 0.0937815
[Epoch 53; Iter   202/  209] train: loss: 0.1264031
[Epoch 53] ogbg-moltox21: 0.774141 val loss: 0.338024
[Epoch 53] ogbg-moltox21: 0.755681 test loss: 0.339564
[Epoch 54; Iter    23/  209] train: loss: 0.0812377
[Epoch 54; Iter    53/  209] train: loss: 0.0665244
[Epoch 54; Iter    83/  209] train: loss: 0.0938054
[Epoch 54; Iter   113/  209] train: loss: 0.1027121
[Epoch 54; Iter   143/  209] train: loss: 0.1173594
[Epoch 54; Iter   173/  209] train: loss: 0.1130325
[Epoch 54; Iter   203/  209] train: loss: 0.0762136
[Epoch 54] ogbg-moltox21: 0.774607 val loss: 0.336568
[Epoch 54] ogbg-moltox21: 0.745602 test loss: 0.342402
[Epoch 55; Iter    24/  209] train: loss: 0.0824183
[Epoch 55; Iter    54/  209] train: loss: 0.0727305
[Epoch 55; Iter    84/  209] train: loss: 0.0730531
[Epoch 55; Iter   114/  209] train: loss: 0.0998899
[Epoch 55; Iter   144/  209] train: loss: 0.0706680
[Epoch 55; Iter   174/  209] train: loss: 0.0578779
[Epoch 55; Iter   204/  209] train: loss: 0.0494095
[Epoch 55] ogbg-moltox21: 0.763586 val loss: 0.320024
[Epoch 55] ogbg-moltox21: 0.736498 test loss: 0.332645
[Epoch 56; Iter    25/  209] train: loss: 0.0860659
[Epoch 56; Iter    55/  209] train: loss: 0.0719136
[Epoch 56; Iter    85/  209] train: loss: 0.0732529
[Epoch 56; Iter   115/  209] train: loss: 0.0692475
[Epoch 56; Iter   145/  209] train: loss: 0.0430760
[Epoch 56; Iter   175/  209] train: loss: 0.1154891
[Epoch 56; Iter   205/  209] train: loss: 0.1000180
[Epoch 56] ogbg-moltox21: 0.774953 val loss: 0.341332
[Epoch 56] ogbg-moltox21: 0.750146 test loss: 0.349912
[Epoch 57; Iter    26/  209] train: loss: 0.1004638
[Epoch 57; Iter    56/  209] train: loss: 0.1316638
[Epoch 57; Iter    86/  209] train: loss: 0.0800506
[Epoch 57; Iter   116/  209] train: loss: 0.0822057
[Epoch 57; Iter   146/  209] train: loss: 0.0887045
[Epoch 57; Iter   176/  209] train: loss: 0.0603695
[Epoch 57; Iter   206/  209] train: loss: 0.1069441
[Epoch 57] ogbg-moltox21: 0.771177 val loss: 0.389522
[Epoch 57] ogbg-moltox21: 0.739918 test loss: 0.388150
[Epoch 58; Iter    27/  209] train: loss: 0.0750891
[Epoch 58; Iter    57/  209] train: loss: 0.0324578
[Epoch 58; Iter    87/  209] train: loss: 0.0845072
[Epoch 58; Iter   117/  209] train: loss: 0.1012871
[Epoch 58; Iter   147/  209] train: loss: 0.0768940
[Epoch 58; Iter   177/  209] train: loss: 0.0580383
[Epoch 58; Iter   207/  209] train: loss: 0.0739001
[Epoch 58] ogbg-moltox21: 0.761097 val loss: 0.390399
[Epoch 58] ogbg-moltox21: 0.735839 test loss: 0.387374
[Epoch 59; Iter    28/  209] train: loss: 0.0808389
[Epoch 59; Iter    58/  209] train: loss: 0.0607881
[Epoch 59; Iter    88/  209] train: loss: 0.0682540
[Epoch 59; Iter   118/  209] train: loss: 0.0556993
[Epoch 59; Iter   148/  209] train: loss: 0.1206947
[Epoch 59; Iter   178/  209] train: loss: 0.0682103
[Epoch 59; Iter   208/  209] train: loss: 0.0854782
[Epoch 59] ogbg-moltox21: 0.781766 val loss: 0.333118
[Epoch 59] ogbg-moltox21: 0.740420 test loss: 0.348587
[Epoch 60; Iter    29/  209] train: loss: 0.0561684
[Epoch 60; Iter    59/  209] train: loss: 0.0267837
[Epoch 60; Iter    89/  209] train: loss: 0.0915681
[Epoch 60; Iter   119/  209] train: loss: 0.0825653
[Epoch 60; Iter   149/  209] train: loss: 0.0444209
[Epoch 60; Iter   179/  209] train: loss: 0.1024630
[Epoch 60; Iter   209/  209] train: loss: 0.0864990
[Epoch 60] ogbg-moltox21: 0.775869 val loss: 0.348572
[Epoch 60] ogbg-moltox21: 0.723297 test loss: 0.384114
[Epoch 61; Iter    30/  209] train: loss: 0.0694269
[Epoch 61; Iter    60/  209] train: loss: 0.0679561
[Epoch 61; Iter    90/  209] train: loss: 0.0910477
[Epoch 61; Iter   120/  209] train: loss: 0.0843385
[Epoch 61; Iter   150/  209] train: loss: 0.1322138
[Epoch 61; Iter   180/  209] train: loss: 0.1179212
[Epoch 61] ogbg-moltox21: 0.776670 val loss: 0.359762
[Epoch 61] ogbg-moltox21: 0.746525 test loss: 0.371911
[Epoch 62; Iter     1/  209] train: loss: 0.0998074
[Epoch 62; Iter    31/  209] train: loss: 0.0308866
[Epoch 62; Iter    61/  209] train: loss: 0.0346779
[Epoch 62; Iter    91/  209] train: loss: 0.0656426
[Epoch 62; Iter   121/  209] train: loss: 0.1023077
[Epoch 62; Iter   151/  209] train: loss: 0.0709917
[Epoch 62; Iter   181/  209] train: loss: 0.0696601
[Epoch 62] ogbg-moltox21: 0.766880 val loss: 0.355257
[Epoch 62] ogbg-moltox21: 0.737619 test loss: 0.368480
[Epoch 63; Iter     2/  209] train: loss: 0.0674269
[Epoch 63; Iter    32/  209] train: loss: 0.1005115
[Epoch 63; Iter    62/  209] train: loss: 0.0563214
[Epoch 63; Iter    92/  209] train: loss: 0.0774193
[Epoch 63; Iter   122/  209] train: loss: 0.0632553
[Epoch 63; Iter   152/  209] train: loss: 0.0461136
[Epoch 63; Iter   182/  209] train: loss: 0.0516369
[Epoch 63] ogbg-moltox21: 0.776339 val loss: 0.357543
[Epoch 63] ogbg-moltox21: 0.743511 test loss: 0.368685
[Epoch 64; Iter     3/  209] train: loss: 0.0752735
[Epoch 64; Iter    33/  209] train: loss: 0.0516745
[Epoch 64; Iter    63/  209] train: loss: 0.0598095
[Epoch 64; Iter    93/  209] train: loss: 0.0566414
[Epoch 64; Iter   123/  209] train: loss: 0.0704177
[Epoch 64; Iter   153/  209] train: loss: 0.0733982
[Epoch 64; Iter   183/  209] train: loss: 0.1512500
[Epoch 64] ogbg-moltox21: 0.772675 val loss: 0.357507
[Epoch 47; Iter   166/  209] train: loss: 0.0569653
[Epoch 47; Iter   196/  209] train: loss: 0.1124282
[Epoch 47] ogbg-moltox21: 0.768555 val loss: 0.311973
[Epoch 47] ogbg-moltox21: 0.729117 test loss: 0.341481
[Epoch 48; Iter    17/  209] train: loss: 0.0718912
[Epoch 48; Iter    47/  209] train: loss: 0.1189122
[Epoch 48; Iter    77/  209] train: loss: 0.0948865
[Epoch 48; Iter   107/  209] train: loss: 0.0678475
[Epoch 48; Iter   137/  209] train: loss: 0.1279707
[Epoch 48; Iter   167/  209] train: loss: 0.0963166
[Epoch 48; Iter   197/  209] train: loss: 0.0340452
[Epoch 48] ogbg-moltox21: 0.774847 val loss: 0.327825
[Epoch 48] ogbg-moltox21: 0.732204 test loss: 0.351045
[Epoch 49; Iter    18/  209] train: loss: 0.0692836
[Epoch 49; Iter    48/  209] train: loss: 0.0870508
[Epoch 49; Iter    78/  209] train: loss: 0.1047916
[Epoch 49; Iter   108/  209] train: loss: 0.1217734
[Epoch 49; Iter   138/  209] train: loss: 0.0803463
[Epoch 49; Iter   168/  209] train: loss: 0.0775050
[Epoch 49; Iter   198/  209] train: loss: 0.1553600
[Epoch 49] ogbg-moltox21: 0.758252 val loss: 0.393636
[Epoch 49] ogbg-moltox21: 0.730677 test loss: 0.426402
[Epoch 50; Iter    19/  209] train: loss: 0.0752087
[Epoch 50; Iter    49/  209] train: loss: 0.0758303
[Epoch 50; Iter    79/  209] train: loss: 0.0788428
[Epoch 50; Iter   109/  209] train: loss: 0.0792702
[Epoch 50; Iter   139/  209] train: loss: 0.0769359
[Epoch 50; Iter   169/  209] train: loss: 0.0772390
[Epoch 50; Iter   199/  209] train: loss: 0.0928630
[Epoch 50] ogbg-moltox21: 0.762122 val loss: 0.352662
[Epoch 50] ogbg-moltox21: 0.719709 test loss: 0.388050
[Epoch 51; Iter    20/  209] train: loss: 0.0905206
[Epoch 51; Iter    50/  209] train: loss: 0.0955728
[Epoch 51; Iter    80/  209] train: loss: 0.0391861
[Epoch 51; Iter   110/  209] train: loss: 0.0932836
[Epoch 51; Iter   140/  209] train: loss: 0.0817381
[Epoch 51; Iter   170/  209] train: loss: 0.0901272
[Epoch 51; Iter   200/  209] train: loss: 0.0876502
[Epoch 51] ogbg-moltox21: 0.765207 val loss: 0.340819
[Epoch 51] ogbg-moltox21: 0.734378 test loss: 0.362472
[Epoch 52; Iter    21/  209] train: loss: 0.0647473
[Epoch 52; Iter    51/  209] train: loss: 0.0676815
[Epoch 52; Iter    81/  209] train: loss: 0.0815543
[Epoch 52; Iter   111/  209] train: loss: 0.0620718
[Epoch 52; Iter   141/  209] train: loss: 0.0461341
[Epoch 52; Iter   171/  209] train: loss: 0.0880380
[Epoch 52; Iter   201/  209] train: loss: 0.0669756
[Epoch 52] ogbg-moltox21: 0.780190 val loss: 0.325966
[Epoch 52] ogbg-moltox21: 0.738775 test loss: 0.359094
[Epoch 53; Iter    22/  209] train: loss: 0.0736210
[Epoch 53; Iter    52/  209] train: loss: 0.0931564
[Epoch 53; Iter    82/  209] train: loss: 0.0420807
[Epoch 53; Iter   112/  209] train: loss: 0.1318034
[Epoch 53; Iter   142/  209] train: loss: 0.0984303
[Epoch 53; Iter   172/  209] train: loss: 0.0513039
[Epoch 53; Iter   202/  209] train: loss: 0.0840512
[Epoch 53] ogbg-moltox21: 0.767843 val loss: 0.361901
[Epoch 53] ogbg-moltox21: 0.729712 test loss: 0.378510
[Epoch 54; Iter    23/  209] train: loss: 0.1008825
[Epoch 54; Iter    53/  209] train: loss: 0.0580123
[Epoch 54; Iter    83/  209] train: loss: 0.0767118
[Epoch 54; Iter   113/  209] train: loss: 0.0502498
[Epoch 54; Iter   143/  209] train: loss: 0.0964427
[Epoch 54; Iter   173/  209] train: loss: 0.0941154
[Epoch 54; Iter   203/  209] train: loss: 0.0663076
[Epoch 54] ogbg-moltox21: 0.762359 val loss: 0.364950
[Epoch 54] ogbg-moltox21: 0.731091 test loss: 0.371553
[Epoch 55; Iter    24/  209] train: loss: 0.0792229
[Epoch 55; Iter    54/  209] train: loss: 0.0670176
[Epoch 55; Iter    84/  209] train: loss: 0.0692632
[Epoch 55; Iter   114/  209] train: loss: 0.0513144
[Epoch 55; Iter   144/  209] train: loss: 0.0666883
[Epoch 55; Iter   174/  209] train: loss: 0.0676262
[Epoch 55; Iter   204/  209] train: loss: 0.0331366
[Epoch 55] ogbg-moltox21: 0.773910 val loss: 0.356347
[Epoch 55] ogbg-moltox21: 0.741429 test loss: 0.377208
[Epoch 56; Iter    25/  209] train: loss: 0.0998597
[Epoch 56; Iter    55/  209] train: loss: 0.0894020
[Epoch 56; Iter    85/  209] train: loss: 0.0581154
[Epoch 56; Iter   115/  209] train: loss: 0.0556089
[Epoch 56; Iter   145/  209] train: loss: 0.0678962
[Epoch 56; Iter   175/  209] train: loss: 0.0435897
[Epoch 56; Iter   205/  209] train: loss: 0.0511391
[Epoch 56] ogbg-moltox21: 0.760066 val loss: 0.348963
[Epoch 56] ogbg-moltox21: 0.727671 test loss: 0.380078
[Epoch 57; Iter    26/  209] train: loss: 0.0552610
[Epoch 57; Iter    56/  209] train: loss: 0.0498325
[Epoch 57; Iter    86/  209] train: loss: 0.1035894
[Epoch 57; Iter   116/  209] train: loss: 0.0455152
[Epoch 57; Iter   146/  209] train: loss: 0.0683824
[Epoch 57; Iter   176/  209] train: loss: 0.0467700
[Epoch 57; Iter   206/  209] train: loss: 0.0917652
[Epoch 57] ogbg-moltox21: 0.764467 val loss: 0.396304
[Epoch 57] ogbg-moltox21: 0.737455 test loss: 0.410539
[Epoch 58; Iter    27/  209] train: loss: 0.0517491
[Epoch 58; Iter    57/  209] train: loss: 0.0304623
[Epoch 58; Iter    87/  209] train: loss: 0.0737248
[Epoch 58; Iter   117/  209] train: loss: 0.0545162
[Epoch 58; Iter   147/  209] train: loss: 0.0717975
[Epoch 58; Iter   177/  209] train: loss: 0.0530975
[Epoch 58; Iter   207/  209] train: loss: 0.0554726
[Epoch 58] ogbg-moltox21: 0.764547 val loss: 0.351208
[Epoch 58] ogbg-moltox21: 0.728757 test loss: 0.386786
[Epoch 59; Iter    28/  209] train: loss: 0.0499841
[Epoch 59; Iter    58/  209] train: loss: 0.0519028
[Epoch 59; Iter    88/  209] train: loss: 0.0707263
[Epoch 59; Iter   118/  209] train: loss: 0.0737382
[Epoch 59; Iter   148/  209] train: loss: 0.0636527
[Epoch 59; Iter   178/  209] train: loss: 0.0476275
[Epoch 59; Iter   208/  209] train: loss: 0.0786085
[Epoch 59] ogbg-moltox21: 0.759484 val loss: 0.404903
[Epoch 59] ogbg-moltox21: 0.738783 test loss: 0.419434
[Epoch 60; Iter    29/  209] train: loss: 0.0678094
[Epoch 60; Iter    59/  209] train: loss: 0.0491552
[Epoch 60; Iter    89/  209] train: loss: 0.0500194
[Epoch 60; Iter   119/  209] train: loss: 0.0631256
[Epoch 60; Iter   149/  209] train: loss: 0.0704833
[Epoch 60; Iter   179/  209] train: loss: 0.1491347
[Epoch 60; Iter   209/  209] train: loss: 0.0893157
[Epoch 60] ogbg-moltox21: 0.762102 val loss: 0.377734
[Epoch 60] ogbg-moltox21: 0.731428 test loss: 0.408148
[Epoch 61; Iter    30/  209] train: loss: 0.0411784
[Epoch 61; Iter    60/  209] train: loss: 0.0443221
[Epoch 61; Iter    90/  209] train: loss: 0.0931852
[Epoch 61; Iter   120/  209] train: loss: 0.0480315
[Epoch 61; Iter   150/  209] train: loss: 0.0365856
[Epoch 61; Iter   180/  209] train: loss: 0.0570314
[Epoch 61] ogbg-moltox21: 0.761263 val loss: 0.391895
[Epoch 61] ogbg-moltox21: 0.739372 test loss: 0.422171
[Epoch 62; Iter     1/  209] train: loss: 0.0341327
[Epoch 62; Iter    31/  209] train: loss: 0.0345828
[Epoch 62; Iter    61/  209] train: loss: 0.0447427
[Epoch 62; Iter    91/  209] train: loss: 0.0349009
[Epoch 62; Iter   121/  209] train: loss: 0.0731565
[Epoch 62; Iter   151/  209] train: loss: 0.0448083
[Epoch 62; Iter   181/  209] train: loss: 0.0739958
[Epoch 62] ogbg-moltox21: 0.762312 val loss: 0.375839
[Epoch 62] ogbg-moltox21: 0.736268 test loss: 0.412331
[Epoch 63; Iter     2/  209] train: loss: 0.0504536
[Epoch 63; Iter    32/  209] train: loss: 0.0742994
[Epoch 63; Iter    62/  209] train: loss: 0.0390792
[Epoch 63; Iter    92/  209] train: loss: 0.0766723
[Epoch 63; Iter   122/  209] train: loss: 0.0752833
[Epoch 63; Iter   152/  209] train: loss: 0.0551826
[Epoch 63; Iter   182/  209] train: loss: 0.0608689
[Epoch 63] ogbg-moltox21: 0.754850 val loss: 0.422219
[Epoch 63] ogbg-moltox21: 0.724022 test loss: 0.443765
[Epoch 64; Iter     3/  209] train: loss: 0.0563478
[Epoch 64; Iter    33/  209] train: loss: 0.0594593
[Epoch 64; Iter    63/  209] train: loss: 0.0500102
[Epoch 64; Iter    93/  209] train: loss: 0.0472405
[Epoch 64; Iter   123/  209] train: loss: 0.0857811
[Epoch 64; Iter   153/  209] train: loss: 0.0534997
[Epoch 64; Iter   183/  209] train: loss: 0.0560309
[Epoch 64] ogbg-moltox21: 0.759816 val loss: 0.397182
[Epoch 47; Iter   166/  209] train: loss: 0.0341478
[Epoch 47; Iter   196/  209] train: loss: 0.0828290
[Epoch 47] ogbg-moltox21: 0.731785 val loss: 0.448199
[Epoch 47] ogbg-moltox21: 0.711988 test loss: 0.486417
[Epoch 48; Iter    17/  209] train: loss: 0.0636906
[Epoch 48; Iter    47/  209] train: loss: 0.1001066
[Epoch 48; Iter    77/  209] train: loss: 0.0671870
[Epoch 48; Iter   107/  209] train: loss: 0.0498505
[Epoch 48; Iter   137/  209] train: loss: 0.0916888
[Epoch 48; Iter   167/  209] train: loss: 0.0685566
[Epoch 48; Iter   197/  209] train: loss: 0.0393100
[Epoch 48] ogbg-moltox21: 0.721449 val loss: 0.460807
[Epoch 48] ogbg-moltox21: 0.706002 test loss: 0.480198
[Epoch 49; Iter    18/  209] train: loss: 0.0513867
[Epoch 49; Iter    48/  209] train: loss: 0.0543243
[Epoch 49; Iter    78/  209] train: loss: 0.0470562
[Epoch 49; Iter   108/  209] train: loss: 0.0902590
[Epoch 49; Iter   138/  209] train: loss: 0.0857548
[Epoch 49; Iter   168/  209] train: loss: 0.0709051
[Epoch 49; Iter   198/  209] train: loss: 0.1340402
[Epoch 49] ogbg-moltox21: 0.722547 val loss: 0.464192
[Epoch 49] ogbg-moltox21: 0.716116 test loss: 0.486396
[Epoch 50; Iter    19/  209] train: loss: 0.0482832
[Epoch 50; Iter    49/  209] train: loss: 0.0427579
[Epoch 50; Iter    79/  209] train: loss: 0.0426659
[Epoch 50; Iter   109/  209] train: loss: 0.0481037
[Epoch 50; Iter   139/  209] train: loss: 0.0464442
[Epoch 50; Iter   169/  209] train: loss: 0.0493344
[Epoch 50; Iter   199/  209] train: loss: 0.0586916
[Epoch 50] ogbg-moltox21: 0.729993 val loss: 0.461467
[Epoch 50] ogbg-moltox21: 0.720344 test loss: 0.486757
[Epoch 51; Iter    20/  209] train: loss: 0.0482527
[Epoch 51; Iter    50/  209] train: loss: 0.0566679
[Epoch 51; Iter    80/  209] train: loss: 0.0302884
[Epoch 51; Iter   110/  209] train: loss: 0.0363724
[Epoch 51; Iter   140/  209] train: loss: 0.0468124
[Epoch 51; Iter   170/  209] train: loss: 0.0644828
[Epoch 51; Iter   200/  209] train: loss: 0.0868781
[Epoch 51] ogbg-moltox21: 0.725288 val loss: 0.478083
[Epoch 51] ogbg-moltox21: 0.712356 test loss: 0.495011
[Epoch 52; Iter    21/  209] train: loss: 0.0301230
[Epoch 52; Iter    51/  209] train: loss: 0.0443064
[Epoch 52; Iter    81/  209] train: loss: 0.0428667
[Epoch 52; Iter   111/  209] train: loss: 0.0315483
[Epoch 52; Iter   141/  209] train: loss: 0.0223553
[Epoch 52; Iter   171/  209] train: loss: 0.0686275
[Epoch 52; Iter   201/  209] train: loss: 0.0267869
[Epoch 52] ogbg-moltox21: 0.732166 val loss: 0.463188
[Epoch 52] ogbg-moltox21: 0.719937 test loss: 0.492563
[Epoch 53; Iter    22/  209] train: loss: 0.0731334
[Epoch 53; Iter    52/  209] train: loss: 0.0592354
[Epoch 53; Iter    82/  209] train: loss: 0.0151870
[Epoch 53; Iter   112/  209] train: loss: 0.0590591
[Epoch 53; Iter   142/  209] train: loss: 0.0471096
[Epoch 53; Iter   172/  209] train: loss: 0.0196203
[Epoch 53; Iter   202/  209] train: loss: 0.0281978
[Epoch 53] ogbg-moltox21: 0.729572 val loss: 0.498838
[Epoch 53] ogbg-moltox21: 0.708912 test loss: 0.530469
[Epoch 54; Iter    23/  209] train: loss: 0.0479761
[Epoch 54; Iter    53/  209] train: loss: 0.0216550
[Epoch 54; Iter    83/  209] train: loss: 0.0329356
[Epoch 54; Iter   113/  209] train: loss: 0.0388615
[Epoch 54; Iter   143/  209] train: loss: 0.0636311
[Epoch 54; Iter   173/  209] train: loss: 0.0355005
[Epoch 54; Iter   203/  209] train: loss: 0.0369802
[Epoch 54] ogbg-moltox21: 0.740463 val loss: 0.479296
[Epoch 54] ogbg-moltox21: 0.707642 test loss: 0.521147
[Epoch 55; Iter    24/  209] train: loss: 0.0292506
[Epoch 55; Iter    54/  209] train: loss: 0.0479960
[Epoch 55; Iter    84/  209] train: loss: 0.0253931
[Epoch 55; Iter   114/  209] train: loss: 0.0318457
[Epoch 55; Iter   144/  209] train: loss: 0.0477813
[Epoch 55; Iter   174/  209] train: loss: 0.0301802
[Epoch 55; Iter   204/  209] train: loss: 0.0466799
[Epoch 55] ogbg-moltox21: 0.736009 val loss: 0.487426
[Epoch 55] ogbg-moltox21: 0.713516 test loss: 0.517237
[Epoch 56; Iter    25/  209] train: loss: 0.0398931
[Epoch 56; Iter    55/  209] train: loss: 0.0420250
[Epoch 56; Iter    85/  209] train: loss: 0.0296265
[Epoch 56; Iter   115/  209] train: loss: 0.0289856
[Epoch 56; Iter   145/  209] train: loss: 0.0288064
[Epoch 56; Iter   175/  209] train: loss: 0.0333877
[Epoch 56; Iter   205/  209] train: loss: 0.0313978
[Epoch 56] ogbg-moltox21: 0.726651 val loss: 0.509246
[Epoch 56] ogbg-moltox21: 0.706436 test loss: 0.542914
[Epoch 57; Iter    26/  209] train: loss: 0.0246442
[Epoch 57; Iter    56/  209] train: loss: 0.0500152
[Epoch 57; Iter    86/  209] train: loss: 0.0362896
[Epoch 57; Iter   116/  209] train: loss: 0.0225995
[Epoch 57; Iter   146/  209] train: loss: 0.0527594
[Epoch 57; Iter   176/  209] train: loss: 0.0343736
[Epoch 57; Iter   206/  209] train: loss: 0.0257092
[Epoch 57] ogbg-moltox21: 0.737945 val loss: 0.509547
[Epoch 57] ogbg-moltox21: 0.711267 test loss: 0.552756
[Epoch 58; Iter    27/  209] train: loss: 0.0186188
[Epoch 58; Iter    57/  209] train: loss: 0.0184169
[Epoch 58; Iter    87/  209] train: loss: 0.0567790
[Epoch 58; Iter   117/  209] train: loss: 0.0297310
[Epoch 58; Iter   147/  209] train: loss: 0.0252276
[Epoch 58; Iter   177/  209] train: loss: 0.0380481
[Epoch 58; Iter   207/  209] train: loss: 0.0382116
[Epoch 58] ogbg-moltox21: 0.723558 val loss: 0.555431
[Epoch 58] ogbg-moltox21: 0.700916 test loss: 0.589617
[Epoch 59; Iter    28/  209] train: loss: 0.0309280
[Epoch 59; Iter    58/  209] train: loss: 0.0385027
[Epoch 59; Iter    88/  209] train: loss: 0.0704139
[Epoch 59; Iter   118/  209] train: loss: 0.0441943
[Epoch 59; Iter   148/  209] train: loss: 0.0290042
[Epoch 59; Iter   178/  209] train: loss: 0.0196566
[Epoch 59; Iter   208/  209] train: loss: 0.0372330
[Epoch 59] ogbg-moltox21: 0.725982 val loss: 0.529519
[Epoch 59] ogbg-moltox21: 0.713211 test loss: 0.566218
[Epoch 60; Iter    29/  209] train: loss: 0.0239279
[Epoch 60; Iter    59/  209] train: loss: 0.0368602
[Epoch 60; Iter    89/  209] train: loss: 0.0199133
[Epoch 60; Iter   119/  209] train: loss: 0.0442400
[Epoch 60; Iter   149/  209] train: loss: 0.0539165
[Epoch 60; Iter   179/  209] train: loss: 0.0730571
[Epoch 60; Iter   209/  209] train: loss: 0.0410783
[Epoch 60] ogbg-moltox21: 0.719247 val loss: 0.564448
[Epoch 60] ogbg-moltox21: 0.694814 test loss: 0.600963
[Epoch 61; Iter    30/  209] train: loss: 0.0258023
[Epoch 61; Iter    60/  209] train: loss: 0.0181424
[Epoch 61; Iter    90/  209] train: loss: 0.0556105
[Epoch 61; Iter   120/  209] train: loss: 0.0174356
[Epoch 61; Iter   150/  209] train: loss: 0.0146683
[Epoch 61; Iter   180/  209] train: loss: 0.0360902
[Epoch 61] ogbg-moltox21: 0.726409 val loss: 0.567033
[Epoch 61] ogbg-moltox21: 0.701562 test loss: 0.598886
[Epoch 62; Iter     1/  209] train: loss: 0.0246823
[Epoch 62; Iter    31/  209] train: loss: 0.0302146
[Epoch 62; Iter    61/  209] train: loss: 0.0227063
[Epoch 62; Iter    91/  209] train: loss: 0.0131040
[Epoch 62; Iter   121/  209] train: loss: 0.0260981
[Epoch 62; Iter   151/  209] train: loss: 0.0200939
[Epoch 62; Iter   181/  209] train: loss: 0.0350370
[Epoch 62] ogbg-moltox21: 0.726406 val loss: 0.582493
[Epoch 62] ogbg-moltox21: 0.702750 test loss: 0.614532
[Epoch 63; Iter     2/  209] train: loss: 0.0213382
[Epoch 63; Iter    32/  209] train: loss: 0.0300027
[Epoch 63; Iter    62/  209] train: loss: 0.0214993
[Epoch 63; Iter    92/  209] train: loss: 0.0185939
[Epoch 63; Iter   122/  209] train: loss: 0.0289438
[Epoch 63; Iter   152/  209] train: loss: 0.0207169
[Epoch 63; Iter   182/  209] train: loss: 0.0227506
[Epoch 63] ogbg-moltox21: 0.729983 val loss: 0.565023
[Epoch 63] ogbg-moltox21: 0.702151 test loss: 0.611196
[Epoch 64; Iter     3/  209] train: loss: 0.0383389
[Epoch 64; Iter    33/  209] train: loss: 0.0525995
[Epoch 64; Iter    63/  209] train: loss: 0.0340677
[Epoch 64; Iter    93/  209] train: loss: 0.0246492
[Epoch 64; Iter   123/  209] train: loss: 0.0503463
[Epoch 64; Iter   153/  209] train: loss: 0.0372138
[Epoch 64; Iter   183/  209] train: loss: 0.0309683
[Epoch 64] ogbg-moltox21: 0.725583 val loss: 0.621701
[Epoch 47; Iter   166/  209] train: loss: 0.0975076
[Epoch 47; Iter   196/  209] train: loss: 0.0512656
[Epoch 47] ogbg-moltox21: 0.744000 val loss: 0.413734
[Epoch 47] ogbg-moltox21: 0.712541 test loss: 0.435479
[Epoch 48; Iter    17/  209] train: loss: 0.0908328
[Epoch 48; Iter    47/  209] train: loss: 0.0545003
[Epoch 48; Iter    77/  209] train: loss: 0.0633596
[Epoch 48; Iter   107/  209] train: loss: 0.0636839
[Epoch 48; Iter   137/  209] train: loss: 0.0683797
[Epoch 48; Iter   167/  209] train: loss: 0.0815609
[Epoch 48; Iter   197/  209] train: loss: 0.0560157
[Epoch 48] ogbg-moltox21: 0.742922 val loss: 0.382906
[Epoch 48] ogbg-moltox21: 0.707263 test loss: 0.441535
[Epoch 49; Iter    18/  209] train: loss: 0.0434346
[Epoch 49; Iter    48/  209] train: loss: 0.0415770
[Epoch 49; Iter    78/  209] train: loss: 0.0524289
[Epoch 49; Iter   108/  209] train: loss: 0.0330928
[Epoch 49; Iter   138/  209] train: loss: 0.0920531
[Epoch 49; Iter   168/  209] train: loss: 0.0998420
[Epoch 49; Iter   198/  209] train: loss: 0.0730922
[Epoch 49] ogbg-moltox21: 0.719142 val loss: 0.585898
[Epoch 49] ogbg-moltox21: 0.706611 test loss: 0.517810
[Epoch 50; Iter    19/  209] train: loss: 0.1241174
[Epoch 50; Iter    49/  209] train: loss: 0.0465121
[Epoch 50; Iter    79/  209] train: loss: 0.0537795
[Epoch 50; Iter   109/  209] train: loss: 0.0443009
[Epoch 50; Iter   139/  209] train: loss: 0.0539861
[Epoch 50; Iter   169/  209] train: loss: 0.0551458
[Epoch 50; Iter   199/  209] train: loss: 0.0316172
[Epoch 50] ogbg-moltox21: 0.738904 val loss: 0.399716
[Epoch 50] ogbg-moltox21: 0.708143 test loss: 0.469945
[Epoch 51; Iter    20/  209] train: loss: 0.0636317
[Epoch 51; Iter    50/  209] train: loss: 0.0655390
[Epoch 51; Iter    80/  209] train: loss: 0.0451010
[Epoch 51; Iter   110/  209] train: loss: 0.0467409
[Epoch 51; Iter   140/  209] train: loss: 0.0751885
[Epoch 51; Iter   170/  209] train: loss: 0.0479174
[Epoch 51; Iter   200/  209] train: loss: 0.0615302
[Epoch 51] ogbg-moltox21: 0.741204 val loss: 0.460191
[Epoch 51] ogbg-moltox21: 0.697622 test loss: 0.500406
[Epoch 52; Iter    21/  209] train: loss: 0.0420063
[Epoch 52; Iter    51/  209] train: loss: 0.0425109
[Epoch 52; Iter    81/  209] train: loss: 0.0623633
[Epoch 52; Iter   111/  209] train: loss: 0.1174172
[Epoch 52; Iter   141/  209] train: loss: 0.0436143
[Epoch 52; Iter   171/  209] train: loss: 0.0442352
[Epoch 52; Iter   201/  209] train: loss: 0.0487082
[Epoch 52] ogbg-moltox21: 0.740874 val loss: 0.408422
[Epoch 52] ogbg-moltox21: 0.709241 test loss: 0.439578
[Epoch 53; Iter    22/  209] train: loss: 0.0658929
[Epoch 53; Iter    52/  209] train: loss: 0.0542638
[Epoch 53; Iter    82/  209] train: loss: 0.0819468
[Epoch 53; Iter   112/  209] train: loss: 0.0522984
[Epoch 53; Iter   142/  209] train: loss: 0.0469017
[Epoch 53; Iter   172/  209] train: loss: 0.0358732
[Epoch 53; Iter   202/  209] train: loss: 0.0819406
[Epoch 53] ogbg-moltox21: 0.732906 val loss: 0.460800
[Epoch 53] ogbg-moltox21: 0.710993 test loss: 0.470264
[Epoch 54; Iter    23/  209] train: loss: 0.0530250
[Epoch 54; Iter    53/  209] train: loss: 0.0493648
[Epoch 54; Iter    83/  209] train: loss: 0.0549975
[Epoch 54; Iter   113/  209] train: loss: 0.0542037
[Epoch 54; Iter   143/  209] train: loss: 0.0668897
[Epoch 54; Iter   173/  209] train: loss: 0.0701386
[Epoch 54; Iter   203/  209] train: loss: 0.0631051
[Epoch 54] ogbg-moltox21: 0.734955 val loss: 0.480520
[Epoch 54] ogbg-moltox21: 0.701987 test loss: 0.511160
[Epoch 55; Iter    24/  209] train: loss: 0.0466854
[Epoch 55; Iter    54/  209] train: loss: 0.0229417
[Epoch 55; Iter    84/  209] train: loss: 0.0484024
[Epoch 55; Iter   114/  209] train: loss: 0.0611026
[Epoch 55; Iter   144/  209] train: loss: 0.0815362
[Epoch 55; Iter   174/  209] train: loss: 0.0513889
[Epoch 55; Iter   204/  209] train: loss: 0.0407363
[Epoch 55] ogbg-moltox21: 0.740557 val loss: 0.453435
[Epoch 55] ogbg-moltox21: 0.703265 test loss: 0.490339
[Epoch 56; Iter    25/  209] train: loss: 0.0284372
[Epoch 56; Iter    55/  209] train: loss: 0.0613474
[Epoch 56; Iter    85/  209] train: loss: 0.0350037
[Epoch 56; Iter   115/  209] train: loss: 0.0197551
[Epoch 56; Iter   145/  209] train: loss: 0.0882671
[Epoch 56; Iter   175/  209] train: loss: 0.0493100
[Epoch 56; Iter   205/  209] train: loss: 0.0435497
[Epoch 56] ogbg-moltox21: 0.722765 val loss: 0.480724
[Epoch 56] ogbg-moltox21: 0.693813 test loss: 0.504130
[Epoch 57; Iter    26/  209] train: loss: 0.0419485
[Epoch 57; Iter    56/  209] train: loss: 0.0476114
[Epoch 57; Iter    86/  209] train: loss: 0.0695495
[Epoch 57; Iter   116/  209] train: loss: 0.0257402
[Epoch 57; Iter   146/  209] train: loss: 0.0418440
[Epoch 57; Iter   176/  209] train: loss: 0.0773258
[Epoch 57; Iter   206/  209] train: loss: 0.0628249
[Epoch 57] ogbg-moltox21: 0.742892 val loss: 0.487153
[Epoch 57] ogbg-moltox21: 0.695340 test loss: 0.528864
[Epoch 58; Iter    27/  209] train: loss: 0.0301899
[Epoch 58; Iter    57/  209] train: loss: 0.0171737
[Epoch 58; Iter    87/  209] train: loss: 0.0565568
[Epoch 58; Iter   117/  209] train: loss: 0.0233540
[Epoch 58; Iter   147/  209] train: loss: 0.0420090
[Epoch 58; Iter   177/  209] train: loss: 0.0374802
[Epoch 58; Iter   207/  209] train: loss: 0.0370134
[Epoch 58] ogbg-moltox21: 0.732818 val loss: 0.479938
[Epoch 58] ogbg-moltox21: 0.695249 test loss: 0.522764
[Epoch 59; Iter    28/  209] train: loss: 0.0686702
[Epoch 59; Iter    58/  209] train: loss: 0.0716308
[Epoch 59; Iter    88/  209] train: loss: 0.0471516
[Epoch 59; Iter   118/  209] train: loss: 0.0424386
[Epoch 59; Iter   148/  209] train: loss: 0.0420117
[Epoch 59; Iter   178/  209] train: loss: 0.0593530
[Epoch 59; Iter   208/  209] train: loss: 0.0692177
[Epoch 59] ogbg-moltox21: 0.739924 val loss: 0.466932
[Epoch 59] ogbg-moltox21: 0.709212 test loss: 0.496258
[Epoch 60; Iter    29/  209] train: loss: 0.0191715
[Epoch 60; Iter    59/  209] train: loss: 0.0408850
[Epoch 60; Iter    89/  209] train: loss: 0.0293723
[Epoch 60; Iter   119/  209] train: loss: 0.0249180
[Epoch 60; Iter   149/  209] train: loss: 0.0336706
[Epoch 60; Iter   179/  209] train: loss: 0.0250268
[Epoch 60; Iter   209/  209] train: loss: 0.0593547
[Epoch 60] ogbg-moltox21: 0.737750 val loss: 0.598753
[Epoch 60] ogbg-moltox21: 0.703225 test loss: 0.579288
[Epoch 61; Iter    30/  209] train: loss: 0.0441995
[Epoch 61; Iter    60/  209] train: loss: 0.0306360
[Epoch 61; Iter    90/  209] train: loss: 0.0229620
[Epoch 61; Iter   120/  209] train: loss: 0.0347225
[Epoch 61; Iter   150/  209] train: loss: 0.0561030
[Epoch 61; Iter   180/  209] train: loss: 0.0589225
[Epoch 61] ogbg-moltox21: 0.745595 val loss: 0.486125
[Epoch 61] ogbg-moltox21: 0.713894 test loss: 0.513344
[Epoch 62; Iter     1/  209] train: loss: 0.0418341
[Epoch 62; Iter    31/  209] train: loss: 0.0350042
[Epoch 62; Iter    61/  209] train: loss: 0.0290108
[Epoch 62; Iter    91/  209] train: loss: 0.0596330
[Epoch 62; Iter   121/  209] train: loss: 0.0452770
[Epoch 62; Iter   151/  209] train: loss: 0.0508384
[Epoch 62; Iter   181/  209] train: loss: 0.0408312
[Epoch 62] ogbg-moltox21: 0.724106 val loss: 0.579456
[Epoch 62] ogbg-moltox21: 0.703479 test loss: 0.567693
[Epoch 63; Iter     2/  209] train: loss: 0.0741990
[Epoch 63; Iter    32/  209] train: loss: 0.1234220
[Epoch 63; Iter    62/  209] train: loss: 0.0343665
[Epoch 63; Iter    92/  209] train: loss: 0.0314345
[Epoch 63; Iter   122/  209] train: loss: 0.0416358
[Epoch 63; Iter   152/  209] train: loss: 0.0575249
[Epoch 63; Iter   182/  209] train: loss: 0.0497618
[Epoch 63] ogbg-moltox21: 0.734163 val loss: 0.506002
[Epoch 63] ogbg-moltox21: 0.704722 test loss: 0.567692
[Epoch 64; Iter     3/  209] train: loss: 0.0252053
[Epoch 64; Iter    33/  209] train: loss: 0.0349261
[Epoch 64; Iter    63/  209] train: loss: 0.0348070
[Epoch 64; Iter    93/  209] train: loss: 0.0459544
[Epoch 64; Iter   123/  209] train: loss: 0.0448667
[Epoch 64; Iter   153/  209] train: loss: 0.0688874
[Epoch 64; Iter   183/  209] train: loss: 0.0329639
[Epoch 64] ogbg-moltox21: 0.737942 val loss: 0.523786
[Epoch 47; Iter   166/  209] train: loss: 0.1009193
[Epoch 47; Iter   196/  209] train: loss: 0.0922562
[Epoch 47] ogbg-moltox21: 0.710064 val loss: 0.917689
[Epoch 47] ogbg-moltox21: 0.665693 test loss: 0.561025
[Epoch 48; Iter    17/  209] train: loss: 0.1448554
[Epoch 48; Iter    47/  209] train: loss: 0.0866678
[Epoch 48; Iter    77/  209] train: loss: 0.1045157
[Epoch 48; Iter   107/  209] train: loss: 0.1013628
[Epoch 48; Iter   137/  209] train: loss: 0.0855976
[Epoch 48; Iter   167/  209] train: loss: 0.0964933
[Epoch 48; Iter   197/  209] train: loss: 0.0898008
[Epoch 48] ogbg-moltox21: 0.682987 val loss: 0.589265
[Epoch 48] ogbg-moltox21: 0.645478 test loss: 0.543860
[Epoch 49; Iter    18/  209] train: loss: 0.0871142
[Epoch 49; Iter    48/  209] train: loss: 0.0749964
[Epoch 49; Iter    78/  209] train: loss: 0.0647970
[Epoch 49; Iter   108/  209] train: loss: 0.0496390
[Epoch 49; Iter   138/  209] train: loss: 0.1000744
[Epoch 49; Iter   168/  209] train: loss: 0.0952347
[Epoch 49; Iter   198/  209] train: loss: 0.0753772
[Epoch 49] ogbg-moltox21: 0.708882 val loss: 0.537532
[Epoch 49] ogbg-moltox21: 0.658321 test loss: 0.583373
[Epoch 50; Iter    19/  209] train: loss: 0.1408323
[Epoch 50; Iter    49/  209] train: loss: 0.0622656
[Epoch 50; Iter    79/  209] train: loss: 0.0609794
[Epoch 50; Iter   109/  209] train: loss: 0.0620793
[Epoch 50; Iter   139/  209] train: loss: 0.0771918
[Epoch 50; Iter   169/  209] train: loss: 0.0736906
[Epoch 50; Iter   199/  209] train: loss: 0.0451229
[Epoch 50] ogbg-moltox21: 0.694303 val loss: 0.799857
[Epoch 50] ogbg-moltox21: 0.655919 test loss: 0.594583
[Epoch 51; Iter    20/  209] train: loss: 0.0800126
[Epoch 51; Iter    50/  209] train: loss: 0.0804404
[Epoch 51; Iter    80/  209] train: loss: 0.0512116
[Epoch 51; Iter   110/  209] train: loss: 0.0648873
[Epoch 51; Iter   140/  209] train: loss: 0.0897913
[Epoch 51; Iter   170/  209] train: loss: 0.0757901
[Epoch 51; Iter   200/  209] train: loss: 0.0916641
[Epoch 51] ogbg-moltox21: 0.706538 val loss: 0.822753
[Epoch 51] ogbg-moltox21: 0.657838 test loss: 0.655422
[Epoch 52; Iter    21/  209] train: loss: 0.0717897
[Epoch 52; Iter    51/  209] train: loss: 0.0634861
[Epoch 52; Iter    81/  209] train: loss: 0.0671256
[Epoch 52; Iter   111/  209] train: loss: 0.1060969
[Epoch 52; Iter   141/  209] train: loss: 0.0735277
[Epoch 52; Iter   171/  209] train: loss: 0.0651686
[Epoch 52; Iter   201/  209] train: loss: 0.0918835
[Epoch 52] ogbg-moltox21: 0.703705 val loss: 0.999927
[Epoch 52] ogbg-moltox21: 0.666399 test loss: 0.653993
[Epoch 53; Iter    22/  209] train: loss: 0.0674819
[Epoch 53; Iter    52/  209] train: loss: 0.0716973
[Epoch 53; Iter    82/  209] train: loss: 0.1003235
[Epoch 53; Iter   112/  209] train: loss: 0.0764650
[Epoch 53; Iter   142/  209] train: loss: 0.0757263
[Epoch 53; Iter   172/  209] train: loss: 0.0708853
[Epoch 53; Iter   202/  209] train: loss: 0.0749891
[Epoch 53] ogbg-moltox21: 0.698917 val loss: 0.613516
[Epoch 53] ogbg-moltox21: 0.677568 test loss: 0.525607
[Epoch 54; Iter    23/  209] train: loss: 0.0513792
[Epoch 54; Iter    53/  209] train: loss: 0.0702346
[Epoch 54; Iter    83/  209] train: loss: 0.0530918
[Epoch 54; Iter   113/  209] train: loss: 0.0824571
[Epoch 54; Iter   143/  209] train: loss: 0.0883569
[Epoch 54; Iter   173/  209] train: loss: 0.1049643
[Epoch 54; Iter   203/  209] train: loss: 0.0677831
[Epoch 54] ogbg-moltox21: 0.686293 val loss: 1.256541
[Epoch 54] ogbg-moltox21: 0.652500 test loss: 0.692495
[Epoch 55; Iter    24/  209] train: loss: 0.0777752
[Epoch 55; Iter    54/  209] train: loss: 0.0486787
[Epoch 55; Iter    84/  209] train: loss: 0.0691124
[Epoch 55; Iter   114/  209] train: loss: 0.1032922
[Epoch 55; Iter   144/  209] train: loss: 0.0963337
[Epoch 55; Iter   174/  209] train: loss: 0.0505480
[Epoch 55; Iter   204/  209] train: loss: 0.0507305
[Epoch 55] ogbg-moltox21: 0.706491 val loss: 0.789711
[Epoch 55] ogbg-moltox21: 0.664185 test loss: 0.577472
[Epoch 56; Iter    25/  209] train: loss: 0.0531726
[Epoch 56; Iter    55/  209] train: loss: 0.0925551
[Epoch 56; Iter    85/  209] train: loss: 0.0446983
[Epoch 56; Iter   115/  209] train: loss: 0.0423317
[Epoch 56; Iter   145/  209] train: loss: 0.0661158
[Epoch 56; Iter   175/  209] train: loss: 0.0854514
[Epoch 56; Iter   205/  209] train: loss: 0.0529154
[Epoch 56] ogbg-moltox21: 0.682908 val loss: 1.374720
[Epoch 56] ogbg-moltox21: 0.645258 test loss: 0.804611
[Epoch 57; Iter    26/  209] train: loss: 0.0439503
[Epoch 57; Iter    56/  209] train: loss: 0.0777351
[Epoch 57; Iter    86/  209] train: loss: 0.0861067
[Epoch 57; Iter   116/  209] train: loss: 0.0341962
[Epoch 57; Iter   146/  209] train: loss: 0.0483386
[Epoch 57; Iter   176/  209] train: loss: 0.0822333
[Epoch 57; Iter   206/  209] train: loss: 0.0835001
[Epoch 57] ogbg-moltox21: 0.671420 val loss: 1.880054
[Epoch 57] ogbg-moltox21: 0.634481 test loss: 1.172542
[Epoch 58; Iter    27/  209] train: loss: 0.0521297
[Epoch 58; Iter    57/  209] train: loss: 0.0380179
[Epoch 58; Iter    87/  209] train: loss: 0.0682919
[Epoch 58; Iter   117/  209] train: loss: 0.0359555
[Epoch 58; Iter   147/  209] train: loss: 0.0450959
[Epoch 58; Iter   177/  209] train: loss: 0.0463892
[Epoch 58; Iter   207/  209] train: loss: 0.0613551
[Epoch 58] ogbg-moltox21: 0.682290 val loss: 1.248403
[Epoch 58] ogbg-moltox21: 0.642101 test loss: 0.702772
[Epoch 59; Iter    28/  209] train: loss: 0.0774581
[Epoch 59; Iter    58/  209] train: loss: 0.1207426
[Epoch 59; Iter    88/  209] train: loss: 0.0745378
[Epoch 59; Iter   118/  209] train: loss: 0.0579233
[Epoch 59; Iter   148/  209] train: loss: 0.0672642
[Epoch 59; Iter   178/  209] train: loss: 0.0605143
[Epoch 59; Iter   208/  209] train: loss: 0.0911056
[Epoch 59] ogbg-moltox21: 0.690650 val loss: 1.756392
[Epoch 59] ogbg-moltox21: 0.655249 test loss: 0.634658
[Epoch 60; Iter    29/  209] train: loss: 0.0342832
[Epoch 60; Iter    59/  209] train: loss: 0.0421575
[Epoch 60; Iter    89/  209] train: loss: 0.0533273
[Epoch 60; Iter   119/  209] train: loss: 0.0342519
[Epoch 60; Iter   149/  209] train: loss: 0.0531226
[Epoch 60; Iter   179/  209] train: loss: 0.0739911
[Epoch 60; Iter   209/  209] train: loss: 0.0868392
[Epoch 60] ogbg-moltox21: 0.699100 val loss: 1.571369
[Epoch 60] ogbg-moltox21: 0.667233 test loss: 0.790919
[Epoch 61; Iter    30/  209] train: loss: 0.0536357
[Epoch 61; Iter    60/  209] train: loss: 0.0420971
[Epoch 61; Iter    90/  209] train: loss: 0.0379633
[Epoch 61; Iter   120/  209] train: loss: 0.0446170
[Epoch 61; Iter   150/  209] train: loss: 0.0775196
[Epoch 61; Iter   180/  209] train: loss: 0.0570492
[Epoch 61] ogbg-moltox21: 0.695238 val loss: 1.553405
[Epoch 61] ogbg-moltox21: 0.651485 test loss: 0.842669
[Epoch 62; Iter     1/  209] train: loss: 0.0826616
[Epoch 62; Iter    31/  209] train: loss: 0.0590271
[Epoch 62; Iter    61/  209] train: loss: 0.0443473
[Epoch 62; Iter    91/  209] train: loss: 0.0548716
[Epoch 62; Iter   121/  209] train: loss: 0.0415195
[Epoch 62; Iter   151/  209] train: loss: 0.0871427
[Epoch 62; Iter   181/  209] train: loss: 0.0675546
[Epoch 62] ogbg-moltox21: 0.691952 val loss: 0.868367
[Epoch 62] ogbg-moltox21: 0.656307 test loss: 0.631314
[Epoch 63; Iter     2/  209] train: loss: 0.0732335
[Epoch 63; Iter    32/  209] train: loss: 0.1627823
[Epoch 63; Iter    62/  209] train: loss: 0.0351452
[Epoch 63; Iter    92/  209] train: loss: 0.0392299
[Epoch 63; Iter   122/  209] train: loss: 0.0384581
[Epoch 63; Iter   152/  209] train: loss: 0.0516532
[Epoch 63; Iter   182/  209] train: loss: 0.0311073
[Epoch 63] ogbg-moltox21: 0.682116 val loss: 1.259592
[Epoch 63] ogbg-moltox21: 0.633978 test loss: 0.835418
[Epoch 64; Iter     3/  209] train: loss: 0.0211311
[Epoch 64; Iter    33/  209] train: loss: 0.0412216
[Epoch 64; Iter    63/  209] train: loss: 0.0444996
[Epoch 64; Iter    93/  209] train: loss: 0.0446742
[Epoch 64; Iter   123/  209] train: loss: 0.0635231
[Epoch 64; Iter   153/  209] train: loss: 0.0700429
[Epoch 64; Iter   183/  209] train: loss: 0.0434995
[Epoch 64] ogbg-moltox21: 0.699249 val loss: 1.277472
[Epoch 47; Iter   166/  209] train: loss: 0.0446757
[Epoch 47; Iter   196/  209] train: loss: 0.0905885
[Epoch 47] ogbg-moltox21: 0.751040 val loss: 1.022920
[Epoch 47] ogbg-moltox21: 0.695783 test loss: 0.733473
[Epoch 48; Iter    17/  209] train: loss: 0.0731284
[Epoch 48; Iter    47/  209] train: loss: 0.0455873
[Epoch 48; Iter    77/  209] train: loss: 0.0767089
[Epoch 48; Iter   107/  209] train: loss: 0.1298314
[Epoch 48; Iter   137/  209] train: loss: 0.0815253
[Epoch 48; Iter   167/  209] train: loss: 0.0834918
[Epoch 48; Iter   197/  209] train: loss: 0.0655990
[Epoch 48] ogbg-moltox21: 0.743243 val loss: 0.889863
[Epoch 48] ogbg-moltox21: 0.678927 test loss: 0.820461
[Epoch 49; Iter    18/  209] train: loss: 0.0921774
[Epoch 49; Iter    48/  209] train: loss: 0.0645788
[Epoch 49; Iter    78/  209] train: loss: 0.0522562
[Epoch 49; Iter   108/  209] train: loss: 0.0539722
[Epoch 49; Iter   138/  209] train: loss: 0.1022425
[Epoch 49; Iter   168/  209] train: loss: 0.0588707
[Epoch 49; Iter   198/  209] train: loss: 0.0543955
[Epoch 49] ogbg-moltox21: 0.740695 val loss: 0.861479
[Epoch 49] ogbg-moltox21: 0.683048 test loss: 0.766632
[Epoch 50; Iter    19/  209] train: loss: 0.0575887
[Epoch 50; Iter    49/  209] train: loss: 0.0439417
[Epoch 50; Iter    79/  209] train: loss: 0.0468935
[Epoch 50; Iter   109/  209] train: loss: 0.0580053
[Epoch 50; Iter   139/  209] train: loss: 0.0779514
[Epoch 50; Iter   169/  209] train: loss: 0.0502419
[Epoch 50; Iter   199/  209] train: loss: 0.1058814
[Epoch 50] ogbg-moltox21: 0.740226 val loss: 0.712868
[Epoch 50] ogbg-moltox21: 0.686741 test loss: 0.657214
[Epoch 51; Iter    20/  209] train: loss: 0.0591457
[Epoch 51; Iter    50/  209] train: loss: 0.0462712
[Epoch 51; Iter    80/  209] train: loss: 0.0681942
[Epoch 51; Iter   110/  209] train: loss: 0.0639407
[Epoch 51; Iter   140/  209] train: loss: 0.0626816
[Epoch 51; Iter   170/  209] train: loss: 0.0606718
[Epoch 51; Iter   200/  209] train: loss: 0.0503137
[Epoch 51] ogbg-moltox21: 0.722307 val loss: 0.743696
[Epoch 51] ogbg-moltox21: 0.665270 test loss: 0.638031
[Epoch 52; Iter    21/  209] train: loss: 0.1031881
[Epoch 52; Iter    51/  209] train: loss: 0.0338965
[Epoch 52; Iter    81/  209] train: loss: 0.0604827
[Epoch 52; Iter   111/  209] train: loss: 0.0812864
[Epoch 52; Iter   141/  209] train: loss: 0.0471015
[Epoch 52; Iter   171/  209] train: loss: 0.0534193
[Epoch 52; Iter   201/  209] train: loss: 0.1068469
[Epoch 52] ogbg-moltox21: 0.736456 val loss: 1.702224
[Epoch 52] ogbg-moltox21: 0.679575 test loss: 0.799553
[Epoch 53; Iter    22/  209] train: loss: 0.0495335
[Epoch 53; Iter    52/  209] train: loss: 0.0416376
[Epoch 53; Iter    82/  209] train: loss: 0.0468753
[Epoch 53; Iter   112/  209] train: loss: 0.0469737
[Epoch 53; Iter   142/  209] train: loss: 0.0816911
[Epoch 53; Iter   172/  209] train: loss: 0.0410255
[Epoch 53; Iter   202/  209] train: loss: 0.0906323
[Epoch 53] ogbg-moltox21: 0.730043 val loss: 0.817570
[Epoch 53] ogbg-moltox21: 0.677953 test loss: 0.708178
[Epoch 54; Iter    23/  209] train: loss: 0.0552151
[Epoch 54; Iter    53/  209] train: loss: 0.0274972
[Epoch 54; Iter    83/  209] train: loss: 0.0613164
[Epoch 54; Iter   113/  209] train: loss: 0.0469171
[Epoch 54; Iter   143/  209] train: loss: 0.0753327
[Epoch 54; Iter   173/  209] train: loss: 0.0960105
[Epoch 54; Iter   203/  209] train: loss: 0.0509310
[Epoch 54] ogbg-moltox21: 0.724730 val loss: 0.649667
[Epoch 54] ogbg-moltox21: 0.678611 test loss: 0.667048
[Epoch 55; Iter    24/  209] train: loss: 0.0286216
[Epoch 55; Iter    54/  209] train: loss: 0.0592303
[Epoch 55; Iter    84/  209] train: loss: 0.0550335
[Epoch 55; Iter   114/  209] train: loss: 0.0678067
[Epoch 55; Iter   144/  209] train: loss: 0.0837684
[Epoch 55; Iter   174/  209] train: loss: 0.0495056
[Epoch 55; Iter   204/  209] train: loss: 0.0344779
[Epoch 55] ogbg-moltox21: 0.719827 val loss: 1.309579
[Epoch 55] ogbg-moltox21: 0.656916 test loss: 0.636407
[Epoch 56; Iter    25/  209] train: loss: 0.0523134
[Epoch 56; Iter    55/  209] train: loss: 0.0695522
[Epoch 56; Iter    85/  209] train: loss: 0.0420727
[Epoch 56; Iter   115/  209] train: loss: 0.0389354
[Epoch 56; Iter   145/  209] train: loss: 0.0427962
[Epoch 56; Iter   175/  209] train: loss: 0.0409257
[Epoch 56; Iter   205/  209] train: loss: 0.0482550
[Epoch 56] ogbg-moltox21: 0.737726 val loss: 0.899641
[Epoch 56] ogbg-moltox21: 0.681202 test loss: 0.667887
[Epoch 57; Iter    26/  209] train: loss: 0.0479891
[Epoch 57; Iter    56/  209] train: loss: 0.0708635
[Epoch 57; Iter    86/  209] train: loss: 0.0604877
[Epoch 57; Iter   116/  209] train: loss: 0.0358383
[Epoch 57; Iter   146/  209] train: loss: 0.0880400
[Epoch 57; Iter   176/  209] train: loss: 0.0517620
[Epoch 57; Iter   206/  209] train: loss: 0.0396357
[Epoch 57] ogbg-moltox21: 0.713218 val loss: 0.821929
[Epoch 57] ogbg-moltox21: 0.663224 test loss: 0.748512
[Epoch 58; Iter    27/  209] train: loss: 0.0344277
[Epoch 58; Iter    57/  209] train: loss: 0.0195594
[Epoch 58; Iter    87/  209] train: loss: 0.0204618
[Epoch 58; Iter   117/  209] train: loss: 0.0347457
[Epoch 58; Iter   147/  209] train: loss: 0.0242657
[Epoch 58; Iter   177/  209] train: loss: 0.0306097
[Epoch 58; Iter   207/  209] train: loss: 0.0140827
[Epoch 58] ogbg-moltox21: 0.730909 val loss: 0.887173
[Epoch 58] ogbg-moltox21: 0.674490 test loss: 0.687103
[Epoch 59; Iter    28/  209] train: loss: 0.0413236
[Epoch 59; Iter    58/  209] train: loss: 0.0206081
[Epoch 59; Iter    88/  209] train: loss: 0.0171699
[Epoch 59; Iter   118/  209] train: loss: 0.0123193
[Epoch 59; Iter   148/  209] train: loss: 0.0537067
[Epoch 59; Iter   178/  209] train: loss: 0.0377532
[Epoch 59; Iter   208/  209] train: loss: 0.0178219
[Epoch 59] ogbg-moltox21: 0.723996 val loss: 0.622018
[Epoch 59] ogbg-moltox21: 0.661728 test loss: 0.720932
[Epoch 60; Iter    29/  209] train: loss: 0.0165765
[Epoch 60; Iter    59/  209] train: loss: 0.0111473
[Epoch 60; Iter    89/  209] train: loss: 0.0603710
[Epoch 60; Iter   119/  209] train: loss: 0.0334374
[Epoch 60; Iter   149/  209] train: loss: 0.0115483
[Epoch 60; Iter   179/  209] train: loss: 0.0314387
[Epoch 60; Iter   209/  209] train: loss: 0.0411432
[Epoch 60] ogbg-moltox21: 0.716315 val loss: 0.789396
[Epoch 60] ogbg-moltox21: 0.670237 test loss: 0.703752
[Epoch 61; Iter    30/  209] train: loss: 0.0276394
[Epoch 61; Iter    60/  209] train: loss: 0.0132030
[Epoch 61; Iter    90/  209] train: loss: 0.0363988
[Epoch 61; Iter   120/  209] train: loss: 0.0443669
[Epoch 61; Iter   150/  209] train: loss: 0.0802820
[Epoch 61; Iter   180/  209] train: loss: 0.0785433
[Epoch 61] ogbg-moltox21: 0.722077 val loss: 0.728572
[Epoch 61] ogbg-moltox21: 0.680584 test loss: 0.714681
[Epoch 62; Iter     1/  209] train: loss: 0.0467836
[Epoch 62; Iter    31/  209] train: loss: 0.0305599
[Epoch 62; Iter    61/  209] train: loss: 0.0157472
[Epoch 62; Iter    91/  209] train: loss: 0.0345140
[Epoch 62; Iter   121/  209] train: loss: 0.0451751
[Epoch 62; Iter   151/  209] train: loss: 0.0304856
[Epoch 62; Iter   181/  209] train: loss: 0.0231871
[Epoch 62] ogbg-moltox21: 0.737339 val loss: 0.853197
[Epoch 62] ogbg-moltox21: 0.673783 test loss: 0.762941
[Epoch 63; Iter     2/  209] train: loss: 0.0249166
[Epoch 63; Iter    32/  209] train: loss: 0.0513672
[Epoch 63; Iter    62/  209] train: loss: 0.0276539
[Epoch 63; Iter    92/  209] train: loss: 0.0195314
[Epoch 63; Iter   122/  209] train: loss: 0.0165619
[Epoch 63; Iter   152/  209] train: loss: 0.0388885
[Epoch 63; Iter   182/  209] train: loss: 0.0245994
[Epoch 63] ogbg-moltox21: 0.729854 val loss: 0.703773
[Epoch 63] ogbg-moltox21: 0.666023 test loss: 0.848495
[Epoch 64; Iter     3/  209] train: loss: 0.0278027
[Epoch 64; Iter    33/  209] train: loss: 0.0286403
[Epoch 64; Iter    63/  209] train: loss: 0.0425200
[Epoch 64; Iter    93/  209] train: loss: 0.0323932
[Epoch 64; Iter   123/  209] train: loss: 0.0514358
[Epoch 64; Iter   153/  209] train: loss: 0.0304809
[Epoch 64; Iter   183/  209] train: loss: 0.0523650
[Epoch 64] ogbg-moltox21: 0.721170 val loss: 0.686130
[Epoch 47; Iter   166/  209] train: loss: 0.1243897
[Epoch 47; Iter   196/  209] train: loss: 0.0811872
[Epoch 47] ogbg-moltox21: 0.798601 val loss: 0.259009
[Epoch 47] ogbg-moltox21: 0.767482 test loss: 0.270622
[Epoch 48; Iter    17/  209] train: loss: 0.1541708
[Epoch 48; Iter    47/  209] train: loss: 0.1058247
[Epoch 48; Iter    77/  209] train: loss: 0.1319506
[Epoch 48; Iter   107/  209] train: loss: 0.1221631
[Epoch 48; Iter   137/  209] train: loss: 0.1612844
[Epoch 48; Iter   167/  209] train: loss: 0.1523402
[Epoch 48; Iter   197/  209] train: loss: 0.1138255
[Epoch 48] ogbg-moltox21: 0.798497 val loss: 0.263683
[Epoch 48] ogbg-moltox21: 0.766107 test loss: 0.286779
[Epoch 49; Iter    18/  209] train: loss: 0.1222242
[Epoch 49; Iter    48/  209] train: loss: 0.0787764
[Epoch 49; Iter    78/  209] train: loss: 0.1086031
[Epoch 49; Iter   108/  209] train: loss: 0.0967851
[Epoch 49; Iter   138/  209] train: loss: 0.1398135
[Epoch 49; Iter   168/  209] train: loss: 0.1364470
[Epoch 49; Iter   198/  209] train: loss: 0.1455736
[Epoch 49] ogbg-moltox21: 0.790942 val loss: 0.277484
[Epoch 49] ogbg-moltox21: 0.757443 test loss: 0.358676
[Epoch 50; Iter    19/  209] train: loss: 0.1707990
[Epoch 50; Iter    49/  209] train: loss: 0.0721245
[Epoch 50; Iter    79/  209] train: loss: 0.0908236
[Epoch 50; Iter   109/  209] train: loss: 0.1259214
[Epoch 50; Iter   139/  209] train: loss: 0.0968863
[Epoch 50; Iter   169/  209] train: loss: 0.0995896
[Epoch 50; Iter   199/  209] train: loss: 0.0655532
[Epoch 50] ogbg-moltox21: 0.796805 val loss: 0.262835
[Epoch 50] ogbg-moltox21: 0.767597 test loss: 0.274757
[Epoch 51; Iter    20/  209] train: loss: 0.1390812
[Epoch 51; Iter    50/  209] train: loss: 0.1037146
[Epoch 51; Iter    80/  209] train: loss: 0.0514783
[Epoch 51; Iter   110/  209] train: loss: 0.0832176
[Epoch 51; Iter   140/  209] train: loss: 0.1291745
[Epoch 51; Iter   170/  209] train: loss: 0.0948261
[Epoch 51; Iter   200/  209] train: loss: 0.1420506
[Epoch 51] ogbg-moltox21: 0.796489 val loss: 0.265225
[Epoch 51] ogbg-moltox21: 0.763942 test loss: 0.293681
[Epoch 52; Iter    21/  209] train: loss: 0.1106396
[Epoch 52; Iter    51/  209] train: loss: 0.1039524
[Epoch 52; Iter    81/  209] train: loss: 0.1295732
[Epoch 52; Iter   111/  209] train: loss: 0.1664970
[Epoch 52; Iter   141/  209] train: loss: 0.0943162
[Epoch 52; Iter   171/  209] train: loss: 0.0948092
[Epoch 52; Iter   201/  209] train: loss: 0.1135998
[Epoch 52] ogbg-moltox21: 0.778399 val loss: 0.270573
[Epoch 52] ogbg-moltox21: 0.758527 test loss: 0.283553
[Epoch 53; Iter    22/  209] train: loss: 0.1279944
[Epoch 53; Iter    52/  209] train: loss: 0.0938978
[Epoch 53; Iter    82/  209] train: loss: 0.1099330
[Epoch 53; Iter   112/  209] train: loss: 0.0854127
[Epoch 53; Iter   142/  209] train: loss: 0.0812265
[Epoch 53; Iter   172/  209] train: loss: 0.0979047
[Epoch 53; Iter   202/  209] train: loss: 0.1187062
[Epoch 53] ogbg-moltox21: 0.782699 val loss: 0.314621
[Epoch 53] ogbg-moltox21: 0.765229 test loss: 0.289486
[Epoch 54; Iter    23/  209] train: loss: 0.1129201
[Epoch 54; Iter    53/  209] train: loss: 0.1305842
[Epoch 54; Iter    83/  209] train: loss: 0.0798076
[Epoch 54; Iter   113/  209] train: loss: 0.1106729
[Epoch 54; Iter   143/  209] train: loss: 0.1099563
[Epoch 54; Iter   173/  209] train: loss: 0.1459756
[Epoch 54; Iter   203/  209] train: loss: 0.1228690
[Epoch 54] ogbg-moltox21: 0.786386 val loss: 0.287367
[Epoch 54] ogbg-moltox21: 0.774588 test loss: 0.286256
[Epoch 55; Iter    24/  209] train: loss: 0.0932780
[Epoch 55; Iter    54/  209] train: loss: 0.0908807
[Epoch 55; Iter    84/  209] train: loss: 0.1094837
[Epoch 55; Iter   114/  209] train: loss: 0.1276627
[Epoch 55; Iter   144/  209] train: loss: 0.1220869
[Epoch 55; Iter   174/  209] train: loss: 0.1013584
[Epoch 55; Iter   204/  209] train: loss: 0.0828454
[Epoch 55] ogbg-moltox21: 0.784456 val loss: 0.283855
[Epoch 55] ogbg-moltox21: 0.750944 test loss: 0.296469
[Epoch 56; Iter    25/  209] train: loss: 0.1258638
[Epoch 56; Iter    55/  209] train: loss: 0.1147828
[Epoch 56; Iter    85/  209] train: loss: 0.0989421
[Epoch 56; Iter   115/  209] train: loss: 0.1117755
[Epoch 56; Iter   145/  209] train: loss: 0.1502682
[Epoch 56; Iter   175/  209] train: loss: 0.1224366
[Epoch 56; Iter   205/  209] train: loss: 0.0887535
[Epoch 56] ogbg-moltox21: 0.782740 val loss: 0.295975
[Epoch 56] ogbg-moltox21: 0.770309 test loss: 0.291346
[Epoch 57; Iter    26/  209] train: loss: 0.1118730
[Epoch 57; Iter    56/  209] train: loss: 0.1284256
[Epoch 57; Iter    86/  209] train: loss: 0.1298066
[Epoch 57; Iter   116/  209] train: loss: 0.0448965
[Epoch 57; Iter   146/  209] train: loss: 0.0873142
[Epoch 57; Iter   176/  209] train: loss: 0.1404230
[Epoch 57; Iter   206/  209] train: loss: 0.1151642
[Epoch 57] ogbg-moltox21: 0.790441 val loss: 0.280875
[Epoch 57] ogbg-moltox21: 0.766083 test loss: 0.292926
[Epoch 58; Iter    27/  209] train: loss: 0.0741414
[Epoch 58; Iter    57/  209] train: loss: 0.0560715
[Epoch 58; Iter    87/  209] train: loss: 0.1157686
[Epoch 58; Iter   117/  209] train: loss: 0.0538563
[Epoch 58; Iter   147/  209] train: loss: 0.0883253
[Epoch 58; Iter   177/  209] train: loss: 0.0675106
[Epoch 58; Iter   207/  209] train: loss: 0.0969436
[Epoch 58] ogbg-moltox21: 0.785894 val loss: 0.283846
[Epoch 58] ogbg-moltox21: 0.753676 test loss: 0.304981
[Epoch 59; Iter    28/  209] train: loss: 0.1634469
[Epoch 59; Iter    58/  209] train: loss: 0.1413971
[Epoch 59; Iter    88/  209] train: loss: 0.1086905
[Epoch 59; Iter   118/  209] train: loss: 0.1033658
[Epoch 59; Iter   148/  209] train: loss: 0.1348151
[Epoch 59; Iter   178/  209] train: loss: 0.1567061
[Epoch 59; Iter   208/  209] train: loss: 0.1378403
[Epoch 59] ogbg-moltox21: 0.783742 val loss: 0.280763
[Epoch 59] ogbg-moltox21: 0.766703 test loss: 0.285868
[Epoch 60; Iter    29/  209] train: loss: 0.1072759
[Epoch 60; Iter    59/  209] train: loss: 0.0659015
[Epoch 60; Iter    89/  209] train: loss: 0.0723887
[Epoch 60; Iter   119/  209] train: loss: 0.0890527
[Epoch 60; Iter   149/  209] train: loss: 0.0850564
[Epoch 60; Iter   179/  209] train: loss: 0.0915745
[Epoch 60; Iter   209/  209] train: loss: 0.1856975
[Epoch 60] ogbg-moltox21: 0.778558 val loss: 0.292115
[Epoch 60] ogbg-moltox21: 0.762296 test loss: 0.298208
[Epoch 61; Iter    30/  209] train: loss: 0.1081515
[Epoch 61; Iter    60/  209] train: loss: 0.1025561
[Epoch 61; Iter    90/  209] train: loss: 0.0694212
[Epoch 61; Iter   120/  209] train: loss: 0.0954000
[Epoch 61; Iter   150/  209] train: loss: 0.1454753
[Epoch 61; Iter   180/  209] train: loss: 0.1151369
[Epoch 61] ogbg-moltox21: 0.784187 val loss: 0.313487
[Epoch 61] ogbg-moltox21: 0.747096 test loss: 0.323344
[Epoch 62; Iter     1/  209] train: loss: 0.0953506
[Epoch 62; Iter    31/  209] train: loss: 0.0856479
[Epoch 62; Iter    61/  209] train: loss: 0.0809186
[Epoch 62; Iter    91/  209] train: loss: 0.1372199
[Epoch 62; Iter   121/  209] train: loss: 0.0838313
[Epoch 62; Iter   151/  209] train: loss: 0.0972209
[Epoch 62; Iter   181/  209] train: loss: 0.1080956
[Epoch 62] ogbg-moltox21: 0.770526 val loss: 0.315985
[Epoch 62] ogbg-moltox21: 0.757061 test loss: 0.306095
[Epoch 63; Iter     2/  209] train: loss: 0.0976884
[Epoch 63; Iter    32/  209] train: loss: 0.2154663
[Epoch 63; Iter    62/  209] train: loss: 0.1096680
[Epoch 63; Iter    92/  209] train: loss: 0.0826681
[Epoch 63; Iter   122/  209] train: loss: 0.1189812
[Epoch 63; Iter   152/  209] train: loss: 0.1317291
[Epoch 63; Iter   182/  209] train: loss: 0.0536276
[Epoch 63] ogbg-moltox21: 0.781565 val loss: 0.315292
[Epoch 63] ogbg-moltox21: 0.754621 test loss: 0.313418
[Epoch 64; Iter     3/  209] train: loss: 0.0705342
[Epoch 64; Iter    33/  209] train: loss: 0.0810438
[Epoch 64; Iter    63/  209] train: loss: 0.0939649
[Epoch 64; Iter    93/  209] train: loss: 0.0780687
[Epoch 64; Iter   123/  209] train: loss: 0.1324997
[Epoch 64; Iter   153/  209] train: loss: 0.1459084
[Epoch 64; Iter   183/  209] train: loss: 0.1141538
[Epoch 64] ogbg-moltox21: 0.777494 val loss: 0.309766
[Epoch 64] ogbg-moltox21: 0.738900 test loss: 0.433802
[Epoch 65; Iter     4/  209] train: loss: 0.0697113
[Epoch 65; Iter    34/  209] train: loss: 0.0831156
[Epoch 65; Iter    64/  209] train: loss: 0.0551743
[Epoch 65; Iter    94/  209] train: loss: 0.1119665
[Epoch 65; Iter   124/  209] train: loss: 0.1148413
[Epoch 65; Iter   154/  209] train: loss: 0.0402305
[Epoch 65; Iter   184/  209] train: loss: 0.0621636
[Epoch 65] ogbg-moltox21: 0.755474 val loss: 0.440938
[Epoch 65] ogbg-moltox21: 0.728094 test loss: 0.453699
[Epoch 66; Iter     5/  209] train: loss: 0.0777477
[Epoch 66; Iter    35/  209] train: loss: 0.0425287
[Epoch 66; Iter    65/  209] train: loss: 0.0261361
[Epoch 66; Iter    95/  209] train: loss: 0.0404049
[Epoch 66; Iter   125/  209] train: loss: 0.0858817
[Epoch 66; Iter   155/  209] train: loss: 0.0905067
[Epoch 66; Iter   185/  209] train: loss: 0.0425310
[Epoch 66] ogbg-moltox21: 0.749980 val loss: 0.447012
[Epoch 66] ogbg-moltox21: 0.724606 test loss: 0.467664
[Epoch 67; Iter     6/  209] train: loss: 0.0586340
[Epoch 67; Iter    36/  209] train: loss: 0.0348228
[Epoch 67; Iter    66/  209] train: loss: 0.0293997
[Epoch 67; Iter    96/  209] train: loss: 0.0457115
[Epoch 67; Iter   126/  209] train: loss: 0.0573342
[Epoch 67; Iter   156/  209] train: loss: 0.0699890
[Epoch 67; Iter   186/  209] train: loss: 0.0690726
[Epoch 67] ogbg-moltox21: 0.745276 val loss: 0.456809
[Epoch 67] ogbg-moltox21: 0.733513 test loss: 0.442861
[Epoch 68; Iter     7/  209] train: loss: 0.0485968
[Epoch 68; Iter    37/  209] train: loss: 0.0344137
[Epoch 68; Iter    67/  209] train: loss: 0.0662092
[Epoch 68; Iter    97/  209] train: loss: 0.0516635
[Epoch 68; Iter   127/  209] train: loss: 0.0835928
[Epoch 68; Iter   157/  209] train: loss: 0.0440624
[Epoch 68; Iter   187/  209] train: loss: 0.0598301
[Epoch 68] ogbg-moltox21: 0.743933 val loss: 0.460613
[Epoch 68] ogbg-moltox21: 0.720016 test loss: 0.476371
[Epoch 69; Iter     8/  209] train: loss: 0.0522148
[Epoch 69; Iter    38/  209] train: loss: 0.0195858
[Epoch 69; Iter    68/  209] train: loss: 0.0300644
[Epoch 69; Iter    98/  209] train: loss: 0.0312107
[Epoch 69; Iter   128/  209] train: loss: 0.0573921
[Epoch 69; Iter   158/  209] train: loss: 0.0789951
[Epoch 69; Iter   188/  209] train: loss: 0.0426360
[Epoch 69] ogbg-moltox21: 0.754720 val loss: 0.437282
[Epoch 69] ogbg-moltox21: 0.736720 test loss: 0.446148
[Epoch 70; Iter     9/  209] train: loss: 0.0318893
[Epoch 70; Iter    39/  209] train: loss: 0.0421877
[Epoch 70; Iter    69/  209] train: loss: 0.0567003
[Epoch 70; Iter    99/  209] train: loss: 0.0412212
[Epoch 70; Iter   129/  209] train: loss: 0.0497308
[Epoch 70; Iter   159/  209] train: loss: 0.0948655
[Epoch 70; Iter   189/  209] train: loss: 0.0578303
[Epoch 70] ogbg-moltox21: 0.757479 val loss: 0.468825
[Epoch 70] ogbg-moltox21: 0.741167 test loss: 0.470948
[Epoch 71; Iter    10/  209] train: loss: 0.0430579
[Epoch 71; Iter    40/  209] train: loss: 0.0524777
[Epoch 71; Iter    70/  209] train: loss: 0.0412607
[Epoch 71; Iter   100/  209] train: loss: 0.0681279
[Epoch 71; Iter   130/  209] train: loss: 0.0401173
[Epoch 71; Iter   160/  209] train: loss: 0.0780000
[Epoch 71; Iter   190/  209] train: loss: 0.0481635
[Epoch 71] ogbg-moltox21: 0.751946 val loss: 0.469190
[Epoch 71] ogbg-moltox21: 0.728382 test loss: 0.494737
[Epoch 72; Iter    11/  209] train: loss: 0.0531850
[Epoch 72; Iter    41/  209] train: loss: 0.0872307
[Epoch 72; Iter    71/  209] train: loss: 0.0488285
[Epoch 72; Iter   101/  209] train: loss: 0.0206676
[Epoch 72; Iter   131/  209] train: loss: 0.0529377
[Epoch 72; Iter   161/  209] train: loss: 0.0354217
[Epoch 72; Iter   191/  209] train: loss: 0.0835180
[Epoch 72] ogbg-moltox21: 0.747905 val loss: 0.494066
[Epoch 72] ogbg-moltox21: 0.729107 test loss: 0.500731
[Epoch 73; Iter    12/  209] train: loss: 0.0349375
[Epoch 73; Iter    42/  209] train: loss: 0.0424490
[Epoch 73; Iter    72/  209] train: loss: 0.0684401
[Epoch 73; Iter   102/  209] train: loss: 0.0302067
[Epoch 73; Iter   132/  209] train: loss: 0.0366328
[Epoch 73; Iter   162/  209] train: loss: 0.0489228
[Epoch 73; Iter   192/  209] train: loss: 0.0437196
[Epoch 73] ogbg-moltox21: 0.740733 val loss: 0.508711
[Epoch 73] ogbg-moltox21: 0.726618 test loss: 0.507660
[Epoch 74; Iter    13/  209] train: loss: 0.0586207
[Epoch 74; Iter    43/  209] train: loss: 0.0618305
[Epoch 74; Iter    73/  209] train: loss: 0.0610448
[Epoch 74; Iter   103/  209] train: loss: 0.0310272
[Epoch 74; Iter   133/  209] train: loss: 0.0752998
[Epoch 74; Iter   163/  209] train: loss: 0.0428326
[Epoch 74; Iter   193/  209] train: loss: 0.0409472
[Epoch 74] ogbg-moltox21: 0.737678 val loss: 0.471938
[Epoch 74] ogbg-moltox21: 0.728073 test loss: 0.477031
[Epoch 75; Iter    14/  209] train: loss: 0.0275908
[Epoch 75; Iter    44/  209] train: loss: 0.0188944
[Epoch 75; Iter    74/  209] train: loss: 0.0578730
[Epoch 75; Iter   104/  209] train: loss: 0.0599936
[Epoch 75; Iter   134/  209] train: loss: 0.0232826
[Epoch 75; Iter   164/  209] train: loss: 0.0536240
[Epoch 75; Iter   194/  209] train: loss: 0.0606226
[Epoch 75] ogbg-moltox21: 0.748018 val loss: 0.484100
[Epoch 75] ogbg-moltox21: 0.732222 test loss: 0.480148
[Epoch 76; Iter    15/  209] train: loss: 0.0346299
[Epoch 76; Iter    45/  209] train: loss: 0.0468671
[Epoch 76; Iter    75/  209] train: loss: 0.0387530
[Epoch 76; Iter   105/  209] train: loss: 0.0341906
[Epoch 76; Iter   135/  209] train: loss: 0.0625460
[Epoch 76; Iter   165/  209] train: loss: 0.0122998
[Epoch 76; Iter   195/  209] train: loss: 0.0447892
[Epoch 76] ogbg-moltox21: 0.744014 val loss: 0.498524
[Epoch 76] ogbg-moltox21: 0.730663 test loss: 0.506322
[Epoch 77; Iter    16/  209] train: loss: 0.0638193
[Epoch 77; Iter    46/  209] train: loss: 0.0227259
[Epoch 77; Iter    76/  209] train: loss: 0.0283598
[Epoch 77; Iter   106/  209] train: loss: 0.0232606
[Epoch 77; Iter   136/  209] train: loss: 0.0653038
[Epoch 77; Iter   166/  209] train: loss: 0.0643281
[Epoch 77; Iter   196/  209] train: loss: 0.0605695
[Epoch 77] ogbg-moltox21: 0.745338 val loss: 0.494393
[Epoch 77] ogbg-moltox21: 0.723381 test loss: 0.499455
[Epoch 78; Iter    17/  209] train: loss: 0.0178497
[Epoch 78; Iter    47/  209] train: loss: 0.0176959
[Epoch 78; Iter    77/  209] train: loss: 0.0260451
[Epoch 78; Iter   107/  209] train: loss: 0.0355504
[Epoch 78; Iter   137/  209] train: loss: 0.0418886
[Epoch 78; Iter   167/  209] train: loss: 0.0306465
[Epoch 78; Iter   197/  209] train: loss: 0.0346635
[Epoch 78] ogbg-moltox21: 0.763156 val loss: 0.516065
[Epoch 78] ogbg-moltox21: 0.728618 test loss: 0.547553
[Epoch 79; Iter    18/  209] train: loss: 0.0247062
[Epoch 79; Iter    48/  209] train: loss: 0.0373389
[Epoch 79; Iter    78/  209] train: loss: 0.0511583
[Epoch 79; Iter   108/  209] train: loss: 0.0320613
[Epoch 79; Iter   138/  209] train: loss: 0.0272685
[Epoch 79; Iter   168/  209] train: loss: 0.0335661
[Epoch 79; Iter   198/  209] train: loss: 0.0362091
[Epoch 79] ogbg-moltox21: 0.751721 val loss: 0.515415
[Epoch 79] ogbg-moltox21: 0.730550 test loss: 0.528802
[Epoch 80; Iter    19/  209] train: loss: 0.0286616
[Epoch 80; Iter    49/  209] train: loss: 0.0353448
[Epoch 80; Iter    79/  209] train: loss: 0.0261569
[Epoch 80; Iter   109/  209] train: loss: 0.0173907
[Epoch 80; Iter   139/  209] train: loss: 0.0229886
[Epoch 80; Iter   169/  209] train: loss: 0.0429246
[Epoch 80; Iter   199/  209] train: loss: 0.0738457
[Epoch 80] ogbg-moltox21: 0.755076 val loss: 0.510061
[Epoch 80] ogbg-moltox21: 0.732996 test loss: 0.529966
[Epoch 81; Iter    20/  209] train: loss: 0.0466118
[Epoch 81; Iter    50/  209] train: loss: 0.0248456
[Epoch 81; Iter    80/  209] train: loss: 0.0444160
[Epoch 81; Iter   110/  209] train: loss: 0.0312453
[Epoch 81; Iter   140/  209] train: loss: 0.0621714
[Epoch 81; Iter   170/  209] train: loss: 0.0597562
[Epoch 81; Iter   200/  209] train: loss: 0.0357425
[Epoch 81] ogbg-moltox21: 0.756780 val loss: 0.525954
[Epoch 81] ogbg-moltox21: 0.734265 test loss: 0.544354
[Epoch 82; Iter    21/  209] train: loss: 0.0259575
[Epoch 64] ogbg-moltox21: 0.703619 test loss: 0.533659
[Epoch 65; Iter     4/  209] train: loss: 0.0321689
[Epoch 65; Iter    34/  209] train: loss: 0.0260637
[Epoch 65; Iter    64/  209] train: loss: 0.0537245
[Epoch 65; Iter    94/  209] train: loss: 0.0404115
[Epoch 65; Iter   124/  209] train: loss: 0.0504467
[Epoch 65; Iter   154/  209] train: loss: 0.0492573
[Epoch 65; Iter   184/  209] train: loss: 0.0601576
[Epoch 65] ogbg-moltox21: 0.726005 val loss: 0.517973
[Epoch 65] ogbg-moltox21: 0.710579 test loss: 0.536870
[Epoch 66; Iter     5/  209] train: loss: 0.0594094
[Epoch 66; Iter    35/  209] train: loss: 0.0286819
[Epoch 66; Iter    65/  209] train: loss: 0.0334770
[Epoch 66; Iter    95/  209] train: loss: 0.0493382
[Epoch 66; Iter   125/  209] train: loss: 0.0428857
[Epoch 66; Iter   155/  209] train: loss: 0.0405860
[Epoch 66; Iter   185/  209] train: loss: 0.0495893
[Epoch 66] ogbg-moltox21: 0.729983 val loss: 0.870890
[Epoch 66] ogbg-moltox21: 0.719890 test loss: 0.985074
[Epoch 67; Iter     6/  209] train: loss: 0.0478577
[Epoch 67; Iter    36/  209] train: loss: 0.0482516
[Epoch 67; Iter    66/  209] train: loss: 0.0466283
[Epoch 67; Iter    96/  209] train: loss: 0.0390278
[Epoch 67; Iter   126/  209] train: loss: 0.0289396
[Epoch 67; Iter   156/  209] train: loss: 0.0517147
[Epoch 67; Iter   186/  209] train: loss: 0.0290372
[Epoch 67] ogbg-moltox21: 0.737742 val loss: 0.613226
[Epoch 67] ogbg-moltox21: 0.704208 test loss: 0.733167
[Epoch 68; Iter     7/  209] train: loss: 0.0567176
[Epoch 68; Iter    37/  209] train: loss: 0.0537686
[Epoch 68; Iter    67/  209] train: loss: 0.0564499
[Epoch 68; Iter    97/  209] train: loss: 0.0305279
[Epoch 68; Iter   127/  209] train: loss: 0.0698410
[Epoch 68; Iter   157/  209] train: loss: 0.0347561
[Epoch 68; Iter   187/  209] train: loss: 0.0210596
[Epoch 68] ogbg-moltox21: 0.731800 val loss: 0.518251
[Epoch 68] ogbg-moltox21: 0.724744 test loss: 0.526066
[Epoch 69; Iter     8/  209] train: loss: 0.0463804
[Epoch 69; Iter    38/  209] train: loss: 0.0235712
[Epoch 69; Iter    68/  209] train: loss: 0.0302450
[Epoch 69; Iter    98/  209] train: loss: 0.0294105
[Epoch 69; Iter   128/  209] train: loss: 0.0202514
[Epoch 69; Iter   158/  209] train: loss: 0.0272182
[Epoch 69; Iter   188/  209] train: loss: 0.0295351
[Epoch 69] ogbg-moltox21: 0.724468 val loss: 0.964113
[Epoch 69] ogbg-moltox21: 0.713644 test loss: 0.993247
[Epoch 70; Iter     9/  209] train: loss: 0.0280688
[Epoch 70; Iter    39/  209] train: loss: 0.0199145
[Epoch 70; Iter    69/  209] train: loss: 0.0441049
[Epoch 70; Iter    99/  209] train: loss: 0.0414857
[Epoch 70; Iter   129/  209] train: loss: 0.0513895
[Epoch 70; Iter   159/  209] train: loss: 0.0188614
[Epoch 70; Iter   189/  209] train: loss: 0.0513638
[Epoch 70] ogbg-moltox21: 0.726292 val loss: 0.606505
[Epoch 70] ogbg-moltox21: 0.709959 test loss: 0.674880
[Epoch 71; Iter    10/  209] train: loss: 0.0176093
[Epoch 71; Iter    40/  209] train: loss: 0.0631037
[Epoch 71; Iter    70/  209] train: loss: 0.0282993
[Epoch 71; Iter   100/  209] train: loss: 0.0356616
[Epoch 71; Iter   130/  209] train: loss: 0.0260147
[Epoch 71; Iter   160/  209] train: loss: 0.0260887
[Epoch 71; Iter   190/  209] train: loss: 0.0172525
[Epoch 71] ogbg-moltox21: 0.727297 val loss: 0.679291
[Epoch 71] ogbg-moltox21: 0.719581 test loss: 0.757098
[Epoch 72; Iter    11/  209] train: loss: 0.0348941
[Epoch 72; Iter    41/  209] train: loss: 0.0517630
[Epoch 72; Iter    71/  209] train: loss: 0.0638715
[Epoch 72; Iter   101/  209] train: loss: 0.0573484
[Epoch 72; Iter   131/  209] train: loss: 0.0711616
[Epoch 72; Iter   161/  209] train: loss: 0.0468766
[Epoch 72; Iter   191/  209] train: loss: 0.0341880
[Epoch 72] ogbg-moltox21: 0.727226 val loss: 0.557804
[Epoch 72] ogbg-moltox21: 0.710359 test loss: 0.580418
[Epoch 73; Iter    12/  209] train: loss: 0.0314907
[Epoch 73; Iter    42/  209] train: loss: 0.0238907
[Epoch 73; Iter    72/  209] train: loss: 0.0169755
[Epoch 73; Iter   102/  209] train: loss: 0.0393722
[Epoch 73; Iter   132/  209] train: loss: 0.0473078
[Epoch 73; Iter   162/  209] train: loss: 0.0388176
[Epoch 73; Iter   192/  209] train: loss: 0.0406118
[Epoch 73] ogbg-moltox21: 0.709482 val loss: 0.602053
[Epoch 73] ogbg-moltox21: 0.693766 test loss: 0.802943
[Epoch 74; Iter    13/  209] train: loss: 0.0409043
[Epoch 74; Iter    43/  209] train: loss: 0.0503318
[Epoch 74; Iter    73/  209] train: loss: 0.0236472
[Epoch 74; Iter   103/  209] train: loss: 0.0345227
[Epoch 74; Iter   133/  209] train: loss: 0.0203937
[Epoch 74; Iter   163/  209] train: loss: 0.0238860
[Epoch 74; Iter   193/  209] train: loss: 0.0542936
[Epoch 74] ogbg-moltox21: 0.712681 val loss: 0.741645
[Epoch 74] ogbg-moltox21: 0.710311 test loss: 0.805424
[Epoch 75; Iter    14/  209] train: loss: 0.0208768
[Epoch 75; Iter    44/  209] train: loss: 0.0289806
[Epoch 75; Iter    74/  209] train: loss: 0.0224508
[Epoch 75; Iter   104/  209] train: loss: 0.0246907
[Epoch 75; Iter   134/  209] train: loss: 0.0328232
[Epoch 75; Iter   164/  209] train: loss: 0.0217264
[Epoch 75; Iter   194/  209] train: loss: 0.0543609
[Epoch 75] ogbg-moltox21: 0.729926 val loss: 0.648115
[Epoch 75] ogbg-moltox21: 0.719354 test loss: 0.721708
[Epoch 76; Iter    15/  209] train: loss: 0.0309415
[Epoch 76; Iter    45/  209] train: loss: 0.0093913
[Epoch 76; Iter    75/  209] train: loss: 0.0295611
[Epoch 76; Iter   105/  209] train: loss: 0.0146107
[Epoch 76; Iter   135/  209] train: loss: 0.0226537
[Epoch 76; Iter   165/  209] train: loss: 0.0366422
[Epoch 76; Iter   195/  209] train: loss: 0.0247469
[Epoch 76] ogbg-moltox21: 0.716493 val loss: 0.603260
[Epoch 76] ogbg-moltox21: 0.699276 test loss: 0.611299
[Epoch 77; Iter    16/  209] train: loss: 0.0264621
[Epoch 77; Iter    46/  209] train: loss: 0.0231842
[Epoch 77; Iter    76/  209] train: loss: 0.0308654
[Epoch 77; Iter   106/  209] train: loss: 0.0188387
[Epoch 77; Iter   136/  209] train: loss: 0.0410229
[Epoch 77; Iter   166/  209] train: loss: 0.0326409
[Epoch 77; Iter   196/  209] train: loss: 0.0332649
[Epoch 77] ogbg-moltox21: 0.719596 val loss: 0.680621
[Epoch 77] ogbg-moltox21: 0.710156 test loss: 0.693844
[Epoch 78; Iter    17/  209] train: loss: 0.0400582
[Epoch 78; Iter    47/  209] train: loss: 0.0136508
[Epoch 78; Iter    77/  209] train: loss: 0.0265916
[Epoch 78; Iter   107/  209] train: loss: 0.0498617
[Epoch 78; Iter   137/  209] train: loss: 0.0505025
[Epoch 78; Iter   167/  209] train: loss: 0.0553359
[Epoch 78; Iter   197/  209] train: loss: 0.0326019
[Epoch 78] ogbg-moltox21: 0.717227 val loss: 0.624027
[Epoch 78] ogbg-moltox21: 0.706271 test loss: 0.613073
[Epoch 79; Iter    18/  209] train: loss: 0.0890200
[Epoch 79; Iter    48/  209] train: loss: 0.0296243
[Epoch 79; Iter    78/  209] train: loss: 0.0191731
[Epoch 79; Iter   108/  209] train: loss: 0.0287068
[Epoch 79; Iter   138/  209] train: loss: 0.0284419
[Epoch 79; Iter   168/  209] train: loss: 0.0177935
[Epoch 79; Iter   198/  209] train: loss: 0.0244780
[Epoch 79] ogbg-moltox21: 0.731230 val loss: 0.714496
[Epoch 79] ogbg-moltox21: 0.694768 test loss: 0.713629
[Epoch 80; Iter    19/  209] train: loss: 0.0680264
[Epoch 80; Iter    49/  209] train: loss: 0.0197982
[Epoch 80; Iter    79/  209] train: loss: 0.0184573
[Epoch 80; Iter   109/  209] train: loss: 0.0271508
[Epoch 80; Iter   139/  209] train: loss: 0.0256387
[Epoch 80; Iter   169/  209] train: loss: 0.0718359
[Epoch 80; Iter   199/  209] train: loss: 0.0245720
[Epoch 80] ogbg-moltox21: 0.736620 val loss: 0.591986
[Epoch 80] ogbg-moltox21: 0.714168 test loss: 0.680402
[Epoch 81; Iter    20/  209] train: loss: 0.0359649
[Epoch 81; Iter    50/  209] train: loss: 0.0165561
[Epoch 81; Iter    80/  209] train: loss: 0.0521269
[Epoch 81; Iter   110/  209] train: loss: 0.0205881
[Epoch 81; Iter   140/  209] train: loss: 0.0154729
[Epoch 81; Iter   170/  209] train: loss: 0.0396026
[Epoch 81; Iter   200/  209] train: loss: 0.0307524
[Epoch 81] ogbg-moltox21: 0.712455 val loss: 0.874540
[Epoch 81] ogbg-moltox21: 0.700397 test loss: 0.959601
[Epoch 82; Iter    21/  209] train: loss: 0.0306391
[Epoch 64] ogbg-moltox21: 0.718338 test loss: 0.609064
[Epoch 65; Iter     4/  209] train: loss: 0.0281375
[Epoch 65; Iter    34/  209] train: loss: 0.0283345
[Epoch 65; Iter    64/  209] train: loss: 0.0319079
[Epoch 65; Iter    94/  209] train: loss: 0.0264855
[Epoch 65; Iter   124/  209] train: loss: 0.0244015
[Epoch 65; Iter   154/  209] train: loss: 0.0171493
[Epoch 65; Iter   184/  209] train: loss: 0.0458225
[Epoch 65] ogbg-moltox21: 0.743678 val loss: 0.512930
[Epoch 65] ogbg-moltox21: 0.718947 test loss: 0.566609
[Epoch 66; Iter     5/  209] train: loss: 0.0319946
[Epoch 66; Iter    35/  209] train: loss: 0.0488242
[Epoch 66; Iter    65/  209] train: loss: 0.0229197
[Epoch 66; Iter    95/  209] train: loss: 0.0441115
[Epoch 66; Iter   125/  209] train: loss: 0.0291621
[Epoch 66; Iter   155/  209] train: loss: 0.0235001
[Epoch 66; Iter   185/  209] train: loss: 0.0212168
[Epoch 66] ogbg-moltox21: 0.740871 val loss: 0.554232
[Epoch 66] ogbg-moltox21: 0.719809 test loss: 0.603656
[Epoch 67; Iter     6/  209] train: loss: 0.0309621
[Epoch 67; Iter    36/  209] train: loss: 0.0283654
[Epoch 67; Iter    66/  209] train: loss: 0.0278595
[Epoch 67; Iter    96/  209] train: loss: 0.0202360
[Epoch 67; Iter   126/  209] train: loss: 0.0269608
[Epoch 67; Iter   156/  209] train: loss: 0.0179818
[Epoch 67; Iter   186/  209] train: loss: 0.0249671
[Epoch 67] ogbg-moltox21: 0.748174 val loss: 0.559427
[Epoch 67] ogbg-moltox21: 0.726388 test loss: 0.626161
[Epoch 68; Iter     7/  209] train: loss: 0.0254403
[Epoch 68; Iter    37/  209] train: loss: 0.0284269
[Epoch 68; Iter    67/  209] train: loss: 0.0709736
[Epoch 68; Iter    97/  209] train: loss: 0.0249150
[Epoch 68; Iter   127/  209] train: loss: 0.0172258
[Epoch 68; Iter   157/  209] train: loss: 0.0608710
[Epoch 68; Iter   187/  209] train: loss: 0.0324213
[Epoch 68] ogbg-moltox21: 0.743014 val loss: 0.540446
[Epoch 68] ogbg-moltox21: 0.730892 test loss: 0.591720
[Epoch 69; Iter     8/  209] train: loss: 0.0287609
[Epoch 69; Iter    38/  209] train: loss: 0.0550499
[Epoch 69; Iter    68/  209] train: loss: 0.0287139
[Epoch 69; Iter    98/  209] train: loss: 0.0219300
[Epoch 69; Iter   128/  209] train: loss: 0.0331485
[Epoch 69; Iter   158/  209] train: loss: 0.0364488
[Epoch 69; Iter   188/  209] train: loss: 0.0295931
[Epoch 69] ogbg-moltox21: 0.734576 val loss: 0.582146
[Epoch 69] ogbg-moltox21: 0.719465 test loss: 0.627415
[Epoch 70; Iter     9/  209] train: loss: 0.0347615
[Epoch 70; Iter    39/  209] train: loss: 0.0438156
[Epoch 70; Iter    69/  209] train: loss: 0.0479270
[Epoch 70; Iter    99/  209] train: loss: 0.0424712
[Epoch 70; Iter   129/  209] train: loss: 0.0417204
[Epoch 70; Iter   159/  209] train: loss: 0.0252502
[Epoch 70; Iter   189/  209] train: loss: 0.0259766
[Epoch 70] ogbg-moltox21: 0.739499 val loss: 0.551688
[Epoch 70] ogbg-moltox21: 0.720419 test loss: 0.604981
[Epoch 71; Iter    10/  209] train: loss: 0.0123037
[Epoch 71; Iter    40/  209] train: loss: 0.0140895
[Epoch 71; Iter    70/  209] train: loss: 0.0145129
[Epoch 71; Iter   100/  209] train: loss: 0.0356601
[Epoch 71; Iter   130/  209] train: loss: 0.0415254
[Epoch 71; Iter   160/  209] train: loss: 0.0268807
[Epoch 71; Iter   190/  209] train: loss: 0.0354833
[Epoch 71] ogbg-moltox21: 0.725811 val loss: 0.612519
[Epoch 71] ogbg-moltox21: 0.716424 test loss: 0.668441
[Epoch 72; Iter    11/  209] train: loss: 0.0349606
[Epoch 72; Iter    41/  209] train: loss: 0.0351550
[Epoch 72; Iter    71/  209] train: loss: 0.0176791
[Epoch 72; Iter   101/  209] train: loss: 0.0108851
[Epoch 72; Iter   131/  209] train: loss: 0.0293922
[Epoch 72; Iter   161/  209] train: loss: 0.0526865
[Epoch 72; Iter   191/  209] train: loss: 0.0638570
[Epoch 72] ogbg-moltox21: 0.740398 val loss: 0.601847
[Epoch 72] ogbg-moltox21: 0.722122 test loss: 0.660126
[Epoch 73; Iter    12/  209] train: loss: 0.0191834
[Epoch 73; Iter    42/  209] train: loss: 0.0202826
[Epoch 73; Iter    72/  209] train: loss: 0.0242319
[Epoch 73; Iter   102/  209] train: loss: 0.0204571
[Epoch 73; Iter   132/  209] train: loss: 0.0175870
[Epoch 73; Iter   162/  209] train: loss: 0.0180868
[Epoch 73; Iter   192/  209] train: loss: 0.0169110
[Epoch 73] ogbg-moltox21: 0.739853 val loss: 0.569894
[Epoch 73] ogbg-moltox21: 0.725092 test loss: 0.639526
[Epoch 74; Iter    13/  209] train: loss: 0.0112103
[Epoch 74; Iter    43/  209] train: loss: 0.0159137
[Epoch 74; Iter    73/  209] train: loss: 0.0453705
[Epoch 74; Iter   103/  209] train: loss: 0.0221435
[Epoch 74; Iter   133/  209] train: loss: 0.0144044
[Epoch 74; Iter   163/  209] train: loss: 0.0536638
[Epoch 74; Iter   193/  209] train: loss: 0.0523952
[Epoch 74] ogbg-moltox21: 0.734301 val loss: 0.601565
[Epoch 74] ogbg-moltox21: 0.727070 test loss: 0.644459
[Epoch 75; Iter    14/  209] train: loss: 0.0131031
[Epoch 75; Iter    44/  209] train: loss: 0.0172393
[Epoch 75; Iter    74/  209] train: loss: 0.0189554
[Epoch 75; Iter   104/  209] train: loss: 0.0482876
[Epoch 75; Iter   134/  209] train: loss: 0.0432651
[Epoch 75; Iter   164/  209] train: loss: 0.0391268
[Epoch 75; Iter   194/  209] train: loss: 0.0242248
[Epoch 75] ogbg-moltox21: 0.743205 val loss: 0.613164
[Epoch 75] ogbg-moltox21: 0.731621 test loss: 0.674955
[Epoch 76; Iter    15/  209] train: loss: 0.0301394
[Epoch 76; Iter    45/  209] train: loss: 0.0210544
[Epoch 76; Iter    75/  209] train: loss: 0.0168073
[Epoch 76; Iter   105/  209] train: loss: 0.0267841
[Epoch 76; Iter   135/  209] train: loss: 0.0274095
[Epoch 76; Iter   165/  209] train: loss: 0.0447108
[Epoch 76; Iter   195/  209] train: loss: 0.0185354
[Epoch 76] ogbg-moltox21: 0.738069 val loss: 0.593941
[Epoch 76] ogbg-moltox21: 0.735073 test loss: 0.642231
[Epoch 77; Iter    16/  209] train: loss: 0.0163274
[Epoch 77; Iter    46/  209] train: loss: 0.0129114
[Epoch 77; Iter    76/  209] train: loss: 0.0184198
[Epoch 77; Iter   106/  209] train: loss: 0.0272268
[Epoch 77; Iter   136/  209] train: loss: 0.0114877
[Epoch 77; Iter   166/  209] train: loss: 0.0417940
[Epoch 77; Iter   196/  209] train: loss: 0.0206232
[Epoch 77] ogbg-moltox21: 0.734108 val loss: 0.590021
[Epoch 77] ogbg-moltox21: 0.728209 test loss: 0.651995
[Epoch 78; Iter    17/  209] train: loss: 0.0377809
[Epoch 78; Iter    47/  209] train: loss: 0.0212885
[Epoch 78; Iter    77/  209] train: loss: 0.0909360
[Epoch 78; Iter   107/  209] train: loss: 0.0368974
[Epoch 78; Iter   137/  209] train: loss: 0.0178893
[Epoch 78; Iter   167/  209] train: loss: 0.0241806
[Epoch 78; Iter   197/  209] train: loss: 0.0201868
[Epoch 78] ogbg-moltox21: 0.732216 val loss: 0.582017
[Epoch 78] ogbg-moltox21: 0.731000 test loss: 0.641397
[Epoch 79; Iter    18/  209] train: loss: 0.0315189
[Epoch 79; Iter    48/  209] train: loss: 0.0227764
[Epoch 79; Iter    78/  209] train: loss: 0.0874168
[Epoch 79; Iter   108/  209] train: loss: 0.0212170
[Epoch 79; Iter   138/  209] train: loss: 0.0468087
[Epoch 79; Iter   168/  209] train: loss: 0.0206228
[Epoch 79; Iter   198/  209] train: loss: 0.0188624
[Epoch 79] ogbg-moltox21: 0.739726 val loss: 0.662401
[Epoch 79] ogbg-moltox21: 0.724779 test loss: 0.755346
[Epoch 80; Iter    19/  209] train: loss: 0.0290444
[Epoch 80; Iter    49/  209] train: loss: 0.0120165
[Epoch 80; Iter    79/  209] train: loss: 0.0303065
[Epoch 80; Iter   109/  209] train: loss: 0.0385919
[Epoch 80; Iter   139/  209] train: loss: 0.0287072
[Epoch 80; Iter   169/  209] train: loss: 0.0147483
[Epoch 80; Iter   199/  209] train: loss: 0.0278226
[Epoch 80] ogbg-moltox21: 0.732486 val loss: 0.591578
[Epoch 80] ogbg-moltox21: 0.719028 test loss: 0.644787
[Epoch 81; Iter    20/  209] train: loss: 0.0199907
[Epoch 81; Iter    50/  209] train: loss: 0.0109131
[Epoch 81; Iter    80/  209] train: loss: 0.0190328
[Epoch 81; Iter   110/  209] train: loss: 0.0180822
[Epoch 81; Iter   140/  209] train: loss: 0.0153383
[Epoch 81; Iter   170/  209] train: loss: 0.0234004
[Epoch 81; Iter   200/  209] train: loss: 0.0159512
[Epoch 81] ogbg-moltox21: 0.736021 val loss: 0.641850
[Epoch 81] ogbg-moltox21: 0.727245 test loss: 0.699700
[Epoch 82; Iter    21/  209] train: loss: 0.0191012
[Epoch 47; Iter   166/  209] train: loss: 0.1126422
[Epoch 47; Iter   196/  209] train: loss: 0.1532067
[Epoch 47] ogbg-moltox21: 0.783104 val loss: 0.283347
[Epoch 47] ogbg-moltox21: 0.755340 test loss: 0.296488
[Epoch 48; Iter    17/  209] train: loss: 0.1412918
[Epoch 48; Iter    47/  209] train: loss: 0.1680510
[Epoch 48; Iter    77/  209] train: loss: 0.1217628
[Epoch 48; Iter   107/  209] train: loss: 0.0857228
[Epoch 48; Iter   137/  209] train: loss: 0.1777248
[Epoch 48; Iter   167/  209] train: loss: 0.1276756
[Epoch 48; Iter   197/  209] train: loss: 0.0798114
[Epoch 48] ogbg-moltox21: 0.782918 val loss: 0.348903
[Epoch 48] ogbg-moltox21: 0.758239 test loss: 0.293458
[Epoch 49; Iter    18/  209] train: loss: 0.1163987
[Epoch 49; Iter    48/  209] train: loss: 0.1043536
[Epoch 49; Iter    78/  209] train: loss: 0.1836807
[Epoch 49; Iter   108/  209] train: loss: 0.1820092
[Epoch 49; Iter   138/  209] train: loss: 0.1010529
[Epoch 49; Iter   168/  209] train: loss: 0.1183035
[Epoch 49; Iter   198/  209] train: loss: 0.1725412
[Epoch 49] ogbg-moltox21: 0.782448 val loss: 0.305412
[Epoch 49] ogbg-moltox21: 0.758099 test loss: 0.299612
[Epoch 50; Iter    19/  209] train: loss: 0.0930037
[Epoch 50; Iter    49/  209] train: loss: 0.1332659
[Epoch 50; Iter    79/  209] train: loss: 0.1101530
[Epoch 50; Iter   109/  209] train: loss: 0.1241733
[Epoch 50; Iter   139/  209] train: loss: 0.1542249
[Epoch 50; Iter   169/  209] train: loss: 0.1211063
[Epoch 50; Iter   199/  209] train: loss: 0.1385837
[Epoch 50] ogbg-moltox21: 0.788651 val loss: 0.279599
[Epoch 50] ogbg-moltox21: 0.755486 test loss: 0.287829
[Epoch 51; Iter    20/  209] train: loss: 0.1292503
[Epoch 51; Iter    50/  209] train: loss: 0.1701288
[Epoch 51; Iter    80/  209] train: loss: 0.1058183
[Epoch 51; Iter   110/  209] train: loss: 0.1405862
[Epoch 51; Iter   140/  209] train: loss: 0.1337059
[Epoch 51; Iter   170/  209] train: loss: 0.1334346
[Epoch 51; Iter   200/  209] train: loss: 0.1326044
[Epoch 51] ogbg-moltox21: 0.792268 val loss: 0.286493
[Epoch 51] ogbg-moltox21: 0.757990 test loss: 0.280406
[Epoch 52; Iter    21/  209] train: loss: 0.1040429
[Epoch 52; Iter    51/  209] train: loss: 0.1126939
[Epoch 52; Iter    81/  209] train: loss: 0.1375716
[Epoch 52; Iter   111/  209] train: loss: 0.1224193
[Epoch 52; Iter   141/  209] train: loss: 0.0877005
[Epoch 52; Iter   171/  209] train: loss: 0.1517229
[Epoch 52; Iter   201/  209] train: loss: 0.1082404
[Epoch 52] ogbg-moltox21: 0.788658 val loss: 0.289882
[Epoch 52] ogbg-moltox21: 0.749351 test loss: 0.312453
[Epoch 53; Iter    22/  209] train: loss: 0.1183146
[Epoch 53; Iter    52/  209] train: loss: 0.1601077
[Epoch 53; Iter    82/  209] train: loss: 0.0771690
[Epoch 53; Iter   112/  209] train: loss: 0.1779395
[Epoch 53; Iter   142/  209] train: loss: 0.1171665
[Epoch 53; Iter   172/  209] train: loss: 0.0814405
[Epoch 53; Iter   202/  209] train: loss: 0.1199171
[Epoch 53] ogbg-moltox21: 0.787391 val loss: 0.262150
[Epoch 53] ogbg-moltox21: 0.758977 test loss: 0.277565
[Epoch 54; Iter    23/  209] train: loss: 0.1590797
[Epoch 54; Iter    53/  209] train: loss: 0.0738350
[Epoch 54; Iter    83/  209] train: loss: 0.0851625
[Epoch 54; Iter   113/  209] train: loss: 0.0874013
[Epoch 54; Iter   143/  209] train: loss: 0.1880934
[Epoch 54; Iter   173/  209] train: loss: 0.1122243
[Epoch 54; Iter   203/  209] train: loss: 0.1671208
[Epoch 54] ogbg-moltox21: 0.798088 val loss: 0.287989
[Epoch 54] ogbg-moltox21: 0.763070 test loss: 0.312859
[Epoch 55; Iter    24/  209] train: loss: 0.1030033
[Epoch 55; Iter    54/  209] train: loss: 0.0858309
[Epoch 55; Iter    84/  209] train: loss: 0.1046812
[Epoch 55; Iter   114/  209] train: loss: 0.0724957
[Epoch 55; Iter   144/  209] train: loss: 0.1181027
[Epoch 55; Iter   174/  209] train: loss: 0.1625095
[Epoch 55; Iter   204/  209] train: loss: 0.0869107
[Epoch 55] ogbg-moltox21: 0.789886 val loss: 0.267016
[Epoch 55] ogbg-moltox21: 0.763869 test loss: 0.288510
[Epoch 56; Iter    25/  209] train: loss: 0.1643149
[Epoch 56; Iter    55/  209] train: loss: 0.1288126
[Epoch 56; Iter    85/  209] train: loss: 0.1315593
[Epoch 56; Iter   115/  209] train: loss: 0.0919407
[Epoch 56; Iter   145/  209] train: loss: 0.1012177
[Epoch 56; Iter   175/  209] train: loss: 0.0750228
[Epoch 56; Iter   205/  209] train: loss: 0.1066616
[Epoch 56] ogbg-moltox21: 0.796341 val loss: 0.267719
[Epoch 56] ogbg-moltox21: 0.761179 test loss: 0.292506
[Epoch 57; Iter    26/  209] train: loss: 0.0685624
[Epoch 57; Iter    56/  209] train: loss: 0.0941707
[Epoch 57; Iter    86/  209] train: loss: 0.1602194
[Epoch 57; Iter   116/  209] train: loss: 0.0872868
[Epoch 57; Iter   146/  209] train: loss: 0.1051802
[Epoch 57; Iter   176/  209] train: loss: 0.1043282
[Epoch 57; Iter   206/  209] train: loss: 0.1209697
[Epoch 57] ogbg-moltox21: 0.792461 val loss: 0.272446
[Epoch 57] ogbg-moltox21: 0.761543 test loss: 0.324425
[Epoch 58; Iter    27/  209] train: loss: 0.1179723
[Epoch 58; Iter    57/  209] train: loss: 0.0764171
[Epoch 58; Iter    87/  209] train: loss: 0.0831658
[Epoch 58; Iter   117/  209] train: loss: 0.0819018
[Epoch 58; Iter   147/  209] train: loss: 0.1052919
[Epoch 58; Iter   177/  209] train: loss: 0.0956414
[Epoch 58; Iter   207/  209] train: loss: 0.0870144
[Epoch 58] ogbg-moltox21: 0.786943 val loss: 0.274510
[Epoch 58] ogbg-moltox21: 0.755235 test loss: 0.298624
[Epoch 59; Iter    28/  209] train: loss: 0.0929984
[Epoch 59; Iter    58/  209] train: loss: 0.0941453
[Epoch 59; Iter    88/  209] train: loss: 0.1465131
[Epoch 59; Iter   118/  209] train: loss: 0.1475226
[Epoch 59; Iter   148/  209] train: loss: 0.1454126
[Epoch 59; Iter   178/  209] train: loss: 0.0842060
[Epoch 59; Iter   208/  209] train: loss: 0.1072739
[Epoch 59] ogbg-moltox21: 0.789923 val loss: 0.287611
[Epoch 59] ogbg-moltox21: 0.761181 test loss: 0.307779
[Epoch 60; Iter    29/  209] train: loss: 0.1565021
[Epoch 60; Iter    59/  209] train: loss: 0.1054137
[Epoch 60; Iter    89/  209] train: loss: 0.0923762
[Epoch 60; Iter   119/  209] train: loss: 0.1118852
[Epoch 60; Iter   149/  209] train: loss: 0.0990731
[Epoch 60; Iter   179/  209] train: loss: 0.1808824
[Epoch 60; Iter   209/  209] train: loss: 0.1233981
[Epoch 60] ogbg-moltox21: 0.781971 val loss: 0.290971
[Epoch 60] ogbg-moltox21: 0.762131 test loss: 0.314767
[Epoch 61; Iter    30/  209] train: loss: 0.0942582
[Epoch 61; Iter    60/  209] train: loss: 0.1119602
[Epoch 61; Iter    90/  209] train: loss: 0.1382268
[Epoch 61; Iter   120/  209] train: loss: 0.1115817
[Epoch 61; Iter   150/  209] train: loss: 0.0892753
[Epoch 61; Iter   180/  209] train: loss: 0.0879143
[Epoch 61] ogbg-moltox21: 0.785900 val loss: 0.279417
[Epoch 61] ogbg-moltox21: 0.756721 test loss: 0.302018
[Epoch 62; Iter     1/  209] train: loss: 0.0634828
[Epoch 62; Iter    31/  209] train: loss: 0.0770170
[Epoch 62; Iter    61/  209] train: loss: 0.1023501
[Epoch 62; Iter    91/  209] train: loss: 0.0896840
[Epoch 62; Iter   121/  209] train: loss: 0.1549148
[Epoch 62; Iter   151/  209] train: loss: 0.0658705
[Epoch 62; Iter   181/  209] train: loss: 0.1114300
[Epoch 62] ogbg-moltox21: 0.782575 val loss: 0.293610
[Epoch 62] ogbg-moltox21: 0.758508 test loss: 0.322352
[Epoch 63; Iter     2/  209] train: loss: 0.0998080
[Epoch 63; Iter    32/  209] train: loss: 0.1221006
[Epoch 63; Iter    62/  209] train: loss: 0.0964849
[Epoch 63; Iter    92/  209] train: loss: 0.0933932
[Epoch 63; Iter   122/  209] train: loss: 0.1008485
[Epoch 63; Iter   152/  209] train: loss: 0.0971621
[Epoch 63; Iter   182/  209] train: loss: 0.1009185
[Epoch 63] ogbg-moltox21: 0.784449 val loss: 0.304893
[Epoch 63] ogbg-moltox21: 0.755518 test loss: 0.337074
[Epoch 64; Iter     3/  209] train: loss: 0.0760167
[Epoch 64; Iter    33/  209] train: loss: 0.0894158
[Epoch 64; Iter    63/  209] train: loss: 0.1018244
[Epoch 64; Iter    93/  209] train: loss: 0.0911556
[Epoch 64; Iter   123/  209] train: loss: 0.1316850
[Epoch 64; Iter   153/  209] train: loss: 0.0880442
[Epoch 64; Iter   183/  209] train: loss: 0.1260646
[Epoch 64] ogbg-moltox21: 0.783430 val loss: 0.288796
[Epoch 64] ogbg-moltox21: 0.727415 test loss: 0.446733
[Epoch 65; Iter     4/  209] train: loss: 0.0750203
[Epoch 65; Iter    34/  209] train: loss: 0.0289891
[Epoch 65; Iter    64/  209] train: loss: 0.0739637
[Epoch 65; Iter    94/  209] train: loss: 0.0461040
[Epoch 65; Iter   124/  209] train: loss: 0.0354520
[Epoch 65; Iter   154/  209] train: loss: 0.0626818
[Epoch 65; Iter   184/  209] train: loss: 0.0965575
[Epoch 65] ogbg-moltox21: 0.762200 val loss: 0.399475
[Epoch 65] ogbg-moltox21: 0.719676 test loss: 0.444678
[Epoch 66; Iter     5/  209] train: loss: 0.0522964
[Epoch 66; Iter    35/  209] train: loss: 0.0610636
[Epoch 66; Iter    65/  209] train: loss: 0.0473285
[Epoch 66; Iter    95/  209] train: loss: 0.0546476
[Epoch 66; Iter   125/  209] train: loss: 0.0486532
[Epoch 66; Iter   155/  209] train: loss: 0.0603099
[Epoch 66; Iter   185/  209] train: loss: 0.0397220
[Epoch 66] ogbg-moltox21: 0.765354 val loss: 0.485980
[Epoch 66] ogbg-moltox21: 0.728956 test loss: 0.514180
[Epoch 67; Iter     6/  209] train: loss: 0.0938559
[Epoch 67; Iter    36/  209] train: loss: 0.0640040
[Epoch 67; Iter    66/  209] train: loss: 0.0641446
[Epoch 67; Iter    96/  209] train: loss: 0.0527509
[Epoch 67; Iter   126/  209] train: loss: 0.0329357
[Epoch 67; Iter   156/  209] train: loss: 0.0460681
[Epoch 67; Iter   186/  209] train: loss: 0.0382815
[Epoch 67] ogbg-moltox21: 0.759800 val loss: 0.432543
[Epoch 67] ogbg-moltox21: 0.733696 test loss: 0.468350
[Epoch 68; Iter     7/  209] train: loss: 0.0471431
[Epoch 68; Iter    37/  209] train: loss: 0.0535513
[Epoch 68; Iter    67/  209] train: loss: 0.0442774
[Epoch 68; Iter    97/  209] train: loss: 0.0335341
[Epoch 68; Iter   127/  209] train: loss: 0.0554124
[Epoch 68; Iter   157/  209] train: loss: 0.0418884
[Epoch 68; Iter   187/  209] train: loss: 0.0167809
[Epoch 68] ogbg-moltox21: 0.763292 val loss: 0.417381
[Epoch 68] ogbg-moltox21: 0.728895 test loss: 0.457250
[Epoch 69; Iter     8/  209] train: loss: 0.0379123
[Epoch 69; Iter    38/  209] train: loss: 0.0306477
[Epoch 69; Iter    68/  209] train: loss: 0.0352458
[Epoch 69; Iter    98/  209] train: loss: 0.0297754
[Epoch 69; Iter   128/  209] train: loss: 0.0232820
[Epoch 69; Iter   158/  209] train: loss: 0.0372865
[Epoch 69; Iter   188/  209] train: loss: 0.0284131
[Epoch 69] ogbg-moltox21: 0.762374 val loss: 0.420811
[Epoch 69] ogbg-moltox21: 0.727957 test loss: 0.457959
[Epoch 70; Iter     9/  209] train: loss: 0.0433889
[Epoch 70; Iter    39/  209] train: loss: 0.0161840
[Epoch 70; Iter    69/  209] train: loss: 0.0551933
[Epoch 70; Iter    99/  209] train: loss: 0.0421280
[Epoch 70; Iter   129/  209] train: loss: 0.0318256
[Epoch 70; Iter   159/  209] train: loss: 0.0286536
[Epoch 70; Iter   189/  209] train: loss: 0.0354908
[Epoch 70] ogbg-moltox21: 0.749937 val loss: 0.456680
[Epoch 70] ogbg-moltox21: 0.725812 test loss: 0.495115
[Epoch 71; Iter    10/  209] train: loss: 0.0360992
[Epoch 71; Iter    40/  209] train: loss: 0.0461247
[Epoch 71; Iter    70/  209] train: loss: 0.0350264
[Epoch 71; Iter   100/  209] train: loss: 0.0602828
[Epoch 71; Iter   130/  209] train: loss: 0.0312619
[Epoch 71; Iter   160/  209] train: loss: 0.0201839
[Epoch 71; Iter   190/  209] train: loss: 0.0334691
[Epoch 71] ogbg-moltox21: 0.747704 val loss: 0.450138
[Epoch 71] ogbg-moltox21: 0.727055 test loss: 0.474118
[Epoch 72; Iter    11/  209] train: loss: 0.0531580
[Epoch 72; Iter    41/  209] train: loss: 0.0393388
[Epoch 72; Iter    71/  209] train: loss: 0.0600600
[Epoch 72; Iter   101/  209] train: loss: 0.0645794
[Epoch 72; Iter   131/  209] train: loss: 0.0717522
[Epoch 72; Iter   161/  209] train: loss: 0.0453094
[Epoch 72; Iter   191/  209] train: loss: 0.0271003
[Epoch 72] ogbg-moltox21: 0.753909 val loss: 0.422063
[Epoch 72] ogbg-moltox21: 0.716123 test loss: 0.467389
[Epoch 73; Iter    12/  209] train: loss: 0.0532813
[Epoch 73; Iter    42/  209] train: loss: 0.0241186
[Epoch 73; Iter    72/  209] train: loss: 0.0151261
[Epoch 73; Iter   102/  209] train: loss: 0.0417255
[Epoch 73; Iter   132/  209] train: loss: 0.0483945
[Epoch 73; Iter   162/  209] train: loss: 0.0368388
[Epoch 73; Iter   192/  209] train: loss: 0.0504141
[Epoch 73] ogbg-moltox21: 0.756560 val loss: 0.446504
[Epoch 73] ogbg-moltox21: 0.729924 test loss: 0.489543
[Epoch 74; Iter    13/  209] train: loss: 0.0427883
[Epoch 74; Iter    43/  209] train: loss: 0.0421622
[Epoch 74; Iter    73/  209] train: loss: 0.0245671
[Epoch 74; Iter   103/  209] train: loss: 0.0276168
[Epoch 74; Iter   133/  209] train: loss: 0.0259524
[Epoch 74; Iter   163/  209] train: loss: 0.0277866
[Epoch 74; Iter   193/  209] train: loss: 0.0432157
[Epoch 74] ogbg-moltox21: 0.745749 val loss: 0.473958
[Epoch 74] ogbg-moltox21: 0.715679 test loss: 0.505492
[Epoch 75; Iter    14/  209] train: loss: 0.0275528
[Epoch 75; Iter    44/  209] train: loss: 0.0564299
[Epoch 75; Iter    74/  209] train: loss: 0.0436945
[Epoch 75; Iter   104/  209] train: loss: 0.0287616
[Epoch 75; Iter   134/  209] train: loss: 0.0280219
[Epoch 75; Iter   164/  209] train: loss: 0.0325291
[Epoch 75; Iter   194/  209] train: loss: 0.0474261
[Epoch 75] ogbg-moltox21: 0.758901 val loss: 0.461082
[Epoch 75] ogbg-moltox21: 0.725678 test loss: 0.509853
[Epoch 76; Iter    15/  209] train: loss: 0.0504932
[Epoch 76; Iter    45/  209] train: loss: 0.0165965
[Epoch 76; Iter    75/  209] train: loss: 0.0378476
[Epoch 76; Iter   105/  209] train: loss: 0.0126170
[Epoch 76; Iter   135/  209] train: loss: 0.0299583
[Epoch 76; Iter   165/  209] train: loss: 0.0224713
[Epoch 76; Iter   195/  209] train: loss: 0.0441710
[Epoch 76] ogbg-moltox21: 0.753234 val loss: 0.475832
[Epoch 76] ogbg-moltox21: 0.725165 test loss: 0.512784
[Epoch 77; Iter    16/  209] train: loss: 0.0263670
[Epoch 77; Iter    46/  209] train: loss: 0.0281558
[Epoch 77; Iter    76/  209] train: loss: 0.0233262
[Epoch 77; Iter   106/  209] train: loss: 0.0341847
[Epoch 77; Iter   136/  209] train: loss: 0.0347517
[Epoch 77; Iter   166/  209] train: loss: 0.0265450
[Epoch 77; Iter   196/  209] train: loss: 0.0393391
[Epoch 77] ogbg-moltox21: 0.749040 val loss: 0.473638
[Epoch 77] ogbg-moltox21: 0.720823 test loss: 0.499686
[Epoch 78; Iter    17/  209] train: loss: 0.0289996
[Epoch 78; Iter    47/  209] train: loss: 0.0332388
[Epoch 78; Iter    77/  209] train: loss: 0.0446595
[Epoch 78; Iter   107/  209] train: loss: 0.0871588
[Epoch 78; Iter   137/  209] train: loss: 0.0361269
[Epoch 78; Iter   167/  209] train: loss: 0.1083287
[Epoch 78; Iter   197/  209] train: loss: 0.0232634
[Epoch 78] ogbg-moltox21: 0.753930 val loss: 0.470568
[Epoch 78] ogbg-moltox21: 0.727290 test loss: 0.516004
[Epoch 79; Iter    18/  209] train: loss: 0.1323693
[Epoch 79; Iter    48/  209] train: loss: 0.0373876
[Epoch 79; Iter    78/  209] train: loss: 0.0187973
[Epoch 79; Iter   108/  209] train: loss: 0.0398449
[Epoch 79; Iter   138/  209] train: loss: 0.0253968
[Epoch 79; Iter   168/  209] train: loss: 0.0233946
[Epoch 79; Iter   198/  209] train: loss: 0.0204641
[Epoch 79] ogbg-moltox21: 0.758217 val loss: 0.496534
[Epoch 79] ogbg-moltox21: 0.719173 test loss: 0.531909
[Epoch 80; Iter    19/  209] train: loss: 0.0788834
[Epoch 80; Iter    49/  209] train: loss: 0.0260884
[Epoch 80; Iter    79/  209] train: loss: 0.0120123
[Epoch 80; Iter   109/  209] train: loss: 0.0272931
[Epoch 80; Iter   139/  209] train: loss: 0.0200331
[Epoch 80; Iter   169/  209] train: loss: 0.0379336
[Epoch 80; Iter   199/  209] train: loss: 0.0405760
[Epoch 80] ogbg-moltox21: 0.750357 val loss: 0.472834
[Epoch 80] ogbg-moltox21: 0.728813 test loss: 0.520749
[Epoch 81; Iter    20/  209] train: loss: 0.0227758
[Epoch 81; Iter    50/  209] train: loss: 0.0131327
[Epoch 81; Iter    80/  209] train: loss: 0.0369288
[Epoch 81; Iter   110/  209] train: loss: 0.0164966
[Epoch 81; Iter   140/  209] train: loss: 0.0832296
[Epoch 81; Iter   170/  209] train: loss: 0.1007802
[Epoch 81; Iter   200/  209] train: loss: 0.0453830
[Epoch 81] ogbg-moltox21: 0.744945 val loss: 0.493077
[Epoch 81] ogbg-moltox21: 0.725089 test loss: 0.512797
[Epoch 82; Iter    21/  209] train: loss: 0.0262461
[Epoch 64] ogbg-moltox21: 0.745993 test loss: 0.364650
[Epoch 65; Iter     4/  209] train: loss: 0.0467590
[Epoch 65; Iter    34/  209] train: loss: 0.0639777
[Epoch 65; Iter    64/  209] train: loss: 0.0577470
[Epoch 65; Iter    94/  209] train: loss: 0.0575387
[Epoch 65; Iter   124/  209] train: loss: 0.0546601
[Epoch 65; Iter   154/  209] train: loss: 0.0443538
[Epoch 65; Iter   184/  209] train: loss: 0.0814809
[Epoch 65] ogbg-moltox21: 0.774988 val loss: 0.369698
[Epoch 65] ogbg-moltox21: 0.742127 test loss: 0.381249
[Epoch 66; Iter     5/  209] train: loss: 0.0286755
[Epoch 66; Iter    35/  209] train: loss: 0.0687911
[Epoch 66; Iter    65/  209] train: loss: 0.0443860
[Epoch 66; Iter    95/  209] train: loss: 0.0512599
[Epoch 66; Iter   125/  209] train: loss: 0.0363783
[Epoch 66; Iter   155/  209] train: loss: 0.0412790
[Epoch 66; Iter   185/  209] train: loss: 0.0247310
[Epoch 66] ogbg-moltox21: 0.767914 val loss: 0.370300
[Epoch 66] ogbg-moltox21: 0.737345 test loss: 0.376624
[Epoch 67; Iter     6/  209] train: loss: 0.0419174
[Epoch 67; Iter    36/  209] train: loss: 0.0496765
[Epoch 67; Iter    66/  209] train: loss: 0.0433767
[Epoch 67; Iter    96/  209] train: loss: 0.0488296
[Epoch 67; Iter   126/  209] train: loss: 0.0324584
[Epoch 67; Iter   156/  209] train: loss: 0.0503929
[Epoch 67; Iter   186/  209] train: loss: 0.0586097
[Epoch 67] ogbg-moltox21: 0.777256 val loss: 0.371330
[Epoch 67] ogbg-moltox21: 0.742882 test loss: 0.382878
[Epoch 68; Iter     7/  209] train: loss: 0.0202848
[Epoch 68; Iter    37/  209] train: loss: 0.0314614
[Epoch 68; Iter    67/  209] train: loss: 0.1148217
[Epoch 68; Iter    97/  209] train: loss: 0.0478792
[Epoch 68; Iter   127/  209] train: loss: 0.0553690
[Epoch 68; Iter   157/  209] train: loss: 0.0459389
[Epoch 68; Iter   187/  209] train: loss: 0.0670077
[Epoch 68] ogbg-moltox21: 0.777805 val loss: 0.388417
[Epoch 68] ogbg-moltox21: 0.743976 test loss: 0.407580
[Epoch 69; Iter     8/  209] train: loss: 0.0534752
[Epoch 69; Iter    38/  209] train: loss: 0.0617793
[Epoch 69; Iter    68/  209] train: loss: 0.0377667
[Epoch 69; Iter    98/  209] train: loss: 0.0514270
[Epoch 69; Iter   128/  209] train: loss: 0.0971856
[Epoch 69; Iter   158/  209] train: loss: 0.0520925
[Epoch 69; Iter   188/  209] train: loss: 0.0902540
[Epoch 69] ogbg-moltox21: 0.779408 val loss: 0.394266
[Epoch 69] ogbg-moltox21: 0.742397 test loss: 0.402636
[Epoch 70; Iter     9/  209] train: loss: 0.0648376
[Epoch 70; Iter    39/  209] train: loss: 0.0664915
[Epoch 70; Iter    69/  209] train: loss: 0.0979034
[Epoch 70; Iter    99/  209] train: loss: 0.0668359
[Epoch 70; Iter   129/  209] train: loss: 0.0472705
[Epoch 70; Iter   159/  209] train: loss: 0.0569964
[Epoch 70; Iter   189/  209] train: loss: 0.0431468
[Epoch 70] ogbg-moltox21: 0.772528 val loss: 0.381775
[Epoch 70] ogbg-moltox21: 0.742419 test loss: 0.398427
[Epoch 71; Iter    10/  209] train: loss: 0.0355665
[Epoch 71; Iter    40/  209] train: loss: 0.0638401
[Epoch 71; Iter    70/  209] train: loss: 0.0356957
[Epoch 71; Iter   100/  209] train: loss: 0.0846465
[Epoch 71; Iter   130/  209] train: loss: 0.0501277
[Epoch 71; Iter   160/  209] train: loss: 0.0531669
[Epoch 71; Iter   190/  209] train: loss: 0.0505308
[Epoch 71] ogbg-moltox21: 0.777383 val loss: 0.379967
[Epoch 71] ogbg-moltox21: 0.740328 test loss: 0.406539
[Epoch 72; Iter    11/  209] train: loss: 0.0518627
[Epoch 72; Iter    41/  209] train: loss: 0.0372499
[Epoch 72; Iter    71/  209] train: loss: 0.0288411
[Epoch 72; Iter   101/  209] train: loss: 0.0405788
[Epoch 72; Iter   131/  209] train: loss: 0.0329571
[Epoch 72; Iter   161/  209] train: loss: 0.0795699
[Epoch 72; Iter   191/  209] train: loss: 0.0683496
[Epoch 72] ogbg-moltox21: 0.775000 val loss: 0.393356
[Epoch 72] ogbg-moltox21: 0.733411 test loss: 0.411617
[Epoch 73; Iter    12/  209] train: loss: 0.0287685
[Epoch 73; Iter    42/  209] train: loss: 0.0682107
[Epoch 73; Iter    72/  209] train: loss: 0.0622327
[Epoch 73; Iter   102/  209] train: loss: 0.0407044
[Epoch 73; Iter   132/  209] train: loss: 0.0555999
[Epoch 73; Iter   162/  209] train: loss: 0.0316870
[Epoch 73; Iter   192/  209] train: loss: 0.0319787
[Epoch 73] ogbg-moltox21: 0.775696 val loss: 0.406239
[Epoch 73] ogbg-moltox21: 0.737286 test loss: 0.420887
[Epoch 74; Iter    13/  209] train: loss: 0.0477847
[Epoch 74; Iter    43/  209] train: loss: 0.0427623
[Epoch 74; Iter    73/  209] train: loss: 0.0852739
[Epoch 74; Iter   103/  209] train: loss: 0.0424093
[Epoch 74; Iter   133/  209] train: loss: 0.0332742
[Epoch 74; Iter   163/  209] train: loss: 0.0901811
[Epoch 74; Iter   193/  209] train: loss: 0.0292127
[Epoch 74] ogbg-moltox21: 0.776818 val loss: 0.396898
[Epoch 74] ogbg-moltox21: 0.737173 test loss: 0.427770
[Epoch 75; Iter    14/  209] train: loss: 0.0421123
[Epoch 75; Iter    44/  209] train: loss: 0.0369053
[Epoch 75; Iter    74/  209] train: loss: 0.0291400
[Epoch 75; Iter   104/  209] train: loss: 0.0740739
[Epoch 75; Iter   134/  209] train: loss: 0.0684477
[Epoch 75; Iter   164/  209] train: loss: 0.0495997
[Epoch 75; Iter   194/  209] train: loss: 0.0165562
[Epoch 75] ogbg-moltox21: 0.770715 val loss: 0.414449
[Epoch 75] ogbg-moltox21: 0.738285 test loss: 0.435377
[Epoch 76; Iter    15/  209] train: loss: 0.0598168
[Epoch 76; Iter    45/  209] train: loss: 0.0459125
[Epoch 76; Iter    75/  209] train: loss: 0.0302858
[Epoch 76; Iter   105/  209] train: loss: 0.0561907
[Epoch 76; Iter   135/  209] train: loss: 0.0467411
[Epoch 76; Iter   165/  209] train: loss: 0.0652304
[Epoch 76; Iter   195/  209] train: loss: 0.0372512
[Epoch 76] ogbg-moltox21: 0.773036 val loss: 0.402176
[Epoch 76] ogbg-moltox21: 0.735853 test loss: 0.430191
[Epoch 77; Iter    16/  209] train: loss: 0.0246830
[Epoch 77; Iter    46/  209] train: loss: 0.0330540
[Epoch 77; Iter    76/  209] train: loss: 0.0203545
[Epoch 77; Iter   106/  209] train: loss: 0.0467679
[Epoch 77; Iter   136/  209] train: loss: 0.0336489
[Epoch 77; Iter   166/  209] train: loss: 0.0975497
[Epoch 77; Iter   196/  209] train: loss: 0.0166839
[Epoch 77] ogbg-moltox21: 0.772014 val loss: 0.407651
[Epoch 77] ogbg-moltox21: 0.736228 test loss: 0.431199
[Epoch 78; Iter    17/  209] train: loss: 0.1187851
[Epoch 78; Iter    47/  209] train: loss: 0.0459591
[Epoch 78; Iter    77/  209] train: loss: 0.1305443
[Epoch 78; Iter   107/  209] train: loss: 0.0589737
[Epoch 78; Iter   137/  209] train: loss: 0.0379707
[Epoch 78; Iter   167/  209] train: loss: 0.0382068
[Epoch 78; Iter   197/  209] train: loss: 0.0361535
[Epoch 78] ogbg-moltox21: 0.766232 val loss: 0.420478
[Epoch 78] ogbg-moltox21: 0.731411 test loss: 0.436417
[Epoch 79; Iter    18/  209] train: loss: 0.0428800
[Epoch 79; Iter    48/  209] train: loss: 0.0436757
[Epoch 79; Iter    78/  209] train: loss: 0.0670659
[Epoch 79; Iter   108/  209] train: loss: 0.0475287
[Epoch 79; Iter   138/  209] train: loss: 0.0439254
[Epoch 79; Iter   168/  209] train: loss: 0.0345532
[Epoch 79; Iter   198/  209] train: loss: 0.0414443
[Epoch 79] ogbg-moltox21: 0.771174 val loss: 0.414110
[Epoch 79] ogbg-moltox21: 0.727190 test loss: 0.445271
[Epoch 80; Iter    19/  209] train: loss: 0.0360218
[Epoch 80; Iter    49/  209] train: loss: 0.0293575
[Epoch 80; Iter    79/  209] train: loss: 0.0824248
[Epoch 80; Iter   109/  209] train: loss: 0.0593809
[Epoch 80; Iter   139/  209] train: loss: 0.0734056
[Epoch 80; Iter   169/  209] train: loss: 0.0249222
[Epoch 80; Iter   199/  209] train: loss: 0.0556223
[Epoch 80] ogbg-moltox21: 0.773185 val loss: 0.402277
[Epoch 80] ogbg-moltox21: 0.727607 test loss: 0.435505
[Epoch 81; Iter    20/  209] train: loss: 0.0355285
[Epoch 81; Iter    50/  209] train: loss: 0.0484073
[Epoch 81; Iter    80/  209] train: loss: 0.0375092
[Epoch 81; Iter   110/  209] train: loss: 0.0415850
[Epoch 81; Iter   140/  209] train: loss: 0.0365451
[Epoch 81; Iter   170/  209] train: loss: 0.0373561
[Epoch 81; Iter   200/  209] train: loss: 0.0327762
[Epoch 81] ogbg-moltox21: 0.773873 val loss: 0.409776
[Epoch 81] ogbg-moltox21: 0.731499 test loss: 0.443853
[Epoch 82; Iter    21/  209] train: loss: 0.0327717
[Epoch 47; Iter   166/  209] train: loss: 0.0669342
[Epoch 47; Iter   196/  209] train: loss: 0.1423058
[Epoch 47] ogbg-moltox21: 0.788641 val loss: 0.263679
[Epoch 47] ogbg-moltox21: 0.760830 test loss: 0.269970
[Epoch 48; Iter    17/  209] train: loss: 0.1872884
[Epoch 48; Iter    47/  209] train: loss: 0.1189507
[Epoch 48; Iter    77/  209] train: loss: 0.1547837
[Epoch 48; Iter   107/  209] train: loss: 0.1172754
[Epoch 48; Iter   137/  209] train: loss: 0.1554066
[Epoch 48; Iter   167/  209] train: loss: 0.1125740
[Epoch 48; Iter   197/  209] train: loss: 0.0983187
[Epoch 48] ogbg-moltox21: 0.795205 val loss: 0.270342
[Epoch 48] ogbg-moltox21: 0.764394 test loss: 0.279647
[Epoch 49; Iter    18/  209] train: loss: 0.1607754
[Epoch 49; Iter    48/  209] train: loss: 0.1496627
[Epoch 49; Iter    78/  209] train: loss: 0.0976699
[Epoch 49; Iter   108/  209] train: loss: 0.0740401
[Epoch 49; Iter   138/  209] train: loss: 0.1510715
[Epoch 49; Iter   168/  209] train: loss: 0.1452175
[Epoch 49; Iter   198/  209] train: loss: 0.1267440
[Epoch 49] ogbg-moltox21: 0.782114 val loss: 0.272920
[Epoch 49] ogbg-moltox21: 0.752234 test loss: 0.281790
[Epoch 50; Iter    19/  209] train: loss: 0.1128192
[Epoch 50; Iter    49/  209] train: loss: 0.0975714
[Epoch 50; Iter    79/  209] train: loss: 0.1732876
[Epoch 50; Iter   109/  209] train: loss: 0.1126382
[Epoch 50; Iter   139/  209] train: loss: 0.1163078
[Epoch 50; Iter   169/  209] train: loss: 0.1167553
[Epoch 50; Iter   199/  209] train: loss: 0.1722177
[Epoch 50] ogbg-moltox21: 0.785247 val loss: 0.272354
[Epoch 50] ogbg-moltox21: 0.759532 test loss: 0.283522
[Epoch 51; Iter    20/  209] train: loss: 0.1125665
[Epoch 51; Iter    50/  209] train: loss: 0.1008048
[Epoch 51; Iter    80/  209] train: loss: 0.0663911
[Epoch 51; Iter   110/  209] train: loss: 0.1206909
[Epoch 51; Iter   140/  209] train: loss: 0.1495709
[Epoch 51; Iter   170/  209] train: loss: 0.1237248
[Epoch 51; Iter   200/  209] train: loss: 0.0691361
[Epoch 51] ogbg-moltox21: 0.780444 val loss: 0.283641
[Epoch 51] ogbg-moltox21: 0.758489 test loss: 0.286509
[Epoch 52; Iter    21/  209] train: loss: 0.1570411
[Epoch 52; Iter    51/  209] train: loss: 0.0910038
[Epoch 52; Iter    81/  209] train: loss: 0.0827658
[Epoch 52; Iter   111/  209] train: loss: 0.1224343
[Epoch 52; Iter   141/  209] train: loss: 0.0930298
[Epoch 52; Iter   171/  209] train: loss: 0.1165056
[Epoch 52; Iter   201/  209] train: loss: 0.1787560
[Epoch 52] ogbg-moltox21: 0.780533 val loss: 0.291082
[Epoch 52] ogbg-moltox21: 0.761528 test loss: 0.297544
[Epoch 53; Iter    22/  209] train: loss: 0.0777380
[Epoch 53; Iter    52/  209] train: loss: 0.0856261
[Epoch 53; Iter    82/  209] train: loss: 0.1376890
[Epoch 53; Iter   112/  209] train: loss: 0.0813062
[Epoch 53; Iter   142/  209] train: loss: 0.0978242
[Epoch 53; Iter   172/  209] train: loss: 0.0977083
[Epoch 53; Iter   202/  209] train: loss: 0.1635687
[Epoch 53] ogbg-moltox21: 0.786922 val loss: 0.285294
[Epoch 53] ogbg-moltox21: 0.756210 test loss: 0.300170
[Epoch 54; Iter    23/  209] train: loss: 0.0860860
[Epoch 54; Iter    53/  209] train: loss: 0.0835316
[Epoch 54; Iter    83/  209] train: loss: 0.1050912
[Epoch 54; Iter   113/  209] train: loss: 0.1262030
[Epoch 54; Iter   143/  209] train: loss: 0.1534496
[Epoch 54; Iter   173/  209] train: loss: 0.1351745
[Epoch 54; Iter   203/  209] train: loss: 0.1018429
[Epoch 54] ogbg-moltox21: 0.791277 val loss: 0.284091
[Epoch 54] ogbg-moltox21: 0.744725 test loss: 0.293429
[Epoch 55; Iter    24/  209] train: loss: 0.0776473
[Epoch 55; Iter    54/  209] train: loss: 0.0693870
[Epoch 55; Iter    84/  209] train: loss: 0.0805297
[Epoch 55; Iter   114/  209] train: loss: 0.1053866
[Epoch 55; Iter   144/  209] train: loss: 0.0808597
[Epoch 55; Iter   174/  209] train: loss: 0.0940494
[Epoch 55; Iter   204/  209] train: loss: 0.0538796
[Epoch 55] ogbg-moltox21: 0.784705 val loss: 0.282270
[Epoch 55] ogbg-moltox21: 0.752079 test loss: 0.293109
[Epoch 56; Iter    25/  209] train: loss: 0.1312398
[Epoch 56; Iter    55/  209] train: loss: 0.0997563
[Epoch 56; Iter    85/  209] train: loss: 0.1118589
[Epoch 56; Iter   115/  209] train: loss: 0.0702927
[Epoch 56; Iter   145/  209] train: loss: 0.0635599
[Epoch 56; Iter   175/  209] train: loss: 0.1030335
[Epoch 56; Iter   205/  209] train: loss: 0.1074363
[Epoch 56] ogbg-moltox21: 0.779034 val loss: 0.299615
[Epoch 56] ogbg-moltox21: 0.752689 test loss: 0.304123
[Epoch 57; Iter    26/  209] train: loss: 0.0989144
[Epoch 57; Iter    56/  209] train: loss: 0.1194649
[Epoch 57; Iter    86/  209] train: loss: 0.1273465
[Epoch 57; Iter   116/  209] train: loss: 0.0865943
[Epoch 57; Iter   146/  209] train: loss: 0.1285059
[Epoch 57; Iter   176/  209] train: loss: 0.1014031
[Epoch 57; Iter   206/  209] train: loss: 0.1164769
[Epoch 57] ogbg-moltox21: 0.774575 val loss: 0.345024
[Epoch 57] ogbg-moltox21: 0.741912 test loss: 0.305659
[Epoch 58; Iter    27/  209] train: loss: 0.0857391
[Epoch 58; Iter    57/  209] train: loss: 0.0594820
[Epoch 58; Iter    87/  209] train: loss: 0.1112024
[Epoch 58; Iter   117/  209] train: loss: 0.1149326
[Epoch 58; Iter   147/  209] train: loss: 0.0921706
[Epoch 58; Iter   177/  209] train: loss: 0.0854350
[Epoch 58; Iter   207/  209] train: loss: 0.1036856
[Epoch 58] ogbg-moltox21: 0.767599 val loss: 0.315377
[Epoch 58] ogbg-moltox21: 0.756744 test loss: 0.318109
[Epoch 59; Iter    28/  209] train: loss: 0.1173682
[Epoch 59; Iter    58/  209] train: loss: 0.0653823
[Epoch 59; Iter    88/  209] train: loss: 0.1364868
[Epoch 59; Iter   118/  209] train: loss: 0.0692628
[Epoch 59; Iter   148/  209] train: loss: 0.1578849
[Epoch 59; Iter   178/  209] train: loss: 0.0966958
[Epoch 59; Iter   208/  209] train: loss: 0.0828214
[Epoch 59] ogbg-moltox21: 0.784676 val loss: 0.286304
[Epoch 59] ogbg-moltox21: 0.752932 test loss: 0.300195
[Epoch 60; Iter    29/  209] train: loss: 0.0889625
[Epoch 60; Iter    59/  209] train: loss: 0.0517478
[Epoch 60; Iter    89/  209] train: loss: 0.1014754
[Epoch 60; Iter   119/  209] train: loss: 0.1203776
[Epoch 60; Iter   149/  209] train: loss: 0.0792137
[Epoch 60; Iter   179/  209] train: loss: 0.0871789
[Epoch 60; Iter   209/  209] train: loss: 0.0878161
[Epoch 60] ogbg-moltox21: 0.779639 val loss: 0.295778
[Epoch 60] ogbg-moltox21: 0.749467 test loss: 0.316957
[Epoch 61; Iter    30/  209] train: loss: 0.0973361
[Epoch 61; Iter    60/  209] train: loss: 0.1004236
[Epoch 61; Iter    90/  209] train: loss: 0.1334098
[Epoch 61; Iter   120/  209] train: loss: 0.0844392
[Epoch 61; Iter   150/  209] train: loss: 0.1922644
[Epoch 61; Iter   180/  209] train: loss: 0.1588814
[Epoch 61] ogbg-moltox21: 0.773416 val loss: 0.294992
[Epoch 61] ogbg-moltox21: 0.739620 test loss: 0.317029
[Epoch 62; Iter     1/  209] train: loss: 0.1348692
[Epoch 62; Iter    31/  209] train: loss: 0.0682922
[Epoch 62; Iter    61/  209] train: loss: 0.0570754
[Epoch 62; Iter    91/  209] train: loss: 0.1049241
[Epoch 62; Iter   121/  209] train: loss: 0.0988072
[Epoch 62; Iter   151/  209] train: loss: 0.0546439
[Epoch 62; Iter   181/  209] train: loss: 0.0719569
[Epoch 62] ogbg-moltox21: 0.775541 val loss: 0.294813
[Epoch 62] ogbg-moltox21: 0.743776 test loss: 0.309957
[Epoch 63; Iter     2/  209] train: loss: 0.0779505
[Epoch 63; Iter    32/  209] train: loss: 0.1094166
[Epoch 63; Iter    62/  209] train: loss: 0.0875811
[Epoch 63; Iter    92/  209] train: loss: 0.0843287
[Epoch 63; Iter   122/  209] train: loss: 0.0618441
[Epoch 63; Iter   152/  209] train: loss: 0.0618399
[Epoch 63; Iter   182/  209] train: loss: 0.0851422
[Epoch 63] ogbg-moltox21: 0.786203 val loss: 0.299617
[Epoch 63] ogbg-moltox21: 0.751023 test loss: 0.316134
[Epoch 64; Iter     3/  209] train: loss: 0.1104052
[Epoch 64; Iter    33/  209] train: loss: 0.0952802
[Epoch 64; Iter    63/  209] train: loss: 0.0816713
[Epoch 64; Iter    93/  209] train: loss: 0.0791011
[Epoch 64; Iter   123/  209] train: loss: 0.1129719
[Epoch 64; Iter   153/  209] train: loss: 0.0962377
[Epoch 64; Iter   183/  209] train: loss: 0.1728267
[Epoch 64] ogbg-moltox21: 0.781756 val loss: 0.297649
[Epoch 64] ogbg-moltox21: 0.698005 test loss: 0.643303
[Epoch 65; Iter     4/  209] train: loss: 0.0352935
[Epoch 65; Iter    34/  209] train: loss: 0.0055869
[Epoch 65; Iter    64/  209] train: loss: 0.0304678
[Epoch 65; Iter    94/  209] train: loss: 0.0226660
[Epoch 65; Iter   124/  209] train: loss: 0.0315027
[Epoch 65; Iter   154/  209] train: loss: 0.0426907
[Epoch 65; Iter   184/  209] train: loss: 0.0404883
[Epoch 65] ogbg-moltox21: 0.716470 val loss: 0.612079
[Epoch 65] ogbg-moltox21: 0.702878 test loss: 0.641688
[Epoch 66; Iter     5/  209] train: loss: 0.0290511
[Epoch 66; Iter    35/  209] train: loss: 0.0228260
[Epoch 66; Iter    65/  209] train: loss: 0.0428601
[Epoch 66; Iter    95/  209] train: loss: 0.0216498
[Epoch 66; Iter   125/  209] train: loss: 0.0258159
[Epoch 66; Iter   155/  209] train: loss: 0.0112646
[Epoch 66; Iter   185/  209] train: loss: 0.0152866
[Epoch 66] ogbg-moltox21: 0.726578 val loss: 0.589370
[Epoch 66] ogbg-moltox21: 0.695112 test loss: 0.643943
[Epoch 67; Iter     6/  209] train: loss: 0.0494022
[Epoch 67; Iter    36/  209] train: loss: 0.0245734
[Epoch 67; Iter    66/  209] train: loss: 0.0210274
[Epoch 67; Iter    96/  209] train: loss: 0.0255386
[Epoch 67; Iter   126/  209] train: loss: 0.0125178
[Epoch 67; Iter   156/  209] train: loss: 0.0455297
[Epoch 67; Iter   186/  209] train: loss: 0.0314422
[Epoch 67] ogbg-moltox21: 0.727915 val loss: 0.613376
[Epoch 67] ogbg-moltox21: 0.694614 test loss: 0.674644
[Epoch 68; Iter     7/  209] train: loss: 0.0279860
[Epoch 68; Iter    37/  209] train: loss: 0.0383312
[Epoch 68; Iter    67/  209] train: loss: 0.0237105
[Epoch 68; Iter    97/  209] train: loss: 0.0259226
[Epoch 68; Iter   127/  209] train: loss: 0.0282984
[Epoch 68; Iter   157/  209] train: loss: 0.0163003
[Epoch 68; Iter   187/  209] train: loss: 0.0156754
[Epoch 68] ogbg-moltox21: 0.724246 val loss: 0.645255
[Epoch 68] ogbg-moltox21: 0.703746 test loss: 0.684535
[Epoch 69; Iter     8/  209] train: loss: 0.0320399
[Epoch 69; Iter    38/  209] train: loss: 0.0121206
[Epoch 69; Iter    68/  209] train: loss: 0.0207577
[Epoch 69; Iter    98/  209] train: loss: 0.0071415
[Epoch 69; Iter   128/  209] train: loss: 0.0084932
[Epoch 69; Iter   158/  209] train: loss: 0.0363015
[Epoch 69; Iter   188/  209] train: loss: 0.0139967
[Epoch 69] ogbg-moltox21: 0.724521 val loss: 0.626950
[Epoch 69] ogbg-moltox21: 0.702392 test loss: 0.672709
[Epoch 70; Iter     9/  209] train: loss: 0.0179925
[Epoch 70; Iter    39/  209] train: loss: 0.0151677
[Epoch 70; Iter    69/  209] train: loss: 0.0404676
[Epoch 70; Iter    99/  209] train: loss: 0.0191503
[Epoch 70; Iter   129/  209] train: loss: 0.0179522
[Epoch 70; Iter   159/  209] train: loss: 0.0185033
[Epoch 70; Iter   189/  209] train: loss: 0.0215518
[Epoch 70] ogbg-moltox21: 0.730836 val loss: 0.624822
[Epoch 70] ogbg-moltox21: 0.700440 test loss: 0.678706
[Epoch 71; Iter    10/  209] train: loss: 0.0186818
[Epoch 71; Iter    40/  209] train: loss: 0.0278282
[Epoch 71; Iter    70/  209] train: loss: 0.0101205
[Epoch 71; Iter   100/  209] train: loss: 0.0276238
[Epoch 71; Iter   130/  209] train: loss: 0.0149694
[Epoch 71; Iter   160/  209] train: loss: 0.0112658
[Epoch 71; Iter   190/  209] train: loss: 0.0295214
[Epoch 71] ogbg-moltox21: 0.724229 val loss: 0.638090
[Epoch 71] ogbg-moltox21: 0.701768 test loss: 0.669998
[Epoch 72; Iter    11/  209] train: loss: 0.0245631
[Epoch 72; Iter    41/  209] train: loss: 0.0265405
[Epoch 72; Iter    71/  209] train: loss: 0.0520702
[Epoch 72; Iter   101/  209] train: loss: 0.0471783
[Epoch 72; Iter   131/  209] train: loss: 0.0225856
[Epoch 72; Iter   161/  209] train: loss: 0.0218254
[Epoch 72; Iter   191/  209] train: loss: 0.0089832
[Epoch 72] ogbg-moltox21: 0.721960 val loss: 0.688732
[Epoch 72] ogbg-moltox21: 0.700468 test loss: 0.728446
[Epoch 73; Iter    12/  209] train: loss: 0.0223607
[Epoch 73; Iter    42/  209] train: loss: 0.0129236
[Epoch 73; Iter    72/  209] train: loss: 0.0167367
[Epoch 73; Iter   102/  209] train: loss: 0.0379855
[Epoch 73; Iter   132/  209] train: loss: 0.0307398
[Epoch 73; Iter   162/  209] train: loss: 0.0144166
[Epoch 73; Iter   192/  209] train: loss: 0.0301319
[Epoch 73] ogbg-moltox21: 0.714112 val loss: 0.693203
[Epoch 73] ogbg-moltox21: 0.688190 test loss: 0.748598
[Epoch 74; Iter    13/  209] train: loss: 0.0198960
[Epoch 74; Iter    43/  209] train: loss: 0.0226662
[Epoch 74; Iter    73/  209] train: loss: 0.0147038
[Epoch 74; Iter   103/  209] train: loss: 0.0264312
[Epoch 74; Iter   133/  209] train: loss: 0.0133593
[Epoch 74; Iter   163/  209] train: loss: 0.0102227
[Epoch 74; Iter   193/  209] train: loss: 0.0262222
[Epoch 74] ogbg-moltox21: 0.724635 val loss: 0.653245
[Epoch 74] ogbg-moltox21: 0.686432 test loss: 0.723831
[Epoch 75; Iter    14/  209] train: loss: 0.0108493
[Epoch 75; Iter    44/  209] train: loss: 0.0307163
[Epoch 75; Iter    74/  209] train: loss: 0.0252657
[Epoch 75; Iter   104/  209] train: loss: 0.0187665
[Epoch 75; Iter   134/  209] train: loss: 0.0158089
[Epoch 75; Iter   164/  209] train: loss: 0.0171226
[Epoch 75; Iter   194/  209] train: loss: 0.0172995
[Epoch 75] ogbg-moltox21: 0.718280 val loss: 0.754114
[Epoch 75] ogbg-moltox21: 0.678574 test loss: 0.826624
[Epoch 76; Iter    15/  209] train: loss: 0.0180552
[Epoch 76; Iter    45/  209] train: loss: 0.0106489
[Epoch 76; Iter    75/  209] train: loss: 0.0219313
[Epoch 76; Iter   105/  209] train: loss: 0.0088047
[Epoch 76; Iter   135/  209] train: loss: 0.0193112
[Epoch 76; Iter   165/  209] train: loss: 0.0060013
[Epoch 76; Iter   195/  209] train: loss: 0.0148945
[Epoch 76] ogbg-moltox21: 0.729956 val loss: 0.656158
[Epoch 76] ogbg-moltox21: 0.697125 test loss: 0.717971
[Epoch 77; Iter    16/  209] train: loss: 0.0172007
[Epoch 77; Iter    46/  209] train: loss: 0.0133939
[Epoch 77; Iter    76/  209] train: loss: 0.0138454
[Epoch 77; Iter   106/  209] train: loss: 0.0064396
[Epoch 77; Iter   136/  209] train: loss: 0.0182675
[Epoch 77; Iter   166/  209] train: loss: 0.0217752
[Epoch 77; Iter   196/  209] train: loss: 0.0354668
[Epoch 77] ogbg-moltox21: 0.727700 val loss: 0.699199
[Epoch 77] ogbg-moltox21: 0.695869 test loss: 0.760128
[Epoch 78; Iter    17/  209] train: loss: 0.0092887
[Epoch 78; Iter    47/  209] train: loss: 0.0064525
[Epoch 78; Iter    77/  209] train: loss: 0.0199671
[Epoch 78; Iter   107/  209] train: loss: 0.0504892
[Epoch 78; Iter   137/  209] train: loss: 0.0128903
[Epoch 78; Iter   167/  209] train: loss: 0.0475264
[Epoch 78; Iter   197/  209] train: loss: 0.0040259
[Epoch 78] ogbg-moltox21: 0.729113 val loss: 0.683415
[Epoch 78] ogbg-moltox21: 0.696255 test loss: 0.741200
[Epoch 79; Iter    18/  209] train: loss: 0.0524547
[Epoch 79; Iter    48/  209] train: loss: 0.0106270
[Epoch 79; Iter    78/  209] train: loss: 0.0052382
[Epoch 79; Iter   108/  209] train: loss: 0.0294623
[Epoch 79; Iter   138/  209] train: loss: 0.0054279
[Epoch 79; Iter   168/  209] train: loss: 0.0071971
[Epoch 79; Iter   198/  209] train: loss: 0.0099528
[Epoch 79] ogbg-moltox21: 0.727563 val loss: 0.680962
[Epoch 79] ogbg-moltox21: 0.696603 test loss: 0.741282
[Epoch 80; Iter    19/  209] train: loss: 0.0455354
[Epoch 80; Iter    49/  209] train: loss: 0.0075108
[Epoch 80; Iter    79/  209] train: loss: 0.0032192
[Epoch 80; Iter   109/  209] train: loss: 0.0071007
[Epoch 80; Iter   139/  209] train: loss: 0.0053168
[Epoch 80; Iter   169/  209] train: loss: 0.0226091
[Epoch 80; Iter   199/  209] train: loss: 0.0071861
[Epoch 80] ogbg-moltox21: 0.723678 val loss: 0.710220
[Epoch 80] ogbg-moltox21: 0.693326 test loss: 0.778736
[Epoch 81; Iter    20/  209] train: loss: 0.0053210
[Epoch 81; Iter    50/  209] train: loss: 0.0155528
[Epoch 81; Iter    80/  209] train: loss: 0.0178269
[Epoch 81; Iter   110/  209] train: loss: 0.0069332
[Epoch 81; Iter   140/  209] train: loss: 0.0037594
[Epoch 81; Iter   170/  209] train: loss: 0.0281231
[Epoch 81; Iter   200/  209] train: loss: 0.0087896
[Epoch 81] ogbg-moltox21: 0.721880 val loss: 0.721317
[Epoch 81] ogbg-moltox21: 0.688160 test loss: 0.783179
[Epoch 82; Iter    21/  209] train: loss: 0.0071113
[Epoch 64] ogbg-moltox21: 0.657620 test loss: 0.648965
[Epoch 65; Iter     4/  209] train: loss: 0.0762194
[Epoch 65; Iter    34/  209] train: loss: 0.0557812
[Epoch 65; Iter    64/  209] train: loss: 0.0598608
[Epoch 65; Iter    94/  209] train: loss: 0.0876478
[Epoch 65; Iter   124/  209] train: loss: 0.0762179
[Epoch 65; Iter   154/  209] train: loss: 0.0324080
[Epoch 65; Iter   184/  209] train: loss: 0.0404469
[Epoch 65] ogbg-moltox21: 0.694303 val loss: 1.388170
[Epoch 65] ogbg-moltox21: 0.651207 test loss: 0.698142
[Epoch 66; Iter     5/  209] train: loss: 0.0451499
[Epoch 66; Iter    35/  209] train: loss: 0.0578653
[Epoch 66; Iter    65/  209] train: loss: 0.0298823
[Epoch 66; Iter    95/  209] train: loss: 0.0296224
[Epoch 66; Iter   125/  209] train: loss: 0.0666278
[Epoch 66; Iter   155/  209] train: loss: 0.0440153
[Epoch 66; Iter   185/  209] train: loss: 0.0487253
[Epoch 66] ogbg-moltox21: 0.677385 val loss: 0.902933
[Epoch 66] ogbg-moltox21: 0.639343 test loss: 0.889259
[Epoch 67; Iter     6/  209] train: loss: 0.0450624
[Epoch 67; Iter    36/  209] train: loss: 0.0308088
[Epoch 67; Iter    66/  209] train: loss: 0.0263448
[Epoch 67; Iter    96/  209] train: loss: 0.0414074
[Epoch 67; Iter   126/  209] train: loss: 0.0683802
[Epoch 67; Iter   156/  209] train: loss: 0.0520738
[Epoch 67; Iter   186/  209] train: loss: 0.0514716
[Epoch 67] ogbg-moltox21: 0.680475 val loss: 1.461024
[Epoch 67] ogbg-moltox21: 0.653969 test loss: 0.796551
[Epoch 68; Iter     7/  209] train: loss: 0.0334980
[Epoch 68; Iter    37/  209] train: loss: 0.0376455
[Epoch 68; Iter    67/  209] train: loss: 0.0431218
[Epoch 68; Iter    97/  209] train: loss: 0.0639945
[Epoch 68; Iter   127/  209] train: loss: 0.0519034
[Epoch 68; Iter   157/  209] train: loss: 0.0372541
[Epoch 68; Iter   187/  209] train: loss: 0.0541444
[Epoch 68] ogbg-moltox21: 0.661707 val loss: 1.125916
[Epoch 68] ogbg-moltox21: 0.628182 test loss: 0.760186
[Epoch 69; Iter     8/  209] train: loss: 0.0365377
[Epoch 69; Iter    38/  209] train: loss: 0.0316759
[Epoch 69; Iter    68/  209] train: loss: 0.0388211
[Epoch 69; Iter    98/  209] train: loss: 0.0430983
[Epoch 69; Iter   128/  209] train: loss: 0.0354280
[Epoch 69; Iter   158/  209] train: loss: 0.0724000
[Epoch 69; Iter   188/  209] train: loss: 0.0303642
[Epoch 69] ogbg-moltox21: 0.688142 val loss: 0.797577
[Epoch 69] ogbg-moltox21: 0.638678 test loss: 0.741417
[Epoch 70; Iter     9/  209] train: loss: 0.0301753
[Epoch 70; Iter    39/  209] train: loss: 0.0204943
[Epoch 70; Iter    69/  209] train: loss: 0.0208460
[Epoch 70; Iter    99/  209] train: loss: 0.0516681
[Epoch 70; Iter   129/  209] train: loss: 0.0712414
[Epoch 70; Iter   159/  209] train: loss: 0.0535667
[Epoch 70; Iter   189/  209] train: loss: 0.0463178
[Epoch 70] ogbg-moltox21: 0.684134 val loss: 1.206136
[Epoch 70] ogbg-moltox21: 0.642535 test loss: 1.019031
[Epoch 71; Iter    10/  209] train: loss: 0.0267945
[Epoch 71; Iter    40/  209] train: loss: 0.0422753
[Epoch 71; Iter    70/  209] train: loss: 0.0389586
[Epoch 71; Iter   100/  209] train: loss: 0.0405622
[Epoch 71; Iter   130/  209] train: loss: 0.0456538
[Epoch 71; Iter   160/  209] train: loss: 0.0416159
[Epoch 71; Iter   190/  209] train: loss: 0.0316861
[Epoch 71] ogbg-moltox21: 0.683233 val loss: 0.709796
[Epoch 71] ogbg-moltox21: 0.642959 test loss: 1.052028
[Epoch 72; Iter    11/  209] train: loss: 0.0669128
[Epoch 72; Iter    41/  209] train: loss: 0.0517662
[Epoch 72; Iter    71/  209] train: loss: 0.0861289
[Epoch 72; Iter   101/  209] train: loss: 0.0315834
[Epoch 72; Iter   131/  209] train: loss: 0.0441816
[Epoch 72; Iter   161/  209] train: loss: 0.0762359
[Epoch 72; Iter   191/  209] train: loss: 0.0794906
[Epoch 72] ogbg-moltox21: 0.681135 val loss: 2.658893
[Epoch 72] ogbg-moltox21: 0.631879 test loss: 1.337045
[Epoch 73; Iter    12/  209] train: loss: 0.0351080
[Epoch 73; Iter    42/  209] train: loss: 0.0185925
[Epoch 73; Iter    72/  209] train: loss: 0.0398140
[Epoch 73; Iter   102/  209] train: loss: 0.0245318
[Epoch 73; Iter   132/  209] train: loss: 0.0360845
[Epoch 73; Iter   162/  209] train: loss: 0.0527684
[Epoch 73; Iter   192/  209] train: loss: 0.0699213
[Epoch 73] ogbg-moltox21: 0.691584 val loss: 0.947646
[Epoch 73] ogbg-moltox21: 0.648613 test loss: 0.805930
[Epoch 74; Iter    13/  209] train: loss: 0.0498834
[Epoch 74; Iter    43/  209] train: loss: 0.0684386
[Epoch 74; Iter    73/  209] train: loss: 0.0614516
[Epoch 74; Iter   103/  209] train: loss: 0.0187206
[Epoch 74; Iter   133/  209] train: loss: 0.0666164
[Epoch 74; Iter   163/  209] train: loss: 0.0237705
[Epoch 74; Iter   193/  209] train: loss: 0.0237361
[Epoch 74] ogbg-moltox21: 0.674893 val loss: 1.355528
[Epoch 74] ogbg-moltox21: 0.630103 test loss: 1.085459
[Epoch 75; Iter    14/  209] train: loss: 0.0206421
[Epoch 75; Iter    44/  209] train: loss: 0.0163793
[Epoch 75; Iter    74/  209] train: loss: 0.0343244
[Epoch 75; Iter   104/  209] train: loss: 0.0574275
[Epoch 75; Iter   134/  209] train: loss: 0.0122790
[Epoch 75; Iter   164/  209] train: loss: 0.0398003
[Epoch 75; Iter   194/  209] train: loss: 0.0279025
[Epoch 75] ogbg-moltox21: 0.668637 val loss: 2.050437
[Epoch 75] ogbg-moltox21: 0.636402 test loss: 1.298997
[Epoch 76; Iter    15/  209] train: loss: 0.0177533
[Epoch 76; Iter    45/  209] train: loss: 0.0249075
[Epoch 76; Iter    75/  209] train: loss: 0.0321506
[Epoch 76; Iter   105/  209] train: loss: 0.0207443
[Epoch 76; Iter   135/  209] train: loss: 0.0307554
[Epoch 76; Iter   165/  209] train: loss: 0.0080281
[Epoch 76; Iter   195/  209] train: loss: 0.0156750
[Epoch 76] ogbg-moltox21: 0.679179 val loss: 1.634400
[Epoch 76] ogbg-moltox21: 0.637208 test loss: 0.965206
[Epoch 77; Iter    16/  209] train: loss: 0.0391646
[Epoch 77; Iter    46/  209] train: loss: 0.0273149
[Epoch 77; Iter    76/  209] train: loss: 0.0337474
[Epoch 77; Iter   106/  209] train: loss: 0.0220077
[Epoch 77; Iter   136/  209] train: loss: 0.0411485
[Epoch 77; Iter   166/  209] train: loss: 0.0289713
[Epoch 77; Iter   196/  209] train: loss: 0.0415313
[Epoch 77] ogbg-moltox21: 0.691648 val loss: 1.286527
[Epoch 77] ogbg-moltox21: 0.649295 test loss: 0.792300
[Epoch 78; Iter    17/  209] train: loss: 0.0150772
[Epoch 78; Iter    47/  209] train: loss: 0.0085641
[Epoch 78; Iter    77/  209] train: loss: 0.0189217
[Epoch 78; Iter   107/  209] train: loss: 0.0223000
[Epoch 78; Iter   137/  209] train: loss: 0.0368226
[Epoch 78; Iter   167/  209] train: loss: 0.0197497
[Epoch 78; Iter   197/  209] train: loss: 0.0137730
[Epoch 78] ogbg-moltox21: 0.678599 val loss: 2.302997
[Epoch 78] ogbg-moltox21: 0.644467 test loss: 1.198538
[Epoch 79; Iter    18/  209] train: loss: 0.0123580
[Epoch 79; Iter    48/  209] train: loss: 0.0284517
[Epoch 79; Iter    78/  209] train: loss: 0.0331297
[Epoch 79; Iter   108/  209] train: loss: 0.0286850
[Epoch 79; Iter   138/  209] train: loss: 0.0042953
[Epoch 79; Iter   168/  209] train: loss: 0.0229092
[Epoch 79; Iter   198/  209] train: loss: 0.0155036
[Epoch 79] ogbg-moltox21: 0.680717 val loss: 1.595935
[Epoch 79] ogbg-moltox21: 0.643749 test loss: 0.973258
[Epoch 80; Iter    19/  209] train: loss: 0.0140512
[Epoch 80; Iter    49/  209] train: loss: 0.0330112
[Epoch 80; Iter    79/  209] train: loss: 0.0101972
[Epoch 80; Iter   109/  209] train: loss: 0.0134288
[Epoch 80; Iter   139/  209] train: loss: 0.0207933
[Epoch 80; Iter   169/  209] train: loss: 0.0135310
[Epoch 80; Iter   199/  209] train: loss: 0.0427790
[Epoch 80] ogbg-moltox21: 0.680004 val loss: 2.509294
[Epoch 80] ogbg-moltox21: 0.636010 test loss: 1.139732
[Epoch 81; Iter    20/  209] train: loss: 0.0311704
[Epoch 81; Iter    50/  209] train: loss: 0.0106914
[Epoch 81; Iter    80/  209] train: loss: 0.0281345
[Epoch 81; Iter   110/  209] train: loss: 0.0168646
[Epoch 81; Iter   140/  209] train: loss: 0.0373700
[Epoch 81; Iter   170/  209] train: loss: 0.0187318
[Epoch 81; Iter   200/  209] train: loss: 0.0253878
[Epoch 81] ogbg-moltox21: 0.680145 val loss: 3.109002
[Epoch 81] ogbg-moltox21: 0.645111 test loss: 1.200872
[Epoch 82; Iter    21/  209] train: loss: 0.0130343
[Epoch 64] ogbg-moltox21: 0.712835 test loss: 0.559573
[Epoch 65; Iter     4/  209] train: loss: 0.0399172
[Epoch 65; Iter    34/  209] train: loss: 0.0473735
[Epoch 65; Iter    64/  209] train: loss: 0.0271798
[Epoch 65; Iter    94/  209] train: loss: 0.0963099
[Epoch 65; Iter   124/  209] train: loss: 0.0699225
[Epoch 65; Iter   154/  209] train: loss: 0.0278440
[Epoch 65; Iter   184/  209] train: loss: 0.0181970
[Epoch 65] ogbg-moltox21: 0.737788 val loss: 0.646364
[Epoch 65] ogbg-moltox21: 0.703119 test loss: 0.613620
[Epoch 66; Iter     5/  209] train: loss: 0.0546755
[Epoch 66; Iter    35/  209] train: loss: 0.0204061
[Epoch 66; Iter    65/  209] train: loss: 0.0115505
[Epoch 66; Iter    95/  209] train: loss: 0.0312677
[Epoch 66; Iter   125/  209] train: loss: 0.0512429
[Epoch 66; Iter   155/  209] train: loss: 0.0507326
[Epoch 66; Iter   185/  209] train: loss: 0.0454468
[Epoch 66] ogbg-moltox21: 0.727887 val loss: 0.629379
[Epoch 66] ogbg-moltox21: 0.679514 test loss: 0.589154
[Epoch 67; Iter     6/  209] train: loss: 0.0478255
[Epoch 67; Iter    36/  209] train: loss: 0.0156949
[Epoch 67; Iter    66/  209] train: loss: 0.0196803
[Epoch 67; Iter    96/  209] train: loss: 0.0442643
[Epoch 67; Iter   126/  209] train: loss: 0.0375391
[Epoch 67; Iter   156/  209] train: loss: 0.0403139
[Epoch 67; Iter   186/  209] train: loss: 0.0384557
[Epoch 67] ogbg-moltox21: 0.736860 val loss: 0.560898
[Epoch 67] ogbg-moltox21: 0.692500 test loss: 0.590493
[Epoch 68; Iter     7/  209] train: loss: 0.0247140
[Epoch 68; Iter    37/  209] train: loss: 0.0364259
[Epoch 68; Iter    67/  209] train: loss: 0.0370050
[Epoch 68; Iter    97/  209] train: loss: 0.0452191
[Epoch 68; Iter   127/  209] train: loss: 0.0301758
[Epoch 68; Iter   157/  209] train: loss: 0.0403778
[Epoch 68; Iter   187/  209] train: loss: 0.0395420
[Epoch 68] ogbg-moltox21: 0.731178 val loss: 0.526150
[Epoch 68] ogbg-moltox21: 0.698415 test loss: 0.589098
[Epoch 69; Iter     8/  209] train: loss: 0.0389237
[Epoch 69; Iter    38/  209] train: loss: 0.0273684
[Epoch 69; Iter    68/  209] train: loss: 0.0336127
[Epoch 69; Iter    98/  209] train: loss: 0.0328406
[Epoch 69; Iter   128/  209] train: loss: 0.0261632
[Epoch 69; Iter   158/  209] train: loss: 0.0630039
[Epoch 69; Iter   188/  209] train: loss: 0.0283199
[Epoch 69] ogbg-moltox21: 0.733074 val loss: 0.564400
[Epoch 69] ogbg-moltox21: 0.691201 test loss: 0.649309
[Epoch 70; Iter     9/  209] train: loss: 0.0199864
[Epoch 70; Iter    39/  209] train: loss: 0.0731103
[Epoch 70; Iter    69/  209] train: loss: 0.0193942
[Epoch 70; Iter    99/  209] train: loss: 0.0255044
[Epoch 70; Iter   129/  209] train: loss: 0.0486989
[Epoch 70; Iter   159/  209] train: loss: 0.0526901
[Epoch 70; Iter   189/  209] train: loss: 0.0341145
[Epoch 70] ogbg-moltox21: 0.736601 val loss: 0.570994
[Epoch 70] ogbg-moltox21: 0.704789 test loss: 0.626186
[Epoch 71; Iter    10/  209] train: loss: 0.0213793
[Epoch 71; Iter    40/  209] train: loss: 0.0189310
[Epoch 71; Iter    70/  209] train: loss: 0.0464004
[Epoch 71; Iter   100/  209] train: loss: 0.0272068
[Epoch 71; Iter   130/  209] train: loss: 0.0378769
[Epoch 71; Iter   160/  209] train: loss: 0.0235444
[Epoch 71; Iter   190/  209] train: loss: 0.0349382
[Epoch 71] ogbg-moltox21: 0.732381 val loss: 0.567985
[Epoch 71] ogbg-moltox21: 0.690482 test loss: 0.622546
[Epoch 72; Iter    11/  209] train: loss: 0.0296746
[Epoch 72; Iter    41/  209] train: loss: 0.0409887
[Epoch 72; Iter    71/  209] train: loss: 0.0580568
[Epoch 72; Iter   101/  209] train: loss: 0.0319840
[Epoch 72; Iter   131/  209] train: loss: 0.0419634
[Epoch 72; Iter   161/  209] train: loss: 0.0296127
[Epoch 72; Iter   191/  209] train: loss: 0.0809612
[Epoch 72] ogbg-moltox21: 0.741880 val loss: 0.572182
[Epoch 72] ogbg-moltox21: 0.702908 test loss: 0.637839
[Epoch 73; Iter    12/  209] train: loss: 0.0292657
[Epoch 73; Iter    42/  209] train: loss: 0.0349452
[Epoch 73; Iter    72/  209] train: loss: 0.0248595
[Epoch 73; Iter   102/  209] train: loss: 0.0166095
[Epoch 73; Iter   132/  209] train: loss: 0.0541810
[Epoch 73; Iter   162/  209] train: loss: 0.0420911
[Epoch 73; Iter   192/  209] train: loss: 0.0602942
[Epoch 73] ogbg-moltox21: 0.730065 val loss: 0.616975
[Epoch 73] ogbg-moltox21: 0.688618 test loss: 0.720766
[Epoch 74; Iter    13/  209] train: loss: 0.0428190
[Epoch 74; Iter    43/  209] train: loss: 0.0463274
[Epoch 74; Iter    73/  209] train: loss: 0.0381130
[Epoch 74; Iter   103/  209] train: loss: 0.0080103
[Epoch 74; Iter   133/  209] train: loss: 0.0469166
[Epoch 74; Iter   163/  209] train: loss: 0.0420853
[Epoch 74; Iter   193/  209] train: loss: 0.0266393
[Epoch 74] ogbg-moltox21: 0.724843 val loss: 0.577076
[Epoch 74] ogbg-moltox21: 0.683234 test loss: 0.697626
[Epoch 75; Iter    14/  209] train: loss: 0.0146290
[Epoch 75; Iter    44/  209] train: loss: 0.0211460
[Epoch 75; Iter    74/  209] train: loss: 0.0400584
[Epoch 75; Iter   104/  209] train: loss: 0.0543296
[Epoch 75; Iter   134/  209] train: loss: 0.0312759
[Epoch 75; Iter   164/  209] train: loss: 0.0515260
[Epoch 75; Iter   194/  209] train: loss: 0.0202789
[Epoch 75] ogbg-moltox21: 0.720828 val loss: 0.609813
[Epoch 75] ogbg-moltox21: 0.686365 test loss: 0.663194
[Epoch 76; Iter    15/  209] train: loss: 0.0236601
[Epoch 76; Iter    45/  209] train: loss: 0.0225274
[Epoch 76; Iter    75/  209] train: loss: 0.0207489
[Epoch 76; Iter   105/  209] train: loss: 0.0262013
[Epoch 76; Iter   135/  209] train: loss: 0.0255291
[Epoch 76; Iter   165/  209] train: loss: 0.0068999
[Epoch 76; Iter   195/  209] train: loss: 0.0074626
[Epoch 76] ogbg-moltox21: 0.727602 val loss: 0.574809
[Epoch 76] ogbg-moltox21: 0.697324 test loss: 0.626150
[Epoch 77; Iter    16/  209] train: loss: 0.0358873
[Epoch 77; Iter    46/  209] train: loss: 0.0120389
[Epoch 77; Iter    76/  209] train: loss: 0.0181836
[Epoch 77; Iter   106/  209] train: loss: 0.0175386
[Epoch 77; Iter   136/  209] train: loss: 0.0236633
[Epoch 77; Iter   166/  209] train: loss: 0.0118043
[Epoch 77; Iter   196/  209] train: loss: 0.0468427
[Epoch 77] ogbg-moltox21: 0.729418 val loss: 0.550978
[Epoch 77] ogbg-moltox21: 0.688125 test loss: 0.610478
[Epoch 78; Iter    17/  209] train: loss: 0.0101300
[Epoch 78; Iter    47/  209] train: loss: 0.0062424
[Epoch 78; Iter    77/  209] train: loss: 0.0172055
[Epoch 78; Iter   107/  209] train: loss: 0.0085309
[Epoch 78; Iter   137/  209] train: loss: 0.0235940
[Epoch 78; Iter   167/  209] train: loss: 0.0091822
[Epoch 78; Iter   197/  209] train: loss: 0.0097585
[Epoch 78] ogbg-moltox21: 0.731249 val loss: 0.578652
[Epoch 78] ogbg-moltox21: 0.693316 test loss: 0.621762
[Epoch 79; Iter    18/  209] train: loss: 0.0114421
[Epoch 79; Iter    48/  209] train: loss: 0.0138329
[Epoch 79; Iter    78/  209] train: loss: 0.0108249
[Epoch 79; Iter   108/  209] train: loss: 0.0192390
[Epoch 79; Iter   138/  209] train: loss: 0.0092667
[Epoch 79; Iter   168/  209] train: loss: 0.0133529
[Epoch 79; Iter   198/  209] train: loss: 0.0129153
[Epoch 79] ogbg-moltox21: 0.730952 val loss: 0.569977
[Epoch 79] ogbg-moltox21: 0.692355 test loss: 0.628762
[Epoch 80; Iter    19/  209] train: loss: 0.0190842
[Epoch 80; Iter    49/  209] train: loss: 0.0156320
[Epoch 80; Iter    79/  209] train: loss: 0.0098405
[Epoch 80; Iter   109/  209] train: loss: 0.0066504
[Epoch 80; Iter   139/  209] train: loss: 0.0118052
[Epoch 80; Iter   169/  209] train: loss: 0.0163838
[Epoch 80; Iter   199/  209] train: loss: 0.0488554
[Epoch 80] ogbg-moltox21: 0.730646 val loss: 0.592008
[Epoch 80] ogbg-moltox21: 0.688613 test loss: 0.668788
[Epoch 81; Iter    20/  209] train: loss: 0.0188828
[Epoch 81; Iter    50/  209] train: loss: 0.0042272
[Epoch 81; Iter    80/  209] train: loss: 0.0229696
[Epoch 81; Iter   110/  209] train: loss: 0.0097699
[Epoch 81; Iter   140/  209] train: loss: 0.0307076
[Epoch 81; Iter   170/  209] train: loss: 0.0204768
[Epoch 81; Iter   200/  209] train: loss: 0.0205212
[Epoch 81] ogbg-moltox21: 0.723768 val loss: 0.627818
[Epoch 81] ogbg-moltox21: 0.688100 test loss: 0.675883
[Epoch 82; Iter    21/  209] train: loss: 0.0087066
[Epoch 64] ogbg-moltox21: 0.655218 test loss: 0.814405
[Epoch 65; Iter     4/  209] train: loss: 0.0154150
[Epoch 65; Iter    34/  209] train: loss: 0.0198701
[Epoch 65; Iter    64/  209] train: loss: 0.0272130
[Epoch 65; Iter    94/  209] train: loss: 0.0125744
[Epoch 65; Iter   124/  209] train: loss: 0.0188560
[Epoch 65; Iter   154/  209] train: loss: 0.0114698
[Epoch 65; Iter   184/  209] train: loss: 0.0301100
[Epoch 65] ogbg-moltox21: 0.739418 val loss: 0.829477
[Epoch 65] ogbg-moltox21: 0.665431 test loss: 0.875290
[Epoch 66; Iter     5/  209] train: loss: 0.0115037
[Epoch 66; Iter    35/  209] train: loss: 0.0234644
[Epoch 66; Iter    65/  209] train: loss: 0.0191474
[Epoch 66; Iter    95/  209] train: loss: 0.0282144
[Epoch 66; Iter   125/  209] train: loss: 0.0148879
[Epoch 66; Iter   155/  209] train: loss: 0.0343800
[Epoch 66; Iter   185/  209] train: loss: 0.0104120
[Epoch 66] ogbg-moltox21: 0.725489 val loss: 0.881422
[Epoch 66] ogbg-moltox21: 0.665270 test loss: 0.773928
[Epoch 67; Iter     6/  209] train: loss: 0.0278494
[Epoch 67; Iter    36/  209] train: loss: 0.0188374
[Epoch 67; Iter    66/  209] train: loss: 0.0184308
[Epoch 67; Iter    96/  209] train: loss: 0.0118914
[Epoch 67; Iter   126/  209] train: loss: 0.0213545
[Epoch 67; Iter   156/  209] train: loss: 0.0091876
[Epoch 67; Iter   186/  209] train: loss: 0.0185311
[Epoch 67] ogbg-moltox21: 0.727105 val loss: 0.978219
[Epoch 67] ogbg-moltox21: 0.672081 test loss: 0.970406
[Epoch 68; Iter     7/  209] train: loss: 0.0260815
[Epoch 68; Iter    37/  209] train: loss: 0.0075417
[Epoch 68; Iter    67/  209] train: loss: 0.0575610
[Epoch 68; Iter    97/  209] train: loss: 0.0256279
[Epoch 68; Iter   127/  209] train: loss: 0.0137531
[Epoch 68; Iter   157/  209] train: loss: 0.0304581
[Epoch 68; Iter   187/  209] train: loss: 0.0193179
[Epoch 68] ogbg-moltox21: 0.714317 val loss: 0.930516
[Epoch 68] ogbg-moltox21: 0.657142 test loss: 0.811305
[Epoch 69; Iter     8/  209] train: loss: 0.0180006
[Epoch 69; Iter    38/  209] train: loss: 0.0334191
[Epoch 69; Iter    68/  209] train: loss: 0.0124878
[Epoch 69; Iter    98/  209] train: loss: 0.0086621
[Epoch 69; Iter   128/  209] train: loss: 0.0265126
[Epoch 69; Iter   158/  209] train: loss: 0.0214200
[Epoch 69; Iter   188/  209] train: loss: 0.0321701
[Epoch 69] ogbg-moltox21: 0.726230 val loss: 0.670960
[Epoch 69] ogbg-moltox21: 0.666323 test loss: 0.764870
[Epoch 70; Iter     9/  209] train: loss: 0.0292911
[Epoch 70; Iter    39/  209] train: loss: 0.0172152
[Epoch 70; Iter    69/  209] train: loss: 0.0452876
[Epoch 70; Iter    99/  209] train: loss: 0.0313034
[Epoch 70; Iter   129/  209] train: loss: 0.0173463
[Epoch 70; Iter   159/  209] train: loss: 0.0181945
[Epoch 70; Iter   189/  209] train: loss: 0.0226007
[Epoch 70] ogbg-moltox21: 0.727709 val loss: 0.688994
[Epoch 70] ogbg-moltox21: 0.663566 test loss: 0.932099
[Epoch 71; Iter    10/  209] train: loss: 0.0082001
[Epoch 71; Iter    40/  209] train: loss: 0.0157268
[Epoch 71; Iter    70/  209] train: loss: 0.0189863
[Epoch 71; Iter   100/  209] train: loss: 0.0242014
[Epoch 71; Iter   130/  209] train: loss: 0.0141392
[Epoch 71; Iter   160/  209] train: loss: 0.0127830
[Epoch 71; Iter   190/  209] train: loss: 0.0164753
[Epoch 71] ogbg-moltox21: 0.721800 val loss: 0.676846
[Epoch 71] ogbg-moltox21: 0.660039 test loss: 0.783726
[Epoch 72; Iter    11/  209] train: loss: 0.0324654
[Epoch 72; Iter    41/  209] train: loss: 0.0102399
[Epoch 72; Iter    71/  209] train: loss: 0.0120530
[Epoch 72; Iter   101/  209] train: loss: 0.0132562
[Epoch 72; Iter   131/  209] train: loss: 0.0170207
[Epoch 72; Iter   161/  209] train: loss: 0.0253022
[Epoch 72; Iter   191/  209] train: loss: 0.0417158
[Epoch 72] ogbg-moltox21: 0.719505 val loss: 0.946598
[Epoch 72] ogbg-moltox21: 0.665248 test loss: 0.965096
[Epoch 73; Iter    12/  209] train: loss: 0.0138949
[Epoch 73; Iter    42/  209] train: loss: 0.0189254
[Epoch 73; Iter    72/  209] train: loss: 0.0112334
[Epoch 73; Iter   102/  209] train: loss: 0.0158637
[Epoch 73; Iter   132/  209] train: loss: 0.0230972
[Epoch 73; Iter   162/  209] train: loss: 0.0065435
[Epoch 73; Iter   192/  209] train: loss: 0.0346732
[Epoch 73] ogbg-moltox21: 0.717978 val loss: 0.682576
[Epoch 73] ogbg-moltox21: 0.663967 test loss: 0.809114
[Epoch 74; Iter    13/  209] train: loss: 0.0177675
[Epoch 74; Iter    43/  209] train: loss: 0.0106178
[Epoch 74; Iter    73/  209] train: loss: 0.0377519
[Epoch 74; Iter   103/  209] train: loss: 0.0155274
[Epoch 74; Iter   133/  209] train: loss: 0.0149700
[Epoch 74; Iter   163/  209] train: loss: 0.0363599
[Epoch 74; Iter   193/  209] train: loss: 0.0252582
[Epoch 74] ogbg-moltox21: 0.715796 val loss: 0.928236
[Epoch 74] ogbg-moltox21: 0.654268 test loss: 0.986123
[Epoch 75; Iter    14/  209] train: loss: 0.0164580
[Epoch 75; Iter    44/  209] train: loss: 0.0103026
[Epoch 75; Iter    74/  209] train: loss: 0.0152961
[Epoch 75; Iter   104/  209] train: loss: 0.0201674
[Epoch 75; Iter   134/  209] train: loss: 0.0276839
[Epoch 75; Iter   164/  209] train: loss: 0.0123976
[Epoch 75; Iter   194/  209] train: loss: 0.0084404
[Epoch 75] ogbg-moltox21: 0.720498 val loss: 0.924690
[Epoch 75] ogbg-moltox21: 0.660992 test loss: 1.105860
[Epoch 76; Iter    15/  209] train: loss: 0.0149402
[Epoch 76; Iter    45/  209] train: loss: 0.0204114
[Epoch 76; Iter    75/  209] train: loss: 0.0105396
[Epoch 76; Iter   105/  209] train: loss: 0.0145904
[Epoch 76; Iter   135/  209] train: loss: 0.0315441
[Epoch 76; Iter   165/  209] train: loss: 0.0159024
[Epoch 76; Iter   195/  209] train: loss: 0.0128542
[Epoch 76] ogbg-moltox21: 0.722471 val loss: 1.347577
[Epoch 76] ogbg-moltox21: 0.661877 test loss: 1.475680
[Epoch 77; Iter    16/  209] train: loss: 0.0102881
[Epoch 77; Iter    46/  209] train: loss: 0.0091155
[Epoch 77; Iter    76/  209] train: loss: 0.0139032
[Epoch 77; Iter   106/  209] train: loss: 0.0196591
[Epoch 77; Iter   136/  209] train: loss: 0.0122440
[Epoch 77; Iter   166/  209] train: loss: 0.0262541
[Epoch 77; Iter   196/  209] train: loss: 0.0162767
[Epoch 77] ogbg-moltox21: 0.716918 val loss: 0.995488
[Epoch 77] ogbg-moltox21: 0.662526 test loss: 1.077611
[Epoch 78; Iter    17/  209] train: loss: 0.0397876
[Epoch 78; Iter    47/  209] train: loss: 0.0168430
[Epoch 78; Iter    77/  209] train: loss: 0.0528007
[Epoch 78; Iter   107/  209] train: loss: 0.0195506
[Epoch 78; Iter   137/  209] train: loss: 0.0159865
[Epoch 78; Iter   167/  209] train: loss: 0.0164361
[Epoch 78; Iter   197/  209] train: loss: 0.0063664
[Epoch 78] ogbg-moltox21: 0.712121 val loss: 1.180120
[Epoch 78] ogbg-moltox21: 0.654534 test loss: 0.905112
[Epoch 79; Iter    18/  209] train: loss: 0.0180432
[Epoch 79; Iter    48/  209] train: loss: 0.0292310
[Epoch 79; Iter    78/  209] train: loss: 0.0437483
[Epoch 79; Iter   108/  209] train: loss: 0.0316370
[Epoch 79; Iter   138/  209] train: loss: 0.0240650
[Epoch 79; Iter   168/  209] train: loss: 0.0224922
[Epoch 79; Iter   198/  209] train: loss: 0.0147648
[Epoch 79] ogbg-moltox21: 0.726670 val loss: 0.821134
[Epoch 79] ogbg-moltox21: 0.665286 test loss: 1.049914
[Epoch 80; Iter    19/  209] train: loss: 0.0082449
[Epoch 80; Iter    49/  209] train: loss: 0.0111496
[Epoch 80; Iter    79/  209] train: loss: 0.0263844
[Epoch 80; Iter   109/  209] train: loss: 0.0348831
[Epoch 80; Iter   139/  209] train: loss: 0.0273247
[Epoch 80; Iter   169/  209] train: loss: 0.0055947
[Epoch 80; Iter   199/  209] train: loss: 0.0231525
[Epoch 80] ogbg-moltox21: 0.708762 val loss: 0.909086
[Epoch 80] ogbg-moltox21: 0.651395 test loss: 0.924930
[Epoch 81; Iter    20/  209] train: loss: 0.0131903
[Epoch 81; Iter    50/  209] train: loss: 0.0099693
[Epoch 81; Iter    80/  209] train: loss: 0.0045067
[Epoch 81; Iter   110/  209] train: loss: 0.0124272
[Epoch 81; Iter   140/  209] train: loss: 0.0086644
[Epoch 81; Iter   170/  209] train: loss: 0.0183476
[Epoch 81; Iter   200/  209] train: loss: 0.0161699
[Epoch 81] ogbg-moltox21: 0.714039 val loss: 1.042715
[Epoch 81] ogbg-moltox21: 0.653550 test loss: 0.935479
[Epoch 82; Iter    21/  209] train: loss: 0.0212422
[Epoch 82; Iter    51/  209] train: loss: 0.0400223
[Epoch 82; Iter    81/  209] train: loss: 0.0476493
[Epoch 82; Iter   111/  209] train: loss: 0.0253033
[Epoch 82; Iter   141/  209] train: loss: 0.0636613
[Epoch 82; Iter   171/  209] train: loss: 0.0215761
[Epoch 82; Iter   201/  209] train: loss: 0.0167415
[Epoch 82] ogbg-moltox21: 0.750936 val loss: 0.524590
[Epoch 82] ogbg-moltox21: 0.730806 test loss: 0.535905
[Epoch 83; Iter    22/  209] train: loss: 0.0686608
[Epoch 83; Iter    52/  209] train: loss: 0.0646904
[Epoch 83; Iter    82/  209] train: loss: 0.0235612
[Epoch 83; Iter   112/  209] train: loss: 0.0355315
[Epoch 83; Iter   142/  209] train: loss: 0.0703286
[Epoch 83; Iter   172/  209] train: loss: 0.0239006
[Epoch 83; Iter   202/  209] train: loss: 0.0700037
[Epoch 83] ogbg-moltox21: 0.755533 val loss: 0.507373
[Epoch 83] ogbg-moltox21: 0.738657 test loss: 0.541356
[Epoch 84; Iter    23/  209] train: loss: 0.0202651
[Epoch 84; Iter    53/  209] train: loss: 0.0371729
[Epoch 84; Iter    83/  209] train: loss: 0.0301872
[Epoch 84; Iter   113/  209] train: loss: 0.0233084
[Epoch 84; Iter   143/  209] train: loss: 0.0324717
[Epoch 84; Iter   173/  209] train: loss: 0.0440967
[Epoch 84; Iter   203/  209] train: loss: 0.0602815
[Epoch 84] ogbg-moltox21: 0.743163 val loss: 0.539474
[Epoch 84] ogbg-moltox21: 0.718622 test loss: 0.557193
[Epoch 85; Iter    24/  209] train: loss: 0.0399716
[Epoch 85; Iter    54/  209] train: loss: 0.0491233
[Epoch 85; Iter    84/  209] train: loss: 0.0219635
[Epoch 85; Iter   114/  209] train: loss: 0.0466681
[Epoch 85; Iter   144/  209] train: loss: 0.0663692
[Epoch 85; Iter   174/  209] train: loss: 0.0262874
[Epoch 85; Iter   204/  209] train: loss: 0.0496004
[Epoch 85] ogbg-moltox21: 0.742642 val loss: 0.572380
[Epoch 85] ogbg-moltox21: 0.718262 test loss: 0.587633
[Epoch 86; Iter    25/  209] train: loss: 0.0293993
[Epoch 86; Iter    55/  209] train: loss: 0.0149330
[Epoch 86; Iter    85/  209] train: loss: 0.0264782
[Epoch 86; Iter   115/  209] train: loss: 0.0267600
[Epoch 86; Iter   145/  209] train: loss: 0.0252070
[Epoch 86; Iter   175/  209] train: loss: 0.0271639
[Epoch 86; Iter   205/  209] train: loss: 0.0210363
[Epoch 86] ogbg-moltox21: 0.745916 val loss: 0.561614
[Epoch 86] ogbg-moltox21: 0.736701 test loss: 0.567765
[Epoch 87; Iter    26/  209] train: loss: 0.0217344
[Epoch 87; Iter    56/  209] train: loss: 0.0196042
[Epoch 87; Iter    86/  209] train: loss: 0.0229484
[Epoch 87; Iter   116/  209] train: loss: 0.0569215
[Epoch 87; Iter   146/  209] train: loss: 0.0550068
[Epoch 87; Iter   176/  209] train: loss: 0.0168067
[Epoch 87; Iter   206/  209] train: loss: 0.0760900
[Epoch 87] ogbg-moltox21: 0.747763 val loss: 0.557999
[Epoch 87] ogbg-moltox21: 0.735590 test loss: 0.564281
[Epoch 88; Iter    27/  209] train: loss: 0.0238270
[Epoch 88; Iter    57/  209] train: loss: 0.0321960
[Epoch 88; Iter    87/  209] train: loss: 0.0468329
[Epoch 88; Iter   117/  209] train: loss: 0.0235470
[Epoch 88; Iter   147/  209] train: loss: 0.0193760
[Epoch 88; Iter   177/  209] train: loss: 0.0200532
[Epoch 88; Iter   207/  209] train: loss: 0.0194315
[Epoch 88] ogbg-moltox21: 0.738782 val loss: 0.554172
[Epoch 88] ogbg-moltox21: 0.730064 test loss: 0.552508
[Epoch 89; Iter    28/  209] train: loss: 0.0167469
[Epoch 89; Iter    58/  209] train: loss: 0.0290764
[Epoch 89; Iter    88/  209] train: loss: 0.0305492
[Epoch 89; Iter   118/  209] train: loss: 0.0230813
[Epoch 89; Iter   148/  209] train: loss: 0.0455917
[Epoch 89; Iter   178/  209] train: loss: 0.0210407
[Epoch 89; Iter   208/  209] train: loss: 0.0351295
[Epoch 89] ogbg-moltox21: 0.749551 val loss: 0.571423
[Epoch 89] ogbg-moltox21: 0.737211 test loss: 0.577288
[Epoch 90; Iter    29/  209] train: loss: 0.0389131
[Epoch 90; Iter    59/  209] train: loss: 0.0265090
[Epoch 90; Iter    89/  209] train: loss: 0.0316826
[Epoch 90; Iter   119/  209] train: loss: 0.0893868
[Epoch 90; Iter   149/  209] train: loss: 0.0440240
[Epoch 90; Iter   179/  209] train: loss: 0.0455078
[Epoch 90; Iter   209/  209] train: loss: 0.0542284
[Epoch 90] ogbg-moltox21: 0.754732 val loss: 0.598336
[Epoch 90] ogbg-moltox21: 0.738236 test loss: 0.604938
[Epoch 91; Iter    30/  209] train: loss: 0.0152081
[Epoch 91; Iter    60/  209] train: loss: 0.0262908
[Epoch 91; Iter    90/  209] train: loss: 0.0252440
[Epoch 91; Iter   120/  209] train: loss: 0.0227465
[Epoch 91; Iter   150/  209] train: loss: 0.0242343
[Epoch 91; Iter   180/  209] train: loss: 0.0444284
[Epoch 91] ogbg-moltox21: 0.749863 val loss: 0.586974
[Epoch 91] ogbg-moltox21: 0.726929 test loss: 0.611697
[Epoch 92; Iter     1/  209] train: loss: 0.0150486
[Epoch 92; Iter    31/  209] train: loss: 0.0226178
[Epoch 92; Iter    61/  209] train: loss: 0.0369176
[Epoch 92; Iter    91/  209] train: loss: 0.0389215
[Epoch 92; Iter   121/  209] train: loss: 0.0298056
[Epoch 92; Iter   151/  209] train: loss: 0.0301849
[Epoch 92; Iter   181/  209] train: loss: 0.0130967
[Epoch 92] ogbg-moltox21: 0.735250 val loss: 0.575139
[Epoch 92] ogbg-moltox21: 0.730658 test loss: 0.567564
[Epoch 93; Iter     2/  209] train: loss: 0.0238636
[Epoch 93; Iter    32/  209] train: loss: 0.0391817
[Epoch 93; Iter    62/  209] train: loss: 0.0219324
[Epoch 93; Iter    92/  209] train: loss: 0.0461007
[Epoch 93; Iter   122/  209] train: loss: 0.0457316
[Epoch 93; Iter   152/  209] train: loss: 0.0218837
[Epoch 93; Iter   182/  209] train: loss: 0.0187772
[Epoch 93] ogbg-moltox21: 0.752108 val loss: 0.576961
[Epoch 93] ogbg-moltox21: 0.738886 test loss: 0.561314
[Epoch 94; Iter     3/  209] train: loss: 0.0168747
[Epoch 94; Iter    33/  209] train: loss: 0.0199167
[Epoch 94; Iter    63/  209] train: loss: 0.0191075
[Epoch 94; Iter    93/  209] train: loss: 0.0158066
[Epoch 94; Iter   123/  209] train: loss: 0.0577172
[Epoch 94; Iter   153/  209] train: loss: 0.0157542
[Epoch 94; Iter   183/  209] train: loss: 0.0320674
[Epoch 94] ogbg-moltox21: 0.741057 val loss: 0.592357
[Epoch 94] ogbg-moltox21: 0.730410 test loss: 0.602583
[Epoch 95; Iter     4/  209] train: loss: 0.0277636
[Epoch 95; Iter    34/  209] train: loss: 0.0159287
[Epoch 95; Iter    64/  209] train: loss: 0.0220009
[Epoch 95; Iter    94/  209] train: loss: 0.0360586
[Epoch 95; Iter   124/  209] train: loss: 0.0205260
[Epoch 95; Iter   154/  209] train: loss: 0.0622834
[Epoch 95; Iter   184/  209] train: loss: 0.0251968
[Epoch 95] ogbg-moltox21: 0.740845 val loss: 0.572600
[Epoch 95] ogbg-moltox21: 0.718401 test loss: 0.599878
[Epoch 96; Iter     5/  209] train: loss: 0.0386180
[Epoch 96; Iter    35/  209] train: loss: 0.0236371
[Epoch 96; Iter    65/  209] train: loss: 0.0603904
[Epoch 96; Iter    95/  209] train: loss: 0.0108579
[Epoch 96; Iter   125/  209] train: loss: 0.0250553
[Epoch 96; Iter   155/  209] train: loss: 0.0208757
[Epoch 96; Iter   185/  209] train: loss: 0.0276701
[Epoch 96] ogbg-moltox21: 0.738503 val loss: 0.602220
[Epoch 96] ogbg-moltox21: 0.718165 test loss: 0.637429
[Epoch 97; Iter     6/  209] train: loss: 0.0213194
[Epoch 97; Iter    36/  209] train: loss: 0.0311538
[Epoch 97; Iter    66/  209] train: loss: 0.0141865
[Epoch 97; Iter    96/  209] train: loss: 0.0316868
[Epoch 97; Iter   126/  209] train: loss: 0.0328901
[Epoch 97; Iter   156/  209] train: loss: 0.0460147
[Epoch 97; Iter   186/  209] train: loss: 0.0354664
[Epoch 97] ogbg-moltox21: 0.753776 val loss: 0.585047
[Epoch 97] ogbg-moltox21: 0.734081 test loss: 0.614693
[Epoch 98; Iter     7/  209] train: loss: 0.0424321
[Epoch 98; Iter    37/  209] train: loss: 0.0300990
[Epoch 98; Iter    67/  209] train: loss: 0.0510388
[Epoch 98; Iter    97/  209] train: loss: 0.0257519
[Epoch 98; Iter   127/  209] train: loss: 0.0130248
[Epoch 98; Iter   157/  209] train: loss: 0.0280727
[Epoch 98; Iter   187/  209] train: loss: 0.0251373
[Epoch 98] ogbg-moltox21: 0.742454 val loss: 0.591690
[Epoch 98] ogbg-moltox21: 0.724711 test loss: 0.609374
[Epoch 99; Iter     8/  209] train: loss: 0.0466764
[Epoch 99; Iter    38/  209] train: loss: 0.0370088
[Epoch 99; Iter    68/  209] train: loss: 0.0139326
[Epoch 99; Iter    98/  209] train: loss: 0.0164832
[Epoch 82; Iter    51/  209] train: loss: 0.0157145
[Epoch 82; Iter    81/  209] train: loss: 0.0256299
[Epoch 82; Iter   111/  209] train: loss: 0.0849785
[Epoch 82; Iter   141/  209] train: loss: 0.0191014
[Epoch 82; Iter   171/  209] train: loss: 0.0226076
[Epoch 82; Iter   201/  209] train: loss: 0.0187595
[Epoch 82] ogbg-moltox21: 0.741749 val loss: 0.676988
[Epoch 82] ogbg-moltox21: 0.711889 test loss: 0.813794
[Epoch 83; Iter    22/  209] train: loss: 0.0192419
[Epoch 83; Iter    52/  209] train: loss: 0.0403651
[Epoch 83; Iter    82/  209] train: loss: 0.0388111
[Epoch 83; Iter   112/  209] train: loss: 0.0218896
[Epoch 83; Iter   142/  209] train: loss: 0.0478800
[Epoch 83; Iter   172/  209] train: loss: 0.0185188
[Epoch 83; Iter   202/  209] train: loss: 0.0302676
[Epoch 83] ogbg-moltox21: 0.746401 val loss: 0.628664
[Epoch 83] ogbg-moltox21: 0.720769 test loss: 0.650005
[Epoch 84; Iter    23/  209] train: loss: 0.0125793
[Epoch 84; Iter    53/  209] train: loss: 0.0256454
[Epoch 84; Iter    83/  209] train: loss: 0.0282521
[Epoch 84; Iter   113/  209] train: loss: 0.0267986
[Epoch 84; Iter   143/  209] train: loss: 0.0271338
[Epoch 84; Iter   173/  209] train: loss: 0.0283375
[Epoch 84; Iter   203/  209] train: loss: 0.0383039
[Epoch 84] ogbg-moltox21: 0.738772 val loss: 0.645008
[Epoch 84] ogbg-moltox21: 0.714544 test loss: 0.681991
[Epoch 85; Iter    24/  209] train: loss: 0.0152799
[Epoch 85; Iter    54/  209] train: loss: 0.0257669
[Epoch 85; Iter    84/  209] train: loss: 0.0121480
[Epoch 85; Iter   114/  209] train: loss: 0.0912213
[Epoch 85; Iter   144/  209] train: loss: 0.0218130
[Epoch 85; Iter   174/  209] train: loss: 0.0540793
[Epoch 85; Iter   204/  209] train: loss: 0.0320339
[Epoch 85] ogbg-moltox21: 0.739940 val loss: 0.721710
[Epoch 85] ogbg-moltox21: 0.715138 test loss: 0.741370
[Epoch 86; Iter    25/  209] train: loss: 0.0400090
[Epoch 86; Iter    55/  209] train: loss: 0.0136777
[Epoch 86; Iter    85/  209] train: loss: 0.0133316
[Epoch 86; Iter   115/  209] train: loss: 0.0660320
[Epoch 86; Iter   145/  209] train: loss: 0.0057910
[Epoch 86; Iter   175/  209] train: loss: 0.0265139
[Epoch 86; Iter   205/  209] train: loss: 0.0616851
[Epoch 86] ogbg-moltox21: 0.729389 val loss: 0.731826
[Epoch 86] ogbg-moltox21: 0.717104 test loss: 0.822095
[Epoch 87; Iter    26/  209] train: loss: 0.0182880
[Epoch 87; Iter    56/  209] train: loss: 0.0139845
[Epoch 87; Iter    86/  209] train: loss: 0.0085438
[Epoch 87; Iter   116/  209] train: loss: 0.0173361
[Epoch 87; Iter   146/  209] train: loss: 0.0112374
[Epoch 87; Iter   176/  209] train: loss: 0.0335402
[Epoch 87; Iter   206/  209] train: loss: 0.0163867
[Epoch 87] ogbg-moltox21: 0.746161 val loss: 0.648833
[Epoch 87] ogbg-moltox21: 0.712357 test loss: 0.687359
[Epoch 88; Iter    27/  209] train: loss: 0.0180877
[Epoch 88; Iter    57/  209] train: loss: 0.0522118
[Epoch 88; Iter    87/  209] train: loss: 0.0163417
[Epoch 88; Iter   117/  209] train: loss: 0.0261021
[Epoch 88; Iter   147/  209] train: loss: 0.0092756
[Epoch 88; Iter   177/  209] train: loss: 0.0270071
[Epoch 88; Iter   207/  209] train: loss: 0.0363809
[Epoch 88] ogbg-moltox21: 0.728516 val loss: 0.707879
[Epoch 88] ogbg-moltox21: 0.705402 test loss: 0.844378
[Epoch 89; Iter    28/  209] train: loss: 0.0200424
[Epoch 89; Iter    58/  209] train: loss: 0.0436324
[Epoch 89; Iter    88/  209] train: loss: 0.0349920
[Epoch 89; Iter   118/  209] train: loss: 0.0162016
[Epoch 89; Iter   148/  209] train: loss: 0.0466382
[Epoch 89; Iter   178/  209] train: loss: 0.0196439
[Epoch 89; Iter   208/  209] train: loss: 0.0253931
[Epoch 89] ogbg-moltox21: 0.733556 val loss: 0.797308
[Epoch 89] ogbg-moltox21: 0.718675 test loss: 0.924163
[Epoch 90; Iter    29/  209] train: loss: 0.0139399
[Epoch 90; Iter    59/  209] train: loss: 0.0257144
[Epoch 90; Iter    89/  209] train: loss: 0.0207451
[Epoch 90; Iter   119/  209] train: loss: 0.0197459
[Epoch 90; Iter   149/  209] train: loss: 0.0082275
[Epoch 90; Iter   179/  209] train: loss: 0.0338236
[Epoch 90; Iter   209/  209] train: loss: 0.0505930
[Epoch 90] ogbg-moltox21: 0.742313 val loss: 0.699511
[Epoch 90] ogbg-moltox21: 0.708462 test loss: 0.771969
[Epoch 91; Iter    30/  209] train: loss: 0.0285769
[Epoch 91; Iter    60/  209] train: loss: 0.0130637
[Epoch 91; Iter    90/  209] train: loss: 0.0162726
[Epoch 91; Iter   120/  209] train: loss: 0.0574780
[Epoch 91; Iter   150/  209] train: loss: 0.0322303
[Epoch 91; Iter   180/  209] train: loss: 0.0125069
[Epoch 91] ogbg-moltox21: 0.741150 val loss: 0.821539
[Epoch 91] ogbg-moltox21: 0.717647 test loss: 0.955290
[Epoch 92; Iter     1/  209] train: loss: 0.0189883
[Epoch 92; Iter    31/  209] train: loss: 0.0246846
[Epoch 92; Iter    61/  209] train: loss: 0.0105573
[Epoch 92; Iter    91/  209] train: loss: 0.0408609
[Epoch 92; Iter   121/  209] train: loss: 0.0237216
[Epoch 92; Iter   151/  209] train: loss: 0.0104832
[Epoch 92; Iter   181/  209] train: loss: 0.0183016
[Epoch 92] ogbg-moltox21: 0.740468 val loss: 0.698538
[Epoch 92] ogbg-moltox21: 0.713134 test loss: 0.760515
[Epoch 93; Iter     2/  209] train: loss: 0.0116601
[Epoch 93; Iter    32/  209] train: loss: 0.0193572
[Epoch 93; Iter    62/  209] train: loss: 0.0150351
[Epoch 93; Iter    92/  209] train: loss: 0.0276168
[Epoch 93; Iter   122/  209] train: loss: 0.0105914
[Epoch 93; Iter   152/  209] train: loss: 0.0281606
[Epoch 93; Iter   182/  209] train: loss: 0.0134873
[Epoch 93] ogbg-moltox21: 0.736723 val loss: 0.709435
[Epoch 93] ogbg-moltox21: 0.720905 test loss: 0.785100
[Epoch 94; Iter     3/  209] train: loss: 0.0204066
[Epoch 94; Iter    33/  209] train: loss: 0.0168855
[Epoch 94; Iter    63/  209] train: loss: 0.0115205
[Epoch 94; Iter    93/  209] train: loss: 0.0268731
[Epoch 94; Iter   123/  209] train: loss: 0.0277540
[Epoch 94; Iter   153/  209] train: loss: 0.0110049
[Epoch 94; Iter   183/  209] train: loss: 0.0203462
[Epoch 94] ogbg-moltox21: 0.734863 val loss: 1.237895
[Epoch 94] ogbg-moltox21: 0.721277 test loss: 1.238162
[Epoch 95; Iter     4/  209] train: loss: 0.0195055
[Epoch 95; Iter    34/  209] train: loss: 0.0186119
[Epoch 95; Iter    64/  209] train: loss: 0.0084112
[Epoch 95; Iter    94/  209] train: loss: 0.0157790
[Epoch 95; Iter   124/  209] train: loss: 0.0342437
[Epoch 95; Iter   154/  209] train: loss: 0.0201034
[Epoch 95; Iter   184/  209] train: loss: 0.0573729
[Epoch 95] ogbg-moltox21: 0.736045 val loss: 0.739982
[Epoch 95] ogbg-moltox21: 0.710962 test loss: 0.864519
[Epoch 96; Iter     5/  209] train: loss: 0.0326334
[Epoch 96; Iter    35/  209] train: loss: 0.0238583
[Epoch 96; Iter    65/  209] train: loss: 0.0194022
[Epoch 96; Iter    95/  209] train: loss: 0.0287121
[Epoch 96; Iter   125/  209] train: loss: 0.0066563
[Epoch 96; Iter   155/  209] train: loss: 0.0274817
[Epoch 96; Iter   185/  209] train: loss: 0.0181694
[Epoch 96] ogbg-moltox21: 0.744404 val loss: 0.675402
[Epoch 96] ogbg-moltox21: 0.719844 test loss: 0.759238
[Epoch 97; Iter     6/  209] train: loss: 0.0085653
[Epoch 97; Iter    36/  209] train: loss: 0.0043849
[Epoch 97; Iter    66/  209] train: loss: 0.0361148
[Epoch 97; Iter    96/  209] train: loss: 0.0255436
[Epoch 97; Iter   126/  209] train: loss: 0.0452774
[Epoch 97; Iter   156/  209] train: loss: 0.0190126
[Epoch 97; Iter   186/  209] train: loss: 0.0365226
[Epoch 97] ogbg-moltox21: 0.739902 val loss: 0.751599
[Epoch 97] ogbg-moltox21: 0.720858 test loss: 0.880381
[Epoch 98; Iter     7/  209] train: loss: 0.0198557
[Epoch 98; Iter    37/  209] train: loss: 0.0139417
[Epoch 98; Iter    67/  209] train: loss: 0.0192658
[Epoch 98; Iter    97/  209] train: loss: 0.0261667
[Epoch 98; Iter   127/  209] train: loss: 0.0308972
[Epoch 98; Iter   157/  209] train: loss: 0.0154115
[Epoch 98; Iter   187/  209] train: loss: 0.0295267
[Epoch 98] ogbg-moltox21: 0.733827 val loss: 0.721107
[Epoch 98] ogbg-moltox21: 0.720247 test loss: 0.715434
[Epoch 99; Iter     8/  209] train: loss: 0.0210513
[Epoch 99; Iter    38/  209] train: loss: 0.0122114
[Epoch 99; Iter    68/  209] train: loss: 0.0216840
[Epoch 99; Iter    98/  209] train: loss: 0.0512822
[Epoch 82; Iter    51/  209] train: loss: 0.0122139
[Epoch 82; Iter    81/  209] train: loss: 0.0228412
[Epoch 82; Iter   111/  209] train: loss: 0.0252186
[Epoch 82; Iter   141/  209] train: loss: 0.0249660
[Epoch 82; Iter   171/  209] train: loss: 0.0171290
[Epoch 82; Iter   201/  209] train: loss: 0.0756266
[Epoch 82] ogbg-moltox21: 0.741120 val loss: 0.670893
[Epoch 82] ogbg-moltox21: 0.730862 test loss: 0.736592
[Epoch 83; Iter    22/  209] train: loss: 0.0097998
[Epoch 83; Iter    52/  209] train: loss: 0.0418097
[Epoch 83; Iter    82/  209] train: loss: 0.0331484
[Epoch 83; Iter   112/  209] train: loss: 0.0501956
[Epoch 83; Iter   142/  209] train: loss: 0.0236849
[Epoch 83; Iter   172/  209] train: loss: 0.0440323
[Epoch 83; Iter   202/  209] train: loss: 0.0271284
[Epoch 83] ogbg-moltox21: 0.741072 val loss: 0.629296
[Epoch 83] ogbg-moltox21: 0.729773 test loss: 0.692457
[Epoch 84; Iter    23/  209] train: loss: 0.0057400
[Epoch 84; Iter    53/  209] train: loss: 0.0089189
[Epoch 84; Iter    83/  209] train: loss: 0.0175758
[Epoch 84; Iter   113/  209] train: loss: 0.0295419
[Epoch 84; Iter   143/  209] train: loss: 0.0178732
[Epoch 84; Iter   173/  209] train: loss: 0.0222888
[Epoch 84; Iter   203/  209] train: loss: 0.0171149
[Epoch 84] ogbg-moltox21: 0.736390 val loss: 0.623458
[Epoch 84] ogbg-moltox21: 0.719311 test loss: 0.708136
[Epoch 85; Iter    24/  209] train: loss: 0.0208157
[Epoch 85; Iter    54/  209] train: loss: 0.0856337
[Epoch 85; Iter    84/  209] train: loss: 0.0106348
[Epoch 85; Iter   114/  209] train: loss: 0.0088847
[Epoch 85; Iter   144/  209] train: loss: 0.0359985
[Epoch 85; Iter   174/  209] train: loss: 0.0321088
[Epoch 85; Iter   204/  209] train: loss: 0.0131921
[Epoch 85] ogbg-moltox21: 0.737505 val loss: 0.614958
[Epoch 85] ogbg-moltox21: 0.722804 test loss: 0.693156
[Epoch 86; Iter    25/  209] train: loss: 0.0081584
[Epoch 86; Iter    55/  209] train: loss: 0.0119986
[Epoch 86; Iter    85/  209] train: loss: 0.0144048
[Epoch 86; Iter   115/  209] train: loss: 0.0160367
[Epoch 86; Iter   145/  209] train: loss: 0.0327396
[Epoch 86; Iter   175/  209] train: loss: 0.0119159
[Epoch 86; Iter   205/  209] train: loss: 0.0287996
[Epoch 86] ogbg-moltox21: 0.735129 val loss: 0.644614
[Epoch 86] ogbg-moltox21: 0.722028 test loss: 0.707353
[Epoch 87; Iter    26/  209] train: loss: 0.0124091
[Epoch 87; Iter    56/  209] train: loss: 0.0118744
[Epoch 87; Iter    86/  209] train: loss: 0.0237987
[Epoch 87; Iter   116/  209] train: loss: 0.0117023
[Epoch 87; Iter   146/  209] train: loss: 0.0252523
[Epoch 87; Iter   176/  209] train: loss: 0.0160502
[Epoch 87; Iter   206/  209] train: loss: 0.0359002
[Epoch 87] ogbg-moltox21: 0.734318 val loss: 0.636585
[Epoch 87] ogbg-moltox21: 0.722902 test loss: 0.709337
[Epoch 88; Iter    27/  209] train: loss: 0.0213838
[Epoch 88; Iter    57/  209] train: loss: 0.0173245
[Epoch 88; Iter    87/  209] train: loss: 0.0203800
[Epoch 88; Iter   117/  209] train: loss: 0.0179282
[Epoch 88; Iter   147/  209] train: loss: 0.0281628
[Epoch 88; Iter   177/  209] train: loss: 0.0308980
[Epoch 88; Iter   207/  209] train: loss: 0.0319029
[Epoch 88] ogbg-moltox21: 0.738866 val loss: 0.666095
[Epoch 88] ogbg-moltox21: 0.731371 test loss: 0.725459
[Epoch 89; Iter    28/  209] train: loss: 0.0082234
[Epoch 89; Iter    58/  209] train: loss: 0.0091898
[Epoch 89; Iter    88/  209] train: loss: 0.0126589
[Epoch 89; Iter   118/  209] train: loss: 0.0246973
[Epoch 89; Iter   148/  209] train: loss: 0.0218082
[Epoch 89; Iter   178/  209] train: loss: 0.0146980
[Epoch 89; Iter   208/  209] train: loss: 0.0241628
[Epoch 89] ogbg-moltox21: 0.731879 val loss: 0.633842
[Epoch 89] ogbg-moltox21: 0.725978 test loss: 0.707877
[Epoch 90; Iter    29/  209] train: loss: 0.0097986
[Epoch 90; Iter    59/  209] train: loss: 0.0279306
[Epoch 90; Iter    89/  209] train: loss: 0.0197032
[Epoch 90; Iter   119/  209] train: loss: 0.0165147
[Epoch 90; Iter   149/  209] train: loss: 0.0081196
[Epoch 90; Iter   179/  209] train: loss: 0.0183526
[Epoch 90; Iter   209/  209] train: loss: 0.0192259
[Epoch 90] ogbg-moltox21: 0.745333 val loss: 0.605854
[Epoch 90] ogbg-moltox21: 0.737143 test loss: 0.673179
[Epoch 91; Iter    30/  209] train: loss: 0.0140117
[Epoch 91; Iter    60/  209] train: loss: 0.0219469
[Epoch 91; Iter    90/  209] train: loss: 0.1306199
[Epoch 91; Iter   120/  209] train: loss: 0.0275770
[Epoch 91; Iter   150/  209] train: loss: 0.0232877
[Epoch 91; Iter   180/  209] train: loss: 0.0302201
[Epoch 91] ogbg-moltox21: 0.733851 val loss: 0.648525
[Epoch 91] ogbg-moltox21: 0.729747 test loss: 0.692854
[Epoch 92; Iter     1/  209] train: loss: 0.0090394
[Epoch 92; Iter    31/  209] train: loss: 0.0263953
[Epoch 92; Iter    61/  209] train: loss: 0.0149428
[Epoch 92; Iter    91/  209] train: loss: 0.0097418
[Epoch 92; Iter   121/  209] train: loss: 0.0187664
[Epoch 92; Iter   151/  209] train: loss: 0.0107590
[Epoch 92; Iter   181/  209] train: loss: 0.0143845
[Epoch 92] ogbg-moltox21: 0.737896 val loss: 0.684386
[Epoch 92] ogbg-moltox21: 0.723328 test loss: 0.758148
[Epoch 93; Iter     2/  209] train: loss: 0.0201968
[Epoch 93; Iter    32/  209] train: loss: 0.0382158
[Epoch 93; Iter    62/  209] train: loss: 0.0521417
[Epoch 93; Iter    92/  209] train: loss: 0.0354641
[Epoch 93; Iter   122/  209] train: loss: 0.0180622
[Epoch 93; Iter   152/  209] train: loss: 0.0096634
[Epoch 93; Iter   182/  209] train: loss: 0.0142138
[Epoch 93] ogbg-moltox21: 0.734100 val loss: 0.654796
[Epoch 93] ogbg-moltox21: 0.724135 test loss: 0.731821
[Epoch 94; Iter     3/  209] train: loss: 0.0176773
[Epoch 94; Iter    33/  209] train: loss: 0.0328715
[Epoch 94; Iter    63/  209] train: loss: 0.0112610
[Epoch 94; Iter    93/  209] train: loss: 0.0168930
[Epoch 94; Iter   123/  209] train: loss: 0.0255499
[Epoch 94; Iter   153/  209] train: loss: 0.0160326
[Epoch 94; Iter   183/  209] train: loss: 0.0227606
[Epoch 94] ogbg-moltox21: 0.736853 val loss: 0.681003
[Epoch 94] ogbg-moltox21: 0.725463 test loss: 0.737868
[Epoch 95; Iter     4/  209] train: loss: 0.0136456
[Epoch 95; Iter    34/  209] train: loss: 0.0070887
[Epoch 95; Iter    64/  209] train: loss: 0.0170510
[Epoch 95; Iter    94/  209] train: loss: 0.0046176
[Epoch 95; Iter   124/  209] train: loss: 0.0098774
[Epoch 95; Iter   154/  209] train: loss: 0.0093500
[Epoch 95; Iter   184/  209] train: loss: 0.0292441
[Epoch 95] ogbg-moltox21: 0.742577 val loss: 0.638227
[Epoch 95] ogbg-moltox21: 0.725907 test loss: 0.699174
[Epoch 96; Iter     5/  209] train: loss: 0.0069229
[Epoch 96; Iter    35/  209] train: loss: 0.0088696
[Epoch 96; Iter    65/  209] train: loss: 0.0220123
[Epoch 96; Iter    95/  209] train: loss: 0.0099366
[Epoch 96; Iter   125/  209] train: loss: 0.0275068
[Epoch 96; Iter   155/  209] train: loss: 0.0197122
[Epoch 96; Iter   185/  209] train: loss: 0.0361103
[Epoch 96] ogbg-moltox21: 0.746653 val loss: 0.663923
[Epoch 96] ogbg-moltox21: 0.720842 test loss: 0.737137
[Epoch 97; Iter     6/  209] train: loss: 0.0202208
[Epoch 97; Iter    36/  209] train: loss: 0.0152395
[Epoch 97; Iter    66/  209] train: loss: 0.0250994
[Epoch 97; Iter    96/  209] train: loss: 0.0187149
[Epoch 97; Iter   126/  209] train: loss: 0.0125481
[Epoch 97; Iter   156/  209] train: loss: 0.0521699
[Epoch 97; Iter   186/  209] train: loss: 0.0340708
[Epoch 97] ogbg-moltox21: 0.744309 val loss: 0.691451
[Epoch 97] ogbg-moltox21: 0.721069 test loss: 0.761685
[Epoch 98; Iter     7/  209] train: loss: 0.0171808
[Epoch 98; Iter    37/  209] train: loss: 0.0136918
[Epoch 98; Iter    67/  209] train: loss: 0.0130605
[Epoch 98; Iter    97/  209] train: loss: 0.0132469
[Epoch 98; Iter   127/  209] train: loss: 0.0040438
[Epoch 98; Iter   157/  209] train: loss: 0.0076906
[Epoch 98; Iter   187/  209] train: loss: 0.0093163
[Epoch 98] ogbg-moltox21: 0.742205 val loss: 0.663795
[Epoch 98] ogbg-moltox21: 0.723058 test loss: 0.730141
[Epoch 99; Iter     8/  209] train: loss: 0.0125987
[Epoch 99; Iter    38/  209] train: loss: 0.0032818
[Epoch 99; Iter    68/  209] train: loss: 0.0118988
[Epoch 99; Iter    98/  209] train: loss: 0.0082552
[Epoch 82; Iter    51/  209] train: loss: 0.0280206
[Epoch 82; Iter    81/  209] train: loss: 0.0321808
[Epoch 82; Iter   111/  209] train: loss: 0.0529039
[Epoch 82; Iter   141/  209] train: loss: 0.0467375
[Epoch 82; Iter   171/  209] train: loss: 0.0453901
[Epoch 82; Iter   201/  209] train: loss: 0.1219013
[Epoch 82] ogbg-moltox21: 0.768354 val loss: 0.422873
[Epoch 82] ogbg-moltox21: 0.735968 test loss: 0.448147
[Epoch 83; Iter    22/  209] train: loss: 0.0258389
[Epoch 83; Iter    52/  209] train: loss: 0.0566468
[Epoch 83; Iter    82/  209] train: loss: 0.0354950
[Epoch 83; Iter   112/  209] train: loss: 0.0541182
[Epoch 83; Iter   142/  209] train: loss: 0.0620264
[Epoch 83; Iter   172/  209] train: loss: 0.0730065
[Epoch 83; Iter   202/  209] train: loss: 0.0498528
[Epoch 83] ogbg-moltox21: 0.765161 val loss: 0.443021
[Epoch 83] ogbg-moltox21: 0.728622 test loss: 0.465910
[Epoch 84; Iter    23/  209] train: loss: 0.0291402
[Epoch 84; Iter    53/  209] train: loss: 0.0374844
[Epoch 84; Iter    83/  209] train: loss: 0.0409915
[Epoch 84; Iter   113/  209] train: loss: 0.0414142
[Epoch 84; Iter   143/  209] train: loss: 0.0360819
[Epoch 84; Iter   173/  209] train: loss: 0.0228569
[Epoch 84; Iter   203/  209] train: loss: 0.0359383
[Epoch 84] ogbg-moltox21: 0.765466 val loss: 0.436323
[Epoch 84] ogbg-moltox21: 0.730763 test loss: 0.447446
[Epoch 85; Iter    24/  209] train: loss: 0.0206985
[Epoch 85; Iter    54/  209] train: loss: 0.1039061
[Epoch 85; Iter    84/  209] train: loss: 0.0186972
[Epoch 85; Iter   114/  209] train: loss: 0.0285945
[Epoch 85; Iter   144/  209] train: loss: 0.0279425
[Epoch 85; Iter   174/  209] train: loss: 0.0514978
[Epoch 85; Iter   204/  209] train: loss: 0.0350135
[Epoch 85] ogbg-moltox21: 0.772792 val loss: 0.434360
[Epoch 85] ogbg-moltox21: 0.735172 test loss: 0.463028
[Epoch 86; Iter    25/  209] train: loss: 0.0194694
[Epoch 86; Iter    55/  209] train: loss: 0.0307126
[Epoch 86; Iter    85/  209] train: loss: 0.0390225
[Epoch 86; Iter   115/  209] train: loss: 0.0196789
[Epoch 86; Iter   145/  209] train: loss: 0.1056641
[Epoch 86; Iter   175/  209] train: loss: 0.0292091
[Epoch 86; Iter   205/  209] train: loss: 0.0447040
[Epoch 86] ogbg-moltox21: 0.774515 val loss: 0.425074
[Epoch 86] ogbg-moltox21: 0.737224 test loss: 0.458894
[Epoch 87; Iter    26/  209] train: loss: 0.0144858
[Epoch 87; Iter    56/  209] train: loss: 0.0537317
[Epoch 87; Iter    86/  209] train: loss: 0.0406718
[Epoch 87; Iter   116/  209] train: loss: 0.0326122
[Epoch 87; Iter   146/  209] train: loss: 0.0522833
[Epoch 87; Iter   176/  209] train: loss: 0.0345873
[Epoch 87; Iter   206/  209] train: loss: 0.0583739
[Epoch 87] ogbg-moltox21: 0.770585 val loss: 0.448581
[Epoch 87] ogbg-moltox21: 0.730951 test loss: 0.477001
[Epoch 88; Iter    27/  209] train: loss: 0.0387492
[Epoch 88; Iter    57/  209] train: loss: 0.0207669
[Epoch 88; Iter    87/  209] train: loss: 0.0357213
[Epoch 88; Iter   117/  209] train: loss: 0.0227873
[Epoch 88; Iter   147/  209] train: loss: 0.0393253
[Epoch 88; Iter   177/  209] train: loss: 0.0486900
[Epoch 88; Iter   207/  209] train: loss: 0.0402800
[Epoch 88] ogbg-moltox21: 0.760742 val loss: 0.450706
[Epoch 88] ogbg-moltox21: 0.725015 test loss: 0.472120
[Epoch 89; Iter    28/  209] train: loss: 0.0301741
[Epoch 89; Iter    58/  209] train: loss: 0.0385911
[Epoch 89; Iter    88/  209] train: loss: 0.0336791
[Epoch 89; Iter   118/  209] train: loss: 0.0253515
[Epoch 89; Iter   148/  209] train: loss: 0.0389139
[Epoch 89; Iter   178/  209] train: loss: 0.0255874
[Epoch 89; Iter   208/  209] train: loss: 0.0180686
[Epoch 89] ogbg-moltox21: 0.764017 val loss: 0.448054
[Epoch 89] ogbg-moltox21: 0.729542 test loss: 0.463561
[Epoch 90; Iter    29/  209] train: loss: 0.0197424
[Epoch 90; Iter    59/  209] train: loss: 0.0281363
[Epoch 90; Iter    89/  209] train: loss: 0.0226775
[Epoch 90; Iter   119/  209] train: loss: 0.0417007
[Epoch 90; Iter   149/  209] train: loss: 0.0125264
[Epoch 90; Iter   179/  209] train: loss: 0.0301709
[Epoch 90; Iter   209/  209] train: loss: 0.0240598
[Epoch 90] ogbg-moltox21: 0.764025 val loss: 0.454502
[Epoch 90] ogbg-moltox21: 0.731756 test loss: 0.479558
[Epoch 91; Iter    30/  209] train: loss: 0.0276449
[Epoch 91; Iter    60/  209] train: loss: 0.0353149
[Epoch 91; Iter    90/  209] train: loss: 0.1263142
[Epoch 91; Iter   120/  209] train: loss: 0.0261247
[Epoch 91; Iter   150/  209] train: loss: 0.0237141
[Epoch 91; Iter   180/  209] train: loss: 0.0403836
[Epoch 91] ogbg-moltox21: 0.764464 val loss: 0.466929
[Epoch 91] ogbg-moltox21: 0.725427 test loss: 0.493906
[Epoch 92; Iter     1/  209] train: loss: 0.0322838
[Epoch 92; Iter    31/  209] train: loss: 0.0267021
[Epoch 92; Iter    61/  209] train: loss: 0.0143598
[Epoch 92; Iter    91/  209] train: loss: 0.0363365
[Epoch 92; Iter   121/  209] train: loss: 0.0375019
[Epoch 92; Iter   151/  209] train: loss: 0.0257312
[Epoch 92; Iter   181/  209] train: loss: 0.0276776
[Epoch 92] ogbg-moltox21: 0.768208 val loss: 0.447197
[Epoch 92] ogbg-moltox21: 0.724516 test loss: 0.478646
[Epoch 93; Iter     2/  209] train: loss: 0.0484485
[Epoch 93; Iter    32/  209] train: loss: 0.0470804
[Epoch 93; Iter    62/  209] train: loss: 0.0205090
[Epoch 93; Iter    92/  209] train: loss: 0.0377980
[Epoch 93; Iter   122/  209] train: loss: 0.0156322
[Epoch 93; Iter   152/  209] train: loss: 0.0215404
[Epoch 93; Iter   182/  209] train: loss: 0.0165512
[Epoch 93] ogbg-moltox21: 0.767268 val loss: 0.456296
[Epoch 93] ogbg-moltox21: 0.727960 test loss: 0.484787
[Epoch 94; Iter     3/  209] train: loss: 0.0217607
[Epoch 94; Iter    33/  209] train: loss: 0.0190323
[Epoch 94; Iter    63/  209] train: loss: 0.0196632
[Epoch 94; Iter    93/  209] train: loss: 0.0154217
[Epoch 94; Iter   123/  209] train: loss: 0.0216804
[Epoch 94; Iter   153/  209] train: loss: 0.0217414
[Epoch 94; Iter   183/  209] train: loss: 0.0274449
[Epoch 94] ogbg-moltox21: 0.763227 val loss: 0.458716
[Epoch 94] ogbg-moltox21: 0.723734 test loss: 0.479903
[Epoch 95; Iter     4/  209] train: loss: 0.0695436
[Epoch 95; Iter    34/  209] train: loss: 0.0180243
[Epoch 95; Iter    64/  209] train: loss: 0.0296467
[Epoch 95; Iter    94/  209] train: loss: 0.0116418
[Epoch 95; Iter   124/  209] train: loss: 0.0338618
[Epoch 95; Iter   154/  209] train: loss: 0.0180145
[Epoch 95; Iter   184/  209] train: loss: 0.0314559
[Epoch 95] ogbg-moltox21: 0.776244 val loss: 0.457892
[Epoch 95] ogbg-moltox21: 0.732953 test loss: 0.485468
[Epoch 96; Iter     5/  209] train: loss: 0.0184558
[Epoch 96; Iter    35/  209] train: loss: 0.0242638
[Epoch 96; Iter    65/  209] train: loss: 0.0253967
[Epoch 96; Iter    95/  209] train: loss: 0.0392165
[Epoch 96; Iter   125/  209] train: loss: 0.0354906
[Epoch 96; Iter   155/  209] train: loss: 0.0550270
[Epoch 96; Iter   185/  209] train: loss: 0.0499286
[Epoch 96] ogbg-moltox21: 0.766488 val loss: 0.450187
[Epoch 96] ogbg-moltox21: 0.730141 test loss: 0.479894
[Epoch 97; Iter     6/  209] train: loss: 0.0447996
[Epoch 97; Iter    36/  209] train: loss: 0.0225671
[Epoch 97; Iter    66/  209] train: loss: 0.0252490
[Epoch 97; Iter    96/  209] train: loss: 0.0156891
[Epoch 97; Iter   126/  209] train: loss: 0.0297958
[Epoch 97; Iter   156/  209] train: loss: 0.0674855
[Epoch 97; Iter   186/  209] train: loss: 0.0280487
[Epoch 97] ogbg-moltox21: 0.771498 val loss: 0.461550
[Epoch 97] ogbg-moltox21: 0.727864 test loss: 0.498042
[Epoch 98; Iter     7/  209] train: loss: 0.0356126
[Epoch 98; Iter    37/  209] train: loss: 0.0422034
[Epoch 98; Iter    67/  209] train: loss: 0.0176814
[Epoch 98; Iter    97/  209] train: loss: 0.0515982
[Epoch 98; Iter   127/  209] train: loss: 0.0136192
[Epoch 98; Iter   157/  209] train: loss: 0.0254422
[Epoch 98; Iter   187/  209] train: loss: 0.0473761
[Epoch 98] ogbg-moltox21: 0.765978 val loss: 0.453073
[Epoch 98] ogbg-moltox21: 0.726486 test loss: 0.482782
[Epoch 99; Iter     8/  209] train: loss: 0.0201676
[Epoch 99; Iter    38/  209] train: loss: 0.0145978
[Epoch 99; Iter    68/  209] train: loss: 0.0253823
[Epoch 99; Iter    98/  209] train: loss: 0.0315368
[Epoch 82; Iter    51/  209] train: loss: 0.0274442
[Epoch 82; Iter    81/  209] train: loss: 0.0298216
[Epoch 82; Iter   111/  209] train: loss: 0.1066462
[Epoch 82; Iter   141/  209] train: loss: 0.0185781
[Epoch 82; Iter   171/  209] train: loss: 0.0200026
[Epoch 82; Iter   201/  209] train: loss: 0.0240511
[Epoch 82] ogbg-moltox21: 0.738555 val loss: 0.528407
[Epoch 82] ogbg-moltox21: 0.716695 test loss: 0.533986
[Epoch 83; Iter    22/  209] train: loss: 0.0392603
[Epoch 83; Iter    52/  209] train: loss: 0.0601448
[Epoch 83; Iter    82/  209] train: loss: 0.0481361
[Epoch 83; Iter   112/  209] train: loss: 0.0498839
[Epoch 83; Iter   142/  209] train: loss: 0.0229198
[Epoch 83; Iter   172/  209] train: loss: 0.0126963
[Epoch 83; Iter   202/  209] train: loss: 0.0313018
[Epoch 83] ogbg-moltox21: 0.756345 val loss: 0.477301
[Epoch 83] ogbg-moltox21: 0.730321 test loss: 0.522689
[Epoch 84; Iter    23/  209] train: loss: 0.0368512
[Epoch 84; Iter    53/  209] train: loss: 0.0145617
[Epoch 84; Iter    83/  209] train: loss: 0.0245786
[Epoch 84; Iter   113/  209] train: loss: 0.0315605
[Epoch 84; Iter   143/  209] train: loss: 0.0248009
[Epoch 84; Iter   173/  209] train: loss: 0.0237562
[Epoch 84; Iter   203/  209] train: loss: 0.0145758
[Epoch 84] ogbg-moltox21: 0.740302 val loss: 0.522397
[Epoch 84] ogbg-moltox21: 0.721144 test loss: 0.545778
[Epoch 85; Iter    24/  209] train: loss: 0.0373737
[Epoch 85; Iter    54/  209] train: loss: 0.0346979
[Epoch 85; Iter    84/  209] train: loss: 0.0308488
[Epoch 85; Iter   114/  209] train: loss: 0.0956902
[Epoch 85; Iter   144/  209] train: loss: 0.0315702
[Epoch 85; Iter   174/  209] train: loss: 0.0579207
[Epoch 85; Iter   204/  209] train: loss: 0.0283084
[Epoch 85] ogbg-moltox21: 0.753479 val loss: 0.500041
[Epoch 85] ogbg-moltox21: 0.725881 test loss: 0.531680
[Epoch 86; Iter    25/  209] train: loss: 0.0218368
[Epoch 86; Iter    55/  209] train: loss: 0.0255870
[Epoch 86; Iter    85/  209] train: loss: 0.0458698
[Epoch 86; Iter   115/  209] train: loss: 0.0353026
[Epoch 86; Iter   145/  209] train: loss: 0.0140420
[Epoch 86; Iter   175/  209] train: loss: 0.0192623
[Epoch 86; Iter   205/  209] train: loss: 0.0831243
[Epoch 86] ogbg-moltox21: 0.756693 val loss: 0.483152
[Epoch 86] ogbg-moltox21: 0.726253 test loss: 0.518502
[Epoch 87; Iter    26/  209] train: loss: 0.0255419
[Epoch 87; Iter    56/  209] train: loss: 0.0249966
[Epoch 87; Iter    86/  209] train: loss: 0.0168049
[Epoch 87; Iter   116/  209] train: loss: 0.0133631
[Epoch 87; Iter   146/  209] train: loss: 0.0197051
[Epoch 87; Iter   176/  209] train: loss: 0.0350143
[Epoch 87; Iter   206/  209] train: loss: 0.0125165
[Epoch 87] ogbg-moltox21: 0.755802 val loss: 0.502214
[Epoch 87] ogbg-moltox21: 0.730330 test loss: 0.550104
[Epoch 88; Iter    27/  209] train: loss: 0.0250205
[Epoch 88; Iter    57/  209] train: loss: 0.0292905
[Epoch 88; Iter    87/  209] train: loss: 0.0241686
[Epoch 88; Iter   117/  209] train: loss: 0.0566993
[Epoch 88; Iter   147/  209] train: loss: 0.0102142
[Epoch 88; Iter   177/  209] train: loss: 0.0156108
[Epoch 88; Iter   207/  209] train: loss: 0.0314284
[Epoch 88] ogbg-moltox21: 0.753633 val loss: 0.504349
[Epoch 88] ogbg-moltox21: 0.726444 test loss: 0.550866
[Epoch 89; Iter    28/  209] train: loss: 0.0109360
[Epoch 89; Iter    58/  209] train: loss: 0.0534015
[Epoch 89; Iter    88/  209] train: loss: 0.0216304
[Epoch 89; Iter   118/  209] train: loss: 0.0150652
[Epoch 89; Iter   148/  209] train: loss: 0.0389409
[Epoch 89; Iter   178/  209] train: loss: 0.0554491
[Epoch 89; Iter   208/  209] train: loss: 0.0247700
[Epoch 89] ogbg-moltox21: 0.759626 val loss: 0.494551
[Epoch 89] ogbg-moltox21: 0.729429 test loss: 0.542107
[Epoch 90; Iter    29/  209] train: loss: 0.0205648
[Epoch 90; Iter    59/  209] train: loss: 0.0281005
[Epoch 90; Iter    89/  209] train: loss: 0.0216517
[Epoch 90; Iter   119/  209] train: loss: 0.0390097
[Epoch 90; Iter   149/  209] train: loss: 0.0201568
[Epoch 90; Iter   179/  209] train: loss: 0.0141867
[Epoch 90; Iter   209/  209] train: loss: 0.0533918
[Epoch 90] ogbg-moltox21: 0.751738 val loss: 0.528760
[Epoch 90] ogbg-moltox21: 0.724244 test loss: 0.566661
[Epoch 91; Iter    30/  209] train: loss: 0.0197413
[Epoch 91; Iter    60/  209] train: loss: 0.0093586
[Epoch 91; Iter    90/  209] train: loss: 0.0164873
[Epoch 91; Iter   120/  209] train: loss: 0.0183005
[Epoch 91; Iter   150/  209] train: loss: 0.0410247
[Epoch 91; Iter   180/  209] train: loss: 0.0311790
[Epoch 91] ogbg-moltox21: 0.751168 val loss: 0.545757
[Epoch 91] ogbg-moltox21: 0.719582 test loss: 0.578403
[Epoch 92; Iter     1/  209] train: loss: 0.0142793
[Epoch 92; Iter    31/  209] train: loss: 0.0345253
[Epoch 92; Iter    61/  209] train: loss: 0.0280928
[Epoch 92; Iter    91/  209] train: loss: 0.0438378
[Epoch 92; Iter   121/  209] train: loss: 0.0250460
[Epoch 92; Iter   151/  209] train: loss: 0.0114145
[Epoch 92; Iter   181/  209] train: loss: 0.0080232
[Epoch 92] ogbg-moltox21: 0.748117 val loss: 0.550080
[Epoch 92] ogbg-moltox21: 0.723292 test loss: 0.569583
[Epoch 93; Iter     2/  209] train: loss: 0.0137316
[Epoch 93; Iter    32/  209] train: loss: 0.0247606
[Epoch 93; Iter    62/  209] train: loss: 0.0241043
[Epoch 93; Iter    92/  209] train: loss: 0.0189091
[Epoch 93; Iter   122/  209] train: loss: 0.0156093
[Epoch 93; Iter   152/  209] train: loss: 0.0371419
[Epoch 93; Iter   182/  209] train: loss: 0.0188743
[Epoch 93] ogbg-moltox21: 0.750018 val loss: 0.523874
[Epoch 93] ogbg-moltox21: 0.726511 test loss: 0.559677
[Epoch 94; Iter     3/  209] train: loss: 0.0184646
[Epoch 94; Iter    33/  209] train: loss: 0.0276300
[Epoch 94; Iter    63/  209] train: loss: 0.0100829
[Epoch 94; Iter    93/  209] train: loss: 0.0272088
[Epoch 94; Iter   123/  209] train: loss: 0.0217501
[Epoch 94; Iter   153/  209] train: loss: 0.0155597
[Epoch 94; Iter   183/  209] train: loss: 0.0092386
[Epoch 94] ogbg-moltox21: 0.748090 val loss: 0.532650
[Epoch 94] ogbg-moltox21: 0.721411 test loss: 0.567257
[Epoch 95; Iter     4/  209] train: loss: 0.0158783
[Epoch 95; Iter    34/  209] train: loss: 0.0325013
[Epoch 95; Iter    64/  209] train: loss: 0.0157125
[Epoch 95; Iter    94/  209] train: loss: 0.0118312
[Epoch 95; Iter   124/  209] train: loss: 0.0279457
[Epoch 95; Iter   154/  209] train: loss: 0.0201575
[Epoch 95; Iter   184/  209] train: loss: 0.0169879
[Epoch 95] ogbg-moltox21: 0.745931 val loss: 0.552952
[Epoch 95] ogbg-moltox21: 0.723198 test loss: 0.591341
[Epoch 96; Iter     5/  209] train: loss: 0.0406627
[Epoch 96; Iter    35/  209] train: loss: 0.0147049
[Epoch 96; Iter    65/  209] train: loss: 0.0154073
[Epoch 96; Iter    95/  209] train: loss: 0.0106183
[Epoch 96; Iter   125/  209] train: loss: 0.0110637
[Epoch 96; Iter   155/  209] train: loss: 0.0126826
[Epoch 96; Iter   185/  209] train: loss: 0.0073323
[Epoch 96] ogbg-moltox21: 0.751205 val loss: 0.552794
[Epoch 96] ogbg-moltox21: 0.723513 test loss: 0.653240
[Epoch 97; Iter     6/  209] train: loss: 0.0132364
[Epoch 97; Iter    36/  209] train: loss: 0.0133857
[Epoch 97; Iter    66/  209] train: loss: 0.0128767
[Epoch 97; Iter    96/  209] train: loss: 0.0131900
[Epoch 97; Iter   126/  209] train: loss: 0.0263857
[Epoch 97; Iter   156/  209] train: loss: 0.0149216
[Epoch 97; Iter   186/  209] train: loss: 0.0119586
[Epoch 97] ogbg-moltox21: 0.753849 val loss: 0.534143
[Epoch 97] ogbg-moltox21: 0.723494 test loss: 0.609764
[Epoch 98; Iter     7/  209] train: loss: 0.0199957
[Epoch 98; Iter    37/  209] train: loss: 0.0124557
[Epoch 98; Iter    67/  209] train: loss: 0.0148116
[Epoch 98; Iter    97/  209] train: loss: 0.0237005
[Epoch 98; Iter   127/  209] train: loss: 0.0382644
[Epoch 98; Iter   157/  209] train: loss: 0.0119017
[Epoch 98; Iter   187/  209] train: loss: 0.0116406
[Epoch 98] ogbg-moltox21: 0.745946 val loss: 0.533735
[Epoch 98] ogbg-moltox21: 0.719548 test loss: 0.572105
[Epoch 99; Iter     8/  209] train: loss: 0.0240334
[Epoch 99; Iter    38/  209] train: loss: 0.0216248
[Epoch 99; Iter    68/  209] train: loss: 0.0325736
[Epoch 99; Iter    98/  209] train: loss: 0.0472515
[Epoch 82; Iter    51/  209] train: loss: 0.0143288
[Epoch 82; Iter    81/  209] train: loss: 0.0083609
[Epoch 82; Iter   111/  209] train: loss: 0.0634397
[Epoch 82; Iter   141/  209] train: loss: 0.0045316
[Epoch 82; Iter   171/  209] train: loss: 0.0029441
[Epoch 82; Iter   201/  209] train: loss: 0.0097752
[Epoch 82] ogbg-moltox21: 0.725137 val loss: 0.697438
[Epoch 82] ogbg-moltox21: 0.691570 test loss: 0.763503
[Epoch 83; Iter    22/  209] train: loss: 0.0094913
[Epoch 83; Iter    52/  209] train: loss: 0.0156913
[Epoch 83; Iter    82/  209] train: loss: 0.0107880
[Epoch 83; Iter   112/  209] train: loss: 0.0150561
[Epoch 83; Iter   142/  209] train: loss: 0.0056890
[Epoch 83; Iter   172/  209] train: loss: 0.0050258
[Epoch 83; Iter   202/  209] train: loss: 0.0050443
[Epoch 83] ogbg-moltox21: 0.728362 val loss: 0.687790
[Epoch 83] ogbg-moltox21: 0.692301 test loss: 0.758150
[Epoch 84; Iter    23/  209] train: loss: 0.0051367
[Epoch 84; Iter    53/  209] train: loss: 0.0093732
[Epoch 84; Iter    83/  209] train: loss: 0.0095708
[Epoch 84; Iter   113/  209] train: loss: 0.0243474
[Epoch 84; Iter   143/  209] train: loss: 0.0101706
[Epoch 84; Iter   173/  209] train: loss: 0.0139113
[Epoch 84; Iter   203/  209] train: loss: 0.0036824
[Epoch 84] ogbg-moltox21: 0.716644 val loss: 0.741785
[Epoch 84] ogbg-moltox21: 0.688128 test loss: 0.811554
[Epoch 85; Iter    24/  209] train: loss: 0.0088895
[Epoch 85; Iter    54/  209] train: loss: 0.0075736
[Epoch 85; Iter    84/  209] train: loss: 0.0083864
[Epoch 85; Iter   114/  209] train: loss: 0.0325775
[Epoch 85; Iter   144/  209] train: loss: 0.0088843
[Epoch 85; Iter   174/  209] train: loss: 0.0353531
[Epoch 85; Iter   204/  209] train: loss: 0.0092856
[Epoch 85] ogbg-moltox21: 0.719878 val loss: 0.714765
[Epoch 85] ogbg-moltox21: 0.692052 test loss: 0.771668
[Epoch 86; Iter    25/  209] train: loss: 0.0044113
[Epoch 86; Iter    55/  209] train: loss: 0.0062937
[Epoch 86; Iter    85/  209] train: loss: 0.0090704
[Epoch 86; Iter   115/  209] train: loss: 0.0077506
[Epoch 86; Iter   145/  209] train: loss: 0.0030661
[Epoch 86; Iter   175/  209] train: loss: 0.0110062
[Epoch 86; Iter   205/  209] train: loss: 0.0330943
[Epoch 86] ogbg-moltox21: 0.720156 val loss: 0.725179
[Epoch 86] ogbg-moltox21: 0.688743 test loss: 0.797160
[Epoch 87; Iter    26/  209] train: loss: 0.0050517
[Epoch 87; Iter    56/  209] train: loss: 0.0057304
[Epoch 87; Iter    86/  209] train: loss: 0.0045281
[Epoch 87; Iter   116/  209] train: loss: 0.0139633
[Epoch 87; Iter   146/  209] train: loss: 0.0081339
[Epoch 87; Iter   176/  209] train: loss: 0.0066077
[Epoch 87; Iter   206/  209] train: loss: 0.0133341
[Epoch 87] ogbg-moltox21: 0.724148 val loss: 0.753114
[Epoch 87] ogbg-moltox21: 0.688727 test loss: 0.963571
[Epoch 88; Iter    27/  209] train: loss: 0.0114131
[Epoch 88; Iter    57/  209] train: loss: 0.0190005
[Epoch 88; Iter    87/  209] train: loss: 0.0096266
[Epoch 88; Iter   117/  209] train: loss: 0.0068633
[Epoch 88; Iter   147/  209] train: loss: 0.0074069
[Epoch 88; Iter   177/  209] train: loss: 0.0076519
[Epoch 88; Iter   207/  209] train: loss: 0.0068409
[Epoch 88] ogbg-moltox21: 0.721826 val loss: 0.772156
[Epoch 88] ogbg-moltox21: 0.690705 test loss: 0.844806
[Epoch 89; Iter    28/  209] train: loss: 0.0039281
[Epoch 89; Iter    58/  209] train: loss: 0.0165097
[Epoch 89; Iter    88/  209] train: loss: 0.0046887
[Epoch 89; Iter   118/  209] train: loss: 0.0070988
[Epoch 89; Iter   148/  209] train: loss: 0.0163498
[Epoch 89; Iter   178/  209] train: loss: 0.0087706
[Epoch 89; Iter   208/  209] train: loss: 0.0236145
[Epoch 89] ogbg-moltox21: 0.721241 val loss: 0.762468
[Epoch 89] ogbg-moltox21: 0.686019 test loss: 0.824283
[Epoch 90; Iter    29/  209] train: loss: 0.0215069
[Epoch 90; Iter    59/  209] train: loss: 0.0117937
[Epoch 90; Iter    89/  209] train: loss: 0.0050901
[Epoch 90; Iter   119/  209] train: loss: 0.0107227
[Epoch 90; Iter   149/  209] train: loss: 0.0047099
[Epoch 90; Iter   179/  209] train: loss: 0.0025178
[Epoch 90; Iter   209/  209] train: loss: 0.0515685
[Epoch 90] ogbg-moltox21: 0.721753 val loss: 0.787224
[Epoch 90] ogbg-moltox21: 0.689467 test loss: 0.846484
[Epoch 91; Iter    30/  209] train: loss: 0.0082384
[Epoch 91; Iter    60/  209] train: loss: 0.0019380
[Epoch 91; Iter    90/  209] train: loss: 0.0061017
[Epoch 91; Iter   120/  209] train: loss: 0.0056275
[Epoch 91; Iter   150/  209] train: loss: 0.0123982
[Epoch 91; Iter   180/  209] train: loss: 0.0055530
[Epoch 91] ogbg-moltox21: 0.722284 val loss: 0.725044
[Epoch 91] ogbg-moltox21: 0.690744 test loss: 1.022881
[Epoch 92; Iter     1/  209] train: loss: 0.0072653
[Epoch 92; Iter    31/  209] train: loss: 0.0085247
[Epoch 92; Iter    61/  209] train: loss: 0.0053005
[Epoch 92; Iter    91/  209] train: loss: 0.0169844
[Epoch 92; Iter   121/  209] train: loss: 0.0067627
[Epoch 92; Iter   151/  209] train: loss: 0.0033222
[Epoch 92; Iter   181/  209] train: loss: 0.0058602
[Epoch 92] ogbg-moltox21: 0.722331 val loss: 0.758789
[Epoch 92] ogbg-moltox21: 0.693054 test loss: 0.822007
[Epoch 93; Iter     2/  209] train: loss: 0.0066979
[Epoch 93; Iter    32/  209] train: loss: 0.0141614
[Epoch 93; Iter    62/  209] train: loss: 0.0218982
[Epoch 93; Iter    92/  209] train: loss: 0.0093393
[Epoch 93; Iter   122/  209] train: loss: 0.0023192
[Epoch 93; Iter   152/  209] train: loss: 0.0072435
[Epoch 93; Iter   182/  209] train: loss: 0.0063194
[Epoch 93] ogbg-moltox21: 0.715308 val loss: 0.815583
[Epoch 93] ogbg-moltox21: 0.689841 test loss: 0.869474
[Epoch 94; Iter     3/  209] train: loss: 0.0055067
[Epoch 94; Iter    33/  209] train: loss: 0.0059016
[Epoch 94; Iter    63/  209] train: loss: 0.0022141
[Epoch 94; Iter    93/  209] train: loss: 0.0100441
[Epoch 94; Iter   123/  209] train: loss: 0.0138028
[Epoch 94; Iter   153/  209] train: loss: 0.0034327
[Epoch 94; Iter   183/  209] train: loss: 0.0062134
[Epoch 94] ogbg-moltox21: 0.714577 val loss: 0.776392
[Epoch 94] ogbg-moltox21: 0.690281 test loss: 0.856535
[Epoch 95; Iter     4/  209] train: loss: 0.0033324
[Epoch 95; Iter    34/  209] train: loss: 0.0070279
[Epoch 95; Iter    64/  209] train: loss: 0.0059348
[Epoch 95; Iter    94/  209] train: loss: 0.0048791
[Epoch 95; Iter   124/  209] train: loss: 0.0042473
[Epoch 95; Iter   154/  209] train: loss: 0.0122287
[Epoch 95; Iter   184/  209] train: loss: 0.0079123
[Epoch 95] ogbg-moltox21: 0.723369 val loss: 0.775944
[Epoch 95] ogbg-moltox21: 0.691306 test loss: 0.856273
[Epoch 96; Iter     5/  209] train: loss: 0.0109043
[Epoch 96; Iter    35/  209] train: loss: 0.0080586
[Epoch 96; Iter    65/  209] train: loss: 0.0060887
[Epoch 96; Iter    95/  209] train: loss: 0.0100153
[Epoch 96; Iter   125/  209] train: loss: 0.0094068
[Epoch 96; Iter   155/  209] train: loss: 0.0165198
[Epoch 96; Iter   185/  209] train: loss: 0.0059753
[Epoch 96] ogbg-moltox21: 0.715900 val loss: 0.801710
[Epoch 96] ogbg-moltox21: 0.688782 test loss: 0.855648
[Epoch 97; Iter     6/  209] train: loss: 0.0040219
[Epoch 97; Iter    36/  209] train: loss: 0.0023259
[Epoch 97; Iter    66/  209] train: loss: 0.0038741
[Epoch 97; Iter    96/  209] train: loss: 0.0047906
[Epoch 97; Iter   126/  209] train: loss: 0.0117433
[Epoch 97; Iter   156/  209] train: loss: 0.0103040
[Epoch 97; Iter   186/  209] train: loss: 0.0028146
[Epoch 97] ogbg-moltox21: 0.717084 val loss: 0.825914
[Epoch 97] ogbg-moltox21: 0.682489 test loss: 0.893727
[Epoch 98; Iter     7/  209] train: loss: 0.0124608
[Epoch 98; Iter    37/  209] train: loss: 0.0030880
[Epoch 98; Iter    67/  209] train: loss: 0.0032300
[Epoch 98; Iter    97/  209] train: loss: 0.0107492
[Epoch 98; Iter   127/  209] train: loss: 0.0297746
[Epoch 98; Iter   157/  209] train: loss: 0.0046207
[Epoch 98; Iter   187/  209] train: loss: 0.0129152
[Epoch 98] ogbg-moltox21: 0.718117 val loss: 0.802977
[Epoch 98] ogbg-moltox21: 0.685570 test loss: 1.063499
[Epoch 99; Iter     8/  209] train: loss: 0.0145370
[Epoch 99; Iter    38/  209] train: loss: 0.0040203
[Epoch 99; Iter    68/  209] train: loss: 0.0141112
[Epoch 99; Iter    98/  209] train: loss: 0.0610228
[Epoch 82; Iter    51/  209] train: loss: 0.0121811
[Epoch 82; Iter    81/  209] train: loss: 0.0333133
[Epoch 82; Iter   111/  209] train: loss: 0.0203954
[Epoch 82; Iter   141/  209] train: loss: 0.0309654
[Epoch 82; Iter   171/  209] train: loss: 0.0221216
[Epoch 82; Iter   201/  209] train: loss: 0.0117037
[Epoch 82] ogbg-moltox21: 0.682893 val loss: 1.769454
[Epoch 82] ogbg-moltox21: 0.641580 test loss: 1.101830
[Epoch 83; Iter    22/  209] train: loss: 0.0412835
[Epoch 83; Iter    52/  209] train: loss: 0.0426852
[Epoch 83; Iter    82/  209] train: loss: 0.0095182
[Epoch 83; Iter   112/  209] train: loss: 0.0112666
[Epoch 83; Iter   142/  209] train: loss: 0.0569163
[Epoch 83; Iter   172/  209] train: loss: 0.0108912
[Epoch 83; Iter   202/  209] train: loss: 0.0370438
[Epoch 83] ogbg-moltox21: 0.681482 val loss: 2.248610
[Epoch 83] ogbg-moltox21: 0.647609 test loss: 1.279025
[Epoch 84; Iter    23/  209] train: loss: 0.0200087
[Epoch 84; Iter    53/  209] train: loss: 0.0120539
[Epoch 84; Iter    83/  209] train: loss: 0.0094317
[Epoch 84; Iter   113/  209] train: loss: 0.0080829
[Epoch 84; Iter   143/  209] train: loss: 0.0134615
[Epoch 84; Iter   173/  209] train: loss: 0.0261858
[Epoch 84; Iter   203/  209] train: loss: 0.0351890
[Epoch 84] ogbg-moltox21: 0.676445 val loss: 1.934278
[Epoch 84] ogbg-moltox21: 0.638212 test loss: 1.339194
[Epoch 85; Iter    24/  209] train: loss: 0.0165573
[Epoch 85; Iter    54/  209] train: loss: 0.0315845
[Epoch 85; Iter    84/  209] train: loss: 0.0089903
[Epoch 85; Iter   114/  209] train: loss: 0.0486057
[Epoch 85; Iter   144/  209] train: loss: 0.0278347
[Epoch 85; Iter   174/  209] train: loss: 0.0257877
[Epoch 85; Iter   204/  209] train: loss: 0.0116950
[Epoch 85] ogbg-moltox21: 0.665719 val loss: 1.494717
[Epoch 85] ogbg-moltox21: 0.634566 test loss: 1.619321
[Epoch 86; Iter    25/  209] train: loss: 0.0143364
[Epoch 86; Iter    55/  209] train: loss: 0.0213476
[Epoch 86; Iter    85/  209] train: loss: 0.0079279
[Epoch 86; Iter   115/  209] train: loss: 0.0107070
[Epoch 86; Iter   145/  209] train: loss: 0.0260194
[Epoch 86; Iter   175/  209] train: loss: 0.0125709
[Epoch 86; Iter   205/  209] train: loss: 0.0188672
[Epoch 86] ogbg-moltox21: 0.673568 val loss: 1.956717
[Epoch 86] ogbg-moltox21: 0.639167 test loss: 1.070158
[Epoch 87; Iter    26/  209] train: loss: 0.0072607
[Epoch 87; Iter    56/  209] train: loss: 0.0148088
[Epoch 87; Iter    86/  209] train: loss: 0.0202949
[Epoch 87; Iter   116/  209] train: loss: 0.0232339
[Epoch 87; Iter   146/  209] train: loss: 0.0385977
[Epoch 87; Iter   176/  209] train: loss: 0.0157883
[Epoch 87; Iter   206/  209] train: loss: 0.0591899
[Epoch 87] ogbg-moltox21: 0.685795 val loss: 1.382105
[Epoch 87] ogbg-moltox21: 0.644962 test loss: 1.166330
[Epoch 88; Iter    27/  209] train: loss: 0.0196776
[Epoch 88; Iter    57/  209] train: loss: 0.0102100
[Epoch 88; Iter    87/  209] train: loss: 0.0213779
[Epoch 88; Iter   117/  209] train: loss: 0.0213874
[Epoch 88; Iter   147/  209] train: loss: 0.0102998
[Epoch 88; Iter   177/  209] train: loss: 0.0093698
[Epoch 88; Iter   207/  209] train: loss: 0.0255821
[Epoch 88] ogbg-moltox21: 0.673666 val loss: 0.954069
[Epoch 88] ogbg-moltox21: 0.636373 test loss: 1.034635
[Epoch 89; Iter    28/  209] train: loss: 0.0062133
[Epoch 89; Iter    58/  209] train: loss: 0.0169263
[Epoch 89; Iter    88/  209] train: loss: 0.0180697
[Epoch 89; Iter   118/  209] train: loss: 0.0151726
[Epoch 89; Iter   148/  209] train: loss: 0.0380109
[Epoch 89; Iter   178/  209] train: loss: 0.0160709
[Epoch 89; Iter   208/  209] train: loss: 0.0108273
[Epoch 89] ogbg-moltox21: 0.672017 val loss: 1.242379
[Epoch 89] ogbg-moltox21: 0.628534 test loss: 1.325743
[Epoch 90; Iter    29/  209] train: loss: 0.0389865
[Epoch 90; Iter    59/  209] train: loss: 0.0260270
[Epoch 90; Iter    89/  209] train: loss: 0.0212619
[Epoch 90; Iter   119/  209] train: loss: 0.0533875
[Epoch 90; Iter   149/  209] train: loss: 0.0210492
[Epoch 90; Iter   179/  209] train: loss: 0.0152556
[Epoch 90; Iter   209/  209] train: loss: 0.0343782
[Epoch 90] ogbg-moltox21: 0.674191 val loss: 1.366333
[Epoch 90] ogbg-moltox21: 0.637465 test loss: 1.121223
[Epoch 91; Iter    30/  209] train: loss: 0.0147826
[Epoch 91; Iter    60/  209] train: loss: 0.0191743
[Epoch 91; Iter    90/  209] train: loss: 0.0169598
[Epoch 91; Iter   120/  209] train: loss: 0.0121007
[Epoch 91; Iter   150/  209] train: loss: 0.0076649
[Epoch 91; Iter   180/  209] train: loss: 0.0269530
[Epoch 91] ogbg-moltox21: 0.677573 val loss: 1.419912
[Epoch 91] ogbg-moltox21: 0.635347 test loss: 1.242725
[Epoch 92; Iter     1/  209] train: loss: 0.0225193
[Epoch 92; Iter    31/  209] train: loss: 0.0129221
[Epoch 92; Iter    61/  209] train: loss: 0.0032649
[Epoch 92; Iter    91/  209] train: loss: 0.0332442
[Epoch 92; Iter   121/  209] train: loss: 0.0116048
[Epoch 92; Iter   151/  209] train: loss: 0.0133305
[Epoch 92; Iter   181/  209] train: loss: 0.0095112
[Epoch 92] ogbg-moltox21: 0.672306 val loss: 1.521342
[Epoch 92] ogbg-moltox21: 0.629918 test loss: 1.236372
[Epoch 93; Iter     2/  209] train: loss: 0.0167297
[Epoch 93; Iter    32/  209] train: loss: 0.0208592
[Epoch 93; Iter    62/  209] train: loss: 0.0242700
[Epoch 93; Iter    92/  209] train: loss: 0.0139281
[Epoch 93; Iter   122/  209] train: loss: 0.0149436
[Epoch 93; Iter   152/  209] train: loss: 0.0123189
[Epoch 93; Iter   182/  209] train: loss: 0.0087696
[Epoch 93] ogbg-moltox21: 0.671659 val loss: 1.406620
[Epoch 93] ogbg-moltox21: 0.635239 test loss: 1.160030
[Epoch 94; Iter     3/  209] train: loss: 0.0133225
[Epoch 94; Iter    33/  209] train: loss: 0.0104143
[Epoch 94; Iter    63/  209] train: loss: 0.0061312
[Epoch 94; Iter    93/  209] train: loss: 0.0120723
[Epoch 94; Iter   123/  209] train: loss: 0.0203728
[Epoch 94; Iter   153/  209] train: loss: 0.0082785
[Epoch 94; Iter   183/  209] train: loss: 0.0229285
[Epoch 94] ogbg-moltox21: 0.685037 val loss: 1.975012
[Epoch 94] ogbg-moltox21: 0.650644 test loss: 1.098617
[Epoch 95; Iter     4/  209] train: loss: 0.0138315
[Epoch 95; Iter    34/  209] train: loss: 0.0085928
[Epoch 95; Iter    64/  209] train: loss: 0.0150742
[Epoch 95; Iter    94/  209] train: loss: 0.0172526
[Epoch 95; Iter   124/  209] train: loss: 0.0162722
[Epoch 95; Iter   154/  209] train: loss: 0.0322883
[Epoch 95; Iter   184/  209] train: loss: 0.0090756
[Epoch 95] ogbg-moltox21: 0.678944 val loss: 1.387880
[Epoch 95] ogbg-moltox21: 0.644737 test loss: 1.048433
[Epoch 96; Iter     5/  209] train: loss: 0.0100834
[Epoch 96; Iter    35/  209] train: loss: 0.0106493
[Epoch 96; Iter    65/  209] train: loss: 0.0264919
[Epoch 96; Iter    95/  209] train: loss: 0.0053706
[Epoch 96; Iter   125/  209] train: loss: 0.0093024
[Epoch 96; Iter   155/  209] train: loss: 0.0109315
[Epoch 96; Iter   185/  209] train: loss: 0.0198668
[Epoch 96] ogbg-moltox21: 0.675913 val loss: 1.179656
[Epoch 96] ogbg-moltox21: 0.639679 test loss: 1.142978
[Epoch 97; Iter     6/  209] train: loss: 0.0143521
[Epoch 97; Iter    36/  209] train: loss: 0.0229328
[Epoch 97; Iter    66/  209] train: loss: 0.0107356
[Epoch 97; Iter    96/  209] train: loss: 0.0214052
[Epoch 97; Iter   126/  209] train: loss: 0.0199175
[Epoch 97; Iter   156/  209] train: loss: 0.0222182
[Epoch 97; Iter   186/  209] train: loss: 0.0093279
[Epoch 97] ogbg-moltox21: 0.684284 val loss: 1.008882
[Epoch 97] ogbg-moltox21: 0.646047 test loss: 0.957466
[Epoch 98; Iter     7/  209] train: loss: 0.0199594
[Epoch 98; Iter    37/  209] train: loss: 0.0116293
[Epoch 98; Iter    67/  209] train: loss: 0.0226230
[Epoch 98; Iter    97/  209] train: loss: 0.0146301
[Epoch 98; Iter   127/  209] train: loss: 0.0167312
[Epoch 98; Iter   157/  209] train: loss: 0.0110835
[Epoch 98; Iter   187/  209] train: loss: 0.0129902
[Epoch 98] ogbg-moltox21: 0.664545 val loss: 1.496328
[Epoch 98] ogbg-moltox21: 0.633977 test loss: 1.098423
[Epoch 99; Iter     8/  209] train: loss: 0.0156359
[Epoch 99; Iter    38/  209] train: loss: 0.0120873
[Epoch 99; Iter    68/  209] train: loss: 0.0174660
[Epoch 99; Iter    98/  209] train: loss: 0.0073284
[Epoch 82; Iter    51/  209] train: loss: 0.0132429
[Epoch 82; Iter    81/  209] train: loss: 0.0112625
[Epoch 82; Iter   111/  209] train: loss: 0.0176289
[Epoch 82; Iter   141/  209] train: loss: 0.0176423
[Epoch 82; Iter   171/  209] train: loss: 0.0084120
[Epoch 82; Iter   201/  209] train: loss: 0.0372115
[Epoch 82] ogbg-moltox21: 0.723760 val loss: 1.161578
[Epoch 82] ogbg-moltox21: 0.657465 test loss: 1.079360
[Epoch 83; Iter    22/  209] train: loss: 0.0085631
[Epoch 83; Iter    52/  209] train: loss: 0.0186555
[Epoch 83; Iter    82/  209] train: loss: 0.0164591
[Epoch 83; Iter   112/  209] train: loss: 0.0177772
[Epoch 83; Iter   142/  209] train: loss: 0.0131780
[Epoch 83; Iter   172/  209] train: loss: 0.0263662
[Epoch 83; Iter   202/  209] train: loss: 0.0332381
[Epoch 83] ogbg-moltox21: 0.716195 val loss: 0.850742
[Epoch 83] ogbg-moltox21: 0.648508 test loss: 1.004138
[Epoch 84; Iter    23/  209] train: loss: 0.0074702
[Epoch 84; Iter    53/  209] train: loss: 0.0123694
[Epoch 84; Iter    83/  209] train: loss: 0.0082513
[Epoch 84; Iter   113/  209] train: loss: 0.0051643
[Epoch 84; Iter   143/  209] train: loss: 0.0079163
[Epoch 84; Iter   173/  209] train: loss: 0.0061470
[Epoch 84; Iter   203/  209] train: loss: 0.0093819
[Epoch 84] ogbg-moltox21: 0.725187 val loss: 1.180645
[Epoch 84] ogbg-moltox21: 0.655851 test loss: 1.162287
[Epoch 85; Iter    24/  209] train: loss: 0.0068635
[Epoch 85; Iter    54/  209] train: loss: 0.0304940
[Epoch 85; Iter    84/  209] train: loss: 0.0108057
[Epoch 85; Iter   114/  209] train: loss: 0.0040877
[Epoch 85; Iter   144/  209] train: loss: 0.0090483
[Epoch 85; Iter   174/  209] train: loss: 0.0075722
[Epoch 85; Iter   204/  209] train: loss: 0.0025819
[Epoch 85] ogbg-moltox21: 0.719966 val loss: 0.960336
[Epoch 85] ogbg-moltox21: 0.650515 test loss: 0.974838
[Epoch 86; Iter    25/  209] train: loss: 0.0039706
[Epoch 86; Iter    55/  209] train: loss: 0.0046301
[Epoch 86; Iter    85/  209] train: loss: 0.0052105
[Epoch 86; Iter   115/  209] train: loss: 0.0048546
[Epoch 86; Iter   145/  209] train: loss: 0.0238148
[Epoch 86; Iter   175/  209] train: loss: 0.0050628
[Epoch 86; Iter   205/  209] train: loss: 0.0095424
[Epoch 86] ogbg-moltox21: 0.727518 val loss: 0.916373
[Epoch 86] ogbg-moltox21: 0.663013 test loss: 0.992221
[Epoch 87; Iter    26/  209] train: loss: 0.0078832
[Epoch 87; Iter    56/  209] train: loss: 0.0081498
[Epoch 87; Iter    86/  209] train: loss: 0.0168820
[Epoch 87; Iter   116/  209] train: loss: 0.0047076
[Epoch 87; Iter   146/  209] train: loss: 0.0061204
[Epoch 87; Iter   176/  209] train: loss: 0.0044872
[Epoch 87; Iter   206/  209] train: loss: 0.0163346
[Epoch 87] ogbg-moltox21: 0.724850 val loss: 0.925315
[Epoch 87] ogbg-moltox21: 0.658072 test loss: 0.954808
[Epoch 88; Iter    27/  209] train: loss: 0.0101176
[Epoch 88; Iter    57/  209] train: loss: 0.0056892
[Epoch 88; Iter    87/  209] train: loss: 0.0063172
[Epoch 88; Iter   117/  209] train: loss: 0.0047717
[Epoch 88; Iter   147/  209] train: loss: 0.0077659
[Epoch 88; Iter   177/  209] train: loss: 0.0088477
[Epoch 88; Iter   207/  209] train: loss: 0.0186708
[Epoch 88] ogbg-moltox21: 0.727177 val loss: 1.086176
[Epoch 88] ogbg-moltox21: 0.658301 test loss: 0.934270
[Epoch 89; Iter    28/  209] train: loss: 0.0046155
[Epoch 89; Iter    58/  209] train: loss: 0.0087998
[Epoch 89; Iter    88/  209] train: loss: 0.0054402
[Epoch 89; Iter   118/  209] train: loss: 0.0057302
[Epoch 89; Iter   148/  209] train: loss: 0.0240309
[Epoch 89; Iter   178/  209] train: loss: 0.0091078
[Epoch 89; Iter   208/  209] train: loss: 0.0239633
[Epoch 89] ogbg-moltox21: 0.730725 val loss: 1.442765
[Epoch 89] ogbg-moltox21: 0.664362 test loss: 1.125334
[Epoch 90; Iter    29/  209] train: loss: 0.0069400
[Epoch 90; Iter    59/  209] train: loss: 0.0155456
[Epoch 90; Iter    89/  209] train: loss: 0.0074787
[Epoch 90; Iter   119/  209] train: loss: 0.0053555
[Epoch 90; Iter   149/  209] train: loss: 0.0073538
[Epoch 90; Iter   179/  209] train: loss: 0.0023351
[Epoch 90; Iter   209/  209] train: loss: 0.0081119
[Epoch 90] ogbg-moltox21: 0.714312 val loss: 1.426216
[Epoch 90] ogbg-moltox21: 0.651775 test loss: 1.267896
[Epoch 91; Iter    30/  209] train: loss: 0.0031886
[Epoch 91; Iter    60/  209] train: loss: 0.0095783
[Epoch 91; Iter    90/  209] train: loss: 0.0458226
[Epoch 91; Iter   120/  209] train: loss: 0.0059585
[Epoch 91; Iter   150/  209] train: loss: 0.0054358
[Epoch 91; Iter   180/  209] train: loss: 0.0076903
[Epoch 91] ogbg-moltox21: 0.717482 val loss: 0.988531
[Epoch 91] ogbg-moltox21: 0.652833 test loss: 1.117288
[Epoch 92; Iter     1/  209] train: loss: 0.0103404
[Epoch 92; Iter    31/  209] train: loss: 0.0037290
[Epoch 92; Iter    61/  209] train: loss: 0.0032144
[Epoch 92; Iter    91/  209] train: loss: 0.0073428
[Epoch 92; Iter   121/  209] train: loss: 0.0066962
[Epoch 92; Iter   151/  209] train: loss: 0.0020835
[Epoch 92; Iter   181/  209] train: loss: 0.0034093
[Epoch 92] ogbg-moltox21: 0.720665 val loss: 0.903285
[Epoch 92] ogbg-moltox21: 0.656890 test loss: 0.982935
[Epoch 93; Iter     2/  209] train: loss: 0.0147362
[Epoch 93; Iter    32/  209] train: loss: 0.0186504
[Epoch 93; Iter    62/  209] train: loss: 0.0047886
[Epoch 93; Iter    92/  209] train: loss: 0.0030923
[Epoch 93; Iter   122/  209] train: loss: 0.0140242
[Epoch 93; Iter   152/  209] train: loss: 0.0104835
[Epoch 93; Iter   182/  209] train: loss: 0.0059845
[Epoch 93] ogbg-moltox21: 0.730784 val loss: 1.122249
[Epoch 93] ogbg-moltox21: 0.658976 test loss: 0.994905
[Epoch 94; Iter     3/  209] train: loss: 0.0122742
[Epoch 94; Iter    33/  209] train: loss: 0.0119459
[Epoch 94; Iter    63/  209] train: loss: 0.0193348
[Epoch 94; Iter    93/  209] train: loss: 0.0026088
[Epoch 94; Iter   123/  209] train: loss: 0.0027415
[Epoch 94; Iter   153/  209] train: loss: 0.0039693
[Epoch 94; Iter   183/  209] train: loss: 0.0076575
[Epoch 94] ogbg-moltox21: 0.722118 val loss: 0.879576
[Epoch 94] ogbg-moltox21: 0.657551 test loss: 1.043382
[Epoch 95; Iter     4/  209] train: loss: 0.0073300
[Epoch 95; Iter    34/  209] train: loss: 0.0037572
[Epoch 95; Iter    64/  209] train: loss: 0.0040164
[Epoch 95; Iter    94/  209] train: loss: 0.0042504
[Epoch 95; Iter   124/  209] train: loss: 0.0157685
[Epoch 95; Iter   154/  209] train: loss: 0.0040228
[Epoch 95; Iter   184/  209] train: loss: 0.0285386
[Epoch 95] ogbg-moltox21: 0.715282 val loss: 0.878256
[Epoch 95] ogbg-moltox21: 0.648666 test loss: 1.046327
[Epoch 96; Iter     5/  209] train: loss: 0.0022264
[Epoch 96; Iter    35/  209] train: loss: 0.0044898
[Epoch 96; Iter    65/  209] train: loss: 0.0051334
[Epoch 96; Iter    95/  209] train: loss: 0.0144422
[Epoch 96; Iter   125/  209] train: loss: 0.0079347
[Epoch 96; Iter   155/  209] train: loss: 0.0186760
[Epoch 96; Iter   185/  209] train: loss: 0.0093630
[Epoch 96] ogbg-moltox21: 0.719445 val loss: 0.941992
[Epoch 96] ogbg-moltox21: 0.663664 test loss: 1.042549
[Epoch 97; Iter     6/  209] train: loss: 0.0204115
[Epoch 97; Iter    36/  209] train: loss: 0.0039381
[Epoch 97; Iter    66/  209] train: loss: 0.0123073
[Epoch 97; Iter    96/  209] train: loss: 0.0046266
[Epoch 97; Iter   126/  209] train: loss: 0.0071343
[Epoch 97; Iter   156/  209] train: loss: 0.0618441
[Epoch 97; Iter   186/  209] train: loss: 0.0165136
[Epoch 97] ogbg-moltox21: 0.716899 val loss: 0.895694
[Epoch 97] ogbg-moltox21: 0.655045 test loss: 1.032130
[Epoch 98; Iter     7/  209] train: loss: 0.0027510
[Epoch 98; Iter    37/  209] train: loss: 0.0098617
[Epoch 98; Iter    67/  209] train: loss: 0.0041634
[Epoch 98; Iter    97/  209] train: loss: 0.0138380
[Epoch 98; Iter   127/  209] train: loss: 0.0037301
[Epoch 98; Iter   157/  209] train: loss: 0.0032517
[Epoch 98; Iter   187/  209] train: loss: 0.0036723
[Epoch 98] ogbg-moltox21: 0.726915 val loss: 1.314673
[Epoch 98] ogbg-moltox21: 0.658409 test loss: 1.179976
[Epoch 99; Iter     8/  209] train: loss: 0.0028101
[Epoch 99; Iter    38/  209] train: loss: 0.0033842
[Epoch 99; Iter    68/  209] train: loss: 0.0052596
[Epoch 99; Iter    98/  209] train: loss: 0.0038396
[Epoch 82; Iter    51/  209] train: loss: 0.0097507
[Epoch 82; Iter    81/  209] train: loss: 0.0226708
[Epoch 82; Iter   111/  209] train: loss: 0.0135486
[Epoch 82; Iter   141/  209] train: loss: 0.0196815
[Epoch 82; Iter   171/  209] train: loss: 0.0092926
[Epoch 82; Iter   201/  209] train: loss: 0.0098528
[Epoch 82] ogbg-moltox21: 0.722223 val loss: 0.598157
[Epoch 82] ogbg-moltox21: 0.686706 test loss: 0.657902
[Epoch 83; Iter    22/  209] train: loss: 0.0364142
[Epoch 83; Iter    52/  209] train: loss: 0.0486613
[Epoch 83; Iter    82/  209] train: loss: 0.0149205
[Epoch 83; Iter   112/  209] train: loss: 0.0221213
[Epoch 83; Iter   142/  209] train: loss: 0.0295291
[Epoch 83; Iter   172/  209] train: loss: 0.0091798
[Epoch 83; Iter   202/  209] train: loss: 0.0206474
[Epoch 83] ogbg-moltox21: 0.728840 val loss: 0.609105
[Epoch 83] ogbg-moltox21: 0.687081 test loss: 0.666385
[Epoch 84; Iter    23/  209] train: loss: 0.0101077
[Epoch 84; Iter    53/  209] train: loss: 0.0109202
[Epoch 84; Iter    83/  209] train: loss: 0.0062287
[Epoch 84; Iter   113/  209] train: loss: 0.0202102
[Epoch 84; Iter   143/  209] train: loss: 0.0174782
[Epoch 84; Iter   173/  209] train: loss: 0.0196185
[Epoch 84; Iter   203/  209] train: loss: 0.0351562
[Epoch 84] ogbg-moltox21: 0.726848 val loss: 0.621223
[Epoch 84] ogbg-moltox21: 0.681305 test loss: 0.681193
[Epoch 85; Iter    24/  209] train: loss: 0.0117336
[Epoch 85; Iter    54/  209] train: loss: 0.0236756
[Epoch 85; Iter    84/  209] train: loss: 0.0100174
[Epoch 85; Iter   114/  209] train: loss: 0.0446865
[Epoch 85; Iter   144/  209] train: loss: 0.0412160
[Epoch 85; Iter   174/  209] train: loss: 0.0051693
[Epoch 85; Iter   204/  209] train: loss: 0.0098205
[Epoch 85] ogbg-moltox21: 0.724601 val loss: 0.618816
[Epoch 85] ogbg-moltox21: 0.683344 test loss: 0.684031
[Epoch 86; Iter    25/  209] train: loss: 0.0076661
[Epoch 86; Iter    55/  209] train: loss: 0.0209704
[Epoch 86; Iter    85/  209] train: loss: 0.0057532
[Epoch 86; Iter   115/  209] train: loss: 0.0197878
[Epoch 86; Iter   145/  209] train: loss: 0.0104282
[Epoch 86; Iter   175/  209] train: loss: 0.0094494
[Epoch 86; Iter   205/  209] train: loss: 0.0106414
[Epoch 86] ogbg-moltox21: 0.724112 val loss: 0.649078
[Epoch 86] ogbg-moltox21: 0.684206 test loss: 0.704812
[Epoch 87; Iter    26/  209] train: loss: 0.0052756
[Epoch 87; Iter    56/  209] train: loss: 0.0203488
[Epoch 87; Iter    86/  209] train: loss: 0.0262283
[Epoch 87; Iter   116/  209] train: loss: 0.0164293
[Epoch 87; Iter   146/  209] train: loss: 0.0377404
[Epoch 87; Iter   176/  209] train: loss: 0.0054836
[Epoch 87; Iter   206/  209] train: loss: 0.0476661
[Epoch 87] ogbg-moltox21: 0.731538 val loss: 0.642657
[Epoch 87] ogbg-moltox21: 0.681068 test loss: 0.718588
[Epoch 88; Iter    27/  209] train: loss: 0.0076830
[Epoch 88; Iter    57/  209] train: loss: 0.0087588
[Epoch 88; Iter    87/  209] train: loss: 0.0197905
[Epoch 88; Iter   117/  209] train: loss: 0.0073739
[Epoch 88; Iter   147/  209] train: loss: 0.0040891
[Epoch 88; Iter   177/  209] train: loss: 0.0143210
[Epoch 88; Iter   207/  209] train: loss: 0.0067448
[Epoch 88] ogbg-moltox21: 0.728645 val loss: 0.665310
[Epoch 88] ogbg-moltox21: 0.678418 test loss: 0.739178
[Epoch 89; Iter    28/  209] train: loss: 0.0033411
[Epoch 89; Iter    58/  209] train: loss: 0.0057577
[Epoch 89; Iter    88/  209] train: loss: 0.0231804
[Epoch 89; Iter   118/  209] train: loss: 0.0102757
[Epoch 89; Iter   148/  209] train: loss: 0.0359971
[Epoch 89; Iter   178/  209] train: loss: 0.0222408
[Epoch 89; Iter   208/  209] train: loss: 0.0100219
[Epoch 89] ogbg-moltox21: 0.727551 val loss: 0.631562
[Epoch 89] ogbg-moltox21: 0.674129 test loss: 0.721275
[Epoch 90; Iter    29/  209] train: loss: 0.0220639
[Epoch 90; Iter    59/  209] train: loss: 0.0154175
[Epoch 90; Iter    89/  209] train: loss: 0.0104502
[Epoch 90; Iter   119/  209] train: loss: 0.0562944
[Epoch 90; Iter   149/  209] train: loss: 0.0132645
[Epoch 90; Iter   179/  209] train: loss: 0.0124857
[Epoch 90; Iter   209/  209] train: loss: 0.0137686
[Epoch 90] ogbg-moltox21: 0.725380 val loss: 0.657799
[Epoch 90] ogbg-moltox21: 0.683178 test loss: 0.713954
[Epoch 91; Iter    30/  209] train: loss: 0.0048176
[Epoch 91; Iter    60/  209] train: loss: 0.0194546
[Epoch 91; Iter    90/  209] train: loss: 0.0157932
[Epoch 91; Iter   120/  209] train: loss: 0.0127497
[Epoch 91; Iter   150/  209] train: loss: 0.0066561
[Epoch 91; Iter   180/  209] train: loss: 0.0103130
[Epoch 91] ogbg-moltox21: 0.729323 val loss: 0.657488
[Epoch 91] ogbg-moltox21: 0.686277 test loss: 0.730560
[Epoch 92; Iter     1/  209] train: loss: 0.0061347
[Epoch 92; Iter    31/  209] train: loss: 0.0057126
[Epoch 92; Iter    61/  209] train: loss: 0.0047172
[Epoch 92; Iter    91/  209] train: loss: 0.0152773
[Epoch 92; Iter   121/  209] train: loss: 0.0055707
[Epoch 92; Iter   151/  209] train: loss: 0.0092887
[Epoch 92; Iter   181/  209] train: loss: 0.0059657
[Epoch 92] ogbg-moltox21: 0.722368 val loss: 0.657183
[Epoch 92] ogbg-moltox21: 0.673305 test loss: 0.736496
[Epoch 93; Iter     2/  209] train: loss: 0.0102961
[Epoch 93; Iter    32/  209] train: loss: 0.0275978
[Epoch 93; Iter    62/  209] train: loss: 0.0107988
[Epoch 93; Iter    92/  209] train: loss: 0.0154690
[Epoch 93; Iter   122/  209] train: loss: 0.0157427
[Epoch 93; Iter   152/  209] train: loss: 0.0066754
[Epoch 93; Iter   182/  209] train: loss: 0.0036888
[Epoch 93] ogbg-moltox21: 0.726392 val loss: 0.663932
[Epoch 93] ogbg-moltox21: 0.676599 test loss: 0.735290
[Epoch 94; Iter     3/  209] train: loss: 0.0056907
[Epoch 94; Iter    33/  209] train: loss: 0.0044492
[Epoch 94; Iter    63/  209] train: loss: 0.0031565
[Epoch 94; Iter    93/  209] train: loss: 0.0063596
[Epoch 94; Iter   123/  209] train: loss: 0.0168611
[Epoch 94; Iter   153/  209] train: loss: 0.0030459
[Epoch 94; Iter   183/  209] train: loss: 0.0206333
[Epoch 94] ogbg-moltox21: 0.728065 val loss: 0.674553
[Epoch 94] ogbg-moltox21: 0.676913 test loss: 0.750026
[Epoch 95; Iter     4/  209] train: loss: 0.0171431
[Epoch 95; Iter    34/  209] train: loss: 0.0069421
[Epoch 95; Iter    64/  209] train: loss: 0.0102063
[Epoch 95; Iter    94/  209] train: loss: 0.0195085
[Epoch 95; Iter   124/  209] train: loss: 0.0075369
[Epoch 95; Iter   154/  209] train: loss: 0.0137889
[Epoch 95; Iter   184/  209] train: loss: 0.0112274
[Epoch 95] ogbg-moltox21: 0.725545 val loss: 0.693457
[Epoch 95] ogbg-moltox21: 0.672631 test loss: 0.771688
[Epoch 96; Iter     5/  209] train: loss: 0.0051810
[Epoch 96; Iter    35/  209] train: loss: 0.0084758
[Epoch 96; Iter    65/  209] train: loss: 0.0045737
[Epoch 96; Iter    95/  209] train: loss: 0.0076306
[Epoch 96; Iter   125/  209] train: loss: 0.0078214
[Epoch 96; Iter   155/  209] train: loss: 0.0055561
[Epoch 96; Iter   185/  209] train: loss: 0.0140813
[Epoch 96] ogbg-moltox21: 0.717749 val loss: 0.708204
[Epoch 96] ogbg-moltox21: 0.675926 test loss: 0.765115
[Epoch 97; Iter     6/  209] train: loss: 0.0066488
[Epoch 97; Iter    36/  209] train: loss: 0.0097925
[Epoch 97; Iter    66/  209] train: loss: 0.0065628
[Epoch 97; Iter    96/  209] train: loss: 0.0162036
[Epoch 97; Iter   126/  209] train: loss: 0.0096736
[Epoch 97; Iter   156/  209] train: loss: 0.0067242
[Epoch 97; Iter   186/  209] train: loss: 0.0069080
[Epoch 97] ogbg-moltox21: 0.728109 val loss: 0.705169
[Epoch 97] ogbg-moltox21: 0.684001 test loss: 0.782004
[Epoch 98; Iter     7/  209] train: loss: 0.0174518
[Epoch 98; Iter    37/  209] train: loss: 0.0155801
[Epoch 98; Iter    67/  209] train: loss: 0.0335762
[Epoch 98; Iter    97/  209] train: loss: 0.0179656
[Epoch 98; Iter   127/  209] train: loss: 0.0110473
[Epoch 98; Iter   157/  209] train: loss: 0.0082981
[Epoch 98; Iter   187/  209] train: loss: 0.0067087
[Epoch 98] ogbg-moltox21: 0.720858 val loss: 0.693703
[Epoch 98] ogbg-moltox21: 0.685996 test loss: 0.766785
[Epoch 99; Iter     8/  209] train: loss: 0.0127262
[Epoch 99; Iter    38/  209] train: loss: 0.0044240
[Epoch 99; Iter    68/  209] train: loss: 0.0187606
[Epoch 99; Iter    98/  209] train: loss: 0.0070472
[Epoch 64] ogbg-moltox21: 0.753986 test loss: 0.321485
[Epoch 65; Iter     4/  209] train: loss: 0.0851083
[Epoch 65; Iter    34/  209] train: loss: 0.1073760
[Epoch 65; Iter    64/  209] train: loss: 0.0790036
[Epoch 65; Iter    94/  209] train: loss: 0.1123076
[Epoch 65; Iter   124/  209] train: loss: 0.1434062
[Epoch 65; Iter   154/  209] train: loss: 0.0753722
[Epoch 65; Iter   184/  209] train: loss: 0.0739974
[Epoch 65] ogbg-moltox21: 0.777125 val loss: 0.295902
[Epoch 65] ogbg-moltox21: 0.757733 test loss: 0.299815
[Epoch 66; Iter     5/  209] train: loss: 0.0801793
[Epoch 66; Iter    35/  209] train: loss: 0.0751347
[Epoch 66; Iter    65/  209] train: loss: 0.0547967
[Epoch 66; Iter    95/  209] train: loss: 0.0614953
[Epoch 66; Iter   125/  209] train: loss: 0.1253160
[Epoch 66; Iter   155/  209] train: loss: 0.0978828
[Epoch 66; Iter   185/  209] train: loss: 0.0848620
[Epoch 66] ogbg-moltox21: 0.779883 val loss: 0.298955
[Epoch 66] ogbg-moltox21: 0.758307 test loss: 0.311526
[Epoch 67; Iter     6/  209] train: loss: 0.0741677
[Epoch 67; Iter    36/  209] train: loss: 0.0614038
[Epoch 67; Iter    66/  209] train: loss: 0.0604852
[Epoch 67; Iter    96/  209] train: loss: 0.0689015
[Epoch 67; Iter   126/  209] train: loss: 0.1038496
[Epoch 67; Iter   156/  209] train: loss: 0.1021091
[Epoch 67; Iter   186/  209] train: loss: 0.1068635
[Epoch 67] ogbg-moltox21: 0.784992 val loss: 0.297320
[Epoch 67] ogbg-moltox21: 0.752024 test loss: 0.318271
[Epoch 68; Iter     7/  209] train: loss: 0.0644144
[Epoch 68; Iter    37/  209] train: loss: 0.0641452
[Epoch 68; Iter    67/  209] train: loss: 0.0698412
[Epoch 68; Iter    97/  209] train: loss: 0.0998827
[Epoch 68; Iter   127/  209] train: loss: 0.0925141
[Epoch 68; Iter   157/  209] train: loss: 0.0849407
[Epoch 68; Iter   187/  209] train: loss: 0.0990420
[Epoch 68] ogbg-moltox21: 0.776457 val loss: 0.296456
[Epoch 68] ogbg-moltox21: 0.750780 test loss: 0.313841
[Epoch 69; Iter     8/  209] train: loss: 0.0947438
[Epoch 69; Iter    38/  209] train: loss: 0.0606919
[Epoch 69; Iter    68/  209] train: loss: 0.0653453
[Epoch 69; Iter    98/  209] train: loss: 0.0691927
[Epoch 69; Iter   128/  209] train: loss: 0.0736690
[Epoch 69; Iter   158/  209] train: loss: 0.1462208
[Epoch 69; Iter   188/  209] train: loss: 0.0765263
[Epoch 69] ogbg-moltox21: 0.773388 val loss: 0.309725
[Epoch 69] ogbg-moltox21: 0.753917 test loss: 0.317281
[Epoch 70; Iter     9/  209] train: loss: 0.0742044
[Epoch 70; Iter    39/  209] train: loss: 0.0701752
[Epoch 70; Iter    69/  209] train: loss: 0.0735204
[Epoch 70; Iter    99/  209] train: loss: 0.0534291
[Epoch 70; Iter   129/  209] train: loss: 0.1230675
[Epoch 70; Iter   159/  209] train: loss: 0.1395430
[Epoch 70; Iter   189/  209] train: loss: 0.0801755
[Epoch 70] ogbg-moltox21: 0.765861 val loss: 0.312980
[Epoch 70] ogbg-moltox21: 0.752750 test loss: 0.323700
[Epoch 71; Iter    10/  209] train: loss: 0.0680682
[Epoch 71; Iter    40/  209] train: loss: 0.0624463
[Epoch 71; Iter    70/  209] train: loss: 0.0808334
[Epoch 71; Iter   100/  209] train: loss: 0.0825435
[Epoch 71; Iter   130/  209] train: loss: 0.0966076
[Epoch 71; Iter   160/  209] train: loss: 0.0587488
[Epoch 71; Iter   190/  209] train: loss: 0.0713012
[Epoch 71] ogbg-moltox21: 0.771383 val loss: 0.311689
[Epoch 71] ogbg-moltox21: 0.748893 test loss: 0.322676
[Epoch 72; Iter    11/  209] train: loss: 0.1197074
[Epoch 72; Iter    41/  209] train: loss: 0.1005391
[Epoch 72; Iter    71/  209] train: loss: 0.1033603
[Epoch 72; Iter   101/  209] train: loss: 0.0720956
[Epoch 72; Iter   131/  209] train: loss: 0.1027052
[Epoch 72; Iter   161/  209] train: loss: 0.0703247
[Epoch 72; Iter   191/  209] train: loss: 0.0932074
[Epoch 72] ogbg-moltox21: 0.771152 val loss: 0.313547
[Epoch 72] ogbg-moltox21: 0.747636 test loss: 0.327505
[Epoch 73; Iter    12/  209] train: loss: 0.0678577
[Epoch 73; Iter    42/  209] train: loss: 0.0524275
[Epoch 73; Iter    72/  209] train: loss: 0.1021235
[Epoch 73; Iter   102/  209] train: loss: 0.0745447
[Epoch 73; Iter   132/  209] train: loss: 0.0934450
[Epoch 73; Iter   162/  209] train: loss: 0.1029195
[Epoch 73; Iter   192/  209] train: loss: 0.1456944
[Epoch 73] ogbg-moltox21: 0.772276 val loss: 0.306177
[Epoch 73] ogbg-moltox21: 0.746334 test loss: 0.336088
[Epoch 74; Iter    13/  209] train: loss: 0.0955140
[Epoch 74; Iter    43/  209] train: loss: 0.0968922
[Epoch 74; Iter    73/  209] train: loss: 0.1115793
[Epoch 74; Iter   103/  209] train: loss: 0.0526666
[Epoch 74; Iter   133/  209] train: loss: 0.1286353
[Epoch 74; Iter   163/  209] train: loss: 0.0808762
[Epoch 74; Iter   193/  209] train: loss: 0.1087183
[Epoch 74] ogbg-moltox21: 0.773152 val loss: 0.359367
[Epoch 74] ogbg-moltox21: 0.750296 test loss: 0.332239
[Epoch 75; Iter    14/  209] train: loss: 0.0442928
[Epoch 75; Iter    44/  209] train: loss: 0.0829443
[Epoch 75; Iter    74/  209] train: loss: 0.0702199
[Epoch 75; Iter   104/  209] train: loss: 0.0951208
[Epoch 75; Iter   134/  209] train: loss: 0.0543957
[Epoch 75; Iter   164/  209] train: loss: 0.1184462
[Epoch 75; Iter   194/  209] train: loss: 0.0557034
[Epoch 75] ogbg-moltox21: 0.776671 val loss: 0.314820
[Epoch 75] ogbg-moltox21: 0.748160 test loss: 0.338918
[Epoch 76; Iter    15/  209] train: loss: 0.0700704
[Epoch 76; Iter    45/  209] train: loss: 0.0629286
[Epoch 76; Iter    75/  209] train: loss: 0.0653791
[Epoch 76; Iter   105/  209] train: loss: 0.0641728
[Epoch 76; Iter   135/  209] train: loss: 0.1072505
[Epoch 76; Iter   165/  209] train: loss: 0.0399786
[Epoch 76; Iter   195/  209] train: loss: 0.0673227
[Epoch 76] ogbg-moltox21: 0.773353 val loss: 0.330720
[Epoch 76] ogbg-moltox21: 0.752475 test loss: 0.348818
[Epoch 77; Iter    16/  209] train: loss: 0.0914872
[Epoch 77; Iter    46/  209] train: loss: 0.0653108
[Epoch 77; Iter    76/  209] train: loss: 0.0375589
[Epoch 77; Iter   106/  209] train: loss: 0.0614994
[Epoch 77; Iter   136/  209] train: loss: 0.1112561
[Epoch 77; Iter   166/  209] train: loss: 0.0972584
[Epoch 77; Iter   196/  209] train: loss: 0.1247743
[Epoch 77] ogbg-moltox21: 0.770121 val loss: 0.323646
[Epoch 77] ogbg-moltox21: 0.744516 test loss: 0.345837
[Epoch 78; Iter    17/  209] train: loss: 0.0379409
[Epoch 78; Iter    47/  209] train: loss: 0.0462246
[Epoch 78; Iter    77/  209] train: loss: 0.0631084
[Epoch 78; Iter   107/  209] train: loss: 0.0488586
[Epoch 78; Iter   137/  209] train: loss: 0.0704405
[Epoch 78; Iter   167/  209] train: loss: 0.0865501
[Epoch 78; Iter   197/  209] train: loss: 0.0485206
[Epoch 78] ogbg-moltox21: 0.776031 val loss: 0.314138
[Epoch 78] ogbg-moltox21: 0.738249 test loss: 0.346869
[Epoch 79; Iter    18/  209] train: loss: 0.0567998
[Epoch 79; Iter    48/  209] train: loss: 0.0721185
[Epoch 79; Iter    78/  209] train: loss: 0.0888083
[Epoch 79; Iter   108/  209] train: loss: 0.0907130
[Epoch 79; Iter   138/  209] train: loss: 0.0337439
[Epoch 79; Iter   168/  209] train: loss: 0.0814042
[Epoch 79; Iter   198/  209] train: loss: 0.0416690
[Epoch 79] ogbg-moltox21: 0.775405 val loss: 0.324478
[Epoch 79] ogbg-moltox21: 0.749617 test loss: 0.349435
[Epoch 80; Iter    19/  209] train: loss: 0.0573672
[Epoch 80; Iter    49/  209] train: loss: 0.0933644
[Epoch 80; Iter    79/  209] train: loss: 0.0426591
[Epoch 80; Iter   109/  209] train: loss: 0.0806590
[Epoch 80; Iter   139/  209] train: loss: 0.0538825
[Epoch 80; Iter   169/  209] train: loss: 0.0847527
[Epoch 80; Iter   199/  209] train: loss: 0.1284278
[Epoch 80] ogbg-moltox21: 0.779506 val loss: 0.325263
[Epoch 80] ogbg-moltox21: 0.748549 test loss: 0.359040
[Epoch 81; Iter    20/  209] train: loss: 0.0838222
[Epoch 81; Iter    50/  209] train: loss: 0.0656685
[Epoch 81; Iter    80/  209] train: loss: 0.0727953
[Epoch 81; Iter   110/  209] train: loss: 0.0893077
[Epoch 81; Iter   140/  209] train: loss: 0.1365880
[Epoch 81; Iter   170/  209] train: loss: 0.0951798
[Epoch 81; Iter   200/  209] train: loss: 0.0689370
[Epoch 81] ogbg-moltox21: 0.778002 val loss: 0.326186
[Epoch 81] ogbg-moltox21: 0.747205 test loss: 0.360143
[Epoch 82; Iter    21/  209] train: loss: 0.0637704
[Epoch 64] ogbg-moltox21: 0.762878 test loss: 0.329154
[Epoch 65; Iter     4/  209] train: loss: 0.0876676
[Epoch 65; Iter    34/  209] train: loss: 0.0533851
[Epoch 65; Iter    64/  209] train: loss: 0.1085408
[Epoch 65; Iter    94/  209] train: loss: 0.1166426
[Epoch 65; Iter   124/  209] train: loss: 0.0994993
[Epoch 65; Iter   154/  209] train: loss: 0.1105837
[Epoch 65; Iter   184/  209] train: loss: 0.1574109
[Epoch 65] ogbg-moltox21: 0.791857 val loss: 0.289768
[Epoch 65] ogbg-moltox21: 0.770154 test loss: 0.304581
[Epoch 66; Iter     5/  209] train: loss: 0.0976887
[Epoch 66; Iter    35/  209] train: loss: 0.0688145
[Epoch 66; Iter    65/  209] train: loss: 0.0929772
[Epoch 66; Iter    95/  209] train: loss: 0.1104544
[Epoch 66; Iter   125/  209] train: loss: 0.0854599
[Epoch 66; Iter   155/  209] train: loss: 0.1148200
[Epoch 66; Iter   185/  209] train: loss: 0.0729828
[Epoch 66] ogbg-moltox21: 0.789776 val loss: 0.314331
[Epoch 66] ogbg-moltox21: 0.768433 test loss: 0.336009
[Epoch 67; Iter     6/  209] train: loss: 0.1276612
[Epoch 67; Iter    36/  209] train: loss: 0.1169187
[Epoch 67; Iter    66/  209] train: loss: 0.1024487
[Epoch 67; Iter    96/  209] train: loss: 0.0853754
[Epoch 67; Iter   126/  209] train: loss: 0.0629037
[Epoch 67; Iter   156/  209] train: loss: 0.0616601
[Epoch 67; Iter   186/  209] train: loss: 0.1032273
[Epoch 67] ogbg-moltox21: 0.772529 val loss: 0.311777
[Epoch 67] ogbg-moltox21: 0.755761 test loss: 0.341160
[Epoch 68; Iter     7/  209] train: loss: 0.0978469
[Epoch 68; Iter    37/  209] train: loss: 0.1196455
[Epoch 68; Iter    67/  209] train: loss: 0.1038800
[Epoch 68; Iter    97/  209] train: loss: 0.0766279
[Epoch 68; Iter   127/  209] train: loss: 0.0814271
[Epoch 68; Iter   157/  209] train: loss: 0.0812233
[Epoch 68; Iter   187/  209] train: loss: 0.0808386
[Epoch 68] ogbg-moltox21: 0.784717 val loss: 0.303788
[Epoch 68] ogbg-moltox21: 0.763636 test loss: 0.325640
[Epoch 69; Iter     8/  209] train: loss: 0.0692554
[Epoch 69; Iter    38/  209] train: loss: 0.0822425
[Epoch 69; Iter    68/  209] train: loss: 0.0947804
[Epoch 69; Iter    98/  209] train: loss: 0.0484078
[Epoch 69; Iter   128/  209] train: loss: 0.0846440
[Epoch 69; Iter   158/  209] train: loss: 0.0740408
[Epoch 69; Iter   188/  209] train: loss: 0.0969914
[Epoch 69] ogbg-moltox21: 0.785053 val loss: 0.311296
[Epoch 69] ogbg-moltox21: 0.762973 test loss: 0.351844
[Epoch 70; Iter     9/  209] train: loss: 0.0971735
[Epoch 70; Iter    39/  209] train: loss: 0.0543586
[Epoch 70; Iter    69/  209] train: loss: 0.1508559
[Epoch 70; Iter    99/  209] train: loss: 0.0950280
[Epoch 70; Iter   129/  209] train: loss: 0.0835445
[Epoch 70; Iter   159/  209] train: loss: 0.1137662
[Epoch 70; Iter   189/  209] train: loss: 0.0855434
[Epoch 70] ogbg-moltox21: 0.782770 val loss: 0.310704
[Epoch 70] ogbg-moltox21: 0.758290 test loss: 0.334284
[Epoch 71; Iter    10/  209] train: loss: 0.1067120
[Epoch 71; Iter    40/  209] train: loss: 0.1346852
[Epoch 71; Iter    70/  209] train: loss: 0.0910380
[Epoch 71; Iter   100/  209] train: loss: 0.1054801
[Epoch 71; Iter   130/  209] train: loss: 0.0668821
[Epoch 71; Iter   160/  209] train: loss: 0.0842039
[Epoch 71; Iter   190/  209] train: loss: 0.1028665
[Epoch 71] ogbg-moltox21: 0.773938 val loss: 0.329123
[Epoch 71] ogbg-moltox21: 0.751956 test loss: 0.344723
[Epoch 72; Iter    11/  209] train: loss: 0.1028675
[Epoch 72; Iter    41/  209] train: loss: 0.0997993
[Epoch 72; Iter    71/  209] train: loss: 0.1295131
[Epoch 72; Iter   101/  209] train: loss: 0.0498400
[Epoch 72; Iter   131/  209] train: loss: 0.1379991
[Epoch 72; Iter   161/  209] train: loss: 0.1110757
[Epoch 72; Iter   191/  209] train: loss: 0.0804431
[Epoch 72] ogbg-moltox21: 0.788264 val loss: 0.303811
[Epoch 72] ogbg-moltox21: 0.756124 test loss: 0.329928
[Epoch 73; Iter    12/  209] train: loss: 0.1063701
[Epoch 73; Iter    42/  209] train: loss: 0.0822141
[Epoch 73; Iter    72/  209] train: loss: 0.0647180
[Epoch 73; Iter   102/  209] train: loss: 0.0808459
[Epoch 73; Iter   132/  209] train: loss: 0.0943732
[Epoch 73; Iter   162/  209] train: loss: 0.0411324
[Epoch 73; Iter   192/  209] train: loss: 0.1082547
[Epoch 73] ogbg-moltox21: 0.787632 val loss: 0.311481
[Epoch 73] ogbg-moltox21: 0.751475 test loss: 0.338033
[Epoch 74; Iter    13/  209] train: loss: 0.0747336
[Epoch 74; Iter    43/  209] train: loss: 0.1165135
[Epoch 74; Iter    73/  209] train: loss: 0.0718365
[Epoch 74; Iter   103/  209] train: loss: 0.0758780
[Epoch 74; Iter   133/  209] train: loss: 0.0724778
[Epoch 74; Iter   163/  209] train: loss: 0.0716910
[Epoch 74; Iter   193/  209] train: loss: 0.0568324
[Epoch 74] ogbg-moltox21: 0.779897 val loss: 0.317970
[Epoch 74] ogbg-moltox21: 0.757217 test loss: 0.347887
[Epoch 75; Iter    14/  209] train: loss: 0.0723781
[Epoch 75; Iter    44/  209] train: loss: 0.1160218
[Epoch 75; Iter    74/  209] train: loss: 0.0788828
[Epoch 75; Iter   104/  209] train: loss: 0.0859119
[Epoch 75; Iter   134/  209] train: loss: 0.0714886
[Epoch 75; Iter   164/  209] train: loss: 0.0690724
[Epoch 75; Iter   194/  209] train: loss: 0.0890164
[Epoch 75] ogbg-moltox21: 0.780015 val loss: 0.320174
[Epoch 75] ogbg-moltox21: 0.747048 test loss: 0.355331
[Epoch 76; Iter    15/  209] train: loss: 0.1216413
[Epoch 76; Iter    45/  209] train: loss: 0.0381827
[Epoch 76; Iter    75/  209] train: loss: 0.0755039
[Epoch 76; Iter   105/  209] train: loss: 0.0579582
[Epoch 76; Iter   135/  209] train: loss: 0.0860677
[Epoch 76; Iter   165/  209] train: loss: 0.0680945
[Epoch 76; Iter   195/  209] train: loss: 0.0899091
[Epoch 76] ogbg-moltox21: 0.783731 val loss: 0.316872
[Epoch 76] ogbg-moltox21: 0.745719 test loss: 0.349861
[Epoch 77; Iter    16/  209] train: loss: 0.1262844
[Epoch 77; Iter    46/  209] train: loss: 0.1124486
[Epoch 77; Iter    76/  209] train: loss: 0.0636722
[Epoch 77; Iter   106/  209] train: loss: 0.0972203
[Epoch 77; Iter   136/  209] train: loss: 0.1059638
[Epoch 77; Iter   166/  209] train: loss: 0.0792864
[Epoch 77; Iter   196/  209] train: loss: 0.1003230
[Epoch 77] ogbg-moltox21: 0.787013 val loss: 0.315679
[Epoch 77] ogbg-moltox21: 0.749574 test loss: 0.346032
[Epoch 78; Iter    17/  209] train: loss: 0.0655155
[Epoch 78; Iter    47/  209] train: loss: 0.0697216
[Epoch 78; Iter    77/  209] train: loss: 0.0542312
[Epoch 78; Iter   107/  209] train: loss: 0.1101907
[Epoch 78; Iter   137/  209] train: loss: 0.0844877
[Epoch 78; Iter   167/  209] train: loss: 0.1525857
[Epoch 78; Iter   197/  209] train: loss: 0.0623070
[Epoch 78] ogbg-moltox21: 0.781482 val loss: 0.319710
[Epoch 78] ogbg-moltox21: 0.747421 test loss: 0.350539
[Epoch 79; Iter    18/  209] train: loss: 0.1196119
[Epoch 79; Iter    48/  209] train: loss: 0.0789447
[Epoch 79; Iter    78/  209] train: loss: 0.0464097
[Epoch 79; Iter   108/  209] train: loss: 0.0593127
[Epoch 79; Iter   138/  209] train: loss: 0.0684748
[Epoch 79; Iter   168/  209] train: loss: 0.0612471
[Epoch 79; Iter   198/  209] train: loss: 0.0606266
[Epoch 79] ogbg-moltox21: 0.777851 val loss: 0.339600
[Epoch 79] ogbg-moltox21: 0.750417 test loss: 0.361267
[Epoch 80; Iter    19/  209] train: loss: 0.1279083
[Epoch 80; Iter    49/  209] train: loss: 0.0623454
[Epoch 80; Iter    79/  209] train: loss: 0.0385110
[Epoch 80; Iter   109/  209] train: loss: 0.0675142
[Epoch 80; Iter   139/  209] train: loss: 0.0622901
[Epoch 80; Iter   169/  209] train: loss: 0.1285949
[Epoch 80; Iter   199/  209] train: loss: 0.0773609
[Epoch 80] ogbg-moltox21: 0.784381 val loss: 0.326887
[Epoch 80] ogbg-moltox21: 0.755302 test loss: 0.352691
[Epoch 81; Iter    20/  209] train: loss: 0.0632609
[Epoch 81; Iter    50/  209] train: loss: 0.0423690
[Epoch 81; Iter    80/  209] train: loss: 0.0860828
[Epoch 81; Iter   110/  209] train: loss: 0.0541719
[Epoch 81; Iter   140/  209] train: loss: 0.0806607
[Epoch 81; Iter   170/  209] train: loss: 0.0526838
[Epoch 81; Iter   200/  209] train: loss: 0.0841343
[Epoch 81] ogbg-moltox21: 0.783185 val loss: 0.337999
[Epoch 81] ogbg-moltox21: 0.748936 test loss: 0.365183
[Epoch 82; Iter    21/  209] train: loss: 0.0541052
[Epoch 64] ogbg-moltox21: 0.753112 test loss: 0.311363
[Epoch 65; Iter     4/  209] train: loss: 0.0960131
[Epoch 65; Iter    34/  209] train: loss: 0.1045480
[Epoch 65; Iter    64/  209] train: loss: 0.0714878
[Epoch 65; Iter    94/  209] train: loss: 0.0914494
[Epoch 65; Iter   124/  209] train: loss: 0.0925754
[Epoch 65; Iter   154/  209] train: loss: 0.0628711
[Epoch 65; Iter   184/  209] train: loss: 0.0826805
[Epoch 65] ogbg-moltox21: 0.778907 val loss: 0.310384
[Epoch 65] ogbg-moltox21: 0.750134 test loss: 0.324419
[Epoch 66; Iter     5/  209] train: loss: 0.0629853
[Epoch 66; Iter    35/  209] train: loss: 0.0950418
[Epoch 66; Iter    65/  209] train: loss: 0.0724791
[Epoch 66; Iter    95/  209] train: loss: 0.0852810
[Epoch 66; Iter   125/  209] train: loss: 0.0746669
[Epoch 66; Iter   155/  209] train: loss: 0.1057734
[Epoch 66; Iter   185/  209] train: loss: 0.0670452
[Epoch 66] ogbg-moltox21: 0.771043 val loss: 0.311252
[Epoch 66] ogbg-moltox21: 0.743546 test loss: 0.322599
[Epoch 67; Iter     6/  209] train: loss: 0.0598151
[Epoch 67; Iter    36/  209] train: loss: 0.0728120
[Epoch 67; Iter    66/  209] train: loss: 0.0794145
[Epoch 67; Iter    96/  209] train: loss: 0.0877473
[Epoch 67; Iter   126/  209] train: loss: 0.0512408
[Epoch 67; Iter   156/  209] train: loss: 0.0725415
[Epoch 67; Iter   186/  209] train: loss: 0.0806740
[Epoch 67] ogbg-moltox21: 0.771200 val loss: 0.308324
[Epoch 67] ogbg-moltox21: 0.740186 test loss: 0.330503
[Epoch 68; Iter     7/  209] train: loss: 0.0364423
[Epoch 68; Iter    37/  209] train: loss: 0.0461420
[Epoch 68; Iter    67/  209] train: loss: 0.1339448
[Epoch 68; Iter    97/  209] train: loss: 0.0578740
[Epoch 68; Iter   127/  209] train: loss: 0.0791202
[Epoch 68; Iter   157/  209] train: loss: 0.0807494
[Epoch 68; Iter   187/  209] train: loss: 0.0972925
[Epoch 68] ogbg-moltox21: 0.773589 val loss: 0.315888
[Epoch 68] ogbg-moltox21: 0.747366 test loss: 0.334024
[Epoch 69; Iter     8/  209] train: loss: 0.0850958
[Epoch 69; Iter    38/  209] train: loss: 0.0833408
[Epoch 69; Iter    68/  209] train: loss: 0.0452581
[Epoch 69; Iter    98/  209] train: loss: 0.0878155
[Epoch 69; Iter   128/  209] train: loss: 0.0896175
[Epoch 69; Iter   158/  209] train: loss: 0.0671339
[Epoch 69; Iter   188/  209] train: loss: 0.1242665
[Epoch 69] ogbg-moltox21: 0.780777 val loss: 0.316153
[Epoch 69] ogbg-moltox21: 0.743003 test loss: 0.338901
[Epoch 70; Iter     9/  209] train: loss: 0.0791132
[Epoch 70; Iter    39/  209] train: loss: 0.1132125
[Epoch 70; Iter    69/  209] train: loss: 0.1054993
[Epoch 70; Iter    99/  209] train: loss: 0.1065519
[Epoch 70; Iter   129/  209] train: loss: 0.0640960
[Epoch 70; Iter   159/  209] train: loss: 0.0977575
[Epoch 70; Iter   189/  209] train: loss: 0.0652383
[Epoch 70] ogbg-moltox21: 0.772136 val loss: 0.314864
[Epoch 70] ogbg-moltox21: 0.745018 test loss: 0.329180
[Epoch 71; Iter    10/  209] train: loss: 0.0632131
[Epoch 71; Iter    40/  209] train: loss: 0.0881408
[Epoch 71; Iter    70/  209] train: loss: 0.0612267
[Epoch 71; Iter   100/  209] train: loss: 0.0964087
[Epoch 71; Iter   130/  209] train: loss: 0.0668931
[Epoch 71; Iter   160/  209] train: loss: 0.0707947
[Epoch 71; Iter   190/  209] train: loss: 0.0989799
[Epoch 71] ogbg-moltox21: 0.763829 val loss: 0.330195
[Epoch 71] ogbg-moltox21: 0.743983 test loss: 0.333285
[Epoch 72; Iter    11/  209] train: loss: 0.0864859
[Epoch 72; Iter    41/  209] train: loss: 0.0850524
[Epoch 72; Iter    71/  209] train: loss: 0.0740921
[Epoch 72; Iter   101/  209] train: loss: 0.0677947
[Epoch 72; Iter   131/  209] train: loss: 0.0948203
[Epoch 72; Iter   161/  209] train: loss: 0.0944745
[Epoch 72; Iter   191/  209] train: loss: 0.0990493
[Epoch 72] ogbg-moltox21: 0.776999 val loss: 0.329539
[Epoch 72] ogbg-moltox21: 0.754865 test loss: 0.335281
[Epoch 73; Iter    12/  209] train: loss: 0.0665871
[Epoch 73; Iter    42/  209] train: loss: 0.0868123
[Epoch 73; Iter    72/  209] train: loss: 0.0899409
[Epoch 73; Iter   102/  209] train: loss: 0.0439828
[Epoch 73; Iter   132/  209] train: loss: 0.1145839
[Epoch 73; Iter   162/  209] train: loss: 0.0456806
[Epoch 73; Iter   192/  209] train: loss: 0.0626488
[Epoch 73] ogbg-moltox21: 0.765042 val loss: 0.336486
[Epoch 73] ogbg-moltox21: 0.739904 test loss: 0.352321
[Epoch 74; Iter    13/  209] train: loss: 0.0611536
[Epoch 74; Iter    43/  209] train: loss: 0.0730825
[Epoch 74; Iter    73/  209] train: loss: 0.1193229
[Epoch 74; Iter   103/  209] train: loss: 0.0769632
[Epoch 74; Iter   133/  209] train: loss: 0.0586927
[Epoch 74; Iter   163/  209] train: loss: 0.1410928
[Epoch 74; Iter   193/  209] train: loss: 0.1081171
[Epoch 74] ogbg-moltox21: 0.773144 val loss: 0.335207
[Epoch 74] ogbg-moltox21: 0.744350 test loss: 0.352419
[Epoch 75; Iter    14/  209] train: loss: 0.0588486
[Epoch 75; Iter    44/  209] train: loss: 0.0336919
[Epoch 75; Iter    74/  209] train: loss: 0.0808945
[Epoch 75; Iter   104/  209] train: loss: 0.1050887
[Epoch 75; Iter   134/  209] train: loss: 0.0775842
[Epoch 75; Iter   164/  209] train: loss: 0.0613370
[Epoch 75; Iter   194/  209] train: loss: 0.0531388
[Epoch 75] ogbg-moltox21: 0.768982 val loss: 0.342280
[Epoch 75] ogbg-moltox21: 0.738804 test loss: 0.355708
[Epoch 76; Iter    15/  209] train: loss: 0.0750609
[Epoch 76; Iter    45/  209] train: loss: 0.0875474
[Epoch 76; Iter    75/  209] train: loss: 0.0876674
[Epoch 76; Iter   105/  209] train: loss: 0.0943123
[Epoch 76; Iter   135/  209] train: loss: 0.0766146
[Epoch 76; Iter   165/  209] train: loss: 0.0982083
[Epoch 76; Iter   195/  209] train: loss: 0.0673497
[Epoch 76] ogbg-moltox21: 0.775018 val loss: 0.344134
[Epoch 76] ogbg-moltox21: 0.753714 test loss: 0.348389
[Epoch 77; Iter    16/  209] train: loss: 0.0371329
[Epoch 77; Iter    46/  209] train: loss: 0.0568530
[Epoch 77; Iter    76/  209] train: loss: 0.0555862
[Epoch 77; Iter   106/  209] train: loss: 0.0929193
[Epoch 77; Iter   136/  209] train: loss: 0.0695483
[Epoch 77; Iter   166/  209] train: loss: 0.1324176
[Epoch 77; Iter   196/  209] train: loss: 0.0404951
[Epoch 77] ogbg-moltox21: 0.771036 val loss: 0.337723
[Epoch 77] ogbg-moltox21: 0.738352 test loss: 0.357363
[Epoch 78; Iter    17/  209] train: loss: 0.1135935
[Epoch 78; Iter    47/  209] train: loss: 0.0750588
[Epoch 78; Iter    77/  209] train: loss: 0.1775908
[Epoch 78; Iter   107/  209] train: loss: 0.1126363
[Epoch 78; Iter   137/  209] train: loss: 0.0507310
[Epoch 78; Iter   167/  209] train: loss: 0.0557836
[Epoch 78; Iter   197/  209] train: loss: 0.0650073
[Epoch 78] ogbg-moltox21: 0.770403 val loss: 0.338229
[Epoch 78] ogbg-moltox21: 0.734931 test loss: 0.366569
[Epoch 79; Iter    18/  209] train: loss: 0.0674416
[Epoch 79; Iter    48/  209] train: loss: 0.0585711
[Epoch 79; Iter    78/  209] train: loss: 0.1288960
[Epoch 79; Iter   108/  209] train: loss: 0.0759890
[Epoch 79; Iter   138/  209] train: loss: 0.0948878
[Epoch 79; Iter   168/  209] train: loss: 0.0527988
[Epoch 79; Iter   198/  209] train: loss: 0.0419229
[Epoch 79] ogbg-moltox21: 0.770638 val loss: 0.349575
[Epoch 79] ogbg-moltox21: 0.744028 test loss: 0.361063
[Epoch 80; Iter    19/  209] train: loss: 0.0670098
[Epoch 80; Iter    49/  209] train: loss: 0.0360342
[Epoch 80; Iter    79/  209] train: loss: 0.1078306
[Epoch 80; Iter   109/  209] train: loss: 0.0689362
[Epoch 80; Iter   139/  209] train: loss: 0.0640965
[Epoch 80; Iter   169/  209] train: loss: 0.0505166
[Epoch 80; Iter   199/  209] train: loss: 0.0773699
[Epoch 80] ogbg-moltox21: 0.764863 val loss: 0.343190
[Epoch 80] ogbg-moltox21: 0.737281 test loss: 0.359245
[Epoch 81; Iter    20/  209] train: loss: 0.0532648
[Epoch 81; Iter    50/  209] train: loss: 0.0726461
[Epoch 81; Iter    80/  209] train: loss: 0.0549004
[Epoch 81; Iter   110/  209] train: loss: 0.0841360
[Epoch 81; Iter   140/  209] train: loss: 0.0720307
[Epoch 81; Iter   170/  209] train: loss: 0.0594341
[Epoch 81; Iter   200/  209] train: loss: 0.0908985
[Epoch 81] ogbg-moltox21: 0.774911 val loss: 0.352786
[Epoch 81] ogbg-moltox21: 0.749890 test loss: 0.361442
[Epoch 82; Iter    21/  209] train: loss: 0.0533611
[Epoch 99; Iter   128/  209] train: loss: 0.0195249
[Epoch 99; Iter   158/  209] train: loss: 0.0605221
[Epoch 99; Iter   188/  209] train: loss: 0.0362390
[Epoch 99] ogbg-moltox21: 0.757987 val loss: 0.577079
[Epoch 99] ogbg-moltox21: 0.741845 test loss: 0.591771
[Epoch 100; Iter     9/  209] train: loss: 0.0066318
[Epoch 100; Iter    39/  209] train: loss: 0.0185493
[Epoch 100; Iter    69/  209] train: loss: 0.0440078
[Epoch 100; Iter    99/  209] train: loss: 0.0081697
[Epoch 100; Iter   129/  209] train: loss: 0.0177247
[Epoch 100; Iter   159/  209] train: loss: 0.0215643
[Epoch 100; Iter   189/  209] train: loss: 0.0269668
[Epoch 100] ogbg-moltox21: 0.751147 val loss: 0.586964
[Epoch 100] ogbg-moltox21: 0.735831 test loss: 0.599172
[Epoch 101; Iter    10/  209] train: loss: 0.0390549
[Epoch 101; Iter    40/  209] train: loss: 0.0209030
[Epoch 101; Iter    70/  209] train: loss: 0.0320766
[Epoch 101; Iter   100/  209] train: loss: 0.0285678
[Epoch 101; Iter   130/  209] train: loss: 0.0125782
[Epoch 101; Iter   160/  209] train: loss: 0.0457603
[Epoch 101; Iter   190/  209] train: loss: 0.0295319
[Epoch 101] ogbg-moltox21: 0.755588 val loss: 0.576722
[Epoch 101] ogbg-moltox21: 0.733436 test loss: 0.602817
[Epoch 102; Iter    11/  209] train: loss: 0.0135965
[Epoch 102; Iter    41/  209] train: loss: 0.0230218
[Epoch 102; Iter    71/  209] train: loss: 0.0249288
[Epoch 102; Iter   101/  209] train: loss: 0.0411164
[Epoch 102; Iter   131/  209] train: loss: 0.0151733
[Epoch 102; Iter   161/  209] train: loss: 0.0251366
[Epoch 102; Iter   191/  209] train: loss: 0.0219095
[Epoch 102] ogbg-moltox21: 0.738163 val loss: 0.585471
[Epoch 102] ogbg-moltox21: 0.734877 test loss: 0.586033
[Epoch 103; Iter    12/  209] train: loss: 0.0225898
[Epoch 103; Iter    42/  209] train: loss: 0.0210053
[Epoch 103; Iter    72/  209] train: loss: 0.0197518
[Epoch 103; Iter   102/  209] train: loss: 0.0211423
[Epoch 103; Iter   132/  209] train: loss: 0.0280106
[Epoch 103; Iter   162/  209] train: loss: 0.0122279
[Epoch 103; Iter   192/  209] train: loss: 0.0179093
[Epoch 103] ogbg-moltox21: 0.746509 val loss: 0.622977
[Epoch 103] ogbg-moltox21: 0.735069 test loss: 0.645326
[Epoch 104; Iter    13/  209] train: loss: 0.0626142
[Epoch 104; Iter    43/  209] train: loss: 0.0152422
[Epoch 104; Iter    73/  209] train: loss: 0.0258258
[Epoch 104; Iter   103/  209] train: loss: 0.0150518
[Epoch 104; Iter   133/  209] train: loss: 0.0262895
[Epoch 104; Iter   163/  209] train: loss: 0.0737674
[Epoch 104; Iter   193/  209] train: loss: 0.0226535
[Epoch 104] ogbg-moltox21: 0.748438 val loss: 0.607282
[Epoch 104] ogbg-moltox21: 0.726431 test loss: 0.621363
[Epoch 105; Iter    14/  209] train: loss: 0.0175319
[Epoch 105; Iter    44/  209] train: loss: 0.0287392
[Epoch 105; Iter    74/  209] train: loss: 0.0218874
[Epoch 105; Iter   104/  209] train: loss: 0.0200249
[Epoch 105; Iter   134/  209] train: loss: 0.0112622
[Epoch 105; Iter   164/  209] train: loss: 0.0425251
[Epoch 105; Iter   194/  209] train: loss: 0.0141998
[Epoch 105] ogbg-moltox21: 0.747328 val loss: 0.669072
[Epoch 105] ogbg-moltox21: 0.732198 test loss: 0.674331
[Epoch 106; Iter    15/  209] train: loss: 0.0146369
[Epoch 106; Iter    45/  209] train: loss: 0.0126289
[Epoch 106; Iter    75/  209] train: loss: 0.0329945
[Epoch 106; Iter   105/  209] train: loss: 0.0158650
[Epoch 106; Iter   135/  209] train: loss: 0.0221752
[Epoch 106; Iter   165/  209] train: loss: 0.0237542
[Epoch 106; Iter   195/  209] train: loss: 0.0183505
[Epoch 106] ogbg-moltox21: 0.749957 val loss: 0.616371
[Epoch 106] ogbg-moltox21: 0.729904 test loss: 0.631864
[Epoch 107; Iter    16/  209] train: loss: 0.0247715
[Epoch 107; Iter    46/  209] train: loss: 0.0277491
[Epoch 107; Iter    76/  209] train: loss: 0.0123690
[Epoch 107; Iter   106/  209] train: loss: 0.0424631
[Epoch 107; Iter   136/  209] train: loss: 0.0267390
[Epoch 107; Iter   166/  209] train: loss: 0.0269213
[Epoch 107; Iter   196/  209] train: loss: 0.0353137
[Epoch 107] ogbg-moltox21: 0.742681 val loss: 0.643135
[Epoch 107] ogbg-moltox21: 0.719442 test loss: 0.661813
[Epoch 108; Iter    17/  209] train: loss: 0.0196145
[Epoch 108; Iter    47/  209] train: loss: 0.0215961
[Epoch 108; Iter    77/  209] train: loss: 0.0290268
[Epoch 108; Iter   107/  209] train: loss: 0.0481199
[Epoch 108; Iter   137/  209] train: loss: 0.0256502
[Epoch 108; Iter   167/  209] train: loss: 0.0361850
[Epoch 108; Iter   197/  209] train: loss: 0.0251517
[Epoch 108] ogbg-moltox21: 0.746740 val loss: 0.681140
[Epoch 108] ogbg-moltox21: 0.722159 test loss: 0.692296
[Epoch 109; Iter    18/  209] train: loss: 0.0294779
[Epoch 109; Iter    48/  209] train: loss: 0.0133525
[Epoch 109; Iter    78/  209] train: loss: 0.0144657
[Epoch 109; Iter   108/  209] train: loss: 0.0257237
[Epoch 109; Iter   138/  209] train: loss: 0.0292024
[Epoch 109; Iter   168/  209] train: loss: 0.0411687
[Epoch 109; Iter   198/  209] train: loss: 0.0090380
[Epoch 109] ogbg-moltox21: 0.733039 val loss: 0.631815
[Epoch 109] ogbg-moltox21: 0.724339 test loss: 0.645899
[Epoch 110; Iter    19/  209] train: loss: 0.0063736
[Epoch 110; Iter    49/  209] train: loss: 0.0138365
[Epoch 110; Iter    79/  209] train: loss: 0.0445183
[Epoch 110; Iter   109/  209] train: loss: 0.0261963
[Epoch 110; Iter   139/  209] train: loss: 0.0479742
[Epoch 110; Iter   169/  209] train: loss: 0.0260861
[Epoch 110; Iter   199/  209] train: loss: 0.0117896
[Epoch 110] ogbg-moltox21: 0.747165 val loss: 0.685373
[Epoch 110] ogbg-moltox21: 0.729554 test loss: 0.709178
[Epoch 111; Iter    20/  209] train: loss: 0.0540341
[Epoch 111; Iter    50/  209] train: loss: 0.0287038
[Epoch 111; Iter    80/  209] train: loss: 0.0195537
[Epoch 111; Iter   110/  209] train: loss: 0.0189133
[Epoch 111; Iter   140/  209] train: loss: 0.0291186
[Epoch 111; Iter   170/  209] train: loss: 0.0135975
[Epoch 111; Iter   200/  209] train: loss: 0.0207290
[Epoch 111] ogbg-moltox21: 0.740230 val loss: 0.629164
[Epoch 111] ogbg-moltox21: 0.724446 test loss: 0.651487
[Epoch 112; Iter    21/  209] train: loss: 0.0203855
[Epoch 112; Iter    51/  209] train: loss: 0.0264518
[Epoch 112; Iter    81/  209] train: loss: 0.0352570
[Epoch 112; Iter   111/  209] train: loss: 0.0355827
[Epoch 112; Iter   141/  209] train: loss: 0.0292640
[Epoch 112; Iter   171/  209] train: loss: 0.0140041
[Epoch 112; Iter   201/  209] train: loss: 0.0352301
[Epoch 112] ogbg-moltox21: 0.749627 val loss: 0.642813
[Epoch 112] ogbg-moltox21: 0.725490 test loss: 0.688050
[Epoch 113; Iter    22/  209] train: loss: 0.0189871
[Epoch 113; Iter    52/  209] train: loss: 0.0252044
[Epoch 113; Iter    82/  209] train: loss: 0.0354074
[Epoch 113; Iter   112/  209] train: loss: 0.0373355
[Epoch 113; Iter   142/  209] train: loss: 0.0205250
[Epoch 113; Iter   172/  209] train: loss: 0.0345794
[Epoch 113; Iter   202/  209] train: loss: 0.0100362
[Epoch 113] ogbg-moltox21: 0.735537 val loss: 0.654768
[Epoch 113] ogbg-moltox21: 0.711638 test loss: 0.678004
[Epoch 114; Iter    23/  209] train: loss: 0.0134197
[Epoch 114; Iter    53/  209] train: loss: 0.0104451
[Epoch 114; Iter    83/  209] train: loss: 0.0121339
[Epoch 114; Iter   113/  209] train: loss: 0.0320200
[Epoch 114; Iter   143/  209] train: loss: 0.0170173
[Epoch 114; Iter   173/  209] train: loss: 0.0147775
[Epoch 114; Iter   203/  209] train: loss: 0.0182335
[Epoch 114] ogbg-moltox21: 0.742948 val loss: 0.607155
[Epoch 114] ogbg-moltox21: 0.724832 test loss: 0.640351
[Epoch 115; Iter    24/  209] train: loss: 0.0104717
[Epoch 115; Iter    54/  209] train: loss: 0.0175862
[Epoch 115; Iter    84/  209] train: loss: 0.0227338
[Epoch 115; Iter   114/  209] train: loss: 0.0090702
[Epoch 115; Iter   144/  209] train: loss: 0.0159874
[Epoch 115; Iter   174/  209] train: loss: 0.0361435
[Epoch 115; Iter   204/  209] train: loss: 0.0159522
[Epoch 115] ogbg-moltox21: 0.749892 val loss: 0.678931
[Epoch 115] ogbg-moltox21: 0.723791 test loss: 0.716714
[Epoch 116; Iter    25/  209] train: loss: 0.0348811
[Epoch 116; Iter    55/  209] train: loss: 0.0077126
[Epoch 116; Iter    85/  209] train: loss: 0.0140774
[Epoch 116; Iter   115/  209] train: loss: 0.0204744
[Epoch 99; Iter   128/  209] train: loss: 0.0050172
[Epoch 99; Iter   158/  209] train: loss: 0.0156150
[Epoch 99; Iter   188/  209] train: loss: 0.0032576
[Epoch 99] ogbg-moltox21: 0.742737 val loss: 0.670799
[Epoch 99] ogbg-moltox21: 0.725227 test loss: 0.734179
[Epoch 100; Iter     9/  209] train: loss: 0.0106064
[Epoch 100; Iter    39/  209] train: loss: 0.0114149
[Epoch 100; Iter    69/  209] train: loss: 0.0158670
[Epoch 100; Iter    99/  209] train: loss: 0.0260429
[Epoch 100; Iter   129/  209] train: loss: 0.0149851
[Epoch 100; Iter   159/  209] train: loss: 0.0068725
[Epoch 100; Iter   189/  209] train: loss: 0.0046240
[Epoch 100] ogbg-moltox21: 0.741162 val loss: 0.679584
[Epoch 100] ogbg-moltox21: 0.726059 test loss: 0.756634
[Epoch 101; Iter    10/  209] train: loss: 0.0020370
[Epoch 101; Iter    40/  209] train: loss: 0.0019635
[Epoch 101; Iter    70/  209] train: loss: 0.0048527
[Epoch 101; Iter   100/  209] train: loss: 0.0090650
[Epoch 101; Iter   130/  209] train: loss: 0.0045866
[Epoch 101; Iter   160/  209] train: loss: 0.0125955
[Epoch 101; Iter   190/  209] train: loss: 0.0062055
[Epoch 101] ogbg-moltox21: 0.737984 val loss: 0.701611
[Epoch 101] ogbg-moltox21: 0.720658 test loss: 0.770640
[Epoch 102; Iter    11/  209] train: loss: 0.0117493
[Epoch 102; Iter    41/  209] train: loss: 0.0086668
[Epoch 102; Iter    71/  209] train: loss: 0.0025413
[Epoch 102; Iter   101/  209] train: loss: 0.0076540
[Epoch 102; Iter   131/  209] train: loss: 0.0059832
[Epoch 102; Iter   161/  209] train: loss: 0.0047015
[Epoch 102; Iter   191/  209] train: loss: 0.0058762
[Epoch 102] ogbg-moltox21: 0.746395 val loss: 0.707490
[Epoch 102] ogbg-moltox21: 0.729623 test loss: 0.789817
[Epoch 103; Iter    12/  209] train: loss: 0.0122768
[Epoch 103; Iter    42/  209] train: loss: 0.0031468
[Epoch 103; Iter    72/  209] train: loss: 0.0022558
[Epoch 103; Iter   102/  209] train: loss: 0.0026019
[Epoch 103; Iter   132/  209] train: loss: 0.0069025
[Epoch 103; Iter   162/  209] train: loss: 0.0537441
[Epoch 103; Iter   192/  209] train: loss: 0.0089438
[Epoch 103] ogbg-moltox21: 0.740055 val loss: 0.682538
[Epoch 103] ogbg-moltox21: 0.723329 test loss: 0.751507
[Epoch 104; Iter    13/  209] train: loss: 0.0049724
[Epoch 104; Iter    43/  209] train: loss: 0.0057364
[Epoch 104; Iter    73/  209] train: loss: 0.0030731
[Epoch 104; Iter   103/  209] train: loss: 0.0048765
[Epoch 104; Iter   133/  209] train: loss: 0.0026244
[Epoch 104; Iter   163/  209] train: loss: 0.0085820
[Epoch 104; Iter   193/  209] train: loss: 0.0039693
[Epoch 104] ogbg-moltox21: 0.741183 val loss: 0.682929
[Epoch 104] ogbg-moltox21: 0.730262 test loss: 0.753157
[Epoch 105; Iter    14/  209] train: loss: 0.0065278
[Epoch 105; Iter    44/  209] train: loss: 0.0063477
[Epoch 105; Iter    74/  209] train: loss: 0.0072163
[Epoch 105; Iter   104/  209] train: loss: 0.0099730
[Epoch 105; Iter   134/  209] train: loss: 0.0081947
[Epoch 105; Iter   164/  209] train: loss: 0.0035433
[Epoch 105; Iter   194/  209] train: loss: 0.0028559
[Epoch 105] ogbg-moltox21: 0.738481 val loss: 0.697572
[Epoch 105] ogbg-moltox21: 0.730364 test loss: 0.761916
[Epoch 106; Iter    15/  209] train: loss: 0.0030205
[Epoch 106; Iter    45/  209] train: loss: 0.0111772
[Epoch 106; Iter    75/  209] train: loss: 0.0138779
[Epoch 106; Iter   105/  209] train: loss: 0.0072331
[Epoch 106; Iter   135/  209] train: loss: 0.0081528
[Epoch 106; Iter   165/  209] train: loss: 0.0113775
[Epoch 106; Iter   195/  209] train: loss: 0.0078970
[Epoch 106] ogbg-moltox21: 0.740342 val loss: 0.707691
[Epoch 106] ogbg-moltox21: 0.727214 test loss: 0.783149
[Epoch 107; Iter    16/  209] train: loss: 0.0055407
[Epoch 107; Iter    46/  209] train: loss: 0.0063580
[Epoch 107; Iter    76/  209] train: loss: 0.0302990
[Epoch 107; Iter   106/  209] train: loss: 0.0024529
[Epoch 107; Iter   136/  209] train: loss: 0.0053462
[Epoch 107; Iter   166/  209] train: loss: 0.0051830
[Epoch 107; Iter   196/  209] train: loss: 0.0023096
[Epoch 107] ogbg-moltox21: 0.743751 val loss: 0.679649
[Epoch 107] ogbg-moltox21: 0.731866 test loss: 0.752962
[Epoch 108; Iter    17/  209] train: loss: 0.0057823
[Epoch 108; Iter    47/  209] train: loss: 0.0070997
[Epoch 108; Iter    77/  209] train: loss: 0.0020963
[Epoch 108; Iter   107/  209] train: loss: 0.0216067
[Epoch 108; Iter   137/  209] train: loss: 0.0090375
[Epoch 108; Iter   167/  209] train: loss: 0.0031031
[Epoch 108; Iter   197/  209] train: loss: 0.0082353
[Epoch 108] ogbg-moltox21: 0.739230 val loss: 0.681771
[Epoch 108] ogbg-moltox21: 0.726157 test loss: 0.769560
[Epoch 109; Iter    18/  209] train: loss: 0.0051461
[Epoch 109; Iter    48/  209] train: loss: 0.0026830
[Epoch 109; Iter    78/  209] train: loss: 0.0048105
[Epoch 109; Iter   108/  209] train: loss: 0.0012698
[Epoch 109; Iter   138/  209] train: loss: 0.0067504
[Epoch 109; Iter   168/  209] train: loss: 0.0174540
[Epoch 109; Iter   198/  209] train: loss: 0.0032326
[Epoch 109] ogbg-moltox21: 0.748914 val loss: 0.698330
[Epoch 109] ogbg-moltox21: 0.733502 test loss: 0.773760
[Epoch 110; Iter    19/  209] train: loss: 0.0039011
[Epoch 110; Iter    49/  209] train: loss: 0.0021170
[Epoch 110; Iter    79/  209] train: loss: 0.0107779
[Epoch 110; Iter   109/  209] train: loss: 0.0172116
[Epoch 110; Iter   139/  209] train: loss: 0.0094382
[Epoch 110; Iter   169/  209] train: loss: 0.0074256
[Epoch 110; Iter   199/  209] train: loss: 0.0035016
[Epoch 110] ogbg-moltox21: 0.745360 val loss: 0.679148
[Epoch 110] ogbg-moltox21: 0.725723 test loss: 0.771839
[Epoch 111; Iter    20/  209] train: loss: 0.0065643
[Epoch 111; Iter    50/  209] train: loss: 0.0057269
[Epoch 111; Iter    80/  209] train: loss: 0.0055998
[Epoch 111; Iter   110/  209] train: loss: 0.0070888
[Epoch 111; Iter   140/  209] train: loss: 0.0036030
[Epoch 111; Iter   170/  209] train: loss: 0.0115117
[Epoch 111; Iter   200/  209] train: loss: 0.0091482
[Epoch 111] ogbg-moltox21: 0.747504 val loss: 0.690570
[Epoch 111] ogbg-moltox21: 0.725520 test loss: 0.785724
[Epoch 112; Iter    21/  209] train: loss: 0.0046906
[Epoch 112; Iter    51/  209] train: loss: 0.0032419
[Epoch 112; Iter    81/  209] train: loss: 0.0062933
[Epoch 112; Iter   111/  209] train: loss: 0.0147211
[Epoch 112; Iter   141/  209] train: loss: 0.0061132
[Epoch 112; Iter   171/  209] train: loss: 0.0060353
[Epoch 112; Iter   201/  209] train: loss: 0.0304576
[Epoch 112] ogbg-moltox21: 0.740822 val loss: 0.757964
[Epoch 112] ogbg-moltox21: 0.731489 test loss: 0.831778
[Epoch 113; Iter    22/  209] train: loss: 0.0083152
[Epoch 113; Iter    52/  209] train: loss: 0.0030702
[Epoch 113; Iter    82/  209] train: loss: 0.0041014
[Epoch 113; Iter   112/  209] train: loss: 0.0020901
[Epoch 113; Iter   142/  209] train: loss: 0.0197777
[Epoch 113; Iter   172/  209] train: loss: 0.0065474
[Epoch 113; Iter   202/  209] train: loss: 0.0087316
[Epoch 113] ogbg-moltox21: 0.740597 val loss: 0.694642
[Epoch 113] ogbg-moltox21: 0.725899 test loss: 0.780264
[Epoch 114; Iter    23/  209] train: loss: 0.0021533
[Epoch 114; Iter    53/  209] train: loss: 0.0025136
[Epoch 114; Iter    83/  209] train: loss: 0.0061815
[Epoch 114; Iter   113/  209] train: loss: 0.0089797
[Epoch 114; Iter   143/  209] train: loss: 0.0041341
[Epoch 114; Iter   173/  209] train: loss: 0.0099764
[Epoch 114; Iter   203/  209] train: loss: 0.0103021
[Epoch 114] ogbg-moltox21: 0.736614 val loss: 0.713676
[Epoch 114] ogbg-moltox21: 0.722619 test loss: 0.800420
[Epoch 115; Iter    24/  209] train: loss: 0.0046942
[Epoch 115; Iter    54/  209] train: loss: 0.0029094
[Epoch 115; Iter    84/  209] train: loss: 0.0146411
[Epoch 115; Iter   114/  209] train: loss: 0.0021950
[Epoch 115; Iter   144/  209] train: loss: 0.0051289
[Epoch 115; Iter   174/  209] train: loss: 0.0065146
[Epoch 115; Iter   204/  209] train: loss: 0.0074928
[Epoch 115] ogbg-moltox21: 0.742510 val loss: 0.762931
[Epoch 115] ogbg-moltox21: 0.724724 test loss: 0.869436
[Epoch 116; Iter    25/  209] train: loss: 0.0068333
[Epoch 116; Iter    55/  209] train: loss: 0.0078647
[Epoch 116; Iter    85/  209] train: loss: 0.0221528
[Epoch 116; Iter   115/  209] train: loss: 0.0156019
[Epoch 99; Iter   128/  209] train: loss: 0.0195400
[Epoch 99; Iter   158/  209] train: loss: 0.0257745
[Epoch 99; Iter   188/  209] train: loss: 0.0509696
[Epoch 99] ogbg-moltox21: 0.724445 val loss: 0.738226
[Epoch 99] ogbg-moltox21: 0.711076 test loss: 0.757584
[Epoch 100; Iter     9/  209] train: loss: 0.0173546
[Epoch 100; Iter    39/  209] train: loss: 0.0075447
[Epoch 100; Iter    69/  209] train: loss: 0.0077948
[Epoch 100; Iter    99/  209] train: loss: 0.0123289
[Epoch 100; Iter   129/  209] train: loss: 0.0335914
[Epoch 100; Iter   159/  209] train: loss: 0.0115488
[Epoch 100; Iter   189/  209] train: loss: 0.0038579
[Epoch 100] ogbg-moltox21: 0.732001 val loss: 0.673985
[Epoch 100] ogbg-moltox21: 0.722832 test loss: 0.660806
[Epoch 101; Iter    10/  209] train: loss: 0.0107332
[Epoch 101; Iter    40/  209] train: loss: 0.0097545
[Epoch 101; Iter    70/  209] train: loss: 0.0064106
[Epoch 101; Iter   100/  209] train: loss: 0.0084297
[Epoch 101; Iter   130/  209] train: loss: 0.0055473
[Epoch 101; Iter   160/  209] train: loss: 0.0123520
[Epoch 101; Iter   190/  209] train: loss: 0.0037125
[Epoch 101] ogbg-moltox21: 0.729694 val loss: 0.760686
[Epoch 101] ogbg-moltox21: 0.718069 test loss: 0.770886
[Epoch 102; Iter    11/  209] train: loss: 0.0015499
[Epoch 102; Iter    41/  209] train: loss: 0.0055176
[Epoch 102; Iter    71/  209] train: loss: 0.0068779
[Epoch 102; Iter   101/  209] train: loss: 0.0033441
[Epoch 102; Iter   131/  209] train: loss: 0.0155651
[Epoch 102; Iter   161/  209] train: loss: 0.0126246
[Epoch 102; Iter   191/  209] train: loss: 0.0021464
[Epoch 102] ogbg-moltox21: 0.727581 val loss: 0.773847
[Epoch 102] ogbg-moltox21: 0.719807 test loss: 0.761102
[Epoch 103; Iter    12/  209] train: loss: 0.0048476
[Epoch 103; Iter    42/  209] train: loss: 0.0033995
[Epoch 103; Iter    72/  209] train: loss: 0.0084462
[Epoch 103; Iter   102/  209] train: loss: 0.0025222
[Epoch 103; Iter   132/  209] train: loss: 0.0051202
[Epoch 103; Iter   162/  209] train: loss: 0.0134556
[Epoch 103; Iter   192/  209] train: loss: 0.0054737
[Epoch 103] ogbg-moltox21: 0.729443 val loss: 0.735095
[Epoch 103] ogbg-moltox21: 0.716792 test loss: 0.733373
[Epoch 104; Iter    13/  209] train: loss: 0.0089416
[Epoch 104; Iter    43/  209] train: loss: 0.0037253
[Epoch 104; Iter    73/  209] train: loss: 0.0089473
[Epoch 104; Iter   103/  209] train: loss: 0.0023895
[Epoch 104; Iter   133/  209] train: loss: 0.0077684
[Epoch 104; Iter   163/  209] train: loss: 0.0014151
[Epoch 104; Iter   193/  209] train: loss: 0.0046892
[Epoch 104] ogbg-moltox21: 0.733583 val loss: 0.779809
[Epoch 104] ogbg-moltox21: 0.720440 test loss: 0.825884
[Epoch 105; Iter    14/  209] train: loss: 0.0066275
[Epoch 105; Iter    44/  209] train: loss: 0.0031197
[Epoch 105; Iter    74/  209] train: loss: 0.0060654
[Epoch 105; Iter   104/  209] train: loss: 0.0036931
[Epoch 105; Iter   134/  209] train: loss: 0.0045269
[Epoch 105; Iter   164/  209] train: loss: 0.0038424
[Epoch 105; Iter   194/  209] train: loss: 0.0148285
[Epoch 105] ogbg-moltox21: 0.735008 val loss: 0.791199
[Epoch 105] ogbg-moltox21: 0.722081 test loss: 0.776788
[Epoch 106; Iter    15/  209] train: loss: 0.0032061
[Epoch 106; Iter    45/  209] train: loss: 0.0072306
[Epoch 106; Iter    75/  209] train: loss: 0.0023718
[Epoch 106; Iter   105/  209] train: loss: 0.0103878
[Epoch 106; Iter   135/  209] train: loss: 0.0126393
[Epoch 106; Iter   165/  209] train: loss: 0.0020010
[Epoch 106; Iter   195/  209] train: loss: 0.0015081
[Epoch 106] ogbg-moltox21: 0.735544 val loss: 0.764851
[Epoch 106] ogbg-moltox21: 0.720900 test loss: 0.800014
[Epoch 107; Iter    16/  209] train: loss: 0.0122562
[Epoch 107; Iter    46/  209] train: loss: 0.0059453
[Epoch 107; Iter    76/  209] train: loss: 0.0027745
[Epoch 107; Iter   106/  209] train: loss: 0.0046362
[Epoch 107; Iter   136/  209] train: loss: 0.0088733
[Epoch 107; Iter   166/  209] train: loss: 0.0073410
[Epoch 107; Iter   196/  209] train: loss: 0.0016604
[Epoch 107] ogbg-moltox21: 0.733963 val loss: 0.783844
[Epoch 107] ogbg-moltox21: 0.721810 test loss: 0.804816
[Epoch 108; Iter    17/  209] train: loss: 0.0054871
[Epoch 108; Iter    47/  209] train: loss: 0.0035748
[Epoch 108; Iter    77/  209] train: loss: 0.0044279
[Epoch 108; Iter   107/  209] train: loss: 0.0247456
[Epoch 108; Iter   137/  209] train: loss: 0.0064917
[Epoch 108; Iter   167/  209] train: loss: 0.0073330
[Epoch 108; Iter   197/  209] train: loss: 0.0026768
[Epoch 108] ogbg-moltox21: 0.736007 val loss: 0.725569
[Epoch 108] ogbg-moltox21: 0.716922 test loss: 0.784399
[Epoch 109; Iter    18/  209] train: loss: 0.0035634
[Epoch 109; Iter    48/  209] train: loss: 0.0044783
[Epoch 109; Iter    78/  209] train: loss: 0.0049898
[Epoch 109; Iter   108/  209] train: loss: 0.0020845
[Epoch 109; Iter   138/  209] train: loss: 0.0060595
[Epoch 109; Iter   168/  209] train: loss: 0.0051545
[Epoch 109; Iter   198/  209] train: loss: 0.0024392
[Epoch 109] ogbg-moltox21: 0.726129 val loss: 0.769228
[Epoch 109] ogbg-moltox21: 0.712841 test loss: 0.757628
[Epoch 110; Iter    19/  209] train: loss: 0.0095658
[Epoch 110; Iter    49/  209] train: loss: 0.0032805
[Epoch 110; Iter    79/  209] train: loss: 0.0042351
[Epoch 110; Iter   109/  209] train: loss: 0.0050648
[Epoch 110; Iter   139/  209] train: loss: 0.0190347
[Epoch 110; Iter   169/  209] train: loss: 0.0010017
[Epoch 110; Iter   199/  209] train: loss: 0.0164277
[Epoch 110] ogbg-moltox21: 0.726064 val loss: 0.763886
[Epoch 110] ogbg-moltox21: 0.716299 test loss: 0.782022
[Epoch 111; Iter    20/  209] train: loss: 0.0043074
[Epoch 111; Iter    50/  209] train: loss: 0.0019861
[Epoch 111; Iter    80/  209] train: loss: 0.0050492
[Epoch 111; Iter   110/  209] train: loss: 0.0127516
[Epoch 111; Iter   140/  209] train: loss: 0.0040894
[Epoch 111; Iter   170/  209] train: loss: 0.0224997
[Epoch 111; Iter   200/  209] train: loss: 0.0073168
[Epoch 111] ogbg-moltox21: 0.745330 val loss: 0.782522
[Epoch 111] ogbg-moltox21: 0.726304 test loss: 0.857496
[Epoch 112; Iter    21/  209] train: loss: 0.0140982
[Epoch 112; Iter    51/  209] train: loss: 0.0259183
[Epoch 112; Iter    81/  209] train: loss: 0.0056997
[Epoch 112; Iter   111/  209] train: loss: 0.0071615
[Epoch 112; Iter   141/  209] train: loss: 0.0061525
[Epoch 112; Iter   171/  209] train: loss: 0.0042523
[Epoch 112; Iter   201/  209] train: loss: 0.0101825
[Epoch 112] ogbg-moltox21: 0.731883 val loss: 0.816517
[Epoch 112] ogbg-moltox21: 0.720781 test loss: 0.860074
[Epoch 113; Iter    22/  209] train: loss: 0.0187635
[Epoch 113; Iter    52/  209] train: loss: 0.0023720
[Epoch 113; Iter    82/  209] train: loss: 0.0050652
[Epoch 113; Iter   112/  209] train: loss: 0.0075363
[Epoch 113; Iter   142/  209] train: loss: 0.0035005
[Epoch 113; Iter   172/  209] train: loss: 0.0056958
[Epoch 113; Iter   202/  209] train: loss: 0.0159731
[Epoch 113] ogbg-moltox21: 0.734976 val loss: 0.796642
[Epoch 113] ogbg-moltox21: 0.719391 test loss: 0.850953
[Epoch 114; Iter    23/  209] train: loss: 0.0386938
[Epoch 114; Iter    53/  209] train: loss: 0.0114671
[Epoch 114; Iter    83/  209] train: loss: 0.0063540
[Epoch 114; Iter   113/  209] train: loss: 0.0026111
[Epoch 114; Iter   143/  209] train: loss: 0.0064238
[Epoch 114; Iter   173/  209] train: loss: 0.0086325
[Epoch 114; Iter   203/  209] train: loss: 0.0036800
[Epoch 114] ogbg-moltox21: 0.734549 val loss: 0.770235
[Epoch 114] ogbg-moltox21: 0.722295 test loss: 0.815445
[Epoch 115; Iter    24/  209] train: loss: 0.0029265
[Epoch 115; Iter    54/  209] train: loss: 0.0082567
[Epoch 115; Iter    84/  209] train: loss: 0.0040093
[Epoch 115; Iter   114/  209] train: loss: 0.0016932
[Epoch 115; Iter   144/  209] train: loss: 0.0074767
[Epoch 115; Iter   174/  209] train: loss: 0.0062797
[Epoch 115; Iter   204/  209] train: loss: 0.0037777
[Epoch 115] ogbg-moltox21: 0.739178 val loss: 0.807189
[Epoch 115] ogbg-moltox21: 0.721550 test loss: 0.902408
[Epoch 116; Iter    25/  209] train: loss: 0.0107655
[Epoch 116; Iter    55/  209] train: loss: 0.0056959
[Epoch 116; Iter    85/  209] train: loss: 0.0156243
[Epoch 116; Iter   115/  209] train: loss: 0.0043527
[Epoch 99; Iter   128/  209] train: loss: 0.0233607
[Epoch 99; Iter   158/  209] train: loss: 0.0242148
[Epoch 99; Iter   188/  209] train: loss: 0.0296833
[Epoch 99] ogbg-moltox21: 0.768749 val loss: 0.464774
[Epoch 99] ogbg-moltox21: 0.733243 test loss: 0.492961
[Epoch 100; Iter     9/  209] train: loss: 0.0229621
[Epoch 100; Iter    39/  209] train: loss: 0.0412718
[Epoch 100; Iter    69/  209] train: loss: 0.0322036
[Epoch 100; Iter    99/  209] train: loss: 0.0676337
[Epoch 100; Iter   129/  209] train: loss: 0.0263659
[Epoch 100; Iter   159/  209] train: loss: 0.0320385
[Epoch 100; Iter   189/  209] train: loss: 0.0285407
[Epoch 100] ogbg-moltox21: 0.760711 val loss: 0.474050
[Epoch 100] ogbg-moltox21: 0.726078 test loss: 0.498475
[Epoch 101; Iter    10/  209] train: loss: 0.0138140
[Epoch 101; Iter    40/  209] train: loss: 0.0125625
[Epoch 101; Iter    70/  209] train: loss: 0.0141946
[Epoch 101; Iter   100/  209] train: loss: 0.0204138
[Epoch 101; Iter   130/  209] train: loss: 0.0221683
[Epoch 101; Iter   160/  209] train: loss: 0.0348362
[Epoch 101; Iter   190/  209] train: loss: 0.0169842
[Epoch 101] ogbg-moltox21: 0.765560 val loss: 0.466819
[Epoch 101] ogbg-moltox21: 0.729460 test loss: 0.496320
[Epoch 102; Iter    11/  209] train: loss: 0.0398676
[Epoch 102; Iter    41/  209] train: loss: 0.0167258
[Epoch 102; Iter    71/  209] train: loss: 0.0130577
[Epoch 102; Iter   101/  209] train: loss: 0.0242122
[Epoch 102; Iter   131/  209] train: loss: 0.0217899
[Epoch 102; Iter   161/  209] train: loss: 0.0412787
[Epoch 102; Iter   191/  209] train: loss: 0.0257664
[Epoch 102] ogbg-moltox21: 0.764396 val loss: 0.464771
[Epoch 102] ogbg-moltox21: 0.727465 test loss: 0.503794
[Epoch 103; Iter    12/  209] train: loss: 0.0279962
[Epoch 103; Iter    42/  209] train: loss: 0.0153673
[Epoch 103; Iter    72/  209] train: loss: 0.0215896
[Epoch 103; Iter   102/  209] train: loss: 0.0249522
[Epoch 103; Iter   132/  209] train: loss: 0.0351382
[Epoch 103; Iter   162/  209] train: loss: 0.0955574
[Epoch 103; Iter   192/  209] train: loss: 0.0135736
[Epoch 103] ogbg-moltox21: 0.763691 val loss: 0.473527
[Epoch 103] ogbg-moltox21: 0.721717 test loss: 0.509981
[Epoch 104; Iter    13/  209] train: loss: 0.0237320
[Epoch 104; Iter    43/  209] train: loss: 0.0235984
[Epoch 104; Iter    73/  209] train: loss: 0.0233293
[Epoch 104; Iter   103/  209] train: loss: 0.0232715
[Epoch 104; Iter   133/  209] train: loss: 0.0224321
[Epoch 104; Iter   163/  209] train: loss: 0.0245473
[Epoch 104; Iter   193/  209] train: loss: 0.0122884
[Epoch 104] ogbg-moltox21: 0.762345 val loss: 0.494781
[Epoch 104] ogbg-moltox21: 0.729221 test loss: 0.515514
[Epoch 105; Iter    14/  209] train: loss: 0.0132249
[Epoch 105; Iter    44/  209] train: loss: 0.0177107
[Epoch 105; Iter    74/  209] train: loss: 0.0136375
[Epoch 105; Iter   104/  209] train: loss: 0.0246388
[Epoch 105; Iter   134/  209] train: loss: 0.0222028
[Epoch 105; Iter   164/  209] train: loss: 0.0093607
[Epoch 105; Iter   194/  209] train: loss: 0.0110734
[Epoch 105] ogbg-moltox21: 0.765110 val loss: 0.492393
[Epoch 105] ogbg-moltox21: 0.728401 test loss: 0.519301
[Epoch 106; Iter    15/  209] train: loss: 0.0155480
[Epoch 106; Iter    45/  209] train: loss: 0.0150254
[Epoch 106; Iter    75/  209] train: loss: 0.0288335
[Epoch 106; Iter   105/  209] train: loss: 0.0184465
[Epoch 106; Iter   135/  209] train: loss: 0.0398828
[Epoch 106; Iter   165/  209] train: loss: 0.0250138
[Epoch 106; Iter   195/  209] train: loss: 0.0200831
[Epoch 106] ogbg-moltox21: 0.758670 val loss: 0.503358
[Epoch 106] ogbg-moltox21: 0.723324 test loss: 0.528634
[Epoch 107; Iter    16/  209] train: loss: 0.0387687
[Epoch 107; Iter    46/  209] train: loss: 0.0149747
[Epoch 107; Iter    76/  209] train: loss: 0.0598293
[Epoch 107; Iter   106/  209] train: loss: 0.0104515
[Epoch 107; Iter   136/  209] train: loss: 0.0171797
[Epoch 107; Iter   166/  209] train: loss: 0.0351800
[Epoch 107; Iter   196/  209] train: loss: 0.0178678
[Epoch 107] ogbg-moltox21: 0.757532 val loss: 0.503570
[Epoch 107] ogbg-moltox21: 0.722940 test loss: 0.527555
[Epoch 108; Iter    17/  209] train: loss: 0.0208630
[Epoch 108; Iter    47/  209] train: loss: 0.0626953
[Epoch 108; Iter    77/  209] train: loss: 0.0151758
[Epoch 108; Iter   107/  209] train: loss: 0.0348339
[Epoch 108; Iter   137/  209] train: loss: 0.0193917
[Epoch 108; Iter   167/  209] train: loss: 0.0128106
[Epoch 108; Iter   197/  209] train: loss: 0.0340165
[Epoch 108] ogbg-moltox21: 0.760685 val loss: 0.491354
[Epoch 108] ogbg-moltox21: 0.714911 test loss: 0.529621
[Epoch 109; Iter    18/  209] train: loss: 0.0160342
[Epoch 109; Iter    48/  209] train: loss: 0.0167955
[Epoch 109; Iter    78/  209] train: loss: 0.0195885
[Epoch 109; Iter   108/  209] train: loss: 0.0235192
[Epoch 109; Iter   138/  209] train: loss: 0.0159317
[Epoch 109; Iter   168/  209] train: loss: 0.0166409
[Epoch 109; Iter   198/  209] train: loss: 0.0132140
[Epoch 109] ogbg-moltox21: 0.762656 val loss: 0.494543
[Epoch 109] ogbg-moltox21: 0.721074 test loss: 0.523383
[Epoch 110; Iter    19/  209] train: loss: 0.0155908
[Epoch 110; Iter    49/  209] train: loss: 0.0203847
[Epoch 110; Iter    79/  209] train: loss: 0.0165412
[Epoch 110; Iter   109/  209] train: loss: 0.0380686
[Epoch 110; Iter   139/  209] train: loss: 0.0287440
[Epoch 110; Iter   169/  209] train: loss: 0.0095412
[Epoch 110; Iter   199/  209] train: loss: 0.0208690
[Epoch 110] ogbg-moltox21: 0.763294 val loss: 0.504253
[Epoch 110] ogbg-moltox21: 0.721777 test loss: 0.545418
[Epoch 111; Iter    20/  209] train: loss: 0.0535128
[Epoch 111; Iter    50/  209] train: loss: 0.0215399
[Epoch 111; Iter    80/  209] train: loss: 0.0239456
[Epoch 111; Iter   110/  209] train: loss: 0.0084808
[Epoch 111; Iter   140/  209] train: loss: 0.0226380
[Epoch 111; Iter   170/  209] train: loss: 0.0118494
[Epoch 111; Iter   200/  209] train: loss: 0.0277629
[Epoch 111] ogbg-moltox21: 0.760611 val loss: 0.506536
[Epoch 111] ogbg-moltox21: 0.717047 test loss: 0.546128
[Epoch 112; Iter    21/  209] train: loss: 0.0176985
[Epoch 112; Iter    51/  209] train: loss: 0.0214835
[Epoch 112; Iter    81/  209] train: loss: 0.0145638
[Epoch 112; Iter   111/  209] train: loss: 0.0369529
[Epoch 112; Iter   141/  209] train: loss: 0.0186558
[Epoch 112; Iter   171/  209] train: loss: 0.0158305
[Epoch 112; Iter   201/  209] train: loss: 0.0365525
[Epoch 112] ogbg-moltox21: 0.755749 val loss: 0.526501
[Epoch 112] ogbg-moltox21: 0.716172 test loss: 0.553145
[Epoch 113; Iter    22/  209] train: loss: 0.0263720
[Epoch 113; Iter    52/  209] train: loss: 0.0210433
[Epoch 113; Iter    82/  209] train: loss: 0.0219078
[Epoch 113; Iter   112/  209] train: loss: 0.0118748
[Epoch 113; Iter   142/  209] train: loss: 0.0304198
[Epoch 113; Iter   172/  209] train: loss: 0.0104706
[Epoch 113; Iter   202/  209] train: loss: 0.0430493
[Epoch 113] ogbg-moltox21: 0.763744 val loss: 0.501369
[Epoch 113] ogbg-moltox21: 0.724204 test loss: 0.528527
[Epoch 114; Iter    23/  209] train: loss: 0.0286971
[Epoch 114; Iter    53/  209] train: loss: 0.0165782
[Epoch 114; Iter    83/  209] train: loss: 0.0244607
[Epoch 114; Iter   113/  209] train: loss: 0.0187727
[Epoch 114; Iter   143/  209] train: loss: 0.0243307
[Epoch 114; Iter   173/  209] train: loss: 0.0193962
[Epoch 114; Iter   203/  209] train: loss: 0.0155299
[Epoch 114] ogbg-moltox21: 0.754670 val loss: 0.520870
[Epoch 114] ogbg-moltox21: 0.718023 test loss: 0.550049
[Epoch 115; Iter    24/  209] train: loss: 0.0137334
[Epoch 115; Iter    54/  209] train: loss: 0.0116135
[Epoch 115; Iter    84/  209] train: loss: 0.0404805
[Epoch 115; Iter   114/  209] train: loss: 0.0126876
[Epoch 115; Iter   144/  209] train: loss: 0.0127942
[Epoch 115; Iter   174/  209] train: loss: 0.0250824
[Epoch 115; Iter   204/  209] train: loss: 0.0487670
[Epoch 115] ogbg-moltox21: 0.760082 val loss: 0.513673
[Epoch 115] ogbg-moltox21: 0.722771 test loss: 0.546302
[Epoch 116; Iter    25/  209] train: loss: 0.0156986
[Epoch 116; Iter    55/  209] train: loss: 0.0320963
[Epoch 116; Iter    85/  209] train: loss: 0.0411930
[Epoch 116; Iter   115/  209] train: loss: 0.0165616
[Epoch 99; Iter   128/  209] train: loss: 0.0172076
[Epoch 99; Iter   158/  209] train: loss: 0.0079413
[Epoch 99; Iter   188/  209] train: loss: 0.0308565
[Epoch 99] ogbg-moltox21: 0.746991 val loss: 0.574728
[Epoch 99] ogbg-moltox21: 0.724830 test loss: 0.629441
[Epoch 100; Iter     9/  209] train: loss: 0.0141398
[Epoch 100; Iter    39/  209] train: loss: 0.0162487
[Epoch 100; Iter    69/  209] train: loss: 0.0131080
[Epoch 100; Iter    99/  209] train: loss: 0.0079545
[Epoch 100; Iter   129/  209] train: loss: 0.0459197
[Epoch 100; Iter   159/  209] train: loss: 0.0141491
[Epoch 100; Iter   189/  209] train: loss: 0.0125083
[Epoch 100] ogbg-moltox21: 0.751474 val loss: 0.571972
[Epoch 100] ogbg-moltox21: 0.730366 test loss: 0.607128
[Epoch 101; Iter    10/  209] train: loss: 0.0192766
[Epoch 101; Iter    40/  209] train: loss: 0.0351430
[Epoch 101; Iter    70/  209] train: loss: 0.0141715
[Epoch 101; Iter   100/  209] train: loss: 0.0070182
[Epoch 101; Iter   130/  209] train: loss: 0.0107727
[Epoch 101; Iter   160/  209] train: loss: 0.0081979
[Epoch 101; Iter   190/  209] train: loss: 0.0061772
[Epoch 101] ogbg-moltox21: 0.753358 val loss: 0.551973
[Epoch 101] ogbg-moltox21: 0.726611 test loss: 0.586332
[Epoch 102; Iter    11/  209] train: loss: 0.0152394
[Epoch 102; Iter    41/  209] train: loss: 0.0153520
[Epoch 102; Iter    71/  209] train: loss: 0.0085105
[Epoch 102; Iter   101/  209] train: loss: 0.0094886
[Epoch 102; Iter   131/  209] train: loss: 0.0480125
[Epoch 102; Iter   161/  209] train: loss: 0.0199041
[Epoch 102; Iter   191/  209] train: loss: 0.0068317
[Epoch 102] ogbg-moltox21: 0.745852 val loss: 0.579803
[Epoch 102] ogbg-moltox21: 0.729168 test loss: 0.610261
[Epoch 103; Iter    12/  209] train: loss: 0.0268218
[Epoch 103; Iter    42/  209] train: loss: 0.0201049
[Epoch 103; Iter    72/  209] train: loss: 0.0216958
[Epoch 103; Iter   102/  209] train: loss: 0.0127969
[Epoch 103; Iter   132/  209] train: loss: 0.0287593
[Epoch 103; Iter   162/  209] train: loss: 0.0205963
[Epoch 103; Iter   192/  209] train: loss: 0.0286349
[Epoch 103] ogbg-moltox21: 0.750453 val loss: 0.556285
[Epoch 103] ogbg-moltox21: 0.726539 test loss: 0.620193
[Epoch 104; Iter    13/  209] train: loss: 0.0102991
[Epoch 104; Iter    43/  209] train: loss: 0.0212352
[Epoch 104; Iter    73/  209] train: loss: 0.0141855
[Epoch 104; Iter   103/  209] train: loss: 0.0102779
[Epoch 104; Iter   133/  209] train: loss: 0.0115975
[Epoch 104; Iter   163/  209] train: loss: 0.0073261
[Epoch 104; Iter   193/  209] train: loss: 0.0209916
[Epoch 104] ogbg-moltox21: 0.753160 val loss: 0.569746
[Epoch 104] ogbg-moltox21: 0.732893 test loss: 0.607803
[Epoch 105; Iter    14/  209] train: loss: 0.0161690
[Epoch 105; Iter    44/  209] train: loss: 0.0147394
[Epoch 105; Iter    74/  209] train: loss: 0.0138368
[Epoch 105; Iter   104/  209] train: loss: 0.0083358
[Epoch 105; Iter   134/  209] train: loss: 0.0101194
[Epoch 105; Iter   164/  209] train: loss: 0.0118075
[Epoch 105; Iter   194/  209] train: loss: 0.0300519
[Epoch 105] ogbg-moltox21: 0.750037 val loss: 0.597750
[Epoch 105] ogbg-moltox21: 0.723593 test loss: 0.635335
[Epoch 106; Iter    15/  209] train: loss: 0.0090777
[Epoch 106; Iter    45/  209] train: loss: 0.0144027
[Epoch 106; Iter    75/  209] train: loss: 0.0084265
[Epoch 106; Iter   105/  209] train: loss: 0.0622604
[Epoch 106; Iter   135/  209] train: loss: 0.0163082
[Epoch 106; Iter   165/  209] train: loss: 0.0137986
[Epoch 106; Iter   195/  209] train: loss: 0.0163502
[Epoch 106] ogbg-moltox21: 0.747810 val loss: 0.570419
[Epoch 106] ogbg-moltox21: 0.726415 test loss: 0.599548
[Epoch 107; Iter    16/  209] train: loss: 0.0258998
[Epoch 107; Iter    46/  209] train: loss: 0.0243008
[Epoch 107; Iter    76/  209] train: loss: 0.0081417
[Epoch 107; Iter   106/  209] train: loss: 0.0268916
[Epoch 107; Iter   136/  209] train: loss: 0.0318611
[Epoch 107; Iter   166/  209] train: loss: 0.0152715
[Epoch 107; Iter   196/  209] train: loss: 0.0098347
[Epoch 107] ogbg-moltox21: 0.754446 val loss: 0.555767
[Epoch 107] ogbg-moltox21: 0.725749 test loss: 0.600753
[Epoch 108; Iter    17/  209] train: loss: 0.0233967
[Epoch 108; Iter    47/  209] train: loss: 0.0155493
[Epoch 108; Iter    77/  209] train: loss: 0.0243468
[Epoch 108; Iter   107/  209] train: loss: 0.0369746
[Epoch 108; Iter   137/  209] train: loss: 0.0099084
[Epoch 108; Iter   167/  209] train: loss: 0.0167204
[Epoch 108; Iter   197/  209] train: loss: 0.0192850
[Epoch 108] ogbg-moltox21: 0.754262 val loss: 0.580122
[Epoch 108] ogbg-moltox21: 0.728945 test loss: 0.621234
[Epoch 109; Iter    18/  209] train: loss: 0.0263037
[Epoch 109; Iter    48/  209] train: loss: 0.0250480
[Epoch 109; Iter    78/  209] train: loss: 0.0177796
[Epoch 109; Iter   108/  209] train: loss: 0.0149824
[Epoch 109; Iter   138/  209] train: loss: 0.0235479
[Epoch 109; Iter   168/  209] train: loss: 0.0102843
[Epoch 109; Iter   198/  209] train: loss: 0.0268176
[Epoch 109] ogbg-moltox21: 0.750985 val loss: 0.568394
[Epoch 109] ogbg-moltox21: 0.725982 test loss: 0.613005
[Epoch 110; Iter    19/  209] train: loss: 0.0106369
[Epoch 110; Iter    49/  209] train: loss: 0.0131022
[Epoch 110; Iter    79/  209] train: loss: 0.0217460
[Epoch 110; Iter   109/  209] train: loss: 0.0150738
[Epoch 110; Iter   139/  209] train: loss: 0.0295583
[Epoch 110; Iter   169/  209] train: loss: 0.0123186
[Epoch 110; Iter   199/  209] train: loss: 0.0271247
[Epoch 110] ogbg-moltox21: 0.748852 val loss: 0.585837
[Epoch 110] ogbg-moltox21: 0.724551 test loss: 0.618988
[Epoch 111; Iter    20/  209] train: loss: 0.0137821
[Epoch 111; Iter    50/  209] train: loss: 0.0096082
[Epoch 111; Iter    80/  209] train: loss: 0.0086727
[Epoch 111; Iter   110/  209] train: loss: 0.0271350
[Epoch 111; Iter   140/  209] train: loss: 0.0221756
[Epoch 111; Iter   170/  209] train: loss: 0.0211759
[Epoch 111; Iter   200/  209] train: loss: 0.0139133
[Epoch 111] ogbg-moltox21: 0.755862 val loss: 0.579597
[Epoch 111] ogbg-moltox21: 0.729153 test loss: 0.628447
[Epoch 112; Iter    21/  209] train: loss: 0.0079055
[Epoch 112; Iter    51/  209] train: loss: 0.0160992
[Epoch 112; Iter    81/  209] train: loss: 0.0081434
[Epoch 112; Iter   111/  209] train: loss: 0.0254200
[Epoch 112; Iter   141/  209] train: loss: 0.0168422
[Epoch 112; Iter   171/  209] train: loss: 0.0116261
[Epoch 112; Iter   201/  209] train: loss: 0.0144044
[Epoch 112] ogbg-moltox21: 0.751674 val loss: 0.595894
[Epoch 112] ogbg-moltox21: 0.724818 test loss: 0.627893
[Epoch 113; Iter    22/  209] train: loss: 0.0341558
[Epoch 113; Iter    52/  209] train: loss: 0.0074782
[Epoch 113; Iter    82/  209] train: loss: 0.0239664
[Epoch 113; Iter   112/  209] train: loss: 0.0255684
[Epoch 113; Iter   142/  209] train: loss: 0.0245945
[Epoch 113; Iter   172/  209] train: loss: 0.0053879
[Epoch 113; Iter   202/  209] train: loss: 0.0193799
[Epoch 113] ogbg-moltox21: 0.749380 val loss: 0.577413
[Epoch 113] ogbg-moltox21: 0.725982 test loss: 0.612310
[Epoch 114; Iter    23/  209] train: loss: 0.0692094
[Epoch 114; Iter    53/  209] train: loss: 0.0225155
[Epoch 114; Iter    83/  209] train: loss: 0.0373625
[Epoch 114; Iter   113/  209] train: loss: 0.0134373
[Epoch 114; Iter   143/  209] train: loss: 0.0127643
[Epoch 114; Iter   173/  209] train: loss: 0.0172326
[Epoch 114; Iter   203/  209] train: loss: 0.0112694
[Epoch 114] ogbg-moltox21: 0.749958 val loss: 0.601814
[Epoch 114] ogbg-moltox21: 0.727062 test loss: 0.647001
[Epoch 115; Iter    24/  209] train: loss: 0.0084790
[Epoch 115; Iter    54/  209] train: loss: 0.0143297
[Epoch 115; Iter    84/  209] train: loss: 0.0208632
[Epoch 115; Iter   114/  209] train: loss: 0.0046556
[Epoch 115; Iter   144/  209] train: loss: 0.0123982
[Epoch 115; Iter   174/  209] train: loss: 0.0067815
[Epoch 115; Iter   204/  209] train: loss: 0.0078832
[Epoch 115] ogbg-moltox21: 0.750591 val loss: 0.596603
[Epoch 115] ogbg-moltox21: 0.719205 test loss: 0.644210
[Epoch 116; Iter    25/  209] train: loss: 0.0299689
[Epoch 116; Iter    55/  209] train: loss: 0.0086136
[Epoch 116; Iter    85/  209] train: loss: 0.0104199
[Epoch 116; Iter   115/  209] train: loss: 0.0127292
[Epoch 99; Iter   128/  209] train: loss: 0.0182047
[Epoch 99; Iter   158/  209] train: loss: 0.0085862
[Epoch 99; Iter   188/  209] train: loss: 0.0146319
[Epoch 99] ogbg-moltox21: 0.676630 val loss: 1.133853
[Epoch 99] ogbg-moltox21: 0.636337 test loss: 1.002342
[Epoch 100; Iter     9/  209] train: loss: 0.0052089
[Epoch 100; Iter    39/  209] train: loss: 0.0147876
[Epoch 100; Iter    69/  209] train: loss: 0.0194136
[Epoch 100; Iter    99/  209] train: loss: 0.0116553
[Epoch 100; Iter   129/  209] train: loss: 0.0078060
[Epoch 100; Iter   159/  209] train: loss: 0.0133929
[Epoch 100; Iter   189/  209] train: loss: 0.0088898
[Epoch 100] ogbg-moltox21: 0.676251 val loss: 1.612298
[Epoch 100] ogbg-moltox21: 0.639888 test loss: 1.144152
[Epoch 101; Iter    10/  209] train: loss: 0.0348172
[Epoch 101; Iter    40/  209] train: loss: 0.0125634
[Epoch 101; Iter    70/  209] train: loss: 0.0114538
[Epoch 101; Iter   100/  209] train: loss: 0.0143162
[Epoch 101; Iter   130/  209] train: loss: 0.0220870
[Epoch 101; Iter   160/  209] train: loss: 0.0259466
[Epoch 101; Iter   190/  209] train: loss: 0.0237974
[Epoch 101] ogbg-moltox21: 0.687010 val loss: 1.448585
[Epoch 101] ogbg-moltox21: 0.651268 test loss: 1.136086
[Epoch 102; Iter    11/  209] train: loss: 0.0059767
[Epoch 102; Iter    41/  209] train: loss: 0.0042168
[Epoch 102; Iter    71/  209] train: loss: 0.0036646
[Epoch 102; Iter   101/  209] train: loss: 0.0129301
[Epoch 102; Iter   131/  209] train: loss: 0.0084472
[Epoch 102; Iter   161/  209] train: loss: 0.0049874
[Epoch 102; Iter   191/  209] train: loss: 0.0104691
[Epoch 102] ogbg-moltox21: 0.671427 val loss: 1.306481
[Epoch 102] ogbg-moltox21: 0.637674 test loss: 1.177959
[Epoch 103; Iter    12/  209] train: loss: 0.0073588
[Epoch 103; Iter    42/  209] train: loss: 0.0196023
[Epoch 103; Iter    72/  209] train: loss: 0.0085337
[Epoch 103; Iter   102/  209] train: loss: 0.0040493
[Epoch 103; Iter   132/  209] train: loss: 0.0056868
[Epoch 103; Iter   162/  209] train: loss: 0.0050735
[Epoch 103; Iter   192/  209] train: loss: 0.0088666
[Epoch 103] ogbg-moltox21: 0.672841 val loss: 1.534096
[Epoch 103] ogbg-moltox21: 0.637806 test loss: 1.275004
[Epoch 104; Iter    13/  209] train: loss: 0.0156217
[Epoch 104; Iter    43/  209] train: loss: 0.0063812
[Epoch 104; Iter    73/  209] train: loss: 0.0136094
[Epoch 104; Iter   103/  209] train: loss: 0.0087809
[Epoch 104; Iter   133/  209] train: loss: 0.0105742
[Epoch 104; Iter   163/  209] train: loss: 0.0274645
[Epoch 104; Iter   193/  209] train: loss: 0.0201325
[Epoch 104] ogbg-moltox21: 0.679334 val loss: 1.398099
[Epoch 104] ogbg-moltox21: 0.639317 test loss: 1.188773
[Epoch 105; Iter    14/  209] train: loss: 0.0083872
[Epoch 105; Iter    44/  209] train: loss: 0.0061509
[Epoch 105; Iter    74/  209] train: loss: 0.0138417
[Epoch 105; Iter   104/  209] train: loss: 0.0059846
[Epoch 105; Iter   134/  209] train: loss: 0.0044913
[Epoch 105; Iter   164/  209] train: loss: 0.0289955
[Epoch 105; Iter   194/  209] train: loss: 0.0042441
[Epoch 105] ogbg-moltox21: 0.675902 val loss: 1.415022
[Epoch 105] ogbg-moltox21: 0.636544 test loss: 1.196214
[Epoch 106; Iter    15/  209] train: loss: 0.0143696
[Epoch 106; Iter    45/  209] train: loss: 0.0028289
[Epoch 106; Iter    75/  209] train: loss: 0.0146554
[Epoch 106; Iter   105/  209] train: loss: 0.0091227
[Epoch 106; Iter   135/  209] train: loss: 0.0092366
[Epoch 106; Iter   165/  209] train: loss: 0.0034066
[Epoch 106; Iter   195/  209] train: loss: 0.0050695
[Epoch 106] ogbg-moltox21: 0.674044 val loss: 1.440067
[Epoch 106] ogbg-moltox21: 0.640019 test loss: 1.237469
[Epoch 107; Iter    16/  209] train: loss: 0.0112733
[Epoch 107; Iter    46/  209] train: loss: 0.0102577
[Epoch 107; Iter    76/  209] train: loss: 0.0054378
[Epoch 107; Iter   106/  209] train: loss: 0.0033947
[Epoch 107; Iter   136/  209] train: loss: 0.0044526
[Epoch 107; Iter   166/  209] train: loss: 0.0162417
[Epoch 107; Iter   196/  209] train: loss: 0.0097600
[Epoch 107] ogbg-moltox21: 0.673875 val loss: 1.723115
[Epoch 107] ogbg-moltox21: 0.639842 test loss: 1.163487
[Epoch 108; Iter    17/  209] train: loss: 0.0066395
[Epoch 108; Iter    47/  209] train: loss: 0.0052043
[Epoch 108; Iter    77/  209] train: loss: 0.0036443
[Epoch 108; Iter   107/  209] train: loss: 0.0095375
[Epoch 108; Iter   137/  209] train: loss: 0.0350094
[Epoch 108; Iter   167/  209] train: loss: 0.0113845
[Epoch 108; Iter   197/  209] train: loss: 0.0164638
[Epoch 108] ogbg-moltox21: 0.672100 val loss: 1.389170
[Epoch 108] ogbg-moltox21: 0.636294 test loss: 1.262723
[Epoch 109; Iter    18/  209] train: loss: 0.0050661
[Epoch 109; Iter    48/  209] train: loss: 0.0105361
[Epoch 109; Iter    78/  209] train: loss: 0.0081955
[Epoch 109; Iter   108/  209] train: loss: 0.0079282
[Epoch 109; Iter   138/  209] train: loss: 0.0072397
[Epoch 109; Iter   168/  209] train: loss: 0.0100679
[Epoch 109; Iter   198/  209] train: loss: 0.0101637
[Epoch 109] ogbg-moltox21: 0.677866 val loss: 1.155916
[Epoch 109] ogbg-moltox21: 0.638465 test loss: 1.219870
[Epoch 110; Iter    19/  209] train: loss: 0.0045757
[Epoch 110; Iter    49/  209] train: loss: 0.0039624
[Epoch 110; Iter    79/  209] train: loss: 0.0102708
[Epoch 110; Iter   109/  209] train: loss: 0.0074528
[Epoch 110; Iter   139/  209] train: loss: 0.0074903
[Epoch 110; Iter   169/  209] train: loss: 0.0060958
[Epoch 110; Iter   199/  209] train: loss: 0.0060835
[Epoch 110] ogbg-moltox21: 0.675061 val loss: 1.117364
[Epoch 110] ogbg-moltox21: 0.634934 test loss: 1.258438
[Epoch 111; Iter    20/  209] train: loss: 0.0207582
[Epoch 111; Iter    50/  209] train: loss: 0.0114803
[Epoch 111; Iter    80/  209] train: loss: 0.0037533
[Epoch 111; Iter   110/  209] train: loss: 0.0085508
[Epoch 111; Iter   140/  209] train: loss: 0.0145806
[Epoch 111; Iter   170/  209] train: loss: 0.0057075
[Epoch 111; Iter   200/  209] train: loss: 0.0084616
[Epoch 111] ogbg-moltox21: 0.678252 val loss: 1.437947
[Epoch 111] ogbg-moltox21: 0.641841 test loss: 1.275948
[Epoch 112; Iter    21/  209] train: loss: 0.0036535
[Epoch 112; Iter    51/  209] train: loss: 0.0095846
[Epoch 112; Iter    81/  209] train: loss: 0.0070292
[Epoch 112; Iter   111/  209] train: loss: 0.0071182
[Epoch 112; Iter   141/  209] train: loss: 0.0089133
[Epoch 112; Iter   171/  209] train: loss: 0.0174125
[Epoch 112; Iter   201/  209] train: loss: 0.0085216
[Epoch 112] ogbg-moltox21: 0.675322 val loss: 1.698612
[Epoch 112] ogbg-moltox21: 0.636946 test loss: 1.217463
[Epoch 113; Iter    22/  209] train: loss: 0.0078757
[Epoch 113; Iter    52/  209] train: loss: 0.0230909
[Epoch 113; Iter    82/  209] train: loss: 0.0050277
[Epoch 113; Iter   112/  209] train: loss: 0.0101293
[Epoch 113; Iter   142/  209] train: loss: 0.0152109
[Epoch 113; Iter   172/  209] train: loss: 0.0114217
[Epoch 113; Iter   202/  209] train: loss: 0.0036564
[Epoch 113] ogbg-moltox21: 0.666263 val loss: 1.701841
[Epoch 113] ogbg-moltox21: 0.628842 test loss: 1.266374
[Epoch 114; Iter    23/  209] train: loss: 0.0042793
[Epoch 114; Iter    53/  209] train: loss: 0.0036659
[Epoch 114; Iter    83/  209] train: loss: 0.0101252
[Epoch 114; Iter   113/  209] train: loss: 0.0073958
[Epoch 114; Iter   143/  209] train: loss: 0.0041671
[Epoch 114; Iter   173/  209] train: loss: 0.0045838
[Epoch 114; Iter   203/  209] train: loss: 0.0069679
[Epoch 114] ogbg-moltox21: 0.669496 val loss: 1.492096
[Epoch 114] ogbg-moltox21: 0.632180 test loss: 1.273390
[Epoch 115; Iter    24/  209] train: loss: 0.0028852
[Epoch 115; Iter    54/  209] train: loss: 0.0046918
[Epoch 115; Iter    84/  209] train: loss: 0.0040448
[Epoch 115; Iter   114/  209] train: loss: 0.0119594
[Epoch 115; Iter   144/  209] train: loss: 0.0063202
[Epoch 115; Iter   174/  209] train: loss: 0.0097836
[Epoch 115; Iter   204/  209] train: loss: 0.0075885
[Epoch 115] ogbg-moltox21: 0.674119 val loss: 1.858381
[Epoch 115] ogbg-moltox21: 0.637855 test loss: 1.300288
[Epoch 116; Iter    25/  209] train: loss: 0.0122415
[Epoch 116; Iter    55/  209] train: loss: 0.0055878
[Epoch 116; Iter    85/  209] train: loss: 0.0157712
[Epoch 116; Iter   115/  209] train: loss: 0.0116374
[Epoch 99; Iter   128/  209] train: loss: 0.0082289
[Epoch 99; Iter   158/  209] train: loss: 0.0038990
[Epoch 99; Iter   188/  209] train: loss: 0.0107982
[Epoch 99] ogbg-moltox21: 0.724134 val loss: 0.783718
[Epoch 99] ogbg-moltox21: 0.691656 test loss: 0.849272
[Epoch 100; Iter     9/  209] train: loss: 0.0131682
[Epoch 100; Iter    39/  209] train: loss: 0.0061902
[Epoch 100; Iter    69/  209] train: loss: 0.0077054
[Epoch 100; Iter    99/  209] train: loss: 0.0052130
[Epoch 100; Iter   129/  209] train: loss: 0.0082936
[Epoch 100; Iter   159/  209] train: loss: 0.0064594
[Epoch 100; Iter   189/  209] train: loss: 0.0072599
[Epoch 100] ogbg-moltox21: 0.716974 val loss: 0.800774
[Epoch 100] ogbg-moltox21: 0.689753 test loss: 0.860445
[Epoch 101; Iter    10/  209] train: loss: 0.0100983
[Epoch 101; Iter    40/  209] train: loss: 0.0117548
[Epoch 101; Iter    70/  209] train: loss: 0.0050255
[Epoch 101; Iter   100/  209] train: loss: 0.0031332
[Epoch 101; Iter   130/  209] train: loss: 0.0038235
[Epoch 101; Iter   160/  209] train: loss: 0.0062493
[Epoch 101; Iter   190/  209] train: loss: 0.0094131
[Epoch 101] ogbg-moltox21: 0.720060 val loss: 0.799489
[Epoch 101] ogbg-moltox21: 0.700799 test loss: 0.845101
[Epoch 102; Iter    11/  209] train: loss: 0.0021572
[Epoch 102; Iter    41/  209] train: loss: 0.0034092
[Epoch 102; Iter    71/  209] train: loss: 0.0105118
[Epoch 102; Iter   101/  209] train: loss: 0.0031382
[Epoch 102; Iter   131/  209] train: loss: 0.0216818
[Epoch 102; Iter   161/  209] train: loss: 0.0148767
[Epoch 102; Iter   191/  209] train: loss: 0.0033172
[Epoch 102] ogbg-moltox21: 0.721604 val loss: 0.812917
[Epoch 102] ogbg-moltox21: 0.692773 test loss: 1.084451
[Epoch 103; Iter    12/  209] train: loss: 0.0043589
[Epoch 103; Iter    42/  209] train: loss: 0.0025146
[Epoch 103; Iter    72/  209] train: loss: 0.0060591
[Epoch 103; Iter   102/  209] train: loss: 0.0019253
[Epoch 103; Iter   132/  209] train: loss: 0.0085765
[Epoch 103; Iter   162/  209] train: loss: 0.0046720
[Epoch 103; Iter   192/  209] train: loss: 0.0080956
[Epoch 103] ogbg-moltox21: 0.718956 val loss: 0.808871
[Epoch 103] ogbg-moltox21: 0.696885 test loss: 0.868847
[Epoch 104; Iter    13/  209] train: loss: 0.0043113
[Epoch 104; Iter    43/  209] train: loss: 0.0082384
[Epoch 104; Iter    73/  209] train: loss: 0.0031519
[Epoch 104; Iter   103/  209] train: loss: 0.0035075
[Epoch 104; Iter   133/  209] train: loss: 0.0058938
[Epoch 104; Iter   163/  209] train: loss: 0.0033824
[Epoch 104; Iter   193/  209] train: loss: 0.0028306
[Epoch 104] ogbg-moltox21: 0.718997 val loss: 0.819214
[Epoch 104] ogbg-moltox21: 0.694437 test loss: 0.879599
[Epoch 105; Iter    14/  209] train: loss: 0.0157904
[Epoch 105; Iter    44/  209] train: loss: 0.0015967
[Epoch 105; Iter    74/  209] train: loss: 0.0137923
[Epoch 105; Iter   104/  209] train: loss: 0.0024447
[Epoch 105; Iter   134/  209] train: loss: 0.0039117
[Epoch 105; Iter   164/  209] train: loss: 0.0014094
[Epoch 105; Iter   194/  209] train: loss: 0.0170168
[Epoch 105] ogbg-moltox21: 0.718560 val loss: 0.819813
[Epoch 105] ogbg-moltox21: 0.691248 test loss: 0.883395
[Epoch 106; Iter    15/  209] train: loss: 0.0066248
[Epoch 106; Iter    45/  209] train: loss: 0.0039996
[Epoch 106; Iter    75/  209] train: loss: 0.0025334
[Epoch 106; Iter   105/  209] train: loss: 0.0110464
[Epoch 106; Iter   135/  209] train: loss: 0.0029227
[Epoch 106; Iter   165/  209] train: loss: 0.0072782
[Epoch 106; Iter   195/  209] train: loss: 0.0008858
[Epoch 106] ogbg-moltox21: 0.720424 val loss: 0.820694
[Epoch 106] ogbg-moltox21: 0.691992 test loss: 0.885378
[Epoch 107; Iter    16/  209] train: loss: 0.0058888
[Epoch 107; Iter    46/  209] train: loss: 0.0047769
[Epoch 107; Iter    76/  209] train: loss: 0.0009454
[Epoch 107; Iter   106/  209] train: loss: 0.0092389
[Epoch 107; Iter   136/  209] train: loss: 0.0060318
[Epoch 107; Iter   166/  209] train: loss: 0.0034200
[Epoch 107; Iter   196/  209] train: loss: 0.0115848
[Epoch 107] ogbg-moltox21: 0.720660 val loss: 0.817442
[Epoch 107] ogbg-moltox21: 0.687532 test loss: 1.269594
[Epoch 108; Iter    17/  209] train: loss: 0.0050573
[Epoch 108; Iter    47/  209] train: loss: 0.0033676
[Epoch 108; Iter    77/  209] train: loss: 0.0107045
[Epoch 108; Iter   107/  209] train: loss: 0.0122766
[Epoch 108; Iter   137/  209] train: loss: 0.0061222
[Epoch 108; Iter   167/  209] train: loss: 0.0049060
[Epoch 108; Iter   197/  209] train: loss: 0.0024589
[Epoch 108] ogbg-moltox21: 0.718938 val loss: 0.846773
[Epoch 108] ogbg-moltox21: 0.686445 test loss: 0.920857
[Epoch 109; Iter    18/  209] train: loss: 0.0036997
[Epoch 109; Iter    48/  209] train: loss: 0.0101349
[Epoch 109; Iter    78/  209] train: loss: 0.0116169
[Epoch 109; Iter   108/  209] train: loss: 0.0032752
[Epoch 109; Iter   138/  209] train: loss: 0.0028877
[Epoch 109; Iter   168/  209] train: loss: 0.0018596
[Epoch 109; Iter   198/  209] train: loss: 0.0021604
[Epoch 109] ogbg-moltox21: 0.714577 val loss: 0.866181
[Epoch 109] ogbg-moltox21: 0.682287 test loss: 1.038366
[Epoch 110; Iter    19/  209] train: loss: 0.0044198
[Epoch 110; Iter    49/  209] train: loss: 0.0071508
[Epoch 110; Iter    79/  209] train: loss: 0.0027467
[Epoch 110; Iter   109/  209] train: loss: 0.0036506
[Epoch 110; Iter   139/  209] train: loss: 0.0100594
[Epoch 110; Iter   169/  209] train: loss: 0.0026143
[Epoch 110; Iter   199/  209] train: loss: 0.0098724
[Epoch 110] ogbg-moltox21: 0.720289 val loss: 0.841006
[Epoch 110] ogbg-moltox21: 0.682944 test loss: 0.945359
[Epoch 111; Iter    20/  209] train: loss: 0.0029475
[Epoch 111; Iter    50/  209] train: loss: 0.0028954
[Epoch 111; Iter    80/  209] train: loss: 0.0026674
[Epoch 111; Iter   110/  209] train: loss: 0.0107252
[Epoch 111; Iter   140/  209] train: loss: 0.0041535
[Epoch 111; Iter   170/  209] train: loss: 0.0049130
[Epoch 111; Iter   200/  209] train: loss: 0.0036382
[Epoch 111] ogbg-moltox21: 0.719477 val loss: 0.839903
[Epoch 111] ogbg-moltox21: 0.685491 test loss: 0.909674
[Epoch 112; Iter    21/  209] train: loss: 0.0067981
[Epoch 112; Iter    51/  209] train: loss: 0.0044020
[Epoch 112; Iter    81/  209] train: loss: 0.0023299
[Epoch 112; Iter   111/  209] train: loss: 0.0088814
[Epoch 112; Iter   141/  209] train: loss: 0.0054875
[Epoch 112; Iter   171/  209] train: loss: 0.0032309
[Epoch 112; Iter   201/  209] train: loss: 0.0034325
[Epoch 112] ogbg-moltox21: 0.719477 val loss: 0.823686
[Epoch 112] ogbg-moltox21: 0.682582 test loss: 0.900059
[Epoch 113; Iter    22/  209] train: loss: 0.0251492
[Epoch 113; Iter    52/  209] train: loss: 0.0011547
[Epoch 113; Iter    82/  209] train: loss: 0.0026090
[Epoch 113; Iter   112/  209] train: loss: 0.0044310
[Epoch 113; Iter   142/  209] train: loss: 0.0168683
[Epoch 113; Iter   172/  209] train: loss: 0.0008900
[Epoch 113; Iter   202/  209] train: loss: 0.0060100
[Epoch 113] ogbg-moltox21: 0.720456 val loss: 0.828485
[Epoch 113] ogbg-moltox21: 0.681021 test loss: 0.909835
[Epoch 114; Iter    23/  209] train: loss: 0.0314158
[Epoch 114; Iter    53/  209] train: loss: 0.0132497
[Epoch 114; Iter    83/  209] train: loss: 0.0034666
[Epoch 114; Iter   113/  209] train: loss: 0.0016920
[Epoch 114; Iter   143/  209] train: loss: 0.0017829
[Epoch 114; Iter   173/  209] train: loss: 0.0014934
[Epoch 114; Iter   203/  209] train: loss: 0.0013411
[Epoch 114] ogbg-moltox21: 0.714957 val loss: 0.845209
[Epoch 114] ogbg-moltox21: 0.683039 test loss: 0.916931
[Epoch 115; Iter    24/  209] train: loss: 0.0035912
[Epoch 115; Iter    54/  209] train: loss: 0.0037612
[Epoch 115; Iter    84/  209] train: loss: 0.0089676
[Epoch 115; Iter   114/  209] train: loss: 0.0009096
[Epoch 115; Iter   144/  209] train: loss: 0.0026444
[Epoch 115; Iter   174/  209] train: loss: 0.0016985
[Epoch 115; Iter   204/  209] train: loss: 0.0012586
[Epoch 115] ogbg-moltox21: 0.717008 val loss: 0.858410
[Epoch 115] ogbg-moltox21: 0.687649 test loss: 0.924410
[Epoch 116; Iter    25/  209] train: loss: 0.0049622
[Epoch 116; Iter    55/  209] train: loss: 0.0013366
[Epoch 116; Iter    85/  209] train: loss: 0.0048939
[Epoch 116; Iter   115/  209] train: loss: 0.0027069
[Epoch 99; Iter   128/  209] train: loss: 0.0026065
[Epoch 99; Iter   158/  209] train: loss: 0.0084051
[Epoch 99; Iter   188/  209] train: loss: 0.0068657
[Epoch 99] ogbg-moltox21: 0.733444 val loss: 1.290037
[Epoch 99] ogbg-moltox21: 0.656990 test loss: 1.106426
[Epoch 100; Iter     9/  209] train: loss: 0.0082360
[Epoch 100; Iter    39/  209] train: loss: 0.0140722
[Epoch 100; Iter    69/  209] train: loss: 0.0047696
[Epoch 100; Iter    99/  209] train: loss: 0.0264344
[Epoch 100; Iter   129/  209] train: loss: 0.0170919
[Epoch 100; Iter   159/  209] train: loss: 0.0053085
[Epoch 100; Iter   189/  209] train: loss: 0.0059814
[Epoch 100] ogbg-moltox21: 0.729495 val loss: 1.251806
[Epoch 100] ogbg-moltox21: 0.660437 test loss: 1.339255
[Epoch 101; Iter    10/  209] train: loss: 0.0041258
[Epoch 101; Iter    40/  209] train: loss: 0.0014877
[Epoch 101; Iter    70/  209] train: loss: 0.0058929
[Epoch 101; Iter   100/  209] train: loss: 0.0025616
[Epoch 101; Iter   130/  209] train: loss: 0.0024154
[Epoch 101; Iter   160/  209] train: loss: 0.0052427
[Epoch 101; Iter   190/  209] train: loss: 0.0047945
[Epoch 101] ogbg-moltox21: 0.717829 val loss: 1.129023
[Epoch 101] ogbg-moltox21: 0.661492 test loss: 1.130966
[Epoch 102; Iter    11/  209] train: loss: 0.0142982
[Epoch 102; Iter    41/  209] train: loss: 0.0044153
[Epoch 102; Iter    71/  209] train: loss: 0.0029947
[Epoch 102; Iter   101/  209] train: loss: 0.0069205
[Epoch 102; Iter   131/  209] train: loss: 0.0047368
[Epoch 102; Iter   161/  209] train: loss: 0.0026041
[Epoch 102; Iter   191/  209] train: loss: 0.0041062
[Epoch 102] ogbg-moltox21: 0.716681 val loss: 1.449168
[Epoch 102] ogbg-moltox21: 0.658294 test loss: 1.124741
[Epoch 103; Iter    12/  209] train: loss: 0.0054388
[Epoch 103; Iter    42/  209] train: loss: 0.0015361
[Epoch 103; Iter    72/  209] train: loss: 0.0017942
[Epoch 103; Iter   102/  209] train: loss: 0.0072453
[Epoch 103; Iter   132/  209] train: loss: 0.0050579
[Epoch 103; Iter   162/  209] train: loss: 0.0534931
[Epoch 103; Iter   192/  209] train: loss: 0.0029196
[Epoch 103] ogbg-moltox21: 0.717571 val loss: 0.939830
[Epoch 103] ogbg-moltox21: 0.656859 test loss: 1.066299
[Epoch 104; Iter    13/  209] train: loss: 0.0052237
[Epoch 104; Iter    43/  209] train: loss: 0.0060158
[Epoch 104; Iter    73/  209] train: loss: 0.0072102
[Epoch 104; Iter   103/  209] train: loss: 0.0099694
[Epoch 104; Iter   133/  209] train: loss: 0.0028894
[Epoch 104; Iter   163/  209] train: loss: 0.0081282
[Epoch 104; Iter   193/  209] train: loss: 0.0082066
[Epoch 104] ogbg-moltox21: 0.730512 val loss: 1.214482
[Epoch 104] ogbg-moltox21: 0.662725 test loss: 1.224377
[Epoch 105; Iter    14/  209] train: loss: 0.0049593
[Epoch 105; Iter    44/  209] train: loss: 0.0015561
[Epoch 105; Iter    74/  209] train: loss: 0.0035205
[Epoch 105; Iter   104/  209] train: loss: 0.0095098
[Epoch 105; Iter   134/  209] train: loss: 0.0051011
[Epoch 105; Iter   164/  209] train: loss: 0.0021538
[Epoch 105; Iter   194/  209] train: loss: 0.0025827
[Epoch 105] ogbg-moltox21: 0.723016 val loss: 1.392310
[Epoch 105] ogbg-moltox21: 0.653071 test loss: 1.101058
[Epoch 106; Iter    15/  209] train: loss: 0.0026102
[Epoch 106; Iter    45/  209] train: loss: 0.0042959
[Epoch 106; Iter    75/  209] train: loss: 0.0089255
[Epoch 106; Iter   105/  209] train: loss: 0.0077317
[Epoch 106; Iter   135/  209] train: loss: 0.0071399
[Epoch 106; Iter   165/  209] train: loss: 0.0063774
[Epoch 106; Iter   195/  209] train: loss: 0.0027671
[Epoch 106] ogbg-moltox21: 0.727109 val loss: 1.204842
[Epoch 106] ogbg-moltox21: 0.662421 test loss: 1.124212
[Epoch 107; Iter    16/  209] train: loss: 0.0108734
[Epoch 107; Iter    46/  209] train: loss: 0.0023665
[Epoch 107; Iter    76/  209] train: loss: 0.0356402
[Epoch 107; Iter   106/  209] train: loss: 0.0011682
[Epoch 107; Iter   136/  209] train: loss: 0.0105669
[Epoch 107; Iter   166/  209] train: loss: 0.0084832
[Epoch 107; Iter   196/  209] train: loss: 0.0061244
[Epoch 107] ogbg-moltox21: 0.721241 val loss: 1.132860
[Epoch 107] ogbg-moltox21: 0.654807 test loss: 1.080125
[Epoch 108; Iter    17/  209] train: loss: 0.0075772
[Epoch 108; Iter    47/  209] train: loss: 0.0079200
[Epoch 108; Iter    77/  209] train: loss: 0.0039494
[Epoch 108; Iter   107/  209] train: loss: 0.0096241
[Epoch 108; Iter   137/  209] train: loss: 0.0125506
[Epoch 108; Iter   167/  209] train: loss: 0.0148416
[Epoch 108; Iter   197/  209] train: loss: 0.0096501
[Epoch 108] ogbg-moltox21: 0.719018 val loss: 1.131054
[Epoch 108] ogbg-moltox21: 0.654806 test loss: 1.105755
[Epoch 109; Iter    18/  209] train: loss: 0.0018188
[Epoch 109; Iter    48/  209] train: loss: 0.0010096
[Epoch 109; Iter    78/  209] train: loss: 0.0052430
[Epoch 109; Iter   108/  209] train: loss: 0.0037256
[Epoch 109; Iter   138/  209] train: loss: 0.0055531
[Epoch 109; Iter   168/  209] train: loss: 0.0042575
[Epoch 109; Iter   198/  209] train: loss: 0.0052027
[Epoch 109] ogbg-moltox21: 0.720587 val loss: 1.580721
[Epoch 109] ogbg-moltox21: 0.658678 test loss: 1.337192
[Epoch 110; Iter    19/  209] train: loss: 0.0067143
[Epoch 110; Iter    49/  209] train: loss: 0.0019122
[Epoch 110; Iter    79/  209] train: loss: 0.0020188
[Epoch 110; Iter   109/  209] train: loss: 0.0076739
[Epoch 110; Iter   139/  209] train: loss: 0.0055707
[Epoch 110; Iter   169/  209] train: loss: 0.0168431
[Epoch 110; Iter   199/  209] train: loss: 0.0144347
[Epoch 110] ogbg-moltox21: 0.726180 val loss: 1.170603
[Epoch 110] ogbg-moltox21: 0.656446 test loss: 1.141799
[Epoch 111; Iter    20/  209] train: loss: 0.0082453
[Epoch 111; Iter    50/  209] train: loss: 0.0031019
[Epoch 111; Iter    80/  209] train: loss: 0.0028341
[Epoch 111; Iter   110/  209] train: loss: 0.0023412
[Epoch 111; Iter   140/  209] train: loss: 0.0017724
[Epoch 111; Iter   170/  209] train: loss: 0.0019691
[Epoch 111; Iter   200/  209] train: loss: 0.0133748
[Epoch 111] ogbg-moltox21: 0.720541 val loss: 1.307452
[Epoch 111] ogbg-moltox21: 0.652235 test loss: 1.106786
[Epoch 112; Iter    21/  209] train: loss: 0.0020116
[Epoch 112; Iter    51/  209] train: loss: 0.0039815
[Epoch 112; Iter    81/  209] train: loss: 0.0020709
[Epoch 112; Iter   111/  209] train: loss: 0.0046288
[Epoch 112; Iter   141/  209] train: loss: 0.0029397
[Epoch 112; Iter   171/  209] train: loss: 0.0081700
[Epoch 112; Iter   201/  209] train: loss: 0.0064298
[Epoch 112] ogbg-moltox21: 0.725987 val loss: 1.306213
[Epoch 112] ogbg-moltox21: 0.659200 test loss: 1.139128
[Epoch 113; Iter    22/  209] train: loss: 0.0033638
[Epoch 113; Iter    52/  209] train: loss: 0.0010420
[Epoch 113; Iter    82/  209] train: loss: 0.0021598
[Epoch 113; Iter   112/  209] train: loss: 0.0012068
[Epoch 113; Iter   142/  209] train: loss: 0.0035050
[Epoch 113; Iter   172/  209] train: loss: 0.0099342
[Epoch 113; Iter   202/  209] train: loss: 0.0034563
[Epoch 113] ogbg-moltox21: 0.724807 val loss: 1.048739
[Epoch 113] ogbg-moltox21: 0.658695 test loss: 1.074356
[Epoch 114; Iter    23/  209] train: loss: 0.0013703
[Epoch 114; Iter    53/  209] train: loss: 0.0081670
[Epoch 114; Iter    83/  209] train: loss: 0.0024662
[Epoch 114; Iter   113/  209] train: loss: 0.0032479
[Epoch 114; Iter   143/  209] train: loss: 0.0017409
[Epoch 114; Iter   173/  209] train: loss: 0.0053151
[Epoch 114; Iter   203/  209] train: loss: 0.0020834
[Epoch 114] ogbg-moltox21: 0.725866 val loss: 1.469909
[Epoch 114] ogbg-moltox21: 0.659523 test loss: 1.189349
[Epoch 115; Iter    24/  209] train: loss: 0.0023010
[Epoch 115; Iter    54/  209] train: loss: 0.0013573
[Epoch 115; Iter    84/  209] train: loss: 0.0033917
[Epoch 115; Iter   114/  209] train: loss: 0.0031362
[Epoch 115; Iter   144/  209] train: loss: 0.0012355
[Epoch 115; Iter   174/  209] train: loss: 0.0083438
[Epoch 115; Iter   204/  209] train: loss: 0.0118673
[Epoch 115] ogbg-moltox21: 0.724809 val loss: 1.332188
[Epoch 115] ogbg-moltox21: 0.658174 test loss: 1.118715
[Epoch 116; Iter    25/  209] train: loss: 0.0048116
[Epoch 116; Iter    55/  209] train: loss: 0.0132544
[Epoch 116; Iter    85/  209] train: loss: 0.0175666
[Epoch 116; Iter   115/  209] train: loss: 0.0013805
[Epoch 99; Iter   128/  209] train: loss: 0.0130415
[Epoch 99; Iter   158/  209] train: loss: 0.0050401
[Epoch 99; Iter   188/  209] train: loss: 0.0055693
[Epoch 99] ogbg-moltox21: 0.726031 val loss: 0.705959
[Epoch 99] ogbg-moltox21: 0.674949 test loss: 0.783769
[Epoch 100; Iter     9/  209] train: loss: 0.0063242
[Epoch 100; Iter    39/  209] train: loss: 0.0076508
[Epoch 100; Iter    69/  209] train: loss: 0.0099446
[Epoch 100; Iter    99/  209] train: loss: 0.0069575
[Epoch 100; Iter   129/  209] train: loss: 0.0056309
[Epoch 100; Iter   159/  209] train: loss: 0.0057711
[Epoch 100; Iter   189/  209] train: loss: 0.0111893
[Epoch 100] ogbg-moltox21: 0.722407 val loss: 0.679591
[Epoch 100] ogbg-moltox21: 0.678190 test loss: 0.761953
[Epoch 101; Iter    10/  209] train: loss: 0.0410181
[Epoch 101; Iter    40/  209] train: loss: 0.0125404
[Epoch 101; Iter    70/  209] train: loss: 0.0095115
[Epoch 101; Iter   100/  209] train: loss: 0.0195789
[Epoch 101; Iter   130/  209] train: loss: 0.0074213
[Epoch 101; Iter   160/  209] train: loss: 0.0114976
[Epoch 101; Iter   190/  209] train: loss: 0.0102022
[Epoch 101] ogbg-moltox21: 0.729188 val loss: 0.675424
[Epoch 101] ogbg-moltox21: 0.690071 test loss: 0.759439
[Epoch 102; Iter    11/  209] train: loss: 0.0193063
[Epoch 102; Iter    41/  209] train: loss: 0.0075695
[Epoch 102; Iter    71/  209] train: loss: 0.0179952
[Epoch 102; Iter   101/  209] train: loss: 0.0202269
[Epoch 102; Iter   131/  209] train: loss: 0.0055258
[Epoch 102; Iter   161/  209] train: loss: 0.0195092
[Epoch 102; Iter   191/  209] train: loss: 0.0044220
[Epoch 102] ogbg-moltox21: 0.719805 val loss: 0.690135
[Epoch 102] ogbg-moltox21: 0.673660 test loss: 0.784104
[Epoch 103; Iter    12/  209] train: loss: 0.0081916
[Epoch 103; Iter    42/  209] train: loss: 0.0160863
[Epoch 103; Iter    72/  209] train: loss: 0.0051926
[Epoch 103; Iter   102/  209] train: loss: 0.0045295
[Epoch 103; Iter   132/  209] train: loss: 0.0082003
[Epoch 103; Iter   162/  209] train: loss: 0.0136673
[Epoch 103; Iter   192/  209] train: loss: 0.0072076
[Epoch 103] ogbg-moltox21: 0.720952 val loss: 0.707324
[Epoch 103] ogbg-moltox21: 0.676658 test loss: 0.794633
[Epoch 104; Iter    13/  209] train: loss: 0.0113415
[Epoch 104; Iter    43/  209] train: loss: 0.0050075
[Epoch 104; Iter    73/  209] train: loss: 0.0100274
[Epoch 104; Iter   103/  209] train: loss: 0.0055258
[Epoch 104; Iter   133/  209] train: loss: 0.0073093
[Epoch 104; Iter   163/  209] train: loss: 0.0255519
[Epoch 104; Iter   193/  209] train: loss: 0.0129920
[Epoch 104] ogbg-moltox21: 0.721923 val loss: 0.712388
[Epoch 104] ogbg-moltox21: 0.680113 test loss: 0.798739
[Epoch 105; Iter    14/  209] train: loss: 0.0069487
[Epoch 105; Iter    44/  209] train: loss: 0.0060547
[Epoch 105; Iter    74/  209] train: loss: 0.0084084
[Epoch 105; Iter   104/  209] train: loss: 0.0046345
[Epoch 105; Iter   134/  209] train: loss: 0.0078747
[Epoch 105; Iter   164/  209] train: loss: 0.0272979
[Epoch 105; Iter   194/  209] train: loss: 0.0044525
[Epoch 105] ogbg-moltox21: 0.735376 val loss: 0.701962
[Epoch 105] ogbg-moltox21: 0.680606 test loss: 0.810639
[Epoch 106; Iter    15/  209] train: loss: 0.0126920
[Epoch 106; Iter    45/  209] train: loss: 0.0025014
[Epoch 106; Iter    75/  209] train: loss: 0.0061414
[Epoch 106; Iter   105/  209] train: loss: 0.0044112
[Epoch 106; Iter   135/  209] train: loss: 0.0134575
[Epoch 106; Iter   165/  209] train: loss: 0.0141657
[Epoch 106; Iter   195/  209] train: loss: 0.0079758
[Epoch 106] ogbg-moltox21: 0.733887 val loss: 0.738220
[Epoch 106] ogbg-moltox21: 0.681465 test loss: 0.847216
[Epoch 107; Iter    16/  209] train: loss: 0.0146637
[Epoch 107; Iter    46/  209] train: loss: 0.0100357
[Epoch 107; Iter    76/  209] train: loss: 0.0097297
[Epoch 107; Iter   106/  209] train: loss: 0.0141392
[Epoch 107; Iter   136/  209] train: loss: 0.0126272
[Epoch 107; Iter   166/  209] train: loss: 0.0048612
[Epoch 107; Iter   196/  209] train: loss: 0.0071505
[Epoch 107] ogbg-moltox21: 0.734969 val loss: 0.701997
[Epoch 107] ogbg-moltox21: 0.675306 test loss: 0.802611
[Epoch 108; Iter    17/  209] train: loss: 0.0073490
[Epoch 108; Iter    47/  209] train: loss: 0.0032872
[Epoch 108; Iter    77/  209] train: loss: 0.0034779
[Epoch 108; Iter   107/  209] train: loss: 0.0071106
[Epoch 108; Iter   137/  209] train: loss: 0.0140518
[Epoch 108; Iter   167/  209] train: loss: 0.0111882
[Epoch 108; Iter   197/  209] train: loss: 0.0230108
[Epoch 108] ogbg-moltox21: 0.726276 val loss: 0.738495
[Epoch 108] ogbg-moltox21: 0.675867 test loss: 0.818635
[Epoch 109; Iter    18/  209] train: loss: 0.0100415
[Epoch 109; Iter    48/  209] train: loss: 0.0069781
[Epoch 109; Iter    78/  209] train: loss: 0.0039078
[Epoch 109; Iter   108/  209] train: loss: 0.0170944
[Epoch 109; Iter   138/  209] train: loss: 0.0102381
[Epoch 109; Iter   168/  209] train: loss: 0.0300051
[Epoch 109; Iter   198/  209] train: loss: 0.0139101
[Epoch 109] ogbg-moltox21: 0.735418 val loss: 0.703721
[Epoch 109] ogbg-moltox21: 0.679777 test loss: 0.794924
[Epoch 110; Iter    19/  209] train: loss: 0.0066781
[Epoch 110; Iter    49/  209] train: loss: 0.0061749
[Epoch 110; Iter    79/  209] train: loss: 0.0151147
[Epoch 110; Iter   109/  209] train: loss: 0.0142149
[Epoch 110; Iter   139/  209] train: loss: 0.0222296
[Epoch 110; Iter   169/  209] train: loss: 0.0160671
[Epoch 110; Iter   199/  209] train: loss: 0.0066776
[Epoch 110] ogbg-moltox21: 0.731082 val loss: 0.749483
[Epoch 110] ogbg-moltox21: 0.679003 test loss: 0.827094
[Epoch 111; Iter    20/  209] train: loss: 0.0111065
[Epoch 111; Iter    50/  209] train: loss: 0.0108346
[Epoch 111; Iter    80/  209] train: loss: 0.0082015
[Epoch 111; Iter   110/  209] train: loss: 0.0130348
[Epoch 111; Iter   140/  209] train: loss: 0.0174920
[Epoch 111; Iter   170/  209] train: loss: 0.0022320
[Epoch 111; Iter   200/  209] train: loss: 0.0040415
[Epoch 111] ogbg-moltox21: 0.724719 val loss: 0.742045
[Epoch 111] ogbg-moltox21: 0.685743 test loss: 0.817375
[Epoch 112; Iter    21/  209] train: loss: 0.0064839
[Epoch 112; Iter    51/  209] train: loss: 0.0091841
[Epoch 112; Iter    81/  209] train: loss: 0.0027341
[Epoch 112; Iter   111/  209] train: loss: 0.0082347
[Epoch 112; Iter   141/  209] train: loss: 0.0056388
[Epoch 112; Iter   171/  209] train: loss: 0.0197642
[Epoch 112; Iter   201/  209] train: loss: 0.0143894
[Epoch 112] ogbg-moltox21: 0.736141 val loss: 0.763803
[Epoch 112] ogbg-moltox21: 0.686291 test loss: 0.858617
[Epoch 113; Iter    22/  209] train: loss: 0.0059335
[Epoch 113; Iter    52/  209] train: loss: 0.0069738
[Epoch 113; Iter    82/  209] train: loss: 0.0137728
[Epoch 113; Iter   112/  209] train: loss: 0.0140817
[Epoch 113; Iter   142/  209] train: loss: 0.0111383
[Epoch 113; Iter   172/  209] train: loss: 0.0067403
[Epoch 113; Iter   202/  209] train: loss: 0.0069952
[Epoch 113] ogbg-moltox21: 0.721681 val loss: 0.769746
[Epoch 113] ogbg-moltox21: 0.684026 test loss: 0.849256
[Epoch 114; Iter    23/  209] train: loss: 0.0070467
[Epoch 114; Iter    53/  209] train: loss: 0.0179000
[Epoch 114; Iter    83/  209] train: loss: 0.0119462
[Epoch 114; Iter   113/  209] train: loss: 0.0032613
[Epoch 114; Iter   143/  209] train: loss: 0.0229480
[Epoch 114; Iter   173/  209] train: loss: 0.0077493
[Epoch 114; Iter   203/  209] train: loss: 0.0104537
[Epoch 114] ogbg-moltox21: 0.732428 val loss: 0.710061
[Epoch 114] ogbg-moltox21: 0.679691 test loss: 0.800422
[Epoch 115; Iter    24/  209] train: loss: 0.0065814
[Epoch 115; Iter    54/  209] train: loss: 0.0091878
[Epoch 115; Iter    84/  209] train: loss: 0.0064885
[Epoch 115; Iter   114/  209] train: loss: 0.0039980
[Epoch 115; Iter   144/  209] train: loss: 0.0069506
[Epoch 115; Iter   174/  209] train: loss: 0.0287709
[Epoch 115; Iter   204/  209] train: loss: 0.0036074
[Epoch 115] ogbg-moltox21: 0.728405 val loss: 0.755246
[Epoch 115] ogbg-moltox21: 0.682854 test loss: 0.847282
[Epoch 116; Iter    25/  209] train: loss: 0.0140392
[Epoch 116; Iter    55/  209] train: loss: 0.0043585
[Epoch 116; Iter    85/  209] train: loss: 0.0038214
[Epoch 116; Iter   115/  209] train: loss: 0.0059300
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0034321
[Epoch 116; Iter   175/  209] train: loss: 0.0018391
[Epoch 116; Iter   205/  209] train: loss: 0.0082445
[Epoch 116] ogbg-moltox21: 0.737207 val loss: 0.781354
[Epoch 116] ogbg-moltox21: 0.726745 test loss: 0.872068
[Epoch 117; Iter    26/  209] train: loss: 0.0162099
[Epoch 117; Iter    56/  209] train: loss: 0.0047464
[Epoch 117; Iter    86/  209] train: loss: 0.0094077
[Epoch 117; Iter   116/  209] train: loss: 0.0074719
[Epoch 117; Iter   146/  209] train: loss: 0.0073458
[Epoch 117; Iter   176/  209] train: loss: 0.0019847
[Epoch 117; Iter   206/  209] train: loss: 0.0025733
[Epoch 117] ogbg-moltox21: 0.738812 val loss: 0.789858
[Epoch 117] ogbg-moltox21: 0.726990 test loss: 0.859897
[Epoch 118; Iter    27/  209] train: loss: 0.0062330
[Epoch 118; Iter    57/  209] train: loss: 0.0041098
[Epoch 118; Iter    87/  209] train: loss: 0.0107186
[Epoch 118; Iter   117/  209] train: loss: 0.0035044
[Epoch 118; Iter   147/  209] train: loss: 0.0014700
[Epoch 118; Iter   177/  209] train: loss: 0.0087283
[Epoch 118; Iter   207/  209] train: loss: 0.0029585
[Epoch 118] ogbg-moltox21: 0.743940 val loss: 0.732986
[Epoch 118] ogbg-moltox21: 0.728188 test loss: 0.809666
[Epoch 119; Iter    28/  209] train: loss: 0.0040777
[Epoch 119; Iter    58/  209] train: loss: 0.0105568
[Epoch 119; Iter    88/  209] train: loss: 0.0053097
[Epoch 119; Iter   118/  209] train: loss: 0.0185020
[Epoch 119; Iter   148/  209] train: loss: 0.0078526
[Epoch 119; Iter   178/  209] train: loss: 0.0068633
[Epoch 119; Iter   208/  209] train: loss: 0.0033530
[Epoch 119] ogbg-moltox21: 0.740580 val loss: 0.733000
[Epoch 119] ogbg-moltox21: 0.724445 test loss: 0.819423
[Epoch 120; Iter    29/  209] train: loss: 0.0130140
[Epoch 120; Iter    59/  209] train: loss: 0.0017795
[Epoch 120; Iter    89/  209] train: loss: 0.0043389
[Epoch 120; Iter   119/  209] train: loss: 0.0018529
[Epoch 120; Iter   149/  209] train: loss: 0.0512681
[Epoch 120; Iter   179/  209] train: loss: 0.0050550
[Epoch 120; Iter   209/  209] train: loss: 0.0089891
[Epoch 120] ogbg-moltox21: 0.734335 val loss: 0.752642
[Epoch 120] ogbg-moltox21: 0.719055 test loss: 0.853245
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 24.
Statistics on  val_best_checkpoint
mean_pred: -3.227541208267212
std_pred: 2.3064892292022705
mean_targets: nan
std_targets: nan
prcauc: 0.37932365308024313
rocauc: 0.7802678855663313
ogbg-moltox21: 0.7802678855663313
OGBNanLabelBCEWithLogitsLoss: 0.26932924392598645
Statistics on  test
mean_pred: -3.117751359939575
std_pred: 3.86331844329834
mean_targets: nan
std_targets: nan
prcauc: 0.3082225067589197
rocauc: 0.7340633490847446
ogbg-moltox21: 0.7340633490847446
OGBNanLabelBCEWithLogitsLoss: 0.43628631973708115
Statistics on  train
mean_pred: -3.981328248977661
std_pred: 2.3150696754455566
mean_targets: nan
std_targets: nan
prcauc: 0.6258313855278818
rocauc: 0.9211252872011677
ogbg-moltox21: 0.9211252872011677
OGBNanLabelBCEWithLogitsLoss: 0.1358045511589381
[Epoch 116; Iter   145/  209] train: loss: 0.0352058
[Epoch 116; Iter   175/  209] train: loss: 0.0345854
[Epoch 116; Iter   205/  209] train: loss: 0.0194915
[Epoch 116] ogbg-moltox21: 0.763965 val loss: 0.641309
[Epoch 116] ogbg-moltox21: 0.734065 test loss: 0.684371
[Epoch 117; Iter    26/  209] train: loss: 0.0192206
[Epoch 117; Iter    56/  209] train: loss: 0.0633483
[Epoch 117; Iter    86/  209] train: loss: 0.0096375
[Epoch 117; Iter   116/  209] train: loss: 0.0151404
[Epoch 117; Iter   146/  209] train: loss: 0.0276282
[Epoch 117; Iter   176/  209] train: loss: 0.0241375
[Epoch 117; Iter   206/  209] train: loss: 0.0178630
[Epoch 117] ogbg-moltox21: 0.745614 val loss: 0.671217
[Epoch 117] ogbg-moltox21: 0.732217 test loss: 0.683047
[Epoch 118; Iter    27/  209] train: loss: 0.0154256
[Epoch 118; Iter    57/  209] train: loss: 0.0305636
[Epoch 118; Iter    87/  209] train: loss: 0.0336433
[Epoch 118; Iter   117/  209] train: loss: 0.0093225
[Epoch 118; Iter   147/  209] train: loss: 0.0186814
[Epoch 118; Iter   177/  209] train: loss: 0.0301910
[Epoch 118; Iter   207/  209] train: loss: 0.0220793
[Epoch 118] ogbg-moltox21: 0.726105 val loss: 0.689155
[Epoch 118] ogbg-moltox21: 0.720752 test loss: 0.701755
[Epoch 119; Iter    28/  209] train: loss: 0.0152649
[Epoch 119; Iter    58/  209] train: loss: 0.0213300
[Epoch 119; Iter    88/  209] train: loss: 0.0104911
[Epoch 119; Iter   118/  209] train: loss: 0.0163362
[Epoch 119; Iter   148/  209] train: loss: 0.0220373
[Epoch 119; Iter   178/  209] train: loss: 0.0152262
[Epoch 119; Iter   208/  209] train: loss: 0.0192611
[Epoch 119] ogbg-moltox21: 0.740950 val loss: 0.668883
[Epoch 119] ogbg-moltox21: 0.727694 test loss: 0.687553
[Epoch 120; Iter    29/  209] train: loss: 0.0185124
[Epoch 120; Iter    59/  209] train: loss: 0.0067639
[Epoch 120; Iter    89/  209] train: loss: 0.0225477
[Epoch 120; Iter   119/  209] train: loss: 0.0069402
[Epoch 120; Iter   149/  209] train: loss: 0.0256464
[Epoch 120; Iter   179/  209] train: loss: 0.0123780
[Epoch 120; Iter   209/  209] train: loss: 0.0494312
[Epoch 120] ogbg-moltox21: 0.744366 val loss: 0.674410
[Epoch 120] ogbg-moltox21: 0.726040 test loss: 0.706663
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 15.
Statistics on  val_best_checkpoint
mean_pred: -3.4726197719573975
std_pred: 1.6431723833084106
mean_targets: nan
std_targets: nan
prcauc: 0.3372081126357184
rocauc: 0.7929248718029588
ogbg-moltox21: 0.7929248718029588
OGBNanLabelBCEWithLogitsLoss: 0.2595759264572903
Statistics on  test
mean_pred: -3.4613053798675537
std_pred: 1.6615710258483887
mean_targets: nan
std_targets: nan
prcauc: 0.2859826236258142
rocauc: 0.73492432944734
ogbg-moltox21: 0.73492432944734
OGBNanLabelBCEWithLogitsLoss: 0.28284185296959347
Statistics on  train
mean_pred: -3.6303529739379883
std_pred: 1.4311195611953735
mean_targets: nan
std_targets: nan
prcauc: 0.40071626214480327
rocauc: 0.8620501325146427
ogbg-moltox21: 0.8620501325146427
OGBNanLabelBCEWithLogitsLoss: 0.18186338702172183
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0078799
[Epoch 116; Iter   175/  209] train: loss: 0.0027972
[Epoch 116; Iter   205/  209] train: loss: 0.0219314
[Epoch 116] ogbg-moltox21: 0.734243 val loss: 0.792042
[Epoch 116] ogbg-moltox21: 0.719669 test loss: 0.840045
[Epoch 117; Iter    26/  209] train: loss: 0.0046968
[Epoch 117; Iter    56/  209] train: loss: 0.0045898
[Epoch 117; Iter    86/  209] train: loss: 0.0061516
[Epoch 117; Iter   116/  209] train: loss: 0.0041858
[Epoch 117; Iter   146/  209] train: loss: 0.0059592
[Epoch 117; Iter   176/  209] train: loss: 0.0041905
[Epoch 117; Iter   206/  209] train: loss: 0.0021091
[Epoch 117] ogbg-moltox21: 0.729054 val loss: 0.753106
[Epoch 117] ogbg-moltox21: 0.714861 test loss: 0.804484
[Epoch 118; Iter    27/  209] train: loss: 0.0066186
[Epoch 118; Iter    57/  209] train: loss: 0.0062371
[Epoch 118; Iter    87/  209] train: loss: 0.0079518
[Epoch 118; Iter   117/  209] train: loss: 0.0098754
[Epoch 118; Iter   147/  209] train: loss: 0.0297083
[Epoch 118; Iter   177/  209] train: loss: 0.0067073
[Epoch 118; Iter   207/  209] train: loss: 0.0036780
[Epoch 118] ogbg-moltox21: 0.736919 val loss: 0.853102
[Epoch 118] ogbg-moltox21: 0.712486 test loss: 0.998635
[Epoch 119; Iter    28/  209] train: loss: 0.0095134
[Epoch 119; Iter    58/  209] train: loss: 0.0102178
[Epoch 119; Iter    88/  209] train: loss: 0.0074324
[Epoch 119; Iter   118/  209] train: loss: 0.0028128
[Epoch 119; Iter   148/  209] train: loss: 0.0119891
[Epoch 119; Iter   178/  209] train: loss: 0.0051785
[Epoch 119; Iter   208/  209] train: loss: 0.0020770
[Epoch 119] ogbg-moltox21: 0.731323 val loss: 0.928000
[Epoch 119] ogbg-moltox21: 0.723930 test loss: 0.980948
[Epoch 120; Iter    29/  209] train: loss: 0.0049079
[Epoch 120; Iter    59/  209] train: loss: 0.0019191
[Epoch 120; Iter    89/  209] train: loss: 0.0022162
[Epoch 120; Iter   119/  209] train: loss: 0.0018753
[Epoch 120; Iter   149/  209] train: loss: 0.0037444
[Epoch 120; Iter   179/  209] train: loss: 0.0065484
[Epoch 120; Iter   209/  209] train: loss: 0.0027502
[Epoch 120] ogbg-moltox21: 0.727634 val loss: 0.830736
[Epoch 120] ogbg-moltox21: 0.713560 test loss: 0.905685
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 18.
Statistics on  val_best_checkpoint
mean_pred: -2.84346079826355
std_pred: 1.9077666997909546
mean_targets: nan
std_targets: nan
prcauc: 0.3253095621771942
rocauc: 0.7751246164685425
ogbg-moltox21: 0.7751246164685425
OGBNanLabelBCEWithLogitsLoss: 0.2714024750446832
Statistics on  test
mean_pred: -2.856450319290161
std_pred: 1.940291166305542
mean_targets: nan
std_targets: nan
prcauc: 0.31968360286708497
rocauc: 0.7388398924911111
ogbg-moltox21: 0.7388398924911111
OGBNanLabelBCEWithLogitsLoss: 0.28370150758160484
Statistics on  train
mean_pred: -3.317059278488159
std_pred: 1.6801936626434326
mean_targets: nan
std_targets: nan
prcauc: 0.4744137511539865
rocauc: 0.8778058971556115
ogbg-moltox21: 0.8778058971556115
OGBNanLabelBCEWithLogitsLoss: 0.16639437316137068
[Epoch 116; Iter   145/  209] train: loss: 0.0139188
[Epoch 116; Iter   175/  209] train: loss: 0.0079919
[Epoch 116; Iter   205/  209] train: loss: 0.0072456
[Epoch 116] ogbg-moltox21: 0.751766 val loss: 0.596836
[Epoch 116] ogbg-moltox21: 0.726469 test loss: 0.637550
[Epoch 117; Iter    26/  209] train: loss: 0.0072266
[Epoch 117; Iter    56/  209] train: loss: 0.0076256
[Epoch 117; Iter    86/  209] train: loss: 0.0084621
[Epoch 117; Iter   116/  209] train: loss: 0.0344356
[Epoch 117; Iter   146/  209] train: loss: 0.0079538
[Epoch 117; Iter   176/  209] train: loss: 0.0250136
[Epoch 117; Iter   206/  209] train: loss: 0.0137707
[Epoch 117] ogbg-moltox21: 0.743077 val loss: 0.601120
[Epoch 117] ogbg-moltox21: 0.723052 test loss: 0.640167
[Epoch 118; Iter    27/  209] train: loss: 0.0141707
[Epoch 118; Iter    57/  209] train: loss: 0.0225569
[Epoch 118; Iter    87/  209] train: loss: 0.0073970
[Epoch 118; Iter   117/  209] train: loss: 0.0148292
[Epoch 118; Iter   147/  209] train: loss: 0.0284484
[Epoch 118; Iter   177/  209] train: loss: 0.0111403
[Epoch 118; Iter   207/  209] train: loss: 0.0115908
[Epoch 118] ogbg-moltox21: 0.745181 val loss: 0.595590
[Epoch 118] ogbg-moltox21: 0.722974 test loss: 0.622911
[Epoch 119; Iter    28/  209] train: loss: 0.0221480
[Epoch 119; Iter    58/  209] train: loss: 0.0062409
[Epoch 119; Iter    88/  209] train: loss: 0.0077429
[Epoch 119; Iter   118/  209] train: loss: 0.0120418
[Epoch 119; Iter   148/  209] train: loss: 0.0088035
[Epoch 119; Iter   178/  209] train: loss: 0.0100301
[Epoch 119; Iter   208/  209] train: loss: 0.0154990
[Epoch 119] ogbg-moltox21: 0.750231 val loss: 0.587423
[Epoch 119] ogbg-moltox21: 0.720987 test loss: 0.629498
[Epoch 120; Iter    29/  209] train: loss: 0.0106457
[Epoch 120; Iter    59/  209] train: loss: 0.0095137
[Epoch 120; Iter    89/  209] train: loss: 0.0143033
[Epoch 120; Iter   119/  209] train: loss: 0.0107908
[Epoch 120; Iter   149/  209] train: loss: 0.0068699
[Epoch 120; Iter   179/  209] train: loss: 0.0090867
[Epoch 120; Iter   209/  209] train: loss: 0.0105015
[Epoch 120] ogbg-moltox21: 0.750465 val loss: 0.589892
[Epoch 120] ogbg-moltox21: 0.725642 test loss: 0.614966
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 27.
Statistics on  val_best_checkpoint
mean_pred: -2.897766590118408
std_pred: 2.1463093757629395
mean_targets: nan
std_targets: nan
prcauc: 0.37696672361020545
rocauc: 0.7976469802480445
ogbg-moltox21: 0.7976469802480445
OGBNanLabelBCEWithLogitsLoss: 0.2696477474161872
Statistics on  test
mean_pred: -3.072526216506958
std_pred: 4.507143497467041
mean_targets: nan
std_targets: nan
prcauc: 0.32084664901102505
rocauc: 0.7397076499750961
ogbg-moltox21: 0.7397076499750961
OGBNanLabelBCEWithLogitsLoss: 0.32311902664325853
Statistics on  train
mean_pred: -3.740626811981201
std_pred: 2.5070080757141113
mean_targets: nan
std_targets: nan
prcauc: 0.565981265429064
rocauc: 0.9030213484269533
ogbg-moltox21: 0.9030213484269533
OGBNanLabelBCEWithLogitsLoss: 0.14818953843920996
[Epoch 116; Iter   145/  209] train: loss: 0.0179004
[Epoch 116; Iter   175/  209] train: loss: 0.0129762
[Epoch 116; Iter   205/  209] train: loss: 0.0202713
[Epoch 116] ogbg-moltox21: 0.759104 val loss: 0.519084
[Epoch 116] ogbg-moltox21: 0.724762 test loss: 0.546119
[Epoch 117; Iter    26/  209] train: loss: 0.0139804
[Epoch 117; Iter    56/  209] train: loss: 0.0106100
[Epoch 117; Iter    86/  209] train: loss: 0.0193870
[Epoch 117; Iter   116/  209] train: loss: 0.0117165
[Epoch 117; Iter   146/  209] train: loss: 0.0091102
[Epoch 117; Iter   176/  209] train: loss: 0.0136776
[Epoch 117; Iter   206/  209] train: loss: 0.0088327
[Epoch 117] ogbg-moltox21: 0.760309 val loss: 0.516914
[Epoch 117] ogbg-moltox21: 0.724027 test loss: 0.545666
[Epoch 118; Iter    27/  209] train: loss: 0.0157646
[Epoch 118; Iter    57/  209] train: loss: 0.0318901
[Epoch 118; Iter    87/  209] train: loss: 0.0084387
[Epoch 118; Iter   117/  209] train: loss: 0.0180658
[Epoch 118; Iter   147/  209] train: loss: 0.0106482
[Epoch 118; Iter   177/  209] train: loss: 0.0235205
[Epoch 118; Iter   207/  209] train: loss: 0.0193919
[Epoch 118] ogbg-moltox21: 0.760181 val loss: 0.510078
[Epoch 118] ogbg-moltox21: 0.722560 test loss: 0.540513
[Epoch 119; Iter    28/  209] train: loss: 0.0154000
[Epoch 119; Iter    58/  209] train: loss: 0.0455047
[Epoch 119; Iter    88/  209] train: loss: 0.0247605
[Epoch 119; Iter   118/  209] train: loss: 0.0099255
[Epoch 119; Iter   148/  209] train: loss: 0.0110816
[Epoch 119; Iter   178/  209] train: loss: 0.0340936
[Epoch 119; Iter   208/  209] train: loss: 0.0071369
[Epoch 119] ogbg-moltox21: 0.759266 val loss: 0.515054
[Epoch 119] ogbg-moltox21: 0.717056 test loss: 0.553111
[Epoch 120; Iter    29/  209] train: loss: 0.0186259
[Epoch 120; Iter    59/  209] train: loss: 0.0081072
[Epoch 120; Iter    89/  209] train: loss: 0.0115377
[Epoch 120; Iter   119/  209] train: loss: 0.0135106
[Epoch 120; Iter   149/  209] train: loss: 0.0800587
[Epoch 120; Iter   179/  209] train: loss: 0.0156588
[Epoch 120; Iter   209/  209] train: loss: 0.0189879
[Epoch 120] ogbg-moltox21: 0.758122 val loss: 0.526917
[Epoch 120] ogbg-moltox21: 0.717858 test loss: 0.558367
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 24.
Statistics on  val_best_checkpoint
mean_pred: -2.9321341514587402
std_pred: 1.9667505025863647
mean_targets: nan
std_targets: nan
prcauc: 0.3512661160378691
rocauc: 0.7928592257545931
ogbg-moltox21: 0.7928592257545931
OGBNanLabelBCEWithLogitsLoss: 0.26940916299268053
Statistics on  test
mean_pred: -3.3689351081848145
std_pred: 12.54641056060791
mean_targets: nan
std_targets: nan
prcauc: 0.31735358459648016
rocauc: 0.7657922829158975
ogbg-moltox21: 0.7657922829158975
OGBNanLabelBCEWithLogitsLoss: 0.28331324402932767
Statistics on  train
mean_pred: -3.5642249584198
std_pred: 2.2123422622680664
mean_targets: nan
std_targets: nan
prcauc: 0.47720891435499363
rocauc: 0.8847947768225396
ogbg-moltox21: 0.8847947768225396
OGBNanLabelBCEWithLogitsLoss: 0.161438822603682
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.05.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.05.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.05.yml --seed 6 --device cuda:1
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0019261
[Epoch 116; Iter   175/  209] train: loss: 0.0130848
[Epoch 116; Iter   205/  209] train: loss: 0.0108325
[Epoch 116] ogbg-moltox21: 0.732507 val loss: 0.756801
[Epoch 116] ogbg-moltox21: 0.683015 test loss: 0.850164
[Epoch 117; Iter    26/  209] train: loss: 0.0027456
[Epoch 117; Iter    56/  209] train: loss: 0.0299581
[Epoch 117; Iter    86/  209] train: loss: 0.0039528
[Epoch 117; Iter   116/  209] train: loss: 0.0033209
[Epoch 117; Iter   146/  209] train: loss: 0.0098576
[Epoch 117; Iter   176/  209] train: loss: 0.0118846
[Epoch 117; Iter   206/  209] train: loss: 0.0106799
[Epoch 117] ogbg-moltox21: 0.730138 val loss: 0.784319
[Epoch 117] ogbg-moltox21: 0.673471 test loss: 0.883721
[Epoch 118; Iter    27/  209] train: loss: 0.0037239
[Epoch 118; Iter    57/  209] train: loss: 0.0105903
[Epoch 118; Iter    87/  209] train: loss: 0.0133887
[Epoch 118; Iter   117/  209] train: loss: 0.0050455
[Epoch 118; Iter   147/  209] train: loss: 0.0077723
[Epoch 118; Iter   177/  209] train: loss: 0.0049508
[Epoch 118; Iter   207/  209] train: loss: 0.0074110
[Epoch 118] ogbg-moltox21: 0.731411 val loss: 0.752071
[Epoch 118] ogbg-moltox21: 0.678428 test loss: 0.865156
[Epoch 119; Iter    28/  209] train: loss: 0.0036758
[Epoch 119; Iter    58/  209] train: loss: 0.0140594
[Epoch 119; Iter    88/  209] train: loss: 0.0101746
[Epoch 119; Iter   118/  209] train: loss: 0.0145958
[Epoch 119; Iter   148/  209] train: loss: 0.0026298
[Epoch 119; Iter   178/  209] train: loss: 0.0132280
[Epoch 119; Iter   208/  209] train: loss: 0.0082557
[Epoch 119] ogbg-moltox21: 0.731998 val loss: 0.787129
[Epoch 119] ogbg-moltox21: 0.677198 test loss: 0.885590
[Epoch 120; Iter    29/  209] train: loss: 0.0041392
[Epoch 120; Iter    59/  209] train: loss: 0.0066147
[Epoch 120; Iter    89/  209] train: loss: 0.0067663
[Epoch 120; Iter   119/  209] train: loss: 0.0037314
[Epoch 120; Iter   149/  209] train: loss: 0.0389221
[Epoch 120; Iter   179/  209] train: loss: 0.0095283
[Epoch 120; Iter   209/  209] train: loss: 0.0336029
[Epoch 120] ogbg-moltox21: 0.735215 val loss: 0.742832
[Epoch 120] ogbg-moltox21: 0.680257 test loss: 0.915561
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 13.
Statistics on  val_best_checkpoint
mean_pred: -3.0241494178771973
std_pred: 2.1194653511047363
mean_targets: nan
std_targets: nan
prcauc: 0.33500632346400344
rocauc: 0.7804781565270047
ogbg-moltox21: 0.7804781565270047
OGBNanLabelBCEWithLogitsLoss: 0.2883660089638498
Statistics on  test
mean_pred: -3.0236661434173584
std_pred: 2.354689121246338
mean_targets: nan
std_targets: nan
prcauc: 0.29257121520458956
rocauc: 0.7317635840594302
ogbg-moltox21: 0.7317635840594302
OGBNanLabelBCEWithLogitsLoss: 0.3397366559063947
Statistics on  train
mean_pred: -3.381143808364868
std_pred: 1.7921861410140991
mean_targets: nan
std_targets: nan
prcauc: 0.40637389427343984
rocauc: 0.8520285098060429
ogbg-moltox21: 0.8520285098060429
OGBNanLabelBCEWithLogitsLoss: 0.17747165362515518
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.1.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.1.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.1.yml --seed 6 --device cuda:2
All runs completed.
[Epoch 116; Iter   145/  209] train: loss: 0.0018683
[Epoch 116; Iter   175/  209] train: loss: 0.0021184
[Epoch 116; Iter   205/  209] train: loss: 0.0013680
[Epoch 116] ogbg-moltox21: 0.715969 val loss: 0.860332
[Epoch 116] ogbg-moltox21: 0.690000 test loss: 0.920149
[Epoch 117; Iter    26/  209] train: loss: 0.0011231
[Epoch 117; Iter    56/  209] train: loss: 0.0025975
[Epoch 117; Iter    86/  209] train: loss: 0.0059627
[Epoch 117; Iter   116/  209] train: loss: 0.0017712
[Epoch 117; Iter   146/  209] train: loss: 0.0034269
[Epoch 117; Iter   176/  209] train: loss: 0.0073160
[Epoch 117; Iter   206/  209] train: loss: 0.0053218
[Epoch 117] ogbg-moltox21: 0.716496 val loss: 0.874633
[Epoch 117] ogbg-moltox21: 0.686388 test loss: 0.983692
[Epoch 118; Iter    27/  209] train: loss: 0.0031475
[Epoch 118; Iter    57/  209] train: loss: 0.0023524
[Epoch 118; Iter    87/  209] train: loss: 0.0015922
[Epoch 118; Iter   117/  209] train: loss: 0.0025093
[Epoch 118; Iter   147/  209] train: loss: 0.0127888
[Epoch 118; Iter   177/  209] train: loss: 0.0057500
[Epoch 118; Iter   207/  209] train: loss: 0.0028280
[Epoch 118] ogbg-moltox21: 0.717660 val loss: 0.865869
[Epoch 118] ogbg-moltox21: 0.688541 test loss: 0.942614
[Epoch 119; Iter    28/  209] train: loss: 0.0054292
[Epoch 119; Iter    58/  209] train: loss: 0.0027578
[Epoch 119; Iter    88/  209] train: loss: 0.0058754
[Epoch 119; Iter   118/  209] train: loss: 0.0014788
[Epoch 119; Iter   148/  209] train: loss: 0.0079622
[Epoch 119; Iter   178/  209] train: loss: 0.0052516
[Epoch 119; Iter   208/  209] train: loss: 0.0058803
[Epoch 119] ogbg-moltox21: 0.717756 val loss: 0.862392
[Epoch 119] ogbg-moltox21: 0.685825 test loss: 1.257986
[Epoch 120; Iter    29/  209] train: loss: 0.0021565
[Epoch 120; Iter    59/  209] train: loss: 0.0020993
[Epoch 120; Iter    89/  209] train: loss: 0.0026719
[Epoch 120; Iter   119/  209] train: loss: 0.0045390
[Epoch 120; Iter   149/  209] train: loss: 0.0041982
[Epoch 120; Iter   179/  209] train: loss: 0.0023434
[Epoch 120; Iter   209/  209] train: loss: 0.0018827
[Epoch 120] ogbg-moltox21: 0.718848 val loss: 0.870732
[Epoch 120] ogbg-moltox21: 0.686394 test loss: 1.047183
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 15.
Statistics on  val_best_checkpoint
mean_pred: -2.8130476474761963
std_pred: 2.0029077529907227
mean_targets: nan
std_targets: nan
prcauc: 0.3102287372952453
rocauc: 0.7554111459484992
ogbg-moltox21: 0.7554111459484992
OGBNanLabelBCEWithLogitsLoss: 0.2853787527592094
Statistics on  test
mean_pred: -2.8682408332824707
std_pred: 2.097104549407959
mean_targets: nan
std_targets: nan
prcauc: 0.27624556980341614
rocauc: 0.7158716983709389
ogbg-moltox21: 0.7158716983709389
OGBNanLabelBCEWithLogitsLoss: 0.30807102885511184
Statistics on  train
mean_pred: -3.3290014266967773
std_pred: 1.550276517868042
mean_targets: nan
std_targets: nan
prcauc: 0.44714885632838125
rocauc: 0.8634003277542401
ogbg-moltox21: 0.8634003277542401
OGBNanLabelBCEWithLogitsLoss: 0.17086047615018188
[Epoch 116; Iter   145/  209] train: loss: 0.0070388
[Epoch 116; Iter   175/  209] train: loss: 0.0132172
[Epoch 116; Iter   205/  209] train: loss: 0.0020727
[Epoch 116] ogbg-moltox21: 0.674160 val loss: 2.619892
[Epoch 116] ogbg-moltox21: 0.632828 test loss: 1.907675
[Epoch 117; Iter    26/  209] train: loss: 0.0055018
[Epoch 117; Iter    56/  209] train: loss: 0.0106717
[Epoch 117; Iter    86/  209] train: loss: 0.0079450
[Epoch 117; Iter   116/  209] train: loss: 0.0109002
[Epoch 117; Iter   146/  209] train: loss: 0.0058577
[Epoch 117; Iter   176/  209] train: loss: 0.0089474
[Epoch 117; Iter   206/  209] train: loss: 0.0053360
[Epoch 117] ogbg-moltox21: 0.665797 val loss: 2.045422
[Epoch 117] ogbg-moltox21: 0.631033 test loss: 1.408950
[Epoch 118; Iter    27/  209] train: loss: 0.0036926
[Epoch 118; Iter    57/  209] train: loss: 0.0087178
[Epoch 118; Iter    87/  209] train: loss: 0.0097101
[Epoch 118; Iter   117/  209] train: loss: 0.0109895
[Epoch 118; Iter   147/  209] train: loss: 0.0099420
[Epoch 118; Iter   177/  209] train: loss: 0.0064015
[Epoch 118; Iter   207/  209] train: loss: 0.0098996
[Epoch 118] ogbg-moltox21: 0.660969 val loss: 1.872319
[Epoch 118] ogbg-moltox21: 0.630811 test loss: 1.307239
[Epoch 119; Iter    28/  209] train: loss: 0.0056142
[Epoch 119; Iter    58/  209] train: loss: 0.0040296
[Epoch 119; Iter    88/  209] train: loss: 0.0063136
[Epoch 119; Iter   118/  209] train: loss: 0.0162485
[Epoch 119; Iter   148/  209] train: loss: 0.0117371
[Epoch 119; Iter   178/  209] train: loss: 0.0170769
[Epoch 119; Iter   208/  209] train: loss: 0.0032298
[Epoch 119] ogbg-moltox21: 0.680711 val loss: 1.713398
[Epoch 119] ogbg-moltox21: 0.640723 test loss: 1.259240
[Epoch 120; Iter    29/  209] train: loss: 0.0081993
[Epoch 120; Iter    59/  209] train: loss: 0.0159505
[Epoch 120; Iter    89/  209] train: loss: 0.0085618
[Epoch 120; Iter   119/  209] train: loss: 0.0037292
[Epoch 120; Iter   149/  209] train: loss: 0.0167602
[Epoch 120; Iter   179/  209] train: loss: 0.0039534
[Epoch 120; Iter   209/  209] train: loss: 0.0178310
[Epoch 120] ogbg-moltox21: 0.675920 val loss: 1.184097
[Epoch 120] ogbg-moltox21: 0.638493 test loss: 1.110899
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 13.
Statistics on  val_best_checkpoint
mean_pred: -2.7192697525024414
std_pred: 7.035663604736328
mean_targets: nan
std_targets: nan
prcauc: 0.2917936948024888
rocauc: 0.7601584039386533
ogbg-moltox21: 0.7601584039386533
OGBNanLabelBCEWithLogitsLoss: 0.5978407771499069
Statistics on  test
mean_pred: -2.986736297607422
std_pred: 4.908236026763916
mean_targets: nan
std_targets: nan
prcauc: 0.2695734470557041
rocauc: 0.7188125246410694
ogbg-moltox21: 0.7188125246410694
OGBNanLabelBCEWithLogitsLoss: 0.484280319125564
Statistics on  train
mean_pred: -3.3591625690460205
std_pred: 1.6513575315475464
mean_targets: nan
std_targets: nan
prcauc: 0.3735932613603254
rocauc: 0.8383413468418813
ogbg-moltox21: 0.8383413468418813
OGBNanLabelBCEWithLogitsLoss: 0.1836895082484592
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0037284
[Epoch 116; Iter   175/  209] train: loss: 0.0018964
[Epoch 116; Iter   205/  209] train: loss: 0.0037952
[Epoch 116] ogbg-moltox21: 0.721124 val loss: 1.390689
[Epoch 116] ogbg-moltox21: 0.657300 test loss: 1.177504
[Epoch 117; Iter    26/  209] train: loss: 0.0034922
[Epoch 117; Iter    56/  209] train: loss: 0.0009236
[Epoch 117; Iter    86/  209] train: loss: 0.0025388
[Epoch 117; Iter   116/  209] train: loss: 0.0027581
[Epoch 117; Iter   146/  209] train: loss: 0.0035644
[Epoch 117; Iter   176/  209] train: loss: 0.0042677
[Epoch 117; Iter   206/  209] train: loss: 0.0025797
[Epoch 117] ogbg-moltox21: 0.722954 val loss: 1.310782
[Epoch 117] ogbg-moltox21: 0.655303 test loss: 1.241100
[Epoch 118; Iter    27/  209] train: loss: 0.0015350
[Epoch 118; Iter    57/  209] train: loss: 0.0070328
[Epoch 118; Iter    87/  209] train: loss: 0.0022888
[Epoch 118; Iter   117/  209] train: loss: 0.0111901
[Epoch 118; Iter   147/  209] train: loss: 0.0036243
[Epoch 118; Iter   177/  209] train: loss: 0.0179549
[Epoch 118; Iter   207/  209] train: loss: 0.0036804
[Epoch 118] ogbg-moltox21: 0.729375 val loss: 1.087263
[Epoch 118] ogbg-moltox21: 0.657526 test loss: 1.104724
[Epoch 119; Iter    28/  209] train: loss: 0.0030338
[Epoch 119; Iter    58/  209] train: loss: 0.0157111
[Epoch 119; Iter    88/  209] train: loss: 0.0051897
[Epoch 119; Iter   118/  209] train: loss: 0.0045284
[Epoch 119; Iter   148/  209] train: loss: 0.0025082
[Epoch 119; Iter   178/  209] train: loss: 0.0069230
[Epoch 119; Iter   208/  209] train: loss: 0.0011800
[Epoch 119] ogbg-moltox21: 0.731849 val loss: 1.068977
[Epoch 119] ogbg-moltox21: 0.657436 test loss: 1.071540
[Epoch 120; Iter    29/  209] train: loss: 0.0064077
[Epoch 120; Iter    59/  209] train: loss: 0.0016097
[Epoch 120; Iter    89/  209] train: loss: 0.0019864
[Epoch 120; Iter   119/  209] train: loss: 0.0022438
[Epoch 120; Iter   149/  209] train: loss: 0.0084748
[Epoch 120; Iter   179/  209] train: loss: 0.0059961
[Epoch 120; Iter   209/  209] train: loss: 0.0038549
[Epoch 120] ogbg-moltox21: 0.724866 val loss: 1.357288
[Epoch 120] ogbg-moltox21: 0.656536 test loss: 1.222791
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 16.
Statistics on  val_best_checkpoint
mean_pred: -3.4469783306121826
std_pred: 2.011993169784546
mean_targets: nan
std_targets: nan
prcauc: 0.33054147404258744
rocauc: 0.7678821281672116
ogbg-moltox21: 0.7678821281672116
OGBNanLabelBCEWithLogitsLoss: 0.2767789083774443
Statistics on  test
mean_pred: -3.4947152137756348
std_pred: 2.0108022689819336
mean_targets: nan
std_targets: nan
prcauc: 0.309984485908766
rocauc: 0.7144201825987588
ogbg-moltox21: 0.7144201825987588
OGBNanLabelBCEWithLogitsLoss: 0.292393050260014
Statistics on  train
mean_pred: -3.158775568008423
std_pred: 1.629103183746338
mean_targets: nan
std_targets: nan
prcauc: 0.43885641444182205
rocauc: 0.8678669901010835
ogbg-moltox21: 0.8678669901010835
OGBNanLabelBCEWithLogitsLoss: 0.1739045710227136
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.2.yml --seed 4 --device cuda:3
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.2.yml --seed 5 --device cuda:3
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.2.yml --seed 6 --device cuda:3
All runs completed.
[Epoch 82; Iter    51/  209] train: loss: 0.0502712
[Epoch 82; Iter    81/  209] train: loss: 0.0484655
[Epoch 82; Iter   111/  209] train: loss: 0.1259073
[Epoch 82; Iter   141/  209] train: loss: 0.0534657
[Epoch 82; Iter   171/  209] train: loss: 0.0698525
[Epoch 82; Iter   201/  209] train: loss: 0.0639652
[Epoch 82] ogbg-moltox21: 0.787106 val loss: 0.338054
[Epoch 82] ogbg-moltox21: 0.752485 test loss: 0.364160
[Epoch 83; Iter    22/  209] train: loss: 0.0550122
[Epoch 83; Iter    52/  209] train: loss: 0.0984275
[Epoch 83; Iter    82/  209] train: loss: 0.0909302
[Epoch 83; Iter   112/  209] train: loss: 0.0899968
[Epoch 83; Iter   142/  209] train: loss: 0.0882139
[Epoch 83; Iter   172/  209] train: loss: 0.0582826
[Epoch 83; Iter   202/  209] train: loss: 0.0566499
[Epoch 83] ogbg-moltox21: 0.779190 val loss: 0.348564
[Epoch 83] ogbg-moltox21: 0.754891 test loss: 0.370211
[Epoch 84; Iter    23/  209] train: loss: 0.0564634
[Epoch 84; Iter    53/  209] train: loss: 0.0478552
[Epoch 84; Iter    83/  209] train: loss: 0.0529348
[Epoch 84; Iter   113/  209] train: loss: 0.1020792
[Epoch 84; Iter   143/  209] train: loss: 0.1021678
[Epoch 84; Iter   173/  209] train: loss: 0.0621192
[Epoch 84; Iter   203/  209] train: loss: 0.0546277
[Epoch 84] ogbg-moltox21: 0.768245 val loss: 0.356303
[Epoch 84] ogbg-moltox21: 0.746748 test loss: 0.377775
[Epoch 85; Iter    24/  209] train: loss: 0.0612920
[Epoch 85; Iter    54/  209] train: loss: 0.0674367
[Epoch 85; Iter    84/  209] train: loss: 0.0731685
[Epoch 85; Iter   114/  209] train: loss: 0.1122457
[Epoch 85; Iter   144/  209] train: loss: 0.0551918
[Epoch 85; Iter   174/  209] train: loss: 0.1078643
[Epoch 85; Iter   204/  209] train: loss: 0.0512313
[Epoch 85] ogbg-moltox21: 0.774035 val loss: 0.355289
[Epoch 85] ogbg-moltox21: 0.749801 test loss: 0.373705
[Epoch 86; Iter    25/  209] train: loss: 0.0806047
[Epoch 86; Iter    55/  209] train: loss: 0.0561106
[Epoch 86; Iter    85/  209] train: loss: 0.0918789
[Epoch 86; Iter   115/  209] train: loss: 0.0587851
[Epoch 86; Iter   145/  209] train: loss: 0.0480683
[Epoch 86; Iter   175/  209] train: loss: 0.0849073
[Epoch 86; Iter   205/  209] train: loss: 0.1213411
[Epoch 86] ogbg-moltox21: 0.770923 val loss: 0.362485
[Epoch 86] ogbg-moltox21: 0.750532 test loss: 0.375267
[Epoch 87; Iter    26/  209] train: loss: 0.0725334
[Epoch 87; Iter    56/  209] train: loss: 0.0558840
[Epoch 87; Iter    86/  209] train: loss: 0.0520872
[Epoch 87; Iter   116/  209] train: loss: 0.0614488
[Epoch 87; Iter   146/  209] train: loss: 0.0576574
[Epoch 87; Iter   176/  209] train: loss: 0.0416813
[Epoch 87; Iter   206/  209] train: loss: 0.0352522
[Epoch 87] ogbg-moltox21: 0.775863 val loss: 0.359732
[Epoch 87] ogbg-moltox21: 0.752489 test loss: 0.377731
[Epoch 88; Iter    27/  209] train: loss: 0.0547891
[Epoch 88; Iter    57/  209] train: loss: 0.0538891
[Epoch 88; Iter    87/  209] train: loss: 0.0484095
[Epoch 88; Iter   117/  209] train: loss: 0.0431312
[Epoch 88; Iter   147/  209] train: loss: 0.0515170
[Epoch 88; Iter   177/  209] train: loss: 0.0685053
[Epoch 88; Iter   207/  209] train: loss: 0.0534991
[Epoch 88] ogbg-moltox21: 0.776366 val loss: 0.359795
[Epoch 88] ogbg-moltox21: 0.752530 test loss: 0.383835
[Epoch 89; Iter    28/  209] train: loss: 0.0679292
[Epoch 89; Iter    58/  209] train: loss: 0.1041723
[Epoch 89; Iter    88/  209] train: loss: 0.0710921
[Epoch 89; Iter   118/  209] train: loss: 0.0377100
[Epoch 89; Iter   148/  209] train: loss: 0.0678481
[Epoch 89; Iter   178/  209] train: loss: 0.0809510
[Epoch 89; Iter   208/  209] train: loss: 0.0681125
[Epoch 89] ogbg-moltox21: 0.773749 val loss: 0.377906
[Epoch 89] ogbg-moltox21: 0.745052 test loss: 0.398469
[Epoch 90; Iter    29/  209] train: loss: 0.0493067
[Epoch 90; Iter    59/  209] train: loss: 0.0350613
[Epoch 90; Iter    89/  209] train: loss: 0.0609717
[Epoch 90; Iter   119/  209] train: loss: 0.0612183
[Epoch 90; Iter   149/  209] train: loss: 0.0564011
[Epoch 90; Iter   179/  209] train: loss: 0.0430981
[Epoch 90; Iter   209/  209] train: loss: 0.1021145
[Epoch 90] ogbg-moltox21: 0.774138 val loss: 0.363045
[Epoch 90] ogbg-moltox21: 0.749880 test loss: 0.385072
[Epoch 91; Iter    30/  209] train: loss: 0.0470725
[Epoch 91; Iter    60/  209] train: loss: 0.0274124
[Epoch 91; Iter    90/  209] train: loss: 0.0610156
[Epoch 91; Iter   120/  209] train: loss: 0.0444202
[Epoch 91; Iter   150/  209] train: loss: 0.0838846
[Epoch 91; Iter   180/  209] train: loss: 0.0367583
[Epoch 91] ogbg-moltox21: 0.771986 val loss: 0.368034
[Epoch 91] ogbg-moltox21: 0.749211 test loss: 0.388252
[Epoch 92; Iter     1/  209] train: loss: 0.0287301
[Epoch 92; Iter    31/  209] train: loss: 0.0532230
[Epoch 92; Iter    61/  209] train: loss: 0.0687340
[Epoch 92; Iter    91/  209] train: loss: 0.0684242
[Epoch 92; Iter   121/  209] train: loss: 0.0513534
[Epoch 92; Iter   151/  209] train: loss: 0.0556862
[Epoch 92; Iter   181/  209] train: loss: 0.0513300
[Epoch 92] ogbg-moltox21: 0.778537 val loss: 0.373715
[Epoch 92] ogbg-moltox21: 0.751237 test loss: 0.401887
[Epoch 93; Iter     2/  209] train: loss: 0.0931223
[Epoch 93; Iter    32/  209] train: loss: 0.0386766
[Epoch 93; Iter    62/  209] train: loss: 0.0651389
[Epoch 93; Iter    92/  209] train: loss: 0.0761375
[Epoch 93; Iter   122/  209] train: loss: 0.0571291
[Epoch 93; Iter   152/  209] train: loss: 0.0632558
[Epoch 93; Iter   182/  209] train: loss: 0.0526236
[Epoch 93] ogbg-moltox21: 0.774781 val loss: 0.364230
[Epoch 93] ogbg-moltox21: 0.752283 test loss: 0.384788
[Epoch 94; Iter     3/  209] train: loss: 0.0406466
[Epoch 94; Iter    33/  209] train: loss: 0.0601692
[Epoch 94; Iter    63/  209] train: loss: 0.0818933
[Epoch 94; Iter    93/  209] train: loss: 0.0704513
[Epoch 94; Iter   123/  209] train: loss: 0.0722404
[Epoch 94; Iter   153/  209] train: loss: 0.0496463
[Epoch 94; Iter   183/  209] train: loss: 0.0665351
[Epoch 94] ogbg-moltox21: 0.772803 val loss: 0.383277
[Epoch 94] ogbg-moltox21: 0.751717 test loss: 0.410552
[Epoch 95; Iter     4/  209] train: loss: 0.0414613
[Epoch 95; Iter    34/  209] train: loss: 0.1060914
[Epoch 95; Iter    64/  209] train: loss: 0.0666741
[Epoch 95; Iter    94/  209] train: loss: 0.0915118
[Epoch 95; Iter   124/  209] train: loss: 0.0454559
[Epoch 95; Iter   154/  209] train: loss: 0.0775257
[Epoch 95; Iter   184/  209] train: loss: 0.0593717
[Epoch 95] ogbg-moltox21: 0.768646 val loss: 0.391230
[Epoch 95] ogbg-moltox21: 0.751911 test loss: 0.407342
[Epoch 96; Iter     5/  209] train: loss: 0.0828091
[Epoch 96; Iter    35/  209] train: loss: 0.0402654
[Epoch 96; Iter    65/  209] train: loss: 0.0740027
[Epoch 96; Iter    95/  209] train: loss: 0.0455552
[Epoch 96; Iter   125/  209] train: loss: 0.0285929
[Epoch 96; Iter   155/  209] train: loss: 0.0489182
[Epoch 96; Iter   185/  209] train: loss: 0.0507308
[Epoch 96] ogbg-moltox21: 0.766765 val loss: 0.453149
[Epoch 96] ogbg-moltox21: 0.744809 test loss: 0.415129
[Epoch 97; Iter     6/  209] train: loss: 0.0786312
[Epoch 97; Iter    36/  209] train: loss: 0.0283619
[Epoch 97; Iter    66/  209] train: loss: 0.0772288
[Epoch 97; Iter    96/  209] train: loss: 0.0411280
[Epoch 97; Iter   126/  209] train: loss: 0.0697209
[Epoch 97; Iter   156/  209] train: loss: 0.0571836
[Epoch 97; Iter   186/  209] train: loss: 0.0414497
[Epoch 97] ogbg-moltox21: 0.768565 val loss: 0.384404
[Epoch 97] ogbg-moltox21: 0.750479 test loss: 0.398759
[Epoch 98; Iter     7/  209] train: loss: 0.0614370
[Epoch 98; Iter    37/  209] train: loss: 0.0361017
[Epoch 98; Iter    67/  209] train: loss: 0.0404174
[Epoch 98; Iter    97/  209] train: loss: 0.0844407
[Epoch 98; Iter   127/  209] train: loss: 0.0820674
[Epoch 98; Iter   157/  209] train: loss: 0.0507614
[Epoch 98; Iter   187/  209] train: loss: 0.0655814
[Epoch 98] ogbg-moltox21: 0.763316 val loss: 0.445670
[Epoch 98] ogbg-moltox21: 0.746856 test loss: 0.412230
[Epoch 99; Iter     8/  209] train: loss: 0.1165065
[Epoch 99; Iter    38/  209] train: loss: 0.0572145
[Epoch 99; Iter    68/  209] train: loss: 0.0859212
[Epoch 99; Iter    98/  209] train: loss: 0.1176453
[Epoch 82; Iter    51/  209] train: loss: 0.0607119
[Epoch 82; Iter    81/  209] train: loss: 0.0937667
[Epoch 82; Iter   111/  209] train: loss: 0.0498535
[Epoch 82; Iter   141/  209] train: loss: 0.0806178
[Epoch 82; Iter   171/  209] train: loss: 0.0400382
[Epoch 82; Iter   201/  209] train: loss: 0.0745664
[Epoch 82] ogbg-moltox21: 0.776167 val loss: 0.332091
[Epoch 82] ogbg-moltox21: 0.745444 test loss: 0.363552
[Epoch 83; Iter    22/  209] train: loss: 0.1146298
[Epoch 83; Iter    52/  209] train: loss: 0.1066949
[Epoch 83; Iter    82/  209] train: loss: 0.0498267
[Epoch 83; Iter   112/  209] train: loss: 0.0945858
[Epoch 83; Iter   142/  209] train: loss: 0.1320596
[Epoch 83; Iter   172/  209] train: loss: 0.0510944
[Epoch 83; Iter   202/  209] train: loss: 0.1114007
[Epoch 83] ogbg-moltox21: 0.767648 val loss: 0.336516
[Epoch 83] ogbg-moltox21: 0.740620 test loss: 0.372038
[Epoch 84; Iter    23/  209] train: loss: 0.0645582
[Epoch 84; Iter    53/  209] train: loss: 0.0694366
[Epoch 84; Iter    83/  209] train: loss: 0.0406319
[Epoch 84; Iter   113/  209] train: loss: 0.0637567
[Epoch 84; Iter   143/  209] train: loss: 0.0674310
[Epoch 84; Iter   173/  209] train: loss: 0.0802157
[Epoch 84; Iter   203/  209] train: loss: 0.0953280
[Epoch 84] ogbg-moltox21: 0.772195 val loss: 0.351245
[Epoch 84] ogbg-moltox21: 0.743978 test loss: 0.373607
[Epoch 85; Iter    24/  209] train: loss: 0.0698305
[Epoch 85; Iter    54/  209] train: loss: 0.1130340
[Epoch 85; Iter    84/  209] train: loss: 0.0427445
[Epoch 85; Iter   114/  209] train: loss: 0.0957022
[Epoch 85; Iter   144/  209] train: loss: 0.1224661
[Epoch 85; Iter   174/  209] train: loss: 0.0584086
[Epoch 85; Iter   204/  209] train: loss: 0.0809705
[Epoch 85] ogbg-moltox21: 0.758366 val loss: 0.370827
[Epoch 85] ogbg-moltox21: 0.735894 test loss: 0.373350
[Epoch 86; Iter    25/  209] train: loss: 0.0543099
[Epoch 86; Iter    55/  209] train: loss: 0.0555784
[Epoch 86; Iter    85/  209] train: loss: 0.0633931
[Epoch 86; Iter   115/  209] train: loss: 0.1043376
[Epoch 86; Iter   145/  209] train: loss: 0.0840130
[Epoch 86; Iter   175/  209] train: loss: 0.0594794
[Epoch 86; Iter   205/  209] train: loss: 0.0592076
[Epoch 86] ogbg-moltox21: 0.767061 val loss: 0.336233
[Epoch 86] ogbg-moltox21: 0.743331 test loss: 0.365407
[Epoch 87; Iter    26/  209] train: loss: 0.0513788
[Epoch 87; Iter    56/  209] train: loss: 0.0843977
[Epoch 87; Iter    86/  209] train: loss: 0.0693991
[Epoch 87; Iter   116/  209] train: loss: 0.1084885
[Epoch 87; Iter   146/  209] train: loss: 0.1194176
[Epoch 87; Iter   176/  209] train: loss: 0.0537857
[Epoch 87; Iter   206/  209] train: loss: 0.0865022
[Epoch 87] ogbg-moltox21: 0.769222 val loss: 0.343238
[Epoch 87] ogbg-moltox21: 0.745111 test loss: 0.372493
[Epoch 88; Iter    27/  209] train: loss: 0.0523143
[Epoch 88; Iter    57/  209] train: loss: 0.0841866
[Epoch 88; Iter    87/  209] train: loss: 0.0577386
[Epoch 88; Iter   117/  209] train: loss: 0.0620083
[Epoch 88; Iter   147/  209] train: loss: 0.0383492
[Epoch 88; Iter   177/  209] train: loss: 0.0691007
[Epoch 88; Iter   207/  209] train: loss: 0.0592235
[Epoch 88] ogbg-moltox21: 0.762884 val loss: 0.365887
[Epoch 88] ogbg-moltox21: 0.740312 test loss: 0.381353
[Epoch 89; Iter    28/  209] train: loss: 0.0568027
[Epoch 89; Iter    58/  209] train: loss: 0.0843323
[Epoch 89; Iter    88/  209] train: loss: 0.0900896
[Epoch 89; Iter   118/  209] train: loss: 0.0352355
[Epoch 89; Iter   148/  209] train: loss: 0.1004487
[Epoch 89; Iter   178/  209] train: loss: 0.0658912
[Epoch 89; Iter   208/  209] train: loss: 0.0682377
[Epoch 89] ogbg-moltox21: 0.765500 val loss: 0.361063
[Epoch 89] ogbg-moltox21: 0.742157 test loss: 0.386199
[Epoch 90; Iter    29/  209] train: loss: 0.0762652
[Epoch 90; Iter    59/  209] train: loss: 0.0634672
[Epoch 90; Iter    89/  209] train: loss: 0.0477194
[Epoch 90; Iter   119/  209] train: loss: 0.1398921
[Epoch 90; Iter   149/  209] train: loss: 0.0769481
[Epoch 90; Iter   179/  209] train: loss: 0.0727462
[Epoch 90; Iter   209/  209] train: loss: 0.0545895
[Epoch 90] ogbg-moltox21: 0.771307 val loss: 0.368391
[Epoch 90] ogbg-moltox21: 0.741015 test loss: 0.383547
[Epoch 91; Iter    30/  209] train: loss: 0.0647262
[Epoch 91; Iter    60/  209] train: loss: 0.0299293
[Epoch 91; Iter    90/  209] train: loss: 0.0605117
[Epoch 91; Iter   120/  209] train: loss: 0.0540143
[Epoch 91; Iter   150/  209] train: loss: 0.0865915
[Epoch 91; Iter   180/  209] train: loss: 0.0443935
[Epoch 91] ogbg-moltox21: 0.769930 val loss: 0.352497
[Epoch 91] ogbg-moltox21: 0.741016 test loss: 0.382282
[Epoch 92; Iter     1/  209] train: loss: 0.0446925
[Epoch 92; Iter    31/  209] train: loss: 0.0441054
[Epoch 92; Iter    61/  209] train: loss: 0.0311523
[Epoch 92; Iter    91/  209] train: loss: 0.0495296
[Epoch 92; Iter   121/  209] train: loss: 0.0495095
[Epoch 92; Iter   151/  209] train: loss: 0.0559593
[Epoch 92; Iter   181/  209] train: loss: 0.0296550
[Epoch 92] ogbg-moltox21: 0.766092 val loss: 0.348973
[Epoch 92] ogbg-moltox21: 0.739713 test loss: 0.382434
[Epoch 93; Iter     2/  209] train: loss: 0.0514903
[Epoch 93; Iter    32/  209] train: loss: 0.0799912
[Epoch 93; Iter    62/  209] train: loss: 0.0359667
[Epoch 93; Iter    92/  209] train: loss: 0.0636183
[Epoch 93; Iter   122/  209] train: loss: 0.0669898
[Epoch 93; Iter   152/  209] train: loss: 0.0518548
[Epoch 93; Iter   182/  209] train: loss: 0.0549644
[Epoch 93] ogbg-moltox21: 0.767894 val loss: 0.362291
[Epoch 93] ogbg-moltox21: 0.741564 test loss: 0.384669
[Epoch 94; Iter     3/  209] train: loss: 0.0344661
[Epoch 94; Iter    33/  209] train: loss: 0.0514467
[Epoch 94; Iter    63/  209] train: loss: 0.0365726
[Epoch 94; Iter    93/  209] train: loss: 0.0442360
[Epoch 94; Iter   123/  209] train: loss: 0.0788155
[Epoch 94; Iter   153/  209] train: loss: 0.0487974
[Epoch 94; Iter   183/  209] train: loss: 0.0352099
[Epoch 94] ogbg-moltox21: 0.767211 val loss: 0.362566
[Epoch 94] ogbg-moltox21: 0.735985 test loss: 0.394023
[Epoch 95; Iter     4/  209] train: loss: 0.0520797
[Epoch 95; Iter    34/  209] train: loss: 0.0442926
[Epoch 95; Iter    64/  209] train: loss: 0.0470714
[Epoch 95; Iter    94/  209] train: loss: 0.0696032
[Epoch 95; Iter   124/  209] train: loss: 0.0751566
[Epoch 95; Iter   154/  209] train: loss: 0.0784303
[Epoch 95; Iter   184/  209] train: loss: 0.0507999
[Epoch 95] ogbg-moltox21: 0.764797 val loss: 0.376962
[Epoch 95] ogbg-moltox21: 0.739687 test loss: 0.407055
[Epoch 96; Iter     5/  209] train: loss: 0.0618263
[Epoch 96; Iter    35/  209] train: loss: 0.0778123
[Epoch 96; Iter    65/  209] train: loss: 0.0744630
[Epoch 96; Iter    95/  209] train: loss: 0.0318206
[Epoch 96; Iter   125/  209] train: loss: 0.0717870
[Epoch 96; Iter   155/  209] train: loss: 0.0453985
[Epoch 96; Iter   185/  209] train: loss: 0.0587368
[Epoch 96] ogbg-moltox21: 0.762416 val loss: 0.370000
[Epoch 96] ogbg-moltox21: 0.738546 test loss: 0.406103
[Epoch 97; Iter     6/  209] train: loss: 0.0569874
[Epoch 97; Iter    36/  209] train: loss: 0.0840739
[Epoch 97; Iter    66/  209] train: loss: 0.0422719
[Epoch 97; Iter    96/  209] train: loss: 0.0453487
[Epoch 97; Iter   126/  209] train: loss: 0.0548819
[Epoch 97; Iter   156/  209] train: loss: 0.0400729
[Epoch 97; Iter   186/  209] train: loss: 0.0559256
[Epoch 97] ogbg-moltox21: 0.769240 val loss: 0.374905
[Epoch 97] ogbg-moltox21: 0.744182 test loss: 0.412765
[Epoch 98; Iter     7/  209] train: loss: 0.0716569
[Epoch 98; Iter    37/  209] train: loss: 0.0229689
[Epoch 98; Iter    67/  209] train: loss: 0.0955286
[Epoch 98; Iter    97/  209] train: loss: 0.0427059
[Epoch 98; Iter   127/  209] train: loss: 0.0631054
[Epoch 98; Iter   157/  209] train: loss: 0.0422629
[Epoch 98; Iter   187/  209] train: loss: 0.0695787
[Epoch 98] ogbg-moltox21: 0.764785 val loss: 0.364929
[Epoch 98] ogbg-moltox21: 0.738199 test loss: 0.406521
[Epoch 99; Iter     8/  209] train: loss: 0.0798317
[Epoch 99; Iter    38/  209] train: loss: 0.0529427
[Epoch 99; Iter    68/  209] train: loss: 0.0486561
[Epoch 99; Iter    98/  209] train: loss: 0.0324142
[Epoch 82; Iter    51/  209] train: loss: 0.0618987
[Epoch 82; Iter    81/  209] train: loss: 0.0449341
[Epoch 82; Iter   111/  209] train: loss: 0.0579248
[Epoch 82; Iter   141/  209] train: loss: 0.0754915
[Epoch 82; Iter   171/  209] train: loss: 0.0814099
[Epoch 82; Iter   201/  209] train: loss: 0.1360220
[Epoch 82] ogbg-moltox21: 0.764469 val loss: 0.348750
[Epoch 82] ogbg-moltox21: 0.740565 test loss: 0.367007
[Epoch 83; Iter    22/  209] train: loss: 0.0766571
[Epoch 83; Iter    52/  209] train: loss: 0.0728367
[Epoch 83; Iter    82/  209] train: loss: 0.0704231
[Epoch 83; Iter   112/  209] train: loss: 0.0813056
[Epoch 83; Iter   142/  209] train: loss: 0.0775624
[Epoch 83; Iter   172/  209] train: loss: 0.0923902
[Epoch 83; Iter   202/  209] train: loss: 0.0775084
[Epoch 83] ogbg-moltox21: 0.763624 val loss: 0.357848
[Epoch 83] ogbg-moltox21: 0.738735 test loss: 0.367767
[Epoch 84; Iter    23/  209] train: loss: 0.0690965
[Epoch 84; Iter    53/  209] train: loss: 0.0519009
[Epoch 84; Iter    83/  209] train: loss: 0.0643766
[Epoch 84; Iter   113/  209] train: loss: 0.0388815
[Epoch 84; Iter   143/  209] train: loss: 0.0753230
[Epoch 84; Iter   173/  209] train: loss: 0.0447903
[Epoch 84; Iter   203/  209] train: loss: 0.0733171
[Epoch 84] ogbg-moltox21: 0.772089 val loss: 0.366735
[Epoch 84] ogbg-moltox21: 0.748239 test loss: 0.379405
[Epoch 85; Iter    24/  209] train: loss: 0.0571397
[Epoch 85; Iter    54/  209] train: loss: 0.1573037
[Epoch 85; Iter    84/  209] train: loss: 0.0291743
[Epoch 85; Iter   114/  209] train: loss: 0.0774560
[Epoch 85; Iter   144/  209] train: loss: 0.0571803
[Epoch 85; Iter   174/  209] train: loss: 0.0949503
[Epoch 85; Iter   204/  209] train: loss: 0.0451714
[Epoch 85] ogbg-moltox21: 0.770534 val loss: 0.366617
[Epoch 85] ogbg-moltox21: 0.747643 test loss: 0.380970
[Epoch 86; Iter    25/  209] train: loss: 0.0647896
[Epoch 86; Iter    55/  209] train: loss: 0.0672433
[Epoch 86; Iter    85/  209] train: loss: 0.0574534
[Epoch 86; Iter   115/  209] train: loss: 0.0574431
[Epoch 86; Iter   145/  209] train: loss: 0.1379589
[Epoch 86; Iter   175/  209] train: loss: 0.0850829
[Epoch 86; Iter   205/  209] train: loss: 0.0805109
[Epoch 86] ogbg-moltox21: 0.771565 val loss: 0.357364
[Epoch 86] ogbg-moltox21: 0.743744 test loss: 0.374504
[Epoch 87; Iter    26/  209] train: loss: 0.0566185
[Epoch 87; Iter    56/  209] train: loss: 0.0890467
[Epoch 87; Iter    86/  209] train: loss: 0.0673653
[Epoch 87; Iter   116/  209] train: loss: 0.0707916
[Epoch 87; Iter   146/  209] train: loss: 0.0529331
[Epoch 87; Iter   176/  209] train: loss: 0.0956231
[Epoch 87; Iter   206/  209] train: loss: 0.1049694
[Epoch 87] ogbg-moltox21: 0.761763 val loss: 0.369728
[Epoch 87] ogbg-moltox21: 0.740796 test loss: 0.385467
[Epoch 88; Iter    27/  209] train: loss: 0.0804161
[Epoch 88; Iter    57/  209] train: loss: 0.0639000
[Epoch 88; Iter    87/  209] train: loss: 0.0600735
[Epoch 88; Iter   117/  209] train: loss: 0.0499138
[Epoch 88; Iter   147/  209] train: loss: 0.0744136
[Epoch 88; Iter   177/  209] train: loss: 0.0719732
[Epoch 88; Iter   207/  209] train: loss: 0.0582153
[Epoch 88] ogbg-moltox21: 0.768913 val loss: 0.368550
[Epoch 88] ogbg-moltox21: 0.738169 test loss: 0.389707
[Epoch 89; Iter    28/  209] train: loss: 0.0523148
[Epoch 89; Iter    58/  209] train: loss: 0.0584561
[Epoch 89; Iter    88/  209] train: loss: 0.0636043
[Epoch 89; Iter   118/  209] train: loss: 0.0506947
[Epoch 89; Iter   148/  209] train: loss: 0.0414525
[Epoch 89; Iter   178/  209] train: loss: 0.0377832
[Epoch 89; Iter   208/  209] train: loss: 0.0281569
[Epoch 89] ogbg-moltox21: 0.762870 val loss: 0.373060
[Epoch 89] ogbg-moltox21: 0.737934 test loss: 0.384859
[Epoch 90; Iter    29/  209] train: loss: 0.0381060
[Epoch 90; Iter    59/  209] train: loss: 0.0502672
[Epoch 90; Iter    89/  209] train: loss: 0.0415649
[Epoch 90; Iter   119/  209] train: loss: 0.0533201
[Epoch 90; Iter   149/  209] train: loss: 0.0280693
[Epoch 90; Iter   179/  209] train: loss: 0.0461210
[Epoch 90; Iter   209/  209] train: loss: 0.0311677
[Epoch 90] ogbg-moltox21: 0.766373 val loss: 0.378081
[Epoch 90] ogbg-moltox21: 0.747540 test loss: 0.390263
[Epoch 91; Iter    30/  209] train: loss: 0.0899279
[Epoch 91; Iter    60/  209] train: loss: 0.0697690
[Epoch 91; Iter    90/  209] train: loss: 0.1138656
[Epoch 91; Iter   120/  209] train: loss: 0.0713744
[Epoch 91; Iter   150/  209] train: loss: 0.0590551
[Epoch 91; Iter   180/  209] train: loss: 0.0901183
[Epoch 91] ogbg-moltox21: 0.766474 val loss: 0.385154
[Epoch 91] ogbg-moltox21: 0.741149 test loss: 0.398550
[Epoch 92; Iter     1/  209] train: loss: 0.0452493
[Epoch 92; Iter    31/  209] train: loss: 0.0570361
[Epoch 92; Iter    61/  209] train: loss: 0.0448283
[Epoch 92; Iter    91/  209] train: loss: 0.0383940
[Epoch 92; Iter   121/  209] train: loss: 0.0677393
[Epoch 92; Iter   151/  209] train: loss: 0.0379466
[Epoch 92; Iter   181/  209] train: loss: 0.0451292
[Epoch 92] ogbg-moltox21: 0.768387 val loss: 0.375514
[Epoch 92] ogbg-moltox21: 0.740032 test loss: 0.394338
[Epoch 93; Iter     2/  209] train: loss: 0.0453069
[Epoch 93; Iter    32/  209] train: loss: 0.0762345
[Epoch 93; Iter    62/  209] train: loss: 0.0340750
[Epoch 93; Iter    92/  209] train: loss: 0.0592831
[Epoch 93; Iter   122/  209] train: loss: 0.0344887
[Epoch 93; Iter   152/  209] train: loss: 0.0450272
[Epoch 93; Iter   182/  209] train: loss: 0.0563840
[Epoch 93] ogbg-moltox21: 0.766559 val loss: 0.385737
[Epoch 93] ogbg-moltox21: 0.735757 test loss: 0.410944
[Epoch 94; Iter     3/  209] train: loss: 0.0287059
[Epoch 94; Iter    33/  209] train: loss: 0.0534897
[Epoch 94; Iter    63/  209] train: loss: 0.0250994
[Epoch 94; Iter    93/  209] train: loss: 0.0329187
[Epoch 94; Iter   123/  209] train: loss: 0.0426535
[Epoch 94; Iter   153/  209] train: loss: 0.0558720
[Epoch 94; Iter   183/  209] train: loss: 0.0815137
[Epoch 94] ogbg-moltox21: 0.768280 val loss: 0.376541
[Epoch 94] ogbg-moltox21: 0.733417 test loss: 0.398625
[Epoch 95; Iter     4/  209] train: loss: 0.0719737
[Epoch 95; Iter    34/  209] train: loss: 0.0535551
[Epoch 95; Iter    64/  209] train: loss: 0.0761621
[Epoch 95; Iter    94/  209] train: loss: 0.0382455
[Epoch 95; Iter   124/  209] train: loss: 0.0495303
[Epoch 95; Iter   154/  209] train: loss: 0.0389680
[Epoch 95; Iter   184/  209] train: loss: 0.0820463
[Epoch 95] ogbg-moltox21: 0.766751 val loss: 0.384135
[Epoch 95] ogbg-moltox21: 0.740928 test loss: 0.398758
[Epoch 96; Iter     5/  209] train: loss: 0.0424291
[Epoch 96; Iter    35/  209] train: loss: 0.0490628
[Epoch 96; Iter    65/  209] train: loss: 0.0476473
[Epoch 96; Iter    95/  209] train: loss: 0.0649900
[Epoch 96; Iter   125/  209] train: loss: 0.0463048
[Epoch 96; Iter   155/  209] train: loss: 0.0758410
[Epoch 96; Iter   185/  209] train: loss: 0.0695364
[Epoch 96] ogbg-moltox21: 0.769237 val loss: 0.378751
[Epoch 96] ogbg-moltox21: 0.734548 test loss: 0.407925
[Epoch 97; Iter     6/  209] train: loss: 0.0576056
[Epoch 97; Iter    36/  209] train: loss: 0.0556273
[Epoch 97; Iter    66/  209] train: loss: 0.0664008
[Epoch 97; Iter    96/  209] train: loss: 0.0410193
[Epoch 97; Iter   126/  209] train: loss: 0.0435159
[Epoch 97; Iter   156/  209] train: loss: 0.1048922
[Epoch 97; Iter   186/  209] train: loss: 0.0628123
[Epoch 97] ogbg-moltox21: 0.769056 val loss: 0.389096
[Epoch 97] ogbg-moltox21: 0.732666 test loss: 0.408378
[Epoch 98; Iter     7/  209] train: loss: 0.0439716
[Epoch 98; Iter    37/  209] train: loss: 0.0620586
[Epoch 98; Iter    67/  209] train: loss: 0.0385408
[Epoch 98; Iter    97/  209] train: loss: 0.0795239
[Epoch 98; Iter   127/  209] train: loss: 0.0518969
[Epoch 98; Iter   157/  209] train: loss: 0.0549812
[Epoch 98; Iter   187/  209] train: loss: 0.0711216
[Epoch 98] ogbg-moltox21: 0.762572 val loss: 0.396344
[Epoch 98] ogbg-moltox21: 0.730199 test loss: 0.418281
[Epoch 99; Iter     8/  209] train: loss: 0.0311178
[Epoch 99; Iter    38/  209] train: loss: 0.0231707
[Epoch 99; Iter    68/  209] train: loss: 0.0613881
[Epoch 99; Iter    98/  209] train: loss: 0.0502713
[Epoch 99; Iter   128/  209] train: loss: 0.0422252
[Epoch 99; Iter   158/  209] train: loss: 0.0598856
[Epoch 99; Iter   188/  209] train: loss: 0.0763283
[Epoch 99] ogbg-moltox21: 0.769635 val loss: 0.393763
[Epoch 99] ogbg-moltox21: 0.750283 test loss: 0.418195
[Epoch 100; Iter     9/  209] train: loss: 0.0430598
[Epoch 100; Iter    39/  209] train: loss: 0.0532707
[Epoch 100; Iter    69/  209] train: loss: 0.0904819
[Epoch 100; Iter    99/  209] train: loss: 0.0473440
[Epoch 100; Iter   129/  209] train: loss: 0.0538159
[Epoch 100; Iter   159/  209] train: loss: 0.0849797
[Epoch 100; Iter   189/  209] train: loss: 0.0492275
[Epoch 100] ogbg-moltox21: 0.771935 val loss: 0.389311
[Epoch 100] ogbg-moltox21: 0.756846 test loss: 0.410103
[Epoch 101; Iter    10/  209] train: loss: 0.0449635
[Epoch 101; Iter    40/  209] train: loss: 0.0739472
[Epoch 101; Iter    70/  209] train: loss: 0.0491348
[Epoch 101; Iter   100/  209] train: loss: 0.0785540
[Epoch 101; Iter   130/  209] train: loss: 0.0448924
[Epoch 101; Iter   160/  209] train: loss: 0.0447485
[Epoch 101; Iter   190/  209] train: loss: 0.0430514
[Epoch 101] ogbg-moltox21: 0.768222 val loss: 0.396218
[Epoch 101] ogbg-moltox21: 0.749327 test loss: 0.420695
[Epoch 102; Iter    11/  209] train: loss: 0.0387093
[Epoch 102; Iter    41/  209] train: loss: 0.0610917
[Epoch 102; Iter    71/  209] train: loss: 0.0272073
[Epoch 102; Iter   101/  209] train: loss: 0.0427354
[Epoch 102; Iter   131/  209] train: loss: 0.0923425
[Epoch 102; Iter   161/  209] train: loss: 0.0863785
[Epoch 102; Iter   191/  209] train: loss: 0.0335162
[Epoch 102] ogbg-moltox21: 0.764315 val loss: 0.397190
[Epoch 102] ogbg-moltox21: 0.751960 test loss: 0.412753
[Epoch 103; Iter    12/  209] train: loss: 0.0491574
[Epoch 103; Iter    42/  209] train: loss: 0.0614981
[Epoch 103; Iter    72/  209] train: loss: 0.0496423
[Epoch 103; Iter   102/  209] train: loss: 0.0480793
[Epoch 103; Iter   132/  209] train: loss: 0.0677397
[Epoch 103; Iter   162/  209] train: loss: 0.0483793
[Epoch 103; Iter   192/  209] train: loss: 0.0575369
[Epoch 103] ogbg-moltox21: 0.761736 val loss: 1.018693
[Epoch 103] ogbg-moltox21: 0.751319 test loss: 0.408870
[Epoch 104; Iter    13/  209] train: loss: 0.0450139
[Epoch 104; Iter    43/  209] train: loss: 0.0625392
[Epoch 104; Iter    73/  209] train: loss: 0.0472152
[Epoch 104; Iter   103/  209] train: loss: 0.0447416
[Epoch 104; Iter   133/  209] train: loss: 0.0758424
[Epoch 104; Iter   163/  209] train: loss: 0.0467926
[Epoch 104; Iter   193/  209] train: loss: 0.0770178
[Epoch 104] ogbg-moltox21: 0.773518 val loss: 0.477855
[Epoch 104] ogbg-moltox21: 0.750437 test loss: 0.422820
[Epoch 105; Iter    14/  209] train: loss: 0.0383089
[Epoch 105; Iter    44/  209] train: loss: 0.0535987
[Epoch 105; Iter    74/  209] train: loss: 0.0480465
[Epoch 105; Iter   104/  209] train: loss: 0.0342565
[Epoch 105; Iter   134/  209] train: loss: 0.0494615
[Epoch 105; Iter   164/  209] train: loss: 0.0511273
[Epoch 105; Iter   194/  209] train: loss: 0.0327778
[Epoch 105] ogbg-moltox21: 0.765108 val loss: 0.407527
[Epoch 105] ogbg-moltox21: 0.747211 test loss: 0.421745
[Epoch 106; Iter    15/  209] train: loss: 0.0400211
[Epoch 106; Iter    45/  209] train: loss: 0.0460862
[Epoch 106; Iter    75/  209] train: loss: 0.0590138
[Epoch 106; Iter   105/  209] train: loss: 0.1056321
[Epoch 106; Iter   135/  209] train: loss: 0.0421450
[Epoch 106; Iter   165/  209] train: loss: 0.0574752
[Epoch 106; Iter   195/  209] train: loss: 0.0457006
[Epoch 106] ogbg-moltox21: 0.764220 val loss: 0.414066
[Epoch 106] ogbg-moltox21: 0.753435 test loss: 0.423346
[Epoch 107; Iter    16/  209] train: loss: 0.0530809
[Epoch 107; Iter    46/  209] train: loss: 0.0703427
[Epoch 107; Iter    76/  209] train: loss: 0.0294883
[Epoch 107; Iter   106/  209] train: loss: 0.0567525
[Epoch 107; Iter   136/  209] train: loss: 0.0650866
[Epoch 107; Iter   166/  209] train: loss: 0.0400370
[Epoch 107; Iter   196/  209] train: loss: 0.0376733
[Epoch 107] ogbg-moltox21: 0.765932 val loss: 0.458659
[Epoch 107] ogbg-moltox21: 0.751537 test loss: 0.425243
[Epoch 108; Iter    17/  209] train: loss: 0.0624394
[Epoch 108; Iter    47/  209] train: loss: 0.0391591
[Epoch 108; Iter    77/  209] train: loss: 0.0594673
[Epoch 108; Iter   107/  209] train: loss: 0.0583640
[Epoch 108; Iter   137/  209] train: loss: 0.0344473
[Epoch 108; Iter   167/  209] train: loss: 0.0599930
[Epoch 108; Iter   197/  209] train: loss: 0.0455084
[Epoch 108] ogbg-moltox21: 0.770784 val loss: 0.415613
[Epoch 108] ogbg-moltox21: 0.749487 test loss: 0.435710
[Epoch 109; Iter    18/  209] train: loss: 0.0780917
[Epoch 109; Iter    48/  209] train: loss: 0.0382983
[Epoch 109; Iter    78/  209] train: loss: 0.0309349
[Epoch 109; Iter   108/  209] train: loss: 0.0631758
[Epoch 109; Iter   138/  209] train: loss: 0.0586352
[Epoch 109; Iter   168/  209] train: loss: 0.0539554
[Epoch 109; Iter   198/  209] train: loss: 0.0414301
[Epoch 109] ogbg-moltox21: 0.763960 val loss: 0.412501
[Epoch 109] ogbg-moltox21: 0.750291 test loss: 0.430714
[Epoch 110; Iter    19/  209] train: loss: 0.0517359
[Epoch 110; Iter    49/  209] train: loss: 0.0446582
[Epoch 110; Iter    79/  209] train: loss: 0.0613782
[Epoch 110; Iter   109/  209] train: loss: 0.0485042
[Epoch 110; Iter   139/  209] train: loss: 0.0701417
[Epoch 110; Iter   169/  209] train: loss: 0.0290669
[Epoch 110; Iter   199/  209] train: loss: 0.0628970
[Epoch 110] ogbg-moltox21: 0.769075 val loss: 0.424003
[Epoch 110] ogbg-moltox21: 0.750605 test loss: 0.434412
[Epoch 111; Iter    20/  209] train: loss: 0.0609167
[Epoch 111; Iter    50/  209] train: loss: 0.0357492
[Epoch 111; Iter    80/  209] train: loss: 0.0316232
[Epoch 111; Iter   110/  209] train: loss: 0.0481338
[Epoch 111; Iter   140/  209] train: loss: 0.0293793
[Epoch 111; Iter   170/  209] train: loss: 0.0904852
[Epoch 111; Iter   200/  209] train: loss: 0.0257265
[Epoch 111] ogbg-moltox21: 0.768781 val loss: 0.898006
[Epoch 111] ogbg-moltox21: 0.750397 test loss: 0.438372
[Epoch 112; Iter    21/  209] train: loss: 0.0297678
[Epoch 112; Iter    51/  209] train: loss: 0.0464202
[Epoch 112; Iter    81/  209] train: loss: 0.0354692
[Epoch 112; Iter   111/  209] train: loss: 0.0566671
[Epoch 112; Iter   141/  209] train: loss: 0.0253659
[Epoch 112; Iter   171/  209] train: loss: 0.0406269
[Epoch 112; Iter   201/  209] train: loss: 0.0393580
[Epoch 112] ogbg-moltox21: 0.764384 val loss: 0.748466
[Epoch 112] ogbg-moltox21: 0.747785 test loss: 0.443145
[Epoch 113; Iter    22/  209] train: loss: 0.0957210
[Epoch 113; Iter    52/  209] train: loss: 0.0296597
[Epoch 113; Iter    82/  209] train: loss: 0.0936147
[Epoch 113; Iter   112/  209] train: loss: 0.0735023
[Epoch 113; Iter   142/  209] train: loss: 0.0505304
[Epoch 113; Iter   172/  209] train: loss: 0.0545228
[Epoch 113; Iter   202/  209] train: loss: 0.0382706
[Epoch 113] ogbg-moltox21: 0.767281 val loss: 0.423140
[Epoch 113] ogbg-moltox21: 0.747407 test loss: 0.444307
[Epoch 114; Iter    23/  209] train: loss: 0.0888485
[Epoch 114; Iter    53/  209] train: loss: 0.0285785
[Epoch 114; Iter    83/  209] train: loss: 0.0457475
[Epoch 114; Iter   113/  209] train: loss: 0.0282863
[Epoch 114; Iter   143/  209] train: loss: 0.0370389
[Epoch 114; Iter   173/  209] train: loss: 0.0335093
[Epoch 114; Iter   203/  209] train: loss: 0.0506069
[Epoch 114] ogbg-moltox21: 0.765436 val loss: 0.883401
[Epoch 114] ogbg-moltox21: 0.747277 test loss: 0.443718
[Epoch 115; Iter    24/  209] train: loss: 0.0437398
[Epoch 115; Iter    54/  209] train: loss: 0.0295948
[Epoch 115; Iter    84/  209] train: loss: 0.0772714
[Epoch 115; Iter   114/  209] train: loss: 0.0374028
[Epoch 115; Iter   144/  209] train: loss: 0.0372517
[Epoch 115; Iter   174/  209] train: loss: 0.0842457
[Epoch 115; Iter   204/  209] train: loss: 0.0196869
[Epoch 115] ogbg-moltox21: 0.766863 val loss: 0.431738
[Epoch 115] ogbg-moltox21: 0.751517 test loss: 0.451075
[Epoch 116; Iter    25/  209] train: loss: 0.0637510
[Epoch 116; Iter    55/  209] train: loss: 0.0417524
[Epoch 116; Iter    85/  209] train: loss: 0.0393624
[Epoch 116; Iter   115/  209] train: loss: 0.0482141
[Epoch 99; Iter   128/  209] train: loss: 0.0357223
[Epoch 99; Iter   158/  209] train: loss: 0.0530077
[Epoch 99; Iter   188/  209] train: loss: 0.0555882
[Epoch 99] ogbg-moltox21: 0.759754 val loss: 0.365911
[Epoch 99] ogbg-moltox21: 0.733158 test loss: 0.405832
[Epoch 100; Iter     9/  209] train: loss: 0.0348370
[Epoch 100; Iter    39/  209] train: loss: 0.0653100
[Epoch 100; Iter    69/  209] train: loss: 0.0762680
[Epoch 100; Iter    99/  209] train: loss: 0.0382927
[Epoch 100; Iter   129/  209] train: loss: 0.0450824
[Epoch 100; Iter   159/  209] train: loss: 0.0395282
[Epoch 100; Iter   189/  209] train: loss: 0.0528373
[Epoch 100] ogbg-moltox21: 0.764712 val loss: 0.366492
[Epoch 100] ogbg-moltox21: 0.735252 test loss: 0.410084
[Epoch 101; Iter    10/  209] train: loss: 0.0721320
[Epoch 101; Iter    40/  209] train: loss: 0.0394876
[Epoch 101; Iter    70/  209] train: loss: 0.0441982
[Epoch 101; Iter   100/  209] train: loss: 0.0416623
[Epoch 101; Iter   130/  209] train: loss: 0.0458070
[Epoch 101; Iter   160/  209] train: loss: 0.0544141
[Epoch 101; Iter   190/  209] train: loss: 0.0667176
[Epoch 101] ogbg-moltox21: 0.765545 val loss: 0.367378
[Epoch 101] ogbg-moltox21: 0.737910 test loss: 0.407731
[Epoch 102; Iter    11/  209] train: loss: 0.0232990
[Epoch 102; Iter    41/  209] train: loss: 0.0781660
[Epoch 102; Iter    71/  209] train: loss: 0.0581962
[Epoch 102; Iter   101/  209] train: loss: 0.0707053
[Epoch 102; Iter   131/  209] train: loss: 0.0503544
[Epoch 102; Iter   161/  209] train: loss: 0.0660271
[Epoch 102; Iter   191/  209] train: loss: 0.0565958
[Epoch 102] ogbg-moltox21: 0.764279 val loss: 0.368216
[Epoch 102] ogbg-moltox21: 0.737586 test loss: 0.407658
[Epoch 103; Iter    12/  209] train: loss: 0.0499284
[Epoch 103; Iter    42/  209] train: loss: 0.0505579
[Epoch 103; Iter    72/  209] train: loss: 0.0538126
[Epoch 103; Iter   102/  209] train: loss: 0.0474095
[Epoch 103; Iter   132/  209] train: loss: 0.0529953
[Epoch 103; Iter   162/  209] train: loss: 0.0458966
[Epoch 103; Iter   192/  209] train: loss: 0.0770103
[Epoch 103] ogbg-moltox21: 0.761676 val loss: 0.368081
[Epoch 103] ogbg-moltox21: 0.733932 test loss: 0.414952
[Epoch 104; Iter    13/  209] train: loss: 0.0743702
[Epoch 104; Iter    43/  209] train: loss: 0.0456868
[Epoch 104; Iter    73/  209] train: loss: 0.0505409
[Epoch 104; Iter   103/  209] train: loss: 0.0503988
[Epoch 104; Iter   133/  209] train: loss: 0.0533989
[Epoch 104; Iter   163/  209] train: loss: 0.0845332
[Epoch 104; Iter   193/  209] train: loss: 0.0653475
[Epoch 104] ogbg-moltox21: 0.764118 val loss: 0.373357
[Epoch 104] ogbg-moltox21: 0.734091 test loss: 0.413528
[Epoch 105; Iter    14/  209] train: loss: 0.0367552
[Epoch 105; Iter    44/  209] train: loss: 0.0420498
[Epoch 105; Iter    74/  209] train: loss: 0.0559877
[Epoch 105; Iter   104/  209] train: loss: 0.0529018
[Epoch 105; Iter   134/  209] train: loss: 0.0235855
[Epoch 105; Iter   164/  209] train: loss: 0.0811111
[Epoch 105; Iter   194/  209] train: loss: 0.0434605
[Epoch 105] ogbg-moltox21: 0.761834 val loss: 0.371899
[Epoch 105] ogbg-moltox21: 0.734462 test loss: 0.421683
[Epoch 106; Iter    15/  209] train: loss: 0.0271738
[Epoch 106; Iter    45/  209] train: loss: 0.0412620
[Epoch 106; Iter    75/  209] train: loss: 0.0382544
[Epoch 106; Iter   105/  209] train: loss: 0.0526250
[Epoch 106; Iter   135/  209] train: loss: 0.0467312
[Epoch 106; Iter   165/  209] train: loss: 0.0373787
[Epoch 106; Iter   195/  209] train: loss: 0.0386221
[Epoch 106] ogbg-moltox21: 0.764679 val loss: 0.377075
[Epoch 106] ogbg-moltox21: 0.737593 test loss: 0.423785
[Epoch 107; Iter    16/  209] train: loss: 0.0569139
[Epoch 107; Iter    46/  209] train: loss: 0.0927784
[Epoch 107; Iter    76/  209] train: loss: 0.0617257
[Epoch 107; Iter   106/  209] train: loss: 0.0614799
[Epoch 107; Iter   136/  209] train: loss: 0.0618556
[Epoch 107; Iter   166/  209] train: loss: 0.0458307
[Epoch 107; Iter   196/  209] train: loss: 0.0621799
[Epoch 107] ogbg-moltox21: 0.763804 val loss: 0.379234
[Epoch 107] ogbg-moltox21: 0.735183 test loss: 0.426696
[Epoch 108; Iter    17/  209] train: loss: 0.0352169
[Epoch 108; Iter    47/  209] train: loss: 0.0428649
[Epoch 108; Iter    77/  209] train: loss: 0.0367027
[Epoch 108; Iter   107/  209] train: loss: 0.0615185
[Epoch 108; Iter   137/  209] train: loss: 0.0749551
[Epoch 108; Iter   167/  209] train: loss: 0.0431823
[Epoch 108; Iter   197/  209] train: loss: 0.0685259
[Epoch 108] ogbg-moltox21: 0.761335 val loss: 0.375873
[Epoch 108] ogbg-moltox21: 0.739290 test loss: 0.424339
[Epoch 109; Iter    18/  209] train: loss: 0.0297174
[Epoch 109; Iter    48/  209] train: loss: 0.0365344
[Epoch 109; Iter    78/  209] train: loss: 0.0411330
[Epoch 109; Iter   108/  209] train: loss: 0.0677684
[Epoch 109; Iter   138/  209] train: loss: 0.0555284
[Epoch 109; Iter   168/  209] train: loss: 0.0845424
[Epoch 109; Iter   198/  209] train: loss: 0.0391602
[Epoch 109] ogbg-moltox21: 0.761318 val loss: 0.376638
[Epoch 109] ogbg-moltox21: 0.735324 test loss: 0.423456
[Epoch 110; Iter    19/  209] train: loss: 0.0503217
[Epoch 110; Iter    49/  209] train: loss: 0.0549838
[Epoch 110; Iter    79/  209] train: loss: 0.0731716
[Epoch 110; Iter   109/  209] train: loss: 0.0417438
[Epoch 110; Iter   139/  209] train: loss: 0.0605260
[Epoch 110; Iter   169/  209] train: loss: 0.0604600
[Epoch 110; Iter   199/  209] train: loss: 0.0502813
[Epoch 110] ogbg-moltox21: 0.759955 val loss: 0.395117
[Epoch 110] ogbg-moltox21: 0.737792 test loss: 0.447630
[Epoch 111; Iter    20/  209] train: loss: 0.0544812
[Epoch 111; Iter    50/  209] train: loss: 0.0610055
[Epoch 111; Iter    80/  209] train: loss: 0.0403724
[Epoch 111; Iter   110/  209] train: loss: 0.0238261
[Epoch 111; Iter   140/  209] train: loss: 0.0821762
[Epoch 111; Iter   170/  209] train: loss: 0.0566673
[Epoch 111; Iter   200/  209] train: loss: 0.0519172
[Epoch 111] ogbg-moltox21: 0.760930 val loss: 0.386269
[Epoch 111] ogbg-moltox21: 0.740216 test loss: 0.425157
[Epoch 112; Iter    21/  209] train: loss: 0.0489333
[Epoch 112; Iter    51/  209] train: loss: 0.0842096
[Epoch 112; Iter    81/  209] train: loss: 0.0470129
[Epoch 112; Iter   111/  209] train: loss: 0.0461475
[Epoch 112; Iter   141/  209] train: loss: 0.0489509
[Epoch 112; Iter   171/  209] train: loss: 0.0572463
[Epoch 112; Iter   201/  209] train: loss: 0.0473540
[Epoch 112] ogbg-moltox21: 0.764401 val loss: 0.392562
[Epoch 112] ogbg-moltox21: 0.735063 test loss: 0.441351
[Epoch 113; Iter    22/  209] train: loss: 0.0303887
[Epoch 113; Iter    52/  209] train: loss: 0.0704770
[Epoch 113; Iter    82/  209] train: loss: 0.0588945
[Epoch 113; Iter   112/  209] train: loss: 0.0564188
[Epoch 113; Iter   142/  209] train: loss: 0.0633623
[Epoch 113; Iter   172/  209] train: loss: 0.0806832
[Epoch 113; Iter   202/  209] train: loss: 0.0501494
[Epoch 113] ogbg-moltox21: 0.755564 val loss: 0.394325
[Epoch 113] ogbg-moltox21: 0.735181 test loss: 0.432569
[Epoch 114; Iter    23/  209] train: loss: 0.0426242
[Epoch 114; Iter    53/  209] train: loss: 0.0299127
[Epoch 114; Iter    83/  209] train: loss: 0.0269559
[Epoch 114; Iter   113/  209] train: loss: 0.0612903
[Epoch 114; Iter   143/  209] train: loss: 0.0430266
[Epoch 114; Iter   173/  209] train: loss: 0.0475422
[Epoch 114; Iter   203/  209] train: loss: 0.0519904
[Epoch 114] ogbg-moltox21: 0.758369 val loss: 0.393303
[Epoch 114] ogbg-moltox21: 0.732585 test loss: 0.438141
[Epoch 115; Iter    24/  209] train: loss: 0.0702437
[Epoch 115; Iter    54/  209] train: loss: 0.0643229
[Epoch 115; Iter    84/  209] train: loss: 0.0463450
[Epoch 115; Iter   114/  209] train: loss: 0.0361290
[Epoch 115; Iter   144/  209] train: loss: 0.0432941
[Epoch 115; Iter   174/  209] train: loss: 0.0720131
[Epoch 115; Iter   204/  209] train: loss: 0.0505169
[Epoch 115] ogbg-moltox21: 0.754568 val loss: 0.400115
[Epoch 115] ogbg-moltox21: 0.731947 test loss: 0.445380
[Epoch 116; Iter    25/  209] train: loss: 0.1028220
[Epoch 116; Iter    55/  209] train: loss: 0.0438389
[Epoch 116; Iter    85/  209] train: loss: 0.0227952
[Epoch 116; Iter   115/  209] train: loss: 0.0440212
[Epoch 99; Iter   128/  209] train: loss: 0.0639406
[Epoch 99; Iter   158/  209] train: loss: 0.0618955
[Epoch 99; Iter   188/  209] train: loss: 0.0346412
[Epoch 99] ogbg-moltox21: 0.763916 val loss: 0.397324
[Epoch 99] ogbg-moltox21: 0.734041 test loss: 0.415306
[Epoch 100; Iter     9/  209] train: loss: 0.0540571
[Epoch 100; Iter    39/  209] train: loss: 0.0671841
[Epoch 100; Iter    69/  209] train: loss: 0.0519816
[Epoch 100; Iter    99/  209] train: loss: 0.0820131
[Epoch 100; Iter   129/  209] train: loss: 0.0819688
[Epoch 100; Iter   159/  209] train: loss: 0.0627181
[Epoch 100; Iter   189/  209] train: loss: 0.0453008
[Epoch 100] ogbg-moltox21: 0.763177 val loss: 0.400458
[Epoch 100] ogbg-moltox21: 0.733166 test loss: 0.415816
[Epoch 101; Iter    10/  209] train: loss: 0.0329556
[Epoch 101; Iter    40/  209] train: loss: 0.0326241
[Epoch 101; Iter    70/  209] train: loss: 0.0494555
[Epoch 101; Iter   100/  209] train: loss: 0.0796773
[Epoch 101; Iter   130/  209] train: loss: 0.0520968
[Epoch 101; Iter   160/  209] train: loss: 0.0953428
[Epoch 101; Iter   190/  209] train: loss: 0.0559012
[Epoch 101] ogbg-moltox21: 0.760543 val loss: 0.396502
[Epoch 101] ogbg-moltox21: 0.729929 test loss: 0.410706
[Epoch 102; Iter    11/  209] train: loss: 0.0582722
[Epoch 102; Iter    41/  209] train: loss: 0.0378484
[Epoch 102; Iter    71/  209] train: loss: 0.0434637
[Epoch 102; Iter   101/  209] train: loss: 0.0269264
[Epoch 102; Iter   131/  209] train: loss: 0.0416908
[Epoch 102; Iter   161/  209] train: loss: 0.0757715
[Epoch 102; Iter   191/  209] train: loss: 0.0851650
[Epoch 102] ogbg-moltox21: 0.764148 val loss: 0.400815
[Epoch 102] ogbg-moltox21: 0.733118 test loss: 0.413862
[Epoch 103; Iter    12/  209] train: loss: 0.0243089
[Epoch 103; Iter    42/  209] train: loss: 0.0490319
[Epoch 103; Iter    72/  209] train: loss: 0.0338537
[Epoch 103; Iter   102/  209] train: loss: 0.0441107
[Epoch 103; Iter   132/  209] train: loss: 0.0887236
[Epoch 103; Iter   162/  209] train: loss: 0.1199201
[Epoch 103; Iter   192/  209] train: loss: 0.0446603
[Epoch 103] ogbg-moltox21: 0.766919 val loss: 0.400051
[Epoch 103] ogbg-moltox21: 0.732040 test loss: 0.422808
[Epoch 104; Iter    13/  209] train: loss: 0.0534504
[Epoch 104; Iter    43/  209] train: loss: 0.0475091
[Epoch 104; Iter    73/  209] train: loss: 0.0406959
[Epoch 104; Iter   103/  209] train: loss: 0.0805188
[Epoch 104; Iter   133/  209] train: loss: 0.0460962
[Epoch 104; Iter   163/  209] train: loss: 0.0612581
[Epoch 104; Iter   193/  209] train: loss: 0.0448681
[Epoch 104] ogbg-moltox21: 0.763665 val loss: 0.404213
[Epoch 104] ogbg-moltox21: 0.731649 test loss: 0.425064
[Epoch 105; Iter    14/  209] train: loss: 0.0349327
[Epoch 105; Iter    44/  209] train: loss: 0.0240448
[Epoch 105; Iter    74/  209] train: loss: 0.0326401
[Epoch 105; Iter   104/  209] train: loss: 0.0416791
[Epoch 105; Iter   134/  209] train: loss: 0.0343734
[Epoch 105; Iter   164/  209] train: loss: 0.0277482
[Epoch 105; Iter   194/  209] train: loss: 0.0254552
[Epoch 105] ogbg-moltox21: 0.766981 val loss: 0.404994
[Epoch 105] ogbg-moltox21: 0.740032 test loss: 0.421634
[Epoch 106; Iter    15/  209] train: loss: 0.0520605
[Epoch 106; Iter    45/  209] train: loss: 0.0554476
[Epoch 106; Iter    75/  209] train: loss: 0.0659989
[Epoch 106; Iter   105/  209] train: loss: 0.0572817
[Epoch 106; Iter   135/  209] train: loss: 0.0429615
[Epoch 106; Iter   165/  209] train: loss: 0.0503818
[Epoch 106; Iter   195/  209] train: loss: 0.0173906
[Epoch 106] ogbg-moltox21: 0.755645 val loss: 0.418847
[Epoch 106] ogbg-moltox21: 0.734140 test loss: 0.425220
[Epoch 107; Iter    16/  209] train: loss: 0.0383975
[Epoch 107; Iter    46/  209] train: loss: 0.0388285
[Epoch 107; Iter    76/  209] train: loss: 0.0976772
[Epoch 107; Iter   106/  209] train: loss: 0.0468682
[Epoch 107; Iter   136/  209] train: loss: 0.0274435
[Epoch 107; Iter   166/  209] train: loss: 0.0473426
[Epoch 107; Iter   196/  209] train: loss: 0.0447963
[Epoch 107] ogbg-moltox21: 0.760648 val loss: 0.407522
[Epoch 107] ogbg-moltox21: 0.730572 test loss: 0.425091
[Epoch 108; Iter    17/  209] train: loss: 0.0488719
[Epoch 108; Iter    47/  209] train: loss: 0.0838609
[Epoch 108; Iter    77/  209] train: loss: 0.0567240
[Epoch 108; Iter   107/  209] train: loss: 0.0903190
[Epoch 108; Iter   137/  209] train: loss: 0.0496091
[Epoch 108; Iter   167/  209] train: loss: 0.0297856
[Epoch 108; Iter   197/  209] train: loss: 0.0687082
[Epoch 108] ogbg-moltox21: 0.762941 val loss: 0.420104
[Epoch 108] ogbg-moltox21: 0.728736 test loss: 0.441269
[Epoch 109; Iter    18/  209] train: loss: 0.0263115
[Epoch 109; Iter    48/  209] train: loss: 0.0511953
[Epoch 109; Iter    78/  209] train: loss: 0.0321436
[Epoch 109; Iter   108/  209] train: loss: 0.0775512
[Epoch 109; Iter   138/  209] train: loss: 0.0383410
[Epoch 109; Iter   168/  209] train: loss: 0.0256768
[Epoch 109; Iter   198/  209] train: loss: 0.0292757
[Epoch 109] ogbg-moltox21: 0.762287 val loss: 0.422048
[Epoch 109] ogbg-moltox21: 0.734282 test loss: 0.436619
[Epoch 110; Iter    19/  209] train: loss: 0.0303146
[Epoch 110; Iter    49/  209] train: loss: 0.0671088
[Epoch 110; Iter    79/  209] train: loss: 0.0462032
[Epoch 110; Iter   109/  209] train: loss: 0.0477268
[Epoch 110; Iter   139/  209] train: loss: 0.0640828
[Epoch 110; Iter   169/  209] train: loss: 0.0449132
[Epoch 110; Iter   199/  209] train: loss: 0.0544959
[Epoch 110] ogbg-moltox21: 0.761972 val loss: 0.414810
[Epoch 110] ogbg-moltox21: 0.729922 test loss: 0.440462
[Epoch 111; Iter    20/  209] train: loss: 0.0524903
[Epoch 111; Iter    50/  209] train: loss: 0.0506231
[Epoch 111; Iter    80/  209] train: loss: 0.0464797
[Epoch 111; Iter   110/  209] train: loss: 0.0338288
[Epoch 111; Iter   140/  209] train: loss: 0.0336088
[Epoch 111; Iter   170/  209] train: loss: 0.0398238
[Epoch 111; Iter   200/  209] train: loss: 0.0382293
[Epoch 111] ogbg-moltox21: 0.764205 val loss: 0.414056
[Epoch 111] ogbg-moltox21: 0.724834 test loss: 0.438458
[Epoch 112; Iter    21/  209] train: loss: 0.0444940
[Epoch 112; Iter    51/  209] train: loss: 0.0337030
[Epoch 112; Iter    81/  209] train: loss: 0.0530829
[Epoch 112; Iter   111/  209] train: loss: 0.0397111
[Epoch 112; Iter   141/  209] train: loss: 0.0644203
[Epoch 112; Iter   171/  209] train: loss: 0.0447681
[Epoch 112; Iter   201/  209] train: loss: 0.0710638
[Epoch 112] ogbg-moltox21: 0.767595 val loss: 0.416976
[Epoch 112] ogbg-moltox21: 0.735032 test loss: 0.438912
[Epoch 113; Iter    22/  209] train: loss: 0.0703214
[Epoch 113; Iter    52/  209] train: loss: 0.0313136
[Epoch 113; Iter    82/  209] train: loss: 0.0381817
[Epoch 113; Iter   112/  209] train: loss: 0.0429131
[Epoch 113; Iter   142/  209] train: loss: 0.0437863
[Epoch 113; Iter   172/  209] train: loss: 0.0257128
[Epoch 113; Iter   202/  209] train: loss: 0.0617956
[Epoch 113] ogbg-moltox21: 0.762465 val loss: 0.423064
[Epoch 113] ogbg-moltox21: 0.727918 test loss: 0.438241
[Epoch 114; Iter    23/  209] train: loss: 0.0294993
[Epoch 114; Iter    53/  209] train: loss: 0.0668000
[Epoch 114; Iter    83/  209] train: loss: 0.0591454
[Epoch 114; Iter   113/  209] train: loss: 0.0455565
[Epoch 114; Iter   143/  209] train: loss: 0.0270174
[Epoch 114; Iter   173/  209] train: loss: 0.0217145
[Epoch 114; Iter   203/  209] train: loss: 0.0368815
[Epoch 114] ogbg-moltox21: 0.763281 val loss: 0.420558
[Epoch 114] ogbg-moltox21: 0.730052 test loss: 0.433704
[Epoch 115; Iter    24/  209] train: loss: 0.0349787
[Epoch 115; Iter    54/  209] train: loss: 0.0454402
[Epoch 115; Iter    84/  209] train: loss: 0.0427737
[Epoch 115; Iter   114/  209] train: loss: 0.0438981
[Epoch 115; Iter   144/  209] train: loss: 0.0479983
[Epoch 115; Iter   174/  209] train: loss: 0.0352915
[Epoch 115; Iter   204/  209] train: loss: 0.0630004
[Epoch 115] ogbg-moltox21: 0.763655 val loss: 0.424212
[Epoch 115] ogbg-moltox21: 0.730902 test loss: 0.442013
[Epoch 116; Iter    25/  209] train: loss: 0.0314214
[Epoch 116; Iter    55/  209] train: loss: 0.0349065
[Epoch 116; Iter    85/  209] train: loss: 0.0680505
[Epoch 116; Iter   115/  209] train: loss: 0.0398761
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0588885
[Epoch 116; Iter   175/  209] train: loss: 0.0242048
[Epoch 116; Iter   205/  209] train: loss: 0.0531161
[Epoch 116] ogbg-moltox21: 0.761789 val loss: 0.437251
[Epoch 116] ogbg-moltox21: 0.748836 test loss: 0.447255
[Epoch 117; Iter    26/  209] train: loss: 0.0324234
[Epoch 117; Iter    56/  209] train: loss: 0.0290179
[Epoch 117; Iter    86/  209] train: loss: 0.0267854
[Epoch 117; Iter   116/  209] train: loss: 0.0279835
[Epoch 117; Iter   146/  209] train: loss: 0.0361309
[Epoch 117; Iter   176/  209] train: loss: 0.0394637
[Epoch 117; Iter   206/  209] train: loss: 0.0364710
[Epoch 117] ogbg-moltox21: 0.762848 val loss: 0.426982
[Epoch 117] ogbg-moltox21: 0.750785 test loss: 0.444194
[Epoch 118; Iter    27/  209] train: loss: 0.0421744
[Epoch 118; Iter    57/  209] train: loss: 0.0317400
[Epoch 118; Iter    87/  209] train: loss: 0.0278706
[Epoch 118; Iter   117/  209] train: loss: 0.0363221
[Epoch 118; Iter   147/  209] train: loss: 0.0533550
[Epoch 118; Iter   177/  209] train: loss: 0.0423787
[Epoch 118; Iter   207/  209] train: loss: 0.0374306
[Epoch 118] ogbg-moltox21: 0.766086 val loss: 0.791941
[Epoch 118] ogbg-moltox21: 0.751026 test loss: 0.451198
[Epoch 119; Iter    28/  209] train: loss: 0.0426483
[Epoch 119; Iter    58/  209] train: loss: 0.0462749
[Epoch 119; Iter    88/  209] train: loss: 0.0393602
[Epoch 119; Iter   118/  209] train: loss: 0.0589323
[Epoch 119; Iter   148/  209] train: loss: 0.0249336
[Epoch 119; Iter   178/  209] train: loss: 0.0539846
[Epoch 119; Iter   208/  209] train: loss: 0.0391739
[Epoch 119] ogbg-moltox21: 0.769996 val loss: 0.439549
[Epoch 119] ogbg-moltox21: 0.752835 test loss: 0.452550
[Epoch 120; Iter    29/  209] train: loss: 0.0310600
[Epoch 120; Iter    59/  209] train: loss: 0.0294499
[Epoch 120; Iter    89/  209] train: loss: 0.0399349
[Epoch 120; Iter   119/  209] train: loss: 0.0357202
[Epoch 120; Iter   149/  209] train: loss: 0.0415772
[Epoch 120; Iter   179/  209] train: loss: 0.0302068
[Epoch 120; Iter   209/  209] train: loss: 0.0443929
[Epoch 120] ogbg-moltox21: 0.766286 val loss: 0.428423
[Epoch 120] ogbg-moltox21: 0.750707 test loss: 0.448138
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 24.
Statistics on  val_best_checkpoint
mean_pred: -2.948179006576538
std_pred: 1.8915326595306396
mean_targets: nan
std_targets: nan
prcauc: 0.3970385136458278
rocauc: 0.803562700233563
ogbg-moltox21: 0.803562700233563
OGBNanLabelBCEWithLogitsLoss: 0.24487620371359367
Statistics on  test
mean_pred: -2.9941015243530273
std_pred: 1.9267939329147339
mean_targets: nan
std_targets: nan
prcauc: 0.35363639576186795
rocauc: 0.7703809993071166
ogbg-moltox21: 0.7703809993071166
OGBNanLabelBCEWithLogitsLoss: 0.2581074949767854
Statistics on  train
mean_pred: -3.6707003116607666
std_pred: 2.42179536819458
mean_targets: nan
std_targets: nan
prcauc: 0.5183373871570797
rocauc: 0.8967044245114741
ogbg-moltox21: 0.8967044245114741
OGBNanLabelBCEWithLogitsLoss: 0.17208771473554332
[Epoch 116; Iter   145/  209] train: loss: 0.0210264
[Epoch 116; Iter   175/  209] train: loss: 0.0877077
[Epoch 116; Iter   205/  209] train: loss: 0.0587427
[Epoch 116] ogbg-moltox21: 0.761393 val loss: 0.389907
[Epoch 116] ogbg-moltox21: 0.736802 test loss: 0.435826
[Epoch 117; Iter    26/  209] train: loss: 0.0384242
[Epoch 117; Iter    56/  209] train: loss: 0.0523009
[Epoch 117; Iter    86/  209] train: loss: 0.0377202
[Epoch 117; Iter   116/  209] train: loss: 0.0527302
[Epoch 117; Iter   146/  209] train: loss: 0.0700795
[Epoch 117; Iter   176/  209] train: loss: 0.0561811
[Epoch 117; Iter   206/  209] train: loss: 0.0422489
[Epoch 117] ogbg-moltox21: 0.761777 val loss: 0.396063
[Epoch 117] ogbg-moltox21: 0.733633 test loss: 0.448147
[Epoch 118; Iter    27/  209] train: loss: 0.0267544
[Epoch 118; Iter    57/  209] train: loss: 0.0428770
[Epoch 118; Iter    87/  209] train: loss: 0.0357015
[Epoch 118; Iter   117/  209] train: loss: 0.0535273
[Epoch 118; Iter   147/  209] train: loss: 0.0572555
[Epoch 118; Iter   177/  209] train: loss: 0.0343313
[Epoch 118; Iter   207/  209] train: loss: 0.0482823
[Epoch 118] ogbg-moltox21: 0.759417 val loss: 0.399518
[Epoch 118] ogbg-moltox21: 0.733994 test loss: 0.444107
[Epoch 119; Iter    28/  209] train: loss: 0.0678071
[Epoch 119; Iter    58/  209] train: loss: 0.0666819
[Epoch 119; Iter    88/  209] train: loss: 0.0231060
[Epoch 119; Iter   118/  209] train: loss: 0.1028353
[Epoch 119; Iter   148/  209] train: loss: 0.0450661
[Epoch 119; Iter   178/  209] train: loss: 0.0521469
[Epoch 119; Iter   208/  209] train: loss: 0.0482268
[Epoch 119] ogbg-moltox21: 0.757603 val loss: 0.402717
[Epoch 119] ogbg-moltox21: 0.732962 test loss: 0.446969
[Epoch 120; Iter    29/  209] train: loss: 0.0378957
[Epoch 120; Iter    59/  209] train: loss: 0.0463860
[Epoch 120; Iter    89/  209] train: loss: 0.0398174
[Epoch 120; Iter   119/  209] train: loss: 0.0606670
[Epoch 120; Iter   149/  209] train: loss: 0.0310194
[Epoch 120; Iter   179/  209] train: loss: 0.0661753
[Epoch 120; Iter   209/  209] train: loss: 0.0582654
[Epoch 120] ogbg-moltox21: 0.760121 val loss: 0.395765
[Epoch 120] ogbg-moltox21: 0.737167 test loss: 0.438223
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 39.
Statistics on  val_best_checkpoint
mean_pred: -3.3379666805267334
std_pred: 2.179953098297119
mean_targets: nan
std_targets: nan
prcauc: 0.4183943253332851
rocauc: 0.8092491750065854
ogbg-moltox21: 0.8092491750065854
OGBNanLabelBCEWithLogitsLoss: 0.2456575612779017
Statistics on  test
mean_pred: -3.3686962127685547
std_pred: 2.207005739212036
mean_targets: nan
std_targets: nan
prcauc: 0.37795359016023466
rocauc: 0.767422531465756
ogbg-moltox21: 0.767422531465756
OGBNanLabelBCEWithLogitsLoss: 0.26480337259946046
Statistics on  train
mean_pred: -4.100701332092285
std_pred: 2.407115936279297
mean_targets: nan
std_targets: nan
prcauc: 0.6993591526960218
rocauc: 0.9353546441334958
ogbg-moltox21: 0.9353546441334958
OGBNanLabelBCEWithLogitsLoss: 0.122319807525742
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0504254
[Epoch 116; Iter   175/  209] train: loss: 0.0381224
[Epoch 116; Iter   205/  209] train: loss: 0.0663694
[Epoch 116] ogbg-moltox21: 0.763422 val loss: 0.424364
[Epoch 116] ogbg-moltox21: 0.729920 test loss: 0.440315
[Epoch 117; Iter    26/  209] train: loss: 0.0492392
[Epoch 117; Iter    56/  209] train: loss: 0.0288703
[Epoch 117; Iter    86/  209] train: loss: 0.0330359
[Epoch 117; Iter   116/  209] train: loss: 0.0452329
[Epoch 117; Iter   146/  209] train: loss: 0.0324480
[Epoch 117; Iter   176/  209] train: loss: 0.0319800
[Epoch 117; Iter   206/  209] train: loss: 0.0248275
[Epoch 117] ogbg-moltox21: 0.761014 val loss: 0.432002
[Epoch 117] ogbg-moltox21: 0.729194 test loss: 0.446047
[Epoch 118; Iter    27/  209] train: loss: 0.0232772
[Epoch 118; Iter    57/  209] train: loss: 0.0764409
[Epoch 118; Iter    87/  209] train: loss: 0.0526339
[Epoch 118; Iter   117/  209] train: loss: 0.0647612
[Epoch 118; Iter   147/  209] train: loss: 0.0254170
[Epoch 118; Iter   177/  209] train: loss: 0.0461976
[Epoch 118; Iter   207/  209] train: loss: 0.0282478
[Epoch 118] ogbg-moltox21: 0.759580 val loss: 0.432333
[Epoch 118] ogbg-moltox21: 0.729856 test loss: 0.447344
[Epoch 119; Iter    28/  209] train: loss: 0.0397599
[Epoch 119; Iter    58/  209] train: loss: 0.0512619
[Epoch 119; Iter    88/  209] train: loss: 0.0521097
[Epoch 119; Iter   118/  209] train: loss: 0.0267243
[Epoch 119; Iter   148/  209] train: loss: 0.0391775
[Epoch 119; Iter   178/  209] train: loss: 0.0353518
[Epoch 119; Iter   208/  209] train: loss: 0.0196089
[Epoch 119] ogbg-moltox21: 0.759262 val loss: 0.438657
[Epoch 119] ogbg-moltox21: 0.727638 test loss: 0.451168
[Epoch 120; Iter    29/  209] train: loss: 0.0598175
[Epoch 120; Iter    59/  209] train: loss: 0.0357998
[Epoch 120; Iter    89/  209] train: loss: 0.0553424
[Epoch 120; Iter   119/  209] train: loss: 0.0336775
[Epoch 120; Iter   149/  209] train: loss: 0.1289792
[Epoch 120; Iter   179/  209] train: loss: 0.0348281
[Epoch 120; Iter   209/  209] train: loss: 0.0529800
[Epoch 120] ogbg-moltox21: 0.761709 val loss: 0.434557
[Epoch 120] ogbg-moltox21: 0.729353 test loss: 0.453336
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 31.
Statistics on  val_best_checkpoint
mean_pred: -3.2537355422973633
std_pred: 2.0115697383880615
mean_targets: nan
std_targets: nan
prcauc: 0.3850520703121363
rocauc: 0.8016279833098808
ogbg-moltox21: 0.8016279833098808
OGBNanLabelBCEWithLogitsLoss: 0.2448113406146014
Statistics on  test
mean_pred: -3.289947748184204
std_pred: 2.058291435241699
mean_targets: nan
std_targets: nan
prcauc: 0.368797231634379
rocauc: 0.768739560157632
ogbg-moltox21: 0.768739560157632
OGBNanLabelBCEWithLogitsLoss: 0.25763670493055274
Statistics on  train
mean_pred: -3.7745683193206787
std_pred: 2.431647300720215
mean_targets: nan
std_targets: nan
prcauc: 0.5502872186817791
rocauc: 0.9088669063514603
ogbg-moltox21: 0.9088669063514603
OGBNanLabelBCEWithLogitsLoss: 0.17161466227621552
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.0.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.0.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/tox21/noise=0.0.yml --seed 6 --device cuda:0
All runs completed.
