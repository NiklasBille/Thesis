>>> Starting run for dataset: hiv
Running SCAFF configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml --seed 6 --device cuda:1
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.8/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.8_4_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.8
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6932337
[Epoch 1; Iter    60/ 1097] train: loss: 0.6930318
[Epoch 1; Iter    90/ 1097] train: loss: 0.6948986
[Epoch 1; Iter   120/ 1097] train: loss: 0.6924052
[Epoch 1; Iter   150/ 1097] train: loss: 0.6923461
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913102
[Epoch 1; Iter   210/ 1097] train: loss: 0.6904165
[Epoch 1; Iter   240/ 1097] train: loss: 0.6898558
[Epoch 1; Iter   270/ 1097] train: loss: 0.6888524
[Epoch 1; Iter   300/ 1097] train: loss: 0.6887732
[Epoch 1; Iter   330/ 1097] train: loss: 0.6869187
[Epoch 1; Iter   360/ 1097] train: loss: 0.6860681
[Epoch 1; Iter   390/ 1097] train: loss: 0.6841254
[Epoch 1; Iter   420/ 1097] train: loss: 0.6841123
[Epoch 1; Iter   450/ 1097] train: loss: 0.6810826
[Epoch 1; Iter   480/ 1097] train: loss: 0.6790888
[Epoch 1; Iter   510/ 1097] train: loss: 0.6776734
[Epoch 1; Iter   540/ 1097] train: loss: 0.6758243
[Epoch 1; Iter   570/ 1097] train: loss: 0.6738517
[Epoch 1; Iter   600/ 1097] train: loss: 0.6740881
[Epoch 1; Iter   630/ 1097] train: loss: 0.6721455
[Epoch 1; Iter   660/ 1097] train: loss: 0.6719024
[Epoch 1; Iter   690/ 1097] train: loss: 0.6650224
[Epoch 1; Iter   720/ 1097] train: loss: 0.6625296
[Epoch 1; Iter   750/ 1097] train: loss: 0.6411634
[Epoch 1; Iter   780/ 1097] train: loss: 0.6050566
[Epoch 1; Iter   810/ 1097] train: loss: 0.5548797
[Epoch 1; Iter   840/ 1097] train: loss: 0.4945953
[Epoch 1; Iter   870/ 1097] train: loss: 0.4399142
[Epoch 1; Iter   900/ 1097] train: loss: 0.4088780
[Epoch 1; Iter   930/ 1097] train: loss: 0.3726038
[Epoch 1; Iter   960/ 1097] train: loss: 0.3663881
[Epoch 1; Iter   990/ 1097] train: loss: 0.1864756
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1505080
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1198335
[Epoch 1; Iter  1080/ 1097] train: loss: 0.2121353
[Epoch 1] ogbg-molhiv: 0.706946 val loss: 0.123516
[Epoch 1] ogbg-molhiv: 0.728419 test loss: 0.144008
[Epoch 2; Iter    13/ 1097] train: loss: 0.0884399
[Epoch 2; Iter    43/ 1097] train: loss: 0.1266563
[Epoch 2; Iter    73/ 1097] train: loss: 0.0673797
[Epoch 2; Iter   103/ 1097] train: loss: 0.0563453
[Epoch 2; Iter   133/ 1097] train: loss: 0.0494708
[Epoch 2; Iter   163/ 1097] train: loss: 0.0766103
[Epoch 2; Iter   193/ 1097] train: loss: 0.2575420
[Epoch 2; Iter   223/ 1097] train: loss: 0.1601669
[Epoch 2; Iter   253/ 1097] train: loss: 0.3620630
[Epoch 2; Iter   283/ 1097] train: loss: 0.1461845
[Epoch 2; Iter   313/ 1097] train: loss: 0.6657035
[Epoch 2; Iter   343/ 1097] train: loss: 0.1289547
[Epoch 2; Iter   373/ 1097] train: loss: 0.0474828
[Epoch 2; Iter   403/ 1097] train: loss: 0.0816580
[Epoch 2; Iter   433/ 1097] train: loss: 0.4429979
[Epoch 2; Iter   463/ 1097] train: loss: 0.2993086
[Epoch 2; Iter   493/ 1097] train: loss: 0.2181955
[Epoch 2; Iter   523/ 1097] train: loss: 0.0433473
[Epoch 2; Iter   553/ 1097] train: loss: 0.1072452
[Epoch 2; Iter   583/ 1097] train: loss: 0.1095167
[Epoch 2; Iter   613/ 1097] train: loss: 0.0315071
[Epoch 2; Iter   643/ 1097] train: loss: 0.1772724
[Epoch 2; Iter   673/ 1097] train: loss: 0.1699067
[Epoch 2; Iter   703/ 1097] train: loss: 0.1471341
[Epoch 2; Iter   733/ 1097] train: loss: 0.0403298
[Epoch 2; Iter   763/ 1097] train: loss: 0.1237067
[Epoch 2; Iter   793/ 1097] train: loss: 0.2181662
[Epoch 2; Iter   823/ 1097] train: loss: 0.1570981
[Epoch 2; Iter   853/ 1097] train: loss: 0.0376805
[Epoch 2; Iter   883/ 1097] train: loss: 0.1523675
[Epoch 2; Iter   913/ 1097] train: loss: 0.0330853
[Epoch 2; Iter   943/ 1097] train: loss: 0.2612821
[Epoch 2; Iter   973/ 1097] train: loss: 0.2648103
[Epoch 2; Iter  1003/ 1097] train: loss: 0.0363210
[Epoch 2; Iter  1033/ 1097] train: loss: 0.1361368
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1938251
[Epoch 2; Iter  1093/ 1097] train: loss: 0.3875034
[Epoch 2] ogbg-molhiv: 0.742682 val loss: 0.164315
[Epoch 2] ogbg-molhiv: 0.745267 test loss: 0.134746
[Epoch 3; Iter    26/ 1097] train: loss: 0.0304936
[Epoch 3; Iter    56/ 1097] train: loss: 0.2907247
[Epoch 3; Iter    86/ 1097] train: loss: 0.0387298
[Epoch 3; Iter   116/ 1097] train: loss: 0.1133911
[Epoch 3; Iter   146/ 1097] train: loss: 0.0296965
[Epoch 3; Iter   176/ 1097] train: loss: 0.2060938
[Epoch 3; Iter   206/ 1097] train: loss: 0.1844818
[Epoch 3; Iter   236/ 1097] train: loss: 0.2815030
[Epoch 3; Iter   266/ 1097] train: loss: 0.2734357
[Epoch 3; Iter   296/ 1097] train: loss: 0.1632062
[Epoch 3; Iter   326/ 1097] train: loss: 0.0386477
[Epoch 3; Iter   356/ 1097] train: loss: 0.0374443
[Epoch 3; Iter   386/ 1097] train: loss: 0.0299379
[Epoch 3; Iter   416/ 1097] train: loss: 0.1146769
[Epoch 3; Iter   446/ 1097] train: loss: 0.0440214
[Epoch 3; Iter   476/ 1097] train: loss: 0.0406051
[Epoch 3; Iter   506/ 1097] train: loss: 0.1902243
[Epoch 3; Iter   536/ 1097] train: loss: 0.0581767
[Epoch 3; Iter   566/ 1097] train: loss: 0.0459214
[Epoch 3; Iter   596/ 1097] train: loss: 0.3245722
[Epoch 3; Iter   626/ 1097] train: loss: 0.0425647
[Epoch 3; Iter   656/ 1097] train: loss: 0.0326111
[Epoch 3; Iter   686/ 1097] train: loss: 0.1252044
[Epoch 3; Iter   716/ 1097] train: loss: 0.1007368
[Epoch 3; Iter   746/ 1097] train: loss: 0.0285709
[Epoch 3; Iter   776/ 1097] train: loss: 0.1848589
[Epoch 3; Iter   806/ 1097] train: loss: 0.2672479
[Epoch 3; Iter   836/ 1097] train: loss: 0.0277064
[Epoch 3; Iter   866/ 1097] train: loss: 0.3246000
[Epoch 3; Iter   896/ 1097] train: loss: 0.1412223
[Epoch 3; Iter   926/ 1097] train: loss: 0.0275206
[Epoch 3; Iter   956/ 1097] train: loss: 0.1528415
[Epoch 3; Iter   986/ 1097] train: loss: 0.0444654
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.8/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.8_5_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.8
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6931755
[Epoch 1; Iter    60/ 1097] train: loss: 0.6942084
[Epoch 1; Iter    90/ 1097] train: loss: 0.6929911
[Epoch 1; Iter   120/ 1097] train: loss: 0.6918162
[Epoch 1; Iter   150/ 1097] train: loss: 0.6939001
[Epoch 1; Iter   180/ 1097] train: loss: 0.6895066
[Epoch 1; Iter   210/ 1097] train: loss: 0.6901151
[Epoch 1; Iter   240/ 1097] train: loss: 0.6893087
[Epoch 1; Iter   270/ 1097] train: loss: 0.6894612
[Epoch 1; Iter   300/ 1097] train: loss: 0.6879230
[Epoch 1; Iter   330/ 1097] train: loss: 0.6868504
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856082
[Epoch 1; Iter   390/ 1097] train: loss: 0.6842889
[Epoch 1; Iter   420/ 1097] train: loss: 0.6833008
[Epoch 1; Iter   450/ 1097] train: loss: 0.6820382
[Epoch 1; Iter   480/ 1097] train: loss: 0.6796904
[Epoch 1; Iter   510/ 1097] train: loss: 0.6787589
[Epoch 1; Iter   540/ 1097] train: loss: 0.6784025
[Epoch 1; Iter   570/ 1097] train: loss: 0.6741951
[Epoch 1; Iter   600/ 1097] train: loss: 0.6721469
[Epoch 1; Iter   630/ 1097] train: loss: 0.6707450
[Epoch 1; Iter   660/ 1097] train: loss: 0.6677958
[Epoch 1; Iter   690/ 1097] train: loss: 0.6654670
[Epoch 1; Iter   720/ 1097] train: loss: 0.6620415
[Epoch 1; Iter   750/ 1097] train: loss: 0.6401908
[Epoch 1; Iter   780/ 1097] train: loss: 0.6050695
[Epoch 1; Iter   810/ 1097] train: loss: 0.5550162
[Epoch 1; Iter   840/ 1097] train: loss: 0.4892600
[Epoch 1; Iter   870/ 1097] train: loss: 0.4509248
[Epoch 1; Iter   900/ 1097] train: loss: 0.3540912
[Epoch 1; Iter   930/ 1097] train: loss: 0.3095623
[Epoch 1; Iter   960/ 1097] train: loss: 0.2254927
[Epoch 1; Iter   990/ 1097] train: loss: 0.3960873
[Epoch 1; Iter  1020/ 1097] train: loss: 0.1868164
[Epoch 1; Iter  1050/ 1097] train: loss: 0.2247887
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1455383
[Epoch 1] ogbg-molhiv: 0.683991 val loss: 0.129704
[Epoch 1] ogbg-molhiv: 0.700315 test loss: 0.147472
[Epoch 2; Iter    13/ 1097] train: loss: 0.0804844
[Epoch 2; Iter    43/ 1097] train: loss: 0.0691999
[Epoch 2; Iter    73/ 1097] train: loss: 0.0600288
[Epoch 2; Iter   103/ 1097] train: loss: 0.0490890
[Epoch 2; Iter   133/ 1097] train: loss: 0.1313455
[Epoch 2; Iter   163/ 1097] train: loss: 0.0532522
[Epoch 2; Iter   193/ 1097] train: loss: 0.2572485
[Epoch 2; Iter   223/ 1097] train: loss: 0.0516699
[Epoch 2; Iter   253/ 1097] train: loss: 0.1418556
[Epoch 2; Iter   283/ 1097] train: loss: 0.1240118
[Epoch 2; Iter   313/ 1097] train: loss: 0.1453543
[Epoch 2; Iter   343/ 1097] train: loss: 0.0446745
[Epoch 2; Iter   373/ 1097] train: loss: 0.2413053
[Epoch 2; Iter   403/ 1097] train: loss: 0.2802446
[Epoch 2; Iter   433/ 1097] train: loss: 0.1230917
[Epoch 2; Iter   463/ 1097] train: loss: 0.2653630
[Epoch 2; Iter   493/ 1097] train: loss: 0.0353132
[Epoch 2; Iter   523/ 1097] train: loss: 0.0894790
[Epoch 2; Iter   553/ 1097] train: loss: 0.1487185
[Epoch 2; Iter   583/ 1097] train: loss: 0.2932422
[Epoch 2; Iter   613/ 1097] train: loss: 0.1842712
[Epoch 2; Iter   643/ 1097] train: loss: 0.2338787
[Epoch 2; Iter   673/ 1097] train: loss: 0.0329444
[Epoch 2; Iter   703/ 1097] train: loss: 0.0533881
[Epoch 2; Iter   733/ 1097] train: loss: 0.3035352
[Epoch 2; Iter   763/ 1097] train: loss: 0.2547830
[Epoch 2; Iter   793/ 1097] train: loss: 0.1473566
[Epoch 2; Iter   823/ 1097] train: loss: 0.2617223
[Epoch 2; Iter   853/ 1097] train: loss: 0.0494754
[Epoch 2; Iter   883/ 1097] train: loss: 0.0283402
[Epoch 2; Iter   913/ 1097] train: loss: 0.1483918
[Epoch 2; Iter   943/ 1097] train: loss: 0.2326534
[Epoch 2; Iter   973/ 1097] train: loss: 0.2520090
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1193909
[Epoch 2; Iter  1033/ 1097] train: loss: 0.2080431
[Epoch 2; Iter  1063/ 1097] train: loss: 0.1926289
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1800380
[Epoch 2] ogbg-molhiv: 0.714267 val loss: 0.092754
[Epoch 2] ogbg-molhiv: 0.706843 test loss: 0.123602
[Epoch 3; Iter    26/ 1097] train: loss: 0.1496565
[Epoch 3; Iter    56/ 1097] train: loss: 0.1600954
[Epoch 3; Iter    86/ 1097] train: loss: 0.4573464
[Epoch 3; Iter   116/ 1097] train: loss: 0.0589555
[Epoch 3; Iter   146/ 1097] train: loss: 0.0359599
[Epoch 3; Iter   176/ 1097] train: loss: 0.2929679
[Epoch 3; Iter   206/ 1097] train: loss: 0.0274384
[Epoch 3; Iter   236/ 1097] train: loss: 0.0286868
[Epoch 3; Iter   266/ 1097] train: loss: 0.0464718
[Epoch 3; Iter   296/ 1097] train: loss: 0.0301224
[Epoch 3; Iter   326/ 1097] train: loss: 0.4044516
[Epoch 3; Iter   356/ 1097] train: loss: 0.0311400
[Epoch 3; Iter   386/ 1097] train: loss: 0.2642212
[Epoch 3; Iter   416/ 1097] train: loss: 0.0358456
[Epoch 3; Iter   446/ 1097] train: loss: 0.0398687
[Epoch 3; Iter   476/ 1097] train: loss: 0.1337685
[Epoch 3; Iter   506/ 1097] train: loss: 0.0545726
[Epoch 3; Iter   536/ 1097] train: loss: 0.0952403
[Epoch 3; Iter   566/ 1097] train: loss: 0.1037974
[Epoch 3; Iter   596/ 1097] train: loss: 0.1360060
[Epoch 3; Iter   626/ 1097] train: loss: 0.0329649
[Epoch 3; Iter   656/ 1097] train: loss: 0.1626728
[Epoch 3; Iter   686/ 1097] train: loss: 0.0356005
[Epoch 3; Iter   716/ 1097] train: loss: 0.2479800
[Epoch 3; Iter   746/ 1097] train: loss: 0.1256966
[Epoch 3; Iter   776/ 1097] train: loss: 0.2831394
[Epoch 3; Iter   806/ 1097] train: loss: 0.2751915
[Epoch 3; Iter   836/ 1097] train: loss: 0.1227056
[Epoch 3; Iter   866/ 1097] train: loss: 0.0426561
[Epoch 3; Iter   896/ 1097] train: loss: 0.0602951
[Epoch 3; Iter   926/ 1097] train: loss: 0.4671741
[Epoch 3; Iter   956/ 1097] train: loss: 0.1521043
[Epoch 3; Iter   986/ 1097] train: loss: 0.2399376
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.8/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.8_6_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.8
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/ 1097] train: loss: 0.6924398
[Epoch 1; Iter    60/ 1097] train: loss: 0.6937245
[Epoch 1; Iter    90/ 1097] train: loss: 0.6929802
[Epoch 1; Iter   120/ 1097] train: loss: 0.6926173
[Epoch 1; Iter   150/ 1097] train: loss: 0.6903778
[Epoch 1; Iter   180/ 1097] train: loss: 0.6913554
[Epoch 1; Iter   210/ 1097] train: loss: 0.6923170
[Epoch 1; Iter   240/ 1097] train: loss: 0.6889518
[Epoch 1; Iter   270/ 1097] train: loss: 0.6889689
[Epoch 1; Iter   300/ 1097] train: loss: 0.6894184
[Epoch 1; Iter   330/ 1097] train: loss: 0.6887161
[Epoch 1; Iter   360/ 1097] train: loss: 0.6856205
[Epoch 1; Iter   390/ 1097] train: loss: 0.6872253
[Epoch 1; Iter   420/ 1097] train: loss: 0.6828896
[Epoch 1; Iter   450/ 1097] train: loss: 0.6836463
[Epoch 1; Iter   480/ 1097] train: loss: 0.6798414
[Epoch 1; Iter   510/ 1097] train: loss: 0.6788148
[Epoch 1; Iter   540/ 1097] train: loss: 0.6819549
[Epoch 1; Iter   570/ 1097] train: loss: 0.6792782
[Epoch 1; Iter   600/ 1097] train: loss: 0.6739925
[Epoch 1; Iter   630/ 1097] train: loss: 0.6743887
[Epoch 1; Iter   660/ 1097] train: loss: 0.6734650
[Epoch 1; Iter   690/ 1097] train: loss: 0.6682705
[Epoch 1; Iter   720/ 1097] train: loss: 0.6613860
[Epoch 1; Iter   750/ 1097] train: loss: 0.6408247
[Epoch 1; Iter   780/ 1097] train: loss: 0.6046227
[Epoch 1; Iter   810/ 1097] train: loss: 0.5671275
[Epoch 1; Iter   840/ 1097] train: loss: 0.5009017
[Epoch 1; Iter   870/ 1097] train: loss: 0.4277585
[Epoch 1; Iter   900/ 1097] train: loss: 0.3530954
[Epoch 1; Iter   930/ 1097] train: loss: 0.3823476
[Epoch 1; Iter   960/ 1097] train: loss: 0.2768924
[Epoch 1; Iter   990/ 1097] train: loss: 0.2198012
[Epoch 1; Iter  1020/ 1097] train: loss: 0.2038995
[Epoch 1; Iter  1050/ 1097] train: loss: 0.1162400
[Epoch 1; Iter  1080/ 1097] train: loss: 0.1367576
[Epoch 1] ogbg-molhiv: 0.676244 val loss: 0.135606
[Epoch 1] ogbg-molhiv: 0.623235 test loss: 0.151724
[Epoch 2; Iter    13/ 1097] train: loss: 0.1506402
[Epoch 2; Iter    43/ 1097] train: loss: 0.2434671
[Epoch 2; Iter    73/ 1097] train: loss: 0.0615244
[Epoch 2; Iter   103/ 1097] train: loss: 0.1199270
[Epoch 2; Iter   133/ 1097] train: loss: 0.1829728
[Epoch 2; Iter   163/ 1097] train: loss: 0.1543179
[Epoch 2; Iter   193/ 1097] train: loss: 0.4037243
[Epoch 2; Iter   223/ 1097] train: loss: 0.1467990
[Epoch 2; Iter   253/ 1097] train: loss: 0.1697625
[Epoch 2; Iter   283/ 1097] train: loss: 0.1509592
[Epoch 2; Iter   313/ 1097] train: loss: 0.1040058
[Epoch 2; Iter   343/ 1097] train: loss: 0.1625375
[Epoch 2; Iter   373/ 1097] train: loss: 0.0409805
[Epoch 2; Iter   403/ 1097] train: loss: 0.0551987
[Epoch 2; Iter   433/ 1097] train: loss: 0.2134995
[Epoch 2; Iter   463/ 1097] train: loss: 0.2475459
[Epoch 2; Iter   493/ 1097] train: loss: 0.1475930
[Epoch 2; Iter   523/ 1097] train: loss: 0.2308328
[Epoch 2; Iter   553/ 1097] train: loss: 0.1532574
[Epoch 2; Iter   583/ 1097] train: loss: 0.0479142
[Epoch 2; Iter   613/ 1097] train: loss: 0.2129393
[Epoch 2; Iter   643/ 1097] train: loss: 0.3584108
[Epoch 2; Iter   673/ 1097] train: loss: 0.1605428
[Epoch 2; Iter   703/ 1097] train: loss: 0.1350318
[Epoch 2; Iter   733/ 1097] train: loss: 0.1590535
[Epoch 2; Iter   763/ 1097] train: loss: 0.0336121
[Epoch 2; Iter   793/ 1097] train: loss: 0.1322553
[Epoch 2; Iter   823/ 1097] train: loss: 0.0334504
[Epoch 2; Iter   853/ 1097] train: loss: 0.5784861
[Epoch 2; Iter   883/ 1097] train: loss: 0.1380894
[Epoch 2; Iter   913/ 1097] train: loss: 0.3771990
[Epoch 2; Iter   943/ 1097] train: loss: 0.2623381
[Epoch 2; Iter   973/ 1097] train: loss: 0.0416774
[Epoch 2; Iter  1003/ 1097] train: loss: 0.1096871
[Epoch 2; Iter  1033/ 1097] train: loss: 0.0322569
[Epoch 2; Iter  1063/ 1097] train: loss: 0.0588145
[Epoch 2; Iter  1093/ 1097] train: loss: 0.1373101
[Epoch 2] ogbg-molhiv: 0.704240 val loss: 0.097777
[Epoch 2] ogbg-molhiv: 0.669225 test loss: 0.154974
[Epoch 3; Iter    26/ 1097] train: loss: 0.2683131
[Epoch 3; Iter    56/ 1097] train: loss: 0.1597379
[Epoch 3; Iter    86/ 1097] train: loss: 0.4968908
[Epoch 3; Iter   116/ 1097] train: loss: 0.1224138
[Epoch 3; Iter   146/ 1097] train: loss: 0.1376788
[Epoch 3; Iter   176/ 1097] train: loss: 0.1454568
[Epoch 3; Iter   206/ 1097] train: loss: 0.0447165
[Epoch 3; Iter   236/ 1097] train: loss: 0.4027977
[Epoch 3; Iter   266/ 1097] train: loss: 0.2838451
[Epoch 3; Iter   296/ 1097] train: loss: 0.1275063
[Epoch 3; Iter   326/ 1097] train: loss: 0.1260833
[Epoch 3; Iter   356/ 1097] train: loss: 0.0404377
[Epoch 3; Iter   386/ 1097] train: loss: 0.0950453
[Epoch 3; Iter   416/ 1097] train: loss: 0.1376323
[Epoch 3; Iter   446/ 1097] train: loss: 0.0436937
[Epoch 3; Iter   476/ 1097] train: loss: 0.1688896
[Epoch 3; Iter   506/ 1097] train: loss: 0.0312726
[Epoch 3; Iter   536/ 1097] train: loss: 0.1354459
[Epoch 3; Iter   566/ 1097] train: loss: 0.5009643
[Epoch 3; Iter   596/ 1097] train: loss: 0.4194025
[Epoch 3; Iter   626/ 1097] train: loss: 0.0325132
[Epoch 3; Iter   656/ 1097] train: loss: 0.0369835
[Epoch 3; Iter   686/ 1097] train: loss: 0.3861223
[Epoch 3; Iter   716/ 1097] train: loss: 0.1053190
[Epoch 3; Iter   746/ 1097] train: loss: 0.0927076
[Epoch 3; Iter   776/ 1097] train: loss: 0.1843278
[Epoch 3; Iter   806/ 1097] train: loss: 0.0476887
[Epoch 3; Iter   836/ 1097] train: loss: 0.2865767
[Epoch 3; Iter   866/ 1097] train: loss: 0.0739542
[Epoch 3; Iter   896/ 1097] train: loss: 0.0907499
[Epoch 3; Iter   926/ 1097] train: loss: 0.0410376
[Epoch 3; Iter   956/ 1097] train: loss: 0.0313632
[Epoch 3; Iter   986/ 1097] train: loss: 0.0395912
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.7/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.7_6_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.7
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  960] train: loss: 0.6954380
[Epoch 1; Iter    60/  960] train: loss: 0.6943978
[Epoch 1; Iter    90/  960] train: loss: 0.6922832
[Epoch 1; Iter   120/  960] train: loss: 0.6923907
[Epoch 1; Iter   150/  960] train: loss: 0.6919334
[Epoch 1; Iter   180/  960] train: loss: 0.6924244
[Epoch 1; Iter   210/  960] train: loss: 0.6919938
[Epoch 1; Iter   240/  960] train: loss: 0.6926687
[Epoch 1; Iter   270/  960] train: loss: 0.6889644
[Epoch 1; Iter   300/  960] train: loss: 0.6879458
[Epoch 1; Iter   330/  960] train: loss: 0.6888098
[Epoch 1; Iter   360/  960] train: loss: 0.6870654
[Epoch 1; Iter   390/  960] train: loss: 0.6857218
[Epoch 1; Iter   420/  960] train: loss: 0.6828744
[Epoch 1; Iter   450/  960] train: loss: 0.6813371
[Epoch 1; Iter   480/  960] train: loss: 0.6798158
[Epoch 1; Iter   510/  960] train: loss: 0.6780351
[Epoch 1; Iter   540/  960] train: loss: 0.6790873
[Epoch 1; Iter   570/  960] train: loss: 0.6743280
[Epoch 1; Iter   600/  960] train: loss: 0.6727493
[Epoch 1; Iter   630/  960] train: loss: 0.6757258
[Epoch 1; Iter   660/  960] train: loss: 0.6680604
[Epoch 1; Iter   690/  960] train: loss: 0.6657849
[Epoch 1; Iter   720/  960] train: loss: 0.6620525
[Epoch 1; Iter   750/  960] train: loss: 0.6404520
[Epoch 1; Iter   780/  960] train: loss: 0.6033809
[Epoch 1; Iter   810/  960] train: loss: 0.5718274
[Epoch 1; Iter   840/  960] train: loss: 0.5201924
[Epoch 1; Iter   870/  960] train: loss: 0.4641890
[Epoch 1; Iter   900/  960] train: loss: 0.3743888
[Epoch 1; Iter   930/  960] train: loss: 0.3072645
[Epoch 1; Iter   960/  960] train: loss: 0.3026795
[Epoch 1] ogbg-molhiv: 0.669668 val loss: 0.288657
[Epoch 1] ogbg-molhiv: 0.722916 test loss: 0.277462
[Epoch 2; Iter    30/  960] train: loss: 0.5191596
[Epoch 2; Iter    60/  960] train: loss: 0.1981340
[Epoch 2; Iter    90/  960] train: loss: 0.1672262
[Epoch 2; Iter   120/  960] train: loss: 0.2228781
[Epoch 2; Iter   150/  960] train: loss: 0.0810871
[Epoch 2; Iter   180/  960] train: loss: 0.0763795
[Epoch 2; Iter   210/  960] train: loss: 0.0587828
[Epoch 2; Iter   240/  960] train: loss: 0.1956827
[Epoch 2; Iter   270/  960] train: loss: 0.3440944
[Epoch 2; Iter   300/  960] train: loss: 0.1280154
[Epoch 2; Iter   330/  960] train: loss: 0.0481175
[Epoch 2; Iter   360/  960] train: loss: 0.2139068
[Epoch 2; Iter   390/  960] train: loss: 0.0369003
[Epoch 2; Iter   420/  960] train: loss: 0.0414245
[Epoch 2; Iter   450/  960] train: loss: 0.3467586
[Epoch 2; Iter   480/  960] train: loss: 0.0497072
[Epoch 2; Iter   510/  960] train: loss: 0.2955901
[Epoch 2; Iter   540/  960] train: loss: 0.1137533
[Epoch 2; Iter   570/  960] train: loss: 0.1902150
[Epoch 2; Iter   600/  960] train: loss: 0.1407083
[Epoch 2; Iter   630/  960] train: loss: 0.0463113
[Epoch 2; Iter   660/  960] train: loss: 0.2952190
[Epoch 2; Iter   690/  960] train: loss: 0.2268325
[Epoch 2; Iter   720/  960] train: loss: 0.1027005
[Epoch 2; Iter   750/  960] train: loss: 0.0329179
[Epoch 2; Iter   780/  960] train: loss: 0.0314088
[Epoch 2; Iter   810/  960] train: loss: 0.1628505
[Epoch 2; Iter   840/  960] train: loss: 0.2662813
[Epoch 2; Iter   870/  960] train: loss: 0.1636888
[Epoch 2; Iter   900/  960] train: loss: 0.2483195
[Epoch 2; Iter   930/  960] train: loss: 0.0427163
[Epoch 2; Iter   960/  960] train: loss: 0.2286171
[Epoch 2] ogbg-molhiv: 0.657969 val loss: 0.139208
[Epoch 2] ogbg-molhiv: 0.631845 test loss: 0.125360
[Epoch 3; Iter    30/  960] train: loss: 0.2238888
[Epoch 3; Iter    60/  960] train: loss: 0.0370254
[Epoch 3; Iter    90/  960] train: loss: 0.1456520
[Epoch 3; Iter   120/  960] train: loss: 0.0760665
[Epoch 3; Iter   150/  960] train: loss: 0.0344901
[Epoch 3; Iter   180/  960] train: loss: 0.0473460
[Epoch 3; Iter   210/  960] train: loss: 0.0371754
[Epoch 3; Iter   240/  960] train: loss: 0.0344252
[Epoch 3; Iter   270/  960] train: loss: 0.0476850
[Epoch 3; Iter   300/  960] train: loss: 0.1037303
[Epoch 3; Iter   330/  960] train: loss: 0.1954334
[Epoch 3; Iter   360/  960] train: loss: 0.0614741
[Epoch 3; Iter   390/  960] train: loss: 0.1000360
[Epoch 3; Iter   420/  960] train: loss: 0.1866139
[Epoch 3; Iter   450/  960] train: loss: 0.2496152
[Epoch 3; Iter   480/  960] train: loss: 0.1182082
[Epoch 3; Iter   510/  960] train: loss: 0.3704984
[Epoch 3; Iter   540/  960] train: loss: 0.0342532
[Epoch 3; Iter   570/  960] train: loss: 0.1446340
[Epoch 3; Iter   600/  960] train: loss: 0.1937615
[Epoch 3; Iter   630/  960] train: loss: 0.1269284
[Epoch 3; Iter   660/  960] train: loss: 0.2060131
[Epoch 3; Iter   690/  960] train: loss: 0.1619410
[Epoch 3; Iter   720/  960] train: loss: 0.1400060
[Epoch 3; Iter   750/  960] train: loss: 0.0859270
[Epoch 3; Iter   780/  960] train: loss: 0.0401259
[Epoch 3; Iter   810/  960] train: loss: 0.0863315
[Epoch 3; Iter   840/  960] train: loss: 0.0715924
[Epoch 3; Iter   870/  960] train: loss: 0.0255706
[Epoch 3; Iter   900/  960] train: loss: 0.0509591
[Epoch 3; Iter   930/  960] train: loss: 0.3041393
[Epoch 3; Iter   960/  960] train: loss: 0.0337618
[Epoch 3] ogbg-molhiv: 0.721412 val loss: 0.132401
[Epoch 3] ogbg-molhiv: 0.691473 test loss: 0.164586
[Epoch 4; Iter    30/  960] train: loss: 0.4000716
[Epoch 4; Iter    60/  960] train: loss: 0.1614712
[Epoch 4; Iter    90/  960] train: loss: 0.0355044
[Epoch 4; Iter   120/  960] train: loss: 0.0468267
[Epoch 4; Iter   150/  960] train: loss: 0.0423458
[Epoch 4; Iter   180/  960] train: loss: 0.1455202
[Epoch 4; Iter   210/  960] train: loss: 0.1295185
[Epoch 4; Iter   240/  960] train: loss: 0.1301604
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.7/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.7_4_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.7
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  960] train: loss: 0.6932037
[Epoch 1; Iter    60/  960] train: loss: 0.6930345
[Epoch 1; Iter    90/  960] train: loss: 0.6928003
[Epoch 1; Iter   120/  960] train: loss: 0.6921210
[Epoch 1; Iter   150/  960] train: loss: 0.6916139
[Epoch 1; Iter   180/  960] train: loss: 0.6931716
[Epoch 1; Iter   210/  960] train: loss: 0.6905467
[Epoch 1; Iter   240/  960] train: loss: 0.6898149
[Epoch 1; Iter   270/  960] train: loss: 0.6892817
[Epoch 1; Iter   300/  960] train: loss: 0.6878421
[Epoch 1; Iter   330/  960] train: loss: 0.6866159
[Epoch 1; Iter   360/  960] train: loss: 0.6852005
[Epoch 1; Iter   390/  960] train: loss: 0.6864511
[Epoch 1; Iter   420/  960] train: loss: 0.6827273
[Epoch 1; Iter   450/  960] train: loss: 0.6863257
[Epoch 1; Iter   480/  960] train: loss: 0.6798435
[Epoch 1; Iter   510/  960] train: loss: 0.6812527
[Epoch 1; Iter   540/  960] train: loss: 0.6760000
[Epoch 1; Iter   570/  960] train: loss: 0.6747319
[Epoch 1; Iter   600/  960] train: loss: 0.6735849
[Epoch 1; Iter   630/  960] train: loss: 0.6697024
[Epoch 1; Iter   660/  960] train: loss: 0.6687219
[Epoch 1; Iter   690/  960] train: loss: 0.6708443
[Epoch 1; Iter   720/  960] train: loss: 0.6605912
[Epoch 1; Iter   750/  960] train: loss: 0.6442855
[Epoch 1; Iter   780/  960] train: loss: 0.6320204
[Epoch 1; Iter   810/  960] train: loss: 0.5641394
[Epoch 1; Iter   840/  960] train: loss: 0.4957064
[Epoch 1; Iter   870/  960] train: loss: 0.4369505
[Epoch 1; Iter   900/  960] train: loss: 0.4084770
[Epoch 1; Iter   930/  960] train: loss: 0.2924384
[Epoch 1; Iter   960/  960] train: loss: 0.5285308
[Epoch 1] ogbg-molhiv: 0.674653 val loss: 0.252821
[Epoch 1] ogbg-molhiv: 0.709246 test loss: 0.244644
[Epoch 2; Iter    30/  960] train: loss: 0.2001980
[Epoch 2; Iter    60/  960] train: loss: 0.1456527
[Epoch 2; Iter    90/  960] train: loss: 0.2700494
[Epoch 2; Iter   120/  960] train: loss: 0.1469286
[Epoch 2; Iter   150/  960] train: loss: 0.0818244
[Epoch 2; Iter   180/  960] train: loss: 0.2422135
[Epoch 2; Iter   210/  960] train: loss: 0.0620590
[Epoch 2; Iter   240/  960] train: loss: 0.1726282
[Epoch 2; Iter   270/  960] train: loss: 0.2467375
[Epoch 2; Iter   300/  960] train: loss: 0.2715925
[Epoch 2; Iter   330/  960] train: loss: 0.0502965
[Epoch 2; Iter   360/  960] train: loss: 0.2323886
[Epoch 2; Iter   390/  960] train: loss: 0.1127122
[Epoch 2; Iter   420/  960] train: loss: 0.1432611
[Epoch 2; Iter   450/  960] train: loss: 0.2367826
[Epoch 2; Iter   480/  960] train: loss: 0.3961734
[Epoch 2; Iter   510/  960] train: loss: 0.0364840
[Epoch 2; Iter   540/  960] train: loss: 0.1722296
[Epoch 2; Iter   570/  960] train: loss: 0.0361714
[Epoch 2; Iter   600/  960] train: loss: 0.3095151
[Epoch 2; Iter   630/  960] train: loss: 0.1720273
[Epoch 2; Iter   660/  960] train: loss: 0.0391709
[Epoch 2; Iter   690/  960] train: loss: 0.0370059
[Epoch 2; Iter   720/  960] train: loss: 0.1372402
[Epoch 2; Iter   750/  960] train: loss: 0.2564145
[Epoch 2; Iter   780/  960] train: loss: 0.2229971
[Epoch 2; Iter   810/  960] train: loss: 0.0426464
[Epoch 2; Iter   840/  960] train: loss: 0.1420399
[Epoch 2; Iter   870/  960] train: loss: 0.0346806
[Epoch 2; Iter   900/  960] train: loss: 0.0378227
[Epoch 2; Iter   930/  960] train: loss: 0.1575427
[Epoch 2; Iter   960/  960] train: loss: 0.0392485
[Epoch 2] ogbg-molhiv: 0.622499 val loss: 0.137606
[Epoch 2] ogbg-molhiv: 0.607566 test loss: 0.122229
[Epoch 3; Iter    30/  960] train: loss: 0.2229913
[Epoch 3; Iter    60/  960] train: loss: 0.1205641
[Epoch 3; Iter    90/  960] train: loss: 0.1049653
[Epoch 3; Iter   120/  960] train: loss: 0.1372251
[Epoch 3; Iter   150/  960] train: loss: 0.0337284
[Epoch 3; Iter   180/  960] train: loss: 0.0332391
[Epoch 3; Iter   210/  960] train: loss: 0.1803491
[Epoch 3; Iter   240/  960] train: loss: 0.1058602
[Epoch 3; Iter   270/  960] train: loss: 0.2167736
[Epoch 3; Iter   300/  960] train: loss: 0.1193282
[Epoch 3; Iter   330/  960] train: loss: 0.1735661
[Epoch 3; Iter   360/  960] train: loss: 0.4125762
[Epoch 3; Iter   390/  960] train: loss: 0.0366794
[Epoch 3; Iter   420/  960] train: loss: 0.1745255
[Epoch 3; Iter   450/  960] train: loss: 0.3308619
[Epoch 3; Iter   480/  960] train: loss: 0.0777712
[Epoch 3; Iter   510/  960] train: loss: 0.0381922
[Epoch 3; Iter   540/  960] train: loss: 0.0330152
[Epoch 3; Iter   570/  960] train: loss: 0.2205965
[Epoch 3; Iter   600/  960] train: loss: 0.0498450
[Epoch 3; Iter   630/  960] train: loss: 0.0444186
[Epoch 3; Iter   660/  960] train: loss: 0.1733211
[Epoch 3; Iter   690/  960] train: loss: 0.2518317
[Epoch 3; Iter   720/  960] train: loss: 0.1832092
[Epoch 3; Iter   750/  960] train: loss: 0.3535607
[Epoch 3; Iter   780/  960] train: loss: 0.0722600
[Epoch 3; Iter   810/  960] train: loss: 0.0339401
[Epoch 3; Iter   840/  960] train: loss: 0.0772353
[Epoch 3; Iter   870/  960] train: loss: 0.2151322
[Epoch 3; Iter   900/  960] train: loss: 0.0368976
[Epoch 3; Iter   930/  960] train: loss: 0.1358417
[Epoch 3; Iter   960/  960] train: loss: 0.1934623
[Epoch 3] ogbg-molhiv: 0.722695 val loss: 0.139202
[Epoch 3] ogbg-molhiv: 0.726099 test loss: 0.114235
[Epoch 4; Iter    30/  960] train: loss: 0.1213400
[Epoch 4; Iter    60/  960] train: loss: 0.0371107
[Epoch 4; Iter    90/  960] train: loss: 0.1060351
[Epoch 4; Iter   120/  960] train: loss: 0.1330958
[Epoch 4; Iter   150/  960] train: loss: 0.1478765
[Epoch 4; Iter   180/  960] train: loss: 0.0429196
[Epoch 4; Iter   210/  960] train: loss: 0.1273696
[Epoch 4; Iter   240/  960] train: loss: 0.0482958
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.7/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.7_5_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.7
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  960] train: loss: 0.6930490
[Epoch 1; Iter    60/  960] train: loss: 0.6946664
[Epoch 1; Iter    90/  960] train: loss: 0.6927220
[Epoch 1; Iter   120/  960] train: loss: 0.6923622
[Epoch 1; Iter   150/  960] train: loss: 0.6919768
[Epoch 1; Iter   180/  960] train: loss: 0.6911703
[Epoch 1; Iter   210/  960] train: loss: 0.6911322
[Epoch 1; Iter   240/  960] train: loss: 0.6889594
[Epoch 1; Iter   270/  960] train: loss: 0.6933570
[Epoch 1; Iter   300/  960] train: loss: 0.6898668
[Epoch 1; Iter   330/  960] train: loss: 0.6882620
[Epoch 1; Iter   360/  960] train: loss: 0.6870782
[Epoch 1; Iter   390/  960] train: loss: 0.6862894
[Epoch 1; Iter   420/  960] train: loss: 0.6818469
[Epoch 1; Iter   450/  960] train: loss: 0.6813345
[Epoch 1; Iter   480/  960] train: loss: 0.6823125
[Epoch 1; Iter   510/  960] train: loss: 0.6768478
[Epoch 1; Iter   540/  960] train: loss: 0.6786247
[Epoch 1; Iter   570/  960] train: loss: 0.6754574
[Epoch 1; Iter   600/  960] train: loss: 0.6741525
[Epoch 1; Iter   630/  960] train: loss: 0.6722401
[Epoch 1; Iter   660/  960] train: loss: 0.6714511
[Epoch 1; Iter   690/  960] train: loss: 0.6693839
[Epoch 1; Iter   720/  960] train: loss: 0.6661696
[Epoch 1; Iter   750/  960] train: loss: 0.6357642
[Epoch 1; Iter   780/  960] train: loss: 0.5939228
[Epoch 1; Iter   810/  960] train: loss: 0.5542585
[Epoch 1; Iter   840/  960] train: loss: 0.4930465
[Epoch 1; Iter   870/  960] train: loss: 0.4379774
[Epoch 1; Iter   900/  960] train: loss: 0.4073384
[Epoch 1; Iter   930/  960] train: loss: 0.3154834
[Epoch 1; Iter   960/  960] train: loss: 0.2557621
[Epoch 1] ogbg-molhiv: 0.691364 val loss: 0.292325
[Epoch 1] ogbg-molhiv: 0.701419 test loss: 0.286776
[Epoch 2; Iter    30/  960] train: loss: 0.2314177
[Epoch 2; Iter    60/  960] train: loss: 0.2045194
[Epoch 2; Iter    90/  960] train: loss: 0.2570263
[Epoch 2; Iter   120/  960] train: loss: 0.0941559
[Epoch 2; Iter   150/  960] train: loss: 0.4189263
[Epoch 2; Iter   180/  960] train: loss: 0.1452697
[Epoch 2; Iter   210/  960] train: loss: 0.1793633
[Epoch 2; Iter   240/  960] train: loss: 0.0575371
[Epoch 2; Iter   270/  960] train: loss: 0.0561284
[Epoch 2; Iter   300/  960] train: loss: 0.1284164
[Epoch 2; Iter   330/  960] train: loss: 0.0462356
[Epoch 2; Iter   360/  960] train: loss: 0.0578114
[Epoch 2; Iter   390/  960] train: loss: 0.0400894
[Epoch 2; Iter   420/  960] train: loss: 0.1158966
[Epoch 2; Iter   450/  960] train: loss: 0.0439304
[Epoch 2; Iter   480/  960] train: loss: 0.2711757
[Epoch 2; Iter   510/  960] train: loss: 0.1507223
[Epoch 2; Iter   540/  960] train: loss: 0.2673618
[Epoch 2; Iter   570/  960] train: loss: 0.0952752
[Epoch 2; Iter   600/  960] train: loss: 0.1469845
[Epoch 2; Iter   630/  960] train: loss: 0.0433384
[Epoch 2; Iter   660/  960] train: loss: 0.1358033
[Epoch 2; Iter   690/  960] train: loss: 0.2929320
[Epoch 2; Iter   720/  960] train: loss: 0.0337695
[Epoch 2; Iter   750/  960] train: loss: 0.0323313
[Epoch 2; Iter   780/  960] train: loss: 0.0468029
[Epoch 2; Iter   810/  960] train: loss: 0.0765716
[Epoch 2; Iter   840/  960] train: loss: 0.0436471
[Epoch 2; Iter   870/  960] train: loss: 0.0462742
[Epoch 2; Iter   900/  960] train: loss: 0.0330896
[Epoch 2; Iter   930/  960] train: loss: 0.1366104
[Epoch 2; Iter   960/  960] train: loss: 0.0324983
[Epoch 2] ogbg-molhiv: 0.707841 val loss: 0.148477
[Epoch 2] ogbg-molhiv: 0.720748 test loss: 0.118399
[Epoch 3; Iter    30/  960] train: loss: 0.0970918
[Epoch 3; Iter    60/  960] train: loss: 0.0314326
[Epoch 3; Iter    90/  960] train: loss: 0.0523262
[Epoch 3; Iter   120/  960] train: loss: 0.2244541
[Epoch 3; Iter   150/  960] train: loss: 0.0860564
[Epoch 3; Iter   180/  960] train: loss: 0.2597628
[Epoch 3; Iter   210/  960] train: loss: 0.4369908
[Epoch 3; Iter   240/  960] train: loss: 0.1609625
[Epoch 3; Iter   270/  960] train: loss: 0.2534931
[Epoch 3; Iter   300/  960] train: loss: 0.1572106
[Epoch 3; Iter   330/  960] train: loss: 0.1773634
[Epoch 3; Iter   360/  960] train: loss: 0.2473849
[Epoch 3; Iter   390/  960] train: loss: 0.4644249
[Epoch 3; Iter   420/  960] train: loss: 0.0435820
[Epoch 3; Iter   450/  960] train: loss: 0.0372506
[Epoch 3; Iter   480/  960] train: loss: 0.1249060
[Epoch 3; Iter   510/  960] train: loss: 0.1713400
[Epoch 3; Iter   540/  960] train: loss: 0.0889495
[Epoch 3; Iter   570/  960] train: loss: 0.0984479
[Epoch 3; Iter   600/  960] train: loss: 0.2710649
[Epoch 3; Iter   630/  960] train: loss: 0.3071774
[Epoch 3; Iter   660/  960] train: loss: 0.1352268
[Epoch 3; Iter   690/  960] train: loss: 0.1636413
[Epoch 3; Iter   720/  960] train: loss: 0.1316392
[Epoch 3; Iter   750/  960] train: loss: 0.0351445
[Epoch 3; Iter   780/  960] train: loss: 0.1499131
[Epoch 3; Iter   810/  960] train: loss: 0.0385670
[Epoch 3; Iter   840/  960] train: loss: 0.0919442
[Epoch 3; Iter   870/  960] train: loss: 0.3932654
[Epoch 3; Iter   900/  960] train: loss: 0.0377571
[Epoch 3; Iter   930/  960] train: loss: 0.2756468
[Epoch 3; Iter   960/  960] train: loss: 0.2502096
[Epoch 3] ogbg-molhiv: 0.679094 val loss: 0.133859
[Epoch 3] ogbg-molhiv: 0.688153 test loss: 0.109997
[Epoch 4; Iter    30/  960] train: loss: 0.0958643
[Epoch 4; Iter    60/  960] train: loss: 0.1531676
[Epoch 4; Iter    90/  960] train: loss: 0.0387028
[Epoch 4; Iter   120/  960] train: loss: 0.1884172
[Epoch 4; Iter   150/  960] train: loss: 0.0596378
[Epoch 4; Iter   180/  960] train: loss: 0.0361280
[Epoch 4; Iter   210/  960] train: loss: 0.1721233
[Epoch 4; Iter   240/  960] train: loss: 0.1035209
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.6/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.6_6_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.6
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  823] train: loss: 0.6931818
[Epoch 1; Iter    60/  823] train: loss: 0.6926669
[Epoch 1; Iter    90/  823] train: loss: 0.6927802
[Epoch 1; Iter   120/  823] train: loss: 0.6964900
[Epoch 1; Iter   150/  823] train: loss: 0.6914043
[Epoch 1; Iter   180/  823] train: loss: 0.6929423
[Epoch 1; Iter   210/  823] train: loss: 0.6919645
[Epoch 1; Iter   240/  823] train: loss: 0.6905614
[Epoch 1; Iter   270/  823] train: loss: 0.6915520
[Epoch 1; Iter   300/  823] train: loss: 0.6880754
[Epoch 1; Iter   330/  823] train: loss: 0.6875632
[Epoch 1; Iter   360/  823] train: loss: 0.6860464
[Epoch 1; Iter   390/  823] train: loss: 0.6844535
[Epoch 1; Iter   420/  823] train: loss: 0.6853368
[Epoch 1; Iter   450/  823] train: loss: 0.6840336
[Epoch 1; Iter   480/  823] train: loss: 0.6837143
[Epoch 1; Iter   510/  823] train: loss: 0.6781465
[Epoch 1; Iter   540/  823] train: loss: 0.6775325
[Epoch 1; Iter   570/  823] train: loss: 0.6771699
[Epoch 1; Iter   600/  823] train: loss: 0.6724604
[Epoch 1; Iter   630/  823] train: loss: 0.6713858
[Epoch 1; Iter   660/  823] train: loss: 0.6691518
[Epoch 1; Iter   690/  823] train: loss: 0.6678372
[Epoch 1; Iter   720/  823] train: loss: 0.6672598
[Epoch 1; Iter   750/  823] train: loss: 0.6412696
[Epoch 1; Iter   780/  823] train: loss: 0.6054776
[Epoch 1; Iter   810/  823] train: loss: 0.5547980
[Epoch 1] ogbg-molhiv: 0.663531 val loss: 0.543408
[Epoch 1] ogbg-molhiv: 0.692673 test loss: 0.537457
[Epoch 2; Iter    17/  823] train: loss: 0.4929457
[Epoch 2; Iter    47/  823] train: loss: 0.4601280
[Epoch 2; Iter    77/  823] train: loss: 0.4240538
[Epoch 2; Iter   107/  823] train: loss: 0.2834629
[Epoch 2; Iter   137/  823] train: loss: 0.2672330
[Epoch 2; Iter   167/  823] train: loss: 0.1744752
[Epoch 2; Iter   197/  823] train: loss: 0.2056274
[Epoch 2; Iter   227/  823] train: loss: 0.1887438
[Epoch 2; Iter   257/  823] train: loss: 0.0906924
[Epoch 2; Iter   287/  823] train: loss: 0.2342474
[Epoch 2; Iter   317/  823] train: loss: 0.2138994
[Epoch 2; Iter   347/  823] train: loss: 0.0648774
[Epoch 2; Iter   377/  823] train: loss: 0.2477969
[Epoch 2; Iter   407/  823] train: loss: 0.0809874
[Epoch 2; Iter   437/  823] train: loss: 0.0484335
[Epoch 2; Iter   467/  823] train: loss: 0.0429192
[Epoch 2; Iter   497/  823] train: loss: 0.1407093
[Epoch 2; Iter   527/  823] train: loss: 0.1100142
[Epoch 2; Iter   557/  823] train: loss: 0.1895241
[Epoch 2; Iter   587/  823] train: loss: 0.0451249
[Epoch 2; Iter   617/  823] train: loss: 0.2820603
[Epoch 2; Iter   647/  823] train: loss: 0.1193795
[Epoch 2; Iter   677/  823] train: loss: 0.1529922
[Epoch 2; Iter   707/  823] train: loss: 0.0486393
[Epoch 2; Iter   737/  823] train: loss: 0.1140775
[Epoch 2; Iter   767/  823] train: loss: 0.0470643
[Epoch 2; Iter   797/  823] train: loss: 0.1032041
[Epoch 2] ogbg-molhiv: 0.646651 val loss: 0.148557
[Epoch 2] ogbg-molhiv: 0.663041 test loss: 0.111663
[Epoch 3; Iter     4/  823] train: loss: 0.0385943
[Epoch 3; Iter    34/  823] train: loss: 0.1345540
[Epoch 3; Iter    64/  823] train: loss: 0.0428367
[Epoch 3; Iter    94/  823] train: loss: 0.2387813
[Epoch 3; Iter   124/  823] train: loss: 0.0706486
[Epoch 3; Iter   154/  823] train: loss: 0.1930218
[Epoch 3; Iter   184/  823] train: loss: 0.3437243
[Epoch 3; Iter   214/  823] train: loss: 0.1697171
[Epoch 3; Iter   244/  823] train: loss: 0.0393305
[Epoch 3; Iter   274/  823] train: loss: 0.0349364
[Epoch 3; Iter   304/  823] train: loss: 0.2462206
[Epoch 3; Iter   334/  823] train: loss: 0.1163598
[Epoch 3; Iter   364/  823] train: loss: 0.1055324
[Epoch 3; Iter   394/  823] train: loss: 0.2813594
[Epoch 3; Iter   424/  823] train: loss: 0.1348143
[Epoch 3; Iter   454/  823] train: loss: 0.0272422
[Epoch 3; Iter   484/  823] train: loss: 0.3289036
[Epoch 3; Iter   514/  823] train: loss: 0.1688280
[Epoch 3; Iter   544/  823] train: loss: 0.2157829
[Epoch 3; Iter   574/  823] train: loss: 0.1239028
[Epoch 3; Iter   604/  823] train: loss: 0.0419349
[Epoch 3; Iter   634/  823] train: loss: 0.0445769
[Epoch 3; Iter   664/  823] train: loss: 0.2832378
[Epoch 3; Iter   694/  823] train: loss: 0.1313735
[Epoch 3; Iter   724/  823] train: loss: 0.1654158
[Epoch 3; Iter   754/  823] train: loss: 0.4240858
[Epoch 3; Iter   784/  823] train: loss: 0.1731720
[Epoch 3; Iter   814/  823] train: loss: 0.0392874
[Epoch 3] ogbg-molhiv: 0.667211 val loss: 0.149758
[Epoch 3] ogbg-molhiv: 0.682857 test loss: 0.128818
[Epoch 4; Iter    21/  823] train: loss: 0.2648906
[Epoch 4; Iter    51/  823] train: loss: 0.2010141
[Epoch 4; Iter    81/  823] train: loss: 0.1213297
[Epoch 4; Iter   111/  823] train: loss: 0.3006785
[Epoch 4; Iter   141/  823] train: loss: 0.2166280
[Epoch 4; Iter   171/  823] train: loss: 0.0670067
[Epoch 4; Iter   201/  823] train: loss: 0.0486960
[Epoch 4; Iter   231/  823] train: loss: 0.0325491
[Epoch 4; Iter   261/  823] train: loss: 0.3293382
[Epoch 4; Iter   291/  823] train: loss: 0.0412287
[Epoch 4; Iter   321/  823] train: loss: 0.0271834
[Epoch 4; Iter   351/  823] train: loss: 0.1327512
[Epoch 4; Iter   381/  823] train: loss: 0.0607046
[Epoch 4; Iter   411/  823] train: loss: 0.2707090
[Epoch 4; Iter   441/  823] train: loss: 0.2163688
[Epoch 4; Iter   471/  823] train: loss: 0.1986952
[Epoch 4; Iter   501/  823] train: loss: 0.3485979
[Epoch 4; Iter   531/  823] train: loss: 0.1417051
[Epoch 4; Iter   561/  823] train: loss: 0.2862324
[Epoch 4; Iter   591/  823] train: loss: 0.1793963
[Epoch 4; Iter   621/  823] train: loss: 0.0949101
[Epoch 4; Iter   651/  823] train: loss: 0.1648096
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.6/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.6_4_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.6
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  823] train: loss: 0.6932135
[Epoch 1; Iter    60/  823] train: loss: 0.6928416
[Epoch 1; Iter    90/  823] train: loss: 0.6942483
[Epoch 1; Iter   120/  823] train: loss: 0.6923853
[Epoch 1; Iter   150/  823] train: loss: 0.6916133
[Epoch 1; Iter   180/  823] train: loss: 0.6927487
[Epoch 1; Iter   210/  823] train: loss: 0.6905887
[Epoch 1; Iter   240/  823] train: loss: 0.6894029
[Epoch 1; Iter   270/  823] train: loss: 0.6890190
[Epoch 1; Iter   300/  823] train: loss: 0.6877952
[Epoch 1; Iter   330/  823] train: loss: 0.6879947
[Epoch 1; Iter   360/  823] train: loss: 0.6852852
[Epoch 1; Iter   390/  823] train: loss: 0.6853037
[Epoch 1; Iter   420/  823] train: loss: 0.6820645
[Epoch 1; Iter   450/  823] train: loss: 0.6811202
[Epoch 1; Iter   480/  823] train: loss: 0.6793996
[Epoch 1; Iter   510/  823] train: loss: 0.6790155
[Epoch 1; Iter   540/  823] train: loss: 0.6766119
[Epoch 1; Iter   570/  823] train: loss: 0.6773877
[Epoch 1; Iter   600/  823] train: loss: 0.6728283
[Epoch 1; Iter   630/  823] train: loss: 0.6706379
[Epoch 1; Iter   660/  823] train: loss: 0.6706880
[Epoch 1; Iter   690/  823] train: loss: 0.6665335
[Epoch 1; Iter   720/  823] train: loss: 0.6658239
[Epoch 1; Iter   750/  823] train: loss: 0.6262159
[Epoch 1; Iter   780/  823] train: loss: 0.6034448
[Epoch 1; Iter   810/  823] train: loss: 0.5556097
[Epoch 1] ogbg-molhiv: 0.659429 val loss: 0.536574
[Epoch 1] ogbg-molhiv: 0.679877 test loss: 0.527437
[Epoch 2; Iter    17/  823] train: loss: 0.5120894
[Epoch 2; Iter    47/  823] train: loss: 0.4522032
[Epoch 2; Iter    77/  823] train: loss: 0.3799470
[Epoch 2; Iter   107/  823] train: loss: 0.3982144
[Epoch 2; Iter   137/  823] train: loss: 0.2373704
[Epoch 2; Iter   167/  823] train: loss: 0.1845040
[Epoch 2; Iter   197/  823] train: loss: 0.1448707
[Epoch 2; Iter   227/  823] train: loss: 0.1178543
[Epoch 2; Iter   257/  823] train: loss: 0.2123661
[Epoch 2; Iter   287/  823] train: loss: 0.1822682
[Epoch 2; Iter   317/  823] train: loss: 0.0757660
[Epoch 2; Iter   347/  823] train: loss: 0.0590770
[Epoch 2; Iter   377/  823] train: loss: 0.3227068
[Epoch 2; Iter   407/  823] train: loss: 0.0534437
[Epoch 2; Iter   437/  823] train: loss: 0.1455110
[Epoch 2; Iter   467/  823] train: loss: 0.1751227
[Epoch 2; Iter   497/  823] train: loss: 0.0426609
[Epoch 2; Iter   527/  823] train: loss: 0.0851411
[Epoch 2; Iter   557/  823] train: loss: 0.1512517
[Epoch 2; Iter   587/  823] train: loss: 0.1045081
[Epoch 2; Iter   617/  823] train: loss: 0.0891328
[Epoch 2; Iter   647/  823] train: loss: 0.4854687
[Epoch 2; Iter   677/  823] train: loss: 0.1189720
[Epoch 2; Iter   707/  823] train: loss: 0.0843330
[Epoch 2; Iter   737/  823] train: loss: 0.0492978
[Epoch 2; Iter   767/  823] train: loss: 0.0342046
[Epoch 2; Iter   797/  823] train: loss: 0.0457953
[Epoch 2] ogbg-molhiv: 0.688166 val loss: 0.153362
[Epoch 2] ogbg-molhiv: 0.694098 test loss: 0.124953
[Epoch 3; Iter     4/  823] train: loss: 0.0364004
[Epoch 3; Iter    34/  823] train: loss: 0.3112234
[Epoch 3; Iter    64/  823] train: loss: 0.1399152
[Epoch 3; Iter    94/  823] train: loss: 0.1475987
[Epoch 3; Iter   124/  823] train: loss: 0.1515761
[Epoch 3; Iter   154/  823] train: loss: 0.0417654
[Epoch 3; Iter   184/  823] train: loss: 0.2519844
[Epoch 3; Iter   214/  823] train: loss: 0.2434365
[Epoch 3; Iter   244/  823] train: loss: 0.0439782
[Epoch 3; Iter   274/  823] train: loss: 0.2276571
[Epoch 3; Iter   304/  823] train: loss: 0.1389978
[Epoch 3; Iter   334/  823] train: loss: 0.4786035
[Epoch 3; Iter   364/  823] train: loss: 0.3757666
[Epoch 3; Iter   394/  823] train: loss: 0.0947264
[Epoch 3; Iter   424/  823] train: loss: 0.1709684
[Epoch 3; Iter   454/  823] train: loss: 0.0372274
[Epoch 3; Iter   484/  823] train: loss: 0.4341643
[Epoch 3; Iter   514/  823] train: loss: 0.1448887
[Epoch 3; Iter   544/  823] train: loss: 0.0806639
[Epoch 3; Iter   574/  823] train: loss: 0.1643548
[Epoch 3; Iter   604/  823] train: loss: 0.1479829
[Epoch 3; Iter   634/  823] train: loss: 0.2676707
[Epoch 3; Iter   664/  823] train: loss: 0.4459628
[Epoch 3; Iter   694/  823] train: loss: 0.0390032
[Epoch 3; Iter   724/  823] train: loss: 0.0374060
[Epoch 3; Iter   754/  823] train: loss: 0.1837821
[Epoch 3; Iter   784/  823] train: loss: 0.3138056
[Epoch 3; Iter   814/  823] train: loss: 0.1354266
[Epoch 3] ogbg-molhiv: 0.712667 val loss: 0.148058
[Epoch 3] ogbg-molhiv: 0.730832 test loss: 0.130299
[Epoch 4; Iter    21/  823] train: loss: 0.1455507
[Epoch 4; Iter    51/  823] train: loss: 0.2025842
[Epoch 4; Iter    81/  823] train: loss: 0.2620747
[Epoch 4; Iter   111/  823] train: loss: 0.1745846
[Epoch 4; Iter   141/  823] train: loss: 0.2649282
[Epoch 4; Iter   171/  823] train: loss: 0.1834830
[Epoch 4; Iter   201/  823] train: loss: 0.0332380
[Epoch 4; Iter   231/  823] train: loss: 0.3137011
[Epoch 4; Iter   261/  823] train: loss: 0.3140546
[Epoch 4; Iter   291/  823] train: loss: 0.2852645
[Epoch 4; Iter   321/  823] train: loss: 0.0321805
[Epoch 4; Iter   351/  823] train: loss: 0.0251590
[Epoch 4; Iter   381/  823] train: loss: 0.1392603
[Epoch 4; Iter   411/  823] train: loss: 0.2735629
[Epoch 4; Iter   441/  823] train: loss: 0.1542300
[Epoch 4; Iter   471/  823] train: loss: 0.0425888
[Epoch 4; Iter   501/  823] train: loss: 0.1889822
[Epoch 4; Iter   531/  823] train: loss: 0.0930773
[Epoch 4; Iter   561/  823] train: loss: 0.1820045
[Epoch 4; Iter   591/  823] train: loss: 0.0372531
[Epoch 4; Iter   621/  823] train: loss: 0.0852383
[Epoch 4; Iter   651/  823] train: loss: 0.1150844
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/hiv/scaff/train_prop=0.6/PNA_ogbg-molhiv_GraphCL_hiv_scaff=0.6_5_26-05_09-59-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/hiv/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_hiv_scaff=0.6
logdir: runs/split/GraphCL/hiv/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molhiv
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: BCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molhiv
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 1
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  823] train: loss: 0.6945219
[Epoch 1; Iter    60/  823] train: loss: 0.6947673
[Epoch 1; Iter    90/  823] train: loss: 0.6931350
[Epoch 1; Iter   120/  823] train: loss: 0.6920546
[Epoch 1; Iter   150/  823] train: loss: 0.6904619
[Epoch 1; Iter   180/  823] train: loss: 0.6911247
[Epoch 1; Iter   210/  823] train: loss: 0.6911544
[Epoch 1; Iter   240/  823] train: loss: 0.6901659
[Epoch 1; Iter   270/  823] train: loss: 0.6894236
[Epoch 1; Iter   300/  823] train: loss: 0.6877660
[Epoch 1; Iter   330/  823] train: loss: 0.6869025
[Epoch 1; Iter   360/  823] train: loss: 0.6851560
[Epoch 1; Iter   390/  823] train: loss: 0.6843234
[Epoch 1; Iter   420/  823] train: loss: 0.6828719
[Epoch 1; Iter   450/  823] train: loss: 0.6808932
[Epoch 1; Iter   480/  823] train: loss: 0.6800752
[Epoch 1; Iter   510/  823] train: loss: 0.6793116
[Epoch 1; Iter   540/  823] train: loss: 0.6765471
[Epoch 1; Iter   570/  823] train: loss: 0.6741909
[Epoch 1; Iter   600/  823] train: loss: 0.6722171
[Epoch 1; Iter   630/  823] train: loss: 0.6700870
[Epoch 1; Iter   660/  823] train: loss: 0.6699215
[Epoch 1; Iter   690/  823] train: loss: 0.6656402
[Epoch 1; Iter   720/  823] train: loss: 0.6648827
[Epoch 1; Iter   750/  823] train: loss: 0.6404144
[Epoch 1; Iter   780/  823] train: loss: 0.6041637
[Epoch 1; Iter   810/  823] train: loss: 0.5520815
[Epoch 1] ogbg-molhiv: 0.666813 val loss: 0.562296
[Epoch 1] ogbg-molhiv: 0.693680 test loss: 0.551766
[Epoch 2; Iter    17/  823] train: loss: 0.4875212
[Epoch 2; Iter    47/  823] train: loss: 0.4247406
[Epoch 2; Iter    77/  823] train: loss: 0.3488323
[Epoch 2; Iter   107/  823] train: loss: 0.3215281
[Epoch 2; Iter   137/  823] train: loss: 0.3199702
[Epoch 2; Iter   167/  823] train: loss: 0.2596045
[Epoch 2; Iter   197/  823] train: loss: 0.1437908
[Epoch 2; Iter   227/  823] train: loss: 0.1322973
[Epoch 2; Iter   257/  823] train: loss: 0.3081760
[Epoch 2; Iter   287/  823] train: loss: 0.1563415
[Epoch 2; Iter   317/  823] train: loss: 0.2353038
[Epoch 2; Iter   347/  823] train: loss: 0.3767206
[Epoch 2; Iter   377/  823] train: loss: 0.2085847
[Epoch 2; Iter   407/  823] train: loss: 0.0496253
[Epoch 2; Iter   437/  823] train: loss: 0.2118294
[Epoch 2; Iter   467/  823] train: loss: 0.0386372
[Epoch 2; Iter   497/  823] train: loss: 0.2796971
[Epoch 2; Iter   527/  823] train: loss: 0.1252246
[Epoch 2; Iter   557/  823] train: loss: 0.1378979
[Epoch 2; Iter   587/  823] train: loss: 0.0626437
[Epoch 2; Iter   617/  823] train: loss: 0.1636850
[Epoch 2; Iter   647/  823] train: loss: 0.1087766
[Epoch 2; Iter   677/  823] train: loss: 0.0665200
[Epoch 2; Iter   707/  823] train: loss: 0.0698185
[Epoch 2; Iter   737/  823] train: loss: 0.1591526
[Epoch 2; Iter   767/  823] train: loss: 0.1800906
[Epoch 2; Iter   797/  823] train: loss: 0.2782449
[Epoch 2] ogbg-molhiv: 0.592944 val loss: 0.158387
[Epoch 2] ogbg-molhiv: 0.668460 test loss: 0.116521
[Epoch 3; Iter     4/  823] train: loss: 0.0766313
[Epoch 3; Iter    34/  823] train: loss: 0.1637425
[Epoch 3; Iter    64/  823] train: loss: 0.5168042
[Epoch 3; Iter    94/  823] train: loss: 0.1480870
[Epoch 3; Iter   124/  823] train: loss: 0.1164606
[Epoch 3; Iter   154/  823] train: loss: 0.2772922
[Epoch 3; Iter   184/  823] train: loss: 0.0386245
[Epoch 3; Iter   214/  823] train: loss: 0.0931898
[Epoch 3; Iter   244/  823] train: loss: 0.0515438
[Epoch 3; Iter   274/  823] train: loss: 0.0976544
[Epoch 3; Iter   304/  823] train: loss: 0.1621167
[Epoch 3; Iter   334/  823] train: loss: 0.2394258
[Epoch 3; Iter   364/  823] train: loss: 0.0349709
[Epoch 3; Iter   394/  823] train: loss: 0.1606666
[Epoch 3; Iter   424/  823] train: loss: 0.2558298
[Epoch 3; Iter   454/  823] train: loss: 0.1791726
[Epoch 3; Iter   484/  823] train: loss: 0.1582361
[Epoch 3; Iter   514/  823] train: loss: 0.0430909
[Epoch 3; Iter   544/  823] train: loss: 0.0985003
[Epoch 3; Iter   574/  823] train: loss: 0.1585180
[Epoch 3; Iter   604/  823] train: loss: 0.1471569
[Epoch 3; Iter   634/  823] train: loss: 0.0441282
[Epoch 3; Iter   664/  823] train: loss: 0.0416839
[Epoch 3; Iter   694/  823] train: loss: 0.0342162
[Epoch 3; Iter   724/  823] train: loss: 0.0520683
[Epoch 3; Iter   754/  823] train: loss: 0.1946654
[Epoch 3; Iter   784/  823] train: loss: 0.0582267
[Epoch 3; Iter   814/  823] train: loss: 0.0329120
[Epoch 3] ogbg-molhiv: 0.692804 val loss: 0.141655
[Epoch 3] ogbg-molhiv: 0.730082 test loss: 0.101547
[Epoch 4; Iter    21/  823] train: loss: 0.2773966
[Epoch 4; Iter    51/  823] train: loss: 0.0573871
[Epoch 4; Iter    81/  823] train: loss: 0.1592901
[Epoch 4; Iter   111/  823] train: loss: 0.1543803
[Epoch 4; Iter   141/  823] train: loss: 0.1609045
[Epoch 4; Iter   171/  823] train: loss: 0.2531525
[Epoch 4; Iter   201/  823] train: loss: 0.1171178
[Epoch 4; Iter   231/  823] train: loss: 0.1757358
[Epoch 4; Iter   261/  823] train: loss: 0.1641137
[Epoch 4; Iter   291/  823] train: loss: 0.1203493
[Epoch 4; Iter   321/  823] train: loss: 0.2628301
[Epoch 4; Iter   351/  823] train: loss: 0.3464895
[Epoch 4; Iter   381/  823] train: loss: 0.1502646
[Epoch 4; Iter   411/  823] train: loss: 0.0980540
[Epoch 4; Iter   441/  823] train: loss: 0.0324836
[Epoch 4; Iter   471/  823] train: loss: 0.0361804
[Epoch 4; Iter   501/  823] train: loss: 0.0588297
[Epoch 4; Iter   531/  823] train: loss: 0.1696153
[Epoch 4; Iter   561/  823] train: loss: 0.2596061
[Epoch 4; Iter   591/  823] train: loss: 0.0391960
[Epoch 4; Iter   621/  823] train: loss: 0.2374943
[Epoch 4; Iter   651/  823] train: loss: 0.0304513
[Epoch 3; Iter  1016/ 1097] train: loss: 0.2879734
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0356503
[Epoch 3; Iter  1076/ 1097] train: loss: 0.1131332
[Epoch 3] ogbg-molhiv: 0.732244 val loss: 0.112461
[Epoch 3] ogbg-molhiv: 0.737264 test loss: 0.119073
[Epoch 4; Iter     9/ 1097] train: loss: 0.0747329
[Epoch 4; Iter    39/ 1097] train: loss: 0.0394216
[Epoch 4; Iter    69/ 1097] train: loss: 0.0251545
[Epoch 4; Iter    99/ 1097] train: loss: 0.0263984
[Epoch 4; Iter   129/ 1097] train: loss: 0.2511824
[Epoch 4; Iter   159/ 1097] train: loss: 0.0946443
[Epoch 4; Iter   189/ 1097] train: loss: 0.0432909
[Epoch 4; Iter   219/ 1097] train: loss: 0.0375618
[Epoch 4; Iter   249/ 1097] train: loss: 0.1537941
[Epoch 4; Iter   279/ 1097] train: loss: 0.2498829
[Epoch 4; Iter   309/ 1097] train: loss: 0.0435458
[Epoch 4; Iter   339/ 1097] train: loss: 0.0456140
[Epoch 4; Iter   369/ 1097] train: loss: 0.0662571
[Epoch 4; Iter   399/ 1097] train: loss: 0.2008027
[Epoch 4; Iter   429/ 1097] train: loss: 0.0348333
[Epoch 4; Iter   459/ 1097] train: loss: 0.1368192
[Epoch 4; Iter   489/ 1097] train: loss: 0.0281033
[Epoch 4; Iter   519/ 1097] train: loss: 0.1888455
[Epoch 4; Iter   549/ 1097] train: loss: 0.0427008
[Epoch 4; Iter   579/ 1097] train: loss: 0.1243283
[Epoch 4; Iter   609/ 1097] train: loss: 0.1222722
[Epoch 4; Iter   639/ 1097] train: loss: 0.0881060
[Epoch 4; Iter   669/ 1097] train: loss: 0.2055394
[Epoch 4; Iter   699/ 1097] train: loss: 0.1016146
[Epoch 4; Iter   729/ 1097] train: loss: 0.0385397
[Epoch 4; Iter   759/ 1097] train: loss: 0.0284866
[Epoch 4; Iter   789/ 1097] train: loss: 0.0248681
[Epoch 4; Iter   819/ 1097] train: loss: 0.1487314
[Epoch 4; Iter   849/ 1097] train: loss: 0.0324902
[Epoch 4; Iter   879/ 1097] train: loss: 0.0622596
[Epoch 4; Iter   909/ 1097] train: loss: 0.0351119
[Epoch 4; Iter   939/ 1097] train: loss: 0.3037733
[Epoch 4; Iter   969/ 1097] train: loss: 0.0851412
[Epoch 4; Iter   999/ 1097] train: loss: 0.0401350
[Epoch 4; Iter  1029/ 1097] train: loss: 0.1917348
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1913283
[Epoch 4; Iter  1089/ 1097] train: loss: 0.1751931
[Epoch 4] ogbg-molhiv: 0.766727 val loss: 0.103318
[Epoch 4] ogbg-molhiv: 0.744785 test loss: 0.136097
[Epoch 5; Iter    22/ 1097] train: loss: 0.1033383
[Epoch 5; Iter    52/ 1097] train: loss: 0.1710795
[Epoch 5; Iter    82/ 1097] train: loss: 0.1456616
[Epoch 5; Iter   112/ 1097] train: loss: 0.3403797
[Epoch 5; Iter   142/ 1097] train: loss: 0.2894906
[Epoch 5; Iter   172/ 1097] train: loss: 0.0322463
[Epoch 5; Iter   202/ 1097] train: loss: 0.1837011
[Epoch 5; Iter   232/ 1097] train: loss: 0.1797032
[Epoch 5; Iter   262/ 1097] train: loss: 0.0424503
[Epoch 5; Iter   292/ 1097] train: loss: 0.1907460
[Epoch 5; Iter   322/ 1097] train: loss: 0.0281657
[Epoch 5; Iter   352/ 1097] train: loss: 0.0840359
[Epoch 5; Iter   382/ 1097] train: loss: 0.1588756
[Epoch 5; Iter   412/ 1097] train: loss: 0.3704288
[Epoch 5; Iter   442/ 1097] train: loss: 0.1113095
[Epoch 5; Iter   472/ 1097] train: loss: 0.1400524
[Epoch 5; Iter   502/ 1097] train: loss: 0.1441403
[Epoch 5; Iter   532/ 1097] train: loss: 0.2563429
[Epoch 5; Iter   562/ 1097] train: loss: 0.2414943
[Epoch 5; Iter   592/ 1097] train: loss: 0.0542224
[Epoch 5; Iter   622/ 1097] train: loss: 0.0346543
[Epoch 5; Iter   652/ 1097] train: loss: 0.0825070
[Epoch 5; Iter   682/ 1097] train: loss: 0.1441738
[Epoch 5; Iter   712/ 1097] train: loss: 0.0295033
[Epoch 5; Iter   742/ 1097] train: loss: 0.1918097
[Epoch 5; Iter   772/ 1097] train: loss: 0.2547476
[Epoch 5; Iter   802/ 1097] train: loss: 0.0535526
[Epoch 5; Iter   832/ 1097] train: loss: 0.0540110
[Epoch 5; Iter   862/ 1097] train: loss: 0.0794648
[Epoch 5; Iter   892/ 1097] train: loss: 0.0375636
[Epoch 5; Iter   922/ 1097] train: loss: 0.0385476
[Epoch 5; Iter   952/ 1097] train: loss: 0.0295040
[Epoch 5; Iter   982/ 1097] train: loss: 0.0509876
[Epoch 5; Iter  1012/ 1097] train: loss: 0.0322712
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2062788
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0433830
[Epoch 5] ogbg-molhiv: 0.762239 val loss: 0.101721
[Epoch 5] ogbg-molhiv: 0.759655 test loss: 0.115389
[Epoch 6; Iter     5/ 1097] train: loss: 0.0766389
[Epoch 6; Iter    35/ 1097] train: loss: 0.3060760
[Epoch 6; Iter    65/ 1097] train: loss: 0.0245421
[Epoch 6; Iter    95/ 1097] train: loss: 0.1154330
[Epoch 6; Iter   125/ 1097] train: loss: 0.4262856
[Epoch 6; Iter   155/ 1097] train: loss: 0.3213976
[Epoch 6; Iter   185/ 1097] train: loss: 0.0341989
[Epoch 6; Iter   215/ 1097] train: loss: 0.1328561
[Epoch 6; Iter   245/ 1097] train: loss: 0.2805409
[Epoch 6; Iter   275/ 1097] train: loss: 0.0381625
[Epoch 6; Iter   305/ 1097] train: loss: 0.1912156
[Epoch 6; Iter   335/ 1097] train: loss: 0.0761432
[Epoch 6; Iter   365/ 1097] train: loss: 0.2873353
[Epoch 6; Iter   395/ 1097] train: loss: 0.2705427
[Epoch 6; Iter   425/ 1097] train: loss: 0.0352630
[Epoch 6; Iter   455/ 1097] train: loss: 0.3265480
[Epoch 6; Iter   485/ 1097] train: loss: 0.0337616
[Epoch 6; Iter   515/ 1097] train: loss: 0.0883439
[Epoch 6; Iter   545/ 1097] train: loss: 0.1809455
[Epoch 6; Iter   575/ 1097] train: loss: 0.2238542
[Epoch 6; Iter   605/ 1097] train: loss: 0.0303988
[Epoch 6; Iter   635/ 1097] train: loss: 0.0273117
[Epoch 6; Iter   665/ 1097] train: loss: 0.1720901
[Epoch 6; Iter   695/ 1097] train: loss: 0.1925777
[Epoch 6; Iter   725/ 1097] train: loss: 0.1990484
[Epoch 6; Iter   755/ 1097] train: loss: 0.0388851
[Epoch 6; Iter   785/ 1097] train: loss: 0.0995530
[Epoch 6; Iter   815/ 1097] train: loss: 0.0356800
[Epoch 6; Iter   845/ 1097] train: loss: 0.1033577
[Epoch 6; Iter   875/ 1097] train: loss: 0.1325304
[Epoch 6; Iter   905/ 1097] train: loss: 0.3323328
[Epoch 6; Iter   935/ 1097] train: loss: 0.0328897
[Epoch 6; Iter   965/ 1097] train: loss: 0.0271250
[Epoch 6; Iter   995/ 1097] train: loss: 0.2329697
[Epoch 6; Iter  1025/ 1097] train: loss: 0.2155836
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0369734
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2326777
[Epoch 6] ogbg-molhiv: 0.760294 val loss: 0.096157
[Epoch 6] ogbg-molhiv: 0.697386 test loss: 0.140880
[Epoch 7; Iter    18/ 1097] train: loss: 0.2474813
[Epoch 7; Iter    48/ 1097] train: loss: 0.7672572
[Epoch 7; Iter    78/ 1097] train: loss: 0.3747445
[Epoch 7; Iter   108/ 1097] train: loss: 0.0426883
[Epoch 7; Iter   138/ 1097] train: loss: 0.0257345
[Epoch 7; Iter   168/ 1097] train: loss: 0.0408895
[Epoch 7; Iter   198/ 1097] train: loss: 0.1811229
[Epoch 7; Iter   228/ 1097] train: loss: 0.1524355
[Epoch 7; Iter   258/ 1097] train: loss: 0.1407771
[Epoch 7; Iter   288/ 1097] train: loss: 0.1822060
[Epoch 7; Iter   318/ 1097] train: loss: 0.0335233
[Epoch 7; Iter   348/ 1097] train: loss: 0.0311704
[Epoch 7; Iter   378/ 1097] train: loss: 0.0274625
[Epoch 7; Iter   408/ 1097] train: loss: 0.0405514
[Epoch 7; Iter   438/ 1097] train: loss: 0.0282674
[Epoch 7; Iter   468/ 1097] train: loss: 0.3006254
[Epoch 7; Iter   498/ 1097] train: loss: 0.0352093
[Epoch 7; Iter   528/ 1097] train: loss: 0.0318740
[Epoch 7; Iter   558/ 1097] train: loss: 0.2714717
[Epoch 7; Iter   588/ 1097] train: loss: 0.1683145
[Epoch 7; Iter   618/ 1097] train: loss: 0.2200964
[Epoch 7; Iter   648/ 1097] train: loss: 0.2106451
[Epoch 7; Iter   678/ 1097] train: loss: 0.0801540
[Epoch 7; Iter   708/ 1097] train: loss: 0.0944967
[Epoch 7; Iter   738/ 1097] train: loss: 0.0515511
[Epoch 7; Iter   768/ 1097] train: loss: 0.1195049
[Epoch 7; Iter   798/ 1097] train: loss: 0.2596287
[Epoch 7; Iter   828/ 1097] train: loss: 0.1674988
[Epoch 7; Iter   858/ 1097] train: loss: 0.1636835
[Epoch 7; Iter   888/ 1097] train: loss: 0.1346821
[Epoch 7; Iter   918/ 1097] train: loss: 0.1637997
[Epoch 7; Iter   948/ 1097] train: loss: 0.1785380
[Epoch 7; Iter   978/ 1097] train: loss: 0.0931549
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0274803
[Epoch 7; Iter  1038/ 1097] train: loss: 0.2383915
[Epoch 7; Iter  1068/ 1097] train: loss: 0.0459192
[Epoch 7] ogbg-molhiv: 0.757517 val loss: 0.161497
[Epoch 7] ogbg-molhiv: 0.741611 test loss: 0.181472
[Epoch 8; Iter     1/ 1097] train: loss: 0.1219393
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0438702
[Epoch 3; Iter  1046/ 1097] train: loss: 0.1356005
[Epoch 3; Iter  1076/ 1097] train: loss: 0.3290862
[Epoch 3] ogbg-molhiv: 0.754510 val loss: 0.085237
[Epoch 3] ogbg-molhiv: 0.692205 test loss: 0.127995
[Epoch 4; Iter     9/ 1097] train: loss: 0.2331858
[Epoch 4; Iter    39/ 1097] train: loss: 0.1964575
[Epoch 4; Iter    69/ 1097] train: loss: 0.0452988
[Epoch 4; Iter    99/ 1097] train: loss: 0.3300002
[Epoch 4; Iter   129/ 1097] train: loss: 0.1518773
[Epoch 4; Iter   159/ 1097] train: loss: 0.1166625
[Epoch 4; Iter   189/ 1097] train: loss: 0.2848007
[Epoch 4; Iter   219/ 1097] train: loss: 0.1609160
[Epoch 4; Iter   249/ 1097] train: loss: 0.1767543
[Epoch 4; Iter   279/ 1097] train: loss: 0.1592492
[Epoch 4; Iter   309/ 1097] train: loss: 0.1075662
[Epoch 4; Iter   339/ 1097] train: loss: 0.0257331
[Epoch 4; Iter   369/ 1097] train: loss: 0.1314767
[Epoch 4; Iter   399/ 1097] train: loss: 0.1354958
[Epoch 4; Iter   429/ 1097] train: loss: 0.1625941
[Epoch 4; Iter   459/ 1097] train: loss: 0.0364384
[Epoch 4; Iter   489/ 1097] train: loss: 0.1385746
[Epoch 4; Iter   519/ 1097] train: loss: 0.2908765
[Epoch 4; Iter   549/ 1097] train: loss: 0.1950061
[Epoch 4; Iter   579/ 1097] train: loss: 0.0348369
[Epoch 4; Iter   609/ 1097] train: loss: 0.3115759
[Epoch 4; Iter   639/ 1097] train: loss: 0.3155514
[Epoch 4; Iter   669/ 1097] train: loss: 0.3183367
[Epoch 4; Iter   699/ 1097] train: loss: 0.0365864
[Epoch 4; Iter   729/ 1097] train: loss: 0.2076228
[Epoch 4; Iter   759/ 1097] train: loss: 0.2485455
[Epoch 4; Iter   789/ 1097] train: loss: 0.3904308
[Epoch 4; Iter   819/ 1097] train: loss: 0.1665296
[Epoch 4; Iter   849/ 1097] train: loss: 0.0445720
[Epoch 4; Iter   879/ 1097] train: loss: 0.0329340
[Epoch 4; Iter   909/ 1097] train: loss: 0.3981546
[Epoch 4; Iter   939/ 1097] train: loss: 0.1085851
[Epoch 4; Iter   969/ 1097] train: loss: 0.0411766
[Epoch 4; Iter   999/ 1097] train: loss: 0.1996148
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2883516
[Epoch 4; Iter  1059/ 1097] train: loss: 0.3179044
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0454056
[Epoch 4] ogbg-molhiv: 0.758475 val loss: 0.089559
[Epoch 4] ogbg-molhiv: 0.745646 test loss: 0.118819
[Epoch 5; Iter    22/ 1097] train: loss: 0.3287099
[Epoch 5; Iter    52/ 1097] train: loss: 0.1784368
[Epoch 5; Iter    82/ 1097] train: loss: 0.0863045
[Epoch 5; Iter   112/ 1097] train: loss: 0.0633005
[Epoch 5; Iter   142/ 1097] train: loss: 0.1160640
[Epoch 5; Iter   172/ 1097] train: loss: 0.0351886
[Epoch 5; Iter   202/ 1097] train: loss: 0.1424343
[Epoch 5; Iter   232/ 1097] train: loss: 0.0361848
[Epoch 5; Iter   262/ 1097] train: loss: 0.0434381
[Epoch 5; Iter   292/ 1097] train: loss: 0.1904355
[Epoch 5; Iter   322/ 1097] train: loss: 0.1763391
[Epoch 5; Iter   352/ 1097] train: loss: 0.0581896
[Epoch 5; Iter   382/ 1097] train: loss: 0.2468262
[Epoch 5; Iter   412/ 1097] train: loss: 0.2986820
[Epoch 5; Iter   442/ 1097] train: loss: 0.3040788
[Epoch 5; Iter   472/ 1097] train: loss: 0.1398523
[Epoch 5; Iter   502/ 1097] train: loss: 0.1966238
[Epoch 5; Iter   532/ 1097] train: loss: 0.0656065
[Epoch 5; Iter   562/ 1097] train: loss: 0.0427543
[Epoch 5; Iter   592/ 1097] train: loss: 0.0383438
[Epoch 5; Iter   622/ 1097] train: loss: 0.1260208
[Epoch 5; Iter   652/ 1097] train: loss: 0.1340561
[Epoch 5; Iter   682/ 1097] train: loss: 0.1875018
[Epoch 5; Iter   712/ 1097] train: loss: 0.0255165
[Epoch 5; Iter   742/ 1097] train: loss: 0.1613993
[Epoch 5; Iter   772/ 1097] train: loss: 0.1889832
[Epoch 5; Iter   802/ 1097] train: loss: 0.2244948
[Epoch 5; Iter   832/ 1097] train: loss: 0.0323070
[Epoch 5; Iter   862/ 1097] train: loss: 0.2046985
[Epoch 5; Iter   892/ 1097] train: loss: 0.0462610
[Epoch 5; Iter   922/ 1097] train: loss: 0.2797282
[Epoch 5; Iter   952/ 1097] train: loss: 0.0301262
[Epoch 5; Iter   982/ 1097] train: loss: 0.2793823
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2754315
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2369711
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0540324
[Epoch 5] ogbg-molhiv: 0.765989 val loss: 0.125139
[Epoch 5] ogbg-molhiv: 0.706638 test loss: 0.164657
[Epoch 6; Iter     5/ 1097] train: loss: 0.1075896
[Epoch 6; Iter    35/ 1097] train: loss: 0.0916498
[Epoch 6; Iter    65/ 1097] train: loss: 0.1060894
[Epoch 6; Iter    95/ 1097] train: loss: 0.0417149
[Epoch 6; Iter   125/ 1097] train: loss: 0.1245959
[Epoch 6; Iter   155/ 1097] train: loss: 0.0254557
[Epoch 6; Iter   185/ 1097] train: loss: 0.0305739
[Epoch 6; Iter   215/ 1097] train: loss: 0.3201807
[Epoch 6; Iter   245/ 1097] train: loss: 0.2364873
[Epoch 6; Iter   275/ 1097] train: loss: 0.0320362
[Epoch 6; Iter   305/ 1097] train: loss: 0.0356230
[Epoch 6; Iter   335/ 1097] train: loss: 0.1764380
[Epoch 6; Iter   365/ 1097] train: loss: 0.0623366
[Epoch 6; Iter   395/ 1097] train: loss: 0.2643239
[Epoch 6; Iter   425/ 1097] train: loss: 0.1605420
[Epoch 6; Iter   455/ 1097] train: loss: 0.1065116
[Epoch 6; Iter   485/ 1097] train: loss: 0.1939441
[Epoch 6; Iter   515/ 1097] train: loss: 0.0269550
[Epoch 6; Iter   545/ 1097] train: loss: 0.1340479
[Epoch 6; Iter   575/ 1097] train: loss: 0.0341306
[Epoch 6; Iter   605/ 1097] train: loss: 0.0301356
[Epoch 6; Iter   635/ 1097] train: loss: 0.0336868
[Epoch 6; Iter   665/ 1097] train: loss: 0.0421277
[Epoch 6; Iter   695/ 1097] train: loss: 0.1725646
[Epoch 6; Iter   725/ 1097] train: loss: 0.0343119
[Epoch 6; Iter   755/ 1097] train: loss: 0.0814425
[Epoch 6; Iter   785/ 1097] train: loss: 0.0231887
[Epoch 6; Iter   815/ 1097] train: loss: 0.1568711
[Epoch 6; Iter   845/ 1097] train: loss: 0.1013001
[Epoch 6; Iter   875/ 1097] train: loss: 0.1560525
[Epoch 6; Iter   905/ 1097] train: loss: 0.3677733
[Epoch 6; Iter   935/ 1097] train: loss: 0.1792514
[Epoch 6; Iter   965/ 1097] train: loss: 0.1230064
[Epoch 6; Iter   995/ 1097] train: loss: 0.0346136
[Epoch 6; Iter  1025/ 1097] train: loss: 0.0296949
[Epoch 6; Iter  1055/ 1097] train: loss: 0.0811745
[Epoch 6; Iter  1085/ 1097] train: loss: 0.2134798
[Epoch 6] ogbg-molhiv: 0.778517 val loss: 0.094328
[Epoch 6] ogbg-molhiv: 0.718162 test loss: 0.128051
[Epoch 7; Iter    18/ 1097] train: loss: 0.0360962
[Epoch 7; Iter    48/ 1097] train: loss: 0.0919564
[Epoch 7; Iter    78/ 1097] train: loss: 0.1688641
[Epoch 7; Iter   108/ 1097] train: loss: 0.0332171
[Epoch 7; Iter   138/ 1097] train: loss: 0.0429573
[Epoch 7; Iter   168/ 1097] train: loss: 0.1222860
[Epoch 7; Iter   198/ 1097] train: loss: 0.0727673
[Epoch 7; Iter   228/ 1097] train: loss: 0.0258450
[Epoch 7; Iter   258/ 1097] train: loss: 0.0365817
[Epoch 7; Iter   288/ 1097] train: loss: 0.0851966
[Epoch 7; Iter   318/ 1097] train: loss: 0.0431852
[Epoch 7; Iter   348/ 1097] train: loss: 0.2046417
[Epoch 7; Iter   378/ 1097] train: loss: 0.1571337
[Epoch 7; Iter   408/ 1097] train: loss: 0.1262169
[Epoch 7; Iter   438/ 1097] train: loss: 0.1880025
[Epoch 7; Iter   468/ 1097] train: loss: 0.0426846
[Epoch 7; Iter   498/ 1097] train: loss: 0.0302974
[Epoch 7; Iter   528/ 1097] train: loss: 0.0399580
[Epoch 7; Iter   558/ 1097] train: loss: 0.0298448
[Epoch 7; Iter   588/ 1097] train: loss: 0.2554249
[Epoch 7; Iter   618/ 1097] train: loss: 0.3874366
[Epoch 7; Iter   648/ 1097] train: loss: 0.2388117
[Epoch 7; Iter   678/ 1097] train: loss: 0.0555383
[Epoch 7; Iter   708/ 1097] train: loss: 0.1605940
[Epoch 7; Iter   738/ 1097] train: loss: 0.2129651
[Epoch 7; Iter   768/ 1097] train: loss: 0.0359341
[Epoch 7; Iter   798/ 1097] train: loss: 0.1133877
[Epoch 7; Iter   828/ 1097] train: loss: 0.1398371
[Epoch 7; Iter   858/ 1097] train: loss: 0.0742677
[Epoch 7; Iter   888/ 1097] train: loss: 0.0231141
[Epoch 7; Iter   918/ 1097] train: loss: 0.0606480
[Epoch 7; Iter   948/ 1097] train: loss: 0.1421952
[Epoch 7; Iter   978/ 1097] train: loss: 0.0384683
[Epoch 7; Iter  1008/ 1097] train: loss: 0.1493114
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0272978
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1549985
[Epoch 7] ogbg-molhiv: 0.719690 val loss: 5.200450
[Epoch 7] ogbg-molhiv: 0.643979 test loss: 5.164832
[Epoch 8; Iter     1/ 1097] train: loss: 0.1405453
[Epoch 3; Iter  1016/ 1097] train: loss: 0.0788880
[Epoch 3; Iter  1046/ 1097] train: loss: 0.0646292
[Epoch 3; Iter  1076/ 1097] train: loss: 0.0336451
[Epoch 3] ogbg-molhiv: 0.775873 val loss: 0.099938
[Epoch 3] ogbg-molhiv: 0.743269 test loss: 0.170907
[Epoch 4; Iter     9/ 1097] train: loss: 0.3825997
[Epoch 4; Iter    39/ 1097] train: loss: 0.1076134
[Epoch 4; Iter    69/ 1097] train: loss: 0.1083717
[Epoch 4; Iter    99/ 1097] train: loss: 0.0403102
[Epoch 4; Iter   129/ 1097] train: loss: 0.1245898
[Epoch 4; Iter   159/ 1097] train: loss: 0.4279664
[Epoch 4; Iter   189/ 1097] train: loss: 0.0339354
[Epoch 4; Iter   219/ 1097] train: loss: 0.3778849
[Epoch 4; Iter   249/ 1097] train: loss: 0.0395349
[Epoch 4; Iter   279/ 1097] train: loss: 0.1033115
[Epoch 4; Iter   309/ 1097] train: loss: 0.1527566
[Epoch 4; Iter   339/ 1097] train: loss: 0.0966029
[Epoch 4; Iter   369/ 1097] train: loss: 0.1772719
[Epoch 4; Iter   399/ 1097] train: loss: 0.1468911
[Epoch 4; Iter   429/ 1097] train: loss: 0.0831826
[Epoch 4; Iter   459/ 1097] train: loss: 0.0311560
[Epoch 4; Iter   489/ 1097] train: loss: 0.0315729
[Epoch 4; Iter   519/ 1097] train: loss: 0.0820377
[Epoch 4; Iter   549/ 1097] train: loss: 0.0527844
[Epoch 4; Iter   579/ 1097] train: loss: 0.0335709
[Epoch 4; Iter   609/ 1097] train: loss: 0.2398542
[Epoch 4; Iter   639/ 1097] train: loss: 0.0313362
[Epoch 4; Iter   669/ 1097] train: loss: 0.2534690
[Epoch 4; Iter   699/ 1097] train: loss: 0.0788885
[Epoch 4; Iter   729/ 1097] train: loss: 0.3462230
[Epoch 4; Iter   759/ 1097] train: loss: 0.0593164
[Epoch 4; Iter   789/ 1097] train: loss: 0.3566086
[Epoch 4; Iter   819/ 1097] train: loss: 0.0368048
[Epoch 4; Iter   849/ 1097] train: loss: 0.2279681
[Epoch 4; Iter   879/ 1097] train: loss: 0.1206348
[Epoch 4; Iter   909/ 1097] train: loss: 0.5461442
[Epoch 4; Iter   939/ 1097] train: loss: 0.0355876
[Epoch 4; Iter   969/ 1097] train: loss: 0.0409925
[Epoch 4; Iter   999/ 1097] train: loss: 0.2597575
[Epoch 4; Iter  1029/ 1097] train: loss: 0.2540943
[Epoch 4; Iter  1059/ 1097] train: loss: 0.1840304
[Epoch 4; Iter  1089/ 1097] train: loss: 0.0723448
[Epoch 4] ogbg-molhiv: 0.753800 val loss: 0.086237
[Epoch 4] ogbg-molhiv: 0.762251 test loss: 0.114873
[Epoch 5; Iter    22/ 1097] train: loss: 0.0701154
[Epoch 5; Iter    52/ 1097] train: loss: 0.1404474
[Epoch 5; Iter    82/ 1097] train: loss: 0.3891793
[Epoch 5; Iter   112/ 1097] train: loss: 0.0587011
[Epoch 5; Iter   142/ 1097] train: loss: 0.2969290
[Epoch 5; Iter   172/ 1097] train: loss: 0.2104576
[Epoch 5; Iter   202/ 1097] train: loss: 0.0337742
[Epoch 5; Iter   232/ 1097] train: loss: 0.1096983
[Epoch 5; Iter   262/ 1097] train: loss: 0.1459341
[Epoch 5; Iter   292/ 1097] train: loss: 0.2722644
[Epoch 5; Iter   322/ 1097] train: loss: 0.1630778
[Epoch 5; Iter   352/ 1097] train: loss: 0.2022825
[Epoch 5; Iter   382/ 1097] train: loss: 0.2938483
[Epoch 5; Iter   412/ 1097] train: loss: 0.0314020
[Epoch 5; Iter   442/ 1097] train: loss: 0.1610962
[Epoch 5; Iter   472/ 1097] train: loss: 0.1796293
[Epoch 5; Iter   502/ 1097] train: loss: 0.1033459
[Epoch 5; Iter   532/ 1097] train: loss: 0.0461817
[Epoch 5; Iter   562/ 1097] train: loss: 0.2845807
[Epoch 5; Iter   592/ 1097] train: loss: 0.0764333
[Epoch 5; Iter   622/ 1097] train: loss: 0.1447454
[Epoch 5; Iter   652/ 1097] train: loss: 0.2548845
[Epoch 5; Iter   682/ 1097] train: loss: 0.0252543
[Epoch 5; Iter   712/ 1097] train: loss: 0.1851408
[Epoch 5; Iter   742/ 1097] train: loss: 0.0316458
[Epoch 5; Iter   772/ 1097] train: loss: 0.0383194
[Epoch 5; Iter   802/ 1097] train: loss: 0.1955056
[Epoch 5; Iter   832/ 1097] train: loss: 0.3126516
[Epoch 5; Iter   862/ 1097] train: loss: 0.0469117
[Epoch 5; Iter   892/ 1097] train: loss: 0.1078486
[Epoch 5; Iter   922/ 1097] train: loss: 0.1327555
[Epoch 5; Iter   952/ 1097] train: loss: 0.2081917
[Epoch 5; Iter   982/ 1097] train: loss: 0.0951028
[Epoch 5; Iter  1012/ 1097] train: loss: 0.2826698
[Epoch 5; Iter  1042/ 1097] train: loss: 0.2667184
[Epoch 5; Iter  1072/ 1097] train: loss: 0.0386668
[Epoch 5] ogbg-molhiv: 0.693593 val loss: 0.107077
[Epoch 5] ogbg-molhiv: 0.729589 test loss: 0.125117
[Epoch 6; Iter     5/ 1097] train: loss: 0.2177659
[Epoch 6; Iter    35/ 1097] train: loss: 0.4130965
[Epoch 6; Iter    65/ 1097] train: loss: 0.0446394
[Epoch 6; Iter    95/ 1097] train: loss: 0.1653840
[Epoch 6; Iter   125/ 1097] train: loss: 0.2600326
[Epoch 6; Iter   155/ 1097] train: loss: 0.0611457
[Epoch 6; Iter   185/ 1097] train: loss: 0.1718270
[Epoch 6; Iter   215/ 1097] train: loss: 0.1666387
[Epoch 6; Iter   245/ 1097] train: loss: 0.0624904
[Epoch 6; Iter   275/ 1097] train: loss: 0.1637339
[Epoch 6; Iter   305/ 1097] train: loss: 0.0203369
[Epoch 6; Iter   335/ 1097] train: loss: 0.0290736
[Epoch 6; Iter   365/ 1097] train: loss: 0.0474164
[Epoch 6; Iter   395/ 1097] train: loss: 0.1538301
[Epoch 6; Iter   425/ 1097] train: loss: 0.0528857
[Epoch 6; Iter   455/ 1097] train: loss: 0.2480758
[Epoch 6; Iter   485/ 1097] train: loss: 0.0307957
[Epoch 6; Iter   515/ 1097] train: loss: 0.1279289
[Epoch 6; Iter   545/ 1097] train: loss: 0.1714457
[Epoch 6; Iter   575/ 1097] train: loss: 0.0362473
[Epoch 6; Iter   605/ 1097] train: loss: 0.0564329
[Epoch 6; Iter   635/ 1097] train: loss: 0.2055511
[Epoch 6; Iter   665/ 1097] train: loss: 0.2639779
[Epoch 6; Iter   695/ 1097] train: loss: 0.2519740
[Epoch 6; Iter   725/ 1097] train: loss: 0.3174083
[Epoch 6; Iter   755/ 1097] train: loss: 0.2276277
[Epoch 6; Iter   785/ 1097] train: loss: 0.4343269
[Epoch 6; Iter   815/ 1097] train: loss: 0.0775203
[Epoch 6; Iter   845/ 1097] train: loss: 0.0336775
[Epoch 6; Iter   875/ 1097] train: loss: 0.1191478
[Epoch 6; Iter   905/ 1097] train: loss: 0.1967535
[Epoch 6; Iter   935/ 1097] train: loss: 0.0430976
[Epoch 6; Iter   965/ 1097] train: loss: 0.0757355
[Epoch 6; Iter   995/ 1097] train: loss: 0.0865183
[Epoch 6; Iter  1025/ 1097] train: loss: 0.1506049
[Epoch 6; Iter  1055/ 1097] train: loss: 0.1173077
[Epoch 6; Iter  1085/ 1097] train: loss: 0.1909967
[Epoch 6] ogbg-molhiv: 0.768359 val loss: 0.235072
[Epoch 6] ogbg-molhiv: 0.678041 test loss: 0.127933
[Epoch 7; Iter    18/ 1097] train: loss: 0.0393178
[Epoch 7; Iter    48/ 1097] train: loss: 0.0269978
[Epoch 7; Iter    78/ 1097] train: loss: 0.1650425
[Epoch 7; Iter   108/ 1097] train: loss: 0.3016876
[Epoch 7; Iter   138/ 1097] train: loss: 0.1456693
[Epoch 7; Iter   168/ 1097] train: loss: 0.0257130
[Epoch 7; Iter   198/ 1097] train: loss: 0.2480828
[Epoch 7; Iter   228/ 1097] train: loss: 0.1543343
[Epoch 7; Iter   258/ 1097] train: loss: 0.0222607
[Epoch 7; Iter   288/ 1097] train: loss: 0.0204661
[Epoch 7; Iter   318/ 1097] train: loss: 0.1813026
[Epoch 7; Iter   348/ 1097] train: loss: 0.0285531
[Epoch 7; Iter   378/ 1097] train: loss: 0.2247185
[Epoch 7; Iter   408/ 1097] train: loss: 0.2767946
[Epoch 7; Iter   438/ 1097] train: loss: 0.0701470
[Epoch 7; Iter   468/ 1097] train: loss: 0.0624169
[Epoch 7; Iter   498/ 1097] train: loss: 0.1953679
[Epoch 7; Iter   528/ 1097] train: loss: 0.1270785
[Epoch 7; Iter   558/ 1097] train: loss: 0.0400424
[Epoch 7; Iter   588/ 1097] train: loss: 0.2473297
[Epoch 7; Iter   618/ 1097] train: loss: 0.1033502
[Epoch 7; Iter   648/ 1097] train: loss: 0.1187003
[Epoch 7; Iter   678/ 1097] train: loss: 0.0651564
[Epoch 7; Iter   708/ 1097] train: loss: 0.1884009
[Epoch 7; Iter   738/ 1097] train: loss: 0.1889236
[Epoch 7; Iter   768/ 1097] train: loss: 0.1562417
[Epoch 7; Iter   798/ 1097] train: loss: 0.1784295
[Epoch 7; Iter   828/ 1097] train: loss: 0.0784506
[Epoch 7; Iter   858/ 1097] train: loss: 0.1654945
[Epoch 7; Iter   888/ 1097] train: loss: 0.0313570
[Epoch 7; Iter   918/ 1097] train: loss: 0.1009821
[Epoch 7; Iter   948/ 1097] train: loss: 0.0344614
[Epoch 7; Iter   978/ 1097] train: loss: 0.0581204
[Epoch 7; Iter  1008/ 1097] train: loss: 0.0737622
[Epoch 7; Iter  1038/ 1097] train: loss: 0.0275097
[Epoch 7; Iter  1068/ 1097] train: loss: 0.1583963
[Epoch 7] ogbg-molhiv: 0.747102 val loss: 0.213719
[Epoch 7] ogbg-molhiv: 0.731845 test loss: 0.142829
[Epoch 8; Iter     1/ 1097] train: loss: 0.1877602
[Epoch 4; Iter   270/  960] train: loss: 0.0469240
[Epoch 4; Iter   300/  960] train: loss: 0.0799524
[Epoch 4; Iter   330/  960] train: loss: 0.1813310
[Epoch 4; Iter   360/  960] train: loss: 0.1229889
[Epoch 4; Iter   390/  960] train: loss: 0.1375548
[Epoch 4; Iter   420/  960] train: loss: 0.2404027
[Epoch 4; Iter   450/  960] train: loss: 0.1126163
[Epoch 4; Iter   480/  960] train: loss: 0.1005878
[Epoch 4; Iter   510/  960] train: loss: 0.0280379
[Epoch 4; Iter   540/  960] train: loss: 0.2405443
[Epoch 4; Iter   570/  960] train: loss: 0.0645832
[Epoch 4; Iter   600/  960] train: loss: 0.0445798
[Epoch 4; Iter   630/  960] train: loss: 0.0347992
[Epoch 4; Iter   660/  960] train: loss: 0.1676807
[Epoch 4; Iter   690/  960] train: loss: 0.1800494
[Epoch 4; Iter   720/  960] train: loss: 0.1734481
[Epoch 4; Iter   750/  960] train: loss: 0.0377257
[Epoch 4; Iter   780/  960] train: loss: 0.1775455
[Epoch 4; Iter   810/  960] train: loss: 0.1106841
[Epoch 4; Iter   840/  960] train: loss: 0.0366451
[Epoch 4; Iter   870/  960] train: loss: 0.1197883
[Epoch 4; Iter   900/  960] train: loss: 0.0500599
[Epoch 4; Iter   930/  960] train: loss: 0.0476900
[Epoch 4; Iter   960/  960] train: loss: 0.0512189
[Epoch 4] ogbg-molhiv: 0.726851 val loss: 0.275381
[Epoch 4] ogbg-molhiv: 0.736140 test loss: 0.281486
[Epoch 5; Iter    30/  960] train: loss: 0.1495001
[Epoch 5; Iter    60/  960] train: loss: 0.0298550
[Epoch 5; Iter    90/  960] train: loss: 0.0285755
[Epoch 5; Iter   120/  960] train: loss: 0.1821493
[Epoch 5; Iter   150/  960] train: loss: 0.1437864
[Epoch 5; Iter   180/  960] train: loss: 0.0351969
[Epoch 5; Iter   210/  960] train: loss: 0.0541721
[Epoch 5; Iter   240/  960] train: loss: 0.0416632
[Epoch 5; Iter   270/  960] train: loss: 0.1877353
[Epoch 5; Iter   300/  960] train: loss: 0.0278982
[Epoch 5; Iter   330/  960] train: loss: 0.1642915
[Epoch 5; Iter   360/  960] train: loss: 0.1131933
[Epoch 5; Iter   390/  960] train: loss: 0.0435881
[Epoch 5; Iter   420/  960] train: loss: 0.2008474
[Epoch 5; Iter   450/  960] train: loss: 0.0368028
[Epoch 5; Iter   480/  960] train: loss: 0.2513706
[Epoch 5; Iter   510/  960] train: loss: 0.2708826
[Epoch 5; Iter   540/  960] train: loss: 0.1674446
[Epoch 5; Iter   570/  960] train: loss: 0.0663529
[Epoch 5; Iter   600/  960] train: loss: 0.0399340
[Epoch 5; Iter   630/  960] train: loss: 0.1419374
[Epoch 5; Iter   660/  960] train: loss: 0.0353509
[Epoch 5; Iter   690/  960] train: loss: 0.0755062
[Epoch 5; Iter   720/  960] train: loss: 0.0466192
[Epoch 5; Iter   750/  960] train: loss: 0.1071018
[Epoch 5; Iter   780/  960] train: loss: 0.1306998
[Epoch 5; Iter   810/  960] train: loss: 0.1351037
[Epoch 5; Iter   840/  960] train: loss: 0.0324317
[Epoch 5; Iter   870/  960] train: loss: 0.0932576
[Epoch 5; Iter   900/  960] train: loss: 0.0857091
[Epoch 5; Iter   930/  960] train: loss: 0.0315571
[Epoch 5; Iter   960/  960] train: loss: 0.1002728
[Epoch 5] ogbg-molhiv: 0.745735 val loss: 0.228741
[Epoch 5] ogbg-molhiv: 0.720770 test loss: 0.303699
[Epoch 6; Iter    30/  960] train: loss: 0.0286481
[Epoch 6; Iter    60/  960] train: loss: 0.1291714
[Epoch 6; Iter    90/  960] train: loss: 0.1520423
[Epoch 6; Iter   120/  960] train: loss: 0.3261805
[Epoch 6; Iter   150/  960] train: loss: 0.0464020
[Epoch 6; Iter   180/  960] train: loss: 0.0256746
[Epoch 6; Iter   210/  960] train: loss: 0.0466350
[Epoch 6; Iter   240/  960] train: loss: 0.1665543
[Epoch 6; Iter   270/  960] train: loss: 0.0352882
[Epoch 6; Iter   300/  960] train: loss: 0.0334771
[Epoch 6; Iter   330/  960] train: loss: 0.0510183
[Epoch 6; Iter   360/  960] train: loss: 0.1735857
[Epoch 6; Iter   390/  960] train: loss: 0.3317064
[Epoch 6; Iter   420/  960] train: loss: 0.1242725
[Epoch 6; Iter   450/  960] train: loss: 0.3005637
[Epoch 6; Iter   480/  960] train: loss: 0.1796549
[Epoch 6; Iter   510/  960] train: loss: 0.0327843
[Epoch 6; Iter   540/  960] train: loss: 0.0229104
[Epoch 6; Iter   570/  960] train: loss: 0.0523551
[Epoch 6; Iter   600/  960] train: loss: 0.0268685
[Epoch 6; Iter   630/  960] train: loss: 0.0353586
[Epoch 6; Iter   660/  960] train: loss: 0.2172321
[Epoch 6; Iter   690/  960] train: loss: 0.3632926
[Epoch 6; Iter   720/  960] train: loss: 0.0963423
[Epoch 6; Iter   750/  960] train: loss: 0.2859732
[Epoch 6; Iter   780/  960] train: loss: 0.1636437
[Epoch 6; Iter   810/  960] train: loss: 0.0705198
[Epoch 6; Iter   840/  960] train: loss: 0.0441533
[Epoch 6; Iter   870/  960] train: loss: 0.0377017
[Epoch 6; Iter   900/  960] train: loss: 0.0877847
[Epoch 6; Iter   930/  960] train: loss: 0.0568016
[Epoch 6; Iter   960/  960] train: loss: 0.0460724
[Epoch 6] ogbg-molhiv: 0.751493 val loss: 0.144711
[Epoch 6] ogbg-molhiv: 0.721381 test loss: 0.224875
[Epoch 7; Iter    30/  960] train: loss: 0.1777977
[Epoch 7; Iter    60/  960] train: loss: 0.0490993
[Epoch 7; Iter    90/  960] train: loss: 0.1473536
[Epoch 7; Iter   120/  960] train: loss: 0.0733453
[Epoch 7; Iter   150/  960] train: loss: 0.0249777
[Epoch 7; Iter   180/  960] train: loss: 0.1996706
[Epoch 7; Iter   210/  960] train: loss: 0.0315109
[Epoch 7; Iter   240/  960] train: loss: 0.0243285
[Epoch 7; Iter   270/  960] train: loss: 0.2248656
[Epoch 7; Iter   300/  960] train: loss: 0.1712797
[Epoch 7; Iter   330/  960] train: loss: 0.1796139
[Epoch 7; Iter   360/  960] train: loss: 0.0263672
[Epoch 7; Iter   390/  960] train: loss: 0.0797853
[Epoch 7; Iter   420/  960] train: loss: 0.1163593
[Epoch 7; Iter   450/  960] train: loss: 0.0454543
[Epoch 7; Iter   480/  960] train: loss: 0.0314180
[Epoch 7; Iter   510/  960] train: loss: 0.1150284
[Epoch 7; Iter   540/  960] train: loss: 0.2303593
[Epoch 7; Iter   570/  960] train: loss: 0.0330319
[Epoch 7; Iter   600/  960] train: loss: 0.0337050
[Epoch 7; Iter   630/  960] train: loss: 0.1194997
[Epoch 7; Iter   660/  960] train: loss: 0.2015724
[Epoch 7; Iter   690/  960] train: loss: 0.2163727
[Epoch 7; Iter   720/  960] train: loss: 0.1742400
[Epoch 7; Iter   750/  960] train: loss: 0.0223151
[Epoch 7; Iter   780/  960] train: loss: 0.0399271
[Epoch 7; Iter   810/  960] train: loss: 0.0718117
[Epoch 7; Iter   840/  960] train: loss: 0.0841563
[Epoch 7; Iter   870/  960] train: loss: 0.0990812
[Epoch 7; Iter   900/  960] train: loss: 0.0276584
[Epoch 7; Iter   930/  960] train: loss: 0.2542091
[Epoch 7; Iter   960/  960] train: loss: 0.0538072
[Epoch 7] ogbg-molhiv: 0.750042 val loss: 0.120742
[Epoch 7] ogbg-molhiv: 0.749813 test loss: 0.104723
[Epoch 8; Iter    30/  960] train: loss: 0.0359104
[Epoch 8; Iter    60/  960] train: loss: 0.3861942
[Epoch 8; Iter    90/  960] train: loss: 0.0430117
[Epoch 8; Iter   120/  960] train: loss: 0.0877810
[Epoch 8; Iter   150/  960] train: loss: 0.3127917
[Epoch 8; Iter   180/  960] train: loss: 0.0591566
[Epoch 8; Iter   210/  960] train: loss: 0.0428137
[Epoch 8; Iter   240/  960] train: loss: 0.0958896
[Epoch 8; Iter   270/  960] train: loss: 0.0482169
[Epoch 8; Iter   300/  960] train: loss: 0.0357761
[Epoch 8; Iter   330/  960] train: loss: 0.2808515
[Epoch 8; Iter   360/  960] train: loss: 0.0324030
[Epoch 8; Iter   390/  960] train: loss: 0.1738599
[Epoch 8; Iter   420/  960] train: loss: 0.0670550
[Epoch 8; Iter   450/  960] train: loss: 0.0309983
[Epoch 8; Iter   480/  960] train: loss: 0.1708905
[Epoch 8; Iter   510/  960] train: loss: 0.2661891
[Epoch 8; Iter   540/  960] train: loss: 0.0515537
[Epoch 8; Iter   570/  960] train: loss: 0.1909252
[Epoch 8; Iter   600/  960] train: loss: 0.3573399
[Epoch 8; Iter   630/  960] train: loss: 0.2608460
[Epoch 8; Iter   660/  960] train: loss: 0.0279440
[Epoch 8; Iter   690/  960] train: loss: 0.0368992
[Epoch 8; Iter   720/  960] train: loss: 0.1369473
[Epoch 8; Iter   750/  960] train: loss: 0.0722075
[Epoch 8; Iter   780/  960] train: loss: 0.0382184
[Epoch 8; Iter   810/  960] train: loss: 0.0274478
[Epoch 8; Iter   840/  960] train: loss: 0.1648484
[Epoch 8; Iter   870/  960] train: loss: 0.2290887
[Epoch 8; Iter   900/  960] train: loss: 0.2440422
[Epoch 8; Iter   930/  960] train: loss: 0.0484218
[Epoch 8; Iter   960/  960] train: loss: 0.2980387
[Epoch 4; Iter   270/  960] train: loss: 0.0494097
[Epoch 4; Iter   300/  960] train: loss: 0.1262465
[Epoch 4; Iter   330/  960] train: loss: 0.0385804
[Epoch 4; Iter   360/  960] train: loss: 0.3178581
[Epoch 4; Iter   390/  960] train: loss: 0.1289516
[Epoch 4; Iter   420/  960] train: loss: 0.0629210
[Epoch 4; Iter   450/  960] train: loss: 0.1696195
[Epoch 4; Iter   480/  960] train: loss: 0.1593270
[Epoch 4; Iter   510/  960] train: loss: 0.1699080
[Epoch 4; Iter   540/  960] train: loss: 0.0344438
[Epoch 4; Iter   570/  960] train: loss: 0.3071089
[Epoch 4; Iter   600/  960] train: loss: 0.3243146
[Epoch 4; Iter   630/  960] train: loss: 0.1834050
[Epoch 4; Iter   660/  960] train: loss: 0.0683885
[Epoch 4; Iter   690/  960] train: loss: 0.0387936
[Epoch 4; Iter   720/  960] train: loss: 0.2413262
[Epoch 4; Iter   750/  960] train: loss: 0.2474488
[Epoch 4; Iter   780/  960] train: loss: 0.2006790
[Epoch 4; Iter   810/  960] train: loss: 0.1730629
[Epoch 4; Iter   840/  960] train: loss: 0.1787325
[Epoch 4; Iter   870/  960] train: loss: 0.1627341
[Epoch 4; Iter   900/  960] train: loss: 0.1471266
[Epoch 4; Iter   930/  960] train: loss: 0.0319831
[Epoch 4; Iter   960/  960] train: loss: 0.0444108
[Epoch 4] ogbg-molhiv: 0.744318 val loss: 0.134260
[Epoch 4] ogbg-molhiv: 0.752409 test loss: 0.111004
[Epoch 5; Iter    30/  960] train: loss: 0.2762368
[Epoch 5; Iter    60/  960] train: loss: 0.3284730
[Epoch 5; Iter    90/  960] train: loss: 0.1813851
[Epoch 5; Iter   120/  960] train: loss: 0.1197641
[Epoch 5; Iter   150/  960] train: loss: 0.0483288
[Epoch 5; Iter   180/  960] train: loss: 0.0317394
[Epoch 5; Iter   210/  960] train: loss: 0.0847803
[Epoch 5; Iter   240/  960] train: loss: 0.2518574
[Epoch 5; Iter   270/  960] train: loss: 0.0342117
[Epoch 5; Iter   300/  960] train: loss: 0.0358066
[Epoch 5; Iter   330/  960] train: loss: 0.0316433
[Epoch 5; Iter   360/  960] train: loss: 0.1439023
[Epoch 5; Iter   390/  960] train: loss: 0.0349806
[Epoch 5; Iter   420/  960] train: loss: 0.0526983
[Epoch 5; Iter   450/  960] train: loss: 0.0381735
[Epoch 5; Iter   480/  960] train: loss: 0.0366386
[Epoch 5; Iter   510/  960] train: loss: 0.1586579
[Epoch 5; Iter   540/  960] train: loss: 0.0336198
[Epoch 5; Iter   570/  960] train: loss: 0.0359099
[Epoch 5; Iter   600/  960] train: loss: 0.1554924
[Epoch 5; Iter   630/  960] train: loss: 0.2599134
[Epoch 5; Iter   660/  960] train: loss: 0.1722257
[Epoch 5; Iter   690/  960] train: loss: 0.0476913
[Epoch 5; Iter   720/  960] train: loss: 0.0375646
[Epoch 5; Iter   750/  960] train: loss: 0.0266904
[Epoch 5; Iter   780/  960] train: loss: 0.1292624
[Epoch 5; Iter   810/  960] train: loss: 0.1425770
[Epoch 5; Iter   840/  960] train: loss: 0.1030009
[Epoch 5; Iter   870/  960] train: loss: 0.0351857
[Epoch 5; Iter   900/  960] train: loss: 0.2892500
[Epoch 5; Iter   930/  960] train: loss: 0.0324909
[Epoch 5; Iter   960/  960] train: loss: 0.4870933
[Epoch 5] ogbg-molhiv: 0.747237 val loss: 0.146066
[Epoch 5] ogbg-molhiv: 0.693399 test loss: 0.114211
[Epoch 6; Iter    30/  960] train: loss: 0.0973534
[Epoch 6; Iter    60/  960] train: loss: 0.1924869
[Epoch 6; Iter    90/  960] train: loss: 0.0317918
[Epoch 6; Iter   120/  960] train: loss: 0.1015158
[Epoch 6; Iter   150/  960] train: loss: 0.0290769
[Epoch 6; Iter   180/  960] train: loss: 0.0479518
[Epoch 6; Iter   210/  960] train: loss: 0.2186924
[Epoch 6; Iter   240/  960] train: loss: 0.1795378
[Epoch 6; Iter   270/  960] train: loss: 0.1636470
[Epoch 6; Iter   300/  960] train: loss: 0.3169524
[Epoch 6; Iter   330/  960] train: loss: 0.3084948
[Epoch 6; Iter   360/  960] train: loss: 0.4273765
[Epoch 6; Iter   390/  960] train: loss: 0.1178698
[Epoch 6; Iter   420/  960] train: loss: 0.1320243
[Epoch 6; Iter   450/  960] train: loss: 0.0397926
[Epoch 6; Iter   480/  960] train: loss: 0.0300085
[Epoch 6; Iter   510/  960] train: loss: 0.2814645
[Epoch 6; Iter   540/  960] train: loss: 0.1373871
[Epoch 6; Iter   570/  960] train: loss: 0.0394219
[Epoch 6; Iter   600/  960] train: loss: 0.0407519
[Epoch 6; Iter   630/  960] train: loss: 0.0388473
[Epoch 6; Iter   660/  960] train: loss: 0.1134315
[Epoch 6; Iter   690/  960] train: loss: 0.0357868
[Epoch 6; Iter   720/  960] train: loss: 0.0940773
[Epoch 6; Iter   750/  960] train: loss: 0.0605351
[Epoch 6; Iter   780/  960] train: loss: 0.1438457
[Epoch 6; Iter   810/  960] train: loss: 0.1385477
[Epoch 6; Iter   840/  960] train: loss: 0.2480832
[Epoch 6; Iter   870/  960] train: loss: 0.0363895
[Epoch 6; Iter   900/  960] train: loss: 0.1470012
[Epoch 6; Iter   930/  960] train: loss: 0.2337495
[Epoch 6; Iter   960/  960] train: loss: 0.3293717
[Epoch 6] ogbg-molhiv: 0.752769 val loss: 0.118993
[Epoch 6] ogbg-molhiv: 0.728857 test loss: 0.156340
[Epoch 7; Iter    30/  960] train: loss: 0.2885231
[Epoch 7; Iter    60/  960] train: loss: 0.0354920
[Epoch 7; Iter    90/  960] train: loss: 0.0297579
[Epoch 7; Iter   120/  960] train: loss: 0.1643756
[Epoch 7; Iter   150/  960] train: loss: 0.1341950
[Epoch 7; Iter   180/  960] train: loss: 0.1911733
[Epoch 7; Iter   210/  960] train: loss: 0.1946730
[Epoch 7; Iter   240/  960] train: loss: 0.0235656
[Epoch 7; Iter   270/  960] train: loss: 0.0572015
[Epoch 7; Iter   300/  960] train: loss: 0.3747451
[Epoch 7; Iter   330/  960] train: loss: 0.0645804
[Epoch 7; Iter   360/  960] train: loss: 0.0991432
[Epoch 7; Iter   390/  960] train: loss: 0.1487923
[Epoch 7; Iter   420/  960] train: loss: 0.1720352
[Epoch 7; Iter   450/  960] train: loss: 0.0390051
[Epoch 7; Iter   480/  960] train: loss: 0.3631742
[Epoch 7; Iter   510/  960] train: loss: 0.1518504
[Epoch 7; Iter   540/  960] train: loss: 0.0329207
[Epoch 7; Iter   570/  960] train: loss: 0.0272317
[Epoch 7; Iter   600/  960] train: loss: 0.4360413
[Epoch 7; Iter   630/  960] train: loss: 0.0369754
[Epoch 7; Iter   660/  960] train: loss: 0.0386694
[Epoch 7; Iter   690/  960] train: loss: 0.1283063
[Epoch 7; Iter   720/  960] train: loss: 0.0516128
[Epoch 7; Iter   750/  960] train: loss: 0.2677301
[Epoch 7; Iter   780/  960] train: loss: 0.0558874
[Epoch 7; Iter   810/  960] train: loss: 0.1334422
[Epoch 7; Iter   840/  960] train: loss: 0.2398434
[Epoch 7; Iter   870/  960] train: loss: 0.1939513
[Epoch 7; Iter   900/  960] train: loss: 0.0709161
[Epoch 7; Iter   930/  960] train: loss: 0.2860336
[Epoch 7; Iter   960/  960] train: loss: 0.0284110
[Epoch 7] ogbg-molhiv: 0.745206 val loss: 0.120295
[Epoch 7] ogbg-molhiv: 0.730551 test loss: 0.105148
[Epoch 8; Iter    30/  960] train: loss: 0.0251289
[Epoch 8; Iter    60/  960] train: loss: 0.1525624
[Epoch 8; Iter    90/  960] train: loss: 0.0283465
[Epoch 8; Iter   120/  960] train: loss: 0.0503985
[Epoch 8; Iter   150/  960] train: loss: 0.0335019
[Epoch 8; Iter   180/  960] train: loss: 0.0428092
[Epoch 8; Iter   210/  960] train: loss: 0.0423132
[Epoch 8; Iter   240/  960] train: loss: 0.2367808
[Epoch 8; Iter   270/  960] train: loss: 0.0571312
[Epoch 8; Iter   300/  960] train: loss: 0.0278872
[Epoch 8; Iter   330/  960] train: loss: 0.1875986
[Epoch 8; Iter   360/  960] train: loss: 0.1515934
[Epoch 8; Iter   390/  960] train: loss: 0.0423560
[Epoch 8; Iter   420/  960] train: loss: 0.1908573
[Epoch 8; Iter   450/  960] train: loss: 0.0225371
[Epoch 8; Iter   480/  960] train: loss: 0.0768011
[Epoch 8; Iter   510/  960] train: loss: 0.0241370
[Epoch 8; Iter   540/  960] train: loss: 0.0701142
[Epoch 8; Iter   570/  960] train: loss: 0.1358715
[Epoch 8; Iter   600/  960] train: loss: 0.0306482
[Epoch 8; Iter   630/  960] train: loss: 0.1726298
[Epoch 8; Iter   660/  960] train: loss: 0.0375763
[Epoch 8; Iter   690/  960] train: loss: 0.1758018
[Epoch 8; Iter   720/  960] train: loss: 0.0869723
[Epoch 8; Iter   750/  960] train: loss: 0.1840256
[Epoch 8; Iter   780/  960] train: loss: 0.1107863
[Epoch 8; Iter   810/  960] train: loss: 0.0291042
[Epoch 8; Iter   840/  960] train: loss: 0.0787096
[Epoch 8; Iter   870/  960] train: loss: 0.1303132
[Epoch 8; Iter   900/  960] train: loss: 0.1848876
[Epoch 8; Iter   930/  960] train: loss: 0.0533373
[Epoch 8; Iter   960/  960] train: loss: 0.0370579
[Epoch 4; Iter   270/  960] train: loss: 0.1665213
[Epoch 4; Iter   300/  960] train: loss: 0.0457892
[Epoch 4; Iter   330/  960] train: loss: 0.0365062
[Epoch 4; Iter   360/  960] train: loss: 0.1536412
[Epoch 4; Iter   390/  960] train: loss: 0.0955788
[Epoch 4; Iter   420/  960] train: loss: 0.1789307
[Epoch 4; Iter   450/  960] train: loss: 0.1023454
[Epoch 4; Iter   480/  960] train: loss: 0.1374251
[Epoch 4; Iter   510/  960] train: loss: 0.2435158
[Epoch 4; Iter   540/  960] train: loss: 0.2007223
[Epoch 4; Iter   570/  960] train: loss: 0.0392867
[Epoch 4; Iter   600/  960] train: loss: 0.1653968
[Epoch 4; Iter   630/  960] train: loss: 0.0380556
[Epoch 4; Iter   660/  960] train: loss: 0.1526649
[Epoch 4; Iter   690/  960] train: loss: 0.3224344
[Epoch 4; Iter   720/  960] train: loss: 0.1196714
[Epoch 4; Iter   750/  960] train: loss: 0.0345691
[Epoch 4; Iter   780/  960] train: loss: 0.0483253
[Epoch 4; Iter   810/  960] train: loss: 0.3466552
[Epoch 4; Iter   840/  960] train: loss: 0.1069737
[Epoch 4; Iter   870/  960] train: loss: 0.3506534
[Epoch 4; Iter   900/  960] train: loss: 0.2179331
[Epoch 4; Iter   930/  960] train: loss: 0.2817203
[Epoch 4; Iter   960/  960] train: loss: 0.1739849
[Epoch 4] ogbg-molhiv: 0.710713 val loss: 0.131943
[Epoch 4] ogbg-molhiv: 0.707071 test loss: 0.113853
[Epoch 5; Iter    30/  960] train: loss: 0.1940307
[Epoch 5; Iter    60/  960] train: loss: 0.0875806
[Epoch 5; Iter    90/  960] train: loss: 0.0432230
[Epoch 5; Iter   120/  960] train: loss: 0.1882177
[Epoch 5; Iter   150/  960] train: loss: 0.0298169
[Epoch 5; Iter   180/  960] train: loss: 0.0951824
[Epoch 5; Iter   210/  960] train: loss: 0.0424924
[Epoch 5; Iter   240/  960] train: loss: 0.3116706
[Epoch 5; Iter   270/  960] train: loss: 0.2432464
[Epoch 5; Iter   300/  960] train: loss: 0.1408010
[Epoch 5; Iter   330/  960] train: loss: 0.1712268
[Epoch 5; Iter   360/  960] train: loss: 0.1782787
[Epoch 5; Iter   390/  960] train: loss: 0.1348383
[Epoch 5; Iter   420/  960] train: loss: 0.1554595
[Epoch 5; Iter   450/  960] train: loss: 0.0298265
[Epoch 5; Iter   480/  960] train: loss: 0.1494962
[Epoch 5; Iter   510/  960] train: loss: 0.1004713
[Epoch 5; Iter   540/  960] train: loss: 0.2894681
[Epoch 5; Iter   570/  960] train: loss: 0.2094795
[Epoch 5; Iter   600/  960] train: loss: 0.1811825
[Epoch 5; Iter   630/  960] train: loss: 0.1521039
[Epoch 5; Iter   660/  960] train: loss: 0.0329908
[Epoch 5; Iter   690/  960] train: loss: 0.1991769
[Epoch 5; Iter   720/  960] train: loss: 0.0824224
[Epoch 5; Iter   750/  960] train: loss: 0.1762638
[Epoch 5; Iter   780/  960] train: loss: 0.0431974
[Epoch 5; Iter   810/  960] train: loss: 0.0936345
[Epoch 5; Iter   840/  960] train: loss: 0.0332789
[Epoch 5; Iter   870/  960] train: loss: 0.3224272
[Epoch 5; Iter   900/  960] train: loss: 0.0788303
[Epoch 5; Iter   930/  960] train: loss: 0.0350688
[Epoch 5; Iter   960/  960] train: loss: 0.1563230
[Epoch 5] ogbg-molhiv: 0.734708 val loss: 0.120174
[Epoch 5] ogbg-molhiv: 0.742281 test loss: 0.100964
[Epoch 6; Iter    30/  960] train: loss: 0.0367239
[Epoch 6; Iter    60/  960] train: loss: 0.1699813
[Epoch 6; Iter    90/  960] train: loss: 0.2080397
[Epoch 6; Iter   120/  960] train: loss: 0.0312607
[Epoch 6; Iter   150/  960] train: loss: 0.1796301
[Epoch 6; Iter   180/  960] train: loss: 0.1229114
[Epoch 6; Iter   210/  960] train: loss: 0.1057434
[Epoch 6; Iter   240/  960] train: loss: 0.0505403
[Epoch 6; Iter   270/  960] train: loss: 0.2192130
[Epoch 6; Iter   300/  960] train: loss: 0.0368771
[Epoch 6; Iter   330/  960] train: loss: 0.1429351
[Epoch 6; Iter   360/  960] train: loss: 0.2898433
[Epoch 6; Iter   390/  960] train: loss: 0.2774404
[Epoch 6; Iter   420/  960] train: loss: 0.0443209
[Epoch 6; Iter   450/  960] train: loss: 0.1262296
[Epoch 6; Iter   480/  960] train: loss: 0.0409861
[Epoch 6; Iter   510/  960] train: loss: 0.2948132
[Epoch 6; Iter   540/  960] train: loss: 0.1972238
[Epoch 6; Iter   570/  960] train: loss: 0.0391109
[Epoch 6; Iter   600/  960] train: loss: 0.1145213
[Epoch 6; Iter   630/  960] train: loss: 0.0374697
[Epoch 6; Iter   660/  960] train: loss: 0.1147633
[Epoch 6; Iter   690/  960] train: loss: 0.1466497
[Epoch 6; Iter   720/  960] train: loss: 0.1629296
[Epoch 6; Iter   750/  960] train: loss: 0.1753502
[Epoch 6; Iter   780/  960] train: loss: 0.1660112
[Epoch 6; Iter   810/  960] train: loss: 0.1979900
[Epoch 6; Iter   840/  960] train: loss: 0.1170753
[Epoch 6; Iter   870/  960] train: loss: 0.1689115
[Epoch 6; Iter   900/  960] train: loss: 0.0489642
[Epoch 6; Iter   930/  960] train: loss: 0.1291427
[Epoch 6; Iter   960/  960] train: loss: 0.0294225
[Epoch 6] ogbg-molhiv: 0.697554 val loss: 0.391401
[Epoch 6] ogbg-molhiv: 0.709643 test loss: 0.155430
[Epoch 7; Iter    30/  960] train: loss: 0.2171947
[Epoch 7; Iter    60/  960] train: loss: 0.2558204
[Epoch 7; Iter    90/  960] train: loss: 0.0917147
[Epoch 7; Iter   120/  960] train: loss: 0.1913295
[Epoch 7; Iter   150/  960] train: loss: 0.1826412
[Epoch 7; Iter   180/  960] train: loss: 0.0935501
[Epoch 7; Iter   210/  960] train: loss: 0.1777304
[Epoch 7; Iter   240/  960] train: loss: 0.0395174
[Epoch 7; Iter   270/  960] train: loss: 0.0341362
[Epoch 7; Iter   300/  960] train: loss: 0.0383307
[Epoch 7; Iter   330/  960] train: loss: 0.1106845
[Epoch 7; Iter   360/  960] train: loss: 0.3654916
[Epoch 7; Iter   390/  960] train: loss: 0.2009572
[Epoch 7; Iter   420/  960] train: loss: 0.3758880
[Epoch 7; Iter   450/  960] train: loss: 0.0354786
[Epoch 7; Iter   480/  960] train: loss: 0.0366900
[Epoch 7; Iter   510/  960] train: loss: 0.1993841
[Epoch 7; Iter   540/  960] train: loss: 0.2078092
[Epoch 7; Iter   570/  960] train: loss: 0.0461510
[Epoch 7; Iter   600/  960] train: loss: 0.2381007
[Epoch 7; Iter   630/  960] train: loss: 0.0384298
[Epoch 7; Iter   660/  960] train: loss: 0.0358997
[Epoch 7; Iter   690/  960] train: loss: 0.1519532
[Epoch 7; Iter   720/  960] train: loss: 0.2703098
[Epoch 7; Iter   750/  960] train: loss: 0.3327380
[Epoch 7; Iter   780/  960] train: loss: 0.0287397
[Epoch 7; Iter   810/  960] train: loss: 0.1399281
[Epoch 7; Iter   840/  960] train: loss: 0.1752589
[Epoch 7; Iter   870/  960] train: loss: 0.0300295
[Epoch 7; Iter   900/  960] train: loss: 0.0591341
[Epoch 7; Iter   930/  960] train: loss: 0.1641788
[Epoch 7; Iter   960/  960] train: loss: 0.0996739
[Epoch 7] ogbg-molhiv: 0.710611 val loss: 0.123291
[Epoch 7] ogbg-molhiv: 0.699103 test loss: 0.104425
[Epoch 8; Iter    30/  960] train: loss: 0.1861229
[Epoch 8; Iter    60/  960] train: loss: 0.0278116
[Epoch 8; Iter    90/  960] train: loss: 0.0362843
[Epoch 8; Iter   120/  960] train: loss: 0.1776034
[Epoch 8; Iter   150/  960] train: loss: 0.2450028
[Epoch 8; Iter   180/  960] train: loss: 0.2071315
[Epoch 8; Iter   210/  960] train: loss: 0.2546190
[Epoch 8; Iter   240/  960] train: loss: 0.0361908
[Epoch 8; Iter   270/  960] train: loss: 0.1526103
[Epoch 8; Iter   300/  960] train: loss: 0.0325610
[Epoch 8; Iter   330/  960] train: loss: 0.0418652
[Epoch 8; Iter   360/  960] train: loss: 0.0627444
[Epoch 8; Iter   390/  960] train: loss: 0.0387359
[Epoch 8; Iter   420/  960] train: loss: 0.2327938
[Epoch 8; Iter   450/  960] train: loss: 0.1806011
[Epoch 8; Iter   480/  960] train: loss: 0.1338394
[Epoch 8; Iter   510/  960] train: loss: 0.2242393
[Epoch 8; Iter   540/  960] train: loss: 0.1251936
[Epoch 8; Iter   570/  960] train: loss: 0.0273079
[Epoch 8; Iter   600/  960] train: loss: 0.0305780
[Epoch 8; Iter   630/  960] train: loss: 0.0277699
[Epoch 8; Iter   660/  960] train: loss: 0.0379155
[Epoch 8; Iter   690/  960] train: loss: 0.0466441
[Epoch 8; Iter   720/  960] train: loss: 0.4591608
[Epoch 8; Iter   750/  960] train: loss: 0.0736506
[Epoch 8; Iter   780/  960] train: loss: 0.1421071
[Epoch 8; Iter   810/  960] train: loss: 0.0330465
[Epoch 8; Iter   840/  960] train: loss: 0.2620866
[Epoch 8; Iter   870/  960] train: loss: 0.2466541
[Epoch 8; Iter   900/  960] train: loss: 0.0443856
[Epoch 8; Iter   930/  960] train: loss: 0.0367288
[Epoch 8; Iter   960/  960] train: loss: 0.6141145
[Epoch 4; Iter   681/  823] train: loss: 0.0980234
[Epoch 4; Iter   711/  823] train: loss: 0.0973042
[Epoch 4; Iter   741/  823] train: loss: 0.0470725
[Epoch 4; Iter   771/  823] train: loss: 0.0294462
[Epoch 4; Iter   801/  823] train: loss: 0.4293479
[Epoch 4] ogbg-molhiv: 0.711558 val loss: 0.148617
[Epoch 4] ogbg-molhiv: 0.738842 test loss: 0.106029
[Epoch 5; Iter     8/  823] train: loss: 0.3666951
[Epoch 5; Iter    38/  823] train: loss: 0.1177846
[Epoch 5; Iter    68/  823] train: loss: 0.1703423
[Epoch 5; Iter    98/  823] train: loss: 0.0267585
[Epoch 5; Iter   128/  823] train: loss: 0.3494641
[Epoch 5; Iter   158/  823] train: loss: 0.1970115
[Epoch 5; Iter   188/  823] train: loss: 0.2104305
[Epoch 5; Iter   218/  823] train: loss: 0.1456583
[Epoch 5; Iter   248/  823] train: loss: 0.0333576
[Epoch 5; Iter   278/  823] train: loss: 0.1853724
[Epoch 5; Iter   308/  823] train: loss: 0.1871507
[Epoch 5; Iter   338/  823] train: loss: 0.0356543
[Epoch 5; Iter   368/  823] train: loss: 0.1546610
[Epoch 5; Iter   398/  823] train: loss: 0.0371606
[Epoch 5; Iter   428/  823] train: loss: 0.0430109
[Epoch 5; Iter   458/  823] train: loss: 0.1534890
[Epoch 5; Iter   488/  823] train: loss: 0.0454949
[Epoch 5; Iter   518/  823] train: loss: 0.0938678
[Epoch 5; Iter   548/  823] train: loss: 0.1297451
[Epoch 5; Iter   578/  823] train: loss: 0.0494858
[Epoch 5; Iter   608/  823] train: loss: 0.0323704
[Epoch 5; Iter   638/  823] train: loss: 0.0324961
[Epoch 5; Iter   668/  823] train: loss: 0.0963844
[Epoch 5; Iter   698/  823] train: loss: 0.0348433
[Epoch 5; Iter   728/  823] train: loss: 0.0763927
[Epoch 5; Iter   758/  823] train: loss: 0.0575807
[Epoch 5; Iter   788/  823] train: loss: 0.1745635
[Epoch 5; Iter   818/  823] train: loss: 0.0793987
[Epoch 5] ogbg-molhiv: 0.704623 val loss: 0.160302
[Epoch 5] ogbg-molhiv: 0.714373 test loss: 0.120347
[Epoch 6; Iter    25/  823] train: loss: 0.2747209
[Epoch 6; Iter    55/  823] train: loss: 0.1909438
[Epoch 6; Iter    85/  823] train: loss: 0.1142521
[Epoch 6; Iter   115/  823] train: loss: 0.0400450
[Epoch 6; Iter   145/  823] train: loss: 0.0337638
[Epoch 6; Iter   175/  823] train: loss: 0.1422555
[Epoch 6; Iter   205/  823] train: loss: 0.0297056
[Epoch 6; Iter   235/  823] train: loss: 0.0304148
[Epoch 6; Iter   265/  823] train: loss: 0.5873490
[Epoch 6; Iter   295/  823] train: loss: 0.1438407
[Epoch 6; Iter   325/  823] train: loss: 0.2094902
[Epoch 6; Iter   355/  823] train: loss: 0.0932759
[Epoch 6; Iter   385/  823] train: loss: 0.0325528
[Epoch 6; Iter   415/  823] train: loss: 0.0961684
[Epoch 6; Iter   445/  823] train: loss: 0.1755563
[Epoch 6; Iter   475/  823] train: loss: 0.1233481
[Epoch 6; Iter   505/  823] train: loss: 0.0256296
[Epoch 6; Iter   535/  823] train: loss: 0.0365576
[Epoch 6; Iter   565/  823] train: loss: 0.0325169
[Epoch 6; Iter   595/  823] train: loss: 0.1248463
[Epoch 6; Iter   625/  823] train: loss: 0.1683978
[Epoch 6; Iter   655/  823] train: loss: 0.0358590
[Epoch 6; Iter   685/  823] train: loss: 0.0715775
[Epoch 6; Iter   715/  823] train: loss: 0.0318150
[Epoch 6; Iter   745/  823] train: loss: 0.0710534
[Epoch 6; Iter   775/  823] train: loss: 0.1654354
[Epoch 6; Iter   805/  823] train: loss: 0.0305297
[Epoch 6] ogbg-molhiv: 0.685875 val loss: 0.152546
[Epoch 6] ogbg-molhiv: 0.687834 test loss: 0.149069
[Epoch 7; Iter    12/  823] train: loss: 0.1734452
[Epoch 7; Iter    42/  823] train: loss: 0.0441912
[Epoch 7; Iter    72/  823] train: loss: 0.0383913
[Epoch 7; Iter   102/  823] train: loss: 0.1024371
[Epoch 7; Iter   132/  823] train: loss: 0.2063335
[Epoch 7; Iter   162/  823] train: loss: 0.0322523
[Epoch 7; Iter   192/  823] train: loss: 0.1786684
[Epoch 7; Iter   222/  823] train: loss: 0.2280875
[Epoch 7; Iter   252/  823] train: loss: 0.2637619
[Epoch 7; Iter   282/  823] train: loss: 0.0374568
[Epoch 7; Iter   312/  823] train: loss: 0.2896859
[Epoch 7; Iter   342/  823] train: loss: 0.0303591
[Epoch 7; Iter   372/  823] train: loss: 0.1328838
[Epoch 7; Iter   402/  823] train: loss: 0.1473363
[Epoch 7; Iter   432/  823] train: loss: 0.3022872
[Epoch 7; Iter   462/  823] train: loss: 0.1397963
[Epoch 7; Iter   492/  823] train: loss: 0.0418842
[Epoch 7; Iter   522/  823] train: loss: 0.1027987
[Epoch 7; Iter   552/  823] train: loss: 0.2235494
[Epoch 7; Iter   582/  823] train: loss: 0.1479392
[Epoch 7; Iter   612/  823] train: loss: 0.0961345
[Epoch 7; Iter   642/  823] train: loss: 0.0292766
[Epoch 7; Iter   672/  823] train: loss: 0.2541053
[Epoch 7; Iter   702/  823] train: loss: 0.0348936
[Epoch 7; Iter   732/  823] train: loss: 0.2057132
[Epoch 7; Iter   762/  823] train: loss: 0.1895294
[Epoch 7; Iter   792/  823] train: loss: 0.0488751
[Epoch 7; Iter   822/  823] train: loss: 0.0293645
[Epoch 7] ogbg-molhiv: 0.706696 val loss: 0.216655
[Epoch 7] ogbg-molhiv: 0.731806 test loss: 0.154186
[Epoch 8; Iter    29/  823] train: loss: 0.1484871
[Epoch 8; Iter    59/  823] train: loss: 0.3025427
[Epoch 8; Iter    89/  823] train: loss: 0.1899938
[Epoch 8; Iter   119/  823] train: loss: 0.1337203
[Epoch 8; Iter   149/  823] train: loss: 0.1140787
[Epoch 8; Iter   179/  823] train: loss: 0.2868804
[Epoch 8; Iter   209/  823] train: loss: 0.1537547
[Epoch 8; Iter   239/  823] train: loss: 0.0403405
[Epoch 8; Iter   269/  823] train: loss: 0.0472957
[Epoch 8; Iter   299/  823] train: loss: 0.0278868
[Epoch 8; Iter   329/  823] train: loss: 0.1880141
[Epoch 8; Iter   359/  823] train: loss: 0.0321977
[Epoch 8; Iter   389/  823] train: loss: 0.0352880
[Epoch 8; Iter   419/  823] train: loss: 0.0218085
[Epoch 8; Iter   449/  823] train: loss: 0.0401651
[Epoch 8; Iter   479/  823] train: loss: 0.1470791
[Epoch 8; Iter   509/  823] train: loss: 0.0375178
[Epoch 8; Iter   539/  823] train: loss: 0.3790463
[Epoch 8; Iter   569/  823] train: loss: 0.1075955
[Epoch 8; Iter   599/  823] train: loss: 0.1715835
[Epoch 8; Iter   629/  823] train: loss: 0.2254718
[Epoch 8; Iter   659/  823] train: loss: 0.0938436
[Epoch 8; Iter   689/  823] train: loss: 0.0306561
[Epoch 8; Iter   719/  823] train: loss: 0.0769212
[Epoch 8; Iter   749/  823] train: loss: 0.0694917
[Epoch 8; Iter   779/  823] train: loss: 0.0249856
[Epoch 8; Iter   809/  823] train: loss: 0.0584680
[Epoch 8] ogbg-molhiv: 0.685783 val loss: 0.149342
[Epoch 8] ogbg-molhiv: 0.684709 test loss: 0.125380
[Epoch 9; Iter    16/  823] train: loss: 0.0955413
[Epoch 9; Iter    46/  823] train: loss: 0.0548892
[Epoch 9; Iter    76/  823] train: loss: 0.1694859
[Epoch 9; Iter   106/  823] train: loss: 0.2007437
[Epoch 9; Iter   136/  823] train: loss: 0.1582699
[Epoch 9; Iter   166/  823] train: loss: 0.0571696
[Epoch 9; Iter   196/  823] train: loss: 0.1689273
[Epoch 9; Iter   226/  823] train: loss: 0.0285063
[Epoch 9; Iter   256/  823] train: loss: 0.4667693
[Epoch 9; Iter   286/  823] train: loss: 0.1507587
[Epoch 9; Iter   316/  823] train: loss: 0.0876273
[Epoch 9; Iter   346/  823] train: loss: 0.0595928
[Epoch 9; Iter   376/  823] train: loss: 0.2913377
[Epoch 9; Iter   406/  823] train: loss: 0.0698798
[Epoch 9; Iter   436/  823] train: loss: 0.0852042
[Epoch 9; Iter   466/  823] train: loss: 0.0332912
[Epoch 9; Iter   496/  823] train: loss: 0.0621877
[Epoch 9; Iter   526/  823] train: loss: 0.0421328
[Epoch 9; Iter   556/  823] train: loss: 0.0659660
[Epoch 9; Iter   586/  823] train: loss: 0.1721321
[Epoch 9; Iter   616/  823] train: loss: 0.0254504
[Epoch 9; Iter   646/  823] train: loss: 0.0712763
[Epoch 9; Iter   676/  823] train: loss: 0.0231717
[Epoch 9; Iter   706/  823] train: loss: 0.0303319
[Epoch 9; Iter   736/  823] train: loss: 0.1510911
[Epoch 9; Iter   766/  823] train: loss: 0.0405844
[Epoch 9; Iter   796/  823] train: loss: 0.0347843
[Epoch 9] ogbg-molhiv: 0.708933 val loss: 0.142970
[Epoch 9] ogbg-molhiv: 0.667508 test loss: 0.117226
[Epoch 10; Iter     3/  823] train: loss: 0.0486237
[Epoch 10; Iter    33/  823] train: loss: 0.1957190
[Epoch 10; Iter    63/  823] train: loss: 0.0411534
[Epoch 10; Iter    93/  823] train: loss: 0.2566670
[Epoch 10; Iter   123/  823] train: loss: 0.1085851
[Epoch 10; Iter   153/  823] train: loss: 0.1708356
[Epoch 4; Iter   681/  823] train: loss: 0.1527569
[Epoch 4; Iter   711/  823] train: loss: 0.3203722
[Epoch 4; Iter   741/  823] train: loss: 0.0841085
[Epoch 4; Iter   771/  823] train: loss: 0.4309201
[Epoch 4; Iter   801/  823] train: loss: 0.0298848
[Epoch 4] ogbg-molhiv: 0.714219 val loss: 0.154434
[Epoch 4] ogbg-molhiv: 0.744973 test loss: 0.113224
[Epoch 5; Iter     8/  823] train: loss: 0.1027971
[Epoch 5; Iter    38/  823] train: loss: 0.1147267
[Epoch 5; Iter    68/  823] train: loss: 0.1906012
[Epoch 5; Iter    98/  823] train: loss: 0.0435438
[Epoch 5; Iter   128/  823] train: loss: 0.0330853
[Epoch 5; Iter   158/  823] train: loss: 0.1704246
[Epoch 5; Iter   188/  823] train: loss: 0.1155972
[Epoch 5; Iter   218/  823] train: loss: 0.1379372
[Epoch 5; Iter   248/  823] train: loss: 0.0336278
[Epoch 5; Iter   278/  823] train: loss: 0.2373781
[Epoch 5; Iter   308/  823] train: loss: 0.0342008
[Epoch 5; Iter   338/  823] train: loss: 0.0238424
[Epoch 5; Iter   368/  823] train: loss: 0.3117830
[Epoch 5; Iter   398/  823] train: loss: 0.0739799
[Epoch 5; Iter   428/  823] train: loss: 0.1184026
[Epoch 5; Iter   458/  823] train: loss: 0.2997603
[Epoch 5; Iter   488/  823] train: loss: 0.0426989
[Epoch 5; Iter   518/  823] train: loss: 0.1027532
[Epoch 5; Iter   548/  823] train: loss: 0.0588693
[Epoch 5; Iter   578/  823] train: loss: 0.2344670
[Epoch 5; Iter   608/  823] train: loss: 0.0772434
[Epoch 5; Iter   638/  823] train: loss: 0.1582993
[Epoch 5; Iter   668/  823] train: loss: 0.1150968
[Epoch 5; Iter   698/  823] train: loss: 0.1527472
[Epoch 5; Iter   728/  823] train: loss: 0.0279853
[Epoch 5; Iter   758/  823] train: loss: 0.1406526
[Epoch 5; Iter   788/  823] train: loss: 0.0277387
[Epoch 5; Iter   818/  823] train: loss: 0.1955034
[Epoch 5] ogbg-molhiv: 0.707707 val loss: 0.149994
[Epoch 5] ogbg-molhiv: 0.750151 test loss: 0.109707
[Epoch 6; Iter    25/  823] train: loss: 0.1278624
[Epoch 6; Iter    55/  823] train: loss: 0.2165802
[Epoch 6; Iter    85/  823] train: loss: 0.0300919
[Epoch 6; Iter   115/  823] train: loss: 0.1717637
[Epoch 6; Iter   145/  823] train: loss: 0.1501176
[Epoch 6; Iter   175/  823] train: loss: 0.0588174
[Epoch 6; Iter   205/  823] train: loss: 0.2444752
[Epoch 6; Iter   235/  823] train: loss: 0.0574397
[Epoch 6; Iter   265/  823] train: loss: 0.3070751
[Epoch 6; Iter   295/  823] train: loss: 0.0442663
[Epoch 6; Iter   325/  823] train: loss: 0.3204747
[Epoch 6; Iter   355/  823] train: loss: 0.2120999
[Epoch 6; Iter   385/  823] train: loss: 0.0552819
[Epoch 6; Iter   415/  823] train: loss: 0.1351656
[Epoch 6; Iter   445/  823] train: loss: 0.0401480
[Epoch 6; Iter   475/  823] train: loss: 0.1452284
[Epoch 6; Iter   505/  823] train: loss: 0.0919748
[Epoch 6; Iter   535/  823] train: loss: 0.0385277
[Epoch 6; Iter   565/  823] train: loss: 0.1163944
[Epoch 6; Iter   595/  823] train: loss: 0.3015640
[Epoch 6; Iter   625/  823] train: loss: 0.0313432
[Epoch 6; Iter   655/  823] train: loss: 0.0277774
[Epoch 6; Iter   685/  823] train: loss: 0.1779127
[Epoch 6; Iter   715/  823] train: loss: 0.3835608
[Epoch 6; Iter   745/  823] train: loss: 0.1100100
[Epoch 6; Iter   775/  823] train: loss: 0.0461839
[Epoch 6; Iter   805/  823] train: loss: 0.2109398
[Epoch 6] ogbg-molhiv: 0.726156 val loss: 0.139830
[Epoch 6] ogbg-molhiv: 0.731129 test loss: 0.104671
[Epoch 7; Iter    12/  823] train: loss: 0.5246446
[Epoch 7; Iter    42/  823] train: loss: 0.1763415
[Epoch 7; Iter    72/  823] train: loss: 0.1573635
[Epoch 7; Iter   102/  823] train: loss: 0.0441286
[Epoch 7; Iter   132/  823] train: loss: 0.0490785
[Epoch 7; Iter   162/  823] train: loss: 0.2315356
[Epoch 7; Iter   192/  823] train: loss: 0.0277595
[Epoch 7; Iter   222/  823] train: loss: 0.1243898
[Epoch 7; Iter   252/  823] train: loss: 0.1100663
[Epoch 7; Iter   282/  823] train: loss: 0.0424517
[Epoch 7; Iter   312/  823] train: loss: 0.0465966
[Epoch 7; Iter   342/  823] train: loss: 0.0437668
[Epoch 7; Iter   372/  823] train: loss: 0.1085822
[Epoch 7; Iter   402/  823] train: loss: 0.1525974
[Epoch 7; Iter   432/  823] train: loss: 0.0330049
[Epoch 7; Iter   462/  823] train: loss: 0.1910576
[Epoch 7; Iter   492/  823] train: loss: 0.3457163
[Epoch 7; Iter   522/  823] train: loss: 0.1820455
[Epoch 7; Iter   552/  823] train: loss: 0.1751588
[Epoch 7; Iter   582/  823] train: loss: 0.0510555
[Epoch 7; Iter   612/  823] train: loss: 0.1106063
[Epoch 7; Iter   642/  823] train: loss: 0.0273190
[Epoch 7; Iter   672/  823] train: loss: 0.0743974
[Epoch 7; Iter   702/  823] train: loss: 0.0219627
[Epoch 7; Iter   732/  823] train: loss: 0.0723221
[Epoch 7; Iter   762/  823] train: loss: 0.0893449
[Epoch 7; Iter   792/  823] train: loss: 0.0394867
[Epoch 7; Iter   822/  823] train: loss: 0.0295939
[Epoch 7] ogbg-molhiv: 0.729916 val loss: 0.159975
[Epoch 7] ogbg-molhiv: 0.740076 test loss: 0.115642
[Epoch 8; Iter    29/  823] train: loss: 0.1779785
[Epoch 8; Iter    59/  823] train: loss: 0.0359853
[Epoch 8; Iter    89/  823] train: loss: 0.2881430
[Epoch 8; Iter   119/  823] train: loss: 0.1706065
[Epoch 8; Iter   149/  823] train: loss: 0.0494042
[Epoch 8; Iter   179/  823] train: loss: 0.2170090
[Epoch 8; Iter   209/  823] train: loss: 0.0340313
[Epoch 8; Iter   239/  823] train: loss: 0.1731368
[Epoch 8; Iter   269/  823] train: loss: 0.0310718
[Epoch 8; Iter   299/  823] train: loss: 0.0331756
[Epoch 8; Iter   329/  823] train: loss: 0.2181230
[Epoch 8; Iter   359/  823] train: loss: 0.0380113
[Epoch 8; Iter   389/  823] train: loss: 0.0374184
[Epoch 8; Iter   419/  823] train: loss: 0.0313464
[Epoch 8; Iter   449/  823] train: loss: 0.0232776
[Epoch 8; Iter   479/  823] train: loss: 0.0956290
[Epoch 8; Iter   509/  823] train: loss: 0.2586075
[Epoch 8; Iter   539/  823] train: loss: 0.0302552
[Epoch 8; Iter   569/  823] train: loss: 0.0299581
[Epoch 8; Iter   599/  823] train: loss: 0.0264733
[Epoch 8; Iter   629/  823] train: loss: 0.0516763
[Epoch 8; Iter   659/  823] train: loss: 0.2552640
[Epoch 8; Iter   689/  823] train: loss: 0.0578708
[Epoch 8; Iter   719/  823] train: loss: 0.0281208
[Epoch 8; Iter   749/  823] train: loss: 0.2537327
[Epoch 8; Iter   779/  823] train: loss: 0.0401178
[Epoch 8; Iter   809/  823] train: loss: 0.1893023
[Epoch 8] ogbg-molhiv: 0.699016 val loss: 0.538908
[Epoch 8] ogbg-molhiv: 0.726539 test loss: 0.132480
[Epoch 9; Iter    16/  823] train: loss: 0.2014018
[Epoch 9; Iter    46/  823] train: loss: 0.4031718
[Epoch 9; Iter    76/  823] train: loss: 0.1857146
[Epoch 9; Iter   106/  823] train: loss: 0.0435575
[Epoch 9; Iter   136/  823] train: loss: 0.1169796
[Epoch 9; Iter   166/  823] train: loss: 0.1018226
[Epoch 9; Iter   196/  823] train: loss: 0.1444517
[Epoch 9; Iter   226/  823] train: loss: 0.1144833
[Epoch 9; Iter   256/  823] train: loss: 0.0406197
[Epoch 9; Iter   286/  823] train: loss: 0.2272682
[Epoch 9; Iter   316/  823] train: loss: 0.2263296
[Epoch 9; Iter   346/  823] train: loss: 0.0677512
[Epoch 9; Iter   376/  823] train: loss: 0.0634484
[Epoch 9; Iter   406/  823] train: loss: 0.1096059
[Epoch 9; Iter   436/  823] train: loss: 0.3250973
[Epoch 9; Iter   466/  823] train: loss: 0.1453046
[Epoch 9; Iter   496/  823] train: loss: 0.1801788
[Epoch 9; Iter   526/  823] train: loss: 0.0299294
[Epoch 9; Iter   556/  823] train: loss: 0.0458469
[Epoch 9; Iter   586/  823] train: loss: 0.0267558
[Epoch 9; Iter   616/  823] train: loss: 0.1081577
[Epoch 9; Iter   646/  823] train: loss: 0.0506983
[Epoch 9; Iter   676/  823] train: loss: 0.1002900
[Epoch 9; Iter   706/  823] train: loss: 0.0577828
[Epoch 9; Iter   736/  823] train: loss: 0.0421088
[Epoch 9; Iter   766/  823] train: loss: 0.0362531
[Epoch 9; Iter   796/  823] train: loss: 0.0213546
[Epoch 9] ogbg-molhiv: 0.714383 val loss: 0.555378
[Epoch 9] ogbg-molhiv: 0.735634 test loss: 0.132999
[Epoch 10; Iter     3/  823] train: loss: 0.0609450
[Epoch 10; Iter    33/  823] train: loss: 0.2263866
[Epoch 10; Iter    63/  823] train: loss: 0.0872289
[Epoch 10; Iter    93/  823] train: loss: 0.1336687
[Epoch 10; Iter   123/  823] train: loss: 0.0499144
[Epoch 10; Iter   153/  823] train: loss: 0.0417709
[Epoch 4; Iter   681/  823] train: loss: 0.2275067
[Epoch 4; Iter   711/  823] train: loss: 0.0373966
[Epoch 4; Iter   741/  823] train: loss: 0.0376040
[Epoch 4; Iter   771/  823] train: loss: 0.1495324
[Epoch 4; Iter   801/  823] train: loss: 0.0423188
[Epoch 4] ogbg-molhiv: 0.697933 val loss: 0.245457
[Epoch 4] ogbg-molhiv: 0.719184 test loss: 0.200608
[Epoch 5; Iter     8/  823] train: loss: 0.1041820
[Epoch 5; Iter    38/  823] train: loss: 0.0338537
[Epoch 5; Iter    68/  823] train: loss: 0.0604238
[Epoch 5; Iter    98/  823] train: loss: 0.2032551
[Epoch 5; Iter   128/  823] train: loss: 0.0307775
[Epoch 5; Iter   158/  823] train: loss: 0.0589992
[Epoch 5; Iter   188/  823] train: loss: 0.0427346
[Epoch 5; Iter   218/  823] train: loss: 0.4037458
[Epoch 5; Iter   248/  823] train: loss: 0.1070887
[Epoch 5; Iter   278/  823] train: loss: 0.2784053
[Epoch 5; Iter   308/  823] train: loss: 0.2764708
[Epoch 5; Iter   338/  823] train: loss: 0.1586858
[Epoch 5; Iter   368/  823] train: loss: 0.0330070
[Epoch 5; Iter   398/  823] train: loss: 0.0288813
[Epoch 5; Iter   428/  823] train: loss: 0.0611334
[Epoch 5; Iter   458/  823] train: loss: 0.1648757
[Epoch 5; Iter   488/  823] train: loss: 0.1468840
[Epoch 5; Iter   518/  823] train: loss: 0.0328218
[Epoch 5; Iter   548/  823] train: loss: 0.0732202
[Epoch 5; Iter   578/  823] train: loss: 0.3572857
[Epoch 5; Iter   608/  823] train: loss: 0.0320646
[Epoch 5; Iter   638/  823] train: loss: 0.1703564
[Epoch 5; Iter   668/  823] train: loss: 0.1498964
[Epoch 5; Iter   698/  823] train: loss: 0.0296214
[Epoch 5; Iter   728/  823] train: loss: 0.0448724
[Epoch 5; Iter   758/  823] train: loss: 0.1497348
[Epoch 5; Iter   788/  823] train: loss: 0.1861727
[Epoch 5; Iter   818/  823] train: loss: 0.1439636
[Epoch 5] ogbg-molhiv: 0.723623 val loss: 0.153686
[Epoch 5] ogbg-molhiv: 0.743807 test loss: 0.106053
[Epoch 6; Iter    25/  823] train: loss: 0.1697318
[Epoch 6; Iter    55/  823] train: loss: 0.1602126
[Epoch 6; Iter    85/  823] train: loss: 0.1457676
[Epoch 6; Iter   115/  823] train: loss: 0.0334800
[Epoch 6; Iter   145/  823] train: loss: 0.0801319
[Epoch 6; Iter   175/  823] train: loss: 0.0241908
[Epoch 6; Iter   205/  823] train: loss: 0.2061514
[Epoch 6; Iter   235/  823] train: loss: 0.0413665
[Epoch 6; Iter   265/  823] train: loss: 0.0628365
[Epoch 6; Iter   295/  823] train: loss: 0.0295050
[Epoch 6; Iter   325/  823] train: loss: 0.3256328
[Epoch 6; Iter   355/  823] train: loss: 0.0509425
[Epoch 6; Iter   385/  823] train: loss: 0.0268645
[Epoch 6; Iter   415/  823] train: loss: 0.0275483
[Epoch 6; Iter   445/  823] train: loss: 0.0467853
[Epoch 6; Iter   475/  823] train: loss: 0.0265728
[Epoch 6; Iter   505/  823] train: loss: 0.0401444
[Epoch 6; Iter   535/  823] train: loss: 0.3278498
[Epoch 6; Iter   565/  823] train: loss: 0.1309263
[Epoch 6; Iter   595/  823] train: loss: 0.0801125
[Epoch 6; Iter   625/  823] train: loss: 0.1985313
[Epoch 6; Iter   655/  823] train: loss: 0.0315167
[Epoch 6; Iter   685/  823] train: loss: 0.1104444
[Epoch 6; Iter   715/  823] train: loss: 0.0246433
[Epoch 6; Iter   745/  823] train: loss: 0.0692823
[Epoch 6; Iter   775/  823] train: loss: 0.0333318
[Epoch 6; Iter   805/  823] train: loss: 0.0228388
[Epoch 6] ogbg-molhiv: 0.708545 val loss: 0.143082
[Epoch 6] ogbg-molhiv: 0.709315 test loss: 0.105904
[Epoch 7; Iter    12/  823] train: loss: 0.1251567
[Epoch 7; Iter    42/  823] train: loss: 0.0711108
[Epoch 7; Iter    72/  823] train: loss: 0.0421218
[Epoch 7; Iter   102/  823] train: loss: 0.1839833
[Epoch 7; Iter   132/  823] train: loss: 0.0319558
[Epoch 7; Iter   162/  823] train: loss: 0.2385883
[Epoch 7; Iter   192/  823] train: loss: 0.3115386
[Epoch 7; Iter   222/  823] train: loss: 0.1516606
[Epoch 7; Iter   252/  823] train: loss: 0.2884505
[Epoch 7; Iter   282/  823] train: loss: 0.1341820
[Epoch 7; Iter   312/  823] train: loss: 0.0337801
[Epoch 7; Iter   342/  823] train: loss: 0.1323595
[Epoch 7; Iter   372/  823] train: loss: 0.0634740
[Epoch 7; Iter   402/  823] train: loss: 0.1573359
[Epoch 7; Iter   432/  823] train: loss: 0.1042107
[Epoch 7; Iter   462/  823] train: loss: 0.0459652
[Epoch 7; Iter   492/  823] train: loss: 0.2050186
[Epoch 7; Iter   522/  823] train: loss: 0.0541137
[Epoch 7; Iter   552/  823] train: loss: 0.0987962
[Epoch 7; Iter   582/  823] train: loss: 0.0312085
[Epoch 7; Iter   612/  823] train: loss: 0.1875328
[Epoch 7; Iter   642/  823] train: loss: 0.0404789
[Epoch 7; Iter   672/  823] train: loss: 0.0422892
[Epoch 7; Iter   702/  823] train: loss: 0.0576622
[Epoch 7; Iter   732/  823] train: loss: 0.0420990
[Epoch 7; Iter   762/  823] train: loss: 0.0493746
[Epoch 7; Iter   792/  823] train: loss: 0.1025280
[Epoch 7; Iter   822/  823] train: loss: 0.1544028
[Epoch 7] ogbg-molhiv: 0.700199 val loss: 0.175486
[Epoch 7] ogbg-molhiv: 0.713388 test loss: 0.118990
[Epoch 8; Iter    29/  823] train: loss: 0.4277147
[Epoch 8; Iter    59/  823] train: loss: 0.0402904
[Epoch 8; Iter    89/  823] train: loss: 0.1751899
[Epoch 8; Iter   119/  823] train: loss: 0.0251322
[Epoch 8; Iter   149/  823] train: loss: 0.4086866
[Epoch 8; Iter   179/  823] train: loss: 0.0377624
[Epoch 8; Iter   209/  823] train: loss: 0.0384836
[Epoch 8; Iter   239/  823] train: loss: 0.0735365
[Epoch 8; Iter   269/  823] train: loss: 0.1161682
[Epoch 8; Iter   299/  823] train: loss: 0.1930170
[Epoch 8; Iter   329/  823] train: loss: 0.1541161
[Epoch 8; Iter   359/  823] train: loss: 0.1630440
[Epoch 8; Iter   389/  823] train: loss: 0.0349293
[Epoch 8; Iter   419/  823] train: loss: 0.1275007
[Epoch 8; Iter   449/  823] train: loss: 0.1514183
[Epoch 8; Iter   479/  823] train: loss: 0.2938345
[Epoch 8; Iter   509/  823] train: loss: 0.1648337
[Epoch 8; Iter   539/  823] train: loss: 0.1630601
[Epoch 8; Iter   569/  823] train: loss: 0.0303841
[Epoch 8; Iter   599/  823] train: loss: 0.2270133
[Epoch 8; Iter   629/  823] train: loss: 0.0353565
[Epoch 8; Iter   659/  823] train: loss: 0.1129814
[Epoch 8; Iter   689/  823] train: loss: 0.1148057
[Epoch 8; Iter   719/  823] train: loss: 0.0281444
[Epoch 8; Iter   749/  823] train: loss: 0.0384682
[Epoch 8; Iter   779/  823] train: loss: 0.1933390
[Epoch 8; Iter   809/  823] train: loss: 0.1941041
[Epoch 8] ogbg-molhiv: 0.696024 val loss: 0.280289
[Epoch 8] ogbg-molhiv: 0.714194 test loss: 0.169561
[Epoch 9; Iter    16/  823] train: loss: 0.2000315
[Epoch 9; Iter    46/  823] train: loss: 0.0531752
[Epoch 9; Iter    76/  823] train: loss: 0.2220175
[Epoch 9; Iter   106/  823] train: loss: 0.0300119
[Epoch 9; Iter   136/  823] train: loss: 0.1347160
[Epoch 9; Iter   166/  823] train: loss: 0.1427853
[Epoch 9; Iter   196/  823] train: loss: 0.0351388
[Epoch 9; Iter   226/  823] train: loss: 0.0312928
[Epoch 9; Iter   256/  823] train: loss: 0.1311508
[Epoch 9; Iter   286/  823] train: loss: 0.0284021
[Epoch 9; Iter   316/  823] train: loss: 0.1938486
[Epoch 9; Iter   346/  823] train: loss: 0.0488103
[Epoch 9; Iter   376/  823] train: loss: 0.0339196
[Epoch 9; Iter   406/  823] train: loss: 0.0424535
[Epoch 9; Iter   436/  823] train: loss: 0.3056251
[Epoch 9; Iter   466/  823] train: loss: 0.0684569
[Epoch 9; Iter   496/  823] train: loss: 0.1621856
[Epoch 9; Iter   526/  823] train: loss: 0.0495795
[Epoch 9; Iter   556/  823] train: loss: 0.0255422
[Epoch 9; Iter   586/  823] train: loss: 0.0577819
[Epoch 9; Iter   616/  823] train: loss: 0.0820451
[Epoch 9; Iter   646/  823] train: loss: 0.0262453
[Epoch 9; Iter   676/  823] train: loss: 0.0480735
[Epoch 9; Iter   706/  823] train: loss: 0.0857089
[Epoch 9; Iter   736/  823] train: loss: 0.0349179
[Epoch 9; Iter   766/  823] train: loss: 0.0276221
[Epoch 9; Iter   796/  823] train: loss: 0.1494915
[Epoch 9] ogbg-molhiv: 0.692077 val loss: 0.145679
[Epoch 9] ogbg-molhiv: 0.724747 test loss: 0.107901
[Epoch 10; Iter     3/  823] train: loss: 0.1550138
[Epoch 10; Iter    33/  823] train: loss: 0.1079726
[Epoch 10; Iter    63/  823] train: loss: 0.0324140
[Epoch 10; Iter    93/  823] train: loss: 0.2106985
[Epoch 10; Iter   123/  823] train: loss: 0.0395918
[Epoch 10; Iter   153/  823] train: loss: 0.1443354
[Epoch 8; Iter    31/ 1097] train: loss: 0.1849664
[Epoch 8; Iter    61/ 1097] train: loss: 0.2745106
[Epoch 8; Iter    91/ 1097] train: loss: 0.2495800
[Epoch 8; Iter   121/ 1097] train: loss: 0.0394065
[Epoch 8; Iter   151/ 1097] train: loss: 0.4235139
[Epoch 8; Iter   181/ 1097] train: loss: 0.2254484
[Epoch 8; Iter   211/ 1097] train: loss: 0.2265107
[Epoch 8; Iter   241/ 1097] train: loss: 0.0365202
[Epoch 8; Iter   271/ 1097] train: loss: 0.1285900
[Epoch 8; Iter   301/ 1097] train: loss: 0.0312653
[Epoch 8; Iter   331/ 1097] train: loss: 0.0925892
[Epoch 8; Iter   361/ 1097] train: loss: 0.1404026
[Epoch 8; Iter   391/ 1097] train: loss: 0.0703168
[Epoch 8; Iter   421/ 1097] train: loss: 0.2810739
[Epoch 8; Iter   451/ 1097] train: loss: 0.0310012
[Epoch 8; Iter   481/ 1097] train: loss: 0.1102023
[Epoch 8; Iter   511/ 1097] train: loss: 0.1371619
[Epoch 8; Iter   541/ 1097] train: loss: 0.0345830
[Epoch 8; Iter   571/ 1097] train: loss: 0.4324363
[Epoch 8; Iter   601/ 1097] train: loss: 0.1593647
[Epoch 8; Iter   631/ 1097] train: loss: 0.1029414
[Epoch 8; Iter   661/ 1097] train: loss: 0.0404794
[Epoch 8; Iter   691/ 1097] train: loss: 0.1859093
[Epoch 8; Iter   721/ 1097] train: loss: 0.0794261
[Epoch 8; Iter   751/ 1097] train: loss: 0.0274914
[Epoch 8; Iter   781/ 1097] train: loss: 0.2800406
[Epoch 8; Iter   811/ 1097] train: loss: 0.1089462
[Epoch 8; Iter   841/ 1097] train: loss: 0.0539757
[Epoch 8; Iter   871/ 1097] train: loss: 0.1497059
[Epoch 8; Iter   901/ 1097] train: loss: 0.0263762
[Epoch 8; Iter   931/ 1097] train: loss: 0.0598303
[Epoch 8; Iter   961/ 1097] train: loss: 0.0525968
[Epoch 8; Iter   991/ 1097] train: loss: 0.0307439
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0228598
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0233797
[Epoch 8; Iter  1081/ 1097] train: loss: 0.1660057
[Epoch 8] ogbg-molhiv: 0.793590 val loss: 3.162737
[Epoch 8] ogbg-molhiv: 0.755074 test loss: 0.934756
[Epoch 9; Iter    14/ 1097] train: loss: 0.0247738
[Epoch 9; Iter    44/ 1097] train: loss: 0.0322677
[Epoch 9; Iter    74/ 1097] train: loss: 0.1934455
[Epoch 9; Iter   104/ 1097] train: loss: 0.3341891
[Epoch 9; Iter   134/ 1097] train: loss: 0.2498372
[Epoch 9; Iter   164/ 1097] train: loss: 0.0297502
[Epoch 9; Iter   194/ 1097] train: loss: 0.0555981
[Epoch 9; Iter   224/ 1097] train: loss: 0.0262301
[Epoch 9; Iter   254/ 1097] train: loss: 0.0914674
[Epoch 9; Iter   284/ 1097] train: loss: 0.0460087
[Epoch 9; Iter   314/ 1097] train: loss: 0.0355294
[Epoch 9; Iter   344/ 1097] train: loss: 0.0292979
[Epoch 9; Iter   374/ 1097] train: loss: 0.0351626
[Epoch 9; Iter   404/ 1097] train: loss: 0.1161657
[Epoch 9; Iter   434/ 1097] train: loss: 0.1660279
[Epoch 9; Iter   464/ 1097] train: loss: 0.2389243
[Epoch 9; Iter   494/ 1097] train: loss: 0.1139693
[Epoch 9; Iter   524/ 1097] train: loss: 0.0940626
[Epoch 9; Iter   554/ 1097] train: loss: 0.0368643
[Epoch 9; Iter   584/ 1097] train: loss: 0.2156929
[Epoch 9; Iter   614/ 1097] train: loss: 0.0293990
[Epoch 9; Iter   644/ 1097] train: loss: 0.2076954
[Epoch 9; Iter   674/ 1097] train: loss: 0.0826065
[Epoch 9; Iter   704/ 1097] train: loss: 0.0262673
[Epoch 9; Iter   734/ 1097] train: loss: 0.0845288
[Epoch 9; Iter   764/ 1097] train: loss: 0.0828623
[Epoch 9; Iter   794/ 1097] train: loss: 0.0520356
[Epoch 9; Iter   824/ 1097] train: loss: 0.0292601
[Epoch 9; Iter   854/ 1097] train: loss: 0.0435067
[Epoch 9; Iter   884/ 1097] train: loss: 0.1979960
[Epoch 9; Iter   914/ 1097] train: loss: 0.0255007
[Epoch 9; Iter   944/ 1097] train: loss: 0.1671213
[Epoch 9; Iter   974/ 1097] train: loss: 0.0477376
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1490422
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0892218
[Epoch 9; Iter  1064/ 1097] train: loss: 0.0892090
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0569452
[Epoch 9] ogbg-molhiv: 0.766446 val loss: 2.664117
[Epoch 9] ogbg-molhiv: 0.715097 test loss: 0.464685
[Epoch 10; Iter    27/ 1097] train: loss: 0.1764853
[Epoch 10; Iter    57/ 1097] train: loss: 0.0261538
[Epoch 10; Iter    87/ 1097] train: loss: 0.1810342
[Epoch 10; Iter   117/ 1097] train: loss: 0.0573261
[Epoch 10; Iter   147/ 1097] train: loss: 0.0257723
[Epoch 10; Iter   177/ 1097] train: loss: 0.0234664
[Epoch 10; Iter   207/ 1097] train: loss: 0.0211430
[Epoch 10; Iter   237/ 1097] train: loss: 0.0275225
[Epoch 10; Iter   267/ 1097] train: loss: 0.0226429
[Epoch 10; Iter   297/ 1097] train: loss: 0.0421151
[Epoch 10; Iter   327/ 1097] train: loss: 0.0340120
[Epoch 10; Iter   357/ 1097] train: loss: 0.1071237
[Epoch 10; Iter   387/ 1097] train: loss: 0.1713525
[Epoch 10; Iter   417/ 1097] train: loss: 0.0371353
[Epoch 10; Iter   447/ 1097] train: loss: 0.0617899
[Epoch 10; Iter   477/ 1097] train: loss: 0.0537680
[Epoch 10; Iter   507/ 1097] train: loss: 0.0860073
[Epoch 10; Iter   537/ 1097] train: loss: 0.0273962
[Epoch 10; Iter   567/ 1097] train: loss: 0.1696550
[Epoch 10; Iter   597/ 1097] train: loss: 0.1854842
[Epoch 10; Iter   627/ 1097] train: loss: 0.1924032
[Epoch 10; Iter   657/ 1097] train: loss: 0.0251968
[Epoch 10; Iter   687/ 1097] train: loss: 0.2864646
[Epoch 10; Iter   717/ 1097] train: loss: 0.0685729
[Epoch 10; Iter   747/ 1097] train: loss: 0.3147415
[Epoch 10; Iter   777/ 1097] train: loss: 0.0658140
[Epoch 10; Iter   807/ 1097] train: loss: 0.1217563
[Epoch 10; Iter   837/ 1097] train: loss: 0.0544872
[Epoch 10; Iter   867/ 1097] train: loss: 0.4278553
[Epoch 10; Iter   897/ 1097] train: loss: 0.1789152
[Epoch 10; Iter   927/ 1097] train: loss: 0.3516261
[Epoch 10; Iter   957/ 1097] train: loss: 0.2538254
[Epoch 10; Iter   987/ 1097] train: loss: 0.1935524
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0715510
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1181678
[Epoch 10; Iter  1077/ 1097] train: loss: 0.1575047
[Epoch 10] ogbg-molhiv: 0.812751 val loss: 0.075757
[Epoch 10] ogbg-molhiv: 0.762830 test loss: 0.118350
[Epoch 11; Iter    10/ 1097] train: loss: 0.0419544
[Epoch 11; Iter    40/ 1097] train: loss: 0.0544229
[Epoch 11; Iter    70/ 1097] train: loss: 0.0485531
[Epoch 11; Iter   100/ 1097] train: loss: 0.1528839
[Epoch 11; Iter   130/ 1097] train: loss: 0.0371217
[Epoch 11; Iter   160/ 1097] train: loss: 0.0510791
[Epoch 11; Iter   190/ 1097] train: loss: 0.1385590
[Epoch 11; Iter   220/ 1097] train: loss: 0.0708399
[Epoch 11; Iter   250/ 1097] train: loss: 0.1083435
[Epoch 11; Iter   280/ 1097] train: loss: 0.2147922
[Epoch 11; Iter   310/ 1097] train: loss: 0.1194062
[Epoch 11; Iter   340/ 1097] train: loss: 0.0824846
[Epoch 11; Iter   370/ 1097] train: loss: 0.3025983
[Epoch 11; Iter   400/ 1097] train: loss: 0.0740959
[Epoch 11; Iter   430/ 1097] train: loss: 0.1273252
[Epoch 11; Iter   460/ 1097] train: loss: 0.1478799
[Epoch 11; Iter   490/ 1097] train: loss: 0.1775188
[Epoch 11; Iter   520/ 1097] train: loss: 0.4532506
[Epoch 11; Iter   550/ 1097] train: loss: 0.1330828
[Epoch 11; Iter   580/ 1097] train: loss: 0.1776697
[Epoch 11; Iter   610/ 1097] train: loss: 0.0287806
[Epoch 11; Iter   640/ 1097] train: loss: 0.0505163
[Epoch 11; Iter   670/ 1097] train: loss: 0.0295542
[Epoch 11; Iter   700/ 1097] train: loss: 0.0293865
[Epoch 11; Iter   730/ 1097] train: loss: 0.1363504
[Epoch 11; Iter   760/ 1097] train: loss: 0.0613609
[Epoch 11; Iter   790/ 1097] train: loss: 0.0329289
[Epoch 11; Iter   820/ 1097] train: loss: 0.3066422
[Epoch 11; Iter   850/ 1097] train: loss: 0.2403300
[Epoch 11; Iter   880/ 1097] train: loss: 0.0257838
[Epoch 11; Iter   910/ 1097] train: loss: 0.2181667
[Epoch 11; Iter   940/ 1097] train: loss: 0.2615197
[Epoch 11; Iter   970/ 1097] train: loss: 0.1111398
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0971450
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0704630
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2256851
[Epoch 11; Iter  1090/ 1097] train: loss: 0.3564499
[Epoch 11] ogbg-molhiv: 0.773926 val loss: 0.206455
[Epoch 11] ogbg-molhiv: 0.719703 test loss: 0.186477
[Epoch 12; Iter    23/ 1097] train: loss: 0.1364965
[Epoch 12; Iter    53/ 1097] train: loss: 0.0537320
[Epoch 12; Iter    83/ 1097] train: loss: 0.0470628
[Epoch 12; Iter   113/ 1097] train: loss: 0.0358833
[Epoch 8; Iter    31/ 1097] train: loss: 0.0599076
[Epoch 8; Iter    61/ 1097] train: loss: 0.0966962
[Epoch 8; Iter    91/ 1097] train: loss: 0.1098513
[Epoch 8; Iter   121/ 1097] train: loss: 0.1375435
[Epoch 8; Iter   151/ 1097] train: loss: 0.0291417
[Epoch 8; Iter   181/ 1097] train: loss: 0.0445882
[Epoch 8; Iter   211/ 1097] train: loss: 0.0593198
[Epoch 8; Iter   241/ 1097] train: loss: 0.0294310
[Epoch 8; Iter   271/ 1097] train: loss: 0.2055052
[Epoch 8; Iter   301/ 1097] train: loss: 0.2444881
[Epoch 8; Iter   331/ 1097] train: loss: 0.1150358
[Epoch 8; Iter   361/ 1097] train: loss: 0.1629579
[Epoch 8; Iter   391/ 1097] train: loss: 0.0261022
[Epoch 8; Iter   421/ 1097] train: loss: 0.2426210
[Epoch 8; Iter   451/ 1097] train: loss: 0.1979771
[Epoch 8; Iter   481/ 1097] train: loss: 0.0520439
[Epoch 8; Iter   511/ 1097] train: loss: 0.0851333
[Epoch 8; Iter   541/ 1097] train: loss: 0.1162724
[Epoch 8; Iter   571/ 1097] train: loss: 0.1146281
[Epoch 8; Iter   601/ 1097] train: loss: 0.3721529
[Epoch 8; Iter   631/ 1097] train: loss: 0.0344837
[Epoch 8; Iter   661/ 1097] train: loss: 0.2158298
[Epoch 8; Iter   691/ 1097] train: loss: 0.1623399
[Epoch 8; Iter   721/ 1097] train: loss: 0.0840657
[Epoch 8; Iter   751/ 1097] train: loss: 0.1036979
[Epoch 8; Iter   781/ 1097] train: loss: 0.1404667
[Epoch 8; Iter   811/ 1097] train: loss: 0.2420972
[Epoch 8; Iter   841/ 1097] train: loss: 0.3912809
[Epoch 8; Iter   871/ 1097] train: loss: 0.1770728
[Epoch 8; Iter   901/ 1097] train: loss: 0.0328443
[Epoch 8; Iter   931/ 1097] train: loss: 0.2129827
[Epoch 8; Iter   961/ 1097] train: loss: 0.0361061
[Epoch 8; Iter   991/ 1097] train: loss: 0.1269547
[Epoch 8; Iter  1021/ 1097] train: loss: 0.3066300
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0443231
[Epoch 8; Iter  1081/ 1097] train: loss: 0.0784969
[Epoch 8] ogbg-molhiv: 0.693930 val loss: 0.093885
[Epoch 8] ogbg-molhiv: 0.716144 test loss: 0.124779
[Epoch 9; Iter    14/ 1097] train: loss: 0.3275427
[Epoch 9; Iter    44/ 1097] train: loss: 0.0313219
[Epoch 9; Iter    74/ 1097] train: loss: 0.0248646
[Epoch 9; Iter   104/ 1097] train: loss: 0.2965274
[Epoch 9; Iter   134/ 1097] train: loss: 0.1163239
[Epoch 9; Iter   164/ 1097] train: loss: 0.1368932
[Epoch 9; Iter   194/ 1097] train: loss: 0.1189302
[Epoch 9; Iter   224/ 1097] train: loss: 0.0328555
[Epoch 9; Iter   254/ 1097] train: loss: 0.3435838
[Epoch 9; Iter   284/ 1097] train: loss: 0.2038841
[Epoch 9; Iter   314/ 1097] train: loss: 0.1153277
[Epoch 9; Iter   344/ 1097] train: loss: 0.4656974
[Epoch 9; Iter   374/ 1097] train: loss: 0.1868710
[Epoch 9; Iter   404/ 1097] train: loss: 0.1643157
[Epoch 9; Iter   434/ 1097] train: loss: 0.0767455
[Epoch 9; Iter   464/ 1097] train: loss: 0.0344466
[Epoch 9; Iter   494/ 1097] train: loss: 0.1671245
[Epoch 9; Iter   524/ 1097] train: loss: 0.0281032
[Epoch 9; Iter   554/ 1097] train: loss: 0.0282622
[Epoch 9; Iter   584/ 1097] train: loss: 0.4540988
[Epoch 9; Iter   614/ 1097] train: loss: 0.1027040
[Epoch 9; Iter   644/ 1097] train: loss: 0.2089064
[Epoch 9; Iter   674/ 1097] train: loss: 0.4820710
[Epoch 9; Iter   704/ 1097] train: loss: 0.1423739
[Epoch 9; Iter   734/ 1097] train: loss: 0.0825968
[Epoch 9; Iter   764/ 1097] train: loss: 0.2397166
[Epoch 9; Iter   794/ 1097] train: loss: 0.1860092
[Epoch 9; Iter   824/ 1097] train: loss: 0.0300120
[Epoch 9; Iter   854/ 1097] train: loss: 0.0380897
[Epoch 9; Iter   884/ 1097] train: loss: 0.0789115
[Epoch 9; Iter   914/ 1097] train: loss: 0.1786043
[Epoch 9; Iter   944/ 1097] train: loss: 0.0644331
[Epoch 9; Iter   974/ 1097] train: loss: 0.0959458
[Epoch 9; Iter  1004/ 1097] train: loss: 0.1949442
[Epoch 9; Iter  1034/ 1097] train: loss: 0.2551372
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2721350
[Epoch 9; Iter  1094/ 1097] train: loss: 0.1974197
[Epoch 9] ogbg-molhiv: 0.711444 val loss: 0.095127
[Epoch 9] ogbg-molhiv: 0.725659 test loss: 0.130139
[Epoch 10; Iter    27/ 1097] train: loss: 0.0271361
[Epoch 10; Iter    57/ 1097] train: loss: 0.0253738
[Epoch 10; Iter    87/ 1097] train: loss: 0.1713828
[Epoch 10; Iter   117/ 1097] train: loss: 0.0363052
[Epoch 10; Iter   147/ 1097] train: loss: 0.3960069
[Epoch 10; Iter   177/ 1097] train: loss: 0.1654475
[Epoch 10; Iter   207/ 1097] train: loss: 0.1150520
[Epoch 10; Iter   237/ 1097] train: loss: 0.0415812
[Epoch 10; Iter   267/ 1097] train: loss: 0.0304475
[Epoch 10; Iter   297/ 1097] train: loss: 0.1617922
[Epoch 10; Iter   327/ 1097] train: loss: 0.0268790
[Epoch 10; Iter   357/ 1097] train: loss: 0.1857859
[Epoch 10; Iter   387/ 1097] train: loss: 0.1017671
[Epoch 10; Iter   417/ 1097] train: loss: 0.1205060
[Epoch 10; Iter   447/ 1097] train: loss: 0.2033481
[Epoch 10; Iter   477/ 1097] train: loss: 0.1831334
[Epoch 10; Iter   507/ 1097] train: loss: 0.1128738
[Epoch 10; Iter   537/ 1097] train: loss: 0.0278244
[Epoch 10; Iter   567/ 1097] train: loss: 0.0241217
[Epoch 10; Iter   597/ 1097] train: loss: 0.0331726
[Epoch 10; Iter   627/ 1097] train: loss: 0.2313109
[Epoch 10; Iter   657/ 1097] train: loss: 0.1694254
[Epoch 10; Iter   687/ 1097] train: loss: 0.0650557
[Epoch 10; Iter   717/ 1097] train: loss: 0.1606689
[Epoch 10; Iter   747/ 1097] train: loss: 0.1792089
[Epoch 10; Iter   777/ 1097] train: loss: 0.2086928
[Epoch 10; Iter   807/ 1097] train: loss: 0.0353555
[Epoch 10; Iter   837/ 1097] train: loss: 0.0275929
[Epoch 10; Iter   867/ 1097] train: loss: 0.0468639
[Epoch 10; Iter   897/ 1097] train: loss: 0.0340713
[Epoch 10; Iter   927/ 1097] train: loss: 0.1451191
[Epoch 10; Iter   957/ 1097] train: loss: 0.0374255
[Epoch 10; Iter   987/ 1097] train: loss: 0.2590704
[Epoch 10; Iter  1017/ 1097] train: loss: 0.2184092
[Epoch 10; Iter  1047/ 1097] train: loss: 0.1619427
[Epoch 10; Iter  1077/ 1097] train: loss: 0.0309255
[Epoch 10] ogbg-molhiv: 0.768457 val loss: 0.140511
[Epoch 10] ogbg-molhiv: 0.744528 test loss: 0.122572
[Epoch 11; Iter    10/ 1097] train: loss: 0.3300678
[Epoch 11; Iter    40/ 1097] train: loss: 0.0388983
[Epoch 11; Iter    70/ 1097] train: loss: 0.1309024
[Epoch 11; Iter   100/ 1097] train: loss: 0.0330652
[Epoch 11; Iter   130/ 1097] train: loss: 0.1625618
[Epoch 11; Iter   160/ 1097] train: loss: 0.0439794
[Epoch 11; Iter   190/ 1097] train: loss: 0.2914239
[Epoch 11; Iter   220/ 1097] train: loss: 0.3522641
[Epoch 11; Iter   250/ 1097] train: loss: 0.1391265
[Epoch 11; Iter   280/ 1097] train: loss: 0.0472808
[Epoch 11; Iter   310/ 1097] train: loss: 0.2246071
[Epoch 11; Iter   340/ 1097] train: loss: 0.0289193
[Epoch 11; Iter   370/ 1097] train: loss: 0.0830326
[Epoch 11; Iter   400/ 1097] train: loss: 0.0456273
[Epoch 11; Iter   430/ 1097] train: loss: 0.2009348
[Epoch 11; Iter   460/ 1097] train: loss: 0.1584232
[Epoch 11; Iter   490/ 1097] train: loss: 0.3154585
[Epoch 11; Iter   520/ 1097] train: loss: 0.1944210
[Epoch 11; Iter   550/ 1097] train: loss: 0.0282850
[Epoch 11; Iter   580/ 1097] train: loss: 0.0490150
[Epoch 11; Iter   610/ 1097] train: loss: 0.0345114
[Epoch 11; Iter   640/ 1097] train: loss: 0.0350717
[Epoch 11; Iter   670/ 1097] train: loss: 0.1636734
[Epoch 11; Iter   700/ 1097] train: loss: 0.1698369
[Epoch 11; Iter   730/ 1097] train: loss: 0.0389054
[Epoch 11; Iter   760/ 1097] train: loss: 0.2296191
[Epoch 11; Iter   790/ 1097] train: loss: 0.1814034
[Epoch 11; Iter   820/ 1097] train: loss: 0.0865659
[Epoch 11; Iter   850/ 1097] train: loss: 0.0664298
[Epoch 11; Iter   880/ 1097] train: loss: 0.2417788
[Epoch 11; Iter   910/ 1097] train: loss: 0.3041646
[Epoch 11; Iter   940/ 1097] train: loss: 0.2414756
[Epoch 11; Iter   970/ 1097] train: loss: 0.2530579
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0462053
[Epoch 11; Iter  1030/ 1097] train: loss: 0.0218793
[Epoch 11; Iter  1060/ 1097] train: loss: 0.1334825
[Epoch 11; Iter  1090/ 1097] train: loss: 0.4952837
[Epoch 11] ogbg-molhiv: 0.764140 val loss: 0.179887
[Epoch 11] ogbg-molhiv: 0.762827 test loss: 0.495461
[Epoch 12; Iter    23/ 1097] train: loss: 0.2384703
[Epoch 12; Iter    53/ 1097] train: loss: 0.0321562
[Epoch 12; Iter    83/ 1097] train: loss: 0.0387156
[Epoch 12; Iter   113/ 1097] train: loss: 0.0580219
[Epoch 8; Iter    31/ 1097] train: loss: 0.0349498
[Epoch 8; Iter    61/ 1097] train: loss: 0.1568077
[Epoch 8; Iter    91/ 1097] train: loss: 0.1636580
[Epoch 8; Iter   121/ 1097] train: loss: 0.0412644
[Epoch 8; Iter   151/ 1097] train: loss: 0.1342066
[Epoch 8; Iter   181/ 1097] train: loss: 0.0284645
[Epoch 8; Iter   211/ 1097] train: loss: 0.3297805
[Epoch 8; Iter   241/ 1097] train: loss: 0.0871775
[Epoch 8; Iter   271/ 1097] train: loss: 0.2362154
[Epoch 8; Iter   301/ 1097] train: loss: 0.0464942
[Epoch 8; Iter   331/ 1097] train: loss: 0.1159132
[Epoch 8; Iter   361/ 1097] train: loss: 0.0434436
[Epoch 8; Iter   391/ 1097] train: loss: 0.0393097
[Epoch 8; Iter   421/ 1097] train: loss: 0.2240185
[Epoch 8; Iter   451/ 1097] train: loss: 0.0314632
[Epoch 8; Iter   481/ 1097] train: loss: 0.1243376
[Epoch 8; Iter   511/ 1097] train: loss: 0.1537798
[Epoch 8; Iter   541/ 1097] train: loss: 0.0317219
[Epoch 8; Iter   571/ 1097] train: loss: 0.0304441
[Epoch 8; Iter   601/ 1097] train: loss: 0.0664497
[Epoch 8; Iter   631/ 1097] train: loss: 0.0818668
[Epoch 8; Iter   661/ 1097] train: loss: 0.0396093
[Epoch 8; Iter   691/ 1097] train: loss: 0.2958106
[Epoch 8; Iter   721/ 1097] train: loss: 0.0552568
[Epoch 8; Iter   751/ 1097] train: loss: 0.0700534
[Epoch 8; Iter   781/ 1097] train: loss: 0.0564918
[Epoch 8; Iter   811/ 1097] train: loss: 0.0730096
[Epoch 8; Iter   841/ 1097] train: loss: 0.2143699
[Epoch 8; Iter   871/ 1097] train: loss: 0.2730626
[Epoch 8; Iter   901/ 1097] train: loss: 0.0315620
[Epoch 8; Iter   931/ 1097] train: loss: 0.1557425
[Epoch 8; Iter   961/ 1097] train: loss: 0.0280610
[Epoch 8; Iter   991/ 1097] train: loss: 0.0418078
[Epoch 8; Iter  1021/ 1097] train: loss: 0.0389618
[Epoch 8; Iter  1051/ 1097] train: loss: 0.0335048
[Epoch 8; Iter  1081/ 1097] train: loss: 0.3323888
[Epoch 8] ogbg-molhiv: 0.773742 val loss: 0.081520
[Epoch 8] ogbg-molhiv: 0.683482 test loss: 0.128275
[Epoch 9; Iter    14/ 1097] train: loss: 0.0381207
[Epoch 9; Iter    44/ 1097] train: loss: 0.0638344
[Epoch 9; Iter    74/ 1097] train: loss: 0.0311985
[Epoch 9; Iter   104/ 1097] train: loss: 0.0622169
[Epoch 9; Iter   134/ 1097] train: loss: 0.0483983
[Epoch 9; Iter   164/ 1097] train: loss: 0.0288618
[Epoch 9; Iter   194/ 1097] train: loss: 0.0331975
[Epoch 9; Iter   224/ 1097] train: loss: 0.3166423
[Epoch 9; Iter   254/ 1097] train: loss: 0.1017028
[Epoch 9; Iter   284/ 1097] train: loss: 0.1727972
[Epoch 9; Iter   314/ 1097] train: loss: 0.2367662
[Epoch 9; Iter   344/ 1097] train: loss: 0.0256158
[Epoch 9; Iter   374/ 1097] train: loss: 0.1950345
[Epoch 9; Iter   404/ 1097] train: loss: 0.1621456
[Epoch 9; Iter   434/ 1097] train: loss: 0.1558929
[Epoch 9; Iter   464/ 1097] train: loss: 0.0295610
[Epoch 9; Iter   494/ 1097] train: loss: 0.0444648
[Epoch 9; Iter   524/ 1097] train: loss: 0.0275365
[Epoch 9; Iter   554/ 1097] train: loss: 0.0681663
[Epoch 9; Iter   584/ 1097] train: loss: 0.2020202
[Epoch 9; Iter   614/ 1097] train: loss: 0.0481713
[Epoch 9; Iter   644/ 1097] train: loss: 0.1418382
[Epoch 9; Iter   674/ 1097] train: loss: 0.1928413
[Epoch 9; Iter   704/ 1097] train: loss: 0.0240550
[Epoch 9; Iter   734/ 1097] train: loss: 0.0337822
[Epoch 9; Iter   764/ 1097] train: loss: 0.0795303
[Epoch 9; Iter   794/ 1097] train: loss: 0.0497777
[Epoch 9; Iter   824/ 1097] train: loss: 0.0243297
[Epoch 9; Iter   854/ 1097] train: loss: 0.0252355
[Epoch 9; Iter   884/ 1097] train: loss: 0.3112125
[Epoch 9; Iter   914/ 1097] train: loss: 0.0773889
[Epoch 9; Iter   944/ 1097] train: loss: 0.1173320
[Epoch 9; Iter   974/ 1097] train: loss: 0.0257526
[Epoch 9; Iter  1004/ 1097] train: loss: 0.0218025
[Epoch 9; Iter  1034/ 1097] train: loss: 0.0306263
[Epoch 9; Iter  1064/ 1097] train: loss: 0.2026976
[Epoch 9; Iter  1094/ 1097] train: loss: 0.0367845
[Epoch 9] ogbg-molhiv: 0.791762 val loss: 0.130151
[Epoch 9] ogbg-molhiv: 0.733317 test loss: 0.189165
[Epoch 10; Iter    27/ 1097] train: loss: 0.1902384
[Epoch 10; Iter    57/ 1097] train: loss: 0.2712750
[Epoch 10; Iter    87/ 1097] train: loss: 0.0365746
[Epoch 10; Iter   117/ 1097] train: loss: 0.1708677
[Epoch 10; Iter   147/ 1097] train: loss: 0.0341270
[Epoch 10; Iter   177/ 1097] train: loss: 0.4665691
[Epoch 10; Iter   207/ 1097] train: loss: 0.1009249
[Epoch 10; Iter   237/ 1097] train: loss: 0.0392118
[Epoch 10; Iter   267/ 1097] train: loss: 0.0672142
[Epoch 10; Iter   297/ 1097] train: loss: 0.2829100
[Epoch 10; Iter   327/ 1097] train: loss: 0.2392131
[Epoch 10; Iter   357/ 1097] train: loss: 0.0421449
[Epoch 10; Iter   387/ 1097] train: loss: 0.0826768
[Epoch 10; Iter   417/ 1097] train: loss: 0.2397095
[Epoch 10; Iter   447/ 1097] train: loss: 0.1757339
[Epoch 10; Iter   477/ 1097] train: loss: 0.0274179
[Epoch 10; Iter   507/ 1097] train: loss: 0.0351756
[Epoch 10; Iter   537/ 1097] train: loss: 0.1767730
[Epoch 10; Iter   567/ 1097] train: loss: 0.2387819
[Epoch 10; Iter   597/ 1097] train: loss: 0.1612414
[Epoch 10; Iter   627/ 1097] train: loss: 0.0430387
[Epoch 10; Iter   657/ 1097] train: loss: 0.2418785
[Epoch 10; Iter   687/ 1097] train: loss: 0.1524834
[Epoch 10; Iter   717/ 1097] train: loss: 0.3186882
[Epoch 10; Iter   747/ 1097] train: loss: 0.0387576
[Epoch 10; Iter   777/ 1097] train: loss: 0.0192426
[Epoch 10; Iter   807/ 1097] train: loss: 0.3435748
[Epoch 10; Iter   837/ 1097] train: loss: 0.0352121
[Epoch 10; Iter   867/ 1097] train: loss: 0.0269395
[Epoch 10; Iter   897/ 1097] train: loss: 0.0348577
[Epoch 10; Iter   927/ 1097] train: loss: 0.2367079
[Epoch 10; Iter   957/ 1097] train: loss: 0.1392842
[Epoch 10; Iter   987/ 1097] train: loss: 0.5238495
[Epoch 10; Iter  1017/ 1097] train: loss: 0.0259719
[Epoch 10; Iter  1047/ 1097] train: loss: 0.0429022
[Epoch 10; Iter  1077/ 1097] train: loss: 0.2095357
[Epoch 10] ogbg-molhiv: 0.788149 val loss: 0.619461
[Epoch 10] ogbg-molhiv: 0.727874 test loss: 0.472215
[Epoch 11; Iter    10/ 1097] train: loss: 0.2682755
[Epoch 11; Iter    40/ 1097] train: loss: 0.1769015
[Epoch 11; Iter    70/ 1097] train: loss: 0.0922564
[Epoch 11; Iter   100/ 1097] train: loss: 0.0901130
[Epoch 11; Iter   130/ 1097] train: loss: 0.4459998
[Epoch 11; Iter   160/ 1097] train: loss: 0.2781364
[Epoch 11; Iter   190/ 1097] train: loss: 0.0257619
[Epoch 11; Iter   220/ 1097] train: loss: 0.2198393
[Epoch 11; Iter   250/ 1097] train: loss: 0.0378969
[Epoch 11; Iter   280/ 1097] train: loss: 0.1696642
[Epoch 11; Iter   310/ 1097] train: loss: 0.2163035
[Epoch 11; Iter   340/ 1097] train: loss: 0.0492139
[Epoch 11; Iter   370/ 1097] train: loss: 0.0247934
[Epoch 11; Iter   400/ 1097] train: loss: 0.2129883
[Epoch 11; Iter   430/ 1097] train: loss: 0.0391754
[Epoch 11; Iter   460/ 1097] train: loss: 0.1022919
[Epoch 11; Iter   490/ 1097] train: loss: 0.2327241
[Epoch 11; Iter   520/ 1097] train: loss: 0.1801633
[Epoch 11; Iter   550/ 1097] train: loss: 0.0246531
[Epoch 11; Iter   580/ 1097] train: loss: 0.4444907
[Epoch 11; Iter   610/ 1097] train: loss: 0.0258687
[Epoch 11; Iter   640/ 1097] train: loss: 0.0618977
[Epoch 11; Iter   670/ 1097] train: loss: 0.0258082
[Epoch 11; Iter   700/ 1097] train: loss: 0.2184355
[Epoch 11; Iter   730/ 1097] train: loss: 0.1354420
[Epoch 11; Iter   760/ 1097] train: loss: 0.1679691
[Epoch 11; Iter   790/ 1097] train: loss: 0.0730225
[Epoch 11; Iter   820/ 1097] train: loss: 0.0510183
[Epoch 11; Iter   850/ 1097] train: loss: 0.1959767
[Epoch 11; Iter   880/ 1097] train: loss: 0.0205728
[Epoch 11; Iter   910/ 1097] train: loss: 0.0332919
[Epoch 11; Iter   940/ 1097] train: loss: 0.1944764
[Epoch 11; Iter   970/ 1097] train: loss: 0.0310383
[Epoch 11; Iter  1000/ 1097] train: loss: 0.0633238
[Epoch 11; Iter  1030/ 1097] train: loss: 0.1700469
[Epoch 11; Iter  1060/ 1097] train: loss: 0.2160042
[Epoch 11; Iter  1090/ 1097] train: loss: 0.0392326
[Epoch 11] ogbg-molhiv: 0.752324 val loss: 0.285532
[Epoch 11] ogbg-molhiv: 0.712492 test loss: 0.894340
[Epoch 12; Iter    23/ 1097] train: loss: 0.1820326
[Epoch 12; Iter    53/ 1097] train: loss: 0.0285995
[Epoch 12; Iter    83/ 1097] train: loss: 0.0586919
[Epoch 12; Iter   113/ 1097] train: loss: 0.1226663
[Epoch 8] ogbg-molhiv: 0.686242 val loss: 0.183058
[Epoch 8] ogbg-molhiv: 0.703682 test loss: 0.239808
[Epoch 9; Iter    30/  960] train: loss: 0.0358657
[Epoch 9; Iter    60/  960] train: loss: 0.0326586
[Epoch 9; Iter    90/  960] train: loss: 0.1578607
[Epoch 9; Iter   120/  960] train: loss: 0.1574189
[Epoch 9; Iter   150/  960] train: loss: 0.1150923
[Epoch 9; Iter   180/  960] train: loss: 0.4221527
[Epoch 9; Iter   210/  960] train: loss: 0.1722645
[Epoch 9; Iter   240/  960] train: loss: 0.0690182
[Epoch 9; Iter   270/  960] train: loss: 0.2951498
[Epoch 9; Iter   300/  960] train: loss: 0.0521046
[Epoch 9; Iter   330/  960] train: loss: 0.4829190
[Epoch 9; Iter   360/  960] train: loss: 0.0307581
[Epoch 9; Iter   390/  960] train: loss: 0.0415578
[Epoch 9; Iter   420/  960] train: loss: 0.1028472
[Epoch 9; Iter   450/  960] train: loss: 0.1042523
[Epoch 9; Iter   480/  960] train: loss: 0.1742037
[Epoch 9; Iter   510/  960] train: loss: 0.0384645
[Epoch 9; Iter   540/  960] train: loss: 0.1135761
[Epoch 9; Iter   570/  960] train: loss: 0.0285500
[Epoch 9; Iter   600/  960] train: loss: 0.0274028
[Epoch 9; Iter   630/  960] train: loss: 0.1483156
[Epoch 9; Iter   660/  960] train: loss: 0.3154719
[Epoch 9; Iter   690/  960] train: loss: 0.2128098
[Epoch 9; Iter   720/  960] train: loss: 0.2780060
[Epoch 9; Iter   750/  960] train: loss: 0.1723156
[Epoch 9; Iter   780/  960] train: loss: 0.2165126
[Epoch 9; Iter   810/  960] train: loss: 0.0354773
[Epoch 9; Iter   840/  960] train: loss: 0.0323872
[Epoch 9; Iter   870/  960] train: loss: 0.0294925
[Epoch 9; Iter   900/  960] train: loss: 0.1240917
[Epoch 9; Iter   930/  960] train: loss: 0.3355142
[Epoch 9; Iter   960/  960] train: loss: 0.2333716
[Epoch 9] ogbg-molhiv: 0.728435 val loss: 0.172493
[Epoch 9] ogbg-molhiv: 0.752595 test loss: 0.164062
[Epoch 10; Iter    30/  960] train: loss: 0.0367150
[Epoch 10; Iter    60/  960] train: loss: 0.0349215
[Epoch 10; Iter    90/  960] train: loss: 0.0950518
[Epoch 10; Iter   120/  960] train: loss: 0.0285885
[Epoch 10; Iter   150/  960] train: loss: 0.0345645
[Epoch 10; Iter   180/  960] train: loss: 0.0522482
[Epoch 10; Iter   210/  960] train: loss: 0.2301015
[Epoch 10; Iter   240/  960] train: loss: 0.4303080
[Epoch 10; Iter   270/  960] train: loss: 0.0303623
[Epoch 10; Iter   300/  960] train: loss: 0.2887324
[Epoch 10; Iter   330/  960] train: loss: 0.1921461
[Epoch 10; Iter   360/  960] train: loss: 0.1685833
[Epoch 10; Iter   390/  960] train: loss: 0.1023563
[Epoch 10; Iter   420/  960] train: loss: 0.2014441
[Epoch 10; Iter   450/  960] train: loss: 0.0401080
[Epoch 10; Iter   480/  960] train: loss: 0.0303669
[Epoch 10; Iter   510/  960] train: loss: 0.0843785
[Epoch 10; Iter   540/  960] train: loss: 0.2558673
[Epoch 10; Iter   570/  960] train: loss: 0.0941167
[Epoch 10; Iter   600/  960] train: loss: 0.0475945
[Epoch 10; Iter   630/  960] train: loss: 0.4184310
[Epoch 10; Iter   660/  960] train: loss: 0.0643046
[Epoch 10; Iter   690/  960] train: loss: 0.0368293
[Epoch 10; Iter   720/  960] train: loss: 0.0434862
[Epoch 10; Iter   750/  960] train: loss: 0.0283855
[Epoch 10; Iter   780/  960] train: loss: 0.1920533
[Epoch 10; Iter   810/  960] train: loss: 0.0246466
[Epoch 10; Iter   840/  960] train: loss: 0.0307241
[Epoch 10; Iter   870/  960] train: loss: 0.2609161
[Epoch 10; Iter   900/  960] train: loss: 0.0786671
[Epoch 10; Iter   930/  960] train: loss: 0.2670759
[Epoch 10; Iter   960/  960] train: loss: 0.0268929
[Epoch 10] ogbg-molhiv: 0.727267 val loss: 0.160662
[Epoch 10] ogbg-molhiv: 0.760768 test loss: 0.130480
[Epoch 11; Iter    30/  960] train: loss: 0.1324188
[Epoch 11; Iter    60/  960] train: loss: 0.0288710
[Epoch 11; Iter    90/  960] train: loss: 0.1552690
[Epoch 11; Iter   120/  960] train: loss: 0.1731762
[Epoch 11; Iter   150/  960] train: loss: 0.0599399
[Epoch 11; Iter   180/  960] train: loss: 0.0751153
[Epoch 11; Iter   210/  960] train: loss: 0.0671990
[Epoch 11; Iter   240/  960] train: loss: 0.3677671
[Epoch 11; Iter   270/  960] train: loss: 0.0233704
[Epoch 11; Iter   300/  960] train: loss: 0.0357305
[Epoch 11; Iter   330/  960] train: loss: 0.2841603
[Epoch 11; Iter   360/  960] train: loss: 0.0281765
[Epoch 11; Iter   390/  960] train: loss: 0.1267161
[Epoch 11; Iter   420/  960] train: loss: 0.0226650
[Epoch 11; Iter   450/  960] train: loss: 0.0318313
[Epoch 11; Iter   480/  960] train: loss: 0.0529916
[Epoch 11; Iter   510/  960] train: loss: 0.0779172
[Epoch 11; Iter   540/  960] train: loss: 0.1340265
[Epoch 11; Iter   570/  960] train: loss: 0.0362493
[Epoch 11; Iter   600/  960] train: loss: 0.0493857
[Epoch 11; Iter   630/  960] train: loss: 0.3056558
[Epoch 11; Iter   660/  960] train: loss: 0.0861954
[Epoch 11; Iter   690/  960] train: loss: 0.1724038
[Epoch 11; Iter   720/  960] train: loss: 0.0703833
[Epoch 11; Iter   750/  960] train: loss: 0.2816704
[Epoch 11; Iter   780/  960] train: loss: 0.1357548
[Epoch 11; Iter   810/  960] train: loss: 0.0916208
[Epoch 11; Iter   840/  960] train: loss: 0.0460646
[Epoch 11; Iter   870/  960] train: loss: 0.1320641
[Epoch 11; Iter   900/  960] train: loss: 0.0738792
[Epoch 11; Iter   930/  960] train: loss: 0.3054087
[Epoch 11; Iter   960/  960] train: loss: 0.0300555
[Epoch 11] ogbg-molhiv: 0.722214 val loss: 0.134844
[Epoch 11] ogbg-molhiv: 0.748006 test loss: 0.115195
[Epoch 12; Iter    30/  960] train: loss: 0.3808725
[Epoch 12; Iter    60/  960] train: loss: 0.0266561
[Epoch 12; Iter    90/  960] train: loss: 0.1538747
[Epoch 12; Iter   120/  960] train: loss: 0.0360868
[Epoch 12; Iter   150/  960] train: loss: 0.1412451
[Epoch 12; Iter   180/  960] train: loss: 0.1475051
[Epoch 12; Iter   210/  960] train: loss: 0.1509219
[Epoch 12; Iter   240/  960] train: loss: 0.1698023
[Epoch 12; Iter   270/  960] train: loss: 0.0499670
[Epoch 12; Iter   300/  960] train: loss: 0.2076903
[Epoch 12; Iter   330/  960] train: loss: 0.0450523
[Epoch 12; Iter   360/  960] train: loss: 0.0366231
[Epoch 12; Iter   390/  960] train: loss: 0.0622361
[Epoch 12; Iter   420/  960] train: loss: 0.4282768
[Epoch 12; Iter   450/  960] train: loss: 0.0201514
[Epoch 12; Iter   480/  960] train: loss: 0.0243379
[Epoch 12; Iter   510/  960] train: loss: 0.1642860
[Epoch 12; Iter   540/  960] train: loss: 0.0327903
[Epoch 12; Iter   570/  960] train: loss: 0.0313458
[Epoch 12; Iter   600/  960] train: loss: 0.2983284
[Epoch 12; Iter   630/  960] train: loss: 0.2424651
[Epoch 12; Iter   660/  960] train: loss: 0.1340538
[Epoch 12; Iter   690/  960] train: loss: 0.1221440
[Epoch 12; Iter   720/  960] train: loss: 0.1019369
[Epoch 12; Iter   750/  960] train: loss: 0.1690069
[Epoch 12; Iter   780/  960] train: loss: 0.1919471
[Epoch 12; Iter   810/  960] train: loss: 0.0350505
[Epoch 12; Iter   840/  960] train: loss: 0.1033501
[Epoch 12; Iter   870/  960] train: loss: 0.0898042
[Epoch 12; Iter   900/  960] train: loss: 0.0301189
[Epoch 12; Iter   930/  960] train: loss: 0.1033506
[Epoch 12; Iter   960/  960] train: loss: 0.2995067
[Epoch 12] ogbg-molhiv: 0.721058 val loss: 1.383623
[Epoch 12] ogbg-molhiv: 0.743723 test loss: 2.608336
[Epoch 13; Iter    30/  960] train: loss: 0.0712832
[Epoch 13; Iter    60/  960] train: loss: 0.0267189
[Epoch 13; Iter    90/  960] train: loss: 0.0319525
[Epoch 13; Iter   120/  960] train: loss: 0.0713639
[Epoch 13; Iter   150/  960] train: loss: 0.3247187
[Epoch 13; Iter   180/  960] train: loss: 0.1328163
[Epoch 13; Iter   210/  960] train: loss: 0.2674821
[Epoch 13; Iter   240/  960] train: loss: 0.2797951
[Epoch 13; Iter   270/  960] train: loss: 0.0312539
[Epoch 13; Iter   300/  960] train: loss: 0.0706975
[Epoch 13; Iter   330/  960] train: loss: 0.2033420
[Epoch 13; Iter   360/  960] train: loss: 0.0476157
[Epoch 13; Iter   390/  960] train: loss: 0.4092055
[Epoch 13; Iter   420/  960] train: loss: 0.1162791
[Epoch 13; Iter   450/  960] train: loss: 0.3242641
[Epoch 13; Iter   480/  960] train: loss: 0.0790289
[Epoch 13; Iter   510/  960] train: loss: 0.1500072
[Epoch 13; Iter   540/  960] train: loss: 0.1312305
[Epoch 13; Iter   570/  960] train: loss: 0.0212730
[Epoch 13; Iter   600/  960] train: loss: 0.0684747
[Epoch 8] ogbg-molhiv: 0.759567 val loss: 0.124194
[Epoch 8] ogbg-molhiv: 0.746331 test loss: 0.102289
[Epoch 9; Iter    30/  960] train: loss: 0.0299595
[Epoch 9; Iter    60/  960] train: loss: 0.2499702
[Epoch 9; Iter    90/  960] train: loss: 0.2250328
[Epoch 9; Iter   120/  960] train: loss: 0.0663252
[Epoch 9; Iter   150/  960] train: loss: 0.0312021
[Epoch 9; Iter   180/  960] train: loss: 0.0977098
[Epoch 9; Iter   210/  960] train: loss: 0.0881418
[Epoch 9; Iter   240/  960] train: loss: 0.0471504
[Epoch 9; Iter   270/  960] train: loss: 0.0816423
[Epoch 9; Iter   300/  960] train: loss: 0.0326975
[Epoch 9; Iter   330/  960] train: loss: 0.0945929
[Epoch 9; Iter   360/  960] train: loss: 0.0338497
[Epoch 9; Iter   390/  960] train: loss: 0.1288780
[Epoch 9; Iter   420/  960] train: loss: 0.1192281
[Epoch 9; Iter   450/  960] train: loss: 0.3301987
[Epoch 9; Iter   480/  960] train: loss: 0.1695677
[Epoch 9; Iter   510/  960] train: loss: 0.0602902
[Epoch 9; Iter   540/  960] train: loss: 0.1753671
[Epoch 9; Iter   570/  960] train: loss: 0.1164952
[Epoch 9; Iter   600/  960] train: loss: 0.1365704
[Epoch 9; Iter   630/  960] train: loss: 0.0373221
[Epoch 9; Iter   660/  960] train: loss: 0.0779873
[Epoch 9; Iter   690/  960] train: loss: 0.2997191
[Epoch 9; Iter   720/  960] train: loss: 0.1497004
[Epoch 9; Iter   750/  960] train: loss: 0.2703804
[Epoch 9; Iter   780/  960] train: loss: 0.2863526
[Epoch 9; Iter   810/  960] train: loss: 0.0448773
[Epoch 9; Iter   840/  960] train: loss: 0.0299781
[Epoch 9; Iter   870/  960] train: loss: 0.0273998
[Epoch 9; Iter   900/  960] train: loss: 0.0330045
[Epoch 9; Iter   930/  960] train: loss: 0.1378837
[Epoch 9; Iter   960/  960] train: loss: 0.0331602
[Epoch 9] ogbg-molhiv: 0.764131 val loss: 0.115547
[Epoch 9] ogbg-molhiv: 0.691626 test loss: 0.108104
[Epoch 10; Iter    30/  960] train: loss: 0.0787534
[Epoch 10; Iter    60/  960] train: loss: 0.1159284
[Epoch 10; Iter    90/  960] train: loss: 0.1742123
[Epoch 10; Iter   120/  960] train: loss: 0.0450208
[Epoch 10; Iter   150/  960] train: loss: 0.0221054
[Epoch 10; Iter   180/  960] train: loss: 0.1558243
[Epoch 10; Iter   210/  960] train: loss: 0.2127700
[Epoch 10; Iter   240/  960] train: loss: 0.0284198
[Epoch 10; Iter   270/  960] train: loss: 0.1177973
[Epoch 10; Iter   300/  960] train: loss: 0.1348039
[Epoch 10; Iter   330/  960] train: loss: 0.0434869
[Epoch 10; Iter   360/  960] train: loss: 0.1488344
[Epoch 10; Iter   390/  960] train: loss: 0.0606270
[Epoch 10; Iter   420/  960] train: loss: 0.0288998
[Epoch 10; Iter   450/  960] train: loss: 0.0483343
[Epoch 10; Iter   480/  960] train: loss: 0.1884582
[Epoch 10; Iter   510/  960] train: loss: 0.1028865
[Epoch 10; Iter   540/  960] train: loss: 0.0556900
[Epoch 10; Iter   570/  960] train: loss: 0.1339079
[Epoch 10; Iter   600/  960] train: loss: 0.0419182
[Epoch 10; Iter   630/  960] train: loss: 0.0225562
[Epoch 10; Iter   660/  960] train: loss: 0.0410814
[Epoch 10; Iter   690/  960] train: loss: 0.1498841
[Epoch 10; Iter   720/  960] train: loss: 0.0407494
[Epoch 10; Iter   750/  960] train: loss: 0.0719706
[Epoch 10; Iter   780/  960] train: loss: 0.0349424
[Epoch 10; Iter   810/  960] train: loss: 0.1561091
[Epoch 10; Iter   840/  960] train: loss: 0.1124642
[Epoch 10; Iter   870/  960] train: loss: 0.0803588
[Epoch 10; Iter   900/  960] train: loss: 0.0566006
[Epoch 10; Iter   930/  960] train: loss: 0.0262510
[Epoch 10; Iter   960/  960] train: loss: 0.0289119
[Epoch 10] ogbg-molhiv: 0.735781 val loss: 0.135386
[Epoch 10] ogbg-molhiv: 0.724833 test loss: 0.125386
[Epoch 11; Iter    30/  960] train: loss: 0.1356335
[Epoch 11; Iter    60/  960] train: loss: 0.0984704
[Epoch 11; Iter    90/  960] train: loss: 0.0731079
[Epoch 11; Iter   120/  960] train: loss: 0.0598811
[Epoch 11; Iter   150/  960] train: loss: 0.0323300
[Epoch 11; Iter   180/  960] train: loss: 0.0251690
[Epoch 11; Iter   210/  960] train: loss: 0.2020071
[Epoch 11; Iter   240/  960] train: loss: 0.1608217
[Epoch 11; Iter   270/  960] train: loss: 0.0291136
[Epoch 11; Iter   300/  960] train: loss: 0.1938554
[Epoch 11; Iter   330/  960] train: loss: 0.1478818
[Epoch 11; Iter   360/  960] train: loss: 0.0424262
[Epoch 11; Iter   390/  960] train: loss: 0.3722425
[Epoch 11; Iter   420/  960] train: loss: 0.1979480
[Epoch 11; Iter   450/  960] train: loss: 0.0435483
[Epoch 11; Iter   480/  960] train: loss: 0.0318025
[Epoch 11; Iter   510/  960] train: loss: 0.2122241
[Epoch 11; Iter   540/  960] train: loss: 0.0263348
[Epoch 11; Iter   570/  960] train: loss: 0.0378064
[Epoch 11; Iter   600/  960] train: loss: 0.0280865
[Epoch 11; Iter   630/  960] train: loss: 0.0218787
[Epoch 11; Iter   660/  960] train: loss: 0.0882633
[Epoch 11; Iter   690/  960] train: loss: 0.0298632
[Epoch 11; Iter   720/  960] train: loss: 0.0252484
[Epoch 11; Iter   750/  960] train: loss: 0.0274164
[Epoch 11; Iter   780/  960] train: loss: 0.0429781
[Epoch 11; Iter   810/  960] train: loss: 0.0437575
[Epoch 11; Iter   840/  960] train: loss: 0.1427555
[Epoch 11; Iter   870/  960] train: loss: 0.1838537
[Epoch 11; Iter   900/  960] train: loss: 0.1679577
[Epoch 11; Iter   930/  960] train: loss: 0.1407433
[Epoch 11; Iter   960/  960] train: loss: 0.0339590
[Epoch 11] ogbg-molhiv: 0.728688 val loss: 0.123165
[Epoch 11] ogbg-molhiv: 0.757628 test loss: 0.102181
[Epoch 12; Iter    30/  960] train: loss: 0.0330158
[Epoch 12; Iter    60/  960] train: loss: 0.1151744
[Epoch 12; Iter    90/  960] train: loss: 0.0322157
[Epoch 12; Iter   120/  960] train: loss: 0.2051461
[Epoch 12; Iter   150/  960] train: loss: 0.1995280
[Epoch 12; Iter   180/  960] train: loss: 0.1272519
[Epoch 12; Iter   210/  960] train: loss: 0.0511706
[Epoch 12; Iter   240/  960] train: loss: 0.2391914
[Epoch 12; Iter   270/  960] train: loss: 0.0353986
[Epoch 12; Iter   300/  960] train: loss: 0.0358592
[Epoch 12; Iter   330/  960] train: loss: 0.2160544
[Epoch 12; Iter   360/  960] train: loss: 0.0563538
[Epoch 12; Iter   390/  960] train: loss: 0.4065434
[Epoch 12; Iter   420/  960] train: loss: 0.1030445
[Epoch 12; Iter   450/  960] train: loss: 0.0298191
[Epoch 12; Iter   480/  960] train: loss: 0.1744542
[Epoch 12; Iter   510/  960] train: loss: 0.0878571
[Epoch 12; Iter   540/  960] train: loss: 0.0334421
[Epoch 12; Iter   570/  960] train: loss: 0.1623213
[Epoch 12; Iter   600/  960] train: loss: 0.0346182
[Epoch 12; Iter   630/  960] train: loss: 0.5116245
[Epoch 12; Iter   660/  960] train: loss: 0.0651343
[Epoch 12; Iter   690/  960] train: loss: 0.0693636
[Epoch 12; Iter   720/  960] train: loss: 0.0240809
[Epoch 12; Iter   750/  960] train: loss: 0.0623433
[Epoch 12; Iter   780/  960] train: loss: 0.1497056
[Epoch 12; Iter   810/  960] train: loss: 0.0244851
[Epoch 12; Iter   840/  960] train: loss: 0.0571310
[Epoch 12; Iter   870/  960] train: loss: 0.3984530
[Epoch 12; Iter   900/  960] train: loss: 0.4202809
[Epoch 12; Iter   930/  960] train: loss: 0.1398181
[Epoch 12; Iter   960/  960] train: loss: 0.0734069
[Epoch 12] ogbg-molhiv: 0.735325 val loss: 0.115480
[Epoch 12] ogbg-molhiv: 0.745420 test loss: 0.100750
[Epoch 13; Iter    30/  960] train: loss: 0.0346378
[Epoch 13; Iter    60/  960] train: loss: 0.1139254
[Epoch 13; Iter    90/  960] train: loss: 0.1870144
[Epoch 13; Iter   120/  960] train: loss: 0.0654159
[Epoch 13; Iter   150/  960] train: loss: 0.1579902
[Epoch 13; Iter   180/  960] train: loss: 0.0509484
[Epoch 13; Iter   210/  960] train: loss: 0.0348194
[Epoch 13; Iter   240/  960] train: loss: 0.1524174
[Epoch 13; Iter   270/  960] train: loss: 0.0327534
[Epoch 13; Iter   300/  960] train: loss: 0.0338308
[Epoch 13; Iter   330/  960] train: loss: 0.1466234
[Epoch 13; Iter   360/  960] train: loss: 0.1302305
[Epoch 13; Iter   390/  960] train: loss: 0.0233516
[Epoch 13; Iter   420/  960] train: loss: 0.0734362
[Epoch 13; Iter   450/  960] train: loss: 0.1077300
[Epoch 13; Iter   480/  960] train: loss: 0.0313481
[Epoch 13; Iter   510/  960] train: loss: 0.0295684
[Epoch 13; Iter   540/  960] train: loss: 0.1213343
[Epoch 13; Iter   570/  960] train: loss: 0.0420842
[Epoch 13; Iter   600/  960] train: loss: 0.2801835
[Epoch 8] ogbg-molhiv: 0.763655 val loss: 0.121868
[Epoch 8] ogbg-molhiv: 0.742630 test loss: 0.107254
[Epoch 9; Iter    30/  960] train: loss: 0.0533926
[Epoch 9; Iter    60/  960] train: loss: 0.0333690
[Epoch 9; Iter    90/  960] train: loss: 0.0483500
[Epoch 9; Iter   120/  960] train: loss: 0.0573931
[Epoch 9; Iter   150/  960] train: loss: 0.3901798
[Epoch 9; Iter   180/  960] train: loss: 0.0309943
[Epoch 9; Iter   210/  960] train: loss: 0.0448314
[Epoch 9; Iter   240/  960] train: loss: 0.2251690
[Epoch 9; Iter   270/  960] train: loss: 0.2007871
[Epoch 9; Iter   300/  960] train: loss: 0.0313955
[Epoch 9; Iter   330/  960] train: loss: 0.3418009
[Epoch 9; Iter   360/  960] train: loss: 0.0358120
[Epoch 9; Iter   390/  960] train: loss: 0.1543559
[Epoch 9; Iter   420/  960] train: loss: 0.1051779
[Epoch 9; Iter   450/  960] train: loss: 0.0446044
[Epoch 9; Iter   480/  960] train: loss: 0.0256931
[Epoch 9; Iter   510/  960] train: loss: 0.0366243
[Epoch 9; Iter   540/  960] train: loss: 0.2692574
[Epoch 9; Iter   570/  960] train: loss: 0.1331002
[Epoch 9; Iter   600/  960] train: loss: 0.0308872
[Epoch 9; Iter   630/  960] train: loss: 0.0798739
[Epoch 9; Iter   660/  960] train: loss: 0.0669628
[Epoch 9; Iter   690/  960] train: loss: 0.3614103
[Epoch 9; Iter   720/  960] train: loss: 0.1345332
[Epoch 9; Iter   750/  960] train: loss: 0.2341924
[Epoch 9; Iter   780/  960] train: loss: 0.3549479
[Epoch 9; Iter   810/  960] train: loss: 0.0736469
[Epoch 9; Iter   840/  960] train: loss: 0.0395005
[Epoch 9; Iter   870/  960] train: loss: 0.2935649
[Epoch 9; Iter   900/  960] train: loss: 0.0505899
[Epoch 9; Iter   930/  960] train: loss: 0.0386978
[Epoch 9; Iter   960/  960] train: loss: 0.0478479
[Epoch 9] ogbg-molhiv: 0.757842 val loss: 0.126652
[Epoch 9] ogbg-molhiv: 0.739810 test loss: 0.112143
[Epoch 10; Iter    30/  960] train: loss: 0.0469787
[Epoch 10; Iter    60/  960] train: loss: 0.0313302
[Epoch 10; Iter    90/  960] train: loss: 0.0323685
[Epoch 10; Iter   120/  960] train: loss: 0.1647677
[Epoch 10; Iter   150/  960] train: loss: 0.2600850
[Epoch 10; Iter   180/  960] train: loss: 0.0993990
[Epoch 10; Iter   210/  960] train: loss: 0.1993511
[Epoch 10; Iter   240/  960] train: loss: 0.2794982
[Epoch 10; Iter   270/  960] train: loss: 0.0789405
[Epoch 10; Iter   300/  960] train: loss: 0.2164130
[Epoch 10; Iter   330/  960] train: loss: 0.4122111
[Epoch 10; Iter   360/  960] train: loss: 0.2095235
[Epoch 10; Iter   390/  960] train: loss: 0.0873672
[Epoch 10; Iter   420/  960] train: loss: 0.2445123
[Epoch 10; Iter   450/  960] train: loss: 0.2950705
[Epoch 10; Iter   480/  960] train: loss: 0.1912452
[Epoch 10; Iter   510/  960] train: loss: 0.2068377
[Epoch 10; Iter   540/  960] train: loss: 0.0455309
[Epoch 10; Iter   570/  960] train: loss: 0.0397318
[Epoch 10; Iter   600/  960] train: loss: 0.0336586
[Epoch 10; Iter   630/  960] train: loss: 0.1418847
[Epoch 10; Iter   660/  960] train: loss: 0.1669192
[Epoch 10; Iter   690/  960] train: loss: 0.1220759
[Epoch 10; Iter   720/  960] train: loss: 0.0432258
[Epoch 10; Iter   750/  960] train: loss: 0.0498519
[Epoch 10; Iter   780/  960] train: loss: 0.0466838
[Epoch 10; Iter   810/  960] train: loss: 0.3229438
[Epoch 10; Iter   840/  960] train: loss: 0.1094954
[Epoch 10; Iter   870/  960] train: loss: 0.1369853
[Epoch 10; Iter   900/  960] train: loss: 0.2858123
[Epoch 10; Iter   930/  960] train: loss: 0.0338779
[Epoch 10; Iter   960/  960] train: loss: 0.0342134
[Epoch 10] ogbg-molhiv: 0.760158 val loss: 0.128463
[Epoch 10] ogbg-molhiv: 0.730951 test loss: 0.117243
[Epoch 11; Iter    30/  960] train: loss: 0.0305423
[Epoch 11; Iter    60/  960] train: loss: 0.0281600
[Epoch 11; Iter    90/  960] train: loss: 0.1320546
[Epoch 11; Iter   120/  960] train: loss: 0.1816632
[Epoch 11; Iter   150/  960] train: loss: 0.0933178
[Epoch 11; Iter   180/  960] train: loss: 0.0327252
[Epoch 11; Iter   210/  960] train: loss: 0.0268633
[Epoch 11; Iter   240/  960] train: loss: 0.1056849
[Epoch 11; Iter   270/  960] train: loss: 0.2112349
[Epoch 11; Iter   300/  960] train: loss: 0.0315026
[Epoch 11; Iter   330/  960] train: loss: 0.0410010
[Epoch 11; Iter   360/  960] train: loss: 0.0327210
[Epoch 11; Iter   390/  960] train: loss: 0.1447589
[Epoch 11; Iter   420/  960] train: loss: 0.1595485
[Epoch 11; Iter   450/  960] train: loss: 0.0909682
[Epoch 11; Iter   480/  960] train: loss: 0.0352037
[Epoch 11; Iter   510/  960] train: loss: 0.0241605
[Epoch 11; Iter   540/  960] train: loss: 0.2826818
[Epoch 11; Iter   570/  960] train: loss: 0.1382256
[Epoch 11; Iter   600/  960] train: loss: 0.0871893
[Epoch 11; Iter   630/  960] train: loss: 0.1799969
[Epoch 11; Iter   660/  960] train: loss: 0.1880928
[Epoch 11; Iter   690/  960] train: loss: 0.1822515
[Epoch 11; Iter   720/  960] train: loss: 0.1136593
[Epoch 11; Iter   750/  960] train: loss: 0.1836267
[Epoch 11; Iter   780/  960] train: loss: 0.0628362
[Epoch 11; Iter   810/  960] train: loss: 0.0738530
[Epoch 11; Iter   840/  960] train: loss: 0.0359747
[Epoch 11; Iter   870/  960] train: loss: 0.0352456
[Epoch 11; Iter   900/  960] train: loss: 0.1854700
[Epoch 11; Iter   930/  960] train: loss: 0.0446201
[Epoch 11; Iter   960/  960] train: loss: 0.0980182
[Epoch 11] ogbg-molhiv: 0.759054 val loss: 0.197023
[Epoch 11] ogbg-molhiv: 0.741133 test loss: 0.103893
[Epoch 12; Iter    30/  960] train: loss: 0.0376029
[Epoch 12; Iter    60/  960] train: loss: 0.0357197
[Epoch 12; Iter    90/  960] train: loss: 0.2860405
[Epoch 12; Iter   120/  960] train: loss: 0.0367180
[Epoch 12; Iter   150/  960] train: loss: 0.0239467
[Epoch 12; Iter   180/  960] train: loss: 0.0766211
[Epoch 12; Iter   210/  960] train: loss: 0.0484301
[Epoch 12; Iter   240/  960] train: loss: 0.0669510
[Epoch 12; Iter   270/  960] train: loss: 0.0722243
[Epoch 12; Iter   300/  960] train: loss: 0.1709061
[Epoch 12; Iter   330/  960] train: loss: 0.0332123
[Epoch 12; Iter   360/  960] train: loss: 0.0778206
[Epoch 12; Iter   390/  960] train: loss: 0.2358828
[Epoch 12; Iter   420/  960] train: loss: 0.1136972
[Epoch 12; Iter   450/  960] train: loss: 0.2526557
[Epoch 12; Iter   480/  960] train: loss: 0.0270261
[Epoch 12; Iter   510/  960] train: loss: 0.0378390
[Epoch 12; Iter   540/  960] train: loss: 0.0468010
[Epoch 12; Iter   570/  960] train: loss: 0.1847106
[Epoch 12; Iter   600/  960] train: loss: 0.1326636
[Epoch 12; Iter   630/  960] train: loss: 0.0360526
[Epoch 12; Iter   660/  960] train: loss: 0.0428816
[Epoch 12; Iter   690/  960] train: loss: 0.2414375
[Epoch 12; Iter   720/  960] train: loss: 0.3612843
[Epoch 12; Iter   750/  960] train: loss: 0.0374898
[Epoch 12; Iter   780/  960] train: loss: 0.0528293
[Epoch 12; Iter   810/  960] train: loss: 0.1364304
[Epoch 12; Iter   840/  960] train: loss: 0.1586517
[Epoch 12; Iter   870/  960] train: loss: 0.0753129
[Epoch 12; Iter   900/  960] train: loss: 0.4875982
[Epoch 12; Iter   930/  960] train: loss: 0.0405304
[Epoch 12; Iter   960/  960] train: loss: 0.0208024
[Epoch 12] ogbg-molhiv: 0.764242 val loss: 0.112204
[Epoch 12] ogbg-molhiv: 0.735261 test loss: 0.101808
[Epoch 13; Iter    30/  960] train: loss: 0.2881981
[Epoch 13; Iter    60/  960] train: loss: 0.1230052
[Epoch 13; Iter    90/  960] train: loss: 0.0545154
[Epoch 13; Iter   120/  960] train: loss: 0.0361276
[Epoch 13; Iter   150/  960] train: loss: 0.0321555
[Epoch 13; Iter   180/  960] train: loss: 0.0710692
[Epoch 13; Iter   210/  960] train: loss: 0.0891220
[Epoch 13; Iter   240/  960] train: loss: 0.1422114
[Epoch 13; Iter   270/  960] train: loss: 0.2089113
[Epoch 13; Iter   300/  960] train: loss: 0.1125412
[Epoch 13; Iter   330/  960] train: loss: 0.3019888
[Epoch 13; Iter   360/  960] train: loss: 0.0387250
[Epoch 13; Iter   390/  960] train: loss: 0.0343534
[Epoch 13; Iter   420/  960] train: loss: 0.1329180
[Epoch 13; Iter   450/  960] train: loss: 0.0247951
[Epoch 13; Iter   480/  960] train: loss: 0.0331945
[Epoch 13; Iter   510/  960] train: loss: 0.0398037
[Epoch 13; Iter   540/  960] train: loss: 0.2051978
[Epoch 13; Iter   570/  960] train: loss: 0.0265136
[Epoch 13; Iter   600/  960] train: loss: 0.1645680
[Epoch 10; Iter   183/  823] train: loss: 0.2395059
[Epoch 10; Iter   213/  823] train: loss: 0.0856689
[Epoch 10; Iter   243/  823] train: loss: 0.1000375
[Epoch 10; Iter   273/  823] train: loss: 0.0255235
[Epoch 10; Iter   303/  823] train: loss: 0.2617245
[Epoch 10; Iter   333/  823] train: loss: 0.0242126
[Epoch 10; Iter   363/  823] train: loss: 0.0544884
[Epoch 10; Iter   393/  823] train: loss: 0.0211125
[Epoch 10; Iter   423/  823] train: loss: 0.1541599
[Epoch 10; Iter   453/  823] train: loss: 0.0426510
[Epoch 10; Iter   483/  823] train: loss: 0.0264292
[Epoch 10; Iter   513/  823] train: loss: 0.2172372
[Epoch 10; Iter   543/  823] train: loss: 0.1936100
[Epoch 10; Iter   573/  823] train: loss: 0.1978318
[Epoch 10; Iter   603/  823] train: loss: 0.0516586
[Epoch 10; Iter   633/  823] train: loss: 0.1843396
[Epoch 10; Iter   663/  823] train: loss: 0.0408010
[Epoch 10; Iter   693/  823] train: loss: 0.0451216
[Epoch 10; Iter   723/  823] train: loss: 0.2531826
[Epoch 10; Iter   753/  823] train: loss: 0.4386764
[Epoch 10; Iter   783/  823] train: loss: 0.1243193
[Epoch 10; Iter   813/  823] train: loss: 0.2277080
[Epoch 10] ogbg-molhiv: 0.703687 val loss: 0.135105
[Epoch 10] ogbg-molhiv: 0.677435 test loss: 0.119667
[Epoch 11; Iter    20/  823] train: loss: 0.0877381
[Epoch 11; Iter    50/  823] train: loss: 0.2568030
[Epoch 11; Iter    80/  823] train: loss: 0.0313876
[Epoch 11; Iter   110/  823] train: loss: 0.0504615
[Epoch 11; Iter   140/  823] train: loss: 0.0495708
[Epoch 11; Iter   170/  823] train: loss: 0.0335071
[Epoch 11; Iter   200/  823] train: loss: 0.0878083
[Epoch 11; Iter   230/  823] train: loss: 0.0257564
[Epoch 11; Iter   260/  823] train: loss: 0.1046075
[Epoch 11; Iter   290/  823] train: loss: 0.0349282
[Epoch 11; Iter   320/  823] train: loss: 0.0245803
[Epoch 11; Iter   350/  823] train: loss: 0.0852443
[Epoch 11; Iter   380/  823] train: loss: 0.0207434
[Epoch 11; Iter   410/  823] train: loss: 0.0255278
[Epoch 11; Iter   440/  823] train: loss: 0.0969196
[Epoch 11; Iter   470/  823] train: loss: 0.0439896
[Epoch 11; Iter   500/  823] train: loss: 0.2386835
[Epoch 11; Iter   530/  823] train: loss: 0.1731867
[Epoch 11; Iter   560/  823] train: loss: 0.2028846
[Epoch 11; Iter   590/  823] train: loss: 0.1801882
[Epoch 11; Iter   620/  823] train: loss: 0.0528439
[Epoch 11; Iter   650/  823] train: loss: 0.0289835
[Epoch 11; Iter   680/  823] train: loss: 0.0798742
[Epoch 11; Iter   710/  823] train: loss: 0.0326620
[Epoch 11; Iter   740/  823] train: loss: 0.0810000
[Epoch 11; Iter   770/  823] train: loss: 0.0395267
[Epoch 11; Iter   800/  823] train: loss: 0.1795341
[Epoch 11] ogbg-molhiv: 0.718661 val loss: 0.141866
[Epoch 11] ogbg-molhiv: 0.718871 test loss: 0.102678
[Epoch 12; Iter     7/  823] train: loss: 0.1312117
[Epoch 12; Iter    37/  823] train: loss: 0.1576733
[Epoch 12; Iter    67/  823] train: loss: 0.1230316
[Epoch 12; Iter    97/  823] train: loss: 0.0223990
[Epoch 12; Iter   127/  823] train: loss: 0.0265085
[Epoch 12; Iter   157/  823] train: loss: 0.1659521
[Epoch 12; Iter   187/  823] train: loss: 0.0666794
[Epoch 12; Iter   217/  823] train: loss: 0.0264464
[Epoch 12; Iter   247/  823] train: loss: 0.0282757
[Epoch 12; Iter   277/  823] train: loss: 0.1492848
[Epoch 12; Iter   307/  823] train: loss: 0.3650050
[Epoch 12; Iter   337/  823] train: loss: 0.2201134
[Epoch 12; Iter   367/  823] train: loss: 0.0935975
[Epoch 12; Iter   397/  823] train: loss: 0.0601970
[Epoch 12; Iter   427/  823] train: loss: 0.1026462
[Epoch 12; Iter   457/  823] train: loss: 0.0263775
[Epoch 12; Iter   487/  823] train: loss: 0.0702028
[Epoch 12; Iter   517/  823] train: loss: 0.2015488
[Epoch 12; Iter   547/  823] train: loss: 0.2560299
[Epoch 12; Iter   577/  823] train: loss: 0.0358574
[Epoch 12; Iter   607/  823] train: loss: 0.0973908
[Epoch 12; Iter   637/  823] train: loss: 0.2105799
[Epoch 12; Iter   667/  823] train: loss: 0.0396403
[Epoch 12; Iter   697/  823] train: loss: 0.0496978
[Epoch 12; Iter   727/  823] train: loss: 0.0839881
[Epoch 12; Iter   757/  823] train: loss: 0.0267019
[Epoch 12; Iter   787/  823] train: loss: 0.2564968
[Epoch 12; Iter   817/  823] train: loss: 0.1779522
[Epoch 12] ogbg-molhiv: 0.734641 val loss: 0.130341
[Epoch 12] ogbg-molhiv: 0.748965 test loss: 0.102999
[Epoch 13; Iter    24/  823] train: loss: 0.1853340
[Epoch 13; Iter    54/  823] train: loss: 0.1066149
[Epoch 13; Iter    84/  823] train: loss: 0.0188377
[Epoch 13; Iter   114/  823] train: loss: 0.0877386
[Epoch 13; Iter   144/  823] train: loss: 0.2013472
[Epoch 13; Iter   174/  823] train: loss: 0.1568512
[Epoch 13; Iter   204/  823] train: loss: 0.0586159
[Epoch 13; Iter   234/  823] train: loss: 0.1748960
[Epoch 13; Iter   264/  823] train: loss: 0.0472822
[Epoch 13; Iter   294/  823] train: loss: 0.1560650
[Epoch 13; Iter   324/  823] train: loss: 0.0508601
[Epoch 13; Iter   354/  823] train: loss: 0.0361456
[Epoch 13; Iter   384/  823] train: loss: 0.0549234
[Epoch 13; Iter   414/  823] train: loss: 0.0468613
[Epoch 13; Iter   444/  823] train: loss: 0.1474717
[Epoch 13; Iter   474/  823] train: loss: 0.2205460
[Epoch 13; Iter   504/  823] train: loss: 0.1708670
[Epoch 13; Iter   534/  823] train: loss: 0.1196961
[Epoch 13; Iter   564/  823] train: loss: 0.2397111
[Epoch 13; Iter   594/  823] train: loss: 0.1628810
[Epoch 13; Iter   624/  823] train: loss: 0.2268501
[Epoch 13; Iter   654/  823] train: loss: 0.0256150
[Epoch 13; Iter   684/  823] train: loss: 0.0358826
[Epoch 13; Iter   714/  823] train: loss: 0.1243197
[Epoch 13; Iter   744/  823] train: loss: 0.0274713
[Epoch 13; Iter   774/  823] train: loss: 0.2297387
[Epoch 13; Iter   804/  823] train: loss: 0.2420803
[Epoch 13] ogbg-molhiv: 0.715918 val loss: 0.146335
[Epoch 13] ogbg-molhiv: 0.734513 test loss: 0.102761
[Epoch 14; Iter    11/  823] train: loss: 0.3656917
[Epoch 14; Iter    41/  823] train: loss: 0.0813400
[Epoch 14; Iter    71/  823] train: loss: 0.1548098
[Epoch 14; Iter   101/  823] train: loss: 0.0283625
[Epoch 14; Iter   131/  823] train: loss: 0.2065036
[Epoch 14; Iter   161/  823] train: loss: 0.1059628
[Epoch 14; Iter   191/  823] train: loss: 0.0320290
[Epoch 14; Iter   221/  823] train: loss: 0.2548095
[Epoch 14; Iter   251/  823] train: loss: 0.0266289
[Epoch 14; Iter   281/  823] train: loss: 0.0687350
[Epoch 14; Iter   311/  823] train: loss: 0.4353710
[Epoch 14; Iter   341/  823] train: loss: 0.1496009
[Epoch 14; Iter   371/  823] train: loss: 0.0540865
[Epoch 14; Iter   401/  823] train: loss: 0.1027398
[Epoch 14; Iter   431/  823] train: loss: 0.0245306
[Epoch 14; Iter   461/  823] train: loss: 0.3089662
[Epoch 14; Iter   491/  823] train: loss: 0.2112763
[Epoch 14; Iter   521/  823] train: loss: 0.1747008
[Epoch 14; Iter   551/  823] train: loss: 0.0275571
[Epoch 14; Iter   581/  823] train: loss: 0.1282416
[Epoch 14; Iter   611/  823] train: loss: 0.2207181
[Epoch 14; Iter   641/  823] train: loss: 0.1281440
[Epoch 14; Iter   671/  823] train: loss: 0.0548331
[Epoch 14; Iter   701/  823] train: loss: 0.0838074
[Epoch 14; Iter   731/  823] train: loss: 0.0893748
[Epoch 14; Iter   761/  823] train: loss: 0.1277160
[Epoch 14; Iter   791/  823] train: loss: 0.0312931
[Epoch 14; Iter   821/  823] train: loss: 0.0282204
[Epoch 14] ogbg-molhiv: 0.706645 val loss: 0.144318
[Epoch 14] ogbg-molhiv: 0.711045 test loss: 0.110851
[Epoch 15; Iter    28/  823] train: loss: 0.0340927
[Epoch 15; Iter    58/  823] train: loss: 0.0414432
[Epoch 15; Iter    88/  823] train: loss: 0.0417264
[Epoch 15; Iter   118/  823] train: loss: 0.0520360
[Epoch 15; Iter   148/  823] train: loss: 0.0584355
[Epoch 15; Iter   178/  823] train: loss: 0.0466864
[Epoch 15; Iter   208/  823] train: loss: 0.0185882
[Epoch 15; Iter   238/  823] train: loss: 0.2250519
[Epoch 15; Iter   268/  823] train: loss: 0.0287320
[Epoch 15; Iter   298/  823] train: loss: 0.0621711
[Epoch 15; Iter   328/  823] train: loss: 0.1322386
[Epoch 15; Iter   358/  823] train: loss: 0.2369304
[Epoch 15; Iter   388/  823] train: loss: 0.0796397
[Epoch 15; Iter   418/  823] train: loss: 0.0275474
[Epoch 15; Iter   448/  823] train: loss: 0.1339566
[Epoch 10; Iter   183/  823] train: loss: 0.1920406
[Epoch 10; Iter   213/  823] train: loss: 0.0850462
[Epoch 10; Iter   243/  823] train: loss: 0.0302363
[Epoch 10; Iter   273/  823] train: loss: 0.3233995
[Epoch 10; Iter   303/  823] train: loss: 0.0351673
[Epoch 10; Iter   333/  823] train: loss: 0.0302865
[Epoch 10; Iter   363/  823] train: loss: 0.0941389
[Epoch 10; Iter   393/  823] train: loss: 0.0263463
[Epoch 10; Iter   423/  823] train: loss: 0.0527962
[Epoch 10; Iter   453/  823] train: loss: 0.3441753
[Epoch 10; Iter   483/  823] train: loss: 0.2031444
[Epoch 10; Iter   513/  823] train: loss: 0.2056444
[Epoch 10; Iter   543/  823] train: loss: 0.0399686
[Epoch 10; Iter   573/  823] train: loss: 0.1088802
[Epoch 10; Iter   603/  823] train: loss: 0.1626604
[Epoch 10; Iter   633/  823] train: loss: 0.0342830
[Epoch 10; Iter   663/  823] train: loss: 0.1692335
[Epoch 10; Iter   693/  823] train: loss: 0.0321887
[Epoch 10; Iter   723/  823] train: loss: 0.1393085
[Epoch 10; Iter   753/  823] train: loss: 0.1297584
[Epoch 10; Iter   783/  823] train: loss: 0.2351020
[Epoch 10; Iter   813/  823] train: loss: 0.1406905
[Epoch 10] ogbg-molhiv: 0.677591 val loss: 0.453116
[Epoch 10] ogbg-molhiv: 0.726254 test loss: 0.195038
[Epoch 11; Iter    20/  823] train: loss: 0.2729690
[Epoch 11; Iter    50/  823] train: loss: 0.0319704
[Epoch 11; Iter    80/  823] train: loss: 0.0834797
[Epoch 11; Iter   110/  823] train: loss: 0.1400854
[Epoch 11; Iter   140/  823] train: loss: 0.1446643
[Epoch 11; Iter   170/  823] train: loss: 0.1008939
[Epoch 11; Iter   200/  823] train: loss: 0.0746933
[Epoch 11; Iter   230/  823] train: loss: 0.2126459
[Epoch 11; Iter   260/  823] train: loss: 0.1390612
[Epoch 11; Iter   290/  823] train: loss: 0.0913551
[Epoch 11; Iter   320/  823] train: loss: 0.1539572
[Epoch 11; Iter   350/  823] train: loss: 0.0324274
[Epoch 11; Iter   380/  823] train: loss: 0.1421088
[Epoch 11; Iter   410/  823] train: loss: 0.0306655
[Epoch 11; Iter   440/  823] train: loss: 0.0318723
[Epoch 11; Iter   470/  823] train: loss: 0.0535957
[Epoch 11; Iter   500/  823] train: loss: 0.1604391
[Epoch 11; Iter   530/  823] train: loss: 0.0551629
[Epoch 11; Iter   560/  823] train: loss: 0.0226487
[Epoch 11; Iter   590/  823] train: loss: 0.1457792
[Epoch 11; Iter   620/  823] train: loss: 0.0816908
[Epoch 11; Iter   650/  823] train: loss: 0.0451374
[Epoch 11; Iter   680/  823] train: loss: 0.0525282
[Epoch 11; Iter   710/  823] train: loss: 0.1294388
[Epoch 11; Iter   740/  823] train: loss: 0.0314710
[Epoch 11; Iter   770/  823] train: loss: 0.0541272
[Epoch 11; Iter   800/  823] train: loss: 0.0935873
[Epoch 11] ogbg-molhiv: 0.733019 val loss: 0.218289
[Epoch 11] ogbg-molhiv: 0.724180 test loss: 0.288732
[Epoch 12; Iter     7/  823] train: loss: 0.0204176
[Epoch 12; Iter    37/  823] train: loss: 0.0345524
[Epoch 12; Iter    67/  823] train: loss: 0.1717611
[Epoch 12; Iter    97/  823] train: loss: 0.0459361
[Epoch 12; Iter   127/  823] train: loss: 0.1546710
[Epoch 12; Iter   157/  823] train: loss: 0.0524958
[Epoch 12; Iter   187/  823] train: loss: 0.3725198
[Epoch 12; Iter   217/  823] train: loss: 0.0334104
[Epoch 12; Iter   247/  823] train: loss: 0.0333851
[Epoch 12; Iter   277/  823] train: loss: 0.3403587
[Epoch 12; Iter   307/  823] train: loss: 0.0454198
[Epoch 12; Iter   337/  823] train: loss: 0.0613448
[Epoch 12; Iter   367/  823] train: loss: 0.1234637
[Epoch 12; Iter   397/  823] train: loss: 0.1861968
[Epoch 12; Iter   427/  823] train: loss: 0.0255033
[Epoch 12; Iter   457/  823] train: loss: 0.0868001
[Epoch 12; Iter   487/  823] train: loss: 0.0390111
[Epoch 12; Iter   517/  823] train: loss: 0.1447150
[Epoch 12; Iter   547/  823] train: loss: 0.0496365
[Epoch 12; Iter   577/  823] train: loss: 0.0671455
[Epoch 12; Iter   607/  823] train: loss: 0.0472852
[Epoch 12; Iter   637/  823] train: loss: 0.0343416
[Epoch 12; Iter   667/  823] train: loss: 0.0578271
[Epoch 12; Iter   697/  823] train: loss: 0.0990423
[Epoch 12; Iter   727/  823] train: loss: 0.0628950
[Epoch 12; Iter   757/  823] train: loss: 0.0738044
[Epoch 12; Iter   787/  823] train: loss: 0.0878580
[Epoch 12; Iter   817/  823] train: loss: 0.1061956
[Epoch 12] ogbg-molhiv: 0.735910 val loss: 0.146432
[Epoch 12] ogbg-molhiv: 0.746453 test loss: 0.115041
[Epoch 13; Iter    24/  823] train: loss: 0.0789081
[Epoch 13; Iter    54/  823] train: loss: 0.0249673
[Epoch 13; Iter    84/  823] train: loss: 0.1247642
[Epoch 13; Iter   114/  823] train: loss: 0.0270052
[Epoch 13; Iter   144/  823] train: loss: 0.1026391
[Epoch 13; Iter   174/  823] train: loss: 0.0950132
[Epoch 13; Iter   204/  823] train: loss: 0.0613547
[Epoch 13; Iter   234/  823] train: loss: 0.0640707
[Epoch 13; Iter   264/  823] train: loss: 0.2260827
[Epoch 13; Iter   294/  823] train: loss: 0.1349969
[Epoch 13; Iter   324/  823] train: loss: 0.0428817
[Epoch 13; Iter   354/  823] train: loss: 0.0401274
[Epoch 13; Iter   384/  823] train: loss: 0.0304236
[Epoch 13; Iter   414/  823] train: loss: 0.2163440
[Epoch 13; Iter   444/  823] train: loss: 0.2577340
[Epoch 13; Iter   474/  823] train: loss: 0.0276987
[Epoch 13; Iter   504/  823] train: loss: 0.2699811
[Epoch 13; Iter   534/  823] train: loss: 0.0224135
[Epoch 13; Iter   564/  823] train: loss: 0.2037307
[Epoch 13; Iter   594/  823] train: loss: 0.0984659
[Epoch 13; Iter   624/  823] train: loss: 0.0244160
[Epoch 13; Iter   654/  823] train: loss: 0.1202355
[Epoch 13; Iter   684/  823] train: loss: 0.3286254
[Epoch 13; Iter   714/  823] train: loss: 0.0401288
[Epoch 13; Iter   744/  823] train: loss: 0.0274074
[Epoch 13; Iter   774/  823] train: loss: 0.1476633
[Epoch 13; Iter   804/  823] train: loss: 0.3812758
[Epoch 13] ogbg-molhiv: 0.712302 val loss: 0.403112
[Epoch 13] ogbg-molhiv: 0.723799 test loss: 0.244496
[Epoch 14; Iter    11/  823] train: loss: 0.0365740
[Epoch 14; Iter    41/  823] train: loss: 0.1209199
[Epoch 14; Iter    71/  823] train: loss: 0.0627113
[Epoch 14; Iter   101/  823] train: loss: 0.1418782
[Epoch 14; Iter   131/  823] train: loss: 0.1505890
[Epoch 14; Iter   161/  823] train: loss: 0.0423688
[Epoch 14; Iter   191/  823] train: loss: 0.2414053
[Epoch 14; Iter   221/  823] train: loss: 0.0257938
[Epoch 14; Iter   251/  823] train: loss: 0.2355096
[Epoch 14; Iter   281/  823] train: loss: 0.0911708
[Epoch 14; Iter   311/  823] train: loss: 0.0900705
[Epoch 14; Iter   341/  823] train: loss: 0.0867790
[Epoch 14; Iter   371/  823] train: loss: 0.2839128
[Epoch 14; Iter   401/  823] train: loss: 0.0322760
[Epoch 14; Iter   431/  823] train: loss: 0.0274601
[Epoch 14; Iter   461/  823] train: loss: 0.0296102
[Epoch 14; Iter   491/  823] train: loss: 0.0253388
[Epoch 14; Iter   521/  823] train: loss: 0.3245531
[Epoch 14; Iter   551/  823] train: loss: 0.4128185
[Epoch 14; Iter   581/  823] train: loss: 0.1227593
[Epoch 14; Iter   611/  823] train: loss: 0.0416577
[Epoch 14; Iter   641/  823] train: loss: 0.0583514
[Epoch 14; Iter   671/  823] train: loss: 0.0241990
[Epoch 14; Iter   701/  823] train: loss: 0.0441057
[Epoch 14; Iter   731/  823] train: loss: 0.1320403
[Epoch 14; Iter   761/  823] train: loss: 0.0227675
[Epoch 14; Iter   791/  823] train: loss: 0.0563709
[Epoch 14; Iter   821/  823] train: loss: 0.0247975
[Epoch 14] ogbg-molhiv: 0.731263 val loss: 0.138005
[Epoch 14] ogbg-molhiv: 0.730260 test loss: 0.103070
[Epoch 15; Iter    28/  823] train: loss: 0.2918353
[Epoch 15; Iter    58/  823] train: loss: 0.0378010
[Epoch 15; Iter    88/  823] train: loss: 0.1106443
[Epoch 15; Iter   118/  823] train: loss: 0.0658880
[Epoch 15; Iter   148/  823] train: loss: 0.1928308
[Epoch 15; Iter   178/  823] train: loss: 0.1560508
[Epoch 15; Iter   208/  823] train: loss: 0.1098598
[Epoch 15; Iter   238/  823] train: loss: 0.1459780
[Epoch 15; Iter   268/  823] train: loss: 0.0193069
[Epoch 15; Iter   298/  823] train: loss: 0.0770540
[Epoch 15; Iter   328/  823] train: loss: 0.3233494
[Epoch 15; Iter   358/  823] train: loss: 0.0916763
[Epoch 15; Iter   388/  823] train: loss: 0.3879239
[Epoch 15; Iter   418/  823] train: loss: 0.1222470
[Epoch 15; Iter   448/  823] train: loss: 0.0280940
[Epoch 10; Iter   183/  823] train: loss: 0.2866691
[Epoch 10; Iter   213/  823] train: loss: 0.0954258
[Epoch 10; Iter   243/  823] train: loss: 0.0671419
[Epoch 10; Iter   273/  823] train: loss: 0.0322440
[Epoch 10; Iter   303/  823] train: loss: 0.2607782
[Epoch 10; Iter   333/  823] train: loss: 0.0420599
[Epoch 10; Iter   363/  823] train: loss: 0.0272711
[Epoch 10; Iter   393/  823] train: loss: 0.2671736
[Epoch 10; Iter   423/  823] train: loss: 0.1879063
[Epoch 10; Iter   453/  823] train: loss: 0.0256414
[Epoch 10; Iter   483/  823] train: loss: 0.1388995
[Epoch 10; Iter   513/  823] train: loss: 0.0958091
[Epoch 10; Iter   543/  823] train: loss: 0.2423163
[Epoch 10; Iter   573/  823] train: loss: 0.0410914
[Epoch 10; Iter   603/  823] train: loss: 0.1373341
[Epoch 10; Iter   633/  823] train: loss: 0.0255693
[Epoch 10; Iter   663/  823] train: loss: 0.2341671
[Epoch 10; Iter   693/  823] train: loss: 0.0260707
[Epoch 10; Iter   723/  823] train: loss: 0.0434236
[Epoch 10; Iter   753/  823] train: loss: 0.1618424
[Epoch 10; Iter   783/  823] train: loss: 0.0625165
[Epoch 10; Iter   813/  823] train: loss: 0.2107460
[Epoch 10] ogbg-molhiv: 0.671608 val loss: 0.193619
[Epoch 10] ogbg-molhiv: 0.712624 test loss: 0.115768
[Epoch 11; Iter    20/  823] train: loss: 0.2863447
[Epoch 11; Iter    50/  823] train: loss: 0.0267624
[Epoch 11; Iter    80/  823] train: loss: 0.0312342
[Epoch 11; Iter   110/  823] train: loss: 0.0876115
[Epoch 11; Iter   140/  823] train: loss: 0.2487925
[Epoch 11; Iter   170/  823] train: loss: 0.0229319
[Epoch 11; Iter   200/  823] train: loss: 0.0867691
[Epoch 11; Iter   230/  823] train: loss: 0.0762946
[Epoch 11; Iter   260/  823] train: loss: 0.0256333
[Epoch 11; Iter   290/  823] train: loss: 0.0448151
[Epoch 11; Iter   320/  823] train: loss: 0.0292786
[Epoch 11; Iter   350/  823] train: loss: 0.4057871
[Epoch 11; Iter   380/  823] train: loss: 0.0267874
[Epoch 11; Iter   410/  823] train: loss: 0.0245853
[Epoch 11; Iter   440/  823] train: loss: 0.1690630
[Epoch 11; Iter   470/  823] train: loss: 0.0334426
[Epoch 11; Iter   500/  823] train: loss: 0.0274197
[Epoch 11; Iter   530/  823] train: loss: 0.0452269
[Epoch 11; Iter   560/  823] train: loss: 0.0572258
[Epoch 11; Iter   590/  823] train: loss: 0.0319536
[Epoch 11; Iter   620/  823] train: loss: 0.0850688
[Epoch 11; Iter   650/  823] train: loss: 0.1851591
[Epoch 11; Iter   680/  823] train: loss: 0.4877284
[Epoch 11; Iter   710/  823] train: loss: 0.0224680
[Epoch 11; Iter   740/  823] train: loss: 0.0562842
[Epoch 11; Iter   770/  823] train: loss: 0.0283901
[Epoch 11; Iter   800/  823] train: loss: 0.0530495
[Epoch 11] ogbg-molhiv: 0.717034 val loss: 0.207712
[Epoch 11] ogbg-molhiv: 0.750826 test loss: 0.100940
[Epoch 12; Iter     7/  823] train: loss: 0.1027035
[Epoch 12; Iter    37/  823] train: loss: 0.1828252
[Epoch 12; Iter    67/  823] train: loss: 0.0727697
[Epoch 12; Iter    97/  823] train: loss: 0.1379835
[Epoch 12; Iter   127/  823] train: loss: 0.1792312
[Epoch 12; Iter   157/  823] train: loss: 0.0915174
[Epoch 12; Iter   187/  823] train: loss: 0.0430186
[Epoch 12; Iter   217/  823] train: loss: 0.0310824
[Epoch 12; Iter   247/  823] train: loss: 0.3051644
[Epoch 12; Iter   277/  823] train: loss: 0.0571087
[Epoch 12; Iter   307/  823] train: loss: 0.0350103
[Epoch 12; Iter   337/  823] train: loss: 0.0260405
[Epoch 12; Iter   367/  823] train: loss: 0.1656744
[Epoch 12; Iter   397/  823] train: loss: 0.0971580
[Epoch 12; Iter   427/  823] train: loss: 0.1791436
[Epoch 12; Iter   457/  823] train: loss: 0.0217444
[Epoch 12; Iter   487/  823] train: loss: 0.0243255
[Epoch 12; Iter   517/  823] train: loss: 0.0634404
[Epoch 12; Iter   547/  823] train: loss: 0.0246546
[Epoch 12; Iter   577/  823] train: loss: 0.0333683
[Epoch 12; Iter   607/  823] train: loss: 0.0146315
[Epoch 12; Iter   637/  823] train: loss: 0.0382914
[Epoch 12; Iter   667/  823] train: loss: 0.0460632
[Epoch 12; Iter   697/  823] train: loss: 0.3113685
[Epoch 12; Iter   727/  823] train: loss: 0.2022360
[Epoch 12; Iter   757/  823] train: loss: 0.1147245
[Epoch 12; Iter   787/  823] train: loss: 0.1081912
[Epoch 12; Iter   817/  823] train: loss: 0.0400600
[Epoch 12] ogbg-molhiv: 0.689710 val loss: 0.236255
[Epoch 12] ogbg-molhiv: 0.721535 test loss: 0.102422
[Epoch 13; Iter    24/  823] train: loss: 0.0332827
[Epoch 13; Iter    54/  823] train: loss: 0.1552476
[Epoch 13; Iter    84/  823] train: loss: 0.2588007
[Epoch 13; Iter   114/  823] train: loss: 0.1684780
[Epoch 13; Iter   144/  823] train: loss: 0.0276457
[Epoch 13; Iter   174/  823] train: loss: 0.0310923
[Epoch 13; Iter   204/  823] train: loss: 0.1785624
[Epoch 13; Iter   234/  823] train: loss: 0.0775528
[Epoch 13; Iter   264/  823] train: loss: 0.4095515
[Epoch 13; Iter   294/  823] train: loss: 0.0347083
[Epoch 13; Iter   324/  823] train: loss: 0.0618809
[Epoch 13; Iter   354/  823] train: loss: 0.0379262
[Epoch 13; Iter   384/  823] train: loss: 0.0372612
[Epoch 13; Iter   414/  823] train: loss: 0.0330409
[Epoch 13; Iter   444/  823] train: loss: 0.0327092
[Epoch 13; Iter   474/  823] train: loss: 0.1415839
[Epoch 13; Iter   504/  823] train: loss: 0.1500879
[Epoch 13; Iter   534/  823] train: loss: 0.0746352
[Epoch 13; Iter   564/  823] train: loss: 0.0763388
[Epoch 13; Iter   594/  823] train: loss: 0.0197773
[Epoch 13; Iter   624/  823] train: loss: 0.0915365
[Epoch 13; Iter   654/  823] train: loss: 0.1919363
[Epoch 13; Iter   684/  823] train: loss: 0.0237834
[Epoch 13; Iter   714/  823] train: loss: 0.0751468
[Epoch 13; Iter   744/  823] train: loss: 0.0183369
[Epoch 13; Iter   774/  823] train: loss: 0.0199611
[Epoch 13; Iter   804/  823] train: loss: 0.0207857
[Epoch 13] ogbg-molhiv: 0.715411 val loss: 0.148701
[Epoch 13] ogbg-molhiv: 0.757303 test loss: 0.137791
[Epoch 14; Iter    11/  823] train: loss: 0.0477076
[Epoch 14; Iter    41/  823] train: loss: 0.1601786
[Epoch 14; Iter    71/  823] train: loss: 0.0236157
[Epoch 14; Iter   101/  823] train: loss: 0.0307885
[Epoch 14; Iter   131/  823] train: loss: 0.0193549
[Epoch 14; Iter   161/  823] train: loss: 0.0335699
[Epoch 14; Iter   191/  823] train: loss: 0.1746122
[Epoch 14; Iter   221/  823] train: loss: 0.1451477
[Epoch 14; Iter   251/  823] train: loss: 0.0665892
[Epoch 14; Iter   281/  823] train: loss: 0.0465238
[Epoch 14; Iter   311/  823] train: loss: 0.1652619
[Epoch 14; Iter   341/  823] train: loss: 0.1418332
[Epoch 14; Iter   371/  823] train: loss: 0.0295681
[Epoch 14; Iter   401/  823] train: loss: 0.0529276
[Epoch 14; Iter   431/  823] train: loss: 0.0266580
[Epoch 14; Iter   461/  823] train: loss: 0.0770312
[Epoch 14; Iter   491/  823] train: loss: 0.0383968
[Epoch 14; Iter   521/  823] train: loss: 0.0381946
[Epoch 14; Iter   551/  823] train: loss: 0.0305937
[Epoch 14; Iter   581/  823] train: loss: 0.0906931
[Epoch 14; Iter   611/  823] train: loss: 0.1631121
[Epoch 14; Iter   641/  823] train: loss: 0.2324631
[Epoch 14; Iter   671/  823] train: loss: 0.0986517
[Epoch 14; Iter   701/  823] train: loss: 0.0634366
[Epoch 14; Iter   731/  823] train: loss: 0.1632214
[Epoch 14; Iter   761/  823] train: loss: 0.0210161
[Epoch 14; Iter   791/  823] train: loss: 0.1558169
[Epoch 14; Iter   821/  823] train: loss: 0.1425255
[Epoch 14] ogbg-molhiv: 0.711872 val loss: 0.158361
[Epoch 14] ogbg-molhiv: 0.735681 test loss: 0.153229
[Epoch 15; Iter    28/  823] train: loss: 0.0250363
[Epoch 15; Iter    58/  823] train: loss: 0.0477784
[Epoch 15; Iter    88/  823] train: loss: 0.0897848
[Epoch 15; Iter   118/  823] train: loss: 0.1575968
[Epoch 15; Iter   148/  823] train: loss: 0.0363567
[Epoch 15; Iter   178/  823] train: loss: 0.1656831
[Epoch 15; Iter   208/  823] train: loss: 0.2635259
[Epoch 15; Iter   238/  823] train: loss: 0.0231910
[Epoch 15; Iter   268/  823] train: loss: 0.2315184
[Epoch 15; Iter   298/  823] train: loss: 0.0339480
[Epoch 15; Iter   328/  823] train: loss: 0.0262986
[Epoch 15; Iter   358/  823] train: loss: 0.0344461
[Epoch 15; Iter   388/  823] train: loss: 0.1154437
[Epoch 15; Iter   418/  823] train: loss: 0.0282344
[Epoch 15; Iter   448/  823] train: loss: 0.1879794
[Epoch 12; Iter   143/ 1097] train: loss: 0.0658806
[Epoch 12; Iter   173/ 1097] train: loss: 0.2798362
[Epoch 12; Iter   203/ 1097] train: loss: 0.1796603
[Epoch 12; Iter   233/ 1097] train: loss: 0.3825198
[Epoch 12; Iter   263/ 1097] train: loss: 0.1955286
[Epoch 12; Iter   293/ 1097] train: loss: 0.1327613
[Epoch 12; Iter   323/ 1097] train: loss: 0.1178028
[Epoch 12; Iter   353/ 1097] train: loss: 0.0383792
[Epoch 12; Iter   383/ 1097] train: loss: 0.1926834
[Epoch 12; Iter   413/ 1097] train: loss: 0.0373802
[Epoch 12; Iter   443/ 1097] train: loss: 0.0714663
[Epoch 12; Iter   473/ 1097] train: loss: 0.0307653
[Epoch 12; Iter   503/ 1097] train: loss: 0.0469896
[Epoch 12; Iter   533/ 1097] train: loss: 0.1511696
[Epoch 12; Iter   563/ 1097] train: loss: 0.1969377
[Epoch 12; Iter   593/ 1097] train: loss: 0.2443122
[Epoch 12; Iter   623/ 1097] train: loss: 0.0281326
[Epoch 12; Iter   653/ 1097] train: loss: 0.0342397
[Epoch 12; Iter   683/ 1097] train: loss: 0.0412104
[Epoch 12; Iter   713/ 1097] train: loss: 0.2658336
[Epoch 12; Iter   743/ 1097] train: loss: 0.0437855
[Epoch 12; Iter   773/ 1097] train: loss: 0.3098374
[Epoch 12; Iter   803/ 1097] train: loss: 0.0743440
[Epoch 12; Iter   833/ 1097] train: loss: 0.0435168
[Epoch 12; Iter   863/ 1097] train: loss: 0.0331383
[Epoch 12; Iter   893/ 1097] train: loss: 0.0859030
[Epoch 12; Iter   923/ 1097] train: loss: 0.0244313
[Epoch 12; Iter   953/ 1097] train: loss: 0.0521734
[Epoch 12; Iter   983/ 1097] train: loss: 0.1694576
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0219287
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1901407
[Epoch 12; Iter  1073/ 1097] train: loss: 0.2200059
[Epoch 12] ogbg-molhiv: 0.780102 val loss: 0.091567
[Epoch 12] ogbg-molhiv: 0.737853 test loss: 0.127402
[Epoch 13; Iter     6/ 1097] train: loss: 0.0791769
[Epoch 13; Iter    36/ 1097] train: loss: 0.0368448
[Epoch 13; Iter    66/ 1097] train: loss: 0.0438902
[Epoch 13; Iter    96/ 1097] train: loss: 0.0968864
[Epoch 13; Iter   126/ 1097] train: loss: 0.0247780
[Epoch 13; Iter   156/ 1097] train: loss: 0.2840361
[Epoch 13; Iter   186/ 1097] train: loss: 0.1480937
[Epoch 13; Iter   216/ 1097] train: loss: 0.1174046
[Epoch 13; Iter   246/ 1097] train: loss: 0.1375506
[Epoch 13; Iter   276/ 1097] train: loss: 0.0436437
[Epoch 13; Iter   306/ 1097] train: loss: 0.0206810
[Epoch 13; Iter   336/ 1097] train: loss: 0.0220153
[Epoch 13; Iter   366/ 1097] train: loss: 0.0249923
[Epoch 13; Iter   396/ 1097] train: loss: 0.2230705
[Epoch 13; Iter   426/ 1097] train: loss: 0.0590422
[Epoch 13; Iter   456/ 1097] train: loss: 0.1795263
[Epoch 13; Iter   486/ 1097] train: loss: 0.0443347
[Epoch 13; Iter   516/ 1097] train: loss: 0.1266099
[Epoch 13; Iter   546/ 1097] train: loss: 0.1632278
[Epoch 13; Iter   576/ 1097] train: loss: 0.1934927
[Epoch 13; Iter   606/ 1097] train: loss: 0.0433864
[Epoch 13; Iter   636/ 1097] train: loss: 0.1926180
[Epoch 13; Iter   666/ 1097] train: loss: 0.0264459
[Epoch 13; Iter   696/ 1097] train: loss: 0.1839136
[Epoch 13; Iter   726/ 1097] train: loss: 0.3321521
[Epoch 13; Iter   756/ 1097] train: loss: 0.1814082
[Epoch 13; Iter   786/ 1097] train: loss: 0.3929790
[Epoch 13; Iter   816/ 1097] train: loss: 0.5006202
[Epoch 13; Iter   846/ 1097] train: loss: 0.0643722
[Epoch 13; Iter   876/ 1097] train: loss: 0.0309861
[Epoch 13; Iter   906/ 1097] train: loss: 0.3798193
[Epoch 13; Iter   936/ 1097] train: loss: 0.0326246
[Epoch 13; Iter   966/ 1097] train: loss: 0.0901835
[Epoch 13; Iter   996/ 1097] train: loss: 0.0535318
[Epoch 13; Iter  1026/ 1097] train: loss: 0.1691800
[Epoch 13; Iter  1056/ 1097] train: loss: 0.0898259
[Epoch 13; Iter  1086/ 1097] train: loss: 0.2039192
[Epoch 13] ogbg-molhiv: 0.818030 val loss: 0.170176
[Epoch 13] ogbg-molhiv: 0.775137 test loss: 0.153620
[Epoch 14; Iter    19/ 1097] train: loss: 0.0384221
[Epoch 14; Iter    49/ 1097] train: loss: 0.0343186
[Epoch 14; Iter    79/ 1097] train: loss: 0.2407191
[Epoch 14; Iter   109/ 1097] train: loss: 0.1967665
[Epoch 14; Iter   139/ 1097] train: loss: 0.1560904
[Epoch 14; Iter   169/ 1097] train: loss: 0.1713554
[Epoch 14; Iter   199/ 1097] train: loss: 0.0184925
[Epoch 14; Iter   229/ 1097] train: loss: 0.1358924
[Epoch 14; Iter   259/ 1097] train: loss: 0.0386679
[Epoch 14; Iter   289/ 1097] train: loss: 0.1137365
[Epoch 14; Iter   319/ 1097] train: loss: 0.1491410
[Epoch 14; Iter   349/ 1097] train: loss: 0.0347640
[Epoch 14; Iter   379/ 1097] train: loss: 0.0936975
[Epoch 14; Iter   409/ 1097] train: loss: 0.0381063
[Epoch 14; Iter   439/ 1097] train: loss: 0.1673706
[Epoch 14; Iter   469/ 1097] train: loss: 0.2128379
[Epoch 14; Iter   499/ 1097] train: loss: 0.1501587
[Epoch 14; Iter   529/ 1097] train: loss: 0.0491461
[Epoch 14; Iter   559/ 1097] train: loss: 0.2305389
[Epoch 14; Iter   589/ 1097] train: loss: 0.1376593
[Epoch 14; Iter   619/ 1097] train: loss: 0.1801910
[Epoch 14; Iter   649/ 1097] train: loss: 0.1635341
[Epoch 14; Iter   679/ 1097] train: loss: 0.0290581
[Epoch 14; Iter   709/ 1097] train: loss: 0.0780925
[Epoch 14; Iter   739/ 1097] train: loss: 0.0559295
[Epoch 14; Iter   769/ 1097] train: loss: 0.0220189
[Epoch 14; Iter   799/ 1097] train: loss: 0.0549468
[Epoch 14; Iter   829/ 1097] train: loss: 0.1514839
[Epoch 14; Iter   859/ 1097] train: loss: 0.2435948
[Epoch 14; Iter   889/ 1097] train: loss: 0.0289837
[Epoch 14; Iter   919/ 1097] train: loss: 0.0277400
[Epoch 14; Iter   949/ 1097] train: loss: 0.0268102
[Epoch 14; Iter   979/ 1097] train: loss: 0.2870754
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0404593
[Epoch 14; Iter  1039/ 1097] train: loss: 0.2614763
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0436694
[Epoch 14] ogbg-molhiv: 0.811232 val loss: 0.112518
[Epoch 14] ogbg-molhiv: 0.752212 test loss: 0.265239
[Epoch 15; Iter     2/ 1097] train: loss: 0.0673245
[Epoch 15; Iter    32/ 1097] train: loss: 0.0325227
[Epoch 15; Iter    62/ 1097] train: loss: 0.0938070
[Epoch 15; Iter    92/ 1097] train: loss: 0.0431547
[Epoch 15; Iter   122/ 1097] train: loss: 0.0293968
[Epoch 15; Iter   152/ 1097] train: loss: 0.1947254
[Epoch 15; Iter   182/ 1097] train: loss: 0.0545088
[Epoch 15; Iter   212/ 1097] train: loss: 0.3050854
[Epoch 15; Iter   242/ 1097] train: loss: 0.0820525
[Epoch 15; Iter   272/ 1097] train: loss: 0.1433301
[Epoch 15; Iter   302/ 1097] train: loss: 0.1744710
[Epoch 15; Iter   332/ 1097] train: loss: 0.0832569
[Epoch 15; Iter   362/ 1097] train: loss: 0.1683030
[Epoch 15; Iter   392/ 1097] train: loss: 0.0650620
[Epoch 15; Iter   422/ 1097] train: loss: 0.0429128
[Epoch 15; Iter   452/ 1097] train: loss: 0.3122780
[Epoch 15; Iter   482/ 1097] train: loss: 0.0305701
[Epoch 15; Iter   512/ 1097] train: loss: 0.2005054
[Epoch 15; Iter   542/ 1097] train: loss: 0.0281114
[Epoch 15; Iter   572/ 1097] train: loss: 0.1320711
[Epoch 15; Iter   602/ 1097] train: loss: 0.0190240
[Epoch 15; Iter   632/ 1097] train: loss: 0.1150647
[Epoch 15; Iter   662/ 1097] train: loss: 0.1604948
[Epoch 15; Iter   692/ 1097] train: loss: 0.0439960
[Epoch 15; Iter   722/ 1097] train: loss: 0.3549605
[Epoch 15; Iter   752/ 1097] train: loss: 0.0820798
[Epoch 15; Iter   782/ 1097] train: loss: 0.1650642
[Epoch 15; Iter   812/ 1097] train: loss: 0.0227952
[Epoch 15; Iter   842/ 1097] train: loss: 0.2540176
[Epoch 15; Iter   872/ 1097] train: loss: 0.0473772
[Epoch 15; Iter   902/ 1097] train: loss: 0.1233071
[Epoch 15; Iter   932/ 1097] train: loss: 0.0311978
[Epoch 15; Iter   962/ 1097] train: loss: 0.1518519
[Epoch 15; Iter   992/ 1097] train: loss: 0.1504143
[Epoch 15; Iter  1022/ 1097] train: loss: 0.5648227
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0346568
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0403694
[Epoch 15] ogbg-molhiv: 0.789854 val loss: 1.578787
[Epoch 15] ogbg-molhiv: 0.753703 test loss: 1.425513
[Epoch 16; Iter    15/ 1097] train: loss: 0.1740887
[Epoch 16; Iter    45/ 1097] train: loss: 0.0815163
[Epoch 16; Iter    75/ 1097] train: loss: 0.1011378
[Epoch 16; Iter   105/ 1097] train: loss: 0.1088720
[Epoch 16; Iter   135/ 1097] train: loss: 0.0459674
[Epoch 16; Iter   165/ 1097] train: loss: 0.5299258
[Epoch 16; Iter   195/ 1097] train: loss: 0.0346419
[Epoch 12; Iter   143/ 1097] train: loss: 0.1863724
[Epoch 12; Iter   173/ 1097] train: loss: 0.0219386
[Epoch 12; Iter   203/ 1097] train: loss: 0.1649325
[Epoch 12; Iter   233/ 1097] train: loss: 0.0245371
[Epoch 12; Iter   263/ 1097] train: loss: 0.0345294
[Epoch 12; Iter   293/ 1097] train: loss: 0.1816643
[Epoch 12; Iter   323/ 1097] train: loss: 0.1323135
[Epoch 12; Iter   353/ 1097] train: loss: 0.1021066
[Epoch 12; Iter   383/ 1097] train: loss: 0.0288022
[Epoch 12; Iter   413/ 1097] train: loss: 0.0275316
[Epoch 12; Iter   443/ 1097] train: loss: 0.0281635
[Epoch 12; Iter   473/ 1097] train: loss: 0.2330923
[Epoch 12; Iter   503/ 1097] train: loss: 0.1912427
[Epoch 12; Iter   533/ 1097] train: loss: 0.0424478
[Epoch 12; Iter   563/ 1097] train: loss: 0.1348273
[Epoch 12; Iter   593/ 1097] train: loss: 0.2359390
[Epoch 12; Iter   623/ 1097] train: loss: 0.0338436
[Epoch 12; Iter   653/ 1097] train: loss: 0.1071704
[Epoch 12; Iter   683/ 1097] train: loss: 0.3309786
[Epoch 12; Iter   713/ 1097] train: loss: 0.0823386
[Epoch 12; Iter   743/ 1097] train: loss: 0.0293217
[Epoch 12; Iter   773/ 1097] train: loss: 0.1384554
[Epoch 12; Iter   803/ 1097] train: loss: 0.1509715
[Epoch 12; Iter   833/ 1097] train: loss: 0.1058654
[Epoch 12; Iter   863/ 1097] train: loss: 0.0384561
[Epoch 12; Iter   893/ 1097] train: loss: 0.1925237
[Epoch 12; Iter   923/ 1097] train: loss: 0.0281933
[Epoch 12; Iter   953/ 1097] train: loss: 0.1955454
[Epoch 12; Iter   983/ 1097] train: loss: 0.2915509
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0294402
[Epoch 12; Iter  1043/ 1097] train: loss: 0.0288864
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0261738
[Epoch 12] ogbg-molhiv: 0.781905 val loss: 0.079215
[Epoch 12] ogbg-molhiv: 0.767159 test loss: 0.116786
[Epoch 13; Iter     6/ 1097] train: loss: 0.1862923
[Epoch 13; Iter    36/ 1097] train: loss: 0.1884445
[Epoch 13; Iter    66/ 1097] train: loss: 0.1641016
[Epoch 13; Iter    96/ 1097] train: loss: 0.0204678
[Epoch 13; Iter   126/ 1097] train: loss: 0.0494776
[Epoch 13; Iter   156/ 1097] train: loss: 0.1945735
[Epoch 13; Iter   186/ 1097] train: loss: 0.3182196
[Epoch 13; Iter   216/ 1097] train: loss: 0.1805575
[Epoch 13; Iter   246/ 1097] train: loss: 0.0438561
[Epoch 13; Iter   276/ 1097] train: loss: 0.0198011
[Epoch 13; Iter   306/ 1097] train: loss: 0.3497305
[Epoch 13; Iter   336/ 1097] train: loss: 0.1357901
[Epoch 13; Iter   366/ 1097] train: loss: 0.3866086
[Epoch 13; Iter   396/ 1097] train: loss: 0.0480035
[Epoch 13; Iter   426/ 1097] train: loss: 0.1394807
[Epoch 13; Iter   456/ 1097] train: loss: 0.1633095
[Epoch 13; Iter   486/ 1097] train: loss: 0.0342148
[Epoch 13; Iter   516/ 1097] train: loss: 0.1266062
[Epoch 13; Iter   546/ 1097] train: loss: 0.0309132
[Epoch 13; Iter   576/ 1097] train: loss: 0.0877975
[Epoch 13; Iter   606/ 1097] train: loss: 0.2299199
[Epoch 13; Iter   636/ 1097] train: loss: 0.0416265
[Epoch 13; Iter   666/ 1097] train: loss: 0.1865820
[Epoch 13; Iter   696/ 1097] train: loss: 0.4664505
[Epoch 13; Iter   726/ 1097] train: loss: 0.0513465
[Epoch 13; Iter   756/ 1097] train: loss: 0.0526967
[Epoch 13; Iter   786/ 1097] train: loss: 0.1626103
[Epoch 13; Iter   816/ 1097] train: loss: 0.1053592
[Epoch 13; Iter   846/ 1097] train: loss: 0.0293186
[Epoch 13; Iter   876/ 1097] train: loss: 0.1427763
[Epoch 13; Iter   906/ 1097] train: loss: 0.3392392
[Epoch 13; Iter   936/ 1097] train: loss: 0.0543822
[Epoch 13; Iter   966/ 1097] train: loss: 0.0718063
[Epoch 13; Iter   996/ 1097] train: loss: 0.0306144
[Epoch 13; Iter  1026/ 1097] train: loss: 0.0304921
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2754458
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1604206
[Epoch 13] ogbg-molhiv: 0.811676 val loss: 0.079683
[Epoch 13] ogbg-molhiv: 0.762373 test loss: 0.120753
[Epoch 14; Iter    19/ 1097] train: loss: 0.2675349
[Epoch 14; Iter    49/ 1097] train: loss: 0.1779684
[Epoch 14; Iter    79/ 1097] train: loss: 0.0432923
[Epoch 14; Iter   109/ 1097] train: loss: 0.1416485
[Epoch 14; Iter   139/ 1097] train: loss: 0.0385073
[Epoch 14; Iter   169/ 1097] train: loss: 0.1825392
[Epoch 14; Iter   199/ 1097] train: loss: 0.0262051
[Epoch 14; Iter   229/ 1097] train: loss: 0.2572253
[Epoch 14; Iter   259/ 1097] train: loss: 0.3158887
[Epoch 14; Iter   289/ 1097] train: loss: 0.1283868
[Epoch 14; Iter   319/ 1097] train: loss: 0.0383338
[Epoch 14; Iter   349/ 1097] train: loss: 0.0383568
[Epoch 14; Iter   379/ 1097] train: loss: 0.0578261
[Epoch 14; Iter   409/ 1097] train: loss: 0.1182462
[Epoch 14; Iter   439/ 1097] train: loss: 0.2046933
[Epoch 14; Iter   469/ 1097] train: loss: 0.2311062
[Epoch 14; Iter   499/ 1097] train: loss: 0.0318247
[Epoch 14; Iter   529/ 1097] train: loss: 0.2128621
[Epoch 14; Iter   559/ 1097] train: loss: 0.0495720
[Epoch 14; Iter   589/ 1097] train: loss: 0.1253777
[Epoch 14; Iter   619/ 1097] train: loss: 0.3154308
[Epoch 14; Iter   649/ 1097] train: loss: 0.0536076
[Epoch 14; Iter   679/ 1097] train: loss: 0.0388862
[Epoch 14; Iter   709/ 1097] train: loss: 0.3249432
[Epoch 14; Iter   739/ 1097] train: loss: 0.2251606
[Epoch 14; Iter   769/ 1097] train: loss: 0.0315196
[Epoch 14; Iter   799/ 1097] train: loss: 0.0196021
[Epoch 14; Iter   829/ 1097] train: loss: 0.1610709
[Epoch 14; Iter   859/ 1097] train: loss: 0.0370688
[Epoch 14; Iter   889/ 1097] train: loss: 0.1115402
[Epoch 14; Iter   919/ 1097] train: loss: 0.1310521
[Epoch 14; Iter   949/ 1097] train: loss: 0.1695547
[Epoch 14; Iter   979/ 1097] train: loss: 0.0846202
[Epoch 14; Iter  1009/ 1097] train: loss: 0.2419977
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0274039
[Epoch 14; Iter  1069/ 1097] train: loss: 0.0453007
[Epoch 14] ogbg-molhiv: 0.788831 val loss: 0.148331
[Epoch 14] ogbg-molhiv: 0.788627 test loss: 0.206713
[Epoch 15; Iter     2/ 1097] train: loss: 0.1577844
[Epoch 15; Iter    32/ 1097] train: loss: 0.0840824
[Epoch 15; Iter    62/ 1097] train: loss: 0.1120859
[Epoch 15; Iter    92/ 1097] train: loss: 0.1196407
[Epoch 15; Iter   122/ 1097] train: loss: 0.1117734
[Epoch 15; Iter   152/ 1097] train: loss: 0.0221893
[Epoch 15; Iter   182/ 1097] train: loss: 0.1273335
[Epoch 15; Iter   212/ 1097] train: loss: 0.1304387
[Epoch 15; Iter   242/ 1097] train: loss: 0.1536331
[Epoch 15; Iter   272/ 1097] train: loss: 0.3168173
[Epoch 15; Iter   302/ 1097] train: loss: 0.0989928
[Epoch 15; Iter   332/ 1097] train: loss: 0.2146528
[Epoch 15; Iter   362/ 1097] train: loss: 0.1526872
[Epoch 15; Iter   392/ 1097] train: loss: 0.1631243
[Epoch 15; Iter   422/ 1097] train: loss: 0.0497597
[Epoch 15; Iter   452/ 1097] train: loss: 0.0334920
[Epoch 15; Iter   482/ 1097] train: loss: 0.1149869
[Epoch 15; Iter   512/ 1097] train: loss: 0.3907467
[Epoch 15; Iter   542/ 1097] train: loss: 0.0683561
[Epoch 15; Iter   572/ 1097] train: loss: 0.1362863
[Epoch 15; Iter   602/ 1097] train: loss: 0.0360580
[Epoch 15; Iter   632/ 1097] train: loss: 0.2855625
[Epoch 15; Iter   662/ 1097] train: loss: 0.0695735
[Epoch 15; Iter   692/ 1097] train: loss: 0.1229835
[Epoch 15; Iter   722/ 1097] train: loss: 0.0417703
[Epoch 15; Iter   752/ 1097] train: loss: 0.0634154
[Epoch 15; Iter   782/ 1097] train: loss: 0.0824692
[Epoch 15; Iter   812/ 1097] train: loss: 0.0218286
[Epoch 15; Iter   842/ 1097] train: loss: 0.0375416
[Epoch 15; Iter   872/ 1097] train: loss: 0.0306781
[Epoch 15; Iter   902/ 1097] train: loss: 0.0576313
[Epoch 15; Iter   932/ 1097] train: loss: 0.1727364
[Epoch 15; Iter   962/ 1097] train: loss: 0.2382017
[Epoch 15; Iter   992/ 1097] train: loss: 0.0308267
[Epoch 15; Iter  1022/ 1097] train: loss: 0.1673475
[Epoch 15; Iter  1052/ 1097] train: loss: 0.1470315
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0474159
[Epoch 15] ogbg-molhiv: 0.774639 val loss: 0.073294
[Epoch 15] ogbg-molhiv: 0.753741 test loss: 0.123308
[Epoch 16; Iter    15/ 1097] train: loss: 0.0260575
[Epoch 16; Iter    45/ 1097] train: loss: 0.1555945
[Epoch 16; Iter    75/ 1097] train: loss: 0.1921194
[Epoch 16; Iter   105/ 1097] train: loss: 0.0262113
[Epoch 16; Iter   135/ 1097] train: loss: 0.0606379
[Epoch 16; Iter   165/ 1097] train: loss: 0.1426398
[Epoch 16; Iter   195/ 1097] train: loss: 0.0253988
[Epoch 12; Iter   143/ 1097] train: loss: 0.3065137
[Epoch 12; Iter   173/ 1097] train: loss: 0.0384861
[Epoch 12; Iter   203/ 1097] train: loss: 0.0288897
[Epoch 12; Iter   233/ 1097] train: loss: 0.0280103
[Epoch 12; Iter   263/ 1097] train: loss: 0.0295556
[Epoch 12; Iter   293/ 1097] train: loss: 0.1313785
[Epoch 12; Iter   323/ 1097] train: loss: 0.1540004
[Epoch 12; Iter   353/ 1097] train: loss: 0.2254554
[Epoch 12; Iter   383/ 1097] train: loss: 0.0504222
[Epoch 12; Iter   413/ 1097] train: loss: 0.2147356
[Epoch 12; Iter   443/ 1097] train: loss: 0.3177124
[Epoch 12; Iter   473/ 1097] train: loss: 0.1455223
[Epoch 12; Iter   503/ 1097] train: loss: 0.1769029
[Epoch 12; Iter   533/ 1097] train: loss: 0.1793778
[Epoch 12; Iter   563/ 1097] train: loss: 0.0872539
[Epoch 12; Iter   593/ 1097] train: loss: 0.3306254
[Epoch 12; Iter   623/ 1097] train: loss: 0.1888133
[Epoch 12; Iter   653/ 1097] train: loss: 0.0399960
[Epoch 12; Iter   683/ 1097] train: loss: 0.1679076
[Epoch 12; Iter   713/ 1097] train: loss: 0.0393776
[Epoch 12; Iter   743/ 1097] train: loss: 0.2060149
[Epoch 12; Iter   773/ 1097] train: loss: 0.0272626
[Epoch 12; Iter   803/ 1097] train: loss: 0.1975094
[Epoch 12; Iter   833/ 1097] train: loss: 0.1631453
[Epoch 12; Iter   863/ 1097] train: loss: 0.2591580
[Epoch 12; Iter   893/ 1097] train: loss: 0.0271873
[Epoch 12; Iter   923/ 1097] train: loss: 0.2259042
[Epoch 12; Iter   953/ 1097] train: loss: 0.2360697
[Epoch 12; Iter   983/ 1097] train: loss: 0.0663915
[Epoch 12; Iter  1013/ 1097] train: loss: 0.0554881
[Epoch 12; Iter  1043/ 1097] train: loss: 0.1371213
[Epoch 12; Iter  1073/ 1097] train: loss: 0.0812790
[Epoch 12] ogbg-molhiv: 0.794438 val loss: 0.083972
[Epoch 12] ogbg-molhiv: 0.736799 test loss: 0.126816
[Epoch 13; Iter     6/ 1097] train: loss: 0.0323530
[Epoch 13; Iter    36/ 1097] train: loss: 0.2662985
[Epoch 13; Iter    66/ 1097] train: loss: 0.1519284
[Epoch 13; Iter    96/ 1097] train: loss: 0.0660462
[Epoch 13; Iter   126/ 1097] train: loss: 0.0238777
[Epoch 13; Iter   156/ 1097] train: loss: 0.0225518
[Epoch 13; Iter   186/ 1097] train: loss: 0.1931564
[Epoch 13; Iter   216/ 1097] train: loss: 0.1834909
[Epoch 13; Iter   246/ 1097] train: loss: 0.0259534
[Epoch 13; Iter   276/ 1097] train: loss: 0.0869797
[Epoch 13; Iter   306/ 1097] train: loss: 0.0210993
[Epoch 13; Iter   336/ 1097] train: loss: 0.1362176
[Epoch 13; Iter   366/ 1097] train: loss: 0.1469733
[Epoch 13; Iter   396/ 1097] train: loss: 0.1503223
[Epoch 13; Iter   426/ 1097] train: loss: 0.0462792
[Epoch 13; Iter   456/ 1097] train: loss: 0.0523000
[Epoch 13; Iter   486/ 1097] train: loss: 0.0648877
[Epoch 13; Iter   516/ 1097] train: loss: 0.0286528
[Epoch 13; Iter   546/ 1097] train: loss: 0.0245860
[Epoch 13; Iter   576/ 1097] train: loss: 0.2069490
[Epoch 13; Iter   606/ 1097] train: loss: 0.0727596
[Epoch 13; Iter   636/ 1097] train: loss: 0.2882788
[Epoch 13; Iter   666/ 1097] train: loss: 0.0223179
[Epoch 13; Iter   696/ 1097] train: loss: 0.0285919
[Epoch 13; Iter   726/ 1097] train: loss: 0.0550182
[Epoch 13; Iter   756/ 1097] train: loss: 0.0571426
[Epoch 13; Iter   786/ 1097] train: loss: 0.1907869
[Epoch 13; Iter   816/ 1097] train: loss: 0.0252800
[Epoch 13; Iter   846/ 1097] train: loss: 0.0179501
[Epoch 13; Iter   876/ 1097] train: loss: 0.2171511
[Epoch 13; Iter   906/ 1097] train: loss: 0.2616194
[Epoch 13; Iter   936/ 1097] train: loss: 0.1896343
[Epoch 13; Iter   966/ 1097] train: loss: 0.1281037
[Epoch 13; Iter   996/ 1097] train: loss: 0.1254704
[Epoch 13; Iter  1026/ 1097] train: loss: 0.3260520
[Epoch 13; Iter  1056/ 1097] train: loss: 0.2124580
[Epoch 13; Iter  1086/ 1097] train: loss: 0.1511692
[Epoch 13] ogbg-molhiv: 0.789214 val loss: 0.075752
[Epoch 13] ogbg-molhiv: 0.755996 test loss: 0.114294
[Epoch 14; Iter    19/ 1097] train: loss: 0.0393059
[Epoch 14; Iter    49/ 1097] train: loss: 0.2922467
[Epoch 14; Iter    79/ 1097] train: loss: 0.0316743
[Epoch 14; Iter   109/ 1097] train: loss: 0.0253224
[Epoch 14; Iter   139/ 1097] train: loss: 0.1110432
[Epoch 14; Iter   169/ 1097] train: loss: 0.1356327
[Epoch 14; Iter   199/ 1097] train: loss: 0.0711498
[Epoch 14; Iter   229/ 1097] train: loss: 0.0244768
[Epoch 14; Iter   259/ 1097] train: loss: 0.0547126
[Epoch 14; Iter   289/ 1097] train: loss: 0.0626355
[Epoch 14; Iter   319/ 1097] train: loss: 0.2700351
[Epoch 14; Iter   349/ 1097] train: loss: 0.1809886
[Epoch 14; Iter   379/ 1097] train: loss: 0.1534703
[Epoch 14; Iter   409/ 1097] train: loss: 0.0995839
[Epoch 14; Iter   439/ 1097] train: loss: 0.1552857
[Epoch 14; Iter   469/ 1097] train: loss: 0.1802693
[Epoch 14; Iter   499/ 1097] train: loss: 0.0212649
[Epoch 14; Iter   529/ 1097] train: loss: 0.0216694
[Epoch 14; Iter   559/ 1097] train: loss: 0.1964792
[Epoch 14; Iter   589/ 1097] train: loss: 0.0287423
[Epoch 14; Iter   619/ 1097] train: loss: 0.0428843
[Epoch 14; Iter   649/ 1097] train: loss: 0.0318983
[Epoch 14; Iter   679/ 1097] train: loss: 0.1356522
[Epoch 14; Iter   709/ 1097] train: loss: 0.1998633
[Epoch 14; Iter   739/ 1097] train: loss: 0.0511961
[Epoch 14; Iter   769/ 1097] train: loss: 0.1174506
[Epoch 14; Iter   799/ 1097] train: loss: 0.0539313
[Epoch 14; Iter   829/ 1097] train: loss: 0.0702481
[Epoch 14; Iter   859/ 1097] train: loss: 0.0345807
[Epoch 14; Iter   889/ 1097] train: loss: 0.0277186
[Epoch 14; Iter   919/ 1097] train: loss: 0.0483559
[Epoch 14; Iter   949/ 1097] train: loss: 0.0387508
[Epoch 14; Iter   979/ 1097] train: loss: 0.1709920
[Epoch 14; Iter  1009/ 1097] train: loss: 0.0228538
[Epoch 14; Iter  1039/ 1097] train: loss: 0.0327027
[Epoch 14; Iter  1069/ 1097] train: loss: 0.1320273
[Epoch 14] ogbg-molhiv: 0.782729 val loss: 0.086863
[Epoch 14] ogbg-molhiv: 0.716549 test loss: 0.129087
[Epoch 15; Iter     2/ 1097] train: loss: 0.1725111
[Epoch 15; Iter    32/ 1097] train: loss: 0.0309485
[Epoch 15; Iter    62/ 1097] train: loss: 0.1934611
[Epoch 15; Iter    92/ 1097] train: loss: 0.0253368
[Epoch 15; Iter   122/ 1097] train: loss: 0.1826391
[Epoch 15; Iter   152/ 1097] train: loss: 0.2213352
[Epoch 15; Iter   182/ 1097] train: loss: 0.1955640
[Epoch 15; Iter   212/ 1097] train: loss: 0.0253233
[Epoch 15; Iter   242/ 1097] train: loss: 0.0433426
[Epoch 15; Iter   272/ 1097] train: loss: 0.1506364
[Epoch 15; Iter   302/ 1097] train: loss: 0.1360622
[Epoch 15; Iter   332/ 1097] train: loss: 0.0213783
[Epoch 15; Iter   362/ 1097] train: loss: 0.0546616
[Epoch 15; Iter   392/ 1097] train: loss: 0.1665388
[Epoch 15; Iter   422/ 1097] train: loss: 0.1905185
[Epoch 15; Iter   452/ 1097] train: loss: 0.0754537
[Epoch 15; Iter   482/ 1097] train: loss: 0.1279087
[Epoch 15; Iter   512/ 1097] train: loss: 0.2415869
[Epoch 15; Iter   542/ 1097] train: loss: 0.0615660
[Epoch 15; Iter   572/ 1097] train: loss: 0.0239990
[Epoch 15; Iter   602/ 1097] train: loss: 0.3522414
[Epoch 15; Iter   632/ 1097] train: loss: 0.0261148
[Epoch 15; Iter   662/ 1097] train: loss: 0.1585694
[Epoch 15; Iter   692/ 1097] train: loss: 0.0233887
[Epoch 15; Iter   722/ 1097] train: loss: 0.0821074
[Epoch 15; Iter   752/ 1097] train: loss: 0.2168119
[Epoch 15; Iter   782/ 1097] train: loss: 0.1882240
[Epoch 15; Iter   812/ 1097] train: loss: 0.2238752
[Epoch 15; Iter   842/ 1097] train: loss: 0.0223861
[Epoch 15; Iter   872/ 1097] train: loss: 0.0271212
[Epoch 15; Iter   902/ 1097] train: loss: 0.2316387
[Epoch 15; Iter   932/ 1097] train: loss: 0.0813338
[Epoch 15; Iter   962/ 1097] train: loss: 0.0354338
[Epoch 15; Iter   992/ 1097] train: loss: 0.0383225
[Epoch 15; Iter  1022/ 1097] train: loss: 0.0189922
[Epoch 15; Iter  1052/ 1097] train: loss: 0.0739404
[Epoch 15; Iter  1082/ 1097] train: loss: 0.0244759
[Epoch 15] ogbg-molhiv: 0.776718 val loss: 0.075191
[Epoch 15] ogbg-molhiv: 0.731333 test loss: 0.114418
[Epoch 16; Iter    15/ 1097] train: loss: 0.0457308
[Epoch 16; Iter    45/ 1097] train: loss: 0.0411789
[Epoch 16; Iter    75/ 1097] train: loss: 0.0176926
[Epoch 16; Iter   105/ 1097] train: loss: 0.0248179
[Epoch 16; Iter   135/ 1097] train: loss: 0.0310198
[Epoch 16; Iter   165/ 1097] train: loss: 0.2958682
[Epoch 16; Iter   195/ 1097] train: loss: 0.1045759
[Epoch 13; Iter   630/  960] train: loss: 0.0476069
[Epoch 13; Iter   660/  960] train: loss: 0.0302016
[Epoch 13; Iter   690/  960] train: loss: 0.0697869
[Epoch 13; Iter   720/  960] train: loss: 0.0390774
[Epoch 13; Iter   750/  960] train: loss: 0.2071705
[Epoch 13; Iter   780/  960] train: loss: 0.1261869
[Epoch 13; Iter   810/  960] train: loss: 0.1747883
[Epoch 13; Iter   840/  960] train: loss: 0.1724658
[Epoch 13; Iter   870/  960] train: loss: 0.1875331
[Epoch 13; Iter   900/  960] train: loss: 0.1532742
[Epoch 13; Iter   930/  960] train: loss: 0.1312153
[Epoch 13; Iter   960/  960] train: loss: 0.0497440
[Epoch 13] ogbg-molhiv: 0.718251 val loss: 0.617211
[Epoch 13] ogbg-molhiv: 0.744379 test loss: 1.180857
[Epoch 14; Iter    30/  960] train: loss: 0.2241990
[Epoch 14; Iter    60/  960] train: loss: 0.3215220
[Epoch 14; Iter    90/  960] train: loss: 0.1290128
[Epoch 14; Iter   120/  960] train: loss: 0.0228564
[Epoch 14; Iter   150/  960] train: loss: 0.0657140
[Epoch 14; Iter   180/  960] train: loss: 0.0646042
[Epoch 14; Iter   210/  960] train: loss: 0.1159452
[Epoch 14; Iter   240/  960] train: loss: 0.0321602
[Epoch 14; Iter   270/  960] train: loss: 0.1353522
[Epoch 14; Iter   300/  960] train: loss: 0.1934400
[Epoch 14; Iter   330/  960] train: loss: 0.0326206
[Epoch 14; Iter   360/  960] train: loss: 0.0188683
[Epoch 14; Iter   390/  960] train: loss: 0.1100577
[Epoch 14; Iter   420/  960] train: loss: 0.0240261
[Epoch 14; Iter   450/  960] train: loss: 0.0239840
[Epoch 14; Iter   480/  960] train: loss: 0.1487335
[Epoch 14; Iter   510/  960] train: loss: 0.0212586
[Epoch 14; Iter   540/  960] train: loss: 0.1679118
[Epoch 14; Iter   570/  960] train: loss: 0.1142741
[Epoch 14; Iter   600/  960] train: loss: 0.1158292
[Epoch 14; Iter   630/  960] train: loss: 0.1836185
[Epoch 14; Iter   660/  960] train: loss: 0.0681635
[Epoch 14; Iter   690/  960] train: loss: 0.1677940
[Epoch 14; Iter   720/  960] train: loss: 0.0205358
[Epoch 14; Iter   750/  960] train: loss: 0.0271318
[Epoch 14; Iter   780/  960] train: loss: 0.3046252
[Epoch 14; Iter   810/  960] train: loss: 0.1448925
[Epoch 14; Iter   840/  960] train: loss: 0.1847095
[Epoch 14; Iter   870/  960] train: loss: 0.3553521
[Epoch 14; Iter   900/  960] train: loss: 0.2665431
[Epoch 14; Iter   930/  960] train: loss: 0.1048868
[Epoch 14; Iter   960/  960] train: loss: 0.0374848
[Epoch 14] ogbg-molhiv: 0.736020 val loss: 0.143265
[Epoch 14] ogbg-molhiv: 0.727211 test loss: 0.262927
[Epoch 15; Iter    30/  960] train: loss: 0.2520717
[Epoch 15; Iter    60/  960] train: loss: 0.0254812
[Epoch 15; Iter    90/  960] train: loss: 0.1627186
[Epoch 15; Iter   120/  960] train: loss: 0.0622752
[Epoch 15; Iter   150/  960] train: loss: 0.2086429
[Epoch 15; Iter   180/  960] train: loss: 0.1839520
[Epoch 15; Iter   210/  960] train: loss: 0.0276022
[Epoch 15; Iter   240/  960] train: loss: 0.0256055
[Epoch 15; Iter   270/  960] train: loss: 0.0214437
[Epoch 15; Iter   300/  960] train: loss: 0.3464652
[Epoch 15; Iter   330/  960] train: loss: 0.0716598
[Epoch 15; Iter   360/  960] train: loss: 0.0315429
[Epoch 15; Iter   390/  960] train: loss: 0.3710768
[Epoch 15; Iter   420/  960] train: loss: 0.0594045
[Epoch 15; Iter   450/  960] train: loss: 0.2431413
[Epoch 15; Iter   480/  960] train: loss: 0.0276492
[Epoch 15; Iter   510/  960] train: loss: 0.0206945
[Epoch 15; Iter   540/  960] train: loss: 0.0281384
[Epoch 15; Iter   570/  960] train: loss: 0.0223696
[Epoch 15; Iter   600/  960] train: loss: 0.1973159
[Epoch 15; Iter   630/  960] train: loss: 0.1169828
[Epoch 15; Iter   660/  960] train: loss: 0.1828484
[Epoch 15; Iter   690/  960] train: loss: 0.1848035
[Epoch 15; Iter   720/  960] train: loss: 0.0255725
[Epoch 15; Iter   750/  960] train: loss: 0.0377453
[Epoch 15; Iter   780/  960] train: loss: 0.1215550
[Epoch 15; Iter   810/  960] train: loss: 0.1306633
[Epoch 15; Iter   840/  960] train: loss: 0.1761148
[Epoch 15; Iter   870/  960] train: loss: 0.0359233
[Epoch 15; Iter   900/  960] train: loss: 0.1941708
[Epoch 15; Iter   930/  960] train: loss: 0.0589954
[Epoch 15; Iter   960/  960] train: loss: 0.1148947
[Epoch 15] ogbg-molhiv: 0.749064 val loss: 0.145804
[Epoch 15] ogbg-molhiv: 0.739999 test loss: 0.109484
[Epoch 16; Iter    30/  960] train: loss: 0.1525088
[Epoch 16; Iter    60/  960] train: loss: 0.0270462
[Epoch 16; Iter    90/  960] train: loss: 0.4632404
[Epoch 16; Iter   120/  960] train: loss: 0.5168157
[Epoch 16; Iter   150/  960] train: loss: 0.0290987
[Epoch 16; Iter   180/  960] train: loss: 0.0336017
[Epoch 16; Iter   210/  960] train: loss: 0.1687736
[Epoch 16; Iter   240/  960] train: loss: 0.2924644
[Epoch 16; Iter   270/  960] train: loss: 0.0392768
[Epoch 16; Iter   300/  960] train: loss: 0.1344249
[Epoch 16; Iter   330/  960] train: loss: 0.0935098
[Epoch 16; Iter   360/  960] train: loss: 0.0282823
[Epoch 16; Iter   390/  960] train: loss: 0.0393652
[Epoch 16; Iter   420/  960] train: loss: 0.1938733
[Epoch 16; Iter   450/  960] train: loss: 0.0612662
[Epoch 16; Iter   480/  960] train: loss: 0.0700381
[Epoch 16; Iter   510/  960] train: loss: 0.1356602
[Epoch 16; Iter   540/  960] train: loss: 0.1037370
[Epoch 16; Iter   570/  960] train: loss: 0.0431310
[Epoch 16; Iter   600/  960] train: loss: 0.1069544
[Epoch 16; Iter   630/  960] train: loss: 0.2976749
[Epoch 16; Iter   660/  960] train: loss: 0.0225844
[Epoch 16; Iter   690/  960] train: loss: 0.0794449
[Epoch 16; Iter   720/  960] train: loss: 0.0270253
[Epoch 16; Iter   750/  960] train: loss: 0.0488420
[Epoch 16; Iter   780/  960] train: loss: 0.0225688
[Epoch 16; Iter   810/  960] train: loss: 0.1238366
[Epoch 16; Iter   840/  960] train: loss: 0.0677649
[Epoch 16; Iter   870/  960] train: loss: 0.1280369
[Epoch 16; Iter   900/  960] train: loss: 0.0725263
[Epoch 16; Iter   930/  960] train: loss: 0.2364835
[Epoch 16; Iter   960/  960] train: loss: 0.0973329
[Epoch 16] ogbg-molhiv: 0.763045 val loss: 0.117409
[Epoch 16] ogbg-molhiv: 0.754888 test loss: 0.109308
[Epoch 17; Iter    30/  960] train: loss: 0.0410331
[Epoch 17; Iter    60/  960] train: loss: 0.1444833
[Epoch 17; Iter    90/  960] train: loss: 0.0566255
[Epoch 17; Iter   120/  960] train: loss: 0.0392854
[Epoch 17; Iter   150/  960] train: loss: 0.0309330
[Epoch 17; Iter   180/  960] train: loss: 0.1853964
[Epoch 17; Iter   210/  960] train: loss: 0.0442331
[Epoch 17; Iter   240/  960] train: loss: 0.0247319
[Epoch 17; Iter   270/  960] train: loss: 0.2230058
[Epoch 17; Iter   300/  960] train: loss: 0.1566123
[Epoch 17; Iter   330/  960] train: loss: 0.1336295
[Epoch 17; Iter   360/  960] train: loss: 0.0310584
[Epoch 17; Iter   390/  960] train: loss: 0.0557695
[Epoch 17; Iter   420/  960] train: loss: 0.0384916
[Epoch 17; Iter   450/  960] train: loss: 0.0472525
[Epoch 17; Iter   480/  960] train: loss: 0.1732390
[Epoch 17; Iter   510/  960] train: loss: 0.0415392
[Epoch 17; Iter   540/  960] train: loss: 0.0508137
[Epoch 17; Iter   570/  960] train: loss: 0.0262245
[Epoch 17; Iter   600/  960] train: loss: 0.2755551
[Epoch 17; Iter   630/  960] train: loss: 0.0810587
[Epoch 17; Iter   660/  960] train: loss: 0.1089445
[Epoch 17; Iter   690/  960] train: loss: 0.0326013
[Epoch 17; Iter   720/  960] train: loss: 0.0339762
[Epoch 17; Iter   750/  960] train: loss: 0.0825329
[Epoch 17; Iter   780/  960] train: loss: 0.1595265
[Epoch 17; Iter   810/  960] train: loss: 0.0258023
[Epoch 17; Iter   840/  960] train: loss: 0.0333792
[Epoch 17; Iter   870/  960] train: loss: 0.0211005
[Epoch 17; Iter   900/  960] train: loss: 0.1029572
[Epoch 17; Iter   930/  960] train: loss: 0.0754382
[Epoch 17; Iter   960/  960] train: loss: 0.0608237
[Epoch 17] ogbg-molhiv: 0.731021 val loss: 0.121226
[Epoch 17] ogbg-molhiv: 0.744361 test loss: 0.101827
[Epoch 18; Iter    30/  960] train: loss: 0.0604906
[Epoch 18; Iter    60/  960] train: loss: 0.1910758
[Epoch 18; Iter    90/  960] train: loss: 0.0423272
[Epoch 18; Iter   120/  960] train: loss: 0.0880607
[Epoch 18; Iter   150/  960] train: loss: 0.0285046
[Epoch 18; Iter   180/  960] train: loss: 0.0272650
[Epoch 18; Iter   210/  960] train: loss: 0.1000529
[Epoch 13; Iter   630/  960] train: loss: 0.3809473
[Epoch 13; Iter   660/  960] train: loss: 0.0262453
[Epoch 13; Iter   690/  960] train: loss: 0.0437190
[Epoch 13; Iter   720/  960] train: loss: 0.0295896
[Epoch 13; Iter   750/  960] train: loss: 0.1360799
[Epoch 13; Iter   780/  960] train: loss: 0.1159057
[Epoch 13; Iter   810/  960] train: loss: 0.0331182
[Epoch 13; Iter   840/  960] train: loss: 0.0500777
[Epoch 13; Iter   870/  960] train: loss: 0.1081666
[Epoch 13; Iter   900/  960] train: loss: 0.1415465
[Epoch 13; Iter   930/  960] train: loss: 0.0730795
[Epoch 13; Iter   960/  960] train: loss: 0.0322925
[Epoch 13] ogbg-molhiv: 0.763063 val loss: 0.122048
[Epoch 13] ogbg-molhiv: 0.743291 test loss: 0.110002
[Epoch 14; Iter    30/  960] train: loss: 0.2698806
[Epoch 14; Iter    60/  960] train: loss: 0.1902276
[Epoch 14; Iter    90/  960] train: loss: 0.0324004
[Epoch 14; Iter   120/  960] train: loss: 0.0338396
[Epoch 14; Iter   150/  960] train: loss: 0.0338886
[Epoch 14; Iter   180/  960] train: loss: 0.3077363
[Epoch 14; Iter   210/  960] train: loss: 0.1560022
[Epoch 14; Iter   240/  960] train: loss: 0.1264594
[Epoch 14; Iter   270/  960] train: loss: 0.1017345
[Epoch 14; Iter   300/  960] train: loss: 0.2602724
[Epoch 14; Iter   330/  960] train: loss: 0.3356271
[Epoch 14; Iter   360/  960] train: loss: 0.2078944
[Epoch 14; Iter   390/  960] train: loss: 0.1434539
[Epoch 14; Iter   420/  960] train: loss: 0.2803750
[Epoch 14; Iter   450/  960] train: loss: 0.0933877
[Epoch 14; Iter   480/  960] train: loss: 0.1243634
[Epoch 14; Iter   510/  960] train: loss: 0.0286841
[Epoch 14; Iter   540/  960] train: loss: 0.3015532
[Epoch 14; Iter   570/  960] train: loss: 0.0314330
[Epoch 14; Iter   600/  960] train: loss: 0.0433046
[Epoch 14; Iter   630/  960] train: loss: 0.1551579
[Epoch 14; Iter   660/  960] train: loss: 0.1291729
[Epoch 14; Iter   690/  960] train: loss: 0.1440464
[Epoch 14; Iter   720/  960] train: loss: 0.0232770
[Epoch 14; Iter   750/  960] train: loss: 0.0578885
[Epoch 14; Iter   780/  960] train: loss: 0.0478951
[Epoch 14; Iter   810/  960] train: loss: 0.1722167
[Epoch 14; Iter   840/  960] train: loss: 0.1632492
[Epoch 14; Iter   870/  960] train: loss: 0.1296689
[Epoch 14; Iter   900/  960] train: loss: 0.0311697
[Epoch 14; Iter   930/  960] train: loss: 0.1442140
[Epoch 14; Iter   960/  960] train: loss: 0.1207498
[Epoch 14] ogbg-molhiv: 0.770228 val loss: 0.117014
[Epoch 14] ogbg-molhiv: 0.735011 test loss: 0.105984
[Epoch 15; Iter    30/  960] train: loss: 0.1834155
[Epoch 15; Iter    60/  960] train: loss: 0.1676117
[Epoch 15; Iter    90/  960] train: loss: 0.0383989
[Epoch 15; Iter   120/  960] train: loss: 0.0447343
[Epoch 15; Iter   150/  960] train: loss: 0.1487444
[Epoch 15; Iter   180/  960] train: loss: 0.0568841
[Epoch 15; Iter   210/  960] train: loss: 0.0257241
[Epoch 15; Iter   240/  960] train: loss: 0.1681384
[Epoch 15; Iter   270/  960] train: loss: 0.0754842
[Epoch 15; Iter   300/  960] train: loss: 0.0231696
[Epoch 15; Iter   330/  960] train: loss: 0.0930267
[Epoch 15; Iter   360/  960] train: loss: 0.0243429
[Epoch 15; Iter   390/  960] train: loss: 0.1679968
[Epoch 15; Iter   420/  960] train: loss: 0.0488680
[Epoch 15; Iter   450/  960] train: loss: 0.2428479
[Epoch 15; Iter   480/  960] train: loss: 0.0192901
[Epoch 15; Iter   510/  960] train: loss: 0.1206336
[Epoch 15; Iter   540/  960] train: loss: 0.0580802
[Epoch 15; Iter   570/  960] train: loss: 0.1320762
[Epoch 15; Iter   600/  960] train: loss: 0.0543292
[Epoch 15; Iter   630/  960] train: loss: 0.1927242
[Epoch 15; Iter   660/  960] train: loss: 0.2710107
[Epoch 15; Iter   690/  960] train: loss: 0.0692844
[Epoch 15; Iter   720/  960] train: loss: 0.0911610
[Epoch 15; Iter   750/  960] train: loss: 0.1743114
[Epoch 15; Iter   780/  960] train: loss: 0.1742054
[Epoch 15; Iter   810/  960] train: loss: 0.0593185
[Epoch 15; Iter   840/  960] train: loss: 0.0296607
[Epoch 15; Iter   870/  960] train: loss: 0.2017983
[Epoch 15; Iter   900/  960] train: loss: 0.2403531
[Epoch 15; Iter   930/  960] train: loss: 0.1543192
[Epoch 15; Iter   960/  960] train: loss: 0.0224967
[Epoch 15] ogbg-molhiv: 0.765662 val loss: 0.203246
[Epoch 15] ogbg-molhiv: 0.762900 test loss: 0.113478
[Epoch 16; Iter    30/  960] train: loss: 0.0248989
[Epoch 16; Iter    60/  960] train: loss: 0.1403213
[Epoch 16; Iter    90/  960] train: loss: 0.0951824
[Epoch 16; Iter   120/  960] train: loss: 0.1836820
[Epoch 16; Iter   150/  960] train: loss: 0.0293217
[Epoch 16; Iter   180/  960] train: loss: 0.2091142
[Epoch 16; Iter   210/  960] train: loss: 0.1847389
[Epoch 16; Iter   240/  960] train: loss: 0.2808892
[Epoch 16; Iter   270/  960] train: loss: 0.0254209
[Epoch 16; Iter   300/  960] train: loss: 0.1533519
[Epoch 16; Iter   330/  960] train: loss: 0.1106318
[Epoch 16; Iter   360/  960] train: loss: 0.2385323
[Epoch 16; Iter   390/  960] train: loss: 0.0911383
[Epoch 16; Iter   420/  960] train: loss: 0.0579709
[Epoch 16; Iter   450/  960] train: loss: 0.0201673
[Epoch 16; Iter   480/  960] train: loss: 0.1191753
[Epoch 16; Iter   510/  960] train: loss: 0.1317955
[Epoch 16; Iter   540/  960] train: loss: 0.1772770
[Epoch 16; Iter   570/  960] train: loss: 0.0476026
[Epoch 16; Iter   600/  960] train: loss: 0.3033610
[Epoch 16; Iter   630/  960] train: loss: 0.0874701
[Epoch 16; Iter   660/  960] train: loss: 0.0419144
[Epoch 16; Iter   690/  960] train: loss: 0.0221495
[Epoch 16; Iter   720/  960] train: loss: 0.0303824
[Epoch 16; Iter   750/  960] train: loss: 0.0806629
[Epoch 16; Iter   780/  960] train: loss: 0.1292656
[Epoch 16; Iter   810/  960] train: loss: 0.0618036
[Epoch 16; Iter   840/  960] train: loss: 0.0230578
[Epoch 16; Iter   870/  960] train: loss: 0.1065163
[Epoch 16; Iter   900/  960] train: loss: 0.0208256
[Epoch 16; Iter   930/  960] train: loss: 0.1423017
[Epoch 16; Iter   960/  960] train: loss: 0.0385863
[Epoch 16] ogbg-molhiv: 0.767155 val loss: 0.223747
[Epoch 16] ogbg-molhiv: 0.738999 test loss: 0.136447
[Epoch 17; Iter    30/  960] train: loss: 0.2623384
[Epoch 17; Iter    60/  960] train: loss: 0.1663537
[Epoch 17; Iter    90/  960] train: loss: 0.0841797
[Epoch 17; Iter   120/  960] train: loss: 0.1847718
[Epoch 17; Iter   150/  960] train: loss: 0.0882616
[Epoch 17; Iter   180/  960] train: loss: 0.0228963
[Epoch 17; Iter   210/  960] train: loss: 0.1358231
[Epoch 17; Iter   240/  960] train: loss: 0.0561030
[Epoch 17; Iter   270/  960] train: loss: 0.0236513
[Epoch 17; Iter   300/  960] train: loss: 0.0324643
[Epoch 17; Iter   330/  960] train: loss: 0.1725407
[Epoch 17; Iter   360/  960] train: loss: 0.0939978
[Epoch 17; Iter   390/  960] train: loss: 0.0261517
[Epoch 17; Iter   420/  960] train: loss: 0.0557458
[Epoch 17; Iter   450/  960] train: loss: 0.1148406
[Epoch 17; Iter   480/  960] train: loss: 0.0261122
[Epoch 17; Iter   510/  960] train: loss: 0.1766560
[Epoch 17; Iter   540/  960] train: loss: 0.0339161
[Epoch 17; Iter   570/  960] train: loss: 0.0631963
[Epoch 17; Iter   600/  960] train: loss: 0.2889881
[Epoch 17; Iter   630/  960] train: loss: 0.0724260
[Epoch 17; Iter   660/  960] train: loss: 0.0612418
[Epoch 17; Iter   690/  960] train: loss: 0.2418626
[Epoch 17; Iter   720/  960] train: loss: 0.1577174
[Epoch 17; Iter   750/  960] train: loss: 0.1077244
[Epoch 17; Iter   780/  960] train: loss: 0.2026177
[Epoch 17; Iter   810/  960] train: loss: 0.1651885
[Epoch 17; Iter   840/  960] train: loss: 0.0271339
[Epoch 17; Iter   870/  960] train: loss: 0.0878828
[Epoch 17; Iter   900/  960] train: loss: 0.2572480
[Epoch 17; Iter   930/  960] train: loss: 0.0323028
[Epoch 17; Iter   960/  960] train: loss: 0.0262432
[Epoch 17] ogbg-molhiv: 0.769195 val loss: 4.423333
[Epoch 17] ogbg-molhiv: 0.759940 test loss: 0.649230
[Epoch 18; Iter    30/  960] train: loss: 0.0219525
[Epoch 18; Iter    60/  960] train: loss: 0.1120359
[Epoch 18; Iter    90/  960] train: loss: 0.0985445
[Epoch 18; Iter   120/  960] train: loss: 0.1665593
[Epoch 18; Iter   150/  960] train: loss: 0.0289653
[Epoch 18; Iter   180/  960] train: loss: 0.0266900
[Epoch 18; Iter   210/  960] train: loss: 0.4200478
[Epoch 13; Iter   630/  960] train: loss: 0.1341058
[Epoch 13; Iter   660/  960] train: loss: 0.1675841
[Epoch 13; Iter   690/  960] train: loss: 0.2740282
[Epoch 13; Iter   720/  960] train: loss: 0.1795104
[Epoch 13; Iter   750/  960] train: loss: 0.0452686
[Epoch 13; Iter   780/  960] train: loss: 0.1119051
[Epoch 13; Iter   810/  960] train: loss: 0.0331897
[Epoch 13; Iter   840/  960] train: loss: 0.1708309
[Epoch 13; Iter   870/  960] train: loss: 0.1213391
[Epoch 13; Iter   900/  960] train: loss: 0.0240751
[Epoch 13; Iter   930/  960] train: loss: 0.0995287
[Epoch 13; Iter   960/  960] train: loss: 0.0242731
[Epoch 13] ogbg-molhiv: 0.745528 val loss: 0.117382
[Epoch 13] ogbg-molhiv: 0.737844 test loss: 0.103868
[Epoch 14; Iter    30/  960] train: loss: 0.1066372
[Epoch 14; Iter    60/  960] train: loss: 0.0602716
[Epoch 14; Iter    90/  960] train: loss: 0.0238782
[Epoch 14; Iter   120/  960] train: loss: 0.1343376
[Epoch 14; Iter   150/  960] train: loss: 0.2597126
[Epoch 14; Iter   180/  960] train: loss: 0.2336107
[Epoch 14; Iter   210/  960] train: loss: 0.2990193
[Epoch 14; Iter   240/  960] train: loss: 0.2130370
[Epoch 14; Iter   270/  960] train: loss: 0.2717370
[Epoch 14; Iter   300/  960] train: loss: 0.1600262
[Epoch 14; Iter   330/  960] train: loss: 0.1497589
[Epoch 14; Iter   360/  960] train: loss: 0.3162886
[Epoch 14; Iter   390/  960] train: loss: 0.0661277
[Epoch 14; Iter   420/  960] train: loss: 0.1001250
[Epoch 14; Iter   450/  960] train: loss: 0.0309706
[Epoch 14; Iter   480/  960] train: loss: 0.1367031
[Epoch 14; Iter   510/  960] train: loss: 0.0288670
[Epoch 14; Iter   540/  960] train: loss: 0.1505811
[Epoch 14; Iter   570/  960] train: loss: 0.2062339
[Epoch 14; Iter   600/  960] train: loss: 0.3002587
[Epoch 14; Iter   630/  960] train: loss: 0.2293744
[Epoch 14; Iter   660/  960] train: loss: 0.3040547
[Epoch 14; Iter   690/  960] train: loss: 0.2894248
[Epoch 14; Iter   720/  960] train: loss: 0.0245549
[Epoch 14; Iter   750/  960] train: loss: 0.1630203
[Epoch 14; Iter   780/  960] train: loss: 0.0368180
[Epoch 14; Iter   810/  960] train: loss: 0.0463648
[Epoch 14; Iter   840/  960] train: loss: 0.4846013
[Epoch 14; Iter   870/  960] train: loss: 0.0859062
[Epoch 14; Iter   900/  960] train: loss: 0.0667972
[Epoch 14; Iter   930/  960] train: loss: 0.1061372
[Epoch 14; Iter   960/  960] train: loss: 0.0323729
[Epoch 14] ogbg-molhiv: 0.753604 val loss: 0.231587
[Epoch 14] ogbg-molhiv: 0.735355 test loss: 0.173483
[Epoch 15; Iter    30/  960] train: loss: 0.2275858
[Epoch 15; Iter    60/  960] train: loss: 0.0312773
[Epoch 15; Iter    90/  960] train: loss: 0.0576486
[Epoch 15; Iter   120/  960] train: loss: 0.0299638
[Epoch 15; Iter   150/  960] train: loss: 0.0784149
[Epoch 15; Iter   180/  960] train: loss: 0.0326346
[Epoch 15; Iter   210/  960] train: loss: 0.0313500
[Epoch 15; Iter   240/  960] train: loss: 0.1022783
[Epoch 15; Iter   270/  960] train: loss: 0.0313851
[Epoch 15; Iter   300/  960] train: loss: 0.0408019
[Epoch 15; Iter   330/  960] train: loss: 0.0629170
[Epoch 15; Iter   360/  960] train: loss: 0.0375017
[Epoch 15; Iter   390/  960] train: loss: 0.0215000
[Epoch 15; Iter   420/  960] train: loss: 0.0272674
[Epoch 15; Iter   450/  960] train: loss: 0.0241425
[Epoch 15; Iter   480/  960] train: loss: 0.1954671
[Epoch 15; Iter   510/  960] train: loss: 0.0332852
[Epoch 15; Iter   540/  960] train: loss: 0.0875326
[Epoch 15; Iter   570/  960] train: loss: 0.1185560
[Epoch 15; Iter   600/  960] train: loss: 0.1952567
[Epoch 15; Iter   630/  960] train: loss: 0.2188448
[Epoch 15; Iter   660/  960] train: loss: 0.0218471
[Epoch 15; Iter   690/  960] train: loss: 0.1812984
[Epoch 15; Iter   720/  960] train: loss: 0.1916894
[Epoch 15; Iter   750/  960] train: loss: 0.2807322
[Epoch 15; Iter   780/  960] train: loss: 0.2901872
[Epoch 15; Iter   810/  960] train: loss: 0.1350582
[Epoch 15; Iter   840/  960] train: loss: 0.0469555
[Epoch 15; Iter   870/  960] train: loss: 0.1785210
[Epoch 15; Iter   900/  960] train: loss: 0.0264541
[Epoch 15; Iter   930/  960] train: loss: 0.1273684
[Epoch 15; Iter   960/  960] train: loss: 0.0619390
[Epoch 15] ogbg-molhiv: 0.758019 val loss: 0.118566
[Epoch 15] ogbg-molhiv: 0.750983 test loss: 0.101815
[Epoch 16; Iter    30/  960] train: loss: 0.0689077
[Epoch 16; Iter    60/  960] train: loss: 0.0687197
[Epoch 16; Iter    90/  960] train: loss: 0.0367524
[Epoch 16; Iter   120/  960] train: loss: 0.1393556
[Epoch 16; Iter   150/  960] train: loss: 0.1612378
[Epoch 16; Iter   180/  960] train: loss: 0.1009686
[Epoch 16; Iter   210/  960] train: loss: 0.2667950
[Epoch 16; Iter   240/  960] train: loss: 0.0324184
[Epoch 16; Iter   270/  960] train: loss: 0.0951637
[Epoch 16; Iter   300/  960] train: loss: 0.1661608
[Epoch 16; Iter   330/  960] train: loss: 0.1988345
[Epoch 16; Iter   360/  960] train: loss: 0.1138549
[Epoch 16; Iter   390/  960] train: loss: 0.0291431
[Epoch 16; Iter   420/  960] train: loss: 0.0251506
[Epoch 16; Iter   450/  960] train: loss: 0.0406616
[Epoch 16; Iter   480/  960] train: loss: 0.2916305
[Epoch 16; Iter   510/  960] train: loss: 0.1011498
[Epoch 16; Iter   540/  960] train: loss: 0.0275501
[Epoch 16; Iter   570/  960] train: loss: 0.1784198
[Epoch 16; Iter   600/  960] train: loss: 0.1739917
[Epoch 16; Iter   630/  960] train: loss: 0.0359249
[Epoch 16; Iter   660/  960] train: loss: 0.2400961
[Epoch 16; Iter   690/  960] train: loss: 0.0969771
[Epoch 16; Iter   720/  960] train: loss: 0.1646878
[Epoch 16; Iter   750/  960] train: loss: 0.0270301
[Epoch 16; Iter   780/  960] train: loss: 0.0296541
[Epoch 16; Iter   810/  960] train: loss: 0.0575783
[Epoch 16; Iter   840/  960] train: loss: 0.0488981
[Epoch 16; Iter   870/  960] train: loss: 0.0211429
[Epoch 16; Iter   900/  960] train: loss: 0.1867692
[Epoch 16; Iter   930/  960] train: loss: 0.0335855
[Epoch 16; Iter   960/  960] train: loss: 0.3112534
[Epoch 16] ogbg-molhiv: 0.728039 val loss: 0.120427
[Epoch 16] ogbg-molhiv: 0.728539 test loss: 0.106589
[Epoch 17; Iter    30/  960] train: loss: 0.0308285
[Epoch 17; Iter    60/  960] train: loss: 0.0991546
[Epoch 17; Iter    90/  960] train: loss: 0.1451836
[Epoch 17; Iter   120/  960] train: loss: 0.0766931
[Epoch 17; Iter   150/  960] train: loss: 0.1267816
[Epoch 17; Iter   180/  960] train: loss: 0.2029530
[Epoch 17; Iter   210/  960] train: loss: 0.0699214
[Epoch 17; Iter   240/  960] train: loss: 0.0272375
[Epoch 17; Iter   270/  960] train: loss: 0.1250191
[Epoch 17; Iter   300/  960] train: loss: 0.1171062
[Epoch 17; Iter   330/  960] train: loss: 0.0392934
[Epoch 17; Iter   360/  960] train: loss: 0.2955400
[Epoch 17; Iter   390/  960] train: loss: 0.1167584
[Epoch 17; Iter   420/  960] train: loss: 0.0208849
[Epoch 17; Iter   450/  960] train: loss: 0.0369153
[Epoch 17; Iter   480/  960] train: loss: 0.1003664
[Epoch 17; Iter   510/  960] train: loss: 0.1249730
[Epoch 17; Iter   540/  960] train: loss: 0.0455510
[Epoch 17; Iter   570/  960] train: loss: 0.0665634
[Epoch 17; Iter   600/  960] train: loss: 0.0318599
[Epoch 17; Iter   630/  960] train: loss: 0.0364051
[Epoch 17; Iter   660/  960] train: loss: 0.2024644
[Epoch 17; Iter   690/  960] train: loss: 0.1432332
[Epoch 17; Iter   720/  960] train: loss: 0.0273619
[Epoch 17; Iter   750/  960] train: loss: 0.2589678
[Epoch 17; Iter   780/  960] train: loss: 0.0473381
[Epoch 17; Iter   810/  960] train: loss: 0.1903930
[Epoch 17; Iter   840/  960] train: loss: 0.0450762
[Epoch 17; Iter   870/  960] train: loss: 0.2219944
[Epoch 17; Iter   900/  960] train: loss: 0.0228348
[Epoch 17; Iter   930/  960] train: loss: 0.0655316
[Epoch 17; Iter   960/  960] train: loss: 0.0746521
[Epoch 17] ogbg-molhiv: 0.743651 val loss: 0.115359
[Epoch 17] ogbg-molhiv: 0.741138 test loss: 0.097433
[Epoch 18; Iter    30/  960] train: loss: 0.0274595
[Epoch 18; Iter    60/  960] train: loss: 0.2424010
[Epoch 18; Iter    90/  960] train: loss: 0.0775860
[Epoch 18; Iter   120/  960] train: loss: 0.0260897
[Epoch 18; Iter   150/  960] train: loss: 0.0338506
[Epoch 18; Iter   180/  960] train: loss: 0.0322515
[Epoch 18; Iter   210/  960] train: loss: 0.0690980
[Epoch 15; Iter   478/  823] train: loss: 0.0798588
[Epoch 15; Iter   508/  823] train: loss: 0.1519500
[Epoch 15; Iter   538/  823] train: loss: 0.1096663
[Epoch 15; Iter   568/  823] train: loss: 0.3151578
[Epoch 15; Iter   598/  823] train: loss: 0.0357822
[Epoch 15; Iter   628/  823] train: loss: 0.1536655
[Epoch 15; Iter   658/  823] train: loss: 0.1472456
[Epoch 15; Iter   688/  823] train: loss: 0.1459688
[Epoch 15; Iter   718/  823] train: loss: 0.2939240
[Epoch 15; Iter   748/  823] train: loss: 0.0802251
[Epoch 15; Iter   778/  823] train: loss: 0.1832267
[Epoch 15; Iter   808/  823] train: loss: 0.2116926
[Epoch 15] ogbg-molhiv: 0.711410 val loss: 0.149166
[Epoch 15] ogbg-molhiv: 0.731582 test loss: 0.143245
[Epoch 16; Iter    15/  823] train: loss: 0.0455152
[Epoch 16; Iter    45/  823] train: loss: 0.1600455
[Epoch 16; Iter    75/  823] train: loss: 0.1252853
[Epoch 16; Iter   105/  823] train: loss: 0.1031079
[Epoch 16; Iter   135/  823] train: loss: 0.2835277
[Epoch 16; Iter   165/  823] train: loss: 0.5518131
[Epoch 16; Iter   195/  823] train: loss: 0.0497326
[Epoch 16; Iter   225/  823] train: loss: 0.0795192
[Epoch 16; Iter   255/  823] train: loss: 0.2090291
[Epoch 16; Iter   285/  823] train: loss: 0.0227029
[Epoch 16; Iter   315/  823] train: loss: 0.0403883
[Epoch 16; Iter   345/  823] train: loss: 0.0398484
[Epoch 16; Iter   375/  823] train: loss: 0.1094871
[Epoch 16; Iter   405/  823] train: loss: 0.0477787
[Epoch 16; Iter   435/  823] train: loss: 0.1968995
[Epoch 16; Iter   465/  823] train: loss: 0.3971991
[Epoch 16; Iter   495/  823] train: loss: 0.0256210
[Epoch 16; Iter   525/  823] train: loss: 0.0271805
[Epoch 16; Iter   555/  823] train: loss: 0.0337775
[Epoch 16; Iter   585/  823] train: loss: 0.2081178
[Epoch 16; Iter   615/  823] train: loss: 0.0239170
[Epoch 16; Iter   645/  823] train: loss: 0.1525129
[Epoch 16; Iter   675/  823] train: loss: 0.1876704
[Epoch 16; Iter   705/  823] train: loss: 0.0350611
[Epoch 16; Iter   735/  823] train: loss: 0.0803709
[Epoch 16; Iter   765/  823] train: loss: 0.1724088
[Epoch 16; Iter   795/  823] train: loss: 0.1472292
[Epoch 16] ogbg-molhiv: 0.699250 val loss: 0.169369
[Epoch 16] ogbg-molhiv: 0.729927 test loss: 0.266721
[Epoch 17; Iter     2/  823] train: loss: 0.1236264
[Epoch 17; Iter    32/  823] train: loss: 0.0852334
[Epoch 17; Iter    62/  823] train: loss: 0.1250188
[Epoch 17; Iter    92/  823] train: loss: 0.2156100
[Epoch 17; Iter   122/  823] train: loss: 0.3883052
[Epoch 17; Iter   152/  823] train: loss: 0.1946741
[Epoch 17; Iter   182/  823] train: loss: 0.0449869
[Epoch 17; Iter   212/  823] train: loss: 0.0542100
[Epoch 17; Iter   242/  823] train: loss: 0.3371124
[Epoch 17; Iter   272/  823] train: loss: 0.1421428
[Epoch 17; Iter   302/  823] train: loss: 0.0299060
[Epoch 17; Iter   332/  823] train: loss: 0.2222807
[Epoch 17; Iter   362/  823] train: loss: 0.0402316
[Epoch 17; Iter   392/  823] train: loss: 0.0221414
[Epoch 17; Iter   422/  823] train: loss: 0.1691103
[Epoch 17; Iter   452/  823] train: loss: 0.1577821
[Epoch 17; Iter   482/  823] train: loss: 0.0403982
[Epoch 17; Iter   512/  823] train: loss: 0.2869587
[Epoch 17; Iter   542/  823] train: loss: 0.1460104
[Epoch 17; Iter   572/  823] train: loss: 0.1405391
[Epoch 17; Iter   602/  823] train: loss: 0.1396633
[Epoch 17; Iter   632/  823] train: loss: 0.0436442
[Epoch 17; Iter   662/  823] train: loss: 0.0249708
[Epoch 17; Iter   692/  823] train: loss: 0.0313580
[Epoch 17; Iter   722/  823] train: loss: 0.3859362
[Epoch 17; Iter   752/  823] train: loss: 0.0258510
[Epoch 17; Iter   782/  823] train: loss: 0.0304049
[Epoch 17; Iter   812/  823] train: loss: 0.0427143
[Epoch 17] ogbg-molhiv: 0.724232 val loss: 0.149270
[Epoch 17] ogbg-molhiv: 0.732282 test loss: 0.327591
[Epoch 18; Iter    19/  823] train: loss: 0.2439516
[Epoch 18; Iter    49/  823] train: loss: 0.0474522
[Epoch 18; Iter    79/  823] train: loss: 0.0277525
[Epoch 18; Iter   109/  823] train: loss: 0.1025373
[Epoch 18; Iter   139/  823] train: loss: 0.4550593
[Epoch 18; Iter   169/  823] train: loss: 0.2105135
[Epoch 18; Iter   199/  823] train: loss: 0.1119498
[Epoch 18; Iter   229/  823] train: loss: 0.1225879
[Epoch 18; Iter   259/  823] train: loss: 0.0270792
[Epoch 18; Iter   289/  823] train: loss: 0.0579451
[Epoch 18; Iter   319/  823] train: loss: 0.1853154
[Epoch 18; Iter   349/  823] train: loss: 0.0288662
[Epoch 18; Iter   379/  823] train: loss: 0.1429446
[Epoch 18; Iter   409/  823] train: loss: 0.4362065
[Epoch 18; Iter   439/  823] train: loss: 0.2024028
[Epoch 18; Iter   469/  823] train: loss: 0.1572632
[Epoch 18; Iter   499/  823] train: loss: 0.1465624
[Epoch 18; Iter   529/  823] train: loss: 0.0664303
[Epoch 18; Iter   559/  823] train: loss: 0.1198550
[Epoch 18; Iter   589/  823] train: loss: 0.0353101
[Epoch 18; Iter   619/  823] train: loss: 0.0449899
[Epoch 18; Iter   649/  823] train: loss: 0.0314635
[Epoch 18; Iter   679/  823] train: loss: 0.0190812
[Epoch 18; Iter   709/  823] train: loss: 0.2501187
[Epoch 18; Iter   739/  823] train: loss: 0.2104495
[Epoch 18; Iter   769/  823] train: loss: 0.1230458
[Epoch 18; Iter   799/  823] train: loss: 0.0180387
[Epoch 18] ogbg-molhiv: 0.727407 val loss: 0.140043
[Epoch 18] ogbg-molhiv: 0.745450 test loss: 0.296041
[Epoch 19; Iter     6/  823] train: loss: 0.2254180
[Epoch 19; Iter    36/  823] train: loss: 0.0476938
[Epoch 19; Iter    66/  823] train: loss: 0.3366621
[Epoch 19; Iter    96/  823] train: loss: 0.0544297
[Epoch 19; Iter   126/  823] train: loss: 0.0556584
[Epoch 19; Iter   156/  823] train: loss: 0.3159828
[Epoch 19; Iter   186/  823] train: loss: 0.0299355
[Epoch 19; Iter   216/  823] train: loss: 0.0218344
[Epoch 19; Iter   246/  823] train: loss: 0.0405805
[Epoch 19; Iter   276/  823] train: loss: 0.1813022
[Epoch 19; Iter   306/  823] train: loss: 0.0274871
[Epoch 19; Iter   336/  823] train: loss: 0.0276148
[Epoch 19; Iter   366/  823] train: loss: 0.0824104
[Epoch 19; Iter   396/  823] train: loss: 0.1209085
[Epoch 19; Iter   426/  823] train: loss: 0.0404726
[Epoch 19; Iter   456/  823] train: loss: 0.0195740
[Epoch 19; Iter   486/  823] train: loss: 0.1148207
[Epoch 19; Iter   516/  823] train: loss: 0.0206472
[Epoch 19; Iter   546/  823] train: loss: 0.1180401
[Epoch 19; Iter   576/  823] train: loss: 0.1994351
[Epoch 19; Iter   606/  823] train: loss: 0.0751044
[Epoch 19; Iter   636/  823] train: loss: 0.0542152
[Epoch 19; Iter   666/  823] train: loss: 0.1334568
[Epoch 19; Iter   696/  823] train: loss: 0.2557316
[Epoch 19; Iter   726/  823] train: loss: 0.1860064
[Epoch 19; Iter   756/  823] train: loss: 0.0555593
[Epoch 19; Iter   786/  823] train: loss: 0.1379636
[Epoch 19; Iter   816/  823] train: loss: 0.2463817
[Epoch 19] ogbg-molhiv: 0.753246 val loss: 0.323214
[Epoch 19] ogbg-molhiv: 0.747130 test loss: 0.570288
[Epoch 20; Iter    23/  823] train: loss: 0.0190782
[Epoch 20; Iter    53/  823] train: loss: 0.1200738
[Epoch 20; Iter    83/  823] train: loss: 0.0322161
[Epoch 20; Iter   113/  823] train: loss: 0.0945199
[Epoch 20; Iter   143/  823] train: loss: 0.0386007
[Epoch 20; Iter   173/  823] train: loss: 0.0387201
[Epoch 20; Iter   203/  823] train: loss: 0.1444878
[Epoch 20; Iter   233/  823] train: loss: 0.0434832
[Epoch 20; Iter   263/  823] train: loss: 0.0455895
[Epoch 20; Iter   293/  823] train: loss: 0.1419134
[Epoch 20; Iter   323/  823] train: loss: 0.3252513
[Epoch 20; Iter   353/  823] train: loss: 0.0678630
[Epoch 20; Iter   383/  823] train: loss: 0.0221277
[Epoch 20; Iter   413/  823] train: loss: 0.1279483
[Epoch 20; Iter   443/  823] train: loss: 0.3485069
[Epoch 20; Iter   473/  823] train: loss: 0.0378026
[Epoch 20; Iter   503/  823] train: loss: 0.0281140
[Epoch 20; Iter   533/  823] train: loss: 0.0308454
[Epoch 20; Iter   563/  823] train: loss: 0.0220571
[Epoch 20; Iter   593/  823] train: loss: 0.0466478
[Epoch 20; Iter   623/  823] train: loss: 0.3866829
[Epoch 20; Iter   653/  823] train: loss: 0.0779511
[Epoch 20; Iter   683/  823] train: loss: 0.4204361
[Epoch 20; Iter   713/  823] train: loss: 0.0310385
[Epoch 20; Iter   743/  823] train: loss: 0.1738292
[Epoch 15; Iter   478/  823] train: loss: 0.0965550
[Epoch 15; Iter   508/  823] train: loss: 0.4851609
[Epoch 15; Iter   538/  823] train: loss: 0.0234707
[Epoch 15; Iter   568/  823] train: loss: 0.0647728
[Epoch 15; Iter   598/  823] train: loss: 0.0828049
[Epoch 15; Iter   628/  823] train: loss: 0.0586534
[Epoch 15; Iter   658/  823] train: loss: 0.0609411
[Epoch 15; Iter   688/  823] train: loss: 0.1743900
[Epoch 15; Iter   718/  823] train: loss: 0.0973687
[Epoch 15; Iter   748/  823] train: loss: 0.1077658
[Epoch 15; Iter   778/  823] train: loss: 0.0385777
[Epoch 15; Iter   808/  823] train: loss: 0.1134151
[Epoch 15] ogbg-molhiv: 0.707153 val loss: 0.144383
[Epoch 15] ogbg-molhiv: 0.719917 test loss: 0.187339
[Epoch 16; Iter    15/  823] train: loss: 0.0406036
[Epoch 16; Iter    45/  823] train: loss: 0.2006196
[Epoch 16; Iter    75/  823] train: loss: 0.0260997
[Epoch 16; Iter   105/  823] train: loss: 0.0500308
[Epoch 16; Iter   135/  823] train: loss: 0.0385386
[Epoch 16; Iter   165/  823] train: loss: 0.0507676
[Epoch 16; Iter   195/  823] train: loss: 0.0184664
[Epoch 16; Iter   225/  823] train: loss: 0.1247499
[Epoch 16; Iter   255/  823] train: loss: 0.0305502
[Epoch 16; Iter   285/  823] train: loss: 0.1057226
[Epoch 16; Iter   315/  823] train: loss: 0.0329232
[Epoch 16; Iter   345/  823] train: loss: 0.0468084
[Epoch 16; Iter   375/  823] train: loss: 0.1213617
[Epoch 16; Iter   405/  823] train: loss: 0.1068256
[Epoch 16; Iter   435/  823] train: loss: 0.0295707
[Epoch 16; Iter   465/  823] train: loss: 0.0547143
[Epoch 16; Iter   495/  823] train: loss: 0.2853925
[Epoch 16; Iter   525/  823] train: loss: 0.3353712
[Epoch 16; Iter   555/  823] train: loss: 0.0248012
[Epoch 16; Iter   585/  823] train: loss: 0.0271254
[Epoch 16; Iter   615/  823] train: loss: 0.1477749
[Epoch 16; Iter   645/  823] train: loss: 0.1212533
[Epoch 16; Iter   675/  823] train: loss: 0.3094022
[Epoch 16; Iter   705/  823] train: loss: 0.1570627
[Epoch 16; Iter   735/  823] train: loss: 0.0745963
[Epoch 16; Iter   765/  823] train: loss: 0.0461685
[Epoch 16; Iter   795/  823] train: loss: 0.2101850
[Epoch 16] ogbg-molhiv: 0.715000 val loss: 0.349858
[Epoch 16] ogbg-molhiv: 0.750515 test loss: 0.184613
[Epoch 17; Iter     2/  823] train: loss: 0.0455841
[Epoch 17; Iter    32/  823] train: loss: 0.0309638
[Epoch 17; Iter    62/  823] train: loss: 0.1934842
[Epoch 17; Iter    92/  823] train: loss: 0.0255084
[Epoch 17; Iter   122/  823] train: loss: 0.0156862
[Epoch 17; Iter   152/  823] train: loss: 0.0261361
[Epoch 17; Iter   182/  823] train: loss: 0.0220479
[Epoch 17; Iter   212/  823] train: loss: 0.0198945
[Epoch 17; Iter   242/  823] train: loss: 0.0421452
[Epoch 17; Iter   272/  823] train: loss: 0.1447240
[Epoch 17; Iter   302/  823] train: loss: 0.2672149
[Epoch 17; Iter   332/  823] train: loss: 0.0250388
[Epoch 17; Iter   362/  823] train: loss: 0.0297068
[Epoch 17; Iter   392/  823] train: loss: 0.0321658
[Epoch 17; Iter   422/  823] train: loss: 0.0244873
[Epoch 17; Iter   452/  823] train: loss: 0.0640457
[Epoch 17; Iter   482/  823] train: loss: 0.0237771
[Epoch 17; Iter   512/  823] train: loss: 0.1505311
[Epoch 17; Iter   542/  823] train: loss: 0.0420392
[Epoch 17; Iter   572/  823] train: loss: 0.0347794
[Epoch 17; Iter   602/  823] train: loss: 0.1632102
[Epoch 17; Iter   632/  823] train: loss: 0.2397305
[Epoch 17; Iter   662/  823] train: loss: 0.1754210
[Epoch 17; Iter   692/  823] train: loss: 0.2922438
[Epoch 17; Iter   722/  823] train: loss: 0.1441664
[Epoch 17; Iter   752/  823] train: loss: 0.0254593
[Epoch 17; Iter   782/  823] train: loss: 0.3193643
[Epoch 17; Iter   812/  823] train: loss: 0.0891543
[Epoch 17] ogbg-molhiv: 0.740564 val loss: 0.137567
[Epoch 17] ogbg-molhiv: 0.757719 test loss: 0.099137
[Epoch 18; Iter    19/  823] train: loss: 0.2989948
[Epoch 18; Iter    49/  823] train: loss: 0.2630998
[Epoch 18; Iter    79/  823] train: loss: 0.0346586
[Epoch 18; Iter   109/  823] train: loss: 0.1023890
[Epoch 18; Iter   139/  823] train: loss: 0.0595990
[Epoch 18; Iter   169/  823] train: loss: 0.0556619
[Epoch 18; Iter   199/  823] train: loss: 0.0259872
[Epoch 18; Iter   229/  823] train: loss: 0.0358017
[Epoch 18; Iter   259/  823] train: loss: 0.0234295
[Epoch 18; Iter   289/  823] train: loss: 0.2170328
[Epoch 18; Iter   319/  823] train: loss: 0.0285179
[Epoch 18; Iter   349/  823] train: loss: 0.0193108
[Epoch 18; Iter   379/  823] train: loss: 0.0283649
[Epoch 18; Iter   409/  823] train: loss: 0.0651409
[Epoch 18; Iter   439/  823] train: loss: 0.0215891
[Epoch 18; Iter   469/  823] train: loss: 0.0366027
[Epoch 18; Iter   499/  823] train: loss: 0.0235044
[Epoch 18; Iter   529/  823] train: loss: 0.1810021
[Epoch 18; Iter   559/  823] train: loss: 0.0664481
[Epoch 18; Iter   589/  823] train: loss: 0.0949340
[Epoch 18; Iter   619/  823] train: loss: 0.2053584
[Epoch 18; Iter   649/  823] train: loss: 0.1285808
[Epoch 18; Iter   679/  823] train: loss: 0.0262040
[Epoch 18; Iter   709/  823] train: loss: 0.0382540
[Epoch 18; Iter   739/  823] train: loss: 0.0216060
[Epoch 18; Iter   769/  823] train: loss: 0.0334888
[Epoch 18; Iter   799/  823] train: loss: 0.0353725
[Epoch 18] ogbg-molhiv: 0.726007 val loss: 0.147628
[Epoch 18] ogbg-molhiv: 0.756721 test loss: 0.156008
[Epoch 19; Iter     6/  823] train: loss: 0.0228199
[Epoch 19; Iter    36/  823] train: loss: 0.2670487
[Epoch 19; Iter    66/  823] train: loss: 0.0429087
[Epoch 19; Iter    96/  823] train: loss: 0.0279023
[Epoch 19; Iter   126/  823] train: loss: 0.1373850
[Epoch 19; Iter   156/  823] train: loss: 0.0295399
[Epoch 19; Iter   186/  823] train: loss: 0.2007909
[Epoch 19; Iter   216/  823] train: loss: 0.0590572
[Epoch 19; Iter   246/  823] train: loss: 0.3460003
[Epoch 19; Iter   276/  823] train: loss: 0.0436317
[Epoch 19; Iter   306/  823] train: loss: 0.0222895
[Epoch 19; Iter   336/  823] train: loss: 0.0184535
[Epoch 19; Iter   366/  823] train: loss: 0.0157551
[Epoch 19; Iter   396/  823] train: loss: 0.1848238
[Epoch 19; Iter   426/  823] train: loss: 0.1042509
[Epoch 19; Iter   456/  823] train: loss: 0.0654883
[Epoch 19; Iter   486/  823] train: loss: 0.0296622
[Epoch 19; Iter   516/  823] train: loss: 0.1119358
[Epoch 19; Iter   546/  823] train: loss: 0.1188197
[Epoch 19; Iter   576/  823] train: loss: 0.1283985
[Epoch 19; Iter   606/  823] train: loss: 0.0352384
[Epoch 19; Iter   636/  823] train: loss: 0.0216491
[Epoch 19; Iter   666/  823] train: loss: 0.0772605
[Epoch 19; Iter   696/  823] train: loss: 0.0547615
[Epoch 19; Iter   726/  823] train: loss: 0.1861550
[Epoch 19; Iter   756/  823] train: loss: 0.1255414
[Epoch 19; Iter   786/  823] train: loss: 0.0700821
[Epoch 19; Iter   816/  823] train: loss: 0.0233488
[Epoch 19] ogbg-molhiv: 0.723088 val loss: 0.160729
[Epoch 19] ogbg-molhiv: 0.761652 test loss: 0.105203
[Epoch 20; Iter    23/  823] train: loss: 0.1201529
[Epoch 20; Iter    53/  823] train: loss: 0.0692125
[Epoch 20; Iter    83/  823] train: loss: 0.0265527
[Epoch 20; Iter   113/  823] train: loss: 0.1055611
[Epoch 20; Iter   143/  823] train: loss: 0.0750263
[Epoch 20; Iter   173/  823] train: loss: 0.0328860
[Epoch 20; Iter   203/  823] train: loss: 0.2073068
[Epoch 20; Iter   233/  823] train: loss: 0.1378118
[Epoch 20; Iter   263/  823] train: loss: 0.2174520
[Epoch 20; Iter   293/  823] train: loss: 0.0575259
[Epoch 20; Iter   323/  823] train: loss: 0.0381019
[Epoch 20; Iter   353/  823] train: loss: 0.0473186
[Epoch 20; Iter   383/  823] train: loss: 0.0167728
[Epoch 20; Iter   413/  823] train: loss: 0.0612049
[Epoch 20; Iter   443/  823] train: loss: 0.1045290
[Epoch 20; Iter   473/  823] train: loss: 0.2615052
[Epoch 20; Iter   503/  823] train: loss: 0.1869292
[Epoch 20; Iter   533/  823] train: loss: 0.1463279
[Epoch 20; Iter   563/  823] train: loss: 0.0181595
[Epoch 20; Iter   593/  823] train: loss: 0.1664352
[Epoch 20; Iter   623/  823] train: loss: 0.0313180
[Epoch 20; Iter   653/  823] train: loss: 0.1543222
[Epoch 20; Iter   683/  823] train: loss: 0.0279637
[Epoch 20; Iter   713/  823] train: loss: 0.0284925
[Epoch 20; Iter   743/  823] train: loss: 0.0377242
[Epoch 15; Iter   478/  823] train: loss: 0.0433623
[Epoch 15; Iter   508/  823] train: loss: 0.0247020
[Epoch 15; Iter   538/  823] train: loss: 0.1364221
[Epoch 15; Iter   568/  823] train: loss: 0.0290095
[Epoch 15; Iter   598/  823] train: loss: 0.1350351
[Epoch 15; Iter   628/  823] train: loss: 0.0351257
[Epoch 15; Iter   658/  823] train: loss: 0.0239992
[Epoch 15; Iter   688/  823] train: loss: 0.0256763
[Epoch 15; Iter   718/  823] train: loss: 0.0753513
[Epoch 15; Iter   748/  823] train: loss: 0.0222605
[Epoch 15; Iter   778/  823] train: loss: 0.0445571
[Epoch 15; Iter   808/  823] train: loss: 0.0756835
[Epoch 15] ogbg-molhiv: 0.714357 val loss: 0.237521
[Epoch 15] ogbg-molhiv: 0.736091 test loss: 0.249831
[Epoch 16; Iter    15/  823] train: loss: 0.0329677
[Epoch 16; Iter    45/  823] train: loss: 0.0864395
[Epoch 16; Iter    75/  823] train: loss: 0.4934309
[Epoch 16; Iter   105/  823] train: loss: 0.0297568
[Epoch 16; Iter   135/  823] train: loss: 0.0923975
[Epoch 16; Iter   165/  823] train: loss: 0.1305179
[Epoch 16; Iter   195/  823] train: loss: 0.1401019
[Epoch 16; Iter   225/  823] train: loss: 0.0795719
[Epoch 16; Iter   255/  823] train: loss: 0.3073623
[Epoch 16; Iter   285/  823] train: loss: 0.2107749
[Epoch 16; Iter   315/  823] train: loss: 0.0311365
[Epoch 16; Iter   345/  823] train: loss: 0.0638988
[Epoch 16; Iter   375/  823] train: loss: 0.1810696
[Epoch 16; Iter   405/  823] train: loss: 0.0335809
[Epoch 16; Iter   435/  823] train: loss: 0.0939851
[Epoch 16; Iter   465/  823] train: loss: 0.0768474
[Epoch 16; Iter   495/  823] train: loss: 0.0841916
[Epoch 16; Iter   525/  823] train: loss: 0.0313395
[Epoch 16; Iter   555/  823] train: loss: 0.1635823
[Epoch 16; Iter   585/  823] train: loss: 0.1913645
[Epoch 16; Iter   615/  823] train: loss: 0.1404662
[Epoch 16; Iter   645/  823] train: loss: 0.1640609
[Epoch 16; Iter   675/  823] train: loss: 0.0174691
[Epoch 16; Iter   705/  823] train: loss: 0.0394788
[Epoch 16; Iter   735/  823] train: loss: 0.0620418
[Epoch 16; Iter   765/  823] train: loss: 0.1253582
[Epoch 16; Iter   795/  823] train: loss: 0.0928644
[Epoch 16] ogbg-molhiv: 0.734059 val loss: 0.139760
[Epoch 16] ogbg-molhiv: 0.741629 test loss: 0.187072
[Epoch 17; Iter     2/  823] train: loss: 0.0239055
[Epoch 17; Iter    32/  823] train: loss: 0.2716984
[Epoch 17; Iter    62/  823] train: loss: 0.1337504
[Epoch 17; Iter    92/  823] train: loss: 0.2274944
[Epoch 17; Iter   122/  823] train: loss: 0.1729329
[Epoch 17; Iter   152/  823] train: loss: 0.0169563
[Epoch 17; Iter   182/  823] train: loss: 0.0290259
[Epoch 17; Iter   212/  823] train: loss: 0.0509005
[Epoch 17; Iter   242/  823] train: loss: 0.0277200
[Epoch 17; Iter   272/  823] train: loss: 0.0588136
[Epoch 17; Iter   302/  823] train: loss: 0.1864857
[Epoch 17; Iter   332/  823] train: loss: 0.0517512
[Epoch 17; Iter   362/  823] train: loss: 0.2586120
[Epoch 17; Iter   392/  823] train: loss: 0.1003790
[Epoch 17; Iter   422/  823] train: loss: 0.0343734
[Epoch 17; Iter   452/  823] train: loss: 0.0967039
[Epoch 17; Iter   482/  823] train: loss: 0.0465456
[Epoch 17; Iter   512/  823] train: loss: 0.0158032
[Epoch 17; Iter   542/  823] train: loss: 0.0313485
[Epoch 17; Iter   572/  823] train: loss: 0.1380806
[Epoch 17; Iter   602/  823] train: loss: 0.2822120
[Epoch 17; Iter   632/  823] train: loss: 0.0552580
[Epoch 17; Iter   662/  823] train: loss: 0.0215925
[Epoch 17; Iter   692/  823] train: loss: 0.1826003
[Epoch 17; Iter   722/  823] train: loss: 0.1304930
[Epoch 17; Iter   752/  823] train: loss: 0.2389499
[Epoch 17; Iter   782/  823] train: loss: 0.0955080
[Epoch 17; Iter   812/  823] train: loss: 0.2492902
[Epoch 17] ogbg-molhiv: 0.723501 val loss: 0.185615
[Epoch 17] ogbg-molhiv: 0.747324 test loss: 0.164336
[Epoch 18; Iter    19/  823] train: loss: 0.2063530
[Epoch 18; Iter    49/  823] train: loss: 0.0387480
[Epoch 18; Iter    79/  823] train: loss: 0.0398486
[Epoch 18; Iter   109/  823] train: loss: 0.1189841
[Epoch 18; Iter   139/  823] train: loss: 0.0165426
[Epoch 18; Iter   169/  823] train: loss: 0.0414159
[Epoch 18; Iter   199/  823] train: loss: 0.0163400
[Epoch 18; Iter   229/  823] train: loss: 0.3257835
[Epoch 18; Iter   259/  823] train: loss: 0.0894299
[Epoch 18; Iter   289/  823] train: loss: 0.0228614
[Epoch 18; Iter   319/  823] train: loss: 0.1186783
[Epoch 18; Iter   349/  823] train: loss: 0.0299110
[Epoch 18; Iter   379/  823] train: loss: 0.4347909
[Epoch 18; Iter   409/  823] train: loss: 0.0259544
[Epoch 18; Iter   439/  823] train: loss: 0.0262940
[Epoch 18; Iter   469/  823] train: loss: 0.0775920
[Epoch 18; Iter   499/  823] train: loss: 0.2951136
[Epoch 18; Iter   529/  823] train: loss: 0.0197727
[Epoch 18; Iter   559/  823] train: loss: 0.0165087
[Epoch 18; Iter   589/  823] train: loss: 0.0205320
[Epoch 18; Iter   619/  823] train: loss: 0.1447519
[Epoch 18; Iter   649/  823] train: loss: 0.0674445
[Epoch 18; Iter   679/  823] train: loss: 0.1921174
[Epoch 18; Iter   709/  823] train: loss: 0.0306074
[Epoch 18; Iter   739/  823] train: loss: 0.2601542
[Epoch 18; Iter   769/  823] train: loss: 0.4361720
[Epoch 18; Iter   799/  823] train: loss: 0.0389338
[Epoch 18] ogbg-molhiv: 0.692372 val loss: 0.158455
[Epoch 18] ogbg-molhiv: 0.737364 test loss: 0.262712
[Epoch 19; Iter     6/  823] train: loss: 0.0224441
[Epoch 19; Iter    36/  823] train: loss: 0.0240424
[Epoch 19; Iter    66/  823] train: loss: 0.0401500
[Epoch 19; Iter    96/  823] train: loss: 0.1541925
[Epoch 19; Iter   126/  823] train: loss: 0.1525899
[Epoch 19; Iter   156/  823] train: loss: 0.0904614
[Epoch 19; Iter   186/  823] train: loss: 0.0199938
[Epoch 19; Iter   216/  823] train: loss: 0.0192425
[Epoch 19; Iter   246/  823] train: loss: 0.0739290
[Epoch 19; Iter   276/  823] train: loss: 0.1703275
[Epoch 19; Iter   306/  823] train: loss: 0.0266431
[Epoch 19; Iter   336/  823] train: loss: 0.0751651
[Epoch 19; Iter   366/  823] train: loss: 0.1056623
[Epoch 19; Iter   396/  823] train: loss: 0.0892655
[Epoch 19; Iter   426/  823] train: loss: 0.2046813
[Epoch 19; Iter   456/  823] train: loss: 0.0483559
[Epoch 19; Iter   486/  823] train: loss: 0.0469720
[Epoch 19; Iter   516/  823] train: loss: 0.1084268
[Epoch 19; Iter   546/  823] train: loss: 0.1470744
[Epoch 19; Iter   576/  823] train: loss: 0.0215228
[Epoch 19; Iter   606/  823] train: loss: 0.0666499
[Epoch 19; Iter   636/  823] train: loss: 0.7107826
[Epoch 19; Iter   666/  823] train: loss: 0.3015392
[Epoch 19; Iter   696/  823] train: loss: 0.3679717
[Epoch 19; Iter   726/  823] train: loss: 0.0225720
[Epoch 19; Iter   756/  823] train: loss: 0.0339669
[Epoch 19; Iter   786/  823] train: loss: 0.2908157
[Epoch 19; Iter   816/  823] train: loss: 0.0629988
[Epoch 19] ogbg-molhiv: 0.695927 val loss: 0.142374
[Epoch 19] ogbg-molhiv: 0.698044 test loss: 0.142141
[Epoch 20; Iter    23/  823] train: loss: 0.2014653
[Epoch 20; Iter    53/  823] train: loss: 0.0469178
[Epoch 20; Iter    83/  823] train: loss: 0.0392205
[Epoch 20; Iter   113/  823] train: loss: 0.3051565
[Epoch 20; Iter   143/  823] train: loss: 0.1287336
[Epoch 20; Iter   173/  823] train: loss: 0.0933401
[Epoch 20; Iter   203/  823] train: loss: 0.1577455
[Epoch 20; Iter   233/  823] train: loss: 0.2067800
[Epoch 20; Iter   263/  823] train: loss: 0.0881209
[Epoch 20; Iter   293/  823] train: loss: 0.2829116
[Epoch 20; Iter   323/  823] train: loss: 0.0292046
[Epoch 20; Iter   353/  823] train: loss: 0.1982418
[Epoch 20; Iter   383/  823] train: loss: 0.4709715
[Epoch 20; Iter   413/  823] train: loss: 0.1048360
[Epoch 20; Iter   443/  823] train: loss: 0.6080698
[Epoch 20; Iter   473/  823] train: loss: 0.1635306
[Epoch 20; Iter   503/  823] train: loss: 0.0220021
[Epoch 20; Iter   533/  823] train: loss: 0.2162106
[Epoch 20; Iter   563/  823] train: loss: 0.0234793
[Epoch 20; Iter   593/  823] train: loss: 0.0263429
[Epoch 20; Iter   623/  823] train: loss: 0.0430872
[Epoch 20; Iter   653/  823] train: loss: 0.0358768
[Epoch 20; Iter   683/  823] train: loss: 0.0249559
[Epoch 20; Iter   713/  823] train: loss: 0.0695108
[Epoch 20; Iter   743/  823] train: loss: 0.2549286
[Epoch 16; Iter   225/ 1097] train: loss: 0.0909102
[Epoch 16; Iter   255/ 1097] train: loss: 0.2251528
[Epoch 16; Iter   285/ 1097] train: loss: 0.0331136
[Epoch 16; Iter   315/ 1097] train: loss: 0.0444549
[Epoch 16; Iter   345/ 1097] train: loss: 0.0971289
[Epoch 16; Iter   375/ 1097] train: loss: 0.0735674
[Epoch 16; Iter   405/ 1097] train: loss: 0.0282343
[Epoch 16; Iter   435/ 1097] train: loss: 0.0776556
[Epoch 16; Iter   465/ 1097] train: loss: 0.1883137
[Epoch 16; Iter   495/ 1097] train: loss: 0.0589263
[Epoch 16; Iter   525/ 1097] train: loss: 0.0365449
[Epoch 16; Iter   555/ 1097] train: loss: 0.4837609
[Epoch 16; Iter   585/ 1097] train: loss: 0.0455081
[Epoch 16; Iter   615/ 1097] train: loss: 0.1859095
[Epoch 16; Iter   645/ 1097] train: loss: 0.0888836
[Epoch 16; Iter   675/ 1097] train: loss: 0.1410895
[Epoch 16; Iter   705/ 1097] train: loss: 0.0323821
[Epoch 16; Iter   735/ 1097] train: loss: 0.2177476
[Epoch 16; Iter   765/ 1097] train: loss: 0.4221572
[Epoch 16; Iter   795/ 1097] train: loss: 0.0539671
[Epoch 16; Iter   825/ 1097] train: loss: 0.0295330
[Epoch 16; Iter   855/ 1097] train: loss: 0.0372182
[Epoch 16; Iter   885/ 1097] train: loss: 0.2295278
[Epoch 16; Iter   915/ 1097] train: loss: 0.1483149
[Epoch 16; Iter   945/ 1097] train: loss: 0.0301119
[Epoch 16; Iter   975/ 1097] train: loss: 0.0228623
[Epoch 16; Iter  1005/ 1097] train: loss: 0.1396526
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0533486
[Epoch 16; Iter  1065/ 1097] train: loss: 0.0299898
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0321504
[Epoch 16] ogbg-molhiv: 0.798994 val loss: 0.271244
[Epoch 16] ogbg-molhiv: 0.775506 test loss: 0.247352
[Epoch 17; Iter    28/ 1097] train: loss: 0.1628100
[Epoch 17; Iter    58/ 1097] train: loss: 0.1857541
[Epoch 17; Iter    88/ 1097] train: loss: 0.1029724
[Epoch 17; Iter   118/ 1097] train: loss: 0.0286464
[Epoch 17; Iter   148/ 1097] train: loss: 0.0265287
[Epoch 17; Iter   178/ 1097] train: loss: 0.0267499
[Epoch 17; Iter   208/ 1097] train: loss: 0.0258796
[Epoch 17; Iter   238/ 1097] train: loss: 0.0691139
[Epoch 17; Iter   268/ 1097] train: loss: 0.0900915
[Epoch 17; Iter   298/ 1097] train: loss: 0.0433289
[Epoch 17; Iter   328/ 1097] train: loss: 0.2070220
[Epoch 17; Iter   358/ 1097] train: loss: 0.2771621
[Epoch 17; Iter   388/ 1097] train: loss: 0.0332731
[Epoch 17; Iter   418/ 1097] train: loss: 0.0585184
[Epoch 17; Iter   448/ 1097] train: loss: 0.0665179
[Epoch 17; Iter   478/ 1097] train: loss: 0.1843854
[Epoch 17; Iter   508/ 1097] train: loss: 0.0293407
[Epoch 17; Iter   538/ 1097] train: loss: 0.0849654
[Epoch 17; Iter   568/ 1097] train: loss: 0.0335519
[Epoch 17; Iter   598/ 1097] train: loss: 0.0705502
[Epoch 17; Iter   628/ 1097] train: loss: 0.0410381
[Epoch 17; Iter   658/ 1097] train: loss: 0.1957951
[Epoch 17; Iter   688/ 1097] train: loss: 0.0440908
[Epoch 17; Iter   718/ 1097] train: loss: 0.1256155
[Epoch 17; Iter   748/ 1097] train: loss: 0.1820419
[Epoch 17; Iter   778/ 1097] train: loss: 0.0549834
[Epoch 17; Iter   808/ 1097] train: loss: 0.1878138
[Epoch 17; Iter   838/ 1097] train: loss: 0.0685716
[Epoch 17; Iter   868/ 1097] train: loss: 0.0325545
[Epoch 17; Iter   898/ 1097] train: loss: 0.1585248
[Epoch 17; Iter   928/ 1097] train: loss: 0.2437805
[Epoch 17; Iter   958/ 1097] train: loss: 0.0238891
[Epoch 17; Iter   988/ 1097] train: loss: 0.1619965
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0450215
[Epoch 17; Iter  1048/ 1097] train: loss: 0.2682252
[Epoch 17; Iter  1078/ 1097] train: loss: 0.3252003
[Epoch 17] ogbg-molhiv: 0.825954 val loss: 0.962782
[Epoch 17] ogbg-molhiv: 0.748977 test loss: 0.319533
[Epoch 18; Iter    11/ 1097] train: loss: 0.0263158
[Epoch 18; Iter    41/ 1097] train: loss: 0.1842879
[Epoch 18; Iter    71/ 1097] train: loss: 0.2494138
[Epoch 18; Iter   101/ 1097] train: loss: 0.0227716
[Epoch 18; Iter   131/ 1097] train: loss: 0.0853921
[Epoch 18; Iter   161/ 1097] train: loss: 0.2666537
[Epoch 18; Iter   191/ 1097] train: loss: 0.0483731
[Epoch 18; Iter   221/ 1097] train: loss: 0.1193678
[Epoch 18; Iter   251/ 1097] train: loss: 0.0323203
[Epoch 18; Iter   281/ 1097] train: loss: 0.1131716
[Epoch 18; Iter   311/ 1097] train: loss: 0.0362546
[Epoch 18; Iter   341/ 1097] train: loss: 0.0246958
[Epoch 18; Iter   371/ 1097] train: loss: 0.0272583
[Epoch 18; Iter   401/ 1097] train: loss: 0.1825922
[Epoch 18; Iter   431/ 1097] train: loss: 0.0340417
[Epoch 18; Iter   461/ 1097] train: loss: 0.1462900
[Epoch 18; Iter   491/ 1097] train: loss: 0.0240792
[Epoch 18; Iter   521/ 1097] train: loss: 0.2001422
[Epoch 18; Iter   551/ 1097] train: loss: 0.0779436
[Epoch 18; Iter   581/ 1097] train: loss: 0.0513355
[Epoch 18; Iter   611/ 1097] train: loss: 0.0288203
[Epoch 18; Iter   641/ 1097] train: loss: 0.1593665
[Epoch 18; Iter   671/ 1097] train: loss: 0.0418792
[Epoch 18; Iter   701/ 1097] train: loss: 0.0357550
[Epoch 18; Iter   731/ 1097] train: loss: 0.0343611
[Epoch 18; Iter   761/ 1097] train: loss: 0.0449017
[Epoch 18; Iter   791/ 1097] train: loss: 0.0308873
[Epoch 18; Iter   821/ 1097] train: loss: 0.1051819
[Epoch 18; Iter   851/ 1097] train: loss: 0.0289005
[Epoch 18; Iter   881/ 1097] train: loss: 0.1085458
[Epoch 18; Iter   911/ 1097] train: loss: 0.0331179
[Epoch 18; Iter   941/ 1097] train: loss: 0.1174620
[Epoch 18; Iter   971/ 1097] train: loss: 0.0281045
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1439822
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0607072
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0922111
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0273322
[Epoch 18] ogbg-molhiv: 0.823517 val loss: 0.111766
[Epoch 18] ogbg-molhiv: 0.760880 test loss: 0.225068
[Epoch 19; Iter    24/ 1097] train: loss: 0.0248390
[Epoch 19; Iter    54/ 1097] train: loss: 0.2170896
[Epoch 19; Iter    84/ 1097] train: loss: 0.0946212
[Epoch 19; Iter   114/ 1097] train: loss: 0.0253054
[Epoch 19; Iter   144/ 1097] train: loss: 0.0797373
[Epoch 19; Iter   174/ 1097] train: loss: 0.0414894
[Epoch 19; Iter   204/ 1097] train: loss: 0.0608164
[Epoch 19; Iter   234/ 1097] train: loss: 0.0778567
[Epoch 19; Iter   264/ 1097] train: loss: 0.0256434
[Epoch 19; Iter   294/ 1097] train: loss: 0.0380783
[Epoch 19; Iter   324/ 1097] train: loss: 0.0297257
[Epoch 19; Iter   354/ 1097] train: loss: 0.2686986
[Epoch 19; Iter   384/ 1097] train: loss: 0.0384119
[Epoch 19; Iter   414/ 1097] train: loss: 0.1710902
[Epoch 19; Iter   444/ 1097] train: loss: 0.0309088
[Epoch 19; Iter   474/ 1097] train: loss: 0.2997789
[Epoch 19; Iter   504/ 1097] train: loss: 0.0274256
[Epoch 19; Iter   534/ 1097] train: loss: 0.0175681
[Epoch 19; Iter   564/ 1097] train: loss: 0.1792638
[Epoch 19; Iter   594/ 1097] train: loss: 0.1076331
[Epoch 19; Iter   624/ 1097] train: loss: 0.0666126
[Epoch 19; Iter   654/ 1097] train: loss: 0.0230064
[Epoch 19; Iter   684/ 1097] train: loss: 0.4002364
[Epoch 19; Iter   714/ 1097] train: loss: 0.0276047
[Epoch 19; Iter   744/ 1097] train: loss: 0.0905015
[Epoch 19; Iter   774/ 1097] train: loss: 0.0856868
[Epoch 19; Iter   804/ 1097] train: loss: 0.0464431
[Epoch 19; Iter   834/ 1097] train: loss: 0.0223527
[Epoch 19; Iter   864/ 1097] train: loss: 0.0466012
[Epoch 19; Iter   894/ 1097] train: loss: 0.3797917
[Epoch 19; Iter   924/ 1097] train: loss: 0.1195648
[Epoch 19; Iter   954/ 1097] train: loss: 0.0289301
[Epoch 19; Iter   984/ 1097] train: loss: 0.1052256
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1964424
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0378064
[Epoch 19; Iter  1074/ 1097] train: loss: 0.4018948
[Epoch 19] ogbg-molhiv: 0.809842 val loss: 0.205320
[Epoch 19] ogbg-molhiv: 0.713030 test loss: 0.368914
[Epoch 20; Iter     7/ 1097] train: loss: 0.0624168
[Epoch 20; Iter    37/ 1097] train: loss: 0.0684442
[Epoch 20; Iter    67/ 1097] train: loss: 0.0201421
[Epoch 20; Iter    97/ 1097] train: loss: 0.0389045
[Epoch 20; Iter   127/ 1097] train: loss: 0.0377834
[Epoch 20; Iter   157/ 1097] train: loss: 0.0265018
[Epoch 20; Iter   187/ 1097] train: loss: 0.1123136
[Epoch 20; Iter   217/ 1097] train: loss: 0.3624072
[Epoch 20; Iter   247/ 1097] train: loss: 0.0565991
[Epoch 20; Iter   277/ 1097] train: loss: 0.0198986
[Epoch 16; Iter   225/ 1097] train: loss: 0.1810106
[Epoch 16; Iter   255/ 1097] train: loss: 0.0840761
[Epoch 16; Iter   285/ 1097] train: loss: 0.1580072
[Epoch 16; Iter   315/ 1097] train: loss: 0.0387657
[Epoch 16; Iter   345/ 1097] train: loss: 0.1699082
[Epoch 16; Iter   375/ 1097] train: loss: 0.1033683
[Epoch 16; Iter   405/ 1097] train: loss: 0.0251455
[Epoch 16; Iter   435/ 1097] train: loss: 0.4414364
[Epoch 16; Iter   465/ 1097] train: loss: 0.0476535
[Epoch 16; Iter   495/ 1097] train: loss: 0.0275293
[Epoch 16; Iter   525/ 1097] train: loss: 0.1782279
[Epoch 16; Iter   555/ 1097] train: loss: 0.0215119
[Epoch 16; Iter   585/ 1097] train: loss: 0.2293548
[Epoch 16; Iter   615/ 1097] train: loss: 0.0751121
[Epoch 16; Iter   645/ 1097] train: loss: 0.0689422
[Epoch 16; Iter   675/ 1097] train: loss: 0.0433906
[Epoch 16; Iter   705/ 1097] train: loss: 0.0387716
[Epoch 16; Iter   735/ 1097] train: loss: 0.3471978
[Epoch 16; Iter   765/ 1097] train: loss: 0.0248297
[Epoch 16; Iter   795/ 1097] train: loss: 0.0398351
[Epoch 16; Iter   825/ 1097] train: loss: 0.2695087
[Epoch 16; Iter   855/ 1097] train: loss: 0.1751651
[Epoch 16; Iter   885/ 1097] train: loss: 0.0215676
[Epoch 16; Iter   915/ 1097] train: loss: 0.0548779
[Epoch 16; Iter   945/ 1097] train: loss: 0.1451414
[Epoch 16; Iter   975/ 1097] train: loss: 0.1920796
[Epoch 16; Iter  1005/ 1097] train: loss: 0.2452298
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0518059
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1802547
[Epoch 16; Iter  1095/ 1097] train: loss: 0.1549170
[Epoch 16] ogbg-molhiv: 0.749011 val loss: 0.098673
[Epoch 16] ogbg-molhiv: 0.753643 test loss: 0.123940
[Epoch 17; Iter    28/ 1097] train: loss: 0.2560306
[Epoch 17; Iter    58/ 1097] train: loss: 0.0477158
[Epoch 17; Iter    88/ 1097] train: loss: 0.1416501
[Epoch 17; Iter   118/ 1097] train: loss: 0.1343221
[Epoch 17; Iter   148/ 1097] train: loss: 0.0238752
[Epoch 17; Iter   178/ 1097] train: loss: 0.2017000
[Epoch 17; Iter   208/ 1097] train: loss: 0.0249352
[Epoch 17; Iter   238/ 1097] train: loss: 0.2338932
[Epoch 17; Iter   268/ 1097] train: loss: 0.0607040
[Epoch 17; Iter   298/ 1097] train: loss: 0.1861655
[Epoch 17; Iter   328/ 1097] train: loss: 0.2494278
[Epoch 17; Iter   358/ 1097] train: loss: 0.0295828
[Epoch 17; Iter   388/ 1097] train: loss: 0.1378893
[Epoch 17; Iter   418/ 1097] train: loss: 0.1621025
[Epoch 17; Iter   448/ 1097] train: loss: 0.0353194
[Epoch 17; Iter   478/ 1097] train: loss: 0.0389005
[Epoch 17; Iter   508/ 1097] train: loss: 0.0628240
[Epoch 17; Iter   538/ 1097] train: loss: 0.0415814
[Epoch 17; Iter   568/ 1097] train: loss: 0.2447100
[Epoch 17; Iter   598/ 1097] train: loss: 0.0307578
[Epoch 17; Iter   628/ 1097] train: loss: 0.1824117
[Epoch 17; Iter   658/ 1097] train: loss: 0.0829686
[Epoch 17; Iter   688/ 1097] train: loss: 0.0503459
[Epoch 17; Iter   718/ 1097] train: loss: 0.1415100
[Epoch 17; Iter   748/ 1097] train: loss: 0.0238713
[Epoch 17; Iter   778/ 1097] train: loss: 0.2093990
[Epoch 17; Iter   808/ 1097] train: loss: 0.0307993
[Epoch 17; Iter   838/ 1097] train: loss: 0.0245483
[Epoch 17; Iter   868/ 1097] train: loss: 0.0337998
[Epoch 17; Iter   898/ 1097] train: loss: 0.0500577
[Epoch 17; Iter   928/ 1097] train: loss: 0.3375027
[Epoch 17; Iter   958/ 1097] train: loss: 0.1791064
[Epoch 17; Iter   988/ 1097] train: loss: 0.0416349
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0409125
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0394656
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1563053
[Epoch 17] ogbg-molhiv: 0.745707 val loss: 0.080429
[Epoch 17] ogbg-molhiv: 0.738340 test loss: 0.194656
[Epoch 18; Iter    11/ 1097] train: loss: 0.1388081
[Epoch 18; Iter    41/ 1097] train: loss: 0.0394188
[Epoch 18; Iter    71/ 1097] train: loss: 0.1533543
[Epoch 18; Iter   101/ 1097] train: loss: 0.0234275
[Epoch 18; Iter   131/ 1097] train: loss: 0.1516441
[Epoch 18; Iter   161/ 1097] train: loss: 0.2034871
[Epoch 18; Iter   191/ 1097] train: loss: 0.0580933
[Epoch 18; Iter   221/ 1097] train: loss: 0.0405443
[Epoch 18; Iter   251/ 1097] train: loss: 0.0620884
[Epoch 18; Iter   281/ 1097] train: loss: 0.0309119
[Epoch 18; Iter   311/ 1097] train: loss: 0.3464504
[Epoch 18; Iter   341/ 1097] train: loss: 0.1601790
[Epoch 18; Iter   371/ 1097] train: loss: 0.0470622
[Epoch 18; Iter   401/ 1097] train: loss: 0.0252940
[Epoch 18; Iter   431/ 1097] train: loss: 0.0513176
[Epoch 18; Iter   461/ 1097] train: loss: 0.0409003
[Epoch 18; Iter   491/ 1097] train: loss: 0.1265459
[Epoch 18; Iter   521/ 1097] train: loss: 0.0489830
[Epoch 18; Iter   551/ 1097] train: loss: 0.1039332
[Epoch 18; Iter   581/ 1097] train: loss: 0.0280449
[Epoch 18; Iter   611/ 1097] train: loss: 0.1744010
[Epoch 18; Iter   641/ 1097] train: loss: 0.1154694
[Epoch 18; Iter   671/ 1097] train: loss: 0.1121878
[Epoch 18; Iter   701/ 1097] train: loss: 0.1592238
[Epoch 18; Iter   731/ 1097] train: loss: 0.1800058
[Epoch 18; Iter   761/ 1097] train: loss: 0.0865182
[Epoch 18; Iter   791/ 1097] train: loss: 0.0763015
[Epoch 18; Iter   821/ 1097] train: loss: 0.0673507
[Epoch 18; Iter   851/ 1097] train: loss: 0.2489463
[Epoch 18; Iter   881/ 1097] train: loss: 0.0215629
[Epoch 18; Iter   911/ 1097] train: loss: 0.0593678
[Epoch 18; Iter   941/ 1097] train: loss: 0.0276116
[Epoch 18; Iter   971/ 1097] train: loss: 0.0421982
[Epoch 18; Iter  1001/ 1097] train: loss: 0.1124446
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0265999
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0329497
[Epoch 18; Iter  1091/ 1097] train: loss: 0.0353829
[Epoch 18] ogbg-molhiv: 0.721849 val loss: 0.089102
[Epoch 18] ogbg-molhiv: 0.739748 test loss: 0.194973
[Epoch 19; Iter    24/ 1097] train: loss: 0.1170084
[Epoch 19; Iter    54/ 1097] train: loss: 0.1221269
[Epoch 19; Iter    84/ 1097] train: loss: 0.0291417
[Epoch 19; Iter   114/ 1097] train: loss: 0.0956156
[Epoch 19; Iter   144/ 1097] train: loss: 0.1858568
[Epoch 19; Iter   174/ 1097] train: loss: 0.1222612
[Epoch 19; Iter   204/ 1097] train: loss: 0.1098760
[Epoch 19; Iter   234/ 1097] train: loss: 0.1236150
[Epoch 19; Iter   264/ 1097] train: loss: 0.2311419
[Epoch 19; Iter   294/ 1097] train: loss: 0.1476789
[Epoch 19; Iter   324/ 1097] train: loss: 0.2425800
[Epoch 19; Iter   354/ 1097] train: loss: 0.0349962
[Epoch 19; Iter   384/ 1097] train: loss: 0.2039195
[Epoch 19; Iter   414/ 1097] train: loss: 0.1606647
[Epoch 19; Iter   444/ 1097] train: loss: 0.1231175
[Epoch 19; Iter   474/ 1097] train: loss: 0.0207819
[Epoch 19; Iter   504/ 1097] train: loss: 0.0738679
[Epoch 19; Iter   534/ 1097] train: loss: 0.2948224
[Epoch 19; Iter   564/ 1097] train: loss: 0.2246269
[Epoch 19; Iter   594/ 1097] train: loss: 0.0392290
[Epoch 19; Iter   624/ 1097] train: loss: 0.0433818
[Epoch 19; Iter   654/ 1097] train: loss: 0.2168372
[Epoch 19; Iter   684/ 1097] train: loss: 0.1019991
[Epoch 19; Iter   714/ 1097] train: loss: 0.1297564
[Epoch 19; Iter   744/ 1097] train: loss: 0.1710452
[Epoch 19; Iter   774/ 1097] train: loss: 0.1411906
[Epoch 19; Iter   804/ 1097] train: loss: 0.0287635
[Epoch 19; Iter   834/ 1097] train: loss: 0.1554424
[Epoch 19; Iter   864/ 1097] train: loss: 0.1785938
[Epoch 19; Iter   894/ 1097] train: loss: 0.0452785
[Epoch 19; Iter   924/ 1097] train: loss: 0.1752800
[Epoch 19; Iter   954/ 1097] train: loss: 0.2131649
[Epoch 19; Iter   984/ 1097] train: loss: 0.0379782
[Epoch 19; Iter  1014/ 1097] train: loss: 0.2006005
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0757662
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0272879
[Epoch 19] ogbg-molhiv: 0.707305 val loss: 0.084349
[Epoch 19] ogbg-molhiv: 0.731965 test loss: 0.201736
[Epoch 20; Iter     7/ 1097] train: loss: 0.1097698
[Epoch 20; Iter    37/ 1097] train: loss: 0.2370078
[Epoch 20; Iter    67/ 1097] train: loss: 0.0276798
[Epoch 20; Iter    97/ 1097] train: loss: 0.1510738
[Epoch 20; Iter   127/ 1097] train: loss: 0.2667215
[Epoch 20; Iter   157/ 1097] train: loss: 0.0335662
[Epoch 20; Iter   187/ 1097] train: loss: 0.0646158
[Epoch 20; Iter   217/ 1097] train: loss: 0.0205733
[Epoch 20; Iter   247/ 1097] train: loss: 0.0628111
[Epoch 20; Iter   277/ 1097] train: loss: 0.1863982
[Epoch 16; Iter   225/ 1097] train: loss: 0.0321746
[Epoch 16; Iter   255/ 1097] train: loss: 0.0290689
[Epoch 16; Iter   285/ 1097] train: loss: 0.1545494
[Epoch 16; Iter   315/ 1097] train: loss: 0.0544070
[Epoch 16; Iter   345/ 1097] train: loss: 0.0578287
[Epoch 16; Iter   375/ 1097] train: loss: 0.1770975
[Epoch 16; Iter   405/ 1097] train: loss: 0.1690091
[Epoch 16; Iter   435/ 1097] train: loss: 0.1237445
[Epoch 16; Iter   465/ 1097] train: loss: 0.1538676
[Epoch 16; Iter   495/ 1097] train: loss: 0.0609530
[Epoch 16; Iter   525/ 1097] train: loss: 0.1470502
[Epoch 16; Iter   555/ 1097] train: loss: 0.0262647
[Epoch 16; Iter   585/ 1097] train: loss: 0.0478310
[Epoch 16; Iter   615/ 1097] train: loss: 0.0357469
[Epoch 16; Iter   645/ 1097] train: loss: 0.0396659
[Epoch 16; Iter   675/ 1097] train: loss: 0.1565046
[Epoch 16; Iter   705/ 1097] train: loss: 0.1901444
[Epoch 16; Iter   735/ 1097] train: loss: 0.0831341
[Epoch 16; Iter   765/ 1097] train: loss: 0.0363618
[Epoch 16; Iter   795/ 1097] train: loss: 0.1411643
[Epoch 16; Iter   825/ 1097] train: loss: 0.0296772
[Epoch 16; Iter   855/ 1097] train: loss: 0.1082203
[Epoch 16; Iter   885/ 1097] train: loss: 0.2523567
[Epoch 16; Iter   915/ 1097] train: loss: 0.0255653
[Epoch 16; Iter   945/ 1097] train: loss: 0.0262498
[Epoch 16; Iter   975/ 1097] train: loss: 0.0235821
[Epoch 16; Iter  1005/ 1097] train: loss: 0.0373001
[Epoch 16; Iter  1035/ 1097] train: loss: 0.0216401
[Epoch 16; Iter  1065/ 1097] train: loss: 0.1437625
[Epoch 16; Iter  1095/ 1097] train: loss: 0.0519278
[Epoch 16] ogbg-molhiv: 0.769260 val loss: 0.083132
[Epoch 16] ogbg-molhiv: 0.754570 test loss: 0.118560
[Epoch 17; Iter    28/ 1097] train: loss: 0.0329060
[Epoch 17; Iter    58/ 1097] train: loss: 0.0376305
[Epoch 17; Iter    88/ 1097] train: loss: 0.0178199
[Epoch 17; Iter   118/ 1097] train: loss: 0.1644384
[Epoch 17; Iter   148/ 1097] train: loss: 0.1271928
[Epoch 17; Iter   178/ 1097] train: loss: 0.0633316
[Epoch 17; Iter   208/ 1097] train: loss: 0.0241055
[Epoch 17; Iter   238/ 1097] train: loss: 0.2099025
[Epoch 17; Iter   268/ 1097] train: loss: 0.0304281
[Epoch 17; Iter   298/ 1097] train: loss: 0.0382947
[Epoch 17; Iter   328/ 1097] train: loss: 0.0249311
[Epoch 17; Iter   358/ 1097] train: loss: 0.0245160
[Epoch 17; Iter   388/ 1097] train: loss: 0.0330934
[Epoch 17; Iter   418/ 1097] train: loss: 0.1104297
[Epoch 17; Iter   448/ 1097] train: loss: 0.0205551
[Epoch 17; Iter   478/ 1097] train: loss: 0.0392255
[Epoch 17; Iter   508/ 1097] train: loss: 0.0492864
[Epoch 17; Iter   538/ 1097] train: loss: 0.3062733
[Epoch 17; Iter   568/ 1097] train: loss: 0.2261782
[Epoch 17; Iter   598/ 1097] train: loss: 0.1369033
[Epoch 17; Iter   628/ 1097] train: loss: 0.0653475
[Epoch 17; Iter   658/ 1097] train: loss: 0.0319173
[Epoch 17; Iter   688/ 1097] train: loss: 0.2338794
[Epoch 17; Iter   718/ 1097] train: loss: 0.0514536
[Epoch 17; Iter   748/ 1097] train: loss: 0.1632596
[Epoch 17; Iter   778/ 1097] train: loss: 0.0734155
[Epoch 17; Iter   808/ 1097] train: loss: 0.0999594
[Epoch 17; Iter   838/ 1097] train: loss: 0.0410956
[Epoch 17; Iter   868/ 1097] train: loss: 0.0205741
[Epoch 17; Iter   898/ 1097] train: loss: 0.1794077
[Epoch 17; Iter   928/ 1097] train: loss: 0.2364720
[Epoch 17; Iter   958/ 1097] train: loss: 0.1482346
[Epoch 17; Iter   988/ 1097] train: loss: 0.0310172
[Epoch 17; Iter  1018/ 1097] train: loss: 0.0299174
[Epoch 17; Iter  1048/ 1097] train: loss: 0.0266376
[Epoch 17; Iter  1078/ 1097] train: loss: 0.1871610
[Epoch 17] ogbg-molhiv: 0.764899 val loss: 0.077882
[Epoch 17] ogbg-molhiv: 0.733960 test loss: 0.124306
[Epoch 18; Iter    11/ 1097] train: loss: 0.1386236
[Epoch 18; Iter    41/ 1097] train: loss: 0.2345475
[Epoch 18; Iter    71/ 1097] train: loss: 0.0821346
[Epoch 18; Iter   101/ 1097] train: loss: 0.1220617
[Epoch 18; Iter   131/ 1097] train: loss: 0.1209502
[Epoch 18; Iter   161/ 1097] train: loss: 0.0408310
[Epoch 18; Iter   191/ 1097] train: loss: 0.1447209
[Epoch 18; Iter   221/ 1097] train: loss: 0.1755297
[Epoch 18; Iter   251/ 1097] train: loss: 0.1334917
[Epoch 18; Iter   281/ 1097] train: loss: 0.0190154
[Epoch 18; Iter   311/ 1097] train: loss: 0.1633922
[Epoch 18; Iter   341/ 1097] train: loss: 0.0739612
[Epoch 18; Iter   371/ 1097] train: loss: 0.0708201
[Epoch 18; Iter   401/ 1097] train: loss: 0.1408400
[Epoch 18; Iter   431/ 1097] train: loss: 0.2121653
[Epoch 18; Iter   461/ 1097] train: loss: 0.0445160
[Epoch 18; Iter   491/ 1097] train: loss: 0.2126082
[Epoch 18; Iter   521/ 1097] train: loss: 0.2974404
[Epoch 18; Iter   551/ 1097] train: loss: 0.0416237
[Epoch 18; Iter   581/ 1097] train: loss: 0.0333479
[Epoch 18; Iter   611/ 1097] train: loss: 0.0197164
[Epoch 18; Iter   641/ 1097] train: loss: 0.1743431
[Epoch 18; Iter   671/ 1097] train: loss: 0.0322933
[Epoch 18; Iter   701/ 1097] train: loss: 0.2775362
[Epoch 18; Iter   731/ 1097] train: loss: 0.1398287
[Epoch 18; Iter   761/ 1097] train: loss: 0.2870038
[Epoch 18; Iter   791/ 1097] train: loss: 0.0739027
[Epoch 18; Iter   821/ 1097] train: loss: 0.0823142
[Epoch 18; Iter   851/ 1097] train: loss: 0.1907989
[Epoch 18; Iter   881/ 1097] train: loss: 0.1240001
[Epoch 18; Iter   911/ 1097] train: loss: 0.2086201
[Epoch 18; Iter   941/ 1097] train: loss: 0.0192750
[Epoch 18; Iter   971/ 1097] train: loss: 0.1197192
[Epoch 18; Iter  1001/ 1097] train: loss: 0.0329320
[Epoch 18; Iter  1031/ 1097] train: loss: 0.0499785
[Epoch 18; Iter  1061/ 1097] train: loss: 0.0343359
[Epoch 18; Iter  1091/ 1097] train: loss: 0.1155363
[Epoch 18] ogbg-molhiv: 0.743193 val loss: 0.092834
[Epoch 18] ogbg-molhiv: 0.730953 test loss: 0.126077
[Epoch 19; Iter    24/ 1097] train: loss: 0.2347196
[Epoch 19; Iter    54/ 1097] train: loss: 0.1020625
[Epoch 19; Iter    84/ 1097] train: loss: 0.3015066
[Epoch 19; Iter   114/ 1097] train: loss: 0.0272313
[Epoch 19; Iter   144/ 1097] train: loss: 0.1444002
[Epoch 19; Iter   174/ 1097] train: loss: 0.0341997
[Epoch 19; Iter   204/ 1097] train: loss: 0.0250109
[Epoch 19; Iter   234/ 1097] train: loss: 0.0285319
[Epoch 19; Iter   264/ 1097] train: loss: 0.1384277
[Epoch 19; Iter   294/ 1097] train: loss: 0.1260740
[Epoch 19; Iter   324/ 1097] train: loss: 0.0266982
[Epoch 19; Iter   354/ 1097] train: loss: 0.2612220
[Epoch 19; Iter   384/ 1097] train: loss: 0.0260447
[Epoch 19; Iter   414/ 1097] train: loss: 0.0282951
[Epoch 19; Iter   444/ 1097] train: loss: 0.1321113
[Epoch 19; Iter   474/ 1097] train: loss: 0.1344213
[Epoch 19; Iter   504/ 1097] train: loss: 0.2447585
[Epoch 19; Iter   534/ 1097] train: loss: 0.1591261
[Epoch 19; Iter   564/ 1097] train: loss: 0.0186772
[Epoch 19; Iter   594/ 1097] train: loss: 0.0192679
[Epoch 19; Iter   624/ 1097] train: loss: 0.0481342
[Epoch 19; Iter   654/ 1097] train: loss: 0.1303286
[Epoch 19; Iter   684/ 1097] train: loss: 0.0273784
[Epoch 19; Iter   714/ 1097] train: loss: 0.1391539
[Epoch 19; Iter   744/ 1097] train: loss: 0.0261737
[Epoch 19; Iter   774/ 1097] train: loss: 0.2092542
[Epoch 19; Iter   804/ 1097] train: loss: 0.1036195
[Epoch 19; Iter   834/ 1097] train: loss: 0.1400065
[Epoch 19; Iter   864/ 1097] train: loss: 0.2803279
[Epoch 19; Iter   894/ 1097] train: loss: 0.2079961
[Epoch 19; Iter   924/ 1097] train: loss: 0.5260098
[Epoch 19; Iter   954/ 1097] train: loss: 0.1408958
[Epoch 19; Iter   984/ 1097] train: loss: 0.3267741
[Epoch 19; Iter  1014/ 1097] train: loss: 0.1539519
[Epoch 19; Iter  1044/ 1097] train: loss: 0.0352296
[Epoch 19; Iter  1074/ 1097] train: loss: 0.0349742
[Epoch 19] ogbg-molhiv: 0.830991 val loss: 0.074540
[Epoch 19] ogbg-molhiv: 0.754230 test loss: 0.118585
[Epoch 20; Iter     7/ 1097] train: loss: 0.0588088
[Epoch 20; Iter    37/ 1097] train: loss: 0.2735202
[Epoch 20; Iter    67/ 1097] train: loss: 0.0267412
[Epoch 20; Iter    97/ 1097] train: loss: 0.0280425
[Epoch 20; Iter   127/ 1097] train: loss: 0.0295748
[Epoch 20; Iter   157/ 1097] train: loss: 0.0628332
[Epoch 20; Iter   187/ 1097] train: loss: 0.0146359
[Epoch 20; Iter   217/ 1097] train: loss: 0.0234312
[Epoch 20; Iter   247/ 1097] train: loss: 0.0350030
[Epoch 20; Iter   277/ 1097] train: loss: 0.1046953
[Epoch 18; Iter   240/  960] train: loss: 0.1696101
[Epoch 18; Iter   270/  960] train: loss: 0.0556632
[Epoch 18; Iter   300/  960] train: loss: 0.0295196
[Epoch 18; Iter   330/  960] train: loss: 0.0209681
[Epoch 18; Iter   360/  960] train: loss: 0.2036645
[Epoch 18; Iter   390/  960] train: loss: 0.0574730
[Epoch 18; Iter   420/  960] train: loss: 0.0573861
[Epoch 18; Iter   450/  960] train: loss: 0.2591222
[Epoch 18; Iter   480/  960] train: loss: 0.0330511
[Epoch 18; Iter   510/  960] train: loss: 0.0316080
[Epoch 18; Iter   540/  960] train: loss: 0.0274028
[Epoch 18; Iter   570/  960] train: loss: 0.0273613
[Epoch 18; Iter   600/  960] train: loss: 0.1947720
[Epoch 18; Iter   630/  960] train: loss: 0.1768153
[Epoch 18; Iter   660/  960] train: loss: 0.0657180
[Epoch 18; Iter   690/  960] train: loss: 0.0321582
[Epoch 18; Iter   720/  960] train: loss: 0.0217875
[Epoch 18; Iter   750/  960] train: loss: 0.1533381
[Epoch 18; Iter   780/  960] train: loss: 0.2769102
[Epoch 18; Iter   810/  960] train: loss: 0.0404515
[Epoch 18; Iter   840/  960] train: loss: 0.2245933
[Epoch 18; Iter   870/  960] train: loss: 0.3532714
[Epoch 18; Iter   900/  960] train: loss: 0.1844797
[Epoch 18; Iter   930/  960] train: loss: 0.0329296
[Epoch 18; Iter   960/  960] train: loss: 0.5121168
[Epoch 18] ogbg-molhiv: 0.726863 val loss: 0.200471
[Epoch 18] ogbg-molhiv: 0.727658 test loss: 0.282608
[Epoch 19; Iter    30/  960] train: loss: 0.0408266
[Epoch 19; Iter    60/  960] train: loss: 0.2210331
[Epoch 19; Iter    90/  960] train: loss: 0.0385061
[Epoch 19; Iter   120/  960] train: loss: 0.0297440
[Epoch 19; Iter   150/  960] train: loss: 0.3289030
[Epoch 19; Iter   180/  960] train: loss: 0.0309121
[Epoch 19; Iter   210/  960] train: loss: 0.1573359
[Epoch 19; Iter   240/  960] train: loss: 0.0421772
[Epoch 19; Iter   270/  960] train: loss: 0.0247797
[Epoch 19; Iter   300/  960] train: loss: 0.0310129
[Epoch 19; Iter   330/  960] train: loss: 0.1077284
[Epoch 19; Iter   360/  960] train: loss: 0.0638549
[Epoch 19; Iter   390/  960] train: loss: 0.1005778
[Epoch 19; Iter   420/  960] train: loss: 0.0402373
[Epoch 19; Iter   450/  960] train: loss: 0.2189534
[Epoch 19; Iter   480/  960] train: loss: 0.0297582
[Epoch 19; Iter   510/  960] train: loss: 0.0201574
[Epoch 19; Iter   540/  960] train: loss: 0.1624186
[Epoch 19; Iter   570/  960] train: loss: 0.0514558
[Epoch 19; Iter   600/  960] train: loss: 0.0732530
[Epoch 19; Iter   630/  960] train: loss: 0.0644579
[Epoch 19; Iter   660/  960] train: loss: 0.2075508
[Epoch 19; Iter   690/  960] train: loss: 0.0411349
[Epoch 19; Iter   720/  960] train: loss: 0.0352783
[Epoch 19; Iter   750/  960] train: loss: 0.0741048
[Epoch 19; Iter   780/  960] train: loss: 0.0241813
[Epoch 19; Iter   810/  960] train: loss: 0.0366930
[Epoch 19; Iter   840/  960] train: loss: 0.0811849
[Epoch 19; Iter   870/  960] train: loss: 0.0734595
[Epoch 19; Iter   900/  960] train: loss: 0.2699267
[Epoch 19; Iter   930/  960] train: loss: 0.2259767
[Epoch 19; Iter   960/  960] train: loss: 0.0318917
[Epoch 19] ogbg-molhiv: 0.754567 val loss: 0.122001
[Epoch 19] ogbg-molhiv: 0.759654 test loss: 0.114353
[Epoch 20; Iter    30/  960] train: loss: 0.1919923
[Epoch 20; Iter    60/  960] train: loss: 0.1021534
[Epoch 20; Iter    90/  960] train: loss: 0.0592478
[Epoch 20; Iter   120/  960] train: loss: 0.0213231
[Epoch 20; Iter   150/  960] train: loss: 0.0976431
[Epoch 20; Iter   180/  960] train: loss: 0.2533572
[Epoch 20; Iter   210/  960] train: loss: 0.0235041
[Epoch 20; Iter   240/  960] train: loss: 0.0231968
[Epoch 20; Iter   270/  960] train: loss: 0.0267095
[Epoch 20; Iter   300/  960] train: loss: 0.1053021
[Epoch 20; Iter   330/  960] train: loss: 0.0187902
[Epoch 20; Iter   360/  960] train: loss: 0.4239609
[Epoch 20; Iter   390/  960] train: loss: 0.0219709
[Epoch 20; Iter   420/  960] train: loss: 0.0847642
[Epoch 20; Iter   450/  960] train: loss: 0.0306757
[Epoch 20; Iter   480/  960] train: loss: 0.0428196
[Epoch 20; Iter   510/  960] train: loss: 0.0628753
[Epoch 20; Iter   540/  960] train: loss: 0.2015055
[Epoch 20; Iter   570/  960] train: loss: 0.0303761
[Epoch 20; Iter   600/  960] train: loss: 0.1901607
[Epoch 20; Iter   630/  960] train: loss: 0.0806254
[Epoch 20; Iter   660/  960] train: loss: 0.1820055
[Epoch 20; Iter   690/  960] train: loss: 0.0325282
[Epoch 20; Iter   720/  960] train: loss: 0.2959764
[Epoch 20; Iter   750/  960] train: loss: 0.0889218
[Epoch 20; Iter   780/  960] train: loss: 0.0252613
[Epoch 20; Iter   810/  960] train: loss: 0.0419096
[Epoch 20; Iter   840/  960] train: loss: 0.0234794
[Epoch 20; Iter   870/  960] train: loss: 0.0265483
[Epoch 20; Iter   900/  960] train: loss: 0.2691742
[Epoch 20; Iter   930/  960] train: loss: 0.0394819
[Epoch 20; Iter   960/  960] train: loss: 0.0316756
[Epoch 20] ogbg-molhiv: 0.739597 val loss: 0.141013
[Epoch 20] ogbg-molhiv: 0.757785 test loss: 0.181934
[Epoch 21; Iter    30/  960] train: loss: 0.1895919
[Epoch 21; Iter    60/  960] train: loss: 0.0309370
[Epoch 21; Iter    90/  960] train: loss: 0.1535750
[Epoch 21; Iter   120/  960] train: loss: 0.0288413
[Epoch 21; Iter   150/  960] train: loss: 0.0267395
[Epoch 21; Iter   180/  960] train: loss: 0.1072343
[Epoch 21; Iter   210/  960] train: loss: 0.3508357
[Epoch 21; Iter   240/  960] train: loss: 0.0429595
[Epoch 21; Iter   270/  960] train: loss: 0.0596647
[Epoch 21; Iter   300/  960] train: loss: 0.0373195
[Epoch 21; Iter   330/  960] train: loss: 0.0247645
[Epoch 21; Iter   360/  960] train: loss: 0.1218960
[Epoch 21; Iter   390/  960] train: loss: 0.0732765
[Epoch 21; Iter   420/  960] train: loss: 0.1125163
[Epoch 21; Iter   450/  960] train: loss: 0.0255030
[Epoch 21; Iter   480/  960] train: loss: 0.0251599
[Epoch 21; Iter   510/  960] train: loss: 0.0300576
[Epoch 21; Iter   540/  960] train: loss: 0.1015349
[Epoch 21; Iter   570/  960] train: loss: 0.0212756
[Epoch 21; Iter   600/  960] train: loss: 0.0594744
[Epoch 21; Iter   630/  960] train: loss: 0.0220916
[Epoch 21; Iter   660/  960] train: loss: 0.0374830
[Epoch 21; Iter   690/  960] train: loss: 0.1763835
[Epoch 21; Iter   720/  960] train: loss: 0.0236260
[Epoch 21; Iter   750/  960] train: loss: 0.1257731
[Epoch 21; Iter   780/  960] train: loss: 0.1284188
[Epoch 21; Iter   810/  960] train: loss: 0.0187057
[Epoch 21; Iter   840/  960] train: loss: 0.0508986
[Epoch 21; Iter   870/  960] train: loss: 0.0275139
[Epoch 21; Iter   900/  960] train: loss: 0.2013339
[Epoch 21; Iter   930/  960] train: loss: 0.0463983
[Epoch 21; Iter   960/  960] train: loss: 0.2585953
[Epoch 21] ogbg-molhiv: 0.733611 val loss: 0.124755
[Epoch 21] ogbg-molhiv: 0.756555 test loss: 0.109518
[Epoch 22; Iter    30/  960] train: loss: 0.1397378
[Epoch 22; Iter    60/  960] train: loss: 0.0367201
[Epoch 22; Iter    90/  960] train: loss: 0.1189384
[Epoch 22; Iter   120/  960] train: loss: 0.0163655
[Epoch 22; Iter   150/  960] train: loss: 0.0928143
[Epoch 22; Iter   180/  960] train: loss: 0.3414676
[Epoch 22; Iter   210/  960] train: loss: 0.0520202
[Epoch 22; Iter   240/  960] train: loss: 0.0375845
[Epoch 22; Iter   270/  960] train: loss: 0.0502234
[Epoch 22; Iter   300/  960] train: loss: 0.0533631
[Epoch 22; Iter   330/  960] train: loss: 0.0275135
[Epoch 22; Iter   360/  960] train: loss: 0.0370145
[Epoch 22; Iter   390/  960] train: loss: 0.1121160
[Epoch 22; Iter   420/  960] train: loss: 0.0344028
[Epoch 22; Iter   450/  960] train: loss: 0.0909530
[Epoch 22; Iter   480/  960] train: loss: 0.1131686
[Epoch 22; Iter   510/  960] train: loss: 0.0261232
[Epoch 22; Iter   540/  960] train: loss: 0.0754686
[Epoch 22; Iter   570/  960] train: loss: 0.0211119
[Epoch 22; Iter   600/  960] train: loss: 0.0340686
[Epoch 22; Iter   630/  960] train: loss: 0.1946563
[Epoch 22; Iter   660/  960] train: loss: 0.1855284
[Epoch 22; Iter   690/  960] train: loss: 0.0216515
[Epoch 22; Iter   720/  960] train: loss: 0.4206133
[Epoch 22; Iter   750/  960] train: loss: 0.0289933
[Epoch 22; Iter   780/  960] train: loss: 0.0247520
[Epoch 22; Iter   810/  960] train: loss: 0.0972103
[Epoch 22; Iter   840/  960] train: loss: 0.0243500
[Epoch 18; Iter   240/  960] train: loss: 0.0923475
[Epoch 18; Iter   270/  960] train: loss: 0.0310966
[Epoch 18; Iter   300/  960] train: loss: 0.1255415
[Epoch 18; Iter   330/  960] train: loss: 0.1366307
[Epoch 18; Iter   360/  960] train: loss: 0.0777163
[Epoch 18; Iter   390/  960] train: loss: 0.0232021
[Epoch 18; Iter   420/  960] train: loss: 0.0460964
[Epoch 18; Iter   450/  960] train: loss: 0.0223346
[Epoch 18; Iter   480/  960] train: loss: 0.0922052
[Epoch 18; Iter   510/  960] train: loss: 0.1594106
[Epoch 18; Iter   540/  960] train: loss: 0.0336508
[Epoch 18; Iter   570/  960] train: loss: 0.0203665
[Epoch 18; Iter   600/  960] train: loss: 0.0860359
[Epoch 18; Iter   630/  960] train: loss: 0.0413597
[Epoch 18; Iter   660/  960] train: loss: 0.3647280
[Epoch 18; Iter   690/  960] train: loss: 0.1035570
[Epoch 18; Iter   720/  960] train: loss: 0.0382947
[Epoch 18; Iter   750/  960] train: loss: 0.0372766
[Epoch 18; Iter   780/  960] train: loss: 0.2431605
[Epoch 18; Iter   810/  960] train: loss: 0.2047918
[Epoch 18; Iter   840/  960] train: loss: 0.0240904
[Epoch 18; Iter   870/  960] train: loss: 0.0392616
[Epoch 18; Iter   900/  960] train: loss: 0.0315442
[Epoch 18; Iter   930/  960] train: loss: 0.0838553
[Epoch 18; Iter   960/  960] train: loss: 0.1402175
[Epoch 18] ogbg-molhiv: 0.763109 val loss: 0.125275
[Epoch 18] ogbg-molhiv: 0.754130 test loss: 0.286725
[Epoch 19; Iter    30/  960] train: loss: 0.0255396
[Epoch 19; Iter    60/  960] train: loss: 0.0350171
[Epoch 19; Iter    90/  960] train: loss: 0.0599656
[Epoch 19; Iter   120/  960] train: loss: 0.0266389
[Epoch 19; Iter   150/  960] train: loss: 0.0506921
[Epoch 19; Iter   180/  960] train: loss: 0.0294536
[Epoch 19; Iter   210/  960] train: loss: 0.1543976
[Epoch 19; Iter   240/  960] train: loss: 0.1143036
[Epoch 19; Iter   270/  960] train: loss: 0.0276596
[Epoch 19; Iter   300/  960] train: loss: 0.1230516
[Epoch 19; Iter   330/  960] train: loss: 0.3263860
[Epoch 19; Iter   360/  960] train: loss: 0.0952471
[Epoch 19; Iter   390/  960] train: loss: 0.1472280
[Epoch 19; Iter   420/  960] train: loss: 0.0787873
[Epoch 19; Iter   450/  960] train: loss: 0.2885268
[Epoch 19; Iter   480/  960] train: loss: 0.2253979
[Epoch 19; Iter   510/  960] train: loss: 0.1708659
[Epoch 19; Iter   540/  960] train: loss: 0.1005658
[Epoch 19; Iter   570/  960] train: loss: 0.0357582
[Epoch 19; Iter   600/  960] train: loss: 0.0250739
[Epoch 19; Iter   630/  960] train: loss: 0.0373842
[Epoch 19; Iter   660/  960] train: loss: 0.3087999
[Epoch 19; Iter   690/  960] train: loss: 0.3514949
[Epoch 19; Iter   720/  960] train: loss: 0.1686859
[Epoch 19; Iter   750/  960] train: loss: 0.1571203
[Epoch 19; Iter   780/  960] train: loss: 0.0573080
[Epoch 19; Iter   810/  960] train: loss: 0.0257085
[Epoch 19; Iter   840/  960] train: loss: 0.1897315
[Epoch 19; Iter   870/  960] train: loss: 0.0269002
[Epoch 19; Iter   900/  960] train: loss: 0.0311311
[Epoch 19; Iter   930/  960] train: loss: 0.0553992
[Epoch 19; Iter   960/  960] train: loss: 0.1565488
[Epoch 19] ogbg-molhiv: 0.766340 val loss: 0.155623
[Epoch 19] ogbg-molhiv: 0.750668 test loss: 0.129979
[Epoch 20; Iter    30/  960] train: loss: 0.0193772
[Epoch 20; Iter    60/  960] train: loss: 0.0352826
[Epoch 20; Iter    90/  960] train: loss: 0.0496907
[Epoch 20; Iter   120/  960] train: loss: 0.0190709
[Epoch 20; Iter   150/  960] train: loss: 0.1606012
[Epoch 20; Iter   180/  960] train: loss: 0.0472786
[Epoch 20; Iter   210/  960] train: loss: 0.0214014
[Epoch 20; Iter   240/  960] train: loss: 0.0791602
[Epoch 20; Iter   270/  960] train: loss: 0.0233397
[Epoch 20; Iter   300/  960] train: loss: 0.0334612
[Epoch 20; Iter   330/  960] train: loss: 0.1732358
[Epoch 20; Iter   360/  960] train: loss: 0.3977388
[Epoch 20; Iter   390/  960] train: loss: 0.1456770
[Epoch 20; Iter   420/  960] train: loss: 0.0258864
[Epoch 20; Iter   450/  960] train: loss: 0.0246926
[Epoch 20; Iter   480/  960] train: loss: 0.0251137
[Epoch 20; Iter   510/  960] train: loss: 0.1273319
[Epoch 20; Iter   540/  960] train: loss: 0.0702537
[Epoch 20; Iter   570/  960] train: loss: 0.0339187
[Epoch 20; Iter   600/  960] train: loss: 0.0493480
[Epoch 20; Iter   630/  960] train: loss: 0.0479300
[Epoch 20; Iter   660/  960] train: loss: 0.3829697
[Epoch 20; Iter   690/  960] train: loss: 0.0317809
[Epoch 20; Iter   720/  960] train: loss: 0.1950014
[Epoch 20; Iter   750/  960] train: loss: 0.0950216
[Epoch 20; Iter   780/  960] train: loss: 0.0845072
[Epoch 20; Iter   810/  960] train: loss: 0.0862455
[Epoch 20; Iter   840/  960] train: loss: 0.0728118
[Epoch 20; Iter   870/  960] train: loss: 0.0802419
[Epoch 20; Iter   900/  960] train: loss: 0.1797649
[Epoch 20; Iter   930/  960] train: loss: 0.0802195
[Epoch 20; Iter   960/  960] train: loss: 0.0233132
[Epoch 20] ogbg-molhiv: 0.749227 val loss: 0.162631
[Epoch 20] ogbg-molhiv: 0.754889 test loss: 0.174315
[Epoch 21; Iter    30/  960] train: loss: 0.1146494
[Epoch 21; Iter    60/  960] train: loss: 0.1071745
[Epoch 21; Iter    90/  960] train: loss: 0.1213493
[Epoch 21; Iter   120/  960] train: loss: 0.0353049
[Epoch 21; Iter   150/  960] train: loss: 0.0693823
[Epoch 21; Iter   180/  960] train: loss: 0.1483392
[Epoch 21; Iter   210/  960] train: loss: 0.0961399
[Epoch 21; Iter   240/  960] train: loss: 0.0917206
[Epoch 21; Iter   270/  960] train: loss: 0.0326398
[Epoch 21; Iter   300/  960] train: loss: 0.3986916
[Epoch 21; Iter   330/  960] train: loss: 0.1435147
[Epoch 21; Iter   360/  960] train: loss: 0.0325149
[Epoch 21; Iter   390/  960] train: loss: 0.0340874
[Epoch 21; Iter   420/  960] train: loss: 0.0300866
[Epoch 21; Iter   450/  960] train: loss: 0.1614631
[Epoch 21; Iter   480/  960] train: loss: 0.0295052
[Epoch 21; Iter   510/  960] train: loss: 0.0171648
[Epoch 21; Iter   540/  960] train: loss: 0.0299224
[Epoch 21; Iter   570/  960] train: loss: 0.0804399
[Epoch 21; Iter   600/  960] train: loss: 0.0305574
[Epoch 21; Iter   630/  960] train: loss: 0.1053252
[Epoch 21; Iter   660/  960] train: loss: 0.0332427
[Epoch 21; Iter   690/  960] train: loss: 0.0195242
[Epoch 21; Iter   720/  960] train: loss: 0.1148739
[Epoch 21; Iter   750/  960] train: loss: 0.2442923
[Epoch 21; Iter   780/  960] train: loss: 0.2131031
[Epoch 21; Iter   810/  960] train: loss: 0.0287610
[Epoch 21; Iter   840/  960] train: loss: 0.0344710
[Epoch 21; Iter   870/  960] train: loss: 0.0436892
[Epoch 21; Iter   900/  960] train: loss: 0.1300554
[Epoch 21; Iter   930/  960] train: loss: 0.0173124
[Epoch 21; Iter   960/  960] train: loss: 0.1864085
[Epoch 21] ogbg-molhiv: 0.756717 val loss: 0.177488
[Epoch 21] ogbg-molhiv: 0.763673 test loss: 0.102725
[Epoch 22; Iter    30/  960] train: loss: 0.0345636
[Epoch 22; Iter    60/  960] train: loss: 0.0330447
[Epoch 22; Iter    90/  960] train: loss: 0.0512672
[Epoch 22; Iter   120/  960] train: loss: 0.1558887
[Epoch 22; Iter   150/  960] train: loss: 0.0754567
[Epoch 22; Iter   180/  960] train: loss: 0.1090000
[Epoch 22; Iter   210/  960] train: loss: 0.0458028
[Epoch 22; Iter   240/  960] train: loss: 0.1598344
[Epoch 22; Iter   270/  960] train: loss: 0.0475347
[Epoch 22; Iter   300/  960] train: loss: 0.0667614
[Epoch 22; Iter   330/  960] train: loss: 0.0375010
[Epoch 22; Iter   360/  960] train: loss: 0.0286163
[Epoch 22; Iter   390/  960] train: loss: 0.0636006
[Epoch 22; Iter   420/  960] train: loss: 0.0261059
[Epoch 22; Iter   450/  960] train: loss: 0.0188408
[Epoch 22; Iter   480/  960] train: loss: 0.0282765
[Epoch 22; Iter   510/  960] train: loss: 0.0401749
[Epoch 22; Iter   540/  960] train: loss: 0.1106749
[Epoch 22; Iter   570/  960] train: loss: 0.0262449
[Epoch 22; Iter   600/  960] train: loss: 0.0188473
[Epoch 22; Iter   630/  960] train: loss: 0.0242742
[Epoch 22; Iter   660/  960] train: loss: 0.2330166
[Epoch 22; Iter   690/  960] train: loss: 0.1099219
[Epoch 22; Iter   720/  960] train: loss: 0.2793257
[Epoch 22; Iter   750/  960] train: loss: 0.0433387
[Epoch 22; Iter   780/  960] train: loss: 0.0401367
[Epoch 22; Iter   810/  960] train: loss: 0.1635938
[Epoch 22; Iter   840/  960] train: loss: 0.0703558
[Epoch 18; Iter   240/  960] train: loss: 0.2307618
[Epoch 18; Iter   270/  960] train: loss: 0.0766931
[Epoch 18; Iter   300/  960] train: loss: 0.1803752
[Epoch 18; Iter   330/  960] train: loss: 0.2148574
[Epoch 18; Iter   360/  960] train: loss: 0.3412047
[Epoch 18; Iter   390/  960] train: loss: 0.0338749
[Epoch 18; Iter   420/  960] train: loss: 0.1890779
[Epoch 18; Iter   450/  960] train: loss: 0.0981055
[Epoch 18; Iter   480/  960] train: loss: 0.0568024
[Epoch 18; Iter   510/  960] train: loss: 0.0345013
[Epoch 18; Iter   540/  960] train: loss: 0.1745712
[Epoch 18; Iter   570/  960] train: loss: 0.0241820
[Epoch 18; Iter   600/  960] train: loss: 0.2166303
[Epoch 18; Iter   630/  960] train: loss: 0.0195120
[Epoch 18; Iter   660/  960] train: loss: 0.0256984
[Epoch 18; Iter   690/  960] train: loss: 0.0466731
[Epoch 18; Iter   720/  960] train: loss: 0.2025191
[Epoch 18; Iter   750/  960] train: loss: 0.1017104
[Epoch 18; Iter   780/  960] train: loss: 0.1599278
[Epoch 18; Iter   810/  960] train: loss: 0.0479181
[Epoch 18; Iter   840/  960] train: loss: 0.0213063
[Epoch 18; Iter   870/  960] train: loss: 0.0285788
[Epoch 18; Iter   900/  960] train: loss: 0.1165562
[Epoch 18; Iter   930/  960] train: loss: 0.0483045
[Epoch 18; Iter   960/  960] train: loss: 0.0475176
[Epoch 18] ogbg-molhiv: 0.778190 val loss: 1.958471
[Epoch 18] ogbg-molhiv: 0.765974 test loss: 0.565703
[Epoch 19; Iter    30/  960] train: loss: 0.3557163
[Epoch 19; Iter    60/  960] train: loss: 0.0199471
[Epoch 19; Iter    90/  960] train: loss: 0.2255627
[Epoch 19; Iter   120/  960] train: loss: 0.0397412
[Epoch 19; Iter   150/  960] train: loss: 0.2052309
[Epoch 19; Iter   180/  960] train: loss: 0.0309960
[Epoch 19; Iter   210/  960] train: loss: 0.0221398
[Epoch 19; Iter   240/  960] train: loss: 0.0435616
[Epoch 19; Iter   270/  960] train: loss: 0.1685090
[Epoch 19; Iter   300/  960] train: loss: 0.1344815
[Epoch 19; Iter   330/  960] train: loss: 0.2838366
[Epoch 19; Iter   360/  960] train: loss: 0.0251472
[Epoch 19; Iter   390/  960] train: loss: 0.0254114
[Epoch 19; Iter   420/  960] train: loss: 0.0268589
[Epoch 19; Iter   450/  960] train: loss: 0.0302310
[Epoch 19; Iter   480/  960] train: loss: 0.0350956
[Epoch 19; Iter   510/  960] train: loss: 0.2395992
[Epoch 19; Iter   540/  960] train: loss: 0.1359250
[Epoch 19; Iter   570/  960] train: loss: 0.1466679
[Epoch 19; Iter   600/  960] train: loss: 0.3152524
[Epoch 19; Iter   630/  960] train: loss: 0.0401014
[Epoch 19; Iter   660/  960] train: loss: 0.0796235
[Epoch 19; Iter   690/  960] train: loss: 0.3422829
[Epoch 19; Iter   720/  960] train: loss: 0.1127158
[Epoch 19; Iter   750/  960] train: loss: 0.0671598
[Epoch 19; Iter   780/  960] train: loss: 0.2194130
[Epoch 19; Iter   810/  960] train: loss: 0.2744762
[Epoch 19; Iter   840/  960] train: loss: 0.1158732
[Epoch 19; Iter   870/  960] train: loss: 0.0883553
[Epoch 19; Iter   900/  960] train: loss: 0.2127576
[Epoch 19; Iter   930/  960] train: loss: 0.2806458
[Epoch 19; Iter   960/  960] train: loss: 0.0337611
[Epoch 19] ogbg-molhiv: 0.746401 val loss: 9.818708
[Epoch 19] ogbg-molhiv: 0.699927 test loss: 3.429131
[Epoch 20; Iter    30/  960] train: loss: 0.0475675
[Epoch 20; Iter    60/  960] train: loss: 0.0735986
[Epoch 20; Iter    90/  960] train: loss: 0.0755202
[Epoch 20; Iter   120/  960] train: loss: 0.0705034
[Epoch 20; Iter   150/  960] train: loss: 0.0513090
[Epoch 20; Iter   180/  960] train: loss: 0.0229702
[Epoch 20; Iter   210/  960] train: loss: 0.3281282
[Epoch 20; Iter   240/  960] train: loss: 0.0473585
[Epoch 20; Iter   270/  960] train: loss: 0.1300178
[Epoch 20; Iter   300/  960] train: loss: 0.1115512
[Epoch 20; Iter   330/  960] train: loss: 0.0217336
[Epoch 20; Iter   360/  960] train: loss: 0.0830814
[Epoch 20; Iter   390/  960] train: loss: 0.1147720
[Epoch 20; Iter   420/  960] train: loss: 0.1766737
[Epoch 20; Iter   450/  960] train: loss: 0.3335257
[Epoch 20; Iter   480/  960] train: loss: 0.4867341
[Epoch 20; Iter   510/  960] train: loss: 0.1570104
[Epoch 20; Iter   540/  960] train: loss: 0.1542272
[Epoch 20; Iter   570/  960] train: loss: 0.0372206
[Epoch 20; Iter   600/  960] train: loss: 0.0242863
[Epoch 20; Iter   630/  960] train: loss: 0.0479820
[Epoch 20; Iter   660/  960] train: loss: 0.1034873
[Epoch 20; Iter   690/  960] train: loss: 0.0241263
[Epoch 20; Iter   720/  960] train: loss: 0.0751705
[Epoch 20; Iter   750/  960] train: loss: 0.0504569
[Epoch 20; Iter   780/  960] train: loss: 0.0332072
[Epoch 20; Iter   810/  960] train: loss: 0.0226504
[Epoch 20; Iter   840/  960] train: loss: 0.1379211
[Epoch 20; Iter   870/  960] train: loss: 0.0227994
[Epoch 20; Iter   900/  960] train: loss: 0.0282909
[Epoch 20; Iter   930/  960] train: loss: 0.3383366
[Epoch 20; Iter   960/  960] train: loss: 0.0270483
[Epoch 20] ogbg-molhiv: 0.760252 val loss: 1.768457
[Epoch 20] ogbg-molhiv: 0.728582 test loss: 0.467247
[Epoch 21; Iter    30/  960] train: loss: 0.1407358
[Epoch 21; Iter    60/  960] train: loss: 0.0500761
[Epoch 21; Iter    90/  960] train: loss: 0.0283255
[Epoch 21; Iter   120/  960] train: loss: 0.0258864
[Epoch 21; Iter   150/  960] train: loss: 0.0713941
[Epoch 21; Iter   180/  960] train: loss: 0.2659050
[Epoch 21; Iter   210/  960] train: loss: 0.0489068
[Epoch 21; Iter   240/  960] train: loss: 0.0662285
[Epoch 21; Iter   270/  960] train: loss: 0.1162876
[Epoch 21; Iter   300/  960] train: loss: 0.0383757
[Epoch 21; Iter   330/  960] train: loss: 0.0301851
[Epoch 21; Iter   360/  960] train: loss: 0.2012318
[Epoch 21; Iter   390/  960] train: loss: 0.0431493
[Epoch 21; Iter   420/  960] train: loss: 0.0847829
[Epoch 21; Iter   450/  960] train: loss: 0.0618041
[Epoch 21; Iter   480/  960] train: loss: 0.1287277
[Epoch 21; Iter   510/  960] train: loss: 0.0179043
[Epoch 21; Iter   540/  960] train: loss: 0.0288795
[Epoch 21; Iter   570/  960] train: loss: 0.0431617
[Epoch 21; Iter   600/  960] train: loss: 0.1045185
[Epoch 21; Iter   630/  960] train: loss: 0.2326439
[Epoch 21; Iter   660/  960] train: loss: 0.1746856
[Epoch 21; Iter   690/  960] train: loss: 0.0843569
[Epoch 21; Iter   720/  960] train: loss: 0.0447871
[Epoch 21; Iter   750/  960] train: loss: 0.1219846
[Epoch 21; Iter   780/  960] train: loss: 0.2140468
[Epoch 21; Iter   810/  960] train: loss: 0.0882852
[Epoch 21; Iter   840/  960] train: loss: 0.0228028
[Epoch 21; Iter   870/  960] train: loss: 0.0517474
[Epoch 21; Iter   900/  960] train: loss: 0.0619578
[Epoch 21; Iter   930/  960] train: loss: 0.0473461
[Epoch 21; Iter   960/  960] train: loss: 0.0369265
[Epoch 21] ogbg-molhiv: 0.765450 val loss: 2.361716
[Epoch 21] ogbg-molhiv: 0.752456 test loss: 1.096636
[Epoch 22; Iter    30/  960] train: loss: 0.0228278
[Epoch 22; Iter    60/  960] train: loss: 0.0944020
[Epoch 22; Iter    90/  960] train: loss: 0.2421433
[Epoch 22; Iter   120/  960] train: loss: 0.2483255
[Epoch 22; Iter   150/  960] train: loss: 0.1574949
[Epoch 22; Iter   180/  960] train: loss: 0.0267387
[Epoch 22; Iter   210/  960] train: loss: 0.1786579
[Epoch 22; Iter   240/  960] train: loss: 0.0691158
[Epoch 22; Iter   270/  960] train: loss: 0.0203031
[Epoch 22; Iter   300/  960] train: loss: 0.1187104
[Epoch 22; Iter   330/  960] train: loss: 0.1203822
[Epoch 22; Iter   360/  960] train: loss: 0.1116170
[Epoch 22; Iter   390/  960] train: loss: 0.0247080
[Epoch 22; Iter   420/  960] train: loss: 0.0362738
[Epoch 22; Iter   450/  960] train: loss: 0.1726719
[Epoch 22; Iter   480/  960] train: loss: 0.1394940
[Epoch 22; Iter   510/  960] train: loss: 0.2023722
[Epoch 22; Iter   540/  960] train: loss: 0.1271362
[Epoch 22; Iter   570/  960] train: loss: 0.2569275
[Epoch 22; Iter   600/  960] train: loss: 0.0757656
[Epoch 22; Iter   630/  960] train: loss: 0.0412843
[Epoch 22; Iter   660/  960] train: loss: 0.0717860
[Epoch 22; Iter   690/  960] train: loss: 0.0539283
[Epoch 22; Iter   720/  960] train: loss: 0.0494183
[Epoch 22; Iter   750/  960] train: loss: 0.0931118
[Epoch 22; Iter   780/  960] train: loss: 0.1404794
[Epoch 22; Iter   810/  960] train: loss: 0.1738298
[Epoch 22; Iter   840/  960] train: loss: 0.2028818
[Epoch 20; Iter   773/  823] train: loss: 0.2406133
[Epoch 20; Iter   803/  823] train: loss: 0.0634474
[Epoch 20] ogbg-molhiv: 0.738825 val loss: 0.140515
[Epoch 20] ogbg-molhiv: 0.745161 test loss: 0.230059
[Epoch 21; Iter    10/  823] train: loss: 0.0426064
[Epoch 21; Iter    40/  823] train: loss: 0.1221266
[Epoch 21; Iter    70/  823] train: loss: 0.0863421
[Epoch 21; Iter   100/  823] train: loss: 0.1104428
[Epoch 21; Iter   130/  823] train: loss: 0.0245430
[Epoch 21; Iter   160/  823] train: loss: 0.0437359
[Epoch 21; Iter   190/  823] train: loss: 0.2338424
[Epoch 21; Iter   220/  823] train: loss: 0.0299229
[Epoch 21; Iter   250/  823] train: loss: 0.1457748
[Epoch 21; Iter   280/  823] train: loss: 0.0243940
[Epoch 21; Iter   310/  823] train: loss: 0.3698011
[Epoch 21; Iter   340/  823] train: loss: 0.0839063
[Epoch 21; Iter   370/  823] train: loss: 0.0399117
[Epoch 21; Iter   400/  823] train: loss: 0.1951751
[Epoch 21; Iter   430/  823] train: loss: 0.0378513
[Epoch 21; Iter   460/  823] train: loss: 0.0704896
[Epoch 21; Iter   490/  823] train: loss: 0.0222815
[Epoch 21; Iter   520/  823] train: loss: 0.0273904
[Epoch 21; Iter   550/  823] train: loss: 0.0308405
[Epoch 21; Iter   580/  823] train: loss: 0.0753775
[Epoch 21; Iter   610/  823] train: loss: 0.0501971
[Epoch 21; Iter   640/  823] train: loss: 0.1664298
[Epoch 21; Iter   670/  823] train: loss: 0.1022526
[Epoch 21; Iter   700/  823] train: loss: 0.1353729
[Epoch 21; Iter   730/  823] train: loss: 0.1403749
[Epoch 21; Iter   760/  823] train: loss: 0.1173084
[Epoch 21; Iter   790/  823] train: loss: 0.0286643
[Epoch 21; Iter   820/  823] train: loss: 0.2021964
[Epoch 21] ogbg-molhiv: 0.720948 val loss: 0.373632
[Epoch 21] ogbg-molhiv: 0.743521 test loss: 1.164128
[Epoch 22; Iter    27/  823] train: loss: 0.0324964
[Epoch 22; Iter    57/  823] train: loss: 0.0495012
[Epoch 22; Iter    87/  823] train: loss: 0.0494739
[Epoch 22; Iter   117/  823] train: loss: 0.0293644
[Epoch 22; Iter   147/  823] train: loss: 0.0219282
[Epoch 22; Iter   177/  823] train: loss: 0.0760363
[Epoch 22; Iter   207/  823] train: loss: 0.0390561
[Epoch 22; Iter   237/  823] train: loss: 0.0180668
[Epoch 22; Iter   267/  823] train: loss: 0.0485537
[Epoch 22; Iter   297/  823] train: loss: 0.0242910
[Epoch 22; Iter   327/  823] train: loss: 0.0558752
[Epoch 22; Iter   357/  823] train: loss: 0.2892466
[Epoch 22; Iter   387/  823] train: loss: 0.1682930
[Epoch 22; Iter   417/  823] train: loss: 0.2251918
[Epoch 22; Iter   447/  823] train: loss: 0.1207462
[Epoch 22; Iter   477/  823] train: loss: 0.1233116
[Epoch 22; Iter   507/  823] train: loss: 0.0463571
[Epoch 22; Iter   537/  823] train: loss: 0.0603005
[Epoch 22; Iter   567/  823] train: loss: 0.0900890
[Epoch 22; Iter   597/  823] train: loss: 0.0573084
[Epoch 22; Iter   627/  823] train: loss: 0.1456749
[Epoch 22; Iter   657/  823] train: loss: 0.2053226
[Epoch 22; Iter   687/  823] train: loss: 0.2980020
[Epoch 22; Iter   717/  823] train: loss: 0.0585710
[Epoch 22; Iter   747/  823] train: loss: 0.1693639
[Epoch 22; Iter   777/  823] train: loss: 0.0436011
[Epoch 22; Iter   807/  823] train: loss: 0.2883696
[Epoch 22] ogbg-molhiv: 0.719923 val loss: 0.162404
[Epoch 22] ogbg-molhiv: 0.739085 test loss: 0.365472
[Epoch 23; Iter    14/  823] train: loss: 0.0354670
[Epoch 23; Iter    44/  823] train: loss: 0.0189627
[Epoch 23; Iter    74/  823] train: loss: 0.0728960
[Epoch 23; Iter   104/  823] train: loss: 0.1160575
[Epoch 23; Iter   134/  823] train: loss: 0.1096887
[Epoch 23; Iter   164/  823] train: loss: 0.0477078
[Epoch 23; Iter   194/  823] train: loss: 0.0320434
[Epoch 23; Iter   224/  823] train: loss: 0.1367303
[Epoch 23; Iter   254/  823] train: loss: 0.0260978
[Epoch 23; Iter   284/  823] train: loss: 0.1281511
[Epoch 23; Iter   314/  823] train: loss: 0.0212147
[Epoch 23; Iter   344/  823] train: loss: 0.0309909
[Epoch 23; Iter   374/  823] train: loss: 0.1887463
[Epoch 23; Iter   404/  823] train: loss: 0.0234824
[Epoch 23; Iter   434/  823] train: loss: 0.1252917
[Epoch 23; Iter   464/  823] train: loss: 0.0259181
[Epoch 23; Iter   494/  823] train: loss: 0.0208852
[Epoch 23; Iter   524/  823] train: loss: 0.0613062
[Epoch 23; Iter   554/  823] train: loss: 0.0312322
[Epoch 23; Iter   584/  823] train: loss: 0.3448421
[Epoch 23; Iter   614/  823] train: loss: 0.0505902
[Epoch 23; Iter   644/  823] train: loss: 0.2370124
[Epoch 23; Iter   674/  823] train: loss: 0.0383550
[Epoch 23; Iter   704/  823] train: loss: 0.0762297
[Epoch 23; Iter   734/  823] train: loss: 0.0430738
[Epoch 23; Iter   764/  823] train: loss: 0.0325558
[Epoch 23; Iter   794/  823] train: loss: 0.3397875
[Epoch 23] ogbg-molhiv: 0.709420 val loss: 0.198964
[Epoch 23] ogbg-molhiv: 0.748110 test loss: 0.715105
[Epoch 24; Iter     1/  823] train: loss: 0.1415702
[Epoch 24; Iter    31/  823] train: loss: 0.0314152
[Epoch 24; Iter    61/  823] train: loss: 0.0216500
[Epoch 24; Iter    91/  823] train: loss: 0.0447066
[Epoch 24; Iter   121/  823] train: loss: 0.0196588
[Epoch 24; Iter   151/  823] train: loss: 0.0230070
[Epoch 24; Iter   181/  823] train: loss: 0.0220732
[Epoch 24; Iter   211/  823] train: loss: 0.0270550
[Epoch 24; Iter   241/  823] train: loss: 0.0675213
[Epoch 24; Iter   271/  823] train: loss: 0.0280837
[Epoch 24; Iter   301/  823] train: loss: 0.1883451
[Epoch 24; Iter   331/  823] train: loss: 0.3696860
[Epoch 24; Iter   361/  823] train: loss: 0.1072590
[Epoch 24; Iter   391/  823] train: loss: 0.1267753
[Epoch 24; Iter   421/  823] train: loss: 0.1278187
[Epoch 24; Iter   451/  823] train: loss: 0.0891483
[Epoch 24; Iter   481/  823] train: loss: 0.2024745
[Epoch 24; Iter   511/  823] train: loss: 0.2582737
[Epoch 24; Iter   541/  823] train: loss: 0.0598904
[Epoch 24; Iter   571/  823] train: loss: 0.0316455
[Epoch 24; Iter   601/  823] train: loss: 0.0211802
[Epoch 24; Iter   631/  823] train: loss: 0.0309688
[Epoch 24; Iter   661/  823] train: loss: 0.0181527
[Epoch 24; Iter   691/  823] train: loss: 0.1381835
[Epoch 24; Iter   721/  823] train: loss: 0.0715173
[Epoch 24; Iter   751/  823] train: loss: 0.2597355
[Epoch 24; Iter   781/  823] train: loss: 0.1911955
[Epoch 24; Iter   811/  823] train: loss: 0.3022511
[Epoch 24] ogbg-molhiv: 0.709764 val loss: 0.174956
[Epoch 24] ogbg-molhiv: 0.729821 test loss: 0.281691
[Epoch 25; Iter    18/  823] train: loss: 0.0395958
[Epoch 25; Iter    48/  823] train: loss: 0.0316078
[Epoch 25; Iter    78/  823] train: loss: 0.0626996
[Epoch 25; Iter   108/  823] train: loss: 0.0520569
[Epoch 25; Iter   138/  823] train: loss: 0.1929085
[Epoch 25; Iter   168/  823] train: loss: 0.1880397
[Epoch 25; Iter   198/  823] train: loss: 0.0531595
[Epoch 25; Iter   228/  823] train: loss: 0.3278466
[Epoch 25; Iter   258/  823] train: loss: 0.0462187
[Epoch 25; Iter   288/  823] train: loss: 0.0427192
[Epoch 25; Iter   318/  823] train: loss: 0.0264582
[Epoch 25; Iter   348/  823] train: loss: 0.0329051
[Epoch 25; Iter   378/  823] train: loss: 0.2273306
[Epoch 25; Iter   408/  823] train: loss: 0.0361501
[Epoch 25; Iter   438/  823] train: loss: 0.1595157
[Epoch 25; Iter   468/  823] train: loss: 0.1761438
[Epoch 25; Iter   498/  823] train: loss: 0.0167412
[Epoch 25; Iter   528/  823] train: loss: 0.0213044
[Epoch 25; Iter   558/  823] train: loss: 0.1548290
[Epoch 25; Iter   588/  823] train: loss: 0.0124969
[Epoch 25; Iter   618/  823] train: loss: 0.1807774
[Epoch 25; Iter   648/  823] train: loss: 0.2545580
[Epoch 25; Iter   678/  823] train: loss: 0.0699275
[Epoch 25; Iter   708/  823] train: loss: 0.0619725
[Epoch 25; Iter   738/  823] train: loss: 0.0278923
[Epoch 25; Iter   768/  823] train: loss: 0.0215598
[Epoch 25; Iter   798/  823] train: loss: 0.1940181
[Epoch 25] ogbg-molhiv: 0.717383 val loss: 0.317385
[Epoch 25] ogbg-molhiv: 0.747377 test loss: 0.995384
[Epoch 26; Iter     5/  823] train: loss: 0.0682962
[Epoch 26; Iter    35/  823] train: loss: 0.0355242
[Epoch 26; Iter    65/  823] train: loss: 0.0185292
[Epoch 26; Iter    95/  823] train: loss: 0.2221061
[Epoch 26; Iter   125/  823] train: loss: 0.0659286
[Epoch 26; Iter   155/  823] train: loss: 0.0294797
[Epoch 20; Iter   307/ 1097] train: loss: 0.0759518
[Epoch 20; Iter   337/ 1097] train: loss: 0.2170752
[Epoch 20; Iter   367/ 1097] train: loss: 0.4048352
[Epoch 20; Iter   397/ 1097] train: loss: 0.0492287
[Epoch 20; Iter   427/ 1097] train: loss: 0.0433664
[Epoch 20; Iter   457/ 1097] train: loss: 0.0641990
[Epoch 20; Iter   487/ 1097] train: loss: 0.1162904
[Epoch 20; Iter   517/ 1097] train: loss: 0.0713770
[Epoch 20; Iter   547/ 1097] train: loss: 0.1953576
[Epoch 20; Iter   577/ 1097] train: loss: 0.0379951
[Epoch 20; Iter   607/ 1097] train: loss: 0.2598737
[Epoch 20; Iter   637/ 1097] train: loss: 0.1110846
[Epoch 20; Iter   667/ 1097] train: loss: 0.1093866
[Epoch 20; Iter   697/ 1097] train: loss: 0.0324807
[Epoch 20; Iter   727/ 1097] train: loss: 0.1258023
[Epoch 20; Iter   757/ 1097] train: loss: 0.1535759
[Epoch 20; Iter   787/ 1097] train: loss: 0.0761190
[Epoch 20; Iter   817/ 1097] train: loss: 0.1886587
[Epoch 20; Iter   847/ 1097] train: loss: 0.0268271
[Epoch 20; Iter   877/ 1097] train: loss: 0.1664642
[Epoch 20; Iter   907/ 1097] train: loss: 0.2018102
[Epoch 20; Iter   937/ 1097] train: loss: 0.0583500
[Epoch 20; Iter   967/ 1097] train: loss: 0.0652645
[Epoch 20; Iter   997/ 1097] train: loss: 0.1199539
[Epoch 20; Iter  1027/ 1097] train: loss: 0.1552399
[Epoch 20; Iter  1057/ 1097] train: loss: 0.4169936
[Epoch 20; Iter  1087/ 1097] train: loss: 0.2454712
[Epoch 20] ogbg-molhiv: 0.824365 val loss: 0.366165
[Epoch 20] ogbg-molhiv: 0.771967 test loss: 0.247342
[Epoch 21; Iter    20/ 1097] train: loss: 0.0349087
[Epoch 21; Iter    50/ 1097] train: loss: 0.2103157
[Epoch 21; Iter    80/ 1097] train: loss: 0.0326737
[Epoch 21; Iter   110/ 1097] train: loss: 0.0462843
[Epoch 21; Iter   140/ 1097] train: loss: 0.1717364
[Epoch 21; Iter   170/ 1097] train: loss: 0.1193364
[Epoch 21; Iter   200/ 1097] train: loss: 0.0254698
[Epoch 21; Iter   230/ 1097] train: loss: 0.0672900
[Epoch 21; Iter   260/ 1097] train: loss: 0.2337340
[Epoch 21; Iter   290/ 1097] train: loss: 0.0845674
[Epoch 21; Iter   320/ 1097] train: loss: 0.1051127
[Epoch 21; Iter   350/ 1097] train: loss: 0.1958246
[Epoch 21; Iter   380/ 1097] train: loss: 0.0580832
[Epoch 21; Iter   410/ 1097] train: loss: 0.0384727
[Epoch 21; Iter   440/ 1097] train: loss: 0.2302276
[Epoch 21; Iter   470/ 1097] train: loss: 0.0832819
[Epoch 21; Iter   500/ 1097] train: loss: 0.2876660
[Epoch 21; Iter   530/ 1097] train: loss: 0.1809234
[Epoch 21; Iter   560/ 1097] train: loss: 0.0489090
[Epoch 21; Iter   590/ 1097] train: loss: 0.0272355
[Epoch 21; Iter   620/ 1097] train: loss: 0.2063293
[Epoch 21; Iter   650/ 1097] train: loss: 0.0496739
[Epoch 21; Iter   680/ 1097] train: loss: 0.0289985
[Epoch 21; Iter   710/ 1097] train: loss: 0.0184892
[Epoch 21; Iter   740/ 1097] train: loss: 0.0392196
[Epoch 21; Iter   770/ 1097] train: loss: 0.1625542
[Epoch 21; Iter   800/ 1097] train: loss: 0.0477484
[Epoch 21; Iter   830/ 1097] train: loss: 0.0759743
[Epoch 21; Iter   860/ 1097] train: loss: 0.0297225
[Epoch 21; Iter   890/ 1097] train: loss: 0.0497529
[Epoch 21; Iter   920/ 1097] train: loss: 0.0934040
[Epoch 21; Iter   950/ 1097] train: loss: 0.0460175
[Epoch 21; Iter   980/ 1097] train: loss: 0.2309618
[Epoch 21; Iter  1010/ 1097] train: loss: 0.1679554
[Epoch 21; Iter  1040/ 1097] train: loss: 0.0261370
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0212955
[Epoch 21] ogbg-molhiv: 0.798054 val loss: 0.432664
[Epoch 21] ogbg-molhiv: 0.728674 test loss: 0.265075
[Epoch 22; Iter     3/ 1097] train: loss: 0.0431253
[Epoch 22; Iter    33/ 1097] train: loss: 0.3791707
[Epoch 22; Iter    63/ 1097] train: loss: 0.2303277
[Epoch 22; Iter    93/ 1097] train: loss: 0.0324998
[Epoch 22; Iter   123/ 1097] train: loss: 0.1886307
[Epoch 22; Iter   153/ 1097] train: loss: 0.2961527
[Epoch 22; Iter   183/ 1097] train: loss: 0.1794580
[Epoch 22; Iter   213/ 1097] train: loss: 0.0402684
[Epoch 22; Iter   243/ 1097] train: loss: 0.0284182
[Epoch 22; Iter   273/ 1097] train: loss: 0.0639151
[Epoch 22; Iter   303/ 1097] train: loss: 0.0853607
[Epoch 22; Iter   333/ 1097] train: loss: 0.1524242
[Epoch 22; Iter   363/ 1097] train: loss: 0.0609771
[Epoch 22; Iter   393/ 1097] train: loss: 0.1508750
[Epoch 22; Iter   423/ 1097] train: loss: 0.0255306
[Epoch 22; Iter   453/ 1097] train: loss: 0.0337657
[Epoch 22; Iter   483/ 1097] train: loss: 0.1902502
[Epoch 22; Iter   513/ 1097] train: loss: 0.0440962
[Epoch 22; Iter   543/ 1097] train: loss: 0.0294879
[Epoch 22; Iter   573/ 1097] train: loss: 0.1148247
[Epoch 22; Iter   603/ 1097] train: loss: 0.0206557
[Epoch 22; Iter   633/ 1097] train: loss: 0.0301539
[Epoch 22; Iter   663/ 1097] train: loss: 0.0705151
[Epoch 22; Iter   693/ 1097] train: loss: 0.0207147
[Epoch 22; Iter   723/ 1097] train: loss: 0.0481372
[Epoch 22; Iter   753/ 1097] train: loss: 0.2030466
[Epoch 22; Iter   783/ 1097] train: loss: 0.1936544
[Epoch 22; Iter   813/ 1097] train: loss: 0.0201168
[Epoch 22; Iter   843/ 1097] train: loss: 0.0254969
[Epoch 22; Iter   873/ 1097] train: loss: 0.1382969
[Epoch 22; Iter   903/ 1097] train: loss: 0.0316929
[Epoch 22; Iter   933/ 1097] train: loss: 0.0242214
[Epoch 22; Iter   963/ 1097] train: loss: 0.2605142
[Epoch 22; Iter   993/ 1097] train: loss: 0.0803618
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0286003
[Epoch 22; Iter  1053/ 1097] train: loss: 0.1294989
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0189063
[Epoch 22] ogbg-molhiv: 0.818492 val loss: 0.714295
[Epoch 22] ogbg-molhiv: 0.744613 test loss: 0.579448
[Epoch 23; Iter    16/ 1097] train: loss: 0.0210972
[Epoch 23; Iter    46/ 1097] train: loss: 0.0824506
[Epoch 23; Iter    76/ 1097] train: loss: 0.0435916
[Epoch 23; Iter   106/ 1097] train: loss: 0.0254406
[Epoch 23; Iter   136/ 1097] train: loss: 0.1802909
[Epoch 23; Iter   166/ 1097] train: loss: 0.0584729
[Epoch 23; Iter   196/ 1097] train: loss: 0.3779446
[Epoch 23; Iter   226/ 1097] train: loss: 0.0913657
[Epoch 23; Iter   256/ 1097] train: loss: 0.0507666
[Epoch 23; Iter   286/ 1097] train: loss: 0.0277641
[Epoch 23; Iter   316/ 1097] train: loss: 0.3891622
[Epoch 23; Iter   346/ 1097] train: loss: 0.1777428
[Epoch 23; Iter   376/ 1097] train: loss: 0.2169679
[Epoch 23; Iter   406/ 1097] train: loss: 0.0872140
[Epoch 23; Iter   436/ 1097] train: loss: 0.1941264
[Epoch 23; Iter   466/ 1097] train: loss: 0.1426800
[Epoch 23; Iter   496/ 1097] train: loss: 0.0975770
[Epoch 23; Iter   526/ 1097] train: loss: 0.0247851
[Epoch 23; Iter   556/ 1097] train: loss: 0.1796378
[Epoch 23; Iter   586/ 1097] train: loss: 0.0330696
[Epoch 23; Iter   616/ 1097] train: loss: 0.0267410
[Epoch 23; Iter   646/ 1097] train: loss: 0.0250763
[Epoch 23; Iter   676/ 1097] train: loss: 0.0236375
[Epoch 23; Iter   706/ 1097] train: loss: 0.0618888
[Epoch 23; Iter   736/ 1097] train: loss: 0.1650427
[Epoch 23; Iter   766/ 1097] train: loss: 0.0347637
[Epoch 23; Iter   796/ 1097] train: loss: 0.2789969
[Epoch 23; Iter   826/ 1097] train: loss: 0.0392285
[Epoch 23; Iter   856/ 1097] train: loss: 0.2325430
[Epoch 23; Iter   886/ 1097] train: loss: 0.1022836
[Epoch 23; Iter   916/ 1097] train: loss: 0.0878835
[Epoch 23; Iter   946/ 1097] train: loss: 0.2444933
[Epoch 23; Iter   976/ 1097] train: loss: 0.0232802
[Epoch 23; Iter  1006/ 1097] train: loss: 0.2324053
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0547909
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1847824
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0392368
[Epoch 23] ogbg-molhiv: 0.807812 val loss: 6.266941
[Epoch 23] ogbg-molhiv: 0.699527 test loss: 1.323739
[Epoch 24; Iter    29/ 1097] train: loss: 0.0185911
[Epoch 24; Iter    59/ 1097] train: loss: 0.1344338
[Epoch 24; Iter    89/ 1097] train: loss: 0.0282502
[Epoch 24; Iter   119/ 1097] train: loss: 0.0737797
[Epoch 24; Iter   149/ 1097] train: loss: 0.3668453
[Epoch 24; Iter   179/ 1097] train: loss: 0.0402721
[Epoch 24; Iter   209/ 1097] train: loss: 0.0410096
[Epoch 24; Iter   239/ 1097] train: loss: 0.0790563
[Epoch 24; Iter   269/ 1097] train: loss: 0.0314267
[Epoch 24; Iter   299/ 1097] train: loss: 0.1168493
[Epoch 24; Iter   329/ 1097] train: loss: 0.0530753
[Epoch 24; Iter   359/ 1097] train: loss: 0.0756894
[Epoch 20; Iter   307/ 1097] train: loss: 0.0384797
[Epoch 20; Iter   337/ 1097] train: loss: 0.1444360
[Epoch 20; Iter   367/ 1097] train: loss: 0.0350369
[Epoch 20; Iter   397/ 1097] train: loss: 0.0299659
[Epoch 20; Iter   427/ 1097] train: loss: 0.3576447
[Epoch 20; Iter   457/ 1097] train: loss: 0.1199534
[Epoch 20; Iter   487/ 1097] train: loss: 0.0943241
[Epoch 20; Iter   517/ 1097] train: loss: 0.0480373
[Epoch 20; Iter   547/ 1097] train: loss: 0.0256375
[Epoch 20; Iter   577/ 1097] train: loss: 0.0184464
[Epoch 20; Iter   607/ 1097] train: loss: 0.0243011
[Epoch 20; Iter   637/ 1097] train: loss: 0.2480425
[Epoch 20; Iter   667/ 1097] train: loss: 0.3316975
[Epoch 20; Iter   697/ 1097] train: loss: 0.0250091
[Epoch 20; Iter   727/ 1097] train: loss: 0.0223257
[Epoch 20; Iter   757/ 1097] train: loss: 0.2370970
[Epoch 20; Iter   787/ 1097] train: loss: 0.0337942
[Epoch 20; Iter   817/ 1097] train: loss: 0.0367211
[Epoch 20; Iter   847/ 1097] train: loss: 0.2925041
[Epoch 20; Iter   877/ 1097] train: loss: 0.2092906
[Epoch 20; Iter   907/ 1097] train: loss: 0.0616527
[Epoch 20; Iter   937/ 1097] train: loss: 0.1430957
[Epoch 20; Iter   967/ 1097] train: loss: 0.0438310
[Epoch 20; Iter   997/ 1097] train: loss: 0.0322796
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0711542
[Epoch 20; Iter  1057/ 1097] train: loss: 0.1712683
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0491959
[Epoch 20] ogbg-molhiv: 0.773341 val loss: 0.302312
[Epoch 20] ogbg-molhiv: 0.777450 test loss: 0.285439
[Epoch 21; Iter    20/ 1097] train: loss: 0.0481883
[Epoch 21; Iter    50/ 1097] train: loss: 0.0288851
[Epoch 21; Iter    80/ 1097] train: loss: 0.0355024
[Epoch 21; Iter   110/ 1097] train: loss: 0.0346309
[Epoch 21; Iter   140/ 1097] train: loss: 0.2137221
[Epoch 21; Iter   170/ 1097] train: loss: 0.1647595
[Epoch 21; Iter   200/ 1097] train: loss: 0.0201008
[Epoch 21; Iter   230/ 1097] train: loss: 0.0688071
[Epoch 21; Iter   260/ 1097] train: loss: 0.0278624
[Epoch 21; Iter   290/ 1097] train: loss: 0.0532415
[Epoch 21; Iter   320/ 1097] train: loss: 0.1697983
[Epoch 21; Iter   350/ 1097] train: loss: 0.1618208
[Epoch 21; Iter   380/ 1097] train: loss: 0.0246667
[Epoch 21; Iter   410/ 1097] train: loss: 0.2820237
[Epoch 21; Iter   440/ 1097] train: loss: 0.3065719
[Epoch 21; Iter   470/ 1097] train: loss: 0.1331284
[Epoch 21; Iter   500/ 1097] train: loss: 0.1310048
[Epoch 21; Iter   530/ 1097] train: loss: 0.1023896
[Epoch 21; Iter   560/ 1097] train: loss: 0.1761233
[Epoch 21; Iter   590/ 1097] train: loss: 0.1504616
[Epoch 21; Iter   620/ 1097] train: loss: 0.2185814
[Epoch 21; Iter   650/ 1097] train: loss: 0.0256384
[Epoch 21; Iter   680/ 1097] train: loss: 0.0654872
[Epoch 21; Iter   710/ 1097] train: loss: 0.3113238
[Epoch 21; Iter   740/ 1097] train: loss: 0.0856737
[Epoch 21; Iter   770/ 1097] train: loss: 0.0662188
[Epoch 21; Iter   800/ 1097] train: loss: 0.2581063
[Epoch 21; Iter   830/ 1097] train: loss: 0.4463337
[Epoch 21; Iter   860/ 1097] train: loss: 0.0170319
[Epoch 21; Iter   890/ 1097] train: loss: 0.0435107
[Epoch 21; Iter   920/ 1097] train: loss: 0.1412588
[Epoch 21; Iter   950/ 1097] train: loss: 0.1873644
[Epoch 21; Iter   980/ 1097] train: loss: 0.1811428
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0422114
[Epoch 21; Iter  1040/ 1097] train: loss: 0.3155753
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0245805
[Epoch 21] ogbg-molhiv: 0.786073 val loss: 0.075023
[Epoch 21] ogbg-molhiv: 0.763514 test loss: 0.132018
[Epoch 22; Iter     3/ 1097] train: loss: 0.0347825
[Epoch 22; Iter    33/ 1097] train: loss: 0.0768408
[Epoch 22; Iter    63/ 1097] train: loss: 0.1666741
[Epoch 22; Iter    93/ 1097] train: loss: 0.0269058
[Epoch 22; Iter   123/ 1097] train: loss: 0.0230115
[Epoch 22; Iter   153/ 1097] train: loss: 0.0526606
[Epoch 22; Iter   183/ 1097] train: loss: 0.0544453
[Epoch 22; Iter   213/ 1097] train: loss: 0.0289785
[Epoch 22; Iter   243/ 1097] train: loss: 0.0299341
[Epoch 22; Iter   273/ 1097] train: loss: 0.1815428
[Epoch 22; Iter   303/ 1097] train: loss: 0.0279324
[Epoch 22; Iter   333/ 1097] train: loss: 0.0224406
[Epoch 22; Iter   363/ 1097] train: loss: 0.0506129
[Epoch 22; Iter   393/ 1097] train: loss: 0.0252072
[Epoch 22; Iter   423/ 1097] train: loss: 0.0478884
[Epoch 22; Iter   453/ 1097] train: loss: 0.1098576
[Epoch 22; Iter   483/ 1097] train: loss: 0.0441092
[Epoch 22; Iter   513/ 1097] train: loss: 0.0277553
[Epoch 22; Iter   543/ 1097] train: loss: 0.0955549
[Epoch 22; Iter   573/ 1097] train: loss: 0.0569314
[Epoch 22; Iter   603/ 1097] train: loss: 0.0702378
[Epoch 22; Iter   633/ 1097] train: loss: 0.0196222
[Epoch 22; Iter   663/ 1097] train: loss: 0.0608453
[Epoch 22; Iter   693/ 1097] train: loss: 0.0235898
[Epoch 22; Iter   723/ 1097] train: loss: 0.0230820
[Epoch 22; Iter   753/ 1097] train: loss: 0.0390282
[Epoch 22; Iter   783/ 1097] train: loss: 0.3084447
[Epoch 22; Iter   813/ 1097] train: loss: 0.0359389
[Epoch 22; Iter   843/ 1097] train: loss: 0.1693641
[Epoch 22; Iter   873/ 1097] train: loss: 0.0978028
[Epoch 22; Iter   903/ 1097] train: loss: 0.0319972
[Epoch 22; Iter   933/ 1097] train: loss: 0.0532025
[Epoch 22; Iter   963/ 1097] train: loss: 0.1789516
[Epoch 22; Iter   993/ 1097] train: loss: 0.0266612
[Epoch 22; Iter  1023/ 1097] train: loss: 0.0597694
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0914183
[Epoch 22; Iter  1083/ 1097] train: loss: 0.0345459
[Epoch 22] ogbg-molhiv: 0.790574 val loss: 0.077625
[Epoch 22] ogbg-molhiv: 0.783822 test loss: 0.113062
[Epoch 23; Iter    16/ 1097] train: loss: 0.1084606
[Epoch 23; Iter    46/ 1097] train: loss: 0.0324070
[Epoch 23; Iter    76/ 1097] train: loss: 0.0626053
[Epoch 23; Iter   106/ 1097] train: loss: 0.0222363
[Epoch 23; Iter   136/ 1097] train: loss: 0.1038566
[Epoch 23; Iter   166/ 1097] train: loss: 0.1813852
[Epoch 23; Iter   196/ 1097] train: loss: 0.2088676
[Epoch 23; Iter   226/ 1097] train: loss: 0.1165930
[Epoch 23; Iter   256/ 1097] train: loss: 0.0304095
[Epoch 23; Iter   286/ 1097] train: loss: 0.0672176
[Epoch 23; Iter   316/ 1097] train: loss: 0.0347961
[Epoch 23; Iter   346/ 1097] train: loss: 0.0476900
[Epoch 23; Iter   376/ 1097] train: loss: 0.1311478
[Epoch 23; Iter   406/ 1097] train: loss: 0.0593363
[Epoch 23; Iter   436/ 1097] train: loss: 0.1775497
[Epoch 23; Iter   466/ 1097] train: loss: 0.0564538
[Epoch 23; Iter   496/ 1097] train: loss: 0.0893765
[Epoch 23; Iter   526/ 1097] train: loss: 0.0262980
[Epoch 23; Iter   556/ 1097] train: loss: 0.0745250
[Epoch 23; Iter   586/ 1097] train: loss: 0.0490471
[Epoch 23; Iter   616/ 1097] train: loss: 0.0208725
[Epoch 23; Iter   646/ 1097] train: loss: 0.0310557
[Epoch 23; Iter   676/ 1097] train: loss: 0.2233839
[Epoch 23; Iter   706/ 1097] train: loss: 0.0403848
[Epoch 23; Iter   736/ 1097] train: loss: 0.0473306
[Epoch 23; Iter   766/ 1097] train: loss: 0.1908877
[Epoch 23; Iter   796/ 1097] train: loss: 0.1217505
[Epoch 23; Iter   826/ 1097] train: loss: 0.0933664
[Epoch 23; Iter   856/ 1097] train: loss: 0.0266955
[Epoch 23; Iter   886/ 1097] train: loss: 0.0336544
[Epoch 23; Iter   916/ 1097] train: loss: 0.0422740
[Epoch 23; Iter   946/ 1097] train: loss: 0.0302481
[Epoch 23; Iter   976/ 1097] train: loss: 0.0271334
[Epoch 23; Iter  1006/ 1097] train: loss: 0.1530057
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0818322
[Epoch 23; Iter  1066/ 1097] train: loss: 0.0238338
[Epoch 23; Iter  1096/ 1097] train: loss: 0.1781314
[Epoch 23] ogbg-molhiv: 0.727865 val loss: 0.106662
[Epoch 23] ogbg-molhiv: 0.725221 test loss: 0.142425
[Epoch 24; Iter    29/ 1097] train: loss: 0.0188024
[Epoch 24; Iter    59/ 1097] train: loss: 0.0758630
[Epoch 24; Iter    89/ 1097] train: loss: 0.3071546
[Epoch 24; Iter   119/ 1097] train: loss: 0.0449337
[Epoch 24; Iter   149/ 1097] train: loss: 0.1236351
[Epoch 24; Iter   179/ 1097] train: loss: 0.1775485
[Epoch 24; Iter   209/ 1097] train: loss: 0.0538771
[Epoch 24; Iter   239/ 1097] train: loss: 0.3179088
[Epoch 24; Iter   269/ 1097] train: loss: 0.0731820
[Epoch 24; Iter   299/ 1097] train: loss: 0.0269014
[Epoch 24; Iter   329/ 1097] train: loss: 0.3814151
[Epoch 24; Iter   359/ 1097] train: loss: 0.1694825
[Epoch 20; Iter   773/  823] train: loss: 0.0404468
[Epoch 20; Iter   803/  823] train: loss: 0.1524980
[Epoch 20] ogbg-molhiv: 0.719696 val loss: 0.156000
[Epoch 20] ogbg-molhiv: 0.738276 test loss: 0.107825
[Epoch 21; Iter    10/  823] train: loss: 0.2569156
[Epoch 21; Iter    40/  823] train: loss: 0.0249307
[Epoch 21; Iter    70/  823] train: loss: 0.2140937
[Epoch 21; Iter   100/  823] train: loss: 0.1289658
[Epoch 21; Iter   130/  823] train: loss: 0.0425558
[Epoch 21; Iter   160/  823] train: loss: 0.1571165
[Epoch 21; Iter   190/  823] train: loss: 0.0447983
[Epoch 21; Iter   220/  823] train: loss: 0.0149362
[Epoch 21; Iter   250/  823] train: loss: 0.0393715
[Epoch 21; Iter   280/  823] train: loss: 0.5101629
[Epoch 21; Iter   310/  823] train: loss: 0.0219906
[Epoch 21; Iter   340/  823] train: loss: 0.0237479
[Epoch 21; Iter   370/  823] train: loss: 0.0423637
[Epoch 21; Iter   400/  823] train: loss: 0.4372063
[Epoch 21; Iter   430/  823] train: loss: 0.0264108
[Epoch 21; Iter   460/  823] train: loss: 0.0304463
[Epoch 21; Iter   490/  823] train: loss: 0.0483120
[Epoch 21; Iter   520/  823] train: loss: 0.1748805
[Epoch 21; Iter   550/  823] train: loss: 0.0465053
[Epoch 21; Iter   580/  823] train: loss: 0.0651455
[Epoch 21; Iter   610/  823] train: loss: 0.2192548
[Epoch 21; Iter   640/  823] train: loss: 0.0334760
[Epoch 21; Iter   670/  823] train: loss: 0.0318730
[Epoch 21; Iter   700/  823] train: loss: 0.0281775
[Epoch 21; Iter   730/  823] train: loss: 0.1162406
[Epoch 21; Iter   760/  823] train: loss: 0.1468786
[Epoch 21; Iter   790/  823] train: loss: 0.0548530
[Epoch 21; Iter   820/  823] train: loss: 0.0519874
[Epoch 21] ogbg-molhiv: 0.714682 val loss: 0.153359
[Epoch 21] ogbg-molhiv: 0.766497 test loss: 0.174269
[Epoch 22; Iter    27/  823] train: loss: 0.1029965
[Epoch 22; Iter    57/  823] train: loss: 0.0153840
[Epoch 22; Iter    87/  823] train: loss: 0.0580769
[Epoch 22; Iter   117/  823] train: loss: 0.0960978
[Epoch 22; Iter   147/  823] train: loss: 0.0393490
[Epoch 22; Iter   177/  823] train: loss: 0.0985196
[Epoch 22; Iter   207/  823] train: loss: 0.0451067
[Epoch 22; Iter   237/  823] train: loss: 0.0829301
[Epoch 22; Iter   267/  823] train: loss: 0.1493386
[Epoch 22; Iter   297/  823] train: loss: 0.0415445
[Epoch 22; Iter   327/  823] train: loss: 0.2114825
[Epoch 22; Iter   357/  823] train: loss: 0.1914803
[Epoch 22; Iter   387/  823] train: loss: 0.0220884
[Epoch 22; Iter   417/  823] train: loss: 0.1385069
[Epoch 22; Iter   447/  823] train: loss: 0.0482802
[Epoch 22; Iter   477/  823] train: loss: 0.2395881
[Epoch 22; Iter   507/  823] train: loss: 0.1095656
[Epoch 22; Iter   537/  823] train: loss: 0.0299845
[Epoch 22; Iter   567/  823] train: loss: 0.1060308
[Epoch 22; Iter   597/  823] train: loss: 0.3948116
[Epoch 22; Iter   627/  823] train: loss: 0.0774920
[Epoch 22; Iter   657/  823] train: loss: 0.3675704
[Epoch 22; Iter   687/  823] train: loss: 0.1334908
[Epoch 22; Iter   717/  823] train: loss: 0.0239831
[Epoch 22; Iter   747/  823] train: loss: 0.1714710
[Epoch 22; Iter   777/  823] train: loss: 0.3535700
[Epoch 22; Iter   807/  823] train: loss: 0.1761865
[Epoch 22] ogbg-molhiv: 0.698020 val loss: 0.170737
[Epoch 22] ogbg-molhiv: 0.723986 test loss: 0.245518
[Epoch 23; Iter    14/  823] train: loss: 0.0237745
[Epoch 23; Iter    44/  823] train: loss: 0.2424339
[Epoch 23; Iter    74/  823] train: loss: 0.1773883
[Epoch 23; Iter   104/  823] train: loss: 0.0462270
[Epoch 23; Iter   134/  823] train: loss: 0.0291329
[Epoch 23; Iter   164/  823] train: loss: 0.0973792
[Epoch 23; Iter   194/  823] train: loss: 0.0973942
[Epoch 23; Iter   224/  823] train: loss: 0.2543916
[Epoch 23; Iter   254/  823] train: loss: 0.0245432
[Epoch 23; Iter   284/  823] train: loss: 0.2122154
[Epoch 23; Iter   314/  823] train: loss: 0.0187636
[Epoch 23; Iter   344/  823] train: loss: 0.0249263
[Epoch 23; Iter   374/  823] train: loss: 0.2808224
[Epoch 23; Iter   404/  823] train: loss: 0.0596040
[Epoch 23; Iter   434/  823] train: loss: 0.0180686
[Epoch 23; Iter   464/  823] train: loss: 0.1345128
[Epoch 23; Iter   494/  823] train: loss: 0.0177343
[Epoch 23; Iter   524/  823] train: loss: 0.2005530
[Epoch 23; Iter   554/  823] train: loss: 0.0495479
[Epoch 23; Iter   584/  823] train: loss: 0.1102697
[Epoch 23; Iter   614/  823] train: loss: 0.0228818
[Epoch 23; Iter   644/  823] train: loss: 0.0676203
[Epoch 23; Iter   674/  823] train: loss: 0.2423818
[Epoch 23; Iter   704/  823] train: loss: 0.0873120
[Epoch 23; Iter   734/  823] train: loss: 0.1776602
[Epoch 23; Iter   764/  823] train: loss: 0.0333525
[Epoch 23; Iter   794/  823] train: loss: 0.0220991
[Epoch 23] ogbg-molhiv: 0.717118 val loss: 0.154065
[Epoch 23] ogbg-molhiv: 0.740292 test loss: 0.127244
[Epoch 24; Iter     1/  823] train: loss: 0.0349790
[Epoch 24; Iter    31/  823] train: loss: 0.3063576
[Epoch 24; Iter    61/  823] train: loss: 0.1971986
[Epoch 24; Iter    91/  823] train: loss: 0.2132532
[Epoch 24; Iter   121/  823] train: loss: 0.1484845
[Epoch 24; Iter   151/  823] train: loss: 0.1736709
[Epoch 24; Iter   181/  823] train: loss: 0.2088259
[Epoch 24; Iter   211/  823] train: loss: 0.0162791
[Epoch 24; Iter   241/  823] train: loss: 0.1017598
[Epoch 24; Iter   271/  823] train: loss: 0.0272075
[Epoch 24; Iter   301/  823] train: loss: 0.0568195
[Epoch 24; Iter   331/  823] train: loss: 0.0918056
[Epoch 24; Iter   361/  823] train: loss: 0.0561692
[Epoch 24; Iter   391/  823] train: loss: 0.0336540
[Epoch 24; Iter   421/  823] train: loss: 0.0186999
[Epoch 24; Iter   451/  823] train: loss: 0.1503022
[Epoch 24; Iter   481/  823] train: loss: 0.1483034
[Epoch 24; Iter   511/  823] train: loss: 0.0406883
[Epoch 24; Iter   541/  823] train: loss: 0.0661634
[Epoch 24; Iter   571/  823] train: loss: 0.0533936
[Epoch 24; Iter   601/  823] train: loss: 0.0367578
[Epoch 24; Iter   631/  823] train: loss: 0.1243765
[Epoch 24; Iter   661/  823] train: loss: 0.0177953
[Epoch 24; Iter   691/  823] train: loss: 0.0255925
[Epoch 24; Iter   721/  823] train: loss: 0.3032402
[Epoch 24; Iter   751/  823] train: loss: 0.1440440
[Epoch 24; Iter   781/  823] train: loss: 0.0350882
[Epoch 24; Iter   811/  823] train: loss: 0.0532496
[Epoch 24] ogbg-molhiv: 0.727674 val loss: 0.150218
[Epoch 24] ogbg-molhiv: 0.753311 test loss: 0.109283
[Epoch 25; Iter    18/  823] train: loss: 0.1407322
[Epoch 25; Iter    48/  823] train: loss: 0.2067029
[Epoch 25; Iter    78/  823] train: loss: 0.0283138
[Epoch 25; Iter   108/  823] train: loss: 0.0305280
[Epoch 25; Iter   138/  823] train: loss: 0.2268527
[Epoch 25; Iter   168/  823] train: loss: 0.0240408
[Epoch 25; Iter   198/  823] train: loss: 0.1174624
[Epoch 25; Iter   228/  823] train: loss: 0.2199035
[Epoch 25; Iter   258/  823] train: loss: 0.1217031
[Epoch 25; Iter   288/  823] train: loss: 0.0721974
[Epoch 25; Iter   318/  823] train: loss: 0.0318974
[Epoch 25; Iter   348/  823] train: loss: 0.1270341
[Epoch 25; Iter   378/  823] train: loss: 0.1484392
[Epoch 25; Iter   408/  823] train: loss: 0.1889831
[Epoch 25; Iter   438/  823] train: loss: 0.0841283
[Epoch 25; Iter   468/  823] train: loss: 0.0172630
[Epoch 25; Iter   498/  823] train: loss: 0.0570497
[Epoch 25; Iter   528/  823] train: loss: 0.0224214
[Epoch 25; Iter   558/  823] train: loss: 0.0444202
[Epoch 25; Iter   588/  823] train: loss: 0.1925039
[Epoch 25; Iter   618/  823] train: loss: 0.0660060
[Epoch 25; Iter   648/  823] train: loss: 0.1528244
[Epoch 25; Iter   678/  823] train: loss: 0.4213738
[Epoch 25; Iter   708/  823] train: loss: 0.0446606
[Epoch 25; Iter   738/  823] train: loss: 0.0653391
[Epoch 25; Iter   768/  823] train: loss: 0.0124351
[Epoch 25; Iter   798/  823] train: loss: 0.0319281
[Epoch 25] ogbg-molhiv: 0.718388 val loss: 0.175038
[Epoch 25] ogbg-molhiv: 0.742108 test loss: 0.120233
[Epoch 26; Iter     5/  823] train: loss: 0.3919056
[Epoch 26; Iter    35/  823] train: loss: 0.2318620
[Epoch 26; Iter    65/  823] train: loss: 0.1503290
[Epoch 26; Iter    95/  823] train: loss: 0.1337802
[Epoch 26; Iter   125/  823] train: loss: 0.2163358
[Epoch 26; Iter   155/  823] train: loss: 0.0253349
[Epoch 20; Iter   307/ 1097] train: loss: 0.1633679
[Epoch 20; Iter   337/ 1097] train: loss: 0.1582126
[Epoch 20; Iter   367/ 1097] train: loss: 0.0405457
[Epoch 20; Iter   397/ 1097] train: loss: 0.0337595
[Epoch 20; Iter   427/ 1097] train: loss: 0.0162316
[Epoch 20; Iter   457/ 1097] train: loss: 0.1409997
[Epoch 20; Iter   487/ 1097] train: loss: 0.1695321
[Epoch 20; Iter   517/ 1097] train: loss: 0.0320811
[Epoch 20; Iter   547/ 1097] train: loss: 0.1534262
[Epoch 20; Iter   577/ 1097] train: loss: 0.0214867
[Epoch 20; Iter   607/ 1097] train: loss: 0.0189765
[Epoch 20; Iter   637/ 1097] train: loss: 0.0351985
[Epoch 20; Iter   667/ 1097] train: loss: 0.2136413
[Epoch 20; Iter   697/ 1097] train: loss: 0.0906451
[Epoch 20; Iter   727/ 1097] train: loss: 0.1078795
[Epoch 20; Iter   757/ 1097] train: loss: 0.0173600
[Epoch 20; Iter   787/ 1097] train: loss: 0.0264493
[Epoch 20; Iter   817/ 1097] train: loss: 0.1192115
[Epoch 20; Iter   847/ 1097] train: loss: 0.0328745
[Epoch 20; Iter   877/ 1097] train: loss: 0.1435462
[Epoch 20; Iter   907/ 1097] train: loss: 0.2349509
[Epoch 20; Iter   937/ 1097] train: loss: 0.0172823
[Epoch 20; Iter   967/ 1097] train: loss: 0.0884388
[Epoch 20; Iter   997/ 1097] train: loss: 0.1304158
[Epoch 20; Iter  1027/ 1097] train: loss: 0.0316457
[Epoch 20; Iter  1057/ 1097] train: loss: 0.0553759
[Epoch 20; Iter  1087/ 1097] train: loss: 0.0247422
[Epoch 20] ogbg-molhiv: 0.813866 val loss: 0.113636
[Epoch 20] ogbg-molhiv: 0.754692 test loss: 0.115516
[Epoch 21; Iter    20/ 1097] train: loss: 0.0237990
[Epoch 21; Iter    50/ 1097] train: loss: 0.2312318
[Epoch 21; Iter    80/ 1097] train: loss: 0.0440411
[Epoch 21; Iter   110/ 1097] train: loss: 0.0482074
[Epoch 21; Iter   140/ 1097] train: loss: 0.1334821
[Epoch 21; Iter   170/ 1097] train: loss: 0.1440662
[Epoch 21; Iter   200/ 1097] train: loss: 0.1441502
[Epoch 21; Iter   230/ 1097] train: loss: 0.1585799
[Epoch 21; Iter   260/ 1097] train: loss: 0.1956731
[Epoch 21; Iter   290/ 1097] train: loss: 0.1919216
[Epoch 21; Iter   320/ 1097] train: loss: 0.2628069
[Epoch 21; Iter   350/ 1097] train: loss: 0.0187993
[Epoch 21; Iter   380/ 1097] train: loss: 0.0488142
[Epoch 21; Iter   410/ 1097] train: loss: 0.0723558
[Epoch 21; Iter   440/ 1097] train: loss: 0.1133730
[Epoch 21; Iter   470/ 1097] train: loss: 0.1214610
[Epoch 21; Iter   500/ 1097] train: loss: 0.0227979
[Epoch 21; Iter   530/ 1097] train: loss: 0.0228778
[Epoch 21; Iter   560/ 1097] train: loss: 0.0359510
[Epoch 21; Iter   590/ 1097] train: loss: 0.1731501
[Epoch 21; Iter   620/ 1097] train: loss: 0.1509816
[Epoch 21; Iter   650/ 1097] train: loss: 0.2213881
[Epoch 21; Iter   680/ 1097] train: loss: 0.0632554
[Epoch 21; Iter   710/ 1097] train: loss: 0.0317930
[Epoch 21; Iter   740/ 1097] train: loss: 0.0540482
[Epoch 21; Iter   770/ 1097] train: loss: 0.0551159
[Epoch 21; Iter   800/ 1097] train: loss: 0.0401318
[Epoch 21; Iter   830/ 1097] train: loss: 0.1888841
[Epoch 21; Iter   860/ 1097] train: loss: 0.0454547
[Epoch 21; Iter   890/ 1097] train: loss: 0.0236690
[Epoch 21; Iter   920/ 1097] train: loss: 0.1357593
[Epoch 21; Iter   950/ 1097] train: loss: 0.0395824
[Epoch 21; Iter   980/ 1097] train: loss: 0.0229479
[Epoch 21; Iter  1010/ 1097] train: loss: 0.0236946
[Epoch 21; Iter  1040/ 1097] train: loss: 0.1563823
[Epoch 21; Iter  1070/ 1097] train: loss: 0.0370563
[Epoch 21] ogbg-molhiv: 0.820293 val loss: 0.124400
[Epoch 21] ogbg-molhiv: 0.766940 test loss: 0.114990
[Epoch 22; Iter     3/ 1097] train: loss: 0.1374613
[Epoch 22; Iter    33/ 1097] train: loss: 0.0238389
[Epoch 22; Iter    63/ 1097] train: loss: 0.0509411
[Epoch 22; Iter    93/ 1097] train: loss: 0.0434598
[Epoch 22; Iter   123/ 1097] train: loss: 0.0707780
[Epoch 22; Iter   153/ 1097] train: loss: 0.0508950
[Epoch 22; Iter   183/ 1097] train: loss: 0.0308815
[Epoch 22; Iter   213/ 1097] train: loss: 0.1353578
[Epoch 22; Iter   243/ 1097] train: loss: 0.1521333
[Epoch 22; Iter   273/ 1097] train: loss: 0.1647282
[Epoch 22; Iter   303/ 1097] train: loss: 0.1501414
[Epoch 22; Iter   333/ 1097] train: loss: 0.0287165
[Epoch 22; Iter   363/ 1097] train: loss: 0.2768609
[Epoch 22; Iter   393/ 1097] train: loss: 0.0319897
[Epoch 22; Iter   423/ 1097] train: loss: 0.0540400
[Epoch 22; Iter   453/ 1097] train: loss: 0.0135853
[Epoch 22; Iter   483/ 1097] train: loss: 0.0913835
[Epoch 22; Iter   513/ 1097] train: loss: 0.4325496
[Epoch 22; Iter   543/ 1097] train: loss: 0.1410353
[Epoch 22; Iter   573/ 1097] train: loss: 0.0606623
[Epoch 22; Iter   603/ 1097] train: loss: 0.0319044
[Epoch 22; Iter   633/ 1097] train: loss: 0.0223231
[Epoch 22; Iter   663/ 1097] train: loss: 0.0365594
[Epoch 22; Iter   693/ 1097] train: loss: 0.1601581
[Epoch 22; Iter   723/ 1097] train: loss: 0.2019242
[Epoch 22; Iter   753/ 1097] train: loss: 0.2327008
[Epoch 22; Iter   783/ 1097] train: loss: 0.0275442
[Epoch 22; Iter   813/ 1097] train: loss: 0.1698862
[Epoch 22; Iter   843/ 1097] train: loss: 0.0310608
[Epoch 22; Iter   873/ 1097] train: loss: 0.1441360
[Epoch 22; Iter   903/ 1097] train: loss: 0.2105766
[Epoch 22; Iter   933/ 1097] train: loss: 0.0282392
[Epoch 22; Iter   963/ 1097] train: loss: 0.2809891
[Epoch 22; Iter   993/ 1097] train: loss: 0.2353135
[Epoch 22; Iter  1023/ 1097] train: loss: 0.3894172
[Epoch 22; Iter  1053/ 1097] train: loss: 0.0178531
[Epoch 22; Iter  1083/ 1097] train: loss: 0.1128246
[Epoch 22] ogbg-molhiv: 0.755628 val loss: 0.084491
[Epoch 22] ogbg-molhiv: 0.729728 test loss: 0.118559
[Epoch 23; Iter    16/ 1097] train: loss: 0.0951498
[Epoch 23; Iter    46/ 1097] train: loss: 0.2380370
[Epoch 23; Iter    76/ 1097] train: loss: 0.1154134
[Epoch 23; Iter   106/ 1097] train: loss: 0.1869825
[Epoch 23; Iter   136/ 1097] train: loss: 0.0979901
[Epoch 23; Iter   166/ 1097] train: loss: 0.1815917
[Epoch 23; Iter   196/ 1097] train: loss: 0.1174623
[Epoch 23; Iter   226/ 1097] train: loss: 0.0636590
[Epoch 23; Iter   256/ 1097] train: loss: 0.1523606
[Epoch 23; Iter   286/ 1097] train: loss: 0.0263816
[Epoch 23; Iter   316/ 1097] train: loss: 0.0480059
[Epoch 23; Iter   346/ 1097] train: loss: 0.0299418
[Epoch 23; Iter   376/ 1097] train: loss: 0.0237194
[Epoch 23; Iter   406/ 1097] train: loss: 0.1934955
[Epoch 23; Iter   436/ 1097] train: loss: 0.0603387
[Epoch 23; Iter   466/ 1097] train: loss: 0.0202910
[Epoch 23; Iter   496/ 1097] train: loss: 0.1857125
[Epoch 23; Iter   526/ 1097] train: loss: 0.0515104
[Epoch 23; Iter   556/ 1097] train: loss: 0.0280769
[Epoch 23; Iter   586/ 1097] train: loss: 0.1444896
[Epoch 23; Iter   616/ 1097] train: loss: 0.1070198
[Epoch 23; Iter   646/ 1097] train: loss: 0.1575769
[Epoch 23; Iter   676/ 1097] train: loss: 0.1063209
[Epoch 23; Iter   706/ 1097] train: loss: 0.0251784
[Epoch 23; Iter   736/ 1097] train: loss: 0.2353632
[Epoch 23; Iter   766/ 1097] train: loss: 0.1392878
[Epoch 23; Iter   796/ 1097] train: loss: 0.0473424
[Epoch 23; Iter   826/ 1097] train: loss: 0.2250511
[Epoch 23; Iter   856/ 1097] train: loss: 0.2248841
[Epoch 23; Iter   886/ 1097] train: loss: 0.1450322
[Epoch 23; Iter   916/ 1097] train: loss: 0.2761359
[Epoch 23; Iter   946/ 1097] train: loss: 0.0312308
[Epoch 23; Iter   976/ 1097] train: loss: 0.2366078
[Epoch 23; Iter  1006/ 1097] train: loss: 0.0187088
[Epoch 23; Iter  1036/ 1097] train: loss: 0.0263886
[Epoch 23; Iter  1066/ 1097] train: loss: 0.1878721
[Epoch 23; Iter  1096/ 1097] train: loss: 0.0965749
[Epoch 23] ogbg-molhiv: 0.811649 val loss: 0.072665
[Epoch 23] ogbg-molhiv: 0.758856 test loss: 0.114178
[Epoch 24; Iter    29/ 1097] train: loss: 0.0462143
[Epoch 24; Iter    59/ 1097] train: loss: 0.2925861
[Epoch 24; Iter    89/ 1097] train: loss: 0.1434352
[Epoch 24; Iter   119/ 1097] train: loss: 0.0256487
[Epoch 24; Iter   149/ 1097] train: loss: 0.0664666
[Epoch 24; Iter   179/ 1097] train: loss: 0.0244180
[Epoch 24; Iter   209/ 1097] train: loss: 0.1469775
[Epoch 24; Iter   239/ 1097] train: loss: 0.0245612
[Epoch 24; Iter   269/ 1097] train: loss: 0.2263792
[Epoch 24; Iter   299/ 1097] train: loss: 0.0298448
[Epoch 24; Iter   329/ 1097] train: loss: 0.0210462
[Epoch 24; Iter   359/ 1097] train: loss: 0.0311746
[Epoch 20; Iter   773/  823] train: loss: 0.1339751
[Epoch 20; Iter   803/  823] train: loss: 0.0215274
[Epoch 20] ogbg-molhiv: 0.728928 val loss: 0.143714
[Epoch 20] ogbg-molhiv: 0.727506 test loss: 0.249176
[Epoch 21; Iter    10/  823] train: loss: 0.1313806
[Epoch 21; Iter    40/  823] train: loss: 0.0500123
[Epoch 21; Iter    70/  823] train: loss: 0.0284674
[Epoch 21; Iter   100/  823] train: loss: 0.0857938
[Epoch 21; Iter   130/  823] train: loss: 0.0494535
[Epoch 21; Iter   160/  823] train: loss: 0.1116308
[Epoch 21; Iter   190/  823] train: loss: 0.4496322
[Epoch 21; Iter   220/  823] train: loss: 0.0257862
[Epoch 21; Iter   250/  823] train: loss: 0.0205935
[Epoch 21; Iter   280/  823] train: loss: 0.0378737
[Epoch 21; Iter   310/  823] train: loss: 0.2193812
[Epoch 21; Iter   340/  823] train: loss: 0.2040791
[Epoch 21; Iter   370/  823] train: loss: 0.0299877
[Epoch 21; Iter   400/  823] train: loss: 0.0347686
[Epoch 21; Iter   430/  823] train: loss: 0.1015226
[Epoch 21; Iter   460/  823] train: loss: 0.2499036
[Epoch 21; Iter   490/  823] train: loss: 0.2048429
[Epoch 21; Iter   520/  823] train: loss: 0.0506702
[Epoch 21; Iter   550/  823] train: loss: 0.0979177
[Epoch 21; Iter   580/  823] train: loss: 0.0153704
[Epoch 21; Iter   610/  823] train: loss: 0.0352791
[Epoch 21; Iter   640/  823] train: loss: 0.0195077
[Epoch 21; Iter   670/  823] train: loss: 0.0197563
[Epoch 21; Iter   700/  823] train: loss: 0.2545365
[Epoch 21; Iter   730/  823] train: loss: 0.0330833
[Epoch 21; Iter   760/  823] train: loss: 0.0194072
[Epoch 21; Iter   790/  823] train: loss: 0.1874779
[Epoch 21; Iter   820/  823] train: loss: 0.0283754
[Epoch 21] ogbg-molhiv: 0.709184 val loss: 0.184654
[Epoch 21] ogbg-molhiv: 0.759799 test loss: 0.369523
[Epoch 22; Iter    27/  823] train: loss: 0.0574149
[Epoch 22; Iter    57/  823] train: loss: 0.0379067
[Epoch 22; Iter    87/  823] train: loss: 0.1213299
[Epoch 22; Iter   117/  823] train: loss: 0.0438687
[Epoch 22; Iter   147/  823] train: loss: 0.0317851
[Epoch 22; Iter   177/  823] train: loss: 0.3622315
[Epoch 22; Iter   207/  823] train: loss: 0.1555493
[Epoch 22; Iter   237/  823] train: loss: 0.0201146
[Epoch 22; Iter   267/  823] train: loss: 0.1267496
[Epoch 22; Iter   297/  823] train: loss: 0.0354882
[Epoch 22; Iter   327/  823] train: loss: 0.1916771
[Epoch 22; Iter   357/  823] train: loss: 0.0145225
[Epoch 22; Iter   387/  823] train: loss: 0.0259474
[Epoch 22; Iter   417/  823] train: loss: 0.2250676
[Epoch 22; Iter   447/  823] train: loss: 0.0715316
[Epoch 22; Iter   477/  823] train: loss: 0.1496235
[Epoch 22; Iter   507/  823] train: loss: 0.2504441
[Epoch 22; Iter   537/  823] train: loss: 0.2225090
[Epoch 22; Iter   567/  823] train: loss: 0.0362541
[Epoch 22; Iter   597/  823] train: loss: 0.0743717
[Epoch 22; Iter   627/  823] train: loss: 0.0226555
[Epoch 22; Iter   657/  823] train: loss: 0.3377281
[Epoch 22; Iter   687/  823] train: loss: 0.1883788
[Epoch 22; Iter   717/  823] train: loss: 0.1088154
[Epoch 22; Iter   747/  823] train: loss: 0.3303922
[Epoch 22; Iter   777/  823] train: loss: 0.1882319
[Epoch 22; Iter   807/  823] train: loss: 0.0582923
[Epoch 22] ogbg-molhiv: 0.729448 val loss: 0.149637
[Epoch 22] ogbg-molhiv: 0.747984 test loss: 0.183919
[Epoch 23; Iter    14/  823] train: loss: 0.0376337
[Epoch 23; Iter    44/  823] train: loss: 0.0375033
[Epoch 23; Iter    74/  823] train: loss: 0.0805377
[Epoch 23; Iter   104/  823] train: loss: 0.3085584
[Epoch 23; Iter   134/  823] train: loss: 0.2358928
[Epoch 23; Iter   164/  823] train: loss: 0.0191360
[Epoch 23; Iter   194/  823] train: loss: 0.0566112
[Epoch 23; Iter   224/  823] train: loss: 0.0889189
[Epoch 23; Iter   254/  823] train: loss: 0.0692905
[Epoch 23; Iter   284/  823] train: loss: 0.0780758
[Epoch 23; Iter   314/  823] train: loss: 0.2040383
[Epoch 23; Iter   344/  823] train: loss: 0.0171496
[Epoch 23; Iter   374/  823] train: loss: 0.0634589
[Epoch 23; Iter   404/  823] train: loss: 0.1515377
[Epoch 23; Iter   434/  823] train: loss: 0.0454436
[Epoch 23; Iter   464/  823] train: loss: 0.0765650
[Epoch 23; Iter   494/  823] train: loss: 0.0554793
[Epoch 23; Iter   524/  823] train: loss: 0.0308526
[Epoch 23; Iter   554/  823] train: loss: 0.0175480
[Epoch 23; Iter   584/  823] train: loss: 0.0932126
[Epoch 23; Iter   614/  823] train: loss: 0.0389832
[Epoch 23; Iter   644/  823] train: loss: 0.1111549
[Epoch 23; Iter   674/  823] train: loss: 0.0192942
[Epoch 23; Iter   704/  823] train: loss: 0.0937845
[Epoch 23; Iter   734/  823] train: loss: 0.0170560
[Epoch 23; Iter   764/  823] train: loss: 0.0629949
[Epoch 23; Iter   794/  823] train: loss: 0.0752521
[Epoch 23] ogbg-molhiv: 0.704428 val loss: 0.154193
[Epoch 23] ogbg-molhiv: 0.727008 test loss: 0.180540
[Epoch 24; Iter     1/  823] train: loss: 0.0261356
[Epoch 24; Iter    31/  823] train: loss: 0.0311110
[Epoch 24; Iter    61/  823] train: loss: 0.1386674
[Epoch 24; Iter    91/  823] train: loss: 0.0552167
[Epoch 24; Iter   121/  823] train: loss: 0.1680167
[Epoch 24; Iter   151/  823] train: loss: 0.1384469
[Epoch 24; Iter   181/  823] train: loss: 0.0421684
[Epoch 24; Iter   211/  823] train: loss: 0.0478025
[Epoch 24; Iter   241/  823] train: loss: 0.0165185
[Epoch 24; Iter   271/  823] train: loss: 0.0234946
[Epoch 24; Iter   301/  823] train: loss: 0.0245803
[Epoch 24; Iter   331/  823] train: loss: 0.0218019
[Epoch 24; Iter   361/  823] train: loss: 0.3107928
[Epoch 24; Iter   391/  823] train: loss: 0.0359833
[Epoch 24; Iter   421/  823] train: loss: 0.0275792
[Epoch 24; Iter   451/  823] train: loss: 0.1535999
[Epoch 24; Iter   481/  823] train: loss: 0.2575909
[Epoch 24; Iter   511/  823] train: loss: 0.0560426
[Epoch 24; Iter   541/  823] train: loss: 0.2106645
[Epoch 24; Iter   571/  823] train: loss: 0.1603786
[Epoch 24; Iter   601/  823] train: loss: 0.2188439
[Epoch 24; Iter   631/  823] train: loss: 0.0346695
[Epoch 24; Iter   661/  823] train: loss: 0.0222684
[Epoch 24; Iter   691/  823] train: loss: 0.2501421
[Epoch 24; Iter   721/  823] train: loss: 0.0344531
[Epoch 24; Iter   751/  823] train: loss: 0.0299746
[Epoch 24; Iter   781/  823] train: loss: 0.0753482
[Epoch 24; Iter   811/  823] train: loss: 0.1076898
[Epoch 24] ogbg-molhiv: 0.743057 val loss: 0.659262
[Epoch 24] ogbg-molhiv: 0.777190 test loss: 0.530988
[Epoch 25; Iter    18/  823] train: loss: 0.0341460
[Epoch 25; Iter    48/  823] train: loss: 0.1275338
[Epoch 25; Iter    78/  823] train: loss: 0.0386487
[Epoch 25; Iter   108/  823] train: loss: 0.0495593
[Epoch 25; Iter   138/  823] train: loss: 0.0192721
[Epoch 25; Iter   168/  823] train: loss: 0.0609959
[Epoch 25; Iter   198/  823] train: loss: 0.1407420
[Epoch 25; Iter   228/  823] train: loss: 0.0274416
[Epoch 25; Iter   258/  823] train: loss: 0.0155971
[Epoch 25; Iter   288/  823] train: loss: 0.0716449
[Epoch 25; Iter   318/  823] train: loss: 0.0406520
[Epoch 25; Iter   348/  823] train: loss: 0.1106783
[Epoch 25; Iter   378/  823] train: loss: 0.0537420
[Epoch 25; Iter   408/  823] train: loss: 0.1225934
[Epoch 25; Iter   438/  823] train: loss: 0.0670695
[Epoch 25; Iter   468/  823] train: loss: 0.0311151
[Epoch 25; Iter   498/  823] train: loss: 0.1840354
[Epoch 25; Iter   528/  823] train: loss: 0.0421527
[Epoch 25; Iter   558/  823] train: loss: 0.2087817
[Epoch 25; Iter   588/  823] train: loss: 0.2600639
[Epoch 25; Iter   618/  823] train: loss: 0.1287076
[Epoch 25; Iter   648/  823] train: loss: 0.0224148
[Epoch 25; Iter   678/  823] train: loss: 0.1345621
[Epoch 25; Iter   708/  823] train: loss: 0.0268478
[Epoch 25; Iter   738/  823] train: loss: 0.0237363
[Epoch 25; Iter   768/  823] train: loss: 0.0722329
[Epoch 25; Iter   798/  823] train: loss: 0.0329254
[Epoch 25] ogbg-molhiv: 0.725984 val loss: 0.211061
[Epoch 25] ogbg-molhiv: 0.706807 test loss: 0.414469
[Epoch 26; Iter     5/  823] train: loss: 0.0260754
[Epoch 26; Iter    35/  823] train: loss: 0.3859884
[Epoch 26; Iter    65/  823] train: loss: 0.0334869
[Epoch 26; Iter    95/  823] train: loss: 0.0230303
[Epoch 26; Iter   125/  823] train: loss: 0.2584122
[Epoch 26; Iter   155/  823] train: loss: 0.2058152
[Epoch 22; Iter   870/  960] train: loss: 0.0447580
[Epoch 22; Iter   900/  960] train: loss: 0.0321947
[Epoch 22; Iter   930/  960] train: loss: 0.0829893
[Epoch 22; Iter   960/  960] train: loss: 0.0294943
[Epoch 22] ogbg-molhiv: 0.775747 val loss: 1.364554
[Epoch 22] ogbg-molhiv: 0.725386 test loss: 0.584955
[Epoch 23; Iter    30/  960] train: loss: 0.0771793
[Epoch 23; Iter    60/  960] train: loss: 0.2270132
[Epoch 23; Iter    90/  960] train: loss: 0.0670093
[Epoch 23; Iter   120/  960] train: loss: 0.0268446
[Epoch 23; Iter   150/  960] train: loss: 0.0474368
[Epoch 23; Iter   180/  960] train: loss: 0.1815283
[Epoch 23; Iter   210/  960] train: loss: 0.0375690
[Epoch 23; Iter   240/  960] train: loss: 0.0354914
[Epoch 23; Iter   270/  960] train: loss: 0.1821325
[Epoch 23; Iter   300/  960] train: loss: 0.0668797
[Epoch 23; Iter   330/  960] train: loss: 0.1295187
[Epoch 23; Iter   360/  960] train: loss: 0.0250595
[Epoch 23; Iter   390/  960] train: loss: 0.1478790
[Epoch 23; Iter   420/  960] train: loss: 0.2848802
[Epoch 23; Iter   450/  960] train: loss: 0.0484562
[Epoch 23; Iter   480/  960] train: loss: 0.0322088
[Epoch 23; Iter   510/  960] train: loss: 0.2402065
[Epoch 23; Iter   540/  960] train: loss: 0.0511719
[Epoch 23; Iter   570/  960] train: loss: 0.2440298
[Epoch 23; Iter   600/  960] train: loss: 0.0220144
[Epoch 23; Iter   630/  960] train: loss: 0.0259658
[Epoch 23; Iter   660/  960] train: loss: 0.0347127
[Epoch 23; Iter   690/  960] train: loss: 0.0795638
[Epoch 23; Iter   720/  960] train: loss: 0.0238841
[Epoch 23; Iter   750/  960] train: loss: 0.0821728
[Epoch 23; Iter   780/  960] train: loss: 0.0265654
[Epoch 23; Iter   810/  960] train: loss: 0.1205796
[Epoch 23; Iter   840/  960] train: loss: 0.0707047
[Epoch 23; Iter   870/  960] train: loss: 0.0156237
[Epoch 23; Iter   900/  960] train: loss: 0.0272140
[Epoch 23; Iter   930/  960] train: loss: 0.1585809
[Epoch 23; Iter   960/  960] train: loss: 0.0889902
[Epoch 23] ogbg-molhiv: 0.740979 val loss: 1.418399
[Epoch 23] ogbg-molhiv: 0.727282 test loss: 0.366970
[Epoch 24; Iter    30/  960] train: loss: 0.0374019
[Epoch 24; Iter    60/  960] train: loss: 0.0407224
[Epoch 24; Iter    90/  960] train: loss: 0.1963795
[Epoch 24; Iter   120/  960] train: loss: 0.0393640
[Epoch 24; Iter   150/  960] train: loss: 0.0214905
[Epoch 24; Iter   180/  960] train: loss: 0.0499420
[Epoch 24; Iter   210/  960] train: loss: 0.0497410
[Epoch 24; Iter   240/  960] train: loss: 0.0369944
[Epoch 24; Iter   270/  960] train: loss: 0.0303897
[Epoch 24; Iter   300/  960] train: loss: 0.1474039
[Epoch 24; Iter   330/  960] train: loss: 0.2590415
[Epoch 24; Iter   360/  960] train: loss: 0.1019599
[Epoch 24; Iter   390/  960] train: loss: 0.1765318
[Epoch 24; Iter   420/  960] train: loss: 0.0248255
[Epoch 24; Iter   450/  960] train: loss: 0.1277118
[Epoch 24; Iter   480/  960] train: loss: 0.1701718
[Epoch 24; Iter   510/  960] train: loss: 0.1190814
[Epoch 24; Iter   540/  960] train: loss: 0.1564309
[Epoch 24; Iter   570/  960] train: loss: 0.0257460
[Epoch 24; Iter   600/  960] train: loss: 0.0284625
[Epoch 24; Iter   630/  960] train: loss: 0.0810226
[Epoch 24; Iter   660/  960] train: loss: 0.0596730
[Epoch 24; Iter   690/  960] train: loss: 0.0555233
[Epoch 24; Iter   720/  960] train: loss: 0.0522834
[Epoch 24; Iter   750/  960] train: loss: 0.2120177
[Epoch 24; Iter   780/  960] train: loss: 0.1224222
[Epoch 24; Iter   810/  960] train: loss: 0.0180302
[Epoch 24; Iter   840/  960] train: loss: 0.0456870
[Epoch 24; Iter   870/  960] train: loss: 0.0133379
[Epoch 24; Iter   900/  960] train: loss: 0.0444779
[Epoch 24; Iter   930/  960] train: loss: 0.1294861
[Epoch 24; Iter   960/  960] train: loss: 0.0735632
[Epoch 24] ogbg-molhiv: 0.775536 val loss: 2.442919
[Epoch 24] ogbg-molhiv: 0.750118 test loss: 0.611356
[Epoch 25; Iter    30/  960] train: loss: 0.1184037
[Epoch 25; Iter    60/  960] train: loss: 0.1046677
[Epoch 25; Iter    90/  960] train: loss: 0.1612457
[Epoch 25; Iter   120/  960] train: loss: 0.2802314
[Epoch 25; Iter   150/  960] train: loss: 0.1492398
[Epoch 25; Iter   180/  960] train: loss: 0.0722960
[Epoch 25; Iter   210/  960] train: loss: 0.2208072
[Epoch 25; Iter   240/  960] train: loss: 0.0258926
[Epoch 25; Iter   270/  960] train: loss: 0.0324800
[Epoch 25; Iter   300/  960] train: loss: 0.0354872
[Epoch 25; Iter   330/  960] train: loss: 0.0403701
[Epoch 25; Iter   360/  960] train: loss: 0.0268068
[Epoch 25; Iter   390/  960] train: loss: 0.1648844
[Epoch 25; Iter   420/  960] train: loss: 0.1569801
[Epoch 25; Iter   450/  960] train: loss: 0.1709439
[Epoch 25; Iter   480/  960] train: loss: 0.3675092
[Epoch 25; Iter   510/  960] train: loss: 0.0218883
[Epoch 25; Iter   540/  960] train: loss: 0.1525958
[Epoch 25; Iter   570/  960] train: loss: 0.0401066
[Epoch 25; Iter   600/  960] train: loss: 0.1100519
[Epoch 25; Iter   630/  960] train: loss: 0.1292076
[Epoch 25; Iter   660/  960] train: loss: 0.0237134
[Epoch 25; Iter   690/  960] train: loss: 0.2695692
[Epoch 25; Iter   720/  960] train: loss: 0.0278294
[Epoch 25; Iter   750/  960] train: loss: 0.1422758
[Epoch 25; Iter   780/  960] train: loss: 0.0348387
[Epoch 25; Iter   810/  960] train: loss: 0.0194438
[Epoch 25; Iter   840/  960] train: loss: 0.0244614
[Epoch 25; Iter   870/  960] train: loss: 0.0193629
[Epoch 25; Iter   900/  960] train: loss: 0.3003987
[Epoch 25; Iter   930/  960] train: loss: 0.1656478
[Epoch 25; Iter   960/  960] train: loss: 0.0563315
[Epoch 25] ogbg-molhiv: 0.769545 val loss: 1.320699
[Epoch 25] ogbg-molhiv: 0.758818 test loss: 0.291299
[Epoch 26; Iter    30/  960] train: loss: 0.0634150
[Epoch 26; Iter    60/  960] train: loss: 0.0547465
[Epoch 26; Iter    90/  960] train: loss: 0.0505554
[Epoch 26; Iter   120/  960] train: loss: 0.0182682
[Epoch 26; Iter   150/  960] train: loss: 0.0366934
[Epoch 26; Iter   180/  960] train: loss: 0.0410589
[Epoch 26; Iter   210/  960] train: loss: 0.1221773
[Epoch 26; Iter   240/  960] train: loss: 0.0237125
[Epoch 26; Iter   270/  960] train: loss: 0.1871297
[Epoch 26; Iter   300/  960] train: loss: 0.1855202
[Epoch 26; Iter   330/  960] train: loss: 0.0858362
[Epoch 26; Iter   360/  960] train: loss: 0.1562587
[Epoch 26; Iter   390/  960] train: loss: 0.0183924
[Epoch 26; Iter   420/  960] train: loss: 0.1623475
[Epoch 26; Iter   450/  960] train: loss: 0.0487442
[Epoch 26; Iter   480/  960] train: loss: 0.1489554
[Epoch 26; Iter   510/  960] train: loss: 0.0241380
[Epoch 26; Iter   540/  960] train: loss: 0.0198925
[Epoch 26; Iter   570/  960] train: loss: 0.1196589
[Epoch 26; Iter   600/  960] train: loss: 0.3368388
[Epoch 26; Iter   630/  960] train: loss: 0.0376223
[Epoch 26; Iter   660/  960] train: loss: 0.0317159
[Epoch 26; Iter   690/  960] train: loss: 0.2580207
[Epoch 26; Iter   720/  960] train: loss: 0.0638580
[Epoch 26; Iter   750/  960] train: loss: 0.0193940
[Epoch 26; Iter   780/  960] train: loss: 0.0619445
[Epoch 26; Iter   810/  960] train: loss: 0.2894426
[Epoch 26; Iter   840/  960] train: loss: 0.0234507
[Epoch 26; Iter   870/  960] train: loss: 0.1879468
[Epoch 26; Iter   900/  960] train: loss: 0.1189044
[Epoch 26; Iter   930/  960] train: loss: 0.0555876
[Epoch 26; Iter   960/  960] train: loss: 0.0379381
[Epoch 26] ogbg-molhiv: 0.760649 val loss: 1.889004
[Epoch 26] ogbg-molhiv: 0.761583 test loss: 0.359290
[Epoch 27; Iter    30/  960] train: loss: 0.0361714
[Epoch 27; Iter    60/  960] train: loss: 0.0263770
[Epoch 27; Iter    90/  960] train: loss: 0.0351424
[Epoch 27; Iter   120/  960] train: loss: 0.0291552
[Epoch 27; Iter   150/  960] train: loss: 0.0729160
[Epoch 27; Iter   180/  960] train: loss: 0.2422135
[Epoch 27; Iter   210/  960] train: loss: 0.0211605
[Epoch 27; Iter   240/  960] train: loss: 0.2311022
[Epoch 27; Iter   270/  960] train: loss: 0.1312174
[Epoch 27; Iter   300/  960] train: loss: 0.0337866
[Epoch 27; Iter   330/  960] train: loss: 0.1429350
[Epoch 27; Iter   360/  960] train: loss: 0.0508349
[Epoch 27; Iter   390/  960] train: loss: 0.3176433
[Epoch 27; Iter   420/  960] train: loss: 0.1193181
[Epoch 27; Iter   450/  960] train: loss: 0.0162943
[Epoch 22; Iter   870/  960] train: loss: 0.0824028
[Epoch 22; Iter   900/  960] train: loss: 0.1329130
[Epoch 22; Iter   930/  960] train: loss: 0.2109118
[Epoch 22; Iter   960/  960] train: loss: 0.1280437
[Epoch 22] ogbg-molhiv: 0.765431 val loss: 0.129100
[Epoch 22] ogbg-molhiv: 0.790117 test loss: 0.097182
[Epoch 23; Iter    30/  960] train: loss: 0.0910594
[Epoch 23; Iter    60/  960] train: loss: 0.0210091
[Epoch 23; Iter    90/  960] train: loss: 0.0586841
[Epoch 23; Iter   120/  960] train: loss: 0.0173593
[Epoch 23; Iter   150/  960] train: loss: 0.0226364
[Epoch 23; Iter   180/  960] train: loss: 0.0242872
[Epoch 23; Iter   210/  960] train: loss: 0.1091795
[Epoch 23; Iter   240/  960] train: loss: 0.0882625
[Epoch 23; Iter   270/  960] train: loss: 0.1432929
[Epoch 23; Iter   300/  960] train: loss: 0.0774108
[Epoch 23; Iter   330/  960] train: loss: 0.0460980
[Epoch 23; Iter   360/  960] train: loss: 0.0126357
[Epoch 23; Iter   390/  960] train: loss: 0.0663090
[Epoch 23; Iter   420/  960] train: loss: 0.0215386
[Epoch 23; Iter   450/  960] train: loss: 0.0400102
[Epoch 23; Iter   480/  960] train: loss: 0.2044053
[Epoch 23; Iter   510/  960] train: loss: 0.0243216
[Epoch 23; Iter   540/  960] train: loss: 0.0228037
[Epoch 23; Iter   570/  960] train: loss: 0.0441839
[Epoch 23; Iter   600/  960] train: loss: 0.0403276
[Epoch 23; Iter   630/  960] train: loss: 0.0330975
[Epoch 23; Iter   660/  960] train: loss: 0.0753776
[Epoch 23; Iter   690/  960] train: loss: 0.1319087
[Epoch 23; Iter   720/  960] train: loss: 0.1363502
[Epoch 23; Iter   750/  960] train: loss: 0.1679080
[Epoch 23; Iter   780/  960] train: loss: 0.1628667
[Epoch 23; Iter   810/  960] train: loss: 0.1370407
[Epoch 23; Iter   840/  960] train: loss: 0.0355237
[Epoch 23; Iter   870/  960] train: loss: 0.0968284
[Epoch 23; Iter   900/  960] train: loss: 0.2106401
[Epoch 23; Iter   930/  960] train: loss: 0.1020501
[Epoch 23; Iter   960/  960] train: loss: 0.0353857
[Epoch 23] ogbg-molhiv: 0.770412 val loss: 0.117034
[Epoch 23] ogbg-molhiv: 0.774383 test loss: 0.101986
[Epoch 24; Iter    30/  960] train: loss: 0.0643530
[Epoch 24; Iter    60/  960] train: loss: 0.0855224
[Epoch 24; Iter    90/  960] train: loss: 0.1298775
[Epoch 24; Iter   120/  960] train: loss: 0.1163729
[Epoch 24; Iter   150/  960] train: loss: 0.1526921
[Epoch 24; Iter   180/  960] train: loss: 0.0308836
[Epoch 24; Iter   210/  960] train: loss: 0.1142792
[Epoch 24; Iter   240/  960] train: loss: 0.0284562
[Epoch 24; Iter   270/  960] train: loss: 0.1580344
[Epoch 24; Iter   300/  960] train: loss: 0.2927489
[Epoch 24; Iter   330/  960] train: loss: 0.2260383
[Epoch 24; Iter   360/  960] train: loss: 0.2276350
[Epoch 24; Iter   390/  960] train: loss: 0.0566654
[Epoch 24; Iter   420/  960] train: loss: 0.0230739
[Epoch 24; Iter   450/  960] train: loss: 0.0513383
[Epoch 24; Iter   480/  960] train: loss: 0.0404536
[Epoch 24; Iter   510/  960] train: loss: 0.2074837
[Epoch 24; Iter   540/  960] train: loss: 0.1608002
[Epoch 24; Iter   570/  960] train: loss: 0.0310976
[Epoch 24; Iter   600/  960] train: loss: 0.1260526
[Epoch 24; Iter   630/  960] train: loss: 0.1344086
[Epoch 24; Iter   660/  960] train: loss: 0.1708907
[Epoch 24; Iter   690/  960] train: loss: 0.0341207
[Epoch 24; Iter   720/  960] train: loss: 0.0347074
[Epoch 24; Iter   750/  960] train: loss: 0.0499744
[Epoch 24; Iter   780/  960] train: loss: 0.0358157
[Epoch 24; Iter   810/  960] train: loss: 0.0904485
[Epoch 24; Iter   840/  960] train: loss: 0.0349328
[Epoch 24; Iter   870/  960] train: loss: 0.0321923
[Epoch 24; Iter   900/  960] train: loss: 0.0446021
[Epoch 24; Iter   930/  960] train: loss: 0.0291834
[Epoch 24; Iter   960/  960] train: loss: 0.1642970
[Epoch 24] ogbg-molhiv: 0.752932 val loss: 0.118079
[Epoch 24] ogbg-molhiv: 0.777696 test loss: 0.099345
[Epoch 25; Iter    30/  960] train: loss: 0.0253678
[Epoch 25; Iter    60/  960] train: loss: 0.0366995
[Epoch 25; Iter    90/  960] train: loss: 0.0695190
[Epoch 25; Iter   120/  960] train: loss: 0.0283691
[Epoch 25; Iter   150/  960] train: loss: 0.0444860
[Epoch 25; Iter   180/  960] train: loss: 0.1320325
[Epoch 25; Iter   210/  960] train: loss: 0.0499916
[Epoch 25; Iter   240/  960] train: loss: 0.0158719
[Epoch 25; Iter   270/  960] train: loss: 0.2055314
[Epoch 25; Iter   300/  960] train: loss: 0.1784248
[Epoch 25; Iter   330/  960] train: loss: 0.0752204
[Epoch 25; Iter   360/  960] train: loss: 0.2496782
[Epoch 25; Iter   390/  960] train: loss: 0.0408423
[Epoch 25; Iter   420/  960] train: loss: 0.0304164
[Epoch 25; Iter   450/  960] train: loss: 0.1428834
[Epoch 25; Iter   480/  960] train: loss: 0.0342653
[Epoch 25; Iter   510/  960] train: loss: 0.0185405
[Epoch 25; Iter   540/  960] train: loss: 0.0216164
[Epoch 25; Iter   570/  960] train: loss: 0.0607196
[Epoch 25; Iter   600/  960] train: loss: 0.1618393
[Epoch 25; Iter   630/  960] train: loss: 0.0512250
[Epoch 25; Iter   660/  960] train: loss: 0.1475629
[Epoch 25; Iter   690/  960] train: loss: 0.0262344
[Epoch 25; Iter   720/  960] train: loss: 0.1486731
[Epoch 25; Iter   750/  960] train: loss: 0.4155607
[Epoch 25; Iter   780/  960] train: loss: 0.0452395
[Epoch 25; Iter   810/  960] train: loss: 0.0360278
[Epoch 25; Iter   840/  960] train: loss: 0.1887909
[Epoch 25; Iter   870/  960] train: loss: 0.0182604
[Epoch 25; Iter   900/  960] train: loss: 0.0445886
[Epoch 25; Iter   930/  960] train: loss: 0.1233821
[Epoch 25; Iter   960/  960] train: loss: 0.0190617
[Epoch 25] ogbg-molhiv: 0.767811 val loss: 0.347787
[Epoch 25] ogbg-molhiv: 0.777794 test loss: 0.120092
[Epoch 26; Iter    30/  960] train: loss: 0.1655542
[Epoch 26; Iter    60/  960] train: loss: 0.0360463
[Epoch 26; Iter    90/  960] train: loss: 0.0202187
[Epoch 26; Iter   120/  960] train: loss: 0.0402071
[Epoch 26; Iter   150/  960] train: loss: 0.1552316
[Epoch 26; Iter   180/  960] train: loss: 0.1971889
[Epoch 26; Iter   210/  960] train: loss: 0.1568166
[Epoch 26; Iter   240/  960] train: loss: 0.1034652
[Epoch 26; Iter   270/  960] train: loss: 0.0185216
[Epoch 26; Iter   300/  960] train: loss: 0.0661512
[Epoch 26; Iter   330/  960] train: loss: 0.0759305
[Epoch 26; Iter   360/  960] train: loss: 0.0133963
[Epoch 26; Iter   390/  960] train: loss: 0.0130128
[Epoch 26; Iter   420/  960] train: loss: 0.0429762
[Epoch 26; Iter   450/  960] train: loss: 0.0322075
[Epoch 26; Iter   480/  960] train: loss: 0.1821321
[Epoch 26; Iter   510/  960] train: loss: 0.1692195
[Epoch 26; Iter   540/  960] train: loss: 0.0199419
[Epoch 26; Iter   570/  960] train: loss: 0.0796329
[Epoch 26; Iter   600/  960] train: loss: 0.0303697
[Epoch 26; Iter   630/  960] train: loss: 0.0317928
[Epoch 26; Iter   660/  960] train: loss: 0.2092132
[Epoch 26; Iter   690/  960] train: loss: 0.1426540
[Epoch 26; Iter   720/  960] train: loss: 0.0487683
[Epoch 26; Iter   750/  960] train: loss: 0.0152177
[Epoch 26; Iter   780/  960] train: loss: 0.3072887
[Epoch 26; Iter   810/  960] train: loss: 0.2025928
[Epoch 26; Iter   840/  960] train: loss: 0.0258748
[Epoch 26; Iter   870/  960] train: loss: 0.0181564
[Epoch 26; Iter   900/  960] train: loss: 0.0196221
[Epoch 26; Iter   930/  960] train: loss: 0.2196574
[Epoch 26; Iter   960/  960] train: loss: 0.0367925
[Epoch 26] ogbg-molhiv: 0.751753 val loss: 0.121904
[Epoch 26] ogbg-molhiv: 0.768974 test loss: 0.104508
[Epoch 27; Iter    30/  960] train: loss: 0.4279336
[Epoch 27; Iter    60/  960] train: loss: 0.0464699
[Epoch 27; Iter    90/  960] train: loss: 0.0655617
[Epoch 27; Iter   120/  960] train: loss: 0.0163166
[Epoch 27; Iter   150/  960] train: loss: 0.1127752
[Epoch 27; Iter   180/  960] train: loss: 0.0937659
[Epoch 27; Iter   210/  960] train: loss: 0.3004416
[Epoch 27; Iter   240/  960] train: loss: 0.1940768
[Epoch 27; Iter   270/  960] train: loss: 0.0220103
[Epoch 27; Iter   300/  960] train: loss: 0.0224351
[Epoch 27; Iter   330/  960] train: loss: 0.0377301
[Epoch 27; Iter   360/  960] train: loss: 0.0743781
[Epoch 27; Iter   390/  960] train: loss: 0.1595076
[Epoch 27; Iter   420/  960] train: loss: 0.1621332
[Epoch 27; Iter   450/  960] train: loss: 0.0332510
[Epoch 22; Iter   870/  960] train: loss: 0.0258263
[Epoch 22; Iter   900/  960] train: loss: 0.0730730
[Epoch 22; Iter   930/  960] train: loss: 0.0202324
[Epoch 22; Iter   960/  960] train: loss: 0.0317824
[Epoch 22] ogbg-molhiv: 0.757073 val loss: 0.153592
[Epoch 22] ogbg-molhiv: 0.759250 test loss: 0.212039
[Epoch 23; Iter    30/  960] train: loss: 0.1967554
[Epoch 23; Iter    60/  960] train: loss: 0.3887154
[Epoch 23; Iter    90/  960] train: loss: 0.0413048
[Epoch 23; Iter   120/  960] train: loss: 0.1917463
[Epoch 23; Iter   150/  960] train: loss: 0.0366715
[Epoch 23; Iter   180/  960] train: loss: 0.1348986
[Epoch 23; Iter   210/  960] train: loss: 0.1794485
[Epoch 23; Iter   240/  960] train: loss: 0.0611390
[Epoch 23; Iter   270/  960] train: loss: 0.0369321
[Epoch 23; Iter   300/  960] train: loss: 0.0357972
[Epoch 23; Iter   330/  960] train: loss: 0.0653028
[Epoch 23; Iter   360/  960] train: loss: 0.1212119
[Epoch 23; Iter   390/  960] train: loss: 0.0441996
[Epoch 23; Iter   420/  960] train: loss: 0.1582064
[Epoch 23; Iter   450/  960] train: loss: 0.1472238
[Epoch 23; Iter   480/  960] train: loss: 0.4064596
[Epoch 23; Iter   510/  960] train: loss: 0.1461544
[Epoch 23; Iter   540/  960] train: loss: 0.0739753
[Epoch 23; Iter   570/  960] train: loss: 0.0555592
[Epoch 23; Iter   600/  960] train: loss: 0.1526254
[Epoch 23; Iter   630/  960] train: loss: 0.1828715
[Epoch 23; Iter   660/  960] train: loss: 0.0285645
[Epoch 23; Iter   690/  960] train: loss: 0.0250957
[Epoch 23; Iter   720/  960] train: loss: 0.0642352
[Epoch 23; Iter   750/  960] train: loss: 0.0255647
[Epoch 23; Iter   780/  960] train: loss: 0.0281358
[Epoch 23; Iter   810/  960] train: loss: 0.1297186
[Epoch 23; Iter   840/  960] train: loss: 0.0548544
[Epoch 23; Iter   870/  960] train: loss: 0.1987181
[Epoch 23; Iter   900/  960] train: loss: 0.1370278
[Epoch 23; Iter   930/  960] train: loss: 0.1753978
[Epoch 23; Iter   960/  960] train: loss: 0.5471935
[Epoch 23] ogbg-molhiv: 0.777438 val loss: 0.131694
[Epoch 23] ogbg-molhiv: 0.763411 test loss: 0.116553
[Epoch 24; Iter    30/  960] train: loss: 0.0662007
[Epoch 24; Iter    60/  960] train: loss: 0.3051376
[Epoch 24; Iter    90/  960] train: loss: 0.1358118
[Epoch 24; Iter   120/  960] train: loss: 0.0410708
[Epoch 24; Iter   150/  960] train: loss: 0.0376677
[Epoch 24; Iter   180/  960] train: loss: 0.0942960
[Epoch 24; Iter   210/  960] train: loss: 0.1654961
[Epoch 24; Iter   240/  960] train: loss: 0.0317149
[Epoch 24; Iter   270/  960] train: loss: 0.0201339
[Epoch 24; Iter   300/  960] train: loss: 0.0352398
[Epoch 24; Iter   330/  960] train: loss: 0.0398947
[Epoch 24; Iter   360/  960] train: loss: 0.0462512
[Epoch 24; Iter   390/  960] train: loss: 0.0712428
[Epoch 24; Iter   420/  960] train: loss: 0.0300621
[Epoch 24; Iter   450/  960] train: loss: 0.1791866
[Epoch 24; Iter   480/  960] train: loss: 0.0414838
[Epoch 24; Iter   510/  960] train: loss: 0.1482882
[Epoch 24; Iter   540/  960] train: loss: 0.0354944
[Epoch 24; Iter   570/  960] train: loss: 0.0282133
[Epoch 24; Iter   600/  960] train: loss: 0.0343843
[Epoch 24; Iter   630/  960] train: loss: 0.1403560
[Epoch 24; Iter   660/  960] train: loss: 0.1246951
[Epoch 24; Iter   690/  960] train: loss: 0.0358253
[Epoch 24; Iter   720/  960] train: loss: 0.0627120
[Epoch 24; Iter   750/  960] train: loss: 0.1288219
[Epoch 24; Iter   780/  960] train: loss: 0.1719506
[Epoch 24; Iter   810/  960] train: loss: 0.0162185
[Epoch 24; Iter   840/  960] train: loss: 0.1653248
[Epoch 24; Iter   870/  960] train: loss: 0.0938053
[Epoch 24; Iter   900/  960] train: loss: 0.2182744
[Epoch 24; Iter   930/  960] train: loss: 0.0583165
[Epoch 24; Iter   960/  960] train: loss: 0.0234902
[Epoch 24] ogbg-molhiv: 0.742857 val loss: 0.145656
[Epoch 24] ogbg-molhiv: 0.746822 test loss: 0.133432
[Epoch 25; Iter    30/  960] train: loss: 0.1449463
[Epoch 25; Iter    60/  960] train: loss: 0.1729822
[Epoch 25; Iter    90/  960] train: loss: 0.0955178
[Epoch 25; Iter   120/  960] train: loss: 0.0144753
[Epoch 25; Iter   150/  960] train: loss: 0.1631945
[Epoch 25; Iter   180/  960] train: loss: 0.2070599
[Epoch 25; Iter   210/  960] train: loss: 0.0353313
[Epoch 25; Iter   240/  960] train: loss: 0.0379745
[Epoch 25; Iter   270/  960] train: loss: 0.0326401
[Epoch 25; Iter   300/  960] train: loss: 0.1202154
[Epoch 25; Iter   330/  960] train: loss: 0.0210495
[Epoch 25; Iter   360/  960] train: loss: 0.0199297
[Epoch 25; Iter   390/  960] train: loss: 0.1389088
[Epoch 25; Iter   420/  960] train: loss: 0.0288328
[Epoch 25; Iter   450/  960] train: loss: 0.0216959
[Epoch 25; Iter   480/  960] train: loss: 0.1906401
[Epoch 25; Iter   510/  960] train: loss: 0.0986673
[Epoch 25; Iter   540/  960] train: loss: 0.0795153
[Epoch 25; Iter   570/  960] train: loss: 0.0639735
[Epoch 25; Iter   600/  960] train: loss: 0.2662966
[Epoch 25; Iter   630/  960] train: loss: 0.0422682
[Epoch 25; Iter   660/  960] train: loss: 0.0241652
[Epoch 25; Iter   690/  960] train: loss: 0.0409266
[Epoch 25; Iter   720/  960] train: loss: 0.0216649
[Epoch 25; Iter   750/  960] train: loss: 0.0206786
[Epoch 25; Iter   780/  960] train: loss: 0.0240579
[Epoch 25; Iter   810/  960] train: loss: 0.2081098
[Epoch 25; Iter   840/  960] train: loss: 0.0209705
[Epoch 25; Iter   870/  960] train: loss: 0.0210624
[Epoch 25; Iter   900/  960] train: loss: 0.0175396
[Epoch 25; Iter   930/  960] train: loss: 0.0311194
[Epoch 25; Iter   960/  960] train: loss: 0.0715957
[Epoch 25] ogbg-molhiv: 0.760464 val loss: 0.120961
[Epoch 25] ogbg-molhiv: 0.759736 test loss: 0.312794
[Epoch 26; Iter    30/  960] train: loss: 0.2031644
[Epoch 26; Iter    60/  960] train: loss: 0.1654851
[Epoch 26; Iter    90/  960] train: loss: 0.0535913
[Epoch 26; Iter   120/  960] train: loss: 0.1369199
[Epoch 26; Iter   150/  960] train: loss: 0.0934458
[Epoch 26; Iter   180/  960] train: loss: 0.0314489
[Epoch 26; Iter   210/  960] train: loss: 0.0255852
[Epoch 26; Iter   240/  960] train: loss: 0.1510189
[Epoch 26; Iter   270/  960] train: loss: 0.2770768
[Epoch 26; Iter   300/  960] train: loss: 0.0251347
[Epoch 26; Iter   330/  960] train: loss: 0.3776227
[Epoch 26; Iter   360/  960] train: loss: 0.2557117
[Epoch 26; Iter   390/  960] train: loss: 0.0375981
[Epoch 26; Iter   420/  960] train: loss: 0.1014396
[Epoch 26; Iter   450/  960] train: loss: 0.0392713
[Epoch 26; Iter   480/  960] train: loss: 0.0473397
[Epoch 26; Iter   510/  960] train: loss: 0.0444702
[Epoch 26; Iter   540/  960] train: loss: 0.0559239
[Epoch 26; Iter   570/  960] train: loss: 0.0386859
[Epoch 26; Iter   600/  960] train: loss: 0.0314665
[Epoch 26; Iter   630/  960] train: loss: 0.2805587
[Epoch 26; Iter   660/  960] train: loss: 0.0191861
[Epoch 26; Iter   690/  960] train: loss: 0.1388952
[Epoch 26; Iter   720/  960] train: loss: 0.0353229
[Epoch 26; Iter   750/  960] train: loss: 0.0854826
[Epoch 26; Iter   780/  960] train: loss: 0.2148563
[Epoch 26; Iter   810/  960] train: loss: 0.0244613
[Epoch 26; Iter   840/  960] train: loss: 0.2616843
[Epoch 26; Iter   870/  960] train: loss: 0.0247126
[Epoch 26; Iter   900/  960] train: loss: 0.0548937
[Epoch 26; Iter   930/  960] train: loss: 0.0404400
[Epoch 26; Iter   960/  960] train: loss: 0.1481475
[Epoch 26] ogbg-molhiv: 0.764346 val loss: 0.122859
[Epoch 26] ogbg-molhiv: 0.755303 test loss: 0.106480
[Epoch 27; Iter    30/  960] train: loss: 0.0245545
[Epoch 27; Iter    60/  960] train: loss: 0.0303992
[Epoch 27; Iter    90/  960] train: loss: 0.0180029
[Epoch 27; Iter   120/  960] train: loss: 0.0728692
[Epoch 27; Iter   150/  960] train: loss: 0.1737009
[Epoch 27; Iter   180/  960] train: loss: 0.0925537
[Epoch 27; Iter   210/  960] train: loss: 0.0257024
[Epoch 27; Iter   240/  960] train: loss: 0.0358893
[Epoch 27; Iter   270/  960] train: loss: 0.0388575
[Epoch 27; Iter   300/  960] train: loss: 0.1515969
[Epoch 27; Iter   330/  960] train: loss: 0.1136789
[Epoch 27; Iter   360/  960] train: loss: 0.2108552
[Epoch 27; Iter   390/  960] train: loss: 0.1996246
[Epoch 27; Iter   420/  960] train: loss: 0.0249965
[Epoch 27; Iter   450/  960] train: loss: 0.3193341
[Epoch 24; Iter   389/ 1097] train: loss: 0.0490673
[Epoch 24; Iter   419/ 1097] train: loss: 0.0258358
[Epoch 24; Iter   449/ 1097] train: loss: 0.0326256
[Epoch 24; Iter   479/ 1097] train: loss: 0.2052758
[Epoch 24; Iter   509/ 1097] train: loss: 0.1376240
[Epoch 24; Iter   539/ 1097] train: loss: 0.0442625
[Epoch 24; Iter   569/ 1097] train: loss: 0.0980712
[Epoch 24; Iter   599/ 1097] train: loss: 0.0827179
[Epoch 24; Iter   629/ 1097] train: loss: 0.0320439
[Epoch 24; Iter   659/ 1097] train: loss: 0.1300054
[Epoch 24; Iter   689/ 1097] train: loss: 0.0953363
[Epoch 24; Iter   719/ 1097] train: loss: 0.0474376
[Epoch 24; Iter   749/ 1097] train: loss: 0.0372154
[Epoch 24; Iter   779/ 1097] train: loss: 0.3329631
[Epoch 24; Iter   809/ 1097] train: loss: 0.2279726
[Epoch 24; Iter   839/ 1097] train: loss: 0.0768706
[Epoch 24; Iter   869/ 1097] train: loss: 0.0491074
[Epoch 24; Iter   899/ 1097] train: loss: 0.0205419
[Epoch 24; Iter   929/ 1097] train: loss: 0.0381540
[Epoch 24; Iter   959/ 1097] train: loss: 0.0229189
[Epoch 24; Iter   989/ 1097] train: loss: 0.0492625
[Epoch 24; Iter  1019/ 1097] train: loss: 0.3497434
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0258527
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0969596
[Epoch 24] ogbg-molhiv: 0.780322 val loss: 0.204882
[Epoch 24] ogbg-molhiv: 0.772137 test loss: 0.130316
[Epoch 25; Iter    12/ 1097] train: loss: 0.0644233
[Epoch 25; Iter    42/ 1097] train: loss: 0.2332772
[Epoch 25; Iter    72/ 1097] train: loss: 0.2818764
[Epoch 25; Iter   102/ 1097] train: loss: 0.0826283
[Epoch 25; Iter   132/ 1097] train: loss: 0.0554583
[Epoch 25; Iter   162/ 1097] train: loss: 0.0235212
[Epoch 25; Iter   192/ 1097] train: loss: 0.0762038
[Epoch 25; Iter   222/ 1097] train: loss: 0.1559597
[Epoch 25; Iter   252/ 1097] train: loss: 0.0195976
[Epoch 25; Iter   282/ 1097] train: loss: 0.0409418
[Epoch 25; Iter   312/ 1097] train: loss: 0.0258073
[Epoch 25; Iter   342/ 1097] train: loss: 0.0483839
[Epoch 25; Iter   372/ 1097] train: loss: 0.0211140
[Epoch 25; Iter   402/ 1097] train: loss: 0.0349154
[Epoch 25; Iter   432/ 1097] train: loss: 0.1144565
[Epoch 25; Iter   462/ 1097] train: loss: 0.1852913
[Epoch 25; Iter   492/ 1097] train: loss: 0.0935045
[Epoch 25; Iter   522/ 1097] train: loss: 0.0213385
[Epoch 25; Iter   552/ 1097] train: loss: 0.3188896
[Epoch 25; Iter   582/ 1097] train: loss: 0.3423743
[Epoch 25; Iter   612/ 1097] train: loss: 0.0268873
[Epoch 25; Iter   642/ 1097] train: loss: 0.3171827
[Epoch 25; Iter   672/ 1097] train: loss: 0.0867973
[Epoch 25; Iter   702/ 1097] train: loss: 0.0274190
[Epoch 25; Iter   732/ 1097] train: loss: 0.2205072
[Epoch 25; Iter   762/ 1097] train: loss: 0.0498342
[Epoch 25; Iter   792/ 1097] train: loss: 0.2619268
[Epoch 25; Iter   822/ 1097] train: loss: 0.0236784
[Epoch 25; Iter   852/ 1097] train: loss: 0.0266844
[Epoch 25; Iter   882/ 1097] train: loss: 0.0339085
[Epoch 25; Iter   912/ 1097] train: loss: 0.0378128
[Epoch 25; Iter   942/ 1097] train: loss: 0.2359845
[Epoch 25; Iter   972/ 1097] train: loss: 0.1382167
[Epoch 25; Iter  1002/ 1097] train: loss: 0.1190835
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0491707
[Epoch 25; Iter  1062/ 1097] train: loss: 0.1890774
[Epoch 25; Iter  1092/ 1097] train: loss: 0.0183475
[Epoch 25] ogbg-molhiv: 0.791691 val loss: 0.308142
[Epoch 25] ogbg-molhiv: 0.781336 test loss: 0.173298
[Epoch 26; Iter    25/ 1097] train: loss: 0.1671139
[Epoch 26; Iter    55/ 1097] train: loss: 0.0386736
[Epoch 26; Iter    85/ 1097] train: loss: 0.3348795
[Epoch 26; Iter   115/ 1097] train: loss: 0.0420994
[Epoch 26; Iter   145/ 1097] train: loss: 0.0235381
[Epoch 26; Iter   175/ 1097] train: loss: 0.0394213
[Epoch 26; Iter   205/ 1097] train: loss: 0.0161253
[Epoch 26; Iter   235/ 1097] train: loss: 0.0363745
[Epoch 26; Iter   265/ 1097] train: loss: 0.0604204
[Epoch 26; Iter   295/ 1097] train: loss: 0.1132010
[Epoch 26; Iter   325/ 1097] train: loss: 0.0358995
[Epoch 26; Iter   355/ 1097] train: loss: 0.0955745
[Epoch 26; Iter   385/ 1097] train: loss: 0.1998967
[Epoch 26; Iter   415/ 1097] train: loss: 0.0824672
[Epoch 26; Iter   445/ 1097] train: loss: 0.0739496
[Epoch 26; Iter   475/ 1097] train: loss: 0.0416018
[Epoch 26; Iter   505/ 1097] train: loss: 0.1511109
[Epoch 26; Iter   535/ 1097] train: loss: 0.0207321
[Epoch 26; Iter   565/ 1097] train: loss: 0.1279391
[Epoch 26; Iter   595/ 1097] train: loss: 0.0201958
[Epoch 26; Iter   625/ 1097] train: loss: 0.0878641
[Epoch 26; Iter   655/ 1097] train: loss: 0.1026461
[Epoch 26; Iter   685/ 1097] train: loss: 0.1229280
[Epoch 26; Iter   715/ 1097] train: loss: 0.0440174
[Epoch 26; Iter   745/ 1097] train: loss: 0.0619435
[Epoch 26; Iter   775/ 1097] train: loss: 0.3349276
[Epoch 26; Iter   805/ 1097] train: loss: 0.0388342
[Epoch 26; Iter   835/ 1097] train: loss: 0.0229015
[Epoch 26; Iter   865/ 1097] train: loss: 0.1904689
[Epoch 26; Iter   895/ 1097] train: loss: 0.0216216
[Epoch 26; Iter   925/ 1097] train: loss: 0.0912979
[Epoch 26; Iter   955/ 1097] train: loss: 0.0657437
[Epoch 26; Iter   985/ 1097] train: loss: 0.0579988
[Epoch 26; Iter  1015/ 1097] train: loss: 0.2736733
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0313071
[Epoch 26; Iter  1075/ 1097] train: loss: 0.2615121
[Epoch 26] ogbg-molhiv: 0.781697 val loss: 0.161561
[Epoch 26] ogbg-molhiv: 0.760909 test loss: 0.220358
[Epoch 27; Iter     8/ 1097] train: loss: 0.0331099
[Epoch 27; Iter    38/ 1097] train: loss: 0.1855457
[Epoch 27; Iter    68/ 1097] train: loss: 0.0374178
[Epoch 27; Iter    98/ 1097] train: loss: 0.0803175
[Epoch 27; Iter   128/ 1097] train: loss: 0.0335311
[Epoch 27; Iter   158/ 1097] train: loss: 0.1403312
[Epoch 27; Iter   188/ 1097] train: loss: 0.0656388
[Epoch 27; Iter   218/ 1097] train: loss: 0.1047871
[Epoch 27; Iter   248/ 1097] train: loss: 0.1084366
[Epoch 27; Iter   278/ 1097] train: loss: 0.0942112
[Epoch 27; Iter   308/ 1097] train: loss: 0.1349090
[Epoch 27; Iter   338/ 1097] train: loss: 0.0287177
[Epoch 27; Iter   368/ 1097] train: loss: 0.1168626
[Epoch 27; Iter   398/ 1097] train: loss: 0.2538771
[Epoch 27; Iter   428/ 1097] train: loss: 0.0280686
[Epoch 27; Iter   458/ 1097] train: loss: 0.0537655
[Epoch 27; Iter   488/ 1097] train: loss: 0.1121415
[Epoch 27; Iter   518/ 1097] train: loss: 0.3158606
[Epoch 27; Iter   548/ 1097] train: loss: 0.1682632
[Epoch 27; Iter   578/ 1097] train: loss: 0.1917085
[Epoch 27; Iter   608/ 1097] train: loss: 0.0221002
[Epoch 27; Iter   638/ 1097] train: loss: 0.0242201
[Epoch 27; Iter   668/ 1097] train: loss: 0.0249136
[Epoch 27; Iter   698/ 1097] train: loss: 0.1434197
[Epoch 27; Iter   728/ 1097] train: loss: 0.2065467
[Epoch 27; Iter   758/ 1097] train: loss: 0.0562419
[Epoch 27; Iter   788/ 1097] train: loss: 0.1623591
[Epoch 27; Iter   818/ 1097] train: loss: 0.0305806
[Epoch 27; Iter   848/ 1097] train: loss: 0.0182322
[Epoch 27; Iter   878/ 1097] train: loss: 0.0242229
[Epoch 27; Iter   908/ 1097] train: loss: 0.1589317
[Epoch 27; Iter   938/ 1097] train: loss: 0.1033080
[Epoch 27; Iter   968/ 1097] train: loss: 0.1980717
[Epoch 27; Iter   998/ 1097] train: loss: 0.1119970
[Epoch 27; Iter  1028/ 1097] train: loss: 0.1757975
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0329423
[Epoch 27; Iter  1088/ 1097] train: loss: 0.0312167
[Epoch 27] ogbg-molhiv: 0.786501 val loss: 0.127681
[Epoch 27] ogbg-molhiv: 0.761643 test loss: 0.236890
[Epoch 28; Iter    21/ 1097] train: loss: 0.1842244
[Epoch 28; Iter    51/ 1097] train: loss: 0.0662552
[Epoch 28; Iter    81/ 1097] train: loss: 0.0309957
[Epoch 28; Iter   111/ 1097] train: loss: 0.0216279
[Epoch 28; Iter   141/ 1097] train: loss: 0.0337316
[Epoch 28; Iter   171/ 1097] train: loss: 0.1791841
[Epoch 28; Iter   201/ 1097] train: loss: 0.0313036
[Epoch 28; Iter   231/ 1097] train: loss: 0.0230538
[Epoch 28; Iter   261/ 1097] train: loss: 0.0488279
[Epoch 28; Iter   291/ 1097] train: loss: 0.2136821
[Epoch 28; Iter   321/ 1097] train: loss: 0.1043837
[Epoch 28; Iter   351/ 1097] train: loss: 0.1171145
[Epoch 28; Iter   381/ 1097] train: loss: 0.0227834
[Epoch 28; Iter   411/ 1097] train: loss: 0.0823218
[Epoch 28; Iter   441/ 1097] train: loss: 0.0205422
[Epoch 24; Iter   389/ 1097] train: loss: 0.0636760
[Epoch 24; Iter   419/ 1097] train: loss: 0.3666018
[Epoch 24; Iter   449/ 1097] train: loss: 0.0569198
[Epoch 24; Iter   479/ 1097] train: loss: 0.1908200
[Epoch 24; Iter   509/ 1097] train: loss: 0.2296652
[Epoch 24; Iter   539/ 1097] train: loss: 0.0349755
[Epoch 24; Iter   569/ 1097] train: loss: 0.2112421
[Epoch 24; Iter   599/ 1097] train: loss: 0.1614069
[Epoch 24; Iter   629/ 1097] train: loss: 0.0505209
[Epoch 24; Iter   659/ 1097] train: loss: 0.0350355
[Epoch 24; Iter   689/ 1097] train: loss: 0.0128634
[Epoch 24; Iter   719/ 1097] train: loss: 0.1347784
[Epoch 24; Iter   749/ 1097] train: loss: 0.0444830
[Epoch 24; Iter   779/ 1097] train: loss: 0.1461649
[Epoch 24; Iter   809/ 1097] train: loss: 0.1606621
[Epoch 24; Iter   839/ 1097] train: loss: 0.0852317
[Epoch 24; Iter   869/ 1097] train: loss: 0.0501556
[Epoch 24; Iter   899/ 1097] train: loss: 0.2154637
[Epoch 24; Iter   929/ 1097] train: loss: 0.0919147
[Epoch 24; Iter   959/ 1097] train: loss: 0.2043215
[Epoch 24; Iter   989/ 1097] train: loss: 0.0461429
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1761258
[Epoch 24; Iter  1049/ 1097] train: loss: 0.1363100
[Epoch 24; Iter  1079/ 1097] train: loss: 0.2926192
[Epoch 24] ogbg-molhiv: 0.815146 val loss: 0.557257
[Epoch 24] ogbg-molhiv: 0.759854 test loss: 0.404942
[Epoch 25; Iter    12/ 1097] train: loss: 0.2217086
[Epoch 25; Iter    42/ 1097] train: loss: 0.0421085
[Epoch 25; Iter    72/ 1097] train: loss: 0.0269858
[Epoch 25; Iter   102/ 1097] train: loss: 0.2568963
[Epoch 25; Iter   132/ 1097] train: loss: 0.2528175
[Epoch 25; Iter   162/ 1097] train: loss: 0.0213213
[Epoch 25; Iter   192/ 1097] train: loss: 0.0339410
[Epoch 25; Iter   222/ 1097] train: loss: 0.1561230
[Epoch 25; Iter   252/ 1097] train: loss: 0.0231457
[Epoch 25; Iter   282/ 1097] train: loss: 0.1367463
[Epoch 25; Iter   312/ 1097] train: loss: 0.0868357
[Epoch 25; Iter   342/ 1097] train: loss: 0.0749414
[Epoch 25; Iter   372/ 1097] train: loss: 0.0337065
[Epoch 25; Iter   402/ 1097] train: loss: 0.0217142
[Epoch 25; Iter   432/ 1097] train: loss: 0.0830733
[Epoch 25; Iter   462/ 1097] train: loss: 0.1417942
[Epoch 25; Iter   492/ 1097] train: loss: 0.2023820
[Epoch 25; Iter   522/ 1097] train: loss: 0.2614338
[Epoch 25; Iter   552/ 1097] train: loss: 0.1880790
[Epoch 25; Iter   582/ 1097] train: loss: 0.1403095
[Epoch 25; Iter   612/ 1097] train: loss: 0.0284525
[Epoch 25; Iter   642/ 1097] train: loss: 0.0279056
[Epoch 25; Iter   672/ 1097] train: loss: 0.0235910
[Epoch 25; Iter   702/ 1097] train: loss: 0.0380112
[Epoch 25; Iter   732/ 1097] train: loss: 0.1322133
[Epoch 25; Iter   762/ 1097] train: loss: 0.0283297
[Epoch 25; Iter   792/ 1097] train: loss: 0.0370313
[Epoch 25; Iter   822/ 1097] train: loss: 0.0209321
[Epoch 25; Iter   852/ 1097] train: loss: 0.0213390
[Epoch 25; Iter   882/ 1097] train: loss: 0.0706472
[Epoch 25; Iter   912/ 1097] train: loss: 0.0239502
[Epoch 25; Iter   942/ 1097] train: loss: 0.1629658
[Epoch 25; Iter   972/ 1097] train: loss: 0.2272709
[Epoch 25; Iter  1002/ 1097] train: loss: 0.0266181
[Epoch 25; Iter  1032/ 1097] train: loss: 0.0537133
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0383861
[Epoch 25; Iter  1092/ 1097] train: loss: 0.4255165
[Epoch 25] ogbg-molhiv: 0.804058 val loss: 0.155429
[Epoch 25] ogbg-molhiv: 0.742799 test loss: 0.279255
[Epoch 26; Iter    25/ 1097] train: loss: 0.0466988
[Epoch 26; Iter    55/ 1097] train: loss: 0.0208836
[Epoch 26; Iter    85/ 1097] train: loss: 0.0709555
[Epoch 26; Iter   115/ 1097] train: loss: 0.0202059
[Epoch 26; Iter   145/ 1097] train: loss: 0.3287059
[Epoch 26; Iter   175/ 1097] train: loss: 0.0494081
[Epoch 26; Iter   205/ 1097] train: loss: 0.3411648
[Epoch 26; Iter   235/ 1097] train: loss: 0.0981473
[Epoch 26; Iter   265/ 1097] train: loss: 0.2993323
[Epoch 26; Iter   295/ 1097] train: loss: 0.0663053
[Epoch 26; Iter   325/ 1097] train: loss: 0.0395534
[Epoch 26; Iter   355/ 1097] train: loss: 0.0191457
[Epoch 26; Iter   385/ 1097] train: loss: 0.0867541
[Epoch 26; Iter   415/ 1097] train: loss: 0.0555681
[Epoch 26; Iter   445/ 1097] train: loss: 0.0422230
[Epoch 26; Iter   475/ 1097] train: loss: 0.0274738
[Epoch 26; Iter   505/ 1097] train: loss: 0.0587788
[Epoch 26; Iter   535/ 1097] train: loss: 0.1696242
[Epoch 26; Iter   565/ 1097] train: loss: 0.2866185
[Epoch 26; Iter   595/ 1097] train: loss: 0.0462239
[Epoch 26; Iter   625/ 1097] train: loss: 0.0556957
[Epoch 26; Iter   655/ 1097] train: loss: 0.1404549
[Epoch 26; Iter   685/ 1097] train: loss: 0.0652552
[Epoch 26; Iter   715/ 1097] train: loss: 0.2068789
[Epoch 26; Iter   745/ 1097] train: loss: 0.0882958
[Epoch 26; Iter   775/ 1097] train: loss: 0.0494047
[Epoch 26; Iter   805/ 1097] train: loss: 0.0803747
[Epoch 26; Iter   835/ 1097] train: loss: 0.1820546
[Epoch 26; Iter   865/ 1097] train: loss: 0.0495055
[Epoch 26; Iter   895/ 1097] train: loss: 0.0198226
[Epoch 26; Iter   925/ 1097] train: loss: 0.2713567
[Epoch 26; Iter   955/ 1097] train: loss: 0.0319805
[Epoch 26; Iter   985/ 1097] train: loss: 0.0552023
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0220636
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0417275
[Epoch 26; Iter  1075/ 1097] train: loss: 0.1821379
[Epoch 26] ogbg-molhiv: 0.814356 val loss: 0.111821
[Epoch 26] ogbg-molhiv: 0.737181 test loss: 0.294080
[Epoch 27; Iter     8/ 1097] train: loss: 0.0430278
[Epoch 27; Iter    38/ 1097] train: loss: 0.1741575
[Epoch 27; Iter    68/ 1097] train: loss: 0.3843353
[Epoch 27; Iter    98/ 1097] train: loss: 0.0278861
[Epoch 27; Iter   128/ 1097] train: loss: 0.0333932
[Epoch 27; Iter   158/ 1097] train: loss: 0.0687854
[Epoch 27; Iter   188/ 1097] train: loss: 0.1014835
[Epoch 27; Iter   218/ 1097] train: loss: 0.0410951
[Epoch 27; Iter   248/ 1097] train: loss: 0.0204260
[Epoch 27; Iter   278/ 1097] train: loss: 0.0398450
[Epoch 27; Iter   308/ 1097] train: loss: 0.0470125
[Epoch 27; Iter   338/ 1097] train: loss: 0.2017415
[Epoch 27; Iter   368/ 1097] train: loss: 0.2149797
[Epoch 27; Iter   398/ 1097] train: loss: 0.0278516
[Epoch 27; Iter   428/ 1097] train: loss: 0.0706272
[Epoch 27; Iter   458/ 1097] train: loss: 0.0192172
[Epoch 27; Iter   488/ 1097] train: loss: 0.0202424
[Epoch 27; Iter   518/ 1097] train: loss: 0.1799415
[Epoch 27; Iter   548/ 1097] train: loss: 0.0272146
[Epoch 27; Iter   578/ 1097] train: loss: 0.0333293
[Epoch 27; Iter   608/ 1097] train: loss: 0.0632846
[Epoch 27; Iter   638/ 1097] train: loss: 0.1747191
[Epoch 27; Iter   668/ 1097] train: loss: 0.1596105
[Epoch 27; Iter   698/ 1097] train: loss: 0.0387121
[Epoch 27; Iter   728/ 1097] train: loss: 0.0934414
[Epoch 27; Iter   758/ 1097] train: loss: 0.0557970
[Epoch 27; Iter   788/ 1097] train: loss: 0.0542073
[Epoch 27; Iter   818/ 1097] train: loss: 0.0262776
[Epoch 27; Iter   848/ 1097] train: loss: 0.0437666
[Epoch 27; Iter   878/ 1097] train: loss: 0.3784348
[Epoch 27; Iter   908/ 1097] train: loss: 0.1816305
[Epoch 27; Iter   938/ 1097] train: loss: 0.1025805
[Epoch 27; Iter   968/ 1097] train: loss: 0.0514882
[Epoch 27; Iter   998/ 1097] train: loss: 0.0304160
[Epoch 27; Iter  1028/ 1097] train: loss: 0.3775851
[Epoch 27; Iter  1058/ 1097] train: loss: 0.0811328
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1624761
[Epoch 27] ogbg-molhiv: 0.829359 val loss: 0.795858
[Epoch 27] ogbg-molhiv: 0.749987 test loss: 0.440504
[Epoch 28; Iter    21/ 1097] train: loss: 0.1507055
[Epoch 28; Iter    51/ 1097] train: loss: 0.0373453
[Epoch 28; Iter    81/ 1097] train: loss: 0.1685582
[Epoch 28; Iter   111/ 1097] train: loss: 0.1854794
[Epoch 28; Iter   141/ 1097] train: loss: 0.0210569
[Epoch 28; Iter   171/ 1097] train: loss: 0.0293813
[Epoch 28; Iter   201/ 1097] train: loss: 0.0233190
[Epoch 28; Iter   231/ 1097] train: loss: 0.0410719
[Epoch 28; Iter   261/ 1097] train: loss: 0.0352416
[Epoch 28; Iter   291/ 1097] train: loss: 0.0172671
[Epoch 28; Iter   321/ 1097] train: loss: 0.0830660
[Epoch 28; Iter   351/ 1097] train: loss: 0.0323209
[Epoch 28; Iter   381/ 1097] train: loss: 0.0475693
[Epoch 28; Iter   411/ 1097] train: loss: 0.2144006
[Epoch 28; Iter   441/ 1097] train: loss: 0.1887440
[Epoch 26; Iter   185/  823] train: loss: 0.0173283
[Epoch 26; Iter   215/  823] train: loss: 0.0209006
[Epoch 26; Iter   245/  823] train: loss: 0.0213538
[Epoch 26; Iter   275/  823] train: loss: 0.0945391
[Epoch 26; Iter   305/  823] train: loss: 0.0867387
[Epoch 26; Iter   335/  823] train: loss: 0.1126505
[Epoch 26; Iter   365/  823] train: loss: 0.0421993
[Epoch 26; Iter   395/  823] train: loss: 0.1175352
[Epoch 26; Iter   425/  823] train: loss: 0.0265144
[Epoch 26; Iter   455/  823] train: loss: 0.0775876
[Epoch 26; Iter   485/  823] train: loss: 0.0190831
[Epoch 26; Iter   515/  823] train: loss: 0.0818253
[Epoch 26; Iter   545/  823] train: loss: 0.0559832
[Epoch 26; Iter   575/  823] train: loss: 0.2115858
[Epoch 26; Iter   605/  823] train: loss: 0.0748161
[Epoch 26; Iter   635/  823] train: loss: 0.2634726
[Epoch 26; Iter   665/  823] train: loss: 0.1272026
[Epoch 26; Iter   695/  823] train: loss: 0.2389736
[Epoch 26; Iter   725/  823] train: loss: 0.0355343
[Epoch 26; Iter   755/  823] train: loss: 0.0591910
[Epoch 26; Iter   785/  823] train: loss: 0.0360778
[Epoch 26; Iter   815/  823] train: loss: 0.0237037
[Epoch 26] ogbg-molhiv: 0.693662 val loss: 0.358328
[Epoch 26] ogbg-molhiv: 0.734700 test loss: 1.111368
[Epoch 27; Iter    22/  823] train: loss: 0.0243187
[Epoch 27; Iter    52/  823] train: loss: 0.1568755
[Epoch 27; Iter    82/  823] train: loss: 0.0359929
[Epoch 27; Iter   112/  823] train: loss: 0.0527845
[Epoch 27; Iter   142/  823] train: loss: 0.0227269
[Epoch 27; Iter   172/  823] train: loss: 0.0301884
[Epoch 27; Iter   202/  823] train: loss: 0.0843567
[Epoch 27; Iter   232/  823] train: loss: 0.0215438
[Epoch 27; Iter   262/  823] train: loss: 0.0731195
[Epoch 27; Iter   292/  823] train: loss: 0.1148648
[Epoch 27; Iter   322/  823] train: loss: 0.2683130
[Epoch 27; Iter   352/  823] train: loss: 0.0394576
[Epoch 27; Iter   382/  823] train: loss: 0.1464815
[Epoch 27; Iter   412/  823] train: loss: 0.0622200
[Epoch 27; Iter   442/  823] train: loss: 0.0965181
[Epoch 27; Iter   472/  823] train: loss: 0.0437569
[Epoch 27; Iter   502/  823] train: loss: 0.2646471
[Epoch 27; Iter   532/  823] train: loss: 0.0198462
[Epoch 27; Iter   562/  823] train: loss: 0.0682693
[Epoch 27; Iter   592/  823] train: loss: 0.1365792
[Epoch 27; Iter   622/  823] train: loss: 0.1939447
[Epoch 27; Iter   652/  823] train: loss: 0.0211727
[Epoch 27; Iter   682/  823] train: loss: 0.1688504
[Epoch 27; Iter   712/  823] train: loss: 0.0224624
[Epoch 27; Iter   742/  823] train: loss: 0.0838732
[Epoch 27; Iter   772/  823] train: loss: 0.0178910
[Epoch 27; Iter   802/  823] train: loss: 0.2348409
[Epoch 27] ogbg-molhiv: 0.723755 val loss: 0.357110
[Epoch 27] ogbg-molhiv: 0.762000 test loss: 0.940225
[Epoch 28; Iter     9/  823] train: loss: 0.0489684
[Epoch 28; Iter    39/  823] train: loss: 0.0263257
[Epoch 28; Iter    69/  823] train: loss: 0.1540972
[Epoch 28; Iter    99/  823] train: loss: 0.0263432
[Epoch 28; Iter   129/  823] train: loss: 0.2512392
[Epoch 28; Iter   159/  823] train: loss: 0.3172762
[Epoch 28; Iter   189/  823] train: loss: 0.1766106
[Epoch 28; Iter   219/  823] train: loss: 0.0237190
[Epoch 28; Iter   249/  823] train: loss: 0.0466225
[Epoch 28; Iter   279/  823] train: loss: 0.0156224
[Epoch 28; Iter   309/  823] train: loss: 0.0796248
[Epoch 28; Iter   339/  823] train: loss: 0.0348191
[Epoch 28; Iter   369/  823] train: loss: 0.0221711
[Epoch 28; Iter   399/  823] train: loss: 0.0987369
[Epoch 28; Iter   429/  823] train: loss: 0.1173402
[Epoch 28; Iter   459/  823] train: loss: 0.1432121
[Epoch 28; Iter   489/  823] train: loss: 0.0400180
[Epoch 28; Iter   519/  823] train: loss: 0.0189216
[Epoch 28; Iter   549/  823] train: loss: 0.3612587
[Epoch 28; Iter   579/  823] train: loss: 0.0717434
[Epoch 28; Iter   609/  823] train: loss: 0.0973656
[Epoch 28; Iter   639/  823] train: loss: 0.1408442
[Epoch 28; Iter   669/  823] train: loss: 0.0428523
[Epoch 28; Iter   699/  823] train: loss: 0.1292408
[Epoch 28; Iter   729/  823] train: loss: 0.0325096
[Epoch 28; Iter   759/  823] train: loss: 0.0327379
[Epoch 28; Iter   789/  823] train: loss: 0.0601376
[Epoch 28; Iter   819/  823] train: loss: 0.0197592
[Epoch 28] ogbg-molhiv: 0.705268 val loss: 0.197034
[Epoch 28] ogbg-molhiv: 0.743503 test loss: 0.314061
[Epoch 29; Iter    26/  823] train: loss: 0.1639573
[Epoch 29; Iter    56/  823] train: loss: 0.0272961
[Epoch 29; Iter    86/  823] train: loss: 0.0286045
[Epoch 29; Iter   116/  823] train: loss: 0.0277298
[Epoch 29; Iter   146/  823] train: loss: 0.0206677
[Epoch 29; Iter   176/  823] train: loss: 0.0537787
[Epoch 29; Iter   206/  823] train: loss: 0.0269140
[Epoch 29; Iter   236/  823] train: loss: 0.0383800
[Epoch 29; Iter   266/  823] train: loss: 0.0120040
[Epoch 29; Iter   296/  823] train: loss: 0.5474000
[Epoch 29; Iter   326/  823] train: loss: 0.0904317
[Epoch 29; Iter   356/  823] train: loss: 0.0327758
[Epoch 29; Iter   386/  823] train: loss: 0.2493707
[Epoch 29; Iter   416/  823] train: loss: 0.1452014
[Epoch 29; Iter   446/  823] train: loss: 0.0621938
[Epoch 29; Iter   476/  823] train: loss: 0.1762490
[Epoch 29; Iter   506/  823] train: loss: 0.0290186
[Epoch 29; Iter   536/  823] train: loss: 0.0399041
[Epoch 29; Iter   566/  823] train: loss: 0.0398837
[Epoch 29; Iter   596/  823] train: loss: 0.0932521
[Epoch 29; Iter   626/  823] train: loss: 0.0303991
[Epoch 29; Iter   656/  823] train: loss: 0.1801559
[Epoch 29; Iter   686/  823] train: loss: 0.0955223
[Epoch 29; Iter   716/  823] train: loss: 0.0401319
[Epoch 29; Iter   746/  823] train: loss: 0.1910960
[Epoch 29; Iter   776/  823] train: loss: 0.3823288
[Epoch 29; Iter   806/  823] train: loss: 0.0225652
[Epoch 29] ogbg-molhiv: 0.719330 val loss: 0.147583
[Epoch 29] ogbg-molhiv: 0.762353 test loss: 0.239258
[Epoch 30; Iter    13/  823] train: loss: 0.0428307
[Epoch 30; Iter    43/  823] train: loss: 0.0243138
[Epoch 30; Iter    73/  823] train: loss: 0.2232860
[Epoch 30; Iter   103/  823] train: loss: 0.1026089
[Epoch 30; Iter   133/  823] train: loss: 0.0831201
[Epoch 30; Iter   163/  823] train: loss: 0.1135827
[Epoch 30; Iter   193/  823] train: loss: 0.4090787
[Epoch 30; Iter   223/  823] train: loss: 0.0216108
[Epoch 30; Iter   253/  823] train: loss: 0.0371734
[Epoch 30; Iter   283/  823] train: loss: 0.0470295
[Epoch 30; Iter   313/  823] train: loss: 0.0616043
[Epoch 30; Iter   343/  823] train: loss: 0.0233195
[Epoch 30; Iter   373/  823] train: loss: 0.1133484
[Epoch 30; Iter   403/  823] train: loss: 0.0923275
[Epoch 30; Iter   433/  823] train: loss: 0.0232378
[Epoch 30; Iter   463/  823] train: loss: 0.0194481
[Epoch 30; Iter   493/  823] train: loss: 0.2725566
[Epoch 30; Iter   523/  823] train: loss: 0.0600806
[Epoch 30; Iter   553/  823] train: loss: 0.0183234
[Epoch 30; Iter   583/  823] train: loss: 0.0421182
[Epoch 30; Iter   613/  823] train: loss: 0.1811978
[Epoch 30; Iter   643/  823] train: loss: 0.0278647
[Epoch 30; Iter   673/  823] train: loss: 0.0736383
[Epoch 30; Iter   703/  823] train: loss: 0.1518764
[Epoch 30; Iter   733/  823] train: loss: 0.1539260
[Epoch 30; Iter   763/  823] train: loss: 0.0238501
[Epoch 30; Iter   793/  823] train: loss: 0.2437925
[Epoch 30; Iter   823/  823] train: loss: 0.0177905
[Epoch 30] ogbg-molhiv: 0.705030 val loss: 0.225103
[Epoch 30] ogbg-molhiv: 0.754588 test loss: 0.389227
[Epoch 31; Iter    30/  823] train: loss: 0.0521525
[Epoch 31; Iter    60/  823] train: loss: 0.0158360
[Epoch 31; Iter    90/  823] train: loss: 0.0828761
[Epoch 31; Iter   120/  823] train: loss: 0.0625572
[Epoch 31; Iter   150/  823] train: loss: 0.0753393
[Epoch 31; Iter   180/  823] train: loss: 0.0267156
[Epoch 31; Iter   210/  823] train: loss: 0.0782273
[Epoch 31; Iter   240/  823] train: loss: 0.1222506
[Epoch 31; Iter   270/  823] train: loss: 0.0685671
[Epoch 31; Iter   300/  823] train: loss: 0.0164513
[Epoch 31; Iter   330/  823] train: loss: 0.0616142
[Epoch 31; Iter   360/  823] train: loss: 0.1904385
[Epoch 31; Iter   390/  823] train: loss: 0.1224876
[Epoch 31; Iter   420/  823] train: loss: 0.0345041
[Epoch 31; Iter   450/  823] train: loss: 0.0629212
[Epoch 24; Iter   389/ 1097] train: loss: 0.0989186
[Epoch 24; Iter   419/ 1097] train: loss: 0.3312870
[Epoch 24; Iter   449/ 1097] train: loss: 0.0197862
[Epoch 24; Iter   479/ 1097] train: loss: 0.0665772
[Epoch 24; Iter   509/ 1097] train: loss: 0.0266293
[Epoch 24; Iter   539/ 1097] train: loss: 0.0227799
[Epoch 24; Iter   569/ 1097] train: loss: 0.1603107
[Epoch 24; Iter   599/ 1097] train: loss: 0.1204942
[Epoch 24; Iter   629/ 1097] train: loss: 0.0186442
[Epoch 24; Iter   659/ 1097] train: loss: 0.0193187
[Epoch 24; Iter   689/ 1097] train: loss: 0.0361256
[Epoch 24; Iter   719/ 1097] train: loss: 0.0138432
[Epoch 24; Iter   749/ 1097] train: loss: 0.0321562
[Epoch 24; Iter   779/ 1097] train: loss: 0.1089147
[Epoch 24; Iter   809/ 1097] train: loss: 0.0530985
[Epoch 24; Iter   839/ 1097] train: loss: 0.1663302
[Epoch 24; Iter   869/ 1097] train: loss: 0.1298615
[Epoch 24; Iter   899/ 1097] train: loss: 0.3050092
[Epoch 24; Iter   929/ 1097] train: loss: 0.3210332
[Epoch 24; Iter   959/ 1097] train: loss: 0.0243981
[Epoch 24; Iter   989/ 1097] train: loss: 0.0227342
[Epoch 24; Iter  1019/ 1097] train: loss: 0.1612119
[Epoch 24; Iter  1049/ 1097] train: loss: 0.0546559
[Epoch 24; Iter  1079/ 1097] train: loss: 0.0296940
[Epoch 24] ogbg-molhiv: 0.807518 val loss: 0.083314
[Epoch 24] ogbg-molhiv: 0.729676 test loss: 0.126419
[Epoch 25; Iter    12/ 1097] train: loss: 0.0676899
[Epoch 25; Iter    42/ 1097] train: loss: 0.2043344
[Epoch 25; Iter    72/ 1097] train: loss: 0.0305148
[Epoch 25; Iter   102/ 1097] train: loss: 0.0744945
[Epoch 25; Iter   132/ 1097] train: loss: 0.0416196
[Epoch 25; Iter   162/ 1097] train: loss: 0.0211911
[Epoch 25; Iter   192/ 1097] train: loss: 0.0799771
[Epoch 25; Iter   222/ 1097] train: loss: 0.0192808
[Epoch 25; Iter   252/ 1097] train: loss: 0.0830474
[Epoch 25; Iter   282/ 1097] train: loss: 0.0941169
[Epoch 25; Iter   312/ 1097] train: loss: 0.0590209
[Epoch 25; Iter   342/ 1097] train: loss: 0.0344623
[Epoch 25; Iter   372/ 1097] train: loss: 0.2658708
[Epoch 25; Iter   402/ 1097] train: loss: 0.0245387
[Epoch 25; Iter   432/ 1097] train: loss: 0.2045550
[Epoch 25; Iter   462/ 1097] train: loss: 0.0331544
[Epoch 25; Iter   492/ 1097] train: loss: 0.2088592
[Epoch 25; Iter   522/ 1097] train: loss: 0.0142180
[Epoch 25; Iter   552/ 1097] train: loss: 0.1583553
[Epoch 25; Iter   582/ 1097] train: loss: 0.1781278
[Epoch 25; Iter   612/ 1097] train: loss: 0.1747767
[Epoch 25; Iter   642/ 1097] train: loss: 0.1442976
[Epoch 25; Iter   672/ 1097] train: loss: 0.0179832
[Epoch 25; Iter   702/ 1097] train: loss: 0.1134564
[Epoch 25; Iter   732/ 1097] train: loss: 0.0543382
[Epoch 25; Iter   762/ 1097] train: loss: 0.1670821
[Epoch 25; Iter   792/ 1097] train: loss: 0.0358732
[Epoch 25; Iter   822/ 1097] train: loss: 0.0753154
[Epoch 25; Iter   852/ 1097] train: loss: 0.0312494
[Epoch 25; Iter   882/ 1097] train: loss: 0.0619159
[Epoch 25; Iter   912/ 1097] train: loss: 0.1473571
[Epoch 25; Iter   942/ 1097] train: loss: 0.0361434
[Epoch 25; Iter   972/ 1097] train: loss: 0.1001237
[Epoch 25; Iter  1002/ 1097] train: loss: 0.2796023
[Epoch 25; Iter  1032/ 1097] train: loss: 0.2557904
[Epoch 25; Iter  1062/ 1097] train: loss: 0.0270433
[Epoch 25; Iter  1092/ 1097] train: loss: 0.1381773
[Epoch 25] ogbg-molhiv: 0.780209 val loss: 0.119780
[Epoch 25] ogbg-molhiv: 0.729396 test loss: 0.124256
[Epoch 26; Iter    25/ 1097] train: loss: 0.0330359
[Epoch 26; Iter    55/ 1097] train: loss: 0.0544619
[Epoch 26; Iter    85/ 1097] train: loss: 0.1081673
[Epoch 26; Iter   115/ 1097] train: loss: 0.2069231
[Epoch 26; Iter   145/ 1097] train: loss: 0.0909160
[Epoch 26; Iter   175/ 1097] train: loss: 0.1597927
[Epoch 26; Iter   205/ 1097] train: loss: 0.3801391
[Epoch 26; Iter   235/ 1097] train: loss: 0.0368545
[Epoch 26; Iter   265/ 1097] train: loss: 0.0405175
[Epoch 26; Iter   295/ 1097] train: loss: 0.1467571
[Epoch 26; Iter   325/ 1097] train: loss: 0.0625580
[Epoch 26; Iter   355/ 1097] train: loss: 0.0334465
[Epoch 26; Iter   385/ 1097] train: loss: 0.0346240
[Epoch 26; Iter   415/ 1097] train: loss: 0.0531525
[Epoch 26; Iter   445/ 1097] train: loss: 0.0335108
[Epoch 26; Iter   475/ 1097] train: loss: 0.0469636
[Epoch 26; Iter   505/ 1097] train: loss: 0.1385878
[Epoch 26; Iter   535/ 1097] train: loss: 0.0659994
[Epoch 26; Iter   565/ 1097] train: loss: 0.1415316
[Epoch 26; Iter   595/ 1097] train: loss: 0.0519661
[Epoch 26; Iter   625/ 1097] train: loss: 0.1143129
[Epoch 26; Iter   655/ 1097] train: loss: 0.0302595
[Epoch 26; Iter   685/ 1097] train: loss: 0.1718633
[Epoch 26; Iter   715/ 1097] train: loss: 0.0231086
[Epoch 26; Iter   745/ 1097] train: loss: 0.0173872
[Epoch 26; Iter   775/ 1097] train: loss: 0.0582290
[Epoch 26; Iter   805/ 1097] train: loss: 0.1412613
[Epoch 26; Iter   835/ 1097] train: loss: 0.1976656
[Epoch 26; Iter   865/ 1097] train: loss: 0.1538664
[Epoch 26; Iter   895/ 1097] train: loss: 0.0223730
[Epoch 26; Iter   925/ 1097] train: loss: 0.4425340
[Epoch 26; Iter   955/ 1097] train: loss: 0.0230494
[Epoch 26; Iter   985/ 1097] train: loss: 0.0898554
[Epoch 26; Iter  1015/ 1097] train: loss: 0.0371000
[Epoch 26; Iter  1045/ 1097] train: loss: 0.0457665
[Epoch 26; Iter  1075/ 1097] train: loss: 0.0905547
[Epoch 26] ogbg-molhiv: 0.813140 val loss: 0.075685
[Epoch 26] ogbg-molhiv: 0.755841 test loss: 0.116308
[Epoch 27; Iter     8/ 1097] train: loss: 0.0680514
[Epoch 27; Iter    38/ 1097] train: loss: 0.1229907
[Epoch 27; Iter    68/ 1097] train: loss: 0.0184062
[Epoch 27; Iter    98/ 1097] train: loss: 0.1622553
[Epoch 27; Iter   128/ 1097] train: loss: 0.1476710
[Epoch 27; Iter   158/ 1097] train: loss: 0.0577322
[Epoch 27; Iter   188/ 1097] train: loss: 0.0190298
[Epoch 27; Iter   218/ 1097] train: loss: 0.1058179
[Epoch 27; Iter   248/ 1097] train: loss: 0.0394334
[Epoch 27; Iter   278/ 1097] train: loss: 0.0326703
[Epoch 27; Iter   308/ 1097] train: loss: 0.0401116
[Epoch 27; Iter   338/ 1097] train: loss: 0.0424468
[Epoch 27; Iter   368/ 1097] train: loss: 0.1853589
[Epoch 27; Iter   398/ 1097] train: loss: 0.0186787
[Epoch 27; Iter   428/ 1097] train: loss: 0.1455160
[Epoch 27; Iter   458/ 1097] train: loss: 0.0388155
[Epoch 27; Iter   488/ 1097] train: loss: 0.1080906
[Epoch 27; Iter   518/ 1097] train: loss: 0.1509113
[Epoch 27; Iter   548/ 1097] train: loss: 0.0966119
[Epoch 27; Iter   578/ 1097] train: loss: 0.1497625
[Epoch 27; Iter   608/ 1097] train: loss: 0.1691113
[Epoch 27; Iter   638/ 1097] train: loss: 0.0556321
[Epoch 27; Iter   668/ 1097] train: loss: 0.0573660
[Epoch 27; Iter   698/ 1097] train: loss: 0.0239253
[Epoch 27; Iter   728/ 1097] train: loss: 0.2233212
[Epoch 27; Iter   758/ 1097] train: loss: 0.0204765
[Epoch 27; Iter   788/ 1097] train: loss: 0.0303845
[Epoch 27; Iter   818/ 1097] train: loss: 0.0998605
[Epoch 27; Iter   848/ 1097] train: loss: 0.1183707
[Epoch 27; Iter   878/ 1097] train: loss: 0.0478597
[Epoch 27; Iter   908/ 1097] train: loss: 0.0287735
[Epoch 27; Iter   938/ 1097] train: loss: 0.2765766
[Epoch 27; Iter   968/ 1097] train: loss: 0.0222082
[Epoch 27; Iter   998/ 1097] train: loss: 0.1273036
[Epoch 27; Iter  1028/ 1097] train: loss: 0.0210001
[Epoch 27; Iter  1058/ 1097] train: loss: 0.2859644
[Epoch 27; Iter  1088/ 1097] train: loss: 0.1375800
[Epoch 27] ogbg-molhiv: 0.807990 val loss: 0.074350
[Epoch 27] ogbg-molhiv: 0.737378 test loss: 0.125118
[Epoch 28; Iter    21/ 1097] train: loss: 0.0210383
[Epoch 28; Iter    51/ 1097] train: loss: 0.0455050
[Epoch 28; Iter    81/ 1097] train: loss: 0.0137921
[Epoch 28; Iter   111/ 1097] train: loss: 0.1034644
[Epoch 28; Iter   141/ 1097] train: loss: 0.1743727
[Epoch 28; Iter   171/ 1097] train: loss: 0.1677454
[Epoch 28; Iter   201/ 1097] train: loss: 0.0955662
[Epoch 28; Iter   231/ 1097] train: loss: 0.1277795
[Epoch 28; Iter   261/ 1097] train: loss: 0.1569111
[Epoch 28; Iter   291/ 1097] train: loss: 0.0207047
[Epoch 28; Iter   321/ 1097] train: loss: 0.0290484
[Epoch 28; Iter   351/ 1097] train: loss: 0.0374622
[Epoch 28; Iter   381/ 1097] train: loss: 0.2586946
[Epoch 28; Iter   411/ 1097] train: loss: 0.0178216
[Epoch 28; Iter   441/ 1097] train: loss: 0.6966368
[Epoch 26; Iter   185/  823] train: loss: 0.1284139
[Epoch 26; Iter   215/  823] train: loss: 0.1708309
[Epoch 26; Iter   245/  823] train: loss: 0.0570519
[Epoch 26; Iter   275/  823] train: loss: 0.0708927
[Epoch 26; Iter   305/  823] train: loss: 0.1778168
[Epoch 26; Iter   335/  823] train: loss: 0.0166787
[Epoch 26; Iter   365/  823] train: loss: 0.1691993
[Epoch 26; Iter   395/  823] train: loss: 0.0262214
[Epoch 26; Iter   425/  823] train: loss: 0.0333531
[Epoch 26; Iter   455/  823] train: loss: 0.0724991
[Epoch 26; Iter   485/  823] train: loss: 0.3802115
[Epoch 26; Iter   515/  823] train: loss: 0.1055890
[Epoch 26; Iter   545/  823] train: loss: 0.0211018
[Epoch 26; Iter   575/  823] train: loss: 0.2401127
[Epoch 26; Iter   605/  823] train: loss: 0.0267585
[Epoch 26; Iter   635/  823] train: loss: 0.1762261
[Epoch 26; Iter   665/  823] train: loss: 0.0585471
[Epoch 26; Iter   695/  823] train: loss: 0.0401835
[Epoch 26; Iter   725/  823] train: loss: 0.1376846
[Epoch 26; Iter   755/  823] train: loss: 0.0225075
[Epoch 26; Iter   785/  823] train: loss: 0.1037256
[Epoch 26; Iter   815/  823] train: loss: 0.2492031
[Epoch 26] ogbg-molhiv: 0.708350 val loss: 0.158990
[Epoch 26] ogbg-molhiv: 0.745316 test loss: 0.146776
[Epoch 27; Iter    22/  823] train: loss: 0.0320253
[Epoch 27; Iter    52/  823] train: loss: 0.1623243
[Epoch 27; Iter    82/  823] train: loss: 0.0617088
[Epoch 27; Iter   112/  823] train: loss: 0.1790468
[Epoch 27; Iter   142/  823] train: loss: 0.0201502
[Epoch 27; Iter   172/  823] train: loss: 0.0995700
[Epoch 27; Iter   202/  823] train: loss: 0.1366922
[Epoch 27; Iter   232/  823] train: loss: 0.0771528
[Epoch 27; Iter   262/  823] train: loss: 0.0272683
[Epoch 27; Iter   292/  823] train: loss: 0.0418044
[Epoch 27; Iter   322/  823] train: loss: 0.0643459
[Epoch 27; Iter   352/  823] train: loss: 0.0572286
[Epoch 27; Iter   382/  823] train: loss: 0.0205710
[Epoch 27; Iter   412/  823] train: loss: 0.0298219
[Epoch 27; Iter   442/  823] train: loss: 0.2205365
[Epoch 27; Iter   472/  823] train: loss: 0.0253503
[Epoch 27; Iter   502/  823] train: loss: 0.1092903
[Epoch 27; Iter   532/  823] train: loss: 0.1648580
[Epoch 27; Iter   562/  823] train: loss: 0.1305141
[Epoch 27; Iter   592/  823] train: loss: 0.0184433
[Epoch 27; Iter   622/  823] train: loss: 0.1938737
[Epoch 27; Iter   652/  823] train: loss: 0.1343634
[Epoch 27; Iter   682/  823] train: loss: 0.0361722
[Epoch 27; Iter   712/  823] train: loss: 0.0281542
[Epoch 27; Iter   742/  823] train: loss: 0.0292528
[Epoch 27; Iter   772/  823] train: loss: 0.1989896
[Epoch 27; Iter   802/  823] train: loss: 0.0189696
[Epoch 27] ogbg-molhiv: 0.722027 val loss: 0.271778
[Epoch 27] ogbg-molhiv: 0.767439 test loss: 0.194199
[Epoch 28; Iter     9/  823] train: loss: 0.0220667
[Epoch 28; Iter    39/  823] train: loss: 0.0280116
[Epoch 28; Iter    69/  823] train: loss: 0.0215503
[Epoch 28; Iter    99/  823] train: loss: 0.0174299
[Epoch 28; Iter   129/  823] train: loss: 0.2499449
[Epoch 28; Iter   159/  823] train: loss: 0.1538879
[Epoch 28; Iter   189/  823] train: loss: 0.0549012
[Epoch 28; Iter   219/  823] train: loss: 0.1015732
[Epoch 28; Iter   249/  823] train: loss: 0.1825787
[Epoch 28; Iter   279/  823] train: loss: 0.0382036
[Epoch 28; Iter   309/  823] train: loss: 0.4049289
[Epoch 28; Iter   339/  823] train: loss: 0.0430060
[Epoch 28; Iter   369/  823] train: loss: 0.0497083
[Epoch 28; Iter   399/  823] train: loss: 0.0233638
[Epoch 28; Iter   429/  823] train: loss: 0.2221646
[Epoch 28; Iter   459/  823] train: loss: 0.0971258
[Epoch 28; Iter   489/  823] train: loss: 0.0871024
[Epoch 28; Iter   519/  823] train: loss: 0.0324952
[Epoch 28; Iter   549/  823] train: loss: 0.0397560
[Epoch 28; Iter   579/  823] train: loss: 0.0977978
[Epoch 28; Iter   609/  823] train: loss: 0.2217103
[Epoch 28; Iter   639/  823] train: loss: 0.0312805
[Epoch 28; Iter   669/  823] train: loss: 0.6261276
[Epoch 28; Iter   699/  823] train: loss: 0.0303542
[Epoch 28; Iter   729/  823] train: loss: 0.0249809
[Epoch 28; Iter   759/  823] train: loss: 0.2412011
[Epoch 28; Iter   789/  823] train: loss: 0.0568536
[Epoch 28; Iter   819/  823] train: loss: 0.0176227
[Epoch 28] ogbg-molhiv: 0.719539 val loss: 0.245792
[Epoch 28] ogbg-molhiv: 0.767056 test loss: 0.118990
[Epoch 29; Iter    26/  823] train: loss: 0.0216578
[Epoch 29; Iter    56/  823] train: loss: 0.0177233
[Epoch 29; Iter    86/  823] train: loss: 0.1036697
[Epoch 29; Iter   116/  823] train: loss: 0.0381772
[Epoch 29; Iter   146/  823] train: loss: 0.0608754
[Epoch 29; Iter   176/  823] train: loss: 0.0271311
[Epoch 29; Iter   206/  823] train: loss: 0.1276612
[Epoch 29; Iter   236/  823] train: loss: 0.0677522
[Epoch 29; Iter   266/  823] train: loss: 0.1657259
[Epoch 29; Iter   296/  823] train: loss: 0.0181239
[Epoch 29; Iter   326/  823] train: loss: 0.0686633
[Epoch 29; Iter   356/  823] train: loss: 0.0158448
[Epoch 29; Iter   386/  823] train: loss: 0.0140949
[Epoch 29; Iter   416/  823] train: loss: 0.0412652
[Epoch 29; Iter   446/  823] train: loss: 0.1485016
[Epoch 29; Iter   476/  823] train: loss: 0.1335153
[Epoch 29; Iter   506/  823] train: loss: 0.1248360
[Epoch 29; Iter   536/  823] train: loss: 0.0549979
[Epoch 29; Iter   566/  823] train: loss: 0.0158291
[Epoch 29; Iter   596/  823] train: loss: 0.1456008
[Epoch 29; Iter   626/  823] train: loss: 0.1343365
[Epoch 29; Iter   656/  823] train: loss: 0.2365015
[Epoch 29; Iter   686/  823] train: loss: 0.2200521
[Epoch 29; Iter   716/  823] train: loss: 0.1193958
[Epoch 29; Iter   746/  823] train: loss: 0.1998648
[Epoch 29; Iter   776/  823] train: loss: 0.1909221
[Epoch 29; Iter   806/  823] train: loss: 0.0244636
[Epoch 29] ogbg-molhiv: 0.723103 val loss: 0.167079
[Epoch 29] ogbg-molhiv: 0.752312 test loss: 0.126377
[Epoch 30; Iter    13/  823] train: loss: 0.2793545
[Epoch 30; Iter    43/  823] train: loss: 0.0540177
[Epoch 30; Iter    73/  823] train: loss: 0.0187119
[Epoch 30; Iter   103/  823] train: loss: 0.0301132
[Epoch 30; Iter   133/  823] train: loss: 0.0170511
[Epoch 30; Iter   163/  823] train: loss: 0.1078631
[Epoch 30; Iter   193/  823] train: loss: 0.0188670
[Epoch 30; Iter   223/  823] train: loss: 0.0342770
[Epoch 30; Iter   253/  823] train: loss: 0.0142089
[Epoch 30; Iter   283/  823] train: loss: 0.0753151
[Epoch 30; Iter   313/  823] train: loss: 0.0937263
[Epoch 30; Iter   343/  823] train: loss: 0.1038422
[Epoch 30; Iter   373/  823] train: loss: 0.1439206
[Epoch 30; Iter   403/  823] train: loss: 0.0239328
[Epoch 30; Iter   433/  823] train: loss: 0.1636390
[Epoch 30; Iter   463/  823] train: loss: 0.0661235
[Epoch 30; Iter   493/  823] train: loss: 0.2162084
[Epoch 30; Iter   523/  823] train: loss: 0.0777791
[Epoch 30; Iter   553/  823] train: loss: 0.0704593
[Epoch 30; Iter   583/  823] train: loss: 0.0612095
[Epoch 30; Iter   613/  823] train: loss: 0.0677122
[Epoch 30; Iter   643/  823] train: loss: 0.1537417
[Epoch 30; Iter   673/  823] train: loss: 0.0865276
[Epoch 30; Iter   703/  823] train: loss: 0.0852166
[Epoch 30; Iter   733/  823] train: loss: 0.0274929
[Epoch 30; Iter   763/  823] train: loss: 0.0193188
[Epoch 30; Iter   793/  823] train: loss: 0.1171867
[Epoch 30; Iter   823/  823] train: loss: 0.0399661
[Epoch 30] ogbg-molhiv: 0.739145 val loss: 0.169954
[Epoch 30] ogbg-molhiv: 0.757495 test loss: 0.107629
[Epoch 31; Iter    30/  823] train: loss: 0.1696598
[Epoch 31; Iter    60/  823] train: loss: 0.1263933
[Epoch 31; Iter    90/  823] train: loss: 0.0215174
[Epoch 31; Iter   120/  823] train: loss: 0.0325581
[Epoch 31; Iter   150/  823] train: loss: 0.0333646
[Epoch 31; Iter   180/  823] train: loss: 0.0451123
[Epoch 31; Iter   210/  823] train: loss: 0.0120053
[Epoch 31; Iter   240/  823] train: loss: 0.0246103
[Epoch 31; Iter   270/  823] train: loss: 0.0114126
[Epoch 31; Iter   300/  823] train: loss: 0.0191878
[Epoch 31; Iter   330/  823] train: loss: 0.1570689
[Epoch 31; Iter   360/  823] train: loss: 0.0323285
[Epoch 31; Iter   390/  823] train: loss: 0.1063627
[Epoch 31; Iter   420/  823] train: loss: 0.1462339
[Epoch 31; Iter   450/  823] train: loss: 0.0434230
[Epoch 26; Iter   185/  823] train: loss: 0.0664482
[Epoch 26; Iter   215/  823] train: loss: 0.0321854
[Epoch 26; Iter   245/  823] train: loss: 0.2404283
[Epoch 26; Iter   275/  823] train: loss: 0.1465362
[Epoch 26; Iter   305/  823] train: loss: 0.1750437
[Epoch 26; Iter   335/  823] train: loss: 0.0205007
[Epoch 26; Iter   365/  823] train: loss: 0.1902243
[Epoch 26; Iter   395/  823] train: loss: 0.0222149
[Epoch 26; Iter   425/  823] train: loss: 0.0208201
[Epoch 26; Iter   455/  823] train: loss: 0.0281457
[Epoch 26; Iter   485/  823] train: loss: 0.0310453
[Epoch 26; Iter   515/  823] train: loss: 0.3954068
[Epoch 26; Iter   545/  823] train: loss: 0.0254447
[Epoch 26; Iter   575/  823] train: loss: 0.0348792
[Epoch 26; Iter   605/  823] train: loss: 0.0781023
[Epoch 26; Iter   635/  823] train: loss: 0.1372913
[Epoch 26; Iter   665/  823] train: loss: 0.0253339
[Epoch 26; Iter   695/  823] train: loss: 0.1456390
[Epoch 26; Iter   725/  823] train: loss: 0.0193695
[Epoch 26; Iter   755/  823] train: loss: 0.2973033
[Epoch 26; Iter   785/  823] train: loss: 0.0839645
[Epoch 26; Iter   815/  823] train: loss: 0.2514625
[Epoch 26] ogbg-molhiv: 0.736133 val loss: 0.334063
[Epoch 26] ogbg-molhiv: 0.765006 test loss: 0.225595
[Epoch 27; Iter    22/  823] train: loss: 0.0600773
[Epoch 27; Iter    52/  823] train: loss: 0.0414637
[Epoch 27; Iter    82/  823] train: loss: 0.0189349
[Epoch 27; Iter   112/  823] train: loss: 0.0762697
[Epoch 27; Iter   142/  823] train: loss: 0.0199688
[Epoch 27; Iter   172/  823] train: loss: 0.0648514
[Epoch 27; Iter   202/  823] train: loss: 0.2117773
[Epoch 27; Iter   232/  823] train: loss: 0.0185500
[Epoch 27; Iter   262/  823] train: loss: 0.0178272
[Epoch 27; Iter   292/  823] train: loss: 0.1751708
[Epoch 27; Iter   322/  823] train: loss: 0.1167869
[Epoch 27; Iter   352/  823] train: loss: 0.1539142
[Epoch 27; Iter   382/  823] train: loss: 0.1919784
[Epoch 27; Iter   412/  823] train: loss: 0.0552891
[Epoch 27; Iter   442/  823] train: loss: 0.0278893
[Epoch 27; Iter   472/  823] train: loss: 0.0350318
[Epoch 27; Iter   502/  823] train: loss: 0.3796740
[Epoch 27; Iter   532/  823] train: loss: 0.2248970
[Epoch 27; Iter   562/  823] train: loss: 0.2025781
[Epoch 27; Iter   592/  823] train: loss: 0.0263692
[Epoch 27; Iter   622/  823] train: loss: 0.2195554
[Epoch 27; Iter   652/  823] train: loss: 0.2996887
[Epoch 27; Iter   682/  823] train: loss: 0.0307934
[Epoch 27; Iter   712/  823] train: loss: 0.0207495
[Epoch 27; Iter   742/  823] train: loss: 0.0267543
[Epoch 27; Iter   772/  823] train: loss: 0.0420632
[Epoch 27; Iter   802/  823] train: loss: 0.0594731
[Epoch 27] ogbg-molhiv: 0.688788 val loss: 0.171840
[Epoch 27] ogbg-molhiv: 0.727556 test loss: 0.133700
[Epoch 28; Iter     9/  823] train: loss: 0.2530327
[Epoch 28; Iter    39/  823] train: loss: 0.0276157
[Epoch 28; Iter    69/  823] train: loss: 0.0237345
[Epoch 28; Iter    99/  823] train: loss: 0.0667000
[Epoch 28; Iter   129/  823] train: loss: 0.0141631
[Epoch 28; Iter   159/  823] train: loss: 0.0350644
[Epoch 28; Iter   189/  823] train: loss: 0.0426589
[Epoch 28; Iter   219/  823] train: loss: 0.1394339
[Epoch 28; Iter   249/  823] train: loss: 0.0800960
[Epoch 28; Iter   279/  823] train: loss: 0.0197431
[Epoch 28; Iter   309/  823] train: loss: 0.0176789
[Epoch 28; Iter   339/  823] train: loss: 0.0141966
[Epoch 28; Iter   369/  823] train: loss: 0.1540086
[Epoch 28; Iter   399/  823] train: loss: 0.1878933
[Epoch 28; Iter   429/  823] train: loss: 0.1874870
[Epoch 28; Iter   459/  823] train: loss: 0.0237862
[Epoch 28; Iter   489/  823] train: loss: 0.0199563
[Epoch 28; Iter   519/  823] train: loss: 0.0401677
[Epoch 28; Iter   549/  823] train: loss: 0.0463305
[Epoch 28; Iter   579/  823] train: loss: 0.0495596
[Epoch 28; Iter   609/  823] train: loss: 0.0358068
[Epoch 28; Iter   639/  823] train: loss: 0.0124570
[Epoch 28; Iter   669/  823] train: loss: 0.2197018
[Epoch 28; Iter   699/  823] train: loss: 0.0190271
[Epoch 28; Iter   729/  823] train: loss: 0.0292414
[Epoch 28; Iter   759/  823] train: loss: 0.0349557
[Epoch 28; Iter   789/  823] train: loss: 0.0234000
[Epoch 28; Iter   819/  823] train: loss: 0.1836676
[Epoch 28] ogbg-molhiv: 0.734889 val loss: 0.160781
[Epoch 28] ogbg-molhiv: 0.749395 test loss: 0.177800
[Epoch 29; Iter    26/  823] train: loss: 0.2427601
[Epoch 29; Iter    56/  823] train: loss: 0.3250473
[Epoch 29; Iter    86/  823] train: loss: 0.0250415
[Epoch 29; Iter   116/  823] train: loss: 0.2005875
[Epoch 29; Iter   146/  823] train: loss: 0.0208886
[Epoch 29; Iter   176/  823] train: loss: 0.0221772
[Epoch 29; Iter   206/  823] train: loss: 0.0146830
[Epoch 29; Iter   236/  823] train: loss: 0.1963178
[Epoch 29; Iter   266/  823] train: loss: 0.0237098
[Epoch 29; Iter   296/  823] train: loss: 0.1062712
[Epoch 29; Iter   326/  823] train: loss: 0.0225864
[Epoch 29; Iter   356/  823] train: loss: 0.0182734
[Epoch 29; Iter   386/  823] train: loss: 0.0171259
[Epoch 29; Iter   416/  823] train: loss: 0.0495468
[Epoch 29; Iter   446/  823] train: loss: 0.2091342
[Epoch 29; Iter   476/  823] train: loss: 0.0284462
[Epoch 29; Iter   506/  823] train: loss: 0.0395995
[Epoch 29; Iter   536/  823] train: loss: 0.0209312
[Epoch 29; Iter   566/  823] train: loss: 0.0600722
[Epoch 29; Iter   596/  823] train: loss: 0.1768735
[Epoch 29; Iter   626/  823] train: loss: 0.1282319
[Epoch 29; Iter   656/  823] train: loss: 0.1407353
[Epoch 29; Iter   686/  823] train: loss: 0.1561778
[Epoch 29; Iter   716/  823] train: loss: 0.1969967
[Epoch 29; Iter   746/  823] train: loss: 0.0266255
[Epoch 29; Iter   776/  823] train: loss: 0.0480411
[Epoch 29; Iter   806/  823] train: loss: 0.0204799
[Epoch 29] ogbg-molhiv: 0.729463 val loss: 0.249027
[Epoch 29] ogbg-molhiv: 0.756711 test loss: 0.314611
[Epoch 30; Iter    13/  823] train: loss: 0.0201114
[Epoch 30; Iter    43/  823] train: loss: 0.0334344
[Epoch 30; Iter    73/  823] train: loss: 0.0461443
[Epoch 30; Iter   103/  823] train: loss: 0.0180954
[Epoch 30; Iter   133/  823] train: loss: 0.1338369
[Epoch 30; Iter   163/  823] train: loss: 0.0224267
[Epoch 30; Iter   193/  823] train: loss: 0.0193143
[Epoch 30; Iter   223/  823] train: loss: 0.0232257
[Epoch 30; Iter   253/  823] train: loss: 0.1124760
[Epoch 30; Iter   283/  823] train: loss: 0.0470120
[Epoch 30; Iter   313/  823] train: loss: 0.3790868
[Epoch 30; Iter   343/  823] train: loss: 0.0459941
[Epoch 30; Iter   373/  823] train: loss: 0.0137303
[Epoch 30; Iter   403/  823] train: loss: 0.0248053
[Epoch 30; Iter   433/  823] train: loss: 0.0260978
[Epoch 30; Iter   463/  823] train: loss: 0.0958146
[Epoch 30; Iter   493/  823] train: loss: 0.0166211
[Epoch 30; Iter   523/  823] train: loss: 0.0200287
[Epoch 30; Iter   553/  823] train: loss: 0.0490387
[Epoch 30; Iter   583/  823] train: loss: 0.0284033
[Epoch 30; Iter   613/  823] train: loss: 0.1132090
[Epoch 30; Iter   643/  823] train: loss: 0.0319346
[Epoch 30; Iter   673/  823] train: loss: 0.3473760
[Epoch 30; Iter   703/  823] train: loss: 0.0577507
[Epoch 30; Iter   733/  823] train: loss: 0.0208110
[Epoch 30; Iter   763/  823] train: loss: 0.0861918
[Epoch 30; Iter   793/  823] train: loss: 0.0929536
[Epoch 30; Iter   823/  823] train: loss: 0.0323716
[Epoch 30] ogbg-molhiv: 0.718713 val loss: 0.152524
[Epoch 30] ogbg-molhiv: 0.764845 test loss: 0.150352
[Epoch 31; Iter    30/  823] train: loss: 0.2101735
[Epoch 31; Iter    60/  823] train: loss: 0.1298228
[Epoch 31; Iter    90/  823] train: loss: 0.0438211
[Epoch 31; Iter   120/  823] train: loss: 0.0920230
[Epoch 31; Iter   150/  823] train: loss: 0.1758480
[Epoch 31; Iter   180/  823] train: loss: 0.0213223
[Epoch 31; Iter   210/  823] train: loss: 0.1538071
[Epoch 31; Iter   240/  823] train: loss: 0.0799319
[Epoch 31; Iter   270/  823] train: loss: 0.1669708
[Epoch 31; Iter   300/  823] train: loss: 0.0989018
[Epoch 31; Iter   330/  823] train: loss: 0.0317223
[Epoch 31; Iter   360/  823] train: loss: 0.2235781
[Epoch 31; Iter   390/  823] train: loss: 0.1421018
[Epoch 31; Iter   420/  823] train: loss: 0.0181667
[Epoch 31; Iter   450/  823] train: loss: 0.0385782
[Epoch 27; Iter   480/  960] train: loss: 0.0310869
[Epoch 27; Iter   510/  960] train: loss: 0.0507700
[Epoch 27; Iter   540/  960] train: loss: 0.1498180
[Epoch 27; Iter   570/  960] train: loss: 0.1946848
[Epoch 27; Iter   600/  960] train: loss: 0.2190390
[Epoch 27; Iter   630/  960] train: loss: 0.0755445
[Epoch 27; Iter   660/  960] train: loss: 0.0219305
[Epoch 27; Iter   690/  960] train: loss: 0.2593243
[Epoch 27; Iter   720/  960] train: loss: 0.1111640
[Epoch 27; Iter   750/  960] train: loss: 0.0247764
[Epoch 27; Iter   780/  960] train: loss: 0.3026969
[Epoch 27; Iter   810/  960] train: loss: 0.2889306
[Epoch 27; Iter   840/  960] train: loss: 0.0247785
[Epoch 27; Iter   870/  960] train: loss: 0.0198421
[Epoch 27; Iter   900/  960] train: loss: 0.0666310
[Epoch 27; Iter   930/  960] train: loss: 0.1252116
[Epoch 27; Iter   960/  960] train: loss: 0.0532508
[Epoch 27] ogbg-molhiv: 0.739350 val loss: 0.263755
[Epoch 27] ogbg-molhiv: 0.769714 test loss: 0.161870
[Epoch 28; Iter    30/  960] train: loss: 0.0356359
[Epoch 28; Iter    60/  960] train: loss: 0.1572191
[Epoch 28; Iter    90/  960] train: loss: 0.1134471
[Epoch 28; Iter   120/  960] train: loss: 0.2625016
[Epoch 28; Iter   150/  960] train: loss: 0.0668111
[Epoch 28; Iter   180/  960] train: loss: 0.1981369
[Epoch 28; Iter   210/  960] train: loss: 0.3036140
[Epoch 28; Iter   240/  960] train: loss: 0.1018710
[Epoch 28; Iter   270/  960] train: loss: 0.1246064
[Epoch 28; Iter   300/  960] train: loss: 0.0239355
[Epoch 28; Iter   330/  960] train: loss: 0.1245409
[Epoch 28; Iter   360/  960] train: loss: 0.1314984
[Epoch 28; Iter   390/  960] train: loss: 0.2552696
[Epoch 28; Iter   420/  960] train: loss: 0.0330999
[Epoch 28; Iter   450/  960] train: loss: 0.0227829
[Epoch 28; Iter   480/  960] train: loss: 0.0784936
[Epoch 28; Iter   510/  960] train: loss: 0.2198157
[Epoch 28; Iter   540/  960] train: loss: 0.0431489
[Epoch 28; Iter   570/  960] train: loss: 0.0635068
[Epoch 28; Iter   600/  960] train: loss: 0.0233805
[Epoch 28; Iter   630/  960] train: loss: 0.1224835
[Epoch 28; Iter   660/  960] train: loss: 0.0428727
[Epoch 28; Iter   690/  960] train: loss: 0.1789304
[Epoch 28; Iter   720/  960] train: loss: 0.0451146
[Epoch 28; Iter   750/  960] train: loss: 0.0971762
[Epoch 28; Iter   780/  960] train: loss: 0.1786298
[Epoch 28; Iter   810/  960] train: loss: 0.1668610
[Epoch 28; Iter   840/  960] train: loss: 0.1041203
[Epoch 28; Iter   870/  960] train: loss: 0.0684236
[Epoch 28; Iter   900/  960] train: loss: 0.0327032
[Epoch 28; Iter   930/  960] train: loss: 0.0220079
[Epoch 28; Iter   960/  960] train: loss: 0.1220747
[Epoch 28] ogbg-molhiv: 0.754878 val loss: 5.518903
[Epoch 28] ogbg-molhiv: 0.766022 test loss: 0.113050
[Epoch 29; Iter    30/  960] train: loss: 0.0381485
[Epoch 29; Iter    60/  960] train: loss: 0.1308943
[Epoch 29; Iter    90/  960] train: loss: 0.1409494
[Epoch 29; Iter   120/  960] train: loss: 0.0794323
[Epoch 29; Iter   150/  960] train: loss: 0.0942679
[Epoch 29; Iter   180/  960] train: loss: 0.0187291
[Epoch 29; Iter   210/  960] train: loss: 0.1476777
[Epoch 29; Iter   240/  960] train: loss: 0.0126077
[Epoch 29; Iter   270/  960] train: loss: 0.0217119
[Epoch 29; Iter   300/  960] train: loss: 0.1448048
[Epoch 29; Iter   330/  960] train: loss: 0.0438697
[Epoch 29; Iter   360/  960] train: loss: 0.1145538
[Epoch 29; Iter   390/  960] train: loss: 0.0432647
[Epoch 29; Iter   420/  960] train: loss: 0.0260897
[Epoch 29; Iter   450/  960] train: loss: 0.0692962
[Epoch 29; Iter   480/  960] train: loss: 0.1732266
[Epoch 29; Iter   510/  960] train: loss: 0.0401867
[Epoch 29; Iter   540/  960] train: loss: 0.0362733
[Epoch 29; Iter   570/  960] train: loss: 0.0206368
[Epoch 29; Iter   600/  960] train: loss: 0.2206777
[Epoch 29; Iter   630/  960] train: loss: 0.1550487
[Epoch 29; Iter   660/  960] train: loss: 0.3262109
[Epoch 29; Iter   690/  960] train: loss: 0.1583699
[Epoch 29; Iter   720/  960] train: loss: 0.0387384
[Epoch 29; Iter   750/  960] train: loss: 0.1500103
[Epoch 29; Iter   780/  960] train: loss: 0.0212761
[Epoch 29; Iter   810/  960] train: loss: 0.0603234
[Epoch 29; Iter   840/  960] train: loss: 0.0206906
[Epoch 29; Iter   870/  960] train: loss: 0.2232228
[Epoch 29; Iter   900/  960] train: loss: 0.0598598
[Epoch 29; Iter   930/  960] train: loss: 0.0917840
[Epoch 29; Iter   960/  960] train: loss: 0.0388254
[Epoch 29] ogbg-molhiv: 0.744807 val loss: 0.129848
[Epoch 29] ogbg-molhiv: 0.734902 test loss: 0.112369
[Epoch 30; Iter    30/  960] train: loss: 0.0872157
[Epoch 30; Iter    60/  960] train: loss: 0.1779757
[Epoch 30; Iter    90/  960] train: loss: 0.2495373
[Epoch 30; Iter   120/  960] train: loss: 0.0456927
[Epoch 30; Iter   150/  960] train: loss: 0.1442811
[Epoch 30; Iter   180/  960] train: loss: 0.0268095
[Epoch 30; Iter   210/  960] train: loss: 0.0325397
[Epoch 30; Iter   240/  960] train: loss: 0.0436488
[Epoch 30; Iter   270/  960] train: loss: 0.0434517
[Epoch 30; Iter   300/  960] train: loss: 0.0171997
[Epoch 30; Iter   330/  960] train: loss: 0.1197281
[Epoch 30; Iter   360/  960] train: loss: 0.0588338
[Epoch 30; Iter   390/  960] train: loss: 0.0334533
[Epoch 30; Iter   420/  960] train: loss: 0.0151155
[Epoch 30; Iter   450/  960] train: loss: 0.2323857
[Epoch 30; Iter   480/  960] train: loss: 0.0223477
[Epoch 30; Iter   510/  960] train: loss: 0.0176034
[Epoch 30; Iter   540/  960] train: loss: 0.0172685
[Epoch 30; Iter   570/  960] train: loss: 0.3567179
[Epoch 30; Iter   600/  960] train: loss: 0.1054535
[Epoch 30; Iter   630/  960] train: loss: 0.0498373
[Epoch 30; Iter   660/  960] train: loss: 0.0190387
[Epoch 30; Iter   690/  960] train: loss: 0.0227793
[Epoch 30; Iter   720/  960] train: loss: 0.0167325
[Epoch 30; Iter   750/  960] train: loss: 0.2279492
[Epoch 30; Iter   780/  960] train: loss: 0.1076633
[Epoch 30; Iter   810/  960] train: loss: 0.0169149
[Epoch 30; Iter   840/  960] train: loss: 0.0471572
[Epoch 30; Iter   870/  960] train: loss: 0.0291464
[Epoch 30; Iter   900/  960] train: loss: 0.1764410
[Epoch 30; Iter   930/  960] train: loss: 0.0904211
[Epoch 30; Iter   960/  960] train: loss: 0.0701582
[Epoch 30] ogbg-molhiv: 0.750223 val loss: 0.201586
[Epoch 30] ogbg-molhiv: 0.731444 test loss: 0.116686
[Epoch 31; Iter    30/  960] train: loss: 0.0269321
[Epoch 31; Iter    60/  960] train: loss: 0.0159273
[Epoch 31; Iter    90/  960] train: loss: 0.1197770
[Epoch 31; Iter   120/  960] train: loss: 0.1536020
[Epoch 31; Iter   150/  960] train: loss: 0.0689379
[Epoch 31; Iter   180/  960] train: loss: 0.3130643
[Epoch 31; Iter   210/  960] train: loss: 0.0154394
[Epoch 31; Iter   240/  960] train: loss: 0.0399525
[Epoch 31; Iter   270/  960] train: loss: 0.1276905
[Epoch 31; Iter   300/  960] train: loss: 0.0248480
[Epoch 31; Iter   330/  960] train: loss: 0.0531368
[Epoch 31; Iter   360/  960] train: loss: 0.0195048
[Epoch 31; Iter   390/  960] train: loss: 0.1022985
[Epoch 31; Iter   420/  960] train: loss: 0.0326851
[Epoch 31; Iter   450/  960] train: loss: 0.2443540
[Epoch 31; Iter   480/  960] train: loss: 0.0240093
[Epoch 31; Iter   510/  960] train: loss: 0.0342343
[Epoch 31; Iter   540/  960] train: loss: 0.0151469
[Epoch 31; Iter   570/  960] train: loss: 0.0256285
[Epoch 31; Iter   600/  960] train: loss: 0.0629702
[Epoch 31; Iter   630/  960] train: loss: 0.0246062
[Epoch 31; Iter   660/  960] train: loss: 0.0221821
[Epoch 31; Iter   690/  960] train: loss: 0.0523086
[Epoch 31; Iter   720/  960] train: loss: 0.0403137
[Epoch 31; Iter   750/  960] train: loss: 0.0263590
[Epoch 31; Iter   780/  960] train: loss: 0.0168162
[Epoch 31; Iter   810/  960] train: loss: 0.0248857
[Epoch 31; Iter   840/  960] train: loss: 0.1044112
[Epoch 31; Iter   870/  960] train: loss: 0.1520027
[Epoch 31; Iter   900/  960] train: loss: 0.0204563
[Epoch 31; Iter   930/  960] train: loss: 0.0160139
[Epoch 31; Iter   960/  960] train: loss: 0.0166907
[Epoch 31] ogbg-molhiv: 0.755013 val loss: 0.628440
[Epoch 31] ogbg-molhiv: 0.749467 test loss: 0.260533
[Epoch 32; Iter    30/  960] train: loss: 0.0746241
[Epoch 32; Iter    60/  960] train: loss: 0.2220179
[Epoch 27; Iter   480/  960] train: loss: 0.0633885
[Epoch 27; Iter   510/  960] train: loss: 0.0221004
[Epoch 27; Iter   540/  960] train: loss: 0.1484231
[Epoch 27; Iter   570/  960] train: loss: 0.0185627
[Epoch 27; Iter   600/  960] train: loss: 0.0183004
[Epoch 27; Iter   630/  960] train: loss: 0.0275493
[Epoch 27; Iter   660/  960] train: loss: 0.1310755
[Epoch 27; Iter   690/  960] train: loss: 0.2007551
[Epoch 27; Iter   720/  960] train: loss: 0.1638618
[Epoch 27; Iter   750/  960] train: loss: 0.1547098
[Epoch 27; Iter   780/  960] train: loss: 0.1159087
[Epoch 27; Iter   810/  960] train: loss: 0.0775752
[Epoch 27; Iter   840/  960] train: loss: 0.0219854
[Epoch 27; Iter   870/  960] train: loss: 0.0269186
[Epoch 27; Iter   900/  960] train: loss: 0.0206062
[Epoch 27; Iter   930/  960] train: loss: 0.0815451
[Epoch 27; Iter   960/  960] train: loss: 0.0176007
[Epoch 27] ogbg-molhiv: 0.785002 val loss: 0.264331
[Epoch 27] ogbg-molhiv: 0.742104 test loss: 0.148906
[Epoch 28; Iter    30/  960] train: loss: 0.0529041
[Epoch 28; Iter    60/  960] train: loss: 0.0624457
[Epoch 28; Iter    90/  960] train: loss: 0.2852090
[Epoch 28; Iter   120/  960] train: loss: 0.1502553
[Epoch 28; Iter   150/  960] train: loss: 0.0172174
[Epoch 28; Iter   180/  960] train: loss: 0.1637091
[Epoch 28; Iter   210/  960] train: loss: 0.1535383
[Epoch 28; Iter   240/  960] train: loss: 0.0766229
[Epoch 28; Iter   270/  960] train: loss: 0.0204316
[Epoch 28; Iter   300/  960] train: loss: 0.0261465
[Epoch 28; Iter   330/  960] train: loss: 0.1569956
[Epoch 28; Iter   360/  960] train: loss: 0.0179195
[Epoch 28; Iter   390/  960] train: loss: 0.0413624
[Epoch 28; Iter   420/  960] train: loss: 0.0243152
[Epoch 28; Iter   450/  960] train: loss: 0.0840313
[Epoch 28; Iter   480/  960] train: loss: 0.1013082
[Epoch 28; Iter   510/  960] train: loss: 0.0221084
[Epoch 28; Iter   540/  960] train: loss: 0.0237911
[Epoch 28; Iter   570/  960] train: loss: 0.1959265
[Epoch 28; Iter   600/  960] train: loss: 0.0250048
[Epoch 28; Iter   630/  960] train: loss: 0.1435480
[Epoch 28; Iter   660/  960] train: loss: 0.1693568
[Epoch 28; Iter   690/  960] train: loss: 0.2670908
[Epoch 28; Iter   720/  960] train: loss: 0.2559760
[Epoch 28; Iter   750/  960] train: loss: 0.0349737
[Epoch 28; Iter   780/  960] train: loss: 0.3009454
[Epoch 28; Iter   810/  960] train: loss: 0.0247615
[Epoch 28; Iter   840/  960] train: loss: 0.0376779
[Epoch 28; Iter   870/  960] train: loss: 0.0247655
[Epoch 28; Iter   900/  960] train: loss: 0.0782197
[Epoch 28; Iter   930/  960] train: loss: 0.4453266
[Epoch 28; Iter   960/  960] train: loss: 0.0583138
[Epoch 28] ogbg-molhiv: 0.753205 val loss: 0.142819
[Epoch 28] ogbg-molhiv: 0.768274 test loss: 0.167972
[Epoch 29; Iter    30/  960] train: loss: 0.0205698
[Epoch 29; Iter    60/  960] train: loss: 0.0380739
[Epoch 29; Iter    90/  960] train: loss: 0.0291593
[Epoch 29; Iter   120/  960] train: loss: 0.1471326
[Epoch 29; Iter   150/  960] train: loss: 0.0260213
[Epoch 29; Iter   180/  960] train: loss: 0.0159510
[Epoch 29; Iter   210/  960] train: loss: 0.0971308
[Epoch 29; Iter   240/  960] train: loss: 0.1773358
[Epoch 29; Iter   270/  960] train: loss: 0.0143555
[Epoch 29; Iter   300/  960] train: loss: 0.0553648
[Epoch 29; Iter   330/  960] train: loss: 0.1812086
[Epoch 29; Iter   360/  960] train: loss: 0.1720401
[Epoch 29; Iter   390/  960] train: loss: 0.0447628
[Epoch 29; Iter   420/  960] train: loss: 0.0206701
[Epoch 29; Iter   450/  960] train: loss: 0.1641603
[Epoch 29; Iter   480/  960] train: loss: 0.0324456
[Epoch 29; Iter   510/  960] train: loss: 0.0254851
[Epoch 29; Iter   540/  960] train: loss: 0.0954103
[Epoch 29; Iter   570/  960] train: loss: 0.0142593
[Epoch 29; Iter   600/  960] train: loss: 0.1527374
[Epoch 29; Iter   630/  960] train: loss: 0.2444420
[Epoch 29; Iter   660/  960] train: loss: 0.0353690
[Epoch 29; Iter   690/  960] train: loss: 0.0352033
[Epoch 29; Iter   720/  960] train: loss: 0.0218137
[Epoch 29; Iter   750/  960] train: loss: 0.0393789
[Epoch 29; Iter   780/  960] train: loss: 0.0388675
[Epoch 29; Iter   810/  960] train: loss: 0.1022250
[Epoch 29; Iter   840/  960] train: loss: 0.1963414
[Epoch 29; Iter   870/  960] train: loss: 0.2284886
[Epoch 29; Iter   900/  960] train: loss: 0.0433838
[Epoch 29; Iter   930/  960] train: loss: 0.1829063
[Epoch 29; Iter   960/  960] train: loss: 0.0329470
[Epoch 29] ogbg-molhiv: 0.768116 val loss: 0.557163
[Epoch 29] ogbg-molhiv: 0.765304 test loss: 0.319148
[Epoch 30; Iter    30/  960] train: loss: 0.0222080
[Epoch 30; Iter    60/  960] train: loss: 0.0518568
[Epoch 30; Iter    90/  960] train: loss: 0.0376721
[Epoch 30; Iter   120/  960] train: loss: 0.0573814
[Epoch 30; Iter   150/  960] train: loss: 0.0504029
[Epoch 30; Iter   180/  960] train: loss: 0.0371546
[Epoch 30; Iter   210/  960] train: loss: 0.1179823
[Epoch 30; Iter   240/  960] train: loss: 0.0164036
[Epoch 30; Iter   270/  960] train: loss: 0.0202211
[Epoch 30; Iter   300/  960] train: loss: 0.0276274
[Epoch 30; Iter   330/  960] train: loss: 0.1184081
[Epoch 30; Iter   360/  960] train: loss: 0.0411551
[Epoch 30; Iter   390/  960] train: loss: 0.1709363
[Epoch 30; Iter   420/  960] train: loss: 0.3110473
[Epoch 30; Iter   450/  960] train: loss: 0.0541928
[Epoch 30; Iter   480/  960] train: loss: 0.1993997
[Epoch 30; Iter   510/  960] train: loss: 0.0206903
[Epoch 30; Iter   540/  960] train: loss: 0.1713711
[Epoch 30; Iter   570/  960] train: loss: 0.0140563
[Epoch 30; Iter   600/  960] train: loss: 0.2969823
[Epoch 30; Iter   630/  960] train: loss: 0.2399328
[Epoch 30; Iter   660/  960] train: loss: 0.0775336
[Epoch 30; Iter   690/  960] train: loss: 0.0194205
[Epoch 30; Iter   720/  960] train: loss: 0.0114429
[Epoch 30; Iter   750/  960] train: loss: 0.0432002
[Epoch 30; Iter   780/  960] train: loss: 0.1613649
[Epoch 30; Iter   810/  960] train: loss: 0.0361606
[Epoch 30; Iter   840/  960] train: loss: 0.3038319
[Epoch 30; Iter   870/  960] train: loss: 0.0147506
[Epoch 30; Iter   900/  960] train: loss: 0.0363356
[Epoch 30; Iter   930/  960] train: loss: 0.2608740
[Epoch 30; Iter   960/  960] train: loss: 0.0159588
[Epoch 30] ogbg-molhiv: 0.762338 val loss: 0.218173
[Epoch 30] ogbg-molhiv: 0.768081 test loss: 0.382405
[Epoch 31; Iter    30/  960] train: loss: 0.0111376
[Epoch 31; Iter    60/  960] train: loss: 0.0268478
[Epoch 31; Iter    90/  960] train: loss: 0.1392661
[Epoch 31; Iter   120/  960] train: loss: 0.0879918
[Epoch 31; Iter   150/  960] train: loss: 0.0626470
[Epoch 31; Iter   180/  960] train: loss: 0.0129872
[Epoch 31; Iter   210/  960] train: loss: 0.1449147
[Epoch 31; Iter   240/  960] train: loss: 0.1999545
[Epoch 31; Iter   270/  960] train: loss: 0.0238689
[Epoch 31; Iter   300/  960] train: loss: 0.0716260
[Epoch 31; Iter   330/  960] train: loss: 0.0192789
[Epoch 31; Iter   360/  960] train: loss: 0.0125970
[Epoch 31; Iter   390/  960] train: loss: 0.0468738
[Epoch 31; Iter   420/  960] train: loss: 0.0732668
[Epoch 31; Iter   450/  960] train: loss: 0.2180897
[Epoch 31; Iter   480/  960] train: loss: 0.3003656
[Epoch 31; Iter   510/  960] train: loss: 0.0146216
[Epoch 31; Iter   540/  960] train: loss: 0.0259828
[Epoch 31; Iter   570/  960] train: loss: 0.2301709
[Epoch 31; Iter   600/  960] train: loss: 0.0195737
[Epoch 31; Iter   630/  960] train: loss: 0.1134668
[Epoch 31; Iter   660/  960] train: loss: 0.0406448
[Epoch 31; Iter   690/  960] train: loss: 0.1922019
[Epoch 31; Iter   720/  960] train: loss: 0.1419090
[Epoch 31; Iter   750/  960] train: loss: 0.2129465
[Epoch 31; Iter   780/  960] train: loss: 0.2143339
[Epoch 31; Iter   810/  960] train: loss: 0.1126995
[Epoch 31; Iter   840/  960] train: loss: 0.0392933
[Epoch 31; Iter   870/  960] train: loss: 0.0414384
[Epoch 31; Iter   900/  960] train: loss: 0.1757200
[Epoch 31; Iter   930/  960] train: loss: 0.0256935
[Epoch 31; Iter   960/  960] train: loss: 0.0273850
[Epoch 31] ogbg-molhiv: 0.752501 val loss: 1.507919
[Epoch 31] ogbg-molhiv: 0.744721 test loss: 0.392108
[Epoch 32; Iter    30/  960] train: loss: 0.0296036
[Epoch 32; Iter    60/  960] train: loss: 0.0820470
[Epoch 27; Iter   480/  960] train: loss: 0.2860576
[Epoch 27; Iter   510/  960] train: loss: 0.2670930
[Epoch 27; Iter   540/  960] train: loss: 0.3400855
[Epoch 27; Iter   570/  960] train: loss: 0.2914759
[Epoch 27; Iter   600/  960] train: loss: 0.0305143
[Epoch 27; Iter   630/  960] train: loss: 0.0744867
[Epoch 27; Iter   660/  960] train: loss: 0.0496585
[Epoch 27; Iter   690/  960] train: loss: 0.1746972
[Epoch 27; Iter   720/  960] train: loss: 0.0498415
[Epoch 27; Iter   750/  960] train: loss: 0.0228322
[Epoch 27; Iter   780/  960] train: loss: 0.0250510
[Epoch 27; Iter   810/  960] train: loss: 0.0189435
[Epoch 27; Iter   840/  960] train: loss: 0.1485829
[Epoch 27; Iter   870/  960] train: loss: 0.0734650
[Epoch 27; Iter   900/  960] train: loss: 0.2151377
[Epoch 27; Iter   930/  960] train: loss: 0.2876356
[Epoch 27; Iter   960/  960] train: loss: 0.2872585
[Epoch 27] ogbg-molhiv: 0.753703 val loss: 0.267947
[Epoch 27] ogbg-molhiv: 0.773828 test loss: 0.116806
[Epoch 28; Iter    30/  960] train: loss: 0.1669666
[Epoch 28; Iter    60/  960] train: loss: 0.0800856
[Epoch 28; Iter    90/  960] train: loss: 0.0167240
[Epoch 28; Iter   120/  960] train: loss: 0.0496836
[Epoch 28; Iter   150/  960] train: loss: 0.0999199
[Epoch 28; Iter   180/  960] train: loss: 0.0126058
[Epoch 28; Iter   210/  960] train: loss: 0.0451763
[Epoch 28; Iter   240/  960] train: loss: 0.0193482
[Epoch 28; Iter   270/  960] train: loss: 0.2371843
[Epoch 28; Iter   300/  960] train: loss: 0.0888867
[Epoch 28; Iter   330/  960] train: loss: 0.2089092
[Epoch 28; Iter   360/  960] train: loss: 0.1765093
[Epoch 28; Iter   390/  960] train: loss: 0.0893532
[Epoch 28; Iter   420/  960] train: loss: 0.1733547
[Epoch 28; Iter   450/  960] train: loss: 0.0728111
[Epoch 28; Iter   480/  960] train: loss: 0.1220682
[Epoch 28; Iter   510/  960] train: loss: 0.0162674
[Epoch 28; Iter   540/  960] train: loss: 0.0278488
[Epoch 28; Iter   570/  960] train: loss: 0.0274187
[Epoch 28; Iter   600/  960] train: loss: 0.0595954
[Epoch 28; Iter   630/  960] train: loss: 0.0460715
[Epoch 28; Iter   660/  960] train: loss: 0.0216598
[Epoch 28; Iter   690/  960] train: loss: 0.0175503
[Epoch 28; Iter   720/  960] train: loss: 0.0628892
[Epoch 28; Iter   750/  960] train: loss: 0.1044228
[Epoch 28; Iter   780/  960] train: loss: 0.0846575
[Epoch 28; Iter   810/  960] train: loss: 0.0208151
[Epoch 28; Iter   840/  960] train: loss: 0.1217090
[Epoch 28; Iter   870/  960] train: loss: 0.1961942
[Epoch 28; Iter   900/  960] train: loss: 0.2239433
[Epoch 28; Iter   930/  960] train: loss: 0.1004974
[Epoch 28; Iter   960/  960] train: loss: 0.1768467
[Epoch 28] ogbg-molhiv: 0.762174 val loss: 0.133591
[Epoch 28] ogbg-molhiv: 0.790632 test loss: 0.101178
[Epoch 29; Iter    30/  960] train: loss: 0.0209312
[Epoch 29; Iter    60/  960] train: loss: 0.0669532
[Epoch 29; Iter    90/  960] train: loss: 0.0389016
[Epoch 29; Iter   120/  960] train: loss: 0.0474149
[Epoch 29; Iter   150/  960] train: loss: 0.1111257
[Epoch 29; Iter   180/  960] train: loss: 0.0372498
[Epoch 29; Iter   210/  960] train: loss: 0.0792521
[Epoch 29; Iter   240/  960] train: loss: 0.1184219
[Epoch 29; Iter   270/  960] train: loss: 0.0422627
[Epoch 29; Iter   300/  960] train: loss: 0.1576239
[Epoch 29; Iter   330/  960] train: loss: 0.0185314
[Epoch 29; Iter   360/  960] train: loss: 0.2213616
[Epoch 29; Iter   390/  960] train: loss: 0.0264956
[Epoch 29; Iter   420/  960] train: loss: 0.0243357
[Epoch 29; Iter   450/  960] train: loss: 0.0346134
[Epoch 29; Iter   480/  960] train: loss: 0.1410723
[Epoch 29; Iter   510/  960] train: loss: 0.0578580
[Epoch 29; Iter   540/  960] train: loss: 0.1160935
[Epoch 29; Iter   570/  960] train: loss: 0.0240332
[Epoch 29; Iter   600/  960] train: loss: 0.2183898
[Epoch 29; Iter   630/  960] train: loss: 0.0399602
[Epoch 29; Iter   660/  960] train: loss: 0.0416204
[Epoch 29; Iter   690/  960] train: loss: 0.0440769
[Epoch 29; Iter   720/  960] train: loss: 0.0634211
[Epoch 29; Iter   750/  960] train: loss: 0.1364145
[Epoch 29; Iter   780/  960] train: loss: 0.0422601
[Epoch 29; Iter   810/  960] train: loss: 0.0166704
[Epoch 29; Iter   840/  960] train: loss: 0.0522843
[Epoch 29; Iter   870/  960] train: loss: 0.0318884
[Epoch 29; Iter   900/  960] train: loss: 0.0410476
[Epoch 29; Iter   930/  960] train: loss: 0.0557042
[Epoch 29; Iter   960/  960] train: loss: 0.2741797
[Epoch 29] ogbg-molhiv: 0.751087 val loss: 0.123900
[Epoch 29] ogbg-molhiv: 0.783010 test loss: 0.103133
[Epoch 30; Iter    30/  960] train: loss: 0.1320052
[Epoch 30; Iter    60/  960] train: loss: 0.0221987
[Epoch 30; Iter    90/  960] train: loss: 0.2710215
[Epoch 30; Iter   120/  960] train: loss: 0.0326902
[Epoch 30; Iter   150/  960] train: loss: 0.0867559
[Epoch 30; Iter   180/  960] train: loss: 0.0229123
[Epoch 30; Iter   210/  960] train: loss: 0.2610712
[Epoch 30; Iter   240/  960] train: loss: 0.1629199
[Epoch 30; Iter   270/  960] train: loss: 0.0196263
[Epoch 30; Iter   300/  960] train: loss: 0.0175387
[Epoch 30; Iter   330/  960] train: loss: 0.0281500
[Epoch 30; Iter   360/  960] train: loss: 0.0264662
[Epoch 30; Iter   390/  960] train: loss: 0.0253485
[Epoch 30; Iter   420/  960] train: loss: 0.0378162
[Epoch 30; Iter   450/  960] train: loss: 0.0350718
[Epoch 30; Iter   480/  960] train: loss: 0.0466686
[Epoch 30; Iter   510/  960] train: loss: 0.1528129
[Epoch 30; Iter   540/  960] train: loss: 0.0412707
[Epoch 30; Iter   570/  960] train: loss: 0.0794814
[Epoch 30; Iter   600/  960] train: loss: 0.0241282
[Epoch 30; Iter   630/  960] train: loss: 0.1074540
[Epoch 30; Iter   660/  960] train: loss: 0.0200273
[Epoch 30; Iter   690/  960] train: loss: 0.0215870
[Epoch 30; Iter   720/  960] train: loss: 0.0611367
[Epoch 30; Iter   750/  960] train: loss: 0.2565070
[Epoch 30; Iter   780/  960] train: loss: 0.2319124
[Epoch 30; Iter   810/  960] train: loss: 0.1080962
[Epoch 30; Iter   840/  960] train: loss: 0.2070933
[Epoch 30; Iter   870/  960] train: loss: 0.0916016
[Epoch 30; Iter   900/  960] train: loss: 0.0179265
[Epoch 30; Iter   930/  960] train: loss: 0.1733432
[Epoch 30; Iter   960/  960] train: loss: 0.2359412
[Epoch 30] ogbg-molhiv: 0.752613 val loss: 0.128199
[Epoch 30] ogbg-molhiv: 0.778598 test loss: 0.104178
[Epoch 31; Iter    30/  960] train: loss: 0.1102742
[Epoch 31; Iter    60/  960] train: loss: 0.0226294
[Epoch 31; Iter    90/  960] train: loss: 0.0292983
[Epoch 31; Iter   120/  960] train: loss: 0.1757585
[Epoch 31; Iter   150/  960] train: loss: 0.0377455
[Epoch 31; Iter   180/  960] train: loss: 0.0604420
[Epoch 31; Iter   210/  960] train: loss: 0.0181728
[Epoch 31; Iter   240/  960] train: loss: 0.2039267
[Epoch 31; Iter   270/  960] train: loss: 0.0914452
[Epoch 31; Iter   300/  960] train: loss: 0.1471855
[Epoch 31; Iter   330/  960] train: loss: 0.0849305
[Epoch 31; Iter   360/  960] train: loss: 0.0365477
[Epoch 31; Iter   390/  960] train: loss: 0.0901346
[Epoch 31; Iter   420/  960] train: loss: 0.0430789
[Epoch 31; Iter   450/  960] train: loss: 0.0991019
[Epoch 31; Iter   480/  960] train: loss: 0.1371448
[Epoch 31; Iter   510/  960] train: loss: 0.0491748
[Epoch 31; Iter   540/  960] train: loss: 0.0529738
[Epoch 31; Iter   570/  960] train: loss: 0.0129657
[Epoch 31; Iter   600/  960] train: loss: 0.2153470
[Epoch 31; Iter   630/  960] train: loss: 0.0443088
[Epoch 31; Iter   660/  960] train: loss: 0.0472733
[Epoch 31; Iter   690/  960] train: loss: 0.0769920
[Epoch 31; Iter   720/  960] train: loss: 0.0145479
[Epoch 31; Iter   750/  960] train: loss: 0.0301637
[Epoch 31; Iter   780/  960] train: loss: 0.0533428
[Epoch 31; Iter   810/  960] train: loss: 0.0223768
[Epoch 31; Iter   840/  960] train: loss: 0.0337591
[Epoch 31; Iter   870/  960] train: loss: 0.0150137
[Epoch 31; Iter   900/  960] train: loss: 0.0147719
[Epoch 31; Iter   930/  960] train: loss: 0.0302420
[Epoch 31; Iter   960/  960] train: loss: 0.0098723
[Epoch 31] ogbg-molhiv: 0.754137 val loss: 0.150701
[Epoch 31] ogbg-molhiv: 0.795148 test loss: 0.111474
[Epoch 32; Iter    30/  960] train: loss: 0.0357294
[Epoch 32; Iter    60/  960] train: loss: 0.0535950
[Epoch 28; Iter   471/ 1097] train: loss: 0.0398007
[Epoch 28; Iter   501/ 1097] train: loss: 0.0403183
[Epoch 28; Iter   531/ 1097] train: loss: 0.1604839
[Epoch 28; Iter   561/ 1097] train: loss: 0.0420649
[Epoch 28; Iter   591/ 1097] train: loss: 0.1976247
[Epoch 28; Iter   621/ 1097] train: loss: 0.0942912
[Epoch 28; Iter   651/ 1097] train: loss: 0.2131300
[Epoch 28; Iter   681/ 1097] train: loss: 0.0485106
[Epoch 28; Iter   711/ 1097] train: loss: 0.0594077
[Epoch 28; Iter   741/ 1097] train: loss: 0.1576588
[Epoch 28; Iter   771/ 1097] train: loss: 0.0698426
[Epoch 28; Iter   801/ 1097] train: loss: 0.2310351
[Epoch 28; Iter   831/ 1097] train: loss: 0.0483831
[Epoch 28; Iter   861/ 1097] train: loss: 0.0377594
[Epoch 28; Iter   891/ 1097] train: loss: 0.3145282
[Epoch 28; Iter   921/ 1097] train: loss: 0.0924378
[Epoch 28; Iter   951/ 1097] train: loss: 0.0290259
[Epoch 28; Iter   981/ 1097] train: loss: 0.0379344
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0227418
[Epoch 28; Iter  1041/ 1097] train: loss: 0.1469226
[Epoch 28; Iter  1071/ 1097] train: loss: 0.2207770
[Epoch 28] ogbg-molhiv: 0.766749 val loss: 0.334228
[Epoch 28] ogbg-molhiv: 0.748773 test loss: 0.192134
[Epoch 29; Iter     4/ 1097] train: loss: 0.0693788
[Epoch 29; Iter    34/ 1097] train: loss: 0.0786953
[Epoch 29; Iter    64/ 1097] train: loss: 0.4794202
[Epoch 29; Iter    94/ 1097] train: loss: 0.0295529
[Epoch 29; Iter   124/ 1097] train: loss: 0.0350381
[Epoch 29; Iter   154/ 1097] train: loss: 0.1662599
[Epoch 29; Iter   184/ 1097] train: loss: 0.1774241
[Epoch 29; Iter   214/ 1097] train: loss: 0.1736874
[Epoch 29; Iter   244/ 1097] train: loss: 0.0344606
[Epoch 29; Iter   274/ 1097] train: loss: 0.0762219
[Epoch 29; Iter   304/ 1097] train: loss: 0.0301227
[Epoch 29; Iter   334/ 1097] train: loss: 0.0457217
[Epoch 29; Iter   364/ 1097] train: loss: 0.1080009
[Epoch 29; Iter   394/ 1097] train: loss: 0.0281769
[Epoch 29; Iter   424/ 1097] train: loss: 0.0480079
[Epoch 29; Iter   454/ 1097] train: loss: 0.0226668
[Epoch 29; Iter   484/ 1097] train: loss: 0.0296281
[Epoch 29; Iter   514/ 1097] train: loss: 0.2746204
[Epoch 29; Iter   544/ 1097] train: loss: 0.0328618
[Epoch 29; Iter   574/ 1097] train: loss: 0.0203560
[Epoch 29; Iter   604/ 1097] train: loss: 0.0250774
[Epoch 29; Iter   634/ 1097] train: loss: 0.0148235
[Epoch 29; Iter   664/ 1097] train: loss: 0.0515888
[Epoch 29; Iter   694/ 1097] train: loss: 0.2202180
[Epoch 29; Iter   724/ 1097] train: loss: 0.0291620
[Epoch 29; Iter   754/ 1097] train: loss: 0.0408905
[Epoch 29; Iter   784/ 1097] train: loss: 0.1685415
[Epoch 29; Iter   814/ 1097] train: loss: 0.2169015
[Epoch 29; Iter   844/ 1097] train: loss: 0.0559564
[Epoch 29; Iter   874/ 1097] train: loss: 0.0388519
[Epoch 29; Iter   904/ 1097] train: loss: 0.0429750
[Epoch 29; Iter   934/ 1097] train: loss: 0.0844850
[Epoch 29; Iter   964/ 1097] train: loss: 0.0226081
[Epoch 29; Iter   994/ 1097] train: loss: 0.1047678
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0299102
[Epoch 29; Iter  1054/ 1097] train: loss: 0.1819915
[Epoch 29; Iter  1084/ 1097] train: loss: 0.2594331
[Epoch 29] ogbg-molhiv: 0.806897 val loss: 0.264044
[Epoch 29] ogbg-molhiv: 0.763350 test loss: 0.155320
[Epoch 30; Iter    17/ 1097] train: loss: 0.2737460
[Epoch 30; Iter    47/ 1097] train: loss: 0.0595605
[Epoch 30; Iter    77/ 1097] train: loss: 0.0139966
[Epoch 30; Iter   107/ 1097] train: loss: 0.1617547
[Epoch 30; Iter   137/ 1097] train: loss: 0.0495739
[Epoch 30; Iter   167/ 1097] train: loss: 0.3768342
[Epoch 30; Iter   197/ 1097] train: loss: 0.0806849
[Epoch 30; Iter   227/ 1097] train: loss: 0.0538832
[Epoch 30; Iter   257/ 1097] train: loss: 0.1382871
[Epoch 30; Iter   287/ 1097] train: loss: 0.1198976
[Epoch 30; Iter   317/ 1097] train: loss: 0.1175760
[Epoch 30; Iter   347/ 1097] train: loss: 0.0223661
[Epoch 30; Iter   377/ 1097] train: loss: 0.2582862
[Epoch 30; Iter   407/ 1097] train: loss: 0.0231994
[Epoch 30; Iter   437/ 1097] train: loss: 0.1443353
[Epoch 30; Iter   467/ 1097] train: loss: 0.0285379
[Epoch 30; Iter   497/ 1097] train: loss: 0.1454941
[Epoch 30; Iter   527/ 1097] train: loss: 0.2348730
[Epoch 30; Iter   557/ 1097] train: loss: 0.1512847
[Epoch 30; Iter   587/ 1097] train: loss: 0.2013841
[Epoch 30; Iter   617/ 1097] train: loss: 0.0205917
[Epoch 30; Iter   647/ 1097] train: loss: 0.1111551
[Epoch 30; Iter   677/ 1097] train: loss: 0.1123307
[Epoch 30; Iter   707/ 1097] train: loss: 0.0313779
[Epoch 30; Iter   737/ 1097] train: loss: 0.0200756
[Epoch 30; Iter   767/ 1097] train: loss: 0.0223668
[Epoch 30; Iter   797/ 1097] train: loss: 0.0659487
[Epoch 30; Iter   827/ 1097] train: loss: 0.1019478
[Epoch 30; Iter   857/ 1097] train: loss: 0.1335311
[Epoch 30; Iter   887/ 1097] train: loss: 0.0850538
[Epoch 30; Iter   917/ 1097] train: loss: 0.1518758
[Epoch 30; Iter   947/ 1097] train: loss: 0.2982038
[Epoch 30; Iter   977/ 1097] train: loss: 0.1353935
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0238023
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1436057
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0254936
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0315292
[Epoch 30] ogbg-molhiv: 0.793225 val loss: 0.495027
[Epoch 30] ogbg-molhiv: 0.769511 test loss: 0.245388
[Epoch 31; Iter    30/ 1097] train: loss: 0.0289598
[Epoch 31; Iter    60/ 1097] train: loss: 0.1676914
[Epoch 31; Iter    90/ 1097] train: loss: 0.0198574
[Epoch 31; Iter   120/ 1097] train: loss: 0.0181871
[Epoch 31; Iter   150/ 1097] train: loss: 0.0879577
[Epoch 31; Iter   180/ 1097] train: loss: 0.0396042
[Epoch 31; Iter   210/ 1097] train: loss: 0.2289516
[Epoch 31; Iter   240/ 1097] train: loss: 0.1816540
[Epoch 31; Iter   270/ 1097] train: loss: 0.0757687
[Epoch 31; Iter   300/ 1097] train: loss: 0.0332817
[Epoch 31; Iter   330/ 1097] train: loss: 0.0317333
[Epoch 31; Iter   360/ 1097] train: loss: 0.0504742
[Epoch 31; Iter   390/ 1097] train: loss: 0.1323069
[Epoch 31; Iter   420/ 1097] train: loss: 0.0306426
[Epoch 31; Iter   450/ 1097] train: loss: 0.0274728
[Epoch 31; Iter   480/ 1097] train: loss: 0.0619166
[Epoch 31; Iter   510/ 1097] train: loss: 0.0159763
[Epoch 31; Iter   540/ 1097] train: loss: 0.1713026
[Epoch 31; Iter   570/ 1097] train: loss: 0.0605711
[Epoch 31; Iter   600/ 1097] train: loss: 0.0136680
[Epoch 31; Iter   630/ 1097] train: loss: 0.1833207
[Epoch 31; Iter   660/ 1097] train: loss: 0.0143218
[Epoch 31; Iter   690/ 1097] train: loss: 0.1698687
[Epoch 31; Iter   720/ 1097] train: loss: 0.1188565
[Epoch 31; Iter   750/ 1097] train: loss: 0.1598779
[Epoch 31; Iter   780/ 1097] train: loss: 0.0894904
[Epoch 31; Iter   810/ 1097] train: loss: 0.0320721
[Epoch 31; Iter   840/ 1097] train: loss: 0.0227702
[Epoch 31; Iter   870/ 1097] train: loss: 0.0326657
[Epoch 31; Iter   900/ 1097] train: loss: 0.1751568
[Epoch 31; Iter   930/ 1097] train: loss: 0.1831845
[Epoch 31; Iter   960/ 1097] train: loss: 0.1679948
[Epoch 31; Iter   990/ 1097] train: loss: 0.0259282
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0635609
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0330800
[Epoch 31; Iter  1080/ 1097] train: loss: 0.1211199
[Epoch 31] ogbg-molhiv: 0.811441 val loss: 0.278856
[Epoch 31] ogbg-molhiv: 0.772176 test loss: 0.231471
[Epoch 32; Iter    13/ 1097] train: loss: 0.5855679
[Epoch 32; Iter    43/ 1097] train: loss: 0.0905201
[Epoch 32; Iter    73/ 1097] train: loss: 0.0260114
[Epoch 32; Iter   103/ 1097] train: loss: 0.0204805
[Epoch 32; Iter   133/ 1097] train: loss: 0.0272677
[Epoch 32; Iter   163/ 1097] train: loss: 0.0898326
[Epoch 32; Iter   193/ 1097] train: loss: 0.0267795
[Epoch 32; Iter   223/ 1097] train: loss: 0.0844129
[Epoch 32; Iter   253/ 1097] train: loss: 0.0181975
[Epoch 32; Iter   283/ 1097] train: loss: 0.0443110
[Epoch 32; Iter   313/ 1097] train: loss: 0.0376471
[Epoch 32; Iter   343/ 1097] train: loss: 0.0664294
[Epoch 32; Iter   373/ 1097] train: loss: 0.0209065
[Epoch 32; Iter   403/ 1097] train: loss: 0.2718734
[Epoch 32; Iter   433/ 1097] train: loss: 0.0444655
[Epoch 32; Iter   463/ 1097] train: loss: 0.0505122
[Epoch 32; Iter   493/ 1097] train: loss: 0.0877752
[Epoch 32; Iter   523/ 1097] train: loss: 0.0444658
[Epoch 28; Iter   471/ 1097] train: loss: 0.2181466
[Epoch 28; Iter   501/ 1097] train: loss: 0.0340250
[Epoch 28; Iter   531/ 1097] train: loss: 0.0380342
[Epoch 28; Iter   561/ 1097] train: loss: 0.1254087
[Epoch 28; Iter   591/ 1097] train: loss: 0.0568798
[Epoch 28; Iter   621/ 1097] train: loss: 0.0261036
[Epoch 28; Iter   651/ 1097] train: loss: 0.0268183
[Epoch 28; Iter   681/ 1097] train: loss: 0.0833858
[Epoch 28; Iter   711/ 1097] train: loss: 0.0294245
[Epoch 28; Iter   741/ 1097] train: loss: 0.0258995
[Epoch 28; Iter   771/ 1097] train: loss: 0.0538616
[Epoch 28; Iter   801/ 1097] train: loss: 0.0175310
[Epoch 28; Iter   831/ 1097] train: loss: 0.1743227
[Epoch 28; Iter   861/ 1097] train: loss: 0.0191834
[Epoch 28; Iter   891/ 1097] train: loss: 0.0296347
[Epoch 28; Iter   921/ 1097] train: loss: 0.0179105
[Epoch 28; Iter   951/ 1097] train: loss: 0.0198370
[Epoch 28; Iter   981/ 1097] train: loss: 0.1025187
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0261887
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0543028
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0332426
[Epoch 28] ogbg-molhiv: 0.802405 val loss: 0.470593
[Epoch 28] ogbg-molhiv: 0.759389 test loss: 0.264948
[Epoch 29; Iter     4/ 1097] train: loss: 0.0260991
[Epoch 29; Iter    34/ 1097] train: loss: 0.2033971
[Epoch 29; Iter    64/ 1097] train: loss: 0.0823949
[Epoch 29; Iter    94/ 1097] train: loss: 0.0549965
[Epoch 29; Iter   124/ 1097] train: loss: 0.2227631
[Epoch 29; Iter   154/ 1097] train: loss: 0.0281750
[Epoch 29; Iter   184/ 1097] train: loss: 0.0135071
[Epoch 29; Iter   214/ 1097] train: loss: 0.1364858
[Epoch 29; Iter   244/ 1097] train: loss: 0.1603668
[Epoch 29; Iter   274/ 1097] train: loss: 0.0392915
[Epoch 29; Iter   304/ 1097] train: loss: 0.0281344
[Epoch 29; Iter   334/ 1097] train: loss: 0.1909395
[Epoch 29; Iter   364/ 1097] train: loss: 0.0282509
[Epoch 29; Iter   394/ 1097] train: loss: 0.2216738
[Epoch 29; Iter   424/ 1097] train: loss: 0.0500060
[Epoch 29; Iter   454/ 1097] train: loss: 0.1388420
[Epoch 29; Iter   484/ 1097] train: loss: 0.0208813
[Epoch 29; Iter   514/ 1097] train: loss: 0.0257350
[Epoch 29; Iter   544/ 1097] train: loss: 0.0303725
[Epoch 29; Iter   574/ 1097] train: loss: 0.0196918
[Epoch 29; Iter   604/ 1097] train: loss: 0.0587029
[Epoch 29; Iter   634/ 1097] train: loss: 0.1319624
[Epoch 29; Iter   664/ 1097] train: loss: 0.0399302
[Epoch 29; Iter   694/ 1097] train: loss: 0.3508860
[Epoch 29; Iter   724/ 1097] train: loss: 0.0564471
[Epoch 29; Iter   754/ 1097] train: loss: 0.0276665
[Epoch 29; Iter   784/ 1097] train: loss: 0.0396577
[Epoch 29; Iter   814/ 1097] train: loss: 0.0667021
[Epoch 29; Iter   844/ 1097] train: loss: 0.1901926
[Epoch 29; Iter   874/ 1097] train: loss: 0.0290564
[Epoch 29; Iter   904/ 1097] train: loss: 0.1518511
[Epoch 29; Iter   934/ 1097] train: loss: 0.0906048
[Epoch 29; Iter   964/ 1097] train: loss: 0.0257397
[Epoch 29; Iter   994/ 1097] train: loss: 0.3089812
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0266817
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0196904
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0575016
[Epoch 29] ogbg-molhiv: 0.798476 val loss: 0.408826
[Epoch 29] ogbg-molhiv: 0.731731 test loss: 0.363330
[Epoch 30; Iter    17/ 1097] train: loss: 0.0268899
[Epoch 30; Iter    47/ 1097] train: loss: 0.0236887
[Epoch 30; Iter    77/ 1097] train: loss: 0.1535723
[Epoch 30; Iter   107/ 1097] train: loss: 0.0326274
[Epoch 30; Iter   137/ 1097] train: loss: 0.0585455
[Epoch 30; Iter   167/ 1097] train: loss: 0.0181119
[Epoch 30; Iter   197/ 1097] train: loss: 0.1346426
[Epoch 30; Iter   227/ 1097] train: loss: 0.0217510
[Epoch 30; Iter   257/ 1097] train: loss: 0.0533610
[Epoch 30; Iter   287/ 1097] train: loss: 0.0195810
[Epoch 30; Iter   317/ 1097] train: loss: 0.2490233
[Epoch 30; Iter   347/ 1097] train: loss: 0.0308451
[Epoch 30; Iter   377/ 1097] train: loss: 0.0174551
[Epoch 30; Iter   407/ 1097] train: loss: 0.0988517
[Epoch 30; Iter   437/ 1097] train: loss: 0.1581365
[Epoch 30; Iter   467/ 1097] train: loss: 0.0529511
[Epoch 30; Iter   497/ 1097] train: loss: 0.1301495
[Epoch 30; Iter   527/ 1097] train: loss: 0.0541922
[Epoch 30; Iter   557/ 1097] train: loss: 0.0989980
[Epoch 30; Iter   587/ 1097] train: loss: 0.0258507
[Epoch 30; Iter   617/ 1097] train: loss: 0.0622058
[Epoch 30; Iter   647/ 1097] train: loss: 0.1595221
[Epoch 30; Iter   677/ 1097] train: loss: 0.1019295
[Epoch 30; Iter   707/ 1097] train: loss: 0.0808552
[Epoch 30; Iter   737/ 1097] train: loss: 0.0222635
[Epoch 30; Iter   767/ 1097] train: loss: 0.0152073
[Epoch 30; Iter   797/ 1097] train: loss: 0.0539787
[Epoch 30; Iter   827/ 1097] train: loss: 0.1214440
[Epoch 30; Iter   857/ 1097] train: loss: 0.0265994
[Epoch 30; Iter   887/ 1097] train: loss: 0.0375436
[Epoch 30; Iter   917/ 1097] train: loss: 0.1829869
[Epoch 30; Iter   947/ 1097] train: loss: 0.0494467
[Epoch 30; Iter   977/ 1097] train: loss: 0.1551267
[Epoch 30; Iter  1007/ 1097] train: loss: 0.0193692
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1229522
[Epoch 30; Iter  1067/ 1097] train: loss: 0.1731041
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0236817
[Epoch 30] ogbg-molhiv: 0.822313 val loss: 0.344417
[Epoch 30] ogbg-molhiv: 0.756048 test loss: 0.756832
[Epoch 31; Iter    30/ 1097] train: loss: 0.0627167
[Epoch 31; Iter    60/ 1097] train: loss: 0.1270743
[Epoch 31; Iter    90/ 1097] train: loss: 0.0527254
[Epoch 31; Iter   120/ 1097] train: loss: 0.0292773
[Epoch 31; Iter   150/ 1097] train: loss: 0.1280293
[Epoch 31; Iter   180/ 1097] train: loss: 0.0205764
[Epoch 31; Iter   210/ 1097] train: loss: 0.0444984
[Epoch 31; Iter   240/ 1097] train: loss: 0.0216860
[Epoch 31; Iter   270/ 1097] train: loss: 0.0730147
[Epoch 31; Iter   300/ 1097] train: loss: 0.0425600
[Epoch 31; Iter   330/ 1097] train: loss: 0.1145478
[Epoch 31; Iter   360/ 1097] train: loss: 0.1030971
[Epoch 31; Iter   390/ 1097] train: loss: 0.1589075
[Epoch 31; Iter   420/ 1097] train: loss: 0.0296421
[Epoch 31; Iter   450/ 1097] train: loss: 0.0632339
[Epoch 31; Iter   480/ 1097] train: loss: 0.1056252
[Epoch 31; Iter   510/ 1097] train: loss: 0.0197050
[Epoch 31; Iter   540/ 1097] train: loss: 0.0280560
[Epoch 31; Iter   570/ 1097] train: loss: 0.1354678
[Epoch 31; Iter   600/ 1097] train: loss: 0.0328126
[Epoch 31; Iter   630/ 1097] train: loss: 0.0445946
[Epoch 31; Iter   660/ 1097] train: loss: 0.1594609
[Epoch 31; Iter   690/ 1097] train: loss: 0.0347806
[Epoch 31; Iter   720/ 1097] train: loss: 0.0282589
[Epoch 31; Iter   750/ 1097] train: loss: 0.0627579
[Epoch 31; Iter   780/ 1097] train: loss: 0.0227363
[Epoch 31; Iter   810/ 1097] train: loss: 0.0288632
[Epoch 31; Iter   840/ 1097] train: loss: 0.0479118
[Epoch 31; Iter   870/ 1097] train: loss: 0.0532890
[Epoch 31; Iter   900/ 1097] train: loss: 0.0298296
[Epoch 31; Iter   930/ 1097] train: loss: 0.2098057
[Epoch 31; Iter   960/ 1097] train: loss: 0.0186381
[Epoch 31; Iter   990/ 1097] train: loss: 0.0395992
[Epoch 31; Iter  1020/ 1097] train: loss: 0.0352203
[Epoch 31; Iter  1050/ 1097] train: loss: 0.0176330
[Epoch 31; Iter  1080/ 1097] train: loss: 0.2028577
[Epoch 31] ogbg-molhiv: 0.817053 val loss: 0.278094
[Epoch 31] ogbg-molhiv: 0.736625 test loss: 0.308103
[Epoch 32; Iter    13/ 1097] train: loss: 0.1001581
[Epoch 32; Iter    43/ 1097] train: loss: 0.4139540
[Epoch 32; Iter    73/ 1097] train: loss: 0.1390442
[Epoch 32; Iter   103/ 1097] train: loss: 0.0320742
[Epoch 32; Iter   133/ 1097] train: loss: 0.0173517
[Epoch 32; Iter   163/ 1097] train: loss: 0.0244202
[Epoch 32; Iter   193/ 1097] train: loss: 0.0457846
[Epoch 32; Iter   223/ 1097] train: loss: 0.0208611
[Epoch 32; Iter   253/ 1097] train: loss: 0.0662841
[Epoch 32; Iter   283/ 1097] train: loss: 0.0346832
[Epoch 32; Iter   313/ 1097] train: loss: 0.2059423
[Epoch 32; Iter   343/ 1097] train: loss: 0.1282786
[Epoch 32; Iter   373/ 1097] train: loss: 0.1247064
[Epoch 32; Iter   403/ 1097] train: loss: 0.0467254
[Epoch 32; Iter   433/ 1097] train: loss: 0.0158976
[Epoch 32; Iter   463/ 1097] train: loss: 0.2203214
[Epoch 32; Iter   493/ 1097] train: loss: 0.0160333
[Epoch 32; Iter   523/ 1097] train: loss: 0.0233771
[Epoch 28; Iter   471/ 1097] train: loss: 0.0384799
[Epoch 28; Iter   501/ 1097] train: loss: 0.1766954
[Epoch 28; Iter   531/ 1097] train: loss: 0.0188091
[Epoch 28; Iter   561/ 1097] train: loss: 0.0847957
[Epoch 28; Iter   591/ 1097] train: loss: 0.1755349
[Epoch 28; Iter   621/ 1097] train: loss: 0.0969751
[Epoch 28; Iter   651/ 1097] train: loss: 0.0660566
[Epoch 28; Iter   681/ 1097] train: loss: 0.0263513
[Epoch 28; Iter   711/ 1097] train: loss: 0.0620240
[Epoch 28; Iter   741/ 1097] train: loss: 0.0205688
[Epoch 28; Iter   771/ 1097] train: loss: 0.0854562
[Epoch 28; Iter   801/ 1097] train: loss: 0.0178744
[Epoch 28; Iter   831/ 1097] train: loss: 0.0208023
[Epoch 28; Iter   861/ 1097] train: loss: 0.2435906
[Epoch 28; Iter   891/ 1097] train: loss: 0.0817296
[Epoch 28; Iter   921/ 1097] train: loss: 0.0640845
[Epoch 28; Iter   951/ 1097] train: loss: 0.0697260
[Epoch 28; Iter   981/ 1097] train: loss: 0.0332591
[Epoch 28; Iter  1011/ 1097] train: loss: 0.0184192
[Epoch 28; Iter  1041/ 1097] train: loss: 0.0244018
[Epoch 28; Iter  1071/ 1097] train: loss: 0.0330128
[Epoch 28] ogbg-molhiv: 0.813670 val loss: 0.082619
[Epoch 28] ogbg-molhiv: 0.772979 test loss: 0.118925
[Epoch 29; Iter     4/ 1097] train: loss: 0.0175832
[Epoch 29; Iter    34/ 1097] train: loss: 0.0332851
[Epoch 29; Iter    64/ 1097] train: loss: 0.0522397
[Epoch 29; Iter    94/ 1097] train: loss: 0.0408491
[Epoch 29; Iter   124/ 1097] train: loss: 0.0935524
[Epoch 29; Iter   154/ 1097] train: loss: 0.1675136
[Epoch 29; Iter   184/ 1097] train: loss: 0.0205510
[Epoch 29; Iter   214/ 1097] train: loss: 0.0212766
[Epoch 29; Iter   244/ 1097] train: loss: 0.0391366
[Epoch 29; Iter   274/ 1097] train: loss: 0.0191421
[Epoch 29; Iter   304/ 1097] train: loss: 0.1483885
[Epoch 29; Iter   334/ 1097] train: loss: 0.0655554
[Epoch 29; Iter   364/ 1097] train: loss: 0.0356821
[Epoch 29; Iter   394/ 1097] train: loss: 0.0630953
[Epoch 29; Iter   424/ 1097] train: loss: 0.0569472
[Epoch 29; Iter   454/ 1097] train: loss: 0.0330405
[Epoch 29; Iter   484/ 1097] train: loss: 0.1179802
[Epoch 29; Iter   514/ 1097] train: loss: 0.0750402
[Epoch 29; Iter   544/ 1097] train: loss: 0.0321182
[Epoch 29; Iter   574/ 1097] train: loss: 0.0301684
[Epoch 29; Iter   604/ 1097] train: loss: 0.1768723
[Epoch 29; Iter   634/ 1097] train: loss: 0.2013478
[Epoch 29; Iter   664/ 1097] train: loss: 0.0288012
[Epoch 29; Iter   694/ 1097] train: loss: 0.0325358
[Epoch 29; Iter   724/ 1097] train: loss: 0.0369602
[Epoch 29; Iter   754/ 1097] train: loss: 0.0524322
[Epoch 29; Iter   784/ 1097] train: loss: 0.0650270
[Epoch 29; Iter   814/ 1097] train: loss: 0.0263018
[Epoch 29; Iter   844/ 1097] train: loss: 0.0480929
[Epoch 29; Iter   874/ 1097] train: loss: 0.3547775
[Epoch 29; Iter   904/ 1097] train: loss: 0.0364691
[Epoch 29; Iter   934/ 1097] train: loss: 0.2506530
[Epoch 29; Iter   964/ 1097] train: loss: 0.0440675
[Epoch 29; Iter   994/ 1097] train: loss: 0.0721978
[Epoch 29; Iter  1024/ 1097] train: loss: 0.0329087
[Epoch 29; Iter  1054/ 1097] train: loss: 0.0319826
[Epoch 29; Iter  1084/ 1097] train: loss: 0.0210934
[Epoch 29] ogbg-molhiv: 0.815292 val loss: 0.075031
[Epoch 29] ogbg-molhiv: 0.771417 test loss: 0.120407
[Epoch 30; Iter    17/ 1097] train: loss: 0.0620891
[Epoch 30; Iter    47/ 1097] train: loss: 0.2107285
[Epoch 30; Iter    77/ 1097] train: loss: 0.0830793
[Epoch 30; Iter   107/ 1097] train: loss: 0.0670397
[Epoch 30; Iter   137/ 1097] train: loss: 0.2428737
[Epoch 30; Iter   167/ 1097] train: loss: 0.0195268
[Epoch 30; Iter   197/ 1097] train: loss: 0.0311663
[Epoch 30; Iter   227/ 1097] train: loss: 0.0469832
[Epoch 30; Iter   257/ 1097] train: loss: 0.0849658
[Epoch 30; Iter   287/ 1097] train: loss: 0.0363216
[Epoch 30; Iter   317/ 1097] train: loss: 0.1093249
[Epoch 30; Iter   347/ 1097] train: loss: 0.1060651
[Epoch 30; Iter   377/ 1097] train: loss: 0.0861079
[Epoch 30; Iter   407/ 1097] train: loss: 0.0407219
[Epoch 30; Iter   437/ 1097] train: loss: 0.0413578
[Epoch 30; Iter   467/ 1097] train: loss: 0.0157119
[Epoch 30; Iter   497/ 1097] train: loss: 0.0602702
[Epoch 30; Iter   527/ 1097] train: loss: 0.1577114
[Epoch 30; Iter   557/ 1097] train: loss: 0.1729195
[Epoch 30; Iter   587/ 1097] train: loss: 0.0496427
[Epoch 30; Iter   617/ 1097] train: loss: 0.0204297
[Epoch 30; Iter   647/ 1097] train: loss: 0.0129249
[Epoch 30; Iter   677/ 1097] train: loss: 0.2396065
[Epoch 30; Iter   707/ 1097] train: loss: 0.1478944
[Epoch 30; Iter   737/ 1097] train: loss: 0.0685880
[Epoch 30; Iter   767/ 1097] train: loss: 0.0231376
[Epoch 30; Iter   797/ 1097] train: loss: 0.2701673
[Epoch 30; Iter   827/ 1097] train: loss: 0.3001040
[Epoch 30; Iter   857/ 1097] train: loss: 0.1592291
[Epoch 30; Iter   887/ 1097] train: loss: 0.0682144
[Epoch 30; Iter   917/ 1097] train: loss: 0.2029456
[Epoch 30; Iter   947/ 1097] train: loss: 0.0480159
[Epoch 30; Iter   977/ 1097] train: loss: 0.0912747
[Epoch 30; Iter  1007/ 1097] train: loss: 0.1230386
[Epoch 30; Iter  1037/ 1097] train: loss: 0.1104262
[Epoch 30; Iter  1067/ 1097] train: loss: 0.0391724
[Epoch 30; Iter  1097/ 1097] train: loss: 0.0170708
[Epoch 30] ogbg-molhiv: 0.826294 val loss: 0.074875
[Epoch 30] ogbg-molhiv: 0.758271 test loss: 0.255844
[Epoch 31; Iter    30/ 1097] train: loss: 0.1171868
[Epoch 31; Iter    60/ 1097] train: loss: 0.1531885
[Epoch 31; Iter    90/ 1097] train: loss: 0.0154826
[Epoch 31; Iter   120/ 1097] train: loss: 0.0299095
[Epoch 31; Iter   150/ 1097] train: loss: 0.2857468
[Epoch 31; Iter   180/ 1097] train: loss: 0.0504216
[Epoch 31; Iter   210/ 1097] train: loss: 0.0198135
[Epoch 31; Iter   240/ 1097] train: loss: 0.0801231
[Epoch 31; Iter   270/ 1097] train: loss: 0.1586810
[Epoch 31; Iter   300/ 1097] train: loss: 0.0663582
[Epoch 31; Iter   330/ 1097] train: loss: 0.0797446
[Epoch 31; Iter   360/ 1097] train: loss: 0.0941245
[Epoch 31; Iter   390/ 1097] train: loss: 0.1209531
[Epoch 31; Iter   420/ 1097] train: loss: 0.1519430
[Epoch 31; Iter   450/ 1097] train: loss: 0.0318714
[Epoch 31; Iter   480/ 1097] train: loss: 0.1354437
[Epoch 31; Iter   510/ 1097] train: loss: 0.0270908
[Epoch 31; Iter   540/ 1097] train: loss: 0.1630533
[Epoch 31; Iter   570/ 1097] train: loss: 0.1906020
[Epoch 31; Iter   600/ 1097] train: loss: 0.0110202
[Epoch 31; Iter   630/ 1097] train: loss: 0.0557800
[Epoch 31; Iter   660/ 1097] train: loss: 0.0714119
[Epoch 31; Iter   690/ 1097] train: loss: 0.0370853
[Epoch 31; Iter   720/ 1097] train: loss: 0.0191029
[Epoch 31; Iter   750/ 1097] train: loss: 0.0120441
[Epoch 31; Iter   780/ 1097] train: loss: 0.0702120
[Epoch 31; Iter   810/ 1097] train: loss: 0.0261624
[Epoch 31; Iter   840/ 1097] train: loss: 0.1167311
[Epoch 31; Iter   870/ 1097] train: loss: 0.1438636
[Epoch 31; Iter   900/ 1097] train: loss: 0.0292195
[Epoch 31; Iter   930/ 1097] train: loss: 0.0469123
[Epoch 31; Iter   960/ 1097] train: loss: 0.0510975
[Epoch 31; Iter   990/ 1097] train: loss: 0.1766870
[Epoch 31; Iter  1020/ 1097] train: loss: 0.2103628
[Epoch 31; Iter  1050/ 1097] train: loss: 0.1905220
[Epoch 31; Iter  1080/ 1097] train: loss: 0.0274690
[Epoch 31] ogbg-molhiv: 0.816049 val loss: 0.091687
[Epoch 31] ogbg-molhiv: 0.748655 test loss: 0.205594
[Epoch 32; Iter    13/ 1097] train: loss: 0.0167781
[Epoch 32; Iter    43/ 1097] train: loss: 0.1279634
[Epoch 32; Iter    73/ 1097] train: loss: 0.0211922
[Epoch 32; Iter   103/ 1097] train: loss: 0.0226440
[Epoch 32; Iter   133/ 1097] train: loss: 0.0250937
[Epoch 32; Iter   163/ 1097] train: loss: 0.0838292
[Epoch 32; Iter   193/ 1097] train: loss: 0.1302868
[Epoch 32; Iter   223/ 1097] train: loss: 0.0532850
[Epoch 32; Iter   253/ 1097] train: loss: 0.0516591
[Epoch 32; Iter   283/ 1097] train: loss: 0.0164326
[Epoch 32; Iter   313/ 1097] train: loss: 0.0340869
[Epoch 32; Iter   343/ 1097] train: loss: 0.0997767
[Epoch 32; Iter   373/ 1097] train: loss: 0.1923041
[Epoch 32; Iter   403/ 1097] train: loss: 0.0321680
[Epoch 32; Iter   433/ 1097] train: loss: 0.0113327
[Epoch 32; Iter   463/ 1097] train: loss: 0.2309390
[Epoch 32; Iter   493/ 1097] train: loss: 0.0713995
[Epoch 32; Iter   523/ 1097] train: loss: 0.2380617
[Epoch 31; Iter   480/  823] train: loss: 0.1216421
[Epoch 31; Iter   510/  823] train: loss: 0.1562839
[Epoch 31; Iter   540/  823] train: loss: 0.0324460
[Epoch 31; Iter   570/  823] train: loss: 0.1107063
[Epoch 31; Iter   600/  823] train: loss: 0.1260157
[Epoch 31; Iter   630/  823] train: loss: 0.1121199
[Epoch 31; Iter   660/  823] train: loss: 0.0804418
[Epoch 31; Iter   690/  823] train: loss: 0.1517045
[Epoch 31; Iter   720/  823] train: loss: 0.0239983
[Epoch 31; Iter   750/  823] train: loss: 0.0389034
[Epoch 31; Iter   780/  823] train: loss: 0.2074572
[Epoch 31; Iter   810/  823] train: loss: 0.0516821
[Epoch 31] ogbg-molhiv: 0.730563 val loss: 0.154929
[Epoch 31] ogbg-molhiv: 0.740322 test loss: 0.241288
[Epoch 32; Iter    17/  823] train: loss: 0.2234993
[Epoch 32; Iter    47/  823] train: loss: 0.0438731
[Epoch 32; Iter    77/  823] train: loss: 0.0586526
[Epoch 32; Iter   107/  823] train: loss: 0.0669994
[Epoch 32; Iter   137/  823] train: loss: 0.0223684
[Epoch 32; Iter   167/  823] train: loss: 0.0400484
[Epoch 32; Iter   197/  823] train: loss: 0.2177486
[Epoch 32; Iter   227/  823] train: loss: 0.3313816
[Epoch 32; Iter   257/  823] train: loss: 0.0286805
[Epoch 32; Iter   287/  823] train: loss: 0.1871287
[Epoch 32; Iter   317/  823] train: loss: 0.0763641
[Epoch 32; Iter   347/  823] train: loss: 0.3856836
[Epoch 32; Iter   377/  823] train: loss: 0.2600801
[Epoch 32; Iter   407/  823] train: loss: 0.1110914
[Epoch 32; Iter   437/  823] train: loss: 0.0405393
[Epoch 32; Iter   467/  823] train: loss: 0.0144018
[Epoch 32; Iter   497/  823] train: loss: 0.0235887
[Epoch 32; Iter   527/  823] train: loss: 0.0208835
[Epoch 32; Iter   557/  823] train: loss: 0.0995487
[Epoch 32; Iter   587/  823] train: loss: 0.2069858
[Epoch 32; Iter   617/  823] train: loss: 0.0518230
[Epoch 32; Iter   647/  823] train: loss: 0.0743304
[Epoch 32; Iter   677/  823] train: loss: 0.0264552
[Epoch 32; Iter   707/  823] train: loss: 0.2605979
[Epoch 32; Iter   737/  823] train: loss: 0.1267299
[Epoch 32; Iter   767/  823] train: loss: 0.1822035
[Epoch 32; Iter   797/  823] train: loss: 0.0206479
[Epoch 32] ogbg-molhiv: 0.714641 val loss: 0.160968
[Epoch 32] ogbg-molhiv: 0.747842 test loss: 0.241272
[Epoch 33; Iter     4/  823] train: loss: 0.0476416
[Epoch 33; Iter    34/  823] train: loss: 0.0949026
[Epoch 33; Iter    64/  823] train: loss: 0.0263053
[Epoch 33; Iter    94/  823] train: loss: 0.0525169
[Epoch 33; Iter   124/  823] train: loss: 0.1370500
[Epoch 33; Iter   154/  823] train: loss: 0.0160463
[Epoch 33; Iter   184/  823] train: loss: 0.1857535
[Epoch 33; Iter   214/  823] train: loss: 0.0698272
[Epoch 33; Iter   244/  823] train: loss: 0.0573409
[Epoch 33; Iter   274/  823] train: loss: 0.0410386
[Epoch 33; Iter   304/  823] train: loss: 0.0335006
[Epoch 33; Iter   334/  823] train: loss: 0.0171098
[Epoch 33; Iter   364/  823] train: loss: 0.0623514
[Epoch 33; Iter   394/  823] train: loss: 0.0369983
[Epoch 33; Iter   424/  823] train: loss: 0.0231178
[Epoch 33; Iter   454/  823] train: loss: 0.1362906
[Epoch 33; Iter   484/  823] train: loss: 0.0793428
[Epoch 33; Iter   514/  823] train: loss: 0.0386555
[Epoch 33; Iter   544/  823] train: loss: 0.2340840
[Epoch 33; Iter   574/  823] train: loss: 0.0177128
[Epoch 33; Iter   604/  823] train: loss: 0.0334352
[Epoch 33; Iter   634/  823] train: loss: 0.0505081
[Epoch 33; Iter   664/  823] train: loss: 0.0390228
[Epoch 33; Iter   694/  823] train: loss: 0.0604971
[Epoch 33; Iter   724/  823] train: loss: 0.0781036
[Epoch 33; Iter   754/  823] train: loss: 0.0225032
[Epoch 33; Iter   784/  823] train: loss: 0.0185292
[Epoch 33; Iter   814/  823] train: loss: 0.1869386
[Epoch 33] ogbg-molhiv: 0.708722 val loss: 0.158975
[Epoch 33] ogbg-molhiv: 0.758576 test loss: 0.218821
[Epoch 34; Iter    21/  823] train: loss: 0.2815193
[Epoch 34; Iter    51/  823] train: loss: 0.1505036
[Epoch 34; Iter    81/  823] train: loss: 0.0289965
[Epoch 34; Iter   111/  823] train: loss: 0.3471488
[Epoch 34; Iter   141/  823] train: loss: 0.0973860
[Epoch 34; Iter   171/  823] train: loss: 0.0302603
[Epoch 34; Iter   201/  823] train: loss: 0.0212044
[Epoch 34; Iter   231/  823] train: loss: 0.0205579
[Epoch 34; Iter   261/  823] train: loss: 0.0289279
[Epoch 34; Iter   291/  823] train: loss: 0.2734734
[Epoch 34; Iter   321/  823] train: loss: 0.0212698
[Epoch 34; Iter   351/  823] train: loss: 0.0197587
[Epoch 34; Iter   381/  823] train: loss: 0.0492029
[Epoch 34; Iter   411/  823] train: loss: 0.0322390
[Epoch 34; Iter   441/  823] train: loss: 0.1239222
[Epoch 34; Iter   471/  823] train: loss: 0.1043367
[Epoch 34; Iter   501/  823] train: loss: 0.1276777
[Epoch 34; Iter   531/  823] train: loss: 0.2799647
[Epoch 34; Iter   561/  823] train: loss: 0.0242692
[Epoch 34; Iter   591/  823] train: loss: 0.0231928
[Epoch 34; Iter   621/  823] train: loss: 0.1818260
[Epoch 34; Iter   651/  823] train: loss: 0.0302330
[Epoch 34; Iter   681/  823] train: loss: 0.1445886
[Epoch 34; Iter   711/  823] train: loss: 0.0953622
[Epoch 34; Iter   741/  823] train: loss: 0.3147255
[Epoch 34; Iter   771/  823] train: loss: 0.0207589
[Epoch 34; Iter   801/  823] train: loss: 0.0234836
[Epoch 34] ogbg-molhiv: 0.727181 val loss: 0.192122
[Epoch 34] ogbg-molhiv: 0.777546 test loss: 0.228538
[Epoch 35; Iter     8/  823] train: loss: 0.1155105
[Epoch 35; Iter    38/  823] train: loss: 0.1441240
[Epoch 35; Iter    68/  823] train: loss: 0.0359985
[Epoch 35; Iter    98/  823] train: loss: 0.0143410
[Epoch 35; Iter   128/  823] train: loss: 0.0545701
[Epoch 35; Iter   158/  823] train: loss: 0.1499610
[Epoch 35; Iter   188/  823] train: loss: 0.2844288
[Epoch 35; Iter   218/  823] train: loss: 0.0836858
[Epoch 35; Iter   248/  823] train: loss: 0.0547068
[Epoch 35; Iter   278/  823] train: loss: 0.0709944
[Epoch 35; Iter   308/  823] train: loss: 0.0745609
[Epoch 35; Iter   338/  823] train: loss: 0.1527708
[Epoch 35; Iter   368/  823] train: loss: 0.2705857
[Epoch 35; Iter   398/  823] train: loss: 0.1842956
[Epoch 35; Iter   428/  823] train: loss: 0.2096862
[Epoch 35; Iter   458/  823] train: loss: 0.2908382
[Epoch 35; Iter   488/  823] train: loss: 0.0288678
[Epoch 35; Iter   518/  823] train: loss: 0.1670248
[Epoch 35; Iter   548/  823] train: loss: 0.1259243
[Epoch 35; Iter   578/  823] train: loss: 0.0704381
[Epoch 35; Iter   608/  823] train: loss: 0.1453126
[Epoch 35; Iter   638/  823] train: loss: 0.0197176
[Epoch 35; Iter   668/  823] train: loss: 0.0404692
[Epoch 35; Iter   698/  823] train: loss: 0.0371246
[Epoch 35; Iter   728/  823] train: loss: 0.1579046
[Epoch 35; Iter   758/  823] train: loss: 0.0954996
[Epoch 35; Iter   788/  823] train: loss: 0.4583765
[Epoch 35; Iter   818/  823] train: loss: 0.0261458
[Epoch 35] ogbg-molhiv: 0.719760 val loss: 0.180287
[Epoch 35] ogbg-molhiv: 0.748373 test loss: 0.239486
[Epoch 36; Iter    25/  823] train: loss: 0.0528376
[Epoch 36; Iter    55/  823] train: loss: 0.0715832
[Epoch 36; Iter    85/  823] train: loss: 0.0225074
[Epoch 36; Iter   115/  823] train: loss: 0.0161190
[Epoch 36; Iter   145/  823] train: loss: 0.0200571
[Epoch 36; Iter   175/  823] train: loss: 0.0491341
[Epoch 36; Iter   205/  823] train: loss: 0.0209596
[Epoch 36; Iter   235/  823] train: loss: 0.0249317
[Epoch 36; Iter   265/  823] train: loss: 0.0213815
[Epoch 36; Iter   295/  823] train: loss: 0.0337396
[Epoch 36; Iter   325/  823] train: loss: 0.1273093
[Epoch 36; Iter   355/  823] train: loss: 0.1241284
[Epoch 36; Iter   385/  823] train: loss: 0.0231798
[Epoch 36; Iter   415/  823] train: loss: 0.0262832
[Epoch 36; Iter   445/  823] train: loss: 0.0171279
[Epoch 36; Iter   475/  823] train: loss: 0.0719407
[Epoch 36; Iter   505/  823] train: loss: 0.0169602
[Epoch 36; Iter   535/  823] train: loss: 0.2879565
[Epoch 36; Iter   565/  823] train: loss: 0.0687527
[Epoch 36; Iter   595/  823] train: loss: 0.0758338
[Epoch 36; Iter   625/  823] train: loss: 0.1109049
[Epoch 36; Iter   655/  823] train: loss: 0.1250818
[Epoch 36; Iter   685/  823] train: loss: 0.0282193
[Epoch 36; Iter   715/  823] train: loss: 0.0193049
[Epoch 36; Iter   745/  823] train: loss: 0.2716709
[Epoch 31; Iter   480/  823] train: loss: 0.0455221
[Epoch 31; Iter   510/  823] train: loss: 0.0196100
[Epoch 31; Iter   540/  823] train: loss: 0.2182046
[Epoch 31; Iter   570/  823] train: loss: 0.0152352
[Epoch 31; Iter   600/  823] train: loss: 0.0935463
[Epoch 31; Iter   630/  823] train: loss: 0.0533143
[Epoch 31; Iter   660/  823] train: loss: 0.0559658
[Epoch 31; Iter   690/  823] train: loss: 0.0912795
[Epoch 31; Iter   720/  823] train: loss: 0.0188301
[Epoch 31; Iter   750/  823] train: loss: 0.0452158
[Epoch 31; Iter   780/  823] train: loss: 0.0115452
[Epoch 31; Iter   810/  823] train: loss: 0.0224944
[Epoch 31] ogbg-molhiv: 0.727557 val loss: 0.156923
[Epoch 31] ogbg-molhiv: 0.739658 test loss: 0.109258
[Epoch 32; Iter    17/  823] train: loss: 0.1018048
[Epoch 32; Iter    47/  823] train: loss: 0.1668097
[Epoch 32; Iter    77/  823] train: loss: 0.0378375
[Epoch 32; Iter   107/  823] train: loss: 0.0603776
[Epoch 32; Iter   137/  823] train: loss: 0.0487716
[Epoch 32; Iter   167/  823] train: loss: 0.0173771
[Epoch 32; Iter   197/  823] train: loss: 0.0596225
[Epoch 32; Iter   227/  823] train: loss: 0.0630743
[Epoch 32; Iter   257/  823] train: loss: 0.0350269
[Epoch 32; Iter   287/  823] train: loss: 0.1424051
[Epoch 32; Iter   317/  823] train: loss: 0.0098429
[Epoch 32; Iter   347/  823] train: loss: 0.0485721
[Epoch 32; Iter   377/  823] train: loss: 0.0299168
[Epoch 32; Iter   407/  823] train: loss: 0.0823765
[Epoch 32; Iter   437/  823] train: loss: 0.2060498
[Epoch 32; Iter   467/  823] train: loss: 0.1161143
[Epoch 32; Iter   497/  823] train: loss: 0.0343538
[Epoch 32; Iter   527/  823] train: loss: 0.0541172
[Epoch 32; Iter   557/  823] train: loss: 0.1532178
[Epoch 32; Iter   587/  823] train: loss: 0.0450238
[Epoch 32; Iter   617/  823] train: loss: 0.0123829
[Epoch 32; Iter   647/  823] train: loss: 0.1032751
[Epoch 32; Iter   677/  823] train: loss: 0.0149738
[Epoch 32; Iter   707/  823] train: loss: 0.0092225
[Epoch 32; Iter   737/  823] train: loss: 0.1298934
[Epoch 32; Iter   767/  823] train: loss: 0.0206531
[Epoch 32; Iter   797/  823] train: loss: 0.2485428
[Epoch 32] ogbg-molhiv: 0.725671 val loss: 0.172596
[Epoch 32] ogbg-molhiv: 0.752232 test loss: 0.155820
[Epoch 33; Iter     4/  823] train: loss: 0.1898841
[Epoch 33; Iter    34/  823] train: loss: 0.0473481
[Epoch 33; Iter    64/  823] train: loss: 0.0437849
[Epoch 33; Iter    94/  823] train: loss: 0.0206738
[Epoch 33; Iter   124/  823] train: loss: 0.0521428
[Epoch 33; Iter   154/  823] train: loss: 0.0268298
[Epoch 33; Iter   184/  823] train: loss: 0.1025715
[Epoch 33; Iter   214/  823] train: loss: 0.0139758
[Epoch 33; Iter   244/  823] train: loss: 0.0405609
[Epoch 33; Iter   274/  823] train: loss: 0.0525997
[Epoch 33; Iter   304/  823] train: loss: 0.1029217
[Epoch 33; Iter   334/  823] train: loss: 0.0280153
[Epoch 33; Iter   364/  823] train: loss: 0.1928957
[Epoch 33; Iter   394/  823] train: loss: 0.0241788
[Epoch 33; Iter   424/  823] train: loss: 0.2961819
[Epoch 33; Iter   454/  823] train: loss: 0.1292762
[Epoch 33; Iter   484/  823] train: loss: 0.0815441
[Epoch 33; Iter   514/  823] train: loss: 0.1874768
[Epoch 33; Iter   544/  823] train: loss: 0.2059564
[Epoch 33; Iter   574/  823] train: loss: 0.1166842
[Epoch 33; Iter   604/  823] train: loss: 0.0370238
[Epoch 33; Iter   634/  823] train: loss: 0.0241758
[Epoch 33; Iter   664/  823] train: loss: 0.0288184
[Epoch 33; Iter   694/  823] train: loss: 0.1188940
[Epoch 33; Iter   724/  823] train: loss: 0.2312323
[Epoch 33; Iter   754/  823] train: loss: 0.0192139
[Epoch 33; Iter   784/  823] train: loss: 0.0181391
[Epoch 33; Iter   814/  823] train: loss: 0.0106828
[Epoch 33] ogbg-molhiv: 0.715306 val loss: 0.169731
[Epoch 33] ogbg-molhiv: 0.765371 test loss: 0.122955
[Epoch 34; Iter    21/  823] train: loss: 0.0631264
[Epoch 34; Iter    51/  823] train: loss: 0.0089641
[Epoch 34; Iter    81/  823] train: loss: 0.0903550
[Epoch 34; Iter   111/  823] train: loss: 0.0332499
[Epoch 34; Iter   141/  823] train: loss: 0.0285077
[Epoch 34; Iter   171/  823] train: loss: 0.0459618
[Epoch 34; Iter   201/  823] train: loss: 0.0330216
[Epoch 34; Iter   231/  823] train: loss: 0.0336121
[Epoch 34; Iter   261/  823] train: loss: 0.1202684
[Epoch 34; Iter   291/  823] train: loss: 0.0480402
[Epoch 34; Iter   321/  823] train: loss: 0.0215720
[Epoch 34; Iter   351/  823] train: loss: 0.0219111
[Epoch 34; Iter   381/  823] train: loss: 0.1245760
[Epoch 34; Iter   411/  823] train: loss: 0.0356052
[Epoch 34; Iter   441/  823] train: loss: 0.1120739
[Epoch 34; Iter   471/  823] train: loss: 0.0936227
[Epoch 34; Iter   501/  823] train: loss: 0.1327374
[Epoch 34; Iter   531/  823] train: loss: 0.1441450
[Epoch 34; Iter   561/  823] train: loss: 0.1288218
[Epoch 34; Iter   591/  823] train: loss: 0.0188131
[Epoch 34; Iter   621/  823] train: loss: 0.0130312
[Epoch 34; Iter   651/  823] train: loss: 0.0094537
[Epoch 34; Iter   681/  823] train: loss: 0.0876617
[Epoch 34; Iter   711/  823] train: loss: 0.0516762
[Epoch 34; Iter   741/  823] train: loss: 0.1206966
[Epoch 34; Iter   771/  823] train: loss: 0.0156916
[Epoch 34; Iter   801/  823] train: loss: 0.1274154
[Epoch 34] ogbg-molhiv: 0.719403 val loss: 0.155733
[Epoch 34] ogbg-molhiv: 0.747508 test loss: 0.109697
[Epoch 35; Iter     8/  823] train: loss: 0.0241773
[Epoch 35; Iter    38/  823] train: loss: 0.0163450
[Epoch 35; Iter    68/  823] train: loss: 0.2115147
[Epoch 35; Iter    98/  823] train: loss: 0.1214392
[Epoch 35; Iter   128/  823] train: loss: 0.0155167
[Epoch 35; Iter   158/  823] train: loss: 0.0680018
[Epoch 35; Iter   188/  823] train: loss: 0.1890684
[Epoch 35; Iter   218/  823] train: loss: 0.0701847
[Epoch 35; Iter   248/  823] train: loss: 0.0722468
[Epoch 35; Iter   278/  823] train: loss: 0.0651842
[Epoch 35; Iter   308/  823] train: loss: 0.0909207
[Epoch 35; Iter   338/  823] train: loss: 0.1181249
[Epoch 35; Iter   368/  823] train: loss: 0.0104950
[Epoch 35; Iter   398/  823] train: loss: 0.0305728
[Epoch 35; Iter   428/  823] train: loss: 0.3968610
[Epoch 35; Iter   458/  823] train: loss: 0.0203418
[Epoch 35; Iter   488/  823] train: loss: 0.0254398
[Epoch 35; Iter   518/  823] train: loss: 0.0520948
[Epoch 35; Iter   548/  823] train: loss: 0.1704580
[Epoch 35; Iter   578/  823] train: loss: 0.0351260
[Epoch 35; Iter   608/  823] train: loss: 0.0237094
[Epoch 35; Iter   638/  823] train: loss: 0.2405586
[Epoch 35; Iter   668/  823] train: loss: 0.0154155
[Epoch 35; Iter   698/  823] train: loss: 0.0537359
[Epoch 35; Iter   728/  823] train: loss: 0.0467401
[Epoch 35; Iter   758/  823] train: loss: 0.1371695
[Epoch 35; Iter   788/  823] train: loss: 0.0616937
[Epoch 35; Iter   818/  823] train: loss: 0.0211250
[Epoch 35] ogbg-molhiv: 0.726717 val loss: 0.178525
[Epoch 35] ogbg-molhiv: 0.746537 test loss: 0.118454
[Epoch 36; Iter    25/  823] train: loss: 0.0143493
[Epoch 36; Iter    55/  823] train: loss: 0.0347680
[Epoch 36; Iter    85/  823] train: loss: 0.0219256
[Epoch 36; Iter   115/  823] train: loss: 0.2363481
[Epoch 36; Iter   145/  823] train: loss: 0.0155697
[Epoch 36; Iter   175/  823] train: loss: 0.0234131
[Epoch 36; Iter   205/  823] train: loss: 0.0199415
[Epoch 36; Iter   235/  823] train: loss: 0.1134881
[Epoch 36; Iter   265/  823] train: loss: 0.0478592
[Epoch 36; Iter   295/  823] train: loss: 0.0144005
[Epoch 36; Iter   325/  823] train: loss: 0.1832219
[Epoch 36; Iter   355/  823] train: loss: 0.1992448
[Epoch 36; Iter   385/  823] train: loss: 0.1833188
[Epoch 36; Iter   415/  823] train: loss: 0.0149819
[Epoch 36; Iter   445/  823] train: loss: 0.0161410
[Epoch 36; Iter   475/  823] train: loss: 0.1313908
[Epoch 36; Iter   505/  823] train: loss: 0.0270327
[Epoch 36; Iter   535/  823] train: loss: 0.0265140
[Epoch 36; Iter   565/  823] train: loss: 0.0982548
[Epoch 36; Iter   595/  823] train: loss: 0.1288068
[Epoch 36; Iter   625/  823] train: loss: 0.0481094
[Epoch 36; Iter   655/  823] train: loss: 0.0191611
[Epoch 36; Iter   685/  823] train: loss: 0.0313401
[Epoch 36; Iter   715/  823] train: loss: 0.0217710
[Epoch 36; Iter   745/  823] train: loss: 0.0802613
[Epoch 31; Iter   480/  823] train: loss: 0.2189082
[Epoch 31; Iter   510/  823] train: loss: 0.1104365
[Epoch 31; Iter   540/  823] train: loss: 0.0610141
[Epoch 31; Iter   570/  823] train: loss: 0.0363297
[Epoch 31; Iter   600/  823] train: loss: 0.0212163
[Epoch 31; Iter   630/  823] train: loss: 0.0429919
[Epoch 31; Iter   660/  823] train: loss: 0.0387518
[Epoch 31; Iter   690/  823] train: loss: 0.0482189
[Epoch 31; Iter   720/  823] train: loss: 0.1342950
[Epoch 31; Iter   750/  823] train: loss: 0.2579509
[Epoch 31; Iter   780/  823] train: loss: 0.0815335
[Epoch 31; Iter   810/  823] train: loss: 0.1397720
[Epoch 31] ogbg-molhiv: 0.694032 val loss: 0.602178
[Epoch 31] ogbg-molhiv: 0.766983 test loss: 0.317052
[Epoch 32; Iter    17/  823] train: loss: 0.0278158
[Epoch 32; Iter    47/  823] train: loss: 0.0584099
[Epoch 32; Iter    77/  823] train: loss: 0.0252589
[Epoch 32; Iter   107/  823] train: loss: 0.0097426
[Epoch 32; Iter   137/  823] train: loss: 0.0271482
[Epoch 32; Iter   167/  823] train: loss: 0.2042460
[Epoch 32; Iter   197/  823] train: loss: 0.1924225
[Epoch 32; Iter   227/  823] train: loss: 0.1431824
[Epoch 32; Iter   257/  823] train: loss: 0.0407249
[Epoch 32; Iter   287/  823] train: loss: 0.0453627
[Epoch 32; Iter   317/  823] train: loss: 0.1591713
[Epoch 32; Iter   347/  823] train: loss: 0.2269125
[Epoch 32; Iter   377/  823] train: loss: 0.2288795
[Epoch 32; Iter   407/  823] train: loss: 0.1237031
[Epoch 32; Iter   437/  823] train: loss: 0.0154224
[Epoch 32; Iter   467/  823] train: loss: 0.2536657
[Epoch 32; Iter   497/  823] train: loss: 0.0526968
[Epoch 32; Iter   527/  823] train: loss: 0.0279104
[Epoch 32; Iter   557/  823] train: loss: 0.0590414
[Epoch 32; Iter   587/  823] train: loss: 0.0352829
[Epoch 32; Iter   617/  823] train: loss: 0.1277634
[Epoch 32; Iter   647/  823] train: loss: 0.0647111
[Epoch 32; Iter   677/  823] train: loss: 0.0206211
[Epoch 32; Iter   707/  823] train: loss: 0.0354944
[Epoch 32; Iter   737/  823] train: loss: 0.0201976
[Epoch 32; Iter   767/  823] train: loss: 0.0358159
[Epoch 32; Iter   797/  823] train: loss: 0.0288052
[Epoch 32] ogbg-molhiv: 0.704882 val loss: 0.166660
[Epoch 32] ogbg-molhiv: 0.766284 test loss: 0.107057
[Epoch 33; Iter     4/  823] train: loss: 0.2156040
[Epoch 33; Iter    34/  823] train: loss: 0.0134771
[Epoch 33; Iter    64/  823] train: loss: 0.0233725
[Epoch 33; Iter    94/  823] train: loss: 0.1082205
[Epoch 33; Iter   124/  823] train: loss: 0.0367250
[Epoch 33; Iter   154/  823] train: loss: 0.0344078
[Epoch 33; Iter   184/  823] train: loss: 0.0195575
[Epoch 33; Iter   214/  823] train: loss: 0.0262314
[Epoch 33; Iter   244/  823] train: loss: 0.0903443
[Epoch 33; Iter   274/  823] train: loss: 0.0217141
[Epoch 33; Iter   304/  823] train: loss: 0.1051846
[Epoch 33; Iter   334/  823] train: loss: 0.0558467
[Epoch 33; Iter   364/  823] train: loss: 0.0805967
[Epoch 33; Iter   394/  823] train: loss: 0.0245842
[Epoch 33; Iter   424/  823] train: loss: 0.0851923
[Epoch 33; Iter   454/  823] train: loss: 0.0890146
[Epoch 33; Iter   484/  823] train: loss: 0.0479968
[Epoch 33; Iter   514/  823] train: loss: 0.0494119
[Epoch 33; Iter   544/  823] train: loss: 0.2810209
[Epoch 33; Iter   574/  823] train: loss: 0.0840651
[Epoch 33; Iter   604/  823] train: loss: 0.0221982
[Epoch 33; Iter   634/  823] train: loss: 0.0431056
[Epoch 33; Iter   664/  823] train: loss: 0.0633455
[Epoch 33; Iter   694/  823] train: loss: 0.0434004
[Epoch 33; Iter   724/  823] train: loss: 0.0203113
[Epoch 33; Iter   754/  823] train: loss: 0.0251493
[Epoch 33; Iter   784/  823] train: loss: 0.0243850
[Epoch 33; Iter   814/  823] train: loss: 0.0200813
[Epoch 33] ogbg-molhiv: 0.723059 val loss: 0.151413
[Epoch 33] ogbg-molhiv: 0.763256 test loss: 0.123110
[Epoch 34; Iter    21/  823] train: loss: 0.1843555
[Epoch 34; Iter    51/  823] train: loss: 0.0315650
[Epoch 34; Iter    81/  823] train: loss: 0.0918860
[Epoch 34; Iter   111/  823] train: loss: 0.1856340
[Epoch 34; Iter   141/  823] train: loss: 0.2461640
[Epoch 34; Iter   171/  823] train: loss: 0.0117471
[Epoch 34; Iter   201/  823] train: loss: 0.1702865
[Epoch 34; Iter   231/  823] train: loss: 0.1628429
[Epoch 34; Iter   261/  823] train: loss: 0.1369788
[Epoch 34; Iter   291/  823] train: loss: 0.1250367
[Epoch 34; Iter   321/  823] train: loss: 0.0275961
[Epoch 34; Iter   351/  823] train: loss: 0.0372174
[Epoch 34; Iter   381/  823] train: loss: 0.1825477
[Epoch 34; Iter   411/  823] train: loss: 0.0729391
[Epoch 34; Iter   441/  823] train: loss: 0.0540192
[Epoch 34; Iter   471/  823] train: loss: 0.0681929
[Epoch 34; Iter   501/  823] train: loss: 0.0320897
[Epoch 34; Iter   531/  823] train: loss: 0.2115382
[Epoch 34; Iter   561/  823] train: loss: 0.0182939
[Epoch 34; Iter   591/  823] train: loss: 0.0100531
[Epoch 34; Iter   621/  823] train: loss: 0.0162126
[Epoch 34; Iter   651/  823] train: loss: 0.0185456
[Epoch 34; Iter   681/  823] train: loss: 0.0242620
[Epoch 34; Iter   711/  823] train: loss: 0.0297937
[Epoch 34; Iter   741/  823] train: loss: 0.2211578
[Epoch 34; Iter   771/  823] train: loss: 0.0304058
[Epoch 34; Iter   801/  823] train: loss: 0.0471345
[Epoch 34] ogbg-molhiv: 0.713918 val loss: 0.150002
[Epoch 34] ogbg-molhiv: 0.774005 test loss: 0.170519
[Epoch 35; Iter     8/  823] train: loss: 0.0263288
[Epoch 35; Iter    38/  823] train: loss: 0.0182380
[Epoch 35; Iter    68/  823] train: loss: 0.0513278
[Epoch 35; Iter    98/  823] train: loss: 0.0171043
[Epoch 35; Iter   128/  823] train: loss: 0.0187073
[Epoch 35; Iter   158/  823] train: loss: 0.0592122
[Epoch 35; Iter   188/  823] train: loss: 0.0131658
[Epoch 35; Iter   218/  823] train: loss: 0.0191328
[Epoch 35; Iter   248/  823] train: loss: 0.0131084
[Epoch 35; Iter   278/  823] train: loss: 0.0768543
[Epoch 35; Iter   308/  823] train: loss: 0.1234490
[Epoch 35; Iter   338/  823] train: loss: 0.0988174
[Epoch 35; Iter   368/  823] train: loss: 0.0385157
[Epoch 35; Iter   398/  823] train: loss: 0.0150244
[Epoch 35; Iter   428/  823] train: loss: 0.0183921
[Epoch 35; Iter   458/  823] train: loss: 0.0250162
[Epoch 35; Iter   488/  823] train: loss: 0.1299889
[Epoch 35; Iter   518/  823] train: loss: 0.0193108
[Epoch 35; Iter   548/  823] train: loss: 0.0508597
[Epoch 35; Iter   578/  823] train: loss: 0.0590288
[Epoch 35; Iter   608/  823] train: loss: 0.2331357
[Epoch 35; Iter   638/  823] train: loss: 0.0756425
[Epoch 35; Iter   668/  823] train: loss: 0.0188172
[Epoch 35; Iter   698/  823] train: loss: 0.1105947
[Epoch 35; Iter   728/  823] train: loss: 0.1655827
[Epoch 35; Iter   758/  823] train: loss: 0.2142465
[Epoch 35; Iter   788/  823] train: loss: 0.0447268
[Epoch 35; Iter   818/  823] train: loss: 0.0141918
[Epoch 35] ogbg-molhiv: 0.715171 val loss: 0.153959
[Epoch 35] ogbg-molhiv: 0.775942 test loss: 0.101468
[Epoch 36; Iter    25/  823] train: loss: 0.1677594
[Epoch 36; Iter    55/  823] train: loss: 0.0203959
[Epoch 36; Iter    85/  823] train: loss: 0.0701262
[Epoch 36; Iter   115/  823] train: loss: 0.1293285
[Epoch 36; Iter   145/  823] train: loss: 0.0285185
[Epoch 36; Iter   175/  823] train: loss: 0.0207725
[Epoch 36; Iter   205/  823] train: loss: 0.3298553
[Epoch 36; Iter   235/  823] train: loss: 0.3436303
[Epoch 36; Iter   265/  823] train: loss: 0.0645746
[Epoch 36; Iter   295/  823] train: loss: 0.0205035
[Epoch 36; Iter   325/  823] train: loss: 0.1192616
[Epoch 36; Iter   355/  823] train: loss: 0.0513062
[Epoch 36; Iter   385/  823] train: loss: 0.0412127
[Epoch 36; Iter   415/  823] train: loss: 0.0176031
[Epoch 36; Iter   445/  823] train: loss: 0.0784483
[Epoch 36; Iter   475/  823] train: loss: 0.0256508
[Epoch 36; Iter   505/  823] train: loss: 0.0078581
[Epoch 36; Iter   535/  823] train: loss: 0.0222970
[Epoch 36; Iter   565/  823] train: loss: 0.0674874
[Epoch 36; Iter   595/  823] train: loss: 0.4150327
[Epoch 36; Iter   625/  823] train: loss: 0.0343683
[Epoch 36; Iter   655/  823] train: loss: 0.0494324
[Epoch 36; Iter   685/  823] train: loss: 0.1700107
[Epoch 36; Iter   715/  823] train: loss: 0.2271172
[Epoch 36; Iter   745/  823] train: loss: 0.0771445
[Epoch 32; Iter    90/  960] train: loss: 0.0465312
[Epoch 32; Iter   120/  960] train: loss: 0.0132938
[Epoch 32; Iter   150/  960] train: loss: 0.1251090
[Epoch 32; Iter   180/  960] train: loss: 0.1826013
[Epoch 32; Iter   210/  960] train: loss: 0.1333186
[Epoch 32; Iter   240/  960] train: loss: 0.0164443
[Epoch 32; Iter   270/  960] train: loss: 0.0145369
[Epoch 32; Iter   300/  960] train: loss: 0.0476518
[Epoch 32; Iter   330/  960] train: loss: 0.1236117
[Epoch 32; Iter   360/  960] train: loss: 0.0404061
[Epoch 32; Iter   390/  960] train: loss: 0.0186411
[Epoch 32; Iter   420/  960] train: loss: 0.0214360
[Epoch 32; Iter   450/  960] train: loss: 0.0500398
[Epoch 32; Iter   480/  960] train: loss: 0.0716609
[Epoch 32; Iter   510/  960] train: loss: 0.0176286
[Epoch 32; Iter   540/  960] train: loss: 0.0977817
[Epoch 32; Iter   570/  960] train: loss: 0.0617826
[Epoch 32; Iter   600/  960] train: loss: 0.0198456
[Epoch 32; Iter   630/  960] train: loss: 0.1190629
[Epoch 32; Iter   660/  960] train: loss: 0.0604005
[Epoch 32; Iter   690/  960] train: loss: 0.1335725
[Epoch 32; Iter   720/  960] train: loss: 0.0307405
[Epoch 32; Iter   750/  960] train: loss: 0.1303257
[Epoch 32; Iter   780/  960] train: loss: 0.0228413
[Epoch 32; Iter   810/  960] train: loss: 0.0259476
[Epoch 32; Iter   840/  960] train: loss: 0.0223878
[Epoch 32; Iter   870/  960] train: loss: 0.2576928
[Epoch 32; Iter   900/  960] train: loss: 0.0218409
[Epoch 32; Iter   930/  960] train: loss: 0.1051059
[Epoch 32; Iter   960/  960] train: loss: 0.0250379
[Epoch 32] ogbg-molhiv: 0.768246 val loss: 0.588812
[Epoch 32] ogbg-molhiv: 0.776019 test loss: 0.428802
[Epoch 33; Iter    30/  960] train: loss: 0.0118042
[Epoch 33; Iter    60/  960] train: loss: 0.0235207
[Epoch 33; Iter    90/  960] train: loss: 0.0356715
[Epoch 33; Iter   120/  960] train: loss: 0.0201709
[Epoch 33; Iter   150/  960] train: loss: 0.0408208
[Epoch 33; Iter   180/  960] train: loss: 0.2019942
[Epoch 33; Iter   210/  960] train: loss: 0.0443891
[Epoch 33; Iter   240/  960] train: loss: 0.0445657
[Epoch 33; Iter   270/  960] train: loss: 0.0308265
[Epoch 33; Iter   300/  960] train: loss: 0.0136024
[Epoch 33; Iter   330/  960] train: loss: 0.2567426
[Epoch 33; Iter   360/  960] train: loss: 0.1742306
[Epoch 33; Iter   390/  960] train: loss: 0.0350149
[Epoch 33; Iter   420/  960] train: loss: 0.0242477
[Epoch 33; Iter   450/  960] train: loss: 0.0260219
[Epoch 33; Iter   480/  960] train: loss: 0.2062678
[Epoch 33; Iter   510/  960] train: loss: 0.1895824
[Epoch 33; Iter   540/  960] train: loss: 0.0329422
[Epoch 33; Iter   570/  960] train: loss: 0.0559707
[Epoch 33; Iter   600/  960] train: loss: 0.0141753
[Epoch 33; Iter   630/  960] train: loss: 0.0382896
[Epoch 33; Iter   660/  960] train: loss: 0.0167527
[Epoch 33; Iter   690/  960] train: loss: 0.0327501
[Epoch 33; Iter   720/  960] train: loss: 0.0243583
[Epoch 33; Iter   750/  960] train: loss: 0.0603587
[Epoch 33; Iter   780/  960] train: loss: 0.1190812
[Epoch 33; Iter   810/  960] train: loss: 0.0158225
[Epoch 33; Iter   840/  960] train: loss: 0.0327034
[Epoch 33; Iter   870/  960] train: loss: 0.0850103
[Epoch 33; Iter   900/  960] train: loss: 0.0333075
[Epoch 33; Iter   930/  960] train: loss: 0.1712452
[Epoch 33; Iter   960/  960] train: loss: 0.0519269
[Epoch 33] ogbg-molhiv: 0.743549 val loss: 0.545090
[Epoch 33] ogbg-molhiv: 0.759505 test loss: 0.331564
[Epoch 34; Iter    30/  960] train: loss: 0.0214081
[Epoch 34; Iter    60/  960] train: loss: 0.2330533
[Epoch 34; Iter    90/  960] train: loss: 0.4049301
[Epoch 34; Iter   120/  960] train: loss: 0.0169581
[Epoch 34; Iter   150/  960] train: loss: 0.0232621
[Epoch 34; Iter   180/  960] train: loss: 0.0690223
[Epoch 34; Iter   210/  960] train: loss: 0.2143730
[Epoch 34; Iter   240/  960] train: loss: 0.3082293
[Epoch 34; Iter   270/  960] train: loss: 0.0254123
[Epoch 34; Iter   300/  960] train: loss: 0.1516923
[Epoch 34; Iter   330/  960] train: loss: 0.0217661
[Epoch 34; Iter   360/  960] train: loss: 0.1522256
[Epoch 34; Iter   390/  960] train: loss: 0.0424059
[Epoch 34; Iter   420/  960] train: loss: 0.0108913
[Epoch 34; Iter   450/  960] train: loss: 0.1228309
[Epoch 34; Iter   480/  960] train: loss: 0.0174592
[Epoch 34; Iter   510/  960] train: loss: 0.0219233
[Epoch 34; Iter   540/  960] train: loss: 0.0099815
[Epoch 34; Iter   570/  960] train: loss: 0.0177588
[Epoch 34; Iter   600/  960] train: loss: 0.0442177
[Epoch 34; Iter   630/  960] train: loss: 0.0223042
[Epoch 34; Iter   660/  960] train: loss: 0.0821997
[Epoch 34; Iter   690/  960] train: loss: 0.0245109
[Epoch 34; Iter   720/  960] train: loss: 0.2030192
[Epoch 34; Iter   750/  960] train: loss: 0.0177194
[Epoch 34; Iter   780/  960] train: loss: 0.1245997
[Epoch 34; Iter   810/  960] train: loss: 0.1043375
[Epoch 34; Iter   840/  960] train: loss: 0.0207466
[Epoch 34; Iter   870/  960] train: loss: 0.0200117
[Epoch 34; Iter   900/  960] train: loss: 0.0250624
[Epoch 34; Iter   930/  960] train: loss: 0.0184868
[Epoch 34; Iter   960/  960] train: loss: 0.0212576
[Epoch 34] ogbg-molhiv: 0.764746 val loss: 1.037905
[Epoch 34] ogbg-molhiv: 0.766340 test loss: 0.488711
[Epoch 35; Iter    30/  960] train: loss: 0.0834709
[Epoch 35; Iter    60/  960] train: loss: 0.0135215
[Epoch 35; Iter    90/  960] train: loss: 0.0455114
[Epoch 35; Iter   120/  960] train: loss: 0.0771556
[Epoch 35; Iter   150/  960] train: loss: 0.0701191
[Epoch 35; Iter   180/  960] train: loss: 0.1460835
[Epoch 35; Iter   210/  960] train: loss: 0.0525061
[Epoch 35; Iter   240/  960] train: loss: 0.0492947
[Epoch 35; Iter   270/  960] train: loss: 0.2268718
[Epoch 35; Iter   300/  960] train: loss: 0.0182071
[Epoch 35; Iter   330/  960] train: loss: 0.2014915
[Epoch 35; Iter   360/  960] train: loss: 0.1174177
[Epoch 35; Iter   390/  960] train: loss: 0.0455229
[Epoch 35; Iter   420/  960] train: loss: 0.0959481
[Epoch 35; Iter   450/  960] train: loss: 0.0509684
[Epoch 35; Iter   480/  960] train: loss: 0.0515502
[Epoch 35; Iter   510/  960] train: loss: 0.0343756
[Epoch 35; Iter   540/  960] train: loss: 0.0950821
[Epoch 35; Iter   570/  960] train: loss: 0.0152461
[Epoch 35; Iter   600/  960] train: loss: 0.0279097
[Epoch 35; Iter   630/  960] train: loss: 0.3191617
[Epoch 35; Iter   660/  960] train: loss: 0.1584767
[Epoch 35; Iter   690/  960] train: loss: 0.1696884
[Epoch 35; Iter   720/  960] train: loss: 0.0690245
[Epoch 35; Iter   750/  960] train: loss: 0.3132333
[Epoch 35; Iter   780/  960] train: loss: 0.0151356
[Epoch 35; Iter   810/  960] train: loss: 0.0529904
[Epoch 35; Iter   840/  960] train: loss: 0.1155744
[Epoch 35; Iter   870/  960] train: loss: 0.0961401
[Epoch 35; Iter   900/  960] train: loss: 0.0394694
[Epoch 35; Iter   930/  960] train: loss: 0.0194851
[Epoch 35; Iter   960/  960] train: loss: 0.1783429
[Epoch 35] ogbg-molhiv: 0.769457 val loss: 0.596081
[Epoch 35] ogbg-molhiv: 0.766585 test loss: 0.435824
[Epoch 36; Iter    30/  960] train: loss: 0.0499784
[Epoch 36; Iter    60/  960] train: loss: 0.1862346
[Epoch 36; Iter    90/  960] train: loss: 0.0164822
[Epoch 36; Iter   120/  960] train: loss: 0.0462190
[Epoch 36; Iter   150/  960] train: loss: 0.0302076
[Epoch 36; Iter   180/  960] train: loss: 0.0152231
[Epoch 36; Iter   210/  960] train: loss: 0.0088007
[Epoch 36; Iter   240/  960] train: loss: 0.1353830
[Epoch 36; Iter   270/  960] train: loss: 0.0138721
[Epoch 36; Iter   300/  960] train: loss: 0.0297939
[Epoch 36; Iter   330/  960] train: loss: 0.0262924
[Epoch 36; Iter   360/  960] train: loss: 0.0133257
[Epoch 36; Iter   390/  960] train: loss: 0.0418363
[Epoch 36; Iter   420/  960] train: loss: 0.0473417
[Epoch 36; Iter   450/  960] train: loss: 0.0274827
[Epoch 36; Iter   480/  960] train: loss: 0.1170138
[Epoch 36; Iter   510/  960] train: loss: 0.1146187
[Epoch 36; Iter   540/  960] train: loss: 0.0333164
[Epoch 36; Iter   570/  960] train: loss: 0.0449066
[Epoch 36; Iter   600/  960] train: loss: 0.0184080
[Epoch 36; Iter   630/  960] train: loss: 0.0109098
[Epoch 36; Iter   660/  960] train: loss: 0.2009749
[Epoch 36; Iter   690/  960] train: loss: 0.0506482
[Epoch 32; Iter    90/  960] train: loss: 0.1301681
[Epoch 32; Iter   120/  960] train: loss: 0.2106752
[Epoch 32; Iter   150/  960] train: loss: 0.2140049
[Epoch 32; Iter   180/  960] train: loss: 0.0191354
[Epoch 32; Iter   210/  960] train: loss: 0.1812819
[Epoch 32; Iter   240/  960] train: loss: 0.0194100
[Epoch 32; Iter   270/  960] train: loss: 0.0126942
[Epoch 32; Iter   300/  960] train: loss: 0.0564226
[Epoch 32; Iter   330/  960] train: loss: 0.2746325
[Epoch 32; Iter   360/  960] train: loss: 0.0180992
[Epoch 32; Iter   390/  960] train: loss: 0.0928162
[Epoch 32; Iter   420/  960] train: loss: 0.0148364
[Epoch 32; Iter   450/  960] train: loss: 0.0125240
[Epoch 32; Iter   480/  960] train: loss: 0.0150328
[Epoch 32; Iter   510/  960] train: loss: 0.0369626
[Epoch 32; Iter   540/  960] train: loss: 0.0110840
[Epoch 32; Iter   570/  960] train: loss: 0.1196152
[Epoch 32; Iter   600/  960] train: loss: 0.1270143
[Epoch 32; Iter   630/  960] train: loss: 0.0108689
[Epoch 32; Iter   660/  960] train: loss: 0.0135558
[Epoch 32; Iter   690/  960] train: loss: 0.1883488
[Epoch 32; Iter   720/  960] train: loss: 0.0106131
[Epoch 32; Iter   750/  960] train: loss: 0.0262903
[Epoch 32; Iter   780/  960] train: loss: 0.0278457
[Epoch 32; Iter   810/  960] train: loss: 0.0503712
[Epoch 32; Iter   840/  960] train: loss: 0.0360582
[Epoch 32; Iter   870/  960] train: loss: 0.1008928
[Epoch 32; Iter   900/  960] train: loss: 0.0293737
[Epoch 32; Iter   930/  960] train: loss: 0.0363309
[Epoch 32; Iter   960/  960] train: loss: 0.0195623
[Epoch 32] ogbg-molhiv: 0.741655 val loss: 0.342555
[Epoch 32] ogbg-molhiv: 0.749456 test loss: 0.232320
[Epoch 33; Iter    30/  960] train: loss: 0.1134768
[Epoch 33; Iter    60/  960] train: loss: 0.0791586
[Epoch 33; Iter    90/  960] train: loss: 0.0653696
[Epoch 33; Iter   120/  960] train: loss: 0.0638089
[Epoch 33; Iter   150/  960] train: loss: 0.1825819
[Epoch 33; Iter   180/  960] train: loss: 0.0563033
[Epoch 33; Iter   210/  960] train: loss: 0.0131990
[Epoch 33; Iter   240/  960] train: loss: 0.0362881
[Epoch 33; Iter   270/  960] train: loss: 0.0255507
[Epoch 33; Iter   300/  960] train: loss: 0.0266823
[Epoch 33; Iter   330/  960] train: loss: 0.0134344
[Epoch 33; Iter   360/  960] train: loss: 0.0128837
[Epoch 33; Iter   390/  960] train: loss: 0.0793500
[Epoch 33; Iter   420/  960] train: loss: 0.2917549
[Epoch 33; Iter   450/  960] train: loss: 0.0309196
[Epoch 33; Iter   480/  960] train: loss: 0.0991008
[Epoch 33; Iter   510/  960] train: loss: 0.0208618
[Epoch 33; Iter   540/  960] train: loss: 0.1156971
[Epoch 33; Iter   570/  960] train: loss: 0.0165137
[Epoch 33; Iter   600/  960] train: loss: 0.0423479
[Epoch 33; Iter   630/  960] train: loss: 0.1644420
[Epoch 33; Iter   660/  960] train: loss: 0.0185359
[Epoch 33; Iter   690/  960] train: loss: 0.1290661
[Epoch 33; Iter   720/  960] train: loss: 0.1644681
[Epoch 33; Iter   750/  960] train: loss: 0.0886901
[Epoch 33; Iter   780/  960] train: loss: 0.1736993
[Epoch 33; Iter   810/  960] train: loss: 0.0460444
[Epoch 33; Iter   840/  960] train: loss: 0.0257885
[Epoch 33; Iter   870/  960] train: loss: 0.2146083
[Epoch 33; Iter   900/  960] train: loss: 0.0145778
[Epoch 33; Iter   930/  960] train: loss: 0.0285502
[Epoch 33; Iter   960/  960] train: loss: 0.0224106
[Epoch 33] ogbg-molhiv: 0.762578 val loss: 1.983563
[Epoch 33] ogbg-molhiv: 0.763622 test loss: 0.294935
[Epoch 34; Iter    30/  960] train: loss: 0.1870565
[Epoch 34; Iter    60/  960] train: loss: 0.0184804
[Epoch 34; Iter    90/  960] train: loss: 0.0679367
[Epoch 34; Iter   120/  960] train: loss: 0.0152858
[Epoch 34; Iter   150/  960] train: loss: 0.0277422
[Epoch 34; Iter   180/  960] train: loss: 0.2502863
[Epoch 34; Iter   210/  960] train: loss: 0.1028598
[Epoch 34; Iter   240/  960] train: loss: 0.0099781
[Epoch 34; Iter   270/  960] train: loss: 0.0202346
[Epoch 34; Iter   300/  960] train: loss: 0.0234806
[Epoch 34; Iter   330/  960] train: loss: 0.1023530
[Epoch 34; Iter   360/  960] train: loss: 0.0202191
[Epoch 34; Iter   390/  960] train: loss: 0.1163965
[Epoch 34; Iter   420/  960] train: loss: 0.0882175
[Epoch 34; Iter   450/  960] train: loss: 0.1832063
[Epoch 34; Iter   480/  960] train: loss: 0.0184293
[Epoch 34; Iter   510/  960] train: loss: 0.2298983
[Epoch 34; Iter   540/  960] train: loss: 0.0196266
[Epoch 34; Iter   570/  960] train: loss: 0.0553708
[Epoch 34; Iter   600/  960] train: loss: 0.0743454
[Epoch 34; Iter   630/  960] train: loss: 0.1561492
[Epoch 34; Iter   660/  960] train: loss: 0.1298789
[Epoch 34; Iter   690/  960] train: loss: 0.0156097
[Epoch 34; Iter   720/  960] train: loss: 0.0171169
[Epoch 34; Iter   750/  960] train: loss: 0.1184420
[Epoch 34; Iter   780/  960] train: loss: 0.0203578
[Epoch 34; Iter   810/  960] train: loss: 0.0525121
[Epoch 34; Iter   840/  960] train: loss: 0.0371565
[Epoch 34; Iter   870/  960] train: loss: 0.0381976
[Epoch 34; Iter   900/  960] train: loss: 0.1863277
[Epoch 34; Iter   930/  960] train: loss: 0.0616130
[Epoch 34; Iter   960/  960] train: loss: 0.0137339
[Epoch 34] ogbg-molhiv: 0.750256 val loss: 0.313629
[Epoch 34] ogbg-molhiv: 0.750978 test loss: 0.178843
[Epoch 35; Iter    30/  960] train: loss: 0.0242983
[Epoch 35; Iter    60/  960] train: loss: 0.0621488
[Epoch 35; Iter    90/  960] train: loss: 0.0989784
[Epoch 35; Iter   120/  960] train: loss: 0.0860077
[Epoch 35; Iter   150/  960] train: loss: 0.1661025
[Epoch 35; Iter   180/  960] train: loss: 0.0135998
[Epoch 35; Iter   210/  960] train: loss: 0.0194719
[Epoch 35; Iter   240/  960] train: loss: 0.0220494
[Epoch 35; Iter   270/  960] train: loss: 0.2704412
[Epoch 35; Iter   300/  960] train: loss: 0.0280327
[Epoch 35; Iter   330/  960] train: loss: 0.1910399
[Epoch 35; Iter   360/  960] train: loss: 0.0714636
[Epoch 35; Iter   390/  960] train: loss: 0.0358359
[Epoch 35; Iter   420/  960] train: loss: 0.0341788
[Epoch 35; Iter   450/  960] train: loss: 0.0207967
[Epoch 35; Iter   480/  960] train: loss: 0.0128749
[Epoch 35; Iter   510/  960] train: loss: 0.0437318
[Epoch 35; Iter   540/  960] train: loss: 0.0613709
[Epoch 35; Iter   570/  960] train: loss: 0.3906733
[Epoch 35; Iter   600/  960] train: loss: 0.1594288
[Epoch 35; Iter   630/  960] train: loss: 0.0196408
[Epoch 35; Iter   660/  960] train: loss: 0.1788395
[Epoch 35; Iter   690/  960] train: loss: 0.0218459
[Epoch 35; Iter   720/  960] train: loss: 0.0317528
[Epoch 35; Iter   750/  960] train: loss: 0.1433073
[Epoch 35; Iter   780/  960] train: loss: 0.0579093
[Epoch 35; Iter   810/  960] train: loss: 0.0238365
[Epoch 35; Iter   840/  960] train: loss: 0.0112612
[Epoch 35; Iter   870/  960] train: loss: 0.0511772
[Epoch 35; Iter   900/  960] train: loss: 0.0320274
[Epoch 35; Iter   930/  960] train: loss: 0.1060963
[Epoch 35; Iter   960/  960] train: loss: 0.0132933
[Epoch 35] ogbg-molhiv: 0.751082 val loss: 0.262790
[Epoch 35] ogbg-molhiv: 0.763466 test loss: 0.216805
[Epoch 36; Iter    30/  960] train: loss: 0.0091654
[Epoch 36; Iter    60/  960] train: loss: 0.1136201
[Epoch 36; Iter    90/  960] train: loss: 0.0459739
[Epoch 36; Iter   120/  960] train: loss: 0.0130748
[Epoch 36; Iter   150/  960] train: loss: 0.1112899
[Epoch 36; Iter   180/  960] train: loss: 0.0270527
[Epoch 36; Iter   210/  960] train: loss: 0.0204051
[Epoch 36; Iter   240/  960] train: loss: 0.0116217
[Epoch 36; Iter   270/  960] train: loss: 0.0910141
[Epoch 36; Iter   300/  960] train: loss: 0.1881232
[Epoch 36; Iter   330/  960] train: loss: 0.2729962
[Epoch 36; Iter   360/  960] train: loss: 0.0221757
[Epoch 36; Iter   390/  960] train: loss: 0.0904893
[Epoch 36; Iter   420/  960] train: loss: 0.0296080
[Epoch 36; Iter   450/  960] train: loss: 0.1322507
[Epoch 36; Iter   480/  960] train: loss: 0.1312114
[Epoch 36; Iter   510/  960] train: loss: 0.1905912
[Epoch 36; Iter   540/  960] train: loss: 0.0399105
[Epoch 36; Iter   570/  960] train: loss: 0.0164209
[Epoch 36; Iter   600/  960] train: loss: 0.0468514
[Epoch 36; Iter   630/  960] train: loss: 0.0775063
[Epoch 36; Iter   660/  960] train: loss: 0.0094775
[Epoch 36; Iter   690/  960] train: loss: 0.1747186
[Epoch 32; Iter    90/  960] train: loss: 0.0780034
[Epoch 32; Iter   120/  960] train: loss: 0.0979033
[Epoch 32; Iter   150/  960] train: loss: 0.0235034
[Epoch 32; Iter   180/  960] train: loss: 0.1304199
[Epoch 32; Iter   210/  960] train: loss: 0.0212189
[Epoch 32; Iter   240/  960] train: loss: 0.2057233
[Epoch 32; Iter   270/  960] train: loss: 0.0190355
[Epoch 32; Iter   300/  960] train: loss: 0.3129279
[Epoch 32; Iter   330/  960] train: loss: 0.0162030
[Epoch 32; Iter   360/  960] train: loss: 0.0824843
[Epoch 32; Iter   390/  960] train: loss: 0.1068788
[Epoch 32; Iter   420/  960] train: loss: 0.1275708
[Epoch 32; Iter   450/  960] train: loss: 0.1028426
[Epoch 32; Iter   480/  960] train: loss: 0.0164979
[Epoch 32; Iter   510/  960] train: loss: 0.0247619
[Epoch 32; Iter   540/  960] train: loss: 0.1224674
[Epoch 32; Iter   570/  960] train: loss: 0.0788631
[Epoch 32; Iter   600/  960] train: loss: 0.0211438
[Epoch 32; Iter   630/  960] train: loss: 0.0270423
[Epoch 32; Iter   660/  960] train: loss: 0.0369641
[Epoch 32; Iter   690/  960] train: loss: 0.0364507
[Epoch 32; Iter   720/  960] train: loss: 0.0744563
[Epoch 32; Iter   750/  960] train: loss: 0.1038445
[Epoch 32; Iter   780/  960] train: loss: 0.0408976
[Epoch 32; Iter   810/  960] train: loss: 0.0182247
[Epoch 32; Iter   840/  960] train: loss: 0.1141104
[Epoch 32; Iter   870/  960] train: loss: 0.3140673
[Epoch 32; Iter   900/  960] train: loss: 0.2067932
[Epoch 32; Iter   930/  960] train: loss: 0.1948136
[Epoch 32; Iter   960/  960] train: loss: 0.0122030
[Epoch 32] ogbg-molhiv: 0.737382 val loss: 0.136751
[Epoch 32] ogbg-molhiv: 0.769488 test loss: 0.112290
[Epoch 33; Iter    30/  960] train: loss: 0.0153870
[Epoch 33; Iter    60/  960] train: loss: 0.0726048
[Epoch 33; Iter    90/  960] train: loss: 0.0935835
[Epoch 33; Iter   120/  960] train: loss: 0.0336956
[Epoch 33; Iter   150/  960] train: loss: 0.0984965
[Epoch 33; Iter   180/  960] train: loss: 0.2208199
[Epoch 33; Iter   210/  960] train: loss: 0.0218650
[Epoch 33; Iter   240/  960] train: loss: 0.0173182
[Epoch 33; Iter   270/  960] train: loss: 0.0442814
[Epoch 33; Iter   300/  960] train: loss: 0.0578278
[Epoch 33; Iter   330/  960] train: loss: 0.0319717
[Epoch 33; Iter   360/  960] train: loss: 0.0298178
[Epoch 33; Iter   390/  960] train: loss: 0.0640706
[Epoch 33; Iter   420/  960] train: loss: 0.0193309
[Epoch 33; Iter   450/  960] train: loss: 0.0258237
[Epoch 33; Iter   480/  960] train: loss: 0.1863046
[Epoch 33; Iter   510/  960] train: loss: 0.0234770
[Epoch 33; Iter   540/  960] train: loss: 0.0198502
[Epoch 33; Iter   570/  960] train: loss: 0.0135316
[Epoch 33; Iter   600/  960] train: loss: 0.0131654
[Epoch 33; Iter   630/  960] train: loss: 0.0715173
[Epoch 33; Iter   660/  960] train: loss: 0.0281470
[Epoch 33; Iter   690/  960] train: loss: 0.0600102
[Epoch 33; Iter   720/  960] train: loss: 0.0166185
[Epoch 33; Iter   750/  960] train: loss: 0.2774262
[Epoch 33; Iter   780/  960] train: loss: 0.0173997
[Epoch 33; Iter   810/  960] train: loss: 0.2047937
[Epoch 33; Iter   840/  960] train: loss: 0.0577212
[Epoch 33; Iter   870/  960] train: loss: 0.2647601
[Epoch 33; Iter   900/  960] train: loss: 0.0222015
[Epoch 33; Iter   930/  960] train: loss: 0.1463529
[Epoch 33; Iter   960/  960] train: loss: 0.0454593
[Epoch 33] ogbg-molhiv: 0.742126 val loss: 0.157191
[Epoch 33] ogbg-molhiv: 0.787330 test loss: 0.159400
[Epoch 34; Iter    30/  960] train: loss: 0.0119000
[Epoch 34; Iter    60/  960] train: loss: 0.0840822
[Epoch 34; Iter    90/  960] train: loss: 0.0275165
[Epoch 34; Iter   120/  960] train: loss: 0.0305259
[Epoch 34; Iter   150/  960] train: loss: 0.0275261
[Epoch 34; Iter   180/  960] train: loss: 0.0503540
[Epoch 34; Iter   210/  960] train: loss: 0.1244727
[Epoch 34; Iter   240/  960] train: loss: 0.0434188
[Epoch 34; Iter   270/  960] train: loss: 0.0079441
[Epoch 34; Iter   300/  960] train: loss: 0.0241788
[Epoch 34; Iter   330/  960] train: loss: 0.1224665
[Epoch 34; Iter   360/  960] train: loss: 0.0887312
[Epoch 34; Iter   390/  960] train: loss: 0.0260084
[Epoch 34; Iter   420/  960] train: loss: 0.0157389
[Epoch 34; Iter   450/  960] train: loss: 0.1650082
[Epoch 34; Iter   480/  960] train: loss: 0.0935813
[Epoch 34; Iter   510/  960] train: loss: 0.0238661
[Epoch 34; Iter   540/  960] train: loss: 0.3279254
[Epoch 34; Iter   570/  960] train: loss: 0.0152681
[Epoch 34; Iter   600/  960] train: loss: 0.0086745
[Epoch 34; Iter   630/  960] train: loss: 0.1315096
[Epoch 34; Iter   660/  960] train: loss: 0.0327050
[Epoch 34; Iter   690/  960] train: loss: 0.3269081
[Epoch 34; Iter   720/  960] train: loss: 0.0639398
[Epoch 34; Iter   750/  960] train: loss: 0.0655708
[Epoch 34; Iter   780/  960] train: loss: 0.0591946
[Epoch 34; Iter   810/  960] train: loss: 0.0300059
[Epoch 34; Iter   840/  960] train: loss: 0.0870260
[Epoch 34; Iter   870/  960] train: loss: 0.1478120
[Epoch 34; Iter   900/  960] train: loss: 0.0428542
[Epoch 34; Iter   930/  960] train: loss: 0.0433178
[Epoch 34; Iter   960/  960] train: loss: 0.0133272
[Epoch 34] ogbg-molhiv: 0.745288 val loss: 0.138074
[Epoch 34] ogbg-molhiv: 0.791517 test loss: 0.111317
[Epoch 35; Iter    30/  960] train: loss: 0.0310642
[Epoch 35; Iter    60/  960] train: loss: 0.0627044
[Epoch 35; Iter    90/  960] train: loss: 0.0321238
[Epoch 35; Iter   120/  960] train: loss: 0.2248683
[Epoch 35; Iter   150/  960] train: loss: 0.0866819
[Epoch 35; Iter   180/  960] train: loss: 0.0318516
[Epoch 35; Iter   210/  960] train: loss: 0.0379296
[Epoch 35; Iter   240/  960] train: loss: 0.0955209
[Epoch 35; Iter   270/  960] train: loss: 0.0155373
[Epoch 35; Iter   300/  960] train: loss: 0.0099788
[Epoch 35; Iter   330/  960] train: loss: 0.0863781
[Epoch 35; Iter   360/  960] train: loss: 0.0597072
[Epoch 35; Iter   390/  960] train: loss: 0.0424136
[Epoch 35; Iter   420/  960] train: loss: 0.0563579
[Epoch 35; Iter   450/  960] train: loss: 0.1203143
[Epoch 35; Iter   480/  960] train: loss: 0.3215075
[Epoch 35; Iter   510/  960] train: loss: 0.0273992
[Epoch 35; Iter   540/  960] train: loss: 0.0281017
[Epoch 35; Iter   570/  960] train: loss: 0.0865220
[Epoch 35; Iter   600/  960] train: loss: 0.0479677
[Epoch 35; Iter   630/  960] train: loss: 0.0142922
[Epoch 35; Iter   660/  960] train: loss: 0.0265884
[Epoch 35; Iter   690/  960] train: loss: 0.0453682
[Epoch 35; Iter   720/  960] train: loss: 0.4669282
[Epoch 35; Iter   750/  960] train: loss: 0.0242168
[Epoch 35; Iter   780/  960] train: loss: 0.0221941
[Epoch 35; Iter   810/  960] train: loss: 0.0547739
[Epoch 35; Iter   840/  960] train: loss: 0.0169168
[Epoch 35; Iter   870/  960] train: loss: 0.0138442
[Epoch 35; Iter   900/  960] train: loss: 0.0879581
[Epoch 35; Iter   930/  960] train: loss: 0.0220831
[Epoch 35; Iter   960/  960] train: loss: 0.0068472
[Epoch 35] ogbg-molhiv: 0.743271 val loss: 0.136263
[Epoch 35] ogbg-molhiv: 0.785479 test loss: 0.107598
[Epoch 36; Iter    30/  960] train: loss: 0.0189419
[Epoch 36; Iter    60/  960] train: loss: 0.0673831
[Epoch 36; Iter    90/  960] train: loss: 0.1522191
[Epoch 36; Iter   120/  960] train: loss: 0.1738678
[Epoch 36; Iter   150/  960] train: loss: 0.0421998
[Epoch 36; Iter   180/  960] train: loss: 0.1924517
[Epoch 36; Iter   210/  960] train: loss: 0.0208006
[Epoch 36; Iter   240/  960] train: loss: 0.0255885
[Epoch 36; Iter   270/  960] train: loss: 0.0276576
[Epoch 36; Iter   300/  960] train: loss: 0.0324431
[Epoch 36; Iter   330/  960] train: loss: 0.0151525
[Epoch 36; Iter   360/  960] train: loss: 0.5219598
[Epoch 36; Iter   390/  960] train: loss: 0.0306752
[Epoch 36; Iter   420/  960] train: loss: 0.0460091
[Epoch 36; Iter   450/  960] train: loss: 0.0226184
[Epoch 36; Iter   480/  960] train: loss: 0.1049054
[Epoch 36; Iter   510/  960] train: loss: 0.0132798
[Epoch 36; Iter   540/  960] train: loss: 0.1684128
[Epoch 36; Iter   570/  960] train: loss: 0.0086493
[Epoch 36; Iter   600/  960] train: loss: 0.0931957
[Epoch 36; Iter   630/  960] train: loss: 0.0096175
[Epoch 36; Iter   660/  960] train: loss: 0.0250008
[Epoch 36; Iter   690/  960] train: loss: 0.1034551
[Epoch 32; Iter   553/ 1097] train: loss: 0.0779147
[Epoch 32; Iter   583/ 1097] train: loss: 0.0520319
[Epoch 32; Iter   613/ 1097] train: loss: 0.2988488
[Epoch 32; Iter   643/ 1097] train: loss: 0.0206768
[Epoch 32; Iter   673/ 1097] train: loss: 0.0256658
[Epoch 32; Iter   703/ 1097] train: loss: 0.1099292
[Epoch 32; Iter   733/ 1097] train: loss: 0.0229656
[Epoch 32; Iter   763/ 1097] train: loss: 0.0248731
[Epoch 32; Iter   793/ 1097] train: loss: 0.1821240
[Epoch 32; Iter   823/ 1097] train: loss: 0.1490050
[Epoch 32; Iter   853/ 1097] train: loss: 0.0510058
[Epoch 32; Iter   883/ 1097] train: loss: 0.0342914
[Epoch 32; Iter   913/ 1097] train: loss: 0.1077473
[Epoch 32; Iter   943/ 1097] train: loss: 0.0519802
[Epoch 32; Iter   973/ 1097] train: loss: 0.0506155
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0234281
[Epoch 32; Iter  1033/ 1097] train: loss: 0.2057422
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1009328
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0190308
[Epoch 32] ogbg-molhiv: 0.795026 val loss: 0.254775
[Epoch 32] ogbg-molhiv: 0.763763 test loss: 0.230751
[Epoch 33; Iter    26/ 1097] train: loss: 0.0553106
[Epoch 33; Iter    56/ 1097] train: loss: 0.1217571
[Epoch 33; Iter    86/ 1097] train: loss: 0.0167172
[Epoch 33; Iter   116/ 1097] train: loss: 0.0741782
[Epoch 33; Iter   146/ 1097] train: loss: 0.0338086
[Epoch 33; Iter   176/ 1097] train: loss: 0.0868917
[Epoch 33; Iter   206/ 1097] train: loss: 0.1992855
[Epoch 33; Iter   236/ 1097] train: loss: 0.0188178
[Epoch 33; Iter   266/ 1097] train: loss: 0.0928814
[Epoch 33; Iter   296/ 1097] train: loss: 0.0268640
[Epoch 33; Iter   326/ 1097] train: loss: 0.0557870
[Epoch 33; Iter   356/ 1097] train: loss: 0.0576513
[Epoch 33; Iter   386/ 1097] train: loss: 0.1946693
[Epoch 33; Iter   416/ 1097] train: loss: 0.2048893
[Epoch 33; Iter   446/ 1097] train: loss: 0.0412845
[Epoch 33; Iter   476/ 1097] train: loss: 0.1083695
[Epoch 33; Iter   506/ 1097] train: loss: 0.0457557
[Epoch 33; Iter   536/ 1097] train: loss: 0.0359351
[Epoch 33; Iter   566/ 1097] train: loss: 0.0221991
[Epoch 33; Iter   596/ 1097] train: loss: 0.0540564
[Epoch 33; Iter   626/ 1097] train: loss: 0.0180123
[Epoch 33; Iter   656/ 1097] train: loss: 0.2320588
[Epoch 33; Iter   686/ 1097] train: loss: 0.0197602
[Epoch 33; Iter   716/ 1097] train: loss: 0.0686514
[Epoch 33; Iter   746/ 1097] train: loss: 0.0384718
[Epoch 33; Iter   776/ 1097] train: loss: 0.0187789
[Epoch 33; Iter   806/ 1097] train: loss: 0.0294210
[Epoch 33; Iter   836/ 1097] train: loss: 0.0372469
[Epoch 33; Iter   866/ 1097] train: loss: 0.0611813
[Epoch 33; Iter   896/ 1097] train: loss: 0.0611642
[Epoch 33; Iter   926/ 1097] train: loss: 0.1232104
[Epoch 33; Iter   956/ 1097] train: loss: 0.0163845
[Epoch 33; Iter   986/ 1097] train: loss: 0.0989442
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0209675
[Epoch 33; Iter  1046/ 1097] train: loss: 0.1629909
[Epoch 33; Iter  1076/ 1097] train: loss: 0.0193417
[Epoch 33] ogbg-molhiv: 0.789826 val loss: 0.132653
[Epoch 33] ogbg-molhiv: 0.734348 test loss: 0.263225
[Epoch 34; Iter     9/ 1097] train: loss: 0.0243947
[Epoch 34; Iter    39/ 1097] train: loss: 0.0866866
[Epoch 34; Iter    69/ 1097] train: loss: 0.0648462
[Epoch 34; Iter    99/ 1097] train: loss: 0.0266789
[Epoch 34; Iter   129/ 1097] train: loss: 0.3138874
[Epoch 34; Iter   159/ 1097] train: loss: 0.0171296
[Epoch 34; Iter   189/ 1097] train: loss: 0.0574869
[Epoch 34; Iter   219/ 1097] train: loss: 0.1654374
[Epoch 34; Iter   249/ 1097] train: loss: 0.0367804
[Epoch 34; Iter   279/ 1097] train: loss: 0.3562710
[Epoch 34; Iter   309/ 1097] train: loss: 0.0307602
[Epoch 34; Iter   339/ 1097] train: loss: 0.0965658
[Epoch 34; Iter   369/ 1097] train: loss: 0.0256630
[Epoch 34; Iter   399/ 1097] train: loss: 0.0320429
[Epoch 34; Iter   429/ 1097] train: loss: 0.0375530
[Epoch 34; Iter   459/ 1097] train: loss: 0.1247377
[Epoch 34; Iter   489/ 1097] train: loss: 0.0228900
[Epoch 34; Iter   519/ 1097] train: loss: 0.0151044
[Epoch 34; Iter   549/ 1097] train: loss: 0.2838529
[Epoch 34; Iter   579/ 1097] train: loss: 0.0192915
[Epoch 34; Iter   609/ 1097] train: loss: 0.0590856
[Epoch 34; Iter   639/ 1097] train: loss: 0.0332483
[Epoch 34; Iter   669/ 1097] train: loss: 0.0499101
[Epoch 34; Iter   699/ 1097] train: loss: 0.1845695
[Epoch 34; Iter   729/ 1097] train: loss: 0.2643612
[Epoch 34; Iter   759/ 1097] train: loss: 0.0707970
[Epoch 34; Iter   789/ 1097] train: loss: 0.0282494
[Epoch 34; Iter   819/ 1097] train: loss: 0.1475062
[Epoch 34; Iter   849/ 1097] train: loss: 0.0144995
[Epoch 34; Iter   879/ 1097] train: loss: 0.0712886
[Epoch 34; Iter   909/ 1097] train: loss: 0.0273236
[Epoch 34; Iter   939/ 1097] train: loss: 0.0380747
[Epoch 34; Iter   969/ 1097] train: loss: 0.0684701
[Epoch 34; Iter   999/ 1097] train: loss: 0.0219553
[Epoch 34; Iter  1029/ 1097] train: loss: 0.1774746
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0148948
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0144807
[Epoch 34] ogbg-molhiv: 0.790041 val loss: 0.076819
[Epoch 34] ogbg-molhiv: 0.772164 test loss: 0.165326
[Epoch 35; Iter    22/ 1097] train: loss: 0.0203826
[Epoch 35; Iter    52/ 1097] train: loss: 0.0155111
[Epoch 35; Iter    82/ 1097] train: loss: 0.0388047
[Epoch 35; Iter   112/ 1097] train: loss: 0.1362960
[Epoch 35; Iter   142/ 1097] train: loss: 0.1370900
[Epoch 35; Iter   172/ 1097] train: loss: 0.0794817
[Epoch 35; Iter   202/ 1097] train: loss: 0.1523219
[Epoch 35; Iter   232/ 1097] train: loss: 0.4793644
[Epoch 35; Iter   262/ 1097] train: loss: 0.0868047
[Epoch 35; Iter   292/ 1097] train: loss: 0.1094955
[Epoch 35; Iter   322/ 1097] train: loss: 0.1199592
[Epoch 35; Iter   352/ 1097] train: loss: 0.0225870
[Epoch 35; Iter   382/ 1097] train: loss: 0.0188108
[Epoch 35; Iter   412/ 1097] train: loss: 0.0262676
[Epoch 35; Iter   442/ 1097] train: loss: 0.1280337
[Epoch 35; Iter   472/ 1097] train: loss: 0.0389975
[Epoch 35; Iter   502/ 1097] train: loss: 0.2622406
[Epoch 35; Iter   532/ 1097] train: loss: 0.0524155
[Epoch 35; Iter   562/ 1097] train: loss: 0.0375479
[Epoch 35; Iter   592/ 1097] train: loss: 0.0262900
[Epoch 35; Iter   622/ 1097] train: loss: 0.0601245
[Epoch 35; Iter   652/ 1097] train: loss: 0.0941693
[Epoch 35; Iter   682/ 1097] train: loss: 0.0714976
[Epoch 35; Iter   712/ 1097] train: loss: 0.1349741
[Epoch 35; Iter   742/ 1097] train: loss: 0.0936401
[Epoch 35; Iter   772/ 1097] train: loss: 0.0330746
[Epoch 35; Iter   802/ 1097] train: loss: 0.0335375
[Epoch 35; Iter   832/ 1097] train: loss: 0.0669115
[Epoch 35; Iter   862/ 1097] train: loss: 0.1716033
[Epoch 35; Iter   892/ 1097] train: loss: 0.0350457
[Epoch 35; Iter   922/ 1097] train: loss: 0.1680972
[Epoch 35; Iter   952/ 1097] train: loss: 0.0723229
[Epoch 35; Iter   982/ 1097] train: loss: 0.1860136
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0450499
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0177155
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0366560
[Epoch 35] ogbg-molhiv: 0.801704 val loss: 0.078223
[Epoch 35] ogbg-molhiv: 0.754592 test loss: 0.122824
[Epoch 36; Iter     5/ 1097] train: loss: 0.1617861
[Epoch 36; Iter    35/ 1097] train: loss: 0.0319950
[Epoch 36; Iter    65/ 1097] train: loss: 0.0488390
[Epoch 36; Iter    95/ 1097] train: loss: 0.2058340
[Epoch 36; Iter   125/ 1097] train: loss: 0.0507264
[Epoch 36; Iter   155/ 1097] train: loss: 0.0300526
[Epoch 36; Iter   185/ 1097] train: loss: 0.0356165
[Epoch 36; Iter   215/ 1097] train: loss: 0.4009408
[Epoch 36; Iter   245/ 1097] train: loss: 0.1235583
[Epoch 36; Iter   275/ 1097] train: loss: 0.0274868
[Epoch 36; Iter   305/ 1097] train: loss: 0.1821356
[Epoch 36; Iter   335/ 1097] train: loss: 0.1065081
[Epoch 36; Iter   365/ 1097] train: loss: 0.0361885
[Epoch 36; Iter   395/ 1097] train: loss: 0.0835270
[Epoch 36; Iter   425/ 1097] train: loss: 0.1570663
[Epoch 36; Iter   455/ 1097] train: loss: 0.2224831
[Epoch 36; Iter   485/ 1097] train: loss: 0.0279737
[Epoch 36; Iter   515/ 1097] train: loss: 0.0408242
[Epoch 36; Iter   545/ 1097] train: loss: 0.0418642
[Epoch 36; Iter   575/ 1097] train: loss: 0.0187576
[Epoch 36; Iter   605/ 1097] train: loss: 0.0182751
[Epoch 32; Iter   553/ 1097] train: loss: 0.0499926
[Epoch 32; Iter   583/ 1097] train: loss: 0.0486959
[Epoch 32; Iter   613/ 1097] train: loss: 0.0175733
[Epoch 32; Iter   643/ 1097] train: loss: 0.0202108
[Epoch 32; Iter   673/ 1097] train: loss: 0.3345773
[Epoch 32; Iter   703/ 1097] train: loss: 0.0256662
[Epoch 32; Iter   733/ 1097] train: loss: 0.0356609
[Epoch 32; Iter   763/ 1097] train: loss: 0.1080685
[Epoch 32; Iter   793/ 1097] train: loss: 0.0160174
[Epoch 32; Iter   823/ 1097] train: loss: 0.0591138
[Epoch 32; Iter   853/ 1097] train: loss: 0.0396423
[Epoch 32; Iter   883/ 1097] train: loss: 0.0324217
[Epoch 32; Iter   913/ 1097] train: loss: 0.1725264
[Epoch 32; Iter   943/ 1097] train: loss: 0.2039087
[Epoch 32; Iter   973/ 1097] train: loss: 0.0268435
[Epoch 32; Iter  1003/ 1097] train: loss: 0.0865279
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0249622
[Epoch 32; Iter  1063/ 1097] train: loss: 0.1760300
[Epoch 32; Iter  1093/ 1097] train: loss: 0.1204028
[Epoch 32] ogbg-molhiv: 0.814236 val loss: 0.843074
[Epoch 32] ogbg-molhiv: 0.735775 test loss: 0.979654
[Epoch 33; Iter    26/ 1097] train: loss: 0.0440595
[Epoch 33; Iter    56/ 1097] train: loss: 0.2203971
[Epoch 33; Iter    86/ 1097] train: loss: 0.0424055
[Epoch 33; Iter   116/ 1097] train: loss: 0.2654695
[Epoch 33; Iter   146/ 1097] train: loss: 0.0475084
[Epoch 33; Iter   176/ 1097] train: loss: 0.0178153
[Epoch 33; Iter   206/ 1097] train: loss: 0.0161450
[Epoch 33; Iter   236/ 1097] train: loss: 0.2374778
[Epoch 33; Iter   266/ 1097] train: loss: 0.0182340
[Epoch 33; Iter   296/ 1097] train: loss: 0.1784775
[Epoch 33; Iter   326/ 1097] train: loss: 0.2553917
[Epoch 33; Iter   356/ 1097] train: loss: 0.2923243
[Epoch 33; Iter   386/ 1097] train: loss: 0.0537270
[Epoch 33; Iter   416/ 1097] train: loss: 0.0721243
[Epoch 33; Iter   446/ 1097] train: loss: 0.0198855
[Epoch 33; Iter   476/ 1097] train: loss: 0.1534503
[Epoch 33; Iter   506/ 1097] train: loss: 0.1434242
[Epoch 33; Iter   536/ 1097] train: loss: 0.0212686
[Epoch 33; Iter   566/ 1097] train: loss: 0.0363847
[Epoch 33; Iter   596/ 1097] train: loss: 0.0545325
[Epoch 33; Iter   626/ 1097] train: loss: 0.0354813
[Epoch 33; Iter   656/ 1097] train: loss: 0.0294402
[Epoch 33; Iter   686/ 1097] train: loss: 0.0286212
[Epoch 33; Iter   716/ 1097] train: loss: 0.0295630
[Epoch 33; Iter   746/ 1097] train: loss: 0.0198209
[Epoch 33; Iter   776/ 1097] train: loss: 0.1639010
[Epoch 33; Iter   806/ 1097] train: loss: 0.1063739
[Epoch 33; Iter   836/ 1097] train: loss: 0.0381868
[Epoch 33; Iter   866/ 1097] train: loss: 0.0954198
[Epoch 33; Iter   896/ 1097] train: loss: 0.0712294
[Epoch 33; Iter   926/ 1097] train: loss: 0.0347891
[Epoch 33; Iter   956/ 1097] train: loss: 0.0156198
[Epoch 33; Iter   986/ 1097] train: loss: 0.0206602
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0277013
[Epoch 33; Iter  1046/ 1097] train: loss: 0.2451035
[Epoch 33; Iter  1076/ 1097] train: loss: 0.3179775
[Epoch 33] ogbg-molhiv: 0.809913 val loss: 0.218247
[Epoch 33] ogbg-molhiv: 0.738929 test loss: 0.225796
[Epoch 34; Iter     9/ 1097] train: loss: 0.0180481
[Epoch 34; Iter    39/ 1097] train: loss: 0.1655704
[Epoch 34; Iter    69/ 1097] train: loss: 0.0365786
[Epoch 34; Iter    99/ 1097] train: loss: 0.0358849
[Epoch 34; Iter   129/ 1097] train: loss: 0.1651353
[Epoch 34; Iter   159/ 1097] train: loss: 0.0227599
[Epoch 34; Iter   189/ 1097] train: loss: 0.1351760
[Epoch 34; Iter   219/ 1097] train: loss: 0.0189758
[Epoch 34; Iter   249/ 1097] train: loss: 0.0554104
[Epoch 34; Iter   279/ 1097] train: loss: 0.1393916
[Epoch 34; Iter   309/ 1097] train: loss: 0.0229885
[Epoch 34; Iter   339/ 1097] train: loss: 0.1960525
[Epoch 34; Iter   369/ 1097] train: loss: 0.2490610
[Epoch 34; Iter   399/ 1097] train: loss: 0.1564249
[Epoch 34; Iter   429/ 1097] train: loss: 0.0361518
[Epoch 34; Iter   459/ 1097] train: loss: 0.1072713
[Epoch 34; Iter   489/ 1097] train: loss: 0.0296823
[Epoch 34; Iter   519/ 1097] train: loss: 0.0174147
[Epoch 34; Iter   549/ 1097] train: loss: 0.0356797
[Epoch 34; Iter   579/ 1097] train: loss: 0.1131475
[Epoch 34; Iter   609/ 1097] train: loss: 0.0611637
[Epoch 34; Iter   639/ 1097] train: loss: 0.1535026
[Epoch 34; Iter   669/ 1097] train: loss: 0.0301768
[Epoch 34; Iter   699/ 1097] train: loss: 0.0436287
[Epoch 34; Iter   729/ 1097] train: loss: 0.4090362
[Epoch 34; Iter   759/ 1097] train: loss: 0.0421831
[Epoch 34; Iter   789/ 1097] train: loss: 0.0151953
[Epoch 34; Iter   819/ 1097] train: loss: 0.2217678
[Epoch 34; Iter   849/ 1097] train: loss: 0.0194217
[Epoch 34; Iter   879/ 1097] train: loss: 0.2041299
[Epoch 34; Iter   909/ 1097] train: loss: 0.0466599
[Epoch 34; Iter   939/ 1097] train: loss: 0.1080698
[Epoch 34; Iter   969/ 1097] train: loss: 0.0374031
[Epoch 34; Iter   999/ 1097] train: loss: 0.0225399
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0286404
[Epoch 34; Iter  1059/ 1097] train: loss: 0.0383841
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0162615
[Epoch 34] ogbg-molhiv: 0.797895 val loss: 0.421359
[Epoch 34] ogbg-molhiv: 0.737348 test loss: 0.819215
[Epoch 35; Iter    22/ 1097] train: loss: 0.0337083
[Epoch 35; Iter    52/ 1097] train: loss: 0.0786276
[Epoch 35; Iter    82/ 1097] train: loss: 0.1690146
[Epoch 35; Iter   112/ 1097] train: loss: 0.1621572
[Epoch 35; Iter   142/ 1097] train: loss: 0.0197639
[Epoch 35; Iter   172/ 1097] train: loss: 0.0365826
[Epoch 35; Iter   202/ 1097] train: loss: 0.0349757
[Epoch 35; Iter   232/ 1097] train: loss: 0.0743523
[Epoch 35; Iter   262/ 1097] train: loss: 0.0098144
[Epoch 35; Iter   292/ 1097] train: loss: 0.0156330
[Epoch 35; Iter   322/ 1097] train: loss: 0.1937278
[Epoch 35; Iter   352/ 1097] train: loss: 0.3267303
[Epoch 35; Iter   382/ 1097] train: loss: 0.2564136
[Epoch 35; Iter   412/ 1097] train: loss: 0.0724753
[Epoch 35; Iter   442/ 1097] train: loss: 0.0758542
[Epoch 35; Iter   472/ 1097] train: loss: 0.0266397
[Epoch 35; Iter   502/ 1097] train: loss: 0.0388201
[Epoch 35; Iter   532/ 1097] train: loss: 0.1968105
[Epoch 35; Iter   562/ 1097] train: loss: 0.1933540
[Epoch 35; Iter   592/ 1097] train: loss: 0.0416833
[Epoch 35; Iter   622/ 1097] train: loss: 0.2158146
[Epoch 35; Iter   652/ 1097] train: loss: 0.1386764
[Epoch 35; Iter   682/ 1097] train: loss: 0.0271256
[Epoch 35; Iter   712/ 1097] train: loss: 0.1507083
[Epoch 35; Iter   742/ 1097] train: loss: 0.1420578
[Epoch 35; Iter   772/ 1097] train: loss: 0.0709766
[Epoch 35; Iter   802/ 1097] train: loss: 0.0644220
[Epoch 35; Iter   832/ 1097] train: loss: 0.0733696
[Epoch 35; Iter   862/ 1097] train: loss: 0.0791661
[Epoch 35; Iter   892/ 1097] train: loss: 0.0221534
[Epoch 35; Iter   922/ 1097] train: loss: 0.0289721
[Epoch 35; Iter   952/ 1097] train: loss: 0.1105629
[Epoch 35; Iter   982/ 1097] train: loss: 0.1274244
[Epoch 35; Iter  1012/ 1097] train: loss: 0.1539416
[Epoch 35; Iter  1042/ 1097] train: loss: 0.1571165
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0229224
[Epoch 35] ogbg-molhiv: 0.810314 val loss: 0.102277
[Epoch 35] ogbg-molhiv: 0.731633 test loss: 0.311875
[Epoch 36; Iter     5/ 1097] train: loss: 0.0193120
[Epoch 36; Iter    35/ 1097] train: loss: 0.0241021
[Epoch 36; Iter    65/ 1097] train: loss: 0.0409514
[Epoch 36; Iter    95/ 1097] train: loss: 0.0234353
[Epoch 36; Iter   125/ 1097] train: loss: 0.2158387
[Epoch 36; Iter   155/ 1097] train: loss: 0.0539370
[Epoch 36; Iter   185/ 1097] train: loss: 0.0589123
[Epoch 36; Iter   215/ 1097] train: loss: 0.1432532
[Epoch 36; Iter   245/ 1097] train: loss: 0.0288774
[Epoch 36; Iter   275/ 1097] train: loss: 0.2197514
[Epoch 36; Iter   305/ 1097] train: loss: 0.2641646
[Epoch 36; Iter   335/ 1097] train: loss: 0.0252627
[Epoch 36; Iter   365/ 1097] train: loss: 0.1339642
[Epoch 36; Iter   395/ 1097] train: loss: 0.0201547
[Epoch 36; Iter   425/ 1097] train: loss: 0.0333401
[Epoch 36; Iter   455/ 1097] train: loss: 0.0313559
[Epoch 36; Iter   485/ 1097] train: loss: 0.0338108
[Epoch 36; Iter   515/ 1097] train: loss: 0.0851588
[Epoch 36; Iter   545/ 1097] train: loss: 0.1490049
[Epoch 36; Iter   575/ 1097] train: loss: 0.0307595
[Epoch 36; Iter   605/ 1097] train: loss: 0.1781403
[Epoch 32; Iter   553/ 1097] train: loss: 0.0168381
[Epoch 32; Iter   583/ 1097] train: loss: 0.2043046
[Epoch 32; Iter   613/ 1097] train: loss: 0.0198453
[Epoch 32; Iter   643/ 1097] train: loss: 0.2147056
[Epoch 32; Iter   673/ 1097] train: loss: 0.1827442
[Epoch 32; Iter   703/ 1097] train: loss: 0.1066634
[Epoch 32; Iter   733/ 1097] train: loss: 0.0295444
[Epoch 32; Iter   763/ 1097] train: loss: 0.0112931
[Epoch 32; Iter   793/ 1097] train: loss: 0.1905513
[Epoch 32; Iter   823/ 1097] train: loss: 0.0442658
[Epoch 32; Iter   853/ 1097] train: loss: 0.0572427
[Epoch 32; Iter   883/ 1097] train: loss: 0.0437505
[Epoch 32; Iter   913/ 1097] train: loss: 0.1817598
[Epoch 32; Iter   943/ 1097] train: loss: 0.0372190
[Epoch 32; Iter   973/ 1097] train: loss: 0.0242539
[Epoch 32; Iter  1003/ 1097] train: loss: 0.1015433
[Epoch 32; Iter  1033/ 1097] train: loss: 0.0948560
[Epoch 32; Iter  1063/ 1097] train: loss: 0.0477790
[Epoch 32; Iter  1093/ 1097] train: loss: 0.0192756
[Epoch 32] ogbg-molhiv: 0.818507 val loss: 0.083065
[Epoch 32] ogbg-molhiv: 0.751878 test loss: 0.172568
[Epoch 33; Iter    26/ 1097] train: loss: 0.1037921
[Epoch 33; Iter    56/ 1097] train: loss: 0.0465691
[Epoch 33; Iter    86/ 1097] train: loss: 0.0093359
[Epoch 33; Iter   116/ 1097] train: loss: 0.1297738
[Epoch 33; Iter   146/ 1097] train: loss: 0.0619529
[Epoch 33; Iter   176/ 1097] train: loss: 0.0147313
[Epoch 33; Iter   206/ 1097] train: loss: 0.0246958
[Epoch 33; Iter   236/ 1097] train: loss: 0.1360289
[Epoch 33; Iter   266/ 1097] train: loss: 0.0080520
[Epoch 33; Iter   296/ 1097] train: loss: 0.1520746
[Epoch 33; Iter   326/ 1097] train: loss: 0.0764058
[Epoch 33; Iter   356/ 1097] train: loss: 0.3569131
[Epoch 33; Iter   386/ 1097] train: loss: 0.0783070
[Epoch 33; Iter   416/ 1097] train: loss: 0.0111046
[Epoch 33; Iter   446/ 1097] train: loss: 0.0359020
[Epoch 33; Iter   476/ 1097] train: loss: 0.0792904
[Epoch 33; Iter   506/ 1097] train: loss: 0.0638466
[Epoch 33; Iter   536/ 1097] train: loss: 0.0580292
[Epoch 33; Iter   566/ 1097] train: loss: 0.0979532
[Epoch 33; Iter   596/ 1097] train: loss: 0.1315788
[Epoch 33; Iter   626/ 1097] train: loss: 0.2109134
[Epoch 33; Iter   656/ 1097] train: loss: 0.0099147
[Epoch 33; Iter   686/ 1097] train: loss: 0.0596195
[Epoch 33; Iter   716/ 1097] train: loss: 0.4725351
[Epoch 33; Iter   746/ 1097] train: loss: 0.1208873
[Epoch 33; Iter   776/ 1097] train: loss: 0.3429438
[Epoch 33; Iter   806/ 1097] train: loss: 0.0413770
[Epoch 33; Iter   836/ 1097] train: loss: 0.0492070
[Epoch 33; Iter   866/ 1097] train: loss: 0.0459456
[Epoch 33; Iter   896/ 1097] train: loss: 0.0198464
[Epoch 33; Iter   926/ 1097] train: loss: 0.0708423
[Epoch 33; Iter   956/ 1097] train: loss: 0.0245302
[Epoch 33; Iter   986/ 1097] train: loss: 0.2323832
[Epoch 33; Iter  1016/ 1097] train: loss: 0.0553076
[Epoch 33; Iter  1046/ 1097] train: loss: 0.0271839
[Epoch 33; Iter  1076/ 1097] train: loss: 0.2574719
[Epoch 33] ogbg-molhiv: 0.814444 val loss: 0.079117
[Epoch 33] ogbg-molhiv: 0.754497 test loss: 0.165012
[Epoch 34; Iter     9/ 1097] train: loss: 0.0445359
[Epoch 34; Iter    39/ 1097] train: loss: 0.0596819
[Epoch 34; Iter    69/ 1097] train: loss: 0.0407208
[Epoch 34; Iter    99/ 1097] train: loss: 0.1200538
[Epoch 34; Iter   129/ 1097] train: loss: 0.0194261
[Epoch 34; Iter   159/ 1097] train: loss: 0.0472628
[Epoch 34; Iter   189/ 1097] train: loss: 0.0182037
[Epoch 34; Iter   219/ 1097] train: loss: 0.1133327
[Epoch 34; Iter   249/ 1097] train: loss: 0.0564461
[Epoch 34; Iter   279/ 1097] train: loss: 0.1108390
[Epoch 34; Iter   309/ 1097] train: loss: 0.0575874
[Epoch 34; Iter   339/ 1097] train: loss: 0.0805324
[Epoch 34; Iter   369/ 1097] train: loss: 0.0553606
[Epoch 34; Iter   399/ 1097] train: loss: 0.0396632
[Epoch 34; Iter   429/ 1097] train: loss: 0.0321160
[Epoch 34; Iter   459/ 1097] train: loss: 0.0306283
[Epoch 34; Iter   489/ 1097] train: loss: 0.0546038
[Epoch 34; Iter   519/ 1097] train: loss: 0.0157837
[Epoch 34; Iter   549/ 1097] train: loss: 0.0091297
[Epoch 34; Iter   579/ 1097] train: loss: 0.1387412
[Epoch 34; Iter   609/ 1097] train: loss: 0.0367649
[Epoch 34; Iter   639/ 1097] train: loss: 0.1050822
[Epoch 34; Iter   669/ 1097] train: loss: 0.0487948
[Epoch 34; Iter   699/ 1097] train: loss: 0.1727240
[Epoch 34; Iter   729/ 1097] train: loss: 0.0127006
[Epoch 34; Iter   759/ 1097] train: loss: 0.4002478
[Epoch 34; Iter   789/ 1097] train: loss: 0.0096628
[Epoch 34; Iter   819/ 1097] train: loss: 0.0143558
[Epoch 34; Iter   849/ 1097] train: loss: 0.2278444
[Epoch 34; Iter   879/ 1097] train: loss: 0.0397421
[Epoch 34; Iter   909/ 1097] train: loss: 0.0412022
[Epoch 34; Iter   939/ 1097] train: loss: 0.0131656
[Epoch 34; Iter   969/ 1097] train: loss: 0.1352473
[Epoch 34; Iter   999/ 1097] train: loss: 0.0317527
[Epoch 34; Iter  1029/ 1097] train: loss: 0.0391247
[Epoch 34; Iter  1059/ 1097] train: loss: 0.1322522
[Epoch 34; Iter  1089/ 1097] train: loss: 0.0329448
[Epoch 34] ogbg-molhiv: 0.825336 val loss: 0.079417
[Epoch 34] ogbg-molhiv: 0.745793 test loss: 0.207080
[Epoch 35; Iter    22/ 1097] train: loss: 0.0152711
[Epoch 35; Iter    52/ 1097] train: loss: 0.0206399
[Epoch 35; Iter    82/ 1097] train: loss: 0.0977983
[Epoch 35; Iter   112/ 1097] train: loss: 0.1478560
[Epoch 35; Iter   142/ 1097] train: loss: 0.0133758
[Epoch 35; Iter   172/ 1097] train: loss: 0.0238353
[Epoch 35; Iter   202/ 1097] train: loss: 0.0296027
[Epoch 35; Iter   232/ 1097] train: loss: 0.0156245
[Epoch 35; Iter   262/ 1097] train: loss: 0.0845479
[Epoch 35; Iter   292/ 1097] train: loss: 0.0121051
[Epoch 35; Iter   322/ 1097] train: loss: 0.0182747
[Epoch 35; Iter   352/ 1097] train: loss: 0.0178436
[Epoch 35; Iter   382/ 1097] train: loss: 0.0148633
[Epoch 35; Iter   412/ 1097] train: loss: 0.0159729
[Epoch 35; Iter   442/ 1097] train: loss: 0.0947485
[Epoch 35; Iter   472/ 1097] train: loss: 0.0236804
[Epoch 35; Iter   502/ 1097] train: loss: 0.0222233
[Epoch 35; Iter   532/ 1097] train: loss: 0.0326154
[Epoch 35; Iter   562/ 1097] train: loss: 0.1881119
[Epoch 35; Iter   592/ 1097] train: loss: 0.0324601
[Epoch 35; Iter   622/ 1097] train: loss: 0.1756682
[Epoch 35; Iter   652/ 1097] train: loss: 0.0366506
[Epoch 35; Iter   682/ 1097] train: loss: 0.1958652
[Epoch 35; Iter   712/ 1097] train: loss: 0.1603533
[Epoch 35; Iter   742/ 1097] train: loss: 0.0198922
[Epoch 35; Iter   772/ 1097] train: loss: 0.1925818
[Epoch 35; Iter   802/ 1097] train: loss: 0.0175950
[Epoch 35; Iter   832/ 1097] train: loss: 0.0233026
[Epoch 35; Iter   862/ 1097] train: loss: 0.0437007
[Epoch 35; Iter   892/ 1097] train: loss: 0.2659454
[Epoch 35; Iter   922/ 1097] train: loss: 0.0117390
[Epoch 35; Iter   952/ 1097] train: loss: 0.0513219
[Epoch 35; Iter   982/ 1097] train: loss: 0.0156408
[Epoch 35; Iter  1012/ 1097] train: loss: 0.0245180
[Epoch 35; Iter  1042/ 1097] train: loss: 0.0127446
[Epoch 35; Iter  1072/ 1097] train: loss: 0.0221683
[Epoch 35] ogbg-molhiv: 0.804606 val loss: 0.503451
[Epoch 35] ogbg-molhiv: 0.763066 test loss: 1.015176
[Epoch 36; Iter     5/ 1097] train: loss: 0.0270298
[Epoch 36; Iter    35/ 1097] train: loss: 0.0398179
[Epoch 36; Iter    65/ 1097] train: loss: 0.0333457
[Epoch 36; Iter    95/ 1097] train: loss: 0.0708680
[Epoch 36; Iter   125/ 1097] train: loss: 0.0154347
[Epoch 36; Iter   155/ 1097] train: loss: 0.0329117
[Epoch 36; Iter   185/ 1097] train: loss: 0.0935713
[Epoch 36; Iter   215/ 1097] train: loss: 0.0278866
[Epoch 36; Iter   245/ 1097] train: loss: 0.2960336
[Epoch 36; Iter   275/ 1097] train: loss: 0.0379637
[Epoch 36; Iter   305/ 1097] train: loss: 0.0165208
[Epoch 36; Iter   335/ 1097] train: loss: 0.1329564
[Epoch 36; Iter   365/ 1097] train: loss: 0.2058199
[Epoch 36; Iter   395/ 1097] train: loss: 0.0126561
[Epoch 36; Iter   425/ 1097] train: loss: 0.0592173
[Epoch 36; Iter   455/ 1097] train: loss: 0.0291229
[Epoch 36; Iter   485/ 1097] train: loss: 0.0196664
[Epoch 36; Iter   515/ 1097] train: loss: 0.2944173
[Epoch 36; Iter   545/ 1097] train: loss: 0.1949914
[Epoch 36; Iter   575/ 1097] train: loss: 0.0734670
[Epoch 36; Iter   605/ 1097] train: loss: 0.0205597
[Epoch 36; Iter   775/  823] train: loss: 0.1173826
[Epoch 36; Iter   805/  823] train: loss: 0.0693233
[Epoch 36] ogbg-molhiv: 0.720861 val loss: 0.168444
[Epoch 36] ogbg-molhiv: 0.757271 test loss: 0.149306
[Epoch 37; Iter    12/  823] train: loss: 0.0182589
[Epoch 37; Iter    42/  823] train: loss: 0.0519215
[Epoch 37; Iter    72/  823] train: loss: 0.0539724
[Epoch 37; Iter   102/  823] train: loss: 0.0216064
[Epoch 37; Iter   132/  823] train: loss: 0.0897222
[Epoch 37; Iter   162/  823] train: loss: 0.0345026
[Epoch 37; Iter   192/  823] train: loss: 0.0541722
[Epoch 37; Iter   222/  823] train: loss: 0.0191539
[Epoch 37; Iter   252/  823] train: loss: 0.0501079
[Epoch 37; Iter   282/  823] train: loss: 0.1295136
[Epoch 37; Iter   312/  823] train: loss: 0.0129009
[Epoch 37; Iter   342/  823] train: loss: 0.1014510
[Epoch 37; Iter   372/  823] train: loss: 0.2226844
[Epoch 37; Iter   402/  823] train: loss: 0.1910205
[Epoch 37; Iter   432/  823] train: loss: 0.0243983
[Epoch 37; Iter   462/  823] train: loss: 0.1497320
[Epoch 37; Iter   492/  823] train: loss: 0.0380871
[Epoch 37; Iter   522/  823] train: loss: 0.1354762
[Epoch 37; Iter   552/  823] train: loss: 0.0220301
[Epoch 37; Iter   582/  823] train: loss: 0.0219562
[Epoch 37; Iter   612/  823] train: loss: 0.1403342
[Epoch 37; Iter   642/  823] train: loss: 0.1408953
[Epoch 37; Iter   672/  823] train: loss: 0.1510923
[Epoch 37; Iter   702/  823] train: loss: 0.0252943
[Epoch 37; Iter   732/  823] train: loss: 0.0807208
[Epoch 37; Iter   762/  823] train: loss: 0.0815358
[Epoch 37; Iter   792/  823] train: loss: 0.0282262
[Epoch 37; Iter   822/  823] train: loss: 0.0276930
[Epoch 37] ogbg-molhiv: 0.730703 val loss: 0.158984
[Epoch 37] ogbg-molhiv: 0.754159 test loss: 0.161006
[Epoch 38; Iter    29/  823] train: loss: 0.0224108
[Epoch 38; Iter    59/  823] train: loss: 0.2669295
[Epoch 38; Iter    89/  823] train: loss: 0.4012271
[Epoch 38; Iter   119/  823] train: loss: 0.2260197
[Epoch 38; Iter   149/  823] train: loss: 0.0458096
[Epoch 38; Iter   179/  823] train: loss: 0.2423248
[Epoch 38; Iter   209/  823] train: loss: 0.2431982
[Epoch 38; Iter   239/  823] train: loss: 0.0263663
[Epoch 38; Iter   269/  823] train: loss: 0.0184233
[Epoch 38; Iter   299/  823] train: loss: 0.2287173
[Epoch 38; Iter   329/  823] train: loss: 0.1417959
[Epoch 38; Iter   359/  823] train: loss: 0.0398508
[Epoch 38; Iter   389/  823] train: loss: 0.0484085
[Epoch 38; Iter   419/  823] train: loss: 0.0440598
[Epoch 38; Iter   449/  823] train: loss: 0.0421724
[Epoch 38; Iter   479/  823] train: loss: 0.0155662
[Epoch 38; Iter   509/  823] train: loss: 0.2967056
[Epoch 38; Iter   539/  823] train: loss: 0.0749802
[Epoch 38; Iter   569/  823] train: loss: 0.1091929
[Epoch 38; Iter   599/  823] train: loss: 0.0280724
[Epoch 38; Iter   629/  823] train: loss: 0.0370520
[Epoch 38; Iter   659/  823] train: loss: 0.0189864
[Epoch 38; Iter   689/  823] train: loss: 0.0185114
[Epoch 38; Iter   719/  823] train: loss: 0.1753903
[Epoch 38; Iter   749/  823] train: loss: 0.0172761
[Epoch 38; Iter   779/  823] train: loss: 0.0492998
[Epoch 38; Iter   809/  823] train: loss: 0.1749207
[Epoch 38] ogbg-molhiv: 0.723789 val loss: 0.153799
[Epoch 38] ogbg-molhiv: 0.763442 test loss: 0.185556
[Epoch 39; Iter    16/  823] train: loss: 0.0271840
[Epoch 39; Iter    46/  823] train: loss: 0.0815445
[Epoch 39; Iter    76/  823] train: loss: 0.0372568
[Epoch 39; Iter   106/  823] train: loss: 0.0211334
[Epoch 39; Iter   136/  823] train: loss: 0.0347804
[Epoch 39; Iter   166/  823] train: loss: 0.0811900
[Epoch 39; Iter   196/  823] train: loss: 0.0998079
[Epoch 39; Iter   226/  823] train: loss: 0.0208647
[Epoch 39; Iter   256/  823] train: loss: 0.2940984
[Epoch 39; Iter   286/  823] train: loss: 0.0136825
[Epoch 39; Iter   316/  823] train: loss: 0.2715005
[Epoch 39; Iter   346/  823] train: loss: 0.0898989
[Epoch 39; Iter   376/  823] train: loss: 0.0848143
[Epoch 39; Iter   406/  823] train: loss: 0.0886413
[Epoch 39; Iter   436/  823] train: loss: 0.0166607
[Epoch 39; Iter   466/  823] train: loss: 0.0143212
[Epoch 39; Iter   496/  823] train: loss: 0.1441313
[Epoch 39; Iter   526/  823] train: loss: 0.0300464
[Epoch 39; Iter   556/  823] train: loss: 0.0193838
[Epoch 39; Iter   586/  823] train: loss: 0.0802640
[Epoch 39; Iter   616/  823] train: loss: 0.1376687
[Epoch 39; Iter   646/  823] train: loss: 0.1816402
[Epoch 39; Iter   676/  823] train: loss: 0.1098935
[Epoch 39; Iter   706/  823] train: loss: 0.0289373
[Epoch 39; Iter   736/  823] train: loss: 0.0139404
[Epoch 39; Iter   766/  823] train: loss: 0.0200450
[Epoch 39; Iter   796/  823] train: loss: 0.0191168
[Epoch 39] ogbg-molhiv: 0.736224 val loss: 0.172878
[Epoch 39] ogbg-molhiv: 0.775227 test loss: 0.232451
[Epoch 40; Iter     3/  823] train: loss: 0.1281013
[Epoch 40; Iter    33/  823] train: loss: 0.0146841
[Epoch 40; Iter    63/  823] train: loss: 0.0187586
[Epoch 40; Iter    93/  823] train: loss: 0.0196168
[Epoch 40; Iter   123/  823] train: loss: 0.0160893
[Epoch 40; Iter   153/  823] train: loss: 0.0705536
[Epoch 40; Iter   183/  823] train: loss: 0.0515404
[Epoch 40; Iter   213/  823] train: loss: 0.0131401
[Epoch 40; Iter   243/  823] train: loss: 0.2759561
[Epoch 40; Iter   273/  823] train: loss: 0.1642554
[Epoch 40; Iter   303/  823] train: loss: 0.1471086
[Epoch 40; Iter   333/  823] train: loss: 0.0366277
[Epoch 40; Iter   363/  823] train: loss: 0.1046052
[Epoch 40; Iter   393/  823] train: loss: 0.1143867
[Epoch 40; Iter   423/  823] train: loss: 0.0190112
[Epoch 40; Iter   453/  823] train: loss: 0.1154873
[Epoch 40; Iter   483/  823] train: loss: 0.0145770
[Epoch 40; Iter   513/  823] train: loss: 0.0180177
[Epoch 40; Iter   543/  823] train: loss: 0.0157242
[Epoch 40; Iter   573/  823] train: loss: 0.0218767
[Epoch 40; Iter   603/  823] train: loss: 0.0909807
[Epoch 40; Iter   633/  823] train: loss: 0.0631912
[Epoch 40; Iter   663/  823] train: loss: 0.0313928
[Epoch 40; Iter   693/  823] train: loss: 0.1316259
[Epoch 40; Iter   723/  823] train: loss: 0.0492325
[Epoch 40; Iter   753/  823] train: loss: 0.1740617
[Epoch 40; Iter   783/  823] train: loss: 0.0786081
[Epoch 40; Iter   813/  823] train: loss: 0.1960476
[Epoch 40] ogbg-molhiv: 0.720409 val loss: 0.445351
[Epoch 40] ogbg-molhiv: 0.763896 test loss: 2.156015
[Epoch 41; Iter    20/  823] train: loss: 0.0229184
[Epoch 41; Iter    50/  823] train: loss: 0.0477937
[Epoch 41; Iter    80/  823] train: loss: 0.0287725
[Epoch 41; Iter   110/  823] train: loss: 0.0191679
[Epoch 41; Iter   140/  823] train: loss: 0.0301772
[Epoch 41; Iter   170/  823] train: loss: 0.0788932
[Epoch 41; Iter   200/  823] train: loss: 0.1967605
[Epoch 41; Iter   230/  823] train: loss: 0.0276835
[Epoch 41; Iter   260/  823] train: loss: 0.0402080
[Epoch 41; Iter   290/  823] train: loss: 0.0779240
[Epoch 41; Iter   320/  823] train: loss: 0.0120842
[Epoch 41; Iter   350/  823] train: loss: 0.2461913
[Epoch 41; Iter   380/  823] train: loss: 0.1255556
[Epoch 41; Iter   410/  823] train: loss: 0.0430617
[Epoch 41; Iter   440/  823] train: loss: 0.0308048
[Epoch 41; Iter   470/  823] train: loss: 0.0255204
[Epoch 41; Iter   500/  823] train: loss: 0.0084386
[Epoch 41; Iter   530/  823] train: loss: 0.2815132
[Epoch 41; Iter   560/  823] train: loss: 0.0324857
[Epoch 41; Iter   590/  823] train: loss: 0.0360030
[Epoch 41; Iter   620/  823] train: loss: 0.0289049
[Epoch 41; Iter   650/  823] train: loss: 0.1079330
[Epoch 41; Iter   680/  823] train: loss: 0.0313168
[Epoch 41; Iter   710/  823] train: loss: 0.0278168
[Epoch 41; Iter   740/  823] train: loss: 0.0160941
[Epoch 41; Iter   770/  823] train: loss: 0.1583216
[Epoch 41; Iter   800/  823] train: loss: 0.0323638
[Epoch 41] ogbg-molhiv: 0.716676 val loss: 0.216589
[Epoch 41] ogbg-molhiv: 0.767964 test loss: 1.045425
[Epoch 42; Iter     7/  823] train: loss: 0.0686397
[Epoch 42; Iter    37/  823] train: loss: 0.0098192
[Epoch 42; Iter    67/  823] train: loss: 0.0267943
[Epoch 42; Iter    97/  823] train: loss: 0.0204756
[Epoch 42; Iter   127/  823] train: loss: 0.0347997
[Epoch 42; Iter   157/  823] train: loss: 0.1436756
[Epoch 36; Iter   775/  823] train: loss: 0.0179321
[Epoch 36; Iter   805/  823] train: loss: 0.1195836
[Epoch 36] ogbg-molhiv: 0.711477 val loss: 0.164650
[Epoch 36] ogbg-molhiv: 0.746742 test loss: 0.119015
[Epoch 37; Iter    12/  823] train: loss: 0.1204935
[Epoch 37; Iter    42/  823] train: loss: 0.0206168
[Epoch 37; Iter    72/  823] train: loss: 0.0362760
[Epoch 37; Iter   102/  823] train: loss: 0.0460906
[Epoch 37; Iter   132/  823] train: loss: 0.2167656
[Epoch 37; Iter   162/  823] train: loss: 0.0174139
[Epoch 37; Iter   192/  823] train: loss: 0.1281362
[Epoch 37; Iter   222/  823] train: loss: 0.0726257
[Epoch 37; Iter   252/  823] train: loss: 0.1304217
[Epoch 37; Iter   282/  823] train: loss: 0.0048689
[Epoch 37; Iter   312/  823] train: loss: 0.1068652
[Epoch 37; Iter   342/  823] train: loss: 0.0442825
[Epoch 37; Iter   372/  823] train: loss: 0.0944827
[Epoch 37; Iter   402/  823] train: loss: 0.0745263
[Epoch 37; Iter   432/  823] train: loss: 0.2575727
[Epoch 37; Iter   462/  823] train: loss: 0.0228452
[Epoch 37; Iter   492/  823] train: loss: 0.0250549
[Epoch 37; Iter   522/  823] train: loss: 0.0282911
[Epoch 37; Iter   552/  823] train: loss: 0.0329242
[Epoch 37; Iter   582/  823] train: loss: 0.0118794
[Epoch 37; Iter   612/  823] train: loss: 0.0310244
[Epoch 37; Iter   642/  823] train: loss: 0.0125017
[Epoch 37; Iter   672/  823] train: loss: 0.2703175
[Epoch 37; Iter   702/  823] train: loss: 0.0123838
[Epoch 37; Iter   732/  823] train: loss: 0.0353297
[Epoch 37; Iter   762/  823] train: loss: 0.0335503
[Epoch 37; Iter   792/  823] train: loss: 0.1436656
[Epoch 37; Iter   822/  823] train: loss: 0.0923019
[Epoch 37] ogbg-molhiv: 0.736129 val loss: 0.159859
[Epoch 37] ogbg-molhiv: 0.749016 test loss: 0.115802
[Epoch 38; Iter    29/  823] train: loss: 0.0087955
[Epoch 38; Iter    59/  823] train: loss: 0.0403003
[Epoch 38; Iter    89/  823] train: loss: 0.0237678
[Epoch 38; Iter   119/  823] train: loss: 0.0263857
[Epoch 38; Iter   149/  823] train: loss: 0.3135591
[Epoch 38; Iter   179/  823] train: loss: 0.0158153
[Epoch 38; Iter   209/  823] train: loss: 0.0154731
[Epoch 38; Iter   239/  823] train: loss: 0.0344515
[Epoch 38; Iter   269/  823] train: loss: 0.0357033
[Epoch 38; Iter   299/  823] train: loss: 0.0496297
[Epoch 38; Iter   329/  823] train: loss: 0.0338684
[Epoch 38; Iter   359/  823] train: loss: 0.0526423
[Epoch 38; Iter   389/  823] train: loss: 0.1596101
[Epoch 38; Iter   419/  823] train: loss: 0.1207241
[Epoch 38; Iter   449/  823] train: loss: 0.0273466
[Epoch 38; Iter   479/  823] train: loss: 0.0296383
[Epoch 38; Iter   509/  823] train: loss: 0.1954896
[Epoch 38; Iter   539/  823] train: loss: 0.0265143
[Epoch 38; Iter   569/  823] train: loss: 0.0289145
[Epoch 38; Iter   599/  823] train: loss: 0.1575478
[Epoch 38; Iter   629/  823] train: loss: 0.0203413
[Epoch 38; Iter   659/  823] train: loss: 0.1078084
[Epoch 38; Iter   689/  823] train: loss: 0.1140212
[Epoch 38; Iter   719/  823] train: loss: 0.0320644
[Epoch 38; Iter   749/  823] train: loss: 0.0559885
[Epoch 38; Iter   779/  823] train: loss: 0.0250244
[Epoch 38; Iter   809/  823] train: loss: 0.0118604
[Epoch 38] ogbg-molhiv: 0.727719 val loss: 0.162604
[Epoch 38] ogbg-molhiv: 0.746520 test loss: 0.114178
[Epoch 39; Iter    16/  823] train: loss: 0.1185354
[Epoch 39; Iter    46/  823] train: loss: 0.0288943
[Epoch 39; Iter    76/  823] train: loss: 0.0793428
[Epoch 39; Iter   106/  823] train: loss: 0.0107184
[Epoch 39; Iter   136/  823] train: loss: 0.0261759
[Epoch 39; Iter   166/  823] train: loss: 0.0333801
[Epoch 39; Iter   196/  823] train: loss: 0.0631802
[Epoch 39; Iter   226/  823] train: loss: 0.0396910
[Epoch 39; Iter   256/  823] train: loss: 0.0255583
[Epoch 39; Iter   286/  823] train: loss: 0.0151809
[Epoch 39; Iter   316/  823] train: loss: 0.0678137
[Epoch 39; Iter   346/  823] train: loss: 0.1859106
[Epoch 39; Iter   376/  823] train: loss: 0.0489613
[Epoch 39; Iter   406/  823] train: loss: 0.1924972
[Epoch 39; Iter   436/  823] train: loss: 0.0282453
[Epoch 39; Iter   466/  823] train: loss: 0.0203185
[Epoch 39; Iter   496/  823] train: loss: 0.0107829
[Epoch 39; Iter   526/  823] train: loss: 0.0509556
[Epoch 39; Iter   556/  823] train: loss: 0.0469968
[Epoch 39; Iter   586/  823] train: loss: 0.0127310
[Epoch 39; Iter   616/  823] train: loss: 0.1923819
[Epoch 39; Iter   646/  823] train: loss: 0.1791691
[Epoch 39; Iter   676/  823] train: loss: 0.0906651
[Epoch 39; Iter   706/  823] train: loss: 0.1651482
[Epoch 39; Iter   736/  823] train: loss: 0.0184657
[Epoch 39; Iter   766/  823] train: loss: 0.0196107
[Epoch 39; Iter   796/  823] train: loss: 0.0128810
[Epoch 39] ogbg-molhiv: 0.729215 val loss: 0.165607
[Epoch 39] ogbg-molhiv: 0.758253 test loss: 0.111736
[Epoch 40; Iter     3/  823] train: loss: 0.1075549
[Epoch 40; Iter    33/  823] train: loss: 0.1688654
[Epoch 40; Iter    63/  823] train: loss: 0.0758174
[Epoch 40; Iter    93/  823] train: loss: 0.1179837
[Epoch 40; Iter   123/  823] train: loss: 0.0385451
[Epoch 40; Iter   153/  823] train: loss: 0.0821864
[Epoch 40; Iter   183/  823] train: loss: 0.0614607
[Epoch 40; Iter   213/  823] train: loss: 0.0255286
[Epoch 40; Iter   243/  823] train: loss: 0.0379335
[Epoch 40; Iter   273/  823] train: loss: 0.0241882
[Epoch 40; Iter   303/  823] train: loss: 0.0183104
[Epoch 40; Iter   333/  823] train: loss: 0.0561426
[Epoch 40; Iter   363/  823] train: loss: 0.0211707
[Epoch 40; Iter   393/  823] train: loss: 0.0154371
[Epoch 40; Iter   423/  823] train: loss: 0.1152837
[Epoch 40; Iter   453/  823] train: loss: 0.0531371
[Epoch 40; Iter   483/  823] train: loss: 0.1294851
[Epoch 40; Iter   513/  823] train: loss: 0.0342484
[Epoch 40; Iter   543/  823] train: loss: 0.0065578
[Epoch 40; Iter   573/  823] train: loss: 0.0735808
[Epoch 40; Iter   603/  823] train: loss: 0.0588774
[Epoch 40; Iter   633/  823] train: loss: 0.0128873
[Epoch 40; Iter   663/  823] train: loss: 0.1066370
[Epoch 40; Iter   693/  823] train: loss: 0.0241244
[Epoch 40; Iter   723/  823] train: loss: 0.0234276
[Epoch 40; Iter   753/  823] train: loss: 0.0146495
[Epoch 40; Iter   783/  823] train: loss: 0.0160556
[Epoch 40; Iter   813/  823] train: loss: 0.1113808
[Epoch 40] ogbg-molhiv: 0.731665 val loss: 0.177040
[Epoch 40] ogbg-molhiv: 0.742805 test loss: 0.120582
[Epoch 41; Iter    20/  823] train: loss: 0.0132127
[Epoch 41; Iter    50/  823] train: loss: 0.0138921
[Epoch 41; Iter    80/  823] train: loss: 0.2003758
[Epoch 41; Iter   110/  823] train: loss: 0.0086264
[Epoch 41; Iter   140/  823] train: loss: 0.0177803
[Epoch 41; Iter   170/  823] train: loss: 0.0217034
[Epoch 41; Iter   200/  823] train: loss: 0.0090089
[Epoch 41; Iter   230/  823] train: loss: 0.1556888
[Epoch 41; Iter   260/  823] train: loss: 0.0191097
[Epoch 41; Iter   290/  823] train: loss: 0.0234938
[Epoch 41; Iter   320/  823] train: loss: 0.0759280
[Epoch 41; Iter   350/  823] train: loss: 0.0427039
[Epoch 41; Iter   380/  823] train: loss: 0.0468870
[Epoch 41; Iter   410/  823] train: loss: 0.0110880
[Epoch 41; Iter   440/  823] train: loss: 0.0829561
[Epoch 41; Iter   470/  823] train: loss: 0.0087107
[Epoch 41; Iter   500/  823] train: loss: 0.1961876
[Epoch 41; Iter   530/  823] train: loss: 0.0432348
[Epoch 41; Iter   560/  823] train: loss: 0.1259396
[Epoch 41; Iter   590/  823] train: loss: 0.0622222
[Epoch 41; Iter   620/  823] train: loss: 0.0058637
[Epoch 41; Iter   650/  823] train: loss: 0.0485707
[Epoch 41; Iter   680/  823] train: loss: 0.0130318
[Epoch 41; Iter   710/  823] train: loss: 0.0197888
[Epoch 41; Iter   740/  823] train: loss: 0.0064630
[Epoch 41; Iter   770/  823] train: loss: 0.0311901
[Epoch 41; Iter   800/  823] train: loss: 0.0099742
[Epoch 41] ogbg-molhiv: 0.723658 val loss: 0.186186
[Epoch 41] ogbg-molhiv: 0.746333 test loss: 0.124138
[Epoch 42; Iter     7/  823] train: loss: 0.0715912
[Epoch 42; Iter    37/  823] train: loss: 0.0177099
[Epoch 42; Iter    67/  823] train: loss: 0.0833793
[Epoch 42; Iter    97/  823] train: loss: 0.0536866
[Epoch 42; Iter   127/  823] train: loss: 0.0310099
[Epoch 42; Iter   157/  823] train: loss: 0.0089317
[Epoch 36; Iter   720/  960] train: loss: 0.0750305
[Epoch 36; Iter   750/  960] train: loss: 0.0828601
[Epoch 36; Iter   780/  960] train: loss: 0.0200644
[Epoch 36; Iter   810/  960] train: loss: 0.0224854
[Epoch 36; Iter   840/  960] train: loss: 0.0261346
[Epoch 36; Iter   870/  960] train: loss: 0.0371389
[Epoch 36; Iter   900/  960] train: loss: 0.0132464
[Epoch 36; Iter   930/  960] train: loss: 0.1202039
[Epoch 36; Iter   960/  960] train: loss: 0.5792398
[Epoch 36] ogbg-molhiv: 0.758038 val loss: 0.162792
[Epoch 36] ogbg-molhiv: 0.759159 test loss: 0.120265
[Epoch 37; Iter    30/  960] train: loss: 0.0776088
[Epoch 37; Iter    60/  960] train: loss: 0.0607285
[Epoch 37; Iter    90/  960] train: loss: 0.0718317
[Epoch 37; Iter   120/  960] train: loss: 0.0830509
[Epoch 37; Iter   150/  960] train: loss: 0.0874366
[Epoch 37; Iter   180/  960] train: loss: 0.0602899
[Epoch 37; Iter   210/  960] train: loss: 0.0322356
[Epoch 37; Iter   240/  960] train: loss: 0.0123163
[Epoch 37; Iter   270/  960] train: loss: 0.0159327
[Epoch 37; Iter   300/  960] train: loss: 0.0684872
[Epoch 37; Iter   330/  960] train: loss: 0.0620241
[Epoch 37; Iter   360/  960] train: loss: 0.0281223
[Epoch 37; Iter   390/  960] train: loss: 0.2017252
[Epoch 37; Iter   420/  960] train: loss: 0.0543781
[Epoch 37; Iter   450/  960] train: loss: 0.1619324
[Epoch 37; Iter   480/  960] train: loss: 0.0154967
[Epoch 37; Iter   510/  960] train: loss: 0.0252410
[Epoch 37; Iter   540/  960] train: loss: 0.0127870
[Epoch 37; Iter   570/  960] train: loss: 0.1422246
[Epoch 37; Iter   600/  960] train: loss: 0.0252465
[Epoch 37; Iter   630/  960] train: loss: 0.0536015
[Epoch 37; Iter   660/  960] train: loss: 0.0839746
[Epoch 37; Iter   690/  960] train: loss: 0.0097806
[Epoch 37; Iter   720/  960] train: loss: 0.0119405
[Epoch 37; Iter   750/  960] train: loss: 0.0511508
[Epoch 37; Iter   780/  960] train: loss: 0.2080850
[Epoch 37; Iter   810/  960] train: loss: 0.0789875
[Epoch 37; Iter   840/  960] train: loss: 0.2526490
[Epoch 37; Iter   870/  960] train: loss: 0.0096438
[Epoch 37; Iter   900/  960] train: loss: 0.0809856
[Epoch 37; Iter   930/  960] train: loss: 0.1086244
[Epoch 37; Iter   960/  960] train: loss: 0.0301694
[Epoch 37] ogbg-molhiv: 0.764922 val loss: 0.228772
[Epoch 37] ogbg-molhiv: 0.754537 test loss: 0.207026
[Epoch 38; Iter    30/  960] train: loss: 0.1232623
[Epoch 38; Iter    60/  960] train: loss: 0.0132421
[Epoch 38; Iter    90/  960] train: loss: 0.0805724
[Epoch 38; Iter   120/  960] train: loss: 0.0451738
[Epoch 38; Iter   150/  960] train: loss: 0.2498825
[Epoch 38; Iter   180/  960] train: loss: 0.0292368
[Epoch 38; Iter   210/  960] train: loss: 0.0387131
[Epoch 38; Iter   240/  960] train: loss: 0.0474835
[Epoch 38; Iter   270/  960] train: loss: 0.0216945
[Epoch 38; Iter   300/  960] train: loss: 0.0215465
[Epoch 38; Iter   330/  960] train: loss: 0.1462575
[Epoch 38; Iter   360/  960] train: loss: 0.0180203
[Epoch 38; Iter   390/  960] train: loss: 0.0162142
[Epoch 38; Iter   420/  960] train: loss: 0.0277872
[Epoch 38; Iter   450/  960] train: loss: 0.0518953
[Epoch 38; Iter   480/  960] train: loss: 0.0193048
[Epoch 38; Iter   510/  960] train: loss: 0.3221916
[Epoch 38; Iter   540/  960] train: loss: 0.1056313
[Epoch 38; Iter   570/  960] train: loss: 0.0156466
[Epoch 38; Iter   600/  960] train: loss: 0.0191795
[Epoch 38; Iter   630/  960] train: loss: 0.2491758
[Epoch 38; Iter   660/  960] train: loss: 0.3087008
[Epoch 38; Iter   690/  960] train: loss: 0.0162989
[Epoch 38; Iter   720/  960] train: loss: 0.0107735
[Epoch 38; Iter   750/  960] train: loss: 0.0944700
[Epoch 38; Iter   780/  960] train: loss: 0.0301252
[Epoch 38; Iter   810/  960] train: loss: 0.1652072
[Epoch 38; Iter   840/  960] train: loss: 0.0213108
[Epoch 38; Iter   870/  960] train: loss: 0.1765226
[Epoch 38; Iter   900/  960] train: loss: 0.1809533
[Epoch 38; Iter   930/  960] train: loss: 0.0114216
[Epoch 38; Iter   960/  960] train: loss: 0.1776041
[Epoch 38] ogbg-molhiv: 0.745987 val loss: 0.141801
[Epoch 38] ogbg-molhiv: 0.754964 test loss: 0.118917
[Epoch 39; Iter    30/  960] train: loss: 0.0225906
[Epoch 39; Iter    60/  960] train: loss: 0.2344961
[Epoch 39; Iter    90/  960] train: loss: 0.0379967
[Epoch 39; Iter   120/  960] train: loss: 0.0105290
[Epoch 39; Iter   150/  960] train: loss: 0.0487153
[Epoch 39; Iter   180/  960] train: loss: 0.0286810
[Epoch 39; Iter   210/  960] train: loss: 0.1255400
[Epoch 39; Iter   240/  960] train: loss: 0.0425280
[Epoch 39; Iter   270/  960] train: loss: 0.0225991
[Epoch 39; Iter   300/  960] train: loss: 0.0279120
[Epoch 39; Iter   330/  960] train: loss: 0.0444520
[Epoch 39; Iter   360/  960] train: loss: 0.0861837
[Epoch 39; Iter   390/  960] train: loss: 0.0649611
[Epoch 39; Iter   420/  960] train: loss: 0.0237315
[Epoch 39; Iter   450/  960] train: loss: 0.1127616
[Epoch 39; Iter   480/  960] train: loss: 0.0120259
[Epoch 39; Iter   510/  960] train: loss: 0.0543945
[Epoch 39; Iter   540/  960] train: loss: 0.1290951
[Epoch 39; Iter   570/  960] train: loss: 0.0113057
[Epoch 39; Iter   600/  960] train: loss: 0.0614165
[Epoch 39; Iter   630/  960] train: loss: 0.0359863
[Epoch 39; Iter   660/  960] train: loss: 0.1329411
[Epoch 39; Iter   690/  960] train: loss: 0.0406279
[Epoch 39; Iter   720/  960] train: loss: 0.0553320
[Epoch 39; Iter   750/  960] train: loss: 0.1971155
[Epoch 39; Iter   780/  960] train: loss: 0.0226381
[Epoch 39; Iter   810/  960] train: loss: 0.1030697
[Epoch 39; Iter   840/  960] train: loss: 0.1052222
[Epoch 39; Iter   870/  960] train: loss: 0.1389505
[Epoch 39; Iter   900/  960] train: loss: 0.0145686
[Epoch 39; Iter   930/  960] train: loss: 0.0192007
[Epoch 39; Iter   960/  960] train: loss: 0.0084032
[Epoch 39] ogbg-molhiv: 0.748753 val loss: 0.194689
[Epoch 39] ogbg-molhiv: 0.753144 test loss: 0.215451
[Epoch 40; Iter    30/  960] train: loss: 0.0516591
[Epoch 40; Iter    60/  960] train: loss: 0.0141488
[Epoch 40; Iter    90/  960] train: loss: 0.0176383
[Epoch 40; Iter   120/  960] train: loss: 0.1523014
[Epoch 40; Iter   150/  960] train: loss: 0.0626959
[Epoch 40; Iter   180/  960] train: loss: 0.1514523
[Epoch 40; Iter   210/  960] train: loss: 0.0113970
[Epoch 40; Iter   240/  960] train: loss: 0.0411426
[Epoch 40; Iter   270/  960] train: loss: 0.0176002
[Epoch 40; Iter   300/  960] train: loss: 0.0462438
[Epoch 40; Iter   330/  960] train: loss: 0.1044206
[Epoch 40; Iter   360/  960] train: loss: 0.0157288
[Epoch 40; Iter   390/  960] train: loss: 0.0527158
[Epoch 40; Iter   420/  960] train: loss: 0.1597926
[Epoch 40; Iter   450/  960] train: loss: 0.0136985
[Epoch 40; Iter   480/  960] train: loss: 0.0140950
[Epoch 40; Iter   510/  960] train: loss: 0.0615718
[Epoch 40; Iter   540/  960] train: loss: 0.0082694
[Epoch 40; Iter   570/  960] train: loss: 0.0145517
[Epoch 40; Iter   600/  960] train: loss: 0.0327369
[Epoch 40; Iter   630/  960] train: loss: 0.0370445
[Epoch 40; Iter   660/  960] train: loss: 0.0823466
[Epoch 40; Iter   690/  960] train: loss: 0.0246892
[Epoch 40; Iter   720/  960] train: loss: 0.1735830
[Epoch 40; Iter   750/  960] train: loss: 0.0463386
[Epoch 40; Iter   780/  960] train: loss: 0.0461692
[Epoch 40; Iter   810/  960] train: loss: 0.3619496
[Epoch 40; Iter   840/  960] train: loss: 0.0283141
[Epoch 40; Iter   870/  960] train: loss: 0.5066689
[Epoch 40; Iter   900/  960] train: loss: 0.1198770
[Epoch 40; Iter   930/  960] train: loss: 0.0757045
[Epoch 40; Iter   960/  960] train: loss: 0.0724921
[Epoch 40] ogbg-molhiv: 0.745953 val loss: 0.250521
[Epoch 40] ogbg-molhiv: 0.753193 test loss: 0.218800
[Epoch 41; Iter    30/  960] train: loss: 0.0325892
[Epoch 41; Iter    60/  960] train: loss: 0.0268096
[Epoch 41; Iter    90/  960] train: loss: 0.0153537
[Epoch 41; Iter   120/  960] train: loss: 0.0139291
[Epoch 41; Iter   150/  960] train: loss: 0.0884309
[Epoch 41; Iter   180/  960] train: loss: 0.0112941
[Epoch 41; Iter   210/  960] train: loss: 0.0273349
[Epoch 41; Iter   240/  960] train: loss: 0.0224825
[Epoch 41; Iter   270/  960] train: loss: 0.1886071
[Epoch 41; Iter   300/  960] train: loss: 0.2537048
[Epoch 36; Iter   720/  960] train: loss: 0.1620376
[Epoch 36; Iter   750/  960] train: loss: 0.0457741
[Epoch 36; Iter   780/  960] train: loss: 0.1135179
[Epoch 36; Iter   810/  960] train: loss: 0.0770146
[Epoch 36; Iter   840/  960] train: loss: 0.2909252
[Epoch 36; Iter   870/  960] train: loss: 0.0430646
[Epoch 36; Iter   900/  960] train: loss: 0.0134509
[Epoch 36; Iter   930/  960] train: loss: 0.1118741
[Epoch 36; Iter   960/  960] train: loss: 0.4439107
[Epoch 36] ogbg-molhiv: 0.756252 val loss: 0.690723
[Epoch 36] ogbg-molhiv: 0.757384 test loss: 0.396029
[Epoch 37; Iter    30/  960] train: loss: 0.2032190
[Epoch 37; Iter    60/  960] train: loss: 0.0144943
[Epoch 37; Iter    90/  960] train: loss: 0.0174327
[Epoch 37; Iter   120/  960] train: loss: 0.0181592
[Epoch 37; Iter   150/  960] train: loss: 0.0282875
[Epoch 37; Iter   180/  960] train: loss: 0.1011439
[Epoch 37; Iter   210/  960] train: loss: 0.0348524
[Epoch 37; Iter   240/  960] train: loss: 0.1244222
[Epoch 37; Iter   270/  960] train: loss: 0.2200363
[Epoch 37; Iter   300/  960] train: loss: 0.1084915
[Epoch 37; Iter   330/  960] train: loss: 0.1896637
[Epoch 37; Iter   360/  960] train: loss: 0.0652799
[Epoch 37; Iter   390/  960] train: loss: 0.0330957
[Epoch 37; Iter   420/  960] train: loss: 0.0130136
[Epoch 37; Iter   450/  960] train: loss: 0.1872509
[Epoch 37; Iter   480/  960] train: loss: 0.0499618
[Epoch 37; Iter   510/  960] train: loss: 0.0967675
[Epoch 37; Iter   540/  960] train: loss: 0.0101658
[Epoch 37; Iter   570/  960] train: loss: 0.1954763
[Epoch 37; Iter   600/  960] train: loss: 0.1872643
[Epoch 37; Iter   630/  960] train: loss: 0.0602001
[Epoch 37; Iter   660/  960] train: loss: 0.0113065
[Epoch 37; Iter   690/  960] train: loss: 0.2962344
[Epoch 37; Iter   720/  960] train: loss: 0.0233075
[Epoch 37; Iter   750/  960] train: loss: 0.0348339
[Epoch 37; Iter   780/  960] train: loss: 0.1941328
[Epoch 37; Iter   810/  960] train: loss: 0.1167260
[Epoch 37; Iter   840/  960] train: loss: 0.1115611
[Epoch 37; Iter   870/  960] train: loss: 0.0172358
[Epoch 37; Iter   900/  960] train: loss: 0.0272659
[Epoch 37; Iter   930/  960] train: loss: 0.0230576
[Epoch 37; Iter   960/  960] train: loss: 0.0170508
[Epoch 37] ogbg-molhiv: 0.754158 val loss: 0.513681
[Epoch 37] ogbg-molhiv: 0.759263 test loss: 0.421887
[Epoch 38; Iter    30/  960] train: loss: 0.1240226
[Epoch 38; Iter    60/  960] train: loss: 0.0202905
[Epoch 38; Iter    90/  960] train: loss: 0.0846581
[Epoch 38; Iter   120/  960] train: loss: 0.0251856
[Epoch 38; Iter   150/  960] train: loss: 0.1083665
[Epoch 38; Iter   180/  960] train: loss: 0.0087178
[Epoch 38; Iter   210/  960] train: loss: 0.0993765
[Epoch 38; Iter   240/  960] train: loss: 0.0217298
[Epoch 38; Iter   270/  960] train: loss: 0.0340181
[Epoch 38; Iter   300/  960] train: loss: 0.0304836
[Epoch 38; Iter   330/  960] train: loss: 0.0873417
[Epoch 38; Iter   360/  960] train: loss: 0.1144140
[Epoch 38; Iter   390/  960] train: loss: 0.0319137
[Epoch 38; Iter   420/  960] train: loss: 0.0278553
[Epoch 38; Iter   450/  960] train: loss: 0.0223539
[Epoch 38; Iter   480/  960] train: loss: 0.0171381
[Epoch 38; Iter   510/  960] train: loss: 0.0187069
[Epoch 38; Iter   540/  960] train: loss: 0.0245040
[Epoch 38; Iter   570/  960] train: loss: 0.2737723
[Epoch 38; Iter   600/  960] train: loss: 0.0742999
[Epoch 38; Iter   630/  960] train: loss: 0.0836986
[Epoch 38; Iter   660/  960] train: loss: 0.0244188
[Epoch 38; Iter   690/  960] train: loss: 0.0357029
[Epoch 38; Iter   720/  960] train: loss: 0.0120499
[Epoch 38; Iter   750/  960] train: loss: 0.0228540
[Epoch 38; Iter   780/  960] train: loss: 0.1124875
[Epoch 38; Iter   810/  960] train: loss: 0.0176471
[Epoch 38; Iter   840/  960] train: loss: 0.0264881
[Epoch 38; Iter   870/  960] train: loss: 0.0995013
[Epoch 38; Iter   900/  960] train: loss: 0.0164266
[Epoch 38; Iter   930/  960] train: loss: 0.0531695
[Epoch 38; Iter   960/  960] train: loss: 0.0190220
[Epoch 38] ogbg-molhiv: 0.760704 val loss: 0.746642
[Epoch 38] ogbg-molhiv: 0.764058 test loss: 0.533376
[Epoch 39; Iter    30/  960] train: loss: 0.0192919
[Epoch 39; Iter    60/  960] train: loss: 0.0698394
[Epoch 39; Iter    90/  960] train: loss: 0.1055292
[Epoch 39; Iter   120/  960] train: loss: 0.0118377
[Epoch 39; Iter   150/  960] train: loss: 0.0214948
[Epoch 39; Iter   180/  960] train: loss: 0.0088261
[Epoch 39; Iter   210/  960] train: loss: 0.0632595
[Epoch 39; Iter   240/  960] train: loss: 0.0501632
[Epoch 39; Iter   270/  960] train: loss: 0.0719174
[Epoch 39; Iter   300/  960] train: loss: 0.0351091
[Epoch 39; Iter   330/  960] train: loss: 0.0480073
[Epoch 39; Iter   360/  960] train: loss: 0.0953405
[Epoch 39; Iter   390/  960] train: loss: 0.0896133
[Epoch 39; Iter   420/  960] train: loss: 0.0076032
[Epoch 39; Iter   450/  960] train: loss: 0.1386407
[Epoch 39; Iter   480/  960] train: loss: 0.1348739
[Epoch 39; Iter   510/  960] train: loss: 0.0213350
[Epoch 39; Iter   540/  960] train: loss: 0.0887308
[Epoch 39; Iter   570/  960] train: loss: 0.1126605
[Epoch 39; Iter   600/  960] train: loss: 0.0358259
[Epoch 39; Iter   630/  960] train: loss: 0.0294948
[Epoch 39; Iter   660/  960] train: loss: 0.0168815
[Epoch 39; Iter   690/  960] train: loss: 0.1450183
[Epoch 39; Iter   720/  960] train: loss: 0.0260528
[Epoch 39; Iter   750/  960] train: loss: 0.0137285
[Epoch 39; Iter   780/  960] train: loss: 0.0473993
[Epoch 39; Iter   810/  960] train: loss: 0.1356428
[Epoch 39; Iter   840/  960] train: loss: 0.0891416
[Epoch 39; Iter   870/  960] train: loss: 0.1383107
[Epoch 39; Iter   900/  960] train: loss: 0.0293864
[Epoch 39; Iter   930/  960] train: loss: 0.0154430
[Epoch 39; Iter   960/  960] train: loss: 0.0985160
[Epoch 39] ogbg-molhiv: 0.744825 val loss: 1.698322
[Epoch 39] ogbg-molhiv: 0.745511 test loss: 0.462677
[Epoch 40; Iter    30/  960] train: loss: 0.1541756
[Epoch 40; Iter    60/  960] train: loss: 0.0321978
[Epoch 40; Iter    90/  960] train: loss: 0.0291627
[Epoch 40; Iter   120/  960] train: loss: 0.0143601
[Epoch 40; Iter   150/  960] train: loss: 0.1938121
[Epoch 40; Iter   180/  960] train: loss: 0.2185255
[Epoch 40; Iter   210/  960] train: loss: 0.0615985
[Epoch 40; Iter   240/  960] train: loss: 0.0212305
[Epoch 40; Iter   270/  960] train: loss: 0.0132362
[Epoch 40; Iter   300/  960] train: loss: 0.2336285
[Epoch 40; Iter   330/  960] train: loss: 0.0108905
[Epoch 40; Iter   360/  960] train: loss: 0.2097020
[Epoch 40; Iter   390/  960] train: loss: 0.0250754
[Epoch 40; Iter   420/  960] train: loss: 0.0253340
[Epoch 40; Iter   450/  960] train: loss: 0.1881795
[Epoch 40; Iter   480/  960] train: loss: 0.1195403
[Epoch 40; Iter   510/  960] train: loss: 0.0273091
[Epoch 40; Iter   540/  960] train: loss: 0.0067961
[Epoch 40; Iter   570/  960] train: loss: 0.0107772
[Epoch 40; Iter   600/  960] train: loss: 0.0412029
[Epoch 40; Iter   630/  960] train: loss: 0.0446316
[Epoch 40; Iter   660/  960] train: loss: 0.0143306
[Epoch 40; Iter   690/  960] train: loss: 0.0278998
[Epoch 40; Iter   720/  960] train: loss: 0.0257102
[Epoch 40; Iter   750/  960] train: loss: 0.0227790
[Epoch 40; Iter   780/  960] train: loss: 0.2194994
[Epoch 40; Iter   810/  960] train: loss: 0.0196902
[Epoch 40; Iter   840/  960] train: loss: 0.0474661
[Epoch 40; Iter   870/  960] train: loss: 0.0469711
[Epoch 40; Iter   900/  960] train: loss: 0.1234590
[Epoch 40; Iter   930/  960] train: loss: 0.1736759
[Epoch 40; Iter   960/  960] train: loss: 0.2044382
[Epoch 40] ogbg-molhiv: 0.752840 val loss: 0.733396
[Epoch 40] ogbg-molhiv: 0.757400 test loss: 0.294551
[Epoch 41; Iter    30/  960] train: loss: 0.0173596
[Epoch 41; Iter    60/  960] train: loss: 0.0318951
[Epoch 41; Iter    90/  960] train: loss: 0.0356158
[Epoch 41; Iter   120/  960] train: loss: 0.1354732
[Epoch 41; Iter   150/  960] train: loss: 0.0094632
[Epoch 41; Iter   180/  960] train: loss: 0.0349643
[Epoch 41; Iter   210/  960] train: loss: 0.0232236
[Epoch 41; Iter   240/  960] train: loss: 0.0384930
[Epoch 41; Iter   270/  960] train: loss: 0.1127600
[Epoch 41; Iter   300/  960] train: loss: 0.0112177
[Epoch 36; Iter   775/  823] train: loss: 0.0382565
[Epoch 36; Iter   805/  823] train: loss: 0.0333475
[Epoch 36] ogbg-molhiv: 0.742499 val loss: 0.172765
[Epoch 36] ogbg-molhiv: 0.784813 test loss: 0.146712
[Epoch 37; Iter    12/  823] train: loss: 0.0817701
[Epoch 37; Iter    42/  823] train: loss: 0.0217352
[Epoch 37; Iter    72/  823] train: loss: 0.0339059
[Epoch 37; Iter   102/  823] train: loss: 0.0240221
[Epoch 37; Iter   132/  823] train: loss: 0.0821258
[Epoch 37; Iter   162/  823] train: loss: 0.0674687
[Epoch 37; Iter   192/  823] train: loss: 0.1018763
[Epoch 37; Iter   222/  823] train: loss: 0.0616903
[Epoch 37; Iter   252/  823] train: loss: 0.0324298
[Epoch 37; Iter   282/  823] train: loss: 0.1949046
[Epoch 37; Iter   312/  823] train: loss: 0.0326391
[Epoch 37; Iter   342/  823] train: loss: 0.0223121
[Epoch 37; Iter   372/  823] train: loss: 0.0147016
[Epoch 37; Iter   402/  823] train: loss: 0.2172244
[Epoch 37; Iter   432/  823] train: loss: 0.0290527
[Epoch 37; Iter   462/  823] train: loss: 0.0416859
[Epoch 37; Iter   492/  823] train: loss: 0.0844635
[Epoch 37; Iter   522/  823] train: loss: 0.0115362
[Epoch 37; Iter   552/  823] train: loss: 0.0302271
[Epoch 37; Iter   582/  823] train: loss: 0.2338040
[Epoch 37; Iter   612/  823] train: loss: 0.1281768
[Epoch 37; Iter   642/  823] train: loss: 0.1537984
[Epoch 37; Iter   672/  823] train: loss: 0.0166782
[Epoch 37; Iter   702/  823] train: loss: 0.1007152
[Epoch 37; Iter   732/  823] train: loss: 0.0404784
[Epoch 37; Iter   762/  823] train: loss: 0.0122415
[Epoch 37; Iter   792/  823] train: loss: 0.0505929
[Epoch 37; Iter   822/  823] train: loss: 0.0347316
[Epoch 37] ogbg-molhiv: 0.727159 val loss: 0.167198
[Epoch 37] ogbg-molhiv: 0.779198 test loss: 0.161746
[Epoch 38; Iter    29/  823] train: loss: 0.2511405
[Epoch 38; Iter    59/  823] train: loss: 0.0655221
[Epoch 38; Iter    89/  823] train: loss: 0.0226557
[Epoch 38; Iter   119/  823] train: loss: 0.0329100
[Epoch 38; Iter   149/  823] train: loss: 0.1381274
[Epoch 38; Iter   179/  823] train: loss: 0.0261037
[Epoch 38; Iter   209/  823] train: loss: 0.0180374
[Epoch 38; Iter   239/  823] train: loss: 0.0428260
[Epoch 38; Iter   269/  823] train: loss: 0.2713676
[Epoch 38; Iter   299/  823] train: loss: 0.0167621
[Epoch 38; Iter   329/  823] train: loss: 0.0940756
[Epoch 38; Iter   359/  823] train: loss: 0.0721388
[Epoch 38; Iter   389/  823] train: loss: 0.0201267
[Epoch 38; Iter   419/  823] train: loss: 0.0544316
[Epoch 38; Iter   449/  823] train: loss: 0.0606733
[Epoch 38; Iter   479/  823] train: loss: 0.0881510
[Epoch 38; Iter   509/  823] train: loss: 0.0405161
[Epoch 38; Iter   539/  823] train: loss: 0.0162459
[Epoch 38; Iter   569/  823] train: loss: 0.0232370
[Epoch 38; Iter   599/  823] train: loss: 0.0234683
[Epoch 38; Iter   629/  823] train: loss: 0.1137899
[Epoch 38; Iter   659/  823] train: loss: 0.0166162
[Epoch 38; Iter   689/  823] train: loss: 0.0170989
[Epoch 38; Iter   719/  823] train: loss: 0.0123147
[Epoch 38; Iter   749/  823] train: loss: 0.0268564
[Epoch 38; Iter   779/  823] train: loss: 0.1594247
[Epoch 38; Iter   809/  823] train: loss: 0.0135596
[Epoch 38] ogbg-molhiv: 0.717581 val loss: 0.173905
[Epoch 38] ogbg-molhiv: 0.776360 test loss: 0.129600
[Epoch 39; Iter    16/  823] train: loss: 0.0339419
[Epoch 39; Iter    46/  823] train: loss: 0.0346428
[Epoch 39; Iter    76/  823] train: loss: 0.0369764
[Epoch 39; Iter   106/  823] train: loss: 0.0178118
[Epoch 39; Iter   136/  823] train: loss: 0.2205072
[Epoch 39; Iter   166/  823] train: loss: 0.0831951
[Epoch 39; Iter   196/  823] train: loss: 0.0294801
[Epoch 39; Iter   226/  823] train: loss: 0.0556402
[Epoch 39; Iter   256/  823] train: loss: 0.1247899
[Epoch 39; Iter   286/  823] train: loss: 0.0304565
[Epoch 39; Iter   316/  823] train: loss: 0.0285481
[Epoch 39; Iter   346/  823] train: loss: 0.1540064
[Epoch 39; Iter   376/  823] train: loss: 0.0197120
[Epoch 39; Iter   406/  823] train: loss: 0.0475927
[Epoch 39; Iter   436/  823] train: loss: 0.0095390
[Epoch 39; Iter   466/  823] train: loss: 0.0201468
[Epoch 39; Iter   496/  823] train: loss: 0.0217210
[Epoch 39; Iter   526/  823] train: loss: 0.0967726
[Epoch 39; Iter   556/  823] train: loss: 0.0241996
[Epoch 39; Iter   586/  823] train: loss: 0.5327626
[Epoch 39; Iter   616/  823] train: loss: 0.0141398
[Epoch 39; Iter   646/  823] train: loss: 0.0766206
[Epoch 39; Iter   676/  823] train: loss: 0.0475993
[Epoch 39; Iter   706/  823] train: loss: 0.1440410
[Epoch 39; Iter   736/  823] train: loss: 0.0149940
[Epoch 39; Iter   766/  823] train: loss: 0.0119740
[Epoch 39; Iter   796/  823] train: loss: 0.0491552
[Epoch 39] ogbg-molhiv: 0.723202 val loss: 0.176538
[Epoch 39] ogbg-molhiv: 0.759331 test loss: 0.149138
[Epoch 40; Iter     3/  823] train: loss: 0.0187290
[Epoch 40; Iter    33/  823] train: loss: 0.0189643
[Epoch 40; Iter    63/  823] train: loss: 0.0327556
[Epoch 40; Iter    93/  823] train: loss: 0.0943124
[Epoch 40; Iter   123/  823] train: loss: 0.0731157
[Epoch 40; Iter   153/  823] train: loss: 0.0106738
[Epoch 40; Iter   183/  823] train: loss: 0.0095868
[Epoch 40; Iter   213/  823] train: loss: 0.0154871
[Epoch 40; Iter   243/  823] train: loss: 0.0422781
[Epoch 40; Iter   273/  823] train: loss: 0.0189691
[Epoch 40; Iter   303/  823] train: loss: 0.0755728
[Epoch 40; Iter   333/  823] train: loss: 0.1828940
[Epoch 40; Iter   363/  823] train: loss: 0.0099191
[Epoch 40; Iter   393/  823] train: loss: 0.0999445
[Epoch 40; Iter   423/  823] train: loss: 0.0913754
[Epoch 40; Iter   453/  823] train: loss: 0.0901767
[Epoch 40; Iter   483/  823] train: loss: 0.0147978
[Epoch 40; Iter   513/  823] train: loss: 0.0501313
[Epoch 40; Iter   543/  823] train: loss: 0.1223287
[Epoch 40; Iter   573/  823] train: loss: 0.2366970
[Epoch 40; Iter   603/  823] train: loss: 0.0773163
[Epoch 40; Iter   633/  823] train: loss: 0.0827442
[Epoch 40; Iter   663/  823] train: loss: 0.0472972
[Epoch 40; Iter   693/  823] train: loss: 0.1003762
[Epoch 40; Iter   723/  823] train: loss: 0.0238371
[Epoch 40; Iter   753/  823] train: loss: 0.1847876
[Epoch 40; Iter   783/  823] train: loss: 0.0137789
[Epoch 40; Iter   813/  823] train: loss: 0.0682792
[Epoch 40] ogbg-molhiv: 0.719452 val loss: 0.177299
[Epoch 40] ogbg-molhiv: 0.789597 test loss: 0.124433
[Epoch 41; Iter    20/  823] train: loss: 0.0231832
[Epoch 41; Iter    50/  823] train: loss: 0.1482135
[Epoch 41; Iter    80/  823] train: loss: 0.0333750
[Epoch 41; Iter   110/  823] train: loss: 0.0137189
[Epoch 41; Iter   140/  823] train: loss: 0.1497521
[Epoch 41; Iter   170/  823] train: loss: 0.0179036
[Epoch 41; Iter   200/  823] train: loss: 0.0719499
[Epoch 41; Iter   230/  823] train: loss: 0.0108768
[Epoch 41; Iter   260/  823] train: loss: 0.0058617
[Epoch 41; Iter   290/  823] train: loss: 0.0660360
[Epoch 41; Iter   320/  823] train: loss: 0.0137696
[Epoch 41; Iter   350/  823] train: loss: 0.0135500
[Epoch 41; Iter   380/  823] train: loss: 0.0116928
[Epoch 41; Iter   410/  823] train: loss: 0.0566267
[Epoch 41; Iter   440/  823] train: loss: 0.1614038
[Epoch 41; Iter   470/  823] train: loss: 0.0492199
[Epoch 41; Iter   500/  823] train: loss: 0.1053966
[Epoch 41; Iter   530/  823] train: loss: 0.0130165
[Epoch 41; Iter   560/  823] train: loss: 0.0297676
[Epoch 41; Iter   590/  823] train: loss: 0.0122467
[Epoch 41; Iter   620/  823] train: loss: 0.0276179
[Epoch 41; Iter   650/  823] train: loss: 0.1263916
[Epoch 41; Iter   680/  823] train: loss: 0.0416440
[Epoch 41; Iter   710/  823] train: loss: 0.1457416
[Epoch 41; Iter   740/  823] train: loss: 0.0439255
[Epoch 41; Iter   770/  823] train: loss: 0.1116543
[Epoch 41; Iter   800/  823] train: loss: 0.1418148
[Epoch 41] ogbg-molhiv: 0.717258 val loss: 0.186176
[Epoch 41] ogbg-molhiv: 0.770338 test loss: 0.150631
[Epoch 42; Iter     7/  823] train: loss: 0.0263045
[Epoch 42; Iter    37/  823] train: loss: 0.0446586
[Epoch 42; Iter    67/  823] train: loss: 0.0536005
[Epoch 42; Iter    97/  823] train: loss: 0.0821078
[Epoch 42; Iter   127/  823] train: loss: 0.0302622
[Epoch 42; Iter   157/  823] train: loss: 0.1059325
[Epoch 36; Iter   720/  960] train: loss: 0.0971036
[Epoch 36; Iter   750/  960] train: loss: 0.0686012
[Epoch 36; Iter   780/  960] train: loss: 0.0241312
[Epoch 36; Iter   810/  960] train: loss: 0.0731077
[Epoch 36; Iter   840/  960] train: loss: 0.0298527
[Epoch 36; Iter   870/  960] train: loss: 0.0154473
[Epoch 36; Iter   900/  960] train: loss: 0.3717884
[Epoch 36; Iter   930/  960] train: loss: 0.0250414
[Epoch 36; Iter   960/  960] train: loss: 0.0211972
[Epoch 36] ogbg-molhiv: 0.729673 val loss: 0.143278
[Epoch 36] ogbg-molhiv: 0.784690 test loss: 0.109524
[Epoch 37; Iter    30/  960] train: loss: 0.0736310
[Epoch 37; Iter    60/  960] train: loss: 0.0351959
[Epoch 37; Iter    90/  960] train: loss: 0.0577613
[Epoch 37; Iter   120/  960] train: loss: 0.0140319
[Epoch 37; Iter   150/  960] train: loss: 0.0183339
[Epoch 37; Iter   180/  960] train: loss: 0.0466397
[Epoch 37; Iter   210/  960] train: loss: 0.0251783
[Epoch 37; Iter   240/  960] train: loss: 0.0250673
[Epoch 37; Iter   270/  960] train: loss: 0.2260466
[Epoch 37; Iter   300/  960] train: loss: 0.0361056
[Epoch 37; Iter   330/  960] train: loss: 0.0618634
[Epoch 37; Iter   360/  960] train: loss: 0.0512730
[Epoch 37; Iter   390/  960] train: loss: 0.0305227
[Epoch 37; Iter   420/  960] train: loss: 0.0292601
[Epoch 37; Iter   450/  960] train: loss: 0.3358132
[Epoch 37; Iter   480/  960] train: loss: 0.0465651
[Epoch 37; Iter   510/  960] train: loss: 0.1009011
[Epoch 37; Iter   540/  960] train: loss: 0.0172662
[Epoch 37; Iter   570/  960] train: loss: 0.0420068
[Epoch 37; Iter   600/  960] train: loss: 0.0713425
[Epoch 37; Iter   630/  960] train: loss: 0.0127411
[Epoch 37; Iter   660/  960] train: loss: 0.1001060
[Epoch 37; Iter   690/  960] train: loss: 0.0143723
[Epoch 37; Iter   720/  960] train: loss: 0.0825629
[Epoch 37; Iter   750/  960] train: loss: 0.0190736
[Epoch 37; Iter   780/  960] train: loss: 0.1149364
[Epoch 37; Iter   810/  960] train: loss: 0.1070600
[Epoch 37; Iter   840/  960] train: loss: 0.0177888
[Epoch 37; Iter   870/  960] train: loss: 0.1349446
[Epoch 37; Iter   900/  960] train: loss: 0.0630490
[Epoch 37; Iter   930/  960] train: loss: 0.0324380
[Epoch 37; Iter   960/  960] train: loss: 0.0928777
[Epoch 37] ogbg-molhiv: 0.744215 val loss: 0.136735
[Epoch 37] ogbg-molhiv: 0.790603 test loss: 0.109904
[Epoch 38; Iter    30/  960] train: loss: 0.0317218
[Epoch 38; Iter    60/  960] train: loss: 0.0389938
[Epoch 38; Iter    90/  960] train: loss: 0.0727959
[Epoch 38; Iter   120/  960] train: loss: 0.4230350
[Epoch 38; Iter   150/  960] train: loss: 0.0507520
[Epoch 38; Iter   180/  960] train: loss: 0.0136249
[Epoch 38; Iter   210/  960] train: loss: 0.1663786
[Epoch 38; Iter   240/  960] train: loss: 0.1268493
[Epoch 38; Iter   270/  960] train: loss: 0.1466841
[Epoch 38; Iter   300/  960] train: loss: 0.1288675
[Epoch 38; Iter   330/  960] train: loss: 0.0177021
[Epoch 38; Iter   360/  960] train: loss: 0.0443768
[Epoch 38; Iter   390/  960] train: loss: 0.1728246
[Epoch 38; Iter   420/  960] train: loss: 0.0338678
[Epoch 38; Iter   450/  960] train: loss: 0.0355707
[Epoch 38; Iter   480/  960] train: loss: 0.0633645
[Epoch 38; Iter   510/  960] train: loss: 0.1719306
[Epoch 38; Iter   540/  960] train: loss: 0.1248545
[Epoch 38; Iter   570/  960] train: loss: 0.0328231
[Epoch 38; Iter   600/  960] train: loss: 0.0184671
[Epoch 38; Iter   630/  960] train: loss: 0.1566346
[Epoch 38; Iter   660/  960] train: loss: 0.0567520
[Epoch 38; Iter   690/  960] train: loss: 0.2873761
[Epoch 38; Iter   720/  960] train: loss: 0.0378932
[Epoch 38; Iter   750/  960] train: loss: 0.1499230
[Epoch 38; Iter   780/  960] train: loss: 0.2115919
[Epoch 38; Iter   810/  960] train: loss: 0.0133081
[Epoch 38; Iter   840/  960] train: loss: 0.3722367
[Epoch 38; Iter   870/  960] train: loss: 0.0230949
[Epoch 38; Iter   900/  960] train: loss: 0.0199482
[Epoch 38; Iter   930/  960] train: loss: 0.0446208
[Epoch 38; Iter   960/  960] train: loss: 0.1600819
[Epoch 38] ogbg-molhiv: 0.737671 val loss: 0.140188
[Epoch 38] ogbg-molhiv: 0.784268 test loss: 0.112496
[Epoch 39; Iter    30/  960] train: loss: 0.0759972
[Epoch 39; Iter    60/  960] train: loss: 0.0173387
[Epoch 39; Iter    90/  960] train: loss: 0.0973545
[Epoch 39; Iter   120/  960] train: loss: 0.0860300
[Epoch 39; Iter   150/  960] train: loss: 0.0878200
[Epoch 39; Iter   180/  960] train: loss: 0.0149183
[Epoch 39; Iter   210/  960] train: loss: 0.0994441
[Epoch 39; Iter   240/  960] train: loss: 0.0215654
[Epoch 39; Iter   270/  960] train: loss: 0.0181495
[Epoch 39; Iter   300/  960] train: loss: 0.1843968
[Epoch 39; Iter   330/  960] train: loss: 0.0189181
[Epoch 39; Iter   360/  960] train: loss: 0.0560080
[Epoch 39; Iter   390/  960] train: loss: 0.0362727
[Epoch 39; Iter   420/  960] train: loss: 0.1282523
[Epoch 39; Iter   450/  960] train: loss: 0.0196371
[Epoch 39; Iter   480/  960] train: loss: 0.2130924
[Epoch 39; Iter   510/  960] train: loss: 0.1246618
[Epoch 39; Iter   540/  960] train: loss: 0.1855577
[Epoch 39; Iter   570/  960] train: loss: 0.1238174
[Epoch 39; Iter   600/  960] train: loss: 0.1948963
[Epoch 39; Iter   630/  960] train: loss: 0.0444192
[Epoch 39; Iter   660/  960] train: loss: 0.0339300
[Epoch 39; Iter   690/  960] train: loss: 0.0283264
[Epoch 39; Iter   720/  960] train: loss: 0.0154812
[Epoch 39; Iter   750/  960] train: loss: 0.0120578
[Epoch 39; Iter   780/  960] train: loss: 0.0134213
[Epoch 39; Iter   810/  960] train: loss: 0.0198695
[Epoch 39; Iter   840/  960] train: loss: 0.1044563
[Epoch 39; Iter   870/  960] train: loss: 0.0216126
[Epoch 39; Iter   900/  960] train: loss: 0.0818274
[Epoch 39; Iter   930/  960] train: loss: 0.0742523
[Epoch 39; Iter   960/  960] train: loss: 0.0361348
[Epoch 39] ogbg-molhiv: 0.743636 val loss: 0.140393
[Epoch 39] ogbg-molhiv: 0.782851 test loss: 0.109901
[Epoch 40; Iter    30/  960] train: loss: 0.0099353
[Epoch 40; Iter    60/  960] train: loss: 0.0353997
[Epoch 40; Iter    90/  960] train: loss: 0.0813896
[Epoch 40; Iter   120/  960] train: loss: 0.1733554
[Epoch 40; Iter   150/  960] train: loss: 0.0760922
[Epoch 40; Iter   180/  960] train: loss: 0.1403659
[Epoch 40; Iter   210/  960] train: loss: 0.0641576
[Epoch 40; Iter   240/  960] train: loss: 0.0155477
[Epoch 40; Iter   270/  960] train: loss: 0.0207915
[Epoch 40; Iter   300/  960] train: loss: 0.0204999
[Epoch 40; Iter   330/  960] train: loss: 0.0693443
[Epoch 40; Iter   360/  960] train: loss: 0.0230766
[Epoch 40; Iter   390/  960] train: loss: 0.0712751
[Epoch 40; Iter   420/  960] train: loss: 0.0119596
[Epoch 40; Iter   450/  960] train: loss: 0.0320266
[Epoch 40; Iter   480/  960] train: loss: 0.0267901
[Epoch 40; Iter   510/  960] train: loss: 0.0784934
[Epoch 40; Iter   540/  960] train: loss: 0.0156688
[Epoch 40; Iter   570/  960] train: loss: 0.0292479
[Epoch 40; Iter   600/  960] train: loss: 0.0404152
[Epoch 40; Iter   630/  960] train: loss: 0.1471582
[Epoch 40; Iter   660/  960] train: loss: 0.2351437
[Epoch 40; Iter   690/  960] train: loss: 0.0698010
[Epoch 40; Iter   720/  960] train: loss: 0.0095125
[Epoch 40; Iter   750/  960] train: loss: 0.1401576
[Epoch 40; Iter   780/  960] train: loss: 0.0204563
[Epoch 40; Iter   810/  960] train: loss: 0.1653799
[Epoch 40; Iter   840/  960] train: loss: 0.0503241
[Epoch 40; Iter   870/  960] train: loss: 0.0529872
[Epoch 40; Iter   900/  960] train: loss: 0.1291339
[Epoch 40; Iter   930/  960] train: loss: 0.0092151
[Epoch 40; Iter   960/  960] train: loss: 0.0090728
[Epoch 40] ogbg-molhiv: 0.743459 val loss: 0.141696
[Epoch 40] ogbg-molhiv: 0.788562 test loss: 0.108326
[Epoch 41; Iter    30/  960] train: loss: 0.0275675
[Epoch 41; Iter    60/  960] train: loss: 0.0170971
[Epoch 41; Iter    90/  960] train: loss: 0.0168769
[Epoch 41; Iter   120/  960] train: loss: 0.1358518
[Epoch 41; Iter   150/  960] train: loss: 0.0274851
[Epoch 41; Iter   180/  960] train: loss: 0.1385410
[Epoch 41; Iter   210/  960] train: loss: 0.1422782
[Epoch 41; Iter   240/  960] train: loss: 0.1288078
[Epoch 41; Iter   270/  960] train: loss: 0.0151443
[Epoch 41; Iter   300/  960] train: loss: 0.0188160
[Epoch 36; Iter   635/ 1097] train: loss: 0.2356663
[Epoch 36; Iter   665/ 1097] train: loss: 0.0852890
[Epoch 36; Iter   695/ 1097] train: loss: 0.0488978
[Epoch 36; Iter   725/ 1097] train: loss: 0.1822102
[Epoch 36; Iter   755/ 1097] train: loss: 0.0251163
[Epoch 36; Iter   785/ 1097] train: loss: 0.0522725
[Epoch 36; Iter   815/ 1097] train: loss: 0.1863638
[Epoch 36; Iter   845/ 1097] train: loss: 0.1153798
[Epoch 36; Iter   875/ 1097] train: loss: 0.0492298
[Epoch 36; Iter   905/ 1097] train: loss: 0.0784796
[Epoch 36; Iter   935/ 1097] train: loss: 0.0219372
[Epoch 36; Iter   965/ 1097] train: loss: 0.1446547
[Epoch 36; Iter   995/ 1097] train: loss: 0.0194180
[Epoch 36; Iter  1025/ 1097] train: loss: 0.3888859
[Epoch 36; Iter  1055/ 1097] train: loss: 0.0469488
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0275179
[Epoch 36] ogbg-molhiv: 0.811434 val loss: 0.219532
[Epoch 36] ogbg-molhiv: 0.732229 test loss: 0.349169
[Epoch 37; Iter    18/ 1097] train: loss: 0.0414632
[Epoch 37; Iter    48/ 1097] train: loss: 0.0199685
[Epoch 37; Iter    78/ 1097] train: loss: 0.0446148
[Epoch 37; Iter   108/ 1097] train: loss: 0.1966535
[Epoch 37; Iter   138/ 1097] train: loss: 0.0139257
[Epoch 37; Iter   168/ 1097] train: loss: 0.2130581
[Epoch 37; Iter   198/ 1097] train: loss: 0.0915987
[Epoch 37; Iter   228/ 1097] train: loss: 0.0230361
[Epoch 37; Iter   258/ 1097] train: loss: 0.1656421
[Epoch 37; Iter   288/ 1097] train: loss: 0.1310250
[Epoch 37; Iter   318/ 1097] train: loss: 0.0273372
[Epoch 37; Iter   348/ 1097] train: loss: 0.1787532
[Epoch 37; Iter   378/ 1097] train: loss: 0.0608426
[Epoch 37; Iter   408/ 1097] train: loss: 0.0392562
[Epoch 37; Iter   438/ 1097] train: loss: 0.0176832
[Epoch 37; Iter   468/ 1097] train: loss: 0.1074747
[Epoch 37; Iter   498/ 1097] train: loss: 0.0114334
[Epoch 37; Iter   528/ 1097] train: loss: 0.4206263
[Epoch 37; Iter   558/ 1097] train: loss: 0.4481124
[Epoch 37; Iter   588/ 1097] train: loss: 0.0103009
[Epoch 37; Iter   618/ 1097] train: loss: 0.0434808
[Epoch 37; Iter   648/ 1097] train: loss: 0.0465885
[Epoch 37; Iter   678/ 1097] train: loss: 0.0284219
[Epoch 37; Iter   708/ 1097] train: loss: 0.0393620
[Epoch 37; Iter   738/ 1097] train: loss: 0.1703804
[Epoch 37; Iter   768/ 1097] train: loss: 0.0652545
[Epoch 37; Iter   798/ 1097] train: loss: 0.0746463
[Epoch 37; Iter   828/ 1097] train: loss: 0.0372978
[Epoch 37; Iter   858/ 1097] train: loss: 0.1658378
[Epoch 37; Iter   888/ 1097] train: loss: 0.0567034
[Epoch 37; Iter   918/ 1097] train: loss: 0.1502077
[Epoch 37; Iter   948/ 1097] train: loss: 0.0147017
[Epoch 37; Iter   978/ 1097] train: loss: 0.0560084
[Epoch 37; Iter  1008/ 1097] train: loss: 0.1300695
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0925591
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0518852
[Epoch 37] ogbg-molhiv: 0.810746 val loss: 0.276061
[Epoch 37] ogbg-molhiv: 0.707283 test loss: 0.397565
[Epoch 38; Iter     1/ 1097] train: loss: 0.1681211
[Epoch 38; Iter    31/ 1097] train: loss: 0.0215868
[Epoch 38; Iter    61/ 1097] train: loss: 0.0340600
[Epoch 38; Iter    91/ 1097] train: loss: 0.0355746
[Epoch 38; Iter   121/ 1097] train: loss: 0.0192870
[Epoch 38; Iter   151/ 1097] train: loss: 0.0225849
[Epoch 38; Iter   181/ 1097] train: loss: 0.0265444
[Epoch 38; Iter   211/ 1097] train: loss: 0.0212514
[Epoch 38; Iter   241/ 1097] train: loss: 0.0181646
[Epoch 38; Iter   271/ 1097] train: loss: 0.0323464
[Epoch 38; Iter   301/ 1097] train: loss: 0.0185172
[Epoch 38; Iter   331/ 1097] train: loss: 0.0654687
[Epoch 38; Iter   361/ 1097] train: loss: 0.1137488
[Epoch 38; Iter   391/ 1097] train: loss: 0.0749728
[Epoch 38; Iter   421/ 1097] train: loss: 0.0813939
[Epoch 38; Iter   451/ 1097] train: loss: 0.0444177
[Epoch 38; Iter   481/ 1097] train: loss: 0.3283677
[Epoch 38; Iter   511/ 1097] train: loss: 0.1269264
[Epoch 38; Iter   541/ 1097] train: loss: 0.2029234
[Epoch 38; Iter   571/ 1097] train: loss: 0.0160329
[Epoch 38; Iter   601/ 1097] train: loss: 0.2342164
[Epoch 38; Iter   631/ 1097] train: loss: 0.0547288
[Epoch 38; Iter   661/ 1097] train: loss: 0.0500790
[Epoch 38; Iter   691/ 1097] train: loss: 0.0234887
[Epoch 38; Iter   721/ 1097] train: loss: 0.1403228
[Epoch 38; Iter   751/ 1097] train: loss: 0.1766219
[Epoch 38; Iter   781/ 1097] train: loss: 0.0478720
[Epoch 38; Iter   811/ 1097] train: loss: 0.2176786
[Epoch 38; Iter   841/ 1097] train: loss: 0.0175771
[Epoch 38; Iter   871/ 1097] train: loss: 0.0462964
[Epoch 38; Iter   901/ 1097] train: loss: 0.0121950
[Epoch 38; Iter   931/ 1097] train: loss: 0.0512001
[Epoch 38; Iter   961/ 1097] train: loss: 0.0589076
[Epoch 38; Iter   991/ 1097] train: loss: 0.0743794
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0104214
[Epoch 38; Iter  1051/ 1097] train: loss: 0.1050432
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0875736
[Epoch 38] ogbg-molhiv: 0.779076 val loss: 0.080049
[Epoch 38] ogbg-molhiv: 0.728680 test loss: 0.303669
[Epoch 39; Iter    14/ 1097] train: loss: 0.0958122
[Epoch 39; Iter    44/ 1097] train: loss: 0.1460152
[Epoch 39; Iter    74/ 1097] train: loss: 0.0304836
[Epoch 39; Iter   104/ 1097] train: loss: 0.1070247
[Epoch 39; Iter   134/ 1097] train: loss: 0.1441731
[Epoch 39; Iter   164/ 1097] train: loss: 0.0238275
[Epoch 39; Iter   194/ 1097] train: loss: 0.0384949
[Epoch 39; Iter   224/ 1097] train: loss: 0.0507931
[Epoch 39; Iter   254/ 1097] train: loss: 0.0129650
[Epoch 39; Iter   284/ 1097] train: loss: 0.0178531
[Epoch 39; Iter   314/ 1097] train: loss: 0.0575180
[Epoch 39; Iter   344/ 1097] train: loss: 0.0838027
[Epoch 39; Iter   374/ 1097] train: loss: 0.0746525
[Epoch 39; Iter   404/ 1097] train: loss: 0.1525355
[Epoch 39; Iter   434/ 1097] train: loss: 0.0273803
[Epoch 39; Iter   464/ 1097] train: loss: 0.0504691
[Epoch 39; Iter   494/ 1097] train: loss: 0.0370792
[Epoch 39; Iter   524/ 1097] train: loss: 0.0236555
[Epoch 39; Iter   554/ 1097] train: loss: 0.0229909
[Epoch 39; Iter   584/ 1097] train: loss: 0.0364970
[Epoch 39; Iter   614/ 1097] train: loss: 0.0278168
[Epoch 39; Iter   644/ 1097] train: loss: 0.1247448
[Epoch 39; Iter   674/ 1097] train: loss: 0.0243423
[Epoch 39; Iter   704/ 1097] train: loss: 0.0252319
[Epoch 39; Iter   734/ 1097] train: loss: 0.1830450
[Epoch 39; Iter   764/ 1097] train: loss: 0.1233471
[Epoch 39; Iter   794/ 1097] train: loss: 0.1603397
[Epoch 39; Iter   824/ 1097] train: loss: 0.0455130
[Epoch 39; Iter   854/ 1097] train: loss: 0.1851907
[Epoch 39; Iter   884/ 1097] train: loss: 0.0608912
[Epoch 39; Iter   914/ 1097] train: loss: 0.0283691
[Epoch 39; Iter   944/ 1097] train: loss: 0.0593600
[Epoch 39; Iter   974/ 1097] train: loss: 0.0143218
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0417651
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0227317
[Epoch 39; Iter  1064/ 1097] train: loss: 0.1355374
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1647232
[Epoch 39] ogbg-molhiv: 0.791474 val loss: 0.200611
[Epoch 39] ogbg-molhiv: 0.738299 test loss: 0.325443
[Epoch 40; Iter    27/ 1097] train: loss: 0.0166975
[Epoch 40; Iter    57/ 1097] train: loss: 0.0301902
[Epoch 40; Iter    87/ 1097] train: loss: 0.0556447
[Epoch 40; Iter   117/ 1097] train: loss: 0.1153136
[Epoch 40; Iter   147/ 1097] train: loss: 0.0314563
[Epoch 40; Iter   177/ 1097] train: loss: 0.0284697
[Epoch 40; Iter   207/ 1097] train: loss: 0.1002380
[Epoch 40; Iter   237/ 1097] train: loss: 0.0155583
[Epoch 40; Iter   267/ 1097] train: loss: 0.0167936
[Epoch 40; Iter   297/ 1097] train: loss: 0.3022866
[Epoch 40; Iter   327/ 1097] train: loss: 0.2189459
[Epoch 40; Iter   357/ 1097] train: loss: 0.0178946
[Epoch 40; Iter   387/ 1097] train: loss: 0.0768424
[Epoch 40; Iter   417/ 1097] train: loss: 0.1228264
[Epoch 40; Iter   447/ 1097] train: loss: 0.1416006
[Epoch 40; Iter   477/ 1097] train: loss: 0.0162697
[Epoch 40; Iter   507/ 1097] train: loss: 0.0200478
[Epoch 40; Iter   537/ 1097] train: loss: 0.2074584
[Epoch 40; Iter   567/ 1097] train: loss: 0.0232451
[Epoch 40; Iter   597/ 1097] train: loss: 0.0202612
[Epoch 40; Iter   627/ 1097] train: loss: 0.0321163
[Epoch 40; Iter   657/ 1097] train: loss: 0.0261313
[Epoch 40; Iter   687/ 1097] train: loss: 0.0598989
[Epoch 36; Iter   635/ 1097] train: loss: 0.0217665
[Epoch 36; Iter   665/ 1097] train: loss: 0.0390337
[Epoch 36; Iter   695/ 1097] train: loss: 0.2065053
[Epoch 36; Iter   725/ 1097] train: loss: 0.0352590
[Epoch 36; Iter   755/ 1097] train: loss: 0.1904805
[Epoch 36; Iter   785/ 1097] train: loss: 0.0220569
[Epoch 36; Iter   815/ 1097] train: loss: 0.0723818
[Epoch 36; Iter   845/ 1097] train: loss: 0.0221792
[Epoch 36; Iter   875/ 1097] train: loss: 0.0256778
[Epoch 36; Iter   905/ 1097] train: loss: 0.0169421
[Epoch 36; Iter   935/ 1097] train: loss: 0.1959257
[Epoch 36; Iter   965/ 1097] train: loss: 0.0478342
[Epoch 36; Iter   995/ 1097] train: loss: 0.0406963
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0322565
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1128950
[Epoch 36; Iter  1085/ 1097] train: loss: 0.0263787
[Epoch 36] ogbg-molhiv: 0.794701 val loss: 0.081623
[Epoch 36] ogbg-molhiv: 0.745345 test loss: 0.126671
[Epoch 37; Iter    18/ 1097] train: loss: 0.0865573
[Epoch 37; Iter    48/ 1097] train: loss: 0.0340831
[Epoch 37; Iter    78/ 1097] train: loss: 0.0252285
[Epoch 37; Iter   108/ 1097] train: loss: 0.0749365
[Epoch 37; Iter   138/ 1097] train: loss: 0.0421695
[Epoch 37; Iter   168/ 1097] train: loss: 0.0708986
[Epoch 37; Iter   198/ 1097] train: loss: 0.2788543
[Epoch 37; Iter   228/ 1097] train: loss: 0.0298963
[Epoch 37; Iter   258/ 1097] train: loss: 0.0201673
[Epoch 37; Iter   288/ 1097] train: loss: 0.1133720
[Epoch 37; Iter   318/ 1097] train: loss: 0.0342305
[Epoch 37; Iter   348/ 1097] train: loss: 0.1497628
[Epoch 37; Iter   378/ 1097] train: loss: 0.0418878
[Epoch 37; Iter   408/ 1097] train: loss: 0.0216068
[Epoch 37; Iter   438/ 1097] train: loss: 0.0203471
[Epoch 37; Iter   468/ 1097] train: loss: 0.0753089
[Epoch 37; Iter   498/ 1097] train: loss: 0.1612180
[Epoch 37; Iter   528/ 1097] train: loss: 0.0977396
[Epoch 37; Iter   558/ 1097] train: loss: 0.0136488
[Epoch 37; Iter   588/ 1097] train: loss: 0.1443816
[Epoch 37; Iter   618/ 1097] train: loss: 0.0719000
[Epoch 37; Iter   648/ 1097] train: loss: 0.1028309
[Epoch 37; Iter   678/ 1097] train: loss: 0.1725114
[Epoch 37; Iter   708/ 1097] train: loss: 0.0148801
[Epoch 37; Iter   738/ 1097] train: loss: 0.0382701
[Epoch 37; Iter   768/ 1097] train: loss: 0.0161041
[Epoch 37; Iter   798/ 1097] train: loss: 0.2251067
[Epoch 37; Iter   828/ 1097] train: loss: 0.0260476
[Epoch 37; Iter   858/ 1097] train: loss: 0.0264517
[Epoch 37; Iter   888/ 1097] train: loss: 0.0605094
[Epoch 37; Iter   918/ 1097] train: loss: 0.0695951
[Epoch 37; Iter   948/ 1097] train: loss: 0.0153348
[Epoch 37; Iter   978/ 1097] train: loss: 0.1107963
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0115396
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0621472
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0651927
[Epoch 37] ogbg-molhiv: 0.804037 val loss: 0.084916
[Epoch 37] ogbg-molhiv: 0.774747 test loss: 0.147339
[Epoch 38; Iter     1/ 1097] train: loss: 0.1950727
[Epoch 38; Iter    31/ 1097] train: loss: 0.0205282
[Epoch 38; Iter    61/ 1097] train: loss: 0.0639279
[Epoch 38; Iter    91/ 1097] train: loss: 0.0154131
[Epoch 38; Iter   121/ 1097] train: loss: 0.1664238
[Epoch 38; Iter   151/ 1097] train: loss: 0.0213836
[Epoch 38; Iter   181/ 1097] train: loss: 0.1515092
[Epoch 38; Iter   211/ 1097] train: loss: 0.0394858
[Epoch 38; Iter   241/ 1097] train: loss: 0.1178740
[Epoch 38; Iter   271/ 1097] train: loss: 0.0883697
[Epoch 38; Iter   301/ 1097] train: loss: 0.1257894
[Epoch 38; Iter   331/ 1097] train: loss: 0.2011155
[Epoch 38; Iter   361/ 1097] train: loss: 0.2478502
[Epoch 38; Iter   391/ 1097] train: loss: 0.0137955
[Epoch 38; Iter   421/ 1097] train: loss: 0.0659356
[Epoch 38; Iter   451/ 1097] train: loss: 0.1387076
[Epoch 38; Iter   481/ 1097] train: loss: 0.1914490
[Epoch 38; Iter   511/ 1097] train: loss: 0.0726221
[Epoch 38; Iter   541/ 1097] train: loss: 0.0142872
[Epoch 38; Iter   571/ 1097] train: loss: 0.0233556
[Epoch 38; Iter   601/ 1097] train: loss: 0.1482897
[Epoch 38; Iter   631/ 1097] train: loss: 0.0293833
[Epoch 38; Iter   661/ 1097] train: loss: 0.0229399
[Epoch 38; Iter   691/ 1097] train: loss: 0.0485746
[Epoch 38; Iter   721/ 1097] train: loss: 0.0605561
[Epoch 38; Iter   751/ 1097] train: loss: 0.1220658
[Epoch 38; Iter   781/ 1097] train: loss: 0.1730061
[Epoch 38; Iter   811/ 1097] train: loss: 0.2516562
[Epoch 38; Iter   841/ 1097] train: loss: 0.0407773
[Epoch 38; Iter   871/ 1097] train: loss: 0.1916854
[Epoch 38; Iter   901/ 1097] train: loss: 0.0584458
[Epoch 38; Iter   931/ 1097] train: loss: 0.0149641
[Epoch 38; Iter   961/ 1097] train: loss: 0.0186588
[Epoch 38; Iter   991/ 1097] train: loss: 0.0226452
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0147686
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0305153
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0347017
[Epoch 38] ogbg-molhiv: 0.786348 val loss: 0.107226
[Epoch 38] ogbg-molhiv: 0.740256 test loss: 0.129351
[Epoch 39; Iter    14/ 1097] train: loss: 0.0196770
[Epoch 39; Iter    44/ 1097] train: loss: 0.2060869
[Epoch 39; Iter    74/ 1097] train: loss: 0.2365381
[Epoch 39; Iter   104/ 1097] train: loss: 0.0633461
[Epoch 39; Iter   134/ 1097] train: loss: 0.0288575
[Epoch 39; Iter   164/ 1097] train: loss: 0.0714422
[Epoch 39; Iter   194/ 1097] train: loss: 0.0892286
[Epoch 39; Iter   224/ 1097] train: loss: 0.0188015
[Epoch 39; Iter   254/ 1097] train: loss: 0.0195136
[Epoch 39; Iter   284/ 1097] train: loss: 0.1692029
[Epoch 39; Iter   314/ 1097] train: loss: 0.0204155
[Epoch 39; Iter   344/ 1097] train: loss: 0.0145778
[Epoch 39; Iter   374/ 1097] train: loss: 0.0633389
[Epoch 39; Iter   404/ 1097] train: loss: 0.0230239
[Epoch 39; Iter   434/ 1097] train: loss: 0.0724463
[Epoch 39; Iter   464/ 1097] train: loss: 0.0467968
[Epoch 39; Iter   494/ 1097] train: loss: 0.0233893
[Epoch 39; Iter   524/ 1097] train: loss: 0.0912528
[Epoch 39; Iter   554/ 1097] train: loss: 0.0515081
[Epoch 39; Iter   584/ 1097] train: loss: 0.0219372
[Epoch 39; Iter   614/ 1097] train: loss: 0.3167893
[Epoch 39; Iter   644/ 1097] train: loss: 0.0832172
[Epoch 39; Iter   674/ 1097] train: loss: 0.0423299
[Epoch 39; Iter   704/ 1097] train: loss: 0.1241008
[Epoch 39; Iter   734/ 1097] train: loss: 0.0279870
[Epoch 39; Iter   764/ 1097] train: loss: 0.0194915
[Epoch 39; Iter   794/ 1097] train: loss: 0.0131453
[Epoch 39; Iter   824/ 1097] train: loss: 0.0200289
[Epoch 39; Iter   854/ 1097] train: loss: 0.1206635
[Epoch 39; Iter   884/ 1097] train: loss: 0.0151772
[Epoch 39; Iter   914/ 1097] train: loss: 0.1750763
[Epoch 39; Iter   944/ 1097] train: loss: 0.1077039
[Epoch 39; Iter   974/ 1097] train: loss: 0.0958341
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0236697
[Epoch 39; Iter  1034/ 1097] train: loss: 0.1108683
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0371110
[Epoch 39; Iter  1094/ 1097] train: loss: 0.0654218
[Epoch 39] ogbg-molhiv: 0.803127 val loss: 0.164868
[Epoch 39] ogbg-molhiv: 0.758698 test loss: 0.249691
[Epoch 40; Iter    27/ 1097] train: loss: 0.1013294
[Epoch 40; Iter    57/ 1097] train: loss: 0.1805120
[Epoch 40; Iter    87/ 1097] train: loss: 0.2217016
[Epoch 40; Iter   117/ 1097] train: loss: 0.0152559
[Epoch 40; Iter   147/ 1097] train: loss: 0.0368441
[Epoch 40; Iter   177/ 1097] train: loss: 0.0603476
[Epoch 40; Iter   207/ 1097] train: loss: 0.2330886
[Epoch 40; Iter   237/ 1097] train: loss: 0.0686848
[Epoch 40; Iter   267/ 1097] train: loss: 0.1246214
[Epoch 40; Iter   297/ 1097] train: loss: 0.2177535
[Epoch 40; Iter   327/ 1097] train: loss: 0.2781167
[Epoch 40; Iter   357/ 1097] train: loss: 0.0377812
[Epoch 40; Iter   387/ 1097] train: loss: 0.0208070
[Epoch 40; Iter   417/ 1097] train: loss: 0.1923930
[Epoch 40; Iter   447/ 1097] train: loss: 0.0187770
[Epoch 40; Iter   477/ 1097] train: loss: 0.1988180
[Epoch 40; Iter   507/ 1097] train: loss: 0.0176383
[Epoch 40; Iter   537/ 1097] train: loss: 0.0736141
[Epoch 40; Iter   567/ 1097] train: loss: 0.0551032
[Epoch 40; Iter   597/ 1097] train: loss: 0.0238992
[Epoch 40; Iter   627/ 1097] train: loss: 0.0646004
[Epoch 40; Iter   657/ 1097] train: loss: 0.1580459
[Epoch 40; Iter   687/ 1097] train: loss: 0.0682096
[Epoch 36; Iter   635/ 1097] train: loss: 0.0218368
[Epoch 36; Iter   665/ 1097] train: loss: 0.0890739
[Epoch 36; Iter   695/ 1097] train: loss: 0.3547428
[Epoch 36; Iter   725/ 1097] train: loss: 0.0331863
[Epoch 36; Iter   755/ 1097] train: loss: 0.0173232
[Epoch 36; Iter   785/ 1097] train: loss: 0.0150493
[Epoch 36; Iter   815/ 1097] train: loss: 0.0133686
[Epoch 36; Iter   845/ 1097] train: loss: 0.0234181
[Epoch 36; Iter   875/ 1097] train: loss: 0.0213639
[Epoch 36; Iter   905/ 1097] train: loss: 0.1206979
[Epoch 36; Iter   935/ 1097] train: loss: 0.1735412
[Epoch 36; Iter   965/ 1097] train: loss: 0.0308910
[Epoch 36; Iter   995/ 1097] train: loss: 0.0218011
[Epoch 36; Iter  1025/ 1097] train: loss: 0.0391813
[Epoch 36; Iter  1055/ 1097] train: loss: 0.1563357
[Epoch 36; Iter  1085/ 1097] train: loss: 0.1835256
[Epoch 36] ogbg-molhiv: 0.813272 val loss: 0.102222
[Epoch 36] ogbg-molhiv: 0.757268 test loss: 0.456739
[Epoch 37; Iter    18/ 1097] train: loss: 0.0336496
[Epoch 37; Iter    48/ 1097] train: loss: 0.0119731
[Epoch 37; Iter    78/ 1097] train: loss: 0.0450694
[Epoch 37; Iter   108/ 1097] train: loss: 0.0200999
[Epoch 37; Iter   138/ 1097] train: loss: 0.1377966
[Epoch 37; Iter   168/ 1097] train: loss: 0.0567208
[Epoch 37; Iter   198/ 1097] train: loss: 0.0168021
[Epoch 37; Iter   228/ 1097] train: loss: 0.0173442
[Epoch 37; Iter   258/ 1097] train: loss: 0.0637577
[Epoch 37; Iter   288/ 1097] train: loss: 0.0102035
[Epoch 37; Iter   318/ 1097] train: loss: 0.0128013
[Epoch 37; Iter   348/ 1097] train: loss: 0.0094413
[Epoch 37; Iter   378/ 1097] train: loss: 0.1841141
[Epoch 37; Iter   408/ 1097] train: loss: 0.1467428
[Epoch 37; Iter   438/ 1097] train: loss: 0.0641608
[Epoch 37; Iter   468/ 1097] train: loss: 0.0160017
[Epoch 37; Iter   498/ 1097] train: loss: 0.0450300
[Epoch 37; Iter   528/ 1097] train: loss: 0.0201316
[Epoch 37; Iter   558/ 1097] train: loss: 0.0685339
[Epoch 37; Iter   588/ 1097] train: loss: 0.0365913
[Epoch 37; Iter   618/ 1097] train: loss: 0.1583209
[Epoch 37; Iter   648/ 1097] train: loss: 0.0374885
[Epoch 37; Iter   678/ 1097] train: loss: 0.0898061
[Epoch 37; Iter   708/ 1097] train: loss: 0.0235196
[Epoch 37; Iter   738/ 1097] train: loss: 0.0109618
[Epoch 37; Iter   768/ 1097] train: loss: 0.0709190
[Epoch 37; Iter   798/ 1097] train: loss: 0.1166238
[Epoch 37; Iter   828/ 1097] train: loss: 0.0123999
[Epoch 37; Iter   858/ 1097] train: loss: 0.0185759
[Epoch 37; Iter   888/ 1097] train: loss: 0.0142703
[Epoch 37; Iter   918/ 1097] train: loss: 0.2161033
[Epoch 37; Iter   948/ 1097] train: loss: 0.0433166
[Epoch 37; Iter   978/ 1097] train: loss: 0.2032759
[Epoch 37; Iter  1008/ 1097] train: loss: 0.0135489
[Epoch 37; Iter  1038/ 1097] train: loss: 0.0181038
[Epoch 37; Iter  1068/ 1097] train: loss: 0.0684910
[Epoch 37] ogbg-molhiv: 0.798532 val loss: 0.314466
[Epoch 37] ogbg-molhiv: 0.753628 test loss: 0.776911
[Epoch 38; Iter     1/ 1097] train: loss: 0.0361938
[Epoch 38; Iter    31/ 1097] train: loss: 0.0075873
[Epoch 38; Iter    61/ 1097] train: loss: 0.2260159
[Epoch 38; Iter    91/ 1097] train: loss: 0.1517890
[Epoch 38; Iter   121/ 1097] train: loss: 0.0100514
[Epoch 38; Iter   151/ 1097] train: loss: 0.0131588
[Epoch 38; Iter   181/ 1097] train: loss: 0.0648134
[Epoch 38; Iter   211/ 1097] train: loss: 0.0129045
[Epoch 38; Iter   241/ 1097] train: loss: 0.1141055
[Epoch 38; Iter   271/ 1097] train: loss: 0.0161827
[Epoch 38; Iter   301/ 1097] train: loss: 0.2324508
[Epoch 38; Iter   331/ 1097] train: loss: 0.2194939
[Epoch 38; Iter   361/ 1097] train: loss: 0.0190431
[Epoch 38; Iter   391/ 1097] train: loss: 0.0210684
[Epoch 38; Iter   421/ 1097] train: loss: 0.0958697
[Epoch 38; Iter   451/ 1097] train: loss: 0.0268323
[Epoch 38; Iter   481/ 1097] train: loss: 0.0565764
[Epoch 38; Iter   511/ 1097] train: loss: 0.0847661
[Epoch 38; Iter   541/ 1097] train: loss: 0.0501563
[Epoch 38; Iter   571/ 1097] train: loss: 0.0220618
[Epoch 38; Iter   601/ 1097] train: loss: 0.2267798
[Epoch 38; Iter   631/ 1097] train: loss: 0.1995584
[Epoch 38; Iter   661/ 1097] train: loss: 0.0365516
[Epoch 38; Iter   691/ 1097] train: loss: 0.0678437
[Epoch 38; Iter   721/ 1097] train: loss: 0.1566347
[Epoch 38; Iter   751/ 1097] train: loss: 0.0243820
[Epoch 38; Iter   781/ 1097] train: loss: 0.1482550
[Epoch 38; Iter   811/ 1097] train: loss: 0.1149666
[Epoch 38; Iter   841/ 1097] train: loss: 0.1558592
[Epoch 38; Iter   871/ 1097] train: loss: 0.0265877
[Epoch 38; Iter   901/ 1097] train: loss: 0.0190616
[Epoch 38; Iter   931/ 1097] train: loss: 0.0606164
[Epoch 38; Iter   961/ 1097] train: loss: 0.0171384
[Epoch 38; Iter   991/ 1097] train: loss: 0.0276866
[Epoch 38; Iter  1021/ 1097] train: loss: 0.0237942
[Epoch 38; Iter  1051/ 1097] train: loss: 0.0309581
[Epoch 38; Iter  1081/ 1097] train: loss: 0.0308407
[Epoch 38] ogbg-molhiv: 0.815942 val loss: 0.081258
[Epoch 38] ogbg-molhiv: 0.768555 test loss: 0.283499
[Epoch 39; Iter    14/ 1097] train: loss: 0.1688989
[Epoch 39; Iter    44/ 1097] train: loss: 0.2829925
[Epoch 39; Iter    74/ 1097] train: loss: 0.0373922
[Epoch 39; Iter   104/ 1097] train: loss: 0.0212329
[Epoch 39; Iter   134/ 1097] train: loss: 0.0158862
[Epoch 39; Iter   164/ 1097] train: loss: 0.2390833
[Epoch 39; Iter   194/ 1097] train: loss: 0.0193651
[Epoch 39; Iter   224/ 1097] train: loss: 0.0302463
[Epoch 39; Iter   254/ 1097] train: loss: 0.0840529
[Epoch 39; Iter   284/ 1097] train: loss: 0.0366496
[Epoch 39; Iter   314/ 1097] train: loss: 0.0921090
[Epoch 39; Iter   344/ 1097] train: loss: 0.0666263
[Epoch 39; Iter   374/ 1097] train: loss: 0.0082963
[Epoch 39; Iter   404/ 1097] train: loss: 0.1289169
[Epoch 39; Iter   434/ 1097] train: loss: 0.0100059
[Epoch 39; Iter   464/ 1097] train: loss: 0.1283828
[Epoch 39; Iter   494/ 1097] train: loss: 0.0637188
[Epoch 39; Iter   524/ 1097] train: loss: 0.0243782
[Epoch 39; Iter   554/ 1097] train: loss: 0.0409865
[Epoch 39; Iter   584/ 1097] train: loss: 0.0251677
[Epoch 39; Iter   614/ 1097] train: loss: 0.0597832
[Epoch 39; Iter   644/ 1097] train: loss: 0.0617745
[Epoch 39; Iter   674/ 1097] train: loss: 0.0697534
[Epoch 39; Iter   704/ 1097] train: loss: 0.1486835
[Epoch 39; Iter   734/ 1097] train: loss: 0.0109186
[Epoch 39; Iter   764/ 1097] train: loss: 0.2037873
[Epoch 39; Iter   794/ 1097] train: loss: 0.0816992
[Epoch 39; Iter   824/ 1097] train: loss: 0.1395824
[Epoch 39; Iter   854/ 1097] train: loss: 0.0493403
[Epoch 39; Iter   884/ 1097] train: loss: 0.0196614
[Epoch 39; Iter   914/ 1097] train: loss: 0.0470641
[Epoch 39; Iter   944/ 1097] train: loss: 0.0490162
[Epoch 39; Iter   974/ 1097] train: loss: 0.0540188
[Epoch 39; Iter  1004/ 1097] train: loss: 0.0470870
[Epoch 39; Iter  1034/ 1097] train: loss: 0.0203458
[Epoch 39; Iter  1064/ 1097] train: loss: 0.0138430
[Epoch 39; Iter  1094/ 1097] train: loss: 0.1330855
[Epoch 39] ogbg-molhiv: 0.806128 val loss: 0.102226
[Epoch 39] ogbg-molhiv: 0.755389 test loss: 0.369137
[Epoch 40; Iter    27/ 1097] train: loss: 0.1781709
[Epoch 40; Iter    57/ 1097] train: loss: 0.0349325
[Epoch 40; Iter    87/ 1097] train: loss: 0.0466141
[Epoch 40; Iter   117/ 1097] train: loss: 0.1962736
[Epoch 40; Iter   147/ 1097] train: loss: 0.0435533
[Epoch 40; Iter   177/ 1097] train: loss: 0.0228261
[Epoch 40; Iter   207/ 1097] train: loss: 0.1096773
[Epoch 40; Iter   237/ 1097] train: loss: 0.0405720
[Epoch 40; Iter   267/ 1097] train: loss: 0.2528639
[Epoch 40; Iter   297/ 1097] train: loss: 0.0998236
[Epoch 40; Iter   327/ 1097] train: loss: 0.0504341
[Epoch 40; Iter   357/ 1097] train: loss: 0.2022885
[Epoch 40; Iter   387/ 1097] train: loss: 0.0995839
[Epoch 40; Iter   417/ 1097] train: loss: 0.1011667
[Epoch 40; Iter   447/ 1097] train: loss: 0.1580512
[Epoch 40; Iter   477/ 1097] train: loss: 0.0132671
[Epoch 40; Iter   507/ 1097] train: loss: 0.1018704
[Epoch 40; Iter   537/ 1097] train: loss: 0.0745772
[Epoch 40; Iter   567/ 1097] train: loss: 0.0244401
[Epoch 40; Iter   597/ 1097] train: loss: 0.0356005
[Epoch 40; Iter   627/ 1097] train: loss: 0.0111648
[Epoch 40; Iter   657/ 1097] train: loss: 0.0961781
[Epoch 40; Iter   687/ 1097] train: loss: 0.0265341
[Epoch 42; Iter   187/  823] train: loss: 0.0384565
[Epoch 42; Iter   217/  823] train: loss: 0.0104134
[Epoch 42; Iter   247/  823] train: loss: 0.0195148
[Epoch 42; Iter   277/  823] train: loss: 0.1011804
[Epoch 42; Iter   307/  823] train: loss: 0.0335371
[Epoch 42; Iter   337/  823] train: loss: 0.0735103
[Epoch 42; Iter   367/  823] train: loss: 0.1433101
[Epoch 42; Iter   397/  823] train: loss: 0.0993194
[Epoch 42; Iter   427/  823] train: loss: 0.0291290
[Epoch 42; Iter   457/  823] train: loss: 0.0373248
[Epoch 42; Iter   487/  823] train: loss: 0.0134254
[Epoch 42; Iter   517/  823] train: loss: 0.0150162
[Epoch 42; Iter   547/  823] train: loss: 0.0678626
[Epoch 42; Iter   577/  823] train: loss: 0.1969985
[Epoch 42; Iter   607/  823] train: loss: 0.0148095
[Epoch 42; Iter   637/  823] train: loss: 0.0247778
[Epoch 42; Iter   667/  823] train: loss: 0.0734498
[Epoch 42; Iter   697/  823] train: loss: 0.0287319
[Epoch 42; Iter   727/  823] train: loss: 0.0310345
[Epoch 42; Iter   757/  823] train: loss: 0.1575996
[Epoch 42; Iter   787/  823] train: loss: 0.0404751
[Epoch 42; Iter   817/  823] train: loss: 0.0108580
[Epoch 42] ogbg-molhiv: 0.718682 val loss: 0.168110
[Epoch 42] ogbg-molhiv: 0.761283 test loss: 0.275570
[Epoch 43; Iter    24/  823] train: loss: 0.1589585
[Epoch 43; Iter    54/  823] train: loss: 0.0125865
[Epoch 43; Iter    84/  823] train: loss: 0.1056515
[Epoch 43; Iter   114/  823] train: loss: 0.0690984
[Epoch 43; Iter   144/  823] train: loss: 0.0325575
[Epoch 43; Iter   174/  823] train: loss: 0.0739061
[Epoch 43; Iter   204/  823] train: loss: 0.1624010
[Epoch 43; Iter   234/  823] train: loss: 0.2173906
[Epoch 43; Iter   264/  823] train: loss: 0.0077919
[Epoch 43; Iter   294/  823] train: loss: 0.1059870
[Epoch 43; Iter   324/  823] train: loss: 0.1952652
[Epoch 43; Iter   354/  823] train: loss: 0.1735502
[Epoch 43; Iter   384/  823] train: loss: 0.0935712
[Epoch 43; Iter   414/  823] train: loss: 0.0502692
[Epoch 43; Iter   444/  823] train: loss: 0.1088111
[Epoch 43; Iter   474/  823] train: loss: 0.1167892
[Epoch 43; Iter   504/  823] train: loss: 0.1332387
[Epoch 43; Iter   534/  823] train: loss: 0.0328272
[Epoch 43; Iter   564/  823] train: loss: 0.2605456
[Epoch 43; Iter   594/  823] train: loss: 0.0263972
[Epoch 43; Iter   624/  823] train: loss: 0.0302278
[Epoch 43; Iter   654/  823] train: loss: 0.0224785
[Epoch 43; Iter   684/  823] train: loss: 0.0307812
[Epoch 43; Iter   714/  823] train: loss: 0.0246996
[Epoch 43; Iter   744/  823] train: loss: 0.0381091
[Epoch 43; Iter   774/  823] train: loss: 0.0681028
[Epoch 43; Iter   804/  823] train: loss: 0.0176346
[Epoch 43] ogbg-molhiv: 0.726011 val loss: 0.153674
[Epoch 43] ogbg-molhiv: 0.767135 test loss: 0.224901
[Epoch 44; Iter    11/  823] train: loss: 0.0311592
[Epoch 44; Iter    41/  823] train: loss: 0.0142761
[Epoch 44; Iter    71/  823] train: loss: 0.1737920
[Epoch 44; Iter   101/  823] train: loss: 0.0318396
[Epoch 44; Iter   131/  823] train: loss: 0.0130892
[Epoch 44; Iter   161/  823] train: loss: 0.0213259
[Epoch 44; Iter   191/  823] train: loss: 0.1115732
[Epoch 44; Iter   221/  823] train: loss: 0.0160470
[Epoch 44; Iter   251/  823] train: loss: 0.4454260
[Epoch 44; Iter   281/  823] train: loss: 0.0418265
[Epoch 44; Iter   311/  823] train: loss: 0.0188514
[Epoch 44; Iter   341/  823] train: loss: 0.0856265
[Epoch 44; Iter   371/  823] train: loss: 0.1847688
[Epoch 44; Iter   401/  823] train: loss: 0.2320012
[Epoch 44; Iter   431/  823] train: loss: 0.0365666
[Epoch 44; Iter   461/  823] train: loss: 0.0261255
[Epoch 44; Iter   491/  823] train: loss: 0.1253104
[Epoch 44; Iter   521/  823] train: loss: 0.0376086
[Epoch 44; Iter   551/  823] train: loss: 0.1191501
[Epoch 44; Iter   581/  823] train: loss: 0.1381375
[Epoch 44; Iter   611/  823] train: loss: 0.1920186
[Epoch 44; Iter   641/  823] train: loss: 0.0150740
[Epoch 44; Iter   671/  823] train: loss: 0.0529150
[Epoch 44; Iter   701/  823] train: loss: 0.0997183
[Epoch 44; Iter   731/  823] train: loss: 0.0802360
[Epoch 44; Iter   761/  823] train: loss: 0.0674009
[Epoch 44; Iter   791/  823] train: loss: 0.0662778
[Epoch 44; Iter   821/  823] train: loss: 0.1308303
[Epoch 44] ogbg-molhiv: 0.720969 val loss: 0.253348
[Epoch 44] ogbg-molhiv: 0.760562 test loss: 0.673354
[Epoch 45; Iter    28/  823] train: loss: 0.0450548
[Epoch 45; Iter    58/  823] train: loss: 0.0306555
[Epoch 45; Iter    88/  823] train: loss: 0.0171499
[Epoch 45; Iter   118/  823] train: loss: 0.1915377
[Epoch 45; Iter   148/  823] train: loss: 0.0134337
[Epoch 45; Iter   178/  823] train: loss: 0.0205835
[Epoch 45; Iter   208/  823] train: loss: 0.0815086
[Epoch 45; Iter   238/  823] train: loss: 0.0496280
[Epoch 45; Iter   268/  823] train: loss: 0.0637560
[Epoch 45; Iter   298/  823] train: loss: 0.0227224
[Epoch 45; Iter   328/  823] train: loss: 0.1333329
[Epoch 45; Iter   358/  823] train: loss: 0.0198818
[Epoch 45; Iter   388/  823] train: loss: 0.0271819
[Epoch 45; Iter   418/  823] train: loss: 0.0119301
[Epoch 45; Iter   448/  823] train: loss: 0.0137711
[Epoch 45; Iter   478/  823] train: loss: 0.0541494
[Epoch 45; Iter   508/  823] train: loss: 0.0086817
[Epoch 45; Iter   538/  823] train: loss: 0.0137708
[Epoch 45; Iter   568/  823] train: loss: 0.1523457
[Epoch 45; Iter   598/  823] train: loss: 0.1359722
[Epoch 45; Iter   628/  823] train: loss: 0.1017861
[Epoch 45; Iter   658/  823] train: loss: 0.1312164
[Epoch 45; Iter   688/  823] train: loss: 0.0206317
[Epoch 45; Iter   718/  823] train: loss: 0.0985819
[Epoch 45; Iter   748/  823] train: loss: 0.1612520
[Epoch 45; Iter   778/  823] train: loss: 0.0203408
[Epoch 45; Iter   808/  823] train: loss: 0.0396801
[Epoch 45] ogbg-molhiv: 0.726445 val loss: 0.310022
[Epoch 45] ogbg-molhiv: 0.757980 test loss: 0.893346
[Epoch 46; Iter    15/  823] train: loss: 0.0418593
[Epoch 46; Iter    45/  823] train: loss: 0.0258986
[Epoch 46; Iter    75/  823] train: loss: 0.0879962
[Epoch 46; Iter   105/  823] train: loss: 0.1069857
[Epoch 46; Iter   135/  823] train: loss: 0.0338621
[Epoch 46; Iter   165/  823] train: loss: 0.0136038
[Epoch 46; Iter   195/  823] train: loss: 0.0704339
[Epoch 46; Iter   225/  823] train: loss: 0.0279703
[Epoch 46; Iter   255/  823] train: loss: 0.0515755
[Epoch 46; Iter   285/  823] train: loss: 0.0193351
[Epoch 46; Iter   315/  823] train: loss: 0.0486771
[Epoch 46; Iter   345/  823] train: loss: 0.0877223
[Epoch 46; Iter   375/  823] train: loss: 0.0772483
[Epoch 46; Iter   405/  823] train: loss: 0.1848792
[Epoch 46; Iter   435/  823] train: loss: 0.0696265
[Epoch 46; Iter   465/  823] train: loss: 0.1273725
[Epoch 46; Iter   495/  823] train: loss: 0.1790814
[Epoch 46; Iter   525/  823] train: loss: 0.0187771
[Epoch 46; Iter   555/  823] train: loss: 0.1911277
[Epoch 46; Iter   585/  823] train: loss: 0.0754123
[Epoch 46; Iter   615/  823] train: loss: 0.0220887
[Epoch 46; Iter   645/  823] train: loss: 0.0689482
[Epoch 46; Iter   675/  823] train: loss: 0.0503709
[Epoch 46; Iter   705/  823] train: loss: 0.0095410
[Epoch 46; Iter   735/  823] train: loss: 0.0126459
[Epoch 46; Iter   765/  823] train: loss: 0.0274552
[Epoch 46; Iter   795/  823] train: loss: 0.0145751
[Epoch 46] ogbg-molhiv: 0.724823 val loss: 0.174632
[Epoch 46] ogbg-molhiv: 0.768606 test loss: 0.359547
[Epoch 47; Iter     2/  823] train: loss: 0.0610498
[Epoch 47; Iter    32/  823] train: loss: 0.0809531
[Epoch 47; Iter    62/  823] train: loss: 0.0788093
[Epoch 47; Iter    92/  823] train: loss: 0.0206645
[Epoch 47; Iter   122/  823] train: loss: 0.1111920
[Epoch 47; Iter   152/  823] train: loss: 0.0652843
[Epoch 47; Iter   182/  823] train: loss: 0.0280870
[Epoch 47; Iter   212/  823] train: loss: 0.2885255
[Epoch 47; Iter   242/  823] train: loss: 0.0630936
[Epoch 47; Iter   272/  823] train: loss: 0.1025077
[Epoch 47; Iter   302/  823] train: loss: 0.0402174
[Epoch 47; Iter   332/  823] train: loss: 0.0428931
[Epoch 47; Iter   362/  823] train: loss: 0.0085201
[Epoch 47; Iter   392/  823] train: loss: 0.4084514
[Epoch 47; Iter   422/  823] train: loss: 0.0163698
[Epoch 47; Iter   452/  823] train: loss: 0.0668697
[Epoch 41; Iter   330/  960] train: loss: 0.1061918
[Epoch 41; Iter   360/  960] train: loss: 0.1252353
[Epoch 41; Iter   390/  960] train: loss: 0.2541567
[Epoch 41; Iter   420/  960] train: loss: 0.0275814
[Epoch 41; Iter   450/  960] train: loss: 0.0153949
[Epoch 41; Iter   480/  960] train: loss: 0.0348733
[Epoch 41; Iter   510/  960] train: loss: 0.1803379
[Epoch 41; Iter   540/  960] train: loss: 0.0206083
[Epoch 41; Iter   570/  960] train: loss: 0.0125597
[Epoch 41; Iter   600/  960] train: loss: 0.0324418
[Epoch 41; Iter   630/  960] train: loss: 0.0209995
[Epoch 41; Iter   660/  960] train: loss: 0.0109700
[Epoch 41; Iter   690/  960] train: loss: 0.1242198
[Epoch 41; Iter   720/  960] train: loss: 0.0203609
[Epoch 41; Iter   750/  960] train: loss: 0.0525699
[Epoch 41; Iter   780/  960] train: loss: 0.1947547
[Epoch 41; Iter   810/  960] train: loss: 0.1284222
[Epoch 41; Iter   840/  960] train: loss: 0.0444401
[Epoch 41; Iter   870/  960] train: loss: 0.3209920
[Epoch 41; Iter   900/  960] train: loss: 0.1256270
[Epoch 41; Iter   930/  960] train: loss: 0.1452183
[Epoch 41; Iter   960/  960] train: loss: 0.0354025
[Epoch 41] ogbg-molhiv: 0.753733 val loss: 0.157393
[Epoch 41] ogbg-molhiv: 0.765642 test loss: 0.122331
[Epoch 42; Iter    30/  960] train: loss: 0.0692720
[Epoch 42; Iter    60/  960] train: loss: 0.1954447
[Epoch 42; Iter    90/  960] train: loss: 0.1370099
[Epoch 42; Iter   120/  960] train: loss: 0.1172893
[Epoch 42; Iter   150/  960] train: loss: 0.0226325
[Epoch 42; Iter   180/  960] train: loss: 0.0333054
[Epoch 42; Iter   210/  960] train: loss: 0.0630540
[Epoch 42; Iter   240/  960] train: loss: 0.0524309
[Epoch 42; Iter   270/  960] train: loss: 0.0163408
[Epoch 42; Iter   300/  960] train: loss: 0.0766187
[Epoch 42; Iter   330/  960] train: loss: 0.0176347
[Epoch 42; Iter   360/  960] train: loss: 0.1951521
[Epoch 42; Iter   390/  960] train: loss: 0.0830795
[Epoch 42; Iter   420/  960] train: loss: 0.0136836
[Epoch 42; Iter   450/  960] train: loss: 0.0275528
[Epoch 42; Iter   480/  960] train: loss: 0.0100744
[Epoch 42; Iter   510/  960] train: loss: 0.0564076
[Epoch 42; Iter   540/  960] train: loss: 0.1068909
[Epoch 42; Iter   570/  960] train: loss: 0.0967914
[Epoch 42; Iter   600/  960] train: loss: 0.0209861
[Epoch 42; Iter   630/  960] train: loss: 0.0189205
[Epoch 42; Iter   660/  960] train: loss: 0.0208614
[Epoch 42; Iter   690/  960] train: loss: 0.0108720
[Epoch 42; Iter   720/  960] train: loss: 0.0979821
[Epoch 42; Iter   750/  960] train: loss: 0.0717055
[Epoch 42; Iter   780/  960] train: loss: 0.0542691
[Epoch 42; Iter   810/  960] train: loss: 0.1054120
[Epoch 42; Iter   840/  960] train: loss: 0.0615128
[Epoch 42; Iter   870/  960] train: loss: 0.0162385
[Epoch 42; Iter   900/  960] train: loss: 0.2858331
[Epoch 42; Iter   930/  960] train: loss: 0.0716399
[Epoch 42; Iter   960/  960] train: loss: 0.0126870
[Epoch 42] ogbg-molhiv: 0.746663 val loss: 0.225642
[Epoch 42] ogbg-molhiv: 0.752314 test loss: 0.146696
[Epoch 43; Iter    30/  960] train: loss: 0.0708241
[Epoch 43; Iter    60/  960] train: loss: 0.0241336
[Epoch 43; Iter    90/  960] train: loss: 0.0415435
[Epoch 43; Iter   120/  960] train: loss: 0.0612960
[Epoch 43; Iter   150/  960] train: loss: 0.1860860
[Epoch 43; Iter   180/  960] train: loss: 0.1604964
[Epoch 43; Iter   210/  960] train: loss: 0.2036484
[Epoch 43; Iter   240/  960] train: loss: 0.0223954
[Epoch 43; Iter   270/  960] train: loss: 0.0155148
[Epoch 43; Iter   300/  960] train: loss: 0.1255604
[Epoch 43; Iter   330/  960] train: loss: 0.0528763
[Epoch 43; Iter   360/  960] train: loss: 0.0462372
[Epoch 43; Iter   390/  960] train: loss: 0.1306834
[Epoch 43; Iter   420/  960] train: loss: 0.0594939
[Epoch 43; Iter   450/  960] train: loss: 0.0325605
[Epoch 43; Iter   480/  960] train: loss: 0.0336848
[Epoch 43; Iter   510/  960] train: loss: 0.0647708
[Epoch 43; Iter   540/  960] train: loss: 0.0127378
[Epoch 43; Iter   570/  960] train: loss: 0.0105276
[Epoch 43; Iter   600/  960] train: loss: 0.0884127
[Epoch 43; Iter   630/  960] train: loss: 0.0336942
[Epoch 43; Iter   660/  960] train: loss: 0.0321348
[Epoch 43; Iter   690/  960] train: loss: 0.2100676
[Epoch 43; Iter   720/  960] train: loss: 0.2913540
[Epoch 43; Iter   750/  960] train: loss: 0.0294410
[Epoch 43; Iter   780/  960] train: loss: 0.0113881
[Epoch 43; Iter   810/  960] train: loss: 0.1862048
[Epoch 43; Iter   840/  960] train: loss: 0.0664132
[Epoch 43; Iter   870/  960] train: loss: 0.0122447
[Epoch 43; Iter   900/  960] train: loss: 0.0803689
[Epoch 43; Iter   930/  960] train: loss: 0.0450377
[Epoch 43; Iter   960/  960] train: loss: 0.0280459
[Epoch 43] ogbg-molhiv: 0.742658 val loss: 0.154466
[Epoch 43] ogbg-molhiv: 0.739541 test loss: 0.124511
[Epoch 44; Iter    30/  960] train: loss: 0.0929371
[Epoch 44; Iter    60/  960] train: loss: 0.0171783
[Epoch 44; Iter    90/  960] train: loss: 0.1103939
[Epoch 44; Iter   120/  960] train: loss: 0.0691753
[Epoch 44; Iter   150/  960] train: loss: 0.1226679
[Epoch 44; Iter   180/  960] train: loss: 0.0489245
[Epoch 44; Iter   210/  960] train: loss: 0.0545114
[Epoch 44; Iter   240/  960] train: loss: 0.1020518
[Epoch 44; Iter   270/  960] train: loss: 0.0311496
[Epoch 44; Iter   300/  960] train: loss: 0.0169037
[Epoch 44; Iter   330/  960] train: loss: 0.0092189
[Epoch 44; Iter   360/  960] train: loss: 0.1612211
[Epoch 44; Iter   390/  960] train: loss: 0.0279047
[Epoch 44; Iter   420/  960] train: loss: 0.0422639
[Epoch 44; Iter   450/  960] train: loss: 0.0135910
[Epoch 44; Iter   480/  960] train: loss: 0.0112682
[Epoch 44; Iter   510/  960] train: loss: 0.0141467
[Epoch 44; Iter   540/  960] train: loss: 0.0047290
[Epoch 44; Iter   570/  960] train: loss: 0.1907912
[Epoch 44; Iter   600/  960] train: loss: 0.0143913
[Epoch 44; Iter   630/  960] train: loss: 0.0120534
[Epoch 44; Iter   660/  960] train: loss: 0.0401602
[Epoch 44; Iter   690/  960] train: loss: 0.0301319
[Epoch 44; Iter   720/  960] train: loss: 0.0802446
[Epoch 44; Iter   750/  960] train: loss: 0.0176807
[Epoch 44; Iter   780/  960] train: loss: 0.0414338
[Epoch 44; Iter   810/  960] train: loss: 0.1009782
[Epoch 44; Iter   840/  960] train: loss: 0.0420191
[Epoch 44; Iter   870/  960] train: loss: 0.1140731
[Epoch 44; Iter   900/  960] train: loss: 0.0344817
[Epoch 44; Iter   930/  960] train: loss: 0.0223553
[Epoch 44; Iter   960/  960] train: loss: 0.1585162
[Epoch 44] ogbg-molhiv: 0.742856 val loss: 0.178714
[Epoch 44] ogbg-molhiv: 0.739851 test loss: 0.225452
[Epoch 45; Iter    30/  960] train: loss: 0.0638012
[Epoch 45; Iter    60/  960] train: loss: 0.1122755
[Epoch 45; Iter    90/  960] train: loss: 0.0441856
[Epoch 45; Iter   120/  960] train: loss: 0.0735535
[Epoch 45; Iter   150/  960] train: loss: 0.0771535
[Epoch 45; Iter   180/  960] train: loss: 0.0197648
[Epoch 45; Iter   210/  960] train: loss: 0.0161078
[Epoch 45; Iter   240/  960] train: loss: 0.2205430
[Epoch 45; Iter   270/  960] train: loss: 0.0565625
[Epoch 45; Iter   300/  960] train: loss: 0.0213064
[Epoch 45; Iter   330/  960] train: loss: 0.0227872
[Epoch 45; Iter   360/  960] train: loss: 0.0486754
[Epoch 45; Iter   390/  960] train: loss: 0.0275537
[Epoch 45; Iter   420/  960] train: loss: 0.1606029
[Epoch 45; Iter   450/  960] train: loss: 0.0159553
[Epoch 45; Iter   480/  960] train: loss: 0.0407169
[Epoch 45; Iter   510/  960] train: loss: 0.0409765
[Epoch 45; Iter   540/  960] train: loss: 0.1594265
[Epoch 45; Iter   570/  960] train: loss: 0.0153270
[Epoch 45; Iter   600/  960] train: loss: 0.0712922
[Epoch 45; Iter   630/  960] train: loss: 0.0166816
[Epoch 45; Iter   660/  960] train: loss: 0.0632252
[Epoch 45; Iter   690/  960] train: loss: 0.1104464
[Epoch 45; Iter   720/  960] train: loss: 0.0229936
[Epoch 45; Iter   750/  960] train: loss: 0.0339434
[Epoch 45; Iter   780/  960] train: loss: 0.0355200
[Epoch 45; Iter   810/  960] train: loss: 0.0208302
[Epoch 45; Iter   840/  960] train: loss: 0.0677206
[Epoch 45; Iter   870/  960] train: loss: 0.1878818
[Epoch 45; Iter   900/  960] train: loss: 0.0277528
[Epoch 45; Iter   930/  960] train: loss: 0.0168890
[Epoch 40; Iter   717/ 1097] train: loss: 0.0742912
[Epoch 40; Iter   747/ 1097] train: loss: 0.0234448
[Epoch 40; Iter   777/ 1097] train: loss: 0.2156501
[Epoch 40; Iter   807/ 1097] train: loss: 0.0890698
[Epoch 40; Iter   837/ 1097] train: loss: 0.0199628
[Epoch 40; Iter   867/ 1097] train: loss: 0.0201368
[Epoch 40; Iter   897/ 1097] train: loss: 0.0888500
[Epoch 40; Iter   927/ 1097] train: loss: 0.2231366
[Epoch 40; Iter   957/ 1097] train: loss: 0.2734487
[Epoch 40; Iter   987/ 1097] train: loss: 0.1125462
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0194567
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0146739
[Epoch 40; Iter  1077/ 1097] train: loss: 0.1279429
[Epoch 40] ogbg-molhiv: 0.779306 val loss: 0.262367
[Epoch 40] ogbg-molhiv: 0.729218 test loss: 0.367408
[Epoch 41; Iter    10/ 1097] train: loss: 0.0228868
[Epoch 41; Iter    40/ 1097] train: loss: 0.0597487
[Epoch 41; Iter    70/ 1097] train: loss: 0.0371967
[Epoch 41; Iter   100/ 1097] train: loss: 0.0915764
[Epoch 41; Iter   130/ 1097] train: loss: 0.0429151
[Epoch 41; Iter   160/ 1097] train: loss: 0.1791833
[Epoch 41; Iter   190/ 1097] train: loss: 0.0164235
[Epoch 41; Iter   220/ 1097] train: loss: 0.0202033
[Epoch 41; Iter   250/ 1097] train: loss: 0.1808938
[Epoch 41; Iter   280/ 1097] train: loss: 0.2242823
[Epoch 41; Iter   310/ 1097] train: loss: 0.0182490
[Epoch 41; Iter   340/ 1097] train: loss: 0.3586977
[Epoch 41; Iter   370/ 1097] train: loss: 0.0237830
[Epoch 41; Iter   400/ 1097] train: loss: 0.0210110
[Epoch 41; Iter   430/ 1097] train: loss: 0.0355517
[Epoch 41; Iter   460/ 1097] train: loss: 0.0336172
[Epoch 41; Iter   490/ 1097] train: loss: 0.1504712
[Epoch 41; Iter   520/ 1097] train: loss: 0.0367991
[Epoch 41; Iter   550/ 1097] train: loss: 0.1944546
[Epoch 41; Iter   580/ 1097] train: loss: 0.0173835
[Epoch 41; Iter   610/ 1097] train: loss: 0.1490928
[Epoch 41; Iter   640/ 1097] train: loss: 0.0125033
[Epoch 41; Iter   670/ 1097] train: loss: 0.0395295
[Epoch 41; Iter   700/ 1097] train: loss: 0.0339744
[Epoch 41; Iter   730/ 1097] train: loss: 0.0261962
[Epoch 41; Iter   760/ 1097] train: loss: 0.0698188
[Epoch 41; Iter   790/ 1097] train: loss: 0.0558938
[Epoch 41; Iter   820/ 1097] train: loss: 0.0153297
[Epoch 41; Iter   850/ 1097] train: loss: 0.2262084
[Epoch 41; Iter   880/ 1097] train: loss: 0.0419895
[Epoch 41; Iter   910/ 1097] train: loss: 0.0199618
[Epoch 41; Iter   940/ 1097] train: loss: 0.1956880
[Epoch 41; Iter   970/ 1097] train: loss: 0.0249499
[Epoch 41; Iter  1000/ 1097] train: loss: 0.4046050
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0285516
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0112349
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1751267
[Epoch 41] ogbg-molhiv: 0.809851 val loss: 0.235266
[Epoch 41] ogbg-molhiv: 0.737307 test loss: 0.475323
[Epoch 42; Iter    23/ 1097] train: loss: 0.0135588
[Epoch 42; Iter    53/ 1097] train: loss: 0.0159045
[Epoch 42; Iter    83/ 1097] train: loss: 0.0352081
[Epoch 42; Iter   113/ 1097] train: loss: 0.0224333
[Epoch 42; Iter   143/ 1097] train: loss: 0.0126442
[Epoch 42; Iter   173/ 1097] train: loss: 0.0121094
[Epoch 42; Iter   203/ 1097] train: loss: 0.0173792
[Epoch 42; Iter   233/ 1097] train: loss: 0.0684829
[Epoch 42; Iter   263/ 1097] train: loss: 0.0374782
[Epoch 42; Iter   293/ 1097] train: loss: 0.0164930
[Epoch 42; Iter   323/ 1097] train: loss: 0.2512630
[Epoch 42; Iter   353/ 1097] train: loss: 0.0306390
[Epoch 42; Iter   383/ 1097] train: loss: 0.1229614
[Epoch 42; Iter   413/ 1097] train: loss: 0.2035183
[Epoch 42; Iter   443/ 1097] train: loss: 0.0161582
[Epoch 42; Iter   473/ 1097] train: loss: 0.0830320
[Epoch 42; Iter   503/ 1097] train: loss: 0.1269379
[Epoch 42; Iter   533/ 1097] train: loss: 0.1297463
[Epoch 42; Iter   563/ 1097] train: loss: 0.0193588
[Epoch 42; Iter   593/ 1097] train: loss: 0.0391843
[Epoch 42; Iter   623/ 1097] train: loss: 0.0236099
[Epoch 42; Iter   653/ 1097] train: loss: 0.0362191
[Epoch 42; Iter   683/ 1097] train: loss: 0.0717952
[Epoch 42; Iter   713/ 1097] train: loss: 0.0158839
[Epoch 42; Iter   743/ 1097] train: loss: 0.1433229
[Epoch 42; Iter   773/ 1097] train: loss: 0.0190986
[Epoch 42; Iter   803/ 1097] train: loss: 0.1022618
[Epoch 42; Iter   833/ 1097] train: loss: 0.0294687
[Epoch 42; Iter   863/ 1097] train: loss: 0.0129870
[Epoch 42; Iter   893/ 1097] train: loss: 0.0187317
[Epoch 42; Iter   923/ 1097] train: loss: 0.1801359
[Epoch 42; Iter   953/ 1097] train: loss: 0.0308973
[Epoch 42; Iter   983/ 1097] train: loss: 0.0181264
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1001623
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1182004
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0965791
[Epoch 42] ogbg-molhiv: 0.766348 val loss: 0.201296
[Epoch 42] ogbg-molhiv: 0.722874 test loss: 0.465024
[Epoch 43; Iter     6/ 1097] train: loss: 0.0227700
[Epoch 43; Iter    36/ 1097] train: loss: 0.0300348
[Epoch 43; Iter    66/ 1097] train: loss: 0.3229908
[Epoch 43; Iter    96/ 1097] train: loss: 0.0783105
[Epoch 43; Iter   126/ 1097] train: loss: 0.0240574
[Epoch 43; Iter   156/ 1097] train: loss: 0.0152346
[Epoch 43; Iter   186/ 1097] train: loss: 0.1673191
[Epoch 43; Iter   216/ 1097] train: loss: 0.0116045
[Epoch 43; Iter   246/ 1097] train: loss: 0.0159153
[Epoch 43; Iter   276/ 1097] train: loss: 0.0226526
[Epoch 43; Iter   306/ 1097] train: loss: 0.1172484
[Epoch 43; Iter   336/ 1097] train: loss: 0.0095210
[Epoch 43; Iter   366/ 1097] train: loss: 0.0264800
[Epoch 43; Iter   396/ 1097] train: loss: 0.0329504
[Epoch 43; Iter   426/ 1097] train: loss: 0.0953225
[Epoch 43; Iter   456/ 1097] train: loss: 0.0142002
[Epoch 43; Iter   486/ 1097] train: loss: 0.1607155
[Epoch 43; Iter   516/ 1097] train: loss: 0.1420588
[Epoch 43; Iter   546/ 1097] train: loss: 0.1139819
[Epoch 43; Iter   576/ 1097] train: loss: 0.0204356
[Epoch 43; Iter   606/ 1097] train: loss: 0.0894088
[Epoch 43; Iter   636/ 1097] train: loss: 0.0229846
[Epoch 43; Iter   666/ 1097] train: loss: 0.0123825
[Epoch 43; Iter   696/ 1097] train: loss: 0.0441379
[Epoch 43; Iter   726/ 1097] train: loss: 0.0159303
[Epoch 43; Iter   756/ 1097] train: loss: 0.0535032
[Epoch 43; Iter   786/ 1097] train: loss: 0.0368237
[Epoch 43; Iter   816/ 1097] train: loss: 0.1991377
[Epoch 43; Iter   846/ 1097] train: loss: 0.0802672
[Epoch 43; Iter   876/ 1097] train: loss: 0.1455279
[Epoch 43; Iter   906/ 1097] train: loss: 0.1261943
[Epoch 43; Iter   936/ 1097] train: loss: 0.2058972
[Epoch 43; Iter   966/ 1097] train: loss: 0.1247585
[Epoch 43; Iter   996/ 1097] train: loss: 0.0410008
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0892924
[Epoch 43; Iter  1056/ 1097] train: loss: 0.0179656
[Epoch 43; Iter  1086/ 1097] train: loss: 0.2021777
[Epoch 43] ogbg-molhiv: 0.772125 val loss: 0.250955
[Epoch 43] ogbg-molhiv: 0.730659 test loss: 0.377847
[Epoch 44; Iter    19/ 1097] train: loss: 0.0199132
[Epoch 44; Iter    49/ 1097] train: loss: 0.1224148
[Epoch 44; Iter    79/ 1097] train: loss: 0.0143539
[Epoch 44; Iter   109/ 1097] train: loss: 0.2350403
[Epoch 44; Iter   139/ 1097] train: loss: 0.0197477
[Epoch 44; Iter   169/ 1097] train: loss: 0.0508333
[Epoch 44; Iter   199/ 1097] train: loss: 0.2151238
[Epoch 44; Iter   229/ 1097] train: loss: 0.0928532
[Epoch 44; Iter   259/ 1097] train: loss: 0.0244594
[Epoch 44; Iter   289/ 1097] train: loss: 0.1363736
[Epoch 44; Iter   319/ 1097] train: loss: 0.1596319
[Epoch 44; Iter   349/ 1097] train: loss: 0.0267331
[Epoch 44; Iter   379/ 1097] train: loss: 0.0189820
[Epoch 44; Iter   409/ 1097] train: loss: 0.1100584
[Epoch 44; Iter   439/ 1097] train: loss: 0.0774377
[Epoch 44; Iter   469/ 1097] train: loss: 0.0164865
[Epoch 44; Iter   499/ 1097] train: loss: 0.0183158
[Epoch 44; Iter   529/ 1097] train: loss: 0.0182806
[Epoch 44; Iter   559/ 1097] train: loss: 0.0406952
[Epoch 44; Iter   589/ 1097] train: loss: 0.0205457
[Epoch 44; Iter   619/ 1097] train: loss: 0.0707513
[Epoch 44; Iter   649/ 1097] train: loss: 0.0353029
[Epoch 44; Iter   679/ 1097] train: loss: 0.2255847
[Epoch 44; Iter   709/ 1097] train: loss: 0.0571948
[Epoch 44; Iter   739/ 1097] train: loss: 0.0192455
[Epoch 44; Iter   769/ 1097] train: loss: 0.0258269
[Epoch 42; Iter   187/  823] train: loss: 0.0724913
[Epoch 42; Iter   217/  823] train: loss: 0.0111570
[Epoch 42; Iter   247/  823] train: loss: 0.0502665
[Epoch 42; Iter   277/  823] train: loss: 0.0876511
[Epoch 42; Iter   307/  823] train: loss: 0.1251801
[Epoch 42; Iter   337/  823] train: loss: 0.1348609
[Epoch 42; Iter   367/  823] train: loss: 0.0236354
[Epoch 42; Iter   397/  823] train: loss: 0.3308550
[Epoch 42; Iter   427/  823] train: loss: 0.0830189
[Epoch 42; Iter   457/  823] train: loss: 0.0081012
[Epoch 42; Iter   487/  823] train: loss: 0.1371697
[Epoch 42; Iter   517/  823] train: loss: 0.0132061
[Epoch 42; Iter   547/  823] train: loss: 0.0258992
[Epoch 42; Iter   577/  823] train: loss: 0.0774250
[Epoch 42; Iter   607/  823] train: loss: 0.0294315
[Epoch 42; Iter   637/  823] train: loss: 0.0306974
[Epoch 42; Iter   667/  823] train: loss: 0.0456074
[Epoch 42; Iter   697/  823] train: loss: 0.2221702
[Epoch 42; Iter   727/  823] train: loss: 0.1207732
[Epoch 42; Iter   757/  823] train: loss: 0.0152052
[Epoch 42; Iter   787/  823] train: loss: 0.0213358
[Epoch 42; Iter   817/  823] train: loss: 0.2195398
[Epoch 42] ogbg-molhiv: 0.711130 val loss: 0.174636
[Epoch 42] ogbg-molhiv: 0.752545 test loss: 0.146329
[Epoch 43; Iter    24/  823] train: loss: 0.0093752
[Epoch 43; Iter    54/  823] train: loss: 0.0704802
[Epoch 43; Iter    84/  823] train: loss: 0.0122625
[Epoch 43; Iter   114/  823] train: loss: 0.0214442
[Epoch 43; Iter   144/  823] train: loss: 0.0269569
[Epoch 43; Iter   174/  823] train: loss: 0.0120413
[Epoch 43; Iter   204/  823] train: loss: 0.0117164
[Epoch 43; Iter   234/  823] train: loss: 0.1332548
[Epoch 43; Iter   264/  823] train: loss: 0.0776994
[Epoch 43; Iter   294/  823] train: loss: 0.0668991
[Epoch 43; Iter   324/  823] train: loss: 0.0111705
[Epoch 43; Iter   354/  823] train: loss: 0.1954661
[Epoch 43; Iter   384/  823] train: loss: 0.0165584
[Epoch 43; Iter   414/  823] train: loss: 0.0769381
[Epoch 43; Iter   444/  823] train: loss: 0.0976941
[Epoch 43; Iter   474/  823] train: loss: 0.2587557
[Epoch 43; Iter   504/  823] train: loss: 0.1072934
[Epoch 43; Iter   534/  823] train: loss: 0.0296135
[Epoch 43; Iter   564/  823] train: loss: 0.0331620
[Epoch 43; Iter   594/  823] train: loss: 0.1097628
[Epoch 43; Iter   624/  823] train: loss: 0.0542666
[Epoch 43; Iter   654/  823] train: loss: 0.0758877
[Epoch 43; Iter   684/  823] train: loss: 0.0430609
[Epoch 43; Iter   714/  823] train: loss: 0.0732185
[Epoch 43; Iter   744/  823] train: loss: 0.0155797
[Epoch 43; Iter   774/  823] train: loss: 0.0061351
[Epoch 43; Iter   804/  823] train: loss: 0.0044615
[Epoch 43] ogbg-molhiv: 0.710969 val loss: 0.187591
[Epoch 43] ogbg-molhiv: 0.741047 test loss: 0.134845
[Epoch 44; Iter    11/  823] train: loss: 0.0452297
[Epoch 44; Iter    41/  823] train: loss: 0.0047017
[Epoch 44; Iter    71/  823] train: loss: 0.0535162
[Epoch 44; Iter   101/  823] train: loss: 0.0220393
[Epoch 44; Iter   131/  823] train: loss: 0.0122624
[Epoch 44; Iter   161/  823] train: loss: 0.0431488
[Epoch 44; Iter   191/  823] train: loss: 0.0181093
[Epoch 44; Iter   221/  823] train: loss: 0.0302598
[Epoch 44; Iter   251/  823] train: loss: 0.0548911
[Epoch 44; Iter   281/  823] train: loss: 0.0895900
[Epoch 44; Iter   311/  823] train: loss: 0.0173922
[Epoch 44; Iter   341/  823] train: loss: 0.1168200
[Epoch 44; Iter   371/  823] train: loss: 0.0411110
[Epoch 44; Iter   401/  823] train: loss: 0.0468741
[Epoch 44; Iter   431/  823] train: loss: 0.0420987
[Epoch 44; Iter   461/  823] train: loss: 0.1838221
[Epoch 44; Iter   491/  823] train: loss: 0.0338225
[Epoch 44; Iter   521/  823] train: loss: 0.0110969
[Epoch 44; Iter   551/  823] train: loss: 0.0051351
[Epoch 44; Iter   581/  823] train: loss: 0.0121305
[Epoch 44; Iter   611/  823] train: loss: 0.1347798
[Epoch 44; Iter   641/  823] train: loss: 0.0117073
[Epoch 44; Iter   671/  823] train: loss: 0.0286045
[Epoch 44; Iter   701/  823] train: loss: 0.0253634
[Epoch 44; Iter   731/  823] train: loss: 0.0509833
[Epoch 44; Iter   761/  823] train: loss: 0.0781070
[Epoch 44; Iter   791/  823] train: loss: 0.0086939
[Epoch 44; Iter   821/  823] train: loss: 0.0194341
[Epoch 44] ogbg-molhiv: 0.719606 val loss: 0.185339
[Epoch 44] ogbg-molhiv: 0.753992 test loss: 0.124443
[Epoch 45; Iter    28/  823] train: loss: 0.2652355
[Epoch 45; Iter    58/  823] train: loss: 0.0143939
[Epoch 45; Iter    88/  823] train: loss: 0.0856316
[Epoch 45; Iter   118/  823] train: loss: 0.0539116
[Epoch 45; Iter   148/  823] train: loss: 0.0063371
[Epoch 45; Iter   178/  823] train: loss: 0.0221014
[Epoch 45; Iter   208/  823] train: loss: 0.0155307
[Epoch 45; Iter   238/  823] train: loss: 0.0029557
[Epoch 45; Iter   268/  823] train: loss: 0.0610478
[Epoch 45; Iter   298/  823] train: loss: 0.1738307
[Epoch 45; Iter   328/  823] train: loss: 0.0074975
[Epoch 45; Iter   358/  823] train: loss: 0.0249873
[Epoch 45; Iter   388/  823] train: loss: 0.0335911
[Epoch 45; Iter   418/  823] train: loss: 0.0078513
[Epoch 45; Iter   448/  823] train: loss: 0.0387898
[Epoch 45; Iter   478/  823] train: loss: 0.1398308
[Epoch 45; Iter   508/  823] train: loss: 0.0437182
[Epoch 45; Iter   538/  823] train: loss: 0.0167779
[Epoch 45; Iter   568/  823] train: loss: 0.1945545
[Epoch 45; Iter   598/  823] train: loss: 0.0903042
[Epoch 45; Iter   628/  823] train: loss: 0.1711418
[Epoch 45; Iter   658/  823] train: loss: 0.0269969
[Epoch 45; Iter   688/  823] train: loss: 0.0112006
[Epoch 45; Iter   718/  823] train: loss: 0.0514198
[Epoch 45; Iter   748/  823] train: loss: 0.0652416
[Epoch 45; Iter   778/  823] train: loss: 0.0961389
[Epoch 45; Iter   808/  823] train: loss: 0.0209122
[Epoch 45] ogbg-molhiv: 0.724377 val loss: 0.194216
[Epoch 45] ogbg-molhiv: 0.747756 test loss: 0.129076
[Epoch 46; Iter    15/  823] train: loss: 0.0027884
[Epoch 46; Iter    45/  823] train: loss: 0.0228401
[Epoch 46; Iter    75/  823] train: loss: 0.1200317
[Epoch 46; Iter   105/  823] train: loss: 0.0279279
[Epoch 46; Iter   135/  823] train: loss: 0.0048733
[Epoch 46; Iter   165/  823] train: loss: 0.2761149
[Epoch 46; Iter   195/  823] train: loss: 0.1030613
[Epoch 46; Iter   225/  823] train: loss: 0.0911117
[Epoch 46; Iter   255/  823] train: loss: 0.0733264
[Epoch 46; Iter   285/  823] train: loss: 0.0782367
[Epoch 46; Iter   315/  823] train: loss: 0.0397828
[Epoch 46; Iter   345/  823] train: loss: 0.1273410
[Epoch 46; Iter   375/  823] train: loss: 0.0418053
[Epoch 46; Iter   405/  823] train: loss: 0.0405038
[Epoch 46; Iter   435/  823] train: loss: 0.1312482
[Epoch 46; Iter   465/  823] train: loss: 0.1119171
[Epoch 46; Iter   495/  823] train: loss: 0.0136324
[Epoch 46; Iter   525/  823] train: loss: 0.0184032
[Epoch 46; Iter   555/  823] train: loss: 0.0414757
[Epoch 46; Iter   585/  823] train: loss: 0.0335216
[Epoch 46; Iter   615/  823] train: loss: 0.1202620
[Epoch 46; Iter   645/  823] train: loss: 0.0202615
[Epoch 46; Iter   675/  823] train: loss: 0.0404923
[Epoch 46; Iter   705/  823] train: loss: 0.0670046
[Epoch 46; Iter   735/  823] train: loss: 0.0094703
[Epoch 46; Iter   765/  823] train: loss: 0.0693693
[Epoch 46; Iter   795/  823] train: loss: 0.1025004
[Epoch 46] ogbg-molhiv: 0.729682 val loss: 0.225425
[Epoch 46] ogbg-molhiv: 0.749748 test loss: 0.129373
[Epoch 47; Iter     2/  823] train: loss: 0.0189790
[Epoch 47; Iter    32/  823] train: loss: 0.0743537
[Epoch 47; Iter    62/  823] train: loss: 0.0114108
[Epoch 47; Iter    92/  823] train: loss: 0.0202582
[Epoch 47; Iter   122/  823] train: loss: 0.0387177
[Epoch 47; Iter   152/  823] train: loss: 0.0942564
[Epoch 47; Iter   182/  823] train: loss: 0.0223990
[Epoch 47; Iter   212/  823] train: loss: 0.0108904
[Epoch 47; Iter   242/  823] train: loss: 0.0229264
[Epoch 47; Iter   272/  823] train: loss: 0.0872174
[Epoch 47; Iter   302/  823] train: loss: 0.0112023
[Epoch 47; Iter   332/  823] train: loss: 0.0162192
[Epoch 47; Iter   362/  823] train: loss: 0.1347406
[Epoch 47; Iter   392/  823] train: loss: 0.0140284
[Epoch 47; Iter   422/  823] train: loss: 0.0082273
[Epoch 47; Iter   452/  823] train: loss: 0.2080175
[Epoch 41; Iter   330/  960] train: loss: 0.0848347
[Epoch 41; Iter   360/  960] train: loss: 0.0152757
[Epoch 41; Iter   390/  960] train: loss: 0.1110832
[Epoch 41; Iter   420/  960] train: loss: 0.0847814
[Epoch 41; Iter   450/  960] train: loss: 0.1839922
[Epoch 41; Iter   480/  960] train: loss: 0.0372370
[Epoch 41; Iter   510/  960] train: loss: 0.0135392
[Epoch 41; Iter   540/  960] train: loss: 0.1428536
[Epoch 41; Iter   570/  960] train: loss: 0.1028678
[Epoch 41; Iter   600/  960] train: loss: 0.0329753
[Epoch 41; Iter   630/  960] train: loss: 0.0143343
[Epoch 41; Iter   660/  960] train: loss: 0.0083839
[Epoch 41; Iter   690/  960] train: loss: 0.0212530
[Epoch 41; Iter   720/  960] train: loss: 0.0515089
[Epoch 41; Iter   750/  960] train: loss: 0.1541537
[Epoch 41; Iter   780/  960] train: loss: 0.0721300
[Epoch 41; Iter   810/  960] train: loss: 0.0173633
[Epoch 41; Iter   840/  960] train: loss: 0.0643195
[Epoch 41; Iter   870/  960] train: loss: 0.0752020
[Epoch 41; Iter   900/  960] train: loss: 0.0109486
[Epoch 41; Iter   930/  960] train: loss: 0.1468612
[Epoch 41; Iter   960/  960] train: loss: 0.0680126
[Epoch 41] ogbg-molhiv: 0.772574 val loss: 1.098656
[Epoch 41] ogbg-molhiv: 0.757992 test loss: 0.371313
[Epoch 42; Iter    30/  960] train: loss: 0.0231677
[Epoch 42; Iter    60/  960] train: loss: 0.0137963
[Epoch 42; Iter    90/  960] train: loss: 0.0390854
[Epoch 42; Iter   120/  960] train: loss: 0.0508243
[Epoch 42; Iter   150/  960] train: loss: 0.1360301
[Epoch 42; Iter   180/  960] train: loss: 0.0145342
[Epoch 42; Iter   210/  960] train: loss: 0.0199177
[Epoch 42; Iter   240/  960] train: loss: 0.0333822
[Epoch 42; Iter   270/  960] train: loss: 0.0723248
[Epoch 42; Iter   300/  960] train: loss: 0.0578089
[Epoch 42; Iter   330/  960] train: loss: 0.0195312
[Epoch 42; Iter   360/  960] train: loss: 0.0266730
[Epoch 42; Iter   390/  960] train: loss: 0.0133394
[Epoch 42; Iter   420/  960] train: loss: 0.1431326
[Epoch 42; Iter   450/  960] train: loss: 0.0093909
[Epoch 42; Iter   480/  960] train: loss: 0.0194254
[Epoch 42; Iter   510/  960] train: loss: 0.0760112
[Epoch 42; Iter   540/  960] train: loss: 0.0553711
[Epoch 42; Iter   570/  960] train: loss: 0.1128684
[Epoch 42; Iter   600/  960] train: loss: 0.0315899
[Epoch 42; Iter   630/  960] train: loss: 0.0720034
[Epoch 42; Iter   660/  960] train: loss: 0.0167899
[Epoch 42; Iter   690/  960] train: loss: 0.0929246
[Epoch 42; Iter   720/  960] train: loss: 0.0357887
[Epoch 42; Iter   750/  960] train: loss: 0.0942130
[Epoch 42; Iter   780/  960] train: loss: 0.1897343
[Epoch 42; Iter   810/  960] train: loss: 0.0258708
[Epoch 42; Iter   840/  960] train: loss: 0.1188396
[Epoch 42; Iter   870/  960] train: loss: 0.1088186
[Epoch 42; Iter   900/  960] train: loss: 0.0180692
[Epoch 42; Iter   930/  960] train: loss: 0.1325517
[Epoch 42; Iter   960/  960] train: loss: 0.0217173
[Epoch 42] ogbg-molhiv: 0.756247 val loss: 1.085728
[Epoch 42] ogbg-molhiv: 0.757069 test loss: 0.569283
[Epoch 43; Iter    30/  960] train: loss: 0.0896068
[Epoch 43; Iter    60/  960] train: loss: 0.0153032
[Epoch 43; Iter    90/  960] train: loss: 0.0094928
[Epoch 43; Iter   120/  960] train: loss: 0.0233577
[Epoch 43; Iter   150/  960] train: loss: 0.1965889
[Epoch 43; Iter   180/  960] train: loss: 0.0449569
[Epoch 43; Iter   210/  960] train: loss: 0.0512510
[Epoch 43; Iter   240/  960] train: loss: 0.0269486
[Epoch 43; Iter   270/  960] train: loss: 0.0701114
[Epoch 43; Iter   300/  960] train: loss: 0.0120718
[Epoch 43; Iter   330/  960] train: loss: 0.0494621
[Epoch 43; Iter   360/  960] train: loss: 0.2212610
[Epoch 43; Iter   390/  960] train: loss: 0.0077079
[Epoch 43; Iter   420/  960] train: loss: 0.0641977
[Epoch 43; Iter   450/  960] train: loss: 0.0159030
[Epoch 43; Iter   480/  960] train: loss: 0.3632900
[Epoch 43; Iter   510/  960] train: loss: 0.0234514
[Epoch 43; Iter   540/  960] train: loss: 0.0361770
[Epoch 43; Iter   570/  960] train: loss: 0.0328737
[Epoch 43; Iter   600/  960] train: loss: 0.1792428
[Epoch 43; Iter   630/  960] train: loss: 0.1813374
[Epoch 43; Iter   660/  960] train: loss: 0.0296811
[Epoch 43; Iter   690/  960] train: loss: 0.0385882
[Epoch 43; Iter   720/  960] train: loss: 0.0197854
[Epoch 43; Iter   750/  960] train: loss: 0.0583164
[Epoch 43; Iter   780/  960] train: loss: 0.0079212
[Epoch 43; Iter   810/  960] train: loss: 0.0246054
[Epoch 43; Iter   840/  960] train: loss: 0.0399677
[Epoch 43; Iter   870/  960] train: loss: 0.0524942
[Epoch 43; Iter   900/  960] train: loss: 0.0816120
[Epoch 43; Iter   930/  960] train: loss: 0.0112652
[Epoch 43; Iter   960/  960] train: loss: 0.0302917
[Epoch 43] ogbg-molhiv: 0.765254 val loss: 0.630728
[Epoch 43] ogbg-molhiv: 0.750998 test loss: 0.235594
[Epoch 44; Iter    30/  960] train: loss: 0.0402193
[Epoch 44; Iter    60/  960] train: loss: 0.0298941
[Epoch 44; Iter    90/  960] train: loss: 0.0694551
[Epoch 44; Iter   120/  960] train: loss: 0.0354808
[Epoch 44; Iter   150/  960] train: loss: 0.0198447
[Epoch 44; Iter   180/  960] train: loss: 0.0289550
[Epoch 44; Iter   210/  960] train: loss: 0.0566422
[Epoch 44; Iter   240/  960] train: loss: 0.0154703
[Epoch 44; Iter   270/  960] train: loss: 0.0115052
[Epoch 44; Iter   300/  960] train: loss: 0.1067254
[Epoch 44; Iter   330/  960] train: loss: 0.0334348
[Epoch 44; Iter   360/  960] train: loss: 0.0151819
[Epoch 44; Iter   390/  960] train: loss: 0.1202722
[Epoch 44; Iter   420/  960] train: loss: 0.1038242
[Epoch 44; Iter   450/  960] train: loss: 0.0144799
[Epoch 44; Iter   480/  960] train: loss: 0.0086172
[Epoch 44; Iter   510/  960] train: loss: 0.0962406
[Epoch 44; Iter   540/  960] train: loss: 0.0114395
[Epoch 44; Iter   570/  960] train: loss: 0.0950179
[Epoch 44; Iter   600/  960] train: loss: 0.0721109
[Epoch 44; Iter   630/  960] train: loss: 0.0579349
[Epoch 44; Iter   660/  960] train: loss: 0.1461127
[Epoch 44; Iter   690/  960] train: loss: 0.0072755
[Epoch 44; Iter   720/  960] train: loss: 0.0274190
[Epoch 44; Iter   750/  960] train: loss: 0.1525411
[Epoch 44; Iter   780/  960] train: loss: 0.1012999
[Epoch 44; Iter   810/  960] train: loss: 0.0079246
[Epoch 44; Iter   840/  960] train: loss: 0.0834023
[Epoch 44; Iter   870/  960] train: loss: 0.0156166
[Epoch 44; Iter   900/  960] train: loss: 0.0714623
[Epoch 44; Iter   930/  960] train: loss: 0.0199417
[Epoch 44; Iter   960/  960] train: loss: 0.0074920
[Epoch 44] ogbg-molhiv: 0.757237 val loss: 0.733567
[Epoch 44] ogbg-molhiv: 0.761608 test loss: 0.303399
[Epoch 45; Iter    30/  960] train: loss: 0.0407810
[Epoch 45; Iter    60/  960] train: loss: 0.0130571
[Epoch 45; Iter    90/  960] train: loss: 0.1593549
[Epoch 45; Iter   120/  960] train: loss: 0.1616894
[Epoch 45; Iter   150/  960] train: loss: 0.1509236
[Epoch 45; Iter   180/  960] train: loss: 0.0239420
[Epoch 45; Iter   210/  960] train: loss: 0.0608176
[Epoch 45; Iter   240/  960] train: loss: 0.0956139
[Epoch 45; Iter   270/  960] train: loss: 0.0299568
[Epoch 45; Iter   300/  960] train: loss: 0.0605590
[Epoch 45; Iter   330/  960] train: loss: 0.0224276
[Epoch 45; Iter   360/  960] train: loss: 0.0219598
[Epoch 45; Iter   390/  960] train: loss: 0.2024455
[Epoch 45; Iter   420/  960] train: loss: 0.1543527
[Epoch 45; Iter   450/  960] train: loss: 0.0210199
[Epoch 45; Iter   480/  960] train: loss: 0.0153073
[Epoch 45; Iter   510/  960] train: loss: 0.0494697
[Epoch 45; Iter   540/  960] train: loss: 0.0207542
[Epoch 45; Iter   570/  960] train: loss: 0.1325355
[Epoch 45; Iter   600/  960] train: loss: 0.0215260
[Epoch 45; Iter   630/  960] train: loss: 0.0106531
[Epoch 45; Iter   660/  960] train: loss: 0.0117727
[Epoch 45; Iter   690/  960] train: loss: 0.2577766
[Epoch 45; Iter   720/  960] train: loss: 0.0518375
[Epoch 45; Iter   750/  960] train: loss: 0.1692872
[Epoch 45; Iter   780/  960] train: loss: 0.1965649
[Epoch 45; Iter   810/  960] train: loss: 0.0308939
[Epoch 45; Iter   840/  960] train: loss: 0.0063175
[Epoch 45; Iter   870/  960] train: loss: 0.0558544
[Epoch 45; Iter   900/  960] train: loss: 0.1156542
[Epoch 45; Iter   930/  960] train: loss: 0.2553013
[Epoch 40; Iter   717/ 1097] train: loss: 0.0179826
[Epoch 40; Iter   747/ 1097] train: loss: 0.0373634
[Epoch 40; Iter   777/ 1097] train: loss: 0.2208147
[Epoch 40; Iter   807/ 1097] train: loss: 0.0345381
[Epoch 40; Iter   837/ 1097] train: loss: 0.0287909
[Epoch 40; Iter   867/ 1097] train: loss: 0.1462679
[Epoch 40; Iter   897/ 1097] train: loss: 0.0371382
[Epoch 40; Iter   927/ 1097] train: loss: 0.1765155
[Epoch 40; Iter   957/ 1097] train: loss: 0.0490396
[Epoch 40; Iter   987/ 1097] train: loss: 0.0294891
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0767360
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0484667
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0584284
[Epoch 40] ogbg-molhiv: 0.794312 val loss: 0.081567
[Epoch 40] ogbg-molhiv: 0.755945 test loss: 0.123892
[Epoch 41; Iter    10/ 1097] train: loss: 0.1520890
[Epoch 41; Iter    40/ 1097] train: loss: 0.3187445
[Epoch 41; Iter    70/ 1097] train: loss: 0.0318326
[Epoch 41; Iter   100/ 1097] train: loss: 0.0155026
[Epoch 41; Iter   130/ 1097] train: loss: 0.0838684
[Epoch 41; Iter   160/ 1097] train: loss: 0.0285623
[Epoch 41; Iter   190/ 1097] train: loss: 0.2288283
[Epoch 41; Iter   220/ 1097] train: loss: 0.1974891
[Epoch 41; Iter   250/ 1097] train: loss: 0.0653094
[Epoch 41; Iter   280/ 1097] train: loss: 0.0739906
[Epoch 41; Iter   310/ 1097] train: loss: 0.1567525
[Epoch 41; Iter   340/ 1097] train: loss: 0.0155808
[Epoch 41; Iter   370/ 1097] train: loss: 0.2949490
[Epoch 41; Iter   400/ 1097] train: loss: 0.0649880
[Epoch 41; Iter   430/ 1097] train: loss: 0.0704670
[Epoch 41; Iter   460/ 1097] train: loss: 0.1292473
[Epoch 41; Iter   490/ 1097] train: loss: 0.4987895
[Epoch 41; Iter   520/ 1097] train: loss: 0.0307870
[Epoch 41; Iter   550/ 1097] train: loss: 0.0405550
[Epoch 41; Iter   580/ 1097] train: loss: 0.0927147
[Epoch 41; Iter   610/ 1097] train: loss: 0.1217094
[Epoch 41; Iter   640/ 1097] train: loss: 0.0251757
[Epoch 41; Iter   670/ 1097] train: loss: 0.0482392
[Epoch 41; Iter   700/ 1097] train: loss: 0.1420401
[Epoch 41; Iter   730/ 1097] train: loss: 0.0095079
[Epoch 41; Iter   760/ 1097] train: loss: 0.1281936
[Epoch 41; Iter   790/ 1097] train: loss: 0.1020823
[Epoch 41; Iter   820/ 1097] train: loss: 0.0419125
[Epoch 41; Iter   850/ 1097] train: loss: 0.0179276
[Epoch 41; Iter   880/ 1097] train: loss: 0.0268082
[Epoch 41; Iter   910/ 1097] train: loss: 0.1494210
[Epoch 41; Iter   940/ 1097] train: loss: 0.0249458
[Epoch 41; Iter   970/ 1097] train: loss: 0.1562842
[Epoch 41; Iter  1000/ 1097] train: loss: 0.2218004
[Epoch 41; Iter  1030/ 1097] train: loss: 0.0552260
[Epoch 41; Iter  1060/ 1097] train: loss: 0.1748153
[Epoch 41; Iter  1090/ 1097] train: loss: 0.1233206
[Epoch 41] ogbg-molhiv: 0.809518 val loss: 0.080323
[Epoch 41] ogbg-molhiv: 0.742245 test loss: 0.134570
[Epoch 42; Iter    23/ 1097] train: loss: 0.0297776
[Epoch 42; Iter    53/ 1097] train: loss: 0.1161657
[Epoch 42; Iter    83/ 1097] train: loss: 0.1054099
[Epoch 42; Iter   113/ 1097] train: loss: 0.0583852
[Epoch 42; Iter   143/ 1097] train: loss: 0.1302894
[Epoch 42; Iter   173/ 1097] train: loss: 0.0212271
[Epoch 42; Iter   203/ 1097] train: loss: 0.0573354
[Epoch 42; Iter   233/ 1097] train: loss: 0.0334332
[Epoch 42; Iter   263/ 1097] train: loss: 0.0491230
[Epoch 42; Iter   293/ 1097] train: loss: 0.0567307
[Epoch 42; Iter   323/ 1097] train: loss: 0.0797623
[Epoch 42; Iter   353/ 1097] train: loss: 0.0162909
[Epoch 42; Iter   383/ 1097] train: loss: 0.1161632
[Epoch 42; Iter   413/ 1097] train: loss: 0.2139955
[Epoch 42; Iter   443/ 1097] train: loss: 0.0259288
[Epoch 42; Iter   473/ 1097] train: loss: 0.1476386
[Epoch 42; Iter   503/ 1097] train: loss: 0.0986449
[Epoch 42; Iter   533/ 1097] train: loss: 0.0280773
[Epoch 42; Iter   563/ 1097] train: loss: 0.0728286
[Epoch 42; Iter   593/ 1097] train: loss: 0.0239749
[Epoch 42; Iter   623/ 1097] train: loss: 0.0305900
[Epoch 42; Iter   653/ 1097] train: loss: 0.2355943
[Epoch 42; Iter   683/ 1097] train: loss: 0.0325629
[Epoch 42; Iter   713/ 1097] train: loss: 0.0665282
[Epoch 42; Iter   743/ 1097] train: loss: 0.0574248
[Epoch 42; Iter   773/ 1097] train: loss: 0.0556636
[Epoch 42; Iter   803/ 1097] train: loss: 0.0236860
[Epoch 42; Iter   833/ 1097] train: loss: 0.0385979
[Epoch 42; Iter   863/ 1097] train: loss: 0.0261490
[Epoch 42; Iter   893/ 1097] train: loss: 0.0593259
[Epoch 42; Iter   923/ 1097] train: loss: 0.1356063
[Epoch 42; Iter   953/ 1097] train: loss: 0.0233388
[Epoch 42; Iter   983/ 1097] train: loss: 0.0127687
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1531448
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1671816
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0831929
[Epoch 42] ogbg-molhiv: 0.795084 val loss: 0.084458
[Epoch 42] ogbg-molhiv: 0.740478 test loss: 0.140035
[Epoch 43; Iter     6/ 1097] train: loss: 0.1411350
[Epoch 43; Iter    36/ 1097] train: loss: 0.0284712
[Epoch 43; Iter    66/ 1097] train: loss: 0.3235420
[Epoch 43; Iter    96/ 1097] train: loss: 0.0357756
[Epoch 43; Iter   126/ 1097] train: loss: 0.1576814
[Epoch 43; Iter   156/ 1097] train: loss: 0.2903256
[Epoch 43; Iter   186/ 1097] train: loss: 0.1360969
[Epoch 43; Iter   216/ 1097] train: loss: 0.1134779
[Epoch 43; Iter   246/ 1097] train: loss: 0.0906036
[Epoch 43; Iter   276/ 1097] train: loss: 0.3524557
[Epoch 43; Iter   306/ 1097] train: loss: 0.0262511
[Epoch 43; Iter   336/ 1097] train: loss: 0.2842358
[Epoch 43; Iter   366/ 1097] train: loss: 0.0320238
[Epoch 43; Iter   396/ 1097] train: loss: 0.0212415
[Epoch 43; Iter   426/ 1097] train: loss: 0.1272228
[Epoch 43; Iter   456/ 1097] train: loss: 0.1773448
[Epoch 43; Iter   486/ 1097] train: loss: 0.1049647
[Epoch 43; Iter   516/ 1097] train: loss: 0.0587330
[Epoch 43; Iter   546/ 1097] train: loss: 0.0622177
[Epoch 43; Iter   576/ 1097] train: loss: 0.3614439
[Epoch 43; Iter   606/ 1097] train: loss: 0.0364053
[Epoch 43; Iter   636/ 1097] train: loss: 0.1009370
[Epoch 43; Iter   666/ 1097] train: loss: 0.0590857
[Epoch 43; Iter   696/ 1097] train: loss: 0.2142076
[Epoch 43; Iter   726/ 1097] train: loss: 0.0193018
[Epoch 43; Iter   756/ 1097] train: loss: 0.0950589
[Epoch 43; Iter   786/ 1097] train: loss: 0.0140156
[Epoch 43; Iter   816/ 1097] train: loss: 0.0236372
[Epoch 43; Iter   846/ 1097] train: loss: 0.1091077
[Epoch 43; Iter   876/ 1097] train: loss: 0.1453847
[Epoch 43; Iter   906/ 1097] train: loss: 0.1126375
[Epoch 43; Iter   936/ 1097] train: loss: 0.0273423
[Epoch 43; Iter   966/ 1097] train: loss: 0.0379336
[Epoch 43; Iter   996/ 1097] train: loss: 0.1160784
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0160725
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1318081
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0105187
[Epoch 43] ogbg-molhiv: 0.794784 val loss: 0.083718
[Epoch 43] ogbg-molhiv: 0.738940 test loss: 0.134478
[Epoch 44; Iter    19/ 1097] train: loss: 0.0441390
[Epoch 44; Iter    49/ 1097] train: loss: 0.0197533
[Epoch 44; Iter    79/ 1097] train: loss: 0.0629959
[Epoch 44; Iter   109/ 1097] train: loss: 0.0974095
[Epoch 44; Iter   139/ 1097] train: loss: 0.0228449
[Epoch 44; Iter   169/ 1097] train: loss: 0.1190960
[Epoch 44; Iter   199/ 1097] train: loss: 0.0079587
[Epoch 44; Iter   229/ 1097] train: loss: 0.0867713
[Epoch 44; Iter   259/ 1097] train: loss: 0.0576736
[Epoch 44; Iter   289/ 1097] train: loss: 0.0303415
[Epoch 44; Iter   319/ 1097] train: loss: 0.0207454
[Epoch 44; Iter   349/ 1097] train: loss: 0.1359484
[Epoch 44; Iter   379/ 1097] train: loss: 0.0262734
[Epoch 44; Iter   409/ 1097] train: loss: 0.0597478
[Epoch 44; Iter   439/ 1097] train: loss: 0.0242684
[Epoch 44; Iter   469/ 1097] train: loss: 0.2259989
[Epoch 44; Iter   499/ 1097] train: loss: 0.1780837
[Epoch 44; Iter   529/ 1097] train: loss: 0.1165037
[Epoch 44; Iter   559/ 1097] train: loss: 0.1014458
[Epoch 44; Iter   589/ 1097] train: loss: 0.1101074
[Epoch 44; Iter   619/ 1097] train: loss: 0.0269199
[Epoch 44; Iter   649/ 1097] train: loss: 0.0224416
[Epoch 44; Iter   679/ 1097] train: loss: 0.2669498
[Epoch 44; Iter   709/ 1097] train: loss: 0.0139090
[Epoch 44; Iter   739/ 1097] train: loss: 0.0331217
[Epoch 44; Iter   769/ 1097] train: loss: 0.1039118
[Epoch 41; Iter   330/  960] train: loss: 0.0178051
[Epoch 41; Iter   360/  960] train: loss: 0.3121519
[Epoch 41; Iter   390/  960] train: loss: 0.0477980
[Epoch 41; Iter   420/  960] train: loss: 0.2487425
[Epoch 41; Iter   450/  960] train: loss: 0.1617448
[Epoch 41; Iter   480/  960] train: loss: 0.0113819
[Epoch 41; Iter   510/  960] train: loss: 0.0455014
[Epoch 41; Iter   540/  960] train: loss: 0.1464401
[Epoch 41; Iter   570/  960] train: loss: 0.0687764
[Epoch 41; Iter   600/  960] train: loss: 0.0321966
[Epoch 41; Iter   630/  960] train: loss: 0.0655440
[Epoch 41; Iter   660/  960] train: loss: 0.0197419
[Epoch 41; Iter   690/  960] train: loss: 0.0228805
[Epoch 41; Iter   720/  960] train: loss: 0.3063959
[Epoch 41; Iter   750/  960] train: loss: 0.0401494
[Epoch 41; Iter   780/  960] train: loss: 0.1132843
[Epoch 41; Iter   810/  960] train: loss: 0.0137434
[Epoch 41; Iter   840/  960] train: loss: 0.0346116
[Epoch 41; Iter   870/  960] train: loss: 0.0305620
[Epoch 41; Iter   900/  960] train: loss: 0.2847440
[Epoch 41; Iter   930/  960] train: loss: 0.0649394
[Epoch 41; Iter   960/  960] train: loss: 0.0063635
[Epoch 41] ogbg-molhiv: 0.734709 val loss: 0.144726
[Epoch 41] ogbg-molhiv: 0.776598 test loss: 0.117439
[Epoch 42; Iter    30/  960] train: loss: 0.1701321
[Epoch 42; Iter    60/  960] train: loss: 0.1303321
[Epoch 42; Iter    90/  960] train: loss: 0.0188965
[Epoch 42; Iter   120/  960] train: loss: 0.0141502
[Epoch 42; Iter   150/  960] train: loss: 0.0186510
[Epoch 42; Iter   180/  960] train: loss: 0.0329735
[Epoch 42; Iter   210/  960] train: loss: 0.0967352
[Epoch 42; Iter   240/  960] train: loss: 0.0202018
[Epoch 42; Iter   270/  960] train: loss: 0.0154979
[Epoch 42; Iter   300/  960] train: loss: 0.0267783
[Epoch 42; Iter   330/  960] train: loss: 0.0796564
[Epoch 42; Iter   360/  960] train: loss: 0.2082434
[Epoch 42; Iter   390/  960] train: loss: 0.1390130
[Epoch 42; Iter   420/  960] train: loss: 0.0128584
[Epoch 42; Iter   450/  960] train: loss: 0.0720198
[Epoch 42; Iter   480/  960] train: loss: 0.2167096
[Epoch 42; Iter   510/  960] train: loss: 0.1152014
[Epoch 42; Iter   540/  960] train: loss: 0.0579249
[Epoch 42; Iter   570/  960] train: loss: 0.0142208
[Epoch 42; Iter   600/  960] train: loss: 0.0556453
[Epoch 42; Iter   630/  960] train: loss: 0.1373484
[Epoch 42; Iter   660/  960] train: loss: 0.0533048
[Epoch 42; Iter   690/  960] train: loss: 0.1161810
[Epoch 42; Iter   720/  960] train: loss: 0.1481380
[Epoch 42; Iter   750/  960] train: loss: 0.1689670
[Epoch 42; Iter   780/  960] train: loss: 0.0171516
[Epoch 42; Iter   810/  960] train: loss: 0.0199623
[Epoch 42; Iter   840/  960] train: loss: 0.0288719
[Epoch 42; Iter   870/  960] train: loss: 0.1208602
[Epoch 42; Iter   900/  960] train: loss: 0.0559386
[Epoch 42; Iter   930/  960] train: loss: 0.0084530
[Epoch 42; Iter   960/  960] train: loss: 0.1763092
[Epoch 42] ogbg-molhiv: 0.729531 val loss: 0.147943
[Epoch 42] ogbg-molhiv: 0.770026 test loss: 0.114834
[Epoch 43; Iter    30/  960] train: loss: 0.1739593
[Epoch 43; Iter    60/  960] train: loss: 0.0099747
[Epoch 43; Iter    90/  960] train: loss: 0.1550414
[Epoch 43; Iter   120/  960] train: loss: 0.0652079
[Epoch 43; Iter   150/  960] train: loss: 0.0466117
[Epoch 43; Iter   180/  960] train: loss: 0.0096025
[Epoch 43; Iter   210/  960] train: loss: 0.0742967
[Epoch 43; Iter   240/  960] train: loss: 0.1029416
[Epoch 43; Iter   270/  960] train: loss: 0.0847854
[Epoch 43; Iter   300/  960] train: loss: 0.0296183
[Epoch 43; Iter   330/  960] train: loss: 0.2258476
[Epoch 43; Iter   360/  960] train: loss: 0.0662177
[Epoch 43; Iter   390/  960] train: loss: 0.0467741
[Epoch 43; Iter   420/  960] train: loss: 0.1330429
[Epoch 43; Iter   450/  960] train: loss: 0.0789389
[Epoch 43; Iter   480/  960] train: loss: 0.0466081
[Epoch 43; Iter   510/  960] train: loss: 0.0794931
[Epoch 43; Iter   540/  960] train: loss: 0.0059858
[Epoch 43; Iter   570/  960] train: loss: 0.0102270
[Epoch 43; Iter   600/  960] train: loss: 0.0375682
[Epoch 43; Iter   630/  960] train: loss: 0.0820671
[Epoch 43; Iter   660/  960] train: loss: 0.0483232
[Epoch 43; Iter   690/  960] train: loss: 0.1143147
[Epoch 43; Iter   720/  960] train: loss: 0.0891166
[Epoch 43; Iter   750/  960] train: loss: 0.0766714
[Epoch 43; Iter   780/  960] train: loss: 0.0080779
[Epoch 43; Iter   810/  960] train: loss: 0.2344308
[Epoch 43; Iter   840/  960] train: loss: 0.1167718
[Epoch 43; Iter   870/  960] train: loss: 0.0237702
[Epoch 43; Iter   900/  960] train: loss: 0.1829270
[Epoch 43; Iter   930/  960] train: loss: 0.0055237
[Epoch 43; Iter   960/  960] train: loss: 0.0912642
[Epoch 43] ogbg-molhiv: 0.738190 val loss: 0.146075
[Epoch 43] ogbg-molhiv: 0.778078 test loss: 0.123088
[Epoch 44; Iter    30/  960] train: loss: 0.0087361
[Epoch 44; Iter    60/  960] train: loss: 0.0348364
[Epoch 44; Iter    90/  960] train: loss: 0.0254493
[Epoch 44; Iter   120/  960] train: loss: 0.0261717
[Epoch 44; Iter   150/  960] train: loss: 0.0383238
[Epoch 44; Iter   180/  960] train: loss: 0.0577879
[Epoch 44; Iter   210/  960] train: loss: 0.1439093
[Epoch 44; Iter   240/  960] train: loss: 0.0883197
[Epoch 44; Iter   270/  960] train: loss: 0.0352746
[Epoch 44; Iter   300/  960] train: loss: 0.0143198
[Epoch 44; Iter   330/  960] train: loss: 0.0232073
[Epoch 44; Iter   360/  960] train: loss: 0.1284443
[Epoch 44; Iter   390/  960] train: loss: 0.0941227
[Epoch 44; Iter   420/  960] train: loss: 0.2688204
[Epoch 44; Iter   450/  960] train: loss: 0.0357472
[Epoch 44; Iter   480/  960] train: loss: 0.1839907
[Epoch 44; Iter   510/  960] train: loss: 0.0407396
[Epoch 44; Iter   540/  960] train: loss: 0.0306843
[Epoch 44; Iter   570/  960] train: loss: 0.0227116
[Epoch 44; Iter   600/  960] train: loss: 0.0442454
[Epoch 44; Iter   630/  960] train: loss: 0.0678982
[Epoch 44; Iter   660/  960] train: loss: 0.1144577
[Epoch 44; Iter   690/  960] train: loss: 0.0408096
[Epoch 44; Iter   720/  960] train: loss: 0.2157341
[Epoch 44; Iter   750/  960] train: loss: 0.0657264
[Epoch 44; Iter   780/  960] train: loss: 0.0770594
[Epoch 44; Iter   810/  960] train: loss: 0.1197443
[Epoch 44; Iter   840/  960] train: loss: 0.0211822
[Epoch 44; Iter   870/  960] train: loss: 0.0158041
[Epoch 44; Iter   900/  960] train: loss: 0.0079928
[Epoch 44; Iter   930/  960] train: loss: 0.0123462
[Epoch 44; Iter   960/  960] train: loss: 0.1556032
[Epoch 44] ogbg-molhiv: 0.726314 val loss: 0.148158
[Epoch 44] ogbg-molhiv: 0.768727 test loss: 0.127809
[Epoch 45; Iter    30/  960] train: loss: 0.0584407
[Epoch 45; Iter    60/  960] train: loss: 0.0230571
[Epoch 45; Iter    90/  960] train: loss: 0.0102822
[Epoch 45; Iter   120/  960] train: loss: 0.0233586
[Epoch 45; Iter   150/  960] train: loss: 0.0329055
[Epoch 45; Iter   180/  960] train: loss: 0.0165957
[Epoch 45; Iter   210/  960] train: loss: 0.0300100
[Epoch 45; Iter   240/  960] train: loss: 0.0416063
[Epoch 45; Iter   270/  960] train: loss: 0.0169665
[Epoch 45; Iter   300/  960] train: loss: 0.2934466
[Epoch 45; Iter   330/  960] train: loss: 0.1153917
[Epoch 45; Iter   360/  960] train: loss: 0.1186102
[Epoch 45; Iter   390/  960] train: loss: 0.0235137
[Epoch 45; Iter   420/  960] train: loss: 0.0592558
[Epoch 45; Iter   450/  960] train: loss: 0.0359808
[Epoch 45; Iter   480/  960] train: loss: 0.0074390
[Epoch 45; Iter   510/  960] train: loss: 0.1292464
[Epoch 45; Iter   540/  960] train: loss: 0.0866629
[Epoch 45; Iter   570/  960] train: loss: 0.1050607
[Epoch 45; Iter   600/  960] train: loss: 0.0904845
[Epoch 45; Iter   630/  960] train: loss: 0.0052645
[Epoch 45; Iter   660/  960] train: loss: 0.0373346
[Epoch 45; Iter   690/  960] train: loss: 0.1291760
[Epoch 45; Iter   720/  960] train: loss: 0.1407558
[Epoch 45; Iter   750/  960] train: loss: 0.0989315
[Epoch 45; Iter   780/  960] train: loss: 0.0343547
[Epoch 45; Iter   810/  960] train: loss: 0.2224691
[Epoch 45; Iter   840/  960] train: loss: 0.0252068
[Epoch 45; Iter   870/  960] train: loss: 0.0672236
[Epoch 45; Iter   900/  960] train: loss: 0.0266330
[Epoch 45; Iter   930/  960] train: loss: 0.0481418
[Epoch 42; Iter   187/  823] train: loss: 0.0292622
[Epoch 42; Iter   217/  823] train: loss: 0.0145758
[Epoch 42; Iter   247/  823] train: loss: 0.2026902
[Epoch 42; Iter   277/  823] train: loss: 0.1800805
[Epoch 42; Iter   307/  823] train: loss: 0.0574768
[Epoch 42; Iter   337/  823] train: loss: 0.0513396
[Epoch 42; Iter   367/  823] train: loss: 0.0686272
[Epoch 42; Iter   397/  823] train: loss: 0.1239205
[Epoch 42; Iter   427/  823] train: loss: 0.0378675
[Epoch 42; Iter   457/  823] train: loss: 0.0767977
[Epoch 42; Iter   487/  823] train: loss: 0.2252732
[Epoch 42; Iter   517/  823] train: loss: 0.0796015
[Epoch 42; Iter   547/  823] train: loss: 0.0402748
[Epoch 42; Iter   577/  823] train: loss: 0.1209695
[Epoch 42; Iter   607/  823] train: loss: 0.0059059
[Epoch 42; Iter   637/  823] train: loss: 0.0057803
[Epoch 42; Iter   667/  823] train: loss: 0.0965283
[Epoch 42; Iter   697/  823] train: loss: 0.0610541
[Epoch 42; Iter   727/  823] train: loss: 0.0324557
[Epoch 42; Iter   757/  823] train: loss: 0.2189835
[Epoch 42; Iter   787/  823] train: loss: 0.0210766
[Epoch 42; Iter   817/  823] train: loss: 0.1554000
[Epoch 42] ogbg-molhiv: 0.715710 val loss: 0.182373
[Epoch 42] ogbg-molhiv: 0.770140 test loss: 0.134691
[Epoch 43; Iter    24/  823] train: loss: 0.0464053
[Epoch 43; Iter    54/  823] train: loss: 0.2301308
[Epoch 43; Iter    84/  823] train: loss: 0.0118228
[Epoch 43; Iter   114/  823] train: loss: 0.0084578
[Epoch 43; Iter   144/  823] train: loss: 0.0093977
[Epoch 43; Iter   174/  823] train: loss: 0.2214747
[Epoch 43; Iter   204/  823] train: loss: 0.0095051
[Epoch 43; Iter   234/  823] train: loss: 0.0908704
[Epoch 43; Iter   264/  823] train: loss: 0.0070810
[Epoch 43; Iter   294/  823] train: loss: 0.1541971
[Epoch 43; Iter   324/  823] train: loss: 0.0736155
[Epoch 43; Iter   354/  823] train: loss: 0.0062221
[Epoch 43; Iter   384/  823] train: loss: 0.0925883
[Epoch 43; Iter   414/  823] train: loss: 0.0144824
[Epoch 43; Iter   444/  823] train: loss: 0.0336552
[Epoch 43; Iter   474/  823] train: loss: 0.0096459
[Epoch 43; Iter   504/  823] train: loss: 0.1639799
[Epoch 43; Iter   534/  823] train: loss: 0.3202298
[Epoch 43; Iter   564/  823] train: loss: 0.0285230
[Epoch 43; Iter   594/  823] train: loss: 0.0283995
[Epoch 43; Iter   624/  823] train: loss: 0.0430651
[Epoch 43; Iter   654/  823] train: loss: 0.1942584
[Epoch 43; Iter   684/  823] train: loss: 0.0131213
[Epoch 43; Iter   714/  823] train: loss: 0.0164964
[Epoch 43; Iter   744/  823] train: loss: 0.0072105
[Epoch 43; Iter   774/  823] train: loss: 0.0160839
[Epoch 43; Iter   804/  823] train: loss: 0.0266747
[Epoch 43] ogbg-molhiv: 0.728597 val loss: 0.174528
[Epoch 43] ogbg-molhiv: 0.787535 test loss: 0.117452
[Epoch 44; Iter    11/  823] train: loss: 0.0122054
[Epoch 44; Iter    41/  823] train: loss: 0.0563564
[Epoch 44; Iter    71/  823] train: loss: 0.0331853
[Epoch 44; Iter   101/  823] train: loss: 0.0179279
[Epoch 44; Iter   131/  823] train: loss: 0.0062541
[Epoch 44; Iter   161/  823] train: loss: 0.0476366
[Epoch 44; Iter   191/  823] train: loss: 0.0141078
[Epoch 44; Iter   221/  823] train: loss: 0.0938342
[Epoch 44; Iter   251/  823] train: loss: 0.0643949
[Epoch 44; Iter   281/  823] train: loss: 0.0195278
[Epoch 44; Iter   311/  823] train: loss: 0.1494434
[Epoch 44; Iter   341/  823] train: loss: 0.0160704
[Epoch 44; Iter   371/  823] train: loss: 0.0436368
[Epoch 44; Iter   401/  823] train: loss: 0.0079556
[Epoch 44; Iter   431/  823] train: loss: 0.0512360
[Epoch 44; Iter   461/  823] train: loss: 0.0340063
[Epoch 44; Iter   491/  823] train: loss: 0.0367674
[Epoch 44; Iter   521/  823] train: loss: 0.0506361
[Epoch 44; Iter   551/  823] train: loss: 0.0448531
[Epoch 44; Iter   581/  823] train: loss: 0.0112431
[Epoch 44; Iter   611/  823] train: loss: 0.0780244
[Epoch 44; Iter   641/  823] train: loss: 0.0312618
[Epoch 44; Iter   671/  823] train: loss: 0.1276008
[Epoch 44; Iter   701/  823] train: loss: 0.0163578
[Epoch 44; Iter   731/  823] train: loss: 0.0151278
[Epoch 44; Iter   761/  823] train: loss: 0.0293787
[Epoch 44; Iter   791/  823] train: loss: 0.0107818
[Epoch 44; Iter   821/  823] train: loss: 0.0150455
[Epoch 44] ogbg-molhiv: 0.717376 val loss: 0.247912
[Epoch 44] ogbg-molhiv: 0.776375 test loss: 0.191893
[Epoch 45; Iter    28/  823] train: loss: 0.0339858
[Epoch 45; Iter    58/  823] train: loss: 0.0714694
[Epoch 45; Iter    88/  823] train: loss: 0.0829738
[Epoch 45; Iter   118/  823] train: loss: 0.0275417
[Epoch 45; Iter   148/  823] train: loss: 0.0315009
[Epoch 45; Iter   178/  823] train: loss: 0.0586380
[Epoch 45; Iter   208/  823] train: loss: 0.1171741
[Epoch 45; Iter   238/  823] train: loss: 0.0153429
[Epoch 45; Iter   268/  823] train: loss: 0.0373498
[Epoch 45; Iter   298/  823] train: loss: 0.1065682
[Epoch 45; Iter   328/  823] train: loss: 0.0231136
[Epoch 45; Iter   358/  823] train: loss: 0.0386251
[Epoch 45; Iter   388/  823] train: loss: 0.0160158
[Epoch 45; Iter   418/  823] train: loss: 0.0097571
[Epoch 45; Iter   448/  823] train: loss: 0.0105836
[Epoch 45; Iter   478/  823] train: loss: 0.1002517
[Epoch 45; Iter   508/  823] train: loss: 0.0777117
[Epoch 45; Iter   538/  823] train: loss: 0.0151764
[Epoch 45; Iter   568/  823] train: loss: 0.2680351
[Epoch 45; Iter   598/  823] train: loss: 0.0318481
[Epoch 45; Iter   628/  823] train: loss: 0.1644990
[Epoch 45; Iter   658/  823] train: loss: 0.0991148
[Epoch 45; Iter   688/  823] train: loss: 0.1170194
[Epoch 45; Iter   718/  823] train: loss: 0.0870315
[Epoch 45; Iter   748/  823] train: loss: 0.0116482
[Epoch 45; Iter   778/  823] train: loss: 0.0551708
[Epoch 45; Iter   808/  823] train: loss: 0.0188646
[Epoch 45] ogbg-molhiv: 0.731965 val loss: 0.190218
[Epoch 45] ogbg-molhiv: 0.783040 test loss: 0.142732
[Epoch 46; Iter    15/  823] train: loss: 0.0099598
[Epoch 46; Iter    45/  823] train: loss: 0.0158805
[Epoch 46; Iter    75/  823] train: loss: 0.0200928
[Epoch 46; Iter   105/  823] train: loss: 0.1172104
[Epoch 46; Iter   135/  823] train: loss: 0.0427340
[Epoch 46; Iter   165/  823] train: loss: 0.0167217
[Epoch 46; Iter   195/  823] train: loss: 0.0204547
[Epoch 46; Iter   225/  823] train: loss: 0.0097712
[Epoch 46; Iter   255/  823] train: loss: 0.0104713
[Epoch 46; Iter   285/  823] train: loss: 0.0290847
[Epoch 46; Iter   315/  823] train: loss: 0.0314238
[Epoch 46; Iter   345/  823] train: loss: 0.0340568
[Epoch 46; Iter   375/  823] train: loss: 0.0651225
[Epoch 46; Iter   405/  823] train: loss: 0.0124606
[Epoch 46; Iter   435/  823] train: loss: 0.1824742
[Epoch 46; Iter   465/  823] train: loss: 0.0870998
[Epoch 46; Iter   495/  823] train: loss: 0.1202151
[Epoch 46; Iter   525/  823] train: loss: 0.0378370
[Epoch 46; Iter   555/  823] train: loss: 0.1381192
[Epoch 46; Iter   585/  823] train: loss: 0.0320478
[Epoch 46; Iter   615/  823] train: loss: 0.0305309
[Epoch 46; Iter   645/  823] train: loss: 0.0137236
[Epoch 46; Iter   675/  823] train: loss: 0.0401513
[Epoch 46; Iter   705/  823] train: loss: 0.1440808
[Epoch 46; Iter   735/  823] train: loss: 0.0862092
[Epoch 46; Iter   765/  823] train: loss: 0.0087149
[Epoch 46; Iter   795/  823] train: loss: 0.1498171
[Epoch 46] ogbg-molhiv: 0.709080 val loss: 0.209651
[Epoch 46] ogbg-molhiv: 0.775343 test loss: 0.129872
[Epoch 47; Iter     2/  823] train: loss: 0.0193495
[Epoch 47; Iter    32/  823] train: loss: 0.2498872
[Epoch 47; Iter    62/  823] train: loss: 0.0788752
[Epoch 47; Iter    92/  823] train: loss: 0.1270159
[Epoch 47; Iter   122/  823] train: loss: 0.0208148
[Epoch 47; Iter   152/  823] train: loss: 0.1135746
[Epoch 47; Iter   182/  823] train: loss: 0.0309218
[Epoch 47; Iter   212/  823] train: loss: 0.0123542
[Epoch 47; Iter   242/  823] train: loss: 0.0398570
[Epoch 47; Iter   272/  823] train: loss: 0.0116018
[Epoch 47; Iter   302/  823] train: loss: 0.0087479
[Epoch 47; Iter   332/  823] train: loss: 0.0093619
[Epoch 47; Iter   362/  823] train: loss: 0.0392678
[Epoch 47; Iter   392/  823] train: loss: 0.0917597
[Epoch 47; Iter   422/  823] train: loss: 0.0112346
[Epoch 47; Iter   452/  823] train: loss: 0.1329519
[Epoch 40; Iter   717/ 1097] train: loss: 0.1475891
[Epoch 40; Iter   747/ 1097] train: loss: 0.0472940
[Epoch 40; Iter   777/ 1097] train: loss: 0.0070625
[Epoch 40; Iter   807/ 1097] train: loss: 0.0405216
[Epoch 40; Iter   837/ 1097] train: loss: 0.0129339
[Epoch 40; Iter   867/ 1097] train: loss: 0.1259705
[Epoch 40; Iter   897/ 1097] train: loss: 0.0129485
[Epoch 40; Iter   927/ 1097] train: loss: 0.1578562
[Epoch 40; Iter   957/ 1097] train: loss: 0.2113395
[Epoch 40; Iter   987/ 1097] train: loss: 0.0394442
[Epoch 40; Iter  1017/ 1097] train: loss: 0.0681942
[Epoch 40; Iter  1047/ 1097] train: loss: 0.0133964
[Epoch 40; Iter  1077/ 1097] train: loss: 0.0246402
[Epoch 40] ogbg-molhiv: 0.810889 val loss: 0.078770
[Epoch 40] ogbg-molhiv: 0.751770 test loss: 0.328874
[Epoch 41; Iter    10/ 1097] train: loss: 0.1014234
[Epoch 41; Iter    40/ 1097] train: loss: 0.0090807
[Epoch 41; Iter    70/ 1097] train: loss: 0.0208239
[Epoch 41; Iter   100/ 1097] train: loss: 0.0185642
[Epoch 41; Iter   130/ 1097] train: loss: 0.0647152
[Epoch 41; Iter   160/ 1097] train: loss: 0.0446481
[Epoch 41; Iter   190/ 1097] train: loss: 0.0154048
[Epoch 41; Iter   220/ 1097] train: loss: 0.0095591
[Epoch 41; Iter   250/ 1097] train: loss: 0.0127335
[Epoch 41; Iter   280/ 1097] train: loss: 0.0782205
[Epoch 41; Iter   310/ 1097] train: loss: 0.2242315
[Epoch 41; Iter   340/ 1097] train: loss: 0.1105188
[Epoch 41; Iter   370/ 1097] train: loss: 0.0090794
[Epoch 41; Iter   400/ 1097] train: loss: 0.0098756
[Epoch 41; Iter   430/ 1097] train: loss: 0.0126791
[Epoch 41; Iter   460/ 1097] train: loss: 0.0885290
[Epoch 41; Iter   490/ 1097] train: loss: 0.2381130
[Epoch 41; Iter   520/ 1097] train: loss: 0.0546755
[Epoch 41; Iter   550/ 1097] train: loss: 0.0262190
[Epoch 41; Iter   580/ 1097] train: loss: 0.1226511
[Epoch 41; Iter   610/ 1097] train: loss: 0.0221264
[Epoch 41; Iter   640/ 1097] train: loss: 0.1934514
[Epoch 41; Iter   670/ 1097] train: loss: 0.0444031
[Epoch 41; Iter   700/ 1097] train: loss: 0.0169454
[Epoch 41; Iter   730/ 1097] train: loss: 0.0199128
[Epoch 41; Iter   760/ 1097] train: loss: 0.0530698
[Epoch 41; Iter   790/ 1097] train: loss: 0.0787781
[Epoch 41; Iter   820/ 1097] train: loss: 0.0781397
[Epoch 41; Iter   850/ 1097] train: loss: 0.0141175
[Epoch 41; Iter   880/ 1097] train: loss: 0.0296233
[Epoch 41; Iter   910/ 1097] train: loss: 0.0247993
[Epoch 41; Iter   940/ 1097] train: loss: 0.0094966
[Epoch 41; Iter   970/ 1097] train: loss: 0.0973528
[Epoch 41; Iter  1000/ 1097] train: loss: 0.0410392
[Epoch 41; Iter  1030/ 1097] train: loss: 0.1295675
[Epoch 41; Iter  1060/ 1097] train: loss: 0.0939906
[Epoch 41; Iter  1090/ 1097] train: loss: 0.0874013
[Epoch 41] ogbg-molhiv: 0.806860 val loss: 0.081325
[Epoch 41] ogbg-molhiv: 0.773711 test loss: 0.570706
[Epoch 42; Iter    23/ 1097] train: loss: 0.0360139
[Epoch 42; Iter    53/ 1097] train: loss: 0.0502208
[Epoch 42; Iter    83/ 1097] train: loss: 0.0218849
[Epoch 42; Iter   113/ 1097] train: loss: 0.0164125
[Epoch 42; Iter   143/ 1097] train: loss: 0.0156234
[Epoch 42; Iter   173/ 1097] train: loss: 0.0465549
[Epoch 42; Iter   203/ 1097] train: loss: 0.1677294
[Epoch 42; Iter   233/ 1097] train: loss: 0.0994692
[Epoch 42; Iter   263/ 1097] train: loss: 0.1941619
[Epoch 42; Iter   293/ 1097] train: loss: 0.1093255
[Epoch 42; Iter   323/ 1097] train: loss: 0.0225104
[Epoch 42; Iter   353/ 1097] train: loss: 0.0409978
[Epoch 42; Iter   383/ 1097] train: loss: 0.1249191
[Epoch 42; Iter   413/ 1097] train: loss: 0.0242776
[Epoch 42; Iter   443/ 1097] train: loss: 0.2239212
[Epoch 42; Iter   473/ 1097] train: loss: 0.0356414
[Epoch 42; Iter   503/ 1097] train: loss: 0.0840710
[Epoch 42; Iter   533/ 1097] train: loss: 0.0835542
[Epoch 42; Iter   563/ 1097] train: loss: 0.0333104
[Epoch 42; Iter   593/ 1097] train: loss: 0.0303451
[Epoch 42; Iter   623/ 1097] train: loss: 0.0258284
[Epoch 42; Iter   653/ 1097] train: loss: 0.2053165
[Epoch 42; Iter   683/ 1097] train: loss: 0.2095761
[Epoch 42; Iter   713/ 1097] train: loss: 0.0083862
[Epoch 42; Iter   743/ 1097] train: loss: 0.1378704
[Epoch 42; Iter   773/ 1097] train: loss: 0.3026192
[Epoch 42; Iter   803/ 1097] train: loss: 0.2372197
[Epoch 42; Iter   833/ 1097] train: loss: 0.0184717
[Epoch 42; Iter   863/ 1097] train: loss: 0.1135671
[Epoch 42; Iter   893/ 1097] train: loss: 0.1069573
[Epoch 42; Iter   923/ 1097] train: loss: 0.0220168
[Epoch 42; Iter   953/ 1097] train: loss: 0.1514161
[Epoch 42; Iter   983/ 1097] train: loss: 0.0209397
[Epoch 42; Iter  1013/ 1097] train: loss: 0.1425965
[Epoch 42; Iter  1043/ 1097] train: loss: 0.1532590
[Epoch 42; Iter  1073/ 1097] train: loss: 0.0248018
[Epoch 42] ogbg-molhiv: 0.817959 val loss: 0.083838
[Epoch 42] ogbg-molhiv: 0.770341 test loss: 0.487466
[Epoch 43; Iter     6/ 1097] train: loss: 0.0622464
[Epoch 43; Iter    36/ 1097] train: loss: 0.0682503
[Epoch 43; Iter    66/ 1097] train: loss: 0.1465969
[Epoch 43; Iter    96/ 1097] train: loss: 0.1696530
[Epoch 43; Iter   126/ 1097] train: loss: 0.0382664
[Epoch 43; Iter   156/ 1097] train: loss: 0.0220362
[Epoch 43; Iter   186/ 1097] train: loss: 0.2204294
[Epoch 43; Iter   216/ 1097] train: loss: 0.1716877
[Epoch 43; Iter   246/ 1097] train: loss: 0.1875116
[Epoch 43; Iter   276/ 1097] train: loss: 0.0207666
[Epoch 43; Iter   306/ 1097] train: loss: 0.0209318
[Epoch 43; Iter   336/ 1097] train: loss: 0.0164403
[Epoch 43; Iter   366/ 1097] train: loss: 0.0094115
[Epoch 43; Iter   396/ 1097] train: loss: 0.1834781
[Epoch 43; Iter   426/ 1097] train: loss: 0.0362430
[Epoch 43; Iter   456/ 1097] train: loss: 0.0365771
[Epoch 43; Iter   486/ 1097] train: loss: 0.0155321
[Epoch 43; Iter   516/ 1097] train: loss: 0.0227236
[Epoch 43; Iter   546/ 1097] train: loss: 0.0098593
[Epoch 43; Iter   576/ 1097] train: loss: 0.0648083
[Epoch 43; Iter   606/ 1097] train: loss: 0.1006159
[Epoch 43; Iter   636/ 1097] train: loss: 0.0086566
[Epoch 43; Iter   666/ 1097] train: loss: 0.0548289
[Epoch 43; Iter   696/ 1097] train: loss: 0.0382973
[Epoch 43; Iter   726/ 1097] train: loss: 0.0440454
[Epoch 43; Iter   756/ 1097] train: loss: 0.2210917
[Epoch 43; Iter   786/ 1097] train: loss: 0.1115110
[Epoch 43; Iter   816/ 1097] train: loss: 0.0192258
[Epoch 43; Iter   846/ 1097] train: loss: 0.0357160
[Epoch 43; Iter   876/ 1097] train: loss: 0.0814311
[Epoch 43; Iter   906/ 1097] train: loss: 0.1107718
[Epoch 43; Iter   936/ 1097] train: loss: 0.0298486
[Epoch 43; Iter   966/ 1097] train: loss: 0.0214501
[Epoch 43; Iter   996/ 1097] train: loss: 0.0076245
[Epoch 43; Iter  1026/ 1097] train: loss: 0.0126735
[Epoch 43; Iter  1056/ 1097] train: loss: 0.1855614
[Epoch 43; Iter  1086/ 1097] train: loss: 0.0123007
[Epoch 43] ogbg-molhiv: 0.789444 val loss: 0.382700
[Epoch 43] ogbg-molhiv: 0.727248 test loss: 0.615688
[Epoch 44; Iter    19/ 1097] train: loss: 0.0391602
[Epoch 44; Iter    49/ 1097] train: loss: 0.0074412
[Epoch 44; Iter    79/ 1097] train: loss: 0.0985170
[Epoch 44; Iter   109/ 1097] train: loss: 0.0211397
[Epoch 44; Iter   139/ 1097] train: loss: 0.0165474
[Epoch 44; Iter   169/ 1097] train: loss: 0.0112665
[Epoch 44; Iter   199/ 1097] train: loss: 0.0410511
[Epoch 44; Iter   229/ 1097] train: loss: 0.0114880
[Epoch 44; Iter   259/ 1097] train: loss: 0.0111235
[Epoch 44; Iter   289/ 1097] train: loss: 0.0046752
[Epoch 44; Iter   319/ 1097] train: loss: 0.2136616
[Epoch 44; Iter   349/ 1097] train: loss: 0.1355219
[Epoch 44; Iter   379/ 1097] train: loss: 0.0190590
[Epoch 44; Iter   409/ 1097] train: loss: 0.1759839
[Epoch 44; Iter   439/ 1097] train: loss: 0.0075202
[Epoch 44; Iter   469/ 1097] train: loss: 0.1378566
[Epoch 44; Iter   499/ 1097] train: loss: 0.0641139
[Epoch 44; Iter   529/ 1097] train: loss: 0.0849106
[Epoch 44; Iter   559/ 1097] train: loss: 0.0426882
[Epoch 44; Iter   589/ 1097] train: loss: 0.0362524
[Epoch 44; Iter   619/ 1097] train: loss: 0.0122656
[Epoch 44; Iter   649/ 1097] train: loss: 0.0607166
[Epoch 44; Iter   679/ 1097] train: loss: 0.1515624
[Epoch 44; Iter   709/ 1097] train: loss: 0.1717832
[Epoch 44; Iter   739/ 1097] train: loss: 0.0376855
[Epoch 44; Iter   769/ 1097] train: loss: 0.0368094
[Epoch 44; Iter   799/ 1097] train: loss: 0.0233536
[Epoch 44; Iter   829/ 1097] train: loss: 0.2427088
[Epoch 44; Iter   859/ 1097] train: loss: 0.0193818
[Epoch 44; Iter   889/ 1097] train: loss: 0.0117786
[Epoch 44; Iter   919/ 1097] train: loss: 0.0207677
[Epoch 44; Iter   949/ 1097] train: loss: 0.0984133
[Epoch 44; Iter   979/ 1097] train: loss: 0.0104302
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0230372
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0291805
[Epoch 44; Iter  1069/ 1097] train: loss: 0.1052642
[Epoch 44] ogbg-molhiv: 0.787555 val loss: 0.080264
[Epoch 44] ogbg-molhiv: 0.743899 test loss: 0.320445
[Epoch 45; Iter     2/ 1097] train: loss: 0.0112694
[Epoch 45; Iter    32/ 1097] train: loss: 0.0292462
[Epoch 45; Iter    62/ 1097] train: loss: 0.1639342
[Epoch 45; Iter    92/ 1097] train: loss: 0.0164492
[Epoch 45; Iter   122/ 1097] train: loss: 0.0154097
[Epoch 45; Iter   152/ 1097] train: loss: 0.0476983
[Epoch 45; Iter   182/ 1097] train: loss: 0.3113489
[Epoch 45; Iter   212/ 1097] train: loss: 0.1324112
[Epoch 45; Iter   242/ 1097] train: loss: 0.0337177
[Epoch 45; Iter   272/ 1097] train: loss: 0.0956669
[Epoch 45; Iter   302/ 1097] train: loss: 0.1513338
[Epoch 45; Iter   332/ 1097] train: loss: 0.0100745
[Epoch 45; Iter   362/ 1097] train: loss: 0.0631930
[Epoch 45; Iter   392/ 1097] train: loss: 0.0113101
[Epoch 45; Iter   422/ 1097] train: loss: 0.2460313
[Epoch 45; Iter   452/ 1097] train: loss: 0.1140588
[Epoch 45; Iter   482/ 1097] train: loss: 0.1722100
[Epoch 45; Iter   512/ 1097] train: loss: 0.1246056
[Epoch 45; Iter   542/ 1097] train: loss: 0.0079560
[Epoch 45; Iter   572/ 1097] train: loss: 0.1609250
[Epoch 45; Iter   602/ 1097] train: loss: 0.1525732
[Epoch 45; Iter   632/ 1097] train: loss: 0.0332978
[Epoch 45; Iter   662/ 1097] train: loss: 0.1732076
[Epoch 45; Iter   692/ 1097] train: loss: 0.0250399
[Epoch 45; Iter   722/ 1097] train: loss: 0.0396854
[Epoch 45; Iter   752/ 1097] train: loss: 0.0284535
[Epoch 45; Iter   782/ 1097] train: loss: 0.5408754
[Epoch 45; Iter   812/ 1097] train: loss: 0.0198164
[Epoch 45; Iter   842/ 1097] train: loss: 0.0199139
[Epoch 45; Iter   872/ 1097] train: loss: 0.0429029
[Epoch 45; Iter   902/ 1097] train: loss: 0.0180081
[Epoch 45; Iter   932/ 1097] train: loss: 0.0095113
[Epoch 45; Iter   962/ 1097] train: loss: 0.0269776
[Epoch 45; Iter   992/ 1097] train: loss: 0.1024283
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0236600
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0450173
[Epoch 45; Iter  1082/ 1097] train: loss: 0.1748144
[Epoch 45] ogbg-molhiv: 0.777196 val loss: 0.147071
[Epoch 45] ogbg-molhiv: 0.726435 test loss: 0.341763
[Epoch 46; Iter    15/ 1097] train: loss: 0.1853696
[Epoch 46; Iter    45/ 1097] train: loss: 0.0243733
[Epoch 46; Iter    75/ 1097] train: loss: 0.0630659
[Epoch 46; Iter   105/ 1097] train: loss: 0.0259259
[Epoch 46; Iter   135/ 1097] train: loss: 0.1021608
[Epoch 46; Iter   165/ 1097] train: loss: 0.1030510
[Epoch 46; Iter   195/ 1097] train: loss: 0.0149102
[Epoch 46; Iter   225/ 1097] train: loss: 0.0770067
[Epoch 46; Iter   255/ 1097] train: loss: 0.0472593
[Epoch 46; Iter   285/ 1097] train: loss: 0.0281119
[Epoch 46; Iter   315/ 1097] train: loss: 0.0743447
[Epoch 46; Iter   345/ 1097] train: loss: 0.0298918
[Epoch 46; Iter   375/ 1097] train: loss: 0.0187727
[Epoch 46; Iter   405/ 1097] train: loss: 0.1224489
[Epoch 46; Iter   435/ 1097] train: loss: 0.0133608
[Epoch 46; Iter   465/ 1097] train: loss: 0.0368818
[Epoch 46; Iter   495/ 1097] train: loss: 0.2189171
[Epoch 46; Iter   525/ 1097] train: loss: 0.0497913
[Epoch 46; Iter   555/ 1097] train: loss: 0.1234577
[Epoch 46; Iter   585/ 1097] train: loss: 0.1138951
[Epoch 46; Iter   615/ 1097] train: loss: 0.0240400
[Epoch 46; Iter   645/ 1097] train: loss: 0.1248547
[Epoch 46; Iter   675/ 1097] train: loss: 0.0175513
[Epoch 46; Iter   705/ 1097] train: loss: 0.0514415
[Epoch 46; Iter   735/ 1097] train: loss: 0.0139310
[Epoch 46; Iter   765/ 1097] train: loss: 0.2021736
[Epoch 46; Iter   795/ 1097] train: loss: 0.0534527
[Epoch 46; Iter   825/ 1097] train: loss: 0.0577670
[Epoch 46; Iter   855/ 1097] train: loss: 0.0340275
[Epoch 46; Iter   885/ 1097] train: loss: 0.1927443
[Epoch 46; Iter   915/ 1097] train: loss: 0.0292045
[Epoch 46; Iter   945/ 1097] train: loss: 0.0189537
[Epoch 46; Iter   975/ 1097] train: loss: 0.0143806
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0265578
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0273847
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0505668
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0295101
[Epoch 46] ogbg-molhiv: 0.804181 val loss: 0.140799
[Epoch 46] ogbg-molhiv: 0.734781 test loss: 0.369222
[Epoch 47; Iter    28/ 1097] train: loss: 0.0287826
[Epoch 47; Iter    58/ 1097] train: loss: 0.0946409
[Epoch 47; Iter    88/ 1097] train: loss: 0.0485478
[Epoch 47; Iter   118/ 1097] train: loss: 0.0898155
[Epoch 47; Iter   148/ 1097] train: loss: 0.0246403
[Epoch 47; Iter   178/ 1097] train: loss: 0.0883755
[Epoch 47; Iter   208/ 1097] train: loss: 0.2144098
[Epoch 47; Iter   238/ 1097] train: loss: 0.0247641
[Epoch 47; Iter   268/ 1097] train: loss: 0.0410874
[Epoch 47; Iter   298/ 1097] train: loss: 0.0072949
[Epoch 47; Iter   328/ 1097] train: loss: 0.1661100
[Epoch 47; Iter   358/ 1097] train: loss: 0.0541461
[Epoch 47; Iter   388/ 1097] train: loss: 0.0164185
[Epoch 47; Iter   418/ 1097] train: loss: 0.1374594
[Epoch 47; Iter   448/ 1097] train: loss: 0.0489365
[Epoch 47; Iter   478/ 1097] train: loss: 0.0213882
[Epoch 47; Iter   508/ 1097] train: loss: 0.1245761
[Epoch 47; Iter   538/ 1097] train: loss: 0.2138771
[Epoch 47; Iter   568/ 1097] train: loss: 0.0976462
[Epoch 47; Iter   598/ 1097] train: loss: 0.0993884
[Epoch 47; Iter   628/ 1097] train: loss: 0.0096071
[Epoch 47; Iter   658/ 1097] train: loss: 0.0397498
[Epoch 47; Iter   688/ 1097] train: loss: 0.0367794
[Epoch 47; Iter   718/ 1097] train: loss: 0.0128373
[Epoch 47; Iter   748/ 1097] train: loss: 0.0154895
[Epoch 47; Iter   778/ 1097] train: loss: 0.0407841
[Epoch 47; Iter   808/ 1097] train: loss: 0.0087912
[Epoch 47; Iter   838/ 1097] train: loss: 0.0125249
[Epoch 47; Iter   868/ 1097] train: loss: 0.0714942
[Epoch 47; Iter   898/ 1097] train: loss: 0.0879102
[Epoch 47; Iter   928/ 1097] train: loss: 0.0145575
[Epoch 47; Iter   958/ 1097] train: loss: 0.3698148
[Epoch 47; Iter   988/ 1097] train: loss: 0.3071221
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0835382
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0355835
[Epoch 47; Iter  1078/ 1097] train: loss: 0.1053222
[Epoch 47] ogbg-molhiv: 0.774419 val loss: 0.217730
[Epoch 47] ogbg-molhiv: 0.730109 test loss: 0.455574
[Epoch 48; Iter    11/ 1097] train: loss: 0.1729876
[Epoch 48; Iter    41/ 1097] train: loss: 0.1389906
[Epoch 48; Iter    71/ 1097] train: loss: 0.0225658
[Epoch 48; Iter   101/ 1097] train: loss: 0.4265406
[Epoch 48; Iter   131/ 1097] train: loss: 0.0179498
[Epoch 48; Iter   161/ 1097] train: loss: 0.0155089
[Epoch 48; Iter   191/ 1097] train: loss: 0.1597911
[Epoch 48; Iter   221/ 1097] train: loss: 0.0504916
[Epoch 48; Iter   251/ 1097] train: loss: 0.0374440
[Epoch 48; Iter   281/ 1097] train: loss: 0.0136126
[Epoch 48; Iter   311/ 1097] train: loss: 0.0208443
[Epoch 48; Iter   341/ 1097] train: loss: 0.0185586
[Epoch 48; Iter   371/ 1097] train: loss: 0.0182700
[Epoch 48; Iter   401/ 1097] train: loss: 0.0478773
[Epoch 48; Iter   431/ 1097] train: loss: 0.0334398
[Epoch 48; Iter   461/ 1097] train: loss: 0.0835607
[Epoch 48; Iter   491/ 1097] train: loss: 0.1110475
[Epoch 48; Iter   521/ 1097] train: loss: 0.0135525
[Epoch 48; Iter   551/ 1097] train: loss: 0.0865521
[Epoch 48; Iter   581/ 1097] train: loss: 0.1177331
[Epoch 48; Iter   611/ 1097] train: loss: 0.0083586
[Epoch 48; Iter   641/ 1097] train: loss: 0.0423551
[Epoch 48; Iter   671/ 1097] train: loss: 0.0111155
[Epoch 48; Iter   701/ 1097] train: loss: 0.0479013
[Epoch 48; Iter   731/ 1097] train: loss: 0.0975448
[Epoch 48; Iter   761/ 1097] train: loss: 0.0967449
[Epoch 48; Iter   791/ 1097] train: loss: 0.0576632
[Epoch 48; Iter   821/ 1097] train: loss: 0.0634070
[Epoch 48; Iter   851/ 1097] train: loss: 0.0056028
[Epoch 47; Iter   482/  823] train: loss: 0.0167385
[Epoch 47; Iter   512/  823] train: loss: 0.0103569
[Epoch 47; Iter   542/  823] train: loss: 0.0209423
[Epoch 47; Iter   572/  823] train: loss: 0.0136239
[Epoch 47; Iter   602/  823] train: loss: 0.1126814
[Epoch 47; Iter   632/  823] train: loss: 0.1719136
[Epoch 47; Iter   662/  823] train: loss: 0.0185125
[Epoch 47; Iter   692/  823] train: loss: 0.1761299
[Epoch 47; Iter   722/  823] train: loss: 0.0087234
[Epoch 47; Iter   752/  823] train: loss: 0.0284855
[Epoch 47; Iter   782/  823] train: loss: 0.0330373
[Epoch 47; Iter   812/  823] train: loss: 0.0191877
[Epoch 47] ogbg-molhiv: 0.726360 val loss: 0.165306
[Epoch 47] ogbg-molhiv: 0.765724 test loss: 0.212720
[Epoch 48; Iter    19/  823] train: loss: 0.0199539
[Epoch 48; Iter    49/  823] train: loss: 0.0185571
[Epoch 48; Iter    79/  823] train: loss: 0.0511719
[Epoch 48; Iter   109/  823] train: loss: 0.0888362
[Epoch 48; Iter   139/  823] train: loss: 0.0118411
[Epoch 48; Iter   169/  823] train: loss: 0.0698574
[Epoch 48; Iter   199/  823] train: loss: 0.0086965
[Epoch 48; Iter   229/  823] train: loss: 0.0378005
[Epoch 48; Iter   259/  823] train: loss: 0.0110139
[Epoch 48; Iter   289/  823] train: loss: 0.0242857
[Epoch 48; Iter   319/  823] train: loss: 0.0131666
[Epoch 48; Iter   349/  823] train: loss: 0.0159537
[Epoch 48; Iter   379/  823] train: loss: 0.0241296
[Epoch 48; Iter   409/  823] train: loss: 0.0131107
[Epoch 48; Iter   439/  823] train: loss: 0.0384755
[Epoch 48; Iter   469/  823] train: loss: 0.0129902
[Epoch 48; Iter   499/  823] train: loss: 0.0722075
[Epoch 48; Iter   529/  823] train: loss: 0.0148643
[Epoch 48; Iter   559/  823] train: loss: 0.3124194
[Epoch 48; Iter   589/  823] train: loss: 0.0701019
[Epoch 48; Iter   619/  823] train: loss: 0.0519373
[Epoch 48; Iter   649/  823] train: loss: 0.0461524
[Epoch 48; Iter   679/  823] train: loss: 0.0391078
[Epoch 48; Iter   709/  823] train: loss: 0.0239642
[Epoch 48; Iter   739/  823] train: loss: 0.0506225
[Epoch 48; Iter   769/  823] train: loss: 0.0267178
[Epoch 48; Iter   799/  823] train: loss: 0.1143781
[Epoch 48] ogbg-molhiv: 0.720110 val loss: 0.199707
[Epoch 48] ogbg-molhiv: 0.757088 test loss: 0.237556
[Epoch 49; Iter     6/  823] train: loss: 0.0164479
[Epoch 49; Iter    36/  823] train: loss: 0.0505069
[Epoch 49; Iter    66/  823] train: loss: 0.0612525
[Epoch 49; Iter    96/  823] train: loss: 0.0433470
[Epoch 49; Iter   126/  823] train: loss: 0.1696093
[Epoch 49; Iter   156/  823] train: loss: 0.0353048
[Epoch 49; Iter   186/  823] train: loss: 0.0243831
[Epoch 49; Iter   216/  823] train: loss: 0.0113568
[Epoch 49; Iter   246/  823] train: loss: 0.0555904
[Epoch 49; Iter   276/  823] train: loss: 0.0949979
[Epoch 49; Iter   306/  823] train: loss: 0.0166973
[Epoch 49; Iter   336/  823] train: loss: 0.0172378
[Epoch 49; Iter   366/  823] train: loss: 0.0390460
[Epoch 49; Iter   396/  823] train: loss: 0.1418731
[Epoch 49; Iter   426/  823] train: loss: 0.0398746
[Epoch 49; Iter   456/  823] train: loss: 0.0137873
[Epoch 49; Iter   486/  823] train: loss: 0.0089323
[Epoch 49; Iter   516/  823] train: loss: 0.1529029
[Epoch 49; Iter   546/  823] train: loss: 0.1465789
[Epoch 49; Iter   576/  823] train: loss: 0.0285116
[Epoch 49; Iter   606/  823] train: loss: 0.0127662
[Epoch 49; Iter   636/  823] train: loss: 0.1450808
[Epoch 49; Iter   666/  823] train: loss: 0.0950051
[Epoch 49; Iter   696/  823] train: loss: 0.0099841
[Epoch 49; Iter   726/  823] train: loss: 0.1060690
[Epoch 49; Iter   756/  823] train: loss: 0.0472026
[Epoch 49; Iter   786/  823] train: loss: 0.0331639
[Epoch 49; Iter   816/  823] train: loss: 0.0090726
[Epoch 49] ogbg-molhiv: 0.728059 val loss: 0.205900
[Epoch 49] ogbg-molhiv: 0.768770 test loss: 0.234623
[Epoch 50; Iter    23/  823] train: loss: 0.1045746
[Epoch 50; Iter    53/  823] train: loss: 0.0274257
[Epoch 50; Iter    83/  823] train: loss: 0.0217783
[Epoch 50; Iter   113/  823] train: loss: 0.0372876
[Epoch 50; Iter   143/  823] train: loss: 0.0332945
[Epoch 50; Iter   173/  823] train: loss: 0.0133950
[Epoch 50; Iter   203/  823] train: loss: 0.0732045
[Epoch 50; Iter   233/  823] train: loss: 0.0193766
[Epoch 50; Iter   263/  823] train: loss: 0.1698309
[Epoch 50; Iter   293/  823] train: loss: 0.1195702
[Epoch 50; Iter   323/  823] train: loss: 0.0103854
[Epoch 50; Iter   353/  823] train: loss: 0.0178259
[Epoch 50; Iter   383/  823] train: loss: 0.0473058
[Epoch 50; Iter   413/  823] train: loss: 0.1102604
[Epoch 50; Iter   443/  823] train: loss: 0.0651194
[Epoch 50; Iter   473/  823] train: loss: 0.0974586
[Epoch 50; Iter   503/  823] train: loss: 0.0903505
[Epoch 50; Iter   533/  823] train: loss: 0.0200035
[Epoch 50; Iter   563/  823] train: loss: 0.1844590
[Epoch 50; Iter   593/  823] train: loss: 0.1821869
[Epoch 50; Iter   623/  823] train: loss: 0.0387269
[Epoch 50; Iter   653/  823] train: loss: 0.0255917
[Epoch 50; Iter   683/  823] train: loss: 0.0100640
[Epoch 50; Iter   713/  823] train: loss: 0.0754147
[Epoch 50; Iter   743/  823] train: loss: 0.0116935
[Epoch 50; Iter   773/  823] train: loss: 0.0281980
[Epoch 50; Iter   803/  823] train: loss: 0.0096252
[Epoch 50] ogbg-molhiv: 0.735051 val loss: 0.155243
[Epoch 50] ogbg-molhiv: 0.772846 test loss: 0.244695
[Epoch 51; Iter    10/  823] train: loss: 0.0437187
[Epoch 51; Iter    40/  823] train: loss: 0.0750911
[Epoch 51; Iter    70/  823] train: loss: 0.0213904
[Epoch 51; Iter   100/  823] train: loss: 0.0242956
[Epoch 51; Iter   130/  823] train: loss: 0.0405302
[Epoch 51; Iter   160/  823] train: loss: 0.1122481
[Epoch 51; Iter   190/  823] train: loss: 0.0294397
[Epoch 51; Iter   220/  823] train: loss: 0.0143138
[Epoch 51; Iter   250/  823] train: loss: 0.0192649
[Epoch 51; Iter   280/  823] train: loss: 0.0125292
[Epoch 51; Iter   310/  823] train: loss: 0.0275861
[Epoch 51; Iter   340/  823] train: loss: 0.1164584
[Epoch 51; Iter   370/  823] train: loss: 0.0145307
[Epoch 51; Iter   400/  823] train: loss: 0.1390449
[Epoch 51; Iter   430/  823] train: loss: 0.0419307
[Epoch 51; Iter   460/  823] train: loss: 0.1835109
[Epoch 51; Iter   490/  823] train: loss: 0.0162605
[Epoch 51; Iter   520/  823] train: loss: 0.0298168
[Epoch 51; Iter   550/  823] train: loss: 0.0103738
[Epoch 51; Iter   580/  823] train: loss: 0.0145034
[Epoch 51; Iter   610/  823] train: loss: 0.1440095
[Epoch 51; Iter   640/  823] train: loss: 0.0615352
[Epoch 51; Iter   670/  823] train: loss: 0.0212011
[Epoch 51; Iter   700/  823] train: loss: 0.1117903
[Epoch 51; Iter   730/  823] train: loss: 0.0299502
[Epoch 51; Iter   760/  823] train: loss: 0.0252167
[Epoch 51; Iter   790/  823] train: loss: 0.0455204
[Epoch 51; Iter   820/  823] train: loss: 0.0134257
[Epoch 51] ogbg-molhiv: 0.740940 val loss: 0.188094
[Epoch 51] ogbg-molhiv: 0.761498 test loss: 0.190321
[Epoch 52; Iter    27/  823] train: loss: 0.1103358
[Epoch 52; Iter    57/  823] train: loss: 0.0175825
[Epoch 52; Iter    87/  823] train: loss: 0.0098620
[Epoch 52; Iter   117/  823] train: loss: 0.0445751
[Epoch 52; Iter   147/  823] train: loss: 0.0177997
[Epoch 52; Iter   177/  823] train: loss: 0.0732047
[Epoch 52; Iter   207/  823] train: loss: 0.0081460
[Epoch 52; Iter   237/  823] train: loss: 0.0365387
[Epoch 52; Iter   267/  823] train: loss: 0.0872459
[Epoch 52; Iter   297/  823] train: loss: 0.0630864
[Epoch 52; Iter   327/  823] train: loss: 0.0104361
[Epoch 52; Iter   357/  823] train: loss: 0.0401845
[Epoch 52; Iter   387/  823] train: loss: 0.1592759
[Epoch 52; Iter   417/  823] train: loss: 0.0092463
[Epoch 52; Iter   447/  823] train: loss: 0.0562363
[Epoch 52; Iter   477/  823] train: loss: 0.1044170
[Epoch 52; Iter   507/  823] train: loss: 0.0299855
[Epoch 52; Iter   537/  823] train: loss: 0.0539516
[Epoch 52; Iter   567/  823] train: loss: 0.0223001
[Epoch 52; Iter   597/  823] train: loss: 0.1365501
[Epoch 52; Iter   627/  823] train: loss: 0.0126040
[Epoch 52; Iter   657/  823] train: loss: 0.0694635
[Epoch 52; Iter   687/  823] train: loss: 0.1907021
[Epoch 52; Iter   717/  823] train: loss: 0.1092441
[Epoch 52; Iter   747/  823] train: loss: 0.0190210
[Epoch 44; Iter   799/ 1097] train: loss: 0.0197842
[Epoch 44; Iter   829/ 1097] train: loss: 0.0642225
[Epoch 44; Iter   859/ 1097] train: loss: 0.0946622
[Epoch 44; Iter   889/ 1097] train: loss: 0.0220400
[Epoch 44; Iter   919/ 1097] train: loss: 0.0210219
[Epoch 44; Iter   949/ 1097] train: loss: 0.0222763
[Epoch 44; Iter   979/ 1097] train: loss: 0.0158902
[Epoch 44; Iter  1009/ 1097] train: loss: 0.2722726
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0098260
[Epoch 44; Iter  1069/ 1097] train: loss: 0.1499522
[Epoch 44] ogbg-molhiv: 0.800384 val loss: 0.083381
[Epoch 44] ogbg-molhiv: 0.749582 test loss: 0.131732
[Epoch 45; Iter     2/ 1097] train: loss: 0.0595954
[Epoch 45; Iter    32/ 1097] train: loss: 0.2593888
[Epoch 45; Iter    62/ 1097] train: loss: 0.0469778
[Epoch 45; Iter    92/ 1097] train: loss: 0.0871946
[Epoch 45; Iter   122/ 1097] train: loss: 0.0303467
[Epoch 45; Iter   152/ 1097] train: loss: 0.1091725
[Epoch 45; Iter   182/ 1097] train: loss: 0.0313652
[Epoch 45; Iter   212/ 1097] train: loss: 0.0821732
[Epoch 45; Iter   242/ 1097] train: loss: 0.0930813
[Epoch 45; Iter   272/ 1097] train: loss: 0.0347149
[Epoch 45; Iter   302/ 1097] train: loss: 0.1819802
[Epoch 45; Iter   332/ 1097] train: loss: 0.2181082
[Epoch 45; Iter   362/ 1097] train: loss: 0.0645790
[Epoch 45; Iter   392/ 1097] train: loss: 0.0267013
[Epoch 45; Iter   422/ 1097] train: loss: 0.0682663
[Epoch 45; Iter   452/ 1097] train: loss: 0.0214144
[Epoch 45; Iter   482/ 1097] train: loss: 0.1438411
[Epoch 45; Iter   512/ 1097] train: loss: 0.0811881
[Epoch 45; Iter   542/ 1097] train: loss: 0.0248060
[Epoch 45; Iter   572/ 1097] train: loss: 0.2254413
[Epoch 45; Iter   602/ 1097] train: loss: 0.0338096
[Epoch 45; Iter   632/ 1097] train: loss: 0.1269957
[Epoch 45; Iter   662/ 1097] train: loss: 0.0864802
[Epoch 45; Iter   692/ 1097] train: loss: 0.0128797
[Epoch 45; Iter   722/ 1097] train: loss: 0.1892221
[Epoch 45; Iter   752/ 1097] train: loss: 0.0195231
[Epoch 45; Iter   782/ 1097] train: loss: 0.1510128
[Epoch 45; Iter   812/ 1097] train: loss: 0.0203045
[Epoch 45; Iter   842/ 1097] train: loss: 0.0243856
[Epoch 45; Iter   872/ 1097] train: loss: 0.0227340
[Epoch 45; Iter   902/ 1097] train: loss: 0.0351903
[Epoch 45; Iter   932/ 1097] train: loss: 0.0826426
[Epoch 45; Iter   962/ 1097] train: loss: 0.0220591
[Epoch 45; Iter   992/ 1097] train: loss: 0.2293739
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0985893
[Epoch 45; Iter  1052/ 1097] train: loss: 0.0660966
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0467911
[Epoch 45] ogbg-molhiv: 0.789349 val loss: 0.088565
[Epoch 45] ogbg-molhiv: 0.745567 test loss: 0.137669
[Epoch 46; Iter    15/ 1097] train: loss: 0.0261104
[Epoch 46; Iter    45/ 1097] train: loss: 0.0142667
[Epoch 46; Iter    75/ 1097] train: loss: 0.0157308
[Epoch 46; Iter   105/ 1097] train: loss: 0.0182189
[Epoch 46; Iter   135/ 1097] train: loss: 0.1203852
[Epoch 46; Iter   165/ 1097] train: loss: 0.0167459
[Epoch 46; Iter   195/ 1097] train: loss: 0.0128400
[Epoch 46; Iter   225/ 1097] train: loss: 0.1964947
[Epoch 46; Iter   255/ 1097] train: loss: 0.0561565
[Epoch 46; Iter   285/ 1097] train: loss: 0.0130149
[Epoch 46; Iter   315/ 1097] train: loss: 0.0270425
[Epoch 46; Iter   345/ 1097] train: loss: 0.0169031
[Epoch 46; Iter   375/ 1097] train: loss: 0.0240843
[Epoch 46; Iter   405/ 1097] train: loss: 0.0290951
[Epoch 46; Iter   435/ 1097] train: loss: 0.1235620
[Epoch 46; Iter   465/ 1097] train: loss: 0.0158797
[Epoch 46; Iter   495/ 1097] train: loss: 0.0095781
[Epoch 46; Iter   525/ 1097] train: loss: 0.1326044
[Epoch 46; Iter   555/ 1097] train: loss: 0.0348020
[Epoch 46; Iter   585/ 1097] train: loss: 0.0251853
[Epoch 46; Iter   615/ 1097] train: loss: 0.1521090
[Epoch 46; Iter   645/ 1097] train: loss: 0.0767290
[Epoch 46; Iter   675/ 1097] train: loss: 0.1129471
[Epoch 46; Iter   705/ 1097] train: loss: 0.0863698
[Epoch 46; Iter   735/ 1097] train: loss: 0.0160190
[Epoch 46; Iter   765/ 1097] train: loss: 0.1213835
[Epoch 46; Iter   795/ 1097] train: loss: 0.1606115
[Epoch 46; Iter   825/ 1097] train: loss: 0.0204320
[Epoch 46; Iter   855/ 1097] train: loss: 0.0470849
[Epoch 46; Iter   885/ 1097] train: loss: 0.1559171
[Epoch 46; Iter   915/ 1097] train: loss: 0.0374293
[Epoch 46; Iter   945/ 1097] train: loss: 0.0248565
[Epoch 46; Iter   975/ 1097] train: loss: 0.0641560
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0315359
[Epoch 46; Iter  1035/ 1097] train: loss: 0.0456462
[Epoch 46; Iter  1065/ 1097] train: loss: 0.0167221
[Epoch 46; Iter  1095/ 1097] train: loss: 0.1594793
[Epoch 46] ogbg-molhiv: 0.788234 val loss: 0.085611
[Epoch 46] ogbg-molhiv: 0.742757 test loss: 0.137459
[Epoch 47; Iter    28/ 1097] train: loss: 0.0459401
[Epoch 47; Iter    58/ 1097] train: loss: 0.0215927
[Epoch 47; Iter    88/ 1097] train: loss: 0.0201964
[Epoch 47; Iter   118/ 1097] train: loss: 0.0193338
[Epoch 47; Iter   148/ 1097] train: loss: 0.1137585
[Epoch 47; Iter   178/ 1097] train: loss: 0.0626983
[Epoch 47; Iter   208/ 1097] train: loss: 0.0452639
[Epoch 47; Iter   238/ 1097] train: loss: 0.1240999
[Epoch 47; Iter   268/ 1097] train: loss: 0.1594694
[Epoch 47; Iter   298/ 1097] train: loss: 0.1128381
[Epoch 47; Iter   328/ 1097] train: loss: 0.1400471
[Epoch 47; Iter   358/ 1097] train: loss: 0.0956723
[Epoch 47; Iter   388/ 1097] train: loss: 0.0289410
[Epoch 47; Iter   418/ 1097] train: loss: 0.1880770
[Epoch 47; Iter   448/ 1097] train: loss: 0.0297991
[Epoch 47; Iter   478/ 1097] train: loss: 0.1728236
[Epoch 47; Iter   508/ 1097] train: loss: 0.0741027
[Epoch 47; Iter   538/ 1097] train: loss: 0.0224990
[Epoch 47; Iter   568/ 1097] train: loss: 0.0639130
[Epoch 47; Iter   598/ 1097] train: loss: 0.1215989
[Epoch 47; Iter   628/ 1097] train: loss: 0.0182407
[Epoch 47; Iter   658/ 1097] train: loss: 0.0242930
[Epoch 47; Iter   688/ 1097] train: loss: 0.0124735
[Epoch 47; Iter   718/ 1097] train: loss: 0.0108566
[Epoch 47; Iter   748/ 1097] train: loss: 0.0360181
[Epoch 47; Iter   778/ 1097] train: loss: 0.0158096
[Epoch 47; Iter   808/ 1097] train: loss: 0.0206007
[Epoch 47; Iter   838/ 1097] train: loss: 0.0257173
[Epoch 47; Iter   868/ 1097] train: loss: 0.0173160
[Epoch 47; Iter   898/ 1097] train: loss: 0.0382635
[Epoch 47; Iter   928/ 1097] train: loss: 0.0235234
[Epoch 47; Iter   958/ 1097] train: loss: 0.1816857
[Epoch 47; Iter   988/ 1097] train: loss: 0.0566081
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0395749
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0172344
[Epoch 47; Iter  1078/ 1097] train: loss: 0.0492872
[Epoch 47] ogbg-molhiv: 0.806842 val loss: 0.083842
[Epoch 47] ogbg-molhiv: 0.758898 test loss: 0.134696
[Epoch 48; Iter    11/ 1097] train: loss: 0.0164701
[Epoch 48; Iter    41/ 1097] train: loss: 0.0320576
[Epoch 48; Iter    71/ 1097] train: loss: 0.0446544
[Epoch 48; Iter   101/ 1097] train: loss: 0.1962928
[Epoch 48; Iter   131/ 1097] train: loss: 0.0219988
[Epoch 48; Iter   161/ 1097] train: loss: 0.0371107
[Epoch 48; Iter   191/ 1097] train: loss: 0.0435820
[Epoch 48; Iter   221/ 1097] train: loss: 0.0408921
[Epoch 48; Iter   251/ 1097] train: loss: 0.0183625
[Epoch 48; Iter   281/ 1097] train: loss: 0.0118034
[Epoch 48; Iter   311/ 1097] train: loss: 0.2104512
[Epoch 48; Iter   341/ 1097] train: loss: 0.1294851
[Epoch 48; Iter   371/ 1097] train: loss: 0.0875447
[Epoch 48; Iter   401/ 1097] train: loss: 0.0333516
[Epoch 48; Iter   431/ 1097] train: loss: 0.0200779
[Epoch 48; Iter   461/ 1097] train: loss: 0.0235130
[Epoch 48; Iter   491/ 1097] train: loss: 0.0205732
[Epoch 48; Iter   521/ 1097] train: loss: 0.0373598
[Epoch 48; Iter   551/ 1097] train: loss: 0.0399616
[Epoch 48; Iter   581/ 1097] train: loss: 0.1811381
[Epoch 48; Iter   611/ 1097] train: loss: 0.0505641
[Epoch 48; Iter   641/ 1097] train: loss: 0.1846898
[Epoch 48; Iter   671/ 1097] train: loss: 0.0117642
[Epoch 48; Iter   701/ 1097] train: loss: 0.0195499
[Epoch 48; Iter   731/ 1097] train: loss: 0.0179881
[Epoch 48; Iter   761/ 1097] train: loss: 0.1705374
[Epoch 48; Iter   791/ 1097] train: loss: 0.0159961
[Epoch 48; Iter   821/ 1097] train: loss: 0.0189807
[Epoch 48; Iter   851/ 1097] train: loss: 0.1809888
[Epoch 45; Iter   960/  960] train: loss: 0.0110530
[Epoch 45] ogbg-molhiv: 0.758774 val loss: 0.192866
[Epoch 45] ogbg-molhiv: 0.754751 test loss: 0.178418
[Epoch 46; Iter    30/  960] train: loss: 0.0548903
[Epoch 46; Iter    60/  960] train: loss: 0.1848589
[Epoch 46; Iter    90/  960] train: loss: 0.0215479
[Epoch 46; Iter   120/  960] train: loss: 0.0082951
[Epoch 46; Iter   150/  960] train: loss: 0.0715595
[Epoch 46; Iter   180/  960] train: loss: 0.0581058
[Epoch 46; Iter   210/  960] train: loss: 0.2124603
[Epoch 46; Iter   240/  960] train: loss: 0.0683558
[Epoch 46; Iter   270/  960] train: loss: 0.0163434
[Epoch 46; Iter   300/  960] train: loss: 0.1015490
[Epoch 46; Iter   330/  960] train: loss: 0.0182108
[Epoch 46; Iter   360/  960] train: loss: 0.0100292
[Epoch 46; Iter   390/  960] train: loss: 0.0257808
[Epoch 46; Iter   420/  960] train: loss: 0.0133319
[Epoch 46; Iter   450/  960] train: loss: 0.0096316
[Epoch 46; Iter   480/  960] train: loss: 0.0081170
[Epoch 46; Iter   510/  960] train: loss: 0.1689840
[Epoch 46; Iter   540/  960] train: loss: 0.0609751
[Epoch 46; Iter   570/  960] train: loss: 0.0147543
[Epoch 46; Iter   600/  960] train: loss: 0.1925823
[Epoch 46; Iter   630/  960] train: loss: 0.0420908
[Epoch 46; Iter   660/  960] train: loss: 0.0176434
[Epoch 46; Iter   690/  960] train: loss: 0.0483017
[Epoch 46; Iter   720/  960] train: loss: 0.0499332
[Epoch 46; Iter   750/  960] train: loss: 0.0580730
[Epoch 46; Iter   780/  960] train: loss: 0.0956493
[Epoch 46; Iter   810/  960] train: loss: 0.0099068
[Epoch 46; Iter   840/  960] train: loss: 0.4682370
[Epoch 46; Iter   870/  960] train: loss: 0.0576439
[Epoch 46; Iter   900/  960] train: loss: 0.0728813
[Epoch 46; Iter   930/  960] train: loss: 0.0464053
[Epoch 46; Iter   960/  960] train: loss: 0.0591394
[Epoch 46] ogbg-molhiv: 0.741560 val loss: 0.212051
[Epoch 46] ogbg-molhiv: 0.769609 test loss: 0.201643
[Epoch 47; Iter    30/  960] train: loss: 0.2190256
[Epoch 47; Iter    60/  960] train: loss: 0.1193716
[Epoch 47; Iter    90/  960] train: loss: 0.0117030
[Epoch 47; Iter   120/  960] train: loss: 0.0243190
[Epoch 47; Iter   150/  960] train: loss: 0.0579255
[Epoch 47; Iter   180/  960] train: loss: 0.0137316
[Epoch 47; Iter   210/  960] train: loss: 0.0108553
[Epoch 47; Iter   240/  960] train: loss: 0.0058449
[Epoch 47; Iter   270/  960] train: loss: 0.1456150
[Epoch 47; Iter   300/  960] train: loss: 0.0653979
[Epoch 47; Iter   330/  960] train: loss: 0.0203327
[Epoch 47; Iter   360/  960] train: loss: 0.0598452
[Epoch 47; Iter   390/  960] train: loss: 0.0683383
[Epoch 47; Iter   420/  960] train: loss: 0.1477202
[Epoch 47; Iter   450/  960] train: loss: 0.0424744
[Epoch 47; Iter   480/  960] train: loss: 0.0403767
[Epoch 47; Iter   510/  960] train: loss: 0.0123921
[Epoch 47; Iter   540/  960] train: loss: 0.1133491
[Epoch 47; Iter   570/  960] train: loss: 0.0680005
[Epoch 47; Iter   600/  960] train: loss: 0.0099557
[Epoch 47; Iter   630/  960] train: loss: 0.0140810
[Epoch 47; Iter   660/  960] train: loss: 0.0374270
[Epoch 47; Iter   690/  960] train: loss: 0.0373663
[Epoch 47; Iter   720/  960] train: loss: 0.1919002
[Epoch 47; Iter   750/  960] train: loss: 0.0122866
[Epoch 47; Iter   780/  960] train: loss: 0.0137379
[Epoch 47; Iter   810/  960] train: loss: 0.0075955
[Epoch 47; Iter   840/  960] train: loss: 0.0166636
[Epoch 47; Iter   870/  960] train: loss: 0.0510914
[Epoch 47; Iter   900/  960] train: loss: 0.0609770
[Epoch 47; Iter   930/  960] train: loss: 0.0382164
[Epoch 47; Iter   960/  960] train: loss: 0.2534825
[Epoch 47] ogbg-molhiv: 0.742358 val loss: 0.813186
[Epoch 47] ogbg-molhiv: 0.756072 test loss: 0.250299
[Epoch 48; Iter    30/  960] train: loss: 0.0938583
[Epoch 48; Iter    60/  960] train: loss: 0.0402452
[Epoch 48; Iter    90/  960] train: loss: 0.1200988
[Epoch 48; Iter   120/  960] train: loss: 0.0211170
[Epoch 48; Iter   150/  960] train: loss: 0.0104100
[Epoch 48; Iter   180/  960] train: loss: 0.1017208
[Epoch 48; Iter   210/  960] train: loss: 0.1705410
[Epoch 48; Iter   240/  960] train: loss: 0.0512943
[Epoch 48; Iter   270/  960] train: loss: 0.0926149
[Epoch 48; Iter   300/  960] train: loss: 0.0533995
[Epoch 48; Iter   330/  960] train: loss: 0.0176982
[Epoch 48; Iter   360/  960] train: loss: 0.0130950
[Epoch 48; Iter   390/  960] train: loss: 0.0281839
[Epoch 48; Iter   420/  960] train: loss: 0.0464895
[Epoch 48; Iter   450/  960] train: loss: 0.0211714
[Epoch 48; Iter   480/  960] train: loss: 0.0717794
[Epoch 48; Iter   510/  960] train: loss: 0.1730850
[Epoch 48; Iter   540/  960] train: loss: 0.0598903
[Epoch 48; Iter   570/  960] train: loss: 0.0921964
[Epoch 48; Iter   600/  960] train: loss: 0.0119975
[Epoch 48; Iter   630/  960] train: loss: 0.0090953
[Epoch 48; Iter   660/  960] train: loss: 0.0168628
[Epoch 48; Iter   690/  960] train: loss: 0.0160812
[Epoch 48; Iter   720/  960] train: loss: 0.0455027
[Epoch 48; Iter   750/  960] train: loss: 0.0111488
[Epoch 48; Iter   780/  960] train: loss: 0.0158561
[Epoch 48; Iter   810/  960] train: loss: 0.1717640
[Epoch 48; Iter   840/  960] train: loss: 0.0141273
[Epoch 48; Iter   870/  960] train: loss: 0.0635819
[Epoch 48; Iter   900/  960] train: loss: 0.0068499
[Epoch 48; Iter   930/  960] train: loss: 0.0439138
[Epoch 48; Iter   960/  960] train: loss: 0.2680462
[Epoch 48] ogbg-molhiv: 0.763376 val loss: 0.644697
[Epoch 48] ogbg-molhiv: 0.767055 test loss: 0.252955
[Epoch 49; Iter    30/  960] train: loss: 0.0490776
[Epoch 49; Iter    60/  960] train: loss: 0.0558956
[Epoch 49; Iter    90/  960] train: loss: 0.0709546
[Epoch 49; Iter   120/  960] train: loss: 0.0894323
[Epoch 49; Iter   150/  960] train: loss: 0.0196568
[Epoch 49; Iter   180/  960] train: loss: 0.0176985
[Epoch 49; Iter   210/  960] train: loss: 0.1077608
[Epoch 49; Iter   240/  960] train: loss: 0.0273781
[Epoch 49; Iter   270/  960] train: loss: 0.1672505
[Epoch 49; Iter   300/  960] train: loss: 0.0064874
[Epoch 49; Iter   330/  960] train: loss: 0.0686854
[Epoch 49; Iter   360/  960] train: loss: 0.0073450
[Epoch 49; Iter   390/  960] train: loss: 0.0934006
[Epoch 49; Iter   420/  960] train: loss: 0.0273311
[Epoch 49; Iter   450/  960] train: loss: 0.3268257
[Epoch 49; Iter   480/  960] train: loss: 0.0627368
[Epoch 49; Iter   510/  960] train: loss: 0.0168059
[Epoch 49; Iter   540/  960] train: loss: 0.1989111
[Epoch 49; Iter   570/  960] train: loss: 0.0198447
[Epoch 49; Iter   600/  960] train: loss: 0.0452070
[Epoch 49; Iter   630/  960] train: loss: 0.1802254
[Epoch 49; Iter   660/  960] train: loss: 0.0316842
[Epoch 49; Iter   690/  960] train: loss: 0.0370324
[Epoch 49; Iter   720/  960] train: loss: 0.0316094
[Epoch 49; Iter   750/  960] train: loss: 0.0457844
[Epoch 49; Iter   780/  960] train: loss: 0.1826682
[Epoch 49; Iter   810/  960] train: loss: 0.0357457
[Epoch 49; Iter   840/  960] train: loss: 0.0115026
[Epoch 49; Iter   870/  960] train: loss: 0.0929191
[Epoch 49; Iter   900/  960] train: loss: 0.0126100
[Epoch 49; Iter   930/  960] train: loss: 0.0904898
[Epoch 49; Iter   960/  960] train: loss: 0.0080652
[Epoch 49] ogbg-molhiv: 0.757489 val loss: 0.158835
[Epoch 49] ogbg-molhiv: 0.754412 test loss: 0.199970
[Epoch 50; Iter    30/  960] train: loss: 0.2628440
[Epoch 50; Iter    60/  960] train: loss: 0.0392749
[Epoch 50; Iter    90/  960] train: loss: 0.0143212
[Epoch 50; Iter   120/  960] train: loss: 0.1062251
[Epoch 50; Iter   150/  960] train: loss: 0.0191435
[Epoch 50; Iter   180/  960] train: loss: 0.0370722
[Epoch 50; Iter   210/  960] train: loss: 0.0495269
[Epoch 50; Iter   240/  960] train: loss: 0.0130714
[Epoch 50; Iter   270/  960] train: loss: 0.1404566
[Epoch 50; Iter   300/  960] train: loss: 0.0391257
[Epoch 50; Iter   330/  960] train: loss: 0.0157737
[Epoch 50; Iter   360/  960] train: loss: 0.0247683
[Epoch 50; Iter   390/  960] train: loss: 0.0133637
[Epoch 50; Iter   420/  960] train: loss: 0.0152787
[Epoch 50; Iter   450/  960] train: loss: 0.0109436
[Epoch 50; Iter   480/  960] train: loss: 0.0105929
[Epoch 50; Iter   510/  960] train: loss: 0.0955942
[Epoch 50; Iter   540/  960] train: loss: 0.0963655
[Epoch 45; Iter   960/  960] train: loss: 0.0143197
[Epoch 45] ogbg-molhiv: 0.738094 val loss: 0.219859
[Epoch 45] ogbg-molhiv: 0.747791 test loss: 0.175319
[Epoch 46; Iter    30/  960] train: loss: 0.0249624
[Epoch 46; Iter    60/  960] train: loss: 0.0939248
[Epoch 46; Iter    90/  960] train: loss: 0.0302259
[Epoch 46; Iter   120/  960] train: loss: 0.0080559
[Epoch 46; Iter   150/  960] train: loss: 0.0430005
[Epoch 46; Iter   180/  960] train: loss: 0.1270995
[Epoch 46; Iter   210/  960] train: loss: 0.0576735
[Epoch 46; Iter   240/  960] train: loss: 0.1008074
[Epoch 46; Iter   270/  960] train: loss: 0.0116875
[Epoch 46; Iter   300/  960] train: loss: 0.0636974
[Epoch 46; Iter   330/  960] train: loss: 0.0151608
[Epoch 46; Iter   360/  960] train: loss: 0.0074945
[Epoch 46; Iter   390/  960] train: loss: 0.0137964
[Epoch 46; Iter   420/  960] train: loss: 0.0523055
[Epoch 46; Iter   450/  960] train: loss: 0.2208112
[Epoch 46; Iter   480/  960] train: loss: 0.0048084
[Epoch 46; Iter   510/  960] train: loss: 0.0330443
[Epoch 46; Iter   540/  960] train: loss: 0.0156339
[Epoch 46; Iter   570/  960] train: loss: 0.0319632
[Epoch 46; Iter   600/  960] train: loss: 0.0201948
[Epoch 46; Iter   630/  960] train: loss: 0.3343063
[Epoch 46; Iter   660/  960] train: loss: 0.1873266
[Epoch 46; Iter   690/  960] train: loss: 0.1800314
[Epoch 46; Iter   720/  960] train: loss: 0.0277505
[Epoch 46; Iter   750/  960] train: loss: 0.2057925
[Epoch 46; Iter   780/  960] train: loss: 0.1385466
[Epoch 46; Iter   810/  960] train: loss: 0.0394821
[Epoch 46; Iter   840/  960] train: loss: 0.1937058
[Epoch 46; Iter   870/  960] train: loss: 0.0112579
[Epoch 46; Iter   900/  960] train: loss: 0.0275874
[Epoch 46; Iter   930/  960] train: loss: 0.1999416
[Epoch 46; Iter   960/  960] train: loss: 0.3496808
[Epoch 46] ogbg-molhiv: 0.749131 val loss: 0.265235
[Epoch 46] ogbg-molhiv: 0.742878 test loss: 0.170154
[Epoch 47; Iter    30/  960] train: loss: 0.0127149
[Epoch 47; Iter    60/  960] train: loss: 0.0222711
[Epoch 47; Iter    90/  960] train: loss: 0.0106405
[Epoch 47; Iter   120/  960] train: loss: 0.0086620
[Epoch 47; Iter   150/  960] train: loss: 0.0419750
[Epoch 47; Iter   180/  960] train: loss: 0.1583169
[Epoch 47; Iter   210/  960] train: loss: 0.2206937
[Epoch 47; Iter   240/  960] train: loss: 0.0305503
[Epoch 47; Iter   270/  960] train: loss: 0.1327493
[Epoch 47; Iter   300/  960] train: loss: 0.1264653
[Epoch 47; Iter   330/  960] train: loss: 0.1783476
[Epoch 47; Iter   360/  960] train: loss: 0.0741756
[Epoch 47; Iter   390/  960] train: loss: 0.0112932
[Epoch 47; Iter   420/  960] train: loss: 0.0998644
[Epoch 47; Iter   450/  960] train: loss: 0.0969668
[Epoch 47; Iter   480/  960] train: loss: 0.0823209
[Epoch 47; Iter   510/  960] train: loss: 0.0342140
[Epoch 47; Iter   540/  960] train: loss: 0.0208843
[Epoch 47; Iter   570/  960] train: loss: 0.0106849
[Epoch 47; Iter   600/  960] train: loss: 0.0895288
[Epoch 47; Iter   630/  960] train: loss: 0.1147339
[Epoch 47; Iter   660/  960] train: loss: 0.0158070
[Epoch 47; Iter   690/  960] train: loss: 0.2244194
[Epoch 47; Iter   720/  960] train: loss: 0.0146196
[Epoch 47; Iter   750/  960] train: loss: 0.0368662
[Epoch 47; Iter   780/  960] train: loss: 0.1448940
[Epoch 47; Iter   810/  960] train: loss: 0.2051733
[Epoch 47; Iter   840/  960] train: loss: 0.0148036
[Epoch 47; Iter   870/  960] train: loss: 0.0658363
[Epoch 47; Iter   900/  960] train: loss: 0.0191344
[Epoch 47; Iter   930/  960] train: loss: 0.0161204
[Epoch 47; Iter   960/  960] train: loss: 0.0184679
[Epoch 47] ogbg-molhiv: 0.739006 val loss: 0.265515
[Epoch 47] ogbg-molhiv: 0.748433 test loss: 0.236688
[Epoch 48; Iter    30/  960] train: loss: 0.1151063
[Epoch 48; Iter    60/  960] train: loss: 0.0111058
[Epoch 48; Iter    90/  960] train: loss: 0.0190799
[Epoch 48; Iter   120/  960] train: loss: 0.0260096
[Epoch 48; Iter   150/  960] train: loss: 0.1287989
[Epoch 48; Iter   180/  960] train: loss: 0.1376916
[Epoch 48; Iter   210/  960] train: loss: 0.0807706
[Epoch 48; Iter   240/  960] train: loss: 0.0155186
[Epoch 48; Iter   270/  960] train: loss: 0.0145110
[Epoch 48; Iter   300/  960] train: loss: 0.0787326
[Epoch 48; Iter   330/  960] train: loss: 0.0169602
[Epoch 48; Iter   360/  960] train: loss: 0.0512928
[Epoch 48; Iter   390/  960] train: loss: 0.0496463
[Epoch 48; Iter   420/  960] train: loss: 0.1875737
[Epoch 48; Iter   450/  960] train: loss: 0.0338462
[Epoch 48; Iter   480/  960] train: loss: 0.0534767
[Epoch 48; Iter   510/  960] train: loss: 0.0352161
[Epoch 48; Iter   540/  960] train: loss: 0.0201497
[Epoch 48; Iter   570/  960] train: loss: 0.0178701
[Epoch 48; Iter   600/  960] train: loss: 0.1237889
[Epoch 48; Iter   630/  960] train: loss: 0.0707101
[Epoch 48; Iter   660/  960] train: loss: 0.0197191
[Epoch 48; Iter   690/  960] train: loss: 0.0078519
[Epoch 48; Iter   720/  960] train: loss: 0.1811323
[Epoch 48; Iter   750/  960] train: loss: 0.0545455
[Epoch 48; Iter   780/  960] train: loss: 0.0253470
[Epoch 48; Iter   810/  960] train: loss: 0.1029755
[Epoch 48; Iter   840/  960] train: loss: 0.0439348
[Epoch 48; Iter   870/  960] train: loss: 0.2107528
[Epoch 48; Iter   900/  960] train: loss: 0.0117807
[Epoch 48; Iter   930/  960] train: loss: 0.0156254
[Epoch 48; Iter   960/  960] train: loss: 0.0617070
[Epoch 48] ogbg-molhiv: 0.713861 val loss: 0.299663
[Epoch 48] ogbg-molhiv: 0.724667 test loss: 0.251930
[Epoch 49; Iter    30/  960] train: loss: 0.0264976
[Epoch 49; Iter    60/  960] train: loss: 0.1042088
[Epoch 49; Iter    90/  960] train: loss: 0.0413278
[Epoch 49; Iter   120/  960] train: loss: 0.0893278
[Epoch 49; Iter   150/  960] train: loss: 0.0558597
[Epoch 49; Iter   180/  960] train: loss: 0.0115675
[Epoch 49; Iter   210/  960] train: loss: 0.0148591
[Epoch 49; Iter   240/  960] train: loss: 0.0886082
[Epoch 49; Iter   270/  960] train: loss: 0.1052467
[Epoch 49; Iter   300/  960] train: loss: 0.1381701
[Epoch 49; Iter   330/  960] train: loss: 0.0498579
[Epoch 49; Iter   360/  960] train: loss: 0.0180722
[Epoch 49; Iter   390/  960] train: loss: 0.1811614
[Epoch 49; Iter   420/  960] train: loss: 0.0160080
[Epoch 49; Iter   450/  960] train: loss: 0.3542999
[Epoch 49; Iter   480/  960] train: loss: 0.0520923
[Epoch 49; Iter   510/  960] train: loss: 0.0215825
[Epoch 49; Iter   540/  960] train: loss: 0.1203115
[Epoch 49; Iter   570/  960] train: loss: 0.0935929
[Epoch 49; Iter   600/  960] train: loss: 0.0110334
[Epoch 49; Iter   630/  960] train: loss: 0.0174701
[Epoch 49; Iter   660/  960] train: loss: 0.0918610
[Epoch 49; Iter   690/  960] train: loss: 0.1789332
[Epoch 49; Iter   720/  960] train: loss: 0.0202755
[Epoch 49; Iter   750/  960] train: loss: 0.0126534
[Epoch 49; Iter   780/  960] train: loss: 0.0408211
[Epoch 49; Iter   810/  960] train: loss: 0.0111786
[Epoch 49; Iter   840/  960] train: loss: 0.0201703
[Epoch 49; Iter   870/  960] train: loss: 0.0152645
[Epoch 49; Iter   900/  960] train: loss: 0.0151724
[Epoch 49; Iter   930/  960] train: loss: 0.0213918
[Epoch 49; Iter   960/  960] train: loss: 0.0295241
[Epoch 49] ogbg-molhiv: 0.723360 val loss: 0.233961
[Epoch 49] ogbg-molhiv: 0.732751 test loss: 0.146110
[Epoch 50; Iter    30/  960] train: loss: 0.0332397
[Epoch 50; Iter    60/  960] train: loss: 0.0655076
[Epoch 50; Iter    90/  960] train: loss: 0.0248614
[Epoch 50; Iter   120/  960] train: loss: 0.0576677
[Epoch 50; Iter   150/  960] train: loss: 0.0615029
[Epoch 50; Iter   180/  960] train: loss: 0.0175568
[Epoch 50; Iter   210/  960] train: loss: 0.0064951
[Epoch 50; Iter   240/  960] train: loss: 0.0968106
[Epoch 50; Iter   270/  960] train: loss: 0.0135003
[Epoch 50; Iter   300/  960] train: loss: 0.1598436
[Epoch 50; Iter   330/  960] train: loss: 0.1228592
[Epoch 50; Iter   360/  960] train: loss: 0.1584249
[Epoch 50; Iter   390/  960] train: loss: 0.0661131
[Epoch 50; Iter   420/  960] train: loss: 0.1596618
[Epoch 50; Iter   450/  960] train: loss: 0.0419789
[Epoch 50; Iter   480/  960] train: loss: 0.0490440
[Epoch 50; Iter   510/  960] train: loss: 0.1379978
[Epoch 50; Iter   540/  960] train: loss: 0.0421009
[Epoch 45; Iter   960/  960] train: loss: 0.0145365
[Epoch 45] ogbg-molhiv: 0.734615 val loss: 0.150921
[Epoch 45] ogbg-molhiv: 0.764165 test loss: 0.136446
[Epoch 46; Iter    30/  960] train: loss: 0.0602114
[Epoch 46; Iter    60/  960] train: loss: 0.1646660
[Epoch 46; Iter    90/  960] train: loss: 0.1087361
[Epoch 46; Iter   120/  960] train: loss: 0.0072134
[Epoch 46; Iter   150/  960] train: loss: 0.0154946
[Epoch 46; Iter   180/  960] train: loss: 0.0874863
[Epoch 46; Iter   210/  960] train: loss: 0.1025938
[Epoch 46; Iter   240/  960] train: loss: 0.0556484
[Epoch 46; Iter   270/  960] train: loss: 0.1301810
[Epoch 46; Iter   300/  960] train: loss: 0.0222487
[Epoch 46; Iter   330/  960] train: loss: 0.0396232
[Epoch 46; Iter   360/  960] train: loss: 0.0768031
[Epoch 46; Iter   390/  960] train: loss: 0.0469937
[Epoch 46; Iter   420/  960] train: loss: 0.0201019
[Epoch 46; Iter   450/  960] train: loss: 0.1535536
[Epoch 46; Iter   480/  960] train: loss: 0.1856465
[Epoch 46; Iter   510/  960] train: loss: 0.1391962
[Epoch 46; Iter   540/  960] train: loss: 0.0149958
[Epoch 46; Iter   570/  960] train: loss: 0.0869221
[Epoch 46; Iter   600/  960] train: loss: 0.0097920
[Epoch 46; Iter   630/  960] train: loss: 0.0276677
[Epoch 46; Iter   660/  960] train: loss: 0.0506590
[Epoch 46; Iter   690/  960] train: loss: 0.0214991
[Epoch 46; Iter   720/  960] train: loss: 0.0187049
[Epoch 46; Iter   750/  960] train: loss: 0.0654241
[Epoch 46; Iter   780/  960] train: loss: 0.0651898
[Epoch 46; Iter   810/  960] train: loss: 0.0122935
[Epoch 46; Iter   840/  960] train: loss: 0.0274795
[Epoch 46; Iter   870/  960] train: loss: 0.0220837
[Epoch 46; Iter   900/  960] train: loss: 0.0435122
[Epoch 46; Iter   930/  960] train: loss: 0.0068813
[Epoch 46; Iter   960/  960] train: loss: 0.0036602
[Epoch 46] ogbg-molhiv: 0.731173 val loss: 0.156820
[Epoch 46] ogbg-molhiv: 0.767575 test loss: 0.128182
[Epoch 47; Iter    30/  960] train: loss: 0.0487007
[Epoch 47; Iter    60/  960] train: loss: 0.0111434
[Epoch 47; Iter    90/  960] train: loss: 0.0228368
[Epoch 47; Iter   120/  960] train: loss: 0.0696340
[Epoch 47; Iter   150/  960] train: loss: 0.0688711
[Epoch 47; Iter   180/  960] train: loss: 0.2193657
[Epoch 47; Iter   210/  960] train: loss: 0.0125396
[Epoch 47; Iter   240/  960] train: loss: 0.1082660
[Epoch 47; Iter   270/  960] train: loss: 0.0247578
[Epoch 47; Iter   300/  960] train: loss: 0.0241819
[Epoch 47; Iter   330/  960] train: loss: 0.0310736
[Epoch 47; Iter   360/  960] train: loss: 0.0405439
[Epoch 47; Iter   390/  960] train: loss: 0.0090912
[Epoch 47; Iter   420/  960] train: loss: 0.0139285
[Epoch 47; Iter   450/  960] train: loss: 0.1931196
[Epoch 47; Iter   480/  960] train: loss: 0.0554141
[Epoch 47; Iter   510/  960] train: loss: 0.0106544
[Epoch 47; Iter   540/  960] train: loss: 0.0580174
[Epoch 47; Iter   570/  960] train: loss: 0.0449527
[Epoch 47; Iter   600/  960] train: loss: 0.1618878
[Epoch 47; Iter   630/  960] train: loss: 0.0212392
[Epoch 47; Iter   660/  960] train: loss: 0.2444290
[Epoch 47; Iter   690/  960] train: loss: 0.1181228
[Epoch 47; Iter   720/  960] train: loss: 0.4218417
[Epoch 47; Iter   750/  960] train: loss: 0.0318812
[Epoch 47; Iter   780/  960] train: loss: 0.1802552
[Epoch 47; Iter   810/  960] train: loss: 0.0366016
[Epoch 47; Iter   840/  960] train: loss: 0.1225480
[Epoch 47; Iter   870/  960] train: loss: 0.1614321
[Epoch 47; Iter   900/  960] train: loss: 0.0233522
[Epoch 47; Iter   930/  960] train: loss: 0.0464710
[Epoch 47; Iter   960/  960] train: loss: 0.0108652
[Epoch 47] ogbg-molhiv: 0.715165 val loss: 0.152856
[Epoch 47] ogbg-molhiv: 0.761936 test loss: 0.122500
[Epoch 48; Iter    30/  960] train: loss: 0.0423594
[Epoch 48; Iter    60/  960] train: loss: 0.0266856
[Epoch 48; Iter    90/  960] train: loss: 0.0115790
[Epoch 48; Iter   120/  960] train: loss: 0.0164869
[Epoch 48; Iter   150/  960] train: loss: 0.0243755
[Epoch 48; Iter   180/  960] train: loss: 0.0541380
[Epoch 48; Iter   210/  960] train: loss: 0.0927693
[Epoch 48; Iter   240/  960] train: loss: 0.0226328
[Epoch 48; Iter   270/  960] train: loss: 0.0119483
[Epoch 48; Iter   300/  960] train: loss: 0.0313173
[Epoch 48; Iter   330/  960] train: loss: 0.1534596
[Epoch 48; Iter   360/  960] train: loss: 0.3411075
[Epoch 48; Iter   390/  960] train: loss: 0.0923568
[Epoch 48; Iter   420/  960] train: loss: 0.0224014
[Epoch 48; Iter   450/  960] train: loss: 0.0265219
[Epoch 48; Iter   480/  960] train: loss: 0.0288307
[Epoch 48; Iter   510/  960] train: loss: 0.0575090
[Epoch 48; Iter   540/  960] train: loss: 0.0181421
[Epoch 48; Iter   570/  960] train: loss: 0.0150879
[Epoch 48; Iter   600/  960] train: loss: 0.0882829
[Epoch 48; Iter   630/  960] train: loss: 0.0920126
[Epoch 48; Iter   660/  960] train: loss: 0.0300264
[Epoch 48; Iter   690/  960] train: loss: 0.2412439
[Epoch 48; Iter   720/  960] train: loss: 0.0904405
[Epoch 48; Iter   750/  960] train: loss: 0.2173868
[Epoch 48; Iter   780/  960] train: loss: 0.0838180
[Epoch 48; Iter   810/  960] train: loss: 0.3323838
[Epoch 48; Iter   840/  960] train: loss: 0.0263236
[Epoch 48; Iter   870/  960] train: loss: 0.0216010
[Epoch 48; Iter   900/  960] train: loss: 0.0075630
[Epoch 48; Iter   930/  960] train: loss: 0.0451099
[Epoch 48; Iter   960/  960] train: loss: 0.0164007
[Epoch 48] ogbg-molhiv: 0.734450 val loss: 0.204309
[Epoch 48] ogbg-molhiv: 0.783642 test loss: 0.126858
[Epoch 49; Iter    30/  960] train: loss: 0.0076264
[Epoch 49; Iter    60/  960] train: loss: 0.0181678
[Epoch 49; Iter    90/  960] train: loss: 0.1527983
[Epoch 49; Iter   120/  960] train: loss: 0.0992324
[Epoch 49; Iter   150/  960] train: loss: 0.0190269
[Epoch 49; Iter   180/  960] train: loss: 0.0248998
[Epoch 49; Iter   210/  960] train: loss: 0.1030436
[Epoch 49; Iter   240/  960] train: loss: 0.1471342
[Epoch 49; Iter   270/  960] train: loss: 0.1284625
[Epoch 49; Iter   300/  960] train: loss: 0.0253388
[Epoch 49; Iter   330/  960] train: loss: 0.0308241
[Epoch 49; Iter   360/  960] train: loss: 0.0475120
[Epoch 49; Iter   390/  960] train: loss: 0.0076459
[Epoch 49; Iter   420/  960] train: loss: 0.1372548
[Epoch 49; Iter   450/  960] train: loss: 0.0125299
[Epoch 49; Iter   480/  960] train: loss: 0.0375534
[Epoch 49; Iter   510/  960] train: loss: 0.3266603
[Epoch 49; Iter   540/  960] train: loss: 0.0106659
[Epoch 49; Iter   570/  960] train: loss: 0.0563083
[Epoch 49; Iter   600/  960] train: loss: 0.0116820
[Epoch 49; Iter   630/  960] train: loss: 0.0453989
[Epoch 49; Iter   660/  960] train: loss: 0.0262694
[Epoch 49; Iter   690/  960] train: loss: 0.0680229
[Epoch 49; Iter   720/  960] train: loss: 0.0699495
[Epoch 49; Iter   750/  960] train: loss: 0.0552076
[Epoch 49; Iter   780/  960] train: loss: 0.0964516
[Epoch 49; Iter   810/  960] train: loss: 0.0194279
[Epoch 49; Iter   840/  960] train: loss: 0.1566012
[Epoch 49; Iter   870/  960] train: loss: 0.0116698
[Epoch 49; Iter   900/  960] train: loss: 0.2637193
[Epoch 49; Iter   930/  960] train: loss: 0.0161706
[Epoch 49; Iter   960/  960] train: loss: 0.1921879
[Epoch 49] ogbg-molhiv: 0.742527 val loss: 0.154723
[Epoch 49] ogbg-molhiv: 0.777115 test loss: 0.126143
[Epoch 50; Iter    30/  960] train: loss: 0.0918860
[Epoch 50; Iter    60/  960] train: loss: 0.0163654
[Epoch 50; Iter    90/  960] train: loss: 0.0871687
[Epoch 50; Iter   120/  960] train: loss: 0.1826606
[Epoch 50; Iter   150/  960] train: loss: 0.0476706
[Epoch 50; Iter   180/  960] train: loss: 0.0053645
[Epoch 50; Iter   210/  960] train: loss: 0.0065147
[Epoch 50; Iter   240/  960] train: loss: 0.0821924
[Epoch 50; Iter   270/  960] train: loss: 0.0989896
[Epoch 50; Iter   300/  960] train: loss: 0.0341307
[Epoch 50; Iter   330/  960] train: loss: 0.0898396
[Epoch 50; Iter   360/  960] train: loss: 0.0223639
[Epoch 50; Iter   390/  960] train: loss: 0.0251310
[Epoch 50; Iter   420/  960] train: loss: 0.0080756
[Epoch 50; Iter   450/  960] train: loss: 0.0243573
[Epoch 50; Iter   480/  960] train: loss: 0.0132452
[Epoch 50; Iter   510/  960] train: loss: 0.0135532
[Epoch 50; Iter   540/  960] train: loss: 0.0170540
[Epoch 47; Iter   482/  823] train: loss: 0.0586335
[Epoch 47; Iter   512/  823] train: loss: 0.1144100
[Epoch 47; Iter   542/  823] train: loss: 0.0777748
[Epoch 47; Iter   572/  823] train: loss: 0.0391910
[Epoch 47; Iter   602/  823] train: loss: 0.0716313
[Epoch 47; Iter   632/  823] train: loss: 0.0176253
[Epoch 47; Iter   662/  823] train: loss: 0.0682239
[Epoch 47; Iter   692/  823] train: loss: 0.0098122
[Epoch 47; Iter   722/  823] train: loss: 0.0078028
[Epoch 47; Iter   752/  823] train: loss: 0.0101498
[Epoch 47; Iter   782/  823] train: loss: 0.1516247
[Epoch 47; Iter   812/  823] train: loss: 0.0670572
[Epoch 47] ogbg-molhiv: 0.709229 val loss: 0.192585
[Epoch 47] ogbg-molhiv: 0.746986 test loss: 0.127340
[Epoch 48; Iter    19/  823] train: loss: 0.0191029
[Epoch 48; Iter    49/  823] train: loss: 0.0124426
[Epoch 48; Iter    79/  823] train: loss: 0.0220951
[Epoch 48; Iter   109/  823] train: loss: 0.0581366
[Epoch 48; Iter   139/  823] train: loss: 0.0218409
[Epoch 48; Iter   169/  823] train: loss: 0.0637323
[Epoch 48; Iter   199/  823] train: loss: 0.0649293
[Epoch 48; Iter   229/  823] train: loss: 0.1050839
[Epoch 48; Iter   259/  823] train: loss: 0.0304230
[Epoch 48; Iter   289/  823] train: loss: 0.1101273
[Epoch 48; Iter   319/  823] train: loss: 0.0397732
[Epoch 48; Iter   349/  823] train: loss: 0.0166007
[Epoch 48; Iter   379/  823] train: loss: 0.0084067
[Epoch 48; Iter   409/  823] train: loss: 0.0191673
[Epoch 48; Iter   439/  823] train: loss: 0.2103139
[Epoch 48; Iter   469/  823] train: loss: 0.0488413
[Epoch 48; Iter   499/  823] train: loss: 0.0809112
[Epoch 48; Iter   529/  823] train: loss: 0.0827632
[Epoch 48; Iter   559/  823] train: loss: 0.1044469
[Epoch 48; Iter   589/  823] train: loss: 0.0198957
[Epoch 48; Iter   619/  823] train: loss: 0.0056864
[Epoch 48; Iter   649/  823] train: loss: 0.0112275
[Epoch 48; Iter   679/  823] train: loss: 0.1374321
[Epoch 48; Iter   709/  823] train: loss: 0.0302550
[Epoch 48; Iter   739/  823] train: loss: 0.0100763
[Epoch 48; Iter   769/  823] train: loss: 0.1628271
[Epoch 48; Iter   799/  823] train: loss: 0.0668077
[Epoch 48] ogbg-molhiv: 0.717304 val loss: 0.192991
[Epoch 48] ogbg-molhiv: 0.733261 test loss: 0.128531
[Epoch 49; Iter     6/  823] train: loss: 0.0103513
[Epoch 49; Iter    36/  823] train: loss: 0.0087389
[Epoch 49; Iter    66/  823] train: loss: 0.0119005
[Epoch 49; Iter    96/  823] train: loss: 0.0401748
[Epoch 49; Iter   126/  823] train: loss: 0.0304211
[Epoch 49; Iter   156/  823] train: loss: 0.0070348
[Epoch 49; Iter   186/  823] train: loss: 0.0176585
[Epoch 49; Iter   216/  823] train: loss: 0.0672527
[Epoch 49; Iter   246/  823] train: loss: 0.0129552
[Epoch 49; Iter   276/  823] train: loss: 0.0696134
[Epoch 49; Iter   306/  823] train: loss: 0.0610491
[Epoch 49; Iter   336/  823] train: loss: 0.0690708
[Epoch 49; Iter   366/  823] train: loss: 0.1377834
[Epoch 49; Iter   396/  823] train: loss: 0.0070370
[Epoch 49; Iter   426/  823] train: loss: 0.0691397
[Epoch 49; Iter   456/  823] train: loss: 0.2351290
[Epoch 49; Iter   486/  823] train: loss: 0.0365652
[Epoch 49; Iter   516/  823] train: loss: 0.0283034
[Epoch 49; Iter   546/  823] train: loss: 0.1287951
[Epoch 49; Iter   576/  823] train: loss: 0.0338062
[Epoch 49; Iter   606/  823] train: loss: 0.0814277
[Epoch 49; Iter   636/  823] train: loss: 0.0097120
[Epoch 49; Iter   666/  823] train: loss: 0.0126516
[Epoch 49; Iter   696/  823] train: loss: 0.1088946
[Epoch 49; Iter   726/  823] train: loss: 0.0430713
[Epoch 49; Iter   756/  823] train: loss: 0.0125135
[Epoch 49; Iter   786/  823] train: loss: 0.0795391
[Epoch 49; Iter   816/  823] train: loss: 0.0125964
[Epoch 49] ogbg-molhiv: 0.738573 val loss: 0.181623
[Epoch 49] ogbg-molhiv: 0.761608 test loss: 0.123523
[Epoch 50; Iter    23/  823] train: loss: 0.0421239
[Epoch 50; Iter    53/  823] train: loss: 0.0280995
[Epoch 50; Iter    83/  823] train: loss: 0.0142209
[Epoch 50; Iter   113/  823] train: loss: 0.0166409
[Epoch 50; Iter   143/  823] train: loss: 0.1162876
[Epoch 50; Iter   173/  823] train: loss: 0.0362793
[Epoch 50; Iter   203/  823] train: loss: 0.0080701
[Epoch 50; Iter   233/  823] train: loss: 0.0293055
[Epoch 50; Iter   263/  823] train: loss: 0.0264380
[Epoch 50; Iter   293/  823] train: loss: 0.0658748
[Epoch 50; Iter   323/  823] train: loss: 0.0280536
[Epoch 50; Iter   353/  823] train: loss: 0.0149606
[Epoch 50; Iter   383/  823] train: loss: 0.0105754
[Epoch 50; Iter   413/  823] train: loss: 0.0161070
[Epoch 50; Iter   443/  823] train: loss: 0.0105663
[Epoch 50; Iter   473/  823] train: loss: 0.0121014
[Epoch 50; Iter   503/  823] train: loss: 0.1111913
[Epoch 50; Iter   533/  823] train: loss: 0.0090516
[Epoch 50; Iter   563/  823] train: loss: 0.0158963
[Epoch 50; Iter   593/  823] train: loss: 0.1599086
[Epoch 50; Iter   623/  823] train: loss: 0.0834819
[Epoch 50; Iter   653/  823] train: loss: 0.0850987
[Epoch 50; Iter   683/  823] train: loss: 0.0083032
[Epoch 50; Iter   713/  823] train: loss: 0.0480165
[Epoch 50; Iter   743/  823] train: loss: 0.0773007
[Epoch 50; Iter   773/  823] train: loss: 0.0270101
[Epoch 50; Iter   803/  823] train: loss: 0.0205560
[Epoch 50] ogbg-molhiv: 0.693975 val loss: 0.206409
[Epoch 50] ogbg-molhiv: 0.724948 test loss: 0.140585
[Epoch 51; Iter    10/  823] train: loss: 0.1225499
[Epoch 51; Iter    40/  823] train: loss: 0.1250120
[Epoch 51; Iter    70/  823] train: loss: 0.0852310
[Epoch 51; Iter   100/  823] train: loss: 0.0907272
[Epoch 51; Iter   130/  823] train: loss: 0.0439309
[Epoch 51; Iter   160/  823] train: loss: 0.0505046
[Epoch 51; Iter   190/  823] train: loss: 0.0425585
[Epoch 51; Iter   220/  823] train: loss: 0.0134944
[Epoch 51; Iter   250/  823] train: loss: 0.0072926
[Epoch 51; Iter   280/  823] train: loss: 0.0142765
[Epoch 51; Iter   310/  823] train: loss: 0.0407660
[Epoch 51; Iter   340/  823] train: loss: 0.1541433
[Epoch 51; Iter   370/  823] train: loss: 0.0136676
[Epoch 51; Iter   400/  823] train: loss: 0.0336438
[Epoch 51; Iter   430/  823] train: loss: 0.0107309
[Epoch 51; Iter   460/  823] train: loss: 0.0077485
[Epoch 51; Iter   490/  823] train: loss: 0.0931845
[Epoch 51; Iter   520/  823] train: loss: 0.0274168
[Epoch 51; Iter   550/  823] train: loss: 0.0858825
[Epoch 51; Iter   580/  823] train: loss: 0.0297505
[Epoch 51; Iter   610/  823] train: loss: 0.0675950
[Epoch 51; Iter   640/  823] train: loss: 0.0885551
[Epoch 51; Iter   670/  823] train: loss: 0.2075919
[Epoch 51; Iter   700/  823] train: loss: 0.0525086
[Epoch 51; Iter   730/  823] train: loss: 0.0030498
[Epoch 51; Iter   760/  823] train: loss: 0.0080261
[Epoch 51; Iter   790/  823] train: loss: 0.0145655
[Epoch 51; Iter   820/  823] train: loss: 0.0250427
[Epoch 51] ogbg-molhiv: 0.709477 val loss: 0.228000
[Epoch 51] ogbg-molhiv: 0.738456 test loss: 0.139238
[Epoch 52; Iter    27/  823] train: loss: 0.0080694
[Epoch 52; Iter    57/  823] train: loss: 0.0066582
[Epoch 52; Iter    87/  823] train: loss: 0.3109757
[Epoch 52; Iter   117/  823] train: loss: 0.0460693
[Epoch 52; Iter   147/  823] train: loss: 0.0217142
[Epoch 52; Iter   177/  823] train: loss: 0.0142946
[Epoch 52; Iter   207/  823] train: loss: 0.0107511
[Epoch 52; Iter   237/  823] train: loss: 0.0374655
[Epoch 52; Iter   267/  823] train: loss: 0.0136944
[Epoch 52; Iter   297/  823] train: loss: 0.0244930
[Epoch 52; Iter   327/  823] train: loss: 0.0134125
[Epoch 52; Iter   357/  823] train: loss: 0.0864304
[Epoch 52; Iter   387/  823] train: loss: 0.0796453
[Epoch 52; Iter   417/  823] train: loss: 0.0295545
[Epoch 52; Iter   447/  823] train: loss: 0.0294752
[Epoch 52; Iter   477/  823] train: loss: 0.1414859
[Epoch 52; Iter   507/  823] train: loss: 0.0123373
[Epoch 52; Iter   537/  823] train: loss: 0.0055461
[Epoch 52; Iter   567/  823] train: loss: 0.0104320
[Epoch 52; Iter   597/  823] train: loss: 0.0649999
[Epoch 52; Iter   627/  823] train: loss: 0.0150750
[Epoch 52; Iter   657/  823] train: loss: 0.1444373
[Epoch 52; Iter   687/  823] train: loss: 0.0078358
[Epoch 52; Iter   717/  823] train: loss: 0.0142720
[Epoch 52; Iter   747/  823] train: loss: 0.0381640
[Epoch 44; Iter   799/ 1097] train: loss: 0.0256429
[Epoch 44; Iter   829/ 1097] train: loss: 0.1705178
[Epoch 44; Iter   859/ 1097] train: loss: 0.0659533
[Epoch 44; Iter   889/ 1097] train: loss: 0.0417113
[Epoch 44; Iter   919/ 1097] train: loss: 0.0101657
[Epoch 44; Iter   949/ 1097] train: loss: 0.0721325
[Epoch 44; Iter   979/ 1097] train: loss: 0.0946692
[Epoch 44; Iter  1009/ 1097] train: loss: 0.0113347
[Epoch 44; Iter  1039/ 1097] train: loss: 0.0400643
[Epoch 44; Iter  1069/ 1097] train: loss: 0.0231759
[Epoch 44] ogbg-molhiv: 0.816603 val loss: 0.097574
[Epoch 44] ogbg-molhiv: 0.782163 test loss: 0.161785
[Epoch 45; Iter     2/ 1097] train: loss: 0.0597028
[Epoch 45; Iter    32/ 1097] train: loss: 0.0336097
[Epoch 45; Iter    62/ 1097] train: loss: 0.0312311
[Epoch 45; Iter    92/ 1097] train: loss: 0.0125017
[Epoch 45; Iter   122/ 1097] train: loss: 0.0095564
[Epoch 45; Iter   152/ 1097] train: loss: 0.0454710
[Epoch 45; Iter   182/ 1097] train: loss: 0.1003541
[Epoch 45; Iter   212/ 1097] train: loss: 0.0618526
[Epoch 45; Iter   242/ 1097] train: loss: 0.0219502
[Epoch 45; Iter   272/ 1097] train: loss: 0.0469117
[Epoch 45; Iter   302/ 1097] train: loss: 0.1974213
[Epoch 45; Iter   332/ 1097] train: loss: 0.0737805
[Epoch 45; Iter   362/ 1097] train: loss: 0.0171387
[Epoch 45; Iter   392/ 1097] train: loss: 0.1629819
[Epoch 45; Iter   422/ 1097] train: loss: 0.1586536
[Epoch 45; Iter   452/ 1097] train: loss: 0.0640381
[Epoch 45; Iter   482/ 1097] train: loss: 0.0521362
[Epoch 45; Iter   512/ 1097] train: loss: 0.0199130
[Epoch 45; Iter   542/ 1097] train: loss: 0.0295470
[Epoch 45; Iter   572/ 1097] train: loss: 0.2149609
[Epoch 45; Iter   602/ 1097] train: loss: 0.0084671
[Epoch 45; Iter   632/ 1097] train: loss: 0.0504202
[Epoch 45; Iter   662/ 1097] train: loss: 0.0128698
[Epoch 45; Iter   692/ 1097] train: loss: 0.0324677
[Epoch 45; Iter   722/ 1097] train: loss: 0.0287666
[Epoch 45; Iter   752/ 1097] train: loss: 0.0116956
[Epoch 45; Iter   782/ 1097] train: loss: 0.1336186
[Epoch 45; Iter   812/ 1097] train: loss: 0.0090004
[Epoch 45; Iter   842/ 1097] train: loss: 0.0142486
[Epoch 45; Iter   872/ 1097] train: loss: 0.0303736
[Epoch 45; Iter   902/ 1097] train: loss: 0.0173302
[Epoch 45; Iter   932/ 1097] train: loss: 0.3606915
[Epoch 45; Iter   962/ 1097] train: loss: 0.0329588
[Epoch 45; Iter   992/ 1097] train: loss: 0.1757964
[Epoch 45; Iter  1022/ 1097] train: loss: 0.0203664
[Epoch 45; Iter  1052/ 1097] train: loss: 0.1169977
[Epoch 45; Iter  1082/ 1097] train: loss: 0.0193623
[Epoch 45] ogbg-molhiv: 0.773632 val loss: 0.093259
[Epoch 45] ogbg-molhiv: 0.737762 test loss: 0.157331
[Epoch 46; Iter    15/ 1097] train: loss: 0.0352031
[Epoch 46; Iter    45/ 1097] train: loss: 0.0175769
[Epoch 46; Iter    75/ 1097] train: loss: 0.0153546
[Epoch 46; Iter   105/ 1097] train: loss: 0.0280155
[Epoch 46; Iter   135/ 1097] train: loss: 0.0564096
[Epoch 46; Iter   165/ 1097] train: loss: 0.0793431
[Epoch 46; Iter   195/ 1097] train: loss: 0.0972973
[Epoch 46; Iter   225/ 1097] train: loss: 0.0538102
[Epoch 46; Iter   255/ 1097] train: loss: 0.0068118
[Epoch 46; Iter   285/ 1097] train: loss: 0.0221633
[Epoch 46; Iter   315/ 1097] train: loss: 0.0153267
[Epoch 46; Iter   345/ 1097] train: loss: 0.0178723
[Epoch 46; Iter   375/ 1097] train: loss: 0.0957682
[Epoch 46; Iter   405/ 1097] train: loss: 0.0158940
[Epoch 46; Iter   435/ 1097] train: loss: 0.1555937
[Epoch 46; Iter   465/ 1097] train: loss: 0.0229037
[Epoch 46; Iter   495/ 1097] train: loss: 0.0634060
[Epoch 46; Iter   525/ 1097] train: loss: 0.0075289
[Epoch 46; Iter   555/ 1097] train: loss: 0.0258830
[Epoch 46; Iter   585/ 1097] train: loss: 0.0128369
[Epoch 46; Iter   615/ 1097] train: loss: 0.1601873
[Epoch 46; Iter   645/ 1097] train: loss: 0.1585846
[Epoch 46; Iter   675/ 1097] train: loss: 0.0182397
[Epoch 46; Iter   705/ 1097] train: loss: 0.0167628
[Epoch 46; Iter   735/ 1097] train: loss: 0.0098648
[Epoch 46; Iter   765/ 1097] train: loss: 0.1393875
[Epoch 46; Iter   795/ 1097] train: loss: 0.0146960
[Epoch 46; Iter   825/ 1097] train: loss: 0.1052674
[Epoch 46; Iter   855/ 1097] train: loss: 0.0298037
[Epoch 46; Iter   885/ 1097] train: loss: 0.1478474
[Epoch 46; Iter   915/ 1097] train: loss: 0.2892040
[Epoch 46; Iter   945/ 1097] train: loss: 0.0334515
[Epoch 46; Iter   975/ 1097] train: loss: 0.1657515
[Epoch 46; Iter  1005/ 1097] train: loss: 0.0724169
[Epoch 46; Iter  1035/ 1097] train: loss: 0.1010101
[Epoch 46; Iter  1065/ 1097] train: loss: 0.1208794
[Epoch 46; Iter  1095/ 1097] train: loss: 0.0468274
[Epoch 46] ogbg-molhiv: 0.794566 val loss: 0.091270
[Epoch 46] ogbg-molhiv: 0.742513 test loss: 0.168813
[Epoch 47; Iter    28/ 1097] train: loss: 0.0174459
[Epoch 47; Iter    58/ 1097] train: loss: 0.0105338
[Epoch 47; Iter    88/ 1097] train: loss: 0.0257693
[Epoch 47; Iter   118/ 1097] train: loss: 0.0156322
[Epoch 47; Iter   148/ 1097] train: loss: 0.0629977
[Epoch 47; Iter   178/ 1097] train: loss: 0.0560552
[Epoch 47; Iter   208/ 1097] train: loss: 0.0291555
[Epoch 47; Iter   238/ 1097] train: loss: 0.0040775
[Epoch 47; Iter   268/ 1097] train: loss: 0.0059124
[Epoch 47; Iter   298/ 1097] train: loss: 0.0111062
[Epoch 47; Iter   328/ 1097] train: loss: 0.0037144
[Epoch 47; Iter   358/ 1097] train: loss: 0.1161290
[Epoch 47; Iter   388/ 1097] train: loss: 0.1495414
[Epoch 47; Iter   418/ 1097] train: loss: 0.1027093
[Epoch 47; Iter   448/ 1097] train: loss: 0.0185593
[Epoch 47; Iter   478/ 1097] train: loss: 0.0940026
[Epoch 47; Iter   508/ 1097] train: loss: 0.0070374
[Epoch 47; Iter   538/ 1097] train: loss: 0.0199404
[Epoch 47; Iter   568/ 1097] train: loss: 0.1218593
[Epoch 47; Iter   598/ 1097] train: loss: 0.0779443
[Epoch 47; Iter   628/ 1097] train: loss: 0.0360661
[Epoch 47; Iter   658/ 1097] train: loss: 0.0269934
[Epoch 47; Iter   688/ 1097] train: loss: 0.0688690
[Epoch 47; Iter   718/ 1097] train: loss: 0.0424821
[Epoch 47; Iter   748/ 1097] train: loss: 0.0197752
[Epoch 47; Iter   778/ 1097] train: loss: 0.0172499
[Epoch 47; Iter   808/ 1097] train: loss: 0.0294676
[Epoch 47; Iter   838/ 1097] train: loss: 0.0393931
[Epoch 47; Iter   868/ 1097] train: loss: 0.0849969
[Epoch 47; Iter   898/ 1097] train: loss: 0.0359393
[Epoch 47; Iter   928/ 1097] train: loss: 0.0199488
[Epoch 47; Iter   958/ 1097] train: loss: 0.1012694
[Epoch 47; Iter   988/ 1097] train: loss: 0.0208794
[Epoch 47; Iter  1018/ 1097] train: loss: 0.0184602
[Epoch 47; Iter  1048/ 1097] train: loss: 0.0340668
[Epoch 47; Iter  1078/ 1097] train: loss: 0.1147687
[Epoch 47] ogbg-molhiv: 0.822767 val loss: 0.089203
[Epoch 47] ogbg-molhiv: 0.785343 test loss: 0.654272
[Epoch 48; Iter    11/ 1097] train: loss: 0.0247494
[Epoch 48; Iter    41/ 1097] train: loss: 0.1942374
[Epoch 48; Iter    71/ 1097] train: loss: 0.0098519
[Epoch 48; Iter   101/ 1097] train: loss: 0.0379339
[Epoch 48; Iter   131/ 1097] train: loss: 0.0216196
[Epoch 48; Iter   161/ 1097] train: loss: 0.0205295
[Epoch 48; Iter   191/ 1097] train: loss: 0.0353292
[Epoch 48; Iter   221/ 1097] train: loss: 0.0261264
[Epoch 48; Iter   251/ 1097] train: loss: 0.0197571
[Epoch 48; Iter   281/ 1097] train: loss: 0.0095852
[Epoch 48; Iter   311/ 1097] train: loss: 0.0174162
[Epoch 48; Iter   341/ 1097] train: loss: 0.0090978
[Epoch 48; Iter   371/ 1097] train: loss: 0.1133875
[Epoch 48; Iter   401/ 1097] train: loss: 0.0327794
[Epoch 48; Iter   431/ 1097] train: loss: 0.1648675
[Epoch 48; Iter   461/ 1097] train: loss: 0.1024521
[Epoch 48; Iter   491/ 1097] train: loss: 0.0404511
[Epoch 48; Iter   521/ 1097] train: loss: 0.0922844
[Epoch 48; Iter   551/ 1097] train: loss: 0.0888169
[Epoch 48; Iter   581/ 1097] train: loss: 0.0700010
[Epoch 48; Iter   611/ 1097] train: loss: 0.0198263
[Epoch 48; Iter   641/ 1097] train: loss: 0.0588632
[Epoch 48; Iter   671/ 1097] train: loss: 0.0543721
[Epoch 48; Iter   701/ 1097] train: loss: 0.1469018
[Epoch 48; Iter   731/ 1097] train: loss: 0.0570256
[Epoch 48; Iter   761/ 1097] train: loss: 0.0383895
[Epoch 48; Iter   791/ 1097] train: loss: 0.0442553
[Epoch 48; Iter   821/ 1097] train: loss: 0.0929181
[Epoch 48; Iter   851/ 1097] train: loss: 0.0465689
[Epoch 47; Iter   482/  823] train: loss: 0.1277155
[Epoch 47; Iter   512/  823] train: loss: 0.0136884
[Epoch 47; Iter   542/  823] train: loss: 0.0864254
[Epoch 47; Iter   572/  823] train: loss: 0.0111424
[Epoch 47; Iter   602/  823] train: loss: 0.0053684
[Epoch 47; Iter   632/  823] train: loss: 0.0040236
[Epoch 47; Iter   662/  823] train: loss: 0.0916873
[Epoch 47; Iter   692/  823] train: loss: 0.0278544
[Epoch 47; Iter   722/  823] train: loss: 0.0494843
[Epoch 47; Iter   752/  823] train: loss: 0.0136796
[Epoch 47; Iter   782/  823] train: loss: 0.0237239
[Epoch 47; Iter   812/  823] train: loss: 0.0359102
[Epoch 47] ogbg-molhiv: 0.733909 val loss: 0.292635
[Epoch 47] ogbg-molhiv: 0.777883 test loss: 0.200594
[Epoch 48; Iter    19/  823] train: loss: 0.0622166
[Epoch 48; Iter    49/  823] train: loss: 0.0197024
[Epoch 48; Iter    79/  823] train: loss: 0.0088540
[Epoch 48; Iter   109/  823] train: loss: 0.0431815
[Epoch 48; Iter   139/  823] train: loss: 0.0065040
[Epoch 48; Iter   169/  823] train: loss: 0.0081967
[Epoch 48; Iter   199/  823] train: loss: 0.0689103
[Epoch 48; Iter   229/  823] train: loss: 0.0982650
[Epoch 48; Iter   259/  823] train: loss: 0.1131846
[Epoch 48; Iter   289/  823] train: loss: 0.0195405
[Epoch 48; Iter   319/  823] train: loss: 0.1743812
[Epoch 48; Iter   349/  823] train: loss: 0.0994534
[Epoch 48; Iter   379/  823] train: loss: 0.0841240
[Epoch 48; Iter   409/  823] train: loss: 0.0387762
[Epoch 48; Iter   439/  823] train: loss: 0.0552353
[Epoch 48; Iter   469/  823] train: loss: 0.0118176
[Epoch 48; Iter   499/  823] train: loss: 0.2055384
[Epoch 48; Iter   529/  823] train: loss: 0.1911439
[Epoch 48; Iter   559/  823] train: loss: 0.0349445
[Epoch 48; Iter   589/  823] train: loss: 0.0237253
[Epoch 48; Iter   619/  823] train: loss: 0.0147653
[Epoch 48; Iter   649/  823] train: loss: 0.1393283
[Epoch 48; Iter   679/  823] train: loss: 0.0372955
[Epoch 48; Iter   709/  823] train: loss: 0.1266260
[Epoch 48; Iter   739/  823] train: loss: 0.0174114
[Epoch 48; Iter   769/  823] train: loss: 0.0748097
[Epoch 48; Iter   799/  823] train: loss: 0.0205024
[Epoch 48] ogbg-molhiv: 0.724975 val loss: 0.188666
[Epoch 48] ogbg-molhiv: 0.771806 test loss: 0.122695
[Epoch 49; Iter     6/  823] train: loss: 0.0252443
[Epoch 49; Iter    36/  823] train: loss: 0.0131297
[Epoch 49; Iter    66/  823] train: loss: 0.0101106
[Epoch 49; Iter    96/  823] train: loss: 0.0061392
[Epoch 49; Iter   126/  823] train: loss: 0.1505549
[Epoch 49; Iter   156/  823] train: loss: 0.0535827
[Epoch 49; Iter   186/  823] train: loss: 0.0957274
[Epoch 49; Iter   216/  823] train: loss: 0.0460860
[Epoch 49; Iter   246/  823] train: loss: 0.0181209
[Epoch 49; Iter   276/  823] train: loss: 0.0039529
[Epoch 49; Iter   306/  823] train: loss: 0.0997042
[Epoch 49; Iter   336/  823] train: loss: 0.1237133
[Epoch 49; Iter   366/  823] train: loss: 0.0590658
[Epoch 49; Iter   396/  823] train: loss: 0.1399167
[Epoch 49; Iter   426/  823] train: loss: 0.0020872
[Epoch 49; Iter   456/  823] train: loss: 0.0108632
[Epoch 49; Iter   486/  823] train: loss: 0.0150959
[Epoch 49; Iter   516/  823] train: loss: 0.1601161
[Epoch 49; Iter   546/  823] train: loss: 0.0901320
[Epoch 49; Iter   576/  823] train: loss: 0.1479411
[Epoch 49; Iter   606/  823] train: loss: 0.0519269
[Epoch 49; Iter   636/  823] train: loss: 0.1201568
[Epoch 49; Iter   666/  823] train: loss: 0.0446064
[Epoch 49; Iter   696/  823] train: loss: 0.0787683
[Epoch 49; Iter   726/  823] train: loss: 0.0059384
[Epoch 49; Iter   756/  823] train: loss: 0.0150629
[Epoch 49; Iter   786/  823] train: loss: 0.0135423
[Epoch 49; Iter   816/  823] train: loss: 0.0461649
[Epoch 49] ogbg-molhiv: 0.716206 val loss: 0.200082
[Epoch 49] ogbg-molhiv: 0.767027 test loss: 0.125395
[Epoch 50; Iter    23/  823] train: loss: 0.0424711
[Epoch 50; Iter    53/  823] train: loss: 0.0534067
[Epoch 50; Iter    83/  823] train: loss: 0.0130786
[Epoch 50; Iter   113/  823] train: loss: 0.1810953
[Epoch 50; Iter   143/  823] train: loss: 0.0645551
[Epoch 50; Iter   173/  823] train: loss: 0.0218647
[Epoch 50; Iter   203/  823] train: loss: 0.0385783
[Epoch 50; Iter   233/  823] train: loss: 0.0495741
[Epoch 50; Iter   263/  823] train: loss: 0.0077003
[Epoch 50; Iter   293/  823] train: loss: 0.0077311
[Epoch 50; Iter   323/  823] train: loss: 0.0849656
[Epoch 50; Iter   353/  823] train: loss: 0.0096560
[Epoch 50; Iter   383/  823] train: loss: 0.0482879
[Epoch 50; Iter   413/  823] train: loss: 0.0193537
[Epoch 50; Iter   443/  823] train: loss: 0.0115121
[Epoch 50; Iter   473/  823] train: loss: 0.0114598
[Epoch 50; Iter   503/  823] train: loss: 0.0137221
[Epoch 50; Iter   533/  823] train: loss: 0.0611202
[Epoch 50; Iter   563/  823] train: loss: 0.0259732
[Epoch 50; Iter   593/  823] train: loss: 0.1344105
[Epoch 50; Iter   623/  823] train: loss: 0.0160877
[Epoch 50; Iter   653/  823] train: loss: 0.0699966
[Epoch 50; Iter   683/  823] train: loss: 0.2985738
[Epoch 50; Iter   713/  823] train: loss: 0.0091137
[Epoch 50; Iter   743/  823] train: loss: 0.0193195
[Epoch 50; Iter   773/  823] train: loss: 0.1694261
[Epoch 50; Iter   803/  823] train: loss: 0.0739522
[Epoch 50] ogbg-molhiv: 0.720466 val loss: 0.540661
[Epoch 50] ogbg-molhiv: 0.760586 test loss: 0.419008
[Epoch 51; Iter    10/  823] train: loss: 0.0189410
[Epoch 51; Iter    40/  823] train: loss: 0.0031020
[Epoch 51; Iter    70/  823] train: loss: 0.1186515
[Epoch 51; Iter   100/  823] train: loss: 0.0350170
[Epoch 51; Iter   130/  823] train: loss: 0.0742454
[Epoch 51; Iter   160/  823] train: loss: 0.0108328
[Epoch 51; Iter   190/  823] train: loss: 0.1376747
[Epoch 51; Iter   220/  823] train: loss: 0.0061256
[Epoch 51; Iter   250/  823] train: loss: 0.0342671
[Epoch 51; Iter   280/  823] train: loss: 0.0353167
[Epoch 51; Iter   310/  823] train: loss: 0.1048027
[Epoch 51; Iter   340/  823] train: loss: 0.0197654
[Epoch 51; Iter   370/  823] train: loss: 0.0042206
[Epoch 51; Iter   400/  823] train: loss: 0.1269521
[Epoch 51; Iter   430/  823] train: loss: 0.0074574
[Epoch 51; Iter   460/  823] train: loss: 0.0109263
[Epoch 51; Iter   490/  823] train: loss: 0.0379819
[Epoch 51; Iter   520/  823] train: loss: 0.0833623
[Epoch 51; Iter   550/  823] train: loss: 0.0827721
[Epoch 51; Iter   580/  823] train: loss: 0.0171188
[Epoch 51; Iter   610/  823] train: loss: 0.0299371
[Epoch 51; Iter   640/  823] train: loss: 0.2005514
[Epoch 51; Iter   670/  823] train: loss: 0.1046731
[Epoch 51; Iter   700/  823] train: loss: 0.0138470
[Epoch 51; Iter   730/  823] train: loss: 0.0710088
[Epoch 51; Iter   760/  823] train: loss: 0.1246413
[Epoch 51; Iter   790/  823] train: loss: 0.0200761
[Epoch 51; Iter   820/  823] train: loss: 0.0334508
[Epoch 51] ogbg-molhiv: 0.725294 val loss: 0.405007
[Epoch 51] ogbg-molhiv: 0.760591 test loss: 0.308575
[Epoch 52; Iter    27/  823] train: loss: 0.1920470
[Epoch 52; Iter    57/  823] train: loss: 0.0089905
[Epoch 52; Iter    87/  823] train: loss: 0.0463819
[Epoch 52; Iter   117/  823] train: loss: 0.0135409
[Epoch 52; Iter   147/  823] train: loss: 0.2669156
[Epoch 52; Iter   177/  823] train: loss: 0.0266250
[Epoch 52; Iter   207/  823] train: loss: 0.0609223
[Epoch 52; Iter   237/  823] train: loss: 0.1171934
[Epoch 52; Iter   267/  823] train: loss: 0.0247431
[Epoch 52; Iter   297/  823] train: loss: 0.0100243
[Epoch 52; Iter   327/  823] train: loss: 0.0065858
[Epoch 52; Iter   357/  823] train: loss: 0.0120359
[Epoch 52; Iter   387/  823] train: loss: 0.0115570
[Epoch 52; Iter   417/  823] train: loss: 0.0615196
[Epoch 52; Iter   447/  823] train: loss: 0.1400467
[Epoch 52; Iter   477/  823] train: loss: 0.1159822
[Epoch 52; Iter   507/  823] train: loss: 0.0296456
[Epoch 52; Iter   537/  823] train: loss: 0.0728276
[Epoch 52; Iter   567/  823] train: loss: 0.0779249
[Epoch 52; Iter   597/  823] train: loss: 0.0089139
[Epoch 52; Iter   627/  823] train: loss: 0.0080209
[Epoch 52; Iter   657/  823] train: loss: 0.0742876
[Epoch 52; Iter   687/  823] train: loss: 0.0581307
[Epoch 52; Iter   717/  823] train: loss: 0.0057923
[Epoch 52; Iter   747/  823] train: loss: 0.0074621
[Epoch 48; Iter   881/ 1097] train: loss: 0.2708862
[Epoch 48; Iter   911/ 1097] train: loss: 0.2123366
[Epoch 48; Iter   941/ 1097] train: loss: 0.0391672
[Epoch 48; Iter   971/ 1097] train: loss: 0.0530524
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0144189
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0239976
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0232713
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0299447
[Epoch 48] ogbg-molhiv: 0.774434 val loss: 0.144343
[Epoch 48] ogbg-molhiv: 0.731887 test loss: 0.280916
[Epoch 49; Iter    24/ 1097] train: loss: 0.0632872
[Epoch 49; Iter    54/ 1097] train: loss: 0.0953757
[Epoch 49; Iter    84/ 1097] train: loss: 0.0548288
[Epoch 49; Iter   114/ 1097] train: loss: 0.1020830
[Epoch 49; Iter   144/ 1097] train: loss: 0.0359386
[Epoch 49; Iter   174/ 1097] train: loss: 0.1461930
[Epoch 49; Iter   204/ 1097] train: loss: 0.0125753
[Epoch 49; Iter   234/ 1097] train: loss: 0.0223785
[Epoch 49; Iter   264/ 1097] train: loss: 0.0499445
[Epoch 49; Iter   294/ 1097] train: loss: 0.1675539
[Epoch 49; Iter   324/ 1097] train: loss: 0.0111667
[Epoch 49; Iter   354/ 1097] train: loss: 0.0593869
[Epoch 49; Iter   384/ 1097] train: loss: 0.0568012
[Epoch 49; Iter   414/ 1097] train: loss: 0.0507308
[Epoch 49; Iter   444/ 1097] train: loss: 0.0343289
[Epoch 49; Iter   474/ 1097] train: loss: 0.2555439
[Epoch 49; Iter   504/ 1097] train: loss: 0.0487139
[Epoch 49; Iter   534/ 1097] train: loss: 0.0244951
[Epoch 49; Iter   564/ 1097] train: loss: 0.0212987
[Epoch 49; Iter   594/ 1097] train: loss: 0.1055363
[Epoch 49; Iter   624/ 1097] train: loss: 0.1072107
[Epoch 49; Iter   654/ 1097] train: loss: 0.1363196
[Epoch 49; Iter   684/ 1097] train: loss: 0.0433371
[Epoch 49; Iter   714/ 1097] train: loss: 0.0609770
[Epoch 49; Iter   744/ 1097] train: loss: 0.1113339
[Epoch 49; Iter   774/ 1097] train: loss: 0.1292833
[Epoch 49; Iter   804/ 1097] train: loss: 0.0810545
[Epoch 49; Iter   834/ 1097] train: loss: 0.0320722
[Epoch 49; Iter   864/ 1097] train: loss: 0.0420431
[Epoch 49; Iter   894/ 1097] train: loss: 0.0070712
[Epoch 49; Iter   924/ 1097] train: loss: 0.0875998
[Epoch 49; Iter   954/ 1097] train: loss: 0.0497637
[Epoch 49; Iter   984/ 1097] train: loss: 0.0330829
[Epoch 49; Iter  1014/ 1097] train: loss: 0.0080508
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0529068
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0256276
[Epoch 49] ogbg-molhiv: 0.787322 val loss: 0.206525
[Epoch 49] ogbg-molhiv: 0.744844 test loss: 0.380517
[Epoch 50; Iter     7/ 1097] train: loss: 0.0334288
[Epoch 50; Iter    37/ 1097] train: loss: 0.1010143
[Epoch 50; Iter    67/ 1097] train: loss: 0.0118288
[Epoch 50; Iter    97/ 1097] train: loss: 0.0161052
[Epoch 50; Iter   127/ 1097] train: loss: 0.0341453
[Epoch 50; Iter   157/ 1097] train: loss: 0.0926968
[Epoch 50; Iter   187/ 1097] train: loss: 0.1775804
[Epoch 50; Iter   217/ 1097] train: loss: 0.0268090
[Epoch 50; Iter   247/ 1097] train: loss: 0.0332793
[Epoch 50; Iter   277/ 1097] train: loss: 0.0255902
[Epoch 50; Iter   307/ 1097] train: loss: 0.1882357
[Epoch 50; Iter   337/ 1097] train: loss: 0.1518132
[Epoch 50; Iter   367/ 1097] train: loss: 0.0923324
[Epoch 50; Iter   397/ 1097] train: loss: 0.0234432
[Epoch 50; Iter   427/ 1097] train: loss: 0.0667859
[Epoch 50; Iter   457/ 1097] train: loss: 0.0690141
[Epoch 50; Iter   487/ 1097] train: loss: 0.0377951
[Epoch 50; Iter   517/ 1097] train: loss: 0.1190560
[Epoch 50; Iter   547/ 1097] train: loss: 0.0202353
[Epoch 50; Iter   577/ 1097] train: loss: 0.0101735
[Epoch 50; Iter   607/ 1097] train: loss: 0.0231681
[Epoch 50; Iter   637/ 1097] train: loss: 0.1507303
[Epoch 50; Iter   667/ 1097] train: loss: 0.0421250
[Epoch 50; Iter   697/ 1097] train: loss: 0.0592297
[Epoch 50; Iter   727/ 1097] train: loss: 0.0654243
[Epoch 50; Iter   757/ 1097] train: loss: 0.0083585
[Epoch 50; Iter   787/ 1097] train: loss: 0.1121963
[Epoch 50; Iter   817/ 1097] train: loss: 0.1180592
[Epoch 50; Iter   847/ 1097] train: loss: 0.0307946
[Epoch 50; Iter   877/ 1097] train: loss: 0.0161511
[Epoch 50; Iter   907/ 1097] train: loss: 0.0231507
[Epoch 50; Iter   937/ 1097] train: loss: 0.0279468
[Epoch 50; Iter   967/ 1097] train: loss: 0.0492782
[Epoch 50; Iter   997/ 1097] train: loss: 0.0538708
[Epoch 50; Iter  1027/ 1097] train: loss: 0.1324944
[Epoch 50; Iter  1057/ 1097] train: loss: 0.1621975
[Epoch 50; Iter  1087/ 1097] train: loss: 0.1967056
[Epoch 50] ogbg-molhiv: 0.801312 val loss: 0.148777
[Epoch 50] ogbg-molhiv: 0.738000 test loss: 0.269340
[Epoch 51; Iter    20/ 1097] train: loss: 0.0961336
[Epoch 51; Iter    50/ 1097] train: loss: 0.0118881
[Epoch 51; Iter    80/ 1097] train: loss: 0.0521603
[Epoch 51; Iter   110/ 1097] train: loss: 0.1411021
[Epoch 51; Iter   140/ 1097] train: loss: 0.0372593
[Epoch 51; Iter   170/ 1097] train: loss: 0.0833329
[Epoch 51; Iter   200/ 1097] train: loss: 0.0495760
[Epoch 51; Iter   230/ 1097] train: loss: 0.1590295
[Epoch 51; Iter   260/ 1097] train: loss: 0.0756387
[Epoch 51; Iter   290/ 1097] train: loss: 0.1463322
[Epoch 51; Iter   320/ 1097] train: loss: 0.0171685
[Epoch 51; Iter   350/ 1097] train: loss: 0.0361845
[Epoch 51; Iter   380/ 1097] train: loss: 0.0381061
[Epoch 51; Iter   410/ 1097] train: loss: 0.1250630
[Epoch 51; Iter   440/ 1097] train: loss: 0.0679865
[Epoch 51; Iter   470/ 1097] train: loss: 0.0682580
[Epoch 51; Iter   500/ 1097] train: loss: 0.1370063
[Epoch 51; Iter   530/ 1097] train: loss: 0.0170234
[Epoch 51; Iter   560/ 1097] train: loss: 0.0390346
[Epoch 51; Iter   590/ 1097] train: loss: 0.2247540
[Epoch 51; Iter   620/ 1097] train: loss: 0.0492714
[Epoch 51; Iter   650/ 1097] train: loss: 0.0287682
[Epoch 51; Iter   680/ 1097] train: loss: 0.0335117
[Epoch 51; Iter   710/ 1097] train: loss: 0.1765658
[Epoch 51; Iter   740/ 1097] train: loss: 0.0439354
[Epoch 51; Iter   770/ 1097] train: loss: 0.0170465
[Epoch 51; Iter   800/ 1097] train: loss: 0.0144476
[Epoch 51; Iter   830/ 1097] train: loss: 0.0110263
[Epoch 51; Iter   860/ 1097] train: loss: 0.0109141
[Epoch 51; Iter   890/ 1097] train: loss: 0.0134742
[Epoch 51; Iter   920/ 1097] train: loss: 0.0278792
[Epoch 51; Iter   950/ 1097] train: loss: 0.1510143
[Epoch 51; Iter   980/ 1097] train: loss: 0.0249860
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0405363
[Epoch 51; Iter  1040/ 1097] train: loss: 0.0910405
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0680240
[Epoch 51] ogbg-molhiv: 0.783672 val loss: 0.151460
[Epoch 51] ogbg-molhiv: 0.729018 test loss: 0.321288
[Epoch 52; Iter     3/ 1097] train: loss: 0.0548765
[Epoch 52; Iter    33/ 1097] train: loss: 0.0677173
[Epoch 52; Iter    63/ 1097] train: loss: 0.0147496
[Epoch 52; Iter    93/ 1097] train: loss: 0.0726955
[Epoch 52; Iter   123/ 1097] train: loss: 0.0155736
[Epoch 52; Iter   153/ 1097] train: loss: 0.0264613
[Epoch 52; Iter   183/ 1097] train: loss: 0.0158517
[Epoch 52; Iter   213/ 1097] train: loss: 0.0401804
[Epoch 52; Iter   243/ 1097] train: loss: 0.0188216
[Epoch 52; Iter   273/ 1097] train: loss: 0.0157852
[Epoch 52; Iter   303/ 1097] train: loss: 0.0714397
[Epoch 52; Iter   333/ 1097] train: loss: 0.0906740
[Epoch 52; Iter   363/ 1097] train: loss: 0.0124066
[Epoch 52; Iter   393/ 1097] train: loss: 0.0553192
[Epoch 52; Iter   423/ 1097] train: loss: 0.0240615
[Epoch 52; Iter   453/ 1097] train: loss: 0.1140611
[Epoch 52; Iter   483/ 1097] train: loss: 0.0463989
[Epoch 52; Iter   513/ 1097] train: loss: 0.0131748
[Epoch 52; Iter   543/ 1097] train: loss: 0.0392667
[Epoch 52; Iter   573/ 1097] train: loss: 0.2326527
[Epoch 52; Iter   603/ 1097] train: loss: 0.0115411
[Epoch 52; Iter   633/ 1097] train: loss: 0.0131663
[Epoch 52; Iter   663/ 1097] train: loss: 0.0167527
[Epoch 52; Iter   693/ 1097] train: loss: 0.0281375
[Epoch 52; Iter   723/ 1097] train: loss: 0.0585732
[Epoch 52; Iter   753/ 1097] train: loss: 0.1310074
[Epoch 52; Iter   783/ 1097] train: loss: 0.0742103
[Epoch 52; Iter   813/ 1097] train: loss: 0.0541270
[Epoch 52; Iter   843/ 1097] train: loss: 0.0156845
[Epoch 52; Iter   873/ 1097] train: loss: 0.0504544
[Epoch 52; Iter   903/ 1097] train: loss: 0.0678666
[Epoch 52; Iter   933/ 1097] train: loss: 0.0117109
[Epoch 48; Iter   881/ 1097] train: loss: 0.1008539
[Epoch 48; Iter   911/ 1097] train: loss: 0.1409336
[Epoch 48; Iter   941/ 1097] train: loss: 0.0624241
[Epoch 48; Iter   971/ 1097] train: loss: 0.0239686
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0150935
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0204306
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0602442
[Epoch 48; Iter  1091/ 1097] train: loss: 0.0197367
[Epoch 48] ogbg-molhiv: 0.789392 val loss: 0.089652
[Epoch 48] ogbg-molhiv: 0.764016 test loss: 0.161338
[Epoch 49; Iter    24/ 1097] train: loss: 0.0941386
[Epoch 49; Iter    54/ 1097] train: loss: 0.0323463
[Epoch 49; Iter    84/ 1097] train: loss: 0.0153049
[Epoch 49; Iter   114/ 1097] train: loss: 0.0110002
[Epoch 49; Iter   144/ 1097] train: loss: 0.0140188
[Epoch 49; Iter   174/ 1097] train: loss: 0.0247538
[Epoch 49; Iter   204/ 1097] train: loss: 0.0138770
[Epoch 49; Iter   234/ 1097] train: loss: 0.0137639
[Epoch 49; Iter   264/ 1097] train: loss: 0.1920140
[Epoch 49; Iter   294/ 1097] train: loss: 0.0077660
[Epoch 49; Iter   324/ 1097] train: loss: 0.0813523
[Epoch 49; Iter   354/ 1097] train: loss: 0.1709872
[Epoch 49; Iter   384/ 1097] train: loss: 0.1124926
[Epoch 49; Iter   414/ 1097] train: loss: 0.2926833
[Epoch 49; Iter   444/ 1097] train: loss: 0.0566657
[Epoch 49; Iter   474/ 1097] train: loss: 0.0424331
[Epoch 49; Iter   504/ 1097] train: loss: 0.0407376
[Epoch 49; Iter   534/ 1097] train: loss: 0.0161168
[Epoch 49; Iter   564/ 1097] train: loss: 0.0136889
[Epoch 49; Iter   594/ 1097] train: loss: 0.1606460
[Epoch 49; Iter   624/ 1097] train: loss: 0.2445790
[Epoch 49; Iter   654/ 1097] train: loss: 0.1351930
[Epoch 49; Iter   684/ 1097] train: loss: 0.0777239
[Epoch 49; Iter   714/ 1097] train: loss: 0.0127666
[Epoch 49; Iter   744/ 1097] train: loss: 0.1402273
[Epoch 49; Iter   774/ 1097] train: loss: 0.0246377
[Epoch 49; Iter   804/ 1097] train: loss: 0.0813880
[Epoch 49; Iter   834/ 1097] train: loss: 0.0314142
[Epoch 49; Iter   864/ 1097] train: loss: 0.0592302
[Epoch 49; Iter   894/ 1097] train: loss: 0.1584944
[Epoch 49; Iter   924/ 1097] train: loss: 0.0400976
[Epoch 49; Iter   954/ 1097] train: loss: 0.0770900
[Epoch 49; Iter   984/ 1097] train: loss: 0.0230576
[Epoch 49; Iter  1014/ 1097] train: loss: 0.1235483
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0253058
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0160263
[Epoch 49] ogbg-molhiv: 0.787383 val loss: 0.100999
[Epoch 49] ogbg-molhiv: 0.763165 test loss: 0.232740
[Epoch 50; Iter     7/ 1097] train: loss: 0.3015379
[Epoch 50; Iter    37/ 1097] train: loss: 0.0204313
[Epoch 50; Iter    67/ 1097] train: loss: 0.1410571
[Epoch 50; Iter    97/ 1097] train: loss: 0.0136630
[Epoch 50; Iter   127/ 1097] train: loss: 0.0793190
[Epoch 50; Iter   157/ 1097] train: loss: 0.0830904
[Epoch 50; Iter   187/ 1097] train: loss: 0.0297099
[Epoch 50; Iter   217/ 1097] train: loss: 0.0284328
[Epoch 50; Iter   247/ 1097] train: loss: 0.0333836
[Epoch 50; Iter   277/ 1097] train: loss: 0.1303328
[Epoch 50; Iter   307/ 1097] train: loss: 0.0118100
[Epoch 50; Iter   337/ 1097] train: loss: 0.0766361
[Epoch 50; Iter   367/ 1097] train: loss: 0.0392801
[Epoch 50; Iter   397/ 1097] train: loss: 0.1128795
[Epoch 50; Iter   427/ 1097] train: loss: 0.1516570
[Epoch 50; Iter   457/ 1097] train: loss: 0.0523564
[Epoch 50; Iter   487/ 1097] train: loss: 0.1026701
[Epoch 50; Iter   517/ 1097] train: loss: 0.0134332
[Epoch 50; Iter   547/ 1097] train: loss: 0.1352643
[Epoch 50; Iter   577/ 1097] train: loss: 0.1235430
[Epoch 50; Iter   607/ 1097] train: loss: 0.0100447
[Epoch 50; Iter   637/ 1097] train: loss: 0.0892407
[Epoch 50; Iter   667/ 1097] train: loss: 0.1040594
[Epoch 50; Iter   697/ 1097] train: loss: 0.1328523
[Epoch 50; Iter   727/ 1097] train: loss: 0.2189517
[Epoch 50; Iter   757/ 1097] train: loss: 0.0056179
[Epoch 50; Iter   787/ 1097] train: loss: 0.1292133
[Epoch 50; Iter   817/ 1097] train: loss: 0.0196676
[Epoch 50; Iter   847/ 1097] train: loss: 0.0483168
[Epoch 50; Iter   877/ 1097] train: loss: 0.0252124
[Epoch 50; Iter   907/ 1097] train: loss: 0.1126198
[Epoch 50; Iter   937/ 1097] train: loss: 0.0303834
[Epoch 50; Iter   967/ 1097] train: loss: 0.0600203
[Epoch 50; Iter   997/ 1097] train: loss: 0.0326485
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0205275
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0123468
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0289956
[Epoch 50] ogbg-molhiv: 0.805011 val loss: 0.086060
[Epoch 50] ogbg-molhiv: 0.746627 test loss: 0.185927
[Epoch 51; Iter    20/ 1097] train: loss: 0.1038212
[Epoch 51; Iter    50/ 1097] train: loss: 0.0568345
[Epoch 51; Iter    80/ 1097] train: loss: 0.0373779
[Epoch 51; Iter   110/ 1097] train: loss: 0.0941944
[Epoch 51; Iter   140/ 1097] train: loss: 0.0398748
[Epoch 51; Iter   170/ 1097] train: loss: 0.0173162
[Epoch 51; Iter   200/ 1097] train: loss: 0.1689131
[Epoch 51; Iter   230/ 1097] train: loss: 0.0123276
[Epoch 51; Iter   260/ 1097] train: loss: 0.0207476
[Epoch 51; Iter   290/ 1097] train: loss: 0.0195587
[Epoch 51; Iter   320/ 1097] train: loss: 0.0212055
[Epoch 51; Iter   350/ 1097] train: loss: 0.1064541
[Epoch 51; Iter   380/ 1097] train: loss: 0.0384773
[Epoch 51; Iter   410/ 1097] train: loss: 0.0544327
[Epoch 51; Iter   440/ 1097] train: loss: 0.0946276
[Epoch 51; Iter   470/ 1097] train: loss: 0.0142058
[Epoch 51; Iter   500/ 1097] train: loss: 0.0679623
[Epoch 51; Iter   530/ 1097] train: loss: 0.0262851
[Epoch 51; Iter   560/ 1097] train: loss: 0.0128888
[Epoch 51; Iter   590/ 1097] train: loss: 0.0298540
[Epoch 51; Iter   620/ 1097] train: loss: 0.1088244
[Epoch 51; Iter   650/ 1097] train: loss: 0.0273239
[Epoch 51; Iter   680/ 1097] train: loss: 0.1482048
[Epoch 51; Iter   710/ 1097] train: loss: 0.0260344
[Epoch 51; Iter   740/ 1097] train: loss: 0.0900805
[Epoch 51; Iter   770/ 1097] train: loss: 0.3492613
[Epoch 51; Iter   800/ 1097] train: loss: 0.1017015
[Epoch 51; Iter   830/ 1097] train: loss: 0.0295996
[Epoch 51; Iter   860/ 1097] train: loss: 0.0629624
[Epoch 51; Iter   890/ 1097] train: loss: 0.0150395
[Epoch 51; Iter   920/ 1097] train: loss: 0.0785352
[Epoch 51; Iter   950/ 1097] train: loss: 0.1376735
[Epoch 51; Iter   980/ 1097] train: loss: 0.0991731
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0512591
[Epoch 51; Iter  1040/ 1097] train: loss: 0.1886904
[Epoch 51; Iter  1070/ 1097] train: loss: 0.1010901
[Epoch 51] ogbg-molhiv: 0.796624 val loss: 0.089111
[Epoch 51] ogbg-molhiv: 0.748475 test loss: 0.185975
[Epoch 52; Iter     3/ 1097] train: loss: 0.0300008
[Epoch 52; Iter    33/ 1097] train: loss: 0.0172046
[Epoch 52; Iter    63/ 1097] train: loss: 0.0192193
[Epoch 52; Iter    93/ 1097] train: loss: 0.0286811
[Epoch 52; Iter   123/ 1097] train: loss: 0.1248837
[Epoch 52; Iter   153/ 1097] train: loss: 0.0518121
[Epoch 52; Iter   183/ 1097] train: loss: 0.0925690
[Epoch 52; Iter   213/ 1097] train: loss: 0.0117784
[Epoch 52; Iter   243/ 1097] train: loss: 0.1245353
[Epoch 52; Iter   273/ 1097] train: loss: 0.0794769
[Epoch 52; Iter   303/ 1097] train: loss: 0.1414351
[Epoch 52; Iter   333/ 1097] train: loss: 0.0316292
[Epoch 52; Iter   363/ 1097] train: loss: 0.1234538
[Epoch 52; Iter   393/ 1097] train: loss: 0.0455294
[Epoch 52; Iter   423/ 1097] train: loss: 0.0103712
[Epoch 52; Iter   453/ 1097] train: loss: 0.0694672
[Epoch 52; Iter   483/ 1097] train: loss: 0.0380599
[Epoch 52; Iter   513/ 1097] train: loss: 0.0789445
[Epoch 52; Iter   543/ 1097] train: loss: 0.1062423
[Epoch 52; Iter   573/ 1097] train: loss: 0.1281025
[Epoch 52; Iter   603/ 1097] train: loss: 0.0207696
[Epoch 52; Iter   633/ 1097] train: loss: 0.1598836
[Epoch 52; Iter   663/ 1097] train: loss: 0.0193490
[Epoch 52; Iter   693/ 1097] train: loss: 0.0788777
[Epoch 52; Iter   723/ 1097] train: loss: 0.0130375
[Epoch 52; Iter   753/ 1097] train: loss: 0.2115909
[Epoch 52; Iter   783/ 1097] train: loss: 0.0348209
[Epoch 52; Iter   813/ 1097] train: loss: 0.0809513
[Epoch 52; Iter   843/ 1097] train: loss: 0.0140966
[Epoch 52; Iter   873/ 1097] train: loss: 0.0204804
[Epoch 52; Iter   903/ 1097] train: loss: 0.1118782
[Epoch 52; Iter   933/ 1097] train: loss: 0.0113615
[Epoch 50; Iter   570/  960] train: loss: 0.0220910
[Epoch 50; Iter   600/  960] train: loss: 0.0160367
[Epoch 50; Iter   630/  960] train: loss: 0.0088789
[Epoch 50; Iter   660/  960] train: loss: 0.0539255
[Epoch 50; Iter   690/  960] train: loss: 0.0137757
[Epoch 50; Iter   720/  960] train: loss: 0.0174182
[Epoch 50; Iter   750/  960] train: loss: 0.1796336
[Epoch 50; Iter   780/  960] train: loss: 0.0407465
[Epoch 50; Iter   810/  960] train: loss: 0.1088718
[Epoch 50; Iter   840/  960] train: loss: 0.0215345
[Epoch 50; Iter   870/  960] train: loss: 0.2430936
[Epoch 50; Iter   900/  960] train: loss: 0.0228163
[Epoch 50; Iter   930/  960] train: loss: 0.0113753
[Epoch 50; Iter   960/  960] train: loss: 0.2323907
[Epoch 50] ogbg-molhiv: 0.762860 val loss: 0.191481
[Epoch 50] ogbg-molhiv: 0.761643 test loss: 0.349154
[Epoch 51; Iter    30/  960] train: loss: 0.0676903
[Epoch 51; Iter    60/  960] train: loss: 0.0137629
[Epoch 51; Iter    90/  960] train: loss: 0.0318687
[Epoch 51; Iter   120/  960] train: loss: 0.0544096
[Epoch 51; Iter   150/  960] train: loss: 0.0439675
[Epoch 51; Iter   180/  960] train: loss: 0.0595903
[Epoch 51; Iter   210/  960] train: loss: 0.0087845
[Epoch 51; Iter   240/  960] train: loss: 0.0142126
[Epoch 51; Iter   270/  960] train: loss: 0.0142021
[Epoch 51; Iter   300/  960] train: loss: 0.1555379
[Epoch 51; Iter   330/  960] train: loss: 0.0098871
[Epoch 51; Iter   360/  960] train: loss: 0.1270979
[Epoch 51; Iter   390/  960] train: loss: 0.0661438
[Epoch 51; Iter   420/  960] train: loss: 0.0199219
[Epoch 51; Iter   450/  960] train: loss: 0.0087889
[Epoch 51; Iter   480/  960] train: loss: 0.1095036
[Epoch 51; Iter   510/  960] train: loss: 0.0346943
[Epoch 51; Iter   540/  960] train: loss: 0.0112952
[Epoch 51; Iter   570/  960] train: loss: 0.0802791
[Epoch 51; Iter   600/  960] train: loss: 0.2262958
[Epoch 51; Iter   630/  960] train: loss: 0.0327585
[Epoch 51; Iter   660/  960] train: loss: 0.0340569
[Epoch 51; Iter   690/  960] train: loss: 0.0404434
[Epoch 51; Iter   720/  960] train: loss: 0.1269878
[Epoch 51; Iter   750/  960] train: loss: 0.0294657
[Epoch 51; Iter   780/  960] train: loss: 0.2164266
[Epoch 51; Iter   810/  960] train: loss: 0.0496856
[Epoch 51; Iter   840/  960] train: loss: 0.0766491
[Epoch 51; Iter   870/  960] train: loss: 0.0435115
[Epoch 51; Iter   900/  960] train: loss: 0.0230775
[Epoch 51; Iter   930/  960] train: loss: 0.1428251
[Epoch 51; Iter   960/  960] train: loss: 0.0048097
[Epoch 51] ogbg-molhiv: 0.754797 val loss: 0.942945
[Epoch 51] ogbg-molhiv: 0.751164 test loss: 0.304795
[Epoch 52; Iter    30/  960] train: loss: 0.0104443
[Epoch 52; Iter    60/  960] train: loss: 0.0124699
[Epoch 52; Iter    90/  960] train: loss: 0.0569122
[Epoch 52; Iter   120/  960] train: loss: 0.0129883
[Epoch 52; Iter   150/  960] train: loss: 0.0303802
[Epoch 52; Iter   180/  960] train: loss: 0.0355965
[Epoch 52; Iter   210/  960] train: loss: 0.0130430
[Epoch 52; Iter   240/  960] train: loss: 0.0147843
[Epoch 52; Iter   270/  960] train: loss: 0.1190372
[Epoch 52; Iter   300/  960] train: loss: 0.0167490
[Epoch 52; Iter   330/  960] train: loss: 0.0131431
[Epoch 52; Iter   360/  960] train: loss: 0.0041834
[Epoch 52; Iter   390/  960] train: loss: 0.1497948
[Epoch 52; Iter   420/  960] train: loss: 0.0413479
[Epoch 52; Iter   450/  960] train: loss: 0.0219588
[Epoch 52; Iter   480/  960] train: loss: 0.0187768
[Epoch 52; Iter   510/  960] train: loss: 0.1962193
[Epoch 52; Iter   540/  960] train: loss: 0.1921708
[Epoch 52; Iter   570/  960] train: loss: 0.0415617
[Epoch 52; Iter   600/  960] train: loss: 0.0867055
[Epoch 52; Iter   630/  960] train: loss: 0.1075989
[Epoch 52; Iter   660/  960] train: loss: 0.0165453
[Epoch 52; Iter   690/  960] train: loss: 0.0123890
[Epoch 52; Iter   720/  960] train: loss: 0.0121813
[Epoch 52; Iter   750/  960] train: loss: 0.0201445
[Epoch 52; Iter   780/  960] train: loss: 0.0221178
[Epoch 52; Iter   810/  960] train: loss: 0.0716961
[Epoch 52; Iter   840/  960] train: loss: 0.0157097
[Epoch 52; Iter   870/  960] train: loss: 0.1255099
[Epoch 52; Iter   900/  960] train: loss: 0.1230208
[Epoch 52; Iter   930/  960] train: loss: 0.0330730
[Epoch 52; Iter   960/  960] train: loss: 0.0154575
[Epoch 52] ogbg-molhiv: 0.755424 val loss: 0.484203
[Epoch 52] ogbg-molhiv: 0.750634 test loss: 0.298316
[Epoch 53; Iter    30/  960] train: loss: 0.0301866
[Epoch 53; Iter    60/  960] train: loss: 0.0228411
[Epoch 53; Iter    90/  960] train: loss: 0.0238806
[Epoch 53; Iter   120/  960] train: loss: 0.0225879
[Epoch 53; Iter   150/  960] train: loss: 0.0093909
[Epoch 53; Iter   180/  960] train: loss: 0.0326875
[Epoch 53; Iter   210/  960] train: loss: 0.0097611
[Epoch 53; Iter   240/  960] train: loss: 0.1602878
[Epoch 53; Iter   270/  960] train: loss: 0.0350470
[Epoch 53; Iter   300/  960] train: loss: 0.0218321
[Epoch 53; Iter   330/  960] train: loss: 0.0721955
[Epoch 53; Iter   360/  960] train: loss: 0.0067527
[Epoch 53; Iter   390/  960] train: loss: 0.1601578
[Epoch 53; Iter   420/  960] train: loss: 0.0110732
[Epoch 53; Iter   450/  960] train: loss: 0.0700305
[Epoch 53; Iter   480/  960] train: loss: 0.0275557
[Epoch 53; Iter   510/  960] train: loss: 0.0038136
[Epoch 53; Iter   540/  960] train: loss: 0.0118712
[Epoch 53; Iter   570/  960] train: loss: 0.0635714
[Epoch 53; Iter   600/  960] train: loss: 0.0896028
[Epoch 53; Iter   630/  960] train: loss: 0.0451962
[Epoch 53; Iter   660/  960] train: loss: 0.0568865
[Epoch 53; Iter   690/  960] train: loss: 0.0347936
[Epoch 53; Iter   720/  960] train: loss: 0.0227649
[Epoch 53; Iter   750/  960] train: loss: 0.0427554
[Epoch 53; Iter   780/  960] train: loss: 0.0171204
[Epoch 53; Iter   810/  960] train: loss: 0.0867465
[Epoch 53; Iter   840/  960] train: loss: 0.0201909
[Epoch 53; Iter   870/  960] train: loss: 0.2110445
[Epoch 53; Iter   900/  960] train: loss: 0.0117729
[Epoch 53; Iter   930/  960] train: loss: 0.0497371
[Epoch 53; Iter   960/  960] train: loss: 0.0057132
[Epoch 53] ogbg-molhiv: 0.754554 val loss: 0.285030
[Epoch 53] ogbg-molhiv: 0.778158 test loss: 0.132576
[Epoch 54; Iter    30/  960] train: loss: 0.0072201
[Epoch 54; Iter    60/  960] train: loss: 0.0846595
[Epoch 54; Iter    90/  960] train: loss: 0.0409846
[Epoch 54; Iter   120/  960] train: loss: 0.0189778
[Epoch 54; Iter   150/  960] train: loss: 0.0156662
[Epoch 54; Iter   180/  960] train: loss: 0.0265009
[Epoch 54; Iter   210/  960] train: loss: 0.0444731
[Epoch 54; Iter   240/  960] train: loss: 0.0179357
[Epoch 54; Iter   270/  960] train: loss: 0.0464348
[Epoch 54; Iter   300/  960] train: loss: 0.0323137
[Epoch 54; Iter   330/  960] train: loss: 0.0260717
[Epoch 54; Iter   360/  960] train: loss: 0.0381466
[Epoch 54; Iter   390/  960] train: loss: 0.0510001
[Epoch 54; Iter   420/  960] train: loss: 0.0490606
[Epoch 54; Iter   450/  960] train: loss: 0.0487366
[Epoch 54; Iter   480/  960] train: loss: 0.0245534
[Epoch 54; Iter   510/  960] train: loss: 0.0470005
[Epoch 54; Iter   540/  960] train: loss: 0.0099089
[Epoch 54; Iter   570/  960] train: loss: 0.0503025
[Epoch 54; Iter   600/  960] train: loss: 0.0289497
[Epoch 54; Iter   630/  960] train: loss: 0.0142953
[Epoch 54; Iter   660/  960] train: loss: 0.0584389
[Epoch 54; Iter   690/  960] train: loss: 0.2773115
[Epoch 54; Iter   720/  960] train: loss: 0.0205821
[Epoch 54; Iter   750/  960] train: loss: 0.0750770
[Epoch 54; Iter   780/  960] train: loss: 0.0257578
[Epoch 54; Iter   810/  960] train: loss: 0.0958379
[Epoch 54; Iter   840/  960] train: loss: 0.0256269
[Epoch 54; Iter   870/  960] train: loss: 0.1091439
[Epoch 54; Iter   900/  960] train: loss: 0.0444770
[Epoch 54; Iter   930/  960] train: loss: 0.1225781
[Epoch 54; Iter   960/  960] train: loss: 0.2127422
[Epoch 54] ogbg-molhiv: 0.747115 val loss: 0.473266
[Epoch 54] ogbg-molhiv: 0.750132 test loss: 0.170541
[Epoch 55; Iter    30/  960] train: loss: 0.0085663
[Epoch 55; Iter    60/  960] train: loss: 0.0223879
[Epoch 55; Iter    90/  960] train: loss: 0.1842853
[Epoch 55; Iter   120/  960] train: loss: 0.0238907
[Epoch 55; Iter   150/  960] train: loss: 0.0188115
[Epoch 50; Iter   570/  960] train: loss: 0.0511348
[Epoch 50; Iter   600/  960] train: loss: 0.0563101
[Epoch 50; Iter   630/  960] train: loss: 0.0373867
[Epoch 50; Iter   660/  960] train: loss: 0.0494593
[Epoch 50; Iter   690/  960] train: loss: 0.0874219
[Epoch 50; Iter   720/  960] train: loss: 0.0090138
[Epoch 50; Iter   750/  960] train: loss: 0.1177551
[Epoch 50; Iter   780/  960] train: loss: 0.0312382
[Epoch 50; Iter   810/  960] train: loss: 0.0800835
[Epoch 50; Iter   840/  960] train: loss: 0.0255426
[Epoch 50; Iter   870/  960] train: loss: 0.0111371
[Epoch 50; Iter   900/  960] train: loss: 0.0160712
[Epoch 50; Iter   930/  960] train: loss: 0.0119235
[Epoch 50; Iter   960/  960] train: loss: 0.0148849
[Epoch 50] ogbg-molhiv: 0.725433 val loss: 0.206243
[Epoch 50] ogbg-molhiv: 0.744532 test loss: 0.207023
[Epoch 51; Iter    30/  960] train: loss: 0.0068393
[Epoch 51; Iter    60/  960] train: loss: 0.0197059
[Epoch 51; Iter    90/  960] train: loss: 0.1233703
[Epoch 51; Iter   120/  960] train: loss: 0.0075891
[Epoch 51; Iter   150/  960] train: loss: 0.0548236
[Epoch 51; Iter   180/  960] train: loss: 0.1277828
[Epoch 51; Iter   210/  960] train: loss: 0.0212233
[Epoch 51; Iter   240/  960] train: loss: 0.1659192
[Epoch 51; Iter   270/  960] train: loss: 0.0227453
[Epoch 51; Iter   300/  960] train: loss: 0.0258480
[Epoch 51; Iter   330/  960] train: loss: 0.1077920
[Epoch 51; Iter   360/  960] train: loss: 0.2663082
[Epoch 51; Iter   390/  960] train: loss: 0.0502003
[Epoch 51; Iter   420/  960] train: loss: 0.0387901
[Epoch 51; Iter   450/  960] train: loss: 0.0331424
[Epoch 51; Iter   480/  960] train: loss: 0.0424346
[Epoch 51; Iter   510/  960] train: loss: 0.0267428
[Epoch 51; Iter   540/  960] train: loss: 0.0981291
[Epoch 51; Iter   570/  960] train: loss: 0.0836864
[Epoch 51; Iter   600/  960] train: loss: 0.0396800
[Epoch 51; Iter   630/  960] train: loss: 0.0402141
[Epoch 51; Iter   660/  960] train: loss: 0.0154288
[Epoch 51; Iter   690/  960] train: loss: 0.2281886
[Epoch 51; Iter   720/  960] train: loss: 0.0093486
[Epoch 51; Iter   750/  960] train: loss: 0.0155130
[Epoch 51; Iter   780/  960] train: loss: 0.4741339
[Epoch 51; Iter   810/  960] train: loss: 0.0120746
[Epoch 51; Iter   840/  960] train: loss: 0.0070797
[Epoch 51; Iter   870/  960] train: loss: 0.1235169
[Epoch 51; Iter   900/  960] train: loss: 0.2516558
[Epoch 51; Iter   930/  960] train: loss: 0.0575596
[Epoch 51; Iter   960/  960] train: loss: 0.0842614
[Epoch 51] ogbg-molhiv: 0.733450 val loss: 0.212846
[Epoch 51] ogbg-molhiv: 0.744309 test loss: 0.218226
[Epoch 52; Iter    30/  960] train: loss: 0.0112965
[Epoch 52; Iter    60/  960] train: loss: 0.0407431
[Epoch 52; Iter    90/  960] train: loss: 0.1765995
[Epoch 52; Iter   120/  960] train: loss: 0.0139400
[Epoch 52; Iter   150/  960] train: loss: 0.0424037
[Epoch 52; Iter   180/  960] train: loss: 0.1339599
[Epoch 52; Iter   210/  960] train: loss: 0.1697790
[Epoch 52; Iter   240/  960] train: loss: 0.0093380
[Epoch 52; Iter   270/  960] train: loss: 0.0412950
[Epoch 52; Iter   300/  960] train: loss: 0.0198959
[Epoch 52; Iter   330/  960] train: loss: 0.0750475
[Epoch 52; Iter   360/  960] train: loss: 0.0376801
[Epoch 52; Iter   390/  960] train: loss: 0.1105791
[Epoch 52; Iter   420/  960] train: loss: 0.0190135
[Epoch 52; Iter   450/  960] train: loss: 0.0280450
[Epoch 52; Iter   480/  960] train: loss: 0.1159344
[Epoch 52; Iter   510/  960] train: loss: 0.0897861
[Epoch 52; Iter   540/  960] train: loss: 0.0135445
[Epoch 52; Iter   570/  960] train: loss: 0.0130767
[Epoch 52; Iter   600/  960] train: loss: 0.0894625
[Epoch 52; Iter   630/  960] train: loss: 0.0156301
[Epoch 52; Iter   660/  960] train: loss: 0.0926037
[Epoch 52; Iter   690/  960] train: loss: 0.0239336
[Epoch 52; Iter   720/  960] train: loss: 0.1200449
[Epoch 52; Iter   750/  960] train: loss: 0.0218299
[Epoch 52; Iter   780/  960] train: loss: 0.0275548
[Epoch 52; Iter   810/  960] train: loss: 0.0287436
[Epoch 52; Iter   840/  960] train: loss: 0.0132029
[Epoch 52; Iter   870/  960] train: loss: 0.0146720
[Epoch 52; Iter   900/  960] train: loss: 0.0999886
[Epoch 52; Iter   930/  960] train: loss: 0.0189193
[Epoch 52; Iter   960/  960] train: loss: 0.0068042
[Epoch 52] ogbg-molhiv: 0.734305 val loss: 0.297142
[Epoch 52] ogbg-molhiv: 0.754418 test loss: 0.233190
[Epoch 53; Iter    30/  960] train: loss: 0.0138139
[Epoch 53; Iter    60/  960] train: loss: 0.0401453
[Epoch 53; Iter    90/  960] train: loss: 0.0187542
[Epoch 53; Iter   120/  960] train: loss: 0.0170673
[Epoch 53; Iter   150/  960] train: loss: 0.0338534
[Epoch 53; Iter   180/  960] train: loss: 0.0711523
[Epoch 53; Iter   210/  960] train: loss: 0.0197834
[Epoch 53; Iter   240/  960] train: loss: 0.0313264
[Epoch 53; Iter   270/  960] train: loss: 0.0102038
[Epoch 53; Iter   300/  960] train: loss: 0.0729509
[Epoch 53; Iter   330/  960] train: loss: 0.0393733
[Epoch 53; Iter   360/  960] train: loss: 0.0238845
[Epoch 53; Iter   390/  960] train: loss: 0.0128864
[Epoch 53; Iter   420/  960] train: loss: 0.0600003
[Epoch 53; Iter   450/  960] train: loss: 0.0514112
[Epoch 53; Iter   480/  960] train: loss: 0.0126430
[Epoch 53; Iter   510/  960] train: loss: 0.0140545
[Epoch 53; Iter   540/  960] train: loss: 0.0119138
[Epoch 53; Iter   570/  960] train: loss: 0.0379562
[Epoch 53; Iter   600/  960] train: loss: 0.0220292
[Epoch 53; Iter   630/  960] train: loss: 0.0055472
[Epoch 53; Iter   660/  960] train: loss: 0.0390337
[Epoch 53; Iter   690/  960] train: loss: 0.0147102
[Epoch 53; Iter   720/  960] train: loss: 0.1280496
[Epoch 53; Iter   750/  960] train: loss: 0.0452037
[Epoch 53; Iter   780/  960] train: loss: 0.0216108
[Epoch 53; Iter   810/  960] train: loss: 0.0602659
[Epoch 53; Iter   840/  960] train: loss: 0.0071538
[Epoch 53; Iter   870/  960] train: loss: 0.0585222
[Epoch 53; Iter   900/  960] train: loss: 0.0442547
[Epoch 53; Iter   930/  960] train: loss: 0.0553649
[Epoch 53; Iter   960/  960] train: loss: 0.0106597
[Epoch 53] ogbg-molhiv: 0.736818 val loss: 0.256911
[Epoch 53] ogbg-molhiv: 0.748445 test loss: 0.195413
[Epoch 54; Iter    30/  960] train: loss: 0.0610623
[Epoch 54; Iter    60/  960] train: loss: 0.0109548
[Epoch 54; Iter    90/  960] train: loss: 0.0514072
[Epoch 54; Iter   120/  960] train: loss: 0.1044189
[Epoch 54; Iter   150/  960] train: loss: 0.0606972
[Epoch 54; Iter   180/  960] train: loss: 0.0723203
[Epoch 54; Iter   210/  960] train: loss: 0.0755802
[Epoch 54; Iter   240/  960] train: loss: 0.0175829
[Epoch 54; Iter   270/  960] train: loss: 0.2279098
[Epoch 54; Iter   300/  960] train: loss: 0.0477327
[Epoch 54; Iter   330/  960] train: loss: 0.0239452
[Epoch 54; Iter   360/  960] train: loss: 0.0158106
[Epoch 54; Iter   390/  960] train: loss: 0.0107059
[Epoch 54; Iter   420/  960] train: loss: 0.0862696
[Epoch 54; Iter   450/  960] train: loss: 0.0066579
[Epoch 54; Iter   480/  960] train: loss: 0.0108867
[Epoch 54; Iter   510/  960] train: loss: 0.1351887
[Epoch 54; Iter   540/  960] train: loss: 0.0467480
[Epoch 54; Iter   570/  960] train: loss: 0.0667043
[Epoch 54; Iter   600/  960] train: loss: 0.0782531
[Epoch 54; Iter   630/  960] train: loss: 0.1953567
[Epoch 54; Iter   660/  960] train: loss: 0.0048340
[Epoch 54; Iter   690/  960] train: loss: 0.0210042
[Epoch 54; Iter   720/  960] train: loss: 0.0506211
[Epoch 54; Iter   750/  960] train: loss: 0.1571769
[Epoch 54; Iter   780/  960] train: loss: 0.0223136
[Epoch 54; Iter   810/  960] train: loss: 0.1440948
[Epoch 54; Iter   840/  960] train: loss: 0.1172837
[Epoch 54; Iter   870/  960] train: loss: 0.1420535
[Epoch 54; Iter   900/  960] train: loss: 0.0476638
[Epoch 54; Iter   930/  960] train: loss: 0.0197490
[Epoch 54; Iter   960/  960] train: loss: 0.0061719
[Epoch 54] ogbg-molhiv: 0.726651 val loss: 0.470603
[Epoch 54] ogbg-molhiv: 0.758344 test loss: 0.363362
[Epoch 55; Iter    30/  960] train: loss: 0.1070495
[Epoch 55; Iter    60/  960] train: loss: 0.0282532
[Epoch 55; Iter    90/  960] train: loss: 0.0099901
[Epoch 55; Iter   120/  960] train: loss: 0.0925930
[Epoch 55; Iter   150/  960] train: loss: 0.1538245
[Epoch 50; Iter   570/  960] train: loss: 0.0706702
[Epoch 50; Iter   600/  960] train: loss: 0.0321015
[Epoch 50; Iter   630/  960] train: loss: 0.0090010
[Epoch 50; Iter   660/  960] train: loss: 0.0265891
[Epoch 50; Iter   690/  960] train: loss: 0.0566062
[Epoch 50; Iter   720/  960] train: loss: 0.0113480
[Epoch 50; Iter   750/  960] train: loss: 0.0741080
[Epoch 50; Iter   780/  960] train: loss: 0.0325834
[Epoch 50; Iter   810/  960] train: loss: 0.0502916
[Epoch 50; Iter   840/  960] train: loss: 0.0118803
[Epoch 50; Iter   870/  960] train: loss: 0.0937457
[Epoch 50; Iter   900/  960] train: loss: 0.0757283
[Epoch 50; Iter   930/  960] train: loss: 0.0094066
[Epoch 50; Iter   960/  960] train: loss: 0.0310022
[Epoch 50] ogbg-molhiv: 0.757678 val loss: 0.149451
[Epoch 50] ogbg-molhiv: 0.769214 test loss: 0.125046
[Epoch 51; Iter    30/  960] train: loss: 0.0160491
[Epoch 51; Iter    60/  960] train: loss: 0.0312953
[Epoch 51; Iter    90/  960] train: loss: 0.0209944
[Epoch 51; Iter   120/  960] train: loss: 0.0459166
[Epoch 51; Iter   150/  960] train: loss: 0.1005866
[Epoch 51; Iter   180/  960] train: loss: 0.0926394
[Epoch 51; Iter   210/  960] train: loss: 0.0319117
[Epoch 51; Iter   240/  960] train: loss: 0.1205963
[Epoch 51; Iter   270/  960] train: loss: 0.0429312
[Epoch 51; Iter   300/  960] train: loss: 0.0145733
[Epoch 51; Iter   330/  960] train: loss: 0.0604687
[Epoch 51; Iter   360/  960] train: loss: 0.0069358
[Epoch 51; Iter   390/  960] train: loss: 0.0096937
[Epoch 51; Iter   420/  960] train: loss: 0.1321603
[Epoch 51; Iter   450/  960] train: loss: 0.0167290
[Epoch 51; Iter   480/  960] train: loss: 0.0728670
[Epoch 51; Iter   510/  960] train: loss: 0.0696827
[Epoch 51; Iter   540/  960] train: loss: 0.0496274
[Epoch 51; Iter   570/  960] train: loss: 0.0191189
[Epoch 51; Iter   600/  960] train: loss: 0.0280800
[Epoch 51; Iter   630/  960] train: loss: 0.0231604
[Epoch 51; Iter   660/  960] train: loss: 0.0448234
[Epoch 51; Iter   690/  960] train: loss: 0.0639571
[Epoch 51; Iter   720/  960] train: loss: 0.0104658
[Epoch 51; Iter   750/  960] train: loss: 0.0662544
[Epoch 51; Iter   780/  960] train: loss: 0.0740544
[Epoch 51; Iter   810/  960] train: loss: 0.1436415
[Epoch 51; Iter   840/  960] train: loss: 0.0386136
[Epoch 51; Iter   870/  960] train: loss: 0.0074207
[Epoch 51; Iter   900/  960] train: loss: 0.0823182
[Epoch 51; Iter   930/  960] train: loss: 0.0140027
[Epoch 51; Iter   960/  960] train: loss: 0.1435685
[Epoch 51] ogbg-molhiv: 0.739006 val loss: 0.158021
[Epoch 51] ogbg-molhiv: 0.759528 test loss: 0.133557
[Epoch 52; Iter    30/  960] train: loss: 0.0718990
[Epoch 52; Iter    60/  960] train: loss: 0.0148820
[Epoch 52; Iter    90/  960] train: loss: 0.0052161
[Epoch 52; Iter   120/  960] train: loss: 0.1429215
[Epoch 52; Iter   150/  960] train: loss: 0.0258632
[Epoch 52; Iter   180/  960] train: loss: 0.1049894
[Epoch 52; Iter   210/  960] train: loss: 0.0070268
[Epoch 52; Iter   240/  960] train: loss: 0.0387368
[Epoch 52; Iter   270/  960] train: loss: 0.0050533
[Epoch 52; Iter   300/  960] train: loss: 0.1127508
[Epoch 52; Iter   330/  960] train: loss: 0.0154484
[Epoch 52; Iter   360/  960] train: loss: 0.0231541
[Epoch 52; Iter   390/  960] train: loss: 0.1019225
[Epoch 52; Iter   420/  960] train: loss: 0.0360101
[Epoch 52; Iter   450/  960] train: loss: 0.0184063
[Epoch 52; Iter   480/  960] train: loss: 0.1023794
[Epoch 52; Iter   510/  960] train: loss: 0.0436511
[Epoch 52; Iter   540/  960] train: loss: 0.0277543
[Epoch 52; Iter   570/  960] train: loss: 0.1370744
[Epoch 52; Iter   600/  960] train: loss: 0.0071539
[Epoch 52; Iter   630/  960] train: loss: 0.0144547
[Epoch 52; Iter   660/  960] train: loss: 0.0127771
[Epoch 52; Iter   690/  960] train: loss: 0.1295730
[Epoch 52; Iter   720/  960] train: loss: 0.0328129
[Epoch 52; Iter   750/  960] train: loss: 0.0184682
[Epoch 52; Iter   780/  960] train: loss: 0.0381960
[Epoch 52; Iter   810/  960] train: loss: 0.0550091
[Epoch 52; Iter   840/  960] train: loss: 0.0970686
[Epoch 52; Iter   870/  960] train: loss: 0.0206583
[Epoch 52; Iter   900/  960] train: loss: 0.0330107
[Epoch 52; Iter   930/  960] train: loss: 0.0115962
[Epoch 52; Iter   960/  960] train: loss: 0.0134855
[Epoch 52] ogbg-molhiv: 0.743035 val loss: 0.217672
[Epoch 52] ogbg-molhiv: 0.778079 test loss: 0.246114
[Epoch 53; Iter    30/  960] train: loss: 0.1408684
[Epoch 53; Iter    60/  960] train: loss: 0.0134569
[Epoch 53; Iter    90/  960] train: loss: 0.0470717
[Epoch 53; Iter   120/  960] train: loss: 0.0875309
[Epoch 53; Iter   150/  960] train: loss: 0.0095620
[Epoch 53; Iter   180/  960] train: loss: 0.0074253
[Epoch 53; Iter   210/  960] train: loss: 0.0208791
[Epoch 53; Iter   240/  960] train: loss: 0.0420032
[Epoch 53; Iter   270/  960] train: loss: 0.0636541
[Epoch 53; Iter   300/  960] train: loss: 0.0721965
[Epoch 53; Iter   330/  960] train: loss: 0.0422345
[Epoch 53; Iter   360/  960] train: loss: 0.1552998
[Epoch 53; Iter   390/  960] train: loss: 0.0130519
[Epoch 53; Iter   420/  960] train: loss: 0.0413562
[Epoch 53; Iter   450/  960] train: loss: 0.1852712
[Epoch 53; Iter   480/  960] train: loss: 0.2330123
[Epoch 53; Iter   510/  960] train: loss: 0.0147594
[Epoch 53; Iter   540/  960] train: loss: 0.0420873
[Epoch 53; Iter   570/  960] train: loss: 0.0146287
[Epoch 53; Iter   600/  960] train: loss: 0.0166000
[Epoch 53; Iter   630/  960] train: loss: 0.0284818
[Epoch 53; Iter   660/  960] train: loss: 0.0237156
[Epoch 53; Iter   690/  960] train: loss: 0.0173590
[Epoch 53; Iter   720/  960] train: loss: 0.0519144
[Epoch 53; Iter   750/  960] train: loss: 0.0063843
[Epoch 53; Iter   780/  960] train: loss: 0.0566741
[Epoch 53; Iter   810/  960] train: loss: 0.1806086
[Epoch 53; Iter   840/  960] train: loss: 0.0550366
[Epoch 53; Iter   870/  960] train: loss: 0.0139872
[Epoch 53; Iter   900/  960] train: loss: 0.0704883
[Epoch 53; Iter   930/  960] train: loss: 0.0079968
[Epoch 53; Iter   960/  960] train: loss: 0.0295897
[Epoch 53] ogbg-molhiv: 0.735457 val loss: 0.164583
[Epoch 53] ogbg-molhiv: 0.763507 test loss: 0.127943
[Epoch 54; Iter    30/  960] train: loss: 0.0219810
[Epoch 54; Iter    60/  960] train: loss: 0.0682956
[Epoch 54; Iter    90/  960] train: loss: 0.0385017
[Epoch 54; Iter   120/  960] train: loss: 0.0234656
[Epoch 54; Iter   150/  960] train: loss: 0.2581101
[Epoch 54; Iter   180/  960] train: loss: 0.0227843
[Epoch 54; Iter   210/  960] train: loss: 0.0895066
[Epoch 54; Iter   240/  960] train: loss: 0.1051702
[Epoch 54; Iter   270/  960] train: loss: 0.0047704
[Epoch 54; Iter   300/  960] train: loss: 0.0198623
[Epoch 54; Iter   330/  960] train: loss: 0.0488705
[Epoch 54; Iter   360/  960] train: loss: 0.1581995
[Epoch 54; Iter   390/  960] train: loss: 0.0153713
[Epoch 54; Iter   420/  960] train: loss: 0.0804247
[Epoch 54; Iter   450/  960] train: loss: 0.2359874
[Epoch 54; Iter   480/  960] train: loss: 0.0197684
[Epoch 54; Iter   510/  960] train: loss: 0.0169829
[Epoch 54; Iter   540/  960] train: loss: 0.0139344
[Epoch 54; Iter   570/  960] train: loss: 0.0623862
[Epoch 54; Iter   600/  960] train: loss: 0.0134154
[Epoch 54; Iter   630/  960] train: loss: 0.0325056
[Epoch 54; Iter   660/  960] train: loss: 0.0824109
[Epoch 54; Iter   690/  960] train: loss: 0.0078902
[Epoch 54; Iter   720/  960] train: loss: 0.0122569
[Epoch 54; Iter   750/  960] train: loss: 0.0120274
[Epoch 54; Iter   780/  960] train: loss: 0.1419712
[Epoch 54; Iter   810/  960] train: loss: 0.1149847
[Epoch 54; Iter   840/  960] train: loss: 0.0478765
[Epoch 54; Iter   870/  960] train: loss: 0.0271074
[Epoch 54; Iter   900/  960] train: loss: 0.0232663
[Epoch 54; Iter   930/  960] train: loss: 0.0152836
[Epoch 54; Iter   960/  960] train: loss: 0.0330695
[Epoch 54] ogbg-molhiv: 0.734745 val loss: 0.214459
[Epoch 54] ogbg-molhiv: 0.772383 test loss: 0.173884
[Epoch 55; Iter    30/  960] train: loss: 0.0099386
[Epoch 55; Iter    60/  960] train: loss: 0.0193560
[Epoch 55; Iter    90/  960] train: loss: 0.0062154
[Epoch 55; Iter   120/  960] train: loss: 0.0352052
[Epoch 55; Iter   150/  960] train: loss: 0.0498964
[Epoch 52; Iter   777/  823] train: loss: 0.1959164
[Epoch 52; Iter   807/  823] train: loss: 0.2023675
[Epoch 52] ogbg-molhiv: 0.732981 val loss: 0.209493
[Epoch 52] ogbg-molhiv: 0.769988 test loss: 0.306470
[Epoch 53; Iter    14/  823] train: loss: 0.0096245
[Epoch 53; Iter    44/  823] train: loss: 0.1795237
[Epoch 53; Iter    74/  823] train: loss: 0.0108144
[Epoch 53; Iter   104/  823] train: loss: 0.0198554
[Epoch 53; Iter   134/  823] train: loss: 0.0237448
[Epoch 53; Iter   164/  823] train: loss: 0.1578941
[Epoch 53; Iter   194/  823] train: loss: 0.0071692
[Epoch 53; Iter   224/  823] train: loss: 0.0879140
[Epoch 53; Iter   254/  823] train: loss: 0.0606099
[Epoch 53; Iter   284/  823] train: loss: 0.0170660
[Epoch 53; Iter   314/  823] train: loss: 0.0562870
[Epoch 53; Iter   344/  823] train: loss: 0.0307706
[Epoch 53; Iter   374/  823] train: loss: 0.0645692
[Epoch 53; Iter   404/  823] train: loss: 0.0090945
[Epoch 53; Iter   434/  823] train: loss: 0.0090525
[Epoch 53; Iter   464/  823] train: loss: 0.0224794
[Epoch 53; Iter   494/  823] train: loss: 0.1295775
[Epoch 53; Iter   524/  823] train: loss: 0.0391168
[Epoch 53; Iter   554/  823] train: loss: 0.0506926
[Epoch 53; Iter   584/  823] train: loss: 0.0541058
[Epoch 53; Iter   614/  823] train: loss: 0.0397830
[Epoch 53; Iter   644/  823] train: loss: 0.0101546
[Epoch 53; Iter   674/  823] train: loss: 0.1583329
[Epoch 53; Iter   704/  823] train: loss: 0.0289772
[Epoch 53; Iter   734/  823] train: loss: 0.0230448
[Epoch 53; Iter   764/  823] train: loss: 0.1230155
[Epoch 53; Iter   794/  823] train: loss: 0.0616022
[Epoch 53] ogbg-molhiv: 0.737045 val loss: 0.181594
[Epoch 53] ogbg-molhiv: 0.765174 test loss: 0.210686
[Epoch 54; Iter     1/  823] train: loss: 0.0308023
[Epoch 54; Iter    31/  823] train: loss: 0.0181674
[Epoch 54; Iter    61/  823] train: loss: 0.0124771
[Epoch 54; Iter    91/  823] train: loss: 0.0559354
[Epoch 54; Iter   121/  823] train: loss: 0.0140281
[Epoch 54; Iter   151/  823] train: loss: 0.1729055
[Epoch 54; Iter   181/  823] train: loss: 0.1276449
[Epoch 54; Iter   211/  823] train: loss: 0.0322574
[Epoch 54; Iter   241/  823] train: loss: 0.0285453
[Epoch 54; Iter   271/  823] train: loss: 0.0399568
[Epoch 54; Iter   301/  823] train: loss: 0.0294660
[Epoch 54; Iter   331/  823] train: loss: 0.0420890
[Epoch 54; Iter   361/  823] train: loss: 0.1051077
[Epoch 54; Iter   391/  823] train: loss: 0.0103472
[Epoch 54; Iter   421/  823] train: loss: 0.1714732
[Epoch 54; Iter   451/  823] train: loss: 0.0892534
[Epoch 54; Iter   481/  823] train: loss: 0.0474226
[Epoch 54; Iter   511/  823] train: loss: 0.0887856
[Epoch 54; Iter   541/  823] train: loss: 0.0305410
[Epoch 54; Iter   571/  823] train: loss: 0.2605354
[Epoch 54; Iter   601/  823] train: loss: 0.0337953
[Epoch 54; Iter   631/  823] train: loss: 0.0360286
[Epoch 54; Iter   661/  823] train: loss: 0.0179980
[Epoch 54; Iter   691/  823] train: loss: 0.0421470
[Epoch 54; Iter   721/  823] train: loss: 0.0777294
[Epoch 54; Iter   751/  823] train: loss: 0.1659255
[Epoch 54; Iter   781/  823] train: loss: 0.0144140
[Epoch 54; Iter   811/  823] train: loss: 0.0783133
[Epoch 54] ogbg-molhiv: 0.727846 val loss: 0.186679
[Epoch 54] ogbg-molhiv: 0.762101 test loss: 0.258443
[Epoch 55; Iter    18/  823] train: loss: 0.0613822
[Epoch 55; Iter    48/  823] train: loss: 0.0926719
[Epoch 55; Iter    78/  823] train: loss: 0.0128441
[Epoch 55; Iter   108/  823] train: loss: 0.0865982
[Epoch 55; Iter   138/  823] train: loss: 0.0476661
[Epoch 55; Iter   168/  823] train: loss: 0.2397849
[Epoch 55; Iter   198/  823] train: loss: 0.0191666
[Epoch 55; Iter   228/  823] train: loss: 0.0117342
[Epoch 55; Iter   258/  823] train: loss: 0.0396028
[Epoch 55; Iter   288/  823] train: loss: 0.1264436
[Epoch 55; Iter   318/  823] train: loss: 0.0691684
[Epoch 55; Iter   348/  823] train: loss: 0.0134554
[Epoch 55; Iter   378/  823] train: loss: 0.0242677
[Epoch 55; Iter   408/  823] train: loss: 0.1757047
[Epoch 55; Iter   438/  823] train: loss: 0.0161336
[Epoch 55; Iter   468/  823] train: loss: 0.2538520
[Epoch 55; Iter   498/  823] train: loss: 0.0114503
[Epoch 55; Iter   528/  823] train: loss: 0.0257892
[Epoch 55; Iter   558/  823] train: loss: 0.0188199
[Epoch 55; Iter   588/  823] train: loss: 0.0164049
[Epoch 55; Iter   618/  823] train: loss: 0.0223119
[Epoch 55; Iter   648/  823] train: loss: 0.0285621
[Epoch 55; Iter   678/  823] train: loss: 0.0595732
[Epoch 55; Iter   708/  823] train: loss: 0.0097969
[Epoch 55; Iter   738/  823] train: loss: 0.0141095
[Epoch 55; Iter   768/  823] train: loss: 0.1282449
[Epoch 55; Iter   798/  823] train: loss: 0.0537463
[Epoch 55] ogbg-molhiv: 0.723490 val loss: 0.242669
[Epoch 55] ogbg-molhiv: 0.772033 test loss: 0.317722
[Epoch 56; Iter     5/  823] train: loss: 0.0080332
[Epoch 56; Iter    35/  823] train: loss: 0.0401672
[Epoch 56; Iter    65/  823] train: loss: 0.0336438
[Epoch 56; Iter    95/  823] train: loss: 0.0514672
[Epoch 56; Iter   125/  823] train: loss: 0.0091307
[Epoch 56; Iter   155/  823] train: loss: 0.0498392
[Epoch 56; Iter   185/  823] train: loss: 0.1753533
[Epoch 56; Iter   215/  823] train: loss: 0.0121670
[Epoch 56; Iter   245/  823] train: loss: 0.0371186
[Epoch 56; Iter   275/  823] train: loss: 0.0436957
[Epoch 56; Iter   305/  823] train: loss: 0.0172386
[Epoch 56; Iter   335/  823] train: loss: 0.0223915
[Epoch 56; Iter   365/  823] train: loss: 0.0208796
[Epoch 56; Iter   395/  823] train: loss: 0.1127414
[Epoch 56; Iter   425/  823] train: loss: 0.0333622
[Epoch 56; Iter   455/  823] train: loss: 0.1308277
[Epoch 56; Iter   485/  823] train: loss: 0.0616517
[Epoch 56; Iter   515/  823] train: loss: 0.0165958
[Epoch 56; Iter   545/  823] train: loss: 0.0153137
[Epoch 56; Iter   575/  823] train: loss: 0.1031400
[Epoch 56; Iter   605/  823] train: loss: 0.0990846
[Epoch 56; Iter   635/  823] train: loss: 0.0551888
[Epoch 56; Iter   665/  823] train: loss: 0.0242783
[Epoch 56; Iter   695/  823] train: loss: 0.0481537
[Epoch 56; Iter   725/  823] train: loss: 0.0075324
[Epoch 56; Iter   755/  823] train: loss: 0.0892073
[Epoch 56; Iter   785/  823] train: loss: 0.0189985
[Epoch 56; Iter   815/  823] train: loss: 0.1091768
[Epoch 56] ogbg-molhiv: 0.722405 val loss: 0.251312
[Epoch 56] ogbg-molhiv: 0.760093 test loss: 0.365979
[Epoch 57; Iter    22/  823] train: loss: 0.2032851
[Epoch 57; Iter    52/  823] train: loss: 0.0090402
[Epoch 57; Iter    82/  823] train: loss: 0.1029656
[Epoch 57; Iter   112/  823] train: loss: 0.0439162
[Epoch 57; Iter   142/  823] train: loss: 0.1798351
[Epoch 57; Iter   172/  823] train: loss: 0.0231690
[Epoch 57; Iter   202/  823] train: loss: 0.0193509
[Epoch 57; Iter   232/  823] train: loss: 0.0713295
[Epoch 57; Iter   262/  823] train: loss: 0.0107491
[Epoch 57; Iter   292/  823] train: loss: 0.0356315
[Epoch 57; Iter   322/  823] train: loss: 0.0200863
[Epoch 57; Iter   352/  823] train: loss: 0.0103579
[Epoch 57; Iter   382/  823] train: loss: 0.0355770
[Epoch 57; Iter   412/  823] train: loss: 0.0091429
[Epoch 57; Iter   442/  823] train: loss: 0.0399913
[Epoch 57; Iter   472/  823] train: loss: 0.0381182
[Epoch 57; Iter   502/  823] train: loss: 0.1433987
[Epoch 57; Iter   532/  823] train: loss: 0.1078703
[Epoch 57; Iter   562/  823] train: loss: 0.0339146
[Epoch 57; Iter   592/  823] train: loss: 0.1129499
[Epoch 57; Iter   622/  823] train: loss: 0.0733593
[Epoch 57; Iter   652/  823] train: loss: 0.0543998
[Epoch 57; Iter   682/  823] train: loss: 0.0032674
[Epoch 57; Iter   712/  823] train: loss: 0.0092114
[Epoch 57; Iter   742/  823] train: loss: 0.3036740
[Epoch 57; Iter   772/  823] train: loss: 0.0136871
[Epoch 57; Iter   802/  823] train: loss: 0.0541322
[Epoch 57] ogbg-molhiv: 0.735662 val loss: 0.294588
[Epoch 57] ogbg-molhiv: 0.747882 test loss: 0.429818
[Epoch 58; Iter     9/  823] train: loss: 0.1273854
[Epoch 58; Iter    39/  823] train: loss: 0.0155347
[Epoch 58; Iter    69/  823] train: loss: 0.0520574
[Epoch 58; Iter    99/  823] train: loss: 0.0854679
[Epoch 58; Iter   129/  823] train: loss: 0.0661852
[Epoch 58; Iter   159/  823] train: loss: 0.0106300
[Epoch 48; Iter   881/ 1097] train: loss: 0.0694178
[Epoch 48; Iter   911/ 1097] train: loss: 0.0632293
[Epoch 48; Iter   941/ 1097] train: loss: 0.0309330
[Epoch 48; Iter   971/ 1097] train: loss: 0.2291219
[Epoch 48; Iter  1001/ 1097] train: loss: 0.0148915
[Epoch 48; Iter  1031/ 1097] train: loss: 0.0665227
[Epoch 48; Iter  1061/ 1097] train: loss: 0.0413756
[Epoch 48; Iter  1091/ 1097] train: loss: 0.2169111
[Epoch 48] ogbg-molhiv: 0.785892 val loss: 0.090845
[Epoch 48] ogbg-molhiv: 0.781183 test loss: 0.483275
[Epoch 49; Iter    24/ 1097] train: loss: 0.0247654
[Epoch 49; Iter    54/ 1097] train: loss: 0.0230668
[Epoch 49; Iter    84/ 1097] train: loss: 0.0583579
[Epoch 49; Iter   114/ 1097] train: loss: 0.0070893
[Epoch 49; Iter   144/ 1097] train: loss: 0.0207562
[Epoch 49; Iter   174/ 1097] train: loss: 0.0303672
[Epoch 49; Iter   204/ 1097] train: loss: 0.0736677
[Epoch 49; Iter   234/ 1097] train: loss: 0.0176659
[Epoch 49; Iter   264/ 1097] train: loss: 0.0118772
[Epoch 49; Iter   294/ 1097] train: loss: 0.0171019
[Epoch 49; Iter   324/ 1097] train: loss: 0.1292147
[Epoch 49; Iter   354/ 1097] train: loss: 0.0354817
[Epoch 49; Iter   384/ 1097] train: loss: 0.0112660
[Epoch 49; Iter   414/ 1097] train: loss: 0.2344504
[Epoch 49; Iter   444/ 1097] train: loss: 0.0197615
[Epoch 49; Iter   474/ 1097] train: loss: 0.1097581
[Epoch 49; Iter   504/ 1097] train: loss: 0.0154717
[Epoch 49; Iter   534/ 1097] train: loss: 0.0150996
[Epoch 49; Iter   564/ 1097] train: loss: 0.0088413
[Epoch 49; Iter   594/ 1097] train: loss: 0.0695523
[Epoch 49; Iter   624/ 1097] train: loss: 0.0431966
[Epoch 49; Iter   654/ 1097] train: loss: 0.0221400
[Epoch 49; Iter   684/ 1097] train: loss: 0.0190111
[Epoch 49; Iter   714/ 1097] train: loss: 0.0565280
[Epoch 49; Iter   744/ 1097] train: loss: 0.0862389
[Epoch 49; Iter   774/ 1097] train: loss: 0.0626828
[Epoch 49; Iter   804/ 1097] train: loss: 0.0091867
[Epoch 49; Iter   834/ 1097] train: loss: 0.0256718
[Epoch 49; Iter   864/ 1097] train: loss: 0.0612394
[Epoch 49; Iter   894/ 1097] train: loss: 0.0186022
[Epoch 49; Iter   924/ 1097] train: loss: 0.0425240
[Epoch 49; Iter   954/ 1097] train: loss: 0.0086931
[Epoch 49; Iter   984/ 1097] train: loss: 0.0909903
[Epoch 49; Iter  1014/ 1097] train: loss: 0.1445369
[Epoch 49; Iter  1044/ 1097] train: loss: 0.0069730
[Epoch 49; Iter  1074/ 1097] train: loss: 0.0315773
[Epoch 49] ogbg-molhiv: 0.794597 val loss: 0.232060
[Epoch 49] ogbg-molhiv: 0.767037 test loss: 0.734576
[Epoch 50; Iter     7/ 1097] train: loss: 0.0757162
[Epoch 50; Iter    37/ 1097] train: loss: 0.0146647
[Epoch 50; Iter    67/ 1097] train: loss: 0.1103150
[Epoch 50; Iter    97/ 1097] train: loss: 0.0284808
[Epoch 50; Iter   127/ 1097] train: loss: 0.1215452
[Epoch 50; Iter   157/ 1097] train: loss: 0.0222757
[Epoch 50; Iter   187/ 1097] train: loss: 0.0100872
[Epoch 50; Iter   217/ 1097] train: loss: 0.0133781
[Epoch 50; Iter   247/ 1097] train: loss: 0.0427371
[Epoch 50; Iter   277/ 1097] train: loss: 0.0166909
[Epoch 50; Iter   307/ 1097] train: loss: 0.0087766
[Epoch 50; Iter   337/ 1097] train: loss: 0.0152893
[Epoch 50; Iter   367/ 1097] train: loss: 0.0203076
[Epoch 50; Iter   397/ 1097] train: loss: 0.0304407
[Epoch 50; Iter   427/ 1097] train: loss: 0.0336215
[Epoch 50; Iter   457/ 1097] train: loss: 0.0092795
[Epoch 50; Iter   487/ 1097] train: loss: 0.0941672
[Epoch 50; Iter   517/ 1097] train: loss: 0.1320806
[Epoch 50; Iter   547/ 1097] train: loss: 0.0191188
[Epoch 50; Iter   577/ 1097] train: loss: 0.0240903
[Epoch 50; Iter   607/ 1097] train: loss: 0.1009313
[Epoch 50; Iter   637/ 1097] train: loss: 0.1139804
[Epoch 50; Iter   667/ 1097] train: loss: 0.0248667
[Epoch 50; Iter   697/ 1097] train: loss: 0.0763140
[Epoch 50; Iter   727/ 1097] train: loss: 0.0270616
[Epoch 50; Iter   757/ 1097] train: loss: 0.0270242
[Epoch 50; Iter   787/ 1097] train: loss: 0.0113381
[Epoch 50; Iter   817/ 1097] train: loss: 0.0145694
[Epoch 50; Iter   847/ 1097] train: loss: 0.0371078
[Epoch 50; Iter   877/ 1097] train: loss: 0.0103281
[Epoch 50; Iter   907/ 1097] train: loss: 0.0471179
[Epoch 50; Iter   937/ 1097] train: loss: 0.0091574
[Epoch 50; Iter   967/ 1097] train: loss: 0.0958914
[Epoch 50; Iter   997/ 1097] train: loss: 0.0083170
[Epoch 50; Iter  1027/ 1097] train: loss: 0.0107340
[Epoch 50; Iter  1057/ 1097] train: loss: 0.0078059
[Epoch 50; Iter  1087/ 1097] train: loss: 0.0689955
[Epoch 50] ogbg-molhiv: 0.773730 val loss: 0.094961
[Epoch 50] ogbg-molhiv: 0.737905 test loss: 0.205411
[Epoch 51; Iter    20/ 1097] train: loss: 0.0146015
[Epoch 51; Iter    50/ 1097] train: loss: 0.2017623
[Epoch 51; Iter    80/ 1097] train: loss: 0.0302492
[Epoch 51; Iter   110/ 1097] train: loss: 0.0356443
[Epoch 51; Iter   140/ 1097] train: loss: 0.0514348
[Epoch 51; Iter   170/ 1097] train: loss: 0.0935007
[Epoch 51; Iter   200/ 1097] train: loss: 0.1245904
[Epoch 51; Iter   230/ 1097] train: loss: 0.0691424
[Epoch 51; Iter   260/ 1097] train: loss: 0.0111141
[Epoch 51; Iter   290/ 1097] train: loss: 0.0060873
[Epoch 51; Iter   320/ 1097] train: loss: 0.1345121
[Epoch 51; Iter   350/ 1097] train: loss: 0.0040322
[Epoch 51; Iter   380/ 1097] train: loss: 0.0827719
[Epoch 51; Iter   410/ 1097] train: loss: 0.0252643
[Epoch 51; Iter   440/ 1097] train: loss: 0.1009048
[Epoch 51; Iter   470/ 1097] train: loss: 0.1016891
[Epoch 51; Iter   500/ 1097] train: loss: 0.0098293
[Epoch 51; Iter   530/ 1097] train: loss: 0.0086111
[Epoch 51; Iter   560/ 1097] train: loss: 0.0379065
[Epoch 51; Iter   590/ 1097] train: loss: 0.0988617
[Epoch 51; Iter   620/ 1097] train: loss: 0.0082365
[Epoch 51; Iter   650/ 1097] train: loss: 0.0127088
[Epoch 51; Iter   680/ 1097] train: loss: 0.0356021
[Epoch 51; Iter   710/ 1097] train: loss: 0.0929737
[Epoch 51; Iter   740/ 1097] train: loss: 0.0117399
[Epoch 51; Iter   770/ 1097] train: loss: 0.0277060
[Epoch 51; Iter   800/ 1097] train: loss: 0.3229853
[Epoch 51; Iter   830/ 1097] train: loss: 0.1751851
[Epoch 51; Iter   860/ 1097] train: loss: 0.1280912
[Epoch 51; Iter   890/ 1097] train: loss: 0.0505616
[Epoch 51; Iter   920/ 1097] train: loss: 0.0099873
[Epoch 51; Iter   950/ 1097] train: loss: 0.0992391
[Epoch 51; Iter   980/ 1097] train: loss: 0.0108969
[Epoch 51; Iter  1010/ 1097] train: loss: 0.0423210
[Epoch 51; Iter  1040/ 1097] train: loss: 0.1160307
[Epoch 51; Iter  1070/ 1097] train: loss: 0.0196270
[Epoch 51] ogbg-molhiv: 0.787426 val loss: 0.093645
[Epoch 51] ogbg-molhiv: 0.756911 test loss: 0.319117
[Epoch 52; Iter     3/ 1097] train: loss: 0.1547287
[Epoch 52; Iter    33/ 1097] train: loss: 0.0152331
[Epoch 52; Iter    63/ 1097] train: loss: 0.0984261
[Epoch 52; Iter    93/ 1097] train: loss: 0.0410251
[Epoch 52; Iter   123/ 1097] train: loss: 0.0075284
[Epoch 52; Iter   153/ 1097] train: loss: 0.0112443
[Epoch 52; Iter   183/ 1097] train: loss: 0.0240358
[Epoch 52; Iter   213/ 1097] train: loss: 0.0434905
[Epoch 52; Iter   243/ 1097] train: loss: 0.0043403
[Epoch 52; Iter   273/ 1097] train: loss: 0.0843903
[Epoch 52; Iter   303/ 1097] train: loss: 0.0545581
[Epoch 52; Iter   333/ 1097] train: loss: 0.0085224
[Epoch 52; Iter   363/ 1097] train: loss: 0.0255188
[Epoch 52; Iter   393/ 1097] train: loss: 0.0261133
[Epoch 52; Iter   423/ 1097] train: loss: 0.1023893
[Epoch 52; Iter   453/ 1097] train: loss: 0.0166751
[Epoch 52; Iter   483/ 1097] train: loss: 0.2133633
[Epoch 52; Iter   513/ 1097] train: loss: 0.0045815
[Epoch 52; Iter   543/ 1097] train: loss: 0.0662828
[Epoch 52; Iter   573/ 1097] train: loss: 0.0090952
[Epoch 52; Iter   603/ 1097] train: loss: 0.0139660
[Epoch 52; Iter   633/ 1097] train: loss: 0.0442496
[Epoch 52; Iter   663/ 1097] train: loss: 0.1291736
[Epoch 52; Iter   693/ 1097] train: loss: 0.0603345
[Epoch 52; Iter   723/ 1097] train: loss: 0.0727131
[Epoch 52; Iter   753/ 1097] train: loss: 0.0153777
[Epoch 52; Iter   783/ 1097] train: loss: 0.0439083
[Epoch 52; Iter   813/ 1097] train: loss: 0.0633561
[Epoch 52; Iter   843/ 1097] train: loss: 0.1619662
[Epoch 52; Iter   873/ 1097] train: loss: 0.0137190
[Epoch 52; Iter   903/ 1097] train: loss: 0.0102844
[Epoch 52; Iter   933/ 1097] train: loss: 0.0110976
[Epoch 52; Iter   777/  823] train: loss: 0.0207411
[Epoch 52; Iter   807/  823] train: loss: 0.0079500
[Epoch 52] ogbg-molhiv: 0.718606 val loss: 0.205674
[Epoch 52] ogbg-molhiv: 0.758938 test loss: 0.127092
[Epoch 53; Iter    14/  823] train: loss: 0.0098035
[Epoch 53; Iter    44/  823] train: loss: 0.0267547
[Epoch 53; Iter    74/  823] train: loss: 0.0159008
[Epoch 53; Iter   104/  823] train: loss: 0.0217560
[Epoch 53; Iter   134/  823] train: loss: 0.0082544
[Epoch 53; Iter   164/  823] train: loss: 0.0486408
[Epoch 53; Iter   194/  823] train: loss: 0.0306808
[Epoch 53; Iter   224/  823] train: loss: 0.1355865
[Epoch 53; Iter   254/  823] train: loss: 0.0210195
[Epoch 53; Iter   284/  823] train: loss: 0.0194218
[Epoch 53; Iter   314/  823] train: loss: 0.0422817
[Epoch 53; Iter   344/  823] train: loss: 0.0059761
[Epoch 53; Iter   374/  823] train: loss: 0.0985973
[Epoch 53; Iter   404/  823] train: loss: 0.0124491
[Epoch 53; Iter   434/  823] train: loss: 0.0468758
[Epoch 53; Iter   464/  823] train: loss: 0.0032261
[Epoch 53; Iter   494/  823] train: loss: 0.0080726
[Epoch 53; Iter   524/  823] train: loss: 0.2031387
[Epoch 53; Iter   554/  823] train: loss: 0.0313065
[Epoch 53; Iter   584/  823] train: loss: 0.0980533
[Epoch 53; Iter   614/  823] train: loss: 0.0252204
[Epoch 53; Iter   644/  823] train: loss: 0.0074948
[Epoch 53; Iter   674/  823] train: loss: 0.0164677
[Epoch 53; Iter   704/  823] train: loss: 0.0891615
[Epoch 53; Iter   734/  823] train: loss: 0.0518015
[Epoch 53; Iter   764/  823] train: loss: 0.0443988
[Epoch 53; Iter   794/  823] train: loss: 0.0048655
[Epoch 53] ogbg-molhiv: 0.715138 val loss: 0.223252
[Epoch 53] ogbg-molhiv: 0.733729 test loss: 0.139202
[Epoch 54; Iter     1/  823] train: loss: 0.0765731
[Epoch 54; Iter    31/  823] train: loss: 0.0070823
[Epoch 54; Iter    61/  823] train: loss: 0.0883229
[Epoch 54; Iter    91/  823] train: loss: 0.0260505
[Epoch 54; Iter   121/  823] train: loss: 0.0571505
[Epoch 54; Iter   151/  823] train: loss: 0.0612793
[Epoch 54; Iter   181/  823] train: loss: 0.0769365
[Epoch 54; Iter   211/  823] train: loss: 0.0115999
[Epoch 54; Iter   241/  823] train: loss: 0.0600414
[Epoch 54; Iter   271/  823] train: loss: 0.0787176
[Epoch 54; Iter   301/  823] train: loss: 0.0172189
[Epoch 54; Iter   331/  823] train: loss: 0.0312976
[Epoch 54; Iter   361/  823] train: loss: 0.1292333
[Epoch 54; Iter   391/  823] train: loss: 0.0290587
[Epoch 54; Iter   421/  823] train: loss: 0.1441250
[Epoch 54; Iter   451/  823] train: loss: 0.0093900
[Epoch 54; Iter   481/  823] train: loss: 0.0117875
[Epoch 54; Iter   511/  823] train: loss: 0.0070756
[Epoch 54; Iter   541/  823] train: loss: 0.0884803
[Epoch 54; Iter   571/  823] train: loss: 0.0608426
[Epoch 54; Iter   601/  823] train: loss: 0.0079189
[Epoch 54; Iter   631/  823] train: loss: 0.0323371
[Epoch 54; Iter   661/  823] train: loss: 0.1027386
[Epoch 54; Iter   691/  823] train: loss: 0.0453035
[Epoch 54; Iter   721/  823] train: loss: 0.0501475
[Epoch 54; Iter   751/  823] train: loss: 0.0662100
[Epoch 54; Iter   781/  823] train: loss: 0.0425481
[Epoch 54; Iter   811/  823] train: loss: 0.0886592
[Epoch 54] ogbg-molhiv: 0.707385 val loss: 0.214787
[Epoch 54] ogbg-molhiv: 0.748653 test loss: 0.148827
[Epoch 55; Iter    18/  823] train: loss: 0.1636366
[Epoch 55; Iter    48/  823] train: loss: 0.0068348
[Epoch 55; Iter    78/  823] train: loss: 0.0166741
[Epoch 55; Iter   108/  823] train: loss: 0.0835192
[Epoch 55; Iter   138/  823] train: loss: 0.0087053
[Epoch 55; Iter   168/  823] train: loss: 0.0108582
[Epoch 55; Iter   198/  823] train: loss: 0.0089471
[Epoch 55; Iter   228/  823] train: loss: 0.0107577
[Epoch 55; Iter   258/  823] train: loss: 0.0830792
[Epoch 55; Iter   288/  823] train: loss: 0.0406907
[Epoch 55; Iter   318/  823] train: loss: 0.1113301
[Epoch 55; Iter   348/  823] train: loss: 0.0366774
[Epoch 55; Iter   378/  823] train: loss: 0.0097176
[Epoch 55; Iter   408/  823] train: loss: 0.0553073
[Epoch 55; Iter   438/  823] train: loss: 0.0118593
[Epoch 55; Iter   468/  823] train: loss: 0.0631049
[Epoch 55; Iter   498/  823] train: loss: 0.0373839
[Epoch 55; Iter   528/  823] train: loss: 0.0090547
[Epoch 55; Iter   558/  823] train: loss: 0.0824919
[Epoch 55; Iter   588/  823] train: loss: 0.0540199
[Epoch 55; Iter   618/  823] train: loss: 0.0416603
[Epoch 55; Iter   648/  823] train: loss: 0.0159094
[Epoch 55; Iter   678/  823] train: loss: 0.0073597
[Epoch 55; Iter   708/  823] train: loss: 0.0104414
[Epoch 55; Iter   738/  823] train: loss: 0.0317457
[Epoch 55; Iter   768/  823] train: loss: 0.0222173
[Epoch 55; Iter   798/  823] train: loss: 0.0949442
[Epoch 55] ogbg-molhiv: 0.720199 val loss: 0.246587
[Epoch 55] ogbg-molhiv: 0.755254 test loss: 0.176948
[Epoch 56; Iter     5/  823] train: loss: 0.0220905
[Epoch 56; Iter    35/  823] train: loss: 0.0106505
[Epoch 56; Iter    65/  823] train: loss: 0.0108488
[Epoch 56; Iter    95/  823] train: loss: 0.0213644
[Epoch 56; Iter   125/  823] train: loss: 0.0164225
[Epoch 56; Iter   155/  823] train: loss: 0.0568857
[Epoch 56; Iter   185/  823] train: loss: 0.0478234
[Epoch 56; Iter   215/  823] train: loss: 0.0380531
[Epoch 56; Iter   245/  823] train: loss: 0.0236097
[Epoch 56; Iter   275/  823] train: loss: 0.0843966
[Epoch 56; Iter   305/  823] train: loss: 0.0197243
[Epoch 56; Iter   335/  823] train: loss: 0.0323428
[Epoch 56; Iter   365/  823] train: loss: 0.0114057
[Epoch 56; Iter   395/  823] train: loss: 0.0668625
[Epoch 56; Iter   425/  823] train: loss: 0.0129549
[Epoch 56; Iter   455/  823] train: loss: 0.1269920
[Epoch 56; Iter   485/  823] train: loss: 0.0247723
[Epoch 56; Iter   515/  823] train: loss: 0.0147722
[Epoch 56; Iter   545/  823] train: loss: 0.0076194
[Epoch 56; Iter   575/  823] train: loss: 0.0535367
[Epoch 56; Iter   605/  823] train: loss: 0.1175387
[Epoch 56; Iter   635/  823] train: loss: 0.0219461
[Epoch 56; Iter   665/  823] train: loss: 0.0053878
[Epoch 56; Iter   695/  823] train: loss: 0.0197500
[Epoch 56; Iter   725/  823] train: loss: 0.2047239
[Epoch 56; Iter   755/  823] train: loss: 0.1228017
[Epoch 56; Iter   785/  823] train: loss: 0.1213118
[Epoch 56; Iter   815/  823] train: loss: 0.0647070
[Epoch 56] ogbg-molhiv: 0.700895 val loss: 0.222283
[Epoch 56] ogbg-molhiv: 0.752003 test loss: 0.143502
[Epoch 57; Iter    22/  823] train: loss: 0.0196985
[Epoch 57; Iter    52/  823] train: loss: 0.0145006
[Epoch 57; Iter    82/  823] train: loss: 0.0251962
[Epoch 57; Iter   112/  823] train: loss: 0.0493573
[Epoch 57; Iter   142/  823] train: loss: 0.0234258
[Epoch 57; Iter   172/  823] train: loss: 0.1536936
[Epoch 57; Iter   202/  823] train: loss: 0.0057395
[Epoch 57; Iter   232/  823] train: loss: 0.1305541
[Epoch 57; Iter   262/  823] train: loss: 0.0163270
[Epoch 57; Iter   292/  823] train: loss: 0.0336348
[Epoch 57; Iter   322/  823] train: loss: 0.0148004
[Epoch 57; Iter   352/  823] train: loss: 0.0091276
[Epoch 57; Iter   382/  823] train: loss: 0.0120951
[Epoch 57; Iter   412/  823] train: loss: 0.0132454
[Epoch 57; Iter   442/  823] train: loss: 0.0108095
[Epoch 57; Iter   472/  823] train: loss: 0.0206963
[Epoch 57; Iter   502/  823] train: loss: 0.0254461
[Epoch 57; Iter   532/  823] train: loss: 0.1448946
[Epoch 57; Iter   562/  823] train: loss: 0.0040377
[Epoch 57; Iter   592/  823] train: loss: 0.0099640
[Epoch 57; Iter   622/  823] train: loss: 0.1675474
[Epoch 57; Iter   652/  823] train: loss: 0.0669809
[Epoch 57; Iter   682/  823] train: loss: 0.0109964
[Epoch 57; Iter   712/  823] train: loss: 0.0153673
[Epoch 57; Iter   742/  823] train: loss: 0.0495155
[Epoch 57; Iter   772/  823] train: loss: 0.0128819
[Epoch 57; Iter   802/  823] train: loss: 0.0041877
[Epoch 57] ogbg-molhiv: 0.701972 val loss: 0.264678
[Epoch 57] ogbg-molhiv: 0.741915 test loss: 0.163294
[Epoch 58; Iter     9/  823] train: loss: 0.0499241
[Epoch 58; Iter    39/  823] train: loss: 0.0119912
[Epoch 58; Iter    69/  823] train: loss: 0.0385388
[Epoch 58; Iter    99/  823] train: loss: 0.0715786
[Epoch 58; Iter   129/  823] train: loss: 0.0064773
[Epoch 58; Iter   159/  823] train: loss: 0.0063205
[Epoch 52; Iter   777/  823] train: loss: 0.0070159
[Epoch 52; Iter   807/  823] train: loss: 0.0257303
[Epoch 52] ogbg-molhiv: 0.696309 val loss: 0.205993
[Epoch 52] ogbg-molhiv: 0.744421 test loss: 0.164655
[Epoch 53; Iter    14/  823] train: loss: 0.0156223
[Epoch 53; Iter    44/  823] train: loss: 0.0079010
[Epoch 53; Iter    74/  823] train: loss: 0.0031862
[Epoch 53; Iter   104/  823] train: loss: 0.0605724
[Epoch 53; Iter   134/  823] train: loss: 0.0101413
[Epoch 53; Iter   164/  823] train: loss: 0.0152362
[Epoch 53; Iter   194/  823] train: loss: 0.1076870
[Epoch 53; Iter   224/  823] train: loss: 0.0660313
[Epoch 53; Iter   254/  823] train: loss: 0.0656442
[Epoch 53; Iter   284/  823] train: loss: 0.1118767
[Epoch 53; Iter   314/  823] train: loss: 0.0047933
[Epoch 53; Iter   344/  823] train: loss: 0.0306251
[Epoch 53; Iter   374/  823] train: loss: 0.0354980
[Epoch 53; Iter   404/  823] train: loss: 0.0102220
[Epoch 53; Iter   434/  823] train: loss: 0.0338204
[Epoch 53; Iter   464/  823] train: loss: 0.0082046
[Epoch 53; Iter   494/  823] train: loss: 0.0889039
[Epoch 53; Iter   524/  823] train: loss: 0.0137572
[Epoch 53; Iter   554/  823] train: loss: 0.2135694
[Epoch 53; Iter   584/  823] train: loss: 0.0053613
[Epoch 53; Iter   614/  823] train: loss: 0.0254701
[Epoch 53; Iter   644/  823] train: loss: 0.0210344
[Epoch 53; Iter   674/  823] train: loss: 0.0602824
[Epoch 53; Iter   704/  823] train: loss: 0.0948155
[Epoch 53; Iter   734/  823] train: loss: 0.0075470
[Epoch 53; Iter   764/  823] train: loss: 0.1474503
[Epoch 53; Iter   794/  823] train: loss: 0.0058908
[Epoch 53] ogbg-molhiv: 0.719711 val loss: 0.199954
[Epoch 53] ogbg-molhiv: 0.757886 test loss: 0.135581
[Epoch 54; Iter     1/  823] train: loss: 0.0897444
[Epoch 54; Iter    31/  823] train: loss: 0.1694485
[Epoch 54; Iter    61/  823] train: loss: 0.2243364
[Epoch 54; Iter    91/  823] train: loss: 0.0304643
[Epoch 54; Iter   121/  823] train: loss: 0.0034170
[Epoch 54; Iter   151/  823] train: loss: 0.0141685
[Epoch 54; Iter   181/  823] train: loss: 0.0112712
[Epoch 54; Iter   211/  823] train: loss: 0.0132763
[Epoch 54; Iter   241/  823] train: loss: 0.0361908
[Epoch 54; Iter   271/  823] train: loss: 0.1644487
[Epoch 54; Iter   301/  823] train: loss: 0.0217728
[Epoch 54; Iter   331/  823] train: loss: 0.0088214
[Epoch 54; Iter   361/  823] train: loss: 0.0224919
[Epoch 54; Iter   391/  823] train: loss: 0.0145763
[Epoch 54; Iter   421/  823] train: loss: 0.0739372
[Epoch 54; Iter   451/  823] train: loss: 0.0529590
[Epoch 54; Iter   481/  823] train: loss: 0.0246937
[Epoch 54; Iter   511/  823] train: loss: 0.0862218
[Epoch 54; Iter   541/  823] train: loss: 0.0149657
[Epoch 54; Iter   571/  823] train: loss: 0.0418545
[Epoch 54; Iter   601/  823] train: loss: 0.1198571
[Epoch 54; Iter   631/  823] train: loss: 0.0157158
[Epoch 54; Iter   661/  823] train: loss: 0.0992312
[Epoch 54; Iter   691/  823] train: loss: 0.0206817
[Epoch 54; Iter   721/  823] train: loss: 0.1235736
[Epoch 54; Iter   751/  823] train: loss: 0.0813592
[Epoch 54; Iter   781/  823] train: loss: 0.0270396
[Epoch 54; Iter   811/  823] train: loss: 0.0076175
[Epoch 54] ogbg-molhiv: 0.733215 val loss: 0.220548
[Epoch 54] ogbg-molhiv: 0.771611 test loss: 0.142991
[Epoch 55; Iter    18/  823] train: loss: 0.0656583
[Epoch 55; Iter    48/  823] train: loss: 0.0365474
[Epoch 55; Iter    78/  823] train: loss: 0.0082121
[Epoch 55; Iter   108/  823] train: loss: 0.0045803
[Epoch 55; Iter   138/  823] train: loss: 0.0277884
[Epoch 55; Iter   168/  823] train: loss: 0.0240299
[Epoch 55; Iter   198/  823] train: loss: 0.1382871
[Epoch 55; Iter   228/  823] train: loss: 0.0331580
[Epoch 55; Iter   258/  823] train: loss: 0.0705479
[Epoch 55; Iter   288/  823] train: loss: 0.0364507
[Epoch 55; Iter   318/  823] train: loss: 0.0519742
[Epoch 55; Iter   348/  823] train: loss: 0.0566398
[Epoch 55; Iter   378/  823] train: loss: 0.2050032
[Epoch 55; Iter   408/  823] train: loss: 0.0074933
[Epoch 55; Iter   438/  823] train: loss: 0.0080168
[Epoch 55; Iter   468/  823] train: loss: 0.0087676
[Epoch 55; Iter   498/  823] train: loss: 0.2094710
[Epoch 55; Iter   528/  823] train: loss: 0.0297291
[Epoch 55; Iter   558/  823] train: loss: 0.0299513
[Epoch 55; Iter   588/  823] train: loss: 0.1024746
[Epoch 55; Iter   618/  823] train: loss: 0.1151741
[Epoch 55; Iter   648/  823] train: loss: 0.0147434
[Epoch 55; Iter   678/  823] train: loss: 0.0088919
[Epoch 55; Iter   708/  823] train: loss: 0.0068555
[Epoch 55; Iter   738/  823] train: loss: 0.0551774
[Epoch 55; Iter   768/  823] train: loss: 0.0050666
[Epoch 55; Iter   798/  823] train: loss: 0.0298934
[Epoch 55] ogbg-molhiv: 0.720376 val loss: 0.216542
[Epoch 55] ogbg-molhiv: 0.778546 test loss: 0.142134
[Epoch 56; Iter     5/  823] train: loss: 0.0267134
[Epoch 56; Iter    35/  823] train: loss: 0.0166469
[Epoch 56; Iter    65/  823] train: loss: 0.0716175
[Epoch 56; Iter    95/  823] train: loss: 0.1159070
[Epoch 56; Iter   125/  823] train: loss: 0.0231010
[Epoch 56; Iter   155/  823] train: loss: 0.0118407
[Epoch 56; Iter   185/  823] train: loss: 0.0476964
[Epoch 56; Iter   215/  823] train: loss: 0.0812274
[Epoch 56; Iter   245/  823] train: loss: 0.1148895
[Epoch 56; Iter   275/  823] train: loss: 0.0054541
[Epoch 56; Iter   305/  823] train: loss: 0.0256779
[Epoch 56; Iter   335/  823] train: loss: 0.0357028
[Epoch 56; Iter   365/  823] train: loss: 0.0141665
[Epoch 56; Iter   395/  823] train: loss: 0.0133057
[Epoch 56; Iter   425/  823] train: loss: 0.0958986
[Epoch 56; Iter   455/  823] train: loss: 0.0085812
[Epoch 56; Iter   485/  823] train: loss: 0.0657555
[Epoch 56; Iter   515/  823] train: loss: 0.2161231
[Epoch 56; Iter   545/  823] train: loss: 0.0054744
[Epoch 56; Iter   575/  823] train: loss: 0.0195374
[Epoch 56; Iter   605/  823] train: loss: 0.1177150
[Epoch 56; Iter   635/  823] train: loss: 0.0125766
[Epoch 56; Iter   665/  823] train: loss: 0.1669669
[Epoch 56; Iter   695/  823] train: loss: 0.0067932
[Epoch 56; Iter   725/  823] train: loss: 0.1370521
[Epoch 56; Iter   755/  823] train: loss: 0.0201395
[Epoch 56; Iter   785/  823] train: loss: 0.0179917
[Epoch 56; Iter   815/  823] train: loss: 0.0455762
[Epoch 56] ogbg-molhiv: 0.724984 val loss: 0.205956
[Epoch 56] ogbg-molhiv: 0.762929 test loss: 0.135896
[Epoch 57; Iter    22/  823] train: loss: 0.0093031
[Epoch 57; Iter    52/  823] train: loss: 0.0487684
[Epoch 57; Iter    82/  823] train: loss: 0.0294104
[Epoch 57; Iter   112/  823] train: loss: 0.0201093
[Epoch 57; Iter   142/  823] train: loss: 0.0310521
[Epoch 57; Iter   172/  823] train: loss: 0.0177930
[Epoch 57; Iter   202/  823] train: loss: 0.1046985
[Epoch 57; Iter   232/  823] train: loss: 0.0211029
[Epoch 57; Iter   262/  823] train: loss: 0.0157820
[Epoch 57; Iter   292/  823] train: loss: 0.1109695
[Epoch 57; Iter   322/  823] train: loss: 0.1056713
[Epoch 57; Iter   352/  823] train: loss: 0.0232395
[Epoch 57; Iter   382/  823] train: loss: 0.0092502
[Epoch 57; Iter   412/  823] train: loss: 0.0921029
[Epoch 57; Iter   442/  823] train: loss: 0.0237225
[Epoch 57; Iter   472/  823] train: loss: 0.0126166
[Epoch 57; Iter   502/  823] train: loss: 0.2743371
[Epoch 57; Iter   532/  823] train: loss: 0.0696988
[Epoch 57; Iter   562/  823] train: loss: 0.0846637
[Epoch 57; Iter   592/  823] train: loss: 0.0146541
[Epoch 57; Iter   622/  823] train: loss: 0.0077484
[Epoch 57; Iter   652/  823] train: loss: 0.0067781
[Epoch 57; Iter   682/  823] train: loss: 0.0036652
[Epoch 57; Iter   712/  823] train: loss: 0.0491238
[Epoch 57; Iter   742/  823] train: loss: 0.0251654
[Epoch 57; Iter   772/  823] train: loss: 0.0248630
[Epoch 57; Iter   802/  823] train: loss: 0.0169892
[Epoch 57] ogbg-molhiv: 0.730867 val loss: 0.211376
[Epoch 57] ogbg-molhiv: 0.758536 test loss: 0.152032
[Epoch 58; Iter     9/  823] train: loss: 0.0504430
[Epoch 58; Iter    39/  823] train: loss: 0.0060336
[Epoch 58; Iter    69/  823] train: loss: 0.0167739
[Epoch 58; Iter    99/  823] train: loss: 0.0162672
[Epoch 58; Iter   129/  823] train: loss: 0.0093546
[Epoch 58; Iter   159/  823] train: loss: 0.0348169
[Epoch 52; Iter   963/ 1097] train: loss: 0.0176120
[Epoch 52; Iter   993/ 1097] train: loss: 0.0181331
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0893919
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0264952
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0157748
[Epoch 52] ogbg-molhiv: 0.753555 val loss: 0.199634
[Epoch 52] ogbg-molhiv: 0.732797 test loss: 0.387677
[Epoch 53; Iter    16/ 1097] train: loss: 0.0405608
[Epoch 53; Iter    46/ 1097] train: loss: 0.0311315
[Epoch 53; Iter    76/ 1097] train: loss: 0.0083734
[Epoch 53; Iter   106/ 1097] train: loss: 0.0100356
[Epoch 53; Iter   136/ 1097] train: loss: 0.1036095
[Epoch 53; Iter   166/ 1097] train: loss: 0.0131888
[Epoch 53; Iter   196/ 1097] train: loss: 0.0237268
[Epoch 53; Iter   226/ 1097] train: loss: 0.1435113
[Epoch 53; Iter   256/ 1097] train: loss: 0.0401495
[Epoch 53; Iter   286/ 1097] train: loss: 0.0150454
[Epoch 53; Iter   316/ 1097] train: loss: 0.0219160
[Epoch 53; Iter   346/ 1097] train: loss: 0.1076279
[Epoch 53; Iter   376/ 1097] train: loss: 0.1398657
[Epoch 53; Iter   406/ 1097] train: loss: 0.0209006
[Epoch 53; Iter   436/ 1097] train: loss: 0.0322608
[Epoch 53; Iter   466/ 1097] train: loss: 0.2199592
[Epoch 53; Iter   496/ 1097] train: loss: 0.0495183
[Epoch 53; Iter   526/ 1097] train: loss: 0.0340545
[Epoch 53; Iter   556/ 1097] train: loss: 0.0957294
[Epoch 53; Iter   586/ 1097] train: loss: 0.0852291
[Epoch 53; Iter   616/ 1097] train: loss: 0.0069099
[Epoch 53; Iter   646/ 1097] train: loss: 0.1605788
[Epoch 53; Iter   676/ 1097] train: loss: 0.0805944
[Epoch 53; Iter   706/ 1097] train: loss: 0.0609993
[Epoch 53; Iter   736/ 1097] train: loss: 0.0152696
[Epoch 53; Iter   766/ 1097] train: loss: 0.0101554
[Epoch 53; Iter   796/ 1097] train: loss: 0.0278857
[Epoch 53; Iter   826/ 1097] train: loss: 0.0418227
[Epoch 53; Iter   856/ 1097] train: loss: 0.0854974
[Epoch 53; Iter   886/ 1097] train: loss: 0.0106532
[Epoch 53; Iter   916/ 1097] train: loss: 0.1583019
[Epoch 53; Iter   946/ 1097] train: loss: 0.0532992
[Epoch 53; Iter   976/ 1097] train: loss: 0.0147997
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0175959
[Epoch 53; Iter  1036/ 1097] train: loss: 0.1031509
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0149015
[Epoch 53; Iter  1096/ 1097] train: loss: 0.1011183
[Epoch 53] ogbg-molhiv: 0.764660 val loss: 0.149534
[Epoch 53] ogbg-molhiv: 0.732260 test loss: 0.361050
[Epoch 54; Iter    29/ 1097] train: loss: 0.0328964
[Epoch 54; Iter    59/ 1097] train: loss: 0.0323083
[Epoch 54; Iter    89/ 1097] train: loss: 0.0183858
[Epoch 54; Iter   119/ 1097] train: loss: 0.0747510
[Epoch 54; Iter   149/ 1097] train: loss: 0.0175291
[Epoch 54; Iter   179/ 1097] train: loss: 0.0405051
[Epoch 54; Iter   209/ 1097] train: loss: 0.0300072
[Epoch 54; Iter   239/ 1097] train: loss: 0.0250695
[Epoch 54; Iter   269/ 1097] train: loss: 0.0167953
[Epoch 54; Iter   299/ 1097] train: loss: 0.1218969
[Epoch 54; Iter   329/ 1097] train: loss: 0.0126643
[Epoch 54; Iter   359/ 1097] train: loss: 0.0052040
[Epoch 54; Iter   389/ 1097] train: loss: 0.0743817
[Epoch 54; Iter   419/ 1097] train: loss: 0.0727341
[Epoch 54; Iter   449/ 1097] train: loss: 0.0527912
[Epoch 54; Iter   479/ 1097] train: loss: 0.0556174
[Epoch 54; Iter   509/ 1097] train: loss: 0.0951204
[Epoch 54; Iter   539/ 1097] train: loss: 0.0446167
[Epoch 54; Iter   569/ 1097] train: loss: 0.0168983
[Epoch 54; Iter   599/ 1097] train: loss: 0.0884407
[Epoch 54; Iter   629/ 1097] train: loss: 0.0508621
[Epoch 54; Iter   659/ 1097] train: loss: 0.0334965
[Epoch 54; Iter   689/ 1097] train: loss: 0.0513821
[Epoch 54; Iter   719/ 1097] train: loss: 0.0357260
[Epoch 54; Iter   749/ 1097] train: loss: 0.0107403
[Epoch 54; Iter   779/ 1097] train: loss: 0.0259399
[Epoch 54; Iter   809/ 1097] train: loss: 0.1056353
[Epoch 54; Iter   839/ 1097] train: loss: 0.2259487
[Epoch 54; Iter   869/ 1097] train: loss: 0.0205184
[Epoch 54; Iter   899/ 1097] train: loss: 0.0251345
[Epoch 54; Iter   929/ 1097] train: loss: 0.0090226
[Epoch 54; Iter   959/ 1097] train: loss: 0.0787048
[Epoch 54; Iter   989/ 1097] train: loss: 0.0134526
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0062724
[Epoch 54; Iter  1049/ 1097] train: loss: 0.3194233
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0437456
[Epoch 54] ogbg-molhiv: 0.752661 val loss: 0.154435
[Epoch 54] ogbg-molhiv: 0.719774 test loss: 0.371467
[Epoch 55; Iter    12/ 1097] train: loss: 0.0649651
[Epoch 55; Iter    42/ 1097] train: loss: 0.0502965
[Epoch 55; Iter    72/ 1097] train: loss: 0.0190531
[Epoch 55; Iter   102/ 1097] train: loss: 0.0580912
[Epoch 55; Iter   132/ 1097] train: loss: 0.4507909
[Epoch 55; Iter   162/ 1097] train: loss: 0.0623272
[Epoch 55; Iter   192/ 1097] train: loss: 0.0113810
[Epoch 55; Iter   222/ 1097] train: loss: 0.0061202
[Epoch 55; Iter   252/ 1097] train: loss: 0.0273609
[Epoch 55; Iter   282/ 1097] train: loss: 0.2131945
[Epoch 55; Iter   312/ 1097] train: loss: 0.1503556
[Epoch 55; Iter   342/ 1097] train: loss: 0.0247185
[Epoch 55; Iter   372/ 1097] train: loss: 0.1277097
[Epoch 55; Iter   402/ 1097] train: loss: 0.0248204
[Epoch 55; Iter   432/ 1097] train: loss: 0.0104655
[Epoch 55; Iter   462/ 1097] train: loss: 0.0407162
[Epoch 55; Iter   492/ 1097] train: loss: 0.0470405
[Epoch 55; Iter   522/ 1097] train: loss: 0.0337959
[Epoch 55; Iter   552/ 1097] train: loss: 0.0468613
[Epoch 55; Iter   582/ 1097] train: loss: 0.1518378
[Epoch 55; Iter   612/ 1097] train: loss: 0.0699615
[Epoch 55; Iter   642/ 1097] train: loss: 0.0148934
[Epoch 55; Iter   672/ 1097] train: loss: 0.0118519
[Epoch 55; Iter   702/ 1097] train: loss: 0.0236416
[Epoch 55; Iter   732/ 1097] train: loss: 0.0796157
[Epoch 55; Iter   762/ 1097] train: loss: 0.0232082
[Epoch 55; Iter   792/ 1097] train: loss: 0.0318766
[Epoch 55; Iter   822/ 1097] train: loss: 0.0229461
[Epoch 55; Iter   852/ 1097] train: loss: 0.0677066
[Epoch 55; Iter   882/ 1097] train: loss: 0.1015485
[Epoch 55; Iter   912/ 1097] train: loss: 0.0323775
[Epoch 55; Iter   942/ 1097] train: loss: 0.0074798
[Epoch 55; Iter   972/ 1097] train: loss: 0.0137366
[Epoch 55; Iter  1002/ 1097] train: loss: 0.1231749
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0233096
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0103080
[Epoch 55; Iter  1092/ 1097] train: loss: 0.1656212
[Epoch 55] ogbg-molhiv: 0.778785 val loss: 0.163678
[Epoch 55] ogbg-molhiv: 0.717422 test loss: 0.371749
[Epoch 56; Iter    25/ 1097] train: loss: 0.0401367
[Epoch 56; Iter    55/ 1097] train: loss: 0.1289724
[Epoch 56; Iter    85/ 1097] train: loss: 0.0183127
[Epoch 56; Iter   115/ 1097] train: loss: 0.0071907
[Epoch 56; Iter   145/ 1097] train: loss: 0.0508698
[Epoch 56; Iter   175/ 1097] train: loss: 0.1949721
[Epoch 56; Iter   205/ 1097] train: loss: 0.1091192
[Epoch 56; Iter   235/ 1097] train: loss: 0.0133250
[Epoch 56; Iter   265/ 1097] train: loss: 0.0175156
[Epoch 56; Iter   295/ 1097] train: loss: 0.1763595
[Epoch 56; Iter   325/ 1097] train: loss: 0.0245748
[Epoch 56; Iter   355/ 1097] train: loss: 0.0621133
[Epoch 56; Iter   385/ 1097] train: loss: 0.0946927
[Epoch 56; Iter   415/ 1097] train: loss: 0.0059321
[Epoch 56; Iter   445/ 1097] train: loss: 0.0305894
[Epoch 56; Iter   475/ 1097] train: loss: 0.0272683
[Epoch 56; Iter   505/ 1097] train: loss: 0.0071857
[Epoch 56; Iter   535/ 1097] train: loss: 0.0257016
[Epoch 56; Iter   565/ 1097] train: loss: 0.0089882
[Epoch 56; Iter   595/ 1097] train: loss: 0.0260435
[Epoch 56; Iter   625/ 1097] train: loss: 0.0083002
[Epoch 56; Iter   655/ 1097] train: loss: 0.1370737
[Epoch 56; Iter   685/ 1097] train: loss: 0.0170850
[Epoch 56; Iter   715/ 1097] train: loss: 0.0532245
[Epoch 56; Iter   745/ 1097] train: loss: 0.0056424
[Epoch 56; Iter   775/ 1097] train: loss: 0.0347343
[Epoch 56; Iter   805/ 1097] train: loss: 0.0136986
[Epoch 56; Iter   835/ 1097] train: loss: 0.0113096
[Epoch 56; Iter   865/ 1097] train: loss: 0.1280550
[Epoch 56; Iter   895/ 1097] train: loss: 0.0800937
[Epoch 56; Iter   925/ 1097] train: loss: 0.1447114
[Epoch 56; Iter   955/ 1097] train: loss: 0.0568323
[Epoch 56; Iter   985/ 1097] train: loss: 0.1818586
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0214576
[Epoch 52; Iter   963/ 1097] train: loss: 0.0842245
[Epoch 52; Iter   993/ 1097] train: loss: 0.0211890
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0200658
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0225993
[Epoch 52; Iter  1083/ 1097] train: loss: 0.0132281
[Epoch 52] ogbg-molhiv: 0.800978 val loss: 0.082598
[Epoch 52] ogbg-molhiv: 0.735864 test loss: 0.175817
[Epoch 53; Iter    16/ 1097] train: loss: 0.0230989
[Epoch 53; Iter    46/ 1097] train: loss: 0.0726340
[Epoch 53; Iter    76/ 1097] train: loss: 0.0342008
[Epoch 53; Iter   106/ 1097] train: loss: 0.0191744
[Epoch 53; Iter   136/ 1097] train: loss: 0.0171360
[Epoch 53; Iter   166/ 1097] train: loss: 0.3997436
[Epoch 53; Iter   196/ 1097] train: loss: 0.0194703
[Epoch 53; Iter   226/ 1097] train: loss: 0.0354956
[Epoch 53; Iter   256/ 1097] train: loss: 0.1299544
[Epoch 53; Iter   286/ 1097] train: loss: 0.2822947
[Epoch 53; Iter   316/ 1097] train: loss: 0.0238123
[Epoch 53; Iter   346/ 1097] train: loss: 0.1550704
[Epoch 53; Iter   376/ 1097] train: loss: 0.0349920
[Epoch 53; Iter   406/ 1097] train: loss: 0.0257857
[Epoch 53; Iter   436/ 1097] train: loss: 0.2287065
[Epoch 53; Iter   466/ 1097] train: loss: 0.1767087
[Epoch 53; Iter   496/ 1097] train: loss: 0.0142742
[Epoch 53; Iter   526/ 1097] train: loss: 0.0668108
[Epoch 53; Iter   556/ 1097] train: loss: 0.0127601
[Epoch 53; Iter   586/ 1097] train: loss: 0.0629927
[Epoch 53; Iter   616/ 1097] train: loss: 0.0461871
[Epoch 53; Iter   646/ 1097] train: loss: 0.0879388
[Epoch 53; Iter   676/ 1097] train: loss: 0.0241920
[Epoch 53; Iter   706/ 1097] train: loss: 0.0187474
[Epoch 53; Iter   736/ 1097] train: loss: 0.0567554
[Epoch 53; Iter   766/ 1097] train: loss: 0.0273986
[Epoch 53; Iter   796/ 1097] train: loss: 0.0450645
[Epoch 53; Iter   826/ 1097] train: loss: 0.1616325
[Epoch 53; Iter   856/ 1097] train: loss: 0.1325440
[Epoch 53; Iter   886/ 1097] train: loss: 0.1029482
[Epoch 53; Iter   916/ 1097] train: loss: 0.0228173
[Epoch 53; Iter   946/ 1097] train: loss: 0.0115608
[Epoch 53; Iter   976/ 1097] train: loss: 0.0211787
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0285540
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0112632
[Epoch 53; Iter  1066/ 1097] train: loss: 0.1603577
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0193485
[Epoch 53] ogbg-molhiv: 0.791771 val loss: 0.099109
[Epoch 53] ogbg-molhiv: 0.742734 test loss: 0.184880
[Epoch 54; Iter    29/ 1097] train: loss: 0.0171523
[Epoch 54; Iter    59/ 1097] train: loss: 0.1081260
[Epoch 54; Iter    89/ 1097] train: loss: 0.0289201
[Epoch 54; Iter   119/ 1097] train: loss: 0.0459175
[Epoch 54; Iter   149/ 1097] train: loss: 0.0660031
[Epoch 54; Iter   179/ 1097] train: loss: 0.0070190
[Epoch 54; Iter   209/ 1097] train: loss: 0.1148547
[Epoch 54; Iter   239/ 1097] train: loss: 0.1393162
[Epoch 54; Iter   269/ 1097] train: loss: 0.1269834
[Epoch 54; Iter   299/ 1097] train: loss: 0.0149723
[Epoch 54; Iter   329/ 1097] train: loss: 0.0136306
[Epoch 54; Iter   359/ 1097] train: loss: 0.0807490
[Epoch 54; Iter   389/ 1097] train: loss: 0.0414792
[Epoch 54; Iter   419/ 1097] train: loss: 0.0562149
[Epoch 54; Iter   449/ 1097] train: loss: 0.0129152
[Epoch 54; Iter   479/ 1097] train: loss: 0.0099905
[Epoch 54; Iter   509/ 1097] train: loss: 0.0157306
[Epoch 54; Iter   539/ 1097] train: loss: 0.1349282
[Epoch 54; Iter   569/ 1097] train: loss: 0.0220615
[Epoch 54; Iter   599/ 1097] train: loss: 0.0174551
[Epoch 54; Iter   629/ 1097] train: loss: 0.0108879
[Epoch 54; Iter   659/ 1097] train: loss: 0.0852290
[Epoch 54; Iter   689/ 1097] train: loss: 0.0104457
[Epoch 54; Iter   719/ 1097] train: loss: 0.0097621
[Epoch 54; Iter   749/ 1097] train: loss: 0.1936446
[Epoch 54; Iter   779/ 1097] train: loss: 0.0643091
[Epoch 54; Iter   809/ 1097] train: loss: 0.4171887
[Epoch 54; Iter   839/ 1097] train: loss: 0.1538609
[Epoch 54; Iter   869/ 1097] train: loss: 0.0225474
[Epoch 54; Iter   899/ 1097] train: loss: 0.0421372
[Epoch 54; Iter   929/ 1097] train: loss: 0.1210276
[Epoch 54; Iter   959/ 1097] train: loss: 0.0192218
[Epoch 54; Iter   989/ 1097] train: loss: 0.2090521
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0515854
[Epoch 54; Iter  1049/ 1097] train: loss: 0.0136388
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0174990
[Epoch 54] ogbg-molhiv: 0.796498 val loss: 0.088789
[Epoch 54] ogbg-molhiv: 0.738226 test loss: 0.149592
[Epoch 55; Iter    12/ 1097] train: loss: 0.0263785
[Epoch 55; Iter    42/ 1097] train: loss: 0.0468576
[Epoch 55; Iter    72/ 1097] train: loss: 0.0316526
[Epoch 55; Iter   102/ 1097] train: loss: 0.0257432
[Epoch 55; Iter   132/ 1097] train: loss: 0.3315198
[Epoch 55; Iter   162/ 1097] train: loss: 0.0461582
[Epoch 55; Iter   192/ 1097] train: loss: 0.0377999
[Epoch 55; Iter   222/ 1097] train: loss: 0.1099842
[Epoch 55; Iter   252/ 1097] train: loss: 0.0317181
[Epoch 55; Iter   282/ 1097] train: loss: 0.1125636
[Epoch 55; Iter   312/ 1097] train: loss: 0.1022282
[Epoch 55; Iter   342/ 1097] train: loss: 0.0865773
[Epoch 55; Iter   372/ 1097] train: loss: 0.0810608
[Epoch 55; Iter   402/ 1097] train: loss: 0.1535337
[Epoch 55; Iter   432/ 1097] train: loss: 0.0125638
[Epoch 55; Iter   462/ 1097] train: loss: 0.0130270
[Epoch 55; Iter   492/ 1097] train: loss: 0.0231774
[Epoch 55; Iter   522/ 1097] train: loss: 0.0492499
[Epoch 55; Iter   552/ 1097] train: loss: 0.0449174
[Epoch 55; Iter   582/ 1097] train: loss: 0.0358805
[Epoch 55; Iter   612/ 1097] train: loss: 0.0314123
[Epoch 55; Iter   642/ 1097] train: loss: 0.0126137
[Epoch 55; Iter   672/ 1097] train: loss: 0.0687392
[Epoch 55; Iter   702/ 1097] train: loss: 0.0395954
[Epoch 55; Iter   732/ 1097] train: loss: 0.0246190
[Epoch 55; Iter   762/ 1097] train: loss: 0.0140167
[Epoch 55; Iter   792/ 1097] train: loss: 0.0468486
[Epoch 55; Iter   822/ 1097] train: loss: 0.1532221
[Epoch 55; Iter   852/ 1097] train: loss: 0.0525963
[Epoch 55; Iter   882/ 1097] train: loss: 0.1750219
[Epoch 55; Iter   912/ 1097] train: loss: 0.0381324
[Epoch 55; Iter   942/ 1097] train: loss: 0.0196334
[Epoch 55; Iter   972/ 1097] train: loss: 0.1084220
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0302651
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0563181
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0680019
[Epoch 55; Iter  1092/ 1097] train: loss: 0.1025870
[Epoch 55] ogbg-molhiv: 0.811238 val loss: 0.084837
[Epoch 55] ogbg-molhiv: 0.754684 test loss: 0.221385
[Epoch 56; Iter    25/ 1097] train: loss: 0.0252607
[Epoch 56; Iter    55/ 1097] train: loss: 0.0214921
[Epoch 56; Iter    85/ 1097] train: loss: 0.0532611
[Epoch 56; Iter   115/ 1097] train: loss: 0.0106008
[Epoch 56; Iter   145/ 1097] train: loss: 0.0194363
[Epoch 56; Iter   175/ 1097] train: loss: 0.0222356
[Epoch 56; Iter   205/ 1097] train: loss: 0.0196342
[Epoch 56; Iter   235/ 1097] train: loss: 0.0189368
[Epoch 56; Iter   265/ 1097] train: loss: 0.0130781
[Epoch 56; Iter   295/ 1097] train: loss: 0.0143418
[Epoch 56; Iter   325/ 1097] train: loss: 0.0137499
[Epoch 56; Iter   355/ 1097] train: loss: 0.0242285
[Epoch 56; Iter   385/ 1097] train: loss: 0.0834130
[Epoch 56; Iter   415/ 1097] train: loss: 0.0617977
[Epoch 56; Iter   445/ 1097] train: loss: 0.1088666
[Epoch 56; Iter   475/ 1097] train: loss: 0.0211728
[Epoch 56; Iter   505/ 1097] train: loss: 0.0903219
[Epoch 56; Iter   535/ 1097] train: loss: 0.0473105
[Epoch 56; Iter   565/ 1097] train: loss: 0.0994115
[Epoch 56; Iter   595/ 1097] train: loss: 0.0870977
[Epoch 56; Iter   625/ 1097] train: loss: 0.0235264
[Epoch 56; Iter   655/ 1097] train: loss: 0.0099135
[Epoch 56; Iter   685/ 1097] train: loss: 0.0116077
[Epoch 56; Iter   715/ 1097] train: loss: 0.0116302
[Epoch 56; Iter   745/ 1097] train: loss: 0.0608847
[Epoch 56; Iter   775/ 1097] train: loss: 0.1567814
[Epoch 56; Iter   805/ 1097] train: loss: 0.0897693
[Epoch 56; Iter   835/ 1097] train: loss: 0.0636398
[Epoch 56; Iter   865/ 1097] train: loss: 0.1109721
[Epoch 56; Iter   895/ 1097] train: loss: 0.1074846
[Epoch 56; Iter   925/ 1097] train: loss: 0.0093514
[Epoch 56; Iter   955/ 1097] train: loss: 0.0381155
[Epoch 56; Iter   985/ 1097] train: loss: 0.0184655
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0287628
[Epoch 55; Iter   180/  960] train: loss: 0.0155957
[Epoch 55; Iter   210/  960] train: loss: 0.0077752
[Epoch 55; Iter   240/  960] train: loss: 0.0254217
[Epoch 55; Iter   270/  960] train: loss: 0.0462837
[Epoch 55; Iter   300/  960] train: loss: 0.0731979
[Epoch 55; Iter   330/  960] train: loss: 0.0091556
[Epoch 55; Iter   360/  960] train: loss: 0.0392966
[Epoch 55; Iter   390/  960] train: loss: 0.0187226
[Epoch 55; Iter   420/  960] train: loss: 0.0326061
[Epoch 55; Iter   450/  960] train: loss: 0.0283445
[Epoch 55; Iter   480/  960] train: loss: 0.0102091
[Epoch 55; Iter   510/  960] train: loss: 0.0443588
[Epoch 55; Iter   540/  960] train: loss: 0.0947748
[Epoch 55; Iter   570/  960] train: loss: 0.2448296
[Epoch 55; Iter   600/  960] train: loss: 0.0109491
[Epoch 55; Iter   630/  960] train: loss: 0.0127346
[Epoch 55; Iter   660/  960] train: loss: 0.1262414
[Epoch 55; Iter   690/  960] train: loss: 0.0153431
[Epoch 55; Iter   720/  960] train: loss: 0.0095782
[Epoch 55; Iter   750/  960] train: loss: 0.0150240
[Epoch 55; Iter   780/  960] train: loss: 0.0135188
[Epoch 55; Iter   810/  960] train: loss: 0.0276313
[Epoch 55; Iter   840/  960] train: loss: 0.0417240
[Epoch 55; Iter   870/  960] train: loss: 0.0250204
[Epoch 55; Iter   900/  960] train: loss: 0.0287559
[Epoch 55; Iter   930/  960] train: loss: 0.0320419
[Epoch 55; Iter   960/  960] train: loss: 0.0213320
[Epoch 55] ogbg-molhiv: 0.753229 val loss: 0.354305
[Epoch 55] ogbg-molhiv: 0.747892 test loss: 0.224119
[Epoch 56; Iter    30/  960] train: loss: 0.0214228
[Epoch 56; Iter    60/  960] train: loss: 0.0300120
[Epoch 56; Iter    90/  960] train: loss: 0.0517325
[Epoch 56; Iter   120/  960] train: loss: 0.0733193
[Epoch 56; Iter   150/  960] train: loss: 0.0155425
[Epoch 56; Iter   180/  960] train: loss: 0.0191053
[Epoch 56; Iter   210/  960] train: loss: 0.0133484
[Epoch 56; Iter   240/  960] train: loss: 0.0200049
[Epoch 56; Iter   270/  960] train: loss: 0.0085585
[Epoch 56; Iter   300/  960] train: loss: 0.0064081
[Epoch 56; Iter   330/  960] train: loss: 0.0192155
[Epoch 56; Iter   360/  960] train: loss: 0.1047772
[Epoch 56; Iter   390/  960] train: loss: 0.1609779
[Epoch 56; Iter   420/  960] train: loss: 0.0060844
[Epoch 56; Iter   450/  960] train: loss: 0.0113477
[Epoch 56; Iter   480/  960] train: loss: 0.0312796
[Epoch 56; Iter   510/  960] train: loss: 0.0477629
[Epoch 56; Iter   540/  960] train: loss: 0.0161547
[Epoch 56; Iter   570/  960] train: loss: 0.0787797
[Epoch 56; Iter   600/  960] train: loss: 0.0242178
[Epoch 56; Iter   630/  960] train: loss: 0.0057548
[Epoch 56; Iter   660/  960] train: loss: 0.0157394
[Epoch 56; Iter   690/  960] train: loss: 0.0288596
[Epoch 56; Iter   720/  960] train: loss: 0.1825532
[Epoch 56; Iter   750/  960] train: loss: 0.0093219
[Epoch 56; Iter   780/  960] train: loss: 0.0360863
[Epoch 56; Iter   810/  960] train: loss: 0.0122316
[Epoch 56; Iter   840/  960] train: loss: 0.0933988
[Epoch 56; Iter   870/  960] train: loss: 0.0141433
[Epoch 56; Iter   900/  960] train: loss: 0.0249397
[Epoch 56; Iter   930/  960] train: loss: 0.0186997
[Epoch 56; Iter   960/  960] train: loss: 0.0463956
[Epoch 56] ogbg-molhiv: 0.758135 val loss: 0.502986
[Epoch 56] ogbg-molhiv: 0.762776 test loss: 0.273531
[Epoch 57; Iter    30/  960] train: loss: 0.0206600
[Epoch 57; Iter    60/  960] train: loss: 0.1691550
[Epoch 57; Iter    90/  960] train: loss: 0.0723661
[Epoch 57; Iter   120/  960] train: loss: 0.0181160
[Epoch 57; Iter   150/  960] train: loss: 0.0211465
[Epoch 57; Iter   180/  960] train: loss: 0.0101312
[Epoch 57; Iter   210/  960] train: loss: 0.0492649
[Epoch 57; Iter   240/  960] train: loss: 0.0134013
[Epoch 57; Iter   270/  960] train: loss: 0.0179481
[Epoch 57; Iter   300/  960] train: loss: 0.0086154
[Epoch 57; Iter   330/  960] train: loss: 0.0301693
[Epoch 57; Iter   360/  960] train: loss: 0.0210808
[Epoch 57; Iter   390/  960] train: loss: 0.1035722
[Epoch 57; Iter   420/  960] train: loss: 0.0173403
[Epoch 57; Iter   450/  960] train: loss: 0.1581656
[Epoch 57; Iter   480/  960] train: loss: 0.0793061
[Epoch 57; Iter   510/  960] train: loss: 0.0256981
[Epoch 57; Iter   540/  960] train: loss: 0.0116953
[Epoch 57; Iter   570/  960] train: loss: 0.0081462
[Epoch 57; Iter   600/  960] train: loss: 0.0317387
[Epoch 57; Iter   630/  960] train: loss: 0.0105411
[Epoch 57; Iter   660/  960] train: loss: 0.0611963
[Epoch 57; Iter   690/  960] train: loss: 0.0164559
[Epoch 57; Iter   720/  960] train: loss: 0.0141119
[Epoch 57; Iter   750/  960] train: loss: 0.0232670
[Epoch 57; Iter   780/  960] train: loss: 0.0743896
[Epoch 57; Iter   810/  960] train: loss: 0.0520245
[Epoch 57; Iter   840/  960] train: loss: 0.0038745
[Epoch 57; Iter   870/  960] train: loss: 0.0357015
[Epoch 57; Iter   900/  960] train: loss: 0.0314182
[Epoch 57; Iter   930/  960] train: loss: 0.0201540
[Epoch 57; Iter   960/  960] train: loss: 0.0055548
[Epoch 57] ogbg-molhiv: 0.762450 val loss: 0.259687
[Epoch 57] ogbg-molhiv: 0.758328 test loss: 0.188923
[Epoch 58; Iter    30/  960] train: loss: 0.0177774
[Epoch 58; Iter    60/  960] train: loss: 0.0168526
[Epoch 58; Iter    90/  960] train: loss: 0.0268127
[Epoch 58; Iter   120/  960] train: loss: 0.0850400
[Epoch 58; Iter   150/  960] train: loss: 0.0263086
[Epoch 58; Iter   180/  960] train: loss: 0.0193106
[Epoch 58; Iter   210/  960] train: loss: 0.0081934
[Epoch 58; Iter   240/  960] train: loss: 0.0037645
[Epoch 58; Iter   270/  960] train: loss: 0.0964118
[Epoch 58; Iter   300/  960] train: loss: 0.0409287
[Epoch 58; Iter   330/  960] train: loss: 0.0342821
[Epoch 58; Iter   360/  960] train: loss: 0.0041462
[Epoch 58; Iter   390/  960] train: loss: 0.0408533
[Epoch 58; Iter   420/  960] train: loss: 0.0386510
[Epoch 58; Iter   450/  960] train: loss: 0.0099209
[Epoch 58; Iter   480/  960] train: loss: 0.0059082
[Epoch 58; Iter   510/  960] train: loss: 0.0186841
[Epoch 58; Iter   540/  960] train: loss: 0.0521229
[Epoch 58; Iter   570/  960] train: loss: 0.0740057
[Epoch 58; Iter   600/  960] train: loss: 0.0636273
[Epoch 58; Iter   630/  960] train: loss: 0.0231548
[Epoch 58; Iter   660/  960] train: loss: 0.0079153
[Epoch 58; Iter   690/  960] train: loss: 0.0389998
[Epoch 58; Iter   720/  960] train: loss: 0.1217294
[Epoch 58; Iter   750/  960] train: loss: 0.0075917
[Epoch 58; Iter   780/  960] train: loss: 0.0066583
[Epoch 58; Iter   810/  960] train: loss: 0.0451604
[Epoch 58; Iter   840/  960] train: loss: 0.0189086
[Epoch 58; Iter   870/  960] train: loss: 0.0029911
[Epoch 58; Iter   900/  960] train: loss: 0.0367041
[Epoch 58; Iter   930/  960] train: loss: 0.0044237
[Epoch 58; Iter   960/  960] train: loss: 0.1208713
[Epoch 58] ogbg-molhiv: 0.763660 val loss: 0.421676
[Epoch 58] ogbg-molhiv: 0.751860 test loss: 0.253925
[Epoch 59; Iter    30/  960] train: loss: 0.0323300
[Epoch 59; Iter    60/  960] train: loss: 0.0707701
[Epoch 59; Iter    90/  960] train: loss: 0.0105183
[Epoch 59; Iter   120/  960] train: loss: 0.0159259
[Epoch 59; Iter   150/  960] train: loss: 0.0054362
[Epoch 59; Iter   180/  960] train: loss: 0.0683917
[Epoch 59; Iter   210/  960] train: loss: 0.0128382
[Epoch 59; Iter   240/  960] train: loss: 0.0056235
[Epoch 59; Iter   270/  960] train: loss: 0.0802582
[Epoch 59; Iter   300/  960] train: loss: 0.0555564
[Epoch 59; Iter   330/  960] train: loss: 0.0605830
[Epoch 59; Iter   360/  960] train: loss: 0.0416502
[Epoch 59; Iter   390/  960] train: loss: 0.0026093
[Epoch 59; Iter   420/  960] train: loss: 0.0230232
[Epoch 59; Iter   450/  960] train: loss: 0.0163428
[Epoch 59; Iter   480/  960] train: loss: 0.0780707
[Epoch 59; Iter   510/  960] train: loss: 0.0498316
[Epoch 59; Iter   540/  960] train: loss: 0.0129635
[Epoch 59; Iter   570/  960] train: loss: 0.1218319
[Epoch 59; Iter   600/  960] train: loss: 0.0171109
[Epoch 59; Iter   630/  960] train: loss: 0.0252875
[Epoch 59; Iter   660/  960] train: loss: 0.0350151
[Epoch 59; Iter   690/  960] train: loss: 0.1465822
[Epoch 59; Iter   720/  960] train: loss: 0.0106883
[Epoch 59; Iter   750/  960] train: loss: 0.0150494
[Epoch 59; Iter   780/  960] train: loss: 0.0077902
[Epoch 55; Iter   180/  960] train: loss: 0.1293999
[Epoch 55; Iter   210/  960] train: loss: 0.0039296
[Epoch 55; Iter   240/  960] train: loss: 0.0051334
[Epoch 55; Iter   270/  960] train: loss: 0.0695451
[Epoch 55; Iter   300/  960] train: loss: 0.0661794
[Epoch 55; Iter   330/  960] train: loss: 0.0133670
[Epoch 55; Iter   360/  960] train: loss: 0.0609923
[Epoch 55; Iter   390/  960] train: loss: 0.0348629
[Epoch 55; Iter   420/  960] train: loss: 0.2535522
[Epoch 55; Iter   450/  960] train: loss: 0.0280304
[Epoch 55; Iter   480/  960] train: loss: 0.1428531
[Epoch 55; Iter   510/  960] train: loss: 0.0164683
[Epoch 55; Iter   540/  960] train: loss: 0.0134706
[Epoch 55; Iter   570/  960] train: loss: 0.1612800
[Epoch 55; Iter   600/  960] train: loss: 0.0084786
[Epoch 55; Iter   630/  960] train: loss: 0.0414580
[Epoch 55; Iter   660/  960] train: loss: 0.0128507
[Epoch 55; Iter   690/  960] train: loss: 0.0325483
[Epoch 55; Iter   720/  960] train: loss: 0.1470030
[Epoch 55; Iter   750/  960] train: loss: 0.1224550
[Epoch 55; Iter   780/  960] train: loss: 0.0397242
[Epoch 55; Iter   810/  960] train: loss: 0.0375305
[Epoch 55; Iter   840/  960] train: loss: 0.0019987
[Epoch 55; Iter   870/  960] train: loss: 0.0038845
[Epoch 55; Iter   900/  960] train: loss: 0.0119068
[Epoch 55; Iter   930/  960] train: loss: 0.0176861
[Epoch 55; Iter   960/  960] train: loss: 0.2016150
[Epoch 55] ogbg-molhiv: 0.729388 val loss: 0.190727
[Epoch 55] ogbg-molhiv: 0.748966 test loss: 0.150587
[Epoch 56; Iter    30/  960] train: loss: 0.0145458
[Epoch 56; Iter    60/  960] train: loss: 0.0457669
[Epoch 56; Iter    90/  960] train: loss: 0.0279597
[Epoch 56; Iter   120/  960] train: loss: 0.0234614
[Epoch 56; Iter   150/  960] train: loss: 0.0028995
[Epoch 56; Iter   180/  960] train: loss: 0.0366238
[Epoch 56; Iter   210/  960] train: loss: 0.0317422
[Epoch 56; Iter   240/  960] train: loss: 0.0224607
[Epoch 56; Iter   270/  960] train: loss: 0.0618856
[Epoch 56; Iter   300/  960] train: loss: 0.0062871
[Epoch 56; Iter   330/  960] train: loss: 0.0194842
[Epoch 56; Iter   360/  960] train: loss: 0.0120894
[Epoch 56; Iter   390/  960] train: loss: 0.2451828
[Epoch 56; Iter   420/  960] train: loss: 0.0144223
[Epoch 56; Iter   450/  960] train: loss: 0.0210495
[Epoch 56; Iter   480/  960] train: loss: 0.0151771
[Epoch 56; Iter   510/  960] train: loss: 0.0420620
[Epoch 56; Iter   540/  960] train: loss: 0.0854752
[Epoch 56; Iter   570/  960] train: loss: 0.0297067
[Epoch 56; Iter   600/  960] train: loss: 0.1432270
[Epoch 56; Iter   630/  960] train: loss: 0.1485288
[Epoch 56; Iter   660/  960] train: loss: 0.0239351
[Epoch 56; Iter   690/  960] train: loss: 0.0070208
[Epoch 56; Iter   720/  960] train: loss: 0.0087526
[Epoch 56; Iter   750/  960] train: loss: 0.0224043
[Epoch 56; Iter   780/  960] train: loss: 0.0290528
[Epoch 56; Iter   810/  960] train: loss: 0.1117264
[Epoch 56; Iter   840/  960] train: loss: 0.0322483
[Epoch 56; Iter   870/  960] train: loss: 0.1344859
[Epoch 56; Iter   900/  960] train: loss: 0.0148972
[Epoch 56; Iter   930/  960] train: loss: 0.0070413
[Epoch 56; Iter   960/  960] train: loss: 0.0089748
[Epoch 56] ogbg-molhiv: 0.711138 val loss: 0.176393
[Epoch 56] ogbg-molhiv: 0.736491 test loss: 0.143946
[Epoch 57; Iter    30/  960] train: loss: 0.0202073
[Epoch 57; Iter    60/  960] train: loss: 0.0950991
[Epoch 57; Iter    90/  960] train: loss: 0.0287249
[Epoch 57; Iter   120/  960] train: loss: 0.0854498
[Epoch 57; Iter   150/  960] train: loss: 0.2234787
[Epoch 57; Iter   180/  960] train: loss: 0.0656377
[Epoch 57; Iter   210/  960] train: loss: 0.0626187
[Epoch 57; Iter   240/  960] train: loss: 0.0112637
[Epoch 57; Iter   270/  960] train: loss: 0.0217087
[Epoch 57; Iter   300/  960] train: loss: 0.0219236
[Epoch 57; Iter   330/  960] train: loss: 0.0095973
[Epoch 57; Iter   360/  960] train: loss: 0.0454182
[Epoch 57; Iter   390/  960] train: loss: 0.0199418
[Epoch 57; Iter   420/  960] train: loss: 0.0034701
[Epoch 57; Iter   450/  960] train: loss: 0.1256869
[Epoch 57; Iter   480/  960] train: loss: 0.0297718
[Epoch 57; Iter   510/  960] train: loss: 0.0353663
[Epoch 57; Iter   540/  960] train: loss: 0.0820489
[Epoch 57; Iter   570/  960] train: loss: 0.0069518
[Epoch 57; Iter   600/  960] train: loss: 0.2325226
[Epoch 57; Iter   630/  960] train: loss: 0.0415031
[Epoch 57; Iter   660/  960] train: loss: 0.0133788
[Epoch 57; Iter   690/  960] train: loss: 0.0629308
[Epoch 57; Iter   720/  960] train: loss: 0.0764409
[Epoch 57; Iter   750/  960] train: loss: 0.0034033
[Epoch 57; Iter   780/  960] train: loss: 0.0133679
[Epoch 57; Iter   810/  960] train: loss: 0.0193859
[Epoch 57; Iter   840/  960] train: loss: 0.0257841
[Epoch 57; Iter   870/  960] train: loss: 0.0071431
[Epoch 57; Iter   900/  960] train: loss: 0.3265117
[Epoch 57; Iter   930/  960] train: loss: 0.0340720
[Epoch 57; Iter   960/  960] train: loss: 0.0041654
[Epoch 57] ogbg-molhiv: 0.717501 val loss: 0.230607
[Epoch 57] ogbg-molhiv: 0.745104 test loss: 0.169130
[Epoch 58; Iter    30/  960] train: loss: 0.0098658
[Epoch 58; Iter    60/  960] train: loss: 0.0068476
[Epoch 58; Iter    90/  960] train: loss: 0.0050130
[Epoch 58; Iter   120/  960] train: loss: 0.1148701
[Epoch 58; Iter   150/  960] train: loss: 0.0488559
[Epoch 58; Iter   180/  960] train: loss: 0.0057227
[Epoch 58; Iter   210/  960] train: loss: 0.0053603
[Epoch 58; Iter   240/  960] train: loss: 0.0103694
[Epoch 58; Iter   270/  960] train: loss: 0.0599185
[Epoch 58; Iter   300/  960] train: loss: 0.0142885
[Epoch 58; Iter   330/  960] train: loss: 0.0092986
[Epoch 58; Iter   360/  960] train: loss: 0.0247326
[Epoch 58; Iter   390/  960] train: loss: 0.0359916
[Epoch 58; Iter   420/  960] train: loss: 0.0140396
[Epoch 58; Iter   450/  960] train: loss: 0.0105063
[Epoch 58; Iter   480/  960] train: loss: 0.0496530
[Epoch 58; Iter   510/  960] train: loss: 0.0709094
[Epoch 58; Iter   540/  960] train: loss: 0.0244116
[Epoch 58; Iter   570/  960] train: loss: 0.0503829
[Epoch 58; Iter   600/  960] train: loss: 0.0132459
[Epoch 58; Iter   630/  960] train: loss: 0.0068725
[Epoch 58; Iter   660/  960] train: loss: 0.1213281
[Epoch 58; Iter   690/  960] train: loss: 0.0163742
[Epoch 58; Iter   720/  960] train: loss: 0.0447984
[Epoch 58; Iter   750/  960] train: loss: 0.0149368
[Epoch 58; Iter   780/  960] train: loss: 0.0022826
[Epoch 58; Iter   810/  960] train: loss: 0.0179583
[Epoch 58; Iter   840/  960] train: loss: 0.0726661
[Epoch 58; Iter   870/  960] train: loss: 0.0256977
[Epoch 58; Iter   900/  960] train: loss: 0.0089800
[Epoch 58; Iter   930/  960] train: loss: 0.0965681
[Epoch 58; Iter   960/  960] train: loss: 0.0135989
[Epoch 58] ogbg-molhiv: 0.715225 val loss: 0.653539
[Epoch 58] ogbg-molhiv: 0.745510 test loss: 0.498210
[Epoch 59; Iter    30/  960] train: loss: 0.2420804
[Epoch 59; Iter    60/  960] train: loss: 0.0135140
[Epoch 59; Iter    90/  960] train: loss: 0.0116845
[Epoch 59; Iter   120/  960] train: loss: 0.0690929
[Epoch 59; Iter   150/  960] train: loss: 0.0283581
[Epoch 59; Iter   180/  960] train: loss: 0.0241709
[Epoch 59; Iter   210/  960] train: loss: 0.1138579
[Epoch 59; Iter   240/  960] train: loss: 0.0081359
[Epoch 59; Iter   270/  960] train: loss: 0.0749495
[Epoch 59; Iter   300/  960] train: loss: 0.0126985
[Epoch 59; Iter   330/  960] train: loss: 0.0034551
[Epoch 59; Iter   360/  960] train: loss: 0.0061273
[Epoch 59; Iter   390/  960] train: loss: 0.0716518
[Epoch 59; Iter   420/  960] train: loss: 0.1415381
[Epoch 59; Iter   450/  960] train: loss: 0.0305027
[Epoch 59; Iter   480/  960] train: loss: 0.0317806
[Epoch 59; Iter   510/  960] train: loss: 0.0125867
[Epoch 59; Iter   540/  960] train: loss: 0.0195659
[Epoch 59; Iter   570/  960] train: loss: 0.0056697
[Epoch 59; Iter   600/  960] train: loss: 0.0352233
[Epoch 59; Iter   630/  960] train: loss: 0.0553022
[Epoch 59; Iter   660/  960] train: loss: 0.0071617
[Epoch 59; Iter   690/  960] train: loss: 0.0397211
[Epoch 59; Iter   720/  960] train: loss: 0.0322855
[Epoch 59; Iter   750/  960] train: loss: 0.0982682
[Epoch 59; Iter   780/  960] train: loss: 0.0557315
[Epoch 55; Iter   180/  960] train: loss: 0.0317191
[Epoch 55; Iter   210/  960] train: loss: 0.0597073
[Epoch 55; Iter   240/  960] train: loss: 0.0795750
[Epoch 55; Iter   270/  960] train: loss: 0.0115595
[Epoch 55; Iter   300/  960] train: loss: 0.0105478
[Epoch 55; Iter   330/  960] train: loss: 0.0654464
[Epoch 55; Iter   360/  960] train: loss: 0.0747414
[Epoch 55; Iter   390/  960] train: loss: 0.0026581
[Epoch 55; Iter   420/  960] train: loss: 0.0611120
[Epoch 55; Iter   450/  960] train: loss: 0.0663520
[Epoch 55; Iter   480/  960] train: loss: 0.0547710
[Epoch 55; Iter   510/  960] train: loss: 0.0019199
[Epoch 55; Iter   540/  960] train: loss: 0.1703106
[Epoch 55; Iter   570/  960] train: loss: 0.0144845
[Epoch 55; Iter   600/  960] train: loss: 0.0319376
[Epoch 55; Iter   630/  960] train: loss: 0.0129911
[Epoch 55; Iter   660/  960] train: loss: 0.0192746
[Epoch 55; Iter   690/  960] train: loss: 0.0113562
[Epoch 55; Iter   720/  960] train: loss: 0.0205887
[Epoch 55; Iter   750/  960] train: loss: 0.0653271
[Epoch 55; Iter   780/  960] train: loss: 0.0250961
[Epoch 55; Iter   810/  960] train: loss: 0.0307522
[Epoch 55; Iter   840/  960] train: loss: 0.0755838
[Epoch 55; Iter   870/  960] train: loss: 0.0162838
[Epoch 55; Iter   900/  960] train: loss: 0.0110806
[Epoch 55; Iter   930/  960] train: loss: 0.0596274
[Epoch 55; Iter   960/  960] train: loss: 0.0775292
[Epoch 55] ogbg-molhiv: 0.728597 val loss: 0.240846
[Epoch 55] ogbg-molhiv: 0.761833 test loss: 0.199670
[Epoch 56; Iter    30/  960] train: loss: 0.0252525
[Epoch 56; Iter    60/  960] train: loss: 0.0382832
[Epoch 56; Iter    90/  960] train: loss: 0.0360063
[Epoch 56; Iter   120/  960] train: loss: 0.0062344
[Epoch 56; Iter   150/  960] train: loss: 0.0258069
[Epoch 56; Iter   180/  960] train: loss: 0.0399786
[Epoch 56; Iter   210/  960] train: loss: 0.0370242
[Epoch 56; Iter   240/  960] train: loss: 0.0764782
[Epoch 56; Iter   270/  960] train: loss: 0.0146409
[Epoch 56; Iter   300/  960] train: loss: 0.1185700
[Epoch 56; Iter   330/  960] train: loss: 0.0569247
[Epoch 56; Iter   360/  960] train: loss: 0.2546732
[Epoch 56; Iter   390/  960] train: loss: 0.0153888
[Epoch 56; Iter   420/  960] train: loss: 0.0974667
[Epoch 56; Iter   450/  960] train: loss: 0.0177278
[Epoch 56; Iter   480/  960] train: loss: 0.0207531
[Epoch 56; Iter   510/  960] train: loss: 0.0175246
[Epoch 56; Iter   540/  960] train: loss: 0.0083122
[Epoch 56; Iter   570/  960] train: loss: 0.0253844
[Epoch 56; Iter   600/  960] train: loss: 0.0201597
[Epoch 56; Iter   630/  960] train: loss: 0.0063633
[Epoch 56; Iter   660/  960] train: loss: 0.0130228
[Epoch 56; Iter   690/  960] train: loss: 0.0635560
[Epoch 56; Iter   720/  960] train: loss: 0.0078487
[Epoch 56; Iter   750/  960] train: loss: 0.0266451
[Epoch 56; Iter   780/  960] train: loss: 0.0468915
[Epoch 56; Iter   810/  960] train: loss: 0.0070926
[Epoch 56; Iter   840/  960] train: loss: 0.0261262
[Epoch 56; Iter   870/  960] train: loss: 0.0882102
[Epoch 56; Iter   900/  960] train: loss: 0.0079369
[Epoch 56; Iter   930/  960] train: loss: 0.0293626
[Epoch 56; Iter   960/  960] train: loss: 0.0057640
[Epoch 56] ogbg-molhiv: 0.731672 val loss: 0.243659
[Epoch 56] ogbg-molhiv: 0.761052 test loss: 0.145037
[Epoch 57; Iter    30/  960] train: loss: 0.0095561
[Epoch 57; Iter    60/  960] train: loss: 0.0079674
[Epoch 57; Iter    90/  960] train: loss: 0.0107363
[Epoch 57; Iter   120/  960] train: loss: 0.1162206
[Epoch 57; Iter   150/  960] train: loss: 0.0161357
[Epoch 57; Iter   180/  960] train: loss: 0.0201090
[Epoch 57; Iter   210/  960] train: loss: 0.0301423
[Epoch 57; Iter   240/  960] train: loss: 0.1736633
[Epoch 57; Iter   270/  960] train: loss: 0.0524262
[Epoch 57; Iter   300/  960] train: loss: 0.0230244
[Epoch 57; Iter   330/  960] train: loss: 0.0064934
[Epoch 57; Iter   360/  960] train: loss: 0.0065684
[Epoch 57; Iter   390/  960] train: loss: 0.0491466
[Epoch 57; Iter   420/  960] train: loss: 0.0248342
[Epoch 57; Iter   450/  960] train: loss: 0.0458615
[Epoch 57; Iter   480/  960] train: loss: 0.1016706
[Epoch 57; Iter   510/  960] train: loss: 0.0083207
[Epoch 57; Iter   540/  960] train: loss: 0.0064840
[Epoch 57; Iter   570/  960] train: loss: 0.0926335
[Epoch 57; Iter   600/  960] train: loss: 0.0023341
[Epoch 57; Iter   630/  960] train: loss: 0.0113609
[Epoch 57; Iter   660/  960] train: loss: 0.0125372
[Epoch 57; Iter   690/  960] train: loss: 0.0145968
[Epoch 57; Iter   720/  960] train: loss: 0.1516756
[Epoch 57; Iter   750/  960] train: loss: 0.1345199
[Epoch 57; Iter   780/  960] train: loss: 0.0291579
[Epoch 57; Iter   810/  960] train: loss: 0.1609048
[Epoch 57; Iter   840/  960] train: loss: 0.1692193
[Epoch 57; Iter   870/  960] train: loss: 0.0031456
[Epoch 57; Iter   900/  960] train: loss: 0.0495168
[Epoch 57; Iter   930/  960] train: loss: 0.0259846
[Epoch 57; Iter   960/  960] train: loss: 0.0400700
[Epoch 57] ogbg-molhiv: 0.732222 val loss: 0.216153
[Epoch 57] ogbg-molhiv: 0.765614 test loss: 0.155861
[Epoch 58; Iter    30/  960] train: loss: 0.0153956
[Epoch 58; Iter    60/  960] train: loss: 0.0157594
[Epoch 58; Iter    90/  960] train: loss: 0.0868071
[Epoch 58; Iter   120/  960] train: loss: 0.1103311
[Epoch 58; Iter   150/  960] train: loss: 0.0354184
[Epoch 58; Iter   180/  960] train: loss: 0.0745056
[Epoch 58; Iter   210/  960] train: loss: 0.0140454
[Epoch 58; Iter   240/  960] train: loss: 0.0281827
[Epoch 58; Iter   270/  960] train: loss: 0.0561743
[Epoch 58; Iter   300/  960] train: loss: 0.0078453
[Epoch 58; Iter   330/  960] train: loss: 0.0972318
[Epoch 58; Iter   360/  960] train: loss: 0.0123395
[Epoch 58; Iter   390/  960] train: loss: 0.0241143
[Epoch 58; Iter   420/  960] train: loss: 0.0685723
[Epoch 58; Iter   450/  960] train: loss: 0.0086178
[Epoch 58; Iter   480/  960] train: loss: 0.0629551
[Epoch 58; Iter   510/  960] train: loss: 0.0033982
[Epoch 58; Iter   540/  960] train: loss: 0.0588487
[Epoch 58; Iter   570/  960] train: loss: 0.0044244
[Epoch 58; Iter   600/  960] train: loss: 0.0422130
[Epoch 58; Iter   630/  960] train: loss: 0.0372684
[Epoch 58; Iter   660/  960] train: loss: 0.0117610
[Epoch 58; Iter   690/  960] train: loss: 0.0586119
[Epoch 58; Iter   720/  960] train: loss: 0.0173160
[Epoch 58; Iter   750/  960] train: loss: 0.0163956
[Epoch 58; Iter   780/  960] train: loss: 0.0416421
[Epoch 58; Iter   810/  960] train: loss: 0.0186913
[Epoch 58; Iter   840/  960] train: loss: 0.0269292
[Epoch 58; Iter   870/  960] train: loss: 0.0059621
[Epoch 58; Iter   900/  960] train: loss: 0.0107959
[Epoch 58; Iter   930/  960] train: loss: 0.0149116
[Epoch 58; Iter   960/  960] train: loss: 0.0039115
[Epoch 58] ogbg-molhiv: 0.736337 val loss: 0.193419
[Epoch 58] ogbg-molhiv: 0.742816 test loss: 0.160016
[Epoch 59; Iter    30/  960] train: loss: 0.0193928
[Epoch 59; Iter    60/  960] train: loss: 0.0640472
[Epoch 59; Iter    90/  960] train: loss: 0.0130423
[Epoch 59; Iter   120/  960] train: loss: 0.0052627
[Epoch 59; Iter   150/  960] train: loss: 0.0036931
[Epoch 59; Iter   180/  960] train: loss: 0.0371486
[Epoch 59; Iter   210/  960] train: loss: 0.0883704
[Epoch 59; Iter   240/  960] train: loss: 0.0904674
[Epoch 59; Iter   270/  960] train: loss: 0.0725892
[Epoch 59; Iter   300/  960] train: loss: 0.0083075
[Epoch 59; Iter   330/  960] train: loss: 0.0225628
[Epoch 59; Iter   360/  960] train: loss: 0.0062290
[Epoch 59; Iter   390/  960] train: loss: 0.0350659
[Epoch 59; Iter   420/  960] train: loss: 0.2067527
[Epoch 59; Iter   450/  960] train: loss: 0.0757111
[Epoch 59; Iter   480/  960] train: loss: 0.0046536
[Epoch 59; Iter   510/  960] train: loss: 0.0416493
[Epoch 59; Iter   540/  960] train: loss: 0.0223704
[Epoch 59; Iter   570/  960] train: loss: 0.0016920
[Epoch 59; Iter   600/  960] train: loss: 0.0285510
[Epoch 59; Iter   630/  960] train: loss: 0.1284649
[Epoch 59; Iter   660/  960] train: loss: 0.0329661
[Epoch 59; Iter   690/  960] train: loss: 0.0596761
[Epoch 59; Iter   720/  960] train: loss: 0.0068195
[Epoch 59; Iter   750/  960] train: loss: 0.0367637
[Epoch 59; Iter   780/  960] train: loss: 0.0311022
[Epoch 52; Iter   963/ 1097] train: loss: 0.0256526
[Epoch 52; Iter   993/ 1097] train: loss: 0.0095834
[Epoch 52; Iter  1023/ 1097] train: loss: 0.0162180
[Epoch 52; Iter  1053/ 1097] train: loss: 0.0183020
[Epoch 52; Iter  1083/ 1097] train: loss: 0.1035882
[Epoch 52] ogbg-molhiv: 0.819236 val loss: 0.087685
[Epoch 52] ogbg-molhiv: 0.765092 test loss: 0.357233
[Epoch 53; Iter    16/ 1097] train: loss: 0.0408223
[Epoch 53; Iter    46/ 1097] train: loss: 0.0073586
[Epoch 53; Iter    76/ 1097] train: loss: 0.0163570
[Epoch 53; Iter   106/ 1097] train: loss: 0.1023809
[Epoch 53; Iter   136/ 1097] train: loss: 0.0145823
[Epoch 53; Iter   166/ 1097] train: loss: 0.0115552
[Epoch 53; Iter   196/ 1097] train: loss: 0.0235558
[Epoch 53; Iter   226/ 1097] train: loss: 0.0185503
[Epoch 53; Iter   256/ 1097] train: loss: 0.0298512
[Epoch 53; Iter   286/ 1097] train: loss: 0.0839550
[Epoch 53; Iter   316/ 1097] train: loss: 0.0394599
[Epoch 53; Iter   346/ 1097] train: loss: 0.0204331
[Epoch 53; Iter   376/ 1097] train: loss: 0.0134947
[Epoch 53; Iter   406/ 1097] train: loss: 0.0159567
[Epoch 53; Iter   436/ 1097] train: loss: 0.0556767
[Epoch 53; Iter   466/ 1097] train: loss: 0.0980769
[Epoch 53; Iter   496/ 1097] train: loss: 0.0197258
[Epoch 53; Iter   526/ 1097] train: loss: 0.0815934
[Epoch 53; Iter   556/ 1097] train: loss: 0.0356531
[Epoch 53; Iter   586/ 1097] train: loss: 0.0293166
[Epoch 53; Iter   616/ 1097] train: loss: 0.0362847
[Epoch 53; Iter   646/ 1097] train: loss: 0.0257656
[Epoch 53; Iter   676/ 1097] train: loss: 0.3402141
[Epoch 53; Iter   706/ 1097] train: loss: 0.1753612
[Epoch 53; Iter   736/ 1097] train: loss: 0.0881855
[Epoch 53; Iter   766/ 1097] train: loss: 0.0439003
[Epoch 53; Iter   796/ 1097] train: loss: 0.0360216
[Epoch 53; Iter   826/ 1097] train: loss: 0.0577131
[Epoch 53; Iter   856/ 1097] train: loss: 0.0116407
[Epoch 53; Iter   886/ 1097] train: loss: 0.0178857
[Epoch 53; Iter   916/ 1097] train: loss: 0.0047844
[Epoch 53; Iter   946/ 1097] train: loss: 0.1419322
[Epoch 53; Iter   976/ 1097] train: loss: 0.0038692
[Epoch 53; Iter  1006/ 1097] train: loss: 0.0073034
[Epoch 53; Iter  1036/ 1097] train: loss: 0.0149786
[Epoch 53; Iter  1066/ 1097] train: loss: 0.0101297
[Epoch 53; Iter  1096/ 1097] train: loss: 0.0592030
[Epoch 53] ogbg-molhiv: 0.805540 val loss: 0.085373
[Epoch 53] ogbg-molhiv: 0.769957 test loss: 0.152700
[Epoch 54; Iter    29/ 1097] train: loss: 0.0047401
[Epoch 54; Iter    59/ 1097] train: loss: 0.0068807
[Epoch 54; Iter    89/ 1097] train: loss: 0.0056617
[Epoch 54; Iter   119/ 1097] train: loss: 0.0903273
[Epoch 54; Iter   149/ 1097] train: loss: 0.0290391
[Epoch 54; Iter   179/ 1097] train: loss: 0.0174866
[Epoch 54; Iter   209/ 1097] train: loss: 0.0218563
[Epoch 54; Iter   239/ 1097] train: loss: 0.0734641
[Epoch 54; Iter   269/ 1097] train: loss: 0.0152498
[Epoch 54; Iter   299/ 1097] train: loss: 0.0302558
[Epoch 54; Iter   329/ 1097] train: loss: 0.0154267
[Epoch 54; Iter   359/ 1097] train: loss: 0.0321081
[Epoch 54; Iter   389/ 1097] train: loss: 0.1718673
[Epoch 54; Iter   419/ 1097] train: loss: 0.0272085
[Epoch 54; Iter   449/ 1097] train: loss: 0.0903741
[Epoch 54; Iter   479/ 1097] train: loss: 0.0105144
[Epoch 54; Iter   509/ 1097] train: loss: 0.0296301
[Epoch 54; Iter   539/ 1097] train: loss: 0.2075832
[Epoch 54; Iter   569/ 1097] train: loss: 0.0282681
[Epoch 54; Iter   599/ 1097] train: loss: 0.0911131
[Epoch 54; Iter   629/ 1097] train: loss: 0.0481522
[Epoch 54; Iter   659/ 1097] train: loss: 0.2289411
[Epoch 54; Iter   689/ 1097] train: loss: 0.0638503
[Epoch 54; Iter   719/ 1097] train: loss: 0.0124330
[Epoch 54; Iter   749/ 1097] train: loss: 0.0166458
[Epoch 54; Iter   779/ 1097] train: loss: 0.0399949
[Epoch 54; Iter   809/ 1097] train: loss: 0.0504425
[Epoch 54; Iter   839/ 1097] train: loss: 0.0120670
[Epoch 54; Iter   869/ 1097] train: loss: 0.0070110
[Epoch 54; Iter   899/ 1097] train: loss: 0.0192392
[Epoch 54; Iter   929/ 1097] train: loss: 0.0041171
[Epoch 54; Iter   959/ 1097] train: loss: 0.0352365
[Epoch 54; Iter   989/ 1097] train: loss: 0.1523745
[Epoch 54; Iter  1019/ 1097] train: loss: 0.0240144
[Epoch 54; Iter  1049/ 1097] train: loss: 0.1155518
[Epoch 54; Iter  1079/ 1097] train: loss: 0.0081190
[Epoch 54] ogbg-molhiv: 0.794327 val loss: 0.100225
[Epoch 54] ogbg-molhiv: 0.736181 test loss: 0.164468
[Epoch 55; Iter    12/ 1097] train: loss: 0.0156796
[Epoch 55; Iter    42/ 1097] train: loss: 0.0045483
[Epoch 55; Iter    72/ 1097] train: loss: 0.0586026
[Epoch 55; Iter   102/ 1097] train: loss: 0.0120447
[Epoch 55; Iter   132/ 1097] train: loss: 0.0221935
[Epoch 55; Iter   162/ 1097] train: loss: 0.0928673
[Epoch 55; Iter   192/ 1097] train: loss: 0.0273773
[Epoch 55; Iter   222/ 1097] train: loss: 0.0156472
[Epoch 55; Iter   252/ 1097] train: loss: 0.0069992
[Epoch 55; Iter   282/ 1097] train: loss: 0.0075303
[Epoch 55; Iter   312/ 1097] train: loss: 0.0041407
[Epoch 55; Iter   342/ 1097] train: loss: 0.0237919
[Epoch 55; Iter   372/ 1097] train: loss: 0.0474365
[Epoch 55; Iter   402/ 1097] train: loss: 0.0275828
[Epoch 55; Iter   432/ 1097] train: loss: 0.0131393
[Epoch 55; Iter   462/ 1097] train: loss: 0.0084091
[Epoch 55; Iter   492/ 1097] train: loss: 0.0611091
[Epoch 55; Iter   522/ 1097] train: loss: 0.0066811
[Epoch 55; Iter   552/ 1097] train: loss: 0.0201063
[Epoch 55; Iter   582/ 1097] train: loss: 0.1374830
[Epoch 55; Iter   612/ 1097] train: loss: 0.0077876
[Epoch 55; Iter   642/ 1097] train: loss: 0.1188531
[Epoch 55; Iter   672/ 1097] train: loss: 0.1192718
[Epoch 55; Iter   702/ 1097] train: loss: 0.0768881
[Epoch 55; Iter   732/ 1097] train: loss: 0.0276351
[Epoch 55; Iter   762/ 1097] train: loss: 0.0515609
[Epoch 55; Iter   792/ 1097] train: loss: 0.0189165
[Epoch 55; Iter   822/ 1097] train: loss: 0.1242368
[Epoch 55; Iter   852/ 1097] train: loss: 0.0393092
[Epoch 55; Iter   882/ 1097] train: loss: 0.0254083
[Epoch 55; Iter   912/ 1097] train: loss: 0.0195179
[Epoch 55; Iter   942/ 1097] train: loss: 0.2783920
[Epoch 55; Iter   972/ 1097] train: loss: 0.1281141
[Epoch 55; Iter  1002/ 1097] train: loss: 0.0215188
[Epoch 55; Iter  1032/ 1097] train: loss: 0.0717622
[Epoch 55; Iter  1062/ 1097] train: loss: 0.0758559
[Epoch 55; Iter  1092/ 1097] train: loss: 0.0092816
[Epoch 55] ogbg-molhiv: 0.806275 val loss: 0.088785
[Epoch 55] ogbg-molhiv: 0.765565 test loss: 0.162600
[Epoch 56; Iter    25/ 1097] train: loss: 0.0348856
[Epoch 56; Iter    55/ 1097] train: loss: 0.0716172
[Epoch 56; Iter    85/ 1097] train: loss: 0.0205051
[Epoch 56; Iter   115/ 1097] train: loss: 0.0109942
[Epoch 56; Iter   145/ 1097] train: loss: 0.0110968
[Epoch 56; Iter   175/ 1097] train: loss: 0.0323547
[Epoch 56; Iter   205/ 1097] train: loss: 0.1316014
[Epoch 56; Iter   235/ 1097] train: loss: 0.0484230
[Epoch 56; Iter   265/ 1097] train: loss: 0.0639510
[Epoch 56; Iter   295/ 1097] train: loss: 0.0317012
[Epoch 56; Iter   325/ 1097] train: loss: 0.0085205
[Epoch 56; Iter   355/ 1097] train: loss: 0.0070782
[Epoch 56; Iter   385/ 1097] train: loss: 0.0256318
[Epoch 56; Iter   415/ 1097] train: loss: 0.0779787
[Epoch 56; Iter   445/ 1097] train: loss: 0.0286547
[Epoch 56; Iter   475/ 1097] train: loss: 0.0069980
[Epoch 56; Iter   505/ 1097] train: loss: 0.0042428
[Epoch 56; Iter   535/ 1097] train: loss: 0.0072847
[Epoch 56; Iter   565/ 1097] train: loss: 0.0817473
[Epoch 56; Iter   595/ 1097] train: loss: 0.1631627
[Epoch 56; Iter   625/ 1097] train: loss: 0.0702164
[Epoch 56; Iter   655/ 1097] train: loss: 0.0185051
[Epoch 56; Iter   685/ 1097] train: loss: 0.1407629
[Epoch 56; Iter   715/ 1097] train: loss: 0.1182260
[Epoch 56; Iter   745/ 1097] train: loss: 0.0091820
[Epoch 56; Iter   775/ 1097] train: loss: 0.0048367
[Epoch 56; Iter   805/ 1097] train: loss: 0.0144122
[Epoch 56; Iter   835/ 1097] train: loss: 0.0786742
[Epoch 56; Iter   865/ 1097] train: loss: 0.0594481
[Epoch 56; Iter   895/ 1097] train: loss: 0.0857423
[Epoch 56; Iter   925/ 1097] train: loss: 0.1063052
[Epoch 56; Iter   955/ 1097] train: loss: 0.0516364
[Epoch 56; Iter   985/ 1097] train: loss: 0.0222245
[Epoch 56; Iter  1015/ 1097] train: loss: 0.0257488
[Epoch 58; Iter   189/  823] train: loss: 0.0109797
[Epoch 58; Iter   219/  823] train: loss: 0.0380342
[Epoch 58; Iter   249/  823] train: loss: 0.0144816
[Epoch 58; Iter   279/  823] train: loss: 0.0471942
[Epoch 58; Iter   309/  823] train: loss: 0.1236131
[Epoch 58; Iter   339/  823] train: loss: 0.0189210
[Epoch 58; Iter   369/  823] train: loss: 0.3725582
[Epoch 58; Iter   399/  823] train: loss: 0.1555871
[Epoch 58; Iter   429/  823] train: loss: 0.0118398
[Epoch 58; Iter   459/  823] train: loss: 0.0255664
[Epoch 58; Iter   489/  823] train: loss: 0.0621502
[Epoch 58; Iter   519/  823] train: loss: 0.0143143
[Epoch 58; Iter   549/  823] train: loss: 0.0312686
[Epoch 58; Iter   579/  823] train: loss: 0.1178100
[Epoch 58; Iter   609/  823] train: loss: 0.0245408
[Epoch 58; Iter   639/  823] train: loss: 0.0452436
[Epoch 58; Iter   669/  823] train: loss: 0.0419718
[Epoch 58; Iter   699/  823] train: loss: 0.0455620
[Epoch 58; Iter   729/  823] train: loss: 0.0240696
[Epoch 58; Iter   759/  823] train: loss: 0.0219752
[Epoch 58; Iter   789/  823] train: loss: 0.0718856
[Epoch 58; Iter   819/  823] train: loss: 0.0817477
[Epoch 58] ogbg-molhiv: 0.734499 val loss: 0.187528
[Epoch 58] ogbg-molhiv: 0.757553 test loss: 0.257512
[Epoch 59; Iter    26/  823] train: loss: 0.0791452
[Epoch 59; Iter    56/  823] train: loss: 0.0462970
[Epoch 59; Iter    86/  823] train: loss: 0.0561284
[Epoch 59; Iter   116/  823] train: loss: 0.0779423
[Epoch 59; Iter   146/  823] train: loss: 0.0040490
[Epoch 59; Iter   176/  823] train: loss: 0.1322397
[Epoch 59; Iter   206/  823] train: loss: 0.1116437
[Epoch 59; Iter   236/  823] train: loss: 0.0399867
[Epoch 59; Iter   266/  823] train: loss: 0.0466428
[Epoch 59; Iter   296/  823] train: loss: 0.1915634
[Epoch 59; Iter   326/  823] train: loss: 0.0324640
[Epoch 59; Iter   356/  823] train: loss: 0.1087172
[Epoch 59; Iter   386/  823] train: loss: 0.0135648
[Epoch 59; Iter   416/  823] train: loss: 0.1885219
[Epoch 59; Iter   446/  823] train: loss: 0.1475008
[Epoch 59; Iter   476/  823] train: loss: 0.0103514
[Epoch 59; Iter   506/  823] train: loss: 0.0203620
[Epoch 59; Iter   536/  823] train: loss: 0.0611111
[Epoch 59; Iter   566/  823] train: loss: 0.1111640
[Epoch 59; Iter   596/  823] train: loss: 0.0668805
[Epoch 59; Iter   626/  823] train: loss: 0.1188534
[Epoch 59; Iter   656/  823] train: loss: 0.0754935
[Epoch 59; Iter   686/  823] train: loss: 0.1501159
[Epoch 59; Iter   716/  823] train: loss: 0.1801839
[Epoch 59; Iter   746/  823] train: loss: 0.0387390
[Epoch 59; Iter   776/  823] train: loss: 0.0113094
[Epoch 59; Iter   806/  823] train: loss: 0.0062259
[Epoch 59] ogbg-molhiv: 0.724747 val loss: 0.284974
[Epoch 59] ogbg-molhiv: 0.754769 test loss: 0.450315
[Epoch 60; Iter    13/  823] train: loss: 0.0263958
[Epoch 60; Iter    43/  823] train: loss: 0.2116412
[Epoch 60; Iter    73/  823] train: loss: 0.1395368
[Epoch 60; Iter   103/  823] train: loss: 0.0122665
[Epoch 60; Iter   133/  823] train: loss: 0.0251510
[Epoch 60; Iter   163/  823] train: loss: 0.0260062
[Epoch 60; Iter   193/  823] train: loss: 0.0579152
[Epoch 60; Iter   223/  823] train: loss: 0.0645300
[Epoch 60; Iter   253/  823] train: loss: 0.0153916
[Epoch 60; Iter   283/  823] train: loss: 0.0281597
[Epoch 60; Iter   313/  823] train: loss: 0.0843275
[Epoch 60; Iter   343/  823] train: loss: 0.1021988
[Epoch 60; Iter   373/  823] train: loss: 0.0341638
[Epoch 60; Iter   403/  823] train: loss: 0.0263680
[Epoch 60; Iter   433/  823] train: loss: 0.0800461
[Epoch 60; Iter   463/  823] train: loss: 0.0848559
[Epoch 60; Iter   493/  823] train: loss: 0.0093628
[Epoch 60; Iter   523/  823] train: loss: 0.0234411
[Epoch 60; Iter   553/  823] train: loss: 0.3772850
[Epoch 60; Iter   583/  823] train: loss: 0.0827374
[Epoch 60; Iter   613/  823] train: loss: 0.0909925
[Epoch 60; Iter   643/  823] train: loss: 0.0146213
[Epoch 60; Iter   673/  823] train: loss: 0.0139508
[Epoch 60; Iter   703/  823] train: loss: 0.0096331
[Epoch 60; Iter   733/  823] train: loss: 0.0472576
[Epoch 60; Iter   763/  823] train: loss: 0.0101760
[Epoch 60; Iter   793/  823] train: loss: 0.0092766
[Epoch 60; Iter   823/  823] train: loss: 0.2355340
[Epoch 60] ogbg-molhiv: 0.728769 val loss: 0.207458
[Epoch 60] ogbg-molhiv: 0.764468 test loss: 0.323288
[Epoch 61; Iter    30/  823] train: loss: 0.1285140
[Epoch 61; Iter    60/  823] train: loss: 0.0071710
[Epoch 61; Iter    90/  823] train: loss: 0.0618265
[Epoch 61; Iter   120/  823] train: loss: 0.0386567
[Epoch 61; Iter   150/  823] train: loss: 0.1413093
[Epoch 61; Iter   180/  823] train: loss: 0.0044611
[Epoch 61; Iter   210/  823] train: loss: 0.0676348
[Epoch 61; Iter   240/  823] train: loss: 0.0444380
[Epoch 61; Iter   270/  823] train: loss: 0.0780058
[Epoch 61; Iter   300/  823] train: loss: 0.0226784
[Epoch 61; Iter   330/  823] train: loss: 0.0194905
[Epoch 61; Iter   360/  823] train: loss: 0.0074283
[Epoch 61; Iter   390/  823] train: loss: 0.0462555
[Epoch 61; Iter   420/  823] train: loss: 0.1517974
[Epoch 61; Iter   450/  823] train: loss: 0.0199776
[Epoch 61; Iter   480/  823] train: loss: 0.0132880
[Epoch 61; Iter   510/  823] train: loss: 0.0067912
[Epoch 61; Iter   540/  823] train: loss: 0.0177179
[Epoch 61; Iter   570/  823] train: loss: 0.0189423
[Epoch 61; Iter   600/  823] train: loss: 0.0660350
[Epoch 61; Iter   630/  823] train: loss: 0.1079371
[Epoch 61; Iter   660/  823] train: loss: 0.0584388
[Epoch 61; Iter   690/  823] train: loss: 0.0628021
[Epoch 61; Iter   720/  823] train: loss: 0.0287071
[Epoch 61; Iter   750/  823] train: loss: 0.0102969
[Epoch 61; Iter   780/  823] train: loss: 0.0109650
[Epoch 61; Iter   810/  823] train: loss: 0.0070405
[Epoch 61] ogbg-molhiv: 0.737682 val loss: 0.196105
[Epoch 61] ogbg-molhiv: 0.762311 test loss: 0.324090
[Epoch 62; Iter    17/  823] train: loss: 0.1831201
[Epoch 62; Iter    47/  823] train: loss: 0.0323030
[Epoch 62; Iter    77/  823] train: loss: 0.0251224
[Epoch 62; Iter   107/  823] train: loss: 0.0580804
[Epoch 62; Iter   137/  823] train: loss: 0.0194016
[Epoch 62; Iter   167/  823] train: loss: 0.0122011
[Epoch 62; Iter   197/  823] train: loss: 0.0078299
[Epoch 62; Iter   227/  823] train: loss: 0.0221406
[Epoch 62; Iter   257/  823] train: loss: 0.0402758
[Epoch 62; Iter   287/  823] train: loss: 0.0117629
[Epoch 62; Iter   317/  823] train: loss: 0.0202910
[Epoch 62; Iter   347/  823] train: loss: 0.0280677
[Epoch 62; Iter   377/  823] train: loss: 0.0210596
[Epoch 62; Iter   407/  823] train: loss: 0.1225993
[Epoch 62; Iter   437/  823] train: loss: 0.0449350
[Epoch 62; Iter   467/  823] train: loss: 0.0212267
[Epoch 62; Iter   497/  823] train: loss: 0.0087463
[Epoch 62; Iter   527/  823] train: loss: 0.0415705
[Epoch 62; Iter   557/  823] train: loss: 0.0058781
[Epoch 62; Iter   587/  823] train: loss: 0.0124469
[Epoch 62; Iter   617/  823] train: loss: 0.0352210
[Epoch 62; Iter   647/  823] train: loss: 0.0238295
[Epoch 62; Iter   677/  823] train: loss: 0.1626131
[Epoch 62; Iter   707/  823] train: loss: 0.0223238
[Epoch 62; Iter   737/  823] train: loss: 0.0350766
[Epoch 62; Iter   767/  823] train: loss: 0.0192712
[Epoch 62; Iter   797/  823] train: loss: 0.0300582
[Epoch 62] ogbg-molhiv: 0.730033 val loss: 0.235906
[Epoch 62] ogbg-molhiv: 0.743414 test loss: 0.347814
[Epoch 63; Iter     4/  823] train: loss: 0.1008681
[Epoch 63; Iter    34/  823] train: loss: 0.0138015
[Epoch 63; Iter    64/  823] train: loss: 0.0306046
[Epoch 63; Iter    94/  823] train: loss: 0.0292780
[Epoch 63; Iter   124/  823] train: loss: 0.0091546
[Epoch 63; Iter   154/  823] train: loss: 0.0466690
[Epoch 63; Iter   184/  823] train: loss: 0.0361606
[Epoch 63; Iter   214/  823] train: loss: 0.0345676
[Epoch 63; Iter   244/  823] train: loss: 0.0112355
[Epoch 63; Iter   274/  823] train: loss: 0.0929674
[Epoch 63; Iter   304/  823] train: loss: 0.0539499
[Epoch 63; Iter   334/  823] train: loss: 0.0691412
[Epoch 63; Iter   364/  823] train: loss: 0.0975408
[Epoch 63; Iter   394/  823] train: loss: 0.0298801
[Epoch 63; Iter   424/  823] train: loss: 0.1610721
[Epoch 63; Iter   454/  823] train: loss: 0.0170951
[Epoch 58; Iter   189/  823] train: loss: 0.0326652
[Epoch 58; Iter   219/  823] train: loss: 0.0115695
[Epoch 58; Iter   249/  823] train: loss: 0.0218850
[Epoch 58; Iter   279/  823] train: loss: 0.0368560
[Epoch 58; Iter   309/  823] train: loss: 0.0066024
[Epoch 58; Iter   339/  823] train: loss: 0.0371217
[Epoch 58; Iter   369/  823] train: loss: 0.0078559
[Epoch 58; Iter   399/  823] train: loss: 0.0232107
[Epoch 58; Iter   429/  823] train: loss: 0.1103409
[Epoch 58; Iter   459/  823] train: loss: 0.1312868
[Epoch 58; Iter   489/  823] train: loss: 0.0097152
[Epoch 58; Iter   519/  823] train: loss: 0.0254988
[Epoch 58; Iter   549/  823] train: loss: 0.0135088
[Epoch 58; Iter   579/  823] train: loss: 0.0331677
[Epoch 58; Iter   609/  823] train: loss: 0.0429737
[Epoch 58; Iter   639/  823] train: loss: 0.0058004
[Epoch 58; Iter   669/  823] train: loss: 0.0289541
[Epoch 58; Iter   699/  823] train: loss: 0.1228012
[Epoch 58; Iter   729/  823] train: loss: 0.0050753
[Epoch 58; Iter   759/  823] train: loss: 0.0178580
[Epoch 58; Iter   789/  823] train: loss: 0.0312207
[Epoch 58; Iter   819/  823] train: loss: 0.0117731
[Epoch 58] ogbg-molhiv: 0.703444 val loss: 0.234599
[Epoch 58] ogbg-molhiv: 0.745196 test loss: 0.178419
[Epoch 59; Iter    26/  823] train: loss: 0.0211022
[Epoch 59; Iter    56/  823] train: loss: 0.0673423
[Epoch 59; Iter    86/  823] train: loss: 0.0304931
[Epoch 59; Iter   116/  823] train: loss: 0.1043442
[Epoch 59; Iter   146/  823] train: loss: 0.0162380
[Epoch 59; Iter   176/  823] train: loss: 0.0315188
[Epoch 59; Iter   206/  823] train: loss: 0.0628639
[Epoch 59; Iter   236/  823] train: loss: 0.0041618
[Epoch 59; Iter   266/  823] train: loss: 0.0558766
[Epoch 59; Iter   296/  823] train: loss: 0.0067647
[Epoch 59; Iter   326/  823] train: loss: 0.0095308
[Epoch 59; Iter   356/  823] train: loss: 0.0630575
[Epoch 59; Iter   386/  823] train: loss: 0.0192604
[Epoch 59; Iter   416/  823] train: loss: 0.0086625
[Epoch 59; Iter   446/  823] train: loss: 0.1287854
[Epoch 59; Iter   476/  823] train: loss: 0.1185740
[Epoch 59; Iter   506/  823] train: loss: 0.0085174
[Epoch 59; Iter   536/  823] train: loss: 0.0363159
[Epoch 59; Iter   566/  823] train: loss: 0.0028345
[Epoch 59; Iter   596/  823] train: loss: 0.0234899
[Epoch 59; Iter   626/  823] train: loss: 0.1080056
[Epoch 59; Iter   656/  823] train: loss: 0.0187475
[Epoch 59; Iter   686/  823] train: loss: 0.0412839
[Epoch 59; Iter   716/  823] train: loss: 0.0036279
[Epoch 59; Iter   746/  823] train: loss: 0.0301708
[Epoch 59; Iter   776/  823] train: loss: 0.0489672
[Epoch 59; Iter   806/  823] train: loss: 0.0105724
[Epoch 59] ogbg-molhiv: 0.703276 val loss: 0.238161
[Epoch 59] ogbg-molhiv: 0.747131 test loss: 0.173320
[Epoch 60; Iter    13/  823] train: loss: 0.0288531
[Epoch 60; Iter    43/  823] train: loss: 0.0301082
[Epoch 60; Iter    73/  823] train: loss: 0.0042478
[Epoch 60; Iter   103/  823] train: loss: 0.0321749
[Epoch 60; Iter   133/  823] train: loss: 0.0137110
[Epoch 60; Iter   163/  823] train: loss: 0.0771322
[Epoch 60; Iter   193/  823] train: loss: 0.0129304
[Epoch 60; Iter   223/  823] train: loss: 0.1101468
[Epoch 60; Iter   253/  823] train: loss: 0.0188536
[Epoch 60; Iter   283/  823] train: loss: 0.0117101
[Epoch 60; Iter   313/  823] train: loss: 0.0690994
[Epoch 60; Iter   343/  823] train: loss: 0.0045818
[Epoch 60; Iter   373/  823] train: loss: 0.0078865
[Epoch 60; Iter   403/  823] train: loss: 0.0255740
[Epoch 60; Iter   433/  823] train: loss: 0.0101555
[Epoch 60; Iter   463/  823] train: loss: 0.0120695
[Epoch 60; Iter   493/  823] train: loss: 0.0049359
[Epoch 60; Iter   523/  823] train: loss: 0.2387662
[Epoch 60; Iter   553/  823] train: loss: 0.0315022
[Epoch 60; Iter   583/  823] train: loss: 0.0036825
[Epoch 60; Iter   613/  823] train: loss: 0.0716447
[Epoch 60; Iter   643/  823] train: loss: 0.0208770
[Epoch 60; Iter   673/  823] train: loss: 0.0356353
[Epoch 60; Iter   703/  823] train: loss: 0.0298061
[Epoch 60; Iter   733/  823] train: loss: 0.0036464
[Epoch 60; Iter   763/  823] train: loss: 0.0069727
[Epoch 60; Iter   793/  823] train: loss: 0.0293987
[Epoch 60; Iter   823/  823] train: loss: 0.0109140
[Epoch 60] ogbg-molhiv: 0.705568 val loss: 0.268135
[Epoch 60] ogbg-molhiv: 0.754117 test loss: 0.180324
[Epoch 61; Iter    30/  823] train: loss: 0.0038777
[Epoch 61; Iter    60/  823] train: loss: 0.0661150
[Epoch 61; Iter    90/  823] train: loss: 0.0517174
[Epoch 61; Iter   120/  823] train: loss: 0.0170351
[Epoch 61; Iter   150/  823] train: loss: 0.0379973
[Epoch 61; Iter   180/  823] train: loss: 0.0109687
[Epoch 61; Iter   210/  823] train: loss: 0.0545340
[Epoch 61; Iter   240/  823] train: loss: 0.0462790
[Epoch 61; Iter   270/  823] train: loss: 0.0682406
[Epoch 61; Iter   300/  823] train: loss: 0.0208652
[Epoch 61; Iter   330/  823] train: loss: 0.0659687
[Epoch 61; Iter   360/  823] train: loss: 0.2390210
[Epoch 61; Iter   390/  823] train: loss: 0.0082229
[Epoch 61; Iter   420/  823] train: loss: 0.0186293
[Epoch 61; Iter   450/  823] train: loss: 0.0253344
[Epoch 61; Iter   480/  823] train: loss: 0.0428643
[Epoch 61; Iter   510/  823] train: loss: 0.0250692
[Epoch 61; Iter   540/  823] train: loss: 0.0234856
[Epoch 61; Iter   570/  823] train: loss: 0.0114608
[Epoch 61; Iter   600/  823] train: loss: 0.0047915
[Epoch 61; Iter   630/  823] train: loss: 0.0046435
[Epoch 61; Iter   660/  823] train: loss: 0.1182664
[Epoch 61; Iter   690/  823] train: loss: 0.0490961
[Epoch 61; Iter   720/  823] train: loss: 0.1298229
[Epoch 61; Iter   750/  823] train: loss: 0.0016026
[Epoch 61; Iter   780/  823] train: loss: 0.0071551
[Epoch 61; Iter   810/  823] train: loss: 0.0133663
[Epoch 61] ogbg-molhiv: 0.710159 val loss: 0.278278
[Epoch 61] ogbg-molhiv: 0.751117 test loss: 0.170410
[Epoch 62; Iter    17/  823] train: loss: 0.0206970
[Epoch 62; Iter    47/  823] train: loss: 0.0201006
[Epoch 62; Iter    77/  823] train: loss: 0.0248839
[Epoch 62; Iter   107/  823] train: loss: 0.0173657
[Epoch 62; Iter   137/  823] train: loss: 0.0029603
[Epoch 62; Iter   167/  823] train: loss: 0.0029968
[Epoch 62; Iter   197/  823] train: loss: 0.0749432
[Epoch 62; Iter   227/  823] train: loss: 0.0210252
[Epoch 62; Iter   257/  823] train: loss: 0.0171320
[Epoch 62; Iter   287/  823] train: loss: 0.0084049
[Epoch 62; Iter   317/  823] train: loss: 0.0167090
[Epoch 62; Iter   347/  823] train: loss: 0.0471319
[Epoch 62; Iter   377/  823] train: loss: 0.0119669
[Epoch 62; Iter   407/  823] train: loss: 0.0049282
[Epoch 62; Iter   437/  823] train: loss: 0.0216172
[Epoch 62; Iter   467/  823] train: loss: 0.0249254
[Epoch 62; Iter   497/  823] train: loss: 0.0301549
[Epoch 62; Iter   527/  823] train: loss: 0.0088460
[Epoch 62; Iter   557/  823] train: loss: 0.0205973
[Epoch 62; Iter   587/  823] train: loss: 0.0047260
[Epoch 62; Iter   617/  823] train: loss: 0.0146389
[Epoch 62; Iter   647/  823] train: loss: 0.0069283
[Epoch 62; Iter   677/  823] train: loss: 0.0275218
[Epoch 62; Iter   707/  823] train: loss: 0.0076762
[Epoch 62; Iter   737/  823] train: loss: 0.0899395
[Epoch 62; Iter   767/  823] train: loss: 0.0585084
[Epoch 62; Iter   797/  823] train: loss: 0.0889401
[Epoch 62] ogbg-molhiv: 0.706109 val loss: 0.273948
[Epoch 62] ogbg-molhiv: 0.753102 test loss: 0.176065
[Epoch 63; Iter     4/  823] train: loss: 0.0057521
[Epoch 63; Iter    34/  823] train: loss: 0.0050876
[Epoch 63; Iter    64/  823] train: loss: 0.0163235
[Epoch 63; Iter    94/  823] train: loss: 0.0069734
[Epoch 63; Iter   124/  823] train: loss: 0.0241406
[Epoch 63; Iter   154/  823] train: loss: 0.0335335
[Epoch 63; Iter   184/  823] train: loss: 0.0043074
[Epoch 63; Iter   214/  823] train: loss: 0.0022154
[Epoch 63; Iter   244/  823] train: loss: 0.0050561
[Epoch 63; Iter   274/  823] train: loss: 0.0046582
[Epoch 63; Iter   304/  823] train: loss: 0.0748200
[Epoch 63; Iter   334/  823] train: loss: 0.0108278
[Epoch 63; Iter   364/  823] train: loss: 0.0465101
[Epoch 63; Iter   394/  823] train: loss: 0.0063629
[Epoch 63; Iter   424/  823] train: loss: 0.0136030
[Epoch 63; Iter   454/  823] train: loss: 0.0572329
[Epoch 58; Iter   189/  823] train: loss: 0.0026219
[Epoch 58; Iter   219/  823] train: loss: 0.1418712
[Epoch 58; Iter   249/  823] train: loss: 0.0753606
[Epoch 58; Iter   279/  823] train: loss: 0.0100676
[Epoch 58; Iter   309/  823] train: loss: 0.0553801
[Epoch 58; Iter   339/  823] train: loss: 0.0117066
[Epoch 58; Iter   369/  823] train: loss: 0.0554251
[Epoch 58; Iter   399/  823] train: loss: 0.0309177
[Epoch 58; Iter   429/  823] train: loss: 0.0153107
[Epoch 58; Iter   459/  823] train: loss: 0.0153399
[Epoch 58; Iter   489/  823] train: loss: 0.0697561
[Epoch 58; Iter   519/  823] train: loss: 0.0115235
[Epoch 58; Iter   549/  823] train: loss: 0.0097280
[Epoch 58; Iter   579/  823] train: loss: 0.0219715
[Epoch 58; Iter   609/  823] train: loss: 0.0192692
[Epoch 58; Iter   639/  823] train: loss: 0.0198074
[Epoch 58; Iter   669/  823] train: loss: 0.1840321
[Epoch 58; Iter   699/  823] train: loss: 0.0070811
[Epoch 58; Iter   729/  823] train: loss: 0.0125383
[Epoch 58; Iter   759/  823] train: loss: 0.0295119
[Epoch 58; Iter   789/  823] train: loss: 0.0754999
[Epoch 58; Iter   819/  823] train: loss: 0.1072305
[Epoch 58] ogbg-molhiv: 0.719492 val loss: 0.212949
[Epoch 58] ogbg-molhiv: 0.748968 test loss: 0.147553
[Epoch 59; Iter    26/  823] train: loss: 0.0360178
[Epoch 59; Iter    56/  823] train: loss: 0.0152756
[Epoch 59; Iter    86/  823] train: loss: 0.0251879
[Epoch 59; Iter   116/  823] train: loss: 0.0031976
[Epoch 59; Iter   146/  823] train: loss: 0.0211527
[Epoch 59; Iter   176/  823] train: loss: 0.0165258
[Epoch 59; Iter   206/  823] train: loss: 0.0272860
[Epoch 59; Iter   236/  823] train: loss: 0.0176559
[Epoch 59; Iter   266/  823] train: loss: 0.0174288
[Epoch 59; Iter   296/  823] train: loss: 0.0808214
[Epoch 59; Iter   326/  823] train: loss: 0.0100516
[Epoch 59; Iter   356/  823] train: loss: 0.2270373
[Epoch 59; Iter   386/  823] train: loss: 0.0046339
[Epoch 59; Iter   416/  823] train: loss: 0.2603456
[Epoch 59; Iter   446/  823] train: loss: 0.0203972
[Epoch 59; Iter   476/  823] train: loss: 0.0224498
[Epoch 59; Iter   506/  823] train: loss: 0.0626417
[Epoch 59; Iter   536/  823] train: loss: 0.0055057
[Epoch 59; Iter   566/  823] train: loss: 0.0296480
[Epoch 59; Iter   596/  823] train: loss: 0.0247578
[Epoch 59; Iter   626/  823] train: loss: 0.0142843
[Epoch 59; Iter   656/  823] train: loss: 0.0317200
[Epoch 59; Iter   686/  823] train: loss: 0.0018915
[Epoch 59; Iter   716/  823] train: loss: 0.0030857
[Epoch 59; Iter   746/  823] train: loss: 0.0011827
[Epoch 59; Iter   776/  823] train: loss: 0.0054593
[Epoch 59; Iter   806/  823] train: loss: 0.0128185
[Epoch 59] ogbg-molhiv: 0.718083 val loss: 0.199544
[Epoch 59] ogbg-molhiv: 0.760032 test loss: 0.131965
[Epoch 60; Iter    13/  823] train: loss: 0.0112958
[Epoch 60; Iter    43/  823] train: loss: 0.0044674
[Epoch 60; Iter    73/  823] train: loss: 0.0662607
[Epoch 60; Iter   103/  823] train: loss: 0.0527520
[Epoch 60; Iter   133/  823] train: loss: 0.0059415
[Epoch 60; Iter   163/  823] train: loss: 0.0097717
[Epoch 60; Iter   193/  823] train: loss: 0.0019953
[Epoch 60; Iter   223/  823] train: loss: 0.0305053
[Epoch 60; Iter   253/  823] train: loss: 0.0207603
[Epoch 60; Iter   283/  823] train: loss: 0.0031196
[Epoch 60; Iter   313/  823] train: loss: 0.0618629
[Epoch 60; Iter   343/  823] train: loss: 0.1422111
[Epoch 60; Iter   373/  823] train: loss: 0.0368507
[Epoch 60; Iter   403/  823] train: loss: 0.0034414
[Epoch 60; Iter   433/  823] train: loss: 0.0196091
[Epoch 60; Iter   463/  823] train: loss: 0.0498039
[Epoch 60; Iter   493/  823] train: loss: 0.0052579
[Epoch 60; Iter   523/  823] train: loss: 0.0305934
[Epoch 60; Iter   553/  823] train: loss: 0.0311200
[Epoch 60; Iter   583/  823] train: loss: 0.0354157
[Epoch 60; Iter   613/  823] train: loss: 0.0276231
[Epoch 60; Iter   643/  823] train: loss: 0.0256032
[Epoch 60; Iter   673/  823] train: loss: 0.0063811
[Epoch 60; Iter   703/  823] train: loss: 0.0581695
[Epoch 60; Iter   733/  823] train: loss: 0.0345084
[Epoch 60; Iter   763/  823] train: loss: 0.0324178
[Epoch 60; Iter   793/  823] train: loss: 0.0057059
[Epoch 60; Iter   823/  823] train: loss: 0.0123453
[Epoch 60] ogbg-molhiv: 0.733625 val loss: 0.234412
[Epoch 60] ogbg-molhiv: 0.750803 test loss: 0.179759
[Epoch 61; Iter    30/  823] train: loss: 0.0134287
[Epoch 61; Iter    60/  823] train: loss: 0.0087145
[Epoch 61; Iter    90/  823] train: loss: 0.0675784
[Epoch 61; Iter   120/  823] train: loss: 0.0125304
[Epoch 61; Iter   150/  823] train: loss: 0.0580966
[Epoch 61; Iter   180/  823] train: loss: 0.0062453
[Epoch 61; Iter   210/  823] train: loss: 0.0171963
[Epoch 61; Iter   240/  823] train: loss: 0.0480475
[Epoch 61; Iter   270/  823] train: loss: 0.2058930
[Epoch 61; Iter   300/  823] train: loss: 0.0562463
[Epoch 61; Iter   330/  823] train: loss: 0.0038897
[Epoch 61; Iter   360/  823] train: loss: 0.0181011
[Epoch 61; Iter   390/  823] train: loss: 0.0289682
[Epoch 61; Iter   420/  823] train: loss: 0.0909846
[Epoch 61; Iter   450/  823] train: loss: 0.0748912
[Epoch 61; Iter   480/  823] train: loss: 0.0963922
[Epoch 61; Iter   510/  823] train: loss: 0.0102394
[Epoch 61; Iter   540/  823] train: loss: 0.1491441
[Epoch 61; Iter   570/  823] train: loss: 0.0044263
[Epoch 61; Iter   600/  823] train: loss: 0.0204021
[Epoch 61; Iter   630/  823] train: loss: 0.0059831
[Epoch 61; Iter   660/  823] train: loss: 0.0238506
[Epoch 61; Iter   690/  823] train: loss: 0.0037631
[Epoch 61; Iter   720/  823] train: loss: 0.1417527
[Epoch 61; Iter   750/  823] train: loss: 0.0874063
[Epoch 61; Iter   780/  823] train: loss: 0.0665318
[Epoch 61; Iter   810/  823] train: loss: 0.0127826
[Epoch 61] ogbg-molhiv: 0.736153 val loss: 0.210415
[Epoch 61] ogbg-molhiv: 0.765438 test loss: 0.140095
[Epoch 62; Iter    17/  823] train: loss: 0.2246256
[Epoch 62; Iter    47/  823] train: loss: 0.0222193
[Epoch 62; Iter    77/  823] train: loss: 0.0030727
[Epoch 62; Iter   107/  823] train: loss: 0.0067357
[Epoch 62; Iter   137/  823] train: loss: 0.0362448
[Epoch 62; Iter   167/  823] train: loss: 0.0037291
[Epoch 62; Iter   197/  823] train: loss: 0.0164472
[Epoch 62; Iter   227/  823] train: loss: 0.0338709
[Epoch 62; Iter   257/  823] train: loss: 0.0043388
[Epoch 62; Iter   287/  823] train: loss: 0.0113969
[Epoch 62; Iter   317/  823] train: loss: 0.1189510
[Epoch 62; Iter   347/  823] train: loss: 0.0065042
[Epoch 62; Iter   377/  823] train: loss: 0.0568314
[Epoch 62; Iter   407/  823] train: loss: 0.0245543
[Epoch 62; Iter   437/  823] train: loss: 0.0053527
[Epoch 62; Iter   467/  823] train: loss: 0.0277199
[Epoch 62; Iter   497/  823] train: loss: 0.1810693
[Epoch 62; Iter   527/  823] train: loss: 0.0325667
[Epoch 62; Iter   557/  823] train: loss: 0.0296740
[Epoch 62; Iter   587/  823] train: loss: 0.0019455
[Epoch 62; Iter   617/  823] train: loss: 0.1233277
[Epoch 62; Iter   647/  823] train: loss: 0.0201247
[Epoch 62; Iter   677/  823] train: loss: 0.0044810
[Epoch 62; Iter   707/  823] train: loss: 0.0462275
[Epoch 62; Iter   737/  823] train: loss: 0.0051449
[Epoch 62; Iter   767/  823] train: loss: 0.2228679
[Epoch 62; Iter   797/  823] train: loss: 0.0717438
[Epoch 62] ogbg-molhiv: 0.724778 val loss: 0.274021
[Epoch 62] ogbg-molhiv: 0.742673 test loss: 0.195881
[Epoch 63; Iter     4/  823] train: loss: 0.0023123
[Epoch 63; Iter    34/  823] train: loss: 0.0051569
[Epoch 63; Iter    64/  823] train: loss: 0.0917553
[Epoch 63; Iter    94/  823] train: loss: 0.0445561
[Epoch 63; Iter   124/  823] train: loss: 0.0241591
[Epoch 63; Iter   154/  823] train: loss: 0.0097215
[Epoch 63; Iter   184/  823] train: loss: 0.0145769
[Epoch 63; Iter   214/  823] train: loss: 0.0200817
[Epoch 63; Iter   244/  823] train: loss: 0.0098313
[Epoch 63; Iter   274/  823] train: loss: 0.0527195
[Epoch 63; Iter   304/  823] train: loss: 0.0076614
[Epoch 63; Iter   334/  823] train: loss: 0.0225692
[Epoch 63; Iter   364/  823] train: loss: 0.0024549
[Epoch 63; Iter   394/  823] train: loss: 0.0238116
[Epoch 63; Iter   424/  823] train: loss: 0.0075159
[Epoch 63; Iter   454/  823] train: loss: 0.1084231
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0965565
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0315370
[Epoch 56] ogbg-molhiv: 0.762471 val loss: 0.143636
[Epoch 56] ogbg-molhiv: 0.730476 test loss: 0.364740
[Epoch 57; Iter     8/ 1097] train: loss: 0.0263502
[Epoch 57; Iter    38/ 1097] train: loss: 0.1115427
[Epoch 57; Iter    68/ 1097] train: loss: 0.0872303
[Epoch 57; Iter    98/ 1097] train: loss: 0.0436115
[Epoch 57; Iter   128/ 1097] train: loss: 0.0941907
[Epoch 57; Iter   158/ 1097] train: loss: 0.0344795
[Epoch 57; Iter   188/ 1097] train: loss: 0.0488889
[Epoch 57; Iter   218/ 1097] train: loss: 0.0227920
[Epoch 57; Iter   248/ 1097] train: loss: 0.0276512
[Epoch 57; Iter   278/ 1097] train: loss: 0.0047130
[Epoch 57; Iter   308/ 1097] train: loss: 0.1671971
[Epoch 57; Iter   338/ 1097] train: loss: 0.0596396
[Epoch 57; Iter   368/ 1097] train: loss: 0.0562907
[Epoch 57; Iter   398/ 1097] train: loss: 0.0524304
[Epoch 57; Iter   428/ 1097] train: loss: 0.0635175
[Epoch 57; Iter   458/ 1097] train: loss: 0.0346269
[Epoch 57; Iter   488/ 1097] train: loss: 0.0239497
[Epoch 57; Iter   518/ 1097] train: loss: 0.2019928
[Epoch 57; Iter   548/ 1097] train: loss: 0.0124393
[Epoch 57; Iter   578/ 1097] train: loss: 0.0227362
[Epoch 57; Iter   608/ 1097] train: loss: 0.3378644
[Epoch 57; Iter   638/ 1097] train: loss: 0.3266383
[Epoch 57; Iter   668/ 1097] train: loss: 0.0128968
[Epoch 57; Iter   698/ 1097] train: loss: 0.3618132
[Epoch 57; Iter   728/ 1097] train: loss: 0.0292850
[Epoch 57; Iter   758/ 1097] train: loss: 0.1779204
[Epoch 57; Iter   788/ 1097] train: loss: 0.0057799
[Epoch 57; Iter   818/ 1097] train: loss: 0.0158987
[Epoch 57; Iter   848/ 1097] train: loss: 0.0344766
[Epoch 57; Iter   878/ 1097] train: loss: 0.0121203
[Epoch 57; Iter   908/ 1097] train: loss: 0.1562971
[Epoch 57; Iter   938/ 1097] train: loss: 0.0265419
[Epoch 57; Iter   968/ 1097] train: loss: 0.1210802
[Epoch 57; Iter   998/ 1097] train: loss: 0.0173046
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0271838
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0183201
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0698413
[Epoch 57] ogbg-molhiv: 0.750799 val loss: 0.147356
[Epoch 57] ogbg-molhiv: 0.718496 test loss: 0.378613
[Epoch 58; Iter    21/ 1097] train: loss: 0.0110972
[Epoch 58; Iter    51/ 1097] train: loss: 0.0207207
[Epoch 58; Iter    81/ 1097] train: loss: 0.0146985
[Epoch 58; Iter   111/ 1097] train: loss: 0.0170093
[Epoch 58; Iter   141/ 1097] train: loss: 0.0988666
[Epoch 58; Iter   171/ 1097] train: loss: 0.0086067
[Epoch 58; Iter   201/ 1097] train: loss: 0.1181301
[Epoch 58; Iter   231/ 1097] train: loss: 0.1437379
[Epoch 58; Iter   261/ 1097] train: loss: 0.0474696
[Epoch 58; Iter   291/ 1097] train: loss: 0.0255080
[Epoch 58; Iter   321/ 1097] train: loss: 0.0184247
[Epoch 58; Iter   351/ 1097] train: loss: 0.0279935
[Epoch 58; Iter   381/ 1097] train: loss: 0.0439742
[Epoch 58; Iter   411/ 1097] train: loss: 0.0272623
[Epoch 58; Iter   441/ 1097] train: loss: 0.0416415
[Epoch 58; Iter   471/ 1097] train: loss: 0.0047402
[Epoch 58; Iter   501/ 1097] train: loss: 0.0357293
[Epoch 58; Iter   531/ 1097] train: loss: 0.0386576
[Epoch 58; Iter   561/ 1097] train: loss: 0.0105914
[Epoch 58; Iter   591/ 1097] train: loss: 0.1399840
[Epoch 58; Iter   621/ 1097] train: loss: 0.0122756
[Epoch 58; Iter   651/ 1097] train: loss: 0.0541771
[Epoch 58; Iter   681/ 1097] train: loss: 0.0596362
[Epoch 58; Iter   711/ 1097] train: loss: 0.0283055
[Epoch 58; Iter   741/ 1097] train: loss: 0.0143618
[Epoch 58; Iter   771/ 1097] train: loss: 0.0972903
[Epoch 58; Iter   801/ 1097] train: loss: 0.0069314
[Epoch 58; Iter   831/ 1097] train: loss: 0.0069873
[Epoch 58; Iter   861/ 1097] train: loss: 0.0643722
[Epoch 58; Iter   891/ 1097] train: loss: 0.0163909
[Epoch 58; Iter   921/ 1097] train: loss: 0.1427244
[Epoch 58; Iter   951/ 1097] train: loss: 0.0974141
[Epoch 58; Iter   981/ 1097] train: loss: 0.0321826
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0091439
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0071597
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0270995
[Epoch 58] ogbg-molhiv: 0.757036 val loss: 0.142081
[Epoch 58] ogbg-molhiv: 0.727642 test loss: 0.356778
[Epoch 59; Iter     4/ 1097] train: loss: 0.0373293
[Epoch 59; Iter    34/ 1097] train: loss: 0.0159110
[Epoch 59; Iter    64/ 1097] train: loss: 0.0248365
[Epoch 59; Iter    94/ 1097] train: loss: 0.1874303
[Epoch 59; Iter   124/ 1097] train: loss: 0.0059188
[Epoch 59; Iter   154/ 1097] train: loss: 0.0748857
[Epoch 59; Iter   184/ 1097] train: loss: 0.0223338
[Epoch 59; Iter   214/ 1097] train: loss: 0.0212303
[Epoch 59; Iter   244/ 1097] train: loss: 0.0319087
[Epoch 59; Iter   274/ 1097] train: loss: 0.0053814
[Epoch 59; Iter   304/ 1097] train: loss: 0.2831253
[Epoch 59; Iter   334/ 1097] train: loss: 0.0062753
[Epoch 59; Iter   364/ 1097] train: loss: 0.0207047
[Epoch 59; Iter   394/ 1097] train: loss: 0.0089764
[Epoch 59; Iter   424/ 1097] train: loss: 0.0792820
[Epoch 59; Iter   454/ 1097] train: loss: 0.0316517
[Epoch 59; Iter   484/ 1097] train: loss: 0.0054225
[Epoch 59; Iter   514/ 1097] train: loss: 0.0152291
[Epoch 59; Iter   544/ 1097] train: loss: 0.0144054
[Epoch 59; Iter   574/ 1097] train: loss: 0.0540759
[Epoch 59; Iter   604/ 1097] train: loss: 0.0176741
[Epoch 59; Iter   634/ 1097] train: loss: 0.0605124
[Epoch 59; Iter   664/ 1097] train: loss: 0.0077773
[Epoch 59; Iter   694/ 1097] train: loss: 0.0396690
[Epoch 59; Iter   724/ 1097] train: loss: 0.2221793
[Epoch 59; Iter   754/ 1097] train: loss: 0.0329350
[Epoch 59; Iter   784/ 1097] train: loss: 0.0039576
[Epoch 59; Iter   814/ 1097] train: loss: 0.1243905
[Epoch 59; Iter   844/ 1097] train: loss: 0.0383586
[Epoch 59; Iter   874/ 1097] train: loss: 0.0584508
[Epoch 59; Iter   904/ 1097] train: loss: 0.1324361
[Epoch 59; Iter   934/ 1097] train: loss: 0.1488825
[Epoch 59; Iter   964/ 1097] train: loss: 0.0477132
[Epoch 59; Iter   994/ 1097] train: loss: 0.0148775
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0137287
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0039894
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0619571
[Epoch 59] ogbg-molhiv: 0.732994 val loss: 0.165189
[Epoch 59] ogbg-molhiv: 0.717297 test loss: 0.385204
[Epoch 60; Iter    17/ 1097] train: loss: 0.0581936
[Epoch 60; Iter    47/ 1097] train: loss: 0.0230697
[Epoch 60; Iter    77/ 1097] train: loss: 0.0266476
[Epoch 60; Iter   107/ 1097] train: loss: 0.0799643
[Epoch 60; Iter   137/ 1097] train: loss: 0.0470522
[Epoch 60; Iter   167/ 1097] train: loss: 0.0036684
[Epoch 60; Iter   197/ 1097] train: loss: 0.0132311
[Epoch 60; Iter   227/ 1097] train: loss: 0.0106275
[Epoch 60; Iter   257/ 1097] train: loss: 0.0987787
[Epoch 60; Iter   287/ 1097] train: loss: 0.0543743
[Epoch 60; Iter   317/ 1097] train: loss: 0.0099279
[Epoch 60; Iter   347/ 1097] train: loss: 0.0325737
[Epoch 60; Iter   377/ 1097] train: loss: 0.1152737
[Epoch 60; Iter   407/ 1097] train: loss: 0.0198815
[Epoch 60; Iter   437/ 1097] train: loss: 0.0617335
[Epoch 60; Iter   467/ 1097] train: loss: 0.0499308
[Epoch 60; Iter   497/ 1097] train: loss: 0.0065647
[Epoch 60; Iter   527/ 1097] train: loss: 0.0083055
[Epoch 60; Iter   557/ 1097] train: loss: 0.0555700
[Epoch 60; Iter   587/ 1097] train: loss: 0.0760913
[Epoch 60; Iter   617/ 1097] train: loss: 0.0159671
[Epoch 60; Iter   647/ 1097] train: loss: 0.1333752
[Epoch 60; Iter   677/ 1097] train: loss: 0.0558326
[Epoch 60; Iter   707/ 1097] train: loss: 0.0101887
[Epoch 60; Iter   737/ 1097] train: loss: 0.0208927
[Epoch 60; Iter   767/ 1097] train: loss: 0.0585257
[Epoch 60; Iter   797/ 1097] train: loss: 0.0103482
[Epoch 60; Iter   827/ 1097] train: loss: 0.0123669
[Epoch 60; Iter   857/ 1097] train: loss: 0.0461483
[Epoch 60; Iter   887/ 1097] train: loss: 0.1085816
[Epoch 60; Iter   917/ 1097] train: loss: 0.0281869
[Epoch 60; Iter   947/ 1097] train: loss: 0.0389445
[Epoch 60; Iter   977/ 1097] train: loss: 0.0055363
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0469980
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0607232
[Epoch 60; Iter  1067/ 1097] train: loss: 0.1667248
[Epoch 60; Iter  1097/ 1097] train: loss: 0.2446963
[Epoch 56; Iter  1045/ 1097] train: loss: 0.2627880
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0154446
[Epoch 56] ogbg-molhiv: 0.795696 val loss: 0.090512
[Epoch 56] ogbg-molhiv: 0.734311 test loss: 0.144292
[Epoch 57; Iter     8/ 1097] train: loss: 0.1078146
[Epoch 57; Iter    38/ 1097] train: loss: 0.0542470
[Epoch 57; Iter    68/ 1097] train: loss: 0.0441344
[Epoch 57; Iter    98/ 1097] train: loss: 0.0998661
[Epoch 57; Iter   128/ 1097] train: loss: 0.0287288
[Epoch 57; Iter   158/ 1097] train: loss: 0.0229800
[Epoch 57; Iter   188/ 1097] train: loss: 0.0397304
[Epoch 57; Iter   218/ 1097] train: loss: 0.0113196
[Epoch 57; Iter   248/ 1097] train: loss: 0.0116927
[Epoch 57; Iter   278/ 1097] train: loss: 0.0211393
[Epoch 57; Iter   308/ 1097] train: loss: 0.0384412
[Epoch 57; Iter   338/ 1097] train: loss: 0.0198064
[Epoch 57; Iter   368/ 1097] train: loss: 0.0391809
[Epoch 57; Iter   398/ 1097] train: loss: 0.0453441
[Epoch 57; Iter   428/ 1097] train: loss: 0.0175449
[Epoch 57; Iter   458/ 1097] train: loss: 0.0198941
[Epoch 57; Iter   488/ 1097] train: loss: 0.0151208
[Epoch 57; Iter   518/ 1097] train: loss: 0.0154343
[Epoch 57; Iter   548/ 1097] train: loss: 0.1007150
[Epoch 57; Iter   578/ 1097] train: loss: 0.2463481
[Epoch 57; Iter   608/ 1097] train: loss: 0.1210161
[Epoch 57; Iter   638/ 1097] train: loss: 0.0093800
[Epoch 57; Iter   668/ 1097] train: loss: 0.1140867
[Epoch 57; Iter   698/ 1097] train: loss: 0.0249638
[Epoch 57; Iter   728/ 1097] train: loss: 0.0402848
[Epoch 57; Iter   758/ 1097] train: loss: 0.0097036
[Epoch 57; Iter   788/ 1097] train: loss: 0.1797809
[Epoch 57; Iter   818/ 1097] train: loss: 0.0266293
[Epoch 57; Iter   848/ 1097] train: loss: 0.1600167
[Epoch 57; Iter   878/ 1097] train: loss: 0.0184792
[Epoch 57; Iter   908/ 1097] train: loss: 0.0233910
[Epoch 57; Iter   938/ 1097] train: loss: 0.0245104
[Epoch 57; Iter   968/ 1097] train: loss: 0.0507683
[Epoch 57; Iter   998/ 1097] train: loss: 0.1102656
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0553031
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0345108
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0069098
[Epoch 57] ogbg-molhiv: 0.804417 val loss: 0.096716
[Epoch 57] ogbg-molhiv: 0.738543 test loss: 0.153935
[Epoch 58; Iter    21/ 1097] train: loss: 0.0535254
[Epoch 58; Iter    51/ 1097] train: loss: 0.0099534
[Epoch 58; Iter    81/ 1097] train: loss: 0.0134933
[Epoch 58; Iter   111/ 1097] train: loss: 0.0189588
[Epoch 58; Iter   141/ 1097] train: loss: 0.0226768
[Epoch 58; Iter   171/ 1097] train: loss: 0.0578252
[Epoch 58; Iter   201/ 1097] train: loss: 0.0338082
[Epoch 58; Iter   231/ 1097] train: loss: 0.1020689
[Epoch 58; Iter   261/ 1097] train: loss: 0.0189773
[Epoch 58; Iter   291/ 1097] train: loss: 0.0151956
[Epoch 58; Iter   321/ 1097] train: loss: 0.0276175
[Epoch 58; Iter   351/ 1097] train: loss: 0.1846041
[Epoch 58; Iter   381/ 1097] train: loss: 0.2079583
[Epoch 58; Iter   411/ 1097] train: loss: 0.0372164
[Epoch 58; Iter   441/ 1097] train: loss: 0.0560700
[Epoch 58; Iter   471/ 1097] train: loss: 0.1538550
[Epoch 58; Iter   501/ 1097] train: loss: 0.0133310
[Epoch 58; Iter   531/ 1097] train: loss: 0.0110455
[Epoch 58; Iter   561/ 1097] train: loss: 0.0410538
[Epoch 58; Iter   591/ 1097] train: loss: 0.0204560
[Epoch 58; Iter   621/ 1097] train: loss: 0.0849794
[Epoch 58; Iter   651/ 1097] train: loss: 0.0352376
[Epoch 58; Iter   681/ 1097] train: loss: 0.0113543
[Epoch 58; Iter   711/ 1097] train: loss: 0.3773001
[Epoch 58; Iter   741/ 1097] train: loss: 0.0156912
[Epoch 58; Iter   771/ 1097] train: loss: 0.0483523
[Epoch 58; Iter   801/ 1097] train: loss: 0.0173427
[Epoch 58; Iter   831/ 1097] train: loss: 0.0501063
[Epoch 58; Iter   861/ 1097] train: loss: 0.0114877
[Epoch 58; Iter   891/ 1097] train: loss: 0.0060953
[Epoch 58; Iter   921/ 1097] train: loss: 0.0173268
[Epoch 58; Iter   951/ 1097] train: loss: 0.0170759
[Epoch 58; Iter   981/ 1097] train: loss: 0.0744769
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0239706
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0319493
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0696220
[Epoch 58] ogbg-molhiv: 0.806434 val loss: 0.091129
[Epoch 58] ogbg-molhiv: 0.753697 test loss: 0.144375
[Epoch 59; Iter     4/ 1097] train: loss: 0.0788753
[Epoch 59; Iter    34/ 1097] train: loss: 0.0346765
[Epoch 59; Iter    64/ 1097] train: loss: 0.0561925
[Epoch 59; Iter    94/ 1097] train: loss: 0.1646018
[Epoch 59; Iter   124/ 1097] train: loss: 0.0225909
[Epoch 59; Iter   154/ 1097] train: loss: 0.0177312
[Epoch 59; Iter   184/ 1097] train: loss: 0.0067163
[Epoch 59; Iter   214/ 1097] train: loss: 0.0147344
[Epoch 59; Iter   244/ 1097] train: loss: 0.0138766
[Epoch 59; Iter   274/ 1097] train: loss: 0.0151759
[Epoch 59; Iter   304/ 1097] train: loss: 0.0529513
[Epoch 59; Iter   334/ 1097] train: loss: 0.1367289
[Epoch 59; Iter   364/ 1097] train: loss: 0.1953055
[Epoch 59; Iter   394/ 1097] train: loss: 0.0102913
[Epoch 59; Iter   424/ 1097] train: loss: 0.0139970
[Epoch 59; Iter   454/ 1097] train: loss: 0.0161680
[Epoch 59; Iter   484/ 1097] train: loss: 0.1642503
[Epoch 59; Iter   514/ 1097] train: loss: 0.0698501
[Epoch 59; Iter   544/ 1097] train: loss: 0.0430617
[Epoch 59; Iter   574/ 1097] train: loss: 0.0229919
[Epoch 59; Iter   604/ 1097] train: loss: 0.0167960
[Epoch 59; Iter   634/ 1097] train: loss: 0.1286315
[Epoch 59; Iter   664/ 1097] train: loss: 0.0240008
[Epoch 59; Iter   694/ 1097] train: loss: 0.0223276
[Epoch 59; Iter   724/ 1097] train: loss: 0.0162592
[Epoch 59; Iter   754/ 1097] train: loss: 0.0198748
[Epoch 59; Iter   784/ 1097] train: loss: 0.0056587
[Epoch 59; Iter   814/ 1097] train: loss: 0.1781260
[Epoch 59; Iter   844/ 1097] train: loss: 0.0153591
[Epoch 59; Iter   874/ 1097] train: loss: 0.0986381
[Epoch 59; Iter   904/ 1097] train: loss: 0.0566719
[Epoch 59; Iter   934/ 1097] train: loss: 0.0115448
[Epoch 59; Iter   964/ 1097] train: loss: 0.0208674
[Epoch 59; Iter   994/ 1097] train: loss: 0.1051161
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0150839
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0143061
[Epoch 59; Iter  1084/ 1097] train: loss: 0.1132182
[Epoch 59] ogbg-molhiv: 0.810372 val loss: 0.109026
[Epoch 59] ogbg-molhiv: 0.750849 test loss: 0.150420
[Epoch 60; Iter    17/ 1097] train: loss: 0.0175546
[Epoch 60; Iter    47/ 1097] train: loss: 0.0142874
[Epoch 60; Iter    77/ 1097] train: loss: 0.0341928
[Epoch 60; Iter   107/ 1097] train: loss: 0.0098572
[Epoch 60; Iter   137/ 1097] train: loss: 0.0227762
[Epoch 60; Iter   167/ 1097] train: loss: 0.0319357
[Epoch 60; Iter   197/ 1097] train: loss: 0.0109449
[Epoch 60; Iter   227/ 1097] train: loss: 0.1067996
[Epoch 60; Iter   257/ 1097] train: loss: 0.0181660
[Epoch 60; Iter   287/ 1097] train: loss: 0.0088225
[Epoch 60; Iter   317/ 1097] train: loss: 0.1032256
[Epoch 60; Iter   347/ 1097] train: loss: 0.2646395
[Epoch 60; Iter   377/ 1097] train: loss: 0.0159144
[Epoch 60; Iter   407/ 1097] train: loss: 0.0086145
[Epoch 60; Iter   437/ 1097] train: loss: 0.0424343
[Epoch 60; Iter   467/ 1097] train: loss: 0.0445185
[Epoch 60; Iter   497/ 1097] train: loss: 0.1127985
[Epoch 60; Iter   527/ 1097] train: loss: 0.0216732
[Epoch 60; Iter   557/ 1097] train: loss: 0.0125867
[Epoch 60; Iter   587/ 1097] train: loss: 0.1825950
[Epoch 60; Iter   617/ 1097] train: loss: 0.0678315
[Epoch 60; Iter   647/ 1097] train: loss: 0.0155828
[Epoch 60; Iter   677/ 1097] train: loss: 0.0116162
[Epoch 60; Iter   707/ 1097] train: loss: 0.1593914
[Epoch 60; Iter   737/ 1097] train: loss: 0.0932103
[Epoch 60; Iter   767/ 1097] train: loss: 0.0927682
[Epoch 60; Iter   797/ 1097] train: loss: 0.0300646
[Epoch 60; Iter   827/ 1097] train: loss: 0.0254087
[Epoch 60; Iter   857/ 1097] train: loss: 0.1103738
[Epoch 60; Iter   887/ 1097] train: loss: 0.0101154
[Epoch 60; Iter   917/ 1097] train: loss: 0.0766957
[Epoch 60; Iter   947/ 1097] train: loss: 0.0690309
[Epoch 60; Iter   977/ 1097] train: loss: 0.0655335
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0865372
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0442573
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0877744
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0052655
[Epoch 59; Iter   810/  960] train: loss: 0.0039290
[Epoch 59; Iter   840/  960] train: loss: 0.0118531
[Epoch 59; Iter   870/  960] train: loss: 0.1737264
[Epoch 59; Iter   900/  960] train: loss: 0.0519052
[Epoch 59; Iter   930/  960] train: loss: 0.0132610
[Epoch 59; Iter   960/  960] train: loss: 0.0034415
[Epoch 59] ogbg-molhiv: 0.734687 val loss: 0.543620
[Epoch 59] ogbg-molhiv: 0.771759 test loss: 0.406705
[Epoch 60; Iter    30/  960] train: loss: 0.0038520
[Epoch 60; Iter    60/  960] train: loss: 0.0101414
[Epoch 60; Iter    90/  960] train: loss: 0.2085220
[Epoch 60; Iter   120/  960] train: loss: 0.0137039
[Epoch 60; Iter   150/  960] train: loss: 0.0531770
[Epoch 60; Iter   180/  960] train: loss: 0.3324037
[Epoch 60; Iter   210/  960] train: loss: 0.0351537
[Epoch 60; Iter   240/  960] train: loss: 0.0273037
[Epoch 60; Iter   270/  960] train: loss: 0.0889811
[Epoch 60; Iter   300/  960] train: loss: 0.0379018
[Epoch 60; Iter   330/  960] train: loss: 0.0605003
[Epoch 60; Iter   360/  960] train: loss: 0.0049865
[Epoch 60; Iter   390/  960] train: loss: 0.0447582
[Epoch 60; Iter   420/  960] train: loss: 0.0131629
[Epoch 60; Iter   450/  960] train: loss: 0.0027939
[Epoch 60; Iter   480/  960] train: loss: 0.0186913
[Epoch 60; Iter   510/  960] train: loss: 0.0125279
[Epoch 60; Iter   540/  960] train: loss: 0.0178508
[Epoch 60; Iter   570/  960] train: loss: 0.0097274
[Epoch 60; Iter   600/  960] train: loss: 0.0047869
[Epoch 60; Iter   630/  960] train: loss: 0.0079937
[Epoch 60; Iter   660/  960] train: loss: 0.0416794
[Epoch 60; Iter   690/  960] train: loss: 0.0302549
[Epoch 60; Iter   720/  960] train: loss: 0.0965018
[Epoch 60; Iter   750/  960] train: loss: 0.0755937
[Epoch 60; Iter   780/  960] train: loss: 0.0070914
[Epoch 60; Iter   810/  960] train: loss: 0.0353055
[Epoch 60; Iter   840/  960] train: loss: 0.0067755
[Epoch 60; Iter   870/  960] train: loss: 0.0083744
[Epoch 60; Iter   900/  960] train: loss: 0.0071097
[Epoch 60; Iter   930/  960] train: loss: 0.0151987
[Epoch 60; Iter   960/  960] train: loss: 0.0165024
[Epoch 60] ogbg-molhiv: 0.740961 val loss: 0.398656
[Epoch 60] ogbg-molhiv: 0.776009 test loss: 0.255910
[Epoch 61; Iter    30/  960] train: loss: 0.0154408
[Epoch 61; Iter    60/  960] train: loss: 0.0408528
[Epoch 61; Iter    90/  960] train: loss: 0.0965773
[Epoch 61; Iter   120/  960] train: loss: 0.1146007
[Epoch 61; Iter   150/  960] train: loss: 0.0058128
[Epoch 61; Iter   180/  960] train: loss: 0.0816888
[Epoch 61; Iter   210/  960] train: loss: 0.0114719
[Epoch 61; Iter   240/  960] train: loss: 0.0590259
[Epoch 61; Iter   270/  960] train: loss: 0.0419908
[Epoch 61; Iter   300/  960] train: loss: 0.1287414
[Epoch 61; Iter   330/  960] train: loss: 0.0029442
[Epoch 61; Iter   360/  960] train: loss: 0.0248273
[Epoch 61; Iter   390/  960] train: loss: 0.0098960
[Epoch 61; Iter   420/  960] train: loss: 0.0446490
[Epoch 61; Iter   450/  960] train: loss: 0.0230954
[Epoch 61; Iter   480/  960] train: loss: 0.0160662
[Epoch 61; Iter   510/  960] train: loss: 0.0256129
[Epoch 61; Iter   540/  960] train: loss: 0.0030994
[Epoch 61; Iter   570/  960] train: loss: 0.0365386
[Epoch 61; Iter   600/  960] train: loss: 0.0125186
[Epoch 61; Iter   630/  960] train: loss: 0.1168415
[Epoch 61; Iter   660/  960] train: loss: 0.1801578
[Epoch 61; Iter   690/  960] train: loss: 0.0687214
[Epoch 61; Iter   720/  960] train: loss: 0.0131569
[Epoch 61; Iter   750/  960] train: loss: 0.0036415
[Epoch 61; Iter   780/  960] train: loss: 0.0159932
[Epoch 61; Iter   810/  960] train: loss: 0.1329726
[Epoch 61; Iter   840/  960] train: loss: 0.0255919
[Epoch 61; Iter   870/  960] train: loss: 0.0687479
[Epoch 61; Iter   900/  960] train: loss: 0.0071094
[Epoch 61; Iter   930/  960] train: loss: 0.0291619
[Epoch 61; Iter   960/  960] train: loss: 0.0717618
[Epoch 61] ogbg-molhiv: 0.740267 val loss: 0.198041
[Epoch 61] ogbg-molhiv: 0.765495 test loss: 0.159281
[Epoch 62; Iter    30/  960] train: loss: 0.0387572
[Epoch 62; Iter    60/  960] train: loss: 0.0245649
[Epoch 62; Iter    90/  960] train: loss: 0.0246717
[Epoch 62; Iter   120/  960] train: loss: 0.0912304
[Epoch 62; Iter   150/  960] train: loss: 0.3545042
[Epoch 62; Iter   180/  960] train: loss: 0.0081749
[Epoch 62; Iter   210/  960] train: loss: 0.0076852
[Epoch 62; Iter   240/  960] train: loss: 0.0041097
[Epoch 62; Iter   270/  960] train: loss: 0.0349574
[Epoch 62; Iter   300/  960] train: loss: 0.0115635
[Epoch 62; Iter   330/  960] train: loss: 0.0825333
[Epoch 62; Iter   360/  960] train: loss: 0.0023559
[Epoch 62; Iter   390/  960] train: loss: 0.0093999
[Epoch 62; Iter   420/  960] train: loss: 0.0215129
[Epoch 62; Iter   450/  960] train: loss: 0.0084612
[Epoch 62; Iter   480/  960] train: loss: 0.0076034
[Epoch 62; Iter   510/  960] train: loss: 0.0100635
[Epoch 62; Iter   540/  960] train: loss: 0.0311929
[Epoch 62; Iter   570/  960] train: loss: 0.0164379
[Epoch 62; Iter   600/  960] train: loss: 0.0121952
[Epoch 62; Iter   630/  960] train: loss: 0.1029919
[Epoch 62; Iter   660/  960] train: loss: 0.0087976
[Epoch 62; Iter   690/  960] train: loss: 0.0266397
[Epoch 62; Iter   720/  960] train: loss: 0.0156743
[Epoch 62; Iter   750/  960] train: loss: 0.0101245
[Epoch 62; Iter   780/  960] train: loss: 0.1255917
[Epoch 62; Iter   810/  960] train: loss: 0.0070314
[Epoch 62; Iter   840/  960] train: loss: 0.0052199
[Epoch 62; Iter   870/  960] train: loss: 0.0161283
[Epoch 62; Iter   900/  960] train: loss: 0.0052651
[Epoch 62; Iter   930/  960] train: loss: 0.0639038
[Epoch 62; Iter   960/  960] train: loss: 0.0042825
[Epoch 62] ogbg-molhiv: 0.724644 val loss: 0.268964
[Epoch 62] ogbg-molhiv: 0.751479 test loss: 0.167665
[Epoch 63; Iter    30/  960] train: loss: 0.0091988
[Epoch 63; Iter    60/  960] train: loss: 0.0080623
[Epoch 63; Iter    90/  960] train: loss: 0.0118732
[Epoch 63; Iter   120/  960] train: loss: 0.0041279
[Epoch 63; Iter   150/  960] train: loss: 0.0086374
[Epoch 63; Iter   180/  960] train: loss: 0.0067501
[Epoch 63; Iter   210/  960] train: loss: 0.0107281
[Epoch 63; Iter   240/  960] train: loss: 0.0320515
[Epoch 63; Iter   270/  960] train: loss: 0.1169224
[Epoch 63; Iter   300/  960] train: loss: 0.0171012
[Epoch 63; Iter   330/  960] train: loss: 0.0048498
[Epoch 63; Iter   360/  960] train: loss: 0.0050573
[Epoch 63; Iter   390/  960] train: loss: 0.0387348
[Epoch 63; Iter   420/  960] train: loss: 0.0103439
[Epoch 63; Iter   450/  960] train: loss: 0.0090336
[Epoch 63; Iter   480/  960] train: loss: 0.0046713
[Epoch 63; Iter   510/  960] train: loss: 0.0184094
[Epoch 63; Iter   540/  960] train: loss: 0.1232223
[Epoch 63; Iter   570/  960] train: loss: 0.0406562
[Epoch 63; Iter   600/  960] train: loss: 0.0317201
[Epoch 63; Iter   630/  960] train: loss: 0.0123046
[Epoch 63; Iter   660/  960] train: loss: 0.0082293
[Epoch 63; Iter   690/  960] train: loss: 0.0856403
[Epoch 63; Iter   720/  960] train: loss: 0.0051376
[Epoch 63; Iter   750/  960] train: loss: 0.0987736
[Epoch 63; Iter   780/  960] train: loss: 0.1930314
[Epoch 63; Iter   810/  960] train: loss: 0.0463104
[Epoch 63; Iter   840/  960] train: loss: 0.0036149
[Epoch 63; Iter   870/  960] train: loss: 0.0037572
[Epoch 63; Iter   900/  960] train: loss: 0.0158329
[Epoch 63; Iter   930/  960] train: loss: 0.0569560
[Epoch 63; Iter   960/  960] train: loss: 0.0129796
[Epoch 63] ogbg-molhiv: 0.738112 val loss: 0.197482
[Epoch 63] ogbg-molhiv: 0.758078 test loss: 0.159743
[Epoch 64; Iter    30/  960] train: loss: 0.0132235
[Epoch 64; Iter    60/  960] train: loss: 0.0086054
[Epoch 64; Iter    90/  960] train: loss: 0.1208716
[Epoch 64; Iter   120/  960] train: loss: 0.1143885
[Epoch 64; Iter   150/  960] train: loss: 0.0041652
[Epoch 64; Iter   180/  960] train: loss: 0.0035050
[Epoch 64; Iter   210/  960] train: loss: 0.0038954
[Epoch 64; Iter   240/  960] train: loss: 0.0124123
[Epoch 64; Iter   270/  960] train: loss: 0.0272101
[Epoch 64; Iter   300/  960] train: loss: 0.0131585
[Epoch 64; Iter   330/  960] train: loss: 0.0114054
[Epoch 64; Iter   360/  960] train: loss: 0.0227479
[Epoch 64; Iter   390/  960] train: loss: 0.0175843
[Epoch 56; Iter  1045/ 1097] train: loss: 0.0083152
[Epoch 56; Iter  1075/ 1097] train: loss: 0.0164339
[Epoch 56] ogbg-molhiv: 0.797233 val loss: 0.096555
[Epoch 56] ogbg-molhiv: 0.770503 test loss: 0.164656
[Epoch 57; Iter     8/ 1097] train: loss: 0.0102244
[Epoch 57; Iter    38/ 1097] train: loss: 0.0069435
[Epoch 57; Iter    68/ 1097] train: loss: 0.0082188
[Epoch 57; Iter    98/ 1097] train: loss: 0.0033525
[Epoch 57; Iter   128/ 1097] train: loss: 0.0848690
[Epoch 57; Iter   158/ 1097] train: loss: 0.0023965
[Epoch 57; Iter   188/ 1097] train: loss: 0.0180823
[Epoch 57; Iter   218/ 1097] train: loss: 0.0114216
[Epoch 57; Iter   248/ 1097] train: loss: 0.0216473
[Epoch 57; Iter   278/ 1097] train: loss: 0.0182514
[Epoch 57; Iter   308/ 1097] train: loss: 0.0042634
[Epoch 57; Iter   338/ 1097] train: loss: 0.0212988
[Epoch 57; Iter   368/ 1097] train: loss: 0.0345906
[Epoch 57; Iter   398/ 1097] train: loss: 0.0187379
[Epoch 57; Iter   428/ 1097] train: loss: 0.1601064
[Epoch 57; Iter   458/ 1097] train: loss: 0.0057827
[Epoch 57; Iter   488/ 1097] train: loss: 0.2542290
[Epoch 57; Iter   518/ 1097] train: loss: 0.0118199
[Epoch 57; Iter   548/ 1097] train: loss: 0.0114903
[Epoch 57; Iter   578/ 1097] train: loss: 0.0028340
[Epoch 57; Iter   608/ 1097] train: loss: 0.0581849
[Epoch 57; Iter   638/ 1097] train: loss: 0.1369867
[Epoch 57; Iter   668/ 1097] train: loss: 0.1019867
[Epoch 57; Iter   698/ 1097] train: loss: 0.0833373
[Epoch 57; Iter   728/ 1097] train: loss: 0.0063536
[Epoch 57; Iter   758/ 1097] train: loss: 0.1388103
[Epoch 57; Iter   788/ 1097] train: loss: 0.0902123
[Epoch 57; Iter   818/ 1097] train: loss: 0.0695694
[Epoch 57; Iter   848/ 1097] train: loss: 0.1253358
[Epoch 57; Iter   878/ 1097] train: loss: 0.0797744
[Epoch 57; Iter   908/ 1097] train: loss: 0.0321096
[Epoch 57; Iter   938/ 1097] train: loss: 0.0687471
[Epoch 57; Iter   968/ 1097] train: loss: 0.0178816
[Epoch 57; Iter   998/ 1097] train: loss: 0.0525725
[Epoch 57; Iter  1028/ 1097] train: loss: 0.0292020
[Epoch 57; Iter  1058/ 1097] train: loss: 0.0298465
[Epoch 57; Iter  1088/ 1097] train: loss: 0.0508228
[Epoch 57] ogbg-molhiv: 0.795834 val loss: 0.098514
[Epoch 57] ogbg-molhiv: 0.751111 test loss: 0.180150
[Epoch 58; Iter    21/ 1097] train: loss: 0.0029013
[Epoch 58; Iter    51/ 1097] train: loss: 0.0077975
[Epoch 58; Iter    81/ 1097] train: loss: 0.0095763
[Epoch 58; Iter   111/ 1097] train: loss: 0.0042533
[Epoch 58; Iter   141/ 1097] train: loss: 0.0064091
[Epoch 58; Iter   171/ 1097] train: loss: 0.0258012
[Epoch 58; Iter   201/ 1097] train: loss: 0.1383693
[Epoch 58; Iter   231/ 1097] train: loss: 0.0121418
[Epoch 58; Iter   261/ 1097] train: loss: 0.1177461
[Epoch 58; Iter   291/ 1097] train: loss: 0.0359152
[Epoch 58; Iter   321/ 1097] train: loss: 0.0177697
[Epoch 58; Iter   351/ 1097] train: loss: 0.0067389
[Epoch 58; Iter   381/ 1097] train: loss: 0.0048485
[Epoch 58; Iter   411/ 1097] train: loss: 0.0692538
[Epoch 58; Iter   441/ 1097] train: loss: 0.0262881
[Epoch 58; Iter   471/ 1097] train: loss: 0.0670401
[Epoch 58; Iter   501/ 1097] train: loss: 0.0274382
[Epoch 58; Iter   531/ 1097] train: loss: 0.0865940
[Epoch 58; Iter   561/ 1097] train: loss: 0.0263395
[Epoch 58; Iter   591/ 1097] train: loss: 0.0063699
[Epoch 58; Iter   621/ 1097] train: loss: 0.0039309
[Epoch 58; Iter   651/ 1097] train: loss: 0.0082148
[Epoch 58; Iter   681/ 1097] train: loss: 0.0202610
[Epoch 58; Iter   711/ 1097] train: loss: 0.0061471
[Epoch 58; Iter   741/ 1097] train: loss: 0.0199899
[Epoch 58; Iter   771/ 1097] train: loss: 0.0301442
[Epoch 58; Iter   801/ 1097] train: loss: 0.0038411
[Epoch 58; Iter   831/ 1097] train: loss: 0.0311088
[Epoch 58; Iter   861/ 1097] train: loss: 0.0032951
[Epoch 58; Iter   891/ 1097] train: loss: 0.0039415
[Epoch 58; Iter   921/ 1097] train: loss: 0.0119323
[Epoch 58; Iter   951/ 1097] train: loss: 0.0486679
[Epoch 58; Iter   981/ 1097] train: loss: 0.0322922
[Epoch 58; Iter  1011/ 1097] train: loss: 0.0116854
[Epoch 58; Iter  1041/ 1097] train: loss: 0.0051160
[Epoch 58; Iter  1071/ 1097] train: loss: 0.0204583
[Epoch 58] ogbg-molhiv: 0.800908 val loss: 0.096925
[Epoch 58] ogbg-molhiv: 0.752077 test loss: 0.176741
[Epoch 59; Iter     4/ 1097] train: loss: 0.0052877
[Epoch 59; Iter    34/ 1097] train: loss: 0.0073479
[Epoch 59; Iter    64/ 1097] train: loss: 0.0046826
[Epoch 59; Iter    94/ 1097] train: loss: 0.1376623
[Epoch 59; Iter   124/ 1097] train: loss: 0.0076191
[Epoch 59; Iter   154/ 1097] train: loss: 0.0987759
[Epoch 59; Iter   184/ 1097] train: loss: 0.0103130
[Epoch 59; Iter   214/ 1097] train: loss: 0.0849823
[Epoch 59; Iter   244/ 1097] train: loss: 0.0568691
[Epoch 59; Iter   274/ 1097] train: loss: 0.0516398
[Epoch 59; Iter   304/ 1097] train: loss: 0.0681619
[Epoch 59; Iter   334/ 1097] train: loss: 0.0686455
[Epoch 59; Iter   364/ 1097] train: loss: 0.0126325
[Epoch 59; Iter   394/ 1097] train: loss: 0.0036590
[Epoch 59; Iter   424/ 1097] train: loss: 0.0284065
[Epoch 59; Iter   454/ 1097] train: loss: 0.0275801
[Epoch 59; Iter   484/ 1097] train: loss: 0.0030011
[Epoch 59; Iter   514/ 1097] train: loss: 0.0567956
[Epoch 59; Iter   544/ 1097] train: loss: 0.0053248
[Epoch 59; Iter   574/ 1097] train: loss: 0.1174129
[Epoch 59; Iter   604/ 1097] train: loss: 0.0060839
[Epoch 59; Iter   634/ 1097] train: loss: 0.0813334
[Epoch 59; Iter   664/ 1097] train: loss: 0.0683061
[Epoch 59; Iter   694/ 1097] train: loss: 0.0124763
[Epoch 59; Iter   724/ 1097] train: loss: 0.0034329
[Epoch 59; Iter   754/ 1097] train: loss: 0.0069414
[Epoch 59; Iter   784/ 1097] train: loss: 0.0311092
[Epoch 59; Iter   814/ 1097] train: loss: 0.0120741
[Epoch 59; Iter   844/ 1097] train: loss: 0.0324298
[Epoch 59; Iter   874/ 1097] train: loss: 0.0092327
[Epoch 59; Iter   904/ 1097] train: loss: 0.0467590
[Epoch 59; Iter   934/ 1097] train: loss: 0.0577591
[Epoch 59; Iter   964/ 1097] train: loss: 0.0153567
[Epoch 59; Iter   994/ 1097] train: loss: 0.1077477
[Epoch 59; Iter  1024/ 1097] train: loss: 0.0687281
[Epoch 59; Iter  1054/ 1097] train: loss: 0.0271946
[Epoch 59; Iter  1084/ 1097] train: loss: 0.0395224
[Epoch 59] ogbg-molhiv: 0.805739 val loss: 0.095745
[Epoch 59] ogbg-molhiv: 0.754155 test loss: 0.185879
[Epoch 60; Iter    17/ 1097] train: loss: 0.0091443
[Epoch 60; Iter    47/ 1097] train: loss: 0.0103861
[Epoch 60; Iter    77/ 1097] train: loss: 0.0199730
[Epoch 60; Iter   107/ 1097] train: loss: 0.0090203
[Epoch 60; Iter   137/ 1097] train: loss: 0.0048602
[Epoch 60; Iter   167/ 1097] train: loss: 0.0193958
[Epoch 60; Iter   197/ 1097] train: loss: 0.0095925
[Epoch 60; Iter   227/ 1097] train: loss: 0.0562248
[Epoch 60; Iter   257/ 1097] train: loss: 0.0506926
[Epoch 60; Iter   287/ 1097] train: loss: 0.0029955
[Epoch 60; Iter   317/ 1097] train: loss: 0.0191786
[Epoch 60; Iter   347/ 1097] train: loss: 0.0218149
[Epoch 60; Iter   377/ 1097] train: loss: 0.0286319
[Epoch 60; Iter   407/ 1097] train: loss: 0.0578886
[Epoch 60; Iter   437/ 1097] train: loss: 0.0046208
[Epoch 60; Iter   467/ 1097] train: loss: 0.0032364
[Epoch 60; Iter   497/ 1097] train: loss: 0.0185103
[Epoch 60; Iter   527/ 1097] train: loss: 0.0081197
[Epoch 60; Iter   557/ 1097] train: loss: 0.0184947
[Epoch 60; Iter   587/ 1097] train: loss: 0.0148953
[Epoch 60; Iter   617/ 1097] train: loss: 0.0043031
[Epoch 60; Iter   647/ 1097] train: loss: 0.0109226
[Epoch 60; Iter   677/ 1097] train: loss: 0.0083521
[Epoch 60; Iter   707/ 1097] train: loss: 0.0492844
[Epoch 60; Iter   737/ 1097] train: loss: 0.0942544
[Epoch 60; Iter   767/ 1097] train: loss: 0.0577422
[Epoch 60; Iter   797/ 1097] train: loss: 0.0106151
[Epoch 60; Iter   827/ 1097] train: loss: 0.0680921
[Epoch 60; Iter   857/ 1097] train: loss: 0.0928125
[Epoch 60; Iter   887/ 1097] train: loss: 0.0130670
[Epoch 60; Iter   917/ 1097] train: loss: 0.0766449
[Epoch 60; Iter   947/ 1097] train: loss: 0.1048235
[Epoch 60; Iter   977/ 1097] train: loss: 0.0070304
[Epoch 60; Iter  1007/ 1097] train: loss: 0.0846563
[Epoch 60; Iter  1037/ 1097] train: loss: 0.0229863
[Epoch 60; Iter  1067/ 1097] train: loss: 0.0143846
[Epoch 60; Iter  1097/ 1097] train: loss: 0.0337100
[Epoch 59; Iter   810/  960] train: loss: 0.0353783
[Epoch 59; Iter   840/  960] train: loss: 0.0208941
[Epoch 59; Iter   870/  960] train: loss: 0.0468690
[Epoch 59; Iter   900/  960] train: loss: 0.0184130
[Epoch 59; Iter   930/  960] train: loss: 0.0242165
[Epoch 59; Iter   960/  960] train: loss: 0.0053226
[Epoch 59] ogbg-molhiv: 0.759167 val loss: 0.318082
[Epoch 59] ogbg-molhiv: 0.767266 test loss: 0.301551
[Epoch 60; Iter    30/  960] train: loss: 0.1014615
[Epoch 60; Iter    60/  960] train: loss: 0.0119794
[Epoch 60; Iter    90/  960] train: loss: 0.0325047
[Epoch 60; Iter   120/  960] train: loss: 0.0075510
[Epoch 60; Iter   150/  960] train: loss: 0.0039083
[Epoch 60; Iter   180/  960] train: loss: 0.0205457
[Epoch 60; Iter   210/  960] train: loss: 0.0069067
[Epoch 60; Iter   240/  960] train: loss: 0.0105693
[Epoch 60; Iter   270/  960] train: loss: 0.0020646
[Epoch 60; Iter   300/  960] train: loss: 0.0478246
[Epoch 60; Iter   330/  960] train: loss: 0.0070962
[Epoch 60; Iter   360/  960] train: loss: 0.0308952
[Epoch 60; Iter   390/  960] train: loss: 0.0182496
[Epoch 60; Iter   420/  960] train: loss: 0.0384994
[Epoch 60; Iter   450/  960] train: loss: 0.0692118
[Epoch 60; Iter   480/  960] train: loss: 0.0190404
[Epoch 60; Iter   510/  960] train: loss: 0.0809013
[Epoch 60; Iter   540/  960] train: loss: 0.0227101
[Epoch 60; Iter   570/  960] train: loss: 0.0748376
[Epoch 60; Iter   600/  960] train: loss: 0.0423074
[Epoch 60; Iter   630/  960] train: loss: 0.1463280
[Epoch 60; Iter   660/  960] train: loss: 0.0051933
[Epoch 60; Iter   690/  960] train: loss: 0.0360618
[Epoch 60; Iter   720/  960] train: loss: 0.0114773
[Epoch 60; Iter   750/  960] train: loss: 0.0572433
[Epoch 60; Iter   780/  960] train: loss: 0.0959226
[Epoch 60; Iter   810/  960] train: loss: 0.0756179
[Epoch 60; Iter   840/  960] train: loss: 0.1344128
[Epoch 60; Iter   870/  960] train: loss: 0.0960301
[Epoch 60; Iter   900/  960] train: loss: 0.0052050
[Epoch 60; Iter   930/  960] train: loss: 0.0105582
[Epoch 60; Iter   960/  960] train: loss: 0.0135008
[Epoch 60] ogbg-molhiv: 0.764096 val loss: 0.313158
[Epoch 60] ogbg-molhiv: 0.756663 test loss: 0.205666
[Epoch 61; Iter    30/  960] train: loss: 0.0185890
[Epoch 61; Iter    60/  960] train: loss: 0.0124000
[Epoch 61; Iter    90/  960] train: loss: 0.0027208
[Epoch 61; Iter   120/  960] train: loss: 0.0629223
[Epoch 61; Iter   150/  960] train: loss: 0.0208574
[Epoch 61; Iter   180/  960] train: loss: 0.0531949
[Epoch 61; Iter   210/  960] train: loss: 0.0089279
[Epoch 61; Iter   240/  960] train: loss: 0.0668251
[Epoch 61; Iter   270/  960] train: loss: 0.0317519
[Epoch 61; Iter   300/  960] train: loss: 0.0446465
[Epoch 61; Iter   330/  960] train: loss: 0.1207669
[Epoch 61; Iter   360/  960] train: loss: 0.0042649
[Epoch 61; Iter   390/  960] train: loss: 0.0072417
[Epoch 61; Iter   420/  960] train: loss: 0.0315201
[Epoch 61; Iter   450/  960] train: loss: 0.0016715
[Epoch 61; Iter   480/  960] train: loss: 0.0113692
[Epoch 61; Iter   510/  960] train: loss: 0.0241751
[Epoch 61; Iter   540/  960] train: loss: 0.0556601
[Epoch 61; Iter   570/  960] train: loss: 0.0283355
[Epoch 61; Iter   600/  960] train: loss: 0.0124056
[Epoch 61; Iter   630/  960] train: loss: 0.0043597
[Epoch 61; Iter   660/  960] train: loss: 0.0703682
[Epoch 61; Iter   690/  960] train: loss: 0.0261282
[Epoch 61; Iter   720/  960] train: loss: 0.0293965
[Epoch 61; Iter   750/  960] train: loss: 0.0794196
[Epoch 61; Iter   780/  960] train: loss: 0.0582814
[Epoch 61; Iter   810/  960] train: loss: 0.0806275
[Epoch 61; Iter   840/  960] train: loss: 0.0072991
[Epoch 61; Iter   870/  960] train: loss: 0.0594078
[Epoch 61; Iter   900/  960] train: loss: 0.0735973
[Epoch 61; Iter   930/  960] train: loss: 0.0506916
[Epoch 61; Iter   960/  960] train: loss: 0.0584868
[Epoch 61] ogbg-molhiv: 0.750701 val loss: 0.549070
[Epoch 61] ogbg-molhiv: 0.762399 test loss: 0.219759
[Epoch 62; Iter    30/  960] train: loss: 0.1930285
[Epoch 62; Iter    60/  960] train: loss: 0.0517168
[Epoch 62; Iter    90/  960] train: loss: 0.0794719
[Epoch 62; Iter   120/  960] train: loss: 0.0020902
[Epoch 62; Iter   150/  960] train: loss: 0.0103192
[Epoch 62; Iter   180/  960] train: loss: 0.0496246
[Epoch 62; Iter   210/  960] train: loss: 0.0031290
[Epoch 62; Iter   240/  960] train: loss: 0.0105129
[Epoch 62; Iter   270/  960] train: loss: 0.0122080
[Epoch 62; Iter   300/  960] train: loss: 0.0395051
[Epoch 62; Iter   330/  960] train: loss: 0.0107545
[Epoch 62; Iter   360/  960] train: loss: 0.0051228
[Epoch 62; Iter   390/  960] train: loss: 0.0068655
[Epoch 62; Iter   420/  960] train: loss: 0.0183266
[Epoch 62; Iter   450/  960] train: loss: 0.0517396
[Epoch 62; Iter   480/  960] train: loss: 0.0105923
[Epoch 62; Iter   510/  960] train: loss: 0.0411208
[Epoch 62; Iter   540/  960] train: loss: 0.0381004
[Epoch 62; Iter   570/  960] train: loss: 0.0075740
[Epoch 62; Iter   600/  960] train: loss: 0.0136942
[Epoch 62; Iter   630/  960] train: loss: 0.3146510
[Epoch 62; Iter   660/  960] train: loss: 0.0135329
[Epoch 62; Iter   690/  960] train: loss: 0.0601915
[Epoch 62; Iter   720/  960] train: loss: 0.0194944
[Epoch 62; Iter   750/  960] train: loss: 0.0182335
[Epoch 62; Iter   780/  960] train: loss: 0.1048704
[Epoch 62; Iter   810/  960] train: loss: 0.0086878
[Epoch 62; Iter   840/  960] train: loss: 0.0163797
[Epoch 62; Iter   870/  960] train: loss: 0.0608305
[Epoch 62; Iter   900/  960] train: loss: 0.0605563
[Epoch 62; Iter   930/  960] train: loss: 0.1467110
[Epoch 62; Iter   960/  960] train: loss: 0.0031360
[Epoch 62] ogbg-molhiv: 0.760548 val loss: 0.508639
[Epoch 62] ogbg-molhiv: 0.759094 test loss: 0.210904
[Epoch 63; Iter    30/  960] train: loss: 0.1153311
[Epoch 63; Iter    60/  960] train: loss: 0.1076202
[Epoch 63; Iter    90/  960] train: loss: 0.0638425
[Epoch 63; Iter   120/  960] train: loss: 0.0023253
[Epoch 63; Iter   150/  960] train: loss: 0.0103321
[Epoch 63; Iter   180/  960] train: loss: 0.1011316
[Epoch 63; Iter   210/  960] train: loss: 0.0168139
[Epoch 63; Iter   240/  960] train: loss: 0.0179005
[Epoch 63; Iter   270/  960] train: loss: 0.0064615
[Epoch 63; Iter   300/  960] train: loss: 0.2401201
[Epoch 63; Iter   330/  960] train: loss: 0.0099497
[Epoch 63; Iter   360/  960] train: loss: 0.0208105
[Epoch 63; Iter   390/  960] train: loss: 0.0124852
[Epoch 63; Iter   420/  960] train: loss: 0.0992452
[Epoch 63; Iter   450/  960] train: loss: 0.0316977
[Epoch 63; Iter   480/  960] train: loss: 0.0516743
[Epoch 63; Iter   510/  960] train: loss: 0.1144402
[Epoch 63; Iter   540/  960] train: loss: 0.0059860
[Epoch 63; Iter   570/  960] train: loss: 0.1504727
[Epoch 63; Iter   600/  960] train: loss: 0.0687922
[Epoch 63; Iter   630/  960] train: loss: 0.0068373
[Epoch 63; Iter   660/  960] train: loss: 0.0811331
[Epoch 63; Iter   690/  960] train: loss: 0.0172871
[Epoch 63; Iter   720/  960] train: loss: 0.1406459
[Epoch 63; Iter   750/  960] train: loss: 0.0734084
[Epoch 63; Iter   780/  960] train: loss: 0.0123507
[Epoch 63; Iter   810/  960] train: loss: 0.0098415
[Epoch 63; Iter   840/  960] train: loss: 0.0060898
[Epoch 63; Iter   870/  960] train: loss: 0.0064852
[Epoch 63; Iter   900/  960] train: loss: 0.0220050
[Epoch 63; Iter   930/  960] train: loss: 0.0263350
[Epoch 63; Iter   960/  960] train: loss: 0.3239982
[Epoch 63] ogbg-molhiv: 0.755952 val loss: 0.370361
[Epoch 63] ogbg-molhiv: 0.758561 test loss: 0.197627
[Epoch 64; Iter    30/  960] train: loss: 0.0042734
[Epoch 64; Iter    60/  960] train: loss: 0.0104646
[Epoch 64; Iter    90/  960] train: loss: 0.0064614
[Epoch 64; Iter   120/  960] train: loss: 0.0121017
[Epoch 64; Iter   150/  960] train: loss: 0.0811970
[Epoch 64; Iter   180/  960] train: loss: 0.0130349
[Epoch 64; Iter   210/  960] train: loss: 0.2240731
[Epoch 64; Iter   240/  960] train: loss: 0.1022564
[Epoch 64; Iter   270/  960] train: loss: 0.0126155
[Epoch 64; Iter   300/  960] train: loss: 0.0035693
[Epoch 64; Iter   330/  960] train: loss: 0.0202773
[Epoch 64; Iter   360/  960] train: loss: 0.0238901
[Epoch 64; Iter   390/  960] train: loss: 0.0418211
[Epoch 59; Iter   810/  960] train: loss: 0.0152133
[Epoch 59; Iter   840/  960] train: loss: 0.0070846
[Epoch 59; Iter   870/  960] train: loss: 0.0358685
[Epoch 59; Iter   900/  960] train: loss: 0.0036667
[Epoch 59; Iter   930/  960] train: loss: 0.0176242
[Epoch 59; Iter   960/  960] train: loss: 0.0117451
[Epoch 59] ogbg-molhiv: 0.720470 val loss: 0.557519
[Epoch 59] ogbg-molhiv: 0.750675 test loss: 0.417155
[Epoch 60; Iter    30/  960] train: loss: 0.0065254
[Epoch 60; Iter    60/  960] train: loss: 0.0068661
[Epoch 60; Iter    90/  960] train: loss: 0.0099909
[Epoch 60; Iter   120/  960] train: loss: 0.0077065
[Epoch 60; Iter   150/  960] train: loss: 0.0776199
[Epoch 60; Iter   180/  960] train: loss: 0.0193262
[Epoch 60; Iter   210/  960] train: loss: 0.0118069
[Epoch 60; Iter   240/  960] train: loss: 0.0075297
[Epoch 60; Iter   270/  960] train: loss: 0.0207865
[Epoch 60; Iter   300/  960] train: loss: 0.0174242
[Epoch 60; Iter   330/  960] train: loss: 0.0419392
[Epoch 60; Iter   360/  960] train: loss: 0.0106181
[Epoch 60; Iter   390/  960] train: loss: 0.0069192
[Epoch 60; Iter   420/  960] train: loss: 0.0586329
[Epoch 60; Iter   450/  960] train: loss: 0.0951652
[Epoch 60; Iter   480/  960] train: loss: 0.0058272
[Epoch 60; Iter   510/  960] train: loss: 0.0703255
[Epoch 60; Iter   540/  960] train: loss: 0.0327543
[Epoch 60; Iter   570/  960] train: loss: 0.0239863
[Epoch 60; Iter   600/  960] train: loss: 0.0510483
[Epoch 60; Iter   630/  960] train: loss: 0.0594497
[Epoch 60; Iter   660/  960] train: loss: 0.0285792
[Epoch 60; Iter   690/  960] train: loss: 0.0093968
[Epoch 60; Iter   720/  960] train: loss: 0.1015604
[Epoch 60; Iter   750/  960] train: loss: 0.0489260
[Epoch 60; Iter   780/  960] train: loss: 0.0320658
[Epoch 60; Iter   810/  960] train: loss: 0.0222688
[Epoch 60; Iter   840/  960] train: loss: 0.0243256
[Epoch 60; Iter   870/  960] train: loss: 0.0119680
[Epoch 60; Iter   900/  960] train: loss: 0.1962505
[Epoch 60; Iter   930/  960] train: loss: 0.0061723
[Epoch 60; Iter   960/  960] train: loss: 0.0059803
[Epoch 60] ogbg-molhiv: 0.724175 val loss: 0.216431
[Epoch 60] ogbg-molhiv: 0.751503 test loss: 0.167848
[Epoch 61; Iter    30/  960] train: loss: 0.0407113
[Epoch 61; Iter    60/  960] train: loss: 0.0229292
[Epoch 61; Iter    90/  960] train: loss: 0.0202527
[Epoch 61; Iter   120/  960] train: loss: 0.0073459
[Epoch 61; Iter   150/  960] train: loss: 0.0061680
[Epoch 61; Iter   180/  960] train: loss: 0.0032870
[Epoch 61; Iter   210/  960] train: loss: 0.0135231
[Epoch 61; Iter   240/  960] train: loss: 0.0158046
[Epoch 61; Iter   270/  960] train: loss: 0.0214907
[Epoch 61; Iter   300/  960] train: loss: 0.0480999
[Epoch 61; Iter   330/  960] train: loss: 0.0269425
[Epoch 61; Iter   360/  960] train: loss: 0.0209595
[Epoch 61; Iter   390/  960] train: loss: 0.0528245
[Epoch 61; Iter   420/  960] train: loss: 0.0029887
[Epoch 61; Iter   450/  960] train: loss: 0.0415583
[Epoch 61; Iter   480/  960] train: loss: 0.0182114
[Epoch 61; Iter   510/  960] train: loss: 0.0386031
[Epoch 61; Iter   540/  960] train: loss: 0.0035532
[Epoch 61; Iter   570/  960] train: loss: 0.0049910
[Epoch 61; Iter   600/  960] train: loss: 0.1127007
[Epoch 61; Iter   630/  960] train: loss: 0.0115199
[Epoch 61; Iter   660/  960] train: loss: 0.0151803
[Epoch 61; Iter   690/  960] train: loss: 0.0069022
[Epoch 61; Iter   720/  960] train: loss: 0.0173938
[Epoch 61; Iter   750/  960] train: loss: 0.0259404
[Epoch 61; Iter   780/  960] train: loss: 0.0041197
[Epoch 61; Iter   810/  960] train: loss: 0.0536548
[Epoch 61; Iter   840/  960] train: loss: 0.0520044
[Epoch 61; Iter   870/  960] train: loss: 0.0325799
[Epoch 61; Iter   900/  960] train: loss: 0.0049170
[Epoch 61; Iter   930/  960] train: loss: 0.1365707
[Epoch 61; Iter   960/  960] train: loss: 0.0012027
[Epoch 61] ogbg-molhiv: 0.705303 val loss: 0.347136
[Epoch 61] ogbg-molhiv: 0.752849 test loss: 0.285666
[Epoch 62; Iter    30/  960] train: loss: 0.0101327
[Epoch 62; Iter    60/  960] train: loss: 0.0353371
[Epoch 62; Iter    90/  960] train: loss: 0.0246701
[Epoch 62; Iter   120/  960] train: loss: 0.0603025
[Epoch 62; Iter   150/  960] train: loss: 0.0088434
[Epoch 62; Iter   180/  960] train: loss: 0.0057726
[Epoch 62; Iter   210/  960] train: loss: 0.0076498
[Epoch 62; Iter   240/  960] train: loss: 0.0082578
[Epoch 62; Iter   270/  960] train: loss: 0.0357777
[Epoch 62; Iter   300/  960] train: loss: 0.0128537
[Epoch 62; Iter   330/  960] train: loss: 0.0168774
[Epoch 62; Iter   360/  960] train: loss: 0.0714304
[Epoch 62; Iter   390/  960] train: loss: 0.0306211
[Epoch 62; Iter   420/  960] train: loss: 0.1704570
[Epoch 62; Iter   450/  960] train: loss: 0.0130740
[Epoch 62; Iter   480/  960] train: loss: 0.0192147
[Epoch 62; Iter   510/  960] train: loss: 0.0108213
[Epoch 62; Iter   540/  960] train: loss: 0.0563576
[Epoch 62; Iter   570/  960] train: loss: 0.0573769
[Epoch 62; Iter   600/  960] train: loss: 0.0101170
[Epoch 62; Iter   630/  960] train: loss: 0.0066381
[Epoch 62; Iter   660/  960] train: loss: 0.1328147
[Epoch 62; Iter   690/  960] train: loss: 0.0361102
[Epoch 62; Iter   720/  960] train: loss: 0.0498723
[Epoch 62; Iter   750/  960] train: loss: 0.0082817
[Epoch 62; Iter   780/  960] train: loss: 0.1242811
[Epoch 62; Iter   810/  960] train: loss: 0.0143802
[Epoch 62; Iter   840/  960] train: loss: 0.0098625
[Epoch 62; Iter   870/  960] train: loss: 0.2584169
[Epoch 62; Iter   900/  960] train: loss: 0.3249087
[Epoch 62; Iter   930/  960] train: loss: 0.1011357
[Epoch 62; Iter   960/  960] train: loss: 0.0045386
[Epoch 62] ogbg-molhiv: 0.721823 val loss: 0.603039
[Epoch 62] ogbg-molhiv: 0.752339 test loss: 0.364563
[Epoch 63; Iter    30/  960] train: loss: 0.1911795
[Epoch 63; Iter    60/  960] train: loss: 0.0132751
[Epoch 63; Iter    90/  960] train: loss: 0.2195633
[Epoch 63; Iter   120/  960] train: loss: 0.1069923
[Epoch 63; Iter   150/  960] train: loss: 0.0185831
[Epoch 63; Iter   180/  960] train: loss: 0.0162151
[Epoch 63; Iter   210/  960] train: loss: 0.0657966
[Epoch 63; Iter   240/  960] train: loss: 0.0220450
[Epoch 63; Iter   270/  960] train: loss: 0.0401716
[Epoch 63; Iter   300/  960] train: loss: 0.0657509
[Epoch 63; Iter   330/  960] train: loss: 0.0454589
[Epoch 63; Iter   360/  960] train: loss: 0.0100811
[Epoch 63; Iter   390/  960] train: loss: 0.0819515
[Epoch 63; Iter   420/  960] train: loss: 0.0646188
[Epoch 63; Iter   450/  960] train: loss: 0.0391769
[Epoch 63; Iter   480/  960] train: loss: 0.0771040
[Epoch 63; Iter   510/  960] train: loss: 0.0160295
[Epoch 63; Iter   540/  960] train: loss: 0.1405303
[Epoch 63; Iter   570/  960] train: loss: 0.0188264
[Epoch 63; Iter   600/  960] train: loss: 0.0464040
[Epoch 63; Iter   630/  960] train: loss: 0.0412726
[Epoch 63; Iter   660/  960] train: loss: 0.0129703
[Epoch 63; Iter   690/  960] train: loss: 0.1206029
[Epoch 63; Iter   720/  960] train: loss: 0.0737753
[Epoch 63; Iter   750/  960] train: loss: 0.0038419
[Epoch 63; Iter   780/  960] train: loss: 0.0052245
[Epoch 63; Iter   810/  960] train: loss: 0.1915015
[Epoch 63; Iter   840/  960] train: loss: 0.0080227
[Epoch 63; Iter   870/  960] train: loss: 0.0419100
[Epoch 63; Iter   900/  960] train: loss: 0.0337793
[Epoch 63; Iter   930/  960] train: loss: 0.0091755
[Epoch 63; Iter   960/  960] train: loss: 0.0102630
[Epoch 63] ogbg-molhiv: 0.717021 val loss: 0.318988
[Epoch 63] ogbg-molhiv: 0.737563 test loss: 0.307919
[Epoch 64; Iter    30/  960] train: loss: 0.0103599
[Epoch 64; Iter    60/  960] train: loss: 0.0470591
[Epoch 64; Iter    90/  960] train: loss: 0.0099175
[Epoch 64; Iter   120/  960] train: loss: 0.0877380
[Epoch 64; Iter   150/  960] train: loss: 0.0194496
[Epoch 64; Iter   180/  960] train: loss: 0.0154832
[Epoch 64; Iter   210/  960] train: loss: 0.0089011
[Epoch 64; Iter   240/  960] train: loss: 0.0024165
[Epoch 64; Iter   270/  960] train: loss: 0.0219249
[Epoch 64; Iter   300/  960] train: loss: 0.0122021
[Epoch 64; Iter   330/  960] train: loss: 0.0246327
[Epoch 64; Iter   360/  960] train: loss: 0.0033615
[Epoch 64; Iter   390/  960] train: loss: 0.0065550
[Epoch 63; Iter   484/  823] train: loss: 0.0262646
[Epoch 63; Iter   514/  823] train: loss: 0.1448291
[Epoch 63; Iter   544/  823] train: loss: 0.0569351
[Epoch 63; Iter   574/  823] train: loss: 0.0180216
[Epoch 63; Iter   604/  823] train: loss: 0.0790275
[Epoch 63; Iter   634/  823] train: loss: 0.1102718
[Epoch 63; Iter   664/  823] train: loss: 0.0079848
[Epoch 63; Iter   694/  823] train: loss: 0.0168924
[Epoch 63; Iter   724/  823] train: loss: 0.0060755
[Epoch 63; Iter   754/  823] train: loss: 0.0317825
[Epoch 63; Iter   784/  823] train: loss: 0.0309803
[Epoch 63; Iter   814/  823] train: loss: 0.0224242
[Epoch 63] ogbg-molhiv: 0.732424 val loss: 0.189690
[Epoch 63] ogbg-molhiv: 0.756060 test loss: 0.296007
[Epoch 64; Iter    21/  823] train: loss: 0.0179318
[Epoch 64; Iter    51/  823] train: loss: 0.1662595
[Epoch 64; Iter    81/  823] train: loss: 0.0156335
[Epoch 64; Iter   111/  823] train: loss: 0.0131802
[Epoch 64; Iter   141/  823] train: loss: 0.0327397
[Epoch 64; Iter   171/  823] train: loss: 0.0124668
[Epoch 64; Iter   201/  823] train: loss: 0.0099846
[Epoch 64; Iter   231/  823] train: loss: 0.0103830
[Epoch 64; Iter   261/  823] train: loss: 0.1528646
[Epoch 64; Iter   291/  823] train: loss: 0.0242311
[Epoch 64; Iter   321/  823] train: loss: 0.0282308
[Epoch 64; Iter   351/  823] train: loss: 0.0462795
[Epoch 64; Iter   381/  823] train: loss: 0.1094248
[Epoch 64; Iter   411/  823] train: loss: 0.0088622
[Epoch 64; Iter   441/  823] train: loss: 0.0888079
[Epoch 64; Iter   471/  823] train: loss: 0.0103813
[Epoch 64; Iter   501/  823] train: loss: 0.1450782
[Epoch 64; Iter   531/  823] train: loss: 0.1862652
[Epoch 64; Iter   561/  823] train: loss: 0.0713755
[Epoch 64; Iter   591/  823] train: loss: 0.0074928
[Epoch 64; Iter   621/  823] train: loss: 0.0252418
[Epoch 64; Iter   651/  823] train: loss: 0.1121877
[Epoch 64; Iter   681/  823] train: loss: 0.0303543
[Epoch 64; Iter   711/  823] train: loss: 0.1296187
[Epoch 64; Iter   741/  823] train: loss: 0.0198564
[Epoch 64; Iter   771/  823] train: loss: 0.1551727
[Epoch 64; Iter   801/  823] train: loss: 0.0568169
[Epoch 64] ogbg-molhiv: 0.735609 val loss: 0.250901
[Epoch 64] ogbg-molhiv: 0.759183 test loss: 0.345852
[Epoch 65; Iter     8/  823] train: loss: 0.0533334
[Epoch 65; Iter    38/  823] train: loss: 0.0213862
[Epoch 65; Iter    68/  823] train: loss: 0.0459909
[Epoch 65; Iter    98/  823] train: loss: 0.0389621
[Epoch 65; Iter   128/  823] train: loss: 0.0162249
[Epoch 65; Iter   158/  823] train: loss: 0.0406879
[Epoch 65; Iter   188/  823] train: loss: 0.0378570
[Epoch 65; Iter   218/  823] train: loss: 0.0196610
[Epoch 65; Iter   248/  823] train: loss: 0.1684901
[Epoch 65; Iter   278/  823] train: loss: 0.1775209
[Epoch 65; Iter   308/  823] train: loss: 0.0092487
[Epoch 65; Iter   338/  823] train: loss: 0.0285530
[Epoch 65; Iter   368/  823] train: loss: 0.0131450
[Epoch 65; Iter   398/  823] train: loss: 0.0591196
[Epoch 65; Iter   428/  823] train: loss: 0.0031094
[Epoch 65; Iter   458/  823] train: loss: 0.0127284
[Epoch 65; Iter   488/  823] train: loss: 0.1002290
[Epoch 65; Iter   518/  823] train: loss: 0.0141874
[Epoch 65; Iter   548/  823] train: loss: 0.0110794
[Epoch 65; Iter   578/  823] train: loss: 0.0475992
[Epoch 65; Iter   608/  823] train: loss: 0.1125349
[Epoch 65; Iter   638/  823] train: loss: 0.0068317
[Epoch 65; Iter   668/  823] train: loss: 0.0918237
[Epoch 65; Iter   698/  823] train: loss: 0.2940392
[Epoch 65; Iter   728/  823] train: loss: 0.0187456
[Epoch 65; Iter   758/  823] train: loss: 0.0075186
[Epoch 65; Iter   788/  823] train: loss: 0.0587831
[Epoch 65; Iter   818/  823] train: loss: 0.0233485
[Epoch 65] ogbg-molhiv: 0.733197 val loss: 0.206162
[Epoch 65] ogbg-molhiv: 0.755362 test loss: 0.213986
[Epoch 66; Iter    25/  823] train: loss: 0.0088853
[Epoch 66; Iter    55/  823] train: loss: 0.0126274
[Epoch 66; Iter    85/  823] train: loss: 0.0670944
[Epoch 66; Iter   115/  823] train: loss: 0.0145456
[Epoch 66; Iter   145/  823] train: loss: 0.0031165
[Epoch 66; Iter   175/  823] train: loss: 0.0600007
[Epoch 66; Iter   205/  823] train: loss: 0.0637868
[Epoch 66; Iter   235/  823] train: loss: 0.0067108
[Epoch 66; Iter   265/  823] train: loss: 0.0177874
[Epoch 66; Iter   295/  823] train: loss: 0.0044728
[Epoch 66; Iter   325/  823] train: loss: 0.0170046
[Epoch 66; Iter   355/  823] train: loss: 0.0263425
[Epoch 66; Iter   385/  823] train: loss: 0.0801019
[Epoch 66; Iter   415/  823] train: loss: 0.0472786
[Epoch 66; Iter   445/  823] train: loss: 0.1568839
[Epoch 66; Iter   475/  823] train: loss: 0.0069803
[Epoch 66; Iter   505/  823] train: loss: 0.0247225
[Epoch 66; Iter   535/  823] train: loss: 0.0070990
[Epoch 66; Iter   565/  823] train: loss: 0.0826866
[Epoch 66; Iter   595/  823] train: loss: 0.0063492
[Epoch 66; Iter   625/  823] train: loss: 0.1216262
[Epoch 66; Iter   655/  823] train: loss: 0.0146336
[Epoch 66; Iter   685/  823] train: loss: 0.0192982
[Epoch 66; Iter   715/  823] train: loss: 0.0539466
[Epoch 66; Iter   745/  823] train: loss: 0.0074399
[Epoch 66; Iter   775/  823] train: loss: 0.0165722
[Epoch 66; Iter   805/  823] train: loss: 0.0121230
[Epoch 66] ogbg-molhiv: 0.740438 val loss: 0.194626
[Epoch 66] ogbg-molhiv: 0.760057 test loss: 0.197004
[Epoch 67; Iter    12/  823] train: loss: 0.0276811
[Epoch 67; Iter    42/  823] train: loss: 0.0312562
[Epoch 67; Iter    72/  823] train: loss: 0.1393650
[Epoch 67; Iter   102/  823] train: loss: 0.0733116
[Epoch 67; Iter   132/  823] train: loss: 0.1639544
[Epoch 67; Iter   162/  823] train: loss: 0.0106988
[Epoch 67; Iter   192/  823] train: loss: 0.0431375
[Epoch 67; Iter   222/  823] train: loss: 0.0958791
[Epoch 67; Iter   252/  823] train: loss: 0.0727277
[Epoch 67; Iter   282/  823] train: loss: 0.0337056
[Epoch 67; Iter   312/  823] train: loss: 0.2004268
[Epoch 67; Iter   342/  823] train: loss: 0.0627214
[Epoch 67; Iter   372/  823] train: loss: 0.0421451
[Epoch 67; Iter   402/  823] train: loss: 0.0218116
[Epoch 67; Iter   432/  823] train: loss: 0.0102149
[Epoch 67; Iter   462/  823] train: loss: 0.0056510
[Epoch 67; Iter   492/  823] train: loss: 0.0143572
[Epoch 67; Iter   522/  823] train: loss: 0.0076966
[Epoch 67; Iter   552/  823] train: loss: 0.1274027
[Epoch 67; Iter   582/  823] train: loss: 0.0618520
[Epoch 67; Iter   612/  823] train: loss: 0.0170257
[Epoch 67; Iter   642/  823] train: loss: 0.0063202
[Epoch 67; Iter   672/  823] train: loss: 0.1873843
[Epoch 67; Iter   702/  823] train: loss: 0.0080272
[Epoch 67; Iter   732/  823] train: loss: 0.0056284
[Epoch 67; Iter   762/  823] train: loss: 0.0386409
[Epoch 67; Iter   792/  823] train: loss: 0.0229770
[Epoch 67; Iter   822/  823] train: loss: 0.0200440
[Epoch 67] ogbg-molhiv: 0.737071 val loss: 0.258209
[Epoch 67] ogbg-molhiv: 0.747102 test loss: 0.214335
[Epoch 68; Iter    29/  823] train: loss: 0.0534829
[Epoch 68; Iter    59/  823] train: loss: 0.0085408
[Epoch 68; Iter    89/  823] train: loss: 0.1116931
[Epoch 68; Iter   119/  823] train: loss: 0.0233113
[Epoch 68; Iter   149/  823] train: loss: 0.0658530
[Epoch 68; Iter   179/  823] train: loss: 0.0552235
[Epoch 68; Iter   209/  823] train: loss: 0.0219499
[Epoch 68; Iter   239/  823] train: loss: 0.0534511
[Epoch 68; Iter   269/  823] train: loss: 0.0122517
[Epoch 68; Iter   299/  823] train: loss: 0.0037566
[Epoch 68; Iter   329/  823] train: loss: 0.0365099
[Epoch 68; Iter   359/  823] train: loss: 0.0330411
[Epoch 68; Iter   389/  823] train: loss: 0.0325859
[Epoch 68; Iter   419/  823] train: loss: 0.0507033
[Epoch 68; Iter   449/  823] train: loss: 0.1792067
[Epoch 68; Iter   479/  823] train: loss: 0.0058229
[Epoch 68; Iter   509/  823] train: loss: 0.0350584
[Epoch 68; Iter   539/  823] train: loss: 0.0048501
[Epoch 68; Iter   569/  823] train: loss: 0.2449201
[Epoch 68; Iter   599/  823] train: loss: 0.0051191
[Epoch 68; Iter   629/  823] train: loss: 0.0565726
[Epoch 68; Iter   659/  823] train: loss: 0.0375287
[Epoch 68; Iter   689/  823] train: loss: 0.0145229
[Epoch 68; Iter   719/  823] train: loss: 0.0538086
[Epoch 68; Iter   749/  823] train: loss: 0.0074965
[Epoch 63; Iter   484/  823] train: loss: 0.0079905
[Epoch 63; Iter   514/  823] train: loss: 0.0444086
[Epoch 63; Iter   544/  823] train: loss: 0.0365103
[Epoch 63; Iter   574/  823] train: loss: 0.0284693
[Epoch 63; Iter   604/  823] train: loss: 0.0070524
[Epoch 63; Iter   634/  823] train: loss: 0.0377248
[Epoch 63; Iter   664/  823] train: loss: 0.0374106
[Epoch 63; Iter   694/  823] train: loss: 0.0102765
[Epoch 63; Iter   724/  823] train: loss: 0.0174012
[Epoch 63; Iter   754/  823] train: loss: 0.0523251
[Epoch 63; Iter   784/  823] train: loss: 0.0366496
[Epoch 63; Iter   814/  823] train: loss: 0.0463131
[Epoch 63] ogbg-molhiv: 0.711024 val loss: 0.305541
[Epoch 63] ogbg-molhiv: 0.742553 test loss: 0.199242
[Epoch 64; Iter    21/  823] train: loss: 0.0192083
[Epoch 64; Iter    51/  823] train: loss: 0.0941136
[Epoch 64; Iter    81/  823] train: loss: 0.0017394
[Epoch 64; Iter   111/  823] train: loss: 0.0104245
[Epoch 64; Iter   141/  823] train: loss: 0.0171721
[Epoch 64; Iter   171/  823] train: loss: 0.0118459
[Epoch 64; Iter   201/  823] train: loss: 0.0075381
[Epoch 64; Iter   231/  823] train: loss: 0.0103244
[Epoch 64; Iter   261/  823] train: loss: 0.0344289
[Epoch 64; Iter   291/  823] train: loss: 0.0061248
[Epoch 64; Iter   321/  823] train: loss: 0.0051166
[Epoch 64; Iter   351/  823] train: loss: 0.0051986
[Epoch 64; Iter   381/  823] train: loss: 0.0171603
[Epoch 64; Iter   411/  823] train: loss: 0.0051550
[Epoch 64; Iter   441/  823] train: loss: 0.0871497
[Epoch 64; Iter   471/  823] train: loss: 0.0854804
[Epoch 64; Iter   501/  823] train: loss: 0.0086806
[Epoch 64; Iter   531/  823] train: loss: 0.0062655
[Epoch 64; Iter   561/  823] train: loss: 0.0577204
[Epoch 64; Iter   591/  823] train: loss: 0.0082795
[Epoch 64; Iter   621/  823] train: loss: 0.0197240
[Epoch 64; Iter   651/  823] train: loss: 0.1533509
[Epoch 64; Iter   681/  823] train: loss: 0.0043825
[Epoch 64; Iter   711/  823] train: loss: 0.0376750
[Epoch 64; Iter   741/  823] train: loss: 0.0090268
[Epoch 64; Iter   771/  823] train: loss: 0.1357676
[Epoch 64; Iter   801/  823] train: loss: 0.0193309
[Epoch 64] ogbg-molhiv: 0.701807 val loss: 0.290753
[Epoch 64] ogbg-molhiv: 0.750911 test loss: 0.176399
[Epoch 65; Iter     8/  823] train: loss: 0.0144271
[Epoch 65; Iter    38/  823] train: loss: 0.0151244
[Epoch 65; Iter    68/  823] train: loss: 0.0017787
[Epoch 65; Iter    98/  823] train: loss: 0.0148734
[Epoch 65; Iter   128/  823] train: loss: 0.0127653
[Epoch 65; Iter   158/  823] train: loss: 0.0020344
[Epoch 65; Iter   188/  823] train: loss: 0.0022637
[Epoch 65; Iter   218/  823] train: loss: 0.0054395
[Epoch 65; Iter   248/  823] train: loss: 0.0224858
[Epoch 65; Iter   278/  823] train: loss: 0.0146858
[Epoch 65; Iter   308/  823] train: loss: 0.0056451
[Epoch 65; Iter   338/  823] train: loss: 0.0128491
[Epoch 65; Iter   368/  823] train: loss: 0.0031335
[Epoch 65; Iter   398/  823] train: loss: 0.0210712
[Epoch 65; Iter   428/  823] train: loss: 0.0022434
[Epoch 65; Iter   458/  823] train: loss: 0.0233920
[Epoch 65; Iter   488/  823] train: loss: 0.0107650
[Epoch 65; Iter   518/  823] train: loss: 0.0206508
[Epoch 65; Iter   548/  823] train: loss: 0.0431087
[Epoch 65; Iter   578/  823] train: loss: 0.0106445
[Epoch 65; Iter   608/  823] train: loss: 0.0076346
[Epoch 65; Iter   638/  823] train: loss: 0.0074180
[Epoch 65; Iter   668/  823] train: loss: 0.0076558
[Epoch 65; Iter   698/  823] train: loss: 0.0783441
[Epoch 65; Iter   728/  823] train: loss: 0.0048120
[Epoch 65; Iter   758/  823] train: loss: 0.0533613
[Epoch 65; Iter   788/  823] train: loss: 0.0055647
[Epoch 65; Iter   818/  823] train: loss: 0.1248906
[Epoch 65] ogbg-molhiv: 0.711980 val loss: 0.260930
[Epoch 65] ogbg-molhiv: 0.753930 test loss: 0.157279
[Epoch 66; Iter    25/  823] train: loss: 0.0060158
[Epoch 66; Iter    55/  823] train: loss: 0.0052477
[Epoch 66; Iter    85/  823] train: loss: 0.0285578
[Epoch 66; Iter   115/  823] train: loss: 0.0072545
[Epoch 66; Iter   145/  823] train: loss: 0.0036244
[Epoch 66; Iter   175/  823] train: loss: 0.0441275
[Epoch 66; Iter   205/  823] train: loss: 0.0122333
[Epoch 66; Iter   235/  823] train: loss: 0.1767770
[Epoch 66; Iter   265/  823] train: loss: 0.0056630
[Epoch 66; Iter   295/  823] train: loss: 0.0292914
[Epoch 66; Iter   325/  823] train: loss: 0.0953428
[Epoch 66; Iter   355/  823] train: loss: 0.0054946
[Epoch 66; Iter   385/  823] train: loss: 0.0155099
[Epoch 66; Iter   415/  823] train: loss: 0.0682748
[Epoch 66; Iter   445/  823] train: loss: 0.0163313
[Epoch 66; Iter   475/  823] train: loss: 0.0746936
[Epoch 66; Iter   505/  823] train: loss: 0.0673058
[Epoch 66; Iter   535/  823] train: loss: 0.0592087
[Epoch 66; Iter   565/  823] train: loss: 0.0151283
[Epoch 66; Iter   595/  823] train: loss: 0.0130325
[Epoch 66; Iter   625/  823] train: loss: 0.0540559
[Epoch 66; Iter   655/  823] train: loss: 0.0217536
[Epoch 66; Iter   685/  823] train: loss: 0.0144806
[Epoch 66; Iter   715/  823] train: loss: 0.0366308
[Epoch 66; Iter   745/  823] train: loss: 0.0468866
[Epoch 66; Iter   775/  823] train: loss: 0.0019362
[Epoch 66; Iter   805/  823] train: loss: 0.0168419
[Epoch 66] ogbg-molhiv: 0.707053 val loss: 0.303173
[Epoch 66] ogbg-molhiv: 0.749595 test loss: 0.168648
[Epoch 67; Iter    12/  823] train: loss: 0.0265936
[Epoch 67; Iter    42/  823] train: loss: 0.0028205
[Epoch 67; Iter    72/  823] train: loss: 0.0224564
[Epoch 67; Iter   102/  823] train: loss: 0.0788490
[Epoch 67; Iter   132/  823] train: loss: 0.0021116
[Epoch 67; Iter   162/  823] train: loss: 0.0219095
[Epoch 67; Iter   192/  823] train: loss: 0.0128000
[Epoch 67; Iter   222/  823] train: loss: 0.0284993
[Epoch 67; Iter   252/  823] train: loss: 0.0254290
[Epoch 67; Iter   282/  823] train: loss: 0.0017009
[Epoch 67; Iter   312/  823] train: loss: 0.0046185
[Epoch 67; Iter   342/  823] train: loss: 0.0761449
[Epoch 67; Iter   372/  823] train: loss: 0.0440331
[Epoch 67; Iter   402/  823] train: loss: 0.0099020
[Epoch 67; Iter   432/  823] train: loss: 0.0174239
[Epoch 67; Iter   462/  823] train: loss: 0.0179585
[Epoch 67; Iter   492/  823] train: loss: 0.0179742
[Epoch 67; Iter   522/  823] train: loss: 0.0540242
[Epoch 67; Iter   552/  823] train: loss: 0.0168822
[Epoch 67; Iter   582/  823] train: loss: 0.0116078
[Epoch 67; Iter   612/  823] train: loss: 0.2045088
[Epoch 67; Iter   642/  823] train: loss: 0.0118078
[Epoch 67; Iter   672/  823] train: loss: 0.0152848
[Epoch 67; Iter   702/  823] train: loss: 0.0123120
[Epoch 67; Iter   732/  823] train: loss: 0.0086117
[Epoch 67; Iter   762/  823] train: loss: 0.0270855
[Epoch 67; Iter   792/  823] train: loss: 0.0038373
[Epoch 67; Iter   822/  823] train: loss: 0.2107713
[Epoch 67] ogbg-molhiv: 0.699058 val loss: 0.294851
[Epoch 67] ogbg-molhiv: 0.737385 test loss: 0.201230
[Epoch 68; Iter    29/  823] train: loss: 0.0022331
[Epoch 68; Iter    59/  823] train: loss: 0.0188668
[Epoch 68; Iter    89/  823] train: loss: 0.0233087
[Epoch 68; Iter   119/  823] train: loss: 0.0436316
[Epoch 68; Iter   149/  823] train: loss: 0.0038433
[Epoch 68; Iter   179/  823] train: loss: 0.0036636
[Epoch 68; Iter   209/  823] train: loss: 0.0103082
[Epoch 68; Iter   239/  823] train: loss: 0.0414373
[Epoch 68; Iter   269/  823] train: loss: 0.0082716
[Epoch 68; Iter   299/  823] train: loss: 0.0391923
[Epoch 68; Iter   329/  823] train: loss: 0.0086491
[Epoch 68; Iter   359/  823] train: loss: 0.0231790
[Epoch 68; Iter   389/  823] train: loss: 0.0043522
[Epoch 68; Iter   419/  823] train: loss: 0.0171802
[Epoch 68; Iter   449/  823] train: loss: 0.0520654
[Epoch 68; Iter   479/  823] train: loss: 0.0309910
[Epoch 68; Iter   509/  823] train: loss: 0.0137854
[Epoch 68; Iter   539/  823] train: loss: 0.0286238
[Epoch 68; Iter   569/  823] train: loss: 0.0073361
[Epoch 68; Iter   599/  823] train: loss: 0.0026761
[Epoch 68; Iter   629/  823] train: loss: 0.0325765
[Epoch 68; Iter   659/  823] train: loss: 0.0200545
[Epoch 68; Iter   689/  823] train: loss: 0.0020234
[Epoch 68; Iter   719/  823] train: loss: 0.0378081
[Epoch 68; Iter   749/  823] train: loss: 0.0599068
[Epoch 60] ogbg-molhiv: 0.745021 val loss: 0.151345
[Epoch 60] ogbg-molhiv: 0.717783 test loss: 0.411185
[Epoch 61; Iter    30/ 1097] train: loss: 0.0174839
[Epoch 61; Iter    60/ 1097] train: loss: 0.0068038
[Epoch 61; Iter    90/ 1097] train: loss: 0.0429584
[Epoch 61; Iter   120/ 1097] train: loss: 0.0167618
[Epoch 61; Iter   150/ 1097] train: loss: 0.2523325
[Epoch 61; Iter   180/ 1097] train: loss: 0.0649622
[Epoch 61; Iter   210/ 1097] train: loss: 0.0043978
[Epoch 61; Iter   240/ 1097] train: loss: 0.0181489
[Epoch 61; Iter   270/ 1097] train: loss: 0.0313129
[Epoch 61; Iter   300/ 1097] train: loss: 0.0581125
[Epoch 61; Iter   330/ 1097] train: loss: 0.0136577
[Epoch 61; Iter   360/ 1097] train: loss: 0.0049900
[Epoch 61; Iter   390/ 1097] train: loss: 0.0467432
[Epoch 61; Iter   420/ 1097] train: loss: 0.0120669
[Epoch 61; Iter   450/ 1097] train: loss: 0.1723832
[Epoch 61; Iter   480/ 1097] train: loss: 0.0054914
[Epoch 61; Iter   510/ 1097] train: loss: 0.0373420
[Epoch 61; Iter   540/ 1097] train: loss: 0.0055055
[Epoch 61; Iter   570/ 1097] train: loss: 0.1065279
[Epoch 61; Iter   600/ 1097] train: loss: 0.0157678
[Epoch 61; Iter   630/ 1097] train: loss: 0.0298143
[Epoch 61; Iter   660/ 1097] train: loss: 0.0636125
[Epoch 61; Iter   690/ 1097] train: loss: 0.0078165
[Epoch 61; Iter   720/ 1097] train: loss: 0.2599659
[Epoch 61; Iter   750/ 1097] train: loss: 0.0534141
[Epoch 61; Iter   780/ 1097] train: loss: 0.0053226
[Epoch 61; Iter   810/ 1097] train: loss: 0.0045376
[Epoch 61; Iter   840/ 1097] train: loss: 0.0225930
[Epoch 61; Iter   870/ 1097] train: loss: 0.0541034
[Epoch 61; Iter   900/ 1097] train: loss: 0.0938442
[Epoch 61; Iter   930/ 1097] train: loss: 0.0312891
[Epoch 61; Iter   960/ 1097] train: loss: 0.0156618
[Epoch 61; Iter   990/ 1097] train: loss: 0.0085713
[Epoch 61; Iter  1020/ 1097] train: loss: 0.1087558
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0098927
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0320039
[Epoch 61] ogbg-molhiv: 0.778660 val loss: 0.192438
[Epoch 61] ogbg-molhiv: 0.733944 test loss: 0.442199
[Epoch 62; Iter    13/ 1097] train: loss: 0.0159546
[Epoch 62; Iter    43/ 1097] train: loss: 0.0562265
[Epoch 62; Iter    73/ 1097] train: loss: 0.0170199
[Epoch 62; Iter   103/ 1097] train: loss: 0.0487176
[Epoch 62; Iter   133/ 1097] train: loss: 0.0099958
[Epoch 62; Iter   163/ 1097] train: loss: 0.0230348
[Epoch 62; Iter   193/ 1097] train: loss: 0.0038662
[Epoch 62; Iter   223/ 1097] train: loss: 0.0074847
[Epoch 62; Iter   253/ 1097] train: loss: 0.0052545
[Epoch 62; Iter   283/ 1097] train: loss: 0.0129902
[Epoch 62; Iter   313/ 1097] train: loss: 0.0611596
[Epoch 62; Iter   343/ 1097] train: loss: 0.0059920
[Epoch 62; Iter   373/ 1097] train: loss: 0.0950661
[Epoch 62; Iter   403/ 1097] train: loss: 0.0064361
[Epoch 62; Iter   433/ 1097] train: loss: 0.0447947
[Epoch 62; Iter   463/ 1097] train: loss: 0.1325006
[Epoch 62; Iter   493/ 1097] train: loss: 0.1060032
[Epoch 62; Iter   523/ 1097] train: loss: 0.0102915
[Epoch 62; Iter   553/ 1097] train: loss: 0.0222373
[Epoch 62; Iter   583/ 1097] train: loss: 0.0126262
[Epoch 62; Iter   613/ 1097] train: loss: 0.0229762
[Epoch 62; Iter   643/ 1097] train: loss: 0.0082814
[Epoch 62; Iter   673/ 1097] train: loss: 0.0618698
[Epoch 62; Iter   703/ 1097] train: loss: 0.0505253
[Epoch 62; Iter   733/ 1097] train: loss: 0.0427243
[Epoch 62; Iter   763/ 1097] train: loss: 0.0092163
[Epoch 62; Iter   793/ 1097] train: loss: 0.0828044
[Epoch 62; Iter   823/ 1097] train: loss: 0.0598108
[Epoch 62; Iter   853/ 1097] train: loss: 0.0556888
[Epoch 62; Iter   883/ 1097] train: loss: 0.0054847
[Epoch 62; Iter   913/ 1097] train: loss: 0.0383212
[Epoch 62; Iter   943/ 1097] train: loss: 0.0395515
[Epoch 62; Iter   973/ 1097] train: loss: 0.0366199
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0413043
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0021353
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0704086
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0207493
[Epoch 62] ogbg-molhiv: 0.765104 val loss: 0.207221
[Epoch 62] ogbg-molhiv: 0.720232 test loss: 0.447380
[Epoch 63; Iter    26/ 1097] train: loss: 0.0697056
[Epoch 63; Iter    56/ 1097] train: loss: 0.0197558
[Epoch 63; Iter    86/ 1097] train: loss: 0.1360804
[Epoch 63; Iter   116/ 1097] train: loss: 0.0138346
[Epoch 63; Iter   146/ 1097] train: loss: 0.0714796
[Epoch 63; Iter   176/ 1097] train: loss: 0.0209770
[Epoch 63; Iter   206/ 1097] train: loss: 0.0090883
[Epoch 63; Iter   236/ 1097] train: loss: 0.0402683
[Epoch 63; Iter   266/ 1097] train: loss: 0.0155661
[Epoch 63; Iter   296/ 1097] train: loss: 0.0081211
[Epoch 63; Iter   326/ 1097] train: loss: 0.0144163
[Epoch 63; Iter   356/ 1097] train: loss: 0.0514443
[Epoch 63; Iter   386/ 1097] train: loss: 0.0158011
[Epoch 63; Iter   416/ 1097] train: loss: 0.0232980
[Epoch 63; Iter   446/ 1097] train: loss: 0.0060687
[Epoch 63; Iter   476/ 1097] train: loss: 0.0163580
[Epoch 63; Iter   506/ 1097] train: loss: 0.0539714
[Epoch 63; Iter   536/ 1097] train: loss: 0.0105157
[Epoch 63; Iter   566/ 1097] train: loss: 0.1520970
[Epoch 63; Iter   596/ 1097] train: loss: 0.0109786
[Epoch 63; Iter   626/ 1097] train: loss: 0.0027549
[Epoch 63; Iter   656/ 1097] train: loss: 0.0959735
[Epoch 63; Iter   686/ 1097] train: loss: 0.0064543
[Epoch 63; Iter   716/ 1097] train: loss: 0.0297490
[Epoch 63; Iter   746/ 1097] train: loss: 0.1265061
[Epoch 63; Iter   776/ 1097] train: loss: 0.0768092
[Epoch 63; Iter   806/ 1097] train: loss: 0.0656715
[Epoch 63; Iter   836/ 1097] train: loss: 0.0063941
[Epoch 63; Iter   866/ 1097] train: loss: 0.0120654
[Epoch 63; Iter   896/ 1097] train: loss: 0.0471309
[Epoch 63; Iter   926/ 1097] train: loss: 0.0218796
[Epoch 63; Iter   956/ 1097] train: loss: 0.0193288
[Epoch 63; Iter   986/ 1097] train: loss: 0.0054859
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0173541
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0502842
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0164295
[Epoch 63] ogbg-molhiv: 0.745245 val loss: 0.238750
[Epoch 63] ogbg-molhiv: 0.710601 test loss: 0.502737
[Epoch 64; Iter     9/ 1097] train: loss: 0.0245945
[Epoch 64; Iter    39/ 1097] train: loss: 0.2291598
[Epoch 64; Iter    69/ 1097] train: loss: 0.0402831
[Epoch 64; Iter    99/ 1097] train: loss: 0.0507728
[Epoch 64; Iter   129/ 1097] train: loss: 0.0134059
[Epoch 64; Iter   159/ 1097] train: loss: 0.0068602
[Epoch 64; Iter   189/ 1097] train: loss: 0.0212223
[Epoch 64; Iter   219/ 1097] train: loss: 0.0463809
[Epoch 64; Iter   249/ 1097] train: loss: 0.0056738
[Epoch 64; Iter   279/ 1097] train: loss: 0.0041628
[Epoch 64; Iter   309/ 1097] train: loss: 0.0145558
[Epoch 64; Iter   339/ 1097] train: loss: 0.0117701
[Epoch 64; Iter   369/ 1097] train: loss: 0.0390796
[Epoch 64; Iter   399/ 1097] train: loss: 0.0167031
[Epoch 64; Iter   429/ 1097] train: loss: 0.0484169
[Epoch 64; Iter   459/ 1097] train: loss: 0.0404085
[Epoch 64; Iter   489/ 1097] train: loss: 0.0182114
[Epoch 64; Iter   519/ 1097] train: loss: 0.0961024
[Epoch 64; Iter   549/ 1097] train: loss: 0.0071591
[Epoch 64; Iter   579/ 1097] train: loss: 0.0407258
[Epoch 64; Iter   609/ 1097] train: loss: 0.0197545
[Epoch 64; Iter   639/ 1097] train: loss: 0.0107412
[Epoch 64; Iter   669/ 1097] train: loss: 0.0540523
[Epoch 64; Iter   699/ 1097] train: loss: 0.0141784
[Epoch 64; Iter   729/ 1097] train: loss: 0.0071278
[Epoch 64; Iter   759/ 1097] train: loss: 0.0213215
[Epoch 64; Iter   789/ 1097] train: loss: 0.0137046
[Epoch 64; Iter   819/ 1097] train: loss: 0.0030497
[Epoch 64; Iter   849/ 1097] train: loss: 0.0743326
[Epoch 64; Iter   879/ 1097] train: loss: 0.0183448
[Epoch 64; Iter   909/ 1097] train: loss: 0.0885491
[Epoch 64; Iter   939/ 1097] train: loss: 0.0879216
[Epoch 64; Iter   969/ 1097] train: loss: 0.0543983
[Epoch 64; Iter   999/ 1097] train: loss: 0.0440560
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0521026
[Epoch 64; Iter  1059/ 1097] train: loss: 0.1483194
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0397104
[Epoch 64] ogbg-molhiv: 0.771856 val loss: 0.208310
[Epoch 64] ogbg-molhiv: 0.735876 test loss: 0.430925
[Epoch 65; Iter    22/ 1097] train: loss: 0.1283498
[Epoch 60] ogbg-molhiv: 0.796722 val loss: 0.098195
[Epoch 60] ogbg-molhiv: 0.740215 test loss: 0.159294
[Epoch 61; Iter    30/ 1097] train: loss: 0.0862822
[Epoch 61; Iter    60/ 1097] train: loss: 0.0091960
[Epoch 61; Iter    90/ 1097] train: loss: 0.0203180
[Epoch 61; Iter   120/ 1097] train: loss: 0.0744809
[Epoch 61; Iter   150/ 1097] train: loss: 0.0406027
[Epoch 61; Iter   180/ 1097] train: loss: 0.0153914
[Epoch 61; Iter   210/ 1097] train: loss: 0.1716123
[Epoch 61; Iter   240/ 1097] train: loss: 0.1532519
[Epoch 61; Iter   270/ 1097] train: loss: 0.0108914
[Epoch 61; Iter   300/ 1097] train: loss: 0.0118481
[Epoch 61; Iter   330/ 1097] train: loss: 0.0302663
[Epoch 61; Iter   360/ 1097] train: loss: 0.0096299
[Epoch 61; Iter   390/ 1097] train: loss: 0.0143618
[Epoch 61; Iter   420/ 1097] train: loss: 0.0067626
[Epoch 61; Iter   450/ 1097] train: loss: 0.0823204
[Epoch 61; Iter   480/ 1097] train: loss: 0.0148457
[Epoch 61; Iter   510/ 1097] train: loss: 0.0365900
[Epoch 61; Iter   540/ 1097] train: loss: 0.0355217
[Epoch 61; Iter   570/ 1097] train: loss: 0.0777856
[Epoch 61; Iter   600/ 1097] train: loss: 0.0219708
[Epoch 61; Iter   630/ 1097] train: loss: 0.0222833
[Epoch 61; Iter   660/ 1097] train: loss: 0.0202236
[Epoch 61; Iter   690/ 1097] train: loss: 0.1728850
[Epoch 61; Iter   720/ 1097] train: loss: 0.0218098
[Epoch 61; Iter   750/ 1097] train: loss: 0.0128665
[Epoch 61; Iter   780/ 1097] train: loss: 0.0228163
[Epoch 61; Iter   810/ 1097] train: loss: 0.0398402
[Epoch 61; Iter   840/ 1097] train: loss: 0.0540516
[Epoch 61; Iter   870/ 1097] train: loss: 0.0108966
[Epoch 61; Iter   900/ 1097] train: loss: 0.0238786
[Epoch 61; Iter   930/ 1097] train: loss: 0.0800336
[Epoch 61; Iter   960/ 1097] train: loss: 0.0105354
[Epoch 61; Iter   990/ 1097] train: loss: 0.0196911
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0131920
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0429054
[Epoch 61; Iter  1080/ 1097] train: loss: 0.1667402
[Epoch 61] ogbg-molhiv: 0.790497 val loss: 0.104469
[Epoch 61] ogbg-molhiv: 0.743809 test loss: 0.162543
[Epoch 62; Iter    13/ 1097] train: loss: 0.0114650
[Epoch 62; Iter    43/ 1097] train: loss: 0.0631729
[Epoch 62; Iter    73/ 1097] train: loss: 0.0277753
[Epoch 62; Iter   103/ 1097] train: loss: 0.0143374
[Epoch 62; Iter   133/ 1097] train: loss: 0.3048471
[Epoch 62; Iter   163/ 1097] train: loss: 0.1239783
[Epoch 62; Iter   193/ 1097] train: loss: 0.0592490
[Epoch 62; Iter   223/ 1097] train: loss: 0.0673709
[Epoch 62; Iter   253/ 1097] train: loss: 0.1236373
[Epoch 62; Iter   283/ 1097] train: loss: 0.0137843
[Epoch 62; Iter   313/ 1097] train: loss: 0.2447046
[Epoch 62; Iter   343/ 1097] train: loss: 0.0217119
[Epoch 62; Iter   373/ 1097] train: loss: 0.0530374
[Epoch 62; Iter   403/ 1097] train: loss: 0.0284615
[Epoch 62; Iter   433/ 1097] train: loss: 0.0094816
[Epoch 62; Iter   463/ 1097] train: loss: 0.0145616
[Epoch 62; Iter   493/ 1097] train: loss: 0.0102008
[Epoch 62; Iter   523/ 1097] train: loss: 0.0167183
[Epoch 62; Iter   553/ 1097] train: loss: 0.0175918
[Epoch 62; Iter   583/ 1097] train: loss: 0.0243449
[Epoch 62; Iter   613/ 1097] train: loss: 0.0093894
[Epoch 62; Iter   643/ 1097] train: loss: 0.0216720
[Epoch 62; Iter   673/ 1097] train: loss: 0.0075296
[Epoch 62; Iter   703/ 1097] train: loss: 0.0082672
[Epoch 62; Iter   733/ 1097] train: loss: 0.0107996
[Epoch 62; Iter   763/ 1097] train: loss: 0.0249601
[Epoch 62; Iter   793/ 1097] train: loss: 0.1157230
[Epoch 62; Iter   823/ 1097] train: loss: 0.0385693
[Epoch 62; Iter   853/ 1097] train: loss: 0.1040615
[Epoch 62; Iter   883/ 1097] train: loss: 0.1237951
[Epoch 62; Iter   913/ 1097] train: loss: 0.0155266
[Epoch 62; Iter   943/ 1097] train: loss: 0.0090885
[Epoch 62; Iter   973/ 1097] train: loss: 0.0145979
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0734811
[Epoch 62; Iter  1033/ 1097] train: loss: 0.1296768
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0105302
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0531500
[Epoch 62] ogbg-molhiv: 0.804710 val loss: 0.122994
[Epoch 62] ogbg-molhiv: 0.746563 test loss: 0.164913
[Epoch 63; Iter    26/ 1097] train: loss: 0.0602090
[Epoch 63; Iter    56/ 1097] train: loss: 0.0845344
[Epoch 63; Iter    86/ 1097] train: loss: 0.0109491
[Epoch 63; Iter   116/ 1097] train: loss: 0.0305924
[Epoch 63; Iter   146/ 1097] train: loss: 0.0305230
[Epoch 63; Iter   176/ 1097] train: loss: 0.0225723
[Epoch 63; Iter   206/ 1097] train: loss: 0.0973067
[Epoch 63; Iter   236/ 1097] train: loss: 0.0146275
[Epoch 63; Iter   266/ 1097] train: loss: 0.0473966
[Epoch 63; Iter   296/ 1097] train: loss: 0.0971886
[Epoch 63; Iter   326/ 1097] train: loss: 0.0260371
[Epoch 63; Iter   356/ 1097] train: loss: 0.2980415
[Epoch 63; Iter   386/ 1097] train: loss: 0.0845659
[Epoch 63; Iter   416/ 1097] train: loss: 0.0677447
[Epoch 63; Iter   446/ 1097] train: loss: 0.0307412
[Epoch 63; Iter   476/ 1097] train: loss: 0.0416187
[Epoch 63; Iter   506/ 1097] train: loss: 0.0653471
[Epoch 63; Iter   536/ 1097] train: loss: 0.2034967
[Epoch 63; Iter   566/ 1097] train: loss: 0.0122636
[Epoch 63; Iter   596/ 1097] train: loss: 0.1267858
[Epoch 63; Iter   626/ 1097] train: loss: 0.0448615
[Epoch 63; Iter   656/ 1097] train: loss: 0.0275867
[Epoch 63; Iter   686/ 1097] train: loss: 0.0336166
[Epoch 63; Iter   716/ 1097] train: loss: 0.0212465
[Epoch 63; Iter   746/ 1097] train: loss: 0.0120142
[Epoch 63; Iter   776/ 1097] train: loss: 0.0611669
[Epoch 63; Iter   806/ 1097] train: loss: 0.0148482
[Epoch 63; Iter   836/ 1097] train: loss: 0.0974286
[Epoch 63; Iter   866/ 1097] train: loss: 0.0410561
[Epoch 63; Iter   896/ 1097] train: loss: 0.1511620
[Epoch 63; Iter   926/ 1097] train: loss: 0.0890196
[Epoch 63; Iter   956/ 1097] train: loss: 0.0222015
[Epoch 63; Iter   986/ 1097] train: loss: 0.0929558
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0205862
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0081019
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0052477
[Epoch 63] ogbg-molhiv: 0.796780 val loss: 0.094476
[Epoch 63] ogbg-molhiv: 0.743985 test loss: 0.159036
[Epoch 64; Iter     9/ 1097] train: loss: 0.1081307
[Epoch 64; Iter    39/ 1097] train: loss: 0.0436446
[Epoch 64; Iter    69/ 1097] train: loss: 0.1397275
[Epoch 64; Iter    99/ 1097] train: loss: 0.0199718
[Epoch 64; Iter   129/ 1097] train: loss: 0.0646989
[Epoch 64; Iter   159/ 1097] train: loss: 0.0065429
[Epoch 64; Iter   189/ 1097] train: loss: 0.0345182
[Epoch 64; Iter   219/ 1097] train: loss: 0.0157220
[Epoch 64; Iter   249/ 1097] train: loss: 0.0136575
[Epoch 64; Iter   279/ 1097] train: loss: 0.0229677
[Epoch 64; Iter   309/ 1097] train: loss: 0.0586674
[Epoch 64; Iter   339/ 1097] train: loss: 0.1236496
[Epoch 64; Iter   369/ 1097] train: loss: 0.0448789
[Epoch 64; Iter   399/ 1097] train: loss: 0.0140455
[Epoch 64; Iter   429/ 1097] train: loss: 0.0934195
[Epoch 64; Iter   459/ 1097] train: loss: 0.0233841
[Epoch 64; Iter   489/ 1097] train: loss: 0.0587029
[Epoch 64; Iter   519/ 1097] train: loss: 0.0970276
[Epoch 64; Iter   549/ 1097] train: loss: 0.0077207
[Epoch 64; Iter   579/ 1097] train: loss: 0.1264239
[Epoch 64; Iter   609/ 1097] train: loss: 0.0172827
[Epoch 64; Iter   639/ 1097] train: loss: 0.0618316
[Epoch 64; Iter   669/ 1097] train: loss: 0.0412015
[Epoch 64; Iter   699/ 1097] train: loss: 0.1757994
[Epoch 64; Iter   729/ 1097] train: loss: 0.2042532
[Epoch 64; Iter   759/ 1097] train: loss: 0.0893535
[Epoch 64; Iter   789/ 1097] train: loss: 0.0817619
[Epoch 64; Iter   819/ 1097] train: loss: 0.0205579
[Epoch 64; Iter   849/ 1097] train: loss: 0.0138099
[Epoch 64; Iter   879/ 1097] train: loss: 0.0348435
[Epoch 64; Iter   909/ 1097] train: loss: 0.0140318
[Epoch 64; Iter   939/ 1097] train: loss: 0.0070415
[Epoch 64; Iter   969/ 1097] train: loss: 0.1061219
[Epoch 64; Iter   999/ 1097] train: loss: 0.1228282
[Epoch 64; Iter  1029/ 1097] train: loss: 0.1220727
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0607030
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0466243
[Epoch 64] ogbg-molhiv: 0.799058 val loss: 0.104656
[Epoch 64] ogbg-molhiv: 0.744178 test loss: 0.164725
[Epoch 65; Iter    22/ 1097] train: loss: 0.0355402
[Epoch 63; Iter   484/  823] train: loss: 0.0387225
[Epoch 63; Iter   514/  823] train: loss: 0.0920423
[Epoch 63; Iter   544/  823] train: loss: 0.0349193
[Epoch 63; Iter   574/  823] train: loss: 0.0051783
[Epoch 63; Iter   604/  823] train: loss: 0.0501008
[Epoch 63; Iter   634/  823] train: loss: 0.0292757
[Epoch 63; Iter   664/  823] train: loss: 0.0983988
[Epoch 63; Iter   694/  823] train: loss: 0.0027747
[Epoch 63; Iter   724/  823] train: loss: 0.0077177
[Epoch 63; Iter   754/  823] train: loss: 0.0305915
[Epoch 63; Iter   784/  823] train: loss: 0.1457606
[Epoch 63; Iter   814/  823] train: loss: 0.0042295
[Epoch 63] ogbg-molhiv: 0.732163 val loss: 0.238866
[Epoch 63] ogbg-molhiv: 0.760673 test loss: 0.180563
[Epoch 64; Iter    21/  823] train: loss: 0.0532645
[Epoch 64; Iter    51/  823] train: loss: 0.0134969
[Epoch 64; Iter    81/  823] train: loss: 0.0182572
[Epoch 64; Iter   111/  823] train: loss: 0.0141436
[Epoch 64; Iter   141/  823] train: loss: 0.0312094
[Epoch 64; Iter   171/  823] train: loss: 0.0024170
[Epoch 64; Iter   201/  823] train: loss: 0.0964620
[Epoch 64; Iter   231/  823] train: loss: 0.0509017
[Epoch 64; Iter   261/  823] train: loss: 0.0067605
[Epoch 64; Iter   291/  823] train: loss: 0.1071090
[Epoch 64; Iter   321/  823] train: loss: 0.0367870
[Epoch 64; Iter   351/  823] train: loss: 0.0066240
[Epoch 64; Iter   381/  823] train: loss: 0.0217476
[Epoch 64; Iter   411/  823] train: loss: 0.0032180
[Epoch 64; Iter   441/  823] train: loss: 0.0035087
[Epoch 64; Iter   471/  823] train: loss: 0.0327095
[Epoch 64; Iter   501/  823] train: loss: 0.0303429
[Epoch 64; Iter   531/  823] train: loss: 0.0198704
[Epoch 64; Iter   561/  823] train: loss: 0.0069686
[Epoch 64; Iter   591/  823] train: loss: 0.0226938
[Epoch 64; Iter   621/  823] train: loss: 0.0115783
[Epoch 64; Iter   651/  823] train: loss: 0.0657442
[Epoch 64; Iter   681/  823] train: loss: 0.0248284
[Epoch 64; Iter   711/  823] train: loss: 0.0026760
[Epoch 64; Iter   741/  823] train: loss: 0.0379127
[Epoch 64; Iter   771/  823] train: loss: 0.0095477
[Epoch 64; Iter   801/  823] train: loss: 0.0138832
[Epoch 64] ogbg-molhiv: 0.733990 val loss: 0.236612
[Epoch 64] ogbg-molhiv: 0.756700 test loss: 0.171549
[Epoch 65; Iter     8/  823] train: loss: 0.0480761
[Epoch 65; Iter    38/  823] train: loss: 0.0665428
[Epoch 65; Iter    68/  823] train: loss: 0.0207207
[Epoch 65; Iter    98/  823] train: loss: 0.0062095
[Epoch 65; Iter   128/  823] train: loss: 0.0344074
[Epoch 65; Iter   158/  823] train: loss: 0.0028198
[Epoch 65; Iter   188/  823] train: loss: 0.0153791
[Epoch 65; Iter   218/  823] train: loss: 0.0387344
[Epoch 65; Iter   248/  823] train: loss: 0.0088843
[Epoch 65; Iter   278/  823] train: loss: 0.0130982
[Epoch 65; Iter   308/  823] train: loss: 0.1815806
[Epoch 65; Iter   338/  823] train: loss: 0.0207203
[Epoch 65; Iter   368/  823] train: loss: 0.0042781
[Epoch 65; Iter   398/  823] train: loss: 0.0144795
[Epoch 65; Iter   428/  823] train: loss: 0.0021813
[Epoch 65; Iter   458/  823] train: loss: 0.0072193
[Epoch 65; Iter   488/  823] train: loss: 0.0263835
[Epoch 65; Iter   518/  823] train: loss: 0.0321329
[Epoch 65; Iter   548/  823] train: loss: 0.0295768
[Epoch 65; Iter   578/  823] train: loss: 0.0093987
[Epoch 65; Iter   608/  823] train: loss: 0.0113976
[Epoch 65; Iter   638/  823] train: loss: 0.0149000
[Epoch 65; Iter   668/  823] train: loss: 0.2579007
[Epoch 65; Iter   698/  823] train: loss: 0.0087625
[Epoch 65; Iter   728/  823] train: loss: 0.0740661
[Epoch 65; Iter   758/  823] train: loss: 0.0312231
[Epoch 65; Iter   788/  823] train: loss: 0.0072932
[Epoch 65; Iter   818/  823] train: loss: 0.1108652
[Epoch 65] ogbg-molhiv: 0.724566 val loss: 0.237740
[Epoch 65] ogbg-molhiv: 0.762277 test loss: 0.171555
[Epoch 66; Iter    25/  823] train: loss: 0.0038397
[Epoch 66; Iter    55/  823] train: loss: 0.1477672
[Epoch 66; Iter    85/  823] train: loss: 0.0033304
[Epoch 66; Iter   115/  823] train: loss: 0.0028162
[Epoch 66; Iter   145/  823] train: loss: 0.0689193
[Epoch 66; Iter   175/  823] train: loss: 0.0513914
[Epoch 66; Iter   205/  823] train: loss: 0.0570852
[Epoch 66; Iter   235/  823] train: loss: 0.0110599
[Epoch 66; Iter   265/  823] train: loss: 0.0119014
[Epoch 66; Iter   295/  823] train: loss: 0.0093230
[Epoch 66; Iter   325/  823] train: loss: 0.0010952
[Epoch 66; Iter   355/  823] train: loss: 0.0161277
[Epoch 66; Iter   385/  823] train: loss: 0.0027314
[Epoch 66; Iter   415/  823] train: loss: 0.0319931
[Epoch 66; Iter   445/  823] train: loss: 0.0143375
[Epoch 66; Iter   475/  823] train: loss: 0.0125144
[Epoch 66; Iter   505/  823] train: loss: 0.0135075
[Epoch 66; Iter   535/  823] train: loss: 0.0132248
[Epoch 66; Iter   565/  823] train: loss: 0.0023858
[Epoch 66; Iter   595/  823] train: loss: 0.0090777
[Epoch 66; Iter   625/  823] train: loss: 0.0077752
[Epoch 66; Iter   655/  823] train: loss: 0.0584821
[Epoch 66; Iter   685/  823] train: loss: 0.0031710
[Epoch 66; Iter   715/  823] train: loss: 0.0110263
[Epoch 66; Iter   745/  823] train: loss: 0.0038293
[Epoch 66; Iter   775/  823] train: loss: 0.0607441
[Epoch 66; Iter   805/  823] train: loss: 0.0347535
[Epoch 66] ogbg-molhiv: 0.735226 val loss: 0.269642
[Epoch 66] ogbg-molhiv: 0.775814 test loss: 0.195589
[Epoch 67; Iter    12/  823] train: loss: 0.0621391
[Epoch 67; Iter    42/  823] train: loss: 0.0024611
[Epoch 67; Iter    72/  823] train: loss: 0.0641504
[Epoch 67; Iter   102/  823] train: loss: 0.0165304
[Epoch 67; Iter   132/  823] train: loss: 0.0307106
[Epoch 67; Iter   162/  823] train: loss: 0.0390585
[Epoch 67; Iter   192/  823] train: loss: 0.0136076
[Epoch 67; Iter   222/  823] train: loss: 0.0076518
[Epoch 67; Iter   252/  823] train: loss: 0.1934566
[Epoch 67; Iter   282/  823] train: loss: 0.0487837
[Epoch 67; Iter   312/  823] train: loss: 0.0042838
[Epoch 67; Iter   342/  823] train: loss: 0.0103217
[Epoch 67; Iter   372/  823] train: loss: 0.0220389
[Epoch 67; Iter   402/  823] train: loss: 0.0120410
[Epoch 67; Iter   432/  823] train: loss: 0.0198418
[Epoch 67; Iter   462/  823] train: loss: 0.0502215
[Epoch 67; Iter   492/  823] train: loss: 0.0011421
[Epoch 67; Iter   522/  823] train: loss: 0.0042413
[Epoch 67; Iter   552/  823] train: loss: 0.0021161
[Epoch 67; Iter   582/  823] train: loss: 0.0419665
[Epoch 67; Iter   612/  823] train: loss: 0.0152696
[Epoch 67; Iter   642/  823] train: loss: 0.0039071
[Epoch 67; Iter   672/  823] train: loss: 0.0376992
[Epoch 67; Iter   702/  823] train: loss: 0.0995256
[Epoch 67; Iter   732/  823] train: loss: 0.0061819
[Epoch 67; Iter   762/  823] train: loss: 0.0028531
[Epoch 67; Iter   792/  823] train: loss: 0.0590497
[Epoch 67; Iter   822/  823] train: loss: 0.0063453
[Epoch 67] ogbg-molhiv: 0.737103 val loss: 0.277863
[Epoch 67] ogbg-molhiv: 0.768209 test loss: 0.208802
[Epoch 68; Iter    29/  823] train: loss: 0.0275117
[Epoch 68; Iter    59/  823] train: loss: 0.0146790
[Epoch 68; Iter    89/  823] train: loss: 0.0564600
[Epoch 68; Iter   119/  823] train: loss: 0.0385767
[Epoch 68; Iter   149/  823] train: loss: 0.0466627
[Epoch 68; Iter   179/  823] train: loss: 0.0233030
[Epoch 68; Iter   209/  823] train: loss: 0.0047792
[Epoch 68; Iter   239/  823] train: loss: 0.0038854
[Epoch 68; Iter   269/  823] train: loss: 0.0060748
[Epoch 68; Iter   299/  823] train: loss: 0.0173302
[Epoch 68; Iter   329/  823] train: loss: 0.0029019
[Epoch 68; Iter   359/  823] train: loss: 0.1375174
[Epoch 68; Iter   389/  823] train: loss: 0.0118057
[Epoch 68; Iter   419/  823] train: loss: 0.0055410
[Epoch 68; Iter   449/  823] train: loss: 0.0253127
[Epoch 68; Iter   479/  823] train: loss: 0.0410787
[Epoch 68; Iter   509/  823] train: loss: 0.0043763
[Epoch 68; Iter   539/  823] train: loss: 0.0993825
[Epoch 68; Iter   569/  823] train: loss: 0.0016232
[Epoch 68; Iter   599/  823] train: loss: 0.0291878
[Epoch 68; Iter   629/  823] train: loss: 0.0183953
[Epoch 68; Iter   659/  823] train: loss: 0.0663182
[Epoch 68; Iter   689/  823] train: loss: 0.0600717
[Epoch 68; Iter   719/  823] train: loss: 0.0007881
[Epoch 68; Iter   749/  823] train: loss: 0.0029848
[Epoch 60] ogbg-molhiv: 0.807169 val loss: 0.106042
[Epoch 60] ogbg-molhiv: 0.747709 test loss: 0.189565
[Epoch 61; Iter    30/ 1097] train: loss: 0.0142845
[Epoch 61; Iter    60/ 1097] train: loss: 0.0051628
[Epoch 61; Iter    90/ 1097] train: loss: 0.0084315
[Epoch 61; Iter   120/ 1097] train: loss: 0.0040723
[Epoch 61; Iter   150/ 1097] train: loss: 0.0030415
[Epoch 61; Iter   180/ 1097] train: loss: 0.0113501
[Epoch 61; Iter   210/ 1097] train: loss: 0.0257265
[Epoch 61; Iter   240/ 1097] train: loss: 0.0254139
[Epoch 61; Iter   270/ 1097] train: loss: 0.0162368
[Epoch 61; Iter   300/ 1097] train: loss: 0.0876750
[Epoch 61; Iter   330/ 1097] train: loss: 0.0301712
[Epoch 61; Iter   360/ 1097] train: loss: 0.0051661
[Epoch 61; Iter   390/ 1097] train: loss: 0.0261820
[Epoch 61; Iter   420/ 1097] train: loss: 0.0217096
[Epoch 61; Iter   450/ 1097] train: loss: 0.0110543
[Epoch 61; Iter   480/ 1097] train: loss: 0.0321829
[Epoch 61; Iter   510/ 1097] train: loss: 0.0094246
[Epoch 61; Iter   540/ 1097] train: loss: 0.0928165
[Epoch 61; Iter   570/ 1097] train: loss: 0.0055466
[Epoch 61; Iter   600/ 1097] train: loss: 0.1779284
[Epoch 61; Iter   630/ 1097] train: loss: 0.0928122
[Epoch 61; Iter   660/ 1097] train: loss: 0.0341575
[Epoch 61; Iter   690/ 1097] train: loss: 0.1458703
[Epoch 61; Iter   720/ 1097] train: loss: 0.0335385
[Epoch 61; Iter   750/ 1097] train: loss: 0.1063748
[Epoch 61; Iter   780/ 1097] train: loss: 0.0088983
[Epoch 61; Iter   810/ 1097] train: loss: 0.0373519
[Epoch 61; Iter   840/ 1097] train: loss: 0.0744032
[Epoch 61; Iter   870/ 1097] train: loss: 0.0201431
[Epoch 61; Iter   900/ 1097] train: loss: 0.0867520
[Epoch 61; Iter   930/ 1097] train: loss: 0.0046866
[Epoch 61; Iter   960/ 1097] train: loss: 0.0293500
[Epoch 61; Iter   990/ 1097] train: loss: 0.0293052
[Epoch 61; Iter  1020/ 1097] train: loss: 0.0024360
[Epoch 61; Iter  1050/ 1097] train: loss: 0.0214018
[Epoch 61; Iter  1080/ 1097] train: loss: 0.0081247
[Epoch 61] ogbg-molhiv: 0.806101 val loss: 0.100861
[Epoch 61] ogbg-molhiv: 0.763914 test loss: 0.184726
[Epoch 62; Iter    13/ 1097] train: loss: 0.0091946
[Epoch 62; Iter    43/ 1097] train: loss: 0.0065419
[Epoch 62; Iter    73/ 1097] train: loss: 0.0248468
[Epoch 62; Iter   103/ 1097] train: loss: 0.0139361
[Epoch 62; Iter   133/ 1097] train: loss: 0.0141264
[Epoch 62; Iter   163/ 1097] train: loss: 0.0056913
[Epoch 62; Iter   193/ 1097] train: loss: 0.0075040
[Epoch 62; Iter   223/ 1097] train: loss: 0.0124599
[Epoch 62; Iter   253/ 1097] train: loss: 0.0064465
[Epoch 62; Iter   283/ 1097] train: loss: 0.0098103
[Epoch 62; Iter   313/ 1097] train: loss: 0.0239997
[Epoch 62; Iter   343/ 1097] train: loss: 0.0021898
[Epoch 62; Iter   373/ 1097] train: loss: 0.0057077
[Epoch 62; Iter   403/ 1097] train: loss: 0.0366469
[Epoch 62; Iter   433/ 1097] train: loss: 0.0209836
[Epoch 62; Iter   463/ 1097] train: loss: 0.0385453
[Epoch 62; Iter   493/ 1097] train: loss: 0.0326234
[Epoch 62; Iter   523/ 1097] train: loss: 0.0104139
[Epoch 62; Iter   553/ 1097] train: loss: 0.1336282
[Epoch 62; Iter   583/ 1097] train: loss: 0.0186601
[Epoch 62; Iter   613/ 1097] train: loss: 0.0235566
[Epoch 62; Iter   643/ 1097] train: loss: 0.0430927
[Epoch 62; Iter   673/ 1097] train: loss: 0.0107993
[Epoch 62; Iter   703/ 1097] train: loss: 0.0401654
[Epoch 62; Iter   733/ 1097] train: loss: 0.0521061
[Epoch 62; Iter   763/ 1097] train: loss: 0.2129421
[Epoch 62; Iter   793/ 1097] train: loss: 0.0062935
[Epoch 62; Iter   823/ 1097] train: loss: 0.0142688
[Epoch 62; Iter   853/ 1097] train: loss: 0.0281671
[Epoch 62; Iter   883/ 1097] train: loss: 0.0552712
[Epoch 62; Iter   913/ 1097] train: loss: 0.0309359
[Epoch 62; Iter   943/ 1097] train: loss: 0.0029027
[Epoch 62; Iter   973/ 1097] train: loss: 0.0024742
[Epoch 62; Iter  1003/ 1097] train: loss: 0.0888223
[Epoch 62; Iter  1033/ 1097] train: loss: 0.0133130
[Epoch 62; Iter  1063/ 1097] train: loss: 0.0423509
[Epoch 62; Iter  1093/ 1097] train: loss: 0.0052060
[Epoch 62] ogbg-molhiv: 0.797990 val loss: 0.099933
[Epoch 62] ogbg-molhiv: 0.768072 test loss: 0.174458
[Epoch 63; Iter    26/ 1097] train: loss: 0.0255604
[Epoch 63; Iter    56/ 1097] train: loss: 0.0720216
[Epoch 63; Iter    86/ 1097] train: loss: 0.0107233
[Epoch 63; Iter   116/ 1097] train: loss: 0.0066300
[Epoch 63; Iter   146/ 1097] train: loss: 0.0447223
[Epoch 63; Iter   176/ 1097] train: loss: 0.0027167
[Epoch 63; Iter   206/ 1097] train: loss: 0.1100615
[Epoch 63; Iter   236/ 1097] train: loss: 0.0506134
[Epoch 63; Iter   266/ 1097] train: loss: 0.0088653
[Epoch 63; Iter   296/ 1097] train: loss: 0.0079842
[Epoch 63; Iter   326/ 1097] train: loss: 0.1580667
[Epoch 63; Iter   356/ 1097] train: loss: 0.0062652
[Epoch 63; Iter   386/ 1097] train: loss: 0.0017537
[Epoch 63; Iter   416/ 1097] train: loss: 0.0095466
[Epoch 63; Iter   446/ 1097] train: loss: 0.0139753
[Epoch 63; Iter   476/ 1097] train: loss: 0.0030486
[Epoch 63; Iter   506/ 1097] train: loss: 0.0116413
[Epoch 63; Iter   536/ 1097] train: loss: 0.0307989
[Epoch 63; Iter   566/ 1097] train: loss: 0.0283856
[Epoch 63; Iter   596/ 1097] train: loss: 0.0969529
[Epoch 63; Iter   626/ 1097] train: loss: 0.0050797
[Epoch 63; Iter   656/ 1097] train: loss: 0.0069999
[Epoch 63; Iter   686/ 1097] train: loss: 0.0011668
[Epoch 63; Iter   716/ 1097] train: loss: 0.0282213
[Epoch 63; Iter   746/ 1097] train: loss: 0.0052447
[Epoch 63; Iter   776/ 1097] train: loss: 0.0033046
[Epoch 63; Iter   806/ 1097] train: loss: 0.0614620
[Epoch 63; Iter   836/ 1097] train: loss: 0.0020019
[Epoch 63; Iter   866/ 1097] train: loss: 0.0044689
[Epoch 63; Iter   896/ 1097] train: loss: 0.0187219
[Epoch 63; Iter   926/ 1097] train: loss: 0.0062487
[Epoch 63; Iter   956/ 1097] train: loss: 0.2423094
[Epoch 63; Iter   986/ 1097] train: loss: 0.0096071
[Epoch 63; Iter  1016/ 1097] train: loss: 0.0043216
[Epoch 63; Iter  1046/ 1097] train: loss: 0.0110783
[Epoch 63; Iter  1076/ 1097] train: loss: 0.0411493
[Epoch 63] ogbg-molhiv: 0.797833 val loss: 0.106171
[Epoch 63] ogbg-molhiv: 0.754118 test loss: 0.222948
[Epoch 64; Iter     9/ 1097] train: loss: 0.0016988
[Epoch 64; Iter    39/ 1097] train: loss: 0.0207694
[Epoch 64; Iter    69/ 1097] train: loss: 0.0131178
[Epoch 64; Iter    99/ 1097] train: loss: 0.0277343
[Epoch 64; Iter   129/ 1097] train: loss: 0.0066487
[Epoch 64; Iter   159/ 1097] train: loss: 0.0061849
[Epoch 64; Iter   189/ 1097] train: loss: 0.0161894
[Epoch 64; Iter   219/ 1097] train: loss: 0.0226872
[Epoch 64; Iter   249/ 1097] train: loss: 0.0024923
[Epoch 64; Iter   279/ 1097] train: loss: 0.0035610
[Epoch 64; Iter   309/ 1097] train: loss: 0.0069620
[Epoch 64; Iter   339/ 1097] train: loss: 0.0020229
[Epoch 64; Iter   369/ 1097] train: loss: 0.0886735
[Epoch 64; Iter   399/ 1097] train: loss: 0.1001397
[Epoch 64; Iter   429/ 1097] train: loss: 0.0360143
[Epoch 64; Iter   459/ 1097] train: loss: 0.1913602
[Epoch 64; Iter   489/ 1097] train: loss: 0.0486386
[Epoch 64; Iter   519/ 1097] train: loss: 0.0366815
[Epoch 64; Iter   549/ 1097] train: loss: 0.0082131
[Epoch 64; Iter   579/ 1097] train: loss: 0.0057355
[Epoch 64; Iter   609/ 1097] train: loss: 0.0210383
[Epoch 64; Iter   639/ 1097] train: loss: 0.0299296
[Epoch 64; Iter   669/ 1097] train: loss: 0.0027630
[Epoch 64; Iter   699/ 1097] train: loss: 0.0101476
[Epoch 64; Iter   729/ 1097] train: loss: 0.0044653
[Epoch 64; Iter   759/ 1097] train: loss: 0.0196530
[Epoch 64; Iter   789/ 1097] train: loss: 0.0770413
[Epoch 64; Iter   819/ 1097] train: loss: 0.0188716
[Epoch 64; Iter   849/ 1097] train: loss: 0.0436538
[Epoch 64; Iter   879/ 1097] train: loss: 0.0281714
[Epoch 64; Iter   909/ 1097] train: loss: 0.0721800
[Epoch 64; Iter   939/ 1097] train: loss: 0.0133038
[Epoch 64; Iter   969/ 1097] train: loss: 0.0305999
[Epoch 64; Iter   999/ 1097] train: loss: 0.0361027
[Epoch 64; Iter  1029/ 1097] train: loss: 0.0859058
[Epoch 64; Iter  1059/ 1097] train: loss: 0.0038170
[Epoch 64; Iter  1089/ 1097] train: loss: 0.0303815
[Epoch 64] ogbg-molhiv: 0.793470 val loss: 0.105963
[Epoch 64] ogbg-molhiv: 0.767842 test loss: 0.180560
[Epoch 65; Iter    22/ 1097] train: loss: 0.1237747
[Epoch 64; Iter   420/  960] train: loss: 0.0064800
[Epoch 64; Iter   450/  960] train: loss: 0.0320143
[Epoch 64; Iter   480/  960] train: loss: 0.0133597
[Epoch 64; Iter   510/  960] train: loss: 0.0139103
[Epoch 64; Iter   540/  960] train: loss: 0.0129576
[Epoch 64; Iter   570/  960] train: loss: 0.0241801
[Epoch 64; Iter   600/  960] train: loss: 0.2203813
[Epoch 64; Iter   630/  960] train: loss: 0.0453927
[Epoch 64; Iter   660/  960] train: loss: 0.0103392
[Epoch 64; Iter   690/  960] train: loss: 0.0141827
[Epoch 64; Iter   720/  960] train: loss: 0.0028226
[Epoch 64; Iter   750/  960] train: loss: 0.1149856
[Epoch 64; Iter   780/  960] train: loss: 0.0080196
[Epoch 64; Iter   810/  960] train: loss: 0.0059884
[Epoch 64; Iter   840/  960] train: loss: 0.0018671
[Epoch 64; Iter   870/  960] train: loss: 0.0239656
[Epoch 64; Iter   900/  960] train: loss: 0.0137584
[Epoch 64; Iter   930/  960] train: loss: 0.0040451
[Epoch 64; Iter   960/  960] train: loss: 0.0032037
[Epoch 64] ogbg-molhiv: 0.738670 val loss: 0.190701
[Epoch 64] ogbg-molhiv: 0.772531 test loss: 0.155229
[Epoch 65; Iter    30/  960] train: loss: 0.0033734
[Epoch 65; Iter    60/  960] train: loss: 0.1320642
[Epoch 65; Iter    90/  960] train: loss: 0.0067057
[Epoch 65; Iter   120/  960] train: loss: 0.1311686
[Epoch 65; Iter   150/  960] train: loss: 0.0075680
[Epoch 65; Iter   180/  960] train: loss: 0.0296971
[Epoch 65; Iter   210/  960] train: loss: 0.0076296
[Epoch 65; Iter   240/  960] train: loss: 0.0148207
[Epoch 65; Iter   270/  960] train: loss: 0.0790768
[Epoch 65; Iter   300/  960] train: loss: 0.0677475
[Epoch 65; Iter   330/  960] train: loss: 0.0035197
[Epoch 65; Iter   360/  960] train: loss: 0.0562593
[Epoch 65; Iter   390/  960] train: loss: 0.0579248
[Epoch 65; Iter   420/  960] train: loss: 0.0443525
[Epoch 65; Iter   450/  960] train: loss: 0.0271381
[Epoch 65; Iter   480/  960] train: loss: 0.0116748
[Epoch 65; Iter   510/  960] train: loss: 0.0926568
[Epoch 65; Iter   540/  960] train: loss: 0.1777946
[Epoch 65; Iter   570/  960] train: loss: 0.0035952
[Epoch 65; Iter   600/  960] train: loss: 0.0820417
[Epoch 65; Iter   630/  960] train: loss: 0.0360264
[Epoch 65; Iter   660/  960] train: loss: 0.1918783
[Epoch 65; Iter   690/  960] train: loss: 0.0018363
[Epoch 65; Iter   720/  960] train: loss: 0.0320916
[Epoch 65; Iter   750/  960] train: loss: 0.0959764
[Epoch 65; Iter   780/  960] train: loss: 0.0048502
[Epoch 65; Iter   810/  960] train: loss: 0.0012415
[Epoch 65; Iter   840/  960] train: loss: 0.0064222
[Epoch 65; Iter   870/  960] train: loss: 0.0042221
[Epoch 65; Iter   900/  960] train: loss: 0.0925099
[Epoch 65; Iter   930/  960] train: loss: 0.0139024
[Epoch 65; Iter   960/  960] train: loss: 0.0458255
[Epoch 65] ogbg-molhiv: 0.738423 val loss: 0.207077
[Epoch 65] ogbg-molhiv: 0.782570 test loss: 0.166268
[Epoch 66; Iter    30/  960] train: loss: 0.0150446
[Epoch 66; Iter    60/  960] train: loss: 0.0294982
[Epoch 66; Iter    90/  960] train: loss: 0.0035689
[Epoch 66; Iter   120/  960] train: loss: 0.0668222
[Epoch 66; Iter   150/  960] train: loss: 0.0455792
[Epoch 66; Iter   180/  960] train: loss: 0.0430016
[Epoch 66; Iter   210/  960] train: loss: 0.0447326
[Epoch 66; Iter   240/  960] train: loss: 0.0179805
[Epoch 66; Iter   270/  960] train: loss: 0.0016969
[Epoch 66; Iter   300/  960] train: loss: 0.0039079
[Epoch 66; Iter   330/  960] train: loss: 0.0134320
[Epoch 66; Iter   360/  960] train: loss: 0.0101574
[Epoch 66; Iter   390/  960] train: loss: 0.0047764
[Epoch 66; Iter   420/  960] train: loss: 0.0047084
[Epoch 66; Iter   450/  960] train: loss: 0.0248832
[Epoch 66; Iter   480/  960] train: loss: 0.0579451
[Epoch 66; Iter   510/  960] train: loss: 0.0112963
[Epoch 66; Iter   540/  960] train: loss: 0.0112720
[Epoch 66; Iter   570/  960] train: loss: 0.0081164
[Epoch 66; Iter   600/  960] train: loss: 0.0340483
[Epoch 66; Iter   630/  960] train: loss: 0.0447448
[Epoch 66; Iter   660/  960] train: loss: 0.0198898
[Epoch 66; Iter   690/  960] train: loss: 0.0943892
[Epoch 66; Iter   720/  960] train: loss: 0.0033548
[Epoch 66; Iter   750/  960] train: loss: 0.0934986
[Epoch 66; Iter   780/  960] train: loss: 0.0238351
[Epoch 66; Iter   810/  960] train: loss: 0.0230084
[Epoch 66; Iter   840/  960] train: loss: 0.0053058
[Epoch 66; Iter   870/  960] train: loss: 0.0486073
[Epoch 66; Iter   900/  960] train: loss: 0.0465780
[Epoch 66; Iter   930/  960] train: loss: 0.0044608
[Epoch 66; Iter   960/  960] train: loss: 0.0064180
[Epoch 66] ogbg-molhiv: 0.735152 val loss: 0.207799
[Epoch 66] ogbg-molhiv: 0.764388 test loss: 0.173150
[Epoch 67; Iter    30/  960] train: loss: 0.0361578
[Epoch 67; Iter    60/  960] train: loss: 0.0045287
[Epoch 67; Iter    90/  960] train: loss: 0.2006728
[Epoch 67; Iter   120/  960] train: loss: 0.0198486
[Epoch 67; Iter   150/  960] train: loss: 0.0104817
[Epoch 67; Iter   180/  960] train: loss: 0.0769788
[Epoch 67; Iter   210/  960] train: loss: 0.0071593
[Epoch 67; Iter   240/  960] train: loss: 0.0655020
[Epoch 67; Iter   270/  960] train: loss: 0.0038995
[Epoch 67; Iter   300/  960] train: loss: 0.0913286
[Epoch 67; Iter   330/  960] train: loss: 0.0110891
[Epoch 67; Iter   360/  960] train: loss: 0.0329602
[Epoch 67; Iter   390/  960] train: loss: 0.0183949
[Epoch 67; Iter   420/  960] train: loss: 0.0121618
[Epoch 67; Iter   450/  960] train: loss: 0.0037677
[Epoch 67; Iter   480/  960] train: loss: 0.0059511
[Epoch 67; Iter   510/  960] train: loss: 0.1953036
[Epoch 67; Iter   540/  960] train: loss: 0.0103839
[Epoch 67; Iter   570/  960] train: loss: 0.0126725
[Epoch 67; Iter   600/  960] train: loss: 0.0053084
[Epoch 67; Iter   630/  960] train: loss: 0.0139129
[Epoch 67; Iter   660/  960] train: loss: 0.0196787
[Epoch 67; Iter   690/  960] train: loss: 0.0057434
[Epoch 67; Iter   720/  960] train: loss: 0.0365283
[Epoch 67; Iter   750/  960] train: loss: 0.0547679
[Epoch 67; Iter   780/  960] train: loss: 0.0932271
[Epoch 67; Iter   810/  960] train: loss: 0.0107199
[Epoch 67; Iter   840/  960] train: loss: 0.0291967
[Epoch 67; Iter   870/  960] train: loss: 0.0288602
[Epoch 67; Iter   900/  960] train: loss: 0.0105894
[Epoch 67; Iter   930/  960] train: loss: 0.1057430
[Epoch 67; Iter   960/  960] train: loss: 0.1733484
[Epoch 67] ogbg-molhiv: 0.735619 val loss: 0.226553
[Epoch 67] ogbg-molhiv: 0.764016 test loss: 0.172979
[Epoch 68; Iter    30/  960] train: loss: 0.0026577
[Epoch 68; Iter    60/  960] train: loss: 0.1342844
[Epoch 68; Iter    90/  960] train: loss: 0.0022388
[Epoch 68; Iter   120/  960] train: loss: 0.0255874
[Epoch 68; Iter   150/  960] train: loss: 0.0058429
[Epoch 68; Iter   180/  960] train: loss: 0.0233220
[Epoch 68; Iter   210/  960] train: loss: 0.0422963
[Epoch 68; Iter   240/  960] train: loss: 0.0383445
[Epoch 68; Iter   270/  960] train: loss: 0.0076874
[Epoch 68; Iter   300/  960] train: loss: 0.0068181
[Epoch 68; Iter   330/  960] train: loss: 0.0506434
[Epoch 68; Iter   360/  960] train: loss: 0.0161425
[Epoch 68; Iter   390/  960] train: loss: 0.0630853
[Epoch 68; Iter   420/  960] train: loss: 0.0131823
[Epoch 68; Iter   450/  960] train: loss: 0.0884352
[Epoch 68; Iter   480/  960] train: loss: 0.0085368
[Epoch 68; Iter   510/  960] train: loss: 0.0027004
[Epoch 68; Iter   540/  960] train: loss: 0.1210738
[Epoch 68; Iter   570/  960] train: loss: 0.0121544
[Epoch 68; Iter   600/  960] train: loss: 0.0127843
[Epoch 68; Iter   630/  960] train: loss: 0.0359350
[Epoch 68; Iter   660/  960] train: loss: 0.0189606
[Epoch 68; Iter   690/  960] train: loss: 0.0058323
[Epoch 68; Iter   720/  960] train: loss: 0.0339033
[Epoch 68; Iter   750/  960] train: loss: 0.0261567
[Epoch 68; Iter   780/  960] train: loss: 0.0143481
[Epoch 68; Iter   810/  960] train: loss: 0.0039206
[Epoch 68; Iter   840/  960] train: loss: 0.1243207
[Epoch 68; Iter   870/  960] train: loss: 0.0161567
[Epoch 68; Iter   900/  960] train: loss: 0.0077743
[Epoch 68; Iter   930/  960] train: loss: 0.0473014
[Epoch 68; Iter   960/  960] train: loss: 0.0574547
[Epoch 68] ogbg-molhiv: 0.722391 val loss: 0.231832
[Epoch 68] ogbg-molhiv: 0.755009 test loss: 0.224751
[Epoch 64; Iter   420/  960] train: loss: 0.0083620
[Epoch 64; Iter   450/  960] train: loss: 0.0106161
[Epoch 64; Iter   480/  960] train: loss: 0.0072272
[Epoch 64; Iter   510/  960] train: loss: 0.0153806
[Epoch 64; Iter   540/  960] train: loss: 0.0202832
[Epoch 64; Iter   570/  960] train: loss: 0.0583913
[Epoch 64; Iter   600/  960] train: loss: 0.0354034
[Epoch 64; Iter   630/  960] train: loss: 0.0054650
[Epoch 64; Iter   660/  960] train: loss: 0.0604416
[Epoch 64; Iter   690/  960] train: loss: 0.0244731
[Epoch 64; Iter   720/  960] train: loss: 0.1182506
[Epoch 64; Iter   750/  960] train: loss: 0.0065194
[Epoch 64; Iter   780/  960] train: loss: 0.1553562
[Epoch 64; Iter   810/  960] train: loss: 0.0893149
[Epoch 64; Iter   840/  960] train: loss: 0.0534657
[Epoch 64; Iter   870/  960] train: loss: 0.0350024
[Epoch 64; Iter   900/  960] train: loss: 0.0196196
[Epoch 64; Iter   930/  960] train: loss: 0.0373327
[Epoch 64; Iter   960/  960] train: loss: 0.0045426
[Epoch 64] ogbg-molhiv: 0.721940 val loss: 0.593825
[Epoch 64] ogbg-molhiv: 0.740990 test loss: 0.468567
[Epoch 65; Iter    30/  960] train: loss: 0.0260617
[Epoch 65; Iter    60/  960] train: loss: 0.0190412
[Epoch 65; Iter    90/  960] train: loss: 0.1025804
[Epoch 65; Iter   120/  960] train: loss: 0.0193241
[Epoch 65; Iter   150/  960] train: loss: 0.0675133
[Epoch 65; Iter   180/  960] train: loss: 0.0049957
[Epoch 65; Iter   210/  960] train: loss: 0.0191237
[Epoch 65; Iter   240/  960] train: loss: 0.0959635
[Epoch 65; Iter   270/  960] train: loss: 0.0225602
[Epoch 65; Iter   300/  960] train: loss: 0.0048848
[Epoch 65; Iter   330/  960] train: loss: 0.0318213
[Epoch 65; Iter   360/  960] train: loss: 0.0411907
[Epoch 65; Iter   390/  960] train: loss: 0.0761037
[Epoch 65; Iter   420/  960] train: loss: 0.0741612
[Epoch 65; Iter   450/  960] train: loss: 0.0652976
[Epoch 65; Iter   480/  960] train: loss: 0.1412192
[Epoch 65; Iter   510/  960] train: loss: 0.0017335
[Epoch 65; Iter   540/  960] train: loss: 0.0567777
[Epoch 65; Iter   570/  960] train: loss: 0.0605716
[Epoch 65; Iter   600/  960] train: loss: 0.1068690
[Epoch 65; Iter   630/  960] train: loss: 0.1268677
[Epoch 65; Iter   660/  960] train: loss: 0.0031155
[Epoch 65; Iter   690/  960] train: loss: 0.0199880
[Epoch 65; Iter   720/  960] train: loss: 0.0218384
[Epoch 65; Iter   750/  960] train: loss: 0.0044010
[Epoch 65; Iter   780/  960] train: loss: 0.0086650
[Epoch 65; Iter   810/  960] train: loss: 0.0078059
[Epoch 65; Iter   840/  960] train: loss: 0.0171568
[Epoch 65; Iter   870/  960] train: loss: 0.1639970
[Epoch 65; Iter   900/  960] train: loss: 0.0061951
[Epoch 65; Iter   930/  960] train: loss: 0.0119804
[Epoch 65; Iter   960/  960] train: loss: 0.0090733
[Epoch 65] ogbg-molhiv: 0.715487 val loss: 0.474512
[Epoch 65] ogbg-molhiv: 0.747351 test loss: 0.392313
[Epoch 66; Iter    30/  960] train: loss: 0.0117933
[Epoch 66; Iter    60/  960] train: loss: 0.0201728
[Epoch 66; Iter    90/  960] train: loss: 0.0713189
[Epoch 66; Iter   120/  960] train: loss: 0.0489417
[Epoch 66; Iter   150/  960] train: loss: 0.1600024
[Epoch 66; Iter   180/  960] train: loss: 0.0575035
[Epoch 66; Iter   210/  960] train: loss: 0.0630904
[Epoch 66; Iter   240/  960] train: loss: 0.0799559
[Epoch 66; Iter   270/  960] train: loss: 0.0090246
[Epoch 66; Iter   300/  960] train: loss: 0.0045956
[Epoch 66; Iter   330/  960] train: loss: 0.0074642
[Epoch 66; Iter   360/  960] train: loss: 0.0172324
[Epoch 66; Iter   390/  960] train: loss: 0.0018929
[Epoch 66; Iter   420/  960] train: loss: 0.0685509
[Epoch 66; Iter   450/  960] train: loss: 0.0092107
[Epoch 66; Iter   480/  960] train: loss: 0.0580512
[Epoch 66; Iter   510/  960] train: loss: 0.1502878
[Epoch 66; Iter   540/  960] train: loss: 0.0055203
[Epoch 66; Iter   570/  960] train: loss: 0.0232779
[Epoch 66; Iter   600/  960] train: loss: 0.0332501
[Epoch 66; Iter   630/  960] train: loss: 0.0306031
[Epoch 66; Iter   660/  960] train: loss: 0.0586043
[Epoch 66; Iter   690/  960] train: loss: 0.0082216
[Epoch 66; Iter   720/  960] train: loss: 0.0679636
[Epoch 66; Iter   750/  960] train: loss: 0.0072204
[Epoch 66; Iter   780/  960] train: loss: 0.1295299
[Epoch 66; Iter   810/  960] train: loss: 0.0220465
[Epoch 66; Iter   840/  960] train: loss: 0.1514246
[Epoch 66; Iter   870/  960] train: loss: 0.0035751
[Epoch 66; Iter   900/  960] train: loss: 0.1267362
[Epoch 66; Iter   930/  960] train: loss: 0.0035081
[Epoch 66; Iter   960/  960] train: loss: 0.0282856
[Epoch 66] ogbg-molhiv: 0.723206 val loss: 0.216424
[Epoch 66] ogbg-molhiv: 0.745777 test loss: 0.168555
[Epoch 67; Iter    30/  960] train: loss: 0.0521078
[Epoch 67; Iter    60/  960] train: loss: 0.0347245
[Epoch 67; Iter    90/  960] train: loss: 0.0324194
[Epoch 67; Iter   120/  960] train: loss: 0.0119334
[Epoch 67; Iter   150/  960] train: loss: 0.0320341
[Epoch 67; Iter   180/  960] train: loss: 0.0683039
[Epoch 67; Iter   210/  960] train: loss: 0.0491553
[Epoch 67; Iter   240/  960] train: loss: 0.0126285
[Epoch 67; Iter   270/  960] train: loss: 0.0165780
[Epoch 67; Iter   300/  960] train: loss: 0.0168712
[Epoch 67; Iter   330/  960] train: loss: 0.0162252
[Epoch 67; Iter   360/  960] train: loss: 0.0339664
[Epoch 67; Iter   390/  960] train: loss: 0.0201811
[Epoch 67; Iter   420/  960] train: loss: 0.0128729
[Epoch 67; Iter   450/  960] train: loss: 0.0631847
[Epoch 67; Iter   480/  960] train: loss: 0.0472372
[Epoch 67; Iter   510/  960] train: loss: 0.0184555
[Epoch 67; Iter   540/  960] train: loss: 0.0655845
[Epoch 67; Iter   570/  960] train: loss: 0.0283041
[Epoch 67; Iter   600/  960] train: loss: 0.0819502
[Epoch 67; Iter   630/  960] train: loss: 0.0076595
[Epoch 67; Iter   660/  960] train: loss: 0.0232799
[Epoch 67; Iter   690/  960] train: loss: 0.0150776
[Epoch 67; Iter   720/  960] train: loss: 0.0883456
[Epoch 67; Iter   750/  960] train: loss: 0.0717847
[Epoch 67; Iter   780/  960] train: loss: 0.0141043
[Epoch 67; Iter   810/  960] train: loss: 0.0081374
[Epoch 67; Iter   840/  960] train: loss: 0.0131884
[Epoch 67; Iter   870/  960] train: loss: 0.0028416
[Epoch 67; Iter   900/  960] train: loss: 0.0285474
[Epoch 67; Iter   930/  960] train: loss: 0.0078316
[Epoch 67; Iter   960/  960] train: loss: 0.0491212
[Epoch 67] ogbg-molhiv: 0.721183 val loss: 0.655406
[Epoch 67] ogbg-molhiv: 0.752827 test loss: 0.439400
[Epoch 68; Iter    30/  960] train: loss: 0.0313339
[Epoch 68; Iter    60/  960] train: loss: 0.0182636
[Epoch 68; Iter    90/  960] train: loss: 0.0087072
[Epoch 68; Iter   120/  960] train: loss: 0.0216161
[Epoch 68; Iter   150/  960] train: loss: 0.0201374
[Epoch 68; Iter   180/  960] train: loss: 0.0155513
[Epoch 68; Iter   210/  960] train: loss: 0.0656583
[Epoch 68; Iter   240/  960] train: loss: 0.1100819
[Epoch 68; Iter   270/  960] train: loss: 0.0358426
[Epoch 68; Iter   300/  960] train: loss: 0.0118116
[Epoch 68; Iter   330/  960] train: loss: 0.0162998
[Epoch 68; Iter   360/  960] train: loss: 0.0028826
[Epoch 68; Iter   390/  960] train: loss: 0.1019470
[Epoch 68; Iter   420/  960] train: loss: 0.0096996
[Epoch 68; Iter   450/  960] train: loss: 0.0179303
[Epoch 68; Iter   480/  960] train: loss: 0.0176345
[Epoch 68; Iter   510/  960] train: loss: 0.0697530
[Epoch 68; Iter   540/  960] train: loss: 0.0425480
[Epoch 68; Iter   570/  960] train: loss: 0.0732100
[Epoch 68; Iter   600/  960] train: loss: 0.0112687
[Epoch 68; Iter   630/  960] train: loss: 0.0119617
[Epoch 68; Iter   660/  960] train: loss: 0.0355460
[Epoch 68; Iter   690/  960] train: loss: 0.0124854
[Epoch 68; Iter   720/  960] train: loss: 0.0236631
[Epoch 68; Iter   750/  960] train: loss: 0.0240748
[Epoch 68; Iter   780/  960] train: loss: 0.0057546
[Epoch 68; Iter   810/  960] train: loss: 0.0106368
[Epoch 68; Iter   840/  960] train: loss: 0.0446035
[Epoch 68; Iter   870/  960] train: loss: 0.0239548
[Epoch 68; Iter   900/  960] train: loss: 0.0889962
[Epoch 68; Iter   930/  960] train: loss: 0.0603811
[Epoch 68; Iter   960/  960] train: loss: 0.0205229
[Epoch 68] ogbg-molhiv: 0.720776 val loss: 0.657389
[Epoch 68] ogbg-molhiv: 0.767242 test loss: 0.431204
[Epoch 64; Iter   420/  960] train: loss: 0.0205944
[Epoch 64; Iter   450/  960] train: loss: 0.0059100
[Epoch 64; Iter   480/  960] train: loss: 0.0058399
[Epoch 64; Iter   510/  960] train: loss: 0.0177894
[Epoch 64; Iter   540/  960] train: loss: 0.0742975
[Epoch 64; Iter   570/  960] train: loss: 0.0235796
[Epoch 64; Iter   600/  960] train: loss: 0.0157599
[Epoch 64; Iter   630/  960] train: loss: 0.0296252
[Epoch 64; Iter   660/  960] train: loss: 0.0576641
[Epoch 64; Iter   690/  960] train: loss: 0.0150241
[Epoch 64; Iter   720/  960] train: loss: 0.1423739
[Epoch 64; Iter   750/  960] train: loss: 0.0452921
[Epoch 64; Iter   780/  960] train: loss: 0.0190999
[Epoch 64; Iter   810/  960] train: loss: 0.0889163
[Epoch 64; Iter   840/  960] train: loss: 0.0075376
[Epoch 64; Iter   870/  960] train: loss: 0.1089966
[Epoch 64; Iter   900/  960] train: loss: 0.0205193
[Epoch 64; Iter   930/  960] train: loss: 0.0165173
[Epoch 64; Iter   960/  960] train: loss: 0.0316147
[Epoch 64] ogbg-molhiv: 0.750872 val loss: 0.247993
[Epoch 64] ogbg-molhiv: 0.755647 test loss: 0.225337
[Epoch 65; Iter    30/  960] train: loss: 0.0123798
[Epoch 65; Iter    60/  960] train: loss: 0.2265421
[Epoch 65; Iter    90/  960] train: loss: 0.0054107
[Epoch 65; Iter   120/  960] train: loss: 0.0826509
[Epoch 65; Iter   150/  960] train: loss: 0.0457436
[Epoch 65; Iter   180/  960] train: loss: 0.0122972
[Epoch 65; Iter   210/  960] train: loss: 0.0051436
[Epoch 65; Iter   240/  960] train: loss: 0.0226693
[Epoch 65; Iter   270/  960] train: loss: 0.0035384
[Epoch 65; Iter   300/  960] train: loss: 0.0295375
[Epoch 65; Iter   330/  960] train: loss: 0.0090723
[Epoch 65; Iter   360/  960] train: loss: 0.0477524
[Epoch 65; Iter   390/  960] train: loss: 0.0324016
[Epoch 65; Iter   420/  960] train: loss: 0.0621544
[Epoch 65; Iter   450/  960] train: loss: 0.0244367
[Epoch 65; Iter   480/  960] train: loss: 0.0045916
[Epoch 65; Iter   510/  960] train: loss: 0.0164549
[Epoch 65; Iter   540/  960] train: loss: 0.0051629
[Epoch 65; Iter   570/  960] train: loss: 0.1059919
[Epoch 65; Iter   600/  960] train: loss: 0.0937408
[Epoch 65; Iter   630/  960] train: loss: 0.0116169
[Epoch 65; Iter   660/  960] train: loss: 0.0473214
[Epoch 65; Iter   690/  960] train: loss: 0.0606076
[Epoch 65; Iter   720/  960] train: loss: 0.0078423
[Epoch 65; Iter   750/  960] train: loss: 0.0177929
[Epoch 65; Iter   780/  960] train: loss: 0.0315540
[Epoch 65; Iter   810/  960] train: loss: 0.0423454
[Epoch 65; Iter   840/  960] train: loss: 0.0161822
[Epoch 65; Iter   870/  960] train: loss: 0.0190133
[Epoch 65; Iter   900/  960] train: loss: 0.0143321
[Epoch 65; Iter   930/  960] train: loss: 0.0108174
[Epoch 65; Iter   960/  960] train: loss: 0.0019140
[Epoch 65] ogbg-molhiv: 0.755920 val loss: 0.589969
[Epoch 65] ogbg-molhiv: 0.754787 test loss: 0.217371
[Epoch 66; Iter    30/  960] train: loss: 0.0357877
[Epoch 66; Iter    60/  960] train: loss: 0.0288074
[Epoch 66; Iter    90/  960] train: loss: 0.0591625
[Epoch 66; Iter   120/  960] train: loss: 0.0321643
[Epoch 66; Iter   150/  960] train: loss: 0.0921290
[Epoch 66; Iter   180/  960] train: loss: 0.0111796
[Epoch 66; Iter   210/  960] train: loss: 0.0195592
[Epoch 66; Iter   240/  960] train: loss: 0.0055067
[Epoch 66; Iter   270/  960] train: loss: 0.1069351
[Epoch 66; Iter   300/  960] train: loss: 0.0124041
[Epoch 66; Iter   330/  960] train: loss: 0.0773377
[Epoch 66; Iter   360/  960] train: loss: 0.0172483
[Epoch 66; Iter   390/  960] train: loss: 0.0034559
[Epoch 66; Iter   420/  960] train: loss: 0.1277355
[Epoch 66; Iter   450/  960] train: loss: 0.0291041
[Epoch 66; Iter   480/  960] train: loss: 0.0233199
[Epoch 66; Iter   510/  960] train: loss: 0.0035644
[Epoch 66; Iter   540/  960] train: loss: 0.0286416
[Epoch 66; Iter   570/  960] train: loss: 0.0219115
[Epoch 66; Iter   600/  960] train: loss: 0.0914818
[Epoch 66; Iter   630/  960] train: loss: 0.1243011
[Epoch 66; Iter   660/  960] train: loss: 0.0657133
[Epoch 66; Iter   690/  960] train: loss: 0.0034990
[Epoch 66; Iter   720/  960] train: loss: 0.0031386
[Epoch 66; Iter   750/  960] train: loss: 0.1492837
[Epoch 66; Iter   780/  960] train: loss: 0.0063621
[Epoch 66; Iter   810/  960] train: loss: 0.0511785
[Epoch 66; Iter   840/  960] train: loss: 0.2139595
[Epoch 66; Iter   870/  960] train: loss: 0.1091887
[Epoch 66; Iter   900/  960] train: loss: 0.0665634
[Epoch 66; Iter   930/  960] train: loss: 0.0680395
[Epoch 66; Iter   960/  960] train: loss: 0.0060912
[Epoch 66] ogbg-molhiv: 0.759917 val loss: 0.216563
[Epoch 66] ogbg-molhiv: 0.745524 test loss: 0.199095
[Epoch 67; Iter    30/  960] train: loss: 0.0804728
[Epoch 67; Iter    60/  960] train: loss: 0.0625495
[Epoch 67; Iter    90/  960] train: loss: 0.0113265
[Epoch 67; Iter   120/  960] train: loss: 0.0059007
[Epoch 67; Iter   150/  960] train: loss: 0.0598353
[Epoch 67; Iter   180/  960] train: loss: 0.0102656
[Epoch 67; Iter   210/  960] train: loss: 0.0709703
[Epoch 67; Iter   240/  960] train: loss: 0.0119040
[Epoch 67; Iter   270/  960] train: loss: 0.0164811
[Epoch 67; Iter   300/  960] train: loss: 0.0504104
[Epoch 67; Iter   330/  960] train: loss: 0.0205115
[Epoch 67; Iter   360/  960] train: loss: 0.0095582
[Epoch 67; Iter   390/  960] train: loss: 0.0311586
[Epoch 67; Iter   420/  960] train: loss: 0.0464937
[Epoch 67; Iter   450/  960] train: loss: 0.0749095
[Epoch 67; Iter   480/  960] train: loss: 0.0074420
[Epoch 67; Iter   510/  960] train: loss: 0.0105660
[Epoch 67; Iter   540/  960] train: loss: 0.0199472
[Epoch 67; Iter   570/  960] train: loss: 0.0279033
[Epoch 67; Iter   600/  960] train: loss: 0.0352954
[Epoch 67; Iter   630/  960] train: loss: 0.0059961
[Epoch 67; Iter   660/  960] train: loss: 0.0628627
[Epoch 67; Iter   690/  960] train: loss: 0.0242137
[Epoch 67; Iter   720/  960] train: loss: 0.0335778
[Epoch 67; Iter   750/  960] train: loss: 0.1338881
[Epoch 67; Iter   780/  960] train: loss: 0.0406290
[Epoch 67; Iter   810/  960] train: loss: 0.0382197
[Epoch 67; Iter   840/  960] train: loss: 0.0073966
[Epoch 67; Iter   870/  960] train: loss: 0.0469678
[Epoch 67; Iter   900/  960] train: loss: 0.0150344
[Epoch 67; Iter   930/  960] train: loss: 0.0073917
[Epoch 67; Iter   960/  960] train: loss: 0.0018031
[Epoch 67] ogbg-molhiv: 0.754983 val loss: 0.444860
[Epoch 67] ogbg-molhiv: 0.765882 test loss: 0.205729
[Epoch 68; Iter    30/  960] train: loss: 0.0156863
[Epoch 68; Iter    60/  960] train: loss: 0.0242437
[Epoch 68; Iter    90/  960] train: loss: 0.0140638
[Epoch 68; Iter   120/  960] train: loss: 0.0183032
[Epoch 68; Iter   150/  960] train: loss: 0.0139215
[Epoch 68; Iter   180/  960] train: loss: 0.0586716
[Epoch 68; Iter   210/  960] train: loss: 0.1322844
[Epoch 68; Iter   240/  960] train: loss: 0.0119489
[Epoch 68; Iter   270/  960] train: loss: 0.0138163
[Epoch 68; Iter   300/  960] train: loss: 0.0150584
[Epoch 68; Iter   330/  960] train: loss: 0.0233179
[Epoch 68; Iter   360/  960] train: loss: 0.1366864
[Epoch 68; Iter   390/  960] train: loss: 0.0220044
[Epoch 68; Iter   420/  960] train: loss: 0.0072279
[Epoch 68; Iter   450/  960] train: loss: 0.0068365
[Epoch 68; Iter   480/  960] train: loss: 0.0529221
[Epoch 68; Iter   510/  960] train: loss: 0.1442979
[Epoch 68; Iter   540/  960] train: loss: 0.1508969
[Epoch 68; Iter   570/  960] train: loss: 0.0116709
[Epoch 68; Iter   600/  960] train: loss: 0.1173888
[Epoch 68; Iter   630/  960] train: loss: 0.0020224
[Epoch 68; Iter   660/  960] train: loss: 0.0230638
[Epoch 68; Iter   690/  960] train: loss: 0.0496876
[Epoch 68; Iter   720/  960] train: loss: 0.0384044
[Epoch 68; Iter   750/  960] train: loss: 0.0128004
[Epoch 68; Iter   780/  960] train: loss: 0.0608293
[Epoch 68; Iter   810/  960] train: loss: 0.0192709
[Epoch 68; Iter   840/  960] train: loss: 0.0376955
[Epoch 68; Iter   870/  960] train: loss: 0.0039718
[Epoch 68; Iter   900/  960] train: loss: 0.0032158
[Epoch 68; Iter   930/  960] train: loss: 0.1051282
[Epoch 68; Iter   960/  960] train: loss: 0.0422322
[Epoch 68] ogbg-molhiv: 0.756362 val loss: 0.602408
[Epoch 68] ogbg-molhiv: 0.755048 test loss: 0.204179
[Epoch 68; Iter   779/  823] train: loss: 0.0078335
[Epoch 68; Iter   809/  823] train: loss: 0.1265342
[Epoch 68] ogbg-molhiv: 0.731824 val loss: 0.269303
[Epoch 68] ogbg-molhiv: 0.755125 test loss: 0.329032
[Epoch 69; Iter    16/  823] train: loss: 0.1593692
[Epoch 69; Iter    46/  823] train: loss: 0.0195322
[Epoch 69; Iter    76/  823] train: loss: 0.0577625
[Epoch 69; Iter   106/  823] train: loss: 0.0062696
[Epoch 69; Iter   136/  823] train: loss: 0.0715218
[Epoch 69; Iter   166/  823] train: loss: 0.0324918
[Epoch 69; Iter   196/  823] train: loss: 0.1060408
[Epoch 69; Iter   226/  823] train: loss: 0.0451066
[Epoch 69; Iter   256/  823] train: loss: 0.0238127
[Epoch 69; Iter   286/  823] train: loss: 0.0191137
[Epoch 69; Iter   316/  823] train: loss: 0.0318337
[Epoch 69; Iter   346/  823] train: loss: 0.0482459
[Epoch 69; Iter   376/  823] train: loss: 0.0068816
[Epoch 69; Iter   406/  823] train: loss: 0.0231726
[Epoch 69; Iter   436/  823] train: loss: 0.1061446
[Epoch 69; Iter   466/  823] train: loss: 0.0311786
[Epoch 69; Iter   496/  823] train: loss: 0.0094920
[Epoch 69; Iter   526/  823] train: loss: 0.0072366
[Epoch 69; Iter   556/  823] train: loss: 0.1781511
[Epoch 69; Iter   586/  823] train: loss: 0.0317609
[Epoch 69; Iter   616/  823] train: loss: 0.0081885
[Epoch 69; Iter   646/  823] train: loss: 0.0076784
[Epoch 69; Iter   676/  823] train: loss: 0.0087004
[Epoch 69; Iter   706/  823] train: loss: 0.0085298
[Epoch 69; Iter   736/  823] train: loss: 0.1127173
[Epoch 69; Iter   766/  823] train: loss: 0.0319416
[Epoch 69; Iter   796/  823] train: loss: 0.0492575
[Epoch 69] ogbg-molhiv: 0.740467 val loss: 0.242078
[Epoch 69] ogbg-molhiv: 0.753913 test loss: 0.275535
[Epoch 70; Iter     3/  823] train: loss: 0.0160810
[Epoch 70; Iter    33/  823] train: loss: 0.0032351
[Epoch 70; Iter    63/  823] train: loss: 0.0071650
[Epoch 70; Iter    93/  823] train: loss: 0.0098599
[Epoch 70; Iter   123/  823] train: loss: 0.0126362
[Epoch 70; Iter   153/  823] train: loss: 0.0825457
[Epoch 70; Iter   183/  823] train: loss: 0.0425117
[Epoch 70; Iter   213/  823] train: loss: 0.0116801
[Epoch 70; Iter   243/  823] train: loss: 0.0262655
[Epoch 70; Iter   273/  823] train: loss: 0.0446698
[Epoch 70; Iter   303/  823] train: loss: 0.0110328
[Epoch 70; Iter   333/  823] train: loss: 0.0944829
[Epoch 70; Iter   363/  823] train: loss: 0.0079287
[Epoch 70; Iter   393/  823] train: loss: 0.1020521
[Epoch 70; Iter   423/  823] train: loss: 0.0453678
[Epoch 70; Iter   453/  823] train: loss: 0.0085404
[Epoch 70; Iter   483/  823] train: loss: 0.0127338
[Epoch 70; Iter   513/  823] train: loss: 0.0077546
[Epoch 70; Iter   543/  823] train: loss: 0.0067404
[Epoch 70; Iter   573/  823] train: loss: 0.0272862
[Epoch 70; Iter   603/  823] train: loss: 0.1641337
[Epoch 70; Iter   633/  823] train: loss: 0.1317047
[Epoch 70; Iter   663/  823] train: loss: 0.0066981
[Epoch 70; Iter   693/  823] train: loss: 0.0385456
[Epoch 70; Iter   723/  823] train: loss: 0.1007950
[Epoch 70; Iter   753/  823] train: loss: 0.0162208
[Epoch 70; Iter   783/  823] train: loss: 0.0043228
[Epoch 70; Iter   813/  823] train: loss: 0.0253171
[Epoch 70] ogbg-molhiv: 0.726648 val loss: 0.236609
[Epoch 70] ogbg-molhiv: 0.750292 test loss: 0.321166
[Epoch 71; Iter    20/  823] train: loss: 0.0114410
[Epoch 71; Iter    50/  823] train: loss: 0.0213709
[Epoch 71; Iter    80/  823] train: loss: 0.0199444
[Epoch 71; Iter   110/  823] train: loss: 0.0453022
[Epoch 71; Iter   140/  823] train: loss: 0.0840898
[Epoch 71; Iter   170/  823] train: loss: 0.0044485
[Epoch 71; Iter   200/  823] train: loss: 0.0678452
[Epoch 71; Iter   230/  823] train: loss: 0.0827152
[Epoch 71; Iter   260/  823] train: loss: 0.0366720
[Epoch 71; Iter   290/  823] train: loss: 0.0098938
[Epoch 71; Iter   320/  823] train: loss: 0.0442637
[Epoch 71; Iter   350/  823] train: loss: 0.0434732
[Epoch 71; Iter   380/  823] train: loss: 0.0808119
[Epoch 71; Iter   410/  823] train: loss: 0.0332503
[Epoch 71; Iter   440/  823] train: loss: 0.0363971
[Epoch 71; Iter   470/  823] train: loss: 0.0087091
[Epoch 71; Iter   500/  823] train: loss: 0.0133342
[Epoch 71; Iter   530/  823] train: loss: 0.0092725
[Epoch 71; Iter   560/  823] train: loss: 0.0139058
[Epoch 71; Iter   590/  823] train: loss: 0.0398352
[Epoch 71; Iter   620/  823] train: loss: 0.0298966
[Epoch 71; Iter   650/  823] train: loss: 0.0135354
[Epoch 71; Iter   680/  823] train: loss: 0.0890499
[Epoch 71; Iter   710/  823] train: loss: 0.2381513
[Epoch 71; Iter   740/  823] train: loss: 0.0415109
[Epoch 71; Iter   770/  823] train: loss: 0.0053655
[Epoch 71; Iter   800/  823] train: loss: 0.0702743
[Epoch 71] ogbg-molhiv: 0.736759 val loss: 0.247497
[Epoch 71] ogbg-molhiv: 0.750298 test loss: 0.203647
[Epoch 72; Iter     7/  823] train: loss: 0.0073083
[Epoch 72; Iter    37/  823] train: loss: 0.0205109
[Epoch 72; Iter    67/  823] train: loss: 0.0127847
[Epoch 72; Iter    97/  823] train: loss: 0.0183294
[Epoch 72; Iter   127/  823] train: loss: 0.0479061
[Epoch 72; Iter   157/  823] train: loss: 0.0020035
[Epoch 72; Iter   187/  823] train: loss: 0.0159844
[Epoch 72; Iter   217/  823] train: loss: 0.0946566
[Epoch 72; Iter   247/  823] train: loss: 0.0115979
[Epoch 72; Iter   277/  823] train: loss: 0.0097409
[Epoch 72; Iter   307/  823] train: loss: 0.0434766
[Epoch 72; Iter   337/  823] train: loss: 0.0044509
[Epoch 72; Iter   367/  823] train: loss: 0.0113984
[Epoch 72; Iter   397/  823] train: loss: 0.1136454
[Epoch 72; Iter   427/  823] train: loss: 0.0329635
[Epoch 72; Iter   457/  823] train: loss: 0.0040926
[Epoch 72; Iter   487/  823] train: loss: 0.0066894
[Epoch 72; Iter   517/  823] train: loss: 0.0243709
[Epoch 72; Iter   547/  823] train: loss: 0.0221166
[Epoch 72; Iter   577/  823] train: loss: 0.0049143
[Epoch 72; Iter   607/  823] train: loss: 0.0057385
[Epoch 72; Iter   637/  823] train: loss: 0.0534420
[Epoch 72; Iter   667/  823] train: loss: 0.1487224
[Epoch 72; Iter   697/  823] train: loss: 0.0046415
[Epoch 72; Iter   727/  823] train: loss: 0.0059510
[Epoch 72; Iter   757/  823] train: loss: 0.0309339
[Epoch 72; Iter   787/  823] train: loss: 0.0274462
[Epoch 72; Iter   817/  823] train: loss: 0.1556855
[Epoch 72] ogbg-molhiv: 0.739582 val loss: 0.210403
[Epoch 72] ogbg-molhiv: 0.751591 test loss: 0.333667
[Epoch 73; Iter    24/  823] train: loss: 0.0112577
[Epoch 73; Iter    54/  823] train: loss: 0.0545337
[Epoch 73; Iter    84/  823] train: loss: 0.0078405
[Epoch 73; Iter   114/  823] train: loss: 0.0042677
[Epoch 73; Iter   144/  823] train: loss: 0.0079034
[Epoch 73; Iter   174/  823] train: loss: 0.0392604
[Epoch 73; Iter   204/  823] train: loss: 0.0073271
[Epoch 73; Iter   234/  823] train: loss: 0.0031492
[Epoch 73; Iter   264/  823] train: loss: 0.1201820
[Epoch 73; Iter   294/  823] train: loss: 0.0122865
[Epoch 73; Iter   324/  823] train: loss: 0.0044358
[Epoch 73; Iter   354/  823] train: loss: 0.1298692
[Epoch 73; Iter   384/  823] train: loss: 0.0053744
[Epoch 73; Iter   414/  823] train: loss: 0.0854480
[Epoch 73; Iter   444/  823] train: loss: 0.1156536
[Epoch 73; Iter   474/  823] train: loss: 0.0091999
[Epoch 73; Iter   504/  823] train: loss: 0.0036065
[Epoch 73; Iter   534/  823] train: loss: 0.1055419
[Epoch 73; Iter   564/  823] train: loss: 0.2195791
[Epoch 73; Iter   594/  823] train: loss: 0.0033709
[Epoch 73; Iter   624/  823] train: loss: 0.0125651
[Epoch 73; Iter   654/  823] train: loss: 0.0524134
[Epoch 73; Iter   684/  823] train: loss: 0.0186408
[Epoch 73; Iter   714/  823] train: loss: 0.0508693
[Epoch 73; Iter   744/  823] train: loss: 0.0290649
[Epoch 73; Iter   774/  823] train: loss: 0.0031084
[Epoch 73; Iter   804/  823] train: loss: 0.0408191
[Epoch 73] ogbg-molhiv: 0.743913 val loss: 0.219282
[Epoch 73] ogbg-molhiv: 0.747285 test loss: 0.247911
[Epoch 74; Iter    11/  823] train: loss: 0.0170169
[Epoch 74; Iter    41/  823] train: loss: 0.0203194
[Epoch 74; Iter    71/  823] train: loss: 0.0271559
[Epoch 74; Iter   101/  823] train: loss: 0.0309452
[Epoch 74; Iter   131/  823] train: loss: 0.0565689
[Epoch 74; Iter   161/  823] train: loss: 0.0234185
[Epoch 65; Iter    52/ 1097] train: loss: 0.0150124
[Epoch 65; Iter    82/ 1097] train: loss: 0.0209512
[Epoch 65; Iter   112/ 1097] train: loss: 0.0142318
[Epoch 65; Iter   142/ 1097] train: loss: 0.0651483
[Epoch 65; Iter   172/ 1097] train: loss: 0.0101622
[Epoch 65; Iter   202/ 1097] train: loss: 0.0105206
[Epoch 65; Iter   232/ 1097] train: loss: 0.0099431
[Epoch 65; Iter   262/ 1097] train: loss: 0.0052681
[Epoch 65; Iter   292/ 1097] train: loss: 0.0121556
[Epoch 65; Iter   322/ 1097] train: loss: 0.0385562
[Epoch 65; Iter   352/ 1097] train: loss: 0.0518905
[Epoch 65; Iter   382/ 1097] train: loss: 0.0190625
[Epoch 65; Iter   412/ 1097] train: loss: 0.0143668
[Epoch 65; Iter   442/ 1097] train: loss: 0.0101650
[Epoch 65; Iter   472/ 1097] train: loss: 0.0034189
[Epoch 65; Iter   502/ 1097] train: loss: 0.0250169
[Epoch 65; Iter   532/ 1097] train: loss: 0.1149078
[Epoch 65; Iter   562/ 1097] train: loss: 0.0069667
[Epoch 65; Iter   592/ 1097] train: loss: 0.0424685
[Epoch 65; Iter   622/ 1097] train: loss: 0.0213745
[Epoch 65; Iter   652/ 1097] train: loss: 0.0540429
[Epoch 65; Iter   682/ 1097] train: loss: 0.0081184
[Epoch 65; Iter   712/ 1097] train: loss: 0.2001844
[Epoch 65; Iter   742/ 1097] train: loss: 0.0110200
[Epoch 65; Iter   772/ 1097] train: loss: 0.1266469
[Epoch 65; Iter   802/ 1097] train: loss: 0.0163193
[Epoch 65; Iter   832/ 1097] train: loss: 0.0624360
[Epoch 65; Iter   862/ 1097] train: loss: 0.0184347
[Epoch 65; Iter   892/ 1097] train: loss: 0.0850550
[Epoch 65; Iter   922/ 1097] train: loss: 0.0378075
[Epoch 65; Iter   952/ 1097] train: loss: 0.0637013
[Epoch 65; Iter   982/ 1097] train: loss: 0.2318223
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0145346
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0134766
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0261370
[Epoch 65] ogbg-molhiv: 0.756063 val loss: 0.210295
[Epoch 65] ogbg-molhiv: 0.733446 test loss: 0.463769
[Epoch 66; Iter     5/ 1097] train: loss: 0.0036426
[Epoch 66; Iter    35/ 1097] train: loss: 0.0111933
[Epoch 66; Iter    65/ 1097] train: loss: 0.0123586
[Epoch 66; Iter    95/ 1097] train: loss: 0.0496738
[Epoch 66; Iter   125/ 1097] train: loss: 0.0035356
[Epoch 66; Iter   155/ 1097] train: loss: 0.0081282
[Epoch 66; Iter   185/ 1097] train: loss: 0.0057362
[Epoch 66; Iter   215/ 1097] train: loss: 0.0103078
[Epoch 66; Iter   245/ 1097] train: loss: 0.0295069
[Epoch 66; Iter   275/ 1097] train: loss: 0.0601249
[Epoch 66; Iter   305/ 1097] train: loss: 0.0174440
[Epoch 66; Iter   335/ 1097] train: loss: 0.1191469
[Epoch 66; Iter   365/ 1097] train: loss: 0.0048808
[Epoch 66; Iter   395/ 1097] train: loss: 0.0074609
[Epoch 66; Iter   425/ 1097] train: loss: 0.0040996
[Epoch 66; Iter   455/ 1097] train: loss: 0.0097681
[Epoch 66; Iter   485/ 1097] train: loss: 0.0334830
[Epoch 66; Iter   515/ 1097] train: loss: 0.1463387
[Epoch 66; Iter   545/ 1097] train: loss: 0.0177636
[Epoch 66; Iter   575/ 1097] train: loss: 0.1132338
[Epoch 66; Iter   605/ 1097] train: loss: 0.0029424
[Epoch 66; Iter   635/ 1097] train: loss: 0.0145236
[Epoch 66; Iter   665/ 1097] train: loss: 0.0141102
[Epoch 66; Iter   695/ 1097] train: loss: 0.1174257
[Epoch 66; Iter   725/ 1097] train: loss: 0.1239133
[Epoch 66; Iter   755/ 1097] train: loss: 0.0700005
[Epoch 66; Iter   785/ 1097] train: loss: 0.0543671
[Epoch 66; Iter   815/ 1097] train: loss: 0.0380321
[Epoch 66; Iter   845/ 1097] train: loss: 0.0228503
[Epoch 66; Iter   875/ 1097] train: loss: 0.0407758
[Epoch 66; Iter   905/ 1097] train: loss: 0.0103938
[Epoch 66; Iter   935/ 1097] train: loss: 0.0053788
[Epoch 66; Iter   965/ 1097] train: loss: 0.0251098
[Epoch 66; Iter   995/ 1097] train: loss: 0.0131684
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0079845
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0185629
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0129131
[Epoch 66] ogbg-molhiv: 0.761055 val loss: 0.218113
[Epoch 66] ogbg-molhiv: 0.730935 test loss: 0.454706
[Epoch 67; Iter    18/ 1097] train: loss: 0.0136875
[Epoch 67; Iter    48/ 1097] train: loss: 0.0066416
[Epoch 67; Iter    78/ 1097] train: loss: 0.0104500
[Epoch 67; Iter   108/ 1097] train: loss: 0.0070258
[Epoch 67; Iter   138/ 1097] train: loss: 0.0252604
[Epoch 67; Iter   168/ 1097] train: loss: 0.0602771
[Epoch 67; Iter   198/ 1097] train: loss: 0.0242094
[Epoch 67; Iter   228/ 1097] train: loss: 0.0152661
[Epoch 67; Iter   258/ 1097] train: loss: 0.0357113
[Epoch 67; Iter   288/ 1097] train: loss: 0.0192267
[Epoch 67; Iter   318/ 1097] train: loss: 0.0128307
[Epoch 67; Iter   348/ 1097] train: loss: 0.0578020
[Epoch 67; Iter   378/ 1097] train: loss: 0.0171351
[Epoch 67; Iter   408/ 1097] train: loss: 0.0071159
[Epoch 67; Iter   438/ 1097] train: loss: 0.0036461
[Epoch 67; Iter   468/ 1097] train: loss: 0.0715338
[Epoch 67; Iter   498/ 1097] train: loss: 0.0126966
[Epoch 67; Iter   528/ 1097] train: loss: 0.0132332
[Epoch 67; Iter   558/ 1097] train: loss: 0.0330478
[Epoch 67; Iter   588/ 1097] train: loss: 0.0112923
[Epoch 67; Iter   618/ 1097] train: loss: 0.1058266
[Epoch 67; Iter   648/ 1097] train: loss: 0.0290423
[Epoch 67; Iter   678/ 1097] train: loss: 0.0082305
[Epoch 67; Iter   708/ 1097] train: loss: 0.0243991
[Epoch 67; Iter   738/ 1097] train: loss: 0.0232763
[Epoch 67; Iter   768/ 1097] train: loss: 0.0123347
[Epoch 67; Iter   798/ 1097] train: loss: 0.0963869
[Epoch 67; Iter   828/ 1097] train: loss: 0.1749736
[Epoch 67; Iter   858/ 1097] train: loss: 0.0067857
[Epoch 67; Iter   888/ 1097] train: loss: 0.0336641
[Epoch 67; Iter   918/ 1097] train: loss: 0.0065381
[Epoch 67; Iter   948/ 1097] train: loss: 0.0592667
[Epoch 67; Iter   978/ 1097] train: loss: 0.0189546
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0065676
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0071013
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0243807
[Epoch 67] ogbg-molhiv: 0.761978 val loss: 0.260817
[Epoch 67] ogbg-molhiv: 0.732061 test loss: 0.603450
[Epoch 68; Iter     1/ 1097] train: loss: 0.1535042
[Epoch 68; Iter    31/ 1097] train: loss: 0.0207790
[Epoch 68; Iter    61/ 1097] train: loss: 0.1054949
[Epoch 68; Iter    91/ 1097] train: loss: 0.0380903
[Epoch 68; Iter   121/ 1097] train: loss: 0.0073238
[Epoch 68; Iter   151/ 1097] train: loss: 0.0130550
[Epoch 68; Iter   181/ 1097] train: loss: 0.0110968
[Epoch 68; Iter   211/ 1097] train: loss: 0.0249764
[Epoch 68; Iter   241/ 1097] train: loss: 0.0033016
[Epoch 68; Iter   271/ 1097] train: loss: 0.0634879
[Epoch 68; Iter   301/ 1097] train: loss: 0.0144442
[Epoch 68; Iter   331/ 1097] train: loss: 0.0055619
[Epoch 68; Iter   361/ 1097] train: loss: 0.0122805
[Epoch 68; Iter   391/ 1097] train: loss: 0.0106365
[Epoch 68; Iter   421/ 1097] train: loss: 0.0219843
[Epoch 68; Iter   451/ 1097] train: loss: 0.0935526
[Epoch 68; Iter   481/ 1097] train: loss: 0.0143178
[Epoch 68; Iter   511/ 1097] train: loss: 0.0133712
[Epoch 68; Iter   541/ 1097] train: loss: 0.0067112
[Epoch 68; Iter   571/ 1097] train: loss: 0.1287623
[Epoch 68; Iter   601/ 1097] train: loss: 0.0594619
[Epoch 68; Iter   631/ 1097] train: loss: 0.0120797
[Epoch 68; Iter   661/ 1097] train: loss: 0.0456899
[Epoch 68; Iter   691/ 1097] train: loss: 0.0983334
[Epoch 68; Iter   721/ 1097] train: loss: 0.0057768
[Epoch 68; Iter   751/ 1097] train: loss: 0.0369231
[Epoch 68; Iter   781/ 1097] train: loss: 0.0043850
[Epoch 68; Iter   811/ 1097] train: loss: 0.1071740
[Epoch 68; Iter   841/ 1097] train: loss: 0.0511265
[Epoch 68; Iter   871/ 1097] train: loss: 0.0400680
[Epoch 68; Iter   901/ 1097] train: loss: 0.0116053
[Epoch 68; Iter   931/ 1097] train: loss: 0.0109727
[Epoch 68; Iter   961/ 1097] train: loss: 0.0261982
[Epoch 68; Iter   991/ 1097] train: loss: 0.1296885
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0256164
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0450447
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0409268
[Epoch 68] ogbg-molhiv: 0.757489 val loss: 0.132740
[Epoch 68] ogbg-molhiv: 0.716006 test loss: 0.283564
[Epoch 69; Iter    14/ 1097] train: loss: 0.0063827
[Epoch 69; Iter    44/ 1097] train: loss: 0.0699507
[Epoch 69; Iter    74/ 1097] train: loss: 0.0254635
[Epoch 69; Iter   104/ 1097] train: loss: 0.0185193
[Epoch 68; Iter   779/  823] train: loss: 0.0274188
[Epoch 68; Iter   809/  823] train: loss: 0.0041870
[Epoch 68] ogbg-molhiv: 0.703884 val loss: 0.328143
[Epoch 68] ogbg-molhiv: 0.741563 test loss: 0.268686
[Epoch 69; Iter    16/  823] train: loss: 0.0054179
[Epoch 69; Iter    46/  823] train: loss: 0.0052539
[Epoch 69; Iter    76/  823] train: loss: 0.1105831
[Epoch 69; Iter   106/  823] train: loss: 0.0785144
[Epoch 69; Iter   136/  823] train: loss: 0.0069876
[Epoch 69; Iter   166/  823] train: loss: 0.0093377
[Epoch 69; Iter   196/  823] train: loss: 0.0027748
[Epoch 69; Iter   226/  823] train: loss: 0.0864584
[Epoch 69; Iter   256/  823] train: loss: 0.0077917
[Epoch 69; Iter   286/  823] train: loss: 0.0998744
[Epoch 69; Iter   316/  823] train: loss: 0.0095889
[Epoch 69; Iter   346/  823] train: loss: 0.0713121
[Epoch 69; Iter   376/  823] train: loss: 0.0405159
[Epoch 69; Iter   406/  823] train: loss: 0.0219696
[Epoch 69; Iter   436/  823] train: loss: 0.0067470
[Epoch 69; Iter   466/  823] train: loss: 0.0069163
[Epoch 69; Iter   496/  823] train: loss: 0.0489710
[Epoch 69; Iter   526/  823] train: loss: 0.0552661
[Epoch 69; Iter   556/  823] train: loss: 0.0019716
[Epoch 69; Iter   586/  823] train: loss: 0.0158519
[Epoch 69; Iter   616/  823] train: loss: 0.2065339
[Epoch 69; Iter   646/  823] train: loss: 0.0056910
[Epoch 69; Iter   676/  823] train: loss: 0.0410704
[Epoch 69; Iter   706/  823] train: loss: 0.0295683
[Epoch 69; Iter   736/  823] train: loss: 0.0048974
[Epoch 69; Iter   766/  823] train: loss: 0.0077955
[Epoch 69; Iter   796/  823] train: loss: 0.0023006
[Epoch 69] ogbg-molhiv: 0.700456 val loss: 0.317058
[Epoch 69] ogbg-molhiv: 0.746968 test loss: 0.208790
[Epoch 70; Iter     3/  823] train: loss: 0.0175376
[Epoch 70; Iter    33/  823] train: loss: 0.0175347
[Epoch 70; Iter    63/  823] train: loss: 0.0057926
[Epoch 70; Iter    93/  823] train: loss: 0.0419212
[Epoch 70; Iter   123/  823] train: loss: 0.0095640
[Epoch 70; Iter   153/  823] train: loss: 0.0098170
[Epoch 70; Iter   183/  823] train: loss: 0.0241017
[Epoch 70; Iter   213/  823] train: loss: 0.0282986
[Epoch 70; Iter   243/  823] train: loss: 0.0152354
[Epoch 70; Iter   273/  823] train: loss: 0.0374029
[Epoch 70; Iter   303/  823] train: loss: 0.0028238
[Epoch 70; Iter   333/  823] train: loss: 0.0142695
[Epoch 70; Iter   363/  823] train: loss: 0.0346831
[Epoch 70; Iter   393/  823] train: loss: 0.0813463
[Epoch 70; Iter   423/  823] train: loss: 0.0077141
[Epoch 70; Iter   453/  823] train: loss: 0.0054717
[Epoch 70; Iter   483/  823] train: loss: 0.0646385
[Epoch 70; Iter   513/  823] train: loss: 0.0490854
[Epoch 70; Iter   543/  823] train: loss: 0.0109293
[Epoch 70; Iter   573/  823] train: loss: 0.1771313
[Epoch 70; Iter   603/  823] train: loss: 0.0223066
[Epoch 70; Iter   633/  823] train: loss: 0.0964304
[Epoch 70; Iter   663/  823] train: loss: 0.0234515
[Epoch 70; Iter   693/  823] train: loss: 0.0611188
[Epoch 70; Iter   723/  823] train: loss: 0.0143872
[Epoch 70; Iter   753/  823] train: loss: 0.0058945
[Epoch 70; Iter   783/  823] train: loss: 0.0610075
[Epoch 70; Iter   813/  823] train: loss: 0.0086433
[Epoch 70] ogbg-molhiv: 0.702009 val loss: 0.309927
[Epoch 70] ogbg-molhiv: 0.732791 test loss: 0.210103
[Epoch 71; Iter    20/  823] train: loss: 0.0235869
[Epoch 71; Iter    50/  823] train: loss: 0.0259596
[Epoch 71; Iter    80/  823] train: loss: 0.0838697
[Epoch 71; Iter   110/  823] train: loss: 0.0369403
[Epoch 71; Iter   140/  823] train: loss: 0.0412510
[Epoch 71; Iter   170/  823] train: loss: 0.0036138
[Epoch 71; Iter   200/  823] train: loss: 0.0017150
[Epoch 71; Iter   230/  823] train: loss: 0.1032945
[Epoch 71; Iter   260/  823] train: loss: 0.0058564
[Epoch 71; Iter   290/  823] train: loss: 0.0046070
[Epoch 71; Iter   320/  823] train: loss: 0.0035114
[Epoch 71; Iter   350/  823] train: loss: 0.0016686
[Epoch 71; Iter   380/  823] train: loss: 0.0276030
[Epoch 71; Iter   410/  823] train: loss: 0.0585217
[Epoch 71; Iter   440/  823] train: loss: 0.0117597
[Epoch 71; Iter   470/  823] train: loss: 0.2043835
[Epoch 71; Iter   500/  823] train: loss: 0.0030561
[Epoch 71; Iter   530/  823] train: loss: 0.0059360
[Epoch 71; Iter   560/  823] train: loss: 0.0015008
[Epoch 71; Iter   590/  823] train: loss: 0.0055890
[Epoch 71; Iter   620/  823] train: loss: 0.0140268
[Epoch 71; Iter   650/  823] train: loss: 0.1097340
[Epoch 71; Iter   680/  823] train: loss: 0.0171716
[Epoch 71; Iter   710/  823] train: loss: 0.0078274
[Epoch 71; Iter   740/  823] train: loss: 0.0022740
[Epoch 71; Iter   770/  823] train: loss: 0.0063145
[Epoch 71; Iter   800/  823] train: loss: 0.0395719
[Epoch 71] ogbg-molhiv: 0.711720 val loss: 0.292048
[Epoch 71] ogbg-molhiv: 0.738943 test loss: 0.196716
[Epoch 72; Iter     7/  823] train: loss: 0.0080865
[Epoch 72; Iter    37/  823] train: loss: 0.0448572
[Epoch 72; Iter    67/  823] train: loss: 0.1238617
[Epoch 72; Iter    97/  823] train: loss: 0.0163421
[Epoch 72; Iter   127/  823] train: loss: 0.0029380
[Epoch 72; Iter   157/  823] train: loss: 0.0045474
[Epoch 72; Iter   187/  823] train: loss: 0.0038906
[Epoch 72; Iter   217/  823] train: loss: 0.0083253
[Epoch 72; Iter   247/  823] train: loss: 0.0116624
[Epoch 72; Iter   277/  823] train: loss: 0.0013005
[Epoch 72; Iter   307/  823] train: loss: 0.0202772
[Epoch 72; Iter   337/  823] train: loss: 0.0012341
[Epoch 72; Iter   367/  823] train: loss: 0.0107191
[Epoch 72; Iter   397/  823] train: loss: 0.0053755
[Epoch 72; Iter   427/  823] train: loss: 0.0051303
[Epoch 72; Iter   457/  823] train: loss: 0.0042297
[Epoch 72; Iter   487/  823] train: loss: 0.0348995
[Epoch 72; Iter   517/  823] train: loss: 0.0070776
[Epoch 72; Iter   547/  823] train: loss: 0.1120489
[Epoch 72; Iter   577/  823] train: loss: 0.1110295
[Epoch 72; Iter   607/  823] train: loss: 0.0436950
[Epoch 72; Iter   637/  823] train: loss: 0.0025942
[Epoch 72; Iter   667/  823] train: loss: 0.1302921
[Epoch 72; Iter   697/  823] train: loss: 0.0380938
[Epoch 72; Iter   727/  823] train: loss: 0.0143595
[Epoch 72; Iter   757/  823] train: loss: 0.0857308
[Epoch 72; Iter   787/  823] train: loss: 0.0148259
[Epoch 72; Iter   817/  823] train: loss: 0.0538905
[Epoch 72] ogbg-molhiv: 0.704896 val loss: 0.281833
[Epoch 72] ogbg-molhiv: 0.742253 test loss: 0.205967
[Epoch 73; Iter    24/  823] train: loss: 0.0348286
[Epoch 73; Iter    54/  823] train: loss: 0.0021814
[Epoch 73; Iter    84/  823] train: loss: 0.0062315
[Epoch 73; Iter   114/  823] train: loss: 0.0018115
[Epoch 73; Iter   144/  823] train: loss: 0.0901298
[Epoch 73; Iter   174/  823] train: loss: 0.0154174
[Epoch 73; Iter   204/  823] train: loss: 0.0139214
[Epoch 73; Iter   234/  823] train: loss: 0.0022776
[Epoch 73; Iter   264/  823] train: loss: 0.0972370
[Epoch 73; Iter   294/  823] train: loss: 0.1365307
[Epoch 73; Iter   324/  823] train: loss: 0.0078920
[Epoch 73; Iter   354/  823] train: loss: 0.0101375
[Epoch 73; Iter   384/  823] train: loss: 0.0107463
[Epoch 73; Iter   414/  823] train: loss: 0.0410322
[Epoch 73; Iter   444/  823] train: loss: 0.0243602
[Epoch 73; Iter   474/  823] train: loss: 0.1610578
[Epoch 73; Iter   504/  823] train: loss: 0.0088004
[Epoch 73; Iter   534/  823] train: loss: 0.0030864
[Epoch 73; Iter   564/  823] train: loss: 0.0036846
[Epoch 73; Iter   594/  823] train: loss: 0.0109075
[Epoch 73; Iter   624/  823] train: loss: 0.0243191
[Epoch 73; Iter   654/  823] train: loss: 0.0131508
[Epoch 73; Iter   684/  823] train: loss: 0.0020111
[Epoch 73; Iter   714/  823] train: loss: 0.0036858
[Epoch 73; Iter   744/  823] train: loss: 0.0079271
[Epoch 73; Iter   774/  823] train: loss: 0.0430103
[Epoch 73; Iter   804/  823] train: loss: 0.0405489
[Epoch 73] ogbg-molhiv: 0.692587 val loss: 0.345578
[Epoch 73] ogbg-molhiv: 0.748671 test loss: 0.209063
[Epoch 74; Iter    11/  823] train: loss: 0.0413856
[Epoch 74; Iter    41/  823] train: loss: 0.0032171
[Epoch 74; Iter    71/  823] train: loss: 0.0027276
[Epoch 74; Iter   101/  823] train: loss: 0.0068576
[Epoch 74; Iter   131/  823] train: loss: 0.0163769
[Epoch 74; Iter   161/  823] train: loss: 0.0230065
[Epoch 65; Iter    52/ 1097] train: loss: 0.0472846
[Epoch 65; Iter    82/ 1097] train: loss: 0.0835956
[Epoch 65; Iter   112/ 1097] train: loss: 0.0762408
[Epoch 65; Iter   142/ 1097] train: loss: 0.0894397
[Epoch 65; Iter   172/ 1097] train: loss: 0.0152342
[Epoch 65; Iter   202/ 1097] train: loss: 0.0196568
[Epoch 65; Iter   232/ 1097] train: loss: 0.0024237
[Epoch 65; Iter   262/ 1097] train: loss: 0.0091373
[Epoch 65; Iter   292/ 1097] train: loss: 0.0091816
[Epoch 65; Iter   322/ 1097] train: loss: 0.0057729
[Epoch 65; Iter   352/ 1097] train: loss: 0.0140622
[Epoch 65; Iter   382/ 1097] train: loss: 0.0175592
[Epoch 65; Iter   412/ 1097] train: loss: 0.1047363
[Epoch 65; Iter   442/ 1097] train: loss: 0.0278166
[Epoch 65; Iter   472/ 1097] train: loss: 0.1070471
[Epoch 65; Iter   502/ 1097] train: loss: 0.0691553
[Epoch 65; Iter   532/ 1097] train: loss: 0.0229664
[Epoch 65; Iter   562/ 1097] train: loss: 0.1139313
[Epoch 65; Iter   592/ 1097] train: loss: 0.0606300
[Epoch 65; Iter   622/ 1097] train: loss: 0.0174817
[Epoch 65; Iter   652/ 1097] train: loss: 0.0143926
[Epoch 65; Iter   682/ 1097] train: loss: 0.0293491
[Epoch 65; Iter   712/ 1097] train: loss: 0.0126666
[Epoch 65; Iter   742/ 1097] train: loss: 0.0275256
[Epoch 65; Iter   772/ 1097] train: loss: 0.1097187
[Epoch 65; Iter   802/ 1097] train: loss: 0.0498037
[Epoch 65; Iter   832/ 1097] train: loss: 0.0325723
[Epoch 65; Iter   862/ 1097] train: loss: 0.0832618
[Epoch 65; Iter   892/ 1097] train: loss: 0.0846474
[Epoch 65; Iter   922/ 1097] train: loss: 0.0107848
[Epoch 65; Iter   952/ 1097] train: loss: 0.0157718
[Epoch 65; Iter   982/ 1097] train: loss: 0.0294338
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0307534
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0557928
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0119000
[Epoch 65] ogbg-molhiv: 0.791771 val loss: 0.102391
[Epoch 65] ogbg-molhiv: 0.740424 test loss: 0.168785
[Epoch 66; Iter     5/ 1097] train: loss: 0.0923854
[Epoch 66; Iter    35/ 1097] train: loss: 0.0639428
[Epoch 66; Iter    65/ 1097] train: loss: 0.0387156
[Epoch 66; Iter    95/ 1097] train: loss: 0.0262085
[Epoch 66; Iter   125/ 1097] train: loss: 0.0204172
[Epoch 66; Iter   155/ 1097] train: loss: 0.1540457
[Epoch 66; Iter   185/ 1097] train: loss: 0.0685937
[Epoch 66; Iter   215/ 1097] train: loss: 0.0071722
[Epoch 66; Iter   245/ 1097] train: loss: 0.0146037
[Epoch 66; Iter   275/ 1097] train: loss: 0.0151587
[Epoch 66; Iter   305/ 1097] train: loss: 0.1140324
[Epoch 66; Iter   335/ 1097] train: loss: 0.0094032
[Epoch 66; Iter   365/ 1097] train: loss: 0.0279613
[Epoch 66; Iter   395/ 1097] train: loss: 0.1206374
[Epoch 66; Iter   425/ 1097] train: loss: 0.0398633
[Epoch 66; Iter   455/ 1097] train: loss: 0.1135610
[Epoch 66; Iter   485/ 1097] train: loss: 0.0776726
[Epoch 66; Iter   515/ 1097] train: loss: 0.0484007
[Epoch 66; Iter   545/ 1097] train: loss: 0.1287695
[Epoch 66; Iter   575/ 1097] train: loss: 0.0508648
[Epoch 66; Iter   605/ 1097] train: loss: 0.0409122
[Epoch 66; Iter   635/ 1097] train: loss: 0.0820967
[Epoch 66; Iter   665/ 1097] train: loss: 0.2886587
[Epoch 66; Iter   695/ 1097] train: loss: 0.0684393
[Epoch 66; Iter   725/ 1097] train: loss: 0.1494667
[Epoch 66; Iter   755/ 1097] train: loss: 0.0420655
[Epoch 66; Iter   785/ 1097] train: loss: 0.0162220
[Epoch 66; Iter   815/ 1097] train: loss: 0.0676039
[Epoch 66; Iter   845/ 1097] train: loss: 0.0891067
[Epoch 66; Iter   875/ 1097] train: loss: 0.0785291
[Epoch 66; Iter   905/ 1097] train: loss: 0.0135592
[Epoch 66; Iter   935/ 1097] train: loss: 0.0231720
[Epoch 66; Iter   965/ 1097] train: loss: 0.1005416
[Epoch 66; Iter   995/ 1097] train: loss: 0.0281031
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0197489
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0056476
[Epoch 66; Iter  1085/ 1097] train: loss: 0.0084147
[Epoch 66] ogbg-molhiv: 0.799383 val loss: 0.101575
[Epoch 66] ogbg-molhiv: 0.732797 test loss: 0.168013
[Epoch 67; Iter    18/ 1097] train: loss: 0.0228993
[Epoch 67; Iter    48/ 1097] train: loss: 0.0304615
[Epoch 67; Iter    78/ 1097] train: loss: 0.0106378
[Epoch 67; Iter   108/ 1097] train: loss: 0.0127772
[Epoch 67; Iter   138/ 1097] train: loss: 0.0068279
[Epoch 67; Iter   168/ 1097] train: loss: 0.0179929
[Epoch 67; Iter   198/ 1097] train: loss: 0.0104649
[Epoch 67; Iter   228/ 1097] train: loss: 0.0663166
[Epoch 67; Iter   258/ 1097] train: loss: 0.0144872
[Epoch 67; Iter   288/ 1097] train: loss: 0.1909258
[Epoch 67; Iter   318/ 1097] train: loss: 0.0696967
[Epoch 67; Iter   348/ 1097] train: loss: 0.0222888
[Epoch 67; Iter   378/ 1097] train: loss: 0.0090701
[Epoch 67; Iter   408/ 1097] train: loss: 0.0836703
[Epoch 67; Iter   438/ 1097] train: loss: 0.0289419
[Epoch 67; Iter   468/ 1097] train: loss: 0.0048982
[Epoch 67; Iter   498/ 1097] train: loss: 0.0604503
[Epoch 67; Iter   528/ 1097] train: loss: 0.0647498
[Epoch 67; Iter   558/ 1097] train: loss: 0.0799411
[Epoch 67; Iter   588/ 1097] train: loss: 0.0598474
[Epoch 67; Iter   618/ 1097] train: loss: 0.0141651
[Epoch 67; Iter   648/ 1097] train: loss: 0.0072485
[Epoch 67; Iter   678/ 1097] train: loss: 0.1421175
[Epoch 67; Iter   708/ 1097] train: loss: 0.1733947
[Epoch 67; Iter   738/ 1097] train: loss: 0.0169311
[Epoch 67; Iter   768/ 1097] train: loss: 0.0180424
[Epoch 67; Iter   798/ 1097] train: loss: 0.0796943
[Epoch 67; Iter   828/ 1097] train: loss: 0.0910684
[Epoch 67; Iter   858/ 1097] train: loss: 0.0211933
[Epoch 67; Iter   888/ 1097] train: loss: 0.1467416
[Epoch 67; Iter   918/ 1097] train: loss: 0.0112519
[Epoch 67; Iter   948/ 1097] train: loss: 0.0150634
[Epoch 67; Iter   978/ 1097] train: loss: 0.0141369
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0198218
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0284981
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0231315
[Epoch 67] ogbg-molhiv: 0.798663 val loss: 0.108863
[Epoch 67] ogbg-molhiv: 0.727347 test loss: 0.179865
[Epoch 68; Iter     1/ 1097] train: loss: 0.0215555
[Epoch 68; Iter    31/ 1097] train: loss: 0.0487966
[Epoch 68; Iter    61/ 1097] train: loss: 0.0107115
[Epoch 68; Iter    91/ 1097] train: loss: 0.0066368
[Epoch 68; Iter   121/ 1097] train: loss: 0.0370131
[Epoch 68; Iter   151/ 1097] train: loss: 0.0027834
[Epoch 68; Iter   181/ 1097] train: loss: 0.0107494
[Epoch 68; Iter   211/ 1097] train: loss: 0.1370698
[Epoch 68; Iter   241/ 1097] train: loss: 0.1516122
[Epoch 68; Iter   271/ 1097] train: loss: 0.0087826
[Epoch 68; Iter   301/ 1097] train: loss: 0.0082846
[Epoch 68; Iter   331/ 1097] train: loss: 0.0147218
[Epoch 68; Iter   361/ 1097] train: loss: 0.0724963
[Epoch 68; Iter   391/ 1097] train: loss: 0.0527474
[Epoch 68; Iter   421/ 1097] train: loss: 0.0125463
[Epoch 68; Iter   451/ 1097] train: loss: 0.0435274
[Epoch 68; Iter   481/ 1097] train: loss: 0.0072425
[Epoch 68; Iter   511/ 1097] train: loss: 0.0931266
[Epoch 68; Iter   541/ 1097] train: loss: 0.0193545
[Epoch 68; Iter   571/ 1097] train: loss: 0.0099458
[Epoch 68; Iter   601/ 1097] train: loss: 0.0392799
[Epoch 68; Iter   631/ 1097] train: loss: 0.0124090
[Epoch 68; Iter   661/ 1097] train: loss: 0.0202206
[Epoch 68; Iter   691/ 1097] train: loss: 0.0174309
[Epoch 68; Iter   721/ 1097] train: loss: 0.0507456
[Epoch 68; Iter   751/ 1097] train: loss: 0.0263792
[Epoch 68; Iter   781/ 1097] train: loss: 0.1601198
[Epoch 68; Iter   811/ 1097] train: loss: 0.0281018
[Epoch 68; Iter   841/ 1097] train: loss: 0.1493058
[Epoch 68; Iter   871/ 1097] train: loss: 0.3350160
[Epoch 68; Iter   901/ 1097] train: loss: 0.0332785
[Epoch 68; Iter   931/ 1097] train: loss: 0.2691980
[Epoch 68; Iter   961/ 1097] train: loss: 0.0393265
[Epoch 68; Iter   991/ 1097] train: loss: 0.0231588
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0106880
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0587851
[Epoch 68; Iter  1081/ 1097] train: loss: 0.1924250
[Epoch 68] ogbg-molhiv: 0.789174 val loss: 0.110384
[Epoch 68] ogbg-molhiv: 0.742954 test loss: 0.173122
[Epoch 69; Iter    14/ 1097] train: loss: 0.0918318
[Epoch 69; Iter    44/ 1097] train: loss: 0.0506725
[Epoch 69; Iter    74/ 1097] train: loss: 0.2069161
[Epoch 69; Iter   104/ 1097] train: loss: 0.0514419
[Epoch 65; Iter    52/ 1097] train: loss: 0.0123415
[Epoch 65; Iter    82/ 1097] train: loss: 0.0566652
[Epoch 65; Iter   112/ 1097] train: loss: 0.0106478
[Epoch 65; Iter   142/ 1097] train: loss: 0.0568992
[Epoch 65; Iter   172/ 1097] train: loss: 0.1374665
[Epoch 65; Iter   202/ 1097] train: loss: 0.0102121
[Epoch 65; Iter   232/ 1097] train: loss: 0.0058826
[Epoch 65; Iter   262/ 1097] train: loss: 0.0181546
[Epoch 65; Iter   292/ 1097] train: loss: 0.0122131
[Epoch 65; Iter   322/ 1097] train: loss: 0.0217164
[Epoch 65; Iter   352/ 1097] train: loss: 0.0574370
[Epoch 65; Iter   382/ 1097] train: loss: 0.0047237
[Epoch 65; Iter   412/ 1097] train: loss: 0.0141115
[Epoch 65; Iter   442/ 1097] train: loss: 0.0235628
[Epoch 65; Iter   472/ 1097] train: loss: 0.1617026
[Epoch 65; Iter   502/ 1097] train: loss: 0.0256433
[Epoch 65; Iter   532/ 1097] train: loss: 0.0300471
[Epoch 65; Iter   562/ 1097] train: loss: 0.2313405
[Epoch 65; Iter   592/ 1097] train: loss: 0.0165281
[Epoch 65; Iter   622/ 1097] train: loss: 0.0085740
[Epoch 65; Iter   652/ 1097] train: loss: 0.0082913
[Epoch 65; Iter   682/ 1097] train: loss: 0.0014853
[Epoch 65; Iter   712/ 1097] train: loss: 0.0393045
[Epoch 65; Iter   742/ 1097] train: loss: 0.0016192
[Epoch 65; Iter   772/ 1097] train: loss: 0.0119644
[Epoch 65; Iter   802/ 1097] train: loss: 0.0587764
[Epoch 65; Iter   832/ 1097] train: loss: 0.0476464
[Epoch 65; Iter   862/ 1097] train: loss: 0.0291893
[Epoch 65; Iter   892/ 1097] train: loss: 0.0262655
[Epoch 65; Iter   922/ 1097] train: loss: 0.0520628
[Epoch 65; Iter   952/ 1097] train: loss: 0.0182828
[Epoch 65; Iter   982/ 1097] train: loss: 0.0998911
[Epoch 65; Iter  1012/ 1097] train: loss: 0.0093420
[Epoch 65; Iter  1042/ 1097] train: loss: 0.0654824
[Epoch 65; Iter  1072/ 1097] train: loss: 0.0067842
[Epoch 65] ogbg-molhiv: 0.798100 val loss: 0.106067
[Epoch 65] ogbg-molhiv: 0.768423 test loss: 0.198440
[Epoch 66; Iter     5/ 1097] train: loss: 0.0246673
[Epoch 66; Iter    35/ 1097] train: loss: 0.0557328
[Epoch 66; Iter    65/ 1097] train: loss: 0.0247799
[Epoch 66; Iter    95/ 1097] train: loss: 0.0084475
[Epoch 66; Iter   125/ 1097] train: loss: 0.0076550
[Epoch 66; Iter   155/ 1097] train: loss: 0.0258948
[Epoch 66; Iter   185/ 1097] train: loss: 0.0039303
[Epoch 66; Iter   215/ 1097] train: loss: 0.0759901
[Epoch 66; Iter   245/ 1097] train: loss: 0.0052829
[Epoch 66; Iter   275/ 1097] train: loss: 0.0219725
[Epoch 66; Iter   305/ 1097] train: loss: 0.1919381
[Epoch 66; Iter   335/ 1097] train: loss: 0.0072541
[Epoch 66; Iter   365/ 1097] train: loss: 0.1621001
[Epoch 66; Iter   395/ 1097] train: loss: 0.1198539
[Epoch 66; Iter   425/ 1097] train: loss: 0.0250160
[Epoch 66; Iter   455/ 1097] train: loss: 0.1200704
[Epoch 66; Iter   485/ 1097] train: loss: 0.0119224
[Epoch 66; Iter   515/ 1097] train: loss: 0.0569509
[Epoch 66; Iter   545/ 1097] train: loss: 0.0047215
[Epoch 66; Iter   575/ 1097] train: loss: 0.0247766
[Epoch 66; Iter   605/ 1097] train: loss: 0.0059326
[Epoch 66; Iter   635/ 1097] train: loss: 0.0096627
[Epoch 66; Iter   665/ 1097] train: loss: 0.0450337
[Epoch 66; Iter   695/ 1097] train: loss: 0.0068020
[Epoch 66; Iter   725/ 1097] train: loss: 0.0290103
[Epoch 66; Iter   755/ 1097] train: loss: 0.0643468
[Epoch 66; Iter   785/ 1097] train: loss: 0.0513505
[Epoch 66; Iter   815/ 1097] train: loss: 0.0093031
[Epoch 66; Iter   845/ 1097] train: loss: 0.1381416
[Epoch 66; Iter   875/ 1097] train: loss: 0.0013144
[Epoch 66; Iter   905/ 1097] train: loss: 0.0029549
[Epoch 66; Iter   935/ 1097] train: loss: 0.0513468
[Epoch 66; Iter   965/ 1097] train: loss: 0.1184188
[Epoch 66; Iter   995/ 1097] train: loss: 0.0018417
[Epoch 66; Iter  1025/ 1097] train: loss: 0.0067285
[Epoch 66; Iter  1055/ 1097] train: loss: 0.0252595
[Epoch 66; Iter  1085/ 1097] train: loss: 0.1101428
[Epoch 66] ogbg-molhiv: 0.800957 val loss: 0.103704
[Epoch 66] ogbg-molhiv: 0.783401 test loss: 0.178187
[Epoch 67; Iter    18/ 1097] train: loss: 0.0363561
[Epoch 67; Iter    48/ 1097] train: loss: 0.0040336
[Epoch 67; Iter    78/ 1097] train: loss: 0.0144568
[Epoch 67; Iter   108/ 1097] train: loss: 0.0376939
[Epoch 67; Iter   138/ 1097] train: loss: 0.0385461
[Epoch 67; Iter   168/ 1097] train: loss: 0.0034980
[Epoch 67; Iter   198/ 1097] train: loss: 0.0079031
[Epoch 67; Iter   228/ 1097] train: loss: 0.0015193
[Epoch 67; Iter   258/ 1097] train: loss: 0.0130732
[Epoch 67; Iter   288/ 1097] train: loss: 0.0729285
[Epoch 67; Iter   318/ 1097] train: loss: 0.0081679
[Epoch 67; Iter   348/ 1097] train: loss: 0.0072533
[Epoch 67; Iter   378/ 1097] train: loss: 0.0178188
[Epoch 67; Iter   408/ 1097] train: loss: 0.1098391
[Epoch 67; Iter   438/ 1097] train: loss: 0.0024057
[Epoch 67; Iter   468/ 1097] train: loss: 0.0143578
[Epoch 67; Iter   498/ 1097] train: loss: 0.0131729
[Epoch 67; Iter   528/ 1097] train: loss: 0.0274410
[Epoch 67; Iter   558/ 1097] train: loss: 0.0013505
[Epoch 67; Iter   588/ 1097] train: loss: 0.0095602
[Epoch 67; Iter   618/ 1097] train: loss: 0.0034425
[Epoch 67; Iter   648/ 1097] train: loss: 0.0464268
[Epoch 67; Iter   678/ 1097] train: loss: 0.0134076
[Epoch 67; Iter   708/ 1097] train: loss: 0.0268582
[Epoch 67; Iter   738/ 1097] train: loss: 0.0360688
[Epoch 67; Iter   768/ 1097] train: loss: 0.0269049
[Epoch 67; Iter   798/ 1097] train: loss: 0.0036837
[Epoch 67; Iter   828/ 1097] train: loss: 0.0028584
[Epoch 67; Iter   858/ 1097] train: loss: 0.0095282
[Epoch 67; Iter   888/ 1097] train: loss: 0.0039544
[Epoch 67; Iter   918/ 1097] train: loss: 0.0081874
[Epoch 67; Iter   948/ 1097] train: loss: 0.0088301
[Epoch 67; Iter   978/ 1097] train: loss: 0.0061908
[Epoch 67; Iter  1008/ 1097] train: loss: 0.0208538
[Epoch 67; Iter  1038/ 1097] train: loss: 0.0075966
[Epoch 67; Iter  1068/ 1097] train: loss: 0.0019742
[Epoch 67] ogbg-molhiv: 0.797521 val loss: 0.103713
[Epoch 67] ogbg-molhiv: 0.760897 test loss: 0.189311
[Epoch 68; Iter     1/ 1097] train: loss: 0.0941724
[Epoch 68; Iter    31/ 1097] train: loss: 0.0232533
[Epoch 68; Iter    61/ 1097] train: loss: 0.0335170
[Epoch 68; Iter    91/ 1097] train: loss: 0.0743426
[Epoch 68; Iter   121/ 1097] train: loss: 0.0100913
[Epoch 68; Iter   151/ 1097] train: loss: 0.0273587
[Epoch 68; Iter   181/ 1097] train: loss: 0.0441035
[Epoch 68; Iter   211/ 1097] train: loss: 0.0498167
[Epoch 68; Iter   241/ 1097] train: loss: 0.0516222
[Epoch 68; Iter   271/ 1097] train: loss: 0.0425952
[Epoch 68; Iter   301/ 1097] train: loss: 0.0062825
[Epoch 68; Iter   331/ 1097] train: loss: 0.0638413
[Epoch 68; Iter   361/ 1097] train: loss: 0.0082112
[Epoch 68; Iter   391/ 1097] train: loss: 0.0027036
[Epoch 68; Iter   421/ 1097] train: loss: 0.0032699
[Epoch 68; Iter   451/ 1097] train: loss: 0.0447189
[Epoch 68; Iter   481/ 1097] train: loss: 0.0383283
[Epoch 68; Iter   511/ 1097] train: loss: 0.0263020
[Epoch 68; Iter   541/ 1097] train: loss: 0.0067218
[Epoch 68; Iter   571/ 1097] train: loss: 0.0412715
[Epoch 68; Iter   601/ 1097] train: loss: 0.0500918
[Epoch 68; Iter   631/ 1097] train: loss: 0.0025299
[Epoch 68; Iter   661/ 1097] train: loss: 0.0207655
[Epoch 68; Iter   691/ 1097] train: loss: 0.0169809
[Epoch 68; Iter   721/ 1097] train: loss: 0.0049805
[Epoch 68; Iter   751/ 1097] train: loss: 0.0184041
[Epoch 68; Iter   781/ 1097] train: loss: 0.0112351
[Epoch 68; Iter   811/ 1097] train: loss: 0.0082051
[Epoch 68; Iter   841/ 1097] train: loss: 0.0124352
[Epoch 68; Iter   871/ 1097] train: loss: 0.0023577
[Epoch 68; Iter   901/ 1097] train: loss: 0.0193077
[Epoch 68; Iter   931/ 1097] train: loss: 0.0070756
[Epoch 68; Iter   961/ 1097] train: loss: 0.0287551
[Epoch 68; Iter   991/ 1097] train: loss: 0.0881449
[Epoch 68; Iter  1021/ 1097] train: loss: 0.0227354
[Epoch 68; Iter  1051/ 1097] train: loss: 0.0070785
[Epoch 68; Iter  1081/ 1097] train: loss: 0.0029837
[Epoch 68] ogbg-molhiv: 0.792509 val loss: 0.109245
[Epoch 68] ogbg-molhiv: 0.759818 test loss: 0.195686
[Epoch 69; Iter    14/ 1097] train: loss: 0.0104323
[Epoch 69; Iter    44/ 1097] train: loss: 0.0131998
[Epoch 69; Iter    74/ 1097] train: loss: 0.0063022
[Epoch 69; Iter   104/ 1097] train: loss: 0.0133014
[Epoch 68; Iter   779/  823] train: loss: 0.0087923
[Epoch 68; Iter   809/  823] train: loss: 0.0006693
[Epoch 68] ogbg-molhiv: 0.732869 val loss: 0.286531
[Epoch 68] ogbg-molhiv: 0.758360 test loss: 0.209703
[Epoch 69; Iter    16/  823] train: loss: 0.0081311
[Epoch 69; Iter    46/  823] train: loss: 0.0089202
[Epoch 69; Iter    76/  823] train: loss: 0.0033163
[Epoch 69; Iter   106/  823] train: loss: 0.0083639
[Epoch 69; Iter   136/  823] train: loss: 0.0150538
[Epoch 69; Iter   166/  823] train: loss: 0.2666386
[Epoch 69; Iter   196/  823] train: loss: 0.0299859
[Epoch 69; Iter   226/  823] train: loss: 0.0032377
[Epoch 69; Iter   256/  823] train: loss: 0.0059900
[Epoch 69; Iter   286/  823] train: loss: 0.0037500
[Epoch 69; Iter   316/  823] train: loss: 0.0037062
[Epoch 69; Iter   346/  823] train: loss: 0.0028351
[Epoch 69; Iter   376/  823] train: loss: 0.0066950
[Epoch 69; Iter   406/  823] train: loss: 0.0114483
[Epoch 69; Iter   436/  823] train: loss: 0.0031983
[Epoch 69; Iter   466/  823] train: loss: 0.0635096
[Epoch 69; Iter   496/  823] train: loss: 0.0049179
[Epoch 69; Iter   526/  823] train: loss: 0.0044409
[Epoch 69; Iter   556/  823] train: loss: 0.0159760
[Epoch 69; Iter   586/  823] train: loss: 0.0388335
[Epoch 69; Iter   616/  823] train: loss: 0.0057355
[Epoch 69; Iter   646/  823] train: loss: 0.0108282
[Epoch 69; Iter   676/  823] train: loss: 0.0895876
[Epoch 69; Iter   706/  823] train: loss: 0.0820750
[Epoch 69; Iter   736/  823] train: loss: 0.0056326
[Epoch 69; Iter   766/  823] train: loss: 0.0109022
[Epoch 69; Iter   796/  823] train: loss: 0.0093123
[Epoch 69] ogbg-molhiv: 0.746026 val loss: 0.280117
[Epoch 69] ogbg-molhiv: 0.769242 test loss: 0.206506
[Epoch 70; Iter     3/  823] train: loss: 0.0029332
[Epoch 70; Iter    33/  823] train: loss: 0.0032702
[Epoch 70; Iter    63/  823] train: loss: 0.0031128
[Epoch 70; Iter    93/  823] train: loss: 0.1085381
[Epoch 70; Iter   123/  823] train: loss: 0.0159149
[Epoch 70; Iter   153/  823] train: loss: 0.1216738
[Epoch 70; Iter   183/  823] train: loss: 0.0012252
[Epoch 70; Iter   213/  823] train: loss: 0.0492111
[Epoch 70; Iter   243/  823] train: loss: 0.0338755
[Epoch 70; Iter   273/  823] train: loss: 0.0043947
[Epoch 70; Iter   303/  823] train: loss: 0.0850224
[Epoch 70; Iter   333/  823] train: loss: 0.0032492
[Epoch 70; Iter   363/  823] train: loss: 0.0217400
[Epoch 70; Iter   393/  823] train: loss: 0.0159168
[Epoch 70; Iter   423/  823] train: loss: 0.0064796
[Epoch 70; Iter   453/  823] train: loss: 0.0189764
[Epoch 70; Iter   483/  823] train: loss: 0.0361619
[Epoch 70; Iter   513/  823] train: loss: 0.0075735
[Epoch 70; Iter   543/  823] train: loss: 0.0531580
[Epoch 70; Iter   573/  823] train: loss: 0.0026936
[Epoch 70; Iter   603/  823] train: loss: 0.0036127
[Epoch 70; Iter   633/  823] train: loss: 0.0011516
[Epoch 70; Iter   663/  823] train: loss: 0.0043932
[Epoch 70; Iter   693/  823] train: loss: 0.0036706
[Epoch 70; Iter   723/  823] train: loss: 0.0119222
[Epoch 70; Iter   753/  823] train: loss: 0.0010370
[Epoch 70; Iter   783/  823] train: loss: 0.0570737
[Epoch 70; Iter   813/  823] train: loss: 0.0074048
[Epoch 70] ogbg-molhiv: 0.734133 val loss: 0.234719
[Epoch 70] ogbg-molhiv: 0.756174 test loss: 0.159461
[Epoch 71; Iter    20/  823] train: loss: 0.0049785
[Epoch 71; Iter    50/  823] train: loss: 0.0213372
[Epoch 71; Iter    80/  823] train: loss: 0.0014320
[Epoch 71; Iter   110/  823] train: loss: 0.0611243
[Epoch 71; Iter   140/  823] train: loss: 0.1025536
[Epoch 71; Iter   170/  823] train: loss: 0.0021298
[Epoch 71; Iter   200/  823] train: loss: 0.0053073
[Epoch 71; Iter   230/  823] train: loss: 0.0560483
[Epoch 71; Iter   260/  823] train: loss: 0.0066901
[Epoch 71; Iter   290/  823] train: loss: 0.0879772
[Epoch 71; Iter   320/  823] train: loss: 0.0531020
[Epoch 71; Iter   350/  823] train: loss: 0.0036909
[Epoch 71; Iter   380/  823] train: loss: 0.0048374
[Epoch 71; Iter   410/  823] train: loss: 0.0145511
[Epoch 71; Iter   440/  823] train: loss: 0.0351433
[Epoch 71; Iter   470/  823] train: loss: 0.0408086
[Epoch 71; Iter   500/  823] train: loss: 0.0154337
[Epoch 71; Iter   530/  823] train: loss: 0.0065125
[Epoch 71; Iter   560/  823] train: loss: 0.0018940
[Epoch 71; Iter   590/  823] train: loss: 0.0014780
[Epoch 71; Iter   620/  823] train: loss: 0.0010905
[Epoch 71; Iter   650/  823] train: loss: 0.0050633
[Epoch 71; Iter   680/  823] train: loss: 0.0051369
[Epoch 71; Iter   710/  823] train: loss: 0.0885795
[Epoch 71; Iter   740/  823] train: loss: 0.0331879
[Epoch 71; Iter   770/  823] train: loss: 0.0894663
[Epoch 71; Iter   800/  823] train: loss: 0.0148268
[Epoch 71] ogbg-molhiv: 0.737689 val loss: 0.280967
[Epoch 71] ogbg-molhiv: 0.756418 test loss: 0.220689
[Epoch 72; Iter     7/  823] train: loss: 0.0102085
[Epoch 72; Iter    37/  823] train: loss: 0.0126764
[Epoch 72; Iter    67/  823] train: loss: 0.0379100
[Epoch 72; Iter    97/  823] train: loss: 0.0443487
[Epoch 72; Iter   127/  823] train: loss: 0.0012093
[Epoch 72; Iter   157/  823] train: loss: 0.0239090
[Epoch 72; Iter   187/  823] train: loss: 0.0057220
[Epoch 72; Iter   217/  823] train: loss: 0.0044430
[Epoch 72; Iter   247/  823] train: loss: 0.0658366
[Epoch 72; Iter   277/  823] train: loss: 0.1334899
[Epoch 72; Iter   307/  823] train: loss: 0.0145055
[Epoch 72; Iter   337/  823] train: loss: 0.0219950
[Epoch 72; Iter   367/  823] train: loss: 0.0092197
[Epoch 72; Iter   397/  823] train: loss: 0.0324246
[Epoch 72; Iter   427/  823] train: loss: 0.0083363
[Epoch 72; Iter   457/  823] train: loss: 0.0056383
[Epoch 72; Iter   487/  823] train: loss: 0.0323084
[Epoch 72; Iter   517/  823] train: loss: 0.0159316
[Epoch 72; Iter   547/  823] train: loss: 0.0033468
[Epoch 72; Iter   577/  823] train: loss: 0.0885519
[Epoch 72; Iter   607/  823] train: loss: 0.0152386
[Epoch 72; Iter   637/  823] train: loss: 0.1024765
[Epoch 72; Iter   667/  823] train: loss: 0.0105247
[Epoch 72; Iter   697/  823] train: loss: 0.0049018
[Epoch 72; Iter   727/  823] train: loss: 0.0522480
[Epoch 72; Iter   757/  823] train: loss: 0.0048478
[Epoch 72; Iter   787/  823] train: loss: 0.0372358
[Epoch 72; Iter   817/  823] train: loss: 0.0601153
[Epoch 72] ogbg-molhiv: 0.733094 val loss: 0.280069
[Epoch 72] ogbg-molhiv: 0.751670 test loss: 0.219104
[Epoch 73; Iter    24/  823] train: loss: 0.0136771
[Epoch 73; Iter    54/  823] train: loss: 0.0066870
[Epoch 73; Iter    84/  823] train: loss: 0.0038442
[Epoch 73; Iter   114/  823] train: loss: 0.0584926
[Epoch 73; Iter   144/  823] train: loss: 0.0071021
[Epoch 73; Iter   174/  823] train: loss: 0.0844679
[Epoch 73; Iter   204/  823] train: loss: 0.0016495
[Epoch 73; Iter   234/  823] train: loss: 0.0025636
[Epoch 73; Iter   264/  823] train: loss: 0.0045767
[Epoch 73; Iter   294/  823] train: loss: 0.0024313
[Epoch 73; Iter   324/  823] train: loss: 0.0012514
[Epoch 73; Iter   354/  823] train: loss: 0.0007030
[Epoch 73; Iter   384/  823] train: loss: 0.0325098
[Epoch 73; Iter   414/  823] train: loss: 0.0091721
[Epoch 73; Iter   444/  823] train: loss: 0.0009627
[Epoch 73; Iter   474/  823] train: loss: 0.0096082
[Epoch 73; Iter   504/  823] train: loss: 0.0261734
[Epoch 73; Iter   534/  823] train: loss: 0.0139840
[Epoch 73; Iter   564/  823] train: loss: 0.0097500
[Epoch 73; Iter   594/  823] train: loss: 0.0307050
[Epoch 73; Iter   624/  823] train: loss: 0.0570472
[Epoch 73; Iter   654/  823] train: loss: 0.0038752
[Epoch 73; Iter   684/  823] train: loss: 0.0824313
[Epoch 73; Iter   714/  823] train: loss: 0.0329560
[Epoch 73; Iter   744/  823] train: loss: 0.0113004
[Epoch 73; Iter   774/  823] train: loss: 0.0195089
[Epoch 73; Iter   804/  823] train: loss: 0.0032646
[Epoch 73] ogbg-molhiv: 0.733360 val loss: 0.288186
[Epoch 73] ogbg-molhiv: 0.759155 test loss: 0.235553
[Epoch 74; Iter    11/  823] train: loss: 0.0021504
[Epoch 74; Iter    41/  823] train: loss: 0.0083071
[Epoch 74; Iter    71/  823] train: loss: 0.0121710
[Epoch 74; Iter   101/  823] train: loss: 0.0224037
[Epoch 74; Iter   131/  823] train: loss: 0.0127517
[Epoch 74; Iter   161/  823] train: loss: 0.0208740
[Epoch 69; Iter    30/  960] train: loss: 0.0349992
[Epoch 69; Iter    60/  960] train: loss: 0.0057059
[Epoch 69; Iter    90/  960] train: loss: 0.0049801
[Epoch 69; Iter   120/  960] train: loss: 0.0048833
[Epoch 69; Iter   150/  960] train: loss: 0.0365341
[Epoch 69; Iter   180/  960] train: loss: 0.0339392
[Epoch 69; Iter   210/  960] train: loss: 0.0199339
[Epoch 69; Iter   240/  960] train: loss: 0.0065059
[Epoch 69; Iter   270/  960] train: loss: 0.0298304
[Epoch 69; Iter   300/  960] train: loss: 0.0731128
[Epoch 69; Iter   330/  960] train: loss: 0.1217062
[Epoch 69; Iter   360/  960] train: loss: 0.0255753
[Epoch 69; Iter   390/  960] train: loss: 0.0321269
[Epoch 69; Iter   420/  960] train: loss: 0.0062500
[Epoch 69; Iter   450/  960] train: loss: 0.1171061
[Epoch 69; Iter   480/  960] train: loss: 0.0363481
[Epoch 69; Iter   510/  960] train: loss: 0.0151059
[Epoch 69; Iter   540/  960] train: loss: 0.0046321
[Epoch 69; Iter   570/  960] train: loss: 0.0074141
[Epoch 69; Iter   600/  960] train: loss: 0.0131309
[Epoch 69; Iter   630/  960] train: loss: 0.1811481
[Epoch 69; Iter   660/  960] train: loss: 0.0087957
[Epoch 69; Iter   690/  960] train: loss: 0.1510475
[Epoch 69; Iter   720/  960] train: loss: 0.0142726
[Epoch 69; Iter   750/  960] train: loss: 0.0036578
[Epoch 69; Iter   780/  960] train: loss: 0.0075989
[Epoch 69; Iter   810/  960] train: loss: 0.0632479
[Epoch 69; Iter   840/  960] train: loss: 0.0133075
[Epoch 69; Iter   870/  960] train: loss: 0.0206073
[Epoch 69; Iter   900/  960] train: loss: 0.0477013
[Epoch 69; Iter   930/  960] train: loss: 0.0373042
[Epoch 69; Iter   960/  960] train: loss: 0.0116968
[Epoch 69] ogbg-molhiv: 0.734791 val loss: 0.209459
[Epoch 69] ogbg-molhiv: 0.763507 test loss: 0.166145
[Epoch 70; Iter    30/  960] train: loss: 0.0549378
[Epoch 70; Iter    60/  960] train: loss: 0.0030876
[Epoch 70; Iter    90/  960] train: loss: 0.0065965
[Epoch 70; Iter   120/  960] train: loss: 0.0061249
[Epoch 70; Iter   150/  960] train: loss: 0.0636250
[Epoch 70; Iter   180/  960] train: loss: 0.0063382
[Epoch 70; Iter   210/  960] train: loss: 0.0199385
[Epoch 70; Iter   240/  960] train: loss: 0.0118222
[Epoch 70; Iter   270/  960] train: loss: 0.0515211
[Epoch 70; Iter   300/  960] train: loss: 0.0040226
[Epoch 70; Iter   330/  960] train: loss: 0.0027967
[Epoch 70; Iter   360/  960] train: loss: 0.0284175
[Epoch 70; Iter   390/  960] train: loss: 0.0054140
[Epoch 70; Iter   420/  960] train: loss: 0.1066185
[Epoch 70; Iter   450/  960] train: loss: 0.0714450
[Epoch 70; Iter   480/  960] train: loss: 0.0219011
[Epoch 70; Iter   510/  960] train: loss: 0.0222058
[Epoch 70; Iter   540/  960] train: loss: 0.2505638
[Epoch 70; Iter   570/  960] train: loss: 0.0307577
[Epoch 70; Iter   600/  960] train: loss: 0.0089494
[Epoch 70; Iter   630/  960] train: loss: 0.0435447
[Epoch 70; Iter   660/  960] train: loss: 0.0337993
[Epoch 70; Iter   690/  960] train: loss: 0.0018217
[Epoch 70; Iter   720/  960] train: loss: 0.0187659
[Epoch 70; Iter   750/  960] train: loss: 0.0222640
[Epoch 70; Iter   780/  960] train: loss: 0.0083488
[Epoch 70; Iter   810/  960] train: loss: 0.0056338
[Epoch 70; Iter   840/  960] train: loss: 0.0047035
[Epoch 70; Iter   870/  960] train: loss: 0.0084851
[Epoch 70; Iter   900/  960] train: loss: 0.0680358
[Epoch 70; Iter   930/  960] train: loss: 0.0152081
[Epoch 70; Iter   960/  960] train: loss: 0.4104726
[Epoch 70] ogbg-molhiv: 0.718459 val loss: 0.219867
[Epoch 70] ogbg-molhiv: 0.745156 test loss: 0.188399
[Epoch 71; Iter    30/  960] train: loss: 0.1242343
[Epoch 71; Iter    60/  960] train: loss: 0.0081834
[Epoch 71; Iter    90/  960] train: loss: 0.0936863
[Epoch 71; Iter   120/  960] train: loss: 0.0286366
[Epoch 71; Iter   150/  960] train: loss: 0.0517639
[Epoch 71; Iter   180/  960] train: loss: 0.0178989
[Epoch 71; Iter   210/  960] train: loss: 0.0656122
[Epoch 71; Iter   240/  960] train: loss: 0.0039446
[Epoch 71; Iter   270/  960] train: loss: 0.0415430
[Epoch 71; Iter   300/  960] train: loss: 0.0128975
[Epoch 71; Iter   330/  960] train: loss: 0.0424449
[Epoch 71; Iter   360/  960] train: loss: 0.0030577
[Epoch 71; Iter   390/  960] train: loss: 0.0076752
[Epoch 71; Iter   420/  960] train: loss: 0.0199659
[Epoch 71; Iter   450/  960] train: loss: 0.0084439
[Epoch 71; Iter   480/  960] train: loss: 0.0044122
[Epoch 71; Iter   510/  960] train: loss: 0.0126812
[Epoch 71; Iter   540/  960] train: loss: 0.0846086
[Epoch 71; Iter   570/  960] train: loss: 0.0082755
[Epoch 71; Iter   600/  960] train: loss: 0.0128690
[Epoch 71; Iter   630/  960] train: loss: 0.0334458
[Epoch 71; Iter   660/  960] train: loss: 0.0598636
[Epoch 71; Iter   690/  960] train: loss: 0.1140425
[Epoch 71; Iter   720/  960] train: loss: 0.0256492
[Epoch 71; Iter   750/  960] train: loss: 0.0015546
[Epoch 71; Iter   780/  960] train: loss: 0.0049673
[Epoch 71; Iter   810/  960] train: loss: 0.1853645
[Epoch 71; Iter   840/  960] train: loss: 0.0996811
[Epoch 71; Iter   870/  960] train: loss: 0.0087870
[Epoch 71; Iter   900/  960] train: loss: 0.1215508
[Epoch 71; Iter   930/  960] train: loss: 0.0068672
[Epoch 71; Iter   960/  960] train: loss: 0.0467211
[Epoch 71] ogbg-molhiv: 0.731287 val loss: 0.244542
[Epoch 71] ogbg-molhiv: 0.765553 test loss: 0.219269
[Epoch 72; Iter    30/  960] train: loss: 0.0264223
[Epoch 72; Iter    60/  960] train: loss: 0.0320717
[Epoch 72; Iter    90/  960] train: loss: 0.0371495
[Epoch 72; Iter   120/  960] train: loss: 0.1732941
[Epoch 72; Iter   150/  960] train: loss: 0.0113458
[Epoch 72; Iter   180/  960] train: loss: 0.0097074
[Epoch 72; Iter   210/  960] train: loss: 0.0259691
[Epoch 72; Iter   240/  960] train: loss: 0.0033478
[Epoch 72; Iter   270/  960] train: loss: 0.0892542
[Epoch 72; Iter   300/  960] train: loss: 0.0146312
[Epoch 72; Iter   330/  960] train: loss: 0.0059805
[Epoch 72; Iter   360/  960] train: loss: 0.0295877
[Epoch 72; Iter   390/  960] train: loss: 0.0686677
[Epoch 72; Iter   420/  960] train: loss: 0.1203044
[Epoch 72; Iter   450/  960] train: loss: 0.0111365
[Epoch 72; Iter   480/  960] train: loss: 0.0184356
[Epoch 72; Iter   510/  960] train: loss: 0.0044549
[Epoch 72; Iter   540/  960] train: loss: 0.0075872
[Epoch 72; Iter   570/  960] train: loss: 0.0087122
[Epoch 72; Iter   600/  960] train: loss: 0.0070918
[Epoch 72; Iter   630/  960] train: loss: 0.0256715
[Epoch 72; Iter   660/  960] train: loss: 0.0017408
[Epoch 72; Iter   690/  960] train: loss: 0.0050049
[Epoch 72; Iter   720/  960] train: loss: 0.0194886
[Epoch 72; Iter   750/  960] train: loss: 0.0256423
[Epoch 72; Iter   780/  960] train: loss: 0.0013118
[Epoch 72; Iter   810/  960] train: loss: 0.0070102
[Epoch 72; Iter   840/  960] train: loss: 0.0070043
[Epoch 72; Iter   870/  960] train: loss: 0.0059877
[Epoch 72; Iter   900/  960] train: loss: 0.0423102
[Epoch 72; Iter   930/  960] train: loss: 0.0019364
[Epoch 72; Iter   960/  960] train: loss: 0.1394045
[Epoch 72] ogbg-molhiv: 0.728003 val loss: 0.226157
[Epoch 72] ogbg-molhiv: 0.767905 test loss: 0.180257
[Epoch 73; Iter    30/  960] train: loss: 0.0037574
[Epoch 73; Iter    60/  960] train: loss: 0.0134949
[Epoch 73; Iter    90/  960] train: loss: 0.0124746
[Epoch 73; Iter   120/  960] train: loss: 0.0187944
[Epoch 73; Iter   150/  960] train: loss: 0.0120598
[Epoch 73; Iter   180/  960] train: loss: 0.0140077
[Epoch 73; Iter   210/  960] train: loss: 0.0036310
[Epoch 73; Iter   240/  960] train: loss: 0.0042373
[Epoch 73; Iter   270/  960] train: loss: 0.0026667
[Epoch 73; Iter   300/  960] train: loss: 0.0950261
[Epoch 73; Iter   330/  960] train: loss: 0.1215537
[Epoch 73; Iter   360/  960] train: loss: 0.0031109
[Epoch 73; Iter   390/  960] train: loss: 0.0299963
[Epoch 73; Iter   420/  960] train: loss: 0.0650838
[Epoch 73; Iter   450/  960] train: loss: 0.0291001
[Epoch 73; Iter   480/  960] train: loss: 0.0283298
[Epoch 73; Iter   510/  960] train: loss: 0.0043760
[Epoch 73; Iter   540/  960] train: loss: 0.0756084
[Epoch 73; Iter   570/  960] train: loss: 0.0216966
[Epoch 73; Iter   600/  960] train: loss: 0.0051622
[Epoch 73; Iter   630/  960] train: loss: 0.0158280
[Epoch 69; Iter    30/  960] train: loss: 0.0261247
[Epoch 69; Iter    60/  960] train: loss: 0.0053863
[Epoch 69; Iter    90/  960] train: loss: 0.0112844
[Epoch 69; Iter   120/  960] train: loss: 0.0249102
[Epoch 69; Iter   150/  960] train: loss: 0.0141569
[Epoch 69; Iter   180/  960] train: loss: 0.0266799
[Epoch 69; Iter   210/  960] train: loss: 0.0765010
[Epoch 69; Iter   240/  960] train: loss: 0.0808284
[Epoch 69; Iter   270/  960] train: loss: 0.0316569
[Epoch 69; Iter   300/  960] train: loss: 0.0352191
[Epoch 69; Iter   330/  960] train: loss: 0.0057382
[Epoch 69; Iter   360/  960] train: loss: 0.0689735
[Epoch 69; Iter   390/  960] train: loss: 0.0030824
[Epoch 69; Iter   420/  960] train: loss: 0.0038040
[Epoch 69; Iter   450/  960] train: loss: 0.0352702
[Epoch 69; Iter   480/  960] train: loss: 0.0165032
[Epoch 69; Iter   510/  960] train: loss: 0.0247585
[Epoch 69; Iter   540/  960] train: loss: 0.0307428
[Epoch 69; Iter   570/  960] train: loss: 0.0098607
[Epoch 69; Iter   600/  960] train: loss: 0.0073126
[Epoch 69; Iter   630/  960] train: loss: 0.0226896
[Epoch 69; Iter   660/  960] train: loss: 0.0607620
[Epoch 69; Iter   690/  960] train: loss: 0.0681319
[Epoch 69; Iter   720/  960] train: loss: 0.0123844
[Epoch 69; Iter   750/  960] train: loss: 0.0087560
[Epoch 69; Iter   780/  960] train: loss: 0.0080140
[Epoch 69; Iter   810/  960] train: loss: 0.2177587
[Epoch 69; Iter   840/  960] train: loss: 0.0175828
[Epoch 69; Iter   870/  960] train: loss: 0.0179318
[Epoch 69; Iter   900/  960] train: loss: 0.0585306
[Epoch 69; Iter   930/  960] train: loss: 0.0582088
[Epoch 69; Iter   960/  960] train: loss: 0.0285214
[Epoch 69] ogbg-molhiv: 0.717627 val loss: 0.539684
[Epoch 69] ogbg-molhiv: 0.748276 test loss: 0.460961
[Epoch 70; Iter    30/  960] train: loss: 0.0193684
[Epoch 70; Iter    60/  960] train: loss: 0.0304169
[Epoch 70; Iter    90/  960] train: loss: 0.0373581
[Epoch 70; Iter   120/  960] train: loss: 0.0083440
[Epoch 70; Iter   150/  960] train: loss: 0.0233880
[Epoch 70; Iter   180/  960] train: loss: 0.0068542
[Epoch 70; Iter   210/  960] train: loss: 0.0369893
[Epoch 70; Iter   240/  960] train: loss: 0.0115394
[Epoch 70; Iter   270/  960] train: loss: 0.0031683
[Epoch 70; Iter   300/  960] train: loss: 0.0020836
[Epoch 70; Iter   330/  960] train: loss: 0.0884658
[Epoch 70; Iter   360/  960] train: loss: 0.0062476
[Epoch 70; Iter   390/  960] train: loss: 0.0107392
[Epoch 70; Iter   420/  960] train: loss: 0.0149546
[Epoch 70; Iter   450/  960] train: loss: 0.0047244
[Epoch 70; Iter   480/  960] train: loss: 0.0605530
[Epoch 70; Iter   510/  960] train: loss: 0.1288583
[Epoch 70; Iter   540/  960] train: loss: 0.3477471
[Epoch 70; Iter   570/  960] train: loss: 0.0609092
[Epoch 70; Iter   600/  960] train: loss: 0.0037508
[Epoch 70; Iter   630/  960] train: loss: 0.0056187
[Epoch 70; Iter   660/  960] train: loss: 0.1080121
[Epoch 70; Iter   690/  960] train: loss: 0.0126009
[Epoch 70; Iter   720/  960] train: loss: 0.0450344
[Epoch 70; Iter   750/  960] train: loss: 0.0049190
[Epoch 70; Iter   780/  960] train: loss: 0.0105926
[Epoch 70; Iter   810/  960] train: loss: 0.0332182
[Epoch 70; Iter   840/  960] train: loss: 0.0190912
[Epoch 70; Iter   870/  960] train: loss: 0.0625775
[Epoch 70; Iter   900/  960] train: loss: 0.0262413
[Epoch 70; Iter   930/  960] train: loss: 0.0564026
[Epoch 70; Iter   960/  960] train: loss: 0.0345627
[Epoch 70] ogbg-molhiv: 0.711280 val loss: 0.536513
[Epoch 70] ogbg-molhiv: 0.750273 test loss: 0.407099
[Epoch 71; Iter    30/  960] train: loss: 0.0058277
[Epoch 71; Iter    60/  960] train: loss: 0.0066742
[Epoch 71; Iter    90/  960] train: loss: 0.0040345
[Epoch 71; Iter   120/  960] train: loss: 0.0058442
[Epoch 71; Iter   150/  960] train: loss: 0.0090595
[Epoch 71; Iter   180/  960] train: loss: 0.0812401
[Epoch 71; Iter   210/  960] train: loss: 0.0453033
[Epoch 71; Iter   240/  960] train: loss: 0.0113484
[Epoch 71; Iter   270/  960] train: loss: 0.0336977
[Epoch 71; Iter   300/  960] train: loss: 0.0105671
[Epoch 71; Iter   330/  960] train: loss: 0.0242671
[Epoch 71; Iter   360/  960] train: loss: 0.0159760
[Epoch 71; Iter   390/  960] train: loss: 0.0222835
[Epoch 71; Iter   420/  960] train: loss: 0.0105940
[Epoch 71; Iter   450/  960] train: loss: 0.0525843
[Epoch 71; Iter   480/  960] train: loss: 0.0240961
[Epoch 71; Iter   510/  960] train: loss: 0.0066693
[Epoch 71; Iter   540/  960] train: loss: 0.0090592
[Epoch 71; Iter   570/  960] train: loss: 0.0743430
[Epoch 71; Iter   600/  960] train: loss: 0.0052016
[Epoch 71; Iter   630/  960] train: loss: 0.0177208
[Epoch 71; Iter   660/  960] train: loss: 0.2370448
[Epoch 71; Iter   690/  960] train: loss: 0.0070433
[Epoch 71; Iter   720/  960] train: loss: 0.0042884
[Epoch 71; Iter   750/  960] train: loss: 0.0267085
[Epoch 71; Iter   780/  960] train: loss: 0.0114184
[Epoch 71; Iter   810/  960] train: loss: 0.0141372
[Epoch 71; Iter   840/  960] train: loss: 0.0149043
[Epoch 71; Iter   870/  960] train: loss: 0.0526838
[Epoch 71; Iter   900/  960] train: loss: 0.0154356
[Epoch 71; Iter   930/  960] train: loss: 0.0192961
[Epoch 71; Iter   960/  960] train: loss: 0.0742286
[Epoch 71] ogbg-molhiv: 0.710961 val loss: 0.655406
[Epoch 71] ogbg-molhiv: 0.761676 test loss: 0.429302
[Epoch 72; Iter    30/  960] train: loss: 0.0124261
[Epoch 72; Iter    60/  960] train: loss: 0.0188252
[Epoch 72; Iter    90/  960] train: loss: 0.0397380
[Epoch 72; Iter   120/  960] train: loss: 0.0056746
[Epoch 72; Iter   150/  960] train: loss: 0.0135066
[Epoch 72; Iter   180/  960] train: loss: 0.0303478
[Epoch 72; Iter   210/  960] train: loss: 0.0134570
[Epoch 72; Iter   240/  960] train: loss: 0.0093124
[Epoch 72; Iter   270/  960] train: loss: 0.0982465
[Epoch 72; Iter   300/  960] train: loss: 0.0329280
[Epoch 72; Iter   330/  960] train: loss: 0.0234222
[Epoch 72; Iter   360/  960] train: loss: 0.0037620
[Epoch 72; Iter   390/  960] train: loss: 0.0021504
[Epoch 72; Iter   420/  960] train: loss: 0.0183859
[Epoch 72; Iter   450/  960] train: loss: 0.0460880
[Epoch 72; Iter   480/  960] train: loss: 0.0114080
[Epoch 72; Iter   510/  960] train: loss: 0.0077519
[Epoch 72; Iter   540/  960] train: loss: 0.0034990
[Epoch 72; Iter   570/  960] train: loss: 0.0241673
[Epoch 72; Iter   600/  960] train: loss: 0.0018728
[Epoch 72; Iter   630/  960] train: loss: 0.0250421
[Epoch 72; Iter   660/  960] train: loss: 0.0061670
[Epoch 72; Iter   690/  960] train: loss: 0.0070811
[Epoch 72; Iter   720/  960] train: loss: 0.0417369
[Epoch 72; Iter   750/  960] train: loss: 0.0412221
[Epoch 72; Iter   780/  960] train: loss: 0.0040776
[Epoch 72; Iter   810/  960] train: loss: 0.0057715
[Epoch 72; Iter   840/  960] train: loss: 0.0482706
[Epoch 72; Iter   870/  960] train: loss: 0.0195007
[Epoch 72; Iter   900/  960] train: loss: 0.0129782
[Epoch 72; Iter   930/  960] train: loss: 0.0109407
[Epoch 72; Iter   960/  960] train: loss: 0.0021204
[Epoch 72] ogbg-molhiv: 0.716997 val loss: 0.599351
[Epoch 72] ogbg-molhiv: 0.751913 test loss: 0.402737
[Epoch 73; Iter    30/  960] train: loss: 0.0178361
[Epoch 73; Iter    60/  960] train: loss: 0.0061054
[Epoch 73; Iter    90/  960] train: loss: 0.1792556
[Epoch 73; Iter   120/  960] train: loss: 0.0049441
[Epoch 73; Iter   150/  960] train: loss: 0.0318802
[Epoch 73; Iter   180/  960] train: loss: 0.0068721
[Epoch 73; Iter   210/  960] train: loss: 0.0031855
[Epoch 73; Iter   240/  960] train: loss: 0.0111419
[Epoch 73; Iter   270/  960] train: loss: 0.0731112
[Epoch 73; Iter   300/  960] train: loss: 0.0126166
[Epoch 73; Iter   330/  960] train: loss: 0.0786681
[Epoch 73; Iter   360/  960] train: loss: 0.1752325
[Epoch 73; Iter   390/  960] train: loss: 0.0387457
[Epoch 73; Iter   420/  960] train: loss: 0.0255555
[Epoch 73; Iter   450/  960] train: loss: 0.0169261
[Epoch 73; Iter   480/  960] train: loss: 0.0931045
[Epoch 73; Iter   510/  960] train: loss: 0.0024489
[Epoch 73; Iter   540/  960] train: loss: 0.0304808
[Epoch 73; Iter   570/  960] train: loss: 0.0883342
[Epoch 73; Iter   600/  960] train: loss: 0.0042880
[Epoch 73; Iter   630/  960] train: loss: 0.0479359
[Epoch 69; Iter    30/  960] train: loss: 0.0446809
[Epoch 69; Iter    60/  960] train: loss: 0.0242025
[Epoch 69; Iter    90/  960] train: loss: 0.0126708
[Epoch 69; Iter   120/  960] train: loss: 0.0034933
[Epoch 69; Iter   150/  960] train: loss: 0.0617929
[Epoch 69; Iter   180/  960] train: loss: 0.0268429
[Epoch 69; Iter   210/  960] train: loss: 0.0966960
[Epoch 69; Iter   240/  960] train: loss: 0.0329344
[Epoch 69; Iter   270/  960] train: loss: 0.0053499
[Epoch 69; Iter   300/  960] train: loss: 0.0081199
[Epoch 69; Iter   330/  960] train: loss: 0.0248456
[Epoch 69; Iter   360/  960] train: loss: 0.0062859
[Epoch 69; Iter   390/  960] train: loss: 0.0304227
[Epoch 69; Iter   420/  960] train: loss: 0.0083386
[Epoch 69; Iter   450/  960] train: loss: 0.1069450
[Epoch 69; Iter   480/  960] train: loss: 0.0500230
[Epoch 69; Iter   510/  960] train: loss: 0.0912341
[Epoch 69; Iter   540/  960] train: loss: 0.0285593
[Epoch 69; Iter   570/  960] train: loss: 0.0122804
[Epoch 69; Iter   600/  960] train: loss: 0.0116198
[Epoch 69; Iter   630/  960] train: loss: 0.0807663
[Epoch 69; Iter   660/  960] train: loss: 0.0959989
[Epoch 69; Iter   690/  960] train: loss: 0.0171177
[Epoch 69; Iter   720/  960] train: loss: 0.1046201
[Epoch 69; Iter   750/  960] train: loss: 0.0441823
[Epoch 69; Iter   780/  960] train: loss: 0.0028428
[Epoch 69; Iter   810/  960] train: loss: 0.0791745
[Epoch 69; Iter   840/  960] train: loss: 0.0205292
[Epoch 69; Iter   870/  960] train: loss: 0.1153886
[Epoch 69; Iter   900/  960] train: loss: 0.0053150
[Epoch 69; Iter   930/  960] train: loss: 0.0030992
[Epoch 69; Iter   960/  960] train: loss: 0.0052620
[Epoch 69] ogbg-molhiv: 0.752007 val loss: 0.439822
[Epoch 69] ogbg-molhiv: 0.746173 test loss: 0.251681
[Epoch 70; Iter    30/  960] train: loss: 0.0231452
[Epoch 70; Iter    60/  960] train: loss: 0.0085351
[Epoch 70; Iter    90/  960] train: loss: 0.0179790
[Epoch 70; Iter   120/  960] train: loss: 0.0272916
[Epoch 70; Iter   150/  960] train: loss: 0.0088292
[Epoch 70; Iter   180/  960] train: loss: 0.0062489
[Epoch 70; Iter   210/  960] train: loss: 0.0277210
[Epoch 70; Iter   240/  960] train: loss: 0.0465008
[Epoch 70; Iter   270/  960] train: loss: 0.2312568
[Epoch 70; Iter   300/  960] train: loss: 0.0255344
[Epoch 70; Iter   330/  960] train: loss: 0.0081085
[Epoch 70; Iter   360/  960] train: loss: 0.0253496
[Epoch 70; Iter   390/  960] train: loss: 0.0232488
[Epoch 70; Iter   420/  960] train: loss: 0.0040980
[Epoch 70; Iter   450/  960] train: loss: 0.0090454
[Epoch 70; Iter   480/  960] train: loss: 0.0077026
[Epoch 70; Iter   510/  960] train: loss: 0.2397299
[Epoch 70; Iter   540/  960] train: loss: 0.0414681
[Epoch 70; Iter   570/  960] train: loss: 0.0020638
[Epoch 70; Iter   600/  960] train: loss: 0.0496213
[Epoch 70; Iter   630/  960] train: loss: 0.0105347
[Epoch 70; Iter   660/  960] train: loss: 0.0157307
[Epoch 70; Iter   690/  960] train: loss: 0.0702320
[Epoch 70; Iter   720/  960] train: loss: 0.0392313
[Epoch 70; Iter   750/  960] train: loss: 0.0057627
[Epoch 70; Iter   780/  960] train: loss: 0.0125623
[Epoch 70; Iter   810/  960] train: loss: 0.0351961
[Epoch 70; Iter   840/  960] train: loss: 0.0144856
[Epoch 70; Iter   870/  960] train: loss: 0.0166236
[Epoch 70; Iter   900/  960] train: loss: 0.0857613
[Epoch 70; Iter   930/  960] train: loss: 0.0093056
[Epoch 70; Iter   960/  960] train: loss: 0.0270695
[Epoch 70] ogbg-molhiv: 0.758172 val loss: 0.348106
[Epoch 70] ogbg-molhiv: 0.756084 test loss: 0.222978
[Epoch 71; Iter    30/  960] train: loss: 0.0186637
[Epoch 71; Iter    60/  960] train: loss: 0.0020158
[Epoch 71; Iter    90/  960] train: loss: 0.0362611
[Epoch 71; Iter   120/  960] train: loss: 0.1098105
[Epoch 71; Iter   150/  960] train: loss: 0.1122473
[Epoch 71; Iter   180/  960] train: loss: 0.0390327
[Epoch 71; Iter   210/  960] train: loss: 0.0112654
[Epoch 71; Iter   240/  960] train: loss: 0.1485051
[Epoch 71; Iter   270/  960] train: loss: 0.0162608
[Epoch 71; Iter   300/  960] train: loss: 0.0026130
[Epoch 71; Iter   330/  960] train: loss: 0.1382080
[Epoch 71; Iter   360/  960] train: loss: 0.0253314
[Epoch 71; Iter   390/  960] train: loss: 0.0877200
[Epoch 71; Iter   420/  960] train: loss: 0.0022909
[Epoch 71; Iter   450/  960] train: loss: 0.0038386
[Epoch 71; Iter   480/  960] train: loss: 0.0331049
[Epoch 71; Iter   510/  960] train: loss: 0.0060618
[Epoch 71; Iter   540/  960] train: loss: 0.0072688
[Epoch 71; Iter   570/  960] train: loss: 0.0158829
[Epoch 71; Iter   600/  960] train: loss: 0.0048439
[Epoch 71; Iter   630/  960] train: loss: 0.1456958
[Epoch 71; Iter   660/  960] train: loss: 0.0312604
[Epoch 71; Iter   690/  960] train: loss: 0.0223122
[Epoch 71; Iter   720/  960] train: loss: 0.0086189
[Epoch 71; Iter   750/  960] train: loss: 0.1497781
[Epoch 71; Iter   780/  960] train: loss: 0.0282620
[Epoch 71; Iter   810/  960] train: loss: 0.0137870
[Epoch 71; Iter   840/  960] train: loss: 0.0691886
[Epoch 71; Iter   870/  960] train: loss: 0.1243640
[Epoch 71; Iter   900/  960] train: loss: 0.0188556
[Epoch 71; Iter   930/  960] train: loss: 0.0038254
[Epoch 71; Iter   960/  960] train: loss: 0.1496761
[Epoch 71] ogbg-molhiv: 0.757271 val loss: 0.482065
[Epoch 71] ogbg-molhiv: 0.759266 test loss: 0.245504
[Epoch 72; Iter    30/  960] train: loss: 0.0059117
[Epoch 72; Iter    60/  960] train: loss: 0.0727044
[Epoch 72; Iter    90/  960] train: loss: 0.0917056
[Epoch 72; Iter   120/  960] train: loss: 0.0118021
[Epoch 72; Iter   150/  960] train: loss: 0.0148233
[Epoch 72; Iter   180/  960] train: loss: 0.0633910
[Epoch 72; Iter   210/  960] train: loss: 0.0047825
[Epoch 72; Iter   240/  960] train: loss: 0.0025170
[Epoch 72; Iter   270/  960] train: loss: 0.1118444
[Epoch 72; Iter   300/  960] train: loss: 0.1164133
[Epoch 72; Iter   330/  960] train: loss: 0.0191181
[Epoch 72; Iter   360/  960] train: loss: 0.0476334
[Epoch 72; Iter   390/  960] train: loss: 0.1064199
[Epoch 72; Iter   420/  960] train: loss: 0.0439678
[Epoch 72; Iter   450/  960] train: loss: 0.0232482
[Epoch 72; Iter   480/  960] train: loss: 0.0265515
[Epoch 72; Iter   510/  960] train: loss: 0.0108159
[Epoch 72; Iter   540/  960] train: loss: 0.0673596
[Epoch 72; Iter   570/  960] train: loss: 0.1409239
[Epoch 72; Iter   600/  960] train: loss: 0.0213898
[Epoch 72; Iter   630/  960] train: loss: 0.0080524
[Epoch 72; Iter   660/  960] train: loss: 0.0082566
[Epoch 72; Iter   690/  960] train: loss: 0.1145125
[Epoch 72; Iter   720/  960] train: loss: 0.0552088
[Epoch 72; Iter   750/  960] train: loss: 0.0157936
[Epoch 72; Iter   780/  960] train: loss: 0.0074225
[Epoch 72; Iter   810/  960] train: loss: 0.0579348
[Epoch 72; Iter   840/  960] train: loss: 0.1005988
[Epoch 72; Iter   870/  960] train: loss: 0.0365441
[Epoch 72; Iter   900/  960] train: loss: 0.0322746
[Epoch 72; Iter   930/  960] train: loss: 0.0066828
[Epoch 72; Iter   960/  960] train: loss: 0.0126775
[Epoch 72] ogbg-molhiv: 0.750082 val loss: 0.625884
[Epoch 72] ogbg-molhiv: 0.749168 test loss: 0.197435
[Epoch 73; Iter    30/  960] train: loss: 0.0301412
[Epoch 73; Iter    60/  960] train: loss: 0.1381295
[Epoch 73; Iter    90/  960] train: loss: 0.0090434
[Epoch 73; Iter   120/  960] train: loss: 0.0231273
[Epoch 73; Iter   150/  960] train: loss: 0.0562917
[Epoch 73; Iter   180/  960] train: loss: 0.0100887
[Epoch 73; Iter   210/  960] train: loss: 0.0355288
[Epoch 73; Iter   240/  960] train: loss: 0.1324554
[Epoch 73; Iter   270/  960] train: loss: 0.0609190
[Epoch 73; Iter   300/  960] train: loss: 0.0374685
[Epoch 73; Iter   330/  960] train: loss: 0.0060961
[Epoch 73; Iter   360/  960] train: loss: 0.0380201
[Epoch 73; Iter   390/  960] train: loss: 0.0536534
[Epoch 73; Iter   420/  960] train: loss: 0.1203940
[Epoch 73; Iter   450/  960] train: loss: 0.0331820
[Epoch 73; Iter   480/  960] train: loss: 0.0179343
[Epoch 73; Iter   510/  960] train: loss: 0.0024275
[Epoch 73; Iter   540/  960] train: loss: 0.0046361
[Epoch 73; Iter   570/  960] train: loss: 0.0372923
[Epoch 73; Iter   600/  960] train: loss: 0.1153974
[Epoch 73; Iter   630/  960] train: loss: 0.0066481
[Epoch 69; Iter   134/ 1097] train: loss: 0.0028715
[Epoch 69; Iter   164/ 1097] train: loss: 0.0147227
[Epoch 69; Iter   194/ 1097] train: loss: 0.0361295
[Epoch 69; Iter   224/ 1097] train: loss: 0.0226100
[Epoch 69; Iter   254/ 1097] train: loss: 0.0236973
[Epoch 69; Iter   284/ 1097] train: loss: 0.0744967
[Epoch 69; Iter   314/ 1097] train: loss: 0.0412288
[Epoch 69; Iter   344/ 1097] train: loss: 0.0584681
[Epoch 69; Iter   374/ 1097] train: loss: 0.0395051
[Epoch 69; Iter   404/ 1097] train: loss: 0.0059356
[Epoch 69; Iter   434/ 1097] train: loss: 0.0083890
[Epoch 69; Iter   464/ 1097] train: loss: 0.0056380
[Epoch 69; Iter   494/ 1097] train: loss: 0.0203163
[Epoch 69; Iter   524/ 1097] train: loss: 0.0956692
[Epoch 69; Iter   554/ 1097] train: loss: 0.0235975
[Epoch 69; Iter   584/ 1097] train: loss: 0.0290109
[Epoch 69; Iter   614/ 1097] train: loss: 0.0218135
[Epoch 69; Iter   644/ 1097] train: loss: 0.0467126
[Epoch 69; Iter   674/ 1097] train: loss: 0.0393698
[Epoch 69; Iter   704/ 1097] train: loss: 0.0520126
[Epoch 69; Iter   734/ 1097] train: loss: 0.0233178
[Epoch 69; Iter   764/ 1097] train: loss: 0.0078814
[Epoch 69; Iter   794/ 1097] train: loss: 0.0182996
[Epoch 69; Iter   824/ 1097] train: loss: 0.1228078
[Epoch 69; Iter   854/ 1097] train: loss: 0.0287621
[Epoch 69; Iter   884/ 1097] train: loss: 0.0340402
[Epoch 69; Iter   914/ 1097] train: loss: 0.0056244
[Epoch 69; Iter   944/ 1097] train: loss: 0.1223188
[Epoch 69; Iter   974/ 1097] train: loss: 0.0632272
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0155685
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0290290
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0011928
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0095408
[Epoch 69] ogbg-molhiv: 0.759232 val loss: 0.283433
[Epoch 69] ogbg-molhiv: 0.727583 test loss: 1.043015
[Epoch 70; Iter    27/ 1097] train: loss: 0.0203264
[Epoch 70; Iter    57/ 1097] train: loss: 0.0392316
[Epoch 70; Iter    87/ 1097] train: loss: 0.0068363
[Epoch 70; Iter   117/ 1097] train: loss: 0.0195262
[Epoch 70; Iter   147/ 1097] train: loss: 0.0085191
[Epoch 70; Iter   177/ 1097] train: loss: 0.0090085
[Epoch 70; Iter   207/ 1097] train: loss: 0.0045080
[Epoch 70; Iter   237/ 1097] train: loss: 0.0229896
[Epoch 70; Iter   267/ 1097] train: loss: 0.0106973
[Epoch 70; Iter   297/ 1097] train: loss: 0.0033190
[Epoch 70; Iter   327/ 1097] train: loss: 0.0070149
[Epoch 70; Iter   357/ 1097] train: loss: 0.1173082
[Epoch 70; Iter   387/ 1097] train: loss: 0.0111705
[Epoch 70; Iter   417/ 1097] train: loss: 0.0287513
[Epoch 70; Iter   447/ 1097] train: loss: 0.0300915
[Epoch 70; Iter   477/ 1097] train: loss: 0.1068254
[Epoch 70; Iter   507/ 1097] train: loss: 0.0309199
[Epoch 70; Iter   537/ 1097] train: loss: 0.0494403
[Epoch 70; Iter   567/ 1097] train: loss: 0.1368352
[Epoch 70; Iter   597/ 1097] train: loss: 0.1582761
[Epoch 70; Iter   627/ 1097] train: loss: 0.0027081
[Epoch 70; Iter   657/ 1097] train: loss: 0.0066528
[Epoch 70; Iter   687/ 1097] train: loss: 0.0333752
[Epoch 70; Iter   717/ 1097] train: loss: 0.0159744
[Epoch 70; Iter   747/ 1097] train: loss: 0.0373701
[Epoch 70; Iter   777/ 1097] train: loss: 0.0076126
[Epoch 70; Iter   807/ 1097] train: loss: 0.0117012
[Epoch 70; Iter   837/ 1097] train: loss: 0.0137671
[Epoch 70; Iter   867/ 1097] train: loss: 0.0544448
[Epoch 70; Iter   897/ 1097] train: loss: 0.0226214
[Epoch 70; Iter   927/ 1097] train: loss: 0.1327702
[Epoch 70; Iter   957/ 1097] train: loss: 0.1544772
[Epoch 70; Iter   987/ 1097] train: loss: 0.0095241
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0136245
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0115160
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0512965
[Epoch 70] ogbg-molhiv: 0.763699 val loss: 0.114680
[Epoch 70] ogbg-molhiv: 0.735740 test loss: 0.226625
[Epoch 71; Iter    10/ 1097] train: loss: 0.0349616
[Epoch 71; Iter    40/ 1097] train: loss: 0.0083572
[Epoch 71; Iter    70/ 1097] train: loss: 0.0547759
[Epoch 71; Iter   100/ 1097] train: loss: 0.0062337
[Epoch 71; Iter   130/ 1097] train: loss: 0.0024561
[Epoch 71; Iter   160/ 1097] train: loss: 0.0468908
[Epoch 71; Iter   190/ 1097] train: loss: 0.0255504
[Epoch 71; Iter   220/ 1097] train: loss: 0.0137563
[Epoch 71; Iter   250/ 1097] train: loss: 0.0095049
[Epoch 71; Iter   280/ 1097] train: loss: 0.0146462
[Epoch 71; Iter   310/ 1097] train: loss: 0.0140072
[Epoch 71; Iter   340/ 1097] train: loss: 0.0325716
[Epoch 71; Iter   370/ 1097] train: loss: 0.0687886
[Epoch 71; Iter   400/ 1097] train: loss: 0.0082849
[Epoch 71; Iter   430/ 1097] train: loss: 0.0115470
[Epoch 71; Iter   460/ 1097] train: loss: 0.0159197
[Epoch 71; Iter   490/ 1097] train: loss: 0.0285328
[Epoch 71; Iter   520/ 1097] train: loss: 0.0128250
[Epoch 71; Iter   550/ 1097] train: loss: 0.0138640
[Epoch 71; Iter   580/ 1097] train: loss: 0.1116092
[Epoch 71; Iter   610/ 1097] train: loss: 0.0560793
[Epoch 71; Iter   640/ 1097] train: loss: 0.0078644
[Epoch 71; Iter   670/ 1097] train: loss: 0.0527120
[Epoch 71; Iter   700/ 1097] train: loss: 0.0364380
[Epoch 71; Iter   730/ 1097] train: loss: 0.2151872
[Epoch 71; Iter   760/ 1097] train: loss: 0.0152044
[Epoch 71; Iter   790/ 1097] train: loss: 0.0373616
[Epoch 71; Iter   820/ 1097] train: loss: 0.0885006
[Epoch 71; Iter   850/ 1097] train: loss: 0.0340234
[Epoch 71; Iter   880/ 1097] train: loss: 0.0131881
[Epoch 71; Iter   910/ 1097] train: loss: 0.0044494
[Epoch 71; Iter   940/ 1097] train: loss: 0.0120499
[Epoch 71; Iter   970/ 1097] train: loss: 0.0217687
[Epoch 71; Iter  1000/ 1097] train: loss: 0.0131622
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0069741
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0299840
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0429511
[Epoch 71] ogbg-molhiv: 0.744391 val loss: 0.153604
[Epoch 71] ogbg-molhiv: 0.723123 test loss: 0.301570
[Epoch 72; Iter    23/ 1097] train: loss: 0.0181882
[Epoch 72; Iter    53/ 1097] train: loss: 0.0038497
[Epoch 72; Iter    83/ 1097] train: loss: 0.1422543
[Epoch 72; Iter   113/ 1097] train: loss: 0.0183836
[Epoch 72; Iter   143/ 1097] train: loss: 0.0289738
[Epoch 72; Iter   173/ 1097] train: loss: 0.0183474
[Epoch 72; Iter   203/ 1097] train: loss: 0.1078784
[Epoch 72; Iter   233/ 1097] train: loss: 0.0312277
[Epoch 72; Iter   263/ 1097] train: loss: 0.0265349
[Epoch 72; Iter   293/ 1097] train: loss: 0.0339469
[Epoch 72; Iter   323/ 1097] train: loss: 0.0150461
[Epoch 72; Iter   353/ 1097] train: loss: 0.0042403
[Epoch 72; Iter   383/ 1097] train: loss: 0.0212549
[Epoch 72; Iter   413/ 1097] train: loss: 0.0197876
[Epoch 72; Iter   443/ 1097] train: loss: 0.0099147
[Epoch 72; Iter   473/ 1097] train: loss: 0.0927910
[Epoch 72; Iter   503/ 1097] train: loss: 0.0089986
[Epoch 72; Iter   533/ 1097] train: loss: 0.0343491
[Epoch 72; Iter   563/ 1097] train: loss: 0.0098300
[Epoch 72; Iter   593/ 1097] train: loss: 0.0035721
[Epoch 72; Iter   623/ 1097] train: loss: 0.0186488
[Epoch 72; Iter   653/ 1097] train: loss: 0.0358347
[Epoch 72; Iter   683/ 1097] train: loss: 0.2071873
[Epoch 72; Iter   713/ 1097] train: loss: 0.0043478
[Epoch 72; Iter   743/ 1097] train: loss: 0.0043176
[Epoch 72; Iter   773/ 1097] train: loss: 0.1250264
[Epoch 72; Iter   803/ 1097] train: loss: 0.0175647
[Epoch 72; Iter   833/ 1097] train: loss: 0.0693384
[Epoch 72; Iter   863/ 1097] train: loss: 0.0829423
[Epoch 72; Iter   893/ 1097] train: loss: 0.0219627
[Epoch 72; Iter   923/ 1097] train: loss: 0.0057732
[Epoch 72; Iter   953/ 1097] train: loss: 0.0330057
[Epoch 72; Iter   983/ 1097] train: loss: 0.0567452
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0051088
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0222989
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0188750
[Epoch 72] ogbg-molhiv: 0.742667 val loss: 0.204672
[Epoch 72] ogbg-molhiv: 0.731239 test loss: 0.345484
[Epoch 73; Iter     6/ 1097] train: loss: 0.0050348
[Epoch 73; Iter    36/ 1097] train: loss: 0.0115388
[Epoch 73; Iter    66/ 1097] train: loss: 0.0251097
[Epoch 73; Iter    96/ 1097] train: loss: 0.0099499
[Epoch 73; Iter   126/ 1097] train: loss: 0.0080786
[Epoch 73; Iter   156/ 1097] train: loss: 0.0347575
[Epoch 73; Iter   186/ 1097] train: loss: 0.0016167
[Epoch 69; Iter   134/ 1097] train: loss: 0.0267098
[Epoch 69; Iter   164/ 1097] train: loss: 0.0234429
[Epoch 69; Iter   194/ 1097] train: loss: 0.1859596
[Epoch 69; Iter   224/ 1097] train: loss: 0.0357802
[Epoch 69; Iter   254/ 1097] train: loss: 0.0199190
[Epoch 69; Iter   284/ 1097] train: loss: 0.0317448
[Epoch 69; Iter   314/ 1097] train: loss: 0.0473183
[Epoch 69; Iter   344/ 1097] train: loss: 0.0366106
[Epoch 69; Iter   374/ 1097] train: loss: 0.0232498
[Epoch 69; Iter   404/ 1097] train: loss: 0.0255736
[Epoch 69; Iter   434/ 1097] train: loss: 0.0779618
[Epoch 69; Iter   464/ 1097] train: loss: 0.0386777
[Epoch 69; Iter   494/ 1097] train: loss: 0.0117392
[Epoch 69; Iter   524/ 1097] train: loss: 0.0466531
[Epoch 69; Iter   554/ 1097] train: loss: 0.0238729
[Epoch 69; Iter   584/ 1097] train: loss: 0.0121017
[Epoch 69; Iter   614/ 1097] train: loss: 0.0090444
[Epoch 69; Iter   644/ 1097] train: loss: 0.2055727
[Epoch 69; Iter   674/ 1097] train: loss: 0.0624191
[Epoch 69; Iter   704/ 1097] train: loss: 0.0087649
[Epoch 69; Iter   734/ 1097] train: loss: 0.0344792
[Epoch 69; Iter   764/ 1097] train: loss: 0.0894744
[Epoch 69; Iter   794/ 1097] train: loss: 0.1162101
[Epoch 69; Iter   824/ 1097] train: loss: 0.3050204
[Epoch 69; Iter   854/ 1097] train: loss: 0.2067685
[Epoch 69; Iter   884/ 1097] train: loss: 0.0108370
[Epoch 69; Iter   914/ 1097] train: loss: 0.0097980
[Epoch 69; Iter   944/ 1097] train: loss: 0.0179380
[Epoch 69; Iter   974/ 1097] train: loss: 0.0316412
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0961927
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0212509
[Epoch 69; Iter  1064/ 1097] train: loss: 0.0359421
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0237821
[Epoch 69] ogbg-molhiv: 0.796348 val loss: 0.109642
[Epoch 69] ogbg-molhiv: 0.735229 test loss: 0.179372
[Epoch 70; Iter    27/ 1097] train: loss: 0.0336699
[Epoch 70; Iter    57/ 1097] train: loss: 0.0501651
[Epoch 70; Iter    87/ 1097] train: loss: 0.0670686
[Epoch 70; Iter   117/ 1097] train: loss: 0.1034709
[Epoch 70; Iter   147/ 1097] train: loss: 0.0102853
[Epoch 70; Iter   177/ 1097] train: loss: 0.1129680
[Epoch 70; Iter   207/ 1097] train: loss: 0.0504287
[Epoch 70; Iter   237/ 1097] train: loss: 0.0229102
[Epoch 70; Iter   267/ 1097] train: loss: 0.0101937
[Epoch 70; Iter   297/ 1097] train: loss: 0.0418270
[Epoch 70; Iter   327/ 1097] train: loss: 0.0223957
[Epoch 70; Iter   357/ 1097] train: loss: 0.1060815
[Epoch 70; Iter   387/ 1097] train: loss: 0.0078041
[Epoch 70; Iter   417/ 1097] train: loss: 0.1882048
[Epoch 70; Iter   447/ 1097] train: loss: 0.0333868
[Epoch 70; Iter   477/ 1097] train: loss: 0.0343972
[Epoch 70; Iter   507/ 1097] train: loss: 0.0284048
[Epoch 70; Iter   537/ 1097] train: loss: 0.0152580
[Epoch 70; Iter   567/ 1097] train: loss: 0.0172432
[Epoch 70; Iter   597/ 1097] train: loss: 0.0256278
[Epoch 70; Iter   627/ 1097] train: loss: 0.0500909
[Epoch 70; Iter   657/ 1097] train: loss: 0.1087231
[Epoch 70; Iter   687/ 1097] train: loss: 0.1410919
[Epoch 70; Iter   717/ 1097] train: loss: 0.0311046
[Epoch 70; Iter   747/ 1097] train: loss: 0.0115107
[Epoch 70; Iter   777/ 1097] train: loss: 0.0825168
[Epoch 70; Iter   807/ 1097] train: loss: 0.0937385
[Epoch 70; Iter   837/ 1097] train: loss: 0.0076798
[Epoch 70; Iter   867/ 1097] train: loss: 0.0137332
[Epoch 70; Iter   897/ 1097] train: loss: 0.0102006
[Epoch 70; Iter   927/ 1097] train: loss: 0.0077744
[Epoch 70; Iter   957/ 1097] train: loss: 0.0521211
[Epoch 70; Iter   987/ 1097] train: loss: 0.0898010
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0265572
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0537625
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0232175
[Epoch 70] ogbg-molhiv: 0.804499 val loss: 0.102880
[Epoch 70] ogbg-molhiv: 0.744414 test loss: 0.173083
[Epoch 71; Iter    10/ 1097] train: loss: 0.0734158
[Epoch 71; Iter    40/ 1097] train: loss: 0.0054470
[Epoch 71; Iter    70/ 1097] train: loss: 0.0174457
[Epoch 71; Iter   100/ 1097] train: loss: 0.1981743
[Epoch 71; Iter   130/ 1097] train: loss: 0.0366409
[Epoch 71; Iter   160/ 1097] train: loss: 0.0417759
[Epoch 71; Iter   190/ 1097] train: loss: 0.2026019
[Epoch 71; Iter   220/ 1097] train: loss: 0.0356357
[Epoch 71; Iter   250/ 1097] train: loss: 0.0199483
[Epoch 71; Iter   280/ 1097] train: loss: 0.0075401
[Epoch 71; Iter   310/ 1097] train: loss: 0.0184664
[Epoch 71; Iter   340/ 1097] train: loss: 0.0350157
[Epoch 71; Iter   370/ 1097] train: loss: 0.0326036
[Epoch 71; Iter   400/ 1097] train: loss: 0.0284684
[Epoch 71; Iter   430/ 1097] train: loss: 0.1603815
[Epoch 71; Iter   460/ 1097] train: loss: 0.0293228
[Epoch 71; Iter   490/ 1097] train: loss: 0.0476133
[Epoch 71; Iter   520/ 1097] train: loss: 0.0595323
[Epoch 71; Iter   550/ 1097] train: loss: 0.0232259
[Epoch 71; Iter   580/ 1097] train: loss: 0.0065845
[Epoch 71; Iter   610/ 1097] train: loss: 0.0308804
[Epoch 71; Iter   640/ 1097] train: loss: 0.0670386
[Epoch 71; Iter   670/ 1097] train: loss: 0.0335797
[Epoch 71; Iter   700/ 1097] train: loss: 0.2378865
[Epoch 71; Iter   730/ 1097] train: loss: 0.0838444
[Epoch 71; Iter   760/ 1097] train: loss: 0.0660835
[Epoch 71; Iter   790/ 1097] train: loss: 0.0205008
[Epoch 71; Iter   820/ 1097] train: loss: 0.0402636
[Epoch 71; Iter   850/ 1097] train: loss: 0.0322955
[Epoch 71; Iter   880/ 1097] train: loss: 0.0597787
[Epoch 71; Iter   910/ 1097] train: loss: 0.0313258
[Epoch 71; Iter   940/ 1097] train: loss: 0.0643026
[Epoch 71; Iter   970/ 1097] train: loss: 0.0206964
[Epoch 71; Iter  1000/ 1097] train: loss: 0.1240581
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0177973
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0648295
[Epoch 71; Iter  1090/ 1097] train: loss: 0.1024848
[Epoch 71] ogbg-molhiv: 0.793538 val loss: 0.104616
[Epoch 71] ogbg-molhiv: 0.723963 test loss: 0.179883
[Epoch 72; Iter    23/ 1097] train: loss: 0.0201179
[Epoch 72; Iter    53/ 1097] train: loss: 0.1100923
[Epoch 72; Iter    83/ 1097] train: loss: 0.0052111
[Epoch 72; Iter   113/ 1097] train: loss: 0.1063096
[Epoch 72; Iter   143/ 1097] train: loss: 0.0824929
[Epoch 72; Iter   173/ 1097] train: loss: 0.0115066
[Epoch 72; Iter   203/ 1097] train: loss: 0.0822420
[Epoch 72; Iter   233/ 1097] train: loss: 0.0211850
[Epoch 72; Iter   263/ 1097] train: loss: 0.0161244
[Epoch 72; Iter   293/ 1097] train: loss: 0.1854450
[Epoch 72; Iter   323/ 1097] train: loss: 0.0921554
[Epoch 72; Iter   353/ 1097] train: loss: 0.0093505
[Epoch 72; Iter   383/ 1097] train: loss: 0.0269264
[Epoch 72; Iter   413/ 1097] train: loss: 0.1609279
[Epoch 72; Iter   443/ 1097] train: loss: 0.0237689
[Epoch 72; Iter   473/ 1097] train: loss: 0.0303672
[Epoch 72; Iter   503/ 1097] train: loss: 0.0429135
[Epoch 72; Iter   533/ 1097] train: loss: 0.0221373
[Epoch 72; Iter   563/ 1097] train: loss: 0.0131183
[Epoch 72; Iter   593/ 1097] train: loss: 0.0344590
[Epoch 72; Iter   623/ 1097] train: loss: 0.0287727
[Epoch 72; Iter   653/ 1097] train: loss: 0.2317395
[Epoch 72; Iter   683/ 1097] train: loss: 0.0050642
[Epoch 72; Iter   713/ 1097] train: loss: 0.0138564
[Epoch 72; Iter   743/ 1097] train: loss: 0.0251218
[Epoch 72; Iter   773/ 1097] train: loss: 0.0452751
[Epoch 72; Iter   803/ 1097] train: loss: 0.0097314
[Epoch 72; Iter   833/ 1097] train: loss: 0.0203142
[Epoch 72; Iter   863/ 1097] train: loss: 0.0080850
[Epoch 72; Iter   893/ 1097] train: loss: 0.0494977
[Epoch 72; Iter   923/ 1097] train: loss: 0.0213944
[Epoch 72; Iter   953/ 1097] train: loss: 0.0359167
[Epoch 72; Iter   983/ 1097] train: loss: 0.0220910
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0484634
[Epoch 72; Iter  1043/ 1097] train: loss: 0.1520461
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0270661
[Epoch 72] ogbg-molhiv: 0.779315 val loss: 0.117948
[Epoch 72] ogbg-molhiv: 0.721103 test loss: 0.187475
[Epoch 73; Iter     6/ 1097] train: loss: 0.0093844
[Epoch 73; Iter    36/ 1097] train: loss: 0.0550046
[Epoch 73; Iter    66/ 1097] train: loss: 0.0201714
[Epoch 73; Iter    96/ 1097] train: loss: 0.1115895
[Epoch 73; Iter   126/ 1097] train: loss: 0.0639901
[Epoch 73; Iter   156/ 1097] train: loss: 0.0118220
[Epoch 73; Iter   186/ 1097] train: loss: 0.0283567
[Epoch 74; Iter   191/  823] train: loss: 0.0662501
[Epoch 74; Iter   221/  823] train: loss: 0.0359913
[Epoch 74; Iter   251/  823] train: loss: 0.0188317
[Epoch 74; Iter   281/  823] train: loss: 0.0195022
[Epoch 74; Iter   311/  823] train: loss: 0.0424629
[Epoch 74; Iter   341/  823] train: loss: 0.0310962
[Epoch 74; Iter   371/  823] train: loss: 0.0914392
[Epoch 74; Iter   401/  823] train: loss: 0.0126237
[Epoch 74; Iter   431/  823] train: loss: 0.0070246
[Epoch 74; Iter   461/  823] train: loss: 0.1637371
[Epoch 74; Iter   491/  823] train: loss: 0.0178290
[Epoch 74; Iter   521/  823] train: loss: 0.1928313
[Epoch 74; Iter   551/  823] train: loss: 0.0104613
[Epoch 74; Iter   581/  823] train: loss: 0.0100118
[Epoch 74; Iter   611/  823] train: loss: 0.0222122
[Epoch 74; Iter   641/  823] train: loss: 0.0527948
[Epoch 74; Iter   671/  823] train: loss: 0.0200078
[Epoch 74; Iter   701/  823] train: loss: 0.0052246
[Epoch 74; Iter   731/  823] train: loss: 0.0472550
[Epoch 74; Iter   761/  823] train: loss: 0.0508928
[Epoch 74; Iter   791/  823] train: loss: 0.0086535
[Epoch 74; Iter   821/  823] train: loss: 0.0076305
[Epoch 74] ogbg-molhiv: 0.744438 val loss: 0.224691
[Epoch 74] ogbg-molhiv: 0.748676 test loss: 0.245403
[Epoch 75; Iter    28/  823] train: loss: 0.1002466
[Epoch 75; Iter    58/  823] train: loss: 0.0868023
[Epoch 75; Iter    88/  823] train: loss: 0.0485302
[Epoch 75; Iter   118/  823] train: loss: 0.0319883
[Epoch 75; Iter   148/  823] train: loss: 0.0104763
[Epoch 75; Iter   178/  823] train: loss: 0.0269943
[Epoch 75; Iter   208/  823] train: loss: 0.2026502
[Epoch 75; Iter   238/  823] train: loss: 0.0111756
[Epoch 75; Iter   268/  823] train: loss: 0.0069197
[Epoch 75; Iter   298/  823] train: loss: 0.0270464
[Epoch 75; Iter   328/  823] train: loss: 0.0076644
[Epoch 75; Iter   358/  823] train: loss: 0.1152745
[Epoch 75; Iter   388/  823] train: loss: 0.0030298
[Epoch 75; Iter   418/  823] train: loss: 0.0689455
[Epoch 75; Iter   448/  823] train: loss: 0.0512561
[Epoch 75; Iter   478/  823] train: loss: 0.0290380
[Epoch 75; Iter   508/  823] train: loss: 0.0482050
[Epoch 75; Iter   538/  823] train: loss: 0.0519729
[Epoch 75; Iter   568/  823] train: loss: 0.0747050
[Epoch 75; Iter   598/  823] train: loss: 0.0605549
[Epoch 75; Iter   628/  823] train: loss: 0.0084637
[Epoch 75; Iter   658/  823] train: loss: 0.0967248
[Epoch 75; Iter   688/  823] train: loss: 0.1697542
[Epoch 75; Iter   718/  823] train: loss: 0.0246466
[Epoch 75; Iter   748/  823] train: loss: 0.0803403
[Epoch 75; Iter   778/  823] train: loss: 0.0162711
[Epoch 75; Iter   808/  823] train: loss: 0.0671821
[Epoch 75] ogbg-molhiv: 0.742018 val loss: 0.205993
[Epoch 75] ogbg-molhiv: 0.751161 test loss: 0.212836
[Epoch 76; Iter    15/  823] train: loss: 0.0048474
[Epoch 76; Iter    45/  823] train: loss: 0.0257917
[Epoch 76; Iter    75/  823] train: loss: 0.0688388
[Epoch 76; Iter   105/  823] train: loss: 0.0336021
[Epoch 76; Iter   135/  823] train: loss: 0.0485674
[Epoch 76; Iter   165/  823] train: loss: 0.0537309
[Epoch 76; Iter   195/  823] train: loss: 0.0042259
[Epoch 76; Iter   225/  823] train: loss: 0.0461903
[Epoch 76; Iter   255/  823] train: loss: 0.1326863
[Epoch 76; Iter   285/  823] train: loss: 0.0846700
[Epoch 76; Iter   315/  823] train: loss: 0.0207640
[Epoch 76; Iter   345/  823] train: loss: 0.0704923
[Epoch 76; Iter   375/  823] train: loss: 0.0574299
[Epoch 76; Iter   405/  823] train: loss: 0.0100333
[Epoch 76; Iter   435/  823] train: loss: 0.0139487
[Epoch 76; Iter   465/  823] train: loss: 0.0148061
[Epoch 76; Iter   495/  823] train: loss: 0.0173469
[Epoch 76; Iter   525/  823] train: loss: 0.0033689
[Epoch 76; Iter   555/  823] train: loss: 0.0038809
[Epoch 76; Iter   585/  823] train: loss: 0.0306160
[Epoch 76; Iter   615/  823] train: loss: 0.1074798
[Epoch 76; Iter   645/  823] train: loss: 0.0149080
[Epoch 76; Iter   675/  823] train: loss: 0.0189295
[Epoch 76; Iter   705/  823] train: loss: 0.0084063
[Epoch 76; Iter   735/  823] train: loss: 0.0421346
[Epoch 76; Iter   765/  823] train: loss: 0.0816226
[Epoch 76; Iter   795/  823] train: loss: 0.0073923
[Epoch 76] ogbg-molhiv: 0.739541 val loss: 0.229483
[Epoch 76] ogbg-molhiv: 0.755919 test loss: 0.266634
[Epoch 77; Iter     2/  823] train: loss: 0.0132517
[Epoch 77; Iter    32/  823] train: loss: 0.0197872
[Epoch 77; Iter    62/  823] train: loss: 0.0018055
[Epoch 77; Iter    92/  823] train: loss: 0.0454815
[Epoch 77; Iter   122/  823] train: loss: 0.0177765
[Epoch 77; Iter   152/  823] train: loss: 0.0054721
[Epoch 77; Iter   182/  823] train: loss: 0.0411571
[Epoch 77; Iter   212/  823] train: loss: 0.0105258
[Epoch 77; Iter   242/  823] train: loss: 0.0110018
[Epoch 77; Iter   272/  823] train: loss: 0.1578442
[Epoch 77; Iter   302/  823] train: loss: 0.0271004
[Epoch 77; Iter   332/  823] train: loss: 0.0194245
[Epoch 77; Iter   362/  823] train: loss: 0.0848343
[Epoch 77; Iter   392/  823] train: loss: 0.0457910
[Epoch 77; Iter   422/  823] train: loss: 0.0420422
[Epoch 77; Iter   452/  823] train: loss: 0.0031729
[Epoch 77; Iter   482/  823] train: loss: 0.0053606
[Epoch 77; Iter   512/  823] train: loss: 0.0041579
[Epoch 77; Iter   542/  823] train: loss: 0.0014362
[Epoch 77; Iter   572/  823] train: loss: 0.0455811
[Epoch 77; Iter   602/  823] train: loss: 0.0328285
[Epoch 77; Iter   632/  823] train: loss: 0.0556388
[Epoch 77; Iter   662/  823] train: loss: 0.0796547
[Epoch 77; Iter   692/  823] train: loss: 0.0426719
[Epoch 77; Iter   722/  823] train: loss: 0.0102768
[Epoch 77; Iter   752/  823] train: loss: 0.0254893
[Epoch 77; Iter   782/  823] train: loss: 0.0034796
[Epoch 77; Iter   812/  823] train: loss: 0.0017769
[Epoch 77] ogbg-molhiv: 0.737636 val loss: 0.209107
[Epoch 77] ogbg-molhiv: 0.751327 test loss: 0.280911
[Epoch 78; Iter    19/  823] train: loss: 0.0022993
[Epoch 78; Iter    49/  823] train: loss: 0.0107411
[Epoch 78; Iter    79/  823] train: loss: 0.0057962
[Epoch 78; Iter   109/  823] train: loss: 0.0211041
[Epoch 78; Iter   139/  823] train: loss: 0.0063571
[Epoch 78; Iter   169/  823] train: loss: 0.0330957
[Epoch 78; Iter   199/  823] train: loss: 0.0209642
[Epoch 78; Iter   229/  823] train: loss: 0.0141853
[Epoch 78; Iter   259/  823] train: loss: 0.0226387
[Epoch 78; Iter   289/  823] train: loss: 0.0197965
[Epoch 78; Iter   319/  823] train: loss: 0.0988866
[Epoch 78; Iter   349/  823] train: loss: 0.0044368
[Epoch 78; Iter   379/  823] train: loss: 0.0430528
[Epoch 78; Iter   409/  823] train: loss: 0.0700645
[Epoch 78; Iter   439/  823] train: loss: 0.0424347
[Epoch 78; Iter   469/  823] train: loss: 0.0073174
[Epoch 78; Iter   499/  823] train: loss: 0.0420878
[Epoch 78; Iter   529/  823] train: loss: 0.0597984
[Epoch 78; Iter   559/  823] train: loss: 0.0061449
[Epoch 78; Iter   589/  823] train: loss: 0.0034591
[Epoch 78; Iter   619/  823] train: loss: 0.0268812
[Epoch 78; Iter   649/  823] train: loss: 0.0192640
[Epoch 78; Iter   679/  823] train: loss: 0.0394665
[Epoch 78; Iter   709/  823] train: loss: 0.1812067
[Epoch 78; Iter   739/  823] train: loss: 0.0921066
[Epoch 78; Iter   769/  823] train: loss: 0.0340898
[Epoch 78; Iter   799/  823] train: loss: 0.0096231
[Epoch 78] ogbg-molhiv: 0.738413 val loss: 0.219265
[Epoch 78] ogbg-molhiv: 0.747478 test loss: 0.310431
[Epoch 79; Iter     6/  823] train: loss: 0.2197849
[Epoch 79; Iter    36/  823] train: loss: 0.0087510
[Epoch 79; Iter    66/  823] train: loss: 0.0296105
[Epoch 79; Iter    96/  823] train: loss: 0.0410440
[Epoch 79; Iter   126/  823] train: loss: 0.0024919
[Epoch 79; Iter   156/  823] train: loss: 0.0119800
[Epoch 79; Iter   186/  823] train: loss: 0.0301238
[Epoch 79; Iter   216/  823] train: loss: 0.0280975
[Epoch 79; Iter   246/  823] train: loss: 0.0483155
[Epoch 79; Iter   276/  823] train: loss: 0.0106814
[Epoch 79; Iter   306/  823] train: loss: 0.0193086
[Epoch 79; Iter   336/  823] train: loss: 0.1555367
[Epoch 79; Iter   366/  823] train: loss: 0.0020825
[Epoch 79; Iter   396/  823] train: loss: 0.0052404
[Epoch 79; Iter   426/  823] train: loss: 0.0220375
[Epoch 79; Iter   456/  823] train: loss: 0.0237518
[Epoch 74; Iter   191/  823] train: loss: 0.0270524
[Epoch 74; Iter   221/  823] train: loss: 0.0178364
[Epoch 74; Iter   251/  823] train: loss: 0.0036430
[Epoch 74; Iter   281/  823] train: loss: 0.0179419
[Epoch 74; Iter   311/  823] train: loss: 0.0543954
[Epoch 74; Iter   341/  823] train: loss: 0.0732549
[Epoch 74; Iter   371/  823] train: loss: 0.0892846
[Epoch 74; Iter   401/  823] train: loss: 0.0096586
[Epoch 74; Iter   431/  823] train: loss: 0.0368890
[Epoch 74; Iter   461/  823] train: loss: 0.0049962
[Epoch 74; Iter   491/  823] train: loss: 0.0490920
[Epoch 74; Iter   521/  823] train: loss: 0.1815745
[Epoch 74; Iter   551/  823] train: loss: 0.0256993
[Epoch 74; Iter   581/  823] train: loss: 0.0352363
[Epoch 74; Iter   611/  823] train: loss: 0.0181694
[Epoch 74; Iter   641/  823] train: loss: 0.0290183
[Epoch 74; Iter   671/  823] train: loss: 0.0319922
[Epoch 74; Iter   701/  823] train: loss: 0.0510266
[Epoch 74; Iter   731/  823] train: loss: 0.0347852
[Epoch 74; Iter   761/  823] train: loss: 0.0812061
[Epoch 74; Iter   791/  823] train: loss: 0.0044925
[Epoch 74; Iter   821/  823] train: loss: 0.0092874
[Epoch 74] ogbg-molhiv: 0.706108 val loss: 0.280284
[Epoch 74] ogbg-molhiv: 0.750471 test loss: 0.175720
[Epoch 75; Iter    28/  823] train: loss: 0.0122118
[Epoch 75; Iter    58/  823] train: loss: 0.0212297
[Epoch 75; Iter    88/  823] train: loss: 0.0352959
[Epoch 75; Iter   118/  823] train: loss: 0.0551574
[Epoch 75; Iter   148/  823] train: loss: 0.0152378
[Epoch 75; Iter   178/  823] train: loss: 0.0016175
[Epoch 75; Iter   208/  823] train: loss: 0.1458159
[Epoch 75; Iter   238/  823] train: loss: 0.0098868
[Epoch 75; Iter   268/  823] train: loss: 0.0073944
[Epoch 75; Iter   298/  823] train: loss: 0.0057462
[Epoch 75; Iter   328/  823] train: loss: 0.0212385
[Epoch 75; Iter   358/  823] train: loss: 0.0291653
[Epoch 75; Iter   388/  823] train: loss: 0.0021167
[Epoch 75; Iter   418/  823] train: loss: 0.0041075
[Epoch 75; Iter   448/  823] train: loss: 0.0021736
[Epoch 75; Iter   478/  823] train: loss: 0.1431580
[Epoch 75; Iter   508/  823] train: loss: 0.0204213
[Epoch 75; Iter   538/  823] train: loss: 0.0041050
[Epoch 75; Iter   568/  823] train: loss: 0.0136701
[Epoch 75; Iter   598/  823] train: loss: 0.0315811
[Epoch 75; Iter   628/  823] train: loss: 0.0731100
[Epoch 75; Iter   658/  823] train: loss: 0.0035227
[Epoch 75; Iter   688/  823] train: loss: 0.0672138
[Epoch 75; Iter   718/  823] train: loss: 0.0011701
[Epoch 75; Iter   748/  823] train: loss: 0.0051444
[Epoch 75; Iter   778/  823] train: loss: 0.0028491
[Epoch 75; Iter   808/  823] train: loss: 0.0683952
[Epoch 75] ogbg-molhiv: 0.707434 val loss: 0.310396
[Epoch 75] ogbg-molhiv: 0.754601 test loss: 0.181079
[Epoch 76; Iter    15/  823] train: loss: 0.0092938
[Epoch 76; Iter    45/  823] train: loss: 0.0019464
[Epoch 76; Iter    75/  823] train: loss: 0.0378339
[Epoch 76; Iter   105/  823] train: loss: 0.0144179
[Epoch 76; Iter   135/  823] train: loss: 0.0241071
[Epoch 76; Iter   165/  823] train: loss: 0.1216769
[Epoch 76; Iter   195/  823] train: loss: 0.0105441
[Epoch 76; Iter   225/  823] train: loss: 0.0427292
[Epoch 76; Iter   255/  823] train: loss: 0.0256924
[Epoch 76; Iter   285/  823] train: loss: 0.0027386
[Epoch 76; Iter   315/  823] train: loss: 0.0034167
[Epoch 76; Iter   345/  823] train: loss: 0.0111139
[Epoch 76; Iter   375/  823] train: loss: 0.0834009
[Epoch 76; Iter   405/  823] train: loss: 0.0017430
[Epoch 76; Iter   435/  823] train: loss: 0.0283111
[Epoch 76; Iter   465/  823] train: loss: 0.1195182
[Epoch 76; Iter   495/  823] train: loss: 0.0213981
[Epoch 76; Iter   525/  823] train: loss: 0.0037481
[Epoch 76; Iter   555/  823] train: loss: 0.0041166
[Epoch 76; Iter   585/  823] train: loss: 0.0047596
[Epoch 76; Iter   615/  823] train: loss: 0.0061197
[Epoch 76; Iter   645/  823] train: loss: 0.0026253
[Epoch 76; Iter   675/  823] train: loss: 0.0395053
[Epoch 76; Iter   705/  823] train: loss: 0.0026373
[Epoch 76; Iter   735/  823] train: loss: 0.0694382
[Epoch 76; Iter   765/  823] train: loss: 0.0765963
[Epoch 76; Iter   795/  823] train: loss: 0.0226102
[Epoch 76] ogbg-molhiv: 0.699338 val loss: 0.320820
[Epoch 76] ogbg-molhiv: 0.743542 test loss: 0.219557
[Epoch 77; Iter     2/  823] train: loss: 0.0079742
[Epoch 77; Iter    32/  823] train: loss: 0.0057855
[Epoch 77; Iter    62/  823] train: loss: 0.0048688
[Epoch 77; Iter    92/  823] train: loss: 0.0547792
[Epoch 77; Iter   122/  823] train: loss: 0.0200703
[Epoch 77; Iter   152/  823] train: loss: 0.0208800
[Epoch 77; Iter   182/  823] train: loss: 0.0005435
[Epoch 77; Iter   212/  823] train: loss: 0.0045254
[Epoch 77; Iter   242/  823] train: loss: 0.0451105
[Epoch 77; Iter   272/  823] train: loss: 0.0213632
[Epoch 77; Iter   302/  823] train: loss: 0.0474464
[Epoch 77; Iter   332/  823] train: loss: 0.0126079
[Epoch 77; Iter   362/  823] train: loss: 0.0334843
[Epoch 77; Iter   392/  823] train: loss: 0.0304943
[Epoch 77; Iter   422/  823] train: loss: 0.0135896
[Epoch 77; Iter   452/  823] train: loss: 0.1510481
[Epoch 77; Iter   482/  823] train: loss: 0.0084233
[Epoch 77; Iter   512/  823] train: loss: 0.0018813
[Epoch 77; Iter   542/  823] train: loss: 0.0018776
[Epoch 77; Iter   572/  823] train: loss: 0.0032542
[Epoch 77; Iter   602/  823] train: loss: 0.1038900
[Epoch 77; Iter   632/  823] train: loss: 0.0540687
[Epoch 77; Iter   662/  823] train: loss: 0.0021023
[Epoch 77; Iter   692/  823] train: loss: 0.0039205
[Epoch 77; Iter   722/  823] train: loss: 0.0070010
[Epoch 77; Iter   752/  823] train: loss: 0.1342162
[Epoch 77; Iter   782/  823] train: loss: 0.0935895
[Epoch 77; Iter   812/  823] train: loss: 0.0165712
[Epoch 77] ogbg-molhiv: 0.714285 val loss: 0.343221
[Epoch 77] ogbg-molhiv: 0.755040 test loss: 0.215478
[Epoch 78; Iter    19/  823] train: loss: 0.0110038
[Epoch 78; Iter    49/  823] train: loss: 0.0295648
[Epoch 78; Iter    79/  823] train: loss: 0.0016735
[Epoch 78; Iter   109/  823] train: loss: 0.0508334
[Epoch 78; Iter   139/  823] train: loss: 0.1541220
[Epoch 78; Iter   169/  823] train: loss: 0.0559443
[Epoch 78; Iter   199/  823] train: loss: 0.0320520
[Epoch 78; Iter   229/  823] train: loss: 0.0068500
[Epoch 78; Iter   259/  823] train: loss: 0.0013389
[Epoch 78; Iter   289/  823] train: loss: 0.0077637
[Epoch 78; Iter   319/  823] train: loss: 0.0248927
[Epoch 78; Iter   349/  823] train: loss: 0.0094345
[Epoch 78; Iter   379/  823] train: loss: 0.0146894
[Epoch 78; Iter   409/  823] train: loss: 0.0622381
[Epoch 78; Iter   439/  823] train: loss: 0.0065184
[Epoch 78; Iter   469/  823] train: loss: 0.0945985
[Epoch 78; Iter   499/  823] train: loss: 0.0012684
[Epoch 78; Iter   529/  823] train: loss: 0.0078050
[Epoch 78; Iter   559/  823] train: loss: 0.0471343
[Epoch 78; Iter   589/  823] train: loss: 0.0133071
[Epoch 78; Iter   619/  823] train: loss: 0.0069385
[Epoch 78; Iter   649/  823] train: loss: 0.0417125
[Epoch 78; Iter   679/  823] train: loss: 0.0176448
[Epoch 78; Iter   709/  823] train: loss: 0.0758725
[Epoch 78; Iter   739/  823] train: loss: 0.0234547
[Epoch 78; Iter   769/  823] train: loss: 0.0048573
[Epoch 78; Iter   799/  823] train: loss: 0.0020299
[Epoch 78] ogbg-molhiv: 0.709645 val loss: 0.373200
[Epoch 78] ogbg-molhiv: 0.738755 test loss: 0.224128
[Epoch 79; Iter     6/  823] train: loss: 0.0054842
[Epoch 79; Iter    36/  823] train: loss: 0.0017311
[Epoch 79; Iter    66/  823] train: loss: 0.0061679
[Epoch 79; Iter    96/  823] train: loss: 0.0028567
[Epoch 79; Iter   126/  823] train: loss: 0.0073383
[Epoch 79; Iter   156/  823] train: loss: 0.0646101
[Epoch 79; Iter   186/  823] train: loss: 0.0016735
[Epoch 79; Iter   216/  823] train: loss: 0.0773669
[Epoch 79; Iter   246/  823] train: loss: 0.0059576
[Epoch 79; Iter   276/  823] train: loss: 0.0173139
[Epoch 79; Iter   306/  823] train: loss: 0.0253912
[Epoch 79; Iter   336/  823] train: loss: 0.0751573
[Epoch 79; Iter   366/  823] train: loss: 0.1474067
[Epoch 79; Iter   396/  823] train: loss: 0.0505969
[Epoch 79; Iter   426/  823] train: loss: 0.0607411
[Epoch 79; Iter   456/  823] train: loss: 0.0330263
[Epoch 69; Iter   134/ 1097] train: loss: 0.0071758
[Epoch 69; Iter   164/ 1097] train: loss: 0.0167289
[Epoch 69; Iter   194/ 1097] train: loss: 0.0129493
[Epoch 69; Iter   224/ 1097] train: loss: 0.1061811
[Epoch 69; Iter   254/ 1097] train: loss: 0.0074207
[Epoch 69; Iter   284/ 1097] train: loss: 0.0033340
[Epoch 69; Iter   314/ 1097] train: loss: 0.0488654
[Epoch 69; Iter   344/ 1097] train: loss: 0.0597584
[Epoch 69; Iter   374/ 1097] train: loss: 0.1559779
[Epoch 69; Iter   404/ 1097] train: loss: 0.1338125
[Epoch 69; Iter   434/ 1097] train: loss: 0.0582554
[Epoch 69; Iter   464/ 1097] train: loss: 0.0897158
[Epoch 69; Iter   494/ 1097] train: loss: 0.0103437
[Epoch 69; Iter   524/ 1097] train: loss: 0.0104909
[Epoch 69; Iter   554/ 1097] train: loss: 0.0166157
[Epoch 69; Iter   584/ 1097] train: loss: 0.0017665
[Epoch 69; Iter   614/ 1097] train: loss: 0.0034663
[Epoch 69; Iter   644/ 1097] train: loss: 0.0067534
[Epoch 69; Iter   674/ 1097] train: loss: 0.0280471
[Epoch 69; Iter   704/ 1097] train: loss: 0.0010129
[Epoch 69; Iter   734/ 1097] train: loss: 0.1079656
[Epoch 69; Iter   764/ 1097] train: loss: 0.0342406
[Epoch 69; Iter   794/ 1097] train: loss: 0.0040312
[Epoch 69; Iter   824/ 1097] train: loss: 0.0071129
[Epoch 69; Iter   854/ 1097] train: loss: 0.0493927
[Epoch 69; Iter   884/ 1097] train: loss: 0.0457331
[Epoch 69; Iter   914/ 1097] train: loss: 0.0117815
[Epoch 69; Iter   944/ 1097] train: loss: 0.0093161
[Epoch 69; Iter   974/ 1097] train: loss: 0.0099383
[Epoch 69; Iter  1004/ 1097] train: loss: 0.0069677
[Epoch 69; Iter  1034/ 1097] train: loss: 0.0069356
[Epoch 69; Iter  1064/ 1097] train: loss: 0.1772494
[Epoch 69; Iter  1094/ 1097] train: loss: 0.0474065
[Epoch 69] ogbg-molhiv: 0.805660 val loss: 0.105304
[Epoch 69] ogbg-molhiv: 0.776384 test loss: 0.194014
[Epoch 70; Iter    27/ 1097] train: loss: 0.0188531
[Epoch 70; Iter    57/ 1097] train: loss: 0.0267933
[Epoch 70; Iter    87/ 1097] train: loss: 0.0046071
[Epoch 70; Iter   117/ 1097] train: loss: 0.3623159
[Epoch 70; Iter   147/ 1097] train: loss: 0.0024591
[Epoch 70; Iter   177/ 1097] train: loss: 0.0386264
[Epoch 70; Iter   207/ 1097] train: loss: 0.0013102
[Epoch 70; Iter   237/ 1097] train: loss: 0.0049758
[Epoch 70; Iter   267/ 1097] train: loss: 0.1761239
[Epoch 70; Iter   297/ 1097] train: loss: 0.0374839
[Epoch 70; Iter   327/ 1097] train: loss: 0.0170743
[Epoch 70; Iter   357/ 1097] train: loss: 0.1890438
[Epoch 70; Iter   387/ 1097] train: loss: 0.0805926
[Epoch 70; Iter   417/ 1097] train: loss: 0.0057258
[Epoch 70; Iter   447/ 1097] train: loss: 0.0608842
[Epoch 70; Iter   477/ 1097] train: loss: 0.0118161
[Epoch 70; Iter   507/ 1097] train: loss: 0.0264237
[Epoch 70; Iter   537/ 1097] train: loss: 0.0170221
[Epoch 70; Iter   567/ 1097] train: loss: 0.0179275
[Epoch 70; Iter   597/ 1097] train: loss: 0.0016128
[Epoch 70; Iter   627/ 1097] train: loss: 0.0266639
[Epoch 70; Iter   657/ 1097] train: loss: 0.0245367
[Epoch 70; Iter   687/ 1097] train: loss: 0.0193162
[Epoch 70; Iter   717/ 1097] train: loss: 0.0195376
[Epoch 70; Iter   747/ 1097] train: loss: 0.0060258
[Epoch 70; Iter   777/ 1097] train: loss: 0.0117081
[Epoch 70; Iter   807/ 1097] train: loss: 0.1011774
[Epoch 70; Iter   837/ 1097] train: loss: 0.0160417
[Epoch 70; Iter   867/ 1097] train: loss: 0.0192073
[Epoch 70; Iter   897/ 1097] train: loss: 0.0354960
[Epoch 70; Iter   927/ 1097] train: loss: 0.0042179
[Epoch 70; Iter   957/ 1097] train: loss: 0.0549469
[Epoch 70; Iter   987/ 1097] train: loss: 0.0405171
[Epoch 70; Iter  1017/ 1097] train: loss: 0.0231893
[Epoch 70; Iter  1047/ 1097] train: loss: 0.0116110
[Epoch 70; Iter  1077/ 1097] train: loss: 0.0276338
[Epoch 70] ogbg-molhiv: 0.792989 val loss: 0.109516
[Epoch 70] ogbg-molhiv: 0.756903 test loss: 0.209768
[Epoch 71; Iter    10/ 1097] train: loss: 0.0353302
[Epoch 71; Iter    40/ 1097] train: loss: 0.0147587
[Epoch 71; Iter    70/ 1097] train: loss: 0.0206100
[Epoch 71; Iter   100/ 1097] train: loss: 0.0178603
[Epoch 71; Iter   130/ 1097] train: loss: 0.0070985
[Epoch 71; Iter   160/ 1097] train: loss: 0.0056931
[Epoch 71; Iter   190/ 1097] train: loss: 0.1101388
[Epoch 71; Iter   220/ 1097] train: loss: 0.0139988
[Epoch 71; Iter   250/ 1097] train: loss: 0.0086242
[Epoch 71; Iter   280/ 1097] train: loss: 0.0256589
[Epoch 71; Iter   310/ 1097] train: loss: 0.0014888
[Epoch 71; Iter   340/ 1097] train: loss: 0.0447250
[Epoch 71; Iter   370/ 1097] train: loss: 0.1085831
[Epoch 71; Iter   400/ 1097] train: loss: 0.0089557
[Epoch 71; Iter   430/ 1097] train: loss: 0.0878533
[Epoch 71; Iter   460/ 1097] train: loss: 0.0044872
[Epoch 71; Iter   490/ 1097] train: loss: 0.0180124
[Epoch 71; Iter   520/ 1097] train: loss: 0.0952408
[Epoch 71; Iter   550/ 1097] train: loss: 0.0484192
[Epoch 71; Iter   580/ 1097] train: loss: 0.0107252
[Epoch 71; Iter   610/ 1097] train: loss: 0.0612218
[Epoch 71; Iter   640/ 1097] train: loss: 0.0053827
[Epoch 71; Iter   670/ 1097] train: loss: 0.0057235
[Epoch 71; Iter   700/ 1097] train: loss: 0.0881007
[Epoch 71; Iter   730/ 1097] train: loss: 0.0613394
[Epoch 71; Iter   760/ 1097] train: loss: 0.0031628
[Epoch 71; Iter   790/ 1097] train: loss: 0.0153589
[Epoch 71; Iter   820/ 1097] train: loss: 0.2400163
[Epoch 71; Iter   850/ 1097] train: loss: 0.0217834
[Epoch 71; Iter   880/ 1097] train: loss: 0.1958614
[Epoch 71; Iter   910/ 1097] train: loss: 0.0048332
[Epoch 71; Iter   940/ 1097] train: loss: 0.0085657
[Epoch 71; Iter   970/ 1097] train: loss: 0.0187067
[Epoch 71; Iter  1000/ 1097] train: loss: 0.1111983
[Epoch 71; Iter  1030/ 1097] train: loss: 0.0648281
[Epoch 71; Iter  1060/ 1097] train: loss: 0.0044238
[Epoch 71; Iter  1090/ 1097] train: loss: 0.0174755
[Epoch 71] ogbg-molhiv: 0.794324 val loss: 0.106645
[Epoch 71] ogbg-molhiv: 0.770741 test loss: 0.191115
[Epoch 72; Iter    23/ 1097] train: loss: 0.0790585
[Epoch 72; Iter    53/ 1097] train: loss: 0.1133738
[Epoch 72; Iter    83/ 1097] train: loss: 0.0068241
[Epoch 72; Iter   113/ 1097] train: loss: 0.0036266
[Epoch 72; Iter   143/ 1097] train: loss: 0.0116943
[Epoch 72; Iter   173/ 1097] train: loss: 0.0093273
[Epoch 72; Iter   203/ 1097] train: loss: 0.0020366
[Epoch 72; Iter   233/ 1097] train: loss: 0.0435504
[Epoch 72; Iter   263/ 1097] train: loss: 0.0063287
[Epoch 72; Iter   293/ 1097] train: loss: 0.0103066
[Epoch 72; Iter   323/ 1097] train: loss: 0.0182075
[Epoch 72; Iter   353/ 1097] train: loss: 0.1893583
[Epoch 72; Iter   383/ 1097] train: loss: 0.0029478
[Epoch 72; Iter   413/ 1097] train: loss: 0.0938325
[Epoch 72; Iter   443/ 1097] train: loss: 0.0013733
[Epoch 72; Iter   473/ 1097] train: loss: 0.0705011
[Epoch 72; Iter   503/ 1097] train: loss: 0.1950375
[Epoch 72; Iter   533/ 1097] train: loss: 0.0953899
[Epoch 72; Iter   563/ 1097] train: loss: 0.0233470
[Epoch 72; Iter   593/ 1097] train: loss: 0.0099714
[Epoch 72; Iter   623/ 1097] train: loss: 0.0687621
[Epoch 72; Iter   653/ 1097] train: loss: 0.0257766
[Epoch 72; Iter   683/ 1097] train: loss: 0.0062054
[Epoch 72; Iter   713/ 1097] train: loss: 0.0054376
[Epoch 72; Iter   743/ 1097] train: loss: 0.1017991
[Epoch 72; Iter   773/ 1097] train: loss: 0.0454144
[Epoch 72; Iter   803/ 1097] train: loss: 0.0105065
[Epoch 72; Iter   833/ 1097] train: loss: 0.1993072
[Epoch 72; Iter   863/ 1097] train: loss: 0.0073242
[Epoch 72; Iter   893/ 1097] train: loss: 0.0023221
[Epoch 72; Iter   923/ 1097] train: loss: 0.0075288
[Epoch 72; Iter   953/ 1097] train: loss: 0.0384792
[Epoch 72; Iter   983/ 1097] train: loss: 0.0039977
[Epoch 72; Iter  1013/ 1097] train: loss: 0.0016801
[Epoch 72; Iter  1043/ 1097] train: loss: 0.0069328
[Epoch 72; Iter  1073/ 1097] train: loss: 0.0232773
[Epoch 72] ogbg-molhiv: 0.803078 val loss: 0.106548
[Epoch 72] ogbg-molhiv: 0.770233 test loss: 0.197971
[Epoch 73; Iter     6/ 1097] train: loss: 0.0297301
[Epoch 73; Iter    36/ 1097] train: loss: 0.0101812
[Epoch 73; Iter    66/ 1097] train: loss: 0.0071811
[Epoch 73; Iter    96/ 1097] train: loss: 0.0054146
[Epoch 73; Iter   126/ 1097] train: loss: 0.0022298
[Epoch 73; Iter   156/ 1097] train: loss: 0.0141224
[Epoch 73; Iter   186/ 1097] train: loss: 0.1135300
[Epoch 74; Iter   191/  823] train: loss: 0.0209812
[Epoch 74; Iter   221/  823] train: loss: 0.0026102
[Epoch 74; Iter   251/  823] train: loss: 0.0377296
[Epoch 74; Iter   281/  823] train: loss: 0.0624656
[Epoch 74; Iter   311/  823] train: loss: 0.0648446
[Epoch 74; Iter   341/  823] train: loss: 0.0825755
[Epoch 74; Iter   371/  823] train: loss: 0.0177562
[Epoch 74; Iter   401/  823] train: loss: 0.0089200
[Epoch 74; Iter   431/  823] train: loss: 0.0433849
[Epoch 74; Iter   461/  823] train: loss: 0.0124572
[Epoch 74; Iter   491/  823] train: loss: 0.0158338
[Epoch 74; Iter   521/  823] train: loss: 0.0009177
[Epoch 74; Iter   551/  823] train: loss: 0.0061122
[Epoch 74; Iter   581/  823] train: loss: 0.0163090
[Epoch 74; Iter   611/  823] train: loss: 0.0026584
[Epoch 74; Iter   641/  823] train: loss: 0.0255089
[Epoch 74; Iter   671/  823] train: loss: 0.1341833
[Epoch 74; Iter   701/  823] train: loss: 0.0194661
[Epoch 74; Iter   731/  823] train: loss: 0.0157785
[Epoch 74; Iter   761/  823] train: loss: 0.0173377
[Epoch 74; Iter   791/  823] train: loss: 0.0032694
[Epoch 74; Iter   821/  823] train: loss: 0.0239316
[Epoch 74] ogbg-molhiv: 0.738126 val loss: 0.278246
[Epoch 74] ogbg-molhiv: 0.763217 test loss: 0.219508
[Epoch 75; Iter    28/  823] train: loss: 0.0024453
[Epoch 75; Iter    58/  823] train: loss: 0.0057639
[Epoch 75; Iter    88/  823] train: loss: 0.0022586
[Epoch 75; Iter   118/  823] train: loss: 0.0139475
[Epoch 75; Iter   148/  823] train: loss: 0.0037216
[Epoch 75; Iter   178/  823] train: loss: 0.0096596
[Epoch 75; Iter   208/  823] train: loss: 0.0061149
[Epoch 75; Iter   238/  823] train: loss: 0.0048720
[Epoch 75; Iter   268/  823] train: loss: 0.0058929
[Epoch 75; Iter   298/  823] train: loss: 0.0070631
[Epoch 75; Iter   328/  823] train: loss: 0.0092497
[Epoch 75; Iter   358/  823] train: loss: 0.0278842
[Epoch 75; Iter   388/  823] train: loss: 0.0165200
[Epoch 75; Iter   418/  823] train: loss: 0.0259985
[Epoch 75; Iter   448/  823] train: loss: 0.0116435
[Epoch 75; Iter   478/  823] train: loss: 0.0058269
[Epoch 75; Iter   508/  823] train: loss: 0.1011705
[Epoch 75; Iter   538/  823] train: loss: 0.0050672
[Epoch 75; Iter   568/  823] train: loss: 0.0752004
[Epoch 75; Iter   598/  823] train: loss: 0.0597176
[Epoch 75; Iter   628/  823] train: loss: 0.0012264
[Epoch 75; Iter   658/  823] train: loss: 0.0537593
[Epoch 75; Iter   688/  823] train: loss: 0.0034602
[Epoch 75; Iter   718/  823] train: loss: 0.0309684
[Epoch 75; Iter   748/  823] train: loss: 0.0010817
[Epoch 75; Iter   778/  823] train: loss: 0.0419348
[Epoch 75; Iter   808/  823] train: loss: 0.0092684
[Epoch 75] ogbg-molhiv: 0.739031 val loss: 0.282643
[Epoch 75] ogbg-molhiv: 0.770616 test loss: 0.220422
[Epoch 76; Iter    15/  823] train: loss: 0.0328505
[Epoch 76; Iter    45/  823] train: loss: 0.0255884
[Epoch 76; Iter    75/  823] train: loss: 0.0265780
[Epoch 76; Iter   105/  823] train: loss: 0.0224793
[Epoch 76; Iter   135/  823] train: loss: 0.0851787
[Epoch 76; Iter   165/  823] train: loss: 0.0032188
[Epoch 76; Iter   195/  823] train: loss: 0.0767821
[Epoch 76; Iter   225/  823] train: loss: 0.0055878
[Epoch 76; Iter   255/  823] train: loss: 0.0111542
[Epoch 76; Iter   285/  823] train: loss: 0.0021820
[Epoch 76; Iter   315/  823] train: loss: 0.1066026
[Epoch 76; Iter   345/  823] train: loss: 0.0128591
[Epoch 76; Iter   375/  823] train: loss: 0.0135577
[Epoch 76; Iter   405/  823] train: loss: 0.0069762
[Epoch 76; Iter   435/  823] train: loss: 0.0076422
[Epoch 76; Iter   465/  823] train: loss: 0.0318189
[Epoch 76; Iter   495/  823] train: loss: 0.0750710
[Epoch 76; Iter   525/  823] train: loss: 0.0241986
[Epoch 76; Iter   555/  823] train: loss: 0.0396404
[Epoch 76; Iter   585/  823] train: loss: 0.0240965
[Epoch 76; Iter   615/  823] train: loss: 0.0103777
[Epoch 76; Iter   645/  823] train: loss: 0.0195657
[Epoch 76; Iter   675/  823] train: loss: 0.0260940
[Epoch 76; Iter   705/  823] train: loss: 0.0342719
[Epoch 76; Iter   735/  823] train: loss: 0.0022849
[Epoch 76; Iter   765/  823] train: loss: 0.0337417
[Epoch 76; Iter   795/  823] train: loss: 0.0018533
[Epoch 76] ogbg-molhiv: 0.739674 val loss: 0.276026
[Epoch 76] ogbg-molhiv: 0.751023 test loss: 0.228501
[Epoch 77; Iter     2/  823] train: loss: 0.0160441
[Epoch 77; Iter    32/  823] train: loss: 0.0164564
[Epoch 77; Iter    62/  823] train: loss: 0.0005905
[Epoch 77; Iter    92/  823] train: loss: 0.0401550
[Epoch 77; Iter   122/  823] train: loss: 0.0012595
[Epoch 77; Iter   152/  823] train: loss: 0.1102237
[Epoch 77; Iter   182/  823] train: loss: 0.0719136
[Epoch 77; Iter   212/  823] train: loss: 0.0040900
[Epoch 77; Iter   242/  823] train: loss: 0.0201609
[Epoch 77; Iter   272/  823] train: loss: 0.0008780
[Epoch 77; Iter   302/  823] train: loss: 0.0030792
[Epoch 77; Iter   332/  823] train: loss: 0.1394952
[Epoch 77; Iter   362/  823] train: loss: 0.0058798
[Epoch 77; Iter   392/  823] train: loss: 0.0061315
[Epoch 77; Iter   422/  823] train: loss: 0.1050649
[Epoch 77; Iter   452/  823] train: loss: 0.0020029
[Epoch 77; Iter   482/  823] train: loss: 0.0230431
[Epoch 77; Iter   512/  823] train: loss: 0.0017604
[Epoch 77; Iter   542/  823] train: loss: 0.0180321
[Epoch 77; Iter   572/  823] train: loss: 0.0845780
[Epoch 77; Iter   602/  823] train: loss: 0.1314044
[Epoch 77; Iter   632/  823] train: loss: 0.0111462
[Epoch 77; Iter   662/  823] train: loss: 0.0235954
[Epoch 77; Iter   692/  823] train: loss: 0.0050849
[Epoch 77; Iter   722/  823] train: loss: 0.1294884
[Epoch 77; Iter   752/  823] train: loss: 0.0373626
[Epoch 77; Iter   782/  823] train: loss: 0.0020594
[Epoch 77; Iter   812/  823] train: loss: 0.0743590
[Epoch 77] ogbg-molhiv: 0.742159 val loss: 0.312074
[Epoch 77] ogbg-molhiv: 0.756935 test loss: 0.262908
[Epoch 78; Iter    19/  823] train: loss: 0.0224505
[Epoch 78; Iter    49/  823] train: loss: 0.0123930
[Epoch 78; Iter    79/  823] train: loss: 0.0188736
[Epoch 78; Iter   109/  823] train: loss: 0.0897364
[Epoch 78; Iter   139/  823] train: loss: 0.0283674
[Epoch 78; Iter   169/  823] train: loss: 0.0011289
[Epoch 78; Iter   199/  823] train: loss: 0.1785365
[Epoch 78; Iter   229/  823] train: loss: 0.0153977
[Epoch 78; Iter   259/  823] train: loss: 0.0204104
[Epoch 78; Iter   289/  823] train: loss: 0.0120566
[Epoch 78; Iter   319/  823] train: loss: 0.0212362
[Epoch 78; Iter   349/  823] train: loss: 0.0056801
[Epoch 78; Iter   379/  823] train: loss: 0.0137760
[Epoch 78; Iter   409/  823] train: loss: 0.0111356
[Epoch 78; Iter   439/  823] train: loss: 0.0037691
[Epoch 78; Iter   469/  823] train: loss: 0.0354680
[Epoch 78; Iter   499/  823] train: loss: 0.0070178
[Epoch 78; Iter   529/  823] train: loss: 0.0015500
[Epoch 78; Iter   559/  823] train: loss: 0.0022002
[Epoch 78; Iter   589/  823] train: loss: 0.0018643
[Epoch 78; Iter   619/  823] train: loss: 0.0028843
[Epoch 78; Iter   649/  823] train: loss: 0.0593406
[Epoch 78; Iter   679/  823] train: loss: 0.0088822
[Epoch 78; Iter   709/  823] train: loss: 0.0216769
[Epoch 78; Iter   739/  823] train: loss: 0.0020013
[Epoch 78; Iter   769/  823] train: loss: 0.1786629
[Epoch 78; Iter   799/  823] train: loss: 0.0101452
[Epoch 78] ogbg-molhiv: 0.741748 val loss: 0.325276
[Epoch 78] ogbg-molhiv: 0.761987 test loss: 0.282351
[Epoch 79; Iter     6/  823] train: loss: 0.0080781
[Epoch 79; Iter    36/  823] train: loss: 0.0090804
[Epoch 79; Iter    66/  823] train: loss: 0.0016555
[Epoch 79; Iter    96/  823] train: loss: 0.0009591
[Epoch 79; Iter   126/  823] train: loss: 0.0020096
[Epoch 79; Iter   156/  823] train: loss: 0.0420450
[Epoch 79; Iter   186/  823] train: loss: 0.0198254
[Epoch 79; Iter   216/  823] train: loss: 0.0265361
[Epoch 79; Iter   246/  823] train: loss: 0.0068218
[Epoch 79; Iter   276/  823] train: loss: 0.0036956
[Epoch 79; Iter   306/  823] train: loss: 0.0014491
[Epoch 79; Iter   336/  823] train: loss: 0.1473038
[Epoch 79; Iter   366/  823] train: loss: 0.0017022
[Epoch 79; Iter   396/  823] train: loss: 0.0616335
[Epoch 79; Iter   426/  823] train: loss: 0.0015895
[Epoch 79; Iter   456/  823] train: loss: 0.0146698
[Epoch 73; Iter   660/  960] train: loss: 0.0959032
[Epoch 73; Iter   690/  960] train: loss: 0.0032160
[Epoch 73; Iter   720/  960] train: loss: 0.0122079
[Epoch 73; Iter   750/  960] train: loss: 0.0029199
[Epoch 73; Iter   780/  960] train: loss: 0.0169149
[Epoch 73; Iter   810/  960] train: loss: 0.0044527
[Epoch 73; Iter   840/  960] train: loss: 0.0038992
[Epoch 73; Iter   870/  960] train: loss: 0.0246761
[Epoch 73; Iter   900/  960] train: loss: 0.0140403
[Epoch 73; Iter   930/  960] train: loss: 0.1730853
[Epoch 73; Iter   960/  960] train: loss: 0.0084650
[Epoch 73] ogbg-molhiv: 0.722370 val loss: 0.232427
[Epoch 73] ogbg-molhiv: 0.753815 test loss: 0.177878
[Epoch 74; Iter    30/  960] train: loss: 0.0434929
[Epoch 74; Iter    60/  960] train: loss: 0.0138249
[Epoch 74; Iter    90/  960] train: loss: 0.0016126
[Epoch 74; Iter   120/  960] train: loss: 0.1645945
[Epoch 74; Iter   150/  960] train: loss: 0.0122239
[Epoch 74; Iter   180/  960] train: loss: 0.0017843
[Epoch 74; Iter   210/  960] train: loss: 0.0016909
[Epoch 74; Iter   240/  960] train: loss: 0.0044966
[Epoch 74; Iter   270/  960] train: loss: 0.0078787
[Epoch 74; Iter   300/  960] train: loss: 0.0113669
[Epoch 74; Iter   330/  960] train: loss: 0.0143841
[Epoch 74; Iter   360/  960] train: loss: 0.0034380
[Epoch 74; Iter   390/  960] train: loss: 0.0024803
[Epoch 74; Iter   420/  960] train: loss: 0.0042021
[Epoch 74; Iter   450/  960] train: loss: 0.0039653
[Epoch 74; Iter   480/  960] train: loss: 0.0052767
[Epoch 74; Iter   510/  960] train: loss: 0.0549691
[Epoch 74; Iter   540/  960] train: loss: 0.0062212
[Epoch 74; Iter   570/  960] train: loss: 0.0342165
[Epoch 74; Iter   600/  960] train: loss: 0.0680309
[Epoch 74; Iter   630/  960] train: loss: 0.0089494
[Epoch 74; Iter   660/  960] train: loss: 0.0162594
[Epoch 74; Iter   690/  960] train: loss: 0.0518443
[Epoch 74; Iter   720/  960] train: loss: 0.1113324
[Epoch 74; Iter   750/  960] train: loss: 0.0130059
[Epoch 74; Iter   780/  960] train: loss: 0.0985486
[Epoch 74; Iter   810/  960] train: loss: 0.0160540
[Epoch 74; Iter   840/  960] train: loss: 0.0079783
[Epoch 74; Iter   870/  960] train: loss: 0.0331775
[Epoch 74; Iter   900/  960] train: loss: 0.0177502
[Epoch 74; Iter   930/  960] train: loss: 0.0012208
[Epoch 74; Iter   960/  960] train: loss: 0.0011974
[Epoch 74] ogbg-molhiv: 0.721003 val loss: 0.275667
[Epoch 74] ogbg-molhiv: 0.764249 test loss: 0.232598
[Epoch 75; Iter    30/  960] train: loss: 0.0202047
[Epoch 75; Iter    60/  960] train: loss: 0.1197075
[Epoch 75; Iter    90/  960] train: loss: 0.0038204
[Epoch 75; Iter   120/  960] train: loss: 0.0686543
[Epoch 75; Iter   150/  960] train: loss: 0.0045398
[Epoch 75; Iter   180/  960] train: loss: 0.0767382
[Epoch 75; Iter   210/  960] train: loss: 0.0038717
[Epoch 75; Iter   240/  960] train: loss: 0.0886936
[Epoch 75; Iter   270/  960] train: loss: 0.0564076
[Epoch 75; Iter   300/  960] train: loss: 0.0922453
[Epoch 75; Iter   330/  960] train: loss: 0.0140521
[Epoch 75; Iter   360/  960] train: loss: 0.0732734
[Epoch 75; Iter   390/  960] train: loss: 0.0043452
[Epoch 75; Iter   420/  960] train: loss: 0.0293175
[Epoch 75; Iter   450/  960] train: loss: 0.0019920
[Epoch 75; Iter   480/  960] train: loss: 0.0726286
[Epoch 75; Iter   510/  960] train: loss: 0.0022575
[Epoch 75; Iter   540/  960] train: loss: 0.0159234
[Epoch 75; Iter   570/  960] train: loss: 0.0111625
[Epoch 75; Iter   600/  960] train: loss: 0.0544334
[Epoch 75; Iter   630/  960] train: loss: 0.1085846
[Epoch 75; Iter   660/  960] train: loss: 0.0535694
[Epoch 75; Iter   690/  960] train: loss: 0.0015164
[Epoch 75; Iter   720/  960] train: loss: 0.0026114
[Epoch 75; Iter   750/  960] train: loss: 0.0316570
[Epoch 75; Iter   780/  960] train: loss: 0.0010490
[Epoch 75; Iter   810/  960] train: loss: 0.0049971
[Epoch 75; Iter   840/  960] train: loss: 0.0327103
[Epoch 75; Iter   870/  960] train: loss: 0.2287019
[Epoch 75; Iter   900/  960] train: loss: 0.0109277
[Epoch 75; Iter   930/  960] train: loss: 0.0046266
[Epoch 75; Iter   960/  960] train: loss: 0.1772483
[Epoch 75] ogbg-molhiv: 0.721512 val loss: 0.491038
[Epoch 75] ogbg-molhiv: 0.778543 test loss: 0.376290
[Epoch 76; Iter    30/  960] train: loss: 0.0029805
[Epoch 76; Iter    60/  960] train: loss: 0.0888563
[Epoch 76; Iter    90/  960] train: loss: 0.0109505
[Epoch 76; Iter   120/  960] train: loss: 0.0129862
[Epoch 76; Iter   150/  960] train: loss: 0.0142689
[Epoch 76; Iter   180/  960] train: loss: 0.0105434
[Epoch 76; Iter   210/  960] train: loss: 0.0202942
[Epoch 76; Iter   240/  960] train: loss: 0.0023599
[Epoch 76; Iter   270/  960] train: loss: 0.1340985
[Epoch 76; Iter   300/  960] train: loss: 0.0629219
[Epoch 76; Iter   330/  960] train: loss: 0.0204726
[Epoch 76; Iter   360/  960] train: loss: 0.0025965
[Epoch 76; Iter   390/  960] train: loss: 0.0070839
[Epoch 76; Iter   420/  960] train: loss: 0.0505058
[Epoch 76; Iter   450/  960] train: loss: 0.0056560
[Epoch 76; Iter   480/  960] train: loss: 0.0111020
[Epoch 76; Iter   510/  960] train: loss: 0.0169017
[Epoch 76; Iter   540/  960] train: loss: 0.0208398
[Epoch 76; Iter   570/  960] train: loss: 0.0142505
[Epoch 76; Iter   600/  960] train: loss: 0.0022745
[Epoch 76; Iter   630/  960] train: loss: 0.0342009
[Epoch 76; Iter   660/  960] train: loss: 0.0059087
[Epoch 76; Iter   690/  960] train: loss: 0.0446915
[Epoch 76; Iter   720/  960] train: loss: 0.1054675
[Epoch 76; Iter   750/  960] train: loss: 0.0637005
[Epoch 76; Iter   780/  960] train: loss: 0.0034370
[Epoch 76; Iter   810/  960] train: loss: 0.0090915
[Epoch 76; Iter   840/  960] train: loss: 0.0025951
[Epoch 76; Iter   870/  960] train: loss: 0.0034884
[Epoch 76; Iter   900/  960] train: loss: 0.1111348
[Epoch 76; Iter   930/  960] train: loss: 0.0098238
[Epoch 76; Iter   960/  960] train: loss: 0.0285110
[Epoch 76] ogbg-molhiv: 0.725925 val loss: 0.302569
[Epoch 76] ogbg-molhiv: 0.768338 test loss: 0.258285
[Epoch 77; Iter    30/  960] train: loss: 0.0091368
[Epoch 77; Iter    60/  960] train: loss: 0.0027922
[Epoch 77; Iter    90/  960] train: loss: 0.0022238
[Epoch 77; Iter   120/  960] train: loss: 0.0017856
[Epoch 77; Iter   150/  960] train: loss: 0.0053818
[Epoch 77; Iter   180/  960] train: loss: 0.0057457
[Epoch 77; Iter   210/  960] train: loss: 0.0146065
[Epoch 77; Iter   240/  960] train: loss: 0.0049708
[Epoch 77; Iter   270/  960] train: loss: 0.0242876
[Epoch 77; Iter   300/  960] train: loss: 0.0655815
[Epoch 77; Iter   330/  960] train: loss: 0.0059673
[Epoch 77; Iter   360/  960] train: loss: 0.0179277
[Epoch 77; Iter   390/  960] train: loss: 0.0260445
[Epoch 77; Iter   420/  960] train: loss: 0.0230289
[Epoch 77; Iter   450/  960] train: loss: 0.0359676
[Epoch 77; Iter   480/  960] train: loss: 0.0175666
[Epoch 77; Iter   510/  960] train: loss: 0.0098696
[Epoch 77; Iter   540/  960] train: loss: 0.0101750
[Epoch 77; Iter   570/  960] train: loss: 0.0070236
[Epoch 77; Iter   600/  960] train: loss: 0.0345101
[Epoch 77; Iter   630/  960] train: loss: 0.0857005
[Epoch 77; Iter   660/  960] train: loss: 0.0563886
[Epoch 77; Iter   690/  960] train: loss: 0.0064937
[Epoch 77; Iter   720/  960] train: loss: 0.0768913
[Epoch 77; Iter   750/  960] train: loss: 0.0279524
[Epoch 77; Iter   780/  960] train: loss: 0.0087332
[Epoch 77; Iter   810/  960] train: loss: 0.0560390
[Epoch 77; Iter   840/  960] train: loss: 0.0053012
[Epoch 77; Iter   870/  960] train: loss: 0.0600977
[Epoch 77; Iter   900/  960] train: loss: 0.0378126
[Epoch 77; Iter   930/  960] train: loss: 0.0800140
[Epoch 77; Iter   960/  960] train: loss: 0.0439871
[Epoch 77] ogbg-molhiv: 0.721724 val loss: 0.531467
[Epoch 77] ogbg-molhiv: 0.770857 test loss: 0.517304
[Epoch 78; Iter    30/  960] train: loss: 0.0021636
[Epoch 78; Iter    60/  960] train: loss: 0.0209624
[Epoch 78; Iter    90/  960] train: loss: 0.0236909
[Epoch 78; Iter   120/  960] train: loss: 0.0394362
[Epoch 78; Iter   150/  960] train: loss: 0.0290602
[Epoch 78; Iter   180/  960] train: loss: 0.0361002
[Epoch 78; Iter   210/  960] train: loss: 0.0202051
[Epoch 78; Iter   240/  960] train: loss: 0.0029898
[Epoch 73; Iter   660/  960] train: loss: 0.1439682
[Epoch 73; Iter   690/  960] train: loss: 0.0266364
[Epoch 73; Iter   720/  960] train: loss: 0.0049573
[Epoch 73; Iter   750/  960] train: loss: 0.0256622
[Epoch 73; Iter   780/  960] train: loss: 0.0332036
[Epoch 73; Iter   810/  960] train: loss: 0.0063629
[Epoch 73; Iter   840/  960] train: loss: 0.0258419
[Epoch 73; Iter   870/  960] train: loss: 0.2023845
[Epoch 73; Iter   900/  960] train: loss: 0.0231916
[Epoch 73; Iter   930/  960] train: loss: 0.0424659
[Epoch 73; Iter   960/  960] train: loss: 0.0135208
[Epoch 73] ogbg-molhiv: 0.760857 val loss: 0.836687
[Epoch 73] ogbg-molhiv: 0.745974 test loss: 0.317445
[Epoch 74; Iter    30/  960] train: loss: 0.0210022
[Epoch 74; Iter    60/  960] train: loss: 0.0095513
[Epoch 74; Iter    90/  960] train: loss: 0.0358665
[Epoch 74; Iter   120/  960] train: loss: 0.0129428
[Epoch 74; Iter   150/  960] train: loss: 0.0091394
[Epoch 74; Iter   180/  960] train: loss: 0.0139501
[Epoch 74; Iter   210/  960] train: loss: 0.0539792
[Epoch 74; Iter   240/  960] train: loss: 0.0131065
[Epoch 74; Iter   270/  960] train: loss: 0.0021065
[Epoch 74; Iter   300/  960] train: loss: 0.0380501
[Epoch 74; Iter   330/  960] train: loss: 0.0071047
[Epoch 74; Iter   360/  960] train: loss: 0.0960141
[Epoch 74; Iter   390/  960] train: loss: 0.0100019
[Epoch 74; Iter   420/  960] train: loss: 0.0471051
[Epoch 74; Iter   450/  960] train: loss: 0.0045311
[Epoch 74; Iter   480/  960] train: loss: 0.0022713
[Epoch 74; Iter   510/  960] train: loss: 0.0053431
[Epoch 74; Iter   540/  960] train: loss: 0.0027746
[Epoch 74; Iter   570/  960] train: loss: 0.0158378
[Epoch 74; Iter   600/  960] train: loss: 0.0263629
[Epoch 74; Iter   630/  960] train: loss: 0.0216426
[Epoch 74; Iter   660/  960] train: loss: 0.1872207
[Epoch 74; Iter   690/  960] train: loss: 0.0137532
[Epoch 74; Iter   720/  960] train: loss: 0.0169305
[Epoch 74; Iter   750/  960] train: loss: 0.0066034
[Epoch 74; Iter   780/  960] train: loss: 0.0011204
[Epoch 74; Iter   810/  960] train: loss: 0.0120471
[Epoch 74; Iter   840/  960] train: loss: 0.0687497
[Epoch 74; Iter   870/  960] train: loss: 0.0244421
[Epoch 74; Iter   900/  960] train: loss: 0.0151309
[Epoch 74; Iter   930/  960] train: loss: 0.0042048
[Epoch 74; Iter   960/  960] train: loss: 0.0661585
[Epoch 74] ogbg-molhiv: 0.752227 val loss: 0.657041
[Epoch 74] ogbg-molhiv: 0.756206 test loss: 0.342226
[Epoch 75; Iter    30/  960] train: loss: 0.0432502
[Epoch 75; Iter    60/  960] train: loss: 0.0058843
[Epoch 75; Iter    90/  960] train: loss: 0.0147417
[Epoch 75; Iter   120/  960] train: loss: 0.0078934
[Epoch 75; Iter   150/  960] train: loss: 0.0130094
[Epoch 75; Iter   180/  960] train: loss: 0.0675633
[Epoch 75; Iter   210/  960] train: loss: 0.1042880
[Epoch 75; Iter   240/  960] train: loss: 0.0055214
[Epoch 75; Iter   270/  960] train: loss: 0.0203945
[Epoch 75; Iter   300/  960] train: loss: 0.0037825
[Epoch 75; Iter   330/  960] train: loss: 0.0021600
[Epoch 75; Iter   360/  960] train: loss: 0.0287630
[Epoch 75; Iter   390/  960] train: loss: 0.0070857
[Epoch 75; Iter   420/  960] train: loss: 0.0647605
[Epoch 75; Iter   450/  960] train: loss: 0.0480737
[Epoch 75; Iter   480/  960] train: loss: 0.0605644
[Epoch 75; Iter   510/  960] train: loss: 0.1642055
[Epoch 75; Iter   540/  960] train: loss: 0.0446402
[Epoch 75; Iter   570/  960] train: loss: 0.0038904
[Epoch 75; Iter   600/  960] train: loss: 0.0313424
[Epoch 75; Iter   630/  960] train: loss: 0.0440246
[Epoch 75; Iter   660/  960] train: loss: 0.0016870
[Epoch 75; Iter   690/  960] train: loss: 0.0045182
[Epoch 75; Iter   720/  960] train: loss: 0.0058437
[Epoch 75; Iter   750/  960] train: loss: 0.0115857
[Epoch 75; Iter   780/  960] train: loss: 0.0050024
[Epoch 75; Iter   810/  960] train: loss: 0.1191570
[Epoch 75; Iter   840/  960] train: loss: 0.0078850
[Epoch 75; Iter   870/  960] train: loss: 0.0023895
[Epoch 75; Iter   900/  960] train: loss: 0.0092887
[Epoch 75; Iter   930/  960] train: loss: 0.0436685
[Epoch 75; Iter   960/  960] train: loss: 0.0149592
[Epoch 75] ogbg-molhiv: 0.762170 val loss: 0.428287
[Epoch 75] ogbg-molhiv: 0.756518 test loss: 0.266941
[Epoch 76; Iter    30/  960] train: loss: 0.0785509
[Epoch 76; Iter    60/  960] train: loss: 0.0030445
[Epoch 76; Iter    90/  960] train: loss: 0.0624459
[Epoch 76; Iter   120/  960] train: loss: 0.0347981
[Epoch 76; Iter   150/  960] train: loss: 0.0008952
[Epoch 76; Iter   180/  960] train: loss: 0.0103018
[Epoch 76; Iter   210/  960] train: loss: 0.0427144
[Epoch 76; Iter   240/  960] train: loss: 0.0036483
[Epoch 76; Iter   270/  960] train: loss: 0.1242979
[Epoch 76; Iter   300/  960] train: loss: 0.0206641
[Epoch 76; Iter   330/  960] train: loss: 0.1115518
[Epoch 76; Iter   360/  960] train: loss: 0.0089921
[Epoch 76; Iter   390/  960] train: loss: 0.0061732
[Epoch 76; Iter   420/  960] train: loss: 0.0465820
[Epoch 76; Iter   450/  960] train: loss: 0.0583952
[Epoch 76; Iter   480/  960] train: loss: 0.0760993
[Epoch 76; Iter   510/  960] train: loss: 0.0545228
[Epoch 76; Iter   540/  960] train: loss: 0.0070085
[Epoch 76; Iter   570/  960] train: loss: 0.0435647
[Epoch 76; Iter   600/  960] train: loss: 0.0414071
[Epoch 76; Iter   630/  960] train: loss: 0.0938369
[Epoch 76; Iter   660/  960] train: loss: 0.0010293
[Epoch 76; Iter   690/  960] train: loss: 0.0575484
[Epoch 76; Iter   720/  960] train: loss: 0.1477900
[Epoch 76; Iter   750/  960] train: loss: 0.0368375
[Epoch 76; Iter   780/  960] train: loss: 0.0022164
[Epoch 76; Iter   810/  960] train: loss: 0.0165179
[Epoch 76; Iter   840/  960] train: loss: 0.0167388
[Epoch 76; Iter   870/  960] train: loss: 0.0070031
[Epoch 76; Iter   900/  960] train: loss: 0.0056480
[Epoch 76; Iter   930/  960] train: loss: 0.0297921
[Epoch 76; Iter   960/  960] train: loss: 0.1980189
[Epoch 76] ogbg-molhiv: 0.752925 val loss: 0.978291
[Epoch 76] ogbg-molhiv: 0.749902 test loss: 0.273129
[Epoch 77; Iter    30/  960] train: loss: 0.2004365
[Epoch 77; Iter    60/  960] train: loss: 0.0296359
[Epoch 77; Iter    90/  960] train: loss: 0.0051880
[Epoch 77; Iter   120/  960] train: loss: 0.0951627
[Epoch 77; Iter   150/  960] train: loss: 0.0700141
[Epoch 77; Iter   180/  960] train: loss: 0.0334938
[Epoch 77; Iter   210/  960] train: loss: 0.0082411
[Epoch 77; Iter   240/  960] train: loss: 0.0341378
[Epoch 77; Iter   270/  960] train: loss: 0.0232398
[Epoch 77; Iter   300/  960] train: loss: 0.0256252
[Epoch 77; Iter   330/  960] train: loss: 0.0119428
[Epoch 77; Iter   360/  960] train: loss: 0.0087578
[Epoch 77; Iter   390/  960] train: loss: 0.0074187
[Epoch 77; Iter   420/  960] train: loss: 0.0319968
[Epoch 77; Iter   450/  960] train: loss: 0.0227186
[Epoch 77; Iter   480/  960] train: loss: 0.0675025
[Epoch 77; Iter   510/  960] train: loss: 0.0291494
[Epoch 77; Iter   540/  960] train: loss: 0.0067760
[Epoch 77; Iter   570/  960] train: loss: 0.0315272
[Epoch 77; Iter   600/  960] train: loss: 0.0157530
[Epoch 77; Iter   630/  960] train: loss: 0.0210215
[Epoch 77; Iter   660/  960] train: loss: 0.0393643
[Epoch 77; Iter   690/  960] train: loss: 0.0114289
[Epoch 77; Iter   720/  960] train: loss: 0.0033619
[Epoch 77; Iter   750/  960] train: loss: 0.1559445
[Epoch 77; Iter   780/  960] train: loss: 0.0342266
[Epoch 77; Iter   810/  960] train: loss: 0.0127649
[Epoch 77; Iter   840/  960] train: loss: 0.0306420
[Epoch 77; Iter   870/  960] train: loss: 0.0046841
[Epoch 77; Iter   900/  960] train: loss: 0.0189660
[Epoch 77; Iter   930/  960] train: loss: 0.0056436
[Epoch 77; Iter   960/  960] train: loss: 0.0032683
[Epoch 77] ogbg-molhiv: 0.749435 val loss: 0.723431
[Epoch 77] ogbg-molhiv: 0.749891 test loss: 0.285331
[Epoch 78; Iter    30/  960] train: loss: 0.0207273
[Epoch 78; Iter    60/  960] train: loss: 0.1109542
[Epoch 78; Iter    90/  960] train: loss: 0.0011671
[Epoch 78; Iter   120/  960] train: loss: 0.0068046
[Epoch 78; Iter   150/  960] train: loss: 0.0160221
[Epoch 78; Iter   180/  960] train: loss: 0.0117160
[Epoch 78; Iter   210/  960] train: loss: 0.0061784
[Epoch 78; Iter   240/  960] train: loss: 0.0015208
[Epoch 73; Iter   660/  960] train: loss: 0.0312556
[Epoch 73; Iter   690/  960] train: loss: 0.0110317
[Epoch 73; Iter   720/  960] train: loss: 0.0135995
[Epoch 73; Iter   750/  960] train: loss: 0.1896106
[Epoch 73; Iter   780/  960] train: loss: 0.0060320
[Epoch 73; Iter   810/  960] train: loss: 0.0155109
[Epoch 73; Iter   840/  960] train: loss: 0.0780991
[Epoch 73; Iter   870/  960] train: loss: 0.0335803
[Epoch 73; Iter   900/  960] train: loss: 0.0261910
[Epoch 73; Iter   930/  960] train: loss: 0.0256106
[Epoch 73; Iter   960/  960] train: loss: 0.0093751
[Epoch 73] ogbg-molhiv: 0.717287 val loss: 1.043834
[Epoch 73] ogbg-molhiv: 0.752991 test loss: 0.628719
[Epoch 74; Iter    30/  960] train: loss: 0.2062761
[Epoch 74; Iter    60/  960] train: loss: 0.0241994
[Epoch 74; Iter    90/  960] train: loss: 0.0019375
[Epoch 74; Iter   120/  960] train: loss: 0.0365010
[Epoch 74; Iter   150/  960] train: loss: 0.0026758
[Epoch 74; Iter   180/  960] train: loss: 0.0044845
[Epoch 74; Iter   210/  960] train: loss: 0.0044579
[Epoch 74; Iter   240/  960] train: loss: 0.0085822
[Epoch 74; Iter   270/  960] train: loss: 0.0402233
[Epoch 74; Iter   300/  960] train: loss: 0.0292847
[Epoch 74; Iter   330/  960] train: loss: 0.0077510
[Epoch 74; Iter   360/  960] train: loss: 0.1333046
[Epoch 74; Iter   390/  960] train: loss: 0.0117174
[Epoch 74; Iter   420/  960] train: loss: 0.0848612
[Epoch 74; Iter   450/  960] train: loss: 0.1191190
[Epoch 74; Iter   480/  960] train: loss: 0.0077262
[Epoch 74; Iter   510/  960] train: loss: 0.0185000
[Epoch 74; Iter   540/  960] train: loss: 0.0026640
[Epoch 74; Iter   570/  960] train: loss: 0.0061370
[Epoch 74; Iter   600/  960] train: loss: 0.0194644
[Epoch 74; Iter   630/  960] train: loss: 0.0392851
[Epoch 74; Iter   660/  960] train: loss: 0.0136317
[Epoch 74; Iter   690/  960] train: loss: 0.0394044
[Epoch 74; Iter   720/  960] train: loss: 0.0234487
[Epoch 74; Iter   750/  960] train: loss: 0.0473763
[Epoch 74; Iter   780/  960] train: loss: 0.0373706
[Epoch 74; Iter   810/  960] train: loss: 0.0099264
[Epoch 74; Iter   840/  960] train: loss: 0.0474461
[Epoch 74; Iter   870/  960] train: loss: 0.0065028
[Epoch 74; Iter   900/  960] train: loss: 0.0094028
[Epoch 74; Iter   930/  960] train: loss: 0.0193825
[Epoch 74; Iter   960/  960] train: loss: 0.0013282
[Epoch 74] ogbg-molhiv: 0.714882 val loss: 0.322132
[Epoch 74] ogbg-molhiv: 0.742023 test loss: 0.243557
[Epoch 75; Iter    30/  960] train: loss: 0.0125095
[Epoch 75; Iter    60/  960] train: loss: 0.0577263
[Epoch 75; Iter    90/  960] train: loss: 0.0659889
[Epoch 75; Iter   120/  960] train: loss: 0.1045725
[Epoch 75; Iter   150/  960] train: loss: 0.0369816
[Epoch 75; Iter   180/  960] train: loss: 0.0167486
[Epoch 75; Iter   210/  960] train: loss: 0.1317091
[Epoch 75; Iter   240/  960] train: loss: 0.1646451
[Epoch 75; Iter   270/  960] train: loss: 0.0168684
[Epoch 75; Iter   300/  960] train: loss: 0.0266828
[Epoch 75; Iter   330/  960] train: loss: 0.0181162
[Epoch 75; Iter   360/  960] train: loss: 0.0608623
[Epoch 75; Iter   390/  960] train: loss: 0.0747395
[Epoch 75; Iter   420/  960] train: loss: 0.0171603
[Epoch 75; Iter   450/  960] train: loss: 0.0053495
[Epoch 75; Iter   480/  960] train: loss: 0.0778678
[Epoch 75; Iter   510/  960] train: loss: 0.0050518
[Epoch 75; Iter   540/  960] train: loss: 0.0124790
[Epoch 75; Iter   570/  960] train: loss: 0.0337609
[Epoch 75; Iter   600/  960] train: loss: 0.0373928
[Epoch 75; Iter   630/  960] train: loss: 0.0208417
[Epoch 75; Iter   660/  960] train: loss: 0.0076802
[Epoch 75; Iter   690/  960] train: loss: 0.0765160
[Epoch 75; Iter   720/  960] train: loss: 0.0107435
[Epoch 75; Iter   750/  960] train: loss: 0.0075990
[Epoch 75; Iter   780/  960] train: loss: 0.0225075
[Epoch 75; Iter   810/  960] train: loss: 0.1012973
[Epoch 75; Iter   840/  960] train: loss: 0.1850170
[Epoch 75; Iter   870/  960] train: loss: 0.0058415
[Epoch 75; Iter   900/  960] train: loss: 0.0032151
[Epoch 75; Iter   930/  960] train: loss: 0.0186522
[Epoch 75; Iter   960/  960] train: loss: 0.0061805
[Epoch 75] ogbg-molhiv: 0.708947 val loss: 0.669803
[Epoch 75] ogbg-molhiv: 0.745571 test loss: 0.408046
[Epoch 76; Iter    30/  960] train: loss: 0.0148327
[Epoch 76; Iter    60/  960] train: loss: 0.1957550
[Epoch 76; Iter    90/  960] train: loss: 0.0013861
[Epoch 76; Iter   120/  960] train: loss: 0.0052447
[Epoch 76; Iter   150/  960] train: loss: 0.0053733
[Epoch 76; Iter   180/  960] train: loss: 0.1405922
[Epoch 76; Iter   210/  960] train: loss: 0.0113625
[Epoch 76; Iter   240/  960] train: loss: 0.0259960
[Epoch 76; Iter   270/  960] train: loss: 0.0022052
[Epoch 76; Iter   300/  960] train: loss: 0.0806788
[Epoch 76; Iter   330/  960] train: loss: 0.0044975
[Epoch 76; Iter   360/  960] train: loss: 0.0051110
[Epoch 76; Iter   390/  960] train: loss: 0.0042534
[Epoch 76; Iter   420/  960] train: loss: 0.0235522
[Epoch 76; Iter   450/  960] train: loss: 0.0172956
[Epoch 76; Iter   480/  960] train: loss: 0.0022073
[Epoch 76; Iter   510/  960] train: loss: 0.0212246
[Epoch 76; Iter   540/  960] train: loss: 0.0964537
[Epoch 76; Iter   570/  960] train: loss: 0.0023769
[Epoch 76; Iter   600/  960] train: loss: 0.0215462
[Epoch 76; Iter   630/  960] train: loss: 0.0165949
[Epoch 76; Iter   660/  960] train: loss: 0.0639939
[Epoch 76; Iter   690/  960] train: loss: 0.0264972
[Epoch 76; Iter   720/  960] train: loss: 0.0415400
[Epoch 76; Iter   750/  960] train: loss: 0.0548688
[Epoch 76; Iter   780/  960] train: loss: 0.0083823
[Epoch 76; Iter   810/  960] train: loss: 0.0050864
[Epoch 76; Iter   840/  960] train: loss: 0.0109666
[Epoch 76; Iter   870/  960] train: loss: 0.0227733
[Epoch 76; Iter   900/  960] train: loss: 0.0110575
[Epoch 76; Iter   930/  960] train: loss: 0.0113758
[Epoch 76; Iter   960/  960] train: loss: 0.0194215
[Epoch 76] ogbg-molhiv: 0.715648 val loss: 0.920045
[Epoch 76] ogbg-molhiv: 0.745015 test loss: 0.577043
[Epoch 77; Iter    30/  960] train: loss: 0.0060865
[Epoch 77; Iter    60/  960] train: loss: 0.0025429
[Epoch 77; Iter    90/  960] train: loss: 0.0101898
[Epoch 77; Iter   120/  960] train: loss: 0.0155075
[Epoch 77; Iter   150/  960] train: loss: 0.0059970
[Epoch 77; Iter   180/  960] train: loss: 0.0026955
[Epoch 77; Iter   210/  960] train: loss: 0.0148328
[Epoch 77; Iter   240/  960] train: loss: 0.0123991
[Epoch 77; Iter   270/  960] train: loss: 0.0569472
[Epoch 77; Iter   300/  960] train: loss: 0.0077896
[Epoch 77; Iter   330/  960] train: loss: 0.0353245
[Epoch 77; Iter   360/  960] train: loss: 0.0025128
[Epoch 77; Iter   390/  960] train: loss: 0.0460613
[Epoch 77; Iter   420/  960] train: loss: 0.0071439
[Epoch 77; Iter   450/  960] train: loss: 0.0872667
[Epoch 77; Iter   480/  960] train: loss: 0.0113834
[Epoch 77; Iter   510/  960] train: loss: 0.0660330
[Epoch 77; Iter   540/  960] train: loss: 0.0636697
[Epoch 77; Iter   570/  960] train: loss: 0.0912143
[Epoch 77; Iter   600/  960] train: loss: 0.0140824
[Epoch 77; Iter   630/  960] train: loss: 0.0099535
[Epoch 77; Iter   660/  960] train: loss: 0.0861034
[Epoch 77; Iter   690/  960] train: loss: 0.0510864
[Epoch 77; Iter   720/  960] train: loss: 0.0211617
[Epoch 77; Iter   750/  960] train: loss: 0.0023983
[Epoch 77; Iter   780/  960] train: loss: 0.0209256
[Epoch 77; Iter   810/  960] train: loss: 0.0240169
[Epoch 77; Iter   840/  960] train: loss: 0.2061252
[Epoch 77; Iter   870/  960] train: loss: 0.0075997
[Epoch 77; Iter   900/  960] train: loss: 0.1168280
[Epoch 77; Iter   930/  960] train: loss: 0.0185577
[Epoch 77; Iter   960/  960] train: loss: 0.0474150
[Epoch 77] ogbg-molhiv: 0.713404 val loss: 0.955398
[Epoch 77] ogbg-molhiv: 0.743807 test loss: 0.738923
[Epoch 78; Iter    30/  960] train: loss: 0.0986142
[Epoch 78; Iter    60/  960] train: loss: 0.0069124
[Epoch 78; Iter    90/  960] train: loss: 0.0234014
[Epoch 78; Iter   120/  960] train: loss: 0.0353790
[Epoch 78; Iter   150/  960] train: loss: 0.0145077
[Epoch 78; Iter   180/  960] train: loss: 0.0168983
[Epoch 78; Iter   210/  960] train: loss: 0.0096765
[Epoch 78; Iter   240/  960] train: loss: 0.0063040
[Epoch 73; Iter   216/ 1097] train: loss: 0.0107368
[Epoch 73; Iter   246/ 1097] train: loss: 0.0450344
[Epoch 73; Iter   276/ 1097] train: loss: 0.0281341
[Epoch 73; Iter   306/ 1097] train: loss: 0.0142888
[Epoch 73; Iter   336/ 1097] train: loss: 0.1134683
[Epoch 73; Iter   366/ 1097] train: loss: 0.0325283
[Epoch 73; Iter   396/ 1097] train: loss: 0.1310549
[Epoch 73; Iter   426/ 1097] train: loss: 0.0111231
[Epoch 73; Iter   456/ 1097] train: loss: 0.1079957
[Epoch 73; Iter   486/ 1097] train: loss: 0.1780855
[Epoch 73; Iter   516/ 1097] train: loss: 0.0115143
[Epoch 73; Iter   546/ 1097] train: loss: 0.0218361
[Epoch 73; Iter   576/ 1097] train: loss: 0.0736478
[Epoch 73; Iter   606/ 1097] train: loss: 0.0021230
[Epoch 73; Iter   636/ 1097] train: loss: 0.0090212
[Epoch 73; Iter   666/ 1097] train: loss: 0.0080072
[Epoch 73; Iter   696/ 1097] train: loss: 0.0398747
[Epoch 73; Iter   726/ 1097] train: loss: 0.0163736
[Epoch 73; Iter   756/ 1097] train: loss: 0.0366987
[Epoch 73; Iter   786/ 1097] train: loss: 0.0197300
[Epoch 73; Iter   816/ 1097] train: loss: 0.0102695
[Epoch 73; Iter   846/ 1097] train: loss: 0.0037430
[Epoch 73; Iter   876/ 1097] train: loss: 0.0054535
[Epoch 73; Iter   906/ 1097] train: loss: 0.1860285
[Epoch 73; Iter   936/ 1097] train: loss: 0.0053347
[Epoch 73; Iter   966/ 1097] train: loss: 0.0200181
[Epoch 73; Iter   996/ 1097] train: loss: 0.0426156
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0676369
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0093259
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0073249
[Epoch 73] ogbg-molhiv: 0.759317 val loss: 0.113415
[Epoch 73] ogbg-molhiv: 0.734502 test loss: 0.221225
[Epoch 74; Iter    19/ 1097] train: loss: 0.0158897
[Epoch 74; Iter    49/ 1097] train: loss: 0.0222609
[Epoch 74; Iter    79/ 1097] train: loss: 0.0455864
[Epoch 74; Iter   109/ 1097] train: loss: 0.0526697
[Epoch 74; Iter   139/ 1097] train: loss: 0.0103557
[Epoch 74; Iter   169/ 1097] train: loss: 0.2231314
[Epoch 74; Iter   199/ 1097] train: loss: 0.0036573
[Epoch 74; Iter   229/ 1097] train: loss: 0.0502851
[Epoch 74; Iter   259/ 1097] train: loss: 0.0881675
[Epoch 74; Iter   289/ 1097] train: loss: 0.0056105
[Epoch 74; Iter   319/ 1097] train: loss: 0.0057373
[Epoch 74; Iter   349/ 1097] train: loss: 0.0119437
[Epoch 74; Iter   379/ 1097] train: loss: 0.0063319
[Epoch 74; Iter   409/ 1097] train: loss: 0.0428670
[Epoch 74; Iter   439/ 1097] train: loss: 0.0343412
[Epoch 74; Iter   469/ 1097] train: loss: 0.0043398
[Epoch 74; Iter   499/ 1097] train: loss: 0.0799463
[Epoch 74; Iter   529/ 1097] train: loss: 0.0346106
[Epoch 74; Iter   559/ 1097] train: loss: 0.0134991
[Epoch 74; Iter   589/ 1097] train: loss: 0.0642238
[Epoch 74; Iter   619/ 1097] train: loss: 0.0402577
[Epoch 74; Iter   649/ 1097] train: loss: 0.0022889
[Epoch 74; Iter   679/ 1097] train: loss: 0.0725115
[Epoch 74; Iter   709/ 1097] train: loss: 0.0060775
[Epoch 74; Iter   739/ 1097] train: loss: 0.0847407
[Epoch 74; Iter   769/ 1097] train: loss: 0.0359190
[Epoch 74; Iter   799/ 1097] train: loss: 0.0739769
[Epoch 74; Iter   829/ 1097] train: loss: 0.0497005
[Epoch 74; Iter   859/ 1097] train: loss: 0.0029275
[Epoch 74; Iter   889/ 1097] train: loss: 0.0032876
[Epoch 74; Iter   919/ 1097] train: loss: 0.0078719
[Epoch 74; Iter   949/ 1097] train: loss: 0.0181308
[Epoch 74; Iter   979/ 1097] train: loss: 0.0411165
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0437414
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0273446
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0197424
[Epoch 74] ogbg-molhiv: 0.755496 val loss: 0.121473
[Epoch 74] ogbg-molhiv: 0.735406 test loss: 0.210072
[Epoch 75; Iter     2/ 1097] train: loss: 0.0018280
[Epoch 75; Iter    32/ 1097] train: loss: 0.0380780
[Epoch 75; Iter    62/ 1097] train: loss: 0.0394807
[Epoch 75; Iter    92/ 1097] train: loss: 0.1740109
[Epoch 75; Iter   122/ 1097] train: loss: 0.0037065
[Epoch 75; Iter   152/ 1097] train: loss: 0.0384433
[Epoch 75; Iter   182/ 1097] train: loss: 0.0179620
[Epoch 75; Iter   212/ 1097] train: loss: 0.0260020
[Epoch 75; Iter   242/ 1097] train: loss: 0.0028733
[Epoch 75; Iter   272/ 1097] train: loss: 0.0066403
[Epoch 75; Iter   302/ 1097] train: loss: 0.0448192
[Epoch 75; Iter   332/ 1097] train: loss: 0.0182033
[Epoch 75; Iter   362/ 1097] train: loss: 0.0320745
[Epoch 75; Iter   392/ 1097] train: loss: 0.1072518
[Epoch 75; Iter   422/ 1097] train: loss: 0.0368544
[Epoch 75; Iter   452/ 1097] train: loss: 0.0054359
[Epoch 75; Iter   482/ 1097] train: loss: 0.0417335
[Epoch 75; Iter   512/ 1097] train: loss: 0.0119732
[Epoch 75; Iter   542/ 1097] train: loss: 0.0582887
[Epoch 75; Iter   572/ 1097] train: loss: 0.0272569
[Epoch 75; Iter   602/ 1097] train: loss: 0.0691037
[Epoch 75; Iter   632/ 1097] train: loss: 0.0094835
[Epoch 75; Iter   662/ 1097] train: loss: 0.0326141
[Epoch 75; Iter   692/ 1097] train: loss: 0.0077544
[Epoch 75; Iter   722/ 1097] train: loss: 0.0291436
[Epoch 75; Iter   752/ 1097] train: loss: 0.0136202
[Epoch 75; Iter   782/ 1097] train: loss: 0.0225877
[Epoch 75; Iter   812/ 1097] train: loss: 0.0158057
[Epoch 75; Iter   842/ 1097] train: loss: 0.1613619
[Epoch 75; Iter   872/ 1097] train: loss: 0.1089544
[Epoch 75; Iter   902/ 1097] train: loss: 0.0331489
[Epoch 75; Iter   932/ 1097] train: loss: 0.0117881
[Epoch 75; Iter   962/ 1097] train: loss: 0.0192710
[Epoch 75; Iter   992/ 1097] train: loss: 0.0080428
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0059193
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0252659
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0339662
[Epoch 75] ogbg-molhiv: 0.736001 val loss: 0.287453
[Epoch 75] ogbg-molhiv: 0.729359 test loss: 0.897496
[Epoch 76; Iter    15/ 1097] train: loss: 0.0119350
[Epoch 76; Iter    45/ 1097] train: loss: 0.0342949
[Epoch 76; Iter    75/ 1097] train: loss: 0.0259016
[Epoch 76; Iter   105/ 1097] train: loss: 0.1167537
[Epoch 76; Iter   135/ 1097] train: loss: 0.2359958
[Epoch 76; Iter   165/ 1097] train: loss: 0.0494476
[Epoch 76; Iter   195/ 1097] train: loss: 0.0286695
[Epoch 76; Iter   225/ 1097] train: loss: 0.0311748
[Epoch 76; Iter   255/ 1097] train: loss: 0.0744197
[Epoch 76; Iter   285/ 1097] train: loss: 0.1020577
[Epoch 76; Iter   315/ 1097] train: loss: 0.0132908
[Epoch 76; Iter   345/ 1097] train: loss: 0.0163043
[Epoch 76; Iter   375/ 1097] train: loss: 0.0823150
[Epoch 76; Iter   405/ 1097] train: loss: 0.0422513
[Epoch 76; Iter   435/ 1097] train: loss: 0.0024299
[Epoch 76; Iter   465/ 1097] train: loss: 0.0736986
[Epoch 76; Iter   495/ 1097] train: loss: 0.0416860
[Epoch 76; Iter   525/ 1097] train: loss: 0.0209500
[Epoch 76; Iter   555/ 1097] train: loss: 0.0773902
[Epoch 76; Iter   585/ 1097] train: loss: 0.0764786
[Epoch 76; Iter   615/ 1097] train: loss: 0.0056422
[Epoch 76; Iter   645/ 1097] train: loss: 0.0320446
[Epoch 76; Iter   675/ 1097] train: loss: 0.0148070
[Epoch 76; Iter   705/ 1097] train: loss: 0.0044887
[Epoch 76; Iter   735/ 1097] train: loss: 0.0145778
[Epoch 76; Iter   765/ 1097] train: loss: 0.0456625
[Epoch 76; Iter   795/ 1097] train: loss: 0.0148623
[Epoch 76; Iter   825/ 1097] train: loss: 0.0638881
[Epoch 76; Iter   855/ 1097] train: loss: 0.0145392
[Epoch 76; Iter   885/ 1097] train: loss: 0.0084844
[Epoch 76; Iter   915/ 1097] train: loss: 0.0033386
[Epoch 76; Iter   945/ 1097] train: loss: 0.0048947
[Epoch 76; Iter   975/ 1097] train: loss: 0.0187701
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0480529
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0328813
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0252751
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0366106
[Epoch 76] ogbg-molhiv: 0.752107 val loss: 0.128955
[Epoch 76] ogbg-molhiv: 0.731826 test loss: 0.288447
[Epoch 77; Iter    28/ 1097] train: loss: 0.0700413
[Epoch 77; Iter    58/ 1097] train: loss: 0.0118706
[Epoch 77; Iter    88/ 1097] train: loss: 0.0495381
[Epoch 77; Iter   118/ 1097] train: loss: 0.0375116
[Epoch 77; Iter   148/ 1097] train: loss: 0.0136219
[Epoch 77; Iter   178/ 1097] train: loss: 0.0308940
[Epoch 77; Iter   208/ 1097] train: loss: 0.0046458
[Epoch 77; Iter   238/ 1097] train: loss: 0.0500431
[Epoch 77; Iter   268/ 1097] train: loss: 0.0413644
[Epoch 73; Iter   216/ 1097] train: loss: 0.0712881
[Epoch 73; Iter   246/ 1097] train: loss: 0.0380468
[Epoch 73; Iter   276/ 1097] train: loss: 0.0112692
[Epoch 73; Iter   306/ 1097] train: loss: 0.0972545
[Epoch 73; Iter   336/ 1097] train: loss: 0.0269347
[Epoch 73; Iter   366/ 1097] train: loss: 0.0102134
[Epoch 73; Iter   396/ 1097] train: loss: 0.0685345
[Epoch 73; Iter   426/ 1097] train: loss: 0.0446756
[Epoch 73; Iter   456/ 1097] train: loss: 0.0061253
[Epoch 73; Iter   486/ 1097] train: loss: 0.0624969
[Epoch 73; Iter   516/ 1097] train: loss: 0.0144403
[Epoch 73; Iter   546/ 1097] train: loss: 0.0040847
[Epoch 73; Iter   576/ 1097] train: loss: 0.0051878
[Epoch 73; Iter   606/ 1097] train: loss: 0.1305960
[Epoch 73; Iter   636/ 1097] train: loss: 0.0063157
[Epoch 73; Iter   666/ 1097] train: loss: 0.1424535
[Epoch 73; Iter   696/ 1097] train: loss: 0.0092401
[Epoch 73; Iter   726/ 1097] train: loss: 0.0585046
[Epoch 73; Iter   756/ 1097] train: loss: 0.0195277
[Epoch 73; Iter   786/ 1097] train: loss: 0.1185213
[Epoch 73; Iter   816/ 1097] train: loss: 0.0111736
[Epoch 73; Iter   846/ 1097] train: loss: 0.0185922
[Epoch 73; Iter   876/ 1097] train: loss: 0.0313603
[Epoch 73; Iter   906/ 1097] train: loss: 0.0450250
[Epoch 73; Iter   936/ 1097] train: loss: 0.0146186
[Epoch 73; Iter   966/ 1097] train: loss: 0.0081551
[Epoch 73; Iter   996/ 1097] train: loss: 0.0449342
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0107101
[Epoch 73; Iter  1056/ 1097] train: loss: 0.2082233
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0761659
[Epoch 73] ogbg-molhiv: 0.790812 val loss: 0.119739
[Epoch 73] ogbg-molhiv: 0.737448 test loss: 0.187407
[Epoch 74; Iter    19/ 1097] train: loss: 0.0095206
[Epoch 74; Iter    49/ 1097] train: loss: 0.0727807
[Epoch 74; Iter    79/ 1097] train: loss: 0.0644172
[Epoch 74; Iter   109/ 1097] train: loss: 0.0120949
[Epoch 74; Iter   139/ 1097] train: loss: 0.0498137
[Epoch 74; Iter   169/ 1097] train: loss: 0.0458795
[Epoch 74; Iter   199/ 1097] train: loss: 0.0423171
[Epoch 74; Iter   229/ 1097] train: loss: 0.0173732
[Epoch 74; Iter   259/ 1097] train: loss: 0.0301334
[Epoch 74; Iter   289/ 1097] train: loss: 0.0035793
[Epoch 74; Iter   319/ 1097] train: loss: 0.0228824
[Epoch 74; Iter   349/ 1097] train: loss: 0.0989013
[Epoch 74; Iter   379/ 1097] train: loss: 0.0187511
[Epoch 74; Iter   409/ 1097] train: loss: 0.0719933
[Epoch 74; Iter   439/ 1097] train: loss: 0.0064962
[Epoch 74; Iter   469/ 1097] train: loss: 0.0159051
[Epoch 74; Iter   499/ 1097] train: loss: 0.0796873
[Epoch 74; Iter   529/ 1097] train: loss: 0.2069976
[Epoch 74; Iter   559/ 1097] train: loss: 0.0183379
[Epoch 74; Iter   589/ 1097] train: loss: 0.0069136
[Epoch 74; Iter   619/ 1097] train: loss: 0.0323150
[Epoch 74; Iter   649/ 1097] train: loss: 0.0424159
[Epoch 74; Iter   679/ 1097] train: loss: 0.0321110
[Epoch 74; Iter   709/ 1097] train: loss: 0.1298350
[Epoch 74; Iter   739/ 1097] train: loss: 0.0064636
[Epoch 74; Iter   769/ 1097] train: loss: 0.0100126
[Epoch 74; Iter   799/ 1097] train: loss: 0.0086609
[Epoch 74; Iter   829/ 1097] train: loss: 0.0270322
[Epoch 74; Iter   859/ 1097] train: loss: 0.2481374
[Epoch 74; Iter   889/ 1097] train: loss: 0.1045096
[Epoch 74; Iter   919/ 1097] train: loss: 0.0123368
[Epoch 74; Iter   949/ 1097] train: loss: 0.0109835
[Epoch 74; Iter   979/ 1097] train: loss: 0.0067537
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0653636
[Epoch 74; Iter  1039/ 1097] train: loss: 0.0145276
[Epoch 74; Iter  1069/ 1097] train: loss: 0.0050933
[Epoch 74] ogbg-molhiv: 0.768730 val loss: 0.131797
[Epoch 74] ogbg-molhiv: 0.720839 test loss: 0.198088
[Epoch 75; Iter     2/ 1097] train: loss: 0.0091186
[Epoch 75; Iter    32/ 1097] train: loss: 0.0646405
[Epoch 75; Iter    62/ 1097] train: loss: 0.0165800
[Epoch 75; Iter    92/ 1097] train: loss: 0.0919332
[Epoch 75; Iter   122/ 1097] train: loss: 0.0288981
[Epoch 75; Iter   152/ 1097] train: loss: 0.0119241
[Epoch 75; Iter   182/ 1097] train: loss: 0.0277198
[Epoch 75; Iter   212/ 1097] train: loss: 0.1018095
[Epoch 75; Iter   242/ 1097] train: loss: 0.0146845
[Epoch 75; Iter   272/ 1097] train: loss: 0.0259470
[Epoch 75; Iter   302/ 1097] train: loss: 0.0055578
[Epoch 75; Iter   332/ 1097] train: loss: 0.1608785
[Epoch 75; Iter   362/ 1097] train: loss: 0.1005767
[Epoch 75; Iter   392/ 1097] train: loss: 0.0333079
[Epoch 75; Iter   422/ 1097] train: loss: 0.0149084
[Epoch 75; Iter   452/ 1097] train: loss: 0.0121643
[Epoch 75; Iter   482/ 1097] train: loss: 0.0702377
[Epoch 75; Iter   512/ 1097] train: loss: 0.0103336
[Epoch 75; Iter   542/ 1097] train: loss: 0.0140162
[Epoch 75; Iter   572/ 1097] train: loss: 0.0050151
[Epoch 75; Iter   602/ 1097] train: loss: 0.0084064
[Epoch 75; Iter   632/ 1097] train: loss: 0.0045446
[Epoch 75; Iter   662/ 1097] train: loss: 0.0745944
[Epoch 75; Iter   692/ 1097] train: loss: 0.0249442
[Epoch 75; Iter   722/ 1097] train: loss: 0.0176587
[Epoch 75; Iter   752/ 1097] train: loss: 0.1385974
[Epoch 75; Iter   782/ 1097] train: loss: 0.0718388
[Epoch 75; Iter   812/ 1097] train: loss: 0.1079110
[Epoch 75; Iter   842/ 1097] train: loss: 0.0027346
[Epoch 75; Iter   872/ 1097] train: loss: 0.0035093
[Epoch 75; Iter   902/ 1097] train: loss: 0.1882173
[Epoch 75; Iter   932/ 1097] train: loss: 0.0055138
[Epoch 75; Iter   962/ 1097] train: loss: 0.1527842
[Epoch 75; Iter   992/ 1097] train: loss: 0.0871553
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0068826
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0286072
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0409251
[Epoch 75] ogbg-molhiv: 0.779737 val loss: 0.116313
[Epoch 75] ogbg-molhiv: 0.729481 test loss: 0.190752
[Epoch 76; Iter    15/ 1097] train: loss: 0.0745071
[Epoch 76; Iter    45/ 1097] train: loss: 0.0610741
[Epoch 76; Iter    75/ 1097] train: loss: 0.0849142
[Epoch 76; Iter   105/ 1097] train: loss: 0.0074077
[Epoch 76; Iter   135/ 1097] train: loss: 0.0209522
[Epoch 76; Iter   165/ 1097] train: loss: 0.0080262
[Epoch 76; Iter   195/ 1097] train: loss: 0.0240354
[Epoch 76; Iter   225/ 1097] train: loss: 0.0075246
[Epoch 76; Iter   255/ 1097] train: loss: 0.0145831
[Epoch 76; Iter   285/ 1097] train: loss: 0.0182798
[Epoch 76; Iter   315/ 1097] train: loss: 0.1750425
[Epoch 76; Iter   345/ 1097] train: loss: 0.0320450
[Epoch 76; Iter   375/ 1097] train: loss: 0.0218978
[Epoch 76; Iter   405/ 1097] train: loss: 0.0117256
[Epoch 76; Iter   435/ 1097] train: loss: 0.0263951
[Epoch 76; Iter   465/ 1097] train: loss: 0.1739362
[Epoch 76; Iter   495/ 1097] train: loss: 0.0463021
[Epoch 76; Iter   525/ 1097] train: loss: 0.0175856
[Epoch 76; Iter   555/ 1097] train: loss: 0.0286233
[Epoch 76; Iter   585/ 1097] train: loss: 0.1304032
[Epoch 76; Iter   615/ 1097] train: loss: 0.0402277
[Epoch 76; Iter   645/ 1097] train: loss: 0.0132165
[Epoch 76; Iter   675/ 1097] train: loss: 0.1467405
[Epoch 76; Iter   705/ 1097] train: loss: 0.0042406
[Epoch 76; Iter   735/ 1097] train: loss: 0.0122290
[Epoch 76; Iter   765/ 1097] train: loss: 0.0686654
[Epoch 76; Iter   795/ 1097] train: loss: 0.0509309
[Epoch 76; Iter   825/ 1097] train: loss: 0.0147984
[Epoch 76; Iter   855/ 1097] train: loss: 0.0073183
[Epoch 76; Iter   885/ 1097] train: loss: 0.1406563
[Epoch 76; Iter   915/ 1097] train: loss: 0.0364014
[Epoch 76; Iter   945/ 1097] train: loss: 0.1602219
[Epoch 76; Iter   975/ 1097] train: loss: 0.0164315
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0171183
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0384022
[Epoch 76; Iter  1065/ 1097] train: loss: 0.1439601
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0115970
[Epoch 76] ogbg-molhiv: 0.785059 val loss: 0.117253
[Epoch 76] ogbg-molhiv: 0.725354 test loss: 0.194201
[Epoch 77; Iter    28/ 1097] train: loss: 0.0106426
[Epoch 77; Iter    58/ 1097] train: loss: 0.0210508
[Epoch 77; Iter    88/ 1097] train: loss: 0.0339470
[Epoch 77; Iter   118/ 1097] train: loss: 0.0066080
[Epoch 77; Iter   148/ 1097] train: loss: 0.0187530
[Epoch 77; Iter   178/ 1097] train: loss: 0.0120466
[Epoch 77; Iter   208/ 1097] train: loss: 0.0462187
[Epoch 77; Iter   238/ 1097] train: loss: 0.0113811
[Epoch 77; Iter   268/ 1097] train: loss: 0.0088867
[Epoch 79; Iter   486/  823] train: loss: 0.0663336
[Epoch 79; Iter   516/  823] train: loss: 0.0049301
[Epoch 79; Iter   546/  823] train: loss: 0.0209991
[Epoch 79; Iter   576/  823] train: loss: 0.0139502
[Epoch 79; Iter   606/  823] train: loss: 0.0660619
[Epoch 79; Iter   636/  823] train: loss: 0.0187369
[Epoch 79; Iter   666/  823] train: loss: 0.0168853
[Epoch 79; Iter   696/  823] train: loss: 0.0411135
[Epoch 79; Iter   726/  823] train: loss: 0.0709714
[Epoch 79; Iter   756/  823] train: loss: 0.0080040
[Epoch 79; Iter   786/  823] train: loss: 0.0048005
[Epoch 79; Iter   816/  823] train: loss: 0.0289123
[Epoch 79] ogbg-molhiv: 0.731721 val loss: 0.213085
[Epoch 79] ogbg-molhiv: 0.734692 test loss: 0.263742
[Epoch 80; Iter    23/  823] train: loss: 0.1682797
[Epoch 80; Iter    53/  823] train: loss: 0.0651770
[Epoch 80; Iter    83/  823] train: loss: 0.0944350
[Epoch 80; Iter   113/  823] train: loss: 0.0157087
[Epoch 80; Iter   143/  823] train: loss: 0.0874029
[Epoch 80; Iter   173/  823] train: loss: 0.0042251
[Epoch 80; Iter   203/  823] train: loss: 0.0007112
[Epoch 80; Iter   233/  823] train: loss: 0.0062313
[Epoch 80; Iter   263/  823] train: loss: 0.0137653
[Epoch 80; Iter   293/  823] train: loss: 0.0146489
[Epoch 80; Iter   323/  823] train: loss: 0.0212795
[Epoch 80; Iter   353/  823] train: loss: 0.0651389
[Epoch 80; Iter   383/  823] train: loss: 0.0659413
[Epoch 80; Iter   413/  823] train: loss: 0.0069780
[Epoch 80; Iter   443/  823] train: loss: 0.0072878
[Epoch 80; Iter   473/  823] train: loss: 0.0601778
[Epoch 80; Iter   503/  823] train: loss: 0.0658361
[Epoch 80; Iter   533/  823] train: loss: 0.0343966
[Epoch 80; Iter   563/  823] train: loss: 0.0050673
[Epoch 80; Iter   593/  823] train: loss: 0.0856000
[Epoch 80; Iter   623/  823] train: loss: 0.0114342
[Epoch 80; Iter   653/  823] train: loss: 0.0024182
[Epoch 80; Iter   683/  823] train: loss: 0.0101041
[Epoch 80; Iter   713/  823] train: loss: 0.0030721
[Epoch 80; Iter   743/  823] train: loss: 0.0144090
[Epoch 80; Iter   773/  823] train: loss: 0.0586670
[Epoch 80; Iter   803/  823] train: loss: 0.0101403
[Epoch 80] ogbg-molhiv: 0.743645 val loss: 0.221670
[Epoch 80] ogbg-molhiv: 0.743259 test loss: 0.245338
[Epoch 81; Iter    10/  823] train: loss: 0.0062421
[Epoch 81; Iter    40/  823] train: loss: 0.0475417
[Epoch 81; Iter    70/  823] train: loss: 0.0210937
[Epoch 81; Iter   100/  823] train: loss: 0.0104239
[Epoch 81; Iter   130/  823] train: loss: 0.0424290
[Epoch 81; Iter   160/  823] train: loss: 0.0188845
[Epoch 81; Iter   190/  823] train: loss: 0.0102347
[Epoch 81; Iter   220/  823] train: loss: 0.0291914
[Epoch 81; Iter   250/  823] train: loss: 0.0453192
[Epoch 81; Iter   280/  823] train: loss: 0.0007880
[Epoch 81; Iter   310/  823] train: loss: 0.0071510
[Epoch 81; Iter   340/  823] train: loss: 0.0205457
[Epoch 81; Iter   370/  823] train: loss: 0.0988811
[Epoch 81; Iter   400/  823] train: loss: 0.0552578
[Epoch 81; Iter   430/  823] train: loss: 0.0058482
[Epoch 81; Iter   460/  823] train: loss: 0.0130559
[Epoch 81; Iter   490/  823] train: loss: 0.0225485
[Epoch 81; Iter   520/  823] train: loss: 0.0577908
[Epoch 81; Iter   550/  823] train: loss: 0.0275321
[Epoch 81; Iter   580/  823] train: loss: 0.0059509
[Epoch 81; Iter   610/  823] train: loss: 0.2274987
[Epoch 81; Iter   640/  823] train: loss: 0.0119055
[Epoch 81; Iter   670/  823] train: loss: 0.0844368
[Epoch 81; Iter   700/  823] train: loss: 0.0264217
[Epoch 81; Iter   730/  823] train: loss: 0.0152965
[Epoch 81; Iter   760/  823] train: loss: 0.1526348
[Epoch 81; Iter   790/  823] train: loss: 0.0849414
[Epoch 81; Iter   820/  823] train: loss: 0.0859723
[Epoch 81] ogbg-molhiv: 0.731816 val loss: 0.219091
[Epoch 81] ogbg-molhiv: 0.741651 test loss: 0.185994
[Epoch 82; Iter    27/  823] train: loss: 0.0560948
[Epoch 82; Iter    57/  823] train: loss: 0.0449233
[Epoch 82; Iter    87/  823] train: loss: 0.0120865
[Epoch 82; Iter   117/  823] train: loss: 0.1658862
[Epoch 82; Iter   147/  823] train: loss: 0.0206066
[Epoch 82; Iter   177/  823] train: loss: 0.1298769
[Epoch 82; Iter   207/  823] train: loss: 0.0508805
[Epoch 82; Iter   237/  823] train: loss: 0.0207828
[Epoch 82; Iter   267/  823] train: loss: 0.0072451
[Epoch 82; Iter   297/  823] train: loss: 0.0057596
[Epoch 82; Iter   327/  823] train: loss: 0.0050791
[Epoch 82; Iter   357/  823] train: loss: 0.0122575
[Epoch 82; Iter   387/  823] train: loss: 0.0221566
[Epoch 82; Iter   417/  823] train: loss: 0.0067652
[Epoch 82; Iter   447/  823] train: loss: 0.1017845
[Epoch 82; Iter   477/  823] train: loss: 0.0163573
[Epoch 82; Iter   507/  823] train: loss: 0.0229539
[Epoch 82; Iter   537/  823] train: loss: 0.0087664
[Epoch 82; Iter   567/  823] train: loss: 0.0178276
[Epoch 82; Iter   597/  823] train: loss: 0.0242610
[Epoch 82; Iter   627/  823] train: loss: 0.0071081
[Epoch 82; Iter   657/  823] train: loss: 0.0128848
[Epoch 82; Iter   687/  823] train: loss: 0.0020375
[Epoch 82; Iter   717/  823] train: loss: 0.0022107
[Epoch 82; Iter   747/  823] train: loss: 0.0131347
[Epoch 82; Iter   777/  823] train: loss: 0.0513724
[Epoch 82; Iter   807/  823] train: loss: 0.0222283
[Epoch 82] ogbg-molhiv: 0.735368 val loss: 0.394717
[Epoch 82] ogbg-molhiv: 0.740373 test loss: 2.050776
[Epoch 83; Iter    14/  823] train: loss: 0.0015585
[Epoch 83; Iter    44/  823] train: loss: 0.0190795
[Epoch 83; Iter    74/  823] train: loss: 0.0254847
[Epoch 83; Iter   104/  823] train: loss: 0.0230535
[Epoch 83; Iter   134/  823] train: loss: 0.0654098
[Epoch 83; Iter   164/  823] train: loss: 0.1318549
[Epoch 83; Iter   194/  823] train: loss: 0.0045137
[Epoch 83; Iter   224/  823] train: loss: 0.0054164
[Epoch 83; Iter   254/  823] train: loss: 0.0017142
[Epoch 83; Iter   284/  823] train: loss: 0.1593813
[Epoch 83; Iter   314/  823] train: loss: 0.0135670
[Epoch 83; Iter   344/  823] train: loss: 0.0103931
[Epoch 83; Iter   374/  823] train: loss: 0.0956471
[Epoch 83; Iter   404/  823] train: loss: 0.0508669
[Epoch 83; Iter   434/  823] train: loss: 0.0107002
[Epoch 83; Iter   464/  823] train: loss: 0.0164789
[Epoch 83; Iter   494/  823] train: loss: 0.0672036
[Epoch 83; Iter   524/  823] train: loss: 0.0294451
[Epoch 83; Iter   554/  823] train: loss: 0.0131589
[Epoch 83; Iter   584/  823] train: loss: 0.0137161
[Epoch 83; Iter   614/  823] train: loss: 0.1352095
[Epoch 83; Iter   644/  823] train: loss: 0.1225343
[Epoch 83; Iter   674/  823] train: loss: 0.0041300
[Epoch 83; Iter   704/  823] train: loss: 0.0022246
[Epoch 83; Iter   734/  823] train: loss: 0.0146791
[Epoch 83; Iter   764/  823] train: loss: 0.0513308
[Epoch 83; Iter   794/  823] train: loss: 0.0220369
[Epoch 83] ogbg-molhiv: 0.743143 val loss: 0.247533
[Epoch 83] ogbg-molhiv: 0.747495 test loss: 0.436368
[Epoch 84; Iter     1/  823] train: loss: 0.0276375
[Epoch 84; Iter    31/  823] train: loss: 0.0105206
[Epoch 84; Iter    61/  823] train: loss: 0.0099563
[Epoch 84; Iter    91/  823] train: loss: 0.0274970
[Epoch 84; Iter   121/  823] train: loss: 0.0196805
[Epoch 84; Iter   151/  823] train: loss: 0.0224757
[Epoch 84; Iter   181/  823] train: loss: 0.1538461
[Epoch 84; Iter   211/  823] train: loss: 0.1237497
[Epoch 84; Iter   241/  823] train: loss: 0.0178002
[Epoch 84; Iter   271/  823] train: loss: 0.0166245
[Epoch 84; Iter   301/  823] train: loss: 0.0018723
[Epoch 84; Iter   331/  823] train: loss: 0.0120665
[Epoch 84; Iter   361/  823] train: loss: 0.0022712
[Epoch 84; Iter   391/  823] train: loss: 0.0121490
[Epoch 84; Iter   421/  823] train: loss: 0.1067230
[Epoch 84; Iter   451/  823] train: loss: 0.0683784
[Epoch 84; Iter   481/  823] train: loss: 0.0006620
[Epoch 84; Iter   511/  823] train: loss: 0.0719352
[Epoch 84; Iter   541/  823] train: loss: 0.0133222
[Epoch 84; Iter   571/  823] train: loss: 0.0068182
[Epoch 84; Iter   601/  823] train: loss: 0.0809465
[Epoch 84; Iter   631/  823] train: loss: 0.0185485
[Epoch 84; Iter   661/  823] train: loss: 0.0099162
[Epoch 84; Iter   691/  823] train: loss: 0.0122727
[Epoch 84; Iter   721/  823] train: loss: 0.0075791
[Epoch 84; Iter   751/  823] train: loss: 0.0110088
[Epoch 73; Iter   216/ 1097] train: loss: 0.0352611
[Epoch 73; Iter   246/ 1097] train: loss: 0.0140993
[Epoch 73; Iter   276/ 1097] train: loss: 0.0372446
[Epoch 73; Iter   306/ 1097] train: loss: 0.0323461
[Epoch 73; Iter   336/ 1097] train: loss: 0.0080529
[Epoch 73; Iter   366/ 1097] train: loss: 0.2025285
[Epoch 73; Iter   396/ 1097] train: loss: 0.0400891
[Epoch 73; Iter   426/ 1097] train: loss: 0.0353602
[Epoch 73; Iter   456/ 1097] train: loss: 0.0284744
[Epoch 73; Iter   486/ 1097] train: loss: 0.0120225
[Epoch 73; Iter   516/ 1097] train: loss: 0.0169309
[Epoch 73; Iter   546/ 1097] train: loss: 0.0160324
[Epoch 73; Iter   576/ 1097] train: loss: 0.0155727
[Epoch 73; Iter   606/ 1097] train: loss: 0.0232271
[Epoch 73; Iter   636/ 1097] train: loss: 0.0040376
[Epoch 73; Iter   666/ 1097] train: loss: 0.0816866
[Epoch 73; Iter   696/ 1097] train: loss: 0.0040364
[Epoch 73; Iter   726/ 1097] train: loss: 0.0290257
[Epoch 73; Iter   756/ 1097] train: loss: 0.0034742
[Epoch 73; Iter   786/ 1097] train: loss: 0.0396623
[Epoch 73; Iter   816/ 1097] train: loss: 0.0038513
[Epoch 73; Iter   846/ 1097] train: loss: 0.0304540
[Epoch 73; Iter   876/ 1097] train: loss: 0.1192658
[Epoch 73; Iter   906/ 1097] train: loss: 0.0331950
[Epoch 73; Iter   936/ 1097] train: loss: 0.0047910
[Epoch 73; Iter   966/ 1097] train: loss: 0.0192094
[Epoch 73; Iter   996/ 1097] train: loss: 0.0122315
[Epoch 73; Iter  1026/ 1097] train: loss: 0.0031352
[Epoch 73; Iter  1056/ 1097] train: loss: 0.0046660
[Epoch 73; Iter  1086/ 1097] train: loss: 0.0354865
[Epoch 73] ogbg-molhiv: 0.781036 val loss: 0.113298
[Epoch 73] ogbg-molhiv: 0.757083 test loss: 0.223463
[Epoch 74; Iter    19/ 1097] train: loss: 0.0024816
[Epoch 74; Iter    49/ 1097] train: loss: 0.0026060
[Epoch 74; Iter    79/ 1097] train: loss: 0.0136593
[Epoch 74; Iter   109/ 1097] train: loss: 0.0377570
[Epoch 74; Iter   139/ 1097] train: loss: 0.0028712
[Epoch 74; Iter   169/ 1097] train: loss: 0.0086264
[Epoch 74; Iter   199/ 1097] train: loss: 0.0630641
[Epoch 74; Iter   229/ 1097] train: loss: 0.0148935
[Epoch 74; Iter   259/ 1097] train: loss: 0.0482581
[Epoch 74; Iter   289/ 1097] train: loss: 0.0211757
[Epoch 74; Iter   319/ 1097] train: loss: 0.2212294
[Epoch 74; Iter   349/ 1097] train: loss: 0.0837624
[Epoch 74; Iter   379/ 1097] train: loss: 0.0503530
[Epoch 74; Iter   409/ 1097] train: loss: 0.0023484
[Epoch 74; Iter   439/ 1097] train: loss: 0.0180045
[Epoch 74; Iter   469/ 1097] train: loss: 0.0018627
[Epoch 74; Iter   499/ 1097] train: loss: 0.0220063
[Epoch 74; Iter   529/ 1097] train: loss: 0.0017675
[Epoch 74; Iter   559/ 1097] train: loss: 0.0239452
[Epoch 74; Iter   589/ 1097] train: loss: 0.0490242
[Epoch 74; Iter   619/ 1097] train: loss: 0.0030303
[Epoch 74; Iter   649/ 1097] train: loss: 0.0258911
[Epoch 74; Iter   679/ 1097] train: loss: 0.0914900
[Epoch 74; Iter   709/ 1097] train: loss: 0.1630521
[Epoch 74; Iter   739/ 1097] train: loss: 0.0062401
[Epoch 74; Iter   769/ 1097] train: loss: 0.0058638
[Epoch 74; Iter   799/ 1097] train: loss: 0.0919719
[Epoch 74; Iter   829/ 1097] train: loss: 0.0115564
[Epoch 74; Iter   859/ 1097] train: loss: 0.0052686
[Epoch 74; Iter   889/ 1097] train: loss: 0.0036430
[Epoch 74; Iter   919/ 1097] train: loss: 0.0482342
[Epoch 74; Iter   949/ 1097] train: loss: 0.0189552
[Epoch 74; Iter   979/ 1097] train: loss: 0.0201054
[Epoch 74; Iter  1009/ 1097] train: loss: 0.0056670
[Epoch 74; Iter  1039/ 1097] train: loss: 0.3081813
[Epoch 74; Iter  1069/ 1097] train: loss: 0.1000734
[Epoch 74] ogbg-molhiv: 0.802279 val loss: 0.120155
[Epoch 74] ogbg-molhiv: 0.754489 test loss: 0.211083
[Epoch 75; Iter     2/ 1097] train: loss: 0.0037739
[Epoch 75; Iter    32/ 1097] train: loss: 0.3044215
[Epoch 75; Iter    62/ 1097] train: loss: 0.0059542
[Epoch 75; Iter    92/ 1097] train: loss: 0.0018969
[Epoch 75; Iter   122/ 1097] train: loss: 0.0098643
[Epoch 75; Iter   152/ 1097] train: loss: 0.0604436
[Epoch 75; Iter   182/ 1097] train: loss: 0.1096490
[Epoch 75; Iter   212/ 1097] train: loss: 0.0083047
[Epoch 75; Iter   242/ 1097] train: loss: 0.0050448
[Epoch 75; Iter   272/ 1097] train: loss: 0.0078348
[Epoch 75; Iter   302/ 1097] train: loss: 0.0080702
[Epoch 75; Iter   332/ 1097] train: loss: 0.0042695
[Epoch 75; Iter   362/ 1097] train: loss: 0.0025652
[Epoch 75; Iter   392/ 1097] train: loss: 0.0161618
[Epoch 75; Iter   422/ 1097] train: loss: 0.0094044
[Epoch 75; Iter   452/ 1097] train: loss: 0.0039795
[Epoch 75; Iter   482/ 1097] train: loss: 0.0100017
[Epoch 75; Iter   512/ 1097] train: loss: 0.0183896
[Epoch 75; Iter   542/ 1097] train: loss: 0.0049530
[Epoch 75; Iter   572/ 1097] train: loss: 0.1105284
[Epoch 75; Iter   602/ 1097] train: loss: 0.1179602
[Epoch 75; Iter   632/ 1097] train: loss: 0.1132140
[Epoch 75; Iter   662/ 1097] train: loss: 0.0044318
[Epoch 75; Iter   692/ 1097] train: loss: 0.0064314
[Epoch 75; Iter   722/ 1097] train: loss: 0.0330838
[Epoch 75; Iter   752/ 1097] train: loss: 0.0170130
[Epoch 75; Iter   782/ 1097] train: loss: 0.0241865
[Epoch 75; Iter   812/ 1097] train: loss: 0.0189712
[Epoch 75; Iter   842/ 1097] train: loss: 0.0259520
[Epoch 75; Iter   872/ 1097] train: loss: 0.0011457
[Epoch 75; Iter   902/ 1097] train: loss: 0.0541028
[Epoch 75; Iter   932/ 1097] train: loss: 0.0404304
[Epoch 75; Iter   962/ 1097] train: loss: 0.0275067
[Epoch 75; Iter   992/ 1097] train: loss: 0.0233630
[Epoch 75; Iter  1022/ 1097] train: loss: 0.0534147
[Epoch 75; Iter  1052/ 1097] train: loss: 0.0111652
[Epoch 75; Iter  1082/ 1097] train: loss: 0.0527992
[Epoch 75] ogbg-molhiv: 0.787812 val loss: 0.115245
[Epoch 75] ogbg-molhiv: 0.761813 test loss: 0.201135
[Epoch 76; Iter    15/ 1097] train: loss: 0.0041250
[Epoch 76; Iter    45/ 1097] train: loss: 0.0253299
[Epoch 76; Iter    75/ 1097] train: loss: 0.0032322
[Epoch 76; Iter   105/ 1097] train: loss: 0.0280960
[Epoch 76; Iter   135/ 1097] train: loss: 0.0330282
[Epoch 76; Iter   165/ 1097] train: loss: 0.0008534
[Epoch 76; Iter   195/ 1097] train: loss: 0.0043763
[Epoch 76; Iter   225/ 1097] train: loss: 0.0045748
[Epoch 76; Iter   255/ 1097] train: loss: 0.0170504
[Epoch 76; Iter   285/ 1097] train: loss: 0.0014029
[Epoch 76; Iter   315/ 1097] train: loss: 0.0042409
[Epoch 76; Iter   345/ 1097] train: loss: 0.0210253
[Epoch 76; Iter   375/ 1097] train: loss: 0.0374418
[Epoch 76; Iter   405/ 1097] train: loss: 0.0136252
[Epoch 76; Iter   435/ 1097] train: loss: 0.0017221
[Epoch 76; Iter   465/ 1097] train: loss: 0.0094900
[Epoch 76; Iter   495/ 1097] train: loss: 0.0015981
[Epoch 76; Iter   525/ 1097] train: loss: 0.0109972
[Epoch 76; Iter   555/ 1097] train: loss: 0.0125211
[Epoch 76; Iter   585/ 1097] train: loss: 0.0183231
[Epoch 76; Iter   615/ 1097] train: loss: 0.0021419
[Epoch 76; Iter   645/ 1097] train: loss: 0.0074945
[Epoch 76; Iter   675/ 1097] train: loss: 0.0097560
[Epoch 76; Iter   705/ 1097] train: loss: 0.0109490
[Epoch 76; Iter   735/ 1097] train: loss: 0.0166378
[Epoch 76; Iter   765/ 1097] train: loss: 0.0143159
[Epoch 76; Iter   795/ 1097] train: loss: 0.0112870
[Epoch 76; Iter   825/ 1097] train: loss: 0.0185140
[Epoch 76; Iter   855/ 1097] train: loss: 0.0022045
[Epoch 76; Iter   885/ 1097] train: loss: 0.0545571
[Epoch 76; Iter   915/ 1097] train: loss: 0.0117847
[Epoch 76; Iter   945/ 1097] train: loss: 0.0164835
[Epoch 76; Iter   975/ 1097] train: loss: 0.0133879
[Epoch 76; Iter  1005/ 1097] train: loss: 0.0232235
[Epoch 76; Iter  1035/ 1097] train: loss: 0.0061153
[Epoch 76; Iter  1065/ 1097] train: loss: 0.0845327
[Epoch 76; Iter  1095/ 1097] train: loss: 0.0220496
[Epoch 76] ogbg-molhiv: 0.787582 val loss: 0.115119
[Epoch 76] ogbg-molhiv: 0.775388 test loss: 0.195109
[Epoch 77; Iter    28/ 1097] train: loss: 0.0398390
[Epoch 77; Iter    58/ 1097] train: loss: 0.0050439
[Epoch 77; Iter    88/ 1097] train: loss: 0.0698580
[Epoch 77; Iter   118/ 1097] train: loss: 0.0037371
[Epoch 77; Iter   148/ 1097] train: loss: 0.0059034
[Epoch 77; Iter   178/ 1097] train: loss: 0.0454742
[Epoch 77; Iter   208/ 1097] train: loss: 0.0864568
[Epoch 77; Iter   238/ 1097] train: loss: 0.0042482
[Epoch 77; Iter   268/ 1097] train: loss: 0.0868730
[Epoch 79; Iter   486/  823] train: loss: 0.0180631
[Epoch 79; Iter   516/  823] train: loss: 0.0244410
[Epoch 79; Iter   546/  823] train: loss: 0.0355134
[Epoch 79; Iter   576/  823] train: loss: 0.0071338
[Epoch 79; Iter   606/  823] train: loss: 0.0402426
[Epoch 79; Iter   636/  823] train: loss: 0.0232983
[Epoch 79; Iter   666/  823] train: loss: 0.0413451
[Epoch 79; Iter   696/  823] train: loss: 0.0087324
[Epoch 79; Iter   726/  823] train: loss: 0.0199269
[Epoch 79; Iter   756/  823] train: loss: 0.1133016
[Epoch 79; Iter   786/  823] train: loss: 0.0176080
[Epoch 79; Iter   816/  823] train: loss: 0.0297702
[Epoch 79] ogbg-molhiv: 0.700618 val loss: 0.337458
[Epoch 79] ogbg-molhiv: 0.743166 test loss: 0.192218
[Epoch 80; Iter    23/  823] train: loss: 0.0031968
[Epoch 80; Iter    53/  823] train: loss: 0.0427101
[Epoch 80; Iter    83/  823] train: loss: 0.0026217
[Epoch 80; Iter   113/  823] train: loss: 0.0589225
[Epoch 80; Iter   143/  823] train: loss: 0.0266492
[Epoch 80; Iter   173/  823] train: loss: 0.0040074
[Epoch 80; Iter   203/  823] train: loss: 0.0267013
[Epoch 80; Iter   233/  823] train: loss: 0.0319129
[Epoch 80; Iter   263/  823] train: loss: 0.0040501
[Epoch 80; Iter   293/  823] train: loss: 0.0071983
[Epoch 80; Iter   323/  823] train: loss: 0.0367610
[Epoch 80; Iter   353/  823] train: loss: 0.0174129
[Epoch 80; Iter   383/  823] train: loss: 0.0153259
[Epoch 80; Iter   413/  823] train: loss: 0.0073627
[Epoch 80; Iter   443/  823] train: loss: 0.0052414
[Epoch 80; Iter   473/  823] train: loss: 0.0436600
[Epoch 80; Iter   503/  823] train: loss: 0.0003765
[Epoch 80; Iter   533/  823] train: loss: 0.0684879
[Epoch 80; Iter   563/  823] train: loss: 0.0289891
[Epoch 80; Iter   593/  823] train: loss: 0.0221774
[Epoch 80; Iter   623/  823] train: loss: 0.1496045
[Epoch 80; Iter   653/  823] train: loss: 0.0021039
[Epoch 80; Iter   683/  823] train: loss: 0.0025106
[Epoch 80; Iter   713/  823] train: loss: 0.0082717
[Epoch 80; Iter   743/  823] train: loss: 0.0193539
[Epoch 80; Iter   773/  823] train: loss: 0.0477143
[Epoch 80; Iter   803/  823] train: loss: 0.0115594
[Epoch 80] ogbg-molhiv: 0.704809 val loss: 0.392526
[Epoch 80] ogbg-molhiv: 0.750037 test loss: 0.228076
[Epoch 81; Iter    10/  823] train: loss: 0.0881011
[Epoch 81; Iter    40/  823] train: loss: 0.0073356
[Epoch 81; Iter    70/  823] train: loss: 0.0101137
[Epoch 81; Iter   100/  823] train: loss: 0.0004569
[Epoch 81; Iter   130/  823] train: loss: 0.1224740
[Epoch 81; Iter   160/  823] train: loss: 0.0120721
[Epoch 81; Iter   190/  823] train: loss: 0.0111637
[Epoch 81; Iter   220/  823] train: loss: 0.0032074
[Epoch 81; Iter   250/  823] train: loss: 0.0016947
[Epoch 81; Iter   280/  823] train: loss: 0.0080542
[Epoch 81; Iter   310/  823] train: loss: 0.0019295
[Epoch 81; Iter   340/  823] train: loss: 0.0079462
[Epoch 81; Iter   370/  823] train: loss: 0.0174551
[Epoch 81; Iter   400/  823] train: loss: 0.0137614
[Epoch 81; Iter   430/  823] train: loss: 0.0080520
[Epoch 81; Iter   460/  823] train: loss: 0.0048063
[Epoch 81; Iter   490/  823] train: loss: 0.0004896
[Epoch 81; Iter   520/  823] train: loss: 0.0205571
[Epoch 81; Iter   550/  823] train: loss: 0.0011905
[Epoch 81; Iter   580/  823] train: loss: 0.0070015
[Epoch 81; Iter   610/  823] train: loss: 0.0009575
[Epoch 81; Iter   640/  823] train: loss: 0.0110083
[Epoch 81; Iter   670/  823] train: loss: 0.0068933
[Epoch 81; Iter   700/  823] train: loss: 0.1048171
[Epoch 81; Iter   730/  823] train: loss: 0.0034528
[Epoch 81; Iter   760/  823] train: loss: 0.0201562
[Epoch 81; Iter   790/  823] train: loss: 0.0044162
[Epoch 81; Iter   820/  823] train: loss: 0.1255226
[Epoch 81] ogbg-molhiv: 0.708483 val loss: 0.349641
[Epoch 81] ogbg-molhiv: 0.739904 test loss: 0.222907
[Epoch 82; Iter    27/  823] train: loss: 0.0094297
[Epoch 82; Iter    57/  823] train: loss: 0.0343309
[Epoch 82; Iter    87/  823] train: loss: 0.0063831
[Epoch 82; Iter   117/  823] train: loss: 0.0070015
[Epoch 82; Iter   147/  823] train: loss: 0.1560919
[Epoch 82; Iter   177/  823] train: loss: 0.0105980
[Epoch 82; Iter   207/  823] train: loss: 0.0039409
[Epoch 82; Iter   237/  823] train: loss: 0.0171842
[Epoch 82; Iter   267/  823] train: loss: 0.0083202
[Epoch 82; Iter   297/  823] train: loss: 0.0045059
[Epoch 82; Iter   327/  823] train: loss: 0.0047522
[Epoch 82; Iter   357/  823] train: loss: 0.0045475
[Epoch 82; Iter   387/  823] train: loss: 0.0954974
[Epoch 82; Iter   417/  823] train: loss: 0.0176247
[Epoch 82; Iter   447/  823] train: loss: 0.0556943
[Epoch 82; Iter   477/  823] train: loss: 0.0487840
[Epoch 82; Iter   507/  823] train: loss: 0.0342976
[Epoch 82; Iter   537/  823] train: loss: 0.0177291
[Epoch 82; Iter   567/  823] train: loss: 0.0045640
[Epoch 82; Iter   597/  823] train: loss: 0.0251198
[Epoch 82; Iter   627/  823] train: loss: 0.0587365
[Epoch 82; Iter   657/  823] train: loss: 0.0051079
[Epoch 82; Iter   687/  823] train: loss: 0.0014425
[Epoch 82; Iter   717/  823] train: loss: 0.1144667
[Epoch 82; Iter   747/  823] train: loss: 0.0401823
[Epoch 82; Iter   777/  823] train: loss: 0.0280416
[Epoch 82; Iter   807/  823] train: loss: 0.0280097
[Epoch 82] ogbg-molhiv: 0.709280 val loss: 0.352590
[Epoch 82] ogbg-molhiv: 0.762003 test loss: 0.209101
[Epoch 83; Iter    14/  823] train: loss: 0.0282895
[Epoch 83; Iter    44/  823] train: loss: 0.0373131
[Epoch 83; Iter    74/  823] train: loss: 0.0096244
[Epoch 83; Iter   104/  823] train: loss: 0.0149703
[Epoch 83; Iter   134/  823] train: loss: 0.0098361
[Epoch 83; Iter   164/  823] train: loss: 0.0044962
[Epoch 83; Iter   194/  823] train: loss: 0.0276693
[Epoch 83; Iter   224/  823] train: loss: 0.0091434
[Epoch 83; Iter   254/  823] train: loss: 0.0506759
[Epoch 83; Iter   284/  823] train: loss: 0.0063470
[Epoch 83; Iter   314/  823] train: loss: 0.0007479
[Epoch 83; Iter   344/  823] train: loss: 0.0039263
[Epoch 83; Iter   374/  823] train: loss: 0.0100369
[Epoch 83; Iter   404/  823] train: loss: 0.0142903
[Epoch 83; Iter   434/  823] train: loss: 0.1525313
[Epoch 83; Iter   464/  823] train: loss: 0.0027445
[Epoch 83; Iter   494/  823] train: loss: 0.0070144
[Epoch 83; Iter   524/  823] train: loss: 0.0090892
[Epoch 83; Iter   554/  823] train: loss: 0.0021386
[Epoch 83; Iter   584/  823] train: loss: 0.0119763
[Epoch 83; Iter   614/  823] train: loss: 0.0072551
[Epoch 83; Iter   644/  823] train: loss: 0.0459681
[Epoch 83; Iter   674/  823] train: loss: 0.0022924
[Epoch 83; Iter   704/  823] train: loss: 0.0064743
[Epoch 83; Iter   734/  823] train: loss: 0.0304439
[Epoch 83; Iter   764/  823] train: loss: 0.0147286
[Epoch 83; Iter   794/  823] train: loss: 0.0324359
[Epoch 83] ogbg-molhiv: 0.708521 val loss: 0.343498
[Epoch 83] ogbg-molhiv: 0.759711 test loss: 0.215039
[Epoch 84; Iter     1/  823] train: loss: 0.0010227
[Epoch 84; Iter    31/  823] train: loss: 0.0709303
[Epoch 84; Iter    61/  823] train: loss: 0.1477862
[Epoch 84; Iter    91/  823] train: loss: 0.0168511
[Epoch 84; Iter   121/  823] train: loss: 0.0031396
[Epoch 84; Iter   151/  823] train: loss: 0.0015641
[Epoch 84; Iter   181/  823] train: loss: 0.0075879
[Epoch 84; Iter   211/  823] train: loss: 0.0428221
[Epoch 84; Iter   241/  823] train: loss: 0.0191889
[Epoch 84; Iter   271/  823] train: loss: 0.0047438
[Epoch 84; Iter   301/  823] train: loss: 0.0057827
[Epoch 84; Iter   331/  823] train: loss: 0.0102356
[Epoch 84; Iter   361/  823] train: loss: 0.0885232
[Epoch 84; Iter   391/  823] train: loss: 0.0022721
[Epoch 84; Iter   421/  823] train: loss: 0.0072330
[Epoch 84; Iter   451/  823] train: loss: 0.0014117
[Epoch 84; Iter   481/  823] train: loss: 0.0091954
[Epoch 84; Iter   511/  823] train: loss: 0.0854167
[Epoch 84; Iter   541/  823] train: loss: 0.0099680
[Epoch 84; Iter   571/  823] train: loss: 0.0017232
[Epoch 84; Iter   601/  823] train: loss: 0.0073651
[Epoch 84; Iter   631/  823] train: loss: 0.0016070
[Epoch 84; Iter   661/  823] train: loss: 0.0056048
[Epoch 84; Iter   691/  823] train: loss: 0.0020991
[Epoch 84; Iter   721/  823] train: loss: 0.0181217
[Epoch 84; Iter   751/  823] train: loss: 0.0116786
[Epoch 78; Iter   270/  960] train: loss: 0.0143482
[Epoch 78; Iter   300/  960] train: loss: 0.0586761
[Epoch 78; Iter   330/  960] train: loss: 0.0165933
[Epoch 78; Iter   360/  960] train: loss: 0.0049316
[Epoch 78; Iter   390/  960] train: loss: 0.0275475
[Epoch 78; Iter   420/  960] train: loss: 0.0825430
[Epoch 78; Iter   450/  960] train: loss: 0.0239126
[Epoch 78; Iter   480/  960] train: loss: 0.3140170
[Epoch 78; Iter   510/  960] train: loss: 0.0066042
[Epoch 78; Iter   540/  960] train: loss: 0.0581104
[Epoch 78; Iter   570/  960] train: loss: 0.0174503
[Epoch 78; Iter   600/  960] train: loss: 0.0255402
[Epoch 78; Iter   630/  960] train: loss: 0.0309409
[Epoch 78; Iter   660/  960] train: loss: 0.0090066
[Epoch 78; Iter   690/  960] train: loss: 0.0159305
[Epoch 78; Iter   720/  960] train: loss: 0.0087935
[Epoch 78; Iter   750/  960] train: loss: 0.0382547
[Epoch 78; Iter   780/  960] train: loss: 0.0159719
[Epoch 78; Iter   810/  960] train: loss: 0.0223283
[Epoch 78; Iter   840/  960] train: loss: 0.0042936
[Epoch 78; Iter   870/  960] train: loss: 0.0217866
[Epoch 78; Iter   900/  960] train: loss: 0.1645104
[Epoch 78; Iter   930/  960] train: loss: 0.0019242
[Epoch 78; Iter   960/  960] train: loss: 0.0047924
[Epoch 78] ogbg-molhiv: 0.727608 val loss: 0.244228
[Epoch 78] ogbg-molhiv: 0.768037 test loss: 0.220034
[Epoch 79; Iter    30/  960] train: loss: 0.0673377
[Epoch 79; Iter    60/  960] train: loss: 0.0036064
[Epoch 79; Iter    90/  960] train: loss: 0.0952176
[Epoch 79; Iter   120/  960] train: loss: 0.0014275
[Epoch 79; Iter   150/  960] train: loss: 0.0076484
[Epoch 79; Iter   180/  960] train: loss: 0.0039936
[Epoch 79; Iter   210/  960] train: loss: 0.0138898
[Epoch 79; Iter   240/  960] train: loss: 0.0034640
[Epoch 79; Iter   270/  960] train: loss: 0.0032577
[Epoch 79; Iter   300/  960] train: loss: 0.0103610
[Epoch 79; Iter   330/  960] train: loss: 0.0022342
[Epoch 79; Iter   360/  960] train: loss: 0.0444688
[Epoch 79; Iter   390/  960] train: loss: 0.0550350
[Epoch 79; Iter   420/  960] train: loss: 0.0433091
[Epoch 79; Iter   450/  960] train: loss: 0.0208232
[Epoch 79; Iter   480/  960] train: loss: 0.0092882
[Epoch 79; Iter   510/  960] train: loss: 0.0094569
[Epoch 79; Iter   540/  960] train: loss: 0.0197405
[Epoch 79; Iter   570/  960] train: loss: 0.0223687
[Epoch 79; Iter   600/  960] train: loss: 0.0006719
[Epoch 79; Iter   630/  960] train: loss: 0.1371376
[Epoch 79; Iter   660/  960] train: loss: 0.0166744
[Epoch 79; Iter   690/  960] train: loss: 0.0040478
[Epoch 79; Iter   720/  960] train: loss: 0.0039539
[Epoch 79; Iter   750/  960] train: loss: 0.0252671
[Epoch 79; Iter   780/  960] train: loss: 0.0913003
[Epoch 79; Iter   810/  960] train: loss: 0.0054060
[Epoch 79; Iter   840/  960] train: loss: 0.0078699
[Epoch 79; Iter   870/  960] train: loss: 0.0352714
[Epoch 79; Iter   900/  960] train: loss: 0.0318831
[Epoch 79; Iter   930/  960] train: loss: 0.0085854
[Epoch 79; Iter   960/  960] train: loss: 0.0300948
[Epoch 79] ogbg-molhiv: 0.731994 val loss: 0.242918
[Epoch 79] ogbg-molhiv: 0.767535 test loss: 0.187266
[Epoch 80; Iter    30/  960] train: loss: 0.0110180
[Epoch 80; Iter    60/  960] train: loss: 0.0007678
[Epoch 80; Iter    90/  960] train: loss: 0.0138739
[Epoch 80; Iter   120/  960] train: loss: 0.0030254
[Epoch 80; Iter   150/  960] train: loss: 0.0682315
[Epoch 80; Iter   180/  960] train: loss: 0.0613913
[Epoch 80; Iter   210/  960] train: loss: 0.0094330
[Epoch 80; Iter   240/  960] train: loss: 0.0082835
[Epoch 80; Iter   270/  960] train: loss: 0.0026570
[Epoch 80; Iter   300/  960] train: loss: 0.0355378
[Epoch 80; Iter   330/  960] train: loss: 0.0056136
[Epoch 80; Iter   360/  960] train: loss: 0.0042713
[Epoch 80; Iter   390/  960] train: loss: 0.0222038
[Epoch 80; Iter   420/  960] train: loss: 0.0716524
[Epoch 80; Iter   450/  960] train: loss: 0.0133253
[Epoch 80; Iter   480/  960] train: loss: 0.0726189
[Epoch 80; Iter   510/  960] train: loss: 0.0061932
[Epoch 80; Iter   540/  960] train: loss: 0.0199956
[Epoch 80; Iter   570/  960] train: loss: 0.0139185
[Epoch 80; Iter   600/  960] train: loss: 0.0238418
[Epoch 80; Iter   630/  960] train: loss: 0.0146015
[Epoch 80; Iter   660/  960] train: loss: 0.1086297
[Epoch 80; Iter   690/  960] train: loss: 0.0022646
[Epoch 80; Iter   720/  960] train: loss: 0.0313894
[Epoch 80; Iter   750/  960] train: loss: 0.1500414
[Epoch 80; Iter   780/  960] train: loss: 0.0349813
[Epoch 80; Iter   810/  960] train: loss: 0.0182283
[Epoch 80; Iter   840/  960] train: loss: 0.0060396
[Epoch 80; Iter   870/  960] train: loss: 0.0175953
[Epoch 80; Iter   900/  960] train: loss: 0.0022287
[Epoch 80; Iter   930/  960] train: loss: 0.0726389
[Epoch 80; Iter   960/  960] train: loss: 0.0009871
[Epoch 80] ogbg-molhiv: 0.715937 val loss: 0.248208
[Epoch 80] ogbg-molhiv: 0.754673 test loss: 0.196384
[Epoch 81; Iter    30/  960] train: loss: 0.0087208
[Epoch 81; Iter    60/  960] train: loss: 0.0108076
[Epoch 81; Iter    90/  960] train: loss: 0.0060971
[Epoch 81; Iter   120/  960] train: loss: 0.0668494
[Epoch 81; Iter   150/  960] train: loss: 0.0140733
[Epoch 81; Iter   180/  960] train: loss: 0.1761221
[Epoch 81; Iter   210/  960] train: loss: 0.0109552
[Epoch 81; Iter   240/  960] train: loss: 0.0218137
[Epoch 81; Iter   270/  960] train: loss: 0.0065097
[Epoch 81; Iter   300/  960] train: loss: 0.0079752
[Epoch 81; Iter   330/  960] train: loss: 0.0048520
[Epoch 81; Iter   360/  960] train: loss: 0.0094037
[Epoch 81; Iter   390/  960] train: loss: 0.0290146
[Epoch 81; Iter   420/  960] train: loss: 0.0110544
[Epoch 81; Iter   450/  960] train: loss: 0.0024801
[Epoch 81; Iter   480/  960] train: loss: 0.0009036
[Epoch 81; Iter   510/  960] train: loss: 0.0022543
[Epoch 81; Iter   540/  960] train: loss: 0.0030882
[Epoch 81; Iter   570/  960] train: loss: 0.0062088
[Epoch 81; Iter   600/  960] train: loss: 0.0142888
[Epoch 81; Iter   630/  960] train: loss: 0.0074009
[Epoch 81; Iter   660/  960] train: loss: 0.0141089
[Epoch 81; Iter   690/  960] train: loss: 0.0023945
[Epoch 81; Iter   720/  960] train: loss: 0.0014620
[Epoch 81; Iter   750/  960] train: loss: 0.0008598
[Epoch 81; Iter   780/  960] train: loss: 0.0672954
[Epoch 81; Iter   810/  960] train: loss: 0.1737199
[Epoch 81; Iter   840/  960] train: loss: 0.0049175
[Epoch 81; Iter   870/  960] train: loss: 0.0030374
[Epoch 81; Iter   900/  960] train: loss: 0.0004663
[Epoch 81; Iter   930/  960] train: loss: 0.0088935
[Epoch 81; Iter   960/  960] train: loss: 0.0024752
[Epoch 81] ogbg-molhiv: 0.724104 val loss: 0.578947
[Epoch 81] ogbg-molhiv: 0.766841 test loss: 0.517991
[Epoch 82; Iter    30/  960] train: loss: 0.0012366
[Epoch 82; Iter    60/  960] train: loss: 0.0300148
[Epoch 82; Iter    90/  960] train: loss: 0.0107564
[Epoch 82; Iter   120/  960] train: loss: 0.0039458
[Epoch 82; Iter   150/  960] train: loss: 0.0073750
[Epoch 82; Iter   180/  960] train: loss: 0.0045644
[Epoch 82; Iter   210/  960] train: loss: 0.0223030
[Epoch 82; Iter   240/  960] train: loss: 0.0044686
[Epoch 82; Iter   270/  960] train: loss: 0.0255969
[Epoch 82; Iter   300/  960] train: loss: 0.0601672
[Epoch 82; Iter   330/  960] train: loss: 0.0147155
[Epoch 82; Iter   360/  960] train: loss: 0.0031476
[Epoch 82; Iter   390/  960] train: loss: 0.0741659
[Epoch 82; Iter   420/  960] train: loss: 0.0067512
[Epoch 82; Iter   450/  960] train: loss: 0.1159270
[Epoch 82; Iter   480/  960] train: loss: 0.0449458
[Epoch 82; Iter   510/  960] train: loss: 0.0305647
[Epoch 82; Iter   540/  960] train: loss: 0.0036637
[Epoch 82; Iter   570/  960] train: loss: 0.0258518
[Epoch 82; Iter   600/  960] train: loss: 0.0007094
[Epoch 82; Iter   630/  960] train: loss: 0.0328901
[Epoch 82; Iter   660/  960] train: loss: 0.0095893
[Epoch 82; Iter   690/  960] train: loss: 0.0664185
[Epoch 82; Iter   720/  960] train: loss: 0.0022632
[Epoch 82; Iter   750/  960] train: loss: 0.0045492
[Epoch 82; Iter   780/  960] train: loss: 0.0405068
[Epoch 82; Iter   810/  960] train: loss: 0.0055337
[Epoch 82; Iter   840/  960] train: loss: 0.0007486
[Epoch 82; Iter   870/  960] train: loss: 0.0067066
[Epoch 78; Iter   270/  960] train: loss: 0.0405223
[Epoch 78; Iter   300/  960] train: loss: 0.0232669
[Epoch 78; Iter   330/  960] train: loss: 0.0144637
[Epoch 78; Iter   360/  960] train: loss: 0.0351469
[Epoch 78; Iter   390/  960] train: loss: 0.0011192
[Epoch 78; Iter   420/  960] train: loss: 0.0090016
[Epoch 78; Iter   450/  960] train: loss: 0.0123579
[Epoch 78; Iter   480/  960] train: loss: 0.0319291
[Epoch 78; Iter   510/  960] train: loss: 0.0182513
[Epoch 78; Iter   540/  960] train: loss: 0.0045398
[Epoch 78; Iter   570/  960] train: loss: 0.0085168
[Epoch 78; Iter   600/  960] train: loss: 0.0130255
[Epoch 78; Iter   630/  960] train: loss: 0.0050546
[Epoch 78; Iter   660/  960] train: loss: 0.0856353
[Epoch 78; Iter   690/  960] train: loss: 0.0013682
[Epoch 78; Iter   720/  960] train: loss: 0.0386837
[Epoch 78; Iter   750/  960] train: loss: 0.0278375
[Epoch 78; Iter   780/  960] train: loss: 0.1160088
[Epoch 78; Iter   810/  960] train: loss: 0.0036012
[Epoch 78; Iter   840/  960] train: loss: 0.1400046
[Epoch 78; Iter   870/  960] train: loss: 0.0103223
[Epoch 78; Iter   900/  960] train: loss: 0.0336938
[Epoch 78; Iter   930/  960] train: loss: 0.0075498
[Epoch 78; Iter   960/  960] train: loss: 0.1357503
[Epoch 78] ogbg-molhiv: 0.752030 val loss: 0.908110
[Epoch 78] ogbg-molhiv: 0.746457 test loss: 0.307565
[Epoch 79; Iter    30/  960] train: loss: 0.0174448
[Epoch 79; Iter    60/  960] train: loss: 0.0044909
[Epoch 79; Iter    90/  960] train: loss: 0.0137543
[Epoch 79; Iter   120/  960] train: loss: 0.0034996
[Epoch 79; Iter   150/  960] train: loss: 0.0285546
[Epoch 79; Iter   180/  960] train: loss: 0.0028944
[Epoch 79; Iter   210/  960] train: loss: 0.0053197
[Epoch 79; Iter   240/  960] train: loss: 0.0325483
[Epoch 79; Iter   270/  960] train: loss: 0.0030346
[Epoch 79; Iter   300/  960] train: loss: 0.0054217
[Epoch 79; Iter   330/  960] train: loss: 0.0025797
[Epoch 79; Iter   360/  960] train: loss: 0.1009323
[Epoch 79; Iter   390/  960] train: loss: 0.0208664
[Epoch 79; Iter   420/  960] train: loss: 0.0020960
[Epoch 79; Iter   450/  960] train: loss: 0.0303199
[Epoch 79; Iter   480/  960] train: loss: 0.0047915
[Epoch 79; Iter   510/  960] train: loss: 0.0221616
[Epoch 79; Iter   540/  960] train: loss: 0.0280261
[Epoch 79; Iter   570/  960] train: loss: 0.0536862
[Epoch 79; Iter   600/  960] train: loss: 0.0204475
[Epoch 79; Iter   630/  960] train: loss: 0.1707638
[Epoch 79; Iter   660/  960] train: loss: 0.0468973
[Epoch 79; Iter   690/  960] train: loss: 0.0378620
[Epoch 79; Iter   720/  960] train: loss: 0.0061085
[Epoch 79; Iter   750/  960] train: loss: 0.0025260
[Epoch 79; Iter   780/  960] train: loss: 0.0242332
[Epoch 79; Iter   810/  960] train: loss: 0.0310348
[Epoch 79; Iter   840/  960] train: loss: 0.0954907
[Epoch 79; Iter   870/  960] train: loss: 0.0472445
[Epoch 79; Iter   900/  960] train: loss: 0.1852875
[Epoch 79; Iter   930/  960] train: loss: 0.0285244
[Epoch 79; Iter   960/  960] train: loss: 0.0019240
[Epoch 79] ogbg-molhiv: 0.755422 val loss: 0.849599
[Epoch 79] ogbg-molhiv: 0.751021 test loss: 0.272977
[Epoch 80; Iter    30/  960] train: loss: 0.0274138
[Epoch 80; Iter    60/  960] train: loss: 0.0043684
[Epoch 80; Iter    90/  960] train: loss: 0.0054468
[Epoch 80; Iter   120/  960] train: loss: 0.0305917
[Epoch 80; Iter   150/  960] train: loss: 0.0056196
[Epoch 80; Iter   180/  960] train: loss: 0.0100945
[Epoch 80; Iter   210/  960] train: loss: 0.0083249
[Epoch 80; Iter   240/  960] train: loss: 0.0181304
[Epoch 80; Iter   270/  960] train: loss: 0.0024166
[Epoch 80; Iter   300/  960] train: loss: 0.0189991
[Epoch 80; Iter   330/  960] train: loss: 0.0035220
[Epoch 80; Iter   360/  960] train: loss: 0.0229561
[Epoch 80; Iter   390/  960] train: loss: 0.0142786
[Epoch 80; Iter   420/  960] train: loss: 0.0659128
[Epoch 80; Iter   450/  960] train: loss: 0.0025750
[Epoch 80; Iter   480/  960] train: loss: 0.0254600
[Epoch 80; Iter   510/  960] train: loss: 0.0413023
[Epoch 80; Iter   540/  960] train: loss: 0.0014400
[Epoch 80; Iter   570/  960] train: loss: 0.0753634
[Epoch 80; Iter   600/  960] train: loss: 0.0037592
[Epoch 80; Iter   630/  960] train: loss: 0.0335335
[Epoch 80; Iter   660/  960] train: loss: 0.0015444
[Epoch 80; Iter   690/  960] train: loss: 0.0266083
[Epoch 80; Iter   720/  960] train: loss: 0.0468921
[Epoch 80; Iter   750/  960] train: loss: 0.0211486
[Epoch 80; Iter   780/  960] train: loss: 0.0190845
[Epoch 80; Iter   810/  960] train: loss: 0.0468415
[Epoch 80; Iter   840/  960] train: loss: 0.0050784
[Epoch 80; Iter   870/  960] train: loss: 0.0051602
[Epoch 80; Iter   900/  960] train: loss: 0.0944740
[Epoch 80; Iter   930/  960] train: loss: 0.0230897
[Epoch 80; Iter   960/  960] train: loss: 0.0073696
[Epoch 80] ogbg-molhiv: 0.742536 val loss: 0.573882
[Epoch 80] ogbg-molhiv: 0.754136 test loss: 0.194836
[Epoch 81; Iter    30/  960] train: loss: 0.1786073
[Epoch 81; Iter    60/  960] train: loss: 0.0319826
[Epoch 81; Iter    90/  960] train: loss: 0.0122078
[Epoch 81; Iter   120/  960] train: loss: 0.0103922
[Epoch 81; Iter   150/  960] train: loss: 0.0189045
[Epoch 81; Iter   180/  960] train: loss: 0.0039541
[Epoch 81; Iter   210/  960] train: loss: 0.0087413
[Epoch 81; Iter   240/  960] train: loss: 0.0357489
[Epoch 81; Iter   270/  960] train: loss: 0.0026124
[Epoch 81; Iter   300/  960] train: loss: 0.0071574
[Epoch 81; Iter   330/  960] train: loss: 0.0031638
[Epoch 81; Iter   360/  960] train: loss: 0.0246572
[Epoch 81; Iter   390/  960] train: loss: 0.2076748
[Epoch 81; Iter   420/  960] train: loss: 0.0277281
[Epoch 81; Iter   450/  960] train: loss: 0.0079168
[Epoch 81; Iter   480/  960] train: loss: 0.0115557
[Epoch 81; Iter   510/  960] train: loss: 0.0077097
[Epoch 81; Iter   540/  960] train: loss: 0.1868377
[Epoch 81; Iter   570/  960] train: loss: 0.0450635
[Epoch 81; Iter   600/  960] train: loss: 0.0038733
[Epoch 81; Iter   630/  960] train: loss: 0.0037845
[Epoch 81; Iter   660/  960] train: loss: 0.0019000
[Epoch 81; Iter   690/  960] train: loss: 0.0054091
[Epoch 81; Iter   720/  960] train: loss: 0.0843536
[Epoch 81; Iter   750/  960] train: loss: 0.0032749
[Epoch 81; Iter   780/  960] train: loss: 0.0584417
[Epoch 81; Iter   810/  960] train: loss: 0.0094948
[Epoch 81; Iter   840/  960] train: loss: 0.0155483
[Epoch 81; Iter   870/  960] train: loss: 0.0555843
[Epoch 81; Iter   900/  960] train: loss: 0.0040669
[Epoch 81; Iter   930/  960] train: loss: 0.0159946
[Epoch 81; Iter   960/  960] train: loss: 0.0214539
[Epoch 81] ogbg-molhiv: 0.748865 val loss: 0.640144
[Epoch 81] ogbg-molhiv: 0.750630 test loss: 0.230345
[Epoch 82; Iter    30/  960] train: loss: 0.0139137
[Epoch 82; Iter    60/  960] train: loss: 0.0097257
[Epoch 82; Iter    90/  960] train: loss: 0.0161139
[Epoch 82; Iter   120/  960] train: loss: 0.0065757
[Epoch 82; Iter   150/  960] train: loss: 0.0007072
[Epoch 82; Iter   180/  960] train: loss: 0.0718993
[Epoch 82; Iter   210/  960] train: loss: 0.0025276
[Epoch 82; Iter   240/  960] train: loss: 0.0331036
[Epoch 82; Iter   270/  960] train: loss: 0.0748598
[Epoch 82; Iter   300/  960] train: loss: 0.0730755
[Epoch 82; Iter   330/  960] train: loss: 0.0410472
[Epoch 82; Iter   360/  960] train: loss: 0.0078075
[Epoch 82; Iter   390/  960] train: loss: 0.0137836
[Epoch 82; Iter   420/  960] train: loss: 0.0107159
[Epoch 82; Iter   450/  960] train: loss: 0.0373812
[Epoch 82; Iter   480/  960] train: loss: 0.0185579
[Epoch 82; Iter   510/  960] train: loss: 0.0057412
[Epoch 82; Iter   540/  960] train: loss: 0.0041810
[Epoch 82; Iter   570/  960] train: loss: 0.0017563
[Epoch 82; Iter   600/  960] train: loss: 0.0359488
[Epoch 82; Iter   630/  960] train: loss: 0.0424453
[Epoch 82; Iter   660/  960] train: loss: 0.0016992
[Epoch 82; Iter   690/  960] train: loss: 0.0072308
[Epoch 82; Iter   720/  960] train: loss: 0.0252777
[Epoch 82; Iter   750/  960] train: loss: 0.0967077
[Epoch 82; Iter   780/  960] train: loss: 0.0049960
[Epoch 82; Iter   810/  960] train: loss: 0.0344539
[Epoch 82; Iter   840/  960] train: loss: 0.0137438
[Epoch 82; Iter   870/  960] train: loss: 0.0613794
[Epoch 78; Iter   270/  960] train: loss: 0.0558147
[Epoch 78; Iter   300/  960] train: loss: 0.0112242
[Epoch 78; Iter   330/  960] train: loss: 0.0477326
[Epoch 78; Iter   360/  960] train: loss: 0.0054885
[Epoch 78; Iter   390/  960] train: loss: 0.0450287
[Epoch 78; Iter   420/  960] train: loss: 0.0891625
[Epoch 78; Iter   450/  960] train: loss: 0.1168952
[Epoch 78; Iter   480/  960] train: loss: 0.0399814
[Epoch 78; Iter   510/  960] train: loss: 0.0284163
[Epoch 78; Iter   540/  960] train: loss: 0.0138691
[Epoch 78; Iter   570/  960] train: loss: 0.0029133
[Epoch 78; Iter   600/  960] train: loss: 0.0169833
[Epoch 78; Iter   630/  960] train: loss: 0.0064669
[Epoch 78; Iter   660/  960] train: loss: 0.0137503
[Epoch 78; Iter   690/  960] train: loss: 0.0085321
[Epoch 78; Iter   720/  960] train: loss: 0.0192850
[Epoch 78; Iter   750/  960] train: loss: 0.0169994
[Epoch 78; Iter   780/  960] train: loss: 0.1008590
[Epoch 78; Iter   810/  960] train: loss: 0.0721862
[Epoch 78; Iter   840/  960] train: loss: 0.0065356
[Epoch 78; Iter   870/  960] train: loss: 0.0218072
[Epoch 78; Iter   900/  960] train: loss: 0.0104739
[Epoch 78; Iter   930/  960] train: loss: 0.0139154
[Epoch 78; Iter   960/  960] train: loss: 0.0396589
[Epoch 78] ogbg-molhiv: 0.717307 val loss: 0.410201
[Epoch 78] ogbg-molhiv: 0.758374 test loss: 0.239286
[Epoch 79; Iter    30/  960] train: loss: 0.0628837
[Epoch 79; Iter    60/  960] train: loss: 0.0369019
[Epoch 79; Iter    90/  960] train: loss: 0.0155638
[Epoch 79; Iter   120/  960] train: loss: 0.0159195
[Epoch 79; Iter   150/  960] train: loss: 0.0227370
[Epoch 79; Iter   180/  960] train: loss: 0.0395237
[Epoch 79; Iter   210/  960] train: loss: 0.0045593
[Epoch 79; Iter   240/  960] train: loss: 0.0231902
[Epoch 79; Iter   270/  960] train: loss: 0.0203191
[Epoch 79; Iter   300/  960] train: loss: 0.0060578
[Epoch 79; Iter   330/  960] train: loss: 0.0436181
[Epoch 79; Iter   360/  960] train: loss: 0.0273139
[Epoch 79; Iter   390/  960] train: loss: 0.0283628
[Epoch 79; Iter   420/  960] train: loss: 0.1074334
[Epoch 79; Iter   450/  960] train: loss: 0.0073081
[Epoch 79; Iter   480/  960] train: loss: 0.0241160
[Epoch 79; Iter   510/  960] train: loss: 0.0486578
[Epoch 79; Iter   540/  960] train: loss: 0.0145070
[Epoch 79; Iter   570/  960] train: loss: 0.1154569
[Epoch 79; Iter   600/  960] train: loss: 0.0247610
[Epoch 79; Iter   630/  960] train: loss: 0.0142570
[Epoch 79; Iter   660/  960] train: loss: 0.2257524
[Epoch 79; Iter   690/  960] train: loss: 0.0704633
[Epoch 79; Iter   720/  960] train: loss: 0.0202403
[Epoch 79; Iter   750/  960] train: loss: 0.1098570
[Epoch 79; Iter   780/  960] train: loss: 0.0498936
[Epoch 79; Iter   810/  960] train: loss: 0.0282866
[Epoch 79; Iter   840/  960] train: loss: 0.0283981
[Epoch 79; Iter   870/  960] train: loss: 0.0046483
[Epoch 79; Iter   900/  960] train: loss: 0.0064063
[Epoch 79; Iter   930/  960] train: loss: 0.0185802
[Epoch 79; Iter   960/  960] train: loss: 0.0022322
[Epoch 79] ogbg-molhiv: 0.716668 val loss: 0.758802
[Epoch 79] ogbg-molhiv: 0.752506 test loss: 0.569409
[Epoch 80; Iter    30/  960] train: loss: 0.0050139
[Epoch 80; Iter    60/  960] train: loss: 0.0446864
[Epoch 80; Iter    90/  960] train: loss: 0.0063992
[Epoch 80; Iter   120/  960] train: loss: 0.0026416
[Epoch 80; Iter   150/  960] train: loss: 0.0103544
[Epoch 80; Iter   180/  960] train: loss: 0.0945545
[Epoch 80; Iter   210/  960] train: loss: 0.0201522
[Epoch 80; Iter   240/  960] train: loss: 0.0203636
[Epoch 80; Iter   270/  960] train: loss: 0.0642912
[Epoch 80; Iter   300/  960] train: loss: 0.0076234
[Epoch 80; Iter   330/  960] train: loss: 0.0138442
[Epoch 80; Iter   360/  960] train: loss: 0.0011608
[Epoch 80; Iter   390/  960] train: loss: 0.0096358
[Epoch 80; Iter   420/  960] train: loss: 0.0302777
[Epoch 80; Iter   450/  960] train: loss: 0.0290546
[Epoch 80; Iter   480/  960] train: loss: 0.0206655
[Epoch 80; Iter   510/  960] train: loss: 0.0097168
[Epoch 80; Iter   540/  960] train: loss: 0.0424470
[Epoch 80; Iter   570/  960] train: loss: 0.0226640
[Epoch 80; Iter   600/  960] train: loss: 0.0088373
[Epoch 80; Iter   630/  960] train: loss: 0.0189504
[Epoch 80; Iter   660/  960] train: loss: 0.0283317
[Epoch 80; Iter   690/  960] train: loss: 0.0558384
[Epoch 80; Iter   720/  960] train: loss: 0.0293292
[Epoch 80; Iter   750/  960] train: loss: 0.0040282
[Epoch 80; Iter   780/  960] train: loss: 0.0907946
[Epoch 80; Iter   810/  960] train: loss: 0.0441441
[Epoch 80; Iter   840/  960] train: loss: 0.0045521
[Epoch 80; Iter   870/  960] train: loss: 0.0089310
[Epoch 80; Iter   900/  960] train: loss: 0.0020286
[Epoch 80; Iter   930/  960] train: loss: 0.0422247
[Epoch 80; Iter   960/  960] train: loss: 0.0471766
[Epoch 80] ogbg-molhiv: 0.719433 val loss: 0.709069
[Epoch 80] ogbg-molhiv: 0.750239 test loss: 0.454733
[Epoch 81; Iter    30/  960] train: loss: 0.0506159
[Epoch 81; Iter    60/  960] train: loss: 0.0072602
[Epoch 81; Iter    90/  960] train: loss: 0.0187812
[Epoch 81; Iter   120/  960] train: loss: 0.0059453
[Epoch 81; Iter   150/  960] train: loss: 0.0096284
[Epoch 81; Iter   180/  960] train: loss: 0.0448105
[Epoch 81; Iter   210/  960] train: loss: 0.0236707
[Epoch 81; Iter   240/  960] train: loss: 0.0347281
[Epoch 81; Iter   270/  960] train: loss: 0.0274013
[Epoch 81; Iter   300/  960] train: loss: 0.0031983
[Epoch 81; Iter   330/  960] train: loss: 0.0823299
[Epoch 81; Iter   360/  960] train: loss: 0.0277166
[Epoch 81; Iter   390/  960] train: loss: 0.0110949
[Epoch 81; Iter   420/  960] train: loss: 0.0095969
[Epoch 81; Iter   450/  960] train: loss: 0.0931201
[Epoch 81; Iter   480/  960] train: loss: 0.0945737
[Epoch 81; Iter   510/  960] train: loss: 0.0115195
[Epoch 81; Iter   540/  960] train: loss: 0.1626398
[Epoch 81; Iter   570/  960] train: loss: 0.0027135
[Epoch 81; Iter   600/  960] train: loss: 0.0099299
[Epoch 81; Iter   630/  960] train: loss: 0.0050696
[Epoch 81; Iter   660/  960] train: loss: 0.0245604
[Epoch 81; Iter   690/  960] train: loss: 0.0241862
[Epoch 81; Iter   720/  960] train: loss: 0.0015803
[Epoch 81; Iter   750/  960] train: loss: 0.0095827
[Epoch 81; Iter   780/  960] train: loss: 0.0565707
[Epoch 81; Iter   810/  960] train: loss: 0.1205601
[Epoch 81; Iter   840/  960] train: loss: 0.0572980
[Epoch 81; Iter   870/  960] train: loss: 0.1410740
[Epoch 81; Iter   900/  960] train: loss: 0.0203765
[Epoch 81; Iter   930/  960] train: loss: 0.0270339
[Epoch 81; Iter   960/  960] train: loss: 0.0020862
[Epoch 81] ogbg-molhiv: 0.721639 val loss: 1.091968
[Epoch 81] ogbg-molhiv: 0.744658 test loss: 0.664972
[Epoch 82; Iter    30/  960] train: loss: 0.0006971
[Epoch 82; Iter    60/  960] train: loss: 0.0063833
[Epoch 82; Iter    90/  960] train: loss: 0.0168699
[Epoch 82; Iter   120/  960] train: loss: 0.0053284
[Epoch 82; Iter   150/  960] train: loss: 0.0532590
[Epoch 82; Iter   180/  960] train: loss: 0.0189316
[Epoch 82; Iter   210/  960] train: loss: 0.0075421
[Epoch 82; Iter   240/  960] train: loss: 0.0164165
[Epoch 82; Iter   270/  960] train: loss: 0.0094327
[Epoch 82; Iter   300/  960] train: loss: 0.0718582
[Epoch 82; Iter   330/  960] train: loss: 0.0072750
[Epoch 82; Iter   360/  960] train: loss: 0.0123839
[Epoch 82; Iter   390/  960] train: loss: 0.0031255
[Epoch 82; Iter   420/  960] train: loss: 0.0029699
[Epoch 82; Iter   450/  960] train: loss: 0.0075731
[Epoch 82; Iter   480/  960] train: loss: 0.0106924
[Epoch 82; Iter   510/  960] train: loss: 0.0842176
[Epoch 82; Iter   540/  960] train: loss: 0.0055208
[Epoch 82; Iter   570/  960] train: loss: 0.0210326
[Epoch 82; Iter   600/  960] train: loss: 0.0309026
[Epoch 82; Iter   630/  960] train: loss: 0.0052173
[Epoch 82; Iter   660/  960] train: loss: 0.0066310
[Epoch 82; Iter   690/  960] train: loss: 0.0289371
[Epoch 82; Iter   720/  960] train: loss: 0.0081841
[Epoch 82; Iter   750/  960] train: loss: 0.0020068
[Epoch 82; Iter   780/  960] train: loss: 0.0121112
[Epoch 82; Iter   810/  960] train: loss: 0.0388709
[Epoch 82; Iter   840/  960] train: loss: 0.0083037
[Epoch 82; Iter   870/  960] train: loss: 0.0467146
[Epoch 79; Iter   486/  823] train: loss: 0.0270659
[Epoch 79; Iter   516/  823] train: loss: 0.0901221
[Epoch 79; Iter   546/  823] train: loss: 0.0010243
[Epoch 79; Iter   576/  823] train: loss: 0.2027873
[Epoch 79; Iter   606/  823] train: loss: 0.0301884
[Epoch 79; Iter   636/  823] train: loss: 0.0020484
[Epoch 79; Iter   666/  823] train: loss: 0.0039034
[Epoch 79; Iter   696/  823] train: loss: 0.0237787
[Epoch 79; Iter   726/  823] train: loss: 0.0006520
[Epoch 79; Iter   756/  823] train: loss: 0.0008802
[Epoch 79; Iter   786/  823] train: loss: 0.0177806
[Epoch 79; Iter   816/  823] train: loss: 0.0019446
[Epoch 79] ogbg-molhiv: 0.744435 val loss: 0.281508
[Epoch 79] ogbg-molhiv: 0.763634 test loss: 0.224552
[Epoch 80; Iter    23/  823] train: loss: 0.0015107
[Epoch 80; Iter    53/  823] train: loss: 0.0364287
[Epoch 80; Iter    83/  823] train: loss: 0.0016802
[Epoch 80; Iter   113/  823] train: loss: 0.0060981
[Epoch 80; Iter   143/  823] train: loss: 0.0054774
[Epoch 80; Iter   173/  823] train: loss: 0.0015358
[Epoch 80; Iter   203/  823] train: loss: 0.0020676
[Epoch 80; Iter   233/  823] train: loss: 0.0659233
[Epoch 80; Iter   263/  823] train: loss: 0.0027719
[Epoch 80; Iter   293/  823] train: loss: 0.3167363
[Epoch 80; Iter   323/  823] train: loss: 0.0076516
[Epoch 80; Iter   353/  823] train: loss: 0.0087597
[Epoch 80; Iter   383/  823] train: loss: 0.0018019
[Epoch 80; Iter   413/  823] train: loss: 0.0014308
[Epoch 80; Iter   443/  823] train: loss: 0.0152145
[Epoch 80; Iter   473/  823] train: loss: 0.0021053
[Epoch 80; Iter   503/  823] train: loss: 0.0016773
[Epoch 80; Iter   533/  823] train: loss: 0.0011101
[Epoch 80; Iter   563/  823] train: loss: 0.0406520
[Epoch 80; Iter   593/  823] train: loss: 0.0049063
[Epoch 80; Iter   623/  823] train: loss: 0.0840722
[Epoch 80; Iter   653/  823] train: loss: 0.0017660
[Epoch 80; Iter   683/  823] train: loss: 0.0095923
[Epoch 80; Iter   713/  823] train: loss: 0.0218666
[Epoch 80; Iter   743/  823] train: loss: 0.0287725
[Epoch 80; Iter   773/  823] train: loss: 0.0849777
[Epoch 80; Iter   803/  823] train: loss: 0.0028851
[Epoch 80] ogbg-molhiv: 0.741152 val loss: 0.300388
[Epoch 80] ogbg-molhiv: 0.762524 test loss: 0.234582
[Epoch 81; Iter    10/  823] train: loss: 0.0039929
[Epoch 81; Iter    40/  823] train: loss: 0.0008528
[Epoch 81; Iter    70/  823] train: loss: 0.0134476
[Epoch 81; Iter   100/  823] train: loss: 0.0313425
[Epoch 81; Iter   130/  823] train: loss: 0.0152001
[Epoch 81; Iter   160/  823] train: loss: 0.0061036
[Epoch 81; Iter   190/  823] train: loss: 0.0030909
[Epoch 81; Iter   220/  823] train: loss: 0.0047473
[Epoch 81; Iter   250/  823] train: loss: 0.0099101
[Epoch 81; Iter   280/  823] train: loss: 0.0163486
[Epoch 81; Iter   310/  823] train: loss: 0.0171832
[Epoch 81; Iter   340/  823] train: loss: 0.0210514
[Epoch 81; Iter   370/  823] train: loss: 0.0187611
[Epoch 81; Iter   400/  823] train: loss: 0.0808625
[Epoch 81; Iter   430/  823] train: loss: 0.0040134
[Epoch 81; Iter   460/  823] train: loss: 0.0789384
[Epoch 81; Iter   490/  823] train: loss: 0.0261305
[Epoch 81; Iter   520/  823] train: loss: 0.0210270
[Epoch 81; Iter   550/  823] train: loss: 0.2290892
[Epoch 81; Iter   580/  823] train: loss: 0.0117096
[Epoch 81; Iter   610/  823] train: loss: 0.0179058
[Epoch 81; Iter   640/  823] train: loss: 0.0252924
[Epoch 81; Iter   670/  823] train: loss: 0.0101036
[Epoch 81; Iter   700/  823] train: loss: 0.0024113
[Epoch 81; Iter   730/  823] train: loss: 0.0024116
[Epoch 81; Iter   760/  823] train: loss: 0.0321116
[Epoch 81; Iter   790/  823] train: loss: 0.0039474
[Epoch 81; Iter   820/  823] train: loss: 0.0239189
[Epoch 81] ogbg-molhiv: 0.736799 val loss: 0.287021
[Epoch 81] ogbg-molhiv: 0.760167 test loss: 0.219133
[Epoch 82; Iter    27/  823] train: loss: 0.0062234
[Epoch 82; Iter    57/  823] train: loss: 0.0083033
[Epoch 82; Iter    87/  823] train: loss: 0.0089347
[Epoch 82; Iter   117/  823] train: loss: 0.0108274
[Epoch 82; Iter   147/  823] train: loss: 0.0870357
[Epoch 82; Iter   177/  823] train: loss: 0.0398922
[Epoch 82; Iter   207/  823] train: loss: 0.0273007
[Epoch 82; Iter   237/  823] train: loss: 0.0206980
[Epoch 82; Iter   267/  823] train: loss: 0.0755029
[Epoch 82; Iter   297/  823] train: loss: 0.0107177
[Epoch 82; Iter   327/  823] train: loss: 0.0034504
[Epoch 82; Iter   357/  823] train: loss: 0.0022944
[Epoch 82; Iter   387/  823] train: loss: 0.0803489
[Epoch 82; Iter   417/  823] train: loss: 0.0010230
[Epoch 82; Iter   447/  823] train: loss: 0.0044991
[Epoch 82; Iter   477/  823] train: loss: 0.0128256
[Epoch 82; Iter   507/  823] train: loss: 0.0021556
[Epoch 82; Iter   537/  823] train: loss: 0.0056537
[Epoch 82; Iter   567/  823] train: loss: 0.0025248
[Epoch 82; Iter   597/  823] train: loss: 0.0015080
[Epoch 82; Iter   627/  823] train: loss: 0.0154572
[Epoch 82; Iter   657/  823] train: loss: 0.0612140
[Epoch 82; Iter   687/  823] train: loss: 0.0007622
[Epoch 82; Iter   717/  823] train: loss: 0.0065400
[Epoch 82; Iter   747/  823] train: loss: 0.0199698
[Epoch 82; Iter   777/  823] train: loss: 0.0007051
[Epoch 82; Iter   807/  823] train: loss: 0.2307804
[Epoch 82] ogbg-molhiv: 0.745874 val loss: 0.323766
[Epoch 82] ogbg-molhiv: 0.772149 test loss: 0.289346
[Epoch 83; Iter    14/  823] train: loss: 0.0106006
[Epoch 83; Iter    44/  823] train: loss: 0.0870041
[Epoch 83; Iter    74/  823] train: loss: 0.0310283
[Epoch 83; Iter   104/  823] train: loss: 0.0010809
[Epoch 83; Iter   134/  823] train: loss: 0.0247329
[Epoch 83; Iter   164/  823] train: loss: 0.0022242
[Epoch 83; Iter   194/  823] train: loss: 0.0061924
[Epoch 83; Iter   224/  823] train: loss: 0.1552446
[Epoch 83; Iter   254/  823] train: loss: 0.0007607
[Epoch 83; Iter   284/  823] train: loss: 0.0287742
[Epoch 83; Iter   314/  823] train: loss: 0.0258997
[Epoch 83; Iter   344/  823] train: loss: 0.0259169
[Epoch 83; Iter   374/  823] train: loss: 0.0186221
[Epoch 83; Iter   404/  823] train: loss: 0.0094413
[Epoch 83; Iter   434/  823] train: loss: 0.0026792
[Epoch 83; Iter   464/  823] train: loss: 0.0009557
[Epoch 83; Iter   494/  823] train: loss: 0.0090867
[Epoch 83; Iter   524/  823] train: loss: 0.0084277
[Epoch 83; Iter   554/  823] train: loss: 0.0417562
[Epoch 83; Iter   584/  823] train: loss: 0.0171815
[Epoch 83; Iter   614/  823] train: loss: 0.0529529
[Epoch 83; Iter   644/  823] train: loss: 0.0281977
[Epoch 83; Iter   674/  823] train: loss: 0.1109791
[Epoch 83; Iter   704/  823] train: loss: 0.0014814
[Epoch 83; Iter   734/  823] train: loss: 0.0336709
[Epoch 83; Iter   764/  823] train: loss: 0.0568722
[Epoch 83; Iter   794/  823] train: loss: 0.0075489
[Epoch 83] ogbg-molhiv: 0.736310 val loss: 0.273357
[Epoch 83] ogbg-molhiv: 0.767223 test loss: 0.209293
[Epoch 84; Iter     1/  823] train: loss: 0.0257933
[Epoch 84; Iter    31/  823] train: loss: 0.0033266
[Epoch 84; Iter    61/  823] train: loss: 0.0095916
[Epoch 84; Iter    91/  823] train: loss: 0.0085346
[Epoch 84; Iter   121/  823] train: loss: 0.0059865
[Epoch 84; Iter   151/  823] train: loss: 0.0099180
[Epoch 84; Iter   181/  823] train: loss: 0.0005355
[Epoch 84; Iter   211/  823] train: loss: 0.0121278
[Epoch 84; Iter   241/  823] train: loss: 0.0030771
[Epoch 84; Iter   271/  823] train: loss: 0.0162981
[Epoch 84; Iter   301/  823] train: loss: 0.0728180
[Epoch 84; Iter   331/  823] train: loss: 0.0143654
[Epoch 84; Iter   361/  823] train: loss: 0.0523546
[Epoch 84; Iter   391/  823] train: loss: 0.0022918
[Epoch 84; Iter   421/  823] train: loss: 0.1535331
[Epoch 84; Iter   451/  823] train: loss: 0.0003236
[Epoch 84; Iter   481/  823] train: loss: 0.0035760
[Epoch 84; Iter   511/  823] train: loss: 0.0292816
[Epoch 84; Iter   541/  823] train: loss: 0.0040634
[Epoch 84; Iter   571/  823] train: loss: 0.0048609
[Epoch 84; Iter   601/  823] train: loss: 0.0239990
[Epoch 84; Iter   631/  823] train: loss: 0.0419299
[Epoch 84; Iter   661/  823] train: loss: 0.0284224
[Epoch 84; Iter   691/  823] train: loss: 0.0468019
[Epoch 84; Iter   721/  823] train: loss: 0.0008585
[Epoch 84; Iter   751/  823] train: loss: 0.1436394
[Epoch 77; Iter   298/ 1097] train: loss: 0.0122863
[Epoch 77; Iter   328/ 1097] train: loss: 0.0184184
[Epoch 77; Iter   358/ 1097] train: loss: 0.0059939
[Epoch 77; Iter   388/ 1097] train: loss: 0.0056104
[Epoch 77; Iter   418/ 1097] train: loss: 0.0045027
[Epoch 77; Iter   448/ 1097] train: loss: 0.0054910
[Epoch 77; Iter   478/ 1097] train: loss: 0.0296513
[Epoch 77; Iter   508/ 1097] train: loss: 0.0086260
[Epoch 77; Iter   538/ 1097] train: loss: 0.0854721
[Epoch 77; Iter   568/ 1097] train: loss: 0.0114992
[Epoch 77; Iter   598/ 1097] train: loss: 0.0784750
[Epoch 77; Iter   628/ 1097] train: loss: 0.0189169
[Epoch 77; Iter   658/ 1097] train: loss: 0.0050651
[Epoch 77; Iter   688/ 1097] train: loss: 0.1216567
[Epoch 77; Iter   718/ 1097] train: loss: 0.0662908
[Epoch 77; Iter   748/ 1097] train: loss: 0.0289532
[Epoch 77; Iter   778/ 1097] train: loss: 0.0375317
[Epoch 77; Iter   808/ 1097] train: loss: 0.0113453
[Epoch 77; Iter   838/ 1097] train: loss: 0.0063120
[Epoch 77; Iter   868/ 1097] train: loss: 0.0048908
[Epoch 77; Iter   898/ 1097] train: loss: 0.0128939
[Epoch 77; Iter   928/ 1097] train: loss: 0.0399051
[Epoch 77; Iter   958/ 1097] train: loss: 0.0342910
[Epoch 77; Iter   988/ 1097] train: loss: 0.0039250
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0046129
[Epoch 77; Iter  1048/ 1097] train: loss: 0.1127585
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0283129
[Epoch 77] ogbg-molhiv: 0.764654 val loss: 0.122699
[Epoch 77] ogbg-molhiv: 0.727783 test loss: 0.236205
[Epoch 78; Iter    11/ 1097] train: loss: 0.0087659
[Epoch 78; Iter    41/ 1097] train: loss: 0.0708217
[Epoch 78; Iter    71/ 1097] train: loss: 0.0118678
[Epoch 78; Iter   101/ 1097] train: loss: 0.0981269
[Epoch 78; Iter   131/ 1097] train: loss: 0.0905325
[Epoch 78; Iter   161/ 1097] train: loss: 0.0074438
[Epoch 78; Iter   191/ 1097] train: loss: 0.0797218
[Epoch 78; Iter   221/ 1097] train: loss: 0.0692272
[Epoch 78; Iter   251/ 1097] train: loss: 0.0079787
[Epoch 78; Iter   281/ 1097] train: loss: 0.0774090
[Epoch 78; Iter   311/ 1097] train: loss: 0.0636947
[Epoch 78; Iter   341/ 1097] train: loss: 0.0737022
[Epoch 78; Iter   371/ 1097] train: loss: 0.0134591
[Epoch 78; Iter   401/ 1097] train: loss: 0.0054086
[Epoch 78; Iter   431/ 1097] train: loss: 0.0237913
[Epoch 78; Iter   461/ 1097] train: loss: 0.1255457
[Epoch 78; Iter   491/ 1097] train: loss: 0.0601959
[Epoch 78; Iter   521/ 1097] train: loss: 0.0612118
[Epoch 78; Iter   551/ 1097] train: loss: 0.0092767
[Epoch 78; Iter   581/ 1097] train: loss: 0.0046616
[Epoch 78; Iter   611/ 1097] train: loss: 0.0169361
[Epoch 78; Iter   641/ 1097] train: loss: 0.0079182
[Epoch 78; Iter   671/ 1097] train: loss: 0.0080816
[Epoch 78; Iter   701/ 1097] train: loss: 0.0035632
[Epoch 78; Iter   731/ 1097] train: loss: 0.0229445
[Epoch 78; Iter   761/ 1097] train: loss: 0.0059970
[Epoch 78; Iter   791/ 1097] train: loss: 0.0775653
[Epoch 78; Iter   821/ 1097] train: loss: 0.0125438
[Epoch 78; Iter   851/ 1097] train: loss: 0.0249089
[Epoch 78; Iter   881/ 1097] train: loss: 0.0794485
[Epoch 78; Iter   911/ 1097] train: loss: 0.0233611
[Epoch 78; Iter   941/ 1097] train: loss: 0.0389144
[Epoch 78; Iter   971/ 1097] train: loss: 0.0135702
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0020758
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0065984
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0033594
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0280925
[Epoch 78] ogbg-molhiv: 0.765426 val loss: 0.786171
[Epoch 78] ogbg-molhiv: 0.732762 test loss: 1.228155
[Epoch 79; Iter    24/ 1097] train: loss: 0.0444421
[Epoch 79; Iter    54/ 1097] train: loss: 0.0126972
[Epoch 79; Iter    84/ 1097] train: loss: 0.0910015
[Epoch 79; Iter   114/ 1097] train: loss: 0.0427931
[Epoch 79; Iter   144/ 1097] train: loss: 0.0064517
[Epoch 79; Iter   174/ 1097] train: loss: 0.0023576
[Epoch 79; Iter   204/ 1097] train: loss: 0.0162906
[Epoch 79; Iter   234/ 1097] train: loss: 0.0040334
[Epoch 79; Iter   264/ 1097] train: loss: 0.0189764
[Epoch 79; Iter   294/ 1097] train: loss: 0.0808434
[Epoch 79; Iter   324/ 1097] train: loss: 0.0028575
[Epoch 79; Iter   354/ 1097] train: loss: 0.0329927
[Epoch 79; Iter   384/ 1097] train: loss: 0.2083492
[Epoch 79; Iter   414/ 1097] train: loss: 0.0827764
[Epoch 79; Iter   444/ 1097] train: loss: 0.0176828
[Epoch 79; Iter   474/ 1097] train: loss: 0.0124443
[Epoch 79; Iter   504/ 1097] train: loss: 0.0228874
[Epoch 79; Iter   534/ 1097] train: loss: 0.0075987
[Epoch 79; Iter   564/ 1097] train: loss: 0.0015372
[Epoch 79; Iter   594/ 1097] train: loss: 0.0648231
[Epoch 79; Iter   624/ 1097] train: loss: 0.1738043
[Epoch 79; Iter   654/ 1097] train: loss: 0.0580120
[Epoch 79; Iter   684/ 1097] train: loss: 0.1420874
[Epoch 79; Iter   714/ 1097] train: loss: 0.0544057
[Epoch 79; Iter   744/ 1097] train: loss: 0.0199605
[Epoch 79; Iter   774/ 1097] train: loss: 0.0229698
[Epoch 79; Iter   804/ 1097] train: loss: 0.0097357
[Epoch 79; Iter   834/ 1097] train: loss: 0.0099224
[Epoch 79; Iter   864/ 1097] train: loss: 0.0195535
[Epoch 79; Iter   894/ 1097] train: loss: 0.0542648
[Epoch 79; Iter   924/ 1097] train: loss: 0.0159305
[Epoch 79; Iter   954/ 1097] train: loss: 0.0149333
[Epoch 79; Iter   984/ 1097] train: loss: 0.0125218
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0040030
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0025585
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0097416
[Epoch 79] ogbg-molhiv: 0.765968 val loss: 0.153932
[Epoch 79] ogbg-molhiv: 0.736582 test loss: 0.395521
[Epoch 80; Iter     7/ 1097] train: loss: 0.0158372
[Epoch 80; Iter    37/ 1097] train: loss: 0.0512972
[Epoch 80; Iter    67/ 1097] train: loss: 0.0046997
[Epoch 80; Iter    97/ 1097] train: loss: 0.1205291
[Epoch 80; Iter   127/ 1097] train: loss: 0.0227918
[Epoch 80; Iter   157/ 1097] train: loss: 0.0123197
[Epoch 80; Iter   187/ 1097] train: loss: 0.0418037
[Epoch 80; Iter   217/ 1097] train: loss: 0.0141716
[Epoch 80; Iter   247/ 1097] train: loss: 0.0223197
[Epoch 80; Iter   277/ 1097] train: loss: 0.0099026
[Epoch 80; Iter   307/ 1097] train: loss: 0.0069682
[Epoch 80; Iter   337/ 1097] train: loss: 0.0082239
[Epoch 80; Iter   367/ 1097] train: loss: 0.0500147
[Epoch 80; Iter   397/ 1097] train: loss: 0.0142127
[Epoch 80; Iter   427/ 1097] train: loss: 0.0018972
[Epoch 80; Iter   457/ 1097] train: loss: 0.0029721
[Epoch 80; Iter   487/ 1097] train: loss: 0.0465462
[Epoch 80; Iter   517/ 1097] train: loss: 0.0066265
[Epoch 80; Iter   547/ 1097] train: loss: 0.1404062
[Epoch 80; Iter   577/ 1097] train: loss: 0.0109664
[Epoch 80; Iter   607/ 1097] train: loss: 0.0382204
[Epoch 80; Iter   637/ 1097] train: loss: 0.0231059
[Epoch 80; Iter   667/ 1097] train: loss: 0.0264919
[Epoch 80; Iter   697/ 1097] train: loss: 0.0345032
[Epoch 80; Iter   727/ 1097] train: loss: 0.0207465
[Epoch 80; Iter   757/ 1097] train: loss: 0.0088852
[Epoch 80; Iter   787/ 1097] train: loss: 0.0088163
[Epoch 80; Iter   817/ 1097] train: loss: 0.0061171
[Epoch 80; Iter   847/ 1097] train: loss: 0.0141253
[Epoch 80; Iter   877/ 1097] train: loss: 0.0097241
[Epoch 80; Iter   907/ 1097] train: loss: 0.0197517
[Epoch 80; Iter   937/ 1097] train: loss: 0.0336237
[Epoch 80; Iter   967/ 1097] train: loss: 0.0020086
[Epoch 80; Iter   997/ 1097] train: loss: 0.0090556
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0266662
[Epoch 80; Iter  1057/ 1097] train: loss: 0.1322865
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0162023
[Epoch 80] ogbg-molhiv: 0.770515 val loss: 0.200192
[Epoch 80] ogbg-molhiv: 0.728504 test loss: 0.380366
[Epoch 81; Iter    20/ 1097] train: loss: 0.1373615
[Epoch 81; Iter    50/ 1097] train: loss: 0.0486780
[Epoch 81; Iter    80/ 1097] train: loss: 0.0100468
[Epoch 81; Iter   110/ 1097] train: loss: 0.0151751
[Epoch 81; Iter   140/ 1097] train: loss: 0.0630789
[Epoch 81; Iter   170/ 1097] train: loss: 0.1889745
[Epoch 81; Iter   200/ 1097] train: loss: 0.0486269
[Epoch 81; Iter   230/ 1097] train: loss: 0.0455517
[Epoch 81; Iter   260/ 1097] train: loss: 0.0555086
[Epoch 81; Iter   290/ 1097] train: loss: 0.0505550
[Epoch 81; Iter   320/ 1097] train: loss: 0.0115592
[Epoch 81; Iter   350/ 1097] train: loss: 0.0219838
[Epoch 77; Iter   298/ 1097] train: loss: 0.0109111
[Epoch 77; Iter   328/ 1097] train: loss: 0.1067917
[Epoch 77; Iter   358/ 1097] train: loss: 0.0390303
[Epoch 77; Iter   388/ 1097] train: loss: 0.0089433
[Epoch 77; Iter   418/ 1097] train: loss: 0.0091458
[Epoch 77; Iter   448/ 1097] train: loss: 0.0136903
[Epoch 77; Iter   478/ 1097] train: loss: 0.0167379
[Epoch 77; Iter   508/ 1097] train: loss: 0.0552008
[Epoch 77; Iter   538/ 1097] train: loss: 0.1059153
[Epoch 77; Iter   568/ 1097] train: loss: 0.0191432
[Epoch 77; Iter   598/ 1097] train: loss: 0.0977201
[Epoch 77; Iter   628/ 1097] train: loss: 0.0192436
[Epoch 77; Iter   658/ 1097] train: loss: 0.0731157
[Epoch 77; Iter   688/ 1097] train: loss: 0.0262224
[Epoch 77; Iter   718/ 1097] train: loss: 0.0961202
[Epoch 77; Iter   748/ 1097] train: loss: 0.0310808
[Epoch 77; Iter   778/ 1097] train: loss: 0.0102425
[Epoch 77; Iter   808/ 1097] train: loss: 0.0276286
[Epoch 77; Iter   838/ 1097] train: loss: 0.0348376
[Epoch 77; Iter   868/ 1097] train: loss: 0.0413423
[Epoch 77; Iter   898/ 1097] train: loss: 0.0134336
[Epoch 77; Iter   928/ 1097] train: loss: 0.1331638
[Epoch 77; Iter   958/ 1097] train: loss: 0.0269188
[Epoch 77; Iter   988/ 1097] train: loss: 0.0350592
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0783236
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0880274
[Epoch 77; Iter  1078/ 1097] train: loss: 0.2425939
[Epoch 77] ogbg-molhiv: 0.779064 val loss: 0.112523
[Epoch 77] ogbg-molhiv: 0.722718 test loss: 0.194418
[Epoch 78; Iter    11/ 1097] train: loss: 0.0490721
[Epoch 78; Iter    41/ 1097] train: loss: 0.0091080
[Epoch 78; Iter    71/ 1097] train: loss: 0.0763480
[Epoch 78; Iter   101/ 1097] train: loss: 0.0090071
[Epoch 78; Iter   131/ 1097] train: loss: 0.0222854
[Epoch 78; Iter   161/ 1097] train: loss: 0.0126886
[Epoch 78; Iter   191/ 1097] train: loss: 0.0310023
[Epoch 78; Iter   221/ 1097] train: loss: 0.0550227
[Epoch 78; Iter   251/ 1097] train: loss: 0.1604527
[Epoch 78; Iter   281/ 1097] train: loss: 0.0419360
[Epoch 78; Iter   311/ 1097] train: loss: 0.0077882
[Epoch 78; Iter   341/ 1097] train: loss: 0.0302882
[Epoch 78; Iter   371/ 1097] train: loss: 0.0998842
[Epoch 78; Iter   401/ 1097] train: loss: 0.0110557
[Epoch 78; Iter   431/ 1097] train: loss: 0.0321708
[Epoch 78; Iter   461/ 1097] train: loss: 0.0067985
[Epoch 78; Iter   491/ 1097] train: loss: 0.0293390
[Epoch 78; Iter   521/ 1097] train: loss: 0.0271607
[Epoch 78; Iter   551/ 1097] train: loss: 0.0958683
[Epoch 78; Iter   581/ 1097] train: loss: 0.2432343
[Epoch 78; Iter   611/ 1097] train: loss: 0.0207675
[Epoch 78; Iter   641/ 1097] train: loss: 0.0048468
[Epoch 78; Iter   671/ 1097] train: loss: 0.0113255
[Epoch 78; Iter   701/ 1097] train: loss: 0.0260863
[Epoch 78; Iter   731/ 1097] train: loss: 0.0468910
[Epoch 78; Iter   761/ 1097] train: loss: 0.0444228
[Epoch 78; Iter   791/ 1097] train: loss: 0.0381880
[Epoch 78; Iter   821/ 1097] train: loss: 0.0879703
[Epoch 78; Iter   851/ 1097] train: loss: 0.0541996
[Epoch 78; Iter   881/ 1097] train: loss: 0.0117851
[Epoch 78; Iter   911/ 1097] train: loss: 0.0304461
[Epoch 78; Iter   941/ 1097] train: loss: 0.0096928
[Epoch 78; Iter   971/ 1097] train: loss: 0.0942404
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0846549
[Epoch 78; Iter  1031/ 1097] train: loss: 0.1080538
[Epoch 78; Iter  1061/ 1097] train: loss: 0.1460106
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0102987
[Epoch 78] ogbg-molhiv: 0.787953 val loss: 0.118345
[Epoch 78] ogbg-molhiv: 0.730557 test loss: 0.193313
[Epoch 79; Iter    24/ 1097] train: loss: 0.0738862
[Epoch 79; Iter    54/ 1097] train: loss: 0.0676165
[Epoch 79; Iter    84/ 1097] train: loss: 0.0609157
[Epoch 79; Iter   114/ 1097] train: loss: 0.0105083
[Epoch 79; Iter   144/ 1097] train: loss: 0.0118673
[Epoch 79; Iter   174/ 1097] train: loss: 0.0628164
[Epoch 79; Iter   204/ 1097] train: loss: 0.0185000
[Epoch 79; Iter   234/ 1097] train: loss: 0.0924856
[Epoch 79; Iter   264/ 1097] train: loss: 0.0141310
[Epoch 79; Iter   294/ 1097] train: loss: 0.0088709
[Epoch 79; Iter   324/ 1097] train: loss: 0.0136765
[Epoch 79; Iter   354/ 1097] train: loss: 0.0841096
[Epoch 79; Iter   384/ 1097] train: loss: 0.0299695
[Epoch 79; Iter   414/ 1097] train: loss: 0.0518479
[Epoch 79; Iter   444/ 1097] train: loss: 0.0741547
[Epoch 79; Iter   474/ 1097] train: loss: 0.0376966
[Epoch 79; Iter   504/ 1097] train: loss: 0.0649484
[Epoch 79; Iter   534/ 1097] train: loss: 0.0349102
[Epoch 79; Iter   564/ 1097] train: loss: 0.0664437
[Epoch 79; Iter   594/ 1097] train: loss: 0.0108945
[Epoch 79; Iter   624/ 1097] train: loss: 0.0150331
[Epoch 79; Iter   654/ 1097] train: loss: 0.0477183
[Epoch 79; Iter   684/ 1097] train: loss: 0.0052732
[Epoch 79; Iter   714/ 1097] train: loss: 0.0138923
[Epoch 79; Iter   744/ 1097] train: loss: 0.0347191
[Epoch 79; Iter   774/ 1097] train: loss: 0.0121807
[Epoch 79; Iter   804/ 1097] train: loss: 0.0054528
[Epoch 79; Iter   834/ 1097] train: loss: 0.1121617
[Epoch 79; Iter   864/ 1097] train: loss: 0.0085869
[Epoch 79; Iter   894/ 1097] train: loss: 0.0150030
[Epoch 79; Iter   924/ 1097] train: loss: 0.0104350
[Epoch 79; Iter   954/ 1097] train: loss: 0.0342515
[Epoch 79; Iter   984/ 1097] train: loss: 0.0147953
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0302684
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0053853
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0149392
[Epoch 79] ogbg-molhiv: 0.777318 val loss: 0.118909
[Epoch 79] ogbg-molhiv: 0.726053 test loss: 0.196223
[Epoch 80; Iter     7/ 1097] train: loss: 0.0217851
[Epoch 80; Iter    37/ 1097] train: loss: 0.0196610
[Epoch 80; Iter    67/ 1097] train: loss: 0.0808473
[Epoch 80; Iter    97/ 1097] train: loss: 0.0063803
[Epoch 80; Iter   127/ 1097] train: loss: 0.0049424
[Epoch 80; Iter   157/ 1097] train: loss: 0.0132856
[Epoch 80; Iter   187/ 1097] train: loss: 0.1076216
[Epoch 80; Iter   217/ 1097] train: loss: 0.0653519
[Epoch 80; Iter   247/ 1097] train: loss: 0.1145035
[Epoch 80; Iter   277/ 1097] train: loss: 0.0103844
[Epoch 80; Iter   307/ 1097] train: loss: 0.0666312
[Epoch 80; Iter   337/ 1097] train: loss: 0.0308773
[Epoch 80; Iter   367/ 1097] train: loss: 0.0058367
[Epoch 80; Iter   397/ 1097] train: loss: 0.0113840
[Epoch 80; Iter   427/ 1097] train: loss: 0.0999890
[Epoch 80; Iter   457/ 1097] train: loss: 0.0465541
[Epoch 80; Iter   487/ 1097] train: loss: 0.0093697
[Epoch 80; Iter   517/ 1097] train: loss: 0.1230614
[Epoch 80; Iter   547/ 1097] train: loss: 0.0179530
[Epoch 80; Iter   577/ 1097] train: loss: 0.0099340
[Epoch 80; Iter   607/ 1097] train: loss: 0.0037046
[Epoch 80; Iter   637/ 1097] train: loss: 0.0165660
[Epoch 80; Iter   667/ 1097] train: loss: 0.0440596
[Epoch 80; Iter   697/ 1097] train: loss: 0.0149206
[Epoch 80; Iter   727/ 1097] train: loss: 0.0140142
[Epoch 80; Iter   757/ 1097] train: loss: 0.0262300
[Epoch 80; Iter   787/ 1097] train: loss: 0.0162463
[Epoch 80; Iter   817/ 1097] train: loss: 0.0500648
[Epoch 80; Iter   847/ 1097] train: loss: 0.0545778
[Epoch 80; Iter   877/ 1097] train: loss: 0.0959815
[Epoch 80; Iter   907/ 1097] train: loss: 0.0320965
[Epoch 80; Iter   937/ 1097] train: loss: 0.0294535
[Epoch 80; Iter   967/ 1097] train: loss: 0.0100426
[Epoch 80; Iter   997/ 1097] train: loss: 0.1613808
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0182314
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0585044
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0238036
[Epoch 80] ogbg-molhiv: 0.786183 val loss: 0.114087
[Epoch 80] ogbg-molhiv: 0.739804 test loss: 0.191417
[Epoch 81; Iter    20/ 1097] train: loss: 0.0512816
[Epoch 81; Iter    50/ 1097] train: loss: 0.0361458
[Epoch 81; Iter    80/ 1097] train: loss: 0.1411242
[Epoch 81; Iter   110/ 1097] train: loss: 0.0367677
[Epoch 81; Iter   140/ 1097] train: loss: 0.0958974
[Epoch 81; Iter   170/ 1097] train: loss: 0.0045441
[Epoch 81; Iter   200/ 1097] train: loss: 0.0684613
[Epoch 81; Iter   230/ 1097] train: loss: 0.0042784
[Epoch 81; Iter   260/ 1097] train: loss: 0.0424959
[Epoch 81; Iter   290/ 1097] train: loss: 0.0059688
[Epoch 81; Iter   320/ 1097] train: loss: 0.0101668
[Epoch 81; Iter   350/ 1097] train: loss: 0.0513263
[Epoch 77; Iter   298/ 1097] train: loss: 0.0041864
[Epoch 77; Iter   328/ 1097] train: loss: 0.0013280
[Epoch 77; Iter   358/ 1097] train: loss: 0.0103026
[Epoch 77; Iter   388/ 1097] train: loss: 0.0225893
[Epoch 77; Iter   418/ 1097] train: loss: 0.0290013
[Epoch 77; Iter   448/ 1097] train: loss: 0.0530215
[Epoch 77; Iter   478/ 1097] train: loss: 0.0021193
[Epoch 77; Iter   508/ 1097] train: loss: 0.0086873
[Epoch 77; Iter   538/ 1097] train: loss: 0.0115554
[Epoch 77; Iter   568/ 1097] train: loss: 0.0535024
[Epoch 77; Iter   598/ 1097] train: loss: 0.0759496
[Epoch 77; Iter   628/ 1097] train: loss: 0.0105275
[Epoch 77; Iter   658/ 1097] train: loss: 0.1869948
[Epoch 77; Iter   688/ 1097] train: loss: 0.0973625
[Epoch 77; Iter   718/ 1097] train: loss: 0.0240957
[Epoch 77; Iter   748/ 1097] train: loss: 0.0093699
[Epoch 77; Iter   778/ 1097] train: loss: 0.0441834
[Epoch 77; Iter   808/ 1097] train: loss: 0.0127268
[Epoch 77; Iter   838/ 1097] train: loss: 0.0058734
[Epoch 77; Iter   868/ 1097] train: loss: 0.0341068
[Epoch 77; Iter   898/ 1097] train: loss: 0.2730892
[Epoch 77; Iter   928/ 1097] train: loss: 0.0275804
[Epoch 77; Iter   958/ 1097] train: loss: 0.0062072
[Epoch 77; Iter   988/ 1097] train: loss: 0.0750553
[Epoch 77; Iter  1018/ 1097] train: loss: 0.0146786
[Epoch 77; Iter  1048/ 1097] train: loss: 0.0048706
[Epoch 77; Iter  1078/ 1097] train: loss: 0.0548976
[Epoch 77] ogbg-molhiv: 0.787417 val loss: 0.115014
[Epoch 77] ogbg-molhiv: 0.751297 test loss: 0.209698
[Epoch 78; Iter    11/ 1097] train: loss: 0.0061731
[Epoch 78; Iter    41/ 1097] train: loss: 0.0057438
[Epoch 78; Iter    71/ 1097] train: loss: 0.0319666
[Epoch 78; Iter   101/ 1097] train: loss: 0.0026662
[Epoch 78; Iter   131/ 1097] train: loss: 0.0288578
[Epoch 78; Iter   161/ 1097] train: loss: 0.0068858
[Epoch 78; Iter   191/ 1097] train: loss: 0.0014554
[Epoch 78; Iter   221/ 1097] train: loss: 0.0041555
[Epoch 78; Iter   251/ 1097] train: loss: 0.0442874
[Epoch 78; Iter   281/ 1097] train: loss: 0.0543690
[Epoch 78; Iter   311/ 1097] train: loss: 0.0032707
[Epoch 78; Iter   341/ 1097] train: loss: 0.0072540
[Epoch 78; Iter   371/ 1097] train: loss: 0.0084386
[Epoch 78; Iter   401/ 1097] train: loss: 0.0926559
[Epoch 78; Iter   431/ 1097] train: loss: 0.1193389
[Epoch 78; Iter   461/ 1097] train: loss: 0.0216289
[Epoch 78; Iter   491/ 1097] train: loss: 0.0236911
[Epoch 78; Iter   521/ 1097] train: loss: 0.0595566
[Epoch 78; Iter   551/ 1097] train: loss: 0.0267619
[Epoch 78; Iter   581/ 1097] train: loss: 0.0042176
[Epoch 78; Iter   611/ 1097] train: loss: 0.0031253
[Epoch 78; Iter   641/ 1097] train: loss: 0.0059871
[Epoch 78; Iter   671/ 1097] train: loss: 0.0087598
[Epoch 78; Iter   701/ 1097] train: loss: 0.0231367
[Epoch 78; Iter   731/ 1097] train: loss: 0.0016915
[Epoch 78; Iter   761/ 1097] train: loss: 0.0372614
[Epoch 78; Iter   791/ 1097] train: loss: 0.0037086
[Epoch 78; Iter   821/ 1097] train: loss: 0.0078179
[Epoch 78; Iter   851/ 1097] train: loss: 0.0038106
[Epoch 78; Iter   881/ 1097] train: loss: 0.0063163
[Epoch 78; Iter   911/ 1097] train: loss: 0.0085021
[Epoch 78; Iter   941/ 1097] train: loss: 0.0143753
[Epoch 78; Iter   971/ 1097] train: loss: 0.0033446
[Epoch 78; Iter  1001/ 1097] train: loss: 0.0054716
[Epoch 78; Iter  1031/ 1097] train: loss: 0.0073006
[Epoch 78; Iter  1061/ 1097] train: loss: 0.0024296
[Epoch 78; Iter  1091/ 1097] train: loss: 0.0174635
[Epoch 78] ogbg-molhiv: 0.796192 val loss: 0.113217
[Epoch 78] ogbg-molhiv: 0.751086 test loss: 0.215884
[Epoch 79; Iter    24/ 1097] train: loss: 0.0355007
[Epoch 79; Iter    54/ 1097] train: loss: 0.0455419
[Epoch 79; Iter    84/ 1097] train: loss: 0.1291760
[Epoch 79; Iter   114/ 1097] train: loss: 0.0075898
[Epoch 79; Iter   144/ 1097] train: loss: 0.0102762
[Epoch 79; Iter   174/ 1097] train: loss: 0.0143317
[Epoch 79; Iter   204/ 1097] train: loss: 0.0651858
[Epoch 79; Iter   234/ 1097] train: loss: 0.0064943
[Epoch 79; Iter   264/ 1097] train: loss: 0.0428544
[Epoch 79; Iter   294/ 1097] train: loss: 0.1583303
[Epoch 79; Iter   324/ 1097] train: loss: 0.0944741
[Epoch 79; Iter   354/ 1097] train: loss: 0.0099560
[Epoch 79; Iter   384/ 1097] train: loss: 0.0630796
[Epoch 79; Iter   414/ 1097] train: loss: 0.0032008
[Epoch 79; Iter   444/ 1097] train: loss: 0.0115107
[Epoch 79; Iter   474/ 1097] train: loss: 0.0676098
[Epoch 79; Iter   504/ 1097] train: loss: 0.0009654
[Epoch 79; Iter   534/ 1097] train: loss: 0.0339357
[Epoch 79; Iter   564/ 1097] train: loss: 0.0181732
[Epoch 79; Iter   594/ 1097] train: loss: 0.0038102
[Epoch 79; Iter   624/ 1097] train: loss: 0.0035198
[Epoch 79; Iter   654/ 1097] train: loss: 0.0042921
[Epoch 79; Iter   684/ 1097] train: loss: 0.0007697
[Epoch 79; Iter   714/ 1097] train: loss: 0.1130476
[Epoch 79; Iter   744/ 1097] train: loss: 0.0153942
[Epoch 79; Iter   774/ 1097] train: loss: 0.0681162
[Epoch 79; Iter   804/ 1097] train: loss: 0.0656273
[Epoch 79; Iter   834/ 1097] train: loss: 0.0089477
[Epoch 79; Iter   864/ 1097] train: loss: 0.0853686
[Epoch 79; Iter   894/ 1097] train: loss: 0.0627805
[Epoch 79; Iter   924/ 1097] train: loss: 0.0106150
[Epoch 79; Iter   954/ 1097] train: loss: 0.0102154
[Epoch 79; Iter   984/ 1097] train: loss: 0.0124299
[Epoch 79; Iter  1014/ 1097] train: loss: 0.0268406
[Epoch 79; Iter  1044/ 1097] train: loss: 0.0163103
[Epoch 79; Iter  1074/ 1097] train: loss: 0.0131786
[Epoch 79] ogbg-molhiv: 0.785451 val loss: 0.127441
[Epoch 79] ogbg-molhiv: 0.751583 test loss: 0.220925
[Epoch 80; Iter     7/ 1097] train: loss: 0.0003243
[Epoch 80; Iter    37/ 1097] train: loss: 0.0234726
[Epoch 80; Iter    67/ 1097] train: loss: 0.0040781
[Epoch 80; Iter    97/ 1097] train: loss: 0.0423038
[Epoch 80; Iter   127/ 1097] train: loss: 0.0246501
[Epoch 80; Iter   157/ 1097] train: loss: 0.0183327
[Epoch 80; Iter   187/ 1097] train: loss: 0.1666189
[Epoch 80; Iter   217/ 1097] train: loss: 0.0666451
[Epoch 80; Iter   247/ 1097] train: loss: 0.0087245
[Epoch 80; Iter   277/ 1097] train: loss: 0.0040673
[Epoch 80; Iter   307/ 1097] train: loss: 0.0076681
[Epoch 80; Iter   337/ 1097] train: loss: 0.0042758
[Epoch 80; Iter   367/ 1097] train: loss: 0.0116715
[Epoch 80; Iter   397/ 1097] train: loss: 0.0368451
[Epoch 80; Iter   427/ 1097] train: loss: 0.0249134
[Epoch 80; Iter   457/ 1097] train: loss: 0.0229997
[Epoch 80; Iter   487/ 1097] train: loss: 0.0158618
[Epoch 80; Iter   517/ 1097] train: loss: 0.0036267
[Epoch 80; Iter   547/ 1097] train: loss: 0.0125373
[Epoch 80; Iter   577/ 1097] train: loss: 0.0113534
[Epoch 80; Iter   607/ 1097] train: loss: 0.0038371
[Epoch 80; Iter   637/ 1097] train: loss: 0.0043935
[Epoch 80; Iter   667/ 1097] train: loss: 0.0026226
[Epoch 80; Iter   697/ 1097] train: loss: 0.0042429
[Epoch 80; Iter   727/ 1097] train: loss: 0.0034819
[Epoch 80; Iter   757/ 1097] train: loss: 0.0071267
[Epoch 80; Iter   787/ 1097] train: loss: 0.0035195
[Epoch 80; Iter   817/ 1097] train: loss: 0.0205085
[Epoch 80; Iter   847/ 1097] train: loss: 0.0246321
[Epoch 80; Iter   877/ 1097] train: loss: 0.0425237
[Epoch 80; Iter   907/ 1097] train: loss: 0.0017637
[Epoch 80; Iter   937/ 1097] train: loss: 0.0409144
[Epoch 80; Iter   967/ 1097] train: loss: 0.0064500
[Epoch 80; Iter   997/ 1097] train: loss: 0.0014319
[Epoch 80; Iter  1027/ 1097] train: loss: 0.0168459
[Epoch 80; Iter  1057/ 1097] train: loss: 0.0277149
[Epoch 80; Iter  1087/ 1097] train: loss: 0.0009265
[Epoch 80] ogbg-molhiv: 0.784636 val loss: 0.119135
[Epoch 80] ogbg-molhiv: 0.767251 test loss: 0.206228
[Epoch 81; Iter    20/ 1097] train: loss: 0.0108459
[Epoch 81; Iter    50/ 1097] train: loss: 0.0113986
[Epoch 81; Iter    80/ 1097] train: loss: 0.0284284
[Epoch 81; Iter   110/ 1097] train: loss: 0.0058108
[Epoch 81; Iter   140/ 1097] train: loss: 0.0036416
[Epoch 81; Iter   170/ 1097] train: loss: 0.0165071
[Epoch 81; Iter   200/ 1097] train: loss: 0.0055441
[Epoch 81; Iter   230/ 1097] train: loss: 0.0085600
[Epoch 81; Iter   260/ 1097] train: loss: 0.0879108
[Epoch 81; Iter   290/ 1097] train: loss: 0.0289732
[Epoch 81; Iter   320/ 1097] train: loss: 0.0062346
[Epoch 81; Iter   350/ 1097] train: loss: 0.0052537
[Epoch 84; Iter   781/  823] train: loss: 0.0525998
[Epoch 84; Iter   811/  823] train: loss: 0.0041323
[Epoch 84] ogbg-molhiv: 0.745711 val loss: 0.236030
[Epoch 84] ogbg-molhiv: 0.754972 test loss: 0.315204
[Epoch 85; Iter    18/  823] train: loss: 0.0056258
[Epoch 85; Iter    48/  823] train: loss: 0.0187179
[Epoch 85; Iter    78/  823] train: loss: 0.0028311
[Epoch 85; Iter   108/  823] train: loss: 0.0035667
[Epoch 85; Iter   138/  823] train: loss: 0.1463145
[Epoch 85; Iter   168/  823] train: loss: 0.0092398
[Epoch 85; Iter   198/  823] train: loss: 0.0061648
[Epoch 85; Iter   228/  823] train: loss: 0.0042091
[Epoch 85; Iter   258/  823] train: loss: 0.0973742
[Epoch 85; Iter   288/  823] train: loss: 0.0042696
[Epoch 85; Iter   318/  823] train: loss: 0.0167694
[Epoch 85; Iter   348/  823] train: loss: 0.0173965
[Epoch 85; Iter   378/  823] train: loss: 0.0167752
[Epoch 85; Iter   408/  823] train: loss: 0.0064785
[Epoch 85; Iter   438/  823] train: loss: 0.0088397
[Epoch 85; Iter   468/  823] train: loss: 0.0021487
[Epoch 85; Iter   498/  823] train: loss: 0.0283027
[Epoch 85; Iter   528/  823] train: loss: 0.0146634
[Epoch 85; Iter   558/  823] train: loss: 0.0308410
[Epoch 85; Iter   588/  823] train: loss: 0.0034034
[Epoch 85; Iter   618/  823] train: loss: 0.1535219
[Epoch 85; Iter   648/  823] train: loss: 0.0167198
[Epoch 85; Iter   678/  823] train: loss: 0.0417304
[Epoch 85; Iter   708/  823] train: loss: 0.0187931
[Epoch 85; Iter   738/  823] train: loss: 0.2012477
[Epoch 85; Iter   768/  823] train: loss: 0.0297714
[Epoch 85; Iter   798/  823] train: loss: 0.0587922
[Epoch 85] ogbg-molhiv: 0.737582 val loss: 0.349279
[Epoch 85] ogbg-molhiv: 0.753585 test loss: 1.044076
[Epoch 86; Iter     5/  823] train: loss: 0.0364643
[Epoch 86; Iter    35/  823] train: loss: 0.0133016
[Epoch 86; Iter    65/  823] train: loss: 0.0046655
[Epoch 86; Iter    95/  823] train: loss: 0.0089631
[Epoch 86; Iter   125/  823] train: loss: 0.0079664
[Epoch 86; Iter   155/  823] train: loss: 0.0123847
[Epoch 86; Iter   185/  823] train: loss: 0.0649532
[Epoch 86; Iter   215/  823] train: loss: 0.1350303
[Epoch 86; Iter   245/  823] train: loss: 0.0044724
[Epoch 86; Iter   275/  823] train: loss: 0.0039375
[Epoch 86; Iter   305/  823] train: loss: 0.0508608
[Epoch 86; Iter   335/  823] train: loss: 0.2235045
[Epoch 86; Iter   365/  823] train: loss: 0.0873596
[Epoch 86; Iter   395/  823] train: loss: 0.0055511
[Epoch 86; Iter   425/  823] train: loss: 0.0078424
[Epoch 86; Iter   455/  823] train: loss: 0.0280764
[Epoch 86; Iter   485/  823] train: loss: 0.0025067
[Epoch 86; Iter   515/  823] train: loss: 0.0077318
[Epoch 86; Iter   545/  823] train: loss: 0.1309545
[Epoch 86; Iter   575/  823] train: loss: 0.0018894
[Epoch 86; Iter   605/  823] train: loss: 0.0501756
[Epoch 86; Iter   635/  823] train: loss: 0.0116227
[Epoch 86; Iter   665/  823] train: loss: 0.0394763
[Epoch 86; Iter   695/  823] train: loss: 0.1766867
[Epoch 86; Iter   725/  823] train: loss: 0.0037649
[Epoch 86; Iter   755/  823] train: loss: 0.0041805
[Epoch 86; Iter   785/  823] train: loss: 0.0108593
[Epoch 86; Iter   815/  823] train: loss: 0.0551830
[Epoch 86] ogbg-molhiv: 0.740140 val loss: 0.235484
[Epoch 86] ogbg-molhiv: 0.748159 test loss: 0.283774
[Epoch 87; Iter    22/  823] train: loss: 0.0158836
[Epoch 87; Iter    52/  823] train: loss: 0.0021178
[Epoch 87; Iter    82/  823] train: loss: 0.0365501
[Epoch 87; Iter   112/  823] train: loss: 0.0013489
[Epoch 87; Iter   142/  823] train: loss: 0.0103678
[Epoch 87; Iter   172/  823] train: loss: 0.0368556
[Epoch 87; Iter   202/  823] train: loss: 0.0015337
[Epoch 87; Iter   232/  823] train: loss: 0.0877064
[Epoch 87; Iter   262/  823] train: loss: 0.0063446
[Epoch 87; Iter   292/  823] train: loss: 0.0025065
[Epoch 87; Iter   322/  823] train: loss: 0.0209815
[Epoch 87; Iter   352/  823] train: loss: 0.0191668
[Epoch 87; Iter   382/  823] train: loss: 0.0118927
[Epoch 87; Iter   412/  823] train: loss: 0.0100723
[Epoch 87; Iter   442/  823] train: loss: 0.0186700
[Epoch 87; Iter   472/  823] train: loss: 0.0501258
[Epoch 87; Iter   502/  823] train: loss: 0.0575062
[Epoch 87; Iter   532/  823] train: loss: 0.0090338
[Epoch 87; Iter   562/  823] train: loss: 0.0051484
[Epoch 87; Iter   592/  823] train: loss: 0.0156322
[Epoch 87; Iter   622/  823] train: loss: 0.0145342
[Epoch 87; Iter   652/  823] train: loss: 0.0479121
[Epoch 87; Iter   682/  823] train: loss: 0.0234655
[Epoch 87; Iter   712/  823] train: loss: 0.0919612
[Epoch 87; Iter   742/  823] train: loss: 0.1011950
[Epoch 87; Iter   772/  823] train: loss: 0.0926292
[Epoch 87; Iter   802/  823] train: loss: 0.0030514
[Epoch 87] ogbg-molhiv: 0.738620 val loss: 0.270506
[Epoch 87] ogbg-molhiv: 0.745616 test loss: 0.665732
[Epoch 88; Iter     9/  823] train: loss: 0.0194821
[Epoch 88; Iter    39/  823] train: loss: 0.0094232
[Epoch 88; Iter    69/  823] train: loss: 0.0138151
[Epoch 88; Iter    99/  823] train: loss: 0.0050715
[Epoch 88; Iter   129/  823] train: loss: 0.0167649
[Epoch 88; Iter   159/  823] train: loss: 0.0052784
[Epoch 88; Iter   189/  823] train: loss: 0.0931521
[Epoch 88; Iter   219/  823] train: loss: 0.0134188
[Epoch 88; Iter   249/  823] train: loss: 0.0642154
[Epoch 88; Iter   279/  823] train: loss: 0.0065292
[Epoch 88; Iter   309/  823] train: loss: 0.0130988
[Epoch 88; Iter   339/  823] train: loss: 0.0093961
[Epoch 88; Iter   369/  823] train: loss: 0.0077109
[Epoch 88; Iter   399/  823] train: loss: 0.0078376
[Epoch 88; Iter   429/  823] train: loss: 0.0342633
[Epoch 88; Iter   459/  823] train: loss: 0.0240376
[Epoch 88; Iter   489/  823] train: loss: 0.0418496
[Epoch 88; Iter   519/  823] train: loss: 0.0036003
[Epoch 88; Iter   549/  823] train: loss: 0.0181248
[Epoch 88; Iter   579/  823] train: loss: 0.0020096
[Epoch 88; Iter   609/  823] train: loss: 0.0045414
[Epoch 88; Iter   639/  823] train: loss: 0.0283439
[Epoch 88; Iter   669/  823] train: loss: 0.0261545
[Epoch 88; Iter   699/  823] train: loss: 0.0030300
[Epoch 88; Iter   729/  823] train: loss: 0.0147035
[Epoch 88; Iter   759/  823] train: loss: 0.0220265
[Epoch 88; Iter   789/  823] train: loss: 0.0839086
[Epoch 88; Iter   819/  823] train: loss: 0.1094107
[Epoch 88] ogbg-molhiv: 0.737146 val loss: 0.229340
[Epoch 88] ogbg-molhiv: 0.750037 test loss: 0.188940
[Epoch 89; Iter    26/  823] train: loss: 0.0501956
[Epoch 89; Iter    56/  823] train: loss: 0.0029256
[Epoch 89; Iter    86/  823] train: loss: 0.0068038
[Epoch 89; Iter   116/  823] train: loss: 0.0259149
[Epoch 89; Iter   146/  823] train: loss: 0.0560508
[Epoch 89; Iter   176/  823] train: loss: 0.0247486
[Epoch 89; Iter   206/  823] train: loss: 0.0076946
[Epoch 89; Iter   236/  823] train: loss: 0.0418233
[Epoch 89; Iter   266/  823] train: loss: 0.0120378
[Epoch 89; Iter   296/  823] train: loss: 0.0012327
[Epoch 89; Iter   326/  823] train: loss: 0.0140003
[Epoch 89; Iter   356/  823] train: loss: 0.0028822
[Epoch 89; Iter   386/  823] train: loss: 0.0210533
[Epoch 89; Iter   416/  823] train: loss: 0.0375433
[Epoch 89; Iter   446/  823] train: loss: 0.0325112
[Epoch 89; Iter   476/  823] train: loss: 0.0117525
[Epoch 89; Iter   506/  823] train: loss: 0.0112317
[Epoch 89; Iter   536/  823] train: loss: 0.0196661
[Epoch 89; Iter   566/  823] train: loss: 0.0031760
[Epoch 89; Iter   596/  823] train: loss: 0.0754241
[Epoch 89; Iter   626/  823] train: loss: 0.0183896
[Epoch 89; Iter   656/  823] train: loss: 0.0133980
[Epoch 89; Iter   686/  823] train: loss: 0.0098474
[Epoch 89; Iter   716/  823] train: loss: 0.0041340
[Epoch 89; Iter   746/  823] train: loss: 0.0046886
[Epoch 89; Iter   776/  823] train: loss: 0.0391944
[Epoch 89; Iter   806/  823] train: loss: 0.0185161
[Epoch 89] ogbg-molhiv: 0.741337 val loss: 0.263596
[Epoch 89] ogbg-molhiv: 0.745823 test loss: 0.447589
[Epoch 90; Iter    13/  823] train: loss: 0.0074482
[Epoch 90; Iter    43/  823] train: loss: 0.0037087
[Epoch 90; Iter    73/  823] train: loss: 0.0211099
[Epoch 90; Iter   103/  823] train: loss: 0.0157673
[Epoch 90; Iter   133/  823] train: loss: 0.0112596
[Epoch 90; Iter   163/  823] train: loss: 0.0224965
[Epoch 84; Iter   781/  823] train: loss: 0.0021122
[Epoch 84; Iter   811/  823] train: loss: 0.0024746
[Epoch 84] ogbg-molhiv: 0.705209 val loss: 0.363444
[Epoch 84] ogbg-molhiv: 0.755605 test loss: 0.234161
[Epoch 85; Iter    18/  823] train: loss: 0.0007365
[Epoch 85; Iter    48/  823] train: loss: 0.0050963
[Epoch 85; Iter    78/  823] train: loss: 0.0092209
[Epoch 85; Iter   108/  823] train: loss: 0.0117767
[Epoch 85; Iter   138/  823] train: loss: 0.0021302
[Epoch 85; Iter   168/  823] train: loss: 0.0020889
[Epoch 85; Iter   198/  823] train: loss: 0.0462012
[Epoch 85; Iter   228/  823] train: loss: 0.0106856
[Epoch 85; Iter   258/  823] train: loss: 0.0057817
[Epoch 85; Iter   288/  823] train: loss: 0.0477508
[Epoch 85; Iter   318/  823] train: loss: 0.0055568
[Epoch 85; Iter   348/  823] train: loss: 0.0051761
[Epoch 85; Iter   378/  823] train: loss: 0.0006256
[Epoch 85; Iter   408/  823] train: loss: 0.0141433
[Epoch 85; Iter   438/  823] train: loss: 0.0029690
[Epoch 85; Iter   468/  823] train: loss: 0.1969202
[Epoch 85; Iter   498/  823] train: loss: 0.0053536
[Epoch 85; Iter   528/  823] train: loss: 0.0179341
[Epoch 85; Iter   558/  823] train: loss: 0.0063935
[Epoch 85; Iter   588/  823] train: loss: 0.0747534
[Epoch 85; Iter   618/  823] train: loss: 0.0113817
[Epoch 85; Iter   648/  823] train: loss: 0.0104641
[Epoch 85; Iter   678/  823] train: loss: 0.0111173
[Epoch 85; Iter   708/  823] train: loss: 0.0022972
[Epoch 85; Iter   738/  823] train: loss: 0.0072634
[Epoch 85; Iter   768/  823] train: loss: 0.0075457
[Epoch 85; Iter   798/  823] train: loss: 0.1430866
[Epoch 85] ogbg-molhiv: 0.696363 val loss: 0.391935
[Epoch 85] ogbg-molhiv: 0.753871 test loss: 0.219723
[Epoch 86; Iter     5/  823] train: loss: 0.0059442
[Epoch 86; Iter    35/  823] train: loss: 0.0053621
[Epoch 86; Iter    65/  823] train: loss: 0.0041799
[Epoch 86; Iter    95/  823] train: loss: 0.0016840
[Epoch 86; Iter   125/  823] train: loss: 0.0060044
[Epoch 86; Iter   155/  823] train: loss: 0.0113521
[Epoch 86; Iter   185/  823] train: loss: 0.0671853
[Epoch 86; Iter   215/  823] train: loss: 0.0165190
[Epoch 86; Iter   245/  823] train: loss: 0.0031768
[Epoch 86; Iter   275/  823] train: loss: 0.0180216
[Epoch 86; Iter   305/  823] train: loss: 0.0143128
[Epoch 86; Iter   335/  823] train: loss: 0.0021144
[Epoch 86; Iter   365/  823] train: loss: 0.0072046
[Epoch 86; Iter   395/  823] train: loss: 0.0403293
[Epoch 86; Iter   425/  823] train: loss: 0.0019177
[Epoch 86; Iter   455/  823] train: loss: 0.0185096
[Epoch 86; Iter   485/  823] train: loss: 0.0680951
[Epoch 86; Iter   515/  823] train: loss: 0.0011277
[Epoch 86; Iter   545/  823] train: loss: 0.0011401
[Epoch 86; Iter   575/  823] train: loss: 0.0206040
[Epoch 86; Iter   605/  823] train: loss: 0.0094707
[Epoch 86; Iter   635/  823] train: loss: 0.0075977
[Epoch 86; Iter   665/  823] train: loss: 0.0118280
[Epoch 86; Iter   695/  823] train: loss: 0.0147584
[Epoch 86; Iter   725/  823] train: loss: 0.0023107
[Epoch 86; Iter   755/  823] train: loss: 0.0415398
[Epoch 86; Iter   785/  823] train: loss: 0.0227013
[Epoch 86; Iter   815/  823] train: loss: 0.0092835
[Epoch 86] ogbg-molhiv: 0.700319 val loss: 0.370363
[Epoch 86] ogbg-molhiv: 0.750676 test loss: 0.213455
[Epoch 87; Iter    22/  823] train: loss: 0.0308977
[Epoch 87; Iter    52/  823] train: loss: 0.0090581
[Epoch 87; Iter    82/  823] train: loss: 0.0062695
[Epoch 87; Iter   112/  823] train: loss: 0.0215792
[Epoch 87; Iter   142/  823] train: loss: 0.0041994
[Epoch 87; Iter   172/  823] train: loss: 0.0102497
[Epoch 87; Iter   202/  823] train: loss: 0.0143348
[Epoch 87; Iter   232/  823] train: loss: 0.0067407
[Epoch 87; Iter   262/  823] train: loss: 0.0056799
[Epoch 87; Iter   292/  823] train: loss: 0.0179005
[Epoch 87; Iter   322/  823] train: loss: 0.0022141
[Epoch 87; Iter   352/  823] train: loss: 0.0128869
[Epoch 87; Iter   382/  823] train: loss: 0.0014364
[Epoch 87; Iter   412/  823] train: loss: 0.0041725
[Epoch 87; Iter   442/  823] train: loss: 0.0588415
[Epoch 87; Iter   472/  823] train: loss: 0.0007624
[Epoch 87; Iter   502/  823] train: loss: 0.0145288
[Epoch 87; Iter   532/  823] train: loss: 0.0040901
[Epoch 87; Iter   562/  823] train: loss: 0.0007452
[Epoch 87; Iter   592/  823] train: loss: 0.0143948
[Epoch 87; Iter   622/  823] train: loss: 0.0073502
[Epoch 87; Iter   652/  823] train: loss: 0.0852829
[Epoch 87; Iter   682/  823] train: loss: 0.0014748
[Epoch 87; Iter   712/  823] train: loss: 0.0201045
[Epoch 87; Iter   742/  823] train: loss: 0.0027116
[Epoch 87; Iter   772/  823] train: loss: 0.0054272
[Epoch 87; Iter   802/  823] train: loss: 0.0059758
[Epoch 87] ogbg-molhiv: 0.698051 val loss: 0.418536
[Epoch 87] ogbg-molhiv: 0.739938 test loss: 0.239070
[Epoch 88; Iter     9/  823] train: loss: 0.0015844
[Epoch 88; Iter    39/  823] train: loss: 0.0252372
[Epoch 88; Iter    69/  823] train: loss: 0.0011035
[Epoch 88; Iter    99/  823] train: loss: 0.0069620
[Epoch 88; Iter   129/  823] train: loss: 0.0112729
[Epoch 88; Iter   159/  823] train: loss: 0.0345577
[Epoch 88; Iter   189/  823] train: loss: 0.0151444
[Epoch 88; Iter   219/  823] train: loss: 0.0177221
[Epoch 88; Iter   249/  823] train: loss: 0.0021323
[Epoch 88; Iter   279/  823] train: loss: 0.0014775
[Epoch 88; Iter   309/  823] train: loss: 0.0422389
[Epoch 88; Iter   339/  823] train: loss: 0.0396742
[Epoch 88; Iter   369/  823] train: loss: 0.0007114
[Epoch 88; Iter   399/  823] train: loss: 0.0033555
[Epoch 88; Iter   429/  823] train: loss: 0.0368404
[Epoch 88; Iter   459/  823] train: loss: 0.0623895
[Epoch 88; Iter   489/  823] train: loss: 0.0021077
[Epoch 88; Iter   519/  823] train: loss: 0.0032545
[Epoch 88; Iter   549/  823] train: loss: 0.0030270
[Epoch 88; Iter   579/  823] train: loss: 0.0190046
[Epoch 88; Iter   609/  823] train: loss: 0.0663240
[Epoch 88; Iter   639/  823] train: loss: 0.0465205
[Epoch 88; Iter   669/  823] train: loss: 0.0180161
[Epoch 88; Iter   699/  823] train: loss: 0.0062069
[Epoch 88; Iter   729/  823] train: loss: 0.0066980
[Epoch 88; Iter   759/  823] train: loss: 0.0912030
[Epoch 88; Iter   789/  823] train: loss: 0.0107750
[Epoch 88; Iter   819/  823] train: loss: 0.0041258
[Epoch 88] ogbg-molhiv: 0.715824 val loss: 0.338824
[Epoch 88] ogbg-molhiv: 0.755785 test loss: 0.199187
[Epoch 89; Iter    26/  823] train: loss: 0.0019741
[Epoch 89; Iter    56/  823] train: loss: 0.0578000
[Epoch 89; Iter    86/  823] train: loss: 0.0083477
[Epoch 89; Iter   116/  823] train: loss: 0.0165611
[Epoch 89; Iter   146/  823] train: loss: 0.0038095
[Epoch 89; Iter   176/  823] train: loss: 0.0058334
[Epoch 89; Iter   206/  823] train: loss: 0.0008626
[Epoch 89; Iter   236/  823] train: loss: 0.0751210
[Epoch 89; Iter   266/  823] train: loss: 0.0015798
[Epoch 89; Iter   296/  823] train: loss: 0.0111213
[Epoch 89; Iter   326/  823] train: loss: 0.0083411
[Epoch 89; Iter   356/  823] train: loss: 0.0688120
[Epoch 89; Iter   386/  823] train: loss: 0.0651571
[Epoch 89; Iter   416/  823] train: loss: 0.0033991
[Epoch 89; Iter   446/  823] train: loss: 0.0543564
[Epoch 89; Iter   476/  823] train: loss: 0.0041930
[Epoch 89; Iter   506/  823] train: loss: 0.0101064
[Epoch 89; Iter   536/  823] train: loss: 0.0032393
[Epoch 89; Iter   566/  823] train: loss: 0.0247424
[Epoch 89; Iter   596/  823] train: loss: 0.0461142
[Epoch 89; Iter   626/  823] train: loss: 0.0069901
[Epoch 89; Iter   656/  823] train: loss: 0.0070596
[Epoch 89; Iter   686/  823] train: loss: 0.0088682
[Epoch 89; Iter   716/  823] train: loss: 0.1218588
[Epoch 89; Iter   746/  823] train: loss: 0.0568103
[Epoch 89; Iter   776/  823] train: loss: 0.0180678
[Epoch 89; Iter   806/  823] train: loss: 0.0041378
[Epoch 89] ogbg-molhiv: 0.715413 val loss: 0.365220
[Epoch 89] ogbg-molhiv: 0.749783 test loss: 0.225573
[Epoch 90; Iter    13/  823] train: loss: 0.0090266
[Epoch 90; Iter    43/  823] train: loss: 0.0023843
[Epoch 90; Iter    73/  823] train: loss: 0.0340297
[Epoch 90; Iter   103/  823] train: loss: 0.0250974
[Epoch 90; Iter   133/  823] train: loss: 0.0152401
[Epoch 90; Iter   163/  823] train: loss: 0.1269672
[Epoch 82; Iter   900/  960] train: loss: 0.0011893
[Epoch 82; Iter   930/  960] train: loss: 0.0152099
[Epoch 82; Iter   960/  960] train: loss: 0.0036252
[Epoch 82] ogbg-molhiv: 0.712553 val loss: 0.685597
[Epoch 82] ogbg-molhiv: 0.751534 test loss: 0.800460
[Epoch 83; Iter    30/  960] train: loss: 0.0212322
[Epoch 83; Iter    60/  960] train: loss: 0.1205769
[Epoch 83; Iter    90/  960] train: loss: 0.0193752
[Epoch 83; Iter   120/  960] train: loss: 0.0056967
[Epoch 83; Iter   150/  960] train: loss: 0.0159394
[Epoch 83; Iter   180/  960] train: loss: 0.0219852
[Epoch 83; Iter   210/  960] train: loss: 0.0247035
[Epoch 83; Iter   240/  960] train: loss: 0.0016701
[Epoch 83; Iter   270/  960] train: loss: 0.0005763
[Epoch 83; Iter   300/  960] train: loss: 0.0217514
[Epoch 83; Iter   330/  960] train: loss: 0.0056398
[Epoch 83; Iter   360/  960] train: loss: 0.0727766
[Epoch 83; Iter   390/  960] train: loss: 0.0623274
[Epoch 83; Iter   420/  960] train: loss: 0.0077107
[Epoch 83; Iter   450/  960] train: loss: 0.0019520
[Epoch 83; Iter   480/  960] train: loss: 0.0070655
[Epoch 83; Iter   510/  960] train: loss: 0.0036698
[Epoch 83; Iter   540/  960] train: loss: 0.0125734
[Epoch 83; Iter   570/  960] train: loss: 0.0462168
[Epoch 83; Iter   600/  960] train: loss: 0.0019366
[Epoch 83; Iter   630/  960] train: loss: 0.0021318
[Epoch 83; Iter   660/  960] train: loss: 0.0115482
[Epoch 83; Iter   690/  960] train: loss: 0.0378732
[Epoch 83; Iter   720/  960] train: loss: 0.0021175
[Epoch 83; Iter   750/  960] train: loss: 0.0257202
[Epoch 83; Iter   780/  960] train: loss: 0.0043570
[Epoch 83; Iter   810/  960] train: loss: 0.0062369
[Epoch 83; Iter   840/  960] train: loss: 0.0302865
[Epoch 83; Iter   870/  960] train: loss: 0.0043875
[Epoch 83; Iter   900/  960] train: loss: 0.1186439
[Epoch 83; Iter   930/  960] train: loss: 0.0120277
[Epoch 83; Iter   960/  960] train: loss: 0.0156706
[Epoch 83] ogbg-molhiv: 0.719683 val loss: 0.258140
[Epoch 83] ogbg-molhiv: 0.755721 test loss: 0.207155
[Epoch 84; Iter    30/  960] train: loss: 0.0357132
[Epoch 84; Iter    60/  960] train: loss: 0.0036782
[Epoch 84; Iter    90/  960] train: loss: 0.0032676
[Epoch 84; Iter   120/  960] train: loss: 0.0332532
[Epoch 84; Iter   150/  960] train: loss: 0.0069672
[Epoch 84; Iter   180/  960] train: loss: 0.0044677
[Epoch 84; Iter   210/  960] train: loss: 0.0026045
[Epoch 84; Iter   240/  960] train: loss: 0.2127794
[Epoch 84; Iter   270/  960] train: loss: 0.0257001
[Epoch 84; Iter   300/  960] train: loss: 0.0018867
[Epoch 84; Iter   330/  960] train: loss: 0.0946425
[Epoch 84; Iter   360/  960] train: loss: 0.0506560
[Epoch 84; Iter   390/  960] train: loss: 0.0006996
[Epoch 84; Iter   420/  960] train: loss: 0.0030813
[Epoch 84; Iter   450/  960] train: loss: 0.1329145
[Epoch 84; Iter   480/  960] train: loss: 0.0174065
[Epoch 84; Iter   510/  960] train: loss: 0.0374157
[Epoch 84; Iter   540/  960] train: loss: 0.0011203
[Epoch 84; Iter   570/  960] train: loss: 0.0033278
[Epoch 84; Iter   600/  960] train: loss: 0.0435703
[Epoch 84; Iter   630/  960] train: loss: 0.0015281
[Epoch 84; Iter   660/  960] train: loss: 0.0023285
[Epoch 84; Iter   690/  960] train: loss: 0.0006519
[Epoch 84; Iter   720/  960] train: loss: 0.0101346
[Epoch 84; Iter   750/  960] train: loss: 0.0016407
[Epoch 84; Iter   780/  960] train: loss: 0.0162139
[Epoch 84; Iter   810/  960] train: loss: 0.0245523
[Epoch 84; Iter   840/  960] train: loss: 0.0035396
[Epoch 84; Iter   870/  960] train: loss: 0.0038377
[Epoch 84; Iter   900/  960] train: loss: 0.1008097
[Epoch 84; Iter   930/  960] train: loss: 0.0469564
[Epoch 84; Iter   960/  960] train: loss: 0.0267753
[Epoch 84] ogbg-molhiv: 0.720483 val loss: 0.252007
[Epoch 84] ogbg-molhiv: 0.763123 test loss: 0.200186
[Epoch 85; Iter    30/  960] train: loss: 0.0020870
[Epoch 85; Iter    60/  960] train: loss: 0.0052608
[Epoch 85; Iter    90/  960] train: loss: 0.0329991
[Epoch 85; Iter   120/  960] train: loss: 0.0206787
[Epoch 85; Iter   150/  960] train: loss: 0.0015570
[Epoch 85; Iter   180/  960] train: loss: 0.0006356
[Epoch 85; Iter   210/  960] train: loss: 0.0026716
[Epoch 85; Iter   240/  960] train: loss: 0.0610776
[Epoch 85; Iter   270/  960] train: loss: 0.0026836
[Epoch 85; Iter   300/  960] train: loss: 0.0022193
[Epoch 85; Iter   330/  960] train: loss: 0.0041478
[Epoch 85; Iter   360/  960] train: loss: 0.0153486
[Epoch 85; Iter   390/  960] train: loss: 0.0127661
[Epoch 85; Iter   420/  960] train: loss: 0.0167702
[Epoch 85; Iter   450/  960] train: loss: 0.0590964
[Epoch 85; Iter   480/  960] train: loss: 0.0025635
[Epoch 85; Iter   510/  960] train: loss: 0.0022624
[Epoch 85; Iter   540/  960] train: loss: 0.0183732
[Epoch 85; Iter   570/  960] train: loss: 0.0005449
[Epoch 85; Iter   600/  960] train: loss: 0.1127612
[Epoch 85; Iter   630/  960] train: loss: 0.0066884
[Epoch 85; Iter   660/  960] train: loss: 0.0754212
[Epoch 85; Iter   690/  960] train: loss: 0.0532924
[Epoch 85; Iter   720/  960] train: loss: 0.0845402
[Epoch 85; Iter   750/  960] train: loss: 0.0119062
[Epoch 85; Iter   780/  960] train: loss: 0.0157081
[Epoch 85; Iter   810/  960] train: loss: 0.0050652
[Epoch 85; Iter   840/  960] train: loss: 0.0010073
[Epoch 85; Iter   870/  960] train: loss: 0.0472742
[Epoch 85; Iter   900/  960] train: loss: 0.0159651
[Epoch 85; Iter   930/  960] train: loss: 0.0051736
[Epoch 85; Iter   960/  960] train: loss: 0.0030676
[Epoch 85] ogbg-molhiv: 0.720957 val loss: 0.353007
[Epoch 85] ogbg-molhiv: 0.751502 test loss: 0.404350
[Epoch 86; Iter    30/  960] train: loss: 0.0010992
[Epoch 86; Iter    60/  960] train: loss: 0.1271844
[Epoch 86; Iter    90/  960] train: loss: 0.0145646
[Epoch 86; Iter   120/  960] train: loss: 0.0003419
[Epoch 86; Iter   150/  960] train: loss: 0.0022574
[Epoch 86; Iter   180/  960] train: loss: 0.0027999
[Epoch 86; Iter   210/  960] train: loss: 0.0849833
[Epoch 86; Iter   240/  960] train: loss: 0.0115358
[Epoch 86; Iter   270/  960] train: loss: 0.0649823
[Epoch 86; Iter   300/  960] train: loss: 0.0020817
[Epoch 86; Iter   330/  960] train: loss: 0.0193156
[Epoch 86; Iter   360/  960] train: loss: 0.1487194
[Epoch 86; Iter   390/  960] train: loss: 0.0054981
[Epoch 86; Iter   420/  960] train: loss: 0.0040711
[Epoch 86; Iter   450/  960] train: loss: 0.0046539
[Epoch 86; Iter   480/  960] train: loss: 0.0239481
[Epoch 86; Iter   510/  960] train: loss: 0.0007434
[Epoch 86; Iter   540/  960] train: loss: 0.0075268
[Epoch 86; Iter   570/  960] train: loss: 0.0016268
[Epoch 86; Iter   600/  960] train: loss: 0.0238029
[Epoch 86; Iter   630/  960] train: loss: 0.0090122
[Epoch 86; Iter   660/  960] train: loss: 0.0060168
[Epoch 86; Iter   690/  960] train: loss: 0.0088777
[Epoch 86; Iter   720/  960] train: loss: 0.0025598
[Epoch 86; Iter   750/  960] train: loss: 0.0182985
[Epoch 86; Iter   780/  960] train: loss: 0.0721352
[Epoch 86; Iter   810/  960] train: loss: 0.0035054
[Epoch 86; Iter   840/  960] train: loss: 0.0249670
[Epoch 86; Iter   870/  960] train: loss: 0.0205173
[Epoch 86; Iter   900/  960] train: loss: 0.0082056
[Epoch 86; Iter   930/  960] train: loss: 0.0089843
[Epoch 86; Iter   960/  960] train: loss: 0.0026071
[Epoch 86] ogbg-molhiv: 0.723439 val loss: 0.255376
[Epoch 86] ogbg-molhiv: 0.759033 test loss: 0.208775
[Epoch 87; Iter    30/  960] train: loss: 0.0049324
[Epoch 87; Iter    60/  960] train: loss: 0.0338135
[Epoch 87; Iter    90/  960] train: loss: 0.0024147
[Epoch 87; Iter   120/  960] train: loss: 0.0176458
[Epoch 87; Iter   150/  960] train: loss: 0.0049773
[Epoch 87; Iter   180/  960] train: loss: 0.1039834
[Epoch 87; Iter   210/  960] train: loss: 0.0057233
[Epoch 87; Iter   240/  960] train: loss: 0.0008239
[Epoch 87; Iter   270/  960] train: loss: 0.0040861
[Epoch 87; Iter   300/  960] train: loss: 0.0129872
[Epoch 87; Iter   330/  960] train: loss: 0.0319764
[Epoch 87; Iter   360/  960] train: loss: 0.0740874
[Epoch 87; Iter   390/  960] train: loss: 0.0728901
[Epoch 87; Iter   420/  960] train: loss: 0.0318019
[Epoch 87; Iter   450/  960] train: loss: 0.0142621
[Epoch 87; Iter   480/  960] train: loss: 0.0006692
[Epoch 82; Iter   900/  960] train: loss: 0.0936774
[Epoch 82; Iter   930/  960] train: loss: 0.0404518
[Epoch 82; Iter   960/  960] train: loss: 0.0106793
[Epoch 82] ogbg-molhiv: 0.749868 val loss: 0.705688
[Epoch 82] ogbg-molhiv: 0.744011 test loss: 0.246694
[Epoch 83; Iter    30/  960] train: loss: 0.0597798
[Epoch 83; Iter    60/  960] train: loss: 0.0010548
[Epoch 83; Iter    90/  960] train: loss: 0.0720193
[Epoch 83; Iter   120/  960] train: loss: 0.0207665
[Epoch 83; Iter   150/  960] train: loss: 0.0196134
[Epoch 83; Iter   180/  960] train: loss: 0.0075241
[Epoch 83; Iter   210/  960] train: loss: 0.0224410
[Epoch 83; Iter   240/  960] train: loss: 0.0057605
[Epoch 83; Iter   270/  960] train: loss: 0.0172259
[Epoch 83; Iter   300/  960] train: loss: 0.0148107
[Epoch 83; Iter   330/  960] train: loss: 0.0283979
[Epoch 83; Iter   360/  960] train: loss: 0.1152389
[Epoch 83; Iter   390/  960] train: loss: 0.0232670
[Epoch 83; Iter   420/  960] train: loss: 0.0081856
[Epoch 83; Iter   450/  960] train: loss: 0.0834742
[Epoch 83; Iter   480/  960] train: loss: 0.0053321
[Epoch 83; Iter   510/  960] train: loss: 0.0266302
[Epoch 83; Iter   540/  960] train: loss: 0.0045509
[Epoch 83; Iter   570/  960] train: loss: 0.0037799
[Epoch 83; Iter   600/  960] train: loss: 0.0054355
[Epoch 83; Iter   630/  960] train: loss: 0.0025405
[Epoch 83; Iter   660/  960] train: loss: 0.0271072
[Epoch 83; Iter   690/  960] train: loss: 0.0016745
[Epoch 83; Iter   720/  960] train: loss: 0.0762550
[Epoch 83; Iter   750/  960] train: loss: 0.0336998
[Epoch 83; Iter   780/  960] train: loss: 0.0014740
[Epoch 83; Iter   810/  960] train: loss: 0.0644299
[Epoch 83; Iter   840/  960] train: loss: 0.0869973
[Epoch 83; Iter   870/  960] train: loss: 0.0083899
[Epoch 83; Iter   900/  960] train: loss: 0.0569257
[Epoch 83; Iter   930/  960] train: loss: 0.0938452
[Epoch 83; Iter   960/  960] train: loss: 0.0625124
[Epoch 83] ogbg-molhiv: 0.754530 val loss: 0.667895
[Epoch 83] ogbg-molhiv: 0.756651 test loss: 0.229542
[Epoch 84; Iter    30/  960] train: loss: 0.0086620
[Epoch 84; Iter    60/  960] train: loss: 0.0020390
[Epoch 84; Iter    90/  960] train: loss: 0.0041091
[Epoch 84; Iter   120/  960] train: loss: 0.0451435
[Epoch 84; Iter   150/  960] train: loss: 0.0238551
[Epoch 84; Iter   180/  960] train: loss: 0.0039513
[Epoch 84; Iter   210/  960] train: loss: 0.0085578
[Epoch 84; Iter   240/  960] train: loss: 0.0878709
[Epoch 84; Iter   270/  960] train: loss: 0.1104862
[Epoch 84; Iter   300/  960] train: loss: 0.0931082
[Epoch 84; Iter   330/  960] train: loss: 0.0029004
[Epoch 84; Iter   360/  960] train: loss: 0.0126415
[Epoch 84; Iter   390/  960] train: loss: 0.0302012
[Epoch 84; Iter   420/  960] train: loss: 0.0125134
[Epoch 84; Iter   450/  960] train: loss: 0.0509412
[Epoch 84; Iter   480/  960] train: loss: 0.0051890
[Epoch 84; Iter   510/  960] train: loss: 0.0076936
[Epoch 84; Iter   540/  960] train: loss: 0.0309165
[Epoch 84; Iter   570/  960] train: loss: 0.0097312
[Epoch 84; Iter   600/  960] train: loss: 0.0046026
[Epoch 84; Iter   630/  960] train: loss: 0.0339938
[Epoch 84; Iter   660/  960] train: loss: 0.0047834
[Epoch 84; Iter   690/  960] train: loss: 0.0215148
[Epoch 84; Iter   720/  960] train: loss: 0.0018983
[Epoch 84; Iter   750/  960] train: loss: 0.0028198
[Epoch 84; Iter   780/  960] train: loss: 0.0375948
[Epoch 84; Iter   810/  960] train: loss: 0.0188766
[Epoch 84; Iter   840/  960] train: loss: 0.0133976
[Epoch 84; Iter   870/  960] train: loss: 0.0192353
[Epoch 84; Iter   900/  960] train: loss: 0.0501047
[Epoch 84; Iter   930/  960] train: loss: 0.0735470
[Epoch 84; Iter   960/  960] train: loss: 0.1026217
[Epoch 84] ogbg-molhiv: 0.755972 val loss: 0.873771
[Epoch 84] ogbg-molhiv: 0.756315 test loss: 0.222464
[Epoch 85; Iter    30/  960] train: loss: 0.0255976
[Epoch 85; Iter    60/  960] train: loss: 0.0059537
[Epoch 85; Iter    90/  960] train: loss: 0.0128087
[Epoch 85; Iter   120/  960] train: loss: 0.0013037
[Epoch 85; Iter   150/  960] train: loss: 0.0165821
[Epoch 85; Iter   180/  960] train: loss: 0.0135106
[Epoch 85; Iter   210/  960] train: loss: 0.0073709
[Epoch 85; Iter   240/  960] train: loss: 0.0019039
[Epoch 85; Iter   270/  960] train: loss: 0.0042317
[Epoch 85; Iter   300/  960] train: loss: 0.0027300
[Epoch 85; Iter   330/  960] train: loss: 0.0417386
[Epoch 85; Iter   360/  960] train: loss: 0.0143446
[Epoch 85; Iter   390/  960] train: loss: 0.0282884
[Epoch 85; Iter   420/  960] train: loss: 0.0062459
[Epoch 85; Iter   450/  960] train: loss: 0.0718550
[Epoch 85; Iter   480/  960] train: loss: 0.0539027
[Epoch 85; Iter   510/  960] train: loss: 0.1863925
[Epoch 85; Iter   540/  960] train: loss: 0.0220003
[Epoch 85; Iter   570/  960] train: loss: 0.0194934
[Epoch 85; Iter   600/  960] train: loss: 0.0030296
[Epoch 85; Iter   630/  960] train: loss: 0.0022381
[Epoch 85; Iter   660/  960] train: loss: 0.0082603
[Epoch 85; Iter   690/  960] train: loss: 0.1040602
[Epoch 85; Iter   720/  960] train: loss: 0.0831082
[Epoch 85; Iter   750/  960] train: loss: 0.0500609
[Epoch 85; Iter   780/  960] train: loss: 0.0717074
[Epoch 85; Iter   810/  960] train: loss: 0.0342672
[Epoch 85; Iter   840/  960] train: loss: 0.0474347
[Epoch 85; Iter   870/  960] train: loss: 0.0091142
[Epoch 85; Iter   900/  960] train: loss: 0.0208649
[Epoch 85; Iter   930/  960] train: loss: 0.0636382
[Epoch 85; Iter   960/  960] train: loss: 0.0473317
[Epoch 85] ogbg-molhiv: 0.758979 val loss: 1.084291
[Epoch 85] ogbg-molhiv: 0.761102 test loss: 0.240467
[Epoch 86; Iter    30/  960] train: loss: 0.0016211
[Epoch 86; Iter    60/  960] train: loss: 0.0025284
[Epoch 86; Iter    90/  960] train: loss: 0.0535839
[Epoch 86; Iter   120/  960] train: loss: 0.0300311
[Epoch 86; Iter   150/  960] train: loss: 0.0236270
[Epoch 86; Iter   180/  960] train: loss: 0.0550760
[Epoch 86; Iter   210/  960] train: loss: 0.0426029
[Epoch 86; Iter   240/  960] train: loss: 0.0107182
[Epoch 86; Iter   270/  960] train: loss: 0.0354433
[Epoch 86; Iter   300/  960] train: loss: 0.0332834
[Epoch 86; Iter   330/  960] train: loss: 0.0027080
[Epoch 86; Iter   360/  960] train: loss: 0.0050183
[Epoch 86; Iter   390/  960] train: loss: 0.0069964
[Epoch 86; Iter   420/  960] train: loss: 0.0041904
[Epoch 86; Iter   450/  960] train: loss: 0.0305652
[Epoch 86; Iter   480/  960] train: loss: 0.1023994
[Epoch 86; Iter   510/  960] train: loss: 0.0355868
[Epoch 86; Iter   540/  960] train: loss: 0.0246223
[Epoch 86; Iter   570/  960] train: loss: 0.1036915
[Epoch 86; Iter   600/  960] train: loss: 0.0018913
[Epoch 86; Iter   630/  960] train: loss: 0.0234908
[Epoch 86; Iter   660/  960] train: loss: 0.0268969
[Epoch 86; Iter   690/  960] train: loss: 0.0360712
[Epoch 86; Iter   720/  960] train: loss: 0.0029000
[Epoch 86; Iter   750/  960] train: loss: 0.0106902
[Epoch 86; Iter   780/  960] train: loss: 0.0444816
[Epoch 86; Iter   810/  960] train: loss: 0.0013181
[Epoch 86; Iter   840/  960] train: loss: 0.0107531
[Epoch 86; Iter   870/  960] train: loss: 0.0056635
[Epoch 86; Iter   900/  960] train: loss: 0.0117283
[Epoch 86; Iter   930/  960] train: loss: 0.0200252
[Epoch 86; Iter   960/  960] train: loss: 0.1900824
[Epoch 86] ogbg-molhiv: 0.755348 val loss: 1.187638
[Epoch 86] ogbg-molhiv: 0.757798 test loss: 0.272188
[Epoch 87; Iter    30/  960] train: loss: 0.0014070
[Epoch 87; Iter    60/  960] train: loss: 0.0108998
[Epoch 87; Iter    90/  960] train: loss: 0.0065448
[Epoch 87; Iter   120/  960] train: loss: 0.0308583
[Epoch 87; Iter   150/  960] train: loss: 0.0059438
[Epoch 87; Iter   180/  960] train: loss: 0.0011186
[Epoch 87; Iter   210/  960] train: loss: 0.0010251
[Epoch 87; Iter   240/  960] train: loss: 0.0157578
[Epoch 87; Iter   270/  960] train: loss: 0.0017999
[Epoch 87; Iter   300/  960] train: loss: 0.0065038
[Epoch 87; Iter   330/  960] train: loss: 0.0230828
[Epoch 87; Iter   360/  960] train: loss: 0.0097819
[Epoch 87; Iter   390/  960] train: loss: 0.0217533
[Epoch 87; Iter   420/  960] train: loss: 0.0021197
[Epoch 87; Iter   450/  960] train: loss: 0.0022955
[Epoch 87; Iter   480/  960] train: loss: 0.0152691
[Epoch 81; Iter   380/ 1097] train: loss: 0.0473899
[Epoch 81; Iter   410/ 1097] train: loss: 0.0069251
[Epoch 81; Iter   440/ 1097] train: loss: 0.0031240
[Epoch 81; Iter   470/ 1097] train: loss: 0.1828319
[Epoch 81; Iter   500/ 1097] train: loss: 0.0118909
[Epoch 81; Iter   530/ 1097] train: loss: 0.0116963
[Epoch 81; Iter   560/ 1097] train: loss: 0.0027239
[Epoch 81; Iter   590/ 1097] train: loss: 0.0205290
[Epoch 81; Iter   620/ 1097] train: loss: 0.0064671
[Epoch 81; Iter   650/ 1097] train: loss: 0.0882455
[Epoch 81; Iter   680/ 1097] train: loss: 0.0158733
[Epoch 81; Iter   710/ 1097] train: loss: 0.0174162
[Epoch 81; Iter   740/ 1097] train: loss: 0.0156124
[Epoch 81; Iter   770/ 1097] train: loss: 0.0697744
[Epoch 81; Iter   800/ 1097] train: loss: 0.0123671
[Epoch 81; Iter   830/ 1097] train: loss: 0.0092478
[Epoch 81; Iter   860/ 1097] train: loss: 0.0969733
[Epoch 81; Iter   890/ 1097] train: loss: 0.0474054
[Epoch 81; Iter   920/ 1097] train: loss: 0.0824837
[Epoch 81; Iter   950/ 1097] train: loss: 0.0070286
[Epoch 81; Iter   980/ 1097] train: loss: 0.0140349
[Epoch 81; Iter  1010/ 1097] train: loss: 0.1215600
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0602422
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0154489
[Epoch 81] ogbg-molhiv: 0.759002 val loss: 0.232185
[Epoch 81] ogbg-molhiv: 0.731717 test loss: 0.923213
[Epoch 82; Iter     3/ 1097] train: loss: 0.0453551
[Epoch 82; Iter    33/ 1097] train: loss: 0.0032729
[Epoch 82; Iter    63/ 1097] train: loss: 0.0195035
[Epoch 82; Iter    93/ 1097] train: loss: 0.0025596
[Epoch 82; Iter   123/ 1097] train: loss: 0.1217890
[Epoch 82; Iter   153/ 1097] train: loss: 0.0149453
[Epoch 82; Iter   183/ 1097] train: loss: 0.1945739
[Epoch 82; Iter   213/ 1097] train: loss: 0.0340473
[Epoch 82; Iter   243/ 1097] train: loss: 0.0670878
[Epoch 82; Iter   273/ 1097] train: loss: 0.0653074
[Epoch 82; Iter   303/ 1097] train: loss: 0.0189130
[Epoch 82; Iter   333/ 1097] train: loss: 0.0022828
[Epoch 82; Iter   363/ 1097] train: loss: 0.0250337
[Epoch 82; Iter   393/ 1097] train: loss: 0.0080321
[Epoch 82; Iter   423/ 1097] train: loss: 0.1179072
[Epoch 82; Iter   453/ 1097] train: loss: 0.0768729
[Epoch 82; Iter   483/ 1097] train: loss: 0.0329405
[Epoch 82; Iter   513/ 1097] train: loss: 0.0098139
[Epoch 82; Iter   543/ 1097] train: loss: 0.0083115
[Epoch 82; Iter   573/ 1097] train: loss: 0.0732104
[Epoch 82; Iter   603/ 1097] train: loss: 0.0094273
[Epoch 82; Iter   633/ 1097] train: loss: 0.0340653
[Epoch 82; Iter   663/ 1097] train: loss: 0.0079068
[Epoch 82; Iter   693/ 1097] train: loss: 0.0225098
[Epoch 82; Iter   723/ 1097] train: loss: 0.0290538
[Epoch 82; Iter   753/ 1097] train: loss: 0.0623703
[Epoch 82; Iter   783/ 1097] train: loss: 0.0386162
[Epoch 82; Iter   813/ 1097] train: loss: 0.0358989
[Epoch 82; Iter   843/ 1097] train: loss: 0.0061970
[Epoch 82; Iter   873/ 1097] train: loss: 0.1295026
[Epoch 82; Iter   903/ 1097] train: loss: 0.0162057
[Epoch 82; Iter   933/ 1097] train: loss: 0.0046702
[Epoch 82; Iter   963/ 1097] train: loss: 0.0099502
[Epoch 82; Iter   993/ 1097] train: loss: 0.0291365
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0135843
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0110720
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0088915
[Epoch 82] ogbg-molhiv: 0.761810 val loss: 0.219923
[Epoch 82] ogbg-molhiv: 0.734099 test loss: 0.649566
[Epoch 83; Iter    16/ 1097] train: loss: 0.0172718
[Epoch 83; Iter    46/ 1097] train: loss: 0.0038820
[Epoch 83; Iter    76/ 1097] train: loss: 0.0024738
[Epoch 83; Iter   106/ 1097] train: loss: 0.0060898
[Epoch 83; Iter   136/ 1097] train: loss: 0.0281266
[Epoch 83; Iter   166/ 1097] train: loss: 0.0625444
[Epoch 83; Iter   196/ 1097] train: loss: 0.0018746
[Epoch 83; Iter   226/ 1097] train: loss: 0.0911371
[Epoch 83; Iter   256/ 1097] train: loss: 0.0205352
[Epoch 83; Iter   286/ 1097] train: loss: 0.0177651
[Epoch 83; Iter   316/ 1097] train: loss: 0.1041202
[Epoch 83; Iter   346/ 1097] train: loss: 0.0539296
[Epoch 83; Iter   376/ 1097] train: loss: 0.0333081
[Epoch 83; Iter   406/ 1097] train: loss: 0.0033071
[Epoch 83; Iter   436/ 1097] train: loss: 0.0096289
[Epoch 83; Iter   466/ 1097] train: loss: 0.0056074
[Epoch 83; Iter   496/ 1097] train: loss: 0.0126097
[Epoch 83; Iter   526/ 1097] train: loss: 0.0037597
[Epoch 83; Iter   556/ 1097] train: loss: 0.0051732
[Epoch 83; Iter   586/ 1097] train: loss: 0.0024427
[Epoch 83; Iter   616/ 1097] train: loss: 0.0087060
[Epoch 83; Iter   646/ 1097] train: loss: 0.0506936
[Epoch 83; Iter   676/ 1097] train: loss: 0.0254195
[Epoch 83; Iter   706/ 1097] train: loss: 0.0094326
[Epoch 83; Iter   736/ 1097] train: loss: 0.0281216
[Epoch 83; Iter   766/ 1097] train: loss: 0.0545049
[Epoch 83; Iter   796/ 1097] train: loss: 0.0995447
[Epoch 83; Iter   826/ 1097] train: loss: 0.1970669
[Epoch 83; Iter   856/ 1097] train: loss: 0.0260670
[Epoch 83; Iter   886/ 1097] train: loss: 0.0164475
[Epoch 83; Iter   916/ 1097] train: loss: 0.0099424
[Epoch 83; Iter   946/ 1097] train: loss: 0.0394784
[Epoch 83; Iter   976/ 1097] train: loss: 0.0031743
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0327839
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0348423
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0091754
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0116659
[Epoch 83] ogbg-molhiv: 0.762211 val loss: 0.130897
[Epoch 83] ogbg-molhiv: 0.736546 test loss: 0.294900
[Epoch 84; Iter    29/ 1097] train: loss: 0.0044919
[Epoch 84; Iter    59/ 1097] train: loss: 0.0205215
[Epoch 84; Iter    89/ 1097] train: loss: 0.0733253
[Epoch 84; Iter   119/ 1097] train: loss: 0.0102151
[Epoch 84; Iter   149/ 1097] train: loss: 0.0010499
[Epoch 84; Iter   179/ 1097] train: loss: 0.0356131
[Epoch 84; Iter   209/ 1097] train: loss: 0.0188918
[Epoch 84; Iter   239/ 1097] train: loss: 0.0084595
[Epoch 84; Iter   269/ 1097] train: loss: 0.1309453
[Epoch 84; Iter   299/ 1097] train: loss: 0.0597074
[Epoch 84; Iter   329/ 1097] train: loss: 0.0070928
[Epoch 84; Iter   359/ 1097] train: loss: 0.0821710
[Epoch 84; Iter   389/ 1097] train: loss: 0.0103662
[Epoch 84; Iter   419/ 1097] train: loss: 0.0139086
[Epoch 84; Iter   449/ 1097] train: loss: 0.0043766
[Epoch 84; Iter   479/ 1097] train: loss: 0.0187391
[Epoch 84; Iter   509/ 1097] train: loss: 0.0093763
[Epoch 84; Iter   539/ 1097] train: loss: 0.0048426
[Epoch 84; Iter   569/ 1097] train: loss: 0.0900620
[Epoch 84; Iter   599/ 1097] train: loss: 0.0023977
[Epoch 84; Iter   629/ 1097] train: loss: 0.0332211
[Epoch 84; Iter   659/ 1097] train: loss: 0.0223490
[Epoch 84; Iter   689/ 1097] train: loss: 0.0096938
[Epoch 84; Iter   719/ 1097] train: loss: 0.0289059
[Epoch 84; Iter   749/ 1097] train: loss: 0.0122759
[Epoch 84; Iter   779/ 1097] train: loss: 0.0128080
[Epoch 84; Iter   809/ 1097] train: loss: 0.0049617
[Epoch 84; Iter   839/ 1097] train: loss: 0.0147499
[Epoch 84; Iter   869/ 1097] train: loss: 0.0087076
[Epoch 84; Iter   899/ 1097] train: loss: 0.0125589
[Epoch 84; Iter   929/ 1097] train: loss: 0.0373474
[Epoch 84; Iter   959/ 1097] train: loss: 0.0100731
[Epoch 84; Iter   989/ 1097] train: loss: 0.0032040
[Epoch 84; Iter  1019/ 1097] train: loss: 0.1045197
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0077478
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0016773
[Epoch 84] ogbg-molhiv: 0.752750 val loss: 0.221260
[Epoch 84] ogbg-molhiv: 0.723146 test loss: 0.664082
[Epoch 85; Iter    12/ 1097] train: loss: 0.0299626
[Epoch 85; Iter    42/ 1097] train: loss: 0.0132102
[Epoch 85; Iter    72/ 1097] train: loss: 0.0027430
[Epoch 85; Iter   102/ 1097] train: loss: 0.1165891
[Epoch 85; Iter   132/ 1097] train: loss: 0.0031465
[Epoch 85; Iter   162/ 1097] train: loss: 0.0059490
[Epoch 85; Iter   192/ 1097] train: loss: 0.0039063
[Epoch 85; Iter   222/ 1097] train: loss: 0.0143690
[Epoch 85; Iter   252/ 1097] train: loss: 0.0219978
[Epoch 85; Iter   282/ 1097] train: loss: 0.0603603
[Epoch 85; Iter   312/ 1097] train: loss: 0.0403205
[Epoch 85; Iter   342/ 1097] train: loss: 0.0797992
[Epoch 85; Iter   372/ 1097] train: loss: 0.0071335
[Epoch 85; Iter   402/ 1097] train: loss: 0.0101931
[Epoch 85; Iter   432/ 1097] train: loss: 0.0264047
[Epoch 82; Iter   900/  960] train: loss: 0.0066566
[Epoch 82; Iter   930/  960] train: loss: 0.0070456
[Epoch 82; Iter   960/  960] train: loss: 0.0907791
[Epoch 82] ogbg-molhiv: 0.723067 val loss: 0.990795
[Epoch 82] ogbg-molhiv: 0.755246 test loss: 0.601120
[Epoch 83; Iter    30/  960] train: loss: 0.0061373
[Epoch 83; Iter    60/  960] train: loss: 0.0032105
[Epoch 83; Iter    90/  960] train: loss: 0.0027333
[Epoch 83; Iter   120/  960] train: loss: 0.0074466
[Epoch 83; Iter   150/  960] train: loss: 0.0087235
[Epoch 83; Iter   180/  960] train: loss: 0.0026301
[Epoch 83; Iter   210/  960] train: loss: 0.0157072
[Epoch 83; Iter   240/  960] train: loss: 0.0334382
[Epoch 83; Iter   270/  960] train: loss: 0.0480166
[Epoch 83; Iter   300/  960] train: loss: 0.0934663
[Epoch 83; Iter   330/  960] train: loss: 0.0013511
[Epoch 83; Iter   360/  960] train: loss: 0.0059955
[Epoch 83; Iter   390/  960] train: loss: 0.1042230
[Epoch 83; Iter   420/  960] train: loss: 0.0047370
[Epoch 83; Iter   450/  960] train: loss: 0.0028900
[Epoch 83; Iter   480/  960] train: loss: 0.0085717
[Epoch 83; Iter   510/  960] train: loss: 0.0201264
[Epoch 83; Iter   540/  960] train: loss: 0.0197055
[Epoch 83; Iter   570/  960] train: loss: 0.0022061
[Epoch 83; Iter   600/  960] train: loss: 0.0011036
[Epoch 83; Iter   630/  960] train: loss: 0.0039013
[Epoch 83; Iter   660/  960] train: loss: 0.0185704
[Epoch 83; Iter   690/  960] train: loss: 0.1420762
[Epoch 83; Iter   720/  960] train: loss: 0.2066924
[Epoch 83; Iter   750/  960] train: loss: 0.0273866
[Epoch 83; Iter   780/  960] train: loss: 0.0023386
[Epoch 83; Iter   810/  960] train: loss: 0.0503503
[Epoch 83; Iter   840/  960] train: loss: 0.0244021
[Epoch 83; Iter   870/  960] train: loss: 0.0316018
[Epoch 83; Iter   900/  960] train: loss: 0.0118344
[Epoch 83; Iter   930/  960] train: loss: 0.0329537
[Epoch 83; Iter   960/  960] train: loss: 0.0893892
[Epoch 83] ogbg-molhiv: 0.720201 val loss: 0.926356
[Epoch 83] ogbg-molhiv: 0.744543 test loss: 0.501627
[Epoch 84; Iter    30/  960] train: loss: 0.0016547
[Epoch 84; Iter    60/  960] train: loss: 0.0472770
[Epoch 84; Iter    90/  960] train: loss: 0.0065068
[Epoch 84; Iter   120/  960] train: loss: 0.0532082
[Epoch 84; Iter   150/  960] train: loss: 0.0021005
[Epoch 84; Iter   180/  960] train: loss: 0.0076862
[Epoch 84; Iter   210/  960] train: loss: 0.0024406
[Epoch 84; Iter   240/  960] train: loss: 0.0075172
[Epoch 84; Iter   270/  960] train: loss: 0.0035246
[Epoch 84; Iter   300/  960] train: loss: 0.0198992
[Epoch 84; Iter   330/  960] train: loss: 0.0059893
[Epoch 84; Iter   360/  960] train: loss: 0.0075076
[Epoch 84; Iter   390/  960] train: loss: 0.0197750
[Epoch 84; Iter   420/  960] train: loss: 0.0224138
[Epoch 84; Iter   450/  960] train: loss: 0.1472815
[Epoch 84; Iter   480/  960] train: loss: 0.0391649
[Epoch 84; Iter   510/  960] train: loss: 0.0123436
[Epoch 84; Iter   540/  960] train: loss: 0.0060841
[Epoch 84; Iter   570/  960] train: loss: 0.0523274
[Epoch 84; Iter   600/  960] train: loss: 0.0964849
[Epoch 84; Iter   630/  960] train: loss: 0.0281620
[Epoch 84; Iter   660/  960] train: loss: 0.0086987
[Epoch 84; Iter   690/  960] train: loss: 0.0596223
[Epoch 84; Iter   720/  960] train: loss: 0.0204053
[Epoch 84; Iter   750/  960] train: loss: 0.0100795
[Epoch 84; Iter   780/  960] train: loss: 0.0553510
[Epoch 84; Iter   810/  960] train: loss: 0.0425140
[Epoch 84; Iter   840/  960] train: loss: 0.0096803
[Epoch 84; Iter   870/  960] train: loss: 0.0041001
[Epoch 84; Iter   900/  960] train: loss: 0.0042139
[Epoch 84; Iter   930/  960] train: loss: 0.0046851
[Epoch 84; Iter   960/  960] train: loss: 0.0074579
[Epoch 84] ogbg-molhiv: 0.713993 val loss: 0.985284
[Epoch 84] ogbg-molhiv: 0.744810 test loss: 0.531475
[Epoch 85; Iter    30/  960] train: loss: 0.0300558
[Epoch 85; Iter    60/  960] train: loss: 0.0073141
[Epoch 85; Iter    90/  960] train: loss: 0.0052009
[Epoch 85; Iter   120/  960] train: loss: 0.0191889
[Epoch 85; Iter   150/  960] train: loss: 0.0028979
[Epoch 85; Iter   180/  960] train: loss: 0.0098653
[Epoch 85; Iter   210/  960] train: loss: 0.0336787
[Epoch 85; Iter   240/  960] train: loss: 0.0469896
[Epoch 85; Iter   270/  960] train: loss: 0.0040858
[Epoch 85; Iter   300/  960] train: loss: 0.0048693
[Epoch 85; Iter   330/  960] train: loss: 0.0069720
[Epoch 85; Iter   360/  960] train: loss: 0.0043207
[Epoch 85; Iter   390/  960] train: loss: 0.0065129
[Epoch 85; Iter   420/  960] train: loss: 0.0120511
[Epoch 85; Iter   450/  960] train: loss: 0.1247867
[Epoch 85; Iter   480/  960] train: loss: 0.0098277
[Epoch 85; Iter   510/  960] train: loss: 0.0348599
[Epoch 85; Iter   540/  960] train: loss: 0.0025695
[Epoch 85; Iter   570/  960] train: loss: 0.0381270
[Epoch 85; Iter   600/  960] train: loss: 0.0338190
[Epoch 85; Iter   630/  960] train: loss: 0.0026361
[Epoch 85; Iter   660/  960] train: loss: 0.0281498
[Epoch 85; Iter   690/  960] train: loss: 0.0740607
[Epoch 85; Iter   720/  960] train: loss: 0.0028921
[Epoch 85; Iter   750/  960] train: loss: 0.0044992
[Epoch 85; Iter   780/  960] train: loss: 0.1003614
[Epoch 85; Iter   810/  960] train: loss: 0.0073725
[Epoch 85; Iter   840/  960] train: loss: 0.0152051
[Epoch 85; Iter   870/  960] train: loss: 0.0496484
[Epoch 85; Iter   900/  960] train: loss: 0.0235593
[Epoch 85; Iter   930/  960] train: loss: 0.0179122
[Epoch 85; Iter   960/  960] train: loss: 0.0018161
[Epoch 85] ogbg-molhiv: 0.724218 val loss: 0.300597
[Epoch 85] ogbg-molhiv: 0.742592 test loss: 0.210096
[Epoch 86; Iter    30/  960] train: loss: 0.0216718
[Epoch 86; Iter    60/  960] train: loss: 0.0011628
[Epoch 86; Iter    90/  960] train: loss: 0.0074422
[Epoch 86; Iter   120/  960] train: loss: 0.0064122
[Epoch 86; Iter   150/  960] train: loss: 0.0545951
[Epoch 86; Iter   180/  960] train: loss: 0.0311715
[Epoch 86; Iter   210/  960] train: loss: 0.0052215
[Epoch 86; Iter   240/  960] train: loss: 0.0102707
[Epoch 86; Iter   270/  960] train: loss: 0.0039088
[Epoch 86; Iter   300/  960] train: loss: 0.0013042
[Epoch 86; Iter   330/  960] train: loss: 0.0011949
[Epoch 86; Iter   360/  960] train: loss: 0.0103913
[Epoch 86; Iter   390/  960] train: loss: 0.0082202
[Epoch 86; Iter   420/  960] train: loss: 0.1109202
[Epoch 86; Iter   450/  960] train: loss: 0.0128110
[Epoch 86; Iter   480/  960] train: loss: 0.0141996
[Epoch 86; Iter   510/  960] train: loss: 0.0020307
[Epoch 86; Iter   540/  960] train: loss: 0.0900728
[Epoch 86; Iter   570/  960] train: loss: 0.0053373
[Epoch 86; Iter   600/  960] train: loss: 0.0060165
[Epoch 86; Iter   630/  960] train: loss: 0.0043526
[Epoch 86; Iter   660/  960] train: loss: 0.1647067
[Epoch 86; Iter   690/  960] train: loss: 0.0044337
[Epoch 86; Iter   720/  960] train: loss: 0.0040103
[Epoch 86; Iter   750/  960] train: loss: 0.0058247
[Epoch 86; Iter   780/  960] train: loss: 0.0582379
[Epoch 86; Iter   810/  960] train: loss: 0.0047359
[Epoch 86; Iter   840/  960] train: loss: 0.0052530
[Epoch 86; Iter   870/  960] train: loss: 0.0297704
[Epoch 86; Iter   900/  960] train: loss: 0.0117890
[Epoch 86; Iter   930/  960] train: loss: 0.0095131
[Epoch 86; Iter   960/  960] train: loss: 0.0371066
[Epoch 86] ogbg-molhiv: 0.719802 val loss: 1.196772
[Epoch 86] ogbg-molhiv: 0.751133 test loss: 0.880501
[Epoch 87; Iter    30/  960] train: loss: 0.0006820
[Epoch 87; Iter    60/  960] train: loss: 0.0081223
[Epoch 87; Iter    90/  960] train: loss: 0.0015759
[Epoch 87; Iter   120/  960] train: loss: 0.0157645
[Epoch 87; Iter   150/  960] train: loss: 0.1741460
[Epoch 87; Iter   180/  960] train: loss: 0.0261235
[Epoch 87; Iter   210/  960] train: loss: 0.0047103
[Epoch 87; Iter   240/  960] train: loss: 0.0038522
[Epoch 87; Iter   270/  960] train: loss: 0.0030344
[Epoch 87; Iter   300/  960] train: loss: 0.0126339
[Epoch 87; Iter   330/  960] train: loss: 0.0209406
[Epoch 87; Iter   360/  960] train: loss: 0.0041814
[Epoch 87; Iter   390/  960] train: loss: 0.0047810
[Epoch 87; Iter   420/  960] train: loss: 0.0015842
[Epoch 87; Iter   450/  960] train: loss: 0.0113444
[Epoch 87; Iter   480/  960] train: loss: 0.0208592
[Epoch 84; Iter   781/  823] train: loss: 0.0999892
[Epoch 84; Iter   811/  823] train: loss: 0.0164510
[Epoch 84] ogbg-molhiv: 0.737285 val loss: 0.307617
[Epoch 84] ogbg-molhiv: 0.755082 test loss: 0.257930
[Epoch 85; Iter    18/  823] train: loss: 0.0043715
[Epoch 85; Iter    48/  823] train: loss: 0.0001879
[Epoch 85; Iter    78/  823] train: loss: 0.0051175
[Epoch 85; Iter   108/  823] train: loss: 0.0038186
[Epoch 85; Iter   138/  823] train: loss: 0.0055230
[Epoch 85; Iter   168/  823] train: loss: 0.0035981
[Epoch 85; Iter   198/  823] train: loss: 0.0070442
[Epoch 85; Iter   228/  823] train: loss: 0.0037587
[Epoch 85; Iter   258/  823] train: loss: 0.0147228
[Epoch 85; Iter   288/  823] train: loss: 0.0808543
[Epoch 85; Iter   318/  823] train: loss: 0.0045011
[Epoch 85; Iter   348/  823] train: loss: 0.0084795
[Epoch 85; Iter   378/  823] train: loss: 0.0064887
[Epoch 85; Iter   408/  823] train: loss: 0.0190809
[Epoch 85; Iter   438/  823] train: loss: 0.0014710
[Epoch 85; Iter   468/  823] train: loss: 0.0043365
[Epoch 85; Iter   498/  823] train: loss: 0.0042868
[Epoch 85; Iter   528/  823] train: loss: 0.0011676
[Epoch 85; Iter   558/  823] train: loss: 0.0035225
[Epoch 85; Iter   588/  823] train: loss: 0.0494458
[Epoch 85; Iter   618/  823] train: loss: 0.0138539
[Epoch 85; Iter   648/  823] train: loss: 0.1634064
[Epoch 85; Iter   678/  823] train: loss: 0.0602065
[Epoch 85; Iter   708/  823] train: loss: 0.0235013
[Epoch 85; Iter   738/  823] train: loss: 0.0003471
[Epoch 85; Iter   768/  823] train: loss: 0.0605659
[Epoch 85; Iter   798/  823] train: loss: 0.0004935
[Epoch 85] ogbg-molhiv: 0.743017 val loss: 0.306507
[Epoch 85] ogbg-molhiv: 0.758300 test loss: 0.273666
[Epoch 86; Iter     5/  823] train: loss: 0.0257918
[Epoch 86; Iter    35/  823] train: loss: 0.0843356
[Epoch 86; Iter    65/  823] train: loss: 0.0020045
[Epoch 86; Iter    95/  823] train: loss: 0.0170345
[Epoch 86; Iter   125/  823] train: loss: 0.0057831
[Epoch 86; Iter   155/  823] train: loss: 0.1749085
[Epoch 86; Iter   185/  823] train: loss: 0.0007687
[Epoch 86; Iter   215/  823] train: loss: 0.0020539
[Epoch 86; Iter   245/  823] train: loss: 0.0265558
[Epoch 86; Iter   275/  823] train: loss: 0.0041125
[Epoch 86; Iter   305/  823] train: loss: 0.0094958
[Epoch 86; Iter   335/  823] train: loss: 0.0083610
[Epoch 86; Iter   365/  823] train: loss: 0.0084062
[Epoch 86; Iter   395/  823] train: loss: 0.0219269
[Epoch 86; Iter   425/  823] train: loss: 0.0101491
[Epoch 86; Iter   455/  823] train: loss: 0.0028435
[Epoch 86; Iter   485/  823] train: loss: 0.0078715
[Epoch 86; Iter   515/  823] train: loss: 0.0040074
[Epoch 86; Iter   545/  823] train: loss: 0.0076712
[Epoch 86; Iter   575/  823] train: loss: 0.0228325
[Epoch 86; Iter   605/  823] train: loss: 0.0648966
[Epoch 86; Iter   635/  823] train: loss: 0.0037872
[Epoch 86; Iter   665/  823] train: loss: 0.0053519
[Epoch 86; Iter   695/  823] train: loss: 0.0064691
[Epoch 86; Iter   725/  823] train: loss: 0.0196793
[Epoch 86; Iter   755/  823] train: loss: 0.0183235
[Epoch 86; Iter   785/  823] train: loss: 0.0018582
[Epoch 86; Iter   815/  823] train: loss: 0.0184950
[Epoch 86] ogbg-molhiv: 0.749887 val loss: 0.263090
[Epoch 86] ogbg-molhiv: 0.767555 test loss: 0.208995
[Epoch 87; Iter    22/  823] train: loss: 0.0106304
[Epoch 87; Iter    52/  823] train: loss: 0.0064607
[Epoch 87; Iter    82/  823] train: loss: 0.0029501
[Epoch 87; Iter   112/  823] train: loss: 0.0084398
[Epoch 87; Iter   142/  823] train: loss: 0.0027229
[Epoch 87; Iter   172/  823] train: loss: 0.0042547
[Epoch 87; Iter   202/  823] train: loss: 0.0030832
[Epoch 87; Iter   232/  823] train: loss: 0.0141216
[Epoch 87; Iter   262/  823] train: loss: 0.0322104
[Epoch 87; Iter   292/  823] train: loss: 0.0474195
[Epoch 87; Iter   322/  823] train: loss: 0.0097255
[Epoch 87; Iter   352/  823] train: loss: 0.0864710
[Epoch 87; Iter   382/  823] train: loss: 0.0002482
[Epoch 87; Iter   412/  823] train: loss: 0.0036927
[Epoch 87; Iter   442/  823] train: loss: 0.0182422
[Epoch 87; Iter   472/  823] train: loss: 0.0115794
[Epoch 87; Iter   502/  823] train: loss: 0.0019691
[Epoch 87; Iter   532/  823] train: loss: 0.1009796
[Epoch 87; Iter   562/  823] train: loss: 0.0026700
[Epoch 87; Iter   592/  823] train: loss: 0.0114430
[Epoch 87; Iter   622/  823] train: loss: 0.0189068
[Epoch 87; Iter   652/  823] train: loss: 0.0028704
[Epoch 87; Iter   682/  823] train: loss: 0.1935332
[Epoch 87; Iter   712/  823] train: loss: 0.0120389
[Epoch 87; Iter   742/  823] train: loss: 0.0096439
[Epoch 87; Iter   772/  823] train: loss: 0.0045028
[Epoch 87; Iter   802/  823] train: loss: 0.0050729
[Epoch 87] ogbg-molhiv: 0.738693 val loss: 0.313858
[Epoch 87] ogbg-molhiv: 0.755181 test loss: 0.245876
[Epoch 88; Iter     9/  823] train: loss: 0.0057736
[Epoch 88; Iter    39/  823] train: loss: 0.0041097
[Epoch 88; Iter    69/  823] train: loss: 0.0043794
[Epoch 88; Iter    99/  823] train: loss: 0.0265725
[Epoch 88; Iter   129/  823] train: loss: 0.0169926
[Epoch 88; Iter   159/  823] train: loss: 0.0121585
[Epoch 88; Iter   189/  823] train: loss: 0.0229992
[Epoch 88; Iter   219/  823] train: loss: 0.0121972
[Epoch 88; Iter   249/  823] train: loss: 0.0672308
[Epoch 88; Iter   279/  823] train: loss: 0.0512526
[Epoch 88; Iter   309/  823] train: loss: 0.0035374
[Epoch 88; Iter   339/  823] train: loss: 0.0005133
[Epoch 88; Iter   369/  823] train: loss: 0.0007792
[Epoch 88; Iter   399/  823] train: loss: 0.0625040
[Epoch 88; Iter   429/  823] train: loss: 0.0023663
[Epoch 88; Iter   459/  823] train: loss: 0.0027401
[Epoch 88; Iter   489/  823] train: loss: 0.0211920
[Epoch 88; Iter   519/  823] train: loss: 0.0012415
[Epoch 88; Iter   549/  823] train: loss: 0.0430399
[Epoch 88; Iter   579/  823] train: loss: 0.0043983
[Epoch 88; Iter   609/  823] train: loss: 0.0250532
[Epoch 88; Iter   639/  823] train: loss: 0.0086579
[Epoch 88; Iter   669/  823] train: loss: 0.0244588
[Epoch 88; Iter   699/  823] train: loss: 0.0015903
[Epoch 88; Iter   729/  823] train: loss: 0.0026678
[Epoch 88; Iter   759/  823] train: loss: 0.0023283
[Epoch 88; Iter   789/  823] train: loss: 0.0002235
[Epoch 88; Iter   819/  823] train: loss: 0.0111046
[Epoch 88] ogbg-molhiv: 0.745948 val loss: 0.313420
[Epoch 88] ogbg-molhiv: 0.758244 test loss: 0.249483
[Epoch 89; Iter    26/  823] train: loss: 0.0445098
[Epoch 89; Iter    56/  823] train: loss: 0.0017781
[Epoch 89; Iter    86/  823] train: loss: 0.0024451
[Epoch 89; Iter   116/  823] train: loss: 0.0007354
[Epoch 89; Iter   146/  823] train: loss: 0.0094882
[Epoch 89; Iter   176/  823] train: loss: 0.0158764
[Epoch 89; Iter   206/  823] train: loss: 0.0033209
[Epoch 89; Iter   236/  823] train: loss: 0.0017648
[Epoch 89; Iter   266/  823] train: loss: 0.0034954
[Epoch 89; Iter   296/  823] train: loss: 0.0021285
[Epoch 89; Iter   326/  823] train: loss: 0.0355993
[Epoch 89; Iter   356/  823] train: loss: 0.0027540
[Epoch 89; Iter   386/  823] train: loss: 0.0677794
[Epoch 89; Iter   416/  823] train: loss: 0.0147470
[Epoch 89; Iter   446/  823] train: loss: 0.0486830
[Epoch 89; Iter   476/  823] train: loss: 0.0128916
[Epoch 89; Iter   506/  823] train: loss: 0.0242347
[Epoch 89; Iter   536/  823] train: loss: 0.0287243
[Epoch 89; Iter   566/  823] train: loss: 0.0152891
[Epoch 89; Iter   596/  823] train: loss: 0.0190337
[Epoch 89; Iter   626/  823] train: loss: 0.0019932
[Epoch 89; Iter   656/  823] train: loss: 0.0032688
[Epoch 89; Iter   686/  823] train: loss: 0.1120669
[Epoch 89; Iter   716/  823] train: loss: 0.0021283
[Epoch 89; Iter   746/  823] train: loss: 0.0093413
[Epoch 89; Iter   776/  823] train: loss: 0.0540202
[Epoch 89; Iter   806/  823] train: loss: 0.0006926
[Epoch 89] ogbg-molhiv: 0.731416 val loss: 0.319726
[Epoch 89] ogbg-molhiv: 0.751961 test loss: 0.264020
[Epoch 90; Iter    13/  823] train: loss: 0.0032778
[Epoch 90; Iter    43/  823] train: loss: 0.0200238
[Epoch 90; Iter    73/  823] train: loss: 0.0206605
[Epoch 90; Iter   103/  823] train: loss: 0.0170930
[Epoch 90; Iter   133/  823] train: loss: 0.0343192
[Epoch 90; Iter   163/  823] train: loss: 0.0123294
[Epoch 81; Iter   380/ 1097] train: loss: 0.0432418
[Epoch 81; Iter   410/ 1097] train: loss: 0.1682297
[Epoch 81; Iter   440/ 1097] train: loss: 0.0069608
[Epoch 81; Iter   470/ 1097] train: loss: 0.0233871
[Epoch 81; Iter   500/ 1097] train: loss: 0.0105999
[Epoch 81; Iter   530/ 1097] train: loss: 0.0127920
[Epoch 81; Iter   560/ 1097] train: loss: 0.0109503
[Epoch 81; Iter   590/ 1097] train: loss: 0.0091223
[Epoch 81; Iter   620/ 1097] train: loss: 0.0280764
[Epoch 81; Iter   650/ 1097] train: loss: 0.0266719
[Epoch 81; Iter   680/ 1097] train: loss: 0.1660136
[Epoch 81; Iter   710/ 1097] train: loss: 0.0110423
[Epoch 81; Iter   740/ 1097] train: loss: 0.0509383
[Epoch 81; Iter   770/ 1097] train: loss: 0.0243109
[Epoch 81; Iter   800/ 1097] train: loss: 0.0101294
[Epoch 81; Iter   830/ 1097] train: loss: 0.2966161
[Epoch 81; Iter   860/ 1097] train: loss: 0.0229811
[Epoch 81; Iter   890/ 1097] train: loss: 0.0044553
[Epoch 81; Iter   920/ 1097] train: loss: 0.0231491
[Epoch 81; Iter   950/ 1097] train: loss: 0.0176274
[Epoch 81; Iter   980/ 1097] train: loss: 0.0288947
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0349744
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0158365
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0163015
[Epoch 81] ogbg-molhiv: 0.789269 val loss: 0.119716
[Epoch 81] ogbg-molhiv: 0.732843 test loss: 0.197823
[Epoch 82; Iter     3/ 1097] train: loss: 0.0049186
[Epoch 82; Iter    33/ 1097] train: loss: 0.0050435
[Epoch 82; Iter    63/ 1097] train: loss: 0.0649168
[Epoch 82; Iter    93/ 1097] train: loss: 0.0103294
[Epoch 82; Iter   123/ 1097] train: loss: 0.0897176
[Epoch 82; Iter   153/ 1097] train: loss: 0.2030633
[Epoch 82; Iter   183/ 1097] train: loss: 0.0776432
[Epoch 82; Iter   213/ 1097] train: loss: 0.0257770
[Epoch 82; Iter   243/ 1097] train: loss: 0.0420978
[Epoch 82; Iter   273/ 1097] train: loss: 0.0335862
[Epoch 82; Iter   303/ 1097] train: loss: 0.0139562
[Epoch 82; Iter   333/ 1097] train: loss: 0.0027240
[Epoch 82; Iter   363/ 1097] train: loss: 0.0262321
[Epoch 82; Iter   393/ 1097] train: loss: 0.0013672
[Epoch 82; Iter   423/ 1097] train: loss: 0.0753446
[Epoch 82; Iter   453/ 1097] train: loss: 0.0418292
[Epoch 82; Iter   483/ 1097] train: loss: 0.0514190
[Epoch 82; Iter   513/ 1097] train: loss: 0.0182360
[Epoch 82; Iter   543/ 1097] train: loss: 0.2056485
[Epoch 82; Iter   573/ 1097] train: loss: 0.0131490
[Epoch 82; Iter   603/ 1097] train: loss: 0.0057371
[Epoch 82; Iter   633/ 1097] train: loss: 0.0320554
[Epoch 82; Iter   663/ 1097] train: loss: 0.0434540
[Epoch 82; Iter   693/ 1097] train: loss: 0.0189264
[Epoch 82; Iter   723/ 1097] train: loss: 0.0100696
[Epoch 82; Iter   753/ 1097] train: loss: 0.0095383
[Epoch 82; Iter   783/ 1097] train: loss: 0.0645145
[Epoch 82; Iter   813/ 1097] train: loss: 0.0036931
[Epoch 82; Iter   843/ 1097] train: loss: 0.1451606
[Epoch 82; Iter   873/ 1097] train: loss: 0.0032152
[Epoch 82; Iter   903/ 1097] train: loss: 0.1899834
[Epoch 82; Iter   933/ 1097] train: loss: 0.0295186
[Epoch 82; Iter   963/ 1097] train: loss: 0.0665297
[Epoch 82; Iter   993/ 1097] train: loss: 0.0263983
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0331196
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0702675
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0080431
[Epoch 82] ogbg-molhiv: 0.780644 val loss: 0.131403
[Epoch 82] ogbg-molhiv: 0.721246 test loss: 0.197547
[Epoch 83; Iter    16/ 1097] train: loss: 0.0054633
[Epoch 83; Iter    46/ 1097] train: loss: 0.0119981
[Epoch 83; Iter    76/ 1097] train: loss: 0.0601388
[Epoch 83; Iter   106/ 1097] train: loss: 0.0264535
[Epoch 83; Iter   136/ 1097] train: loss: 0.0092561
[Epoch 83; Iter   166/ 1097] train: loss: 0.0119863
[Epoch 83; Iter   196/ 1097] train: loss: 0.0078021
[Epoch 83; Iter   226/ 1097] train: loss: 0.0067491
[Epoch 83; Iter   256/ 1097] train: loss: 0.0139850
[Epoch 83; Iter   286/ 1097] train: loss: 0.0223974
[Epoch 83; Iter   316/ 1097] train: loss: 0.0684253
[Epoch 83; Iter   346/ 1097] train: loss: 0.0040714
[Epoch 83; Iter   376/ 1097] train: loss: 0.0049611
[Epoch 83; Iter   406/ 1097] train: loss: 0.0092406
[Epoch 83; Iter   436/ 1097] train: loss: 0.0138100
[Epoch 83; Iter   466/ 1097] train: loss: 0.1799945
[Epoch 83; Iter   496/ 1097] train: loss: 0.0894336
[Epoch 83; Iter   526/ 1097] train: loss: 0.0514378
[Epoch 83; Iter   556/ 1097] train: loss: 0.0405464
[Epoch 83; Iter   586/ 1097] train: loss: 0.0185888
[Epoch 83; Iter   616/ 1097] train: loss: 0.0507554
[Epoch 83; Iter   646/ 1097] train: loss: 0.0184963
[Epoch 83; Iter   676/ 1097] train: loss: 0.0310874
[Epoch 83; Iter   706/ 1097] train: loss: 0.0111454
[Epoch 83; Iter   736/ 1097] train: loss: 0.0816304
[Epoch 83; Iter   766/ 1097] train: loss: 0.0054048
[Epoch 83; Iter   796/ 1097] train: loss: 0.0171945
[Epoch 83; Iter   826/ 1097] train: loss: 0.0992634
[Epoch 83; Iter   856/ 1097] train: loss: 0.0906090
[Epoch 83; Iter   886/ 1097] train: loss: 0.0195028
[Epoch 83; Iter   916/ 1097] train: loss: 0.1075495
[Epoch 83; Iter   946/ 1097] train: loss: 0.0033725
[Epoch 83; Iter   976/ 1097] train: loss: 0.0888943
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0044808
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0139301
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0056200
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0956054
[Epoch 83] ogbg-molhiv: 0.772845 val loss: 0.126385
[Epoch 83] ogbg-molhiv: 0.727853 test loss: 0.203640
[Epoch 84; Iter    29/ 1097] train: loss: 0.0979244
[Epoch 84; Iter    59/ 1097] train: loss: 0.0110150
[Epoch 84; Iter    89/ 1097] train: loss: 0.0346487
[Epoch 84; Iter   119/ 1097] train: loss: 0.0327978
[Epoch 84; Iter   149/ 1097] train: loss: 0.0544052
[Epoch 84; Iter   179/ 1097] train: loss: 0.0279295
[Epoch 84; Iter   209/ 1097] train: loss: 0.0100037
[Epoch 84; Iter   239/ 1097] train: loss: 0.0024119
[Epoch 84; Iter   269/ 1097] train: loss: 0.0799028
[Epoch 84; Iter   299/ 1097] train: loss: 0.0617965
[Epoch 84; Iter   329/ 1097] train: loss: 0.0935826
[Epoch 84; Iter   359/ 1097] train: loss: 0.0433271
[Epoch 84; Iter   389/ 1097] train: loss: 0.0483069
[Epoch 84; Iter   419/ 1097] train: loss: 0.0156730
[Epoch 84; Iter   449/ 1097] train: loss: 0.0137941
[Epoch 84; Iter   479/ 1097] train: loss: 0.0065973
[Epoch 84; Iter   509/ 1097] train: loss: 0.0168501
[Epoch 84; Iter   539/ 1097] train: loss: 0.0282436
[Epoch 84; Iter   569/ 1097] train: loss: 0.0408822
[Epoch 84; Iter   599/ 1097] train: loss: 0.0168609
[Epoch 84; Iter   629/ 1097] train: loss: 0.0123646
[Epoch 84; Iter   659/ 1097] train: loss: 0.0700958
[Epoch 84; Iter   689/ 1097] train: loss: 0.0090907
[Epoch 84; Iter   719/ 1097] train: loss: 0.0103856
[Epoch 84; Iter   749/ 1097] train: loss: 0.0615605
[Epoch 84; Iter   779/ 1097] train: loss: 0.0019024
[Epoch 84; Iter   809/ 1097] train: loss: 0.0051007
[Epoch 84; Iter   839/ 1097] train: loss: 0.0363407
[Epoch 84; Iter   869/ 1097] train: loss: 0.0327491
[Epoch 84; Iter   899/ 1097] train: loss: 0.0064608
[Epoch 84; Iter   929/ 1097] train: loss: 0.0934591
[Epoch 84; Iter   959/ 1097] train: loss: 0.0350317
[Epoch 84; Iter   989/ 1097] train: loss: 0.0053557
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0985226
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0272339
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0399667
[Epoch 84] ogbg-molhiv: 0.765585 val loss: 0.134823
[Epoch 84] ogbg-molhiv: 0.731128 test loss: 0.203733
[Epoch 85; Iter    12/ 1097] train: loss: 0.0107221
[Epoch 85; Iter    42/ 1097] train: loss: 0.0650767
[Epoch 85; Iter    72/ 1097] train: loss: 0.0140560
[Epoch 85; Iter   102/ 1097] train: loss: 0.0135526
[Epoch 85; Iter   132/ 1097] train: loss: 0.0654233
[Epoch 85; Iter   162/ 1097] train: loss: 0.0102661
[Epoch 85; Iter   192/ 1097] train: loss: 0.0369779
[Epoch 85; Iter   222/ 1097] train: loss: 0.0395411
[Epoch 85; Iter   252/ 1097] train: loss: 0.0765272
[Epoch 85; Iter   282/ 1097] train: loss: 0.0077634
[Epoch 85; Iter   312/ 1097] train: loss: 0.0483104
[Epoch 85; Iter   342/ 1097] train: loss: 0.0113548
[Epoch 85; Iter   372/ 1097] train: loss: 0.0112604
[Epoch 85; Iter   402/ 1097] train: loss: 0.0347007
[Epoch 85; Iter   432/ 1097] train: loss: 0.0199468
[Epoch 81; Iter   380/ 1097] train: loss: 0.0017551
[Epoch 81; Iter   410/ 1097] train: loss: 0.0253226
[Epoch 81; Iter   440/ 1097] train: loss: 0.0014987
[Epoch 81; Iter   470/ 1097] train: loss: 0.0029981
[Epoch 81; Iter   500/ 1097] train: loss: 0.0050013
[Epoch 81; Iter   530/ 1097] train: loss: 0.0062302
[Epoch 81; Iter   560/ 1097] train: loss: 0.0081684
[Epoch 81; Iter   590/ 1097] train: loss: 0.1065596
[Epoch 81; Iter   620/ 1097] train: loss: 0.0273618
[Epoch 81; Iter   650/ 1097] train: loss: 0.0038454
[Epoch 81; Iter   680/ 1097] train: loss: 0.0134093
[Epoch 81; Iter   710/ 1097] train: loss: 0.0160200
[Epoch 81; Iter   740/ 1097] train: loss: 0.0007276
[Epoch 81; Iter   770/ 1097] train: loss: 0.2277728
[Epoch 81; Iter   800/ 1097] train: loss: 0.0194236
[Epoch 81; Iter   830/ 1097] train: loss: 0.0746511
[Epoch 81; Iter   860/ 1097] train: loss: 0.0033090
[Epoch 81; Iter   890/ 1097] train: loss: 0.0480181
[Epoch 81; Iter   920/ 1097] train: loss: 0.0377732
[Epoch 81; Iter   950/ 1097] train: loss: 0.1181384
[Epoch 81; Iter   980/ 1097] train: loss: 0.0054083
[Epoch 81; Iter  1010/ 1097] train: loss: 0.0510812
[Epoch 81; Iter  1040/ 1097] train: loss: 0.0062777
[Epoch 81; Iter  1070/ 1097] train: loss: 0.0193528
[Epoch 81] ogbg-molhiv: 0.795711 val loss: 0.117715
[Epoch 81] ogbg-molhiv: 0.769656 test loss: 0.208254
[Epoch 82; Iter     3/ 1097] train: loss: 0.0105251
[Epoch 82; Iter    33/ 1097] train: loss: 0.0268247
[Epoch 82; Iter    63/ 1097] train: loss: 0.0027962
[Epoch 82; Iter    93/ 1097] train: loss: 0.0021635
[Epoch 82; Iter   123/ 1097] train: loss: 0.0011096
[Epoch 82; Iter   153/ 1097] train: loss: 0.1555621
[Epoch 82; Iter   183/ 1097] train: loss: 0.0015919
[Epoch 82; Iter   213/ 1097] train: loss: 0.0024572
[Epoch 82; Iter   243/ 1097] train: loss: 0.0049715
[Epoch 82; Iter   273/ 1097] train: loss: 0.0605405
[Epoch 82; Iter   303/ 1097] train: loss: 0.0078227
[Epoch 82; Iter   333/ 1097] train: loss: 0.0330301
[Epoch 82; Iter   363/ 1097] train: loss: 0.0090585
[Epoch 82; Iter   393/ 1097] train: loss: 0.0723098
[Epoch 82; Iter   423/ 1097] train: loss: 0.1900812
[Epoch 82; Iter   453/ 1097] train: loss: 0.0003689
[Epoch 82; Iter   483/ 1097] train: loss: 0.0023279
[Epoch 82; Iter   513/ 1097] train: loss: 0.0030542
[Epoch 82; Iter   543/ 1097] train: loss: 0.0013149
[Epoch 82; Iter   573/ 1097] train: loss: 0.0023905
[Epoch 82; Iter   603/ 1097] train: loss: 0.0035468
[Epoch 82; Iter   633/ 1097] train: loss: 0.0995404
[Epoch 82; Iter   663/ 1097] train: loss: 0.0027600
[Epoch 82; Iter   693/ 1097] train: loss: 0.0018106
[Epoch 82; Iter   723/ 1097] train: loss: 0.0012583
[Epoch 82; Iter   753/ 1097] train: loss: 0.0053702
[Epoch 82; Iter   783/ 1097] train: loss: 0.0034108
[Epoch 82; Iter   813/ 1097] train: loss: 0.0043289
[Epoch 82; Iter   843/ 1097] train: loss: 0.0082352
[Epoch 82; Iter   873/ 1097] train: loss: 0.1251551
[Epoch 82; Iter   903/ 1097] train: loss: 0.0075964
[Epoch 82; Iter   933/ 1097] train: loss: 0.0197725
[Epoch 82; Iter   963/ 1097] train: loss: 0.0026879
[Epoch 82; Iter   993/ 1097] train: loss: 0.0701187
[Epoch 82; Iter  1023/ 1097] train: loss: 0.0202411
[Epoch 82; Iter  1053/ 1097] train: loss: 0.0099987
[Epoch 82; Iter  1083/ 1097] train: loss: 0.0949386
[Epoch 82] ogbg-molhiv: 0.792907 val loss: 0.121339
[Epoch 82] ogbg-molhiv: 0.765826 test loss: 0.210612
[Epoch 83; Iter    16/ 1097] train: loss: 0.0035441
[Epoch 83; Iter    46/ 1097] train: loss: 0.0138701
[Epoch 83; Iter    76/ 1097] train: loss: 0.0045283
[Epoch 83; Iter   106/ 1097] train: loss: 0.0533945
[Epoch 83; Iter   136/ 1097] train: loss: 0.0164827
[Epoch 83; Iter   166/ 1097] train: loss: 0.0553142
[Epoch 83; Iter   196/ 1097] train: loss: 0.0012265
[Epoch 83; Iter   226/ 1097] train: loss: 0.0109792
[Epoch 83; Iter   256/ 1097] train: loss: 0.0144626
[Epoch 83; Iter   286/ 1097] train: loss: 0.0033188
[Epoch 83; Iter   316/ 1097] train: loss: 0.0008862
[Epoch 83; Iter   346/ 1097] train: loss: 0.0015612
[Epoch 83; Iter   376/ 1097] train: loss: 0.0244857
[Epoch 83; Iter   406/ 1097] train: loss: 0.0357231
[Epoch 83; Iter   436/ 1097] train: loss: 0.0566659
[Epoch 83; Iter   466/ 1097] train: loss: 0.0283665
[Epoch 83; Iter   496/ 1097] train: loss: 0.0030890
[Epoch 83; Iter   526/ 1097] train: loss: 0.0284522
[Epoch 83; Iter   556/ 1097] train: loss: 0.0184631
[Epoch 83; Iter   586/ 1097] train: loss: 0.0043705
[Epoch 83; Iter   616/ 1097] train: loss: 0.0179336
[Epoch 83; Iter   646/ 1097] train: loss: 0.0046526
[Epoch 83; Iter   676/ 1097] train: loss: 0.0608765
[Epoch 83; Iter   706/ 1097] train: loss: 0.0029747
[Epoch 83; Iter   736/ 1097] train: loss: 0.0789320
[Epoch 83; Iter   766/ 1097] train: loss: 0.0050376
[Epoch 83; Iter   796/ 1097] train: loss: 0.0120922
[Epoch 83; Iter   826/ 1097] train: loss: 0.0066356
[Epoch 83; Iter   856/ 1097] train: loss: 0.0100147
[Epoch 83; Iter   886/ 1097] train: loss: 0.0361506
[Epoch 83; Iter   916/ 1097] train: loss: 0.0388653
[Epoch 83; Iter   946/ 1097] train: loss: 0.0073826
[Epoch 83; Iter   976/ 1097] train: loss: 0.0105475
[Epoch 83; Iter  1006/ 1097] train: loss: 0.0307223
[Epoch 83; Iter  1036/ 1097] train: loss: 0.0271517
[Epoch 83; Iter  1066/ 1097] train: loss: 0.0014380
[Epoch 83; Iter  1096/ 1097] train: loss: 0.0081051
[Epoch 83] ogbg-molhiv: 0.789275 val loss: 0.121069
[Epoch 83] ogbg-molhiv: 0.760808 test loss: 0.212844
[Epoch 84; Iter    29/ 1097] train: loss: 0.0003657
[Epoch 84; Iter    59/ 1097] train: loss: 0.0041324
[Epoch 84; Iter    89/ 1097] train: loss: 0.0438988
[Epoch 84; Iter   119/ 1097] train: loss: 0.0147465
[Epoch 84; Iter   149/ 1097] train: loss: 0.0249294
[Epoch 84; Iter   179/ 1097] train: loss: 0.1062711
[Epoch 84; Iter   209/ 1097] train: loss: 0.0092421
[Epoch 84; Iter   239/ 1097] train: loss: 0.0014426
[Epoch 84; Iter   269/ 1097] train: loss: 0.0047875
[Epoch 84; Iter   299/ 1097] train: loss: 0.0342908
[Epoch 84; Iter   329/ 1097] train: loss: 0.0033366
[Epoch 84; Iter   359/ 1097] train: loss: 0.0287601
[Epoch 84; Iter   389/ 1097] train: loss: 0.0040921
[Epoch 84; Iter   419/ 1097] train: loss: 0.0505746
[Epoch 84; Iter   449/ 1097] train: loss: 0.0492368
[Epoch 84; Iter   479/ 1097] train: loss: 0.0033228
[Epoch 84; Iter   509/ 1097] train: loss: 0.0171546
[Epoch 84; Iter   539/ 1097] train: loss: 0.0030776
[Epoch 84; Iter   569/ 1097] train: loss: 0.0085993
[Epoch 84; Iter   599/ 1097] train: loss: 0.0101366
[Epoch 84; Iter   629/ 1097] train: loss: 0.0006895
[Epoch 84; Iter   659/ 1097] train: loss: 0.0089290
[Epoch 84; Iter   689/ 1097] train: loss: 0.0632342
[Epoch 84; Iter   719/ 1097] train: loss: 0.0059111
[Epoch 84; Iter   749/ 1097] train: loss: 0.0098653
[Epoch 84; Iter   779/ 1097] train: loss: 0.0918168
[Epoch 84; Iter   809/ 1097] train: loss: 0.0125284
[Epoch 84; Iter   839/ 1097] train: loss: 0.0031483
[Epoch 84; Iter   869/ 1097] train: loss: 0.0639554
[Epoch 84; Iter   899/ 1097] train: loss: 0.0074398
[Epoch 84; Iter   929/ 1097] train: loss: 0.0004773
[Epoch 84; Iter   959/ 1097] train: loss: 0.0211046
[Epoch 84; Iter   989/ 1097] train: loss: 0.0444002
[Epoch 84; Iter  1019/ 1097] train: loss: 0.0071286
[Epoch 84; Iter  1049/ 1097] train: loss: 0.0002299
[Epoch 84; Iter  1079/ 1097] train: loss: 0.0229526
[Epoch 84] ogbg-molhiv: 0.790310 val loss: 0.118876
[Epoch 84] ogbg-molhiv: 0.769688 test loss: 0.208297
[Epoch 85; Iter    12/ 1097] train: loss: 0.0476550
[Epoch 85; Iter    42/ 1097] train: loss: 0.0224685
[Epoch 85; Iter    72/ 1097] train: loss: 0.0030385
[Epoch 85; Iter   102/ 1097] train: loss: 0.0068522
[Epoch 85; Iter   132/ 1097] train: loss: 0.0126903
[Epoch 85; Iter   162/ 1097] train: loss: 0.0198338
[Epoch 85; Iter   192/ 1097] train: loss: 0.0184352
[Epoch 85; Iter   222/ 1097] train: loss: 0.0266154
[Epoch 85; Iter   252/ 1097] train: loss: 0.0058276
[Epoch 85; Iter   282/ 1097] train: loss: 0.0010700
[Epoch 85; Iter   312/ 1097] train: loss: 0.0471475
[Epoch 85; Iter   342/ 1097] train: loss: 0.0129809
[Epoch 85; Iter   372/ 1097] train: loss: 0.0230496
[Epoch 85; Iter   402/ 1097] train: loss: 0.1295937
[Epoch 85; Iter   432/ 1097] train: loss: 0.0467031
[Epoch 90; Iter   193/  823] train: loss: 0.0572031
[Epoch 90; Iter   223/  823] train: loss: 0.0132410
[Epoch 90; Iter   253/  823] train: loss: 0.0246352
[Epoch 90; Iter   283/  823] train: loss: 0.0071808
[Epoch 90; Iter   313/  823] train: loss: 0.0076836
[Epoch 90; Iter   343/  823] train: loss: 0.0642610
[Epoch 90; Iter   373/  823] train: loss: 0.0266548
[Epoch 90; Iter   403/  823] train: loss: 0.0345293
[Epoch 90; Iter   433/  823] train: loss: 0.0525613
[Epoch 90; Iter   463/  823] train: loss: 0.0275984
[Epoch 90; Iter   493/  823] train: loss: 0.0257492
[Epoch 90; Iter   523/  823] train: loss: 0.0013552
[Epoch 90; Iter   553/  823] train: loss: 0.1553268
[Epoch 90; Iter   583/  823] train: loss: 0.0052848
[Epoch 90; Iter   613/  823] train: loss: 0.0295206
[Epoch 90; Iter   643/  823] train: loss: 0.0009740
[Epoch 90; Iter   673/  823] train: loss: 0.0042885
[Epoch 90; Iter   703/  823] train: loss: 0.0088645
[Epoch 90; Iter   733/  823] train: loss: 0.1106433
[Epoch 90; Iter   763/  823] train: loss: 0.0033504
[Epoch 90; Iter   793/  823] train: loss: 0.0103480
[Epoch 90; Iter   823/  823] train: loss: 0.2347231
[Epoch 90] ogbg-molhiv: 0.740207 val loss: 0.230464
[Epoch 90] ogbg-molhiv: 0.759631 test loss: 0.166096
[Epoch 91; Iter    30/  823] train: loss: 0.1364374
[Epoch 91; Iter    60/  823] train: loss: 0.0176816
[Epoch 91; Iter    90/  823] train: loss: 0.0312422
[Epoch 91; Iter   120/  823] train: loss: 0.0290604
[Epoch 91; Iter   150/  823] train: loss: 0.0237100
[Epoch 91; Iter   180/  823] train: loss: 0.0085238
[Epoch 91; Iter   210/  823] train: loss: 0.0053305
[Epoch 91; Iter   240/  823] train: loss: 0.0057486
[Epoch 91; Iter   270/  823] train: loss: 0.1271746
[Epoch 91; Iter   300/  823] train: loss: 0.0928570
[Epoch 91; Iter   330/  823] train: loss: 0.0095223
[Epoch 91; Iter   360/  823] train: loss: 0.0419496
[Epoch 91; Iter   390/  823] train: loss: 0.0683236
[Epoch 91; Iter   420/  823] train: loss: 0.0172506
[Epoch 91; Iter   450/  823] train: loss: 0.0040379
[Epoch 91; Iter   480/  823] train: loss: 0.0075251
[Epoch 91; Iter   510/  823] train: loss: 0.0069383
[Epoch 91; Iter   540/  823] train: loss: 0.0155785
[Epoch 91; Iter   570/  823] train: loss: 0.0085901
[Epoch 91; Iter   600/  823] train: loss: 0.0344808
[Epoch 91; Iter   630/  823] train: loss: 0.0163135
[Epoch 91; Iter   660/  823] train: loss: 0.0129434
[Epoch 91; Iter   690/  823] train: loss: 0.0154043
[Epoch 91; Iter   720/  823] train: loss: 0.0024360
[Epoch 91; Iter   750/  823] train: loss: 0.0105633
[Epoch 91; Iter   780/  823] train: loss: 0.1171046
[Epoch 91; Iter   810/  823] train: loss: 0.0060675
[Epoch 91] ogbg-molhiv: 0.738987 val loss: 0.239653
[Epoch 91] ogbg-molhiv: 0.749020 test loss: 0.273653
[Epoch 92; Iter    17/  823] train: loss: 0.0102098
[Epoch 92; Iter    47/  823] train: loss: 0.0011311
[Epoch 92; Iter    77/  823] train: loss: 0.0416030
[Epoch 92; Iter   107/  823] train: loss: 0.0131706
[Epoch 92; Iter   137/  823] train: loss: 0.0509451
[Epoch 92; Iter   167/  823] train: loss: 0.0133875
[Epoch 92; Iter   197/  823] train: loss: 0.0085949
[Epoch 92; Iter   227/  823] train: loss: 0.0509202
[Epoch 92; Iter   257/  823] train: loss: 0.0443092
[Epoch 92; Iter   287/  823] train: loss: 0.0033941
[Epoch 92; Iter   317/  823] train: loss: 0.0146036
[Epoch 92; Iter   347/  823] train: loss: 0.0033740
[Epoch 92; Iter   377/  823] train: loss: 0.0485860
[Epoch 92; Iter   407/  823] train: loss: 0.0102795
[Epoch 92; Iter   437/  823] train: loss: 0.0240047
[Epoch 92; Iter   467/  823] train: loss: 0.0199009
[Epoch 92; Iter   497/  823] train: loss: 0.0046833
[Epoch 92; Iter   527/  823] train: loss: 0.0013963
[Epoch 92; Iter   557/  823] train: loss: 0.0880869
[Epoch 92; Iter   587/  823] train: loss: 0.0048065
[Epoch 92; Iter   617/  823] train: loss: 0.0026973
[Epoch 92; Iter   647/  823] train: loss: 0.0108952
[Epoch 92; Iter   677/  823] train: loss: 0.0243245
[Epoch 92; Iter   707/  823] train: loss: 0.0040020
[Epoch 92; Iter   737/  823] train: loss: 0.0059926
[Epoch 92; Iter   767/  823] train: loss: 0.0101900
[Epoch 92; Iter   797/  823] train: loss: 0.0066017
[Epoch 92] ogbg-molhiv: 0.742783 val loss: 0.231005
[Epoch 92] ogbg-molhiv: 0.751111 test loss: 0.196556
[Epoch 93; Iter     4/  823] train: loss: 0.0146413
[Epoch 93; Iter    34/  823] train: loss: 0.0167069
[Epoch 93; Iter    64/  823] train: loss: 0.0909472
[Epoch 93; Iter    94/  823] train: loss: 0.0237063
[Epoch 93; Iter   124/  823] train: loss: 0.0221651
[Epoch 93; Iter   154/  823] train: loss: 0.0246914
[Epoch 93; Iter   184/  823] train: loss: 0.0253908
[Epoch 93; Iter   214/  823] train: loss: 0.1122022
[Epoch 93; Iter   244/  823] train: loss: 0.0096468
[Epoch 93; Iter   274/  823] train: loss: 0.0005133
[Epoch 93; Iter   304/  823] train: loss: 0.1229396
[Epoch 93; Iter   334/  823] train: loss: 0.0052106
[Epoch 93; Iter   364/  823] train: loss: 0.2635409
[Epoch 93; Iter   394/  823] train: loss: 0.0634466
[Epoch 93; Iter   424/  823] train: loss: 0.0233160
[Epoch 93; Iter   454/  823] train: loss: 0.0142860
[Epoch 93; Iter   484/  823] train: loss: 0.0044437
[Epoch 93; Iter   514/  823] train: loss: 0.0132993
[Epoch 93; Iter   544/  823] train: loss: 0.0088932
[Epoch 93; Iter   574/  823] train: loss: 0.1008540
[Epoch 93; Iter   604/  823] train: loss: 0.0136475
[Epoch 93; Iter   634/  823] train: loss: 0.0368090
[Epoch 93; Iter   664/  823] train: loss: 0.0030106
[Epoch 93; Iter   694/  823] train: loss: 0.0051744
[Epoch 93; Iter   724/  823] train: loss: 0.0168539
[Epoch 93; Iter   754/  823] train: loss: 0.0082697
[Epoch 93; Iter   784/  823] train: loss: 0.0158375
[Epoch 93; Iter   814/  823] train: loss: 0.0086447
[Epoch 93] ogbg-molhiv: 0.744258 val loss: 0.239318
[Epoch 93] ogbg-molhiv: 0.746641 test loss: 0.247845
[Epoch 94; Iter    21/  823] train: loss: 0.0139930
[Epoch 94; Iter    51/  823] train: loss: 0.0092431
[Epoch 94; Iter    81/  823] train: loss: 0.0012609
[Epoch 94; Iter   111/  823] train: loss: 0.0104897
[Epoch 94; Iter   141/  823] train: loss: 0.0294141
[Epoch 94; Iter   171/  823] train: loss: 0.0083653
[Epoch 94; Iter   201/  823] train: loss: 0.0013504
[Epoch 94; Iter   231/  823] train: loss: 0.0022120
[Epoch 94; Iter   261/  823] train: loss: 0.0199546
[Epoch 94; Iter   291/  823] train: loss: 0.0765597
[Epoch 94; Iter   321/  823] train: loss: 0.0732448
[Epoch 94; Iter   351/  823] train: loss: 0.0744587
[Epoch 94; Iter   381/  823] train: loss: 0.1186749
[Epoch 94; Iter   411/  823] train: loss: 0.0362113
[Epoch 94; Iter   441/  823] train: loss: 0.0019488
[Epoch 94; Iter   471/  823] train: loss: 0.0012680
[Epoch 94; Iter   501/  823] train: loss: 0.0047273
[Epoch 94; Iter   531/  823] train: loss: 0.0213818
[Epoch 94; Iter   561/  823] train: loss: 0.0017664
[Epoch 94; Iter   591/  823] train: loss: 0.0148147
[Epoch 94; Iter   621/  823] train: loss: 0.0920250
[Epoch 94; Iter   651/  823] train: loss: 0.0043706
[Epoch 94; Iter   681/  823] train: loss: 0.0594213
[Epoch 94; Iter   711/  823] train: loss: 0.0169883
[Epoch 94; Iter   741/  823] train: loss: 0.0117211
[Epoch 94; Iter   771/  823] train: loss: 0.0231687
[Epoch 94; Iter   801/  823] train: loss: 0.0034815
[Epoch 94] ogbg-molhiv: 0.748604 val loss: 0.237423
[Epoch 94] ogbg-molhiv: 0.750364 test loss: 0.236563
[Epoch 95; Iter     8/  823] train: loss: 0.0369121
[Epoch 95; Iter    38/  823] train: loss: 0.0181366
[Epoch 95; Iter    68/  823] train: loss: 0.0050689
[Epoch 95; Iter    98/  823] train: loss: 0.0039898
[Epoch 95; Iter   128/  823] train: loss: 0.0504118
[Epoch 95; Iter   158/  823] train: loss: 0.1345657
[Epoch 95; Iter   188/  823] train: loss: 0.0291725
[Epoch 95; Iter   218/  823] train: loss: 0.0034103
[Epoch 95; Iter   248/  823] train: loss: 0.0018229
[Epoch 95; Iter   278/  823] train: loss: 0.0624793
[Epoch 95; Iter   308/  823] train: loss: 0.0132387
[Epoch 95; Iter   338/  823] train: loss: 0.0029804
[Epoch 95; Iter   368/  823] train: loss: 0.0055172
[Epoch 95; Iter   398/  823] train: loss: 0.0035836
[Epoch 95; Iter   428/  823] train: loss: 0.0266844
[Epoch 95; Iter   458/  823] train: loss: 0.0120442
[Epoch 90; Iter   193/  823] train: loss: 0.0115349
[Epoch 90; Iter   223/  823] train: loss: 0.0021630
[Epoch 90; Iter   253/  823] train: loss: 0.0720055
[Epoch 90; Iter   283/  823] train: loss: 0.0024561
[Epoch 90; Iter   313/  823] train: loss: 0.0023276
[Epoch 90; Iter   343/  823] train: loss: 0.0255273
[Epoch 90; Iter   373/  823] train: loss: 0.0065284
[Epoch 90; Iter   403/  823] train: loss: 0.0086704
[Epoch 90; Iter   433/  823] train: loss: 0.0059805
[Epoch 90; Iter   463/  823] train: loss: 0.0016000
[Epoch 90; Iter   493/  823] train: loss: 0.0104068
[Epoch 90; Iter   523/  823] train: loss: 0.0046786
[Epoch 90; Iter   553/  823] train: loss: 0.0051153
[Epoch 90; Iter   583/  823] train: loss: 0.0232150
[Epoch 90; Iter   613/  823] train: loss: 0.0007529
[Epoch 90; Iter   643/  823] train: loss: 0.0088258
[Epoch 90; Iter   673/  823] train: loss: 0.0012354
[Epoch 90; Iter   703/  823] train: loss: 0.0029994
[Epoch 90; Iter   733/  823] train: loss: 0.0088244
[Epoch 90; Iter   763/  823] train: loss: 0.0030037
[Epoch 90; Iter   793/  823] train: loss: 0.0481947
[Epoch 90; Iter   823/  823] train: loss: 0.0060552
[Epoch 90] ogbg-molhiv: 0.708827 val loss: 0.393262
[Epoch 90] ogbg-molhiv: 0.751818 test loss: 0.216701
[Epoch 91; Iter    30/  823] train: loss: 0.0034681
[Epoch 91; Iter    60/  823] train: loss: 0.0170691
[Epoch 91; Iter    90/  823] train: loss: 0.0035473
[Epoch 91; Iter   120/  823] train: loss: 0.0017582
[Epoch 91; Iter   150/  823] train: loss: 0.0023336
[Epoch 91; Iter   180/  823] train: loss: 0.0057177
[Epoch 91; Iter   210/  823] train: loss: 0.0541669
[Epoch 91; Iter   240/  823] train: loss: 0.0135160
[Epoch 91; Iter   270/  823] train: loss: 0.0115076
[Epoch 91; Iter   300/  823] train: loss: 0.0024883
[Epoch 91; Iter   330/  823] train: loss: 0.0007454
[Epoch 91; Iter   360/  823] train: loss: 0.0471919
[Epoch 91; Iter   390/  823] train: loss: 0.0137034
[Epoch 91; Iter   420/  823] train: loss: 0.0049892
[Epoch 91; Iter   450/  823] train: loss: 0.0144184
[Epoch 91; Iter   480/  823] train: loss: 0.0221040
[Epoch 91; Iter   510/  823] train: loss: 0.0376487
[Epoch 91; Iter   540/  823] train: loss: 0.0029595
[Epoch 91; Iter   570/  823] train: loss: 0.0030370
[Epoch 91; Iter   600/  823] train: loss: 0.0178705
[Epoch 91; Iter   630/  823] train: loss: 0.0030164
[Epoch 91; Iter   660/  823] train: loss: 0.0084231
[Epoch 91; Iter   690/  823] train: loss: 0.0036667
[Epoch 91; Iter   720/  823] train: loss: 0.0007064
[Epoch 91; Iter   750/  823] train: loss: 0.0095475
[Epoch 91; Iter   780/  823] train: loss: 0.0018819
[Epoch 91; Iter   810/  823] train: loss: 0.0012597
[Epoch 91] ogbg-molhiv: 0.708537 val loss: 0.392851
[Epoch 91] ogbg-molhiv: 0.737353 test loss: 0.224449
[Epoch 92; Iter    17/  823] train: loss: 0.0445915
[Epoch 92; Iter    47/  823] train: loss: 0.0006583
[Epoch 92; Iter    77/  823] train: loss: 0.0007539
[Epoch 92; Iter   107/  823] train: loss: 0.0095380
[Epoch 92; Iter   137/  823] train: loss: 0.0396551
[Epoch 92; Iter   167/  823] train: loss: 0.0044789
[Epoch 92; Iter   197/  823] train: loss: 0.0893478
[Epoch 92; Iter   227/  823] train: loss: 0.0410247
[Epoch 92; Iter   257/  823] train: loss: 0.0037160
[Epoch 92; Iter   287/  823] train: loss: 0.0304815
[Epoch 92; Iter   317/  823] train: loss: 0.0169278
[Epoch 92; Iter   347/  823] train: loss: 0.0064041
[Epoch 92; Iter   377/  823] train: loss: 0.0055955
[Epoch 92; Iter   407/  823] train: loss: 0.0107417
[Epoch 92; Iter   437/  823] train: loss: 0.1357239
[Epoch 92; Iter   467/  823] train: loss: 0.0987970
[Epoch 92; Iter   497/  823] train: loss: 0.0314943
[Epoch 92; Iter   527/  823] train: loss: 0.0008702
[Epoch 92; Iter   557/  823] train: loss: 0.0039159
[Epoch 92; Iter   587/  823] train: loss: 0.0141911
[Epoch 92; Iter   617/  823] train: loss: 0.1244189
[Epoch 92; Iter   647/  823] train: loss: 0.0023002
[Epoch 92; Iter   677/  823] train: loss: 0.0055589
[Epoch 92; Iter   707/  823] train: loss: 0.0226304
[Epoch 92; Iter   737/  823] train: loss: 0.0096645
[Epoch 92; Iter   767/  823] train: loss: 0.0049743
[Epoch 92; Iter   797/  823] train: loss: 0.0023880
[Epoch 92] ogbg-molhiv: 0.707155 val loss: 0.398321
[Epoch 92] ogbg-molhiv: 0.746794 test loss: 0.224383
[Epoch 93; Iter     4/  823] train: loss: 0.0128284
[Epoch 93; Iter    34/  823] train: loss: 0.0045823
[Epoch 93; Iter    64/  823] train: loss: 0.0071458
[Epoch 93; Iter    94/  823] train: loss: 0.0034341
[Epoch 93; Iter   124/  823] train: loss: 0.0007652
[Epoch 93; Iter   154/  823] train: loss: 0.0107025
[Epoch 93; Iter   184/  823] train: loss: 0.0010662
[Epoch 93; Iter   214/  823] train: loss: 0.0016188
[Epoch 93; Iter   244/  823] train: loss: 0.0115713
[Epoch 93; Iter   274/  823] train: loss: 0.0007017
[Epoch 93; Iter   304/  823] train: loss: 0.0372585
[Epoch 93; Iter   334/  823] train: loss: 0.0031392
[Epoch 93; Iter   364/  823] train: loss: 0.0003030
[Epoch 93; Iter   394/  823] train: loss: 0.0012089
[Epoch 93; Iter   424/  823] train: loss: 0.0035348
[Epoch 93; Iter   454/  823] train: loss: 0.0857947
[Epoch 93; Iter   484/  823] train: loss: 0.0756914
[Epoch 93; Iter   514/  823] train: loss: 0.0049510
[Epoch 93; Iter   544/  823] train: loss: 0.0007165
[Epoch 93; Iter   574/  823] train: loss: 0.0022324
[Epoch 93; Iter   604/  823] train: loss: 0.0010209
[Epoch 93; Iter   634/  823] train: loss: 0.0064299
[Epoch 93; Iter   664/  823] train: loss: 0.0059071
[Epoch 93; Iter   694/  823] train: loss: 0.0026782
[Epoch 93; Iter   724/  823] train: loss: 0.0013826
[Epoch 93; Iter   754/  823] train: loss: 0.0024428
[Epoch 93; Iter   784/  823] train: loss: 0.0256262
[Epoch 93; Iter   814/  823] train: loss: 0.0092032
[Epoch 93] ogbg-molhiv: 0.703785 val loss: 0.374685
[Epoch 93] ogbg-molhiv: 0.751401 test loss: 0.239059
[Epoch 94; Iter    21/  823] train: loss: 0.0047448
[Epoch 94; Iter    51/  823] train: loss: 0.0232965
[Epoch 94; Iter    81/  823] train: loss: 0.0091088
[Epoch 94; Iter   111/  823] train: loss: 0.0119111
[Epoch 94; Iter   141/  823] train: loss: 0.0061381
[Epoch 94; Iter   171/  823] train: loss: 0.0050297
[Epoch 94; Iter   201/  823] train: loss: 0.2356325
[Epoch 94; Iter   231/  823] train: loss: 0.0108966
[Epoch 94; Iter   261/  823] train: loss: 0.0048230
[Epoch 94; Iter   291/  823] train: loss: 0.0024134
[Epoch 94; Iter   321/  823] train: loss: 0.1456168
[Epoch 94; Iter   351/  823] train: loss: 0.0152346
[Epoch 94; Iter   381/  823] train: loss: 0.1515537
[Epoch 94; Iter   411/  823] train: loss: 0.0033395
[Epoch 94; Iter   441/  823] train: loss: 0.0092373
[Epoch 94; Iter   471/  823] train: loss: 0.0026508
[Epoch 94; Iter   501/  823] train: loss: 0.0005201
[Epoch 94; Iter   531/  823] train: loss: 0.0109438
[Epoch 94; Iter   561/  823] train: loss: 0.0241775
[Epoch 94; Iter   591/  823] train: loss: 0.0104164
[Epoch 94; Iter   621/  823] train: loss: 0.0061881
[Epoch 94; Iter   651/  823] train: loss: 0.0017096
[Epoch 94; Iter   681/  823] train: loss: 0.0089840
[Epoch 94; Iter   711/  823] train: loss: 0.0489814
[Epoch 94; Iter   741/  823] train: loss: 0.0218157
[Epoch 94; Iter   771/  823] train: loss: 0.0871403
[Epoch 94; Iter   801/  823] train: loss: 0.0019243
[Epoch 94] ogbg-molhiv: 0.711665 val loss: 0.355458
[Epoch 94] ogbg-molhiv: 0.765029 test loss: 0.201852
[Epoch 95; Iter     8/  823] train: loss: 0.0187337
[Epoch 95; Iter    38/  823] train: loss: 0.0041469
[Epoch 95; Iter    68/  823] train: loss: 0.0118594
[Epoch 95; Iter    98/  823] train: loss: 0.0040830
[Epoch 95; Iter   128/  823] train: loss: 0.0025888
[Epoch 95; Iter   158/  823] train: loss: 0.0087870
[Epoch 95; Iter   188/  823] train: loss: 0.0585275
[Epoch 95; Iter   218/  823] train: loss: 0.0224074
[Epoch 95; Iter   248/  823] train: loss: 0.0158331
[Epoch 95; Iter   278/  823] train: loss: 0.0006649
[Epoch 95; Iter   308/  823] train: loss: 0.0008649
[Epoch 95; Iter   338/  823] train: loss: 0.0010018
[Epoch 95; Iter   368/  823] train: loss: 0.0061418
[Epoch 95; Iter   398/  823] train: loss: 0.0088355
[Epoch 95; Iter   428/  823] train: loss: 0.0048037
[Epoch 95; Iter   458/  823] train: loss: 0.0700426
[Epoch 85; Iter   462/ 1097] train: loss: 0.0209888
[Epoch 85; Iter   492/ 1097] train: loss: 0.1612678
[Epoch 85; Iter   522/ 1097] train: loss: 0.0095489
[Epoch 85; Iter   552/ 1097] train: loss: 0.0168691
[Epoch 85; Iter   582/ 1097] train: loss: 0.0159110
[Epoch 85; Iter   612/ 1097] train: loss: 0.0036162
[Epoch 85; Iter   642/ 1097] train: loss: 0.0796412
[Epoch 85; Iter   672/ 1097] train: loss: 0.0017985
[Epoch 85; Iter   702/ 1097] train: loss: 0.0248356
[Epoch 85; Iter   732/ 1097] train: loss: 0.0416131
[Epoch 85; Iter   762/ 1097] train: loss: 0.0115054
[Epoch 85; Iter   792/ 1097] train: loss: 0.0201507
[Epoch 85; Iter   822/ 1097] train: loss: 0.0397527
[Epoch 85; Iter   852/ 1097] train: loss: 0.0038815
[Epoch 85; Iter   882/ 1097] train: loss: 0.0688371
[Epoch 85; Iter   912/ 1097] train: loss: 0.0447408
[Epoch 85; Iter   942/ 1097] train: loss: 0.0474644
[Epoch 85; Iter   972/ 1097] train: loss: 0.0508301
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0395666
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0751950
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0287044
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0542100
[Epoch 85] ogbg-molhiv: 0.747269 val loss: 0.246687
[Epoch 85] ogbg-molhiv: 0.731806 test loss: 0.635308
[Epoch 86; Iter    25/ 1097] train: loss: 0.0054910
[Epoch 86; Iter    55/ 1097] train: loss: 0.0173316
[Epoch 86; Iter    85/ 1097] train: loss: 0.0057144
[Epoch 86; Iter   115/ 1097] train: loss: 0.0145942
[Epoch 86; Iter   145/ 1097] train: loss: 0.0052298
[Epoch 86; Iter   175/ 1097] train: loss: 0.0225743
[Epoch 86; Iter   205/ 1097] train: loss: 0.0137434
[Epoch 86; Iter   235/ 1097] train: loss: 0.0046353
[Epoch 86; Iter   265/ 1097] train: loss: 0.0022879
[Epoch 86; Iter   295/ 1097] train: loss: 0.0052721
[Epoch 86; Iter   325/ 1097] train: loss: 0.0110008
[Epoch 86; Iter   355/ 1097] train: loss: 0.0165345
[Epoch 86; Iter   385/ 1097] train: loss: 0.0525411
[Epoch 86; Iter   415/ 1097] train: loss: 0.0443135
[Epoch 86; Iter   445/ 1097] train: loss: 0.0657577
[Epoch 86; Iter   475/ 1097] train: loss: 0.0041885
[Epoch 86; Iter   505/ 1097] train: loss: 0.0128296
[Epoch 86; Iter   535/ 1097] train: loss: 0.0304279
[Epoch 86; Iter   565/ 1097] train: loss: 0.0174686
[Epoch 86; Iter   595/ 1097] train: loss: 0.0038632
[Epoch 86; Iter   625/ 1097] train: loss: 0.0028688
[Epoch 86; Iter   655/ 1097] train: loss: 0.0287668
[Epoch 86; Iter   685/ 1097] train: loss: 0.1156250
[Epoch 86; Iter   715/ 1097] train: loss: 0.0222424
[Epoch 86; Iter   745/ 1097] train: loss: 0.0091506
[Epoch 86; Iter   775/ 1097] train: loss: 0.0106871
[Epoch 86; Iter   805/ 1097] train: loss: 0.0027652
[Epoch 86; Iter   835/ 1097] train: loss: 0.0224879
[Epoch 86; Iter   865/ 1097] train: loss: 0.0024848
[Epoch 86; Iter   895/ 1097] train: loss: 0.0593865
[Epoch 86; Iter   925/ 1097] train: loss: 0.0031460
[Epoch 86; Iter   955/ 1097] train: loss: 0.0149010
[Epoch 86; Iter   985/ 1097] train: loss: 0.0030323
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0238774
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0013028
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0897327
[Epoch 86] ogbg-molhiv: 0.759991 val loss: 0.213202
[Epoch 86] ogbg-molhiv: 0.741387 test loss: 0.729153
[Epoch 87; Iter     8/ 1097] train: loss: 0.0055928
[Epoch 87; Iter    38/ 1097] train: loss: 0.0041902
[Epoch 87; Iter    68/ 1097] train: loss: 0.0048208
[Epoch 87; Iter    98/ 1097] train: loss: 0.0636635
[Epoch 87; Iter   128/ 1097] train: loss: 0.0112473
[Epoch 87; Iter   158/ 1097] train: loss: 0.0044801
[Epoch 87; Iter   188/ 1097] train: loss: 0.0043016
[Epoch 87; Iter   218/ 1097] train: loss: 0.0352168
[Epoch 87; Iter   248/ 1097] train: loss: 0.0034484
[Epoch 87; Iter   278/ 1097] train: loss: 0.0053198
[Epoch 87; Iter   308/ 1097] train: loss: 0.0264881
[Epoch 87; Iter   338/ 1097] train: loss: 0.0026971
[Epoch 87; Iter   368/ 1097] train: loss: 0.0086759
[Epoch 87; Iter   398/ 1097] train: loss: 0.0224416
[Epoch 87; Iter   428/ 1097] train: loss: 0.0095252
[Epoch 87; Iter   458/ 1097] train: loss: 0.0045796
[Epoch 87; Iter   488/ 1097] train: loss: 0.0274048
[Epoch 87; Iter   518/ 1097] train: loss: 0.0491390
[Epoch 87; Iter   548/ 1097] train: loss: 0.0229127
[Epoch 87; Iter   578/ 1097] train: loss: 0.0811503
[Epoch 87; Iter   608/ 1097] train: loss: 0.1043281
[Epoch 87; Iter   638/ 1097] train: loss: 0.0052144
[Epoch 87; Iter   668/ 1097] train: loss: 0.0048114
[Epoch 87; Iter   698/ 1097] train: loss: 0.0251189
[Epoch 87; Iter   728/ 1097] train: loss: 0.1554080
[Epoch 87; Iter   758/ 1097] train: loss: 0.0125440
[Epoch 87; Iter   788/ 1097] train: loss: 0.0392128
[Epoch 87; Iter   818/ 1097] train: loss: 0.0126519
[Epoch 87; Iter   848/ 1097] train: loss: 0.0145167
[Epoch 87; Iter   878/ 1097] train: loss: 0.0053115
[Epoch 87; Iter   908/ 1097] train: loss: 0.0500603
[Epoch 87; Iter   938/ 1097] train: loss: 0.0044277
[Epoch 87; Iter   968/ 1097] train: loss: 0.0401602
[Epoch 87; Iter   998/ 1097] train: loss: 0.0285814
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0231143
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0125608
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0115649
[Epoch 87] ogbg-molhiv: 0.762003 val loss: 0.167412
[Epoch 87] ogbg-molhiv: 0.737001 test loss: 0.360591
[Epoch 88; Iter    21/ 1097] train: loss: 0.0423298
[Epoch 88; Iter    51/ 1097] train: loss: 0.0021907
[Epoch 88; Iter    81/ 1097] train: loss: 0.0145211
[Epoch 88; Iter   111/ 1097] train: loss: 0.0065895
[Epoch 88; Iter   141/ 1097] train: loss: 0.0252747
[Epoch 88; Iter   171/ 1097] train: loss: 0.0178549
[Epoch 88; Iter   201/ 1097] train: loss: 0.0008010
[Epoch 88; Iter   231/ 1097] train: loss: 0.0496964
[Epoch 88; Iter   261/ 1097] train: loss: 0.0284923
[Epoch 88; Iter   291/ 1097] train: loss: 0.0021629
[Epoch 88; Iter   321/ 1097] train: loss: 0.0039778
[Epoch 88; Iter   351/ 1097] train: loss: 0.0073853
[Epoch 88; Iter   381/ 1097] train: loss: 0.0035853
[Epoch 88; Iter   411/ 1097] train: loss: 0.0313502
[Epoch 88; Iter   441/ 1097] train: loss: 0.0016510
[Epoch 88; Iter   471/ 1097] train: loss: 0.0588627
[Epoch 88; Iter   501/ 1097] train: loss: 0.0037960
[Epoch 88; Iter   531/ 1097] train: loss: 0.0882190
[Epoch 88; Iter   561/ 1097] train: loss: 0.0797473
[Epoch 88; Iter   591/ 1097] train: loss: 0.2177963
[Epoch 88; Iter   621/ 1097] train: loss: 0.0045176
[Epoch 88; Iter   651/ 1097] train: loss: 0.0023540
[Epoch 88; Iter   681/ 1097] train: loss: 0.0061508
[Epoch 88; Iter   711/ 1097] train: loss: 0.0428365
[Epoch 88; Iter   741/ 1097] train: loss: 0.0381531
[Epoch 88; Iter   771/ 1097] train: loss: 0.0019341
[Epoch 88; Iter   801/ 1097] train: loss: 0.0016213
[Epoch 88; Iter   831/ 1097] train: loss: 0.0092483
[Epoch 88; Iter   861/ 1097] train: loss: 0.0139349
[Epoch 88; Iter   891/ 1097] train: loss: 0.0043556
[Epoch 88; Iter   921/ 1097] train: loss: 0.0929867
[Epoch 88; Iter   951/ 1097] train: loss: 0.0016785
[Epoch 88; Iter   981/ 1097] train: loss: 0.0072352
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0044477
[Epoch 88; Iter  1041/ 1097] train: loss: 0.1143512
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0050922
[Epoch 88] ogbg-molhiv: 0.757480 val loss: 0.162377
[Epoch 88] ogbg-molhiv: 0.731130 test loss: 0.336775
[Epoch 89; Iter     4/ 1097] train: loss: 0.0132715
[Epoch 89; Iter    34/ 1097] train: loss: 0.0126777
[Epoch 89; Iter    64/ 1097] train: loss: 0.0263520
[Epoch 89; Iter    94/ 1097] train: loss: 0.0214163
[Epoch 89; Iter   124/ 1097] train: loss: 0.0631570
[Epoch 89; Iter   154/ 1097] train: loss: 0.0348064
[Epoch 89; Iter   184/ 1097] train: loss: 0.0077478
[Epoch 89; Iter   214/ 1097] train: loss: 0.0132200
[Epoch 89; Iter   244/ 1097] train: loss: 0.0019273
[Epoch 89; Iter   274/ 1097] train: loss: 0.1598896
[Epoch 89; Iter   304/ 1097] train: loss: 0.0070056
[Epoch 89; Iter   334/ 1097] train: loss: 0.0779761
[Epoch 89; Iter   364/ 1097] train: loss: 0.0142719
[Epoch 89; Iter   394/ 1097] train: loss: 0.0013243
[Epoch 89; Iter   424/ 1097] train: loss: 0.0593523
[Epoch 89; Iter   454/ 1097] train: loss: 0.0109487
[Epoch 89; Iter   484/ 1097] train: loss: 0.0044250
[Epoch 89; Iter   514/ 1097] train: loss: 0.0079222
[Epoch 87; Iter   510/  960] train: loss: 0.0049660
[Epoch 87; Iter   540/  960] train: loss: 0.0019417
[Epoch 87; Iter   570/  960] train: loss: 0.0660972
[Epoch 87; Iter   600/  960] train: loss: 0.0040360
[Epoch 87; Iter   630/  960] train: loss: 0.0205611
[Epoch 87; Iter   660/  960] train: loss: 0.0212187
[Epoch 87; Iter   690/  960] train: loss: 0.0236885
[Epoch 87; Iter   720/  960] train: loss: 0.0229870
[Epoch 87; Iter   750/  960] train: loss: 0.1828981
[Epoch 87; Iter   780/  960] train: loss: 0.0240087
[Epoch 87; Iter   810/  960] train: loss: 0.0161963
[Epoch 87; Iter   840/  960] train: loss: 0.0023555
[Epoch 87; Iter   870/  960] train: loss: 0.0846447
[Epoch 87; Iter   900/  960] train: loss: 0.0270189
[Epoch 87; Iter   930/  960] train: loss: 0.0343566
[Epoch 87; Iter   960/  960] train: loss: 0.0018538
[Epoch 87] ogbg-molhiv: 0.724265 val loss: 0.261933
[Epoch 87] ogbg-molhiv: 0.753404 test loss: 0.221738
[Epoch 88; Iter    30/  960] train: loss: 0.0007606
[Epoch 88; Iter    60/  960] train: loss: 0.0016730
[Epoch 88; Iter    90/  960] train: loss: 0.0083704
[Epoch 88; Iter   120/  960] train: loss: 0.0530779
[Epoch 88; Iter   150/  960] train: loss: 0.0555055
[Epoch 88; Iter   180/  960] train: loss: 0.0035964
[Epoch 88; Iter   210/  960] train: loss: 0.0056862
[Epoch 88; Iter   240/  960] train: loss: 0.0678019
[Epoch 88; Iter   270/  960] train: loss: 0.0014969
[Epoch 88; Iter   300/  960] train: loss: 0.0072154
[Epoch 88; Iter   330/  960] train: loss: 0.0396713
[Epoch 88; Iter   360/  960] train: loss: 0.0137609
[Epoch 88; Iter   390/  960] train: loss: 0.0172236
[Epoch 88; Iter   420/  960] train: loss: 0.0090398
[Epoch 88; Iter   450/  960] train: loss: 0.0028408
[Epoch 88; Iter   480/  960] train: loss: 0.0026693
[Epoch 88; Iter   510/  960] train: loss: 0.0075768
[Epoch 88; Iter   540/  960] train: loss: 0.0125087
[Epoch 88; Iter   570/  960] train: loss: 0.0195923
[Epoch 88; Iter   600/  960] train: loss: 0.0614037
[Epoch 88; Iter   630/  960] train: loss: 0.0148680
[Epoch 88; Iter   660/  960] train: loss: 0.0970326
[Epoch 88; Iter   690/  960] train: loss: 0.0039049
[Epoch 88; Iter   720/  960] train: loss: 0.0072994
[Epoch 88; Iter   750/  960] train: loss: 0.0093453
[Epoch 88; Iter   780/  960] train: loss: 0.0044162
[Epoch 88; Iter   810/  960] train: loss: 0.0129387
[Epoch 88; Iter   840/  960] train: loss: 0.0164637
[Epoch 88; Iter   870/  960] train: loss: 0.0065470
[Epoch 88; Iter   900/  960] train: loss: 0.0115206
[Epoch 88; Iter   930/  960] train: loss: 0.0277197
[Epoch 88; Iter   960/  960] train: loss: 0.0033137
[Epoch 88] ogbg-molhiv: 0.728089 val loss: 0.299296
[Epoch 88] ogbg-molhiv: 0.758794 test loss: 0.208587
[Epoch 89; Iter    30/  960] train: loss: 0.0153127
[Epoch 89; Iter    60/  960] train: loss: 0.0247920
[Epoch 89; Iter    90/  960] train: loss: 0.0036950
[Epoch 89; Iter   120/  960] train: loss: 0.0262144
[Epoch 89; Iter   150/  960] train: loss: 0.0121873
[Epoch 89; Iter   180/  960] train: loss: 0.0104947
[Epoch 89; Iter   210/  960] train: loss: 0.0035430
[Epoch 89; Iter   240/  960] train: loss: 0.0871917
[Epoch 89; Iter   270/  960] train: loss: 0.0061041
[Epoch 89; Iter   300/  960] train: loss: 0.0024765
[Epoch 89; Iter   330/  960] train: loss: 0.0086554
[Epoch 89; Iter   360/  960] train: loss: 0.0260419
[Epoch 89; Iter   390/  960] train: loss: 0.0033514
[Epoch 89; Iter   420/  960] train: loss: 0.0391984
[Epoch 89; Iter   450/  960] train: loss: 0.0021680
[Epoch 89; Iter   480/  960] train: loss: 0.0008134
[Epoch 89; Iter   510/  960] train: loss: 0.0075866
[Epoch 89; Iter   540/  960] train: loss: 0.0230988
[Epoch 89; Iter   570/  960] train: loss: 0.0014685
[Epoch 89; Iter   600/  960] train: loss: 0.0300635
[Epoch 89; Iter   630/  960] train: loss: 0.0878083
[Epoch 89; Iter   660/  960] train: loss: 0.0042664
[Epoch 89; Iter   690/  960] train: loss: 0.0218186
[Epoch 89; Iter   720/  960] train: loss: 0.0052730
[Epoch 89; Iter   750/  960] train: loss: 0.0076497
[Epoch 89; Iter   780/  960] train: loss: 0.0015449
[Epoch 89; Iter   810/  960] train: loss: 0.0060078
[Epoch 89; Iter   840/  960] train: loss: 0.0025540
[Epoch 89; Iter   870/  960] train: loss: 0.0038762
[Epoch 89; Iter   900/  960] train: loss: 0.0011460
[Epoch 89; Iter   930/  960] train: loss: 0.0006762
[Epoch 89; Iter   960/  960] train: loss: 0.0093420
[Epoch 89] ogbg-molhiv: 0.719238 val loss: 0.277867
[Epoch 89] ogbg-molhiv: 0.762328 test loss: 0.207158
[Epoch 90; Iter    30/  960] train: loss: 0.0011310
[Epoch 90; Iter    60/  960] train: loss: 0.0006205
[Epoch 90; Iter    90/  960] train: loss: 0.0302945
[Epoch 90; Iter   120/  960] train: loss: 0.0758989
[Epoch 90; Iter   150/  960] train: loss: 0.0770108
[Epoch 90; Iter   180/  960] train: loss: 0.0133403
[Epoch 90; Iter   210/  960] train: loss: 0.0019243
[Epoch 90; Iter   240/  960] train: loss: 0.0297982
[Epoch 90; Iter   270/  960] train: loss: 0.0769926
[Epoch 90; Iter   300/  960] train: loss: 0.0121343
[Epoch 90; Iter   330/  960] train: loss: 0.0184902
[Epoch 90; Iter   360/  960] train: loss: 0.0054737
[Epoch 90; Iter   390/  960] train: loss: 0.0361978
[Epoch 90; Iter   420/  960] train: loss: 0.0901722
[Epoch 90; Iter   450/  960] train: loss: 0.0077349
[Epoch 90; Iter   480/  960] train: loss: 0.0909932
[Epoch 90; Iter   510/  960] train: loss: 0.0436949
[Epoch 90; Iter   540/  960] train: loss: 0.0073847
[Epoch 90; Iter   570/  960] train: loss: 0.0023780
[Epoch 90; Iter   600/  960] train: loss: 0.0167627
[Epoch 90; Iter   630/  960] train: loss: 0.0094931
[Epoch 90; Iter   660/  960] train: loss: 0.0006503
[Epoch 90; Iter   690/  960] train: loss: 0.0015009
[Epoch 90; Iter   720/  960] train: loss: 0.0338233
[Epoch 90; Iter   750/  960] train: loss: 0.0029015
[Epoch 90; Iter   780/  960] train: loss: 0.0030642
[Epoch 90; Iter   810/  960] train: loss: 0.0016322
[Epoch 90; Iter   840/  960] train: loss: 0.0067102
[Epoch 90; Iter   870/  960] train: loss: 0.0017186
[Epoch 90; Iter   900/  960] train: loss: 0.0225301
[Epoch 90; Iter   930/  960] train: loss: 0.0038466
[Epoch 90; Iter   960/  960] train: loss: 0.0038743
[Epoch 90] ogbg-molhiv: 0.723156 val loss: 0.270251
[Epoch 90] ogbg-molhiv: 0.759581 test loss: 0.209822
[Epoch 91; Iter    30/  960] train: loss: 0.0007296
[Epoch 91; Iter    60/  960] train: loss: 0.0006492
[Epoch 91; Iter    90/  960] train: loss: 0.0038677
[Epoch 91; Iter   120/  960] train: loss: 0.0601866
[Epoch 91; Iter   150/  960] train: loss: 0.0061256
[Epoch 91; Iter   180/  960] train: loss: 0.0022093
[Epoch 91; Iter   210/  960] train: loss: 0.0687912
[Epoch 91; Iter   240/  960] train: loss: 0.0007057
[Epoch 91; Iter   270/  960] train: loss: 0.0039033
[Epoch 91; Iter   300/  960] train: loss: 0.0110483
[Epoch 91; Iter   330/  960] train: loss: 0.0029614
[Epoch 91; Iter   360/  960] train: loss: 0.0247236
[Epoch 91; Iter   390/  960] train: loss: 0.0533887
[Epoch 91; Iter   420/  960] train: loss: 0.0132300
[Epoch 91; Iter   450/  960] train: loss: 0.0125076
[Epoch 91; Iter   480/  960] train: loss: 0.0096533
[Epoch 91; Iter   510/  960] train: loss: 0.0090145
[Epoch 91; Iter   540/  960] train: loss: 0.0341658
[Epoch 91; Iter   570/  960] train: loss: 0.0064135
[Epoch 91; Iter   600/  960] train: loss: 0.0034032
[Epoch 91; Iter   630/  960] train: loss: 0.0023397
[Epoch 91; Iter   660/  960] train: loss: 0.0009469
[Epoch 91; Iter   690/  960] train: loss: 0.1960114
[Epoch 91; Iter   720/  960] train: loss: 0.0061879
[Epoch 91; Iter   750/  960] train: loss: 0.0031299
[Epoch 91; Iter   780/  960] train: loss: 0.0011237
[Epoch 91; Iter   810/  960] train: loss: 0.0090483
[Epoch 91; Iter   840/  960] train: loss: 0.0061515
[Epoch 91; Iter   870/  960] train: loss: 0.0015382
[Epoch 91; Iter   900/  960] train: loss: 0.0269591
[Epoch 91; Iter   930/  960] train: loss: 0.0292968
[Epoch 91; Iter   960/  960] train: loss: 0.0172110
[Epoch 91] ogbg-molhiv: 0.712629 val loss: 0.619051
[Epoch 91] ogbg-molhiv: 0.748635 test loss: 0.789424
[Epoch 92; Iter    30/  960] train: loss: 0.0489358
[Epoch 92; Iter    60/  960] train: loss: 0.0841057
[Epoch 92; Iter    90/  960] train: loss: 0.0019511
[Epoch 87; Iter   510/  960] train: loss: 0.0213976
[Epoch 87; Iter   540/  960] train: loss: 0.0282469
[Epoch 87; Iter   570/  960] train: loss: 0.0079269
[Epoch 87; Iter   600/  960] train: loss: 0.0009157
[Epoch 87; Iter   630/  960] train: loss: 0.0007493
[Epoch 87; Iter   660/  960] train: loss: 0.0067273
[Epoch 87; Iter   690/  960] train: loss: 0.0763520
[Epoch 87; Iter   720/  960] train: loss: 0.0490635
[Epoch 87; Iter   750/  960] train: loss: 0.0246148
[Epoch 87; Iter   780/  960] train: loss: 0.1107600
[Epoch 87; Iter   810/  960] train: loss: 0.0340782
[Epoch 87; Iter   840/  960] train: loss: 0.0012851
[Epoch 87; Iter   870/  960] train: loss: 0.0058349
[Epoch 87; Iter   900/  960] train: loss: 0.0049856
[Epoch 87; Iter   930/  960] train: loss: 0.2494732
[Epoch 87; Iter   960/  960] train: loss: 0.0066787
[Epoch 87] ogbg-molhiv: 0.754872 val loss: 0.939982
[Epoch 87] ogbg-molhiv: 0.752909 test loss: 0.231966
[Epoch 88; Iter    30/  960] train: loss: 0.0047884
[Epoch 88; Iter    60/  960] train: loss: 0.0741256
[Epoch 88; Iter    90/  960] train: loss: 0.0444804
[Epoch 88; Iter   120/  960] train: loss: 0.0047502
[Epoch 88; Iter   150/  960] train: loss: 0.0038890
[Epoch 88; Iter   180/  960] train: loss: 0.0293181
[Epoch 88; Iter   210/  960] train: loss: 0.0729619
[Epoch 88; Iter   240/  960] train: loss: 0.0361519
[Epoch 88; Iter   270/  960] train: loss: 0.0394358
[Epoch 88; Iter   300/  960] train: loss: 0.0405198
[Epoch 88; Iter   330/  960] train: loss: 0.0137868
[Epoch 88; Iter   360/  960] train: loss: 0.0083621
[Epoch 88; Iter   390/  960] train: loss: 0.0115595
[Epoch 88; Iter   420/  960] train: loss: 0.0136735
[Epoch 88; Iter   450/  960] train: loss: 0.0116331
[Epoch 88; Iter   480/  960] train: loss: 0.0085778
[Epoch 88; Iter   510/  960] train: loss: 0.0037402
[Epoch 88; Iter   540/  960] train: loss: 0.1387080
[Epoch 88; Iter   570/  960] train: loss: 0.0388350
[Epoch 88; Iter   600/  960] train: loss: 0.0096917
[Epoch 88; Iter   630/  960] train: loss: 0.0068543
[Epoch 88; Iter   660/  960] train: loss: 0.0322684
[Epoch 88; Iter   690/  960] train: loss: 0.0133512
[Epoch 88; Iter   720/  960] train: loss: 0.1489388
[Epoch 88; Iter   750/  960] train: loss: 0.0919715
[Epoch 88; Iter   780/  960] train: loss: 0.0689998
[Epoch 88; Iter   810/  960] train: loss: 0.0214232
[Epoch 88; Iter   840/  960] train: loss: 0.0017669
[Epoch 88; Iter   870/  960] train: loss: 0.0143799
[Epoch 88; Iter   900/  960] train: loss: 0.0227181
[Epoch 88; Iter   930/  960] train: loss: 0.0049627
[Epoch 88; Iter   960/  960] train: loss: 0.3776008
[Epoch 88] ogbg-molhiv: 0.752210 val loss: 0.881839
[Epoch 88] ogbg-molhiv: 0.754514 test loss: 0.261577
[Epoch 89; Iter    30/  960] train: loss: 0.0069926
[Epoch 89; Iter    60/  960] train: loss: 0.0019312
[Epoch 89; Iter    90/  960] train: loss: 0.0833594
[Epoch 89; Iter   120/  960] train: loss: 0.0144547
[Epoch 89; Iter   150/  960] train: loss: 0.0202564
[Epoch 89; Iter   180/  960] train: loss: 0.0021276
[Epoch 89; Iter   210/  960] train: loss: 0.0128114
[Epoch 89; Iter   240/  960] train: loss: 0.0007115
[Epoch 89; Iter   270/  960] train: loss: 0.0027732
[Epoch 89; Iter   300/  960] train: loss: 0.1156220
[Epoch 89; Iter   330/  960] train: loss: 0.0156449
[Epoch 89; Iter   360/  960] train: loss: 0.0009994
[Epoch 89; Iter   390/  960] train: loss: 0.0167872
[Epoch 89; Iter   420/  960] train: loss: 0.1032110
[Epoch 89; Iter   450/  960] train: loss: 0.0138354
[Epoch 89; Iter   480/  960] train: loss: 0.0026606
[Epoch 89; Iter   510/  960] train: loss: 0.0053558
[Epoch 89; Iter   540/  960] train: loss: 0.0008997
[Epoch 89; Iter   570/  960] train: loss: 0.0046844
[Epoch 89; Iter   600/  960] train: loss: 0.0093050
[Epoch 89; Iter   630/  960] train: loss: 0.0506695
[Epoch 89; Iter   660/  960] train: loss: 0.0106887
[Epoch 89; Iter   690/  960] train: loss: 0.0149242
[Epoch 89; Iter   720/  960] train: loss: 0.0201309
[Epoch 89; Iter   750/  960] train: loss: 0.0013721
[Epoch 89; Iter   780/  960] train: loss: 0.0045381
[Epoch 89; Iter   810/  960] train: loss: 0.0011767
[Epoch 89; Iter   840/  960] train: loss: 0.0013598
[Epoch 89; Iter   870/  960] train: loss: 0.0020293
[Epoch 89; Iter   900/  960] train: loss: 0.0279287
[Epoch 89; Iter   930/  960] train: loss: 0.0265048
[Epoch 89; Iter   960/  960] train: loss: 0.0126322
[Epoch 89] ogbg-molhiv: 0.751803 val loss: 0.965435
[Epoch 89] ogbg-molhiv: 0.753144 test loss: 0.262352
[Epoch 90; Iter    30/  960] train: loss: 0.0166230
[Epoch 90; Iter    60/  960] train: loss: 0.0149541
[Epoch 90; Iter    90/  960] train: loss: 0.0015049
[Epoch 90; Iter   120/  960] train: loss: 0.0878871
[Epoch 90; Iter   150/  960] train: loss: 0.0277814
[Epoch 90; Iter   180/  960] train: loss: 0.0026301
[Epoch 90; Iter   210/  960] train: loss: 0.0169753
[Epoch 90; Iter   240/  960] train: loss: 0.0109553
[Epoch 90; Iter   270/  960] train: loss: 0.0407066
[Epoch 90; Iter   300/  960] train: loss: 0.0128093
[Epoch 90; Iter   330/  960] train: loss: 0.0044933
[Epoch 90; Iter   360/  960] train: loss: 0.0074315
[Epoch 90; Iter   390/  960] train: loss: 0.0017316
[Epoch 90; Iter   420/  960] train: loss: 0.0020533
[Epoch 90; Iter   450/  960] train: loss: 0.0058291
[Epoch 90; Iter   480/  960] train: loss: 0.0151345
[Epoch 90; Iter   510/  960] train: loss: 0.0015601
[Epoch 90; Iter   540/  960] train: loss: 0.1419574
[Epoch 90; Iter   570/  960] train: loss: 0.0416633
[Epoch 90; Iter   600/  960] train: loss: 0.0052058
[Epoch 90; Iter   630/  960] train: loss: 0.0206937
[Epoch 90; Iter   660/  960] train: loss: 0.0098934
[Epoch 90; Iter   690/  960] train: loss: 0.0047285
[Epoch 90; Iter   720/  960] train: loss: 0.0190534
[Epoch 90; Iter   750/  960] train: loss: 0.0101096
[Epoch 90; Iter   780/  960] train: loss: 0.0035636
[Epoch 90; Iter   810/  960] train: loss: 0.0088767
[Epoch 90; Iter   840/  960] train: loss: 0.0377791
[Epoch 90; Iter   870/  960] train: loss: 0.0008586
[Epoch 90; Iter   900/  960] train: loss: 0.0279712
[Epoch 90; Iter   930/  960] train: loss: 0.0795575
[Epoch 90; Iter   960/  960] train: loss: 0.0032548
[Epoch 90] ogbg-molhiv: 0.751012 val loss: 0.877620
[Epoch 90] ogbg-molhiv: 0.753312 test loss: 0.295927
[Epoch 91; Iter    30/  960] train: loss: 0.0119570
[Epoch 91; Iter    60/  960] train: loss: 0.0075054
[Epoch 91; Iter    90/  960] train: loss: 0.0106373
[Epoch 91; Iter   120/  960] train: loss: 0.0043105
[Epoch 91; Iter   150/  960] train: loss: 0.0375011
[Epoch 91; Iter   180/  960] train: loss: 0.0120229
[Epoch 91; Iter   210/  960] train: loss: 0.0293946
[Epoch 91; Iter   240/  960] train: loss: 0.0038321
[Epoch 91; Iter   270/  960] train: loss: 0.0028304
[Epoch 91; Iter   300/  960] train: loss: 0.0080084
[Epoch 91; Iter   330/  960] train: loss: 0.0022051
[Epoch 91; Iter   360/  960] train: loss: 0.0029238
[Epoch 91; Iter   390/  960] train: loss: 0.0167011
[Epoch 91; Iter   420/  960] train: loss: 0.0669382
[Epoch 91; Iter   450/  960] train: loss: 0.0450282
[Epoch 91; Iter   480/  960] train: loss: 0.0233612
[Epoch 91; Iter   510/  960] train: loss: 0.0063218
[Epoch 91; Iter   540/  960] train: loss: 0.0261780
[Epoch 91; Iter   570/  960] train: loss: 0.0962070
[Epoch 91; Iter   600/  960] train: loss: 0.0414163
[Epoch 91; Iter   630/  960] train: loss: 0.0408637
[Epoch 91; Iter   660/  960] train: loss: 0.0661168
[Epoch 91; Iter   690/  960] train: loss: 0.0060407
[Epoch 91; Iter   720/  960] train: loss: 0.0235581
[Epoch 91; Iter   750/  960] train: loss: 0.0386055
[Epoch 91; Iter   780/  960] train: loss: 0.0087245
[Epoch 91; Iter   810/  960] train: loss: 0.0025652
[Epoch 91; Iter   840/  960] train: loss: 0.0470691
[Epoch 91; Iter   870/  960] train: loss: 0.0008888
[Epoch 91; Iter   900/  960] train: loss: 0.0469299
[Epoch 91; Iter   930/  960] train: loss: 0.0071535
[Epoch 91; Iter   960/  960] train: loss: 0.0033410
[Epoch 91] ogbg-molhiv: 0.757458 val loss: 1.188363
[Epoch 91] ogbg-molhiv: 0.752368 test loss: 0.302598
[Epoch 92; Iter    30/  960] train: loss: 0.0729407
[Epoch 92; Iter    60/  960] train: loss: 0.0080203
[Epoch 92; Iter    90/  960] train: loss: 0.0060568
[Epoch 85; Iter   462/ 1097] train: loss: 0.0040361
[Epoch 85; Iter   492/ 1097] train: loss: 0.0098066
[Epoch 85; Iter   522/ 1097] train: loss: 0.0293385
[Epoch 85; Iter   552/ 1097] train: loss: 0.0737613
[Epoch 85; Iter   582/ 1097] train: loss: 0.2224868
[Epoch 85; Iter   612/ 1097] train: loss: 0.0127544
[Epoch 85; Iter   642/ 1097] train: loss: 0.0452842
[Epoch 85; Iter   672/ 1097] train: loss: 0.0043776
[Epoch 85; Iter   702/ 1097] train: loss: 0.0142839
[Epoch 85; Iter   732/ 1097] train: loss: 0.0048199
[Epoch 85; Iter   762/ 1097] train: loss: 0.0462546
[Epoch 85; Iter   792/ 1097] train: loss: 0.0303156
[Epoch 85; Iter   822/ 1097] train: loss: 0.0404252
[Epoch 85; Iter   852/ 1097] train: loss: 0.0223096
[Epoch 85; Iter   882/ 1097] train: loss: 0.1182109
[Epoch 85; Iter   912/ 1097] train: loss: 0.0149526
[Epoch 85; Iter   942/ 1097] train: loss: 0.0052173
[Epoch 85; Iter   972/ 1097] train: loss: 0.0346639
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0020587
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0130731
[Epoch 85; Iter  1062/ 1097] train: loss: 0.1542473
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0069344
[Epoch 85] ogbg-molhiv: 0.787383 val loss: 0.123840
[Epoch 85] ogbg-molhiv: 0.726862 test loss: 0.207319
[Epoch 86; Iter    25/ 1097] train: loss: 0.0046251
[Epoch 86; Iter    55/ 1097] train: loss: 0.0084937
[Epoch 86; Iter    85/ 1097] train: loss: 0.0133075
[Epoch 86; Iter   115/ 1097] train: loss: 0.0455034
[Epoch 86; Iter   145/ 1097] train: loss: 0.0036504
[Epoch 86; Iter   175/ 1097] train: loss: 0.0237706
[Epoch 86; Iter   205/ 1097] train: loss: 0.0772006
[Epoch 86; Iter   235/ 1097] train: loss: 0.0052970
[Epoch 86; Iter   265/ 1097] train: loss: 0.0571486
[Epoch 86; Iter   295/ 1097] train: loss: 0.0066256
[Epoch 86; Iter   325/ 1097] train: loss: 0.0046930
[Epoch 86; Iter   355/ 1097] train: loss: 0.0076344
[Epoch 86; Iter   385/ 1097] train: loss: 0.0107110
[Epoch 86; Iter   415/ 1097] train: loss: 0.0034984
[Epoch 86; Iter   445/ 1097] train: loss: 0.0075772
[Epoch 86; Iter   475/ 1097] train: loss: 0.0463059
[Epoch 86; Iter   505/ 1097] train: loss: 0.0524583
[Epoch 86; Iter   535/ 1097] train: loss: 0.0084842
[Epoch 86; Iter   565/ 1097] train: loss: 0.0095728
[Epoch 86; Iter   595/ 1097] train: loss: 0.0150503
[Epoch 86; Iter   625/ 1097] train: loss: 0.0196828
[Epoch 86; Iter   655/ 1097] train: loss: 0.1977197
[Epoch 86; Iter   685/ 1097] train: loss: 0.0218436
[Epoch 86; Iter   715/ 1097] train: loss: 0.0185895
[Epoch 86; Iter   745/ 1097] train: loss: 0.0415963
[Epoch 86; Iter   775/ 1097] train: loss: 0.0596300
[Epoch 86; Iter   805/ 1097] train: loss: 0.0172768
[Epoch 86; Iter   835/ 1097] train: loss: 0.0294731
[Epoch 86; Iter   865/ 1097] train: loss: 0.0062282
[Epoch 86; Iter   895/ 1097] train: loss: 0.0097032
[Epoch 86; Iter   925/ 1097] train: loss: 0.0084596
[Epoch 86; Iter   955/ 1097] train: loss: 0.0406959
[Epoch 86; Iter   985/ 1097] train: loss: 0.0229806
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0100539
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0387303
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0454581
[Epoch 86] ogbg-molhiv: 0.781278 val loss: 0.131171
[Epoch 86] ogbg-molhiv: 0.732509 test loss: 0.205501
[Epoch 87; Iter     8/ 1097] train: loss: 0.0233985
[Epoch 87; Iter    38/ 1097] train: loss: 0.0040282
[Epoch 87; Iter    68/ 1097] train: loss: 0.0071005
[Epoch 87; Iter    98/ 1097] train: loss: 0.0107695
[Epoch 87; Iter   128/ 1097] train: loss: 0.0975897
[Epoch 87; Iter   158/ 1097] train: loss: 0.0139018
[Epoch 87; Iter   188/ 1097] train: loss: 0.0872358
[Epoch 87; Iter   218/ 1097] train: loss: 0.0593689
[Epoch 87; Iter   248/ 1097] train: loss: 0.0576575
[Epoch 87; Iter   278/ 1097] train: loss: 0.0957206
[Epoch 87; Iter   308/ 1097] train: loss: 0.0056541
[Epoch 87; Iter   338/ 1097] train: loss: 0.0205683
[Epoch 87; Iter   368/ 1097] train: loss: 0.2230947
[Epoch 87; Iter   398/ 1097] train: loss: 0.0095401
[Epoch 87; Iter   428/ 1097] train: loss: 0.0167417
[Epoch 87; Iter   458/ 1097] train: loss: 0.0027938
[Epoch 87; Iter   488/ 1097] train: loss: 0.0187323
[Epoch 87; Iter   518/ 1097] train: loss: 0.0048157
[Epoch 87; Iter   548/ 1097] train: loss: 0.0204210
[Epoch 87; Iter   578/ 1097] train: loss: 0.0553137
[Epoch 87; Iter   608/ 1097] train: loss: 0.0131465
[Epoch 87; Iter   638/ 1097] train: loss: 0.0095955
[Epoch 87; Iter   668/ 1097] train: loss: 0.0039180
[Epoch 87; Iter   698/ 1097] train: loss: 0.1693781
[Epoch 87; Iter   728/ 1097] train: loss: 0.1383515
[Epoch 87; Iter   758/ 1097] train: loss: 0.0090842
[Epoch 87; Iter   788/ 1097] train: loss: 0.0322065
[Epoch 87; Iter   818/ 1097] train: loss: 0.0043107
[Epoch 87; Iter   848/ 1097] train: loss: 0.0456287
[Epoch 87; Iter   878/ 1097] train: loss: 0.0184748
[Epoch 87; Iter   908/ 1097] train: loss: 0.0622288
[Epoch 87; Iter   938/ 1097] train: loss: 0.0066488
[Epoch 87; Iter   968/ 1097] train: loss: 0.0399774
[Epoch 87; Iter   998/ 1097] train: loss: 0.0289589
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0938047
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0094479
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0050605
[Epoch 87] ogbg-molhiv: 0.780668 val loss: 0.124772
[Epoch 87] ogbg-molhiv: 0.734736 test loss: 0.204886
[Epoch 88; Iter    21/ 1097] train: loss: 0.0421732
[Epoch 88; Iter    51/ 1097] train: loss: 0.0163978
[Epoch 88; Iter    81/ 1097] train: loss: 0.2121315
[Epoch 88; Iter   111/ 1097] train: loss: 0.0103456
[Epoch 88; Iter   141/ 1097] train: loss: 0.0099916
[Epoch 88; Iter   171/ 1097] train: loss: 0.0510284
[Epoch 88; Iter   201/ 1097] train: loss: 0.0702255
[Epoch 88; Iter   231/ 1097] train: loss: 0.0591880
[Epoch 88; Iter   261/ 1097] train: loss: 0.0244204
[Epoch 88; Iter   291/ 1097] train: loss: 0.0289884
[Epoch 88; Iter   321/ 1097] train: loss: 0.0185636
[Epoch 88; Iter   351/ 1097] train: loss: 0.0303932
[Epoch 88; Iter   381/ 1097] train: loss: 0.0214147
[Epoch 88; Iter   411/ 1097] train: loss: 0.0065837
[Epoch 88; Iter   441/ 1097] train: loss: 0.0015385
[Epoch 88; Iter   471/ 1097] train: loss: 0.0388247
[Epoch 88; Iter   501/ 1097] train: loss: 0.0186705
[Epoch 88; Iter   531/ 1097] train: loss: 0.0096204
[Epoch 88; Iter   561/ 1097] train: loss: 0.0054318
[Epoch 88; Iter   591/ 1097] train: loss: 0.0076058
[Epoch 88; Iter   621/ 1097] train: loss: 0.0030338
[Epoch 88; Iter   651/ 1097] train: loss: 0.0487098
[Epoch 88; Iter   681/ 1097] train: loss: 0.0559959
[Epoch 88; Iter   711/ 1097] train: loss: 0.0270470
[Epoch 88; Iter   741/ 1097] train: loss: 0.0394724
[Epoch 88; Iter   771/ 1097] train: loss: 0.2068577
[Epoch 88; Iter   801/ 1097] train: loss: 0.0235403
[Epoch 88; Iter   831/ 1097] train: loss: 0.0628930
[Epoch 88; Iter   861/ 1097] train: loss: 0.0234025
[Epoch 88; Iter   891/ 1097] train: loss: 0.0274757
[Epoch 88; Iter   921/ 1097] train: loss: 0.0023431
[Epoch 88; Iter   951/ 1097] train: loss: 0.0446110
[Epoch 88; Iter   981/ 1097] train: loss: 0.0244411
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0398395
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0929460
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0057659
[Epoch 88] ogbg-molhiv: 0.781755 val loss: 0.141062
[Epoch 88] ogbg-molhiv: 0.742844 test loss: 0.203091
[Epoch 89; Iter     4/ 1097] train: loss: 0.0043107
[Epoch 89; Iter    34/ 1097] train: loss: 0.0282280
[Epoch 89; Iter    64/ 1097] train: loss: 0.0047399
[Epoch 89; Iter    94/ 1097] train: loss: 0.0112750
[Epoch 89; Iter   124/ 1097] train: loss: 0.0019116
[Epoch 89; Iter   154/ 1097] train: loss: 0.0273408
[Epoch 89; Iter   184/ 1097] train: loss: 0.0733512
[Epoch 89; Iter   214/ 1097] train: loss: 0.0038254
[Epoch 89; Iter   244/ 1097] train: loss: 0.0793014
[Epoch 89; Iter   274/ 1097] train: loss: 0.0186752
[Epoch 89; Iter   304/ 1097] train: loss: 0.0767585
[Epoch 89; Iter   334/ 1097] train: loss: 0.0501392
[Epoch 89; Iter   364/ 1097] train: loss: 0.1025697
[Epoch 89; Iter   394/ 1097] train: loss: 0.0571767
[Epoch 89; Iter   424/ 1097] train: loss: 0.0373768
[Epoch 89; Iter   454/ 1097] train: loss: 0.0077479
[Epoch 89; Iter   484/ 1097] train: loss: 0.0186130
[Epoch 89; Iter   514/ 1097] train: loss: 0.0125167
[Epoch 87; Iter   510/  960] train: loss: 0.0016042
[Epoch 87; Iter   540/  960] train: loss: 0.0064985
[Epoch 87; Iter   570/  960] train: loss: 0.0016669
[Epoch 87; Iter   600/  960] train: loss: 0.0084903
[Epoch 87; Iter   630/  960] train: loss: 0.0242491
[Epoch 87; Iter   660/  960] train: loss: 0.0063777
[Epoch 87; Iter   690/  960] train: loss: 0.0019964
[Epoch 87; Iter   720/  960] train: loss: 0.0095914
[Epoch 87; Iter   750/  960] train: loss: 0.0369337
[Epoch 87; Iter   780/  960] train: loss: 0.0912472
[Epoch 87; Iter   810/  960] train: loss: 0.0063580
[Epoch 87; Iter   840/  960] train: loss: 0.0035435
[Epoch 87; Iter   870/  960] train: loss: 0.0036592
[Epoch 87; Iter   900/  960] train: loss: 0.0220351
[Epoch 87; Iter   930/  960] train: loss: 0.0086430
[Epoch 87; Iter   960/  960] train: loss: 0.0089024
[Epoch 87] ogbg-molhiv: 0.726385 val loss: 0.257572
[Epoch 87] ogbg-molhiv: 0.759399 test loss: 0.195639
[Epoch 88; Iter    30/  960] train: loss: 0.0234286
[Epoch 88; Iter    60/  960] train: loss: 0.0103883
[Epoch 88; Iter    90/  960] train: loss: 0.0699159
[Epoch 88; Iter   120/  960] train: loss: 0.0345945
[Epoch 88; Iter   150/  960] train: loss: 0.0389913
[Epoch 88; Iter   180/  960] train: loss: 0.0218637
[Epoch 88; Iter   210/  960] train: loss: 0.0654779
[Epoch 88; Iter   240/  960] train: loss: 0.0035512
[Epoch 88; Iter   270/  960] train: loss: 0.0472461
[Epoch 88; Iter   300/  960] train: loss: 0.0100404
[Epoch 88; Iter   330/  960] train: loss: 0.0475509
[Epoch 88; Iter   360/  960] train: loss: 0.0373545
[Epoch 88; Iter   390/  960] train: loss: 0.0083179
[Epoch 88; Iter   420/  960] train: loss: 0.0099959
[Epoch 88; Iter   450/  960] train: loss: 0.0480133
[Epoch 88; Iter   480/  960] train: loss: 0.0154797
[Epoch 88; Iter   510/  960] train: loss: 0.0072205
[Epoch 88; Iter   540/  960] train: loss: 0.0128565
[Epoch 88; Iter   570/  960] train: loss: 0.0021834
[Epoch 88; Iter   600/  960] train: loss: 0.0628175
[Epoch 88; Iter   630/  960] train: loss: 0.0015877
[Epoch 88; Iter   660/  960] train: loss: 0.0023061
[Epoch 88; Iter   690/  960] train: loss: 0.0077451
[Epoch 88; Iter   720/  960] train: loss: 0.0403799
[Epoch 88; Iter   750/  960] train: loss: 0.0009441
[Epoch 88; Iter   780/  960] train: loss: 0.0139693
[Epoch 88; Iter   810/  960] train: loss: 0.0262684
[Epoch 88; Iter   840/  960] train: loss: 0.0122841
[Epoch 88; Iter   870/  960] train: loss: 0.0017361
[Epoch 88; Iter   900/  960] train: loss: 0.0290210
[Epoch 88; Iter   930/  960] train: loss: 0.0040447
[Epoch 88; Iter   960/  960] train: loss: 0.1876404
[Epoch 88] ogbg-molhiv: 0.723536 val loss: 0.245016
[Epoch 88] ogbg-molhiv: 0.747254 test loss: 0.189599
[Epoch 89; Iter    30/  960] train: loss: 0.0013410
[Epoch 89; Iter    60/  960] train: loss: 0.0295231
[Epoch 89; Iter    90/  960] train: loss: 0.0136685
[Epoch 89; Iter   120/  960] train: loss: 0.0051804
[Epoch 89; Iter   150/  960] train: loss: 0.0643208
[Epoch 89; Iter   180/  960] train: loss: 0.0014104
[Epoch 89; Iter   210/  960] train: loss: 0.0196171
[Epoch 89; Iter   240/  960] train: loss: 0.0265863
[Epoch 89; Iter   270/  960] train: loss: 0.0186608
[Epoch 89; Iter   300/  960] train: loss: 0.0227622
[Epoch 89; Iter   330/  960] train: loss: 0.0377256
[Epoch 89; Iter   360/  960] train: loss: 0.0379407
[Epoch 89; Iter   390/  960] train: loss: 0.0037526
[Epoch 89; Iter   420/  960] train: loss: 0.0056371
[Epoch 89; Iter   450/  960] train: loss: 0.1656030
[Epoch 89; Iter   480/  960] train: loss: 0.0008753
[Epoch 89; Iter   510/  960] train: loss: 0.0030305
[Epoch 89; Iter   540/  960] train: loss: 0.0030406
[Epoch 89; Iter   570/  960] train: loss: 0.0096856
[Epoch 89; Iter   600/  960] train: loss: 0.1107494
[Epoch 89; Iter   630/  960] train: loss: 0.0075581
[Epoch 89; Iter   660/  960] train: loss: 0.0133291
[Epoch 89; Iter   690/  960] train: loss: 0.0076868
[Epoch 89; Iter   720/  960] train: loss: 0.0019465
[Epoch 89; Iter   750/  960] train: loss: 0.0061755
[Epoch 89; Iter   780/  960] train: loss: 0.1749386
[Epoch 89; Iter   810/  960] train: loss: 0.0020810
[Epoch 89; Iter   840/  960] train: loss: 0.0109297
[Epoch 89; Iter   870/  960] train: loss: 0.0199913
[Epoch 89; Iter   900/  960] train: loss: 0.0101464
[Epoch 89; Iter   930/  960] train: loss: 0.0061472
[Epoch 89; Iter   960/  960] train: loss: 0.0111049
[Epoch 89] ogbg-molhiv: 0.726622 val loss: 0.251743
[Epoch 89] ogbg-molhiv: 0.750448 test loss: 0.201164
[Epoch 90; Iter    30/  960] train: loss: 0.0521995
[Epoch 90; Iter    60/  960] train: loss: 0.0007592
[Epoch 90; Iter    90/  960] train: loss: 0.0241424
[Epoch 90; Iter   120/  960] train: loss: 0.0943071
[Epoch 90; Iter   150/  960] train: loss: 0.0194656
[Epoch 90; Iter   180/  960] train: loss: 0.0374083
[Epoch 90; Iter   210/  960] train: loss: 0.0373177
[Epoch 90; Iter   240/  960] train: loss: 0.0017106
[Epoch 90; Iter   270/  960] train: loss: 0.0016039
[Epoch 90; Iter   300/  960] train: loss: 0.0012713
[Epoch 90; Iter   330/  960] train: loss: 0.0013246
[Epoch 90; Iter   360/  960] train: loss: 0.0505067
[Epoch 90; Iter   390/  960] train: loss: 0.0954515
[Epoch 90; Iter   420/  960] train: loss: 0.0139313
[Epoch 90; Iter   450/  960] train: loss: 0.0113156
[Epoch 90; Iter   480/  960] train: loss: 0.0136411
[Epoch 90; Iter   510/  960] train: loss: 0.0510895
[Epoch 90; Iter   540/  960] train: loss: 0.0110282
[Epoch 90; Iter   570/  960] train: loss: 0.0410140
[Epoch 90; Iter   600/  960] train: loss: 0.0179884
[Epoch 90; Iter   630/  960] train: loss: 0.0197909
[Epoch 90; Iter   660/  960] train: loss: 0.0015326
[Epoch 90; Iter   690/  960] train: loss: 0.0036167
[Epoch 90; Iter   720/  960] train: loss: 0.0038234
[Epoch 90; Iter   750/  960] train: loss: 0.0010294
[Epoch 90; Iter   780/  960] train: loss: 0.0088087
[Epoch 90; Iter   810/  960] train: loss: 0.0262126
[Epoch 90; Iter   840/  960] train: loss: 0.0045283
[Epoch 90; Iter   870/  960] train: loss: 0.0106494
[Epoch 90; Iter   900/  960] train: loss: 0.0041262
[Epoch 90; Iter   930/  960] train: loss: 0.0362029
[Epoch 90; Iter   960/  960] train: loss: 0.0131144
[Epoch 90] ogbg-molhiv: 0.717032 val loss: 0.365634
[Epoch 90] ogbg-molhiv: 0.753641 test loss: 0.277401
[Epoch 91; Iter    30/  960] train: loss: 0.0079332
[Epoch 91; Iter    60/  960] train: loss: 0.0509419
[Epoch 91; Iter    90/  960] train: loss: 0.1044232
[Epoch 91; Iter   120/  960] train: loss: 0.1326188
[Epoch 91; Iter   150/  960] train: loss: 0.0141870
[Epoch 91; Iter   180/  960] train: loss: 0.0040440
[Epoch 91; Iter   210/  960] train: loss: 0.0110932
[Epoch 91; Iter   240/  960] train: loss: 0.0147601
[Epoch 91; Iter   270/  960] train: loss: 0.0176647
[Epoch 91; Iter   300/  960] train: loss: 0.0003860
[Epoch 91; Iter   330/  960] train: loss: 0.0015168
[Epoch 91; Iter   360/  960] train: loss: 0.0163252
[Epoch 91; Iter   390/  960] train: loss: 0.0326874
[Epoch 91; Iter   420/  960] train: loss: 0.0025113
[Epoch 91; Iter   450/  960] train: loss: 0.0054078
[Epoch 91; Iter   480/  960] train: loss: 0.0167953
[Epoch 91; Iter   510/  960] train: loss: 0.0007308
[Epoch 91; Iter   540/  960] train: loss: 0.0128867
[Epoch 91; Iter   570/  960] train: loss: 0.0019817
[Epoch 91; Iter   600/  960] train: loss: 0.0085879
[Epoch 91; Iter   630/  960] train: loss: 0.0581583
[Epoch 91; Iter   660/  960] train: loss: 0.0207131
[Epoch 91; Iter   690/  960] train: loss: 0.0020854
[Epoch 91; Iter   720/  960] train: loss: 0.0403150
[Epoch 91; Iter   750/  960] train: loss: 0.0023868
[Epoch 91; Iter   780/  960] train: loss: 0.0063067
[Epoch 91; Iter   810/  960] train: loss: 0.0042227
[Epoch 91; Iter   840/  960] train: loss: 0.0121986
[Epoch 91; Iter   870/  960] train: loss: 0.0029282
[Epoch 91; Iter   900/  960] train: loss: 0.0974109
[Epoch 91; Iter   930/  960] train: loss: 0.0064325
[Epoch 91; Iter   960/  960] train: loss: 0.1178516
[Epoch 91] ogbg-molhiv: 0.720931 val loss: 0.810696
[Epoch 91] ogbg-molhiv: 0.743815 test loss: 0.503354
[Epoch 92; Iter    30/  960] train: loss: 0.0042495
[Epoch 92; Iter    60/  960] train: loss: 0.0376269
[Epoch 92; Iter    90/  960] train: loss: 0.0032187
[Epoch 90; Iter   193/  823] train: loss: 0.0044327
[Epoch 90; Iter   223/  823] train: loss: 0.0010354
[Epoch 90; Iter   253/  823] train: loss: 0.0127720
[Epoch 90; Iter   283/  823] train: loss: 0.0269429
[Epoch 90; Iter   313/  823] train: loss: 0.0070441
[Epoch 90; Iter   343/  823] train: loss: 0.0036235
[Epoch 90; Iter   373/  823] train: loss: 0.0183180
[Epoch 90; Iter   403/  823] train: loss: 0.0540418
[Epoch 90; Iter   433/  823] train: loss: 0.0253508
[Epoch 90; Iter   463/  823] train: loss: 0.0360553
[Epoch 90; Iter   493/  823] train: loss: 0.0825123
[Epoch 90; Iter   523/  823] train: loss: 0.0034953
[Epoch 90; Iter   553/  823] train: loss: 0.0143526
[Epoch 90; Iter   583/  823] train: loss: 0.0371287
[Epoch 90; Iter   613/  823] train: loss: 0.0356787
[Epoch 90; Iter   643/  823] train: loss: 0.1904278
[Epoch 90; Iter   673/  823] train: loss: 0.0300799
[Epoch 90; Iter   703/  823] train: loss: 0.0072647
[Epoch 90; Iter   733/  823] train: loss: 0.0133509
[Epoch 90; Iter   763/  823] train: loss: 0.0039963
[Epoch 90; Iter   793/  823] train: loss: 0.0044366
[Epoch 90; Iter   823/  823] train: loss: 0.1342996
[Epoch 90] ogbg-molhiv: 0.736764 val loss: 0.312729
[Epoch 90] ogbg-molhiv: 0.750130 test loss: 0.271594
[Epoch 91; Iter    30/  823] train: loss: 0.0038286
[Epoch 91; Iter    60/  823] train: loss: 0.0046773
[Epoch 91; Iter    90/  823] train: loss: 0.0012361
[Epoch 91; Iter   120/  823] train: loss: 0.0006018
[Epoch 91; Iter   150/  823] train: loss: 0.0127729
[Epoch 91; Iter   180/  823] train: loss: 0.0319690
[Epoch 91; Iter   210/  823] train: loss: 0.0055647
[Epoch 91; Iter   240/  823] train: loss: 0.0033386
[Epoch 91; Iter   270/  823] train: loss: 0.0082089
[Epoch 91; Iter   300/  823] train: loss: 0.0015111
[Epoch 91; Iter   330/  823] train: loss: 0.0338694
[Epoch 91; Iter   360/  823] train: loss: 0.0096962
[Epoch 91; Iter   390/  823] train: loss: 0.0181069
[Epoch 91; Iter   420/  823] train: loss: 0.0594219
[Epoch 91; Iter   450/  823] train: loss: 0.0236857
[Epoch 91; Iter   480/  823] train: loss: 0.0015039
[Epoch 91; Iter   510/  823] train: loss: 0.0150928
[Epoch 91; Iter   540/  823] train: loss: 0.0514168
[Epoch 91; Iter   570/  823] train: loss: 0.0008759
[Epoch 91; Iter   600/  823] train: loss: 0.0011490
[Epoch 91; Iter   630/  823] train: loss: 0.0584977
[Epoch 91; Iter   660/  823] train: loss: 0.0005690
[Epoch 91; Iter   690/  823] train: loss: 0.0222034
[Epoch 91; Iter   720/  823] train: loss: 0.0049275
[Epoch 91; Iter   750/  823] train: loss: 0.0243428
[Epoch 91; Iter   780/  823] train: loss: 0.0008409
[Epoch 91; Iter   810/  823] train: loss: 0.0023292
[Epoch 91] ogbg-molhiv: 0.736036 val loss: 0.326014
[Epoch 91] ogbg-molhiv: 0.748117 test loss: 0.279733
[Epoch 92; Iter    17/  823] train: loss: 0.0190045
[Epoch 92; Iter    47/  823] train: loss: 0.0115976
[Epoch 92; Iter    77/  823] train: loss: 0.0059449
[Epoch 92; Iter   107/  823] train: loss: 0.0191669
[Epoch 92; Iter   137/  823] train: loss: 0.0068238
[Epoch 92; Iter   167/  823] train: loss: 0.0073172
[Epoch 92; Iter   197/  823] train: loss: 0.0885394
[Epoch 92; Iter   227/  823] train: loss: 0.0009312
[Epoch 92; Iter   257/  823] train: loss: 0.0128833
[Epoch 92; Iter   287/  823] train: loss: 0.0064267
[Epoch 92; Iter   317/  823] train: loss: 0.0153375
[Epoch 92; Iter   347/  823] train: loss: 0.0007264
[Epoch 92; Iter   377/  823] train: loss: 0.0044439
[Epoch 92; Iter   407/  823] train: loss: 0.0082498
[Epoch 92; Iter   437/  823] train: loss: 0.0399223
[Epoch 92; Iter   467/  823] train: loss: 0.0008967
[Epoch 92; Iter   497/  823] train: loss: 0.0069159
[Epoch 92; Iter   527/  823] train: loss: 0.0031219
[Epoch 92; Iter   557/  823] train: loss: 0.0081763
[Epoch 92; Iter   587/  823] train: loss: 0.0626090
[Epoch 92; Iter   617/  823] train: loss: 0.0992352
[Epoch 92; Iter   647/  823] train: loss: 0.0134020
[Epoch 92; Iter   677/  823] train: loss: 0.0159094
[Epoch 92; Iter   707/  823] train: loss: 0.0043489
[Epoch 92; Iter   737/  823] train: loss: 0.1195874
[Epoch 92; Iter   767/  823] train: loss: 0.0062534
[Epoch 92; Iter   797/  823] train: loss: 0.0156799
[Epoch 92] ogbg-molhiv: 0.740604 val loss: 0.333867
[Epoch 92] ogbg-molhiv: 0.760215 test loss: 0.288878
[Epoch 93; Iter     4/  823] train: loss: 0.0181910
[Epoch 93; Iter    34/  823] train: loss: 0.0048304
[Epoch 93; Iter    64/  823] train: loss: 0.0022732
[Epoch 93; Iter    94/  823] train: loss: 0.0030600
[Epoch 93; Iter   124/  823] train: loss: 0.0010889
[Epoch 93; Iter   154/  823] train: loss: 0.0061037
[Epoch 93; Iter   184/  823] train: loss: 0.0020001
[Epoch 93; Iter   214/  823] train: loss: 0.0090590
[Epoch 93; Iter   244/  823] train: loss: 0.0200266
[Epoch 93; Iter   274/  823] train: loss: 0.0039117
[Epoch 93; Iter   304/  823] train: loss: 0.0015182
[Epoch 93; Iter   334/  823] train: loss: 0.0107444
[Epoch 93; Iter   364/  823] train: loss: 0.0163020
[Epoch 93; Iter   394/  823] train: loss: 0.0005789
[Epoch 93; Iter   424/  823] train: loss: 0.0023561
[Epoch 93; Iter   454/  823] train: loss: 0.0039680
[Epoch 93; Iter   484/  823] train: loss: 0.0037429
[Epoch 93; Iter   514/  823] train: loss: 0.0035488
[Epoch 93; Iter   544/  823] train: loss: 0.0123786
[Epoch 93; Iter   574/  823] train: loss: 0.0087110
[Epoch 93; Iter   604/  823] train: loss: 0.0012083
[Epoch 93; Iter   634/  823] train: loss: 0.0042807
[Epoch 93; Iter   664/  823] train: loss: 0.0016884
[Epoch 93; Iter   694/  823] train: loss: 0.0029970
[Epoch 93; Iter   724/  823] train: loss: 0.0024026
[Epoch 93; Iter   754/  823] train: loss: 0.0430105
[Epoch 93; Iter   784/  823] train: loss: 0.0041537
[Epoch 93; Iter   814/  823] train: loss: 0.0069584
[Epoch 93] ogbg-molhiv: 0.741722 val loss: 0.312351
[Epoch 93] ogbg-molhiv: 0.760118 test loss: 0.261558
[Epoch 94; Iter    21/  823] train: loss: 0.0026795
[Epoch 94; Iter    51/  823] train: loss: 0.0091984
[Epoch 94; Iter    81/  823] train: loss: 0.0019114
[Epoch 94; Iter   111/  823] train: loss: 0.0057790
[Epoch 94; Iter   141/  823] train: loss: 0.0032689
[Epoch 94; Iter   171/  823] train: loss: 0.0371938
[Epoch 94; Iter   201/  823] train: loss: 0.0292920
[Epoch 94; Iter   231/  823] train: loss: 0.0577481
[Epoch 94; Iter   261/  823] train: loss: 0.0068756
[Epoch 94; Iter   291/  823] train: loss: 0.1012102
[Epoch 94; Iter   321/  823] train: loss: 0.0051931
[Epoch 94; Iter   351/  823] train: loss: 0.1248376
[Epoch 94; Iter   381/  823] train: loss: 0.0238748
[Epoch 94; Iter   411/  823] train: loss: 0.0026799
[Epoch 94; Iter   441/  823] train: loss: 0.0174847
[Epoch 94; Iter   471/  823] train: loss: 0.0039728
[Epoch 94; Iter   501/  823] train: loss: 0.0021384
[Epoch 94; Iter   531/  823] train: loss: 0.1573469
[Epoch 94; Iter   561/  823] train: loss: 0.0022651
[Epoch 94; Iter   591/  823] train: loss: 0.0069774
[Epoch 94; Iter   621/  823] train: loss: 0.0289885
[Epoch 94; Iter   651/  823] train: loss: 0.0005986
[Epoch 94; Iter   681/  823] train: loss: 0.0143611
[Epoch 94; Iter   711/  823] train: loss: 0.0018949
[Epoch 94; Iter   741/  823] train: loss: 0.0573720
[Epoch 94; Iter   771/  823] train: loss: 0.0353951
[Epoch 94; Iter   801/  823] train: loss: 0.0079531
[Epoch 94] ogbg-molhiv: 0.737757 val loss: 0.329868
[Epoch 94] ogbg-molhiv: 0.749854 test loss: 0.284279
[Epoch 95; Iter     8/  823] train: loss: 0.0048308
[Epoch 95; Iter    38/  823] train: loss: 0.0306817
[Epoch 95; Iter    68/  823] train: loss: 0.0085493
[Epoch 95; Iter    98/  823] train: loss: 0.0016251
[Epoch 95; Iter   128/  823] train: loss: 0.0146364
[Epoch 95; Iter   158/  823] train: loss: 0.0050730
[Epoch 95; Iter   188/  823] train: loss: 0.0014395
[Epoch 95; Iter   218/  823] train: loss: 0.0007746
[Epoch 95; Iter   248/  823] train: loss: 0.0129506
[Epoch 95; Iter   278/  823] train: loss: 0.0681091
[Epoch 95; Iter   308/  823] train: loss: 0.0016289
[Epoch 95; Iter   338/  823] train: loss: 0.1139118
[Epoch 95; Iter   368/  823] train: loss: 0.0209978
[Epoch 95; Iter   398/  823] train: loss: 0.0043397
[Epoch 95; Iter   428/  823] train: loss: 0.0396161
[Epoch 95; Iter   458/  823] train: loss: 0.1438392
[Epoch 85; Iter   462/ 1097] train: loss: 0.0009311
[Epoch 85; Iter   492/ 1097] train: loss: 0.0078029
[Epoch 85; Iter   522/ 1097] train: loss: 0.0078296
[Epoch 85; Iter   552/ 1097] train: loss: 0.0660864
[Epoch 85; Iter   582/ 1097] train: loss: 0.0796268
[Epoch 85; Iter   612/ 1097] train: loss: 0.0315861
[Epoch 85; Iter   642/ 1097] train: loss: 0.0036973
[Epoch 85; Iter   672/ 1097] train: loss: 0.0101146
[Epoch 85; Iter   702/ 1097] train: loss: 0.0107001
[Epoch 85; Iter   732/ 1097] train: loss: 0.0376587
[Epoch 85; Iter   762/ 1097] train: loss: 0.0022236
[Epoch 85; Iter   792/ 1097] train: loss: 0.0829616
[Epoch 85; Iter   822/ 1097] train: loss: 0.0028723
[Epoch 85; Iter   852/ 1097] train: loss: 0.0022523
[Epoch 85; Iter   882/ 1097] train: loss: 0.0276272
[Epoch 85; Iter   912/ 1097] train: loss: 0.0035062
[Epoch 85; Iter   942/ 1097] train: loss: 0.0027300
[Epoch 85; Iter   972/ 1097] train: loss: 0.0010770
[Epoch 85; Iter  1002/ 1097] train: loss: 0.0713999
[Epoch 85; Iter  1032/ 1097] train: loss: 0.0129232
[Epoch 85; Iter  1062/ 1097] train: loss: 0.0786082
[Epoch 85; Iter  1092/ 1097] train: loss: 0.0142957
[Epoch 85] ogbg-molhiv: 0.801667 val loss: 0.118316
[Epoch 85] ogbg-molhiv: 0.774654 test loss: 0.214272
[Epoch 86; Iter    25/ 1097] train: loss: 0.0040720
[Epoch 86; Iter    55/ 1097] train: loss: 0.0214383
[Epoch 86; Iter    85/ 1097] train: loss: 0.0310849
[Epoch 86; Iter   115/ 1097] train: loss: 0.0043784
[Epoch 86; Iter   145/ 1097] train: loss: 0.0034441
[Epoch 86; Iter   175/ 1097] train: loss: 0.0243083
[Epoch 86; Iter   205/ 1097] train: loss: 0.0525216
[Epoch 86; Iter   235/ 1097] train: loss: 0.0234759
[Epoch 86; Iter   265/ 1097] train: loss: 0.0701971
[Epoch 86; Iter   295/ 1097] train: loss: 0.0015969
[Epoch 86; Iter   325/ 1097] train: loss: 0.0146058
[Epoch 86; Iter   355/ 1097] train: loss: 0.0019034
[Epoch 86; Iter   385/ 1097] train: loss: 0.0045281
[Epoch 86; Iter   415/ 1097] train: loss: 0.0906217
[Epoch 86; Iter   445/ 1097] train: loss: 0.0031215
[Epoch 86; Iter   475/ 1097] train: loss: 0.0059652
[Epoch 86; Iter   505/ 1097] train: loss: 0.0057439
[Epoch 86; Iter   535/ 1097] train: loss: 0.0142499
[Epoch 86; Iter   565/ 1097] train: loss: 0.0154445
[Epoch 86; Iter   595/ 1097] train: loss: 0.0305900
[Epoch 86; Iter   625/ 1097] train: loss: 0.0143656
[Epoch 86; Iter   655/ 1097] train: loss: 0.0083799
[Epoch 86; Iter   685/ 1097] train: loss: 0.0450536
[Epoch 86; Iter   715/ 1097] train: loss: 0.0895960
[Epoch 86; Iter   745/ 1097] train: loss: 0.1730947
[Epoch 86; Iter   775/ 1097] train: loss: 0.0559493
[Epoch 86; Iter   805/ 1097] train: loss: 0.0190049
[Epoch 86; Iter   835/ 1097] train: loss: 0.0045811
[Epoch 86; Iter   865/ 1097] train: loss: 0.0190972
[Epoch 86; Iter   895/ 1097] train: loss: 0.0049987
[Epoch 86; Iter   925/ 1097] train: loss: 0.0473089
[Epoch 86; Iter   955/ 1097] train: loss: 0.0635090
[Epoch 86; Iter   985/ 1097] train: loss: 0.1084422
[Epoch 86; Iter  1015/ 1097] train: loss: 0.0196928
[Epoch 86; Iter  1045/ 1097] train: loss: 0.0007645
[Epoch 86; Iter  1075/ 1097] train: loss: 0.0014755
[Epoch 86] ogbg-molhiv: 0.798841 val loss: 0.120052
[Epoch 86] ogbg-molhiv: 0.771237 test loss: 0.215055
[Epoch 87; Iter     8/ 1097] train: loss: 0.0091030
[Epoch 87; Iter    38/ 1097] train: loss: 0.0028672
[Epoch 87; Iter    68/ 1097] train: loss: 0.0014557
[Epoch 87; Iter    98/ 1097] train: loss: 0.0026447
[Epoch 87; Iter   128/ 1097] train: loss: 0.0410080
[Epoch 87; Iter   158/ 1097] train: loss: 0.0014390
[Epoch 87; Iter   188/ 1097] train: loss: 0.0065958
[Epoch 87; Iter   218/ 1097] train: loss: 0.0105304
[Epoch 87; Iter   248/ 1097] train: loss: 0.0103966
[Epoch 87; Iter   278/ 1097] train: loss: 0.0242963
[Epoch 87; Iter   308/ 1097] train: loss: 0.0044146
[Epoch 87; Iter   338/ 1097] train: loss: 0.0242642
[Epoch 87; Iter   368/ 1097] train: loss: 0.0023347
[Epoch 87; Iter   398/ 1097] train: loss: 0.0224221
[Epoch 87; Iter   428/ 1097] train: loss: 0.0046416
[Epoch 87; Iter   458/ 1097] train: loss: 0.0089493
[Epoch 87; Iter   488/ 1097] train: loss: 0.0070905
[Epoch 87; Iter   518/ 1097] train: loss: 0.0010822
[Epoch 87; Iter   548/ 1097] train: loss: 0.0595645
[Epoch 87; Iter   578/ 1097] train: loss: 0.0058128
[Epoch 87; Iter   608/ 1097] train: loss: 0.0271142
[Epoch 87; Iter   638/ 1097] train: loss: 0.0123704
[Epoch 87; Iter   668/ 1097] train: loss: 0.0013693
[Epoch 87; Iter   698/ 1097] train: loss: 0.0136113
[Epoch 87; Iter   728/ 1097] train: loss: 0.0032948
[Epoch 87; Iter   758/ 1097] train: loss: 0.0017204
[Epoch 87; Iter   788/ 1097] train: loss: 0.0012840
[Epoch 87; Iter   818/ 1097] train: loss: 0.0356689
[Epoch 87; Iter   848/ 1097] train: loss: 0.0066252
[Epoch 87; Iter   878/ 1097] train: loss: 0.0003767
[Epoch 87; Iter   908/ 1097] train: loss: 0.0762109
[Epoch 87; Iter   938/ 1097] train: loss: 0.0134364
[Epoch 87; Iter   968/ 1097] train: loss: 0.0012822
[Epoch 87; Iter   998/ 1097] train: loss: 0.0097734
[Epoch 87; Iter  1028/ 1097] train: loss: 0.0070229
[Epoch 87; Iter  1058/ 1097] train: loss: 0.0044698
[Epoch 87; Iter  1088/ 1097] train: loss: 0.0988024
[Epoch 87] ogbg-molhiv: 0.805516 val loss: 0.120253
[Epoch 87] ogbg-molhiv: 0.771684 test loss: 0.217850
[Epoch 88; Iter    21/ 1097] train: loss: 0.0032687
[Epoch 88; Iter    51/ 1097] train: loss: 0.1182274
[Epoch 88; Iter    81/ 1097] train: loss: 0.0065004
[Epoch 88; Iter   111/ 1097] train: loss: 0.0033843
[Epoch 88; Iter   141/ 1097] train: loss: 0.0054117
[Epoch 88; Iter   171/ 1097] train: loss: 0.0297204
[Epoch 88; Iter   201/ 1097] train: loss: 0.0082683
[Epoch 88; Iter   231/ 1097] train: loss: 0.0219417
[Epoch 88; Iter   261/ 1097] train: loss: 0.0119688
[Epoch 88; Iter   291/ 1097] train: loss: 0.0509208
[Epoch 88; Iter   321/ 1097] train: loss: 0.0678799
[Epoch 88; Iter   351/ 1097] train: loss: 0.0608388
[Epoch 88; Iter   381/ 1097] train: loss: 0.0409388
[Epoch 88; Iter   411/ 1097] train: loss: 0.0041114
[Epoch 88; Iter   441/ 1097] train: loss: 0.0009324
[Epoch 88; Iter   471/ 1097] train: loss: 0.0012821
[Epoch 88; Iter   501/ 1097] train: loss: 0.0284325
[Epoch 88; Iter   531/ 1097] train: loss: 0.0012583
[Epoch 88; Iter   561/ 1097] train: loss: 0.0066262
[Epoch 88; Iter   591/ 1097] train: loss: 0.0027270
[Epoch 88; Iter   621/ 1097] train: loss: 0.0091766
[Epoch 88; Iter   651/ 1097] train: loss: 0.1078835
[Epoch 88; Iter   681/ 1097] train: loss: 0.0059272
[Epoch 88; Iter   711/ 1097] train: loss: 0.0030871
[Epoch 88; Iter   741/ 1097] train: loss: 0.0029652
[Epoch 88; Iter   771/ 1097] train: loss: 0.0033057
[Epoch 88; Iter   801/ 1097] train: loss: 0.0406548
[Epoch 88; Iter   831/ 1097] train: loss: 0.0005147
[Epoch 88; Iter   861/ 1097] train: loss: 0.0220244
[Epoch 88; Iter   891/ 1097] train: loss: 0.0090364
[Epoch 88; Iter   921/ 1097] train: loss: 0.0435827
[Epoch 88; Iter   951/ 1097] train: loss: 0.0210552
[Epoch 88; Iter   981/ 1097] train: loss: 0.0019146
[Epoch 88; Iter  1011/ 1097] train: loss: 0.0022590
[Epoch 88; Iter  1041/ 1097] train: loss: 0.0369091
[Epoch 88; Iter  1071/ 1097] train: loss: 0.0266731
[Epoch 88] ogbg-molhiv: 0.798740 val loss: 0.120994
[Epoch 88] ogbg-molhiv: 0.758732 test loss: 0.223053
[Epoch 89; Iter     4/ 1097] train: loss: 0.0189007
[Epoch 89; Iter    34/ 1097] train: loss: 0.0003797
[Epoch 89; Iter    64/ 1097] train: loss: 0.0037865
[Epoch 89; Iter    94/ 1097] train: loss: 0.0061087
[Epoch 89; Iter   124/ 1097] train: loss: 0.0018944
[Epoch 89; Iter   154/ 1097] train: loss: 0.0714190
[Epoch 89; Iter   184/ 1097] train: loss: 0.0139504
[Epoch 89; Iter   214/ 1097] train: loss: 0.0194848
[Epoch 89; Iter   244/ 1097] train: loss: 0.0729765
[Epoch 89; Iter   274/ 1097] train: loss: 0.0116815
[Epoch 89; Iter   304/ 1097] train: loss: 0.0011204
[Epoch 89; Iter   334/ 1097] train: loss: 0.0096953
[Epoch 89; Iter   364/ 1097] train: loss: 0.0041784
[Epoch 89; Iter   394/ 1097] train: loss: 0.0150935
[Epoch 89; Iter   424/ 1097] train: loss: 0.0003041
[Epoch 89; Iter   454/ 1097] train: loss: 0.0095158
[Epoch 89; Iter   484/ 1097] train: loss: 0.0087419
[Epoch 89; Iter   514/ 1097] train: loss: 0.0592124
[Epoch 95; Iter   488/  823] train: loss: 0.0293180
[Epoch 95; Iter   518/  823] train: loss: 0.0212957
[Epoch 95; Iter   548/  823] train: loss: 0.1037449
[Epoch 95; Iter   578/  823] train: loss: 0.0283952
[Epoch 95; Iter   608/  823] train: loss: 0.0522121
[Epoch 95; Iter   638/  823] train: loss: 0.0024506
[Epoch 95; Iter   668/  823] train: loss: 0.0042570
[Epoch 95; Iter   698/  823] train: loss: 0.0037376
[Epoch 95; Iter   728/  823] train: loss: 0.0158351
[Epoch 95; Iter   758/  823] train: loss: 0.0045176
[Epoch 95; Iter   788/  823] train: loss: 0.1523641
[Epoch 95; Iter   818/  823] train: loss: 0.0298419
[Epoch 95] ogbg-molhiv: 0.744066 val loss: 0.245377
[Epoch 95] ogbg-molhiv: 0.750821 test loss: 0.310865
[Epoch 96; Iter    25/  823] train: loss: 0.1569350
[Epoch 96; Iter    55/  823] train: loss: 0.0245519
[Epoch 96; Iter    85/  823] train: loss: 0.0371839
[Epoch 96; Iter   115/  823] train: loss: 0.0080927
[Epoch 96; Iter   145/  823] train: loss: 0.0086298
[Epoch 96; Iter   175/  823] train: loss: 0.0025844
[Epoch 96; Iter   205/  823] train: loss: 0.1056540
[Epoch 96; Iter   235/  823] train: loss: 0.0113693
[Epoch 96; Iter   265/  823] train: loss: 0.0263612
[Epoch 96; Iter   295/  823] train: loss: 0.0186043
[Epoch 96; Iter   325/  823] train: loss: 0.0075441
[Epoch 96; Iter   355/  823] train: loss: 0.0287455
[Epoch 96; Iter   385/  823] train: loss: 0.0057696
[Epoch 96; Iter   415/  823] train: loss: 0.0459124
[Epoch 96; Iter   445/  823] train: loss: 0.0053370
[Epoch 96; Iter   475/  823] train: loss: 0.0032500
[Epoch 96; Iter   505/  823] train: loss: 0.0028825
[Epoch 96; Iter   535/  823] train: loss: 0.0951645
[Epoch 96; Iter   565/  823] train: loss: 0.0051288
[Epoch 96; Iter   595/  823] train: loss: 0.0016203
[Epoch 96; Iter   625/  823] train: loss: 0.0055258
[Epoch 96; Iter   655/  823] train: loss: 0.0242225
[Epoch 96; Iter   685/  823] train: loss: 0.0445005
[Epoch 96; Iter   715/  823] train: loss: 0.0125997
[Epoch 96; Iter   745/  823] train: loss: 0.0516557
[Epoch 96; Iter   775/  823] train: loss: 0.0031930
[Epoch 96; Iter   805/  823] train: loss: 0.0049644
[Epoch 96] ogbg-molhiv: 0.741985 val loss: 0.252462
[Epoch 96] ogbg-molhiv: 0.750814 test loss: 0.316108
[Epoch 97; Iter    12/  823] train: loss: 0.0280358
[Epoch 97; Iter    42/  823] train: loss: 0.0086549
[Epoch 97; Iter    72/  823] train: loss: 0.0797555
[Epoch 97; Iter   102/  823] train: loss: 0.0036106
[Epoch 97; Iter   132/  823] train: loss: 0.0109737
[Epoch 97; Iter   162/  823] train: loss: 0.0221178
[Epoch 97; Iter   192/  823] train: loss: 0.0066130
[Epoch 97; Iter   222/  823] train: loss: 0.0002119
[Epoch 97; Iter   252/  823] train: loss: 0.0136112
[Epoch 97; Iter   282/  823] train: loss: 0.0037871
[Epoch 97; Iter   312/  823] train: loss: 0.0329723
[Epoch 97; Iter   342/  823] train: loss: 0.0208480
[Epoch 97; Iter   372/  823] train: loss: 0.0090251
[Epoch 97; Iter   402/  823] train: loss: 0.0107820
[Epoch 97; Iter   432/  823] train: loss: 0.0272166
[Epoch 97; Iter   462/  823] train: loss: 0.0780575
[Epoch 97; Iter   492/  823] train: loss: 0.0164294
[Epoch 97; Iter   522/  823] train: loss: 0.0121897
[Epoch 97; Iter   552/  823] train: loss: 0.0099431
[Epoch 97; Iter   582/  823] train: loss: 0.0058708
[Epoch 97; Iter   612/  823] train: loss: 0.0015739
[Epoch 97; Iter   642/  823] train: loss: 0.0013033
[Epoch 97; Iter   672/  823] train: loss: 0.0089771
[Epoch 97; Iter   702/  823] train: loss: 0.0253830
[Epoch 97; Iter   732/  823] train: loss: 0.0056246
[Epoch 97; Iter   762/  823] train: loss: 0.0023053
[Epoch 97; Iter   792/  823] train: loss: 0.0300302
[Epoch 97; Iter   822/  823] train: loss: 0.0498722
[Epoch 97] ogbg-molhiv: 0.737825 val loss: 0.249931
[Epoch 97] ogbg-molhiv: 0.747974 test loss: 0.216130
[Epoch 98; Iter    29/  823] train: loss: 0.0038229
[Epoch 98; Iter    59/  823] train: loss: 0.0214387
[Epoch 98; Iter    89/  823] train: loss: 0.0636162
[Epoch 98; Iter   119/  823] train: loss: 0.0047570
[Epoch 98; Iter   149/  823] train: loss: 0.0062566
[Epoch 98; Iter   179/  823] train: loss: 0.0059262
[Epoch 98; Iter   209/  823] train: loss: 0.0058149
[Epoch 98; Iter   239/  823] train: loss: 0.0062341
[Epoch 98; Iter   269/  823] train: loss: 0.0349157
[Epoch 98; Iter   299/  823] train: loss: 0.0027963
[Epoch 98; Iter   329/  823] train: loss: 0.0044946
[Epoch 98; Iter   359/  823] train: loss: 0.0409755
[Epoch 98; Iter   389/  823] train: loss: 0.0982699
[Epoch 98; Iter   419/  823] train: loss: 0.0079405
[Epoch 98; Iter   449/  823] train: loss: 0.0106102
[Epoch 98; Iter   479/  823] train: loss: 0.0557354
[Epoch 98; Iter   509/  823] train: loss: 0.0269188
[Epoch 98; Iter   539/  823] train: loss: 0.0027878
[Epoch 98; Iter   569/  823] train: loss: 0.0996708
[Epoch 98; Iter   599/  823] train: loss: 0.0236795
[Epoch 98; Iter   629/  823] train: loss: 0.0029515
[Epoch 98; Iter   659/  823] train: loss: 0.1244270
[Epoch 98; Iter   689/  823] train: loss: 0.0009333
[Epoch 98; Iter   719/  823] train: loss: 0.1101063
[Epoch 98; Iter   749/  823] train: loss: 0.0053485
[Epoch 98; Iter   779/  823] train: loss: 0.0205693
[Epoch 98; Iter   809/  823] train: loss: 0.0172307
[Epoch 98] ogbg-molhiv: 0.742390 val loss: 0.685589
[Epoch 98] ogbg-molhiv: 0.753772 test loss: 2.210282
[Epoch 99; Iter    16/  823] train: loss: 0.0009579
[Epoch 99; Iter    46/  823] train: loss: 0.0066028
[Epoch 99; Iter    76/  823] train: loss: 0.0085504
[Epoch 99; Iter   106/  823] train: loss: 0.0096708
[Epoch 99; Iter   136/  823] train: loss: 0.0279906
[Epoch 99; Iter   166/  823] train: loss: 0.0063528
[Epoch 99; Iter   196/  823] train: loss: 0.0078185
[Epoch 99; Iter   226/  823] train: loss: 0.1485728
[Epoch 99; Iter   256/  823] train: loss: 0.0167899
[Epoch 99; Iter   286/  823] train: loss: 0.0097358
[Epoch 99; Iter   316/  823] train: loss: 0.0673608
[Epoch 99; Iter   346/  823] train: loss: 0.0044898
[Epoch 99; Iter   376/  823] train: loss: 0.0028869
[Epoch 99; Iter   406/  823] train: loss: 0.0941349
[Epoch 99; Iter   436/  823] train: loss: 0.1266820
[Epoch 99; Iter   466/  823] train: loss: 0.0034032
[Epoch 99; Iter   496/  823] train: loss: 0.0569879
[Epoch 99; Iter   526/  823] train: loss: 0.1758749
[Epoch 99; Iter   556/  823] train: loss: 0.1563052
[Epoch 99; Iter   586/  823] train: loss: 0.0304536
[Epoch 99; Iter   616/  823] train: loss: 0.0059528
[Epoch 99; Iter   646/  823] train: loss: 0.0563038
[Epoch 99; Iter   676/  823] train: loss: 0.0093944
[Epoch 99; Iter   706/  823] train: loss: 0.0131004
[Epoch 99; Iter   736/  823] train: loss: 0.0006444
[Epoch 99; Iter   766/  823] train: loss: 0.0367658
[Epoch 99; Iter   796/  823] train: loss: 0.0011360
[Epoch 99] ogbg-molhiv: 0.744040 val loss: 0.253363
[Epoch 99] ogbg-molhiv: 0.752292 test loss: 0.322514
[Epoch 100; Iter     3/  823] train: loss: 0.0828473
[Epoch 100; Iter    33/  823] train: loss: 0.0024979
[Epoch 100; Iter    63/  823] train: loss: 0.0235425
[Epoch 100; Iter    93/  823] train: loss: 0.0027756
[Epoch 100; Iter   123/  823] train: loss: 0.0055662
[Epoch 100; Iter   153/  823] train: loss: 0.0066447
[Epoch 100; Iter   183/  823] train: loss: 0.0606805
[Epoch 100; Iter   213/  823] train: loss: 0.0137180
[Epoch 100; Iter   243/  823] train: loss: 0.0013066
[Epoch 100; Iter   273/  823] train: loss: 0.0012629
[Epoch 100; Iter   303/  823] train: loss: 0.0027196
[Epoch 100; Iter   333/  823] train: loss: 0.0264211
[Epoch 100; Iter   363/  823] train: loss: 0.0142301
[Epoch 100; Iter   393/  823] train: loss: 0.0051379
[Epoch 100; Iter   423/  823] train: loss: 0.0124773
[Epoch 100; Iter   453/  823] train: loss: 0.0064999
[Epoch 100; Iter   483/  823] train: loss: 0.0418087
[Epoch 100; Iter   513/  823] train: loss: 0.1050401
[Epoch 100; Iter   543/  823] train: loss: 0.1637513
[Epoch 100; Iter   573/  823] train: loss: 0.0009907
[Epoch 100; Iter   603/  823] train: loss: 0.0278775
[Epoch 100; Iter   633/  823] train: loss: 0.0040935
[Epoch 100; Iter   663/  823] train: loss: 0.0631083
[Epoch 100; Iter   693/  823] train: loss: 0.0081406
[Epoch 100; Iter   723/  823] train: loss: 0.0384692
[Epoch 89; Iter   544/ 1097] train: loss: 0.0015503
[Epoch 89; Iter   574/ 1097] train: loss: 0.0025896
[Epoch 89; Iter   604/ 1097] train: loss: 0.0176400
[Epoch 89; Iter   634/ 1097] train: loss: 0.0027099
[Epoch 89; Iter   664/ 1097] train: loss: 0.0700229
[Epoch 89; Iter   694/ 1097] train: loss: 0.0012630
[Epoch 89; Iter   724/ 1097] train: loss: 0.0075336
[Epoch 89; Iter   754/ 1097] train: loss: 0.0100773
[Epoch 89; Iter   784/ 1097] train: loss: 0.0398733
[Epoch 89; Iter   814/ 1097] train: loss: 0.0504645
[Epoch 89; Iter   844/ 1097] train: loss: 0.0044944
[Epoch 89; Iter   874/ 1097] train: loss: 0.0127677
[Epoch 89; Iter   904/ 1097] train: loss: 0.0340044
[Epoch 89; Iter   934/ 1097] train: loss: 0.0178725
[Epoch 89; Iter   964/ 1097] train: loss: 0.0317667
[Epoch 89; Iter   994/ 1097] train: loss: 0.0248742
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0085723
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0209581
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0264635
[Epoch 89] ogbg-molhiv: 0.758956 val loss: 0.419415
[Epoch 89] ogbg-molhiv: 0.732519 test loss: 1.426515
[Epoch 90; Iter    17/ 1097] train: loss: 0.0073248
[Epoch 90; Iter    47/ 1097] train: loss: 0.0557101
[Epoch 90; Iter    77/ 1097] train: loss: 0.0362797
[Epoch 90; Iter   107/ 1097] train: loss: 0.0469524
[Epoch 90; Iter   137/ 1097] train: loss: 0.0022045
[Epoch 90; Iter   167/ 1097] train: loss: 0.1612996
[Epoch 90; Iter   197/ 1097] train: loss: 0.0080122
[Epoch 90; Iter   227/ 1097] train: loss: 0.0042498
[Epoch 90; Iter   257/ 1097] train: loss: 0.0013840
[Epoch 90; Iter   287/ 1097] train: loss: 0.0135980
[Epoch 90; Iter   317/ 1097] train: loss: 0.0029036
[Epoch 90; Iter   347/ 1097] train: loss: 0.0153506
[Epoch 90; Iter   377/ 1097] train: loss: 0.0014505
[Epoch 90; Iter   407/ 1097] train: loss: 0.0450504
[Epoch 90; Iter   437/ 1097] train: loss: 0.0027312
[Epoch 90; Iter   467/ 1097] train: loss: 0.0131059
[Epoch 90; Iter   497/ 1097] train: loss: 0.0838525
[Epoch 90; Iter   527/ 1097] train: loss: 0.0196445
[Epoch 90; Iter   557/ 1097] train: loss: 0.0492525
[Epoch 90; Iter   587/ 1097] train: loss: 0.0081169
[Epoch 90; Iter   617/ 1097] train: loss: 0.0025456
[Epoch 90; Iter   647/ 1097] train: loss: 0.0006608
[Epoch 90; Iter   677/ 1097] train: loss: 0.0042586
[Epoch 90; Iter   707/ 1097] train: loss: 0.0025439
[Epoch 90; Iter   737/ 1097] train: loss: 0.0028385
[Epoch 90; Iter   767/ 1097] train: loss: 0.0799233
[Epoch 90; Iter   797/ 1097] train: loss: 0.0043504
[Epoch 90; Iter   827/ 1097] train: loss: 0.0087494
[Epoch 90; Iter   857/ 1097] train: loss: 0.0035203
[Epoch 90; Iter   887/ 1097] train: loss: 0.0374836
[Epoch 90; Iter   917/ 1097] train: loss: 0.0078076
[Epoch 90; Iter   947/ 1097] train: loss: 0.0016782
[Epoch 90; Iter   977/ 1097] train: loss: 0.0180353
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0041305
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0873680
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0029220
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0038818
[Epoch 90] ogbg-molhiv: 0.765700 val loss: 0.579257
[Epoch 90] ogbg-molhiv: 0.738564 test loss: 1.234195
[Epoch 91; Iter    30/ 1097] train: loss: 0.0072410
[Epoch 91; Iter    60/ 1097] train: loss: 0.0533929
[Epoch 91; Iter    90/ 1097] train: loss: 0.0068926
[Epoch 91; Iter   120/ 1097] train: loss: 0.0119559
[Epoch 91; Iter   150/ 1097] train: loss: 0.0058575
[Epoch 91; Iter   180/ 1097] train: loss: 0.0372248
[Epoch 91; Iter   210/ 1097] train: loss: 0.0028173
[Epoch 91; Iter   240/ 1097] train: loss: 0.0245895
[Epoch 91; Iter   270/ 1097] train: loss: 0.0190552
[Epoch 91; Iter   300/ 1097] train: loss: 0.0113257
[Epoch 91; Iter   330/ 1097] train: loss: 0.0105674
[Epoch 91; Iter   360/ 1097] train: loss: 0.0056619
[Epoch 91; Iter   390/ 1097] train: loss: 0.0254452
[Epoch 91; Iter   420/ 1097] train: loss: 0.0115452
[Epoch 91; Iter   450/ 1097] train: loss: 0.0028622
[Epoch 91; Iter   480/ 1097] train: loss: 0.0053630
[Epoch 91; Iter   510/ 1097] train: loss: 0.0068111
[Epoch 91; Iter   540/ 1097] train: loss: 0.0186505
[Epoch 91; Iter   570/ 1097] train: loss: 0.0216013
[Epoch 91; Iter   600/ 1097] train: loss: 0.0250947
[Epoch 91; Iter   630/ 1097] train: loss: 0.0184607
[Epoch 91; Iter   660/ 1097] train: loss: 0.0470464
[Epoch 91; Iter   690/ 1097] train: loss: 0.0440332
[Epoch 91; Iter   720/ 1097] train: loss: 0.0212093
[Epoch 91; Iter   750/ 1097] train: loss: 0.0049728
[Epoch 91; Iter   780/ 1097] train: loss: 0.0052551
[Epoch 91; Iter   810/ 1097] train: loss: 0.0199758
[Epoch 91; Iter   840/ 1097] train: loss: 0.0126701
[Epoch 91; Iter   870/ 1097] train: loss: 0.0094715
[Epoch 91; Iter   900/ 1097] train: loss: 0.0012242
[Epoch 91; Iter   930/ 1097] train: loss: 0.0030369
[Epoch 91; Iter   960/ 1097] train: loss: 0.0072148
[Epoch 91; Iter   990/ 1097] train: loss: 0.0158764
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0074451
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0198734
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0051902
[Epoch 91] ogbg-molhiv: 0.751258 val loss: 0.488450
[Epoch 91] ogbg-molhiv: 0.733604 test loss: 1.208331
[Epoch 92; Iter    13/ 1097] train: loss: 0.0069839
[Epoch 92; Iter    43/ 1097] train: loss: 0.0037503
[Epoch 92; Iter    73/ 1097] train: loss: 0.0190837
[Epoch 92; Iter   103/ 1097] train: loss: 0.0108966
[Epoch 92; Iter   133/ 1097] train: loss: 0.0256999
[Epoch 92; Iter   163/ 1097] train: loss: 0.0106523
[Epoch 92; Iter   193/ 1097] train: loss: 0.0295658
[Epoch 92; Iter   223/ 1097] train: loss: 0.0100181
[Epoch 92; Iter   253/ 1097] train: loss: 0.0014520
[Epoch 92; Iter   283/ 1097] train: loss: 0.0113946
[Epoch 92; Iter   313/ 1097] train: loss: 0.0406814
[Epoch 92; Iter   343/ 1097] train: loss: 0.0072632
[Epoch 92; Iter   373/ 1097] train: loss: 0.0184695
[Epoch 92; Iter   403/ 1097] train: loss: 0.0117147
[Epoch 92; Iter   433/ 1097] train: loss: 0.0133674
[Epoch 92; Iter   463/ 1097] train: loss: 0.0253690
[Epoch 92; Iter   493/ 1097] train: loss: 0.0060806
[Epoch 92; Iter   523/ 1097] train: loss: 0.0332342
[Epoch 92; Iter   553/ 1097] train: loss: 0.0142134
[Epoch 92; Iter   583/ 1097] train: loss: 0.0055345
[Epoch 92; Iter   613/ 1097] train: loss: 0.0030604
[Epoch 92; Iter   643/ 1097] train: loss: 0.0031801
[Epoch 92; Iter   673/ 1097] train: loss: 0.0011622
[Epoch 92; Iter   703/ 1097] train: loss: 0.2088603
[Epoch 92; Iter   733/ 1097] train: loss: 0.0024467
[Epoch 92; Iter   763/ 1097] train: loss: 0.0773118
[Epoch 92; Iter   793/ 1097] train: loss: 0.0117973
[Epoch 92; Iter   823/ 1097] train: loss: 0.0159474
[Epoch 92; Iter   853/ 1097] train: loss: 0.0044145
[Epoch 92; Iter   883/ 1097] train: loss: 0.0017884
[Epoch 92; Iter   913/ 1097] train: loss: 0.0016828
[Epoch 92; Iter   943/ 1097] train: loss: 0.0237398
[Epoch 92; Iter   973/ 1097] train: loss: 0.0076700
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0086703
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0117197
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0044869
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0482058
[Epoch 92] ogbg-molhiv: 0.759930 val loss: 0.175614
[Epoch 92] ogbg-molhiv: 0.737085 test loss: 0.338441
[Epoch 93; Iter    26/ 1097] train: loss: 0.0217343
[Epoch 93; Iter    56/ 1097] train: loss: 0.0043238
[Epoch 93; Iter    86/ 1097] train: loss: 0.0192681
[Epoch 93; Iter   116/ 1097] train: loss: 0.0031419
[Epoch 93; Iter   146/ 1097] train: loss: 0.0265151
[Epoch 93; Iter   176/ 1097] train: loss: 0.0504364
[Epoch 93; Iter   206/ 1097] train: loss: 0.0650222
[Epoch 93; Iter   236/ 1097] train: loss: 0.0200008
[Epoch 93; Iter   266/ 1097] train: loss: 0.0026681
[Epoch 93; Iter   296/ 1097] train: loss: 0.0006382
[Epoch 93; Iter   326/ 1097] train: loss: 0.0052906
[Epoch 93; Iter   356/ 1097] train: loss: 0.0032167
[Epoch 93; Iter   386/ 1097] train: loss: 0.0085445
[Epoch 93; Iter   416/ 1097] train: loss: 0.0016232
[Epoch 93; Iter   446/ 1097] train: loss: 0.0301052
[Epoch 93; Iter   476/ 1097] train: loss: 0.0053976
[Epoch 93; Iter   506/ 1097] train: loss: 0.0252282
[Epoch 93; Iter   536/ 1097] train: loss: 0.0082218
[Epoch 93; Iter   566/ 1097] train: loss: 0.1131469
[Epoch 93; Iter   596/ 1097] train: loss: 0.0167827
[Epoch 92; Iter   120/  960] train: loss: 0.0090553
[Epoch 92; Iter   150/  960] train: loss: 0.0027212
[Epoch 92; Iter   180/  960] train: loss: 0.2382632
[Epoch 92; Iter   210/  960] train: loss: 0.0103556
[Epoch 92; Iter   240/  960] train: loss: 0.2532902
[Epoch 92; Iter   270/  960] train: loss: 0.0021769
[Epoch 92; Iter   300/  960] train: loss: 0.0020197
[Epoch 92; Iter   330/  960] train: loss: 0.0074712
[Epoch 92; Iter   360/  960] train: loss: 0.0046547
[Epoch 92; Iter   390/  960] train: loss: 0.0167742
[Epoch 92; Iter   420/  960] train: loss: 0.0391374
[Epoch 92; Iter   450/  960] train: loss: 0.0235828
[Epoch 92; Iter   480/  960] train: loss: 0.0031476
[Epoch 92; Iter   510/  960] train: loss: 0.0031123
[Epoch 92; Iter   540/  960] train: loss: 0.0247933
[Epoch 92; Iter   570/  960] train: loss: 0.0018162
[Epoch 92; Iter   600/  960] train: loss: 0.0024996
[Epoch 92; Iter   630/  960] train: loss: 0.0126026
[Epoch 92; Iter   660/  960] train: loss: 0.0842299
[Epoch 92; Iter   690/  960] train: loss: 0.0153399
[Epoch 92; Iter   720/  960] train: loss: 0.0012515
[Epoch 92; Iter   750/  960] train: loss: 0.0012570
[Epoch 92; Iter   780/  960] train: loss: 0.0109536
[Epoch 92; Iter   810/  960] train: loss: 0.0055226
[Epoch 92; Iter   840/  960] train: loss: 0.0598739
[Epoch 92; Iter   870/  960] train: loss: 0.0027439
[Epoch 92; Iter   900/  960] train: loss: 0.0051488
[Epoch 92; Iter   930/  960] train: loss: 0.0053330
[Epoch 92; Iter   960/  960] train: loss: 0.0045115
[Epoch 92] ogbg-molhiv: 0.720762 val loss: 0.263829
[Epoch 92] ogbg-molhiv: 0.760628 test loss: 0.218128
[Epoch 93; Iter    30/  960] train: loss: 0.0037365
[Epoch 93; Iter    60/  960] train: loss: 0.0080052
[Epoch 93; Iter    90/  960] train: loss: 0.0265286
[Epoch 93; Iter   120/  960] train: loss: 0.0054893
[Epoch 93; Iter   150/  960] train: loss: 0.0294784
[Epoch 93; Iter   180/  960] train: loss: 0.0363590
[Epoch 93; Iter   210/  960] train: loss: 0.0251370
[Epoch 93; Iter   240/  960] train: loss: 0.0016335
[Epoch 93; Iter   270/  960] train: loss: 0.0019058
[Epoch 93; Iter   300/  960] train: loss: 0.0121297
[Epoch 93; Iter   330/  960] train: loss: 0.0096757
[Epoch 93; Iter   360/  960] train: loss: 0.0023858
[Epoch 93; Iter   390/  960] train: loss: 0.0950326
[Epoch 93; Iter   420/  960] train: loss: 0.0013524
[Epoch 93; Iter   450/  960] train: loss: 0.0130995
[Epoch 93; Iter   480/  960] train: loss: 0.0068720
[Epoch 93; Iter   510/  960] train: loss: 0.0140623
[Epoch 93; Iter   540/  960] train: loss: 0.0030216
[Epoch 93; Iter   570/  960] train: loss: 0.0206329
[Epoch 93; Iter   600/  960] train: loss: 0.0530148
[Epoch 93; Iter   630/  960] train: loss: 0.0035908
[Epoch 93; Iter   660/  960] train: loss: 0.0179827
[Epoch 93; Iter   690/  960] train: loss: 0.0214033
[Epoch 93; Iter   720/  960] train: loss: 0.0822688
[Epoch 93; Iter   750/  960] train: loss: 0.0012770
[Epoch 93; Iter   780/  960] train: loss: 0.1046607
[Epoch 93; Iter   810/  960] train: loss: 0.0028475
[Epoch 93; Iter   840/  960] train: loss: 0.0198731
[Epoch 93; Iter   870/  960] train: loss: 0.0090164
[Epoch 93; Iter   900/  960] train: loss: 0.0194862
[Epoch 93; Iter   930/  960] train: loss: 0.0013451
[Epoch 93; Iter   960/  960] train: loss: 0.0266383
[Epoch 93] ogbg-molhiv: 0.709596 val loss: 0.502854
[Epoch 93] ogbg-molhiv: 0.764687 test loss: 0.600504
[Epoch 94; Iter    30/  960] train: loss: 0.0170657
[Epoch 94; Iter    60/  960] train: loss: 0.0660420
[Epoch 94; Iter    90/  960] train: loss: 0.0074137
[Epoch 94; Iter   120/  960] train: loss: 0.0014787
[Epoch 94; Iter   150/  960] train: loss: 0.0164391
[Epoch 94; Iter   180/  960] train: loss: 0.0031552
[Epoch 94; Iter   210/  960] train: loss: 0.0381794
[Epoch 94; Iter   240/  960] train: loss: 0.0070116
[Epoch 94; Iter   270/  960] train: loss: 0.0106642
[Epoch 94; Iter   300/  960] train: loss: 0.0047981
[Epoch 94; Iter   330/  960] train: loss: 0.0010145
[Epoch 94; Iter   360/  960] train: loss: 0.0025008
[Epoch 94; Iter   390/  960] train: loss: 0.0140318
[Epoch 94; Iter   420/  960] train: loss: 0.0014777
[Epoch 94; Iter   450/  960] train: loss: 0.0161368
[Epoch 94; Iter   480/  960] train: loss: 0.0701187
[Epoch 94; Iter   510/  960] train: loss: 0.0235519
[Epoch 94; Iter   540/  960] train: loss: 0.0125454
[Epoch 94; Iter   570/  960] train: loss: 0.0003965
[Epoch 94; Iter   600/  960] train: loss: 0.0049312
[Epoch 94; Iter   630/  960] train: loss: 0.0138042
[Epoch 94; Iter   660/  960] train: loss: 0.0047497
[Epoch 94; Iter   690/  960] train: loss: 0.0033938
[Epoch 94; Iter   720/  960] train: loss: 0.0255021
[Epoch 94; Iter   750/  960] train: loss: 0.0288529
[Epoch 94; Iter   780/  960] train: loss: 0.0033960
[Epoch 94; Iter   810/  960] train: loss: 0.0137306
[Epoch 94; Iter   840/  960] train: loss: 0.0004012
[Epoch 94; Iter   870/  960] train: loss: 0.0038478
[Epoch 94; Iter   900/  960] train: loss: 0.0003799
[Epoch 94; Iter   930/  960] train: loss: 0.0960442
[Epoch 94; Iter   960/  960] train: loss: 0.0241599
[Epoch 94] ogbg-molhiv: 0.717659 val loss: 0.278691
[Epoch 94] ogbg-molhiv: 0.765528 test loss: 0.231507
[Epoch 95; Iter    30/  960] train: loss: 0.0040375
[Epoch 95; Iter    60/  960] train: loss: 0.0007943
[Epoch 95; Iter    90/  960] train: loss: 0.0009477
[Epoch 95; Iter   120/  960] train: loss: 0.0102877
[Epoch 95; Iter   150/  960] train: loss: 0.0037078
[Epoch 95; Iter   180/  960] train: loss: 0.0027237
[Epoch 95; Iter   210/  960] train: loss: 0.0002114
[Epoch 95; Iter   240/  960] train: loss: 0.0117699
[Epoch 95; Iter   270/  960] train: loss: 0.0026416
[Epoch 95; Iter   300/  960] train: loss: 0.0138724
[Epoch 95; Iter   330/  960] train: loss: 0.0045583
[Epoch 95; Iter   360/  960] train: loss: 0.0172336
[Epoch 95; Iter   390/  960] train: loss: 0.0006387
[Epoch 95; Iter   420/  960] train: loss: 0.0808875
[Epoch 95; Iter   450/  960] train: loss: 0.0048889
[Epoch 95; Iter   480/  960] train: loss: 0.0382593
[Epoch 95; Iter   510/  960] train: loss: 0.0777452
[Epoch 95; Iter   540/  960] train: loss: 0.0148618
[Epoch 95; Iter   570/  960] train: loss: 0.0015969
[Epoch 95; Iter   600/  960] train: loss: 0.0697957
[Epoch 95; Iter   630/  960] train: loss: 0.0242380
[Epoch 95; Iter   660/  960] train: loss: 0.0018925
[Epoch 95; Iter   690/  960] train: loss: 0.0510099
[Epoch 95; Iter   720/  960] train: loss: 0.1195753
[Epoch 95; Iter   750/  960] train: loss: 0.0406190
[Epoch 95; Iter   780/  960] train: loss: 0.0028854
[Epoch 95; Iter   810/  960] train: loss: 0.0147790
[Epoch 95; Iter   840/  960] train: loss: 0.0011073
[Epoch 95; Iter   870/  960] train: loss: 0.0017762
[Epoch 95; Iter   900/  960] train: loss: 0.1632074
[Epoch 95; Iter   930/  960] train: loss: 0.0299628
[Epoch 95; Iter   960/  960] train: loss: 0.0092595
[Epoch 95] ogbg-molhiv: 0.717556 val loss: 0.272655
[Epoch 95] ogbg-molhiv: 0.767308 test loss: 0.210832
[Epoch 96; Iter    30/  960] train: loss: 0.0235130
[Epoch 96; Iter    60/  960] train: loss: 0.0139433
[Epoch 96; Iter    90/  960] train: loss: 0.0008643
[Epoch 96; Iter   120/  960] train: loss: 0.0025838
[Epoch 96; Iter   150/  960] train: loss: 0.0022051
[Epoch 96; Iter   180/  960] train: loss: 0.0018274
[Epoch 96; Iter   210/  960] train: loss: 0.0312541
[Epoch 96; Iter   240/  960] train: loss: 0.0014987
[Epoch 96; Iter   270/  960] train: loss: 0.0014861
[Epoch 96; Iter   300/  960] train: loss: 0.0148245
[Epoch 96; Iter   330/  960] train: loss: 0.0099327
[Epoch 96; Iter   360/  960] train: loss: 0.0017808
[Epoch 96; Iter   390/  960] train: loss: 0.0089999
[Epoch 96; Iter   420/  960] train: loss: 0.0131369
[Epoch 96; Iter   450/  960] train: loss: 0.0083260
[Epoch 96; Iter   480/  960] train: loss: 0.0857735
[Epoch 96; Iter   510/  960] train: loss: 0.0012560
[Epoch 96; Iter   540/  960] train: loss: 0.0143573
[Epoch 96; Iter   570/  960] train: loss: 0.0015408
[Epoch 96; Iter   600/  960] train: loss: 0.0103906
[Epoch 96; Iter   630/  960] train: loss: 0.0144133
[Epoch 96; Iter   660/  960] train: loss: 0.0394526
[Epoch 96; Iter   690/  960] train: loss: 0.0157234
[Epoch 96; Iter   720/  960] train: loss: 0.0117372
[Epoch 92; Iter   120/  960] train: loss: 0.0240192
[Epoch 92; Iter   150/  960] train: loss: 0.0048164
[Epoch 92; Iter   180/  960] train: loss: 0.0095911
[Epoch 92; Iter   210/  960] train: loss: 0.0028754
[Epoch 92; Iter   240/  960] train: loss: 0.0203530
[Epoch 92; Iter   270/  960] train: loss: 0.0133796
[Epoch 92; Iter   300/  960] train: loss: 0.0382505
[Epoch 92; Iter   330/  960] train: loss: 0.0067783
[Epoch 92; Iter   360/  960] train: loss: 0.0188039
[Epoch 92; Iter   390/  960] train: loss: 0.0204069
[Epoch 92; Iter   420/  960] train: loss: 0.0557167
[Epoch 92; Iter   450/  960] train: loss: 0.0112869
[Epoch 92; Iter   480/  960] train: loss: 0.0015833
[Epoch 92; Iter   510/  960] train: loss: 0.0527377
[Epoch 92; Iter   540/  960] train: loss: 0.0006991
[Epoch 92; Iter   570/  960] train: loss: 0.0013568
[Epoch 92; Iter   600/  960] train: loss: 0.0314978
[Epoch 92; Iter   630/  960] train: loss: 0.0794707
[Epoch 92; Iter   660/  960] train: loss: 0.0026422
[Epoch 92; Iter   690/  960] train: loss: 0.0033136
[Epoch 92; Iter   720/  960] train: loss: 0.0136447
[Epoch 92; Iter   750/  960] train: loss: 0.0038196
[Epoch 92; Iter   780/  960] train: loss: 0.0399755
[Epoch 92; Iter   810/  960] train: loss: 0.0014966
[Epoch 92; Iter   840/  960] train: loss: 0.0053582
[Epoch 92; Iter   870/  960] train: loss: 0.0097943
[Epoch 92; Iter   900/  960] train: loss: 0.0293953
[Epoch 92; Iter   930/  960] train: loss: 0.0689621
[Epoch 92; Iter   960/  960] train: loss: 0.0317125
[Epoch 92] ogbg-molhiv: 0.751338 val loss: 1.157277
[Epoch 92] ogbg-molhiv: 0.752428 test loss: 0.247176
[Epoch 93; Iter    30/  960] train: loss: 0.0066172
[Epoch 93; Iter    60/  960] train: loss: 0.0006604
[Epoch 93; Iter    90/  960] train: loss: 0.0434168
[Epoch 93; Iter   120/  960] train: loss: 0.0188061
[Epoch 93; Iter   150/  960] train: loss: 0.0188295
[Epoch 93; Iter   180/  960] train: loss: 0.0267077
[Epoch 93; Iter   210/  960] train: loss: 0.0233346
[Epoch 93; Iter   240/  960] train: loss: 0.0043903
[Epoch 93; Iter   270/  960] train: loss: 0.0232102
[Epoch 93; Iter   300/  960] train: loss: 0.0293430
[Epoch 93; Iter   330/  960] train: loss: 0.0070645
[Epoch 93; Iter   360/  960] train: loss: 0.0242577
[Epoch 93; Iter   390/  960] train: loss: 0.0064385
[Epoch 93; Iter   420/  960] train: loss: 0.0102178
[Epoch 93; Iter   450/  960] train: loss: 0.1697586
[Epoch 93; Iter   480/  960] train: loss: 0.0080571
[Epoch 93; Iter   510/  960] train: loss: 0.0033924
[Epoch 93; Iter   540/  960] train: loss: 0.0056884
[Epoch 93; Iter   570/  960] train: loss: 0.0065694
[Epoch 93; Iter   600/  960] train: loss: 0.0099109
[Epoch 93; Iter   630/  960] train: loss: 0.0025387
[Epoch 93; Iter   660/  960] train: loss: 0.0019393
[Epoch 93; Iter   690/  960] train: loss: 0.0189294
[Epoch 93; Iter   720/  960] train: loss: 0.0124954
[Epoch 93; Iter   750/  960] train: loss: 0.0018135
[Epoch 93; Iter   780/  960] train: loss: 0.0048205
[Epoch 93; Iter   810/  960] train: loss: 0.0220846
[Epoch 93; Iter   840/  960] train: loss: 0.0400636
[Epoch 93; Iter   870/  960] train: loss: 0.0008124
[Epoch 93; Iter   900/  960] train: loss: 0.1123717
[Epoch 93; Iter   930/  960] train: loss: 0.0060649
[Epoch 93; Iter   960/  960] train: loss: 0.0076292
[Epoch 93] ogbg-molhiv: 0.749886 val loss: 1.213213
[Epoch 93] ogbg-molhiv: 0.754346 test loss: 0.241304
[Epoch 94; Iter    30/  960] train: loss: 0.0152026
[Epoch 94; Iter    60/  960] train: loss: 0.2038334
[Epoch 94; Iter    90/  960] train: loss: 0.0087709
[Epoch 94; Iter   120/  960] train: loss: 0.0141508
[Epoch 94; Iter   150/  960] train: loss: 0.0215730
[Epoch 94; Iter   180/  960] train: loss: 0.0009571
[Epoch 94; Iter   210/  960] train: loss: 0.0041470
[Epoch 94; Iter   240/  960] train: loss: 0.0013056
[Epoch 94; Iter   270/  960] train: loss: 0.0064479
[Epoch 94; Iter   300/  960] train: loss: 0.0028365
[Epoch 94; Iter   330/  960] train: loss: 0.0018290
[Epoch 94; Iter   360/  960] train: loss: 0.0035748
[Epoch 94; Iter   390/  960] train: loss: 0.0162088
[Epoch 94; Iter   420/  960] train: loss: 0.0040224
[Epoch 94; Iter   450/  960] train: loss: 0.0007021
[Epoch 94; Iter   480/  960] train: loss: 0.0019909
[Epoch 94; Iter   510/  960] train: loss: 0.0216371
[Epoch 94; Iter   540/  960] train: loss: 0.1192178
[Epoch 94; Iter   570/  960] train: loss: 0.0125020
[Epoch 94; Iter   600/  960] train: loss: 0.0019302
[Epoch 94; Iter   630/  960] train: loss: 0.0139048
[Epoch 94; Iter   660/  960] train: loss: 0.0062081
[Epoch 94; Iter   690/  960] train: loss: 0.0051583
[Epoch 94; Iter   720/  960] train: loss: 0.0126058
[Epoch 94; Iter   750/  960] train: loss: 0.0527367
[Epoch 94; Iter   780/  960] train: loss: 0.0586009
[Epoch 94; Iter   810/  960] train: loss: 0.0258019
[Epoch 94; Iter   840/  960] train: loss: 0.0215868
[Epoch 94; Iter   870/  960] train: loss: 0.0067090
[Epoch 94; Iter   900/  960] train: loss: 0.0073967
[Epoch 94; Iter   930/  960] train: loss: 0.0045908
[Epoch 94; Iter   960/  960] train: loss: 0.0019763
[Epoch 94] ogbg-molhiv: 0.754886 val loss: 0.983577
[Epoch 94] ogbg-molhiv: 0.756319 test loss: 0.302696
[Epoch 95; Iter    30/  960] train: loss: 0.0035874
[Epoch 95; Iter    60/  960] train: loss: 0.0243353
[Epoch 95; Iter    90/  960] train: loss: 0.0015496
[Epoch 95; Iter   120/  960] train: loss: 0.0226118
[Epoch 95; Iter   150/  960] train: loss: 0.0038549
[Epoch 95; Iter   180/  960] train: loss: 0.0058404
[Epoch 95; Iter   210/  960] train: loss: 0.0643960
[Epoch 95; Iter   240/  960] train: loss: 0.0024540
[Epoch 95; Iter   270/  960] train: loss: 0.0074166
[Epoch 95; Iter   300/  960] train: loss: 0.0033424
[Epoch 95; Iter   330/  960] train: loss: 0.0045616
[Epoch 95; Iter   360/  960] train: loss: 0.0175431
[Epoch 95; Iter   390/  960] train: loss: 0.0014834
[Epoch 95; Iter   420/  960] train: loss: 0.0334389
[Epoch 95; Iter   450/  960] train: loss: 0.0192897
[Epoch 95; Iter   480/  960] train: loss: 0.0365242
[Epoch 95; Iter   510/  960] train: loss: 0.0062984
[Epoch 95; Iter   540/  960] train: loss: 0.0012502
[Epoch 95; Iter   570/  960] train: loss: 0.0050932
[Epoch 95; Iter   600/  960] train: loss: 0.0095859
[Epoch 95; Iter   630/  960] train: loss: 0.0296339
[Epoch 95; Iter   660/  960] train: loss: 0.0080914
[Epoch 95; Iter   690/  960] train: loss: 0.0126836
[Epoch 95; Iter   720/  960] train: loss: 0.0015564
[Epoch 95; Iter   750/  960] train: loss: 0.0010348
[Epoch 95; Iter   780/  960] train: loss: 0.0044769
[Epoch 95; Iter   810/  960] train: loss: 0.0634300
[Epoch 95; Iter   840/  960] train: loss: 0.0201565
[Epoch 95; Iter   870/  960] train: loss: 0.0020154
[Epoch 95; Iter   900/  960] train: loss: 0.0238166
[Epoch 95; Iter   930/  960] train: loss: 0.0454855
[Epoch 95; Iter   960/  960] train: loss: 0.0017639
[Epoch 95] ogbg-molhiv: 0.757948 val loss: 0.852364
[Epoch 95] ogbg-molhiv: 0.761015 test loss: 0.215976
[Epoch 96; Iter    30/  960] train: loss: 0.0053503
[Epoch 96; Iter    60/  960] train: loss: 0.0050016
[Epoch 96; Iter    90/  960] train: loss: 0.0096961
[Epoch 96; Iter   120/  960] train: loss: 0.0897040
[Epoch 96; Iter   150/  960] train: loss: 0.0294080
[Epoch 96; Iter   180/  960] train: loss: 0.0096012
[Epoch 96; Iter   210/  960] train: loss: 0.0403223
[Epoch 96; Iter   240/  960] train: loss: 0.0177513
[Epoch 96; Iter   270/  960] train: loss: 0.0057174
[Epoch 96; Iter   300/  960] train: loss: 0.0090650
[Epoch 96; Iter   330/  960] train: loss: 0.0441517
[Epoch 96; Iter   360/  960] train: loss: 0.0043295
[Epoch 96; Iter   390/  960] train: loss: 0.0011628
[Epoch 96; Iter   420/  960] train: loss: 0.1007264
[Epoch 96; Iter   450/  960] train: loss: 0.0031686
[Epoch 96; Iter   480/  960] train: loss: 0.1419176
[Epoch 96; Iter   510/  960] train: loss: 0.0242106
[Epoch 96; Iter   540/  960] train: loss: 0.0006009
[Epoch 96; Iter   570/  960] train: loss: 0.0125576
[Epoch 96; Iter   600/  960] train: loss: 0.0030092
[Epoch 96; Iter   630/  960] train: loss: 0.0084150
[Epoch 96; Iter   660/  960] train: loss: 0.0166225
[Epoch 96; Iter   690/  960] train: loss: 0.0017301
[Epoch 96; Iter   720/  960] train: loss: 0.0737491
[Epoch 89; Iter   544/ 1097] train: loss: 0.0515657
[Epoch 89; Iter   574/ 1097] train: loss: 0.0038227
[Epoch 89; Iter   604/ 1097] train: loss: 0.0176680
[Epoch 89; Iter   634/ 1097] train: loss: 0.0739621
[Epoch 89; Iter   664/ 1097] train: loss: 0.0087819
[Epoch 89; Iter   694/ 1097] train: loss: 0.0336637
[Epoch 89; Iter   724/ 1097] train: loss: 0.0830661
[Epoch 89; Iter   754/ 1097] train: loss: 0.0254439
[Epoch 89; Iter   784/ 1097] train: loss: 0.0596533
[Epoch 89; Iter   814/ 1097] train: loss: 0.0287609
[Epoch 89; Iter   844/ 1097] train: loss: 0.0192350
[Epoch 89; Iter   874/ 1097] train: loss: 0.0213881
[Epoch 89; Iter   904/ 1097] train: loss: 0.0205358
[Epoch 89; Iter   934/ 1097] train: loss: 0.0059198
[Epoch 89; Iter   964/ 1097] train: loss: 0.0132485
[Epoch 89; Iter   994/ 1097] train: loss: 0.0072644
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0145805
[Epoch 89; Iter  1054/ 1097] train: loss: 0.1433600
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0099782
[Epoch 89] ogbg-molhiv: 0.775172 val loss: 0.134821
[Epoch 89] ogbg-molhiv: 0.724749 test loss: 0.217130
[Epoch 90; Iter    17/ 1097] train: loss: 0.0203990
[Epoch 90; Iter    47/ 1097] train: loss: 0.0742847
[Epoch 90; Iter    77/ 1097] train: loss: 0.0515230
[Epoch 90; Iter   107/ 1097] train: loss: 0.0038603
[Epoch 90; Iter   137/ 1097] train: loss: 0.0124259
[Epoch 90; Iter   167/ 1097] train: loss: 0.0453986
[Epoch 90; Iter   197/ 1097] train: loss: 0.0320438
[Epoch 90; Iter   227/ 1097] train: loss: 0.0178715
[Epoch 90; Iter   257/ 1097] train: loss: 0.0073483
[Epoch 90; Iter   287/ 1097] train: loss: 0.0022700
[Epoch 90; Iter   317/ 1097] train: loss: 0.1271197
[Epoch 90; Iter   347/ 1097] train: loss: 0.0148662
[Epoch 90; Iter   377/ 1097] train: loss: 0.0448734
[Epoch 90; Iter   407/ 1097] train: loss: 0.0317512
[Epoch 90; Iter   437/ 1097] train: loss: 0.0044052
[Epoch 90; Iter   467/ 1097] train: loss: 0.1832912
[Epoch 90; Iter   497/ 1097] train: loss: 0.0431972
[Epoch 90; Iter   527/ 1097] train: loss: 0.0601032
[Epoch 90; Iter   557/ 1097] train: loss: 0.0078892
[Epoch 90; Iter   587/ 1097] train: loss: 0.0172807
[Epoch 90; Iter   617/ 1097] train: loss: 0.0269327
[Epoch 90; Iter   647/ 1097] train: loss: 0.0218248
[Epoch 90; Iter   677/ 1097] train: loss: 0.0031121
[Epoch 90; Iter   707/ 1097] train: loss: 0.0049703
[Epoch 90; Iter   737/ 1097] train: loss: 0.0061084
[Epoch 90; Iter   767/ 1097] train: loss: 0.0062683
[Epoch 90; Iter   797/ 1097] train: loss: 0.1154369
[Epoch 90; Iter   827/ 1097] train: loss: 0.1082247
[Epoch 90; Iter   857/ 1097] train: loss: 0.0220224
[Epoch 90; Iter   887/ 1097] train: loss: 0.1400158
[Epoch 90; Iter   917/ 1097] train: loss: 0.0196998
[Epoch 90; Iter   947/ 1097] train: loss: 0.0562087
[Epoch 90; Iter   977/ 1097] train: loss: 0.0081199
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0369578
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0565765
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0470125
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0335891
[Epoch 90] ogbg-molhiv: 0.774743 val loss: 0.137246
[Epoch 90] ogbg-molhiv: 0.723407 test loss: 0.223339
[Epoch 91; Iter    30/ 1097] train: loss: 0.0064268
[Epoch 91; Iter    60/ 1097] train: loss: 0.0158639
[Epoch 91; Iter    90/ 1097] train: loss: 0.0029201
[Epoch 91; Iter   120/ 1097] train: loss: 0.0035053
[Epoch 91; Iter   150/ 1097] train: loss: 0.0575810
[Epoch 91; Iter   180/ 1097] train: loss: 0.0052907
[Epoch 91; Iter   210/ 1097] train: loss: 0.0060781
[Epoch 91; Iter   240/ 1097] train: loss: 0.0421878
[Epoch 91; Iter   270/ 1097] train: loss: 0.0134841
[Epoch 91; Iter   300/ 1097] train: loss: 0.0028272
[Epoch 91; Iter   330/ 1097] train: loss: 0.2198108
[Epoch 91; Iter   360/ 1097] train: loss: 0.0593998
[Epoch 91; Iter   390/ 1097] train: loss: 0.0356445
[Epoch 91; Iter   420/ 1097] train: loss: 0.0679038
[Epoch 91; Iter   450/ 1097] train: loss: 0.0138785
[Epoch 91; Iter   480/ 1097] train: loss: 0.0028449
[Epoch 91; Iter   510/ 1097] train: loss: 0.0270800
[Epoch 91; Iter   540/ 1097] train: loss: 0.0438390
[Epoch 91; Iter   570/ 1097] train: loss: 0.0206024
[Epoch 91; Iter   600/ 1097] train: loss: 0.1794824
[Epoch 91; Iter   630/ 1097] train: loss: 0.0309553
[Epoch 91; Iter   660/ 1097] train: loss: 0.0989927
[Epoch 91; Iter   690/ 1097] train: loss: 0.0802182
[Epoch 91; Iter   720/ 1097] train: loss: 0.0196419
[Epoch 91; Iter   750/ 1097] train: loss: 0.0060444
[Epoch 91; Iter   780/ 1097] train: loss: 0.0078817
[Epoch 91; Iter   810/ 1097] train: loss: 0.0300498
[Epoch 91; Iter   840/ 1097] train: loss: 0.0188425
[Epoch 91; Iter   870/ 1097] train: loss: 0.0178557
[Epoch 91; Iter   900/ 1097] train: loss: 0.0178559
[Epoch 91; Iter   930/ 1097] train: loss: 0.0684580
[Epoch 91; Iter   960/ 1097] train: loss: 0.0124271
[Epoch 91; Iter   990/ 1097] train: loss: 0.0163580
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0910123
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0195484
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0695112
[Epoch 91] ogbg-molhiv: 0.782022 val loss: 0.136637
[Epoch 91] ogbg-molhiv: 0.729916 test loss: 0.216906
[Epoch 92; Iter    13/ 1097] train: loss: 0.1418245
[Epoch 92; Iter    43/ 1097] train: loss: 0.0683134
[Epoch 92; Iter    73/ 1097] train: loss: 0.0533176
[Epoch 92; Iter   103/ 1097] train: loss: 0.0775420
[Epoch 92; Iter   133/ 1097] train: loss: 0.1233117
[Epoch 92; Iter   163/ 1097] train: loss: 0.0122878
[Epoch 92; Iter   193/ 1097] train: loss: 0.0703928
[Epoch 92; Iter   223/ 1097] train: loss: 0.0047555
[Epoch 92; Iter   253/ 1097] train: loss: 0.0148387
[Epoch 92; Iter   283/ 1097] train: loss: 0.0468620
[Epoch 92; Iter   313/ 1097] train: loss: 0.0856142
[Epoch 92; Iter   343/ 1097] train: loss: 0.0458395
[Epoch 92; Iter   373/ 1097] train: loss: 0.0443713
[Epoch 92; Iter   403/ 1097] train: loss: 0.1035843
[Epoch 92; Iter   433/ 1097] train: loss: 0.0110866
[Epoch 92; Iter   463/ 1097] train: loss: 0.0032657
[Epoch 92; Iter   493/ 1097] train: loss: 0.0282683
[Epoch 92; Iter   523/ 1097] train: loss: 0.0043304
[Epoch 92; Iter   553/ 1097] train: loss: 0.1001581
[Epoch 92; Iter   583/ 1097] train: loss: 0.0544622
[Epoch 92; Iter   613/ 1097] train: loss: 0.0863264
[Epoch 92; Iter   643/ 1097] train: loss: 0.0055333
[Epoch 92; Iter   673/ 1097] train: loss: 0.0166260
[Epoch 92; Iter   703/ 1097] train: loss: 0.0049922
[Epoch 92; Iter   733/ 1097] train: loss: 0.0225292
[Epoch 92; Iter   763/ 1097] train: loss: 0.0432839
[Epoch 92; Iter   793/ 1097] train: loss: 0.0108208
[Epoch 92; Iter   823/ 1097] train: loss: 0.0819529
[Epoch 92; Iter   853/ 1097] train: loss: 0.0366243
[Epoch 92; Iter   883/ 1097] train: loss: 0.0056879
[Epoch 92; Iter   913/ 1097] train: loss: 0.0620353
[Epoch 92; Iter   943/ 1097] train: loss: 0.0607452
[Epoch 92; Iter   973/ 1097] train: loss: 0.0164941
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0045894
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0472173
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0536347
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0188551
[Epoch 92] ogbg-molhiv: 0.774603 val loss: 0.151928
[Epoch 92] ogbg-molhiv: 0.731922 test loss: 0.221188
[Epoch 93; Iter    26/ 1097] train: loss: 0.0206461
[Epoch 93; Iter    56/ 1097] train: loss: 0.0184580
[Epoch 93; Iter    86/ 1097] train: loss: 0.0157464
[Epoch 93; Iter   116/ 1097] train: loss: 0.0512533
[Epoch 93; Iter   146/ 1097] train: loss: 0.0242871
[Epoch 93; Iter   176/ 1097] train: loss: 0.0138880
[Epoch 93; Iter   206/ 1097] train: loss: 0.0074570
[Epoch 93; Iter   236/ 1097] train: loss: 0.0511080
[Epoch 93; Iter   266/ 1097] train: loss: 0.0099190
[Epoch 93; Iter   296/ 1097] train: loss: 0.0123279
[Epoch 93; Iter   326/ 1097] train: loss: 0.0406737
[Epoch 93; Iter   356/ 1097] train: loss: 0.0589063
[Epoch 93; Iter   386/ 1097] train: loss: 0.0080919
[Epoch 93; Iter   416/ 1097] train: loss: 0.0203595
[Epoch 93; Iter   446/ 1097] train: loss: 0.0133735
[Epoch 93; Iter   476/ 1097] train: loss: 0.0106228
[Epoch 93; Iter   506/ 1097] train: loss: 0.0036141
[Epoch 93; Iter   536/ 1097] train: loss: 0.0066022
[Epoch 93; Iter   566/ 1097] train: loss: 0.0087972
[Epoch 93; Iter   596/ 1097] train: loss: 0.0531125
[Epoch 95; Iter   488/  823] train: loss: 0.1222469
[Epoch 95; Iter   518/  823] train: loss: 0.0080885
[Epoch 95; Iter   548/  823] train: loss: 0.0381947
[Epoch 95; Iter   578/  823] train: loss: 0.0163577
[Epoch 95; Iter   608/  823] train: loss: 0.0055311
[Epoch 95; Iter   638/  823] train: loss: 0.0113243
[Epoch 95; Iter   668/  823] train: loss: 0.0291610
[Epoch 95; Iter   698/  823] train: loss: 0.0005961
[Epoch 95; Iter   728/  823] train: loss: 0.0028443
[Epoch 95; Iter   758/  823] train: loss: 0.0031953
[Epoch 95; Iter   788/  823] train: loss: 0.0070239
[Epoch 95; Iter   818/  823] train: loss: 0.0012710
[Epoch 95] ogbg-molhiv: 0.703024 val loss: 0.404152
[Epoch 95] ogbg-molhiv: 0.754078 test loss: 0.221660
[Epoch 96; Iter    25/  823] train: loss: 0.0048656
[Epoch 96; Iter    55/  823] train: loss: 0.0021887
[Epoch 96; Iter    85/  823] train: loss: 0.0055905
[Epoch 96; Iter   115/  823] train: loss: 0.0186561
[Epoch 96; Iter   145/  823] train: loss: 0.0259099
[Epoch 96; Iter   175/  823] train: loss: 0.0008254
[Epoch 96; Iter   205/  823] train: loss: 0.0081851
[Epoch 96; Iter   235/  823] train: loss: 0.0088040
[Epoch 96; Iter   265/  823] train: loss: 0.0031423
[Epoch 96; Iter   295/  823] train: loss: 0.0028275
[Epoch 96; Iter   325/  823] train: loss: 0.0749669
[Epoch 96; Iter   355/  823] train: loss: 0.0023457
[Epoch 96; Iter   385/  823] train: loss: 0.0076521
[Epoch 96; Iter   415/  823] train: loss: 0.0022699
[Epoch 96; Iter   445/  823] train: loss: 0.0089264
[Epoch 96; Iter   475/  823] train: loss: 0.1874969
[Epoch 96; Iter   505/  823] train: loss: 0.0302741
[Epoch 96; Iter   535/  823] train: loss: 0.0058606
[Epoch 96; Iter   565/  823] train: loss: 0.0065580
[Epoch 96; Iter   595/  823] train: loss: 0.0043603
[Epoch 96; Iter   625/  823] train: loss: 0.0775076
[Epoch 96; Iter   655/  823] train: loss: 0.0115394
[Epoch 96; Iter   685/  823] train: loss: 0.0136233
[Epoch 96; Iter   715/  823] train: loss: 0.0015372
[Epoch 96; Iter   745/  823] train: loss: 0.0026000
[Epoch 96; Iter   775/  823] train: loss: 0.0013906
[Epoch 96; Iter   805/  823] train: loss: 0.0017443
[Epoch 96] ogbg-molhiv: 0.701372 val loss: 0.426627
[Epoch 96] ogbg-molhiv: 0.751611 test loss: 0.220580
[Epoch 97; Iter    12/  823] train: loss: 0.0071884
[Epoch 97; Iter    42/  823] train: loss: 0.0075580
[Epoch 97; Iter    72/  823] train: loss: 0.0014345
[Epoch 97; Iter   102/  823] train: loss: 0.0047119
[Epoch 97; Iter   132/  823] train: loss: 0.0534688
[Epoch 97; Iter   162/  823] train: loss: 0.0082440
[Epoch 97; Iter   192/  823] train: loss: 0.0032708
[Epoch 97; Iter   222/  823] train: loss: 0.0793633
[Epoch 97; Iter   252/  823] train: loss: 0.0191149
[Epoch 97; Iter   282/  823] train: loss: 0.0054579
[Epoch 97; Iter   312/  823] train: loss: 0.0279623
[Epoch 97; Iter   342/  823] train: loss: 0.0007804
[Epoch 97; Iter   372/  823] train: loss: 0.0029494
[Epoch 97; Iter   402/  823] train: loss: 0.0073858
[Epoch 97; Iter   432/  823] train: loss: 0.0087469
[Epoch 97; Iter   462/  823] train: loss: 0.0157924
[Epoch 97; Iter   492/  823] train: loss: 0.0360183
[Epoch 97; Iter   522/  823] train: loss: 0.0023134
[Epoch 97; Iter   552/  823] train: loss: 0.0424422
[Epoch 97; Iter   582/  823] train: loss: 0.0008194
[Epoch 97; Iter   612/  823] train: loss: 0.0082899
[Epoch 97; Iter   642/  823] train: loss: 0.0076344
[Epoch 97; Iter   672/  823] train: loss: 0.0009149
[Epoch 97; Iter   702/  823] train: loss: 0.0078577
[Epoch 97; Iter   732/  823] train: loss: 0.0077311
[Epoch 97; Iter   762/  823] train: loss: 0.0006058
[Epoch 97; Iter   792/  823] train: loss: 0.0755905
[Epoch 97; Iter   822/  823] train: loss: 0.0989511
[Epoch 97] ogbg-molhiv: 0.714031 val loss: 0.469927
[Epoch 97] ogbg-molhiv: 0.756457 test loss: 0.239718
[Epoch 98; Iter    29/  823] train: loss: 0.0456902
[Epoch 98; Iter    59/  823] train: loss: 0.0018390
[Epoch 98; Iter    89/  823] train: loss: 0.0008923
[Epoch 98; Iter   119/  823] train: loss: 0.0331295
[Epoch 98; Iter   149/  823] train: loss: 0.0212787
[Epoch 98; Iter   179/  823] train: loss: 0.0043973
[Epoch 98; Iter   209/  823] train: loss: 0.1393345
[Epoch 98; Iter   239/  823] train: loss: 0.0074019
[Epoch 98; Iter   269/  823] train: loss: 0.0414217
[Epoch 98; Iter   299/  823] train: loss: 0.0012309
[Epoch 98; Iter   329/  823] train: loss: 0.0718099
[Epoch 98; Iter   359/  823] train: loss: 0.0188040
[Epoch 98; Iter   389/  823] train: loss: 0.0752444
[Epoch 98; Iter   419/  823] train: loss: 0.0132514
[Epoch 98; Iter   449/  823] train: loss: 0.0002114
[Epoch 98; Iter   479/  823] train: loss: 0.0129267
[Epoch 98; Iter   509/  823] train: loss: 0.0640754
[Epoch 98; Iter   539/  823] train: loss: 0.0014100
[Epoch 98; Iter   569/  823] train: loss: 0.0054472
[Epoch 98; Iter   599/  823] train: loss: 0.0004523
[Epoch 98; Iter   629/  823] train: loss: 0.0060589
[Epoch 98; Iter   659/  823] train: loss: 0.0005901
[Epoch 98; Iter   689/  823] train: loss: 0.0093457
[Epoch 98; Iter   719/  823] train: loss: 0.0240353
[Epoch 98; Iter   749/  823] train: loss: 0.0048962
[Epoch 98; Iter   779/  823] train: loss: 0.0036984
[Epoch 98; Iter   809/  823] train: loss: 0.0014583
[Epoch 98] ogbg-molhiv: 0.706892 val loss: 0.445012
[Epoch 98] ogbg-molhiv: 0.752126 test loss: 0.260052
[Epoch 99; Iter    16/  823] train: loss: 0.0008544
[Epoch 99; Iter    46/  823] train: loss: 0.0070229
[Epoch 99; Iter    76/  823] train: loss: 0.0188702
[Epoch 99; Iter   106/  823] train: loss: 0.0007611
[Epoch 99; Iter   136/  823] train: loss: 0.0035946
[Epoch 99; Iter   166/  823] train: loss: 0.0064371
[Epoch 99; Iter   196/  823] train: loss: 0.0269056
[Epoch 99; Iter   226/  823] train: loss: 0.0028321
[Epoch 99; Iter   256/  823] train: loss: 0.0033279
[Epoch 99; Iter   286/  823] train: loss: 0.0511790
[Epoch 99; Iter   316/  823] train: loss: 0.0003791
[Epoch 99; Iter   346/  823] train: loss: 0.0037523
[Epoch 99; Iter   376/  823] train: loss: 0.0097073
[Epoch 99; Iter   406/  823] train: loss: 0.0343174
[Epoch 99; Iter   436/  823] train: loss: 0.0018147
[Epoch 99; Iter   466/  823] train: loss: 0.0425060
[Epoch 99; Iter   496/  823] train: loss: 0.0017488
[Epoch 99; Iter   526/  823] train: loss: 0.0386964
[Epoch 99; Iter   556/  823] train: loss: 0.0062464
[Epoch 99; Iter   586/  823] train: loss: 0.0208661
[Epoch 99; Iter   616/  823] train: loss: 0.0027568
[Epoch 99; Iter   646/  823] train: loss: 0.0042818
[Epoch 99; Iter   676/  823] train: loss: 0.0006560
[Epoch 99; Iter   706/  823] train: loss: 0.0630764
[Epoch 99; Iter   736/  823] train: loss: 0.0022309
[Epoch 99; Iter   766/  823] train: loss: 0.0034572
[Epoch 99; Iter   796/  823] train: loss: 0.0011443
[Epoch 99] ogbg-molhiv: 0.714695 val loss: 0.403537
[Epoch 99] ogbg-molhiv: 0.754971 test loss: 0.221511
[Epoch 100; Iter     3/  823] train: loss: 0.0016151
[Epoch 100; Iter    33/  823] train: loss: 0.0051207
[Epoch 100; Iter    63/  823] train: loss: 0.0009188
[Epoch 100; Iter    93/  823] train: loss: 0.0145800
[Epoch 100; Iter   123/  823] train: loss: 0.1257533
[Epoch 100; Iter   153/  823] train: loss: 0.0011921
[Epoch 100; Iter   183/  823] train: loss: 0.0048052
[Epoch 100; Iter   213/  823] train: loss: 0.0006072
[Epoch 100; Iter   243/  823] train: loss: 0.0049539
[Epoch 100; Iter   273/  823] train: loss: 0.0228571
[Epoch 100; Iter   303/  823] train: loss: 0.0004651
[Epoch 100; Iter   333/  823] train: loss: 0.0122918
[Epoch 100; Iter   363/  823] train: loss: 0.0002474
[Epoch 100; Iter   393/  823] train: loss: 0.0008522
[Epoch 100; Iter   423/  823] train: loss: 0.0479212
[Epoch 100; Iter   453/  823] train: loss: 0.0729538
[Epoch 100; Iter   483/  823] train: loss: 0.0075316
[Epoch 100; Iter   513/  823] train: loss: 0.0009462
[Epoch 100; Iter   543/  823] train: loss: 0.0033372
[Epoch 100; Iter   573/  823] train: loss: 0.0033788
[Epoch 100; Iter   603/  823] train: loss: 0.1315143
[Epoch 100; Iter   633/  823] train: loss: 0.0109736
[Epoch 100; Iter   663/  823] train: loss: 0.0009633
[Epoch 100; Iter   693/  823] train: loss: 0.0649496
[Epoch 100; Iter   723/  823] train: loss: 0.0013895
[Epoch 92; Iter   120/  960] train: loss: 0.1355850
[Epoch 92; Iter   150/  960] train: loss: 0.0051079
[Epoch 92; Iter   180/  960] train: loss: 0.0071102
[Epoch 92; Iter   210/  960] train: loss: 0.0584328
[Epoch 92; Iter   240/  960] train: loss: 0.0065946
[Epoch 92; Iter   270/  960] train: loss: 0.0019119
[Epoch 92; Iter   300/  960] train: loss: 0.0062483
[Epoch 92; Iter   330/  960] train: loss: 0.0262431
[Epoch 92; Iter   360/  960] train: loss: 0.0002684
[Epoch 92; Iter   390/  960] train: loss: 0.0493955
[Epoch 92; Iter   420/  960] train: loss: 0.0025590
[Epoch 92; Iter   450/  960] train: loss: 0.0035031
[Epoch 92; Iter   480/  960] train: loss: 0.0038761
[Epoch 92; Iter   510/  960] train: loss: 0.0018237
[Epoch 92; Iter   540/  960] train: loss: 0.0174054
[Epoch 92; Iter   570/  960] train: loss: 0.0120623
[Epoch 92; Iter   600/  960] train: loss: 0.0430500
[Epoch 92; Iter   630/  960] train: loss: 0.0027809
[Epoch 92; Iter   660/  960] train: loss: 0.0887526
[Epoch 92; Iter   690/  960] train: loss: 0.0205039
[Epoch 92; Iter   720/  960] train: loss: 0.0270253
[Epoch 92; Iter   750/  960] train: loss: 0.0691667
[Epoch 92; Iter   780/  960] train: loss: 0.0015276
[Epoch 92; Iter   810/  960] train: loss: 0.0074990
[Epoch 92; Iter   840/  960] train: loss: 0.0688630
[Epoch 92; Iter   870/  960] train: loss: 0.0108060
[Epoch 92; Iter   900/  960] train: loss: 0.0072399
[Epoch 92; Iter   930/  960] train: loss: 0.0069804
[Epoch 92; Iter   960/  960] train: loss: 0.0005226
[Epoch 92] ogbg-molhiv: 0.719451 val loss: 1.223236
[Epoch 92] ogbg-molhiv: 0.745401 test loss: 0.944313
[Epoch 93; Iter    30/  960] train: loss: 0.0010435
[Epoch 93; Iter    60/  960] train: loss: 0.0075673
[Epoch 93; Iter    90/  960] train: loss: 0.0516145
[Epoch 93; Iter   120/  960] train: loss: 0.0066574
[Epoch 93; Iter   150/  960] train: loss: 0.0283682
[Epoch 93; Iter   180/  960] train: loss: 0.3011411
[Epoch 93; Iter   210/  960] train: loss: 0.0140967
[Epoch 93; Iter   240/  960] train: loss: 0.0133992
[Epoch 93; Iter   270/  960] train: loss: 0.0268187
[Epoch 93; Iter   300/  960] train: loss: 0.0104959
[Epoch 93; Iter   330/  960] train: loss: 0.0196594
[Epoch 93; Iter   360/  960] train: loss: 0.0043732
[Epoch 93; Iter   390/  960] train: loss: 0.0125004
[Epoch 93; Iter   420/  960] train: loss: 0.0017694
[Epoch 93; Iter   450/  960] train: loss: 0.0061628
[Epoch 93; Iter   480/  960] train: loss: 0.1440774
[Epoch 93; Iter   510/  960] train: loss: 0.0036338
[Epoch 93; Iter   540/  960] train: loss: 0.0028396
[Epoch 93; Iter   570/  960] train: loss: 0.1533562
[Epoch 93; Iter   600/  960] train: loss: 0.0055752
[Epoch 93; Iter   630/  960] train: loss: 0.0025488
[Epoch 93; Iter   660/  960] train: loss: 0.0073369
[Epoch 93; Iter   690/  960] train: loss: 0.0029552
[Epoch 93; Iter   720/  960] train: loss: 0.0026199
[Epoch 93; Iter   750/  960] train: loss: 0.0045716
[Epoch 93; Iter   780/  960] train: loss: 0.0023606
[Epoch 93; Iter   810/  960] train: loss: 0.0025844
[Epoch 93; Iter   840/  960] train: loss: 0.0055492
[Epoch 93; Iter   870/  960] train: loss: 0.0049757
[Epoch 93; Iter   900/  960] train: loss: 0.0019155
[Epoch 93; Iter   930/  960] train: loss: 0.0049239
[Epoch 93; Iter   960/  960] train: loss: 0.1279435
[Epoch 93] ogbg-molhiv: 0.723312 val loss: 0.295245
[Epoch 93] ogbg-molhiv: 0.745314 test loss: 0.246857
[Epoch 94; Iter    30/  960] train: loss: 0.0271094
[Epoch 94; Iter    60/  960] train: loss: 0.0635360
[Epoch 94; Iter    90/  960] train: loss: 0.0196259
[Epoch 94; Iter   120/  960] train: loss: 0.0031416
[Epoch 94; Iter   150/  960] train: loss: 0.0085386
[Epoch 94; Iter   180/  960] train: loss: 0.0152240
[Epoch 94; Iter   210/  960] train: loss: 0.0032499
[Epoch 94; Iter   240/  960] train: loss: 0.0163933
[Epoch 94; Iter   270/  960] train: loss: 0.0198111
[Epoch 94; Iter   300/  960] train: loss: 0.0077805
[Epoch 94; Iter   330/  960] train: loss: 0.0044643
[Epoch 94; Iter   360/  960] train: loss: 0.0147352
[Epoch 94; Iter   390/  960] train: loss: 0.0876823
[Epoch 94; Iter   420/  960] train: loss: 0.0182184
[Epoch 94; Iter   450/  960] train: loss: 0.0244461
[Epoch 94; Iter   480/  960] train: loss: 0.0013567
[Epoch 94; Iter   510/  960] train: loss: 0.0050812
[Epoch 94; Iter   540/  960] train: loss: 0.0076209
[Epoch 94; Iter   570/  960] train: loss: 0.0074331
[Epoch 94; Iter   600/  960] train: loss: 0.0094175
[Epoch 94; Iter   630/  960] train: loss: 0.0158961
[Epoch 94; Iter   660/  960] train: loss: 0.0014680
[Epoch 94; Iter   690/  960] train: loss: 0.0021999
[Epoch 94; Iter   720/  960] train: loss: 0.0018784
[Epoch 94; Iter   750/  960] train: loss: 0.0045793
[Epoch 94; Iter   780/  960] train: loss: 0.0708121
[Epoch 94; Iter   810/  960] train: loss: 0.0102471
[Epoch 94; Iter   840/  960] train: loss: 0.0071653
[Epoch 94; Iter   870/  960] train: loss: 0.0050378
[Epoch 94; Iter   900/  960] train: loss: 0.0015390
[Epoch 94; Iter   930/  960] train: loss: 0.0018122
[Epoch 94; Iter   960/  960] train: loss: 0.0010373
[Epoch 94] ogbg-molhiv: 0.722316 val loss: 0.713311
[Epoch 94] ogbg-molhiv: 0.748721 test loss: 0.523425
[Epoch 95; Iter    30/  960] train: loss: 0.0397512
[Epoch 95; Iter    60/  960] train: loss: 0.0105813
[Epoch 95; Iter    90/  960] train: loss: 0.0009333
[Epoch 95; Iter   120/  960] train: loss: 0.0214194
[Epoch 95; Iter   150/  960] train: loss: 0.0143244
[Epoch 95; Iter   180/  960] train: loss: 0.1661842
[Epoch 95; Iter   210/  960] train: loss: 0.0040255
[Epoch 95; Iter   240/  960] train: loss: 0.0341173
[Epoch 95; Iter   270/  960] train: loss: 0.0424837
[Epoch 95; Iter   300/  960] train: loss: 0.0071708
[Epoch 95; Iter   330/  960] train: loss: 0.0035267
[Epoch 95; Iter   360/  960] train: loss: 0.0314180
[Epoch 95; Iter   390/  960] train: loss: 0.0452708
[Epoch 95; Iter   420/  960] train: loss: 0.0223422
[Epoch 95; Iter   450/  960] train: loss: 0.0285723
[Epoch 95; Iter   480/  960] train: loss: 0.0314718
[Epoch 95; Iter   510/  960] train: loss: 0.0145878
[Epoch 95; Iter   540/  960] train: loss: 0.0065993
[Epoch 95; Iter   570/  960] train: loss: 0.0069806
[Epoch 95; Iter   600/  960] train: loss: 0.0076645
[Epoch 95; Iter   630/  960] train: loss: 0.0400996
[Epoch 95; Iter   660/  960] train: loss: 0.0011313
[Epoch 95; Iter   690/  960] train: loss: 0.0449713
[Epoch 95; Iter   720/  960] train: loss: 0.0071594
[Epoch 95; Iter   750/  960] train: loss: 0.0012839
[Epoch 95; Iter   780/  960] train: loss: 0.0049001
[Epoch 95; Iter   810/  960] train: loss: 0.0233429
[Epoch 95; Iter   840/  960] train: loss: 0.0017391
[Epoch 95; Iter   870/  960] train: loss: 0.0017673
[Epoch 95; Iter   900/  960] train: loss: 0.0047166
[Epoch 95; Iter   930/  960] train: loss: 0.0026750
[Epoch 95; Iter   960/  960] train: loss: 0.0016257
[Epoch 95] ogbg-molhiv: 0.719156 val loss: 0.957725
[Epoch 95] ogbg-molhiv: 0.744495 test loss: 0.729585
[Epoch 96; Iter    30/  960] train: loss: 0.0104431
[Epoch 96; Iter    60/  960] train: loss: 0.0024826
[Epoch 96; Iter    90/  960] train: loss: 0.0072910
[Epoch 96; Iter   120/  960] train: loss: 0.0034188
[Epoch 96; Iter   150/  960] train: loss: 0.0007998
[Epoch 96; Iter   180/  960] train: loss: 0.0336538
[Epoch 96; Iter   210/  960] train: loss: 0.0066936
[Epoch 96; Iter   240/  960] train: loss: 0.0027742
[Epoch 96; Iter   270/  960] train: loss: 0.0308470
[Epoch 96; Iter   300/  960] train: loss: 0.0013045
[Epoch 96; Iter   330/  960] train: loss: 0.0142816
[Epoch 96; Iter   360/  960] train: loss: 0.0103880
[Epoch 96; Iter   390/  960] train: loss: 0.0026654
[Epoch 96; Iter   420/  960] train: loss: 0.0027840
[Epoch 96; Iter   450/  960] train: loss: 0.0126812
[Epoch 96; Iter   480/  960] train: loss: 0.1600674
[Epoch 96; Iter   510/  960] train: loss: 0.1281768
[Epoch 96; Iter   540/  960] train: loss: 0.0049247
[Epoch 96; Iter   570/  960] train: loss: 0.0186280
[Epoch 96; Iter   600/  960] train: loss: 0.0071412
[Epoch 96; Iter   630/  960] train: loss: 0.0445728
[Epoch 96; Iter   660/  960] train: loss: 0.0811606
[Epoch 96; Iter   690/  960] train: loss: 0.0062397
[Epoch 96; Iter   720/  960] train: loss: 0.0039586
[Epoch 89; Iter   544/ 1097] train: loss: 0.0074289
[Epoch 89; Iter   574/ 1097] train: loss: 0.0235544
[Epoch 89; Iter   604/ 1097] train: loss: 0.0193464
[Epoch 89; Iter   634/ 1097] train: loss: 0.0040287
[Epoch 89; Iter   664/ 1097] train: loss: 0.0031187
[Epoch 89; Iter   694/ 1097] train: loss: 0.0018403
[Epoch 89; Iter   724/ 1097] train: loss: 0.0651565
[Epoch 89; Iter   754/ 1097] train: loss: 0.0113168
[Epoch 89; Iter   784/ 1097] train: loss: 0.0170470
[Epoch 89; Iter   814/ 1097] train: loss: 0.0015709
[Epoch 89; Iter   844/ 1097] train: loss: 0.0058782
[Epoch 89; Iter   874/ 1097] train: loss: 0.0012639
[Epoch 89; Iter   904/ 1097] train: loss: 0.0007858
[Epoch 89; Iter   934/ 1097] train: loss: 0.0023229
[Epoch 89; Iter   964/ 1097] train: loss: 0.0005225
[Epoch 89; Iter   994/ 1097] train: loss: 0.0636982
[Epoch 89; Iter  1024/ 1097] train: loss: 0.0633516
[Epoch 89; Iter  1054/ 1097] train: loss: 0.0207094
[Epoch 89; Iter  1084/ 1097] train: loss: 0.0046749
[Epoch 89] ogbg-molhiv: 0.793899 val loss: 0.131311
[Epoch 89] ogbg-molhiv: 0.756451 test loss: 0.231365
[Epoch 90; Iter    17/ 1097] train: loss: 0.0012294
[Epoch 90; Iter    47/ 1097] train: loss: 0.0273533
[Epoch 90; Iter    77/ 1097] train: loss: 0.0089534
[Epoch 90; Iter   107/ 1097] train: loss: 0.0058973
[Epoch 90; Iter   137/ 1097] train: loss: 0.0033958
[Epoch 90; Iter   167/ 1097] train: loss: 0.0061504
[Epoch 90; Iter   197/ 1097] train: loss: 0.0075663
[Epoch 90; Iter   227/ 1097] train: loss: 0.0039635
[Epoch 90; Iter   257/ 1097] train: loss: 0.0184031
[Epoch 90; Iter   287/ 1097] train: loss: 0.0020266
[Epoch 90; Iter   317/ 1097] train: loss: 0.0046574
[Epoch 90; Iter   347/ 1097] train: loss: 0.0205977
[Epoch 90; Iter   377/ 1097] train: loss: 0.0005155
[Epoch 90; Iter   407/ 1097] train: loss: 0.0296794
[Epoch 90; Iter   437/ 1097] train: loss: 0.0023936
[Epoch 90; Iter   467/ 1097] train: loss: 0.0038377
[Epoch 90; Iter   497/ 1097] train: loss: 0.0056194
[Epoch 90; Iter   527/ 1097] train: loss: 0.0372351
[Epoch 90; Iter   557/ 1097] train: loss: 0.0407348
[Epoch 90; Iter   587/ 1097] train: loss: 0.0119537
[Epoch 90; Iter   617/ 1097] train: loss: 0.0021393
[Epoch 90; Iter   647/ 1097] train: loss: 0.0511731
[Epoch 90; Iter   677/ 1097] train: loss: 0.0087164
[Epoch 90; Iter   707/ 1097] train: loss: 0.0174300
[Epoch 90; Iter   737/ 1097] train: loss: 0.0595166
[Epoch 90; Iter   767/ 1097] train: loss: 0.0051750
[Epoch 90; Iter   797/ 1097] train: loss: 0.0067640
[Epoch 90; Iter   827/ 1097] train: loss: 0.0029306
[Epoch 90; Iter   857/ 1097] train: loss: 0.0486680
[Epoch 90; Iter   887/ 1097] train: loss: 0.0192916
[Epoch 90; Iter   917/ 1097] train: loss: 0.0768893
[Epoch 90; Iter   947/ 1097] train: loss: 0.0058669
[Epoch 90; Iter   977/ 1097] train: loss: 0.0044693
[Epoch 90; Iter  1007/ 1097] train: loss: 0.0089132
[Epoch 90; Iter  1037/ 1097] train: loss: 0.0117172
[Epoch 90; Iter  1067/ 1097] train: loss: 0.0019582
[Epoch 90; Iter  1097/ 1097] train: loss: 0.0184608
[Epoch 90] ogbg-molhiv: 0.800209 val loss: 0.123387
[Epoch 90] ogbg-molhiv: 0.761836 test loss: 0.229868
[Epoch 91; Iter    30/ 1097] train: loss: 0.0160561
[Epoch 91; Iter    60/ 1097] train: loss: 0.0065145
[Epoch 91; Iter    90/ 1097] train: loss: 0.0172765
[Epoch 91; Iter   120/ 1097] train: loss: 0.0066783
[Epoch 91; Iter   150/ 1097] train: loss: 0.0056252
[Epoch 91; Iter   180/ 1097] train: loss: 0.0015575
[Epoch 91; Iter   210/ 1097] train: loss: 0.0079788
[Epoch 91; Iter   240/ 1097] train: loss: 0.0599729
[Epoch 91; Iter   270/ 1097] train: loss: 0.0411445
[Epoch 91; Iter   300/ 1097] train: loss: 0.0048514
[Epoch 91; Iter   330/ 1097] train: loss: 0.0180661
[Epoch 91; Iter   360/ 1097] train: loss: 0.0015277
[Epoch 91; Iter   390/ 1097] train: loss: 0.0029344
[Epoch 91; Iter   420/ 1097] train: loss: 0.0030463
[Epoch 91; Iter   450/ 1097] train: loss: 0.0145969
[Epoch 91; Iter   480/ 1097] train: loss: 0.0016532
[Epoch 91; Iter   510/ 1097] train: loss: 0.0274492
[Epoch 91; Iter   540/ 1097] train: loss: 0.0017726
[Epoch 91; Iter   570/ 1097] train: loss: 0.0005685
[Epoch 91; Iter   600/ 1097] train: loss: 0.0032497
[Epoch 91; Iter   630/ 1097] train: loss: 0.0207163
[Epoch 91; Iter   660/ 1097] train: loss: 0.0303248
[Epoch 91; Iter   690/ 1097] train: loss: 0.0088133
[Epoch 91; Iter   720/ 1097] train: loss: 0.0029714
[Epoch 91; Iter   750/ 1097] train: loss: 0.0396684
[Epoch 91; Iter   780/ 1097] train: loss: 0.0674608
[Epoch 91; Iter   810/ 1097] train: loss: 0.0393159
[Epoch 91; Iter   840/ 1097] train: loss: 0.0010872
[Epoch 91; Iter   870/ 1097] train: loss: 0.0103944
[Epoch 91; Iter   900/ 1097] train: loss: 0.0202208
[Epoch 91; Iter   930/ 1097] train: loss: 0.0402452
[Epoch 91; Iter   960/ 1097] train: loss: 0.0473306
[Epoch 91; Iter   990/ 1097] train: loss: 0.0007494
[Epoch 91; Iter  1020/ 1097] train: loss: 0.0366424
[Epoch 91; Iter  1050/ 1097] train: loss: 0.0064710
[Epoch 91; Iter  1080/ 1097] train: loss: 0.0044611
[Epoch 91] ogbg-molhiv: 0.796266 val loss: 0.131834
[Epoch 91] ogbg-molhiv: 0.751326 test loss: 0.239503
[Epoch 92; Iter    13/ 1097] train: loss: 0.0146038
[Epoch 92; Iter    43/ 1097] train: loss: 0.0024312
[Epoch 92; Iter    73/ 1097] train: loss: 0.0063841
[Epoch 92; Iter   103/ 1097] train: loss: 0.0011264
[Epoch 92; Iter   133/ 1097] train: loss: 0.0043543
[Epoch 92; Iter   163/ 1097] train: loss: 0.0040885
[Epoch 92; Iter   193/ 1097] train: loss: 0.0683793
[Epoch 92; Iter   223/ 1097] train: loss: 0.0014966
[Epoch 92; Iter   253/ 1097] train: loss: 0.0133627
[Epoch 92; Iter   283/ 1097] train: loss: 0.0103373
[Epoch 92; Iter   313/ 1097] train: loss: 0.0056654
[Epoch 92; Iter   343/ 1097] train: loss: 0.0084140
[Epoch 92; Iter   373/ 1097] train: loss: 0.0987522
[Epoch 92; Iter   403/ 1097] train: loss: 0.0026557
[Epoch 92; Iter   433/ 1097] train: loss: 0.0035060
[Epoch 92; Iter   463/ 1097] train: loss: 0.0274063
[Epoch 92; Iter   493/ 1097] train: loss: 0.0085243
[Epoch 92; Iter   523/ 1097] train: loss: 0.0026333
[Epoch 92; Iter   553/ 1097] train: loss: 0.0158211
[Epoch 92; Iter   583/ 1097] train: loss: 0.0076849
[Epoch 92; Iter   613/ 1097] train: loss: 0.0447418
[Epoch 92; Iter   643/ 1097] train: loss: 0.0011029
[Epoch 92; Iter   673/ 1097] train: loss: 0.0779202
[Epoch 92; Iter   703/ 1097] train: loss: 0.1350327
[Epoch 92; Iter   733/ 1097] train: loss: 0.0031520
[Epoch 92; Iter   763/ 1097] train: loss: 0.0083396
[Epoch 92; Iter   793/ 1097] train: loss: 0.0046879
[Epoch 92; Iter   823/ 1097] train: loss: 0.0061260
[Epoch 92; Iter   853/ 1097] train: loss: 0.0100722
[Epoch 92; Iter   883/ 1097] train: loss: 0.0531558
[Epoch 92; Iter   913/ 1097] train: loss: 0.0018527
[Epoch 92; Iter   943/ 1097] train: loss: 0.0062596
[Epoch 92; Iter   973/ 1097] train: loss: 0.0063683
[Epoch 92; Iter  1003/ 1097] train: loss: 0.0016517
[Epoch 92; Iter  1033/ 1097] train: loss: 0.0044774
[Epoch 92; Iter  1063/ 1097] train: loss: 0.0125569
[Epoch 92; Iter  1093/ 1097] train: loss: 0.0026715
[Epoch 92] ogbg-molhiv: 0.801205 val loss: 0.130309
[Epoch 92] ogbg-molhiv: 0.751567 test loss: 0.243314
[Epoch 93; Iter    26/ 1097] train: loss: 0.0017531
[Epoch 93; Iter    56/ 1097] train: loss: 0.0010607
[Epoch 93; Iter    86/ 1097] train: loss: 0.0077068
[Epoch 93; Iter   116/ 1097] train: loss: 0.0077819
[Epoch 93; Iter   146/ 1097] train: loss: 0.0114304
[Epoch 93; Iter   176/ 1097] train: loss: 0.0015760
[Epoch 93; Iter   206/ 1097] train: loss: 0.0022913
[Epoch 93; Iter   236/ 1097] train: loss: 0.0112828
[Epoch 93; Iter   266/ 1097] train: loss: 0.0146582
[Epoch 93; Iter   296/ 1097] train: loss: 0.0008454
[Epoch 93; Iter   326/ 1097] train: loss: 0.0185258
[Epoch 93; Iter   356/ 1097] train: loss: 0.0308549
[Epoch 93; Iter   386/ 1097] train: loss: 0.0120795
[Epoch 93; Iter   416/ 1097] train: loss: 0.0054018
[Epoch 93; Iter   446/ 1097] train: loss: 0.0012334
[Epoch 93; Iter   476/ 1097] train: loss: 0.0030008
[Epoch 93; Iter   506/ 1097] train: loss: 0.0053577
[Epoch 93; Iter   536/ 1097] train: loss: 0.0032603
[Epoch 93; Iter   566/ 1097] train: loss: 0.0019401
[Epoch 93; Iter   596/ 1097] train: loss: 0.0041209
[Epoch 95; Iter   488/  823] train: loss: 0.0271320
[Epoch 95; Iter   518/  823] train: loss: 0.0188145
[Epoch 95; Iter   548/  823] train: loss: 0.0011518
[Epoch 95; Iter   578/  823] train: loss: 0.0201146
[Epoch 95; Iter   608/  823] train: loss: 0.0026546
[Epoch 95; Iter   638/  823] train: loss: 0.0362453
[Epoch 95; Iter   668/  823] train: loss: 0.0008554
[Epoch 95; Iter   698/  823] train: loss: 0.0133865
[Epoch 95; Iter   728/  823] train: loss: 0.0063285
[Epoch 95; Iter   758/  823] train: loss: 0.0031072
[Epoch 95; Iter   788/  823] train: loss: 0.0042134
[Epoch 95; Iter   818/  823] train: loss: 0.0047102
[Epoch 95] ogbg-molhiv: 0.738641 val loss: 0.320178
[Epoch 95] ogbg-molhiv: 0.759052 test loss: 0.256606
[Epoch 96; Iter    25/  823] train: loss: 0.0017773
[Epoch 96; Iter    55/  823] train: loss: 0.0045855
[Epoch 96; Iter    85/  823] train: loss: 0.0007987
[Epoch 96; Iter   115/  823] train: loss: 0.0088897
[Epoch 96; Iter   145/  823] train: loss: 0.0006321
[Epoch 96; Iter   175/  823] train: loss: 0.0352180
[Epoch 96; Iter   205/  823] train: loss: 0.0099060
[Epoch 96; Iter   235/  823] train: loss: 0.0143084
[Epoch 96; Iter   265/  823] train: loss: 0.0045813
[Epoch 96; Iter   295/  823] train: loss: 0.0006010
[Epoch 96; Iter   325/  823] train: loss: 0.0676133
[Epoch 96; Iter   355/  823] train: loss: 0.0034339
[Epoch 96; Iter   385/  823] train: loss: 0.0328511
[Epoch 96; Iter   415/  823] train: loss: 0.0406944
[Epoch 96; Iter   445/  823] train: loss: 0.0398692
[Epoch 96; Iter   475/  823] train: loss: 0.0044190
[Epoch 96; Iter   505/  823] train: loss: 0.0040453
[Epoch 96; Iter   535/  823] train: loss: 0.0001582
[Epoch 96; Iter   565/  823] train: loss: 0.0031660
[Epoch 96; Iter   595/  823] train: loss: 0.0006606
[Epoch 96; Iter   625/  823] train: loss: 0.0017666
[Epoch 96; Iter   655/  823] train: loss: 0.0114627
[Epoch 96; Iter   685/  823] train: loss: 0.0044855
[Epoch 96; Iter   715/  823] train: loss: 0.0084196
[Epoch 96; Iter   745/  823] train: loss: 0.0285712
[Epoch 96; Iter   775/  823] train: loss: 0.0046475
[Epoch 96; Iter   805/  823] train: loss: 0.0030277
[Epoch 96] ogbg-molhiv: 0.736777 val loss: 0.349046
[Epoch 96] ogbg-molhiv: 0.753179 test loss: 0.293701
[Epoch 97; Iter    12/  823] train: loss: 0.0032272
[Epoch 97; Iter    42/  823] train: loss: 0.0029590
[Epoch 97; Iter    72/  823] train: loss: 0.0240180
[Epoch 97; Iter   102/  823] train: loss: 0.0014862
[Epoch 97; Iter   132/  823] train: loss: 0.0231933
[Epoch 97; Iter   162/  823] train: loss: 0.0118694
[Epoch 97; Iter   192/  823] train: loss: 0.0004490
[Epoch 97; Iter   222/  823] train: loss: 0.0302621
[Epoch 97; Iter   252/  823] train: loss: 0.0003496
[Epoch 97; Iter   282/  823] train: loss: 0.0030242
[Epoch 97; Iter   312/  823] train: loss: 0.0008651
[Epoch 97; Iter   342/  823] train: loss: 0.0024762
[Epoch 97; Iter   372/  823] train: loss: 0.0207284
[Epoch 97; Iter   402/  823] train: loss: 0.0019049
[Epoch 97; Iter   432/  823] train: loss: 0.0025776
[Epoch 97; Iter   462/  823] train: loss: 0.0039062
[Epoch 97; Iter   492/  823] train: loss: 0.0008374
[Epoch 97; Iter   522/  823] train: loss: 0.0228127
[Epoch 97; Iter   552/  823] train: loss: 0.0764784
[Epoch 97; Iter   582/  823] train: loss: 0.0092502
[Epoch 97; Iter   612/  823] train: loss: 0.0010604
[Epoch 97; Iter   642/  823] train: loss: 0.0925507
[Epoch 97; Iter   672/  823] train: loss: 0.0001989
[Epoch 97; Iter   702/  823] train: loss: 0.0034024
[Epoch 97; Iter   732/  823] train: loss: 0.0016784
[Epoch 97; Iter   762/  823] train: loss: 0.0070650
[Epoch 97; Iter   792/  823] train: loss: 0.0003841
[Epoch 97; Iter   822/  823] train: loss: 0.0167265
[Epoch 97] ogbg-molhiv: 0.744335 val loss: 0.359045
[Epoch 97] ogbg-molhiv: 0.757835 test loss: 0.298765
[Epoch 98; Iter    29/  823] train: loss: 0.0086382
[Epoch 98; Iter    59/  823] train: loss: 0.0045662
[Epoch 98; Iter    89/  823] train: loss: 0.0368149
[Epoch 98; Iter   119/  823] train: loss: 0.0020825
[Epoch 98; Iter   149/  823] train: loss: 0.0088566
[Epoch 98; Iter   179/  823] train: loss: 0.0212526
[Epoch 98; Iter   209/  823] train: loss: 0.0088633
[Epoch 98; Iter   239/  823] train: loss: 0.0042553
[Epoch 98; Iter   269/  823] train: loss: 0.0005995
[Epoch 98; Iter   299/  823] train: loss: 0.0029309
[Epoch 98; Iter   329/  823] train: loss: 0.0011989
[Epoch 98; Iter   359/  823] train: loss: 0.0011632
[Epoch 98; Iter   389/  823] train: loss: 0.1376713
[Epoch 98; Iter   419/  823] train: loss: 0.0024240
[Epoch 98; Iter   449/  823] train: loss: 0.0439314
[Epoch 98; Iter   479/  823] train: loss: 0.0444519
[Epoch 98; Iter   509/  823] train: loss: 0.0033319
[Epoch 98; Iter   539/  823] train: loss: 0.1058281
[Epoch 98; Iter   569/  823] train: loss: 0.0499902
[Epoch 98; Iter   599/  823] train: loss: 0.0010761
[Epoch 98; Iter   629/  823] train: loss: 0.0029503
[Epoch 98; Iter   659/  823] train: loss: 0.1875639
[Epoch 98; Iter   689/  823] train: loss: 0.0086131
[Epoch 98; Iter   719/  823] train: loss: 0.0015267
[Epoch 98; Iter   749/  823] train: loss: 0.0010291
[Epoch 98; Iter   779/  823] train: loss: 0.0019401
[Epoch 98; Iter   809/  823] train: loss: 0.0084203
[Epoch 98] ogbg-molhiv: 0.739515 val loss: 0.286668
[Epoch 98] ogbg-molhiv: 0.759934 test loss: 0.209381
[Epoch 99; Iter    16/  823] train: loss: 0.0013897
[Epoch 99; Iter    46/  823] train: loss: 0.0089385
[Epoch 99; Iter    76/  823] train: loss: 0.0010843
[Epoch 99; Iter   106/  823] train: loss: 0.0058660
[Epoch 99; Iter   136/  823] train: loss: 0.0055995
[Epoch 99; Iter   166/  823] train: loss: 0.0005810
[Epoch 99; Iter   196/  823] train: loss: 0.0010494
[Epoch 99; Iter   226/  823] train: loss: 0.0051661
[Epoch 99; Iter   256/  823] train: loss: 0.0027008
[Epoch 99; Iter   286/  823] train: loss: 0.0027712
[Epoch 99; Iter   316/  823] train: loss: 0.1295362
[Epoch 99; Iter   346/  823] train: loss: 0.0011302
[Epoch 99; Iter   376/  823] train: loss: 0.0007378
[Epoch 99; Iter   406/  823] train: loss: 0.0922543
[Epoch 99; Iter   436/  823] train: loss: 0.0340861
[Epoch 99; Iter   466/  823] train: loss: 0.0014912
[Epoch 99; Iter   496/  823] train: loss: 0.0002310
[Epoch 99; Iter   526/  823] train: loss: 0.0064304
[Epoch 99; Iter   556/  823] train: loss: 0.0808740
[Epoch 99; Iter   586/  823] train: loss: 0.0506600
[Epoch 99; Iter   616/  823] train: loss: 0.0071336
[Epoch 99; Iter   646/  823] train: loss: 0.0012082
[Epoch 99; Iter   676/  823] train: loss: 0.0050581
[Epoch 99; Iter   706/  823] train: loss: 0.0127678
[Epoch 99; Iter   736/  823] train: loss: 0.1684973
[Epoch 99; Iter   766/  823] train: loss: 0.0030170
[Epoch 99; Iter   796/  823] train: loss: 0.0012311
[Epoch 99] ogbg-molhiv: 0.741430 val loss: 0.332067
[Epoch 99] ogbg-molhiv: 0.759504 test loss: 0.271756
[Epoch 100; Iter     3/  823] train: loss: 0.0025741
[Epoch 100; Iter    33/  823] train: loss: 0.0096029
[Epoch 100; Iter    63/  823] train: loss: 0.0800004
[Epoch 100; Iter    93/  823] train: loss: 0.0093914
[Epoch 100; Iter   123/  823] train: loss: 0.0280909
[Epoch 100; Iter   153/  823] train: loss: 0.0065405
[Epoch 100; Iter   183/  823] train: loss: 0.0015487
[Epoch 100; Iter   213/  823] train: loss: 0.0002647
[Epoch 100; Iter   243/  823] train: loss: 0.0040485
[Epoch 100; Iter   273/  823] train: loss: 0.0090785
[Epoch 100; Iter   303/  823] train: loss: 0.0379575
[Epoch 100; Iter   333/  823] train: loss: 0.0019176
[Epoch 100; Iter   363/  823] train: loss: 0.0027449
[Epoch 100; Iter   393/  823] train: loss: 0.0239573
[Epoch 100; Iter   423/  823] train: loss: 0.0019697
[Epoch 100; Iter   453/  823] train: loss: 0.0354276
[Epoch 100; Iter   483/  823] train: loss: 0.0007264
[Epoch 100; Iter   513/  823] train: loss: 0.0010266
[Epoch 100; Iter   543/  823] train: loss: 0.0010489
[Epoch 100; Iter   573/  823] train: loss: 0.0002550
[Epoch 100; Iter   603/  823] train: loss: 0.0003717
[Epoch 100; Iter   633/  823] train: loss: 0.0127077
[Epoch 100; Iter   663/  823] train: loss: 0.0007304
[Epoch 100; Iter   693/  823] train: loss: 0.0129425
[Epoch 100; Iter   723/  823] train: loss: 0.0556917
[Epoch 93; Iter   626/ 1097] train: loss: 0.0040210
[Epoch 93; Iter   656/ 1097] train: loss: 0.0049282
[Epoch 93; Iter   686/ 1097] train: loss: 0.0002832
[Epoch 93; Iter   716/ 1097] train: loss: 0.1057496
[Epoch 93; Iter   746/ 1097] train: loss: 0.0030214
[Epoch 93; Iter   776/ 1097] train: loss: 0.0077997
[Epoch 93; Iter   806/ 1097] train: loss: 0.0274684
[Epoch 93; Iter   836/ 1097] train: loss: 0.0034389
[Epoch 93; Iter   866/ 1097] train: loss: 0.0007149
[Epoch 93; Iter   896/ 1097] train: loss: 0.0273722
[Epoch 93; Iter   926/ 1097] train: loss: 0.0158754
[Epoch 93; Iter   956/ 1097] train: loss: 0.0045420
[Epoch 93; Iter   986/ 1097] train: loss: 0.0008484
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0802895
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0066613
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0079450
[Epoch 93] ogbg-molhiv: 0.756871 val loss: 0.196721
[Epoch 93] ogbg-molhiv: 0.742158 test loss: 0.431906
[Epoch 94; Iter     9/ 1097] train: loss: 0.0559016
[Epoch 94; Iter    39/ 1097] train: loss: 0.0045137
[Epoch 94; Iter    69/ 1097] train: loss: 0.0023266
[Epoch 94; Iter    99/ 1097] train: loss: 0.0289565
[Epoch 94; Iter   129/ 1097] train: loss: 0.0051001
[Epoch 94; Iter   159/ 1097] train: loss: 0.0052954
[Epoch 94; Iter   189/ 1097] train: loss: 0.0038026
[Epoch 94; Iter   219/ 1097] train: loss: 0.0336859
[Epoch 94; Iter   249/ 1097] train: loss: 0.0070607
[Epoch 94; Iter   279/ 1097] train: loss: 0.0052410
[Epoch 94; Iter   309/ 1097] train: loss: 0.0176945
[Epoch 94; Iter   339/ 1097] train: loss: 0.0138200
[Epoch 94; Iter   369/ 1097] train: loss: 0.0353203
[Epoch 94; Iter   399/ 1097] train: loss: 0.0086706
[Epoch 94; Iter   429/ 1097] train: loss: 0.0113792
[Epoch 94; Iter   459/ 1097] train: loss: 0.0791917
[Epoch 94; Iter   489/ 1097] train: loss: 0.0129976
[Epoch 94; Iter   519/ 1097] train: loss: 0.0041430
[Epoch 94; Iter   549/ 1097] train: loss: 0.0075213
[Epoch 94; Iter   579/ 1097] train: loss: 0.0029976
[Epoch 94; Iter   609/ 1097] train: loss: 0.1172555
[Epoch 94; Iter   639/ 1097] train: loss: 0.0130101
[Epoch 94; Iter   669/ 1097] train: loss: 0.0414336
[Epoch 94; Iter   699/ 1097] train: loss: 0.0028701
[Epoch 94; Iter   729/ 1097] train: loss: 0.0064983
[Epoch 94; Iter   759/ 1097] train: loss: 0.0086705
[Epoch 94; Iter   789/ 1097] train: loss: 0.0397723
[Epoch 94; Iter   819/ 1097] train: loss: 0.0012257
[Epoch 94; Iter   849/ 1097] train: loss: 0.0205014
[Epoch 94; Iter   879/ 1097] train: loss: 0.0596400
[Epoch 94; Iter   909/ 1097] train: loss: 0.0030523
[Epoch 94; Iter   939/ 1097] train: loss: 0.0592461
[Epoch 94; Iter   969/ 1097] train: loss: 0.0274222
[Epoch 94; Iter   999/ 1097] train: loss: 0.0232404
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0234650
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0489947
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0198534
[Epoch 94] ogbg-molhiv: 0.763457 val loss: 0.144395
[Epoch 94] ogbg-molhiv: 0.727534 test loss: 0.270165
[Epoch 95; Iter    22/ 1097] train: loss: 0.0190764
[Epoch 95; Iter    52/ 1097] train: loss: 0.0108051
[Epoch 95; Iter    82/ 1097] train: loss: 0.0209089
[Epoch 95; Iter   112/ 1097] train: loss: 0.0035235
[Epoch 95; Iter   142/ 1097] train: loss: 0.0498017
[Epoch 95; Iter   172/ 1097] train: loss: 0.0128122
[Epoch 95; Iter   202/ 1097] train: loss: 0.0222409
[Epoch 95; Iter   232/ 1097] train: loss: 0.0376961
[Epoch 95; Iter   262/ 1097] train: loss: 0.0039851
[Epoch 95; Iter   292/ 1097] train: loss: 0.0049375
[Epoch 95; Iter   322/ 1097] train: loss: 0.0010005
[Epoch 95; Iter   352/ 1097] train: loss: 0.0516750
[Epoch 95; Iter   382/ 1097] train: loss: 0.0368473
[Epoch 95; Iter   412/ 1097] train: loss: 0.0061900
[Epoch 95; Iter   442/ 1097] train: loss: 0.0031084
[Epoch 95; Iter   472/ 1097] train: loss: 0.0150970
[Epoch 95; Iter   502/ 1097] train: loss: 0.0078418
[Epoch 95; Iter   532/ 1097] train: loss: 0.0042000
[Epoch 95; Iter   562/ 1097] train: loss: 0.1284122
[Epoch 95; Iter   592/ 1097] train: loss: 0.0019775
[Epoch 95; Iter   622/ 1097] train: loss: 0.2990876
[Epoch 95; Iter   652/ 1097] train: loss: 0.1535280
[Epoch 95; Iter   682/ 1097] train: loss: 0.0109275
[Epoch 95; Iter   712/ 1097] train: loss: 0.0212849
[Epoch 95; Iter   742/ 1097] train: loss: 0.0021885
[Epoch 95; Iter   772/ 1097] train: loss: 0.0883273
[Epoch 95; Iter   802/ 1097] train: loss: 0.0016954
[Epoch 95; Iter   832/ 1097] train: loss: 0.0040923
[Epoch 95; Iter   862/ 1097] train: loss: 0.0035150
[Epoch 95; Iter   892/ 1097] train: loss: 0.0194493
[Epoch 95; Iter   922/ 1097] train: loss: 0.0762006
[Epoch 95; Iter   952/ 1097] train: loss: 0.0421643
[Epoch 95; Iter   982/ 1097] train: loss: 0.0098568
[Epoch 95; Iter  1012/ 1097] train: loss: 0.3639955
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0010536
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0035430
[Epoch 95] ogbg-molhiv: 0.757447 val loss: 0.330785
[Epoch 95] ogbg-molhiv: 0.730881 test loss: 0.956789
[Epoch 96; Iter     5/ 1097] train: loss: 0.0040226
[Epoch 96; Iter    35/ 1097] train: loss: 0.0055874
[Epoch 96; Iter    65/ 1097] train: loss: 0.0152763
[Epoch 96; Iter    95/ 1097] train: loss: 0.0025961
[Epoch 96; Iter   125/ 1097] train: loss: 0.0319714
[Epoch 96; Iter   155/ 1097] train: loss: 0.0110382
[Epoch 96; Iter   185/ 1097] train: loss: 0.0067077
[Epoch 96; Iter   215/ 1097] train: loss: 0.0474930
[Epoch 96; Iter   245/ 1097] train: loss: 0.0517636
[Epoch 96; Iter   275/ 1097] train: loss: 0.0014604
[Epoch 96; Iter   305/ 1097] train: loss: 0.0269406
[Epoch 96; Iter   335/ 1097] train: loss: 0.0093600
[Epoch 96; Iter   365/ 1097] train: loss: 0.0698020
[Epoch 96; Iter   395/ 1097] train: loss: 0.0138735
[Epoch 96; Iter   425/ 1097] train: loss: 0.0078673
[Epoch 96; Iter   455/ 1097] train: loss: 0.0019609
[Epoch 96; Iter   485/ 1097] train: loss: 0.1355581
[Epoch 96; Iter   515/ 1097] train: loss: 0.0204928
[Epoch 96; Iter   545/ 1097] train: loss: 0.0056595
[Epoch 96; Iter   575/ 1097] train: loss: 0.0572496
[Epoch 96; Iter   605/ 1097] train: loss: 0.0132669
[Epoch 96; Iter   635/ 1097] train: loss: 0.0031202
[Epoch 96; Iter   665/ 1097] train: loss: 0.0079532
[Epoch 96; Iter   695/ 1097] train: loss: 0.0235731
[Epoch 96; Iter   725/ 1097] train: loss: 0.0116643
[Epoch 96; Iter   755/ 1097] train: loss: 0.0177841
[Epoch 96; Iter   785/ 1097] train: loss: 0.0034879
[Epoch 96; Iter   815/ 1097] train: loss: 0.0005651
[Epoch 96; Iter   845/ 1097] train: loss: 0.0313525
[Epoch 96; Iter   875/ 1097] train: loss: 0.0272498
[Epoch 96; Iter   905/ 1097] train: loss: 0.0217692
[Epoch 96; Iter   935/ 1097] train: loss: 0.0482787
[Epoch 96; Iter   965/ 1097] train: loss: 0.0150245
[Epoch 96; Iter   995/ 1097] train: loss: 0.0039771
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0489507
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0046377
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0117682
[Epoch 96] ogbg-molhiv: 0.760689 val loss: 0.250059
[Epoch 96] ogbg-molhiv: 0.735879 test loss: 0.522324
[Epoch 97; Iter    18/ 1097] train: loss: 0.0549601
[Epoch 97; Iter    48/ 1097] train: loss: 0.0134100
[Epoch 97; Iter    78/ 1097] train: loss: 0.0136717
[Epoch 97; Iter   108/ 1097] train: loss: 0.0261716
[Epoch 97; Iter   138/ 1097] train: loss: 0.0013912
[Epoch 97; Iter   168/ 1097] train: loss: 0.0008036
[Epoch 97; Iter   198/ 1097] train: loss: 0.0135799
[Epoch 97; Iter   228/ 1097] train: loss: 0.0013314
[Epoch 97; Iter   258/ 1097] train: loss: 0.0015464
[Epoch 97; Iter   288/ 1097] train: loss: 0.0131796
[Epoch 97; Iter   318/ 1097] train: loss: 0.0054743
[Epoch 97; Iter   348/ 1097] train: loss: 0.0553369
[Epoch 97; Iter   378/ 1097] train: loss: 0.0028366
[Epoch 97; Iter   408/ 1097] train: loss: 0.0057172
[Epoch 97; Iter   438/ 1097] train: loss: 0.0314202
[Epoch 97; Iter   468/ 1097] train: loss: 0.0360863
[Epoch 97; Iter   498/ 1097] train: loss: 0.0161369
[Epoch 97; Iter   528/ 1097] train: loss: 0.0054735
[Epoch 97; Iter   558/ 1097] train: loss: 0.0224545
[Epoch 97; Iter   588/ 1097] train: loss: 0.0025964
[Epoch 97; Iter   618/ 1097] train: loss: 0.0056543
[Epoch 97; Iter   648/ 1097] train: loss: 0.1260618
[Epoch 97; Iter   678/ 1097] train: loss: 0.0011710
[Epoch 93; Iter   626/ 1097] train: loss: 0.0091133
[Epoch 93; Iter   656/ 1097] train: loss: 0.0534212
[Epoch 93; Iter   686/ 1097] train: loss: 0.0052640
[Epoch 93; Iter   716/ 1097] train: loss: 0.0138102
[Epoch 93; Iter   746/ 1097] train: loss: 0.0183408
[Epoch 93; Iter   776/ 1097] train: loss: 0.0085296
[Epoch 93; Iter   806/ 1097] train: loss: 0.0037186
[Epoch 93; Iter   836/ 1097] train: loss: 0.0020765
[Epoch 93; Iter   866/ 1097] train: loss: 0.0121515
[Epoch 93; Iter   896/ 1097] train: loss: 0.0212688
[Epoch 93; Iter   926/ 1097] train: loss: 0.0067633
[Epoch 93; Iter   956/ 1097] train: loss: 0.0209712
[Epoch 93; Iter   986/ 1097] train: loss: 0.0143949
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0382420
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0021891
[Epoch 93; Iter  1076/ 1097] train: loss: 0.1759560
[Epoch 93] ogbg-molhiv: 0.775102 val loss: 0.161396
[Epoch 93] ogbg-molhiv: 0.733367 test loss: 0.215809
[Epoch 94; Iter     9/ 1097] train: loss: 0.0194422
[Epoch 94; Iter    39/ 1097] train: loss: 0.0112886
[Epoch 94; Iter    69/ 1097] train: loss: 0.0114513
[Epoch 94; Iter    99/ 1097] train: loss: 0.0011736
[Epoch 94; Iter   129/ 1097] train: loss: 0.0019808
[Epoch 94; Iter   159/ 1097] train: loss: 0.0114864
[Epoch 94; Iter   189/ 1097] train: loss: 0.0208756
[Epoch 94; Iter   219/ 1097] train: loss: 0.0365284
[Epoch 94; Iter   249/ 1097] train: loss: 0.0083681
[Epoch 94; Iter   279/ 1097] train: loss: 0.0373887
[Epoch 94; Iter   309/ 1097] train: loss: 0.0062660
[Epoch 94; Iter   339/ 1097] train: loss: 0.0030794
[Epoch 94; Iter   369/ 1097] train: loss: 0.1161450
[Epoch 94; Iter   399/ 1097] train: loss: 0.0156461
[Epoch 94; Iter   429/ 1097] train: loss: 0.0219764
[Epoch 94; Iter   459/ 1097] train: loss: 0.0343191
[Epoch 94; Iter   489/ 1097] train: loss: 0.0262177
[Epoch 94; Iter   519/ 1097] train: loss: 0.0958207
[Epoch 94; Iter   549/ 1097] train: loss: 0.0583064
[Epoch 94; Iter   579/ 1097] train: loss: 0.0279182
[Epoch 94; Iter   609/ 1097] train: loss: 0.0036601
[Epoch 94; Iter   639/ 1097] train: loss: 0.0859630
[Epoch 94; Iter   669/ 1097] train: loss: 0.1312509
[Epoch 94; Iter   699/ 1097] train: loss: 0.0193911
[Epoch 94; Iter   729/ 1097] train: loss: 0.1060700
[Epoch 94; Iter   759/ 1097] train: loss: 0.0064032
[Epoch 94; Iter   789/ 1097] train: loss: 0.0446032
[Epoch 94; Iter   819/ 1097] train: loss: 0.0766658
[Epoch 94; Iter   849/ 1097] train: loss: 0.0062441
[Epoch 94; Iter   879/ 1097] train: loss: 0.0885663
[Epoch 94; Iter   909/ 1097] train: loss: 0.0192183
[Epoch 94; Iter   939/ 1097] train: loss: 0.0045794
[Epoch 94; Iter   969/ 1097] train: loss: 0.0597103
[Epoch 94; Iter   999/ 1097] train: loss: 0.0156797
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0273574
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0146595
[Epoch 94; Iter  1089/ 1097] train: loss: 0.1547859
[Epoch 94] ogbg-molhiv: 0.771167 val loss: 0.153176
[Epoch 94] ogbg-molhiv: 0.731387 test loss: 0.226958
[Epoch 95; Iter    22/ 1097] train: loss: 0.0173966
[Epoch 95; Iter    52/ 1097] train: loss: 0.0148278
[Epoch 95; Iter    82/ 1097] train: loss: 0.0032981
[Epoch 95; Iter   112/ 1097] train: loss: 0.0232265
[Epoch 95; Iter   142/ 1097] train: loss: 0.0025284
[Epoch 95; Iter   172/ 1097] train: loss: 0.0038483
[Epoch 95; Iter   202/ 1097] train: loss: 0.0393952
[Epoch 95; Iter   232/ 1097] train: loss: 0.0339674
[Epoch 95; Iter   262/ 1097] train: loss: 0.0116408
[Epoch 95; Iter   292/ 1097] train: loss: 0.0338755
[Epoch 95; Iter   322/ 1097] train: loss: 0.0404994
[Epoch 95; Iter   352/ 1097] train: loss: 0.0477196
[Epoch 95; Iter   382/ 1097] train: loss: 0.0161915
[Epoch 95; Iter   412/ 1097] train: loss: 0.0431724
[Epoch 95; Iter   442/ 1097] train: loss: 0.0023942
[Epoch 95; Iter   472/ 1097] train: loss: 0.0187716
[Epoch 95; Iter   502/ 1097] train: loss: 0.0855532
[Epoch 95; Iter   532/ 1097] train: loss: 0.0078236
[Epoch 95; Iter   562/ 1097] train: loss: 0.0300374
[Epoch 95; Iter   592/ 1097] train: loss: 0.0151738
[Epoch 95; Iter   622/ 1097] train: loss: 0.0138647
[Epoch 95; Iter   652/ 1097] train: loss: 0.0169276
[Epoch 95; Iter   682/ 1097] train: loss: 0.0128629
[Epoch 95; Iter   712/ 1097] train: loss: 0.0028712
[Epoch 95; Iter   742/ 1097] train: loss: 0.0137447
[Epoch 95; Iter   772/ 1097] train: loss: 0.0096937
[Epoch 95; Iter   802/ 1097] train: loss: 0.0053992
[Epoch 95; Iter   832/ 1097] train: loss: 0.0042714
[Epoch 95; Iter   862/ 1097] train: loss: 0.0605659
[Epoch 95; Iter   892/ 1097] train: loss: 0.0291654
[Epoch 95; Iter   922/ 1097] train: loss: 0.0110226
[Epoch 95; Iter   952/ 1097] train: loss: 0.1838567
[Epoch 95; Iter   982/ 1097] train: loss: 0.0179184
[Epoch 95; Iter  1012/ 1097] train: loss: 0.1007312
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0144235
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0277303
[Epoch 95] ogbg-molhiv: 0.773626 val loss: 0.150212
[Epoch 95] ogbg-molhiv: 0.720315 test loss: 0.231476
[Epoch 96; Iter     5/ 1097] train: loss: 0.0052295
[Epoch 96; Iter    35/ 1097] train: loss: 0.0113250
[Epoch 96; Iter    65/ 1097] train: loss: 0.0697549
[Epoch 96; Iter    95/ 1097] train: loss: 0.0447022
[Epoch 96; Iter   125/ 1097] train: loss: 0.0228160
[Epoch 96; Iter   155/ 1097] train: loss: 0.0208083
[Epoch 96; Iter   185/ 1097] train: loss: 0.0019552
[Epoch 96; Iter   215/ 1097] train: loss: 0.0294041
[Epoch 96; Iter   245/ 1097] train: loss: 0.0010550
[Epoch 96; Iter   275/ 1097] train: loss: 0.0937262
[Epoch 96; Iter   305/ 1097] train: loss: 0.0366978
[Epoch 96; Iter   335/ 1097] train: loss: 0.0056751
[Epoch 96; Iter   365/ 1097] train: loss: 0.0361795
[Epoch 96; Iter   395/ 1097] train: loss: 0.1286019
[Epoch 96; Iter   425/ 1097] train: loss: 0.0092684
[Epoch 96; Iter   455/ 1097] train: loss: 0.0113770
[Epoch 96; Iter   485/ 1097] train: loss: 0.0007840
[Epoch 96; Iter   515/ 1097] train: loss: 0.0234096
[Epoch 96; Iter   545/ 1097] train: loss: 0.0362505
[Epoch 96; Iter   575/ 1097] train: loss: 0.0138782
[Epoch 96; Iter   605/ 1097] train: loss: 0.0319995
[Epoch 96; Iter   635/ 1097] train: loss: 0.0241043
[Epoch 96; Iter   665/ 1097] train: loss: 0.0176226
[Epoch 96; Iter   695/ 1097] train: loss: 0.0284905
[Epoch 96; Iter   725/ 1097] train: loss: 0.0083184
[Epoch 96; Iter   755/ 1097] train: loss: 0.0081476
[Epoch 96; Iter   785/ 1097] train: loss: 0.0629898
[Epoch 96; Iter   815/ 1097] train: loss: 0.0854581
[Epoch 96; Iter   845/ 1097] train: loss: 0.0467803
[Epoch 96; Iter   875/ 1097] train: loss: 0.1295061
[Epoch 96; Iter   905/ 1097] train: loss: 0.0133113
[Epoch 96; Iter   935/ 1097] train: loss: 0.0025498
[Epoch 96; Iter   965/ 1097] train: loss: 0.0126853
[Epoch 96; Iter   995/ 1097] train: loss: 0.0155804
[Epoch 96; Iter  1025/ 1097] train: loss: 0.1322773
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0119368
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0170738
[Epoch 96] ogbg-molhiv: 0.782279 val loss: 0.134275
[Epoch 96] ogbg-molhiv: 0.725062 test loss: 0.224820
[Epoch 97; Iter    18/ 1097] train: loss: 0.0079646
[Epoch 97; Iter    48/ 1097] train: loss: 0.0029165
[Epoch 97; Iter    78/ 1097] train: loss: 0.0087679
[Epoch 97; Iter   108/ 1097] train: loss: 0.0474341
[Epoch 97; Iter   138/ 1097] train: loss: 0.0851608
[Epoch 97; Iter   168/ 1097] train: loss: 0.2035253
[Epoch 97; Iter   198/ 1097] train: loss: 0.0011627
[Epoch 97; Iter   228/ 1097] train: loss: 0.0053261
[Epoch 97; Iter   258/ 1097] train: loss: 0.0616436
[Epoch 97; Iter   288/ 1097] train: loss: 0.0150877
[Epoch 97; Iter   318/ 1097] train: loss: 0.0063174
[Epoch 97; Iter   348/ 1097] train: loss: 0.0919487
[Epoch 97; Iter   378/ 1097] train: loss: 0.0070522
[Epoch 97; Iter   408/ 1097] train: loss: 0.0639151
[Epoch 97; Iter   438/ 1097] train: loss: 0.0106589
[Epoch 97; Iter   468/ 1097] train: loss: 0.0336810
[Epoch 97; Iter   498/ 1097] train: loss: 0.0035599
[Epoch 97; Iter   528/ 1097] train: loss: 0.0212394
[Epoch 97; Iter   558/ 1097] train: loss: 0.0296246
[Epoch 97; Iter   588/ 1097] train: loss: 0.0028884
[Epoch 97; Iter   618/ 1097] train: loss: 0.0063189
[Epoch 97; Iter   648/ 1097] train: loss: 0.0433577
[Epoch 97; Iter   678/ 1097] train: loss: 0.0753524
[Epoch 96; Iter   750/  960] train: loss: 0.0016605
[Epoch 96; Iter   780/  960] train: loss: 0.0056739
[Epoch 96; Iter   810/  960] train: loss: 0.0047701
[Epoch 96; Iter   840/  960] train: loss: 0.0034542
[Epoch 96; Iter   870/  960] train: loss: 0.0008355
[Epoch 96; Iter   900/  960] train: loss: 0.1262179
[Epoch 96; Iter   930/  960] train: loss: 0.0005404
[Epoch 96; Iter   960/  960] train: loss: 0.0052382
[Epoch 96] ogbg-molhiv: 0.719708 val loss: 0.270822
[Epoch 96] ogbg-molhiv: 0.767242 test loss: 0.208159
[Epoch 97; Iter    30/  960] train: loss: 0.1563293
[Epoch 97; Iter    60/  960] train: loss: 0.0089817
[Epoch 97; Iter    90/  960] train: loss: 0.0049933
[Epoch 97; Iter   120/  960] train: loss: 0.0280447
[Epoch 97; Iter   150/  960] train: loss: 0.0056563
[Epoch 97; Iter   180/  960] train: loss: 0.0228459
[Epoch 97; Iter   210/  960] train: loss: 0.0039923
[Epoch 97; Iter   240/  960] train: loss: 0.0041742
[Epoch 97; Iter   270/  960] train: loss: 0.0659470
[Epoch 97; Iter   300/  960] train: loss: 0.1671142
[Epoch 97; Iter   330/  960] train: loss: 0.0198658
[Epoch 97; Iter   360/  960] train: loss: 0.0174566
[Epoch 97; Iter   390/  960] train: loss: 0.0018144
[Epoch 97; Iter   420/  960] train: loss: 0.0120837
[Epoch 97; Iter   450/  960] train: loss: 0.0020271
[Epoch 97; Iter   480/  960] train: loss: 0.0172580
[Epoch 97; Iter   510/  960] train: loss: 0.0353566
[Epoch 97; Iter   540/  960] train: loss: 0.0109499
[Epoch 97; Iter   570/  960] train: loss: 0.0101508
[Epoch 97; Iter   600/  960] train: loss: 0.0008227
[Epoch 97; Iter   630/  960] train: loss: 0.0145645
[Epoch 97; Iter   660/  960] train: loss: 0.0005555
[Epoch 97; Iter   690/  960] train: loss: 0.0021255
[Epoch 97; Iter   720/  960] train: loss: 0.0812515
[Epoch 97; Iter   750/  960] train: loss: 0.0014576
[Epoch 97; Iter   780/  960] train: loss: 0.0003893
[Epoch 97; Iter   810/  960] train: loss: 0.0024001
[Epoch 97; Iter   840/  960] train: loss: 0.0081173
[Epoch 97; Iter   870/  960] train: loss: 0.0016872
[Epoch 97; Iter   900/  960] train: loss: 0.0028085
[Epoch 97; Iter   930/  960] train: loss: 0.0466672
[Epoch 97; Iter   960/  960] train: loss: 0.0066955
[Epoch 97] ogbg-molhiv: 0.717851 val loss: 0.273579
[Epoch 97] ogbg-molhiv: 0.744897 test loss: 0.253283
[Epoch 98; Iter    30/  960] train: loss: 0.0011139
[Epoch 98; Iter    60/  960] train: loss: 0.0031750
[Epoch 98; Iter    90/  960] train: loss: 0.0141687
[Epoch 98; Iter   120/  960] train: loss: 0.0075874
[Epoch 98; Iter   150/  960] train: loss: 0.0032261
[Epoch 98; Iter   180/  960] train: loss: 0.0022462
[Epoch 98; Iter   210/  960] train: loss: 0.0316905
[Epoch 98; Iter   240/  960] train: loss: 0.0087109
[Epoch 98; Iter   270/  960] train: loss: 0.0018230
[Epoch 98; Iter   300/  960] train: loss: 0.1260448
[Epoch 98; Iter   330/  960] train: loss: 0.0036133
[Epoch 98; Iter   360/  960] train: loss: 0.0049053
[Epoch 98; Iter   390/  960] train: loss: 0.0201186
[Epoch 98; Iter   420/  960] train: loss: 0.0007504
[Epoch 98; Iter   450/  960] train: loss: 0.0061778
[Epoch 98; Iter   480/  960] train: loss: 0.0224944
[Epoch 98; Iter   510/  960] train: loss: 0.0001051
[Epoch 98; Iter   540/  960] train: loss: 0.0436271
[Epoch 98; Iter   570/  960] train: loss: 0.0291803
[Epoch 98; Iter   600/  960] train: loss: 0.0061136
[Epoch 98; Iter   630/  960] train: loss: 0.0008789
[Epoch 98; Iter   660/  960] train: loss: 0.0008068
[Epoch 98; Iter   690/  960] train: loss: 0.0070420
[Epoch 98; Iter   720/  960] train: loss: 0.0466067
[Epoch 98; Iter   750/  960] train: loss: 0.0010642
[Epoch 98; Iter   780/  960] train: loss: 0.0078676
[Epoch 98; Iter   810/  960] train: loss: 0.0007523
[Epoch 98; Iter   840/  960] train: loss: 0.0030493
[Epoch 98; Iter   870/  960] train: loss: 0.0130103
[Epoch 98; Iter   900/  960] train: loss: 0.0208677
[Epoch 98; Iter   930/  960] train: loss: 0.0004857
[Epoch 98; Iter   960/  960] train: loss: 0.0002734
[Epoch 98] ogbg-molhiv: 0.726400 val loss: 0.281875
[Epoch 98] ogbg-molhiv: 0.767445 test loss: 0.235298
[Epoch 99; Iter    30/  960] train: loss: 0.0003449
[Epoch 99; Iter    60/  960] train: loss: 0.0056645
[Epoch 99; Iter    90/  960] train: loss: 0.0077022
[Epoch 99; Iter   120/  960] train: loss: 0.0078009
[Epoch 99; Iter   150/  960] train: loss: 0.0139880
[Epoch 99; Iter   180/  960] train: loss: 0.0012183
[Epoch 99; Iter   210/  960] train: loss: 0.0053951
[Epoch 99; Iter   240/  960] train: loss: 0.0278478
[Epoch 99; Iter   270/  960] train: loss: 0.0240160
[Epoch 99; Iter   300/  960] train: loss: 0.0012643
[Epoch 99; Iter   330/  960] train: loss: 0.0004436
[Epoch 99; Iter   360/  960] train: loss: 0.0091025
[Epoch 99; Iter   390/  960] train: loss: 0.0034849
[Epoch 99; Iter   420/  960] train: loss: 0.0018728
[Epoch 99; Iter   450/  960] train: loss: 0.0015599
[Epoch 99; Iter   480/  960] train: loss: 0.0006811
[Epoch 99; Iter   510/  960] train: loss: 0.0161799
[Epoch 99; Iter   540/  960] train: loss: 0.0037535
[Epoch 99; Iter   570/  960] train: loss: 0.0155320
[Epoch 99; Iter   600/  960] train: loss: 0.0108848
[Epoch 99; Iter   630/  960] train: loss: 0.0012408
[Epoch 99; Iter   660/  960] train: loss: 0.0115031
[Epoch 99; Iter   690/  960] train: loss: 0.0342095
[Epoch 99; Iter   720/  960] train: loss: 0.0019149
[Epoch 99; Iter   750/  960] train: loss: 0.0916559
[Epoch 99; Iter   780/  960] train: loss: 0.0145864
[Epoch 99; Iter   810/  960] train: loss: 0.0200352
[Epoch 99; Iter   840/  960] train: loss: 0.0019538
[Epoch 99; Iter   870/  960] train: loss: 0.0850647
[Epoch 99; Iter   900/  960] train: loss: 0.0031005
[Epoch 99; Iter   930/  960] train: loss: 0.0013471
[Epoch 99; Iter   960/  960] train: loss: 0.0165535
[Epoch 99] ogbg-molhiv: 0.722304 val loss: 0.272786
[Epoch 99] ogbg-molhiv: 0.760309 test loss: 0.216061
[Epoch 100; Iter    30/  960] train: loss: 0.0171948
[Epoch 100; Iter    60/  960] train: loss: 0.0701861
[Epoch 100; Iter    90/  960] train: loss: 0.0125109
[Epoch 100; Iter   120/  960] train: loss: 0.0014568
[Epoch 100; Iter   150/  960] train: loss: 0.0007101
[Epoch 100; Iter   180/  960] train: loss: 0.0017272
[Epoch 100; Iter   210/  960] train: loss: 0.0013557
[Epoch 100; Iter   240/  960] train: loss: 0.0068935
[Epoch 100; Iter   270/  960] train: loss: 0.0591098
[Epoch 100; Iter   300/  960] train: loss: 0.0211326
[Epoch 100; Iter   330/  960] train: loss: 0.0537779
[Epoch 100; Iter   360/  960] train: loss: 0.0372616
[Epoch 100; Iter   390/  960] train: loss: 0.0032421
[Epoch 100; Iter   420/  960] train: loss: 0.0014105
[Epoch 100; Iter   450/  960] train: loss: 0.1073515
[Epoch 100; Iter   480/  960] train: loss: 0.0373569
[Epoch 100; Iter   510/  960] train: loss: 0.0528112
[Epoch 100; Iter   540/  960] train: loss: 0.0031062
[Epoch 100; Iter   570/  960] train: loss: 0.0730619
[Epoch 100; Iter   600/  960] train: loss: 0.0447428
[Epoch 100; Iter   630/  960] train: loss: 0.0033199
[Epoch 100; Iter   660/  960] train: loss: 0.0190732
[Epoch 100; Iter   690/  960] train: loss: 0.0026747
[Epoch 100; Iter   720/  960] train: loss: 0.0108648
[Epoch 100; Iter   750/  960] train: loss: 0.0013579
[Epoch 100; Iter   780/  960] train: loss: 0.0021055
[Epoch 100; Iter   810/  960] train: loss: 0.0065238
[Epoch 100; Iter   840/  960] train: loss: 0.0426350
[Epoch 100; Iter   870/  960] train: loss: 0.0033748
[Epoch 100; Iter   900/  960] train: loss: 0.0030217
[Epoch 100; Iter   930/  960] train: loss: 0.0105343
[Epoch 100; Iter   960/  960] train: loss: 0.0233360
[Epoch 100] ogbg-molhiv: 0.720642 val loss: 0.371496
[Epoch 100] ogbg-molhiv: 0.754009 test loss: 0.558528
[Epoch 101; Iter    30/  960] train: loss: 0.0087228
[Epoch 101; Iter    60/  960] train: loss: 0.0533136
[Epoch 101; Iter    90/  960] train: loss: 0.0004013
[Epoch 101; Iter   120/  960] train: loss: 0.0001171
[Epoch 101; Iter   150/  960] train: loss: 0.0018247
[Epoch 101; Iter   180/  960] train: loss: 0.0162049
[Epoch 101; Iter   210/  960] train: loss: 0.0019658
[Epoch 101; Iter   240/  960] train: loss: 0.0421873
[Epoch 101; Iter   270/  960] train: loss: 0.0040807
[Epoch 101; Iter   300/  960] train: loss: 0.0076476
[Epoch 96; Iter   750/  960] train: loss: 0.0030255
[Epoch 96; Iter   780/  960] train: loss: 0.0567638
[Epoch 96; Iter   810/  960] train: loss: 0.0235409
[Epoch 96; Iter   840/  960] train: loss: 0.0603996
[Epoch 96; Iter   870/  960] train: loss: 0.0320336
[Epoch 96; Iter   900/  960] train: loss: 0.0383945
[Epoch 96; Iter   930/  960] train: loss: 0.0018720
[Epoch 96; Iter   960/  960] train: loss: 0.0014916
[Epoch 96] ogbg-molhiv: 0.756474 val loss: 1.109732
[Epoch 96] ogbg-molhiv: 0.752786 test loss: 0.269111
[Epoch 97; Iter    30/  960] train: loss: 0.1593341
[Epoch 97; Iter    60/  960] train: loss: 0.0037908
[Epoch 97; Iter    90/  960] train: loss: 0.1240605
[Epoch 97; Iter   120/  960] train: loss: 0.0030516
[Epoch 97; Iter   150/  960] train: loss: 0.0015796
[Epoch 97; Iter   180/  960] train: loss: 0.0034618
[Epoch 97; Iter   210/  960] train: loss: 0.0039440
[Epoch 97; Iter   240/  960] train: loss: 0.0085370
[Epoch 97; Iter   270/  960] train: loss: 0.0241934
[Epoch 97; Iter   300/  960] train: loss: 0.0254475
[Epoch 97; Iter   330/  960] train: loss: 0.0021895
[Epoch 97; Iter   360/  960] train: loss: 0.0016580
[Epoch 97; Iter   390/  960] train: loss: 0.0335430
[Epoch 97; Iter   420/  960] train: loss: 0.0007852
[Epoch 97; Iter   450/  960] train: loss: 0.0006993
[Epoch 97; Iter   480/  960] train: loss: 0.0154055
[Epoch 97; Iter   510/  960] train: loss: 0.0246914
[Epoch 97; Iter   540/  960] train: loss: 0.0431973
[Epoch 97; Iter   570/  960] train: loss: 0.0510498
[Epoch 97; Iter   600/  960] train: loss: 0.0146224
[Epoch 97; Iter   630/  960] train: loss: 0.0037291
[Epoch 97; Iter   660/  960] train: loss: 0.0006777
[Epoch 97; Iter   690/  960] train: loss: 0.0158679
[Epoch 97; Iter   720/  960] train: loss: 0.0188026
[Epoch 97; Iter   750/  960] train: loss: 0.1695956
[Epoch 97; Iter   780/  960] train: loss: 0.0016886
[Epoch 97; Iter   810/  960] train: loss: 0.0047410
[Epoch 97; Iter   840/  960] train: loss: 0.1045566
[Epoch 97; Iter   870/  960] train: loss: 0.0096273
[Epoch 97; Iter   900/  960] train: loss: 0.0461761
[Epoch 97; Iter   930/  960] train: loss: 0.0042936
[Epoch 97; Iter   960/  960] train: loss: 0.0010836
[Epoch 97] ogbg-molhiv: 0.754959 val loss: 1.189042
[Epoch 97] ogbg-molhiv: 0.753140 test loss: 0.322339
[Epoch 98; Iter    30/  960] train: loss: 0.0025158
[Epoch 98; Iter    60/  960] train: loss: 0.0019150
[Epoch 98; Iter    90/  960] train: loss: 0.0035920
[Epoch 98; Iter   120/  960] train: loss: 0.0290671
[Epoch 98; Iter   150/  960] train: loss: 0.0129529
[Epoch 98; Iter   180/  960] train: loss: 0.0631495
[Epoch 98; Iter   210/  960] train: loss: 0.0015394
[Epoch 98; Iter   240/  960] train: loss: 0.0462016
[Epoch 98; Iter   270/  960] train: loss: 0.0032169
[Epoch 98; Iter   300/  960] train: loss: 0.0388004
[Epoch 98; Iter   330/  960] train: loss: 0.0315152
[Epoch 98; Iter   360/  960] train: loss: 0.0041752
[Epoch 98; Iter   390/  960] train: loss: 0.0029494
[Epoch 98; Iter   420/  960] train: loss: 0.0277599
[Epoch 98; Iter   450/  960] train: loss: 0.0389488
[Epoch 98; Iter   480/  960] train: loss: 0.0019189
[Epoch 98; Iter   510/  960] train: loss: 0.0031646
[Epoch 98; Iter   540/  960] train: loss: 0.0015887
[Epoch 98; Iter   570/  960] train: loss: 0.0320183
[Epoch 98; Iter   600/  960] train: loss: 0.0042961
[Epoch 98; Iter   630/  960] train: loss: 0.0106997
[Epoch 98; Iter   660/  960] train: loss: 0.0030708
[Epoch 98; Iter   690/  960] train: loss: 0.0027786
[Epoch 98; Iter   720/  960] train: loss: 0.0009731
[Epoch 98; Iter   750/  960] train: loss: 0.0043095
[Epoch 98; Iter   780/  960] train: loss: 0.0113899
[Epoch 98; Iter   810/  960] train: loss: 0.0135479
[Epoch 98; Iter   840/  960] train: loss: 0.0033198
[Epoch 98; Iter   870/  960] train: loss: 0.0088562
[Epoch 98; Iter   900/  960] train: loss: 0.0097170
[Epoch 98; Iter   930/  960] train: loss: 0.0010253
[Epoch 98; Iter   960/  960] train: loss: 0.0713369
[Epoch 98] ogbg-molhiv: 0.755959 val loss: 1.260944
[Epoch 98] ogbg-molhiv: 0.754820 test loss: 0.345381
[Epoch 99; Iter    30/  960] train: loss: 0.0194140
[Epoch 99; Iter    60/  960] train: loss: 0.0041087
[Epoch 99; Iter    90/  960] train: loss: 0.0029872
[Epoch 99; Iter   120/  960] train: loss: 0.0567666
[Epoch 99; Iter   150/  960] train: loss: 0.0030975
[Epoch 99; Iter   180/  960] train: loss: 0.0104781
[Epoch 99; Iter   210/  960] train: loss: 0.0034289
[Epoch 99; Iter   240/  960] train: loss: 0.0033439
[Epoch 99; Iter   270/  960] train: loss: 0.0048794
[Epoch 99; Iter   300/  960] train: loss: 0.0183290
[Epoch 99; Iter   330/  960] train: loss: 0.0087180
[Epoch 99; Iter   360/  960] train: loss: 0.0067410
[Epoch 99; Iter   390/  960] train: loss: 0.0044504
[Epoch 99; Iter   420/  960] train: loss: 0.0062215
[Epoch 99; Iter   450/  960] train: loss: 0.0048946
[Epoch 99; Iter   480/  960] train: loss: 0.0420672
[Epoch 99; Iter   510/  960] train: loss: 0.0019553
[Epoch 99; Iter   540/  960] train: loss: 0.0061431
[Epoch 99; Iter   570/  960] train: loss: 0.0106154
[Epoch 99; Iter   600/  960] train: loss: 0.0035297
[Epoch 99; Iter   630/  960] train: loss: 0.0399512
[Epoch 99; Iter   660/  960] train: loss: 0.0027733
[Epoch 99; Iter   690/  960] train: loss: 0.0433420
[Epoch 99; Iter   720/  960] train: loss: 0.0422855
[Epoch 99; Iter   750/  960] train: loss: 0.0170173
[Epoch 99; Iter   780/  960] train: loss: 0.0015544
[Epoch 99; Iter   810/  960] train: loss: 0.0035210
[Epoch 99; Iter   840/  960] train: loss: 0.0037933
[Epoch 99; Iter   870/  960] train: loss: 0.0124691
[Epoch 99; Iter   900/  960] train: loss: 0.0024087
[Epoch 99; Iter   930/  960] train: loss: 0.0153015
[Epoch 99; Iter   960/  960] train: loss: 0.0079487
[Epoch 99] ogbg-molhiv: 0.758408 val loss: 1.129317
[Epoch 99] ogbg-molhiv: 0.758725 test loss: 0.307587
[Epoch 100; Iter    30/  960] train: loss: 0.0522219
[Epoch 100; Iter    60/  960] train: loss: 0.0140506
[Epoch 100; Iter    90/  960] train: loss: 0.0007319
[Epoch 100; Iter   120/  960] train: loss: 0.0006258
[Epoch 100; Iter   150/  960] train: loss: 0.0693189
[Epoch 100; Iter   180/  960] train: loss: 0.0027283
[Epoch 100; Iter   210/  960] train: loss: 0.0023240
[Epoch 100; Iter   240/  960] train: loss: 0.0041502
[Epoch 100; Iter   270/  960] train: loss: 0.0013208
[Epoch 100; Iter   300/  960] train: loss: 0.0347549
[Epoch 100; Iter   330/  960] train: loss: 0.0520375
[Epoch 100; Iter   360/  960] train: loss: 0.2202249
[Epoch 100; Iter   390/  960] train: loss: 0.0013465
[Epoch 100; Iter   420/  960] train: loss: 0.0223239
[Epoch 100; Iter   450/  960] train: loss: 0.0246341
[Epoch 100; Iter   480/  960] train: loss: 0.0009176
[Epoch 100; Iter   510/  960] train: loss: 0.0492322
[Epoch 100; Iter   540/  960] train: loss: 0.0142864
[Epoch 100; Iter   570/  960] train: loss: 0.0240805
[Epoch 100; Iter   600/  960] train: loss: 0.0007961
[Epoch 100; Iter   630/  960] train: loss: 0.0364403
[Epoch 100; Iter   660/  960] train: loss: 0.0012153
[Epoch 100; Iter   690/  960] train: loss: 0.0006771
[Epoch 100; Iter   720/  960] train: loss: 0.0056114
[Epoch 100; Iter   750/  960] train: loss: 0.0181982
[Epoch 100; Iter   780/  960] train: loss: 0.0013460
[Epoch 100; Iter   810/  960] train: loss: 0.0179593
[Epoch 100; Iter   840/  960] train: loss: 0.0516908
[Epoch 100; Iter   870/  960] train: loss: 0.0107910
[Epoch 100; Iter   900/  960] train: loss: 0.0477176
[Epoch 100; Iter   930/  960] train: loss: 0.0013308
[Epoch 100; Iter   960/  960] train: loss: 0.0027893
[Epoch 100] ogbg-molhiv: 0.757547 val loss: 1.039903
[Epoch 100] ogbg-molhiv: 0.747835 test loss: 0.240170
[Epoch 101; Iter    30/  960] train: loss: 0.0013361
[Epoch 101; Iter    60/  960] train: loss: 0.0085442
[Epoch 101; Iter    90/  960] train: loss: 0.0014880
[Epoch 101; Iter   120/  960] train: loss: 0.0064021
[Epoch 101; Iter   150/  960] train: loss: 0.0512100
[Epoch 101; Iter   180/  960] train: loss: 0.0273684
[Epoch 101; Iter   210/  960] train: loss: 0.0087166
[Epoch 101; Iter   240/  960] train: loss: 0.0256617
[Epoch 101; Iter   270/  960] train: loss: 0.0124024
[Epoch 101; Iter   300/  960] train: loss: 0.0371157
[Epoch 100; Iter   753/  823] train: loss: 0.0235803
[Epoch 100; Iter   783/  823] train: loss: 0.0348318
[Epoch 100; Iter   813/  823] train: loss: 0.0035192
[Epoch 100] ogbg-molhiv: 0.747862 val loss: 0.263341
[Epoch 100] ogbg-molhiv: 0.754563 test loss: 0.251390
[Epoch 101; Iter    20/  823] train: loss: 0.0475308
[Epoch 101; Iter    50/  823] train: loss: 0.0254474
[Epoch 101; Iter    80/  823] train: loss: 0.0076864
[Epoch 101; Iter   110/  823] train: loss: 0.0033046
[Epoch 101; Iter   140/  823] train: loss: 0.0650310
[Epoch 101; Iter   170/  823] train: loss: 0.0179570
[Epoch 101; Iter   200/  823] train: loss: 0.0018395
[Epoch 101; Iter   230/  823] train: loss: 0.0027082
[Epoch 101; Iter   260/  823] train: loss: 0.0228992
[Epoch 101; Iter   290/  823] train: loss: 0.0050843
[Epoch 101; Iter   320/  823] train: loss: 0.0261554
[Epoch 101; Iter   350/  823] train: loss: 0.0083510
[Epoch 101; Iter   380/  823] train: loss: 0.0684211
[Epoch 101; Iter   410/  823] train: loss: 0.0081322
[Epoch 101; Iter   440/  823] train: loss: 0.0017017
[Epoch 101; Iter   470/  823] train: loss: 0.0109101
[Epoch 101; Iter   500/  823] train: loss: 0.0013978
[Epoch 101; Iter   530/  823] train: loss: 0.0010743
[Epoch 101; Iter   560/  823] train: loss: 0.0031366
[Epoch 101; Iter   590/  823] train: loss: 0.0329789
[Epoch 101; Iter   620/  823] train: loss: 0.0339099
[Epoch 101; Iter   650/  823] train: loss: 0.0081883
[Epoch 101; Iter   680/  823] train: loss: 0.0231116
[Epoch 101; Iter   710/  823] train: loss: 0.0178041
[Epoch 101; Iter   740/  823] train: loss: 0.0083681
[Epoch 101; Iter   770/  823] train: loss: 0.0056136
[Epoch 101; Iter   800/  823] train: loss: 0.0042301
[Epoch 101] ogbg-molhiv: 0.741777 val loss: 0.257373
[Epoch 101] ogbg-molhiv: 0.751083 test loss: 0.250860
[Epoch 102; Iter     7/  823] train: loss: 0.0034130
[Epoch 102; Iter    37/  823] train: loss: 0.0025288
[Epoch 102; Iter    67/  823] train: loss: 0.0139807
[Epoch 102; Iter    97/  823] train: loss: 0.0200628
[Epoch 102; Iter   127/  823] train: loss: 0.0094612
[Epoch 102; Iter   157/  823] train: loss: 0.0128580
[Epoch 102; Iter   187/  823] train: loss: 0.0148851
[Epoch 102; Iter   217/  823] train: loss: 0.0016309
[Epoch 102; Iter   247/  823] train: loss: 0.0214895
[Epoch 102; Iter   277/  823] train: loss: 0.0018420
[Epoch 102; Iter   307/  823] train: loss: 0.0154804
[Epoch 102; Iter   337/  823] train: loss: 0.0012535
[Epoch 102; Iter   367/  823] train: loss: 0.0340055
[Epoch 102; Iter   397/  823] train: loss: 0.0048439
[Epoch 102; Iter   427/  823] train: loss: 0.0287969
[Epoch 102; Iter   457/  823] train: loss: 0.0033838
[Epoch 102; Iter   487/  823] train: loss: 0.0377166
[Epoch 102; Iter   517/  823] train: loss: 0.0020772
[Epoch 102; Iter   547/  823] train: loss: 0.0092146
[Epoch 102; Iter   577/  823] train: loss: 0.0126971
[Epoch 102; Iter   607/  823] train: loss: 0.0159621
[Epoch 102; Iter   637/  823] train: loss: 0.0032577
[Epoch 102; Iter   667/  823] train: loss: 0.0055948
[Epoch 102; Iter   697/  823] train: loss: 0.0039919
[Epoch 102; Iter   727/  823] train: loss: 0.0569026
[Epoch 102; Iter   757/  823] train: loss: 0.0201002
[Epoch 102; Iter   787/  823] train: loss: 0.0046230
[Epoch 102; Iter   817/  823] train: loss: 0.0047640
[Epoch 102] ogbg-molhiv: 0.745743 val loss: 0.279275
[Epoch 102] ogbg-molhiv: 0.751341 test loss: 0.306161
[Epoch 103; Iter    24/  823] train: loss: 0.0012930
[Epoch 103; Iter    54/  823] train: loss: 0.0492093
[Epoch 103; Iter    84/  823] train: loss: 0.0320212
[Epoch 103; Iter   114/  823] train: loss: 0.0022877
[Epoch 103; Iter   144/  823] train: loss: 0.0021818
[Epoch 103; Iter   174/  823] train: loss: 0.0362901
[Epoch 103; Iter   204/  823] train: loss: 0.0124256
[Epoch 103; Iter   234/  823] train: loss: 0.0191118
[Epoch 103; Iter   264/  823] train: loss: 0.0025541
[Epoch 103; Iter   294/  823] train: loss: 0.0299501
[Epoch 103; Iter   324/  823] train: loss: 0.0082511
[Epoch 103; Iter   354/  823] train: loss: 0.0136950
[Epoch 103; Iter   384/  823] train: loss: 0.0317593
[Epoch 103; Iter   414/  823] train: loss: 0.0679939
[Epoch 103; Iter   444/  823] train: loss: 0.0116837
[Epoch 103; Iter   474/  823] train: loss: 0.0166338
[Epoch 103; Iter   504/  823] train: loss: 0.1209229
[Epoch 103; Iter   534/  823] train: loss: 0.0405938
[Epoch 103; Iter   564/  823] train: loss: 0.0610836
[Epoch 103; Iter   594/  823] train: loss: 0.0024725
[Epoch 103; Iter   624/  823] train: loss: 0.0062926
[Epoch 103; Iter   654/  823] train: loss: 0.0233682
[Epoch 103; Iter   684/  823] train: loss: 0.0362167
[Epoch 103; Iter   714/  823] train: loss: 0.0803504
[Epoch 103; Iter   744/  823] train: loss: 0.1152612
[Epoch 103; Iter   774/  823] train: loss: 0.0239410
[Epoch 103; Iter   804/  823] train: loss: 0.0162319
[Epoch 103] ogbg-molhiv: 0.744128 val loss: 0.262990
[Epoch 103] ogbg-molhiv: 0.758450 test loss: 0.190483
[Epoch 104; Iter    11/  823] train: loss: 0.0708520
[Epoch 104; Iter    41/  823] train: loss: 0.0063888
[Epoch 104; Iter    71/  823] train: loss: 0.0064030
[Epoch 104; Iter   101/  823] train: loss: 0.0025781
[Epoch 104; Iter   131/  823] train: loss: 0.0018799
[Epoch 104; Iter   161/  823] train: loss: 0.0055198
[Epoch 104; Iter   191/  823] train: loss: 0.0514697
[Epoch 104; Iter   221/  823] train: loss: 0.0812751
[Epoch 104; Iter   251/  823] train: loss: 0.1188259
[Epoch 104; Iter   281/  823] train: loss: 0.0198556
[Epoch 104; Iter   311/  823] train: loss: 0.0363111
[Epoch 104; Iter   341/  823] train: loss: 0.0774592
[Epoch 104; Iter   371/  823] train: loss: 0.0023122
[Epoch 104; Iter   401/  823] train: loss: 0.0150501
[Epoch 104; Iter   431/  823] train: loss: 0.0024062
[Epoch 104; Iter   461/  823] train: loss: 0.0120251
[Epoch 104; Iter   491/  823] train: loss: 0.0174121
[Epoch 104; Iter   521/  823] train: loss: 0.0135479
[Epoch 104; Iter   551/  823] train: loss: 0.0009443
[Epoch 104; Iter   581/  823] train: loss: 0.0105205
[Epoch 104; Iter   611/  823] train: loss: 0.0039674
[Epoch 104; Iter   641/  823] train: loss: 0.0085231
[Epoch 104; Iter   671/  823] train: loss: 0.0034932
[Epoch 104; Iter   701/  823] train: loss: 0.0033265
[Epoch 104; Iter   731/  823] train: loss: 0.0134099
[Epoch 104; Iter   761/  823] train: loss: 0.0218202
[Epoch 104; Iter   791/  823] train: loss: 0.0443075
[Epoch 104; Iter   821/  823] train: loss: 0.0019830
[Epoch 104] ogbg-molhiv: 0.742834 val loss: 0.270262
[Epoch 104] ogbg-molhiv: 0.748661 test loss: 0.220047
[Epoch 105; Iter    28/  823] train: loss: 0.0049890
[Epoch 105; Iter    58/  823] train: loss: 0.0080209
[Epoch 105; Iter    88/  823] train: loss: 0.0653007
[Epoch 105; Iter   118/  823] train: loss: 0.0119016
[Epoch 105; Iter   148/  823] train: loss: 0.0183673
[Epoch 105; Iter   178/  823] train: loss: 0.0704196
[Epoch 105; Iter   208/  823] train: loss: 0.0015862
[Epoch 105; Iter   238/  823] train: loss: 0.0016840
[Epoch 105; Iter   268/  823] train: loss: 0.0281664
[Epoch 105; Iter   298/  823] train: loss: 0.0037266
[Epoch 105; Iter   328/  823] train: loss: 0.0263402
[Epoch 105; Iter   358/  823] train: loss: 0.0598895
[Epoch 105; Iter   388/  823] train: loss: 0.0073290
[Epoch 105; Iter   418/  823] train: loss: 0.0070102
[Epoch 105; Iter   448/  823] train: loss: 0.0046715
[Epoch 105; Iter   478/  823] train: loss: 0.0594557
[Epoch 105; Iter   508/  823] train: loss: 0.0093979
[Epoch 105; Iter   538/  823] train: loss: 0.0536376
[Epoch 105; Iter   568/  823] train: loss: 0.0078966
[Epoch 105; Iter   598/  823] train: loss: 0.0008818
[Epoch 105; Iter   628/  823] train: loss: 0.0208786
[Epoch 105; Iter   658/  823] train: loss: 0.0056986
[Epoch 105; Iter   688/  823] train: loss: 0.0441404
[Epoch 105; Iter   718/  823] train: loss: 0.0050842
[Epoch 105; Iter   748/  823] train: loss: 0.1188441
[Epoch 105; Iter   778/  823] train: loss: 0.0026555
[Epoch 105; Iter   808/  823] train: loss: 0.0401362
[Epoch 105] ogbg-molhiv: 0.750471 val loss: 0.264404
[Epoch 105] ogbg-molhiv: 0.749913 test loss: 0.234893
[Epoch 106; Iter    15/  823] train: loss: 0.0585540
[Epoch 106; Iter    45/  823] train: loss: 0.0412211
[Epoch 96; Iter   750/  960] train: loss: 0.0150038
[Epoch 96; Iter   780/  960] train: loss: 0.0795836
[Epoch 96; Iter   810/  960] train: loss: 0.0065743
[Epoch 96; Iter   840/  960] train: loss: 0.0104456
[Epoch 96; Iter   870/  960] train: loss: 0.0080409
[Epoch 96; Iter   900/  960] train: loss: 0.0162783
[Epoch 96; Iter   930/  960] train: loss: 0.0019392
[Epoch 96; Iter   960/  960] train: loss: 0.0717466
[Epoch 96] ogbg-molhiv: 0.714376 val loss: 0.681668
[Epoch 96] ogbg-molhiv: 0.735094 test loss: 0.500492
[Epoch 97; Iter    30/  960] train: loss: 0.0090171
[Epoch 97; Iter    60/  960] train: loss: 0.0026882
[Epoch 97; Iter    90/  960] train: loss: 0.0018776
[Epoch 97; Iter   120/  960] train: loss: 0.0014466
[Epoch 97; Iter   150/  960] train: loss: 0.0018133
[Epoch 97; Iter   180/  960] train: loss: 0.0312534
[Epoch 97; Iter   210/  960] train: loss: 0.0011444
[Epoch 97; Iter   240/  960] train: loss: 0.0185317
[Epoch 97; Iter   270/  960] train: loss: 0.0056907
[Epoch 97; Iter   300/  960] train: loss: 0.0026269
[Epoch 97; Iter   330/  960] train: loss: 0.0818856
[Epoch 97; Iter   360/  960] train: loss: 0.0294839
[Epoch 97; Iter   390/  960] train: loss: 0.0018042
[Epoch 97; Iter   420/  960] train: loss: 0.0004082
[Epoch 97; Iter   450/  960] train: loss: 0.1099495
[Epoch 97; Iter   480/  960] train: loss: 0.0085970
[Epoch 97; Iter   510/  960] train: loss: 0.0014053
[Epoch 97; Iter   540/  960] train: loss: 0.0413275
[Epoch 97; Iter   570/  960] train: loss: 0.0158261
[Epoch 97; Iter   600/  960] train: loss: 0.0069657
[Epoch 97; Iter   630/  960] train: loss: 0.0078340
[Epoch 97; Iter   660/  960] train: loss: 0.0041803
[Epoch 97; Iter   690/  960] train: loss: 0.0035781
[Epoch 97; Iter   720/  960] train: loss: 0.0184643
[Epoch 97; Iter   750/  960] train: loss: 0.0006661
[Epoch 97; Iter   780/  960] train: loss: 0.0593155
[Epoch 97; Iter   810/  960] train: loss: 0.0357899
[Epoch 97; Iter   840/  960] train: loss: 0.0012597
[Epoch 97; Iter   870/  960] train: loss: 0.0053335
[Epoch 97; Iter   900/  960] train: loss: 0.0241704
[Epoch 97; Iter   930/  960] train: loss: 0.0454492
[Epoch 97; Iter   960/  960] train: loss: 0.0004097
[Epoch 97] ogbg-molhiv: 0.723426 val loss: 0.804494
[Epoch 97] ogbg-molhiv: 0.747678 test loss: 0.638016
[Epoch 98; Iter    30/  960] train: loss: 0.0263202
[Epoch 98; Iter    60/  960] train: loss: 0.0179866
[Epoch 98; Iter    90/  960] train: loss: 0.0154606
[Epoch 98; Iter   120/  960] train: loss: 0.0016503
[Epoch 98; Iter   150/  960] train: loss: 0.0512323
[Epoch 98; Iter   180/  960] train: loss: 0.0033624
[Epoch 98; Iter   210/  960] train: loss: 0.0124616
[Epoch 98; Iter   240/  960] train: loss: 0.0059602
[Epoch 98; Iter   270/  960] train: loss: 0.0045861
[Epoch 98; Iter   300/  960] train: loss: 0.1143755
[Epoch 98; Iter   330/  960] train: loss: 0.0118731
[Epoch 98; Iter   360/  960] train: loss: 0.0139815
[Epoch 98; Iter   390/  960] train: loss: 0.0008960
[Epoch 98; Iter   420/  960] train: loss: 0.0111877
[Epoch 98; Iter   450/  960] train: loss: 0.0258203
[Epoch 98; Iter   480/  960] train: loss: 0.0238363
[Epoch 98; Iter   510/  960] train: loss: 0.0086219
[Epoch 98; Iter   540/  960] train: loss: 0.0005966
[Epoch 98; Iter   570/  960] train: loss: 0.0033847
[Epoch 98; Iter   600/  960] train: loss: 0.0069748
[Epoch 98; Iter   630/  960] train: loss: 0.0022452
[Epoch 98; Iter   660/  960] train: loss: 0.0051325
[Epoch 98; Iter   690/  960] train: loss: 0.0298517
[Epoch 98; Iter   720/  960] train: loss: 0.1272584
[Epoch 98; Iter   750/  960] train: loss: 0.0071489
[Epoch 98; Iter   780/  960] train: loss: 0.0175827
[Epoch 98; Iter   810/  960] train: loss: 0.0003196
[Epoch 98; Iter   840/  960] train: loss: 0.0016113
[Epoch 98; Iter   870/  960] train: loss: 0.0108177
[Epoch 98; Iter   900/  960] train: loss: 0.0014536
[Epoch 98; Iter   930/  960] train: loss: 0.0153979
[Epoch 98; Iter   960/  960] train: loss: 0.0749281
[Epoch 98] ogbg-molhiv: 0.725887 val loss: 0.960078
[Epoch 98] ogbg-molhiv: 0.748162 test loss: 0.699190
[Epoch 99; Iter    30/  960] train: loss: 0.0260911
[Epoch 99; Iter    60/  960] train: loss: 0.0051723
[Epoch 99; Iter    90/  960] train: loss: 0.0467213
[Epoch 99; Iter   120/  960] train: loss: 0.0115703
[Epoch 99; Iter   150/  960] train: loss: 0.0204646
[Epoch 99; Iter   180/  960] train: loss: 0.0116565
[Epoch 99; Iter   210/  960] train: loss: 0.0223563
[Epoch 99; Iter   240/  960] train: loss: 0.0033134
[Epoch 99; Iter   270/  960] train: loss: 0.0025737
[Epoch 99; Iter   300/  960] train: loss: 0.0335664
[Epoch 99; Iter   330/  960] train: loss: 0.0153086
[Epoch 99; Iter   360/  960] train: loss: 0.0232543
[Epoch 99; Iter   390/  960] train: loss: 0.0023018
[Epoch 99; Iter   420/  960] train: loss: 0.0509313
[Epoch 99; Iter   450/  960] train: loss: 0.0021488
[Epoch 99; Iter   480/  960] train: loss: 0.0136430
[Epoch 99; Iter   510/  960] train: loss: 0.0918575
[Epoch 99; Iter   540/  960] train: loss: 0.0080933
[Epoch 99; Iter   570/  960] train: loss: 0.0113636
[Epoch 99; Iter   600/  960] train: loss: 0.0821572
[Epoch 99; Iter   630/  960] train: loss: 0.0545104
[Epoch 99; Iter   660/  960] train: loss: 0.2618994
[Epoch 99; Iter   690/  960] train: loss: 0.0010903
[Epoch 99; Iter   720/  960] train: loss: 0.0243122
[Epoch 99; Iter   750/  960] train: loss: 0.0235167
[Epoch 99; Iter   780/  960] train: loss: 0.0044071
[Epoch 99; Iter   810/  960] train: loss: 0.0123165
[Epoch 99; Iter   840/  960] train: loss: 0.0314663
[Epoch 99; Iter   870/  960] train: loss: 0.0169833
[Epoch 99; Iter   900/  960] train: loss: 0.0080898
[Epoch 99; Iter   930/  960] train: loss: 0.0121773
[Epoch 99; Iter   960/  960] train: loss: 0.0020442
[Epoch 99] ogbg-molhiv: 0.723285 val loss: 0.937821
[Epoch 99] ogbg-molhiv: 0.754526 test loss: 0.623493
[Epoch 100; Iter    30/  960] train: loss: 0.0013163
[Epoch 100; Iter    60/  960] train: loss: 0.0116413
[Epoch 100; Iter    90/  960] train: loss: 0.0055963
[Epoch 100; Iter   120/  960] train: loss: 0.0324811
[Epoch 100; Iter   150/  960] train: loss: 0.0182350
[Epoch 100; Iter   180/  960] train: loss: 0.0016985
[Epoch 100; Iter   210/  960] train: loss: 0.0008754
[Epoch 100; Iter   240/  960] train: loss: 0.0050062
[Epoch 100; Iter   270/  960] train: loss: 0.0143850
[Epoch 100; Iter   300/  960] train: loss: 0.0301092
[Epoch 100; Iter   330/  960] train: loss: 0.0020353
[Epoch 100; Iter   360/  960] train: loss: 0.0038693
[Epoch 100; Iter   390/  960] train: loss: 0.0011013
[Epoch 100; Iter   420/  960] train: loss: 0.0040048
[Epoch 100; Iter   450/  960] train: loss: 0.0209644
[Epoch 100; Iter   480/  960] train: loss: 0.0016703
[Epoch 100; Iter   510/  960] train: loss: 0.0368156
[Epoch 100; Iter   540/  960] train: loss: 0.0018126
[Epoch 100; Iter   570/  960] train: loss: 0.1098680
[Epoch 100; Iter   600/  960] train: loss: 0.0053204
[Epoch 100; Iter   630/  960] train: loss: 0.0368593
[Epoch 100; Iter   660/  960] train: loss: 0.0183584
[Epoch 100; Iter   690/  960] train: loss: 0.0609871
[Epoch 100; Iter   720/  960] train: loss: 0.0047671
[Epoch 100; Iter   750/  960] train: loss: 0.0083134
[Epoch 100; Iter   780/  960] train: loss: 0.0173479
[Epoch 100; Iter   810/  960] train: loss: 0.0098137
[Epoch 100; Iter   840/  960] train: loss: 0.0040576
[Epoch 100; Iter   870/  960] train: loss: 0.0014008
[Epoch 100; Iter   900/  960] train: loss: 0.0248778
[Epoch 100; Iter   930/  960] train: loss: 0.0016980
[Epoch 100; Iter   960/  960] train: loss: 0.0037758
[Epoch 100] ogbg-molhiv: 0.721027 val loss: 0.417316
[Epoch 100] ogbg-molhiv: 0.754637 test loss: 0.345768
[Epoch 101; Iter    30/  960] train: loss: 0.0013091
[Epoch 101; Iter    60/  960] train: loss: 0.0113079
[Epoch 101; Iter    90/  960] train: loss: 0.0017562
[Epoch 101; Iter   120/  960] train: loss: 0.0018767
[Epoch 101; Iter   150/  960] train: loss: 0.0169767
[Epoch 101; Iter   180/  960] train: loss: 0.0041058
[Epoch 101; Iter   210/  960] train: loss: 0.0035008
[Epoch 101; Iter   240/  960] train: loss: 0.0009790
[Epoch 101; Iter   270/  960] train: loss: 0.1415391
[Epoch 101; Iter   300/  960] train: loss: 0.0019396
[Epoch 100; Iter   753/  823] train: loss: 0.0051600
[Epoch 100; Iter   783/  823] train: loss: 0.0147720
[Epoch 100; Iter   813/  823] train: loss: 0.0013523
[Epoch 100] ogbg-molhiv: 0.708940 val loss: 0.487988
[Epoch 100] ogbg-molhiv: 0.755073 test loss: 0.242079
[Epoch 101; Iter    20/  823] train: loss: 0.0047699
[Epoch 101; Iter    50/  823] train: loss: 0.0098854
[Epoch 101; Iter    80/  823] train: loss: 0.0086581
[Epoch 101; Iter   110/  823] train: loss: 0.0008239
[Epoch 101; Iter   140/  823] train: loss: 0.0029427
[Epoch 101; Iter   170/  823] train: loss: 0.0152712
[Epoch 101; Iter   200/  823] train: loss: 0.0576284
[Epoch 101; Iter   230/  823] train: loss: 0.0373877
[Epoch 101; Iter   260/  823] train: loss: 0.0022928
[Epoch 101; Iter   290/  823] train: loss: 0.0039279
[Epoch 101; Iter   320/  823] train: loss: 0.0037165
[Epoch 101; Iter   350/  823] train: loss: 0.0023990
[Epoch 101; Iter   380/  823] train: loss: 0.0114664
[Epoch 101; Iter   410/  823] train: loss: 0.0136212
[Epoch 101; Iter   440/  823] train: loss: 0.0076799
[Epoch 101; Iter   470/  823] train: loss: 0.0077804
[Epoch 101; Iter   500/  823] train: loss: 0.0128892
[Epoch 101; Iter   530/  823] train: loss: 0.0010856
[Epoch 101; Iter   560/  823] train: loss: 0.0763464
[Epoch 101; Iter   590/  823] train: loss: 0.0080063
[Epoch 101; Iter   620/  823] train: loss: 0.0015607
[Epoch 101; Iter   650/  823] train: loss: 0.0156984
[Epoch 101; Iter   680/  823] train: loss: 0.0016264
[Epoch 101; Iter   710/  823] train: loss: 0.0071643
[Epoch 101; Iter   740/  823] train: loss: 0.0490849
[Epoch 101; Iter   770/  823] train: loss: 0.0132056
[Epoch 101; Iter   800/  823] train: loss: 0.0006344
[Epoch 101] ogbg-molhiv: 0.716132 val loss: 0.421494
[Epoch 101] ogbg-molhiv: 0.758973 test loss: 0.216472
[Epoch 102; Iter     7/  823] train: loss: 0.0028614
[Epoch 102; Iter    37/  823] train: loss: 0.0001271
[Epoch 102; Iter    67/  823] train: loss: 0.0590392
[Epoch 102; Iter    97/  823] train: loss: 0.0119083
[Epoch 102; Iter   127/  823] train: loss: 0.0013135
[Epoch 102; Iter   157/  823] train: loss: 0.0453020
[Epoch 102; Iter   187/  823] train: loss: 0.0031902
[Epoch 102; Iter   217/  823] train: loss: 0.0007953
[Epoch 102; Iter   247/  823] train: loss: 0.0282131
[Epoch 102; Iter   277/  823] train: loss: 0.0025052
[Epoch 102; Iter   307/  823] train: loss: 0.0142343
[Epoch 102; Iter   337/  823] train: loss: 0.1336153
[Epoch 102; Iter   367/  823] train: loss: 0.0026246
[Epoch 102; Iter   397/  823] train: loss: 0.0041543
[Epoch 102; Iter   427/  823] train: loss: 0.0032703
[Epoch 102; Iter   457/  823] train: loss: 0.0578777
[Epoch 102; Iter   487/  823] train: loss: 0.0016184
[Epoch 102; Iter   517/  823] train: loss: 0.0101593
[Epoch 102; Iter   547/  823] train: loss: 0.0347608
[Epoch 102; Iter   577/  823] train: loss: 0.0000982
[Epoch 102; Iter   607/  823] train: loss: 0.0035887
[Epoch 102; Iter   637/  823] train: loss: 0.0042014
[Epoch 102; Iter   667/  823] train: loss: 0.1098335
[Epoch 102; Iter   697/  823] train: loss: 0.0008659
[Epoch 102; Iter   727/  823] train: loss: 0.0009790
[Epoch 102; Iter   757/  823] train: loss: 0.0058210
[Epoch 102; Iter   787/  823] train: loss: 0.0084262
[Epoch 102; Iter   817/  823] train: loss: 0.0008209
[Epoch 102] ogbg-molhiv: 0.705006 val loss: 0.446084
[Epoch 102] ogbg-molhiv: 0.746023 test loss: 0.246301
[Epoch 103; Iter    24/  823] train: loss: 0.0032235
[Epoch 103; Iter    54/  823] train: loss: 0.0008145
[Epoch 103; Iter    84/  823] train: loss: 0.0010286
[Epoch 103; Iter   114/  823] train: loss: 0.0007579
[Epoch 103; Iter   144/  823] train: loss: 0.0006456
[Epoch 103; Iter   174/  823] train: loss: 0.0005126
[Epoch 103; Iter   204/  823] train: loss: 0.0024452
[Epoch 103; Iter   234/  823] train: loss: 0.0027607
[Epoch 103; Iter   264/  823] train: loss: 0.0095774
[Epoch 103; Iter   294/  823] train: loss: 0.0054045
[Epoch 103; Iter   324/  823] train: loss: 0.0345827
[Epoch 103; Iter   354/  823] train: loss: 0.0006936
[Epoch 103; Iter   384/  823] train: loss: 0.0303862
[Epoch 103; Iter   414/  823] train: loss: 0.2339236
[Epoch 103; Iter   444/  823] train: loss: 0.0410517
[Epoch 103; Iter   474/  823] train: loss: 0.0030000
[Epoch 103; Iter   504/  823] train: loss: 0.0010660
[Epoch 103; Iter   534/  823] train: loss: 0.0021609
[Epoch 103; Iter   564/  823] train: loss: 0.0243613
[Epoch 103; Iter   594/  823] train: loss: 0.0625743
[Epoch 103; Iter   624/  823] train: loss: 0.0028176
[Epoch 103; Iter   654/  823] train: loss: 0.0017681
[Epoch 103; Iter   684/  823] train: loss: 0.0022956
[Epoch 103; Iter   714/  823] train: loss: 0.0030733
[Epoch 103; Iter   744/  823] train: loss: 0.0040273
[Epoch 103; Iter   774/  823] train: loss: 0.0180342
[Epoch 103; Iter   804/  823] train: loss: 0.0210441
[Epoch 103] ogbg-molhiv: 0.714713 val loss: 0.437322
[Epoch 103] ogbg-molhiv: 0.750155 test loss: 0.233556
[Epoch 104; Iter    11/  823] train: loss: 0.0087843
[Epoch 104; Iter    41/  823] train: loss: 0.0924187
[Epoch 104; Iter    71/  823] train: loss: 0.0028764
[Epoch 104; Iter   101/  823] train: loss: 0.0096959
[Epoch 104; Iter   131/  823] train: loss: 0.0426606
[Epoch 104; Iter   161/  823] train: loss: 0.0380426
[Epoch 104; Iter   191/  823] train: loss: 0.0048672
[Epoch 104; Iter   221/  823] train: loss: 0.0071625
[Epoch 104; Iter   251/  823] train: loss: 0.0225181
[Epoch 104; Iter   281/  823] train: loss: 0.0023964
[Epoch 104; Iter   311/  823] train: loss: 0.0025682
[Epoch 104; Iter   341/  823] train: loss: 0.0004724
[Epoch 104; Iter   371/  823] train: loss: 0.0055156
[Epoch 104; Iter   401/  823] train: loss: 0.0469171
[Epoch 104; Iter   431/  823] train: loss: 0.0007208
[Epoch 104; Iter   461/  823] train: loss: 0.0028884
[Epoch 104; Iter   491/  823] train: loss: 0.0335747
[Epoch 104; Iter   521/  823] train: loss: 0.0061847
[Epoch 104; Iter   551/  823] train: loss: 0.0020900
[Epoch 104; Iter   581/  823] train: loss: 0.0014504
[Epoch 104; Iter   611/  823] train: loss: 0.0015029
[Epoch 104; Iter   641/  823] train: loss: 0.0142433
[Epoch 104; Iter   671/  823] train: loss: 0.0620910
[Epoch 104; Iter   701/  823] train: loss: 0.0111464
[Epoch 104; Iter   731/  823] train: loss: 0.0235783
[Epoch 104; Iter   761/  823] train: loss: 0.0029633
[Epoch 104; Iter   791/  823] train: loss: 0.0036222
[Epoch 104; Iter   821/  823] train: loss: 0.0537592
[Epoch 104] ogbg-molhiv: 0.712090 val loss: 0.419480
[Epoch 104] ogbg-molhiv: 0.745023 test loss: 0.248811
[Epoch 105; Iter    28/  823] train: loss: 0.0027414
[Epoch 105; Iter    58/  823] train: loss: 0.0028304
[Epoch 105; Iter    88/  823] train: loss: 0.0018062
[Epoch 105; Iter   118/  823] train: loss: 0.0024608
[Epoch 105; Iter   148/  823] train: loss: 0.0069487
[Epoch 105; Iter   178/  823] train: loss: 0.0342736
[Epoch 105; Iter   208/  823] train: loss: 0.0069066
[Epoch 105; Iter   238/  823] train: loss: 0.0321066
[Epoch 105; Iter   268/  823] train: loss: 0.0022704
[Epoch 105; Iter   298/  823] train: loss: 0.0023738
[Epoch 105; Iter   328/  823] train: loss: 0.0011441
[Epoch 105; Iter   358/  823] train: loss: 0.0026151
[Epoch 105; Iter   388/  823] train: loss: 0.0205276
[Epoch 105; Iter   418/  823] train: loss: 0.0270896
[Epoch 105; Iter   448/  823] train: loss: 0.0078004
[Epoch 105; Iter   478/  823] train: loss: 0.0013628
[Epoch 105; Iter   508/  823] train: loss: 0.0105165
[Epoch 105; Iter   538/  823] train: loss: 0.0002017
[Epoch 105; Iter   568/  823] train: loss: 0.0350367
[Epoch 105; Iter   598/  823] train: loss: 0.0015693
[Epoch 105; Iter   628/  823] train: loss: 0.0067761
[Epoch 105; Iter   658/  823] train: loss: 0.0013758
[Epoch 105; Iter   688/  823] train: loss: 0.0902833
[Epoch 105; Iter   718/  823] train: loss: 0.0030776
[Epoch 105; Iter   748/  823] train: loss: 0.0015113
[Epoch 105; Iter   778/  823] train: loss: 0.0786575
[Epoch 105; Iter   808/  823] train: loss: 0.0619726
[Epoch 105] ogbg-molhiv: 0.710551 val loss: 0.448478
[Epoch 105] ogbg-molhiv: 0.751473 test loss: 0.234196
[Epoch 106; Iter    15/  823] train: loss: 0.0023603
[Epoch 106; Iter    45/  823] train: loss: 0.0514215
[Epoch 93; Iter   626/ 1097] train: loss: 0.0035958
[Epoch 93; Iter   656/ 1097] train: loss: 0.0023096
[Epoch 93; Iter   686/ 1097] train: loss: 0.0069049
[Epoch 93; Iter   716/ 1097] train: loss: 0.0428496
[Epoch 93; Iter   746/ 1097] train: loss: 0.0515503
[Epoch 93; Iter   776/ 1097] train: loss: 0.0076855
[Epoch 93; Iter   806/ 1097] train: loss: 0.0915181
[Epoch 93; Iter   836/ 1097] train: loss: 0.0030894
[Epoch 93; Iter   866/ 1097] train: loss: 0.0872458
[Epoch 93; Iter   896/ 1097] train: loss: 0.0027521
[Epoch 93; Iter   926/ 1097] train: loss: 0.0103475
[Epoch 93; Iter   956/ 1097] train: loss: 0.0268125
[Epoch 93; Iter   986/ 1097] train: loss: 0.0025011
[Epoch 93; Iter  1016/ 1097] train: loss: 0.0026713
[Epoch 93; Iter  1046/ 1097] train: loss: 0.0055877
[Epoch 93; Iter  1076/ 1097] train: loss: 0.0022284
[Epoch 93] ogbg-molhiv: 0.798856 val loss: 0.127016
[Epoch 93] ogbg-molhiv: 0.758170 test loss: 0.230286
[Epoch 94; Iter     9/ 1097] train: loss: 0.0281007
[Epoch 94; Iter    39/ 1097] train: loss: 0.0026253
[Epoch 94; Iter    69/ 1097] train: loss: 0.0131049
[Epoch 94; Iter    99/ 1097] train: loss: 0.0027890
[Epoch 94; Iter   129/ 1097] train: loss: 0.0040163
[Epoch 94; Iter   159/ 1097] train: loss: 0.0067473
[Epoch 94; Iter   189/ 1097] train: loss: 0.1073457
[Epoch 94; Iter   219/ 1097] train: loss: 0.0071683
[Epoch 94; Iter   249/ 1097] train: loss: 0.0573316
[Epoch 94; Iter   279/ 1097] train: loss: 0.0739016
[Epoch 94; Iter   309/ 1097] train: loss: 0.0030061
[Epoch 94; Iter   339/ 1097] train: loss: 0.0123083
[Epoch 94; Iter   369/ 1097] train: loss: 0.0644759
[Epoch 94; Iter   399/ 1097] train: loss: 0.0008517
[Epoch 94; Iter   429/ 1097] train: loss: 0.0019443
[Epoch 94; Iter   459/ 1097] train: loss: 0.0098541
[Epoch 94; Iter   489/ 1097] train: loss: 0.0631504
[Epoch 94; Iter   519/ 1097] train: loss: 0.1168339
[Epoch 94; Iter   549/ 1097] train: loss: 0.0253960
[Epoch 94; Iter   579/ 1097] train: loss: 0.0083931
[Epoch 94; Iter   609/ 1097] train: loss: 0.0007853
[Epoch 94; Iter   639/ 1097] train: loss: 0.0031125
[Epoch 94; Iter   669/ 1097] train: loss: 0.0724918
[Epoch 94; Iter   699/ 1097] train: loss: 0.0462694
[Epoch 94; Iter   729/ 1097] train: loss: 0.0050631
[Epoch 94; Iter   759/ 1097] train: loss: 0.0013187
[Epoch 94; Iter   789/ 1097] train: loss: 0.0431765
[Epoch 94; Iter   819/ 1097] train: loss: 0.0006172
[Epoch 94; Iter   849/ 1097] train: loss: 0.0372855
[Epoch 94; Iter   879/ 1097] train: loss: 0.0344165
[Epoch 94; Iter   909/ 1097] train: loss: 0.0020914
[Epoch 94; Iter   939/ 1097] train: loss: 0.0224715
[Epoch 94; Iter   969/ 1097] train: loss: 0.0021466
[Epoch 94; Iter   999/ 1097] train: loss: 0.0068026
[Epoch 94; Iter  1029/ 1097] train: loss: 0.0086881
[Epoch 94; Iter  1059/ 1097] train: loss: 0.0033634
[Epoch 94; Iter  1089/ 1097] train: loss: 0.0125717
[Epoch 94] ogbg-molhiv: 0.789683 val loss: 0.134935
[Epoch 94] ogbg-molhiv: 0.752371 test loss: 0.246189
[Epoch 95; Iter    22/ 1097] train: loss: 0.0048758
[Epoch 95; Iter    52/ 1097] train: loss: 0.0165173
[Epoch 95; Iter    82/ 1097] train: loss: 0.2518235
[Epoch 95; Iter   112/ 1097] train: loss: 0.0013584
[Epoch 95; Iter   142/ 1097] train: loss: 0.0184774
[Epoch 95; Iter   172/ 1097] train: loss: 0.0013841
[Epoch 95; Iter   202/ 1097] train: loss: 0.1444709
[Epoch 95; Iter   232/ 1097] train: loss: 0.0225476
[Epoch 95; Iter   262/ 1097] train: loss: 0.0009302
[Epoch 95; Iter   292/ 1097] train: loss: 0.0077691
[Epoch 95; Iter   322/ 1097] train: loss: 0.0301436
[Epoch 95; Iter   352/ 1097] train: loss: 0.0129074
[Epoch 95; Iter   382/ 1097] train: loss: 0.0144588
[Epoch 95; Iter   412/ 1097] train: loss: 0.0037960
[Epoch 95; Iter   442/ 1097] train: loss: 0.0003773
[Epoch 95; Iter   472/ 1097] train: loss: 0.0079639
[Epoch 95; Iter   502/ 1097] train: loss: 0.0401444
[Epoch 95; Iter   532/ 1097] train: loss: 0.0041210
[Epoch 95; Iter   562/ 1097] train: loss: 0.0004062
[Epoch 95; Iter   592/ 1097] train: loss: 0.0092475
[Epoch 95; Iter   622/ 1097] train: loss: 0.0162537
[Epoch 95; Iter   652/ 1097] train: loss: 0.0056725
[Epoch 95; Iter   682/ 1097] train: loss: 0.0052220
[Epoch 95; Iter   712/ 1097] train: loss: 0.0020278
[Epoch 95; Iter   742/ 1097] train: loss: 0.0031509
[Epoch 95; Iter   772/ 1097] train: loss: 0.0356513
[Epoch 95; Iter   802/ 1097] train: loss: 0.0203935
[Epoch 95; Iter   832/ 1097] train: loss: 0.0222888
[Epoch 95; Iter   862/ 1097] train: loss: 0.0672717
[Epoch 95; Iter   892/ 1097] train: loss: 0.0034134
[Epoch 95; Iter   922/ 1097] train: loss: 0.0307637
[Epoch 95; Iter   952/ 1097] train: loss: 0.0118414
[Epoch 95; Iter   982/ 1097] train: loss: 0.0007025
[Epoch 95; Iter  1012/ 1097] train: loss: 0.0092332
[Epoch 95; Iter  1042/ 1097] train: loss: 0.0021072
[Epoch 95; Iter  1072/ 1097] train: loss: 0.0016942
[Epoch 95] ogbg-molhiv: 0.801440 val loss: 0.128091
[Epoch 95] ogbg-molhiv: 0.755123 test loss: 0.242109
[Epoch 96; Iter     5/ 1097] train: loss: 0.0498147
[Epoch 96; Iter    35/ 1097] train: loss: 0.0217288
[Epoch 96; Iter    65/ 1097] train: loss: 0.0071408
[Epoch 96; Iter    95/ 1097] train: loss: 0.0037241
[Epoch 96; Iter   125/ 1097] train: loss: 0.0023627
[Epoch 96; Iter   155/ 1097] train: loss: 0.0033493
[Epoch 96; Iter   185/ 1097] train: loss: 0.0051027
[Epoch 96; Iter   215/ 1097] train: loss: 0.0315237
[Epoch 96; Iter   245/ 1097] train: loss: 0.0026394
[Epoch 96; Iter   275/ 1097] train: loss: 0.0030593
[Epoch 96; Iter   305/ 1097] train: loss: 0.0069598
[Epoch 96; Iter   335/ 1097] train: loss: 0.0025415
[Epoch 96; Iter   365/ 1097] train: loss: 0.0145119
[Epoch 96; Iter   395/ 1097] train: loss: 0.0027391
[Epoch 96; Iter   425/ 1097] train: loss: 0.0575667
[Epoch 96; Iter   455/ 1097] train: loss: 0.0337458
[Epoch 96; Iter   485/ 1097] train: loss: 0.0009199
[Epoch 96; Iter   515/ 1097] train: loss: 0.0182928
[Epoch 96; Iter   545/ 1097] train: loss: 0.0130560
[Epoch 96; Iter   575/ 1097] train: loss: 0.0013332
[Epoch 96; Iter   605/ 1097] train: loss: 0.0095470
[Epoch 96; Iter   635/ 1097] train: loss: 0.0148676
[Epoch 96; Iter   665/ 1097] train: loss: 0.0013994
[Epoch 96; Iter   695/ 1097] train: loss: 0.0124970
[Epoch 96; Iter   725/ 1097] train: loss: 0.0386879
[Epoch 96; Iter   755/ 1097] train: loss: 0.0492560
[Epoch 96; Iter   785/ 1097] train: loss: 0.0034402
[Epoch 96; Iter   815/ 1097] train: loss: 0.0003165
[Epoch 96; Iter   845/ 1097] train: loss: 0.0013864
[Epoch 96; Iter   875/ 1097] train: loss: 0.0073854
[Epoch 96; Iter   905/ 1097] train: loss: 0.0179941
[Epoch 96; Iter   935/ 1097] train: loss: 0.0053682
[Epoch 96; Iter   965/ 1097] train: loss: 0.0196172
[Epoch 96; Iter   995/ 1097] train: loss: 0.0548326
[Epoch 96; Iter  1025/ 1097] train: loss: 0.0587452
[Epoch 96; Iter  1055/ 1097] train: loss: 0.0069311
[Epoch 96; Iter  1085/ 1097] train: loss: 0.0550180
[Epoch 96] ogbg-molhiv: 0.795130 val loss: 0.134653
[Epoch 96] ogbg-molhiv: 0.745244 test loss: 0.242613
[Epoch 97; Iter    18/ 1097] train: loss: 0.0354919
[Epoch 97; Iter    48/ 1097] train: loss: 0.0055991
[Epoch 97; Iter    78/ 1097] train: loss: 0.0025715
[Epoch 97; Iter   108/ 1097] train: loss: 0.0035803
[Epoch 97; Iter   138/ 1097] train: loss: 0.0026319
[Epoch 97; Iter   168/ 1097] train: loss: 0.0494380
[Epoch 97; Iter   198/ 1097] train: loss: 0.0033047
[Epoch 97; Iter   228/ 1097] train: loss: 0.0006524
[Epoch 97; Iter   258/ 1097] train: loss: 0.0005296
[Epoch 97; Iter   288/ 1097] train: loss: 0.0185931
[Epoch 97; Iter   318/ 1097] train: loss: 0.0012302
[Epoch 97; Iter   348/ 1097] train: loss: 0.0101535
[Epoch 97; Iter   378/ 1097] train: loss: 0.0218625
[Epoch 97; Iter   408/ 1097] train: loss: 0.0460727
[Epoch 97; Iter   438/ 1097] train: loss: 0.0012531
[Epoch 97; Iter   468/ 1097] train: loss: 0.0674913
[Epoch 97; Iter   498/ 1097] train: loss: 0.0138731
[Epoch 97; Iter   528/ 1097] train: loss: 0.0067571
[Epoch 97; Iter   558/ 1097] train: loss: 0.0005093
[Epoch 97; Iter   588/ 1097] train: loss: 0.0109135
[Epoch 97; Iter   618/ 1097] train: loss: 0.0100514
[Epoch 97; Iter   648/ 1097] train: loss: 0.0127436
[Epoch 97; Iter   678/ 1097] train: loss: 0.0049159
[Epoch 100; Iter   753/  823] train: loss: 0.0464364
[Epoch 100; Iter   783/  823] train: loss: 0.0004152
[Epoch 100; Iter   813/  823] train: loss: 0.1379482
[Epoch 100] ogbg-molhiv: 0.736945 val loss: 0.341095
[Epoch 100] ogbg-molhiv: 0.757279 test loss: 0.276199
[Epoch 101; Iter    20/  823] train: loss: 0.0088750
[Epoch 101; Iter    50/  823] train: loss: 0.0014481
[Epoch 101; Iter    80/  823] train: loss: 0.0017657
[Epoch 101; Iter   110/  823] train: loss: 0.0224354
[Epoch 101; Iter   140/  823] train: loss: 0.0006602
[Epoch 101; Iter   170/  823] train: loss: 0.0063206
[Epoch 101; Iter   200/  823] train: loss: 0.0483781
[Epoch 101; Iter   230/  823] train: loss: 0.0051834
[Epoch 101; Iter   260/  823] train: loss: 0.0215417
[Epoch 101; Iter   290/  823] train: loss: 0.1337631
[Epoch 101; Iter   320/  823] train: loss: 0.0084790
[Epoch 101; Iter   350/  823] train: loss: 0.0046163
[Epoch 101; Iter   380/  823] train: loss: 0.0004046
[Epoch 101; Iter   410/  823] train: loss: 0.0181322
[Epoch 101; Iter   440/  823] train: loss: 0.1465316
[Epoch 101; Iter   470/  823] train: loss: 0.0012542
[Epoch 101; Iter   500/  823] train: loss: 0.0006941
[Epoch 101; Iter   530/  823] train: loss: 0.0024378
[Epoch 101; Iter   560/  823] train: loss: 0.0042609
[Epoch 101; Iter   590/  823] train: loss: 0.0071688
[Epoch 101; Iter   620/  823] train: loss: 0.0018431
[Epoch 101; Iter   650/  823] train: loss: 0.0038673
[Epoch 101; Iter   680/  823] train: loss: 0.0231629
[Epoch 101; Iter   710/  823] train: loss: 0.0042877
[Epoch 101; Iter   740/  823] train: loss: 0.0802387
[Epoch 101; Iter   770/  823] train: loss: 0.0014856
[Epoch 101; Iter   800/  823] train: loss: 0.0041295
[Epoch 101] ogbg-molhiv: 0.736654 val loss: 0.341523
[Epoch 101] ogbg-molhiv: 0.755256 test loss: 0.280340
[Epoch 102; Iter     7/  823] train: loss: 0.0318623
[Epoch 102; Iter    37/  823] train: loss: 0.0194357
[Epoch 102; Iter    67/  823] train: loss: 0.0011214
[Epoch 102; Iter    97/  823] train: loss: 0.0360499
[Epoch 102; Iter   127/  823] train: loss: 0.0249628
[Epoch 102; Iter   157/  823] train: loss: 0.0027670
[Epoch 102; Iter   187/  823] train: loss: 0.0157163
[Epoch 102; Iter   217/  823] train: loss: 0.0434450
[Epoch 102; Iter   247/  823] train: loss: 0.0258053
[Epoch 102; Iter   277/  823] train: loss: 0.0038135
[Epoch 102; Iter   307/  823] train: loss: 0.0091437
[Epoch 102; Iter   337/  823] train: loss: 0.0003845
[Epoch 102; Iter   367/  823] train: loss: 0.0577377
[Epoch 102; Iter   397/  823] train: loss: 0.0082242
[Epoch 102; Iter   427/  823] train: loss: 0.0015745
[Epoch 102; Iter   457/  823] train: loss: 0.0014589
[Epoch 102; Iter   487/  823] train: loss: 0.0343571
[Epoch 102; Iter   517/  823] train: loss: 0.0012872
[Epoch 102; Iter   547/  823] train: loss: 0.0001610
[Epoch 102; Iter   577/  823] train: loss: 0.0019796
[Epoch 102; Iter   607/  823] train: loss: 0.0007326
[Epoch 102; Iter   637/  823] train: loss: 0.0056094
[Epoch 102; Iter   667/  823] train: loss: 0.0002588
[Epoch 102; Iter   697/  823] train: loss: 0.0525157
[Epoch 102; Iter   727/  823] train: loss: 0.0107410
[Epoch 102; Iter   757/  823] train: loss: 0.0014975
[Epoch 102; Iter   787/  823] train: loss: 0.0017813
[Epoch 102; Iter   817/  823] train: loss: 0.0471106
[Epoch 102] ogbg-molhiv: 0.737190 val loss: 0.345918
[Epoch 102] ogbg-molhiv: 0.752003 test loss: 0.294441
[Epoch 103; Iter    24/  823] train: loss: 0.0136502
[Epoch 103; Iter    54/  823] train: loss: 0.0142782
[Epoch 103; Iter    84/  823] train: loss: 0.0316005
[Epoch 103; Iter   114/  823] train: loss: 0.0303150
[Epoch 103; Iter   144/  823] train: loss: 0.0170941
[Epoch 103; Iter   174/  823] train: loss: 0.0029362
[Epoch 103; Iter   204/  823] train: loss: 0.0136928
[Epoch 103; Iter   234/  823] train: loss: 0.0017249
[Epoch 103; Iter   264/  823] train: loss: 0.0183963
[Epoch 103; Iter   294/  823] train: loss: 0.0007981
[Epoch 103; Iter   324/  823] train: loss: 0.0045803
[Epoch 103; Iter   354/  823] train: loss: 0.0027185
[Epoch 103; Iter   384/  823] train: loss: 0.0016234
[Epoch 103; Iter   414/  823] train: loss: 0.0008349
[Epoch 103; Iter   444/  823] train: loss: 0.0328022
[Epoch 103; Iter   474/  823] train: loss: 0.0031895
[Epoch 103; Iter   504/  823] train: loss: 0.0034286
[Epoch 103; Iter   534/  823] train: loss: 0.0001992
[Epoch 103; Iter   564/  823] train: loss: 0.0225084
[Epoch 103; Iter   594/  823] train: loss: 0.0844268
[Epoch 103; Iter   624/  823] train: loss: 0.0276632
[Epoch 103; Iter   654/  823] train: loss: 0.0021679
[Epoch 103; Iter   684/  823] train: loss: 0.0009222
[Epoch 103; Iter   714/  823] train: loss: 0.0624018
[Epoch 103; Iter   744/  823] train: loss: 0.0004677
[Epoch 103; Iter   774/  823] train: loss: 0.0136000
[Epoch 103; Iter   804/  823] train: loss: 0.0103901
[Epoch 103] ogbg-molhiv: 0.741223 val loss: 0.360779
[Epoch 103] ogbg-molhiv: 0.755509 test loss: 0.306928
[Epoch 104; Iter    11/  823] train: loss: 0.0014949
[Epoch 104; Iter    41/  823] train: loss: 0.0129776
[Epoch 104; Iter    71/  823] train: loss: 0.0081850
[Epoch 104; Iter   101/  823] train: loss: 0.0047095
[Epoch 104; Iter   131/  823] train: loss: 0.2799500
[Epoch 104; Iter   161/  823] train: loss: 0.0028620
[Epoch 104; Iter   191/  823] train: loss: 0.0049992
[Epoch 104; Iter   221/  823] train: loss: 0.0791079
[Epoch 104; Iter   251/  823] train: loss: 0.0036937
[Epoch 104; Iter   281/  823] train: loss: 0.0002802
[Epoch 104; Iter   311/  823] train: loss: 0.0008851
[Epoch 104; Iter   341/  823] train: loss: 0.0006993
[Epoch 104; Iter   371/  823] train: loss: 0.0350883
[Epoch 104; Iter   401/  823] train: loss: 0.0440440
[Epoch 104; Iter   431/  823] train: loss: 0.0118285
[Epoch 104; Iter   461/  823] train: loss: 0.0004412
[Epoch 104; Iter   491/  823] train: loss: 0.0033505
[Epoch 104; Iter   521/  823] train: loss: 0.1023881
[Epoch 104; Iter   551/  823] train: loss: 0.0077826
[Epoch 104; Iter   581/  823] train: loss: 0.0046796
[Epoch 104; Iter   611/  823] train: loss: 0.0004337
[Epoch 104; Iter   641/  823] train: loss: 0.0333398
[Epoch 104; Iter   671/  823] train: loss: 0.0188538
[Epoch 104; Iter   701/  823] train: loss: 0.0039702
[Epoch 104; Iter   731/  823] train: loss: 0.0005020
[Epoch 104; Iter   761/  823] train: loss: 0.0014942
[Epoch 104; Iter   791/  823] train: loss: 0.0005241
[Epoch 104; Iter   821/  823] train: loss: 0.0008650
[Epoch 104] ogbg-molhiv: 0.734625 val loss: 0.311543
[Epoch 104] ogbg-molhiv: 0.752166 test loss: 0.252590
[Epoch 105; Iter    28/  823] train: loss: 0.0179947
[Epoch 105; Iter    58/  823] train: loss: 0.0012420
[Epoch 105; Iter    88/  823] train: loss: 0.0008089
[Epoch 105; Iter   118/  823] train: loss: 0.0025150
[Epoch 105; Iter   148/  823] train: loss: 0.0014094
[Epoch 105; Iter   178/  823] train: loss: 0.0527931
[Epoch 105; Iter   208/  823] train: loss: 0.0148894
[Epoch 105; Iter   238/  823] train: loss: 0.0297837
[Epoch 105; Iter   268/  823] train: loss: 0.0089986
[Epoch 105; Iter   298/  823] train: loss: 0.0002638
[Epoch 105; Iter   328/  823] train: loss: 0.0069687
[Epoch 105; Iter   358/  823] train: loss: 0.0011104
[Epoch 105; Iter   388/  823] train: loss: 0.0514312
[Epoch 105; Iter   418/  823] train: loss: 0.0009257
[Epoch 105; Iter   448/  823] train: loss: 0.0048086
[Epoch 105; Iter   478/  823] train: loss: 0.0220056
[Epoch 105; Iter   508/  823] train: loss: 0.0121901
[Epoch 105; Iter   538/  823] train: loss: 0.0005357
[Epoch 105; Iter   568/  823] train: loss: 0.0005206
[Epoch 105; Iter   598/  823] train: loss: 0.0622951
[Epoch 105; Iter   628/  823] train: loss: 0.0701200
[Epoch 105; Iter   658/  823] train: loss: 0.0072081
[Epoch 105; Iter   688/  823] train: loss: 0.0094272
[Epoch 105; Iter   718/  823] train: loss: 0.0010622
[Epoch 105; Iter   748/  823] train: loss: 0.0010522
[Epoch 105; Iter   778/  823] train: loss: 0.0049227
[Epoch 105; Iter   808/  823] train: loss: 0.0697488
[Epoch 105] ogbg-molhiv: 0.738980 val loss: 0.327123
[Epoch 105] ogbg-molhiv: 0.753437 test loss: 0.276570
[Epoch 106; Iter    15/  823] train: loss: 0.0020685
[Epoch 106; Iter    45/  823] train: loss: 0.0006469
[Epoch 97; Iter   708/ 1097] train: loss: 0.0046142
[Epoch 97; Iter   738/ 1097] train: loss: 0.0098509
[Epoch 97; Iter   768/ 1097] train: loss: 0.0060137
[Epoch 97; Iter   798/ 1097] train: loss: 0.0420874
[Epoch 97; Iter   828/ 1097] train: loss: 0.0301797
[Epoch 97; Iter   858/ 1097] train: loss: 0.0026759
[Epoch 97; Iter   888/ 1097] train: loss: 0.0060572
[Epoch 97; Iter   918/ 1097] train: loss: 0.0055853
[Epoch 97; Iter   948/ 1097] train: loss: 0.0046557
[Epoch 97; Iter   978/ 1097] train: loss: 0.0019940
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0206670
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0084926
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0135928
[Epoch 97] ogbg-molhiv: 0.761044 val loss: 0.337228
[Epoch 97] ogbg-molhiv: 0.735217 test loss: 0.838729
[Epoch 98; Iter     1/ 1097] train: loss: 0.0352429
[Epoch 98; Iter    31/ 1097] train: loss: 0.0043351
[Epoch 98; Iter    61/ 1097] train: loss: 0.0176843
[Epoch 98; Iter    91/ 1097] train: loss: 0.0096018
[Epoch 98; Iter   121/ 1097] train: loss: 0.0185909
[Epoch 98; Iter   151/ 1097] train: loss: 0.0560476
[Epoch 98; Iter   181/ 1097] train: loss: 0.0056750
[Epoch 98; Iter   211/ 1097] train: loss: 0.0073071
[Epoch 98; Iter   241/ 1097] train: loss: 0.0036536
[Epoch 98; Iter   271/ 1097] train: loss: 0.0005183
[Epoch 98; Iter   301/ 1097] train: loss: 0.0534162
[Epoch 98; Iter   331/ 1097] train: loss: 0.0680361
[Epoch 98; Iter   361/ 1097] train: loss: 0.0035137
[Epoch 98; Iter   391/ 1097] train: loss: 0.0094053
[Epoch 98; Iter   421/ 1097] train: loss: 0.0662676
[Epoch 98; Iter   451/ 1097] train: loss: 0.0027232
[Epoch 98; Iter   481/ 1097] train: loss: 0.0102122
[Epoch 98; Iter   511/ 1097] train: loss: 0.0021142
[Epoch 98; Iter   541/ 1097] train: loss: 0.0052928
[Epoch 98; Iter   571/ 1097] train: loss: 0.0102240
[Epoch 98; Iter   601/ 1097] train: loss: 0.0041180
[Epoch 98; Iter   631/ 1097] train: loss: 0.0042075
[Epoch 98; Iter   661/ 1097] train: loss: 0.0086662
[Epoch 98; Iter   691/ 1097] train: loss: 0.0109837
[Epoch 98; Iter   721/ 1097] train: loss: 0.0082985
[Epoch 98; Iter   751/ 1097] train: loss: 0.0189526
[Epoch 98; Iter   781/ 1097] train: loss: 0.0064050
[Epoch 98; Iter   811/ 1097] train: loss: 0.0044514
[Epoch 98; Iter   841/ 1097] train: loss: 0.0153078
[Epoch 98; Iter   871/ 1097] train: loss: 0.0021381
[Epoch 98; Iter   901/ 1097] train: loss: 0.0269927
[Epoch 98; Iter   931/ 1097] train: loss: 0.0107759
[Epoch 98; Iter   961/ 1097] train: loss: 0.0093370
[Epoch 98; Iter   991/ 1097] train: loss: 0.0019322
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0382335
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0088522
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0414378
[Epoch 98] ogbg-molhiv: 0.749339 val loss: 0.169748
[Epoch 98] ogbg-molhiv: 0.737517 test loss: 0.377132
[Epoch 99; Iter    14/ 1097] train: loss: 0.0016053
[Epoch 99; Iter    44/ 1097] train: loss: 0.0241641
[Epoch 99; Iter    74/ 1097] train: loss: 0.0032085
[Epoch 99; Iter   104/ 1097] train: loss: 0.0069060
[Epoch 99; Iter   134/ 1097] train: loss: 0.0009123
[Epoch 99; Iter   164/ 1097] train: loss: 0.0118945
[Epoch 99; Iter   194/ 1097] train: loss: 0.0082396
[Epoch 99; Iter   224/ 1097] train: loss: 0.0030344
[Epoch 99; Iter   254/ 1097] train: loss: 0.0156651
[Epoch 99; Iter   284/ 1097] train: loss: 0.0841560
[Epoch 99; Iter   314/ 1097] train: loss: 0.0108897
[Epoch 99; Iter   344/ 1097] train: loss: 0.0069817
[Epoch 99; Iter   374/ 1097] train: loss: 0.0121420
[Epoch 99; Iter   404/ 1097] train: loss: 0.1800854
[Epoch 99; Iter   434/ 1097] train: loss: 0.0173197
[Epoch 99; Iter   464/ 1097] train: loss: 0.0082889
[Epoch 99; Iter   494/ 1097] train: loss: 0.0038468
[Epoch 99; Iter   524/ 1097] train: loss: 0.0021423
[Epoch 99; Iter   554/ 1097] train: loss: 0.0269720
[Epoch 99; Iter   584/ 1097] train: loss: 0.0043826
[Epoch 99; Iter   614/ 1097] train: loss: 0.0154398
[Epoch 99; Iter   644/ 1097] train: loss: 0.0070426
[Epoch 99; Iter   674/ 1097] train: loss: 0.0363187
[Epoch 99; Iter   704/ 1097] train: loss: 0.0190340
[Epoch 99; Iter   734/ 1097] train: loss: 0.0017892
[Epoch 99; Iter   764/ 1097] train: loss: 0.0132500
[Epoch 99; Iter   794/ 1097] train: loss: 0.0267201
[Epoch 99; Iter   824/ 1097] train: loss: 0.0242229
[Epoch 99; Iter   854/ 1097] train: loss: 0.0149097
[Epoch 99; Iter   884/ 1097] train: loss: 0.0018381
[Epoch 99; Iter   914/ 1097] train: loss: 0.0150813
[Epoch 99; Iter   944/ 1097] train: loss: 0.0005079
[Epoch 99; Iter   974/ 1097] train: loss: 0.0020223
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0635761
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0523183
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0414370
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0021602
[Epoch 99] ogbg-molhiv: 0.762621 val loss: 0.165027
[Epoch 99] ogbg-molhiv: 0.732438 test loss: 0.324542
[Epoch 100; Iter    27/ 1097] train: loss: 0.0085401
[Epoch 100; Iter    57/ 1097] train: loss: 0.0227695
[Epoch 100; Iter    87/ 1097] train: loss: 0.0294721
[Epoch 100; Iter   117/ 1097] train: loss: 0.0224775
[Epoch 100; Iter   147/ 1097] train: loss: 0.0016240
[Epoch 100; Iter   177/ 1097] train: loss: 0.0156862
[Epoch 100; Iter   207/ 1097] train: loss: 0.0061291
[Epoch 100; Iter   237/ 1097] train: loss: 0.0271027
[Epoch 100; Iter   267/ 1097] train: loss: 0.0005763
[Epoch 100; Iter   297/ 1097] train: loss: 0.0027551
[Epoch 100; Iter   327/ 1097] train: loss: 0.0333581
[Epoch 100; Iter   357/ 1097] train: loss: 0.0234609
[Epoch 100; Iter   387/ 1097] train: loss: 0.0132482
[Epoch 100; Iter   417/ 1097] train: loss: 0.0040506
[Epoch 100; Iter   447/ 1097] train: loss: 0.0015943
[Epoch 100; Iter   477/ 1097] train: loss: 0.1773048
[Epoch 100; Iter   507/ 1097] train: loss: 0.0144265
[Epoch 100; Iter   537/ 1097] train: loss: 0.0056781
[Epoch 100; Iter   567/ 1097] train: loss: 0.0033679
[Epoch 100; Iter   597/ 1097] train: loss: 0.0046885
[Epoch 100; Iter   627/ 1097] train: loss: 0.0327931
[Epoch 100; Iter   657/ 1097] train: loss: 0.0319651
[Epoch 100; Iter   687/ 1097] train: loss: 0.0056476
[Epoch 100; Iter   717/ 1097] train: loss: 0.0018909
[Epoch 100; Iter   747/ 1097] train: loss: 0.0867083
[Epoch 100; Iter   777/ 1097] train: loss: 0.0059263
[Epoch 100; Iter   807/ 1097] train: loss: 0.0187373
[Epoch 100; Iter   837/ 1097] train: loss: 0.0022945
[Epoch 100; Iter   867/ 1097] train: loss: 0.1048678
[Epoch 100; Iter   897/ 1097] train: loss: 0.1012712
[Epoch 100; Iter   927/ 1097] train: loss: 0.0483602
[Epoch 100; Iter   957/ 1097] train: loss: 0.0304937
[Epoch 100; Iter   987/ 1097] train: loss: 0.0190230
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0432300
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0051300
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0535772
[Epoch 100] ogbg-molhiv: 0.756060 val loss: 0.152723
[Epoch 100] ogbg-molhiv: 0.735582 test loss: 0.281371
[Epoch 101; Iter    10/ 1097] train: loss: 0.0285893
[Epoch 101; Iter    40/ 1097] train: loss: 0.0096850
[Epoch 101; Iter    70/ 1097] train: loss: 0.0388924
[Epoch 101; Iter   100/ 1097] train: loss: 0.0026846
[Epoch 101; Iter   130/ 1097] train: loss: 0.0028999
[Epoch 101; Iter   160/ 1097] train: loss: 0.0135850
[Epoch 101; Iter   190/ 1097] train: loss: 0.0678876
[Epoch 101; Iter   220/ 1097] train: loss: 0.0168371
[Epoch 101; Iter   250/ 1097] train: loss: 0.0042053
[Epoch 101; Iter   280/ 1097] train: loss: 0.0135946
[Epoch 101; Iter   310/ 1097] train: loss: 0.1938000
[Epoch 101; Iter   340/ 1097] train: loss: 0.0572893
[Epoch 101; Iter   370/ 1097] train: loss: 0.0069989
[Epoch 101; Iter   400/ 1097] train: loss: 0.0028912
[Epoch 101; Iter   430/ 1097] train: loss: 0.0066299
[Epoch 101; Iter   460/ 1097] train: loss: 0.0046374
[Epoch 101; Iter   490/ 1097] train: loss: 0.0036495
[Epoch 101; Iter   520/ 1097] train: loss: 0.0045304
[Epoch 101; Iter   550/ 1097] train: loss: 0.0018998
[Epoch 101; Iter   580/ 1097] train: loss: 0.0033016
[Epoch 101; Iter   610/ 1097] train: loss: 0.0203488
[Epoch 101; Iter   640/ 1097] train: loss: 0.1264362
[Epoch 101; Iter   670/ 1097] train: loss: 0.0008744
[Epoch 101; Iter   700/ 1097] train: loss: 0.0098964
[Epoch 101; Iter   730/ 1097] train: loss: 0.0241067
[Epoch 97; Iter   708/ 1097] train: loss: 0.0077626
[Epoch 97; Iter   738/ 1097] train: loss: 0.0944988
[Epoch 97; Iter   768/ 1097] train: loss: 0.0665566
[Epoch 97; Iter   798/ 1097] train: loss: 0.0453654
[Epoch 97; Iter   828/ 1097] train: loss: 0.0009953
[Epoch 97; Iter   858/ 1097] train: loss: 0.0213754
[Epoch 97; Iter   888/ 1097] train: loss: 0.0946361
[Epoch 97; Iter   918/ 1097] train: loss: 0.0845082
[Epoch 97; Iter   948/ 1097] train: loss: 0.0435093
[Epoch 97; Iter   978/ 1097] train: loss: 0.0097289
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0322038
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0012450
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0083471
[Epoch 97] ogbg-molhiv: 0.774701 val loss: 0.135467
[Epoch 97] ogbg-molhiv: 0.726826 test loss: 0.224843
[Epoch 98; Iter     1/ 1097] train: loss: 0.0316490
[Epoch 98; Iter    31/ 1097] train: loss: 0.0062751
[Epoch 98; Iter    61/ 1097] train: loss: 0.0048126
[Epoch 98; Iter    91/ 1097] train: loss: 0.0112989
[Epoch 98; Iter   121/ 1097] train: loss: 0.1437336
[Epoch 98; Iter   151/ 1097] train: loss: 0.0657755
[Epoch 98; Iter   181/ 1097] train: loss: 0.0045987
[Epoch 98; Iter   211/ 1097] train: loss: 0.0140557
[Epoch 98; Iter   241/ 1097] train: loss: 0.0059553
[Epoch 98; Iter   271/ 1097] train: loss: 0.0046321
[Epoch 98; Iter   301/ 1097] train: loss: 0.0066597
[Epoch 98; Iter   331/ 1097] train: loss: 0.0131899
[Epoch 98; Iter   361/ 1097] train: loss: 0.0369467
[Epoch 98; Iter   391/ 1097] train: loss: 0.0155996
[Epoch 98; Iter   421/ 1097] train: loss: 0.0037944
[Epoch 98; Iter   451/ 1097] train: loss: 0.0057544
[Epoch 98; Iter   481/ 1097] train: loss: 0.0254036
[Epoch 98; Iter   511/ 1097] train: loss: 0.0040390
[Epoch 98; Iter   541/ 1097] train: loss: 0.0105452
[Epoch 98; Iter   571/ 1097] train: loss: 0.0549600
[Epoch 98; Iter   601/ 1097] train: loss: 0.0087390
[Epoch 98; Iter   631/ 1097] train: loss: 0.0700890
[Epoch 98; Iter   661/ 1097] train: loss: 0.0128384
[Epoch 98; Iter   691/ 1097] train: loss: 0.0039740
[Epoch 98; Iter   721/ 1097] train: loss: 0.0108939
[Epoch 98; Iter   751/ 1097] train: loss: 0.0178653
[Epoch 98; Iter   781/ 1097] train: loss: 0.0055188
[Epoch 98; Iter   811/ 1097] train: loss: 0.0031137
[Epoch 98; Iter   841/ 1097] train: loss: 0.0185662
[Epoch 98; Iter   871/ 1097] train: loss: 0.0062325
[Epoch 98; Iter   901/ 1097] train: loss: 0.0064661
[Epoch 98; Iter   931/ 1097] train: loss: 0.1160028
[Epoch 98; Iter   961/ 1097] train: loss: 0.0292031
[Epoch 98; Iter   991/ 1097] train: loss: 0.0304926
[Epoch 98; Iter  1021/ 1097] train: loss: 0.1522883
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0347819
[Epoch 98; Iter  1081/ 1097] train: loss: 0.1265272
[Epoch 98] ogbg-molhiv: 0.773191 val loss: 0.132695
[Epoch 98] ogbg-molhiv: 0.734570 test loss: 0.221769
[Epoch 99; Iter    14/ 1097] train: loss: 0.1012548
[Epoch 99; Iter    44/ 1097] train: loss: 0.0062154
[Epoch 99; Iter    74/ 1097] train: loss: 0.0008768
[Epoch 99; Iter   104/ 1097] train: loss: 0.0436094
[Epoch 99; Iter   134/ 1097] train: loss: 0.0104512
[Epoch 99; Iter   164/ 1097] train: loss: 0.0224549
[Epoch 99; Iter   194/ 1097] train: loss: 0.0055555
[Epoch 99; Iter   224/ 1097] train: loss: 0.0631395
[Epoch 99; Iter   254/ 1097] train: loss: 0.0071595
[Epoch 99; Iter   284/ 1097] train: loss: 0.0146134
[Epoch 99; Iter   314/ 1097] train: loss: 0.0213823
[Epoch 99; Iter   344/ 1097] train: loss: 0.0022863
[Epoch 99; Iter   374/ 1097] train: loss: 0.0105412
[Epoch 99; Iter   404/ 1097] train: loss: 0.0440761
[Epoch 99; Iter   434/ 1097] train: loss: 0.0485485
[Epoch 99; Iter   464/ 1097] train: loss: 0.0501361
[Epoch 99; Iter   494/ 1097] train: loss: 0.0174015
[Epoch 99; Iter   524/ 1097] train: loss: 0.0046946
[Epoch 99; Iter   554/ 1097] train: loss: 0.0129022
[Epoch 99; Iter   584/ 1097] train: loss: 0.0239891
[Epoch 99; Iter   614/ 1097] train: loss: 0.0341033
[Epoch 99; Iter   644/ 1097] train: loss: 0.0036138
[Epoch 99; Iter   674/ 1097] train: loss: 0.0056136
[Epoch 99; Iter   704/ 1097] train: loss: 0.0506596
[Epoch 99; Iter   734/ 1097] train: loss: 0.0182881
[Epoch 99; Iter   764/ 1097] train: loss: 0.0159247
[Epoch 99; Iter   794/ 1097] train: loss: 0.0077857
[Epoch 99; Iter   824/ 1097] train: loss: 0.0235088
[Epoch 99; Iter   854/ 1097] train: loss: 0.0750627
[Epoch 99; Iter   884/ 1097] train: loss: 0.0132134
[Epoch 99; Iter   914/ 1097] train: loss: 0.0018906
[Epoch 99; Iter   944/ 1097] train: loss: 0.1024522
[Epoch 99; Iter   974/ 1097] train: loss: 0.0053353
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0007325
[Epoch 99; Iter  1034/ 1097] train: loss: 0.1270981
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0397456
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0007180
[Epoch 99] ogbg-molhiv: 0.771905 val loss: 0.140112
[Epoch 99] ogbg-molhiv: 0.736158 test loss: 0.222816
[Epoch 100; Iter    27/ 1097] train: loss: 0.0202041
[Epoch 100; Iter    57/ 1097] train: loss: 0.0093295
[Epoch 100; Iter    87/ 1097] train: loss: 0.0646633
[Epoch 100; Iter   117/ 1097] train: loss: 0.0077989
[Epoch 100; Iter   147/ 1097] train: loss: 0.0033256
[Epoch 100; Iter   177/ 1097] train: loss: 0.0115650
[Epoch 100; Iter   207/ 1097] train: loss: 0.1514075
[Epoch 100; Iter   237/ 1097] train: loss: 0.0484193
[Epoch 100; Iter   267/ 1097] train: loss: 0.0429216
[Epoch 100; Iter   297/ 1097] train: loss: 0.0286373
[Epoch 100; Iter   327/ 1097] train: loss: 0.1312543
[Epoch 100; Iter   357/ 1097] train: loss: 0.0030743
[Epoch 100; Iter   387/ 1097] train: loss: 0.0143039
[Epoch 100; Iter   417/ 1097] train: loss: 0.0027479
[Epoch 100; Iter   447/ 1097] train: loss: 0.1514186
[Epoch 100; Iter   477/ 1097] train: loss: 0.0057862
[Epoch 100; Iter   507/ 1097] train: loss: 0.0044702
[Epoch 100; Iter   537/ 1097] train: loss: 0.0277713
[Epoch 100; Iter   567/ 1097] train: loss: 0.0052211
[Epoch 100; Iter   597/ 1097] train: loss: 0.0054437
[Epoch 100; Iter   627/ 1097] train: loss: 0.0207449
[Epoch 100; Iter   657/ 1097] train: loss: 0.1671924
[Epoch 100; Iter   687/ 1097] train: loss: 0.0230281
[Epoch 100; Iter   717/ 1097] train: loss: 0.0043433
[Epoch 100; Iter   747/ 1097] train: loss: 0.0220478
[Epoch 100; Iter   777/ 1097] train: loss: 0.0119353
[Epoch 100; Iter   807/ 1097] train: loss: 0.0050224
[Epoch 100; Iter   837/ 1097] train: loss: 0.0155910
[Epoch 100; Iter   867/ 1097] train: loss: 0.0191406
[Epoch 100; Iter   897/ 1097] train: loss: 0.0017137
[Epoch 100; Iter   927/ 1097] train: loss: 0.0042220
[Epoch 100; Iter   957/ 1097] train: loss: 0.0199339
[Epoch 100; Iter   987/ 1097] train: loss: 0.0560636
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0284167
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0032287
[Epoch 100; Iter  1077/ 1097] train: loss: 0.1031325
[Epoch 100] ogbg-molhiv: 0.767438 val loss: 0.162111
[Epoch 100] ogbg-molhiv: 0.724265 test loss: 0.231286
[Epoch 101; Iter    10/ 1097] train: loss: 0.0632974
[Epoch 101; Iter    40/ 1097] train: loss: 0.1868171
[Epoch 101; Iter    70/ 1097] train: loss: 0.0772694
[Epoch 101; Iter   100/ 1097] train: loss: 0.0975784
[Epoch 101; Iter   130/ 1097] train: loss: 0.0081137
[Epoch 101; Iter   160/ 1097] train: loss: 0.0108556
[Epoch 101; Iter   190/ 1097] train: loss: 0.0432572
[Epoch 101; Iter   220/ 1097] train: loss: 0.0332182
[Epoch 101; Iter   250/ 1097] train: loss: 0.0113559
[Epoch 101; Iter   280/ 1097] train: loss: 0.2419858
[Epoch 101; Iter   310/ 1097] train: loss: 0.0140387
[Epoch 101; Iter   340/ 1097] train: loss: 0.0076953
[Epoch 101; Iter   370/ 1097] train: loss: 0.0012331
[Epoch 101; Iter   400/ 1097] train: loss: 0.0046148
[Epoch 101; Iter   430/ 1097] train: loss: 0.0309534
[Epoch 101; Iter   460/ 1097] train: loss: 0.0135652
[Epoch 101; Iter   490/ 1097] train: loss: 0.0020418
[Epoch 101; Iter   520/ 1097] train: loss: 0.0042075
[Epoch 101; Iter   550/ 1097] train: loss: 0.0036644
[Epoch 101; Iter   580/ 1097] train: loss: 0.0753807
[Epoch 101; Iter   610/ 1097] train: loss: 0.0075438
[Epoch 101; Iter   640/ 1097] train: loss: 0.0517079
[Epoch 101; Iter   670/ 1097] train: loss: 0.0149433
[Epoch 101; Iter   700/ 1097] train: loss: 0.0537226
[Epoch 101; Iter   730/ 1097] train: loss: 0.0184288
[Epoch 101; Iter   330/  960] train: loss: 0.0088693
[Epoch 101; Iter   360/  960] train: loss: 0.0083696
[Epoch 101; Iter   390/  960] train: loss: 0.0039209
[Epoch 101; Iter   420/  960] train: loss: 0.0127068
[Epoch 101; Iter   450/  960] train: loss: 0.0629212
[Epoch 101; Iter   480/  960] train: loss: 0.0012836
[Epoch 101; Iter   510/  960] train: loss: 0.0652761
[Epoch 101; Iter   540/  960] train: loss: 0.0016019
[Epoch 101; Iter   570/  960] train: loss: 0.0255592
[Epoch 101; Iter   600/  960] train: loss: 0.0016904
[Epoch 101; Iter   630/  960] train: loss: 0.0010227
[Epoch 101; Iter   660/  960] train: loss: 0.0085353
[Epoch 101; Iter   690/  960] train: loss: 0.0319630
[Epoch 101; Iter   720/  960] train: loss: 0.0030574
[Epoch 101; Iter   750/  960] train: loss: 0.0297775
[Epoch 101; Iter   780/  960] train: loss: 0.0107553
[Epoch 101; Iter   810/  960] train: loss: 0.0474454
[Epoch 101; Iter   840/  960] train: loss: 0.0008801
[Epoch 101; Iter   870/  960] train: loss: 0.0508296
[Epoch 101; Iter   900/  960] train: loss: 0.0078901
[Epoch 101; Iter   930/  960] train: loss: 0.0045038
[Epoch 101; Iter   960/  960] train: loss: 0.0025162
[Epoch 101] ogbg-molhiv: 0.757965 val loss: 1.230564
[Epoch 101] ogbg-molhiv: 0.756684 test loss: 0.291913
[Epoch 102; Iter    30/  960] train: loss: 0.0176353
[Epoch 102; Iter    60/  960] train: loss: 0.0026372
[Epoch 102; Iter    90/  960] train: loss: 0.0019821
[Epoch 102; Iter   120/  960] train: loss: 0.0101658
[Epoch 102; Iter   150/  960] train: loss: 0.0361142
[Epoch 102; Iter   180/  960] train: loss: 0.0004167
[Epoch 102; Iter   210/  960] train: loss: 0.0209123
[Epoch 102; Iter   240/  960] train: loss: 0.0025979
[Epoch 102; Iter   270/  960] train: loss: 0.0030990
[Epoch 102; Iter   300/  960] train: loss: 0.0026018
[Epoch 102; Iter   330/  960] train: loss: 0.0064746
[Epoch 102; Iter   360/  960] train: loss: 0.0015769
[Epoch 102; Iter   390/  960] train: loss: 0.0010506
[Epoch 102; Iter   420/  960] train: loss: 0.0292863
[Epoch 102; Iter   450/  960] train: loss: 0.0239778
[Epoch 102; Iter   480/  960] train: loss: 0.0006280
[Epoch 102; Iter   510/  960] train: loss: 0.0070457
[Epoch 102; Iter   540/  960] train: loss: 0.0021933
[Epoch 102; Iter   570/  960] train: loss: 0.0035153
[Epoch 102; Iter   600/  960] train: loss: 0.0174111
[Epoch 102; Iter   630/  960] train: loss: 0.0164482
[Epoch 102; Iter   660/  960] train: loss: 0.0553179
[Epoch 102; Iter   690/  960] train: loss: 0.0045190
[Epoch 102; Iter   720/  960] train: loss: 0.0088439
[Epoch 102; Iter   750/  960] train: loss: 0.0435761
[Epoch 102; Iter   780/  960] train: loss: 0.0074588
[Epoch 102; Iter   810/  960] train: loss: 0.0018789
[Epoch 102; Iter   840/  960] train: loss: 0.1198891
[Epoch 102; Iter   870/  960] train: loss: 0.0375801
[Epoch 102; Iter   900/  960] train: loss: 0.0707135
[Epoch 102; Iter   930/  960] train: loss: 0.0708109
[Epoch 102; Iter   960/  960] train: loss: 0.0035007
[Epoch 102] ogbg-molhiv: 0.756113 val loss: 1.202074
[Epoch 102] ogbg-molhiv: 0.756260 test loss: 0.295368
[Epoch 103; Iter    30/  960] train: loss: 0.0055538
[Epoch 103; Iter    60/  960] train: loss: 0.0121122
[Epoch 103; Iter    90/  960] train: loss: 0.0118673
[Epoch 103; Iter   120/  960] train: loss: 0.0770103
[Epoch 103; Iter   150/  960] train: loss: 0.0177816
[Epoch 103; Iter   180/  960] train: loss: 0.0047596
[Epoch 103; Iter   210/  960] train: loss: 0.0010830
[Epoch 103; Iter   240/  960] train: loss: 0.0008966
[Epoch 103; Iter   270/  960] train: loss: 0.0180306
[Epoch 103; Iter   300/  960] train: loss: 0.0036683
[Epoch 103; Iter   330/  960] train: loss: 0.0051605
[Epoch 103; Iter   360/  960] train: loss: 0.0022714
[Epoch 103; Iter   390/  960] train: loss: 0.0230024
[Epoch 103; Iter   420/  960] train: loss: 0.0226847
[Epoch 103; Iter   450/  960] train: loss: 0.0015867
[Epoch 103; Iter   480/  960] train: loss: 0.0201998
[Epoch 103; Iter   510/  960] train: loss: 0.0005974
[Epoch 103; Iter   540/  960] train: loss: 0.0255711
[Epoch 103; Iter   570/  960] train: loss: 0.0076988
[Epoch 103; Iter   600/  960] train: loss: 0.0018690
[Epoch 103; Iter   630/  960] train: loss: 0.0054386
[Epoch 103; Iter   660/  960] train: loss: 0.0172336
[Epoch 103; Iter   690/  960] train: loss: 0.0049363
[Epoch 103; Iter   720/  960] train: loss: 0.0700152
[Epoch 103; Iter   750/  960] train: loss: 0.0870368
[Epoch 103; Iter   780/  960] train: loss: 0.0048972
[Epoch 103; Iter   810/  960] train: loss: 0.0207950
[Epoch 103; Iter   840/  960] train: loss: 0.0032909
[Epoch 103; Iter   870/  960] train: loss: 0.0128892
[Epoch 103; Iter   900/  960] train: loss: 0.0782844
[Epoch 103; Iter   930/  960] train: loss: 0.0197566
[Epoch 103; Iter   960/  960] train: loss: 0.0038617
[Epoch 103] ogbg-molhiv: 0.754970 val loss: 1.173015
[Epoch 103] ogbg-molhiv: 0.759064 test loss: 0.234814
[Epoch 104; Iter    30/  960] train: loss: 0.0084842
[Epoch 104; Iter    60/  960] train: loss: 0.0047958
[Epoch 104; Iter    90/  960] train: loss: 0.0127674
[Epoch 104; Iter   120/  960] train: loss: 0.0270392
[Epoch 104; Iter   150/  960] train: loss: 0.0085840
[Epoch 104; Iter   180/  960] train: loss: 0.0025156
[Epoch 104; Iter   210/  960] train: loss: 0.0014383
[Epoch 104; Iter   240/  960] train: loss: 0.1087060
[Epoch 104; Iter   270/  960] train: loss: 0.0102918
[Epoch 104; Iter   300/  960] train: loss: 0.0016660
[Epoch 104; Iter   330/  960] train: loss: 0.0242376
[Epoch 104; Iter   360/  960] train: loss: 0.0012591
[Epoch 104; Iter   390/  960] train: loss: 0.0125004
[Epoch 104; Iter   420/  960] train: loss: 0.0419800
[Epoch 104; Iter   450/  960] train: loss: 0.0007099
[Epoch 104; Iter   480/  960] train: loss: 0.0434128
[Epoch 104; Iter   510/  960] train: loss: 0.0024708
[Epoch 104; Iter   540/  960] train: loss: 0.0295956
[Epoch 104; Iter   570/  960] train: loss: 0.0064157
[Epoch 104; Iter   600/  960] train: loss: 0.0993703
[Epoch 104; Iter   630/  960] train: loss: 0.0301142
[Epoch 104; Iter   660/  960] train: loss: 0.0073789
[Epoch 104; Iter   690/  960] train: loss: 0.0032834
[Epoch 104; Iter   720/  960] train: loss: 0.0037380
[Epoch 104; Iter   750/  960] train: loss: 0.0151230
[Epoch 104; Iter   780/  960] train: loss: 0.0474341
[Epoch 104; Iter   810/  960] train: loss: 0.0412622
[Epoch 104; Iter   840/  960] train: loss: 0.0589011
[Epoch 104; Iter   870/  960] train: loss: 0.0046538
[Epoch 104; Iter   900/  960] train: loss: 0.0012680
[Epoch 104; Iter   930/  960] train: loss: 0.1136937
[Epoch 104; Iter   960/  960] train: loss: 0.0044882
[Epoch 104] ogbg-molhiv: 0.755475 val loss: 1.063917
[Epoch 104] ogbg-molhiv: 0.757092 test loss: 0.258631
[Epoch 105; Iter    30/  960] train: loss: 0.0021078
[Epoch 105; Iter    60/  960] train: loss: 0.0049592
[Epoch 105; Iter    90/  960] train: loss: 0.0006996
[Epoch 105; Iter   120/  960] train: loss: 0.0051261
[Epoch 105; Iter   150/  960] train: loss: 0.0035432
[Epoch 105; Iter   180/  960] train: loss: 0.0008445
[Epoch 105; Iter   210/  960] train: loss: 0.0389281
[Epoch 105; Iter   240/  960] train: loss: 0.0078198
[Epoch 105; Iter   270/  960] train: loss: 0.0141975
[Epoch 105; Iter   300/  960] train: loss: 0.0025821
[Epoch 105; Iter   330/  960] train: loss: 0.0009811
[Epoch 105; Iter   360/  960] train: loss: 0.0031283
[Epoch 105; Iter   390/  960] train: loss: 0.0032366
[Epoch 105; Iter   420/  960] train: loss: 0.0085340
[Epoch 105; Iter   450/  960] train: loss: 0.0505979
[Epoch 105; Iter   480/  960] train: loss: 0.0187014
[Epoch 105; Iter   510/  960] train: loss: 0.0581721
[Epoch 105; Iter   540/  960] train: loss: 0.0064717
[Epoch 105; Iter   570/  960] train: loss: 0.0035163
[Epoch 105; Iter   600/  960] train: loss: 0.0036521
[Epoch 105; Iter   630/  960] train: loss: 0.0750875
[Epoch 105; Iter   660/  960] train: loss: 0.0024867
[Epoch 105; Iter   690/  960] train: loss: 0.0010180
[Epoch 105; Iter   720/  960] train: loss: 0.0493598
[Epoch 105; Iter   750/  960] train: loss: 0.0076373
[Epoch 105; Iter   780/  960] train: loss: 0.0023279
[Epoch 105; Iter   810/  960] train: loss: 0.0190827
[Epoch 105; Iter   840/  960] train: loss: 0.0054655
[Epoch 101; Iter   330/  960] train: loss: 0.0004396
[Epoch 101; Iter   360/  960] train: loss: 0.0179983
[Epoch 101; Iter   390/  960] train: loss: 0.0570493
[Epoch 101; Iter   420/  960] train: loss: 0.0060625
[Epoch 101; Iter   450/  960] train: loss: 0.0054933
[Epoch 101; Iter   480/  960] train: loss: 0.0035306
[Epoch 101; Iter   510/  960] train: loss: 0.0253214
[Epoch 101; Iter   540/  960] train: loss: 0.0025119
[Epoch 101; Iter   570/  960] train: loss: 0.0122147
[Epoch 101; Iter   600/  960] train: loss: 0.0110367
[Epoch 101; Iter   630/  960] train: loss: 0.0808834
[Epoch 101; Iter   660/  960] train: loss: 0.0195249
[Epoch 101; Iter   690/  960] train: loss: 0.0007236
[Epoch 101; Iter   720/  960] train: loss: 0.0020506
[Epoch 101; Iter   750/  960] train: loss: 0.0111327
[Epoch 101; Iter   780/  960] train: loss: 0.0070934
[Epoch 101; Iter   810/  960] train: loss: 0.0271618
[Epoch 101; Iter   840/  960] train: loss: 0.0078033
[Epoch 101; Iter   870/  960] train: loss: 0.0021697
[Epoch 101; Iter   900/  960] train: loss: 0.0138319
[Epoch 101; Iter   930/  960] train: loss: 0.0010935
[Epoch 101; Iter   960/  960] train: loss: 0.0244385
[Epoch 101] ogbg-molhiv: 0.716201 val loss: 0.282323
[Epoch 101] ogbg-molhiv: 0.750511 test loss: 0.232792
[Epoch 102; Iter    30/  960] train: loss: 0.0081189
[Epoch 102; Iter    60/  960] train: loss: 0.0079821
[Epoch 102; Iter    90/  960] train: loss: 0.0460275
[Epoch 102; Iter   120/  960] train: loss: 0.0100755
[Epoch 102; Iter   150/  960] train: loss: 0.0018044
[Epoch 102; Iter   180/  960] train: loss: 0.0053466
[Epoch 102; Iter   210/  960] train: loss: 0.0127952
[Epoch 102; Iter   240/  960] train: loss: 0.0079481
[Epoch 102; Iter   270/  960] train: loss: 0.0776818
[Epoch 102; Iter   300/  960] train: loss: 0.0032567
[Epoch 102; Iter   330/  960] train: loss: 0.0023284
[Epoch 102; Iter   360/  960] train: loss: 0.0824750
[Epoch 102; Iter   390/  960] train: loss: 0.0017656
[Epoch 102; Iter   420/  960] train: loss: 0.0014118
[Epoch 102; Iter   450/  960] train: loss: 0.0046842
[Epoch 102; Iter   480/  960] train: loss: 0.0642651
[Epoch 102; Iter   510/  960] train: loss: 0.0029738
[Epoch 102; Iter   540/  960] train: loss: 0.0029911
[Epoch 102; Iter   570/  960] train: loss: 0.0012622
[Epoch 102; Iter   600/  960] train: loss: 0.0008010
[Epoch 102; Iter   630/  960] train: loss: 0.0157878
[Epoch 102; Iter   660/  960] train: loss: 0.0253482
[Epoch 102; Iter   690/  960] train: loss: 0.0474130
[Epoch 102; Iter   720/  960] train: loss: 0.0004900
[Epoch 102; Iter   750/  960] train: loss: 0.1018419
[Epoch 102; Iter   780/  960] train: loss: 0.0022444
[Epoch 102; Iter   810/  960] train: loss: 0.0970023
[Epoch 102; Iter   840/  960] train: loss: 0.0114710
[Epoch 102; Iter   870/  960] train: loss: 0.0049547
[Epoch 102; Iter   900/  960] train: loss: 0.0087911
[Epoch 102; Iter   930/  960] train: loss: 0.0413630
[Epoch 102; Iter   960/  960] train: loss: 0.0009121
[Epoch 102] ogbg-molhiv: 0.710122 val loss: 0.388016
[Epoch 102] ogbg-molhiv: 0.754792 test loss: 0.630665
[Epoch 103; Iter    30/  960] train: loss: 0.0029357
[Epoch 103; Iter    60/  960] train: loss: 0.0309269
[Epoch 103; Iter    90/  960] train: loss: 0.0005753
[Epoch 103; Iter   120/  960] train: loss: 0.0175573
[Epoch 103; Iter   150/  960] train: loss: 0.0004786
[Epoch 103; Iter   180/  960] train: loss: 0.0134230
[Epoch 103; Iter   210/  960] train: loss: 0.0005791
[Epoch 103; Iter   240/  960] train: loss: 0.0217981
[Epoch 103; Iter   270/  960] train: loss: 0.0001453
[Epoch 103; Iter   300/  960] train: loss: 0.0001417
[Epoch 103; Iter   330/  960] train: loss: 0.0023001
[Epoch 103; Iter   360/  960] train: loss: 0.0071759
[Epoch 103; Iter   390/  960] train: loss: 0.0149565
[Epoch 103; Iter   420/  960] train: loss: 0.0089942
[Epoch 103; Iter   450/  960] train: loss: 0.0105196
[Epoch 103; Iter   480/  960] train: loss: 0.0008839
[Epoch 103; Iter   510/  960] train: loss: 0.0023069
[Epoch 103; Iter   540/  960] train: loss: 0.0026236
[Epoch 103; Iter   570/  960] train: loss: 0.0092277
[Epoch 103; Iter   600/  960] train: loss: 0.0082783
[Epoch 103; Iter   630/  960] train: loss: 0.0627929
[Epoch 103; Iter   660/  960] train: loss: 0.0126492
[Epoch 103; Iter   690/  960] train: loss: 0.0004856
[Epoch 103; Iter   720/  960] train: loss: 0.0035335
[Epoch 103; Iter   750/  960] train: loss: 0.0089324
[Epoch 103; Iter   780/  960] train: loss: 0.0025184
[Epoch 103; Iter   810/  960] train: loss: 0.0043989
[Epoch 103; Iter   840/  960] train: loss: 0.0015910
[Epoch 103; Iter   870/  960] train: loss: 0.0006821
[Epoch 103; Iter   900/  960] train: loss: 0.0009419
[Epoch 103; Iter   930/  960] train: loss: 0.0394186
[Epoch 103; Iter   960/  960] train: loss: 0.0032571
[Epoch 103] ogbg-molhiv: 0.710835 val loss: 0.303691
[Epoch 103] ogbg-molhiv: 0.749246 test loss: 0.240247
[Epoch 104; Iter    30/  960] train: loss: 0.0007271
[Epoch 104; Iter    60/  960] train: loss: 0.0138971
[Epoch 104; Iter    90/  960] train: loss: 0.0017992
[Epoch 104; Iter   120/  960] train: loss: 0.0050323
[Epoch 104; Iter   150/  960] train: loss: 0.0048375
[Epoch 104; Iter   180/  960] train: loss: 0.0655348
[Epoch 104; Iter   210/  960] train: loss: 0.0911963
[Epoch 104; Iter   240/  960] train: loss: 0.0028511
[Epoch 104; Iter   270/  960] train: loss: 0.0002396
[Epoch 104; Iter   300/  960] train: loss: 0.0251647
[Epoch 104; Iter   330/  960] train: loss: 0.0137178
[Epoch 104; Iter   360/  960] train: loss: 0.0048336
[Epoch 104; Iter   390/  960] train: loss: 0.0007033
[Epoch 104; Iter   420/  960] train: loss: 0.0030312
[Epoch 104; Iter   450/  960] train: loss: 0.0877139
[Epoch 104; Iter   480/  960] train: loss: 0.0405218
[Epoch 104; Iter   510/  960] train: loss: 0.0034145
[Epoch 104; Iter   540/  960] train: loss: 0.0331182
[Epoch 104; Iter   570/  960] train: loss: 0.0301226
[Epoch 104; Iter   600/  960] train: loss: 0.0005817
[Epoch 104; Iter   630/  960] train: loss: 0.0176810
[Epoch 104; Iter   660/  960] train: loss: 0.0223016
[Epoch 104; Iter   690/  960] train: loss: 0.0053916
[Epoch 104; Iter   720/  960] train: loss: 0.0015801
[Epoch 104; Iter   750/  960] train: loss: 0.0045426
[Epoch 104; Iter   780/  960] train: loss: 0.0012552
[Epoch 104; Iter   810/  960] train: loss: 0.0101267
[Epoch 104; Iter   840/  960] train: loss: 0.0011858
[Epoch 104; Iter   870/  960] train: loss: 0.0019939
[Epoch 104; Iter   900/  960] train: loss: 0.0296202
[Epoch 104; Iter   930/  960] train: loss: 0.0036575
[Epoch 104; Iter   960/  960] train: loss: 0.0401947
[Epoch 104] ogbg-molhiv: 0.714703 val loss: 0.291005
[Epoch 104] ogbg-molhiv: 0.754091 test loss: 0.230032
[Epoch 105; Iter    30/  960] train: loss: 0.0717443
[Epoch 105; Iter    60/  960] train: loss: 0.0162382
[Epoch 105; Iter    90/  960] train: loss: 0.0075214
[Epoch 105; Iter   120/  960] train: loss: 0.0005689
[Epoch 105; Iter   150/  960] train: loss: 0.0032715
[Epoch 105; Iter   180/  960] train: loss: 0.0040587
[Epoch 105; Iter   210/  960] train: loss: 0.0017986
[Epoch 105; Iter   240/  960] train: loss: 0.0115396
[Epoch 105; Iter   270/  960] train: loss: 0.0265702
[Epoch 105; Iter   300/  960] train: loss: 0.0265250
[Epoch 105; Iter   330/  960] train: loss: 0.0096512
[Epoch 105; Iter   360/  960] train: loss: 0.0016820
[Epoch 105; Iter   390/  960] train: loss: 0.0210468
[Epoch 105; Iter   420/  960] train: loss: 0.0152716
[Epoch 105; Iter   450/  960] train: loss: 0.0441956
[Epoch 105; Iter   480/  960] train: loss: 0.0465991
[Epoch 105; Iter   510/  960] train: loss: 0.0044011
[Epoch 105; Iter   540/  960] train: loss: 0.0798561
[Epoch 105; Iter   570/  960] train: loss: 0.0196940
[Epoch 105; Iter   600/  960] train: loss: 0.0079472
[Epoch 105; Iter   630/  960] train: loss: 0.0037737
[Epoch 105; Iter   660/  960] train: loss: 0.0688925
[Epoch 105; Iter   690/  960] train: loss: 0.0216378
[Epoch 105; Iter   720/  960] train: loss: 0.0006135
[Epoch 105; Iter   750/  960] train: loss: 0.1373724
[Epoch 105; Iter   780/  960] train: loss: 0.0019970
[Epoch 105; Iter   810/  960] train: loss: 0.0002389
[Epoch 105; Iter   840/  960] train: loss: 0.0146172
[Epoch 101; Iter   330/  960] train: loss: 0.0141244
[Epoch 101; Iter   360/  960] train: loss: 0.0173838
[Epoch 101; Iter   390/  960] train: loss: 0.0116852
[Epoch 101; Iter   420/  960] train: loss: 0.0106373
[Epoch 101; Iter   450/  960] train: loss: 0.0547128
[Epoch 101; Iter   480/  960] train: loss: 0.0017596
[Epoch 101; Iter   510/  960] train: loss: 0.0373202
[Epoch 101; Iter   540/  960] train: loss: 0.0273436
[Epoch 101; Iter   570/  960] train: loss: 0.0531445
[Epoch 101; Iter   600/  960] train: loss: 0.0285765
[Epoch 101; Iter   630/  960] train: loss: 0.0148919
[Epoch 101; Iter   660/  960] train: loss: 0.0212726
[Epoch 101; Iter   690/  960] train: loss: 0.0021038
[Epoch 101; Iter   720/  960] train: loss: 0.0016114
[Epoch 101; Iter   750/  960] train: loss: 0.0002041
[Epoch 101; Iter   780/  960] train: loss: 0.0007801
[Epoch 101; Iter   810/  960] train: loss: 0.0289029
[Epoch 101; Iter   840/  960] train: loss: 0.1403404
[Epoch 101; Iter   870/  960] train: loss: 0.0732924
[Epoch 101; Iter   900/  960] train: loss: 0.0035824
[Epoch 101; Iter   930/  960] train: loss: 0.0359516
[Epoch 101; Iter   960/  960] train: loss: 0.1315309
[Epoch 101] ogbg-molhiv: 0.726072 val loss: 0.968989
[Epoch 101] ogbg-molhiv: 0.750877 test loss: 0.670084
[Epoch 102; Iter    30/  960] train: loss: 0.0092925
[Epoch 102; Iter    60/  960] train: loss: 0.0074785
[Epoch 102; Iter    90/  960] train: loss: 0.0241487
[Epoch 102; Iter   120/  960] train: loss: 0.0008207
[Epoch 102; Iter   150/  960] train: loss: 0.0053292
[Epoch 102; Iter   180/  960] train: loss: 0.1019427
[Epoch 102; Iter   210/  960] train: loss: 0.0166887
[Epoch 102; Iter   240/  960] train: loss: 0.0021558
[Epoch 102; Iter   270/  960] train: loss: 0.0368291
[Epoch 102; Iter   300/  960] train: loss: 0.0859841
[Epoch 102; Iter   330/  960] train: loss: 0.0085027
[Epoch 102; Iter   360/  960] train: loss: 0.0220004
[Epoch 102; Iter   390/  960] train: loss: 0.0320664
[Epoch 102; Iter   420/  960] train: loss: 0.0161344
[Epoch 102; Iter   450/  960] train: loss: 0.0262930
[Epoch 102; Iter   480/  960] train: loss: 0.0271435
[Epoch 102; Iter   510/  960] train: loss: 0.0150231
[Epoch 102; Iter   540/  960] train: loss: 0.0073433
[Epoch 102; Iter   570/  960] train: loss: 0.0059246
[Epoch 102; Iter   600/  960] train: loss: 0.0114312
[Epoch 102; Iter   630/  960] train: loss: 0.0027534
[Epoch 102; Iter   660/  960] train: loss: 0.0059729
[Epoch 102; Iter   690/  960] train: loss: 0.0011537
[Epoch 102; Iter   720/  960] train: loss: 0.0025031
[Epoch 102; Iter   750/  960] train: loss: 0.0477998
[Epoch 102; Iter   780/  960] train: loss: 0.0571936
[Epoch 102; Iter   810/  960] train: loss: 0.0033894
[Epoch 102; Iter   840/  960] train: loss: 0.0021224
[Epoch 102; Iter   870/  960] train: loss: 0.0024696
[Epoch 102; Iter   900/  960] train: loss: 0.0020943
[Epoch 102; Iter   930/  960] train: loss: 0.0043962
[Epoch 102; Iter   960/  960] train: loss: 0.0062217
[Epoch 102] ogbg-molhiv: 0.715862 val loss: 1.001390
[Epoch 102] ogbg-molhiv: 0.746488 test loss: 0.709399
[Epoch 103; Iter    30/  960] train: loss: 0.0045496
[Epoch 103; Iter    60/  960] train: loss: 0.0049645
[Epoch 103; Iter    90/  960] train: loss: 0.0008582
[Epoch 103; Iter   120/  960] train: loss: 0.1012507
[Epoch 103; Iter   150/  960] train: loss: 0.0071599
[Epoch 103; Iter   180/  960] train: loss: 0.0010385
[Epoch 103; Iter   210/  960] train: loss: 0.0012443
[Epoch 103; Iter   240/  960] train: loss: 0.0113649
[Epoch 103; Iter   270/  960] train: loss: 0.0021817
[Epoch 103; Iter   300/  960] train: loss: 0.0271287
[Epoch 103; Iter   330/  960] train: loss: 0.0054472
[Epoch 103; Iter   360/  960] train: loss: 0.0059872
[Epoch 103; Iter   390/  960] train: loss: 0.0082383
[Epoch 103; Iter   420/  960] train: loss: 0.0159675
[Epoch 103; Iter   450/  960] train: loss: 0.0003581
[Epoch 103; Iter   480/  960] train: loss: 0.1598115
[Epoch 103; Iter   510/  960] train: loss: 0.0097492
[Epoch 103; Iter   540/  960] train: loss: 0.0044657
[Epoch 103; Iter   570/  960] train: loss: 0.0336003
[Epoch 103; Iter   600/  960] train: loss: 0.0044333
[Epoch 103; Iter   630/  960] train: loss: 0.0008310
[Epoch 103; Iter   660/  960] train: loss: 0.0043878
[Epoch 103; Iter   690/  960] train: loss: 0.0094622
[Epoch 103; Iter   720/  960] train: loss: 0.0542735
[Epoch 103; Iter   750/  960] train: loss: 0.0032176
[Epoch 103; Iter   780/  960] train: loss: 0.1614684
[Epoch 103; Iter   810/  960] train: loss: 0.0008525
[Epoch 103; Iter   840/  960] train: loss: 0.0379622
[Epoch 103; Iter   870/  960] train: loss: 0.0152774
[Epoch 103; Iter   900/  960] train: loss: 0.0017166
[Epoch 103; Iter   930/  960] train: loss: 0.0208911
[Epoch 103; Iter   960/  960] train: loss: 0.0939413
[Epoch 103] ogbg-molhiv: 0.719620 val loss: 0.718934
[Epoch 103] ogbg-molhiv: 0.741934 test loss: 0.474172
[Epoch 104; Iter    30/  960] train: loss: 0.0138700
[Epoch 104; Iter    60/  960] train: loss: 0.0467846
[Epoch 104; Iter    90/  960] train: loss: 0.0069250
[Epoch 104; Iter   120/  960] train: loss: 0.0015929
[Epoch 104; Iter   150/  960] train: loss: 0.0810247
[Epoch 104; Iter   180/  960] train: loss: 0.0021187
[Epoch 104; Iter   210/  960] train: loss: 0.0041326
[Epoch 104; Iter   240/  960] train: loss: 0.0039156
[Epoch 104; Iter   270/  960] train: loss: 0.0015464
[Epoch 104; Iter   300/  960] train: loss: 0.0042821
[Epoch 104; Iter   330/  960] train: loss: 0.1532293
[Epoch 104; Iter   360/  960] train: loss: 0.0769172
[Epoch 104; Iter   390/  960] train: loss: 0.0052839
[Epoch 104; Iter   420/  960] train: loss: 0.1686433
[Epoch 104; Iter   450/  960] train: loss: 0.0005297
[Epoch 104; Iter   480/  960] train: loss: 0.0078147
[Epoch 104; Iter   510/  960] train: loss: 0.0229177
[Epoch 104; Iter   540/  960] train: loss: 0.0068041
[Epoch 104; Iter   570/  960] train: loss: 0.0105641
[Epoch 104; Iter   600/  960] train: loss: 0.0089331
[Epoch 104; Iter   630/  960] train: loss: 0.1706258
[Epoch 104; Iter   660/  960] train: loss: 0.0022471
[Epoch 104; Iter   690/  960] train: loss: 0.0228753
[Epoch 104; Iter   720/  960] train: loss: 0.0076213
[Epoch 104; Iter   750/  960] train: loss: 0.0015899
[Epoch 104; Iter   780/  960] train: loss: 0.0028483
[Epoch 104; Iter   810/  960] train: loss: 0.0216812
[Epoch 104; Iter   840/  960] train: loss: 0.1232455
[Epoch 104; Iter   870/  960] train: loss: 0.0032780
[Epoch 104; Iter   900/  960] train: loss: 0.0103761
[Epoch 104; Iter   930/  960] train: loss: 0.0058767
[Epoch 104; Iter   960/  960] train: loss: 0.0063956
[Epoch 104] ogbg-molhiv: 0.725364 val loss: 0.824998
[Epoch 104] ogbg-molhiv: 0.753540 test loss: 0.586098
[Epoch 105; Iter    30/  960] train: loss: 0.0488217
[Epoch 105; Iter    60/  960] train: loss: 0.0020726
[Epoch 105; Iter    90/  960] train: loss: 0.0748288
[Epoch 105; Iter   120/  960] train: loss: 0.0032324
[Epoch 105; Iter   150/  960] train: loss: 0.0273274
[Epoch 105; Iter   180/  960] train: loss: 0.0460909
[Epoch 105; Iter   210/  960] train: loss: 0.0025674
[Epoch 105; Iter   240/  960] train: loss: 0.0312850
[Epoch 105; Iter   270/  960] train: loss: 0.0084272
[Epoch 105; Iter   300/  960] train: loss: 0.0012075
[Epoch 105; Iter   330/  960] train: loss: 0.0066029
[Epoch 105; Iter   360/  960] train: loss: 0.0214726
[Epoch 105; Iter   390/  960] train: loss: 0.0389158
[Epoch 105; Iter   420/  960] train: loss: 0.0423727
[Epoch 105; Iter   450/  960] train: loss: 0.0043385
[Epoch 105; Iter   480/  960] train: loss: 0.0883838
[Epoch 105; Iter   510/  960] train: loss: 0.0028678
[Epoch 105; Iter   540/  960] train: loss: 0.0017384
[Epoch 105; Iter   570/  960] train: loss: 0.0042521
[Epoch 105; Iter   600/  960] train: loss: 0.0232483
[Epoch 105; Iter   630/  960] train: loss: 0.0473733
[Epoch 105; Iter   660/  960] train: loss: 0.0043561
[Epoch 105; Iter   690/  960] train: loss: 0.0024832
[Epoch 105; Iter   720/  960] train: loss: 0.0067743
[Epoch 105; Iter   750/  960] train: loss: 0.0012634
[Epoch 105; Iter   780/  960] train: loss: 0.0459202
[Epoch 105; Iter   810/  960] train: loss: 0.0294155
[Epoch 105; Iter   840/  960] train: loss: 0.0226175
[Epoch 106; Iter    75/  823] train: loss: 0.0280233
[Epoch 106; Iter   105/  823] train: loss: 0.0876041
[Epoch 106; Iter   135/  823] train: loss: 0.0137956
[Epoch 106; Iter   165/  823] train: loss: 0.0168287
[Epoch 106; Iter   195/  823] train: loss: 0.0021016
[Epoch 106; Iter   225/  823] train: loss: 0.0080722
[Epoch 106; Iter   255/  823] train: loss: 0.0009319
[Epoch 106; Iter   285/  823] train: loss: 0.0073720
[Epoch 106; Iter   315/  823] train: loss: 0.0113230
[Epoch 106; Iter   345/  823] train: loss: 0.0032195
[Epoch 106; Iter   375/  823] train: loss: 0.0188243
[Epoch 106; Iter   405/  823] train: loss: 0.0016004
[Epoch 106; Iter   435/  823] train: loss: 0.0040100
[Epoch 106; Iter   465/  823] train: loss: 0.0081767
[Epoch 106; Iter   495/  823] train: loss: 0.0650315
[Epoch 106; Iter   525/  823] train: loss: 0.0131428
[Epoch 106; Iter   555/  823] train: loss: 0.0212221
[Epoch 106; Iter   585/  823] train: loss: 0.0199212
[Epoch 106; Iter   615/  823] train: loss: 0.0033056
[Epoch 106; Iter   645/  823] train: loss: 0.0287900
[Epoch 106; Iter   675/  823] train: loss: 0.0129871
[Epoch 106; Iter   705/  823] train: loss: 0.0757570
[Epoch 106; Iter   735/  823] train: loss: 0.0494369
[Epoch 106; Iter   765/  823] train: loss: 0.0088758
[Epoch 106; Iter   795/  823] train: loss: 0.0123103
[Epoch 106] ogbg-molhiv: 0.742610 val loss: 0.261888
[Epoch 106] ogbg-molhiv: 0.750891 test loss: 0.239664
[Epoch 107; Iter     2/  823] train: loss: 0.0013316
[Epoch 107; Iter    32/  823] train: loss: 0.0028281
[Epoch 107; Iter    62/  823] train: loss: 0.0198453
[Epoch 107; Iter    92/  823] train: loss: 0.0009021
[Epoch 107; Iter   122/  823] train: loss: 0.0042321
[Epoch 107; Iter   152/  823] train: loss: 0.0308277
[Epoch 107; Iter   182/  823] train: loss: 0.0026373
[Epoch 107; Iter   212/  823] train: loss: 0.0096439
[Epoch 107; Iter   242/  823] train: loss: 0.0010809
[Epoch 107; Iter   272/  823] train: loss: 0.0065801
[Epoch 107; Iter   302/  823] train: loss: 0.0413406
[Epoch 107; Iter   332/  823] train: loss: 0.0014636
[Epoch 107; Iter   362/  823] train: loss: 0.0182076
[Epoch 107; Iter   392/  823] train: loss: 0.0310164
[Epoch 107; Iter   422/  823] train: loss: 0.0038312
[Epoch 107; Iter   452/  823] train: loss: 0.0029278
[Epoch 107; Iter   482/  823] train: loss: 0.0806004
[Epoch 107; Iter   512/  823] train: loss: 0.0264157
[Epoch 107; Iter   542/  823] train: loss: 0.0084871
[Epoch 107; Iter   572/  823] train: loss: 0.1175729
[Epoch 107; Iter   602/  823] train: loss: 0.0307831
[Epoch 107; Iter   632/  823] train: loss: 0.0400337
[Epoch 107; Iter   662/  823] train: loss: 0.0474290
[Epoch 107; Iter   692/  823] train: loss: 0.0199434
[Epoch 107; Iter   722/  823] train: loss: 0.0048929
[Epoch 107; Iter   752/  823] train: loss: 0.0007794
[Epoch 107; Iter   782/  823] train: loss: 0.0484479
[Epoch 107; Iter   812/  823] train: loss: 0.0076853
[Epoch 107] ogbg-molhiv: 0.746703 val loss: 0.254809
[Epoch 107] ogbg-molhiv: 0.749913 test loss: 0.210828
[Epoch 108; Iter    19/  823] train: loss: 0.0027421
[Epoch 108; Iter    49/  823] train: loss: 0.0018416
[Epoch 108; Iter    79/  823] train: loss: 0.0101825
[Epoch 108; Iter   109/  823] train: loss: 0.0095353
[Epoch 108; Iter   139/  823] train: loss: 0.0017850
[Epoch 108; Iter   169/  823] train: loss: 0.0100993
[Epoch 108; Iter   199/  823] train: loss: 0.0172826
[Epoch 108; Iter   229/  823] train: loss: 0.0026945
[Epoch 108; Iter   259/  823] train: loss: 0.0017065
[Epoch 108; Iter   289/  823] train: loss: 0.0075172
[Epoch 108; Iter   319/  823] train: loss: 0.0258969
[Epoch 108; Iter   349/  823] train: loss: 0.0598290
[Epoch 108; Iter   379/  823] train: loss: 0.0031844
[Epoch 108; Iter   409/  823] train: loss: 0.0226188
[Epoch 108; Iter   439/  823] train: loss: 0.0026331
[Epoch 108; Iter   469/  823] train: loss: 0.0043620
[Epoch 108; Iter   499/  823] train: loss: 0.0037676
[Epoch 108; Iter   529/  823] train: loss: 0.0454014
[Epoch 108; Iter   559/  823] train: loss: 0.0049318
[Epoch 108; Iter   589/  823] train: loss: 0.0047086
[Epoch 108; Iter   619/  823] train: loss: 0.0578006
[Epoch 108; Iter   649/  823] train: loss: 0.0338182
[Epoch 108; Iter   679/  823] train: loss: 0.0231791
[Epoch 108; Iter   709/  823] train: loss: 0.0188810
[Epoch 108; Iter   739/  823] train: loss: 0.0781253
[Epoch 108; Iter   769/  823] train: loss: 0.0011762
[Epoch 108; Iter   799/  823] train: loss: 0.0100454
[Epoch 108] ogbg-molhiv: 0.741642 val loss: 0.269678
[Epoch 108] ogbg-molhiv: 0.758379 test loss: 0.233190
[Epoch 109; Iter     6/  823] train: loss: 0.0161437
[Epoch 109; Iter    36/  823] train: loss: 0.0317448
[Epoch 109; Iter    66/  823] train: loss: 0.0107069
[Epoch 109; Iter    96/  823] train: loss: 0.1299568
[Epoch 109; Iter   126/  823] train: loss: 0.0968197
[Epoch 109; Iter   156/  823] train: loss: 0.0088330
[Epoch 109; Iter   186/  823] train: loss: 0.0023260
[Epoch 109; Iter   216/  823] train: loss: 0.0011741
[Epoch 109; Iter   246/  823] train: loss: 0.0144449
[Epoch 109; Iter   276/  823] train: loss: 0.0077530
[Epoch 109; Iter   306/  823] train: loss: 0.0020210
[Epoch 109; Iter   336/  823] train: loss: 0.0189451
[Epoch 109; Iter   366/  823] train: loss: 0.0266870
[Epoch 109; Iter   396/  823] train: loss: 0.0139722
[Epoch 109; Iter   426/  823] train: loss: 0.1390163
[Epoch 109; Iter   456/  823] train: loss: 0.0745268
[Epoch 109; Iter   486/  823] train: loss: 0.0050451
[Epoch 109; Iter   516/  823] train: loss: 0.0012090
[Epoch 109; Iter   546/  823] train: loss: 0.0584589
[Epoch 109; Iter   576/  823] train: loss: 0.0044935
[Epoch 109; Iter   606/  823] train: loss: 0.0051550
[Epoch 109; Iter   636/  823] train: loss: 0.0338933
[Epoch 109; Iter   666/  823] train: loss: 0.0980041
[Epoch 109; Iter   696/  823] train: loss: 0.0350013
[Epoch 109; Iter   726/  823] train: loss: 0.0183966
[Epoch 109; Iter   756/  823] train: loss: 0.0659510
[Epoch 109; Iter   786/  823] train: loss: 0.0007244
[Epoch 109; Iter   816/  823] train: loss: 0.0053667
[Epoch 109] ogbg-molhiv: 0.748373 val loss: 0.257579
[Epoch 109] ogbg-molhiv: 0.755448 test loss: 0.269805
[Epoch 110; Iter    23/  823] train: loss: 0.0020076
[Epoch 110; Iter    53/  823] train: loss: 0.0145973
[Epoch 110; Iter    83/  823] train: loss: 0.0025377
[Epoch 110; Iter   113/  823] train: loss: 0.0233751
[Epoch 110; Iter   143/  823] train: loss: 0.0023854
[Epoch 110; Iter   173/  823] train: loss: 0.0161231
[Epoch 110; Iter   203/  823] train: loss: 0.0028585
[Epoch 110; Iter   233/  823] train: loss: 0.0279951
[Epoch 110; Iter   263/  823] train: loss: 0.0125717
[Epoch 110; Iter   293/  823] train: loss: 0.0061048
[Epoch 110; Iter   323/  823] train: loss: 0.0041290
[Epoch 110; Iter   353/  823] train: loss: 0.0001843
[Epoch 110; Iter   383/  823] train: loss: 0.0175683
[Epoch 110; Iter   413/  823] train: loss: 0.0025593
[Epoch 110; Iter   443/  823] train: loss: 0.1874557
[Epoch 110; Iter   473/  823] train: loss: 0.0482462
[Epoch 110; Iter   503/  823] train: loss: 0.0087302
[Epoch 110; Iter   533/  823] train: loss: 0.0330397
[Epoch 110; Iter   563/  823] train: loss: 0.0037885
[Epoch 110; Iter   593/  823] train: loss: 0.0012348
[Epoch 110; Iter   623/  823] train: loss: 0.0041908
[Epoch 110; Iter   653/  823] train: loss: 0.0387198
[Epoch 110; Iter   683/  823] train: loss: 0.0808738
[Epoch 110; Iter   713/  823] train: loss: 0.0610302
[Epoch 110; Iter   743/  823] train: loss: 0.0044797
[Epoch 110; Iter   773/  823] train: loss: 0.0066246
[Epoch 110; Iter   803/  823] train: loss: 0.0019063
[Epoch 110] ogbg-molhiv: 0.746677 val loss: 0.254596
[Epoch 110] ogbg-molhiv: 0.748739 test loss: 0.225999
[Epoch 111; Iter    10/  823] train: loss: 0.0330693
[Epoch 111; Iter    40/  823] train: loss: 0.0553345
[Epoch 111; Iter    70/  823] train: loss: 0.0249957
[Epoch 111; Iter   100/  823] train: loss: 0.1065147
[Epoch 111; Iter   130/  823] train: loss: 0.0256274
[Epoch 111; Iter   160/  823] train: loss: 0.0064131
[Epoch 111; Iter   190/  823] train: loss: 0.0033315
[Epoch 111; Iter   220/  823] train: loss: 0.0034910
[Epoch 111; Iter   250/  823] train: loss: 0.0526142
[Epoch 97; Iter   708/ 1097] train: loss: 0.0022934
[Epoch 97; Iter   738/ 1097] train: loss: 0.0005147
[Epoch 97; Iter   768/ 1097] train: loss: 0.0065063
[Epoch 97; Iter   798/ 1097] train: loss: 0.0295250
[Epoch 97; Iter   828/ 1097] train: loss: 0.0035091
[Epoch 97; Iter   858/ 1097] train: loss: 0.0403019
[Epoch 97; Iter   888/ 1097] train: loss: 0.0554820
[Epoch 97; Iter   918/ 1097] train: loss: 0.0070902
[Epoch 97; Iter   948/ 1097] train: loss: 0.0275408
[Epoch 97; Iter   978/ 1097] train: loss: 0.0408110
[Epoch 97; Iter  1008/ 1097] train: loss: 0.0024364
[Epoch 97; Iter  1038/ 1097] train: loss: 0.0250081
[Epoch 97; Iter  1068/ 1097] train: loss: 0.0031707
[Epoch 97] ogbg-molhiv: 0.788856 val loss: 0.135029
[Epoch 97] ogbg-molhiv: 0.751330 test loss: 0.242580
[Epoch 98; Iter     1/ 1097] train: loss: 0.0023174
[Epoch 98; Iter    31/ 1097] train: loss: 0.0824761
[Epoch 98; Iter    61/ 1097] train: loss: 0.0066128
[Epoch 98; Iter    91/ 1097] train: loss: 0.0012974
[Epoch 98; Iter   121/ 1097] train: loss: 0.0037677
[Epoch 98; Iter   151/ 1097] train: loss: 0.0013712
[Epoch 98; Iter   181/ 1097] train: loss: 0.0254248
[Epoch 98; Iter   211/ 1097] train: loss: 0.0033361
[Epoch 98; Iter   241/ 1097] train: loss: 0.0011996
[Epoch 98; Iter   271/ 1097] train: loss: 0.0035277
[Epoch 98; Iter   301/ 1097] train: loss: 0.0064564
[Epoch 98; Iter   331/ 1097] train: loss: 0.0015733
[Epoch 98; Iter   361/ 1097] train: loss: 0.0020712
[Epoch 98; Iter   391/ 1097] train: loss: 0.0026342
[Epoch 98; Iter   421/ 1097] train: loss: 0.0050994
[Epoch 98; Iter   451/ 1097] train: loss: 0.0019683
[Epoch 98; Iter   481/ 1097] train: loss: 0.0184955
[Epoch 98; Iter   511/ 1097] train: loss: 0.1747038
[Epoch 98; Iter   541/ 1097] train: loss: 0.0088807
[Epoch 98; Iter   571/ 1097] train: loss: 0.0034826
[Epoch 98; Iter   601/ 1097] train: loss: 0.0409643
[Epoch 98; Iter   631/ 1097] train: loss: 0.0005103
[Epoch 98; Iter   661/ 1097] train: loss: 0.0006604
[Epoch 98; Iter   691/ 1097] train: loss: 0.0171624
[Epoch 98; Iter   721/ 1097] train: loss: 0.0286866
[Epoch 98; Iter   751/ 1097] train: loss: 0.1209285
[Epoch 98; Iter   781/ 1097] train: loss: 0.0190907
[Epoch 98; Iter   811/ 1097] train: loss: 0.0031828
[Epoch 98; Iter   841/ 1097] train: loss: 0.0058036
[Epoch 98; Iter   871/ 1097] train: loss: 0.0007073
[Epoch 98; Iter   901/ 1097] train: loss: 0.1066413
[Epoch 98; Iter   931/ 1097] train: loss: 0.0237042
[Epoch 98; Iter   961/ 1097] train: loss: 0.0038395
[Epoch 98; Iter   991/ 1097] train: loss: 0.0016997
[Epoch 98; Iter  1021/ 1097] train: loss: 0.0049047
[Epoch 98; Iter  1051/ 1097] train: loss: 0.0004203
[Epoch 98; Iter  1081/ 1097] train: loss: 0.0009075
[Epoch 98] ogbg-molhiv: 0.799199 val loss: 0.132411
[Epoch 98] ogbg-molhiv: 0.760192 test loss: 0.243764
[Epoch 99; Iter    14/ 1097] train: loss: 0.0073589
[Epoch 99; Iter    44/ 1097] train: loss: 0.0106120
[Epoch 99; Iter    74/ 1097] train: loss: 0.0078292
[Epoch 99; Iter   104/ 1097] train: loss: 0.1316135
[Epoch 99; Iter   134/ 1097] train: loss: 0.0016777
[Epoch 99; Iter   164/ 1097] train: loss: 0.0043544
[Epoch 99; Iter   194/ 1097] train: loss: 0.0904563
[Epoch 99; Iter   224/ 1097] train: loss: 0.0021866
[Epoch 99; Iter   254/ 1097] train: loss: 0.0163290
[Epoch 99; Iter   284/ 1097] train: loss: 0.0011387
[Epoch 99; Iter   314/ 1097] train: loss: 0.0020757
[Epoch 99; Iter   344/ 1097] train: loss: 0.0026481
[Epoch 99; Iter   374/ 1097] train: loss: 0.0003402
[Epoch 99; Iter   404/ 1097] train: loss: 0.0774417
[Epoch 99; Iter   434/ 1097] train: loss: 0.0192364
[Epoch 99; Iter   464/ 1097] train: loss: 0.0014365
[Epoch 99; Iter   494/ 1097] train: loss: 0.0072730
[Epoch 99; Iter   524/ 1097] train: loss: 0.0021460
[Epoch 99; Iter   554/ 1097] train: loss: 0.0022744
[Epoch 99; Iter   584/ 1097] train: loss: 0.0016373
[Epoch 99; Iter   614/ 1097] train: loss: 0.0143010
[Epoch 99; Iter   644/ 1097] train: loss: 0.0018672
[Epoch 99; Iter   674/ 1097] train: loss: 0.0135697
[Epoch 99; Iter   704/ 1097] train: loss: 0.0007735
[Epoch 99; Iter   734/ 1097] train: loss: 0.0062100
[Epoch 99; Iter   764/ 1097] train: loss: 0.0018586
[Epoch 99; Iter   794/ 1097] train: loss: 0.0609018
[Epoch 99; Iter   824/ 1097] train: loss: 0.0156959
[Epoch 99; Iter   854/ 1097] train: loss: 0.0028678
[Epoch 99; Iter   884/ 1097] train: loss: 0.0045179
[Epoch 99; Iter   914/ 1097] train: loss: 0.0200927
[Epoch 99; Iter   944/ 1097] train: loss: 0.0023506
[Epoch 99; Iter   974/ 1097] train: loss: 0.0018172
[Epoch 99; Iter  1004/ 1097] train: loss: 0.0008052
[Epoch 99; Iter  1034/ 1097] train: loss: 0.0487684
[Epoch 99; Iter  1064/ 1097] train: loss: 0.0027404
[Epoch 99; Iter  1094/ 1097] train: loss: 0.0620465
[Epoch 99] ogbg-molhiv: 0.800078 val loss: 0.135242
[Epoch 99] ogbg-molhiv: 0.752767 test loss: 0.254235
[Epoch 100; Iter    27/ 1097] train: loss: 0.0046740
[Epoch 100; Iter    57/ 1097] train: loss: 0.0003503
[Epoch 100; Iter    87/ 1097] train: loss: 0.0016976
[Epoch 100; Iter   117/ 1097] train: loss: 0.0369876
[Epoch 100; Iter   147/ 1097] train: loss: 0.0012467
[Epoch 100; Iter   177/ 1097] train: loss: 0.0020529
[Epoch 100; Iter   207/ 1097] train: loss: 0.0742680
[Epoch 100; Iter   237/ 1097] train: loss: 0.0075487
[Epoch 100; Iter   267/ 1097] train: loss: 0.0093089
[Epoch 100; Iter   297/ 1097] train: loss: 0.0004097
[Epoch 100; Iter   327/ 1097] train: loss: 0.0154865
[Epoch 100; Iter   357/ 1097] train: loss: 0.0010656
[Epoch 100; Iter   387/ 1097] train: loss: 0.0084220
[Epoch 100; Iter   417/ 1097] train: loss: 0.0150101
[Epoch 100; Iter   447/ 1097] train: loss: 0.0925393
[Epoch 100; Iter   477/ 1097] train: loss: 0.0488572
[Epoch 100; Iter   507/ 1097] train: loss: 0.0077368
[Epoch 100; Iter   537/ 1097] train: loss: 0.0011660
[Epoch 100; Iter   567/ 1097] train: loss: 0.0033041
[Epoch 100; Iter   597/ 1097] train: loss: 0.0115799
[Epoch 100; Iter   627/ 1097] train: loss: 0.0003256
[Epoch 100; Iter   657/ 1097] train: loss: 0.0012138
[Epoch 100; Iter   687/ 1097] train: loss: 0.0017080
[Epoch 100; Iter   717/ 1097] train: loss: 0.0314366
[Epoch 100; Iter   747/ 1097] train: loss: 0.0352734
[Epoch 100; Iter   777/ 1097] train: loss: 0.0027030
[Epoch 100; Iter   807/ 1097] train: loss: 0.0392274
[Epoch 100; Iter   837/ 1097] train: loss: 0.0124123
[Epoch 100; Iter   867/ 1097] train: loss: 0.0329379
[Epoch 100; Iter   897/ 1097] train: loss: 0.0214793
[Epoch 100; Iter   927/ 1097] train: loss: 0.0100076
[Epoch 100; Iter   957/ 1097] train: loss: 0.0094360
[Epoch 100; Iter   987/ 1097] train: loss: 0.0004675
[Epoch 100; Iter  1017/ 1097] train: loss: 0.0798155
[Epoch 100; Iter  1047/ 1097] train: loss: 0.0029645
[Epoch 100; Iter  1077/ 1097] train: loss: 0.0867929
[Epoch 100] ogbg-molhiv: 0.793008 val loss: 0.134119
[Epoch 100] ogbg-molhiv: 0.745561 test loss: 0.254457
[Epoch 101; Iter    10/ 1097] train: loss: 0.0010080
[Epoch 101; Iter    40/ 1097] train: loss: 0.0038804
[Epoch 101; Iter    70/ 1097] train: loss: 0.0315644
[Epoch 101; Iter   100/ 1097] train: loss: 0.1234452
[Epoch 101; Iter   130/ 1097] train: loss: 0.0114940
[Epoch 101; Iter   160/ 1097] train: loss: 0.0134894
[Epoch 101; Iter   190/ 1097] train: loss: 0.0170184
[Epoch 101; Iter   220/ 1097] train: loss: 0.0022239
[Epoch 101; Iter   250/ 1097] train: loss: 0.0033218
[Epoch 101; Iter   280/ 1097] train: loss: 0.0014798
[Epoch 101; Iter   310/ 1097] train: loss: 0.0062393
[Epoch 101; Iter   340/ 1097] train: loss: 0.0142272
[Epoch 101; Iter   370/ 1097] train: loss: 0.0108380
[Epoch 101; Iter   400/ 1097] train: loss: 0.0778869
[Epoch 101; Iter   430/ 1097] train: loss: 0.0059951
[Epoch 101; Iter   460/ 1097] train: loss: 0.0196934
[Epoch 101; Iter   490/ 1097] train: loss: 0.0034558
[Epoch 101; Iter   520/ 1097] train: loss: 0.0036388
[Epoch 101; Iter   550/ 1097] train: loss: 0.0090418
[Epoch 101; Iter   580/ 1097] train: loss: 0.0038119
[Epoch 101; Iter   610/ 1097] train: loss: 0.0029111
[Epoch 101; Iter   640/ 1097] train: loss: 0.0040909
[Epoch 101; Iter   670/ 1097] train: loss: 0.0014804
[Epoch 101; Iter   700/ 1097] train: loss: 0.0002888
[Epoch 101; Iter   730/ 1097] train: loss: 0.0025153
[Epoch 106; Iter    75/  823] train: loss: 0.0047424
[Epoch 106; Iter   105/  823] train: loss: 0.0018385
[Epoch 106; Iter   135/  823] train: loss: 0.0597117
[Epoch 106; Iter   165/  823] train: loss: 0.0635133
[Epoch 106; Iter   195/  823] train: loss: 0.0031906
[Epoch 106; Iter   225/  823] train: loss: 0.0101970
[Epoch 106; Iter   255/  823] train: loss: 0.1252193
[Epoch 106; Iter   285/  823] train: loss: 0.1065214
[Epoch 106; Iter   315/  823] train: loss: 0.0123898
[Epoch 106; Iter   345/  823] train: loss: 0.0060591
[Epoch 106; Iter   375/  823] train: loss: 0.0023341
[Epoch 106; Iter   405/  823] train: loss: 0.0634464
[Epoch 106; Iter   435/  823] train: loss: 0.0644349
[Epoch 106; Iter   465/  823] train: loss: 0.0142565
[Epoch 106; Iter   495/  823] train: loss: 0.0020312
[Epoch 106; Iter   525/  823] train: loss: 0.0036508
[Epoch 106; Iter   555/  823] train: loss: 0.0615821
[Epoch 106; Iter   585/  823] train: loss: 0.0070007
[Epoch 106; Iter   615/  823] train: loss: 0.0064334
[Epoch 106; Iter   645/  823] train: loss: 0.0163050
[Epoch 106; Iter   675/  823] train: loss: 0.0009541
[Epoch 106; Iter   705/  823] train: loss: 0.0028182
[Epoch 106; Iter   735/  823] train: loss: 0.0053394
[Epoch 106; Iter   765/  823] train: loss: 0.0010014
[Epoch 106; Iter   795/  823] train: loss: 0.0041346
[Epoch 106] ogbg-molhiv: 0.702474 val loss: 0.437564
[Epoch 106] ogbg-molhiv: 0.745678 test loss: 0.241205
[Epoch 107; Iter     2/  823] train: loss: 0.0188389
[Epoch 107; Iter    32/  823] train: loss: 0.0013863
[Epoch 107; Iter    62/  823] train: loss: 0.0022580
[Epoch 107; Iter    92/  823] train: loss: 0.0026816
[Epoch 107; Iter   122/  823] train: loss: 0.0026776
[Epoch 107; Iter   152/  823] train: loss: 0.0440329
[Epoch 107; Iter   182/  823] train: loss: 0.0060595
[Epoch 107; Iter   212/  823] train: loss: 0.0035973
[Epoch 107; Iter   242/  823] train: loss: 0.0058465
[Epoch 107; Iter   272/  823] train: loss: 0.0098223
[Epoch 107; Iter   302/  823] train: loss: 0.0608326
[Epoch 107; Iter   332/  823] train: loss: 0.0014150
[Epoch 107; Iter   362/  823] train: loss: 0.0373833
[Epoch 107; Iter   392/  823] train: loss: 0.0070484
[Epoch 107; Iter   422/  823] train: loss: 0.0275389
[Epoch 107; Iter   452/  823] train: loss: 0.0158729
[Epoch 107; Iter   482/  823] train: loss: 0.0459158
[Epoch 107; Iter   512/  823] train: loss: 0.0096739
[Epoch 107; Iter   542/  823] train: loss: 0.0006063
[Epoch 107; Iter   572/  823] train: loss: 0.0048467
[Epoch 107; Iter   602/  823] train: loss: 0.0008133
[Epoch 107; Iter   632/  823] train: loss: 0.0282670
[Epoch 107; Iter   662/  823] train: loss: 0.0004485
[Epoch 107; Iter   692/  823] train: loss: 0.0158099
[Epoch 107; Iter   722/  823] train: loss: 0.0073842
[Epoch 107; Iter   752/  823] train: loss: 0.0005866
[Epoch 107; Iter   782/  823] train: loss: 0.0004867
[Epoch 107; Iter   812/  823] train: loss: 0.0577087
[Epoch 107] ogbg-molhiv: 0.702945 val loss: 0.449859
[Epoch 107] ogbg-molhiv: 0.749998 test loss: 0.246695
[Epoch 108; Iter    19/  823] train: loss: 0.0046933
[Epoch 108; Iter    49/  823] train: loss: 0.0059351
[Epoch 108; Iter    79/  823] train: loss: 0.0036292
[Epoch 108; Iter   109/  823] train: loss: 0.0005275
[Epoch 108; Iter   139/  823] train: loss: 0.0071493
[Epoch 108; Iter   169/  823] train: loss: 0.0029506
[Epoch 108; Iter   199/  823] train: loss: 0.0152233
[Epoch 108; Iter   229/  823] train: loss: 0.0019549
[Epoch 108; Iter   259/  823] train: loss: 0.0082850
[Epoch 108; Iter   289/  823] train: loss: 0.0179157
[Epoch 108; Iter   319/  823] train: loss: 0.0282268
[Epoch 108; Iter   349/  823] train: loss: 0.0181533
[Epoch 108; Iter   379/  823] train: loss: 0.0084567
[Epoch 108; Iter   409/  823] train: loss: 0.0150466
[Epoch 108; Iter   439/  823] train: loss: 0.0038855
[Epoch 108; Iter   469/  823] train: loss: 0.0114097
[Epoch 108; Iter   499/  823] train: loss: 0.0010505
[Epoch 108; Iter   529/  823] train: loss: 0.0047364
[Epoch 108; Iter   559/  823] train: loss: 0.0182879
[Epoch 108; Iter   589/  823] train: loss: 0.0004669
[Epoch 108; Iter   619/  823] train: loss: 0.0110049
[Epoch 108; Iter   649/  823] train: loss: 0.0275047
[Epoch 108; Iter   679/  823] train: loss: 0.0032847
[Epoch 108; Iter   709/  823] train: loss: 0.0754960
[Epoch 108; Iter   739/  823] train: loss: 0.0022976
[Epoch 108; Iter   769/  823] train: loss: 0.0025247
[Epoch 108; Iter   799/  823] train: loss: 0.0326439
[Epoch 108] ogbg-molhiv: 0.708270 val loss: 0.463006
[Epoch 108] ogbg-molhiv: 0.751625 test loss: 0.249018
[Epoch 109; Iter     6/  823] train: loss: 0.0271359
[Epoch 109; Iter    36/  823] train: loss: 0.0096750
[Epoch 109; Iter    66/  823] train: loss: 0.0432878
[Epoch 109; Iter    96/  823] train: loss: 0.0017442
[Epoch 109; Iter   126/  823] train: loss: 0.1505471
[Epoch 109; Iter   156/  823] train: loss: 0.0035380
[Epoch 109; Iter   186/  823] train: loss: 0.0011946
[Epoch 109; Iter   216/  823] train: loss: 0.0013589
[Epoch 109; Iter   246/  823] train: loss: 0.0004232
[Epoch 109; Iter   276/  823] train: loss: 0.0018819
[Epoch 109; Iter   306/  823] train: loss: 0.0213097
[Epoch 109; Iter   336/  823] train: loss: 0.0046758
[Epoch 109; Iter   366/  823] train: loss: 0.0018489
[Epoch 109; Iter   396/  823] train: loss: 0.1296654
[Epoch 109; Iter   426/  823] train: loss: 0.0034579
[Epoch 109; Iter   456/  823] train: loss: 0.0030529
[Epoch 109; Iter   486/  823] train: loss: 0.0098962
[Epoch 109; Iter   516/  823] train: loss: 0.0005563
[Epoch 109; Iter   546/  823] train: loss: 0.0155985
[Epoch 109; Iter   576/  823] train: loss: 0.0072939
[Epoch 109; Iter   606/  823] train: loss: 0.0003226
[Epoch 109; Iter   636/  823] train: loss: 0.0012490
[Epoch 109; Iter   666/  823] train: loss: 0.0026875
[Epoch 109; Iter   696/  823] train: loss: 0.0334575
[Epoch 109; Iter   726/  823] train: loss: 0.0026849
[Epoch 109; Iter   756/  823] train: loss: 0.0011821
[Epoch 109; Iter   786/  823] train: loss: 0.0163334
[Epoch 109; Iter   816/  823] train: loss: 0.0019216
[Epoch 109] ogbg-molhiv: 0.703346 val loss: 0.461596
[Epoch 109] ogbg-molhiv: 0.742519 test loss: 0.261271
[Epoch 110; Iter    23/  823] train: loss: 0.0236793
[Epoch 110; Iter    53/  823] train: loss: 0.0647458
[Epoch 110; Iter    83/  823] train: loss: 0.0263279
[Epoch 110; Iter   113/  823] train: loss: 0.0017713
[Epoch 110; Iter   143/  823] train: loss: 0.0019308
[Epoch 110; Iter   173/  823] train: loss: 0.0190097
[Epoch 110; Iter   203/  823] train: loss: 0.0009100
[Epoch 110; Iter   233/  823] train: loss: 0.0087383
[Epoch 110; Iter   263/  823] train: loss: 0.0027109
[Epoch 110; Iter   293/  823] train: loss: 0.0098580
[Epoch 110; Iter   323/  823] train: loss: 0.0022148
[Epoch 110; Iter   353/  823] train: loss: 0.0002439
[Epoch 110; Iter   383/  823] train: loss: 0.0028113
[Epoch 110; Iter   413/  823] train: loss: 0.0725615
[Epoch 110; Iter   443/  823] train: loss: 0.0010857
[Epoch 110; Iter   473/  823] train: loss: 0.0005158
[Epoch 110; Iter   503/  823] train: loss: 0.0024882
[Epoch 110; Iter   533/  823] train: loss: 0.0093330
[Epoch 110; Iter   563/  823] train: loss: 0.0661119
[Epoch 110; Iter   593/  823] train: loss: 0.0016353
[Epoch 110; Iter   623/  823] train: loss: 0.0070174
[Epoch 110; Iter   653/  823] train: loss: 0.0001713
[Epoch 110; Iter   683/  823] train: loss: 0.0055352
[Epoch 110; Iter   713/  823] train: loss: 0.0381151
[Epoch 110; Iter   743/  823] train: loss: 0.0007963
[Epoch 110; Iter   773/  823] train: loss: 0.0081315
[Epoch 110; Iter   803/  823] train: loss: 0.0018909
[Epoch 110] ogbg-molhiv: 0.700351 val loss: 0.507497
[Epoch 110] ogbg-molhiv: 0.746104 test loss: 0.277432
[Epoch 111; Iter    10/  823] train: loss: 0.0161705
[Epoch 111; Iter    40/  823] train: loss: 0.0038006
[Epoch 111; Iter    70/  823] train: loss: 0.0009126
[Epoch 111; Iter   100/  823] train: loss: 0.0111622
[Epoch 111; Iter   130/  823] train: loss: 0.0371907
[Epoch 111; Iter   160/  823] train: loss: 0.0024168
[Epoch 111; Iter   190/  823] train: loss: 0.0185358
[Epoch 111; Iter   220/  823] train: loss: 0.0008713
[Epoch 111; Iter   250/  823] train: loss: 0.0023301
[Epoch 106; Iter    75/  823] train: loss: 0.0264508
[Epoch 106; Iter   105/  823] train: loss: 0.0019256
[Epoch 106; Iter   135/  823] train: loss: 0.0016432
[Epoch 106; Iter   165/  823] train: loss: 0.0301480
[Epoch 106; Iter   195/  823] train: loss: 0.0034699
[Epoch 106; Iter   225/  823] train: loss: 0.0472862
[Epoch 106; Iter   255/  823] train: loss: 0.0046040
[Epoch 106; Iter   285/  823] train: loss: 0.0008432
[Epoch 106; Iter   315/  823] train: loss: 0.0003861
[Epoch 106; Iter   345/  823] train: loss: 0.0195459
[Epoch 106; Iter   375/  823] train: loss: 0.0222690
[Epoch 106; Iter   405/  823] train: loss: 0.0059887
[Epoch 106; Iter   435/  823] train: loss: 0.0023357
[Epoch 106; Iter   465/  823] train: loss: 0.0035943
[Epoch 106; Iter   495/  823] train: loss: 0.0260965
[Epoch 106; Iter   525/  823] train: loss: 0.0271320
[Epoch 106; Iter   555/  823] train: loss: 0.0023123
[Epoch 106; Iter   585/  823] train: loss: 0.0018739
[Epoch 106; Iter   615/  823] train: loss: 0.0812927
[Epoch 106; Iter   645/  823] train: loss: 0.0043055
[Epoch 106; Iter   675/  823] train: loss: 0.0105680
[Epoch 106; Iter   705/  823] train: loss: 0.0010947
[Epoch 106; Iter   735/  823] train: loss: 0.0065037
[Epoch 106; Iter   765/  823] train: loss: 0.0012902
[Epoch 106; Iter   795/  823] train: loss: 0.0340655
[Epoch 106] ogbg-molhiv: 0.740798 val loss: 0.347336
[Epoch 106] ogbg-molhiv: 0.760252 test loss: 0.293786
[Epoch 107; Iter     2/  823] train: loss: 0.0164322
[Epoch 107; Iter    32/  823] train: loss: 0.0017711
[Epoch 107; Iter    62/  823] train: loss: 0.1159146
[Epoch 107; Iter    92/  823] train: loss: 0.0100269
[Epoch 107; Iter   122/  823] train: loss: 0.0866762
[Epoch 107; Iter   152/  823] train: loss: 0.0459505
[Epoch 107; Iter   182/  823] train: loss: 0.0017847
[Epoch 107; Iter   212/  823] train: loss: 0.0024842
[Epoch 107; Iter   242/  823] train: loss: 0.0027788
[Epoch 107; Iter   272/  823] train: loss: 0.0001754
[Epoch 107; Iter   302/  823] train: loss: 0.0008424
[Epoch 107; Iter   332/  823] train: loss: 0.0060565
[Epoch 107; Iter   362/  823] train: loss: 0.0216763
[Epoch 107; Iter   392/  823] train: loss: 0.0128173
[Epoch 107; Iter   422/  823] train: loss: 0.0160390
[Epoch 107; Iter   452/  823] train: loss: 0.0393501
[Epoch 107; Iter   482/  823] train: loss: 0.0010042
[Epoch 107; Iter   512/  823] train: loss: 0.0010699
[Epoch 107; Iter   542/  823] train: loss: 0.0999983
[Epoch 107; Iter   572/  823] train: loss: 0.0111353
[Epoch 107; Iter   602/  823] train: loss: 0.0081922
[Epoch 107; Iter   632/  823] train: loss: 0.0027676
[Epoch 107; Iter   662/  823] train: loss: 0.0007038
[Epoch 107; Iter   692/  823] train: loss: 0.0031805
[Epoch 107; Iter   722/  823] train: loss: 0.0003307
[Epoch 107; Iter   752/  823] train: loss: 0.0329471
[Epoch 107; Iter   782/  823] train: loss: 0.0025462
[Epoch 107; Iter   812/  823] train: loss: 0.0100139
[Epoch 107] ogbg-molhiv: 0.738498 val loss: 0.378953
[Epoch 107] ogbg-molhiv: 0.750743 test loss: 0.322218
[Epoch 108; Iter    19/  823] train: loss: 0.0165256
[Epoch 108; Iter    49/  823] train: loss: 0.0028724
[Epoch 108; Iter    79/  823] train: loss: 0.0039016
[Epoch 108; Iter   109/  823] train: loss: 0.0186087
[Epoch 108; Iter   139/  823] train: loss: 0.0000798
[Epoch 108; Iter   169/  823] train: loss: 0.0052653
[Epoch 108; Iter   199/  823] train: loss: 0.0034076
[Epoch 108; Iter   229/  823] train: loss: 0.0006336
[Epoch 108; Iter   259/  823] train: loss: 0.0036573
[Epoch 108; Iter   289/  823] train: loss: 0.0032454
[Epoch 108; Iter   319/  823] train: loss: 0.0041592
[Epoch 108; Iter   349/  823] train: loss: 0.0028702
[Epoch 108; Iter   379/  823] train: loss: 0.0029730
[Epoch 108; Iter   409/  823] train: loss: 0.0008039
[Epoch 108; Iter   439/  823] train: loss: 0.0323752
[Epoch 108; Iter   469/  823] train: loss: 0.0100386
[Epoch 108; Iter   499/  823] train: loss: 0.0075348
[Epoch 108; Iter   529/  823] train: loss: 0.0413779
[Epoch 108; Iter   559/  823] train: loss: 0.0009593
[Epoch 108; Iter   589/  823] train: loss: 0.0009478
[Epoch 108; Iter   619/  823] train: loss: 0.0860406
[Epoch 108; Iter   649/  823] train: loss: 0.1103815
[Epoch 108; Iter   679/  823] train: loss: 0.0024487
[Epoch 108; Iter   709/  823] train: loss: 0.0469538
[Epoch 108; Iter   739/  823] train: loss: 0.0064835
[Epoch 108; Iter   769/  823] train: loss: 0.0006898
[Epoch 108; Iter   799/  823] train: loss: 0.0080767
[Epoch 108] ogbg-molhiv: 0.733855 val loss: 0.351241
[Epoch 108] ogbg-molhiv: 0.753650 test loss: 0.300939
[Epoch 109; Iter     6/  823] train: loss: 0.0086055
[Epoch 109; Iter    36/  823] train: loss: 0.0023602
[Epoch 109; Iter    66/  823] train: loss: 0.0021992
[Epoch 109; Iter    96/  823] train: loss: 0.0137301
[Epoch 109; Iter   126/  823] train: loss: 0.0112702
[Epoch 109; Iter   156/  823] train: loss: 0.0033823
[Epoch 109; Iter   186/  823] train: loss: 0.0068196
[Epoch 109; Iter   216/  823] train: loss: 0.0085798
[Epoch 109; Iter   246/  823] train: loss: 0.0010633
[Epoch 109; Iter   276/  823] train: loss: 0.0100973
[Epoch 109; Iter   306/  823] train: loss: 0.0156020
[Epoch 109; Iter   336/  823] train: loss: 0.0176112
[Epoch 109; Iter   366/  823] train: loss: 0.0043596
[Epoch 109; Iter   396/  823] train: loss: 0.0173399
[Epoch 109; Iter   426/  823] train: loss: 0.0004768
[Epoch 109; Iter   456/  823] train: loss: 0.0019434
[Epoch 109; Iter   486/  823] train: loss: 0.0063256
[Epoch 109; Iter   516/  823] train: loss: 0.0266268
[Epoch 109; Iter   546/  823] train: loss: 0.1356434
[Epoch 109; Iter   576/  823] train: loss: 0.0072223
[Epoch 109; Iter   606/  823] train: loss: 0.0034857
[Epoch 109; Iter   636/  823] train: loss: 0.0020866
[Epoch 109; Iter   666/  823] train: loss: 0.0335767
[Epoch 109; Iter   696/  823] train: loss: 0.0023233
[Epoch 109; Iter   726/  823] train: loss: 0.0007418
[Epoch 109; Iter   756/  823] train: loss: 0.0005138
[Epoch 109; Iter   786/  823] train: loss: 0.0125965
[Epoch 109; Iter   816/  823] train: loss: 0.0024882
[Epoch 109] ogbg-molhiv: 0.734468 val loss: 0.316017
[Epoch 109] ogbg-molhiv: 0.757882 test loss: 0.242649
[Epoch 110; Iter    23/  823] train: loss: 0.0004741
[Epoch 110; Iter    53/  823] train: loss: 0.0359526
[Epoch 110; Iter    83/  823] train: loss: 0.0049970
[Epoch 110; Iter   113/  823] train: loss: 0.0034883
[Epoch 110; Iter   143/  823] train: loss: 0.0000811
[Epoch 110; Iter   173/  823] train: loss: 0.0009548
[Epoch 110; Iter   203/  823] train: loss: 0.1364935
[Epoch 110; Iter   233/  823] train: loss: 0.0422535
[Epoch 110; Iter   263/  823] train: loss: 0.0070786
[Epoch 110; Iter   293/  823] train: loss: 0.0045851
[Epoch 110; Iter   323/  823] train: loss: 0.0150236
[Epoch 110; Iter   353/  823] train: loss: 0.0008314
[Epoch 110; Iter   383/  823] train: loss: 0.0091584
[Epoch 110; Iter   413/  823] train: loss: 0.0089440
[Epoch 110; Iter   443/  823] train: loss: 0.0119730
[Epoch 110; Iter   473/  823] train: loss: 0.0439077
[Epoch 110; Iter   503/  823] train: loss: 0.0008900
[Epoch 110; Iter   533/  823] train: loss: 0.0121745
[Epoch 110; Iter   563/  823] train: loss: 0.0008731
[Epoch 110; Iter   593/  823] train: loss: 0.0007131
[Epoch 110; Iter   623/  823] train: loss: 0.0002060
[Epoch 110; Iter   653/  823] train: loss: 0.0615572
[Epoch 110; Iter   683/  823] train: loss: 0.0003688
[Epoch 110; Iter   713/  823] train: loss: 0.0118926
[Epoch 110; Iter   743/  823] train: loss: 0.0049251
[Epoch 110; Iter   773/  823] train: loss: 0.1302620
[Epoch 110; Iter   803/  823] train: loss: 0.0111208
[Epoch 110] ogbg-molhiv: 0.738593 val loss: 0.418463
[Epoch 110] ogbg-molhiv: 0.764041 test loss: 0.405112
[Epoch 111; Iter    10/  823] train: loss: 0.0160369
[Epoch 111; Iter    40/  823] train: loss: 0.0275077
[Epoch 111; Iter    70/  823] train: loss: 0.0096838
[Epoch 111; Iter   100/  823] train: loss: 0.0007904
[Epoch 111; Iter   130/  823] train: loss: 0.0016585
[Epoch 111; Iter   160/  823] train: loss: 0.0051695
[Epoch 111; Iter   190/  823] train: loss: 0.0413576
[Epoch 111; Iter   220/  823] train: loss: 0.0006107
[Epoch 111; Iter   250/  823] train: loss: 0.0018654
[Epoch 101; Iter   760/ 1097] train: loss: 0.0088638
[Epoch 101; Iter   790/ 1097] train: loss: 0.0095667
[Epoch 101; Iter   820/ 1097] train: loss: 0.0038552
[Epoch 101; Iter   850/ 1097] train: loss: 0.0115630
[Epoch 101; Iter   880/ 1097] train: loss: 0.0224478
[Epoch 101; Iter   910/ 1097] train: loss: 0.0196676
[Epoch 101; Iter   940/ 1097] train: loss: 0.0049931
[Epoch 101; Iter   970/ 1097] train: loss: 0.0153286
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0796629
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0069044
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0367220
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0035954
[Epoch 101] ogbg-molhiv: 0.766642 val loss: 0.148361
[Epoch 101] ogbg-molhiv: 0.728998 test loss: 0.226387
[Epoch 102; Iter    23/ 1097] train: loss: 0.0039919
[Epoch 102; Iter    53/ 1097] train: loss: 0.0217921
[Epoch 102; Iter    83/ 1097] train: loss: 0.0087212
[Epoch 102; Iter   113/ 1097] train: loss: 0.0503235
[Epoch 102; Iter   143/ 1097] train: loss: 0.0414857
[Epoch 102; Iter   173/ 1097] train: loss: 0.0304508
[Epoch 102; Iter   203/ 1097] train: loss: 0.0317071
[Epoch 102; Iter   233/ 1097] train: loss: 0.0019577
[Epoch 102; Iter   263/ 1097] train: loss: 0.0686225
[Epoch 102; Iter   293/ 1097] train: loss: 0.0030921
[Epoch 102; Iter   323/ 1097] train: loss: 0.0178331
[Epoch 102; Iter   353/ 1097] train: loss: 0.0652765
[Epoch 102; Iter   383/ 1097] train: loss: 0.0072592
[Epoch 102; Iter   413/ 1097] train: loss: 0.0158083
[Epoch 102; Iter   443/ 1097] train: loss: 0.0076796
[Epoch 102; Iter   473/ 1097] train: loss: 0.0028653
[Epoch 102; Iter   503/ 1097] train: loss: 0.0033711
[Epoch 102; Iter   533/ 1097] train: loss: 0.0307553
[Epoch 102; Iter   563/ 1097] train: loss: 0.0081919
[Epoch 102; Iter   593/ 1097] train: loss: 0.0107967
[Epoch 102; Iter   623/ 1097] train: loss: 0.0155453
[Epoch 102; Iter   653/ 1097] train: loss: 0.0191346
[Epoch 102; Iter   683/ 1097] train: loss: 0.0036927
[Epoch 102; Iter   713/ 1097] train: loss: 0.0044450
[Epoch 102; Iter   743/ 1097] train: loss: 0.0814075
[Epoch 102; Iter   773/ 1097] train: loss: 0.0018046
[Epoch 102; Iter   803/ 1097] train: loss: 0.0191351
[Epoch 102; Iter   833/ 1097] train: loss: 0.0020694
[Epoch 102; Iter   863/ 1097] train: loss: 0.0248453
[Epoch 102; Iter   893/ 1097] train: loss: 0.0117014
[Epoch 102; Iter   923/ 1097] train: loss: 0.0166023
[Epoch 102; Iter   953/ 1097] train: loss: 0.0318578
[Epoch 102; Iter   983/ 1097] train: loss: 0.0249225
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0349063
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0092692
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0342169
[Epoch 102] ogbg-molhiv: 0.762465 val loss: 0.161947
[Epoch 102] ogbg-molhiv: 0.720916 test loss: 0.235857
[Epoch 103; Iter     6/ 1097] train: loss: 0.0149675
[Epoch 103; Iter    36/ 1097] train: loss: 0.0060392
[Epoch 103; Iter    66/ 1097] train: loss: 0.0040163
[Epoch 103; Iter    96/ 1097] train: loss: 0.0059395
[Epoch 103; Iter   126/ 1097] train: loss: 0.0311956
[Epoch 103; Iter   156/ 1097] train: loss: 0.0056313
[Epoch 103; Iter   186/ 1097] train: loss: 0.0118143
[Epoch 103; Iter   216/ 1097] train: loss: 0.1030587
[Epoch 103; Iter   246/ 1097] train: loss: 0.0022987
[Epoch 103; Iter   276/ 1097] train: loss: 0.0235673
[Epoch 103; Iter   306/ 1097] train: loss: 0.0518868
[Epoch 103; Iter   336/ 1097] train: loss: 0.0523795
[Epoch 103; Iter   366/ 1097] train: loss: 0.0173894
[Epoch 103; Iter   396/ 1097] train: loss: 0.0178140
[Epoch 103; Iter   426/ 1097] train: loss: 0.0182940
[Epoch 103; Iter   456/ 1097] train: loss: 0.0202533
[Epoch 103; Iter   486/ 1097] train: loss: 0.0081265
[Epoch 103; Iter   516/ 1097] train: loss: 0.0083661
[Epoch 103; Iter   546/ 1097] train: loss: 0.0026880
[Epoch 103; Iter   576/ 1097] train: loss: 0.0408379
[Epoch 103; Iter   606/ 1097] train: loss: 0.0238255
[Epoch 103; Iter   636/ 1097] train: loss: 0.0072281
[Epoch 103; Iter   666/ 1097] train: loss: 0.0079970
[Epoch 103; Iter   696/ 1097] train: loss: 0.0068692
[Epoch 103; Iter   726/ 1097] train: loss: 0.0110878
[Epoch 103; Iter   756/ 1097] train: loss: 0.0039398
[Epoch 103; Iter   786/ 1097] train: loss: 0.0096635
[Epoch 103; Iter   816/ 1097] train: loss: 0.0019589
[Epoch 103; Iter   846/ 1097] train: loss: 0.0219716
[Epoch 103; Iter   876/ 1097] train: loss: 0.0093657
[Epoch 103; Iter   906/ 1097] train: loss: 0.0305134
[Epoch 103; Iter   936/ 1097] train: loss: 0.1298206
[Epoch 103; Iter   966/ 1097] train: loss: 0.1605435
[Epoch 103; Iter   996/ 1097] train: loss: 0.0033292
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0030401
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0209656
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0854169
[Epoch 103] ogbg-molhiv: 0.772086 val loss: 0.160093
[Epoch 103] ogbg-molhiv: 0.717017 test loss: 0.238799
[Epoch 104; Iter    19/ 1097] train: loss: 0.1242642
[Epoch 104; Iter    49/ 1097] train: loss: 0.0039801
[Epoch 104; Iter    79/ 1097] train: loss: 0.0800304
[Epoch 104; Iter   109/ 1097] train: loss: 0.0532631
[Epoch 104; Iter   139/ 1097] train: loss: 0.0013173
[Epoch 104; Iter   169/ 1097] train: loss: 0.0188881
[Epoch 104; Iter   199/ 1097] train: loss: 0.0120263
[Epoch 104; Iter   229/ 1097] train: loss: 0.0334335
[Epoch 104; Iter   259/ 1097] train: loss: 0.1506418
[Epoch 104; Iter   289/ 1097] train: loss: 0.0389434
[Epoch 104; Iter   319/ 1097] train: loss: 0.0027897
[Epoch 104; Iter   349/ 1097] train: loss: 0.0060071
[Epoch 104; Iter   379/ 1097] train: loss: 0.0009932
[Epoch 104; Iter   409/ 1097] train: loss: 0.0807035
[Epoch 104; Iter   439/ 1097] train: loss: 0.0018208
[Epoch 104; Iter   469/ 1097] train: loss: 0.0101755
[Epoch 104; Iter   499/ 1097] train: loss: 0.0579048
[Epoch 104; Iter   529/ 1097] train: loss: 0.0125648
[Epoch 104; Iter   559/ 1097] train: loss: 0.0180684
[Epoch 104; Iter   589/ 1097] train: loss: 0.0327279
[Epoch 104; Iter   619/ 1097] train: loss: 0.0139682
[Epoch 104; Iter   649/ 1097] train: loss: 0.0799877
[Epoch 104; Iter   679/ 1097] train: loss: 0.0055521
[Epoch 104; Iter   709/ 1097] train: loss: 0.0089821
[Epoch 104; Iter   739/ 1097] train: loss: 0.0029248
[Epoch 104; Iter   769/ 1097] train: loss: 0.0066046
[Epoch 104; Iter   799/ 1097] train: loss: 0.0206386
[Epoch 104; Iter   829/ 1097] train: loss: 0.0856264
[Epoch 104; Iter   859/ 1097] train: loss: 0.0016532
[Epoch 104; Iter   889/ 1097] train: loss: 0.0122100
[Epoch 104; Iter   919/ 1097] train: loss: 0.0121025
[Epoch 104; Iter   949/ 1097] train: loss: 0.0033914
[Epoch 104; Iter   979/ 1097] train: loss: 0.0295233
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0028044
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0095004
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0129683
[Epoch 104] ogbg-molhiv: 0.781216 val loss: 0.131290
[Epoch 104] ogbg-molhiv: 0.738502 test loss: 0.224039
[Epoch 105; Iter     2/ 1097] train: loss: 0.0856655
[Epoch 105; Iter    32/ 1097] train: loss: 0.0037814
[Epoch 105; Iter    62/ 1097] train: loss: 0.0170361
[Epoch 105; Iter    92/ 1097] train: loss: 0.1008093
[Epoch 105; Iter   122/ 1097] train: loss: 0.0107978
[Epoch 105; Iter   152/ 1097] train: loss: 0.0097802
[Epoch 105; Iter   182/ 1097] train: loss: 0.0209527
[Epoch 105; Iter   212/ 1097] train: loss: 0.1580977
[Epoch 105; Iter   242/ 1097] train: loss: 0.0036003
[Epoch 105; Iter   272/ 1097] train: loss: 0.0188846
[Epoch 105; Iter   302/ 1097] train: loss: 0.0041331
[Epoch 105; Iter   332/ 1097] train: loss: 0.0084022
[Epoch 105; Iter   362/ 1097] train: loss: 0.0176980
[Epoch 105; Iter   392/ 1097] train: loss: 0.0080258
[Epoch 105; Iter   422/ 1097] train: loss: 0.0235193
[Epoch 105; Iter   452/ 1097] train: loss: 0.0028117
[Epoch 105; Iter   482/ 1097] train: loss: 0.1165465
[Epoch 105; Iter   512/ 1097] train: loss: 0.0566287
[Epoch 105; Iter   542/ 1097] train: loss: 0.0184064
[Epoch 105; Iter   572/ 1097] train: loss: 0.0057866
[Epoch 105; Iter   602/ 1097] train: loss: 0.0338750
[Epoch 105; Iter   632/ 1097] train: loss: 0.0629262
[Epoch 105; Iter   662/ 1097] train: loss: 0.0158397
[Epoch 105; Iter   692/ 1097] train: loss: 0.0466733
[Epoch 105; Iter   722/ 1097] train: loss: 0.0078092
[Epoch 101; Iter   760/ 1097] train: loss: 0.0443397
[Epoch 101; Iter   790/ 1097] train: loss: 0.0064850
[Epoch 101; Iter   820/ 1097] train: loss: 0.0444660
[Epoch 101; Iter   850/ 1097] train: loss: 0.0281292
[Epoch 101; Iter   880/ 1097] train: loss: 0.0136250
[Epoch 101; Iter   910/ 1097] train: loss: 0.0049871
[Epoch 101; Iter   940/ 1097] train: loss: 0.0082294
[Epoch 101; Iter   970/ 1097] train: loss: 0.0297705
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0017258
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0558538
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0525624
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0273383
[Epoch 101] ogbg-molhiv: 0.762024 val loss: 0.151233
[Epoch 101] ogbg-molhiv: 0.737054 test loss: 0.250440
[Epoch 102; Iter    23/ 1097] train: loss: 0.0025294
[Epoch 102; Iter    53/ 1097] train: loss: 0.0303303
[Epoch 102; Iter    83/ 1097] train: loss: 0.0233313
[Epoch 102; Iter   113/ 1097] train: loss: 0.0022308
[Epoch 102; Iter   143/ 1097] train: loss: 0.0104273
[Epoch 102; Iter   173/ 1097] train: loss: 0.0084539
[Epoch 102; Iter   203/ 1097] train: loss: 0.0018293
[Epoch 102; Iter   233/ 1097] train: loss: 0.0865563
[Epoch 102; Iter   263/ 1097] train: loss: 0.0033179
[Epoch 102; Iter   293/ 1097] train: loss: 0.0016627
[Epoch 102; Iter   323/ 1097] train: loss: 0.0136666
[Epoch 102; Iter   353/ 1097] train: loss: 0.0571882
[Epoch 102; Iter   383/ 1097] train: loss: 0.0130826
[Epoch 102; Iter   413/ 1097] train: loss: 0.0524087
[Epoch 102; Iter   443/ 1097] train: loss: 0.0052062
[Epoch 102; Iter   473/ 1097] train: loss: 0.0086049
[Epoch 102; Iter   503/ 1097] train: loss: 0.0251708
[Epoch 102; Iter   533/ 1097] train: loss: 0.0877307
[Epoch 102; Iter   563/ 1097] train: loss: 0.0185857
[Epoch 102; Iter   593/ 1097] train: loss: 0.0017480
[Epoch 102; Iter   623/ 1097] train: loss: 0.0254039
[Epoch 102; Iter   653/ 1097] train: loss: 0.0165219
[Epoch 102; Iter   683/ 1097] train: loss: 0.0006616
[Epoch 102; Iter   713/ 1097] train: loss: 0.0519670
[Epoch 102; Iter   743/ 1097] train: loss: 0.0049399
[Epoch 102; Iter   773/ 1097] train: loss: 0.0012731
[Epoch 102; Iter   803/ 1097] train: loss: 0.0065699
[Epoch 102; Iter   833/ 1097] train: loss: 0.0151188
[Epoch 102; Iter   863/ 1097] train: loss: 0.0024026
[Epoch 102; Iter   893/ 1097] train: loss: 0.0107592
[Epoch 102; Iter   923/ 1097] train: loss: 0.0105851
[Epoch 102; Iter   953/ 1097] train: loss: 0.0070112
[Epoch 102; Iter   983/ 1097] train: loss: 0.0028322
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0230303
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0027563
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0011987
[Epoch 102] ogbg-molhiv: 0.754853 val loss: 0.154866
[Epoch 102] ogbg-molhiv: 0.731103 test loss: 0.334425
[Epoch 103; Iter     6/ 1097] train: loss: 0.0510634
[Epoch 103; Iter    36/ 1097] train: loss: 0.0179284
[Epoch 103; Iter    66/ 1097] train: loss: 0.1062099
[Epoch 103; Iter    96/ 1097] train: loss: 0.0034688
[Epoch 103; Iter   126/ 1097] train: loss: 0.0412836
[Epoch 103; Iter   156/ 1097] train: loss: 0.0313558
[Epoch 103; Iter   186/ 1097] train: loss: 0.0637913
[Epoch 103; Iter   216/ 1097] train: loss: 0.0083419
[Epoch 103; Iter   246/ 1097] train: loss: 0.0477063
[Epoch 103; Iter   276/ 1097] train: loss: 0.0764759
[Epoch 103; Iter   306/ 1097] train: loss: 0.0033260
[Epoch 103; Iter   336/ 1097] train: loss: 0.0018040
[Epoch 103; Iter   366/ 1097] train: loss: 0.0017665
[Epoch 103; Iter   396/ 1097] train: loss: 0.0028943
[Epoch 103; Iter   426/ 1097] train: loss: 0.0042939
[Epoch 103; Iter   456/ 1097] train: loss: 0.0059680
[Epoch 103; Iter   486/ 1097] train: loss: 0.0051086
[Epoch 103; Iter   516/ 1097] train: loss: 0.0118467
[Epoch 103; Iter   546/ 1097] train: loss: 0.0020590
[Epoch 103; Iter   576/ 1097] train: loss: 0.0229337
[Epoch 103; Iter   606/ 1097] train: loss: 0.0034754
[Epoch 103; Iter   636/ 1097] train: loss: 0.0658119
[Epoch 103; Iter   666/ 1097] train: loss: 0.0043770
[Epoch 103; Iter   696/ 1097] train: loss: 0.0029731
[Epoch 103; Iter   726/ 1097] train: loss: 0.0148147
[Epoch 103; Iter   756/ 1097] train: loss: 0.0076434
[Epoch 103; Iter   786/ 1097] train: loss: 0.0018270
[Epoch 103; Iter   816/ 1097] train: loss: 0.0063505
[Epoch 103; Iter   846/ 1097] train: loss: 0.0111080
[Epoch 103; Iter   876/ 1097] train: loss: 0.0028179
[Epoch 103; Iter   906/ 1097] train: loss: 0.0415322
[Epoch 103; Iter   936/ 1097] train: loss: 0.0010375
[Epoch 103; Iter   966/ 1097] train: loss: 0.0019129
[Epoch 103; Iter   996/ 1097] train: loss: 0.1703764
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0717490
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0569995
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0015001
[Epoch 103] ogbg-molhiv: 0.753233 val loss: 0.158627
[Epoch 103] ogbg-molhiv: 0.739808 test loss: 0.254510
[Epoch 104; Iter    19/ 1097] train: loss: 0.0035078
[Epoch 104; Iter    49/ 1097] train: loss: 0.0031442
[Epoch 104; Iter    79/ 1097] train: loss: 0.0272888
[Epoch 104; Iter   109/ 1097] train: loss: 0.0056057
[Epoch 104; Iter   139/ 1097] train: loss: 0.0669529
[Epoch 104; Iter   169/ 1097] train: loss: 0.1143627
[Epoch 104; Iter   199/ 1097] train: loss: 0.0509764
[Epoch 104; Iter   229/ 1097] train: loss: 0.0844917
[Epoch 104; Iter   259/ 1097] train: loss: 0.0024283
[Epoch 104; Iter   289/ 1097] train: loss: 0.0041415
[Epoch 104; Iter   319/ 1097] train: loss: 0.0051656
[Epoch 104; Iter   349/ 1097] train: loss: 0.0162091
[Epoch 104; Iter   379/ 1097] train: loss: 0.0001441
[Epoch 104; Iter   409/ 1097] train: loss: 0.0145201
[Epoch 104; Iter   439/ 1097] train: loss: 0.0012026
[Epoch 104; Iter   469/ 1097] train: loss: 0.0039771
[Epoch 104; Iter   499/ 1097] train: loss: 0.0247095
[Epoch 104; Iter   529/ 1097] train: loss: 0.0049037
[Epoch 104; Iter   559/ 1097] train: loss: 0.0087604
[Epoch 104; Iter   589/ 1097] train: loss: 0.0031257
[Epoch 104; Iter   619/ 1097] train: loss: 0.0011479
[Epoch 104; Iter   649/ 1097] train: loss: 0.0131447
[Epoch 104; Iter   679/ 1097] train: loss: 0.0251391
[Epoch 104; Iter   709/ 1097] train: loss: 0.0037904
[Epoch 104; Iter   739/ 1097] train: loss: 0.0038074
[Epoch 104; Iter   769/ 1097] train: loss: 0.0004660
[Epoch 104; Iter   799/ 1097] train: loss: 0.0929040
[Epoch 104; Iter   829/ 1097] train: loss: 0.1082918
[Epoch 104; Iter   859/ 1097] train: loss: 0.0043929
[Epoch 104; Iter   889/ 1097] train: loss: 0.0505418
[Epoch 104; Iter   919/ 1097] train: loss: 0.0105886
[Epoch 104; Iter   949/ 1097] train: loss: 0.0112929
[Epoch 104; Iter   979/ 1097] train: loss: 0.1801095
[Epoch 104; Iter  1009/ 1097] train: loss: 0.0178203
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0576261
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0758577
[Epoch 104] ogbg-molhiv: 0.745208 val loss: 0.167610
[Epoch 104] ogbg-molhiv: 0.735783 test loss: 0.317824
[Epoch 105; Iter     2/ 1097] train: loss: 0.0072940
[Epoch 105; Iter    32/ 1097] train: loss: 0.0106115
[Epoch 105; Iter    62/ 1097] train: loss: 0.0101830
[Epoch 105; Iter    92/ 1097] train: loss: 0.0254519
[Epoch 105; Iter   122/ 1097] train: loss: 0.0033457
[Epoch 105; Iter   152/ 1097] train: loss: 0.0106243
[Epoch 105; Iter   182/ 1097] train: loss: 0.0177460
[Epoch 105; Iter   212/ 1097] train: loss: 0.0043093
[Epoch 105; Iter   242/ 1097] train: loss: 0.0014939
[Epoch 105; Iter   272/ 1097] train: loss: 0.0028598
[Epoch 105; Iter   302/ 1097] train: loss: 0.0074147
[Epoch 105; Iter   332/ 1097] train: loss: 0.1337632
[Epoch 105; Iter   362/ 1097] train: loss: 0.0022063
[Epoch 105; Iter   392/ 1097] train: loss: 0.0031601
[Epoch 105; Iter   422/ 1097] train: loss: 0.0504104
[Epoch 105; Iter   452/ 1097] train: loss: 0.0091461
[Epoch 105; Iter   482/ 1097] train: loss: 0.0114339
[Epoch 105; Iter   512/ 1097] train: loss: 0.0017197
[Epoch 105; Iter   542/ 1097] train: loss: 0.0077036
[Epoch 105; Iter   572/ 1097] train: loss: 0.0023528
[Epoch 105; Iter   602/ 1097] train: loss: 0.0310532
[Epoch 105; Iter   632/ 1097] train: loss: 0.0063029
[Epoch 105; Iter   662/ 1097] train: loss: 0.0020500
[Epoch 105; Iter   692/ 1097] train: loss: 0.0246212
[Epoch 105; Iter   722/ 1097] train: loss: 0.0059725
[Epoch 105; Iter   870/  960] train: loss: 0.0007946
[Epoch 105; Iter   900/  960] train: loss: 0.0092072
[Epoch 105; Iter   930/  960] train: loss: 0.1195076
[Epoch 105; Iter   960/  960] train: loss: 0.0047248
[Epoch 105] ogbg-molhiv: 0.718436 val loss: 0.392135
[Epoch 105] ogbg-molhiv: 0.757820 test loss: 0.537584
[Epoch 106; Iter    30/  960] train: loss: 0.1282531
[Epoch 106; Iter    60/  960] train: loss: 0.0325013
[Epoch 106; Iter    90/  960] train: loss: 0.0252113
[Epoch 106; Iter   120/  960] train: loss: 0.0005499
[Epoch 106; Iter   150/  960] train: loss: 0.0076088
[Epoch 106; Iter   180/  960] train: loss: 0.0356870
[Epoch 106; Iter   210/  960] train: loss: 0.0020239
[Epoch 106; Iter   240/  960] train: loss: 0.0019867
[Epoch 106; Iter   270/  960] train: loss: 0.0165483
[Epoch 106; Iter   300/  960] train: loss: 0.0042048
[Epoch 106; Iter   330/  960] train: loss: 0.0015675
[Epoch 106; Iter   360/  960] train: loss: 0.0017834
[Epoch 106; Iter   390/  960] train: loss: 0.0007204
[Epoch 106; Iter   420/  960] train: loss: 0.0221669
[Epoch 106; Iter   450/  960] train: loss: 0.0014494
[Epoch 106; Iter   480/  960] train: loss: 0.0038925
[Epoch 106; Iter   510/  960] train: loss: 0.0016543
[Epoch 106; Iter   540/  960] train: loss: 0.0180869
[Epoch 106; Iter   570/  960] train: loss: 0.0361940
[Epoch 106; Iter   600/  960] train: loss: 0.0250663
[Epoch 106; Iter   630/  960] train: loss: 0.0078723
[Epoch 106; Iter   660/  960] train: loss: 0.0196654
[Epoch 106; Iter   690/  960] train: loss: 0.0017840
[Epoch 106; Iter   720/  960] train: loss: 0.0345920
[Epoch 106; Iter   750/  960] train: loss: 0.0294968
[Epoch 106; Iter   780/  960] train: loss: 0.0219745
[Epoch 106; Iter   810/  960] train: loss: 0.0014709
[Epoch 106; Iter   840/  960] train: loss: 0.0008676
[Epoch 106; Iter   870/  960] train: loss: 0.0037756
[Epoch 106; Iter   900/  960] train: loss: 0.0043836
[Epoch 106; Iter   930/  960] train: loss: 0.0388826
[Epoch 106; Iter   960/  960] train: loss: 0.0058311
[Epoch 106] ogbg-molhiv: 0.713825 val loss: 0.422509
[Epoch 106] ogbg-molhiv: 0.747644 test loss: 0.656387
[Epoch 107; Iter    30/  960] train: loss: 0.0014985
[Epoch 107; Iter    60/  960] train: loss: 0.0259204
[Epoch 107; Iter    90/  960] train: loss: 0.0027336
[Epoch 107; Iter   120/  960] train: loss: 0.0301114
[Epoch 107; Iter   150/  960] train: loss: 0.0014380
[Epoch 107; Iter   180/  960] train: loss: 0.0054439
[Epoch 107; Iter   210/  960] train: loss: 0.0109106
[Epoch 107; Iter   240/  960] train: loss: 0.0027552
[Epoch 107; Iter   270/  960] train: loss: 0.0076575
[Epoch 107; Iter   300/  960] train: loss: 0.0035372
[Epoch 107; Iter   330/  960] train: loss: 0.0029957
[Epoch 107; Iter   360/  960] train: loss: 0.0070646
[Epoch 107; Iter   390/  960] train: loss: 0.0067483
[Epoch 107; Iter   420/  960] train: loss: 0.0155370
[Epoch 107; Iter   450/  960] train: loss: 0.0029563
[Epoch 107; Iter   480/  960] train: loss: 0.0026188
[Epoch 107; Iter   510/  960] train: loss: 0.0026982
[Epoch 107; Iter   540/  960] train: loss: 0.0108872
[Epoch 107; Iter   570/  960] train: loss: 0.0116014
[Epoch 107; Iter   600/  960] train: loss: 0.0318595
[Epoch 107; Iter   630/  960] train: loss: 0.0128079
[Epoch 107; Iter   660/  960] train: loss: 0.0020788
[Epoch 107; Iter   690/  960] train: loss: 0.0022331
[Epoch 107; Iter   720/  960] train: loss: 0.0007521
[Epoch 107; Iter   750/  960] train: loss: 0.0025450
[Epoch 107; Iter   780/  960] train: loss: 0.0004360
[Epoch 107; Iter   810/  960] train: loss: 0.0002934
[Epoch 107; Iter   840/  960] train: loss: 0.0036596
[Epoch 107; Iter   870/  960] train: loss: 0.0004125
[Epoch 107; Iter   900/  960] train: loss: 0.0131923
[Epoch 107; Iter   930/  960] train: loss: 0.0013149
[Epoch 107; Iter   960/  960] train: loss: 0.0582871
[Epoch 107] ogbg-molhiv: 0.716412 val loss: 0.294327
[Epoch 107] ogbg-molhiv: 0.750099 test loss: 0.253285
[Epoch 108; Iter    30/  960] train: loss: 0.0228030
[Epoch 108; Iter    60/  960] train: loss: 0.0047745
[Epoch 108; Iter    90/  960] train: loss: 0.0427427
[Epoch 108; Iter   120/  960] train: loss: 0.0042620
[Epoch 108; Iter   150/  960] train: loss: 0.0006982
[Epoch 108; Iter   180/  960] train: loss: 0.0519540
[Epoch 108; Iter   210/  960] train: loss: 0.0177657
[Epoch 108; Iter   240/  960] train: loss: 0.0264254
[Epoch 108; Iter   270/  960] train: loss: 0.0231137
[Epoch 108; Iter   300/  960] train: loss: 0.0340349
[Epoch 108; Iter   330/  960] train: loss: 0.0059807
[Epoch 108; Iter   360/  960] train: loss: 0.0079218
[Epoch 108; Iter   390/  960] train: loss: 0.0012376
[Epoch 108; Iter   420/  960] train: loss: 0.0026473
[Epoch 108; Iter   450/  960] train: loss: 0.0009255
[Epoch 108; Iter   480/  960] train: loss: 0.0171840
[Epoch 108; Iter   510/  960] train: loss: 0.0044456
[Epoch 108; Iter   540/  960] train: loss: 0.0024054
[Epoch 108; Iter   570/  960] train: loss: 0.0038124
[Epoch 108; Iter   600/  960] train: loss: 0.0069361
[Epoch 108; Iter   630/  960] train: loss: 0.0440228
[Epoch 108; Iter   660/  960] train: loss: 0.0007462
[Epoch 108; Iter   690/  960] train: loss: 0.0031534
[Epoch 108; Iter   720/  960] train: loss: 0.0016167
[Epoch 108; Iter   750/  960] train: loss: 0.0229182
[Epoch 108; Iter   780/  960] train: loss: 0.0005708
[Epoch 108; Iter   810/  960] train: loss: 0.0880478
[Epoch 108; Iter   840/  960] train: loss: 0.0418535
[Epoch 108; Iter   870/  960] train: loss: 0.0458304
[Epoch 108; Iter   900/  960] train: loss: 0.0064976
[Epoch 108; Iter   930/  960] train: loss: 0.0153874
[Epoch 108; Iter   960/  960] train: loss: 0.1076583
[Epoch 108] ogbg-molhiv: 0.723467 val loss: 0.412296
[Epoch 108] ogbg-molhiv: 0.762430 test loss: 0.593213
[Epoch 109; Iter    30/  960] train: loss: 0.0198201
[Epoch 109; Iter    60/  960] train: loss: 0.0063698
[Epoch 109; Iter    90/  960] train: loss: 0.0037735
[Epoch 109; Iter   120/  960] train: loss: 0.0020127
[Epoch 109; Iter   150/  960] train: loss: 0.0257838
[Epoch 109; Iter   180/  960] train: loss: 0.0452660
[Epoch 109; Iter   210/  960] train: loss: 0.0373393
[Epoch 109; Iter   240/  960] train: loss: 0.0013416
[Epoch 109; Iter   270/  960] train: loss: 0.0045051
[Epoch 109; Iter   300/  960] train: loss: 0.0301285
[Epoch 109; Iter   330/  960] train: loss: 0.0144696
[Epoch 109; Iter   360/  960] train: loss: 0.0081381
[Epoch 109; Iter   390/  960] train: loss: 0.0163191
[Epoch 109; Iter   420/  960] train: loss: 0.0007614
[Epoch 109; Iter   450/  960] train: loss: 0.0011360
[Epoch 109; Iter   480/  960] train: loss: 0.0030061
[Epoch 109; Iter   510/  960] train: loss: 0.0405088
[Epoch 109; Iter   540/  960] train: loss: 0.0014948
[Epoch 109; Iter   570/  960] train: loss: 0.0010017
[Epoch 109; Iter   600/  960] train: loss: 0.0091094
[Epoch 109; Iter   630/  960] train: loss: 0.0774720
[Epoch 109; Iter   660/  960] train: loss: 0.0133616
[Epoch 109; Iter   690/  960] train: loss: 0.0064089
[Epoch 109; Iter   720/  960] train: loss: 0.0058322
[Epoch 109; Iter   750/  960] train: loss: 0.0659393
[Epoch 109; Iter   780/  960] train: loss: 0.0079271
[Epoch 109; Iter   810/  960] train: loss: 0.0128727
[Epoch 109; Iter   840/  960] train: loss: 0.0011053
[Epoch 109; Iter   870/  960] train: loss: 0.0010643
[Epoch 109; Iter   900/  960] train: loss: 0.0048294
[Epoch 109; Iter   930/  960] train: loss: 0.0524965
[Epoch 109; Iter   960/  960] train: loss: 0.0183321
[Epoch 109] ogbg-molhiv: 0.710549 val loss: 0.300609
[Epoch 109] ogbg-molhiv: 0.752016 test loss: 0.238653
[Epoch 110; Iter    30/  960] train: loss: 0.0146401
[Epoch 110; Iter    60/  960] train: loss: 0.0306024
[Epoch 110; Iter    90/  960] train: loss: 0.0088626
[Epoch 110; Iter   120/  960] train: loss: 0.0033158
[Epoch 110; Iter   150/  960] train: loss: 0.0185822
[Epoch 110; Iter   180/  960] train: loss: 0.0210142
[Epoch 110; Iter   210/  960] train: loss: 0.0164845
[Epoch 110; Iter   240/  960] train: loss: 0.0065222
[Epoch 110; Iter   270/  960] train: loss: 0.0001744
[Epoch 110; Iter   300/  960] train: loss: 0.0052764
[Epoch 110; Iter   330/  960] train: loss: 0.0157844
[Epoch 110; Iter   360/  960] train: loss: 0.0104736
[Epoch 105; Iter   870/  960] train: loss: 0.0045974
[Epoch 105; Iter   900/  960] train: loss: 0.0029031
[Epoch 105; Iter   930/  960] train: loss: 0.0040660
[Epoch 105; Iter   960/  960] train: loss: 0.2069362
[Epoch 105] ogbg-molhiv: 0.758850 val loss: 1.160271
[Epoch 105] ogbg-molhiv: 0.755384 test loss: 0.317109
[Epoch 106; Iter    30/  960] train: loss: 0.0318226
[Epoch 106; Iter    60/  960] train: loss: 0.0183344
[Epoch 106; Iter    90/  960] train: loss: 0.0280998
[Epoch 106; Iter   120/  960] train: loss: 0.0005843
[Epoch 106; Iter   150/  960] train: loss: 0.0015165
[Epoch 106; Iter   180/  960] train: loss: 0.0228339
[Epoch 106; Iter   210/  960] train: loss: 0.0017210
[Epoch 106; Iter   240/  960] train: loss: 0.0021497
[Epoch 106; Iter   270/  960] train: loss: 0.0421044
[Epoch 106; Iter   300/  960] train: loss: 0.0020339
[Epoch 106; Iter   330/  960] train: loss: 0.0009605
[Epoch 106; Iter   360/  960] train: loss: 0.0175519
[Epoch 106; Iter   390/  960] train: loss: 0.0422384
[Epoch 106; Iter   420/  960] train: loss: 0.0283828
[Epoch 106; Iter   450/  960] train: loss: 0.0110487
[Epoch 106; Iter   480/  960] train: loss: 0.0972035
[Epoch 106; Iter   510/  960] train: loss: 0.0008375
[Epoch 106; Iter   540/  960] train: loss: 0.0043803
[Epoch 106; Iter   570/  960] train: loss: 0.0381135
[Epoch 106; Iter   600/  960] train: loss: 0.0295537
[Epoch 106; Iter   630/  960] train: loss: 0.0063739
[Epoch 106; Iter   660/  960] train: loss: 0.0013000
[Epoch 106; Iter   690/  960] train: loss: 0.0037714
[Epoch 106; Iter   720/  960] train: loss: 0.0021085
[Epoch 106; Iter   750/  960] train: loss: 0.0253453
[Epoch 106; Iter   780/  960] train: loss: 0.0052332
[Epoch 106; Iter   810/  960] train: loss: 0.0557626
[Epoch 106; Iter   840/  960] train: loss: 0.0010806
[Epoch 106; Iter   870/  960] train: loss: 0.0211573
[Epoch 106; Iter   900/  960] train: loss: 0.0032108
[Epoch 106; Iter   930/  960] train: loss: 0.0268142
[Epoch 106; Iter   960/  960] train: loss: 0.0012493
[Epoch 106] ogbg-molhiv: 0.755446 val loss: 1.242269
[Epoch 106] ogbg-molhiv: 0.748625 test loss: 0.311895
[Epoch 107; Iter    30/  960] train: loss: 0.0057909
[Epoch 107; Iter    60/  960] train: loss: 0.0037517
[Epoch 107; Iter    90/  960] train: loss: 0.0033740
[Epoch 107; Iter   120/  960] train: loss: 0.0131811
[Epoch 107; Iter   150/  960] train: loss: 0.0434753
[Epoch 107; Iter   180/  960] train: loss: 0.0434039
[Epoch 107; Iter   210/  960] train: loss: 0.0114231
[Epoch 107; Iter   240/  960] train: loss: 0.0042874
[Epoch 107; Iter   270/  960] train: loss: 0.0217896
[Epoch 107; Iter   300/  960] train: loss: 0.0013995
[Epoch 107; Iter   330/  960] train: loss: 0.0292288
[Epoch 107; Iter   360/  960] train: loss: 0.0085746
[Epoch 107; Iter   390/  960] train: loss: 0.0194646
[Epoch 107; Iter   420/  960] train: loss: 0.0244432
[Epoch 107; Iter   450/  960] train: loss: 0.0036137
[Epoch 107; Iter   480/  960] train: loss: 0.0007757
[Epoch 107; Iter   510/  960] train: loss: 0.0041032
[Epoch 107; Iter   540/  960] train: loss: 0.0039840
[Epoch 107; Iter   570/  960] train: loss: 0.0218660
[Epoch 107; Iter   600/  960] train: loss: 0.0561000
[Epoch 107; Iter   630/  960] train: loss: 0.0043469
[Epoch 107; Iter   660/  960] train: loss: 0.0109948
[Epoch 107; Iter   690/  960] train: loss: 0.0096983
[Epoch 107; Iter   720/  960] train: loss: 0.0158118
[Epoch 107; Iter   750/  960] train: loss: 0.0058099
[Epoch 107; Iter   780/  960] train: loss: 0.0012658
[Epoch 107; Iter   810/  960] train: loss: 0.0011088
[Epoch 107; Iter   840/  960] train: loss: 0.0015658
[Epoch 107; Iter   870/  960] train: loss: 0.0056899
[Epoch 107; Iter   900/  960] train: loss: 0.0217824
[Epoch 107; Iter   930/  960] train: loss: 0.0028476
[Epoch 107; Iter   960/  960] train: loss: 0.0158118
[Epoch 107] ogbg-molhiv: 0.754708 val loss: 1.116679
[Epoch 107] ogbg-molhiv: 0.755014 test loss: 0.299849
[Epoch 108; Iter    30/  960] train: loss: 0.0040416
[Epoch 108; Iter    60/  960] train: loss: 0.0057172
[Epoch 108; Iter    90/  960] train: loss: 0.0040860
[Epoch 108; Iter   120/  960] train: loss: 0.0004790
[Epoch 108; Iter   150/  960] train: loss: 0.0138620
[Epoch 108; Iter   180/  960] train: loss: 0.0147995
[Epoch 108; Iter   210/  960] train: loss: 0.0113761
[Epoch 108; Iter   240/  960] train: loss: 0.0113017
[Epoch 108; Iter   270/  960] train: loss: 0.0026065
[Epoch 108; Iter   300/  960] train: loss: 0.0011742
[Epoch 108; Iter   330/  960] train: loss: 0.0523797
[Epoch 108; Iter   360/  960] train: loss: 0.0010392
[Epoch 108; Iter   390/  960] train: loss: 0.0042715
[Epoch 108; Iter   420/  960] train: loss: 0.0140721
[Epoch 108; Iter   450/  960] train: loss: 0.0050148
[Epoch 108; Iter   480/  960] train: loss: 0.0023154
[Epoch 108; Iter   510/  960] train: loss: 0.0023978
[Epoch 108; Iter   540/  960] train: loss: 0.0212030
[Epoch 108; Iter   570/  960] train: loss: 0.0291892
[Epoch 108; Iter   600/  960] train: loss: 0.0362753
[Epoch 108; Iter   630/  960] train: loss: 0.0010326
[Epoch 108; Iter   660/  960] train: loss: 0.0516144
[Epoch 108; Iter   690/  960] train: loss: 0.0224800
[Epoch 108; Iter   720/  960] train: loss: 0.0013981
[Epoch 108; Iter   750/  960] train: loss: 0.0015480
[Epoch 108; Iter   780/  960] train: loss: 0.0243787
[Epoch 108; Iter   810/  960] train: loss: 0.0031047
[Epoch 108; Iter   840/  960] train: loss: 0.0063668
[Epoch 108; Iter   870/  960] train: loss: 0.0086072
[Epoch 108; Iter   900/  960] train: loss: 0.0047761
[Epoch 108; Iter   930/  960] train: loss: 0.0023825
[Epoch 108; Iter   960/  960] train: loss: 0.0104563
[Epoch 108] ogbg-molhiv: 0.754398 val loss: 1.223494
[Epoch 108] ogbg-molhiv: 0.759770 test loss: 0.298048
[Epoch 109; Iter    30/  960] train: loss: 0.0300535
[Epoch 109; Iter    60/  960] train: loss: 0.0737135
[Epoch 109; Iter    90/  960] train: loss: 0.0133955
[Epoch 109; Iter   120/  960] train: loss: 0.0739439
[Epoch 109; Iter   150/  960] train: loss: 0.0022210
[Epoch 109; Iter   180/  960] train: loss: 0.0025861
[Epoch 109; Iter   210/  960] train: loss: 0.0006247
[Epoch 109; Iter   240/  960] train: loss: 0.0023912
[Epoch 109; Iter   270/  960] train: loss: 0.0019500
[Epoch 109; Iter   300/  960] train: loss: 0.0018329
[Epoch 109; Iter   330/  960] train: loss: 0.0223063
[Epoch 109; Iter   360/  960] train: loss: 0.0011917
[Epoch 109; Iter   390/  960] train: loss: 0.0080583
[Epoch 109; Iter   420/  960] train: loss: 0.0012222
[Epoch 109; Iter   450/  960] train: loss: 0.0013773
[Epoch 109; Iter   480/  960] train: loss: 0.1110223
[Epoch 109; Iter   510/  960] train: loss: 0.1270473
[Epoch 109; Iter   540/  960] train: loss: 0.0035120
[Epoch 109; Iter   570/  960] train: loss: 0.0032031
[Epoch 109; Iter   600/  960] train: loss: 0.0008392
[Epoch 109; Iter   630/  960] train: loss: 0.0002778
[Epoch 109; Iter   660/  960] train: loss: 0.0194347
[Epoch 109; Iter   690/  960] train: loss: 0.0517539
[Epoch 109; Iter   720/  960] train: loss: 0.0014271
[Epoch 109; Iter   750/  960] train: loss: 0.1329645
[Epoch 109; Iter   780/  960] train: loss: 0.0031995
[Epoch 109; Iter   810/  960] train: loss: 0.0565833
[Epoch 109; Iter   840/  960] train: loss: 0.0016420
[Epoch 109; Iter   870/  960] train: loss: 0.0006123
[Epoch 109; Iter   900/  960] train: loss: 0.0069554
[Epoch 109; Iter   930/  960] train: loss: 0.0046230
[Epoch 109; Iter   960/  960] train: loss: 0.0070821
[Epoch 109] ogbg-molhiv: 0.757332 val loss: 1.241966
[Epoch 109] ogbg-molhiv: 0.756866 test loss: 0.297316
[Epoch 110; Iter    30/  960] train: loss: 0.0093291
[Epoch 110; Iter    60/  960] train: loss: 0.0045059
[Epoch 110; Iter    90/  960] train: loss: 0.0088016
[Epoch 110; Iter   120/  960] train: loss: 0.0033873
[Epoch 110; Iter   150/  960] train: loss: 0.0239263
[Epoch 110; Iter   180/  960] train: loss: 0.0029329
[Epoch 110; Iter   210/  960] train: loss: 0.0006549
[Epoch 110; Iter   240/  960] train: loss: 0.0305645
[Epoch 110; Iter   270/  960] train: loss: 0.0638451
[Epoch 110; Iter   300/  960] train: loss: 0.0031003
[Epoch 110; Iter   330/  960] train: loss: 0.0134833
[Epoch 110; Iter   360/  960] train: loss: 0.0055273
[Epoch 105; Iter   870/  960] train: loss: 0.0064285
[Epoch 105; Iter   900/  960] train: loss: 0.0197331
[Epoch 105; Iter   930/  960] train: loss: 0.0019300
[Epoch 105; Iter   960/  960] train: loss: 0.0442664
[Epoch 105] ogbg-molhiv: 0.709670 val loss: 0.884392
[Epoch 105] ogbg-molhiv: 0.745912 test loss: 0.739822
[Epoch 106; Iter    30/  960] train: loss: 0.0276395
[Epoch 106; Iter    60/  960] train: loss: 0.0619385
[Epoch 106; Iter    90/  960] train: loss: 0.0454529
[Epoch 106; Iter   120/  960] train: loss: 0.0036749
[Epoch 106; Iter   150/  960] train: loss: 0.0077260
[Epoch 106; Iter   180/  960] train: loss: 0.0035637
[Epoch 106; Iter   210/  960] train: loss: 0.0069624
[Epoch 106; Iter   240/  960] train: loss: 0.0321820
[Epoch 106; Iter   270/  960] train: loss: 0.0185494
[Epoch 106; Iter   300/  960] train: loss: 0.0607327
[Epoch 106; Iter   330/  960] train: loss: 0.0061528
[Epoch 106; Iter   360/  960] train: loss: 0.0008471
[Epoch 106; Iter   390/  960] train: loss: 0.0228073
[Epoch 106; Iter   420/  960] train: loss: 0.0187174
[Epoch 106; Iter   450/  960] train: loss: 0.0161770
[Epoch 106; Iter   480/  960] train: loss: 0.0200443
[Epoch 106; Iter   510/  960] train: loss: 0.1459212
[Epoch 106; Iter   540/  960] train: loss: 0.0305738
[Epoch 106; Iter   570/  960] train: loss: 0.0111093
[Epoch 106; Iter   600/  960] train: loss: 0.0284875
[Epoch 106; Iter   630/  960] train: loss: 0.0089214
[Epoch 106; Iter   660/  960] train: loss: 0.0269563
[Epoch 106; Iter   690/  960] train: loss: 0.0370358
[Epoch 106; Iter   720/  960] train: loss: 0.0076134
[Epoch 106; Iter   750/  960] train: loss: 0.0681647
[Epoch 106; Iter   780/  960] train: loss: 0.0048107
[Epoch 106; Iter   810/  960] train: loss: 0.0024402
[Epoch 106; Iter   840/  960] train: loss: 0.0045685
[Epoch 106; Iter   870/  960] train: loss: 0.0063881
[Epoch 106; Iter   900/  960] train: loss: 0.0011802
[Epoch 106; Iter   930/  960] train: loss: 0.0009465
[Epoch 106; Iter   960/  960] train: loss: 0.0038557
[Epoch 106] ogbg-molhiv: 0.716495 val loss: 1.047866
[Epoch 106] ogbg-molhiv: 0.753140 test loss: 0.762129
[Epoch 107; Iter    30/  960] train: loss: 0.0063637
[Epoch 107; Iter    60/  960] train: loss: 0.0040655
[Epoch 107; Iter    90/  960] train: loss: 0.0035007
[Epoch 107; Iter   120/  960] train: loss: 0.0022891
[Epoch 107; Iter   150/  960] train: loss: 0.0298968
[Epoch 107; Iter   180/  960] train: loss: 0.1976853
[Epoch 107; Iter   210/  960] train: loss: 0.0066781
[Epoch 107; Iter   240/  960] train: loss: 0.0013468
[Epoch 107; Iter   270/  960] train: loss: 0.0013583
[Epoch 107; Iter   300/  960] train: loss: 0.0111905
[Epoch 107; Iter   330/  960] train: loss: 0.0071767
[Epoch 107; Iter   360/  960] train: loss: 0.0005246
[Epoch 107; Iter   390/  960] train: loss: 0.0039038
[Epoch 107; Iter   420/  960] train: loss: 0.0527768
[Epoch 107; Iter   450/  960] train: loss: 0.0397419
[Epoch 107; Iter   480/  960] train: loss: 0.0051060
[Epoch 107; Iter   510/  960] train: loss: 0.0245657
[Epoch 107; Iter   540/  960] train: loss: 0.0556483
[Epoch 107; Iter   570/  960] train: loss: 0.0232207
[Epoch 107; Iter   600/  960] train: loss: 0.0529229
[Epoch 107; Iter   630/  960] train: loss: 0.0195798
[Epoch 107; Iter   660/  960] train: loss: 0.0078494
[Epoch 107; Iter   690/  960] train: loss: 0.0274178
[Epoch 107; Iter   720/  960] train: loss: 0.0026172
[Epoch 107; Iter   750/  960] train: loss: 0.0034211
[Epoch 107; Iter   780/  960] train: loss: 0.0601800
[Epoch 107; Iter   810/  960] train: loss: 0.0030563
[Epoch 107; Iter   840/  960] train: loss: 0.0147402
[Epoch 107; Iter   870/  960] train: loss: 0.0018422
[Epoch 107; Iter   900/  960] train: loss: 0.0079855
[Epoch 107; Iter   930/  960] train: loss: 0.0026159
[Epoch 107; Iter   960/  960] train: loss: 0.0147333
[Epoch 107] ogbg-molhiv: 0.714907 val loss: 0.760691
[Epoch 107] ogbg-molhiv: 0.753020 test loss: 0.468213
[Epoch 108; Iter    30/  960] train: loss: 0.0003456
[Epoch 108; Iter    60/  960] train: loss: 0.0050792
[Epoch 108; Iter    90/  960] train: loss: 0.0211365
[Epoch 108; Iter   120/  960] train: loss: 0.0089454
[Epoch 108; Iter   150/  960] train: loss: 0.0126188
[Epoch 108; Iter   180/  960] train: loss: 0.0108733
[Epoch 108; Iter   210/  960] train: loss: 0.0116594
[Epoch 108; Iter   240/  960] train: loss: 0.0291969
[Epoch 108; Iter   270/  960] train: loss: 0.0086513
[Epoch 108; Iter   300/  960] train: loss: 0.0141563
[Epoch 108; Iter   330/  960] train: loss: 0.0055435
[Epoch 108; Iter   360/  960] train: loss: 0.0052580
[Epoch 108; Iter   390/  960] train: loss: 0.0022814
[Epoch 108; Iter   420/  960] train: loss: 0.0046211
[Epoch 108; Iter   450/  960] train: loss: 0.0020489
[Epoch 108; Iter   480/  960] train: loss: 0.0013565
[Epoch 108; Iter   510/  960] train: loss: 0.0150863
[Epoch 108; Iter   540/  960] train: loss: 0.0204906
[Epoch 108; Iter   570/  960] train: loss: 0.0049914
[Epoch 108; Iter   600/  960] train: loss: 0.0208650
[Epoch 108; Iter   630/  960] train: loss: 0.0647338
[Epoch 108; Iter   660/  960] train: loss: 0.0039955
[Epoch 108; Iter   690/  960] train: loss: 0.1083995
[Epoch 108; Iter   720/  960] train: loss: 0.0010594
[Epoch 108; Iter   750/  960] train: loss: 0.0049347
[Epoch 108; Iter   780/  960] train: loss: 0.0057028
[Epoch 108; Iter   810/  960] train: loss: 0.0018674
[Epoch 108; Iter   840/  960] train: loss: 0.1925939
[Epoch 108; Iter   870/  960] train: loss: 0.0432579
[Epoch 108; Iter   900/  960] train: loss: 0.0247054
[Epoch 108; Iter   930/  960] train: loss: 0.0121224
[Epoch 108; Iter   960/  960] train: loss: 0.2099732
[Epoch 108] ogbg-molhiv: 0.717161 val loss: 1.057363
[Epoch 108] ogbg-molhiv: 0.748304 test loss: 0.733507
[Epoch 109; Iter    30/  960] train: loss: 0.0017355
[Epoch 109; Iter    60/  960] train: loss: 0.0030810
[Epoch 109; Iter    90/  960] train: loss: 0.0144862
[Epoch 109; Iter   120/  960] train: loss: 0.0352364
[Epoch 109; Iter   150/  960] train: loss: 0.1578008
[Epoch 109; Iter   180/  960] train: loss: 0.0006714
[Epoch 109; Iter   210/  960] train: loss: 0.0415677
[Epoch 109; Iter   240/  960] train: loss: 0.0052073
[Epoch 109; Iter   270/  960] train: loss: 0.0609446
[Epoch 109; Iter   300/  960] train: loss: 0.0015912
[Epoch 109; Iter   330/  960] train: loss: 0.0252725
[Epoch 109; Iter   360/  960] train: loss: 0.0030485
[Epoch 109; Iter   390/  960] train: loss: 0.0530029
[Epoch 109; Iter   420/  960] train: loss: 0.0006409
[Epoch 109; Iter   450/  960] train: loss: 0.0076634
[Epoch 109; Iter   480/  960] train: loss: 0.0058334
[Epoch 109; Iter   510/  960] train: loss: 0.0309843
[Epoch 109; Iter   540/  960] train: loss: 0.0043237
[Epoch 109; Iter   570/  960] train: loss: 0.0106674
[Epoch 109; Iter   600/  960] train: loss: 0.0090995
[Epoch 109; Iter   630/  960] train: loss: 0.0137399
[Epoch 109; Iter   660/  960] train: loss: 0.0017928
[Epoch 109; Iter   690/  960] train: loss: 0.0291874
[Epoch 109; Iter   720/  960] train: loss: 0.0023677
[Epoch 109; Iter   750/  960] train: loss: 0.0069341
[Epoch 109; Iter   780/  960] train: loss: 0.0215913
[Epoch 109; Iter   810/  960] train: loss: 0.0092492
[Epoch 109; Iter   840/  960] train: loss: 0.0592877
[Epoch 109; Iter   870/  960] train: loss: 0.0624276
[Epoch 109; Iter   900/  960] train: loss: 0.0036851
[Epoch 109; Iter   930/  960] train: loss: 0.0019597
[Epoch 109; Iter   960/  960] train: loss: 0.0008708
[Epoch 109] ogbg-molhiv: 0.716493 val loss: 0.579006
[Epoch 109] ogbg-molhiv: 0.746176 test loss: 0.527021
[Epoch 110; Iter    30/  960] train: loss: 0.1522702
[Epoch 110; Iter    60/  960] train: loss: 0.0126463
[Epoch 110; Iter    90/  960] train: loss: 0.0061421
[Epoch 110; Iter   120/  960] train: loss: 0.0471607
[Epoch 110; Iter   150/  960] train: loss: 0.0020920
[Epoch 110; Iter   180/  960] train: loss: 0.0054949
[Epoch 110; Iter   210/  960] train: loss: 0.0451624
[Epoch 110; Iter   240/  960] train: loss: 0.0129476
[Epoch 110; Iter   270/  960] train: loss: 0.0782550
[Epoch 110; Iter   300/  960] train: loss: 0.0312825
[Epoch 110; Iter   330/  960] train: loss: 0.0029229
[Epoch 110; Iter   360/  960] train: loss: 0.0046555
[Epoch 101; Iter   760/ 1097] train: loss: 0.0995509
[Epoch 101; Iter   790/ 1097] train: loss: 0.0085005
[Epoch 101; Iter   820/ 1097] train: loss: 0.0012497
[Epoch 101; Iter   850/ 1097] train: loss: 0.0069024
[Epoch 101; Iter   880/ 1097] train: loss: 0.0058455
[Epoch 101; Iter   910/ 1097] train: loss: 0.0038360
[Epoch 101; Iter   940/ 1097] train: loss: 0.0059412
[Epoch 101; Iter   970/ 1097] train: loss: 0.0076259
[Epoch 101; Iter  1000/ 1097] train: loss: 0.0012785
[Epoch 101; Iter  1030/ 1097] train: loss: 0.0108630
[Epoch 101; Iter  1060/ 1097] train: loss: 0.0219740
[Epoch 101; Iter  1090/ 1097] train: loss: 0.0105792
[Epoch 101] ogbg-molhiv: 0.793118 val loss: 0.130929
[Epoch 101] ogbg-molhiv: 0.751529 test loss: 0.247486
[Epoch 102; Iter    23/ 1097] train: loss: 0.0015273
[Epoch 102; Iter    53/ 1097] train: loss: 0.0260805
[Epoch 102; Iter    83/ 1097] train: loss: 0.0027637
[Epoch 102; Iter   113/ 1097] train: loss: 0.0021606
[Epoch 102; Iter   143/ 1097] train: loss: 0.0053412
[Epoch 102; Iter   173/ 1097] train: loss: 0.0404557
[Epoch 102; Iter   203/ 1097] train: loss: 0.0009748
[Epoch 102; Iter   233/ 1097] train: loss: 0.0013092
[Epoch 102; Iter   263/ 1097] train: loss: 0.0035743
[Epoch 102; Iter   293/ 1097] train: loss: 0.0067531
[Epoch 102; Iter   323/ 1097] train: loss: 0.0534620
[Epoch 102; Iter   353/ 1097] train: loss: 0.0193643
[Epoch 102; Iter   383/ 1097] train: loss: 0.0078269
[Epoch 102; Iter   413/ 1097] train: loss: 0.0098289
[Epoch 102; Iter   443/ 1097] train: loss: 0.0049177
[Epoch 102; Iter   473/ 1097] train: loss: 0.0288949
[Epoch 102; Iter   503/ 1097] train: loss: 0.0074410
[Epoch 102; Iter   533/ 1097] train: loss: 0.0018445
[Epoch 102; Iter   563/ 1097] train: loss: 0.0064941
[Epoch 102; Iter   593/ 1097] train: loss: 0.0054221
[Epoch 102; Iter   623/ 1097] train: loss: 0.0099985
[Epoch 102; Iter   653/ 1097] train: loss: 0.0474780
[Epoch 102; Iter   683/ 1097] train: loss: 0.0117914
[Epoch 102; Iter   713/ 1097] train: loss: 0.0706073
[Epoch 102; Iter   743/ 1097] train: loss: 0.0510215
[Epoch 102; Iter   773/ 1097] train: loss: 0.0032290
[Epoch 102; Iter   803/ 1097] train: loss: 0.0017818
[Epoch 102; Iter   833/ 1097] train: loss: 0.0065560
[Epoch 102; Iter   863/ 1097] train: loss: 0.0013039
[Epoch 102; Iter   893/ 1097] train: loss: 0.0112979
[Epoch 102; Iter   923/ 1097] train: loss: 0.1101933
[Epoch 102; Iter   953/ 1097] train: loss: 0.0276776
[Epoch 102; Iter   983/ 1097] train: loss: 0.0008655
[Epoch 102; Iter  1013/ 1097] train: loss: 0.0066928
[Epoch 102; Iter  1043/ 1097] train: loss: 0.0293532
[Epoch 102; Iter  1073/ 1097] train: loss: 0.0343217
[Epoch 102] ogbg-molhiv: 0.799664 val loss: 0.130562
[Epoch 102] ogbg-molhiv: 0.757427 test loss: 0.246630
[Epoch 103; Iter     6/ 1097] train: loss: 0.0003583
[Epoch 103; Iter    36/ 1097] train: loss: 0.0154222
[Epoch 103; Iter    66/ 1097] train: loss: 0.0010978
[Epoch 103; Iter    96/ 1097] train: loss: 0.0016000
[Epoch 103; Iter   126/ 1097] train: loss: 0.0063224
[Epoch 103; Iter   156/ 1097] train: loss: 0.0001849
[Epoch 103; Iter   186/ 1097] train: loss: 0.0009677
[Epoch 103; Iter   216/ 1097] train: loss: 0.0534566
[Epoch 103; Iter   246/ 1097] train: loss: 0.0067865
[Epoch 103; Iter   276/ 1097] train: loss: 0.0074067
[Epoch 103; Iter   306/ 1097] train: loss: 0.0077165
[Epoch 103; Iter   336/ 1097] train: loss: 0.1064016
[Epoch 103; Iter   366/ 1097] train: loss: 0.0251925
[Epoch 103; Iter   396/ 1097] train: loss: 0.0160616
[Epoch 103; Iter   426/ 1097] train: loss: 0.0013281
[Epoch 103; Iter   456/ 1097] train: loss: 0.0149690
[Epoch 103; Iter   486/ 1097] train: loss: 0.0433982
[Epoch 103; Iter   516/ 1097] train: loss: 0.1256270
[Epoch 103; Iter   546/ 1097] train: loss: 0.0285977
[Epoch 103; Iter   576/ 1097] train: loss: 0.0021773
[Epoch 103; Iter   606/ 1097] train: loss: 0.0071090
[Epoch 103; Iter   636/ 1097] train: loss: 0.0007686
[Epoch 103; Iter   666/ 1097] train: loss: 0.0058573
[Epoch 103; Iter   696/ 1097] train: loss: 0.0255775
[Epoch 103; Iter   726/ 1097] train: loss: 0.0044797
[Epoch 103; Iter   756/ 1097] train: loss: 0.0251331
[Epoch 103; Iter   786/ 1097] train: loss: 0.0194197
[Epoch 103; Iter   816/ 1097] train: loss: 0.0017482
[Epoch 103; Iter   846/ 1097] train: loss: 0.0661180
[Epoch 103; Iter   876/ 1097] train: loss: 0.0619254
[Epoch 103; Iter   906/ 1097] train: loss: 0.0024880
[Epoch 103; Iter   936/ 1097] train: loss: 0.0182081
[Epoch 103; Iter   966/ 1097] train: loss: 0.0041902
[Epoch 103; Iter   996/ 1097] train: loss: 0.0013303
[Epoch 103; Iter  1026/ 1097] train: loss: 0.0046970
[Epoch 103; Iter  1056/ 1097] train: loss: 0.0006433
[Epoch 103; Iter  1086/ 1097] train: loss: 0.0763967
[Epoch 103] ogbg-molhiv: 0.788090 val loss: 0.139352
[Epoch 103] ogbg-molhiv: 0.754144 test loss: 0.249313
[Epoch 104; Iter    19/ 1097] train: loss: 0.0092927
[Epoch 104; Iter    49/ 1097] train: loss: 0.0008761
[Epoch 104; Iter    79/ 1097] train: loss: 0.0025592
[Epoch 104; Iter   109/ 1097] train: loss: 0.0021856
[Epoch 104; Iter   139/ 1097] train: loss: 0.0043121
[Epoch 104; Iter   169/ 1097] train: loss: 0.0070864
[Epoch 104; Iter   199/ 1097] train: loss: 0.0028750
[Epoch 104; Iter   229/ 1097] train: loss: 0.0128002
[Epoch 104; Iter   259/ 1097] train: loss: 0.0366676
[Epoch 104; Iter   289/ 1097] train: loss: 0.0018937
[Epoch 104; Iter   319/ 1097] train: loss: 0.0278485
[Epoch 104; Iter   349/ 1097] train: loss: 0.0002245
[Epoch 104; Iter   379/ 1097] train: loss: 0.0129373
[Epoch 104; Iter   409/ 1097] train: loss: 0.0019202
[Epoch 104; Iter   439/ 1097] train: loss: 0.0060297
[Epoch 104; Iter   469/ 1097] train: loss: 0.0885639
[Epoch 104; Iter   499/ 1097] train: loss: 0.0018490
[Epoch 104; Iter   529/ 1097] train: loss: 0.0056731
[Epoch 104; Iter   559/ 1097] train: loss: 0.0022503
[Epoch 104; Iter   589/ 1097] train: loss: 0.0097884
[Epoch 104; Iter   619/ 1097] train: loss: 0.0007419
[Epoch 104; Iter   649/ 1097] train: loss: 0.0012074
[Epoch 104; Iter   679/ 1097] train: loss: 0.0164231
[Epoch 104; Iter   709/ 1097] train: loss: 0.0014288
[Epoch 104; Iter   739/ 1097] train: loss: 0.0167829
[Epoch 104; Iter   769/ 1097] train: loss: 0.0127097
[Epoch 104; Iter   799/ 1097] train: loss: 0.0216526
[Epoch 104; Iter   829/ 1097] train: loss: 0.0022113
[Epoch 104; Iter   859/ 1097] train: loss: 0.0013029
[Epoch 104; Iter   889/ 1097] train: loss: 0.0197500
[Epoch 104; Iter   919/ 1097] train: loss: 0.0015850
[Epoch 104; Iter   949/ 1097] train: loss: 0.0397102
[Epoch 104; Iter   979/ 1097] train: loss: 0.0012163
[Epoch 104; Iter  1009/ 1097] train: loss: 0.1607631
[Epoch 104; Iter  1039/ 1097] train: loss: 0.0119139
[Epoch 104; Iter  1069/ 1097] train: loss: 0.0005219
[Epoch 104] ogbg-molhiv: 0.802191 val loss: 0.133650
[Epoch 104] ogbg-molhiv: 0.758172 test loss: 0.246194
[Epoch 105; Iter     2/ 1097] train: loss: 0.0674903
[Epoch 105; Iter    32/ 1097] train: loss: 0.0007393
[Epoch 105; Iter    62/ 1097] train: loss: 0.0238598
[Epoch 105; Iter    92/ 1097] train: loss: 0.1542600
[Epoch 105; Iter   122/ 1097] train: loss: 0.0026625
[Epoch 105; Iter   152/ 1097] train: loss: 0.0045124
[Epoch 105; Iter   182/ 1097] train: loss: 0.0019229
[Epoch 105; Iter   212/ 1097] train: loss: 0.0151787
[Epoch 105; Iter   242/ 1097] train: loss: 0.0367342
[Epoch 105; Iter   272/ 1097] train: loss: 0.0011014
[Epoch 105; Iter   302/ 1097] train: loss: 0.0173405
[Epoch 105; Iter   332/ 1097] train: loss: 0.0014371
[Epoch 105; Iter   362/ 1097] train: loss: 0.0042704
[Epoch 105; Iter   392/ 1097] train: loss: 0.0011404
[Epoch 105; Iter   422/ 1097] train: loss: 0.0024995
[Epoch 105; Iter   452/ 1097] train: loss: 0.0025474
[Epoch 105; Iter   482/ 1097] train: loss: 0.0209818
[Epoch 105; Iter   512/ 1097] train: loss: 0.0007571
[Epoch 105; Iter   542/ 1097] train: loss: 0.0608808
[Epoch 105; Iter   572/ 1097] train: loss: 0.0239478
[Epoch 105; Iter   602/ 1097] train: loss: 0.0040243
[Epoch 105; Iter   632/ 1097] train: loss: 0.0139327
[Epoch 105; Iter   662/ 1097] train: loss: 0.0032801
[Epoch 105; Iter   692/ 1097] train: loss: 0.0026228
[Epoch 105; Iter   722/ 1097] train: loss: 0.0117256
[Epoch 111; Iter   280/  823] train: loss: 0.0856250
[Epoch 111; Iter   310/  823] train: loss: 0.0013371
[Epoch 111; Iter   340/  823] train: loss: 0.0182121
[Epoch 111; Iter   370/  823] train: loss: 0.0256882
[Epoch 111; Iter   400/  823] train: loss: 0.0019405
[Epoch 111; Iter   430/  823] train: loss: 0.0026296
[Epoch 111; Iter   460/  823] train: loss: 0.0028544
[Epoch 111; Iter   490/  823] train: loss: 0.0377404
[Epoch 111; Iter   520/  823] train: loss: 0.0132778
[Epoch 111; Iter   550/  823] train: loss: 0.0304747
[Epoch 111; Iter   580/  823] train: loss: 0.0283079
[Epoch 111; Iter   610/  823] train: loss: 0.0167640
[Epoch 111; Iter   640/  823] train: loss: 0.0428376
[Epoch 111; Iter   670/  823] train: loss: 0.0334867
[Epoch 111; Iter   700/  823] train: loss: 0.0255669
[Epoch 111; Iter   730/  823] train: loss: 0.0263285
[Epoch 111; Iter   760/  823] train: loss: 0.0277135
[Epoch 111; Iter   790/  823] train: loss: 0.0075647
[Epoch 111; Iter   820/  823] train: loss: 0.0101298
[Epoch 111] ogbg-molhiv: 0.744078 val loss: 0.274805
[Epoch 111] ogbg-molhiv: 0.751895 test loss: 0.287688
[Epoch 112; Iter    27/  823] train: loss: 0.0094322
[Epoch 112; Iter    57/  823] train: loss: 0.0061227
[Epoch 112; Iter    87/  823] train: loss: 0.0057821
[Epoch 112; Iter   117/  823] train: loss: 0.0011817
[Epoch 112; Iter   147/  823] train: loss: 0.0012652
[Epoch 112; Iter   177/  823] train: loss: 0.0031460
[Epoch 112; Iter   207/  823] train: loss: 0.0029820
[Epoch 112; Iter   237/  823] train: loss: 0.0066838
[Epoch 112; Iter   267/  823] train: loss: 0.0134344
[Epoch 112; Iter   297/  823] train: loss: 0.0009877
[Epoch 112; Iter   327/  823] train: loss: 0.0015833
[Epoch 112; Iter   357/  823] train: loss: 0.0181240
[Epoch 112; Iter   387/  823] train: loss: 0.0042855
[Epoch 112; Iter   417/  823] train: loss: 0.0012608
[Epoch 112; Iter   447/  823] train: loss: 0.0442848
[Epoch 112; Iter   477/  823] train: loss: 0.0068827
[Epoch 112; Iter   507/  823] train: loss: 0.0097182
[Epoch 112; Iter   537/  823] train: loss: 0.0477701
[Epoch 112; Iter   567/  823] train: loss: 0.1089626
[Epoch 112; Iter   597/  823] train: loss: 0.0103945
[Epoch 112; Iter   627/  823] train: loss: 0.0162036
[Epoch 112; Iter   657/  823] train: loss: 0.1931312
[Epoch 112; Iter   687/  823] train: loss: 0.0002159
[Epoch 112; Iter   717/  823] train: loss: 0.0009629
[Epoch 112; Iter   747/  823] train: loss: 0.0159931
[Epoch 112; Iter   777/  823] train: loss: 0.0034006
[Epoch 112; Iter   807/  823] train: loss: 0.0136728
[Epoch 112] ogbg-molhiv: 0.744343 val loss: 0.257573
[Epoch 112] ogbg-molhiv: 0.743747 test loss: 0.249586
[Epoch 113; Iter    14/  823] train: loss: 0.0008207
[Epoch 113; Iter    44/  823] train: loss: 0.0162134
[Epoch 113; Iter    74/  823] train: loss: 0.0022380
[Epoch 113; Iter   104/  823] train: loss: 0.0069249
[Epoch 113; Iter   134/  823] train: loss: 0.0421601
[Epoch 113; Iter   164/  823] train: loss: 0.0774352
[Epoch 113; Iter   194/  823] train: loss: 0.0122319
[Epoch 113; Iter   224/  823] train: loss: 0.0369307
[Epoch 113; Iter   254/  823] train: loss: 0.0044847
[Epoch 113; Iter   284/  823] train: loss: 0.0154403
[Epoch 113; Iter   314/  823] train: loss: 0.0007736
[Epoch 113; Iter   344/  823] train: loss: 0.0058262
[Epoch 113; Iter   374/  823] train: loss: 0.0042934
[Epoch 113; Iter   404/  823] train: loss: 0.0692083
[Epoch 113; Iter   434/  823] train: loss: 0.0033571
[Epoch 113; Iter   464/  823] train: loss: 0.0722393
[Epoch 113; Iter   494/  823] train: loss: 0.0309010
[Epoch 113; Iter   524/  823] train: loss: 0.0010431
[Epoch 113; Iter   554/  823] train: loss: 0.0022474
[Epoch 113; Iter   584/  823] train: loss: 0.1301767
[Epoch 113; Iter   614/  823] train: loss: 0.0031115
[Epoch 113; Iter   644/  823] train: loss: 0.0841931
[Epoch 113; Iter   674/  823] train: loss: 0.0020876
[Epoch 113; Iter   704/  823] train: loss: 0.0799405
[Epoch 113; Iter   734/  823] train: loss: 0.0700462
[Epoch 113; Iter   764/  823] train: loss: 0.0070460
[Epoch 113; Iter   794/  823] train: loss: 0.0165703
[Epoch 113] ogbg-molhiv: 0.741077 val loss: 0.259678
[Epoch 113] ogbg-molhiv: 0.744806 test loss: 0.248692
[Epoch 114; Iter     1/  823] train: loss: 0.0253573
[Epoch 114; Iter    31/  823] train: loss: 0.0013086
[Epoch 114; Iter    61/  823] train: loss: 0.0236673
[Epoch 114; Iter    91/  823] train: loss: 0.0180137
[Epoch 114; Iter   121/  823] train: loss: 0.0012247
[Epoch 114; Iter   151/  823] train: loss: 0.1087125
[Epoch 114; Iter   181/  823] train: loss: 0.0254728
[Epoch 114; Iter   211/  823] train: loss: 0.0770266
[Epoch 114; Iter   241/  823] train: loss: 0.0079367
[Epoch 114; Iter   271/  823] train: loss: 0.0157293
[Epoch 114; Iter   301/  823] train: loss: 0.0023393
[Epoch 114; Iter   331/  823] train: loss: 0.0039972
[Epoch 114; Iter   361/  823] train: loss: 0.0153688
[Epoch 114; Iter   391/  823] train: loss: 0.0224250
[Epoch 114; Iter   421/  823] train: loss: 0.0081242
[Epoch 114; Iter   451/  823] train: loss: 0.0003231
[Epoch 114; Iter   481/  823] train: loss: 0.0037108
[Epoch 114; Iter   511/  823] train: loss: 0.0021690
[Epoch 114; Iter   541/  823] train: loss: 0.0024338
[Epoch 114; Iter   571/  823] train: loss: 0.0353968
[Epoch 114; Iter   601/  823] train: loss: 0.0013104
[Epoch 114; Iter   631/  823] train: loss: 0.0420583
[Epoch 114; Iter   661/  823] train: loss: 0.0847011
[Epoch 114; Iter   691/  823] train: loss: 0.0332006
[Epoch 114; Iter   721/  823] train: loss: 0.0225675
[Epoch 114; Iter   751/  823] train: loss: 0.0009196
[Epoch 114; Iter   781/  823] train: loss: 0.0014476
[Epoch 114; Iter   811/  823] train: loss: 0.0064855
[Epoch 114] ogbg-molhiv: 0.743468 val loss: 0.283259
[Epoch 114] ogbg-molhiv: 0.747749 test loss: 0.266923
[Epoch 115; Iter    18/  823] train: loss: 0.0039322
[Epoch 115; Iter    48/  823] train: loss: 0.0026962
[Epoch 115; Iter    78/  823] train: loss: 0.0221619
[Epoch 115; Iter   108/  823] train: loss: 0.0050144
[Epoch 115; Iter   138/  823] train: loss: 0.0010117
[Epoch 115; Iter   168/  823] train: loss: 0.0064276
[Epoch 115; Iter   198/  823] train: loss: 0.0066974
[Epoch 115; Iter   228/  823] train: loss: 0.0008462
[Epoch 115; Iter   258/  823] train: loss: 0.0079891
[Epoch 115; Iter   288/  823] train: loss: 0.0348747
[Epoch 115; Iter   318/  823] train: loss: 0.0237473
[Epoch 115; Iter   348/  823] train: loss: 0.0030043
[Epoch 115; Iter   378/  823] train: loss: 0.0073247
[Epoch 115; Iter   408/  823] train: loss: 0.0034903
[Epoch 115; Iter   438/  823] train: loss: 0.0031599
[Epoch 115; Iter   468/  823] train: loss: 0.0115247
[Epoch 115; Iter   498/  823] train: loss: 0.0023803
[Epoch 115; Iter   528/  823] train: loss: 0.0772570
[Epoch 115; Iter   558/  823] train: loss: 0.0012178
[Epoch 115; Iter   588/  823] train: loss: 0.0009517
[Epoch 115; Iter   618/  823] train: loss: 0.0044478
[Epoch 115; Iter   648/  823] train: loss: 0.0141751
[Epoch 115; Iter   678/  823] train: loss: 0.0077972
[Epoch 115; Iter   708/  823] train: loss: 0.0039428
[Epoch 115; Iter   738/  823] train: loss: 0.0180352
[Epoch 115; Iter   768/  823] train: loss: 0.0054446
[Epoch 115; Iter   798/  823] train: loss: 0.0161371
[Epoch 115] ogbg-molhiv: 0.743704 val loss: 0.257823
[Epoch 115] ogbg-molhiv: 0.751985 test loss: 0.258104
[Epoch 116; Iter     5/  823] train: loss: 0.0060791
[Epoch 116; Iter    35/  823] train: loss: 0.0337147
[Epoch 116; Iter    65/  823] train: loss: 0.0274602
[Epoch 116; Iter    95/  823] train: loss: 0.0089782
[Epoch 116; Iter   125/  823] train: loss: 0.0090016
[Epoch 116; Iter   155/  823] train: loss: 0.0023818
[Epoch 116; Iter   185/  823] train: loss: 0.0018767
[Epoch 116; Iter   215/  823] train: loss: 0.0043854
[Epoch 116; Iter   245/  823] train: loss: 0.0029587
[Epoch 116; Iter   275/  823] train: loss: 0.0740697
[Epoch 116; Iter   305/  823] train: loss: 0.0016560
[Epoch 116; Iter   335/  823] train: loss: 0.0029169
[Epoch 116; Iter   365/  823] train: loss: 0.0005470
[Epoch 116; Iter   395/  823] train: loss: 0.0045401
[Epoch 116; Iter   425/  823] train: loss: 0.0264670
[Epoch 116; Iter   455/  823] train: loss: 0.0186276
[Epoch 111; Iter   280/  823] train: loss: 0.0045900
[Epoch 111; Iter   310/  823] train: loss: 0.0379916
[Epoch 111; Iter   340/  823] train: loss: 0.0035980
[Epoch 111; Iter   370/  823] train: loss: 0.0279157
[Epoch 111; Iter   400/  823] train: loss: 0.0012534
[Epoch 111; Iter   430/  823] train: loss: 0.0048920
[Epoch 111; Iter   460/  823] train: loss: 0.0010023
[Epoch 111; Iter   490/  823] train: loss: 0.0061280
[Epoch 111; Iter   520/  823] train: loss: 0.0009717
[Epoch 111; Iter   550/  823] train: loss: 0.0032535
[Epoch 111; Iter   580/  823] train: loss: 0.0001242
[Epoch 111; Iter   610/  823] train: loss: 0.0038243
[Epoch 111; Iter   640/  823] train: loss: 0.0008989
[Epoch 111; Iter   670/  823] train: loss: 0.0015550
[Epoch 111; Iter   700/  823] train: loss: 0.0032776
[Epoch 111; Iter   730/  823] train: loss: 0.0099373
[Epoch 111; Iter   760/  823] train: loss: 0.0211307
[Epoch 111; Iter   790/  823] train: loss: 0.0264099
[Epoch 111; Iter   820/  823] train: loss: 0.0301660
[Epoch 111] ogbg-molhiv: 0.701250 val loss: 0.515951
[Epoch 111] ogbg-molhiv: 0.749428 test loss: 0.274199
[Epoch 112; Iter    27/  823] train: loss: 0.0006045
[Epoch 112; Iter    57/  823] train: loss: 0.0008952
[Epoch 112; Iter    87/  823] train: loss: 0.0740393
[Epoch 112; Iter   117/  823] train: loss: 0.0022180
[Epoch 112; Iter   147/  823] train: loss: 0.0160121
[Epoch 112; Iter   177/  823] train: loss: 0.0297258
[Epoch 112; Iter   207/  823] train: loss: 0.0073423
[Epoch 112; Iter   237/  823] train: loss: 0.0121051
[Epoch 112; Iter   267/  823] train: loss: 0.0036684
[Epoch 112; Iter   297/  823] train: loss: 0.0039502
[Epoch 112; Iter   327/  823] train: loss: 0.1877832
[Epoch 112; Iter   357/  823] train: loss: 0.0065352
[Epoch 112; Iter   387/  823] train: loss: 0.0005727
[Epoch 112; Iter   417/  823] train: loss: 0.0508769
[Epoch 112; Iter   447/  823] train: loss: 0.0053441
[Epoch 112; Iter   477/  823] train: loss: 0.0776563
[Epoch 112; Iter   507/  823] train: loss: 0.1106746
[Epoch 112; Iter   537/  823] train: loss: 0.0008079
[Epoch 112; Iter   567/  823] train: loss: 0.0021171
[Epoch 112; Iter   597/  823] train: loss: 0.0051447
[Epoch 112; Iter   627/  823] train: loss: 0.0034074
[Epoch 112; Iter   657/  823] train: loss: 0.0217656
[Epoch 112; Iter   687/  823] train: loss: 0.0027720
[Epoch 112; Iter   717/  823] train: loss: 0.0554770
[Epoch 112; Iter   747/  823] train: loss: 0.0018752
[Epoch 112; Iter   777/  823] train: loss: 0.0013080
[Epoch 112; Iter   807/  823] train: loss: 0.0227259
[Epoch 112] ogbg-molhiv: 0.701006 val loss: 0.483255
[Epoch 112] ogbg-molhiv: 0.748931 test loss: 0.253731
[Epoch 113; Iter    14/  823] train: loss: 0.0072164
[Epoch 113; Iter    44/  823] train: loss: 0.0077913
[Epoch 113; Iter    74/  823] train: loss: 0.0034934
[Epoch 113; Iter   104/  823] train: loss: 0.0209420
[Epoch 113; Iter   134/  823] train: loss: 0.0396451
[Epoch 113; Iter   164/  823] train: loss: 0.0013227
[Epoch 113; Iter   194/  823] train: loss: 0.0017443
[Epoch 113; Iter   224/  823] train: loss: 0.0114690
[Epoch 113; Iter   254/  823] train: loss: 0.0079509
[Epoch 113; Iter   284/  823] train: loss: 0.0065573
[Epoch 113; Iter   314/  823] train: loss: 0.0004788
[Epoch 113; Iter   344/  823] train: loss: 0.0058452
[Epoch 113; Iter   374/  823] train: loss: 0.0015916
[Epoch 113; Iter   404/  823] train: loss: 0.0450487
[Epoch 113; Iter   434/  823] train: loss: 0.0108506
[Epoch 113; Iter   464/  823] train: loss: 0.1699019
[Epoch 113; Iter   494/  823] train: loss: 0.0017599
[Epoch 113; Iter   524/  823] train: loss: 0.0006257
[Epoch 113; Iter   554/  823] train: loss: 0.0019587
[Epoch 113; Iter   584/  823] train: loss: 0.0205987
[Epoch 113; Iter   614/  823] train: loss: 0.0061113
[Epoch 113; Iter   644/  823] train: loss: 0.0062217
[Epoch 113; Iter   674/  823] train: loss: 0.0142858
[Epoch 113; Iter   704/  823] train: loss: 0.0066137
[Epoch 113; Iter   734/  823] train: loss: 0.0074584
[Epoch 113; Iter   764/  823] train: loss: 0.0013077
[Epoch 113; Iter   794/  823] train: loss: 0.0098945
[Epoch 113] ogbg-molhiv: 0.704256 val loss: 0.464520
[Epoch 113] ogbg-molhiv: 0.743836 test loss: 0.255065
[Epoch 114; Iter     1/  823] train: loss: 0.0024791
[Epoch 114; Iter    31/  823] train: loss: 0.0001875
[Epoch 114; Iter    61/  823] train: loss: 0.0067329
[Epoch 114; Iter    91/  823] train: loss: 0.0710014
[Epoch 114; Iter   121/  823] train: loss: 0.0057511
[Epoch 114; Iter   151/  823] train: loss: 0.0011681
[Epoch 114; Iter   181/  823] train: loss: 0.0010022
[Epoch 114; Iter   211/  823] train: loss: 0.0063777
[Epoch 114; Iter   241/  823] train: loss: 0.0038039
[Epoch 114; Iter   271/  823] train: loss: 0.0008037
[Epoch 114; Iter   301/  823] train: loss: 0.0094500
[Epoch 114; Iter   331/  823] train: loss: 0.0005310
[Epoch 114; Iter   361/  823] train: loss: 0.0053991
[Epoch 114; Iter   391/  823] train: loss: 0.0006262
[Epoch 114; Iter   421/  823] train: loss: 0.0167925
[Epoch 114; Iter   451/  823] train: loss: 0.0022199
[Epoch 114; Iter   481/  823] train: loss: 0.0496788
[Epoch 114; Iter   511/  823] train: loss: 0.0022237
[Epoch 114; Iter   541/  823] train: loss: 0.0110357
[Epoch 114; Iter   571/  823] train: loss: 0.0116380
[Epoch 114; Iter   601/  823] train: loss: 0.0011519
[Epoch 114; Iter   631/  823] train: loss: 0.0018153
[Epoch 114; Iter   661/  823] train: loss: 0.0010382
[Epoch 114; Iter   691/  823] train: loss: 0.0005790
[Epoch 114; Iter   721/  823] train: loss: 0.0064172
[Epoch 114; Iter   751/  823] train: loss: 0.0041098
[Epoch 114; Iter   781/  823] train: loss: 0.0244642
[Epoch 114; Iter   811/  823] train: loss: 0.0054606
[Epoch 114] ogbg-molhiv: 0.697342 val loss: 0.444415
[Epoch 114] ogbg-molhiv: 0.742812 test loss: 0.267383
[Epoch 115; Iter    18/  823] train: loss: 0.0216915
[Epoch 115; Iter    48/  823] train: loss: 0.0054882
[Epoch 115; Iter    78/  823] train: loss: 0.1094718
[Epoch 115; Iter   108/  823] train: loss: 0.0003513
[Epoch 115; Iter   138/  823] train: loss: 0.0037458
[Epoch 115; Iter   168/  823] train: loss: 0.0024965
[Epoch 115; Iter   198/  823] train: loss: 0.0224565
[Epoch 115; Iter   228/  823] train: loss: 0.0112589
[Epoch 115; Iter   258/  823] train: loss: 0.0005981
[Epoch 115; Iter   288/  823] train: loss: 0.0272956
[Epoch 115; Iter   318/  823] train: loss: 0.0179258
[Epoch 115; Iter   348/  823] train: loss: 0.0014437
[Epoch 115; Iter   378/  823] train: loss: 0.0830769
[Epoch 115; Iter   408/  823] train: loss: 0.0014634
[Epoch 115; Iter   438/  823] train: loss: 0.0070575
[Epoch 115; Iter   468/  823] train: loss: 0.0003780
[Epoch 115; Iter   498/  823] train: loss: 0.0012351
[Epoch 115; Iter   528/  823] train: loss: 0.0588904
[Epoch 115; Iter   558/  823] train: loss: 0.0131896
[Epoch 115; Iter   588/  823] train: loss: 0.0057994
[Epoch 115; Iter   618/  823] train: loss: 0.0035770
[Epoch 115; Iter   648/  823] train: loss: 0.0022523
[Epoch 115; Iter   678/  823] train: loss: 0.0148051
[Epoch 115; Iter   708/  823] train: loss: 0.0169230
[Epoch 115; Iter   738/  823] train: loss: 0.0185707
[Epoch 115; Iter   768/  823] train: loss: 0.0093589
[Epoch 115; Iter   798/  823] train: loss: 0.0016307
[Epoch 115] ogbg-molhiv: 0.693394 val loss: 0.488340
[Epoch 115] ogbg-molhiv: 0.746324 test loss: 0.259813
[Epoch 116; Iter     5/  823] train: loss: 0.0045628
[Epoch 116; Iter    35/  823] train: loss: 0.0011720
[Epoch 116; Iter    65/  823] train: loss: 0.0145712
[Epoch 116; Iter    95/  823] train: loss: 0.0155070
[Epoch 116; Iter   125/  823] train: loss: 0.0009527
[Epoch 116; Iter   155/  823] train: loss: 0.0028382
[Epoch 116; Iter   185/  823] train: loss: 0.0492599
[Epoch 116; Iter   215/  823] train: loss: 0.0012912
[Epoch 116; Iter   245/  823] train: loss: 0.0174430
[Epoch 116; Iter   275/  823] train: loss: 0.0054041
[Epoch 116; Iter   305/  823] train: loss: 0.0009984
[Epoch 116; Iter   335/  823] train: loss: 0.0045615
[Epoch 116; Iter   365/  823] train: loss: 0.0110015
[Epoch 116; Iter   395/  823] train: loss: 0.0076939
[Epoch 116; Iter   425/  823] train: loss: 0.0063067
[Epoch 116; Iter   455/  823] train: loss: 0.0036088
[Epoch 105; Iter   752/ 1097] train: loss: 0.0078773
[Epoch 105; Iter   782/ 1097] train: loss: 0.0034220
[Epoch 105; Iter   812/ 1097] train: loss: 0.0063777
[Epoch 105; Iter   842/ 1097] train: loss: 0.0011558
[Epoch 105; Iter   872/ 1097] train: loss: 0.0015656
[Epoch 105; Iter   902/ 1097] train: loss: 0.0055226
[Epoch 105; Iter   932/ 1097] train: loss: 0.0665606
[Epoch 105; Iter   962/ 1097] train: loss: 0.0020043
[Epoch 105; Iter   992/ 1097] train: loss: 0.0176117
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0599855
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0052444
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0014374
[Epoch 105] ogbg-molhiv: 0.752670 val loss: 0.158232
[Epoch 105] ogbg-molhiv: 0.732291 test loss: 0.264308
[Epoch 106; Iter    15/ 1097] train: loss: 0.0022263
[Epoch 106; Iter    45/ 1097] train: loss: 0.0049290
[Epoch 106; Iter    75/ 1097] train: loss: 0.0025096
[Epoch 106; Iter   105/ 1097] train: loss: 0.0205834
[Epoch 106; Iter   135/ 1097] train: loss: 0.0214626
[Epoch 106; Iter   165/ 1097] train: loss: 0.0091521
[Epoch 106; Iter   195/ 1097] train: loss: 0.0236727
[Epoch 106; Iter   225/ 1097] train: loss: 0.1140197
[Epoch 106; Iter   255/ 1097] train: loss: 0.0033771
[Epoch 106; Iter   285/ 1097] train: loss: 0.0030098
[Epoch 106; Iter   315/ 1097] train: loss: 0.0784296
[Epoch 106; Iter   345/ 1097] train: loss: 0.0017590
[Epoch 106; Iter   375/ 1097] train: loss: 0.0213386
[Epoch 106; Iter   405/ 1097] train: loss: 0.0054109
[Epoch 106; Iter   435/ 1097] train: loss: 0.0155491
[Epoch 106; Iter   465/ 1097] train: loss: 0.0143103
[Epoch 106; Iter   495/ 1097] train: loss: 0.0335384
[Epoch 106; Iter   525/ 1097] train: loss: 0.0167468
[Epoch 106; Iter   555/ 1097] train: loss: 0.0069972
[Epoch 106; Iter   585/ 1097] train: loss: 0.0035997
[Epoch 106; Iter   615/ 1097] train: loss: 0.0055224
[Epoch 106; Iter   645/ 1097] train: loss: 0.0053623
[Epoch 106; Iter   675/ 1097] train: loss: 0.0578633
[Epoch 106; Iter   705/ 1097] train: loss: 0.0011905
[Epoch 106; Iter   735/ 1097] train: loss: 0.0088794
[Epoch 106; Iter   765/ 1097] train: loss: 0.0739322
[Epoch 106; Iter   795/ 1097] train: loss: 0.0323497
[Epoch 106; Iter   825/ 1097] train: loss: 0.0028045
[Epoch 106; Iter   855/ 1097] train: loss: 0.0202864
[Epoch 106; Iter   885/ 1097] train: loss: 0.0072103
[Epoch 106; Iter   915/ 1097] train: loss: 0.0030853
[Epoch 106; Iter   945/ 1097] train: loss: 0.0034005
[Epoch 106; Iter   975/ 1097] train: loss: 0.1566720
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0960892
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0103151
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0233793
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0045309
[Epoch 106] ogbg-molhiv: 0.754204 val loss: 0.196469
[Epoch 106] ogbg-molhiv: 0.729836 test loss: 0.509578
[Epoch 107; Iter    28/ 1097] train: loss: 0.0118519
[Epoch 107; Iter    58/ 1097] train: loss: 0.0016974
[Epoch 107; Iter    88/ 1097] train: loss: 0.0710966
[Epoch 107; Iter   118/ 1097] train: loss: 0.0011445
[Epoch 107; Iter   148/ 1097] train: loss: 0.0095422
[Epoch 107; Iter   178/ 1097] train: loss: 0.0024657
[Epoch 107; Iter   208/ 1097] train: loss: 0.0838196
[Epoch 107; Iter   238/ 1097] train: loss: 0.0103891
[Epoch 107; Iter   268/ 1097] train: loss: 0.0434999
[Epoch 107; Iter   298/ 1097] train: loss: 0.0014960
[Epoch 107; Iter   328/ 1097] train: loss: 0.0001638
[Epoch 107; Iter   358/ 1097] train: loss: 0.0318441
[Epoch 107; Iter   388/ 1097] train: loss: 0.0093347
[Epoch 107; Iter   418/ 1097] train: loss: 0.0512057
[Epoch 107; Iter   448/ 1097] train: loss: 0.0117802
[Epoch 107; Iter   478/ 1097] train: loss: 0.0291814
[Epoch 107; Iter   508/ 1097] train: loss: 0.0004015
[Epoch 107; Iter   538/ 1097] train: loss: 0.0469541
[Epoch 107; Iter   568/ 1097] train: loss: 0.0177830
[Epoch 107; Iter   598/ 1097] train: loss: 0.0085968
[Epoch 107; Iter   628/ 1097] train: loss: 0.0049831
[Epoch 107; Iter   658/ 1097] train: loss: 0.0176084
[Epoch 107; Iter   688/ 1097] train: loss: 0.0072567
[Epoch 107; Iter   718/ 1097] train: loss: 0.0020765
[Epoch 107; Iter   748/ 1097] train: loss: 0.0041107
[Epoch 107; Iter   778/ 1097] train: loss: 0.0034785
[Epoch 107; Iter   808/ 1097] train: loss: 0.0062958
[Epoch 107; Iter   838/ 1097] train: loss: 0.0083512
[Epoch 107; Iter   868/ 1097] train: loss: 0.0208634
[Epoch 107; Iter   898/ 1097] train: loss: 0.0161377
[Epoch 107; Iter   928/ 1097] train: loss: 0.0441424
[Epoch 107; Iter   958/ 1097] train: loss: 0.0103472
[Epoch 107; Iter   988/ 1097] train: loss: 0.0171407
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0008977
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0012461
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0084460
[Epoch 107] ogbg-molhiv: 0.748192 val loss: 0.331777
[Epoch 107] ogbg-molhiv: 0.733641 test loss: 0.639270
[Epoch 108; Iter    11/ 1097] train: loss: 0.0117612
[Epoch 108; Iter    41/ 1097] train: loss: 0.0065071
[Epoch 108; Iter    71/ 1097] train: loss: 0.0061632
[Epoch 108; Iter   101/ 1097] train: loss: 0.0583718
[Epoch 108; Iter   131/ 1097] train: loss: 0.0040421
[Epoch 108; Iter   161/ 1097] train: loss: 0.0493369
[Epoch 108; Iter   191/ 1097] train: loss: 0.0013682
[Epoch 108; Iter   221/ 1097] train: loss: 0.0018523
[Epoch 108; Iter   251/ 1097] train: loss: 0.0653843
[Epoch 108; Iter   281/ 1097] train: loss: 0.0072379
[Epoch 108; Iter   311/ 1097] train: loss: 0.0540037
[Epoch 108; Iter   341/ 1097] train: loss: 0.0036626
[Epoch 108; Iter   371/ 1097] train: loss: 0.0010385
[Epoch 108; Iter   401/ 1097] train: loss: 0.0013771
[Epoch 108; Iter   431/ 1097] train: loss: 0.0130535
[Epoch 108; Iter   461/ 1097] train: loss: 0.0043424
[Epoch 108; Iter   491/ 1097] train: loss: 0.0739869
[Epoch 108; Iter   521/ 1097] train: loss: 0.0010245
[Epoch 108; Iter   551/ 1097] train: loss: 0.0099973
[Epoch 108; Iter   581/ 1097] train: loss: 0.0026689
[Epoch 108; Iter   611/ 1097] train: loss: 0.0043947
[Epoch 108; Iter   641/ 1097] train: loss: 0.1202396
[Epoch 108; Iter   671/ 1097] train: loss: 0.0289367
[Epoch 108; Iter   701/ 1097] train: loss: 0.0259287
[Epoch 108; Iter   731/ 1097] train: loss: 0.1074638
[Epoch 108; Iter   761/ 1097] train: loss: 0.0004767
[Epoch 108; Iter   791/ 1097] train: loss: 0.0103026
[Epoch 108; Iter   821/ 1097] train: loss: 0.0022458
[Epoch 108; Iter   851/ 1097] train: loss: 0.0092370
[Epoch 108; Iter   881/ 1097] train: loss: 0.0004001
[Epoch 108; Iter   911/ 1097] train: loss: 0.0041479
[Epoch 108; Iter   941/ 1097] train: loss: 0.0047537
[Epoch 108; Iter   971/ 1097] train: loss: 0.0144296
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0064995
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0028908
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0219496
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0616074
[Epoch 108] ogbg-molhiv: 0.749881 val loss: 0.262643
[Epoch 108] ogbg-molhiv: 0.731565 test loss: 0.833332
[Epoch 109; Iter    24/ 1097] train: loss: 0.0112732
[Epoch 109; Iter    54/ 1097] train: loss: 0.0074892
[Epoch 109; Iter    84/ 1097] train: loss: 0.0232526
[Epoch 109; Iter   114/ 1097] train: loss: 0.0046003
[Epoch 109; Iter   144/ 1097] train: loss: 0.0091616
[Epoch 109; Iter   174/ 1097] train: loss: 0.0012256
[Epoch 109; Iter   204/ 1097] train: loss: 0.0076742
[Epoch 109; Iter   234/ 1097] train: loss: 0.0075370
[Epoch 109; Iter   264/ 1097] train: loss: 0.0019778
[Epoch 109; Iter   294/ 1097] train: loss: 0.0067982
[Epoch 109; Iter   324/ 1097] train: loss: 0.0221969
[Epoch 109; Iter   354/ 1097] train: loss: 0.0059972
[Epoch 109; Iter   384/ 1097] train: loss: 0.0241790
[Epoch 109; Iter   414/ 1097] train: loss: 0.0021129
[Epoch 109; Iter   444/ 1097] train: loss: 0.0274318
[Epoch 109; Iter   474/ 1097] train: loss: 0.0008261
[Epoch 109; Iter   504/ 1097] train: loss: 0.0426583
[Epoch 109; Iter   534/ 1097] train: loss: 0.0016947
[Epoch 109; Iter   564/ 1097] train: loss: 0.0056798
[Epoch 109; Iter   594/ 1097] train: loss: 0.0379667
[Epoch 109; Iter   624/ 1097] train: loss: 0.0041918
[Epoch 109; Iter   654/ 1097] train: loss: 0.0108365
[Epoch 109; Iter   684/ 1097] train: loss: 0.0005804
[Epoch 109; Iter   714/ 1097] train: loss: 0.0118634
[Epoch 105; Iter   752/ 1097] train: loss: 0.0459217
[Epoch 105; Iter   782/ 1097] train: loss: 0.0620329
[Epoch 105; Iter   812/ 1097] train: loss: 0.0075116
[Epoch 105; Iter   842/ 1097] train: loss: 0.0169858
[Epoch 105; Iter   872/ 1097] train: loss: 0.0048874
[Epoch 105; Iter   902/ 1097] train: loss: 0.0070668
[Epoch 105; Iter   932/ 1097] train: loss: 0.1010142
[Epoch 105; Iter   962/ 1097] train: loss: 0.0343883
[Epoch 105; Iter   992/ 1097] train: loss: 0.0046668
[Epoch 105; Iter  1022/ 1097] train: loss: 0.1430120
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0252612
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0127642
[Epoch 105] ogbg-molhiv: 0.764272 val loss: 0.194156
[Epoch 105] ogbg-molhiv: 0.723419 test loss: 0.237827
[Epoch 106; Iter    15/ 1097] train: loss: 0.0024409
[Epoch 106; Iter    45/ 1097] train: loss: 0.0034205
[Epoch 106; Iter    75/ 1097] train: loss: 0.1154234
[Epoch 106; Iter   105/ 1097] train: loss: 0.0081249
[Epoch 106; Iter   135/ 1097] train: loss: 0.0303426
[Epoch 106; Iter   165/ 1097] train: loss: 0.0173893
[Epoch 106; Iter   195/ 1097] train: loss: 0.0537436
[Epoch 106; Iter   225/ 1097] train: loss: 0.0378300
[Epoch 106; Iter   255/ 1097] train: loss: 0.0046051
[Epoch 106; Iter   285/ 1097] train: loss: 0.0032977
[Epoch 106; Iter   315/ 1097] train: loss: 0.0012696
[Epoch 106; Iter   345/ 1097] train: loss: 0.0133487
[Epoch 106; Iter   375/ 1097] train: loss: 0.0119618
[Epoch 106; Iter   405/ 1097] train: loss: 0.0457624
[Epoch 106; Iter   435/ 1097] train: loss: 0.0919410
[Epoch 106; Iter   465/ 1097] train: loss: 0.0142963
[Epoch 106; Iter   495/ 1097] train: loss: 0.0425389
[Epoch 106; Iter   525/ 1097] train: loss: 0.0049233
[Epoch 106; Iter   555/ 1097] train: loss: 0.0016793
[Epoch 106; Iter   585/ 1097] train: loss: 0.0038763
[Epoch 106; Iter   615/ 1097] train: loss: 0.0272022
[Epoch 106; Iter   645/ 1097] train: loss: 0.0098686
[Epoch 106; Iter   675/ 1097] train: loss: 0.0018755
[Epoch 106; Iter   705/ 1097] train: loss: 0.0115093
[Epoch 106; Iter   735/ 1097] train: loss: 0.0344755
[Epoch 106; Iter   765/ 1097] train: loss: 0.0790408
[Epoch 106; Iter   795/ 1097] train: loss: 0.0254782
[Epoch 106; Iter   825/ 1097] train: loss: 0.1002944
[Epoch 106; Iter   855/ 1097] train: loss: 0.0932859
[Epoch 106; Iter   885/ 1097] train: loss: 0.0447923
[Epoch 106; Iter   915/ 1097] train: loss: 0.0034501
[Epoch 106; Iter   945/ 1097] train: loss: 0.0132789
[Epoch 106; Iter   975/ 1097] train: loss: 0.0125661
[Epoch 106; Iter  1005/ 1097] train: loss: 0.1034301
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0086741
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0076228
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0117756
[Epoch 106] ogbg-molhiv: 0.763962 val loss: 0.179745
[Epoch 106] ogbg-molhiv: 0.718884 test loss: 0.255501
[Epoch 107; Iter    28/ 1097] train: loss: 0.0277557
[Epoch 107; Iter    58/ 1097] train: loss: 0.0131169
[Epoch 107; Iter    88/ 1097] train: loss: 0.0536626
[Epoch 107; Iter   118/ 1097] train: loss: 0.0060849
[Epoch 107; Iter   148/ 1097] train: loss: 0.0166211
[Epoch 107; Iter   178/ 1097] train: loss: 0.0183842
[Epoch 107; Iter   208/ 1097] train: loss: 0.0059480
[Epoch 107; Iter   238/ 1097] train: loss: 0.0650034
[Epoch 107; Iter   268/ 1097] train: loss: 0.0271135
[Epoch 107; Iter   298/ 1097] train: loss: 0.0075465
[Epoch 107; Iter   328/ 1097] train: loss: 0.0072196
[Epoch 107; Iter   358/ 1097] train: loss: 0.0448306
[Epoch 107; Iter   388/ 1097] train: loss: 0.0168877
[Epoch 107; Iter   418/ 1097] train: loss: 0.0080477
[Epoch 107; Iter   448/ 1097] train: loss: 0.0540225
[Epoch 107; Iter   478/ 1097] train: loss: 0.0029412
[Epoch 107; Iter   508/ 1097] train: loss: 0.0136151
[Epoch 107; Iter   538/ 1097] train: loss: 0.0280598
[Epoch 107; Iter   568/ 1097] train: loss: 0.0008543
[Epoch 107; Iter   598/ 1097] train: loss: 0.0112460
[Epoch 107; Iter   628/ 1097] train: loss: 0.0025450
[Epoch 107; Iter   658/ 1097] train: loss: 0.0048052
[Epoch 107; Iter   688/ 1097] train: loss: 0.0086431
[Epoch 107; Iter   718/ 1097] train: loss: 0.0228548
[Epoch 107; Iter   748/ 1097] train: loss: 0.0018659
[Epoch 107; Iter   778/ 1097] train: loss: 0.0060502
[Epoch 107; Iter   808/ 1097] train: loss: 0.0247172
[Epoch 107; Iter   838/ 1097] train: loss: 0.0287200
[Epoch 107; Iter   868/ 1097] train: loss: 0.0339636
[Epoch 107; Iter   898/ 1097] train: loss: 0.0653901
[Epoch 107; Iter   928/ 1097] train: loss: 0.0027034
[Epoch 107; Iter   958/ 1097] train: loss: 0.0643232
[Epoch 107; Iter   988/ 1097] train: loss: 0.0031049
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0037023
[Epoch 107; Iter  1048/ 1097] train: loss: 0.1329348
[Epoch 107; Iter  1078/ 1097] train: loss: 0.1461264
[Epoch 107] ogbg-molhiv: 0.771636 val loss: 0.158535
[Epoch 107] ogbg-molhiv: 0.729263 test loss: 0.241019
[Epoch 108; Iter    11/ 1097] train: loss: 0.0322850
[Epoch 108; Iter    41/ 1097] train: loss: 0.0101178
[Epoch 108; Iter    71/ 1097] train: loss: 0.0169585
[Epoch 108; Iter   101/ 1097] train: loss: 0.0233795
[Epoch 108; Iter   131/ 1097] train: loss: 0.0421468
[Epoch 108; Iter   161/ 1097] train: loss: 0.1068325
[Epoch 108; Iter   191/ 1097] train: loss: 0.0024836
[Epoch 108; Iter   221/ 1097] train: loss: 0.0163974
[Epoch 108; Iter   251/ 1097] train: loss: 0.0089388
[Epoch 108; Iter   281/ 1097] train: loss: 0.0098011
[Epoch 108; Iter   311/ 1097] train: loss: 0.0148706
[Epoch 108; Iter   341/ 1097] train: loss: 0.0190617
[Epoch 108; Iter   371/ 1097] train: loss: 0.0380505
[Epoch 108; Iter   401/ 1097] train: loss: 0.0062164
[Epoch 108; Iter   431/ 1097] train: loss: 0.0496152
[Epoch 108; Iter   461/ 1097] train: loss: 0.0046195
[Epoch 108; Iter   491/ 1097] train: loss: 0.0020978
[Epoch 108; Iter   521/ 1097] train: loss: 0.0079574
[Epoch 108; Iter   551/ 1097] train: loss: 0.0883031
[Epoch 108; Iter   581/ 1097] train: loss: 0.0555838
[Epoch 108; Iter   611/ 1097] train: loss: 0.0053753
[Epoch 108; Iter   641/ 1097] train: loss: 0.0207341
[Epoch 108; Iter   671/ 1097] train: loss: 0.0097173
[Epoch 108; Iter   701/ 1097] train: loss: 0.1041104
[Epoch 108; Iter   731/ 1097] train: loss: 0.0128642
[Epoch 108; Iter   761/ 1097] train: loss: 0.0565634
[Epoch 108; Iter   791/ 1097] train: loss: 0.0042165
[Epoch 108; Iter   821/ 1097] train: loss: 0.0018385
[Epoch 108; Iter   851/ 1097] train: loss: 0.0051649
[Epoch 108; Iter   881/ 1097] train: loss: 0.0136926
[Epoch 108; Iter   911/ 1097] train: loss: 0.0404448
[Epoch 108; Iter   941/ 1097] train: loss: 0.0452654
[Epoch 108; Iter   971/ 1097] train: loss: 0.0951753
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0087512
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0815667
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0101129
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0119023
[Epoch 108] ogbg-molhiv: 0.774042 val loss: 0.167535
[Epoch 108] ogbg-molhiv: 0.726464 test loss: 0.238193
[Epoch 109; Iter    24/ 1097] train: loss: 0.0571931
[Epoch 109; Iter    54/ 1097] train: loss: 0.0787181
[Epoch 109; Iter    84/ 1097] train: loss: 0.0238850
[Epoch 109; Iter   114/ 1097] train: loss: 0.0178514
[Epoch 109; Iter   144/ 1097] train: loss: 0.0172419
[Epoch 109; Iter   174/ 1097] train: loss: 0.0106518
[Epoch 109; Iter   204/ 1097] train: loss: 0.0420624
[Epoch 109; Iter   234/ 1097] train: loss: 0.0426982
[Epoch 109; Iter   264/ 1097] train: loss: 0.0351137
[Epoch 109; Iter   294/ 1097] train: loss: 0.0659627
[Epoch 109; Iter   324/ 1097] train: loss: 0.0077286
[Epoch 109; Iter   354/ 1097] train: loss: 0.0243402
[Epoch 109; Iter   384/ 1097] train: loss: 0.0406680
[Epoch 109; Iter   414/ 1097] train: loss: 0.1208958
[Epoch 109; Iter   444/ 1097] train: loss: 0.0478317
[Epoch 109; Iter   474/ 1097] train: loss: 0.0351151
[Epoch 109; Iter   504/ 1097] train: loss: 0.0635790
[Epoch 109; Iter   534/ 1097] train: loss: 0.0082441
[Epoch 109; Iter   564/ 1097] train: loss: 0.0013632
[Epoch 109; Iter   594/ 1097] train: loss: 0.0134962
[Epoch 109; Iter   624/ 1097] train: loss: 0.0023604
[Epoch 109; Iter   654/ 1097] train: loss: 0.0105262
[Epoch 109; Iter   684/ 1097] train: loss: 0.1445590
[Epoch 109; Iter   714/ 1097] train: loss: 0.0069822
[Epoch 111; Iter   280/  823] train: loss: 0.0034284
[Epoch 111; Iter   310/  823] train: loss: 0.0002753
[Epoch 111; Iter   340/  823] train: loss: 0.0005638
[Epoch 111; Iter   370/  823] train: loss: 0.0008104
[Epoch 111; Iter   400/  823] train: loss: 0.1116035
[Epoch 111; Iter   430/  823] train: loss: 0.0067593
[Epoch 111; Iter   460/  823] train: loss: 0.0002954
[Epoch 111; Iter   490/  823] train: loss: 0.0560955
[Epoch 111; Iter   520/  823] train: loss: 0.0003262
[Epoch 111; Iter   550/  823] train: loss: 0.1036972
[Epoch 111; Iter   580/  823] train: loss: 0.0142834
[Epoch 111; Iter   610/  823] train: loss: 0.0033097
[Epoch 111; Iter   640/  823] train: loss: 0.0367433
[Epoch 111; Iter   670/  823] train: loss: 0.0083197
[Epoch 111; Iter   700/  823] train: loss: 0.0008465
[Epoch 111; Iter   730/  823] train: loss: 0.0034056
[Epoch 111; Iter   760/  823] train: loss: 0.0022884
[Epoch 111; Iter   790/  823] train: loss: 0.0042153
[Epoch 111; Iter   820/  823] train: loss: 0.0159261
[Epoch 111] ogbg-molhiv: 0.739982 val loss: 0.456681
[Epoch 111] ogbg-molhiv: 0.756551 test loss: 0.443678
[Epoch 112; Iter    27/  823] train: loss: 0.0009111
[Epoch 112; Iter    57/  823] train: loss: 0.0008655
[Epoch 112; Iter    87/  823] train: loss: 0.0008492
[Epoch 112; Iter   117/  823] train: loss: 0.0007251
[Epoch 112; Iter   147/  823] train: loss: 0.0122296
[Epoch 112; Iter   177/  823] train: loss: 0.0233853
[Epoch 112; Iter   207/  823] train: loss: 0.0076795
[Epoch 112; Iter   237/  823] train: loss: 0.0024059
[Epoch 112; Iter   267/  823] train: loss: 0.0006190
[Epoch 112; Iter   297/  823] train: loss: 0.0014313
[Epoch 112; Iter   327/  823] train: loss: 0.0065814
[Epoch 112; Iter   357/  823] train: loss: 0.0023489
[Epoch 112; Iter   387/  823] train: loss: 0.0001907
[Epoch 112; Iter   417/  823] train: loss: 0.0095865
[Epoch 112; Iter   447/  823] train: loss: 0.0150819
[Epoch 112; Iter   477/  823] train: loss: 0.1233307
[Epoch 112; Iter   507/  823] train: loss: 0.0028493
[Epoch 112; Iter   537/  823] train: loss: 0.0128646
[Epoch 112; Iter   567/  823] train: loss: 0.0021508
[Epoch 112; Iter   597/  823] train: loss: 0.0171987
[Epoch 112; Iter   627/  823] train: loss: 0.0132308
[Epoch 112; Iter   657/  823] train: loss: 0.0114654
[Epoch 112; Iter   687/  823] train: loss: 0.0007116
[Epoch 112; Iter   717/  823] train: loss: 0.0097037
[Epoch 112; Iter   747/  823] train: loss: 0.0022301
[Epoch 112; Iter   777/  823] train: loss: 0.0002573
[Epoch 112; Iter   807/  823] train: loss: 0.0028626
[Epoch 112] ogbg-molhiv: 0.737000 val loss: 0.530227
[Epoch 112] ogbg-molhiv: 0.752325 test loss: 0.486564
[Epoch 113; Iter    14/  823] train: loss: 0.0105059
[Epoch 113; Iter    44/  823] train: loss: 0.0020778
[Epoch 113; Iter    74/  823] train: loss: 0.0031308
[Epoch 113; Iter   104/  823] train: loss: 0.0044667
[Epoch 113; Iter   134/  823] train: loss: 0.0028977
[Epoch 113; Iter   164/  823] train: loss: 0.0108773
[Epoch 113; Iter   194/  823] train: loss: 0.0878664
[Epoch 113; Iter   224/  823] train: loss: 0.0010735
[Epoch 113; Iter   254/  823] train: loss: 0.0254501
[Epoch 113; Iter   284/  823] train: loss: 0.0362750
[Epoch 113; Iter   314/  823] train: loss: 0.0051249
[Epoch 113; Iter   344/  823] train: loss: 0.0078549
[Epoch 113; Iter   374/  823] train: loss: 0.0060875
[Epoch 113; Iter   404/  823] train: loss: 0.0019098
[Epoch 113; Iter   434/  823] train: loss: 0.0237289
[Epoch 113; Iter   464/  823] train: loss: 0.0047931
[Epoch 113; Iter   494/  823] train: loss: 0.0076894
[Epoch 113; Iter   524/  823] train: loss: 0.0834163
[Epoch 113; Iter   554/  823] train: loss: 0.0027640
[Epoch 113; Iter   584/  823] train: loss: 0.0628773
[Epoch 113; Iter   614/  823] train: loss: 0.0006632
[Epoch 113; Iter   644/  823] train: loss: 0.0159030
[Epoch 113; Iter   674/  823] train: loss: 0.0347406
[Epoch 113; Iter   704/  823] train: loss: 0.0014911
[Epoch 113; Iter   734/  823] train: loss: 0.1161275
[Epoch 113; Iter   764/  823] train: loss: 0.0007162
[Epoch 113; Iter   794/  823] train: loss: 0.0978129
[Epoch 113] ogbg-molhiv: 0.737661 val loss: 0.498105
[Epoch 113] ogbg-molhiv: 0.755107 test loss: 0.502208
[Epoch 114; Iter     1/  823] train: loss: 0.0006239
[Epoch 114; Iter    31/  823] train: loss: 0.0013567
[Epoch 114; Iter    61/  823] train: loss: 0.0019100
[Epoch 114; Iter    91/  823] train: loss: 0.0042037
[Epoch 114; Iter   121/  823] train: loss: 0.0037225
[Epoch 114; Iter   151/  823] train: loss: 0.0125479
[Epoch 114; Iter   181/  823] train: loss: 0.0009234
[Epoch 114; Iter   211/  823] train: loss: 0.0021060
[Epoch 114; Iter   241/  823] train: loss: 0.0108290
[Epoch 114; Iter   271/  823] train: loss: 0.0004978
[Epoch 114; Iter   301/  823] train: loss: 0.0020091
[Epoch 114; Iter   331/  823] train: loss: 0.0010188
[Epoch 114; Iter   361/  823] train: loss: 0.0003893
[Epoch 114; Iter   391/  823] train: loss: 0.0090595
[Epoch 114; Iter   421/  823] train: loss: 0.0798856
[Epoch 114; Iter   451/  823] train: loss: 0.0044228
[Epoch 114; Iter   481/  823] train: loss: 0.0027473
[Epoch 114; Iter   511/  823] train: loss: 0.0003686
[Epoch 114; Iter   541/  823] train: loss: 0.0513710
[Epoch 114; Iter   571/  823] train: loss: 0.0471772
[Epoch 114; Iter   601/  823] train: loss: 0.1247065
[Epoch 114; Iter   631/  823] train: loss: 0.0042621
[Epoch 114; Iter   661/  823] train: loss: 0.0056047
[Epoch 114; Iter   691/  823] train: loss: 0.0044597
[Epoch 114; Iter   721/  823] train: loss: 0.0121510
[Epoch 114; Iter   751/  823] train: loss: 0.0019878
[Epoch 114; Iter   781/  823] train: loss: 0.0135664
[Epoch 114; Iter   811/  823] train: loss: 0.0311683
[Epoch 114] ogbg-molhiv: 0.735672 val loss: 0.423510
[Epoch 114] ogbg-molhiv: 0.751433 test loss: 0.418737
[Epoch 115; Iter    18/  823] train: loss: 0.0013707
[Epoch 115; Iter    48/  823] train: loss: 0.0009315
[Epoch 115; Iter    78/  823] train: loss: 0.0032545
[Epoch 115; Iter   108/  823] train: loss: 0.0018634
[Epoch 115; Iter   138/  823] train: loss: 0.0040887
[Epoch 115; Iter   168/  823] train: loss: 0.0014795
[Epoch 115; Iter   198/  823] train: loss: 0.0089621
[Epoch 115; Iter   228/  823] train: loss: 0.0095958
[Epoch 115; Iter   258/  823] train: loss: 0.0039370
[Epoch 115; Iter   288/  823] train: loss: 0.0312933
[Epoch 115; Iter   318/  823] train: loss: 0.0021398
[Epoch 115; Iter   348/  823] train: loss: 0.0005916
[Epoch 115; Iter   378/  823] train: loss: 0.0058716
[Epoch 115; Iter   408/  823] train: loss: 0.0013186
[Epoch 115; Iter   438/  823] train: loss: 0.0027673
[Epoch 115; Iter   468/  823] train: loss: 0.0024281
[Epoch 115; Iter   498/  823] train: loss: 0.0028785
[Epoch 115; Iter   528/  823] train: loss: 0.0046726
[Epoch 115; Iter   558/  823] train: loss: 0.0034590
[Epoch 115; Iter   588/  823] train: loss: 0.0153494
[Epoch 115; Iter   618/  823] train: loss: 0.0002992
[Epoch 115; Iter   648/  823] train: loss: 0.0032038
[Epoch 115; Iter   678/  823] train: loss: 0.0034262
[Epoch 115; Iter   708/  823] train: loss: 0.0061690
[Epoch 115; Iter   738/  823] train: loss: 0.0010954
[Epoch 115; Iter   768/  823] train: loss: 0.0002738
[Epoch 115; Iter   798/  823] train: loss: 0.0271332
[Epoch 115] ogbg-molhiv: 0.736320 val loss: 0.452013
[Epoch 115] ogbg-molhiv: 0.753101 test loss: 0.449436
[Epoch 116; Iter     5/  823] train: loss: 0.0863250
[Epoch 116; Iter    35/  823] train: loss: 0.0020862
[Epoch 116; Iter    65/  823] train: loss: 0.0112155
[Epoch 116; Iter    95/  823] train: loss: 0.0619997
[Epoch 116; Iter   125/  823] train: loss: 0.0278264
[Epoch 116; Iter   155/  823] train: loss: 0.0001027
[Epoch 116; Iter   185/  823] train: loss: 0.0006046
[Epoch 116; Iter   215/  823] train: loss: 0.0105421
[Epoch 116; Iter   245/  823] train: loss: 0.0008285
[Epoch 116; Iter   275/  823] train: loss: 0.0043383
[Epoch 116; Iter   305/  823] train: loss: 0.0057749
[Epoch 116; Iter   335/  823] train: loss: 0.0007828
[Epoch 116; Iter   365/  823] train: loss: 0.0080528
[Epoch 116; Iter   395/  823] train: loss: 0.0005454
[Epoch 116; Iter   425/  823] train: loss: 0.0196553
[Epoch 116; Iter   455/  823] train: loss: 0.0026493
[Epoch 110; Iter   390/  960] train: loss: 0.0091362
[Epoch 110; Iter   420/  960] train: loss: 0.0014124
[Epoch 110; Iter   450/  960] train: loss: 0.0070585
[Epoch 110; Iter   480/  960] train: loss: 0.0181387
[Epoch 110; Iter   510/  960] train: loss: 0.0006840
[Epoch 110; Iter   540/  960] train: loss: 0.0232639
[Epoch 110; Iter   570/  960] train: loss: 0.0006303
[Epoch 110; Iter   600/  960] train: loss: 0.0136051
[Epoch 110; Iter   630/  960] train: loss: 0.0015820
[Epoch 110; Iter   660/  960] train: loss: 0.0035218
[Epoch 110; Iter   690/  960] train: loss: 0.0012770
[Epoch 110; Iter   720/  960] train: loss: 0.0069565
[Epoch 110; Iter   750/  960] train: loss: 0.0109506
[Epoch 110; Iter   780/  960] train: loss: 0.0566424
[Epoch 110; Iter   810/  960] train: loss: 0.0002734
[Epoch 110; Iter   840/  960] train: loss: 0.0054711
[Epoch 110; Iter   870/  960] train: loss: 0.0010043
[Epoch 110; Iter   900/  960] train: loss: 0.0012198
[Epoch 110; Iter   930/  960] train: loss: 0.0004352
[Epoch 110; Iter   960/  960] train: loss: 0.1654781
[Epoch 110] ogbg-molhiv: 0.718187 val loss: 0.307443
[Epoch 110] ogbg-molhiv: 0.756102 test loss: 0.272265
[Epoch 111; Iter    30/  960] train: loss: 0.0313302
[Epoch 111; Iter    60/  960] train: loss: 0.0010242
[Epoch 111; Iter    90/  960] train: loss: 0.0016656
[Epoch 111; Iter   120/  960] train: loss: 0.0012180
[Epoch 111; Iter   150/  960] train: loss: 0.0038256
[Epoch 111; Iter   180/  960] train: loss: 0.0015525
[Epoch 111; Iter   210/  960] train: loss: 0.0006702
[Epoch 111; Iter   240/  960] train: loss: 0.0045854
[Epoch 111; Iter   270/  960] train: loss: 0.0054495
[Epoch 111; Iter   300/  960] train: loss: 0.0571774
[Epoch 111; Iter   330/  960] train: loss: 0.0051460
[Epoch 111; Iter   360/  960] train: loss: 0.0029018
[Epoch 111; Iter   390/  960] train: loss: 0.0014866
[Epoch 111; Iter   420/  960] train: loss: 0.0081068
[Epoch 111; Iter   450/  960] train: loss: 0.0008752
[Epoch 111; Iter   480/  960] train: loss: 0.0005854
[Epoch 111; Iter   510/  960] train: loss: 0.0036517
[Epoch 111; Iter   540/  960] train: loss: 0.0001769
[Epoch 111; Iter   570/  960] train: loss: 0.0029917
[Epoch 111; Iter   600/  960] train: loss: 0.0024976
[Epoch 111; Iter   630/  960] train: loss: 0.0852618
[Epoch 111; Iter   660/  960] train: loss: 0.0014687
[Epoch 111; Iter   690/  960] train: loss: 0.0058602
[Epoch 111; Iter   720/  960] train: loss: 0.0025775
[Epoch 111; Iter   750/  960] train: loss: 0.0019744
[Epoch 111; Iter   780/  960] train: loss: 0.0022619
[Epoch 111; Iter   810/  960] train: loss: 0.0098638
[Epoch 111; Iter   840/  960] train: loss: 0.0008439
[Epoch 111; Iter   870/  960] train: loss: 0.0014479
[Epoch 111; Iter   900/  960] train: loss: 0.0149907
[Epoch 111; Iter   930/  960] train: loss: 0.0777306
[Epoch 111; Iter   960/  960] train: loss: 0.0018984
[Epoch 111] ogbg-molhiv: 0.715838 val loss: 0.315866
[Epoch 111] ogbg-molhiv: 0.759525 test loss: 0.326099
[Epoch 112; Iter    30/  960] train: loss: 0.0566185
[Epoch 112; Iter    60/  960] train: loss: 0.0037148
[Epoch 112; Iter    90/  960] train: loss: 0.0007627
[Epoch 112; Iter   120/  960] train: loss: 0.0060105
[Epoch 112; Iter   150/  960] train: loss: 0.0059183
[Epoch 112; Iter   180/  960] train: loss: 0.0157122
[Epoch 112; Iter   210/  960] train: loss: 0.0249154
[Epoch 112; Iter   240/  960] train: loss: 0.0007138
[Epoch 112; Iter   270/  960] train: loss: 0.0016392
[Epoch 112; Iter   300/  960] train: loss: 0.0020418
[Epoch 112; Iter   330/  960] train: loss: 0.0176040
[Epoch 112; Iter   360/  960] train: loss: 0.0073820
[Epoch 112; Iter   390/  960] train: loss: 0.0598589
[Epoch 112; Iter   420/  960] train: loss: 0.0055957
[Epoch 112; Iter   450/  960] train: loss: 0.0005964
[Epoch 112; Iter   480/  960] train: loss: 0.0071892
[Epoch 112; Iter   510/  960] train: loss: 0.0031743
[Epoch 112; Iter   540/  960] train: loss: 0.0323140
[Epoch 112; Iter   570/  960] train: loss: 0.0522483
[Epoch 112; Iter   600/  960] train: loss: 0.0250365
[Epoch 112; Iter   630/  960] train: loss: 0.0058619
[Epoch 112; Iter   660/  960] train: loss: 0.0664570
[Epoch 112; Iter   690/  960] train: loss: 0.0012947
[Epoch 112; Iter   720/  960] train: loss: 0.1206557
[Epoch 112; Iter   750/  960] train: loss: 0.0021454
[Epoch 112; Iter   780/  960] train: loss: 0.0017084
[Epoch 112; Iter   810/  960] train: loss: 0.0252916
[Epoch 112; Iter   840/  960] train: loss: 0.0041568
[Epoch 112; Iter   870/  960] train: loss: 0.0760954
[Epoch 112; Iter   900/  960] train: loss: 0.0047243
[Epoch 112; Iter   930/  960] train: loss: 0.0109478
[Epoch 112; Iter   960/  960] train: loss: 0.0002030
[Epoch 112] ogbg-molhiv: 0.717578 val loss: 0.305157
[Epoch 112] ogbg-molhiv: 0.755512 test loss: 0.257938
[Epoch 113; Iter    30/  960] train: loss: 0.0171597
[Epoch 113; Iter    60/  960] train: loss: 0.0047120
[Epoch 113; Iter    90/  960] train: loss: 0.0065266
[Epoch 113; Iter   120/  960] train: loss: 0.0061096
[Epoch 113; Iter   150/  960] train: loss: 0.0025812
[Epoch 113; Iter   180/  960] train: loss: 0.0094845
[Epoch 113; Iter   210/  960] train: loss: 0.0004879
[Epoch 113; Iter   240/  960] train: loss: 0.0115361
[Epoch 113; Iter   270/  960] train: loss: 0.0331798
[Epoch 113; Iter   300/  960] train: loss: 0.0836856
[Epoch 113; Iter   330/  960] train: loss: 0.0491483
[Epoch 113; Iter   360/  960] train: loss: 0.1056415
[Epoch 113; Iter   390/  960] train: loss: 0.0062059
[Epoch 113; Iter   420/  960] train: loss: 0.0010599
[Epoch 113; Iter   450/  960] train: loss: 0.0244745
[Epoch 113; Iter   480/  960] train: loss: 0.0013827
[Epoch 113; Iter   510/  960] train: loss: 0.0093304
[Epoch 113; Iter   540/  960] train: loss: 0.0058124
[Epoch 113; Iter   570/  960] train: loss: 0.0156112
[Epoch 113; Iter   600/  960] train: loss: 0.0039786
[Epoch 113; Iter   630/  960] train: loss: 0.0071674
[Epoch 113; Iter   660/  960] train: loss: 0.0114377
[Epoch 113; Iter   690/  960] train: loss: 0.0136320
[Epoch 113; Iter   720/  960] train: loss: 0.0017608
[Epoch 113; Iter   750/  960] train: loss: 0.0023190
[Epoch 113; Iter   780/  960] train: loss: 0.0004258
[Epoch 113; Iter   810/  960] train: loss: 0.0054806
[Epoch 113; Iter   840/  960] train: loss: 0.0601878
[Epoch 113; Iter   870/  960] train: loss: 0.0054994
[Epoch 113; Iter   900/  960] train: loss: 0.0008872
[Epoch 113; Iter   930/  960] train: loss: 0.0013024
[Epoch 113; Iter   960/  960] train: loss: 0.0013455
[Epoch 113] ogbg-molhiv: 0.714658 val loss: 0.411766
[Epoch 113] ogbg-molhiv: 0.753216 test loss: 0.762548
[Epoch 114; Iter    30/  960] train: loss: 0.0134182
[Epoch 114; Iter    60/  960] train: loss: 0.0052496
[Epoch 114; Iter    90/  960] train: loss: 0.0161650
[Epoch 114; Iter   120/  960] train: loss: 0.0696926
[Epoch 114; Iter   150/  960] train: loss: 0.0568305
[Epoch 114; Iter   180/  960] train: loss: 0.0438306
[Epoch 114; Iter   210/  960] train: loss: 0.0055252
[Epoch 114; Iter   240/  960] train: loss: 0.0011464
[Epoch 114; Iter   270/  960] train: loss: 0.0016805
[Epoch 114; Iter   300/  960] train: loss: 0.0005506
[Epoch 114; Iter   330/  960] train: loss: 0.0032127
[Epoch 114; Iter   360/  960] train: loss: 0.0009662
[Epoch 114; Iter   390/  960] train: loss: 0.0218974
[Epoch 114; Iter   420/  960] train: loss: 0.0010434
[Epoch 114; Iter   450/  960] train: loss: 0.0019145
[Epoch 114; Iter   480/  960] train: loss: 0.0389309
[Epoch 114; Iter   510/  960] train: loss: 0.0026629
[Epoch 114; Iter   540/  960] train: loss: 0.0143941
[Epoch 114; Iter   570/  960] train: loss: 0.0126480
[Epoch 114; Iter   600/  960] train: loss: 0.1066185
[Epoch 114; Iter   630/  960] train: loss: 0.0035344
[Epoch 114; Iter   660/  960] train: loss: 0.0005095
[Epoch 114; Iter   690/  960] train: loss: 0.0006998
[Epoch 114; Iter   720/  960] train: loss: 0.0024144
[Epoch 114; Iter   750/  960] train: loss: 0.0006529
[Epoch 114; Iter   780/  960] train: loss: 0.0607773
[Epoch 114; Iter   810/  960] train: loss: 0.0501805
[Epoch 114; Iter   840/  960] train: loss: 0.0031065
[Epoch 114; Iter   870/  960] train: loss: 0.0031599
[Epoch 114; Iter   900/  960] train: loss: 0.0007736
[Epoch 110; Iter   390/  960] train: loss: 0.0189077
[Epoch 110; Iter   420/  960] train: loss: 0.0058027
[Epoch 110; Iter   450/  960] train: loss: 0.0510620
[Epoch 110; Iter   480/  960] train: loss: 0.0116283
[Epoch 110; Iter   510/  960] train: loss: 0.0109596
[Epoch 110; Iter   540/  960] train: loss: 0.0022898
[Epoch 110; Iter   570/  960] train: loss: 0.0171028
[Epoch 110; Iter   600/  960] train: loss: 0.0011573
[Epoch 110; Iter   630/  960] train: loss: 0.0059335
[Epoch 110; Iter   660/  960] train: loss: 0.0074801
[Epoch 110; Iter   690/  960] train: loss: 0.0010461
[Epoch 110; Iter   720/  960] train: loss: 0.0502309
[Epoch 110; Iter   750/  960] train: loss: 0.0145283
[Epoch 110; Iter   780/  960] train: loss: 0.0013921
[Epoch 110; Iter   810/  960] train: loss: 0.0292506
[Epoch 110; Iter   840/  960] train: loss: 0.0088997
[Epoch 110; Iter   870/  960] train: loss: 0.0312096
[Epoch 110; Iter   900/  960] train: loss: 0.0051896
[Epoch 110; Iter   930/  960] train: loss: 0.0982114
[Epoch 110; Iter   960/  960] train: loss: 0.0000291
[Epoch 110] ogbg-molhiv: 0.761902 val loss: 1.014444
[Epoch 110] ogbg-molhiv: 0.750738 test loss: 0.281209
[Epoch 111; Iter    30/  960] train: loss: 0.0060427
[Epoch 111; Iter    60/  960] train: loss: 0.0009943
[Epoch 111; Iter    90/  960] train: loss: 0.0052311
[Epoch 111; Iter   120/  960] train: loss: 0.0022862
[Epoch 111; Iter   150/  960] train: loss: 0.0047722
[Epoch 111; Iter   180/  960] train: loss: 0.0028641
[Epoch 111; Iter   210/  960] train: loss: 0.0265682
[Epoch 111; Iter   240/  960] train: loss: 0.0092525
[Epoch 111; Iter   270/  960] train: loss: 0.0042420
[Epoch 111; Iter   300/  960] train: loss: 0.0213595
[Epoch 111; Iter   330/  960] train: loss: 0.0298407
[Epoch 111; Iter   360/  960] train: loss: 0.0264030
[Epoch 111; Iter   390/  960] train: loss: 0.1786133
[Epoch 111; Iter   420/  960] train: loss: 0.0372871
[Epoch 111; Iter   450/  960] train: loss: 0.0029530
[Epoch 111; Iter   480/  960] train: loss: 0.0151029
[Epoch 111; Iter   510/  960] train: loss: 0.0163938
[Epoch 111; Iter   540/  960] train: loss: 0.0406351
[Epoch 111; Iter   570/  960] train: loss: 0.0011587
[Epoch 111; Iter   600/  960] train: loss: 0.0141496
[Epoch 111; Iter   630/  960] train: loss: 0.0507312
[Epoch 111; Iter   660/  960] train: loss: 0.0187939
[Epoch 111; Iter   690/  960] train: loss: 0.0017463
[Epoch 111; Iter   720/  960] train: loss: 0.0141024
[Epoch 111; Iter   750/  960] train: loss: 0.0186011
[Epoch 111; Iter   780/  960] train: loss: 0.0034422
[Epoch 111; Iter   810/  960] train: loss: 0.0011253
[Epoch 111; Iter   840/  960] train: loss: 0.0040425
[Epoch 111; Iter   870/  960] train: loss: 0.0902208
[Epoch 111; Iter   900/  960] train: loss: 0.0180834
[Epoch 111; Iter   930/  960] train: loss: 0.0012852
[Epoch 111; Iter   960/  960] train: loss: 0.0007412
[Epoch 111] ogbg-molhiv: 0.757407 val loss: 1.219055
[Epoch 111] ogbg-molhiv: 0.757178 test loss: 0.313899
[Epoch 112; Iter    30/  960] train: loss: 0.0010105
[Epoch 112; Iter    60/  960] train: loss: 0.0085587
[Epoch 112; Iter    90/  960] train: loss: 0.0030905
[Epoch 112; Iter   120/  960] train: loss: 0.0536582
[Epoch 112; Iter   150/  960] train: loss: 0.0197535
[Epoch 112; Iter   180/  960] train: loss: 0.0494652
[Epoch 112; Iter   210/  960] train: loss: 0.0017832
[Epoch 112; Iter   240/  960] train: loss: 0.0005845
[Epoch 112; Iter   270/  960] train: loss: 0.0052404
[Epoch 112; Iter   300/  960] train: loss: 0.0031258
[Epoch 112; Iter   330/  960] train: loss: 0.0199206
[Epoch 112; Iter   360/  960] train: loss: 0.0073701
[Epoch 112; Iter   390/  960] train: loss: 0.0008905
[Epoch 112; Iter   420/  960] train: loss: 0.0068547
[Epoch 112; Iter   450/  960] train: loss: 0.0120684
[Epoch 112; Iter   480/  960] train: loss: 0.0274687
[Epoch 112; Iter   510/  960] train: loss: 0.0085884
[Epoch 112; Iter   540/  960] train: loss: 0.0285204
[Epoch 112; Iter   570/  960] train: loss: 0.0067797
[Epoch 112; Iter   600/  960] train: loss: 0.0013378
[Epoch 112; Iter   630/  960] train: loss: 0.0038106
[Epoch 112; Iter   660/  960] train: loss: 0.0026723
[Epoch 112; Iter   690/  960] train: loss: 0.0072940
[Epoch 112; Iter   720/  960] train: loss: 0.0225594
[Epoch 112; Iter   750/  960] train: loss: 0.0028779
[Epoch 112; Iter   780/  960] train: loss: 0.0243574
[Epoch 112; Iter   810/  960] train: loss: 0.0182507
[Epoch 112; Iter   840/  960] train: loss: 0.0575833
[Epoch 112; Iter   870/  960] train: loss: 0.0148354
[Epoch 112; Iter   900/  960] train: loss: 0.0011721
[Epoch 112; Iter   930/  960] train: loss: 0.0013520
[Epoch 112; Iter   960/  960] train: loss: 0.0010011
[Epoch 112] ogbg-molhiv: 0.756088 val loss: 1.087617
[Epoch 112] ogbg-molhiv: 0.758780 test loss: 0.306556
[Epoch 113; Iter    30/  960] train: loss: 0.0042153
[Epoch 113; Iter    60/  960] train: loss: 0.0184250
[Epoch 113; Iter    90/  960] train: loss: 0.0112505
[Epoch 113; Iter   120/  960] train: loss: 0.0039088
[Epoch 113; Iter   150/  960] train: loss: 0.0534050
[Epoch 113; Iter   180/  960] train: loss: 0.0401888
[Epoch 113; Iter   210/  960] train: loss: 0.0169133
[Epoch 113; Iter   240/  960] train: loss: 0.0002528
[Epoch 113; Iter   270/  960] train: loss: 0.0007388
[Epoch 113; Iter   300/  960] train: loss: 0.0097293
[Epoch 113; Iter   330/  960] train: loss: 0.0440713
[Epoch 113; Iter   360/  960] train: loss: 0.0008887
[Epoch 113; Iter   390/  960] train: loss: 0.0368621
[Epoch 113; Iter   420/  960] train: loss: 0.0106814
[Epoch 113; Iter   450/  960] train: loss: 0.0291770
[Epoch 113; Iter   480/  960] train: loss: 0.0358249
[Epoch 113; Iter   510/  960] train: loss: 0.0337661
[Epoch 113; Iter   540/  960] train: loss: 0.0004062
[Epoch 113; Iter   570/  960] train: loss: 0.1119320
[Epoch 113; Iter   600/  960] train: loss: 0.0024508
[Epoch 113; Iter   630/  960] train: loss: 0.0104845
[Epoch 113; Iter   660/  960] train: loss: 0.0019070
[Epoch 113; Iter   690/  960] train: loss: 0.0008485
[Epoch 113; Iter   720/  960] train: loss: 0.0011805
[Epoch 113; Iter   750/  960] train: loss: 0.0142922
[Epoch 113; Iter   780/  960] train: loss: 0.0118652
[Epoch 113; Iter   810/  960] train: loss: 0.0018487
[Epoch 113; Iter   840/  960] train: loss: 0.0019411
[Epoch 113; Iter   870/  960] train: loss: 0.0019271
[Epoch 113; Iter   900/  960] train: loss: 0.0005330
[Epoch 113; Iter   930/  960] train: loss: 0.0023311
[Epoch 113; Iter   960/  960] train: loss: 0.0019249
[Epoch 113] ogbg-molhiv: 0.755122 val loss: 0.985825
[Epoch 113] ogbg-molhiv: 0.754703 test loss: 0.284221
[Epoch 114; Iter    30/  960] train: loss: 0.0138633
[Epoch 114; Iter    60/  960] train: loss: 0.0031766
[Epoch 114; Iter    90/  960] train: loss: 0.1740047
[Epoch 114; Iter   120/  960] train: loss: 0.0203539
[Epoch 114; Iter   150/  960] train: loss: 0.0041990
[Epoch 114; Iter   180/  960] train: loss: 0.0011269
[Epoch 114; Iter   210/  960] train: loss: 0.0091795
[Epoch 114; Iter   240/  960] train: loss: 0.0018445
[Epoch 114; Iter   270/  960] train: loss: 0.0091358
[Epoch 114; Iter   300/  960] train: loss: 0.0021837
[Epoch 114; Iter   330/  960] train: loss: 0.0045095
[Epoch 114; Iter   360/  960] train: loss: 0.0168044
[Epoch 114; Iter   390/  960] train: loss: 0.0421781
[Epoch 114; Iter   420/  960] train: loss: 0.0022793
[Epoch 114; Iter   450/  960] train: loss: 0.0063699
[Epoch 114; Iter   480/  960] train: loss: 0.0625833
[Epoch 114; Iter   510/  960] train: loss: 0.0232798
[Epoch 114; Iter   540/  960] train: loss: 0.0014381
[Epoch 114; Iter   570/  960] train: loss: 0.0125880
[Epoch 114; Iter   600/  960] train: loss: 0.0037398
[Epoch 114; Iter   630/  960] train: loss: 0.0092857
[Epoch 114; Iter   660/  960] train: loss: 0.1925041
[Epoch 114; Iter   690/  960] train: loss: 0.0301667
[Epoch 114; Iter   720/  960] train: loss: 0.0206941
[Epoch 114; Iter   750/  960] train: loss: 0.0030073
[Epoch 114; Iter   780/  960] train: loss: 0.0038480
[Epoch 114; Iter   810/  960] train: loss: 0.0818358
[Epoch 114; Iter   840/  960] train: loss: 0.1739706
[Epoch 114; Iter   870/  960] train: loss: 0.0005217
[Epoch 114; Iter   900/  960] train: loss: 0.0221134
[Epoch 105; Iter   752/ 1097] train: loss: 0.0025189
[Epoch 105; Iter   782/ 1097] train: loss: 0.0051414
[Epoch 105; Iter   812/ 1097] train: loss: 0.0260174
[Epoch 105; Iter   842/ 1097] train: loss: 0.0061745
[Epoch 105; Iter   872/ 1097] train: loss: 0.0118263
[Epoch 105; Iter   902/ 1097] train: loss: 0.0042440
[Epoch 105; Iter   932/ 1097] train: loss: 0.0021168
[Epoch 105; Iter   962/ 1097] train: loss: 0.0141879
[Epoch 105; Iter   992/ 1097] train: loss: 0.0028176
[Epoch 105; Iter  1022/ 1097] train: loss: 0.0067710
[Epoch 105; Iter  1052/ 1097] train: loss: 0.0010342
[Epoch 105; Iter  1082/ 1097] train: loss: 0.0030408
[Epoch 105] ogbg-molhiv: 0.801673 val loss: 0.133279
[Epoch 105] ogbg-molhiv: 0.764582 test loss: 0.245854
[Epoch 106; Iter    15/ 1097] train: loss: 0.0005463
[Epoch 106; Iter    45/ 1097] train: loss: 0.0027488
[Epoch 106; Iter    75/ 1097] train: loss: 0.0110288
[Epoch 106; Iter   105/ 1097] train: loss: 0.0379194
[Epoch 106; Iter   135/ 1097] train: loss: 0.0083623
[Epoch 106; Iter   165/ 1097] train: loss: 0.0023877
[Epoch 106; Iter   195/ 1097] train: loss: 0.0060141
[Epoch 106; Iter   225/ 1097] train: loss: 0.0011498
[Epoch 106; Iter   255/ 1097] train: loss: 0.0012912
[Epoch 106; Iter   285/ 1097] train: loss: 0.0016010
[Epoch 106; Iter   315/ 1097] train: loss: 0.0093989
[Epoch 106; Iter   345/ 1097] train: loss: 0.0151439
[Epoch 106; Iter   375/ 1097] train: loss: 0.0041890
[Epoch 106; Iter   405/ 1097] train: loss: 0.0035522
[Epoch 106; Iter   435/ 1097] train: loss: 0.0155721
[Epoch 106; Iter   465/ 1097] train: loss: 0.0087863
[Epoch 106; Iter   495/ 1097] train: loss: 0.0034520
[Epoch 106; Iter   525/ 1097] train: loss: 0.0041398
[Epoch 106; Iter   555/ 1097] train: loss: 0.0085909
[Epoch 106; Iter   585/ 1097] train: loss: 0.0017111
[Epoch 106; Iter   615/ 1097] train: loss: 0.0695212
[Epoch 106; Iter   645/ 1097] train: loss: 0.0671443
[Epoch 106; Iter   675/ 1097] train: loss: 0.0054434
[Epoch 106; Iter   705/ 1097] train: loss: 0.0162759
[Epoch 106; Iter   735/ 1097] train: loss: 0.0092239
[Epoch 106; Iter   765/ 1097] train: loss: 0.0036289
[Epoch 106; Iter   795/ 1097] train: loss: 0.0802946
[Epoch 106; Iter   825/ 1097] train: loss: 0.0037716
[Epoch 106; Iter   855/ 1097] train: loss: 0.0288905
[Epoch 106; Iter   885/ 1097] train: loss: 0.0461458
[Epoch 106; Iter   915/ 1097] train: loss: 0.0124836
[Epoch 106; Iter   945/ 1097] train: loss: 0.0051940
[Epoch 106; Iter   975/ 1097] train: loss: 0.0007485
[Epoch 106; Iter  1005/ 1097] train: loss: 0.0050005
[Epoch 106; Iter  1035/ 1097] train: loss: 0.0307362
[Epoch 106; Iter  1065/ 1097] train: loss: 0.0008228
[Epoch 106; Iter  1095/ 1097] train: loss: 0.0294424
[Epoch 106] ogbg-molhiv: 0.799150 val loss: 0.140225
[Epoch 106] ogbg-molhiv: 0.745377 test loss: 0.262666
[Epoch 107; Iter    28/ 1097] train: loss: 0.0269966
[Epoch 107; Iter    58/ 1097] train: loss: 0.0131100
[Epoch 107; Iter    88/ 1097] train: loss: 0.0006640
[Epoch 107; Iter   118/ 1097] train: loss: 0.0028019
[Epoch 107; Iter   148/ 1097] train: loss: 0.0119271
[Epoch 107; Iter   178/ 1097] train: loss: 0.0006855
[Epoch 107; Iter   208/ 1097] train: loss: 0.0029218
[Epoch 107; Iter   238/ 1097] train: loss: 0.0026010
[Epoch 107; Iter   268/ 1097] train: loss: 0.0017636
[Epoch 107; Iter   298/ 1097] train: loss: 0.0147306
[Epoch 107; Iter   328/ 1097] train: loss: 0.0017584
[Epoch 107; Iter   358/ 1097] train: loss: 0.0035051
[Epoch 107; Iter   388/ 1097] train: loss: 0.0026797
[Epoch 107; Iter   418/ 1097] train: loss: 0.0218996
[Epoch 107; Iter   448/ 1097] train: loss: 0.0168262
[Epoch 107; Iter   478/ 1097] train: loss: 0.0019696
[Epoch 107; Iter   508/ 1097] train: loss: 0.0276471
[Epoch 107; Iter   538/ 1097] train: loss: 0.0072981
[Epoch 107; Iter   568/ 1097] train: loss: 0.0012736
[Epoch 107; Iter   598/ 1097] train: loss: 0.0175957
[Epoch 107; Iter   628/ 1097] train: loss: 0.0061136
[Epoch 107; Iter   658/ 1097] train: loss: 0.0154067
[Epoch 107; Iter   688/ 1097] train: loss: 0.0197582
[Epoch 107; Iter   718/ 1097] train: loss: 0.1616013
[Epoch 107; Iter   748/ 1097] train: loss: 0.0172559
[Epoch 107; Iter   778/ 1097] train: loss: 0.0007492
[Epoch 107; Iter   808/ 1097] train: loss: 0.0068927
[Epoch 107; Iter   838/ 1097] train: loss: 0.1180848
[Epoch 107; Iter   868/ 1097] train: loss: 0.0023178
[Epoch 107; Iter   898/ 1097] train: loss: 0.0018368
[Epoch 107; Iter   928/ 1097] train: loss: 0.0245665
[Epoch 107; Iter   958/ 1097] train: loss: 0.0019609
[Epoch 107; Iter   988/ 1097] train: loss: 0.0031557
[Epoch 107; Iter  1018/ 1097] train: loss: 0.0810335
[Epoch 107; Iter  1048/ 1097] train: loss: 0.0125485
[Epoch 107; Iter  1078/ 1097] train: loss: 0.0030340
[Epoch 107] ogbg-molhiv: 0.796015 val loss: 0.136228
[Epoch 107] ogbg-molhiv: 0.759132 test loss: 0.250240
[Epoch 108; Iter    11/ 1097] train: loss: 0.0116626
[Epoch 108; Iter    41/ 1097] train: loss: 0.0092217
[Epoch 108; Iter    71/ 1097] train: loss: 0.0034373
[Epoch 108; Iter   101/ 1097] train: loss: 0.0152251
[Epoch 108; Iter   131/ 1097] train: loss: 0.0231582
[Epoch 108; Iter   161/ 1097] train: loss: 0.0021700
[Epoch 108; Iter   191/ 1097] train: loss: 0.0110507
[Epoch 108; Iter   221/ 1097] train: loss: 0.0588056
[Epoch 108; Iter   251/ 1097] train: loss: 0.0694998
[Epoch 108; Iter   281/ 1097] train: loss: 0.0013879
[Epoch 108; Iter   311/ 1097] train: loss: 0.0138286
[Epoch 108; Iter   341/ 1097] train: loss: 0.0072444
[Epoch 108; Iter   371/ 1097] train: loss: 0.0070549
[Epoch 108; Iter   401/ 1097] train: loss: 0.0028831
[Epoch 108; Iter   431/ 1097] train: loss: 0.0535153
[Epoch 108; Iter   461/ 1097] train: loss: 0.0015052
[Epoch 108; Iter   491/ 1097] train: loss: 0.0022256
[Epoch 108; Iter   521/ 1097] train: loss: 0.0024417
[Epoch 108; Iter   551/ 1097] train: loss: 0.0035212
[Epoch 108; Iter   581/ 1097] train: loss: 0.0007815
[Epoch 108; Iter   611/ 1097] train: loss: 0.0034897
[Epoch 108; Iter   641/ 1097] train: loss: 0.0006359
[Epoch 108; Iter   671/ 1097] train: loss: 0.0011621
[Epoch 108; Iter   701/ 1097] train: loss: 0.0183276
[Epoch 108; Iter   731/ 1097] train: loss: 0.0276722
[Epoch 108; Iter   761/ 1097] train: loss: 0.0003387
[Epoch 108; Iter   791/ 1097] train: loss: 0.0146004
[Epoch 108; Iter   821/ 1097] train: loss: 0.0021480
[Epoch 108; Iter   851/ 1097] train: loss: 0.0038473
[Epoch 108; Iter   881/ 1097] train: loss: 0.0034813
[Epoch 108; Iter   911/ 1097] train: loss: 0.0253869
[Epoch 108; Iter   941/ 1097] train: loss: 0.0003103
[Epoch 108; Iter   971/ 1097] train: loss: 0.0051722
[Epoch 108; Iter  1001/ 1097] train: loss: 0.0027264
[Epoch 108; Iter  1031/ 1097] train: loss: 0.0150354
[Epoch 108; Iter  1061/ 1097] train: loss: 0.0023264
[Epoch 108; Iter  1091/ 1097] train: loss: 0.0059790
[Epoch 108] ogbg-molhiv: 0.791918 val loss: 0.135519
[Epoch 108] ogbg-molhiv: 0.751830 test loss: 0.251951
[Epoch 109; Iter    24/ 1097] train: loss: 0.0267534
[Epoch 109; Iter    54/ 1097] train: loss: 0.0010834
[Epoch 109; Iter    84/ 1097] train: loss: 0.0010300
[Epoch 109; Iter   114/ 1097] train: loss: 0.0013398
[Epoch 109; Iter   144/ 1097] train: loss: 0.0009959
[Epoch 109; Iter   174/ 1097] train: loss: 0.0006532
[Epoch 109; Iter   204/ 1097] train: loss: 0.0051278
[Epoch 109; Iter   234/ 1097] train: loss: 0.0025862
[Epoch 109; Iter   264/ 1097] train: loss: 0.0045025
[Epoch 109; Iter   294/ 1097] train: loss: 0.0991004
[Epoch 109; Iter   324/ 1097] train: loss: 0.0767023
[Epoch 109; Iter   354/ 1097] train: loss: 0.0245127
[Epoch 109; Iter   384/ 1097] train: loss: 0.0019590
[Epoch 109; Iter   414/ 1097] train: loss: 0.0092952
[Epoch 109; Iter   444/ 1097] train: loss: 0.0132135
[Epoch 109; Iter   474/ 1097] train: loss: 0.0015391
[Epoch 109; Iter   504/ 1097] train: loss: 0.0371739
[Epoch 109; Iter   534/ 1097] train: loss: 0.0026902
[Epoch 109; Iter   564/ 1097] train: loss: 0.0004448
[Epoch 109; Iter   594/ 1097] train: loss: 0.0320230
[Epoch 109; Iter   624/ 1097] train: loss: 0.0130816
[Epoch 109; Iter   654/ 1097] train: loss: 0.0023293
[Epoch 109; Iter   684/ 1097] train: loss: 0.0026551
[Epoch 109; Iter   714/ 1097] train: loss: 0.0081306
[Epoch 110; Iter   390/  960] train: loss: 0.0028126
[Epoch 110; Iter   420/  960] train: loss: 0.0037472
[Epoch 110; Iter   450/  960] train: loss: 0.0167119
[Epoch 110; Iter   480/  960] train: loss: 0.0784380
[Epoch 110; Iter   510/  960] train: loss: 0.0828307
[Epoch 110; Iter   540/  960] train: loss: 0.0112330
[Epoch 110; Iter   570/  960] train: loss: 0.0015634
[Epoch 110; Iter   600/  960] train: loss: 0.0021594
[Epoch 110; Iter   630/  960] train: loss: 0.0196488
[Epoch 110; Iter   660/  960] train: loss: 0.0109260
[Epoch 110; Iter   690/  960] train: loss: 0.0045712
[Epoch 110; Iter   720/  960] train: loss: 0.0730461
[Epoch 110; Iter   750/  960] train: loss: 0.0506694
[Epoch 110; Iter   780/  960] train: loss: 0.0007484
[Epoch 110; Iter   810/  960] train: loss: 0.0061066
[Epoch 110; Iter   840/  960] train: loss: 0.0256387
[Epoch 110; Iter   870/  960] train: loss: 0.0634143
[Epoch 110; Iter   900/  960] train: loss: 0.0606471
[Epoch 110; Iter   930/  960] train: loss: 0.0066199
[Epoch 110; Iter   960/  960] train: loss: 0.0019116
[Epoch 110] ogbg-molhiv: 0.716000 val loss: 0.602345
[Epoch 110] ogbg-molhiv: 0.748857 test loss: 0.489794
[Epoch 111; Iter    30/  960] train: loss: 0.0012966
[Epoch 111; Iter    60/  960] train: loss: 0.0136794
[Epoch 111; Iter    90/  960] train: loss: 0.0199361
[Epoch 111; Iter   120/  960] train: loss: 0.0080564
[Epoch 111; Iter   150/  960] train: loss: 0.0456103
[Epoch 111; Iter   180/  960] train: loss: 0.0085618
[Epoch 111; Iter   210/  960] train: loss: 0.0002979
[Epoch 111; Iter   240/  960] train: loss: 0.0027717
[Epoch 111; Iter   270/  960] train: loss: 0.0014566
[Epoch 111; Iter   300/  960] train: loss: 0.0018671
[Epoch 111; Iter   330/  960] train: loss: 0.0195198
[Epoch 111; Iter   360/  960] train: loss: 0.0059795
[Epoch 111; Iter   390/  960] train: loss: 0.0438859
[Epoch 111; Iter   420/  960] train: loss: 0.0274851
[Epoch 111; Iter   450/  960] train: loss: 0.0033712
[Epoch 111; Iter   480/  960] train: loss: 0.0114297
[Epoch 111; Iter   510/  960] train: loss: 0.0512041
[Epoch 111; Iter   540/  960] train: loss: 0.0153141
[Epoch 111; Iter   570/  960] train: loss: 0.0020003
[Epoch 111; Iter   600/  960] train: loss: 0.0512797
[Epoch 111; Iter   630/  960] train: loss: 0.0018488
[Epoch 111; Iter   660/  960] train: loss: 0.0075604
[Epoch 111; Iter   690/  960] train: loss: 0.0051592
[Epoch 111; Iter   720/  960] train: loss: 0.0732471
[Epoch 111; Iter   750/  960] train: loss: 0.0009351
[Epoch 111; Iter   780/  960] train: loss: 0.0349913
[Epoch 111; Iter   810/  960] train: loss: 0.0711447
[Epoch 111; Iter   840/  960] train: loss: 0.0182403
[Epoch 111; Iter   870/  960] train: loss: 0.0071766
[Epoch 111; Iter   900/  960] train: loss: 0.0006195
[Epoch 111; Iter   930/  960] train: loss: 0.0143577
[Epoch 111; Iter   960/  960] train: loss: 0.0048960
[Epoch 111] ogbg-molhiv: 0.719417 val loss: 1.064003
[Epoch 111] ogbg-molhiv: 0.744046 test loss: 0.668505
[Epoch 112; Iter    30/  960] train: loss: 0.0044128
[Epoch 112; Iter    60/  960] train: loss: 0.0086298
[Epoch 112; Iter    90/  960] train: loss: 0.0008935
[Epoch 112; Iter   120/  960] train: loss: 0.0103043
[Epoch 112; Iter   150/  960] train: loss: 0.0096739
[Epoch 112; Iter   180/  960] train: loss: 0.0031550
[Epoch 112; Iter   210/  960] train: loss: 0.0010880
[Epoch 112; Iter   240/  960] train: loss: 0.0883243
[Epoch 112; Iter   270/  960] train: loss: 0.0473506
[Epoch 112; Iter   300/  960] train: loss: 0.0033540
[Epoch 112; Iter   330/  960] train: loss: 0.0028267
[Epoch 112; Iter   360/  960] train: loss: 0.0223964
[Epoch 112; Iter   390/  960] train: loss: 0.0095791
[Epoch 112; Iter   420/  960] train: loss: 0.0015222
[Epoch 112; Iter   450/  960] train: loss: 0.0021467
[Epoch 112; Iter   480/  960] train: loss: 0.0014373
[Epoch 112; Iter   510/  960] train: loss: 0.0022978
[Epoch 112; Iter   540/  960] train: loss: 0.0538928
[Epoch 112; Iter   570/  960] train: loss: 0.1833517
[Epoch 112; Iter   600/  960] train: loss: 0.0181183
[Epoch 112; Iter   630/  960] train: loss: 0.0045065
[Epoch 112; Iter   660/  960] train: loss: 0.0013878
[Epoch 112; Iter   690/  960] train: loss: 0.0006573
[Epoch 112; Iter   720/  960] train: loss: 0.0009752
[Epoch 112; Iter   750/  960] train: loss: 0.0015517
[Epoch 112; Iter   780/  960] train: loss: 0.0192311
[Epoch 112; Iter   810/  960] train: loss: 0.0397420
[Epoch 112; Iter   840/  960] train: loss: 0.0074423
[Epoch 112; Iter   870/  960] train: loss: 0.0507501
[Epoch 112; Iter   900/  960] train: loss: 0.0093556
[Epoch 112; Iter   930/  960] train: loss: 0.0405401
[Epoch 112; Iter   960/  960] train: loss: 0.0714439
[Epoch 112] ogbg-molhiv: 0.715894 val loss: 0.915589
[Epoch 112] ogbg-molhiv: 0.746519 test loss: 0.570865
[Epoch 113; Iter    30/  960] train: loss: 0.0271789
[Epoch 113; Iter    60/  960] train: loss: 0.0077290
[Epoch 113; Iter    90/  960] train: loss: 0.0342579
[Epoch 113; Iter   120/  960] train: loss: 0.0091536
[Epoch 113; Iter   150/  960] train: loss: 0.0264125
[Epoch 113; Iter   180/  960] train: loss: 0.0002313
[Epoch 113; Iter   210/  960] train: loss: 0.0056953
[Epoch 113; Iter   240/  960] train: loss: 0.0015655
[Epoch 113; Iter   270/  960] train: loss: 0.0136581
[Epoch 113; Iter   300/  960] train: loss: 0.0208297
[Epoch 113; Iter   330/  960] train: loss: 0.0015390
[Epoch 113; Iter   360/  960] train: loss: 0.0004568
[Epoch 113; Iter   390/  960] train: loss: 0.0340349
[Epoch 113; Iter   420/  960] train: loss: 0.0056578
[Epoch 113; Iter   450/  960] train: loss: 0.0009027
[Epoch 113; Iter   480/  960] train: loss: 0.0013881
[Epoch 113; Iter   510/  960] train: loss: 0.0051485
[Epoch 113; Iter   540/  960] train: loss: 0.0035236
[Epoch 113; Iter   570/  960] train: loss: 0.0035961
[Epoch 113; Iter   600/  960] train: loss: 0.0158661
[Epoch 113; Iter   630/  960] train: loss: 0.1345913
[Epoch 113; Iter   660/  960] train: loss: 0.0034119
[Epoch 113; Iter   690/  960] train: loss: 0.0678560
[Epoch 113; Iter   720/  960] train: loss: 0.0474920
[Epoch 113; Iter   750/  960] train: loss: 0.0445845
[Epoch 113; Iter   780/  960] train: loss: 0.0013651
[Epoch 113; Iter   810/  960] train: loss: 0.0333144
[Epoch 113; Iter   840/  960] train: loss: 0.0266584
[Epoch 113; Iter   870/  960] train: loss: 0.0160758
[Epoch 113; Iter   900/  960] train: loss: 0.0017200
[Epoch 113; Iter   930/  960] train: loss: 0.0555673
[Epoch 113; Iter   960/  960] train: loss: 0.0014329
[Epoch 113] ogbg-molhiv: 0.718356 val loss: 0.294681
[Epoch 113] ogbg-molhiv: 0.743591 test loss: 0.216103
[Epoch 114; Iter    30/  960] train: loss: 0.0059356
[Epoch 114; Iter    60/  960] train: loss: 0.0009199
[Epoch 114; Iter    90/  960] train: loss: 0.0517531
[Epoch 114; Iter   120/  960] train: loss: 0.0009944
[Epoch 114; Iter   150/  960] train: loss: 0.0120887
[Epoch 114; Iter   180/  960] train: loss: 0.0378567
[Epoch 114; Iter   210/  960] train: loss: 0.0683134
[Epoch 114; Iter   240/  960] train: loss: 0.0195585
[Epoch 114; Iter   270/  960] train: loss: 0.0027519
[Epoch 114; Iter   300/  960] train: loss: 0.0122064
[Epoch 114; Iter   330/  960] train: loss: 0.0035691
[Epoch 114; Iter   360/  960] train: loss: 0.0016178
[Epoch 114; Iter   390/  960] train: loss: 0.0103371
[Epoch 114; Iter   420/  960] train: loss: 0.0058358
[Epoch 114; Iter   450/  960] train: loss: 0.0349029
[Epoch 114; Iter   480/  960] train: loss: 0.0002762
[Epoch 114; Iter   510/  960] train: loss: 0.0046082
[Epoch 114; Iter   540/  960] train: loss: 0.0016779
[Epoch 114; Iter   570/  960] train: loss: 0.0206438
[Epoch 114; Iter   600/  960] train: loss: 0.0038536
[Epoch 114; Iter   630/  960] train: loss: 0.0080911
[Epoch 114; Iter   660/  960] train: loss: 0.0021116
[Epoch 114; Iter   690/  960] train: loss: 0.0049408
[Epoch 114; Iter   720/  960] train: loss: 0.0628250
[Epoch 114; Iter   750/  960] train: loss: 0.0611488
[Epoch 114; Iter   780/  960] train: loss: 0.0003689
[Epoch 114; Iter   810/  960] train: loss: 0.0642328
[Epoch 114; Iter   840/  960] train: loss: 0.0014161
[Epoch 114; Iter   870/  960] train: loss: 0.0947450
[Epoch 114; Iter   900/  960] train: loss: 0.0197462
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   485/  823] train: loss: 0.0182351
[Epoch 116; Iter   515/  823] train: loss: 0.0062566
[Epoch 116; Iter   545/  823] train: loss: 0.0002205
[Epoch 116; Iter   575/  823] train: loss: 0.0034116
[Epoch 116; Iter   605/  823] train: loss: 0.0029853
[Epoch 116; Iter   635/  823] train: loss: 0.0073876
[Epoch 116; Iter   665/  823] train: loss: 0.0082939
[Epoch 116; Iter   695/  823] train: loss: 0.0246102
[Epoch 116; Iter   725/  823] train: loss: 0.0071227
[Epoch 116; Iter   755/  823] train: loss: 0.0048881
[Epoch 116; Iter   785/  823] train: loss: 0.0971144
[Epoch 116; Iter   815/  823] train: loss: 0.0030418
[Epoch 116] ogbg-molhiv: 0.742257 val loss: 0.272143
[Epoch 116] ogbg-molhiv: 0.747294 test loss: 0.272310
[Epoch 117; Iter    22/  823] train: loss: 0.0056501
[Epoch 117; Iter    52/  823] train: loss: 0.0009441
[Epoch 117; Iter    82/  823] train: loss: 0.0009790
[Epoch 117; Iter   112/  823] train: loss: 0.0018553
[Epoch 117; Iter   142/  823] train: loss: 0.0228025
[Epoch 117; Iter   172/  823] train: loss: 0.0102179
[Epoch 117; Iter   202/  823] train: loss: 0.0030623
[Epoch 117; Iter   232/  823] train: loss: 0.0090991
[Epoch 117; Iter   262/  823] train: loss: 0.0070157
[Epoch 117; Iter   292/  823] train: loss: 0.0114775
[Epoch 117; Iter   322/  823] train: loss: 0.0054099
[Epoch 117; Iter   352/  823] train: loss: 0.0020233
[Epoch 117; Iter   382/  823] train: loss: 0.0343673
[Epoch 117; Iter   412/  823] train: loss: 0.0121293
[Epoch 117; Iter   442/  823] train: loss: 0.0011023
[Epoch 117; Iter   472/  823] train: loss: 0.0239416
[Epoch 117; Iter   502/  823] train: loss: 0.0455716
[Epoch 117; Iter   532/  823] train: loss: 0.0010753
[Epoch 117; Iter   562/  823] train: loss: 0.0344460
[Epoch 117; Iter   592/  823] train: loss: 0.0013053
[Epoch 117; Iter   622/  823] train: loss: 0.0076498
[Epoch 117; Iter   652/  823] train: loss: 0.0089940
[Epoch 117; Iter   682/  823] train: loss: 0.0068329
[Epoch 117; Iter   712/  823] train: loss: 0.0194050
[Epoch 117; Iter   742/  823] train: loss: 0.0049269
[Epoch 117; Iter   772/  823] train: loss: 0.0155059
[Epoch 117; Iter   802/  823] train: loss: 0.0198227
[Epoch 117] ogbg-molhiv: 0.744988 val loss: 0.273069
[Epoch 117] ogbg-molhiv: 0.748867 test loss: 0.287160
[Epoch 118; Iter     9/  823] train: loss: 0.0039901
[Epoch 118; Iter    39/  823] train: loss: 0.0005316
[Epoch 118; Iter    69/  823] train: loss: 0.0489352
[Epoch 118; Iter    99/  823] train: loss: 0.0071111
[Epoch 118; Iter   129/  823] train: loss: 0.0116286
[Epoch 118; Iter   159/  823] train: loss: 0.0171443
[Epoch 118; Iter   189/  823] train: loss: 0.0026247
[Epoch 118; Iter   219/  823] train: loss: 0.0172351
[Epoch 118; Iter   249/  823] train: loss: 0.0144594
[Epoch 118; Iter   279/  823] train: loss: 0.1273567
[Epoch 118; Iter   309/  823] train: loss: 0.1073037
[Epoch 118; Iter   339/  823] train: loss: 0.0021817
[Epoch 118; Iter   369/  823] train: loss: 0.0052106
[Epoch 118; Iter   399/  823] train: loss: 0.0114963
[Epoch 118; Iter   429/  823] train: loss: 0.0156602
[Epoch 118; Iter   459/  823] train: loss: 0.0026977
[Epoch 118; Iter   489/  823] train: loss: 0.0039200
[Epoch 118; Iter   519/  823] train: loss: 0.0038066
[Epoch 118; Iter   549/  823] train: loss: 0.0221410
[Epoch 118; Iter   579/  823] train: loss: 0.0037267
[Epoch 118; Iter   609/  823] train: loss: 0.0218767
[Epoch 118; Iter   639/  823] train: loss: 0.0025888
[Epoch 118; Iter   669/  823] train: loss: 0.0022750
[Epoch 118; Iter   699/  823] train: loss: 0.0059269
[Epoch 118; Iter   729/  823] train: loss: 0.0112975
[Epoch 118; Iter   759/  823] train: loss: 0.0041849
[Epoch 118; Iter   789/  823] train: loss: 0.0237014
[Epoch 118; Iter   819/  823] train: loss: 0.0008625
[Epoch 118] ogbg-molhiv: 0.741150 val loss: 0.266023
[Epoch 118] ogbg-molhiv: 0.748303 test loss: 0.273869
[Epoch 119; Iter    26/  823] train: loss: 0.0013704
[Epoch 119; Iter    56/  823] train: loss: 0.0247147
[Epoch 119; Iter    86/  823] train: loss: 0.0254005
[Epoch 119; Iter   116/  823] train: loss: 0.0074909
[Epoch 119; Iter   146/  823] train: loss: 0.0304884
[Epoch 119; Iter   176/  823] train: loss: 0.0034317
[Epoch 119; Iter   206/  823] train: loss: 0.0187266
[Epoch 119; Iter   236/  823] train: loss: 0.0056246
[Epoch 119; Iter   266/  823] train: loss: 0.0643567
[Epoch 119; Iter   296/  823] train: loss: 0.0580724
[Epoch 119; Iter   326/  823] train: loss: 0.0030984
[Epoch 119; Iter   356/  823] train: loss: 0.0007838
[Epoch 119; Iter   386/  823] train: loss: 0.0090983
[Epoch 119; Iter   416/  823] train: loss: 0.0019270
[Epoch 119; Iter   446/  823] train: loss: 0.0131369
[Epoch 119; Iter   476/  823] train: loss: 0.0611912
[Epoch 119; Iter   506/  823] train: loss: 0.0128329
[Epoch 119; Iter   536/  823] train: loss: 0.0019331
[Epoch 119; Iter   566/  823] train: loss: 0.0253619
[Epoch 119; Iter   596/  823] train: loss: 0.0055105
[Epoch 119; Iter   626/  823] train: loss: 0.0114462
[Epoch 119; Iter   656/  823] train: loss: 0.0134452
[Epoch 119; Iter   686/  823] train: loss: 0.0290715
[Epoch 119; Iter   716/  823] train: loss: 0.0069231
[Epoch 119; Iter   746/  823] train: loss: 0.0161199
[Epoch 119; Iter   776/  823] train: loss: 0.0049588
[Epoch 119; Iter   806/  823] train: loss: 0.0015561
[Epoch 119] ogbg-molhiv: 0.742607 val loss: 0.273249
[Epoch 119] ogbg-molhiv: 0.748257 test loss: 0.268695
[Epoch 120; Iter    13/  823] train: loss: 0.0027816
[Epoch 120; Iter    43/  823] train: loss: 0.0221214
[Epoch 120; Iter    73/  823] train: loss: 0.0025889
[Epoch 120; Iter   103/  823] train: loss: 0.0155865
[Epoch 120; Iter   133/  823] train: loss: 0.0074720
[Epoch 120; Iter   163/  823] train: loss: 0.0448929
[Epoch 120; Iter   193/  823] train: loss: 0.0047007
[Epoch 120; Iter   223/  823] train: loss: 0.0048043
[Epoch 120; Iter   253/  823] train: loss: 0.0020250
[Epoch 120; Iter   283/  823] train: loss: 0.0017200
[Epoch 120; Iter   313/  823] train: loss: 0.0048849
[Epoch 120; Iter   343/  823] train: loss: 0.0067071
[Epoch 120; Iter   373/  823] train: loss: 0.0058202
[Epoch 120; Iter   403/  823] train: loss: 0.0096357
[Epoch 120; Iter   433/  823] train: loss: 0.0037851
[Epoch 120; Iter   463/  823] train: loss: 0.0177267
[Epoch 120; Iter   493/  823] train: loss: 0.0302564
[Epoch 120; Iter   523/  823] train: loss: 0.0158669
[Epoch 120; Iter   553/  823] train: loss: 0.0010274
[Epoch 120; Iter   583/  823] train: loss: 0.0117304
[Epoch 120; Iter   613/  823] train: loss: 0.0136200
[Epoch 120; Iter   643/  823] train: loss: 0.0012602
[Epoch 120; Iter   673/  823] train: loss: 0.0133052
[Epoch 120; Iter   703/  823] train: loss: 0.0210255
[Epoch 120; Iter   733/  823] train: loss: 0.0467292
[Epoch 120; Iter   763/  823] train: loss: 0.0013592
[Epoch 120; Iter   793/  823] train: loss: 0.0037798
[Epoch 120; Iter   823/  823] train: loss: 0.0865749
[Epoch 120] ogbg-molhiv: 0.747051 val loss: 0.273336
[Epoch 120] ogbg-molhiv: 0.755017 test loss: 0.223366
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 19.
Statistics on  val_best_checkpoint
mean_pred: -3.8706650733947754
std_pred: 6.963168621063232
mean_targets: 0.035501521080732346
std_targets: 0.18505491316318512
prcauc: 0.23234966430059492
rocauc: 0.7532455030054791
ogbg-molhiv: 0.7532455030054791
BCEWithLogitsLoss: 0.32321375848217443
Statistics on  test
mean_pred: -3.684361219406128
std_pred: 12.230270385742188
mean_targets: 0.025650376453995705
std_targets: 0.15809957683086395
prcauc: 0.14233031673127314
rocauc: 0.7471299370552252
ogbg-molhiv: 0.7471299370552252
BCEWithLogitsLoss: 0.5702877379750664
Statistics on  train
mean_pred: -4.032120227813721
std_pred: 6.298065185546875
mean_targets: 0.0380936935544014
std_targets: 0.1914263665676117
prcauc: 0.48046275096611446
rocauc: 0.8874119973968978
ogbg-molhiv: 0.8874119973968978
BCEWithLogitsLoss: 0.18178281083223236
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 109; Iter   744/ 1097] train: loss: 0.0047585
[Epoch 109; Iter   774/ 1097] train: loss: 0.0978710
[Epoch 109; Iter   804/ 1097] train: loss: 0.0727333
[Epoch 109; Iter   834/ 1097] train: loss: 0.0228480
[Epoch 109; Iter   864/ 1097] train: loss: 0.0025684
[Epoch 109; Iter   894/ 1097] train: loss: 0.0130155
[Epoch 109; Iter   924/ 1097] train: loss: 0.0105126
[Epoch 109; Iter   954/ 1097] train: loss: 0.0035277
[Epoch 109; Iter   984/ 1097] train: loss: 0.0032363
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0129040
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0041013
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0029878
[Epoch 109] ogbg-molhiv: 0.765683 val loss: 0.169735
[Epoch 109] ogbg-molhiv: 0.722221 test loss: 0.247586
[Epoch 110; Iter     7/ 1097] train: loss: 0.0037255
[Epoch 110; Iter    37/ 1097] train: loss: 0.0122411
[Epoch 110; Iter    67/ 1097] train: loss: 0.0073818
[Epoch 110; Iter    97/ 1097] train: loss: 0.0951667
[Epoch 110; Iter   127/ 1097] train: loss: 0.1053632
[Epoch 110; Iter   157/ 1097] train: loss: 0.0204275
[Epoch 110; Iter   187/ 1097] train: loss: 0.0258891
[Epoch 110; Iter   217/ 1097] train: loss: 0.0043483
[Epoch 110; Iter   247/ 1097] train: loss: 0.0099558
[Epoch 110; Iter   277/ 1097] train: loss: 0.0115009
[Epoch 110; Iter   307/ 1097] train: loss: 0.0193272
[Epoch 110; Iter   337/ 1097] train: loss: 0.0057051
[Epoch 110; Iter   367/ 1097] train: loss: 0.0071421
[Epoch 110; Iter   397/ 1097] train: loss: 0.0033858
[Epoch 110; Iter   427/ 1097] train: loss: 0.0126102
[Epoch 110; Iter   457/ 1097] train: loss: 0.0119945
[Epoch 110; Iter   487/ 1097] train: loss: 0.0036969
[Epoch 110; Iter   517/ 1097] train: loss: 0.0104374
[Epoch 110; Iter   547/ 1097] train: loss: 0.0066014
[Epoch 110; Iter   577/ 1097] train: loss: 0.0234629
[Epoch 110; Iter   607/ 1097] train: loss: 0.0197703
[Epoch 110; Iter   637/ 1097] train: loss: 0.0387725
[Epoch 110; Iter   667/ 1097] train: loss: 0.0031509
[Epoch 110; Iter   697/ 1097] train: loss: 0.0139648
[Epoch 110; Iter   727/ 1097] train: loss: 0.0015574
[Epoch 110; Iter   757/ 1097] train: loss: 0.0101282
[Epoch 110; Iter   787/ 1097] train: loss: 0.0262568
[Epoch 110; Iter   817/ 1097] train: loss: 0.0046686
[Epoch 110; Iter   847/ 1097] train: loss: 0.0690162
[Epoch 110; Iter   877/ 1097] train: loss: 0.0071397
[Epoch 110; Iter   907/ 1097] train: loss: 0.0083946
[Epoch 110; Iter   937/ 1097] train: loss: 0.0963460
[Epoch 110; Iter   967/ 1097] train: loss: 0.0063647
[Epoch 110; Iter   997/ 1097] train: loss: 0.0105508
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0061276
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0009920
[Epoch 110; Iter  1087/ 1097] train: loss: 0.1299382
[Epoch 110] ogbg-molhiv: 0.772554 val loss: 0.172876
[Epoch 110] ogbg-molhiv: 0.726880 test loss: 0.250729
[Epoch 111; Iter    20/ 1097] train: loss: 0.0058530
[Epoch 111; Iter    50/ 1097] train: loss: 0.0279669
[Epoch 111; Iter    80/ 1097] train: loss: 0.0247351
[Epoch 111; Iter   110/ 1097] train: loss: 0.0407749
[Epoch 111; Iter   140/ 1097] train: loss: 0.0159381
[Epoch 111; Iter   170/ 1097] train: loss: 0.0838470
[Epoch 111; Iter   200/ 1097] train: loss: 0.0013976
[Epoch 111; Iter   230/ 1097] train: loss: 0.0108681
[Epoch 111; Iter   260/ 1097] train: loss: 0.0082923
[Epoch 111; Iter   290/ 1097] train: loss: 0.0341020
[Epoch 111; Iter   320/ 1097] train: loss: 0.0148876
[Epoch 111; Iter   350/ 1097] train: loss: 0.0083876
[Epoch 111; Iter   380/ 1097] train: loss: 0.0149526
[Epoch 111; Iter   410/ 1097] train: loss: 0.1177391
[Epoch 111; Iter   440/ 1097] train: loss: 0.0150533
[Epoch 111; Iter   470/ 1097] train: loss: 0.0256550
[Epoch 111; Iter   500/ 1097] train: loss: 0.0234091
[Epoch 111; Iter   530/ 1097] train: loss: 0.0009355
[Epoch 111; Iter   560/ 1097] train: loss: 0.0014020
[Epoch 111; Iter   590/ 1097] train: loss: 0.0157137
[Epoch 111; Iter   620/ 1097] train: loss: 0.1386289
[Epoch 111; Iter   650/ 1097] train: loss: 0.0042437
[Epoch 111; Iter   680/ 1097] train: loss: 0.0053663
[Epoch 111; Iter   710/ 1097] train: loss: 0.0189533
[Epoch 111; Iter   740/ 1097] train: loss: 0.1823999
[Epoch 111; Iter   770/ 1097] train: loss: 0.0156825
[Epoch 111; Iter   800/ 1097] train: loss: 0.0044039
[Epoch 111; Iter   830/ 1097] train: loss: 0.0047886
[Epoch 111; Iter   860/ 1097] train: loss: 0.1524977
[Epoch 111; Iter   890/ 1097] train: loss: 0.0393629
[Epoch 111; Iter   920/ 1097] train: loss: 0.0054041
[Epoch 111; Iter   950/ 1097] train: loss: 0.0042122
[Epoch 111; Iter   980/ 1097] train: loss: 0.0097025
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0069394
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0080722
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0028503
[Epoch 111] ogbg-molhiv: 0.775983 val loss: 0.167856
[Epoch 111] ogbg-molhiv: 0.730470 test loss: 0.240746
[Epoch 112; Iter     3/ 1097] train: loss: 0.0022873
[Epoch 112; Iter    33/ 1097] train: loss: 0.0142661
[Epoch 112; Iter    63/ 1097] train: loss: 0.0016013
[Epoch 112; Iter    93/ 1097] train: loss: 0.0048647
[Epoch 112; Iter   123/ 1097] train: loss: 0.0446504
[Epoch 112; Iter   153/ 1097] train: loss: 0.0095835
[Epoch 112; Iter   183/ 1097] train: loss: 0.0057582
[Epoch 112; Iter   213/ 1097] train: loss: 0.0325839
[Epoch 112; Iter   243/ 1097] train: loss: 0.0079458
[Epoch 112; Iter   273/ 1097] train: loss: 0.0040887
[Epoch 112; Iter   303/ 1097] train: loss: 0.0085890
[Epoch 112; Iter   333/ 1097] train: loss: 0.0162534
[Epoch 112; Iter   363/ 1097] train: loss: 0.0128486
[Epoch 112; Iter   393/ 1097] train: loss: 0.0016445
[Epoch 112; Iter   423/ 1097] train: loss: 0.0993339
[Epoch 112; Iter   453/ 1097] train: loss: 0.0063136
[Epoch 112; Iter   483/ 1097] train: loss: 0.0057609
[Epoch 112; Iter   513/ 1097] train: loss: 0.0119857
[Epoch 112; Iter   543/ 1097] train: loss: 0.0148457
[Epoch 112; Iter   573/ 1097] train: loss: 0.0094417
[Epoch 112; Iter   603/ 1097] train: loss: 0.0318541
[Epoch 112; Iter   633/ 1097] train: loss: 0.0053817
[Epoch 112; Iter   663/ 1097] train: loss: 0.0693392
[Epoch 112; Iter   693/ 1097] train: loss: 0.0042127
[Epoch 112; Iter   723/ 1097] train: loss: 0.0141603
[Epoch 112; Iter   753/ 1097] train: loss: 0.0253250
[Epoch 112; Iter   783/ 1097] train: loss: 0.0177643
[Epoch 112; Iter   813/ 1097] train: loss: 0.0380392
[Epoch 112; Iter   843/ 1097] train: loss: 0.0061524
[Epoch 112; Iter   873/ 1097] train: loss: 0.0109728
[Epoch 112; Iter   903/ 1097] train: loss: 0.0017466
[Epoch 112; Iter   933/ 1097] train: loss: 0.0605983
[Epoch 112; Iter   963/ 1097] train: loss: 0.0088963
[Epoch 112; Iter   993/ 1097] train: loss: 0.0262080
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0468350
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0047032
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0038540
[Epoch 112] ogbg-molhiv: 0.766819 val loss: 0.185406
[Epoch 112] ogbg-molhiv: 0.719436 test loss: 0.248758
[Epoch 113; Iter    16/ 1097] train: loss: 0.0028333
[Epoch 113; Iter    46/ 1097] train: loss: 0.0107460
[Epoch 113; Iter    76/ 1097] train: loss: 0.0083303
[Epoch 113; Iter   106/ 1097] train: loss: 0.0327595
[Epoch 113; Iter   136/ 1097] train: loss: 0.0156000
[Epoch 113; Iter   166/ 1097] train: loss: 0.0387894
[Epoch 113; Iter   196/ 1097] train: loss: 0.0049035
[Epoch 113; Iter   226/ 1097] train: loss: 0.0049517
[Epoch 113; Iter   256/ 1097] train: loss: 0.0374956
[Epoch 113; Iter   286/ 1097] train: loss: 0.0369504
[Epoch 113; Iter   316/ 1097] train: loss: 0.0027558
[Epoch 113; Iter   346/ 1097] train: loss: 0.0063362
[Epoch 113; Iter   376/ 1097] train: loss: 0.0305275
[Epoch 113; Iter   406/ 1097] train: loss: 0.0013768
[Epoch 113; Iter   436/ 1097] train: loss: 0.0458237
[Epoch 113; Iter   466/ 1097] train: loss: 0.0126473
[Epoch 113; Iter   496/ 1097] train: loss: 0.0049340
[Epoch 113; Iter   526/ 1097] train: loss: 0.0060056
[Epoch 113; Iter   556/ 1097] train: loss: 0.0192332
[Epoch 113; Iter   586/ 1097] train: loss: 0.0227051
[Epoch 113; Iter   616/ 1097] train: loss: 0.0423238
[Epoch 113; Iter   646/ 1097] train: loss: 0.0016797
[Epoch 113; Iter   676/ 1097] train: loss: 0.1010033
[Epoch 113; Iter   706/ 1097] train: loss: 0.0096888
[Epoch 116; Iter   485/  823] train: loss: 0.0099085
[Epoch 116; Iter   515/  823] train: loss: 0.0451161
[Epoch 116; Iter   545/  823] train: loss: 0.0009218
[Epoch 116; Iter   575/  823] train: loss: 0.1698069
[Epoch 116; Iter   605/  823] train: loss: 0.0018667
[Epoch 116; Iter   635/  823] train: loss: 0.0191372
[Epoch 116; Iter   665/  823] train: loss: 0.0002721
[Epoch 116; Iter   695/  823] train: loss: 0.0150591
[Epoch 116; Iter   725/  823] train: loss: 0.0187040
[Epoch 116; Iter   755/  823] train: loss: 0.0528767
[Epoch 116; Iter   785/  823] train: loss: 0.0015082
[Epoch 116; Iter   815/  823] train: loss: 0.0040595
[Epoch 116] ogbg-molhiv: 0.701942 val loss: 0.442316
[Epoch 116] ogbg-molhiv: 0.743836 test loss: 0.245360
[Epoch 117; Iter    22/  823] train: loss: 0.0047751
[Epoch 117; Iter    52/  823] train: loss: 0.0016720
[Epoch 117; Iter    82/  823] train: loss: 0.0092931
[Epoch 117; Iter   112/  823] train: loss: 0.0173169
[Epoch 117; Iter   142/  823] train: loss: 0.0002896
[Epoch 117; Iter   172/  823] train: loss: 0.0010104
[Epoch 117; Iter   202/  823] train: loss: 0.0035479
[Epoch 117; Iter   232/  823] train: loss: 0.0050779
[Epoch 117; Iter   262/  823] train: loss: 0.0027454
[Epoch 117; Iter   292/  823] train: loss: 0.0017064
[Epoch 117; Iter   322/  823] train: loss: 0.0366369
[Epoch 117; Iter   352/  823] train: loss: 0.0853674
[Epoch 117; Iter   382/  823] train: loss: 0.0012355
[Epoch 117; Iter   412/  823] train: loss: 0.0017626
[Epoch 117; Iter   442/  823] train: loss: 0.0005413
[Epoch 117; Iter   472/  823] train: loss: 0.0165504
[Epoch 117; Iter   502/  823] train: loss: 0.0204705
[Epoch 117; Iter   532/  823] train: loss: 0.0072246
[Epoch 117; Iter   562/  823] train: loss: 0.0027400
[Epoch 117; Iter   592/  823] train: loss: 0.0688818
[Epoch 117; Iter   622/  823] train: loss: 0.0004145
[Epoch 117; Iter   652/  823] train: loss: 0.0159203
[Epoch 117; Iter   682/  823] train: loss: 0.0162384
[Epoch 117; Iter   712/  823] train: loss: 0.0151775
[Epoch 117; Iter   742/  823] train: loss: 0.0029007
[Epoch 117; Iter   772/  823] train: loss: 0.0061738
[Epoch 117; Iter   802/  823] train: loss: 0.0142191
[Epoch 117] ogbg-molhiv: 0.697485 val loss: 0.459651
[Epoch 117] ogbg-molhiv: 0.750337 test loss: 0.253268
[Epoch 118; Iter     9/  823] train: loss: 0.0008592
[Epoch 118; Iter    39/  823] train: loss: 0.0052628
[Epoch 118; Iter    69/  823] train: loss: 0.0019734
[Epoch 118; Iter    99/  823] train: loss: 0.0028566
[Epoch 118; Iter   129/  823] train: loss: 0.0014511
[Epoch 118; Iter   159/  823] train: loss: 0.0015379
[Epoch 118; Iter   189/  823] train: loss: 0.0029709
[Epoch 118; Iter   219/  823] train: loss: 0.0009998
[Epoch 118; Iter   249/  823] train: loss: 0.0276922
[Epoch 118; Iter   279/  823] train: loss: 0.0006016
[Epoch 118; Iter   309/  823] train: loss: 0.0062904
[Epoch 118; Iter   339/  823] train: loss: 0.0014804
[Epoch 118; Iter   369/  823] train: loss: 0.0038395
[Epoch 118; Iter   399/  823] train: loss: 0.0016620
[Epoch 118; Iter   429/  823] train: loss: 0.0037318
[Epoch 118; Iter   459/  823] train: loss: 0.0009284
[Epoch 118; Iter   489/  823] train: loss: 0.0042446
[Epoch 118; Iter   519/  823] train: loss: 0.0018425
[Epoch 118; Iter   549/  823] train: loss: 0.0046381
[Epoch 118; Iter   579/  823] train: loss: 0.0194318
[Epoch 118; Iter   609/  823] train: loss: 0.0003530
[Epoch 118; Iter   639/  823] train: loss: 0.0047329
[Epoch 118; Iter   669/  823] train: loss: 0.0016644
[Epoch 118; Iter   699/  823] train: loss: 0.0018011
[Epoch 118; Iter   729/  823] train: loss: 0.0019853
[Epoch 118; Iter   759/  823] train: loss: 0.0107751
[Epoch 118; Iter   789/  823] train: loss: 0.0093886
[Epoch 118; Iter   819/  823] train: loss: 0.0064102
[Epoch 118] ogbg-molhiv: 0.700638 val loss: 0.484288
[Epoch 118] ogbg-molhiv: 0.745773 test loss: 0.251918
[Epoch 119; Iter    26/  823] train: loss: 0.0006923
[Epoch 119; Iter    56/  823] train: loss: 0.0003442
[Epoch 119; Iter    86/  823] train: loss: 0.0029597
[Epoch 119; Iter   116/  823] train: loss: 0.0058968
[Epoch 119; Iter   146/  823] train: loss: 0.0219567
[Epoch 119; Iter   176/  823] train: loss: 0.0187951
[Epoch 119; Iter   206/  823] train: loss: 0.0002002
[Epoch 119; Iter   236/  823] train: loss: 0.0008657
[Epoch 119; Iter   266/  823] train: loss: 0.0002636
[Epoch 119; Iter   296/  823] train: loss: 0.0015303
[Epoch 119; Iter   326/  823] train: loss: 0.0012499
[Epoch 119; Iter   356/  823] train: loss: 0.0013286
[Epoch 119; Iter   386/  823] train: loss: 0.0049609
[Epoch 119; Iter   416/  823] train: loss: 0.0033839
[Epoch 119; Iter   446/  823] train: loss: 0.0184195
[Epoch 119; Iter   476/  823] train: loss: 0.0025830
[Epoch 119; Iter   506/  823] train: loss: 0.0054660
[Epoch 119; Iter   536/  823] train: loss: 0.0010969
[Epoch 119; Iter   566/  823] train: loss: 0.0060189
[Epoch 119; Iter   596/  823] train: loss: 0.0035782
[Epoch 119; Iter   626/  823] train: loss: 0.0116836
[Epoch 119; Iter   656/  823] train: loss: 0.0043234
[Epoch 119; Iter   686/  823] train: loss: 0.0197189
[Epoch 119; Iter   716/  823] train: loss: 0.0027319
[Epoch 119; Iter   746/  823] train: loss: 0.0008478
[Epoch 119; Iter   776/  823] train: loss: 0.0336531
[Epoch 119; Iter   806/  823] train: loss: 0.0122806
[Epoch 119] ogbg-molhiv: 0.701774 val loss: 0.460283
[Epoch 119] ogbg-molhiv: 0.734618 test loss: 0.249724
[Epoch 120; Iter    13/  823] train: loss: 0.0582590
[Epoch 120; Iter    43/  823] train: loss: 0.0382951
[Epoch 120; Iter    73/  823] train: loss: 0.0261017
[Epoch 120; Iter   103/  823] train: loss: 0.0028553
[Epoch 120; Iter   133/  823] train: loss: 0.0010511
[Epoch 120; Iter   163/  823] train: loss: 0.0028763
[Epoch 120; Iter   193/  823] train: loss: 0.0016441
[Epoch 120; Iter   223/  823] train: loss: 0.0004836
[Epoch 120; Iter   253/  823] train: loss: 0.0201245
[Epoch 120; Iter   283/  823] train: loss: 0.0011918
[Epoch 120; Iter   313/  823] train: loss: 0.0180795
[Epoch 120; Iter   343/  823] train: loss: 0.0023578
[Epoch 120; Iter   373/  823] train: loss: 0.0023632
[Epoch 120; Iter   403/  823] train: loss: 0.0057658
[Epoch 120; Iter   433/  823] train: loss: 0.0545670
[Epoch 120; Iter   463/  823] train: loss: 0.0032911
[Epoch 120; Iter   493/  823] train: loss: 0.0205032
[Epoch 120; Iter   523/  823] train: loss: 0.0068722
[Epoch 120; Iter   553/  823] train: loss: 0.0141680
[Epoch 120; Iter   583/  823] train: loss: 0.0154283
[Epoch 120; Iter   613/  823] train: loss: 0.0113805
[Epoch 120; Iter   643/  823] train: loss: 0.0044649
[Epoch 120; Iter   673/  823] train: loss: 0.0038583
[Epoch 120; Iter   703/  823] train: loss: 0.0085158
[Epoch 120; Iter   733/  823] train: loss: 0.0016669
[Epoch 120; Iter   763/  823] train: loss: 0.0237253
[Epoch 120; Iter   793/  823] train: loss: 0.0013980
[Epoch 120; Iter   823/  823] train: loss: 0.0015473
[Epoch 120] ogbg-molhiv: 0.701463 val loss: 0.485134
[Epoch 120] ogbg-molhiv: 0.744769 test loss: 0.244188
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 17.
Statistics on  val_best_checkpoint
mean_pred: -4.014973163604736
std_pred: 3.1828396320343018
mean_targets: 0.035501521080732346
std_targets: 0.18505491316318512
prcauc: 0.25612028577071233
rocauc: 0.7405643842523602
ogbg-molhiv: 0.7405643842523602
BCEWithLogitsLoss: 0.13756718708371574
Statistics on  test
mean_pred: -4.127313137054443
std_pred: 4.430205821990967
mean_targets: 0.025650376453995705
std_targets: 0.15809957683086395
prcauc: 0.2808030706030694
rocauc: 0.7577193827923354
ogbg-molhiv: 0.7577193827923354
BCEWithLogitsLoss: 0.09913743331351063
Statistics on  train
mean_pred: -4.2386860847473145
std_pred: 2.5239710807800293
mean_targets: 0.0380936935544014
std_targets: 0.1914263665676117
prcauc: 0.5247857509343643
rocauc: 0.8996684495765477
ogbg-molhiv: 0.8996684495765477
BCEWithLogitsLoss: 0.1065266279397331
[Epoch 109; Iter   744/ 1097] train: loss: 0.0600171
[Epoch 109; Iter   774/ 1097] train: loss: 0.0029734
[Epoch 109; Iter   804/ 1097] train: loss: 0.0255984
[Epoch 109; Iter   834/ 1097] train: loss: 0.0006507
[Epoch 109; Iter   864/ 1097] train: loss: 0.0019211
[Epoch 109; Iter   894/ 1097] train: loss: 0.0064280
[Epoch 109; Iter   924/ 1097] train: loss: 0.0028941
[Epoch 109; Iter   954/ 1097] train: loss: 0.0026192
[Epoch 109; Iter   984/ 1097] train: loss: 0.0413094
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0019631
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0970744
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0048443
[Epoch 109] ogbg-molhiv: 0.747900 val loss: 0.367635
[Epoch 109] ogbg-molhiv: 0.731544 test loss: 0.951682
[Epoch 110; Iter     7/ 1097] train: loss: 0.0050009
[Epoch 110; Iter    37/ 1097] train: loss: 0.0137216
[Epoch 110; Iter    67/ 1097] train: loss: 0.0070678
[Epoch 110; Iter    97/ 1097] train: loss: 0.0053862
[Epoch 110; Iter   127/ 1097] train: loss: 0.0325819
[Epoch 110; Iter   157/ 1097] train: loss: 0.0734131
[Epoch 110; Iter   187/ 1097] train: loss: 0.0049845
[Epoch 110; Iter   217/ 1097] train: loss: 0.0483802
[Epoch 110; Iter   247/ 1097] train: loss: 0.0059321
[Epoch 110; Iter   277/ 1097] train: loss: 0.0102530
[Epoch 110; Iter   307/ 1097] train: loss: 0.0125325
[Epoch 110; Iter   337/ 1097] train: loss: 0.0131742
[Epoch 110; Iter   367/ 1097] train: loss: 0.0010422
[Epoch 110; Iter   397/ 1097] train: loss: 0.0070172
[Epoch 110; Iter   427/ 1097] train: loss: 0.0095520
[Epoch 110; Iter   457/ 1097] train: loss: 0.0043213
[Epoch 110; Iter   487/ 1097] train: loss: 0.0116358
[Epoch 110; Iter   517/ 1097] train: loss: 0.0630349
[Epoch 110; Iter   547/ 1097] train: loss: 0.0037350
[Epoch 110; Iter   577/ 1097] train: loss: 0.0032740
[Epoch 110; Iter   607/ 1097] train: loss: 0.0010012
[Epoch 110; Iter   637/ 1097] train: loss: 0.0019909
[Epoch 110; Iter   667/ 1097] train: loss: 0.0057872
[Epoch 110; Iter   697/ 1097] train: loss: 0.0021883
[Epoch 110; Iter   727/ 1097] train: loss: 0.0028367
[Epoch 110; Iter   757/ 1097] train: loss: 0.0038516
[Epoch 110; Iter   787/ 1097] train: loss: 0.0097555
[Epoch 110; Iter   817/ 1097] train: loss: 0.0036546
[Epoch 110; Iter   847/ 1097] train: loss: 0.0048606
[Epoch 110; Iter   877/ 1097] train: loss: 0.0884309
[Epoch 110; Iter   907/ 1097] train: loss: 0.0049142
[Epoch 110; Iter   937/ 1097] train: loss: 0.0182629
[Epoch 110; Iter   967/ 1097] train: loss: 0.0019985
[Epoch 110; Iter   997/ 1097] train: loss: 0.0077558
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0191143
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0012878
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0022431
[Epoch 110] ogbg-molhiv: 0.759192 val loss: 0.185435
[Epoch 110] ogbg-molhiv: 0.729821 test loss: 0.391825
[Epoch 111; Iter    20/ 1097] train: loss: 0.0013824
[Epoch 111; Iter    50/ 1097] train: loss: 0.0511476
[Epoch 111; Iter    80/ 1097] train: loss: 0.0044307
[Epoch 111; Iter   110/ 1097] train: loss: 0.0627343
[Epoch 111; Iter   140/ 1097] train: loss: 0.0042321
[Epoch 111; Iter   170/ 1097] train: loss: 0.0083804
[Epoch 111; Iter   200/ 1097] train: loss: 0.0025309
[Epoch 111; Iter   230/ 1097] train: loss: 0.0504863
[Epoch 111; Iter   260/ 1097] train: loss: 0.0985054
[Epoch 111; Iter   290/ 1097] train: loss: 0.0232226
[Epoch 111; Iter   320/ 1097] train: loss: 0.1263913
[Epoch 111; Iter   350/ 1097] train: loss: 0.0011921
[Epoch 111; Iter   380/ 1097] train: loss: 0.0170102
[Epoch 111; Iter   410/ 1097] train: loss: 0.0092939
[Epoch 111; Iter   440/ 1097] train: loss: 0.0049873
[Epoch 111; Iter   470/ 1097] train: loss: 0.0210551
[Epoch 111; Iter   500/ 1097] train: loss: 0.0196915
[Epoch 111; Iter   530/ 1097] train: loss: 0.0021886
[Epoch 111; Iter   560/ 1097] train: loss: 0.0090334
[Epoch 111; Iter   590/ 1097] train: loss: 0.0023673
[Epoch 111; Iter   620/ 1097] train: loss: 0.0002582
[Epoch 111; Iter   650/ 1097] train: loss: 0.0010233
[Epoch 111; Iter   680/ 1097] train: loss: 0.0094523
[Epoch 111; Iter   710/ 1097] train: loss: 0.0106162
[Epoch 111; Iter   740/ 1097] train: loss: 0.0132849
[Epoch 111; Iter   770/ 1097] train: loss: 0.0022318
[Epoch 111; Iter   800/ 1097] train: loss: 0.1264752
[Epoch 111; Iter   830/ 1097] train: loss: 0.0028020
[Epoch 111; Iter   860/ 1097] train: loss: 0.0187164
[Epoch 111; Iter   890/ 1097] train: loss: 0.0118806
[Epoch 111; Iter   920/ 1097] train: loss: 0.0007906
[Epoch 111; Iter   950/ 1097] train: loss: 0.0129888
[Epoch 111; Iter   980/ 1097] train: loss: 0.0074982
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0396451
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0010125
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0498966
[Epoch 111] ogbg-molhiv: 0.755404 val loss: 0.156815
[Epoch 111] ogbg-molhiv: 0.733720 test loss: 0.278313
[Epoch 112; Iter     3/ 1097] train: loss: 0.0037030
[Epoch 112; Iter    33/ 1097] train: loss: 0.1526866
[Epoch 112; Iter    63/ 1097] train: loss: 0.0097793
[Epoch 112; Iter    93/ 1097] train: loss: 0.0148785
[Epoch 112; Iter   123/ 1097] train: loss: 0.0093266
[Epoch 112; Iter   153/ 1097] train: loss: 0.0272458
[Epoch 112; Iter   183/ 1097] train: loss: 0.0125239
[Epoch 112; Iter   213/ 1097] train: loss: 0.0024148
[Epoch 112; Iter   243/ 1097] train: loss: 0.0060789
[Epoch 112; Iter   273/ 1097] train: loss: 0.0045940
[Epoch 112; Iter   303/ 1097] train: loss: 0.0116741
[Epoch 112; Iter   333/ 1097] train: loss: 0.0011256
[Epoch 112; Iter   363/ 1097] train: loss: 0.0047930
[Epoch 112; Iter   393/ 1097] train: loss: 0.0048188
[Epoch 112; Iter   423/ 1097] train: loss: 0.0321656
[Epoch 112; Iter   453/ 1097] train: loss: 0.0360605
[Epoch 112; Iter   483/ 1097] train: loss: 0.0004107
[Epoch 112; Iter   513/ 1097] train: loss: 0.0108703
[Epoch 112; Iter   543/ 1097] train: loss: 0.0770188
[Epoch 112; Iter   573/ 1097] train: loss: 0.0039945
[Epoch 112; Iter   603/ 1097] train: loss: 0.0045830
[Epoch 112; Iter   633/ 1097] train: loss: 0.0087107
[Epoch 112; Iter   663/ 1097] train: loss: 0.0210083
[Epoch 112; Iter   693/ 1097] train: loss: 0.0437538
[Epoch 112; Iter   723/ 1097] train: loss: 0.0019137
[Epoch 112; Iter   753/ 1097] train: loss: 0.0695958
[Epoch 112; Iter   783/ 1097] train: loss: 0.0036002
[Epoch 112; Iter   813/ 1097] train: loss: 0.0468748
[Epoch 112; Iter   843/ 1097] train: loss: 0.0042943
[Epoch 112; Iter   873/ 1097] train: loss: 0.0037425
[Epoch 112; Iter   903/ 1097] train: loss: 0.0103887
[Epoch 112; Iter   933/ 1097] train: loss: 0.0014794
[Epoch 112; Iter   963/ 1097] train: loss: 0.0003718
[Epoch 112; Iter   993/ 1097] train: loss: 0.0239385
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0207364
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0049881
[Epoch 112; Iter  1083/ 1097] train: loss: 0.0025091
[Epoch 112] ogbg-molhiv: 0.747257 val loss: 0.280071
[Epoch 112] ogbg-molhiv: 0.732274 test loss: 0.943261
[Epoch 113; Iter    16/ 1097] train: loss: 0.0015225
[Epoch 113; Iter    46/ 1097] train: loss: 0.0099139
[Epoch 113; Iter    76/ 1097] train: loss: 0.0237610
[Epoch 113; Iter   106/ 1097] train: loss: 0.0034768
[Epoch 113; Iter   136/ 1097] train: loss: 0.0020628
[Epoch 113; Iter   166/ 1097] train: loss: 0.0008981
[Epoch 113; Iter   196/ 1097] train: loss: 0.0729738
[Epoch 113; Iter   226/ 1097] train: loss: 0.0009183
[Epoch 113; Iter   256/ 1097] train: loss: 0.0057312
[Epoch 113; Iter   286/ 1097] train: loss: 0.0803517
[Epoch 113; Iter   316/ 1097] train: loss: 0.0032372
[Epoch 113; Iter   346/ 1097] train: loss: 0.0099373
[Epoch 113; Iter   376/ 1097] train: loss: 0.0103462
[Epoch 113; Iter   406/ 1097] train: loss: 0.0013258
[Epoch 113; Iter   436/ 1097] train: loss: 0.0043790
[Epoch 113; Iter   466/ 1097] train: loss: 0.0677745
[Epoch 113; Iter   496/ 1097] train: loss: 0.0021529
[Epoch 113; Iter   526/ 1097] train: loss: 0.0036715
[Epoch 113; Iter   556/ 1097] train: loss: 0.0076692
[Epoch 113; Iter   586/ 1097] train: loss: 0.0101215
[Epoch 113; Iter   616/ 1097] train: loss: 0.0296702
[Epoch 113; Iter   646/ 1097] train: loss: 0.0072981
[Epoch 113; Iter   676/ 1097] train: loss: 0.0062686
[Epoch 113; Iter   706/ 1097] train: loss: 0.0030944
[Epoch 116; Iter   485/  823] train: loss: 0.0063633
[Epoch 116; Iter   515/  823] train: loss: 0.0440019
[Epoch 116; Iter   545/  823] train: loss: 0.0113048
[Epoch 116; Iter   575/  823] train: loss: 0.0197406
[Epoch 116; Iter   605/  823] train: loss: 0.0214051
[Epoch 116; Iter   635/  823] train: loss: 0.0009226
[Epoch 116; Iter   665/  823] train: loss: 0.0007238
[Epoch 116; Iter   695/  823] train: loss: 0.0022368
[Epoch 116; Iter   725/  823] train: loss: 0.0024338
[Epoch 116; Iter   755/  823] train: loss: 0.0011955
[Epoch 116; Iter   785/  823] train: loss: 0.0005650
[Epoch 116; Iter   815/  823] train: loss: 0.0005947
[Epoch 116] ogbg-molhiv: 0.736689 val loss: 0.304202
[Epoch 116] ogbg-molhiv: 0.759690 test loss: 0.220636
[Epoch 117; Iter    22/  823] train: loss: 0.0545635
[Epoch 117; Iter    52/  823] train: loss: 0.0072008
[Epoch 117; Iter    82/  823] train: loss: 0.0008654
[Epoch 117; Iter   112/  823] train: loss: 0.0023634
[Epoch 117; Iter   142/  823] train: loss: 0.0106716
[Epoch 117; Iter   172/  823] train: loss: 0.0007317
[Epoch 117; Iter   202/  823] train: loss: 0.0047480
[Epoch 117; Iter   232/  823] train: loss: 0.0026448
[Epoch 117; Iter   262/  823] train: loss: 0.0247975
[Epoch 117; Iter   292/  823] train: loss: 0.0008047
[Epoch 117; Iter   322/  823] train: loss: 0.1113590
[Epoch 117; Iter   352/  823] train: loss: 0.0008946
[Epoch 117; Iter   382/  823] train: loss: 0.0013010
[Epoch 117; Iter   412/  823] train: loss: 0.0090341
[Epoch 117; Iter   442/  823] train: loss: 0.0005578
[Epoch 117; Iter   472/  823] train: loss: 0.0024324
[Epoch 117; Iter   502/  823] train: loss: 0.0038672
[Epoch 117; Iter   532/  823] train: loss: 0.0003482
[Epoch 117; Iter   562/  823] train: loss: 0.0003209
[Epoch 117; Iter   592/  823] train: loss: 0.0021339
[Epoch 117; Iter   622/  823] train: loss: 0.0018818
[Epoch 117; Iter   652/  823] train: loss: 0.0009868
[Epoch 117; Iter   682/  823] train: loss: 0.0058536
[Epoch 117; Iter   712/  823] train: loss: 0.0019622
[Epoch 117; Iter   742/  823] train: loss: 0.0050434
[Epoch 117; Iter   772/  823] train: loss: 0.0015046
[Epoch 117; Iter   802/  823] train: loss: 0.0055208
[Epoch 117] ogbg-molhiv: 0.735529 val loss: 0.428061
[Epoch 117] ogbg-molhiv: 0.754183 test loss: 0.406028
[Epoch 118; Iter     9/  823] train: loss: 0.0002428
[Epoch 118; Iter    39/  823] train: loss: 0.0178325
[Epoch 118; Iter    69/  823] train: loss: 0.0772410
[Epoch 118; Iter    99/  823] train: loss: 0.0045539
[Epoch 118; Iter   129/  823] train: loss: 0.0025561
[Epoch 118; Iter   159/  823] train: loss: 0.0229691
[Epoch 118; Iter   189/  823] train: loss: 0.0126755
[Epoch 118; Iter   219/  823] train: loss: 0.0383657
[Epoch 118; Iter   249/  823] train: loss: 0.0118007
[Epoch 118; Iter   279/  823] train: loss: 0.0098321
[Epoch 118; Iter   309/  823] train: loss: 0.0009906
[Epoch 118; Iter   339/  823] train: loss: 0.0037861
[Epoch 118; Iter   369/  823] train: loss: 0.0034749
[Epoch 118; Iter   399/  823] train: loss: 0.0015930
[Epoch 118; Iter   429/  823] train: loss: 0.0035431
[Epoch 118; Iter   459/  823] train: loss: 0.0004839
[Epoch 118; Iter   489/  823] train: loss: 0.0007484
[Epoch 118; Iter   519/  823] train: loss: 0.0020752
[Epoch 118; Iter   549/  823] train: loss: 0.0027395
[Epoch 118; Iter   579/  823] train: loss: 0.0023396
[Epoch 118; Iter   609/  823] train: loss: 0.0031382
[Epoch 118; Iter   639/  823] train: loss: 0.0007485
[Epoch 118; Iter   669/  823] train: loss: 0.0002976
[Epoch 118; Iter   699/  823] train: loss: 0.0174916
[Epoch 118; Iter   729/  823] train: loss: 0.0000536
[Epoch 118; Iter   759/  823] train: loss: 0.0007000
[Epoch 118; Iter   789/  823] train: loss: 0.0018363
[Epoch 118; Iter   819/  823] train: loss: 0.0088472
[Epoch 118] ogbg-molhiv: 0.733906 val loss: 0.308565
[Epoch 118] ogbg-molhiv: 0.752918 test loss: 0.222437
[Epoch 119; Iter    26/  823] train: loss: 0.0014550
[Epoch 119; Iter    56/  823] train: loss: 0.0001750
[Epoch 119; Iter    86/  823] train: loss: 0.0003772
[Epoch 119; Iter   116/  823] train: loss: 0.0002022
[Epoch 119; Iter   146/  823] train: loss: 0.0052042
[Epoch 119; Iter   176/  823] train: loss: 0.0005580
[Epoch 119; Iter   206/  823] train: loss: 0.0017196
[Epoch 119; Iter   236/  823] train: loss: 0.0038998
[Epoch 119; Iter   266/  823] train: loss: 0.0106799
[Epoch 119; Iter   296/  823] train: loss: 0.0009941
[Epoch 119; Iter   326/  823] train: loss: 0.0196193
[Epoch 119; Iter   356/  823] train: loss: 0.0016033
[Epoch 119; Iter   386/  823] train: loss: 0.0258311
[Epoch 119; Iter   416/  823] train: loss: 0.1568814
[Epoch 119; Iter   446/  823] train: loss: 0.0003368
[Epoch 119; Iter   476/  823] train: loss: 0.0086230
[Epoch 119; Iter   506/  823] train: loss: 0.0090492
[Epoch 119; Iter   536/  823] train: loss: 0.0015234
[Epoch 119; Iter   566/  823] train: loss: 0.0040923
[Epoch 119; Iter   596/  823] train: loss: 0.0018241
[Epoch 119; Iter   626/  823] train: loss: 0.0000511
[Epoch 119; Iter   656/  823] train: loss: 0.0049949
[Epoch 119; Iter   686/  823] train: loss: 0.0050605
[Epoch 119; Iter   716/  823] train: loss: 0.0013388
[Epoch 119; Iter   746/  823] train: loss: 0.0010404
[Epoch 119; Iter   776/  823] train: loss: 0.0045772
[Epoch 119; Iter   806/  823] train: loss: 0.0004456
[Epoch 119] ogbg-molhiv: 0.739257 val loss: 0.345978
[Epoch 119] ogbg-molhiv: 0.755059 test loss: 0.282767
[Epoch 120; Iter    13/  823] train: loss: 0.0065254
[Epoch 120; Iter    43/  823] train: loss: 0.0039277
[Epoch 120; Iter    73/  823] train: loss: 0.0002345
[Epoch 120; Iter   103/  823] train: loss: 0.0032690
[Epoch 120; Iter   133/  823] train: loss: 0.0009710
[Epoch 120; Iter   163/  823] train: loss: 0.0050607
[Epoch 120; Iter   193/  823] train: loss: 0.0024456
[Epoch 120; Iter   223/  823] train: loss: 0.0051744
[Epoch 120; Iter   253/  823] train: loss: 0.0005226
[Epoch 120; Iter   283/  823] train: loss: 0.0012188
[Epoch 120; Iter   313/  823] train: loss: 0.0020108
[Epoch 120; Iter   343/  823] train: loss: 0.0065559
[Epoch 120; Iter   373/  823] train: loss: 0.0008832
[Epoch 120; Iter   403/  823] train: loss: 0.0127915
[Epoch 120; Iter   433/  823] train: loss: 0.0394432
[Epoch 120; Iter   463/  823] train: loss: 0.0040863
[Epoch 120; Iter   493/  823] train: loss: 0.0021011
[Epoch 120; Iter   523/  823] train: loss: 0.0008993
[Epoch 120; Iter   553/  823] train: loss: 0.0024556
[Epoch 120; Iter   583/  823] train: loss: 0.0022358
[Epoch 120; Iter   613/  823] train: loss: 0.0014779
[Epoch 120; Iter   643/  823] train: loss: 0.0002293
[Epoch 120; Iter   673/  823] train: loss: 0.0002553
[Epoch 120; Iter   703/  823] train: loss: 0.0048593
[Epoch 120; Iter   733/  823] train: loss: 0.0335251
[Epoch 120; Iter   763/  823] train: loss: 0.0018056
[Epoch 120; Iter   793/  823] train: loss: 0.0074801
[Epoch 120; Iter   823/  823] train: loss: 0.0091365
[Epoch 120] ogbg-molhiv: 0.735508 val loss: 0.320569
[Epoch 120] ogbg-molhiv: 0.755214 test loss: 0.237656
[Epoch 121; Iter    30/  823] train: loss: 0.0015177
[Epoch 121; Iter    60/  823] train: loss: 0.0001755
[Epoch 121; Iter    90/  823] train: loss: 0.0002400
[Epoch 121; Iter   120/  823] train: loss: 0.0069282
[Epoch 121; Iter   150/  823] train: loss: 0.0006547
[Epoch 121; Iter   180/  823] train: loss: 0.0006272
[Epoch 121; Iter   210/  823] train: loss: 0.0012346
[Epoch 121; Iter   240/  823] train: loss: 0.0001492
[Epoch 121; Iter   270/  823] train: loss: 0.0761526
[Epoch 121; Iter   300/  823] train: loss: 0.0011641
[Epoch 121; Iter   330/  823] train: loss: 0.0140224
[Epoch 121; Iter   360/  823] train: loss: 0.0056418
[Epoch 121; Iter   390/  823] train: loss: 0.0002019
[Epoch 121; Iter   420/  823] train: loss: 0.0012465
[Epoch 121; Iter   450/  823] train: loss: 0.0131552
[Epoch 121; Iter   480/  823] train: loss: 0.0025076
[Epoch 121; Iter   510/  823] train: loss: 0.0009690
[Epoch 121; Iter   540/  823] train: loss: 0.0000386
[Epoch 121; Iter   570/  823] train: loss: 0.0005938
[Epoch 121; Iter   600/  823] train: loss: 0.0017091
[Epoch 121; Iter   630/  823] train: loss: 0.0019519
[Epoch 121; Iter   660/  823] train: loss: 0.0071879
[Epoch 114; Iter   930/  960] train: loss: 0.0019625
[Epoch 114; Iter   960/  960] train: loss: 0.0004610
[Epoch 114] ogbg-molhiv: 0.717064 val loss: 0.358665
[Epoch 114] ogbg-molhiv: 0.754828 test loss: 0.607685
[Epoch 115; Iter    30/  960] train: loss: 0.0009975
[Epoch 115; Iter    60/  960] train: loss: 0.0260491
[Epoch 115; Iter    90/  960] train: loss: 0.0017690
[Epoch 115; Iter   120/  960] train: loss: 0.0001970
[Epoch 115; Iter   150/  960] train: loss: 0.0037253
[Epoch 115; Iter   180/  960] train: loss: 0.0008449
[Epoch 115; Iter   210/  960] train: loss: 0.0011342
[Epoch 115; Iter   240/  960] train: loss: 0.0359171
[Epoch 115; Iter   270/  960] train: loss: 0.0093066
[Epoch 115; Iter   300/  960] train: loss: 0.0497403
[Epoch 115; Iter   330/  960] train: loss: 0.0038970
[Epoch 115; Iter   360/  960] train: loss: 0.0008547
[Epoch 115; Iter   390/  960] train: loss: 0.0058396
[Epoch 115; Iter   420/  960] train: loss: 0.0032541
[Epoch 115; Iter   450/  960] train: loss: 0.0006170
[Epoch 115; Iter   480/  960] train: loss: 0.0332441
[Epoch 115; Iter   510/  960] train: loss: 0.0018947
[Epoch 115; Iter   540/  960] train: loss: 0.0001291
[Epoch 115; Iter   570/  960] train: loss: 0.0551328
[Epoch 115; Iter   600/  960] train: loss: 0.0009200
[Epoch 115; Iter   630/  960] train: loss: 0.0292310
[Epoch 115; Iter   660/  960] train: loss: 0.0043497
[Epoch 115; Iter   690/  960] train: loss: 0.0088282
[Epoch 115; Iter   720/  960] train: loss: 0.0125013
[Epoch 115; Iter   750/  960] train: loss: 0.0153040
[Epoch 115; Iter   780/  960] train: loss: 0.0189349
[Epoch 115; Iter   810/  960] train: loss: 0.0058216
[Epoch 115; Iter   840/  960] train: loss: 0.0090000
[Epoch 115; Iter   870/  960] train: loss: 0.0064720
[Epoch 115; Iter   900/  960] train: loss: 0.0383759
[Epoch 115; Iter   930/  960] train: loss: 0.0008433
[Epoch 115; Iter   960/  960] train: loss: 0.0000840
[Epoch 115] ogbg-molhiv: 0.716877 val loss: 0.310075
[Epoch 115] ogbg-molhiv: 0.751920 test loss: 0.282215
[Epoch 116; Iter    30/  960] train: loss: 0.0058752
[Epoch 116; Iter    60/  960] train: loss: 0.0334150
[Epoch 116; Iter    90/  960] train: loss: 0.0073389
[Epoch 116; Iter   120/  960] train: loss: 0.0131698
[Epoch 116; Iter   150/  960] train: loss: 0.0078065
[Epoch 116; Iter   180/  960] train: loss: 0.0011468
[Epoch 116; Iter   210/  960] train: loss: 0.0017399
[Epoch 116; Iter   240/  960] train: loss: 0.0010830
[Epoch 116; Iter   270/  960] train: loss: 0.0048332
[Epoch 116; Iter   300/  960] train: loss: 0.0266478
[Epoch 116; Iter   330/  960] train: loss: 0.0012447
[Epoch 116; Iter   360/  960] train: loss: 0.0242263
[Epoch 116; Iter   390/  960] train: loss: 0.0086443
[Epoch 116; Iter   420/  960] train: loss: 0.0048357
[Epoch 116; Iter   450/  960] train: loss: 0.0057454
[Epoch 116; Iter   480/  960] train: loss: 0.0002342
[Epoch 116; Iter   510/  960] train: loss: 0.0036106
[Epoch 116; Iter   540/  960] train: loss: 0.0026643
[Epoch 116; Iter   570/  960] train: loss: 0.0377099
[Epoch 116; Iter   600/  960] train: loss: 0.0205916
[Epoch 116; Iter   630/  960] train: loss: 0.0024520
[Epoch 116; Iter   660/  960] train: loss: 0.0245173
[Epoch 116; Iter   690/  960] train: loss: 0.0010099
[Epoch 116; Iter   720/  960] train: loss: 0.0993395
[Epoch 116; Iter   750/  960] train: loss: 0.0054411
[Epoch 116; Iter   780/  960] train: loss: 0.0073943
[Epoch 116; Iter   810/  960] train: loss: 0.0609084
[Epoch 116; Iter   840/  960] train: loss: 0.0200769
[Epoch 116; Iter   870/  960] train: loss: 0.0003158
[Epoch 116; Iter   900/  960] train: loss: 0.0948712
[Epoch 116; Iter   930/  960] train: loss: 0.0008177
[Epoch 116; Iter   960/  960] train: loss: 0.0003692
[Epoch 116] ogbg-molhiv: 0.721231 val loss: 0.421264
[Epoch 116] ogbg-molhiv: 0.753701 test loss: 0.730181
[Epoch 117; Iter    30/  960] train: loss: 0.0028798
[Epoch 117; Iter    60/  960] train: loss: 0.0102273
[Epoch 117; Iter    90/  960] train: loss: 0.0102894
[Epoch 117; Iter   120/  960] train: loss: 0.0004053
[Epoch 117; Iter   150/  960] train: loss: 0.0620207
[Epoch 117; Iter   180/  960] train: loss: 0.0118077
[Epoch 117; Iter   210/  960] train: loss: 0.0005628
[Epoch 117; Iter   240/  960] train: loss: 0.0160871
[Epoch 117; Iter   270/  960] train: loss: 0.0028054
[Epoch 117; Iter   300/  960] train: loss: 0.0079899
[Epoch 117; Iter   330/  960] train: loss: 0.0049599
[Epoch 117; Iter   360/  960] train: loss: 0.0049334
[Epoch 117; Iter   390/  960] train: loss: 0.0223242
[Epoch 117; Iter   420/  960] train: loss: 0.0035240
[Epoch 117; Iter   450/  960] train: loss: 0.1413027
[Epoch 117; Iter   480/  960] train: loss: 0.0001926
[Epoch 117; Iter   510/  960] train: loss: 0.1068843
[Epoch 117; Iter   540/  960] train: loss: 0.0019381
[Epoch 117; Iter   570/  960] train: loss: 0.0014186
[Epoch 117; Iter   600/  960] train: loss: 0.0883942
[Epoch 117; Iter   630/  960] train: loss: 0.0305487
[Epoch 117; Iter   660/  960] train: loss: 0.0025542
[Epoch 117; Iter   690/  960] train: loss: 0.0355273
[Epoch 117; Iter   720/  960] train: loss: 0.0103521
[Epoch 117; Iter   750/  960] train: loss: 0.1206578
[Epoch 117; Iter   780/  960] train: loss: 0.0420585
[Epoch 117; Iter   810/  960] train: loss: 0.0007617
[Epoch 117; Iter   840/  960] train: loss: 0.0061905
[Epoch 117; Iter   870/  960] train: loss: 0.0002062
[Epoch 117; Iter   900/  960] train: loss: 0.0111762
[Epoch 117; Iter   930/  960] train: loss: 0.0025731
[Epoch 117; Iter   960/  960] train: loss: 0.0319241
[Epoch 117] ogbg-molhiv: 0.721947 val loss: 0.396792
[Epoch 117] ogbg-molhiv: 0.757908 test loss: 0.705141
[Epoch 118; Iter    30/  960] train: loss: 0.0155436
[Epoch 118; Iter    60/  960] train: loss: 0.0078252
[Epoch 118; Iter    90/  960] train: loss: 0.0021577
[Epoch 118; Iter   120/  960] train: loss: 0.0549666
[Epoch 118; Iter   150/  960] train: loss: 0.1013136
[Epoch 118; Iter   180/  960] train: loss: 0.0033731
[Epoch 118; Iter   210/  960] train: loss: 0.0005706
[Epoch 118; Iter   240/  960] train: loss: 0.0178888
[Epoch 118; Iter   270/  960] train: loss: 0.0032489
[Epoch 118; Iter   300/  960] train: loss: 0.0090529
[Epoch 118; Iter   330/  960] train: loss: 0.0020146
[Epoch 118; Iter   360/  960] train: loss: 0.0004124
[Epoch 118; Iter   390/  960] train: loss: 0.0382098
[Epoch 118; Iter   420/  960] train: loss: 0.0204446
[Epoch 118; Iter   450/  960] train: loss: 0.0016579
[Epoch 118; Iter   480/  960] train: loss: 0.0002304
[Epoch 118; Iter   510/  960] train: loss: 0.0015662
[Epoch 118; Iter   540/  960] train: loss: 0.0002964
[Epoch 118; Iter   570/  960] train: loss: 0.0013510
[Epoch 118; Iter   600/  960] train: loss: 0.0307747
[Epoch 118; Iter   630/  960] train: loss: 0.0334876
[Epoch 118; Iter   660/  960] train: loss: 0.0143598
[Epoch 118; Iter   690/  960] train: loss: 0.0032824
[Epoch 118; Iter   720/  960] train: loss: 0.0005387
[Epoch 118; Iter   750/  960] train: loss: 0.0950133
[Epoch 118; Iter   780/  960] train: loss: 0.0049073
[Epoch 118; Iter   810/  960] train: loss: 0.0062783
[Epoch 118; Iter   840/  960] train: loss: 0.0783210
[Epoch 118; Iter   870/  960] train: loss: 0.0728788
[Epoch 118; Iter   900/  960] train: loss: 0.0119352
[Epoch 118; Iter   930/  960] train: loss: 0.0055473
[Epoch 118; Iter   960/  960] train: loss: 0.1404938
[Epoch 118] ogbg-molhiv: 0.722094 val loss: 0.394664
[Epoch 118] ogbg-molhiv: 0.750417 test loss: 0.705856
[Epoch 119; Iter    30/  960] train: loss: 0.0015630
[Epoch 119; Iter    60/  960] train: loss: 0.0068433
[Epoch 119; Iter    90/  960] train: loss: 0.0058211
[Epoch 119; Iter   120/  960] train: loss: 0.0247190
[Epoch 119; Iter   150/  960] train: loss: 0.0767643
[Epoch 119; Iter   180/  960] train: loss: 0.0122644
[Epoch 119; Iter   210/  960] train: loss: 0.0011853
[Epoch 119; Iter   240/  960] train: loss: 0.1366618
[Epoch 119; Iter   270/  960] train: loss: 0.0002807
[Epoch 119; Iter   300/  960] train: loss: 0.0001803
[Epoch 119; Iter   330/  960] train: loss: 0.0004146
[Epoch 119; Iter   360/  960] train: loss: 0.0127827
[Epoch 119; Iter   390/  960] train: loss: 0.0140942
[Epoch 119; Iter   420/  960] train: loss: 0.0012706
[Epoch 109; Iter   744/ 1097] train: loss: 0.0016316
[Epoch 109; Iter   774/ 1097] train: loss: 0.0608826
[Epoch 109; Iter   804/ 1097] train: loss: 0.0024192
[Epoch 109; Iter   834/ 1097] train: loss: 0.0423664
[Epoch 109; Iter   864/ 1097] train: loss: 0.0030965
[Epoch 109; Iter   894/ 1097] train: loss: 0.0051968
[Epoch 109; Iter   924/ 1097] train: loss: 0.0050802
[Epoch 109; Iter   954/ 1097] train: loss: 0.0005088
[Epoch 109; Iter   984/ 1097] train: loss: 0.0178516
[Epoch 109; Iter  1014/ 1097] train: loss: 0.0024856
[Epoch 109; Iter  1044/ 1097] train: loss: 0.0040736
[Epoch 109; Iter  1074/ 1097] train: loss: 0.0114653
[Epoch 109] ogbg-molhiv: 0.794921 val loss: 0.139560
[Epoch 109] ogbg-molhiv: 0.758296 test loss: 0.257648
[Epoch 110; Iter     7/ 1097] train: loss: 0.0006313
[Epoch 110; Iter    37/ 1097] train: loss: 0.0008483
[Epoch 110; Iter    67/ 1097] train: loss: 0.0054406
[Epoch 110; Iter    97/ 1097] train: loss: 0.0034537
[Epoch 110; Iter   127/ 1097] train: loss: 0.0432790
[Epoch 110; Iter   157/ 1097] train: loss: 0.0005300
[Epoch 110; Iter   187/ 1097] train: loss: 0.0023464
[Epoch 110; Iter   217/ 1097] train: loss: 0.0023237
[Epoch 110; Iter   247/ 1097] train: loss: 0.0029587
[Epoch 110; Iter   277/ 1097] train: loss: 0.0012757
[Epoch 110; Iter   307/ 1097] train: loss: 0.0047623
[Epoch 110; Iter   337/ 1097] train: loss: 0.0012756
[Epoch 110; Iter   367/ 1097] train: loss: 0.0161893
[Epoch 110; Iter   397/ 1097] train: loss: 0.0088877
[Epoch 110; Iter   427/ 1097] train: loss: 0.1839038
[Epoch 110; Iter   457/ 1097] train: loss: 0.0053462
[Epoch 110; Iter   487/ 1097] train: loss: 0.0046602
[Epoch 110; Iter   517/ 1097] train: loss: 0.0061894
[Epoch 110; Iter   547/ 1097] train: loss: 0.0007530
[Epoch 110; Iter   577/ 1097] train: loss: 0.0047692
[Epoch 110; Iter   607/ 1097] train: loss: 0.0032557
[Epoch 110; Iter   637/ 1097] train: loss: 0.0186264
[Epoch 110; Iter   667/ 1097] train: loss: 0.0046666
[Epoch 110; Iter   697/ 1097] train: loss: 0.0118908
[Epoch 110; Iter   727/ 1097] train: loss: 0.0034910
[Epoch 110; Iter   757/ 1097] train: loss: 0.0067264
[Epoch 110; Iter   787/ 1097] train: loss: 0.0101631
[Epoch 110; Iter   817/ 1097] train: loss: 0.0036852
[Epoch 110; Iter   847/ 1097] train: loss: 0.1646792
[Epoch 110; Iter   877/ 1097] train: loss: 0.0844745
[Epoch 110; Iter   907/ 1097] train: loss: 0.0041533
[Epoch 110; Iter   937/ 1097] train: loss: 0.0068519
[Epoch 110; Iter   967/ 1097] train: loss: 0.0065473
[Epoch 110; Iter   997/ 1097] train: loss: 0.0336887
[Epoch 110; Iter  1027/ 1097] train: loss: 0.0025908
[Epoch 110; Iter  1057/ 1097] train: loss: 0.0016013
[Epoch 110; Iter  1087/ 1097] train: loss: 0.0052056
[Epoch 110] ogbg-molhiv: 0.794239 val loss: 0.143598
[Epoch 110] ogbg-molhiv: 0.755385 test loss: 0.258992
[Epoch 111; Iter    20/ 1097] train: loss: 0.0020550
[Epoch 111; Iter    50/ 1097] train: loss: 0.0017736
[Epoch 111; Iter    80/ 1097] train: loss: 0.0068504
[Epoch 111; Iter   110/ 1097] train: loss: 0.0193542
[Epoch 111; Iter   140/ 1097] train: loss: 0.0126267
[Epoch 111; Iter   170/ 1097] train: loss: 0.0335810
[Epoch 111; Iter   200/ 1097] train: loss: 0.0045861
[Epoch 111; Iter   230/ 1097] train: loss: 0.0068115
[Epoch 111; Iter   260/ 1097] train: loss: 0.0013164
[Epoch 111; Iter   290/ 1097] train: loss: 0.0295356
[Epoch 111; Iter   320/ 1097] train: loss: 0.0075231
[Epoch 111; Iter   350/ 1097] train: loss: 0.0004922
[Epoch 111; Iter   380/ 1097] train: loss: 0.0021375
[Epoch 111; Iter   410/ 1097] train: loss: 0.0013884
[Epoch 111; Iter   440/ 1097] train: loss: 0.0046972
[Epoch 111; Iter   470/ 1097] train: loss: 0.0082261
[Epoch 111; Iter   500/ 1097] train: loss: 0.0079196
[Epoch 111; Iter   530/ 1097] train: loss: 0.0856405
[Epoch 111; Iter   560/ 1097] train: loss: 0.0022148
[Epoch 111; Iter   590/ 1097] train: loss: 0.0167081
[Epoch 111; Iter   620/ 1097] train: loss: 0.0124322
[Epoch 111; Iter   650/ 1097] train: loss: 0.0007148
[Epoch 111; Iter   680/ 1097] train: loss: 0.0066477
[Epoch 111; Iter   710/ 1097] train: loss: 0.0045594
[Epoch 111; Iter   740/ 1097] train: loss: 0.0055368
[Epoch 111; Iter   770/ 1097] train: loss: 0.0023530
[Epoch 111; Iter   800/ 1097] train: loss: 0.0036663
[Epoch 111; Iter   830/ 1097] train: loss: 0.0419051
[Epoch 111; Iter   860/ 1097] train: loss: 0.0116918
[Epoch 111; Iter   890/ 1097] train: loss: 0.0006500
[Epoch 111; Iter   920/ 1097] train: loss: 0.0020222
[Epoch 111; Iter   950/ 1097] train: loss: 0.0048263
[Epoch 111; Iter   980/ 1097] train: loss: 0.0061205
[Epoch 111; Iter  1010/ 1097] train: loss: 0.0854204
[Epoch 111; Iter  1040/ 1097] train: loss: 0.0235281
[Epoch 111; Iter  1070/ 1097] train: loss: 0.0058349
[Epoch 111] ogbg-molhiv: 0.794300 val loss: 0.142285
[Epoch 111] ogbg-molhiv: 0.763522 test loss: 0.253908
[Epoch 112; Iter     3/ 1097] train: loss: 0.0042073
[Epoch 112; Iter    33/ 1097] train: loss: 0.0014976
[Epoch 112; Iter    63/ 1097] train: loss: 0.0039741
[Epoch 112; Iter    93/ 1097] train: loss: 0.0120981
[Epoch 112; Iter   123/ 1097] train: loss: 0.0084859
[Epoch 112; Iter   153/ 1097] train: loss: 0.0018176
[Epoch 112; Iter   183/ 1097] train: loss: 0.0002494
[Epoch 112; Iter   213/ 1097] train: loss: 0.0230815
[Epoch 112; Iter   243/ 1097] train: loss: 0.0984337
[Epoch 112; Iter   273/ 1097] train: loss: 0.0015488
[Epoch 112; Iter   303/ 1097] train: loss: 0.0131182
[Epoch 112; Iter   333/ 1097] train: loss: 0.0023303
[Epoch 112; Iter   363/ 1097] train: loss: 0.0120316
[Epoch 112; Iter   393/ 1097] train: loss: 0.0172748
[Epoch 112; Iter   423/ 1097] train: loss: 0.0010052
[Epoch 112; Iter   453/ 1097] train: loss: 0.0075107
[Epoch 112; Iter   483/ 1097] train: loss: 0.0006891
[Epoch 112; Iter   513/ 1097] train: loss: 0.0012629
[Epoch 112; Iter   543/ 1097] train: loss: 0.0045748
[Epoch 112; Iter   573/ 1097] train: loss: 0.0357551
[Epoch 112; Iter   603/ 1097] train: loss: 0.0201231
[Epoch 112; Iter   633/ 1097] train: loss: 0.0010957
[Epoch 112; Iter   663/ 1097] train: loss: 0.0078276
[Epoch 112; Iter   693/ 1097] train: loss: 0.0093221
[Epoch 112; Iter   723/ 1097] train: loss: 0.0181649
[Epoch 112; Iter   753/ 1097] train: loss: 0.0019912
[Epoch 112; Iter   783/ 1097] train: loss: 0.0021032
[Epoch 112; Iter   813/ 1097] train: loss: 0.0238311
[Epoch 112; Iter   843/ 1097] train: loss: 0.0084053
[Epoch 112; Iter   873/ 1097] train: loss: 0.0009646
[Epoch 112; Iter   903/ 1097] train: loss: 0.0872711
[Epoch 112; Iter   933/ 1097] train: loss: 0.0035690
[Epoch 112; Iter   963/ 1097] train: loss: 0.0096484
[Epoch 112; Iter   993/ 1097] train: loss: 0.0041460
[Epoch 112; Iter  1023/ 1097] train: loss: 0.0068160
[Epoch 112; Iter  1053/ 1097] train: loss: 0.0198803
[Epoch 112; Iter  1083/ 1097] train: loss: 0.1983668
[Epoch 112] ogbg-molhiv: 0.795503 val loss: 0.145001
[Epoch 112] ogbg-molhiv: 0.762151 test loss: 0.260268
[Epoch 113; Iter    16/ 1097] train: loss: 0.0058587
[Epoch 113; Iter    46/ 1097] train: loss: 0.0017139
[Epoch 113; Iter    76/ 1097] train: loss: 0.0020703
[Epoch 113; Iter   106/ 1097] train: loss: 0.0091328
[Epoch 113; Iter   136/ 1097] train: loss: 0.0013872
[Epoch 113; Iter   166/ 1097] train: loss: 0.0224742
[Epoch 113; Iter   196/ 1097] train: loss: 0.0016774
[Epoch 113; Iter   226/ 1097] train: loss: 0.0112389
[Epoch 113; Iter   256/ 1097] train: loss: 0.0012206
[Epoch 113; Iter   286/ 1097] train: loss: 0.0044311
[Epoch 113; Iter   316/ 1097] train: loss: 0.0002759
[Epoch 113; Iter   346/ 1097] train: loss: 0.0024349
[Epoch 113; Iter   376/ 1097] train: loss: 0.0004219
[Epoch 113; Iter   406/ 1097] train: loss: 0.0430009
[Epoch 113; Iter   436/ 1097] train: loss: 0.0389514
[Epoch 113; Iter   466/ 1097] train: loss: 0.0687370
[Epoch 113; Iter   496/ 1097] train: loss: 0.0001800
[Epoch 113; Iter   526/ 1097] train: loss: 0.0251209
[Epoch 113; Iter   556/ 1097] train: loss: 0.0013132
[Epoch 113; Iter   586/ 1097] train: loss: 0.0514624
[Epoch 113; Iter   616/ 1097] train: loss: 0.0284674
[Epoch 113; Iter   646/ 1097] train: loss: 0.0731179
[Epoch 113; Iter   676/ 1097] train: loss: 0.0055173
[Epoch 113; Iter   706/ 1097] train: loss: 0.0080329
[Epoch 114; Iter   930/  960] train: loss: 0.0035989
[Epoch 114; Iter   960/  960] train: loss: 0.0063911
[Epoch 114] ogbg-molhiv: 0.756507 val loss: 1.118848
[Epoch 114] ogbg-molhiv: 0.754525 test loss: 0.319901
[Epoch 115; Iter    30/  960] train: loss: 0.0020301
[Epoch 115; Iter    60/  960] train: loss: 0.0028360
[Epoch 115; Iter    90/  960] train: loss: 0.0010873
[Epoch 115; Iter   120/  960] train: loss: 0.0168808
[Epoch 115; Iter   150/  960] train: loss: 0.0049942
[Epoch 115; Iter   180/  960] train: loss: 0.0031226
[Epoch 115; Iter   210/  960] train: loss: 0.0271253
[Epoch 115; Iter   240/  960] train: loss: 0.0006236
[Epoch 115; Iter   270/  960] train: loss: 0.0055470
[Epoch 115; Iter   300/  960] train: loss: 0.0058576
[Epoch 115; Iter   330/  960] train: loss: 0.0003526
[Epoch 115; Iter   360/  960] train: loss: 0.0251499
[Epoch 115; Iter   390/  960] train: loss: 0.0043592
[Epoch 115; Iter   420/  960] train: loss: 0.0020719
[Epoch 115; Iter   450/  960] train: loss: 0.0077251
[Epoch 115; Iter   480/  960] train: loss: 0.0059625
[Epoch 115; Iter   510/  960] train: loss: 0.0010695
[Epoch 115; Iter   540/  960] train: loss: 0.0586285
[Epoch 115; Iter   570/  960] train: loss: 0.0028819
[Epoch 115; Iter   600/  960] train: loss: 0.0054235
[Epoch 115; Iter   630/  960] train: loss: 0.0107896
[Epoch 115; Iter   660/  960] train: loss: 0.0376312
[Epoch 115; Iter   690/  960] train: loss: 0.0002771
[Epoch 115; Iter   720/  960] train: loss: 0.0006364
[Epoch 115; Iter   750/  960] train: loss: 0.0004521
[Epoch 115; Iter   780/  960] train: loss: 0.0026588
[Epoch 115; Iter   810/  960] train: loss: 0.0017205
[Epoch 115; Iter   840/  960] train: loss: 0.0004157
[Epoch 115; Iter   870/  960] train: loss: 0.0037240
[Epoch 115; Iter   900/  960] train: loss: 0.0049313
[Epoch 115; Iter   930/  960] train: loss: 0.0033604
[Epoch 115; Iter   960/  960] train: loss: 0.0030317
[Epoch 115] ogbg-molhiv: 0.757330 val loss: 1.069271
[Epoch 115] ogbg-molhiv: 0.757889 test loss: 0.312832
[Epoch 116; Iter    30/  960] train: loss: 0.0085060
[Epoch 116; Iter    60/  960] train: loss: 0.0170928
[Epoch 116; Iter    90/  960] train: loss: 0.0244290
[Epoch 116; Iter   120/  960] train: loss: 0.0285333
[Epoch 116; Iter   150/  960] train: loss: 0.0035725
[Epoch 116; Iter   180/  960] train: loss: 0.0005329
[Epoch 116; Iter   210/  960] train: loss: 0.0289985
[Epoch 116; Iter   240/  960] train: loss: 0.0074814
[Epoch 116; Iter   270/  960] train: loss: 0.0007844
[Epoch 116; Iter   300/  960] train: loss: 0.0003976
[Epoch 116; Iter   330/  960] train: loss: 0.0013360
[Epoch 116; Iter   360/  960] train: loss: 0.0007465
[Epoch 116; Iter   390/  960] train: loss: 0.0009561
[Epoch 116; Iter   420/  960] train: loss: 0.0007827
[Epoch 116; Iter   450/  960] train: loss: 0.0002902
[Epoch 116; Iter   480/  960] train: loss: 0.0020025
[Epoch 116; Iter   510/  960] train: loss: 0.0117274
[Epoch 116; Iter   540/  960] train: loss: 0.1330273
[Epoch 116; Iter   570/  960] train: loss: 0.0118172
[Epoch 116; Iter   600/  960] train: loss: 0.0040193
[Epoch 116; Iter   630/  960] train: loss: 0.0068141
[Epoch 116; Iter   660/  960] train: loss: 0.0028144
[Epoch 116; Iter   690/  960] train: loss: 0.0363344
[Epoch 116; Iter   720/  960] train: loss: 0.0735618
[Epoch 116; Iter   750/  960] train: loss: 0.0168769
[Epoch 116; Iter   780/  960] train: loss: 0.0441158
[Epoch 116; Iter   810/  960] train: loss: 0.0014591
[Epoch 116; Iter   840/  960] train: loss: 0.0099375
[Epoch 116; Iter   870/  960] train: loss: 0.0131195
[Epoch 116; Iter   900/  960] train: loss: 0.0014558
[Epoch 116; Iter   930/  960] train: loss: 0.0019103
[Epoch 116; Iter   960/  960] train: loss: 0.0005341
[Epoch 116] ogbg-molhiv: 0.756352 val loss: 1.299336
[Epoch 116] ogbg-molhiv: 0.757405 test loss: 0.324520
[Epoch 117; Iter    30/  960] train: loss: 0.0025864
[Epoch 117; Iter    60/  960] train: loss: 0.0023521
[Epoch 117; Iter    90/  960] train: loss: 0.0027632
[Epoch 117; Iter   120/  960] train: loss: 0.0022340
[Epoch 117; Iter   150/  960] train: loss: 0.0161974
[Epoch 117; Iter   180/  960] train: loss: 0.0143373
[Epoch 117; Iter   210/  960] train: loss: 0.0009896
[Epoch 117; Iter   240/  960] train: loss: 0.2952551
[Epoch 117; Iter   270/  960] train: loss: 0.0059747
[Epoch 117; Iter   300/  960] train: loss: 0.0011696
[Epoch 117; Iter   330/  960] train: loss: 0.0240075
[Epoch 117; Iter   360/  960] train: loss: 0.0208033
[Epoch 117; Iter   390/  960] train: loss: 0.0047973
[Epoch 117; Iter   420/  960] train: loss: 0.0481830
[Epoch 117; Iter   450/  960] train: loss: 0.0391621
[Epoch 117; Iter   480/  960] train: loss: 0.0171600
[Epoch 117; Iter   510/  960] train: loss: 0.0285675
[Epoch 117; Iter   540/  960] train: loss: 0.0167337
[Epoch 117; Iter   570/  960] train: loss: 0.0060465
[Epoch 117; Iter   600/  960] train: loss: 0.0079877
[Epoch 117; Iter   630/  960] train: loss: 0.0227187
[Epoch 117; Iter   660/  960] train: loss: 0.0059937
[Epoch 117; Iter   690/  960] train: loss: 0.0435160
[Epoch 117; Iter   720/  960] train: loss: 0.0071458
[Epoch 117; Iter   750/  960] train: loss: 0.0025512
[Epoch 117; Iter   780/  960] train: loss: 0.0039273
[Epoch 117; Iter   810/  960] train: loss: 0.0021902
[Epoch 117; Iter   840/  960] train: loss: 0.0113060
[Epoch 117; Iter   870/  960] train: loss: 0.0035267
[Epoch 117; Iter   900/  960] train: loss: 0.0190058
[Epoch 117; Iter   930/  960] train: loss: 0.0244664
[Epoch 117; Iter   960/  960] train: loss: 0.0701572
[Epoch 117] ogbg-molhiv: 0.754618 val loss: 1.075002
[Epoch 117] ogbg-molhiv: 0.753656 test loss: 0.325731
[Epoch 118; Iter    30/  960] train: loss: 0.0262337
[Epoch 118; Iter    60/  960] train: loss: 0.0040768
[Epoch 118; Iter    90/  960] train: loss: 0.0005554
[Epoch 118; Iter   120/  960] train: loss: 0.0107009
[Epoch 118; Iter   150/  960] train: loss: 0.0690999
[Epoch 118; Iter   180/  960] train: loss: 0.0355798
[Epoch 118; Iter   210/  960] train: loss: 0.0091915
[Epoch 118; Iter   240/  960] train: loss: 0.0057913
[Epoch 118; Iter   270/  960] train: loss: 0.0130868
[Epoch 118; Iter   300/  960] train: loss: 0.0361883
[Epoch 118; Iter   330/  960] train: loss: 0.0109197
[Epoch 118; Iter   360/  960] train: loss: 0.0144487
[Epoch 118; Iter   390/  960] train: loss: 0.0011104
[Epoch 118; Iter   420/  960] train: loss: 0.0008796
[Epoch 118; Iter   450/  960] train: loss: 0.0016855
[Epoch 118; Iter   480/  960] train: loss: 0.0090769
[Epoch 118; Iter   510/  960] train: loss: 0.0305580
[Epoch 118; Iter   540/  960] train: loss: 0.0268003
[Epoch 118; Iter   570/  960] train: loss: 0.0006909
[Epoch 118; Iter   600/  960] train: loss: 0.0024982
[Epoch 118; Iter   630/  960] train: loss: 0.0024130
[Epoch 118; Iter   660/  960] train: loss: 0.0013865
[Epoch 118; Iter   690/  960] train: loss: 0.0074050
[Epoch 118; Iter   720/  960] train: loss: 0.0090172
[Epoch 118; Iter   750/  960] train: loss: 0.0120150
[Epoch 118; Iter   780/  960] train: loss: 0.0126283
[Epoch 118; Iter   810/  960] train: loss: 0.0399833
[Epoch 118; Iter   840/  960] train: loss: 0.0196487
[Epoch 118; Iter   870/  960] train: loss: 0.0041325
[Epoch 118; Iter   900/  960] train: loss: 0.0094079
[Epoch 118; Iter   930/  960] train: loss: 0.0024214
[Epoch 118; Iter   960/  960] train: loss: 0.0001173
[Epoch 118] ogbg-molhiv: 0.754329 val loss: 1.176588
[Epoch 118] ogbg-molhiv: 0.756913 test loss: 0.290136
[Epoch 119; Iter    30/  960] train: loss: 0.0025088
[Epoch 119; Iter    60/  960] train: loss: 0.0050285
[Epoch 119; Iter    90/  960] train: loss: 0.0720504
[Epoch 119; Iter   120/  960] train: loss: 0.0027882
[Epoch 119; Iter   150/  960] train: loss: 0.0083355
[Epoch 119; Iter   180/  960] train: loss: 0.0003247
[Epoch 119; Iter   210/  960] train: loss: 0.0031329
[Epoch 119; Iter   240/  960] train: loss: 0.0502228
[Epoch 119; Iter   270/  960] train: loss: 0.0116346
[Epoch 119; Iter   300/  960] train: loss: 0.0056358
[Epoch 119; Iter   330/  960] train: loss: 0.0035635
[Epoch 119; Iter   360/  960] train: loss: 0.0053554
[Epoch 119; Iter   390/  960] train: loss: 0.0005731
[Epoch 119; Iter   420/  960] train: loss: 0.0006202
[Epoch 114; Iter   930/  960] train: loss: 0.0008272
[Epoch 114; Iter   960/  960] train: loss: 0.0035280
[Epoch 114] ogbg-molhiv: 0.720590 val loss: 0.871938
[Epoch 114] ogbg-molhiv: 0.745146 test loss: 0.498537
[Epoch 115; Iter    30/  960] train: loss: 0.0027436
[Epoch 115; Iter    60/  960] train: loss: 0.0043291
[Epoch 115; Iter    90/  960] train: loss: 0.0259988
[Epoch 115; Iter   120/  960] train: loss: 0.0070799
[Epoch 115; Iter   150/  960] train: loss: 0.0627830
[Epoch 115; Iter   180/  960] train: loss: 0.0053310
[Epoch 115; Iter   210/  960] train: loss: 0.0016924
[Epoch 115; Iter   240/  960] train: loss: 0.0032858
[Epoch 115; Iter   270/  960] train: loss: 0.0013716
[Epoch 115; Iter   300/  960] train: loss: 0.0012905
[Epoch 115; Iter   330/  960] train: loss: 0.0049523
[Epoch 115; Iter   360/  960] train: loss: 0.0153558
[Epoch 115; Iter   390/  960] train: loss: 0.0046143
[Epoch 115; Iter   420/  960] train: loss: 0.0008014
[Epoch 115; Iter   450/  960] train: loss: 0.0049674
[Epoch 115; Iter   480/  960] train: loss: 0.0008920
[Epoch 115; Iter   510/  960] train: loss: 0.0011252
[Epoch 115; Iter   540/  960] train: loss: 0.0080844
[Epoch 115; Iter   570/  960] train: loss: 0.0252229
[Epoch 115; Iter   600/  960] train: loss: 0.0153544
[Epoch 115; Iter   630/  960] train: loss: 0.0047728
[Epoch 115; Iter   660/  960] train: loss: 0.0014640
[Epoch 115; Iter   690/  960] train: loss: 0.0101976
[Epoch 115; Iter   720/  960] train: loss: 0.0128196
[Epoch 115; Iter   750/  960] train: loss: 0.0275854
[Epoch 115; Iter   780/  960] train: loss: 0.0018521
[Epoch 115; Iter   810/  960] train: loss: 0.0021742
[Epoch 115; Iter   840/  960] train: loss: 0.0144789
[Epoch 115; Iter   870/  960] train: loss: 0.0047025
[Epoch 115; Iter   900/  960] train: loss: 0.0437163
[Epoch 115; Iter   930/  960] train: loss: 0.0013911
[Epoch 115; Iter   960/  960] train: loss: 0.0248483
[Epoch 115] ogbg-molhiv: 0.718503 val loss: 1.026615
[Epoch 115] ogbg-molhiv: 0.743245 test loss: 0.652451
[Epoch 116; Iter    30/  960] train: loss: 0.0014116
[Epoch 116; Iter    60/  960] train: loss: 0.0032452
[Epoch 116; Iter    90/  960] train: loss: 0.0157317
[Epoch 116; Iter   120/  960] train: loss: 0.0107644
[Epoch 116; Iter   150/  960] train: loss: 0.0003622
[Epoch 116; Iter   180/  960] train: loss: 0.0102820
[Epoch 116; Iter   210/  960] train: loss: 0.0206915
[Epoch 116; Iter   240/  960] train: loss: 0.0004831
[Epoch 116; Iter   270/  960] train: loss: 0.0048408
[Epoch 116; Iter   300/  960] train: loss: 0.0240267
[Epoch 116; Iter   330/  960] train: loss: 0.0982715
[Epoch 116; Iter   360/  960] train: loss: 0.0070447
[Epoch 116; Iter   390/  960] train: loss: 0.0021913
[Epoch 116; Iter   420/  960] train: loss: 0.0027501
[Epoch 116; Iter   450/  960] train: loss: 0.0028263
[Epoch 116; Iter   480/  960] train: loss: 0.0120628
[Epoch 116; Iter   510/  960] train: loss: 0.1067453
[Epoch 116; Iter   540/  960] train: loss: 0.0357789
[Epoch 116; Iter   570/  960] train: loss: 0.0511647
[Epoch 116; Iter   600/  960] train: loss: 0.0015276
[Epoch 116; Iter   630/  960] train: loss: 0.0009748
[Epoch 116; Iter   660/  960] train: loss: 0.0014263
[Epoch 116; Iter   690/  960] train: loss: 0.0060499
[Epoch 116; Iter   720/  960] train: loss: 0.0015905
[Epoch 116; Iter   750/  960] train: loss: 0.0011543
[Epoch 116; Iter   780/  960] train: loss: 0.0234536
[Epoch 116; Iter   810/  960] train: loss: 0.0541869
[Epoch 116; Iter   840/  960] train: loss: 0.0070770
[Epoch 116; Iter   870/  960] train: loss: 0.0013015
[Epoch 116; Iter   900/  960] train: loss: 0.0029854
[Epoch 116; Iter   930/  960] train: loss: 0.0009715
[Epoch 116; Iter   960/  960] train: loss: 0.0011576
[Epoch 116] ogbg-molhiv: 0.715482 val loss: 1.085060
[Epoch 116] ogbg-molhiv: 0.740720 test loss: 0.602827
[Epoch 117; Iter    30/  960] train: loss: 0.0138426
[Epoch 117; Iter    60/  960] train: loss: 0.0677622
[Epoch 117; Iter    90/  960] train: loss: 0.0085344
[Epoch 117; Iter   120/  960] train: loss: 0.0100594
[Epoch 117; Iter   150/  960] train: loss: 0.0046388
[Epoch 117; Iter   180/  960] train: loss: 0.0093024
[Epoch 117; Iter   210/  960] train: loss: 0.1025933
[Epoch 117; Iter   240/  960] train: loss: 0.0020778
[Epoch 117; Iter   270/  960] train: loss: 0.0065633
[Epoch 117; Iter   300/  960] train: loss: 0.0003701
[Epoch 117; Iter   330/  960] train: loss: 0.0008941
[Epoch 117; Iter   360/  960] train: loss: 0.0254896
[Epoch 117; Iter   390/  960] train: loss: 0.0435307
[Epoch 117; Iter   420/  960] train: loss: 0.0270839
[Epoch 117; Iter   450/  960] train: loss: 0.0121321
[Epoch 117; Iter   480/  960] train: loss: 0.0211685
[Epoch 117; Iter   510/  960] train: loss: 0.0029144
[Epoch 117; Iter   540/  960] train: loss: 0.0057040
[Epoch 117; Iter   570/  960] train: loss: 0.0036417
[Epoch 117; Iter   600/  960] train: loss: 0.0359205
[Epoch 117; Iter   630/  960] train: loss: 0.0038591
[Epoch 117; Iter   660/  960] train: loss: 0.0026374
[Epoch 117; Iter   690/  960] train: loss: 0.0046657
[Epoch 117; Iter   720/  960] train: loss: 0.0010765
[Epoch 117; Iter   750/  960] train: loss: 0.0085558
[Epoch 117; Iter   780/  960] train: loss: 0.0017765
[Epoch 117; Iter   810/  960] train: loss: 0.0006055
[Epoch 117; Iter   840/  960] train: loss: 0.0050696
[Epoch 117; Iter   870/  960] train: loss: 0.0169867
[Epoch 117; Iter   900/  960] train: loss: 0.0026634
[Epoch 117; Iter   930/  960] train: loss: 0.0570236
[Epoch 117; Iter   960/  960] train: loss: 0.0110817
[Epoch 117] ogbg-molhiv: 0.717343 val loss: 0.952662
[Epoch 117] ogbg-molhiv: 0.744401 test loss: 0.607745
[Epoch 118; Iter    30/  960] train: loss: 0.0036230
[Epoch 118; Iter    60/  960] train: loss: 0.0030984
[Epoch 118; Iter    90/  960] train: loss: 0.0075458
[Epoch 118; Iter   120/  960] train: loss: 0.0692321
[Epoch 118; Iter   150/  960] train: loss: 0.0037124
[Epoch 118; Iter   180/  960] train: loss: 0.0269532
[Epoch 118; Iter   210/  960] train: loss: 0.0059350
[Epoch 118; Iter   240/  960] train: loss: 0.0651261
[Epoch 118; Iter   270/  960] train: loss: 0.0027589
[Epoch 118; Iter   300/  960] train: loss: 0.0003250
[Epoch 118; Iter   330/  960] train: loss: 0.0037256
[Epoch 118; Iter   360/  960] train: loss: 0.0021189
[Epoch 118; Iter   390/  960] train: loss: 0.0176328
[Epoch 118; Iter   420/  960] train: loss: 0.0118453
[Epoch 118; Iter   450/  960] train: loss: 0.0451739
[Epoch 118; Iter   480/  960] train: loss: 0.0020289
[Epoch 118; Iter   510/  960] train: loss: 0.0017058
[Epoch 118; Iter   540/  960] train: loss: 0.0004872
[Epoch 118; Iter   570/  960] train: loss: 0.0560216
[Epoch 118; Iter   600/  960] train: loss: 0.0002518
[Epoch 118; Iter   630/  960] train: loss: 0.0015658
[Epoch 118; Iter   660/  960] train: loss: 0.0021483
[Epoch 118; Iter   690/  960] train: loss: 0.0130854
[Epoch 118; Iter   720/  960] train: loss: 0.0018828
[Epoch 118; Iter   750/  960] train: loss: 0.0056167
[Epoch 118; Iter   780/  960] train: loss: 0.0073389
[Epoch 118; Iter   810/  960] train: loss: 0.0004781
[Epoch 118; Iter   840/  960] train: loss: 0.0724078
[Epoch 118; Iter   870/  960] train: loss: 0.0024435
[Epoch 118; Iter   900/  960] train: loss: 0.0484102
[Epoch 118; Iter   930/  960] train: loss: 0.0336573
[Epoch 118; Iter   960/  960] train: loss: 0.0003234
[Epoch 118] ogbg-molhiv: 0.718134 val loss: 1.132186
[Epoch 118] ogbg-molhiv: 0.744630 test loss: 0.628169
[Epoch 119; Iter    30/  960] train: loss: 0.0003660
[Epoch 119; Iter    60/  960] train: loss: 0.0028345
[Epoch 119; Iter    90/  960] train: loss: 0.0070927
[Epoch 119; Iter   120/  960] train: loss: 0.0422705
[Epoch 119; Iter   150/  960] train: loss: 0.0097333
[Epoch 119; Iter   180/  960] train: loss: 0.0059486
[Epoch 119; Iter   210/  960] train: loss: 0.0218629
[Epoch 119; Iter   240/  960] train: loss: 0.0009670
[Epoch 119; Iter   270/  960] train: loss: 0.0052982
[Epoch 119; Iter   300/  960] train: loss: 0.0032974
[Epoch 119; Iter   330/  960] train: loss: 0.0025279
[Epoch 119; Iter   360/  960] train: loss: 0.0113663
[Epoch 119; Iter   390/  960] train: loss: 0.0657161
[Epoch 119; Iter   420/  960] train: loss: 0.0019466
[Epoch 121; Iter   690/  823] train: loss: 0.0096832
[Epoch 121; Iter   720/  823] train: loss: 0.0017633
[Epoch 121; Iter   750/  823] train: loss: 0.0007335
[Epoch 121; Iter   780/  823] train: loss: 0.0005867
[Epoch 121; Iter   810/  823] train: loss: 0.0026979
[Epoch 121] ogbg-molhiv: 0.734130 val loss: 0.320986
[Epoch 121] ogbg-molhiv: 0.758844 test loss: 0.233234
[Epoch 122; Iter    17/  823] train: loss: 0.0040078
[Epoch 122; Iter    47/  823] train: loss: 0.0245236
[Epoch 122; Iter    77/  823] train: loss: 0.0004894
[Epoch 122; Iter   107/  823] train: loss: 0.0028784
[Epoch 122; Iter   137/  823] train: loss: 0.1107417
[Epoch 122; Iter   167/  823] train: loss: 0.0846848
[Epoch 122; Iter   197/  823] train: loss: 0.0013106
[Epoch 122; Iter   227/  823] train: loss: 0.0268271
[Epoch 122; Iter   257/  823] train: loss: 0.0020346
[Epoch 122; Iter   287/  823] train: loss: 0.0001722
[Epoch 122; Iter   317/  823] train: loss: 0.1141595
[Epoch 122; Iter   347/  823] train: loss: 0.0005796
[Epoch 122; Iter   377/  823] train: loss: 0.0338567
[Epoch 122; Iter   407/  823] train: loss: 0.0061861
[Epoch 122; Iter   437/  823] train: loss: 0.1567846
[Epoch 122; Iter   467/  823] train: loss: 0.0123290
[Epoch 122; Iter   497/  823] train: loss: 0.0001841
[Epoch 122; Iter   527/  823] train: loss: 0.0014236
[Epoch 122; Iter   557/  823] train: loss: 0.0530714
[Epoch 122; Iter   587/  823] train: loss: 0.0004393
[Epoch 122; Iter   617/  823] train: loss: 0.0121581
[Epoch 122; Iter   647/  823] train: loss: 0.0011162
[Epoch 122; Iter   677/  823] train: loss: 0.0017180
[Epoch 122; Iter   707/  823] train: loss: 0.1052544
[Epoch 122; Iter   737/  823] train: loss: 0.0073196
[Epoch 122; Iter   767/  823] train: loss: 0.0034887
[Epoch 122; Iter   797/  823] train: loss: 0.0002712
[Epoch 122] ogbg-molhiv: 0.736823 val loss: 0.546977
[Epoch 122] ogbg-molhiv: 0.757155 test loss: 0.598866
[Epoch 123; Iter     4/  823] train: loss: 0.0001703
[Epoch 123; Iter    34/  823] train: loss: 0.0001849
[Epoch 123; Iter    64/  823] train: loss: 0.0018160
[Epoch 123; Iter    94/  823] train: loss: 0.0014758
[Epoch 123; Iter   124/  823] train: loss: 0.0026025
[Epoch 123; Iter   154/  823] train: loss: 0.0007902
[Epoch 123; Iter   184/  823] train: loss: 0.0009150
[Epoch 123; Iter   214/  823] train: loss: 0.0020779
[Epoch 123; Iter   244/  823] train: loss: 0.0386482
[Epoch 123; Iter   274/  823] train: loss: 0.0035670
[Epoch 123; Iter   304/  823] train: loss: 0.0362831
[Epoch 123; Iter   334/  823] train: loss: 0.0004367
[Epoch 123; Iter   364/  823] train: loss: 0.0023956
[Epoch 123; Iter   394/  823] train: loss: 0.0044480
[Epoch 123; Iter   424/  823] train: loss: 0.0038544
[Epoch 123; Iter   454/  823] train: loss: 0.0052010
[Epoch 123; Iter   484/  823] train: loss: 0.0027957
[Epoch 123; Iter   514/  823] train: loss: 0.0005400
[Epoch 123; Iter   544/  823] train: loss: 0.0055863
[Epoch 123; Iter   574/  823] train: loss: 0.0202057
[Epoch 123; Iter   604/  823] train: loss: 0.0005553
[Epoch 123; Iter   634/  823] train: loss: 0.0002919
[Epoch 123; Iter   664/  823] train: loss: 0.0300042
[Epoch 123; Iter   694/  823] train: loss: 0.0013747
[Epoch 123; Iter   724/  823] train: loss: 0.0051358
[Epoch 123; Iter   754/  823] train: loss: 0.0006025
[Epoch 123; Iter   784/  823] train: loss: 0.0041476
[Epoch 123; Iter   814/  823] train: loss: 0.0207445
[Epoch 123] ogbg-molhiv: 0.732337 val loss: 0.326845
[Epoch 123] ogbg-molhiv: 0.751321 test loss: 0.246820
[Epoch 124; Iter    21/  823] train: loss: 0.0034973
[Epoch 124; Iter    51/  823] train: loss: 0.0001767
[Epoch 124; Iter    81/  823] train: loss: 0.0034391
[Epoch 124; Iter   111/  823] train: loss: 0.0034531
[Epoch 124; Iter   141/  823] train: loss: 0.0002562
[Epoch 124; Iter   171/  823] train: loss: 0.0009139
[Epoch 124; Iter   201/  823] train: loss: 0.0000401
[Epoch 124; Iter   231/  823] train: loss: 0.0012307
[Epoch 124; Iter   261/  823] train: loss: 0.0114543
[Epoch 124; Iter   291/  823] train: loss: 0.0030995
[Epoch 124; Iter   321/  823] train: loss: 0.0001585
[Epoch 124; Iter   351/  823] train: loss: 0.0471506
[Epoch 124; Iter   381/  823] train: loss: 0.0004594
[Epoch 124; Iter   411/  823] train: loss: 0.0021856
[Epoch 124; Iter   441/  823] train: loss: 0.0031886
[Epoch 124; Iter   471/  823] train: loss: 0.0159517
[Epoch 124; Iter   501/  823] train: loss: 0.0004373
[Epoch 124; Iter   531/  823] train: loss: 0.0130006
[Epoch 124; Iter   561/  823] train: loss: 0.0002977
[Epoch 124; Iter   591/  823] train: loss: 0.0037912
[Epoch 124; Iter   621/  823] train: loss: 0.0016905
[Epoch 124; Iter   651/  823] train: loss: 0.0040221
[Epoch 124; Iter   681/  823] train: loss: 0.0349080
[Epoch 124; Iter   711/  823] train: loss: 0.0001388
[Epoch 124; Iter   741/  823] train: loss: 0.0149198
[Epoch 124; Iter   771/  823] train: loss: 0.0314365
[Epoch 124; Iter   801/  823] train: loss: 0.0101937
[Epoch 124] ogbg-molhiv: 0.733853 val loss: 0.333737
[Epoch 124] ogbg-molhiv: 0.750669 test loss: 0.247356
[Epoch 125; Iter     8/  823] train: loss: 0.0032642
[Epoch 125; Iter    38/  823] train: loss: 0.0012751
[Epoch 125; Iter    68/  823] train: loss: 0.0012300
[Epoch 125; Iter    98/  823] train: loss: 0.0091770
[Epoch 125; Iter   128/  823] train: loss: 0.0016764
[Epoch 125; Iter   158/  823] train: loss: 0.0064922
[Epoch 125; Iter   188/  823] train: loss: 0.0008056
[Epoch 125; Iter   218/  823] train: loss: 0.0092182
[Epoch 125; Iter   248/  823] train: loss: 0.0066065
[Epoch 125; Iter   278/  823] train: loss: 0.0344548
[Epoch 125; Iter   308/  823] train: loss: 0.0184827
[Epoch 125; Iter   338/  823] train: loss: 0.0007015
[Epoch 125; Iter   368/  823] train: loss: 0.0027809
[Epoch 125; Iter   398/  823] train: loss: 0.0041928
[Epoch 125; Iter   428/  823] train: loss: 0.0001810
[Epoch 125; Iter   458/  823] train: loss: 0.0509441
[Epoch 125; Iter   488/  823] train: loss: 0.0700281
[Epoch 125; Iter   518/  823] train: loss: 0.0036521
[Epoch 125; Iter   548/  823] train: loss: 0.0037876
[Epoch 125; Iter   578/  823] train: loss: 0.0021446
[Epoch 125; Iter   608/  823] train: loss: 0.0139910
[Epoch 125; Iter   638/  823] train: loss: 0.0242867
[Epoch 125; Iter   668/  823] train: loss: 0.0009131
[Epoch 125; Iter   698/  823] train: loss: 0.0012134
[Epoch 125; Iter   728/  823] train: loss: 0.0014489
[Epoch 125; Iter   758/  823] train: loss: 0.0004538
[Epoch 125; Iter   788/  823] train: loss: 0.0004731
[Epoch 125; Iter   818/  823] train: loss: 0.0126007
[Epoch 125] ogbg-molhiv: 0.739143 val loss: 0.525696
[Epoch 125] ogbg-molhiv: 0.757979 test loss: 0.559060
[Epoch 126; Iter    25/  823] train: loss: 0.0001371
[Epoch 126; Iter    55/  823] train: loss: 0.0008680
[Epoch 126; Iter    85/  823] train: loss: 0.0011558
[Epoch 126; Iter   115/  823] train: loss: 0.0001912
[Epoch 126; Iter   145/  823] train: loss: 0.0077697
[Epoch 126; Iter   175/  823] train: loss: 0.0112668
[Epoch 126; Iter   205/  823] train: loss: 0.0007533
[Epoch 126; Iter   235/  823] train: loss: 0.0006743
[Epoch 126; Iter   265/  823] train: loss: 0.0018493
[Epoch 126; Iter   295/  823] train: loss: 0.0002954
[Epoch 126; Iter   325/  823] train: loss: 0.0048740
[Epoch 126; Iter   355/  823] train: loss: 0.0002013
[Epoch 126; Iter   385/  823] train: loss: 0.0108647
[Epoch 126; Iter   415/  823] train: loss: 0.0081526
[Epoch 126; Iter   445/  823] train: loss: 0.0005838
[Epoch 126; Iter   475/  823] train: loss: 0.0016650
[Epoch 126; Iter   505/  823] train: loss: 0.0003664
[Epoch 126; Iter   535/  823] train: loss: 0.1190036
[Epoch 126; Iter   565/  823] train: loss: 0.0275485
[Epoch 126; Iter   595/  823] train: loss: 0.0124690
[Epoch 126; Iter   625/  823] train: loss: 0.0336705
[Epoch 126; Iter   655/  823] train: loss: 0.0092741
[Epoch 126; Iter   685/  823] train: loss: 0.0306964
[Epoch 126; Iter   715/  823] train: loss: 0.0024520
[Epoch 126; Iter   745/  823] train: loss: 0.0594274
[Epoch 126; Iter   775/  823] train: loss: 0.0007303
[Epoch 126; Iter   805/  823] train: loss: 0.0018467
[Epoch 126] ogbg-molhiv: 0.739897 val loss: 0.327765
[Epoch 126] ogbg-molhiv: 0.760090 test loss: 0.234730
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 113; Iter   736/ 1097] train: loss: 0.0187715
[Epoch 113; Iter   766/ 1097] train: loss: 0.0034166
[Epoch 113; Iter   796/ 1097] train: loss: 0.0223935
[Epoch 113; Iter   826/ 1097] train: loss: 0.0434078
[Epoch 113; Iter   856/ 1097] train: loss: 0.0078282
[Epoch 113; Iter   886/ 1097] train: loss: 0.0626011
[Epoch 113; Iter   916/ 1097] train: loss: 0.0124535
[Epoch 113; Iter   946/ 1097] train: loss: 0.0187724
[Epoch 113; Iter   976/ 1097] train: loss: 0.0409353
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0018396
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0077352
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0083818
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0924450
[Epoch 113] ogbg-molhiv: 0.764070 val loss: 0.177424
[Epoch 113] ogbg-molhiv: 0.723596 test loss: 0.251855
[Epoch 114; Iter    29/ 1097] train: loss: 0.0116605
[Epoch 114; Iter    59/ 1097] train: loss: 0.0198431
[Epoch 114; Iter    89/ 1097] train: loss: 0.0038810
[Epoch 114; Iter   119/ 1097] train: loss: 0.0072532
[Epoch 114; Iter   149/ 1097] train: loss: 0.0809179
[Epoch 114; Iter   179/ 1097] train: loss: 0.0344264
[Epoch 114; Iter   209/ 1097] train: loss: 0.0092396
[Epoch 114; Iter   239/ 1097] train: loss: 0.0069840
[Epoch 114; Iter   269/ 1097] train: loss: 0.0006401
[Epoch 114; Iter   299/ 1097] train: loss: 0.0190598
[Epoch 114; Iter   329/ 1097] train: loss: 0.0010618
[Epoch 114; Iter   359/ 1097] train: loss: 0.0847362
[Epoch 114; Iter   389/ 1097] train: loss: 0.0058607
[Epoch 114; Iter   419/ 1097] train: loss: 0.0244294
[Epoch 114; Iter   449/ 1097] train: loss: 0.0012541
[Epoch 114; Iter   479/ 1097] train: loss: 0.0182262
[Epoch 114; Iter   509/ 1097] train: loss: 0.0976594
[Epoch 114; Iter   539/ 1097] train: loss: 0.0898222
[Epoch 114; Iter   569/ 1097] train: loss: 0.1257556
[Epoch 114; Iter   599/ 1097] train: loss: 0.0811647
[Epoch 114; Iter   629/ 1097] train: loss: 0.0389245
[Epoch 114; Iter   659/ 1097] train: loss: 0.0257075
[Epoch 114; Iter   689/ 1097] train: loss: 0.0042800
[Epoch 114; Iter   719/ 1097] train: loss: 0.0065966
[Epoch 114; Iter   749/ 1097] train: loss: 0.0126246
[Epoch 114; Iter   779/ 1097] train: loss: 0.0155682
[Epoch 114; Iter   809/ 1097] train: loss: 0.0013522
[Epoch 114; Iter   839/ 1097] train: loss: 0.1171115
[Epoch 114; Iter   869/ 1097] train: loss: 0.0481660
[Epoch 114; Iter   899/ 1097] train: loss: 0.0053977
[Epoch 114; Iter   929/ 1097] train: loss: 0.0019915
[Epoch 114; Iter   959/ 1097] train: loss: 0.1036306
[Epoch 114; Iter   989/ 1097] train: loss: 0.0050602
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0283319
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0391818
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0807844
[Epoch 114] ogbg-molhiv: 0.762756 val loss: 0.186598
[Epoch 114] ogbg-molhiv: 0.728873 test loss: 0.250547
[Epoch 115; Iter    12/ 1097] train: loss: 0.0073616
[Epoch 115; Iter    42/ 1097] train: loss: 0.0112449
[Epoch 115; Iter    72/ 1097] train: loss: 0.0380424
[Epoch 115; Iter   102/ 1097] train: loss: 0.0257009
[Epoch 115; Iter   132/ 1097] train: loss: 0.0056860
[Epoch 115; Iter   162/ 1097] train: loss: 0.0193444
[Epoch 115; Iter   192/ 1097] train: loss: 0.0319865
[Epoch 115; Iter   222/ 1097] train: loss: 0.0103495
[Epoch 115; Iter   252/ 1097] train: loss: 0.0147398
[Epoch 115; Iter   282/ 1097] train: loss: 0.0296608
[Epoch 115; Iter   312/ 1097] train: loss: 0.0638232
[Epoch 115; Iter   342/ 1097] train: loss: 0.0450071
[Epoch 115; Iter   372/ 1097] train: loss: 0.0178219
[Epoch 115; Iter   402/ 1097] train: loss: 0.0156742
[Epoch 115; Iter   432/ 1097] train: loss: 0.0804095
[Epoch 115; Iter   462/ 1097] train: loss: 0.0260957
[Epoch 115; Iter   492/ 1097] train: loss: 0.0080258
[Epoch 115; Iter   522/ 1097] train: loss: 0.0020722
[Epoch 115; Iter   552/ 1097] train: loss: 0.0409273
[Epoch 115; Iter   582/ 1097] train: loss: 0.0869541
[Epoch 115; Iter   612/ 1097] train: loss: 0.0086080
[Epoch 115; Iter   642/ 1097] train: loss: 0.0016386
[Epoch 115; Iter   672/ 1097] train: loss: 0.0436554
[Epoch 115; Iter   702/ 1097] train: loss: 0.0045936
[Epoch 115; Iter   732/ 1097] train: loss: 0.0151983
[Epoch 115; Iter   762/ 1097] train: loss: 0.0340163
[Epoch 115; Iter   792/ 1097] train: loss: 0.0032985
[Epoch 115; Iter   822/ 1097] train: loss: 0.0247990
[Epoch 115; Iter   852/ 1097] train: loss: 0.0013431
[Epoch 115; Iter   882/ 1097] train: loss: 0.0132568
[Epoch 115; Iter   912/ 1097] train: loss: 0.0122744
[Epoch 115; Iter   942/ 1097] train: loss: 0.0046591
[Epoch 115; Iter   972/ 1097] train: loss: 0.1109674
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0831195
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0326050
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0644718
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0060893
[Epoch 115] ogbg-molhiv: 0.766097 val loss: 0.197699
[Epoch 115] ogbg-molhiv: 0.725452 test loss: 0.250856
[Epoch 116; Iter    25/ 1097] train: loss: 0.0021373
[Epoch 116; Iter    55/ 1097] train: loss: 0.0329169
[Epoch 116; Iter    85/ 1097] train: loss: 0.0698818
[Epoch 116; Iter   115/ 1097] train: loss: 0.0472240
[Epoch 116; Iter   145/ 1097] train: loss: 0.0198102
[Epoch 116; Iter   175/ 1097] train: loss: 0.0061620
[Epoch 116; Iter   205/ 1097] train: loss: 0.0064470
[Epoch 116; Iter   235/ 1097] train: loss: 0.0125161
[Epoch 116; Iter   265/ 1097] train: loss: 0.0027526
[Epoch 116; Iter   295/ 1097] train: loss: 0.0636457
[Epoch 116; Iter   325/ 1097] train: loss: 0.0171371
[Epoch 116; Iter   355/ 1097] train: loss: 0.0200696
[Epoch 116; Iter   385/ 1097] train: loss: 0.0399780
[Epoch 116; Iter   415/ 1097] train: loss: 0.0083924
[Epoch 116; Iter   445/ 1097] train: loss: 0.0107665
[Epoch 116; Iter   475/ 1097] train: loss: 0.0016593
[Epoch 116; Iter   505/ 1097] train: loss: 0.0028951
[Epoch 116; Iter   535/ 1097] train: loss: 0.0207229
[Epoch 116; Iter   565/ 1097] train: loss: 0.0939679
[Epoch 116; Iter   595/ 1097] train: loss: 0.0042141
[Epoch 116; Iter   625/ 1097] train: loss: 0.0034827
[Epoch 116; Iter   655/ 1097] train: loss: 0.0183461
[Epoch 116; Iter   685/ 1097] train: loss: 0.0110927
[Epoch 116; Iter   715/ 1097] train: loss: 0.0199239
[Epoch 116; Iter   745/ 1097] train: loss: 0.0199778
[Epoch 116; Iter   775/ 1097] train: loss: 0.0403254
[Epoch 116; Iter   805/ 1097] train: loss: 0.0014596
[Epoch 116; Iter   835/ 1097] train: loss: 0.0004041
[Epoch 116; Iter   865/ 1097] train: loss: 0.0216182
[Epoch 116; Iter   895/ 1097] train: loss: 0.0065880
[Epoch 116; Iter   925/ 1097] train: loss: 0.0091885
[Epoch 116; Iter   955/ 1097] train: loss: 0.0075262
[Epoch 116; Iter   985/ 1097] train: loss: 0.0756918
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0026635
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0043775
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0315451
[Epoch 116] ogbg-molhiv: 0.772946 val loss: 0.191841
[Epoch 116] ogbg-molhiv: 0.727979 test loss: 0.257781
[Epoch 117; Iter     8/ 1097] train: loss: 0.1462084
[Epoch 117; Iter    38/ 1097] train: loss: 0.0028327
[Epoch 117; Iter    68/ 1097] train: loss: 0.0087064
[Epoch 117; Iter    98/ 1097] train: loss: 0.1033722
[Epoch 117; Iter   128/ 1097] train: loss: 0.0184783
[Epoch 117; Iter   158/ 1097] train: loss: 0.0413205
[Epoch 117; Iter   188/ 1097] train: loss: 0.0254463
[Epoch 117; Iter   218/ 1097] train: loss: 0.1304924
[Epoch 117; Iter   248/ 1097] train: loss: 0.0196782
[Epoch 117; Iter   278/ 1097] train: loss: 0.1375291
[Epoch 117; Iter   308/ 1097] train: loss: 0.0434635
[Epoch 117; Iter   338/ 1097] train: loss: 0.0967702
[Epoch 117; Iter   368/ 1097] train: loss: 0.0144334
[Epoch 117; Iter   398/ 1097] train: loss: 0.0168754
[Epoch 117; Iter   428/ 1097] train: loss: 0.0076010
[Epoch 117; Iter   458/ 1097] train: loss: 0.0258441
[Epoch 117; Iter   488/ 1097] train: loss: 0.0016140
[Epoch 117; Iter   518/ 1097] train: loss: 0.0799623
[Epoch 117; Iter   548/ 1097] train: loss: 0.0035598
[Epoch 117; Iter   578/ 1097] train: loss: 0.0080961
[Epoch 117; Iter   608/ 1097] train: loss: 0.0393467
[Epoch 117; Iter   638/ 1097] train: loss: 0.0205958
[Epoch 117; Iter   668/ 1097] train: loss: 0.0053455
[Epoch 117; Iter   698/ 1097] train: loss: 0.0203777
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 113; Iter   736/ 1097] train: loss: 0.0356022
[Epoch 113; Iter   766/ 1097] train: loss: 0.0023063
[Epoch 113; Iter   796/ 1097] train: loss: 0.0008974
[Epoch 113; Iter   826/ 1097] train: loss: 0.0041908
[Epoch 113; Iter   856/ 1097] train: loss: 0.0052861
[Epoch 113; Iter   886/ 1097] train: loss: 0.0015590
[Epoch 113; Iter   916/ 1097] train: loss: 0.0362370
[Epoch 113; Iter   946/ 1097] train: loss: 0.0099269
[Epoch 113; Iter   976/ 1097] train: loss: 0.0142396
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0008500
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0078934
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0030974
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0016734
[Epoch 113] ogbg-molhiv: 0.761951 val loss: 0.187955
[Epoch 113] ogbg-molhiv: 0.731654 test loss: 0.439445
[Epoch 114; Iter    29/ 1097] train: loss: 0.0028157
[Epoch 114; Iter    59/ 1097] train: loss: 0.0009975
[Epoch 114; Iter    89/ 1097] train: loss: 0.0036196
[Epoch 114; Iter   119/ 1097] train: loss: 0.0086849
[Epoch 114; Iter   149/ 1097] train: loss: 0.0018976
[Epoch 114; Iter   179/ 1097] train: loss: 0.0113932
[Epoch 114; Iter   209/ 1097] train: loss: 0.0017620
[Epoch 114; Iter   239/ 1097] train: loss: 0.0064479
[Epoch 114; Iter   269/ 1097] train: loss: 0.0572168
[Epoch 114; Iter   299/ 1097] train: loss: 0.0037221
[Epoch 114; Iter   329/ 1097] train: loss: 0.0005317
[Epoch 114; Iter   359/ 1097] train: loss: 0.0037634
[Epoch 114; Iter   389/ 1097] train: loss: 0.0025294
[Epoch 114; Iter   419/ 1097] train: loss: 0.0112744
[Epoch 114; Iter   449/ 1097] train: loss: 0.0219698
[Epoch 114; Iter   479/ 1097] train: loss: 0.1132782
[Epoch 114; Iter   509/ 1097] train: loss: 0.0124830
[Epoch 114; Iter   539/ 1097] train: loss: 0.0033319
[Epoch 114; Iter   569/ 1097] train: loss: 0.0375509
[Epoch 114; Iter   599/ 1097] train: loss: 0.0042315
[Epoch 114; Iter   629/ 1097] train: loss: 0.0038539
[Epoch 114; Iter   659/ 1097] train: loss: 0.0003466
[Epoch 114; Iter   689/ 1097] train: loss: 0.0049060
[Epoch 114; Iter   719/ 1097] train: loss: 0.0192792
[Epoch 114; Iter   749/ 1097] train: loss: 0.0189894
[Epoch 114; Iter   779/ 1097] train: loss: 0.0227653
[Epoch 114; Iter   809/ 1097] train: loss: 0.0007742
[Epoch 114; Iter   839/ 1097] train: loss: 0.0037542
[Epoch 114; Iter   869/ 1097] train: loss: 0.0054109
[Epoch 114; Iter   899/ 1097] train: loss: 0.0016271
[Epoch 114; Iter   929/ 1097] train: loss: 0.0132649
[Epoch 114; Iter   959/ 1097] train: loss: 0.0077536
[Epoch 114; Iter   989/ 1097] train: loss: 0.0989893
[Epoch 114; Iter  1019/ 1097] train: loss: 0.0004011
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0006313
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0014884
[Epoch 114] ogbg-molhiv: 0.748772 val loss: 0.249308
[Epoch 114] ogbg-molhiv: 0.730881 test loss: 0.697571
[Epoch 115; Iter    12/ 1097] train: loss: 0.0155146
[Epoch 115; Iter    42/ 1097] train: loss: 0.0027477
[Epoch 115; Iter    72/ 1097] train: loss: 0.0019722
[Epoch 115; Iter   102/ 1097] train: loss: 0.0252678
[Epoch 115; Iter   132/ 1097] train: loss: 0.0027131
[Epoch 115; Iter   162/ 1097] train: loss: 0.0103482
[Epoch 115; Iter   192/ 1097] train: loss: 0.0012167
[Epoch 115; Iter   222/ 1097] train: loss: 0.0087556
[Epoch 115; Iter   252/ 1097] train: loss: 0.0195685
[Epoch 115; Iter   282/ 1097] train: loss: 0.0013822
[Epoch 115; Iter   312/ 1097] train: loss: 0.0012588
[Epoch 115; Iter   342/ 1097] train: loss: 0.0012478
[Epoch 115; Iter   372/ 1097] train: loss: 0.0071026
[Epoch 115; Iter   402/ 1097] train: loss: 0.0006688
[Epoch 115; Iter   432/ 1097] train: loss: 0.0192028
[Epoch 115; Iter   462/ 1097] train: loss: 0.0187305
[Epoch 115; Iter   492/ 1097] train: loss: 0.0034015
[Epoch 115; Iter   522/ 1097] train: loss: 0.0039272
[Epoch 115; Iter   552/ 1097] train: loss: 0.0017604
[Epoch 115; Iter   582/ 1097] train: loss: 0.0009544
[Epoch 115; Iter   612/ 1097] train: loss: 0.0055249
[Epoch 115; Iter   642/ 1097] train: loss: 0.0510195
[Epoch 115; Iter   672/ 1097] train: loss: 0.0448782
[Epoch 115; Iter   702/ 1097] train: loss: 0.0006789
[Epoch 115; Iter   732/ 1097] train: loss: 0.0620116
[Epoch 115; Iter   762/ 1097] train: loss: 0.0302395
[Epoch 115; Iter   792/ 1097] train: loss: 0.0009079
[Epoch 115; Iter   822/ 1097] train: loss: 0.0045764
[Epoch 115; Iter   852/ 1097] train: loss: 0.0244649
[Epoch 115; Iter   882/ 1097] train: loss: 0.0017817
[Epoch 115; Iter   912/ 1097] train: loss: 0.0098968
[Epoch 115; Iter   942/ 1097] train: loss: 0.0024519
[Epoch 115; Iter   972/ 1097] train: loss: 0.0004794
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0068553
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0317885
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0117171
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0012555
[Epoch 115] ogbg-molhiv: 0.749960 val loss: 0.161429
[Epoch 115] ogbg-molhiv: 0.731074 test loss: 0.275452
[Epoch 116; Iter    25/ 1097] train: loss: 0.0065039
[Epoch 116; Iter    55/ 1097] train: loss: 0.0156275
[Epoch 116; Iter    85/ 1097] train: loss: 0.0346878
[Epoch 116; Iter   115/ 1097] train: loss: 0.0078128
[Epoch 116; Iter   145/ 1097] train: loss: 0.0160389
[Epoch 116; Iter   175/ 1097] train: loss: 0.0097406
[Epoch 116; Iter   205/ 1097] train: loss: 0.0003870
[Epoch 116; Iter   235/ 1097] train: loss: 0.0011081
[Epoch 116; Iter   265/ 1097] train: loss: 0.0435651
[Epoch 116; Iter   295/ 1097] train: loss: 0.0026026
[Epoch 116; Iter   325/ 1097] train: loss: 0.0013136
[Epoch 116; Iter   355/ 1097] train: loss: 0.0720233
[Epoch 116; Iter   385/ 1097] train: loss: 0.0006355
[Epoch 116; Iter   415/ 1097] train: loss: 0.0057529
[Epoch 116; Iter   445/ 1097] train: loss: 0.0158594
[Epoch 116; Iter   475/ 1097] train: loss: 0.0150070
[Epoch 116; Iter   505/ 1097] train: loss: 0.0005197
[Epoch 116; Iter   535/ 1097] train: loss: 0.0012146
[Epoch 116; Iter   565/ 1097] train: loss: 0.0081483
[Epoch 116; Iter   595/ 1097] train: loss: 0.0022285
[Epoch 116; Iter   625/ 1097] train: loss: 0.0898270
[Epoch 116; Iter   655/ 1097] train: loss: 0.1250962
[Epoch 116; Iter   685/ 1097] train: loss: 0.0057768
[Epoch 116; Iter   715/ 1097] train: loss: 0.0726850
[Epoch 116; Iter   745/ 1097] train: loss: 0.0016669
[Epoch 116; Iter   775/ 1097] train: loss: 0.0297368
[Epoch 116; Iter   805/ 1097] train: loss: 0.0076620
[Epoch 116; Iter   835/ 1097] train: loss: 0.0022182
[Epoch 116; Iter   865/ 1097] train: loss: 0.0008143
[Epoch 116; Iter   895/ 1097] train: loss: 0.0160018
[Epoch 116; Iter   925/ 1097] train: loss: 0.0365365
[Epoch 116; Iter   955/ 1097] train: loss: 0.0034057
[Epoch 116; Iter   985/ 1097] train: loss: 0.0005332
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0018470
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0581082
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0058703
[Epoch 116] ogbg-molhiv: 0.753769 val loss: 0.193891
[Epoch 116] ogbg-molhiv: 0.733805 test loss: 0.444457
[Epoch 117; Iter     8/ 1097] train: loss: 0.0003923
[Epoch 117; Iter    38/ 1097] train: loss: 0.0023498
[Epoch 117; Iter    68/ 1097] train: loss: 0.0101707
[Epoch 117; Iter    98/ 1097] train: loss: 0.0529714
[Epoch 117; Iter   128/ 1097] train: loss: 0.0318146
[Epoch 117; Iter   158/ 1097] train: loss: 0.0006548
[Epoch 117; Iter   188/ 1097] train: loss: 0.0232022
[Epoch 117; Iter   218/ 1097] train: loss: 0.0111121
[Epoch 117; Iter   248/ 1097] train: loss: 0.0077483
[Epoch 117; Iter   278/ 1097] train: loss: 0.0803086
[Epoch 117; Iter   308/ 1097] train: loss: 0.0009332
[Epoch 117; Iter   338/ 1097] train: loss: 0.0399139
[Epoch 117; Iter   368/ 1097] train: loss: 0.0028358
[Epoch 117; Iter   398/ 1097] train: loss: 0.0067582
[Epoch 117; Iter   428/ 1097] train: loss: 0.0026765
[Epoch 117; Iter   458/ 1097] train: loss: 0.0021407
[Epoch 117; Iter   488/ 1097] train: loss: 0.0480731
[Epoch 117; Iter   518/ 1097] train: loss: 0.0137260
[Epoch 117; Iter   548/ 1097] train: loss: 0.0023819
[Epoch 117; Iter   578/ 1097] train: loss: 0.0014684
[Epoch 117; Iter   608/ 1097] train: loss: 0.0145720
[Epoch 117; Iter   638/ 1097] train: loss: 0.0039810
[Epoch 117; Iter   668/ 1097] train: loss: 0.0067443
[Epoch 117; Iter   698/ 1097] train: loss: 0.0868945
[Epoch 119; Iter   450/  960] train: loss: 0.0011760
[Epoch 119; Iter   480/  960] train: loss: 0.0002079
[Epoch 119; Iter   510/  960] train: loss: 0.0002131
[Epoch 119; Iter   540/  960] train: loss: 0.0051162
[Epoch 119; Iter   570/  960] train: loss: 0.0830813
[Epoch 119; Iter   600/  960] train: loss: 0.0045594
[Epoch 119; Iter   630/  960] train: loss: 0.0302551
[Epoch 119; Iter   660/  960] train: loss: 0.0064230
[Epoch 119; Iter   690/  960] train: loss: 0.0006027
[Epoch 119; Iter   720/  960] train: loss: 0.0019218
[Epoch 119; Iter   750/  960] train: loss: 0.0258112
[Epoch 119; Iter   780/  960] train: loss: 0.0099517
[Epoch 119; Iter   810/  960] train: loss: 0.0128269
[Epoch 119; Iter   840/  960] train: loss: 0.0009569
[Epoch 119; Iter   870/  960] train: loss: 0.0006058
[Epoch 119; Iter   900/  960] train: loss: 0.0013225
[Epoch 119; Iter   930/  960] train: loss: 0.0083762
[Epoch 119; Iter   960/  960] train: loss: 0.0005543
[Epoch 119] ogbg-molhiv: 0.716900 val loss: 0.366807
[Epoch 119] ogbg-molhiv: 0.753550 test loss: 0.565482
[Epoch 120; Iter    30/  960] train: loss: 0.0079440
[Epoch 120; Iter    60/  960] train: loss: 0.0104040
[Epoch 120; Iter    90/  960] train: loss: 0.0029256
[Epoch 120; Iter   120/  960] train: loss: 0.0120432
[Epoch 120; Iter   150/  960] train: loss: 0.0101223
[Epoch 120; Iter   180/  960] train: loss: 0.0194230
[Epoch 120; Iter   210/  960] train: loss: 0.0061338
[Epoch 120; Iter   240/  960] train: loss: 0.0018527
[Epoch 120; Iter   270/  960] train: loss: 0.0023471
[Epoch 120; Iter   300/  960] train: loss: 0.0034494
[Epoch 120; Iter   330/  960] train: loss: 0.0018737
[Epoch 120; Iter   360/  960] train: loss: 0.0509136
[Epoch 120; Iter   390/  960] train: loss: 0.0003511
[Epoch 120; Iter   420/  960] train: loss: 0.0073808
[Epoch 120; Iter   450/  960] train: loss: 0.0006568
[Epoch 120; Iter   480/  960] train: loss: 0.0000832
[Epoch 120; Iter   510/  960] train: loss: 0.0174916
[Epoch 120; Iter   540/  960] train: loss: 0.0002860
[Epoch 120; Iter   570/  960] train: loss: 0.0550889
[Epoch 120; Iter   600/  960] train: loss: 0.0010320
[Epoch 120; Iter   630/  960] train: loss: 0.0515783
[Epoch 120; Iter   660/  960] train: loss: 0.0005549
[Epoch 120; Iter   690/  960] train: loss: 0.0002902
[Epoch 120; Iter   720/  960] train: loss: 0.0350761
[Epoch 120; Iter   750/  960] train: loss: 0.0184248
[Epoch 120; Iter   780/  960] train: loss: 0.0009410
[Epoch 120; Iter   810/  960] train: loss: 0.0254468
[Epoch 120; Iter   840/  960] train: loss: 0.0004809
[Epoch 120; Iter   870/  960] train: loss: 0.0777333
[Epoch 120; Iter   900/  960] train: loss: 0.0360480
[Epoch 120; Iter   930/  960] train: loss: 0.0037330
[Epoch 120; Iter   960/  960] train: loss: 0.0118016
[Epoch 120] ogbg-molhiv: 0.719845 val loss: 0.423727
[Epoch 120] ogbg-molhiv: 0.759536 test loss: 0.715864
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 23.
Statistics on  val_best_checkpoint
mean_pred: -4.365061283111572
std_pred: 1.5092467069625854
mean_targets: 0.03128546103835106
std_targets: 0.17410224676132202
prcauc: 0.3159316382263242
rocauc: 0.7704115252027106
ogbg-molhiv: 0.7704115252027106
BCEWithLogitsLoss: 0.11703378100680567
Statistics on  test
mean_pred: -4.355704307556152
std_pred: 1.4007991552352905
mean_targets: 0.025283630937337875
std_targets: 0.15699796378612518
prcauc: 0.248642302525522
rocauc: 0.7743832766280386
ogbg-molhiv: 0.7743832766280386
BCEWithLogitsLoss: 0.1019861711125857
Statistics on  train
mean_pred: -4.224722385406494
std_pred: 1.496411681175232
mean_targets: 0.03800194337964058
std_targets: 0.1912042498588562
prcauc: 0.5518571752904287
rocauc: 0.9119111723590891
ogbg-molhiv: 0.9119111723590891
BCEWithLogitsLoss: 0.09501498191966676
[Epoch 119; Iter   450/  960] train: loss: 0.0008916
[Epoch 119; Iter   480/  960] train: loss: 0.0022426
[Epoch 119; Iter   510/  960] train: loss: 0.0968803
[Epoch 119; Iter   540/  960] train: loss: 0.0068983
[Epoch 119; Iter   570/  960] train: loss: 0.0185707
[Epoch 119; Iter   600/  960] train: loss: 0.0015045
[Epoch 119; Iter   630/  960] train: loss: 0.0120158
[Epoch 119; Iter   660/  960] train: loss: 0.0016978
[Epoch 119; Iter   690/  960] train: loss: 0.0022520
[Epoch 119; Iter   720/  960] train: loss: 0.0193099
[Epoch 119; Iter   750/  960] train: loss: 0.0290816
[Epoch 119; Iter   780/  960] train: loss: 0.1054644
[Epoch 119; Iter   810/  960] train: loss: 0.0149531
[Epoch 119; Iter   840/  960] train: loss: 0.0016892
[Epoch 119; Iter   870/  960] train: loss: 0.0017918
[Epoch 119; Iter   900/  960] train: loss: 0.0082307
[Epoch 119; Iter   930/  960] train: loss: 0.0001456
[Epoch 119; Iter   960/  960] train: loss: 0.0100852
[Epoch 119] ogbg-molhiv: 0.751112 val loss: 1.237105
[Epoch 119] ogbg-molhiv: 0.751237 test loss: 0.326432
[Epoch 120; Iter    30/  960] train: loss: 0.0010370
[Epoch 120; Iter    60/  960] train: loss: 0.0029223
[Epoch 120; Iter    90/  960] train: loss: 0.0361703
[Epoch 120; Iter   120/  960] train: loss: 0.0003316
[Epoch 120; Iter   150/  960] train: loss: 0.0047736
[Epoch 120; Iter   180/  960] train: loss: 0.0110569
[Epoch 120; Iter   210/  960] train: loss: 0.0081105
[Epoch 120; Iter   240/  960] train: loss: 0.0335712
[Epoch 120; Iter   270/  960] train: loss: 0.0025895
[Epoch 120; Iter   300/  960] train: loss: 0.0034856
[Epoch 120; Iter   330/  960] train: loss: 0.0069057
[Epoch 120; Iter   360/  960] train: loss: 0.0010216
[Epoch 120; Iter   390/  960] train: loss: 0.0008748
[Epoch 120; Iter   420/  960] train: loss: 0.0035837
[Epoch 120; Iter   450/  960] train: loss: 0.0029580
[Epoch 120; Iter   480/  960] train: loss: 0.0402098
[Epoch 120; Iter   510/  960] train: loss: 0.0010818
[Epoch 120; Iter   540/  960] train: loss: 0.0754201
[Epoch 120; Iter   570/  960] train: loss: 0.0002721
[Epoch 120; Iter   600/  960] train: loss: 0.0064491
[Epoch 120; Iter   630/  960] train: loss: 0.0935887
[Epoch 120; Iter   660/  960] train: loss: 0.0012508
[Epoch 120; Iter   690/  960] train: loss: 0.0573086
[Epoch 120; Iter   720/  960] train: loss: 0.0010955
[Epoch 120; Iter   750/  960] train: loss: 0.0012042
[Epoch 120; Iter   780/  960] train: loss: 0.0888559
[Epoch 120; Iter   810/  960] train: loss: 0.0051442
[Epoch 120; Iter   840/  960] train: loss: 0.0446534
[Epoch 120; Iter   870/  960] train: loss: 0.0107040
[Epoch 120; Iter   900/  960] train: loss: 0.0179537
[Epoch 120; Iter   930/  960] train: loss: 0.0048813
[Epoch 120; Iter   960/  960] train: loss: 0.0005605
[Epoch 120] ogbg-molhiv: 0.755714 val loss: 0.962806
[Epoch 120] ogbg-molhiv: 0.751708 test loss: 0.294916
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 27.
Statistics on  val_best_checkpoint
mean_pred: -4.200222969055176
std_pred: 9.100226402282715
mean_targets: 0.03128546103835106
std_targets: 0.17410224676132202
prcauc: 0.2841712811279377
rocauc: 0.7850022716080209
ogbg-molhiv: 0.7850022716080209
BCEWithLogitsLoss: 0.2643306625111806
Statistics on  test
mean_pred: -4.353369235992432
std_pred: 2.3896923065185547
mean_targets: 0.025283630937337875
std_targets: 0.15699796378612518
prcauc: 0.16491322262155966
rocauc: 0.7421038943320287
ogbg-molhiv: 0.7421038943320287
BCEWithLogitsLoss: 0.14890622473728743
Statistics on  train
mean_pred: -4.513921737670898
std_pred: 1.711287498474121
mean_targets: 0.03800194337964058
std_targets: 0.1912042498588562
prcauc: 0.5835100177374531
rocauc: 0.9241164441535196
ogbg-molhiv: 0.9241164441535196
BCEWithLogitsLoss: 0.09192629712294244
[Epoch 119; Iter   450/  960] train: loss: 0.0009494
[Epoch 119; Iter   480/  960] train: loss: 0.0017640
[Epoch 119; Iter   510/  960] train: loss: 0.0067051
[Epoch 119; Iter   540/  960] train: loss: 0.0010238
[Epoch 119; Iter   570/  960] train: loss: 0.0018779
[Epoch 119; Iter   600/  960] train: loss: 0.0084060
[Epoch 119; Iter   630/  960] train: loss: 0.0026799
[Epoch 119; Iter   660/  960] train: loss: 0.0803751
[Epoch 119; Iter   690/  960] train: loss: 0.0054933
[Epoch 119; Iter   720/  960] train: loss: 0.0121963
[Epoch 119; Iter   750/  960] train: loss: 0.0405727
[Epoch 119; Iter   780/  960] train: loss: 0.0027145
[Epoch 119; Iter   810/  960] train: loss: 0.0067846
[Epoch 119; Iter   840/  960] train: loss: 0.0012779
[Epoch 119; Iter   870/  960] train: loss: 0.0171319
[Epoch 119; Iter   900/  960] train: loss: 0.0095256
[Epoch 119; Iter   930/  960] train: loss: 0.0040401
[Epoch 119; Iter   960/  960] train: loss: 0.2055740
[Epoch 119] ogbg-molhiv: 0.714272 val loss: 1.131593
[Epoch 119] ogbg-molhiv: 0.743485 test loss: 0.682064
[Epoch 120; Iter    30/  960] train: loss: 0.1276200
[Epoch 120; Iter    60/  960] train: loss: 0.0020909
[Epoch 120; Iter    90/  960] train: loss: 0.0014827
[Epoch 120; Iter   120/  960] train: loss: 0.0218011
[Epoch 120; Iter   150/  960] train: loss: 0.0350480
[Epoch 120; Iter   180/  960] train: loss: 0.0004733
[Epoch 120; Iter   210/  960] train: loss: 0.0084073
[Epoch 120; Iter   240/  960] train: loss: 0.0042811
[Epoch 120; Iter   270/  960] train: loss: 0.0027298
[Epoch 120; Iter   300/  960] train: loss: 0.0004363
[Epoch 120; Iter   330/  960] train: loss: 0.0173694
[Epoch 120; Iter   360/  960] train: loss: 0.0051471
[Epoch 120; Iter   390/  960] train: loss: 0.0228246
[Epoch 120; Iter   420/  960] train: loss: 0.0025208
[Epoch 120; Iter   450/  960] train: loss: 0.0015320
[Epoch 120; Iter   480/  960] train: loss: 0.0056555
[Epoch 120; Iter   510/  960] train: loss: 0.0092291
[Epoch 120; Iter   540/  960] train: loss: 0.0155246
[Epoch 120; Iter   570/  960] train: loss: 0.0003389
[Epoch 120; Iter   600/  960] train: loss: 0.0274713
[Epoch 120; Iter   630/  960] train: loss: 0.0007875
[Epoch 120; Iter   660/  960] train: loss: 0.0093242
[Epoch 120; Iter   690/  960] train: loss: 0.1173704
[Epoch 120; Iter   720/  960] train: loss: 0.0007020
[Epoch 120; Iter   750/  960] train: loss: 0.0006126
[Epoch 120; Iter   780/  960] train: loss: 0.0130984
[Epoch 120; Iter   810/  960] train: loss: 0.0057319
[Epoch 120; Iter   840/  960] train: loss: 0.0410486
[Epoch 120; Iter   870/  960] train: loss: 0.0052418
[Epoch 120; Iter   900/  960] train: loss: 0.0438997
[Epoch 120; Iter   930/  960] train: loss: 0.0055713
[Epoch 120; Iter   960/  960] train: loss: 0.0488035
[Epoch 120] ogbg-molhiv: 0.718094 val loss: 0.435603
[Epoch 120] ogbg-molhiv: 0.747848 test loss: 0.326725
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 23.
Statistics on  val_best_checkpoint
mean_pred: -3.941765546798706
std_pred: 1.5437005758285522
mean_targets: 0.03128546103835106
std_targets: 0.17410224676132202
prcauc: 0.2727486129466066
rocauc: 0.7774379036005854
ogbg-molhiv: 0.7774379036005854
BCEWithLogitsLoss: 0.13169411500210612
Statistics on  test
mean_pred: -3.9329493045806885
std_pred: 1.4584712982177734
mean_targets: 0.025283630937337875
std_targets: 0.15699796378612518
prcauc: 0.22943082315183075
rocauc: 0.7634110153232203
ogbg-molhiv: 0.7634110153232203
BCEWithLogitsLoss: 0.11655297164705772
Statistics on  train
mean_pred: -4.121524333953857
std_pred: 1.5959066152572632
mean_targets: 0.03800194337964058
std_targets: 0.1912042498588562
prcauc: 0.49390722139127236
rocauc: 0.9012877280290519
ogbg-molhiv: 0.9012877280290519
BCEWithLogitsLoss: 0.10529929296268771
All runs completed.
[Epoch 127; Iter    12/  823] train: loss: 0.0004439
[Epoch 127; Iter    42/  823] train: loss: 0.1291951
[Epoch 127; Iter    72/  823] train: loss: 0.0091961
[Epoch 127; Iter   102/  823] train: loss: 0.0058923
[Epoch 127; Iter   132/  823] train: loss: 0.0000422
[Epoch 127; Iter   162/  823] train: loss: 0.0076942
[Epoch 127; Iter   192/  823] train: loss: 0.0017376
[Epoch 127; Iter   222/  823] train: loss: 0.0606994
[Epoch 127; Iter   252/  823] train: loss: 0.0122728
[Epoch 127; Iter   282/  823] train: loss: 0.0039067
[Epoch 127; Iter   312/  823] train: loss: 0.0320881
[Epoch 127; Iter   342/  823] train: loss: 0.0021847
[Epoch 127; Iter   372/  823] train: loss: 0.0010691
[Epoch 127; Iter   402/  823] train: loss: 0.0012391
[Epoch 127; Iter   432/  823] train: loss: 0.0218075
[Epoch 127; Iter   462/  823] train: loss: 0.0001534
[Epoch 127; Iter   492/  823] train: loss: 0.0033563
[Epoch 127; Iter   522/  823] train: loss: 0.0016749
[Epoch 127; Iter   552/  823] train: loss: 0.0045318
[Epoch 127; Iter   582/  823] train: loss: 0.0428696
[Epoch 127; Iter   612/  823] train: loss: 0.0001118
[Epoch 127; Iter   642/  823] train: loss: 0.0130149
[Epoch 127; Iter   672/  823] train: loss: 0.0051380
[Epoch 127; Iter   702/  823] train: loss: 0.0028733
[Epoch 127; Iter   732/  823] train: loss: 0.0008267
[Epoch 127; Iter   762/  823] train: loss: 0.0017238
[Epoch 127; Iter   792/  823] train: loss: 0.0676950
[Epoch 127; Iter   822/  823] train: loss: 0.0069464
[Epoch 127] ogbg-molhiv: 0.743065 val loss: 0.525028
[Epoch 127] ogbg-molhiv: 0.765544 test loss: 0.560060
[Epoch 128; Iter    29/  823] train: loss: 0.0006056
[Epoch 128; Iter    59/  823] train: loss: 0.0026322
[Epoch 128; Iter    89/  823] train: loss: 0.0046336
[Epoch 128; Iter   119/  823] train: loss: 0.0019946
[Epoch 128; Iter   149/  823] train: loss: 0.0134127
[Epoch 128; Iter   179/  823] train: loss: 0.0013589
[Epoch 128; Iter   209/  823] train: loss: 0.0499172
[Epoch 128; Iter   239/  823] train: loss: 0.0020788
[Epoch 128; Iter   269/  823] train: loss: 0.0001280
[Epoch 128; Iter   299/  823] train: loss: 0.0041541
[Epoch 128; Iter   329/  823] train: loss: 0.0162597
[Epoch 128; Iter   359/  823] train: loss: 0.0152084
[Epoch 128; Iter   389/  823] train: loss: 0.0498292
[Epoch 128; Iter   419/  823] train: loss: 0.0033022
[Epoch 128; Iter   449/  823] train: loss: 0.0031214
[Epoch 128; Iter   479/  823] train: loss: 0.0043543
[Epoch 128; Iter   509/  823] train: loss: 0.0008180
[Epoch 128; Iter   539/  823] train: loss: 0.0518805
[Epoch 128; Iter   569/  823] train: loss: 0.0004286
[Epoch 128; Iter   599/  823] train: loss: 0.0008248
[Epoch 128; Iter   629/  823] train: loss: 0.0012802
[Epoch 128; Iter   659/  823] train: loss: 0.0001379
[Epoch 128; Iter   689/  823] train: loss: 0.0607055
[Epoch 128; Iter   719/  823] train: loss: 0.0180839
[Epoch 128; Iter   749/  823] train: loss: 0.0008691
[Epoch 128; Iter   779/  823] train: loss: 0.0288807
[Epoch 128; Iter   809/  823] train: loss: 0.0033673
[Epoch 128] ogbg-molhiv: 0.739559 val loss: 0.322138
[Epoch 128] ogbg-molhiv: 0.756280 test loss: 0.235789
[Epoch 129; Iter    16/  823] train: loss: 0.0022804
[Epoch 129; Iter    46/  823] train: loss: 0.0025316
[Epoch 129; Iter    76/  823] train: loss: 0.0016311
[Epoch 129; Iter   106/  823] train: loss: 0.0179250
[Epoch 129; Iter   136/  823] train: loss: 0.0021736
[Epoch 129; Iter   166/  823] train: loss: 0.0008796
[Epoch 129; Iter   196/  823] train: loss: 0.0024587
[Epoch 129; Iter   226/  823] train: loss: 0.0003273
[Epoch 129; Iter   256/  823] train: loss: 0.0007831
[Epoch 129; Iter   286/  823] train: loss: 0.0392223
[Epoch 129; Iter   316/  823] train: loss: 0.0287453
[Epoch 129; Iter   346/  823] train: loss: 0.0065984
[Epoch 129; Iter   376/  823] train: loss: 0.0009069
[Epoch 129; Iter   406/  823] train: loss: 0.0002994
[Epoch 129; Iter   436/  823] train: loss: 0.0001345
[Epoch 129; Iter   466/  823] train: loss: 0.0042649
[Epoch 129; Iter   496/  823] train: loss: 0.0103993
[Epoch 129; Iter   526/  823] train: loss: 0.0004718
[Epoch 129; Iter   556/  823] train: loss: 0.0018354
[Epoch 129; Iter   586/  823] train: loss: 0.0677763
[Epoch 129; Iter   616/  823] train: loss: 0.0193747
[Epoch 129; Iter   646/  823] train: loss: 0.0039999
[Epoch 129; Iter   676/  823] train: loss: 0.0028602
[Epoch 129; Iter   706/  823] train: loss: 0.0015032
[Epoch 129; Iter   736/  823] train: loss: 0.0434485
[Epoch 129; Iter   766/  823] train: loss: 0.0018260
[Epoch 129; Iter   796/  823] train: loss: 0.0035444
[Epoch 129] ogbg-molhiv: 0.737401 val loss: 0.563157
[Epoch 129] ogbg-molhiv: 0.754997 test loss: 0.587011
[Epoch 130; Iter     3/  823] train: loss: 0.0864907
[Epoch 130; Iter    33/  823] train: loss: 0.0020153
[Epoch 130; Iter    63/  823] train: loss: 0.0002603
[Epoch 130; Iter    93/  823] train: loss: 0.0016768
[Epoch 130; Iter   123/  823] train: loss: 0.0102722
[Epoch 130; Iter   153/  823] train: loss: 0.0025645
[Epoch 130; Iter   183/  823] train: loss: 0.0434508
[Epoch 130; Iter   213/  823] train: loss: 0.0005267
[Epoch 130; Iter   243/  823] train: loss: 0.0006310
[Epoch 130; Iter   273/  823] train: loss: 0.0262552
[Epoch 130; Iter   303/  823] train: loss: 0.0093519
[Epoch 130; Iter   333/  823] train: loss: 0.0029609
[Epoch 130; Iter   363/  823] train: loss: 0.0019564
[Epoch 130; Iter   393/  823] train: loss: 0.0011293
[Epoch 130; Iter   423/  823] train: loss: 0.0018556
[Epoch 130; Iter   453/  823] train: loss: 0.0169111
[Epoch 130; Iter   483/  823] train: loss: 0.0044833
[Epoch 130; Iter   513/  823] train: loss: 0.0093710
[Epoch 130; Iter   543/  823] train: loss: 0.0963300
[Epoch 130; Iter   573/  823] train: loss: 0.0014011
[Epoch 130; Iter   603/  823] train: loss: 0.0007406
[Epoch 130; Iter   633/  823] train: loss: 0.0425625
[Epoch 130; Iter   663/  823] train: loss: 0.0046072
[Epoch 130; Iter   693/  823] train: loss: 0.0025206
[Epoch 130; Iter   723/  823] train: loss: 0.0011977
[Epoch 130; Iter   753/  823] train: loss: 0.0141266
[Epoch 130; Iter   783/  823] train: loss: 0.0288893
[Epoch 130; Iter   813/  823] train: loss: 0.0036815
[Epoch 130] ogbg-molhiv: 0.736974 val loss: 0.319304
[Epoch 130] ogbg-molhiv: 0.759417 test loss: 0.232198
[Epoch 131; Iter    20/  823] train: loss: 0.0301124
[Epoch 131; Iter    50/  823] train: loss: 0.0055792
[Epoch 131; Iter    80/  823] train: loss: 0.0052552
[Epoch 131; Iter   110/  823] train: loss: 0.0048244
[Epoch 131; Iter   140/  823] train: loss: 0.0006348
[Epoch 131; Iter   170/  823] train: loss: 0.0010712
[Epoch 131; Iter   200/  823] train: loss: 0.0006883
[Epoch 131; Iter   230/  823] train: loss: 0.0006373
[Epoch 131; Iter   260/  823] train: loss: 0.0028233
[Epoch 131; Iter   290/  823] train: loss: 0.0014974
[Epoch 131; Iter   320/  823] train: loss: 0.0345375
[Epoch 131; Iter   350/  823] train: loss: 0.0003741
[Epoch 131; Iter   380/  823] train: loss: 0.0002069
[Epoch 131; Iter   410/  823] train: loss: 0.0013557
[Epoch 131; Iter   440/  823] train: loss: 0.0125787
[Epoch 131; Iter   470/  823] train: loss: 0.0075919
[Epoch 131; Iter   500/  823] train: loss: 0.0219812
[Epoch 131; Iter   530/  823] train: loss: 0.0051351
[Epoch 131; Iter   560/  823] train: loss: 0.0004072
[Epoch 131; Iter   590/  823] train: loss: 0.0015013
[Epoch 131; Iter   620/  823] train: loss: 0.0100839
[Epoch 131; Iter   650/  823] train: loss: 0.0872426
[Epoch 131; Iter   680/  823] train: loss: 0.0017291
[Epoch 131; Iter   710/  823] train: loss: 0.0007883
[Epoch 131; Iter   740/  823] train: loss: 0.0180257
[Epoch 131; Iter   770/  823] train: loss: 0.0003593
[Epoch 131; Iter   800/  823] train: loss: 0.0142137
[Epoch 131] ogbg-molhiv: 0.742558 val loss: 0.326990
[Epoch 131] ogbg-molhiv: 0.767350 test loss: 0.238125
[Epoch 132; Iter     7/  823] train: loss: 0.0147580
[Epoch 132; Iter    37/  823] train: loss: 0.0010667
[Epoch 132; Iter    67/  823] train: loss: 0.1316352
[Epoch 132; Iter    97/  823] train: loss: 0.0002597
[Epoch 132; Iter   127/  823] train: loss: 0.0004428
[Epoch 132; Iter   157/  823] train: loss: 0.0008994
[Epoch 132; Iter   187/  823] train: loss: 0.0006572
[Epoch 113; Iter   736/ 1097] train: loss: 0.0048273
[Epoch 113; Iter   766/ 1097] train: loss: 0.0013875
[Epoch 113; Iter   796/ 1097] train: loss: 0.0024919
[Epoch 113; Iter   826/ 1097] train: loss: 0.0020626
[Epoch 113; Iter   856/ 1097] train: loss: 0.0004631
[Epoch 113; Iter   886/ 1097] train: loss: 0.0021402
[Epoch 113; Iter   916/ 1097] train: loss: 0.0002436
[Epoch 113; Iter   946/ 1097] train: loss: 0.0035665
[Epoch 113; Iter   976/ 1097] train: loss: 0.0034975
[Epoch 113; Iter  1006/ 1097] train: loss: 0.0044910
[Epoch 113; Iter  1036/ 1097] train: loss: 0.0031181
[Epoch 113; Iter  1066/ 1097] train: loss: 0.0071213
[Epoch 113; Iter  1096/ 1097] train: loss: 0.0006887
[Epoch 113] ogbg-molhiv: 0.789869 val loss: 0.143442
[Epoch 113] ogbg-molhiv: 0.763557 test loss: 0.253582
[Epoch 114; Iter    29/ 1097] train: loss: 0.0120998
[Epoch 114; Iter    59/ 1097] train: loss: 0.0098989
[Epoch 114; Iter    89/ 1097] train: loss: 0.0027357
[Epoch 114; Iter   119/ 1097] train: loss: 0.0297329
[Epoch 114; Iter   149/ 1097] train: loss: 0.0009250
[Epoch 114; Iter   179/ 1097] train: loss: 0.0023198
[Epoch 114; Iter   209/ 1097] train: loss: 0.0026577
[Epoch 114; Iter   239/ 1097] train: loss: 0.0005494
[Epoch 114; Iter   269/ 1097] train: loss: 0.0028486
[Epoch 114; Iter   299/ 1097] train: loss: 0.1066697
[Epoch 114; Iter   329/ 1097] train: loss: 0.0193615
[Epoch 114; Iter   359/ 1097] train: loss: 0.1003597
[Epoch 114; Iter   389/ 1097] train: loss: 0.0187705
[Epoch 114; Iter   419/ 1097] train: loss: 0.1360208
[Epoch 114; Iter   449/ 1097] train: loss: 0.0019617
[Epoch 114; Iter   479/ 1097] train: loss: 0.0232731
[Epoch 114; Iter   509/ 1097] train: loss: 0.0021819
[Epoch 114; Iter   539/ 1097] train: loss: 0.0019452
[Epoch 114; Iter   569/ 1097] train: loss: 0.0006962
[Epoch 114; Iter   599/ 1097] train: loss: 0.0008978
[Epoch 114; Iter   629/ 1097] train: loss: 0.0055522
[Epoch 114; Iter   659/ 1097] train: loss: 0.0013053
[Epoch 114; Iter   689/ 1097] train: loss: 0.0196687
[Epoch 114; Iter   719/ 1097] train: loss: 0.0086239
[Epoch 114; Iter   749/ 1097] train: loss: 0.0238568
[Epoch 114; Iter   779/ 1097] train: loss: 0.0252446
[Epoch 114; Iter   809/ 1097] train: loss: 0.0082279
[Epoch 114; Iter   839/ 1097] train: loss: 0.0033569
[Epoch 114; Iter   869/ 1097] train: loss: 0.1775830
[Epoch 114; Iter   899/ 1097] train: loss: 0.1519861
[Epoch 114; Iter   929/ 1097] train: loss: 0.0021137
[Epoch 114; Iter   959/ 1097] train: loss: 0.0084215
[Epoch 114; Iter   989/ 1097] train: loss: 0.0034177
[Epoch 114; Iter  1019/ 1097] train: loss: 0.1222422
[Epoch 114; Iter  1049/ 1097] train: loss: 0.0555368
[Epoch 114; Iter  1079/ 1097] train: loss: 0.0009600
[Epoch 114] ogbg-molhiv: 0.792931 val loss: 0.143225
[Epoch 114] ogbg-molhiv: 0.759704 test loss: 0.259419
[Epoch 115; Iter    12/ 1097] train: loss: 0.0006946
[Epoch 115; Iter    42/ 1097] train: loss: 0.1169354
[Epoch 115; Iter    72/ 1097] train: loss: 0.0044693
[Epoch 115; Iter   102/ 1097] train: loss: 0.1478928
[Epoch 115; Iter   132/ 1097] train: loss: 0.0048494
[Epoch 115; Iter   162/ 1097] train: loss: 0.0036747
[Epoch 115; Iter   192/ 1097] train: loss: 0.0319338
[Epoch 115; Iter   222/ 1097] train: loss: 0.0045511
[Epoch 115; Iter   252/ 1097] train: loss: 0.0044799
[Epoch 115; Iter   282/ 1097] train: loss: 0.0039342
[Epoch 115; Iter   312/ 1097] train: loss: 0.0034578
[Epoch 115; Iter   342/ 1097] train: loss: 0.0018035
[Epoch 115; Iter   372/ 1097] train: loss: 0.0023394
[Epoch 115; Iter   402/ 1097] train: loss: 0.0004537
[Epoch 115; Iter   432/ 1097] train: loss: 0.0033231
[Epoch 115; Iter   462/ 1097] train: loss: 0.0008080
[Epoch 115; Iter   492/ 1097] train: loss: 0.0019762
[Epoch 115; Iter   522/ 1097] train: loss: 0.0778765
[Epoch 115; Iter   552/ 1097] train: loss: 0.0015895
[Epoch 115; Iter   582/ 1097] train: loss: 0.0005040
[Epoch 115; Iter   612/ 1097] train: loss: 0.0556811
[Epoch 115; Iter   642/ 1097] train: loss: 0.0021996
[Epoch 115; Iter   672/ 1097] train: loss: 0.0009420
[Epoch 115; Iter   702/ 1097] train: loss: 0.0061593
[Epoch 115; Iter   732/ 1097] train: loss: 0.0030230
[Epoch 115; Iter   762/ 1097] train: loss: 0.0031673
[Epoch 115; Iter   792/ 1097] train: loss: 0.0118120
[Epoch 115; Iter   822/ 1097] train: loss: 0.0007151
[Epoch 115; Iter   852/ 1097] train: loss: 0.0522364
[Epoch 115; Iter   882/ 1097] train: loss: 0.0106417
[Epoch 115; Iter   912/ 1097] train: loss: 0.0018187
[Epoch 115; Iter   942/ 1097] train: loss: 0.0384479
[Epoch 115; Iter   972/ 1097] train: loss: 0.0061402
[Epoch 115; Iter  1002/ 1097] train: loss: 0.0146394
[Epoch 115; Iter  1032/ 1097] train: loss: 0.0066232
[Epoch 115; Iter  1062/ 1097] train: loss: 0.0131897
[Epoch 115; Iter  1092/ 1097] train: loss: 0.0215730
[Epoch 115] ogbg-molhiv: 0.792346 val loss: 0.142165
[Epoch 115] ogbg-molhiv: 0.766707 test loss: 0.252582
[Epoch 116; Iter    25/ 1097] train: loss: 0.0082804
[Epoch 116; Iter    55/ 1097] train: loss: 0.0026738
[Epoch 116; Iter    85/ 1097] train: loss: 0.0059051
[Epoch 116; Iter   115/ 1097] train: loss: 0.0287340
[Epoch 116; Iter   145/ 1097] train: loss: 0.0020105
[Epoch 116; Iter   175/ 1097] train: loss: 0.0901274
[Epoch 116; Iter   205/ 1097] train: loss: 0.0496566
[Epoch 116; Iter   235/ 1097] train: loss: 0.0018096
[Epoch 116; Iter   265/ 1097] train: loss: 0.0026951
[Epoch 116; Iter   295/ 1097] train: loss: 0.0362527
[Epoch 116; Iter   325/ 1097] train: loss: 0.0006013
[Epoch 116; Iter   355/ 1097] train: loss: 0.0008311
[Epoch 116; Iter   385/ 1097] train: loss: 0.0087221
[Epoch 116; Iter   415/ 1097] train: loss: 0.0012086
[Epoch 116; Iter   445/ 1097] train: loss: 0.0015037
[Epoch 116; Iter   475/ 1097] train: loss: 0.0318232
[Epoch 116; Iter   505/ 1097] train: loss: 0.0006860
[Epoch 116; Iter   535/ 1097] train: loss: 0.0006864
[Epoch 116; Iter   565/ 1097] train: loss: 0.0239903
[Epoch 116; Iter   595/ 1097] train: loss: 0.0004579
[Epoch 116; Iter   625/ 1097] train: loss: 0.0468109
[Epoch 116; Iter   655/ 1097] train: loss: 0.0236785
[Epoch 116; Iter   685/ 1097] train: loss: 0.0006432
[Epoch 116; Iter   715/ 1097] train: loss: 0.0088234
[Epoch 116; Iter   745/ 1097] train: loss: 0.0472124
[Epoch 116; Iter   775/ 1097] train: loss: 0.0030479
[Epoch 116; Iter   805/ 1097] train: loss: 0.0038881
[Epoch 116; Iter   835/ 1097] train: loss: 0.0057904
[Epoch 116; Iter   865/ 1097] train: loss: 0.0743623
[Epoch 116; Iter   895/ 1097] train: loss: 0.0003458
[Epoch 116; Iter   925/ 1097] train: loss: 0.0002269
[Epoch 116; Iter   955/ 1097] train: loss: 0.0103894
[Epoch 116; Iter   985/ 1097] train: loss: 0.0129405
[Epoch 116; Iter  1015/ 1097] train: loss: 0.0106495
[Epoch 116; Iter  1045/ 1097] train: loss: 0.0100921
[Epoch 116; Iter  1075/ 1097] train: loss: 0.0031933
[Epoch 116] ogbg-molhiv: 0.789955 val loss: 0.149153
[Epoch 116] ogbg-molhiv: 0.758792 test loss: 0.263888
[Epoch 117; Iter     8/ 1097] train: loss: 0.0250948
[Epoch 117; Iter    38/ 1097] train: loss: 0.0305874
[Epoch 117; Iter    68/ 1097] train: loss: 0.0070020
[Epoch 117; Iter    98/ 1097] train: loss: 0.0116410
[Epoch 117; Iter   128/ 1097] train: loss: 0.0081430
[Epoch 117; Iter   158/ 1097] train: loss: 0.0253740
[Epoch 117; Iter   188/ 1097] train: loss: 0.0008244
[Epoch 117; Iter   218/ 1097] train: loss: 0.0012881
[Epoch 117; Iter   248/ 1097] train: loss: 0.0005218
[Epoch 117; Iter   278/ 1097] train: loss: 0.0220874
[Epoch 117; Iter   308/ 1097] train: loss: 0.0038960
[Epoch 117; Iter   338/ 1097] train: loss: 0.0014696
[Epoch 117; Iter   368/ 1097] train: loss: 0.0029063
[Epoch 117; Iter   398/ 1097] train: loss: 0.0023121
[Epoch 117; Iter   428/ 1097] train: loss: 0.0004991
[Epoch 117; Iter   458/ 1097] train: loss: 0.0009781
[Epoch 117; Iter   488/ 1097] train: loss: 0.0262550
[Epoch 117; Iter   518/ 1097] train: loss: 0.0027603
[Epoch 117; Iter   548/ 1097] train: loss: 0.0278887
[Epoch 117; Iter   578/ 1097] train: loss: 0.0069881
[Epoch 117; Iter   608/ 1097] train: loss: 0.0079818
[Epoch 117; Iter   638/ 1097] train: loss: 0.0021566
[Epoch 117; Iter   668/ 1097] train: loss: 0.0001851
[Epoch 117; Iter   698/ 1097] train: loss: 0.0677960
[Epoch 132; Iter   217/  823] train: loss: 0.0045499
[Epoch 132; Iter   247/  823] train: loss: 0.0009163
[Epoch 132; Iter   277/  823] train: loss: 0.0155969
[Epoch 132; Iter   307/  823] train: loss: 0.0022077
[Epoch 132; Iter   337/  823] train: loss: 0.0006426
[Epoch 132; Iter   367/  823] train: loss: 0.1537429
[Epoch 132; Iter   397/  823] train: loss: 0.0138004
[Epoch 132; Iter   427/  823] train: loss: 0.0009297
[Epoch 132; Iter   457/  823] train: loss: 0.0105691
[Epoch 132; Iter   487/  823] train: loss: 0.0077770
[Epoch 132; Iter   517/  823] train: loss: 0.0005125
[Epoch 132; Iter   547/  823] train: loss: 0.0046774
[Epoch 132; Iter   577/  823] train: loss: 0.0025694
[Epoch 132; Iter   607/  823] train: loss: 0.0009345
[Epoch 132; Iter   637/  823] train: loss: 0.0833842
[Epoch 132; Iter   667/  823] train: loss: 0.0014521
[Epoch 132; Iter   697/  823] train: loss: 0.0027561
[Epoch 132; Iter   727/  823] train: loss: 0.0009392
[Epoch 132; Iter   757/  823] train: loss: 0.1204240
[Epoch 132; Iter   787/  823] train: loss: 0.0756139
[Epoch 132; Iter   817/  823] train: loss: 0.0004748
[Epoch 132] ogbg-molhiv: 0.738146 val loss: 0.334808
[Epoch 132] ogbg-molhiv: 0.758134 test loss: 0.246161
[Epoch 133; Iter    24/  823] train: loss: 0.0780510
[Epoch 133; Iter    54/  823] train: loss: 0.0012856
[Epoch 133; Iter    84/  823] train: loss: 0.0004222
[Epoch 133; Iter   114/  823] train: loss: 0.0016698
[Epoch 133; Iter   144/  823] train: loss: 0.0035425
[Epoch 133; Iter   174/  823] train: loss: 0.0003617
[Epoch 133; Iter   204/  823] train: loss: 0.0031872
[Epoch 133; Iter   234/  823] train: loss: 0.0029863
[Epoch 133; Iter   264/  823] train: loss: 0.0605481
[Epoch 133; Iter   294/  823] train: loss: 0.0050982
[Epoch 133; Iter   324/  823] train: loss: 0.0160641
[Epoch 133; Iter   354/  823] train: loss: 0.0013256
[Epoch 133; Iter   384/  823] train: loss: 0.0007567
[Epoch 133; Iter   414/  823] train: loss: 0.0002116
[Epoch 133; Iter   444/  823] train: loss: 0.0002448
[Epoch 133; Iter   474/  823] train: loss: 0.0027092
[Epoch 133; Iter   504/  823] train: loss: 0.0815849
[Epoch 133; Iter   534/  823] train: loss: 0.0027894
[Epoch 133; Iter   564/  823] train: loss: 0.0020231
[Epoch 133; Iter   594/  823] train: loss: 0.0019668
[Epoch 133; Iter   624/  823] train: loss: 0.0050169
[Epoch 133; Iter   654/  823] train: loss: 0.0487203
[Epoch 133; Iter   684/  823] train: loss: 0.0034860
[Epoch 133; Iter   714/  823] train: loss: 0.0017470
[Epoch 133; Iter   744/  823] train: loss: 0.0003392
[Epoch 133; Iter   774/  823] train: loss: 0.0033460
[Epoch 133; Iter   804/  823] train: loss: 0.0021309
[Epoch 133] ogbg-molhiv: 0.735069 val loss: 0.333403
[Epoch 133] ogbg-molhiv: 0.751509 test loss: 0.266568
[Epoch 134; Iter    11/  823] train: loss: 0.0026477
[Epoch 134; Iter    41/  823] train: loss: 0.0001362
[Epoch 134; Iter    71/  823] train: loss: 0.1327288
[Epoch 134; Iter   101/  823] train: loss: 0.0545737
[Epoch 134; Iter   131/  823] train: loss: 0.0001614
[Epoch 134; Iter   161/  823] train: loss: 0.0006295
[Epoch 134; Iter   191/  823] train: loss: 0.0010504
[Epoch 134; Iter   221/  823] train: loss: 0.0008532
[Epoch 134; Iter   251/  823] train: loss: 0.0008541
[Epoch 134; Iter   281/  823] train: loss: 0.0116378
[Epoch 134; Iter   311/  823] train: loss: 0.0092556
[Epoch 134; Iter   341/  823] train: loss: 0.0002263
[Epoch 134; Iter   371/  823] train: loss: 0.0012769
[Epoch 134; Iter   401/  823] train: loss: 0.0045828
[Epoch 134; Iter   431/  823] train: loss: 0.0016779
[Epoch 134; Iter   461/  823] train: loss: 0.0019252
[Epoch 134; Iter   491/  823] train: loss: 0.0017422
[Epoch 134; Iter   521/  823] train: loss: 0.0001940
[Epoch 134; Iter   551/  823] train: loss: 0.0474052
[Epoch 134; Iter   581/  823] train: loss: 0.0014581
[Epoch 134; Iter   611/  823] train: loss: 0.0107056
[Epoch 134; Iter   641/  823] train: loss: 0.0040593
[Epoch 134; Iter   671/  823] train: loss: 0.0020354
[Epoch 134; Iter   701/  823] train: loss: 0.0072427
[Epoch 134; Iter   731/  823] train: loss: 0.0927498
[Epoch 134; Iter   761/  823] train: loss: 0.0428152
[Epoch 134; Iter   791/  823] train: loss: 0.0344487
[Epoch 134; Iter   821/  823] train: loss: 0.0042574
[Epoch 134] ogbg-molhiv: 0.742965 val loss: 0.354693
[Epoch 134] ogbg-molhiv: 0.759089 test loss: 0.282732
[Epoch 135; Iter    28/  823] train: loss: 0.0119771
[Epoch 135; Iter    58/  823] train: loss: 0.0003466
[Epoch 135; Iter    88/  823] train: loss: 0.0432666
[Epoch 135; Iter   118/  823] train: loss: 0.0012074
[Epoch 135; Iter   148/  823] train: loss: 0.0065283
[Epoch 135; Iter   178/  823] train: loss: 0.0196871
[Epoch 135; Iter   208/  823] train: loss: 0.0008521
[Epoch 135; Iter   238/  823] train: loss: 0.0015206
[Epoch 135; Iter   268/  823] train: loss: 0.0059971
[Epoch 135; Iter   298/  823] train: loss: 0.0010625
[Epoch 135; Iter   328/  823] train: loss: 0.0011269
[Epoch 135; Iter   358/  823] train: loss: 0.0031827
[Epoch 135; Iter   388/  823] train: loss: 0.0002140
[Epoch 135; Iter   418/  823] train: loss: 0.0032312
[Epoch 135; Iter   448/  823] train: loss: 0.0038415
[Epoch 135; Iter   478/  823] train: loss: 0.0085458
[Epoch 135; Iter   508/  823] train: loss: 0.0008635
[Epoch 135; Iter   538/  823] train: loss: 0.0273135
[Epoch 135; Iter   568/  823] train: loss: 0.0500459
[Epoch 135; Iter   598/  823] train: loss: 0.0165697
[Epoch 135; Iter   628/  823] train: loss: 0.0055781
[Epoch 135; Iter   658/  823] train: loss: 0.0284394
[Epoch 135; Iter   688/  823] train: loss: 0.0328853
[Epoch 135; Iter   718/  823] train: loss: 0.0022886
[Epoch 135; Iter   748/  823] train: loss: 0.0174119
[Epoch 135; Iter   778/  823] train: loss: 0.0008040
[Epoch 135; Iter   808/  823] train: loss: 0.0108400
[Epoch 135] ogbg-molhiv: 0.745514 val loss: 0.623559
[Epoch 135] ogbg-molhiv: 0.759948 test loss: 0.633680
[Epoch 136; Iter    15/  823] train: loss: 0.0029747
[Epoch 136; Iter    45/  823] train: loss: 0.0070556
[Epoch 136; Iter    75/  823] train: loss: 0.0015142
[Epoch 136; Iter   105/  823] train: loss: 0.0089800
[Epoch 136; Iter   135/  823] train: loss: 0.0611883
[Epoch 136; Iter   165/  823] train: loss: 0.0037604
[Epoch 136; Iter   195/  823] train: loss: 0.0008192
[Epoch 136; Iter   225/  823] train: loss: 0.0077972
[Epoch 136; Iter   255/  823] train: loss: 0.0012831
[Epoch 136; Iter   285/  823] train: loss: 0.0079423
[Epoch 136; Iter   315/  823] train: loss: 0.0032344
[Epoch 136; Iter   345/  823] train: loss: 0.0015885
[Epoch 136; Iter   375/  823] train: loss: 0.0008359
[Epoch 136; Iter   405/  823] train: loss: 0.0184771
[Epoch 136; Iter   435/  823] train: loss: 0.0000947
[Epoch 136; Iter   465/  823] train: loss: 0.0028780
[Epoch 136; Iter   495/  823] train: loss: 0.0017601
[Epoch 136; Iter   525/  823] train: loss: 0.0005089
[Epoch 136; Iter   555/  823] train: loss: 0.0434854
[Epoch 136; Iter   585/  823] train: loss: 0.0186937
[Epoch 136; Iter   615/  823] train: loss: 0.0037968
[Epoch 136; Iter   645/  823] train: loss: 0.0077233
[Epoch 136; Iter   675/  823] train: loss: 0.0002093
[Epoch 136; Iter   705/  823] train: loss: 0.0004951
[Epoch 136; Iter   735/  823] train: loss: 0.0014948
[Epoch 136; Iter   765/  823] train: loss: 0.0038105
[Epoch 136; Iter   795/  823] train: loss: 0.0040389
[Epoch 136] ogbg-molhiv: 0.739836 val loss: 0.536191
[Epoch 136] ogbg-molhiv: 0.756596 test loss: 0.590250
[Epoch 137; Iter     2/  823] train: loss: 0.0066505
[Epoch 137; Iter    32/  823] train: loss: 0.0006167
[Epoch 137; Iter    62/  823] train: loss: 0.0010292
[Epoch 137; Iter    92/  823] train: loss: 0.0035655
[Epoch 137; Iter   122/  823] train: loss: 0.0006616
[Epoch 137; Iter   152/  823] train: loss: 0.0025301
[Epoch 137; Iter   182/  823] train: loss: 0.0013286
[Epoch 137; Iter   212/  823] train: loss: 0.0115937
[Epoch 137; Iter   242/  823] train: loss: 0.0022841
[Epoch 137; Iter   272/  823] train: loss: 0.0014790
[Epoch 137; Iter   302/  823] train: loss: 0.0031908
[Epoch 137; Iter   332/  823] train: loss: 0.0011065
[Epoch 137; Iter   362/  823] train: loss: 0.0012082
[Epoch 137; Iter   392/  823] train: loss: 0.0003992
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 117; Iter   728/ 1097] train: loss: 0.0271552
[Epoch 117; Iter   758/ 1097] train: loss: 0.0037618
[Epoch 117; Iter   788/ 1097] train: loss: 0.0140519
[Epoch 117; Iter   818/ 1097] train: loss: 0.0551076
[Epoch 117; Iter   848/ 1097] train: loss: 0.0347726
[Epoch 117; Iter   878/ 1097] train: loss: 0.0164088
[Epoch 117; Iter   908/ 1097] train: loss: 0.0159913
[Epoch 117; Iter   938/ 1097] train: loss: 0.1195607
[Epoch 117; Iter   968/ 1097] train: loss: 0.0132855
[Epoch 117; Iter   998/ 1097] train: loss: 0.0062040
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0147310
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0175619
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0014056
[Epoch 117] ogbg-molhiv: 0.771274 val loss: 0.186906
[Epoch 117] ogbg-molhiv: 0.726540 test loss: 0.249706
[Epoch 118; Iter    21/ 1097] train: loss: 0.0015570
[Epoch 118; Iter    51/ 1097] train: loss: 0.0434427
[Epoch 118; Iter    81/ 1097] train: loss: 0.0038645
[Epoch 118; Iter   111/ 1097] train: loss: 0.0077802
[Epoch 118; Iter   141/ 1097] train: loss: 0.0261935
[Epoch 118; Iter   171/ 1097] train: loss: 0.0376777
[Epoch 118; Iter   201/ 1097] train: loss: 0.0027202
[Epoch 118; Iter   231/ 1097] train: loss: 0.1198312
[Epoch 118; Iter   261/ 1097] train: loss: 0.0272922
[Epoch 118; Iter   291/ 1097] train: loss: 0.0153783
[Epoch 118; Iter   321/ 1097] train: loss: 0.0858624
[Epoch 118; Iter   351/ 1097] train: loss: 0.0240461
[Epoch 118; Iter   381/ 1097] train: loss: 0.0032761
[Epoch 118; Iter   411/ 1097] train: loss: 0.0965552
[Epoch 118; Iter   441/ 1097] train: loss: 0.0079149
[Epoch 118; Iter   471/ 1097] train: loss: 0.0374912
[Epoch 118; Iter   501/ 1097] train: loss: 0.0014845
[Epoch 118; Iter   531/ 1097] train: loss: 0.0310368
[Epoch 118; Iter   561/ 1097] train: loss: 0.0084881
[Epoch 118; Iter   591/ 1097] train: loss: 0.1283855
[Epoch 118; Iter   621/ 1097] train: loss: 0.0163614
[Epoch 118; Iter   651/ 1097] train: loss: 0.0242235
[Epoch 118; Iter   681/ 1097] train: loss: 0.0062386
[Epoch 118; Iter   711/ 1097] train: loss: 0.0290882
[Epoch 118; Iter   741/ 1097] train: loss: 0.0040963
[Epoch 118; Iter   771/ 1097] train: loss: 0.0157977
[Epoch 118; Iter   801/ 1097] train: loss: 0.0069361
[Epoch 118; Iter   831/ 1097] train: loss: 0.0910914
[Epoch 118; Iter   861/ 1097] train: loss: 0.0609502
[Epoch 118; Iter   891/ 1097] train: loss: 0.0507417
[Epoch 118; Iter   921/ 1097] train: loss: 0.0047665
[Epoch 118; Iter   951/ 1097] train: loss: 0.0499449
[Epoch 118; Iter   981/ 1097] train: loss: 0.1617634
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0052432
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0104949
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0035056
[Epoch 118] ogbg-molhiv: 0.757548 val loss: 0.191472
[Epoch 118] ogbg-molhiv: 0.722911 test loss: 0.254832
[Epoch 119; Iter     4/ 1097] train: loss: 0.0205066
[Epoch 119; Iter    34/ 1097] train: loss: 0.0034918
[Epoch 119; Iter    64/ 1097] train: loss: 0.0047164
[Epoch 119; Iter    94/ 1097] train: loss: 0.0079676
[Epoch 119; Iter   124/ 1097] train: loss: 0.0079997
[Epoch 119; Iter   154/ 1097] train: loss: 0.0442744
[Epoch 119; Iter   184/ 1097] train: loss: 0.0591819
[Epoch 119; Iter   214/ 1097] train: loss: 0.0090866
[Epoch 119; Iter   244/ 1097] train: loss: 0.0683698
[Epoch 119; Iter   274/ 1097] train: loss: 0.0206462
[Epoch 119; Iter   304/ 1097] train: loss: 0.2411833
[Epoch 119; Iter   334/ 1097] train: loss: 0.0943192
[Epoch 119; Iter   364/ 1097] train: loss: 0.0046566
[Epoch 119; Iter   394/ 1097] train: loss: 0.1087646
[Epoch 119; Iter   424/ 1097] train: loss: 0.0144475
[Epoch 119; Iter   454/ 1097] train: loss: 0.0154166
[Epoch 119; Iter   484/ 1097] train: loss: 0.1229983
[Epoch 119; Iter   514/ 1097] train: loss: 0.0181616
[Epoch 119; Iter   544/ 1097] train: loss: 0.0095294
[Epoch 119; Iter   574/ 1097] train: loss: 0.0092462
[Epoch 119; Iter   604/ 1097] train: loss: 0.0171233
[Epoch 119; Iter   634/ 1097] train: loss: 0.0248016
[Epoch 119; Iter   664/ 1097] train: loss: 0.0190488
[Epoch 119; Iter   694/ 1097] train: loss: 0.0011425
[Epoch 119; Iter   724/ 1097] train: loss: 0.0071024
[Epoch 119; Iter   754/ 1097] train: loss: 0.0377068
[Epoch 119; Iter   784/ 1097] train: loss: 0.0447701
[Epoch 119; Iter   814/ 1097] train: loss: 0.1131666
[Epoch 119; Iter   844/ 1097] train: loss: 0.0436370
[Epoch 119; Iter   874/ 1097] train: loss: 0.0243838
[Epoch 119; Iter   904/ 1097] train: loss: 0.0393985
[Epoch 119; Iter   934/ 1097] train: loss: 0.0770576
[Epoch 119; Iter   964/ 1097] train: loss: 0.0053911
[Epoch 119; Iter   994/ 1097] train: loss: 0.0038060
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0090533
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0106807
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0037027
[Epoch 119] ogbg-molhiv: 0.767168 val loss: 0.198554
[Epoch 119] ogbg-molhiv: 0.728284 test loss: 0.256047
[Epoch 120; Iter    17/ 1097] train: loss: 0.0504347
[Epoch 120; Iter    47/ 1097] train: loss: 0.0048056
[Epoch 120; Iter    77/ 1097] train: loss: 0.0070763
[Epoch 120; Iter   107/ 1097] train: loss: 0.0166315
[Epoch 120; Iter   137/ 1097] train: loss: 0.0098289
[Epoch 120; Iter   167/ 1097] train: loss: 0.0026947
[Epoch 120; Iter   197/ 1097] train: loss: 0.0023108
[Epoch 120; Iter   227/ 1097] train: loss: 0.0630880
[Epoch 120; Iter   257/ 1097] train: loss: 0.0110167
[Epoch 120; Iter   287/ 1097] train: loss: 0.0254149
[Epoch 120; Iter   317/ 1097] train: loss: 0.0023374
[Epoch 120; Iter   347/ 1097] train: loss: 0.0066279
[Epoch 120; Iter   377/ 1097] train: loss: 0.0124940
[Epoch 120; Iter   407/ 1097] train: loss: 0.0424768
[Epoch 120; Iter   437/ 1097] train: loss: 0.0068844
[Epoch 120; Iter   467/ 1097] train: loss: 0.0239787
[Epoch 120; Iter   497/ 1097] train: loss: 0.0010533
[Epoch 120; Iter   527/ 1097] train: loss: 0.2536294
[Epoch 120; Iter   557/ 1097] train: loss: 0.0013858
[Epoch 120; Iter   587/ 1097] train: loss: 0.0058139
[Epoch 120; Iter   617/ 1097] train: loss: 0.0113816
[Epoch 120; Iter   647/ 1097] train: loss: 0.0400645
[Epoch 120; Iter   677/ 1097] train: loss: 0.0064873
[Epoch 120; Iter   707/ 1097] train: loss: 0.1527817
[Epoch 120; Iter   737/ 1097] train: loss: 0.0051445
[Epoch 120; Iter   767/ 1097] train: loss: 0.0413189
[Epoch 120; Iter   797/ 1097] train: loss: 0.0130340
[Epoch 120; Iter   827/ 1097] train: loss: 0.0158616
[Epoch 120; Iter   857/ 1097] train: loss: 0.0061481
[Epoch 120; Iter   887/ 1097] train: loss: 0.0094082
[Epoch 120; Iter   917/ 1097] train: loss: 0.0142485
[Epoch 120; Iter   947/ 1097] train: loss: 0.0306915
[Epoch 120; Iter   977/ 1097] train: loss: 0.0748342
[Epoch 120; Iter  1007/ 1097] train: loss: 0.1387583
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0773187
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0474919
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0385520
[Epoch 120] ogbg-molhiv: 0.771366 val loss: 0.191091
[Epoch 120] ogbg-molhiv: 0.726887 test loss: 0.267259
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 13.
Statistics on  val_best_checkpoint
mean_pred: -3.867086410522461
std_pred: 1.036506175994873
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.2701637046162001
rocauc: 0.8116763423476386
ogbg-molhiv: 0.8116763423476386
BCEWithLogitsLoss: 0.07968299676650677
Statistics on  test
mean_pred: -3.8181841373443604
std_pred: 0.9559541344642639
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.2024901234074072
rocauc: 0.7623727766082774
ogbg-molhiv: 0.7623727766082774
BCEWithLogitsLoss: 0.12075330811026304
Statistics on  train
mean_pred: -3.754678249359131
std_pred: 4.8383259773254395
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.2577706605864867
rocauc: 0.8078996810761312
ogbg-molhiv: 0.8078996810761312
BCEWithLogitsLoss: 0.2768491672448739
[Epoch 117; Iter   728/ 1097] train: loss: 0.0060842
[Epoch 117; Iter   758/ 1097] train: loss: 0.0097772
[Epoch 117; Iter   788/ 1097] train: loss: 0.0069403
[Epoch 117; Iter   818/ 1097] train: loss: 0.0002615
[Epoch 117; Iter   848/ 1097] train: loss: 0.1654538
[Epoch 117; Iter   878/ 1097] train: loss: 0.0014475
[Epoch 117; Iter   908/ 1097] train: loss: 0.0342408
[Epoch 117; Iter   938/ 1097] train: loss: 0.0035263
[Epoch 117; Iter   968/ 1097] train: loss: 0.0014861
[Epoch 117; Iter   998/ 1097] train: loss: 0.0199214
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0142531
[Epoch 117; Iter  1058/ 1097] train: loss: 0.1060382
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0416414
[Epoch 117] ogbg-molhiv: 0.754795 val loss: 0.201072
[Epoch 117] ogbg-molhiv: 0.735773 test loss: 0.538034
[Epoch 118; Iter    21/ 1097] train: loss: 0.0017039
[Epoch 118; Iter    51/ 1097] train: loss: 0.0005673
[Epoch 118; Iter    81/ 1097] train: loss: 0.0329115
[Epoch 118; Iter   111/ 1097] train: loss: 0.0047982
[Epoch 118; Iter   141/ 1097] train: loss: 0.0944334
[Epoch 118; Iter   171/ 1097] train: loss: 0.0094743
[Epoch 118; Iter   201/ 1097] train: loss: 0.0294602
[Epoch 118; Iter   231/ 1097] train: loss: 0.0034491
[Epoch 118; Iter   261/ 1097] train: loss: 0.0008950
[Epoch 118; Iter   291/ 1097] train: loss: 0.0073804
[Epoch 118; Iter   321/ 1097] train: loss: 0.0099162
[Epoch 118; Iter   351/ 1097] train: loss: 0.1345927
[Epoch 118; Iter   381/ 1097] train: loss: 0.0004379
[Epoch 118; Iter   411/ 1097] train: loss: 0.0176231
[Epoch 118; Iter   441/ 1097] train: loss: 0.0080376
[Epoch 118; Iter   471/ 1097] train: loss: 0.0134681
[Epoch 118; Iter   501/ 1097] train: loss: 0.0059130
[Epoch 118; Iter   531/ 1097] train: loss: 0.0010078
[Epoch 118; Iter   561/ 1097] train: loss: 0.0931107
[Epoch 118; Iter   591/ 1097] train: loss: 0.0188327
[Epoch 118; Iter   621/ 1097] train: loss: 0.0077887
[Epoch 118; Iter   651/ 1097] train: loss: 0.0553777
[Epoch 118; Iter   681/ 1097] train: loss: 0.0003476
[Epoch 118; Iter   711/ 1097] train: loss: 0.0488282
[Epoch 118; Iter   741/ 1097] train: loss: 0.0122298
[Epoch 118; Iter   771/ 1097] train: loss: 0.0028930
[Epoch 118; Iter   801/ 1097] train: loss: 0.0011872
[Epoch 118; Iter   831/ 1097] train: loss: 0.0032542
[Epoch 118; Iter   861/ 1097] train: loss: 0.0182274
[Epoch 118; Iter   891/ 1097] train: loss: 0.0057349
[Epoch 118; Iter   921/ 1097] train: loss: 0.0224083
[Epoch 118; Iter   951/ 1097] train: loss: 0.0077143
[Epoch 118; Iter   981/ 1097] train: loss: 0.0004738
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0109795
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0170864
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0040823
[Epoch 118] ogbg-molhiv: 0.759786 val loss: 0.248546
[Epoch 118] ogbg-molhiv: 0.739219 test loss: 0.775379
[Epoch 119; Iter     4/ 1097] train: loss: 0.0038527
[Epoch 119; Iter    34/ 1097] train: loss: 0.0006323
[Epoch 119; Iter    64/ 1097] train: loss: 0.0031346
[Epoch 119; Iter    94/ 1097] train: loss: 0.0012218
[Epoch 119; Iter   124/ 1097] train: loss: 0.0036676
[Epoch 119; Iter   154/ 1097] train: loss: 0.0166367
[Epoch 119; Iter   184/ 1097] train: loss: 0.0301397
[Epoch 119; Iter   214/ 1097] train: loss: 0.0119659
[Epoch 119; Iter   244/ 1097] train: loss: 0.0035218
[Epoch 119; Iter   274/ 1097] train: loss: 0.0873854
[Epoch 119; Iter   304/ 1097] train: loss: 0.0138745
[Epoch 119; Iter   334/ 1097] train: loss: 0.0005926
[Epoch 119; Iter   364/ 1097] train: loss: 0.0056038
[Epoch 119; Iter   394/ 1097] train: loss: 0.0031691
[Epoch 119; Iter   424/ 1097] train: loss: 0.0039623
[Epoch 119; Iter   454/ 1097] train: loss: 0.0026499
[Epoch 119; Iter   484/ 1097] train: loss: 0.0069842
[Epoch 119; Iter   514/ 1097] train: loss: 0.0007321
[Epoch 119; Iter   544/ 1097] train: loss: 0.0017231
[Epoch 119; Iter   574/ 1097] train: loss: 0.0012642
[Epoch 119; Iter   604/ 1097] train: loss: 0.0006886
[Epoch 119; Iter   634/ 1097] train: loss: 0.0034390
[Epoch 119; Iter   664/ 1097] train: loss: 0.0008044
[Epoch 119; Iter   694/ 1097] train: loss: 0.0014617
[Epoch 119; Iter   724/ 1097] train: loss: 0.0369967
[Epoch 119; Iter   754/ 1097] train: loss: 0.0536014
[Epoch 119; Iter   784/ 1097] train: loss: 0.0122829
[Epoch 119; Iter   814/ 1097] train: loss: 0.0010951
[Epoch 119; Iter   844/ 1097] train: loss: 0.0136452
[Epoch 119; Iter   874/ 1097] train: loss: 0.0386030
[Epoch 119; Iter   904/ 1097] train: loss: 0.0012945
[Epoch 119; Iter   934/ 1097] train: loss: 0.1157755
[Epoch 119; Iter   964/ 1097] train: loss: 0.0010776
[Epoch 119; Iter   994/ 1097] train: loss: 0.0389415
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0979437
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0132607
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0156128
[Epoch 119] ogbg-molhiv: 0.746932 val loss: 0.254879
[Epoch 119] ogbg-molhiv: 0.731352 test loss: 0.812271
[Epoch 120; Iter    17/ 1097] train: loss: 0.0769629
[Epoch 120; Iter    47/ 1097] train: loss: 0.0025667
[Epoch 120; Iter    77/ 1097] train: loss: 0.0169236
[Epoch 120; Iter   107/ 1097] train: loss: 0.0013067
[Epoch 120; Iter   137/ 1097] train: loss: 0.0211298
[Epoch 120; Iter   167/ 1097] train: loss: 0.0093217
[Epoch 120; Iter   197/ 1097] train: loss: 0.0054723
[Epoch 120; Iter   227/ 1097] train: loss: 0.0132056
[Epoch 120; Iter   257/ 1097] train: loss: 0.0002651
[Epoch 120; Iter   287/ 1097] train: loss: 0.0086394
[Epoch 120; Iter   317/ 1097] train: loss: 0.0024514
[Epoch 120; Iter   347/ 1097] train: loss: 0.0005086
[Epoch 120; Iter   377/ 1097] train: loss: 0.0059546
[Epoch 120; Iter   407/ 1097] train: loss: 0.0098293
[Epoch 120; Iter   437/ 1097] train: loss: 0.0031952
[Epoch 120; Iter   467/ 1097] train: loss: 0.0082594
[Epoch 120; Iter   497/ 1097] train: loss: 0.0034758
[Epoch 120; Iter   527/ 1097] train: loss: 0.0171036
[Epoch 120; Iter   557/ 1097] train: loss: 0.0007533
[Epoch 120; Iter   587/ 1097] train: loss: 0.0032032
[Epoch 120; Iter   617/ 1097] train: loss: 0.0164410
[Epoch 120; Iter   647/ 1097] train: loss: 0.0061291
[Epoch 120; Iter   677/ 1097] train: loss: 0.0106633
[Epoch 120; Iter   707/ 1097] train: loss: 0.1330273
[Epoch 120; Iter   737/ 1097] train: loss: 0.0030399
[Epoch 120; Iter   767/ 1097] train: loss: 0.0110611
[Epoch 120; Iter   797/ 1097] train: loss: 0.0005570
[Epoch 120; Iter   827/ 1097] train: loss: 0.0445697
[Epoch 120; Iter   857/ 1097] train: loss: 0.0064920
[Epoch 120; Iter   887/ 1097] train: loss: 0.0026626
[Epoch 120; Iter   917/ 1097] train: loss: 0.0021181
[Epoch 120; Iter   947/ 1097] train: loss: 0.0164890
[Epoch 120; Iter   977/ 1097] train: loss: 0.0007312
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0044348
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0017756
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0014446
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0151717
[Epoch 120] ogbg-molhiv: 0.751326 val loss: 0.260480
[Epoch 120] ogbg-molhiv: 0.730211 test loss: 0.896557
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 27.
Statistics on  val_best_checkpoint
mean_pred: -4.198913097381592
std_pred: 7.302343845367432
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.27724509892348365
rocauc: 0.829358955516363
ogbg-molhiv: 0.829358955516363
BCEWithLogitsLoss: 0.7958577149547637
Statistics on  test
mean_pred: -4.050745010375977
std_pred: 14.047001838684082
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.23948654809773498
rocauc: 0.749987446648255
ogbg-molhiv: 0.749987446648255
BCEWithLogitsLoss: 0.4405041336000938
Statistics on  train
mean_pred: -4.478221416473389
std_pred: 3.687872886657715
mean_targets: 0.03744566813111305
std_targets: 0.18985411524772644
prcauc: 0.5323441468811977
rocauc: 0.9043644118362297
ogbg-molhiv: 0.9043644118362297
BCEWithLogitsLoss: 0.12405563566711482
[Epoch 137; Iter   422/  823] train: loss: 0.0037899
[Epoch 137; Iter   452/  823] train: loss: 0.0015226
[Epoch 137; Iter   482/  823] train: loss: 0.0036507
[Epoch 137; Iter   512/  823] train: loss: 0.0013799
[Epoch 137; Iter   542/  823] train: loss: 0.0051942
[Epoch 137; Iter   572/  823] train: loss: 0.0359614
[Epoch 137; Iter   602/  823] train: loss: 0.0220128
[Epoch 137; Iter   632/  823] train: loss: 0.0007400
[Epoch 137; Iter   662/  823] train: loss: 0.0041397
[Epoch 137; Iter   692/  823] train: loss: 0.0155828
[Epoch 137; Iter   722/  823] train: loss: 0.0058912
[Epoch 137; Iter   752/  823] train: loss: 0.0001862
[Epoch 137; Iter   782/  823] train: loss: 0.0008036
[Epoch 137; Iter   812/  823] train: loss: 0.0384990
[Epoch 137] ogbg-molhiv: 0.739018 val loss: 0.563361
[Epoch 137] ogbg-molhiv: 0.755166 test loss: 0.600824
[Epoch 138; Iter    19/  823] train: loss: 0.0045095
[Epoch 138; Iter    49/  823] train: loss: 0.0000773
[Epoch 138; Iter    79/  823] train: loss: 0.0020946
[Epoch 138; Iter   109/  823] train: loss: 0.0013803
[Epoch 138; Iter   139/  823] train: loss: 0.0019407
[Epoch 138; Iter   169/  823] train: loss: 0.0054906
[Epoch 138; Iter   199/  823] train: loss: 0.0568336
[Epoch 138; Iter   229/  823] train: loss: 0.0004816
[Epoch 138; Iter   259/  823] train: loss: 0.0033590
[Epoch 138; Iter   289/  823] train: loss: 0.0169530
[Epoch 138; Iter   319/  823] train: loss: 0.0007609
[Epoch 138; Iter   349/  823] train: loss: 0.0009794
[Epoch 138; Iter   379/  823] train: loss: 0.0013118
[Epoch 138; Iter   409/  823] train: loss: 0.0136162
[Epoch 138; Iter   439/  823] train: loss: 0.0340509
[Epoch 138; Iter   469/  823] train: loss: 0.0114816
[Epoch 138; Iter   499/  823] train: loss: 0.0006660
[Epoch 138; Iter   529/  823] train: loss: 0.0109500
[Epoch 138; Iter   559/  823] train: loss: 0.0009401
[Epoch 138; Iter   589/  823] train: loss: 0.0000408
[Epoch 138; Iter   619/  823] train: loss: 0.0062235
[Epoch 138; Iter   649/  823] train: loss: 0.0218388
[Epoch 138; Iter   679/  823] train: loss: 0.0053212
[Epoch 138; Iter   709/  823] train: loss: 0.0068608
[Epoch 138; Iter   739/  823] train: loss: 0.0001499
[Epoch 138; Iter   769/  823] train: loss: 0.0009474
[Epoch 138; Iter   799/  823] train: loss: 0.0049860
[Epoch 138] ogbg-molhiv: 0.741324 val loss: 0.515322
[Epoch 138] ogbg-molhiv: 0.755991 test loss: 0.506931
[Epoch 139; Iter     6/  823] train: loss: 0.0007020
[Epoch 139; Iter    36/  823] train: loss: 0.0006495
[Epoch 139; Iter    66/  823] train: loss: 0.0016049
[Epoch 139; Iter    96/  823] train: loss: 0.0006456
[Epoch 139; Iter   126/  823] train: loss: 0.0150031
[Epoch 139; Iter   156/  823] train: loss: 0.0002977
[Epoch 139; Iter   186/  823] train: loss: 0.0320137
[Epoch 139; Iter   216/  823] train: loss: 0.0807135
[Epoch 139; Iter   246/  823] train: loss: 0.0016886
[Epoch 139; Iter   276/  823] train: loss: 0.0263478
[Epoch 139; Iter   306/  823] train: loss: 0.0004822
[Epoch 139; Iter   336/  823] train: loss: 0.0026090
[Epoch 139; Iter   366/  823] train: loss: 0.0133455
[Epoch 139; Iter   396/  823] train: loss: 0.0056303
[Epoch 139; Iter   426/  823] train: loss: 0.0139391
[Epoch 139; Iter   456/  823] train: loss: 0.0111123
[Epoch 139; Iter   486/  823] train: loss: 0.0022390
[Epoch 139; Iter   516/  823] train: loss: 0.0033654
[Epoch 139; Iter   546/  823] train: loss: 0.0257089
[Epoch 139; Iter   576/  823] train: loss: 0.0012946
[Epoch 139; Iter   606/  823] train: loss: 0.0015903
[Epoch 139; Iter   636/  823] train: loss: 0.0006373
[Epoch 139; Iter   666/  823] train: loss: 0.0004810
[Epoch 139; Iter   696/  823] train: loss: 0.0025941
[Epoch 139; Iter   726/  823] train: loss: 0.0015691
[Epoch 139; Iter   756/  823] train: loss: 0.0063389
[Epoch 139; Iter   786/  823] train: loss: 0.0004574
[Epoch 139; Iter   816/  823] train: loss: 0.0005057
[Epoch 139] ogbg-molhiv: 0.742963 val loss: 0.551209
[Epoch 139] ogbg-molhiv: 0.759157 test loss: 0.558019
[Epoch 140; Iter    23/  823] train: loss: 0.0011533
[Epoch 140; Iter    53/  823] train: loss: 0.0117158
[Epoch 140; Iter    83/  823] train: loss: 0.0004438
[Epoch 140; Iter   113/  823] train: loss: 0.0020004
[Epoch 140; Iter   143/  823] train: loss: 0.0003502
[Epoch 140; Iter   173/  823] train: loss: 0.0003172
[Epoch 140; Iter   203/  823] train: loss: 0.0197663
[Epoch 140; Iter   233/  823] train: loss: 0.0012301
[Epoch 140; Iter   263/  823] train: loss: 0.0000672
[Epoch 140; Iter   293/  823] train: loss: 0.0018519
[Epoch 140; Iter   323/  823] train: loss: 0.0018926
[Epoch 140; Iter   353/  823] train: loss: 0.0003502
[Epoch 140; Iter   383/  823] train: loss: 0.1006880
[Epoch 140; Iter   413/  823] train: loss: 0.0037258
[Epoch 140; Iter   443/  823] train: loss: 0.0010746
[Epoch 140; Iter   473/  823] train: loss: 0.0009501
[Epoch 140; Iter   503/  823] train: loss: 0.0007044
[Epoch 140; Iter   533/  823] train: loss: 0.0223559
[Epoch 140; Iter   563/  823] train: loss: 0.0044028
[Epoch 140; Iter   593/  823] train: loss: 0.0006232
[Epoch 140; Iter   623/  823] train: loss: 0.0035770
[Epoch 140; Iter   653/  823] train: loss: 0.0012232
[Epoch 140; Iter   683/  823] train: loss: 0.0020614
[Epoch 140; Iter   713/  823] train: loss: 0.0078316
[Epoch 140; Iter   743/  823] train: loss: 0.0015017
[Epoch 140; Iter   773/  823] train: loss: 0.0014757
[Epoch 140; Iter   803/  823] train: loss: 0.0002357
[Epoch 140] ogbg-molhiv: 0.739160 val loss: 0.485171
[Epoch 140] ogbg-molhiv: 0.755172 test loss: 0.495152
[Epoch 141; Iter    10/  823] train: loss: 0.0042392
[Epoch 141; Iter    40/  823] train: loss: 0.0090272
[Epoch 141; Iter    70/  823] train: loss: 0.0058348
[Epoch 141; Iter   100/  823] train: loss: 0.0021202
[Epoch 141; Iter   130/  823] train: loss: 0.0036384
[Epoch 141; Iter   160/  823] train: loss: 0.0002820
[Epoch 141; Iter   190/  823] train: loss: 0.0024475
[Epoch 141; Iter   220/  823] train: loss: 0.0003721
[Epoch 141; Iter   250/  823] train: loss: 0.0002804
[Epoch 141; Iter   280/  823] train: loss: 0.0017531
[Epoch 141; Iter   310/  823] train: loss: 0.0001715
[Epoch 141; Iter   340/  823] train: loss: 0.0007009
[Epoch 141; Iter   370/  823] train: loss: 0.0917077
[Epoch 141; Iter   400/  823] train: loss: 0.0013787
[Epoch 141; Iter   430/  823] train: loss: 0.0248812
[Epoch 141; Iter   460/  823] train: loss: 0.0025626
[Epoch 141; Iter   490/  823] train: loss: 0.0046020
[Epoch 141; Iter   520/  823] train: loss: 0.0024381
[Epoch 141; Iter   550/  823] train: loss: 0.0001171
[Epoch 141; Iter   580/  823] train: loss: 0.0334787
[Epoch 141; Iter   610/  823] train: loss: 0.0003654
[Epoch 141; Iter   640/  823] train: loss: 0.0005379
[Epoch 141; Iter   670/  823] train: loss: 0.0002368
[Epoch 141; Iter   700/  823] train: loss: 0.0016746
[Epoch 141; Iter   730/  823] train: loss: 0.0161754
[Epoch 141; Iter   760/  823] train: loss: 0.0076962
[Epoch 141; Iter   790/  823] train: loss: 0.0053725
[Epoch 141; Iter   820/  823] train: loss: 0.0024164
[Epoch 141] ogbg-molhiv: 0.740491 val loss: 0.587799
[Epoch 141] ogbg-molhiv: 0.758752 test loss: 0.635418
[Epoch 142; Iter    27/  823] train: loss: 0.0278711
[Epoch 142; Iter    57/  823] train: loss: 0.0010689
[Epoch 142; Iter    87/  823] train: loss: 0.0034339
[Epoch 142; Iter   117/  823] train: loss: 0.0035985
[Epoch 142; Iter   147/  823] train: loss: 0.0004332
[Epoch 142; Iter   177/  823] train: loss: 0.0088042
[Epoch 142; Iter   207/  823] train: loss: 0.0100427
[Epoch 142; Iter   237/  823] train: loss: 0.0029112
[Epoch 142; Iter   267/  823] train: loss: 0.0004375
[Epoch 142; Iter   297/  823] train: loss: 0.0007849
[Epoch 142; Iter   327/  823] train: loss: 0.0059375
[Epoch 142; Iter   357/  823] train: loss: 0.0576163
[Epoch 142; Iter   387/  823] train: loss: 0.0007109
[Epoch 142; Iter   417/  823] train: loss: 0.0001815
[Epoch 142; Iter   447/  823] train: loss: 0.0003057
[Epoch 142; Iter   477/  823] train: loss: 0.0009823
[Epoch 142; Iter   507/  823] train: loss: 0.0130042
[Epoch 142; Iter   537/  823] train: loss: 0.0001392
[Epoch 142; Iter   567/  823] train: loss: 0.0433856
[Epoch 142; Iter   597/  823] train: loss: 0.0008835
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 117; Iter   728/ 1097] train: loss: 0.0019177
[Epoch 117; Iter   758/ 1097] train: loss: 0.0007638
[Epoch 117; Iter   788/ 1097] train: loss: 0.0187742
[Epoch 117; Iter   818/ 1097] train: loss: 0.0281508
[Epoch 117; Iter   848/ 1097] train: loss: 0.0063569
[Epoch 117; Iter   878/ 1097] train: loss: 0.0006987
[Epoch 117; Iter   908/ 1097] train: loss: 0.0014828
[Epoch 117; Iter   938/ 1097] train: loss: 0.0002982
[Epoch 117; Iter   968/ 1097] train: loss: 0.1442086
[Epoch 117; Iter   998/ 1097] train: loss: 0.0005402
[Epoch 117; Iter  1028/ 1097] train: loss: 0.0212033
[Epoch 117; Iter  1058/ 1097] train: loss: 0.0176605
[Epoch 117; Iter  1088/ 1097] train: loss: 0.0035840
[Epoch 117] ogbg-molhiv: 0.795264 val loss: 0.144297
[Epoch 117] ogbg-molhiv: 0.759513 test loss: 0.262554
[Epoch 118; Iter    21/ 1097] train: loss: 0.0000573
[Epoch 118; Iter    51/ 1097] train: loss: 0.0507039
[Epoch 118; Iter    81/ 1097] train: loss: 0.0006882
[Epoch 118; Iter   111/ 1097] train: loss: 0.0434578
[Epoch 118; Iter   141/ 1097] train: loss: 0.0084907
[Epoch 118; Iter   171/ 1097] train: loss: 0.0005184
[Epoch 118; Iter   201/ 1097] train: loss: 0.0145932
[Epoch 118; Iter   231/ 1097] train: loss: 0.0096191
[Epoch 118; Iter   261/ 1097] train: loss: 0.0285683
[Epoch 118; Iter   291/ 1097] train: loss: 0.1090823
[Epoch 118; Iter   321/ 1097] train: loss: 0.0012116
[Epoch 118; Iter   351/ 1097] train: loss: 0.0023015
[Epoch 118; Iter   381/ 1097] train: loss: 0.0051989
[Epoch 118; Iter   411/ 1097] train: loss: 0.0013039
[Epoch 118; Iter   441/ 1097] train: loss: 0.0025822
[Epoch 118; Iter   471/ 1097] train: loss: 0.0040464
[Epoch 118; Iter   501/ 1097] train: loss: 0.0501936
[Epoch 118; Iter   531/ 1097] train: loss: 0.0182451
[Epoch 118; Iter   561/ 1097] train: loss: 0.2257703
[Epoch 118; Iter   591/ 1097] train: loss: 0.0866368
[Epoch 118; Iter   621/ 1097] train: loss: 0.0028301
[Epoch 118; Iter   651/ 1097] train: loss: 0.0021708
[Epoch 118; Iter   681/ 1097] train: loss: 0.0059203
[Epoch 118; Iter   711/ 1097] train: loss: 0.0023381
[Epoch 118; Iter   741/ 1097] train: loss: 0.0021981
[Epoch 118; Iter   771/ 1097] train: loss: 0.0009905
[Epoch 118; Iter   801/ 1097] train: loss: 0.1183684
[Epoch 118; Iter   831/ 1097] train: loss: 0.0012032
[Epoch 118; Iter   861/ 1097] train: loss: 0.0132628
[Epoch 118; Iter   891/ 1097] train: loss: 0.0145212
[Epoch 118; Iter   921/ 1097] train: loss: 0.0008390
[Epoch 118; Iter   951/ 1097] train: loss: 0.0084259
[Epoch 118; Iter   981/ 1097] train: loss: 0.0391321
[Epoch 118; Iter  1011/ 1097] train: loss: 0.0012186
[Epoch 118; Iter  1041/ 1097] train: loss: 0.0035032
[Epoch 118; Iter  1071/ 1097] train: loss: 0.0046522
[Epoch 118] ogbg-molhiv: 0.796208 val loss: 0.141295
[Epoch 118] ogbg-molhiv: 0.763750 test loss: 0.266366
[Epoch 119; Iter     4/ 1097] train: loss: 0.0010596
[Epoch 119; Iter    34/ 1097] train: loss: 0.0002150
[Epoch 119; Iter    64/ 1097] train: loss: 0.0159311
[Epoch 119; Iter    94/ 1097] train: loss: 0.0253360
[Epoch 119; Iter   124/ 1097] train: loss: 0.0010081
[Epoch 119; Iter   154/ 1097] train: loss: 0.0337265
[Epoch 119; Iter   184/ 1097] train: loss: 0.0073459
[Epoch 119; Iter   214/ 1097] train: loss: 0.0387637
[Epoch 119; Iter   244/ 1097] train: loss: 0.0042110
[Epoch 119; Iter   274/ 1097] train: loss: 0.0009880
[Epoch 119; Iter   304/ 1097] train: loss: 0.0087418
[Epoch 119; Iter   334/ 1097] train: loss: 0.0007904
[Epoch 119; Iter   364/ 1097] train: loss: 0.0327996
[Epoch 119; Iter   394/ 1097] train: loss: 0.0010587
[Epoch 119; Iter   424/ 1097] train: loss: 0.1498175
[Epoch 119; Iter   454/ 1097] train: loss: 0.0005662
[Epoch 119; Iter   484/ 1097] train: loss: 0.0023543
[Epoch 119; Iter   514/ 1097] train: loss: 0.0013308
[Epoch 119; Iter   544/ 1097] train: loss: 0.0555111
[Epoch 119; Iter   574/ 1097] train: loss: 0.0026618
[Epoch 119; Iter   604/ 1097] train: loss: 0.0452588
[Epoch 119; Iter   634/ 1097] train: loss: 0.0815381
[Epoch 119; Iter   664/ 1097] train: loss: 0.0019592
[Epoch 119; Iter   694/ 1097] train: loss: 0.0522800
[Epoch 119; Iter   724/ 1097] train: loss: 0.0085926
[Epoch 119; Iter   754/ 1097] train: loss: 0.0006731
[Epoch 119; Iter   784/ 1097] train: loss: 0.0039876
[Epoch 119; Iter   814/ 1097] train: loss: 0.0017277
[Epoch 119; Iter   844/ 1097] train: loss: 0.0010579
[Epoch 119; Iter   874/ 1097] train: loss: 0.0012676
[Epoch 119; Iter   904/ 1097] train: loss: 0.0124387
[Epoch 119; Iter   934/ 1097] train: loss: 0.0082079
[Epoch 119; Iter   964/ 1097] train: loss: 0.0062677
[Epoch 119; Iter   994/ 1097] train: loss: 0.0016491
[Epoch 119; Iter  1024/ 1097] train: loss: 0.0023343
[Epoch 119; Iter  1054/ 1097] train: loss: 0.0210529
[Epoch 119; Iter  1084/ 1097] train: loss: 0.0024048
[Epoch 119] ogbg-molhiv: 0.792095 val loss: 0.151049
[Epoch 119] ogbg-molhiv: 0.756270 test loss: 0.266445
[Epoch 120; Iter    17/ 1097] train: loss: 0.0016143
[Epoch 120; Iter    47/ 1097] train: loss: 0.0004351
[Epoch 120; Iter    77/ 1097] train: loss: 0.0049531
[Epoch 120; Iter   107/ 1097] train: loss: 0.0005758
[Epoch 120; Iter   137/ 1097] train: loss: 0.0025983
[Epoch 120; Iter   167/ 1097] train: loss: 0.0028254
[Epoch 120; Iter   197/ 1097] train: loss: 0.0015088
[Epoch 120; Iter   227/ 1097] train: loss: 0.0019749
[Epoch 120; Iter   257/ 1097] train: loss: 0.0016070
[Epoch 120; Iter   287/ 1097] train: loss: 0.0249476
[Epoch 120; Iter   317/ 1097] train: loss: 0.0080647
[Epoch 120; Iter   347/ 1097] train: loss: 0.0066675
[Epoch 120; Iter   377/ 1097] train: loss: 0.0805710
[Epoch 120; Iter   407/ 1097] train: loss: 0.0008702
[Epoch 120; Iter   437/ 1097] train: loss: 0.0019816
[Epoch 120; Iter   467/ 1097] train: loss: 0.0113935
[Epoch 120; Iter   497/ 1097] train: loss: 0.0011955
[Epoch 120; Iter   527/ 1097] train: loss: 0.0005861
[Epoch 120; Iter   557/ 1097] train: loss: 0.0356825
[Epoch 120; Iter   587/ 1097] train: loss: 0.0026942
[Epoch 120; Iter   617/ 1097] train: loss: 0.0015135
[Epoch 120; Iter   647/ 1097] train: loss: 0.0055291
[Epoch 120; Iter   677/ 1097] train: loss: 0.0052345
[Epoch 120; Iter   707/ 1097] train: loss: 0.0019566
[Epoch 120; Iter   737/ 1097] train: loss: 0.0017962
[Epoch 120; Iter   767/ 1097] train: loss: 0.0677829
[Epoch 120; Iter   797/ 1097] train: loss: 0.0215471
[Epoch 120; Iter   827/ 1097] train: loss: 0.0013293
[Epoch 120; Iter   857/ 1097] train: loss: 0.0018639
[Epoch 120; Iter   887/ 1097] train: loss: 0.0004062
[Epoch 120; Iter   917/ 1097] train: loss: 0.0026641
[Epoch 120; Iter   947/ 1097] train: loss: 0.0308740
[Epoch 120; Iter   977/ 1097] train: loss: 0.0041220
[Epoch 120; Iter  1007/ 1097] train: loss: 0.0029260
[Epoch 120; Iter  1037/ 1097] train: loss: 0.0009879
[Epoch 120; Iter  1067/ 1097] train: loss: 0.0009537
[Epoch 120; Iter  1097/ 1097] train: loss: 0.0011693
[Epoch 120] ogbg-molhiv: 0.792386 val loss: 0.148011
[Epoch 120] ogbg-molhiv: 0.759310 test loss: 0.264583
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 120 epochs. Best model checkpoint was in epoch 19.
Statistics on  val_best_checkpoint
mean_pred: -4.125789165496826
std_pred: 1.247218370437622
mean_targets: 0.019693654030561447
std_targets: 0.1389622539281845
prcauc: 0.3662632308777022
rocauc: 0.8309909611992944
ogbg-molhiv: 0.8309909611992944
BCEWithLogitsLoss: 0.0745397008807007
Statistics on  test
mean_pred: -3.999983787536621
std_pred: 1.2400684356689453
mean_targets: 0.03160709887742996
std_targets: 0.17497295141220093
prcauc: 0.27298577636000965
rocauc: 0.7542304795380367
ogbg-molhiv: 0.7542304795380367
BCEWithLogitsLoss: 0.11858452430021936
Statistics on  train
mean_pred: -4.194502830505371
std_pred: 1.4201314449310303
mean_targets: 0.03744566813111305
std_targets: 0.18985413014888763
prcauc: 0.5208061275254989
rocauc: 0.8926292247570549
ogbg-molhiv: 0.8926292247570549
BCEWithLogitsLoss: 0.09973093566935554
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 142; Iter   627/  823] train: loss: 0.0062927
[Epoch 142; Iter   657/  823] train: loss: 0.0000773
[Epoch 142; Iter   687/  823] train: loss: 0.0014133
[Epoch 142; Iter   717/  823] train: loss: 0.0005988
[Epoch 142; Iter   747/  823] train: loss: 0.0686820
[Epoch 142; Iter   777/  823] train: loss: 0.0107301
[Epoch 142; Iter   807/  823] train: loss: 0.0029188
[Epoch 142] ogbg-molhiv: 0.739902 val loss: 0.562185
[Epoch 142] ogbg-molhiv: 0.752538 test loss: 0.609855
[Epoch 143; Iter    14/  823] train: loss: 0.0139391
[Epoch 143; Iter    44/  823] train: loss: 0.0019726
[Epoch 143; Iter    74/  823] train: loss: 0.0047626
[Epoch 143; Iter   104/  823] train: loss: 0.0000745
[Epoch 143; Iter   134/  823] train: loss: 0.0124860
[Epoch 143; Iter   164/  823] train: loss: 0.0004793
[Epoch 143; Iter   194/  823] train: loss: 0.0172583
[Epoch 143; Iter   224/  823] train: loss: 0.0013513
[Epoch 143; Iter   254/  823] train: loss: 0.0128202
[Epoch 143; Iter   284/  823] train: loss: 0.0006040
[Epoch 143; Iter   314/  823] train: loss: 0.0005048
[Epoch 143; Iter   344/  823] train: loss: 0.0004423
[Epoch 143; Iter   374/  823] train: loss: 0.0271680
[Epoch 143; Iter   404/  823] train: loss: 0.0002028
[Epoch 143; Iter   434/  823] train: loss: 0.0016307
[Epoch 143; Iter   464/  823] train: loss: 0.0186413
[Epoch 143; Iter   494/  823] train: loss: 0.0025567
[Epoch 143; Iter   524/  823] train: loss: 0.0056153
[Epoch 143; Iter   554/  823] train: loss: 0.0000793
[Epoch 143; Iter   584/  823] train: loss: 0.0054768
[Epoch 143; Iter   614/  823] train: loss: 0.0144662
[Epoch 143; Iter   644/  823] train: loss: 0.0000693
[Epoch 143; Iter   674/  823] train: loss: 0.0024111
[Epoch 143; Iter   704/  823] train: loss: 0.0004208
[Epoch 143; Iter   734/  823] train: loss: 0.0043908
[Epoch 143; Iter   764/  823] train: loss: 0.0006115
[Epoch 143; Iter   794/  823] train: loss: 0.0003742
[Epoch 143] ogbg-molhiv: 0.740648 val loss: 0.568574
[Epoch 143] ogbg-molhiv: 0.756473 test loss: 0.620358
[Epoch 144; Iter     1/  823] train: loss: 0.0202421
[Epoch 144; Iter    31/  823] train: loss: 0.0004431
[Epoch 144; Iter    61/  823] train: loss: 0.0037216
[Epoch 144; Iter    91/  823] train: loss: 0.0019903
[Epoch 144; Iter   121/  823] train: loss: 0.0228454
[Epoch 144; Iter   151/  823] train: loss: 0.0009970
[Epoch 144; Iter   181/  823] train: loss: 0.0063805
[Epoch 144; Iter   211/  823] train: loss: 0.0001826
[Epoch 144; Iter   241/  823] train: loss: 0.0001668
[Epoch 144; Iter   271/  823] train: loss: 0.0003359
[Epoch 144; Iter   301/  823] train: loss: 0.0125443
[Epoch 144; Iter   331/  823] train: loss: 0.0026891
[Epoch 144; Iter   361/  823] train: loss: 0.0082710
[Epoch 144; Iter   391/  823] train: loss: 0.0002925
[Epoch 144; Iter   421/  823] train: loss: 0.0119030
[Epoch 144; Iter   451/  823] train: loss: 0.0003856
[Epoch 144; Iter   481/  823] train: loss: 0.0050514
[Epoch 144; Iter   511/  823] train: loss: 0.0353276
[Epoch 144; Iter   541/  823] train: loss: 0.0073163
[Epoch 144; Iter   571/  823] train: loss: 0.0067654
[Epoch 144; Iter   601/  823] train: loss: 0.0166959
[Epoch 144; Iter   631/  823] train: loss: 0.0005466
[Epoch 144; Iter   661/  823] train: loss: 0.0193053
[Epoch 144; Iter   691/  823] train: loss: 0.0110802
[Epoch 144; Iter   721/  823] train: loss: 0.0000790
[Epoch 144; Iter   751/  823] train: loss: 0.0080181
[Epoch 144; Iter   781/  823] train: loss: 0.0216552
[Epoch 144; Iter   811/  823] train: loss: 0.0091550
[Epoch 144] ogbg-molhiv: 0.735626 val loss: 0.335635
[Epoch 144] ogbg-molhiv: 0.752025 test loss: 0.241260
[Epoch 145; Iter    18/  823] train: loss: 0.0214455
[Epoch 145; Iter    48/  823] train: loss: 0.0007103
[Epoch 145; Iter    78/  823] train: loss: 0.0049265
[Epoch 145; Iter   108/  823] train: loss: 0.0051463
[Epoch 145; Iter   138/  823] train: loss: 0.0013485
[Epoch 145; Iter   168/  823] train: loss: 0.0202617
[Epoch 145; Iter   198/  823] train: loss: 0.0151999
[Epoch 145; Iter   228/  823] train: loss: 0.0015954
[Epoch 145; Iter   258/  823] train: loss: 0.0310383
[Epoch 145; Iter   288/  823] train: loss: 0.0041192
[Epoch 145; Iter   318/  823] train: loss: 0.0017299
[Epoch 145; Iter   348/  823] train: loss: 0.0007028
[Epoch 145; Iter   378/  823] train: loss: 0.0398094
[Epoch 145; Iter   408/  823] train: loss: 0.0009896
[Epoch 145; Iter   438/  823] train: loss: 0.0002179
[Epoch 145; Iter   468/  823] train: loss: 0.0103713
[Epoch 145; Iter   498/  823] train: loss: 0.0044885
[Epoch 145; Iter   528/  823] train: loss: 0.0010886
[Epoch 145; Iter   558/  823] train: loss: 0.0008196
[Epoch 145; Iter   588/  823] train: loss: 0.0006093
[Epoch 145; Iter   618/  823] train: loss: 0.0017644
[Epoch 145; Iter   648/  823] train: loss: 0.0015418
[Epoch 145; Iter   678/  823] train: loss: 0.0012707
[Epoch 145; Iter   708/  823] train: loss: 0.0017915
[Epoch 145; Iter   738/  823] train: loss: 0.0242800
[Epoch 145; Iter   768/  823] train: loss: 0.0171579
[Epoch 145; Iter   798/  823] train: loss: 0.0004894
[Epoch 145] ogbg-molhiv: 0.734857 val loss: 0.601243
[Epoch 145] ogbg-molhiv: 0.749321 test loss: 0.644216
[Epoch 146; Iter     5/  823] train: loss: 0.0102855
[Epoch 146; Iter    35/  823] train: loss: 0.0056249
[Epoch 146; Iter    65/  823] train: loss: 0.0141271
[Epoch 146; Iter    95/  823] train: loss: 0.0003596
[Epoch 146; Iter   125/  823] train: loss: 0.0076571
[Epoch 146; Iter   155/  823] train: loss: 0.0000387
[Epoch 146; Iter   185/  823] train: loss: 0.0002050
[Epoch 146; Iter   215/  823] train: loss: 0.0152102
[Epoch 146; Iter   245/  823] train: loss: 0.0160210
[Epoch 146; Iter   275/  823] train: loss: 0.0017883
[Epoch 146; Iter   305/  823] train: loss: 0.0361953
[Epoch 146; Iter   335/  823] train: loss: 0.0005073
[Epoch 146; Iter   365/  823] train: loss: 0.0026241
[Epoch 146; Iter   395/  823] train: loss: 0.0001831
[Epoch 146; Iter   425/  823] train: loss: 0.0001536
[Epoch 146; Iter   455/  823] train: loss: 0.0010006
[Epoch 146; Iter   485/  823] train: loss: 0.0001541
[Epoch 146; Iter   515/  823] train: loss: 0.0051369
[Epoch 146; Iter   545/  823] train: loss: 0.0003642
[Epoch 146; Iter   575/  823] train: loss: 0.0006155
[Epoch 146; Iter   605/  823] train: loss: 0.0554197
[Epoch 146; Iter   635/  823] train: loss: 0.0014353
[Epoch 146; Iter   665/  823] train: loss: 0.0048432
[Epoch 146; Iter   695/  823] train: loss: 0.0017409
[Epoch 146; Iter   725/  823] train: loss: 0.0217923
[Epoch 146; Iter   755/  823] train: loss: 0.0031280
[Epoch 146; Iter   785/  823] train: loss: 0.0014369
[Epoch 146; Iter   815/  823] train: loss: 0.0115946
[Epoch 146] ogbg-molhiv: 0.738819 val loss: 0.521513
[Epoch 146] ogbg-molhiv: 0.756842 test loss: 0.544666
Early stopping criterion based on -ogbg-molhiv- that should be max reached after 146 epochs. Best model checkpoint was in epoch 86.
Statistics on  val_best_checkpoint
mean_pred: -9.853950500488281
std_pred: 5.033872127532959
mean_targets: 0.035501521080732346
std_targets: 0.18505491316318512
prcauc: 0.2649556232986785
rocauc: 0.7498871110619935
ogbg-molhiv: 0.7498871110619935
BCEWithLogitsLoss: 0.2630898102496444
Statistics on  test
mean_pred: -10.295827865600586
std_pred: 5.306612014770508
mean_targets: 0.025650376453995705
std_targets: 0.15809957683086395
prcauc: 0.24354574690701122
rocauc: 0.7675549103724355
ogbg-molhiv: 0.7675549103724355
BCEWithLogitsLoss: 0.20899472695333482
Statistics on  train
mean_pred: -10.423539161682129
std_pred: 5.048061847686768
mean_targets: 0.0380936935544014
std_targets: 0.1914263665676117
prcauc: 0.9796914738229252
rocauc: 0.9993766538304326
ogbg-molhiv: 0.9993766538304326
BCEWithLogitsLoss: 0.014244782622219804
All runs completed.
