>>> Starting run for dataset: toxcast
Running RANDOM configs_split_experiments/GraphCL/toxcast/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/toxcast/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/toxcast/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/toxcast/random/train_prop=0.7.yml --seed 6 --device cuda:1
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.8/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.8_6_26-05_09-42-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.8
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931281
[Epoch 1; Iter    60/  229] train: loss: 0.6931188
[Epoch 1; Iter    90/  229] train: loss: 0.6931593
[Epoch 1; Iter   120/  229] train: loss: 0.6931772
[Epoch 1; Iter   150/  229] train: loss: 0.6931742
[Epoch 1; Iter   180/  229] train: loss: 0.6931670
[Epoch 1; Iter   210/  229] train: loss: 0.6930994
[Epoch 1] ogbg-moltoxcast: 0.514057 val loss: 0.693105
[Epoch 1] ogbg-moltoxcast: 0.521551 test loss: 0.693111
[Epoch 2; Iter    11/  229] train: loss: 0.6930727
[Epoch 2; Iter    41/  229] train: loss: 0.6931052
[Epoch 2; Iter    71/  229] train: loss: 0.6931010
[Epoch 2; Iter   101/  229] train: loss: 0.6930829
[Epoch 2; Iter   131/  229] train: loss: 0.6930619
[Epoch 2; Iter   161/  229] train: loss: 0.6930178
[Epoch 2; Iter   191/  229] train: loss: 0.6930614
[Epoch 2; Iter   221/  229] train: loss: 0.6930398
[Epoch 2] ogbg-moltoxcast: 0.515692 val loss: 0.693000
[Epoch 2] ogbg-moltoxcast: 0.522098 test loss: 0.693010
[Epoch 3; Iter    22/  229] train: loss: 0.6929955
[Epoch 3; Iter    52/  229] train: loss: 0.6930646
[Epoch 3; Iter    82/  229] train: loss: 0.6929022
[Epoch 3; Iter   112/  229] train: loss: 0.6929036
[Epoch 3; Iter   142/  229] train: loss: 0.6928427
[Epoch 3; Iter   172/  229] train: loss: 0.6928523
[Epoch 3; Iter   202/  229] train: loss: 0.6928920
[Epoch 3] ogbg-moltoxcast: 0.516625 val loss: 0.692827
[Epoch 3] ogbg-moltoxcast: 0.523581 test loss: 0.692842
[Epoch 4; Iter     3/  229] train: loss: 0.6928028
[Epoch 4; Iter    33/  229] train: loss: 0.6895818
[Epoch 4; Iter    63/  229] train: loss: 0.6766738
[Epoch 4; Iter    93/  229] train: loss: 0.6522578
[Epoch 4; Iter   123/  229] train: loss: 0.5918161
[Epoch 4; Iter   153/  229] train: loss: 0.5592765
[Epoch 4; Iter   183/  229] train: loss: 0.5340970
[Epoch 4; Iter   213/  229] train: loss: 0.4150712
[Epoch 4] ogbg-moltoxcast: 0.595999 val loss: 0.442379
[Epoch 4] ogbg-moltoxcast: 0.635286 test loss: 0.449801
[Epoch 5; Iter    14/  229] train: loss: 0.3898945
[Epoch 5; Iter    44/  229] train: loss: 0.3268030
[Epoch 5; Iter    74/  229] train: loss: 0.3703889
[Epoch 5; Iter   104/  229] train: loss: 0.3524470
[Epoch 5; Iter   134/  229] train: loss: 0.2844873
[Epoch 5; Iter   164/  229] train: loss: 0.3056589
[Epoch 5; Iter   194/  229] train: loss: 0.2135930
[Epoch 5; Iter   224/  229] train: loss: 0.2320439
[Epoch 5] ogbg-moltoxcast: 0.640460 val loss: 0.237778
[Epoch 5] ogbg-moltoxcast: 0.673912 test loss: 0.257706
[Epoch 6; Iter    25/  229] train: loss: 0.1979477
[Epoch 6; Iter    55/  229] train: loss: 0.2027349
[Epoch 6; Iter    85/  229] train: loss: 0.2423036
[Epoch 6; Iter   115/  229] train: loss: 0.2242311
[Epoch 6; Iter   145/  229] train: loss: 0.2429745
[Epoch 6; Iter   175/  229] train: loss: 0.2767845
[Epoch 6; Iter   205/  229] train: loss: 0.1689533
[Epoch 6] ogbg-moltoxcast: 0.648482 val loss: 0.215970
[Epoch 6] ogbg-moltoxcast: 0.694129 test loss: 0.230563
[Epoch 7; Iter     6/  229] train: loss: 0.3011545
[Epoch 7; Iter    36/  229] train: loss: 0.1506510
[Epoch 7; Iter    66/  229] train: loss: 0.1487450
[Epoch 7; Iter    96/  229] train: loss: 0.1718961
[Epoch 7; Iter   126/  229] train: loss: 0.2368807
[Epoch 7; Iter   156/  229] train: loss: 0.2248905
[Epoch 7; Iter   186/  229] train: loss: 0.3732083
[Epoch 7; Iter   216/  229] train: loss: 0.2510923
[Epoch 7] ogbg-moltoxcast: 0.640352 val loss: 0.214794
[Epoch 7] ogbg-moltoxcast: 0.690440 test loss: 0.225286
[Epoch 8; Iter    17/  229] train: loss: 0.1658127
[Epoch 8; Iter    47/  229] train: loss: 0.1703839
[Epoch 8; Iter    77/  229] train: loss: 0.2506223
[Epoch 8; Iter   107/  229] train: loss: 0.1794596
[Epoch 8; Iter   137/  229] train: loss: 0.2029225
[Epoch 8; Iter   167/  229] train: loss: 0.1705522
[Epoch 8; Iter   197/  229] train: loss: 0.2938911
[Epoch 8; Iter   227/  229] train: loss: 0.1544920
[Epoch 8] ogbg-moltoxcast: 0.649953 val loss: 0.213131
[Epoch 8] ogbg-moltoxcast: 0.679437 test loss: 0.229297
[Epoch 9; Iter    28/  229] train: loss: 0.1795996
[Epoch 9; Iter    58/  229] train: loss: 0.1607771
[Epoch 9; Iter    88/  229] train: loss: 0.1433585
[Epoch 9; Iter   118/  229] train: loss: 0.2581603
[Epoch 9; Iter   148/  229] train: loss: 0.2591493
[Epoch 9; Iter   178/  229] train: loss: 0.1454762
[Epoch 9; Iter   208/  229] train: loss: 0.2611587
[Epoch 9] ogbg-moltoxcast: 0.679713 val loss: 0.207395
[Epoch 9] ogbg-moltoxcast: 0.692896 test loss: 0.235102
[Epoch 10; Iter     9/  229] train: loss: 0.3241443
[Epoch 10; Iter    39/  229] train: loss: 0.2199450
[Epoch 10; Iter    69/  229] train: loss: 0.2343254
[Epoch 10; Iter    99/  229] train: loss: 0.3433071
[Epoch 10; Iter   129/  229] train: loss: 0.1549657
[Epoch 10; Iter   159/  229] train: loss: 0.1928856
[Epoch 10; Iter   189/  229] train: loss: 0.2502577
[Epoch 10; Iter   219/  229] train: loss: 0.2217430
[Epoch 10] ogbg-moltoxcast: 0.677471 val loss: 0.209423
[Epoch 10] ogbg-moltoxcast: 0.701350 test loss: 0.221104
[Epoch 11; Iter    20/  229] train: loss: 0.2118175
[Epoch 11; Iter    50/  229] train: loss: 0.2348550
[Epoch 11; Iter    80/  229] train: loss: 0.1580680
[Epoch 11; Iter   110/  229] train: loss: 0.1396993
[Epoch 11; Iter   140/  229] train: loss: 0.3424267
[Epoch 11; Iter   170/  229] train: loss: 0.2018761
[Epoch 11; Iter   200/  229] train: loss: 0.2135673
[Epoch 11] ogbg-moltoxcast: 0.697647 val loss: 0.205869
[Epoch 11] ogbg-moltoxcast: 0.713533 test loss: 0.219227
[Epoch 12; Iter     1/  229] train: loss: 0.2852162
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.8/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.8_4_26-05_09-42-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.8
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931443
[Epoch 1; Iter    60/  229] train: loss: 0.6931453
[Epoch 1; Iter    90/  229] train: loss: 0.6931266
[Epoch 1; Iter   120/  229] train: loss: 0.6931587
[Epoch 1; Iter   150/  229] train: loss: 0.6931423
[Epoch 1; Iter   180/  229] train: loss: 0.6931329
[Epoch 1; Iter   210/  229] train: loss: 0.6931086
[Epoch 1] ogbg-moltoxcast: 0.502011 val loss: 0.693107
[Epoch 1] ogbg-moltoxcast: 0.492581 test loss: 0.693112
[Epoch 2; Iter    11/  229] train: loss: 0.6930975
[Epoch 2; Iter    41/  229] train: loss: 0.6930580
[Epoch 2; Iter    71/  229] train: loss: 0.6930861
[Epoch 2; Iter   101/  229] train: loss: 0.6930239
[Epoch 2; Iter   131/  229] train: loss: 0.6930225
[Epoch 2; Iter   161/  229] train: loss: 0.6930715
[Epoch 2; Iter   191/  229] train: loss: 0.6930481
[Epoch 2; Iter   221/  229] train: loss: 0.6930736
[Epoch 2] ogbg-moltoxcast: 0.501010 val loss: 0.693010
[Epoch 2] ogbg-moltoxcast: 0.491546 test loss: 0.693014
[Epoch 3; Iter    22/  229] train: loss: 0.6930305
[Epoch 3; Iter    52/  229] train: loss: 0.6929485
[Epoch 3; Iter    82/  229] train: loss: 0.6929837
[Epoch 3; Iter   112/  229] train: loss: 0.6929281
[Epoch 3; Iter   142/  229] train: loss: 0.6928749
[Epoch 3; Iter   172/  229] train: loss: 0.6928672
[Epoch 3; Iter   202/  229] train: loss: 0.6929517
[Epoch 3] ogbg-moltoxcast: 0.503518 val loss: 0.692841
[Epoch 3] ogbg-moltoxcast: 0.491582 test loss: 0.692850
[Epoch 4; Iter     3/  229] train: loss: 0.6929088
[Epoch 4; Iter    33/  229] train: loss: 0.6899785
[Epoch 4; Iter    63/  229] train: loss: 0.6703802
[Epoch 4; Iter    93/  229] train: loss: 0.6402079
[Epoch 4; Iter   123/  229] train: loss: 0.6169616
[Epoch 4; Iter   153/  229] train: loss: 0.5680179
[Epoch 4; Iter   183/  229] train: loss: 0.5363653
[Epoch 4; Iter   213/  229] train: loss: 0.4745858
[Epoch 4] ogbg-moltoxcast: 0.592036 val loss: 0.426108
[Epoch 4] ogbg-moltoxcast: 0.608408 test loss: 0.435624
[Epoch 5; Iter    14/  229] train: loss: 0.4126874
[Epoch 5; Iter    44/  229] train: loss: 0.3497908
[Epoch 5; Iter    74/  229] train: loss: 0.3405697
[Epoch 5; Iter   104/  229] train: loss: 0.2569877
[Epoch 5; Iter   134/  229] train: loss: 0.2885181
[Epoch 5; Iter   164/  229] train: loss: 0.2441446
[Epoch 5; Iter   194/  229] train: loss: 0.1743830
[Epoch 5; Iter   224/  229] train: loss: 0.1801016
[Epoch 5] ogbg-moltoxcast: 0.630502 val loss: 0.233457
[Epoch 5] ogbg-moltoxcast: 0.675952 test loss: 0.245703
[Epoch 6; Iter    25/  229] train: loss: 0.2902556
[Epoch 6; Iter    55/  229] train: loss: 0.2588431
[Epoch 6; Iter    85/  229] train: loss: 0.1903943
[Epoch 6; Iter   115/  229] train: loss: 0.1869939
[Epoch 6; Iter   145/  229] train: loss: 0.1534756
[Epoch 6; Iter   175/  229] train: loss: 0.2791626
[Epoch 6; Iter   205/  229] train: loss: 0.2616502
[Epoch 6] ogbg-moltoxcast: 0.658745 val loss: 0.214777
[Epoch 6] ogbg-moltoxcast: 0.679174 test loss: 0.232827
[Epoch 7; Iter     6/  229] train: loss: 0.1798807
[Epoch 7; Iter    36/  229] train: loss: 0.2348796
[Epoch 7; Iter    66/  229] train: loss: 0.1940296
[Epoch 7; Iter    96/  229] train: loss: 0.2690409
[Epoch 7; Iter   126/  229] train: loss: 0.2025692
[Epoch 7; Iter   156/  229] train: loss: 0.2171265
[Epoch 7; Iter   186/  229] train: loss: 0.2454478
[Epoch 7; Iter   216/  229] train: loss: 0.1951694
[Epoch 7] ogbg-moltoxcast: 0.642685 val loss: 0.215424
[Epoch 7] ogbg-moltoxcast: 0.670823 test loss: 0.232016
[Epoch 8; Iter    17/  229] train: loss: 0.2978056
[Epoch 8; Iter    47/  229] train: loss: 0.1700133
[Epoch 8; Iter    77/  229] train: loss: 0.1919441
[Epoch 8; Iter   107/  229] train: loss: 0.1580487
[Epoch 8; Iter   137/  229] train: loss: 0.1910871
[Epoch 8; Iter   167/  229] train: loss: 0.2357806
[Epoch 8; Iter   197/  229] train: loss: 0.3248505
[Epoch 8; Iter   227/  229] train: loss: 0.1807326
[Epoch 8] ogbg-moltoxcast: 0.643884 val loss: 0.220744
[Epoch 8] ogbg-moltoxcast: 0.650984 test loss: 0.242339
[Epoch 9; Iter    28/  229] train: loss: 0.2227486
[Epoch 9; Iter    58/  229] train: loss: 0.1980956
[Epoch 9; Iter    88/  229] train: loss: 0.2097753
[Epoch 9; Iter   118/  229] train: loss: 0.2148151
[Epoch 9; Iter   148/  229] train: loss: 0.2350358
[Epoch 9; Iter   178/  229] train: loss: 0.2500835
[Epoch 9; Iter   208/  229] train: loss: 0.2953180
[Epoch 9] ogbg-moltoxcast: 0.669498 val loss: 0.210784
[Epoch 9] ogbg-moltoxcast: 0.671700 test loss: 0.230683
[Epoch 10; Iter     9/  229] train: loss: 0.1391427
[Epoch 10; Iter    39/  229] train: loss: 0.1260643
[Epoch 10; Iter    69/  229] train: loss: 0.1968133
[Epoch 10; Iter    99/  229] train: loss: 0.2243515
[Epoch 10; Iter   129/  229] train: loss: 0.2033166
[Epoch 10; Iter   159/  229] train: loss: 0.1956978
[Epoch 10; Iter   189/  229] train: loss: 0.1963190
[Epoch 10; Iter   219/  229] train: loss: 0.1557975
[Epoch 10] ogbg-moltoxcast: 0.678674 val loss: 0.211076
[Epoch 10] ogbg-moltoxcast: 0.690934 test loss: 0.228792
[Epoch 11; Iter    20/  229] train: loss: 0.2430913
[Epoch 11; Iter    50/  229] train: loss: 0.1759237
[Epoch 11; Iter    80/  229] train: loss: 0.1686681
[Epoch 11; Iter   110/  229] train: loss: 0.1874902
[Epoch 11; Iter   140/  229] train: loss: 0.1758320
[Epoch 11; Iter   170/  229] train: loss: 0.2208474
[Epoch 11; Iter   200/  229] train: loss: 0.1829443
[Epoch 11] ogbg-moltoxcast: 0.685995 val loss: 0.207881
[Epoch 11] ogbg-moltoxcast: 0.699330 test loss: 0.231145
[Epoch 12; Iter     1/  229] train: loss: 0.2132445
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.8/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.8_5_26-05_09-42-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.8
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  229] train: loss: 0.6931503
[Epoch 1; Iter    60/  229] train: loss: 0.6931139
[Epoch 1; Iter    90/  229] train: loss: 0.6932184
[Epoch 1; Iter   120/  229] train: loss: 0.6931351
[Epoch 1; Iter   150/  229] train: loss: 0.6931988
[Epoch 1; Iter   180/  229] train: loss: 0.6931189
[Epoch 1; Iter   210/  229] train: loss: 0.6931133
[Epoch 1] ogbg-moltoxcast: 0.497805 val loss: 0.693117
[Epoch 1] ogbg-moltoxcast: 0.506495 test loss: 0.693111
[Epoch 2; Iter    11/  229] train: loss: 0.6930926
[Epoch 2; Iter    41/  229] train: loss: 0.6930466
[Epoch 2; Iter    71/  229] train: loss: 0.6930389
[Epoch 2; Iter   101/  229] train: loss: 0.6930423
[Epoch 2; Iter   131/  229] train: loss: 0.6931227
[Epoch 2; Iter   161/  229] train: loss: 0.6929660
[Epoch 2; Iter   191/  229] train: loss: 0.6930668
[Epoch 2; Iter   221/  229] train: loss: 0.6929554
[Epoch 2] ogbg-moltoxcast: 0.499127 val loss: 0.692966
[Epoch 2] ogbg-moltoxcast: 0.506225 test loss: 0.692963
[Epoch 3; Iter    22/  229] train: loss: 0.6930177
[Epoch 3; Iter    52/  229] train: loss: 0.6928983
[Epoch 3; Iter    82/  229] train: loss: 0.6929395
[Epoch 3; Iter   112/  229] train: loss: 0.6928648
[Epoch 3; Iter   142/  229] train: loss: 0.6928152
[Epoch 3; Iter   172/  229] train: loss: 0.6926673
[Epoch 3; Iter   202/  229] train: loss: 0.6927706
[Epoch 3] ogbg-moltoxcast: 0.498066 val loss: 0.692725
[Epoch 3] ogbg-moltoxcast: 0.509923 test loss: 0.692727
[Epoch 4; Iter     3/  229] train: loss: 0.6927652
[Epoch 4; Iter    33/  229] train: loss: 0.6896527
[Epoch 4; Iter    63/  229] train: loss: 0.6797185
[Epoch 4; Iter    93/  229] train: loss: 0.6437347
[Epoch 4; Iter   123/  229] train: loss: 0.6037846
[Epoch 4; Iter   153/  229] train: loss: 0.5505587
[Epoch 4; Iter   183/  229] train: loss: 0.4903587
[Epoch 4; Iter   213/  229] train: loss: 0.4786153
[Epoch 4] ogbg-moltoxcast: 0.607621 val loss: 0.470665
[Epoch 4] ogbg-moltoxcast: 0.641203 test loss: 0.475571
[Epoch 5; Iter    14/  229] train: loss: 0.3980110
[Epoch 5; Iter    44/  229] train: loss: 0.3525656
[Epoch 5; Iter    74/  229] train: loss: 0.3345218
[Epoch 5; Iter   104/  229] train: loss: 0.3074728
[Epoch 5; Iter   134/  229] train: loss: 0.2771439
[Epoch 5; Iter   164/  229] train: loss: 0.3172911
[Epoch 5; Iter   194/  229] train: loss: 0.2003143
[Epoch 5; Iter   224/  229] train: loss: 0.2618719
[Epoch 5] ogbg-moltoxcast: 0.633385 val loss: 0.231813
[Epoch 5] ogbg-moltoxcast: 0.678112 test loss: 0.248826
[Epoch 6; Iter    25/  229] train: loss: 0.2364196
[Epoch 6; Iter    55/  229] train: loss: 0.2219919
[Epoch 6; Iter    85/  229] train: loss: 0.1889784
[Epoch 6; Iter   115/  229] train: loss: 0.2415799
[Epoch 6; Iter   145/  229] train: loss: 0.2692352
[Epoch 6; Iter   175/  229] train: loss: 0.2111568
[Epoch 6; Iter   205/  229] train: loss: 0.2074407
[Epoch 6] ogbg-moltoxcast: 0.646543 val loss: 0.217874
[Epoch 6] ogbg-moltoxcast: 0.681426 test loss: 0.247812
[Epoch 7; Iter     6/  229] train: loss: 0.2642551
[Epoch 7; Iter    36/  229] train: loss: 0.2583423
[Epoch 7; Iter    66/  229] train: loss: 0.2100251
[Epoch 7; Iter    96/  229] train: loss: 0.2455047
[Epoch 7; Iter   126/  229] train: loss: 0.1437688
[Epoch 7; Iter   156/  229] train: loss: 0.1803299
[Epoch 7; Iter   186/  229] train: loss: 0.2882014
[Epoch 7; Iter   216/  229] train: loss: 0.1892872
[Epoch 7] ogbg-moltoxcast: 0.621381 val loss: 0.224551
[Epoch 7] ogbg-moltoxcast: 0.650485 test loss: 0.240887
[Epoch 8; Iter    17/  229] train: loss: 0.2418476
[Epoch 8; Iter    47/  229] train: loss: 0.1664489
[Epoch 8; Iter    77/  229] train: loss: 0.1976339
[Epoch 8; Iter   107/  229] train: loss: 0.2992834
[Epoch 8; Iter   137/  229] train: loss: 0.1653881
[Epoch 8; Iter   167/  229] train: loss: 0.1451889
[Epoch 8; Iter   197/  229] train: loss: 0.1984990
[Epoch 8; Iter   227/  229] train: loss: 0.2505749
[Epoch 8] ogbg-moltoxcast: 0.660227 val loss: 0.212394
[Epoch 8] ogbg-moltoxcast: 0.665436 test loss: 0.229819
[Epoch 9; Iter    28/  229] train: loss: 0.2437872
[Epoch 9; Iter    58/  229] train: loss: 0.2587199
[Epoch 9; Iter    88/  229] train: loss: 0.2179587
[Epoch 9; Iter   118/  229] train: loss: 0.1887239
[Epoch 9; Iter   148/  229] train: loss: 0.2072239
[Epoch 9; Iter   178/  229] train: loss: 0.2511516
[Epoch 9; Iter   208/  229] train: loss: 0.2359329
[Epoch 9] ogbg-moltoxcast: 0.684191 val loss: 0.208683
[Epoch 9] ogbg-moltoxcast: 0.704828 test loss: 0.228821
[Epoch 10; Iter     9/  229] train: loss: 0.2167725
[Epoch 10; Iter    39/  229] train: loss: 0.2641581
[Epoch 10; Iter    69/  229] train: loss: 0.1912127
[Epoch 10; Iter    99/  229] train: loss: 0.2471154
[Epoch 10; Iter   129/  229] train: loss: 0.2024214
[Epoch 10; Iter   159/  229] train: loss: 0.2619975
[Epoch 10; Iter   189/  229] train: loss: 0.2297792
[Epoch 10; Iter   219/  229] train: loss: 0.1673836
[Epoch 10] ogbg-moltoxcast: 0.688555 val loss: 0.206153
[Epoch 10] ogbg-moltoxcast: 0.710828 test loss: 0.222353
[Epoch 11; Iter    20/  229] train: loss: 0.2535909
[Epoch 11; Iter    50/  229] train: loss: 0.2553768
[Epoch 11; Iter    80/  229] train: loss: 0.2505186
[Epoch 11; Iter   110/  229] train: loss: 0.1970078
[Epoch 11; Iter   140/  229] train: loss: 0.1987702
[Epoch 11; Iter   170/  229] train: loss: 0.2249402
[Epoch 11; Iter   200/  229] train: loss: 0.1655571
[Epoch 11] ogbg-moltoxcast: 0.693781 val loss: 0.201705
[Epoch 11] ogbg-moltoxcast: 0.722405 test loss: 0.216215
[Epoch 12; Iter     1/  229] train: loss: 0.2216431
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.7/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.7_4_26-05_09-42-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.7
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931522
[Epoch 1; Iter    60/  201] train: loss: 0.6931528
[Epoch 1; Iter    90/  201] train: loss: 0.6931289
[Epoch 1; Iter   120/  201] train: loss: 0.6931672
[Epoch 1; Iter   150/  201] train: loss: 0.6931275
[Epoch 1; Iter   180/  201] train: loss: 0.6930655
[Epoch 1] ogbg-moltoxcast: 0.498218 val loss: 0.693120
[Epoch 1] ogbg-moltoxcast: 0.491767 test loss: 0.693123
[Epoch 2; Iter     9/  201] train: loss: 0.6931061
[Epoch 2; Iter    39/  201] train: loss: 0.6930987
[Epoch 2; Iter    69/  201] train: loss: 0.6931026
[Epoch 2; Iter    99/  201] train: loss: 0.6930334
[Epoch 2; Iter   129/  201] train: loss: 0.6930984
[Epoch 2; Iter   159/  201] train: loss: 0.6930431
[Epoch 2; Iter   189/  201] train: loss: 0.6930339
[Epoch 2] ogbg-moltoxcast: 0.498859 val loss: 0.693034
[Epoch 2] ogbg-moltoxcast: 0.489199 test loss: 0.693036
[Epoch 3; Iter    18/  201] train: loss: 0.6929701
[Epoch 3; Iter    48/  201] train: loss: 0.6929843
[Epoch 3; Iter    78/  201] train: loss: 0.6930678
[Epoch 3; Iter   108/  201] train: loss: 0.6929232
[Epoch 3; Iter   138/  201] train: loss: 0.6929560
[Epoch 3; Iter   168/  201] train: loss: 0.6929001
[Epoch 3; Iter   198/  201] train: loss: 0.6928626
[Epoch 3] ogbg-moltoxcast: 0.500030 val loss: 0.692916
[Epoch 3] ogbg-moltoxcast: 0.492340 test loss: 0.692916
[Epoch 4; Iter    27/  201] train: loss: 0.6928790
[Epoch 4; Iter    57/  201] train: loss: 0.6928833
[Epoch 4; Iter    87/  201] train: loss: 0.6927686
[Epoch 4; Iter   117/  201] train: loss: 0.6890879
[Epoch 4; Iter   147/  201] train: loss: 0.6692686
[Epoch 4; Iter   177/  201] train: loss: 0.6441824
[Epoch 4] ogbg-moltoxcast: 0.574981 val loss: 0.592366
[Epoch 4] ogbg-moltoxcast: 0.559343 test loss: 0.587760
[Epoch 5; Iter     6/  201] train: loss: 0.6074519
[Epoch 5; Iter    36/  201] train: loss: 0.5391246
[Epoch 5; Iter    66/  201] train: loss: 0.4776767
[Epoch 5; Iter    96/  201] train: loss: 0.4672156
[Epoch 5; Iter   126/  201] train: loss: 0.4055316
[Epoch 5; Iter   156/  201] train: loss: 0.3844886
[Epoch 5; Iter   186/  201] train: loss: 0.3575286
[Epoch 5] ogbg-moltoxcast: 0.594362 val loss: 0.313086
[Epoch 5] ogbg-moltoxcast: 0.617582 test loss: 0.310508
[Epoch 6; Iter    15/  201] train: loss: 0.2248241
[Epoch 6; Iter    45/  201] train: loss: 0.2571877
[Epoch 6; Iter    75/  201] train: loss: 0.2404916
[Epoch 6; Iter   105/  201] train: loss: 0.2498974
[Epoch 6; Iter   135/  201] train: loss: 0.2138875
[Epoch 6; Iter   165/  201] train: loss: 0.2294847
[Epoch 6; Iter   195/  201] train: loss: 0.2046453
[Epoch 6] ogbg-moltoxcast: 0.639655 val loss: 0.234948
[Epoch 6] ogbg-moltoxcast: 0.671046 test loss: 0.238362
[Epoch 7; Iter    24/  201] train: loss: 0.2189771
[Epoch 7; Iter    54/  201] train: loss: 0.1709258
[Epoch 7; Iter    84/  201] train: loss: 0.2391760
[Epoch 7; Iter   114/  201] train: loss: 0.1604455
[Epoch 7; Iter   144/  201] train: loss: 0.1936845
[Epoch 7; Iter   174/  201] train: loss: 0.1709847
[Epoch 7] ogbg-moltoxcast: 0.666033 val loss: 0.223099
[Epoch 7] ogbg-moltoxcast: 0.678599 test loss: 0.229309
[Epoch 8; Iter     3/  201] train: loss: 0.1659351
[Epoch 8; Iter    33/  201] train: loss: 0.2470749
[Epoch 8; Iter    63/  201] train: loss: 0.2145190
[Epoch 8; Iter    93/  201] train: loss: 0.1962108
[Epoch 8; Iter   123/  201] train: loss: 0.2108502
[Epoch 8; Iter   153/  201] train: loss: 0.1792554
[Epoch 8; Iter   183/  201] train: loss: 0.1910180
[Epoch 8] ogbg-moltoxcast: 0.662813 val loss: 0.232639
[Epoch 8] ogbg-moltoxcast: 0.637138 test loss: 0.243879
[Epoch 9; Iter    12/  201] train: loss: 0.2837183
[Epoch 9; Iter    42/  201] train: loss: 0.1814274
[Epoch 9; Iter    72/  201] train: loss: 0.2035555
[Epoch 9; Iter   102/  201] train: loss: 0.2385907
[Epoch 9; Iter   132/  201] train: loss: 0.1906608
[Epoch 9; Iter   162/  201] train: loss: 0.1299038
[Epoch 9; Iter   192/  201] train: loss: 0.1666249
[Epoch 9] ogbg-moltoxcast: 0.685728 val loss: 0.216681
[Epoch 9] ogbg-moltoxcast: 0.698336 test loss: 0.221326
[Epoch 10; Iter    21/  201] train: loss: 0.2922648
[Epoch 10; Iter    51/  201] train: loss: 0.2208286
[Epoch 10; Iter    81/  201] train: loss: 0.2294927
[Epoch 10; Iter   111/  201] train: loss: 0.1689628
[Epoch 10; Iter   141/  201] train: loss: 0.1991203
[Epoch 10; Iter   171/  201] train: loss: 0.1581588
[Epoch 10; Iter   201/  201] train: loss: 0.0807770
[Epoch 10] ogbg-moltoxcast: 0.690516 val loss: 0.213394
[Epoch 10] ogbg-moltoxcast: 0.710247 test loss: 0.217385
[Epoch 11; Iter    30/  201] train: loss: 0.1883859
[Epoch 11; Iter    60/  201] train: loss: 0.2497952
[Epoch 11; Iter    90/  201] train: loss: 0.1328386
[Epoch 11; Iter   120/  201] train: loss: 0.2821202
[Epoch 11; Iter   150/  201] train: loss: 0.1684666
[Epoch 11; Iter   180/  201] train: loss: 0.1788960
[Epoch 11] ogbg-moltoxcast: 0.680394 val loss: 0.218720
[Epoch 11] ogbg-moltoxcast: 0.700492 test loss: 0.221606
[Epoch 12; Iter     9/  201] train: loss: 0.2173891
[Epoch 12; Iter    39/  201] train: loss: 0.1687667
[Epoch 12; Iter    69/  201] train: loss: 0.2923627
[Epoch 12; Iter    99/  201] train: loss: 0.1957061
[Epoch 12; Iter   129/  201] train: loss: 0.1526186
[Epoch 12; Iter   159/  201] train: loss: 0.1442883
[Epoch 12; Iter   189/  201] train: loss: 0.1841085
[Epoch 12] ogbg-moltoxcast: 0.697166 val loss: 0.214559
[Epoch 12] ogbg-moltoxcast: 0.720993 test loss: 0.214698
[Epoch 13; Iter    18/  201] train: loss: 0.1731634
[Epoch 13; Iter    48/  201] train: loss: 0.2123246
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.7/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.7_6_26-05_09-42-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.7
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931499
[Epoch 1; Iter    60/  201] train: loss: 0.6931566
[Epoch 1; Iter    90/  201] train: loss: 0.6931285
[Epoch 1; Iter   120/  201] train: loss: 0.6931604
[Epoch 1; Iter   150/  201] train: loss: 0.6931227
[Epoch 1; Iter   180/  201] train: loss: 0.6931535
[Epoch 1] ogbg-moltoxcast: 0.509956 val loss: 0.693122
[Epoch 1] ogbg-moltoxcast: 0.519334 test loss: 0.693117
[Epoch 2; Iter     9/  201] train: loss: 0.6931838
[Epoch 2; Iter    39/  201] train: loss: 0.6930677
[Epoch 2; Iter    69/  201] train: loss: 0.6930590
[Epoch 2; Iter    99/  201] train: loss: 0.6930317
[Epoch 2; Iter   129/  201] train: loss: 0.6931272
[Epoch 2; Iter   159/  201] train: loss: 0.6930915
[Epoch 2; Iter   189/  201] train: loss: 0.6929981
[Epoch 2] ogbg-moltoxcast: 0.510298 val loss: 0.693039
[Epoch 2] ogbg-moltoxcast: 0.519406 test loss: 0.693031
[Epoch 3; Iter    18/  201] train: loss: 0.6929874
[Epoch 3; Iter    48/  201] train: loss: 0.6930057
[Epoch 3; Iter    78/  201] train: loss: 0.6929408
[Epoch 3; Iter   108/  201] train: loss: 0.6929705
[Epoch 3; Iter   138/  201] train: loss: 0.6929474
[Epoch 3; Iter   168/  201] train: loss: 0.6929485
[Epoch 3; Iter   198/  201] train: loss: 0.6928732
[Epoch 3] ogbg-moltoxcast: 0.508989 val loss: 0.692895
[Epoch 3] ogbg-moltoxcast: 0.517933 test loss: 0.692888
[Epoch 4; Iter    27/  201] train: loss: 0.6928794
[Epoch 4; Iter    57/  201] train: loss: 0.6927987
[Epoch 4; Iter    87/  201] train: loss: 0.6928156
[Epoch 4; Iter   117/  201] train: loss: 0.6903088
[Epoch 4; Iter   147/  201] train: loss: 0.6732322
[Epoch 4; Iter   177/  201] train: loss: 0.6322380
[Epoch 4] ogbg-moltoxcast: 0.562215 val loss: 0.647951
[Epoch 4] ogbg-moltoxcast: 0.583329 test loss: 0.640299
[Epoch 5; Iter     6/  201] train: loss: 0.6294119
[Epoch 5; Iter    36/  201] train: loss: 0.5496497
[Epoch 5; Iter    66/  201] train: loss: 0.5073417
[Epoch 5; Iter    96/  201] train: loss: 0.4549375
[Epoch 5; Iter   126/  201] train: loss: 0.4236534
[Epoch 5; Iter   156/  201] train: loss: 0.3712314
[Epoch 5; Iter   186/  201] train: loss: 0.3128820
[Epoch 5] ogbg-moltoxcast: 0.632981 val loss: 0.306214
[Epoch 5] ogbg-moltoxcast: 0.653716 test loss: 0.303025
[Epoch 6; Iter    15/  201] train: loss: 0.3342784
[Epoch 6; Iter    45/  201] train: loss: 0.2568991
[Epoch 6; Iter    75/  201] train: loss: 0.2431063
[Epoch 6; Iter   105/  201] train: loss: 0.2438528
[Epoch 6; Iter   135/  201] train: loss: 0.3104466
[Epoch 6; Iter   165/  201] train: loss: 0.1968227
[Epoch 6; Iter   195/  201] train: loss: 0.2076248
[Epoch 6] ogbg-moltoxcast: 0.650403 val loss: 0.237425
[Epoch 6] ogbg-moltoxcast: 0.674566 test loss: 0.238887
[Epoch 7; Iter    24/  201] train: loss: 0.1117254
[Epoch 7; Iter    54/  201] train: loss: 0.1930175
[Epoch 7; Iter    84/  201] train: loss: 0.2329355
[Epoch 7; Iter   114/  201] train: loss: 0.2295138
[Epoch 7; Iter   144/  201] train: loss: 0.2015982
[Epoch 7; Iter   174/  201] train: loss: 0.1700708
[Epoch 7] ogbg-moltoxcast: 0.664019 val loss: 0.237419
[Epoch 7] ogbg-moltoxcast: 0.683031 test loss: 0.241436
[Epoch 8; Iter     3/  201] train: loss: 0.2154904
[Epoch 8; Iter    33/  201] train: loss: 0.2014873
[Epoch 8; Iter    63/  201] train: loss: 0.2067086
[Epoch 8; Iter    93/  201] train: loss: 0.2126909
[Epoch 8; Iter   123/  201] train: loss: 0.2480620
[Epoch 8; Iter   153/  201] train: loss: 0.1521581
[Epoch 8; Iter   183/  201] train: loss: 0.2185728
[Epoch 8] ogbg-moltoxcast: 0.634157 val loss: 0.236959
[Epoch 8] ogbg-moltoxcast: 0.641903 test loss: 0.252231
[Epoch 9; Iter    12/  201] train: loss: 0.1974419
[Epoch 9; Iter    42/  201] train: loss: 0.1786352
[Epoch 9; Iter    72/  201] train: loss: 0.1693318
[Epoch 9; Iter   102/  201] train: loss: 0.2032250
[Epoch 9; Iter   132/  201] train: loss: 0.2503509
[Epoch 9; Iter   162/  201] train: loss: 0.2067559
[Epoch 9; Iter   192/  201] train: loss: 0.1397725
[Epoch 9] ogbg-moltoxcast: 0.640954 val loss: 0.234173
[Epoch 9] ogbg-moltoxcast: 0.664785 test loss: 0.251249
[Epoch 10; Iter    21/  201] train: loss: 0.2150651
[Epoch 10; Iter    51/  201] train: loss: 0.2118026
[Epoch 10; Iter    81/  201] train: loss: 0.2026610
[Epoch 10; Iter   111/  201] train: loss: 0.2876790
[Epoch 10; Iter   141/  201] train: loss: 0.2144410
[Epoch 10; Iter   171/  201] train: loss: 0.1274469
[Epoch 10; Iter   201/  201] train: loss: 0.2052138
[Epoch 10] ogbg-moltoxcast: 0.683347 val loss: 0.220570
[Epoch 10] ogbg-moltoxcast: 0.703385 test loss: 0.226975
[Epoch 11; Iter    30/  201] train: loss: 0.1959342
[Epoch 11; Iter    60/  201] train: loss: 0.2749293
[Epoch 11; Iter    90/  201] train: loss: 0.1748056
[Epoch 11; Iter   120/  201] train: loss: 0.1547120
[Epoch 11; Iter   150/  201] train: loss: 0.2655229
[Epoch 11; Iter   180/  201] train: loss: 0.1979104
[Epoch 11] ogbg-moltoxcast: 0.660419 val loss: 0.223582
[Epoch 11] ogbg-moltoxcast: 0.682388 test loss: 0.229430
[Epoch 12; Iter     9/  201] train: loss: 0.2439719
[Epoch 12; Iter    39/  201] train: loss: 0.2784686
[Epoch 12; Iter    69/  201] train: loss: 0.2117634
[Epoch 12; Iter    99/  201] train: loss: 0.1658403
[Epoch 12; Iter   129/  201] train: loss: 0.1977207
[Epoch 12; Iter   159/  201] train: loss: 0.2431188
[Epoch 12; Iter   189/  201] train: loss: 0.1902922
[Epoch 12] ogbg-moltoxcast: 0.690031 val loss: 0.213885
[Epoch 12] ogbg-moltoxcast: 0.709550 test loss: 0.219165
[Epoch 13; Iter    18/  201] train: loss: 0.1683634
[Epoch 13; Iter    48/  201] train: loss: 0.1589710
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.7/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.7_5_26-05_09-42-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.7
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  201] train: loss: 0.6931871
[Epoch 1; Iter    60/  201] train: loss: 0.6931036
[Epoch 1; Iter    90/  201] train: loss: 0.6931500
[Epoch 1; Iter   120/  201] train: loss: 0.6931447
[Epoch 1; Iter   150/  201] train: loss: 0.6930994
[Epoch 1; Iter   180/  201] train: loss: 0.6931604
[Epoch 1] ogbg-moltoxcast: 0.502844 val loss: 0.693110
[Epoch 1] ogbg-moltoxcast: 0.503962 test loss: 0.693102
[Epoch 2; Iter     9/  201] train: loss: 0.6931514
[Epoch 2; Iter    39/  201] train: loss: 0.6931212
[Epoch 2; Iter    69/  201] train: loss: 0.6930769
[Epoch 2; Iter    99/  201] train: loss: 0.6931028
[Epoch 2; Iter   129/  201] train: loss: 0.6931121
[Epoch 2; Iter   159/  201] train: loss: 0.6930799
[Epoch 2; Iter   189/  201] train: loss: 0.6929857
[Epoch 2] ogbg-moltoxcast: 0.502362 val loss: 0.693008
[Epoch 2] ogbg-moltoxcast: 0.504691 test loss: 0.692999
[Epoch 3; Iter    18/  201] train: loss: 0.6930012
[Epoch 3; Iter    48/  201] train: loss: 0.6929607
[Epoch 3; Iter    78/  201] train: loss: 0.6929264
[Epoch 3; Iter   108/  201] train: loss: 0.6929689
[Epoch 3; Iter   138/  201] train: loss: 0.6928799
[Epoch 3; Iter   168/  201] train: loss: 0.6928783
[Epoch 3; Iter   198/  201] train: loss: 0.6928910
[Epoch 3] ogbg-moltoxcast: 0.503088 val loss: 0.692845
[Epoch 3] ogbg-moltoxcast: 0.505843 test loss: 0.692832
[Epoch 4; Iter    27/  201] train: loss: 0.6927748
[Epoch 4; Iter    57/  201] train: loss: 0.6928049
[Epoch 4; Iter    87/  201] train: loss: 0.6927519
[Epoch 4; Iter   117/  201] train: loss: 0.6900405
[Epoch 4; Iter   147/  201] train: loss: 0.6687384
[Epoch 4; Iter   177/  201] train: loss: 0.6373171
[Epoch 4] ogbg-moltoxcast: 0.596946 val loss: 0.628947
[Epoch 4] ogbg-moltoxcast: 0.638929 test loss: 0.625289
[Epoch 5; Iter     6/  201] train: loss: 0.6139579
[Epoch 5; Iter    36/  201] train: loss: 0.5687540
[Epoch 5; Iter    66/  201] train: loss: 0.5128228
[Epoch 5; Iter    96/  201] train: loss: 0.4188161
[Epoch 5; Iter   126/  201] train: loss: 0.4344398
[Epoch 5; Iter   156/  201] train: loss: 0.3649093
[Epoch 5; Iter   186/  201] train: loss: 0.3041987
[Epoch 5] ogbg-moltoxcast: 0.612458 val loss: 0.331565
[Epoch 5] ogbg-moltoxcast: 0.633953 test loss: 0.326872
[Epoch 6; Iter    15/  201] train: loss: 0.3308772
[Epoch 6; Iter    45/  201] train: loss: 0.2968019
[Epoch 6; Iter    75/  201] train: loss: 0.2697890
[Epoch 6; Iter   105/  201] train: loss: 0.2921370
[Epoch 6; Iter   135/  201] train: loss: 0.1798418
[Epoch 6; Iter   165/  201] train: loss: 0.2154072
[Epoch 6; Iter   195/  201] train: loss: 0.2677024
[Epoch 6] ogbg-moltoxcast: 0.653540 val loss: 0.233008
[Epoch 6] ogbg-moltoxcast: 0.679235 test loss: 0.236160
[Epoch 7; Iter    24/  201] train: loss: 0.1917810
[Epoch 7; Iter    54/  201] train: loss: 0.2735113
[Epoch 7; Iter    84/  201] train: loss: 0.2076488
[Epoch 7; Iter   114/  201] train: loss: 0.1964095
[Epoch 7; Iter   144/  201] train: loss: 0.1705975
[Epoch 7; Iter   174/  201] train: loss: 0.2223931
[Epoch 7] ogbg-moltoxcast: 0.663153 val loss: 0.226164
[Epoch 7] ogbg-moltoxcast: 0.686339 test loss: 0.230806
[Epoch 8; Iter     3/  201] train: loss: 0.1968174
[Epoch 8; Iter    33/  201] train: loss: 0.2329023
[Epoch 8; Iter    63/  201] train: loss: 0.2517682
[Epoch 8; Iter    93/  201] train: loss: 0.1727835
[Epoch 8; Iter   123/  201] train: loss: 0.2053629
[Epoch 8; Iter   153/  201] train: loss: 0.2464956
[Epoch 8; Iter   183/  201] train: loss: 0.1566996
[Epoch 8] ogbg-moltoxcast: 0.651894 val loss: 0.228944
[Epoch 8] ogbg-moltoxcast: 0.678211 test loss: 0.231233
[Epoch 9; Iter    12/  201] train: loss: 0.3149391
[Epoch 9; Iter    42/  201] train: loss: 0.2208611
[Epoch 9; Iter    72/  201] train: loss: 0.2092980
[Epoch 9; Iter   102/  201] train: loss: 0.2078319
[Epoch 9; Iter   132/  201] train: loss: 0.1783243
[Epoch 9; Iter   162/  201] train: loss: 0.2487177
[Epoch 9; Iter   192/  201] train: loss: 0.1659155
[Epoch 9] ogbg-moltoxcast: 0.646579 val loss: 0.223551
[Epoch 9] ogbg-moltoxcast: 0.671253 test loss: 0.228570
[Epoch 10; Iter    21/  201] train: loss: 0.2967948
[Epoch 10; Iter    51/  201] train: loss: 0.1476859
[Epoch 10; Iter    81/  201] train: loss: 0.2169627
[Epoch 10; Iter   111/  201] train: loss: 0.1943585
[Epoch 10; Iter   141/  201] train: loss: 0.2281720
[Epoch 10; Iter   171/  201] train: loss: 0.2506221
[Epoch 10; Iter   201/  201] train: loss: 0.1428020
[Epoch 10] ogbg-moltoxcast: 0.673861 val loss: 0.218658
[Epoch 10] ogbg-moltoxcast: 0.700806 test loss: 0.221705
[Epoch 11; Iter    30/  201] train: loss: 0.2803726
[Epoch 11; Iter    60/  201] train: loss: 0.1712466
[Epoch 11; Iter    90/  201] train: loss: 0.2165441
[Epoch 11; Iter   120/  201] train: loss: 0.1968722
[Epoch 11; Iter   150/  201] train: loss: 0.1724808
[Epoch 11; Iter   180/  201] train: loss: 0.3141313
[Epoch 11] ogbg-moltoxcast: 0.672115 val loss: 0.218370
[Epoch 11] ogbg-moltoxcast: 0.697078 test loss: 0.221387
[Epoch 12; Iter     9/  201] train: loss: 0.1659351
[Epoch 12; Iter    39/  201] train: loss: 0.2351949
[Epoch 12; Iter    69/  201] train: loss: 0.1900365
[Epoch 12; Iter    99/  201] train: loss: 0.1888770
[Epoch 12; Iter   129/  201] train: loss: 0.1844078
[Epoch 12; Iter   159/  201] train: loss: 0.1838347
[Epoch 12; Iter   189/  201] train: loss: 0.2484830
[Epoch 12] ogbg-moltoxcast: 0.686102 val loss: 0.224132
[Epoch 12] ogbg-moltoxcast: 0.694734 test loss: 0.226110
[Epoch 13; Iter    18/  201] train: loss: 0.1896462
[Epoch 13; Iter    48/  201] train: loss: 0.1685768
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.6/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.6_5_26-05_09-42-10
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.6
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931757
[Epoch 1; Iter    60/  172] train: loss: 0.6931170
[Epoch 1; Iter    90/  172] train: loss: 0.6931573
[Epoch 1; Iter   120/  172] train: loss: 0.6931961
[Epoch 1; Iter   150/  172] train: loss: 0.6931599
[Epoch 1] ogbg-moltoxcast: 0.495742 val loss: 0.693135
[Epoch 1] ogbg-moltoxcast: 0.502797 test loss: 0.693125
[Epoch 2; Iter     8/  172] train: loss: 0.6930581
[Epoch 2; Iter    38/  172] train: loss: 0.6931066
[Epoch 2; Iter    68/  172] train: loss: 0.6930746
[Epoch 2; Iter    98/  172] train: loss: 0.6930969
[Epoch 2; Iter   128/  172] train: loss: 0.6930652
[Epoch 2; Iter   158/  172] train: loss: 0.6930733
[Epoch 2] ogbg-moltoxcast: 0.497694 val loss: 0.693051
[Epoch 2] ogbg-moltoxcast: 0.503105 test loss: 0.693043
[Epoch 3; Iter    16/  172] train: loss: 0.6930678
[Epoch 3; Iter    46/  172] train: loss: 0.6930287
[Epoch 3; Iter    76/  172] train: loss: 0.6931023
[Epoch 3; Iter   106/  172] train: loss: 0.6929847
[Epoch 3; Iter   136/  172] train: loss: 0.6929651
[Epoch 3; Iter   166/  172] train: loss: 0.6929309
[Epoch 3] ogbg-moltoxcast: 0.496040 val loss: 0.692923
[Epoch 3] ogbg-moltoxcast: 0.503060 test loss: 0.692913
[Epoch 4; Iter    24/  172] train: loss: 0.6928545
[Epoch 4; Iter    54/  172] train: loss: 0.6928231
[Epoch 4; Iter    84/  172] train: loss: 0.6928774
[Epoch 4; Iter   114/  172] train: loss: 0.6928195
[Epoch 4; Iter   144/  172] train: loss: 0.6927595
[Epoch 4] ogbg-moltoxcast: 0.497024 val loss: 0.692733
[Epoch 4] ogbg-moltoxcast: 0.503926 test loss: 0.692720
[Epoch 5; Iter     2/  172] train: loss: 0.6926558
[Epoch 5; Iter    32/  172] train: loss: 0.6898478
[Epoch 5; Iter    62/  172] train: loss: 0.6695390
[Epoch 5; Iter    92/  172] train: loss: 0.6298506
[Epoch 5; Iter   122/  172] train: loss: 0.5771372
[Epoch 5; Iter   152/  172] train: loss: 0.5505839
[Epoch 5] ogbg-moltoxcast: 0.612981 val loss: 0.533562
[Epoch 5] ogbg-moltoxcast: 0.620498 test loss: 0.527721
[Epoch 6; Iter    10/  172] train: loss: 0.5257414
[Epoch 6; Iter    40/  172] train: loss: 0.4625131
[Epoch 6; Iter    70/  172] train: loss: 0.3886600
[Epoch 6; Iter   100/  172] train: loss: 0.3401256
[Epoch 6; Iter   130/  172] train: loss: 0.2953344
[Epoch 6; Iter   160/  172] train: loss: 0.2624227
[Epoch 6] ogbg-moltoxcast: 0.636481 val loss: 0.275667
[Epoch 6] ogbg-moltoxcast: 0.636066 test loss: 0.272082
[Epoch 7; Iter    18/  172] train: loss: 0.3189832
[Epoch 7; Iter    48/  172] train: loss: 0.3020785
[Epoch 7; Iter    78/  172] train: loss: 0.2240057
[Epoch 7; Iter   108/  172] train: loss: 0.1717328
[Epoch 7; Iter   138/  172] train: loss: 0.2696994
[Epoch 7; Iter   168/  172] train: loss: 0.2040222
[Epoch 7] ogbg-moltoxcast: 0.665123 val loss: 0.228667
[Epoch 7] ogbg-moltoxcast: 0.653788 test loss: 0.229820
[Epoch 8; Iter    26/  172] train: loss: 0.1560064
[Epoch 8; Iter    56/  172] train: loss: 0.2780694
[Epoch 8; Iter    86/  172] train: loss: 0.2156322
[Epoch 8; Iter   116/  172] train: loss: 0.2050227
[Epoch 8; Iter   146/  172] train: loss: 0.1950546
[Epoch 8] ogbg-moltoxcast: 0.668154 val loss: 0.408169
[Epoch 8] ogbg-moltoxcast: 0.648924 test loss: 0.386433
[Epoch 9; Iter     4/  172] train: loss: 0.2608770
[Epoch 9; Iter    34/  172] train: loss: 0.2275784
[Epoch 9; Iter    64/  172] train: loss: 0.3118683
[Epoch 9; Iter    94/  172] train: loss: 0.2198053
[Epoch 9; Iter   124/  172] train: loss: 0.1914045
[Epoch 9; Iter   154/  172] train: loss: 0.1546276
[Epoch 9] ogbg-moltoxcast: 0.665648 val loss: 0.220490
[Epoch 9] ogbg-moltoxcast: 0.670022 test loss: 0.221365
[Epoch 10; Iter    12/  172] train: loss: 0.2545373
[Epoch 10; Iter    42/  172] train: loss: 0.2014652
[Epoch 10; Iter    72/  172] train: loss: 0.1901446
[Epoch 10; Iter   102/  172] train: loss: 0.2506997
[Epoch 10; Iter   132/  172] train: loss: 0.2524590
[Epoch 10; Iter   162/  172] train: loss: 0.1406814
[Epoch 10] ogbg-moltoxcast: 0.666118 val loss: 0.227668
[Epoch 10] ogbg-moltoxcast: 0.663688 test loss: 0.225277
[Epoch 11; Iter    20/  172] train: loss: 0.1963602
[Epoch 11; Iter    50/  172] train: loss: 0.1627018
[Epoch 11; Iter    80/  172] train: loss: 0.3157502
[Epoch 11; Iter   110/  172] train: loss: 0.2648888
[Epoch 11; Iter   140/  172] train: loss: 0.2542655
[Epoch 11; Iter   170/  172] train: loss: 0.1679602
[Epoch 11] ogbg-moltoxcast: 0.655216 val loss: 0.241851
[Epoch 11] ogbg-moltoxcast: 0.656834 test loss: 0.235747
[Epoch 12; Iter    28/  172] train: loss: 0.1805976
[Epoch 12; Iter    58/  172] train: loss: 0.1941227
[Epoch 12; Iter    88/  172] train: loss: 0.2114065
[Epoch 12; Iter   118/  172] train: loss: 0.1596670
[Epoch 12; Iter   148/  172] train: loss: 0.1445418
[Epoch 12] ogbg-moltoxcast: 0.690021 val loss: 0.219773
[Epoch 12] ogbg-moltoxcast: 0.688599 test loss: 0.218147
[Epoch 13; Iter     6/  172] train: loss: 0.2206699
[Epoch 13; Iter    36/  172] train: loss: 0.3195235
[Epoch 13; Iter    66/  172] train: loss: 0.1733977
[Epoch 13; Iter    96/  172] train: loss: 0.2822452
[Epoch 13; Iter   126/  172] train: loss: 0.1669741
[Epoch 13; Iter   156/  172] train: loss: 0.1776817
[Epoch 13] ogbg-moltoxcast: 0.696664 val loss: 0.213795
[Epoch 13] ogbg-moltoxcast: 0.700171 test loss: 0.212155
[Epoch 14; Iter    14/  172] train: loss: 0.1986798
[Epoch 14; Iter    44/  172] train: loss: 0.2217802
[Epoch 14; Iter    74/  172] train: loss: 0.1519824
[Epoch 14; Iter   104/  172] train: loss: 0.2480581
[Epoch 14; Iter   134/  172] train: loss: 0.2368953
[Epoch 14; Iter   164/  172] train: loss: 0.2038984
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.6/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.6_4_26-05_09-42-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.6
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6931116
[Epoch 1; Iter    60/  172] train: loss: 0.6931150
[Epoch 1; Iter    90/  172] train: loss: 0.6931113
[Epoch 1; Iter   120/  172] train: loss: 0.6932017
[Epoch 1; Iter   150/  172] train: loss: 0.6931845
[Epoch 1] ogbg-moltoxcast: 0.492989 val loss: 0.693134
[Epoch 1] ogbg-moltoxcast: 0.492371 test loss: 0.693128
[Epoch 2; Iter     8/  172] train: loss: 0.6931845
[Epoch 2; Iter    38/  172] train: loss: 0.6930544
[Epoch 2; Iter    68/  172] train: loss: 0.6931196
[Epoch 2; Iter    98/  172] train: loss: 0.6931426
[Epoch 2; Iter   128/  172] train: loss: 0.6930768
[Epoch 2; Iter   158/  172] train: loss: 0.6930424
[Epoch 2] ogbg-moltoxcast: 0.493825 val loss: 0.693074
[Epoch 2] ogbg-moltoxcast: 0.493116 test loss: 0.693071
[Epoch 3; Iter    16/  172] train: loss: 0.6930343
[Epoch 3; Iter    46/  172] train: loss: 0.6930450
[Epoch 3; Iter    76/  172] train: loss: 0.6929774
[Epoch 3; Iter   106/  172] train: loss: 0.6930063
[Epoch 3; Iter   136/  172] train: loss: 0.6929737
[Epoch 3; Iter   166/  172] train: loss: 0.6929426
[Epoch 3] ogbg-moltoxcast: 0.493321 val loss: 0.692973
[Epoch 3] ogbg-moltoxcast: 0.492364 test loss: 0.692967
[Epoch 4; Iter    24/  172] train: loss: 0.6929221
[Epoch 4; Iter    54/  172] train: loss: 0.6929520
[Epoch 4; Iter    84/  172] train: loss: 0.6928493
[Epoch 4; Iter   114/  172] train: loss: 0.6929134
[Epoch 4; Iter   144/  172] train: loss: 0.6928154
[Epoch 4] ogbg-moltoxcast: 0.494318 val loss: 0.692844
[Epoch 4] ogbg-moltoxcast: 0.493325 test loss: 0.692838
[Epoch 5; Iter     2/  172] train: loss: 0.6928425
[Epoch 5; Iter    32/  172] train: loss: 0.6893331
[Epoch 5; Iter    62/  172] train: loss: 0.6695679
[Epoch 5; Iter    92/  172] train: loss: 0.6303169
[Epoch 5; Iter   122/  172] train: loss: 0.5832717
[Epoch 5; Iter   152/  172] train: loss: 0.5657905
[Epoch 5] ogbg-moltoxcast: 0.596686 val loss: 0.524390
[Epoch 5] ogbg-moltoxcast: 0.608159 test loss: 0.518860
[Epoch 6; Iter    10/  172] train: loss: 0.5091246
[Epoch 6; Iter    40/  172] train: loss: 0.4772387
[Epoch 6; Iter    70/  172] train: loss: 0.3886239
[Epoch 6; Iter   100/  172] train: loss: 0.3642534
[Epoch 6; Iter   130/  172] train: loss: 0.3028295
[Epoch 6; Iter   160/  172] train: loss: 0.3237685
[Epoch 6] ogbg-moltoxcast: 0.617077 val loss: 0.284942
[Epoch 6] ogbg-moltoxcast: 0.620729 test loss: 0.280003
[Epoch 7; Iter    18/  172] train: loss: 0.2225130
[Epoch 7; Iter    48/  172] train: loss: 0.2126924
[Epoch 7; Iter    78/  172] train: loss: 0.2246246
[Epoch 7; Iter   108/  172] train: loss: 0.3847618
[Epoch 7; Iter   138/  172] train: loss: 0.2372952
[Epoch 7; Iter   168/  172] train: loss: 0.2001623
[Epoch 7] ogbg-moltoxcast: 0.670509 val loss: 0.226676
[Epoch 7] ogbg-moltoxcast: 0.670326 test loss: 0.227028
[Epoch 8; Iter    26/  172] train: loss: 0.1767853
[Epoch 8; Iter    56/  172] train: loss: 0.1413171
[Epoch 8; Iter    86/  172] train: loss: 0.2206379
[Epoch 8; Iter   116/  172] train: loss: 0.1518627
[Epoch 8; Iter   146/  172] train: loss: 0.1921415
[Epoch 8] ogbg-moltoxcast: 0.674325 val loss: 0.220453
[Epoch 8] ogbg-moltoxcast: 0.668574 test loss: 0.221666
[Epoch 9; Iter     4/  172] train: loss: 0.2039898
[Epoch 9; Iter    34/  172] train: loss: 0.2177718
[Epoch 9; Iter    64/  172] train: loss: 0.2724300
[Epoch 9; Iter    94/  172] train: loss: 0.2838977
[Epoch 9; Iter   124/  172] train: loss: 0.1685591
[Epoch 9; Iter   154/  172] train: loss: 0.1874125
[Epoch 9] ogbg-moltoxcast: 0.668952 val loss: 0.218540
[Epoch 9] ogbg-moltoxcast: 0.677779 test loss: 0.218074
[Epoch 10; Iter    12/  172] train: loss: 0.2772576
[Epoch 10; Iter    42/  172] train: loss: 0.1632721
[Epoch 10; Iter    72/  172] train: loss: 0.1710003
[Epoch 10; Iter   102/  172] train: loss: 0.2065851
[Epoch 10; Iter   132/  172] train: loss: 0.2330802
[Epoch 10; Iter   162/  172] train: loss: 0.2303735
[Epoch 10] ogbg-moltoxcast: 0.667133 val loss: 0.221464
[Epoch 10] ogbg-moltoxcast: 0.682864 test loss: 0.222123
[Epoch 11; Iter    20/  172] train: loss: 0.2110381
[Epoch 11; Iter    50/  172] train: loss: 0.1893422
[Epoch 11; Iter    80/  172] train: loss: 0.2029702
[Epoch 11; Iter   110/  172] train: loss: 0.1517806
[Epoch 11; Iter   140/  172] train: loss: 0.2085511
[Epoch 11; Iter   170/  172] train: loss: 0.2071676
[Epoch 11] ogbg-moltoxcast: 0.666485 val loss: 0.227693
[Epoch 11] ogbg-moltoxcast: 0.678199 test loss: 0.226124
[Epoch 12; Iter    28/  172] train: loss: 0.2270758
[Epoch 12; Iter    58/  172] train: loss: 0.2467100
[Epoch 12; Iter    88/  172] train: loss: 0.2322341
[Epoch 12; Iter   118/  172] train: loss: 0.2489262
[Epoch 12; Iter   148/  172] train: loss: 0.2077008
[Epoch 12] ogbg-moltoxcast: 0.680865 val loss: 0.213872
[Epoch 12] ogbg-moltoxcast: 0.697216 test loss: 0.210748
[Epoch 13; Iter     6/  172] train: loss: 0.1270379
[Epoch 13; Iter    36/  172] train: loss: 0.1401317
[Epoch 13; Iter    66/  172] train: loss: 0.1796474
[Epoch 13; Iter    96/  172] train: loss: 0.1328520
[Epoch 13; Iter   126/  172] train: loss: 0.1427369
[Epoch 13; Iter   156/  172] train: loss: 0.2826696
[Epoch 13] ogbg-moltoxcast: 0.680560 val loss: 0.217499
[Epoch 13] ogbg-moltoxcast: 0.684080 test loss: 0.216815
[Epoch 14; Iter    14/  172] train: loss: 0.1568344
[Epoch 14; Iter    44/  172] train: loss: 0.2467543
[Epoch 14; Iter    74/  172] train: loss: 0.1794446
[Epoch 14; Iter   104/  172] train: loss: 0.1347480
[Epoch 14; Iter   134/  172] train: loss: 0.2700765
[Epoch 14; Iter   164/  172] train: loss: 0.1896158
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/toxcast/random/train_prop=0.6/PNA_ogbg-moltoxcast_GraphCL_toxcast_random=0.6_6_26-05_09-42-09
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/toxcast/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_toxcast_random=0.6
logdir: runs/split/GraphCL/toxcast/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltoxcast
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltoxcast
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 617
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  172] train: loss: 0.6930744
[Epoch 1; Iter    60/  172] train: loss: 0.6931247
[Epoch 1; Iter    90/  172] train: loss: 0.6931522
[Epoch 1; Iter   120/  172] train: loss: 0.6930540
[Epoch 1; Iter   150/  172] train: loss: 0.6931414
[Epoch 1] ogbg-moltoxcast: 0.507667 val loss: 0.693141
[Epoch 1] ogbg-moltoxcast: 0.513973 test loss: 0.693137
[Epoch 2; Iter     8/  172] train: loss: 0.6931823
[Epoch 2; Iter    38/  172] train: loss: 0.6931643
[Epoch 2; Iter    68/  172] train: loss: 0.6931242
[Epoch 2; Iter    98/  172] train: loss: 0.6930643
[Epoch 2; Iter   128/  172] train: loss: 0.6931614
[Epoch 2; Iter   158/  172] train: loss: 0.6930214
[Epoch 2] ogbg-moltoxcast: 0.507585 val loss: 0.693082
[Epoch 2] ogbg-moltoxcast: 0.515259 test loss: 0.693075
[Epoch 3; Iter    16/  172] train: loss: 0.6930700
[Epoch 3; Iter    46/  172] train: loss: 0.6931018
[Epoch 3; Iter    76/  172] train: loss: 0.6930038
[Epoch 3; Iter   106/  172] train: loss: 0.6930277
[Epoch 3; Iter   136/  172] train: loss: 0.6929507
[Epoch 3; Iter   166/  172] train: loss: 0.6929439
[Epoch 3] ogbg-moltoxcast: 0.507383 val loss: 0.692971
[Epoch 3] ogbg-moltoxcast: 0.516215 test loss: 0.692963
[Epoch 4; Iter    24/  172] train: loss: 0.6929041
[Epoch 4; Iter    54/  172] train: loss: 0.6928529
[Epoch 4; Iter    84/  172] train: loss: 0.6928424
[Epoch 4; Iter   114/  172] train: loss: 0.6929252
[Epoch 4; Iter   144/  172] train: loss: 0.6928526
[Epoch 4] ogbg-moltoxcast: 0.506452 val loss: 0.692822
[Epoch 4] ogbg-moltoxcast: 0.515196 test loss: 0.692813
[Epoch 5; Iter     2/  172] train: loss: 0.6928726
[Epoch 5; Iter    32/  172] train: loss: 0.6893226
[Epoch 5; Iter    62/  172] train: loss: 0.6707100
[Epoch 5; Iter    92/  172] train: loss: 0.6373043
[Epoch 5; Iter   122/  172] train: loss: 0.6078857
[Epoch 5; Iter   152/  172] train: loss: 0.5459719
[Epoch 5] ogbg-moltoxcast: 0.609465 val loss: 0.529811
[Epoch 5] ogbg-moltoxcast: 0.602199 test loss: 0.524393
[Epoch 6; Iter    10/  172] train: loss: 0.5025292
[Epoch 6; Iter    40/  172] train: loss: 0.4505668
[Epoch 6; Iter    70/  172] train: loss: 0.4023311
[Epoch 6; Iter   100/  172] train: loss: 0.3854394
[Epoch 6; Iter   130/  172] train: loss: 0.3068875
[Epoch 6; Iter   160/  172] train: loss: 0.2199851
[Epoch 6] ogbg-moltoxcast: 0.622773 val loss: 0.299998
[Epoch 6] ogbg-moltoxcast: 0.626871 test loss: 0.296412
[Epoch 7; Iter    18/  172] train: loss: 0.3356622
[Epoch 7; Iter    48/  172] train: loss: 0.3014959
[Epoch 7; Iter    78/  172] train: loss: 0.2022524
[Epoch 7; Iter   108/  172] train: loss: 0.2296836
[Epoch 7; Iter   138/  172] train: loss: 0.1864686
[Epoch 7; Iter   168/  172] train: loss: 0.2745639
[Epoch 7] ogbg-moltoxcast: 0.656365 val loss: 0.232978
[Epoch 7] ogbg-moltoxcast: 0.659518 test loss: 0.232839
[Epoch 8; Iter    26/  172] train: loss: 0.1990993
[Epoch 8; Iter    56/  172] train: loss: 0.1504046
[Epoch 8; Iter    86/  172] train: loss: 0.2671534
[Epoch 8; Iter   116/  172] train: loss: 0.1442394
[Epoch 8; Iter   146/  172] train: loss: 0.1674518
[Epoch 8] ogbg-moltoxcast: 0.647692 val loss: 0.231588
[Epoch 8] ogbg-moltoxcast: 0.641853 test loss: 0.234030
[Epoch 9; Iter     4/  172] train: loss: 0.2917116
[Epoch 9; Iter    34/  172] train: loss: 0.2029069
[Epoch 9; Iter    64/  172] train: loss: 0.1524206
[Epoch 9; Iter    94/  172] train: loss: 0.1949891
[Epoch 9; Iter   124/  172] train: loss: 0.1527085
[Epoch 9; Iter   154/  172] train: loss: 0.2156370
[Epoch 9] ogbg-moltoxcast: 0.669097 val loss: 0.221223
[Epoch 9] ogbg-moltoxcast: 0.673492 test loss: 0.220670
[Epoch 10; Iter    12/  172] train: loss: 0.2181870
[Epoch 10; Iter    42/  172] train: loss: 0.1428149
[Epoch 10; Iter    72/  172] train: loss: 0.1919944
[Epoch 10; Iter   102/  172] train: loss: 0.1667397
[Epoch 10; Iter   132/  172] train: loss: 0.1786078
[Epoch 10; Iter   162/  172] train: loss: 0.2255350
[Epoch 10] ogbg-moltoxcast: 0.662251 val loss: 0.225762
[Epoch 10] ogbg-moltoxcast: 0.672853 test loss: 0.223159
[Epoch 11; Iter    20/  172] train: loss: 0.2800398
[Epoch 11; Iter    50/  172] train: loss: 0.2118299
[Epoch 11; Iter    80/  172] train: loss: 0.2179761
[Epoch 11; Iter   110/  172] train: loss: 0.1886067
[Epoch 11; Iter   140/  172] train: loss: 0.3720336
[Epoch 11; Iter   170/  172] train: loss: 0.1806853
[Epoch 11] ogbg-moltoxcast: 0.671947 val loss: 0.231920
[Epoch 11] ogbg-moltoxcast: 0.682957 test loss: 0.221879
[Epoch 12; Iter    28/  172] train: loss: 0.1532218
[Epoch 12; Iter    58/  172] train: loss: 0.1856228
[Epoch 12; Iter    88/  172] train: loss: 0.2792879
[Epoch 12; Iter   118/  172] train: loss: 0.2430042
[Epoch 12; Iter   148/  172] train: loss: 0.1907557
[Epoch 12] ogbg-moltoxcast: 0.682165 val loss: 0.221154
[Epoch 12] ogbg-moltoxcast: 0.688660 test loss: 0.216909
[Epoch 13; Iter     6/  172] train: loss: 0.2225421
[Epoch 13; Iter    36/  172] train: loss: 0.1569017
[Epoch 13; Iter    66/  172] train: loss: 0.1780294
[Epoch 13; Iter    96/  172] train: loss: 0.1894504
[Epoch 13; Iter   126/  172] train: loss: 0.1479472
[Epoch 13; Iter   156/  172] train: loss: 0.1888243
[Epoch 13] ogbg-moltoxcast: 0.699404 val loss: 0.219807
[Epoch 13] ogbg-moltoxcast: 0.704610 test loss: 0.216097
[Epoch 14; Iter    14/  172] train: loss: 0.2620405
[Epoch 14; Iter    44/  172] train: loss: 0.2023626
[Epoch 14; Iter    74/  172] train: loss: 0.2166584
[Epoch 14; Iter   104/  172] train: loss: 0.2304566
[Epoch 14; Iter   134/  172] train: loss: 0.2288900
[Epoch 14; Iter   164/  172] train: loss: 0.1642005
[Epoch 12; Iter    31/  229] train: loss: 0.3040219
[Epoch 12; Iter    61/  229] train: loss: 0.1574337
[Epoch 12; Iter    91/  229] train: loss: 0.2058462
[Epoch 12; Iter   121/  229] train: loss: 0.2271943
[Epoch 12; Iter   151/  229] train: loss: 0.2644239
[Epoch 12; Iter   181/  229] train: loss: 0.2751980
[Epoch 12; Iter   211/  229] train: loss: 0.2229018
[Epoch 12] ogbg-moltoxcast: 0.684474 val loss: 0.206203
[Epoch 12] ogbg-moltoxcast: 0.699191 test loss: 0.220444
[Epoch 13; Iter    12/  229] train: loss: 0.2131431
[Epoch 13; Iter    42/  229] train: loss: 0.1881936
[Epoch 13; Iter    72/  229] train: loss: 0.1844688
[Epoch 13; Iter   102/  229] train: loss: 0.1722831
[Epoch 13; Iter   132/  229] train: loss: 0.1551185
[Epoch 13; Iter   162/  229] train: loss: 0.1965031
[Epoch 13; Iter   192/  229] train: loss: 0.1433352
[Epoch 13; Iter   222/  229] train: loss: 0.2580527
[Epoch 13] ogbg-moltoxcast: 0.699219 val loss: 0.203319
[Epoch 13] ogbg-moltoxcast: 0.720436 test loss: 0.217558
[Epoch 14; Iter    23/  229] train: loss: 0.1828202
[Epoch 14; Iter    53/  229] train: loss: 0.2513349
[Epoch 14; Iter    83/  229] train: loss: 0.2409074
[Epoch 14; Iter   113/  229] train: loss: 0.1618105
[Epoch 14; Iter   143/  229] train: loss: 0.2065209
[Epoch 14; Iter   173/  229] train: loss: 0.1905174
[Epoch 14; Iter   203/  229] train: loss: 0.1655356
[Epoch 14] ogbg-moltoxcast: 0.701938 val loss: 0.201917
[Epoch 14] ogbg-moltoxcast: 0.720769 test loss: 0.218386
[Epoch 15; Iter     4/  229] train: loss: 0.1182513
[Epoch 15; Iter    34/  229] train: loss: 0.1503792
[Epoch 15; Iter    64/  229] train: loss: 0.2104527
[Epoch 15; Iter    94/  229] train: loss: 0.2749082
[Epoch 15; Iter   124/  229] train: loss: 0.1536025
[Epoch 15; Iter   154/  229] train: loss: 0.2079721
[Epoch 15; Iter   184/  229] train: loss: 0.2179639
[Epoch 15; Iter   214/  229] train: loss: 0.1622566
[Epoch 15] ogbg-moltoxcast: 0.705233 val loss: 0.196841
[Epoch 15] ogbg-moltoxcast: 0.722933 test loss: 0.216710
[Epoch 16; Iter    15/  229] train: loss: 0.1484080
[Epoch 16; Iter    45/  229] train: loss: 0.1539249
[Epoch 16; Iter    75/  229] train: loss: 0.1754843
[Epoch 16; Iter   105/  229] train: loss: 0.1948750
[Epoch 16; Iter   135/  229] train: loss: 0.1976312
[Epoch 16; Iter   165/  229] train: loss: 0.1823763
[Epoch 16; Iter   195/  229] train: loss: 0.2033685
[Epoch 16; Iter   225/  229] train: loss: 0.1380544
[Epoch 16] ogbg-moltoxcast: 0.660962 val loss: 0.215770
[Epoch 16] ogbg-moltoxcast: 0.692840 test loss: 0.233707
[Epoch 17; Iter    26/  229] train: loss: 0.1960028
[Epoch 17; Iter    56/  229] train: loss: 0.2344915
[Epoch 17; Iter    86/  229] train: loss: 0.1669421
[Epoch 17; Iter   116/  229] train: loss: 0.2049104
[Epoch 17; Iter   146/  229] train: loss: 0.1705194
[Epoch 17; Iter   176/  229] train: loss: 0.2234356
[Epoch 17; Iter   206/  229] train: loss: 0.1831321
[Epoch 17] ogbg-moltoxcast: 0.689082 val loss: 0.203541
[Epoch 17] ogbg-moltoxcast: 0.716655 test loss: 0.224297
[Epoch 18; Iter     7/  229] train: loss: 0.1768344
[Epoch 18; Iter    37/  229] train: loss: 0.1462123
[Epoch 18; Iter    67/  229] train: loss: 0.1506614
[Epoch 18; Iter    97/  229] train: loss: 0.2090932
[Epoch 18; Iter   127/  229] train: loss: 0.2829053
[Epoch 18; Iter   157/  229] train: loss: 0.1636410
[Epoch 18; Iter   187/  229] train: loss: 0.1574826
[Epoch 18; Iter   217/  229] train: loss: 0.1872411
[Epoch 18] ogbg-moltoxcast: 0.699902 val loss: 0.201971
[Epoch 18] ogbg-moltoxcast: 0.722564 test loss: 0.229541
[Epoch 19; Iter    18/  229] train: loss: 0.1722035
[Epoch 19; Iter    48/  229] train: loss: 0.1668406
[Epoch 19; Iter    78/  229] train: loss: 0.1588185
[Epoch 19; Iter   108/  229] train: loss: 0.2975762
[Epoch 19; Iter   138/  229] train: loss: 0.1714563
[Epoch 19; Iter   168/  229] train: loss: 0.1847169
[Epoch 19; Iter   198/  229] train: loss: 0.2022858
[Epoch 19; Iter   228/  229] train: loss: 0.1407215
[Epoch 19] ogbg-moltoxcast: 0.709661 val loss: 0.201403
[Epoch 19] ogbg-moltoxcast: 0.720761 test loss: 0.223829
[Epoch 20; Iter    29/  229] train: loss: 0.1597135
[Epoch 20; Iter    59/  229] train: loss: 0.1632009
[Epoch 20; Iter    89/  229] train: loss: 0.2594586
[Epoch 20; Iter   119/  229] train: loss: 0.2464525
[Epoch 20; Iter   149/  229] train: loss: 0.1566138
[Epoch 20; Iter   179/  229] train: loss: 0.2971947
[Epoch 20; Iter   209/  229] train: loss: 0.2503506
[Epoch 20] ogbg-moltoxcast: 0.711848 val loss: 0.202787
[Epoch 20] ogbg-moltoxcast: 0.723702 test loss: 0.227798
[Epoch 21; Iter    10/  229] train: loss: 0.1739257
[Epoch 21; Iter    40/  229] train: loss: 0.2065385
[Epoch 21; Iter    70/  229] train: loss: 0.2619080
[Epoch 21; Iter   100/  229] train: loss: 0.1740577
[Epoch 21; Iter   130/  229] train: loss: 0.1844482
[Epoch 21; Iter   160/  229] train: loss: 0.1883272
[Epoch 21; Iter   190/  229] train: loss: 0.2071318
[Epoch 21; Iter   220/  229] train: loss: 0.2018779
[Epoch 21] ogbg-moltoxcast: 0.706333 val loss: 0.207105
[Epoch 21] ogbg-moltoxcast: 0.712419 test loss: 0.216849
[Epoch 22; Iter    21/  229] train: loss: 0.1690445
[Epoch 22; Iter    51/  229] train: loss: 0.2365272
[Epoch 22; Iter    81/  229] train: loss: 0.2669106
[Epoch 22; Iter   111/  229] train: loss: 0.2345943
[Epoch 22; Iter   141/  229] train: loss: 0.1949054
[Epoch 22; Iter   171/  229] train: loss: 0.2856662
[Epoch 22; Iter   201/  229] train: loss: 0.1519507
[Epoch 22] ogbg-moltoxcast: 0.708789 val loss: 0.198693
[Epoch 22] ogbg-moltoxcast: 0.733812 test loss: 0.214198
[Epoch 23; Iter     2/  229] train: loss: 0.1571038
[Epoch 23; Iter    32/  229] train: loss: 0.2040994
[Epoch 23; Iter    62/  229] train: loss: 0.1915469
[Epoch 23; Iter    92/  229] train: loss: 0.1444452
[Epoch 23; Iter   122/  229] train: loss: 0.2068132
[Epoch 23; Iter   152/  229] train: loss: 0.1648814
[Epoch 23; Iter   182/  229] train: loss: 0.2080550
[Epoch 23; Iter   212/  229] train: loss: 0.2275163
[Epoch 23] ogbg-moltoxcast: 0.702076 val loss: 0.204549
[Epoch 23] ogbg-moltoxcast: 0.737827 test loss: 0.213455
[Epoch 24; Iter    13/  229] train: loss: 0.1855617
[Epoch 24; Iter    43/  229] train: loss: 0.1989505
[Epoch 24; Iter    73/  229] train: loss: 0.2286353
[Epoch 24; Iter   103/  229] train: loss: 0.1914880
[Epoch 24; Iter   133/  229] train: loss: 0.2046163
[Epoch 24; Iter   163/  229] train: loss: 0.1824551
[Epoch 24; Iter   193/  229] train: loss: 0.1622168
[Epoch 24; Iter   223/  229] train: loss: 0.2027914
[Epoch 24] ogbg-moltoxcast: 0.717554 val loss: 0.198918
[Epoch 24] ogbg-moltoxcast: 0.736481 test loss: 0.210499
[Epoch 25; Iter    24/  229] train: loss: 0.2281713
[Epoch 25; Iter    54/  229] train: loss: 0.1841410
[Epoch 25; Iter    84/  229] train: loss: 0.2061671
[Epoch 25; Iter   114/  229] train: loss: 0.2773924
[Epoch 25; Iter   144/  229] train: loss: 0.2951946
[Epoch 25; Iter   174/  229] train: loss: 0.2572856
[Epoch 25; Iter   204/  229] train: loss: 0.1952132
[Epoch 25] ogbg-moltoxcast: 0.713736 val loss: 0.201616
[Epoch 25] ogbg-moltoxcast: 0.741083 test loss: 0.209776
[Epoch 26; Iter     5/  229] train: loss: 0.1769395
[Epoch 26; Iter    35/  229] train: loss: 0.2075304
[Epoch 26; Iter    65/  229] train: loss: 0.1650069
[Epoch 26; Iter    95/  229] train: loss: 0.1865380
[Epoch 26; Iter   125/  229] train: loss: 0.1459704
[Epoch 26; Iter   155/  229] train: loss: 0.1916235
[Epoch 26; Iter   185/  229] train: loss: 0.1557651
[Epoch 26; Iter   215/  229] train: loss: 0.2115311
[Epoch 26] ogbg-moltoxcast: 0.720564 val loss: 0.196704
[Epoch 26] ogbg-moltoxcast: 0.739567 test loss: 0.208351
[Epoch 27; Iter    16/  229] train: loss: 0.1176154
[Epoch 27; Iter    46/  229] train: loss: 0.1478223
[Epoch 27; Iter    76/  229] train: loss: 0.1422932
[Epoch 27; Iter   106/  229] train: loss: 0.1241634
[Epoch 27; Iter   136/  229] train: loss: 0.2524484
[Epoch 27; Iter   166/  229] train: loss: 0.1954825
[Epoch 27; Iter   196/  229] train: loss: 0.2127915
[Epoch 27; Iter   226/  229] train: loss: 0.2484893
[Epoch 27] ogbg-moltoxcast: 0.720649 val loss: 0.198862
[Epoch 27] ogbg-moltoxcast: 0.744804 test loss: 0.206839
[Epoch 12; Iter    31/  229] train: loss: 0.1946180
[Epoch 12; Iter    61/  229] train: loss: 0.2412161
[Epoch 12; Iter    91/  229] train: loss: 0.1949663
[Epoch 12; Iter   121/  229] train: loss: 0.1391445
[Epoch 12; Iter   151/  229] train: loss: 0.1684339
[Epoch 12; Iter   181/  229] train: loss: 0.1671086
[Epoch 12; Iter   211/  229] train: loss: 0.1947318
[Epoch 12] ogbg-moltoxcast: 0.712810 val loss: 0.198215
[Epoch 12] ogbg-moltoxcast: 0.723163 test loss: 0.213309
[Epoch 13; Iter    12/  229] train: loss: 0.1736997
[Epoch 13; Iter    42/  229] train: loss: 0.1654639
[Epoch 13; Iter    72/  229] train: loss: 0.1996678
[Epoch 13; Iter   102/  229] train: loss: 0.2311229
[Epoch 13; Iter   132/  229] train: loss: 0.2636353
[Epoch 13; Iter   162/  229] train: loss: 0.2676413
[Epoch 13; Iter   192/  229] train: loss: 0.1774981
[Epoch 13; Iter   222/  229] train: loss: 0.1684994
[Epoch 13] ogbg-moltoxcast: 0.707555 val loss: 0.199556
[Epoch 13] ogbg-moltoxcast: 0.724041 test loss: 0.215835
[Epoch 14; Iter    23/  229] train: loss: 0.2316012
[Epoch 14; Iter    53/  229] train: loss: 0.1444781
[Epoch 14; Iter    83/  229] train: loss: 0.2104200
[Epoch 14; Iter   113/  229] train: loss: 0.2154898
[Epoch 14; Iter   143/  229] train: loss: 0.2037196
[Epoch 14; Iter   173/  229] train: loss: 0.2169050
[Epoch 14; Iter   203/  229] train: loss: 0.2872758
[Epoch 14] ogbg-moltoxcast: 0.701019 val loss: 0.205552
[Epoch 14] ogbg-moltoxcast: 0.708259 test loss: 0.220734
[Epoch 15; Iter     4/  229] train: loss: 0.1837037
[Epoch 15; Iter    34/  229] train: loss: 0.1840566
[Epoch 15; Iter    64/  229] train: loss: 0.1325777
[Epoch 15; Iter    94/  229] train: loss: 0.1851399
[Epoch 15; Iter   124/  229] train: loss: 0.1090677
[Epoch 15; Iter   154/  229] train: loss: 0.2094700
[Epoch 15; Iter   184/  229] train: loss: 0.1993748
[Epoch 15; Iter   214/  229] train: loss: 0.1998765
[Epoch 15] ogbg-moltoxcast: 0.709279 val loss: 0.200588
[Epoch 15] ogbg-moltoxcast: 0.730280 test loss: 0.213108
[Epoch 16; Iter    15/  229] train: loss: 0.1864352
[Epoch 16; Iter    45/  229] train: loss: 0.1457212
[Epoch 16; Iter    75/  229] train: loss: 0.1344818
[Epoch 16; Iter   105/  229] train: loss: 0.1943525
[Epoch 16; Iter   135/  229] train: loss: 0.2356963
[Epoch 16; Iter   165/  229] train: loss: 0.1799776
[Epoch 16; Iter   195/  229] train: loss: 0.1967089
[Epoch 16; Iter   225/  229] train: loss: 0.1488829
[Epoch 16] ogbg-moltoxcast: 0.718213 val loss: 0.195649
[Epoch 16] ogbg-moltoxcast: 0.744085 test loss: 0.209790
[Epoch 17; Iter    26/  229] train: loss: 0.2386389
[Epoch 17; Iter    56/  229] train: loss: 0.1369204
[Epoch 17; Iter    86/  229] train: loss: 0.1919149
[Epoch 17; Iter   116/  229] train: loss: 0.2272026
[Epoch 17; Iter   146/  229] train: loss: 0.1775570
[Epoch 17; Iter   176/  229] train: loss: 0.1701599
[Epoch 17; Iter   206/  229] train: loss: 0.1903069
[Epoch 17] ogbg-moltoxcast: 0.660152 val loss: 0.278594
[Epoch 17] ogbg-moltoxcast: 0.675795 test loss: 0.311239
[Epoch 18; Iter     7/  229] train: loss: 0.1858004
[Epoch 18; Iter    37/  229] train: loss: 0.2460869
[Epoch 18; Iter    67/  229] train: loss: 0.1313607
[Epoch 18; Iter    97/  229] train: loss: 0.2630647
[Epoch 18; Iter   127/  229] train: loss: 0.1988894
[Epoch 18; Iter   157/  229] train: loss: 0.1469327
[Epoch 18; Iter   187/  229] train: loss: 0.2474981
[Epoch 18; Iter   217/  229] train: loss: 0.1363612
[Epoch 18] ogbg-moltoxcast: 0.614697 val loss: 0.229438
[Epoch 18] ogbg-moltoxcast: 0.620858 test loss: 0.255074
[Epoch 19; Iter    18/  229] train: loss: 0.2236879
[Epoch 19; Iter    48/  229] train: loss: 0.2090552
[Epoch 19; Iter    78/  229] train: loss: 0.2161685
[Epoch 19; Iter   108/  229] train: loss: 0.2000660
[Epoch 19; Iter   138/  229] train: loss: 0.1850750
[Epoch 19; Iter   168/  229] train: loss: 0.1927137
[Epoch 19; Iter   198/  229] train: loss: 0.1505060
[Epoch 19; Iter   228/  229] train: loss: 0.1676696
[Epoch 19] ogbg-moltoxcast: 0.700520 val loss: 0.202409
[Epoch 19] ogbg-moltoxcast: 0.724861 test loss: 0.215223
[Epoch 20; Iter    29/  229] train: loss: 0.2798119
[Epoch 20; Iter    59/  229] train: loss: 0.1860895
[Epoch 20; Iter    89/  229] train: loss: 0.2277199
[Epoch 20; Iter   119/  229] train: loss: 0.1885369
[Epoch 20; Iter   149/  229] train: loss: 0.2307320
[Epoch 20; Iter   179/  229] train: loss: 0.1949001
[Epoch 20; Iter   209/  229] train: loss: 0.1794178
[Epoch 20] ogbg-moltoxcast: 0.729696 val loss: 0.195376
[Epoch 20] ogbg-moltoxcast: 0.730378 test loss: 0.213722
[Epoch 21; Iter    10/  229] train: loss: 0.2809039
[Epoch 21; Iter    40/  229] train: loss: 0.1693812
[Epoch 21; Iter    70/  229] train: loss: 0.2261911
[Epoch 21; Iter   100/  229] train: loss: 0.2231997
[Epoch 21; Iter   130/  229] train: loss: 0.1551851
[Epoch 21; Iter   160/  229] train: loss: 0.1782483
[Epoch 21; Iter   190/  229] train: loss: 0.1980889
[Epoch 21; Iter   220/  229] train: loss: 0.2026062
[Epoch 21] ogbg-moltoxcast: 0.722825 val loss: 0.198215
[Epoch 21] ogbg-moltoxcast: 0.728628 test loss: 0.214338
[Epoch 22; Iter    21/  229] train: loss: 0.2240361
[Epoch 22; Iter    51/  229] train: loss: 0.1385440
[Epoch 22; Iter    81/  229] train: loss: 0.1783163
[Epoch 22; Iter   111/  229] train: loss: 0.1984978
[Epoch 22; Iter   141/  229] train: loss: 0.1926815
[Epoch 22; Iter   171/  229] train: loss: 0.1150760
[Epoch 22; Iter   201/  229] train: loss: 0.1779831
[Epoch 22] ogbg-moltoxcast: 0.718008 val loss: 0.197750
[Epoch 22] ogbg-moltoxcast: 0.738042 test loss: 0.224506
[Epoch 23; Iter     2/  229] train: loss: 0.2311474
[Epoch 23; Iter    32/  229] train: loss: 0.1792572
[Epoch 23; Iter    62/  229] train: loss: 0.1738170
[Epoch 23; Iter    92/  229] train: loss: 0.1453400
[Epoch 23; Iter   122/  229] train: loss: 0.2685837
[Epoch 23; Iter   152/  229] train: loss: 0.1514098
[Epoch 23; Iter   182/  229] train: loss: 0.1392217
[Epoch 23; Iter   212/  229] train: loss: 0.2100724
[Epoch 23] ogbg-moltoxcast: 0.728278 val loss: 0.195625
[Epoch 23] ogbg-moltoxcast: 0.742522 test loss: 0.242795
[Epoch 24; Iter    13/  229] train: loss: 0.1696451
[Epoch 24; Iter    43/  229] train: loss: 0.1270149
[Epoch 24; Iter    73/  229] train: loss: 0.1952926
[Epoch 24; Iter   103/  229] train: loss: 0.2124168
[Epoch 24; Iter   133/  229] train: loss: 0.1827891
[Epoch 24; Iter   163/  229] train: loss: 0.1898443
[Epoch 24; Iter   193/  229] train: loss: 0.2339500
[Epoch 24; Iter   223/  229] train: loss: 0.1869305
[Epoch 24] ogbg-moltoxcast: 0.726584 val loss: 0.195577
[Epoch 24] ogbg-moltoxcast: 0.744729 test loss: 0.213452
[Epoch 25; Iter    24/  229] train: loss: 0.1750730
[Epoch 25; Iter    54/  229] train: loss: 0.1578951
[Epoch 25; Iter    84/  229] train: loss: 0.1693896
[Epoch 25; Iter   114/  229] train: loss: 0.1711760
[Epoch 25; Iter   144/  229] train: loss: 0.1774239
[Epoch 25; Iter   174/  229] train: loss: 0.1613532
[Epoch 25; Iter   204/  229] train: loss: 0.1598472
[Epoch 25] ogbg-moltoxcast: 0.723819 val loss: 0.197613
[Epoch 25] ogbg-moltoxcast: 0.749610 test loss: 0.214480
[Epoch 26; Iter     5/  229] train: loss: 0.1078736
[Epoch 26; Iter    35/  229] train: loss: 0.1315684
[Epoch 26; Iter    65/  229] train: loss: 0.1790138
[Epoch 26; Iter    95/  229] train: loss: 0.2419836
[Epoch 26; Iter   125/  229] train: loss: 0.1692607
[Epoch 26; Iter   155/  229] train: loss: 0.1947750
[Epoch 26; Iter   185/  229] train: loss: 0.1661411
[Epoch 26; Iter   215/  229] train: loss: 0.1613401
[Epoch 26] ogbg-moltoxcast: 0.725838 val loss: 0.198623
[Epoch 26] ogbg-moltoxcast: 0.743027 test loss: 0.213419
[Epoch 27; Iter    16/  229] train: loss: 0.1691088
[Epoch 27; Iter    46/  229] train: loss: 0.1665517
[Epoch 27; Iter    76/  229] train: loss: 0.2085251
[Epoch 27; Iter   106/  229] train: loss: 0.1202493
[Epoch 27; Iter   136/  229] train: loss: 0.2404459
[Epoch 27; Iter   166/  229] train: loss: 0.1529890
[Epoch 27; Iter   196/  229] train: loss: 0.1785353
[Epoch 27; Iter   226/  229] train: loss: 0.2157383
[Epoch 27] ogbg-moltoxcast: 0.733532 val loss: 0.192933
[Epoch 27] ogbg-moltoxcast: 0.740271 test loss: 0.268298
[Epoch 12; Iter    31/  229] train: loss: 0.1736132
[Epoch 12; Iter    61/  229] train: loss: 0.1854846
[Epoch 12; Iter    91/  229] train: loss: 0.2205953
[Epoch 12; Iter   121/  229] train: loss: 0.1342824
[Epoch 12; Iter   151/  229] train: loss: 0.2855527
[Epoch 12; Iter   181/  229] train: loss: 0.2814669
[Epoch 12; Iter   211/  229] train: loss: 0.1736375
[Epoch 12] ogbg-moltoxcast: 0.667574 val loss: 0.210327
[Epoch 12] ogbg-moltoxcast: 0.693219 test loss: 0.223903
[Epoch 13; Iter    12/  229] train: loss: 0.1233766
[Epoch 13; Iter    42/  229] train: loss: 0.2558764
[Epoch 13; Iter    72/  229] train: loss: 0.1506290
[Epoch 13; Iter   102/  229] train: loss: 0.1764977
[Epoch 13; Iter   132/  229] train: loss: 0.1779045
[Epoch 13; Iter   162/  229] train: loss: 0.2196231
[Epoch 13; Iter   192/  229] train: loss: 0.2423413
[Epoch 13; Iter   222/  229] train: loss: 0.1512663
[Epoch 13] ogbg-moltoxcast: 0.689842 val loss: 0.204358
[Epoch 13] ogbg-moltoxcast: 0.709326 test loss: 0.220167
[Epoch 14; Iter    23/  229] train: loss: 0.2099579
[Epoch 14; Iter    53/  229] train: loss: 0.2211570
[Epoch 14; Iter    83/  229] train: loss: 0.2665761
[Epoch 14; Iter   113/  229] train: loss: 0.1590468
[Epoch 14; Iter   143/  229] train: loss: 0.1542980
[Epoch 14; Iter   173/  229] train: loss: 0.1998208
[Epoch 14; Iter   203/  229] train: loss: 0.1893106
[Epoch 14] ogbg-moltoxcast: 0.690648 val loss: 0.213102
[Epoch 14] ogbg-moltoxcast: 0.714501 test loss: 0.225635
[Epoch 15; Iter     4/  229] train: loss: 0.1210360
[Epoch 15; Iter    34/  229] train: loss: 0.1878235
[Epoch 15; Iter    64/  229] train: loss: 0.1395505
[Epoch 15; Iter    94/  229] train: loss: 0.2177137
[Epoch 15; Iter   124/  229] train: loss: 0.2067779
[Epoch 15; Iter   154/  229] train: loss: 0.2376475
[Epoch 15; Iter   184/  229] train: loss: 0.2395472
[Epoch 15; Iter   214/  229] train: loss: 0.2108913
[Epoch 15] ogbg-moltoxcast: 0.692310 val loss: 0.202796
[Epoch 15] ogbg-moltoxcast: 0.718842 test loss: 0.217454
[Epoch 16; Iter    15/  229] train: loss: 0.2284037
[Epoch 16; Iter    45/  229] train: loss: 0.1923773
[Epoch 16; Iter    75/  229] train: loss: 0.2903753
[Epoch 16; Iter   105/  229] train: loss: 0.2499517
[Epoch 16; Iter   135/  229] train: loss: 0.1931724
[Epoch 16; Iter   165/  229] train: loss: 0.2205614
[Epoch 16; Iter   195/  229] train: loss: 0.2015679
[Epoch 16; Iter   225/  229] train: loss: 0.1412128
[Epoch 16] ogbg-moltoxcast: 0.697848 val loss: 0.204469
[Epoch 16] ogbg-moltoxcast: 0.723502 test loss: 0.217382
[Epoch 17; Iter    26/  229] train: loss: 0.1883057
[Epoch 17; Iter    56/  229] train: loss: 0.1862442
[Epoch 17; Iter    86/  229] train: loss: 0.1880926
[Epoch 17; Iter   116/  229] train: loss: 0.1533052
[Epoch 17; Iter   146/  229] train: loss: 0.1542901
[Epoch 17; Iter   176/  229] train: loss: 0.1835999
[Epoch 17; Iter   206/  229] train: loss: 0.2359105
[Epoch 17] ogbg-moltoxcast: 0.701227 val loss: 0.203176
[Epoch 17] ogbg-moltoxcast: 0.733285 test loss: 0.213229
[Epoch 18; Iter     7/  229] train: loss: 0.2295863
[Epoch 18; Iter    37/  229] train: loss: 0.1733973
[Epoch 18; Iter    67/  229] train: loss: 0.2048682
[Epoch 18; Iter    97/  229] train: loss: 0.2462550
[Epoch 18; Iter   127/  229] train: loss: 0.2039933
[Epoch 18; Iter   157/  229] train: loss: 0.2840280
[Epoch 18; Iter   187/  229] train: loss: 0.1802147
[Epoch 18; Iter   217/  229] train: loss: 0.1863950
[Epoch 18] ogbg-moltoxcast: 0.707450 val loss: 0.203609
[Epoch 18] ogbg-moltoxcast: 0.723888 test loss: 0.217066
[Epoch 19; Iter    18/  229] train: loss: 0.1492259
[Epoch 19; Iter    48/  229] train: loss: 0.2476366
[Epoch 19; Iter    78/  229] train: loss: 0.2125239
[Epoch 19; Iter   108/  229] train: loss: 0.1762796
[Epoch 19; Iter   138/  229] train: loss: 0.1977896
[Epoch 19; Iter   168/  229] train: loss: 0.1918033
[Epoch 19; Iter   198/  229] train: loss: 0.1612112
[Epoch 19; Iter   228/  229] train: loss: 0.2093204
[Epoch 19] ogbg-moltoxcast: 0.707003 val loss: 0.204378
[Epoch 19] ogbg-moltoxcast: 0.736060 test loss: 0.211480
[Epoch 20; Iter    29/  229] train: loss: 0.1822861
[Epoch 20; Iter    59/  229] train: loss: 0.2544029
[Epoch 20; Iter    89/  229] train: loss: 0.1218829
[Epoch 20; Iter   119/  229] train: loss: 0.1485405
[Epoch 20; Iter   149/  229] train: loss: 0.2295503
[Epoch 20; Iter   179/  229] train: loss: 0.2083277
[Epoch 20; Iter   209/  229] train: loss: 0.1758343
[Epoch 20] ogbg-moltoxcast: 0.716378 val loss: 0.199797
[Epoch 20] ogbg-moltoxcast: 0.726675 test loss: 0.216444
[Epoch 21; Iter    10/  229] train: loss: 0.2431220
[Epoch 21; Iter    40/  229] train: loss: 0.1352769
[Epoch 21; Iter    70/  229] train: loss: 0.1005996
[Epoch 21; Iter   100/  229] train: loss: 0.1677242
[Epoch 21; Iter   130/  229] train: loss: 0.1545620
[Epoch 21; Iter   160/  229] train: loss: 0.1631544
[Epoch 21; Iter   190/  229] train: loss: 0.2947244
[Epoch 21; Iter   220/  229] train: loss: 0.2175198
[Epoch 21] ogbg-moltoxcast: 0.712078 val loss: 0.199286
[Epoch 21] ogbg-moltoxcast: 0.745350 test loss: 0.207725
[Epoch 22; Iter    21/  229] train: loss: 0.1737231
[Epoch 22; Iter    51/  229] train: loss: 0.1836243
[Epoch 22; Iter    81/  229] train: loss: 0.1858412
[Epoch 22; Iter   111/  229] train: loss: 0.1799745
[Epoch 22; Iter   141/  229] train: loss: 0.1563553
[Epoch 22; Iter   171/  229] train: loss: 0.1167224
[Epoch 22; Iter   201/  229] train: loss: 0.2415106
[Epoch 22] ogbg-moltoxcast: 0.718986 val loss: 0.200369
[Epoch 22] ogbg-moltoxcast: 0.741780 test loss: 0.209023
[Epoch 23; Iter     2/  229] train: loss: 0.1983191
[Epoch 23; Iter    32/  229] train: loss: 0.1559537
[Epoch 23; Iter    62/  229] train: loss: 0.2469235
[Epoch 23; Iter    92/  229] train: loss: 0.1623825
[Epoch 23; Iter   122/  229] train: loss: 0.2190178
[Epoch 23; Iter   152/  229] train: loss: 0.1835171
[Epoch 23; Iter   182/  229] train: loss: 0.2028758
[Epoch 23; Iter   212/  229] train: loss: 0.1514279
[Epoch 23] ogbg-moltoxcast: 0.700882 val loss: 0.202412
[Epoch 23] ogbg-moltoxcast: 0.738672 test loss: 0.213264
[Epoch 24; Iter    13/  229] train: loss: 0.1971152
[Epoch 24; Iter    43/  229] train: loss: 0.1618908
[Epoch 24; Iter    73/  229] train: loss: 0.1602101
[Epoch 24; Iter   103/  229] train: loss: 0.2554027
[Epoch 24; Iter   133/  229] train: loss: 0.1846137
[Epoch 24; Iter   163/  229] train: loss: 0.1484478
[Epoch 24; Iter   193/  229] train: loss: 0.2014707
[Epoch 24; Iter   223/  229] train: loss: 0.1773405
[Epoch 24] ogbg-moltoxcast: 0.724479 val loss: 0.196438
[Epoch 24] ogbg-moltoxcast: 0.752262 test loss: 0.206557
[Epoch 25; Iter    24/  229] train: loss: 0.1904119
[Epoch 25; Iter    54/  229] train: loss: 0.2160963
[Epoch 25; Iter    84/  229] train: loss: 0.2181160
[Epoch 25; Iter   114/  229] train: loss: 0.1866750
[Epoch 25; Iter   144/  229] train: loss: 0.2132664
[Epoch 25; Iter   174/  229] train: loss: 0.1685108
[Epoch 25; Iter   204/  229] train: loss: 0.1764186
[Epoch 25] ogbg-moltoxcast: 0.712911 val loss: 0.201405
[Epoch 25] ogbg-moltoxcast: 0.743664 test loss: 0.211423
[Epoch 26; Iter     5/  229] train: loss: 0.2444306
[Epoch 26; Iter    35/  229] train: loss: 0.1546490
[Epoch 26; Iter    65/  229] train: loss: 0.1619793
[Epoch 26; Iter    95/  229] train: loss: 0.2235787
[Epoch 26; Iter   125/  229] train: loss: 0.2087592
[Epoch 26; Iter   155/  229] train: loss: 0.2217017
[Epoch 26; Iter   185/  229] train: loss: 0.1777364
[Epoch 26; Iter   215/  229] train: loss: 0.1987658
[Epoch 26] ogbg-moltoxcast: 0.715225 val loss: 0.199291
[Epoch 26] ogbg-moltoxcast: 0.748290 test loss: 0.206679
[Epoch 27; Iter    16/  229] train: loss: 0.2299846
[Epoch 27; Iter    46/  229] train: loss: 0.1759293
[Epoch 27; Iter    76/  229] train: loss: 0.1791861
[Epoch 27; Iter   106/  229] train: loss: 0.1548512
[Epoch 27; Iter   136/  229] train: loss: 0.1479015
[Epoch 27; Iter   166/  229] train: loss: 0.2209097
[Epoch 27; Iter   196/  229] train: loss: 0.1691200
[Epoch 27; Iter   226/  229] train: loss: 0.1652212
[Epoch 27] ogbg-moltoxcast: 0.720215 val loss: 0.197715
[Epoch 27] ogbg-moltoxcast: 0.743032 test loss: 0.210876
[Epoch 13; Iter    78/  201] train: loss: 0.1705161
[Epoch 13; Iter   108/  201] train: loss: 0.3152653
[Epoch 13; Iter   138/  201] train: loss: 0.1919845
[Epoch 13; Iter   168/  201] train: loss: 0.1629247
[Epoch 13; Iter   198/  201] train: loss: 0.2481705
[Epoch 13] ogbg-moltoxcast: 0.696168 val loss: 0.212848
[Epoch 13] ogbg-moltoxcast: 0.713839 test loss: 0.213985
[Epoch 14; Iter    27/  201] train: loss: 0.1612960
[Epoch 14; Iter    57/  201] train: loss: 0.2295596
[Epoch 14; Iter    87/  201] train: loss: 0.2015334
[Epoch 14; Iter   117/  201] train: loss: 0.2570641
[Epoch 14; Iter   147/  201] train: loss: 0.2319679
[Epoch 14; Iter   177/  201] train: loss: 0.2269512
[Epoch 14] ogbg-moltoxcast: 0.704331 val loss: 0.211059
[Epoch 14] ogbg-moltoxcast: 0.727272 test loss: 0.212793
[Epoch 15; Iter     6/  201] train: loss: 0.1532944
[Epoch 15; Iter    36/  201] train: loss: 0.1813807
[Epoch 15; Iter    66/  201] train: loss: 0.2255359
[Epoch 15; Iter    96/  201] train: loss: 0.2126977
[Epoch 15; Iter   126/  201] train: loss: 0.1243312
[Epoch 15; Iter   156/  201] train: loss: 0.1718614
[Epoch 15; Iter   186/  201] train: loss: 0.1512114
[Epoch 15] ogbg-moltoxcast: 0.715477 val loss: 0.209111
[Epoch 15] ogbg-moltoxcast: 0.732188 test loss: 0.211140
[Epoch 16; Iter    15/  201] train: loss: 0.2464799
[Epoch 16; Iter    45/  201] train: loss: 0.1683126
[Epoch 16; Iter    75/  201] train: loss: 0.2255114
[Epoch 16; Iter   105/  201] train: loss: 0.1711451
[Epoch 16; Iter   135/  201] train: loss: 0.2133542
[Epoch 16; Iter   165/  201] train: loss: 0.2150570
[Epoch 16; Iter   195/  201] train: loss: 0.2169627
[Epoch 16] ogbg-moltoxcast: 0.708013 val loss: 0.213926
[Epoch 16] ogbg-moltoxcast: 0.731250 test loss: 0.210587
[Epoch 17; Iter    24/  201] train: loss: 0.2516695
[Epoch 17; Iter    54/  201] train: loss: 0.2109311
[Epoch 17; Iter    84/  201] train: loss: 0.3177236
[Epoch 17; Iter   114/  201] train: loss: 0.2184939
[Epoch 17; Iter   144/  201] train: loss: 0.1845296
[Epoch 17; Iter   174/  201] train: loss: 0.2239427
[Epoch 17] ogbg-moltoxcast: 0.726852 val loss: 0.207283
[Epoch 17] ogbg-moltoxcast: 0.728507 test loss: 0.210145
[Epoch 18; Iter     3/  201] train: loss: 0.1314428
[Epoch 18; Iter    33/  201] train: loss: 0.1766324
[Epoch 18; Iter    63/  201] train: loss: 0.2034045
[Epoch 18; Iter    93/  201] train: loss: 0.1441958
[Epoch 18; Iter   123/  201] train: loss: 0.2285262
[Epoch 18; Iter   153/  201] train: loss: 0.2000025
[Epoch 18; Iter   183/  201] train: loss: 0.1975783
[Epoch 18] ogbg-moltoxcast: 0.710452 val loss: 0.209436
[Epoch 18] ogbg-moltoxcast: 0.739058 test loss: 0.204959
[Epoch 19; Iter    12/  201] train: loss: 0.2255479
[Epoch 19; Iter    42/  201] train: loss: 0.1173562
[Epoch 19; Iter    72/  201] train: loss: 0.1464212
[Epoch 19; Iter   102/  201] train: loss: 0.1697815
[Epoch 19; Iter   132/  201] train: loss: 0.1579449
[Epoch 19; Iter   162/  201] train: loss: 0.1482296
[Epoch 19; Iter   192/  201] train: loss: 0.1862269
[Epoch 19] ogbg-moltoxcast: 0.716951 val loss: 0.207609
[Epoch 19] ogbg-moltoxcast: 0.720419 test loss: 0.213300
[Epoch 20; Iter    21/  201] train: loss: 0.1769414
[Epoch 20; Iter    51/  201] train: loss: 0.1806902
[Epoch 20; Iter    81/  201] train: loss: 0.2601452
[Epoch 20; Iter   111/  201] train: loss: 0.2642072
[Epoch 20; Iter   141/  201] train: loss: 0.2050453
[Epoch 20; Iter   171/  201] train: loss: 0.1573356
[Epoch 20; Iter   201/  201] train: loss: 0.1555904
[Epoch 20] ogbg-moltoxcast: 0.716810 val loss: 0.205413
[Epoch 20] ogbg-moltoxcast: 0.733946 test loss: 0.207868
[Epoch 21; Iter    30/  201] train: loss: 0.1468489
[Epoch 21; Iter    60/  201] train: loss: 0.1568216
[Epoch 21; Iter    90/  201] train: loss: 0.2193081
[Epoch 21; Iter   120/  201] train: loss: 0.1867593
[Epoch 21; Iter   150/  201] train: loss: 0.2121732
[Epoch 21; Iter   180/  201] train: loss: 0.1993503
[Epoch 21] ogbg-moltoxcast: 0.720789 val loss: 0.207352
[Epoch 21] ogbg-moltoxcast: 0.744657 test loss: 0.204613
[Epoch 22; Iter     9/  201] train: loss: 0.1577288
[Epoch 22; Iter    39/  201] train: loss: 0.1489591
[Epoch 22; Iter    69/  201] train: loss: 0.1753774
[Epoch 22; Iter    99/  201] train: loss: 0.1264403
[Epoch 22; Iter   129/  201] train: loss: 0.1546437
[Epoch 22; Iter   159/  201] train: loss: 0.2142709
[Epoch 22; Iter   189/  201] train: loss: 0.1852264
[Epoch 22] ogbg-moltoxcast: 0.713384 val loss: 0.209614
[Epoch 22] ogbg-moltoxcast: 0.736374 test loss: 0.207150
[Epoch 23; Iter    18/  201] train: loss: 0.2137699
[Epoch 23; Iter    48/  201] train: loss: 0.2065102
[Epoch 23; Iter    78/  201] train: loss: 0.1757437
[Epoch 23; Iter   108/  201] train: loss: 0.2441042
[Epoch 23; Iter   138/  201] train: loss: 0.1687009
[Epoch 23; Iter   168/  201] train: loss: 0.1416183
[Epoch 23; Iter   198/  201] train: loss: 0.1669618
[Epoch 23] ogbg-moltoxcast: 0.724572 val loss: 0.212415
[Epoch 23] ogbg-moltoxcast: 0.747501 test loss: 0.205236
[Epoch 24; Iter    27/  201] train: loss: 0.2202059
[Epoch 24; Iter    57/  201] train: loss: 0.1227445
[Epoch 24; Iter    87/  201] train: loss: 0.2660252
[Epoch 24; Iter   117/  201] train: loss: 0.2509377
[Epoch 24; Iter   147/  201] train: loss: 0.1963239
[Epoch 24; Iter   177/  201] train: loss: 0.1419759
[Epoch 24] ogbg-moltoxcast: 0.718259 val loss: 0.209169
[Epoch 24] ogbg-moltoxcast: 0.729635 test loss: 0.208790
[Epoch 25; Iter     6/  201] train: loss: 0.2119101
[Epoch 25; Iter    36/  201] train: loss: 0.1395696
[Epoch 25; Iter    66/  201] train: loss: 0.1690597
[Epoch 25; Iter    96/  201] train: loss: 0.2824850
[Epoch 25; Iter   126/  201] train: loss: 0.1484469
[Epoch 25; Iter   156/  201] train: loss: 0.1182573
[Epoch 25; Iter   186/  201] train: loss: 0.1852521
[Epoch 25] ogbg-moltoxcast: 0.726137 val loss: 0.208480
[Epoch 25] ogbg-moltoxcast: 0.742179 test loss: 0.205524
[Epoch 26; Iter    15/  201] train: loss: 0.1583668
[Epoch 26; Iter    45/  201] train: loss: 0.1666518
[Epoch 26; Iter    75/  201] train: loss: 0.1352285
[Epoch 26; Iter   105/  201] train: loss: 0.1690263
[Epoch 26; Iter   135/  201] train: loss: 0.2139710
[Epoch 26; Iter   165/  201] train: loss: 0.1392298
[Epoch 26; Iter   195/  201] train: loss: 0.1773549
[Epoch 26] ogbg-moltoxcast: 0.732690 val loss: 0.203113
[Epoch 26] ogbg-moltoxcast: 0.741726 test loss: 0.205246
[Epoch 27; Iter    24/  201] train: loss: 0.1921759
[Epoch 27; Iter    54/  201] train: loss: 0.2054360
[Epoch 27; Iter    84/  201] train: loss: 0.2733362
[Epoch 27; Iter   114/  201] train: loss: 0.1497505
[Epoch 27; Iter   144/  201] train: loss: 0.1177355
[Epoch 27; Iter   174/  201] train: loss: 0.2043810
[Epoch 27] ogbg-moltoxcast: 0.727493 val loss: 0.204904
[Epoch 27] ogbg-moltoxcast: 0.746622 test loss: 0.202431
[Epoch 28; Iter     3/  201] train: loss: 0.2233025
[Epoch 28; Iter    33/  201] train: loss: 0.1842218
[Epoch 28; Iter    63/  201] train: loss: 0.1392112
[Epoch 28; Iter    93/  201] train: loss: 0.1511386
[Epoch 28; Iter   123/  201] train: loss: 0.2345995
[Epoch 28; Iter   153/  201] train: loss: 0.1810252
[Epoch 28; Iter   183/  201] train: loss: 0.2059203
[Epoch 28] ogbg-moltoxcast: 0.730368 val loss: 0.203889
[Epoch 28] ogbg-moltoxcast: 0.745384 test loss: 0.202089
[Epoch 29; Iter    12/  201] train: loss: 0.1155507
[Epoch 29; Iter    42/  201] train: loss: 0.2296940
[Epoch 29; Iter    72/  201] train: loss: 0.1452256
[Epoch 29; Iter   102/  201] train: loss: 0.1412019
[Epoch 29; Iter   132/  201] train: loss: 0.1281781
[Epoch 29; Iter   162/  201] train: loss: 0.1453233
[Epoch 29; Iter   192/  201] train: loss: 0.2004058
[Epoch 29] ogbg-moltoxcast: 0.729980 val loss: 0.205373
[Epoch 29] ogbg-moltoxcast: 0.749053 test loss: 0.205082
[Epoch 30; Iter    21/  201] train: loss: 0.1845913
[Epoch 30; Iter    51/  201] train: loss: 0.2041438
[Epoch 30; Iter    81/  201] train: loss: 0.1349588
[Epoch 30; Iter   111/  201] train: loss: 0.1656895
[Epoch 30; Iter   141/  201] train: loss: 0.2346841
[Epoch 30; Iter   171/  201] train: loss: 0.1343630
[Epoch 30; Iter   201/  201] train: loss: 0.0986909
[Epoch 30] ogbg-moltoxcast: 0.733342 val loss: 0.204736
[Epoch 13; Iter    78/  201] train: loss: 0.1626554
[Epoch 13; Iter   108/  201] train: loss: 0.2263062
[Epoch 13; Iter   138/  201] train: loss: 0.1882809
[Epoch 13; Iter   168/  201] train: loss: 0.1376094
[Epoch 13; Iter   198/  201] train: loss: 0.2470926
[Epoch 13] ogbg-moltoxcast: 0.689932 val loss: 0.482940
[Epoch 13] ogbg-moltoxcast: 0.706984 test loss: 0.463435
[Epoch 14; Iter    27/  201] train: loss: 0.1551812
[Epoch 14; Iter    57/  201] train: loss: 0.1962113
[Epoch 14; Iter    87/  201] train: loss: 0.1610281
[Epoch 14; Iter   117/  201] train: loss: 0.1975282
[Epoch 14; Iter   147/  201] train: loss: 0.2298633
[Epoch 14; Iter   177/  201] train: loss: 0.2564651
[Epoch 14] ogbg-moltoxcast: 0.699291 val loss: 0.274181
[Epoch 14] ogbg-moltoxcast: 0.706081 test loss: 0.280213
[Epoch 15; Iter     6/  201] train: loss: 0.2117748
[Epoch 15; Iter    36/  201] train: loss: 0.2058157
[Epoch 15; Iter    66/  201] train: loss: 0.2043811
[Epoch 15; Iter    96/  201] train: loss: 0.2202194
[Epoch 15; Iter   126/  201] train: loss: 0.2287178
[Epoch 15; Iter   156/  201] train: loss: 0.1958406
[Epoch 15; Iter   186/  201] train: loss: 0.2026052
[Epoch 15] ogbg-moltoxcast: 0.706189 val loss: 0.212264
[Epoch 15] ogbg-moltoxcast: 0.724050 test loss: 0.214769
[Epoch 16; Iter    15/  201] train: loss: 0.1936595
[Epoch 16; Iter    45/  201] train: loss: 0.1774043
[Epoch 16; Iter    75/  201] train: loss: 0.1780916
[Epoch 16; Iter   105/  201] train: loss: 0.2304415
[Epoch 16; Iter   135/  201] train: loss: 0.2045605
[Epoch 16; Iter   165/  201] train: loss: 0.1697221
[Epoch 16; Iter   195/  201] train: loss: 0.1255186
[Epoch 16] ogbg-moltoxcast: 0.704561 val loss: 0.213288
[Epoch 16] ogbg-moltoxcast: 0.724824 test loss: 0.217866
[Epoch 17; Iter    24/  201] train: loss: 0.2003715
[Epoch 17; Iter    54/  201] train: loss: 0.1441461
[Epoch 17; Iter    84/  201] train: loss: 0.2857350
[Epoch 17; Iter   114/  201] train: loss: 0.1670516
[Epoch 17; Iter   144/  201] train: loss: 0.2395103
[Epoch 17; Iter   174/  201] train: loss: 0.2621038
[Epoch 17] ogbg-moltoxcast: 0.698612 val loss: 0.211529
[Epoch 17] ogbg-moltoxcast: 0.728485 test loss: 0.215500
[Epoch 18; Iter     3/  201] train: loss: 0.1755767
[Epoch 18; Iter    33/  201] train: loss: 0.1678847
[Epoch 18; Iter    63/  201] train: loss: 0.1692051
[Epoch 18; Iter    93/  201] train: loss: 0.1716108
[Epoch 18; Iter   123/  201] train: loss: 0.3555799
[Epoch 18; Iter   153/  201] train: loss: 0.1713030
[Epoch 18; Iter   183/  201] train: loss: 0.2259901
[Epoch 18] ogbg-moltoxcast: 0.706196 val loss: 0.213283
[Epoch 18] ogbg-moltoxcast: 0.723281 test loss: 0.217842
[Epoch 19; Iter    12/  201] train: loss: 0.2114285
[Epoch 19; Iter    42/  201] train: loss: 0.1743900
[Epoch 19; Iter    72/  201] train: loss: 0.2563478
[Epoch 19; Iter   102/  201] train: loss: 0.2240518
[Epoch 19; Iter   132/  201] train: loss: 0.1314913
[Epoch 19; Iter   162/  201] train: loss: 0.1674193
[Epoch 19; Iter   192/  201] train: loss: 0.2553325
[Epoch 19] ogbg-moltoxcast: 0.706115 val loss: 0.215996
[Epoch 19] ogbg-moltoxcast: 0.720346 test loss: 0.221765
[Epoch 20; Iter    21/  201] train: loss: 0.2019911
[Epoch 20; Iter    51/  201] train: loss: 0.1214578
[Epoch 20; Iter    81/  201] train: loss: 0.2423556
[Epoch 20; Iter   111/  201] train: loss: 0.1396864
[Epoch 20; Iter   141/  201] train: loss: 0.2060939
[Epoch 20; Iter   171/  201] train: loss: 0.2151481
[Epoch 20; Iter   201/  201] train: loss: 0.2243917
[Epoch 20] ogbg-moltoxcast: 0.709379 val loss: 0.222814
[Epoch 20] ogbg-moltoxcast: 0.722748 test loss: 0.273548
[Epoch 21; Iter    30/  201] train: loss: 0.3199551
[Epoch 21; Iter    60/  201] train: loss: 0.1371904
[Epoch 21; Iter    90/  201] train: loss: 0.2012113
[Epoch 21; Iter   120/  201] train: loss: 0.2734536
[Epoch 21; Iter   150/  201] train: loss: 0.1997027
[Epoch 21; Iter   180/  201] train: loss: 0.2273295
[Epoch 21] ogbg-moltoxcast: 0.715030 val loss: 0.235243
[Epoch 21] ogbg-moltoxcast: 0.722053 test loss: 0.255755
[Epoch 22; Iter     9/  201] train: loss: 0.1772176
[Epoch 22; Iter    39/  201] train: loss: 0.2126909
[Epoch 22; Iter    69/  201] train: loss: 0.1707518
[Epoch 22; Iter    99/  201] train: loss: 0.1673268
[Epoch 22; Iter   129/  201] train: loss: 0.2414840
[Epoch 22; Iter   159/  201] train: loss: 0.1903429
[Epoch 22; Iter   189/  201] train: loss: 0.2331693
[Epoch 22] ogbg-moltoxcast: 0.716024 val loss: 0.220233
[Epoch 22] ogbg-moltoxcast: 0.736108 test loss: 0.259920
[Epoch 23; Iter    18/  201] train: loss: 0.2135630
[Epoch 23; Iter    48/  201] train: loss: 0.1629505
[Epoch 23; Iter    78/  201] train: loss: 0.2743344
[Epoch 23; Iter   108/  201] train: loss: 0.1256820
[Epoch 23; Iter   138/  201] train: loss: 0.1832765
[Epoch 23; Iter   168/  201] train: loss: 0.1307322
[Epoch 23; Iter   198/  201] train: loss: 0.1559854
[Epoch 23] ogbg-moltoxcast: 0.699802 val loss: 0.216556
[Epoch 23] ogbg-moltoxcast: 0.730835 test loss: 0.214348
[Epoch 24; Iter    27/  201] train: loss: 0.1920407
[Epoch 24; Iter    57/  201] train: loss: 0.1600197
[Epoch 24; Iter    87/  201] train: loss: 0.1884445
[Epoch 24; Iter   117/  201] train: loss: 0.1684635
[Epoch 24; Iter   147/  201] train: loss: 0.2460125
[Epoch 24; Iter   177/  201] train: loss: 0.1305924
[Epoch 24] ogbg-moltoxcast: 0.713014 val loss: 0.216686
[Epoch 24] ogbg-moltoxcast: 0.734769 test loss: 0.214803
[Epoch 25; Iter     6/  201] train: loss: 0.2077703
[Epoch 25; Iter    36/  201] train: loss: 0.1566436
[Epoch 25; Iter    66/  201] train: loss: 0.1969792
[Epoch 25; Iter    96/  201] train: loss: 0.2412086
[Epoch 25; Iter   126/  201] train: loss: 0.1458922
[Epoch 25; Iter   156/  201] train: loss: 0.2017279
[Epoch 25; Iter   186/  201] train: loss: 0.1493769
[Epoch 25] ogbg-moltoxcast: 0.731899 val loss: 0.212199
[Epoch 25] ogbg-moltoxcast: 0.744228 test loss: 0.217497
[Epoch 26; Iter    15/  201] train: loss: 0.1734538
[Epoch 26; Iter    45/  201] train: loss: 0.2427986
[Epoch 26; Iter    75/  201] train: loss: 0.1920860
[Epoch 26; Iter   105/  201] train: loss: 0.1883578
[Epoch 26; Iter   135/  201] train: loss: 0.2387074
[Epoch 26; Iter   165/  201] train: loss: 0.1294409
[Epoch 26; Iter   195/  201] train: loss: 0.1735197
[Epoch 26] ogbg-moltoxcast: 0.724047 val loss: 0.224391
[Epoch 26] ogbg-moltoxcast: 0.743276 test loss: 0.234687
[Epoch 27; Iter    24/  201] train: loss: 0.1954773
[Epoch 27; Iter    54/  201] train: loss: 0.1932648
[Epoch 27; Iter    84/  201] train: loss: 0.1849673
[Epoch 27; Iter   114/  201] train: loss: 0.1828652
[Epoch 27; Iter   144/  201] train: loss: 0.1913858
[Epoch 27; Iter   174/  201] train: loss: 0.2374297
[Epoch 27] ogbg-moltoxcast: 0.728681 val loss: 0.206885
[Epoch 27] ogbg-moltoxcast: 0.738385 test loss: 0.208380
[Epoch 28; Iter     3/  201] train: loss: 0.3141262
[Epoch 28; Iter    33/  201] train: loss: 0.2548605
[Epoch 28; Iter    63/  201] train: loss: 0.2166442
[Epoch 28; Iter    93/  201] train: loss: 0.1947068
[Epoch 28; Iter   123/  201] train: loss: 0.1705502
[Epoch 28; Iter   153/  201] train: loss: 0.2172834
[Epoch 28; Iter   183/  201] train: loss: 0.1650095
[Epoch 28] ogbg-moltoxcast: 0.715785 val loss: 0.210661
[Epoch 28] ogbg-moltoxcast: 0.739868 test loss: 0.210708
[Epoch 29; Iter    12/  201] train: loss: 0.0988850
[Epoch 29; Iter    42/  201] train: loss: 0.1722699
[Epoch 29; Iter    72/  201] train: loss: 0.1803949
[Epoch 29; Iter   102/  201] train: loss: 0.1764747
[Epoch 29; Iter   132/  201] train: loss: 0.1455940
[Epoch 29; Iter   162/  201] train: loss: 0.1727031
[Epoch 29; Iter   192/  201] train: loss: 0.1982232
[Epoch 29] ogbg-moltoxcast: 0.727323 val loss: 0.208932
[Epoch 29] ogbg-moltoxcast: 0.739086 test loss: 0.204979
[Epoch 30; Iter    21/  201] train: loss: 0.1440257
[Epoch 30; Iter    51/  201] train: loss: 0.1934629
[Epoch 30; Iter    81/  201] train: loss: 0.1867934
[Epoch 30; Iter   111/  201] train: loss: 0.1943564
[Epoch 30; Iter   141/  201] train: loss: 0.1813160
[Epoch 30; Iter   171/  201] train: loss: 0.1406369
[Epoch 30; Iter   201/  201] train: loss: 0.1756200
[Epoch 30] ogbg-moltoxcast: 0.721066 val loss: 0.214677
[Epoch 13; Iter    78/  201] train: loss: 0.2427017
[Epoch 13; Iter   108/  201] train: loss: 0.1890709
[Epoch 13; Iter   138/  201] train: loss: 0.2417272
[Epoch 13; Iter   168/  201] train: loss: 0.2323232
[Epoch 13; Iter   198/  201] train: loss: 0.1588050
[Epoch 13] ogbg-moltoxcast: 0.688595 val loss: 0.243240
[Epoch 13] ogbg-moltoxcast: 0.709255 test loss: 0.222243
[Epoch 14; Iter    27/  201] train: loss: 0.2434396
[Epoch 14; Iter    57/  201] train: loss: 0.1818334
[Epoch 14; Iter    87/  201] train: loss: 0.1246889
[Epoch 14; Iter   117/  201] train: loss: 0.1306095
[Epoch 14; Iter   147/  201] train: loss: 0.2086741
[Epoch 14; Iter   177/  201] train: loss: 0.1568327
[Epoch 14] ogbg-moltoxcast: 0.690940 val loss: 0.245012
[Epoch 14] ogbg-moltoxcast: 0.713963 test loss: 0.241381
[Epoch 15; Iter     6/  201] train: loss: 0.1293894
[Epoch 15; Iter    36/  201] train: loss: 0.1183573
[Epoch 15; Iter    66/  201] train: loss: 0.1932604
[Epoch 15; Iter    96/  201] train: loss: 0.1747700
[Epoch 15; Iter   126/  201] train: loss: 0.2671694
[Epoch 15; Iter   156/  201] train: loss: 0.1550945
[Epoch 15; Iter   186/  201] train: loss: 0.2304229
[Epoch 15] ogbg-moltoxcast: 0.693361 val loss: 0.230815
[Epoch 15] ogbg-moltoxcast: 0.723486 test loss: 0.213757
[Epoch 16; Iter    15/  201] train: loss: 0.1713664
[Epoch 16; Iter    45/  201] train: loss: 0.1397514
[Epoch 16; Iter    75/  201] train: loss: 0.2434933
[Epoch 16; Iter   105/  201] train: loss: 0.1980675
[Epoch 16; Iter   135/  201] train: loss: 0.1771938
[Epoch 16; Iter   165/  201] train: loss: 0.1502051
[Epoch 16; Iter   195/  201] train: loss: 0.1963793
[Epoch 16] ogbg-moltoxcast: 0.629759 val loss: 0.363225
[Epoch 16] ogbg-moltoxcast: 0.576898 test loss: 0.519725
[Epoch 17; Iter    24/  201] train: loss: 0.1706568
[Epoch 17; Iter    54/  201] train: loss: 0.1993840
[Epoch 17; Iter    84/  201] train: loss: 0.2006965
[Epoch 17; Iter   114/  201] train: loss: 0.2062510
[Epoch 17; Iter   144/  201] train: loss: 0.2351668
[Epoch 17; Iter   174/  201] train: loss: 0.2219418
[Epoch 17] ogbg-moltoxcast: 0.696154 val loss: 0.211809
[Epoch 17] ogbg-moltoxcast: 0.722813 test loss: 0.213411
[Epoch 18; Iter     3/  201] train: loss: 0.2312883
[Epoch 18; Iter    33/  201] train: loss: 0.1519971
[Epoch 18; Iter    63/  201] train: loss: 0.2646667
[Epoch 18; Iter    93/  201] train: loss: 0.1588541
[Epoch 18; Iter   123/  201] train: loss: 0.1460070
[Epoch 18; Iter   153/  201] train: loss: 0.1525126
[Epoch 18; Iter   183/  201] train: loss: 0.2874097
[Epoch 18] ogbg-moltoxcast: 0.707276 val loss: 0.447536
[Epoch 18] ogbg-moltoxcast: 0.712450 test loss: 0.390101
[Epoch 19; Iter    12/  201] train: loss: 0.1748206
[Epoch 19; Iter    42/  201] train: loss: 0.2607437
[Epoch 19; Iter    72/  201] train: loss: 0.2405653
[Epoch 19; Iter   102/  201] train: loss: 0.1398967
[Epoch 19; Iter   132/  201] train: loss: 0.1371403
[Epoch 19; Iter   162/  201] train: loss: 0.1913401
[Epoch 19; Iter   192/  201] train: loss: 0.1500148
[Epoch 19] ogbg-moltoxcast: 0.705221 val loss: 0.214363
[Epoch 19] ogbg-moltoxcast: 0.728983 test loss: 0.209150
[Epoch 20; Iter    21/  201] train: loss: 0.2528359
[Epoch 20; Iter    51/  201] train: loss: 0.2781444
[Epoch 20; Iter    81/  201] train: loss: 0.1831540
[Epoch 20; Iter   111/  201] train: loss: 0.1592181
[Epoch 20; Iter   141/  201] train: loss: 0.1919643
[Epoch 20; Iter   171/  201] train: loss: 0.2330908
[Epoch 20; Iter   201/  201] train: loss: 0.0566036
[Epoch 20] ogbg-moltoxcast: 0.708419 val loss: 0.210830
[Epoch 20] ogbg-moltoxcast: 0.730685 test loss: 0.210904
[Epoch 21; Iter    30/  201] train: loss: 0.1572305
[Epoch 21; Iter    60/  201] train: loss: 0.2111692
[Epoch 21; Iter    90/  201] train: loss: 0.1775326
[Epoch 21; Iter   120/  201] train: loss: 0.2319661
[Epoch 21; Iter   150/  201] train: loss: 0.1489994
[Epoch 21; Iter   180/  201] train: loss: 0.1777560
[Epoch 21] ogbg-moltoxcast: 0.709163 val loss: 0.257273
[Epoch 21] ogbg-moltoxcast: 0.728749 test loss: 0.222999
[Epoch 22; Iter     9/  201] train: loss: 0.3231412
[Epoch 22; Iter    39/  201] train: loss: 0.1922493
[Epoch 22; Iter    69/  201] train: loss: 0.2037746
[Epoch 22; Iter    99/  201] train: loss: 0.1893343
[Epoch 22; Iter   129/  201] train: loss: 0.2440940
[Epoch 22; Iter   159/  201] train: loss: 0.1893023
[Epoch 22; Iter   189/  201] train: loss: 0.2097251
[Epoch 22] ogbg-moltoxcast: 0.713259 val loss: 0.208811
[Epoch 22] ogbg-moltoxcast: 0.726058 test loss: 0.210810
[Epoch 23; Iter    18/  201] train: loss: 0.2015564
[Epoch 23; Iter    48/  201] train: loss: 0.1639344
[Epoch 23; Iter    78/  201] train: loss: 0.1983887
[Epoch 23; Iter   108/  201] train: loss: 0.1325082
[Epoch 23; Iter   138/  201] train: loss: 0.1926951
[Epoch 23; Iter   168/  201] train: loss: 0.2500906
[Epoch 23; Iter   198/  201] train: loss: 0.1348528
[Epoch 23] ogbg-moltoxcast: 0.721450 val loss: 0.206105
[Epoch 23] ogbg-moltoxcast: 0.731347 test loss: 0.207223
[Epoch 24; Iter    27/  201] train: loss: 0.1660957
[Epoch 24; Iter    57/  201] train: loss: 0.1503246
[Epoch 24; Iter    87/  201] train: loss: 0.2470389
[Epoch 24; Iter   117/  201] train: loss: 0.2214881
[Epoch 24; Iter   147/  201] train: loss: 0.1203144
[Epoch 24; Iter   177/  201] train: loss: 0.1531143
[Epoch 24] ogbg-moltoxcast: 0.719950 val loss: 0.209395
[Epoch 24] ogbg-moltoxcast: 0.738787 test loss: 0.205526
[Epoch 25; Iter     6/  201] train: loss: 0.2449491
[Epoch 25; Iter    36/  201] train: loss: 0.1769386
[Epoch 25; Iter    66/  201] train: loss: 0.1947484
[Epoch 25; Iter    96/  201] train: loss: 0.2187332
[Epoch 25; Iter   126/  201] train: loss: 0.1360209
[Epoch 25; Iter   156/  201] train: loss: 0.2176087
[Epoch 25; Iter   186/  201] train: loss: 0.2544455
[Epoch 25] ogbg-moltoxcast: 0.710547 val loss: 0.221778
[Epoch 25] ogbg-moltoxcast: 0.737998 test loss: 0.217834
[Epoch 26; Iter    15/  201] train: loss: 0.1614769
[Epoch 26; Iter    45/  201] train: loss: 0.2038665
[Epoch 26; Iter    75/  201] train: loss: 0.1450938
[Epoch 26; Iter   105/  201] train: loss: 0.1906907
[Epoch 26; Iter   135/  201] train: loss: 0.2059184
[Epoch 26; Iter   165/  201] train: loss: 0.1794219
[Epoch 26; Iter   195/  201] train: loss: 0.1778529
[Epoch 26] ogbg-moltoxcast: 0.716501 val loss: 0.210025
[Epoch 26] ogbg-moltoxcast: 0.736550 test loss: 0.211699
[Epoch 27; Iter    24/  201] train: loss: 0.1299714
[Epoch 27; Iter    54/  201] train: loss: 0.2312505
[Epoch 27; Iter    84/  201] train: loss: 0.1582643
[Epoch 27; Iter   114/  201] train: loss: 0.2125135
[Epoch 27; Iter   144/  201] train: loss: 0.1678087
[Epoch 27; Iter   174/  201] train: loss: 0.2608261
[Epoch 27] ogbg-moltoxcast: 0.723594 val loss: 0.210522
[Epoch 27] ogbg-moltoxcast: 0.743405 test loss: 0.205637
[Epoch 28; Iter     3/  201] train: loss: 0.1685762
[Epoch 28; Iter    33/  201] train: loss: 0.1697526
[Epoch 28; Iter    63/  201] train: loss: 0.1570245
[Epoch 28; Iter    93/  201] train: loss: 0.1640828
[Epoch 28; Iter   123/  201] train: loss: 0.1356088
[Epoch 28; Iter   153/  201] train: loss: 0.2108825
[Epoch 28; Iter   183/  201] train: loss: 0.1933237
[Epoch 28] ogbg-moltoxcast: 0.708827 val loss: 0.215196
[Epoch 28] ogbg-moltoxcast: 0.735171 test loss: 0.217345
[Epoch 29; Iter    12/  201] train: loss: 0.2322025
[Epoch 29; Iter    42/  201] train: loss: 0.2022291
[Epoch 29; Iter    72/  201] train: loss: 0.1649134
[Epoch 29; Iter   102/  201] train: loss: 0.1862661
[Epoch 29; Iter   132/  201] train: loss: 0.1384752
[Epoch 29; Iter   162/  201] train: loss: 0.1547012
[Epoch 29; Iter   192/  201] train: loss: 0.1543036
[Epoch 29] ogbg-moltoxcast: 0.717337 val loss: 0.209580
[Epoch 29] ogbg-moltoxcast: 0.727511 test loss: 0.210476
[Epoch 30; Iter    21/  201] train: loss: 0.1762511
[Epoch 30; Iter    51/  201] train: loss: 0.1615760
[Epoch 30; Iter    81/  201] train: loss: 0.1461139
[Epoch 30; Iter   111/  201] train: loss: 0.1982586
[Epoch 30; Iter   141/  201] train: loss: 0.1942260
[Epoch 30; Iter   171/  201] train: loss: 0.1753483
[Epoch 30; Iter   201/  201] train: loss: 0.3908642
[Epoch 30] ogbg-moltoxcast: 0.718450 val loss: 0.213700
[Epoch 14] ogbg-moltoxcast: 0.694160 val loss: 0.230167
[Epoch 14] ogbg-moltoxcast: 0.702449 test loss: 0.222901
[Epoch 15; Iter    22/  172] train: loss: 0.1844428
[Epoch 15; Iter    52/  172] train: loss: 0.2012542
[Epoch 15; Iter    82/  172] train: loss: 0.1077277
[Epoch 15; Iter   112/  172] train: loss: 0.1570377
[Epoch 15; Iter   142/  172] train: loss: 0.1502296
[Epoch 15; Iter   172/  172] train: loss: 0.1887148
[Epoch 15] ogbg-moltoxcast: 0.701421 val loss: 0.213133
[Epoch 15] ogbg-moltoxcast: 0.707836 test loss: 0.211171
[Epoch 16; Iter    30/  172] train: loss: 0.1651605
[Epoch 16; Iter    60/  172] train: loss: 0.1646389
[Epoch 16; Iter    90/  172] train: loss: 0.2202528
[Epoch 16; Iter   120/  172] train: loss: 0.2350503
[Epoch 16; Iter   150/  172] train: loss: 0.1606215
[Epoch 16] ogbg-moltoxcast: 0.694087 val loss: 0.213586
[Epoch 16] ogbg-moltoxcast: 0.708206 test loss: 0.211258
[Epoch 17; Iter     8/  172] train: loss: 0.1972479
[Epoch 17; Iter    38/  172] train: loss: 0.1575612
[Epoch 17; Iter    68/  172] train: loss: 0.2192469
[Epoch 17; Iter    98/  172] train: loss: 0.2455245
[Epoch 17; Iter   128/  172] train: loss: 0.2152488
[Epoch 17; Iter   158/  172] train: loss: 0.1716598
[Epoch 17] ogbg-moltoxcast: 0.684797 val loss: 0.219505
[Epoch 17] ogbg-moltoxcast: 0.684317 test loss: 0.219386
[Epoch 18; Iter    16/  172] train: loss: 0.2198358
[Epoch 18; Iter    46/  172] train: loss: 0.2550330
[Epoch 18; Iter    76/  172] train: loss: 0.2964870
[Epoch 18; Iter   106/  172] train: loss: 0.2049714
[Epoch 18; Iter   136/  172] train: loss: 0.1730197
[Epoch 18; Iter   166/  172] train: loss: 0.1218128
[Epoch 18] ogbg-moltoxcast: 0.688277 val loss: 0.218886
[Epoch 18] ogbg-moltoxcast: 0.692044 test loss: 0.217083
[Epoch 19; Iter    24/  172] train: loss: 0.2625692
[Epoch 19; Iter    54/  172] train: loss: 0.1613405
[Epoch 19; Iter    84/  172] train: loss: 0.2906368
[Epoch 19; Iter   114/  172] train: loss: 0.1960439
[Epoch 19; Iter   144/  172] train: loss: 0.2357116
[Epoch 19] ogbg-moltoxcast: 0.690404 val loss: 0.221266
[Epoch 19] ogbg-moltoxcast: 0.698854 test loss: 0.214910
[Epoch 20; Iter     2/  172] train: loss: 0.1568573
[Epoch 20; Iter    32/  172] train: loss: 0.1488033
[Epoch 20; Iter    62/  172] train: loss: 0.2184661
[Epoch 20; Iter    92/  172] train: loss: 0.1502492
[Epoch 20; Iter   122/  172] train: loss: 0.1648183
[Epoch 20; Iter   152/  172] train: loss: 0.1917715
[Epoch 20] ogbg-moltoxcast: 0.709978 val loss: 0.207722
[Epoch 20] ogbg-moltoxcast: 0.710454 test loss: 0.208354
[Epoch 21; Iter    10/  172] train: loss: 0.1871023
[Epoch 21; Iter    40/  172] train: loss: 0.2217662
[Epoch 21; Iter    70/  172] train: loss: 0.2312782
[Epoch 21; Iter   100/  172] train: loss: 0.2106974
[Epoch 21; Iter   130/  172] train: loss: 0.1724279
[Epoch 21; Iter   160/  172] train: loss: 0.1954367
[Epoch 21] ogbg-moltoxcast: 0.712759 val loss: 0.213018
[Epoch 21] ogbg-moltoxcast: 0.722965 test loss: 0.206705
[Epoch 22; Iter    18/  172] train: loss: 0.2266849
[Epoch 22; Iter    48/  172] train: loss: 0.2083052
[Epoch 22; Iter    78/  172] train: loss: 0.1397613
[Epoch 22; Iter   108/  172] train: loss: 0.1813944
[Epoch 22; Iter   138/  172] train: loss: 0.1573743
[Epoch 22; Iter   168/  172] train: loss: 0.1225043
[Epoch 22] ogbg-moltoxcast: 0.712831 val loss: 0.211652
[Epoch 22] ogbg-moltoxcast: 0.717817 test loss: 0.207622
[Epoch 23; Iter    26/  172] train: loss: 0.2254446
[Epoch 23; Iter    56/  172] train: loss: 0.1844085
[Epoch 23; Iter    86/  172] train: loss: 0.1853134
[Epoch 23; Iter   116/  172] train: loss: 0.2232284
[Epoch 23; Iter   146/  172] train: loss: 0.1891327
[Epoch 23] ogbg-moltoxcast: 0.718423 val loss: 0.211562
[Epoch 23] ogbg-moltoxcast: 0.724374 test loss: 0.209950
[Epoch 24; Iter     4/  172] train: loss: 0.1467931
[Epoch 24; Iter    34/  172] train: loss: 0.1971557
[Epoch 24; Iter    64/  172] train: loss: 0.1862900
[Epoch 24; Iter    94/  172] train: loss: 0.1811264
[Epoch 24; Iter   124/  172] train: loss: 0.1776885
[Epoch 24; Iter   154/  172] train: loss: 0.2428689
[Epoch 24] ogbg-moltoxcast: 0.709753 val loss: 0.208249
[Epoch 24] ogbg-moltoxcast: 0.704282 test loss: 0.211533
[Epoch 25; Iter    12/  172] train: loss: 0.2092023
[Epoch 25; Iter    42/  172] train: loss: 0.2027749
[Epoch 25; Iter    72/  172] train: loss: 0.1952148
[Epoch 25; Iter   102/  172] train: loss: 0.1731377
[Epoch 25; Iter   132/  172] train: loss: 0.2073941
[Epoch 25; Iter   162/  172] train: loss: 0.1796044
[Epoch 25] ogbg-moltoxcast: 0.720239 val loss: 0.204692
[Epoch 25] ogbg-moltoxcast: 0.724285 test loss: 0.204596
[Epoch 26; Iter    20/  172] train: loss: 0.1565449
[Epoch 26; Iter    50/  172] train: loss: 0.1289778
[Epoch 26; Iter    80/  172] train: loss: 0.1574031
[Epoch 26; Iter   110/  172] train: loss: 0.1587844
[Epoch 26; Iter   140/  172] train: loss: 0.2486779
[Epoch 26; Iter   170/  172] train: loss: 0.2232736
[Epoch 26] ogbg-moltoxcast: 0.720581 val loss: 0.238334
[Epoch 26] ogbg-moltoxcast: 0.726070 test loss: 0.215567
[Epoch 27; Iter    28/  172] train: loss: 0.2456910
[Epoch 27; Iter    58/  172] train: loss: 0.2440889
[Epoch 27; Iter    88/  172] train: loss: 0.2179697
[Epoch 27; Iter   118/  172] train: loss: 0.1833780
[Epoch 27; Iter   148/  172] train: loss: 0.1551429
[Epoch 27] ogbg-moltoxcast: 0.717575 val loss: 0.237520
[Epoch 27] ogbg-moltoxcast: 0.716570 test loss: 0.209291
[Epoch 28; Iter     6/  172] train: loss: 0.1491298
[Epoch 28; Iter    36/  172] train: loss: 0.1773553
[Epoch 28; Iter    66/  172] train: loss: 0.2119619
[Epoch 28; Iter    96/  172] train: loss: 0.1908024
[Epoch 28; Iter   126/  172] train: loss: 0.2152300
[Epoch 28; Iter   156/  172] train: loss: 0.2208098
[Epoch 28] ogbg-moltoxcast: 0.711929 val loss: 0.211730
[Epoch 28] ogbg-moltoxcast: 0.723934 test loss: 0.209037
[Epoch 29; Iter    14/  172] train: loss: 0.1899751
[Epoch 29; Iter    44/  172] train: loss: 0.1947097
[Epoch 29; Iter    74/  172] train: loss: 0.1705742
[Epoch 29; Iter   104/  172] train: loss: 0.2006342
[Epoch 29; Iter   134/  172] train: loss: 0.2305383
[Epoch 29; Iter   164/  172] train: loss: 0.1469348
[Epoch 29] ogbg-moltoxcast: 0.722957 val loss: 0.205431
[Epoch 29] ogbg-moltoxcast: 0.731420 test loss: 0.202381
[Epoch 30; Iter    22/  172] train: loss: 0.1686212
[Epoch 30; Iter    52/  172] train: loss: 0.2196424
[Epoch 30; Iter    82/  172] train: loss: 0.1682179
[Epoch 30; Iter   112/  172] train: loss: 0.1701436
[Epoch 30; Iter   142/  172] train: loss: 0.2384950
[Epoch 30; Iter   172/  172] train: loss: 0.0877303
[Epoch 30] ogbg-moltoxcast: 0.730267 val loss: 0.201555
[Epoch 30] ogbg-moltoxcast: 0.728703 test loss: 0.203689
[Epoch 31; Iter    30/  172] train: loss: 0.1789415
[Epoch 31; Iter    60/  172] train: loss: 0.1619251
[Epoch 31; Iter    90/  172] train: loss: 0.1877028
[Epoch 31; Iter   120/  172] train: loss: 0.1879426
[Epoch 31; Iter   150/  172] train: loss: 0.1662682
[Epoch 31] ogbg-moltoxcast: 0.722272 val loss: 0.205946
[Epoch 31] ogbg-moltoxcast: 0.727502 test loss: 0.205739
[Epoch 32; Iter     8/  172] train: loss: 0.1269283
[Epoch 32; Iter    38/  172] train: loss: 0.1785107
[Epoch 32; Iter    68/  172] train: loss: 0.2125574
[Epoch 32; Iter    98/  172] train: loss: 0.1902043
[Epoch 32; Iter   128/  172] train: loss: 0.1777518
[Epoch 32; Iter   158/  172] train: loss: 0.1719751
[Epoch 32] ogbg-moltoxcast: 0.730320 val loss: 0.205843
[Epoch 32] ogbg-moltoxcast: 0.732440 test loss: 0.207101
[Epoch 33; Iter    16/  172] train: loss: 0.1690458
[Epoch 33; Iter    46/  172] train: loss: 0.2153353
[Epoch 33; Iter    76/  172] train: loss: 0.2163900
[Epoch 33; Iter   106/  172] train: loss: 0.1218860
[Epoch 33; Iter   136/  172] train: loss: 0.1630478
[Epoch 33; Iter   166/  172] train: loss: 0.1308276
[Epoch 33] ogbg-moltoxcast: 0.726582 val loss: 0.236937
[Epoch 33] ogbg-moltoxcast: 0.726295 test loss: 0.223366
[Epoch 34; Iter    24/  172] train: loss: 0.1835946
[Epoch 34; Iter    54/  172] train: loss: 0.1609720
[Epoch 34; Iter    84/  172] train: loss: 0.1236397
[Epoch 34; Iter   114/  172] train: loss: 0.1461460
[Epoch 34; Iter   144/  172] train: loss: 0.1891871
[Epoch 14] ogbg-moltoxcast: 0.695907 val loss: 0.209086
[Epoch 14] ogbg-moltoxcast: 0.710441 test loss: 0.209014
[Epoch 15; Iter    22/  172] train: loss: 0.2162199
[Epoch 15; Iter    52/  172] train: loss: 0.2477235
[Epoch 15; Iter    82/  172] train: loss: 0.1355783
[Epoch 15; Iter   112/  172] train: loss: 0.1727457
[Epoch 15; Iter   142/  172] train: loss: 0.2552225
[Epoch 15; Iter   172/  172] train: loss: 0.2455483
[Epoch 15] ogbg-moltoxcast: 0.686481 val loss: 0.211457
[Epoch 15] ogbg-moltoxcast: 0.701620 test loss: 0.210000
[Epoch 16; Iter    30/  172] train: loss: 0.2067814
[Epoch 16; Iter    60/  172] train: loss: 0.2479111
[Epoch 16; Iter    90/  172] train: loss: 0.1453775
[Epoch 16; Iter   120/  172] train: loss: 0.1579666
[Epoch 16; Iter   150/  172] train: loss: 0.2641350
[Epoch 16] ogbg-moltoxcast: 0.696854 val loss: 0.208363
[Epoch 16] ogbg-moltoxcast: 0.703075 test loss: 0.209896
[Epoch 17; Iter     8/  172] train: loss: 0.2632297
[Epoch 17; Iter    38/  172] train: loss: 0.1447326
[Epoch 17; Iter    68/  172] train: loss: 0.1490967
[Epoch 17; Iter    98/  172] train: loss: 0.2103440
[Epoch 17; Iter   128/  172] train: loss: 0.1988173
[Epoch 17; Iter   158/  172] train: loss: 0.2087722
[Epoch 17] ogbg-moltoxcast: 0.706882 val loss: 0.212046
[Epoch 17] ogbg-moltoxcast: 0.716796 test loss: 0.211551
[Epoch 18; Iter    16/  172] train: loss: 0.1617951
[Epoch 18; Iter    46/  172] train: loss: 0.1875150
[Epoch 18; Iter    76/  172] train: loss: 0.2103329
[Epoch 18; Iter   106/  172] train: loss: 0.1710999
[Epoch 18; Iter   136/  172] train: loss: 0.1966300
[Epoch 18; Iter   166/  172] train: loss: 0.2131086
[Epoch 18] ogbg-moltoxcast: 0.705710 val loss: 0.208402
[Epoch 18] ogbg-moltoxcast: 0.709722 test loss: 0.211386
[Epoch 19; Iter    24/  172] train: loss: 0.1989136
[Epoch 19; Iter    54/  172] train: loss: 0.1688986
[Epoch 19; Iter    84/  172] train: loss: 0.1544460
[Epoch 19; Iter   114/  172] train: loss: 0.2444355
[Epoch 19; Iter   144/  172] train: loss: 0.1655654
[Epoch 19] ogbg-moltoxcast: 0.707630 val loss: 0.447233
[Epoch 19] ogbg-moltoxcast: 0.719135 test loss: 0.242616
[Epoch 20; Iter     2/  172] train: loss: 0.1087779
[Epoch 20; Iter    32/  172] train: loss: 0.1796934
[Epoch 20; Iter    62/  172] train: loss: 0.1823082
[Epoch 20; Iter    92/  172] train: loss: 0.1452802
[Epoch 20; Iter   122/  172] train: loss: 0.2168999
[Epoch 20; Iter   152/  172] train: loss: 0.1520612
[Epoch 20] ogbg-moltoxcast: 0.716236 val loss: 0.202091
[Epoch 20] ogbg-moltoxcast: 0.720590 test loss: 0.205723
[Epoch 21; Iter    10/  172] train: loss: 0.1997889
[Epoch 21; Iter    40/  172] train: loss: 0.1560976
[Epoch 21; Iter    70/  172] train: loss: 0.1957266
[Epoch 21; Iter   100/  172] train: loss: 0.1790946
[Epoch 21; Iter   130/  172] train: loss: 0.1287546
[Epoch 21; Iter   160/  172] train: loss: 0.1680733
[Epoch 21] ogbg-moltoxcast: 0.716901 val loss: 0.223025
[Epoch 21] ogbg-moltoxcast: 0.733215 test loss: 0.203223
[Epoch 22; Iter    18/  172] train: loss: 0.1511441
[Epoch 22; Iter    48/  172] train: loss: 0.2360342
[Epoch 22; Iter    78/  172] train: loss: 0.1479573
[Epoch 22; Iter   108/  172] train: loss: 0.1802519
[Epoch 22; Iter   138/  172] train: loss: 0.1878065
[Epoch 22; Iter   168/  172] train: loss: 0.1965602
[Epoch 22] ogbg-moltoxcast: 0.712803 val loss: 0.203713
[Epoch 22] ogbg-moltoxcast: 0.729846 test loss: 0.202764
[Epoch 23; Iter    26/  172] train: loss: 0.1551512
[Epoch 23; Iter    56/  172] train: loss: 0.1623807
[Epoch 23; Iter    86/  172] train: loss: 0.1044867
[Epoch 23; Iter   116/  172] train: loss: 0.1701560
[Epoch 23; Iter   146/  172] train: loss: 0.1700418
[Epoch 23] ogbg-moltoxcast: 0.709575 val loss: 0.243459
[Epoch 23] ogbg-moltoxcast: 0.730510 test loss: 0.202206
[Epoch 24; Iter     4/  172] train: loss: 0.2207818
[Epoch 24; Iter    34/  172] train: loss: 0.2010145
[Epoch 24; Iter    64/  172] train: loss: 0.2024172
[Epoch 24; Iter    94/  172] train: loss: 0.1880605
[Epoch 24; Iter   124/  172] train: loss: 0.2222914
[Epoch 24; Iter   154/  172] train: loss: 0.1758775
[Epoch 24] ogbg-moltoxcast: 0.715494 val loss: 0.296089
[Epoch 24] ogbg-moltoxcast: 0.730471 test loss: 0.203416
[Epoch 25; Iter    12/  172] train: loss: 0.1679404
[Epoch 25; Iter    42/  172] train: loss: 0.1629669
[Epoch 25; Iter    72/  172] train: loss: 0.1662916
[Epoch 25; Iter   102/  172] train: loss: 0.1872451
[Epoch 25; Iter   132/  172] train: loss: 0.2190748
[Epoch 25; Iter   162/  172] train: loss: 0.2347953
[Epoch 25] ogbg-moltoxcast: 0.720026 val loss: 0.293795
[Epoch 25] ogbg-moltoxcast: 0.731992 test loss: 0.202707
[Epoch 26; Iter    20/  172] train: loss: 0.1557474
[Epoch 26; Iter    50/  172] train: loss: 0.1395670
[Epoch 26; Iter    80/  172] train: loss: 0.2024257
[Epoch 26; Iter   110/  172] train: loss: 0.1679732
[Epoch 26; Iter   140/  172] train: loss: 0.2312261
[Epoch 26; Iter   170/  172] train: loss: 0.1336756
[Epoch 26] ogbg-moltoxcast: 0.718195 val loss: 0.208556
[Epoch 26] ogbg-moltoxcast: 0.734136 test loss: 0.207297
[Epoch 27; Iter    28/  172] train: loss: 0.1928158
[Epoch 27; Iter    58/  172] train: loss: 0.1980433
[Epoch 27; Iter    88/  172] train: loss: 0.1373952
[Epoch 27; Iter   118/  172] train: loss: 0.2064521
[Epoch 27; Iter   148/  172] train: loss: 0.1552576
[Epoch 27] ogbg-moltoxcast: 0.723320 val loss: 0.202585
[Epoch 27] ogbg-moltoxcast: 0.732982 test loss: 0.203339
[Epoch 28; Iter     6/  172] train: loss: 0.1440122
[Epoch 28; Iter    36/  172] train: loss: 0.2580514
[Epoch 28; Iter    66/  172] train: loss: 0.1899312
[Epoch 28; Iter    96/  172] train: loss: 0.1733783
[Epoch 28; Iter   126/  172] train: loss: 0.1550861
[Epoch 28; Iter   156/  172] train: loss: 0.2555569
[Epoch 28] ogbg-moltoxcast: 0.722248 val loss: 0.208596
[Epoch 28] ogbg-moltoxcast: 0.739703 test loss: 0.199771
[Epoch 29; Iter    14/  172] train: loss: 0.1850887
[Epoch 29; Iter    44/  172] train: loss: 0.1786045
[Epoch 29; Iter    74/  172] train: loss: 0.1526330
[Epoch 29; Iter   104/  172] train: loss: 0.1116029
[Epoch 29; Iter   134/  172] train: loss: 0.2065316
[Epoch 29; Iter   164/  172] train: loss: 0.1851643
[Epoch 29] ogbg-moltoxcast: 0.716766 val loss: 0.224166
[Epoch 29] ogbg-moltoxcast: 0.727780 test loss: 0.204027
[Epoch 30; Iter    22/  172] train: loss: 0.1366116
[Epoch 30; Iter    52/  172] train: loss: 0.2011525
[Epoch 30; Iter    82/  172] train: loss: 0.1858055
[Epoch 30; Iter   112/  172] train: loss: 0.1938057
[Epoch 30; Iter   142/  172] train: loss: 0.2503755
[Epoch 30; Iter   172/  172] train: loss: 0.1277462
[Epoch 30] ogbg-moltoxcast: 0.726568 val loss: 0.250300
[Epoch 30] ogbg-moltoxcast: 0.733496 test loss: 0.203073
[Epoch 31; Iter    30/  172] train: loss: 0.1550855
[Epoch 31; Iter    60/  172] train: loss: 0.2680284
[Epoch 31; Iter    90/  172] train: loss: 0.1274820
[Epoch 31; Iter   120/  172] train: loss: 0.1690935
[Epoch 31; Iter   150/  172] train: loss: 0.1853520
[Epoch 31] ogbg-moltoxcast: 0.722238 val loss: 0.235410
[Epoch 31] ogbg-moltoxcast: 0.736952 test loss: 0.199625
[Epoch 32; Iter     8/  172] train: loss: 0.1643817
[Epoch 32; Iter    38/  172] train: loss: 0.1659444
[Epoch 32; Iter    68/  172] train: loss: 0.1153884
[Epoch 32; Iter    98/  172] train: loss: 0.1768950
[Epoch 32; Iter   128/  172] train: loss: 0.1894750
[Epoch 32; Iter   158/  172] train: loss: 0.1564957
[Epoch 32] ogbg-moltoxcast: 0.716787 val loss: 0.217519
[Epoch 32] ogbg-moltoxcast: 0.738427 test loss: 0.201538
[Epoch 33; Iter    16/  172] train: loss: 0.1109071
[Epoch 33; Iter    46/  172] train: loss: 0.1818805
[Epoch 33; Iter    76/  172] train: loss: 0.1237778
[Epoch 33; Iter   106/  172] train: loss: 0.1735106
[Epoch 33; Iter   136/  172] train: loss: 0.1918679
[Epoch 33; Iter   166/  172] train: loss: 0.1569364
[Epoch 33] ogbg-moltoxcast: 0.721268 val loss: 0.257855
[Epoch 33] ogbg-moltoxcast: 0.738412 test loss: 0.199359
[Epoch 34; Iter    24/  172] train: loss: 0.1238089
[Epoch 34; Iter    54/  172] train: loss: 0.1465319
[Epoch 34; Iter    84/  172] train: loss: 0.2457253
[Epoch 34; Iter   114/  172] train: loss: 0.2040008
[Epoch 34; Iter   144/  172] train: loss: 0.1365004
[Epoch 14] ogbg-moltoxcast: 0.699201 val loss: 0.223095
[Epoch 14] ogbg-moltoxcast: 0.705455 test loss: 0.217419
[Epoch 15; Iter    22/  172] train: loss: 0.2299553
[Epoch 15; Iter    52/  172] train: loss: 0.1587523
[Epoch 15; Iter    82/  172] train: loss: 0.2179886
[Epoch 15; Iter   112/  172] train: loss: 0.1772749
[Epoch 15; Iter   142/  172] train: loss: 0.2045760
[Epoch 15; Iter   172/  172] train: loss: 0.2645681
[Epoch 15] ogbg-moltoxcast: 0.691094 val loss: 0.226038
[Epoch 15] ogbg-moltoxcast: 0.697785 test loss: 0.221181
[Epoch 16; Iter    30/  172] train: loss: 0.2353272
[Epoch 16; Iter    60/  172] train: loss: 0.1306484
[Epoch 16; Iter    90/  172] train: loss: 0.2270560
[Epoch 16; Iter   120/  172] train: loss: 0.2118050
[Epoch 16; Iter   150/  172] train: loss: 0.1693829
[Epoch 16] ogbg-moltoxcast: 0.705543 val loss: 0.221149
[Epoch 16] ogbg-moltoxcast: 0.702700 test loss: 0.220398
[Epoch 17; Iter     8/  172] train: loss: 0.1331840
[Epoch 17; Iter    38/  172] train: loss: 0.1394657
[Epoch 17; Iter    68/  172] train: loss: 0.2090089
[Epoch 17; Iter    98/  172] train: loss: 0.2140752
[Epoch 17; Iter   128/  172] train: loss: 0.2342618
[Epoch 17; Iter   158/  172] train: loss: 0.2580036
[Epoch 17] ogbg-moltoxcast: 0.704196 val loss: 0.236914
[Epoch 17] ogbg-moltoxcast: 0.711753 test loss: 0.224020
[Epoch 18; Iter    16/  172] train: loss: 0.1176703
[Epoch 18; Iter    46/  172] train: loss: 0.1808875
[Epoch 18; Iter    76/  172] train: loss: 0.2093550
[Epoch 18; Iter   106/  172] train: loss: 0.2665319
[Epoch 18; Iter   136/  172] train: loss: 0.1740541
[Epoch 18; Iter   166/  172] train: loss: 0.1513141
[Epoch 18] ogbg-moltoxcast: 0.714742 val loss: 0.208271
[Epoch 18] ogbg-moltoxcast: 0.723363 test loss: 0.206895
[Epoch 19; Iter    24/  172] train: loss: 0.2158593
[Epoch 19; Iter    54/  172] train: loss: 0.1647168
[Epoch 19; Iter    84/  172] train: loss: 0.1543604
[Epoch 19; Iter   114/  172] train: loss: 0.2137875
[Epoch 19; Iter   144/  172] train: loss: 0.2124366
[Epoch 19] ogbg-moltoxcast: 0.708931 val loss: 0.271669
[Epoch 19] ogbg-moltoxcast: 0.715093 test loss: 0.244785
[Epoch 20; Iter     2/  172] train: loss: 0.1828221
[Epoch 20; Iter    32/  172] train: loss: 0.1661216
[Epoch 20; Iter    62/  172] train: loss: 0.1388274
[Epoch 20; Iter    92/  172] train: loss: 0.2368384
[Epoch 20; Iter   122/  172] train: loss: 0.1570528
[Epoch 20; Iter   152/  172] train: loss: 0.1676013
[Epoch 20] ogbg-moltoxcast: 0.718329 val loss: 0.231143
[Epoch 20] ogbg-moltoxcast: 0.721617 test loss: 0.219609
[Epoch 21; Iter    10/  172] train: loss: 0.1969802
[Epoch 21; Iter    40/  172] train: loss: 0.1241693
[Epoch 21; Iter    70/  172] train: loss: 0.2259240
[Epoch 21; Iter   100/  172] train: loss: 0.1764416
[Epoch 21; Iter   130/  172] train: loss: 0.1576158
[Epoch 21; Iter   160/  172] train: loss: 0.1732834
[Epoch 21] ogbg-moltoxcast: 0.722245 val loss: 0.246811
[Epoch 21] ogbg-moltoxcast: 0.727087 test loss: 0.229893
[Epoch 22; Iter    18/  172] train: loss: 0.1262669
[Epoch 22; Iter    48/  172] train: loss: 0.1513914
[Epoch 22; Iter    78/  172] train: loss: 0.1787131
[Epoch 22; Iter   108/  172] train: loss: 0.1626330
[Epoch 22; Iter   138/  172] train: loss: 0.1901335
[Epoch 22; Iter   168/  172] train: loss: 0.2121887
[Epoch 22] ogbg-moltoxcast: 0.719813 val loss: 0.209482
[Epoch 22] ogbg-moltoxcast: 0.717658 test loss: 0.209868
[Epoch 23; Iter    26/  172] train: loss: 0.1736596
[Epoch 23; Iter    56/  172] train: loss: 0.1677458
[Epoch 23; Iter    86/  172] train: loss: 0.1921786
[Epoch 23; Iter   116/  172] train: loss: 0.2338110
[Epoch 23; Iter   146/  172] train: loss: 0.1854558
[Epoch 23] ogbg-moltoxcast: 0.716766 val loss: 0.204962
[Epoch 23] ogbg-moltoxcast: 0.726797 test loss: 0.204436
[Epoch 24; Iter     4/  172] train: loss: 0.1577987
[Epoch 24; Iter    34/  172] train: loss: 0.1619849
[Epoch 24; Iter    64/  172] train: loss: 0.1987950
[Epoch 24; Iter    94/  172] train: loss: 0.2006741
[Epoch 24; Iter   124/  172] train: loss: 0.1984261
[Epoch 24; Iter   154/  172] train: loss: 0.1625554
[Epoch 24] ogbg-moltoxcast: 0.706832 val loss: 0.210580
[Epoch 24] ogbg-moltoxcast: 0.725036 test loss: 0.207732
[Epoch 25; Iter    12/  172] train: loss: 0.1887489
[Epoch 25; Iter    42/  172] train: loss: 0.1048336
[Epoch 25; Iter    72/  172] train: loss: 0.1551074
[Epoch 25; Iter   102/  172] train: loss: 0.1719520
[Epoch 25; Iter   132/  172] train: loss: 0.0985765
[Epoch 25; Iter   162/  172] train: loss: 0.2123660
[Epoch 25] ogbg-moltoxcast: 0.713586 val loss: 0.205144
[Epoch 25] ogbg-moltoxcast: 0.729412 test loss: 0.201914
[Epoch 26; Iter    20/  172] train: loss: 0.1871977
[Epoch 26; Iter    50/  172] train: loss: 0.1463270
[Epoch 26; Iter    80/  172] train: loss: 0.1887361
[Epoch 26; Iter   110/  172] train: loss: 0.1930532
[Epoch 26; Iter   140/  172] train: loss: 0.1503880
[Epoch 26; Iter   170/  172] train: loss: 0.1824853
[Epoch 26] ogbg-moltoxcast: 0.725369 val loss: 0.202761
[Epoch 26] ogbg-moltoxcast: 0.738963 test loss: 0.199350
[Epoch 27; Iter    28/  172] train: loss: 0.1518112
[Epoch 27; Iter    58/  172] train: loss: 0.1238530
[Epoch 27; Iter    88/  172] train: loss: 0.1979619
[Epoch 27; Iter   118/  172] train: loss: 0.2344506
[Epoch 27; Iter   148/  172] train: loss: 0.1492460
[Epoch 27] ogbg-moltoxcast: 0.722097 val loss: 0.202435
[Epoch 27] ogbg-moltoxcast: 0.739776 test loss: 0.198939
[Epoch 28; Iter     6/  172] train: loss: 0.1979319
[Epoch 28; Iter    36/  172] train: loss: 0.2285818
[Epoch 28; Iter    66/  172] train: loss: 0.2257218
[Epoch 28; Iter    96/  172] train: loss: 0.2136052
[Epoch 28; Iter   126/  172] train: loss: 0.1897600
[Epoch 28; Iter   156/  172] train: loss: 0.1190317
[Epoch 28] ogbg-moltoxcast: 0.729150 val loss: 0.203353
[Epoch 28] ogbg-moltoxcast: 0.732240 test loss: 0.205523
[Epoch 29; Iter    14/  172] train: loss: 0.2241187
[Epoch 29; Iter    44/  172] train: loss: 0.1822412
[Epoch 29; Iter    74/  172] train: loss: 0.2071089
[Epoch 29; Iter   104/  172] train: loss: 0.1718036
[Epoch 29; Iter   134/  172] train: loss: 0.2168407
[Epoch 29; Iter   164/  172] train: loss: 0.1347243
[Epoch 29] ogbg-moltoxcast: 0.717442 val loss: 0.206122
[Epoch 29] ogbg-moltoxcast: 0.727131 test loss: 0.206173
[Epoch 30; Iter    22/  172] train: loss: 0.1635125
[Epoch 30; Iter    52/  172] train: loss: 0.1860197
[Epoch 30; Iter    82/  172] train: loss: 0.1286522
[Epoch 30; Iter   112/  172] train: loss: 0.1268658
[Epoch 30; Iter   142/  172] train: loss: 0.1926690
[Epoch 30; Iter   172/  172] train: loss: 0.1603529
[Epoch 30] ogbg-moltoxcast: 0.729078 val loss: 0.202193
[Epoch 30] ogbg-moltoxcast: 0.741202 test loss: 0.200813
[Epoch 31; Iter    30/  172] train: loss: 0.1143099
[Epoch 31; Iter    60/  172] train: loss: 0.1450922
[Epoch 31; Iter    90/  172] train: loss: 0.1692022
[Epoch 31; Iter   120/  172] train: loss: 0.2032206
[Epoch 31; Iter   150/  172] train: loss: 0.1997797
[Epoch 31] ogbg-moltoxcast: 0.724485 val loss: 0.201523
[Epoch 31] ogbg-moltoxcast: 0.737411 test loss: 0.200303
[Epoch 32; Iter     8/  172] train: loss: 0.1218393
[Epoch 32; Iter    38/  172] train: loss: 0.2072993
[Epoch 32; Iter    68/  172] train: loss: 0.1412605
[Epoch 32; Iter    98/  172] train: loss: 0.1725757
[Epoch 32; Iter   128/  172] train: loss: 0.1718919
[Epoch 32; Iter   158/  172] train: loss: 0.1682559
[Epoch 32] ogbg-moltoxcast: 0.725545 val loss: 0.204086
[Epoch 32] ogbg-moltoxcast: 0.741516 test loss: 0.200930
[Epoch 33; Iter    16/  172] train: loss: 0.1767845
[Epoch 33; Iter    46/  172] train: loss: 0.2145574
[Epoch 33; Iter    76/  172] train: loss: 0.1833269
[Epoch 33; Iter   106/  172] train: loss: 0.1641526
[Epoch 33; Iter   136/  172] train: loss: 0.1658624
[Epoch 33; Iter   166/  172] train: loss: 0.1663138
[Epoch 33] ogbg-moltoxcast: 0.727625 val loss: 0.202123
[Epoch 33] ogbg-moltoxcast: 0.735177 test loss: 0.202166
[Epoch 34; Iter    24/  172] train: loss: 0.0918894
[Epoch 34; Iter    54/  172] train: loss: 0.1334522
[Epoch 34; Iter    84/  172] train: loss: 0.2299708
[Epoch 34; Iter   114/  172] train: loss: 0.1238999
[Epoch 34; Iter   144/  172] train: loss: 0.1279171
[Epoch 28; Iter    27/  229] train: loss: 0.2123388
[Epoch 28; Iter    57/  229] train: loss: 0.1310456
[Epoch 28; Iter    87/  229] train: loss: 0.1320830
[Epoch 28; Iter   117/  229] train: loss: 0.1970786
[Epoch 28; Iter   147/  229] train: loss: 0.2023886
[Epoch 28; Iter   177/  229] train: loss: 0.1139895
[Epoch 28; Iter   207/  229] train: loss: 0.1921129
[Epoch 28] ogbg-moltoxcast: 0.713617 val loss: 0.199555
[Epoch 28] ogbg-moltoxcast: 0.736975 test loss: 0.210225
[Epoch 29; Iter     8/  229] train: loss: 0.1806333
[Epoch 29; Iter    38/  229] train: loss: 0.1186937
[Epoch 29; Iter    68/  229] train: loss: 0.2144130
[Epoch 29; Iter    98/  229] train: loss: 0.1935742
[Epoch 29; Iter   128/  229] train: loss: 0.2801820
[Epoch 29; Iter   158/  229] train: loss: 0.1838751
[Epoch 29; Iter   188/  229] train: loss: 0.1970794
[Epoch 29; Iter   218/  229] train: loss: 0.1945129
[Epoch 29] ogbg-moltoxcast: 0.713538 val loss: 0.198196
[Epoch 29] ogbg-moltoxcast: 0.751830 test loss: 0.273095
[Epoch 30; Iter    19/  229] train: loss: 0.1658626
[Epoch 30; Iter    49/  229] train: loss: 0.2035017
[Epoch 30; Iter    79/  229] train: loss: 0.1760739
[Epoch 30; Iter   109/  229] train: loss: 0.1408808
[Epoch 30; Iter   139/  229] train: loss: 0.2497939
[Epoch 30; Iter   169/  229] train: loss: 0.1357169
[Epoch 30; Iter   199/  229] train: loss: 0.1554749
[Epoch 30; Iter   229/  229] train: loss: 0.2263163
[Epoch 30] ogbg-moltoxcast: 0.724682 val loss: 0.195831
[Epoch 30] ogbg-moltoxcast: 0.743836 test loss: 0.244029
[Epoch 31; Iter    30/  229] train: loss: 0.1682001
[Epoch 31; Iter    60/  229] train: loss: 0.1777491
[Epoch 31; Iter    90/  229] train: loss: 0.1130759
[Epoch 31; Iter   120/  229] train: loss: 0.2216077
[Epoch 31; Iter   150/  229] train: loss: 0.1960797
[Epoch 31; Iter   180/  229] train: loss: 0.1828741
[Epoch 31; Iter   210/  229] train: loss: 0.1957636
[Epoch 31] ogbg-moltoxcast: 0.725001 val loss: 0.199316
[Epoch 31] ogbg-moltoxcast: 0.758857 test loss: 0.202841
[Epoch 32; Iter    11/  229] train: loss: 0.1505457
[Epoch 32; Iter    41/  229] train: loss: 0.1423618
[Epoch 32; Iter    71/  229] train: loss: 0.1234756
[Epoch 32; Iter   101/  229] train: loss: 0.2474287
[Epoch 32; Iter   131/  229] train: loss: 0.1976828
[Epoch 32; Iter   161/  229] train: loss: 0.2114815
[Epoch 32; Iter   191/  229] train: loss: 0.2420591
[Epoch 32; Iter   221/  229] train: loss: 0.1938481
[Epoch 32] ogbg-moltoxcast: 0.719415 val loss: 0.202302
[Epoch 32] ogbg-moltoxcast: 0.741397 test loss: 0.209536
[Epoch 33; Iter    22/  229] train: loss: 0.1480123
[Epoch 33; Iter    52/  229] train: loss: 0.1391525
[Epoch 33; Iter    82/  229] train: loss: 0.1519385
[Epoch 33; Iter   112/  229] train: loss: 0.1782521
[Epoch 33; Iter   142/  229] train: loss: 0.1837607
[Epoch 33; Iter   172/  229] train: loss: 0.2489984
[Epoch 33; Iter   202/  229] train: loss: 0.1599930
[Epoch 33] ogbg-moltoxcast: 0.713905 val loss: 0.201374
[Epoch 33] ogbg-moltoxcast: 0.755806 test loss: 0.217497
[Epoch 34; Iter     3/  229] train: loss: 0.1478841
[Epoch 34; Iter    33/  229] train: loss: 0.1370785
[Epoch 34; Iter    63/  229] train: loss: 0.1704349
[Epoch 34; Iter    93/  229] train: loss: 0.1341446
[Epoch 34; Iter   123/  229] train: loss: 0.2184674
[Epoch 34; Iter   153/  229] train: loss: 0.1400159
[Epoch 34; Iter   183/  229] train: loss: 0.1144453
[Epoch 34; Iter   213/  229] train: loss: 0.1200801
[Epoch 34] ogbg-moltoxcast: 0.722644 val loss: 0.199947
[Epoch 34] ogbg-moltoxcast: 0.755739 test loss: 0.214585
[Epoch 35; Iter    14/  229] train: loss: 0.2281733
[Epoch 35; Iter    44/  229] train: loss: 0.1684954
[Epoch 35; Iter    74/  229] train: loss: 0.1628029
[Epoch 35; Iter   104/  229] train: loss: 0.2103097
[Epoch 35; Iter   134/  229] train: loss: 0.2286198
[Epoch 35; Iter   164/  229] train: loss: 0.1665126
[Epoch 35; Iter   194/  229] train: loss: 0.1286416
[Epoch 35; Iter   224/  229] train: loss: 0.2008298
[Epoch 35] ogbg-moltoxcast: 0.710107 val loss: 0.211880
[Epoch 35] ogbg-moltoxcast: 0.756692 test loss: 0.215339
[Epoch 36; Iter    25/  229] train: loss: 0.1649951
[Epoch 36; Iter    55/  229] train: loss: 0.1458975
[Epoch 36; Iter    85/  229] train: loss: 0.1194298
[Epoch 36; Iter   115/  229] train: loss: 0.1322156
[Epoch 36; Iter   145/  229] train: loss: 0.1988059
[Epoch 36; Iter   175/  229] train: loss: 0.1766562
[Epoch 36; Iter   205/  229] train: loss: 0.1796373
[Epoch 36] ogbg-moltoxcast: 0.718629 val loss: 0.200330
[Epoch 36] ogbg-moltoxcast: 0.757339 test loss: 0.215869
[Epoch 37; Iter     6/  229] train: loss: 0.1575470
[Epoch 37; Iter    36/  229] train: loss: 0.1778926
[Epoch 37; Iter    66/  229] train: loss: 0.1278394
[Epoch 37; Iter    96/  229] train: loss: 0.2572378
[Epoch 37; Iter   126/  229] train: loss: 0.1956118
[Epoch 37; Iter   156/  229] train: loss: 0.1764462
[Epoch 37; Iter   186/  229] train: loss: 0.2042276
[Epoch 37; Iter   216/  229] train: loss: 0.1401878
[Epoch 37] ogbg-moltoxcast: 0.720056 val loss: 0.201207
[Epoch 37] ogbg-moltoxcast: 0.762958 test loss: 0.215418
[Epoch 38; Iter    17/  229] train: loss: 0.1743468
[Epoch 38; Iter    47/  229] train: loss: 0.2098635
[Epoch 38; Iter    77/  229] train: loss: 0.1684254
[Epoch 38; Iter   107/  229] train: loss: 0.1824781
[Epoch 38; Iter   137/  229] train: loss: 0.1410720
[Epoch 38; Iter   167/  229] train: loss: 0.1615879
[Epoch 38; Iter   197/  229] train: loss: 0.1509224
[Epoch 38; Iter   227/  229] train: loss: 0.2129214
[Epoch 38] ogbg-moltoxcast: 0.723124 val loss: 0.199709
[Epoch 38] ogbg-moltoxcast: 0.760215 test loss: 0.203823
[Epoch 39; Iter    28/  229] train: loss: 0.1816642
[Epoch 39; Iter    58/  229] train: loss: 0.1395524
[Epoch 39; Iter    88/  229] train: loss: 0.1532233
[Epoch 39; Iter   118/  229] train: loss: 0.1773245
[Epoch 39; Iter   148/  229] train: loss: 0.2198344
[Epoch 39; Iter   178/  229] train: loss: 0.1079180
[Epoch 39; Iter   208/  229] train: loss: 0.1171202
[Epoch 39] ogbg-moltoxcast: 0.722800 val loss: 0.200154
[Epoch 39] ogbg-moltoxcast: 0.762843 test loss: 0.199805
[Epoch 40; Iter     9/  229] train: loss: 0.1868875
[Epoch 40; Iter    39/  229] train: loss: 0.1914821
[Epoch 40; Iter    69/  229] train: loss: 0.1111628
[Epoch 40; Iter    99/  229] train: loss: 0.1400484
[Epoch 40; Iter   129/  229] train: loss: 0.1613061
[Epoch 40; Iter   159/  229] train: loss: 0.2069249
[Epoch 40; Iter   189/  229] train: loss: 0.1726536
[Epoch 40; Iter   219/  229] train: loss: 0.1588306
[Epoch 40] ogbg-moltoxcast: 0.728739 val loss: 0.197737
[Epoch 40] ogbg-moltoxcast: 0.763217 test loss: 0.197397
[Epoch 41; Iter    20/  229] train: loss: 0.1282294
[Epoch 41; Iter    50/  229] train: loss: 0.1598517
[Epoch 41; Iter    80/  229] train: loss: 0.1702895
[Epoch 41; Iter   110/  229] train: loss: 0.1610984
[Epoch 41; Iter   140/  229] train: loss: 0.1802138
[Epoch 41; Iter   170/  229] train: loss: 0.1513725
[Epoch 41; Iter   200/  229] train: loss: 0.2304338
[Epoch 41] ogbg-moltoxcast: 0.723024 val loss: 0.199342
[Epoch 41] ogbg-moltoxcast: 0.758944 test loss: 0.202488
[Epoch 42; Iter     1/  229] train: loss: 0.1736182
[Epoch 42; Iter    31/  229] train: loss: 0.1960765
[Epoch 42; Iter    61/  229] train: loss: 0.1284122
[Epoch 42; Iter    91/  229] train: loss: 0.1831345
[Epoch 42; Iter   121/  229] train: loss: 0.1764013
[Epoch 42; Iter   151/  229] train: loss: 0.1277709
[Epoch 42; Iter   181/  229] train: loss: 0.1602419
[Epoch 42; Iter   211/  229] train: loss: 0.2503167
[Epoch 42] ogbg-moltoxcast: 0.724952 val loss: 0.198128
[Epoch 42] ogbg-moltoxcast: 0.766534 test loss: 0.200677
[Epoch 43; Iter    12/  229] train: loss: 0.1707725
[Epoch 43; Iter    42/  229] train: loss: 0.1756295
[Epoch 43; Iter    72/  229] train: loss: 0.1251211
[Epoch 43; Iter   102/  229] train: loss: 0.1759709
[Epoch 43; Iter   132/  229] train: loss: 0.1363665
[Epoch 43; Iter   162/  229] train: loss: 0.1163175
[Epoch 43; Iter   192/  229] train: loss: 0.1689063
[Epoch 43; Iter   222/  229] train: loss: 0.1144196
[Epoch 43] ogbg-moltoxcast: 0.724510 val loss: 0.202234
[Epoch 43] ogbg-moltoxcast: 0.767698 test loss: 0.200174
[Epoch 28; Iter    27/  229] train: loss: 0.2415606
[Epoch 28; Iter    57/  229] train: loss: 0.1909887
[Epoch 28; Iter    87/  229] train: loss: 0.1215642
[Epoch 28; Iter   117/  229] train: loss: 0.2205214
[Epoch 28; Iter   147/  229] train: loss: 0.1373714
[Epoch 28; Iter   177/  229] train: loss: 0.2013866
[Epoch 28; Iter   207/  229] train: loss: 0.2150583
[Epoch 28] ogbg-moltoxcast: 0.732058 val loss: 0.224629
[Epoch 28] ogbg-moltoxcast: 0.742485 test loss: 0.217161
[Epoch 29; Iter     8/  229] train: loss: 0.1832838
[Epoch 29; Iter    38/  229] train: loss: 0.1292138
[Epoch 29; Iter    68/  229] train: loss: 0.2324947
[Epoch 29; Iter    98/  229] train: loss: 0.1643012
[Epoch 29; Iter   128/  229] train: loss: 0.1795179
[Epoch 29; Iter   158/  229] train: loss: 0.1999809
[Epoch 29; Iter   188/  229] train: loss: 0.1838926
[Epoch 29; Iter   218/  229] train: loss: 0.2042063
[Epoch 29] ogbg-moltoxcast: 0.738779 val loss: 0.194659
[Epoch 29] ogbg-moltoxcast: 0.749435 test loss: 0.210302
[Epoch 30; Iter    19/  229] train: loss: 0.1795394
[Epoch 30; Iter    49/  229] train: loss: 0.1802169
[Epoch 30; Iter    79/  229] train: loss: 0.2096467
[Epoch 30; Iter   109/  229] train: loss: 0.2210712
[Epoch 30; Iter   139/  229] train: loss: 0.1800950
[Epoch 30; Iter   169/  229] train: loss: 0.1501060
[Epoch 30; Iter   199/  229] train: loss: 0.1214059
[Epoch 30; Iter   229/  229] train: loss: 0.1823989
[Epoch 30] ogbg-moltoxcast: 0.736225 val loss: 0.193269
[Epoch 30] ogbg-moltoxcast: 0.751402 test loss: 0.203992
[Epoch 31; Iter    30/  229] train: loss: 0.1793132
[Epoch 31; Iter    60/  229] train: loss: 0.1375707
[Epoch 31; Iter    90/  229] train: loss: 0.1979288
[Epoch 31; Iter   120/  229] train: loss: 0.1412425
[Epoch 31; Iter   150/  229] train: loss: 0.1015399
[Epoch 31; Iter   180/  229] train: loss: 0.1555723
[Epoch 31; Iter   210/  229] train: loss: 0.1716445
[Epoch 31] ogbg-moltoxcast: 0.737684 val loss: 0.195816
[Epoch 31] ogbg-moltoxcast: 0.745495 test loss: 0.209799
[Epoch 32; Iter    11/  229] train: loss: 0.1806262
[Epoch 32; Iter    41/  229] train: loss: 0.1982434
[Epoch 32; Iter    71/  229] train: loss: 0.1682052
[Epoch 32; Iter   101/  229] train: loss: 0.1439107
[Epoch 32; Iter   131/  229] train: loss: 0.1655476
[Epoch 32; Iter   161/  229] train: loss: 0.1486219
[Epoch 32; Iter   191/  229] train: loss: 0.1169127
[Epoch 32; Iter   221/  229] train: loss: 0.2295446
[Epoch 32] ogbg-moltoxcast: 0.743521 val loss: 0.193859
[Epoch 32] ogbg-moltoxcast: 0.745407 test loss: 0.220965
[Epoch 33; Iter    22/  229] train: loss: 0.2314672
[Epoch 33; Iter    52/  229] train: loss: 0.1895188
[Epoch 33; Iter    82/  229] train: loss: 0.1329601
[Epoch 33; Iter   112/  229] train: loss: 0.2723364
[Epoch 33; Iter   142/  229] train: loss: 0.2556904
[Epoch 33; Iter   172/  229] train: loss: 0.1681892
[Epoch 33; Iter   202/  229] train: loss: 0.1927590
[Epoch 33] ogbg-moltoxcast: 0.735237 val loss: 0.195350
[Epoch 33] ogbg-moltoxcast: 0.755613 test loss: 0.207076
[Epoch 34; Iter     3/  229] train: loss: 0.1488274
[Epoch 34; Iter    33/  229] train: loss: 0.1557000
[Epoch 34; Iter    63/  229] train: loss: 0.1784143
[Epoch 34; Iter    93/  229] train: loss: 0.1839911
[Epoch 34; Iter   123/  229] train: loss: 0.2271728
[Epoch 34; Iter   153/  229] train: loss: 0.1665704
[Epoch 34; Iter   183/  229] train: loss: 0.1410296
[Epoch 34; Iter   213/  229] train: loss: 0.1565428
[Epoch 34] ogbg-moltoxcast: 0.742764 val loss: 0.196097
[Epoch 34] ogbg-moltoxcast: 0.752394 test loss: 0.214747
[Epoch 35; Iter    14/  229] train: loss: 0.2254988
[Epoch 35; Iter    44/  229] train: loss: 0.2106622
[Epoch 35; Iter    74/  229] train: loss: 0.1442783
[Epoch 35; Iter   104/  229] train: loss: 0.1717248
[Epoch 35; Iter   134/  229] train: loss: 0.2330936
[Epoch 35; Iter   164/  229] train: loss: 0.1060110
[Epoch 35; Iter   194/  229] train: loss: 0.1520440
[Epoch 35; Iter   224/  229] train: loss: 0.1621104
[Epoch 35] ogbg-moltoxcast: 0.737521 val loss: 0.193562
[Epoch 35] ogbg-moltoxcast: 0.752205 test loss: 0.207827
[Epoch 36; Iter    25/  229] train: loss: 0.1618537
[Epoch 36; Iter    55/  229] train: loss: 0.1353765
[Epoch 36; Iter    85/  229] train: loss: 0.2061780
[Epoch 36; Iter   115/  229] train: loss: 0.1546867
[Epoch 36; Iter   145/  229] train: loss: 0.1470502
[Epoch 36; Iter   175/  229] train: loss: 0.1400612
[Epoch 36; Iter   205/  229] train: loss: 0.1572949
[Epoch 36] ogbg-moltoxcast: 0.738106 val loss: 0.197596
[Epoch 36] ogbg-moltoxcast: 0.756069 test loss: 0.218455
[Epoch 37; Iter     6/  229] train: loss: 0.2004643
[Epoch 37; Iter    36/  229] train: loss: 0.1557699
[Epoch 37; Iter    66/  229] train: loss: 0.2059626
[Epoch 37; Iter    96/  229] train: loss: 0.1590205
[Epoch 37; Iter   126/  229] train: loss: 0.1325027
[Epoch 37; Iter   156/  229] train: loss: 0.1561776
[Epoch 37; Iter   186/  229] train: loss: 0.2545962
[Epoch 37; Iter   216/  229] train: loss: 0.1387811
[Epoch 37] ogbg-moltoxcast: 0.741395 val loss: 0.197491
[Epoch 37] ogbg-moltoxcast: 0.756392 test loss: 0.203271
[Epoch 38; Iter    17/  229] train: loss: 0.1372439
[Epoch 38; Iter    47/  229] train: loss: 0.1136573
[Epoch 38; Iter    77/  229] train: loss: 0.1662791
[Epoch 38; Iter   107/  229] train: loss: 0.1863027
[Epoch 38; Iter   137/  229] train: loss: 0.2093943
[Epoch 38; Iter   167/  229] train: loss: 0.1840106
[Epoch 38; Iter   197/  229] train: loss: 0.1806291
[Epoch 38; Iter   227/  229] train: loss: 0.2278962
[Epoch 38] ogbg-moltoxcast: 0.728495 val loss: 0.201731
[Epoch 38] ogbg-moltoxcast: 0.743186 test loss: 0.211582
[Epoch 39; Iter    28/  229] train: loss: 0.1719170
[Epoch 39; Iter    58/  229] train: loss: 0.1546940
[Epoch 39; Iter    88/  229] train: loss: 0.2527489
[Epoch 39; Iter   118/  229] train: loss: 0.1539826
[Epoch 39; Iter   148/  229] train: loss: 0.2484370
[Epoch 39; Iter   178/  229] train: loss: 0.1618164
[Epoch 39; Iter   208/  229] train: loss: 0.2283484
[Epoch 39] ogbg-moltoxcast: 0.735106 val loss: 0.201792
[Epoch 39] ogbg-moltoxcast: 0.744376 test loss: 0.214515
[Epoch 40; Iter     9/  229] train: loss: 0.1755751
[Epoch 40; Iter    39/  229] train: loss: 0.1700796
[Epoch 40; Iter    69/  229] train: loss: 0.2067866
[Epoch 40; Iter    99/  229] train: loss: 0.1652211
[Epoch 40; Iter   129/  229] train: loss: 0.1508421
[Epoch 40; Iter   159/  229] train: loss: 0.1567968
[Epoch 40; Iter   189/  229] train: loss: 0.2204715
[Epoch 40; Iter   219/  229] train: loss: 0.1409227
[Epoch 40] ogbg-moltoxcast: 0.744962 val loss: 0.195774
[Epoch 40] ogbg-moltoxcast: 0.752429 test loss: 0.207411
[Epoch 41; Iter    20/  229] train: loss: 0.2202635
[Epoch 41; Iter    50/  229] train: loss: 0.1798673
[Epoch 41; Iter    80/  229] train: loss: 0.1843130
[Epoch 41; Iter   110/  229] train: loss: 0.1424791
[Epoch 41; Iter   140/  229] train: loss: 0.1672240
[Epoch 41; Iter   170/  229] train: loss: 0.1551560
[Epoch 41; Iter   200/  229] train: loss: 0.1822299
[Epoch 41] ogbg-moltoxcast: 0.739789 val loss: 0.198642
[Epoch 41] ogbg-moltoxcast: 0.754306 test loss: 0.207383
[Epoch 42; Iter     1/  229] train: loss: 0.2040143
[Epoch 42; Iter    31/  229] train: loss: 0.2041239
[Epoch 42; Iter    61/  229] train: loss: 0.1446344
[Epoch 42; Iter    91/  229] train: loss: 0.1240458
[Epoch 42; Iter   121/  229] train: loss: 0.1849592
[Epoch 42; Iter   151/  229] train: loss: 0.2091934
[Epoch 42; Iter   181/  229] train: loss: 0.2322527
[Epoch 42; Iter   211/  229] train: loss: 0.1607764
[Epoch 42] ogbg-moltoxcast: 0.738511 val loss: 0.200186
[Epoch 42] ogbg-moltoxcast: 0.756456 test loss: 0.218127
[Epoch 43; Iter    12/  229] train: loss: 0.1090113
[Epoch 43; Iter    42/  229] train: loss: 0.1679756
[Epoch 43; Iter    72/  229] train: loss: 0.1202376
[Epoch 43; Iter   102/  229] train: loss: 0.1711136
[Epoch 43; Iter   132/  229] train: loss: 0.1895007
[Epoch 43; Iter   162/  229] train: loss: 0.2266485
[Epoch 43; Iter   192/  229] train: loss: 0.2174229
[Epoch 43; Iter   222/  229] train: loss: 0.1124293
[Epoch 43] ogbg-moltoxcast: 0.736114 val loss: 0.199465
[Epoch 43] ogbg-moltoxcast: 0.751318 test loss: 0.220945
[Epoch 28; Iter    27/  229] train: loss: 0.2453165
[Epoch 28; Iter    57/  229] train: loss: 0.1631795
[Epoch 28; Iter    87/  229] train: loss: 0.2302922
[Epoch 28; Iter   117/  229] train: loss: 0.1405394
[Epoch 28; Iter   147/  229] train: loss: 0.1505539
[Epoch 28; Iter   177/  229] train: loss: 0.1455555
[Epoch 28; Iter   207/  229] train: loss: 0.1275628
[Epoch 28] ogbg-moltoxcast: 0.711943 val loss: 0.197422
[Epoch 28] ogbg-moltoxcast: 0.742691 test loss: 0.211153
[Epoch 29; Iter     8/  229] train: loss: 0.1677352
[Epoch 29; Iter    38/  229] train: loss: 0.1836438
[Epoch 29; Iter    68/  229] train: loss: 0.2347297
[Epoch 29; Iter    98/  229] train: loss: 0.2003552
[Epoch 29; Iter   128/  229] train: loss: 0.2127963
[Epoch 29; Iter   158/  229] train: loss: 0.1828347
[Epoch 29; Iter   188/  229] train: loss: 0.1852585
[Epoch 29; Iter   218/  229] train: loss: 0.1656612
[Epoch 29] ogbg-moltoxcast: 0.719394 val loss: 0.197147
[Epoch 29] ogbg-moltoxcast: 0.749362 test loss: 0.207877
[Epoch 30; Iter    19/  229] train: loss: 0.0996949
[Epoch 30; Iter    49/  229] train: loss: 0.2010912
[Epoch 30; Iter    79/  229] train: loss: 0.2160952
[Epoch 30; Iter   109/  229] train: loss: 0.1591446
[Epoch 30; Iter   139/  229] train: loss: 0.1421800
[Epoch 30; Iter   169/  229] train: loss: 0.1196208
[Epoch 30; Iter   199/  229] train: loss: 0.1939901
[Epoch 30; Iter   229/  229] train: loss: 0.1064276
[Epoch 30] ogbg-moltoxcast: 0.719979 val loss: 0.198357
[Epoch 30] ogbg-moltoxcast: 0.749957 test loss: 0.208876
[Epoch 31; Iter    30/  229] train: loss: 0.1386811
[Epoch 31; Iter    60/  229] train: loss: 0.1303268
[Epoch 31; Iter    90/  229] train: loss: 0.2437190
[Epoch 31; Iter   120/  229] train: loss: 0.1994692
[Epoch 31; Iter   150/  229] train: loss: 0.1127827
[Epoch 31; Iter   180/  229] train: loss: 0.1417885
[Epoch 31; Iter   210/  229] train: loss: 0.1967027
[Epoch 31] ogbg-moltoxcast: 0.723419 val loss: 0.196391
[Epoch 31] ogbg-moltoxcast: 0.755511 test loss: 0.204433
[Epoch 32; Iter    11/  229] train: loss: 0.1843213
[Epoch 32; Iter    41/  229] train: loss: 0.1561898
[Epoch 32; Iter    71/  229] train: loss: 0.1193577
[Epoch 32; Iter   101/  229] train: loss: 0.1568305
[Epoch 32; Iter   131/  229] train: loss: 0.2421482
[Epoch 32; Iter   161/  229] train: loss: 0.1836082
[Epoch 32; Iter   191/  229] train: loss: 0.1882004
[Epoch 32; Iter   221/  229] train: loss: 0.1609663
[Epoch 32] ogbg-moltoxcast: 0.730384 val loss: 0.195708
[Epoch 32] ogbg-moltoxcast: 0.750372 test loss: 0.208624
[Epoch 33; Iter    22/  229] train: loss: 0.1769027
[Epoch 33; Iter    52/  229] train: loss: 0.2620241
[Epoch 33; Iter    82/  229] train: loss: 0.1602378
[Epoch 33; Iter   112/  229] train: loss: 0.1619191
[Epoch 33; Iter   142/  229] train: loss: 0.1458977
[Epoch 33; Iter   172/  229] train: loss: 0.2167130
[Epoch 33; Iter   202/  229] train: loss: 0.1659443
[Epoch 33] ogbg-moltoxcast: 0.728259 val loss: 0.196633
[Epoch 33] ogbg-moltoxcast: 0.748981 test loss: 0.206698
[Epoch 34; Iter     3/  229] train: loss: 0.2190702
[Epoch 34; Iter    33/  229] train: loss: 0.1603998
[Epoch 34; Iter    63/  229] train: loss: 0.1841654
[Epoch 34; Iter    93/  229] train: loss: 0.2717784
[Epoch 34; Iter   123/  229] train: loss: 0.1585307
[Epoch 34; Iter   153/  229] train: loss: 0.2067689
[Epoch 34; Iter   183/  229] train: loss: 0.1575315
[Epoch 34; Iter   213/  229] train: loss: 0.2071926
[Epoch 34] ogbg-moltoxcast: 0.720390 val loss: 0.200211
[Epoch 34] ogbg-moltoxcast: 0.740459 test loss: 0.208363
[Epoch 35; Iter    14/  229] train: loss: 0.1693969
[Epoch 35; Iter    44/  229] train: loss: 0.1629809
[Epoch 35; Iter    74/  229] train: loss: 0.2517747
[Epoch 35; Iter   104/  229] train: loss: 0.2240582
[Epoch 35; Iter   134/  229] train: loss: 0.1910002
[Epoch 35; Iter   164/  229] train: loss: 0.1520845
[Epoch 35; Iter   194/  229] train: loss: 0.1735635
[Epoch 35; Iter   224/  229] train: loss: 0.2548969
[Epoch 35] ogbg-moltoxcast: 0.731065 val loss: 0.195754
[Epoch 35] ogbg-moltoxcast: 0.752619 test loss: 0.204067
[Epoch 36; Iter    25/  229] train: loss: 0.1988862
[Epoch 36; Iter    55/  229] train: loss: 0.1184894
[Epoch 36; Iter    85/  229] train: loss: 0.1073617
[Epoch 36; Iter   115/  229] train: loss: 0.1743461
[Epoch 36; Iter   145/  229] train: loss: 0.2121622
[Epoch 36; Iter   175/  229] train: loss: 0.1489254
[Epoch 36; Iter   205/  229] train: loss: 0.1498694
[Epoch 36] ogbg-moltoxcast: 0.734602 val loss: 0.196861
[Epoch 36] ogbg-moltoxcast: 0.747369 test loss: 0.209046
[Epoch 37; Iter     6/  229] train: loss: 0.1209715
[Epoch 37; Iter    36/  229] train: loss: 0.2604312
[Epoch 37; Iter    66/  229] train: loss: 0.1814006
[Epoch 37; Iter    96/  229] train: loss: 0.2210315
[Epoch 37; Iter   126/  229] train: loss: 0.1601607
[Epoch 37; Iter   156/  229] train: loss: 0.1627222
[Epoch 37; Iter   186/  229] train: loss: 0.1517467
[Epoch 37; Iter   216/  229] train: loss: 0.2259762
[Epoch 37] ogbg-moltoxcast: 0.728006 val loss: 0.197104
[Epoch 37] ogbg-moltoxcast: 0.751568 test loss: 0.206862
[Epoch 38; Iter    17/  229] train: loss: 0.1208564
[Epoch 38; Iter    47/  229] train: loss: 0.1444413
[Epoch 38; Iter    77/  229] train: loss: 0.1368633
[Epoch 38; Iter   107/  229] train: loss: 0.1088743
[Epoch 38; Iter   137/  229] train: loss: 0.1704998
[Epoch 38; Iter   167/  229] train: loss: 0.1568686
[Epoch 38; Iter   197/  229] train: loss: 0.2406940
[Epoch 38; Iter   227/  229] train: loss: 0.1792702
[Epoch 38] ogbg-moltoxcast: 0.729380 val loss: 0.196448
[Epoch 38] ogbg-moltoxcast: 0.743446 test loss: 0.208058
[Epoch 39; Iter    28/  229] train: loss: 0.1725118
[Epoch 39; Iter    58/  229] train: loss: 0.1446382
[Epoch 39; Iter    88/  229] train: loss: 0.1045171
[Epoch 39; Iter   118/  229] train: loss: 0.1138670
[Epoch 39; Iter   148/  229] train: loss: 0.2164638
[Epoch 39; Iter   178/  229] train: loss: 0.2100412
[Epoch 39; Iter   208/  229] train: loss: 0.1673792
[Epoch 39] ogbg-moltoxcast: 0.731787 val loss: 0.199067
[Epoch 39] ogbg-moltoxcast: 0.749827 test loss: 0.206183
[Epoch 40; Iter     9/  229] train: loss: 0.1639962
[Epoch 40; Iter    39/  229] train: loss: 0.1684155
[Epoch 40; Iter    69/  229] train: loss: 0.1562356
[Epoch 40; Iter    99/  229] train: loss: 0.1493376
[Epoch 40; Iter   129/  229] train: loss: 0.2247429
[Epoch 40; Iter   159/  229] train: loss: 0.1676400
[Epoch 40; Iter   189/  229] train: loss: 0.1593330
[Epoch 40; Iter   219/  229] train: loss: 0.1660340
[Epoch 40] ogbg-moltoxcast: 0.734894 val loss: 0.194461
[Epoch 40] ogbg-moltoxcast: 0.750169 test loss: 0.205292
[Epoch 41; Iter    20/  229] train: loss: 0.1609474
[Epoch 41; Iter    50/  229] train: loss: 0.1671069
[Epoch 41; Iter    80/  229] train: loss: 0.1920936
[Epoch 41; Iter   110/  229] train: loss: 0.1528238
[Epoch 41; Iter   140/  229] train: loss: 0.1550711
[Epoch 41; Iter   170/  229] train: loss: 0.2123741
[Epoch 41; Iter   200/  229] train: loss: 0.2004631
[Epoch 41] ogbg-moltoxcast: 0.733711 val loss: 0.194286
[Epoch 41] ogbg-moltoxcast: 0.753716 test loss: 0.317089
[Epoch 42; Iter     1/  229] train: loss: 0.1338799
[Epoch 42; Iter    31/  229] train: loss: 0.1738655
[Epoch 42; Iter    61/  229] train: loss: 0.1816754
[Epoch 42; Iter    91/  229] train: loss: 0.1620951
[Epoch 42; Iter   121/  229] train: loss: 0.1515587
[Epoch 42; Iter   151/  229] train: loss: 0.1571614
[Epoch 42; Iter   181/  229] train: loss: 0.1772320
[Epoch 42; Iter   211/  229] train: loss: 0.1284039
[Epoch 42] ogbg-moltoxcast: 0.732440 val loss: 0.200861
[Epoch 42] ogbg-moltoxcast: 0.760008 test loss: 0.207783
[Epoch 43; Iter    12/  229] train: loss: 0.1372835
[Epoch 43; Iter    42/  229] train: loss: 0.2608195
[Epoch 43; Iter    72/  229] train: loss: 0.1530266
[Epoch 43; Iter   102/  229] train: loss: 0.1559993
[Epoch 43; Iter   132/  229] train: loss: 0.1348854
[Epoch 43; Iter   162/  229] train: loss: 0.1227642
[Epoch 43; Iter   192/  229] train: loss: 0.1939182
[Epoch 43; Iter   222/  229] train: loss: 0.2180848
[Epoch 43] ogbg-moltoxcast: 0.732682 val loss: 0.195734
[Epoch 43] ogbg-moltoxcast: 0.753151 test loss: 0.206687
[Epoch 30] ogbg-moltoxcast: 0.735402 test loss: 0.210827
[Epoch 31; Iter    30/  201] train: loss: 0.1387924
[Epoch 31; Iter    60/  201] train: loss: 0.1570594
[Epoch 31; Iter    90/  201] train: loss: 0.1673837
[Epoch 31; Iter   120/  201] train: loss: 0.2417463
[Epoch 31; Iter   150/  201] train: loss: 0.1553139
[Epoch 31; Iter   180/  201] train: loss: 0.1709580
[Epoch 31] ogbg-moltoxcast: 0.720980 val loss: 0.208646
[Epoch 31] ogbg-moltoxcast: 0.736463 test loss: 0.208735
[Epoch 32; Iter     9/  201] train: loss: 0.1238462
[Epoch 32; Iter    39/  201] train: loss: 0.1922400
[Epoch 32; Iter    69/  201] train: loss: 0.2182525
[Epoch 32; Iter    99/  201] train: loss: 0.1440999
[Epoch 32; Iter   129/  201] train: loss: 0.1665016
[Epoch 32; Iter   159/  201] train: loss: 0.2002144
[Epoch 32; Iter   189/  201] train: loss: 0.1553599
[Epoch 32] ogbg-moltoxcast: 0.719412 val loss: 0.210165
[Epoch 32] ogbg-moltoxcast: 0.745712 test loss: 0.206225
[Epoch 33; Iter    18/  201] train: loss: 0.2011228
[Epoch 33; Iter    48/  201] train: loss: 0.1755971
[Epoch 33; Iter    78/  201] train: loss: 0.1614475
[Epoch 33; Iter   108/  201] train: loss: 0.1740763
[Epoch 33; Iter   138/  201] train: loss: 0.1504299
[Epoch 33; Iter   168/  201] train: loss: 0.1857509
[Epoch 33; Iter   198/  201] train: loss: 0.2000927
[Epoch 33] ogbg-moltoxcast: 0.713848 val loss: 0.209681
[Epoch 33] ogbg-moltoxcast: 0.733147 test loss: 0.209934
[Epoch 34; Iter    27/  201] train: loss: 0.1531012
[Epoch 34; Iter    57/  201] train: loss: 0.1322354
[Epoch 34; Iter    87/  201] train: loss: 0.1172946
[Epoch 34; Iter   117/  201] train: loss: 0.2235804
[Epoch 34; Iter   147/  201] train: loss: 0.1272726
[Epoch 34; Iter   177/  201] train: loss: 0.1999546
[Epoch 34] ogbg-moltoxcast: 0.721542 val loss: 0.208185
[Epoch 34] ogbg-moltoxcast: 0.738033 test loss: 0.264169
[Epoch 35; Iter     6/  201] train: loss: 0.1720517
[Epoch 35; Iter    36/  201] train: loss: 0.2105410
[Epoch 35; Iter    66/  201] train: loss: 0.1264613
[Epoch 35; Iter    96/  201] train: loss: 0.2187997
[Epoch 35; Iter   126/  201] train: loss: 0.1476994
[Epoch 35; Iter   156/  201] train: loss: 0.2623315
[Epoch 35; Iter   186/  201] train: loss: 0.2042812
[Epoch 35] ogbg-moltoxcast: 0.714760 val loss: 0.209308
[Epoch 35] ogbg-moltoxcast: 0.729012 test loss: 0.211632
[Epoch 36; Iter    15/  201] train: loss: 0.1244492
[Epoch 36; Iter    45/  201] train: loss: 0.2039998
[Epoch 36; Iter    75/  201] train: loss: 0.1425640
[Epoch 36; Iter   105/  201] train: loss: 0.1605100
[Epoch 36; Iter   135/  201] train: loss: 0.1792903
[Epoch 36; Iter   165/  201] train: loss: 0.1391070
[Epoch 36; Iter   195/  201] train: loss: 0.1595620
[Epoch 36] ogbg-moltoxcast: 0.736536 val loss: 0.202757
[Epoch 36] ogbg-moltoxcast: 0.746913 test loss: 0.201965
[Epoch 37; Iter    24/  201] train: loss: 0.1551678
[Epoch 37; Iter    54/  201] train: loss: 0.1761185
[Epoch 37; Iter    84/  201] train: loss: 0.2127348
[Epoch 37; Iter   114/  201] train: loss: 0.1637622
[Epoch 37; Iter   144/  201] train: loss: 0.1543275
[Epoch 37; Iter   174/  201] train: loss: 0.1326635
[Epoch 37] ogbg-moltoxcast: 0.733400 val loss: 0.202543
[Epoch 37] ogbg-moltoxcast: 0.748241 test loss: 0.201472
[Epoch 38; Iter     3/  201] train: loss: 0.1966441
[Epoch 38; Iter    33/  201] train: loss: 0.1479943
[Epoch 38; Iter    63/  201] train: loss: 0.1900513
[Epoch 38; Iter    93/  201] train: loss: 0.0846517
[Epoch 38; Iter   123/  201] train: loss: 0.2591664
[Epoch 38; Iter   153/  201] train: loss: 0.1238515
[Epoch 38; Iter   183/  201] train: loss: 0.1358756
[Epoch 38] ogbg-moltoxcast: 0.739270 val loss: 0.202837
[Epoch 38] ogbg-moltoxcast: 0.752508 test loss: 0.201206
[Epoch 39; Iter    12/  201] train: loss: 0.2473427
[Epoch 39; Iter    42/  201] train: loss: 0.1785029
[Epoch 39; Iter    72/  201] train: loss: 0.1515397
[Epoch 39; Iter   102/  201] train: loss: 0.1679248
[Epoch 39; Iter   132/  201] train: loss: 0.1496385
[Epoch 39; Iter   162/  201] train: loss: 0.2077535
[Epoch 39; Iter   192/  201] train: loss: 0.1672090
[Epoch 39] ogbg-moltoxcast: 0.731612 val loss: 0.203730
[Epoch 39] ogbg-moltoxcast: 0.744777 test loss: 0.204151
[Epoch 40; Iter    21/  201] train: loss: 0.1311107
[Epoch 40; Iter    51/  201] train: loss: 0.1650316
[Epoch 40; Iter    81/  201] train: loss: 0.1743323
[Epoch 40; Iter   111/  201] train: loss: 0.1613635
[Epoch 40; Iter   141/  201] train: loss: 0.1430483
[Epoch 40; Iter   171/  201] train: loss: 0.1903545
[Epoch 40; Iter   201/  201] train: loss: 0.1123506
[Epoch 40] ogbg-moltoxcast: 0.736051 val loss: 0.205194
[Epoch 40] ogbg-moltoxcast: 0.748700 test loss: 0.207644
[Epoch 41; Iter    30/  201] train: loss: 0.1944095
[Epoch 41; Iter    60/  201] train: loss: 0.2725660
[Epoch 41; Iter    90/  201] train: loss: 0.1719589
[Epoch 41; Iter   120/  201] train: loss: 0.1700456
[Epoch 41; Iter   150/  201] train: loss: 0.0982435
[Epoch 41; Iter   180/  201] train: loss: 0.1954997
[Epoch 41] ogbg-moltoxcast: 0.736591 val loss: 0.205938
[Epoch 41] ogbg-moltoxcast: 0.743509 test loss: 0.212528
[Epoch 42; Iter     9/  201] train: loss: 0.1675985
[Epoch 42; Iter    39/  201] train: loss: 0.1719237
[Epoch 42; Iter    69/  201] train: loss: 0.1643331
[Epoch 42; Iter    99/  201] train: loss: 0.1825150
[Epoch 42; Iter   129/  201] train: loss: 0.1985290
[Epoch 42; Iter   159/  201] train: loss: 0.2269946
[Epoch 42; Iter   189/  201] train: loss: 0.1566949
[Epoch 42] ogbg-moltoxcast: 0.738545 val loss: 0.224980
[Epoch 42] ogbg-moltoxcast: 0.746552 test loss: 0.314471
[Epoch 43; Iter    18/  201] train: loss: 0.1801644
[Epoch 43; Iter    48/  201] train: loss: 0.2454087
[Epoch 43; Iter    78/  201] train: loss: 0.1163400
[Epoch 43; Iter   108/  201] train: loss: 0.1880542
[Epoch 43; Iter   138/  201] train: loss: 0.2502991
[Epoch 43; Iter   168/  201] train: loss: 0.1650684
[Epoch 43; Iter   198/  201] train: loss: 0.1859723
[Epoch 43] ogbg-moltoxcast: 0.739753 val loss: 0.202705
[Epoch 43] ogbg-moltoxcast: 0.750257 test loss: 0.202321
[Epoch 44; Iter    27/  201] train: loss: 0.1381041
[Epoch 44; Iter    57/  201] train: loss: 0.1677055
[Epoch 44; Iter    87/  201] train: loss: 0.2081949
[Epoch 44; Iter   117/  201] train: loss: 0.1128325
[Epoch 44; Iter   147/  201] train: loss: 0.0862483
[Epoch 44; Iter   177/  201] train: loss: 0.2057102
[Epoch 44] ogbg-moltoxcast: 0.732996 val loss: 0.217111
[Epoch 44] ogbg-moltoxcast: 0.746503 test loss: 0.233293
[Epoch 45; Iter     6/  201] train: loss: 0.1507338
[Epoch 45; Iter    36/  201] train: loss: 0.1742996
[Epoch 45; Iter    66/  201] train: loss: 0.1873515
[Epoch 45; Iter    96/  201] train: loss: 0.1811532
[Epoch 45; Iter   126/  201] train: loss: 0.1850898
[Epoch 45; Iter   156/  201] train: loss: 0.2409282
[Epoch 45; Iter   186/  201] train: loss: 0.1154767
[Epoch 45] ogbg-moltoxcast: 0.731671 val loss: 0.204309
[Epoch 45] ogbg-moltoxcast: 0.745749 test loss: 0.203197
[Epoch 46; Iter    15/  201] train: loss: 0.1575647
[Epoch 46; Iter    45/  201] train: loss: 0.1933684
[Epoch 46; Iter    75/  201] train: loss: 0.1862142
[Epoch 46; Iter   105/  201] train: loss: 0.1523203
[Epoch 46; Iter   135/  201] train: loss: 0.1526675
[Epoch 46; Iter   165/  201] train: loss: 0.1465510
[Epoch 46; Iter   195/  201] train: loss: 0.1398434
[Epoch 46] ogbg-moltoxcast: 0.740553 val loss: 0.213956
[Epoch 46] ogbg-moltoxcast: 0.748658 test loss: 0.216903
[Epoch 47; Iter    24/  201] train: loss: 0.1449416
[Epoch 47; Iter    54/  201] train: loss: 0.1003806
[Epoch 47; Iter    84/  201] train: loss: 0.1940265
[Epoch 47; Iter   114/  201] train: loss: 0.1371924
[Epoch 47; Iter   144/  201] train: loss: 0.1182270
[Epoch 47; Iter   174/  201] train: loss: 0.1606038
[Epoch 47] ogbg-moltoxcast: 0.734926 val loss: 0.204976
[Epoch 47] ogbg-moltoxcast: 0.748435 test loss: 0.204286
[Epoch 48; Iter     3/  201] train: loss: 0.1873948
[Epoch 48; Iter    33/  201] train: loss: 0.2313524
[Epoch 48; Iter    63/  201] train: loss: 0.1506339
[Epoch 48; Iter    93/  201] train: loss: 0.1720423
[Epoch 48; Iter   123/  201] train: loss: 0.2137583
[Epoch 48; Iter   153/  201] train: loss: 0.1626815
[Epoch 30] ogbg-moltoxcast: 0.750043 test loss: 0.200208
[Epoch 31; Iter    30/  201] train: loss: 0.2564162
[Epoch 31; Iter    60/  201] train: loss: 0.1654306
[Epoch 31; Iter    90/  201] train: loss: 0.2441383
[Epoch 31; Iter   120/  201] train: loss: 0.1757768
[Epoch 31; Iter   150/  201] train: loss: 0.1542424
[Epoch 31; Iter   180/  201] train: loss: 0.1821187
[Epoch 31] ogbg-moltoxcast: 0.722666 val loss: 0.207060
[Epoch 31] ogbg-moltoxcast: 0.733821 test loss: 0.206217
[Epoch 32; Iter     9/  201] train: loss: 0.1338828
[Epoch 32; Iter    39/  201] train: loss: 0.1508937
[Epoch 32; Iter    69/  201] train: loss: 0.1504089
[Epoch 32; Iter    99/  201] train: loss: 0.2205302
[Epoch 32; Iter   129/  201] train: loss: 0.1413101
[Epoch 32; Iter   159/  201] train: loss: 0.1376598
[Epoch 32; Iter   189/  201] train: loss: 0.1553534
[Epoch 32] ogbg-moltoxcast: 0.729395 val loss: 0.205924
[Epoch 32] ogbg-moltoxcast: 0.738228 test loss: 0.207100
[Epoch 33; Iter    18/  201] train: loss: 0.2517997
[Epoch 33; Iter    48/  201] train: loss: 0.1641157
[Epoch 33; Iter    78/  201] train: loss: 0.1671127
[Epoch 33; Iter   108/  201] train: loss: 0.1363935
[Epoch 33; Iter   138/  201] train: loss: 0.2817468
[Epoch 33; Iter   168/  201] train: loss: 0.1087847
[Epoch 33; Iter   198/  201] train: loss: 0.1630031
[Epoch 33] ogbg-moltoxcast: 0.734158 val loss: 0.207787
[Epoch 33] ogbg-moltoxcast: 0.736381 test loss: 0.206954
[Epoch 34; Iter    27/  201] train: loss: 0.1913235
[Epoch 34; Iter    57/  201] train: loss: 0.1726874
[Epoch 34; Iter    87/  201] train: loss: 0.1101692
[Epoch 34; Iter   117/  201] train: loss: 0.1314774
[Epoch 34; Iter   147/  201] train: loss: 0.1345308
[Epoch 34; Iter   177/  201] train: loss: 0.1983031
[Epoch 34] ogbg-moltoxcast: 0.718738 val loss: 0.207221
[Epoch 34] ogbg-moltoxcast: 0.740275 test loss: 0.208005
[Epoch 35; Iter     6/  201] train: loss: 0.1968389
[Epoch 35; Iter    36/  201] train: loss: 0.1517719
[Epoch 35; Iter    66/  201] train: loss: 0.1231291
[Epoch 35; Iter    96/  201] train: loss: 0.1173142
[Epoch 35; Iter   126/  201] train: loss: 0.1456900
[Epoch 35; Iter   156/  201] train: loss: 0.1849975
[Epoch 35; Iter   186/  201] train: loss: 0.1783375
[Epoch 35] ogbg-moltoxcast: 0.729055 val loss: 0.202554
[Epoch 35] ogbg-moltoxcast: 0.745525 test loss: 0.202016
[Epoch 36; Iter    15/  201] train: loss: 0.1028830
[Epoch 36; Iter    45/  201] train: loss: 0.1502213
[Epoch 36; Iter    75/  201] train: loss: 0.1984501
[Epoch 36; Iter   105/  201] train: loss: 0.1310746
[Epoch 36; Iter   135/  201] train: loss: 0.1166582
[Epoch 36; Iter   165/  201] train: loss: 0.2003545
[Epoch 36; Iter   195/  201] train: loss: 0.1260222
[Epoch 36] ogbg-moltoxcast: 0.726746 val loss: 0.206017
[Epoch 36] ogbg-moltoxcast: 0.752935 test loss: 0.203001
[Epoch 37; Iter    24/  201] train: loss: 0.1244673
[Epoch 37; Iter    54/  201] train: loss: 0.1644592
[Epoch 37; Iter    84/  201] train: loss: 0.1864250
[Epoch 37; Iter   114/  201] train: loss: 0.1865421
[Epoch 37; Iter   144/  201] train: loss: 0.2093656
[Epoch 37; Iter   174/  201] train: loss: 0.1959240
[Epoch 37] ogbg-moltoxcast: 0.718203 val loss: 0.211773
[Epoch 37] ogbg-moltoxcast: 0.751543 test loss: 0.206741
[Epoch 38; Iter     3/  201] train: loss: 0.1976027
[Epoch 38; Iter    33/  201] train: loss: 0.1913651
[Epoch 38; Iter    63/  201] train: loss: 0.1439283
[Epoch 38; Iter    93/  201] train: loss: 0.1707931
[Epoch 38; Iter   123/  201] train: loss: 0.1637421
[Epoch 38; Iter   153/  201] train: loss: 0.1398689
[Epoch 38; Iter   183/  201] train: loss: 0.1886474
[Epoch 38] ogbg-moltoxcast: 0.734320 val loss: 0.203468
[Epoch 38] ogbg-moltoxcast: 0.751376 test loss: 0.203692
[Epoch 39; Iter    12/  201] train: loss: 0.1291778
[Epoch 39; Iter    42/  201] train: loss: 0.1509114
[Epoch 39; Iter    72/  201] train: loss: 0.1694760
[Epoch 39; Iter   102/  201] train: loss: 0.1579876
[Epoch 39; Iter   132/  201] train: loss: 0.1171877
[Epoch 39; Iter   162/  201] train: loss: 0.1624778
[Epoch 39; Iter   192/  201] train: loss: 0.1581223
[Epoch 39] ogbg-moltoxcast: 0.736141 val loss: 0.203500
[Epoch 39] ogbg-moltoxcast: 0.747302 test loss: 0.207907
[Epoch 40; Iter    21/  201] train: loss: 0.1930439
[Epoch 40; Iter    51/  201] train: loss: 0.1593126
[Epoch 40; Iter    81/  201] train: loss: 0.1821777
[Epoch 40; Iter   111/  201] train: loss: 0.1727981
[Epoch 40; Iter   141/  201] train: loss: 0.1506827
[Epoch 40; Iter   171/  201] train: loss: 0.1796651
[Epoch 40; Iter   201/  201] train: loss: 0.1266412
[Epoch 40] ogbg-moltoxcast: 0.735342 val loss: 0.202572
[Epoch 40] ogbg-moltoxcast: 0.750491 test loss: 0.202301
[Epoch 41; Iter    30/  201] train: loss: 0.2335447
[Epoch 41; Iter    60/  201] train: loss: 0.1130546
[Epoch 41; Iter    90/  201] train: loss: 0.1101547
[Epoch 41; Iter   120/  201] train: loss: 0.1975171
[Epoch 41; Iter   150/  201] train: loss: 0.2253903
[Epoch 41; Iter   180/  201] train: loss: 0.2349114
[Epoch 41] ogbg-moltoxcast: 0.735973 val loss: 0.204378
[Epoch 41] ogbg-moltoxcast: 0.753175 test loss: 0.203953
[Epoch 42; Iter     9/  201] train: loss: 0.1308333
[Epoch 42; Iter    39/  201] train: loss: 0.1416959
[Epoch 42; Iter    69/  201] train: loss: 0.1391452
[Epoch 42; Iter    99/  201] train: loss: 0.1278581
[Epoch 42; Iter   129/  201] train: loss: 0.1603155
[Epoch 42; Iter   159/  201] train: loss: 0.1929089
[Epoch 42; Iter   189/  201] train: loss: 0.1396991
[Epoch 42] ogbg-moltoxcast: 0.732061 val loss: 0.208641
[Epoch 42] ogbg-moltoxcast: 0.751222 test loss: 0.207157
[Epoch 43; Iter    18/  201] train: loss: 0.1085890
[Epoch 43; Iter    48/  201] train: loss: 0.1318721
[Epoch 43; Iter    78/  201] train: loss: 0.1156283
[Epoch 43; Iter   108/  201] train: loss: 0.1726694
[Epoch 43; Iter   138/  201] train: loss: 0.1538569
[Epoch 43; Iter   168/  201] train: loss: 0.1958563
[Epoch 43; Iter   198/  201] train: loss: 0.1745209
[Epoch 43] ogbg-moltoxcast: 0.739692 val loss: 0.204263
[Epoch 43] ogbg-moltoxcast: 0.748318 test loss: 0.205707
[Epoch 44; Iter    27/  201] train: loss: 0.1378781
[Epoch 44; Iter    57/  201] train: loss: 0.1252303
[Epoch 44; Iter    87/  201] train: loss: 0.1667186
[Epoch 44; Iter   117/  201] train: loss: 0.1628487
[Epoch 44; Iter   147/  201] train: loss: 0.1360336
[Epoch 44; Iter   177/  201] train: loss: 0.1530816
[Epoch 44] ogbg-moltoxcast: 0.732446 val loss: 0.207648
[Epoch 44] ogbg-moltoxcast: 0.749730 test loss: 0.206116
[Epoch 45; Iter     6/  201] train: loss: 0.1082892
[Epoch 45; Iter    36/  201] train: loss: 0.1868216
[Epoch 45; Iter    66/  201] train: loss: 0.1603726
[Epoch 45; Iter    96/  201] train: loss: 0.1179066
[Epoch 45; Iter   126/  201] train: loss: 0.1692308
[Epoch 45; Iter   156/  201] train: loss: 0.1306077
[Epoch 45; Iter   186/  201] train: loss: 0.1490185
[Epoch 45] ogbg-moltoxcast: 0.734553 val loss: 0.204927
[Epoch 45] ogbg-moltoxcast: 0.749383 test loss: 0.203983
[Epoch 46; Iter    15/  201] train: loss: 0.1705148
[Epoch 46; Iter    45/  201] train: loss: 0.1551071
[Epoch 46; Iter    75/  201] train: loss: 0.0898605
[Epoch 46; Iter   105/  201] train: loss: 0.1555107
[Epoch 46; Iter   135/  201] train: loss: 0.1595007
[Epoch 46; Iter   165/  201] train: loss: 0.1557235
[Epoch 46; Iter   195/  201] train: loss: 0.0978664
[Epoch 46] ogbg-moltoxcast: 0.734753 val loss: 0.212912
[Epoch 46] ogbg-moltoxcast: 0.753394 test loss: 0.213072
[Epoch 47; Iter    24/  201] train: loss: 0.1355600
[Epoch 47; Iter    54/  201] train: loss: 0.1633839
[Epoch 47; Iter    84/  201] train: loss: 0.1932391
[Epoch 47; Iter   114/  201] train: loss: 0.1660202
[Epoch 47; Iter   144/  201] train: loss: 0.1130743
[Epoch 47; Iter   174/  201] train: loss: 0.1374985
[Epoch 47] ogbg-moltoxcast: 0.729637 val loss: 0.208430
[Epoch 47] ogbg-moltoxcast: 0.749169 test loss: 0.208715
[Epoch 48; Iter     3/  201] train: loss: 0.2093189
[Epoch 48; Iter    33/  201] train: loss: 0.1151701
[Epoch 48; Iter    63/  201] train: loss: 0.2383548
[Epoch 48; Iter    93/  201] train: loss: 0.1285754
[Epoch 48; Iter   123/  201] train: loss: 0.1222546
[Epoch 48; Iter   153/  201] train: loss: 0.2030972
[Epoch 30] ogbg-moltoxcast: 0.724567 test loss: 0.216658
[Epoch 31; Iter    30/  201] train: loss: 0.1494245
[Epoch 31; Iter    60/  201] train: loss: 0.1939121
[Epoch 31; Iter    90/  201] train: loss: 0.1471269
[Epoch 31; Iter   120/  201] train: loss: 0.1470749
[Epoch 31; Iter   150/  201] train: loss: 0.1843702
[Epoch 31; Iter   180/  201] train: loss: 0.2143958
[Epoch 31] ogbg-moltoxcast: 0.721001 val loss: 0.209758
[Epoch 31] ogbg-moltoxcast: 0.735690 test loss: 0.210381
[Epoch 32; Iter     9/  201] train: loss: 0.1850135
[Epoch 32; Iter    39/  201] train: loss: 0.2149754
[Epoch 32; Iter    69/  201] train: loss: 0.1887724
[Epoch 32; Iter    99/  201] train: loss: 0.2306747
[Epoch 32; Iter   129/  201] train: loss: 0.2442296
[Epoch 32; Iter   159/  201] train: loss: 0.1623378
[Epoch 32; Iter   189/  201] train: loss: 0.1691594
[Epoch 32] ogbg-moltoxcast: 0.729790 val loss: 0.206105
[Epoch 32] ogbg-moltoxcast: 0.739201 test loss: 0.207064
[Epoch 33; Iter    18/  201] train: loss: 0.1410984
[Epoch 33; Iter    48/  201] train: loss: 0.1707048
[Epoch 33; Iter    78/  201] train: loss: 0.1177805
[Epoch 33; Iter   108/  201] train: loss: 0.1342897
[Epoch 33; Iter   138/  201] train: loss: 0.2146464
[Epoch 33; Iter   168/  201] train: loss: 0.2817853
[Epoch 33; Iter   198/  201] train: loss: 0.1755870
[Epoch 33] ogbg-moltoxcast: 0.727530 val loss: 0.207052
[Epoch 33] ogbg-moltoxcast: 0.743637 test loss: 0.206537
[Epoch 34; Iter    27/  201] train: loss: 0.2085731
[Epoch 34; Iter    57/  201] train: loss: 0.1996796
[Epoch 34; Iter    87/  201] train: loss: 0.1773428
[Epoch 34; Iter   117/  201] train: loss: 0.1791711
[Epoch 34; Iter   147/  201] train: loss: 0.2539498
[Epoch 34; Iter   177/  201] train: loss: 0.1596189
[Epoch 34] ogbg-moltoxcast: 0.731608 val loss: 0.205447
[Epoch 34] ogbg-moltoxcast: 0.742499 test loss: 0.206087
[Epoch 35; Iter     6/  201] train: loss: 0.1080000
[Epoch 35; Iter    36/  201] train: loss: 0.1323757
[Epoch 35; Iter    66/  201] train: loss: 0.1399461
[Epoch 35; Iter    96/  201] train: loss: 0.1780276
[Epoch 35; Iter   126/  201] train: loss: 0.1432455
[Epoch 35; Iter   156/  201] train: loss: 0.1822450
[Epoch 35; Iter   186/  201] train: loss: 0.1586447
[Epoch 35] ogbg-moltoxcast: 0.724715 val loss: 0.206107
[Epoch 35] ogbg-moltoxcast: 0.741766 test loss: 0.205571
[Epoch 36; Iter    15/  201] train: loss: 0.2319841
[Epoch 36; Iter    45/  201] train: loss: 0.1447054
[Epoch 36; Iter    75/  201] train: loss: 0.2137990
[Epoch 36; Iter   105/  201] train: loss: 0.1708310
[Epoch 36; Iter   135/  201] train: loss: 0.2210595
[Epoch 36; Iter   165/  201] train: loss: 0.1504733
[Epoch 36; Iter   195/  201] train: loss: 0.1361638
[Epoch 36] ogbg-moltoxcast: 0.731919 val loss: 0.203017
[Epoch 36] ogbg-moltoxcast: 0.744488 test loss: 0.203547
[Epoch 37; Iter    24/  201] train: loss: 0.1591198
[Epoch 37; Iter    54/  201] train: loss: 0.1773154
[Epoch 37; Iter    84/  201] train: loss: 0.1783482
[Epoch 37; Iter   114/  201] train: loss: 0.1652836
[Epoch 37; Iter   144/  201] train: loss: 0.1659714
[Epoch 37; Iter   174/  201] train: loss: 0.1414786
[Epoch 37] ogbg-moltoxcast: 0.731138 val loss: 0.205966
[Epoch 37] ogbg-moltoxcast: 0.745393 test loss: 0.205265
[Epoch 38; Iter     3/  201] train: loss: 0.2061444
[Epoch 38; Iter    33/  201] train: loss: 0.1423977
[Epoch 38; Iter    63/  201] train: loss: 0.1427855
[Epoch 38; Iter    93/  201] train: loss: 0.1903171
[Epoch 38; Iter   123/  201] train: loss: 0.1509199
[Epoch 38; Iter   153/  201] train: loss: 0.1474118
[Epoch 38; Iter   183/  201] train: loss: 0.2514109
[Epoch 38] ogbg-moltoxcast: 0.724752 val loss: 0.207389
[Epoch 38] ogbg-moltoxcast: 0.743214 test loss: 0.202501
[Epoch 39; Iter    12/  201] train: loss: 0.1547706
[Epoch 39; Iter    42/  201] train: loss: 0.1928730
[Epoch 39; Iter    72/  201] train: loss: 0.1520798
[Epoch 39; Iter   102/  201] train: loss: 0.1951905
[Epoch 39; Iter   132/  201] train: loss: 0.1623432
[Epoch 39; Iter   162/  201] train: loss: 0.1410903
[Epoch 39; Iter   192/  201] train: loss: 0.1663982
[Epoch 39] ogbg-moltoxcast: 0.726581 val loss: 0.209586
[Epoch 39] ogbg-moltoxcast: 0.747647 test loss: 0.205261
[Epoch 40; Iter    21/  201] train: loss: 0.1422023
[Epoch 40; Iter    51/  201] train: loss: 0.1964668
[Epoch 40; Iter    81/  201] train: loss: 0.1656298
[Epoch 40; Iter   111/  201] train: loss: 0.2136977
[Epoch 40; Iter   141/  201] train: loss: 0.2203607
[Epoch 40; Iter   171/  201] train: loss: 0.1449833
[Epoch 40; Iter   201/  201] train: loss: 0.1041432
[Epoch 40] ogbg-moltoxcast: 0.726982 val loss: 0.209953
[Epoch 40] ogbg-moltoxcast: 0.740735 test loss: 0.211884
[Epoch 41; Iter    30/  201] train: loss: 0.1339755
[Epoch 41; Iter    60/  201] train: loss: 0.1772251
[Epoch 41; Iter    90/  201] train: loss: 0.1861760
[Epoch 41; Iter   120/  201] train: loss: 0.1846617
[Epoch 41; Iter   150/  201] train: loss: 0.1454007
[Epoch 41; Iter   180/  201] train: loss: 0.2333760
[Epoch 41] ogbg-moltoxcast: 0.721888 val loss: 0.208592
[Epoch 41] ogbg-moltoxcast: 0.741570 test loss: 0.207321
[Epoch 42; Iter     9/  201] train: loss: 0.2352721
[Epoch 42; Iter    39/  201] train: loss: 0.1798673
[Epoch 42; Iter    69/  201] train: loss: 0.1768105
[Epoch 42; Iter    99/  201] train: loss: 0.1850715
[Epoch 42; Iter   129/  201] train: loss: 0.2335975
[Epoch 42; Iter   159/  201] train: loss: 0.1636968
[Epoch 42; Iter   189/  201] train: loss: 0.1442093
[Epoch 42] ogbg-moltoxcast: 0.723387 val loss: 0.210073
[Epoch 42] ogbg-moltoxcast: 0.748673 test loss: 0.205255
[Epoch 43; Iter    18/  201] train: loss: 0.1492224
[Epoch 43; Iter    48/  201] train: loss: 0.1824134
[Epoch 43; Iter    78/  201] train: loss: 0.1813723
[Epoch 43; Iter   108/  201] train: loss: 0.1052787
[Epoch 43; Iter   138/  201] train: loss: 0.2152121
[Epoch 43; Iter   168/  201] train: loss: 0.0981642
[Epoch 43; Iter   198/  201] train: loss: 0.2439310
[Epoch 43] ogbg-moltoxcast: 0.730109 val loss: 0.205022
[Epoch 43] ogbg-moltoxcast: 0.746930 test loss: 0.201061
[Epoch 44; Iter    27/  201] train: loss: 0.2092302
[Epoch 44; Iter    57/  201] train: loss: 0.1424785
[Epoch 44; Iter    87/  201] train: loss: 0.1492184
[Epoch 44; Iter   117/  201] train: loss: 0.1892154
[Epoch 44; Iter   147/  201] train: loss: 0.1872720
[Epoch 44; Iter   177/  201] train: loss: 0.1609963
[Epoch 44] ogbg-moltoxcast: 0.726995 val loss: 0.207316
[Epoch 44] ogbg-moltoxcast: 0.745110 test loss: 0.205515
[Epoch 45; Iter     6/  201] train: loss: 0.2191530
[Epoch 45; Iter    36/  201] train: loss: 0.1770556
[Epoch 45; Iter    66/  201] train: loss: 0.1958694
[Epoch 45; Iter    96/  201] train: loss: 0.1732937
[Epoch 45; Iter   126/  201] train: loss: 0.1735191
[Epoch 45; Iter   156/  201] train: loss: 0.1544103
[Epoch 45; Iter   186/  201] train: loss: 0.1504243
[Epoch 45] ogbg-moltoxcast: 0.731026 val loss: 0.205284
[Epoch 45] ogbg-moltoxcast: 0.751494 test loss: 0.202288
[Epoch 46; Iter    15/  201] train: loss: 0.1719042
[Epoch 46; Iter    45/  201] train: loss: 0.1383113
[Epoch 46; Iter    75/  201] train: loss: 0.1431098
[Epoch 46; Iter   105/  201] train: loss: 0.1446410
[Epoch 46; Iter   135/  201] train: loss: 0.2378197
[Epoch 46; Iter   165/  201] train: loss: 0.1305174
[Epoch 46; Iter   195/  201] train: loss: 0.1435233
[Epoch 46] ogbg-moltoxcast: 0.729375 val loss: 0.207202
[Epoch 46] ogbg-moltoxcast: 0.748608 test loss: 0.204639
[Epoch 47; Iter    24/  201] train: loss: 0.1367572
[Epoch 47; Iter    54/  201] train: loss: 0.1642502
[Epoch 47; Iter    84/  201] train: loss: 0.1245455
[Epoch 47; Iter   114/  201] train: loss: 0.1390211
[Epoch 47; Iter   144/  201] train: loss: 0.2193696
[Epoch 47; Iter   174/  201] train: loss: 0.1865475
[Epoch 47] ogbg-moltoxcast: 0.733485 val loss: 0.205807
[Epoch 47] ogbg-moltoxcast: 0.750370 test loss: 0.202295
[Epoch 48; Iter     3/  201] train: loss: 0.0896165
[Epoch 48; Iter    33/  201] train: loss: 0.1818767
[Epoch 48; Iter    63/  201] train: loss: 0.1927423
[Epoch 48; Iter    93/  201] train: loss: 0.1733240
[Epoch 48; Iter   123/  201] train: loss: 0.1642922
[Epoch 48; Iter   153/  201] train: loss: 0.1605991
[Epoch 34] ogbg-moltoxcast: 0.729160 val loss: 0.217479
[Epoch 34] ogbg-moltoxcast: 0.738618 test loss: 0.203424
[Epoch 35; Iter     2/  172] train: loss: 0.1570260
[Epoch 35; Iter    32/  172] train: loss: 0.1799340
[Epoch 35; Iter    62/  172] train: loss: 0.1856117
[Epoch 35; Iter    92/  172] train: loss: 0.1481902
[Epoch 35; Iter   122/  172] train: loss: 0.1749454
[Epoch 35; Iter   152/  172] train: loss: 0.1879638
[Epoch 35] ogbg-moltoxcast: 0.720680 val loss: 0.237234
[Epoch 35] ogbg-moltoxcast: 0.744042 test loss: 0.199119
[Epoch 36; Iter    10/  172] train: loss: 0.1450995
[Epoch 36; Iter    40/  172] train: loss: 0.1754117
[Epoch 36; Iter    70/  172] train: loss: 0.1860670
[Epoch 36; Iter   100/  172] train: loss: 0.1227190
[Epoch 36; Iter   130/  172] train: loss: 0.1728946
[Epoch 36; Iter   160/  172] train: loss: 0.1276275
[Epoch 36] ogbg-moltoxcast: 0.723139 val loss: 0.249600
[Epoch 36] ogbg-moltoxcast: 0.735983 test loss: 0.207449
[Epoch 37; Iter    18/  172] train: loss: 0.1339805
[Epoch 37; Iter    48/  172] train: loss: 0.1666398
[Epoch 37; Iter    78/  172] train: loss: 0.1519015
[Epoch 37; Iter   108/  172] train: loss: 0.1025189
[Epoch 37; Iter   138/  172] train: loss: 0.1544268
[Epoch 37; Iter   168/  172] train: loss: 0.2129012
[Epoch 37] ogbg-moltoxcast: 0.724087 val loss: 0.268621
[Epoch 37] ogbg-moltoxcast: 0.734869 test loss: 0.206509
[Epoch 38; Iter    26/  172] train: loss: 0.1679973
[Epoch 38; Iter    56/  172] train: loss: 0.1280078
[Epoch 38; Iter    86/  172] train: loss: 0.1258449
[Epoch 38; Iter   116/  172] train: loss: 0.1839463
[Epoch 38; Iter   146/  172] train: loss: 0.1902441
[Epoch 38] ogbg-moltoxcast: 0.719141 val loss: 0.251575
[Epoch 38] ogbg-moltoxcast: 0.737873 test loss: 0.201389
[Epoch 39; Iter     4/  172] train: loss: 0.2209917
[Epoch 39; Iter    34/  172] train: loss: 0.1995308
[Epoch 39; Iter    64/  172] train: loss: 0.1448607
[Epoch 39; Iter    94/  172] train: loss: 0.1703899
[Epoch 39; Iter   124/  172] train: loss: 0.2242298
[Epoch 39; Iter   154/  172] train: loss: 0.1860368
[Epoch 39] ogbg-moltoxcast: 0.724120 val loss: 0.202484
[Epoch 39] ogbg-moltoxcast: 0.742959 test loss: 0.199348
[Epoch 40; Iter    12/  172] train: loss: 0.1681140
[Epoch 40; Iter    42/  172] train: loss: 0.1125879
[Epoch 40; Iter    72/  172] train: loss: 0.1890365
[Epoch 40; Iter   102/  172] train: loss: 0.1664104
[Epoch 40; Iter   132/  172] train: loss: 0.1256093
[Epoch 40; Iter   162/  172] train: loss: 0.1426523
[Epoch 40] ogbg-moltoxcast: 0.724434 val loss: 0.204362
[Epoch 40] ogbg-moltoxcast: 0.741723 test loss: 0.201418
[Epoch 41; Iter    20/  172] train: loss: 0.2047724
[Epoch 41; Iter    50/  172] train: loss: 0.2138269
[Epoch 41; Iter    80/  172] train: loss: 0.0626612
[Epoch 41; Iter   110/  172] train: loss: 0.1699830
[Epoch 41; Iter   140/  172] train: loss: 0.1325876
[Epoch 41; Iter   170/  172] train: loss: 0.2613310
[Epoch 41] ogbg-moltoxcast: 0.724011 val loss: 0.206527
[Epoch 41] ogbg-moltoxcast: 0.740368 test loss: 0.204681
[Epoch 42; Iter    28/  172] train: loss: 0.1900526
[Epoch 42; Iter    58/  172] train: loss: 0.2108815
[Epoch 42; Iter    88/  172] train: loss: 0.1798230
[Epoch 42; Iter   118/  172] train: loss: 0.1203877
[Epoch 42; Iter   148/  172] train: loss: 0.1119615
[Epoch 42] ogbg-moltoxcast: 0.722834 val loss: 0.232288
[Epoch 42] ogbg-moltoxcast: 0.737596 test loss: 0.206002
[Epoch 43; Iter     6/  172] train: loss: 0.1403513
[Epoch 43; Iter    36/  172] train: loss: 0.1583496
[Epoch 43; Iter    66/  172] train: loss: 0.1123945
[Epoch 43; Iter    96/  172] train: loss: 0.1581988
[Epoch 43; Iter   126/  172] train: loss: 0.0970946
[Epoch 43; Iter   156/  172] train: loss: 0.1364674
[Epoch 43] ogbg-moltoxcast: 0.725161 val loss: 0.203946
[Epoch 43] ogbg-moltoxcast: 0.743654 test loss: 0.201691
[Epoch 44; Iter    14/  172] train: loss: 0.2076823
[Epoch 44; Iter    44/  172] train: loss: 0.1324496
[Epoch 44; Iter    74/  172] train: loss: 0.1336554
[Epoch 44; Iter   104/  172] train: loss: 0.1706983
[Epoch 44; Iter   134/  172] train: loss: 0.1527272
[Epoch 44; Iter   164/  172] train: loss: 0.1833074
[Epoch 44] ogbg-moltoxcast: 0.722567 val loss: 0.210736
[Epoch 44] ogbg-moltoxcast: 0.746544 test loss: 0.199973
[Epoch 45; Iter    22/  172] train: loss: 0.1341038
[Epoch 45; Iter    52/  172] train: loss: 0.1698321
[Epoch 45; Iter    82/  172] train: loss: 0.1567581
[Epoch 45; Iter   112/  172] train: loss: 0.1578035
[Epoch 45; Iter   142/  172] train: loss: 0.1372541
[Epoch 45; Iter   172/  172] train: loss: 0.2498780
[Epoch 45] ogbg-moltoxcast: 0.720063 val loss: 0.206689
[Epoch 45] ogbg-moltoxcast: 0.742983 test loss: 0.204019
[Epoch 46; Iter    30/  172] train: loss: 0.1187109
[Epoch 46; Iter    60/  172] train: loss: 0.1203821
[Epoch 46; Iter    90/  172] train: loss: 0.0886901
[Epoch 46; Iter   120/  172] train: loss: 0.1354430
[Epoch 46; Iter   150/  172] train: loss: 0.1717259
[Epoch 46] ogbg-moltoxcast: 0.720484 val loss: 0.204165
[Epoch 46] ogbg-moltoxcast: 0.739603 test loss: 0.203271
[Epoch 47; Iter     8/  172] train: loss: 0.1330711
[Epoch 47; Iter    38/  172] train: loss: 0.1330416
[Epoch 47; Iter    68/  172] train: loss: 0.1535984
[Epoch 47; Iter    98/  172] train: loss: 0.1103483
[Epoch 47; Iter   128/  172] train: loss: 0.1167005
[Epoch 47; Iter   158/  172] train: loss: 0.1778388
[Epoch 47] ogbg-moltoxcast: 0.722405 val loss: 0.209477
[Epoch 47] ogbg-moltoxcast: 0.746914 test loss: 0.203267
[Epoch 48; Iter    16/  172] train: loss: 0.1966596
[Epoch 48; Iter    46/  172] train: loss: 0.1447904
[Epoch 48; Iter    76/  172] train: loss: 0.1354553
[Epoch 48; Iter   106/  172] train: loss: 0.1807473
[Epoch 48; Iter   136/  172] train: loss: 0.1725614
[Epoch 48; Iter   166/  172] train: loss: 0.1451709
[Epoch 48] ogbg-moltoxcast: 0.712924 val loss: 0.208540
[Epoch 48] ogbg-moltoxcast: 0.737355 test loss: 0.205076
[Epoch 49; Iter    24/  172] train: loss: 0.1292389
[Epoch 49; Iter    54/  172] train: loss: 0.1548776
[Epoch 49; Iter    84/  172] train: loss: 0.1191660
[Epoch 49; Iter   114/  172] train: loss: 0.1438032
[Epoch 49; Iter   144/  172] train: loss: 0.1763996
[Epoch 49] ogbg-moltoxcast: 0.720376 val loss: 0.208556
[Epoch 49] ogbg-moltoxcast: 0.746650 test loss: 0.204376
[Epoch 50; Iter     2/  172] train: loss: 0.1320589
[Epoch 50; Iter    32/  172] train: loss: 0.1665943
[Epoch 50; Iter    62/  172] train: loss: 0.1350081
[Epoch 50; Iter    92/  172] train: loss: 0.2125749
[Epoch 50; Iter   122/  172] train: loss: 0.1583829
[Epoch 50; Iter   152/  172] train: loss: 0.1473010
[Epoch 50] ogbg-moltoxcast: 0.715434 val loss: 0.209166
[Epoch 50] ogbg-moltoxcast: 0.741382 test loss: 0.204318
[Epoch 51; Iter    10/  172] train: loss: 0.1020093
[Epoch 51; Iter    40/  172] train: loss: 0.1771948
[Epoch 51; Iter    70/  172] train: loss: 0.1448949
[Epoch 51; Iter   100/  172] train: loss: 0.1358033
[Epoch 51; Iter   130/  172] train: loss: 0.1853064
[Epoch 51; Iter   160/  172] train: loss: 0.1661514
[Epoch 51] ogbg-moltoxcast: 0.716975 val loss: 0.213976
[Epoch 51] ogbg-moltoxcast: 0.740711 test loss: 0.207671
[Epoch 52; Iter    18/  172] train: loss: 0.1332344
[Epoch 52; Iter    48/  172] train: loss: 0.1300754
[Epoch 52; Iter    78/  172] train: loss: 0.1546631
[Epoch 52; Iter   108/  172] train: loss: 0.1749253
[Epoch 52; Iter   138/  172] train: loss: 0.1463893
[Epoch 52; Iter   168/  172] train: loss: 0.1452565
[Epoch 52] ogbg-moltoxcast: 0.722287 val loss: 0.209717
[Epoch 52] ogbg-moltoxcast: 0.741688 test loss: 0.206055
[Epoch 53; Iter    26/  172] train: loss: 0.1382215
[Epoch 53; Iter    56/  172] train: loss: 0.1289500
[Epoch 53; Iter    86/  172] train: loss: 0.1499086
[Epoch 53; Iter   116/  172] train: loss: 0.2055693
[Epoch 53; Iter   146/  172] train: loss: 0.1268748
[Epoch 53] ogbg-moltoxcast: 0.722164 val loss: 0.206687
[Epoch 53] ogbg-moltoxcast: 0.744480 test loss: 0.203504
[Epoch 54; Iter     4/  172] train: loss: 0.1227322
[Epoch 54; Iter    34/  172] train: loss: 0.1409362
[Epoch 54; Iter    64/  172] train: loss: 0.1773690
[Epoch 54; Iter    94/  172] train: loss: 0.1585231
[Epoch 54; Iter   124/  172] train: loss: 0.1570224
[Epoch 34] ogbg-moltoxcast: 0.732916 val loss: 0.200635
[Epoch 34] ogbg-moltoxcast: 0.734344 test loss: 0.201414
[Epoch 35; Iter     2/  172] train: loss: 0.1876006
[Epoch 35; Iter    32/  172] train: loss: 0.1689385
[Epoch 35; Iter    62/  172] train: loss: 0.1306996
[Epoch 35; Iter    92/  172] train: loss: 0.1354225
[Epoch 35; Iter   122/  172] train: loss: 0.1029996
[Epoch 35; Iter   152/  172] train: loss: 0.1066304
[Epoch 35] ogbg-moltoxcast: 0.728227 val loss: 0.205808
[Epoch 35] ogbg-moltoxcast: 0.732089 test loss: 0.205493
[Epoch 36; Iter    10/  172] train: loss: 0.1743146
[Epoch 36; Iter    40/  172] train: loss: 0.1284905
[Epoch 36; Iter    70/  172] train: loss: 0.1363815
[Epoch 36; Iter   100/  172] train: loss: 0.1392825
[Epoch 36; Iter   130/  172] train: loss: 0.1694357
[Epoch 36; Iter   160/  172] train: loss: 0.1270070
[Epoch 36] ogbg-moltoxcast: 0.726909 val loss: 0.205786
[Epoch 36] ogbg-moltoxcast: 0.733606 test loss: 0.204249
[Epoch 37; Iter    18/  172] train: loss: 0.1218688
[Epoch 37; Iter    48/  172] train: loss: 0.1378326
[Epoch 37; Iter    78/  172] train: loss: 0.1636467
[Epoch 37; Iter   108/  172] train: loss: 0.1057815
[Epoch 37; Iter   138/  172] train: loss: 0.2336353
[Epoch 37; Iter   168/  172] train: loss: 0.2042204
[Epoch 37] ogbg-moltoxcast: 0.716530 val loss: 0.245974
[Epoch 37] ogbg-moltoxcast: 0.724017 test loss: 0.220033
[Epoch 38; Iter    26/  172] train: loss: 0.2252994
[Epoch 38; Iter    56/  172] train: loss: 0.2062141
[Epoch 38; Iter    86/  172] train: loss: 0.1164653
[Epoch 38; Iter   116/  172] train: loss: 0.1444223
[Epoch 38; Iter   146/  172] train: loss: 0.1590499
[Epoch 38] ogbg-moltoxcast: 0.727787 val loss: 0.294739
[Epoch 38] ogbg-moltoxcast: 0.733603 test loss: 0.232352
[Epoch 39; Iter     4/  172] train: loss: 0.1996618
[Epoch 39; Iter    34/  172] train: loss: 0.1408379
[Epoch 39; Iter    64/  172] train: loss: 0.1065768
[Epoch 39; Iter    94/  172] train: loss: 0.1467441
[Epoch 39; Iter   124/  172] train: loss: 0.2151516
[Epoch 39; Iter   154/  172] train: loss: 0.1504284
[Epoch 39] ogbg-moltoxcast: 0.730565 val loss: 0.312788
[Epoch 39] ogbg-moltoxcast: 0.735689 test loss: 0.211653
[Epoch 40; Iter    12/  172] train: loss: 0.2458481
[Epoch 40; Iter    42/  172] train: loss: 0.1841052
[Epoch 40; Iter    72/  172] train: loss: 0.1449509
[Epoch 40; Iter   102/  172] train: loss: 0.1955858
[Epoch 40; Iter   132/  172] train: loss: 0.1286354
[Epoch 40; Iter   162/  172] train: loss: 0.2212874
[Epoch 40] ogbg-moltoxcast: 0.729114 val loss: 0.239747
[Epoch 40] ogbg-moltoxcast: 0.733041 test loss: 0.206982
[Epoch 41; Iter    20/  172] train: loss: 0.2017811
[Epoch 41; Iter    50/  172] train: loss: 0.1694391
[Epoch 41; Iter    80/  172] train: loss: 0.2356838
[Epoch 41; Iter   110/  172] train: loss: 0.1543497
[Epoch 41; Iter   140/  172] train: loss: 0.1513108
[Epoch 41; Iter   170/  172] train: loss: 0.1551071
[Epoch 41] ogbg-moltoxcast: 0.722986 val loss: 0.296484
[Epoch 41] ogbg-moltoxcast: 0.733957 test loss: 0.204618
[Epoch 42; Iter    28/  172] train: loss: 0.1855240
[Epoch 42; Iter    58/  172] train: loss: 0.1504263
[Epoch 42; Iter    88/  172] train: loss: 0.2356537
[Epoch 42; Iter   118/  172] train: loss: 0.1836512
[Epoch 42; Iter   148/  172] train: loss: 0.1477534
[Epoch 42] ogbg-moltoxcast: 0.731947 val loss: 0.279100
[Epoch 42] ogbg-moltoxcast: 0.739413 test loss: 0.209804
[Epoch 43; Iter     6/  172] train: loss: 0.0956738
[Epoch 43; Iter    36/  172] train: loss: 0.1729744
[Epoch 43; Iter    66/  172] train: loss: 0.1135004
[Epoch 43; Iter    96/  172] train: loss: 0.1531923
[Epoch 43; Iter   126/  172] train: loss: 0.1454515
[Epoch 43; Iter   156/  172] train: loss: 0.2338820
[Epoch 43] ogbg-moltoxcast: 0.731288 val loss: 0.290533
[Epoch 43] ogbg-moltoxcast: 0.735515 test loss: 0.229156
[Epoch 44; Iter    14/  172] train: loss: 0.1296414
[Epoch 44; Iter    44/  172] train: loss: 0.1769771
[Epoch 44; Iter    74/  172] train: loss: 0.1901661
[Epoch 44; Iter   104/  172] train: loss: 0.2393539
[Epoch 44; Iter   134/  172] train: loss: 0.2068381
[Epoch 44; Iter   164/  172] train: loss: 0.2764072
[Epoch 44] ogbg-moltoxcast: 0.722077 val loss: 0.339387
[Epoch 44] ogbg-moltoxcast: 0.737675 test loss: 0.254704
[Epoch 45; Iter    22/  172] train: loss: 0.2384718
[Epoch 45; Iter    52/  172] train: loss: 0.1495680
[Epoch 45; Iter    82/  172] train: loss: 0.1613489
[Epoch 45; Iter   112/  172] train: loss: 0.1809596
[Epoch 45; Iter   142/  172] train: loss: 0.1776862
[Epoch 45; Iter   172/  172] train: loss: 0.1263124
[Epoch 45] ogbg-moltoxcast: 0.727841 val loss: 0.234647
[Epoch 45] ogbg-moltoxcast: 0.740431 test loss: 0.210319
[Epoch 46; Iter    30/  172] train: loss: 0.2060545
[Epoch 46; Iter    60/  172] train: loss: 0.1781323
[Epoch 46; Iter    90/  172] train: loss: 0.1256786
[Epoch 46; Iter   120/  172] train: loss: 0.2111604
[Epoch 46; Iter   150/  172] train: loss: 0.2367888
[Epoch 46] ogbg-moltoxcast: 0.726807 val loss: 0.310444
[Epoch 46] ogbg-moltoxcast: 0.741219 test loss: 0.208880
[Epoch 47; Iter     8/  172] train: loss: 0.1618708
[Epoch 47; Iter    38/  172] train: loss: 0.1463742
[Epoch 47; Iter    68/  172] train: loss: 0.1062007
[Epoch 47; Iter    98/  172] train: loss: 0.1755477
[Epoch 47; Iter   128/  172] train: loss: 0.1384345
[Epoch 47; Iter   158/  172] train: loss: 0.1482058
[Epoch 47] ogbg-moltoxcast: 0.724566 val loss: 0.214732
[Epoch 47] ogbg-moltoxcast: 0.734491 test loss: 0.207310
[Epoch 48; Iter    16/  172] train: loss: 0.1389924
[Epoch 48; Iter    46/  172] train: loss: 0.1703266
[Epoch 48; Iter    76/  172] train: loss: 0.1826368
[Epoch 48; Iter   106/  172] train: loss: 0.1617582
[Epoch 48; Iter   136/  172] train: loss: 0.1581683
[Epoch 48; Iter   166/  172] train: loss: 0.1910142
[Epoch 48] ogbg-moltoxcast: 0.726684 val loss: 0.341052
[Epoch 48] ogbg-moltoxcast: 0.738052 test loss: 0.222358
[Epoch 49; Iter    24/  172] train: loss: 0.1290557
[Epoch 49; Iter    54/  172] train: loss: 0.1453774
[Epoch 49; Iter    84/  172] train: loss: 0.1867546
[Epoch 49; Iter   114/  172] train: loss: 0.1123224
[Epoch 49; Iter   144/  172] train: loss: 0.1871421
[Epoch 49] ogbg-moltoxcast: 0.722653 val loss: 0.360983
[Epoch 49] ogbg-moltoxcast: 0.737750 test loss: 0.230167
[Epoch 50; Iter     2/  172] train: loss: 0.1478459
[Epoch 50; Iter    32/  172] train: loss: 0.1687231
[Epoch 50; Iter    62/  172] train: loss: 0.1171268
[Epoch 50; Iter    92/  172] train: loss: 0.1356900
[Epoch 50; Iter   122/  172] train: loss: 0.1605452
[Epoch 50; Iter   152/  172] train: loss: 0.1514614
[Epoch 50] ogbg-moltoxcast: 0.733674 val loss: 0.262381
[Epoch 50] ogbg-moltoxcast: 0.736669 test loss: 0.202995
[Epoch 51; Iter    10/  172] train: loss: 0.1353868
[Epoch 51; Iter    40/  172] train: loss: 0.1454809
[Epoch 51; Iter    70/  172] train: loss: 0.1930844
[Epoch 51; Iter   100/  172] train: loss: 0.1530693
[Epoch 51; Iter   130/  172] train: loss: 0.1752546
[Epoch 51; Iter   160/  172] train: loss: 0.1889011
[Epoch 51] ogbg-moltoxcast: 0.723261 val loss: 0.404716
[Epoch 51] ogbg-moltoxcast: 0.736546 test loss: 0.259315
[Epoch 52; Iter    18/  172] train: loss: 0.1526663
[Epoch 52; Iter    48/  172] train: loss: 0.1337742
[Epoch 52; Iter    78/  172] train: loss: 0.1668616
[Epoch 52; Iter   108/  172] train: loss: 0.0960969
[Epoch 52; Iter   138/  172] train: loss: 0.1470210
[Epoch 52; Iter   168/  172] train: loss: 0.1597833
[Epoch 52] ogbg-moltoxcast: 0.726660 val loss: 0.310698
[Epoch 52] ogbg-moltoxcast: 0.733676 test loss: 0.206103
[Epoch 53; Iter    26/  172] train: loss: 0.1152619
[Epoch 53; Iter    56/  172] train: loss: 0.1601725
[Epoch 53; Iter    86/  172] train: loss: 0.1200187
[Epoch 53; Iter   116/  172] train: loss: 0.1736553
[Epoch 53; Iter   146/  172] train: loss: 0.1874406
[Epoch 53] ogbg-moltoxcast: 0.727219 val loss: 0.232669
[Epoch 53] ogbg-moltoxcast: 0.738608 test loss: 0.215660
[Epoch 54; Iter     4/  172] train: loss: 0.1829908
[Epoch 54; Iter    34/  172] train: loss: 0.1292211
[Epoch 54; Iter    64/  172] train: loss: 0.1438899
[Epoch 54; Iter    94/  172] train: loss: 0.1492835
[Epoch 54; Iter   124/  172] train: loss: 0.2058561
[Epoch 34] ogbg-moltoxcast: 0.727735 val loss: 0.203278
[Epoch 34] ogbg-moltoxcast: 0.735891 test loss: 0.201815
[Epoch 35; Iter     2/  172] train: loss: 0.1550752
[Epoch 35; Iter    32/  172] train: loss: 0.1633005
[Epoch 35; Iter    62/  172] train: loss: 0.1779091
[Epoch 35; Iter    92/  172] train: loss: 0.1720466
[Epoch 35; Iter   122/  172] train: loss: 0.0995403
[Epoch 35; Iter   152/  172] train: loss: 0.2322249
[Epoch 35] ogbg-moltoxcast: 0.728241 val loss: 0.207151
[Epoch 35] ogbg-moltoxcast: 0.733376 test loss: 0.208708
[Epoch 36; Iter    10/  172] train: loss: 0.1570314
[Epoch 36; Iter    40/  172] train: loss: 0.1772318
[Epoch 36; Iter    70/  172] train: loss: 0.1544152
[Epoch 36; Iter   100/  172] train: loss: 0.1294492
[Epoch 36; Iter   130/  172] train: loss: 0.1825732
[Epoch 36; Iter   160/  172] train: loss: 0.2257998
[Epoch 36] ogbg-moltoxcast: 0.728601 val loss: 0.200491
[Epoch 36] ogbg-moltoxcast: 0.738508 test loss: 0.199917
[Epoch 37; Iter    18/  172] train: loss: 0.1474652
[Epoch 37; Iter    48/  172] train: loss: 0.1576190
[Epoch 37; Iter    78/  172] train: loss: 0.2029495
[Epoch 37; Iter   108/  172] train: loss: 0.1527704
[Epoch 37; Iter   138/  172] train: loss: 0.1380926
[Epoch 37; Iter   168/  172] train: loss: 0.1063369
[Epoch 37] ogbg-moltoxcast: 0.725773 val loss: 0.202457
[Epoch 37] ogbg-moltoxcast: 0.741389 test loss: 0.202186
[Epoch 38; Iter    26/  172] train: loss: 0.1786754
[Epoch 38; Iter    56/  172] train: loss: 0.1464087
[Epoch 38; Iter    86/  172] train: loss: 0.1479108
[Epoch 38; Iter   116/  172] train: loss: 0.1767235
[Epoch 38; Iter   146/  172] train: loss: 0.1159040
[Epoch 38] ogbg-moltoxcast: 0.734995 val loss: 0.200960
[Epoch 38] ogbg-moltoxcast: 0.741176 test loss: 0.201914
[Epoch 39; Iter     4/  172] train: loss: 0.1656713
[Epoch 39; Iter    34/  172] train: loss: 0.1634851
[Epoch 39; Iter    64/  172] train: loss: 0.1430565
[Epoch 39; Iter    94/  172] train: loss: 0.1292398
[Epoch 39; Iter   124/  172] train: loss: 0.1511478
[Epoch 39; Iter   154/  172] train: loss: 0.1364231
[Epoch 39] ogbg-moltoxcast: 0.730076 val loss: 0.205784
[Epoch 39] ogbg-moltoxcast: 0.737708 test loss: 0.205994
[Epoch 40; Iter    12/  172] train: loss: 0.1841343
[Epoch 40; Iter    42/  172] train: loss: 0.1219126
[Epoch 40; Iter    72/  172] train: loss: 0.1560194
[Epoch 40; Iter   102/  172] train: loss: 0.1679716
[Epoch 40; Iter   132/  172] train: loss: 0.1891916
[Epoch 40; Iter   162/  172] train: loss: 0.1480893
[Epoch 40] ogbg-moltoxcast: 0.733998 val loss: 0.201514
[Epoch 40] ogbg-moltoxcast: 0.744189 test loss: 0.199752
[Epoch 41; Iter    20/  172] train: loss: 0.1585335
[Epoch 41; Iter    50/  172] train: loss: 0.1211285
[Epoch 41; Iter    80/  172] train: loss: 0.1417195
[Epoch 41; Iter   110/  172] train: loss: 0.1432540
[Epoch 41; Iter   140/  172] train: loss: 0.1218705
[Epoch 41; Iter   170/  172] train: loss: 0.1398956
[Epoch 41] ogbg-moltoxcast: 0.733252 val loss: 0.201227
[Epoch 41] ogbg-moltoxcast: 0.744093 test loss: 0.200754
[Epoch 42; Iter    28/  172] train: loss: 0.2005065
[Epoch 42; Iter    58/  172] train: loss: 0.1216052
[Epoch 42; Iter    88/  172] train: loss: 0.1208037
[Epoch 42; Iter   118/  172] train: loss: 0.0997758
[Epoch 42; Iter   148/  172] train: loss: 0.1979458
[Epoch 42] ogbg-moltoxcast: 0.734286 val loss: 0.200361
[Epoch 42] ogbg-moltoxcast: 0.745281 test loss: 0.199428
[Epoch 43; Iter     6/  172] train: loss: 0.1849837
[Epoch 43; Iter    36/  172] train: loss: 0.1970670
[Epoch 43; Iter    66/  172] train: loss: 0.1746377
[Epoch 43; Iter    96/  172] train: loss: 0.1344521
[Epoch 43; Iter   126/  172] train: loss: 0.1930869
[Epoch 43; Iter   156/  172] train: loss: 0.1033617
[Epoch 43] ogbg-moltoxcast: 0.735323 val loss: 0.201054
[Epoch 43] ogbg-moltoxcast: 0.744681 test loss: 0.200454
[Epoch 44; Iter    14/  172] train: loss: 0.2315143
[Epoch 44; Iter    44/  172] train: loss: 0.1302778
[Epoch 44; Iter    74/  172] train: loss: 0.1725776
[Epoch 44; Iter   104/  172] train: loss: 0.1755760
[Epoch 44; Iter   134/  172] train: loss: 0.0958986
[Epoch 44; Iter   164/  172] train: loss: 0.1708583
[Epoch 44] ogbg-moltoxcast: 0.733331 val loss: 0.203072
[Epoch 44] ogbg-moltoxcast: 0.742963 test loss: 0.202541
[Epoch 45; Iter    22/  172] train: loss: 0.2751334
[Epoch 45; Iter    52/  172] train: loss: 0.1354850
[Epoch 45; Iter    82/  172] train: loss: 0.1484443
[Epoch 45; Iter   112/  172] train: loss: 0.1337942
[Epoch 45; Iter   142/  172] train: loss: 0.1706153
[Epoch 45; Iter   172/  172] train: loss: 0.2077706
[Epoch 45] ogbg-moltoxcast: 0.735144 val loss: 0.201613
[Epoch 45] ogbg-moltoxcast: 0.745912 test loss: 0.203477
[Epoch 46; Iter    30/  172] train: loss: 0.1870872
[Epoch 46; Iter    60/  172] train: loss: 0.1916870
[Epoch 46; Iter    90/  172] train: loss: 0.1544850
[Epoch 46; Iter   120/  172] train: loss: 0.1346232
[Epoch 46; Iter   150/  172] train: loss: 0.2229191
[Epoch 46] ogbg-moltoxcast: 0.729427 val loss: 0.203695
[Epoch 46] ogbg-moltoxcast: 0.744713 test loss: 0.201355
[Epoch 47; Iter     8/  172] train: loss: 0.2541422
[Epoch 47; Iter    38/  172] train: loss: 0.1750496
[Epoch 47; Iter    68/  172] train: loss: 0.1799687
[Epoch 47; Iter    98/  172] train: loss: 0.1510495
[Epoch 47; Iter   128/  172] train: loss: 0.1114517
[Epoch 47; Iter   158/  172] train: loss: 0.1575415
[Epoch 47] ogbg-moltoxcast: 0.732497 val loss: 0.204061
[Epoch 47] ogbg-moltoxcast: 0.753607 test loss: 0.201738
[Epoch 48; Iter    16/  172] train: loss: 0.1548361
[Epoch 48; Iter    46/  172] train: loss: 0.1459354
[Epoch 48; Iter    76/  172] train: loss: 0.1833313
[Epoch 48; Iter   106/  172] train: loss: 0.1234282
[Epoch 48; Iter   136/  172] train: loss: 0.1626045
[Epoch 48; Iter   166/  172] train: loss: 0.1435322
[Epoch 48] ogbg-moltoxcast: 0.730729 val loss: 0.204383
[Epoch 48] ogbg-moltoxcast: 0.744757 test loss: 0.202935
[Epoch 49; Iter    24/  172] train: loss: 0.1790842
[Epoch 49; Iter    54/  172] train: loss: 0.1249788
[Epoch 49; Iter    84/  172] train: loss: 0.1390841
[Epoch 49; Iter   114/  172] train: loss: 0.1036274
[Epoch 49; Iter   144/  172] train: loss: 0.1222787
[Epoch 49] ogbg-moltoxcast: 0.730289 val loss: 0.203755
[Epoch 49] ogbg-moltoxcast: 0.745697 test loss: 0.202860
[Epoch 50; Iter     2/  172] train: loss: 0.1272303
[Epoch 50; Iter    32/  172] train: loss: 0.1042935
[Epoch 50; Iter    62/  172] train: loss: 0.1254627
[Epoch 50; Iter    92/  172] train: loss: 0.1378666
[Epoch 50; Iter   122/  172] train: loss: 0.1454486
[Epoch 50; Iter   152/  172] train: loss: 0.0956080
[Epoch 50] ogbg-moltoxcast: 0.730913 val loss: 0.206347
[Epoch 50] ogbg-moltoxcast: 0.744057 test loss: 0.206845
[Epoch 51; Iter    10/  172] train: loss: 0.1360705
[Epoch 51; Iter    40/  172] train: loss: 0.1810801
[Epoch 51; Iter    70/  172] train: loss: 0.1515409
[Epoch 51; Iter   100/  172] train: loss: 0.1077167
[Epoch 51; Iter   130/  172] train: loss: 0.2285740
[Epoch 51; Iter   160/  172] train: loss: 0.1520635
[Epoch 51] ogbg-moltoxcast: 0.732714 val loss: 0.204526
[Epoch 51] ogbg-moltoxcast: 0.744460 test loss: 0.204091
[Epoch 52; Iter    18/  172] train: loss: 0.1411624
[Epoch 52; Iter    48/  172] train: loss: 0.1210255
[Epoch 52; Iter    78/  172] train: loss: 0.1369500
[Epoch 52; Iter   108/  172] train: loss: 0.1428673
[Epoch 52; Iter   138/  172] train: loss: 0.1309879
[Epoch 52; Iter   168/  172] train: loss: 0.1273435
[Epoch 52] ogbg-moltoxcast: 0.728251 val loss: 0.207618
[Epoch 52] ogbg-moltoxcast: 0.743862 test loss: 0.205502
[Epoch 53; Iter    26/  172] train: loss: 0.1177745
[Epoch 53; Iter    56/  172] train: loss: 0.1838226
[Epoch 53; Iter    86/  172] train: loss: 0.1944453
[Epoch 53; Iter   116/  172] train: loss: 0.2312362
[Epoch 53; Iter   146/  172] train: loss: 0.2592321
[Epoch 53] ogbg-moltoxcast: 0.729744 val loss: 0.206425
[Epoch 53] ogbg-moltoxcast: 0.743887 test loss: 0.206122
[Epoch 54; Iter     4/  172] train: loss: 0.1469332
[Epoch 54; Iter    34/  172] train: loss: 0.1631760
[Epoch 54; Iter    64/  172] train: loss: 0.1193473
[Epoch 54; Iter    94/  172] train: loss: 0.1859032
[Epoch 54; Iter   124/  172] train: loss: 0.1454947
[Epoch 44; Iter    23/  229] train: loss: 0.1090665
[Epoch 44; Iter    53/  229] train: loss: 0.1857066
[Epoch 44; Iter    83/  229] train: loss: 0.1269163
[Epoch 44; Iter   113/  229] train: loss: 0.1732070
[Epoch 44; Iter   143/  229] train: loss: 0.1420309
[Epoch 44; Iter   173/  229] train: loss: 0.1075134
[Epoch 44; Iter   203/  229] train: loss: 0.1479428
[Epoch 44] ogbg-moltoxcast: 0.720789 val loss: 0.204223
[Epoch 44] ogbg-moltoxcast: 0.761147 test loss: 0.202202
[Epoch 45; Iter     4/  229] train: loss: 0.1435470
[Epoch 45; Iter    34/  229] train: loss: 0.1407620
[Epoch 45; Iter    64/  229] train: loss: 0.1250750
[Epoch 45; Iter    94/  229] train: loss: 0.1934422
[Epoch 45; Iter   124/  229] train: loss: 0.1269425
[Epoch 45; Iter   154/  229] train: loss: 0.1638998
[Epoch 45; Iter   184/  229] train: loss: 0.1797664
[Epoch 45; Iter   214/  229] train: loss: 0.1927224
[Epoch 45] ogbg-moltoxcast: 0.724778 val loss: 0.198692
[Epoch 45] ogbg-moltoxcast: 0.762533 test loss: 0.201602
[Epoch 46; Iter    15/  229] train: loss: 0.1938179
[Epoch 46; Iter    45/  229] train: loss: 0.1600942
[Epoch 46; Iter    75/  229] train: loss: 0.1827120
[Epoch 46; Iter   105/  229] train: loss: 0.1819652
[Epoch 46; Iter   135/  229] train: loss: 0.1689743
[Epoch 46; Iter   165/  229] train: loss: 0.1420740
[Epoch 46; Iter   195/  229] train: loss: 0.1325871
[Epoch 46; Iter   225/  229] train: loss: 0.1093294
[Epoch 46] ogbg-moltoxcast: 0.720331 val loss: 0.205571
[Epoch 46] ogbg-moltoxcast: 0.757074 test loss: 0.203331
[Epoch 47; Iter    26/  229] train: loss: 0.1857713
[Epoch 47; Iter    56/  229] train: loss: 0.1806307
[Epoch 47; Iter    86/  229] train: loss: 0.1801154
[Epoch 47; Iter   116/  229] train: loss: 0.2013303
[Epoch 47; Iter   146/  229] train: loss: 0.1087037
[Epoch 47; Iter   176/  229] train: loss: 0.2039677
[Epoch 47; Iter   206/  229] train: loss: 0.2103614
[Epoch 47] ogbg-moltoxcast: 0.730227 val loss: 0.199240
[Epoch 47] ogbg-moltoxcast: 0.767597 test loss: 0.201558
[Epoch 48; Iter     7/  229] train: loss: 0.1932592
[Epoch 48; Iter    37/  229] train: loss: 0.1517071
[Epoch 48; Iter    67/  229] train: loss: 0.1261563
[Epoch 48; Iter    97/  229] train: loss: 0.1974134
[Epoch 48; Iter   127/  229] train: loss: 0.1159061
[Epoch 48; Iter   157/  229] train: loss: 0.1520125
[Epoch 48; Iter   187/  229] train: loss: 0.1714846
[Epoch 48; Iter   217/  229] train: loss: 0.1801666
[Epoch 48] ogbg-moltoxcast: 0.732171 val loss: 0.198348
[Epoch 48] ogbg-moltoxcast: 0.765890 test loss: 0.200635
[Epoch 49; Iter    18/  229] train: loss: 0.1797657
[Epoch 49; Iter    48/  229] train: loss: 0.1549632
[Epoch 49; Iter    78/  229] train: loss: 0.1368256
[Epoch 49; Iter   108/  229] train: loss: 0.1945992
[Epoch 49; Iter   138/  229] train: loss: 0.1661454
[Epoch 49; Iter   168/  229] train: loss: 0.1327215
[Epoch 49; Iter   198/  229] train: loss: 0.1868740
[Epoch 49; Iter   228/  229] train: loss: 0.1750789
[Epoch 49] ogbg-moltoxcast: 0.732398 val loss: 0.196257
[Epoch 49] ogbg-moltoxcast: 0.766415 test loss: 0.199870
[Epoch 50; Iter    29/  229] train: loss: 0.1585857
[Epoch 50; Iter    59/  229] train: loss: 0.2038241
[Epoch 50; Iter    89/  229] train: loss: 0.1828460
[Epoch 50; Iter   119/  229] train: loss: 0.1698691
[Epoch 50; Iter   149/  229] train: loss: 0.1389431
[Epoch 50; Iter   179/  229] train: loss: 0.1409706
[Epoch 50; Iter   209/  229] train: loss: 0.1181509
[Epoch 50] ogbg-moltoxcast: 0.732884 val loss: 0.198075
[Epoch 50] ogbg-moltoxcast: 0.759719 test loss: 0.202115
[Epoch 51; Iter    10/  229] train: loss: 0.1636981
[Epoch 51; Iter    40/  229] train: loss: 0.1453487
[Epoch 51; Iter    70/  229] train: loss: 0.1288590
[Epoch 51; Iter   100/  229] train: loss: 0.1999134
[Epoch 51; Iter   130/  229] train: loss: 0.1647286
[Epoch 51; Iter   160/  229] train: loss: 0.1816828
[Epoch 51; Iter   190/  229] train: loss: 0.1377046
[Epoch 51; Iter   220/  229] train: loss: 0.1871548
[Epoch 51] ogbg-moltoxcast: 0.725958 val loss: 0.203686
[Epoch 51] ogbg-moltoxcast: 0.764064 test loss: 0.204009
[Epoch 52; Iter    21/  229] train: loss: 0.1352290
[Epoch 52; Iter    51/  229] train: loss: 0.1676785
[Epoch 52; Iter    81/  229] train: loss: 0.1241709
[Epoch 52; Iter   111/  229] train: loss: 0.1369317
[Epoch 52; Iter   141/  229] train: loss: 0.1867854
[Epoch 52; Iter   171/  229] train: loss: 0.1539655
[Epoch 52; Iter   201/  229] train: loss: 0.1292364
[Epoch 52] ogbg-moltoxcast: 0.731902 val loss: 0.202089
[Epoch 52] ogbg-moltoxcast: 0.760177 test loss: 0.202526
[Epoch 53; Iter     2/  229] train: loss: 0.1173187
[Epoch 53; Iter    32/  229] train: loss: 0.1543401
[Epoch 53; Iter    62/  229] train: loss: 0.1465808
[Epoch 53; Iter    92/  229] train: loss: 0.2492659
[Epoch 53; Iter   122/  229] train: loss: 0.1739719
[Epoch 53; Iter   152/  229] train: loss: 0.1403934
[Epoch 53; Iter   182/  229] train: loss: 0.1100994
[Epoch 53; Iter   212/  229] train: loss: 0.1605223
[Epoch 53] ogbg-moltoxcast: 0.730654 val loss: 0.201426
[Epoch 53] ogbg-moltoxcast: 0.760503 test loss: 0.206318
[Epoch 54; Iter    13/  229] train: loss: 0.1557398
[Epoch 54; Iter    43/  229] train: loss: 0.1073053
[Epoch 54; Iter    73/  229] train: loss: 0.1463975
[Epoch 54; Iter   103/  229] train: loss: 0.1884282
[Epoch 54; Iter   133/  229] train: loss: 0.1290980
[Epoch 54; Iter   163/  229] train: loss: 0.1315912
[Epoch 54; Iter   193/  229] train: loss: 0.0966155
[Epoch 54; Iter   223/  229] train: loss: 0.1671802
[Epoch 54] ogbg-moltoxcast: 0.733158 val loss: 0.198321
[Epoch 54] ogbg-moltoxcast: 0.767966 test loss: 0.202071
[Epoch 55; Iter    24/  229] train: loss: 0.1583921
[Epoch 55; Iter    54/  229] train: loss: 0.1729367
[Epoch 55; Iter    84/  229] train: loss: 0.1099100
[Epoch 55; Iter   114/  229] train: loss: 0.1278896
[Epoch 55; Iter   144/  229] train: loss: 0.1973448
[Epoch 55; Iter   174/  229] train: loss: 0.1299461
[Epoch 55; Iter   204/  229] train: loss: 0.1012004
[Epoch 55] ogbg-moltoxcast: 0.736227 val loss: 0.195977
[Epoch 55] ogbg-moltoxcast: 0.764346 test loss: 0.202409
[Epoch 56; Iter     5/  229] train: loss: 0.1395449
[Epoch 56; Iter    35/  229] train: loss: 0.1398106
[Epoch 56; Iter    65/  229] train: loss: 0.1678262
[Epoch 56; Iter    95/  229] train: loss: 0.1260130
[Epoch 56; Iter   125/  229] train: loss: 0.2200076
[Epoch 56; Iter   155/  229] train: loss: 0.1700191
[Epoch 56; Iter   185/  229] train: loss: 0.1886740
[Epoch 56; Iter   215/  229] train: loss: 0.1659646
[Epoch 56] ogbg-moltoxcast: 0.741238 val loss: 0.198638
[Epoch 56] ogbg-moltoxcast: 0.760169 test loss: 0.206342
[Epoch 57; Iter    16/  229] train: loss: 0.1602149
[Epoch 57; Iter    46/  229] train: loss: 0.1279015
[Epoch 57; Iter    76/  229] train: loss: 0.1546056
[Epoch 57; Iter   106/  229] train: loss: 0.1802052
[Epoch 57; Iter   136/  229] train: loss: 0.1740022
[Epoch 57; Iter   166/  229] train: loss: 0.2290955
[Epoch 57; Iter   196/  229] train: loss: 0.2156703
[Epoch 57; Iter   226/  229] train: loss: 0.1459783
[Epoch 57] ogbg-moltoxcast: 0.733799 val loss: 0.202022
[Epoch 57] ogbg-moltoxcast: 0.757520 test loss: 0.206141
[Epoch 58; Iter    27/  229] train: loss: 0.1727594
[Epoch 58; Iter    57/  229] train: loss: 0.1511054
[Epoch 58; Iter    87/  229] train: loss: 0.1376849
[Epoch 58; Iter   117/  229] train: loss: 0.1630214
[Epoch 58; Iter   147/  229] train: loss: 0.1629801
[Epoch 58; Iter   177/  229] train: loss: 0.1596582
[Epoch 58; Iter   207/  229] train: loss: 0.1127174
[Epoch 58] ogbg-moltoxcast: 0.729355 val loss: 0.205037
[Epoch 58] ogbg-moltoxcast: 0.760811 test loss: 0.203847
[Epoch 59; Iter     8/  229] train: loss: 0.2208144
[Epoch 59; Iter    38/  229] train: loss: 0.1844714
[Epoch 59; Iter    68/  229] train: loss: 0.1591168
[Epoch 59; Iter    98/  229] train: loss: 0.1339946
[Epoch 59; Iter   128/  229] train: loss: 0.1400018
[Epoch 59; Iter   158/  229] train: loss: 0.1795622
[Epoch 59; Iter   188/  229] train: loss: 0.1581067
[Epoch 59; Iter   218/  229] train: loss: 0.1857548
[Epoch 59] ogbg-moltoxcast: 0.731153 val loss: 0.204021
[Epoch 59] ogbg-moltoxcast: 0.762482 test loss: 0.206719
[Epoch 44; Iter    23/  229] train: loss: 0.1953409
[Epoch 44; Iter    53/  229] train: loss: 0.1624941
[Epoch 44; Iter    83/  229] train: loss: 0.1880549
[Epoch 44; Iter   113/  229] train: loss: 0.1722656
[Epoch 44; Iter   143/  229] train: loss: 0.1592981
[Epoch 44; Iter   173/  229] train: loss: 0.1665440
[Epoch 44; Iter   203/  229] train: loss: 0.1144291
[Epoch 44] ogbg-moltoxcast: 0.743724 val loss: 0.196897
[Epoch 44] ogbg-moltoxcast: 0.748463 test loss: 0.214557
[Epoch 45; Iter     4/  229] train: loss: 0.1185382
[Epoch 45; Iter    34/  229] train: loss: 0.1848164
[Epoch 45; Iter    64/  229] train: loss: 0.1803478
[Epoch 45; Iter    94/  229] train: loss: 0.1721266
[Epoch 45; Iter   124/  229] train: loss: 0.1649533
[Epoch 45; Iter   154/  229] train: loss: 0.2305209
[Epoch 45; Iter   184/  229] train: loss: 0.1190273
[Epoch 45; Iter   214/  229] train: loss: 0.1994471
[Epoch 45] ogbg-moltoxcast: 0.746079 val loss: 0.194921
[Epoch 45] ogbg-moltoxcast: 0.752176 test loss: 0.215871
[Epoch 46; Iter    15/  229] train: loss: 0.1452804
[Epoch 46; Iter    45/  229] train: loss: 0.1757190
[Epoch 46; Iter    75/  229] train: loss: 0.1305221
[Epoch 46; Iter   105/  229] train: loss: 0.1398199
[Epoch 46; Iter   135/  229] train: loss: 0.1133747
[Epoch 46; Iter   165/  229] train: loss: 0.1373464
[Epoch 46; Iter   195/  229] train: loss: 0.1349093
[Epoch 46; Iter   225/  229] train: loss: 0.2238813
[Epoch 46] ogbg-moltoxcast: 0.746644 val loss: 0.192551
[Epoch 46] ogbg-moltoxcast: 0.750543 test loss: 0.210448
[Epoch 47; Iter    26/  229] train: loss: 0.1071998
[Epoch 47; Iter    56/  229] train: loss: 0.1216347
[Epoch 47; Iter    86/  229] train: loss: 0.2116873
[Epoch 47; Iter   116/  229] train: loss: 0.2109814
[Epoch 47; Iter   146/  229] train: loss: 0.1537106
[Epoch 47; Iter   176/  229] train: loss: 0.1627759
[Epoch 47; Iter   206/  229] train: loss: 0.1825492
[Epoch 47] ogbg-moltoxcast: 0.748057 val loss: 0.194317
[Epoch 47] ogbg-moltoxcast: 0.753786 test loss: 0.213788
[Epoch 48; Iter     7/  229] train: loss: 0.2033653
[Epoch 48; Iter    37/  229] train: loss: 0.1694134
[Epoch 48; Iter    67/  229] train: loss: 0.2371170
[Epoch 48; Iter    97/  229] train: loss: 0.1301671
[Epoch 48; Iter   127/  229] train: loss: 0.2105697
[Epoch 48; Iter   157/  229] train: loss: 0.1674204
[Epoch 48; Iter   187/  229] train: loss: 0.1591367
[Epoch 48; Iter   217/  229] train: loss: 0.1738591
[Epoch 48] ogbg-moltoxcast: 0.750542 val loss: 0.191690
[Epoch 48] ogbg-moltoxcast: 0.756727 test loss: 0.207288
[Epoch 49; Iter    18/  229] train: loss: 0.1421634
[Epoch 49; Iter    48/  229] train: loss: 0.1280707
[Epoch 49; Iter    78/  229] train: loss: 0.2262690
[Epoch 49; Iter   108/  229] train: loss: 0.1196920
[Epoch 49; Iter   138/  229] train: loss: 0.1833890
[Epoch 49; Iter   168/  229] train: loss: 0.1967150
[Epoch 49; Iter   198/  229] train: loss: 0.1260304
[Epoch 49; Iter   228/  229] train: loss: 0.1808910
[Epoch 49] ogbg-moltoxcast: 0.746029 val loss: 0.195245
[Epoch 49] ogbg-moltoxcast: 0.757588 test loss: 0.208353
[Epoch 50; Iter    29/  229] train: loss: 0.1657272
[Epoch 50; Iter    59/  229] train: loss: 0.1623165
[Epoch 50; Iter    89/  229] train: loss: 0.1931956
[Epoch 50; Iter   119/  229] train: loss: 0.1382331
[Epoch 50; Iter   149/  229] train: loss: 0.0948704
[Epoch 50; Iter   179/  229] train: loss: 0.1297537
[Epoch 50; Iter   209/  229] train: loss: 0.1963354
[Epoch 50] ogbg-moltoxcast: 0.744551 val loss: 0.193134
[Epoch 50] ogbg-moltoxcast: 0.757560 test loss: 0.209846
[Epoch 51; Iter    10/  229] train: loss: 0.1689967
[Epoch 51; Iter    40/  229] train: loss: 0.1104621
[Epoch 51; Iter    70/  229] train: loss: 0.1594513
[Epoch 51; Iter   100/  229] train: loss: 0.2016070
[Epoch 51; Iter   130/  229] train: loss: 0.2095744
[Epoch 51; Iter   160/  229] train: loss: 0.1232457
[Epoch 51; Iter   190/  229] train: loss: 0.1316353
[Epoch 51; Iter   220/  229] train: loss: 0.1676788
[Epoch 51] ogbg-moltoxcast: 0.745083 val loss: 0.195203
[Epoch 51] ogbg-moltoxcast: 0.760441 test loss: 0.210243
[Epoch 52; Iter    21/  229] train: loss: 0.1378791
[Epoch 52; Iter    51/  229] train: loss: 0.1587746
[Epoch 52; Iter    81/  229] train: loss: 0.1120405
[Epoch 52; Iter   111/  229] train: loss: 0.1551765
[Epoch 52; Iter   141/  229] train: loss: 0.1596559
[Epoch 52; Iter   171/  229] train: loss: 0.1344062
[Epoch 52; Iter   201/  229] train: loss: 0.1644615
[Epoch 52] ogbg-moltoxcast: 0.748480 val loss: 0.194464
[Epoch 52] ogbg-moltoxcast: 0.755555 test loss: 0.212771
[Epoch 53; Iter     2/  229] train: loss: 0.1539252
[Epoch 53; Iter    32/  229] train: loss: 0.1349052
[Epoch 53; Iter    62/  229] train: loss: 0.2613415
[Epoch 53; Iter    92/  229] train: loss: 0.0909955
[Epoch 53; Iter   122/  229] train: loss: 0.1558014
[Epoch 53; Iter   152/  229] train: loss: 0.1501465
[Epoch 53; Iter   182/  229] train: loss: 0.0966384
[Epoch 53; Iter   212/  229] train: loss: 0.1866320
[Epoch 53] ogbg-moltoxcast: 0.743004 val loss: 0.196779
[Epoch 53] ogbg-moltoxcast: 0.757831 test loss: 0.211186
[Epoch 54; Iter    13/  229] train: loss: 0.1420951
[Epoch 54; Iter    43/  229] train: loss: 0.1720087
[Epoch 54; Iter    73/  229] train: loss: 0.1822853
[Epoch 54; Iter   103/  229] train: loss: 0.1219022
[Epoch 54; Iter   133/  229] train: loss: 0.1633937
[Epoch 54; Iter   163/  229] train: loss: 0.2397853
[Epoch 54; Iter   193/  229] train: loss: 0.1408105
[Epoch 54; Iter   223/  229] train: loss: 0.1509013
[Epoch 54] ogbg-moltoxcast: 0.745815 val loss: 0.193280
[Epoch 54] ogbg-moltoxcast: 0.754038 test loss: 0.208357
[Epoch 55; Iter    24/  229] train: loss: 0.1832961
[Epoch 55; Iter    54/  229] train: loss: 0.1422527
[Epoch 55; Iter    84/  229] train: loss: 0.0921708
[Epoch 55; Iter   114/  229] train: loss: 0.2055216
[Epoch 55; Iter   144/  229] train: loss: 0.1537347
[Epoch 55; Iter   174/  229] train: loss: 0.2051800
[Epoch 55; Iter   204/  229] train: loss: 0.1644488
[Epoch 55] ogbg-moltoxcast: 0.748633 val loss: 0.195727
[Epoch 55] ogbg-moltoxcast: 0.756805 test loss: 0.267759
[Epoch 56; Iter     5/  229] train: loss: 0.1751737
[Epoch 56; Iter    35/  229] train: loss: 0.1391794
[Epoch 56; Iter    65/  229] train: loss: 0.0986496
[Epoch 56; Iter    95/  229] train: loss: 0.1370285
[Epoch 56; Iter   125/  229] train: loss: 0.1431922
[Epoch 56; Iter   155/  229] train: loss: 0.1396538
[Epoch 56; Iter   185/  229] train: loss: 0.1727936
[Epoch 56; Iter   215/  229] train: loss: 0.1395122
[Epoch 56] ogbg-moltoxcast: 0.747666 val loss: 0.194709
[Epoch 56] ogbg-moltoxcast: 0.758420 test loss: 0.210949
[Epoch 57; Iter    16/  229] train: loss: 0.1917732
[Epoch 57; Iter    46/  229] train: loss: 0.1872229
[Epoch 57; Iter    76/  229] train: loss: 0.1197021
[Epoch 57; Iter   106/  229] train: loss: 0.1254680
[Epoch 57; Iter   136/  229] train: loss: 0.2265381
[Epoch 57; Iter   166/  229] train: loss: 0.2367564
[Epoch 57; Iter   196/  229] train: loss: 0.0986618
[Epoch 57; Iter   226/  229] train: loss: 0.1120966
[Epoch 57] ogbg-moltoxcast: 0.739749 val loss: 0.205042
[Epoch 57] ogbg-moltoxcast: 0.756607 test loss: 0.283194
[Epoch 58; Iter    27/  229] train: loss: 0.1171211
[Epoch 58; Iter    57/  229] train: loss: 0.2020086
[Epoch 58; Iter    87/  229] train: loss: 0.1418278
[Epoch 58; Iter   117/  229] train: loss: 0.1860074
[Epoch 58; Iter   147/  229] train: loss: 0.1822602
[Epoch 58; Iter   177/  229] train: loss: 0.1430376
[Epoch 58; Iter   207/  229] train: loss: 0.1571117
[Epoch 58] ogbg-moltoxcast: 0.745313 val loss: 0.194262
[Epoch 58] ogbg-moltoxcast: 0.751532 test loss: 0.209669
[Epoch 59; Iter     8/  229] train: loss: 0.1302522
[Epoch 59; Iter    38/  229] train: loss: 0.1301361
[Epoch 59; Iter    68/  229] train: loss: 0.1755366
[Epoch 59; Iter    98/  229] train: loss: 0.1257845
[Epoch 59; Iter   128/  229] train: loss: 0.1571269
[Epoch 59; Iter   158/  229] train: loss: 0.1619989
[Epoch 59; Iter   188/  229] train: loss: 0.1156684
[Epoch 59; Iter   218/  229] train: loss: 0.2526762
[Epoch 59] ogbg-moltoxcast: 0.741652 val loss: 0.196378
[Epoch 59] ogbg-moltoxcast: 0.748697 test loss: 0.226112
[Epoch 44; Iter    23/  229] train: loss: 0.1811948
[Epoch 44; Iter    53/  229] train: loss: 0.1456985
[Epoch 44; Iter    83/  229] train: loss: 0.1058761
[Epoch 44; Iter   113/  229] train: loss: 0.2102806
[Epoch 44; Iter   143/  229] train: loss: 0.1546092
[Epoch 44; Iter   173/  229] train: loss: 0.1006876
[Epoch 44; Iter   203/  229] train: loss: 0.1501887
[Epoch 44] ogbg-moltoxcast: 0.736784 val loss: 0.194034
[Epoch 44] ogbg-moltoxcast: 0.749264 test loss: 0.229653
[Epoch 45; Iter     4/  229] train: loss: 0.1911594
[Epoch 45; Iter    34/  229] train: loss: 0.1511317
[Epoch 45; Iter    64/  229] train: loss: 0.1064511
[Epoch 45; Iter    94/  229] train: loss: 0.2309065
[Epoch 45; Iter   124/  229] train: loss: 0.1600219
[Epoch 45; Iter   154/  229] train: loss: 0.1782202
[Epoch 45; Iter   184/  229] train: loss: 0.1652950
[Epoch 45; Iter   214/  229] train: loss: 0.1640701
[Epoch 45] ogbg-moltoxcast: 0.734449 val loss: 0.194497
[Epoch 45] ogbg-moltoxcast: 0.748527 test loss: 0.208378
[Epoch 46; Iter    15/  229] train: loss: 0.1703297
[Epoch 46; Iter    45/  229] train: loss: 0.1549336
[Epoch 46; Iter    75/  229] train: loss: 0.1199827
[Epoch 46; Iter   105/  229] train: loss: 0.1707990
[Epoch 46; Iter   135/  229] train: loss: 0.1492308
[Epoch 46; Iter   165/  229] train: loss: 0.1905724
[Epoch 46; Iter   195/  229] train: loss: 0.1655803
[Epoch 46; Iter   225/  229] train: loss: 0.1475477
[Epoch 46] ogbg-moltoxcast: 0.739249 val loss: 0.195892
[Epoch 46] ogbg-moltoxcast: 0.751346 test loss: 0.215784
[Epoch 47; Iter    26/  229] train: loss: 0.1958473
[Epoch 47; Iter    56/  229] train: loss: 0.1604134
[Epoch 47; Iter    86/  229] train: loss: 0.1949615
[Epoch 47; Iter   116/  229] train: loss: 0.1283784
[Epoch 47; Iter   146/  229] train: loss: 0.1013017
[Epoch 47; Iter   176/  229] train: loss: 0.1821423
[Epoch 47; Iter   206/  229] train: loss: 0.1591974
[Epoch 47] ogbg-moltoxcast: 0.741318 val loss: 0.198780
[Epoch 47] ogbg-moltoxcast: 0.747941 test loss: 0.216803
[Epoch 48; Iter     7/  229] train: loss: 0.2048960
[Epoch 48; Iter    37/  229] train: loss: 0.1505182
[Epoch 48; Iter    67/  229] train: loss: 0.1221127
[Epoch 48; Iter    97/  229] train: loss: 0.1881701
[Epoch 48; Iter   127/  229] train: loss: 0.1602509
[Epoch 48; Iter   157/  229] train: loss: 0.1949704
[Epoch 48; Iter   187/  229] train: loss: 0.1446692
[Epoch 48; Iter   217/  229] train: loss: 0.1240614
[Epoch 48] ogbg-moltoxcast: 0.738091 val loss: 0.199997
[Epoch 48] ogbg-moltoxcast: 0.748764 test loss: 0.212297
[Epoch 49; Iter    18/  229] train: loss: 0.1952703
[Epoch 49; Iter    48/  229] train: loss: 0.1243794
[Epoch 49; Iter    78/  229] train: loss: 0.1505875
[Epoch 49; Iter   108/  229] train: loss: 0.1489710
[Epoch 49; Iter   138/  229] train: loss: 0.1723793
[Epoch 49; Iter   168/  229] train: loss: 0.2529143
[Epoch 49; Iter   198/  229] train: loss: 0.1286259
[Epoch 49; Iter   228/  229] train: loss: 0.1872436
[Epoch 49] ogbg-moltoxcast: 0.735334 val loss: 0.197695
[Epoch 49] ogbg-moltoxcast: 0.747838 test loss: 0.211300
[Epoch 50; Iter    29/  229] train: loss: 0.1915453
[Epoch 50; Iter    59/  229] train: loss: 0.1410576
[Epoch 50; Iter    89/  229] train: loss: 0.1745367
[Epoch 50; Iter   119/  229] train: loss: 0.1731445
[Epoch 50; Iter   149/  229] train: loss: 0.1414014
[Epoch 50; Iter   179/  229] train: loss: 0.1752105
[Epoch 50; Iter   209/  229] train: loss: 0.1343084
[Epoch 50] ogbg-moltoxcast: 0.741673 val loss: 0.200422
[Epoch 50] ogbg-moltoxcast: 0.752260 test loss: 0.213063
[Epoch 51; Iter    10/  229] train: loss: 0.1554124
[Epoch 51; Iter    40/  229] train: loss: 0.1460754
[Epoch 51; Iter    70/  229] train: loss: 0.1124623
[Epoch 51; Iter   100/  229] train: loss: 0.2151545
[Epoch 51; Iter   130/  229] train: loss: 0.1616575
[Epoch 51; Iter   160/  229] train: loss: 0.1966413
[Epoch 51; Iter   190/  229] train: loss: 0.1591612
[Epoch 51; Iter   220/  229] train: loss: 0.1312851
[Epoch 51] ogbg-moltoxcast: 0.732835 val loss: 0.203052
[Epoch 51] ogbg-moltoxcast: 0.742871 test loss: 0.215887
[Epoch 52; Iter    21/  229] train: loss: 0.1901533
[Epoch 52; Iter    51/  229] train: loss: 0.1319832
[Epoch 52; Iter    81/  229] train: loss: 0.1869433
[Epoch 52; Iter   111/  229] train: loss: 0.1617016
[Epoch 52; Iter   141/  229] train: loss: 0.1741520
[Epoch 52; Iter   171/  229] train: loss: 0.1625729
[Epoch 52; Iter   201/  229] train: loss: 0.1112302
[Epoch 52] ogbg-moltoxcast: 0.732801 val loss: 0.197124
[Epoch 52] ogbg-moltoxcast: 0.750260 test loss: 0.207329
[Epoch 53; Iter     2/  229] train: loss: 0.1754235
[Epoch 53; Iter    32/  229] train: loss: 0.1862104
[Epoch 53; Iter    62/  229] train: loss: 0.1762674
[Epoch 53; Iter    92/  229] train: loss: 0.1665472
[Epoch 53; Iter   122/  229] train: loss: 0.1932304
[Epoch 53; Iter   152/  229] train: loss: 0.1210755
[Epoch 53; Iter   182/  229] train: loss: 0.1367994
[Epoch 53; Iter   212/  229] train: loss: 0.1149678
[Epoch 53] ogbg-moltoxcast: 0.742359 val loss: 0.198371
[Epoch 53] ogbg-moltoxcast: 0.745093 test loss: 0.214697
[Epoch 54; Iter    13/  229] train: loss: 0.1543572
[Epoch 54; Iter    43/  229] train: loss: 0.1640649
[Epoch 54; Iter    73/  229] train: loss: 0.1452866
[Epoch 54; Iter   103/  229] train: loss: 0.2123005
[Epoch 54; Iter   133/  229] train: loss: 0.1930377
[Epoch 54; Iter   163/  229] train: loss: 0.1358255
[Epoch 54; Iter   193/  229] train: loss: 0.1301135
[Epoch 54; Iter   223/  229] train: loss: 0.1189441
[Epoch 54] ogbg-moltoxcast: 0.750096 val loss: 0.195758
[Epoch 54] ogbg-moltoxcast: 0.752628 test loss: 0.208446
[Epoch 55; Iter    24/  229] train: loss: 0.1545974
[Epoch 55; Iter    54/  229] train: loss: 0.1875636
[Epoch 55; Iter    84/  229] train: loss: 0.1228990
[Epoch 55; Iter   114/  229] train: loss: 0.0949959
[Epoch 55; Iter   144/  229] train: loss: 0.1613939
[Epoch 55; Iter   174/  229] train: loss: 0.1599537
[Epoch 55; Iter   204/  229] train: loss: 0.1648596
[Epoch 55] ogbg-moltoxcast: 0.741265 val loss: 0.199094
[Epoch 55] ogbg-moltoxcast: 0.750146 test loss: 0.212833
[Epoch 56; Iter     5/  229] train: loss: 0.2251897
[Epoch 56; Iter    35/  229] train: loss: 0.2467041
[Epoch 56; Iter    65/  229] train: loss: 0.1632838
[Epoch 56; Iter    95/  229] train: loss: 0.1399033
[Epoch 56; Iter   125/  229] train: loss: 0.1787029
[Epoch 56; Iter   155/  229] train: loss: 0.1111713
[Epoch 56; Iter   185/  229] train: loss: 0.1516289
[Epoch 56; Iter   215/  229] train: loss: 0.1581485
[Epoch 56] ogbg-moltoxcast: 0.741624 val loss: 0.196226
[Epoch 56] ogbg-moltoxcast: 0.746190 test loss: 0.210398
[Epoch 57; Iter    16/  229] train: loss: 0.1318465
[Epoch 57; Iter    46/  229] train: loss: 0.1941788
[Epoch 57; Iter    76/  229] train: loss: 0.1287623
[Epoch 57; Iter   106/  229] train: loss: 0.1172685
[Epoch 57; Iter   136/  229] train: loss: 0.1813776
[Epoch 57; Iter   166/  229] train: loss: 0.1889650
[Epoch 57; Iter   196/  229] train: loss: 0.1357508
[Epoch 57; Iter   226/  229] train: loss: 0.1525933
[Epoch 57] ogbg-moltoxcast: 0.741579 val loss: 0.199126
[Epoch 57] ogbg-moltoxcast: 0.745922 test loss: 0.209494
[Epoch 58; Iter    27/  229] train: loss: 0.1371384
[Epoch 58; Iter    57/  229] train: loss: 0.0947014
[Epoch 58; Iter    87/  229] train: loss: 0.1458051
[Epoch 58; Iter   117/  229] train: loss: 0.2289801
[Epoch 58; Iter   147/  229] train: loss: 0.1911918
[Epoch 58; Iter   177/  229] train: loss: 0.1089596
[Epoch 58; Iter   207/  229] train: loss: 0.1598341
[Epoch 58] ogbg-moltoxcast: 0.746530 val loss: 0.199085
[Epoch 58] ogbg-moltoxcast: 0.756867 test loss: 0.210411
[Epoch 59; Iter     8/  229] train: loss: 0.1901304
[Epoch 59; Iter    38/  229] train: loss: 0.0877811
[Epoch 59; Iter    68/  229] train: loss: 0.1291425
[Epoch 59; Iter    98/  229] train: loss: 0.1198505
[Epoch 59; Iter   128/  229] train: loss: 0.1796666
[Epoch 59; Iter   158/  229] train: loss: 0.1467953
[Epoch 59; Iter   188/  229] train: loss: 0.1355080
[Epoch 59; Iter   218/  229] train: loss: 0.1338823
[Epoch 59] ogbg-moltoxcast: 0.747320 val loss: 0.197007
[Epoch 59] ogbg-moltoxcast: 0.748805 test loss: 0.218654
[Epoch 48; Iter   183/  201] train: loss: 0.1053049
[Epoch 48] ogbg-moltoxcast: 0.741513 val loss: 0.205615
[Epoch 48] ogbg-moltoxcast: 0.742059 test loss: 0.207379
[Epoch 49; Iter    12/  201] train: loss: 0.1527697
[Epoch 49; Iter    42/  201] train: loss: 0.1945387
[Epoch 49; Iter    72/  201] train: loss: 0.1793647
[Epoch 49; Iter   102/  201] train: loss: 0.2090189
[Epoch 49; Iter   132/  201] train: loss: 0.0990822
[Epoch 49; Iter   162/  201] train: loss: 0.1472826
[Epoch 49; Iter   192/  201] train: loss: 0.1952108
[Epoch 49] ogbg-moltoxcast: 0.731199 val loss: 0.207556
[Epoch 49] ogbg-moltoxcast: 0.745277 test loss: 0.205387
[Epoch 50; Iter    21/  201] train: loss: 0.0818561
[Epoch 50; Iter    51/  201] train: loss: 0.1638120
[Epoch 50; Iter    81/  201] train: loss: 0.1639636
[Epoch 50; Iter   111/  201] train: loss: 0.1678848
[Epoch 50; Iter   141/  201] train: loss: 0.1444223
[Epoch 50; Iter   171/  201] train: loss: 0.1207738
[Epoch 50; Iter   201/  201] train: loss: 0.3440961
[Epoch 50] ogbg-moltoxcast: 0.730785 val loss: 0.218965
[Epoch 50] ogbg-moltoxcast: 0.736829 test loss: 0.221073
[Epoch 51; Iter    30/  201] train: loss: 0.1672327
[Epoch 51; Iter    60/  201] train: loss: 0.1977990
[Epoch 51; Iter    90/  201] train: loss: 0.1809960
[Epoch 51; Iter   120/  201] train: loss: 0.1940746
[Epoch 51; Iter   150/  201] train: loss: 0.1275862
[Epoch 51; Iter   180/  201] train: loss: 0.1570623
[Epoch 51] ogbg-moltoxcast: 0.736504 val loss: 0.206729
[Epoch 51] ogbg-moltoxcast: 0.750596 test loss: 0.200849
[Epoch 52; Iter     9/  201] train: loss: 0.1315388
[Epoch 52; Iter    39/  201] train: loss: 0.1644444
[Epoch 52; Iter    69/  201] train: loss: 0.1498046
[Epoch 52; Iter    99/  201] train: loss: 0.1575986
[Epoch 52; Iter   129/  201] train: loss: 0.1514342
[Epoch 52; Iter   159/  201] train: loss: 0.1262322
[Epoch 52; Iter   189/  201] train: loss: 0.1579050
[Epoch 52] ogbg-moltoxcast: 0.734339 val loss: 0.206278
[Epoch 52] ogbg-moltoxcast: 0.749431 test loss: 0.206515
[Epoch 53; Iter    18/  201] train: loss: 0.1306347
[Epoch 53; Iter    48/  201] train: loss: 0.1366162
[Epoch 53; Iter    78/  201] train: loss: 0.1172540
[Epoch 53; Iter   108/  201] train: loss: 0.1573773
[Epoch 53; Iter   138/  201] train: loss: 0.1815409
[Epoch 53; Iter   168/  201] train: loss: 0.1356512
[Epoch 53; Iter   198/  201] train: loss: 0.1486558
[Epoch 53] ogbg-moltoxcast: 0.737554 val loss: 0.206819
[Epoch 53] ogbg-moltoxcast: 0.750212 test loss: 0.202498
[Epoch 54; Iter    27/  201] train: loss: 0.2054810
[Epoch 54; Iter    57/  201] train: loss: 0.1360918
[Epoch 54; Iter    87/  201] train: loss: 0.1335749
[Epoch 54; Iter   117/  201] train: loss: 0.1795577
[Epoch 54; Iter   147/  201] train: loss: 0.1584069
[Epoch 54; Iter   177/  201] train: loss: 0.1430855
[Epoch 54] ogbg-moltoxcast: 0.728066 val loss: 0.212813
[Epoch 54] ogbg-moltoxcast: 0.749273 test loss: 0.205964
[Epoch 55; Iter     6/  201] train: loss: 0.1403429
[Epoch 55; Iter    36/  201] train: loss: 0.1894421
[Epoch 55; Iter    66/  201] train: loss: 0.1302124
[Epoch 55; Iter    96/  201] train: loss: 0.1414786
[Epoch 55; Iter   126/  201] train: loss: 0.2422754
[Epoch 55; Iter   156/  201] train: loss: 0.1372003
[Epoch 55; Iter   186/  201] train: loss: 0.1962673
[Epoch 55] ogbg-moltoxcast: 0.729117 val loss: 0.209760
[Epoch 55] ogbg-moltoxcast: 0.752202 test loss: 0.201408
[Epoch 56; Iter    15/  201] train: loss: 0.1234624
[Epoch 56; Iter    45/  201] train: loss: 0.1706050
[Epoch 56; Iter    75/  201] train: loss: 0.1204012
[Epoch 56; Iter   105/  201] train: loss: 0.1494385
[Epoch 56; Iter   135/  201] train: loss: 0.1261427
[Epoch 56; Iter   165/  201] train: loss: 0.1566373
[Epoch 56; Iter   195/  201] train: loss: 0.1511527
[Epoch 56] ogbg-moltoxcast: 0.731433 val loss: 0.212371
[Epoch 56] ogbg-moltoxcast: 0.745468 test loss: 0.208423
[Epoch 57; Iter    24/  201] train: loss: 0.1987247
[Epoch 57; Iter    54/  201] train: loss: 0.2000668
[Epoch 57; Iter    84/  201] train: loss: 0.2138487
[Epoch 57; Iter   114/  201] train: loss: 0.1414353
[Epoch 57; Iter   144/  201] train: loss: 0.1310722
[Epoch 57; Iter   174/  201] train: loss: 0.1465798
[Epoch 57] ogbg-moltoxcast: 0.737687 val loss: 0.205895
[Epoch 57] ogbg-moltoxcast: 0.745834 test loss: 0.205935
[Epoch 58; Iter     3/  201] train: loss: 0.1611603
[Epoch 58; Iter    33/  201] train: loss: 0.1200926
[Epoch 58; Iter    63/  201] train: loss: 0.2001528
[Epoch 58; Iter    93/  201] train: loss: 0.1597020
[Epoch 58; Iter   123/  201] train: loss: 0.1658563
[Epoch 58; Iter   153/  201] train: loss: 0.2171603
[Epoch 58; Iter   183/  201] train: loss: 0.1473376
[Epoch 58] ogbg-moltoxcast: 0.735695 val loss: 0.208992
[Epoch 58] ogbg-moltoxcast: 0.748861 test loss: 0.203441
[Epoch 59; Iter    12/  201] train: loss: 0.1801958
[Epoch 59; Iter    42/  201] train: loss: 0.2026359
[Epoch 59; Iter    72/  201] train: loss: 0.1070248
[Epoch 59; Iter   102/  201] train: loss: 0.1656563
[Epoch 59; Iter   132/  201] train: loss: 0.1117950
[Epoch 59; Iter   162/  201] train: loss: 0.0994793
[Epoch 59; Iter   192/  201] train: loss: 0.1120826
[Epoch 59] ogbg-moltoxcast: 0.728208 val loss: 0.211189
[Epoch 59] ogbg-moltoxcast: 0.742331 test loss: 0.205494
[Epoch 60; Iter    21/  201] train: loss: 0.1330182
[Epoch 60; Iter    51/  201] train: loss: 0.1190544
[Epoch 60; Iter    81/  201] train: loss: 0.2004958
[Epoch 60; Iter   111/  201] train: loss: 0.1315266
[Epoch 60; Iter   141/  201] train: loss: 0.1865526
[Epoch 60; Iter   171/  201] train: loss: 0.1568986
[Epoch 60; Iter   201/  201] train: loss: 0.5218244
[Epoch 60] ogbg-moltoxcast: 0.730466 val loss: 0.210282
[Epoch 60] ogbg-moltoxcast: 0.747639 test loss: 0.206125
[Epoch 61; Iter    30/  201] train: loss: 0.2486195
[Epoch 61; Iter    60/  201] train: loss: 0.1181619
[Epoch 61; Iter    90/  201] train: loss: 0.2098642
[Epoch 61; Iter   120/  201] train: loss: 0.1781186
[Epoch 61; Iter   150/  201] train: loss: 0.1163400
[Epoch 61; Iter   180/  201] train: loss: 0.1478101
[Epoch 61] ogbg-moltoxcast: 0.730257 val loss: 0.210269
[Epoch 61] ogbg-moltoxcast: 0.745928 test loss: 0.205480
[Epoch 62; Iter     9/  201] train: loss: 0.1566825
[Epoch 62; Iter    39/  201] train: loss: 0.1471448
[Epoch 62; Iter    69/  201] train: loss: 0.1736540
[Epoch 62; Iter    99/  201] train: loss: 0.1088884
[Epoch 62; Iter   129/  201] train: loss: 0.1279990
[Epoch 62; Iter   159/  201] train: loss: 0.1671758
[Epoch 62; Iter   189/  201] train: loss: 0.1438407
[Epoch 62] ogbg-moltoxcast: 0.736535 val loss: 0.208660
[Epoch 62] ogbg-moltoxcast: 0.751680 test loss: 0.203845
[Epoch 63; Iter    18/  201] train: loss: 0.1064856
[Epoch 63; Iter    48/  201] train: loss: 0.1258239
[Epoch 63; Iter    78/  201] train: loss: 0.1371242
[Epoch 63; Iter   108/  201] train: loss: 0.1508711
[Epoch 63; Iter   138/  201] train: loss: 0.1482465
[Epoch 63; Iter   168/  201] train: loss: 0.1608764
[Epoch 63; Iter   198/  201] train: loss: 0.1177807
[Epoch 63] ogbg-moltoxcast: 0.737073 val loss: 0.206633
[Epoch 63] ogbg-moltoxcast: 0.752221 test loss: 0.201872
[Epoch 64; Iter    27/  201] train: loss: 0.1527048
[Epoch 64; Iter    57/  201] train: loss: 0.1184429
[Epoch 64; Iter    87/  201] train: loss: 0.1656743
[Epoch 64; Iter   117/  201] train: loss: 0.1622634
[Epoch 64; Iter   147/  201] train: loss: 0.2219642
[Epoch 64; Iter   177/  201] train: loss: 0.1224611
[Epoch 64] ogbg-moltoxcast: 0.736720 val loss: 0.209464
[Epoch 64] ogbg-moltoxcast: 0.753869 test loss: 0.203894
[Epoch 65; Iter     6/  201] train: loss: 0.1691588
[Epoch 65; Iter    36/  201] train: loss: 0.1768854
[Epoch 65; Iter    66/  201] train: loss: 0.1039762
[Epoch 65; Iter    96/  201] train: loss: 0.1333067
[Epoch 65; Iter   126/  201] train: loss: 0.1919165
[Epoch 65; Iter   156/  201] train: loss: 0.1316930
[Epoch 65; Iter   186/  201] train: loss: 0.1370735
[Epoch 65] ogbg-moltoxcast: 0.736148 val loss: 0.209580
[Epoch 65] ogbg-moltoxcast: 0.752168 test loss: 0.204157
[Epoch 66; Iter    15/  201] train: loss: 0.2107766
[Epoch 66; Iter    45/  201] train: loss: 0.1354744
[Epoch 66; Iter    75/  201] train: loss: 0.1599424
[Epoch 48; Iter   183/  201] train: loss: 0.1491777
[Epoch 48] ogbg-moltoxcast: 0.728927 val loss: 0.206833
[Epoch 48] ogbg-moltoxcast: 0.752185 test loss: 0.205393
[Epoch 49; Iter    12/  201] train: loss: 0.1614029
[Epoch 49; Iter    42/  201] train: loss: 0.1811646
[Epoch 49; Iter    72/  201] train: loss: 0.1221471
[Epoch 49; Iter   102/  201] train: loss: 0.1701842
[Epoch 49; Iter   132/  201] train: loss: 0.1204495
[Epoch 49; Iter   162/  201] train: loss: 0.1241830
[Epoch 49; Iter   192/  201] train: loss: 0.1463415
[Epoch 49] ogbg-moltoxcast: 0.731572 val loss: 0.206586
[Epoch 49] ogbg-moltoxcast: 0.740652 test loss: 0.211925
[Epoch 50; Iter    21/  201] train: loss: 0.1121255
[Epoch 50; Iter    51/  201] train: loss: 0.1267273
[Epoch 50; Iter    81/  201] train: loss: 0.1177493
[Epoch 50; Iter   111/  201] train: loss: 0.1279104
[Epoch 50; Iter   141/  201] train: loss: 0.1184623
[Epoch 50; Iter   171/  201] train: loss: 0.1282355
[Epoch 50; Iter   201/  201] train: loss: 0.1781419
[Epoch 50] ogbg-moltoxcast: 0.734383 val loss: 0.206078
[Epoch 50] ogbg-moltoxcast: 0.751230 test loss: 0.204921
[Epoch 51; Iter    30/  201] train: loss: 0.1489027
[Epoch 51; Iter    60/  201] train: loss: 0.1297307
[Epoch 51; Iter    90/  201] train: loss: 0.1664658
[Epoch 51; Iter   120/  201] train: loss: 0.1375636
[Epoch 51; Iter   150/  201] train: loss: 0.1190015
[Epoch 51; Iter   180/  201] train: loss: 0.1213998
[Epoch 51] ogbg-moltoxcast: 0.731821 val loss: 0.210838
[Epoch 51] ogbg-moltoxcast: 0.744253 test loss: 0.213812
[Epoch 52; Iter     9/  201] train: loss: 0.1634627
[Epoch 52; Iter    39/  201] train: loss: 0.1394278
[Epoch 52; Iter    69/  201] train: loss: 0.1984971
[Epoch 52; Iter    99/  201] train: loss: 0.1499064
[Epoch 52; Iter   129/  201] train: loss: 0.1928114
[Epoch 52; Iter   159/  201] train: loss: 0.1497176
[Epoch 52; Iter   189/  201] train: loss: 0.1495928
[Epoch 52] ogbg-moltoxcast: 0.727036 val loss: 0.213040
[Epoch 52] ogbg-moltoxcast: 0.748101 test loss: 0.209722
[Epoch 53; Iter    18/  201] train: loss: 0.1689472
[Epoch 53; Iter    48/  201] train: loss: 0.1081054
[Epoch 53; Iter    78/  201] train: loss: 0.1068622
[Epoch 53; Iter   108/  201] train: loss: 0.1247918
[Epoch 53; Iter   138/  201] train: loss: 0.1456772
[Epoch 53; Iter   168/  201] train: loss: 0.1402937
[Epoch 53; Iter   198/  201] train: loss: 0.1681116
[Epoch 53] ogbg-moltoxcast: 0.743673 val loss: 0.205638
[Epoch 53] ogbg-moltoxcast: 0.750374 test loss: 0.211796
[Epoch 54; Iter    27/  201] train: loss: 0.1503991
[Epoch 54; Iter    57/  201] train: loss: 0.1705766
[Epoch 54; Iter    87/  201] train: loss: 0.1476589
[Epoch 54; Iter   117/  201] train: loss: 0.1561476
[Epoch 54; Iter   147/  201] train: loss: 0.1497038
[Epoch 54; Iter   177/  201] train: loss: 0.1626771
[Epoch 54] ogbg-moltoxcast: 0.732877 val loss: 0.208175
[Epoch 54] ogbg-moltoxcast: 0.749304 test loss: 0.208779
[Epoch 55; Iter     6/  201] train: loss: 0.1615097
[Epoch 55; Iter    36/  201] train: loss: 0.1435300
[Epoch 55; Iter    66/  201] train: loss: 0.1866214
[Epoch 55; Iter    96/  201] train: loss: 0.1437518
[Epoch 55; Iter   126/  201] train: loss: 0.1573520
[Epoch 55; Iter   156/  201] train: loss: 0.1546867
[Epoch 55; Iter   186/  201] train: loss: 0.1508793
[Epoch 55] ogbg-moltoxcast: 0.737602 val loss: 0.208777
[Epoch 55] ogbg-moltoxcast: 0.750639 test loss: 0.209002
[Epoch 56; Iter    15/  201] train: loss: 0.1230383
[Epoch 56; Iter    45/  201] train: loss: 0.1613829
[Epoch 56; Iter    75/  201] train: loss: 0.1084125
[Epoch 56; Iter   105/  201] train: loss: 0.1779078
[Epoch 56; Iter   135/  201] train: loss: 0.1389424
[Epoch 56; Iter   165/  201] train: loss: 0.2030347
[Epoch 56; Iter   195/  201] train: loss: 0.1285516
[Epoch 56] ogbg-moltoxcast: 0.736196 val loss: 0.206593
[Epoch 56] ogbg-moltoxcast: 0.748266 test loss: 0.208228
[Epoch 57; Iter    24/  201] train: loss: 0.1649079
[Epoch 57; Iter    54/  201] train: loss: 0.1569083
[Epoch 57; Iter    84/  201] train: loss: 0.1193719
[Epoch 57; Iter   114/  201] train: loss: 0.1122214
[Epoch 57; Iter   144/  201] train: loss: 0.1391875
[Epoch 57; Iter   174/  201] train: loss: 0.1503351
[Epoch 57] ogbg-moltoxcast: 0.732518 val loss: 0.208000
[Epoch 57] ogbg-moltoxcast: 0.744144 test loss: 0.207176
[Epoch 58; Iter     3/  201] train: loss: 0.1878776
[Epoch 58; Iter    33/  201] train: loss: 0.1573751
[Epoch 58; Iter    63/  201] train: loss: 0.2018507
[Epoch 58; Iter    93/  201] train: loss: 0.1524487
[Epoch 58; Iter   123/  201] train: loss: 0.1022318
[Epoch 58; Iter   153/  201] train: loss: 0.1158627
[Epoch 58; Iter   183/  201] train: loss: 0.1006781
[Epoch 58] ogbg-moltoxcast: 0.743492 val loss: 0.204734
[Epoch 58] ogbg-moltoxcast: 0.752728 test loss: 0.205662
[Epoch 59; Iter    12/  201] train: loss: 0.1396275
[Epoch 59; Iter    42/  201] train: loss: 0.2104952
[Epoch 59; Iter    72/  201] train: loss: 0.1508160
[Epoch 59; Iter   102/  201] train: loss: 0.1573910
[Epoch 59; Iter   132/  201] train: loss: 0.1770625
[Epoch 59; Iter   162/  201] train: loss: 0.1623466
[Epoch 59; Iter   192/  201] train: loss: 0.1308849
[Epoch 59] ogbg-moltoxcast: 0.732185 val loss: 0.209909
[Epoch 59] ogbg-moltoxcast: 0.746362 test loss: 0.212998
[Epoch 60; Iter    21/  201] train: loss: 0.1470898
[Epoch 60; Iter    51/  201] train: loss: 0.1369151
[Epoch 60; Iter    81/  201] train: loss: 0.1662088
[Epoch 60; Iter   111/  201] train: loss: 0.1477816
[Epoch 60; Iter   141/  201] train: loss: 0.1285671
[Epoch 60; Iter   171/  201] train: loss: 0.0956641
[Epoch 60; Iter   201/  201] train: loss: 0.0856005
[Epoch 60] ogbg-moltoxcast: 0.737301 val loss: 0.207602
[Epoch 60] ogbg-moltoxcast: 0.752535 test loss: 0.208206
[Epoch 61; Iter    30/  201] train: loss: 0.0989440
[Epoch 61; Iter    60/  201] train: loss: 0.1475711
[Epoch 61; Iter    90/  201] train: loss: 0.2033524
[Epoch 61; Iter   120/  201] train: loss: 0.1411928
[Epoch 61; Iter   150/  201] train: loss: 0.1088445
[Epoch 61; Iter   180/  201] train: loss: 0.1679888
[Epoch 61] ogbg-moltoxcast: 0.740152 val loss: 0.204696
[Epoch 61] ogbg-moltoxcast: 0.749944 test loss: 0.206944
[Epoch 62; Iter     9/  201] train: loss: 0.1230676
[Epoch 62; Iter    39/  201] train: loss: 0.1676615
[Epoch 62; Iter    69/  201] train: loss: 0.1233315
[Epoch 62; Iter    99/  201] train: loss: 0.1473804
[Epoch 62; Iter   129/  201] train: loss: 0.1221790
[Epoch 62; Iter   159/  201] train: loss: 0.1391476
[Epoch 62; Iter   189/  201] train: loss: 0.1447623
[Epoch 62] ogbg-moltoxcast: 0.739440 val loss: 0.207651
[Epoch 62] ogbg-moltoxcast: 0.751066 test loss: 0.210514
[Epoch 63; Iter    18/  201] train: loss: 0.1912721
[Epoch 63; Iter    48/  201] train: loss: 0.1454855
[Epoch 63; Iter    78/  201] train: loss: 0.1724367
[Epoch 63; Iter   108/  201] train: loss: 0.1649313
[Epoch 63; Iter   138/  201] train: loss: 0.1728734
[Epoch 63; Iter   168/  201] train: loss: 0.1863021
[Epoch 63; Iter   198/  201] train: loss: 0.1671870
[Epoch 63] ogbg-moltoxcast: 0.730099 val loss: 0.211529
[Epoch 63] ogbg-moltoxcast: 0.744507 test loss: 0.216294
[Epoch 64; Iter    27/  201] train: loss: 0.1773247
[Epoch 64; Iter    57/  201] train: loss: 0.1891331
[Epoch 64; Iter    87/  201] train: loss: 0.1162363
[Epoch 64; Iter   117/  201] train: loss: 0.1533620
[Epoch 64; Iter   147/  201] train: loss: 0.1423278
[Epoch 64; Iter   177/  201] train: loss: 0.1493361
[Epoch 64] ogbg-moltoxcast: 0.739813 val loss: 0.206861
[Epoch 64] ogbg-moltoxcast: 0.749601 test loss: 0.211752
[Epoch 65; Iter     6/  201] train: loss: 0.1141561
[Epoch 65; Iter    36/  201] train: loss: 0.1623660
[Epoch 65; Iter    66/  201] train: loss: 0.1651754
[Epoch 65; Iter    96/  201] train: loss: 0.1683803
[Epoch 65; Iter   126/  201] train: loss: 0.1646763
[Epoch 65; Iter   156/  201] train: loss: 0.1052925
[Epoch 65; Iter   186/  201] train: loss: 0.1759781
[Epoch 65] ogbg-moltoxcast: 0.739583 val loss: 0.208970
[Epoch 65] ogbg-moltoxcast: 0.750491 test loss: 0.210254
[Epoch 66; Iter    15/  201] train: loss: 0.1244369
[Epoch 66; Iter    45/  201] train: loss: 0.1650597
[Epoch 66; Iter    75/  201] train: loss: 0.0858848
[Epoch 48; Iter   183/  201] train: loss: 0.1516639
[Epoch 48] ogbg-moltoxcast: 0.730083 val loss: 0.207605
[Epoch 48] ogbg-moltoxcast: 0.749774 test loss: 0.203603
[Epoch 49; Iter    12/  201] train: loss: 0.1680931
[Epoch 49; Iter    42/  201] train: loss: 0.1447564
[Epoch 49; Iter    72/  201] train: loss: 0.1082781
[Epoch 49; Iter   102/  201] train: loss: 0.1524434
[Epoch 49; Iter   132/  201] train: loss: 0.1809115
[Epoch 49; Iter   162/  201] train: loss: 0.1654592
[Epoch 49; Iter   192/  201] train: loss: 0.1001650
[Epoch 49] ogbg-moltoxcast: 0.734140 val loss: 0.207021
[Epoch 49] ogbg-moltoxcast: 0.754313 test loss: 0.201866
[Epoch 50; Iter    21/  201] train: loss: 0.1864235
[Epoch 50; Iter    51/  201] train: loss: 0.1727099
[Epoch 50; Iter    81/  201] train: loss: 0.1575017
[Epoch 50; Iter   111/  201] train: loss: 0.1514900
[Epoch 50; Iter   141/  201] train: loss: 0.2374599
[Epoch 50; Iter   171/  201] train: loss: 0.1807430
[Epoch 50; Iter   201/  201] train: loss: 0.2728292
[Epoch 50] ogbg-moltoxcast: 0.729944 val loss: 0.212441
[Epoch 50] ogbg-moltoxcast: 0.748886 test loss: 0.202250
[Epoch 51; Iter    30/  201] train: loss: 0.1623451
[Epoch 51; Iter    60/  201] train: loss: 0.1186725
[Epoch 51; Iter    90/  201] train: loss: 0.1946258
[Epoch 51; Iter   120/  201] train: loss: 0.1401384
[Epoch 51; Iter   150/  201] train: loss: 0.1969041
[Epoch 51; Iter   180/  201] train: loss: 0.2186844
[Epoch 51] ogbg-moltoxcast: 0.731939 val loss: 0.210590
[Epoch 51] ogbg-moltoxcast: 0.749686 test loss: 0.207761
[Epoch 52; Iter     9/  201] train: loss: 0.1572623
[Epoch 52; Iter    39/  201] train: loss: 0.1632785
[Epoch 52; Iter    69/  201] train: loss: 0.1571511
[Epoch 52; Iter    99/  201] train: loss: 0.1659752
[Epoch 52; Iter   129/  201] train: loss: 0.1222028
[Epoch 52; Iter   159/  201] train: loss: 0.1214203
[Epoch 52; Iter   189/  201] train: loss: 0.1549707
[Epoch 52] ogbg-moltoxcast: 0.735925 val loss: 0.206896
[Epoch 52] ogbg-moltoxcast: 0.747268 test loss: 0.205809
[Epoch 53; Iter    18/  201] train: loss: 0.1415279
[Epoch 53; Iter    48/  201] train: loss: 0.1418655
[Epoch 53; Iter    78/  201] train: loss: 0.1814328
[Epoch 53; Iter   108/  201] train: loss: 0.1639065
[Epoch 53; Iter   138/  201] train: loss: 0.1143431
[Epoch 53; Iter   168/  201] train: loss: 0.1616304
[Epoch 53; Iter   198/  201] train: loss: 0.2263984
[Epoch 53] ogbg-moltoxcast: 0.738442 val loss: 0.207402
[Epoch 53] ogbg-moltoxcast: 0.746312 test loss: 0.208744
[Epoch 54; Iter    27/  201] train: loss: 0.1578430
[Epoch 54; Iter    57/  201] train: loss: 0.1696481
[Epoch 54; Iter    87/  201] train: loss: 0.1667886
[Epoch 54; Iter   117/  201] train: loss: 0.1019999
[Epoch 54; Iter   147/  201] train: loss: 0.1296373
[Epoch 54; Iter   177/  201] train: loss: 0.1770311
[Epoch 54] ogbg-moltoxcast: 0.736696 val loss: 0.207257
[Epoch 54] ogbg-moltoxcast: 0.751120 test loss: 0.205257
[Epoch 55; Iter     6/  201] train: loss: 0.1048213
[Epoch 55; Iter    36/  201] train: loss: 0.1320433
[Epoch 55; Iter    66/  201] train: loss: 0.1906015
[Epoch 55; Iter    96/  201] train: loss: 0.1482979
[Epoch 55; Iter   126/  201] train: loss: 0.1608029
[Epoch 55; Iter   156/  201] train: loss: 0.1980986
[Epoch 55; Iter   186/  201] train: loss: 0.2093337
[Epoch 55] ogbg-moltoxcast: 0.737212 val loss: 0.207023
[Epoch 55] ogbg-moltoxcast: 0.750695 test loss: 0.202390
[Epoch 56; Iter    15/  201] train: loss: 0.1809912
[Epoch 56; Iter    45/  201] train: loss: 0.2044538
[Epoch 56; Iter    75/  201] train: loss: 0.2282524
[Epoch 56; Iter   105/  201] train: loss: 0.1975983
[Epoch 56; Iter   135/  201] train: loss: 0.1694268
[Epoch 56; Iter   165/  201] train: loss: 0.1455762
[Epoch 56; Iter   195/  201] train: loss: 0.1472539
[Epoch 56] ogbg-moltoxcast: 0.732146 val loss: 0.209478
[Epoch 56] ogbg-moltoxcast: 0.743215 test loss: 0.205548
[Epoch 57; Iter    24/  201] train: loss: 0.1732100
[Epoch 57; Iter    54/  201] train: loss: 0.1236413
[Epoch 57; Iter    84/  201] train: loss: 0.1590200
[Epoch 57; Iter   114/  201] train: loss: 0.1484920
[Epoch 57; Iter   144/  201] train: loss: 0.1599417
[Epoch 57; Iter   174/  201] train: loss: 0.1587566
[Epoch 57] ogbg-moltoxcast: 0.734779 val loss: 0.206877
[Epoch 57] ogbg-moltoxcast: 0.749410 test loss: 0.203610
[Epoch 58; Iter     3/  201] train: loss: 0.1578560
[Epoch 58; Iter    33/  201] train: loss: 0.1912901
[Epoch 58; Iter    63/  201] train: loss: 0.1057059
[Epoch 58; Iter    93/  201] train: loss: 0.1227303
[Epoch 58; Iter   123/  201] train: loss: 0.1807392
[Epoch 58; Iter   153/  201] train: loss: 0.1425025
[Epoch 58; Iter   183/  201] train: loss: 0.1383617
[Epoch 58] ogbg-moltoxcast: 0.732021 val loss: 0.215362
[Epoch 58] ogbg-moltoxcast: 0.752060 test loss: 0.210505
[Epoch 59; Iter    12/  201] train: loss: 0.1392994
[Epoch 59; Iter    42/  201] train: loss: 0.1131307
[Epoch 59; Iter    72/  201] train: loss: 0.1872007
[Epoch 59; Iter   102/  201] train: loss: 0.1117687
[Epoch 59; Iter   132/  201] train: loss: 0.1334461
[Epoch 59; Iter   162/  201] train: loss: 0.1115389
[Epoch 59; Iter   192/  201] train: loss: 0.1648128
[Epoch 59] ogbg-moltoxcast: 0.734834 val loss: 0.210566
[Epoch 59] ogbg-moltoxcast: 0.742994 test loss: 0.206296
[Epoch 60; Iter    21/  201] train: loss: 0.2140953
[Epoch 60; Iter    51/  201] train: loss: 0.1604943
[Epoch 60; Iter    81/  201] train: loss: 0.2183564
[Epoch 60; Iter   111/  201] train: loss: 0.1573805
[Epoch 60; Iter   141/  201] train: loss: 0.1273288
[Epoch 60; Iter   171/  201] train: loss: 0.1500576
[Epoch 60; Iter   201/  201] train: loss: 0.0496313
[Epoch 60] ogbg-moltoxcast: 0.728768 val loss: 0.212520
[Epoch 60] ogbg-moltoxcast: 0.745901 test loss: 0.206379
[Epoch 61; Iter    30/  201] train: loss: 0.1414011
[Epoch 61; Iter    60/  201] train: loss: 0.1500558
[Epoch 61; Iter    90/  201] train: loss: 0.2056999
[Epoch 61; Iter   120/  201] train: loss: 0.0859387
[Epoch 61; Iter   150/  201] train: loss: 0.1644294
[Epoch 61; Iter   180/  201] train: loss: 0.1719536
[Epoch 61] ogbg-moltoxcast: 0.737525 val loss: 0.211274
[Epoch 61] ogbg-moltoxcast: 0.744451 test loss: 0.208390
[Epoch 62; Iter     9/  201] train: loss: 0.1430447
[Epoch 62; Iter    39/  201] train: loss: 0.1938151
[Epoch 62; Iter    69/  201] train: loss: 0.1304617
[Epoch 62; Iter    99/  201] train: loss: 0.1324961
[Epoch 62; Iter   129/  201] train: loss: 0.1237407
[Epoch 62; Iter   159/  201] train: loss: 0.1462156
[Epoch 62; Iter   189/  201] train: loss: 0.1238715
[Epoch 62] ogbg-moltoxcast: 0.738856 val loss: 0.211154
[Epoch 62] ogbg-moltoxcast: 0.739538 test loss: 0.212851
[Epoch 63; Iter    18/  201] train: loss: 0.1380787
[Epoch 63; Iter    48/  201] train: loss: 0.1363912
[Epoch 63; Iter    78/  201] train: loss: 0.1765794
[Epoch 63; Iter   108/  201] train: loss: 0.1813627
[Epoch 63; Iter   138/  201] train: loss: 0.1746018
[Epoch 63; Iter   168/  201] train: loss: 0.1602200
[Epoch 63; Iter   198/  201] train: loss: 0.1476823
[Epoch 63] ogbg-moltoxcast: 0.734816 val loss: 0.212906
[Epoch 63] ogbg-moltoxcast: 0.749356 test loss: 0.205440
[Epoch 64; Iter    27/  201] train: loss: 0.1665880
[Epoch 64; Iter    57/  201] train: loss: 0.1893551
[Epoch 64; Iter    87/  201] train: loss: 0.1775233
[Epoch 64; Iter   117/  201] train: loss: 0.1293513
[Epoch 64; Iter   147/  201] train: loss: 0.1256571
[Epoch 64; Iter   177/  201] train: loss: 0.1196358
[Epoch 64] ogbg-moltoxcast: 0.732744 val loss: 0.218868
[Epoch 64] ogbg-moltoxcast: 0.746440 test loss: 0.216039
[Epoch 65; Iter     6/  201] train: loss: 0.1242233
[Epoch 65; Iter    36/  201] train: loss: 0.2051115
[Epoch 65; Iter    66/  201] train: loss: 0.1501749
[Epoch 65; Iter    96/  201] train: loss: 0.1658565
[Epoch 65; Iter   126/  201] train: loss: 0.1525741
[Epoch 65; Iter   156/  201] train: loss: 0.1043681
[Epoch 65; Iter   186/  201] train: loss: 0.1282720
[Epoch 65] ogbg-moltoxcast: 0.734851 val loss: 0.210278
[Epoch 65] ogbg-moltoxcast: 0.744219 test loss: 0.209241
[Epoch 66; Iter    15/  201] train: loss: 0.1384401
[Epoch 66; Iter    45/  201] train: loss: 0.1650690
[Epoch 66; Iter    75/  201] train: loss: 0.1351327
[Epoch 54; Iter   154/  172] train: loss: 0.1857983
[Epoch 54] ogbg-moltoxcast: 0.719711 val loss: 0.206355
[Epoch 54] ogbg-moltoxcast: 0.743936 test loss: 0.203629
[Epoch 55; Iter    12/  172] train: loss: 0.1598291
[Epoch 55; Iter    42/  172] train: loss: 0.1293945
[Epoch 55; Iter    72/  172] train: loss: 0.1636473
[Epoch 55; Iter   102/  172] train: loss: 0.1384969
[Epoch 55; Iter   132/  172] train: loss: 0.1583443
[Epoch 55; Iter   162/  172] train: loss: 0.1336600
[Epoch 55] ogbg-moltoxcast: 0.722721 val loss: 0.208794
[Epoch 55] ogbg-moltoxcast: 0.745340 test loss: 0.204397
[Epoch 56; Iter    20/  172] train: loss: 0.1367906
[Epoch 56; Iter    50/  172] train: loss: 0.1733532
[Epoch 56; Iter    80/  172] train: loss: 0.1533217
[Epoch 56; Iter   110/  172] train: loss: 0.1854299
[Epoch 56; Iter   140/  172] train: loss: 0.1802469
[Epoch 56; Iter   170/  172] train: loss: 0.1572670
[Epoch 56] ogbg-moltoxcast: 0.721031 val loss: 0.210783
[Epoch 56] ogbg-moltoxcast: 0.746875 test loss: 0.202999
[Epoch 57; Iter    28/  172] train: loss: 0.1600696
[Epoch 57; Iter    58/  172] train: loss: 0.1104797
[Epoch 57; Iter    88/  172] train: loss: 0.1187297
[Epoch 57; Iter   118/  172] train: loss: 0.1868255
[Epoch 57; Iter   148/  172] train: loss: 0.1353961
[Epoch 57] ogbg-moltoxcast: 0.723398 val loss: 0.209868
[Epoch 57] ogbg-moltoxcast: 0.743702 test loss: 0.207764
[Epoch 58; Iter     6/  172] train: loss: 0.1498128
[Epoch 58; Iter    36/  172] train: loss: 0.1236820
[Epoch 58; Iter    66/  172] train: loss: 0.1544803
[Epoch 58; Iter    96/  172] train: loss: 0.1347629
[Epoch 58; Iter   126/  172] train: loss: 0.1148967
[Epoch 58; Iter   156/  172] train: loss: 0.2005251
[Epoch 58] ogbg-moltoxcast: 0.717962 val loss: 0.213109
[Epoch 58] ogbg-moltoxcast: 0.739998 test loss: 0.207395
[Epoch 59; Iter    14/  172] train: loss: 0.2034336
[Epoch 59; Iter    44/  172] train: loss: 0.1499184
[Epoch 59; Iter    74/  172] train: loss: 0.1720138
[Epoch 59; Iter   104/  172] train: loss: 0.1544976
[Epoch 59; Iter   134/  172] train: loss: 0.1427112
[Epoch 59; Iter   164/  172] train: loss: 0.1175354
[Epoch 59] ogbg-moltoxcast: 0.717691 val loss: 0.209983
[Epoch 59] ogbg-moltoxcast: 0.743077 test loss: 0.206199
[Epoch 60; Iter    22/  172] train: loss: 0.1364406
[Epoch 60; Iter    52/  172] train: loss: 0.1700148
[Epoch 60; Iter    82/  172] train: loss: 0.1118944
[Epoch 60; Iter   112/  172] train: loss: 0.1648770
[Epoch 60; Iter   142/  172] train: loss: 0.1490831
[Epoch 60; Iter   172/  172] train: loss: 0.0862964
[Epoch 60] ogbg-moltoxcast: 0.716170 val loss: 0.211587
[Epoch 60] ogbg-moltoxcast: 0.744679 test loss: 0.205652
[Epoch 61; Iter    30/  172] train: loss: 0.1487678
[Epoch 61; Iter    60/  172] train: loss: 0.1479339
[Epoch 61; Iter    90/  172] train: loss: 0.1573815
[Epoch 61; Iter   120/  172] train: loss: 0.1620258
[Epoch 61; Iter   150/  172] train: loss: 0.1220703
[Epoch 61] ogbg-moltoxcast: 0.717626 val loss: 0.213715
[Epoch 61] ogbg-moltoxcast: 0.741052 test loss: 0.209042
[Epoch 62; Iter     8/  172] train: loss: 0.1201527
[Epoch 62; Iter    38/  172] train: loss: 0.1231309
[Epoch 62; Iter    68/  172] train: loss: 0.0980379
[Epoch 62; Iter    98/  172] train: loss: 0.1419089
[Epoch 62; Iter   128/  172] train: loss: 0.1297387
[Epoch 62; Iter   158/  172] train: loss: 0.1373994
[Epoch 62] ogbg-moltoxcast: 0.722082 val loss: 0.209561
[Epoch 62] ogbg-moltoxcast: 0.742989 test loss: 0.205325
[Epoch 63; Iter    16/  172] train: loss: 0.1415315
[Epoch 63; Iter    46/  172] train: loss: 0.1010556
[Epoch 63; Iter    76/  172] train: loss: 0.1913285
[Epoch 63; Iter   106/  172] train: loss: 0.1287859
[Epoch 63; Iter   136/  172] train: loss: 0.1124035
[Epoch 63; Iter   166/  172] train: loss: 0.1536494
[Epoch 63] ogbg-moltoxcast: 0.726115 val loss: 0.210048
[Epoch 63] ogbg-moltoxcast: 0.752678 test loss: 0.205530
[Epoch 64; Iter    24/  172] train: loss: 0.1306884
[Epoch 64; Iter    54/  172] train: loss: 0.0912713
[Epoch 64; Iter    84/  172] train: loss: 0.1237808
[Epoch 64; Iter   114/  172] train: loss: 0.1265950
[Epoch 64; Iter   144/  172] train: loss: 0.0966824
[Epoch 64] ogbg-moltoxcast: 0.724393 val loss: 0.210372
[Epoch 64] ogbg-moltoxcast: 0.748922 test loss: 0.204401
[Epoch 65; Iter     2/  172] train: loss: 0.1150998
[Epoch 65; Iter    32/  172] train: loss: 0.1020443
[Epoch 65; Iter    62/  172] train: loss: 0.1406291
[Epoch 65; Iter    92/  172] train: loss: 0.1566402
[Epoch 65; Iter   122/  172] train: loss: 0.1131739
[Epoch 65; Iter   152/  172] train: loss: 0.1600043
[Epoch 65] ogbg-moltoxcast: 0.721959 val loss: 0.211040
[Epoch 65] ogbg-moltoxcast: 0.746102 test loss: 0.207882
[Epoch 66; Iter    10/  172] train: loss: 0.1324243
[Epoch 66; Iter    40/  172] train: loss: 0.1545836
[Epoch 66; Iter    70/  172] train: loss: 0.1106747
[Epoch 66; Iter   100/  172] train: loss: 0.1131484
[Epoch 66; Iter   130/  172] train: loss: 0.1766531
[Epoch 66; Iter   160/  172] train: loss: 0.1816797
[Epoch 66] ogbg-moltoxcast: 0.724342 val loss: 0.211022
[Epoch 66] ogbg-moltoxcast: 0.746654 test loss: 0.205455
[Epoch 67; Iter    18/  172] train: loss: 0.1153519
[Epoch 67; Iter    48/  172] train: loss: 0.1472140
[Epoch 67; Iter    78/  172] train: loss: 0.1962120
[Epoch 67; Iter   108/  172] train: loss: 0.1078531
[Epoch 67; Iter   138/  172] train: loss: 0.1290758
[Epoch 67; Iter   168/  172] train: loss: 0.0806201
[Epoch 67] ogbg-moltoxcast: 0.725543 val loss: 0.211376
[Epoch 67] ogbg-moltoxcast: 0.748024 test loss: 0.206163
[Epoch 68; Iter    26/  172] train: loss: 0.1123915
[Epoch 68; Iter    56/  172] train: loss: 0.1329048
[Epoch 68; Iter    86/  172] train: loss: 0.1289841
[Epoch 68; Iter   116/  172] train: loss: 0.1379363
[Epoch 68; Iter   146/  172] train: loss: 0.0956980
[Epoch 68] ogbg-moltoxcast: 0.723437 val loss: 0.213072
[Epoch 68] ogbg-moltoxcast: 0.740174 test loss: 0.210248
[Epoch 69; Iter     4/  172] train: loss: 0.1521729
[Epoch 69; Iter    34/  172] train: loss: 0.1321863
[Epoch 69; Iter    64/  172] train: loss: 0.1701481
[Epoch 69; Iter    94/  172] train: loss: 0.1856703
[Epoch 69; Iter   124/  172] train: loss: 0.1156339
[Epoch 69; Iter   154/  172] train: loss: 0.1098137
[Epoch 69] ogbg-moltoxcast: 0.724914 val loss: 0.212007
[Epoch 69] ogbg-moltoxcast: 0.746223 test loss: 0.206962
[Epoch 70; Iter    12/  172] train: loss: 0.1268584
[Epoch 70; Iter    42/  172] train: loss: 0.0912145
[Epoch 70; Iter    72/  172] train: loss: 0.1794730
[Epoch 70; Iter   102/  172] train: loss: 0.1321863
[Epoch 70; Iter   132/  172] train: loss: 0.1530197
[Epoch 70; Iter   162/  172] train: loss: 0.1418884
[Epoch 70] ogbg-moltoxcast: 0.720523 val loss: 0.213788
[Epoch 70] ogbg-moltoxcast: 0.742806 test loss: 0.209143
[Epoch 71; Iter    20/  172] train: loss: 0.1048579
[Epoch 71; Iter    50/  172] train: loss: 0.1269795
[Epoch 71; Iter    80/  172] train: loss: 0.1728770
[Epoch 71; Iter   110/  172] train: loss: 0.1469178
[Epoch 71; Iter   140/  172] train: loss: 0.1480433
[Epoch 71; Iter   170/  172] train: loss: 0.0829455
[Epoch 71] ogbg-moltoxcast: 0.722393 val loss: 0.213331
[Epoch 71] ogbg-moltoxcast: 0.745627 test loss: 0.208751
[Epoch 72; Iter    28/  172] train: loss: 0.1256625
[Epoch 72; Iter    58/  172] train: loss: 0.1529525
[Epoch 72; Iter    88/  172] train: loss: 0.1149290
[Epoch 72; Iter   118/  172] train: loss: 0.1182117
[Epoch 72; Iter   148/  172] train: loss: 0.1319021
[Epoch 72] ogbg-moltoxcast: 0.722545 val loss: 0.216340
[Epoch 72] ogbg-moltoxcast: 0.744442 test loss: 0.210003
[Epoch 73; Iter     6/  172] train: loss: 0.1795454
[Epoch 73; Iter    36/  172] train: loss: 0.1513470
[Epoch 73; Iter    66/  172] train: loss: 0.1396158
[Epoch 73; Iter    96/  172] train: loss: 0.1418494
[Epoch 73; Iter   126/  172] train: loss: 0.1153753
[Epoch 73; Iter   156/  172] train: loss: 0.1525239
[Epoch 73] ogbg-moltoxcast: 0.723595 val loss: 0.214744
[Epoch 73] ogbg-moltoxcast: 0.747161 test loss: 0.209687
[Epoch 74; Iter    14/  172] train: loss: 0.1391225
[Epoch 74; Iter    44/  172] train: loss: 0.1494719
[Epoch 74; Iter    74/  172] train: loss: 0.1027601
[Epoch 74; Iter   104/  172] train: loss: 0.1382447
[Epoch 54; Iter   154/  172] train: loss: 0.2055477
[Epoch 54] ogbg-moltoxcast: 0.721880 val loss: 0.274220
[Epoch 54] ogbg-moltoxcast: 0.734891 test loss: 0.209667
[Epoch 55; Iter    12/  172] train: loss: 0.1509653
[Epoch 55; Iter    42/  172] train: loss: 0.1278039
[Epoch 55; Iter    72/  172] train: loss: 0.1757182
[Epoch 55; Iter   102/  172] train: loss: 0.1481906
[Epoch 55; Iter   132/  172] train: loss: 0.2168659
[Epoch 55; Iter   162/  172] train: loss: 0.1450207
[Epoch 55] ogbg-moltoxcast: 0.722181 val loss: 0.258135
[Epoch 55] ogbg-moltoxcast: 0.738944 test loss: 0.203231
[Epoch 56; Iter    20/  172] train: loss: 0.1366550
[Epoch 56; Iter    50/  172] train: loss: 0.1147892
[Epoch 56; Iter    80/  172] train: loss: 0.1275568
[Epoch 56; Iter   110/  172] train: loss: 0.1256804
[Epoch 56; Iter   140/  172] train: loss: 0.1809340
[Epoch 56; Iter   170/  172] train: loss: 0.1367846
[Epoch 56] ogbg-moltoxcast: 0.721560 val loss: 0.275771
[Epoch 56] ogbg-moltoxcast: 0.737937 test loss: 0.206679
[Epoch 57; Iter    28/  172] train: loss: 0.1866925
[Epoch 57; Iter    58/  172] train: loss: 0.1418305
[Epoch 57; Iter    88/  172] train: loss: 0.1421105
[Epoch 57; Iter   118/  172] train: loss: 0.1608264
[Epoch 57; Iter   148/  172] train: loss: 0.1370843
[Epoch 57] ogbg-moltoxcast: 0.723191 val loss: 0.214933
[Epoch 57] ogbg-moltoxcast: 0.739722 test loss: 0.207863
[Epoch 58; Iter     6/  172] train: loss: 0.1364856
[Epoch 58; Iter    36/  172] train: loss: 0.1405498
[Epoch 58; Iter    66/  172] train: loss: 0.2191774
[Epoch 58; Iter    96/  172] train: loss: 0.1250085
[Epoch 58; Iter   126/  172] train: loss: 0.1273888
[Epoch 58; Iter   156/  172] train: loss: 0.1591647
[Epoch 58] ogbg-moltoxcast: 0.727626 val loss: 0.217347
[Epoch 58] ogbg-moltoxcast: 0.738029 test loss: 0.208413
[Epoch 59; Iter    14/  172] train: loss: 0.1607298
[Epoch 59; Iter    44/  172] train: loss: 0.2017196
[Epoch 59; Iter    74/  172] train: loss: 0.1607838
[Epoch 59; Iter   104/  172] train: loss: 0.1715092
[Epoch 59; Iter   134/  172] train: loss: 0.1266145
[Epoch 59; Iter   164/  172] train: loss: 0.1154571
[Epoch 59] ogbg-moltoxcast: 0.727045 val loss: 0.254473
[Epoch 59] ogbg-moltoxcast: 0.740018 test loss: 0.206067
[Epoch 60; Iter    22/  172] train: loss: 0.1498567
[Epoch 60; Iter    52/  172] train: loss: 0.1389651
[Epoch 60; Iter    82/  172] train: loss: 0.1620725
[Epoch 60; Iter   112/  172] train: loss: 0.0884877
[Epoch 60; Iter   142/  172] train: loss: 0.1537710
[Epoch 60; Iter   172/  172] train: loss: 0.1106706
[Epoch 60] ogbg-moltoxcast: 0.727750 val loss: 0.242203
[Epoch 60] ogbg-moltoxcast: 0.739908 test loss: 0.206092
[Epoch 61; Iter    30/  172] train: loss: 0.1574829
[Epoch 61; Iter    60/  172] train: loss: 0.1721972
[Epoch 61; Iter    90/  172] train: loss: 0.1429332
[Epoch 61; Iter   120/  172] train: loss: 0.1151249
[Epoch 61; Iter   150/  172] train: loss: 0.1470058
[Epoch 61] ogbg-moltoxcast: 0.730005 val loss: 0.245690
[Epoch 61] ogbg-moltoxcast: 0.737577 test loss: 0.208052
[Epoch 62; Iter     8/  172] train: loss: 0.1488408
[Epoch 62; Iter    38/  172] train: loss: 0.1133283
[Epoch 62; Iter    68/  172] train: loss: 0.1671266
[Epoch 62; Iter    98/  172] train: loss: 0.1690554
[Epoch 62; Iter   128/  172] train: loss: 0.1928046
[Epoch 62; Iter   158/  172] train: loss: 0.1877190
[Epoch 62] ogbg-moltoxcast: 0.723492 val loss: 0.214185
[Epoch 62] ogbg-moltoxcast: 0.734171 test loss: 0.210877
[Epoch 63; Iter    16/  172] train: loss: 0.1110639
[Epoch 63; Iter    46/  172] train: loss: 0.1469444
[Epoch 63; Iter    76/  172] train: loss: 0.2198981
[Epoch 63; Iter   106/  172] train: loss: 0.1253295
[Epoch 63; Iter   136/  172] train: loss: 0.2017601
[Epoch 63; Iter   166/  172] train: loss: 0.1178295
[Epoch 63] ogbg-moltoxcast: 0.721248 val loss: 0.227902
[Epoch 63] ogbg-moltoxcast: 0.735101 test loss: 0.209459
[Epoch 64; Iter    24/  172] train: loss: 0.1057595
[Epoch 64; Iter    54/  172] train: loss: 0.1366573
[Epoch 64; Iter    84/  172] train: loss: 0.1318716
[Epoch 64; Iter   114/  172] train: loss: 0.1694012
[Epoch 64; Iter   144/  172] train: loss: 0.1533473
[Epoch 64] ogbg-moltoxcast: 0.727251 val loss: 0.224027
[Epoch 64] ogbg-moltoxcast: 0.740188 test loss: 0.205013
[Epoch 65; Iter     2/  172] train: loss: 0.1109853
[Epoch 65; Iter    32/  172] train: loss: 0.1601265
[Epoch 65; Iter    62/  172] train: loss: 0.1340464
[Epoch 65; Iter    92/  172] train: loss: 0.1882896
[Epoch 65; Iter   122/  172] train: loss: 0.1458134
[Epoch 65; Iter   152/  172] train: loss: 0.1191214
[Epoch 65] ogbg-moltoxcast: 0.726059 val loss: 0.236123
[Epoch 65] ogbg-moltoxcast: 0.739236 test loss: 0.205636
[Epoch 66; Iter    10/  172] train: loss: 0.1684854
[Epoch 66; Iter    40/  172] train: loss: 0.1736844
[Epoch 66; Iter    70/  172] train: loss: 0.1643785
[Epoch 66; Iter   100/  172] train: loss: 0.0976410
[Epoch 66; Iter   130/  172] train: loss: 0.1658962
[Epoch 66; Iter   160/  172] train: loss: 0.0887873
[Epoch 66] ogbg-moltoxcast: 0.726021 val loss: 0.221378
[Epoch 66] ogbg-moltoxcast: 0.742542 test loss: 0.205960
[Epoch 67; Iter    18/  172] train: loss: 0.1166185
[Epoch 67; Iter    48/  172] train: loss: 0.1092298
[Epoch 67; Iter    78/  172] train: loss: 0.1707711
[Epoch 67; Iter   108/  172] train: loss: 0.1150624
[Epoch 67; Iter   138/  172] train: loss: 0.1300168
[Epoch 67; Iter   168/  172] train: loss: 0.1598466
[Epoch 67] ogbg-moltoxcast: 0.726322 val loss: 0.235339
[Epoch 67] ogbg-moltoxcast: 0.741146 test loss: 0.205913
[Epoch 68; Iter    26/  172] train: loss: 0.1106551
[Epoch 68; Iter    56/  172] train: loss: 0.1705053
[Epoch 68; Iter    86/  172] train: loss: 0.1555434
[Epoch 68; Iter   116/  172] train: loss: 0.1156409
[Epoch 68; Iter   146/  172] train: loss: 0.1586872
[Epoch 68] ogbg-moltoxcast: 0.725937 val loss: 0.215219
[Epoch 68] ogbg-moltoxcast: 0.737028 test loss: 0.210107
[Epoch 69; Iter     4/  172] train: loss: 0.1031980
[Epoch 69; Iter    34/  172] train: loss: 0.1755508
[Epoch 69; Iter    64/  172] train: loss: 0.1212337
[Epoch 69; Iter    94/  172] train: loss: 0.1643197
[Epoch 69; Iter   124/  172] train: loss: 0.1161514
[Epoch 69; Iter   154/  172] train: loss: 0.1606891
[Epoch 69] ogbg-moltoxcast: 0.729292 val loss: 0.228763
[Epoch 69] ogbg-moltoxcast: 0.738809 test loss: 0.209630
[Epoch 70; Iter    12/  172] train: loss: 0.1474395
[Epoch 70; Iter    42/  172] train: loss: 0.1543351
[Epoch 70; Iter    72/  172] train: loss: 0.1490720
[Epoch 70; Iter   102/  172] train: loss: 0.1093851
[Epoch 70; Iter   132/  172] train: loss: 0.1281482
[Epoch 70; Iter   162/  172] train: loss: 0.1389001
[Epoch 70] ogbg-moltoxcast: 0.721917 val loss: 0.246753
[Epoch 70] ogbg-moltoxcast: 0.734617 test loss: 0.208306
[Epoch 71; Iter    20/  172] train: loss: 0.1668167
[Epoch 71; Iter    50/  172] train: loss: 0.0838397
[Epoch 71; Iter    80/  172] train: loss: 0.1540377
[Epoch 71; Iter   110/  172] train: loss: 0.1674677
[Epoch 71; Iter   140/  172] train: loss: 0.1659709
[Epoch 71; Iter   170/  172] train: loss: 0.1543005
[Epoch 71] ogbg-moltoxcast: 0.726994 val loss: 0.226594
[Epoch 71] ogbg-moltoxcast: 0.740249 test loss: 0.208888
[Epoch 72; Iter    28/  172] train: loss: 0.1629397
[Epoch 72; Iter    58/  172] train: loss: 0.1194531
[Epoch 72; Iter    88/  172] train: loss: 0.1282888
[Epoch 72; Iter   118/  172] train: loss: 0.1477263
[Epoch 72; Iter   148/  172] train: loss: 0.1503489
[Epoch 72] ogbg-moltoxcast: 0.724216 val loss: 0.226192
[Epoch 72] ogbg-moltoxcast: 0.735565 test loss: 0.210744
[Epoch 73; Iter     6/  172] train: loss: 0.1198551
[Epoch 73; Iter    36/  172] train: loss: 0.1388694
[Epoch 73; Iter    66/  172] train: loss: 0.1052985
[Epoch 73; Iter    96/  172] train: loss: 0.1115277
[Epoch 73; Iter   126/  172] train: loss: 0.1197276
[Epoch 73; Iter   156/  172] train: loss: 0.1728235
[Epoch 73] ogbg-moltoxcast: 0.725850 val loss: 0.232343
[Epoch 73] ogbg-moltoxcast: 0.741231 test loss: 0.207140
[Epoch 74; Iter    14/  172] train: loss: 0.1467483
[Epoch 74; Iter    44/  172] train: loss: 0.1695149
[Epoch 74; Iter    74/  172] train: loss: 0.1358325
[Epoch 74; Iter   104/  172] train: loss: 0.1482501
[Epoch 54; Iter   154/  172] train: loss: 0.1316804
[Epoch 54] ogbg-moltoxcast: 0.728337 val loss: 0.210080
[Epoch 54] ogbg-moltoxcast: 0.746915 test loss: 0.206817
[Epoch 55; Iter    12/  172] train: loss: 0.1533374
[Epoch 55; Iter    42/  172] train: loss: 0.1360376
[Epoch 55; Iter    72/  172] train: loss: 0.1545392
[Epoch 55; Iter   102/  172] train: loss: 0.1391076
[Epoch 55; Iter   132/  172] train: loss: 0.1639056
[Epoch 55; Iter   162/  172] train: loss: 0.1302566
[Epoch 55] ogbg-moltoxcast: 0.726444 val loss: 0.210818
[Epoch 55] ogbg-moltoxcast: 0.737540 test loss: 0.211645
[Epoch 56; Iter    20/  172] train: loss: 0.0893989
[Epoch 56; Iter    50/  172] train: loss: 0.1429097
[Epoch 56; Iter    80/  172] train: loss: 0.1701609
[Epoch 56; Iter   110/  172] train: loss: 0.1298323
[Epoch 56; Iter   140/  172] train: loss: 0.1015439
[Epoch 56; Iter   170/  172] train: loss: 0.1802832
[Epoch 56] ogbg-moltoxcast: 0.734926 val loss: 0.206216
[Epoch 56] ogbg-moltoxcast: 0.745523 test loss: 0.205804
[Epoch 57; Iter    28/  172] train: loss: 0.1725407
[Epoch 57; Iter    58/  172] train: loss: 0.1506707
[Epoch 57; Iter    88/  172] train: loss: 0.1744807
[Epoch 57; Iter   118/  172] train: loss: 0.2140116
[Epoch 57; Iter   148/  172] train: loss: 0.1674120
[Epoch 57] ogbg-moltoxcast: 0.732654 val loss: 0.206246
[Epoch 57] ogbg-moltoxcast: 0.746469 test loss: 0.204592
[Epoch 58; Iter     6/  172] train: loss: 0.1424800
[Epoch 58; Iter    36/  172] train: loss: 0.1596011
[Epoch 58; Iter    66/  172] train: loss: 0.1729773
[Epoch 58; Iter    96/  172] train: loss: 0.1300437
[Epoch 58; Iter   126/  172] train: loss: 0.1482648
[Epoch 58; Iter   156/  172] train: loss: 0.1476617
[Epoch 58] ogbg-moltoxcast: 0.729434 val loss: 0.207982
[Epoch 58] ogbg-moltoxcast: 0.745608 test loss: 0.206749
[Epoch 59; Iter    14/  172] train: loss: 0.1782786
[Epoch 59; Iter    44/  172] train: loss: 0.1501688
[Epoch 59; Iter    74/  172] train: loss: 0.1416563
[Epoch 59; Iter   104/  172] train: loss: 0.1707554
[Epoch 59; Iter   134/  172] train: loss: 0.0941829
[Epoch 59; Iter   164/  172] train: loss: 0.1582160
[Epoch 59] ogbg-moltoxcast: 0.733050 val loss: 0.205308
[Epoch 59] ogbg-moltoxcast: 0.746581 test loss: 0.208221
[Epoch 60; Iter    22/  172] train: loss: 0.1971242
[Epoch 60; Iter    52/  172] train: loss: 0.1217473
[Epoch 60; Iter    82/  172] train: loss: 0.1244848
[Epoch 60; Iter   112/  172] train: loss: 0.0783637
[Epoch 60; Iter   142/  172] train: loss: 0.1225505
[Epoch 60; Iter   172/  172] train: loss: 0.1111867
[Epoch 60] ogbg-moltoxcast: 0.736691 val loss: 0.203313
[Epoch 60] ogbg-moltoxcast: 0.746172 test loss: 0.204638
[Epoch 61; Iter    30/  172] train: loss: 0.0997849
[Epoch 61; Iter    60/  172] train: loss: 0.1253772
[Epoch 61; Iter    90/  172] train: loss: 0.1390697
[Epoch 61; Iter   120/  172] train: loss: 0.1224487
[Epoch 61; Iter   150/  172] train: loss: 0.1684986
[Epoch 61] ogbg-moltoxcast: 0.737234 val loss: 0.206475
[Epoch 61] ogbg-moltoxcast: 0.748560 test loss: 0.205704
[Epoch 62; Iter     8/  172] train: loss: 0.1559516
[Epoch 62; Iter    38/  172] train: loss: 0.1756016
[Epoch 62; Iter    68/  172] train: loss: 0.0817252
[Epoch 62; Iter    98/  172] train: loss: 0.1346259
[Epoch 62; Iter   128/  172] train: loss: 0.1200203
[Epoch 62; Iter   158/  172] train: loss: 0.1324264
[Epoch 62] ogbg-moltoxcast: 0.731071 val loss: 0.207629
[Epoch 62] ogbg-moltoxcast: 0.739382 test loss: 0.210863
[Epoch 63; Iter    16/  172] train: loss: 0.1230701
[Epoch 63; Iter    46/  172] train: loss: 0.1445906
[Epoch 63; Iter    76/  172] train: loss: 0.1004007
[Epoch 63; Iter   106/  172] train: loss: 0.1233990
[Epoch 63; Iter   136/  172] train: loss: 0.1709257
[Epoch 63; Iter   166/  172] train: loss: 0.2045661
[Epoch 63] ogbg-moltoxcast: 0.728418 val loss: 0.207874
[Epoch 63] ogbg-moltoxcast: 0.740044 test loss: 0.210894
[Epoch 64; Iter    24/  172] train: loss: 0.1847316
[Epoch 64; Iter    54/  172] train: loss: 0.1374618
[Epoch 64; Iter    84/  172] train: loss: 0.1394731
[Epoch 64; Iter   114/  172] train: loss: 0.1402689
[Epoch 64; Iter   144/  172] train: loss: 0.1466250
[Epoch 64] ogbg-moltoxcast: 0.734050 val loss: 0.206869
[Epoch 64] ogbg-moltoxcast: 0.747878 test loss: 0.205805
[Epoch 65; Iter     2/  172] train: loss: 0.1850222
[Epoch 65; Iter    32/  172] train: loss: 0.1504265
[Epoch 65; Iter    62/  172] train: loss: 0.2014981
[Epoch 65; Iter    92/  172] train: loss: 0.0871180
[Epoch 65; Iter   122/  172] train: loss: 0.0914343
[Epoch 65; Iter   152/  172] train: loss: 0.0862043
[Epoch 65] ogbg-moltoxcast: 0.734806 val loss: 0.205449
[Epoch 65] ogbg-moltoxcast: 0.748910 test loss: 0.206181
[Epoch 66; Iter    10/  172] train: loss: 0.1017104
[Epoch 66; Iter    40/  172] train: loss: 0.2004984
[Epoch 66; Iter    70/  172] train: loss: 0.1923657
[Epoch 66; Iter   100/  172] train: loss: 0.1194681
[Epoch 66; Iter   130/  172] train: loss: 0.1868324
[Epoch 66; Iter   160/  172] train: loss: 0.0963285
[Epoch 66] ogbg-moltoxcast: 0.731469 val loss: 0.206349
[Epoch 66] ogbg-moltoxcast: 0.747057 test loss: 0.206469
[Epoch 67; Iter    18/  172] train: loss: 0.1409424
[Epoch 67; Iter    48/  172] train: loss: 0.0838287
[Epoch 67; Iter    78/  172] train: loss: 0.1276497
[Epoch 67; Iter   108/  172] train: loss: 0.1169761
[Epoch 67; Iter   138/  172] train: loss: 0.1079783
[Epoch 67; Iter   168/  172] train: loss: 0.1271372
[Epoch 67] ogbg-moltoxcast: 0.733831 val loss: 0.206385
[Epoch 67] ogbg-moltoxcast: 0.746441 test loss: 0.206684
[Epoch 68; Iter    26/  172] train: loss: 0.1606386
[Epoch 68; Iter    56/  172] train: loss: 0.1402154
[Epoch 68; Iter    86/  172] train: loss: 0.1224043
[Epoch 68; Iter   116/  172] train: loss: 0.1826345
[Epoch 68; Iter   146/  172] train: loss: 0.1734744
[Epoch 68] ogbg-moltoxcast: 0.730578 val loss: 0.208952
[Epoch 68] ogbg-moltoxcast: 0.744537 test loss: 0.208964
[Epoch 69; Iter     4/  172] train: loss: 0.1875617
[Epoch 69; Iter    34/  172] train: loss: 0.1494139
[Epoch 69; Iter    64/  172] train: loss: 0.1598334
[Epoch 69; Iter    94/  172] train: loss: 0.1389187
[Epoch 69; Iter   124/  172] train: loss: 0.0886299
[Epoch 69; Iter   154/  172] train: loss: 0.1376817
[Epoch 69] ogbg-moltoxcast: 0.730913 val loss: 0.208329
[Epoch 69] ogbg-moltoxcast: 0.745633 test loss: 0.208492
[Epoch 70; Iter    12/  172] train: loss: 0.1093852
[Epoch 70; Iter    42/  172] train: loss: 0.1436147
[Epoch 70; Iter    72/  172] train: loss: 0.1357718
[Epoch 70; Iter   102/  172] train: loss: 0.1193505
[Epoch 70; Iter   132/  172] train: loss: 0.1701439
[Epoch 70; Iter   162/  172] train: loss: 0.1509533
[Epoch 70] ogbg-moltoxcast: 0.733576 val loss: 0.209006
[Epoch 70] ogbg-moltoxcast: 0.743993 test loss: 0.209620
[Epoch 71; Iter    20/  172] train: loss: 0.1725236
[Epoch 71; Iter    50/  172] train: loss: 0.1541779
[Epoch 71; Iter    80/  172] train: loss: 0.1082542
[Epoch 71; Iter   110/  172] train: loss: 0.1139722
[Epoch 71; Iter   140/  172] train: loss: 0.1797410
[Epoch 71; Iter   170/  172] train: loss: 0.1850980
[Epoch 71] ogbg-moltoxcast: 0.733282 val loss: 0.208950
[Epoch 71] ogbg-moltoxcast: 0.744253 test loss: 0.209615
[Epoch 72; Iter    28/  172] train: loss: 0.1670334
[Epoch 72; Iter    58/  172] train: loss: 0.1625456
[Epoch 72; Iter    88/  172] train: loss: 0.1309842
[Epoch 72; Iter   118/  172] train: loss: 0.1512289
[Epoch 72; Iter   148/  172] train: loss: 0.1169473
[Epoch 72] ogbg-moltoxcast: 0.730539 val loss: 0.209543
[Epoch 72] ogbg-moltoxcast: 0.745211 test loss: 0.211106
[Epoch 73; Iter     6/  172] train: loss: 0.1068171
[Epoch 73; Iter    36/  172] train: loss: 0.1045179
[Epoch 73; Iter    66/  172] train: loss: 0.1496481
[Epoch 73; Iter    96/  172] train: loss: 0.0965021
[Epoch 73; Iter   126/  172] train: loss: 0.1092349
[Epoch 73; Iter   156/  172] train: loss: 0.1487407
[Epoch 73] ogbg-moltoxcast: 0.734442 val loss: 0.207492
[Epoch 73] ogbg-moltoxcast: 0.746818 test loss: 0.210323
[Epoch 74; Iter    14/  172] train: loss: 0.1293589
[Epoch 74; Iter    44/  172] train: loss: 0.1154277
[Epoch 74; Iter    74/  172] train: loss: 0.1880796
[Epoch 74; Iter   104/  172] train: loss: 0.1213467
[Epoch 60; Iter    19/  229] train: loss: 0.1541525
[Epoch 60; Iter    49/  229] train: loss: 0.1841011
[Epoch 60; Iter    79/  229] train: loss: 0.1210359
[Epoch 60; Iter   109/  229] train: loss: 0.1323293
[Epoch 60; Iter   139/  229] train: loss: 0.1754085
[Epoch 60; Iter   169/  229] train: loss: 0.2669924
[Epoch 60; Iter   199/  229] train: loss: 0.1750787
[Epoch 60; Iter   229/  229] train: loss: 0.1083959
[Epoch 60] ogbg-moltoxcast: 0.731178 val loss: 0.199477
[Epoch 60] ogbg-moltoxcast: 0.756679 test loss: 0.217339
[Epoch 61; Iter    30/  229] train: loss: 0.1760272
[Epoch 61; Iter    60/  229] train: loss: 0.0942965
[Epoch 61; Iter    90/  229] train: loss: 0.1740648
[Epoch 61; Iter   120/  229] train: loss: 0.1848669
[Epoch 61; Iter   150/  229] train: loss: 0.0886456
[Epoch 61; Iter   180/  229] train: loss: 0.1645410
[Epoch 61; Iter   210/  229] train: loss: 0.1113280
[Epoch 61] ogbg-moltoxcast: 0.740499 val loss: 0.198516
[Epoch 61] ogbg-moltoxcast: 0.763858 test loss: 0.203542
[Epoch 62; Iter    11/  229] train: loss: 0.2451739
[Epoch 62; Iter    41/  229] train: loss: 0.1753043
[Epoch 62; Iter    71/  229] train: loss: 0.1413475
[Epoch 62; Iter   101/  229] train: loss: 0.1313401
[Epoch 62; Iter   131/  229] train: loss: 0.1343689
[Epoch 62; Iter   161/  229] train: loss: 0.2057016
[Epoch 62; Iter   191/  229] train: loss: 0.1265713
[Epoch 62; Iter   221/  229] train: loss: 0.1524217
[Epoch 62] ogbg-moltoxcast: 0.735954 val loss: 0.200942
[Epoch 62] ogbg-moltoxcast: 0.765516 test loss: 0.203227
[Epoch 63; Iter    22/  229] train: loss: 0.1388762
[Epoch 63; Iter    52/  229] train: loss: 0.1803419
[Epoch 63; Iter    82/  229] train: loss: 0.1531267
[Epoch 63; Iter   112/  229] train: loss: 0.1460559
[Epoch 63; Iter   142/  229] train: loss: 0.1147674
[Epoch 63; Iter   172/  229] train: loss: 0.1699310
[Epoch 63; Iter   202/  229] train: loss: 0.1120295
[Epoch 63] ogbg-moltoxcast: 0.737136 val loss: 0.200644
[Epoch 63] ogbg-moltoxcast: 0.760628 test loss: 0.205167
[Epoch 64; Iter     3/  229] train: loss: 0.1429186
[Epoch 64; Iter    33/  229] train: loss: 0.1269701
[Epoch 64; Iter    63/  229] train: loss: 0.1461752
[Epoch 64; Iter    93/  229] train: loss: 0.1639225
[Epoch 64; Iter   123/  229] train: loss: 0.1673138
[Epoch 64; Iter   153/  229] train: loss: 0.1723044
[Epoch 64; Iter   183/  229] train: loss: 0.1276513
[Epoch 64; Iter   213/  229] train: loss: 0.1682445
[Epoch 64] ogbg-moltoxcast: 0.736592 val loss: 0.200179
[Epoch 64] ogbg-moltoxcast: 0.758661 test loss: 0.210830
[Epoch 65; Iter    14/  229] train: loss: 0.1589570
[Epoch 65; Iter    44/  229] train: loss: 0.1561632
[Epoch 65; Iter    74/  229] train: loss: 0.1467483
[Epoch 65; Iter   104/  229] train: loss: 0.1409463
[Epoch 65; Iter   134/  229] train: loss: 0.1546609
[Epoch 65; Iter   164/  229] train: loss: 0.1334476
[Epoch 65; Iter   194/  229] train: loss: 0.1340080
[Epoch 65; Iter   224/  229] train: loss: 0.1763912
[Epoch 65] ogbg-moltoxcast: 0.743788 val loss: 0.198432
[Epoch 65] ogbg-moltoxcast: 0.760355 test loss: 0.208406
[Epoch 66; Iter    25/  229] train: loss: 0.1108582
[Epoch 66; Iter    55/  229] train: loss: 0.1449339
[Epoch 66; Iter    85/  229] train: loss: 0.0919984
[Epoch 66; Iter   115/  229] train: loss: 0.1621720
[Epoch 66; Iter   145/  229] train: loss: 0.0996210
[Epoch 66; Iter   175/  229] train: loss: 0.1290443
[Epoch 66; Iter   205/  229] train: loss: 0.1235112
[Epoch 66] ogbg-moltoxcast: 0.743085 val loss: 0.199739
[Epoch 66] ogbg-moltoxcast: 0.762032 test loss: 0.206435
[Epoch 67; Iter     6/  229] train: loss: 0.1622193
[Epoch 67; Iter    36/  229] train: loss: 0.1633677
[Epoch 67; Iter    66/  229] train: loss: 0.1219192
[Epoch 67; Iter    96/  229] train: loss: 0.1450476
[Epoch 67; Iter   126/  229] train: loss: 0.2082258
[Epoch 67; Iter   156/  229] train: loss: 0.1352011
[Epoch 67; Iter   186/  229] train: loss: 0.1518385
[Epoch 67; Iter   216/  229] train: loss: 0.1115977
[Epoch 67] ogbg-moltoxcast: 0.746824 val loss: 0.193971
[Epoch 67] ogbg-moltoxcast: 0.758953 test loss: 0.208762
[Epoch 68; Iter    17/  229] train: loss: 0.1862393
[Epoch 68; Iter    47/  229] train: loss: 0.1095034
[Epoch 68; Iter    77/  229] train: loss: 0.1311566
[Epoch 68; Iter   107/  229] train: loss: 0.1576314
[Epoch 68; Iter   137/  229] train: loss: 0.1381399
[Epoch 68; Iter   167/  229] train: loss: 0.1431540
[Epoch 68; Iter   197/  229] train: loss: 0.1387996
[Epoch 68; Iter   227/  229] train: loss: 0.1089415
[Epoch 68] ogbg-moltoxcast: 0.744515 val loss: 0.197031
[Epoch 68] ogbg-moltoxcast: 0.765524 test loss: 0.203341
[Epoch 69; Iter    28/  229] train: loss: 0.1929652
[Epoch 69; Iter    58/  229] train: loss: 0.1006055
[Epoch 69; Iter    88/  229] train: loss: 0.1349544
[Epoch 69; Iter   118/  229] train: loss: 0.2113995
[Epoch 69; Iter   148/  229] train: loss: 0.1063457
[Epoch 69; Iter   178/  229] train: loss: 0.1313782
[Epoch 69; Iter   208/  229] train: loss: 0.1644059
[Epoch 69] ogbg-moltoxcast: 0.742950 val loss: 0.199526
[Epoch 69] ogbg-moltoxcast: 0.761952 test loss: 0.205105
[Epoch 70; Iter     9/  229] train: loss: 0.1723976
[Epoch 70; Iter    39/  229] train: loss: 0.1559993
[Epoch 70; Iter    69/  229] train: loss: 0.1515972
[Epoch 70; Iter    99/  229] train: loss: 0.1401849
[Epoch 70; Iter   129/  229] train: loss: 0.1131237
[Epoch 70; Iter   159/  229] train: loss: 0.1283982
[Epoch 70; Iter   189/  229] train: loss: 0.1577941
[Epoch 70; Iter   219/  229] train: loss: 0.1533900
[Epoch 70] ogbg-moltoxcast: 0.739869 val loss: 0.203758
[Epoch 70] ogbg-moltoxcast: 0.757160 test loss: 0.209212
[Epoch 71; Iter    20/  229] train: loss: 0.1247236
[Epoch 71; Iter    50/  229] train: loss: 0.1529139
[Epoch 71; Iter    80/  229] train: loss: 0.1502514
[Epoch 71; Iter   110/  229] train: loss: 0.1347793
[Epoch 71; Iter   140/  229] train: loss: 0.1190140
[Epoch 71; Iter   170/  229] train: loss: 0.1326006
[Epoch 71; Iter   200/  229] train: loss: 0.2024926
[Epoch 71] ogbg-moltoxcast: 0.744476 val loss: 0.197773
[Epoch 71] ogbg-moltoxcast: 0.758886 test loss: 0.209449
[Epoch 72; Iter     1/  229] train: loss: 0.2007852
[Epoch 72; Iter    31/  229] train: loss: 0.1531153
[Epoch 72; Iter    61/  229] train: loss: 0.1213380
[Epoch 72; Iter    91/  229] train: loss: 0.1270916
[Epoch 72; Iter   121/  229] train: loss: 0.1269854
[Epoch 72; Iter   151/  229] train: loss: 0.1367243
[Epoch 72; Iter   181/  229] train: loss: 0.1437229
[Epoch 72; Iter   211/  229] train: loss: 0.1542547
[Epoch 72] ogbg-moltoxcast: 0.742541 val loss: 0.200529
[Epoch 72] ogbg-moltoxcast: 0.759978 test loss: 0.209681
[Epoch 73; Iter    12/  229] train: loss: 0.1896836
[Epoch 73; Iter    42/  229] train: loss: 0.1333821
[Epoch 73; Iter    72/  229] train: loss: 0.1240105
[Epoch 73; Iter   102/  229] train: loss: 0.1288589
[Epoch 73; Iter   132/  229] train: loss: 0.1547136
[Epoch 73; Iter   162/  229] train: loss: 0.0942343
[Epoch 73; Iter   192/  229] train: loss: 0.1455782
[Epoch 73; Iter   222/  229] train: loss: 0.1573765
[Epoch 73] ogbg-moltoxcast: 0.745632 val loss: 0.199898
[Epoch 73] ogbg-moltoxcast: 0.757885 test loss: 0.208869
[Epoch 74; Iter    23/  229] train: loss: 0.1739660
[Epoch 74; Iter    53/  229] train: loss: 0.1711752
[Epoch 74; Iter    83/  229] train: loss: 0.1777313
[Epoch 74; Iter   113/  229] train: loss: 0.1600083
[Epoch 74; Iter   143/  229] train: loss: 0.0914910
[Epoch 74; Iter   173/  229] train: loss: 0.1110930
[Epoch 74; Iter   203/  229] train: loss: 0.1490366
[Epoch 74] ogbg-moltoxcast: 0.743131 val loss: 0.201585
[Epoch 74] ogbg-moltoxcast: 0.758752 test loss: 0.212637
[Epoch 75; Iter     4/  229] train: loss: 0.1225074
[Epoch 75; Iter    34/  229] train: loss: 0.1283880
[Epoch 75; Iter    64/  229] train: loss: 0.1756064
[Epoch 75; Iter    94/  229] train: loss: 0.1678069
[Epoch 75; Iter   124/  229] train: loss: 0.1176604
[Epoch 75; Iter   154/  229] train: loss: 0.1848674
[Epoch 75; Iter   184/  229] train: loss: 0.1250298
[Epoch 75; Iter   214/  229] train: loss: 0.1581846
[Epoch 75] ogbg-moltoxcast: 0.743948 val loss: 0.200337
[Epoch 75] ogbg-moltoxcast: 0.761888 test loss: 0.208526
[Epoch 60; Iter    19/  229] train: loss: 0.1226954
[Epoch 60; Iter    49/  229] train: loss: 0.0867135
[Epoch 60; Iter    79/  229] train: loss: 0.1484154
[Epoch 60; Iter   109/  229] train: loss: 0.2366238
[Epoch 60; Iter   139/  229] train: loss: 0.1779615
[Epoch 60; Iter   169/  229] train: loss: 0.2072393
[Epoch 60; Iter   199/  229] train: loss: 0.1617202
[Epoch 60; Iter   229/  229] train: loss: 0.1579805
[Epoch 60] ogbg-moltoxcast: 0.748317 val loss: 0.193278
[Epoch 60] ogbg-moltoxcast: 0.752776 test loss: 0.289868
[Epoch 61; Iter    30/  229] train: loss: 0.1421604
[Epoch 61; Iter    60/  229] train: loss: 0.1679294
[Epoch 61; Iter    90/  229] train: loss: 0.1562839
[Epoch 61; Iter   120/  229] train: loss: 0.1832880
[Epoch 61; Iter   150/  229] train: loss: 0.1591848
[Epoch 61; Iter   180/  229] train: loss: 0.2050528
[Epoch 61; Iter   210/  229] train: loss: 0.1929742
[Epoch 61] ogbg-moltoxcast: 0.734140 val loss: 0.200420
[Epoch 61] ogbg-moltoxcast: 0.749251 test loss: 0.215307
[Epoch 62; Iter    11/  229] train: loss: 0.1446493
[Epoch 62; Iter    41/  229] train: loss: 0.0927417
[Epoch 62; Iter    71/  229] train: loss: 0.1155510
[Epoch 62; Iter   101/  229] train: loss: 0.1537382
[Epoch 62; Iter   131/  229] train: loss: 0.1700395
[Epoch 62; Iter   161/  229] train: loss: 0.1551311
[Epoch 62; Iter   191/  229] train: loss: 0.1828509
[Epoch 62; Iter   221/  229] train: loss: 0.1319080
[Epoch 62] ogbg-moltoxcast: 0.746989 val loss: 0.195793
[Epoch 62] ogbg-moltoxcast: 0.754680 test loss: 0.209194
[Epoch 63; Iter    22/  229] train: loss: 0.1664865
[Epoch 63; Iter    52/  229] train: loss: 0.1391708
[Epoch 63; Iter    82/  229] train: loss: 0.1415108
[Epoch 63; Iter   112/  229] train: loss: 0.1815798
[Epoch 63; Iter   142/  229] train: loss: 0.1591288
[Epoch 63; Iter   172/  229] train: loss: 0.1800661
[Epoch 63; Iter   202/  229] train: loss: 0.1506568
[Epoch 63] ogbg-moltoxcast: 0.747047 val loss: 0.194407
[Epoch 63] ogbg-moltoxcast: 0.756932 test loss: 0.211572
[Epoch 64; Iter     3/  229] train: loss: 0.1438058
[Epoch 64; Iter    33/  229] train: loss: 0.1660157
[Epoch 64; Iter    63/  229] train: loss: 0.1517603
[Epoch 64; Iter    93/  229] train: loss: 0.1114947
[Epoch 64; Iter   123/  229] train: loss: 0.1125522
[Epoch 64; Iter   153/  229] train: loss: 0.1702138
[Epoch 64; Iter   183/  229] train: loss: 0.1275435
[Epoch 64; Iter   213/  229] train: loss: 0.1331992
[Epoch 64] ogbg-moltoxcast: 0.745827 val loss: 0.192872
[Epoch 64] ogbg-moltoxcast: 0.753892 test loss: 0.208909
[Epoch 65; Iter    14/  229] train: loss: 0.2067681
[Epoch 65; Iter    44/  229] train: loss: 0.1340407
[Epoch 65; Iter    74/  229] train: loss: 0.1402209
[Epoch 65; Iter   104/  229] train: loss: 0.1925548
[Epoch 65; Iter   134/  229] train: loss: 0.1290598
[Epoch 65; Iter   164/  229] train: loss: 0.1373534
[Epoch 65; Iter   194/  229] train: loss: 0.1807614
[Epoch 65; Iter   224/  229] train: loss: 0.1417322
[Epoch 65] ogbg-moltoxcast: 0.747768 val loss: 0.196756
[Epoch 65] ogbg-moltoxcast: 0.756333 test loss: 0.213996
[Epoch 66; Iter    25/  229] train: loss: 0.1599965
[Epoch 66; Iter    55/  229] train: loss: 0.2099243
[Epoch 66; Iter    85/  229] train: loss: 0.1484205
[Epoch 66; Iter   115/  229] train: loss: 0.1335575
[Epoch 66; Iter   145/  229] train: loss: 0.1148825
[Epoch 66; Iter   175/  229] train: loss: 0.1693273
[Epoch 66; Iter   205/  229] train: loss: 0.1812629
[Epoch 66] ogbg-moltoxcast: 0.743842 val loss: 0.196015
[Epoch 66] ogbg-moltoxcast: 0.749970 test loss: 0.215640
[Epoch 67; Iter     6/  229] train: loss: 0.1055902
[Epoch 67; Iter    36/  229] train: loss: 0.1240079
[Epoch 67; Iter    66/  229] train: loss: 0.1574541
[Epoch 67; Iter    96/  229] train: loss: 0.1526000
[Epoch 67; Iter   126/  229] train: loss: 0.1082749
[Epoch 67; Iter   156/  229] train: loss: 0.1213306
[Epoch 67; Iter   186/  229] train: loss: 0.1245686
[Epoch 67; Iter   216/  229] train: loss: 0.1810124
[Epoch 67] ogbg-moltoxcast: 0.742655 val loss: 0.196259
[Epoch 67] ogbg-moltoxcast: 0.757598 test loss: 0.210072
[Epoch 68; Iter    17/  229] train: loss: 0.1601703
[Epoch 68; Iter    47/  229] train: loss: 0.1188823
[Epoch 68; Iter    77/  229] train: loss: 0.1259191
[Epoch 68; Iter   107/  229] train: loss: 0.2136638
[Epoch 68; Iter   137/  229] train: loss: 0.1333790
[Epoch 68; Iter   167/  229] train: loss: 0.1448140
[Epoch 68; Iter   197/  229] train: loss: 0.2205540
[Epoch 68; Iter   227/  229] train: loss: 0.1453464
[Epoch 68] ogbg-moltoxcast: 0.750399 val loss: 0.195337
[Epoch 68] ogbg-moltoxcast: 0.753314 test loss: 0.219496
[Epoch 69; Iter    28/  229] train: loss: 0.1447175
[Epoch 69; Iter    58/  229] train: loss: 0.2019967
[Epoch 69; Iter    88/  229] train: loss: 0.1132203
[Epoch 69; Iter   118/  229] train: loss: 0.1759584
[Epoch 69; Iter   148/  229] train: loss: 0.1506228
[Epoch 69; Iter   178/  229] train: loss: 0.1434001
[Epoch 69; Iter   208/  229] train: loss: 0.1142673
[Epoch 69] ogbg-moltoxcast: 0.745237 val loss: 0.197207
[Epoch 69] ogbg-moltoxcast: 0.754153 test loss: 0.210860
[Epoch 70; Iter     9/  229] train: loss: 0.1415927
[Epoch 70; Iter    39/  229] train: loss: 0.1029686
[Epoch 70; Iter    69/  229] train: loss: 0.1110000
[Epoch 70; Iter    99/  229] train: loss: 0.1845590
[Epoch 70; Iter   129/  229] train: loss: 0.1478620
[Epoch 70; Iter   159/  229] train: loss: 0.2114830
[Epoch 70; Iter   189/  229] train: loss: 0.0992216
[Epoch 70; Iter   219/  229] train: loss: 0.1527275
[Epoch 70] ogbg-moltoxcast: 0.739676 val loss: 0.201331
[Epoch 70] ogbg-moltoxcast: 0.756847 test loss: 0.213152
[Epoch 71; Iter    20/  229] train: loss: 0.1321785
[Epoch 71; Iter    50/  229] train: loss: 0.1709772
[Epoch 71; Iter    80/  229] train: loss: 0.1507363
[Epoch 71; Iter   110/  229] train: loss: 0.1618004
[Epoch 71; Iter   140/  229] train: loss: 0.1636033
[Epoch 71; Iter   170/  229] train: loss: 0.1359563
[Epoch 71; Iter   200/  229] train: loss: 0.1272108
[Epoch 71] ogbg-moltoxcast: 0.744240 val loss: 0.198751
[Epoch 71] ogbg-moltoxcast: 0.757458 test loss: 0.217409
[Epoch 72; Iter     1/  229] train: loss: 0.1700678
[Epoch 72; Iter    31/  229] train: loss: 0.1327860
[Epoch 72; Iter    61/  229] train: loss: 0.0846624
[Epoch 72; Iter    91/  229] train: loss: 0.1517691
[Epoch 72; Iter   121/  229] train: loss: 0.1587654
[Epoch 72; Iter   151/  229] train: loss: 0.1234972
[Epoch 72; Iter   181/  229] train: loss: 0.1836340
[Epoch 72; Iter   211/  229] train: loss: 0.1452674
[Epoch 72] ogbg-moltoxcast: 0.741402 val loss: 0.200110
[Epoch 72] ogbg-moltoxcast: 0.754236 test loss: 0.214492
[Epoch 73; Iter    12/  229] train: loss: 0.1379227
[Epoch 73; Iter    42/  229] train: loss: 0.1279241
[Epoch 73; Iter    72/  229] train: loss: 0.1079607
[Epoch 73; Iter   102/  229] train: loss: 0.1368818
[Epoch 73; Iter   132/  229] train: loss: 0.1335834
[Epoch 73; Iter   162/  229] train: loss: 0.1331408
[Epoch 73; Iter   192/  229] train: loss: 0.2081794
[Epoch 73; Iter   222/  229] train: loss: 0.1109122
[Epoch 73] ogbg-moltoxcast: 0.750268 val loss: 0.194422
[Epoch 73] ogbg-moltoxcast: 0.758005 test loss: 0.213604
[Epoch 74; Iter    23/  229] train: loss: 0.1166562
[Epoch 74; Iter    53/  229] train: loss: 0.1228750
[Epoch 74; Iter    83/  229] train: loss: 0.1282992
[Epoch 74; Iter   113/  229] train: loss: 0.1504305
[Epoch 74; Iter   143/  229] train: loss: 0.1613540
[Epoch 74; Iter   173/  229] train: loss: 0.1272532
[Epoch 74; Iter   203/  229] train: loss: 0.1663764
[Epoch 74] ogbg-moltoxcast: 0.745935 val loss: 0.197872
[Epoch 74] ogbg-moltoxcast: 0.754854 test loss: 0.212752
[Epoch 75; Iter     4/  229] train: loss: 0.1552070
[Epoch 75; Iter    34/  229] train: loss: 0.1187307
[Epoch 75; Iter    64/  229] train: loss: 0.1212367
[Epoch 75; Iter    94/  229] train: loss: 0.1299086
[Epoch 75; Iter   124/  229] train: loss: 0.1264787
[Epoch 75; Iter   154/  229] train: loss: 0.1258953
[Epoch 75; Iter   184/  229] train: loss: 0.1339063
[Epoch 75; Iter   214/  229] train: loss: 0.2087799
[Epoch 75] ogbg-moltoxcast: 0.743042 val loss: 0.207864
[Epoch 75] ogbg-moltoxcast: 0.753076 test loss: 0.236175
[Epoch 60; Iter    19/  229] train: loss: 0.1121305
[Epoch 60; Iter    49/  229] train: loss: 0.1962961
[Epoch 60; Iter    79/  229] train: loss: 0.1510719
[Epoch 60; Iter   109/  229] train: loss: 0.1651448
[Epoch 60; Iter   139/  229] train: loss: 0.1232536
[Epoch 60; Iter   169/  229] train: loss: 0.1223273
[Epoch 60; Iter   199/  229] train: loss: 0.2058788
[Epoch 60; Iter   229/  229] train: loss: 0.1820818
[Epoch 60] ogbg-moltoxcast: 0.737234 val loss: 0.200224
[Epoch 60] ogbg-moltoxcast: 0.747376 test loss: 0.212982
[Epoch 61; Iter    30/  229] train: loss: 0.1668214
[Epoch 61; Iter    60/  229] train: loss: 0.1121422
[Epoch 61; Iter    90/  229] train: loss: 0.1071988
[Epoch 61; Iter   120/  229] train: loss: 0.1039333
[Epoch 61; Iter   150/  229] train: loss: 0.1432174
[Epoch 61; Iter   180/  229] train: loss: 0.1332689
[Epoch 61; Iter   210/  229] train: loss: 0.1665530
[Epoch 61] ogbg-moltoxcast: 0.743300 val loss: 0.198492
[Epoch 61] ogbg-moltoxcast: 0.756395 test loss: 0.204988
[Epoch 62; Iter    11/  229] train: loss: 0.1802248
[Epoch 62; Iter    41/  229] train: loss: 0.1164605
[Epoch 62; Iter    71/  229] train: loss: 0.1388210
[Epoch 62; Iter   101/  229] train: loss: 0.1801164
[Epoch 62; Iter   131/  229] train: loss: 0.1223514
[Epoch 62; Iter   161/  229] train: loss: 0.1265659
[Epoch 62; Iter   191/  229] train: loss: 0.1706085
[Epoch 62; Iter   221/  229] train: loss: 0.2236300
[Epoch 62] ogbg-moltoxcast: 0.741045 val loss: 0.198704
[Epoch 62] ogbg-moltoxcast: 0.754062 test loss: 0.208112
[Epoch 63; Iter    22/  229] train: loss: 0.1558094
[Epoch 63; Iter    52/  229] train: loss: 0.1528394
[Epoch 63; Iter    82/  229] train: loss: 0.1343147
[Epoch 63; Iter   112/  229] train: loss: 0.1066214
[Epoch 63; Iter   142/  229] train: loss: 0.1660850
[Epoch 63; Iter   172/  229] train: loss: 0.1492197
[Epoch 63; Iter   202/  229] train: loss: 0.1227142
[Epoch 63] ogbg-moltoxcast: 0.743809 val loss: 0.196436
[Epoch 63] ogbg-moltoxcast: 0.748619 test loss: 0.212849
[Epoch 64; Iter     3/  229] train: loss: 0.1549484
[Epoch 64; Iter    33/  229] train: loss: 0.1728610
[Epoch 64; Iter    63/  229] train: loss: 0.1648422
[Epoch 64; Iter    93/  229] train: loss: 0.1859882
[Epoch 64; Iter   123/  229] train: loss: 0.0906308
[Epoch 64; Iter   153/  229] train: loss: 0.1373439
[Epoch 64; Iter   183/  229] train: loss: 0.1296445
[Epoch 64; Iter   213/  229] train: loss: 0.1413385
[Epoch 64] ogbg-moltoxcast: 0.748850 val loss: 0.197015
[Epoch 64] ogbg-moltoxcast: 0.751986 test loss: 0.215302
[Epoch 65; Iter    14/  229] train: loss: 0.1353846
[Epoch 65; Iter    44/  229] train: loss: 0.1013333
[Epoch 65; Iter    74/  229] train: loss: 0.1627955
[Epoch 65; Iter   104/  229] train: loss: 0.1242271
[Epoch 65; Iter   134/  229] train: loss: 0.1561162
[Epoch 65; Iter   164/  229] train: loss: 0.1284858
[Epoch 65; Iter   194/  229] train: loss: 0.1126703
[Epoch 65; Iter   224/  229] train: loss: 0.1554781
[Epoch 65] ogbg-moltoxcast: 0.744493 val loss: 0.199339
[Epoch 65] ogbg-moltoxcast: 0.754142 test loss: 0.210957
[Epoch 66; Iter    25/  229] train: loss: 0.1608830
[Epoch 66; Iter    55/  229] train: loss: 0.1777735
[Epoch 66; Iter    85/  229] train: loss: 0.1180389
[Epoch 66; Iter   115/  229] train: loss: 0.1858868
[Epoch 66; Iter   145/  229] train: loss: 0.1522733
[Epoch 66; Iter   175/  229] train: loss: 0.1659367
[Epoch 66; Iter   205/  229] train: loss: 0.1608062
[Epoch 66] ogbg-moltoxcast: 0.737942 val loss: 0.201959
[Epoch 66] ogbg-moltoxcast: 0.753111 test loss: 0.209711
[Epoch 67; Iter     6/  229] train: loss: 0.1645791
[Epoch 67; Iter    36/  229] train: loss: 0.1393762
[Epoch 67; Iter    66/  229] train: loss: 0.1651846
[Epoch 67; Iter    96/  229] train: loss: 0.1167812
[Epoch 67; Iter   126/  229] train: loss: 0.1846816
[Epoch 67; Iter   156/  229] train: loss: 0.1278307
[Epoch 67; Iter   186/  229] train: loss: 0.1118484
[Epoch 67; Iter   216/  229] train: loss: 0.1565746
[Epoch 67] ogbg-moltoxcast: 0.741761 val loss: 0.200453
[Epoch 67] ogbg-moltoxcast: 0.753583 test loss: 0.207127
[Epoch 68; Iter    17/  229] train: loss: 0.1555977
[Epoch 68; Iter    47/  229] train: loss: 0.1619519
[Epoch 68; Iter    77/  229] train: loss: 0.1876838
[Epoch 68; Iter   107/  229] train: loss: 0.1660737
[Epoch 68; Iter   137/  229] train: loss: 0.1159263
[Epoch 68; Iter   167/  229] train: loss: 0.1334172
[Epoch 68; Iter   197/  229] train: loss: 0.0943968
[Epoch 68; Iter   227/  229] train: loss: 0.1279989
[Epoch 68] ogbg-moltoxcast: 0.740662 val loss: 0.198936
[Epoch 68] ogbg-moltoxcast: 0.752248 test loss: 0.214304
[Epoch 69; Iter    28/  229] train: loss: 0.1198684
[Epoch 69; Iter    58/  229] train: loss: 0.1236660
[Epoch 69; Iter    88/  229] train: loss: 0.1132730
[Epoch 69; Iter   118/  229] train: loss: 0.1174059
[Epoch 69; Iter   148/  229] train: loss: 0.1590850
[Epoch 69; Iter   178/  229] train: loss: 0.1044326
[Epoch 69; Iter   208/  229] train: loss: 0.1539238
[Epoch 69] ogbg-moltoxcast: 0.741668 val loss: 0.201073
[Epoch 69] ogbg-moltoxcast: 0.750187 test loss: 0.209280
[Epoch 70; Iter     9/  229] train: loss: 0.1566115
[Epoch 70; Iter    39/  229] train: loss: 0.1502901
[Epoch 70; Iter    69/  229] train: loss: 0.1187046
[Epoch 70; Iter    99/  229] train: loss: 0.1374300
[Epoch 70; Iter   129/  229] train: loss: 0.1829094
[Epoch 70; Iter   159/  229] train: loss: 0.1082711
[Epoch 70; Iter   189/  229] train: loss: 0.1618335
[Epoch 70; Iter   219/  229] train: loss: 0.1715123
[Epoch 70] ogbg-moltoxcast: 0.744372 val loss: 0.198909
[Epoch 70] ogbg-moltoxcast: 0.752050 test loss: 0.211153
[Epoch 71; Iter    20/  229] train: loss: 0.1456045
[Epoch 71; Iter    50/  229] train: loss: 0.1344348
[Epoch 71; Iter    80/  229] train: loss: 0.1016786
[Epoch 71; Iter   110/  229] train: loss: 0.1117439
[Epoch 71; Iter   140/  229] train: loss: 0.1122096
[Epoch 71; Iter   170/  229] train: loss: 0.1970080
[Epoch 71; Iter   200/  229] train: loss: 0.1292838
[Epoch 71] ogbg-moltoxcast: 0.741076 val loss: 0.200102
[Epoch 71] ogbg-moltoxcast: 0.751762 test loss: 0.216414
[Epoch 72; Iter     1/  229] train: loss: 0.0931867
[Epoch 72; Iter    31/  229] train: loss: 0.1379119
[Epoch 72; Iter    61/  229] train: loss: 0.2229622
[Epoch 72; Iter    91/  229] train: loss: 0.1999338
[Epoch 72; Iter   121/  229] train: loss: 0.1782598
[Epoch 72; Iter   151/  229] train: loss: 0.1211007
[Epoch 72; Iter   181/  229] train: loss: 0.1348917
[Epoch 72; Iter   211/  229] train: loss: 0.1176333
[Epoch 72] ogbg-moltoxcast: 0.743628 val loss: 0.199680
[Epoch 72] ogbg-moltoxcast: 0.751420 test loss: 0.207373
[Epoch 73; Iter    12/  229] train: loss: 0.1386682
[Epoch 73; Iter    42/  229] train: loss: 0.0746052
[Epoch 73; Iter    72/  229] train: loss: 0.1351986
[Epoch 73; Iter   102/  229] train: loss: 0.1469628
[Epoch 73; Iter   132/  229] train: loss: 0.1689426
[Epoch 73; Iter   162/  229] train: loss: 0.1483847
[Epoch 73; Iter   192/  229] train: loss: 0.2013803
[Epoch 73; Iter   222/  229] train: loss: 0.1987523
[Epoch 73] ogbg-moltoxcast: 0.735552 val loss: 0.201443
[Epoch 73] ogbg-moltoxcast: 0.747168 test loss: 0.211259
[Epoch 74; Iter    23/  229] train: loss: 0.1586236
[Epoch 74; Iter    53/  229] train: loss: 0.1425607
[Epoch 74; Iter    83/  229] train: loss: 0.0902480
[Epoch 74; Iter   113/  229] train: loss: 0.1637986
[Epoch 74; Iter   143/  229] train: loss: 0.1347226
[Epoch 74; Iter   173/  229] train: loss: 0.1781278
[Epoch 74; Iter   203/  229] train: loss: 0.1046318
[Epoch 74] ogbg-moltoxcast: 0.747099 val loss: 0.199441
[Epoch 74] ogbg-moltoxcast: 0.753873 test loss: 0.214188
[Epoch 75; Iter     4/  229] train: loss: 0.1445811
[Epoch 75; Iter    34/  229] train: loss: 0.0983108
[Epoch 75; Iter    64/  229] train: loss: 0.1467654
[Epoch 75; Iter    94/  229] train: loss: 0.1731122
[Epoch 75; Iter   124/  229] train: loss: 0.1404062
[Epoch 75; Iter   154/  229] train: loss: 0.1479481
[Epoch 75; Iter   184/  229] train: loss: 0.1606074
[Epoch 75; Iter   214/  229] train: loss: 0.1577831
[Epoch 75] ogbg-moltoxcast: 0.740944 val loss: 0.200599
[Epoch 75] ogbg-moltoxcast: 0.751876 test loss: 0.211800
[Epoch 66; Iter   105/  201] train: loss: 0.1813488
[Epoch 66; Iter   135/  201] train: loss: 0.1429259
[Epoch 66; Iter   165/  201] train: loss: 0.0873935
[Epoch 66; Iter   195/  201] train: loss: 0.1268391
[Epoch 66] ogbg-moltoxcast: 0.736575 val loss: 0.209569
[Epoch 66] ogbg-moltoxcast: 0.751807 test loss: 0.203757
[Epoch 67; Iter    24/  201] train: loss: 0.1322651
[Epoch 67; Iter    54/  201] train: loss: 0.1595218
[Epoch 67; Iter    84/  201] train: loss: 0.1246905
[Epoch 67; Iter   114/  201] train: loss: 0.1368410
[Epoch 67; Iter   144/  201] train: loss: 0.1205767
[Epoch 67; Iter   174/  201] train: loss: 0.1109637
[Epoch 67] ogbg-moltoxcast: 0.737425 val loss: 0.212338
[Epoch 67] ogbg-moltoxcast: 0.749912 test loss: 0.209203
[Epoch 68; Iter     3/  201] train: loss: 0.1183820
[Epoch 68; Iter    33/  201] train: loss: 0.1331967
[Epoch 68; Iter    63/  201] train: loss: 0.1233325
[Epoch 68; Iter    93/  201] train: loss: 0.1447813
[Epoch 68; Iter   123/  201] train: loss: 0.1566073
[Epoch 68; Iter   153/  201] train: loss: 0.1656491
[Epoch 68; Iter   183/  201] train: loss: 0.1287222
[Epoch 68] ogbg-moltoxcast: 0.732348 val loss: 0.210041
[Epoch 68] ogbg-moltoxcast: 0.752520 test loss: 0.203004
[Epoch 69; Iter    12/  201] train: loss: 0.1422557
[Epoch 69; Iter    42/  201] train: loss: 0.1535944
[Epoch 69; Iter    72/  201] train: loss: 0.1441086
[Epoch 69; Iter   102/  201] train: loss: 0.1886044
[Epoch 69; Iter   132/  201] train: loss: 0.1796791
[Epoch 69; Iter   162/  201] train: loss: 0.1424071
[Epoch 69; Iter   192/  201] train: loss: 0.1806137
[Epoch 69] ogbg-moltoxcast: 0.733367 val loss: 0.210290
[Epoch 69] ogbg-moltoxcast: 0.751278 test loss: 0.203415
[Epoch 70; Iter    21/  201] train: loss: 0.1900355
[Epoch 70; Iter    51/  201] train: loss: 0.1404911
[Epoch 70; Iter    81/  201] train: loss: 0.1163296
[Epoch 70; Iter   111/  201] train: loss: 0.1129139
[Epoch 70; Iter   141/  201] train: loss: 0.1746375
[Epoch 70; Iter   171/  201] train: loss: 0.1633972
[Epoch 70; Iter   201/  201] train: loss: 0.3435138
[Epoch 70] ogbg-moltoxcast: 0.733892 val loss: 0.212794
[Epoch 70] ogbg-moltoxcast: 0.751579 test loss: 0.204980
[Epoch 71; Iter    30/  201] train: loss: 0.1475090
[Epoch 71; Iter    60/  201] train: loss: 0.1368352
[Epoch 71; Iter    90/  201] train: loss: 0.1566207
[Epoch 71; Iter   120/  201] train: loss: 0.1371414
[Epoch 71; Iter   150/  201] train: loss: 0.2379499
[Epoch 71; Iter   180/  201] train: loss: 0.1602926
[Epoch 71] ogbg-moltoxcast: 0.734042 val loss: 0.209396
[Epoch 71] ogbg-moltoxcast: 0.753872 test loss: 0.204057
[Epoch 72; Iter     9/  201] train: loss: 0.1282470
[Epoch 72; Iter    39/  201] train: loss: 0.1514179
[Epoch 72; Iter    69/  201] train: loss: 0.1603016
[Epoch 72; Iter    99/  201] train: loss: 0.1805961
[Epoch 72; Iter   129/  201] train: loss: 0.1262352
[Epoch 72; Iter   159/  201] train: loss: 0.1759288
[Epoch 72; Iter   189/  201] train: loss: 0.1916246
[Epoch 72] ogbg-moltoxcast: 0.729528 val loss: 0.213093
[Epoch 72] ogbg-moltoxcast: 0.746867 test loss: 0.206469
[Epoch 73; Iter    18/  201] train: loss: 0.1143474
[Epoch 73; Iter    48/  201] train: loss: 0.1147043
[Epoch 73; Iter    78/  201] train: loss: 0.1273098
[Epoch 73; Iter   108/  201] train: loss: 0.1529855
[Epoch 73; Iter   138/  201] train: loss: 0.1465742
[Epoch 73; Iter   168/  201] train: loss: 0.1534225
[Epoch 73; Iter   198/  201] train: loss: 0.2099633
[Epoch 73] ogbg-moltoxcast: 0.732012 val loss: 0.215751
[Epoch 73] ogbg-moltoxcast: 0.751531 test loss: 0.209103
[Epoch 74; Iter    27/  201] train: loss: 0.1631566
[Epoch 74; Iter    57/  201] train: loss: 0.1692050
[Epoch 74; Iter    87/  201] train: loss: 0.1346899
[Epoch 74; Iter   117/  201] train: loss: 0.1550035
[Epoch 74; Iter   147/  201] train: loss: 0.1726624
[Epoch 74; Iter   177/  201] train: loss: 0.1308521
[Epoch 74] ogbg-moltoxcast: 0.735767 val loss: 0.210402
[Epoch 74] ogbg-moltoxcast: 0.751469 test loss: 0.205073
[Epoch 75; Iter     6/  201] train: loss: 0.1384899
[Epoch 75; Iter    36/  201] train: loss: 0.1472729
[Epoch 75; Iter    66/  201] train: loss: 0.1458674
[Epoch 75; Iter    96/  201] train: loss: 0.1716160
[Epoch 75; Iter   126/  201] train: loss: 0.0988300
[Epoch 75; Iter   156/  201] train: loss: 0.1754315
[Epoch 75; Iter   186/  201] train: loss: 0.1709062
[Epoch 75] ogbg-moltoxcast: 0.734646 val loss: 0.210509
[Epoch 75] ogbg-moltoxcast: 0.748451 test loss: 0.205089
[Epoch 76; Iter    15/  201] train: loss: 0.1772632
[Epoch 76; Iter    45/  201] train: loss: 0.1097201
[Epoch 76; Iter    75/  201] train: loss: 0.1255599
[Epoch 76; Iter   105/  201] train: loss: 0.1518126
[Epoch 76; Iter   135/  201] train: loss: 0.1403549
[Epoch 76; Iter   165/  201] train: loss: 0.1460047
[Epoch 76; Iter   195/  201] train: loss: 0.1280865
[Epoch 76] ogbg-moltoxcast: 0.731915 val loss: 0.212415
[Epoch 76] ogbg-moltoxcast: 0.749225 test loss: 0.204917
[Epoch 77; Iter    24/  201] train: loss: 0.1706457
[Epoch 77; Iter    54/  201] train: loss: 0.1545608
[Epoch 77; Iter    84/  201] train: loss: 0.1719333
[Epoch 77; Iter   114/  201] train: loss: 0.1384963
[Epoch 77; Iter   144/  201] train: loss: 0.1138770
[Epoch 77; Iter   174/  201] train: loss: 0.1477270
[Epoch 77] ogbg-moltoxcast: 0.733290 val loss: 0.212750
[Epoch 77] ogbg-moltoxcast: 0.754722 test loss: 0.203271
[Epoch 78; Iter     3/  201] train: loss: 0.1352773
[Epoch 78; Iter    33/  201] train: loss: 0.1146468
[Epoch 78; Iter    63/  201] train: loss: 0.1882634
[Epoch 78; Iter    93/  201] train: loss: 0.1230713
[Epoch 78; Iter   123/  201] train: loss: 0.1381151
[Epoch 78; Iter   153/  201] train: loss: 0.1381815
[Epoch 78; Iter   183/  201] train: loss: 0.1845445
[Epoch 78] ogbg-moltoxcast: 0.734744 val loss: 0.212980
[Epoch 78] ogbg-moltoxcast: 0.750997 test loss: 0.209140
[Epoch 79; Iter    12/  201] train: loss: 0.1047299
[Epoch 79; Iter    42/  201] train: loss: 0.2453814
[Epoch 79; Iter    72/  201] train: loss: 0.1788303
[Epoch 79; Iter   102/  201] train: loss: 0.1377379
[Epoch 79; Iter   132/  201] train: loss: 0.1838042
[Epoch 79; Iter   162/  201] train: loss: 0.1675580
[Epoch 79; Iter   192/  201] train: loss: 0.1745665
[Epoch 79] ogbg-moltoxcast: 0.728573 val loss: 0.214433
[Epoch 79] ogbg-moltoxcast: 0.749021 test loss: 0.206456
[Epoch 80; Iter    21/  201] train: loss: 0.1891083
[Epoch 80; Iter    51/  201] train: loss: 0.1551236
[Epoch 80; Iter    81/  201] train: loss: 0.1703789
[Epoch 80; Iter   111/  201] train: loss: 0.1776083
[Epoch 80; Iter   141/  201] train: loss: 0.1446075
[Epoch 80; Iter   171/  201] train: loss: 0.1868673
[Epoch 80; Iter   201/  201] train: loss: 0.2201924
[Epoch 80] ogbg-moltoxcast: 0.730463 val loss: 0.210196
[Epoch 80] ogbg-moltoxcast: 0.750412 test loss: 0.204422
[Epoch 81; Iter    30/  201] train: loss: 0.1342565
[Epoch 81; Iter    60/  201] train: loss: 0.1355540
[Epoch 81; Iter    90/  201] train: loss: 0.1431221
[Epoch 81; Iter   120/  201] train: loss: 0.1613934
[Epoch 81; Iter   150/  201] train: loss: 0.1491421
[Epoch 81; Iter   180/  201] train: loss: 0.1353061
[Epoch 81] ogbg-moltoxcast: 0.734815 val loss: 0.210669
[Epoch 81] ogbg-moltoxcast: 0.756099 test loss: 0.203489
[Epoch 82; Iter     9/  201] train: loss: 0.0982862
[Epoch 82; Iter    39/  201] train: loss: 0.1052156
[Epoch 82; Iter    69/  201] train: loss: 0.1164932
[Epoch 82; Iter    99/  201] train: loss: 0.1388471
[Epoch 82; Iter   129/  201] train: loss: 0.1476631
[Epoch 82; Iter   159/  201] train: loss: 0.1599198
[Epoch 82; Iter   189/  201] train: loss: 0.1157870
[Epoch 82] ogbg-moltoxcast: 0.730288 val loss: 0.214157
[Epoch 82] ogbg-moltoxcast: 0.751088 test loss: 0.208475
[Epoch 83; Iter    18/  201] train: loss: 0.1873835
[Epoch 83; Iter    48/  201] train: loss: 0.0975458
[Epoch 83; Iter    78/  201] train: loss: 0.1255966
[Epoch 83; Iter   108/  201] train: loss: 0.1257540
[Epoch 83; Iter   138/  201] train: loss: 0.1568809
[Epoch 83; Iter   168/  201] train: loss: 0.1191782
[Epoch 83; Iter   198/  201] train: loss: 0.1431369
[Epoch 83] ogbg-moltoxcast: 0.730345 val loss: 0.212322
[Epoch 83] ogbg-moltoxcast: 0.751845 test loss: 0.205132
[Epoch 66; Iter   105/  201] train: loss: 0.1009641
[Epoch 66; Iter   135/  201] train: loss: 0.1222003
[Epoch 66; Iter   165/  201] train: loss: 0.1160970
[Epoch 66; Iter   195/  201] train: loss: 0.1996098
[Epoch 66] ogbg-moltoxcast: 0.737227 val loss: 0.208884
[Epoch 66] ogbg-moltoxcast: 0.752297 test loss: 0.208707
[Epoch 67; Iter    24/  201] train: loss: 0.1432322
[Epoch 67; Iter    54/  201] train: loss: 0.1191140
[Epoch 67; Iter    84/  201] train: loss: 0.1894319
[Epoch 67; Iter   114/  201] train: loss: 0.1391463
[Epoch 67; Iter   144/  201] train: loss: 0.1394536
[Epoch 67; Iter   174/  201] train: loss: 0.1162073
[Epoch 67] ogbg-moltoxcast: 0.739203 val loss: 0.208342
[Epoch 67] ogbg-moltoxcast: 0.749888 test loss: 0.209919
[Epoch 68; Iter     3/  201] train: loss: 0.1297410
[Epoch 68; Iter    33/  201] train: loss: 0.1712367
[Epoch 68; Iter    63/  201] train: loss: 0.1793455
[Epoch 68; Iter    93/  201] train: loss: 0.1077875
[Epoch 68; Iter   123/  201] train: loss: 0.1123328
[Epoch 68; Iter   153/  201] train: loss: 0.1517463
[Epoch 68; Iter   183/  201] train: loss: 0.1732092
[Epoch 68] ogbg-moltoxcast: 0.739620 val loss: 0.208165
[Epoch 68] ogbg-moltoxcast: 0.747928 test loss: 0.211415
[Epoch 69; Iter    12/  201] train: loss: 0.1993302
[Epoch 69; Iter    42/  201] train: loss: 0.1568860
[Epoch 69; Iter    72/  201] train: loss: 0.1229279
[Epoch 69; Iter   102/  201] train: loss: 0.1158618
[Epoch 69; Iter   132/  201] train: loss: 0.0952009
[Epoch 69; Iter   162/  201] train: loss: 0.1544146
[Epoch 69; Iter   192/  201] train: loss: 0.1237124
[Epoch 69] ogbg-moltoxcast: 0.739202 val loss: 0.208518
[Epoch 69] ogbg-moltoxcast: 0.746952 test loss: 0.214379
[Epoch 70; Iter    21/  201] train: loss: 0.1309137
[Epoch 70; Iter    51/  201] train: loss: 0.1608008
[Epoch 70; Iter    81/  201] train: loss: 0.1492496
[Epoch 70; Iter   111/  201] train: loss: 0.1059262
[Epoch 70; Iter   141/  201] train: loss: 0.1593037
[Epoch 70; Iter   171/  201] train: loss: 0.1174391
[Epoch 70; Iter   201/  201] train: loss: 0.0466145
[Epoch 70] ogbg-moltoxcast: 0.734008 val loss: 0.211593
[Epoch 70] ogbg-moltoxcast: 0.748724 test loss: 0.211919
[Epoch 71; Iter    30/  201] train: loss: 0.1107048
[Epoch 71; Iter    60/  201] train: loss: 0.1758662
[Epoch 71; Iter    90/  201] train: loss: 0.1955696
[Epoch 71; Iter   120/  201] train: loss: 0.1453178
[Epoch 71; Iter   150/  201] train: loss: 0.1707519
[Epoch 71; Iter   180/  201] train: loss: 0.1726698
[Epoch 71] ogbg-moltoxcast: 0.739324 val loss: 0.209751
[Epoch 71] ogbg-moltoxcast: 0.748183 test loss: 0.214258
[Epoch 72; Iter     9/  201] train: loss: 0.1659829
[Epoch 72; Iter    39/  201] train: loss: 0.1289874
[Epoch 72; Iter    69/  201] train: loss: 0.1032505
[Epoch 72; Iter    99/  201] train: loss: 0.1701081
[Epoch 72; Iter   129/  201] train: loss: 0.1463347
[Epoch 72; Iter   159/  201] train: loss: 0.1560235
[Epoch 72; Iter   189/  201] train: loss: 0.1908296
[Epoch 72] ogbg-moltoxcast: 0.744968 val loss: 0.206577
[Epoch 72] ogbg-moltoxcast: 0.754556 test loss: 0.210878
[Epoch 73; Iter    18/  201] train: loss: 0.1755396
[Epoch 73; Iter    48/  201] train: loss: 0.1285450
[Epoch 73; Iter    78/  201] train: loss: 0.1461702
[Epoch 73; Iter   108/  201] train: loss: 0.1444906
[Epoch 73; Iter   138/  201] train: loss: 0.1574551
[Epoch 73; Iter   168/  201] train: loss: 0.1218779
[Epoch 73; Iter   198/  201] train: loss: 0.0932206
[Epoch 73] ogbg-moltoxcast: 0.740437 val loss: 0.212882
[Epoch 73] ogbg-moltoxcast: 0.748116 test loss: 0.219350
[Epoch 74; Iter    27/  201] train: loss: 0.1416448
[Epoch 74; Iter    57/  201] train: loss: 0.1331445
[Epoch 74; Iter    87/  201] train: loss: 0.1500209
[Epoch 74; Iter   117/  201] train: loss: 0.1439332
[Epoch 74; Iter   147/  201] train: loss: 0.1354280
[Epoch 74; Iter   177/  201] train: loss: 0.1490621
[Epoch 74] ogbg-moltoxcast: 0.737014 val loss: 0.213156
[Epoch 74] ogbg-moltoxcast: 0.753174 test loss: 0.212999
[Epoch 75; Iter     6/  201] train: loss: 0.1535049
[Epoch 75; Iter    36/  201] train: loss: 0.1627512
[Epoch 75; Iter    66/  201] train: loss: 0.1584935
[Epoch 75; Iter    96/  201] train: loss: 0.1160764
[Epoch 75; Iter   126/  201] train: loss: 0.1430816
[Epoch 75; Iter   156/  201] train: loss: 0.1232353
[Epoch 75; Iter   186/  201] train: loss: 0.1293161
[Epoch 75] ogbg-moltoxcast: 0.737178 val loss: 0.210954
[Epoch 75] ogbg-moltoxcast: 0.743027 test loss: 0.217485
[Epoch 76; Iter    15/  201] train: loss: 0.1370341
[Epoch 76; Iter    45/  201] train: loss: 0.0917511
[Epoch 76; Iter    75/  201] train: loss: 0.1403714
[Epoch 76; Iter   105/  201] train: loss: 0.1093456
[Epoch 76; Iter   135/  201] train: loss: 0.1686784
[Epoch 76; Iter   165/  201] train: loss: 0.1589714
[Epoch 76; Iter   195/  201] train: loss: 0.0905967
[Epoch 76] ogbg-moltoxcast: 0.738698 val loss: 0.212044
[Epoch 76] ogbg-moltoxcast: 0.751013 test loss: 0.213352
[Epoch 77; Iter    24/  201] train: loss: 0.1490542
[Epoch 77; Iter    54/  201] train: loss: 0.1335590
[Epoch 77; Iter    84/  201] train: loss: 0.1218467
[Epoch 77; Iter   114/  201] train: loss: 0.0647262
[Epoch 77; Iter   144/  201] train: loss: 0.1168882
[Epoch 77; Iter   174/  201] train: loss: 0.0978688
[Epoch 77] ogbg-moltoxcast: 0.733320 val loss: 0.213725
[Epoch 77] ogbg-moltoxcast: 0.750764 test loss: 0.216079
[Epoch 78; Iter     3/  201] train: loss: 0.1246268
[Epoch 78; Iter    33/  201] train: loss: 0.1130818
[Epoch 78; Iter    63/  201] train: loss: 0.1196998
[Epoch 78; Iter    93/  201] train: loss: 0.1969401
[Epoch 78; Iter   123/  201] train: loss: 0.0977690
[Epoch 78; Iter   153/  201] train: loss: 0.1157047
[Epoch 78; Iter   183/  201] train: loss: 0.1738092
[Epoch 78] ogbg-moltoxcast: 0.737568 val loss: 0.212842
[Epoch 78] ogbg-moltoxcast: 0.751042 test loss: 0.214591
[Epoch 79; Iter    12/  201] train: loss: 0.1372299
[Epoch 79; Iter    42/  201] train: loss: 0.1169951
[Epoch 79; Iter    72/  201] train: loss: 0.1215553
[Epoch 79; Iter   102/  201] train: loss: 0.0732387
[Epoch 79; Iter   132/  201] train: loss: 0.1257229
[Epoch 79; Iter   162/  201] train: loss: 0.1680616
[Epoch 79; Iter   192/  201] train: loss: 0.0923209
[Epoch 79] ogbg-moltoxcast: 0.740952 val loss: 0.210576
[Epoch 79] ogbg-moltoxcast: 0.749687 test loss: 0.213332
[Epoch 80; Iter    21/  201] train: loss: 0.1258320
[Epoch 80; Iter    51/  201] train: loss: 0.1306885
[Epoch 80; Iter    81/  201] train: loss: 0.1390861
[Epoch 80; Iter   111/  201] train: loss: 0.1148701
[Epoch 80; Iter   141/  201] train: loss: 0.1515335
[Epoch 80; Iter   171/  201] train: loss: 0.1487137
[Epoch 80; Iter   201/  201] train: loss: 0.0885687
[Epoch 80] ogbg-moltoxcast: 0.738058 val loss: 0.207899
[Epoch 80] ogbg-moltoxcast: 0.742273 test loss: 0.215304
[Epoch 81; Iter    30/  201] train: loss: 0.1309822
[Epoch 81; Iter    60/  201] train: loss: 0.1139657
[Epoch 81; Iter    90/  201] train: loss: 0.1328865
[Epoch 81; Iter   120/  201] train: loss: 0.1223558
[Epoch 81; Iter   150/  201] train: loss: 0.1347789
[Epoch 81; Iter   180/  201] train: loss: 0.1412765
[Epoch 81] ogbg-moltoxcast: 0.738522 val loss: 0.214042
[Epoch 81] ogbg-moltoxcast: 0.750036 test loss: 0.215550
[Epoch 82; Iter     9/  201] train: loss: 0.1339186
[Epoch 82; Iter    39/  201] train: loss: 0.1288823
[Epoch 82; Iter    69/  201] train: loss: 0.1348110
[Epoch 82; Iter    99/  201] train: loss: 0.1398655
[Epoch 82; Iter   129/  201] train: loss: 0.1303253
[Epoch 82; Iter   159/  201] train: loss: 0.1240548
[Epoch 82; Iter   189/  201] train: loss: 0.1724613
[Epoch 82] ogbg-moltoxcast: 0.736435 val loss: 0.214542
[Epoch 82] ogbg-moltoxcast: 0.746128 test loss: 0.219316
[Epoch 83; Iter    18/  201] train: loss: 0.1104666
[Epoch 83; Iter    48/  201] train: loss: 0.1511171
[Epoch 83; Iter    78/  201] train: loss: 0.1120725
[Epoch 83; Iter   108/  201] train: loss: 0.1368327
[Epoch 83; Iter   138/  201] train: loss: 0.1837607
[Epoch 83; Iter   168/  201] train: loss: 0.1631172
[Epoch 83; Iter   198/  201] train: loss: 0.1053027
[Epoch 83] ogbg-moltoxcast: 0.731033 val loss: 0.217035
[Epoch 83] ogbg-moltoxcast: 0.746394 test loss: 0.217388
[Epoch 66; Iter   105/  201] train: loss: 0.1688990
[Epoch 66; Iter   135/  201] train: loss: 0.1402379
[Epoch 66; Iter   165/  201] train: loss: 0.1429945
[Epoch 66; Iter   195/  201] train: loss: 0.1655085
[Epoch 66] ogbg-moltoxcast: 0.732583 val loss: 0.210070
[Epoch 66] ogbg-moltoxcast: 0.749035 test loss: 0.208809
[Epoch 67; Iter    24/  201] train: loss: 0.1405255
[Epoch 67; Iter    54/  201] train: loss: 0.1110718
[Epoch 67; Iter    84/  201] train: loss: 0.1897897
[Epoch 67; Iter   114/  201] train: loss: 0.1819524
[Epoch 67; Iter   144/  201] train: loss: 0.1686792
[Epoch 67; Iter   174/  201] train: loss: 0.1463577
[Epoch 67] ogbg-moltoxcast: 0.736783 val loss: 0.213924
[Epoch 67] ogbg-moltoxcast: 0.753126 test loss: 0.205190
[Epoch 68; Iter     3/  201] train: loss: 0.1807691
[Epoch 68; Iter    33/  201] train: loss: 0.1361523
[Epoch 68; Iter    63/  201] train: loss: 0.1592091
[Epoch 68; Iter    93/  201] train: loss: 0.1341539
[Epoch 68; Iter   123/  201] train: loss: 0.1587664
[Epoch 68; Iter   153/  201] train: loss: 0.1315012
[Epoch 68; Iter   183/  201] train: loss: 0.1998260
[Epoch 68] ogbg-moltoxcast: 0.735768 val loss: 0.212547
[Epoch 68] ogbg-moltoxcast: 0.743701 test loss: 0.210516
[Epoch 69; Iter    12/  201] train: loss: 0.1109803
[Epoch 69; Iter    42/  201] train: loss: 0.1393664
[Epoch 69; Iter    72/  201] train: loss: 0.1834194
[Epoch 69; Iter   102/  201] train: loss: 0.1237251
[Epoch 69; Iter   132/  201] train: loss: 0.1605181
[Epoch 69; Iter   162/  201] train: loss: 0.1210070
[Epoch 69; Iter   192/  201] train: loss: 0.1291957
[Epoch 69] ogbg-moltoxcast: 0.738549 val loss: 0.212398
[Epoch 69] ogbg-moltoxcast: 0.748116 test loss: 0.208934
[Epoch 70; Iter    21/  201] train: loss: 0.1529882
[Epoch 70; Iter    51/  201] train: loss: 0.1083258
[Epoch 70; Iter    81/  201] train: loss: 0.1416256
[Epoch 70; Iter   111/  201] train: loss: 0.1626618
[Epoch 70; Iter   141/  201] train: loss: 0.1374326
[Epoch 70; Iter   171/  201] train: loss: 0.1654626
[Epoch 70; Iter   201/  201] train: loss: 0.0395093
[Epoch 70] ogbg-moltoxcast: 0.734810 val loss: 0.214140
[Epoch 70] ogbg-moltoxcast: 0.744297 test loss: 0.210476
[Epoch 71; Iter    30/  201] train: loss: 0.1674062
[Epoch 71; Iter    60/  201] train: loss: 0.1129528
[Epoch 71; Iter    90/  201] train: loss: 0.1974663
[Epoch 71; Iter   120/  201] train: loss: 0.1124854
[Epoch 71; Iter   150/  201] train: loss: 0.1902967
[Epoch 71; Iter   180/  201] train: loss: 0.1489503
[Epoch 71] ogbg-moltoxcast: 0.733381 val loss: 0.212470
[Epoch 71] ogbg-moltoxcast: 0.746824 test loss: 0.208169
[Epoch 72; Iter     9/  201] train: loss: 0.1090803
[Epoch 72; Iter    39/  201] train: loss: 0.1167139
[Epoch 72; Iter    69/  201] train: loss: 0.1483902
[Epoch 72; Iter    99/  201] train: loss: 0.1626884
[Epoch 72; Iter   129/  201] train: loss: 0.1710185
[Epoch 72; Iter   159/  201] train: loss: 0.1709952
[Epoch 72; Iter   189/  201] train: loss: 0.1370390
[Epoch 72] ogbg-moltoxcast: 0.732296 val loss: 0.213141
[Epoch 72] ogbg-moltoxcast: 0.745183 test loss: 0.212630
[Epoch 73; Iter    18/  201] train: loss: 0.1377127
[Epoch 73; Iter    48/  201] train: loss: 0.1425406
[Epoch 73; Iter    78/  201] train: loss: 0.1503855
[Epoch 73; Iter   108/  201] train: loss: 0.1920735
[Epoch 73; Iter   138/  201] train: loss: 0.1515272
[Epoch 73; Iter   168/  201] train: loss: 0.1739891
[Epoch 73; Iter   198/  201] train: loss: 0.1325138
[Epoch 73] ogbg-moltoxcast: 0.736818 val loss: 0.211132
[Epoch 73] ogbg-moltoxcast: 0.748080 test loss: 0.207775
[Epoch 74; Iter    27/  201] train: loss: 0.2607383
[Epoch 74; Iter    57/  201] train: loss: 0.1289296
[Epoch 74; Iter    87/  201] train: loss: 0.1338346
[Epoch 74; Iter   117/  201] train: loss: 0.1333157
[Epoch 74; Iter   147/  201] train: loss: 0.1201672
[Epoch 74; Iter   177/  201] train: loss: 0.1189142
[Epoch 74] ogbg-moltoxcast: 0.738603 val loss: 0.212300
[Epoch 74] ogbg-moltoxcast: 0.747249 test loss: 0.209915
[Epoch 75; Iter     6/  201] train: loss: 0.1302236
[Epoch 75; Iter    36/  201] train: loss: 0.1359480
[Epoch 75; Iter    66/  201] train: loss: 0.1178409
[Epoch 75; Iter    96/  201] train: loss: 0.1225209
[Epoch 75; Iter   126/  201] train: loss: 0.1248932
[Epoch 75; Iter   156/  201] train: loss: 0.1669777
[Epoch 75; Iter   186/  201] train: loss: 0.1337623
[Epoch 75] ogbg-moltoxcast: 0.735290 val loss: 0.212361
[Epoch 75] ogbg-moltoxcast: 0.744021 test loss: 0.210627
[Epoch 76; Iter    15/  201] train: loss: 0.1779203
[Epoch 76; Iter    45/  201] train: loss: 0.1285459
[Epoch 76; Iter    75/  201] train: loss: 0.1055859
[Epoch 76; Iter   105/  201] train: loss: 0.1142400
[Epoch 76; Iter   135/  201] train: loss: 0.1077988
[Epoch 76; Iter   165/  201] train: loss: 0.1276834
[Epoch 76; Iter   195/  201] train: loss: 0.2011306
[Epoch 76] ogbg-moltoxcast: 0.736388 val loss: 0.213381
[Epoch 76] ogbg-moltoxcast: 0.747791 test loss: 0.211324
[Epoch 77; Iter    24/  201] train: loss: 0.2111001
[Epoch 77; Iter    54/  201] train: loss: 0.0961673
[Epoch 77; Iter    84/  201] train: loss: 0.1457481
[Epoch 77; Iter   114/  201] train: loss: 0.1179167
[Epoch 77; Iter   144/  201] train: loss: 0.2635765
[Epoch 77; Iter   174/  201] train: loss: 0.2351661
[Epoch 77] ogbg-moltoxcast: 0.735473 val loss: 0.218189
[Epoch 77] ogbg-moltoxcast: 0.746805 test loss: 0.218358
[Epoch 78; Iter     3/  201] train: loss: 0.1515189
[Epoch 78; Iter    33/  201] train: loss: 0.1513103
[Epoch 78; Iter    63/  201] train: loss: 0.1492763
[Epoch 78; Iter    93/  201] train: loss: 0.1628480
[Epoch 78; Iter   123/  201] train: loss: 0.1371861
[Epoch 78; Iter   153/  201] train: loss: 0.1206163
[Epoch 78; Iter   183/  201] train: loss: 0.1475541
[Epoch 78] ogbg-moltoxcast: 0.735670 val loss: 0.213386
[Epoch 78] ogbg-moltoxcast: 0.748299 test loss: 0.211187
[Epoch 79; Iter    12/  201] train: loss: 0.2103114
[Epoch 79; Iter    42/  201] train: loss: 0.1319298
[Epoch 79; Iter    72/  201] train: loss: 0.1257890
[Epoch 79; Iter   102/  201] train: loss: 0.1622074
[Epoch 79; Iter   132/  201] train: loss: 0.1737527
[Epoch 79; Iter   162/  201] train: loss: 0.1436729
[Epoch 79; Iter   192/  201] train: loss: 0.1429583
[Epoch 79] ogbg-moltoxcast: 0.733750 val loss: 0.213897
[Epoch 79] ogbg-moltoxcast: 0.745009 test loss: 0.214723
[Epoch 80; Iter    21/  201] train: loss: 0.0932015
[Epoch 80; Iter    51/  201] train: loss: 0.1433289
[Epoch 80; Iter    81/  201] train: loss: 0.1376391
[Epoch 80; Iter   111/  201] train: loss: 0.1573387
[Epoch 80; Iter   141/  201] train: loss: 0.1934061
[Epoch 80; Iter   171/  201] train: loss: 0.1417290
[Epoch 80; Iter   201/  201] train: loss: 0.0733982
[Epoch 80] ogbg-moltoxcast: 0.731668 val loss: 0.214308
[Epoch 80] ogbg-moltoxcast: 0.746363 test loss: 0.213612
[Epoch 81; Iter    30/  201] train: loss: 0.1679175
[Epoch 81; Iter    60/  201] train: loss: 0.1597873
[Epoch 81; Iter    90/  201] train: loss: 0.1479573
[Epoch 81; Iter   120/  201] train: loss: 0.1607972
[Epoch 81; Iter   150/  201] train: loss: 0.1365716
[Epoch 81; Iter   180/  201] train: loss: 0.2052434
[Epoch 81] ogbg-moltoxcast: 0.736159 val loss: 0.213413
[Epoch 81] ogbg-moltoxcast: 0.742794 test loss: 0.215312
[Epoch 82; Iter     9/  201] train: loss: 0.1730599
[Epoch 82; Iter    39/  201] train: loss: 0.1657990
[Epoch 82; Iter    69/  201] train: loss: 0.1630596
[Epoch 82; Iter    99/  201] train: loss: 0.1274407
[Epoch 82; Iter   129/  201] train: loss: 0.1425610
[Epoch 82; Iter   159/  201] train: loss: 0.1830483
[Epoch 82; Iter   189/  201] train: loss: 0.1705630
[Epoch 82] ogbg-moltoxcast: 0.734257 val loss: 0.215326
[Epoch 82] ogbg-moltoxcast: 0.746213 test loss: 0.214694
[Epoch 83; Iter    18/  201] train: loss: 0.1727450
[Epoch 83; Iter    48/  201] train: loss: 0.1430682
[Epoch 83; Iter    78/  201] train: loss: 0.1445262
[Epoch 83; Iter   108/  201] train: loss: 0.1217091
[Epoch 83; Iter   138/  201] train: loss: 0.1693351
[Epoch 83; Iter   168/  201] train: loss: 0.1250512
[Epoch 83; Iter   198/  201] train: loss: 0.1457493
[Epoch 83] ogbg-moltoxcast: 0.735474 val loss: 0.215291
[Epoch 83] ogbg-moltoxcast: 0.744047 test loss: 0.214490
[Epoch 74; Iter   134/  172] train: loss: 0.1127307
[Epoch 74; Iter   164/  172] train: loss: 0.1193612
[Epoch 74] ogbg-moltoxcast: 0.722571 val loss: 0.214668
[Epoch 74] ogbg-moltoxcast: 0.745259 test loss: 0.208810
[Epoch 75; Iter    22/  172] train: loss: 0.1480474
[Epoch 75; Iter    52/  172] train: loss: 0.1480163
[Epoch 75; Iter    82/  172] train: loss: 0.0797611
[Epoch 75; Iter   112/  172] train: loss: 0.1238974
[Epoch 75; Iter   142/  172] train: loss: 0.1486882
[Epoch 75; Iter   172/  172] train: loss: 0.1869803
[Epoch 75] ogbg-moltoxcast: 0.718102 val loss: 0.216680
[Epoch 75] ogbg-moltoxcast: 0.742364 test loss: 0.210263
[Epoch 76; Iter    30/  172] train: loss: 0.1732669
[Epoch 76; Iter    60/  172] train: loss: 0.1670903
[Epoch 76; Iter    90/  172] train: loss: 0.1363107
[Epoch 76; Iter   120/  172] train: loss: 0.1569996
[Epoch 76; Iter   150/  172] train: loss: 0.1268620
[Epoch 76] ogbg-moltoxcast: 0.724077 val loss: 0.214695
[Epoch 76] ogbg-moltoxcast: 0.748370 test loss: 0.208454
[Epoch 77; Iter     8/  172] train: loss: 0.1085427
[Epoch 77; Iter    38/  172] train: loss: 0.1344013
[Epoch 77; Iter    68/  172] train: loss: 0.1196419
[Epoch 77; Iter    98/  172] train: loss: 0.1379331
[Epoch 77; Iter   128/  172] train: loss: 0.1694274
[Epoch 77; Iter   158/  172] train: loss: 0.1299349
[Epoch 77] ogbg-moltoxcast: 0.720549 val loss: 0.216450
[Epoch 77] ogbg-moltoxcast: 0.743392 test loss: 0.210641
[Epoch 78; Iter    16/  172] train: loss: 0.0875434
[Epoch 78; Iter    46/  172] train: loss: 0.1039473
[Epoch 78; Iter    76/  172] train: loss: 0.1092738
[Epoch 78; Iter   106/  172] train: loss: 0.1525362
[Epoch 78; Iter   136/  172] train: loss: 0.1821443
[Epoch 78; Iter   166/  172] train: loss: 0.1088221
[Epoch 78] ogbg-moltoxcast: 0.722815 val loss: 0.219325
[Epoch 78] ogbg-moltoxcast: 0.746995 test loss: 0.210784
[Epoch 79; Iter    24/  172] train: loss: 0.1159697
[Epoch 79; Iter    54/  172] train: loss: 0.0881957
[Epoch 79; Iter    84/  172] train: loss: 0.1368703
[Epoch 79; Iter   114/  172] train: loss: 0.1670839
[Epoch 79; Iter   144/  172] train: loss: 0.1262847
[Epoch 79] ogbg-moltoxcast: 0.722232 val loss: 0.217046
[Epoch 79] ogbg-moltoxcast: 0.741053 test loss: 0.211800
[Epoch 80; Iter     2/  172] train: loss: 0.1280280
[Epoch 80; Iter    32/  172] train: loss: 0.1366044
[Epoch 80; Iter    62/  172] train: loss: 0.1519830
[Epoch 80; Iter    92/  172] train: loss: 0.1511758
[Epoch 80; Iter   122/  172] train: loss: 0.1311460
[Epoch 80; Iter   152/  172] train: loss: 0.1141657
[Epoch 80] ogbg-moltoxcast: 0.719466 val loss: 0.216836
[Epoch 80] ogbg-moltoxcast: 0.743815 test loss: 0.210148
[Epoch 81; Iter    10/  172] train: loss: 0.1584830
[Epoch 81; Iter    40/  172] train: loss: 0.1177676
[Epoch 81; Iter    70/  172] train: loss: 0.1238755
[Epoch 81; Iter   100/  172] train: loss: 0.1268259
[Epoch 81; Iter   130/  172] train: loss: 0.1361142
[Epoch 81; Iter   160/  172] train: loss: 0.1694573
[Epoch 81] ogbg-moltoxcast: 0.721914 val loss: 0.217716
[Epoch 81] ogbg-moltoxcast: 0.744990 test loss: 0.210935
[Epoch 82; Iter    18/  172] train: loss: 0.1270097
[Epoch 82; Iter    48/  172] train: loss: 0.1334356
[Epoch 82; Iter    78/  172] train: loss: 0.1394067
[Epoch 82; Iter   108/  172] train: loss: 0.1145422
[Epoch 82; Iter   138/  172] train: loss: 0.1485797
[Epoch 82; Iter   168/  172] train: loss: 0.1288841
[Epoch 82] ogbg-moltoxcast: 0.719633 val loss: 0.216568
[Epoch 82] ogbg-moltoxcast: 0.742646 test loss: 0.211646
[Epoch 83; Iter    26/  172] train: loss: 0.0970330
[Epoch 83; Iter    56/  172] train: loss: 0.1386807
[Epoch 83; Iter    86/  172] train: loss: 0.1962873
[Epoch 83; Iter   116/  172] train: loss: 0.1296882
[Epoch 83; Iter   146/  172] train: loss: 0.1234397
[Epoch 83] ogbg-moltoxcast: 0.723549 val loss: 0.220752
[Epoch 83] ogbg-moltoxcast: 0.745479 test loss: 0.214481
[Epoch 84; Iter     4/  172] train: loss: 0.1316776
[Epoch 84; Iter    34/  172] train: loss: 0.1346567
[Epoch 84; Iter    64/  172] train: loss: 0.1077318
[Epoch 84; Iter    94/  172] train: loss: 0.1216269
[Epoch 84; Iter   124/  172] train: loss: 0.1153711
[Epoch 84; Iter   154/  172] train: loss: 0.1572930
[Epoch 84] ogbg-moltoxcast: 0.722931 val loss: 0.219934
[Epoch 84] ogbg-moltoxcast: 0.746646 test loss: 0.211875
[Epoch 85; Iter    12/  172] train: loss: 0.1495468
[Epoch 85; Iter    42/  172] train: loss: 0.1252865
[Epoch 85; Iter    72/  172] train: loss: 0.1197241
[Epoch 85; Iter   102/  172] train: loss: 0.1010127
[Epoch 85; Iter   132/  172] train: loss: 0.1377419
[Epoch 85; Iter   162/  172] train: loss: 0.1578843
[Epoch 85] ogbg-moltoxcast: 0.718931 val loss: 0.220625
[Epoch 85] ogbg-moltoxcast: 0.741489 test loss: 0.210695
[Epoch 86; Iter    20/  172] train: loss: 0.1498260
[Epoch 86; Iter    50/  172] train: loss: 0.0831586
[Epoch 86; Iter    80/  172] train: loss: 0.1453120
[Epoch 86; Iter   110/  172] train: loss: 0.1534880
[Epoch 86; Iter   140/  172] train: loss: 0.1676015
[Epoch 86; Iter   170/  172] train: loss: 0.0910652
[Epoch 86] ogbg-moltoxcast: 0.720933 val loss: 0.218622
[Epoch 86] ogbg-moltoxcast: 0.741513 test loss: 0.212516
[Epoch 87; Iter    28/  172] train: loss: 0.1878828
[Epoch 87; Iter    58/  172] train: loss: 0.0850038
[Epoch 87; Iter    88/  172] train: loss: 0.1378591
[Epoch 87; Iter   118/  172] train: loss: 0.1400542
[Epoch 87; Iter   148/  172] train: loss: 0.1257311
[Epoch 87] ogbg-moltoxcast: 0.720811 val loss: 0.217175
[Epoch 87] ogbg-moltoxcast: 0.743241 test loss: 0.210250
[Epoch 88; Iter     6/  172] train: loss: 0.1789326
[Epoch 88; Iter    36/  172] train: loss: 0.0951989
[Epoch 88; Iter    66/  172] train: loss: 0.1004514
[Epoch 88; Iter    96/  172] train: loss: 0.1828203
[Epoch 88; Iter   126/  172] train: loss: 0.1540828
[Epoch 88; Iter   156/  172] train: loss: 0.1175871
[Epoch 88] ogbg-moltoxcast: 0.719546 val loss: 0.219958
[Epoch 88] ogbg-moltoxcast: 0.746139 test loss: 0.211250
[Epoch 89; Iter    14/  172] train: loss: 0.1520985
[Epoch 89; Iter    44/  172] train: loss: 0.0936476
[Epoch 89; Iter    74/  172] train: loss: 0.1891467
[Epoch 89; Iter   104/  172] train: loss: 0.1340231
[Epoch 89; Iter   134/  172] train: loss: 0.1272434
[Epoch 89; Iter   164/  172] train: loss: 0.1453804
[Epoch 89] ogbg-moltoxcast: 0.720198 val loss: 0.221829
[Epoch 89] ogbg-moltoxcast: 0.745098 test loss: 0.213775
[Epoch 90; Iter    22/  172] train: loss: 0.1149323
[Epoch 90; Iter    52/  172] train: loss: 0.1481148
[Epoch 90; Iter    82/  172] train: loss: 0.1195511
[Epoch 90; Iter   112/  172] train: loss: 0.1608125
[Epoch 90; Iter   142/  172] train: loss: 0.1055485
[Epoch 90; Iter   172/  172] train: loss: 0.1276206
[Epoch 90] ogbg-moltoxcast: 0.720588 val loss: 0.220717
[Epoch 90] ogbg-moltoxcast: 0.741723 test loss: 0.214856
[Epoch 91; Iter    30/  172] train: loss: 0.1070807
[Epoch 91; Iter    60/  172] train: loss: 0.1004526
[Epoch 91; Iter    90/  172] train: loss: 0.1615544
[Epoch 91; Iter   120/  172] train: loss: 0.1027276
[Epoch 91; Iter   150/  172] train: loss: 0.1333196
[Epoch 91] ogbg-moltoxcast: 0.719435 val loss: 0.222045
[Epoch 91] ogbg-moltoxcast: 0.743588 test loss: 0.214397
[Epoch 92; Iter     8/  172] train: loss: 0.1252712
[Epoch 92; Iter    38/  172] train: loss: 0.1024539
[Epoch 92; Iter    68/  172] train: loss: 0.1299085
[Epoch 92; Iter    98/  172] train: loss: 0.0828099
[Epoch 92; Iter   128/  172] train: loss: 0.1046263
[Epoch 92; Iter   158/  172] train: loss: 0.1441790
[Epoch 92] ogbg-moltoxcast: 0.720714 val loss: 0.221244
[Epoch 92] ogbg-moltoxcast: 0.742587 test loss: 0.215478
[Epoch 93; Iter    16/  172] train: loss: 0.1025218
[Epoch 93; Iter    46/  172] train: loss: 0.1690871
[Epoch 93; Iter    76/  172] train: loss: 0.1891352
[Epoch 93; Iter   106/  172] train: loss: 0.0976236
[Epoch 93; Iter   136/  172] train: loss: 0.1201240
[Epoch 93; Iter   166/  172] train: loss: 0.1127119
[Epoch 93] ogbg-moltoxcast: 0.721330 val loss: 0.219207
[Epoch 93] ogbg-moltoxcast: 0.742861 test loss: 0.213399
[Epoch 94; Iter    24/  172] train: loss: 0.1398878
[Epoch 94; Iter    54/  172] train: loss: 0.1350638
[Epoch 94; Iter    84/  172] train: loss: 0.1805275
[Epoch 74; Iter   134/  172] train: loss: 0.2121907
[Epoch 74; Iter   164/  172] train: loss: 0.1421451
[Epoch 74] ogbg-moltoxcast: 0.726856 val loss: 0.230119
[Epoch 74] ogbg-moltoxcast: 0.741115 test loss: 0.209225
[Epoch 75; Iter    22/  172] train: loss: 0.1533156
[Epoch 75; Iter    52/  172] train: loss: 0.1022083
[Epoch 75; Iter    82/  172] train: loss: 0.1568711
[Epoch 75; Iter   112/  172] train: loss: 0.1414872
[Epoch 75; Iter   142/  172] train: loss: 0.1791091
[Epoch 75; Iter   172/  172] train: loss: 0.1755636
[Epoch 75] ogbg-moltoxcast: 0.721527 val loss: 0.234078
[Epoch 75] ogbg-moltoxcast: 0.734260 test loss: 0.211282
[Epoch 76; Iter    30/  172] train: loss: 0.1707755
[Epoch 76; Iter    60/  172] train: loss: 0.1212325
[Epoch 76; Iter    90/  172] train: loss: 0.1872424
[Epoch 76; Iter   120/  172] train: loss: 0.1756027
[Epoch 76; Iter   150/  172] train: loss: 0.1661577
[Epoch 76] ogbg-moltoxcast: 0.727650 val loss: 0.250543
[Epoch 76] ogbg-moltoxcast: 0.737973 test loss: 0.210468
[Epoch 77; Iter     8/  172] train: loss: 0.1139541
[Epoch 77; Iter    38/  172] train: loss: 0.0962598
[Epoch 77; Iter    68/  172] train: loss: 0.1051361
[Epoch 77; Iter    98/  172] train: loss: 0.1380549
[Epoch 77; Iter   128/  172] train: loss: 0.1768233
[Epoch 77; Iter   158/  172] train: loss: 0.0893854
[Epoch 77] ogbg-moltoxcast: 0.724923 val loss: 0.220578
[Epoch 77] ogbg-moltoxcast: 0.735723 test loss: 0.211285
[Epoch 78; Iter    16/  172] train: loss: 0.1573294
[Epoch 78; Iter    46/  172] train: loss: 0.0884691
[Epoch 78; Iter    76/  172] train: loss: 0.1425439
[Epoch 78; Iter   106/  172] train: loss: 0.1820395
[Epoch 78; Iter   136/  172] train: loss: 0.1294084
[Epoch 78; Iter   166/  172] train: loss: 0.1476940
[Epoch 78] ogbg-moltoxcast: 0.726910 val loss: 0.227044
[Epoch 78] ogbg-moltoxcast: 0.733857 test loss: 0.213865
[Epoch 79; Iter    24/  172] train: loss: 0.1151368
[Epoch 79; Iter    54/  172] train: loss: 0.1575834
[Epoch 79; Iter    84/  172] train: loss: 0.1292324
[Epoch 79; Iter   114/  172] train: loss: 0.1269108
[Epoch 79; Iter   144/  172] train: loss: 0.1804782
[Epoch 79] ogbg-moltoxcast: 0.723437 val loss: 0.221225
[Epoch 79] ogbg-moltoxcast: 0.738524 test loss: 0.210627
[Epoch 80; Iter     2/  172] train: loss: 0.1328709
[Epoch 80; Iter    32/  172] train: loss: 0.1385233
[Epoch 80; Iter    62/  172] train: loss: 0.1449221
[Epoch 80; Iter    92/  172] train: loss: 0.1861096
[Epoch 80; Iter   122/  172] train: loss: 0.1638033
[Epoch 80; Iter   152/  172] train: loss: 0.1615232
[Epoch 80] ogbg-moltoxcast: 0.727196 val loss: 0.222640
[Epoch 80] ogbg-moltoxcast: 0.738414 test loss: 0.212030
[Epoch 81; Iter    10/  172] train: loss: 0.1665295
[Epoch 81; Iter    40/  172] train: loss: 0.0723285
[Epoch 81; Iter    70/  172] train: loss: 0.1325654
[Epoch 81; Iter   100/  172] train: loss: 0.1585349
[Epoch 81; Iter   130/  172] train: loss: 0.1381596
[Epoch 81; Iter   160/  172] train: loss: 0.1526332
[Epoch 81] ogbg-moltoxcast: 0.725683 val loss: 0.216444
[Epoch 81] ogbg-moltoxcast: 0.739147 test loss: 0.213289
[Epoch 82; Iter    18/  172] train: loss: 0.1547234
[Epoch 82; Iter    48/  172] train: loss: 0.1195027
[Epoch 82; Iter    78/  172] train: loss: 0.1728623
[Epoch 82; Iter   108/  172] train: loss: 0.1662391
[Epoch 82; Iter   138/  172] train: loss: 0.1357474
[Epoch 82; Iter   168/  172] train: loss: 0.1437700
[Epoch 82] ogbg-moltoxcast: 0.724380 val loss: 0.215525
[Epoch 82] ogbg-moltoxcast: 0.731275 test loss: 0.214639
[Epoch 83; Iter    26/  172] train: loss: 0.0946068
[Epoch 83; Iter    56/  172] train: loss: 0.1116434
[Epoch 83; Iter    86/  172] train: loss: 0.1087521
[Epoch 83; Iter   116/  172] train: loss: 0.1861858
[Epoch 83; Iter   146/  172] train: loss: 0.0916577
[Epoch 83] ogbg-moltoxcast: 0.722805 val loss: 0.214541
[Epoch 83] ogbg-moltoxcast: 0.737594 test loss: 0.210869
[Epoch 84; Iter     4/  172] train: loss: 0.1185480
[Epoch 84; Iter    34/  172] train: loss: 0.1928702
[Epoch 84; Iter    64/  172] train: loss: 0.1091268
[Epoch 84; Iter    94/  172] train: loss: 0.1132752
[Epoch 84; Iter   124/  172] train: loss: 0.1073210
[Epoch 84; Iter   154/  172] train: loss: 0.1229448
[Epoch 84] ogbg-moltoxcast: 0.726121 val loss: 0.215495
[Epoch 84] ogbg-moltoxcast: 0.733268 test loss: 0.213366
[Epoch 85; Iter    12/  172] train: loss: 0.1292557
[Epoch 85; Iter    42/  172] train: loss: 0.1359027
[Epoch 85; Iter    72/  172] train: loss: 0.0987168
[Epoch 85; Iter   102/  172] train: loss: 0.1813083
[Epoch 85; Iter   132/  172] train: loss: 0.1179819
[Epoch 85; Iter   162/  172] train: loss: 0.1267669
[Epoch 85] ogbg-moltoxcast: 0.723431 val loss: 0.234121
[Epoch 85] ogbg-moltoxcast: 0.736113 test loss: 0.212549
[Epoch 86; Iter    20/  172] train: loss: 0.1910866
[Epoch 86; Iter    50/  172] train: loss: 0.1064063
[Epoch 86; Iter    80/  172] train: loss: 0.1590987
[Epoch 86; Iter   110/  172] train: loss: 0.1175955
[Epoch 86; Iter   140/  172] train: loss: 0.1380230
[Epoch 86; Iter   170/  172] train: loss: 0.1569945
[Epoch 86] ogbg-moltoxcast: 0.724120 val loss: 0.239357
[Epoch 86] ogbg-moltoxcast: 0.735749 test loss: 0.211688
[Epoch 87; Iter    28/  172] train: loss: 0.1860277
[Epoch 87; Iter    58/  172] train: loss: 0.1222320
[Epoch 87; Iter    88/  172] train: loss: 0.1427236
[Epoch 87; Iter   118/  172] train: loss: 0.1070823
[Epoch 87; Iter   148/  172] train: loss: 0.1262660
[Epoch 87] ogbg-moltoxcast: 0.720594 val loss: 0.232003
[Epoch 87] ogbg-moltoxcast: 0.734570 test loss: 0.213933
[Epoch 88; Iter     6/  172] train: loss: 0.1029058
[Epoch 88; Iter    36/  172] train: loss: 0.1692382
[Epoch 88; Iter    66/  172] train: loss: 0.1716439
[Epoch 88; Iter    96/  172] train: loss: 0.1421970
[Epoch 88; Iter   126/  172] train: loss: 0.1337197
[Epoch 88; Iter   156/  172] train: loss: 0.1259894
[Epoch 88] ogbg-moltoxcast: 0.716081 val loss: 0.230753
[Epoch 88] ogbg-moltoxcast: 0.725782 test loss: 0.219730
[Epoch 89; Iter    14/  172] train: loss: 0.1258272
[Epoch 89; Iter    44/  172] train: loss: 0.1383371
[Epoch 89; Iter    74/  172] train: loss: 0.1157664
[Epoch 89; Iter   104/  172] train: loss: 0.0953706
[Epoch 89; Iter   134/  172] train: loss: 0.1630402
[Epoch 89; Iter   164/  172] train: loss: 0.1701529
[Epoch 89] ogbg-moltoxcast: 0.721655 val loss: 0.227478
[Epoch 89] ogbg-moltoxcast: 0.733685 test loss: 0.217044
[Epoch 90; Iter    22/  172] train: loss: 0.1403474
[Epoch 90; Iter    52/  172] train: loss: 0.0985726
[Epoch 90; Iter    82/  172] train: loss: 0.0996247
[Epoch 90; Iter   112/  172] train: loss: 0.1520857
[Epoch 90; Iter   142/  172] train: loss: 0.1614289
[Epoch 90; Iter   172/  172] train: loss: 0.1371137
[Epoch 90] ogbg-moltoxcast: 0.724527 val loss: 0.227992
[Epoch 90] ogbg-moltoxcast: 0.733945 test loss: 0.213371
[Epoch 91; Iter    30/  172] train: loss: 0.1206945
[Epoch 91; Iter    60/  172] train: loss: 0.1270353
[Epoch 91; Iter    90/  172] train: loss: 0.1079409
[Epoch 91; Iter   120/  172] train: loss: 0.1197240
[Epoch 91; Iter   150/  172] train: loss: 0.1547435
[Epoch 91] ogbg-moltoxcast: 0.723640 val loss: 0.228642
[Epoch 91] ogbg-moltoxcast: 0.730861 test loss: 0.215518
[Epoch 92; Iter     8/  172] train: loss: 0.1111033
[Epoch 92; Iter    38/  172] train: loss: 0.1343579
[Epoch 92; Iter    68/  172] train: loss: 0.1030614
[Epoch 92; Iter    98/  172] train: loss: 0.1407309
[Epoch 92; Iter   128/  172] train: loss: 0.1807561
[Epoch 92; Iter   158/  172] train: loss: 0.1098923
[Epoch 92] ogbg-moltoxcast: 0.724098 val loss: 0.217093
[Epoch 92] ogbg-moltoxcast: 0.732604 test loss: 0.215648
[Epoch 93; Iter    16/  172] train: loss: 0.1403706
[Epoch 93; Iter    46/  172] train: loss: 0.1612322
[Epoch 93; Iter    76/  172] train: loss: 0.1749126
[Epoch 93; Iter   106/  172] train: loss: 0.1058175
[Epoch 93; Iter   136/  172] train: loss: 0.1162245
[Epoch 93; Iter   166/  172] train: loss: 0.1311400
[Epoch 93] ogbg-moltoxcast: 0.724288 val loss: 0.226590
[Epoch 93] ogbg-moltoxcast: 0.733929 test loss: 0.216610
[Epoch 94; Iter    24/  172] train: loss: 0.0962280
[Epoch 94; Iter    54/  172] train: loss: 0.1136700
[Epoch 94; Iter    84/  172] train: loss: 0.1673831
[Epoch 74; Iter   134/  172] train: loss: 0.1862793
[Epoch 74; Iter   164/  172] train: loss: 0.1505916
[Epoch 74] ogbg-moltoxcast: 0.729182 val loss: 0.211408
[Epoch 74] ogbg-moltoxcast: 0.744310 test loss: 0.210392
[Epoch 75; Iter    22/  172] train: loss: 0.1337379
[Epoch 75; Iter    52/  172] train: loss: 0.1310488
[Epoch 75; Iter    82/  172] train: loss: 0.1690575
[Epoch 75; Iter   112/  172] train: loss: 0.0843812
[Epoch 75; Iter   142/  172] train: loss: 0.1510900
[Epoch 75; Iter   172/  172] train: loss: 0.1467615
[Epoch 75] ogbg-moltoxcast: 0.731876 val loss: 0.209959
[Epoch 75] ogbg-moltoxcast: 0.744787 test loss: 0.210617
[Epoch 76; Iter    30/  172] train: loss: 0.1122439
[Epoch 76; Iter    60/  172] train: loss: 0.1318818
[Epoch 76; Iter    90/  172] train: loss: 0.1326883
[Epoch 76; Iter   120/  172] train: loss: 0.1299246
[Epoch 76; Iter   150/  172] train: loss: 0.1196087
[Epoch 76] ogbg-moltoxcast: 0.728438 val loss: 0.212407
[Epoch 76] ogbg-moltoxcast: 0.742242 test loss: 0.210826
[Epoch 77; Iter     8/  172] train: loss: 0.1233661
[Epoch 77; Iter    38/  172] train: loss: 0.1173927
[Epoch 77; Iter    68/  172] train: loss: 0.1408297
[Epoch 77; Iter    98/  172] train: loss: 0.0788899
[Epoch 77; Iter   128/  172] train: loss: 0.1227314
[Epoch 77; Iter   158/  172] train: loss: 0.1220688
[Epoch 77] ogbg-moltoxcast: 0.728459 val loss: 0.210846
[Epoch 77] ogbg-moltoxcast: 0.742299 test loss: 0.213166
[Epoch 78; Iter    16/  172] train: loss: 0.1261735
[Epoch 78; Iter    46/  172] train: loss: 0.1507820
[Epoch 78; Iter    76/  172] train: loss: 0.1084378
[Epoch 78; Iter   106/  172] train: loss: 0.1187088
[Epoch 78; Iter   136/  172] train: loss: 0.1279963
[Epoch 78; Iter   166/  172] train: loss: 0.1249323
[Epoch 78] ogbg-moltoxcast: 0.731875 val loss: 0.210563
[Epoch 78] ogbg-moltoxcast: 0.745760 test loss: 0.209854
[Epoch 79; Iter    24/  172] train: loss: 0.1021688
[Epoch 79; Iter    54/  172] train: loss: 0.1450489
[Epoch 79; Iter    84/  172] train: loss: 0.1433096
[Epoch 79; Iter   114/  172] train: loss: 0.0860277
[Epoch 79; Iter   144/  172] train: loss: 0.1113546
[Epoch 79] ogbg-moltoxcast: 0.730933 val loss: 0.212020
[Epoch 79] ogbg-moltoxcast: 0.742391 test loss: 0.213605
[Epoch 80; Iter     2/  172] train: loss: 0.1146285
[Epoch 80; Iter    32/  172] train: loss: 0.1515304
[Epoch 80; Iter    62/  172] train: loss: 0.1474443
[Epoch 80; Iter    92/  172] train: loss: 0.1012124
[Epoch 80; Iter   122/  172] train: loss: 0.1110958
[Epoch 80; Iter   152/  172] train: loss: 0.1185962
[Epoch 80] ogbg-moltoxcast: 0.733347 val loss: 0.208328
[Epoch 80] ogbg-moltoxcast: 0.744043 test loss: 0.211072
[Epoch 81; Iter    10/  172] train: loss: 0.1255427
[Epoch 81; Iter    40/  172] train: loss: 0.1698190
[Epoch 81; Iter    70/  172] train: loss: 0.0964366
[Epoch 81; Iter   100/  172] train: loss: 0.1175876
[Epoch 81; Iter   130/  172] train: loss: 0.1446241
[Epoch 81; Iter   160/  172] train: loss: 0.1410555
[Epoch 81] ogbg-moltoxcast: 0.731131 val loss: 0.211850
[Epoch 81] ogbg-moltoxcast: 0.741419 test loss: 0.212138
[Epoch 82; Iter    18/  172] train: loss: 0.1192849
[Epoch 82; Iter    48/  172] train: loss: 0.1659949
[Epoch 82; Iter    78/  172] train: loss: 0.1099871
[Epoch 82; Iter   108/  172] train: loss: 0.1270875
[Epoch 82; Iter   138/  172] train: loss: 0.1251741
[Epoch 82; Iter   168/  172] train: loss: 0.1153222
[Epoch 82] ogbg-moltoxcast: 0.728212 val loss: 0.211486
[Epoch 82] ogbg-moltoxcast: 0.741852 test loss: 0.211692
[Epoch 83; Iter    26/  172] train: loss: 0.1423992
[Epoch 83; Iter    56/  172] train: loss: 0.1271031
[Epoch 83; Iter    86/  172] train: loss: 0.1468703
[Epoch 83; Iter   116/  172] train: loss: 0.1067049
[Epoch 83; Iter   146/  172] train: loss: 0.1220786
[Epoch 83] ogbg-moltoxcast: 0.730141 val loss: 0.212247
[Epoch 83] ogbg-moltoxcast: 0.742048 test loss: 0.213583
[Epoch 84; Iter     4/  172] train: loss: 0.1234402
[Epoch 84; Iter    34/  172] train: loss: 0.1414630
[Epoch 84; Iter    64/  172] train: loss: 0.1079849
[Epoch 84; Iter    94/  172] train: loss: 0.1347151
[Epoch 84; Iter   124/  172] train: loss: 0.1256318
[Epoch 84; Iter   154/  172] train: loss: 0.1113133
[Epoch 84] ogbg-moltoxcast: 0.728533 val loss: 0.210738
[Epoch 84] ogbg-moltoxcast: 0.742242 test loss: 0.210208
[Epoch 85; Iter    12/  172] train: loss: 0.1211137
[Epoch 85; Iter    42/  172] train: loss: 0.1307413
[Epoch 85; Iter    72/  172] train: loss: 0.1469843
[Epoch 85; Iter   102/  172] train: loss: 0.1701016
[Epoch 85; Iter   132/  172] train: loss: 0.1689940
[Epoch 85; Iter   162/  172] train: loss: 0.1360388
[Epoch 85] ogbg-moltoxcast: 0.725849 val loss: 0.212947
[Epoch 85] ogbg-moltoxcast: 0.739241 test loss: 0.213657
[Epoch 86; Iter    20/  172] train: loss: 0.1414394
[Epoch 86; Iter    50/  172] train: loss: 0.1652069
[Epoch 86; Iter    80/  172] train: loss: 0.1393916
[Epoch 86; Iter   110/  172] train: loss: 0.1891614
[Epoch 86; Iter   140/  172] train: loss: 0.1647221
[Epoch 86; Iter   170/  172] train: loss: 0.1519427
[Epoch 86] ogbg-moltoxcast: 0.730055 val loss: 0.212233
[Epoch 86] ogbg-moltoxcast: 0.739863 test loss: 0.214251
[Epoch 87; Iter    28/  172] train: loss: 0.1422485
[Epoch 87; Iter    58/  172] train: loss: 0.1243492
[Epoch 87; Iter    88/  172] train: loss: 0.1481951
[Epoch 87; Iter   118/  172] train: loss: 0.1639481
[Epoch 87; Iter   148/  172] train: loss: 0.1196246
[Epoch 87] ogbg-moltoxcast: 0.728001 val loss: 0.214928
[Epoch 87] ogbg-moltoxcast: 0.738862 test loss: 0.214780
[Epoch 88; Iter     6/  172] train: loss: 0.2057894
[Epoch 88; Iter    36/  172] train: loss: 0.1295120
[Epoch 88; Iter    66/  172] train: loss: 0.1399976
[Epoch 88; Iter    96/  172] train: loss: 0.1516495
[Epoch 88; Iter   126/  172] train: loss: 0.1201501
[Epoch 88; Iter   156/  172] train: loss: 0.1077228
[Epoch 88] ogbg-moltoxcast: 0.725633 val loss: 0.215418
[Epoch 88] ogbg-moltoxcast: 0.737987 test loss: 0.215175
[Epoch 89; Iter    14/  172] train: loss: 0.0962636
[Epoch 89; Iter    44/  172] train: loss: 0.1469069
[Epoch 89; Iter    74/  172] train: loss: 0.1668980
[Epoch 89; Iter   104/  172] train: loss: 0.1213013
[Epoch 89; Iter   134/  172] train: loss: 0.0877381
[Epoch 89; Iter   164/  172] train: loss: 0.1184521
[Epoch 89] ogbg-moltoxcast: 0.730680 val loss: 0.211619
[Epoch 89] ogbg-moltoxcast: 0.738646 test loss: 0.213368
[Epoch 90; Iter    22/  172] train: loss: 0.1476291
[Epoch 90; Iter    52/  172] train: loss: 0.1202181
[Epoch 90; Iter    82/  172] train: loss: 0.0889794
[Epoch 90; Iter   112/  172] train: loss: 0.1040219
[Epoch 90; Iter   142/  172] train: loss: 0.1211445
[Epoch 90; Iter   172/  172] train: loss: 0.1445701
[Epoch 90] ogbg-moltoxcast: 0.729692 val loss: 0.212949
[Epoch 90] ogbg-moltoxcast: 0.741323 test loss: 0.214788
[Epoch 91; Iter    30/  172] train: loss: 0.1554957
[Epoch 91; Iter    60/  172] train: loss: 0.1233668
[Epoch 91; Iter    90/  172] train: loss: 0.1463251
[Epoch 91; Iter   120/  172] train: loss: 0.0895891
[Epoch 91; Iter   150/  172] train: loss: 0.1543180
[Epoch 91] ogbg-moltoxcast: 0.731080 val loss: 0.212316
[Epoch 91] ogbg-moltoxcast: 0.740793 test loss: 0.214898
[Epoch 92; Iter     8/  172] train: loss: 0.1153588
[Epoch 92; Iter    38/  172] train: loss: 0.1166496
[Epoch 92; Iter    68/  172] train: loss: 0.1535058
[Epoch 92; Iter    98/  172] train: loss: 0.1386832
[Epoch 92; Iter   128/  172] train: loss: 0.1245963
[Epoch 92; Iter   158/  172] train: loss: 0.1143442
[Epoch 92] ogbg-moltoxcast: 0.730314 val loss: 0.210954
[Epoch 92] ogbg-moltoxcast: 0.741345 test loss: 0.213406
[Epoch 93; Iter    16/  172] train: loss: 0.1301204
[Epoch 93; Iter    46/  172] train: loss: 0.1573281
[Epoch 93; Iter    76/  172] train: loss: 0.1414872
[Epoch 93; Iter   106/  172] train: loss: 0.1625557
[Epoch 93; Iter   136/  172] train: loss: 0.1302606
[Epoch 93; Iter   166/  172] train: loss: 0.1523346
[Epoch 93] ogbg-moltoxcast: 0.729483 val loss: 0.215578
[Epoch 93] ogbg-moltoxcast: 0.739282 test loss: 0.217706
[Epoch 94; Iter    24/  172] train: loss: 0.1101489
[Epoch 94; Iter    54/  172] train: loss: 0.1550139
[Epoch 94; Iter    84/  172] train: loss: 0.0891679
[Epoch 76; Iter    15/  229] train: loss: 0.1171530
[Epoch 76; Iter    45/  229] train: loss: 0.2102858
[Epoch 76; Iter    75/  229] train: loss: 0.1549853
[Epoch 76; Iter   105/  229] train: loss: 0.1462406
[Epoch 76; Iter   135/  229] train: loss: 0.1187366
[Epoch 76; Iter   165/  229] train: loss: 0.1791529
[Epoch 76; Iter   195/  229] train: loss: 0.1258413
[Epoch 76; Iter   225/  229] train: loss: 0.1637167
[Epoch 76] ogbg-moltoxcast: 0.740967 val loss: 0.201878
[Epoch 76] ogbg-moltoxcast: 0.761613 test loss: 0.214272
[Epoch 77; Iter    26/  229] train: loss: 0.1380111
[Epoch 77; Iter    56/  229] train: loss: 0.1168388
[Epoch 77; Iter    86/  229] train: loss: 0.2164944
[Epoch 77; Iter   116/  229] train: loss: 0.1557722
[Epoch 77; Iter   146/  229] train: loss: 0.1459319
[Epoch 77; Iter   176/  229] train: loss: 0.1363689
[Epoch 77; Iter   206/  229] train: loss: 0.1145313
[Epoch 77] ogbg-moltoxcast: 0.743777 val loss: 0.203858
[Epoch 77] ogbg-moltoxcast: 0.758214 test loss: 0.210321
[Epoch 78; Iter     7/  229] train: loss: 0.1031116
[Epoch 78; Iter    37/  229] train: loss: 0.1771944
[Epoch 78; Iter    67/  229] train: loss: 0.1307995
[Epoch 78; Iter    97/  229] train: loss: 0.1766743
[Epoch 78; Iter   127/  229] train: loss: 0.1241877
[Epoch 78; Iter   157/  229] train: loss: 0.1368572
[Epoch 78; Iter   187/  229] train: loss: 0.1038766
[Epoch 78; Iter   217/  229] train: loss: 0.1214399
[Epoch 78] ogbg-moltoxcast: 0.746453 val loss: 0.200584
[Epoch 78] ogbg-moltoxcast: 0.760935 test loss: 0.207965
[Epoch 79; Iter    18/  229] train: loss: 0.1880491
[Epoch 79; Iter    48/  229] train: loss: 0.1619635
[Epoch 79; Iter    78/  229] train: loss: 0.1588714
[Epoch 79; Iter   108/  229] train: loss: 0.1113153
[Epoch 79; Iter   138/  229] train: loss: 0.1572832
[Epoch 79; Iter   168/  229] train: loss: 0.0975206
[Epoch 79; Iter   198/  229] train: loss: 0.1486747
[Epoch 79; Iter   228/  229] train: loss: 0.1435938
[Epoch 79] ogbg-moltoxcast: 0.744663 val loss: 0.202666
[Epoch 79] ogbg-moltoxcast: 0.761550 test loss: 0.213300
[Epoch 80; Iter    29/  229] train: loss: 0.1274963
[Epoch 80; Iter    59/  229] train: loss: 0.1295173
[Epoch 80; Iter    89/  229] train: loss: 0.1015567
[Epoch 80; Iter   119/  229] train: loss: 0.1566945
[Epoch 80; Iter   149/  229] train: loss: 0.1506267
[Epoch 80; Iter   179/  229] train: loss: 0.1361952
[Epoch 80; Iter   209/  229] train: loss: 0.1249459
[Epoch 80] ogbg-moltoxcast: 0.745685 val loss: 0.202157
[Epoch 80] ogbg-moltoxcast: 0.763756 test loss: 0.205600
[Epoch 81; Iter    10/  229] train: loss: 0.2257627
[Epoch 81; Iter    40/  229] train: loss: 0.1437329
[Epoch 81; Iter    70/  229] train: loss: 0.1052032
[Epoch 81; Iter   100/  229] train: loss: 0.1176208
[Epoch 81; Iter   130/  229] train: loss: 0.1574492
[Epoch 81; Iter   160/  229] train: loss: 0.1314389
[Epoch 81; Iter   190/  229] train: loss: 0.1353372
[Epoch 81; Iter   220/  229] train: loss: 0.1512527
[Epoch 81] ogbg-moltoxcast: 0.745217 val loss: 0.200306
[Epoch 81] ogbg-moltoxcast: 0.760701 test loss: 0.211612
[Epoch 82; Iter    21/  229] train: loss: 0.1259804
[Epoch 82; Iter    51/  229] train: loss: 0.1265612
[Epoch 82; Iter    81/  229] train: loss: 0.1749092
[Epoch 82; Iter   111/  229] train: loss: 0.1618529
[Epoch 82; Iter   141/  229] train: loss: 0.1354346
[Epoch 82; Iter   171/  229] train: loss: 0.1454061
[Epoch 82; Iter   201/  229] train: loss: 0.1376925
[Epoch 82] ogbg-moltoxcast: 0.740175 val loss: 0.203271
[Epoch 82] ogbg-moltoxcast: 0.759640 test loss: 0.209855
[Epoch 83; Iter     2/  229] train: loss: 0.1868402
[Epoch 83; Iter    32/  229] train: loss: 0.1524439
[Epoch 83; Iter    62/  229] train: loss: 0.1525848
[Epoch 83; Iter    92/  229] train: loss: 0.1802721
[Epoch 83; Iter   122/  229] train: loss: 0.1450284
[Epoch 83; Iter   152/  229] train: loss: 0.1375454
[Epoch 83; Iter   182/  229] train: loss: 0.0980737
[Epoch 83; Iter   212/  229] train: loss: 0.1437898
[Epoch 83] ogbg-moltoxcast: 0.743724 val loss: 0.202440
[Epoch 83] ogbg-moltoxcast: 0.762150 test loss: 0.213595
[Epoch 84; Iter    13/  229] train: loss: 0.1214366
[Epoch 84; Iter    43/  229] train: loss: 0.1463237
[Epoch 84; Iter    73/  229] train: loss: 0.1196650
[Epoch 84; Iter   103/  229] train: loss: 0.1365750
[Epoch 84; Iter   133/  229] train: loss: 0.1603587
[Epoch 84; Iter   163/  229] train: loss: 0.1456955
[Epoch 84; Iter   193/  229] train: loss: 0.1525289
[Epoch 84; Iter   223/  229] train: loss: 0.1212990
[Epoch 84] ogbg-moltoxcast: 0.743903 val loss: 0.204466
[Epoch 84] ogbg-moltoxcast: 0.761036 test loss: 0.209026
[Epoch 85; Iter    24/  229] train: loss: 0.2170400
[Epoch 85; Iter    54/  229] train: loss: 0.1949631
[Epoch 85; Iter    84/  229] train: loss: 0.1591081
[Epoch 85; Iter   114/  229] train: loss: 0.1360380
[Epoch 85; Iter   144/  229] train: loss: 0.1181506
[Epoch 85; Iter   174/  229] train: loss: 0.1390187
[Epoch 85; Iter   204/  229] train: loss: 0.1211079
[Epoch 85] ogbg-moltoxcast: 0.746422 val loss: 0.199649
[Epoch 85] ogbg-moltoxcast: 0.761260 test loss: 0.209194
[Epoch 86; Iter     5/  229] train: loss: 0.1847155
[Epoch 86; Iter    35/  229] train: loss: 0.0893711
[Epoch 86; Iter    65/  229] train: loss: 0.2296669
[Epoch 86; Iter    95/  229] train: loss: 0.1494014
[Epoch 86; Iter   125/  229] train: loss: 0.1564998
[Epoch 86; Iter   155/  229] train: loss: 0.1435501
[Epoch 86; Iter   185/  229] train: loss: 0.1538989
[Epoch 86; Iter   215/  229] train: loss: 0.1326841
[Epoch 86] ogbg-moltoxcast: 0.747360 val loss: 0.201196
[Epoch 86] ogbg-moltoxcast: 0.757598 test loss: 0.210149
[Epoch 87; Iter    16/  229] train: loss: 0.1126679
[Epoch 87; Iter    46/  229] train: loss: 0.1433467
[Epoch 87; Iter    76/  229] train: loss: 0.1398455
[Epoch 87; Iter   106/  229] train: loss: 0.1785963
[Epoch 87; Iter   136/  229] train: loss: 0.1746454
[Epoch 87; Iter   166/  229] train: loss: 0.1798792
[Epoch 87; Iter   196/  229] train: loss: 0.0991829
[Epoch 87; Iter   226/  229] train: loss: 0.1512132
[Epoch 87] ogbg-moltoxcast: 0.747316 val loss: 0.201817
[Epoch 87] ogbg-moltoxcast: 0.759160 test loss: 0.209517
[Epoch 88; Iter    27/  229] train: loss: 0.1349888
[Epoch 88; Iter    57/  229] train: loss: 0.1231841
[Epoch 88; Iter    87/  229] train: loss: 0.1334732
[Epoch 88; Iter   117/  229] train: loss: 0.1413253
[Epoch 88; Iter   147/  229] train: loss: 0.1564567
[Epoch 88; Iter   177/  229] train: loss: 0.1168955
[Epoch 88; Iter   207/  229] train: loss: 0.1264852
[Epoch 88] ogbg-moltoxcast: 0.748431 val loss: 0.202030
[Epoch 88] ogbg-moltoxcast: 0.763399 test loss: 0.212414
[Epoch 89; Iter     8/  229] train: loss: 0.1134265
[Epoch 89; Iter    38/  229] train: loss: 0.1386804
[Epoch 89; Iter    68/  229] train: loss: 0.1561710
[Epoch 89; Iter    98/  229] train: loss: 0.1181883
[Epoch 89; Iter   128/  229] train: loss: 0.1117493
[Epoch 89; Iter   158/  229] train: loss: 0.1456499
[Epoch 89; Iter   188/  229] train: loss: 0.1523394
[Epoch 89; Iter   218/  229] train: loss: 0.1496733
[Epoch 89] ogbg-moltoxcast: 0.747749 val loss: 0.203064
[Epoch 89] ogbg-moltoxcast: 0.760015 test loss: 0.210409
[Epoch 90; Iter    19/  229] train: loss: 0.1772314
[Epoch 90; Iter    49/  229] train: loss: 0.1426883
[Epoch 90; Iter    79/  229] train: loss: 0.1243683
[Epoch 90; Iter   109/  229] train: loss: 0.1662196
[Epoch 90; Iter   139/  229] train: loss: 0.1603245
[Epoch 90; Iter   169/  229] train: loss: 0.1597237
[Epoch 90; Iter   199/  229] train: loss: 0.1915397
[Epoch 90; Iter   229/  229] train: loss: 0.1310319
[Epoch 90] ogbg-moltoxcast: 0.747740 val loss: 0.201357
[Epoch 90] ogbg-moltoxcast: 0.760798 test loss: 0.216004
[Epoch 91; Iter    30/  229] train: loss: 0.1550893
[Epoch 91; Iter    60/  229] train: loss: 0.1582366
[Epoch 91; Iter    90/  229] train: loss: 0.1129187
[Epoch 91; Iter   120/  229] train: loss: 0.1597251
[Epoch 91; Iter   150/  229] train: loss: 0.1453049
[Epoch 91; Iter   180/  229] train: loss: 0.1379327
[Epoch 91; Iter   210/  229] train: loss: 0.1270949
[Epoch 91] ogbg-moltoxcast: 0.750008 val loss: 0.203901
[Epoch 91] ogbg-moltoxcast: 0.759518 test loss: 0.212279
[Epoch 76; Iter    15/  229] train: loss: 0.1638176
[Epoch 76; Iter    45/  229] train: loss: 0.1059866
[Epoch 76; Iter    75/  229] train: loss: 0.1082682
[Epoch 76; Iter   105/  229] train: loss: 0.1161066
[Epoch 76; Iter   135/  229] train: loss: 0.1091591
[Epoch 76; Iter   165/  229] train: loss: 0.1441791
[Epoch 76; Iter   195/  229] train: loss: 0.1215916
[Epoch 76; Iter   225/  229] train: loss: 0.1561164
[Epoch 76] ogbg-moltoxcast: 0.736679 val loss: 0.202254
[Epoch 76] ogbg-moltoxcast: 0.747243 test loss: 0.214440
[Epoch 77; Iter    26/  229] train: loss: 0.1555987
[Epoch 77; Iter    56/  229] train: loss: 0.1974833
[Epoch 77; Iter    86/  229] train: loss: 0.1294265
[Epoch 77; Iter   116/  229] train: loss: 0.1411600
[Epoch 77; Iter   146/  229] train: loss: 0.1498687
[Epoch 77; Iter   176/  229] train: loss: 0.1313045
[Epoch 77; Iter   206/  229] train: loss: 0.1372692
[Epoch 77] ogbg-moltoxcast: 0.742372 val loss: 0.199531
[Epoch 77] ogbg-moltoxcast: 0.749989 test loss: 0.209445
[Epoch 78; Iter     7/  229] train: loss: 0.1387797
[Epoch 78; Iter    37/  229] train: loss: 0.1659148
[Epoch 78; Iter    67/  229] train: loss: 0.1880744
[Epoch 78; Iter    97/  229] train: loss: 0.1534040
[Epoch 78; Iter   127/  229] train: loss: 0.1601433
[Epoch 78; Iter   157/  229] train: loss: 0.2009408
[Epoch 78; Iter   187/  229] train: loss: 0.1550421
[Epoch 78; Iter   217/  229] train: loss: 0.1133034
[Epoch 78] ogbg-moltoxcast: 0.745956 val loss: 0.200520
[Epoch 78] ogbg-moltoxcast: 0.755186 test loss: 0.224948
[Epoch 79; Iter    18/  229] train: loss: 0.1228189
[Epoch 79; Iter    48/  229] train: loss: 0.1009969
[Epoch 79; Iter    78/  229] train: loss: 0.1530237
[Epoch 79; Iter   108/  229] train: loss: 0.1173759
[Epoch 79; Iter   138/  229] train: loss: 0.1774039
[Epoch 79; Iter   168/  229] train: loss: 0.1124950
[Epoch 79; Iter   198/  229] train: loss: 0.1270747
[Epoch 79; Iter   228/  229] train: loss: 0.2272314
[Epoch 79] ogbg-moltoxcast: 0.743960 val loss: 0.200805
[Epoch 79] ogbg-moltoxcast: 0.759796 test loss: 0.210038
[Epoch 80; Iter    29/  229] train: loss: 0.1198758
[Epoch 80; Iter    59/  229] train: loss: 0.1483083
[Epoch 80; Iter    89/  229] train: loss: 0.1127707
[Epoch 80; Iter   119/  229] train: loss: 0.1036216
[Epoch 80; Iter   149/  229] train: loss: 0.1767644
[Epoch 80; Iter   179/  229] train: loss: 0.1621907
[Epoch 80; Iter   209/  229] train: loss: 0.1566600
[Epoch 80] ogbg-moltoxcast: 0.740037 val loss: 0.202832
[Epoch 80] ogbg-moltoxcast: 0.745799 test loss: 0.216341
[Epoch 81; Iter    10/  229] train: loss: 0.1261907
[Epoch 81; Iter    40/  229] train: loss: 0.1297948
[Epoch 81; Iter    70/  229] train: loss: 0.1717696
[Epoch 81; Iter   100/  229] train: loss: 0.0955677
[Epoch 81; Iter   130/  229] train: loss: 0.1463494
[Epoch 81; Iter   160/  229] train: loss: 0.1503796
[Epoch 81; Iter   190/  229] train: loss: 0.1199109
[Epoch 81; Iter   220/  229] train: loss: 0.1123946
[Epoch 81] ogbg-moltoxcast: 0.742041 val loss: 0.201674
[Epoch 81] ogbg-moltoxcast: 0.751838 test loss: 0.212827
[Epoch 82; Iter    21/  229] train: loss: 0.1443393
[Epoch 82; Iter    51/  229] train: loss: 0.1140460
[Epoch 82; Iter    81/  229] train: loss: 0.2118697
[Epoch 82; Iter   111/  229] train: loss: 0.1401140
[Epoch 82; Iter   141/  229] train: loss: 0.1547825
[Epoch 82; Iter   171/  229] train: loss: 0.1454548
[Epoch 82; Iter   201/  229] train: loss: 0.1824736
[Epoch 82] ogbg-moltoxcast: 0.736823 val loss: 0.206099
[Epoch 82] ogbg-moltoxcast: 0.755352 test loss: 0.216419
[Epoch 83; Iter     2/  229] train: loss: 0.1284336
[Epoch 83; Iter    32/  229] train: loss: 0.1417332
[Epoch 83; Iter    62/  229] train: loss: 0.1297388
[Epoch 83; Iter    92/  229] train: loss: 0.1059273
[Epoch 83; Iter   122/  229] train: loss: 0.1012672
[Epoch 83; Iter   152/  229] train: loss: 0.1100542
[Epoch 83; Iter   182/  229] train: loss: 0.1657153
[Epoch 83; Iter   212/  229] train: loss: 0.1176375
[Epoch 83] ogbg-moltoxcast: 0.744002 val loss: 0.201709
[Epoch 83] ogbg-moltoxcast: 0.750732 test loss: 0.216254
[Epoch 84; Iter    13/  229] train: loss: 0.0746575
[Epoch 84; Iter    43/  229] train: loss: 0.1273118
[Epoch 84; Iter    73/  229] train: loss: 0.2080734
[Epoch 84; Iter   103/  229] train: loss: 0.1375577
[Epoch 84; Iter   133/  229] train: loss: 0.1726505
[Epoch 84; Iter   163/  229] train: loss: 0.1252812
[Epoch 84; Iter   193/  229] train: loss: 0.1996639
[Epoch 84; Iter   223/  229] train: loss: 0.1501809
[Epoch 84] ogbg-moltoxcast: 0.746306 val loss: 0.200686
[Epoch 84] ogbg-moltoxcast: 0.749393 test loss: 0.219164
[Epoch 85; Iter    24/  229] train: loss: 0.1455804
[Epoch 85; Iter    54/  229] train: loss: 0.1321948
[Epoch 85; Iter    84/  229] train: loss: 0.1626174
[Epoch 85; Iter   114/  229] train: loss: 0.1445891
[Epoch 85; Iter   144/  229] train: loss: 0.1343148
[Epoch 85; Iter   174/  229] train: loss: 0.1580670
[Epoch 85; Iter   204/  229] train: loss: 0.1667900
[Epoch 85] ogbg-moltoxcast: 0.742400 val loss: 0.203888
[Epoch 85] ogbg-moltoxcast: 0.753910 test loss: 0.214439
[Epoch 86; Iter     5/  229] train: loss: 0.1227390
[Epoch 86; Iter    35/  229] train: loss: 0.1236223
[Epoch 86; Iter    65/  229] train: loss: 0.1856193
[Epoch 86; Iter    95/  229] train: loss: 0.1295493
[Epoch 86; Iter   125/  229] train: loss: 0.0761797
[Epoch 86; Iter   155/  229] train: loss: 0.1222135
[Epoch 86; Iter   185/  229] train: loss: 0.1233315
[Epoch 86; Iter   215/  229] train: loss: 0.1164313
[Epoch 86] ogbg-moltoxcast: 0.743555 val loss: 0.203536
[Epoch 86] ogbg-moltoxcast: 0.752509 test loss: 0.214684
[Epoch 87; Iter    16/  229] train: loss: 0.1141910
[Epoch 87; Iter    46/  229] train: loss: 0.1640345
[Epoch 87; Iter    76/  229] train: loss: 0.1503386
[Epoch 87; Iter   106/  229] train: loss: 0.1665542
[Epoch 87; Iter   136/  229] train: loss: 0.1048425
[Epoch 87; Iter   166/  229] train: loss: 0.1760398
[Epoch 87; Iter   196/  229] train: loss: 0.1755339
[Epoch 87; Iter   226/  229] train: loss: 0.1487973
[Epoch 87] ogbg-moltoxcast: 0.743743 val loss: 0.201062
[Epoch 87] ogbg-moltoxcast: 0.754076 test loss: 0.251396
[Epoch 88; Iter    27/  229] train: loss: 0.1305378
[Epoch 88; Iter    57/  229] train: loss: 0.1371976
[Epoch 88; Iter    87/  229] train: loss: 0.1772294
[Epoch 88; Iter   117/  229] train: loss: 0.1462620
[Epoch 88; Iter   147/  229] train: loss: 0.1184046
[Epoch 88; Iter   177/  229] train: loss: 0.1108407
[Epoch 88; Iter   207/  229] train: loss: 0.1639367
[Epoch 88] ogbg-moltoxcast: 0.743074 val loss: 0.202697
[Epoch 88] ogbg-moltoxcast: 0.753566 test loss: 0.213209
[Epoch 89; Iter     8/  229] train: loss: 0.0794286
[Epoch 89; Iter    38/  229] train: loss: 0.1110266
[Epoch 89; Iter    68/  229] train: loss: 0.0963211
[Epoch 89; Iter    98/  229] train: loss: 0.1172710
[Epoch 89; Iter   128/  229] train: loss: 0.1377036
[Epoch 89; Iter   158/  229] train: loss: 0.1641690
[Epoch 89; Iter   188/  229] train: loss: 0.1320780
[Epoch 89; Iter   218/  229] train: loss: 0.2010270
[Epoch 89] ogbg-moltoxcast: 0.743651 val loss: 0.201704
[Epoch 89] ogbg-moltoxcast: 0.750649 test loss: 0.223418
[Epoch 90; Iter    19/  229] train: loss: 0.1395473
[Epoch 90; Iter    49/  229] train: loss: 0.2215611
[Epoch 90; Iter    79/  229] train: loss: 0.1811813
[Epoch 90; Iter   109/  229] train: loss: 0.0948568
[Epoch 90; Iter   139/  229] train: loss: 0.1097764
[Epoch 90; Iter   169/  229] train: loss: 0.0762848
[Epoch 90; Iter   199/  229] train: loss: 0.1411567
[Epoch 90; Iter   229/  229] train: loss: 0.1166135
[Epoch 90] ogbg-moltoxcast: 0.738669 val loss: 0.205928
[Epoch 90] ogbg-moltoxcast: 0.750438 test loss: 0.215352
[Epoch 91; Iter    30/  229] train: loss: 0.1101407
[Epoch 91; Iter    60/  229] train: loss: 0.1748745
[Epoch 91; Iter    90/  229] train: loss: 0.1847047
[Epoch 91; Iter   120/  229] train: loss: 0.2211663
[Epoch 91; Iter   150/  229] train: loss: 0.0974551
[Epoch 91; Iter   180/  229] train: loss: 0.1285223
[Epoch 91; Iter   210/  229] train: loss: 0.1517707
[Epoch 91] ogbg-moltoxcast: 0.746605 val loss: 0.201951
[Epoch 91] ogbg-moltoxcast: 0.751647 test loss: 0.232944
[Epoch 76; Iter    15/  229] train: loss: 0.1465556
[Epoch 76; Iter    45/  229] train: loss: 0.0994342
[Epoch 76; Iter    75/  229] train: loss: 0.1694826
[Epoch 76; Iter   105/  229] train: loss: 0.1704894
[Epoch 76; Iter   135/  229] train: loss: 0.1302181
[Epoch 76; Iter   165/  229] train: loss: 0.1399732
[Epoch 76; Iter   195/  229] train: loss: 0.1050366
[Epoch 76; Iter   225/  229] train: loss: 0.1181885
[Epoch 76] ogbg-moltoxcast: 0.743160 val loss: 0.199818
[Epoch 76] ogbg-moltoxcast: 0.758954 test loss: 0.210917
[Epoch 77; Iter    26/  229] train: loss: 0.1264245
[Epoch 77; Iter    56/  229] train: loss: 0.1694170
[Epoch 77; Iter    86/  229] train: loss: 0.0784586
[Epoch 77; Iter   116/  229] train: loss: 0.1487892
[Epoch 77; Iter   146/  229] train: loss: 0.1108521
[Epoch 77; Iter   176/  229] train: loss: 0.1243680
[Epoch 77; Iter   206/  229] train: loss: 0.1034006
[Epoch 77] ogbg-moltoxcast: 0.740830 val loss: 0.202391
[Epoch 77] ogbg-moltoxcast: 0.757583 test loss: 0.216320
[Epoch 78; Iter     7/  229] train: loss: 0.1301430
[Epoch 78; Iter    37/  229] train: loss: 0.1130741
[Epoch 78; Iter    67/  229] train: loss: 0.1047737
[Epoch 78; Iter    97/  229] train: loss: 0.1651069
[Epoch 78; Iter   127/  229] train: loss: 0.1892265
[Epoch 78; Iter   157/  229] train: loss: 0.1405395
[Epoch 78; Iter   187/  229] train: loss: 0.1274985
[Epoch 78; Iter   217/  229] train: loss: 0.1915455
[Epoch 78] ogbg-moltoxcast: 0.746871 val loss: 0.197146
[Epoch 78] ogbg-moltoxcast: 0.753459 test loss: 0.216546
[Epoch 79; Iter    18/  229] train: loss: 0.1389132
[Epoch 79; Iter    48/  229] train: loss: 0.1177237
[Epoch 79; Iter    78/  229] train: loss: 0.1164690
[Epoch 79; Iter   108/  229] train: loss: 0.1604696
[Epoch 79; Iter   138/  229] train: loss: 0.2030573
[Epoch 79; Iter   168/  229] train: loss: 0.1380955
[Epoch 79; Iter   198/  229] train: loss: 0.1266411
[Epoch 79; Iter   228/  229] train: loss: 0.1675459
[Epoch 79] ogbg-moltoxcast: 0.744378 val loss: 0.199673
[Epoch 79] ogbg-moltoxcast: 0.755249 test loss: 0.214589
[Epoch 80; Iter    29/  229] train: loss: 0.2049720
[Epoch 80; Iter    59/  229] train: loss: 0.1200407
[Epoch 80; Iter    89/  229] train: loss: 0.1017123
[Epoch 80; Iter   119/  229] train: loss: 0.1177573
[Epoch 80; Iter   149/  229] train: loss: 0.1632944
[Epoch 80; Iter   179/  229] train: loss: 0.1589144
[Epoch 80; Iter   209/  229] train: loss: 0.1270653
[Epoch 80] ogbg-moltoxcast: 0.746060 val loss: 0.198667
[Epoch 80] ogbg-moltoxcast: 0.757748 test loss: 0.214883
[Epoch 81; Iter    10/  229] train: loss: 0.2434041
[Epoch 81; Iter    40/  229] train: loss: 0.0977041
[Epoch 81; Iter    70/  229] train: loss: 0.1339514
[Epoch 81; Iter   100/  229] train: loss: 0.1135067
[Epoch 81; Iter   130/  229] train: loss: 0.0953475
[Epoch 81; Iter   160/  229] train: loss: 0.1414873
[Epoch 81; Iter   190/  229] train: loss: 0.1671167
[Epoch 81; Iter   220/  229] train: loss: 0.1617074
[Epoch 81] ogbg-moltoxcast: 0.742598 val loss: 0.201026
[Epoch 81] ogbg-moltoxcast: 0.750607 test loss: 0.219716
[Epoch 82; Iter    21/  229] train: loss: 0.1565323
[Epoch 82; Iter    51/  229] train: loss: 0.1366064
[Epoch 82; Iter    81/  229] train: loss: 0.1408301
[Epoch 82; Iter   111/  229] train: loss: 0.1529474
[Epoch 82; Iter   141/  229] train: loss: 0.1021228
[Epoch 82; Iter   171/  229] train: loss: 0.1567292
[Epoch 82; Iter   201/  229] train: loss: 0.1360957
[Epoch 82] ogbg-moltoxcast: 0.746821 val loss: 0.197540
[Epoch 82] ogbg-moltoxcast: 0.754564 test loss: 0.215740
[Epoch 83; Iter     2/  229] train: loss: 0.1394304
[Epoch 83; Iter    32/  229] train: loss: 0.1001719
[Epoch 83; Iter    62/  229] train: loss: 0.1371313
[Epoch 83; Iter    92/  229] train: loss: 0.0902936
[Epoch 83; Iter   122/  229] train: loss: 0.0999787
[Epoch 83; Iter   152/  229] train: loss: 0.1017634
[Epoch 83; Iter   182/  229] train: loss: 0.1520551
[Epoch 83; Iter   212/  229] train: loss: 0.1848299
[Epoch 83] ogbg-moltoxcast: 0.744550 val loss: 0.201626
[Epoch 83] ogbg-moltoxcast: 0.753430 test loss: 0.218856
[Epoch 84; Iter    13/  229] train: loss: 0.0903924
[Epoch 84; Iter    43/  229] train: loss: 0.1808344
[Epoch 84; Iter    73/  229] train: loss: 0.1583374
[Epoch 84; Iter   103/  229] train: loss: 0.1397812
[Epoch 84; Iter   133/  229] train: loss: 0.1378863
[Epoch 84; Iter   163/  229] train: loss: 0.1714507
[Epoch 84; Iter   193/  229] train: loss: 0.1667867
[Epoch 84; Iter   223/  229] train: loss: 0.1302333
[Epoch 84] ogbg-moltoxcast: 0.744999 val loss: 0.199311
[Epoch 84] ogbg-moltoxcast: 0.757649 test loss: 0.210543
[Epoch 85; Iter    24/  229] train: loss: 0.1849108
[Epoch 85; Iter    54/  229] train: loss: 0.1410605
[Epoch 85; Iter    84/  229] train: loss: 0.1116423
[Epoch 85; Iter   114/  229] train: loss: 0.1283187
[Epoch 85; Iter   144/  229] train: loss: 0.1727200
[Epoch 85; Iter   174/  229] train: loss: 0.1653556
[Epoch 85; Iter   204/  229] train: loss: 0.1747114
[Epoch 85] ogbg-moltoxcast: 0.745953 val loss: 0.199256
[Epoch 85] ogbg-moltoxcast: 0.748731 test loss: 0.218317
[Epoch 86; Iter     5/  229] train: loss: 0.1131617
[Epoch 86; Iter    35/  229] train: loss: 0.1033904
[Epoch 86; Iter    65/  229] train: loss: 0.1625196
[Epoch 86; Iter    95/  229] train: loss: 0.1705216
[Epoch 86; Iter   125/  229] train: loss: 0.0753645
[Epoch 86; Iter   155/  229] train: loss: 0.1427721
[Epoch 86; Iter   185/  229] train: loss: 0.1019444
[Epoch 86; Iter   215/  229] train: loss: 0.1519682
[Epoch 86] ogbg-moltoxcast: 0.747902 val loss: 0.198093
[Epoch 86] ogbg-moltoxcast: 0.753989 test loss: 0.217866
[Epoch 87; Iter    16/  229] train: loss: 0.1203573
[Epoch 87; Iter    46/  229] train: loss: 0.1418198
[Epoch 87; Iter    76/  229] train: loss: 0.1617519
[Epoch 87; Iter   106/  229] train: loss: 0.1839470
[Epoch 87; Iter   136/  229] train: loss: 0.1090485
[Epoch 87; Iter   166/  229] train: loss: 0.1244113
[Epoch 87; Iter   196/  229] train: loss: 0.0884899
[Epoch 87; Iter   226/  229] train: loss: 0.1610928
[Epoch 87] ogbg-moltoxcast: 0.742433 val loss: 0.201049
[Epoch 87] ogbg-moltoxcast: 0.755084 test loss: 0.217030
[Epoch 88; Iter    27/  229] train: loss: 0.0965417
[Epoch 88; Iter    57/  229] train: loss: 0.1544075
[Epoch 88; Iter    87/  229] train: loss: 0.1848369
[Epoch 88; Iter   117/  229] train: loss: 0.1719638
[Epoch 88; Iter   147/  229] train: loss: 0.1370937
[Epoch 88; Iter   177/  229] train: loss: 0.1285109
[Epoch 88; Iter   207/  229] train: loss: 0.1225832
[Epoch 88] ogbg-moltoxcast: 0.745047 val loss: 0.199670
[Epoch 88] ogbg-moltoxcast: 0.757208 test loss: 0.214073
[Epoch 89; Iter     8/  229] train: loss: 0.1522023
[Epoch 89; Iter    38/  229] train: loss: 0.1673387
[Epoch 89; Iter    68/  229] train: loss: 0.1718121
[Epoch 89; Iter    98/  229] train: loss: 0.1249698
[Epoch 89; Iter   128/  229] train: loss: 0.1626567
[Epoch 89; Iter   158/  229] train: loss: 0.0895164
[Epoch 89; Iter   188/  229] train: loss: 0.1731266
[Epoch 89; Iter   218/  229] train: loss: 0.1481151
[Epoch 89] ogbg-moltoxcast: 0.747555 val loss: 0.199366
[Epoch 89] ogbg-moltoxcast: 0.757397 test loss: 0.217918
[Epoch 90; Iter    19/  229] train: loss: 0.1267611
[Epoch 90; Iter    49/  229] train: loss: 0.1717125
[Epoch 90; Iter    79/  229] train: loss: 0.1075248
[Epoch 90; Iter   109/  229] train: loss: 0.1574188
[Epoch 90; Iter   139/  229] train: loss: 0.1716212
[Epoch 90; Iter   169/  229] train: loss: 0.1014462
[Epoch 90; Iter   199/  229] train: loss: 0.1046953
[Epoch 90; Iter   229/  229] train: loss: 0.1508650
[Epoch 90] ogbg-moltoxcast: 0.744163 val loss: 0.198743
[Epoch 90] ogbg-moltoxcast: 0.758146 test loss: 0.216288
[Epoch 91; Iter    30/  229] train: loss: 0.1451239
[Epoch 91; Iter    60/  229] train: loss: 0.1117784
[Epoch 91; Iter    90/  229] train: loss: 0.1401865
[Epoch 91; Iter   120/  229] train: loss: 0.1429243
[Epoch 91; Iter   150/  229] train: loss: 0.1716232
[Epoch 91; Iter   180/  229] train: loss: 0.1341713
[Epoch 91; Iter   210/  229] train: loss: 0.1182896
[Epoch 91] ogbg-moltoxcast: 0.739338 val loss: 0.203774
[Epoch 91] ogbg-moltoxcast: 0.760629 test loss: 0.217846
[Epoch 84; Iter    27/  201] train: loss: 0.1145164
[Epoch 84; Iter    57/  201] train: loss: 0.1425009
[Epoch 84; Iter    87/  201] train: loss: 0.1323113
[Epoch 84; Iter   117/  201] train: loss: 0.1033782
[Epoch 84; Iter   147/  201] train: loss: 0.1295519
[Epoch 84; Iter   177/  201] train: loss: 0.1332561
[Epoch 84] ogbg-moltoxcast: 0.733887 val loss: 0.213234
[Epoch 84] ogbg-moltoxcast: 0.744516 test loss: 0.218766
[Epoch 85; Iter     6/  201] train: loss: 0.1466011
[Epoch 85; Iter    36/  201] train: loss: 0.1156305
[Epoch 85; Iter    66/  201] train: loss: 0.1756609
[Epoch 85; Iter    96/  201] train: loss: 0.1420715
[Epoch 85; Iter   126/  201] train: loss: 0.1725855
[Epoch 85; Iter   156/  201] train: loss: 0.1082236
[Epoch 85; Iter   186/  201] train: loss: 0.1716908
[Epoch 85] ogbg-moltoxcast: 0.737884 val loss: 0.211134
[Epoch 85] ogbg-moltoxcast: 0.745803 test loss: 0.216027
[Epoch 86; Iter    15/  201] train: loss: 0.1482707
[Epoch 86; Iter    45/  201] train: loss: 0.1399338
[Epoch 86; Iter    75/  201] train: loss: 0.1153402
[Epoch 86; Iter   105/  201] train: loss: 0.1098604
[Epoch 86; Iter   135/  201] train: loss: 0.1329180
[Epoch 86; Iter   165/  201] train: loss: 0.1278364
[Epoch 86; Iter   195/  201] train: loss: 0.1246310
[Epoch 86] ogbg-moltoxcast: 0.740793 val loss: 0.212163
[Epoch 86] ogbg-moltoxcast: 0.748160 test loss: 0.217581
[Epoch 87; Iter    24/  201] train: loss: 0.1351887
[Epoch 87; Iter    54/  201] train: loss: 0.1382886
[Epoch 87; Iter    84/  201] train: loss: 0.1345288
[Epoch 87; Iter   114/  201] train: loss: 0.1020331
[Epoch 87; Iter   144/  201] train: loss: 0.1235769
[Epoch 87; Iter   174/  201] train: loss: 0.1163175
[Epoch 87] ogbg-moltoxcast: 0.740159 val loss: 0.214310
[Epoch 87] ogbg-moltoxcast: 0.746790 test loss: 0.222929
[Epoch 88; Iter     3/  201] train: loss: 0.1433474
[Epoch 88; Iter    33/  201] train: loss: 0.1008855
[Epoch 88; Iter    63/  201] train: loss: 0.1307675
[Epoch 88; Iter    93/  201] train: loss: 0.1865716
[Epoch 88; Iter   123/  201] train: loss: 0.1619543
[Epoch 88; Iter   153/  201] train: loss: 0.1746594
[Epoch 88; Iter   183/  201] train: loss: 0.1121178
[Epoch 88] ogbg-moltoxcast: 0.738271 val loss: 0.214584
[Epoch 88] ogbg-moltoxcast: 0.744434 test loss: 0.218496
[Epoch 89; Iter    12/  201] train: loss: 0.0903000
[Epoch 89; Iter    42/  201] train: loss: 0.1573176
[Epoch 89; Iter    72/  201] train: loss: 0.1427442
[Epoch 89; Iter   102/  201] train: loss: 0.1393563
[Epoch 89; Iter   132/  201] train: loss: 0.0871304
[Epoch 89; Iter   162/  201] train: loss: 0.1497653
[Epoch 89; Iter   192/  201] train: loss: 0.1597185
[Epoch 89] ogbg-moltoxcast: 0.738058 val loss: 0.214222
[Epoch 89] ogbg-moltoxcast: 0.749038 test loss: 0.218095
[Epoch 90; Iter    21/  201] train: loss: 0.1381043
[Epoch 90; Iter    51/  201] train: loss: 0.1345084
[Epoch 90; Iter    81/  201] train: loss: 0.0976972
[Epoch 90; Iter   111/  201] train: loss: 0.1442111
[Epoch 90; Iter   141/  201] train: loss: 0.1071277
[Epoch 90; Iter   171/  201] train: loss: 0.1024966
[Epoch 90; Iter   201/  201] train: loss: 0.1292840
[Epoch 90] ogbg-moltoxcast: 0.737217 val loss: 0.213550
[Epoch 90] ogbg-moltoxcast: 0.748068 test loss: 0.216670
[Epoch 91; Iter    30/  201] train: loss: 0.1137996
[Epoch 91; Iter    60/  201] train: loss: 0.1442611
[Epoch 91; Iter    90/  201] train: loss: 0.1184930
[Epoch 91; Iter   120/  201] train: loss: 0.1132730
[Epoch 91; Iter   150/  201] train: loss: 0.1227411
[Epoch 91; Iter   180/  201] train: loss: 0.1253185
[Epoch 91] ogbg-moltoxcast: 0.732770 val loss: 0.215589
[Epoch 91] ogbg-moltoxcast: 0.747298 test loss: 0.217404
[Epoch 92; Iter     9/  201] train: loss: 0.1788503
[Epoch 92; Iter    39/  201] train: loss: 0.1440304
[Epoch 92; Iter    69/  201] train: loss: 0.1517375
[Epoch 92; Iter    99/  201] train: loss: 0.0904795
[Epoch 92; Iter   129/  201] train: loss: 0.1191651
[Epoch 92; Iter   159/  201] train: loss: 0.1342040
[Epoch 92; Iter   189/  201] train: loss: 0.2093097
[Epoch 92] ogbg-moltoxcast: 0.728256 val loss: 0.217030
[Epoch 92] ogbg-moltoxcast: 0.742929 test loss: 0.218497
[Epoch 93; Iter    18/  201] train: loss: 0.1745860
[Epoch 93; Iter    48/  201] train: loss: 0.0877782
[Epoch 93; Iter    78/  201] train: loss: 0.1296355
[Epoch 93; Iter   108/  201] train: loss: 0.1276560
[Epoch 93; Iter   138/  201] train: loss: 0.0992096
[Epoch 93; Iter   168/  201] train: loss: 0.1186492
[Epoch 93; Iter   198/  201] train: loss: 0.1636740
[Epoch 93] ogbg-moltoxcast: 0.735977 val loss: 0.216110
[Epoch 93] ogbg-moltoxcast: 0.748639 test loss: 0.219656
[Epoch 94; Iter    27/  201] train: loss: 0.1080166
[Epoch 94; Iter    57/  201] train: loss: 0.0953015
[Epoch 94; Iter    87/  201] train: loss: 0.1748563
[Epoch 94; Iter   117/  201] train: loss: 0.1053979
[Epoch 94; Iter   147/  201] train: loss: 0.1554293
[Epoch 94; Iter   177/  201] train: loss: 0.1258427
[Epoch 94] ogbg-moltoxcast: 0.733451 val loss: 0.214933
[Epoch 94] ogbg-moltoxcast: 0.746155 test loss: 0.216641
[Epoch 95; Iter     6/  201] train: loss: 0.1221920
[Epoch 95; Iter    36/  201] train: loss: 0.1779720
[Epoch 95; Iter    66/  201] train: loss: 0.1556747
[Epoch 95; Iter    96/  201] train: loss: 0.1139850
[Epoch 95; Iter   126/  201] train: loss: 0.1125005
[Epoch 95; Iter   156/  201] train: loss: 0.1247241
[Epoch 95; Iter   186/  201] train: loss: 0.0910360
[Epoch 95] ogbg-moltoxcast: 0.736897 val loss: 0.214670
[Epoch 95] ogbg-moltoxcast: 0.750220 test loss: 0.217638
[Epoch 96; Iter    15/  201] train: loss: 0.1461714
[Epoch 96; Iter    45/  201] train: loss: 0.1142195
[Epoch 96; Iter    75/  201] train: loss: 0.0967585
[Epoch 96; Iter   105/  201] train: loss: 0.1548139
[Epoch 96; Iter   135/  201] train: loss: 0.1047965
[Epoch 96; Iter   165/  201] train: loss: 0.1182703
[Epoch 96; Iter   195/  201] train: loss: 0.1696867
[Epoch 96] ogbg-moltoxcast: 0.737334 val loss: 0.215302
[Epoch 96] ogbg-moltoxcast: 0.746240 test loss: 0.219890
[Epoch 97; Iter    24/  201] train: loss: 0.1164162
[Epoch 97; Iter    54/  201] train: loss: 0.0999421
[Epoch 97; Iter    84/  201] train: loss: 0.1628986
[Epoch 97; Iter   114/  201] train: loss: 0.1687635
[Epoch 97; Iter   144/  201] train: loss: 0.1241896
[Epoch 97; Iter   174/  201] train: loss: 0.2076820
[Epoch 97] ogbg-moltoxcast: 0.739338 val loss: 0.213493
[Epoch 97] ogbg-moltoxcast: 0.746792 test loss: 0.218671
[Epoch 98; Iter     3/  201] train: loss: 0.1218688
[Epoch 98; Iter    33/  201] train: loss: 0.1738434
[Epoch 98; Iter    63/  201] train: loss: 0.1409037
[Epoch 98; Iter    93/  201] train: loss: 0.1082975
[Epoch 98; Iter   123/  201] train: loss: 0.1322696
[Epoch 98; Iter   153/  201] train: loss: 0.1173489
[Epoch 98; Iter   183/  201] train: loss: 0.1705240
[Epoch 98] ogbg-moltoxcast: 0.734966 val loss: 0.216310
[Epoch 98] ogbg-moltoxcast: 0.746061 test loss: 0.221480
[Epoch 99; Iter    12/  201] train: loss: 0.1892576
[Epoch 99; Iter    42/  201] train: loss: 0.1236357
[Epoch 99; Iter    72/  201] train: loss: 0.1253347
[Epoch 99; Iter   102/  201] train: loss: 0.1366111
[Epoch 99; Iter   132/  201] train: loss: 0.1518152
[Epoch 99; Iter   162/  201] train: loss: 0.1503587
[Epoch 99; Iter   192/  201] train: loss: 0.1109552
[Epoch 99] ogbg-moltoxcast: 0.735301 val loss: 0.216164
[Epoch 99] ogbg-moltoxcast: 0.743921 test loss: 0.221994
[Epoch 100; Iter    21/  201] train: loss: 0.1363069
[Epoch 100; Iter    51/  201] train: loss: 0.1272601
[Epoch 100; Iter    81/  201] train: loss: 0.1863883
[Epoch 100; Iter   111/  201] train: loss: 0.1309529
[Epoch 100; Iter   141/  201] train: loss: 0.0849278
[Epoch 100; Iter   171/  201] train: loss: 0.1915757
[Epoch 100; Iter   201/  201] train: loss: 0.6039636
[Epoch 100] ogbg-moltoxcast: 0.736276 val loss: 0.217360
[Epoch 100] ogbg-moltoxcast: 0.747065 test loss: 0.222721
[Epoch 101; Iter    30/  201] train: loss: 0.1473716
[Epoch 101; Iter    60/  201] train: loss: 0.1379030
[Epoch 101; Iter    90/  201] train: loss: 0.1083685
[Epoch 101; Iter   120/  201] train: loss: 0.1015831
[Epoch 101; Iter   150/  201] train: loss: 0.1065313
[Epoch 101; Iter   180/  201] train: loss: 0.1606828
[Epoch 84; Iter    27/  201] train: loss: 0.1095476
[Epoch 84; Iter    57/  201] train: loss: 0.1673021
[Epoch 84; Iter    87/  201] train: loss: 0.1236474
[Epoch 84; Iter   117/  201] train: loss: 0.1650089
[Epoch 84; Iter   147/  201] train: loss: 0.1928560
[Epoch 84; Iter   177/  201] train: loss: 0.1500148
[Epoch 84] ogbg-moltoxcast: 0.730237 val loss: 0.212833
[Epoch 84] ogbg-moltoxcast: 0.748933 test loss: 0.207242
[Epoch 85; Iter     6/  201] train: loss: 0.1437061
[Epoch 85; Iter    36/  201] train: loss: 0.1650547
[Epoch 85; Iter    66/  201] train: loss: 0.1428846
[Epoch 85; Iter    96/  201] train: loss: 0.1345178
[Epoch 85; Iter   126/  201] train: loss: 0.1173351
[Epoch 85; Iter   156/  201] train: loss: 0.1322775
[Epoch 85; Iter   186/  201] train: loss: 0.1304223
[Epoch 85] ogbg-moltoxcast: 0.733002 val loss: 0.215048
[Epoch 85] ogbg-moltoxcast: 0.753076 test loss: 0.206315
[Epoch 86; Iter    15/  201] train: loss: 0.1260424
[Epoch 86; Iter    45/  201] train: loss: 0.1321448
[Epoch 86; Iter    75/  201] train: loss: 0.1486610
[Epoch 86; Iter   105/  201] train: loss: 0.1823101
[Epoch 86; Iter   135/  201] train: loss: 0.0980833
[Epoch 86; Iter   165/  201] train: loss: 0.1084105
[Epoch 86; Iter   195/  201] train: loss: 0.2500621
[Epoch 86] ogbg-moltoxcast: 0.733314 val loss: 0.213959
[Epoch 86] ogbg-moltoxcast: 0.750121 test loss: 0.207732
[Epoch 87; Iter    24/  201] train: loss: 0.1611261
[Epoch 87; Iter    54/  201] train: loss: 0.1242447
[Epoch 87; Iter    84/  201] train: loss: 0.1772195
[Epoch 87; Iter   114/  201] train: loss: 0.1468475
[Epoch 87; Iter   144/  201] train: loss: 0.1635815
[Epoch 87; Iter   174/  201] train: loss: 0.1525094
[Epoch 87] ogbg-moltoxcast: 0.732621 val loss: 0.214922
[Epoch 87] ogbg-moltoxcast: 0.755082 test loss: 0.205251
[Epoch 88; Iter     3/  201] train: loss: 0.0978600
[Epoch 88; Iter    33/  201] train: loss: 0.1154382
[Epoch 88; Iter    63/  201] train: loss: 0.1865793
[Epoch 88; Iter    93/  201] train: loss: 0.1609272
[Epoch 88; Iter   123/  201] train: loss: 0.1124163
[Epoch 88; Iter   153/  201] train: loss: 0.1008485
[Epoch 88; Iter   183/  201] train: loss: 0.1738850
[Epoch 88] ogbg-moltoxcast: 0.733845 val loss: 0.213627
[Epoch 88] ogbg-moltoxcast: 0.750638 test loss: 0.207504
[Epoch 89; Iter    12/  201] train: loss: 0.1480028
[Epoch 89; Iter    42/  201] train: loss: 0.1324941
[Epoch 89; Iter    72/  201] train: loss: 0.2063457
[Epoch 89; Iter   102/  201] train: loss: 0.1420994
[Epoch 89; Iter   132/  201] train: loss: 0.1184296
[Epoch 89; Iter   162/  201] train: loss: 0.1890299
[Epoch 89; Iter   192/  201] train: loss: 0.1396584
[Epoch 89] ogbg-moltoxcast: 0.728380 val loss: 0.214902
[Epoch 89] ogbg-moltoxcast: 0.751629 test loss: 0.206772
[Epoch 90; Iter    21/  201] train: loss: 0.0997418
[Epoch 90; Iter    51/  201] train: loss: 0.1963149
[Epoch 90; Iter    81/  201] train: loss: 0.1388676
[Epoch 90; Iter   111/  201] train: loss: 0.1315157
[Epoch 90; Iter   141/  201] train: loss: 0.1241418
[Epoch 90; Iter   171/  201] train: loss: 0.1169965
[Epoch 90; Iter   201/  201] train: loss: 0.1268331
[Epoch 90] ogbg-moltoxcast: 0.732213 val loss: 0.212885
[Epoch 90] ogbg-moltoxcast: 0.752881 test loss: 0.204655
[Epoch 91; Iter    30/  201] train: loss: 0.1207960
[Epoch 91; Iter    60/  201] train: loss: 0.1106296
[Epoch 91; Iter    90/  201] train: loss: 0.0996200
[Epoch 91; Iter   120/  201] train: loss: 0.1547068
[Epoch 91; Iter   150/  201] train: loss: 0.1479836
[Epoch 91; Iter   180/  201] train: loss: 0.0942991
[Epoch 91] ogbg-moltoxcast: 0.732249 val loss: 0.218116
[Epoch 91] ogbg-moltoxcast: 0.748183 test loss: 0.213889
[Epoch 92; Iter     9/  201] train: loss: 0.1151751
[Epoch 92; Iter    39/  201] train: loss: 0.1341839
[Epoch 92; Iter    69/  201] train: loss: 0.1380067
[Epoch 92; Iter    99/  201] train: loss: 0.1059091
[Epoch 92; Iter   129/  201] train: loss: 0.1138645
[Epoch 92; Iter   159/  201] train: loss: 0.1086970
[Epoch 92; Iter   189/  201] train: loss: 0.1355776
[Epoch 92] ogbg-moltoxcast: 0.731106 val loss: 0.213220
[Epoch 92] ogbg-moltoxcast: 0.751170 test loss: 0.206296
[Epoch 93; Iter    18/  201] train: loss: 0.1045139
[Epoch 93; Iter    48/  201] train: loss: 0.1674044
[Epoch 93; Iter    78/  201] train: loss: 0.0940012
[Epoch 93; Iter   108/  201] train: loss: 0.1157471
[Epoch 93; Iter   138/  201] train: loss: 0.1509214
[Epoch 93; Iter   168/  201] train: loss: 0.2045641
[Epoch 93; Iter   198/  201] train: loss: 0.1424094
[Epoch 93] ogbg-moltoxcast: 0.733787 val loss: 0.214102
[Epoch 93] ogbg-moltoxcast: 0.751628 test loss: 0.206837
[Epoch 94; Iter    27/  201] train: loss: 0.1167917
[Epoch 94; Iter    57/  201] train: loss: 0.1314087
[Epoch 94; Iter    87/  201] train: loss: 0.2095258
[Epoch 94; Iter   117/  201] train: loss: 0.1271841
[Epoch 94; Iter   147/  201] train: loss: 0.1477336
[Epoch 94; Iter   177/  201] train: loss: 0.1323251
[Epoch 94] ogbg-moltoxcast: 0.733502 val loss: 0.211150
[Epoch 94] ogbg-moltoxcast: 0.753601 test loss: 0.205002
[Epoch 95; Iter     6/  201] train: loss: 0.1344274
[Epoch 95; Iter    36/  201] train: loss: 0.0917681
[Epoch 95; Iter    66/  201] train: loss: 0.1006086
[Epoch 95; Iter    96/  201] train: loss: 0.1176620
[Epoch 95; Iter   126/  201] train: loss: 0.1464639
[Epoch 95; Iter   156/  201] train: loss: 0.1547136
[Epoch 95; Iter   186/  201] train: loss: 0.1811645
[Epoch 95] ogbg-moltoxcast: 0.733496 val loss: 0.211442
[Epoch 95] ogbg-moltoxcast: 0.752875 test loss: 0.205649
[Epoch 96; Iter    15/  201] train: loss: 0.1456989
[Epoch 96; Iter    45/  201] train: loss: 0.1153999
[Epoch 96; Iter    75/  201] train: loss: 0.1276538
[Epoch 96; Iter   105/  201] train: loss: 0.1036333
[Epoch 96; Iter   135/  201] train: loss: 0.1620407
[Epoch 96; Iter   165/  201] train: loss: 0.1366722
[Epoch 96; Iter   195/  201] train: loss: 0.1287223
[Epoch 96] ogbg-moltoxcast: 0.730933 val loss: 0.217755
[Epoch 96] ogbg-moltoxcast: 0.747322 test loss: 0.212568
[Epoch 97; Iter    24/  201] train: loss: 0.0910948
[Epoch 97; Iter    54/  201] train: loss: 0.1068862
[Epoch 97; Iter    84/  201] train: loss: 0.1463398
[Epoch 97; Iter   114/  201] train: loss: 0.1353974
[Epoch 97; Iter   144/  201] train: loss: 0.1325719
[Epoch 97; Iter   174/  201] train: loss: 0.2208418
[Epoch 97] ogbg-moltoxcast: 0.732819 val loss: 0.217881
[Epoch 97] ogbg-moltoxcast: 0.752193 test loss: 0.212632
[Epoch 98; Iter     3/  201] train: loss: 0.1655225
[Epoch 98; Iter    33/  201] train: loss: 0.1642719
[Epoch 98; Iter    63/  201] train: loss: 0.1328053
[Epoch 98; Iter    93/  201] train: loss: 0.1454313
[Epoch 98; Iter   123/  201] train: loss: 0.1332332
[Epoch 98; Iter   153/  201] train: loss: 0.1748594
[Epoch 98; Iter   183/  201] train: loss: 0.1255685
[Epoch 98] ogbg-moltoxcast: 0.732294 val loss: 0.212743
[Epoch 98] ogbg-moltoxcast: 0.751155 test loss: 0.206717
[Epoch 99; Iter    12/  201] train: loss: 0.1355560
[Epoch 99; Iter    42/  201] train: loss: 0.1236430
[Epoch 99; Iter    72/  201] train: loss: 0.1098219
[Epoch 99; Iter   102/  201] train: loss: 0.1493036
[Epoch 99; Iter   132/  201] train: loss: 0.0922136
[Epoch 99; Iter   162/  201] train: loss: 0.1704405
[Epoch 99; Iter   192/  201] train: loss: 0.1641096
[Epoch 99] ogbg-moltoxcast: 0.730456 val loss: 0.214934
[Epoch 99] ogbg-moltoxcast: 0.749936 test loss: 0.209902
[Epoch 100; Iter    21/  201] train: loss: 0.1547506
[Epoch 100; Iter    51/  201] train: loss: 0.1403903
[Epoch 100; Iter    81/  201] train: loss: 0.1203318
[Epoch 100; Iter   111/  201] train: loss: 0.1505002
[Epoch 100; Iter   141/  201] train: loss: 0.1498839
[Epoch 100; Iter   171/  201] train: loss: 0.1761946
[Epoch 100; Iter   201/  201] train: loss: 0.5567661
[Epoch 100] ogbg-moltoxcast: 0.730455 val loss: 0.218532
[Epoch 100] ogbg-moltoxcast: 0.748569 test loss: 0.213954
[Epoch 101; Iter    30/  201] train: loss: 0.1670854
[Epoch 101; Iter    60/  201] train: loss: 0.1587713
[Epoch 101; Iter    90/  201] train: loss: 0.1350185
[Epoch 101; Iter   120/  201] train: loss: 0.1504660
[Epoch 101; Iter   150/  201] train: loss: 0.1440228
[Epoch 101; Iter   180/  201] train: loss: 0.1453160
[Epoch 84; Iter    27/  201] train: loss: 0.1626988
[Epoch 84; Iter    57/  201] train: loss: 0.1452995
[Epoch 84; Iter    87/  201] train: loss: 0.1368951
[Epoch 84; Iter   117/  201] train: loss: 0.1067411
[Epoch 84; Iter   147/  201] train: loss: 0.1429881
[Epoch 84; Iter   177/  201] train: loss: 0.1441831
[Epoch 84] ogbg-moltoxcast: 0.735060 val loss: 0.217269
[Epoch 84] ogbg-moltoxcast: 0.743391 test loss: 0.219956
[Epoch 85; Iter     6/  201] train: loss: 0.0904830
[Epoch 85; Iter    36/  201] train: loss: 0.1047536
[Epoch 85; Iter    66/  201] train: loss: 0.1419481
[Epoch 85; Iter    96/  201] train: loss: 0.1404662
[Epoch 85; Iter   126/  201] train: loss: 0.1377068
[Epoch 85; Iter   156/  201] train: loss: 0.1358009
[Epoch 85; Iter   186/  201] train: loss: 0.1311578
[Epoch 85] ogbg-moltoxcast: 0.733435 val loss: 0.214734
[Epoch 85] ogbg-moltoxcast: 0.742420 test loss: 0.212172
[Epoch 86; Iter    15/  201] train: loss: 0.1409226
[Epoch 86; Iter    45/  201] train: loss: 0.1143970
[Epoch 86; Iter    75/  201] train: loss: 0.1226416
[Epoch 86; Iter   105/  201] train: loss: 0.1240536
[Epoch 86; Iter   135/  201] train: loss: 0.1302252
[Epoch 86; Iter   165/  201] train: loss: 0.1306741
[Epoch 86; Iter   195/  201] train: loss: 0.0872988
[Epoch 86] ogbg-moltoxcast: 0.732164 val loss: 0.215940
[Epoch 86] ogbg-moltoxcast: 0.744762 test loss: 0.213137
[Epoch 87; Iter    24/  201] train: loss: 0.1917897
[Epoch 87; Iter    54/  201] train: loss: 0.1330898
[Epoch 87; Iter    84/  201] train: loss: 0.1373356
[Epoch 87; Iter   114/  201] train: loss: 0.1351535
[Epoch 87; Iter   144/  201] train: loss: 0.1550349
[Epoch 87; Iter   174/  201] train: loss: 0.1723272
[Epoch 87] ogbg-moltoxcast: 0.736114 val loss: 0.222509
[Epoch 87] ogbg-moltoxcast: 0.744044 test loss: 0.221119
[Epoch 88; Iter     3/  201] train: loss: 0.1274019
[Epoch 88; Iter    33/  201] train: loss: 0.1236992
[Epoch 88; Iter    63/  201] train: loss: 0.1189092
[Epoch 88; Iter    93/  201] train: loss: 0.1423189
[Epoch 88; Iter   123/  201] train: loss: 0.1766697
[Epoch 88; Iter   153/  201] train: loss: 0.1066860
[Epoch 88; Iter   183/  201] train: loss: 0.1538519
[Epoch 88] ogbg-moltoxcast: 0.733434 val loss: 0.214441
[Epoch 88] ogbg-moltoxcast: 0.746199 test loss: 0.213137
[Epoch 89; Iter    12/  201] train: loss: 0.1074518
[Epoch 89; Iter    42/  201] train: loss: 0.1569931
[Epoch 89; Iter    72/  201] train: loss: 0.1201274
[Epoch 89; Iter   102/  201] train: loss: 0.0979672
[Epoch 89; Iter   132/  201] train: loss: 0.1224328
[Epoch 89; Iter   162/  201] train: loss: 0.1726016
[Epoch 89; Iter   192/  201] train: loss: 0.1157639
[Epoch 89] ogbg-moltoxcast: 0.730184 val loss: 0.217805
[Epoch 89] ogbg-moltoxcast: 0.743535 test loss: 0.214299
[Epoch 90; Iter    21/  201] train: loss: 0.1851998
[Epoch 90; Iter    51/  201] train: loss: 0.1077848
[Epoch 90; Iter    81/  201] train: loss: 0.1172278
[Epoch 90; Iter   111/  201] train: loss: 0.0856917
[Epoch 90; Iter   141/  201] train: loss: 0.1525402
[Epoch 90; Iter   171/  201] train: loss: 0.0953400
[Epoch 90; Iter   201/  201] train: loss: 0.5639670
[Epoch 90] ogbg-moltoxcast: 0.733784 val loss: 0.218443
[Epoch 90] ogbg-moltoxcast: 0.744027 test loss: 0.219413
[Epoch 91; Iter    30/  201] train: loss: 0.1558593
[Epoch 91; Iter    60/  201] train: loss: 0.0860711
[Epoch 91; Iter    90/  201] train: loss: 0.1456877
[Epoch 91; Iter   120/  201] train: loss: 0.0716588
[Epoch 91; Iter   150/  201] train: loss: 0.1647152
[Epoch 91; Iter   180/  201] train: loss: 0.1736302
[Epoch 91] ogbg-moltoxcast: 0.736785 val loss: 0.218193
[Epoch 91] ogbg-moltoxcast: 0.745681 test loss: 0.214898
[Epoch 92; Iter     9/  201] train: loss: 0.1339795
[Epoch 92; Iter    39/  201] train: loss: 0.1897821
[Epoch 92; Iter    69/  201] train: loss: 0.1719521
[Epoch 92; Iter    99/  201] train: loss: 0.1157098
[Epoch 92; Iter   129/  201] train: loss: 0.1438912
[Epoch 92; Iter   159/  201] train: loss: 0.1703893
[Epoch 92; Iter   189/  201] train: loss: 0.1758562
[Epoch 92] ogbg-moltoxcast: 0.737888 val loss: 0.214839
[Epoch 92] ogbg-moltoxcast: 0.743915 test loss: 0.214171
[Epoch 93; Iter    18/  201] train: loss: 0.1573842
[Epoch 93; Iter    48/  201] train: loss: 0.1306996
[Epoch 93; Iter    78/  201] train: loss: 0.2036301
[Epoch 93; Iter   108/  201] train: loss: 0.1487938
[Epoch 93; Iter   138/  201] train: loss: 0.1368059
[Epoch 93; Iter   168/  201] train: loss: 0.0862736
[Epoch 93; Iter   198/  201] train: loss: 0.1529243
[Epoch 93] ogbg-moltoxcast: 0.734510 val loss: 0.219203
[Epoch 93] ogbg-moltoxcast: 0.743976 test loss: 0.215432
[Epoch 94; Iter    27/  201] train: loss: 0.1794832
[Epoch 94; Iter    57/  201] train: loss: 0.1228816
[Epoch 94; Iter    87/  201] train: loss: 0.1577053
[Epoch 94; Iter   117/  201] train: loss: 0.1381834
[Epoch 94; Iter   147/  201] train: loss: 0.1355178
[Epoch 94; Iter   177/  201] train: loss: 0.1248871
[Epoch 94] ogbg-moltoxcast: 0.732387 val loss: 0.217192
[Epoch 94] ogbg-moltoxcast: 0.742906 test loss: 0.215577
[Epoch 95; Iter     6/  201] train: loss: 0.1561274
[Epoch 95; Iter    36/  201] train: loss: 0.1224357
[Epoch 95; Iter    66/  201] train: loss: 0.1417591
[Epoch 95; Iter    96/  201] train: loss: 0.1582664
[Epoch 95; Iter   126/  201] train: loss: 0.1248037
[Epoch 95; Iter   156/  201] train: loss: 0.1184867
[Epoch 95; Iter   186/  201] train: loss: 0.1062403
[Epoch 95] ogbg-moltoxcast: 0.734995 val loss: 0.216741
[Epoch 95] ogbg-moltoxcast: 0.744479 test loss: 0.212879
[Epoch 96; Iter    15/  201] train: loss: 0.1263477
[Epoch 96; Iter    45/  201] train: loss: 0.1782597
[Epoch 96; Iter    75/  201] train: loss: 0.1937830
[Epoch 96; Iter   105/  201] train: loss: 0.1663157
[Epoch 96; Iter   135/  201] train: loss: 0.1070761
[Epoch 96; Iter   165/  201] train: loss: 0.1724177
[Epoch 96; Iter   195/  201] train: loss: 0.0778661
[Epoch 96] ogbg-moltoxcast: 0.734479 val loss: 0.219243
[Epoch 96] ogbg-moltoxcast: 0.744740 test loss: 0.215587
[Epoch 97; Iter    24/  201] train: loss: 0.1767384
[Epoch 97; Iter    54/  201] train: loss: 0.1298871
[Epoch 97; Iter    84/  201] train: loss: 0.1312925
[Epoch 97; Iter   114/  201] train: loss: 0.1182983
[Epoch 97; Iter   144/  201] train: loss: 0.1422539
[Epoch 97; Iter   174/  201] train: loss: 0.1305970
[Epoch 97] ogbg-moltoxcast: 0.733595 val loss: 0.218522
[Epoch 97] ogbg-moltoxcast: 0.744534 test loss: 0.215745
[Epoch 98; Iter     3/  201] train: loss: 0.1450323
[Epoch 98; Iter    33/  201] train: loss: 0.1472261
[Epoch 98; Iter    63/  201] train: loss: 0.1325466
[Epoch 98; Iter    93/  201] train: loss: 0.1799362
[Epoch 98; Iter   123/  201] train: loss: 0.0862801
[Epoch 98; Iter   153/  201] train: loss: 0.1319727
[Epoch 98; Iter   183/  201] train: loss: 0.1071999
[Epoch 98] ogbg-moltoxcast: 0.731605 val loss: 0.219161
[Epoch 98] ogbg-moltoxcast: 0.744365 test loss: 0.217648
[Epoch 99; Iter    12/  201] train: loss: 0.2120615
[Epoch 99; Iter    42/  201] train: loss: 0.0843598
[Epoch 99; Iter    72/  201] train: loss: 0.1399469
[Epoch 99; Iter   102/  201] train: loss: 0.1727185
[Epoch 99; Iter   132/  201] train: loss: 0.1358872
[Epoch 99; Iter   162/  201] train: loss: 0.1334932
[Epoch 99; Iter   192/  201] train: loss: 0.1092726
[Epoch 99] ogbg-moltoxcast: 0.731899 val loss: 0.218347
[Epoch 99] ogbg-moltoxcast: 0.741834 test loss: 0.217245
[Epoch 100; Iter    21/  201] train: loss: 0.1413162
[Epoch 100; Iter    51/  201] train: loss: 0.1148931
[Epoch 100; Iter    81/  201] train: loss: 0.1372901
[Epoch 100; Iter   111/  201] train: loss: 0.1353427
[Epoch 100; Iter   141/  201] train: loss: 0.1457139
[Epoch 100; Iter   171/  201] train: loss: 0.1324991
[Epoch 100; Iter   201/  201] train: loss: 0.1652486
[Epoch 100] ogbg-moltoxcast: 0.733333 val loss: 0.217501
[Epoch 100] ogbg-moltoxcast: 0.744658 test loss: 0.214111
[Epoch 101; Iter    30/  201] train: loss: 0.1304810
[Epoch 101; Iter    60/  201] train: loss: 0.1084323
[Epoch 101; Iter    90/  201] train: loss: 0.1374316
[Epoch 101; Iter   120/  201] train: loss: 0.2071945
[Epoch 101; Iter   150/  201] train: loss: 0.1031357
[Epoch 101; Iter   180/  201] train: loss: 0.1225865
[Epoch 94; Iter   114/  172] train: loss: 0.1091133
[Epoch 94; Iter   144/  172] train: loss: 0.1366541
[Epoch 94] ogbg-moltoxcast: 0.719769 val loss: 0.221835
[Epoch 94] ogbg-moltoxcast: 0.742998 test loss: 0.215531
[Epoch 95; Iter     2/  172] train: loss: 0.1498428
[Epoch 95; Iter    32/  172] train: loss: 0.1170206
[Epoch 95; Iter    62/  172] train: loss: 0.1605740
[Epoch 95; Iter    92/  172] train: loss: 0.1252522
[Epoch 95; Iter   122/  172] train: loss: 0.1217795
[Epoch 95; Iter   152/  172] train: loss: 0.1609777
[Epoch 95] ogbg-moltoxcast: 0.718156 val loss: 0.220141
[Epoch 95] ogbg-moltoxcast: 0.740646 test loss: 0.213963
[Epoch 96; Iter    10/  172] train: loss: 0.1342762
[Epoch 96; Iter    40/  172] train: loss: 0.1224677
[Epoch 96; Iter    70/  172] train: loss: 0.1209489
[Epoch 96; Iter   100/  172] train: loss: 0.1075408
[Epoch 96; Iter   130/  172] train: loss: 0.1232772
[Epoch 96; Iter   160/  172] train: loss: 0.0945376
[Epoch 96] ogbg-moltoxcast: 0.721617 val loss: 0.220577
[Epoch 96] ogbg-moltoxcast: 0.743209 test loss: 0.214351
[Epoch 97; Iter    18/  172] train: loss: 0.1071185
[Epoch 97; Iter    48/  172] train: loss: 0.1263050
[Epoch 97; Iter    78/  172] train: loss: 0.1345072
[Epoch 97; Iter   108/  172] train: loss: 0.1316680
[Epoch 97; Iter   138/  172] train: loss: 0.1112772
[Epoch 97; Iter   168/  172] train: loss: 0.1384397
[Epoch 97] ogbg-moltoxcast: 0.717398 val loss: 0.223893
[Epoch 97] ogbg-moltoxcast: 0.736108 test loss: 0.218667
[Epoch 98; Iter    26/  172] train: loss: 0.1125541
[Epoch 98; Iter    56/  172] train: loss: 0.1474124
[Epoch 98; Iter    86/  172] train: loss: 0.1076263
[Epoch 98; Iter   116/  172] train: loss: 0.1450775
[Epoch 98; Iter   146/  172] train: loss: 0.1177057
[Epoch 98] ogbg-moltoxcast: 0.720473 val loss: 0.221078
[Epoch 98] ogbg-moltoxcast: 0.742167 test loss: 0.215633
[Epoch 99; Iter     4/  172] train: loss: 0.1396329
[Epoch 99; Iter    34/  172] train: loss: 0.1655043
[Epoch 99; Iter    64/  172] train: loss: 0.1227797
[Epoch 99; Iter    94/  172] train: loss: 0.1114285
[Epoch 99; Iter   124/  172] train: loss: 0.1111321
[Epoch 99; Iter   154/  172] train: loss: 0.1461735
[Epoch 99] ogbg-moltoxcast: 0.722270 val loss: 0.219869
[Epoch 99] ogbg-moltoxcast: 0.742769 test loss: 0.213626
[Epoch 100; Iter    12/  172] train: loss: 0.0874640
[Epoch 100; Iter    42/  172] train: loss: 0.1284173
[Epoch 100; Iter    72/  172] train: loss: 0.2007033
[Epoch 100; Iter   102/  172] train: loss: 0.0878528
[Epoch 100; Iter   132/  172] train: loss: 0.1514690
[Epoch 100; Iter   162/  172] train: loss: 0.1187042
[Epoch 100] ogbg-moltoxcast: 0.721675 val loss: 0.220783
[Epoch 100] ogbg-moltoxcast: 0.743833 test loss: 0.213040
[Epoch 101; Iter    20/  172] train: loss: 0.1317053
[Epoch 101; Iter    50/  172] train: loss: 0.1193375
[Epoch 101; Iter    80/  172] train: loss: 0.1222085
[Epoch 101; Iter   110/  172] train: loss: 0.1252185
[Epoch 101; Iter   140/  172] train: loss: 0.1150554
[Epoch 101; Iter   170/  172] train: loss: 0.1531299
[Epoch 101] ogbg-moltoxcast: 0.718896 val loss: 0.231864
[Epoch 101] ogbg-moltoxcast: 0.740149 test loss: 0.217091
[Epoch 102; Iter    28/  172] train: loss: 0.1913560
[Epoch 102; Iter    58/  172] train: loss: 0.1119540
[Epoch 102; Iter    88/  172] train: loss: 0.1122742
[Epoch 102; Iter   118/  172] train: loss: 0.1480296
[Epoch 102; Iter   148/  172] train: loss: 0.1401346
[Epoch 102] ogbg-moltoxcast: 0.717693 val loss: 0.224868
[Epoch 102] ogbg-moltoxcast: 0.738337 test loss: 0.217525
[Epoch 103; Iter     6/  172] train: loss: 0.1344346
[Epoch 103; Iter    36/  172] train: loss: 0.1019539
[Epoch 103; Iter    66/  172] train: loss: 0.1125320
[Epoch 103; Iter    96/  172] train: loss: 0.1401591
[Epoch 103; Iter   126/  172] train: loss: 0.1149197
[Epoch 103; Iter   156/  172] train: loss: 0.1471560
[Epoch 103] ogbg-moltoxcast: 0.719621 val loss: 0.222528
[Epoch 103] ogbg-moltoxcast: 0.740612 test loss: 0.216777
[Epoch 104; Iter    14/  172] train: loss: 0.2225762
[Epoch 104; Iter    44/  172] train: loss: 0.1382659
[Epoch 104; Iter    74/  172] train: loss: 0.0935112
[Epoch 104; Iter   104/  172] train: loss: 0.1338349
[Epoch 104; Iter   134/  172] train: loss: 0.0976575
[Epoch 104; Iter   164/  172] train: loss: 0.1338642
[Epoch 104] ogbg-moltoxcast: 0.721724 val loss: 0.223719
[Epoch 104] ogbg-moltoxcast: 0.743533 test loss: 0.216163
[Epoch 105; Iter    22/  172] train: loss: 0.0903221
[Epoch 105; Iter    52/  172] train: loss: 0.1702373
[Epoch 105; Iter    82/  172] train: loss: 0.1354141
[Epoch 105; Iter   112/  172] train: loss: 0.1434403
[Epoch 105; Iter   142/  172] train: loss: 0.1423930
[Epoch 105; Iter   172/  172] train: loss: 0.0927479
[Epoch 105] ogbg-moltoxcast: 0.722752 val loss: 0.221742
[Epoch 105] ogbg-moltoxcast: 0.742466 test loss: 0.215371
[Epoch 106; Iter    30/  172] train: loss: 0.1606759
[Epoch 106; Iter    60/  172] train: loss: 0.1333549
[Epoch 106; Iter    90/  172] train: loss: 0.1647524
[Epoch 106; Iter   120/  172] train: loss: 0.1671958
[Epoch 106; Iter   150/  172] train: loss: 0.1463690
[Epoch 106] ogbg-moltoxcast: 0.720234 val loss: 0.223608
[Epoch 106] ogbg-moltoxcast: 0.742137 test loss: 0.217387
[Epoch 107; Iter     8/  172] train: loss: 0.1560411
[Epoch 107; Iter    38/  172] train: loss: 0.1305190
[Epoch 107; Iter    68/  172] train: loss: 0.1105783
[Epoch 107; Iter    98/  172] train: loss: 0.1343042
[Epoch 107; Iter   128/  172] train: loss: 0.1136739
[Epoch 107; Iter   158/  172] train: loss: 0.1333154
[Epoch 107] ogbg-moltoxcast: 0.719761 val loss: 0.225380
[Epoch 107] ogbg-moltoxcast: 0.742549 test loss: 0.217318
[Epoch 108; Iter    16/  172] train: loss: 0.1646276
[Epoch 108; Iter    46/  172] train: loss: 0.1608998
[Epoch 108; Iter    76/  172] train: loss: 0.1821174
[Epoch 108; Iter   106/  172] train: loss: 0.1096244
[Epoch 108; Iter   136/  172] train: loss: 0.1356943
[Epoch 108; Iter   166/  172] train: loss: 0.1761054
[Epoch 108] ogbg-moltoxcast: 0.718735 val loss: 0.225632
[Epoch 108] ogbg-moltoxcast: 0.739335 test loss: 0.218664
[Epoch 109; Iter    24/  172] train: loss: 0.1333640
[Epoch 109; Iter    54/  172] train: loss: 0.1084777
[Epoch 109; Iter    84/  172] train: loss: 0.1046571
[Epoch 109; Iter   114/  172] train: loss: 0.1251791
[Epoch 109; Iter   144/  172] train: loss: 0.1444429
[Epoch 109] ogbg-moltoxcast: 0.718125 val loss: 0.223523
[Epoch 109] ogbg-moltoxcast: 0.742255 test loss: 0.216156
[Epoch 110; Iter     2/  172] train: loss: 0.1217224
[Epoch 110; Iter    32/  172] train: loss: 0.1521588
[Epoch 110; Iter    62/  172] train: loss: 0.0748397
[Epoch 110; Iter    92/  172] train: loss: 0.0940676
[Epoch 110; Iter   122/  172] train: loss: 0.0807156
[Epoch 110; Iter   152/  172] train: loss: 0.1370436
[Epoch 110] ogbg-moltoxcast: 0.721010 val loss: 0.223080
[Epoch 110] ogbg-moltoxcast: 0.741810 test loss: 0.219072
[Epoch 111; Iter    10/  172] train: loss: 0.1460725
[Epoch 111; Iter    40/  172] train: loss: 0.1298328
[Epoch 111; Iter    70/  172] train: loss: 0.1091083
[Epoch 111; Iter   100/  172] train: loss: 0.1102939
[Epoch 111; Iter   130/  172] train: loss: 0.1306060
[Epoch 111; Iter   160/  172] train: loss: 0.0909182
[Epoch 111] ogbg-moltoxcast: 0.720981 val loss: 0.223915
[Epoch 111] ogbg-moltoxcast: 0.745007 test loss: 0.215821
[Epoch 112; Iter    18/  172] train: loss: 0.1393685
[Epoch 112; Iter    48/  172] train: loss: 0.1413925
[Epoch 112; Iter    78/  172] train: loss: 0.1519988
[Epoch 112; Iter   108/  172] train: loss: 0.1344331
[Epoch 112; Iter   138/  172] train: loss: 0.1320659
[Epoch 112; Iter   168/  172] train: loss: 0.1513570
[Epoch 112] ogbg-moltoxcast: 0.718884 val loss: 0.223142
[Epoch 112] ogbg-moltoxcast: 0.739151 test loss: 0.217353
[Epoch 113; Iter    26/  172] train: loss: 0.1195182
[Epoch 113; Iter    56/  172] train: loss: 0.1224116
[Epoch 113; Iter    86/  172] train: loss: 0.1516854
[Epoch 113; Iter   116/  172] train: loss: 0.1317937
[Epoch 113; Iter   146/  172] train: loss: 0.1235086
[Epoch 113] ogbg-moltoxcast: 0.720419 val loss: 0.223726
[Epoch 113] ogbg-moltoxcast: 0.738588 test loss: 0.219246
[Epoch 114; Iter     4/  172] train: loss: 0.1052872[Epoch 92; Iter    11/  229] train: loss: 0.1249612
[Epoch 92; Iter    41/  229] train: loss: 0.1211125
[Epoch 92; Iter    71/  229] train: loss: 0.1129939
[Epoch 92; Iter   101/  229] train: loss: 0.1837847
[Epoch 92; Iter   131/  229] train: loss: 0.1110029
[Epoch 92; Iter   161/  229] train: loss: 0.1189884
[Epoch 92; Iter   191/  229] train: loss: 0.1499932
[Epoch 92; Iter   221/  229] train: loss: 0.1720511
[Epoch 92] ogbg-moltoxcast: 0.748624 val loss: 0.204453
[Epoch 92] ogbg-moltoxcast: 0.761393 test loss: 0.211883
[Epoch 93; Iter    22/  229] train: loss: 0.1585845
[Epoch 93; Iter    52/  229] train: loss: 0.1038747
[Epoch 93; Iter    82/  229] train: loss: 0.1035453
[Epoch 93; Iter   112/  229] train: loss: 0.1528201
[Epoch 93; Iter   142/  229] train: loss: 0.1155470
[Epoch 93; Iter   172/  229] train: loss: 0.0953979
[Epoch 93; Iter   202/  229] train: loss: 0.1484549
[Epoch 93] ogbg-moltoxcast: 0.746957 val loss: 0.203282
[Epoch 93] ogbg-moltoxcast: 0.760721 test loss: 0.212770
[Epoch 94; Iter     3/  229] train: loss: 0.1418747
[Epoch 94; Iter    33/  229] train: loss: 0.1469905
[Epoch 94; Iter    63/  229] train: loss: 0.1340848
[Epoch 94; Iter    93/  229] train: loss: 0.1472405
[Epoch 94; Iter   123/  229] train: loss: 0.1211767
[Epoch 94; Iter   153/  229] train: loss: 0.1034163
[Epoch 94; Iter   183/  229] train: loss: 0.1207688
[Epoch 94; Iter   213/  229] train: loss: 0.1369879
[Epoch 94] ogbg-moltoxcast: 0.746682 val loss: 0.203773
[Epoch 94] ogbg-moltoxcast: 0.759674 test loss: 0.214374
[Epoch 95; Iter    14/  229] train: loss: 0.1150264
[Epoch 95; Iter    44/  229] train: loss: 0.1792965
[Epoch 95; Iter    74/  229] train: loss: 0.1548912
[Epoch 95; Iter   104/  229] train: loss: 0.1479699
[Epoch 95; Iter   134/  229] train: loss: 0.1584963
[Epoch 95; Iter   164/  229] train: loss: 0.1309776
[Epoch 95; Iter   194/  229] train: loss: 0.1166871
[Epoch 95; Iter   224/  229] train: loss: 0.1502725
[Epoch 95] ogbg-moltoxcast: 0.746289 val loss: 0.202406
[Epoch 95] ogbg-moltoxcast: 0.761005 test loss: 0.210437
[Epoch 96; Iter    25/  229] train: loss: 0.1089213
[Epoch 96; Iter    55/  229] train: loss: 0.1279546
[Epoch 96; Iter    85/  229] train: loss: 0.1358592
[Epoch 96; Iter   115/  229] train: loss: 0.1415174
[Epoch 96; Iter   145/  229] train: loss: 0.1514081
[Epoch 96; Iter   175/  229] train: loss: 0.1216297
[Epoch 96; Iter   205/  229] train: loss: 0.1442788
[Epoch 96] ogbg-moltoxcast: 0.747432 val loss: 0.205267
[Epoch 96] ogbg-moltoxcast: 0.758373 test loss: 0.213801
[Epoch 97; Iter     6/  229] train: loss: 0.1217577
[Epoch 97; Iter    36/  229] train: loss: 0.1183264
[Epoch 97; Iter    66/  229] train: loss: 0.1620821
[Epoch 97; Iter    96/  229] train: loss: 0.1226574
[Epoch 97; Iter   126/  229] train: loss: 0.1547330
[Epoch 97; Iter   156/  229] train: loss: 0.0708077
[Epoch 97; Iter   186/  229] train: loss: 0.1789531
[Epoch 97; Iter   216/  229] train: loss: 0.1556103
[Epoch 97] ogbg-moltoxcast: 0.749910 val loss: 0.200739
[Epoch 97] ogbg-moltoxcast: 0.762563 test loss: 0.234461
[Epoch 98; Iter    17/  229] train: loss: 0.1547728
[Epoch 98; Iter    47/  229] train: loss: 0.1663305
[Epoch 98; Iter    77/  229] train: loss: 0.1235116
[Epoch 98; Iter   107/  229] train: loss: 0.1507899
[Epoch 98; Iter   137/  229] train: loss: 0.1051720
[Epoch 98; Iter   167/  229] train: loss: 0.1674908
[Epoch 98; Iter   197/  229] train: loss: 0.1391516
[Epoch 98; Iter   227/  229] train: loss: 0.1833821
[Epoch 98] ogbg-moltoxcast: 0.748572 val loss: 0.203944
[Epoch 98] ogbg-moltoxcast: 0.758396 test loss: 0.213317
[Epoch 99; Iter    28/  229] train: loss: 0.1614461
[Epoch 99; Iter    58/  229] train: loss: 0.1478020
[Epoch 99; Iter    88/  229] train: loss: 0.1456590
[Epoch 99; Iter   118/  229] train: loss: 0.1422305
[Epoch 99; Iter   148/  229] train: loss: 0.1366074
[Epoch 99; Iter   178/  229] train: loss: 0.1941252
[Epoch 99; Iter   208/  229] train: loss: 0.1580615
[Epoch 99] ogbg-moltoxcast: 0.748819 val loss: 0.203056
[Epoch 99] ogbg-moltoxcast: 0.762670 test loss: 0.240352
[Epoch 100; Iter     9/  229] train: loss: 0.1709051
[Epoch 100; Iter    39/  229] train: loss: 0.1060070
[Epoch 100; Iter    69/  229] train: loss: 0.1023957
[Epoch 100; Iter    99/  229] train: loss: 0.1073184
[Epoch 100; Iter   129/  229] train: loss: 0.1577810
[Epoch 100; Iter   159/  229] train: loss: 0.1418819
[Epoch 100; Iter   189/  229] train: loss: 0.1214488
[Epoch 100; Iter   219/  229] train: loss: 0.1457062
[Epoch 100] ogbg-moltoxcast: 0.746875 val loss: 0.203612
[Epoch 100] ogbg-moltoxcast: 0.761538 test loss: 0.214076
[Epoch 101; Iter    20/  229] train: loss: 0.1330315
[Epoch 101; Iter    50/  229] train: loss: 0.0911728
[Epoch 101; Iter    80/  229] train: loss: 0.1319441
[Epoch 101; Iter   110/  229] train: loss: 0.1529638
[Epoch 101; Iter   140/  229] train: loss: 0.1566316
[Epoch 101; Iter   170/  229] train: loss: 0.0978372
[Epoch 101; Iter   200/  229] train: loss: 0.1369571
[Epoch 101] ogbg-moltoxcast: 0.750429 val loss: 0.201653
[Epoch 101] ogbg-moltoxcast: 0.760730 test loss: 0.242340
[Epoch 102; Iter     1/  229] train: loss: 0.1520297
[Epoch 102; Iter    31/  229] train: loss: 0.1399179
[Epoch 102; Iter    61/  229] train: loss: 0.1616490
[Epoch 102; Iter    91/  229] train: loss: 0.1755645
[Epoch 102; Iter   121/  229] train: loss: 0.1202511
[Epoch 102; Iter   151/  229] train: loss: 0.1441936
[Epoch 102; Iter   181/  229] train: loss: 0.1530754
[Epoch 102; Iter   211/  229] train: loss: 0.1579612
[Epoch 102] ogbg-moltoxcast: 0.747902 val loss: 0.206119
[Epoch 102] ogbg-moltoxcast: 0.762242 test loss: 0.213137
[Epoch 103; Iter    12/  229] train: loss: 0.1090905
[Epoch 103; Iter    42/  229] train: loss: 0.1484384
[Epoch 103; Iter    72/  229] train: loss: 0.1626738
[Epoch 103; Iter   102/  229] train: loss: 0.0894293
[Epoch 103; Iter   132/  229] train: loss: 0.1232821
[Epoch 103; Iter   162/  229] train: loss: 0.1304519
[Epoch 103; Iter   192/  229] train: loss: 0.1366216
[Epoch 103; Iter   222/  229] train: loss: 0.1205489
[Epoch 103] ogbg-moltoxcast: 0.746888 val loss: 0.203673
[Epoch 103] ogbg-moltoxcast: 0.759726 test loss: 0.210072
[Epoch 104; Iter    23/  229] train: loss: 0.1181026
[Epoch 104; Iter    53/  229] train: loss: 0.1350635
[Epoch 104; Iter    83/  229] train: loss: 0.1357848
[Epoch 104; Iter   113/  229] train: loss: 0.1472680
[Epoch 104; Iter   143/  229] train: loss: 0.1435896
[Epoch 104; Iter   173/  229] train: loss: 0.1282938
[Epoch 104; Iter   203/  229] train: loss: 0.1431201
[Epoch 104] ogbg-moltoxcast: 0.747797 val loss: 0.203432
[Epoch 104] ogbg-moltoxcast: 0.758285 test loss: 0.213555
[Epoch 105; Iter     4/  229] train: loss: 0.1259881
[Epoch 105; Iter    34/  229] train: loss: 0.1175447
[Epoch 105; Iter    64/  229] train: loss: 0.1302191
[Epoch 105; Iter    94/  229] train: loss: 0.1240147
[Epoch 105; Iter   124/  229] train: loss: 0.1251804
[Epoch 105; Iter   154/  229] train: loss: 0.1388177
[Epoch 105; Iter   184/  229] train: loss: 0.1628563
[Epoch 105; Iter   214/  229] train: loss: 0.0971748
[Epoch 105] ogbg-moltoxcast: 0.746452 val loss: 0.204221
[Epoch 105] ogbg-moltoxcast: 0.761120 test loss: 0.213108
[Epoch 106; Iter    15/  229] train: loss: 0.1285364
[Epoch 106; Iter    45/  229] train: loss: 0.2304226
[Epoch 106; Iter    75/  229] train: loss: 0.1271722
[Epoch 106; Iter   105/  229] train: loss: 0.1367160
[Epoch 106; Iter   135/  229] train: loss: 0.1129790
[Epoch 106; Iter   165/  229] train: loss: 0.1515716
[Epoch 106; Iter   195/  229] train: loss: 0.1292339
[Epoch 106; Iter   225/  229] train: loss: 0.1237191
[Epoch 106] ogbg-moltoxcast: 0.745392 val loss: 0.204365
[Epoch 106] ogbg-moltoxcast: 0.756983 test loss: 0.214386
[Epoch 107; Iter    26/  229] train: loss: 0.0985427
[Epoch 107; Iter    56/  229] train: loss: 0.1126685
[Epoch 107; Iter    86/  229] train: loss: 0.1539729
[Epoch 107; Iter   116/  229] train: loss: 0.1037287
[Epoch 107; Iter   146/  229] train: loss: 0.1290101
[Epoch 107; Iter   176/  229] train: loss: 0.1957056
[Epoch 107; Iter   206/  229] train: loss: 0.1121993
[Epoch 107] ogbg-moltoxcast: 0.745580 val loss: 0.204751
[Epoch 92; Iter    11/  229] train: loss: 0.1585156
[Epoch 92; Iter    41/  229] train: loss: 0.1540611
[Epoch 92; Iter    71/  229] train: loss: 0.1262557
[Epoch 92; Iter   101/  229] train: loss: 0.1894068
[Epoch 92; Iter   131/  229] train: loss: 0.1431953
[Epoch 92; Iter   161/  229] train: loss: 0.1291385
[Epoch 92; Iter   191/  229] train: loss: 0.1124672
[Epoch 92; Iter   221/  229] train: loss: 0.1400910
[Epoch 92] ogbg-moltoxcast: 0.743775 val loss: 0.203453
[Epoch 92] ogbg-moltoxcast: 0.754545 test loss: 0.211702
[Epoch 93; Iter    22/  229] train: loss: 0.1413217
[Epoch 93; Iter    52/  229] train: loss: 0.1448041
[Epoch 93; Iter    82/  229] train: loss: 0.1327519
[Epoch 93; Iter   112/  229] train: loss: 0.1617742
[Epoch 93; Iter   142/  229] train: loss: 0.1425523
[Epoch 93; Iter   172/  229] train: loss: 0.1584083
[Epoch 93; Iter   202/  229] train: loss: 0.1557821
[Epoch 93] ogbg-moltoxcast: 0.741967 val loss: 0.204022
[Epoch 93] ogbg-moltoxcast: 0.755690 test loss: 0.209590
[Epoch 94; Iter     3/  229] train: loss: 0.1591639
[Epoch 94; Iter    33/  229] train: loss: 0.1219866
[Epoch 94; Iter    63/  229] train: loss: 0.0898048
[Epoch 94; Iter    93/  229] train: loss: 0.1877494
[Epoch 94; Iter   123/  229] train: loss: 0.1325465
[Epoch 94; Iter   153/  229] train: loss: 0.1440307
[Epoch 94; Iter   183/  229] train: loss: 0.1241229
[Epoch 94; Iter   213/  229] train: loss: 0.0765116
[Epoch 94] ogbg-moltoxcast: 0.740153 val loss: 0.203962
[Epoch 94] ogbg-moltoxcast: 0.753061 test loss: 0.309108
[Epoch 95; Iter    14/  229] train: loss: 0.1273249
[Epoch 95; Iter    44/  229] train: loss: 0.1309905
[Epoch 95; Iter    74/  229] train: loss: 0.1365816
[Epoch 95; Iter   104/  229] train: loss: 0.1577829
[Epoch 95; Iter   134/  229] train: loss: 0.1073270
[Epoch 95; Iter   164/  229] train: loss: 0.2190169
[Epoch 95; Iter   194/  229] train: loss: 0.1337212
[Epoch 95; Iter   224/  229] train: loss: 0.2119159
[Epoch 95] ogbg-moltoxcast: 0.741862 val loss: 0.204414
[Epoch 95] ogbg-moltoxcast: 0.752492 test loss: 0.214208
[Epoch 96; Iter    25/  229] train: loss: 0.1393109
[Epoch 96; Iter    55/  229] train: loss: 0.1578804
[Epoch 96; Iter    85/  229] train: loss: 0.1246429
[Epoch 96; Iter   115/  229] train: loss: 0.1467850
[Epoch 96; Iter   145/  229] train: loss: 0.1249060
[Epoch 96; Iter   175/  229] train: loss: 0.1643514
[Epoch 96; Iter   205/  229] train: loss: 0.1822414
[Epoch 96] ogbg-moltoxcast: 0.740241 val loss: 0.203584
[Epoch 96] ogbg-moltoxcast: 0.753502 test loss: 0.215058
[Epoch 97; Iter     6/  229] train: loss: 0.1517909
[Epoch 97; Iter    36/  229] train: loss: 0.1124374
[Epoch 97; Iter    66/  229] train: loss: 0.1150806
[Epoch 97; Iter    96/  229] train: loss: 0.1566951
[Epoch 97; Iter   126/  229] train: loss: 0.1353007
[Epoch 97; Iter   156/  229] train: loss: 0.1269611
[Epoch 97; Iter   186/  229] train: loss: 0.0919146
[Epoch 97; Iter   216/  229] train: loss: 0.1502408
[Epoch 97] ogbg-moltoxcast: 0.739311 val loss: 0.206777
[Epoch 97] ogbg-moltoxcast: 0.755300 test loss: 0.213129
[Epoch 98; Iter    17/  229] train: loss: 0.1663221
[Epoch 98; Iter    47/  229] train: loss: 0.1315940
[Epoch 98; Iter    77/  229] train: loss: 0.1227539
[Epoch 98; Iter   107/  229] train: loss: 0.1595576
[Epoch 98; Iter   137/  229] train: loss: 0.1492209
[Epoch 98; Iter   167/  229] train: loss: 0.1090704
[Epoch 98; Iter   197/  229] train: loss: 0.1268013
[Epoch 98; Iter   227/  229] train: loss: 0.1318019
[Epoch 98] ogbg-moltoxcast: 0.741835 val loss: 0.203110
[Epoch 98] ogbg-moltoxcast: 0.755311 test loss: 0.212443
[Epoch 99; Iter    28/  229] train: loss: 0.1297554
[Epoch 99; Iter    58/  229] train: loss: 0.1288294
[Epoch 99; Iter    88/  229] train: loss: 0.1676792
[Epoch 99; Iter   118/  229] train: loss: 0.0999757
[Epoch 99; Iter   148/  229] train: loss: 0.0668073
[Epoch 99; Iter   178/  229] train: loss: 0.1722461
[Epoch 99; Iter   208/  229] train: loss: 0.1412014
[Epoch 99] ogbg-moltoxcast: 0.741366 val loss: 0.206869
[Epoch 99] ogbg-moltoxcast: 0.753422 test loss: 0.212580
[Epoch 100; Iter     9/  229] train: loss: 0.1269343
[Epoch 100; Iter    39/  229] train: loss: 0.1411885
[Epoch 100; Iter    69/  229] train: loss: 0.1196343
[Epoch 100; Iter    99/  229] train: loss: 0.1920943
[Epoch 100; Iter   129/  229] train: loss: 0.2064172
[Epoch 100; Iter   159/  229] train: loss: 0.1518957
[Epoch 100; Iter   189/  229] train: loss: 0.1169220
[Epoch 100; Iter   219/  229] train: loss: 0.1641182
[Epoch 100] ogbg-moltoxcast: 0.742507 val loss: 0.204926
[Epoch 100] ogbg-moltoxcast: 0.753818 test loss: 0.213658
[Epoch 101; Iter    20/  229] train: loss: 0.1486304
[Epoch 101; Iter    50/  229] train: loss: 0.1304879
[Epoch 101; Iter    80/  229] train: loss: 0.1030508
[Epoch 101; Iter   110/  229] train: loss: 0.1861007
[Epoch 101; Iter   140/  229] train: loss: 0.1573237
[Epoch 101; Iter   170/  229] train: loss: 0.1956971
[Epoch 101; Iter   200/  229] train: loss: 0.1219276
[Epoch 101] ogbg-moltoxcast: 0.745379 val loss: 0.203508
[Epoch 101] ogbg-moltoxcast: 0.753745 test loss: 0.213782
[Epoch 102; Iter     1/  229] train: loss: 0.1402776
[Epoch 102; Iter    31/  229] train: loss: 0.1248190
[Epoch 102; Iter    61/  229] train: loss: 0.1875450
[Epoch 102; Iter    91/  229] train: loss: 0.1591092
[Epoch 102; Iter   121/  229] train: loss: 0.1386285
[Epoch 102; Iter   151/  229] train: loss: 0.1395524
[Epoch 102; Iter   181/  229] train: loss: 0.0813077
[Epoch 102; Iter   211/  229] train: loss: 0.0935309
[Epoch 102] ogbg-moltoxcast: 0.741596 val loss: 0.205659
[Epoch 102] ogbg-moltoxcast: 0.749413 test loss: 0.215194
[Epoch 103; Iter    12/  229] train: loss: 0.1460808
[Epoch 103; Iter    42/  229] train: loss: 0.2017298
[Epoch 103; Iter    72/  229] train: loss: 0.1372453
[Epoch 103; Iter   102/  229] train: loss: 0.1170374
[Epoch 103; Iter   132/  229] train: loss: 0.1655928
[Epoch 103; Iter   162/  229] train: loss: 0.1553502
[Epoch 103; Iter   192/  229] train: loss: 0.0892749
[Epoch 103; Iter   222/  229] train: loss: 0.1322436
[Epoch 103] ogbg-moltoxcast: 0.741273 val loss: 0.205021
[Epoch 103] ogbg-moltoxcast: 0.749975 test loss: 0.220144
[Epoch 104; Iter    23/  229] train: loss: 0.1319695
[Epoch 104; Iter    53/  229] train: loss: 0.1251252
[Epoch 104; Iter    83/  229] train: loss: 0.1605202
[Epoch 104; Iter   113/  229] train: loss: 0.1260333
[Epoch 104; Iter   143/  229] train: loss: 0.1199617
[Epoch 104; Iter   173/  229] train: loss: 0.1474226
[Epoch 104; Iter   203/  229] train: loss: 0.1136897
[Epoch 104] ogbg-moltoxcast: 0.741375 val loss: 0.205826
[Epoch 104] ogbg-moltoxcast: 0.750229 test loss: 0.217996
[Epoch 105; Iter     4/  229] train: loss: 0.1108300
[Epoch 105; Iter    34/  229] train: loss: 0.2065938
[Epoch 105; Iter    64/  229] train: loss: 0.1267340
[Epoch 105; Iter    94/  229] train: loss: 0.1531899
[Epoch 105; Iter   124/  229] train: loss: 0.1504771
[Epoch 105; Iter   154/  229] train: loss: 0.1422747
[Epoch 105; Iter   184/  229] train: loss: 0.1411067
[Epoch 105; Iter   214/  229] train: loss: 0.1160066
[Epoch 105] ogbg-moltoxcast: 0.740038 val loss: 0.206301
[Epoch 105] ogbg-moltoxcast: 0.754644 test loss: 0.215533
[Epoch 106; Iter    15/  229] train: loss: 0.2506946
[Epoch 106; Iter    45/  229] train: loss: 0.1479672
[Epoch 106; Iter    75/  229] train: loss: 0.0869688
[Epoch 106; Iter   105/  229] train: loss: 0.1153517
[Epoch 106; Iter   135/  229] train: loss: 0.1393230
[Epoch 106; Iter   165/  229] train: loss: 0.1696325
[Epoch 106; Iter   195/  229] train: loss: 0.1153742
[Epoch 106; Iter   225/  229] train: loss: 0.1178190
[Epoch 106] ogbg-moltoxcast: 0.737496 val loss: 0.205715
[Epoch 106] ogbg-moltoxcast: 0.747466 test loss: 0.216889
[Epoch 107; Iter    26/  229] train: loss: 0.1032975
[Epoch 107; Iter    56/  229] train: loss: 0.1511204
[Epoch 107; Iter    86/  229] train: loss: 0.1063272
[Epoch 107; Iter   116/  229] train: loss: 0.1284555
[Epoch 107; Iter   146/  229] train: loss: 0.1165673
[Epoch 107; Iter   176/  229] train: loss: 0.1171947
[Epoch 107; Iter   206/  229] train: loss: 0.1000377
[Epoch 107] ogbg-moltoxcast: 0.745451 val loss: 0.204233
[Epoch 94; Iter   114/  172] train: loss: 0.1252924
[Epoch 94; Iter   144/  172] train: loss: 0.1612633
[Epoch 94] ogbg-moltoxcast: 0.722359 val loss: 0.218472
[Epoch 94] ogbg-moltoxcast: 0.734661 test loss: 0.215629
[Epoch 95; Iter     2/  172] train: loss: 0.1105674
[Epoch 95; Iter    32/  172] train: loss: 0.1489193
[Epoch 95; Iter    62/  172] train: loss: 0.1118894
[Epoch 95; Iter    92/  172] train: loss: 0.1203468
[Epoch 95; Iter   122/  172] train: loss: 0.1711111
[Epoch 95; Iter   152/  172] train: loss: 0.1257271
[Epoch 95] ogbg-moltoxcast: 0.722527 val loss: 0.217946
[Epoch 95] ogbg-moltoxcast: 0.733490 test loss: 0.215213
[Epoch 96; Iter    10/  172] train: loss: 0.1392895
[Epoch 96; Iter    40/  172] train: loss: 0.1341669
[Epoch 96; Iter    70/  172] train: loss: 0.0963540
[Epoch 96; Iter   100/  172] train: loss: 0.1537636
[Epoch 96; Iter   130/  172] train: loss: 0.0902982
[Epoch 96; Iter   160/  172] train: loss: 0.1589199
[Epoch 96] ogbg-moltoxcast: 0.721708 val loss: 0.218788
[Epoch 96] ogbg-moltoxcast: 0.732233 test loss: 0.216138
[Epoch 97; Iter    18/  172] train: loss: 0.0875789
[Epoch 97; Iter    48/  172] train: loss: 0.1283394
[Epoch 97; Iter    78/  172] train: loss: 0.1848960
[Epoch 97; Iter   108/  172] train: loss: 0.1617559
[Epoch 97; Iter   138/  172] train: loss: 0.1475503
[Epoch 97; Iter   168/  172] train: loss: 0.1488270
[Epoch 97] ogbg-moltoxcast: 0.722902 val loss: 0.223395
[Epoch 97] ogbg-moltoxcast: 0.735995 test loss: 0.217175
[Epoch 98; Iter    26/  172] train: loss: 0.1120624
[Epoch 98; Iter    56/  172] train: loss: 0.1848341
[Epoch 98; Iter    86/  172] train: loss: 0.1125186
[Epoch 98; Iter   116/  172] train: loss: 0.1270531
[Epoch 98; Iter   146/  172] train: loss: 0.1009504
[Epoch 98] ogbg-moltoxcast: 0.721293 val loss: 0.218506
[Epoch 98] ogbg-moltoxcast: 0.732007 test loss: 0.217424
[Epoch 99; Iter     4/  172] train: loss: 0.1520864
[Epoch 99; Iter    34/  172] train: loss: 0.1119126
[Epoch 99; Iter    64/  172] train: loss: 0.1422896
[Epoch 99; Iter    94/  172] train: loss: 0.1425085
[Epoch 99; Iter   124/  172] train: loss: 0.1606732
[Epoch 99; Iter   154/  172] train: loss: 0.1614483
[Epoch 99] ogbg-moltoxcast: 0.725921 val loss: 0.218926
[Epoch 99] ogbg-moltoxcast: 0.735692 test loss: 0.217531
[Epoch 100; Iter    12/  172] train: loss: 0.1307217
[Epoch 100; Iter    42/  172] train: loss: 0.0939110
[Epoch 100; Iter    72/  172] train: loss: 0.1436789
[Epoch 100; Iter   102/  172] train: loss: 0.1240076
[Epoch 100; Iter   132/  172] train: loss: 0.1139708
[Epoch 100; Iter   162/  172] train: loss: 0.1505002
[Epoch 100] ogbg-moltoxcast: 0.722710 val loss: 0.230132
[Epoch 100] ogbg-moltoxcast: 0.736507 test loss: 0.216405
[Epoch 101; Iter    20/  172] train: loss: 0.1202163
[Epoch 101; Iter    50/  172] train: loss: 0.1516563
[Epoch 101; Iter    80/  172] train: loss: 0.1192536
[Epoch 101; Iter   110/  172] train: loss: 0.0802312
[Epoch 101; Iter   140/  172] train: loss: 0.1395110
[Epoch 101; Iter   170/  172] train: loss: 0.1400814
[Epoch 101] ogbg-moltoxcast: 0.721281 val loss: 0.236808
[Epoch 101] ogbg-moltoxcast: 0.734021 test loss: 0.216728
[Epoch 102; Iter    28/  172] train: loss: 0.1202817
[Epoch 102; Iter    58/  172] train: loss: 0.1001321
[Epoch 102; Iter    88/  172] train: loss: 0.1551421
[Epoch 102; Iter   118/  172] train: loss: 0.1608646
[Epoch 102; Iter   148/  172] train: loss: 0.1512625
[Epoch 102] ogbg-moltoxcast: 0.720277 val loss: 0.221645
[Epoch 102] ogbg-moltoxcast: 0.733845 test loss: 0.218511
[Epoch 103; Iter     6/  172] train: loss: 0.1314854
[Epoch 103; Iter    36/  172] train: loss: 0.0923886
[Epoch 103; Iter    66/  172] train: loss: 0.1081190
[Epoch 103; Iter    96/  172] train: loss: 0.1120051
[Epoch 103; Iter   126/  172] train: loss: 0.1836446
[Epoch 103; Iter   156/  172] train: loss: 0.0990010
[Epoch 103] ogbg-moltoxcast: 0.721337 val loss: 0.221867
[Epoch 103] ogbg-moltoxcast: 0.733356 test loss: 0.218610
[Epoch 104; Iter    14/  172] train: loss: 0.1414002
[Epoch 104; Iter    44/  172] train: loss: 0.1138885
[Epoch 104; Iter    74/  172] train: loss: 0.1545092
[Epoch 104; Iter   104/  172] train: loss: 0.1033467
[Epoch 104; Iter   134/  172] train: loss: 0.1720087
[Epoch 104; Iter   164/  172] train: loss: 0.1735462
[Epoch 104] ogbg-moltoxcast: 0.718923 val loss: 0.221176
[Epoch 104] ogbg-moltoxcast: 0.734349 test loss: 0.216383
[Epoch 105; Iter    22/  172] train: loss: 0.1220188
[Epoch 105; Iter    52/  172] train: loss: 0.1400522
[Epoch 105; Iter    82/  172] train: loss: 0.1252956
[Epoch 105; Iter   112/  172] train: loss: 0.1104811
[Epoch 105; Iter   142/  172] train: loss: 0.1289347
[Epoch 105; Iter   172/  172] train: loss: 0.1621337
[Epoch 105] ogbg-moltoxcast: 0.720325 val loss: 0.230343
[Epoch 105] ogbg-moltoxcast: 0.731786 test loss: 0.218105
[Epoch 106; Iter    30/  172] train: loss: 0.1072301
[Epoch 106; Iter    60/  172] train: loss: 0.1407839
[Epoch 106; Iter    90/  172] train: loss: 0.1267807
[Epoch 106; Iter   120/  172] train: loss: 0.1183088
[Epoch 106; Iter   150/  172] train: loss: 0.1391199
[Epoch 106] ogbg-moltoxcast: 0.720347 val loss: 0.220042
[Epoch 106] ogbg-moltoxcast: 0.734230 test loss: 0.216306
[Epoch 107; Iter     8/  172] train: loss: 0.1730581
[Epoch 107; Iter    38/  172] train: loss: 0.1169987
[Epoch 107; Iter    68/  172] train: loss: 0.0854298
[Epoch 107; Iter    98/  172] train: loss: 0.1579228
[Epoch 107; Iter   128/  172] train: loss: 0.1207634
[Epoch 107; Iter   158/  172] train: loss: 0.1574721
[Epoch 107] ogbg-moltoxcast: 0.719574 val loss: 0.226132
[Epoch 107] ogbg-moltoxcast: 0.732688 test loss: 0.218123
[Epoch 108; Iter    16/  172] train: loss: 0.1734567
[Epoch 108; Iter    46/  172] train: loss: 0.1331770
[Epoch 108; Iter    76/  172] train: loss: 0.1271118
[Epoch 108; Iter   106/  172] train: loss: 0.1692044
[Epoch 108; Iter   136/  172] train: loss: 0.1380841
[Epoch 108; Iter   166/  172] train: loss: 0.1406668
[Epoch 108] ogbg-moltoxcast: 0.720606 val loss: 0.222153
[Epoch 108] ogbg-moltoxcast: 0.733119 test loss: 0.219350
[Epoch 109; Iter    24/  172] train: loss: 0.0984755
[Epoch 109; Iter    54/  172] train: loss: 0.1510571
[Epoch 109; Iter    84/  172] train: loss: 0.1314612
[Epoch 109; Iter   114/  172] train: loss: 0.1487272
[Epoch 109; Iter   144/  172] train: loss: 0.1067686
[Epoch 109] ogbg-moltoxcast: 0.717773 val loss: 0.223720
[Epoch 109] ogbg-moltoxcast: 0.732022 test loss: 0.220254
[Epoch 110; Iter     2/  172] train: loss: 0.1856203
[Epoch 110; Iter    32/  172] train: loss: 0.1426013
[Epoch 110; Iter    62/  172] train: loss: 0.1331738
[Epoch 110; Iter    92/  172] train: loss: 0.0877302
[Epoch 110; Iter   122/  172] train: loss: 0.1300805
[Epoch 110; Iter   152/  172] train: loss: 0.1201493
[Epoch 110] ogbg-moltoxcast: 0.720265 val loss: 0.233611
[Epoch 110] ogbg-moltoxcast: 0.733534 test loss: 0.218832
[Epoch 111; Iter    10/  172] train: loss: 0.1214215
[Epoch 111; Iter    40/  172] train: loss: 0.1686816
[Epoch 111; Iter    70/  172] train: loss: 0.1408832
[Epoch 111; Iter   100/  172] train: loss: 0.1191562
[Epoch 111; Iter   130/  172] train: loss: 0.1216518
[Epoch 111; Iter   160/  172] train: loss: 0.1463735
[Epoch 111] ogbg-moltoxcast: 0.721974 val loss: 0.232484
[Epoch 111] ogbg-moltoxcast: 0.735627 test loss: 0.218334
[Epoch 112; Iter    18/  172] train: loss: 0.1292833
[Epoch 112; Iter    48/  172] train: loss: 0.1387798
[Epoch 112; Iter    78/  172] train: loss: 0.2238208
[Epoch 112; Iter   108/  172] train: loss: 0.1168358
[Epoch 112; Iter   138/  172] train: loss: 0.1228573
[Epoch 112; Iter   168/  172] train: loss: 0.0922506
[Epoch 112] ogbg-moltoxcast: 0.722421 val loss: 0.221153
[Epoch 112] ogbg-moltoxcast: 0.733016 test loss: 0.219918
[Epoch 113; Iter    26/  172] train: loss: 0.1283200
[Epoch 113; Iter    56/  172] train: loss: 0.1829352
[Epoch 113; Iter    86/  172] train: loss: 0.1558090
[Epoch 113; Iter   116/  172] train: loss: 0.0986421
[Epoch 113; Iter   146/  172] train: loss: 0.1452919
[Epoch 113] ogbg-moltoxcast: 0.719874 val loss: 0.241818
[Epoch 113] ogbg-moltoxcast: 0.732016 test loss: 0.219573
[Epoch 114; Iter     4/  172] train: loss: 0.1345830[Epoch 92; Iter    11/  229] train: loss: 0.1412426
[Epoch 92; Iter    41/  229] train: loss: 0.1386388
[Epoch 92; Iter    71/  229] train: loss: 0.1567696
[Epoch 92; Iter   101/  229] train: loss: 0.1838405
[Epoch 92; Iter   131/  229] train: loss: 0.1160698
[Epoch 92; Iter   161/  229] train: loss: 0.0991310
[Epoch 92; Iter   191/  229] train: loss: 0.1805125
[Epoch 92; Iter   221/  229] train: loss: 0.0975958
[Epoch 92] ogbg-moltoxcast: 0.739674 val loss: 0.202142
[Epoch 92] ogbg-moltoxcast: 0.754535 test loss: 0.216737
[Epoch 93; Iter    22/  229] train: loss: 0.0983574
[Epoch 93; Iter    52/  229] train: loss: 0.0824398
[Epoch 93; Iter    82/  229] train: loss: 0.1330558
[Epoch 93; Iter   112/  229] train: loss: 0.1618904
[Epoch 93; Iter   142/  229] train: loss: 0.0718573
[Epoch 93; Iter   172/  229] train: loss: 0.1516866
[Epoch 93; Iter   202/  229] train: loss: 0.1413812
[Epoch 93] ogbg-moltoxcast: 0.744021 val loss: 0.198792
[Epoch 93] ogbg-moltoxcast: 0.755625 test loss: 0.214444
[Epoch 94; Iter     3/  229] train: loss: 0.1547936
[Epoch 94; Iter    33/  229] train: loss: 0.1420221
[Epoch 94; Iter    63/  229] train: loss: 0.0851422
[Epoch 94; Iter    93/  229] train: loss: 0.2025252
[Epoch 94; Iter   123/  229] train: loss: 0.1341064
[Epoch 94; Iter   153/  229] train: loss: 0.1493287
[Epoch 94; Iter   183/  229] train: loss: 0.1719332
[Epoch 94; Iter   213/  229] train: loss: 0.1581472
[Epoch 94] ogbg-moltoxcast: 0.745080 val loss: 0.199624
[Epoch 94] ogbg-moltoxcast: 0.755651 test loss: 0.216909
[Epoch 95; Iter    14/  229] train: loss: 0.1060131
[Epoch 95; Iter    44/  229] train: loss: 0.1930096
[Epoch 95; Iter    74/  229] train: loss: 0.1077832
[Epoch 95; Iter   104/  229] train: loss: 0.1685883
[Epoch 95; Iter   134/  229] train: loss: 0.1453740
[Epoch 95; Iter   164/  229] train: loss: 0.1558578
[Epoch 95; Iter   194/  229] train: loss: 0.1703411
[Epoch 95; Iter   224/  229] train: loss: 0.0966604
[Epoch 95] ogbg-moltoxcast: 0.744764 val loss: 0.202419
[Epoch 95] ogbg-moltoxcast: 0.754048 test loss: 0.219812
[Epoch 96; Iter    25/  229] train: loss: 0.1427695
[Epoch 96; Iter    55/  229] train: loss: 0.1311467
[Epoch 96; Iter    85/  229] train: loss: 0.1092349
[Epoch 96; Iter   115/  229] train: loss: 0.1135286
[Epoch 96; Iter   145/  229] train: loss: 0.1036319
[Epoch 96; Iter   175/  229] train: loss: 0.1525964
[Epoch 96; Iter   205/  229] train: loss: 0.1238110
[Epoch 96] ogbg-moltoxcast: 0.739788 val loss: 0.201420
[Epoch 96] ogbg-moltoxcast: 0.755616 test loss: 0.215960
[Epoch 97; Iter     6/  229] train: loss: 0.1328543
[Epoch 97; Iter    36/  229] train: loss: 0.1113567
[Epoch 97; Iter    66/  229] train: loss: 0.1023015
[Epoch 97; Iter    96/  229] train: loss: 0.1388155
[Epoch 97; Iter   126/  229] train: loss: 0.1423243
[Epoch 97; Iter   156/  229] train: loss: 0.1574129
[Epoch 97; Iter   186/  229] train: loss: 0.1134993
[Epoch 97; Iter   216/  229] train: loss: 0.0800484
[Epoch 97] ogbg-moltoxcast: 0.743560 val loss: 0.201240
[Epoch 97] ogbg-moltoxcast: 0.753964 test loss: 0.216809
[Epoch 98; Iter    17/  229] train: loss: 0.1545958
[Epoch 98; Iter    47/  229] train: loss: 0.1610023
[Epoch 98; Iter    77/  229] train: loss: 0.1649942
[Epoch 98; Iter   107/  229] train: loss: 0.0915951
[Epoch 98; Iter   137/  229] train: loss: 0.1883039
[Epoch 98; Iter   167/  229] train: loss: 0.1174587
[Epoch 98; Iter   197/  229] train: loss: 0.1754426
[Epoch 98; Iter   227/  229] train: loss: 0.1467627
[Epoch 98] ogbg-moltoxcast: 0.743900 val loss: 0.201740
[Epoch 98] ogbg-moltoxcast: 0.755746 test loss: 0.217818
[Epoch 99; Iter    28/  229] train: loss: 0.2049052
[Epoch 99; Iter    58/  229] train: loss: 0.1242835
[Epoch 99; Iter    88/  229] train: loss: 0.1365146
[Epoch 99; Iter   118/  229] train: loss: 0.1638097
[Epoch 99; Iter   148/  229] train: loss: 0.1331588
[Epoch 99; Iter   178/  229] train: loss: 0.1458438
[Epoch 99; Iter   208/  229] train: loss: 0.1656183
[Epoch 99] ogbg-moltoxcast: 0.741638 val loss: 0.202521
[Epoch 99] ogbg-moltoxcast: 0.756098 test loss: 0.218338
[Epoch 100; Iter     9/  229] train: loss: 0.1335573
[Epoch 100; Iter    39/  229] train: loss: 0.1265056
[Epoch 100; Iter    69/  229] train: loss: 0.1690498
[Epoch 100; Iter    99/  229] train: loss: 0.0993258
[Epoch 100; Iter   129/  229] train: loss: 0.1484937
[Epoch 100; Iter   159/  229] train: loss: 0.1338895
[Epoch 100; Iter   189/  229] train: loss: 0.2035298
[Epoch 100; Iter   219/  229] train: loss: 0.1051630
[Epoch 100] ogbg-moltoxcast: 0.742165 val loss: 0.202188
[Epoch 100] ogbg-moltoxcast: 0.754137 test loss: 0.216908
[Epoch 101; Iter    20/  229] train: loss: 0.1508378
[Epoch 101; Iter    50/  229] train: loss: 0.0778436
[Epoch 101; Iter    80/  229] train: loss: 0.1586414
[Epoch 101; Iter   110/  229] train: loss: 0.1422307
[Epoch 101; Iter   140/  229] train: loss: 0.1424506
[Epoch 101; Iter   170/  229] train: loss: 0.1189484
[Epoch 101; Iter   200/  229] train: loss: 0.2108910
[Epoch 101] ogbg-moltoxcast: 0.741979 val loss: 0.202517
[Epoch 101] ogbg-moltoxcast: 0.755690 test loss: 0.214473
[Epoch 102; Iter     1/  229] train: loss: 0.0952126
[Epoch 102; Iter    31/  229] train: loss: 0.1360177
[Epoch 102; Iter    61/  229] train: loss: 0.2092837
[Epoch 102; Iter    91/  229] train: loss: 0.1295769
[Epoch 102; Iter   121/  229] train: loss: 0.1121666
[Epoch 102; Iter   151/  229] train: loss: 0.0906974
[Epoch 102; Iter   181/  229] train: loss: 0.0734448
[Epoch 102; Iter   211/  229] train: loss: 0.1228558
[Epoch 102] ogbg-moltoxcast: 0.740420 val loss: 0.205648
[Epoch 102] ogbg-moltoxcast: 0.756402 test loss: 0.221249
[Epoch 103; Iter    12/  229] train: loss: 0.1304146
[Epoch 103; Iter    42/  229] train: loss: 0.1483855
[Epoch 103; Iter    72/  229] train: loss: 0.1622327
[Epoch 103; Iter   102/  229] train: loss: 0.1471278
[Epoch 103; Iter   132/  229] train: loss: 0.1537781
[Epoch 103; Iter   162/  229] train: loss: 0.1234647
[Epoch 103; Iter   192/  229] train: loss: 0.1566072
[Epoch 103; Iter   222/  229] train: loss: 0.1106262
[Epoch 103] ogbg-moltoxcast: 0.741750 val loss: 0.204604
[Epoch 103] ogbg-moltoxcast: 0.754116 test loss: 0.220207
[Epoch 104; Iter    23/  229] train: loss: 0.1361454
[Epoch 104; Iter    53/  229] train: loss: 0.1379375
[Epoch 104; Iter    83/  229] train: loss: 0.1392826
[Epoch 104; Iter   113/  229] train: loss: 0.1202800
[Epoch 104; Iter   143/  229] train: loss: 0.1295816
[Epoch 104; Iter   173/  229] train: loss: 0.1351470
[Epoch 104; Iter   203/  229] train: loss: 0.1056785
[Epoch 104] ogbg-moltoxcast: 0.745248 val loss: 0.202495
[Epoch 104] ogbg-moltoxcast: 0.757193 test loss: 0.218650
[Epoch 105; Iter     4/  229] train: loss: 0.1523291
[Epoch 105; Iter    34/  229] train: loss: 0.1651142
[Epoch 105; Iter    64/  229] train: loss: 0.1354703
[Epoch 105; Iter    94/  229] train: loss: 0.1081752
[Epoch 105; Iter   124/  229] train: loss: 0.1420906
[Epoch 105; Iter   154/  229] train: loss: 0.1580559
[Epoch 105; Iter   184/  229] train: loss: 0.1659596
[Epoch 105; Iter   214/  229] train: loss: 0.1792725
[Epoch 105] ogbg-moltoxcast: 0.741811 val loss: 0.203938
[Epoch 105] ogbg-moltoxcast: 0.758835 test loss: 0.218290
[Epoch 106; Iter    15/  229] train: loss: 0.0983736
[Epoch 106; Iter    45/  229] train: loss: 0.1628636
[Epoch 106; Iter    75/  229] train: loss: 0.1858187
[Epoch 106; Iter   105/  229] train: loss: 0.1530298
[Epoch 106; Iter   135/  229] train: loss: 0.1759177
[Epoch 106; Iter   165/  229] train: loss: 0.1435508
[Epoch 106; Iter   195/  229] train: loss: 0.1328370
[Epoch 106; Iter   225/  229] train: loss: 0.1242730
[Epoch 106] ogbg-moltoxcast: 0.743211 val loss: 0.202094
[Epoch 106] ogbg-moltoxcast: 0.754552 test loss: 0.218821
[Epoch 107; Iter    26/  229] train: loss: 0.1395176
[Epoch 107; Iter    56/  229] train: loss: 0.1274618
[Epoch 107; Iter    86/  229] train: loss: 0.1072999
[Epoch 107; Iter   116/  229] train: loss: 0.1419010
[Epoch 107; Iter   146/  229] train: loss: 0.1375584
[Epoch 107; Iter   176/  229] train: loss: 0.0935772
[Epoch 107; Iter   206/  229] train: loss: 0.1599733
[Epoch 107] ogbg-moltoxcast: 0.741377 val loss: 0.204795
[Epoch 94; Iter   114/  172] train: loss: 0.1214060
[Epoch 94; Iter   144/  172] train: loss: 0.1532995
[Epoch 94] ogbg-moltoxcast: 0.729159 val loss: 0.215062
[Epoch 94] ogbg-moltoxcast: 0.741419 test loss: 0.215786
[Epoch 95; Iter     2/  172] train: loss: 0.1329550
[Epoch 95; Iter    32/  172] train: loss: 0.0861678
[Epoch 95; Iter    62/  172] train: loss: 0.1026912
[Epoch 95; Iter    92/  172] train: loss: 0.1177131
[Epoch 95; Iter   122/  172] train: loss: 0.1558153
[Epoch 95; Iter   152/  172] train: loss: 0.1708979
[Epoch 95] ogbg-moltoxcast: 0.727174 val loss: 0.214597
[Epoch 95] ogbg-moltoxcast: 0.740808 test loss: 0.215511
[Epoch 96; Iter    10/  172] train: loss: 0.0798293
[Epoch 96; Iter    40/  172] train: loss: 0.1162448
[Epoch 96; Iter    70/  172] train: loss: 0.1474002
[Epoch 96; Iter   100/  172] train: loss: 0.1289802
[Epoch 96; Iter   130/  172] train: loss: 0.1211025
[Epoch 96; Iter   160/  172] train: loss: 0.1400782
[Epoch 96] ogbg-moltoxcast: 0.728747 val loss: 0.213095
[Epoch 96] ogbg-moltoxcast: 0.737939 test loss: 0.216107
[Epoch 97; Iter    18/  172] train: loss: 0.1155391
[Epoch 97; Iter    48/  172] train: loss: 0.1017062
[Epoch 97; Iter    78/  172] train: loss: 0.1713651
[Epoch 97; Iter   108/  172] train: loss: 0.1172175
[Epoch 97; Iter   138/  172] train: loss: 0.1552967
[Epoch 97; Iter   168/  172] train: loss: 0.1068144
[Epoch 97] ogbg-moltoxcast: 0.726538 val loss: 0.216097
[Epoch 97] ogbg-moltoxcast: 0.741320 test loss: 0.215177
[Epoch 98; Iter    26/  172] train: loss: 0.1213707
[Epoch 98; Iter    56/  172] train: loss: 0.1095059
[Epoch 98; Iter    86/  172] train: loss: 0.1579484
[Epoch 98; Iter   116/  172] train: loss: 0.0766621
[Epoch 98; Iter   146/  172] train: loss: 0.1240445
[Epoch 98] ogbg-moltoxcast: 0.726796 val loss: 0.213467
[Epoch 98] ogbg-moltoxcast: 0.738776 test loss: 0.216286
[Epoch 99; Iter     4/  172] train: loss: 0.1187714
[Epoch 99; Iter    34/  172] train: loss: 0.1279939
[Epoch 99; Iter    64/  172] train: loss: 0.1452214
[Epoch 99; Iter    94/  172] train: loss: 0.1113472
[Epoch 99; Iter   124/  172] train: loss: 0.1134611
[Epoch 99; Iter   154/  172] train: loss: 0.1033687
[Epoch 99] ogbg-moltoxcast: 0.729340 val loss: 0.214402
[Epoch 99] ogbg-moltoxcast: 0.738920 test loss: 0.216711
[Epoch 100; Iter    12/  172] train: loss: 0.0872204
[Epoch 100; Iter    42/  172] train: loss: 0.1362095
[Epoch 100; Iter    72/  172] train: loss: 0.1098338
[Epoch 100; Iter   102/  172] train: loss: 0.0859135
[Epoch 100; Iter   132/  172] train: loss: 0.1258534
[Epoch 100; Iter   162/  172] train: loss: 0.1315297
[Epoch 100] ogbg-moltoxcast: 0.729494 val loss: 0.216516
[Epoch 100] ogbg-moltoxcast: 0.740431 test loss: 0.217971
[Epoch 101; Iter    20/  172] train: loss: 0.1681277
[Epoch 101; Iter    50/  172] train: loss: 0.1112317
[Epoch 101; Iter    80/  172] train: loss: 0.1727794
[Epoch 101; Iter   110/  172] train: loss: 0.1165489
[Epoch 101; Iter   140/  172] train: loss: 0.1365305
[Epoch 101; Iter   170/  172] train: loss: 0.1811153
[Epoch 101] ogbg-moltoxcast: 0.726586 val loss: 0.215391
[Epoch 101] ogbg-moltoxcast: 0.740323 test loss: 0.215812
[Epoch 102; Iter    28/  172] train: loss: 0.1339206
[Epoch 102; Iter    58/  172] train: loss: 0.1424001
[Epoch 102; Iter    88/  172] train: loss: 0.1194082
[Epoch 102; Iter   118/  172] train: loss: 0.1448167
[Epoch 102; Iter   148/  172] train: loss: 0.1402021
[Epoch 102] ogbg-moltoxcast: 0.725828 val loss: 0.214496
[Epoch 102] ogbg-moltoxcast: 0.738260 test loss: 0.217086
[Epoch 103; Iter     6/  172] train: loss: 0.1314267
[Epoch 103; Iter    36/  172] train: loss: 0.1350588
[Epoch 103; Iter    66/  172] train: loss: 0.0935601
[Epoch 103; Iter    96/  172] train: loss: 0.1365539
[Epoch 103; Iter   126/  172] train: loss: 0.1350005
[Epoch 103; Iter   156/  172] train: loss: 0.1035965
[Epoch 103] ogbg-moltoxcast: 0.726046 val loss: 0.216343
[Epoch 103] ogbg-moltoxcast: 0.739281 test loss: 0.217488
[Epoch 104; Iter    14/  172] train: loss: 0.1104303
[Epoch 104; Iter    44/  172] train: loss: 0.1150695
[Epoch 104; Iter    74/  172] train: loss: 0.1499457
[Epoch 104; Iter   104/  172] train: loss: 0.1371797
[Epoch 104; Iter   134/  172] train: loss: 0.1677437
[Epoch 104; Iter   164/  172] train: loss: 0.0943424
[Epoch 104] ogbg-moltoxcast: 0.728240 val loss: 0.216113
[Epoch 104] ogbg-moltoxcast: 0.739992 test loss: 0.217528
[Epoch 105; Iter    22/  172] train: loss: 0.1924654
[Epoch 105; Iter    52/  172] train: loss: 0.1311631
[Epoch 105; Iter    82/  172] train: loss: 0.1628376
[Epoch 105; Iter   112/  172] train: loss: 0.1325621
[Epoch 105; Iter   142/  172] train: loss: 0.1597850
[Epoch 105; Iter   172/  172] train: loss: 0.0992761
[Epoch 105] ogbg-moltoxcast: 0.727383 val loss: 0.217532
[Epoch 105] ogbg-moltoxcast: 0.738292 test loss: 0.218890
[Epoch 106; Iter    30/  172] train: loss: 0.1113741
[Epoch 106; Iter    60/  172] train: loss: 0.1429107
[Epoch 106; Iter    90/  172] train: loss: 0.1176139
[Epoch 106; Iter   120/  172] train: loss: 0.1341823
[Epoch 106; Iter   150/  172] train: loss: 0.1041647
[Epoch 106] ogbg-moltoxcast: 0.729335 val loss: 0.217127
[Epoch 106] ogbg-moltoxcast: 0.739173 test loss: 0.219068
[Epoch 107; Iter     8/  172] train: loss: 0.1680303
[Epoch 107; Iter    38/  172] train: loss: 0.1604828
[Epoch 107; Iter    68/  172] train: loss: 0.1034378
[Epoch 107; Iter    98/  172] train: loss: 0.1277622
[Epoch 107; Iter   128/  172] train: loss: 0.1150579
[Epoch 107; Iter   158/  172] train: loss: 0.1058851
[Epoch 107] ogbg-moltoxcast: 0.727526 val loss: 0.216852
[Epoch 107] ogbg-moltoxcast: 0.735996 test loss: 0.220221
[Epoch 108; Iter    16/  172] train: loss: 0.1324485
[Epoch 108; Iter    46/  172] train: loss: 0.1361718
[Epoch 108; Iter    76/  172] train: loss: 0.1203884
[Epoch 108; Iter   106/  172] train: loss: 0.1419699
[Epoch 108; Iter   136/  172] train: loss: 0.1327155
[Epoch 108; Iter   166/  172] train: loss: 0.1644066
[Epoch 108] ogbg-moltoxcast: 0.724908 val loss: 0.217541
[Epoch 108] ogbg-moltoxcast: 0.736200 test loss: 0.219268
[Epoch 109; Iter    24/  172] train: loss: 0.1747616
[Epoch 109; Iter    54/  172] train: loss: 0.0946100
[Epoch 109; Iter    84/  172] train: loss: 0.1050278
[Epoch 109; Iter   114/  172] train: loss: 0.1533789
[Epoch 109; Iter   144/  172] train: loss: 0.1034343
[Epoch 109] ogbg-moltoxcast: 0.724676 val loss: 0.217258
[Epoch 109] ogbg-moltoxcast: 0.738401 test loss: 0.217666
[Epoch 110; Iter     2/  172] train: loss: 0.1256014
[Epoch 110; Iter    32/  172] train: loss: 0.1858353
[Epoch 110; Iter    62/  172] train: loss: 0.1151349
[Epoch 110; Iter    92/  172] train: loss: 0.1572407
[Epoch 110; Iter   122/  172] train: loss: 0.1592512
[Epoch 110; Iter   152/  172] train: loss: 0.1653211
[Epoch 110] ogbg-moltoxcast: 0.726330 val loss: 0.216861
[Epoch 110] ogbg-moltoxcast: 0.736552 test loss: 0.219959
[Epoch 111; Iter    10/  172] train: loss: 0.1240354
[Epoch 111; Iter    40/  172] train: loss: 0.1616761
[Epoch 111; Iter    70/  172] train: loss: 0.1281411
[Epoch 111; Iter   100/  172] train: loss: 0.1080695
[Epoch 111; Iter   130/  172] train: loss: 0.1120005
[Epoch 111; Iter   160/  172] train: loss: 0.1298041
[Epoch 111] ogbg-moltoxcast: 0.726111 val loss: 0.216897
[Epoch 111] ogbg-moltoxcast: 0.737435 test loss: 0.219205
[Epoch 112; Iter    18/  172] train: loss: 0.1538480
[Epoch 112; Iter    48/  172] train: loss: 0.1196672
[Epoch 112; Iter    78/  172] train: loss: 0.1631588
[Epoch 112; Iter   108/  172] train: loss: 0.1109867
[Epoch 112; Iter   138/  172] train: loss: 0.1201040
[Epoch 112; Iter   168/  172] train: loss: 0.1219160
[Epoch 112] ogbg-moltoxcast: 0.723949 val loss: 0.219055
[Epoch 112] ogbg-moltoxcast: 0.737597 test loss: 0.219445
[Epoch 113; Iter    26/  172] train: loss: 0.1171332
[Epoch 113; Iter    56/  172] train: loss: 0.1119353
[Epoch 113; Iter    86/  172] train: loss: 0.1148590
[Epoch 113; Iter   116/  172] train: loss: 0.1274666
[Epoch 113; Iter   146/  172] train: loss: 0.1443038
[Epoch 113] ogbg-moltoxcast: 0.727376 val loss: 0.218961
[Epoch 113] ogbg-moltoxcast: 0.740159 test loss: 0.220414
[Epoch 114; Iter     4/  172] train: loss: 0.0940279/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)

[Epoch 114; Iter    34/  172] train: loss: 0.1426089
[Epoch 114; Iter    64/  172] train: loss: 0.1653195
[Epoch 114; Iter    94/  172] train: loss: 0.1342998
[Epoch 114; Iter   124/  172] train: loss: 0.1151914
[Epoch 114; Iter   154/  172] train: loss: 0.1280890
[Epoch 114] ogbg-moltoxcast: 0.719748 val loss: 0.224154
[Epoch 114] ogbg-moltoxcast: 0.739797 test loss: 0.219611
[Epoch 115; Iter    12/  172] train: loss: 0.0879011
[Epoch 115; Iter    42/  172] train: loss: 0.1256014
[Epoch 115; Iter    72/  172] train: loss: 0.1402757
[Epoch 115; Iter   102/  172] train: loss: 0.1464751
[Epoch 115; Iter   132/  172] train: loss: 0.1668841
[Epoch 115; Iter   162/  172] train: loss: 0.1329270
[Epoch 115] ogbg-moltoxcast: 0.719224 val loss: 0.224052
[Epoch 115] ogbg-moltoxcast: 0.737257 test loss: 0.220244
[Epoch 116; Iter    20/  172] train: loss: 0.1378490
[Epoch 116; Iter    50/  172] train: loss: 0.1405502
[Epoch 116; Iter    80/  172] train: loss: 0.1267067
[Epoch 116; Iter   110/  172] train: loss: 0.1503936
[Epoch 116; Iter   140/  172] train: loss: 0.1403943
[Epoch 116; Iter   170/  172] train: loss: 0.1123660
[Epoch 116] ogbg-moltoxcast: 0.718851 val loss: 0.223069
[Epoch 116] ogbg-moltoxcast: 0.739647 test loss: 0.218319
[Epoch 117; Iter    28/  172] train: loss: 0.0923902
[Epoch 117; Iter    58/  172] train: loss: 0.1006887
[Epoch 117; Iter    88/  172] train: loss: 0.1082869
[Epoch 117; Iter   118/  172] train: loss: 0.1396085
[Epoch 117; Iter   148/  172] train: loss: 0.1065501
[Epoch 117] ogbg-moltoxcast: 0.719818 val loss: 0.224600
[Epoch 117] ogbg-moltoxcast: 0.741078 test loss: 0.218963
[Epoch 118; Iter     6/  172] train: loss: 0.1528291
[Epoch 118; Iter    36/  172] train: loss: 0.1388798
[Epoch 118; Iter    66/  172] train: loss: 0.1613327
[Epoch 118; Iter    96/  172] train: loss: 0.1289720
[Epoch 118; Iter   126/  172] train: loss: 0.1289576
[Epoch 118; Iter   156/  172] train: loss: 0.1214501
[Epoch 118] ogbg-moltoxcast: 0.719801 val loss: 0.223925
[Epoch 118] ogbg-moltoxcast: 0.740110 test loss: 0.219197
[Epoch 119; Iter    14/  172] train: loss: 0.0923232
[Epoch 119; Iter    44/  172] train: loss: 0.0879049
[Epoch 119; Iter    74/  172] train: loss: 0.1230888
[Epoch 119; Iter   104/  172] train: loss: 0.0805907
[Epoch 119; Iter   134/  172] train: loss: 0.1444726
[Epoch 119; Iter   164/  172] train: loss: 0.1125934
[Epoch 119] ogbg-moltoxcast: 0.720496 val loss: 0.223483
[Epoch 119] ogbg-moltoxcast: 0.740539 test loss: 0.218539
[Epoch 120; Iter    22/  172] train: loss: 0.1511012
[Epoch 120; Iter    52/  172] train: loss: 0.1338994
[Epoch 120; Iter    82/  172] train: loss: 0.0818260
[Epoch 120; Iter   112/  172] train: loss: 0.1652712
[Epoch 120; Iter   142/  172] train: loss: 0.0892386
[Epoch 120; Iter   172/  172] train: loss: 0.1111488
[Epoch 120] ogbg-moltoxcast: 0.719445 val loss: 0.224765
[Epoch 120] ogbg-moltoxcast: 0.740046 test loss: 0.219615
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 34.
Statistics on  val_best_checkpoint
mean_pred: -3.011492967605591
std_pred: 2.413403034210205
mean_targets: nan
std_targets: nan
prcauc: 0.38719965165987635
rocauc: 0.7291603640056438
ogbg-moltoxcast: 0.7291603640056438
OGBNanLabelBCEWithLogitsLoss: 0.21747939667568125
Statistics on  test
mean_pred: -2.997440814971924
std_pred: 2.358043909072876
mean_targets: nan
std_targets: nan
prcauc: 0.38731241526836
rocauc: 0.7386183546684145
ogbg-moltoxcast: 0.7386183546684145
OGBNanLabelBCEWithLogitsLoss: 0.20342366692834887
Statistics on  train
mean_pred: -3.030646800994873
std_pred: 2.3911221027374268
mean_targets: nan
std_targets: nan
prcauc: 0.5157963830169076
rocauc: 0.851628879818694
ogbg-moltoxcast: 0.851628879818694
OGBNanLabelBCEWithLogitsLoss: 0.162576527702947
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101] ogbg-moltoxcast: 0.735252 val loss: 0.214041
[Epoch 101] ogbg-moltoxcast: 0.746884 test loss: 0.218373
[Epoch 102; Iter     9/  201] train: loss: 0.1359813
[Epoch 102; Iter    39/  201] train: loss: 0.1571466
[Epoch 102; Iter    69/  201] train: loss: 0.1119162
[Epoch 102; Iter    99/  201] train: loss: 0.1148016
[Epoch 102; Iter   129/  201] train: loss: 0.1971378
[Epoch 102; Iter   159/  201] train: loss: 0.1505164
[Epoch 102; Iter   189/  201] train: loss: 0.1456690
[Epoch 102] ogbg-moltoxcast: 0.735744 val loss: 0.217584
[Epoch 102] ogbg-moltoxcast: 0.746716 test loss: 0.222737
[Epoch 103; Iter    18/  201] train: loss: 0.1394100
[Epoch 103; Iter    48/  201] train: loss: 0.1490235
[Epoch 103; Iter    78/  201] train: loss: 0.1603028
[Epoch 103; Iter   108/  201] train: loss: 0.1771519
[Epoch 103; Iter   138/  201] train: loss: 0.1120539
[Epoch 103; Iter   168/  201] train: loss: 0.1331217
[Epoch 103; Iter   198/  201] train: loss: 0.1912884
[Epoch 103] ogbg-moltoxcast: 0.734357 val loss: 0.216219
[Epoch 103] ogbg-moltoxcast: 0.745233 test loss: 0.219737
[Epoch 104; Iter    27/  201] train: loss: 0.1524315
[Epoch 104; Iter    57/  201] train: loss: 0.1080011
[Epoch 104; Iter    87/  201] train: loss: 0.1035284
[Epoch 104; Iter   117/  201] train: loss: 0.1028096
[Epoch 104; Iter   147/  201] train: loss: 0.1079941
[Epoch 104; Iter   177/  201] train: loss: 0.1228344
[Epoch 104] ogbg-moltoxcast: 0.737688 val loss: 0.215518
[Epoch 104] ogbg-moltoxcast: 0.747359 test loss: 0.221422
[Epoch 105; Iter     6/  201] train: loss: 0.1524021
[Epoch 105; Iter    36/  201] train: loss: 0.1626178
[Epoch 105; Iter    66/  201] train: loss: 0.1324363
[Epoch 105; Iter    96/  201] train: loss: 0.1420760
[Epoch 105; Iter   126/  201] train: loss: 0.1472105
[Epoch 105; Iter   156/  201] train: loss: 0.2007419
[Epoch 105; Iter   186/  201] train: loss: 0.1668091
[Epoch 105] ogbg-moltoxcast: 0.738138 val loss: 0.220661
[Epoch 105] ogbg-moltoxcast: 0.752107 test loss: 0.224237
[Epoch 106; Iter    15/  201] train: loss: 0.1259414
[Epoch 106; Iter    45/  201] train: loss: 0.1238830
[Epoch 106; Iter    75/  201] train: loss: 0.1254718
[Epoch 106; Iter   105/  201] train: loss: 0.1382038
[Epoch 106; Iter   135/  201] train: loss: 0.1044031
[Epoch 106; Iter   165/  201] train: loss: 0.1230951
[Epoch 106; Iter   195/  201] train: loss: 0.1157321
[Epoch 106] ogbg-moltoxcast: 0.736890 val loss: 0.218309
[Epoch 106] ogbg-moltoxcast: 0.747077 test loss: 0.222893
[Epoch 107; Iter    24/  201] train: loss: 0.1068897
[Epoch 107; Iter    54/  201] train: loss: 0.1497727
[Epoch 107; Iter    84/  201] train: loss: 0.0936327
[Epoch 107; Iter   114/  201] train: loss: 0.1297878
[Epoch 107; Iter   144/  201] train: loss: 0.0931246
[Epoch 107; Iter   174/  201] train: loss: 0.1559465
[Epoch 107] ogbg-moltoxcast: 0.737393 val loss: 0.216670
[Epoch 107] ogbg-moltoxcast: 0.746941 test loss: 0.218856
[Epoch 108; Iter     3/  201] train: loss: 0.1319079
[Epoch 108; Iter    33/  201] train: loss: 0.1285395
[Epoch 108; Iter    63/  201] train: loss: 0.1177448
[Epoch 108; Iter    93/  201] train: loss: 0.1841019
[Epoch 108; Iter   123/  201] train: loss: 0.0943499
[Epoch 108; Iter   153/  201] train: loss: 0.1473494
[Epoch 108; Iter   183/  201] train: loss: 0.1247054
[Epoch 108] ogbg-moltoxcast: 0.738797 val loss: 0.220050
[Epoch 108] ogbg-moltoxcast: 0.746587 test loss: 0.225703
[Epoch 109; Iter    12/  201] train: loss: 0.1246063
[Epoch 109; Iter    42/  201] train: loss: 0.0963721
[Epoch 109; Iter    72/  201] train: loss: 0.1142582
[Epoch 109; Iter   102/  201] train: loss: 0.1505233
[Epoch 109; Iter   132/  201] train: loss: 0.1158628
[Epoch 109; Iter   162/  201] train: loss: 0.1181666
[Epoch 109; Iter   192/  201] train: loss: 0.0855368
[Epoch 109] ogbg-moltoxcast: 0.738529 val loss: 0.217373
[Epoch 109] ogbg-moltoxcast: 0.747348 test loss: 0.222958
[Epoch 110; Iter    21/  201] train: loss: 0.2032604
[Epoch 110; Iter    51/  201] train: loss: 0.1172959
[Epoch 110; Iter    81/  201] train: loss: 0.1108577
[Epoch 110; Iter   111/  201] train: loss: 0.1604023
[Epoch 110; Iter   141/  201] train: loss: 0.0978727
[Epoch 110; Iter   171/  201] train: loss: 0.1240398
[Epoch 110; Iter   201/  201] train: loss: 0.3189256
[Epoch 110] ogbg-moltoxcast: 0.735333 val loss: 0.217778
[Epoch 110] ogbg-moltoxcast: 0.746440 test loss: 0.221764
[Epoch 111; Iter    30/  201] train: loss: 0.1367496
[Epoch 111; Iter    60/  201] train: loss: 0.1017760
[Epoch 111; Iter    90/  201] train: loss: 0.1177592
[Epoch 111; Iter   120/  201] train: loss: 0.0989821
[Epoch 111; Iter   150/  201] train: loss: 0.1327852
[Epoch 111; Iter   180/  201] train: loss: 0.1038965
[Epoch 111] ogbg-moltoxcast: 0.739654 val loss: 0.217638
[Epoch 111] ogbg-moltoxcast: 0.749065 test loss: 0.223335
[Epoch 112; Iter     9/  201] train: loss: 0.1571538
[Epoch 112; Iter    39/  201] train: loss: 0.1012802
[Epoch 112; Iter    69/  201] train: loss: 0.1271851
[Epoch 112; Iter    99/  201] train: loss: 0.1309713
[Epoch 112; Iter   129/  201] train: loss: 0.1140286
[Epoch 112; Iter   159/  201] train: loss: 0.1461027
[Epoch 112; Iter   189/  201] train: loss: 0.1220506
[Epoch 112] ogbg-moltoxcast: 0.738462 val loss: 0.217435
[Epoch 112] ogbg-moltoxcast: 0.743155 test loss: 0.223084
[Epoch 113; Iter    18/  201] train: loss: 0.1491650
[Epoch 113; Iter    48/  201] train: loss: 0.1472834
[Epoch 113; Iter    78/  201] train: loss: 0.1490039
[Epoch 113; Iter   108/  201] train: loss: 0.1055531
[Epoch 113; Iter   138/  201] train: loss: 0.1454866
[Epoch 113; Iter   168/  201] train: loss: 0.1523025
[Epoch 113; Iter   198/  201] train: loss: 0.1252041
[Epoch 113] ogbg-moltoxcast: 0.736368 val loss: 0.220450
[Epoch 113] ogbg-moltoxcast: 0.745829 test loss: 0.225109
[Epoch 114; Iter    27/  201] train: loss: 0.1935630
[Epoch 114; Iter    57/  201] train: loss: 0.1665739
[Epoch 114; Iter    87/  201] train: loss: 0.1089817
[Epoch 114; Iter   117/  201] train: loss: 0.0903362
[Epoch 114; Iter   147/  201] train: loss: 0.1203922
[Epoch 114; Iter   177/  201] train: loss: 0.0940425
[Epoch 114] ogbg-moltoxcast: 0.736941 val loss: 0.217128
[Epoch 114] ogbg-moltoxcast: 0.745768 test loss: 0.221683
[Epoch 115; Iter     6/  201] train: loss: 0.1374017
[Epoch 115; Iter    36/  201] train: loss: 0.1257961
[Epoch 115; Iter    66/  201] train: loss: 0.1555119
[Epoch 115; Iter    96/  201] train: loss: 0.1030666
[Epoch 115; Iter   126/  201] train: loss: 0.0988379
[Epoch 115; Iter   156/  201] train: loss: 0.1587005
[Epoch 115; Iter   186/  201] train: loss: 0.0809147
[Epoch 115] ogbg-moltoxcast: 0.736076 val loss: 0.220814
[Epoch 115] ogbg-moltoxcast: 0.744517 test loss: 0.227812
[Epoch 116; Iter    15/  201] train: loss: 0.1520937
[Epoch 116; Iter    45/  201] train: loss: 0.1250261
[Epoch 116; Iter    75/  201] train: loss: 0.1264208
[Epoch 116; Iter   105/  201] train: loss: 0.1676656
[Epoch 116; Iter   135/  201] train: loss: 0.1138884
[Epoch 116; Iter   165/  201] train: loss: 0.0828070
[Epoch 116; Iter   195/  201] train: loss: 0.1776015
[Epoch 116] ogbg-moltoxcast: 0.736348 val loss: 0.217694
[Epoch 116] ogbg-moltoxcast: 0.743901 test loss: 0.223405
[Epoch 117; Iter    24/  201] train: loss: 0.1479513
[Epoch 117; Iter    54/  201] train: loss: 0.1262388
[Epoch 117; Iter    84/  201] train: loss: 0.1425192
[Epoch 117; Iter   114/  201] train: loss: 0.1795891
[Epoch 117; Iter   144/  201] train: loss: 0.1312826
[Epoch 117; Iter   174/  201] train: loss: 0.0961889
[Epoch 117] ogbg-moltoxcast: 0.737791 val loss: 0.217281
[Epoch 117] ogbg-moltoxcast: 0.745581 test loss: 0.222266
[Epoch 118; Iter     3/  201] train: loss: 0.1689245
[Epoch 118; Iter    33/  201] train: loss: 0.1519816
[Epoch 118; Iter    63/  201] train: loss: 0.1162667
[Epoch 118; Iter    93/  201] train: loss: 0.1567882
[Epoch 118; Iter   123/  201] train: loss: 0.1678673
[Epoch 118; Iter   153/  201] train: loss: 0.1111828
[Epoch 118; Iter   183/  201] train: loss: 0.1647734
[Epoch 118] ogbg-moltoxcast: 0.736715 val loss: 0.218228
[Epoch 118] ogbg-moltoxcast: 0.745830 test loss: 0.221748
[Epoch 119; Iter    12/  201] train: loss: 0.1283038

[Epoch 114; Iter    34/  172] train: loss: 0.1067171
[Epoch 114; Iter    64/  172] train: loss: 0.1313710
[Epoch 114; Iter    94/  172] train: loss: 0.1315624
[Epoch 114; Iter   124/  172] train: loss: 0.1274973
[Epoch 114; Iter   154/  172] train: loss: 0.1217274
[Epoch 114] ogbg-moltoxcast: 0.718772 val loss: 0.239726
[Epoch 114] ogbg-moltoxcast: 0.731805 test loss: 0.220337
[Epoch 115; Iter    12/  172] train: loss: 0.1533500
[Epoch 115; Iter    42/  172] train: loss: 0.0902547
[Epoch 115; Iter    72/  172] train: loss: 0.1180646
[Epoch 115; Iter   102/  172] train: loss: 0.1358231
[Epoch 115; Iter   132/  172] train: loss: 0.1055359
[Epoch 115; Iter   162/  172] train: loss: 0.1332964
[Epoch 115] ogbg-moltoxcast: 0.716555 val loss: 0.223708
[Epoch 115] ogbg-moltoxcast: 0.729988 test loss: 0.221566
[Epoch 116; Iter    20/  172] train: loss: 0.1775128
[Epoch 116; Iter    50/  172] train: loss: 0.1068007
[Epoch 116; Iter    80/  172] train: loss: 0.0882625
[Epoch 116; Iter   110/  172] train: loss: 0.1492371
[Epoch 116; Iter   140/  172] train: loss: 0.1483735
[Epoch 116; Iter   170/  172] train: loss: 0.0931521
[Epoch 116] ogbg-moltoxcast: 0.718220 val loss: 0.237899
[Epoch 116] ogbg-moltoxcast: 0.732382 test loss: 0.219294
[Epoch 117; Iter    28/  172] train: loss: 0.1196019
[Epoch 117; Iter    58/  172] train: loss: 0.1491277
[Epoch 117; Iter    88/  172] train: loss: 0.1149371
[Epoch 117; Iter   118/  172] train: loss: 0.1469045
[Epoch 117; Iter   148/  172] train: loss: 0.1462374
[Epoch 117] ogbg-moltoxcast: 0.721365 val loss: 0.230616
[Epoch 117] ogbg-moltoxcast: 0.732990 test loss: 0.221247
[Epoch 118; Iter     6/  172] train: loss: 0.1325605
[Epoch 118; Iter    36/  172] train: loss: 0.1369364
[Epoch 118; Iter    66/  172] train: loss: 0.1238627
[Epoch 118; Iter    96/  172] train: loss: 0.1121370
[Epoch 118; Iter   126/  172] train: loss: 0.1509147
[Epoch 118; Iter   156/  172] train: loss: 0.1187806
[Epoch 118] ogbg-moltoxcast: 0.723875 val loss: 0.224010
[Epoch 118] ogbg-moltoxcast: 0.734985 test loss: 0.218565
[Epoch 119; Iter    14/  172] train: loss: 0.1507031
[Epoch 119; Iter    44/  172] train: loss: 0.1486971
[Epoch 119; Iter    74/  172] train: loss: 0.1576018
[Epoch 119; Iter   104/  172] train: loss: 0.1689375
[Epoch 119; Iter   134/  172] train: loss: 0.1279666
[Epoch 119; Iter   164/  172] train: loss: 0.1302554
[Epoch 119] ogbg-moltoxcast: 0.721551 val loss: 0.222629
[Epoch 119] ogbg-moltoxcast: 0.732785 test loss: 0.220448
[Epoch 120; Iter    22/  172] train: loss: 0.1258393
[Epoch 120; Iter    52/  172] train: loss: 0.0993215
[Epoch 120; Iter    82/  172] train: loss: 0.0742052
[Epoch 120; Iter   112/  172] train: loss: 0.1123525
[Epoch 120; Iter   142/  172] train: loss: 0.1086646
[Epoch 120; Iter   172/  172] train: loss: 0.0633928
[Epoch 120] ogbg-moltoxcast: 0.719698 val loss: 0.222685
[Epoch 120] ogbg-moltoxcast: 0.732623 test loss: 0.219193
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 50.
Statistics on  val_best_checkpoint
mean_pred: -3.058873176574707
std_pred: 6.484668731689453
mean_targets: nan
std_targets: nan
prcauc: 0.39916127154683406
rocauc: 0.7336744795051819
ogbg-moltoxcast: 0.7336744795051819
OGBNanLabelBCEWithLogitsLoss: 0.2623814693170375
Statistics on  test
mean_pred: -3.1196205615997314
std_pred: 2.4459011554718018
mean_targets: nan
std_targets: nan
prcauc: 0.4003737770384029
rocauc: 0.7366685740941549
ogbg-moltoxcast: 0.7366685740941549
OGBNanLabelBCEWithLogitsLoss: 0.2029951672101843
Statistics on  train
mean_pred: -3.123082160949707
std_pred: 3.303463935852051
mean_targets: nan
std_targets: nan
prcauc: 0.5645450572406753
rocauc: 0.8738289480113016
ogbg-moltoxcast: 0.8738289480113016
OGBNanLabelBCEWithLogitsLoss: 0.15585651495602243
[Epoch 101] ogbg-moltoxcast: 0.731958 val loss: 0.214856
[Epoch 101] ogbg-moltoxcast: 0.750864 test loss: 0.209688
[Epoch 102; Iter     9/  201] train: loss: 0.1115886
[Epoch 102; Iter    39/  201] train: loss: 0.1922551
[Epoch 102; Iter    69/  201] train: loss: 0.1259026
[Epoch 102; Iter    99/  201] train: loss: 0.1137423
[Epoch 102; Iter   129/  201] train: loss: 0.1174167
[Epoch 102; Iter   159/  201] train: loss: 0.1799522
[Epoch 102; Iter   189/  201] train: loss: 0.1215068
[Epoch 102] ogbg-moltoxcast: 0.732778 val loss: 0.215992
[Epoch 102] ogbg-moltoxcast: 0.751335 test loss: 0.210727
[Epoch 103; Iter    18/  201] train: loss: 0.1200699
[Epoch 103; Iter    48/  201] train: loss: 0.1497477
[Epoch 103; Iter    78/  201] train: loss: 0.1512477
[Epoch 103; Iter   108/  201] train: loss: 0.1399570
[Epoch 103; Iter   138/  201] train: loss: 0.1488871
[Epoch 103; Iter   168/  201] train: loss: 0.1102777
[Epoch 103; Iter   198/  201] train: loss: 0.1298871
[Epoch 103] ogbg-moltoxcast: 0.731961 val loss: 0.215661
[Epoch 103] ogbg-moltoxcast: 0.751259 test loss: 0.209859
[Epoch 104; Iter    27/  201] train: loss: 0.1271911
[Epoch 104; Iter    57/  201] train: loss: 0.1117425
[Epoch 104; Iter    87/  201] train: loss: 0.1179063
[Epoch 104; Iter   117/  201] train: loss: 0.1053443
[Epoch 104; Iter   147/  201] train: loss: 0.1281623
[Epoch 104; Iter   177/  201] train: loss: 0.1384707
[Epoch 104] ogbg-moltoxcast: 0.732362 val loss: 0.214589
[Epoch 104] ogbg-moltoxcast: 0.748720 test loss: 0.209011
[Epoch 105; Iter     6/  201] train: loss: 0.1316896
[Epoch 105; Iter    36/  201] train: loss: 0.1532355
[Epoch 105; Iter    66/  201] train: loss: 0.1193039
[Epoch 105; Iter    96/  201] train: loss: 0.0985554
[Epoch 105; Iter   126/  201] train: loss: 0.1295192
[Epoch 105; Iter   156/  201] train: loss: 0.1594571
[Epoch 105; Iter   186/  201] train: loss: 0.1290179
[Epoch 105] ogbg-moltoxcast: 0.729709 val loss: 0.216460
[Epoch 105] ogbg-moltoxcast: 0.747334 test loss: 0.210860
[Epoch 106; Iter    15/  201] train: loss: 0.1290932
[Epoch 106; Iter    45/  201] train: loss: 0.1091503
[Epoch 106; Iter    75/  201] train: loss: 0.1253384
[Epoch 106; Iter   105/  201] train: loss: 0.1747674
[Epoch 106; Iter   135/  201] train: loss: 0.1601525
[Epoch 106; Iter   165/  201] train: loss: 0.1590692
[Epoch 106; Iter   195/  201] train: loss: 0.1455971
[Epoch 106] ogbg-moltoxcast: 0.737134 val loss: 0.215307
[Epoch 106] ogbg-moltoxcast: 0.753461 test loss: 0.209523
[Epoch 107; Iter    24/  201] train: loss: 0.1950744
[Epoch 107; Iter    54/  201] train: loss: 0.1101253
[Epoch 107; Iter    84/  201] train: loss: 0.0994879
[Epoch 107; Iter   114/  201] train: loss: 0.0916210
[Epoch 107; Iter   144/  201] train: loss: 0.1329295
[Epoch 107; Iter   174/  201] train: loss: 0.1086972
[Epoch 107] ogbg-moltoxcast: 0.731387 val loss: 0.216765
[Epoch 107] ogbg-moltoxcast: 0.749975 test loss: 0.211563
[Epoch 108; Iter     3/  201] train: loss: 0.1154503
[Epoch 108; Iter    33/  201] train: loss: 0.1335125
[Epoch 108; Iter    63/  201] train: loss: 0.1162664
[Epoch 108; Iter    93/  201] train: loss: 0.0912841
[Epoch 108; Iter   123/  201] train: loss: 0.1441856
[Epoch 108; Iter   153/  201] train: loss: 0.0870764
[Epoch 108; Iter   183/  201] train: loss: 0.1010056
[Epoch 108] ogbg-moltoxcast: 0.729700 val loss: 0.217573
[Epoch 108] ogbg-moltoxcast: 0.750743 test loss: 0.210444
[Epoch 109; Iter    12/  201] train: loss: 0.1021349
[Epoch 109; Iter    42/  201] train: loss: 0.1929907
[Epoch 109; Iter    72/  201] train: loss: 0.1073482
[Epoch 109; Iter   102/  201] train: loss: 0.1241895
[Epoch 109; Iter   132/  201] train: loss: 0.1633905
[Epoch 109; Iter   162/  201] train: loss: 0.1400010
[Epoch 109; Iter   192/  201] train: loss: 0.1249438
[Epoch 109] ogbg-moltoxcast: 0.729692 val loss: 0.217125
[Epoch 109] ogbg-moltoxcast: 0.749441 test loss: 0.210535
[Epoch 110; Iter    21/  201] train: loss: 0.1535686
[Epoch 110; Iter    51/  201] train: loss: 0.1289376
[Epoch 110; Iter    81/  201] train: loss: 0.1717469
[Epoch 110; Iter   111/  201] train: loss: 0.1337377
[Epoch 110; Iter   141/  201] train: loss: 0.1730640
[Epoch 110; Iter   171/  201] train: loss: 0.1422411
[Epoch 110; Iter   201/  201] train: loss: 0.1813022
[Epoch 110] ogbg-moltoxcast: 0.730869 val loss: 0.215677
[Epoch 110] ogbg-moltoxcast: 0.751144 test loss: 0.210075
[Epoch 111; Iter    30/  201] train: loss: 0.1041658
[Epoch 111; Iter    60/  201] train: loss: 0.1724568
[Epoch 111; Iter    90/  201] train: loss: 0.1058230
[Epoch 111; Iter   120/  201] train: loss: 0.1764209
[Epoch 111; Iter   150/  201] train: loss: 0.1425095
[Epoch 111; Iter   180/  201] train: loss: 0.1012652
[Epoch 111] ogbg-moltoxcast: 0.731188 val loss: 0.214861
[Epoch 111] ogbg-moltoxcast: 0.745531 test loss: 0.210591
[Epoch 112; Iter     9/  201] train: loss: 0.1487054
[Epoch 112; Iter    39/  201] train: loss: 0.1115232
[Epoch 112; Iter    69/  201] train: loss: 0.1072693
[Epoch 112; Iter    99/  201] train: loss: 0.1228409
[Epoch 112; Iter   129/  201] train: loss: 0.1003639
[Epoch 112; Iter   159/  201] train: loss: 0.1590814
[Epoch 112; Iter   189/  201] train: loss: 0.1149609
[Epoch 112] ogbg-moltoxcast: 0.728387 val loss: 0.214689
[Epoch 112] ogbg-moltoxcast: 0.744085 test loss: 0.210322
[Epoch 113; Iter    18/  201] train: loss: 0.1289048
[Epoch 113; Iter    48/  201] train: loss: 0.1135105
[Epoch 113; Iter    78/  201] train: loss: 0.1156454
[Epoch 113; Iter   108/  201] train: loss: 0.1623988
[Epoch 113; Iter   138/  201] train: loss: 0.1793412
[Epoch 113; Iter   168/  201] train: loss: 0.1142262
[Epoch 113; Iter   198/  201] train: loss: 0.1526897
[Epoch 113] ogbg-moltoxcast: 0.729904 val loss: 0.215504
[Epoch 113] ogbg-moltoxcast: 0.748791 test loss: 0.210823
[Epoch 114; Iter    27/  201] train: loss: 0.1332531
[Epoch 114; Iter    57/  201] train: loss: 0.1419376
[Epoch 114; Iter    87/  201] train: loss: 0.1340871
[Epoch 114; Iter   117/  201] train: loss: 0.1385277
[Epoch 114; Iter   147/  201] train: loss: 0.1453720
[Epoch 114; Iter   177/  201] train: loss: 0.1133988
[Epoch 114] ogbg-moltoxcast: 0.732916 val loss: 0.213453
[Epoch 114] ogbg-moltoxcast: 0.750145 test loss: 0.207641
[Epoch 115; Iter     6/  201] train: loss: 0.1621810
[Epoch 115; Iter    36/  201] train: loss: 0.1069766
[Epoch 115; Iter    66/  201] train: loss: 0.2422665
[Epoch 115; Iter    96/  201] train: loss: 0.1135809
[Epoch 115; Iter   126/  201] train: loss: 0.1281335
[Epoch 115; Iter   156/  201] train: loss: 0.0974932
[Epoch 115; Iter   186/  201] train: loss: 0.1538857
[Epoch 115] ogbg-moltoxcast: 0.732925 val loss: 0.214626
[Epoch 115] ogbg-moltoxcast: 0.751068 test loss: 0.208513
[Epoch 116; Iter    15/  201] train: loss: 0.1631314
[Epoch 116; Iter    45/  201] train: loss: 0.0958655
[Epoch 116; Iter    75/  201] train: loss: 0.1560678
[Epoch 116; Iter   105/  201] train: loss: 0.1770714
[Epoch 116; Iter   135/  201] train: loss: 0.1601911
[Epoch 116; Iter   165/  201] train: loss: 0.1392474
[Epoch 116; Iter   195/  201] train: loss: 0.1998703
[Epoch 116] ogbg-moltoxcast: 0.731616 val loss: 0.213627
[Epoch 116] ogbg-moltoxcast: 0.750735 test loss: 0.207548
[Epoch 117; Iter    24/  201] train: loss: 0.1686905
[Epoch 117; Iter    54/  201] train: loss: 0.1673841
[Epoch 117; Iter    84/  201] train: loss: 0.1767129
[Epoch 117; Iter   114/  201] train: loss: 0.1421647
[Epoch 117; Iter   144/  201] train: loss: 0.1353420
[Epoch 117; Iter   174/  201] train: loss: 0.0995445
[Epoch 117] ogbg-moltoxcast: 0.729137 val loss: 0.215048
[Epoch 117] ogbg-moltoxcast: 0.746735 test loss: 0.210291
[Epoch 118; Iter     3/  201] train: loss: 0.1808732
[Epoch 118; Iter    33/  201] train: loss: 0.0871263
[Epoch 118; Iter    63/  201] train: loss: 0.1288606
[Epoch 118; Iter    93/  201] train: loss: 0.1320138
[Epoch 118; Iter   123/  201] train: loss: 0.1506202
[Epoch 118; Iter   153/  201] train: loss: 0.1972014
[Epoch 118; Iter   183/  201] train: loss: 0.2075098
[Epoch 118] ogbg-moltoxcast: 0.733942 val loss: 0.214381
[Epoch 118] ogbg-moltoxcast: 0.749617 test loss: 0.210086
[Epoch 119; Iter    12/  201] train: loss: 0.1675211
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101] ogbg-moltoxcast: 0.734582 val loss: 0.218839
[Epoch 101] ogbg-moltoxcast: 0.743121 test loss: 0.216932
[Epoch 102; Iter     9/  201] train: loss: 0.1546057
[Epoch 102; Iter    39/  201] train: loss: 0.1349745
[Epoch 102; Iter    69/  201] train: loss: 0.1266864
[Epoch 102; Iter    99/  201] train: loss: 0.1160481
[Epoch 102; Iter   129/  201] train: loss: 0.1469618
[Epoch 102; Iter   159/  201] train: loss: 0.1609982
[Epoch 102; Iter   189/  201] train: loss: 0.1695468
[Epoch 102] ogbg-moltoxcast: 0.733181 val loss: 0.218327
[Epoch 102] ogbg-moltoxcast: 0.740116 test loss: 0.218412
[Epoch 103; Iter    18/  201] train: loss: 0.1379688
[Epoch 103; Iter    48/  201] train: loss: 0.1612982
[Epoch 103; Iter    78/  201] train: loss: 0.1565170
[Epoch 103; Iter   108/  201] train: loss: 0.1172975
[Epoch 103; Iter   138/  201] train: loss: 0.1777572
[Epoch 103; Iter   168/  201] train: loss: 0.1557614
[Epoch 103; Iter   198/  201] train: loss: 0.1316659
[Epoch 103] ogbg-moltoxcast: 0.733346 val loss: 0.217320
[Epoch 103] ogbg-moltoxcast: 0.744646 test loss: 0.214901
[Epoch 104; Iter    27/  201] train: loss: 0.1280100
[Epoch 104; Iter    57/  201] train: loss: 0.1157489
[Epoch 104; Iter    87/  201] train: loss: 0.1592923
[Epoch 104; Iter   117/  201] train: loss: 0.1457592
[Epoch 104; Iter   147/  201] train: loss: 0.1581663
[Epoch 104; Iter   177/  201] train: loss: 0.1045985
[Epoch 104] ogbg-moltoxcast: 0.735743 val loss: 0.218412
[Epoch 104] ogbg-moltoxcast: 0.742061 test loss: 0.216343
[Epoch 105; Iter     6/  201] train: loss: 0.1480108
[Epoch 105; Iter    36/  201] train: loss: 0.1267288
[Epoch 105; Iter    66/  201] train: loss: 0.1267515
[Epoch 105; Iter    96/  201] train: loss: 0.1652676
[Epoch 105; Iter   126/  201] train: loss: 0.1080240
[Epoch 105; Iter   156/  201] train: loss: 0.1150824
[Epoch 105; Iter   186/  201] train: loss: 0.1356107
[Epoch 105] ogbg-moltoxcast: 0.733314 val loss: 0.218322
[Epoch 105] ogbg-moltoxcast: 0.744823 test loss: 0.214055
[Epoch 106; Iter    15/  201] train: loss: 0.1137477
[Epoch 106; Iter    45/  201] train: loss: 0.1106741
[Epoch 106; Iter    75/  201] train: loss: 0.1125855
[Epoch 106; Iter   105/  201] train: loss: 0.1135418
[Epoch 106; Iter   135/  201] train: loss: 0.1056281
[Epoch 106; Iter   165/  201] train: loss: 0.1497405
[Epoch 106; Iter   195/  201] train: loss: 0.1786572
[Epoch 106] ogbg-moltoxcast: 0.730658 val loss: 0.220972
[Epoch 106] ogbg-moltoxcast: 0.740482 test loss: 0.222185
[Epoch 107; Iter    24/  201] train: loss: 0.1167535
[Epoch 107; Iter    54/  201] train: loss: 0.1249782
[Epoch 107; Iter    84/  201] train: loss: 0.1426998
[Epoch 107; Iter   114/  201] train: loss: 0.1120760
[Epoch 107; Iter   144/  201] train: loss: 0.1245691
[Epoch 107; Iter   174/  201] train: loss: 0.1449904
[Epoch 107] ogbg-moltoxcast: 0.733558 val loss: 0.218815
[Epoch 107] ogbg-moltoxcast: 0.744407 test loss: 0.215260
[Epoch 108; Iter     3/  201] train: loss: 0.1283204
[Epoch 108; Iter    33/  201] train: loss: 0.0949461
[Epoch 108; Iter    63/  201] train: loss: 0.1449783
[Epoch 108; Iter    93/  201] train: loss: 0.0999009
[Epoch 108; Iter   123/  201] train: loss: 0.1514803
[Epoch 108; Iter   153/  201] train: loss: 0.1691900
[Epoch 108; Iter   183/  201] train: loss: 0.0909471
[Epoch 108] ogbg-moltoxcast: 0.732455 val loss: 0.218682
[Epoch 108] ogbg-moltoxcast: 0.744328 test loss: 0.216647
[Epoch 109; Iter    12/  201] train: loss: 0.1976384
[Epoch 109; Iter    42/  201] train: loss: 0.1479245
[Epoch 109; Iter    72/  201] train: loss: 0.1763534
[Epoch 109; Iter   102/  201] train: loss: 0.1100668
[Epoch 109; Iter   132/  201] train: loss: 0.2144610
[Epoch 109; Iter   162/  201] train: loss: 0.1532738
[Epoch 109; Iter   192/  201] train: loss: 0.1293182
[Epoch 109] ogbg-moltoxcast: 0.734365 val loss: 0.219479
[Epoch 109] ogbg-moltoxcast: 0.740953 test loss: 0.218221
[Epoch 110; Iter    21/  201] train: loss: 0.1122643
[Epoch 110; Iter    51/  201] train: loss: 0.1705260
[Epoch 110; Iter    81/  201] train: loss: 0.2100277
[Epoch 110; Iter   111/  201] train: loss: 0.1138561
[Epoch 110; Iter   141/  201] train: loss: 0.1147314
[Epoch 110; Iter   171/  201] train: loss: 0.0798025
[Epoch 110; Iter   201/  201] train: loss: 0.2332976
[Epoch 110] ogbg-moltoxcast: 0.733631 val loss: 0.221257
[Epoch 110] ogbg-moltoxcast: 0.740512 test loss: 0.220065
[Epoch 111; Iter    30/  201] train: loss: 0.1302346
[Epoch 111; Iter    60/  201] train: loss: 0.1235088
[Epoch 111; Iter    90/  201] train: loss: 0.0907930
[Epoch 111; Iter   120/  201] train: loss: 0.1767380
[Epoch 111; Iter   150/  201] train: loss: 0.1522335
[Epoch 111; Iter   180/  201] train: loss: 0.1743448
[Epoch 111] ogbg-moltoxcast: 0.734176 val loss: 0.218486
[Epoch 111] ogbg-moltoxcast: 0.740282 test loss: 0.218251
[Epoch 112; Iter     9/  201] train: loss: 0.1086381
[Epoch 112; Iter    39/  201] train: loss: 0.1380848
[Epoch 112; Iter    69/  201] train: loss: 0.1370870
[Epoch 112; Iter    99/  201] train: loss: 0.1071988
[Epoch 112; Iter   129/  201] train: loss: 0.1576247
[Epoch 112; Iter   159/  201] train: loss: 0.0962687
[Epoch 112; Iter   189/  201] train: loss: 0.0752721
[Epoch 112] ogbg-moltoxcast: 0.735255 val loss: 0.217529
[Epoch 112] ogbg-moltoxcast: 0.744482 test loss: 0.215476
[Epoch 113; Iter    18/  201] train: loss: 0.1269802
[Epoch 113; Iter    48/  201] train: loss: 0.1171301
[Epoch 113; Iter    78/  201] train: loss: 0.0917487
[Epoch 113; Iter   108/  201] train: loss: 0.1596783
[Epoch 113; Iter   138/  201] train: loss: 0.1240102
[Epoch 113; Iter   168/  201] train: loss: 0.1381233
[Epoch 113; Iter   198/  201] train: loss: 0.1190394
[Epoch 113] ogbg-moltoxcast: 0.735396 val loss: 0.219687
[Epoch 113] ogbg-moltoxcast: 0.743045 test loss: 0.217277
[Epoch 114; Iter    27/  201] train: loss: 0.1541519
[Epoch 114; Iter    57/  201] train: loss: 0.1904531
[Epoch 114; Iter    87/  201] train: loss: 0.1368653
[Epoch 114; Iter   117/  201] train: loss: 0.1279286
[Epoch 114; Iter   147/  201] train: loss: 0.0906709
[Epoch 114; Iter   177/  201] train: loss: 0.1257963
[Epoch 114] ogbg-moltoxcast: 0.734462 val loss: 0.221276
[Epoch 114] ogbg-moltoxcast: 0.741354 test loss: 0.218978
[Epoch 115; Iter     6/  201] train: loss: 0.1193047
[Epoch 115; Iter    36/  201] train: loss: 0.1526907
[Epoch 115; Iter    66/  201] train: loss: 0.1640179
[Epoch 115; Iter    96/  201] train: loss: 0.1477906
[Epoch 115; Iter   126/  201] train: loss: 0.1511671
[Epoch 115; Iter   156/  201] train: loss: 0.1194757
[Epoch 115; Iter   186/  201] train: loss: 0.1641987
[Epoch 115] ogbg-moltoxcast: 0.732776 val loss: 0.223630
[Epoch 115] ogbg-moltoxcast: 0.742094 test loss: 0.220025
[Epoch 116; Iter    15/  201] train: loss: 0.1469446
[Epoch 116; Iter    45/  201] train: loss: 0.1503476
[Epoch 116; Iter    75/  201] train: loss: 0.1751283
[Epoch 116; Iter   105/  201] train: loss: 0.1114931
[Epoch 116; Iter   135/  201] train: loss: 0.1454824
[Epoch 116; Iter   165/  201] train: loss: 0.1250049
[Epoch 116; Iter   195/  201] train: loss: 0.1075354
[Epoch 116] ogbg-moltoxcast: 0.735242 val loss: 0.223064
[Epoch 116] ogbg-moltoxcast: 0.744718 test loss: 0.221757
[Epoch 117; Iter    24/  201] train: loss: 0.1059975
[Epoch 117; Iter    54/  201] train: loss: 0.0783394
[Epoch 117; Iter    84/  201] train: loss: 0.1379154
[Epoch 117; Iter   114/  201] train: loss: 0.1055836
[Epoch 117; Iter   144/  201] train: loss: 0.1309190
[Epoch 117; Iter   174/  201] train: loss: 0.1391236
[Epoch 117] ogbg-moltoxcast: 0.731524 val loss: 0.222424
[Epoch 117] ogbg-moltoxcast: 0.741456 test loss: 0.217972
[Epoch 118; Iter     3/  201] train: loss: 0.1188526
[Epoch 118; Iter    33/  201] train: loss: 0.1420749
[Epoch 118; Iter    63/  201] train: loss: 0.1781127
[Epoch 118; Iter    93/  201] train: loss: 0.1631691
[Epoch 118; Iter   123/  201] train: loss: 0.1091099
[Epoch 118; Iter   153/  201] train: loss: 0.1561224
[Epoch 118; Iter   183/  201] train: loss: 0.1388117
[Epoch 118] ogbg-moltoxcast: 0.731846 val loss: 0.222300
[Epoch 118] ogbg-moltoxcast: 0.738116 test loss: 0.222674
[Epoch 119; Iter    12/  201] train: loss: 0.1628741

[Epoch 114; Iter    34/  172] train: loss: 0.1430707
[Epoch 114; Iter    64/  172] train: loss: 0.1433553
[Epoch 114; Iter    94/  172] train: loss: 0.0833128
[Epoch 114; Iter   124/  172] train: loss: 0.1237252
[Epoch 114; Iter   154/  172] train: loss: 0.1423535
[Epoch 114] ogbg-moltoxcast: 0.722944 val loss: 0.218839
[Epoch 114] ogbg-moltoxcast: 0.736997 test loss: 0.219042
[Epoch 115; Iter    12/  172] train: loss: 0.1173831
[Epoch 115; Iter    42/  172] train: loss: 0.0996173
[Epoch 115; Iter    72/  172] train: loss: 0.1308873
[Epoch 115; Iter   102/  172] train: loss: 0.1385903
[Epoch 115; Iter   132/  172] train: loss: 0.1331235
[Epoch 115; Iter   162/  172] train: loss: 0.1870833
[Epoch 115] ogbg-moltoxcast: 0.723871 val loss: 0.219927
[Epoch 115] ogbg-moltoxcast: 0.735571 test loss: 0.221499
[Epoch 116; Iter    20/  172] train: loss: 0.1388008
[Epoch 116; Iter    50/  172] train: loss: 0.1549559
[Epoch 116; Iter    80/  172] train: loss: 0.1193635
[Epoch 116; Iter   110/  172] train: loss: 0.1373291
[Epoch 116; Iter   140/  172] train: loss: 0.0996553
[Epoch 116; Iter   170/  172] train: loss: 0.1347204
[Epoch 116] ogbg-moltoxcast: 0.724555 val loss: 0.219602
[Epoch 116] ogbg-moltoxcast: 0.736451 test loss: 0.220405
[Epoch 117; Iter    28/  172] train: loss: 0.1435065
[Epoch 117; Iter    58/  172] train: loss: 0.1506285
[Epoch 117; Iter    88/  172] train: loss: 0.0950512
[Epoch 117; Iter   118/  172] train: loss: 0.1450340
[Epoch 117; Iter   148/  172] train: loss: 0.1281718
[Epoch 117] ogbg-moltoxcast: 0.725845 val loss: 0.217779
[Epoch 117] ogbg-moltoxcast: 0.736806 test loss: 0.219586
[Epoch 118; Iter     6/  172] train: loss: 0.0950593
[Epoch 118; Iter    36/  172] train: loss: 0.0928262
[Epoch 118; Iter    66/  172] train: loss: 0.1492819
[Epoch 118; Iter    96/  172] train: loss: 0.1191863
[Epoch 118; Iter   126/  172] train: loss: 0.1240876
[Epoch 118; Iter   156/  172] train: loss: 0.1203231
[Epoch 118] ogbg-moltoxcast: 0.726752 val loss: 0.220568
[Epoch 118] ogbg-moltoxcast: 0.738134 test loss: 0.220676
[Epoch 119; Iter    14/  172] train: loss: 0.1278996
[Epoch 119; Iter    44/  172] train: loss: 0.1510400
[Epoch 119; Iter    74/  172] train: loss: 0.1666412
[Epoch 119; Iter   104/  172] train: loss: 0.1350962
[Epoch 119; Iter   134/  172] train: loss: 0.1562654
[Epoch 119; Iter   164/  172] train: loss: 0.0907792
[Epoch 119] ogbg-moltoxcast: 0.724150 val loss: 0.217946
[Epoch 119] ogbg-moltoxcast: 0.734802 test loss: 0.220632
[Epoch 120; Iter    22/  172] train: loss: 0.0917016
[Epoch 120; Iter    52/  172] train: loss: 0.0932064
[Epoch 120; Iter    82/  172] train: loss: 0.1704019
[Epoch 120; Iter   112/  172] train: loss: 0.1380301
[Epoch 120; Iter   142/  172] train: loss: 0.0891961
[Epoch 120; Iter   172/  172] train: loss: 0.1330058
[Epoch 120] ogbg-moltoxcast: 0.725319 val loss: 0.218881
[Epoch 120] ogbg-moltoxcast: 0.734377 test loss: 0.220895
[Epoch 121; Iter    30/  172] train: loss: 0.1176921
[Epoch 121; Iter    60/  172] train: loss: 0.1166873
[Epoch 121; Iter    90/  172] train: loss: 0.1426906
[Epoch 121; Iter   120/  172] train: loss: 0.1405894
[Epoch 121; Iter   150/  172] train: loss: 0.1324041
[Epoch 121] ogbg-moltoxcast: 0.724119 val loss: 0.218528
[Epoch 121] ogbg-moltoxcast: 0.735988 test loss: 0.220120
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 121 epochs. Best model checkpoint was in epoch 61.
Statistics on  val_best_checkpoint
mean_pred: -3.334822177886963
std_pred: 2.6707024574279785
mean_targets: nan
std_targets: nan
prcauc: 0.41787602370017396
rocauc: 0.7372342652608618
ogbg-moltoxcast: 0.7372342652608618
OGBNanLabelBCEWithLogitsLoss: 0.2064753084860999
Statistics on  test
mean_pred: -3.2697699069976807
std_pred: 2.6179919242858887
mean_targets: nan
std_targets: nan
prcauc: 0.40714131215363836
rocauc: 0.7485595883756267
ogbg-moltoxcast: 0.7485595883756267
OGBNanLabelBCEWithLogitsLoss: 0.2057043651825395
Statistics on  train
mean_pred: -3.315622091293335
std_pred: 2.6770737171173096
mean_targets: nan
std_targets: nan
prcauc: 0.6083144846065685
rocauc: 0.8944283190211625
ogbg-moltoxcast: 0.8944283190211625
OGBNanLabelBCEWithLogitsLoss: 0.1390573661774397
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.1212196
[Epoch 119; Iter    72/  201] train: loss: 0.1550281
[Epoch 119; Iter   102/  201] train: loss: 0.1671349
[Epoch 119; Iter   132/  201] train: loss: 0.1476956
[Epoch 119; Iter   162/  201] train: loss: 0.1078804
[Epoch 119; Iter   192/  201] train: loss: 0.1126700
[Epoch 119] ogbg-moltoxcast: 0.730083 val loss: 0.216932
[Epoch 119] ogbg-moltoxcast: 0.748489 test loss: 0.210854
[Epoch 120; Iter    21/  201] train: loss: 0.0850056
[Epoch 120; Iter    51/  201] train: loss: 0.1244835
[Epoch 120; Iter    81/  201] train: loss: 0.1111173
[Epoch 120; Iter   111/  201] train: loss: 0.1136864
[Epoch 120; Iter   141/  201] train: loss: 0.0999901
[Epoch 120; Iter   171/  201] train: loss: 0.0895227
[Epoch 120; Iter   201/  201] train: loss: 0.2286064
[Epoch 120] ogbg-moltoxcast: 0.730336 val loss: 0.218879
[Epoch 120] ogbg-moltoxcast: 0.745583 test loss: 0.215137
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 48.
Statistics on  val_best_checkpoint
mean_pred: -3.123758316040039
std_pred: 2.390829563140869
mean_targets: nan
std_targets: nan
prcauc: 0.4173926145620649
rocauc: 0.741513472690186
ogbg-moltoxcast: 0.741513472690186
OGBNanLabelBCEWithLogitsLoss: 0.20561466366052628
Statistics on  test
mean_pred: -3.1287033557891846
std_pred: 2.4046947956085205
mean_targets: nan
std_targets: nan
prcauc: 0.421820490073499
rocauc: 0.7420586727371313
ogbg-moltoxcast: 0.7420586727371313
OGBNanLabelBCEWithLogitsLoss: 0.20737884124351103
Statistics on  train
mean_pred: -3.1596333980560303
std_pred: 2.551476001739502
mean_targets: nan
std_targets: nan
prcauc: 0.5423056985922572
rocauc: 0.8593437673512576
ogbg-moltoxcast: 0.8593437673512576
OGBNanLabelBCEWithLogitsLoss: 0.15822768326274197
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.0939873
[Epoch 119; Iter    72/  201] train: loss: 0.1000255
[Epoch 119; Iter   102/  201] train: loss: 0.1242423
[Epoch 119; Iter   132/  201] train: loss: 0.1687204
[Epoch 119; Iter   162/  201] train: loss: 0.1301866
[Epoch 119; Iter   192/  201] train: loss: 0.1738350
[Epoch 119] ogbg-moltoxcast: 0.731784 val loss: 0.222240
[Epoch 119] ogbg-moltoxcast: 0.742349 test loss: 0.219291
[Epoch 120; Iter    21/  201] train: loss: 0.1556034
[Epoch 120; Iter    51/  201] train: loss: 0.1407466
[Epoch 120; Iter    81/  201] train: loss: 0.0864562
[Epoch 120; Iter   111/  201] train: loss: 0.0632589
[Epoch 120; Iter   141/  201] train: loss: 0.1413159
[Epoch 120; Iter   171/  201] train: loss: 0.1120707
[Epoch 120; Iter   201/  201] train: loss: 0.0543192
[Epoch 120] ogbg-moltoxcast: 0.733306 val loss: 0.221722
[Epoch 120] ogbg-moltoxcast: 0.741602 test loss: 0.219493
[Epoch 121; Iter    30/  201] train: loss: 0.1429845
[Epoch 121; Iter    60/  201] train: loss: 0.1738036
[Epoch 121; Iter    90/  201] train: loss: 0.1019208
[Epoch 121; Iter   120/  201] train: loss: 0.1179967
[Epoch 121; Iter   150/  201] train: loss: 0.0918615
[Epoch 121; Iter   180/  201] train: loss: 0.1078540
[Epoch 121] ogbg-moltoxcast: 0.736048 val loss: 0.221234
[Epoch 121] ogbg-moltoxcast: 0.743896 test loss: 0.217481
[Epoch 122; Iter     9/  201] train: loss: 0.0877426
[Epoch 122; Iter    39/  201] train: loss: 0.1375147
[Epoch 122; Iter    69/  201] train: loss: 0.1589336
[Epoch 122; Iter    99/  201] train: loss: 0.1242129
[Epoch 122; Iter   129/  201] train: loss: 0.1264698
[Epoch 122; Iter   159/  201] train: loss: 0.1274557
[Epoch 122; Iter   189/  201] train: loss: 0.1359466
[Epoch 122] ogbg-moltoxcast: 0.731675 val loss: 0.220544
[Epoch 122] ogbg-moltoxcast: 0.739400 test loss: 0.219280
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 122 epochs. Best model checkpoint was in epoch 62.
Statistics on  val_best_checkpoint
mean_pred: -3.320242404937744
std_pred: 2.556580066680908
mean_targets: nan
std_targets: nan
prcauc: 0.4081550356734113
rocauc: 0.7388564456682641
ogbg-moltoxcast: 0.7388564456682641
OGBNanLabelBCEWithLogitsLoss: 0.2111540587488995
Statistics on  test
mean_pred: -3.3397371768951416
std_pred: 2.586750030517578
mean_targets: nan
std_targets: nan
prcauc: 0.42465396669947725
rocauc: 0.7395379020347028
ogbg-moltoxcast: 0.7395379020347028
OGBNanLabelBCEWithLogitsLoss: 0.21285070998724118
Statistics on  train
mean_pred: -3.368412733078003
std_pred: 2.6260626316070557
mean_targets: nan
std_targets: nan
prcauc: 0.5882814711367887
rocauc: 0.8838322588810822
ogbg-moltoxcast: 0.8838322588810822
OGBNanLabelBCEWithLogitsLoss: 0.1464967665758299
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.760044 test loss: 0.215316
[Epoch 108; Iter     7/  229] train: loss: 0.1436344
[Epoch 108; Iter    37/  229] train: loss: 0.1184381
[Epoch 108; Iter    67/  229] train: loss: 0.1884655
[Epoch 108; Iter    97/  229] train: loss: 0.1296385
[Epoch 108; Iter   127/  229] train: loss: 0.1374190
[Epoch 108; Iter   157/  229] train: loss: 0.1292679
[Epoch 108; Iter   187/  229] train: loss: 0.1232030
[Epoch 108; Iter   217/  229] train: loss: 0.1886333
[Epoch 108] ogbg-moltoxcast: 0.742373 val loss: 0.204984
[Epoch 108] ogbg-moltoxcast: 0.757990 test loss: 0.215236
[Epoch 109; Iter    18/  229] train: loss: 0.1346647
[Epoch 109; Iter    48/  229] train: loss: 0.1419614
[Epoch 109; Iter    78/  229] train: loss: 0.1565913
[Epoch 109; Iter   108/  229] train: loss: 0.1131456
[Epoch 109; Iter   138/  229] train: loss: 0.1263325
[Epoch 109; Iter   168/  229] train: loss: 0.1836954
[Epoch 109; Iter   198/  229] train: loss: 0.1319601
[Epoch 109; Iter   228/  229] train: loss: 0.1739501
[Epoch 109] ogbg-moltoxcast: 0.744917 val loss: 0.204238
[Epoch 109] ogbg-moltoxcast: 0.758288 test loss: 0.214658
[Epoch 110; Iter    29/  229] train: loss: 0.1074308
[Epoch 110; Iter    59/  229] train: loss: 0.1440990
[Epoch 110; Iter    89/  229] train: loss: 0.1270336
[Epoch 110; Iter   119/  229] train: loss: 0.1187852
[Epoch 110; Iter   149/  229] train: loss: 0.1174506
[Epoch 110; Iter   179/  229] train: loss: 0.1239937
[Epoch 110; Iter   209/  229] train: loss: 0.0841734
[Epoch 110] ogbg-moltoxcast: 0.747180 val loss: 0.204596
[Epoch 110] ogbg-moltoxcast: 0.760044 test loss: 0.215052
[Epoch 111; Iter    10/  229] train: loss: 0.1304340
[Epoch 111; Iter    40/  229] train: loss: 0.1642066
[Epoch 111; Iter    70/  229] train: loss: 0.1207434
[Epoch 111; Iter   100/  229] train: loss: 0.0893795
[Epoch 111; Iter   130/  229] train: loss: 0.1814752
[Epoch 111; Iter   160/  229] train: loss: 0.1499721
[Epoch 111; Iter   190/  229] train: loss: 0.1308298
[Epoch 111; Iter   220/  229] train: loss: 0.1147089
[Epoch 111] ogbg-moltoxcast: 0.746519 val loss: 0.203825
[Epoch 111] ogbg-moltoxcast: 0.758831 test loss: 0.211923
[Epoch 112; Iter    21/  229] train: loss: 0.0961326
[Epoch 112; Iter    51/  229] train: loss: 0.1446046
[Epoch 112; Iter    81/  229] train: loss: 0.1752659
[Epoch 112; Iter   111/  229] train: loss: 0.1584502
[Epoch 112; Iter   141/  229] train: loss: 0.1298975
[Epoch 112; Iter   171/  229] train: loss: 0.1322078
[Epoch 112; Iter   201/  229] train: loss: 0.1486399
[Epoch 112] ogbg-moltoxcast: 0.744464 val loss: 0.205849
[Epoch 112] ogbg-moltoxcast: 0.756885 test loss: 0.215742
[Epoch 113; Iter     2/  229] train: loss: 0.1143213
[Epoch 113; Iter    32/  229] train: loss: 0.1632783
[Epoch 113; Iter    62/  229] train: loss: 0.1485088
[Epoch 113; Iter    92/  229] train: loss: 0.1106576
[Epoch 113; Iter   122/  229] train: loss: 0.1616194
[Epoch 113; Iter   152/  229] train: loss: 0.1226479
[Epoch 113; Iter   182/  229] train: loss: 0.1351383
[Epoch 113; Iter   212/  229] train: loss: 0.1498610
[Epoch 113] ogbg-moltoxcast: 0.745293 val loss: 0.205365
[Epoch 113] ogbg-moltoxcast: 0.757598 test loss: 0.213421
[Epoch 114; Iter    13/  229] train: loss: 0.1235851
[Epoch 114; Iter    43/  229] train: loss: 0.1206967
[Epoch 114; Iter    73/  229] train: loss: 0.1104454
[Epoch 114; Iter   103/  229] train: loss: 0.1360476
[Epoch 114; Iter   133/  229] train: loss: 0.1515252
[Epoch 114; Iter   163/  229] train: loss: 0.1413987
[Epoch 114; Iter   193/  229] train: loss: 0.1058514
[Epoch 114; Iter   223/  229] train: loss: 0.1241880
[Epoch 114] ogbg-moltoxcast: 0.745179 val loss: 0.205098
[Epoch 114] ogbg-moltoxcast: 0.758450 test loss: 0.215166
[Epoch 115; Iter    24/  229] train: loss: 0.1212181
[Epoch 115; Iter    54/  229] train: loss: 0.1780291
[Epoch 115; Iter    84/  229] train: loss: 0.1199991
[Epoch 115; Iter   114/  229] train: loss: 0.0864324
[Epoch 115; Iter   144/  229] train: loss: 0.1612558
[Epoch 115; Iter   174/  229] train: loss: 0.1343397
[Epoch 115; Iter   204/  229] train: loss: 0.1527337
[Epoch 115] ogbg-moltoxcast: 0.746879 val loss: 0.205223
[Epoch 115] ogbg-moltoxcast: 0.762801 test loss: 0.217341
[Epoch 116; Iter     5/  229] train: loss: 0.1669823
[Epoch 116; Iter    35/  229] train: loss: 0.1008868
[Epoch 116; Iter    65/  229] train: loss: 0.1336643
[Epoch 116; Iter    95/  229] train: loss: 0.1062260
[Epoch 116; Iter   125/  229] train: loss: 0.1495382
[Epoch 116; Iter   155/  229] train: loss: 0.1160673
[Epoch 116; Iter   185/  229] train: loss: 0.1683836
[Epoch 116; Iter   215/  229] train: loss: 0.1613956
[Epoch 116] ogbg-moltoxcast: 0.747115 val loss: 0.201840
[Epoch 116] ogbg-moltoxcast: 0.760325 test loss: 0.215723
[Epoch 117; Iter    16/  229] train: loss: 0.1424954
[Epoch 117; Iter    46/  229] train: loss: 0.1207019
[Epoch 117; Iter    76/  229] train: loss: 0.1319032
[Epoch 117; Iter   106/  229] train: loss: 0.1479878
[Epoch 117; Iter   136/  229] train: loss: 0.1713275
[Epoch 117; Iter   166/  229] train: loss: 0.1127807
[Epoch 117; Iter   196/  229] train: loss: 0.1456718
[Epoch 117; Iter   226/  229] train: loss: 0.1039735
[Epoch 117] ogbg-moltoxcast: 0.747732 val loss: 0.202801
[Epoch 117] ogbg-moltoxcast: 0.761157 test loss: 0.213749
[Epoch 118; Iter    27/  229] train: loss: 0.1802180
[Epoch 118; Iter    57/  229] train: loss: 0.1313838
[Epoch 118; Iter    87/  229] train: loss: 0.0980513
[Epoch 118; Iter   117/  229] train: loss: 0.1295283
[Epoch 118; Iter   147/  229] train: loss: 0.1534698
[Epoch 118; Iter   177/  229] train: loss: 0.1196760
[Epoch 118; Iter   207/  229] train: loss: 0.1262085
[Epoch 118] ogbg-moltoxcast: 0.746177 val loss: 0.205173
[Epoch 118] ogbg-moltoxcast: 0.756441 test loss: 0.216123
[Epoch 119; Iter     8/  229] train: loss: 0.1728736
[Epoch 119; Iter    38/  229] train: loss: 0.1062703
[Epoch 119; Iter    68/  229] train: loss: 0.1243008
[Epoch 119; Iter    98/  229] train: loss: 0.1303626
[Epoch 119; Iter   128/  229] train: loss: 0.1564820
[Epoch 119; Iter   158/  229] train: loss: 0.1291277
[Epoch 119; Iter   188/  229] train: loss: 0.1226819
[Epoch 119; Iter   218/  229] train: loss: 0.1298329
[Epoch 119] ogbg-moltoxcast: 0.746050 val loss: 0.206433
[Epoch 119] ogbg-moltoxcast: 0.755853 test loss: 0.218563
[Epoch 120; Iter    19/  229] train: loss: 0.1079732
[Epoch 120; Iter    49/  229] train: loss: 0.1337716
[Epoch 120; Iter    79/  229] train: loss: 0.1490422
[Epoch 120; Iter   109/  229] train: loss: 0.0856328
[Epoch 120; Iter   139/  229] train: loss: 0.0963456
[Epoch 120; Iter   169/  229] train: loss: 0.1896985
[Epoch 120; Iter   199/  229] train: loss: 0.1394237
[Epoch 120; Iter   229/  229] train: loss: 0.1825437
[Epoch 120] ogbg-moltoxcast: 0.745203 val loss: 0.204158
[Epoch 120] ogbg-moltoxcast: 0.757158 test loss: 0.216389
[Epoch 121; Iter    30/  229] train: loss: 0.0964487
[Epoch 121; Iter    60/  229] train: loss: 0.1958283
[Epoch 121; Iter    90/  229] train: loss: 0.1452405
[Epoch 121; Iter   120/  229] train: loss: 0.1559886
[Epoch 121; Iter   150/  229] train: loss: 0.1332856
[Epoch 121; Iter   180/  229] train: loss: 0.1078030
[Epoch 121; Iter   210/  229] train: loss: 0.1180909
[Epoch 121] ogbg-moltoxcast: 0.748355 val loss: 0.204666
[Epoch 121] ogbg-moltoxcast: 0.759915 test loss: 0.215545
[Epoch 122; Iter    11/  229] train: loss: 0.1616938
[Epoch 122; Iter    41/  229] train: loss: 0.1441024
[Epoch 122; Iter    71/  229] train: loss: 0.1608388
[Epoch 122; Iter   101/  229] train: loss: 0.1099921
[Epoch 122; Iter   131/  229] train: loss: 0.1532612
[Epoch 122; Iter   161/  229] train: loss: 0.1256684
[Epoch 122; Iter   191/  229] train: loss: 0.1398740
[Epoch 122; Iter   221/  229] train: loss: 0.1623289
[Epoch 122] ogbg-moltoxcast: 0.744654 val loss: 0.207293
[Epoch 122] ogbg-moltoxcast: 0.758188 test loss: 0.216416
[Epoch 123; Iter    22/  229] train: loss: 0.1213819
[Epoch 123; Iter    52/  229] train: loss: 0.1245861
[Epoch 123; Iter    82/  229] train: loss: 0.1067951
[Epoch 123; Iter   112/  229] train: loss: 0.1425200
[Epoch 123; Iter   142/  229] train: loss: 0.0923413
[Epoch 107] ogbg-moltoxcast: 0.749666 test loss: 0.220279
[Epoch 108; Iter     7/  229] train: loss: 0.0991394
[Epoch 108; Iter    37/  229] train: loss: 0.1565458
[Epoch 108; Iter    67/  229] train: loss: 0.1442372
[Epoch 108; Iter    97/  229] train: loss: 0.1163394
[Epoch 108; Iter   127/  229] train: loss: 0.1394114
[Epoch 108; Iter   157/  229] train: loss: 0.1089410
[Epoch 108; Iter   187/  229] train: loss: 0.1211671
[Epoch 108; Iter   217/  229] train: loss: 0.1336443
[Epoch 108] ogbg-moltoxcast: 0.738107 val loss: 0.205976
[Epoch 108] ogbg-moltoxcast: 0.752987 test loss: 0.215240
[Epoch 109; Iter    18/  229] train: loss: 0.1465692
[Epoch 109; Iter    48/  229] train: loss: 0.1294384
[Epoch 109; Iter    78/  229] train: loss: 0.1076123
[Epoch 109; Iter   108/  229] train: loss: 0.1517543
[Epoch 109; Iter   138/  229] train: loss: 0.1065767
[Epoch 109; Iter   168/  229] train: loss: 0.0858159
[Epoch 109; Iter   198/  229] train: loss: 0.1484836
[Epoch 109; Iter   228/  229] train: loss: 0.1993271
[Epoch 109] ogbg-moltoxcast: 0.736725 val loss: 0.205233
[Epoch 109] ogbg-moltoxcast: 0.752702 test loss: 0.214867
[Epoch 110; Iter    29/  229] train: loss: 0.1406624
[Epoch 110; Iter    59/  229] train: loss: 0.1890853
[Epoch 110; Iter    89/  229] train: loss: 0.1266412
[Epoch 110; Iter   119/  229] train: loss: 0.1205052
[Epoch 110; Iter   149/  229] train: loss: 0.0915465
[Epoch 110; Iter   179/  229] train: loss: 0.1173086
[Epoch 110; Iter   209/  229] train: loss: 0.1606183
[Epoch 110] ogbg-moltoxcast: 0.738137 val loss: 0.208427
[Epoch 110] ogbg-moltoxcast: 0.752429 test loss: 0.227465
[Epoch 111; Iter    10/  229] train: loss: 0.1150708
[Epoch 111; Iter    40/  229] train: loss: 0.1014045
[Epoch 111; Iter    70/  229] train: loss: 0.1786723
[Epoch 111; Iter   100/  229] train: loss: 0.1729940
[Epoch 111; Iter   130/  229] train: loss: 0.1341830
[Epoch 111; Iter   160/  229] train: loss: 0.1513899
[Epoch 111; Iter   190/  229] train: loss: 0.1506039
[Epoch 111; Iter   220/  229] train: loss: 0.1574442
[Epoch 111] ogbg-moltoxcast: 0.737710 val loss: 0.206443
[Epoch 111] ogbg-moltoxcast: 0.752048 test loss: 0.217917
[Epoch 112; Iter    21/  229] train: loss: 0.1308790
[Epoch 112; Iter    51/  229] train: loss: 0.1392473
[Epoch 112; Iter    81/  229] train: loss: 0.1147758
[Epoch 112; Iter   111/  229] train: loss: 0.1265080
[Epoch 112; Iter   141/  229] train: loss: 0.1282867
[Epoch 112; Iter   171/  229] train: loss: 0.1599298
[Epoch 112; Iter   201/  229] train: loss: 0.1339903
[Epoch 112] ogbg-moltoxcast: 0.739590 val loss: 0.208651
[Epoch 112] ogbg-moltoxcast: 0.749556 test loss: 0.219656
[Epoch 113; Iter     2/  229] train: loss: 0.1106814
[Epoch 113; Iter    32/  229] train: loss: 0.1135604
[Epoch 113; Iter    62/  229] train: loss: 0.1175599
[Epoch 113; Iter    92/  229] train: loss: 0.1682628
[Epoch 113; Iter   122/  229] train: loss: 0.1177586
[Epoch 113; Iter   152/  229] train: loss: 0.1605093
[Epoch 113; Iter   182/  229] train: loss: 0.1435073
[Epoch 113; Iter   212/  229] train: loss: 0.1276926
[Epoch 113] ogbg-moltoxcast: 0.743348 val loss: 0.205907
[Epoch 113] ogbg-moltoxcast: 0.752648 test loss: 0.217723
[Epoch 114; Iter    13/  229] train: loss: 0.2162494
[Epoch 114; Iter    43/  229] train: loss: 0.1234012
[Epoch 114; Iter    73/  229] train: loss: 0.1229074
[Epoch 114; Iter   103/  229] train: loss: 0.1316363
[Epoch 114; Iter   133/  229] train: loss: 0.1563364
[Epoch 114; Iter   163/  229] train: loss: 0.1295675
[Epoch 114; Iter   193/  229] train: loss: 0.0816044
[Epoch 114; Iter   223/  229] train: loss: 0.0997580
[Epoch 114] ogbg-moltoxcast: 0.740122 val loss: 0.206503
[Epoch 114] ogbg-moltoxcast: 0.750851 test loss: 0.216731
[Epoch 115; Iter    24/  229] train: loss: 0.1543632
[Epoch 115; Iter    54/  229] train: loss: 0.1279241
[Epoch 115; Iter    84/  229] train: loss: 0.1747111
[Epoch 115; Iter   114/  229] train: loss: 0.0992873
[Epoch 115; Iter   144/  229] train: loss: 0.1160847
[Epoch 115; Iter   174/  229] train: loss: 0.1342639
[Epoch 115; Iter   204/  229] train: loss: 0.1230110
[Epoch 115] ogbg-moltoxcast: 0.739597 val loss: 0.208098
[Epoch 115] ogbg-moltoxcast: 0.750541 test loss: 0.265727
[Epoch 116; Iter     5/  229] train: loss: 0.1316687
[Epoch 116; Iter    35/  229] train: loss: 0.1270262
[Epoch 116; Iter    65/  229] train: loss: 0.1586750
[Epoch 116; Iter    95/  229] train: loss: 0.1459515
[Epoch 116; Iter   125/  229] train: loss: 0.1133752
[Epoch 116; Iter   155/  229] train: loss: 0.1439276
[Epoch 116; Iter   185/  229] train: loss: 0.1534782
[Epoch 116; Iter   215/  229] train: loss: 0.1378265
[Epoch 116] ogbg-moltoxcast: 0.737509 val loss: 0.206215
[Epoch 116] ogbg-moltoxcast: 0.751930 test loss: 0.253091
[Epoch 117; Iter    16/  229] train: loss: 0.1468416
[Epoch 117; Iter    46/  229] train: loss: 0.1128319
[Epoch 117; Iter    76/  229] train: loss: 0.1545910
[Epoch 117; Iter   106/  229] train: loss: 0.0947011
[Epoch 117; Iter   136/  229] train: loss: 0.1474603
[Epoch 117; Iter   166/  229] train: loss: 0.1215000
[Epoch 117; Iter   196/  229] train: loss: 0.1079385
[Epoch 117; Iter   226/  229] train: loss: 0.1177870
[Epoch 117] ogbg-moltoxcast: 0.739087 val loss: 0.205877
[Epoch 117] ogbg-moltoxcast: 0.753760 test loss: 0.215115
[Epoch 118; Iter    27/  229] train: loss: 0.1734264
[Epoch 118; Iter    57/  229] train: loss: 0.1401773
[Epoch 118; Iter    87/  229] train: loss: 0.1124209
[Epoch 118; Iter   117/  229] train: loss: 0.1421857
[Epoch 118; Iter   147/  229] train: loss: 0.1069525
[Epoch 118; Iter   177/  229] train: loss: 0.1475959
[Epoch 118; Iter   207/  229] train: loss: 0.1021905
[Epoch 118] ogbg-moltoxcast: 0.739804 val loss: 0.206321
[Epoch 118] ogbg-moltoxcast: 0.752519 test loss: 0.215863
[Epoch 119; Iter     8/  229] train: loss: 0.1519937
[Epoch 119; Iter    38/  229] train: loss: 0.1305342
[Epoch 119; Iter    68/  229] train: loss: 0.1122580
[Epoch 119; Iter    98/  229] train: loss: 0.1110918
[Epoch 119; Iter   128/  229] train: loss: 0.1331862
[Epoch 119; Iter   158/  229] train: loss: 0.1193705
[Epoch 119; Iter   188/  229] train: loss: 0.0801293
[Epoch 119; Iter   218/  229] train: loss: 0.1674154
[Epoch 119] ogbg-moltoxcast: 0.742226 val loss: 0.205852
[Epoch 119] ogbg-moltoxcast: 0.753976 test loss: 0.216990
[Epoch 120; Iter    19/  229] train: loss: 0.1093796
[Epoch 120; Iter    49/  229] train: loss: 0.1616872
[Epoch 120; Iter    79/  229] train: loss: 0.1549704
[Epoch 120; Iter   109/  229] train: loss: 0.1432617
[Epoch 120; Iter   139/  229] train: loss: 0.1326050
[Epoch 120; Iter   169/  229] train: loss: 0.1499397
[Epoch 120; Iter   199/  229] train: loss: 0.1450037
[Epoch 120; Iter   229/  229] train: loss: 0.1758904
[Epoch 120] ogbg-moltoxcast: 0.742447 val loss: 0.206282
[Epoch 120] ogbg-moltoxcast: 0.756025 test loss: 0.216348
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 54.
Statistics on  val_best_checkpoint
mean_pred: -3.1263010501861572
std_pred: 2.5088865756988525
mean_targets: nan
std_targets: nan
prcauc: 0.4253826908893631
rocauc: 0.7500963435174784
ogbg-moltoxcast: 0.7500963435174784
OGBNanLabelBCEWithLogitsLoss: 0.19575829341493803
Statistics on  test
mean_pred: -3.1441490650177
std_pred: 2.560218334197998
mean_targets: nan
std_targets: nan
prcauc: 0.4427585735796695
rocauc: 0.7526281902156069
ogbg-moltoxcast: 0.7526281902156069
OGBNanLabelBCEWithLogitsLoss: 0.20844602944522067
Statistics on  train
mean_pred: -3.1497879028320312
std_pred: 2.583199977874756
mean_targets: nan
std_targets: nan
prcauc: 0.5644555721701803
rocauc: 0.875023088824108
ogbg-moltoxcast: 0.875023088824108
OGBNanLabelBCEWithLogitsLoss: 0.15165636237857122
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 107] ogbg-moltoxcast: 0.754170 test loss: 0.217058
[Epoch 108; Iter     7/  229] train: loss: 0.1334146
[Epoch 108; Iter    37/  229] train: loss: 0.1363467
[Epoch 108; Iter    67/  229] train: loss: 0.1344499
[Epoch 108; Iter    97/  229] train: loss: 0.1369787
[Epoch 108; Iter   127/  229] train: loss: 0.0865262
[Epoch 108; Iter   157/  229] train: loss: 0.1309076
[Epoch 108; Iter   187/  229] train: loss: 0.1297890
[Epoch 108; Iter   217/  229] train: loss: 0.1175509
[Epoch 108] ogbg-moltoxcast: 0.744851 val loss: 0.202652
[Epoch 108] ogbg-moltoxcast: 0.753464 test loss: 0.220730
[Epoch 109; Iter    18/  229] train: loss: 0.1131437
[Epoch 109; Iter    48/  229] train: loss: 0.1095227
[Epoch 109; Iter    78/  229] train: loss: 0.1078267
[Epoch 109; Iter   108/  229] train: loss: 0.1324172
[Epoch 109; Iter   138/  229] train: loss: 0.1349245
[Epoch 109; Iter   168/  229] train: loss: 0.1086568
[Epoch 109; Iter   198/  229] train: loss: 0.1505752
[Epoch 109; Iter   228/  229] train: loss: 0.0880999
[Epoch 109] ogbg-moltoxcast: 0.744144 val loss: 0.202315
[Epoch 109] ogbg-moltoxcast: 0.755484 test loss: 0.224009
[Epoch 110; Iter    29/  229] train: loss: 0.1078315
[Epoch 110; Iter    59/  229] train: loss: 0.1464203
[Epoch 110; Iter    89/  229] train: loss: 0.1717280
[Epoch 110; Iter   119/  229] train: loss: 0.1133647
[Epoch 110; Iter   149/  229] train: loss: 0.0862763
[Epoch 110; Iter   179/  229] train: loss: 0.1429517
[Epoch 110; Iter   209/  229] train: loss: 0.1585309
[Epoch 110] ogbg-moltoxcast: 0.745040 val loss: 0.201038
[Epoch 110] ogbg-moltoxcast: 0.754852 test loss: 0.221875
[Epoch 111; Iter    10/  229] train: loss: 0.1355475
[Epoch 111; Iter    40/  229] train: loss: 0.1013547
[Epoch 111; Iter    70/  229] train: loss: 0.0895684
[Epoch 111; Iter   100/  229] train: loss: 0.0782300
[Epoch 111; Iter   130/  229] train: loss: 0.1314135
[Epoch 111; Iter   160/  229] train: loss: 0.1190026
[Epoch 111; Iter   190/  229] train: loss: 0.1665763
[Epoch 111; Iter   220/  229] train: loss: 0.1069376
[Epoch 111] ogbg-moltoxcast: 0.745369 val loss: 0.201632
[Epoch 111] ogbg-moltoxcast: 0.757153 test loss: 0.217199
[Epoch 112; Iter    21/  229] train: loss: 0.1287168
[Epoch 112; Iter    51/  229] train: loss: 0.1939497
[Epoch 112; Iter    81/  229] train: loss: 0.0867680
[Epoch 112; Iter   111/  229] train: loss: 0.1206159
[Epoch 112; Iter   141/  229] train: loss: 0.1860635
[Epoch 112; Iter   171/  229] train: loss: 0.1702650
[Epoch 112; Iter   201/  229] train: loss: 0.1147882
[Epoch 112] ogbg-moltoxcast: 0.744336 val loss: 0.202388
[Epoch 112] ogbg-moltoxcast: 0.756712 test loss: 0.215895
[Epoch 113; Iter     2/  229] train: loss: 0.1514628
[Epoch 113; Iter    32/  229] train: loss: 0.1254245
[Epoch 113; Iter    62/  229] train: loss: 0.0930805
[Epoch 113; Iter    92/  229] train: loss: 0.1701938
[Epoch 113; Iter   122/  229] train: loss: 0.1300539
[Epoch 113; Iter   152/  229] train: loss: 0.1136088
[Epoch 113; Iter   182/  229] train: loss: 0.1264087
[Epoch 113; Iter   212/  229] train: loss: 0.1545789
[Epoch 113] ogbg-moltoxcast: 0.744842 val loss: 0.202286
[Epoch 113] ogbg-moltoxcast: 0.754820 test loss: 0.219763
[Epoch 114; Iter    13/  229] train: loss: 0.1196032
[Epoch 114; Iter    43/  229] train: loss: 0.1132668
[Epoch 114; Iter    73/  229] train: loss: 0.1096779
[Epoch 114; Iter   103/  229] train: loss: 0.1190201
[Epoch 114; Iter   133/  229] train: loss: 0.0974177
[Epoch 114; Iter   163/  229] train: loss: 0.1610808
[Epoch 114; Iter   193/  229] train: loss: 0.1260497
[Epoch 114; Iter   223/  229] train: loss: 0.2457236
[Epoch 114] ogbg-moltoxcast: 0.747628 val loss: 0.204383
[Epoch 114] ogbg-moltoxcast: 0.754617 test loss: 0.220954
[Epoch 115; Iter    24/  229] train: loss: 0.1614397
[Epoch 115; Iter    54/  229] train: loss: 0.1602422
[Epoch 115; Iter    84/  229] train: loss: 0.1327475
[Epoch 115; Iter   114/  229] train: loss: 0.1730335
[Epoch 115; Iter   144/  229] train: loss: 0.1305022
[Epoch 115; Iter   174/  229] train: loss: 0.1655093
[Epoch 115; Iter   204/  229] train: loss: 0.1249166
[Epoch 115] ogbg-moltoxcast: 0.742706 val loss: 0.203423
[Epoch 115] ogbg-moltoxcast: 0.753826 test loss: 0.220403
[Epoch 116; Iter     5/  229] train: loss: 0.1446329
[Epoch 116; Iter    35/  229] train: loss: 0.1831665
[Epoch 116; Iter    65/  229] train: loss: 0.1033644
[Epoch 116; Iter    95/  229] train: loss: 0.1332937
[Epoch 116; Iter   125/  229] train: loss: 0.1396978
[Epoch 116; Iter   155/  229] train: loss: 0.1532566
[Epoch 116; Iter   185/  229] train: loss: 0.1431081
[Epoch 116; Iter   215/  229] train: loss: 0.1486071
[Epoch 116] ogbg-moltoxcast: 0.744682 val loss: 0.204285
[Epoch 116] ogbg-moltoxcast: 0.756063 test loss: 0.219210
[Epoch 117; Iter    16/  229] train: loss: 0.1343058
[Epoch 117; Iter    46/  229] train: loss: 0.1511923
[Epoch 117; Iter    76/  229] train: loss: 0.1437783
[Epoch 117; Iter   106/  229] train: loss: 0.0955912
[Epoch 117; Iter   136/  229] train: loss: 0.1397949
[Epoch 117; Iter   166/  229] train: loss: 0.1209812
[Epoch 117; Iter   196/  229] train: loss: 0.1424402
[Epoch 117; Iter   226/  229] train: loss: 0.0944673
[Epoch 117] ogbg-moltoxcast: 0.742650 val loss: 0.205417
[Epoch 117] ogbg-moltoxcast: 0.755555 test loss: 0.221255
[Epoch 118; Iter    27/  229] train: loss: 0.1436297
[Epoch 118; Iter    57/  229] train: loss: 0.1300143
[Epoch 118; Iter    87/  229] train: loss: 0.1777271
[Epoch 118; Iter   117/  229] train: loss: 0.1191227
[Epoch 118; Iter   147/  229] train: loss: 0.1087045
[Epoch 118; Iter   177/  229] train: loss: 0.1371436
[Epoch 118; Iter   207/  229] train: loss: 0.0885266
[Epoch 118] ogbg-moltoxcast: 0.741940 val loss: 0.205452
[Epoch 118] ogbg-moltoxcast: 0.754344 test loss: 0.226710
[Epoch 119; Iter     8/  229] train: loss: 0.1087259
[Epoch 119; Iter    38/  229] train: loss: 0.1062425
[Epoch 119; Iter    68/  229] train: loss: 0.1269659
[Epoch 119; Iter    98/  229] train: loss: 0.1728401
[Epoch 119; Iter   128/  229] train: loss: 0.1652224
[Epoch 119; Iter   158/  229] train: loss: 0.1182128
[Epoch 119; Iter   188/  229] train: loss: 0.1309218
[Epoch 119; Iter   218/  229] train: loss: 0.1275990
[Epoch 119] ogbg-moltoxcast: 0.743834 val loss: 0.204951
[Epoch 119] ogbg-moltoxcast: 0.754010 test loss: 0.217219
[Epoch 120; Iter    19/  229] train: loss: 0.0679282
[Epoch 120; Iter    49/  229] train: loss: 0.1367461
[Epoch 120; Iter    79/  229] train: loss: 0.1739563
[Epoch 120; Iter   109/  229] train: loss: 0.0917092
[Epoch 120; Iter   139/  229] train: loss: 0.1149794
[Epoch 120; Iter   169/  229] train: loss: 0.1260247
[Epoch 120; Iter   199/  229] train: loss: 0.1389277
[Epoch 120; Iter   229/  229] train: loss: 0.1015038
[Epoch 120] ogbg-moltoxcast: 0.739396 val loss: 0.206389
[Epoch 120] ogbg-moltoxcast: 0.757449 test loss: 0.218839
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 120 epochs. Best model checkpoint was in epoch 48.
Statistics on  val_best_checkpoint
mean_pred: -3.072970151901245
std_pred: 2.435577392578125
mean_targets: nan
std_targets: nan
prcauc: 0.42805880908875504
rocauc: 0.75054194605362
ogbg-moltoxcast: 0.75054194605362
OGBNanLabelBCEWithLogitsLoss: 0.19169048810827322
Statistics on  test
mean_pred: -3.1303560733795166
std_pred: 2.454434871673584
mean_targets: nan
std_targets: nan
prcauc: 0.45328509034938314
rocauc: 0.7567274192743141
ogbg-moltoxcast: 0.7567274192743141
OGBNanLabelBCEWithLogitsLoss: 0.20728757540727483
Statistics on  train
mean_pred: -3.13594126701355
std_pred: 2.7053346633911133
mean_targets: nan
std_targets: nan
prcauc: 0.5628161732403664
rocauc: 0.87263951892274
ogbg-moltoxcast: 0.87263951892274
OGBNanLabelBCEWithLogitsLoss: 0.15155840206354465
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 119; Iter    42/  201] train: loss: 0.1060136
[Epoch 119; Iter    72/  201] train: loss: 0.0978610
[Epoch 119; Iter   102/  201] train: loss: 0.1297936
[Epoch 119; Iter   132/  201] train: loss: 0.1280650
[Epoch 119; Iter   162/  201] train: loss: 0.1414791
[Epoch 119; Iter   192/  201] train: loss: 0.1695653
[Epoch 119] ogbg-moltoxcast: 0.733229 val loss: 0.217516
[Epoch 119] ogbg-moltoxcast: 0.742179 test loss: 0.223082
[Epoch 120; Iter    21/  201] train: loss: 0.1120418
[Epoch 120; Iter    51/  201] train: loss: 0.1388588
[Epoch 120; Iter    81/  201] train: loss: 0.1189863
[Epoch 120; Iter   111/  201] train: loss: 0.1725657
[Epoch 120; Iter   141/  201] train: loss: 0.1368556
[Epoch 120; Iter   171/  201] train: loss: 0.1295630
[Epoch 120; Iter   201/  201] train: loss: 0.2538666
[Epoch 120] ogbg-moltoxcast: 0.736306 val loss: 0.222212
[Epoch 120] ogbg-moltoxcast: 0.746931 test loss: 0.226120
[Epoch 121; Iter    30/  201] train: loss: 0.1209773
[Epoch 121; Iter    60/  201] train: loss: 0.1453396
[Epoch 121; Iter    90/  201] train: loss: 0.0701259
[Epoch 121; Iter   120/  201] train: loss: 0.1339563
[Epoch 121; Iter   150/  201] train: loss: 0.0850052
[Epoch 121; Iter   180/  201] train: loss: 0.0771457
[Epoch 121] ogbg-moltoxcast: 0.735298 val loss: 0.218231
[Epoch 121] ogbg-moltoxcast: 0.744722 test loss: 0.221888
[Epoch 122; Iter     9/  201] train: loss: 0.1130366
[Epoch 122; Iter    39/  201] train: loss: 0.1497480
[Epoch 122; Iter    69/  201] train: loss: 0.1136246
[Epoch 122; Iter    99/  201] train: loss: 0.1061851
[Epoch 122; Iter   129/  201] train: loss: 0.1248131
[Epoch 122; Iter   159/  201] train: loss: 0.1147737
[Epoch 122; Iter   189/  201] train: loss: 0.1279714
[Epoch 122] ogbg-moltoxcast: 0.737110 val loss: 0.219106
[Epoch 122] ogbg-moltoxcast: 0.746620 test loss: 0.222954
[Epoch 123; Iter    18/  201] train: loss: 0.0756647
[Epoch 123; Iter    48/  201] train: loss: 0.1175869
[Epoch 123; Iter    78/  201] train: loss: 0.1144710
[Epoch 123; Iter   108/  201] train: loss: 0.1236537
[Epoch 123; Iter   138/  201] train: loss: 0.1161340
[Epoch 123; Iter   168/  201] train: loss: 0.1189141
[Epoch 123; Iter   198/  201] train: loss: 0.1579232
[Epoch 123] ogbg-moltoxcast: 0.733723 val loss: 0.218301
[Epoch 123] ogbg-moltoxcast: 0.744740 test loss: 0.221709
[Epoch 124; Iter    27/  201] train: loss: 0.1007299
[Epoch 124; Iter    57/  201] train: loss: 0.1244279
[Epoch 124; Iter    87/  201] train: loss: 0.0978027
[Epoch 124; Iter   117/  201] train: loss: 0.1536648
[Epoch 124; Iter   147/  201] train: loss: 0.1965095
[Epoch 124; Iter   177/  201] train: loss: 0.1729688
[Epoch 124] ogbg-moltoxcast: 0.735347 val loss: 0.221023
[Epoch 124] ogbg-moltoxcast: 0.745506 test loss: 0.225218
[Epoch 125; Iter     6/  201] train: loss: 0.1814589
[Epoch 125; Iter    36/  201] train: loss: 0.1593387
[Epoch 125; Iter    66/  201] train: loss: 0.1522799
[Epoch 125; Iter    96/  201] train: loss: 0.1643908
[Epoch 125; Iter   126/  201] train: loss: 0.1403483
[Epoch 125; Iter   156/  201] train: loss: 0.1127581
[Epoch 125; Iter   186/  201] train: loss: 0.0971530
[Epoch 125] ogbg-moltoxcast: 0.736215 val loss: 0.219532
[Epoch 125] ogbg-moltoxcast: 0.748042 test loss: 0.223419
[Epoch 126; Iter    15/  201] train: loss: 0.1395835
[Epoch 126; Iter    45/  201] train: loss: 0.0966409
[Epoch 126; Iter    75/  201] train: loss: 0.1179873
[Epoch 126; Iter   105/  201] train: loss: 0.1557687
[Epoch 126; Iter   135/  201] train: loss: 0.1667211
[Epoch 126; Iter   165/  201] train: loss: 0.1086723
[Epoch 126; Iter   195/  201] train: loss: 0.1404344
[Epoch 126] ogbg-moltoxcast: 0.736893 val loss: 0.222170
[Epoch 126] ogbg-moltoxcast: 0.747501 test loss: 0.225613
[Epoch 127; Iter    24/  201] train: loss: 0.1837479
[Epoch 127; Iter    54/  201] train: loss: 0.1639799
[Epoch 127; Iter    84/  201] train: loss: 0.1451012
[Epoch 127; Iter   114/  201] train: loss: 0.1168223
[Epoch 127; Iter   144/  201] train: loss: 0.1012365
[Epoch 127; Iter   174/  201] train: loss: 0.0943597
[Epoch 127] ogbg-moltoxcast: 0.734384 val loss: 0.219980
[Epoch 127] ogbg-moltoxcast: 0.746468 test loss: 0.222761
[Epoch 128; Iter     3/  201] train: loss: 0.1198515
[Epoch 128; Iter    33/  201] train: loss: 0.1390986
[Epoch 128; Iter    63/  201] train: loss: 0.1332291
[Epoch 128; Iter    93/  201] train: loss: 0.0919073
[Epoch 128; Iter   123/  201] train: loss: 0.1189042
[Epoch 128; Iter   153/  201] train: loss: 0.1186817
[Epoch 128; Iter   183/  201] train: loss: 0.1355402
[Epoch 128] ogbg-moltoxcast: 0.737395 val loss: 0.219403
[Epoch 128] ogbg-moltoxcast: 0.744927 test loss: 0.224888
[Epoch 129; Iter    12/  201] train: loss: 0.0702590
[Epoch 129; Iter    42/  201] train: loss: 0.1341410
[Epoch 129; Iter    72/  201] train: loss: 0.1220467
[Epoch 129; Iter   102/  201] train: loss: 0.1214326
[Epoch 129; Iter   132/  201] train: loss: 0.1523753
[Epoch 129; Iter   162/  201] train: loss: 0.1147686
[Epoch 129; Iter   192/  201] train: loss: 0.1412577
[Epoch 129] ogbg-moltoxcast: 0.737802 val loss: 0.218981
[Epoch 129] ogbg-moltoxcast: 0.749367 test loss: 0.223606
[Epoch 130; Iter    21/  201] train: loss: 0.1356516
[Epoch 130; Iter    51/  201] train: loss: 0.0999812
[Epoch 130; Iter    81/  201] train: loss: 0.1201284
[Epoch 130; Iter   111/  201] train: loss: 0.0633463
[Epoch 130; Iter   141/  201] train: loss: 0.1452659
[Epoch 130; Iter   171/  201] train: loss: 0.1392672
[Epoch 130; Iter   201/  201] train: loss: 0.1986261
[Epoch 130] ogbg-moltoxcast: 0.738891 val loss: 0.221178
[Epoch 130] ogbg-moltoxcast: 0.749438 test loss: 0.228055
[Epoch 131; Iter    30/  201] train: loss: 0.1677597
[Epoch 131; Iter    60/  201] train: loss: 0.0867772
[Epoch 131; Iter    90/  201] train: loss: 0.1235879
[Epoch 131; Iter   120/  201] train: loss: 0.1429501
[Epoch 131; Iter   150/  201] train: loss: 0.1690520
[Epoch 131; Iter   180/  201] train: loss: 0.0766217
[Epoch 131] ogbg-moltoxcast: 0.736792 val loss: 0.218631
[Epoch 131] ogbg-moltoxcast: 0.748026 test loss: 0.223515
[Epoch 132; Iter     9/  201] train: loss: 0.1368063
[Epoch 132; Iter    39/  201] train: loss: 0.0946747
[Epoch 132; Iter    69/  201] train: loss: 0.1820903
[Epoch 132; Iter    99/  201] train: loss: 0.1013604
[Epoch 132; Iter   129/  201] train: loss: 0.1384116
[Epoch 132; Iter   159/  201] train: loss: 0.1104525
[Epoch 132; Iter   189/  201] train: loss: 0.1630981
[Epoch 132] ogbg-moltoxcast: 0.735895 val loss: 0.222816
[Epoch 132] ogbg-moltoxcast: 0.748176 test loss: 0.227484
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 132 epochs. Best model checkpoint was in epoch 72.
Statistics on  val_best_checkpoint
mean_pred: -3.4064600467681885
std_pred: 2.6703035831451416
mean_targets: nan
std_targets: nan
prcauc: 0.4264980722935465
rocauc: 0.7449684759052151
ogbg-moltoxcast: 0.7449684759052151
OGBNanLabelBCEWithLogitsLoss: 0.20657671190971552
Statistics on  test
mean_pred: -3.410330295562744
std_pred: 2.7124648094177246
mean_targets: nan
std_targets: nan
prcauc: 0.4364591467730245
rocauc: 0.7545556383178571
ogbg-moltoxcast: 0.7545556383178571
OGBNanLabelBCEWithLogitsLoss: 0.21087809808032457
Statistics on  train
mean_pred: -3.4505395889282227
std_pred: 2.745332717895508
mean_targets: nan
std_targets: nan
prcauc: 0.6289260542067721
rocauc: 0.8996558172974054
ogbg-moltoxcast: 0.8996558172974054
OGBNanLabelBCEWithLogitsLoss: 0.13145326003802948
All runs completed.
[Epoch 123; Iter   172/  229] train: loss: 0.1261303
[Epoch 123; Iter   202/  229] train: loss: 0.1263380
[Epoch 123] ogbg-moltoxcast: 0.745868 val loss: 0.208079
[Epoch 123] ogbg-moltoxcast: 0.755606 test loss: 0.218460
[Epoch 124; Iter     3/  229] train: loss: 0.1893389
[Epoch 124; Iter    33/  229] train: loss: 0.0934562
[Epoch 124; Iter    63/  229] train: loss: 0.1033887
[Epoch 124; Iter    93/  229] train: loss: 0.1431945
[Epoch 124; Iter   123/  229] train: loss: 0.1141668
[Epoch 124; Iter   153/  229] train: loss: 0.0867065
[Epoch 124; Iter   183/  229] train: loss: 0.1274508
[Epoch 124; Iter   213/  229] train: loss: 0.1040719
[Epoch 124] ogbg-moltoxcast: 0.745037 val loss: 0.206358
[Epoch 124] ogbg-moltoxcast: 0.755238 test loss: 0.217197
[Epoch 125; Iter    14/  229] train: loss: 0.1065930
[Epoch 125; Iter    44/  229] train: loss: 0.1298107
[Epoch 125; Iter    74/  229] train: loss: 0.1470741
[Epoch 125; Iter   104/  229] train: loss: 0.1223428
[Epoch 125; Iter   134/  229] train: loss: 0.1420217
[Epoch 125; Iter   164/  229] train: loss: 0.1599452
[Epoch 125; Iter   194/  229] train: loss: 0.1372796
[Epoch 125; Iter   224/  229] train: loss: 0.1385671
[Epoch 125] ogbg-moltoxcast: 0.745288 val loss: 0.207613
[Epoch 125] ogbg-moltoxcast: 0.754777 test loss: 0.218183
[Epoch 126; Iter    25/  229] train: loss: 0.1057713
[Epoch 126; Iter    55/  229] train: loss: 0.1278545
[Epoch 126; Iter    85/  229] train: loss: 0.1318710
[Epoch 126; Iter   115/  229] train: loss: 0.1462604
[Epoch 126; Iter   145/  229] train: loss: 0.1115463
[Epoch 126; Iter   175/  229] train: loss: 0.1109508
[Epoch 126; Iter   205/  229] train: loss: 0.1257477
[Epoch 126] ogbg-moltoxcast: 0.746409 val loss: 0.206146
[Epoch 126] ogbg-moltoxcast: 0.758167 test loss: 0.216668
[Epoch 127; Iter     6/  229] train: loss: 0.1076402
[Epoch 127; Iter    36/  229] train: loss: 0.1711331
[Epoch 127; Iter    66/  229] train: loss: 0.1101869
[Epoch 127; Iter    96/  229] train: loss: 0.0951255
[Epoch 127; Iter   126/  229] train: loss: 0.1143098
[Epoch 127; Iter   156/  229] train: loss: 0.1396526
[Epoch 127; Iter   186/  229] train: loss: 0.1216362
[Epoch 127; Iter   216/  229] train: loss: 0.1120694
[Epoch 127] ogbg-moltoxcast: 0.746875 val loss: 0.205333
[Epoch 127] ogbg-moltoxcast: 0.763005 test loss: 0.214170
[Epoch 128; Iter    17/  229] train: loss: 0.1314160
[Epoch 128; Iter    47/  229] train: loss: 0.1585786
[Epoch 128; Iter    77/  229] train: loss: 0.1155357
[Epoch 128; Iter   107/  229] train: loss: 0.1398918
[Epoch 128; Iter   137/  229] train: loss: 0.1214838
[Epoch 128; Iter   167/  229] train: loss: 0.1340367
[Epoch 128; Iter   197/  229] train: loss: 0.1180862
[Epoch 128; Iter   227/  229] train: loss: 0.1190512
[Epoch 128] ogbg-moltoxcast: 0.746479 val loss: 0.207432
[Epoch 128] ogbg-moltoxcast: 0.753895 test loss: 0.218132
[Epoch 129; Iter    28/  229] train: loss: 0.0817718
[Epoch 129; Iter    58/  229] train: loss: 0.1049095
[Epoch 129; Iter    88/  229] train: loss: 0.1140937
[Epoch 129; Iter   118/  229] train: loss: 0.1127696
[Epoch 129; Iter   148/  229] train: loss: 0.1287790
[Epoch 129; Iter   178/  229] train: loss: 0.1389458
[Epoch 129; Iter   208/  229] train: loss: 0.1090344
[Epoch 129] ogbg-moltoxcast: 0.744899 val loss: 0.209119
[Epoch 129] ogbg-moltoxcast: 0.757547 test loss: 0.218699
[Epoch 130; Iter     9/  229] train: loss: 0.1170184
[Epoch 130; Iter    39/  229] train: loss: 0.1370450
[Epoch 130; Iter    69/  229] train: loss: 0.1223881
[Epoch 130; Iter    99/  229] train: loss: 0.0962951
[Epoch 130; Iter   129/  229] train: loss: 0.1648647
[Epoch 130; Iter   159/  229] train: loss: 0.1372509
[Epoch 130; Iter   189/  229] train: loss: 0.1234920
[Epoch 130; Iter   219/  229] train: loss: 0.1562590
[Epoch 130] ogbg-moltoxcast: 0.748526 val loss: 0.207670
[Epoch 130] ogbg-moltoxcast: 0.755527 test loss: 0.217407
[Epoch 131; Iter    20/  229] train: loss: 0.1862477
[Epoch 131; Iter    50/  229] train: loss: 0.1825609
[Epoch 131; Iter    80/  229] train: loss: 0.1181118
[Epoch 131; Iter   110/  229] train: loss: 0.1095737
[Epoch 131; Iter   140/  229] train: loss: 0.1039255
[Epoch 131; Iter   170/  229] train: loss: 0.1445866
[Epoch 131; Iter   200/  229] train: loss: 0.1511483
[Epoch 131] ogbg-moltoxcast: 0.746105 val loss: 0.207483
[Epoch 131] ogbg-moltoxcast: 0.756830 test loss: 0.219396
[Epoch 132; Iter     1/  229] train: loss: 0.1015509
[Epoch 132; Iter    31/  229] train: loss: 0.1326898
[Epoch 132; Iter    61/  229] train: loss: 0.1121239
[Epoch 132; Iter    91/  229] train: loss: 0.1295254
[Epoch 132; Iter   121/  229] train: loss: 0.0927759
[Epoch 132; Iter   151/  229] train: loss: 0.1047195
[Epoch 132; Iter   181/  229] train: loss: 0.1666612
[Epoch 132; Iter   211/  229] train: loss: 0.1016769
[Epoch 132] ogbg-moltoxcast: 0.744344 val loss: 0.206900
[Epoch 132] ogbg-moltoxcast: 0.759749 test loss: 0.216044
[Epoch 133; Iter    12/  229] train: loss: 0.1532949
[Epoch 133; Iter    42/  229] train: loss: 0.0918254
[Epoch 133; Iter    72/  229] train: loss: 0.1270158
[Epoch 133; Iter   102/  229] train: loss: 0.1629301
[Epoch 133; Iter   132/  229] train: loss: 0.1876542
[Epoch 133; Iter   162/  229] train: loss: 0.1160928
[Epoch 133; Iter   192/  229] train: loss: 0.0997819
[Epoch 133; Iter   222/  229] train: loss: 0.1122374
[Epoch 133] ogbg-moltoxcast: 0.744463 val loss: 0.208275
[Epoch 133] ogbg-moltoxcast: 0.760205 test loss: 0.216464
[Epoch 134; Iter    23/  229] train: loss: 0.1607287
[Epoch 134; Iter    53/  229] train: loss: 0.1718183
[Epoch 134; Iter    83/  229] train: loss: 0.1458489
[Epoch 134; Iter   113/  229] train: loss: 0.1067392
[Epoch 134; Iter   143/  229] train: loss: 0.1527605
[Epoch 134; Iter   173/  229] train: loss: 0.1453807
[Epoch 134; Iter   203/  229] train: loss: 0.1323446
[Epoch 134] ogbg-moltoxcast: 0.746910 val loss: 0.206130
[Epoch 134] ogbg-moltoxcast: 0.759608 test loss: 0.215752
[Epoch 135; Iter     4/  229] train: loss: 0.1472563
[Epoch 135; Iter    34/  229] train: loss: 0.1131065
[Epoch 135; Iter    64/  229] train: loss: 0.1601634
[Epoch 135; Iter    94/  229] train: loss: 0.1568155
[Epoch 135; Iter   124/  229] train: loss: 0.1265123
[Epoch 135; Iter   154/  229] train: loss: 0.1033813
[Epoch 135; Iter   184/  229] train: loss: 0.1362472
[Epoch 135; Iter   214/  229] train: loss: 0.1810797
[Epoch 135] ogbg-moltoxcast: 0.744602 val loss: 0.208008
[Epoch 135] ogbg-moltoxcast: 0.755459 test loss: 0.218440
[Epoch 136; Iter    15/  229] train: loss: 0.1400169
[Epoch 136; Iter    45/  229] train: loss: 0.1576420
[Epoch 136; Iter    75/  229] train: loss: 0.1369193
[Epoch 136; Iter   105/  229] train: loss: 0.1195217
[Epoch 136; Iter   135/  229] train: loss: 0.1614168
[Epoch 136; Iter   165/  229] train: loss: 0.1165924
[Epoch 136; Iter   195/  229] train: loss: 0.1647583
[Epoch 136; Iter   225/  229] train: loss: 0.0959182
[Epoch 136] ogbg-moltoxcast: 0.745429 val loss: 0.208863
[Epoch 136] ogbg-moltoxcast: 0.752294 test loss: 0.221306
[Epoch 137; Iter    26/  229] train: loss: 0.1524988
[Epoch 137; Iter    56/  229] train: loss: 0.0931378
[Epoch 137; Iter    86/  229] train: loss: 0.0996254
[Epoch 137; Iter   116/  229] train: loss: 0.1052260
[Epoch 137; Iter   146/  229] train: loss: 0.1600040
[Epoch 137; Iter   176/  229] train: loss: 0.0886059
[Epoch 137; Iter   206/  229] train: loss: 0.1488888
[Epoch 137] ogbg-moltoxcast: 0.745624 val loss: 0.206564
[Epoch 137] ogbg-moltoxcast: 0.755669 test loss: 0.217223
[Epoch 138; Iter     7/  229] train: loss: 0.1619049
[Epoch 138; Iter    37/  229] train: loss: 0.1846011
[Epoch 138; Iter    67/  229] train: loss: 0.1184326
[Epoch 138; Iter    97/  229] train: loss: 0.1097837
[Epoch 138; Iter   127/  229] train: loss: 0.1234794
[Epoch 138; Iter   157/  229] train: loss: 0.2470665
[Epoch 138; Iter   187/  229] train: loss: 0.1058423
[Epoch 138; Iter   217/  229] train: loss: 0.1404872
[Epoch 138] ogbg-moltoxcast: 0.744948 val loss: 0.210276
[Epoch 138] ogbg-moltoxcast: 0.756667 test loss: 0.217173
[Epoch 139; Iter    18/  229] train: loss: 0.1581271
[Epoch 139; Iter    48/  229] train: loss: 0.1644512
[Epoch 139; Iter    78/  229] train: loss: 0.2197357
[Epoch 139; Iter   108/  229] train: loss: 0.1763735
[Epoch 139; Iter   138/  229] train: loss: 0.1810815
[Epoch 139; Iter   168/  229] train: loss: 0.1038119
[Epoch 139; Iter   198/  229] train: loss: 0.1972627
[Epoch 139; Iter   228/  229] train: loss: 0.1328464
[Epoch 139] ogbg-moltoxcast: 0.745741 val loss: 0.208954
[Epoch 139] ogbg-moltoxcast: 0.756620 test loss: 0.220695
[Epoch 140; Iter    29/  229] train: loss: 0.1310259
[Epoch 140; Iter    59/  229] train: loss: 0.1742484
[Epoch 140; Iter    89/  229] train: loss: 0.1064698
[Epoch 140; Iter   119/  229] train: loss: 0.0783677
[Epoch 140; Iter   149/  229] train: loss: 0.1541774
[Epoch 140; Iter   179/  229] train: loss: 0.0890070
[Epoch 140; Iter   209/  229] train: loss: 0.1469180
[Epoch 140] ogbg-moltoxcast: 0.746411 val loss: 0.205978
[Epoch 140] ogbg-moltoxcast: 0.756809 test loss: 0.217414
[Epoch 141; Iter    10/  229] train: loss: 0.1089883
[Epoch 141; Iter    40/  229] train: loss: 0.1612301
[Epoch 141; Iter    70/  229] train: loss: 0.1144981
[Epoch 141; Iter   100/  229] train: loss: 0.1520402
[Epoch 141; Iter   130/  229] train: loss: 0.0982762
[Epoch 141; Iter   160/  229] train: loss: 0.1270794
[Epoch 141; Iter   190/  229] train: loss: 0.1552800
[Epoch 141; Iter   220/  229] train: loss: 0.1674293
[Epoch 141] ogbg-moltoxcast: 0.747161 val loss: 0.207430
[Epoch 141] ogbg-moltoxcast: 0.754288 test loss: 0.220199
[Epoch 142; Iter    21/  229] train: loss: 0.0886580
[Epoch 142; Iter    51/  229] train: loss: 0.1232885
[Epoch 142; Iter    81/  229] train: loss: 0.1476531
[Epoch 142; Iter   111/  229] train: loss: 0.1139809
[Epoch 142; Iter   141/  229] train: loss: 0.1492579
[Epoch 142; Iter   171/  229] train: loss: 0.1310486
[Epoch 142; Iter   201/  229] train: loss: 0.1115737
[Epoch 142] ogbg-moltoxcast: 0.748504 val loss: 0.205176
[Epoch 142] ogbg-moltoxcast: 0.756785 test loss: 0.219345
[Epoch 143; Iter     2/  229] train: loss: 0.1201045
[Epoch 143; Iter    32/  229] train: loss: 0.1162532
[Epoch 143; Iter    62/  229] train: loss: 0.0877371
[Epoch 143; Iter    92/  229] train: loss: 0.1107403
[Epoch 143; Iter   122/  229] train: loss: 0.0861991
[Epoch 143; Iter   152/  229] train: loss: 0.1071931
[Epoch 143; Iter   182/  229] train: loss: 0.1545613
[Epoch 143; Iter   212/  229] train: loss: 0.0772310
[Epoch 143] ogbg-moltoxcast: 0.746104 val loss: 0.207376
[Epoch 143] ogbg-moltoxcast: 0.755235 test loss: 0.217673
[Epoch 144; Iter    13/  229] train: loss: 0.1454095
[Epoch 144; Iter    43/  229] train: loss: 0.1396462
[Epoch 144; Iter    73/  229] train: loss: 0.1669028
[Epoch 144; Iter   103/  229] train: loss: 0.1424768
[Epoch 144; Iter   133/  229] train: loss: 0.1807046
[Epoch 144; Iter   163/  229] train: loss: 0.1457761
[Epoch 144; Iter   193/  229] train: loss: 0.1336244
[Epoch 144; Iter   223/  229] train: loss: 0.1009957
[Epoch 144] ogbg-moltoxcast: 0.745665 val loss: 0.207954
[Epoch 144] ogbg-moltoxcast: 0.756672 test loss: 0.217409
[Epoch 145; Iter    24/  229] train: loss: 0.1215851
[Epoch 145; Iter    54/  229] train: loss: 0.1062344
[Epoch 145; Iter    84/  229] train: loss: 0.1084805
[Epoch 145; Iter   114/  229] train: loss: 0.1037442
[Epoch 145; Iter   144/  229] train: loss: 0.1311908
[Epoch 145; Iter   174/  229] train: loss: 0.1623449
[Epoch 145; Iter   204/  229] train: loss: 0.1064143
[Epoch 145] ogbg-moltoxcast: 0.745914 val loss: 0.209180
[Epoch 145] ogbg-moltoxcast: 0.756322 test loss: 0.220739
[Epoch 146; Iter     5/  229] train: loss: 0.1212660
[Epoch 146; Iter    35/  229] train: loss: 0.1423658
[Epoch 146; Iter    65/  229] train: loss: 0.1932238
[Epoch 146; Iter    95/  229] train: loss: 0.1302031
[Epoch 146; Iter   125/  229] train: loss: 0.1656827
[Epoch 146; Iter   155/  229] train: loss: 0.1334191
[Epoch 146; Iter   185/  229] train: loss: 0.1475012
[Epoch 146; Iter   215/  229] train: loss: 0.1146560
[Epoch 146] ogbg-moltoxcast: 0.745506 val loss: 0.207635
[Epoch 146] ogbg-moltoxcast: 0.757566 test loss: 0.219117
[Epoch 147; Iter    16/  229] train: loss: 0.1360530
[Epoch 147; Iter    46/  229] train: loss: 0.1743450
[Epoch 147; Iter    76/  229] train: loss: 0.1293157
[Epoch 147; Iter   106/  229] train: loss: 0.1512267
[Epoch 147; Iter   136/  229] train: loss: 0.1422317
[Epoch 147; Iter   166/  229] train: loss: 0.1291531
[Epoch 147; Iter   196/  229] train: loss: 0.0721748
[Epoch 147; Iter   226/  229] train: loss: 0.1723784
[Epoch 147] ogbg-moltoxcast: 0.744328 val loss: 0.209170
[Epoch 147] ogbg-moltoxcast: 0.756432 test loss: 0.221553
[Epoch 148; Iter    27/  229] train: loss: 0.0948730
[Epoch 148; Iter    57/  229] train: loss: 0.1465878
[Epoch 148; Iter    87/  229] train: loss: 0.1447378
[Epoch 148; Iter   117/  229] train: loss: 0.1391157
[Epoch 148; Iter   147/  229] train: loss: 0.1683716
[Epoch 148; Iter   177/  229] train: loss: 0.1707617
[Epoch 148; Iter   207/  229] train: loss: 0.1361846
[Epoch 148] ogbg-moltoxcast: 0.746124 val loss: 0.206572
[Epoch 148] ogbg-moltoxcast: 0.755979 test loss: 0.218334
[Epoch 149; Iter     8/  229] train: loss: 0.1745475
[Epoch 149; Iter    38/  229] train: loss: 0.1023303
[Epoch 149; Iter    68/  229] train: loss: 0.1595102
[Epoch 149; Iter    98/  229] train: loss: 0.1895852
[Epoch 149; Iter   128/  229] train: loss: 0.1119136
[Epoch 149; Iter   158/  229] train: loss: 0.1040707
[Epoch 149; Iter   188/  229] train: loss: 0.1211844
[Epoch 149; Iter   218/  229] train: loss: 0.1065886
[Epoch 149] ogbg-moltoxcast: 0.744782 val loss: 0.208580
[Epoch 149] ogbg-moltoxcast: 0.755678 test loss: 0.220895
[Epoch 150; Iter    19/  229] train: loss: 0.1147176
[Epoch 150; Iter    49/  229] train: loss: 0.1079545
[Epoch 150; Iter    79/  229] train: loss: 0.1085420
[Epoch 150; Iter   109/  229] train: loss: 0.1260130
[Epoch 150; Iter   139/  229] train: loss: 0.2733583
[Epoch 150; Iter   169/  229] train: loss: 0.1418662
[Epoch 150; Iter   199/  229] train: loss: 0.1431879
[Epoch 150; Iter   229/  229] train: loss: 0.1201887
[Epoch 150] ogbg-moltoxcast: 0.745374 val loss: 0.209742
[Epoch 150] ogbg-moltoxcast: 0.756027 test loss: 0.218629
[Epoch 151; Iter    30/  229] train: loss: 0.1651917
[Epoch 151; Iter    60/  229] train: loss: 0.0975081
[Epoch 151; Iter    90/  229] train: loss: 0.1018412
[Epoch 151; Iter   120/  229] train: loss: 0.1426659
[Epoch 151; Iter   150/  229] train: loss: 0.1095598
[Epoch 151; Iter   180/  229] train: loss: 0.1322404
[Epoch 151; Iter   210/  229] train: loss: 0.0782733
[Epoch 151] ogbg-moltoxcast: 0.744854 val loss: 0.209527
[Epoch 151] ogbg-moltoxcast: 0.753525 test loss: 0.221812
[Epoch 152; Iter    11/  229] train: loss: 0.1469175
[Epoch 152; Iter    41/  229] train: loss: 0.1398354
[Epoch 152; Iter    71/  229] train: loss: 0.1275777
[Epoch 152; Iter   101/  229] train: loss: 0.1574563
[Epoch 152; Iter   131/  229] train: loss: 0.1144794
[Epoch 152; Iter   161/  229] train: loss: 0.1302256
[Epoch 152; Iter   191/  229] train: loss: 0.1938715
[Epoch 152; Iter   221/  229] train: loss: 0.1246508
[Epoch 152] ogbg-moltoxcast: 0.743644 val loss: 0.210767
[Epoch 152] ogbg-moltoxcast: 0.754193 test loss: 0.219834
[Epoch 153; Iter    22/  229] train: loss: 0.1236131
[Epoch 153; Iter    52/  229] train: loss: 0.0834702
[Epoch 153; Iter    82/  229] train: loss: 0.1058228
[Epoch 153; Iter   112/  229] train: loss: 0.1317081
[Epoch 153; Iter   142/  229] train: loss: 0.1470156
[Epoch 153; Iter   172/  229] train: loss: 0.1081643
[Epoch 153; Iter   202/  229] train: loss: 0.1701161
[Epoch 153] ogbg-moltoxcast: 0.745930 val loss: 0.208087
[Epoch 153] ogbg-moltoxcast: 0.753736 test loss: 0.219171
[Epoch 154; Iter     3/  229] train: loss: 0.1201601
[Epoch 154; Iter    33/  229] train: loss: 0.1614501
[Epoch 154; Iter    63/  229] train: loss: 0.1368664
[Epoch 154; Iter    93/  229] train: loss: 0.1437244
[Epoch 154; Iter   123/  229] train: loss: 0.1124572
[Epoch 154; Iter   153/  229] train: loss: 0.1375863
[Epoch 154; Iter   183/  229] train: loss: 0.1983001
[Epoch 154; Iter   213/  229] train: loss: 0.1127347
[Epoch 154] ogbg-moltoxcast: 0.743066 val loss: 0.208449
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 154] ogbg-moltoxcast: 0.755545 test loss: 0.219928
[Epoch 155; Iter    14/  229] train: loss: 0.1407262
[Epoch 155; Iter    44/  229] train: loss: 0.0752045
[Epoch 155; Iter    74/  229] train: loss: 0.1097440
[Epoch 155; Iter   104/  229] train: loss: 0.1138040
[Epoch 155; Iter   134/  229] train: loss: 0.1670043
[Epoch 155; Iter   164/  229] train: loss: 0.1151686
[Epoch 155; Iter   194/  229] train: loss: 0.1363894
[Epoch 155; Iter   224/  229] train: loss: 0.0992076
[Epoch 155] ogbg-moltoxcast: 0.744505 val loss: 0.210103
[Epoch 155] ogbg-moltoxcast: 0.755662 test loss: 0.221702
[Epoch 156; Iter    25/  229] train: loss: 0.1327277
[Epoch 156; Iter    55/  229] train: loss: 0.0964861
[Epoch 156; Iter    85/  229] train: loss: 0.1402135
[Epoch 156; Iter   115/  229] train: loss: 0.1645506
[Epoch 156; Iter   145/  229] train: loss: 0.1176883
[Epoch 156; Iter   175/  229] train: loss: 0.1525903
[Epoch 156; Iter   205/  229] train: loss: 0.0855237
[Epoch 156] ogbg-moltoxcast: 0.746876 val loss: 0.208949
[Epoch 156] ogbg-moltoxcast: 0.754126 test loss: 0.222140
[Epoch 157; Iter     6/  229] train: loss: 0.1400491
[Epoch 157; Iter    36/  229] train: loss: 0.1298265
[Epoch 157; Iter    66/  229] train: loss: 0.1507936
[Epoch 157; Iter    96/  229] train: loss: 0.1468066
[Epoch 157; Iter   126/  229] train: loss: 0.1488412
[Epoch 157; Iter   156/  229] train: loss: 0.1642786
[Epoch 157; Iter   186/  229] train: loss: 0.1333585
[Epoch 157; Iter   216/  229] train: loss: 0.1484803
[Epoch 157] ogbg-moltoxcast: 0.745864 val loss: 0.207599
[Epoch 157] ogbg-moltoxcast: 0.754368 test loss: 0.218363
[Epoch 158; Iter    17/  229] train: loss: 0.1238481
[Epoch 158; Iter    47/  229] train: loss: 0.1086925
[Epoch 158; Iter    77/  229] train: loss: 0.1064212
[Epoch 158; Iter   107/  229] train: loss: 0.0941531
[Epoch 158; Iter   137/  229] train: loss: 0.1599567
[Epoch 158; Iter   167/  229] train: loss: 0.0785706
[Epoch 158; Iter   197/  229] train: loss: 0.1579123
[Epoch 158; Iter   227/  229] train: loss: 0.1937488
[Epoch 158] ogbg-moltoxcast: 0.742712 val loss: 0.210803
[Epoch 158] ogbg-moltoxcast: 0.752599 test loss: 0.220415
[Epoch 159; Iter    28/  229] train: loss: 0.1347225
[Epoch 159; Iter    58/  229] train: loss: 0.1147841
[Epoch 159; Iter    88/  229] train: loss: 0.1171065
[Epoch 159; Iter   118/  229] train: loss: 0.0991083
[Epoch 159; Iter   148/  229] train: loss: 0.1414838
[Epoch 159; Iter   178/  229] train: loss: 0.1337423
[Epoch 159; Iter   208/  229] train: loss: 0.1782050
[Epoch 159] ogbg-moltoxcast: 0.742450 val loss: 0.209123
[Epoch 159] ogbg-moltoxcast: 0.755458 test loss: 0.219524
[Epoch 160; Iter     9/  229] train: loss: 0.1524291
[Epoch 160; Iter    39/  229] train: loss: 0.0896746
[Epoch 160; Iter    69/  229] train: loss: 0.1268321
[Epoch 160; Iter    99/  229] train: loss: 0.1475586
[Epoch 160; Iter   129/  229] train: loss: 0.0696243
[Epoch 160; Iter   159/  229] train: loss: 0.1202271
[Epoch 160; Iter   189/  229] train: loss: 0.1220396
[Epoch 160; Iter   219/  229] train: loss: 0.0882147
[Epoch 160] ogbg-moltoxcast: 0.742914 val loss: 0.209460
[Epoch 160] ogbg-moltoxcast: 0.755361 test loss: 0.218990
[Epoch 161; Iter    20/  229] train: loss: 0.1690428
[Epoch 161; Iter    50/  229] train: loss: 0.1334359
[Epoch 161; Iter    80/  229] train: loss: 0.1008336
[Epoch 161; Iter   110/  229] train: loss: 0.1470696
[Epoch 161; Iter   140/  229] train: loss: 0.0931511
[Epoch 161; Iter   170/  229] train: loss: 0.1566294
[Epoch 161; Iter   200/  229] train: loss: 0.1164024
[Epoch 161] ogbg-moltoxcast: 0.743260 val loss: 0.210696
[Epoch 161] ogbg-moltoxcast: 0.753345 test loss: 0.219163
Early stopping criterion based on -ogbg-moltoxcast- that should be max reached after 161 epochs. Best model checkpoint was in epoch 101.
Statistics on  val_best_checkpoint
mean_pred: -3.53200364112854
std_pred: 2.790511131286621
mean_targets: nan
std_targets: nan
prcauc: 0.43312618682395115
rocauc: 0.7504292104636049
ogbg-moltoxcast: 0.7504292104636049
OGBNanLabelBCEWithLogitsLoss: 0.20165262987901425
Statistics on  test
mean_pred: -3.565617084503174
std_pred: 3.1923842430114746
mean_targets: nan
std_targets: nan
prcauc: 0.45202557833864393
rocauc: 0.760729970436384
ogbg-moltoxcast: 0.760729970436384
OGBNanLabelBCEWithLogitsLoss: 0.2423401593134321
Statistics on  train
mean_pred: -3.619490623474121
std_pred: 7.72901725769043
mean_targets: nan
std_targets: nan
prcauc: 0.6321807254397027
rocauc: 0.9045564069374118
ogbg-moltoxcast: 0.9045564069374118
OGBNanLabelBCEWithLogitsLoss: 0.15110400432972929
All runs completed.
