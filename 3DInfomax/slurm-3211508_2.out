>>> Starting run for dataset: clintox
Running configs_static_noise_experiments/3DInfomax/clintox/noise=0.0.yml on cuda:0
Running configs_static_noise_experiments/3DInfomax/clintox/noise=0.05.yml on cuda:1
Running configs_static_noise_experiments/3DInfomax/clintox/noise=0.1.yml on cuda:2
Running configs_static_noise_experiments/3DInfomax/clintox/noise=0.2.yml on cuda:3
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.1/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.1_5_26-05_09-18-52
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.1
logdir: runs/static_noise/3DInfomax/clintox/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6933711
[Epoch 1] ogbg-molclintox: 0.427738 val loss: 0.694526
[Epoch 1] ogbg-molclintox: 0.592029 test loss: 0.694305
[Epoch 2; Iter    20/   40] train: loss: 0.6918293
[Epoch 2] ogbg-molclintox: 0.513299 val loss: 0.696608
[Epoch 2] ogbg-molclintox: 0.589806 test loss: 0.696913
[Epoch 3; Iter    10/   40] train: loss: 0.6926743
[Epoch 3; Iter    40/   40] train: loss: 0.6926748
[Epoch 3] ogbg-molclintox: 0.568217 val loss: 0.694240
[Epoch 3] ogbg-molclintox: 0.634883 test loss: 0.692933
[Epoch 4; Iter    30/   40] train: loss: 0.6921178
[Epoch 4] ogbg-molclintox: 0.573984 val loss: 0.693945
[Epoch 4] ogbg-molclintox: 0.657769 test loss: 0.692227
[Epoch 5; Iter    20/   40] train: loss: 0.6913666
[Epoch 5] ogbg-molclintox: 0.580253 val loss: 0.693056
[Epoch 5] ogbg-molclintox: 0.654785 test loss: 0.692012
[Epoch 6; Iter    10/   40] train: loss: 0.6915042
[Epoch 6; Iter    40/   40] train: loss: 0.6910783
[Epoch 6] ogbg-molclintox: 0.591579 val loss: 0.692919
[Epoch 6] ogbg-molclintox: 0.644341 test loss: 0.692352
[Epoch 7; Iter    30/   40] train: loss: 0.6914231
[Epoch 7] ogbg-molclintox: 0.575895 val loss: 0.692380
[Epoch 7] ogbg-molclintox: 0.645103 test loss: 0.691213
[Epoch 8; Iter    20/   40] train: loss: 0.6901814
[Epoch 8] ogbg-molclintox: 0.577407 val loss: 0.690527
[Epoch 8] ogbg-molclintox: 0.649025 test loss: 0.689379
[Epoch 9; Iter    10/   40] train: loss: 0.6897672
[Epoch 9; Iter    40/   40] train: loss: 0.6856605
[Epoch 9] ogbg-molclintox: 0.589456 val loss: 0.690413
[Epoch 9] ogbg-molclintox: 0.646440 test loss: 0.690323
[Epoch 10; Iter    30/   40] train: loss: 0.6889226
[Epoch 10] ogbg-molclintox: 0.583201 val loss: 0.688764
[Epoch 10] ogbg-molclintox: 0.647565 test loss: 0.688106
[Epoch 11; Iter    20/   40] train: loss: 0.6861290
[Epoch 11] ogbg-molclintox: 0.570751 val loss: 0.688092
[Epoch 11] ogbg-molclintox: 0.631660 test loss: 0.687470
[Epoch 12; Iter    10/   40] train: loss: 0.6885405
[Epoch 12; Iter    40/   40] train: loss: 0.6872497
[Epoch 12] ogbg-molclintox: 0.579055 val loss: 0.687417
[Epoch 12] ogbg-molclintox: 0.644853 test loss: 0.686637
[Epoch 13; Iter    30/   40] train: loss: 0.6871328
[Epoch 13] ogbg-molclintox: 0.580415 val loss: 0.685070
[Epoch 13] ogbg-molclintox: 0.658072 test loss: 0.684138
[Epoch 14; Iter    20/   40] train: loss: 0.6831879
[Epoch 14] ogbg-molclintox: 0.587696 val loss: 0.683231
[Epoch 14] ogbg-molclintox: 0.646153 test loss: 0.683105
[Epoch 15; Iter    10/   40] train: loss: 0.6824418
[Epoch 15; Iter    40/   40] train: loss: 0.6806570
[Epoch 15] ogbg-molclintox: 0.605976 val loss: 0.681459
[Epoch 15] ogbg-molclintox: 0.654598 test loss: 0.682134
[Epoch 16; Iter    30/   40] train: loss: 0.6797196
[Epoch 16] ogbg-molclintox: 0.607350 val loss: 0.679684
[Epoch 16] ogbg-molclintox: 0.651976 test loss: 0.680323
[Epoch 17; Iter    20/   40] train: loss: 0.6810454
[Epoch 17] ogbg-molclintox: 0.608236 val loss: 0.677424
[Epoch 17] ogbg-molclintox: 0.653212 test loss: 0.677907
[Epoch 18; Iter    10/   40] train: loss: 0.6777096
[Epoch 18; Iter    40/   40] train: loss: 0.6766698
[Epoch 18] ogbg-molclintox: 0.684618 val loss: 0.627014
[Epoch 18] ogbg-molclintox: 0.608134 test loss: 0.667891
[Epoch 19; Iter    30/   40] train: loss: 0.6510240
[Epoch 19] ogbg-molclintox: 0.695719 val loss: 0.580464
[Epoch 19] ogbg-molclintox: 0.554630 test loss: 0.660118
[Epoch 20; Iter    20/   40] train: loss: 0.5969153
[Epoch 20] ogbg-molclintox: 0.629752 val loss: 0.400274
[Epoch 20] ogbg-molclintox: 0.583661 test loss: 0.500848
[Epoch 21; Iter    10/   40] train: loss: 0.5451475
[Epoch 21; Iter    40/   40] train: loss: 0.4842538
[Epoch 21] ogbg-molclintox: 0.722953 val loss: 0.608999
[Epoch 21] ogbg-molclintox: 0.616651 test loss: 0.641418
[Epoch 22; Iter    30/   40] train: loss: 0.4812559
[Epoch 22] ogbg-molclintox: 0.658136 val loss: 0.303386
[Epoch 22] ogbg-molclintox: 0.600137 test loss: 0.432138
[Epoch 23; Iter    20/   40] train: loss: 0.3421293
[Epoch 23] ogbg-molclintox: 0.596576 val loss: 0.205135
[Epoch 23] ogbg-molclintox: 0.607309 test loss: 0.321571
[Epoch 24; Iter    10/   40] train: loss: 0.3122967
[Epoch 24; Iter    40/   40] train: loss: 0.4615082
[Epoch 24] ogbg-molclintox: 0.572188 val loss: 0.212231
[Epoch 24] ogbg-molclintox: 0.585148 test loss: 0.402735
[Epoch 25; Iter    30/   40] train: loss: 0.3303146
[Epoch 25] ogbg-molclintox: 0.594527 val loss: 0.519443
[Epoch 25] ogbg-molclintox: 0.568671 test loss: 1.154234
[Epoch 26; Iter    20/   40] train: loss: 0.2734442
[Epoch 26] ogbg-molclintox: 0.598111 val loss: 0.645025
[Epoch 26] ogbg-molclintox: 0.586709 test loss: 1.805318
[Epoch 27; Iter    10/   40] train: loss: 0.2667945
[Epoch 27; Iter    40/   40] train: loss: 0.1087691
[Epoch 27] ogbg-molclintox: 0.633562 val loss: 0.761622
[Epoch 27] ogbg-molclintox: 0.584359 test loss: 2.028339
[Epoch 28; Iter    30/   40] train: loss: 0.3946221
[Epoch 28] ogbg-molclintox: 0.769420 val loss: 1.267457
[Epoch 28] ogbg-molclintox: 0.550794 test loss: 2.183829
[Epoch 29; Iter    20/   40] train: loss: 0.2596658
[Epoch 29] ogbg-molclintox: 0.662732 val loss: 0.834679
[Epoch 29] ogbg-molclintox: 0.556229 test loss: 1.528999
[Epoch 30; Iter    10/   40] train: loss: 0.1835131
[Epoch 30; Iter    40/   40] train: loss: 0.3275768
[Epoch 30] ogbg-molclintox: 0.605691 val loss: 0.819923
[Epoch 30] ogbg-molclintox: 0.576153 test loss: 2.014689
[Epoch 31; Iter    30/   40] train: loss: 0.2925587
[Epoch 31] ogbg-molclintox: 0.729637 val loss: 1.073748
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.05/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.05_4_26-05_09-18-49
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.05
logdir: runs/static_noise/3DInfomax/clintox/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6929847
[Epoch 1] ogbg-molclintox: 0.567004 val loss: 0.693050
[Epoch 1] ogbg-molclintox: 0.470920 test loss: 0.693322
[Epoch 2; Iter    20/   40] train: loss: 0.6926981
[Epoch 2] ogbg-molclintox: 0.543853 val loss: 0.693082
[Epoch 2] ogbg-molclintox: 0.492741 test loss: 0.694804
[Epoch 3; Iter    10/   40] train: loss: 0.6926386
[Epoch 3; Iter    40/   40] train: loss: 0.6896236
[Epoch 3] ogbg-molclintox: 0.514707 val loss: 0.693359
[Epoch 3] ogbg-molclintox: 0.490717 test loss: 0.695522
[Epoch 4; Iter    30/   40] train: loss: 0.6921037
[Epoch 4] ogbg-molclintox: 0.515519 val loss: 0.693406
[Epoch 4] ogbg-molclintox: 0.502745 test loss: 0.695415
[Epoch 5; Iter    20/   40] train: loss: 0.6928111
[Epoch 5] ogbg-molclintox: 0.510062 val loss: 0.691718
[Epoch 5] ogbg-molclintox: 0.493840 test loss: 0.694412
[Epoch 6; Iter    10/   40] train: loss: 0.6916854
[Epoch 6; Iter    40/   40] train: loss: 0.6906405
[Epoch 6] ogbg-molclintox: 0.496677 val loss: 0.690860
[Epoch 6] ogbg-molclintox: 0.492977 test loss: 0.693809
[Epoch 7; Iter    30/   40] train: loss: 0.6898060
[Epoch 7] ogbg-molclintox: 0.524210 val loss: 0.688507
[Epoch 7] ogbg-molclintox: 0.484995 test loss: 0.692128
[Epoch 8; Iter    20/   40] train: loss: 0.6908683
[Epoch 8] ogbg-molclintox: 0.507827 val loss: 0.689441
[Epoch 8] ogbg-molclintox: 0.496574 test loss: 0.691954
[Epoch 9; Iter    10/   40] train: loss: 0.6895957
[Epoch 9; Iter    40/   40] train: loss: 0.6899903
[Epoch 9] ogbg-molclintox: 0.493317 val loss: 0.687117
[Epoch 9] ogbg-molclintox: 0.495551 test loss: 0.690659
[Epoch 10; Iter    30/   40] train: loss: 0.6882603
[Epoch 10] ogbg-molclintox: 0.502883 val loss: 0.686431
[Epoch 10] ogbg-molclintox: 0.498460 test loss: 0.689492
[Epoch 11; Iter    20/   40] train: loss: 0.6851686
[Epoch 11] ogbg-molclintox: 0.511661 val loss: 0.683868
[Epoch 11] ogbg-molclintox: 0.494086 test loss: 0.687616
[Epoch 12; Iter    10/   40] train: loss: 0.6838735
[Epoch 12; Iter    40/   40] train: loss: 0.6841221
[Epoch 12] ogbg-molclintox: 0.500971 val loss: 0.683619
[Epoch 12] ogbg-molclintox: 0.498647 test loss: 0.686909
[Epoch 13; Iter    30/   40] train: loss: 0.6833811
[Epoch 13] ogbg-molclintox: 0.496188 val loss: 0.680506
[Epoch 13] ogbg-molclintox: 0.493313 test loss: 0.684647
[Epoch 14; Iter    20/   40] train: loss: 0.6815518
[Epoch 14] ogbg-molclintox: 0.496301 val loss: 0.678812
[Epoch 14] ogbg-molclintox: 0.491913 test loss: 0.683325
[Epoch 15; Iter    10/   40] train: loss: 0.6807846
[Epoch 15; Iter    40/   40] train: loss: 0.6766640
[Epoch 15] ogbg-molclintox: 0.496076 val loss: 0.676646
[Epoch 15] ogbg-molclintox: 0.499734 test loss: 0.680769
[Epoch 16; Iter    30/   40] train: loss: 0.6765720
[Epoch 16] ogbg-molclintox: 0.487885 val loss: 0.675425
[Epoch 16] ogbg-molclintox: 0.489727 test loss: 0.679585
[Epoch 17; Iter    20/   40] train: loss: 0.6742538
[Epoch 17] ogbg-molclintox: 0.495538 val loss: 0.673368
[Epoch 17] ogbg-molclintox: 0.503006 test loss: 0.677397
[Epoch 18; Iter    10/   40] train: loss: 0.6714461
[Epoch 18; Iter    40/   40] train: loss: 0.6599069
[Epoch 18] ogbg-molclintox: 0.684481 val loss: 0.625622
[Epoch 18] ogbg-molclintox: 0.621410 test loss: 0.656604
[Epoch 19; Iter    30/   40] train: loss: 0.6327177
[Epoch 19] ogbg-molclintox: 0.783778 val loss: 0.626146
[Epoch 19] ogbg-molclintox: 0.585196 test loss: 0.645405
[Epoch 20; Iter    20/   40] train: loss: 0.5937946
[Epoch 20] ogbg-molclintox: 0.860572 val loss: 0.600272
[Epoch 20] ogbg-molclintox: 0.584270 test loss: 0.604691
[Epoch 21; Iter    10/   40] train: loss: 0.5372263
[Epoch 21; Iter    40/   40] train: loss: 0.4758046
[Epoch 21] ogbg-molclintox: 0.672856 val loss: 0.432605
[Epoch 21] ogbg-molclintox: 0.591281 test loss: 0.495518
[Epoch 22; Iter    30/   40] train: loss: 0.4425176
[Epoch 22] ogbg-molclintox: 0.676627 val loss: 0.323283
[Epoch 22] ogbg-molclintox: 0.590743 test loss: 0.410151
[Epoch 23; Iter    20/   40] train: loss: 0.4203210
[Epoch 23] ogbg-molclintox: 0.816656 val loss: 0.328897
[Epoch 23] ogbg-molclintox: 0.588969 test loss: 0.353452
[Epoch 24; Iter    10/   40] train: loss: 0.3372033
[Epoch 24; Iter    40/   40] train: loss: 0.3438239
[Epoch 24] ogbg-molclintox: 0.685293 val loss: 0.245857
[Epoch 24] ogbg-molclintox: 0.602461 test loss: 0.341890
[Epoch 25; Iter    30/   40] train: loss: 0.3211019
[Epoch 25] ogbg-molclintox: 0.678974 val loss: 0.210235
[Epoch 25] ogbg-molclintox: 0.608332 test loss: 0.296388
[Epoch 26; Iter    20/   40] train: loss: 0.1892913
[Epoch 26] ogbg-molclintox: 0.698716 val loss: 0.183757
[Epoch 26] ogbg-molclintox: 0.574203 test loss: 0.274924
[Epoch 27; Iter    10/   40] train: loss: 0.2505544
[Epoch 27; Iter    40/   40] train: loss: 0.1863065
[Epoch 27] ogbg-molclintox: 0.667012 val loss: 0.164348
[Epoch 27] ogbg-molclintox: 0.567670 test loss: 0.245027
[Epoch 28; Iter    30/   40] train: loss: 0.2227028
[Epoch 28] ogbg-molclintox: 0.674279 val loss: 0.151735
[Epoch 28] ogbg-molclintox: 0.562075 test loss: 0.246996
[Epoch 29; Iter    20/   40] train: loss: 0.3854032
[Epoch 29] ogbg-molclintox: 0.657921 val loss: 0.179388
[Epoch 29] ogbg-molclintox: 0.583810 test loss: 0.268470
[Epoch 30; Iter    10/   40] train: loss: 0.2035316
[Epoch 30; Iter    40/   40] train: loss: 0.0879044
[Epoch 30] ogbg-molclintox: 0.767420 val loss: 0.329419
[Epoch 30] ogbg-molclintox: 0.558975 test loss: 0.885151
[Epoch 31; Iter    30/   40] train: loss: 0.2231581
[Epoch 31] ogbg-molclintox: 0.821375 val loss: 0.466620
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.05/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.05_5_26-05_09-18-47
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.05
logdir: runs/static_noise/3DInfomax/clintox/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6935953
[Epoch 1] ogbg-molclintox: 0.431874 val loss: 0.694076
[Epoch 1] ogbg-molclintox: 0.608539 test loss: 0.694111
[Epoch 2; Iter    20/   40] train: loss: 0.6919542
[Epoch 2] ogbg-molclintox: 0.509690 val loss: 0.695177
[Epoch 2] ogbg-molclintox: 0.592238 test loss: 0.696321
[Epoch 3; Iter    10/   40] train: loss: 0.6925600
[Epoch 3; Iter    40/   40] train: loss: 0.6927187
[Epoch 3] ogbg-molclintox: 0.540695 val loss: 0.695291
[Epoch 3] ogbg-molclintox: 0.613316 test loss: 0.695139
[Epoch 4; Iter    30/   40] train: loss: 0.6919346
[Epoch 4] ogbg-molclintox: 0.550808 val loss: 0.693855
[Epoch 4] ogbg-molclintox: 0.628844 test loss: 0.693336
[Epoch 5; Iter    20/   40] train: loss: 0.6902543
[Epoch 5] ogbg-molclintox: 0.557127 val loss: 0.693310
[Epoch 5] ogbg-molclintox: 0.627697 test loss: 0.692844
[Epoch 6; Iter    10/   40] train: loss: 0.6910651
[Epoch 6; Iter    40/   40] train: loss: 0.6911023
[Epoch 6] ogbg-molclintox: 0.573372 val loss: 0.693549
[Epoch 6] ogbg-molclintox: 0.621788 test loss: 0.693670
[Epoch 7; Iter    30/   40] train: loss: 0.6918955
[Epoch 7] ogbg-molclintox: 0.550085 val loss: 0.691249
[Epoch 7] ogbg-molclintox: 0.626498 test loss: 0.691276
[Epoch 8; Iter    20/   40] train: loss: 0.6906922
[Epoch 8] ogbg-molclintox: 0.559425 val loss: 0.691238
[Epoch 8] ogbg-molclintox: 0.623099 test loss: 0.691329
[Epoch 9; Iter    10/   40] train: loss: 0.6886585
[Epoch 9; Iter    40/   40] train: loss: 0.6884519
[Epoch 9] ogbg-molclintox: 0.554217 val loss: 0.690492
[Epoch 9] ogbg-molclintox: 0.624074 test loss: 0.690499
[Epoch 10; Iter    30/   40] train: loss: 0.6895220
[Epoch 10] ogbg-molclintox: 0.569440 val loss: 0.688345
[Epoch 10] ogbg-molclintox: 0.629946 test loss: 0.688539
[Epoch 11; Iter    20/   40] train: loss: 0.6870890
[Epoch 11] ogbg-molclintox: 0.547987 val loss: 0.688214
[Epoch 11] ogbg-molclintox: 0.614441 test loss: 0.688545
[Epoch 12; Iter    10/   40] train: loss: 0.6879184
[Epoch 12; Iter    40/   40] train: loss: 0.6872337
[Epoch 12] ogbg-molclintox: 0.561073 val loss: 0.686786
[Epoch 12] ogbg-molclintox: 0.616977 test loss: 0.687323
[Epoch 13; Iter    30/   40] train: loss: 0.6846140
[Epoch 13] ogbg-molclintox: 0.573759 val loss: 0.685692
[Epoch 13] ogbg-molclintox: 0.634506 test loss: 0.685685
[Epoch 14; Iter    20/   40] train: loss: 0.6829956
[Epoch 14] ogbg-molclintox: 0.567753 val loss: 0.684602
[Epoch 14] ogbg-molclintox: 0.618964 test loss: 0.684848
[Epoch 15; Iter    10/   40] train: loss: 0.6822841
[Epoch 15; Iter    40/   40] train: loss: 0.6801783
[Epoch 15] ogbg-molclintox: 0.591315 val loss: 0.682851
[Epoch 15] ogbg-molclintox: 0.623738 test loss: 0.684147
[Epoch 16; Iter    30/   40] train: loss: 0.6797404
[Epoch 16] ogbg-molclintox: 0.598920 val loss: 0.680273
[Epoch 16] ogbg-molclintox: 0.631171 test loss: 0.681826
[Epoch 17; Iter    20/   40] train: loss: 0.6821252
[Epoch 17] ogbg-molclintox: 0.587408 val loss: 0.678762
[Epoch 17] ogbg-molclintox: 0.627536 test loss: 0.680020
[Epoch 18; Iter    10/   40] train: loss: 0.6765349
[Epoch 18; Iter    40/   40] train: loss: 0.6861718
[Epoch 18] ogbg-molclintox: 0.680123 val loss: 0.635477
[Epoch 18] ogbg-molclintox: 0.607294 test loss: 0.672403
[Epoch 19; Iter    30/   40] train: loss: 0.6498826
[Epoch 19] ogbg-molclintox: 0.702536 val loss: 0.633262
[Epoch 19] ogbg-molclintox: 0.608844 test loss: 0.673200
[Epoch 20; Iter    20/   40] train: loss: 0.6018755
[Epoch 20] ogbg-molclintox: 0.678813 val loss: 0.500294
[Epoch 20] ogbg-molclintox: 0.583273 test loss: 0.526263
[Epoch 21; Iter    10/   40] train: loss: 0.5607607
[Epoch 21; Iter    40/   40] train: loss: 0.4794850
[Epoch 21] ogbg-molclintox: 0.818705 val loss: 0.527091
[Epoch 21] ogbg-molclintox: 0.588069 test loss: 0.516890
[Epoch 22; Iter    30/   40] train: loss: 0.4897953
[Epoch 22] ogbg-molclintox: 0.668639 val loss: 0.483955
[Epoch 22] ogbg-molclintox: 0.412947 test loss: 0.572405
[Epoch 23; Iter    20/   40] train: loss: 0.3410433
[Epoch 23] ogbg-molclintox: 0.677864 val loss: 0.233998
[Epoch 23] ogbg-molclintox: 0.646119 test loss: 0.324262
[Epoch 24; Iter    10/   40] train: loss: 0.3117208
[Epoch 24; Iter    40/   40] train: loss: 0.4729318
[Epoch 24] ogbg-molclintox: 0.778447 val loss: 0.298363
[Epoch 24] ogbg-molclintox: 0.577513 test loss: 0.364648
[Epoch 25; Iter    30/   40] train: loss: 0.2616893
[Epoch 25] ogbg-molclintox: 0.770066 val loss: 0.185316
[Epoch 25] ogbg-molclintox: 0.642761 test loss: 0.342027
[Epoch 26; Iter    20/   40] train: loss: 0.2580362
[Epoch 26] ogbg-molclintox: 0.703949 val loss: 0.198777
[Epoch 26] ogbg-molclintox: 0.666293 test loss: 0.327757
[Epoch 27; Iter    10/   40] train: loss: 0.2613575
[Epoch 27; Iter    40/   40] train: loss: 0.1022349
[Epoch 27] ogbg-molclintox: 0.721456 val loss: 0.179904
[Epoch 27] ogbg-molclintox: 0.713287 test loss: 0.301339
[Epoch 28; Iter    30/   40] train: loss: 0.2972327
[Epoch 28] ogbg-molclintox: 0.796253 val loss: 0.200012
[Epoch 28] ogbg-molclintox: 0.659783 test loss: 0.268865
[Epoch 29; Iter    20/   40] train: loss: 0.2376857
[Epoch 29] ogbg-molclintox: 0.746666 val loss: 0.150792
[Epoch 29] ogbg-molclintox: 0.639436 test loss: 0.280815
[Epoch 30; Iter    10/   40] train: loss: 0.1755270
[Epoch 30; Iter    40/   40] train: loss: 0.3306270
[Epoch 30] ogbg-molclintox: 0.693347 val loss: 0.160428
[Epoch 30] ogbg-molclintox: 0.637487 test loss: 0.299040
[Epoch 31; Iter    30/   40] train: loss: 0.3232764
[Epoch 31] ogbg-molclintox: 0.714987 val loss: 0.156191
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.1/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.1_4_26-05_09-18-52
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.1
logdir: runs/static_noise/3DInfomax/clintox/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6928388
[Epoch 1] ogbg-molclintox: 0.518481 val loss: 0.692703
[Epoch 1] ogbg-molclintox: 0.465672 test loss: 0.693261
[Epoch 2; Iter    20/   40] train: loss: 0.6930148
[Epoch 2] ogbg-molclintox: 0.478196 val loss: 0.691883
[Epoch 2] ogbg-molclintox: 0.492402 test loss: 0.695182
[Epoch 3; Iter    10/   40] train: loss: 0.6918503
[Epoch 3; Iter    40/   40] train: loss: 0.6893016
[Epoch 3] ogbg-molclintox: 0.474348 val loss: 0.692489
[Epoch 3] ogbg-molclintox: 0.493575 test loss: 0.696679
[Epoch 4; Iter    30/   40] train: loss: 0.6928839
[Epoch 4] ogbg-molclintox: 0.476221 val loss: 0.693153
[Epoch 4] ogbg-molclintox: 0.496783 test loss: 0.697028
[Epoch 5; Iter    20/   40] train: loss: 0.6915508
[Epoch 5] ogbg-molclintox: 0.489382 val loss: 0.691991
[Epoch 5] ogbg-molclintox: 0.492462 test loss: 0.696518
[Epoch 6; Iter    10/   40] train: loss: 0.6914518
[Epoch 6; Iter    40/   40] train: loss: 0.6905888
[Epoch 6] ogbg-molclintox: 0.467693 val loss: 0.689381
[Epoch 6] ogbg-molclintox: 0.494736 test loss: 0.694662
[Epoch 7; Iter    30/   40] train: loss: 0.6903754
[Epoch 7] ogbg-molclintox: 0.477082 val loss: 0.688635
[Epoch 7] ogbg-molclintox: 0.493011 test loss: 0.693856
[Epoch 8; Iter    20/   40] train: loss: 0.6887509
[Epoch 8] ogbg-molclintox: 0.484349 val loss: 0.689476
[Epoch 8] ogbg-molclintox: 0.501318 test loss: 0.693519
[Epoch 9; Iter    10/   40] train: loss: 0.6883034
[Epoch 9; Iter    40/   40] train: loss: 0.6870247
[Epoch 9] ogbg-molclintox: 0.468641 val loss: 0.687670
[Epoch 9] ogbg-molclintox: 0.493063 test loss: 0.692811
[Epoch 10; Iter    30/   40] train: loss: 0.6872398
[Epoch 10] ogbg-molclintox: 0.469878 val loss: 0.685370
[Epoch 10] ogbg-molclintox: 0.489514 test loss: 0.690608
[Epoch 11; Iter    20/   40] train: loss: 0.6858804
[Epoch 11] ogbg-molclintox: 0.465570 val loss: 0.682468
[Epoch 11] ogbg-molclintox: 0.498046 test loss: 0.688394
[Epoch 12; Iter    10/   40] train: loss: 0.6838781
[Epoch 12; Iter    40/   40] train: loss: 0.6863375
[Epoch 12] ogbg-molclintox: 0.471801 val loss: 0.682458
[Epoch 12] ogbg-molclintox: 0.488614 test loss: 0.687657
[Epoch 13; Iter    30/   40] train: loss: 0.6836339
[Epoch 13] ogbg-molclintox: 0.469541 val loss: 0.680103
[Epoch 13] ogbg-molclintox: 0.490564 test loss: 0.685794
[Epoch 14; Iter    20/   40] train: loss: 0.6825475
[Epoch 14] ogbg-molclintox: 0.472187 val loss: 0.677299
[Epoch 14] ogbg-molclintox: 0.488177 test loss: 0.683839
[Epoch 15; Iter    10/   40] train: loss: 0.6806693
[Epoch 15; Iter    40/   40] train: loss: 0.6766532
[Epoch 15] ogbg-molclintox: 0.476408 val loss: 0.675987
[Epoch 15] ogbg-molclintox: 0.496260 test loss: 0.682445
[Epoch 16; Iter    30/   40] train: loss: 0.6761459
[Epoch 16] ogbg-molclintox: 0.466906 val loss: 0.673370
[Epoch 16] ogbg-molclintox: 0.493048 test loss: 0.679995
[Epoch 17; Iter    20/   40] train: loss: 0.6743186
[Epoch 17] ogbg-molclintox: 0.488145 val loss: 0.672341
[Epoch 17] ogbg-molclintox: 0.494273 test loss: 0.678402
[Epoch 18; Iter    10/   40] train: loss: 0.6714330
[Epoch 18; Iter    40/   40] train: loss: 0.6606502
[Epoch 18] ogbg-molclintox: 0.677126 val loss: 0.585656
[Epoch 18] ogbg-molclintox: 0.599450 test loss: 0.647708
[Epoch 19; Iter    30/   40] train: loss: 0.6356351
[Epoch 19] ogbg-molclintox: 0.678162 val loss: 0.544757
[Epoch 19] ogbg-molclintox: 0.578039 test loss: 0.626777
[Epoch 20; Iter    20/   40] train: loss: 0.5986936
[Epoch 20] ogbg-molclintox: 0.643563 val loss: 0.633385
[Epoch 20] ogbg-molclintox: 0.398731 test loss: 0.587351
[Epoch 21; Iter    10/   40] train: loss: 0.5406214
[Epoch 21; Iter    40/   40] train: loss: 0.4829362
[Epoch 21] ogbg-molclintox: 0.729735 val loss: 0.352066
[Epoch 21] ogbg-molclintox: 0.519866 test loss: 0.423261
[Epoch 22; Iter    30/   40] train: loss: 0.4350055
[Epoch 22] ogbg-molclintox: 0.658708 val loss: 0.381344
[Epoch 22] ogbg-molclintox: 0.548433 test loss: 0.397258
[Epoch 23; Iter    20/   40] train: loss: 0.3984842
[Epoch 23] ogbg-molclintox: 0.623958 val loss: 0.373086
[Epoch 23] ogbg-molclintox: 0.574741 test loss: 0.335666
[Epoch 24; Iter    10/   40] train: loss: 0.3348300
[Epoch 24; Iter    40/   40] train: loss: 0.3329873
[Epoch 24] ogbg-molclintox: 0.635719 val loss: 0.321135
[Epoch 24] ogbg-molclintox: 0.563849 test loss: 0.303570
[Epoch 25; Iter    30/   40] train: loss: 0.3131545
[Epoch 25] ogbg-molclintox: 0.638854 val loss: 0.320797
[Epoch 25] ogbg-molclintox: 0.549733 test loss: 0.268756
[Epoch 26; Iter    20/   40] train: loss: 0.1805355
[Epoch 26] ogbg-molclintox: 0.498178 val loss: 0.856455
[Epoch 26] ogbg-molclintox: 0.368389 test loss: 1.471416
[Epoch 27; Iter    10/   40] train: loss: 0.2685099
[Epoch 27; Iter    40/   40] train: loss: 0.2109369
[Epoch 27] ogbg-molclintox: 0.551160 val loss: 0.717798
[Epoch 27] ogbg-molclintox: 0.405290 test loss: 1.344292
[Epoch 28; Iter    30/   40] train: loss: 0.2145536
[Epoch 28] ogbg-molclintox: 0.520991 val loss: 0.991789
[Epoch 28] ogbg-molclintox: 0.378844 test loss: 1.801745
[Epoch 29; Iter    20/   40] train: loss: 0.3738526
[Epoch 29] ogbg-molclintox: 0.538910 val loss: 0.830764
[Epoch 29] ogbg-molclintox: 0.401629 test loss: 1.782584
[Epoch 30; Iter    10/   40] train: loss: 0.2085174
[Epoch 30; Iter    40/   40] train: loss: 0.0903859
[Epoch 30] ogbg-molclintox: 0.606176 val loss: 0.367315
[Epoch 30] ogbg-molclintox: 0.590893 test loss: 0.260164
[Epoch 31; Iter    30/   40] train: loss: 0.1936047
[Epoch 31] ogbg-molclintox: 0.608960 val loss: 0.368125
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.05/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.05_6_26-05_09-18-49
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.05.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.05
logdir: runs/static_noise/3DInfomax/clintox/noise=0.05
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.05
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6935399
[Epoch 1] ogbg-molclintox: 0.507118 val loss: 0.691567
[Epoch 1] ogbg-molclintox: 0.489394 test loss: 0.692266
[Epoch 2; Iter    20/   40] train: loss: 0.6927610
[Epoch 2] ogbg-molclintox: 0.517716 val loss: 0.686373
[Epoch 2] ogbg-molclintox: 0.497279 test loss: 0.690535
[Epoch 3; Iter    10/   40] train: loss: 0.6945519
[Epoch 3; Iter    40/   40] train: loss: 0.6931198
[Epoch 3] ogbg-molclintox: 0.519101 val loss: 0.684941
[Epoch 3] ogbg-molclintox: 0.492423 test loss: 0.690202
[Epoch 4; Iter    30/   40] train: loss: 0.6923391
[Epoch 4] ogbg-molclintox: 0.502518 val loss: 0.686171
[Epoch 4] ogbg-molclintox: 0.478034 test loss: 0.691258
[Epoch 5; Iter    20/   40] train: loss: 0.6913912
[Epoch 5] ogbg-molclintox: 0.512108 val loss: 0.685876
[Epoch 5] ogbg-molclintox: 0.488213 test loss: 0.690686
[Epoch 6; Iter    10/   40] train: loss: 0.6909961
[Epoch 6; Iter    40/   40] train: loss: 0.6904283
[Epoch 6] ogbg-molclintox: 0.524808 val loss: 0.684934
[Epoch 6] ogbg-molclintox: 0.489375 test loss: 0.689575
[Epoch 7; Iter    30/   40] train: loss: 0.6903774
[Epoch 7] ogbg-molclintox: 0.509986 val loss: 0.683923
[Epoch 7] ogbg-molclintox: 0.482479 test loss: 0.688530
[Epoch 8; Iter    20/   40] train: loss: 0.6887158
[Epoch 8] ogbg-molclintox: 0.519214 val loss: 0.681230
[Epoch 8] ogbg-molclintox: 0.488213 test loss: 0.686706
[Epoch 9; Iter    10/   40] train: loss: 0.6891941
[Epoch 9; Iter    40/   40] train: loss: 0.6855456
[Epoch 9] ogbg-molclintox: 0.518627 val loss: 0.681721
[Epoch 9] ogbg-molclintox: 0.486252 test loss: 0.686654
[Epoch 10; Iter    30/   40] train: loss: 0.6872495
[Epoch 10] ogbg-molclintox: 0.531875 val loss: 0.678501
[Epoch 10] ogbg-molclintox: 0.496270 test loss: 0.684428
[Epoch 11; Iter    20/   40] train: loss: 0.6866822
[Epoch 11] ogbg-molclintox: 0.520162 val loss: 0.678734
[Epoch 11] ogbg-molclintox: 0.487589 test loss: 0.683941
[Epoch 12; Iter    10/   40] train: loss: 0.6854382
[Epoch 12; Iter    40/   40] train: loss: 0.6820153
[Epoch 12] ogbg-molclintox: 0.526593 val loss: 0.675205
[Epoch 12] ogbg-molclintox: 0.489987 test loss: 0.681607
[Epoch 13; Iter    30/   40] train: loss: 0.6843427
[Epoch 13] ogbg-molclintox: 0.522822 val loss: 0.673664
[Epoch 13] ogbg-molclintox: 0.488650 test loss: 0.679549
[Epoch 14; Iter    20/   40] train: loss: 0.6791035
[Epoch 14] ogbg-molclintox: 0.522759 val loss: 0.672931
[Epoch 14] ogbg-molclintox: 0.489401 test loss: 0.678580
[Epoch 15; Iter    10/   40] train: loss: 0.6787383
[Epoch 15; Iter    40/   40] train: loss: 0.6758062
[Epoch 15] ogbg-molclintox: 0.539655 val loss: 0.670994
[Epoch 15] ogbg-molclintox: 0.489950 test loss: 0.677275
[Epoch 16; Iter    30/   40] train: loss: 0.6748339
[Epoch 16] ogbg-molclintox: 0.526382 val loss: 0.665735
[Epoch 16] ogbg-molclintox: 0.493058 test loss: 0.672250
[Epoch 17; Iter    20/   40] train: loss: 0.6730675
[Epoch 17] ogbg-molclintox: 0.541229 val loss: 0.663209
[Epoch 17] ogbg-molclintox: 0.492034 test loss: 0.670978
[Epoch 18; Iter    10/   40] train: loss: 0.6707007
[Epoch 18; Iter    40/   40] train: loss: 0.6572754
[Epoch 18] ogbg-molclintox: 0.647706 val loss: 0.597100
[Epoch 18] ogbg-molclintox: 0.594729 test loss: 0.648586
[Epoch 19; Iter    30/   40] train: loss: 0.6334003
[Epoch 19] ogbg-molclintox: 0.653026 val loss: 0.550087
[Epoch 19] ogbg-molclintox: 0.567409 test loss: 0.597671
[Epoch 20; Iter    20/   40] train: loss: 0.6244563
[Epoch 20] ogbg-molclintox: 0.671609 val loss: 0.549858
[Epoch 20] ogbg-molclintox: 0.574700 test loss: 0.563570
[Epoch 21; Iter    10/   40] train: loss: 0.5598440
[Epoch 21; Iter    40/   40] train: loss: 0.4746038
[Epoch 21] ogbg-molclintox: 0.595089 val loss: 0.435414
[Epoch 21] ogbg-molclintox: 0.518428 test loss: 0.477263
[Epoch 22; Iter    30/   40] train: loss: 0.4475595
[Epoch 22] ogbg-molclintox: 0.644462 val loss: 0.405447
[Epoch 22] ogbg-molclintox: 0.530556 test loss: 0.480721
[Epoch 23; Iter    20/   40] train: loss: 0.4321530
[Epoch 23] ogbg-molclintox: 0.660719 val loss: 0.277075
[Epoch 23] ogbg-molclintox: 0.594478 test loss: 0.362683
[Epoch 24; Iter    10/   40] train: loss: 0.4007406
[Epoch 24; Iter    40/   40] train: loss: 0.2813125
[Epoch 24] ogbg-molclintox: 0.749850 val loss: 0.228348
[Epoch 24] ogbg-molclintox: 0.619800 test loss: 0.317615
[Epoch 25; Iter    30/   40] train: loss: 0.2273067
[Epoch 25] ogbg-molclintox: 0.781206 val loss: 0.227824
[Epoch 25] ogbg-molclintox: 0.525323 test loss: 0.390602
[Epoch 26; Iter    20/   40] train: loss: 0.2902810
[Epoch 26] ogbg-molclintox: 0.796963 val loss: 0.300430
[Epoch 26] ogbg-molclintox: 0.554440 test loss: 0.409609
[Epoch 27; Iter    10/   40] train: loss: 0.2287804
[Epoch 27; Iter    40/   40] train: loss: 0.1123434
[Epoch 27] ogbg-molclintox: 0.778971 val loss: 0.208658
[Epoch 27] ogbg-molclintox: 0.523661 test loss: 0.338710
[Epoch 28; Iter    30/   40] train: loss: 0.2431829
[Epoch 28] ogbg-molclintox: 0.775425 val loss: 0.185195
[Epoch 28] ogbg-molclintox: 0.551392 test loss: 0.301025
[Epoch 29; Iter    20/   40] train: loss: 0.2321620
[Epoch 29] ogbg-molclintox: 0.712302 val loss: 0.142690
[Epoch 29] ogbg-molclintox: 0.603297 test loss: 0.267608
[Epoch 30; Iter    10/   40] train: loss: 0.2037859
[Epoch 30; Iter    40/   40] train: loss: 0.0930756
[Epoch 30] ogbg-molclintox: 0.805218 val loss: 0.161752
[Epoch 30] ogbg-molclintox: 0.659110 test loss: 0.278772
[Epoch 31; Iter    30/   40] train: loss: 0.3072236
[Epoch 31] ogbg-molclintox: 0.725887 val loss: 0.148243
[ Using Seed :  6  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.2/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.2_6_26-05_09-18-55
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.2
logdir: runs/static_noise/3DInfomax/clintox/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6924875
[Epoch 1] ogbg-molclintox: 0.492956 val loss: 0.687647
[Epoch 1] ogbg-molclintox: 0.498739 test loss: 0.690799
[Epoch 2; Iter    20/   40] train: loss: 0.6929663
[Epoch 2] ogbg-molclintox: 0.488110 val loss: 0.665580
[Epoch 2] ogbg-molclintox: 0.517617 test loss: 0.682511
[Epoch 3; Iter    10/   40] train: loss: 0.6924533
[Epoch 3; Iter    40/   40] train: loss: 0.6954328
[Epoch 3] ogbg-molclintox: 0.497314 val loss: 0.659192
[Epoch 3] ogbg-molclintox: 0.520329 test loss: 0.682371
[Epoch 4; Iter    30/   40] train: loss: 0.6922058
[Epoch 4] ogbg-molclintox: 0.505867 val loss: 0.659369
[Epoch 4] ogbg-molclintox: 0.527837 test loss: 0.683770
[Epoch 5; Iter    20/   40] train: loss: 0.6936366
[Epoch 5] ogbg-molclintox: 0.510899 val loss: 0.660514
[Epoch 5] ogbg-molclintox: 0.527799 test loss: 0.684106
[Epoch 6; Iter    10/   40] train: loss: 0.6912735
[Epoch 6; Iter    40/   40] train: loss: 0.6904228
[Epoch 6] ogbg-molclintox: 0.502820 val loss: 0.659375
[Epoch 6] ogbg-molclintox: 0.524277 test loss: 0.682668
[Epoch 7; Iter    30/   40] train: loss: 0.6897062
[Epoch 7] ogbg-molclintox: 0.508938 val loss: 0.657594
[Epoch 7] ogbg-molclintox: 0.528151 test loss: 0.680566
[Epoch 8; Iter    20/   40] train: loss: 0.6893734
[Epoch 8] ogbg-molclintox: 0.501309 val loss: 0.653627
[Epoch 8] ogbg-molclintox: 0.528386 test loss: 0.678313
[Epoch 9; Iter    10/   40] train: loss: 0.6908477
[Epoch 9; Iter    40/   40] train: loss: 0.6852021
[Epoch 9] ogbg-molclintox: 0.496639 val loss: 0.656807
[Epoch 9] ogbg-molclintox: 0.525401 test loss: 0.679416
[Epoch 10; Iter    30/   40] train: loss: 0.6863254
[Epoch 10] ogbg-molclintox: 0.511848 val loss: 0.652948
[Epoch 10] ogbg-molclintox: 0.532222 test loss: 0.677312
[Epoch 11; Iter    20/   40] train: loss: 0.6854616
[Epoch 11] ogbg-molclintox: 0.502933 val loss: 0.652716
[Epoch 11] ogbg-molclintox: 0.524602 test loss: 0.676149
[Epoch 12; Iter    10/   40] train: loss: 0.6840970
[Epoch 12; Iter    40/   40] train: loss: 0.6820825
[Epoch 12] ogbg-molclintox: 0.499661 val loss: 0.648499
[Epoch 12] ogbg-molclintox: 0.524852 test loss: 0.673350
[Epoch 13; Iter    30/   40] train: loss: 0.6861566
[Epoch 13] ogbg-molclintox: 0.488760 val loss: 0.644138
[Epoch 13] ogbg-molclintox: 0.524501 test loss: 0.669257
[Epoch 14; Iter    20/   40] train: loss: 0.6791304
[Epoch 14] ogbg-molclintox: 0.502820 val loss: 0.645858
[Epoch 14] ogbg-molclintox: 0.524352 test loss: 0.669474
[Epoch 15; Iter    10/   40] train: loss: 0.6796892
[Epoch 15; Iter    40/   40] train: loss: 0.6758217
[Epoch 15] ogbg-molclintox: 0.506405 val loss: 0.639719
[Epoch 15] ogbg-molclintox: 0.525039 test loss: 0.666339
[Epoch 16; Iter    30/   40] train: loss: 0.6747587
[Epoch 16] ogbg-molclintox: 0.497064 val loss: 0.640209
[Epoch 16] ogbg-molclintox: 0.531908 test loss: 0.664795
[Epoch 17; Iter    20/   40] train: loss: 0.6741650
[Epoch 17] ogbg-molclintox: 0.492981 val loss: 0.637722
[Epoch 17] ogbg-molclintox: 0.525413 test loss: 0.662288
[Epoch 18; Iter    10/   40] train: loss: 0.6705831
[Epoch 18; Iter    40/   40] train: loss: 0.6624376
[Epoch 18] ogbg-molclintox: 0.560163 val loss: 0.413159
[Epoch 18] ogbg-molclintox: 0.566060 test loss: 0.526896
[Epoch 19; Iter    30/   40] train: loss: 0.6390374
[Epoch 19] ogbg-molclintox: 0.566056 val loss: 0.366811
[Epoch 19] ogbg-molclintox: 0.580587 test loss: 0.502785
[Epoch 20; Iter    20/   40] train: loss: 0.6287018
[Epoch 20] ogbg-molclintox: 0.672168 val loss: 0.362014
[Epoch 20] ogbg-molclintox: 0.564708 test loss: 0.479621
[Epoch 21; Iter    10/   40] train: loss: 0.5343295
[Epoch 21; Iter    40/   40] train: loss: 0.4741437
[Epoch 21] ogbg-molclintox: 0.506169 val loss: 3.771784
[Epoch 21] ogbg-molclintox: 0.383939 test loss: 2.447441
[Epoch 22; Iter    30/   40] train: loss: 0.4613861
[Epoch 22] ogbg-molclintox: 0.494818 val loss: 5.301307
[Epoch 22] ogbg-molclintox: 0.411546 test loss: 3.172226
[Epoch 23; Iter    20/   40] train: loss: 0.4215348
[Epoch 23] ogbg-molclintox: 0.487077 val loss: 6.759215
[Epoch 23] ogbg-molclintox: 0.423664 test loss: 3.960404
[Epoch 24; Iter    10/   40] train: loss: 0.4187181
[Epoch 24; Iter    40/   40] train: loss: 0.2896636
[Epoch 24] ogbg-molclintox: 0.541781 val loss: 6.746580
[Epoch 24] ogbg-molclintox: 0.425875 test loss: 3.245602
[Epoch 25; Iter    30/   40] train: loss: 0.2266935
[Epoch 25] ogbg-molclintox: 0.533414 val loss: 3.930589
[Epoch 25] ogbg-molclintox: 0.524897 test loss: 1.448666
[Epoch 26; Iter    20/   40] train: loss: 0.3606818
[Epoch 26] ogbg-molclintox: 0.678264 val loss: 2.956539
[Epoch 26] ogbg-molclintox: 0.634024 test loss: 0.996662
[Epoch 27; Iter    10/   40] train: loss: 0.2468283
[Epoch 27; Iter    40/   40] train: loss: 0.1208073
[Epoch 27] ogbg-molclintox: 0.555816 val loss: 1.609594
[Epoch 27] ogbg-molclintox: 0.615915 test loss: 0.564349
[Epoch 28; Iter    30/   40] train: loss: 0.2571899
[Epoch 28] ogbg-molclintox: 0.575460 val loss: 2.416471
[Epoch 28] ogbg-molclintox: 0.550368 test loss: 0.876682
[Epoch 29; Iter    20/   40] train: loss: 0.2201858
[Epoch 29] ogbg-molclintox: 0.553982 val loss: 2.050936
[Epoch 29] ogbg-molclintox: 0.591143 test loss: 0.799400
[Epoch 30; Iter    10/   40] train: loss: 0.2149444
[Epoch 30; Iter    40/   40] train: loss: 0.0893310
[Epoch 30] ogbg-molclintox: 0.506893 val loss: 2.121320
[Epoch 30] ogbg-molclintox: 0.607044 test loss: 0.551707
[Epoch 31; Iter    30/   40] train: loss: 0.3114761
[Epoch 31] ogbg-molclintox: 0.512849 val loss: 2.546593
[ Using Seed :  5  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.2/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.2_5_26-05_09-18-58
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.2
logdir: runs/static_noise/3DInfomax/clintox/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6937676
[Epoch 1] ogbg-molclintox: 0.469531 val loss: 0.695182
[Epoch 1] ogbg-molclintox: 0.581649 test loss: 0.694690
[Epoch 2; Iter    20/   40] train: loss: 0.6909630
[Epoch 2] ogbg-molclintox: 0.476025 val loss: 0.697239
[Epoch 2] ogbg-molclintox: 0.537262 test loss: 0.697452
[Epoch 3; Iter    10/   40] train: loss: 0.6931270
[Epoch 3; Iter    40/   40] train: loss: 0.6926999
[Epoch 3] ogbg-molclintox: 0.492084 val loss: 0.685084
[Epoch 3] ogbg-molclintox: 0.484894 test loss: 0.687681
[Epoch 4; Iter    30/   40] train: loss: 0.6925740
[Epoch 4] ogbg-molclintox: 0.475277 val loss: 0.684405
[Epoch 4] ogbg-molclintox: 0.501635 test loss: 0.686869
[Epoch 5; Iter    20/   40] train: loss: 0.6923926
[Epoch 5] ogbg-molclintox: 0.469995 val loss: 0.682748
[Epoch 5] ogbg-molclintox: 0.496525 test loss: 0.686130
[Epoch 6; Iter    10/   40] train: loss: 0.6910195
[Epoch 6; Iter    40/   40] train: loss: 0.6910920
[Epoch 6] ogbg-molclintox: 0.505171 val loss: 0.685143
[Epoch 6] ogbg-molclintox: 0.490627 test loss: 0.688194
[Epoch 7; Iter    30/   40] train: loss: 0.6925733
[Epoch 7] ogbg-molclintox: 0.478211 val loss: 0.684534
[Epoch 7] ogbg-molclintox: 0.494426 test loss: 0.686676
[Epoch 8; Iter    20/   40] train: loss: 0.6901316
[Epoch 8] ogbg-molclintox: 0.480035 val loss: 0.684817
[Epoch 8] ogbg-molclintox: 0.499499 test loss: 0.686923
[Epoch 9; Iter    10/   40] train: loss: 0.6880663
[Epoch 9; Iter    40/   40] train: loss: 0.6860448
[Epoch 9] ogbg-molclintox: 0.462127 val loss: 0.683638
[Epoch 9] ogbg-molclintox: 0.504097 test loss: 0.685730
[Epoch 10; Iter    30/   40] train: loss: 0.6884188
[Epoch 10] ogbg-molclintox: 0.497429 val loss: 0.677800
[Epoch 10] ogbg-molclintox: 0.485906 test loss: 0.682229
[Epoch 11; Iter    20/   40] train: loss: 0.6856595
[Epoch 11] ogbg-molclintox: 0.467946 val loss: 0.682775
[Epoch 11] ogbg-molclintox: 0.497624 test loss: 0.684294
[Epoch 12; Iter    10/   40] train: loss: 0.6881287
[Epoch 12; Iter    40/   40] train: loss: 0.6885951
[Epoch 12] ogbg-molclintox: 0.485292 val loss: 0.677294
[Epoch 12] ogbg-molclintox: 0.495438 test loss: 0.680471
[Epoch 13; Iter    30/   40] train: loss: 0.6830343
[Epoch 13] ogbg-molclintox: 0.475252 val loss: 0.673155
[Epoch 13] ogbg-molclintox: 0.497164 test loss: 0.676559
[Epoch 14; Iter    20/   40] train: loss: 0.6829876
[Epoch 14] ogbg-molclintox: 0.483893 val loss: 0.671641
[Epoch 14] ogbg-molclintox: 0.496525 test loss: 0.676017
[Epoch 15; Iter    10/   40] train: loss: 0.6825013
[Epoch 15; Iter    40/   40] train: loss: 0.6828186
[Epoch 15] ogbg-molclintox: 0.489849 val loss: 0.671993
[Epoch 15] ogbg-molclintox: 0.500511 test loss: 0.676708
[Epoch 16; Iter    30/   40] train: loss: 0.6792941
[Epoch 16] ogbg-molclintox: 0.464351 val loss: 0.666792
[Epoch 16] ogbg-molclintox: 0.505722 test loss: 0.672292
[Epoch 17; Iter    20/   40] train: loss: 0.6811219
[Epoch 17] ogbg-molclintox: 0.471207 val loss: 0.662268
[Epoch 17] ogbg-molclintox: 0.513517 test loss: 0.668633
[Epoch 18; Iter    10/   40] train: loss: 0.6773568
[Epoch 18; Iter    40/   40] train: loss: 0.6730301
[Epoch 18] ogbg-molclintox: 0.649256 val loss: 0.556456
[Epoch 18] ogbg-molclintox: 0.596189 test loss: 0.642024
[Epoch 19; Iter    30/   40] train: loss: 0.6545135
[Epoch 19] ogbg-molclintox: 0.619150 val loss: 0.407625
[Epoch 19] ogbg-molclintox: 0.578465 test loss: 0.575094
[Epoch 20; Iter    20/   40] train: loss: 0.6127653
[Epoch 20] ogbg-molclintox: 0.692412 val loss: 0.547288
[Epoch 20] ogbg-molclintox: 0.445052 test loss: 0.593278
[Epoch 21; Iter    10/   40] train: loss: 0.5538516
[Epoch 21; Iter    40/   40] train: loss: 0.4809088
[Epoch 21] ogbg-molclintox: 0.678876 val loss: 0.636914
[Epoch 21] ogbg-molclintox: 0.452784 test loss: 0.679137
[Epoch 22; Iter    30/   40] train: loss: 0.5188887
[Epoch 22] ogbg-molclintox: 0.598547 val loss: 1.390900
[Epoch 22] ogbg-molclintox: 0.381679 test loss: 1.472772
[Epoch 23; Iter    20/   40] train: loss: 0.3370153
[Epoch 23] ogbg-molclintox: 0.642076 val loss: 2.002665
[Epoch 23] ogbg-molclintox: 0.418755 test loss: 2.204576
[Epoch 24; Iter    10/   40] train: loss: 0.3130220
[Epoch 24; Iter    40/   40] train: loss: 0.4772105
[Epoch 24] ogbg-molclintox: 0.602968 val loss: 4.258543
[Epoch 24] ogbg-molclintox: 0.401779 test loss: 3.696738
[Epoch 25; Iter    30/   40] train: loss: 0.2668180
[Epoch 25] ogbg-molclintox: 0.533667 val loss: 6.075536
[Epoch 25] ogbg-molclintox: 0.428886 test loss: 5.031674
[Epoch 26; Iter    20/   40] train: loss: 0.2393889
[Epoch 26] ogbg-molclintox: 0.607389 val loss: 6.240839
[Epoch 26] ogbg-molclintox: 0.429685 test loss: 5.001052
[Epoch 27; Iter    10/   40] train: loss: 0.2202121
[Epoch 27; Iter    40/   40] train: loss: 0.1170626
[Epoch 27] ogbg-molclintox: 0.535526 val loss: 8.454475
[Epoch 27] ogbg-molclintox: 0.391559 test loss: 5.906135
[Epoch 28; Iter    30/   40] train: loss: 0.2662056
[Epoch 28] ogbg-molclintox: 0.672245 val loss: 7.188262
[Epoch 28] ogbg-molclintox: 0.437604 test loss: 5.232634
[Epoch 29; Iter    20/   40] train: loss: 0.2250179
[Epoch 29] ogbg-molclintox: 0.604367 val loss: 9.167494
[Epoch 29] ogbg-molclintox: 0.410747 test loss: 6.562509
[Epoch 30; Iter    10/   40] train: loss: 0.1360087
[Epoch 30; Iter    40/   40] train: loss: 0.4018277
[Epoch 30] ogbg-molclintox: 0.680910 val loss: 6.234904
[Epoch 30] ogbg-molclintox: 0.388787 test loss: 5.165042
[Epoch 31; Iter    30/   40] train: loss: 0.3079259
[Epoch 31] ogbg-molclintox: 0.680186 val loss: 5.778561
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.1/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.1_6_26-05_09-18-51
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.1.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.1
logdir: runs/static_noise/3DInfomax/clintox/noise=0.1
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.1
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6935289
[Epoch 1] ogbg-molclintox: 0.496291 val loss: 0.690315
[Epoch 1] ogbg-molclintox: 0.498474 test loss: 0.691871
[Epoch 2; Iter    20/   40] train: loss: 0.6933208
[Epoch 2] ogbg-molclintox: 0.526182 val loss: 0.679725
[Epoch 2] ogbg-molclintox: 0.509497 test loss: 0.688489
[Epoch 3; Iter    10/   40] train: loss: 0.6936097
[Epoch 3; Iter    40/   40] train: loss: 0.6934639
[Epoch 3] ogbg-molclintox: 0.520925 val loss: 0.674958
[Epoch 3] ogbg-molclintox: 0.501193 test loss: 0.687136
[Epoch 4; Iter    30/   40] train: loss: 0.6926944
[Epoch 4] ogbg-molclintox: 0.527605 val loss: 0.676200
[Epoch 4] ogbg-molclintox: 0.493961 test loss: 0.688100
[Epoch 5; Iter    20/   40] train: loss: 0.6922805
[Epoch 5] ogbg-molclintox: 0.531601 val loss: 0.677243
[Epoch 5] ogbg-molclintox: 0.496423 test loss: 0.689049
[Epoch 6; Iter    10/   40] train: loss: 0.6912022
[Epoch 6; Iter    40/   40] train: loss: 0.6905042
[Epoch 6] ogbg-molclintox: 0.529928 val loss: 0.676256
[Epoch 6] ogbg-molclintox: 0.499732 test loss: 0.687373
[Epoch 7; Iter    30/   40] train: loss: 0.6911075
[Epoch 7] ogbg-molclintox: 0.527493 val loss: 0.674498
[Epoch 7] ogbg-molclintox: 0.497446 test loss: 0.686281
[Epoch 8; Iter    20/   40] train: loss: 0.6881902
[Epoch 8] ogbg-molclintox: 0.532975 val loss: 0.671045
[Epoch 8] ogbg-molclintox: 0.502392 test loss: 0.683958
[Epoch 9; Iter    10/   40] train: loss: 0.6907092
[Epoch 9; Iter    40/   40] train: loss: 0.6840826
[Epoch 9] ogbg-molclintox: 0.527268 val loss: 0.674223
[Epoch 9] ogbg-molclintox: 0.500095 test loss: 0.685466
[Epoch 10; Iter    30/   40] train: loss: 0.6868878
[Epoch 10] ogbg-molclintox: 0.539131 val loss: 0.669452
[Epoch 10] ogbg-molclintox: 0.503703 test loss: 0.682066
[Epoch 11; Iter    20/   40] train: loss: 0.6854489
[Epoch 11] ogbg-molclintox: 0.537058 val loss: 0.668062
[Epoch 11] ogbg-molclintox: 0.515383 test loss: 0.680905
[Epoch 12; Iter    10/   40] train: loss: 0.6849037
[Epoch 12; Iter    40/   40] train: loss: 0.6820011
[Epoch 12] ogbg-molclintox: 0.535747 val loss: 0.667070
[Epoch 12] ogbg-molclintox: 0.504316 test loss: 0.679683
[Epoch 13; Iter    30/   40] train: loss: 0.6844295
[Epoch 13] ogbg-molclintox: 0.533762 val loss: 0.665297
[Epoch 13] ogbg-molclintox: 0.494484 test loss: 0.678101
[Epoch 14; Iter    20/   40] train: loss: 0.6791185
[Epoch 14] ogbg-molclintox: 0.536696 val loss: 0.663123
[Epoch 14] ogbg-molclintox: 0.505003 test loss: 0.675978
[Epoch 15; Iter    10/   40] train: loss: 0.6793163
[Epoch 15; Iter    40/   40] train: loss: 0.6758382
[Epoch 15] ogbg-molclintox: 0.536647 val loss: 0.659631
[Epoch 15] ogbg-molclintox: 0.503453 test loss: 0.673741
[Epoch 16; Iter    30/   40] train: loss: 0.6743811
[Epoch 16] ogbg-molclintox: 0.541542 val loss: 0.656583
[Epoch 16] ogbg-molclintox: 0.509560 test loss: 0.670611
[Epoch 17; Iter    20/   40] train: loss: 0.6740672
[Epoch 17] ogbg-molclintox: 0.543527 val loss: 0.654553
[Epoch 17] ogbg-molclintox: 0.514468 test loss: 0.668534
[Epoch 18; Iter    10/   40] train: loss: 0.6707223
[Epoch 18; Iter    40/   40] train: loss: 0.6665518
[Epoch 18] ogbg-molclintox: 0.645309 val loss: 0.584232
[Epoch 18] ogbg-molclintox: 0.573094 test loss: 0.645440
[Epoch 19; Iter    30/   40] train: loss: 0.6393629
[Epoch 19] ogbg-molclintox: 0.698428 val loss: 0.626540
[Epoch 19] ogbg-molclintox: 0.565011 test loss: 0.677570
[Epoch 20; Iter    20/   40] train: loss: 0.6259883
[Epoch 20] ogbg-molclintox: 0.662391 val loss: 0.585264
[Epoch 20] ogbg-molclintox: 0.590956 test loss: 0.646916
[Epoch 21; Iter    10/   40] train: loss: 0.5508036
[Epoch 21; Iter    40/   40] train: loss: 0.4841972
[Epoch 21] ogbg-molclintox: 0.656635 val loss: 0.388280
[Epoch 21] ogbg-molclintox: 0.592006 test loss: 0.476825
[Epoch 22; Iter    30/   40] train: loss: 0.4496246
[Epoch 22] ogbg-molclintox: 0.595912 val loss: 0.277986
[Epoch 22] ogbg-molclintox: 0.569721 test loss: 0.374171
[Epoch 23; Iter    20/   40] train: loss: 0.4091243
[Epoch 23] ogbg-molclintox: 0.647969 val loss: 0.261004
[Epoch 23] ogbg-molclintox: 0.620412 test loss: 0.396220
[Epoch 24; Iter    10/   40] train: loss: 0.4086018
[Epoch 24; Iter    40/   40] train: loss: 0.3053291
[Epoch 24] ogbg-molclintox: 0.647832 val loss: 0.187152
[Epoch 24] ogbg-molclintox: 0.569683 test loss: 0.280050
[Epoch 25; Iter    30/   40] train: loss: 0.2276069
[Epoch 25] ogbg-molclintox: 0.629988 val loss: 0.187146
[Epoch 25] ogbg-molclintox: 0.565735 test loss: 0.308980
[Epoch 26; Iter    20/   40] train: loss: 0.3063897
[Epoch 26] ogbg-molclintox: 0.773176 val loss: 2.094273
[Epoch 26] ogbg-molclintox: 0.513344 test loss: 1.108697
[Epoch 27; Iter    10/   40] train: loss: 0.2568596
[Epoch 27; Iter    40/   40] train: loss: 0.1077666
[Epoch 27] ogbg-molclintox: 0.663565 val loss: 0.299721
[Epoch 27] ogbg-molclintox: 0.623685 test loss: 0.295809
[Epoch 28; Iter    30/   40] train: loss: 0.2651908
[Epoch 28] ogbg-molclintox: 0.619087 val loss: 0.278900
[Epoch 28] ogbg-molclintox: 0.611403 test loss: 0.309901
[Epoch 29; Iter    20/   40] train: loss: 0.2369008
[Epoch 29] ogbg-molclintox: 0.663677 val loss: 0.221288
[Epoch 29] ogbg-molclintox: 0.573691 test loss: 0.305209
[Epoch 30; Iter    10/   40] train: loss: 0.2354947
[Epoch 30; Iter    40/   40] train: loss: 0.0937831
[Epoch 30] ogbg-molclintox: 0.668098 val loss: 0.221905
[Epoch 30] ogbg-molclintox: 0.598438 test loss: 0.316469
[Epoch 31; Iter    30/   40] train: loss: 0.3008059
[Epoch 31] ogbg-molclintox: 0.683757 val loss: 0.217661
[ Using Seed :  4  ]
using device:  cuda:3
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.2/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.2_4_26-05_09-18-54
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.2.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.2
logdir: runs/static_noise/3DInfomax/clintox/noise=0.2
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:3
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.2
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6927916
[Epoch 1] ogbg-molclintox: 0.429972 val loss: 0.691900
[Epoch 1] ogbg-molclintox: 0.471428 test loss: 0.692929
[Epoch 2; Iter    20/   40] train: loss: 0.6924700
[Epoch 2] ogbg-molclintox: 0.460288 val loss: 0.690066
[Epoch 2] ogbg-molclintox: 0.483531 test loss: 0.695293
[Epoch 3; Iter    10/   40] train: loss: 0.6923488
[Epoch 3; Iter    40/   40] train: loss: 0.6926616
[Epoch 3] ogbg-molclintox: 0.503565 val loss: 0.696564
[Epoch 3] ogbg-molclintox: 0.504243 test loss: 0.700975
[Epoch 4; Iter    30/   40] train: loss: 0.6929008
[Epoch 4] ogbg-molclintox: 0.504401 val loss: 0.697557
[Epoch 4] ogbg-molclintox: 0.505117 test loss: 0.701209
[Epoch 5; Iter    20/   40] train: loss: 0.6918600
[Epoch 5] ogbg-molclintox: 0.514827 val loss: 0.694224
[Epoch 5] ogbg-molclintox: 0.501845 test loss: 0.699414
[Epoch 6; Iter    10/   40] train: loss: 0.6912442
[Epoch 6; Iter    40/   40] train: loss: 0.6905603
[Epoch 6] ogbg-molclintox: 0.540761 val loss: 0.694194
[Epoch 6] ogbg-molclintox: 0.516973 test loss: 0.699619
[Epoch 7; Iter    30/   40] train: loss: 0.6891345
[Epoch 7] ogbg-molclintox: 0.498532 val loss: 0.692216
[Epoch 7] ogbg-molclintox: 0.497086 test loss: 0.697177
[Epoch 8; Iter    20/   40] train: loss: 0.6901104
[Epoch 8] ogbg-molclintox: 0.519160 val loss: 0.691253
[Epoch 8] ogbg-molclintox: 0.509439 test loss: 0.696540
[Epoch 9; Iter    10/   40] train: loss: 0.6886500
[Epoch 9; Iter    40/   40] train: loss: 0.6900346
[Epoch 9] ogbg-molclintox: 0.522007 val loss: 0.688818
[Epoch 9] ogbg-molclintox: 0.506006 test loss: 0.695015
[Epoch 10; Iter    30/   40] train: loss: 0.6879706
[Epoch 10] ogbg-molclintox: 0.526789 val loss: 0.687676
[Epoch 10] ogbg-molclintox: 0.515710 test loss: 0.694387
[Epoch 11; Iter    20/   40] train: loss: 0.6855412
[Epoch 11] ogbg-molclintox: 0.526065 val loss: 0.685051
[Epoch 11] ogbg-molclintox: 0.507941 test loss: 0.692179
[Epoch 12; Iter    10/   40] train: loss: 0.6838648
[Epoch 12; Iter    40/   40] train: loss: 0.6844965
[Epoch 12] ogbg-molclintox: 0.540761 val loss: 0.686002
[Epoch 12] ogbg-molclintox: 0.513689 test loss: 0.691997
[Epoch 13; Iter    30/   40] train: loss: 0.6829814
[Epoch 13] ogbg-molclintox: 0.541573 val loss: 0.682925
[Epoch 13] ogbg-molclintox: 0.521795 test loss: 0.689974
[Epoch 14; Iter    20/   40] train: loss: 0.6827440
[Epoch 14] ogbg-molclintox: 0.526427 val loss: 0.679816
[Epoch 14] ogbg-molclintox: 0.501434 test loss: 0.687031
[Epoch 15; Iter    10/   40] train: loss: 0.6802874
[Epoch 15; Iter    40/   40] train: loss: 0.6766908
[Epoch 15] ogbg-molclintox: 0.532384 val loss: 0.676022
[Epoch 15] ogbg-molclintox: 0.519759 test loss: 0.684676
[Epoch 16; Iter    30/   40] train: loss: 0.6767521
[Epoch 16] ogbg-molclintox: 0.541436 val loss: 0.675909
[Epoch 16] ogbg-molclintox: 0.517947 test loss: 0.683216
[Epoch 17; Iter    20/   40] train: loss: 0.6737183
[Epoch 17] ogbg-molclintox: 0.543559 val loss: 0.674350
[Epoch 17] ogbg-molclintox: 0.511590 test loss: 0.681705
[Epoch 18; Iter    10/   40] train: loss: 0.6714475
[Epoch 18; Iter    40/   40] train: loss: 0.6603630
[Epoch 18] ogbg-molclintox: 0.630002 val loss: 0.517296
[Epoch 18] ogbg-molclintox: 0.587172 test loss: 0.608086
[Epoch 19; Iter    30/   40] train: loss: 0.6498290
[Epoch 19] ogbg-molclintox: 0.640702 val loss: 0.431179
[Epoch 19] ogbg-molclintox: 0.585211 test loss: 0.547528
[Epoch 20; Iter    20/   40] train: loss: 0.5904406
[Epoch 20] ogbg-molclintox: 0.478411 val loss: 0.493462
[Epoch 20] ogbg-molclintox: 0.493345 test loss: 0.496526
[Epoch 21; Iter    10/   40] train: loss: 0.5388181
[Epoch 21; Iter    40/   40] train: loss: 0.4775957
[Epoch 21] ogbg-molclintox: 0.562960 val loss: 0.271026
[Epoch 21] ogbg-molclintox: 0.566886 test loss: 0.334016
[Epoch 22; Iter    30/   40] train: loss: 0.4289905
[Epoch 22] ogbg-molclintox: 0.593252 val loss: 0.220538
[Epoch 22] ogbg-molclintox: 0.564312 test loss: 0.272498
[Epoch 23; Iter    20/   40] train: loss: 0.4152860
[Epoch 23] ogbg-molclintox: 0.609286 val loss: 0.172215
[Epoch 23] ogbg-molclintox: 0.526324 test loss: 0.273967
[Epoch 24; Iter    10/   40] train: loss: 0.3232048
[Epoch 24; Iter    40/   40] train: loss: 0.2877492
[Epoch 24] ogbg-molclintox: 0.648633 val loss: 0.459004
[Epoch 24] ogbg-molclintox: 0.508286 test loss: 0.412598
[Epoch 25; Iter    30/   40] train: loss: 0.2701133
[Epoch 25] ogbg-molclintox: 0.698105 val loss: 1.339761
[Epoch 25] ogbg-molclintox: 0.469249 test loss: 0.898605
[Epoch 26; Iter    20/   40] train: loss: 0.1835548
[Epoch 26] ogbg-molclintox: 0.682783 val loss: 1.838622
[Epoch 26] ogbg-molclintox: 0.451398 test loss: 0.961808
[Epoch 27; Iter    10/   40] train: loss: 0.2664821
[Epoch 27; Iter    40/   40] train: loss: 0.1955726
[Epoch 27] ogbg-molclintox: 0.713588 val loss: 1.849538
[Epoch 27] ogbg-molclintox: 0.478617 test loss: 1.114865
[Epoch 28; Iter    30/   40] train: loss: 0.2490048
[Epoch 28] ogbg-molclintox: 0.657011 val loss: 1.657775
[Epoch 28] ogbg-molclintox: 0.468013 test loss: 0.833405
[Epoch 29; Iter    20/   40] train: loss: 0.5221328
[Epoch 29] ogbg-molclintox: 0.686979 val loss: 1.504856
[Epoch 29] ogbg-molclintox: 0.471785 test loss: 0.874098
[Epoch 30; Iter    10/   40] train: loss: 0.2259448
[Epoch 30; Iter    40/   40] train: loss: 0.0872351
[Epoch 30] ogbg-molclintox: 0.675130 val loss: 1.793893
[Epoch 30] ogbg-molclintox: 0.483615 test loss: 0.859694
[Epoch 31; Iter    30/   40] train: loss: 0.1720718
[Epoch 31] ogbg-molclintox: 0.630926 val loss: 2.335466
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.0/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.0_5_26-05_09-18-24
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.0
logdir: runs/static_noise/3DInfomax/clintox/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6928144
[Epoch 1] ogbg-molclintox: 0.456483 val loss: 0.693326
[Epoch 1] ogbg-molclintox: 0.651081 test loss: 0.693582
[Epoch 2; Iter    20/   40] train: loss: 0.6927844
[Epoch 2] ogbg-molclintox: 0.517903 val loss: 0.692143
[Epoch 2] ogbg-molclintox: 0.641503 test loss: 0.694549
[Epoch 3; Iter    10/   40] train: loss: 0.6926650
[Epoch 3; Iter    40/   40] train: loss: 0.6926810
[Epoch 3] ogbg-molclintox: 0.546897 val loss: 0.692437
[Epoch 3] ogbg-molclintox: 0.641242 test loss: 0.695051
[Epoch 4; Iter    30/   40] train: loss: 0.6918060
[Epoch 4] ogbg-molclintox: 0.532799 val loss: 0.691490
[Epoch 4] ogbg-molclintox: 0.647525 test loss: 0.693552
[Epoch 5; Iter    20/   40] train: loss: 0.6911660
[Epoch 5] ogbg-molclintox: 0.535484 val loss: 0.690544
[Epoch 5] ogbg-molclintox: 0.645040 test loss: 0.692404
[Epoch 6; Iter    10/   40] train: loss: 0.6905714
[Epoch 6; Iter    40/   40] train: loss: 0.6910768
[Epoch 6] ogbg-molclintox: 0.550805 val loss: 0.690849
[Epoch 6] ogbg-molclintox: 0.641555 test loss: 0.692972
[Epoch 7; Iter    30/   40] train: loss: 0.6918393
[Epoch 7] ogbg-molclintox: 0.533586 val loss: 0.689218
[Epoch 7] ogbg-molclintox: 0.644966 test loss: 0.690931
[Epoch 8; Iter    20/   40] train: loss: 0.6909466
[Epoch 8] ogbg-molclintox: 0.541841 val loss: 0.688564
[Epoch 8] ogbg-molclintox: 0.642803 test loss: 0.690988
[Epoch 9; Iter    10/   40] train: loss: 0.6899628
[Epoch 9; Iter    40/   40] train: loss: 0.6851919
[Epoch 9] ogbg-molclintox: 0.536183 val loss: 0.688863
[Epoch 9] ogbg-molclintox: 0.629012 test loss: 0.691169
[Epoch 10; Iter    30/   40] train: loss: 0.6904100
[Epoch 10] ogbg-molclintox: 0.557911 val loss: 0.686853
[Epoch 10] ogbg-molclintox: 0.646490 test loss: 0.688930
[Epoch 11; Iter    20/   40] train: loss: 0.6866365
[Epoch 11] ogbg-molclintox: 0.529390 val loss: 0.685580
[Epoch 11] ogbg-molclintox: 0.647801 test loss: 0.687817
[Epoch 12; Iter    10/   40] train: loss: 0.6891339
[Epoch 12; Iter    40/   40] train: loss: 0.6849339
[Epoch 12] ogbg-molclintox: 0.540266 val loss: 0.684287
[Epoch 12] ogbg-molclintox: 0.647838 test loss: 0.686901
[Epoch 13; Iter    30/   40] train: loss: 0.6852233
[Epoch 13] ogbg-molclintox: 0.554189 val loss: 0.682768
[Epoch 13] ogbg-molclintox: 0.657583 test loss: 0.685117
[Epoch 14; Iter    20/   40] train: loss: 0.6830212
[Epoch 14] ogbg-molclintox: 0.556287 val loss: 0.681857
[Epoch 14] ogbg-molclintox: 0.652074 test loss: 0.683872
[Epoch 15; Iter    10/   40] train: loss: 0.6827161
[Epoch 15; Iter    40/   40] train: loss: 0.6798384
[Epoch 15] ogbg-molclintox: 0.571334 val loss: 0.680730
[Epoch 15] ogbg-molclintox: 0.641006 test loss: 0.683466
[Epoch 16; Iter    30/   40] train: loss: 0.6793367
[Epoch 16] ogbg-molclintox: 0.567202 val loss: 0.678146
[Epoch 16] ogbg-molclintox: 0.645941 test loss: 0.681381
[Epoch 17; Iter    20/   40] train: loss: 0.6819030
[Epoch 17] ogbg-molclintox: 0.554052 val loss: 0.677181
[Epoch 17] ogbg-molclintox: 0.643804 test loss: 0.679913
[Epoch 18; Iter    10/   40] train: loss: 0.6768451
[Epoch 18; Iter    40/   40] train: loss: 0.6784310
[Epoch 18] ogbg-molclintox: 0.712063 val loss: 0.669492
[Epoch 18] ogbg-molclintox: 0.614526 test loss: 0.693558
[Epoch 19; Iter    30/   40] train: loss: 0.6467096
[Epoch 19] ogbg-molclintox: 0.723389 val loss: 0.714380
[Epoch 19] ogbg-molclintox: 0.634625 test loss: 0.725267
[Epoch 20; Iter    20/   40] train: loss: 0.6045088
[Epoch 20] ogbg-molclintox: 0.793330 val loss: 0.531298
[Epoch 20] ogbg-molclintox: 0.610678 test loss: 0.572734
[Epoch 21; Iter    10/   40] train: loss: 0.5612971
[Epoch 21; Iter    40/   40] train: loss: 0.4851509
[Epoch 21] ogbg-molclintox: 0.842927 val loss: 0.541447
[Epoch 21] ogbg-molclintox: 0.671650 test loss: 0.568222
[Epoch 22; Iter    30/   40] train: loss: 0.5137609
[Epoch 22] ogbg-molclintox: 0.843215 val loss: 0.353176
[Epoch 22] ogbg-molclintox: 0.675773 test loss: 0.421567
[Epoch 23; Iter    20/   40] train: loss: 0.3403093
[Epoch 23] ogbg-molclintox: 0.729310 val loss: 0.300209
[Epoch 23] ogbg-molclintox: 0.725991 test loss: 0.364342
[Epoch 24; Iter    10/   40] train: loss: 0.3051439
[Epoch 24; Iter    40/   40] train: loss: 0.5466050
[Epoch 24] ogbg-molclintox: 0.710541 val loss: 0.311583
[Epoch 24] ogbg-molclintox: 0.706238 test loss: 0.335044
[Epoch 25; Iter    30/   40] train: loss: 0.2853580
[Epoch 25] ogbg-molclintox: 0.784102 val loss: 0.224295
[Epoch 25] ogbg-molclintox: 0.683920 test loss: 0.395517
[Epoch 26; Iter    20/   40] train: loss: 0.2424668
[Epoch 26] ogbg-molclintox: 0.730933 val loss: 0.188614
[Epoch 26] ogbg-molclintox: 0.685739 test loss: 0.299086
[Epoch 27; Iter    10/   40] train: loss: 0.2292866
[Epoch 27; Iter    40/   40] train: loss: 0.1003353
[Epoch 27] ogbg-molclintox: 0.826520 val loss: 0.162830
[Epoch 27] ogbg-molclintox: 0.716432 test loss: 0.268130
[Epoch 28; Iter    30/   40] train: loss: 0.2675993
[Epoch 28] ogbg-molclintox: 0.905338 val loss: 0.196631
[Epoch 28] ogbg-molclintox: 0.686964 test loss: 0.282625
[Epoch 29; Iter    20/   40] train: loss: 0.2412586
[Epoch 29] ogbg-molclintox: 0.915040 val loss: 0.138408
[Epoch 29] ogbg-molclintox: 0.681570 test loss: 0.232742
[Epoch 30; Iter    10/   40] train: loss: 0.1672240
[Epoch 30; Iter    40/   40] train: loss: 0.3388390
[Epoch 30] ogbg-molclintox: 0.853803 val loss: 0.141605
[Epoch 30] ogbg-molclintox: 0.725479 test loss: 0.224693
[Epoch 31; Iter    30/   40] train: loss: 0.2915382
[Epoch 31] ogbg-molclintox: 0.814020 val loss: 0.134163
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.0/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.0_4_26-05_09-18-23
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.0
logdir: runs/static_noise/3DInfomax/clintox/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6929867
[Epoch 1] ogbg-molclintox: 0.542866 val loss: 0.693127
[Epoch 1] ogbg-molclintox: 0.456819 test loss: 0.693144
[Epoch 2; Iter    20/   40] train: loss: 0.6927838
[Epoch 2] ogbg-molclintox: 0.499745 val loss: 0.692438
[Epoch 2] ogbg-molclintox: 0.483089 test loss: 0.693220
[Epoch 3; Iter    10/   40] train: loss: 0.6928375
[Epoch 3; Iter    40/   40] train: loss: 0.6895658
[Epoch 3] ogbg-molclintox: 0.462921 val loss: 0.692153
[Epoch 3] ogbg-molclintox: 0.487273 test loss: 0.693170
[Epoch 4; Iter    30/   40] train: loss: 0.6925436
[Epoch 4] ogbg-molclintox: 0.465243 val loss: 0.692166
[Epoch 4] ogbg-molclintox: 0.492405 test loss: 0.693064
[Epoch 5; Iter    20/   40] train: loss: 0.6924810
[Epoch 5] ogbg-molclintox: 0.468540 val loss: 0.691044
[Epoch 5] ogbg-molclintox: 0.488371 test loss: 0.692189
[Epoch 6; Iter    10/   40] train: loss: 0.6917564
[Epoch 6; Iter    40/   40] train: loss: 0.6905861
[Epoch 6] ogbg-molclintox: 0.481015 val loss: 0.690270
[Epoch 6] ogbg-molclintox: 0.496540 test loss: 0.691694
[Epoch 7; Iter    30/   40] train: loss: 0.6900141
[Epoch 7] ogbg-molclintox: 0.466354 val loss: 0.688802
[Epoch 7] ogbg-molclintox: 0.498751 test loss: 0.690683
[Epoch 8; Iter    20/   40] train: loss: 0.6913281
[Epoch 8] ogbg-molclintox: 0.453693 val loss: 0.688768
[Epoch 8] ogbg-molclintox: 0.496066 test loss: 0.689756
[Epoch 9; Iter    10/   40] train: loss: 0.6883451
[Epoch 9; Iter    40/   40] train: loss: 0.6899762
[Epoch 9] ogbg-molclintox: 0.481763 val loss: 0.686636
[Epoch 9] ogbg-molclintox: 0.497489 test loss: 0.688651
[Epoch 10; Iter    30/   40] train: loss: 0.6878768
[Epoch 10] ogbg-molclintox: 0.466354 val loss: 0.686224
[Epoch 10] ogbg-molclintox: 0.493455 test loss: 0.687543
[Epoch 11; Iter    20/   40] train: loss: 0.6849096
[Epoch 11] ogbg-molclintox: 0.473821 val loss: 0.684343
[Epoch 11] ogbg-molclintox: 0.503884 test loss: 0.686226
[Epoch 12; Iter    10/   40] train: loss: 0.6838738
[Epoch 12; Iter    40/   40] train: loss: 0.6859403
[Epoch 12] ogbg-molclintox: 0.482800 val loss: 0.683498
[Epoch 12] ogbg-molclintox: 0.501086 test loss: 0.685164
[Epoch 13; Iter    30/   40] train: loss: 0.6840032
[Epoch 13] ogbg-molclintox: 0.475044 val loss: 0.680580
[Epoch 13] ogbg-molclintox: 0.501912 test loss: 0.682924
[Epoch 14; Iter    20/   40] train: loss: 0.6812614
[Epoch 14] ogbg-molclintox: 0.494337 val loss: 0.678344
[Epoch 14] ogbg-molclintox: 0.498251 test loss: 0.680924
[Epoch 15; Iter    10/   40] train: loss: 0.6800463
[Epoch 15; Iter    40/   40] train: loss: 0.6766953
[Epoch 15] ogbg-molclintox: 0.483123 val loss: 0.677273
[Epoch 15] ogbg-molclintox: 0.507197 test loss: 0.679588
[Epoch 16; Iter    30/   40] train: loss: 0.6756249
[Epoch 16] ogbg-molclintox: 0.479553 val loss: 0.675650
[Epoch 16] ogbg-molclintox: 0.500761 test loss: 0.677696
[Epoch 17; Iter    20/   40] train: loss: 0.6745874
[Epoch 17] ogbg-molclintox: 0.482125 val loss: 0.672826
[Epoch 17] ogbg-molclintox: 0.504709 test loss: 0.675402
[Epoch 18; Iter    10/   40] train: loss: 0.6714396
[Epoch 18; Iter    40/   40] train: loss: 0.6601542
[Epoch 18] ogbg-molclintox: 0.704996 val loss: 0.653071
[Epoch 18] ogbg-molclintox: 0.634188 test loss: 0.669855
[Epoch 19; Iter    30/   40] train: loss: 0.6434895
[Epoch 19] ogbg-molclintox: 0.765684 val loss: 0.680171
[Epoch 19] ogbg-molclintox: 0.608602 test loss: 0.662226
[Epoch 20; Iter    20/   40] train: loss: 0.6146854
[Epoch 20] ogbg-molclintox: 0.679663 val loss: 0.634147
[Epoch 20] ogbg-molclintox: 0.560771 test loss: 0.596960
[Epoch 21; Iter    10/   40] train: loss: 0.5369684
[Epoch 21; Iter    40/   40] train: loss: 0.4754680
[Epoch 21] ogbg-molclintox: 0.711079 val loss: 0.532818
[Epoch 21] ogbg-molclintox: 0.663066 test loss: 0.512131
[Epoch 22; Iter    30/   40] train: loss: 0.4224999
[Epoch 22] ogbg-molclintox: 0.832589 val loss: 0.395449
[Epoch 22] ogbg-molclintox: 0.675523 test loss: 0.465073
[Epoch 23; Iter    20/   40] train: loss: 0.4295991
[Epoch 23] ogbg-molclintox: 0.698667 val loss: 0.438658
[Epoch 23] ogbg-molclintox: 0.645040 test loss: 0.375941
[Epoch 24; Iter    10/   40] train: loss: 0.3165945
[Epoch 24; Iter    40/   40] train: loss: 0.3532533
[Epoch 24] ogbg-molclintox: 0.758990 val loss: 0.277617
[Epoch 24] ogbg-molclintox: 0.701319 test loss: 0.351332
[Epoch 25; Iter    30/   40] train: loss: 0.3070916
[Epoch 25] ogbg-molclintox: 0.879527 val loss: 0.324053
[Epoch 25] ogbg-molclintox: 0.704539 test loss: 0.354807
[Epoch 26; Iter    20/   40] train: loss: 0.1932262
[Epoch 26] ogbg-molclintox: 0.889180 val loss: 0.205910
[Epoch 26] ogbg-molclintox: 0.608277 test loss: 0.280941
[Epoch 27; Iter    10/   40] train: loss: 0.2136182
[Epoch 27; Iter    40/   40] train: loss: 0.1810317
[Epoch 27] ogbg-molclintox: 0.807502 val loss: 0.198696
[Epoch 27] ogbg-molclintox: 0.673058 test loss: 0.247413
[Epoch 28; Iter    30/   40] train: loss: 0.2130024
[Epoch 28] ogbg-molclintox: 0.877144 val loss: 0.149172
[Epoch 28] ogbg-molclintox: 0.674298 test loss: 0.335700
[Epoch 29; Iter    20/   40] train: loss: 0.3423033
[Epoch 29] ogbg-molclintox: 0.838732 val loss: 0.146394
[Epoch 29] ogbg-molclintox: 0.698708 test loss: 0.233396
[Epoch 30; Iter    10/   40] train: loss: 0.1812040
[Epoch 30; Iter    40/   40] train: loss: 0.0976095
[Epoch 30] ogbg-molclintox: 0.852194 val loss: 0.142879
[Epoch 30] ogbg-molclintox: 0.631200 test loss: 0.240127
[Epoch 31; Iter    30/   40] train: loss: 0.2157429
[Epoch 31] ogbg-molclintox: 0.842478 val loss: 0.180818
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/static_noise/3DInfomax/clintox/noise=0.0/PNA_ogbg-molclintox_3DInfomax_clintox_static_noise=0.0_6_26-05_09-18-23
config: <_io.TextIOWrapper name='configs_static_noise_experiments/3DInfomax/clintox/noise=0.0.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_static_noise=0.0
logdir: runs/static_noise/3DInfomax/clintox/noise=0.0
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: False
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6934478
[Epoch 1] ogbg-molclintox: 0.487903 val loss: 0.692126
[Epoch 1] ogbg-molclintox: 0.471031 test loss: 0.692166
[Epoch 2; Iter    20/   40] train: loss: 0.6932403
[Epoch 2] ogbg-molclintox: 0.444307 val loss: 0.690806
[Epoch 2] ogbg-molclintox: 0.478263 test loss: 0.691136
[Epoch 3; Iter    10/   40] train: loss: 0.6932287
[Epoch 3; Iter    40/   40] train: loss: 0.6925523
[Epoch 3] ogbg-molclintox: 0.433867 val loss: 0.689739
[Epoch 3] ogbg-molclintox: 0.483372 test loss: 0.690132
[Epoch 4; Iter    30/   40] train: loss: 0.6920084
[Epoch 4] ogbg-molclintox: 0.430669 val loss: 0.690009
[Epoch 4] ogbg-molclintox: 0.482173 test loss: 0.690224
[Epoch 5; Iter    20/   40] train: loss: 0.6925848
[Epoch 5] ogbg-molclintox: 0.450274 val loss: 0.689134
[Epoch 5] ogbg-molclintox: 0.486932 test loss: 0.689449
[Epoch 6; Iter    10/   40] train: loss: 0.6908295
[Epoch 6; Iter    40/   40] train: loss: 0.6904486
[Epoch 6] ogbg-molclintox: 0.429422 val loss: 0.688672
[Epoch 6] ogbg-molclintox: 0.484321 test loss: 0.688949
[Epoch 7; Iter    30/   40] train: loss: 0.6899174
[Epoch 7] ogbg-molclintox: 0.453008 val loss: 0.687762
[Epoch 7] ogbg-molclintox: 0.468596 test loss: 0.687863
[Epoch 8; Iter    20/   40] train: loss: 0.6886778
[Epoch 8] ogbg-molclintox: 0.463048 val loss: 0.685917
[Epoch 8] ogbg-molclintox: 0.487470 test loss: 0.686741
[Epoch 9; Iter    10/   40] train: loss: 0.6890686
[Epoch 9; Iter    40/   40] train: loss: 0.6866022
[Epoch 9] ogbg-molclintox: 0.443306 val loss: 0.685542
[Epoch 9] ogbg-molclintox: 0.487795 test loss: 0.685763
[Epoch 10; Iter    30/   40] train: loss: 0.6862919
[Epoch 10] ogbg-molclintox: 0.467356 val loss: 0.683264
[Epoch 10] ogbg-molclintox: 0.482547 test loss: 0.684032
[Epoch 11; Iter    20/   40] train: loss: 0.6848166
[Epoch 11] ogbg-molclintox: 0.458965 val loss: 0.682190
[Epoch 11] ogbg-molclintox: 0.485797 test loss: 0.682923
[Epoch 12; Iter    10/   40] train: loss: 0.6851652
[Epoch 12; Iter    40/   40] train: loss: 0.6820204
[Epoch 12] ogbg-molclintox: 0.467855 val loss: 0.680804
[Epoch 12] ogbg-molclintox: 0.485147 test loss: 0.682291
[Epoch 13; Iter    30/   40] train: loss: 0.6852475
[Epoch 13] ogbg-molclintox: 0.458715 val loss: 0.678089
[Epoch 13] ogbg-molclintox: 0.484310 test loss: 0.679402
[Epoch 14; Iter    20/   40] train: loss: 0.6790775
[Epoch 14] ogbg-molclintox: 0.450896 val loss: 0.677733
[Epoch 14] ogbg-molclintox: 0.487283 test loss: 0.678875
[Epoch 15; Iter    10/   40] train: loss: 0.6796404
[Epoch 15; Iter    40/   40] train: loss: 0.6757994
[Epoch 15] ogbg-molclintox: 0.491505 val loss: 0.675888
[Epoch 15] ogbg-molclintox: 0.493054 test loss: 0.677443
[Epoch 16; Iter    30/   40] train: loss: 0.6742938
[Epoch 16] ogbg-molclintox: 0.481254 val loss: 0.671603
[Epoch 16] ogbg-molclintox: 0.491105 test loss: 0.673235
[Epoch 17; Iter    20/   40] train: loss: 0.6734114
[Epoch 17] ogbg-molclintox: 0.482878 val loss: 0.668616
[Epoch 17] ogbg-molclintox: 0.496439 test loss: 0.670941
[Epoch 18; Iter    10/   40] train: loss: 0.6707343
[Epoch 18; Iter    40/   40] train: loss: 0.6629328
[Epoch 18] ogbg-molclintox: 0.687514 val loss: 0.673913
[Epoch 18] ogbg-molclintox: 0.616502 test loss: 0.691955
[Epoch 19; Iter    30/   40] train: loss: 0.6441582
[Epoch 19] ogbg-molclintox: 0.734377 val loss: 0.647526
[Epoch 19] ogbg-molclintox: 0.619822 test loss: 0.648917
[Epoch 20; Iter    20/   40] train: loss: 0.6314338
[Epoch 20] ogbg-molclintox: 0.802947 val loss: 0.580672
[Epoch 20] ogbg-molclintox: 0.577808 test loss: 0.560349
[Epoch 21; Iter    10/   40] train: loss: 0.5436885
[Epoch 21; Iter    40/   40] train: loss: 0.4815641
[Epoch 21] ogbg-molclintox: 0.784752 val loss: 0.452325
[Epoch 21] ogbg-molclintox: 0.627252 test loss: 0.497630
[Epoch 22; Iter    30/   40] train: loss: 0.4441553
[Epoch 22] ogbg-molclintox: 0.733580 val loss: 0.437480
[Epoch 22] ogbg-molclintox: 0.672524 test loss: 0.480988
[Epoch 23; Iter    20/   40] train: loss: 0.4067132
[Epoch 23] ogbg-molclintox: 0.807639 val loss: 0.439307
[Epoch 23] ogbg-molclintox: 0.745216 test loss: 0.517334
[Epoch 24; Iter    10/   40] train: loss: 0.3762583
[Epoch 24; Iter    40/   40] train: loss: 0.2670995
[Epoch 24] ogbg-molclintox: 0.723603 val loss: 0.250404
[Epoch 24] ogbg-molclintox: 0.623483 test loss: 0.336670
[Epoch 25; Iter    30/   40] train: loss: 0.2167194
[Epoch 25] ogbg-molclintox: 0.755669 val loss: 0.244063
[Epoch 25] ogbg-molclintox: 0.730174 test loss: 0.298607
[Epoch 26; Iter    20/   40] train: loss: 0.2779230
[Epoch 26] ogbg-molclintox: 0.760051 val loss: 0.395770
[Epoch 26] ogbg-molclintox: 0.701566 test loss: 0.309540
[Epoch 27; Iter    10/   40] train: loss: 0.2270784
[Epoch 27; Iter    40/   40] train: loss: 0.1072790
[Epoch 27] ogbg-molclintox: 0.822124 val loss: 0.192718
[Epoch 27] ogbg-molclintox: 0.667664 test loss: 0.279213
[Epoch 28; Iter    30/   40] train: loss: 0.2387445
[Epoch 28] ogbg-molclintox: 0.770867 val loss: 0.242338
[Epoch 28] ogbg-molclintox: 0.595909 test loss: 0.283054
[Epoch 29; Iter    20/   40] train: loss: 0.2415772
[Epoch 29] ogbg-molclintox: 0.790582 val loss: 0.150508
[Epoch 29] ogbg-molclintox: 0.684742 test loss: 0.235386
[Epoch 30; Iter    10/   40] train: loss: 0.2692940
[Epoch 30; Iter    40/   40] train: loss: 0.1143826
[Epoch 30] ogbg-molclintox: 0.858175 val loss: 0.198107
[Epoch 30] ogbg-molclintox: 0.670697 test loss: 0.256192
[Epoch 31; Iter    30/   40] train: loss: 0.2725683
[Epoch 31] ogbg-molclintox: 0.860983 val loss: 0.145708
[Epoch 31] ogbg-molclintox: 0.547421 test loss: 1.198624
[Epoch 32; Iter    20/   40] train: loss: 0.2014548
[Epoch 32] ogbg-molclintox: 0.822725 val loss: 0.413876
[Epoch 32] ogbg-molclintox: 0.565171 test loss: 1.055685
[Epoch 33; Iter    10/   40] train: loss: 0.0759995
[Epoch 33; Iter    40/   40] train: loss: 0.2222508
[Epoch 33] ogbg-molclintox: 0.829792 val loss: 0.319636
[Epoch 33] ogbg-molclintox: 0.597313 test loss: 1.007702
[Epoch 34; Iter    30/   40] train: loss: 0.0839419
[Epoch 34] ogbg-molclintox: 0.834912 val loss: 0.391785
[Epoch 34] ogbg-molclintox: 0.612654 test loss: 1.062570
[Epoch 35; Iter    20/   40] train: loss: 0.3093140
[Epoch 35] ogbg-molclintox: 0.828643 val loss: 0.138208
[Epoch 35] ogbg-molclintox: 0.627719 test loss: 0.416352
[Epoch 36; Iter    10/   40] train: loss: 0.1729973
[Epoch 36; Iter    40/   40] train: loss: 0.2114209
[Epoch 36] ogbg-molclintox: 0.846188 val loss: 0.118243
[Epoch 36] ogbg-molclintox: 0.681320 test loss: 0.412276
[Epoch 37; Iter    30/   40] train: loss: 0.2273972
[Epoch 37] ogbg-molclintox: 0.942098 val loss: 0.228273
[Epoch 37] ogbg-molclintox: 0.727836 test loss: 3.281923
[Epoch 38; Iter    20/   40] train: loss: 0.0593029
[Epoch 38] ogbg-molclintox: 0.816530 val loss: 0.152533
[Epoch 38] ogbg-molclintox: 0.876280 test loss: 0.225336
[Epoch 39; Iter    10/   40] train: loss: 0.0946959
[Epoch 39; Iter    40/   40] train: loss: 0.2426047
[Epoch 39] ogbg-molclintox: 0.957782 val loss: 1.409959
[Epoch 39] ogbg-molclintox: 0.820015 test loss: 3.936897
[Epoch 40; Iter    30/   40] train: loss: 0.1170160
[Epoch 40] ogbg-molclintox: 0.969357 val loss: 0.075034
[Epoch 40] ogbg-molclintox: 0.899928 test loss: 0.662977
[Epoch 41; Iter    20/   40] train: loss: 0.0597693
[Epoch 41] ogbg-molclintox: 0.974052 val loss: 0.073571
[Epoch 41] ogbg-molclintox: 0.888110 test loss: 2.738565
[Epoch 42; Iter    10/   40] train: loss: 0.1389236
[Epoch 42; Iter    40/   40] train: loss: 0.0982113
[Epoch 42] ogbg-molclintox: 0.871434 val loss: 0.160140
[Epoch 42] ogbg-molclintox: 0.871009 test loss: 1.436908
[Epoch 43; Iter    30/   40] train: loss: 0.0660166
[Epoch 43] ogbg-molclintox: 0.902066 val loss: 2.577127
[Epoch 43] ogbg-molclintox: 0.814431 test loss: 2.410968
[Epoch 44; Iter    20/   40] train: loss: 0.0757886
[Epoch 44] ogbg-molclintox: 0.873120 val loss: 0.143533
[Epoch 44] ogbg-molclintox: 0.713832 test loss: 4.965399
[Epoch 45; Iter    10/   40] train: loss: 0.3046361
[Epoch 45; Iter    40/   40] train: loss: 0.0826573
[Epoch 45] ogbg-molclintox: 0.954398 val loss: 0.212458
[Epoch 45] ogbg-molclintox: 0.831968 test loss: 6.458843
[Epoch 46; Iter    30/   40] train: loss: 0.0516415
[Epoch 46] ogbg-molclintox: 0.938040 val loss: 0.443039
[Epoch 46] ogbg-molclintox: 0.805347 test loss: 3.166271
[Epoch 47; Iter    20/   40] train: loss: 0.0408311
[Epoch 47] ogbg-molclintox: 0.965249 val loss: 0.872546
[Epoch 47] ogbg-molclintox: 0.790720 test loss: 3.188582
[Epoch 48; Iter    10/   40] train: loss: 0.1079077
[Epoch 48; Iter    40/   40] train: loss: 0.0788321
[Epoch 48] ogbg-molclintox: 0.679090 val loss: 0.410873
[Epoch 48] ogbg-molclintox: 0.528054 test loss: 7.922677
[Epoch 49; Iter    30/   40] train: loss: 0.0356411
[Epoch 49] ogbg-molclintox: 0.748363 val loss: 0.331005
[Epoch 49] ogbg-molclintox: 0.812377 test loss: 0.238000
[Epoch 50; Iter    20/   40] train: loss: 0.0447536
[Epoch 50] ogbg-molclintox: 0.844452 val loss: 0.205224
[Epoch 50] ogbg-molclintox: 0.753916 test loss: 0.863839
[Epoch 51; Iter    10/   40] train: loss: 0.0216989
[Epoch 51; Iter    40/   40] train: loss: 0.0269617
[Epoch 51] ogbg-molclintox: 0.894560 val loss: 0.146258
[Epoch 51] ogbg-molclintox: 0.878073 test loss: 0.246152
[Epoch 52; Iter    30/   40] train: loss: 0.0097148
[Epoch 52] ogbg-molclintox: 0.863292 val loss: 0.116723
[Epoch 52] ogbg-molclintox: 0.845135 test loss: 0.625973
[Epoch 53; Iter    20/   40] train: loss: 0.0350706
[Epoch 53] ogbg-molclintox: 0.939340 val loss: 0.121719
[Epoch 53] ogbg-molclintox: 0.801742 test loss: 1.115131
[Epoch 54; Iter    10/   40] train: loss: 0.0348147
[Epoch 54; Iter    40/   40] train: loss: 0.0098295
[Epoch 54] ogbg-molclintox: 0.945008 val loss: 0.084398
[Epoch 54] ogbg-molclintox: 0.832932 test loss: 0.533681
[Epoch 55; Iter    30/   40] train: loss: 0.0635928
[Epoch 55] ogbg-molclintox: 0.813757 val loss: 0.212509
[Epoch 55] ogbg-molclintox: 0.876216 test loss: 0.438834
[Epoch 56; Iter    20/   40] train: loss: 0.0108184
[Epoch 56] ogbg-molclintox: 0.898981 val loss: 0.116993
[Epoch 56] ogbg-molclintox: 0.825148 test loss: 0.520072
[Epoch 57; Iter    10/   40] train: loss: 0.0126299
[Epoch 57; Iter    40/   40] train: loss: 0.0058824
[Epoch 57] ogbg-molclintox: 0.963264 val loss: 0.125123
[Epoch 57] ogbg-molclintox: 0.833690 test loss: 0.573388
[Epoch 58; Iter    30/   40] train: loss: 0.0065236
[Epoch 58] ogbg-molclintox: 0.960192 val loss: 0.104463
[Epoch 58] ogbg-molclintox: 0.870255 test loss: 1.382456
[Epoch 59; Iter    20/   40] train: loss: 0.0049128
[Epoch 59] ogbg-molclintox: 0.981182 val loss: 0.127224
[Epoch 59] ogbg-molclintox: 0.869011 test loss: 1.397951
[Epoch 60; Iter    10/   40] train: loss: 0.0351232
[Epoch 60; Iter    40/   40] train: loss: 0.2222135
[Epoch 60] ogbg-molclintox: 0.954124 val loss: 0.282988
[Epoch 60] ogbg-molclintox: 0.843790 test loss: 1.924987
[Epoch 61; Iter    30/   40] train: loss: 0.1548121
[Epoch 61] ogbg-molclintox: 0.972067 val loss: 0.085212
[Epoch 61] ogbg-molclintox: 0.844425 test loss: 0.255799
[Epoch 62; Iter    20/   40] train: loss: 0.0387051
[Epoch 62] ogbg-molclintox: 0.909909 val loss: 0.165394
[Epoch 62] ogbg-molclintox: 0.899738 test loss: 1.011184
[Epoch 63; Iter    10/   40] train: loss: 0.0372085
[Epoch 63; Iter    40/   40] train: loss: 0.0066025
[Epoch 63] ogbg-molclintox: 0.957444 val loss: 0.126461
[Epoch 63] ogbg-molclintox: 0.784011 test loss: 0.429593
[Epoch 64; Iter    30/   40] train: loss: 0.0701039
[Epoch 64] ogbg-molclintox: 0.914277 val loss: 2.506961
[Epoch 64] ogbg-molclintox: 0.838692 test loss: 1.779765
[Epoch 65; Iter    20/   40] train: loss: 0.0240834
[Epoch 65] ogbg-molclintox: 0.949854 val loss: 0.090986
[Epoch 65] ogbg-molclintox: 0.825495 test loss: 0.588781
[Epoch 66; Iter    10/   40] train: loss: 0.0275501
[Epoch 66; Iter    40/   40] train: loss: 0.0133315
[Epoch 66] ogbg-molclintox: 0.914365 val loss: 0.120469
[Epoch 66] ogbg-molclintox: 0.831479 test loss: 0.657967
[Epoch 67; Iter    30/   40] train: loss: 0.0066363
[Epoch 67] ogbg-molclintox: 0.935731 val loss: 0.145094
[Epoch 67] ogbg-molclintox: 0.853865 test loss: 0.736616
[Epoch 68; Iter    20/   40] train: loss: 0.0059664
[Epoch 68] ogbg-molclintox: 0.919636 val loss: 0.167148
[Epoch 68] ogbg-molclintox: 0.894594 test loss: 0.702946
[Epoch 69; Iter    10/   40] train: loss: 0.0393489
[Epoch 69; Iter    40/   40] train: loss: 0.0195701
[Epoch 69] ogbg-molclintox: 0.746691 val loss: 0.237017
[Epoch 69] ogbg-molclintox: 0.849210 test loss: 1.011588
[Epoch 70; Iter    30/   40] train: loss: 0.0027247
[Epoch 70] ogbg-molclintox: 0.970306 val loss: 0.102735
[Epoch 70] ogbg-molclintox: 0.890355 test loss: 0.814875
[Epoch 71; Iter    20/   40] train: loss: 0.0115124
[Epoch 71] ogbg-molclintox: 0.902066 val loss: 0.414956
[Epoch 71] ogbg-molclintox: 0.810054 test loss: 1.031521
[Epoch 72; Iter    10/   40] train: loss: 0.0028272
[Epoch 72; Iter    40/   40] train: loss: 0.0057829
[Epoch 72] ogbg-molclintox: 0.879003 val loss: 0.137278
[Epoch 72] ogbg-molclintox: 0.850178 test loss: 0.317512
[Epoch 73; Iter    30/   40] train: loss: 0.0274110
[Epoch 73] ogbg-molclintox: 0.942411 val loss: 0.237245
[Epoch 73] ogbg-molclintox: 0.923449 test loss: 0.617776
[Epoch 74; Iter    20/   40] train: loss: 0.0081945
[Epoch 74] ogbg-molclintox: 0.909684 val loss: 0.136909
[Epoch 74] ogbg-molclintox: 0.815089 test loss: 0.314610
[Epoch 75; Iter    10/   40] train: loss: 0.0408898
[Epoch 75; Iter    40/   40] train: loss: 0.0128593
[Epoch 75] ogbg-molclintox: 0.901230 val loss: 0.129714
[Epoch 75] ogbg-molclintox: 0.765309 test loss: 0.432491
[Epoch 76; Iter    30/   40] train: loss: 0.0032643
[Epoch 31] ogbg-molclintox: 0.633878 test loss: 0.262356
[Epoch 32; Iter    20/   40] train: loss: 0.2596339
[Epoch 32] ogbg-molclintox: 0.663765 val loss: 0.149497
[Epoch 32] ogbg-molclintox: 0.631641 test loss: 0.273269
[Epoch 33; Iter    10/   40] train: loss: 0.2711861
[Epoch 33; Iter    40/   40] train: loss: 0.3466870
[Epoch 33] ogbg-molclintox: 0.741483 val loss: 0.161789
[Epoch 33] ogbg-molclintox: 0.669091 test loss: 0.275415
[Epoch 34; Iter    30/   40] train: loss: 0.1063672
[Epoch 34] ogbg-molclintox: 0.670558 val loss: 0.153063
[Epoch 34] ogbg-molclintox: 0.653627 test loss: 0.253603
[Epoch 35; Iter    20/   40] train: loss: 0.1317031
[Epoch 35] ogbg-molclintox: 0.755346 val loss: 0.144075
[Epoch 35] ogbg-molclintox: 0.735060 test loss: 0.226393
[Epoch 36; Iter    10/   40] train: loss: 0.1737815
[Epoch 36; Iter    40/   40] train: loss: 0.2186027
[Epoch 36] ogbg-molclintox: 0.863256 val loss: 0.115335
[Epoch 36] ogbg-molclintox: 0.807875 test loss: 0.527068
[Epoch 37; Iter    30/   40] train: loss: 0.1039252
[Epoch 37] ogbg-molclintox: 0.767656 val loss: 0.161620
[Epoch 37] ogbg-molclintox: 0.849274 test loss: 0.527229
[Epoch 38; Iter    20/   40] train: loss: 0.2446805
[Epoch 38] ogbg-molclintox: 0.765670 val loss: 0.160786
[Epoch 38] ogbg-molclintox: 0.773148 test loss: 0.821273
[Epoch 39; Iter    10/   40] train: loss: 0.0768974
[Epoch 39; Iter    40/   40] train: loss: 0.2001546
[Epoch 39] ogbg-molclintox: 0.693821 val loss: 0.154558
[Epoch 39] ogbg-molclintox: 0.725113 test loss: 0.273078
[Epoch 40; Iter    30/   40] train: loss: 0.2474218
[Epoch 40] ogbg-molclintox: 0.854004 val loss: 0.994870
[Epoch 40] ogbg-molclintox: 0.653152 test loss: 0.262675
[Epoch 41; Iter    20/   40] train: loss: 0.0864235
[Epoch 41] ogbg-molclintox: 0.918498 val loss: 0.109483
[Epoch 41] ogbg-molclintox: 0.876239 test loss: 0.182163
[Epoch 42; Iter    10/   40] train: loss: 0.0705121
[Epoch 42; Iter    40/   40] train: loss: 0.0757124
[Epoch 42] ogbg-molclintox: 0.797350 val loss: 0.125184
[Epoch 42] ogbg-molclintox: 0.824662 test loss: 0.271977
[Epoch 43; Iter    30/   40] train: loss: 0.1204752
[Epoch 43] ogbg-molclintox: 0.800534 val loss: 0.139786
[Epoch 43] ogbg-molclintox: 0.755253 test loss: 0.229632
[Epoch 44; Iter    20/   40] train: loss: 0.0396903
[Epoch 44] ogbg-molclintox: 0.959405 val loss: 0.128475
[Epoch 44] ogbg-molclintox: 0.777904 test loss: 0.582771
[Epoch 45; Iter    10/   40] train: loss: 0.2328825
[Epoch 45; Iter    40/   40] train: loss: 0.0660866
[Epoch 45] ogbg-molclintox: 0.950065 val loss: 0.086185
[Epoch 45] ogbg-molclintox: 0.868682 test loss: 0.190076
[Epoch 46; Iter    30/   40] train: loss: 0.1146942
[Epoch 46] ogbg-molclintox: 0.885894 val loss: 0.208787
[Epoch 46] ogbg-molclintox: 0.889346 test loss: 0.526228
[Epoch 47; Iter    20/   40] train: loss: 0.0593908
[Epoch 47] ogbg-molclintox: 0.904575 val loss: 0.210243
[Epoch 47] ogbg-molclintox: 0.859326 test loss: 0.453547
[Epoch 48; Iter    10/   40] train: loss: 0.0438411
[Epoch 48; Iter    40/   40] train: loss: 0.0442527
[Epoch 48] ogbg-molclintox: 0.871272 val loss: 0.105986
[Epoch 48] ogbg-molclintox: 0.903835 test loss: 0.169365
[Epoch 49; Iter    30/   40] train: loss: 0.0178076
[Epoch 49] ogbg-molclintox: 0.915627 val loss: 0.143985
[Epoch 49] ogbg-molclintox: 0.802635 test loss: 0.732273
[Epoch 50; Iter    20/   40] train: loss: 0.0334351
[Epoch 50] ogbg-molclintox: 0.901939 val loss: 0.143500
[Epoch 50] ogbg-molclintox: 0.872556 test loss: 0.401793
[Epoch 51; Iter    10/   40] train: loss: 0.0203235
[Epoch 51; Iter    40/   40] train: loss: 0.3093739
[Epoch 51] ogbg-molclintox: 0.935242 val loss: 0.088336
[Epoch 51] ogbg-molclintox: 0.841613 test loss: 0.187224
[Epoch 52; Iter    30/   40] train: loss: 0.0220522
[Epoch 52] ogbg-molclintox: 0.931647 val loss: 0.146186
[Epoch 52] ogbg-molclintox: 0.816389 test loss: 0.290554
[Epoch 53; Iter    20/   40] train: loss: 0.0834662
[Epoch 53] ogbg-molclintox: 0.908771 val loss: 0.102341
[Epoch 53] ogbg-molclintox: 0.855067 test loss: 0.282357
[Epoch 54; Iter    10/   40] train: loss: 0.0683875
[Epoch 54; Iter    40/   40] train: loss: 0.0142714
[Epoch 54] ogbg-molclintox: 0.790156 val loss: 0.117294
[Epoch 54] ogbg-molclintox: 0.895965 test loss: 0.184231
[Epoch 55; Iter    30/   40] train: loss: 0.0765833
[Epoch 55] ogbg-molclintox: 0.890765 val loss: 0.189821
[Epoch 55] ogbg-molclintox: 0.758503 test loss: 0.347025
[Epoch 56; Iter    20/   40] train: loss: 0.0107269
[Epoch 56] ogbg-molclintox: 0.822535 val loss: 0.127830
[Epoch 56] ogbg-molclintox: 0.783735 test loss: 0.719250
[Epoch 57; Iter    10/   40] train: loss: 0.0644384
[Epoch 57; Iter    40/   40] train: loss: 0.0433103
[Epoch 57] ogbg-molclintox: 0.812784 val loss: 0.142469
[Epoch 57] ogbg-molclintox: 0.835132 test loss: 0.302025
[Epoch 58; Iter    30/   40] train: loss: 0.0906965
[Epoch 58] ogbg-molclintox: 0.882623 val loss: 0.132198
[Epoch 58] ogbg-molclintox: 0.856715 test loss: 0.942939
[Epoch 59; Iter    20/   40] train: loss: 0.0517186
[Epoch 59] ogbg-molclintox: 0.858597 val loss: 0.128040
[Epoch 59] ogbg-molclintox: 0.846771 test loss: 0.197107
[Epoch 60; Iter    10/   40] train: loss: 0.0150391
[Epoch 60; Iter    40/   40] train: loss: 0.0205248
[Epoch 60] ogbg-molclintox: 0.830502 val loss: 0.135840
[Epoch 60] ogbg-molclintox: 0.778576 test loss: 0.245395
[Epoch 61; Iter    30/   40] train: loss: 0.0359224
[Epoch 61] ogbg-molclintox: 0.928762 val loss: 0.100740
[Epoch 61] ogbg-molclintox: 0.805821 test loss: 0.272740
[Epoch 62; Iter    20/   40] train: loss: 0.0963924
[Epoch 62] ogbg-molclintox: 0.832375 val loss: 0.134756
[Epoch 62] ogbg-molclintox: 0.829320 test loss: 0.215276
[Epoch 63; Iter    10/   40] train: loss: 0.0286801
[Epoch 63; Iter    40/   40] train: loss: 0.0031695
[Epoch 63] ogbg-molclintox: 0.861668 val loss: 0.136486
[Epoch 63] ogbg-molclintox: 0.818077 test loss: 0.216913
[Epoch 64; Iter    30/   40] train: loss: 0.0081599
[Epoch 64] ogbg-molclintox: 0.852890 val loss: 0.114576
[Epoch 64] ogbg-molclintox: 0.837164 test loss: 0.285537
[Epoch 65; Iter    20/   40] train: loss: 0.0064641
[Epoch 65] ogbg-molclintox: 0.870534 val loss: 0.116160
[Epoch 65] ogbg-molclintox: 0.863397 test loss: 0.286871
[Epoch 66; Iter    10/   40] train: loss: 0.0088953
[Epoch 66; Iter    40/   40] train: loss: 0.0052764
[Epoch 66] ogbg-molclintox: 0.852328 val loss: 0.143960
[Epoch 66] ogbg-molclintox: 0.862135 test loss: 0.364790
[Epoch 67; Iter    30/   40] train: loss: 0.0027415
[Epoch 67] ogbg-molclintox: 0.819763 val loss: 0.144631
[Epoch 67] ogbg-molclintox: 0.879862 test loss: 0.188723
[Epoch 68; Iter    20/   40] train: loss: 0.0112717
[Epoch 68] ogbg-molclintox: 0.823734 val loss: 0.167244
[Epoch 68] ogbg-molclintox: 0.880351 test loss: 0.253154
[Epoch 69; Iter    10/   40] train: loss: 0.0022628
[Epoch 69; Iter    40/   40] train: loss: 0.0334587
[Epoch 69] ogbg-molclintox: 0.813107 val loss: 0.146079
[Epoch 69] ogbg-molclintox: 0.811835 test loss: 0.231315
[Epoch 70; Iter    30/   40] train: loss: 0.0341959
[Epoch 70] ogbg-molclintox: 0.836620 val loss: 0.151572
[Epoch 70] ogbg-molclintox: 0.824924 test loss: 0.244345
[Epoch 71; Iter    20/   40] train: loss: 0.0182427
[Epoch 71] ogbg-molclintox: 0.834908 val loss: 0.128130
[Epoch 71] ogbg-molclintox: 0.829933 test loss: 0.233959
[Epoch 72; Iter    10/   40] train: loss: 0.0049208
[Epoch 72; Iter    40/   40] train: loss: 0.0413001
[Epoch 72] ogbg-molclintox: 0.884619 val loss: 0.117648
[Epoch 72] ogbg-molclintox: 0.846286 test loss: 0.262120
[Epoch 73; Iter    30/   40] train: loss: 0.0705652
[Epoch 73] ogbg-molclintox: 0.939786 val loss: 0.110587
[Epoch 73] ogbg-molclintox: 0.861249 test loss: 0.240382
[Epoch 74; Iter    20/   40] train: loss: 0.0072424
[Epoch 74] ogbg-molclintox: 0.845285 val loss: 0.143147
[Epoch 74] ogbg-molclintox: 0.886896 test loss: 0.212513
[Epoch 75; Iter    10/   40] train: loss: 0.0040324
[Epoch 75; Iter    40/   40] train: loss: 0.0021661
[Epoch 75] ogbg-molclintox: 0.873043 val loss: 0.132071
[Epoch 75] ogbg-molclintox: 0.883198 test loss: 0.235850
[Epoch 76; Iter    30/   40] train: loss: 0.0055090
[Epoch 31] ogbg-molclintox: 0.621473 test loss: 0.259357
[Epoch 32; Iter    20/   40] train: loss: 0.2068190
[Epoch 32] ogbg-molclintox: 0.608425 val loss: 0.358556
[Epoch 32] ogbg-molclintox: 0.589843 test loss: 0.245249
[Epoch 33; Iter    10/   40] train: loss: 0.1002638
[Epoch 33; Iter    40/   40] train: loss: 0.3850361
[Epoch 33] ogbg-molclintox: 0.629078 val loss: 0.337047
[Epoch 33] ogbg-molclintox: 0.546510 test loss: 0.254219
[Epoch 34; Iter    30/   40] train: loss: 0.0802692
[Epoch 34] ogbg-molclintox: 0.602806 val loss: 0.358025
[Epoch 34] ogbg-molclintox: 0.543974 test loss: 0.262286
[Epoch 35; Iter    20/   40] train: loss: 0.2881529
[Epoch 35] ogbg-molclintox: 0.694383 val loss: 0.186967
[Epoch 35] ogbg-molclintox: 0.641349 test loss: 0.258340
[Epoch 36; Iter    10/   40] train: loss: 0.1853626
[Epoch 36; Iter    40/   40] train: loss: 0.2744907
[Epoch 36] ogbg-molclintox: 0.854018 val loss: 1.810617
[Epoch 36] ogbg-molclintox: 0.745978 test loss: 0.882527
[Epoch 37; Iter    30/   40] train: loss: 0.1566220
[Epoch 37] ogbg-molclintox: 0.797515 val loss: 0.130326
[Epoch 37] ogbg-molclintox: 0.743853 test loss: 0.281900
[Epoch 38; Iter    20/   40] train: loss: 0.0937808
[Epoch 38] ogbg-molclintox: 0.803619 val loss: 1.236536
[Epoch 38] ogbg-molclintox: 0.778203 test loss: 0.592440
[Epoch 39; Iter    10/   40] train: loss: 0.1151193
[Epoch 39; Iter    40/   40] train: loss: 0.2475047
[Epoch 39] ogbg-molclintox: 0.967959 val loss: 0.196723
[Epoch 39] ogbg-molclintox: 0.794847 test loss: 0.386862
[Epoch 40; Iter    30/   40] train: loss: 0.1467215
[Epoch 40] ogbg-molclintox: 0.880451 val loss: 0.132507
[Epoch 40] ogbg-molclintox: 0.795482 test loss: 0.801491
[Epoch 41; Iter    20/   40] train: loss: 0.0817172
[Epoch 41] ogbg-molclintox: 0.791530 val loss: 0.243897
[Epoch 41] ogbg-molclintox: 0.772764 test loss: 1.195280
[Epoch 42; Iter    10/   40] train: loss: 0.0901076
[Epoch 42; Iter    40/   40] train: loss: 0.1394197
[Epoch 42] ogbg-molclintox: 0.828158 val loss: 0.128299
[Epoch 42] ogbg-molclintox: 0.739117 test loss: 0.484818
[Epoch 43; Iter    30/   40] train: loss: 0.1493843
[Epoch 43] ogbg-molclintox: 0.966697 val loss: 0.140068
[Epoch 43] ogbg-molclintox: 0.875918 test loss: 0.613153
[Epoch 44; Iter    20/   40] train: loss: 0.0692915
[Epoch 44] ogbg-molclintox: 0.923231 val loss: 0.150898
[Epoch 44] ogbg-molclintox: 0.734933 test loss: 0.737749
[Epoch 45; Iter    10/   40] train: loss: 0.1572315
[Epoch 45; Iter    40/   40] train: loss: 0.1289074
[Epoch 45] ogbg-molclintox: 0.926840 val loss: 0.420328
[Epoch 45] ogbg-molclintox: 0.770825 test loss: 0.642052
[Epoch 46; Iter    30/   40] train: loss: 0.1020365
[Epoch 46] ogbg-molclintox: 0.940313 val loss: 0.145806
[Epoch 46] ogbg-molclintox: 0.854966 test loss: 0.853054
[Epoch 47; Iter    20/   40] train: loss: 0.0779229
[Epoch 47] ogbg-molclintox: 0.943634 val loss: 0.165024
[Epoch 47] ogbg-molclintox: 0.820243 test loss: 0.619618
[Epoch 48; Iter    10/   40] train: loss: 0.0241870
[Epoch 48; Iter    40/   40] train: loss: 0.1654177
[Epoch 48] ogbg-molclintox: 0.993344 val loss: 0.054502
[Epoch 48] ogbg-molclintox: 0.811297 test loss: 0.251442
[Epoch 49; Iter    30/   40] train: loss: 0.0610220
[Epoch 49] ogbg-molclintox: 0.927251 val loss: 0.103833
[Epoch 49] ogbg-molclintox: 0.800891 test loss: 0.375987
[Epoch 50; Iter    20/   40] train: loss: 0.0600762
[Epoch 50] ogbg-molclintox: 0.971929 val loss: 0.122800
[Epoch 50] ogbg-molclintox: 0.729763 test loss: 0.396346
[Epoch 51; Iter    10/   40] train: loss: 0.0293859
[Epoch 51; Iter    40/   40] train: loss: 0.0110975
[Epoch 51] ogbg-molclintox: 0.989598 val loss: 0.076664
[Epoch 51] ogbg-molclintox: 0.735897 test loss: 0.569420
[Epoch 52; Iter    30/   40] train: loss: 0.0062638
[Epoch 52] ogbg-molclintox: 0.995442 val loss: 0.051478
[Epoch 52] ogbg-molclintox: 0.751723 test loss: 0.373640
[Epoch 53; Iter    20/   40] train: loss: 0.0374535
[Epoch 53] ogbg-molclintox: 0.939438 val loss: 0.299455
[Epoch 53] ogbg-molclintox: 0.814547 test loss: 1.044624
[Epoch 54; Iter    10/   40] train: loss: 0.0216078
[Epoch 54; Iter    40/   40] train: loss: 0.0284462
[Epoch 54] ogbg-molclintox: 0.990884 val loss: 0.057575
[Epoch 54] ogbg-molclintox: 0.792796 test loss: 0.348452
[Epoch 55; Iter    30/   40] train: loss: 0.0290442
[Epoch 55] ogbg-molclintox: 0.976512 val loss: 0.072962
[Epoch 55] ogbg-molclintox: 0.827086 test loss: 0.656711
[Epoch 56; Iter    20/   40] train: loss: 0.0076015
[Epoch 56] ogbg-molclintox: 0.973353 val loss: 0.084432
[Epoch 56] ogbg-molclintox: 0.873068 test loss: 0.347698
[Epoch 57; Iter    10/   40] train: loss: 0.0268159
[Epoch 57; Iter    40/   40] train: loss: 0.0070699
[Epoch 57] ogbg-molclintox: 0.993457 val loss: 0.051534
[Epoch 57] ogbg-molclintox: 0.841403 test loss: 0.464430
[Epoch 58; Iter    30/   40] train: loss: 0.0049712
[Epoch 58] ogbg-molclintox: 0.982581 val loss: 0.076610
[Epoch 58] ogbg-molclintox: 0.834206 test loss: 0.312469
[Epoch 59; Iter    20/   40] train: loss: 0.0030438
[Epoch 59] ogbg-molclintox: 0.993931 val loss: 0.068959
[Epoch 59] ogbg-molclintox: 0.834882 test loss: 0.465482
[Epoch 60; Iter    10/   40] train: loss: 0.0417642
[Epoch 60; Iter    40/   40] train: loss: 0.0148929
[Epoch 60] ogbg-molclintox: 0.969607 val loss: 0.097626
[Epoch 60] ogbg-molclintox: 0.834355 test loss: 0.332455
[Epoch 61; Iter    30/   40] train: loss: 0.0491631
[Epoch 61] ogbg-molclintox: 0.992533 val loss: 0.121000
[Epoch 61] ogbg-molclintox: 0.834131 test loss: 0.487511
[Epoch 62; Iter    20/   40] train: loss: 0.0100326
[Epoch 62] ogbg-molclintox: 0.981070 val loss: 0.084955
[Epoch 62] ogbg-molclintox: 0.843062 test loss: 0.480060
[Epoch 63; Iter    10/   40] train: loss: 0.0313848
[Epoch 63; Iter    40/   40] train: loss: 0.0028720
[Epoch 63] ogbg-molclintox: 0.985627 val loss: 0.131668
[Epoch 63] ogbg-molclintox: 0.860502 test loss: 0.373955
[Epoch 64; Iter    30/   40] train: loss: 0.0049099
[Epoch 64] ogbg-molclintox: 0.975113 val loss: 0.155027
[Epoch 64] ogbg-molclintox: 0.843488 test loss: 0.476891
[Epoch 65; Iter    20/   40] train: loss: 0.0089746
[Epoch 65] ogbg-molclintox: 0.976037 val loss: 0.095990
[Epoch 65] ogbg-molclintox: 0.789498 test loss: 0.309664
[Epoch 66; Iter    10/   40] train: loss: 0.0326940
[Epoch 66; Iter    40/   40] train: loss: 0.0723044
[Epoch 66] ogbg-molclintox: 0.954535 val loss: 0.106943
[Epoch 66] ogbg-molclintox: 0.859516 test loss: 0.615047
[Epoch 67; Iter    30/   40] train: loss: 0.0710828
[Epoch 67] ogbg-molclintox: 0.947854 val loss: 0.119621
[Epoch 67] ogbg-molclintox: 0.772783 test loss: 0.421601
[Epoch 68; Iter    20/   40] train: loss: 0.0109433
[Epoch 68] ogbg-molclintox: 0.989261 val loss: 0.078508
[Epoch 68] ogbg-molclintox: 0.823564 test loss: 0.316756
[Epoch 69; Iter    10/   40] train: loss: 0.0923716
[Epoch 69; Iter    40/   40] train: loss: 0.0175791
[Epoch 69] ogbg-molclintox: 0.966560 val loss: 0.079123
[Epoch 69] ogbg-molclintox: 0.750371 test loss: 0.428141
[Epoch 70; Iter    30/   40] train: loss: 0.0050636
[Epoch 70] ogbg-molclintox: 0.969582 val loss: 0.079404
[Epoch 70] ogbg-molclintox: 0.793480 test loss: 0.409033
[Epoch 71; Iter    20/   40] train: loss: 0.0302737
[Epoch 71] ogbg-molclintox: 0.986664 val loss: 0.057777
[Epoch 71] ogbg-molclintox: 0.769223 test loss: 0.332603
[Epoch 72; Iter    10/   40] train: loss: 0.0033816
[Epoch 72; Iter    40/   40] train: loss: 0.0052920
[Epoch 72] ogbg-molclintox: 0.924004 val loss: 0.077623
[Epoch 72] ogbg-molclintox: 0.826922 test loss: 0.361761
[Epoch 73; Iter    30/   40] train: loss: 0.0222922
[Epoch 73] ogbg-molclintox: 0.980708 val loss: 0.051231
[Epoch 73] ogbg-molclintox: 0.820650 test loss: 0.333321
[Epoch 74; Iter    20/   40] train: loss: 0.0050196
[Epoch 74] ogbg-molclintox: 0.998601 val loss: 0.029731
[Epoch 74] ogbg-molclintox: 0.820464 test loss: 0.343499
[Epoch 75; Iter    10/   40] train: loss: 0.0212218
[Epoch 75; Iter    40/   40] train: loss: 0.0171867
[Epoch 75] ogbg-molclintox: 0.987838 val loss: 0.048341
[Epoch 75] ogbg-molclintox: 0.817378 test loss: 0.348681
[Epoch 76; Iter    30/   40] train: loss: 0.0029151
[Epoch 31] ogbg-molclintox: 0.409675 test loss: 1.433565
[Epoch 32; Iter    20/   40] train: loss: 0.1950475
[Epoch 32] ogbg-molclintox: 0.705010 val loss: 1.786065
[Epoch 32] ogbg-molclintox: 0.513195 test loss: 0.797598
[Epoch 33; Iter    10/   40] train: loss: 0.0881670
[Epoch 33; Iter    40/   40] train: loss: 0.2321226
[Epoch 33] ogbg-molclintox: 0.689689 val loss: 1.670024
[Epoch 33] ogbg-molclintox: 0.475995 test loss: 1.036098
[Epoch 34; Iter    30/   40] train: loss: 0.0954670
[Epoch 34] ogbg-molclintox: 0.676939 val loss: 2.309114
[Epoch 34] ogbg-molclintox: 0.449586 test loss: 1.426508
[Epoch 35; Iter    20/   40] train: loss: 0.3492742
[Epoch 35] ogbg-molclintox: 0.674817 val loss: 0.325210
[Epoch 35] ogbg-molclintox: 0.621174 test loss: 0.331117
[Epoch 36; Iter    10/   40] train: loss: 0.1308905
[Epoch 36; Iter    40/   40] train: loss: 0.2885000
[Epoch 36] ogbg-molclintox: 0.532103 val loss: 5.499104
[Epoch 36] ogbg-molclintox: 0.527931 test loss: 1.403724
[Epoch 37; Iter    30/   40] train: loss: 0.1814553
[Epoch 37] ogbg-molclintox: 0.706296 val loss: 1.313538
[Epoch 37] ogbg-molclintox: 0.655438 test loss: 0.366863
[Epoch 38; Iter    20/   40] train: loss: 0.0639218
[Epoch 38] ogbg-molclintox: 0.696580 val loss: 0.151381
[Epoch 38] ogbg-molclintox: 0.578469 test loss: 0.266305
[Epoch 39; Iter    10/   40] train: loss: 0.1966911
[Epoch 39; Iter    40/   40] train: loss: 0.1968286
[Epoch 39] ogbg-molclintox: 0.710193 val loss: 0.195488
[Epoch 39] ogbg-molclintox: 0.613017 test loss: 0.339675
[Epoch 40; Iter    30/   40] train: loss: 0.1157847
[Epoch 40] ogbg-molclintox: 0.535764 val loss: 0.182959
[Epoch 40] ogbg-molclintox: 0.528532 test loss: 0.356853
[Epoch 41; Iter    20/   40] train: loss: 0.0651441
[Epoch 41] ogbg-molclintox: 0.565606 val loss: 0.322199
[Epoch 41] ogbg-molclintox: 0.651763 test loss: 0.323080
[Epoch 42; Iter    10/   40] train: loss: 0.1298721
[Epoch 42; Iter    40/   40] train: loss: 0.0695634
[Epoch 42] ogbg-molclintox: 0.684597 val loss: 0.158772
[Epoch 42] ogbg-molclintox: 0.548579 test loss: 0.549594
[Epoch 43; Iter    30/   40] train: loss: 0.1093927
[Epoch 43] ogbg-molclintox: 0.693747 val loss: 1.593026
[Epoch 43] ogbg-molclintox: 0.564570 test loss: 3.569714
[Epoch 44; Iter    20/   40] train: loss: 0.0601470
[Epoch 44] ogbg-molclintox: 0.667248 val loss: 0.688103
[Epoch 44] ogbg-molclintox: 0.613159 test loss: 1.080950
[Epoch 45; Iter    10/   40] train: loss: 0.1282483
[Epoch 45; Iter    40/   40] train: loss: 0.0719966
[Epoch 45] ogbg-molclintox: 0.669124 val loss: 0.310057
[Epoch 45] ogbg-molclintox: 0.646257 test loss: 0.511905
[Epoch 46; Iter    30/   40] train: loss: 0.0407111
[Epoch 46] ogbg-molclintox: 0.692711 val loss: 1.462727
[Epoch 46] ogbg-molclintox: 0.569855 test loss: 3.798732
[Epoch 47; Iter    20/   40] train: loss: 0.0378766
[Epoch 47] ogbg-molclintox: 0.739736 val loss: 0.583452
[Epoch 47] ogbg-molclintox: 0.568089 test loss: 2.556995
[Epoch 48; Iter    10/   40] train: loss: 0.0290805
[Epoch 48; Iter    40/   40] train: loss: 0.0430313
[Epoch 48] ogbg-molclintox: 0.695557 val loss: 0.281116
[Epoch 48] ogbg-molclintox: 0.630778 test loss: 0.497631
[Epoch 49; Iter    30/   40] train: loss: 0.0255898
[Epoch 49] ogbg-molclintox: 0.580766 val loss: 0.203982
[Epoch 49] ogbg-molclintox: 0.574248 test loss: 0.331864
[Epoch 50; Iter    20/   40] train: loss: 0.1044588
[Epoch 50] ogbg-molclintox: 0.759180 val loss: 0.164322
[Epoch 50] ogbg-molclintox: 0.602129 test loss: 0.510186
[Epoch 51; Iter    10/   40] train: loss: 0.0506053
[Epoch 51; Iter    40/   40] train: loss: 0.0048177
[Epoch 51] ogbg-molclintox: 0.633512 val loss: 0.262311
[Epoch 51] ogbg-molclintox: 0.593089 test loss: 0.983699
[Epoch 52; Iter    30/   40] train: loss: 0.0095819
[Epoch 52] ogbg-molclintox: 0.704237 val loss: 0.238420
[Epoch 52] ogbg-molclintox: 0.613876 test loss: 1.942727
[Epoch 53; Iter    20/   40] train: loss: 0.0667930
[Epoch 53] ogbg-molclintox: 0.655574 val loss: 0.926730
[Epoch 53] ogbg-molclintox: 0.661531 test loss: 5.350429
[Epoch 54; Iter    10/   40] train: loss: 0.0117195
[Epoch 54; Iter    40/   40] train: loss: 0.0039743
[Epoch 54] ogbg-molclintox: 0.648820 val loss: 2.485229
[Epoch 54] ogbg-molclintox: 0.567816 test loss: 4.801103
[Epoch 55; Iter    30/   40] train: loss: 0.0343920
[Epoch 55] ogbg-molclintox: 0.641553 val loss: 0.235483
[Epoch 55] ogbg-molclintox: 0.572153 test loss: 2.978228
[Epoch 56; Iter    20/   40] train: loss: 0.0103877
[Epoch 56] ogbg-molclintox: 0.609385 val loss: 0.217619
[Epoch 56] ogbg-molclintox: 0.613196 test loss: 1.505413
[Epoch 57; Iter    10/   40] train: loss: 0.0082129
[Epoch 57; Iter    40/   40] train: loss: 0.0017014
[Epoch 57] ogbg-molclintox: 0.590556 val loss: 0.294434
[Epoch 57] ogbg-molclintox: 0.604743 test loss: 2.247029
[Epoch 58; Iter    30/   40] train: loss: 0.0050449
[Epoch 58] ogbg-molclintox: 0.594664 val loss: 0.235094
[Epoch 58] ogbg-molclintox: 0.612374 test loss: 2.592785
[Epoch 59; Iter    20/   40] train: loss: 0.0041209
[Epoch 59] ogbg-molclintox: 0.654864 val loss: 0.231971
[Epoch 59] ogbg-molclintox: 0.648465 test loss: 2.039097
[Epoch 60; Iter    10/   40] train: loss: 0.0355543
[Epoch 60; Iter    40/   40] train: loss: 0.0183957
[Epoch 60] ogbg-molclintox: 0.593902 val loss: 0.263262
[Epoch 60] ogbg-molclintox: 0.609577 test loss: 3.105716
[Epoch 61; Iter    30/   40] train: loss: 0.0150339
[Epoch 61] ogbg-molclintox: 0.716599 val loss: 0.204517
[Epoch 61] ogbg-molclintox: 0.641917 test loss: 4.595958
[Epoch 62; Iter    20/   40] train: loss: 0.0126041
[Epoch 62] ogbg-molclintox: 0.623058 val loss: 0.235003
[Epoch 62] ogbg-molclintox: 0.639556 test loss: 2.773504
[Epoch 63; Iter    10/   40] train: loss: 0.0166040
[Epoch 63; Iter    40/   40] train: loss: 0.0018234
[Epoch 63] ogbg-molclintox: 0.645035 val loss: 0.221137
[Epoch 63] ogbg-molclintox: 0.642791 test loss: 2.764377
[Epoch 64; Iter    30/   40] train: loss: 0.0038356
[Epoch 64] ogbg-molclintox: 0.699043 val loss: 0.236474
[Epoch 64] ogbg-molclintox: 0.680719 test loss: 4.343174
[Epoch 65; Iter    20/   40] train: loss: 0.0043108
[Epoch 65] ogbg-molclintox: 0.657071 val loss: 0.260997
[Epoch 65] ogbg-molclintox: 0.689411 test loss: 3.023980
[Epoch 66; Iter    10/   40] train: loss: 0.0076503
[Epoch 66; Iter    40/   40] train: loss: 0.0045343
[Epoch 66] ogbg-molclintox: 0.764862 val loss: 0.194691
[Epoch 66] ogbg-molclintox: 0.706287 test loss: 3.744808
[Epoch 67; Iter    30/   40] train: loss: 0.0175283
[Epoch 67] ogbg-molclintox: 0.697929 val loss: 0.208354
[Epoch 67] ogbg-molclintox: 0.728770 test loss: 2.633448
[Epoch 68; Iter    20/   40] train: loss: 0.0090823
[Epoch 68] ogbg-molclintox: 0.731060 val loss: 0.198308
[Epoch 68] ogbg-molclintox: 0.688582 test loss: 4.614731
[Epoch 69; Iter    10/   40] train: loss: 0.0015278
[Epoch 69; Iter    40/   40] train: loss: 0.0055231
[Epoch 69] ogbg-molclintox: 0.598386 val loss: 2.919555
[Epoch 69] ogbg-molclintox: 0.593086 test loss: 6.165620
[Epoch 70; Iter    30/   40] train: loss: 0.0014017
[Epoch 70] ogbg-molclintox: 0.614283 val loss: 1.129270
[Epoch 70] ogbg-molclintox: 0.621821 test loss: 4.167840
[Epoch 71; Iter    20/   40] train: loss: 0.0045374
[Epoch 71] ogbg-molclintox: 0.474901 val loss: 0.328583
[Epoch 71] ogbg-molclintox: 0.574036 test loss: 3.048883
[Epoch 72; Iter    10/   40] train: loss: 0.0040108
[Epoch 72; Iter    40/   40] train: loss: 0.0045959
[Epoch 72] ogbg-molclintox: 0.564232 val loss: 0.246332
[Epoch 72] ogbg-molclintox: 0.508881 test loss: 3.098070
[Epoch 73; Iter    30/   40] train: loss: 0.0551519
[Epoch 73] ogbg-molclintox: 0.688251 val loss: 0.203735
[Epoch 73] ogbg-molclintox: 0.632448 test loss: 1.038598
[Epoch 74; Iter    20/   40] train: loss: 0.0191265
[Epoch 74] ogbg-molclintox: 0.635484 val loss: 0.371315
[Epoch 74] ogbg-molclintox: 0.697158 test loss: 1.476137
[Epoch 75; Iter    10/   40] train: loss: 0.0509318
[Epoch 75; Iter    40/   40] train: loss: 0.1140434
[Epoch 75] ogbg-molclintox: 0.814769 val loss: 0.451967
[Epoch 75] ogbg-molclintox: 0.644117 test loss: 1.101190
[Epoch 76; Iter    30/   40] train: loss: 0.0077361
[Epoch 31] ogbg-molclintox: 0.557690 test loss: 1.683536
[Epoch 32; Iter    20/   40] train: loss: 0.1600629
[Epoch 32] ogbg-molclintox: 0.780833 val loss: 0.863451
[Epoch 32] ogbg-molclintox: 0.595136 test loss: 1.468129
[Epoch 33; Iter    10/   40] train: loss: 0.2264462
[Epoch 33; Iter    40/   40] train: loss: 0.7300966
[Epoch 33] ogbg-molclintox: 0.768896 val loss: 1.094198
[Epoch 33] ogbg-molclintox: 0.601123 test loss: 1.623047
[Epoch 34; Iter    30/   40] train: loss: 0.2451508
[Epoch 34] ogbg-molclintox: 0.776388 val loss: 0.797271
[Epoch 34] ogbg-molclintox: 0.595539 test loss: 1.316837
[Epoch 35; Iter    20/   40] train: loss: 0.1821381
[Epoch 35] ogbg-molclintox: 0.715000 val loss: 0.257645
[Epoch 35] ogbg-molclintox: 0.668941 test loss: 1.334673
[Epoch 36; Iter    10/   40] train: loss: 0.1918910
[Epoch 36; Iter    40/   40] train: loss: 0.3833986
[Epoch 36] ogbg-molclintox: 0.720458 val loss: 0.267325
[Epoch 36] ogbg-molclintox: 0.690666 test loss: 0.352511
[Epoch 37; Iter    30/   40] train: loss: 0.3340861
[Epoch 37] ogbg-molclintox: 0.842456 val loss: 0.211971
[Epoch 37] ogbg-molclintox: 0.700269 test loss: 1.148132
[Epoch 38; Iter    20/   40] train: loss: 0.1671858
[Epoch 38] ogbg-molclintox: 0.920884 val loss: 0.547259
[Epoch 38] ogbg-molclintox: 0.750849 test loss: 0.650539
[Epoch 39; Iter    10/   40] train: loss: 0.0822298
[Epoch 39; Iter    40/   40] train: loss: 0.0921946
[Epoch 39] ogbg-molclintox: 0.726787 val loss: 0.702689
[Epoch 39] ogbg-molclintox: 0.764468 test loss: 0.425866
[Epoch 40; Iter    30/   40] train: loss: 0.3089621
[Epoch 40] ogbg-molclintox: 0.937428 val loss: 0.116680
[Epoch 40] ogbg-molclintox: 0.839177 test loss: 0.471214
[Epoch 41; Iter    20/   40] train: loss: 0.1549102
[Epoch 41] ogbg-molclintox: 0.810686 val loss: 0.387183
[Epoch 41] ogbg-molclintox: 0.725568 test loss: 2.017010
[Epoch 42; Iter    10/   40] train: loss: 0.0943061
[Epoch 42; Iter    40/   40] train: loss: 0.1473027
[Epoch 42] ogbg-molclintox: 0.880676 val loss: 0.128620
[Epoch 42] ogbg-molclintox: 0.713548 test loss: 0.421556
[Epoch 43; Iter    30/   40] train: loss: 0.3654378
[Epoch 43] ogbg-molclintox: 0.891963 val loss: 0.127356
[Epoch 43] ogbg-molclintox: 0.812847 test loss: 1.013087
[Epoch 44; Iter    20/   40] train: loss: 0.0754564
[Epoch 44] ogbg-molclintox: 0.803608 val loss: 0.170124
[Epoch 44] ogbg-molclintox: 0.584341 test loss: 1.861036
[Epoch 45; Iter    10/   40] train: loss: 0.1335915
[Epoch 45; Iter    40/   40] train: loss: 0.2887518
[Epoch 45] ogbg-molclintox: 0.955297 val loss: 0.110514
[Epoch 45] ogbg-molclintox: 0.825637 test loss: 0.210513
[Epoch 46; Iter    30/   40] train: loss: 0.1027252
[Epoch 46] ogbg-molclintox: 0.969695 val loss: 0.077077
[Epoch 46] ogbg-molclintox: 0.871357 test loss: 0.466260
[Epoch 47; Iter    20/   40] train: loss: 0.2259005
[Epoch 47] ogbg-molclintox: 0.912042 val loss: 0.278967
[Epoch 47] ogbg-molclintox: 0.735807 test loss: 0.503101
[Epoch 48; Iter    10/   40] train: loss: 0.0484624
[Epoch 48; Iter    40/   40] train: loss: 0.1664721
[Epoch 48] ogbg-molclintox: 0.927589 val loss: 0.127232
[Epoch 48] ogbg-molclintox: 0.729009 test loss: 0.364599
[Epoch 49; Iter    30/   40] train: loss: 0.1051071
[Epoch 49] ogbg-molclintox: 0.937766 val loss: 0.096046
[Epoch 49] ogbg-molclintox: 0.804548 test loss: 0.433698
[Epoch 50; Iter    20/   40] train: loss: 0.0447516
[Epoch 50] ogbg-molclintox: 0.955072 val loss: 0.346623
[Epoch 50] ogbg-molclintox: 0.743801 test loss: 0.559627
[Epoch 51; Iter    10/   40] train: loss: 0.0505026
[Epoch 51; Iter    40/   40] train: loss: 0.0880771
[Epoch 51] ogbg-molclintox: 0.951713 val loss: 0.090158
[Epoch 51] ogbg-molclintox: 0.745299 test loss: 0.326550
[Epoch 52; Iter    30/   40] train: loss: 0.0855765
[Epoch 52] ogbg-molclintox: 0.963039 val loss: 0.134970
[Epoch 52] ogbg-molclintox: 0.752657 test loss: 0.237947
[Epoch 53; Iter    20/   40] train: loss: 0.0564640
[Epoch 53] ogbg-molclintox: 0.938802 val loss: 0.156592
[Epoch 53] ogbg-molclintox: 0.788494 test loss: 0.343484
[Epoch 54; Iter    10/   40] train: loss: 0.0732268
[Epoch 54; Iter    40/   40] train: loss: 0.0080662
[Epoch 54] ogbg-molclintox: 0.943609 val loss: 0.110326
[Epoch 54] ogbg-molclintox: 0.802460 test loss: 0.233974
[Epoch 55; Iter    30/   40] train: loss: 0.0126204
[Epoch 55] ogbg-molclintox: 0.968971 val loss: 0.117557
[Epoch 55] ogbg-molclintox: 0.769948 test loss: 4.706280
[Epoch 56; Iter    20/   40] train: loss: 0.0560603
[Epoch 56] ogbg-molclintox: 0.845036 val loss: 0.184038
[Epoch 56] ogbg-molclintox: 0.793756 test loss: 1.611591
[Epoch 57; Iter    10/   40] train: loss: 0.0562633
[Epoch 57; Iter    40/   40] train: loss: 0.0214234
[Epoch 57] ogbg-molclintox: 0.960892 val loss: 0.092013
[Epoch 57] ogbg-molclintox: 0.786798 test loss: 0.796793
[Epoch 58; Iter    30/   40] train: loss: 0.0168272
[Epoch 58] ogbg-molclintox: 0.960192 val loss: 0.101885
[Epoch 58] ogbg-molclintox: 0.751858 test loss: 0.871477
[Epoch 59; Iter    20/   40] train: loss: 0.0293764
[Epoch 59] ogbg-molclintox: 0.930361 val loss: 0.268785
[Epoch 59] ogbg-molclintox: 0.755343 test loss: 1.560241
[Epoch 60; Iter    10/   40] train: loss: 0.0088216
[Epoch 60; Iter    40/   40] train: loss: 0.0295506
[Epoch 60] ogbg-molclintox: 0.895698 val loss: 0.312610
[Epoch 60] ogbg-molclintox: 0.700688 test loss: 1.157948
[Epoch 61; Iter    30/   40] train: loss: 0.0077058
[Epoch 61] ogbg-molclintox: 0.947781 val loss: 0.143606
[Epoch 61] ogbg-molclintox: 0.761738 test loss: 0.841352
[Epoch 62; Iter    20/   40] train: loss: 0.0032948
[Epoch 62] ogbg-molclintox: 0.897234 val loss: 0.363831
[Epoch 62] ogbg-molclintox: 0.781688 test loss: 1.017944
[Epoch 63; Iter    10/   40] train: loss: 0.0926450
[Epoch 63; Iter    40/   40] train: loss: 0.0034603
[Epoch 63] ogbg-molclintox: 0.906824 val loss: 0.480736
[Epoch 63] ogbg-molclintox: 0.740850 test loss: 0.978929
[Epoch 64; Iter    30/   40] train: loss: 0.0046617
[Epoch 64] ogbg-molclintox: 0.925691 val loss: 0.269400
[Epoch 64] ogbg-molclintox: 0.751084 test loss: 1.300301
[Epoch 65; Iter    20/   40] train: loss: 0.0068516
[Epoch 65] ogbg-molclintox: 0.926078 val loss: 0.132357
[Epoch 65] ogbg-molclintox: 0.790648 test loss: 0.763856
[Epoch 66; Iter    10/   40] train: loss: 0.0242781
[Epoch 66; Iter    40/   40] train: loss: 0.4694375
[Epoch 66] ogbg-molclintox: 0.944646 val loss: 0.407163
[Epoch 66] ogbg-molclintox: 0.734746 test loss: 0.525619
[Epoch 67; Iter    30/   40] train: loss: 0.0122826
[Epoch 67] ogbg-molclintox: 0.911582 val loss: 0.150515
[Epoch 67] ogbg-molclintox: 0.771068 test loss: 0.586460
[Epoch 68; Iter    20/   40] train: loss: 0.0059199
[Epoch 68] ogbg-molclintox: 0.942386 val loss: 0.173441
[Epoch 68] ogbg-molclintox: 0.774766 test loss: 0.657757
[Epoch 69; Iter    10/   40] train: loss: 0.0328766
[Epoch 69; Iter    40/   40] train: loss: 0.0125482
[Epoch 69] ogbg-molclintox: 0.932059 val loss: 0.136630
[Epoch 69] ogbg-molclintox: 0.858302 test loss: 0.219607
[Epoch 70; Iter    30/   40] train: loss: 0.0530168
[Epoch 70] ogbg-molclintox: 0.837248 val loss: 0.517587
[Epoch 70] ogbg-molclintox: 0.744709 test loss: 0.340199
[Epoch 71; Iter    20/   40] train: loss: 0.0208940
[Epoch 71] ogbg-molclintox: 0.881189 val loss: 0.268713
[Epoch 71] ogbg-molclintox: 0.753143 test loss: 0.741613
[Epoch 72; Iter    10/   40] train: loss: 0.0055297
[Epoch 72; Iter    40/   40] train: loss: 0.0168344
[Epoch 72] ogbg-molclintox: 0.913655 val loss: 0.254534
[Epoch 72] ogbg-molclintox: 0.774105 test loss: 2.220335
[Epoch 73; Iter    30/   40] train: loss: 0.0038911
[Epoch 73] ogbg-molclintox: 0.911694 val loss: 0.286110
[Epoch 73] ogbg-molclintox: 0.775427 test loss: 2.585500
[Epoch 74; Iter    20/   40] train: loss: 0.0082192
[Epoch 74] ogbg-molclintox: 0.921309 val loss: 0.419589
[Epoch 74] ogbg-molclintox: 0.771031 test loss: 2.619204
[Epoch 75; Iter    10/   40] train: loss: 0.0741078
[Epoch 75; Iter    40/   40] train: loss: 0.0092668
[Epoch 75] ogbg-molclintox: 0.924131 val loss: 0.588656
[Epoch 75] ogbg-molclintox: 0.781875 test loss: 3.155461
[Epoch 76; Iter    30/   40] train: loss: 0.0027091
[Epoch 31] ogbg-molclintox: 0.619587 test loss: 0.239541
[Epoch 32; Iter    20/   40] train: loss: 0.2963824
[Epoch 32] ogbg-molclintox: 0.680847 val loss: 0.249637
[Epoch 32] ogbg-molclintox: 0.643784 test loss: 0.253069
[Epoch 33; Iter    10/   40] train: loss: 0.2740047
[Epoch 33; Iter    40/   40] train: loss: 0.3184774
[Epoch 33] ogbg-molclintox: 0.681884 val loss: 0.177129
[Epoch 33] ogbg-molclintox: 0.610843 test loss: 0.240101
[Epoch 34; Iter    30/   40] train: loss: 0.1141395
[Epoch 34] ogbg-molclintox: 0.700614 val loss: 0.179014
[Epoch 34] ogbg-molclintox: 0.618862 test loss: 0.242442
[Epoch 35; Iter    20/   40] train: loss: 0.1956281
[Epoch 35] ogbg-molclintox: 0.620661 val loss: 0.175910
[Epoch 35] ogbg-molclintox: 0.697595 test loss: 0.268724
[Epoch 36; Iter    10/   40] train: loss: 0.2815682
[Epoch 36; Iter    40/   40] train: loss: 0.1672192
[Epoch 36] ogbg-molclintox: 0.694995 val loss: 0.192071
[Epoch 36] ogbg-molclintox: 0.727791 test loss: 0.504691
[Epoch 37; Iter    30/   40] train: loss: 0.0972876
[Epoch 37] ogbg-molclintox: 0.724478 val loss: 0.154902
[Epoch 37] ogbg-molclintox: 0.734824 test loss: 0.608020
[Epoch 38; Iter    20/   40] train: loss: 0.1185353
[Epoch 38] ogbg-molclintox: 0.759464 val loss: 0.152412
[Epoch 38] ogbg-molclintox: 0.715188 test loss: 0.271539
[Epoch 39; Iter    10/   40] train: loss: 0.0951706
[Epoch 39; Iter    40/   40] train: loss: 0.1678757
[Epoch 39] ogbg-molclintox: 0.712551 val loss: 0.178188
[Epoch 39] ogbg-molclintox: 0.761767 test loss: 0.926621
[Epoch 40; Iter    30/   40] train: loss: 0.1080822
[Epoch 40] ogbg-molclintox: 0.812260 val loss: 0.291605
[Epoch 40] ogbg-molclintox: 0.628970 test loss: 0.376160
[Epoch 41; Iter    20/   40] train: loss: 0.0920637
[Epoch 41] ogbg-molclintox: 0.848571 val loss: 0.171568
[Epoch 41] ogbg-molclintox: 0.793293 test loss: 0.475296
[Epoch 42; Iter    10/   40] train: loss: 0.0790233
[Epoch 42; Iter    40/   40] train: loss: 0.0459508
[Epoch 42] ogbg-molclintox: 0.835998 val loss: 0.135618
[Epoch 42] ogbg-molclintox: 0.838826 test loss: 0.476350
[Epoch 43; Iter    30/   40] train: loss: 0.1702495
[Epoch 43] ogbg-molclintox: 0.915339 val loss: 0.162015
[Epoch 43] ogbg-molclintox: 0.743143 test loss: 1.251094
[Epoch 44; Iter    20/   40] train: loss: 0.0405539
[Epoch 44] ogbg-molclintox: 0.817243 val loss: 0.152147
[Epoch 44] ogbg-molclintox: 0.832248 test loss: 0.206429
[Epoch 45; Iter    10/   40] train: loss: 0.1600498
[Epoch 45; Iter    40/   40] train: loss: 0.2591555
[Epoch 45] ogbg-molclintox: 0.894398 val loss: 0.146335
[Epoch 45] ogbg-molclintox: 0.760994 test loss: 0.513950
[Epoch 46; Iter    30/   40] train: loss: 0.0848003
[Epoch 46] ogbg-molclintox: 0.848697 val loss: 1.027767
[Epoch 46] ogbg-molclintox: 0.778919 test loss: 0.917565
[Epoch 47; Iter    20/   40] train: loss: 0.0502741
[Epoch 47] ogbg-molclintox: 0.913054 val loss: 0.392904
[Epoch 47] ogbg-molclintox: 0.768864 test loss: 0.389520
[Epoch 48; Iter    10/   40] train: loss: 0.0551908
[Epoch 48; Iter    40/   40] train: loss: 0.0610600
[Epoch 48] ogbg-molclintox: 0.865667 val loss: 2.196523
[Epoch 48] ogbg-molclintox: 0.758233 test loss: 1.478152
[Epoch 49; Iter    30/   40] train: loss: 0.0363486
[Epoch 49] ogbg-molclintox: 0.920859 val loss: 0.906790
[Epoch 49] ogbg-molclintox: 0.713425 test loss: 1.127235
[Epoch 50; Iter    20/   40] train: loss: 0.0976048
[Epoch 50] ogbg-molclintox: 0.864093 val loss: 1.217671
[Epoch 50] ogbg-molclintox: 0.783891 test loss: 0.992703
[Epoch 51; Iter    10/   40] train: loss: 0.0074576
[Epoch 51; Iter    40/   40] train: loss: 0.2952872
[Epoch 51] ogbg-molclintox: 0.870049 val loss: 0.180219
[Epoch 51] ogbg-molclintox: 0.793248 test loss: 0.579782
[Epoch 52; Iter    30/   40] train: loss: 0.0101949
[Epoch 52] ogbg-molclintox: 0.691337 val loss: 1.182723
[Epoch 52] ogbg-molclintox: 0.742919 test loss: 1.167439
[Epoch 53; Iter    20/   40] train: loss: 0.0548524
[Epoch 53] ogbg-molclintox: 0.877903 val loss: 0.114953
[Epoch 53] ogbg-molclintox: 0.802926 test loss: 0.975576
[Epoch 54; Iter    10/   40] train: loss: 0.1026021
[Epoch 54; Iter    40/   40] train: loss: 0.0262934
[Epoch 54] ogbg-molclintox: 0.884084 val loss: 0.384972
[Epoch 54] ogbg-molclintox: 0.781389 test loss: 0.716319
[Epoch 55; Iter    30/   40] train: loss: 0.0079771
[Epoch 55] ogbg-molclintox: 0.793716 val loss: 0.203476
[Epoch 55] ogbg-molclintox: 0.811955 test loss: 0.499760
[Epoch 56; Iter    20/   40] train: loss: 0.0083422
[Epoch 56] ogbg-molclintox: 0.882598 val loss: 0.930430
[Epoch 56] ogbg-molclintox: 0.772435 test loss: 1.381531
[Epoch 57; Iter    10/   40] train: loss: 0.0606952
[Epoch 57; Iter    40/   40] train: loss: 0.0201336
[Epoch 57] ogbg-molclintox: 0.658122 val loss: 6.294446
[Epoch 57] ogbg-molclintox: 0.686748 test loss: 2.014125
[Epoch 58; Iter    30/   40] train: loss: 0.0357224
[Epoch 58] ogbg-molclintox: 0.976712 val loss: 0.129696
[Epoch 58] ogbg-molclintox: 0.801141 test loss: 1.028835
[Epoch 59; Iter    20/   40] train: loss: 0.0076975
[Epoch 59] ogbg-molclintox: 0.859436 val loss: 2.524788
[Epoch 59] ogbg-molclintox: 0.727261 test loss: 2.707808
[Epoch 60; Iter    10/   40] train: loss: 0.0081973
[Epoch 60; Iter    40/   40] train: loss: 0.0063003
[Epoch 60] ogbg-molclintox: 0.786249 val loss: 0.630036
[Epoch 60] ogbg-molclintox: 0.770411 test loss: 2.539598
[Epoch 61; Iter    30/   40] train: loss: 0.0183120
[Epoch 61] ogbg-molclintox: 0.731208 val loss: 2.370500
[Epoch 61] ogbg-molclintox: 0.728658 test loss: 2.692891
[Epoch 62; Iter    20/   40] train: loss: 0.0428723
[Epoch 62] ogbg-molclintox: 0.860645 val loss: 0.169405
[Epoch 62] ogbg-molclintox: 0.829510 test loss: 0.960742
[Epoch 63; Iter    10/   40] train: loss: 0.1185856
[Epoch 63; Iter    40/   40] train: loss: 0.0303030
[Epoch 63] ogbg-molclintox: 0.910394 val loss: 1.383727
[Epoch 63] ogbg-molclintox: 0.643564 test loss: 4.416026
[Epoch 64; Iter    30/   40] train: loss: 0.0044180
[Epoch 64] ogbg-molclintox: 0.875218 val loss: 0.151460
[Epoch 64] ogbg-molclintox: 0.794219 test loss: 0.678865
[Epoch 65; Iter    20/   40] train: loss: 0.0062998
[Epoch 65] ogbg-molclintox: 0.868714 val loss: 0.992367
[Epoch 65] ogbg-molclintox: 0.711061 test loss: 1.051724
[Epoch 66; Iter    10/   40] train: loss: 0.0073211
[Epoch 66; Iter    40/   40] train: loss: 0.0018581
[Epoch 66] ogbg-molclintox: 0.963626 val loss: 0.078153
[Epoch 66] ogbg-molclintox: 0.729700 test loss: 1.081216
[Epoch 67; Iter    30/   40] train: loss: 0.0037365
[Epoch 67] ogbg-molclintox: 0.968770 val loss: 0.079296
[Epoch 67] ogbg-molclintox: 0.769283 test loss: 1.669996
[Epoch 68; Iter    20/   40] train: loss: 0.0163114
[Epoch 68] ogbg-molclintox: 0.824819 val loss: 0.176360
[Epoch 68] ogbg-molclintox: 0.752295 test loss: 3.625734
[Epoch 69; Iter    10/   40] train: loss: 0.0016427
[Epoch 69; Iter    40/   40] train: loss: 0.0105295
[Epoch 69] ogbg-molclintox: 0.854752 val loss: 0.157981
[Epoch 69] ogbg-molclintox: 0.796890 test loss: 0.648434
[Epoch 70; Iter    30/   40] train: loss: 0.0250031
[Epoch 70] ogbg-molclintox: 0.915065 val loss: 0.133770
[Epoch 70] ogbg-molclintox: 0.749060 test loss: 0.819957
[Epoch 71; Iter    20/   40] train: loss: 0.0134467
[Epoch 71] ogbg-molclintox: 0.936891 val loss: 0.273570
[Epoch 71] ogbg-molclintox: 0.793562 test loss: 1.186345
[Epoch 72; Iter    10/   40] train: loss: 0.0033511
[Epoch 72; Iter    40/   40] train: loss: 0.0134641
[Epoch 72] ogbg-molclintox: 0.892624 val loss: 0.170877
[Epoch 72] ogbg-molclintox: 0.743154 test loss: 0.786395
[Epoch 73; Iter    30/   40] train: loss: 0.0251443
[Epoch 73] ogbg-molclintox: 0.893934 val loss: 0.125508
[Epoch 73] ogbg-molclintox: 0.767837 test loss: 0.421597
[Epoch 74; Iter    20/   40] train: loss: 0.0028917
[Epoch 74] ogbg-molclintox: 0.837983 val loss: 0.210001
[Epoch 74] ogbg-molclintox: 0.782565 test loss: 0.909350
[Epoch 75; Iter    10/   40] train: loss: 0.0034002
[Epoch 75; Iter    40/   40] train: loss: 0.0057785
[Epoch 75] ogbg-molclintox: 0.935555 val loss: 0.207259
[Epoch 75] ogbg-molclintox: 0.756082 test loss: 0.565543
[Epoch 76; Iter    30/   40] train: loss: 0.0027677
[Epoch 31] ogbg-molclintox: 0.610731 test loss: 0.478172
[Epoch 32; Iter    20/   40] train: loss: 0.3074819
[Epoch 32] ogbg-molclintox: 0.511314 val loss: 2.943079
[Epoch 32] ogbg-molclintox: 0.602946 test loss: 0.489450
[Epoch 33; Iter    10/   40] train: loss: 0.2623940
[Epoch 33; Iter    40/   40] train: loss: 0.3900079
[Epoch 33] ogbg-molclintox: 0.496779 val loss: 2.965919
[Epoch 33] ogbg-molclintox: 0.615389 test loss: 0.457912
[Epoch 34; Iter    30/   40] train: loss: 0.1184950
[Epoch 34] ogbg-molclintox: 0.459080 val loss: 3.035046
[Epoch 34] ogbg-molclintox: 0.621948 test loss: 0.558879
[Epoch 35; Iter    20/   40] train: loss: 0.1771202
[Epoch 35] ogbg-molclintox: 0.463227 val loss: 12.468890
[Epoch 35] ogbg-molclintox: 0.614313 test loss: 1.754580
[Epoch 36; Iter    10/   40] train: loss: 0.2813090
[Epoch 36; Iter    40/   40] train: loss: 0.2683750
[Epoch 36] ogbg-molclintox: 0.618353 val loss: 9.804946
[Epoch 36] ogbg-molclintox: 0.539465 test loss: 10.346825
[Epoch 37; Iter    30/   40] train: loss: 0.1088269
[Epoch 37] ogbg-molclintox: 0.838384 val loss: 0.548020
[Epoch 37] ogbg-molclintox: 0.659484 test loss: 5.116049
[Epoch 38; Iter    20/   40] train: loss: 0.2019374
[Epoch 38] ogbg-molclintox: 0.540533 val loss: 1.532156
[Epoch 38] ogbg-molclintox: 0.704318 test loss: 0.341698
[Epoch 39; Iter    10/   40] train: loss: 0.0834299
[Epoch 39; Iter    40/   40] train: loss: 0.2217141
[Epoch 39] ogbg-molclintox: 0.381426 val loss: 8.040427
[Epoch 39] ogbg-molclintox: 0.483488 test loss: 11.404448
[Epoch 40; Iter    30/   40] train: loss: 0.2491643
[Epoch 40] ogbg-molclintox: 0.712340 val loss: 3.978552
[Epoch 40] ogbg-molclintox: 0.689179 test loss: 0.501737
[Epoch 41; Iter    20/   40] train: loss: 0.0631759
[Epoch 41] ogbg-molclintox: 0.849010 val loss: 1.899987
[Epoch 41] ogbg-molclintox: 0.768789 test loss: 3.214082
[Epoch 42; Iter    10/   40] train: loss: 0.0633716
[Epoch 42; Iter    40/   40] train: loss: 0.1949158
[Epoch 42] ogbg-molclintox: 0.678749 val loss: 42.646239
[Epoch 42] ogbg-molclintox: 0.615587 test loss: 38.135429
[Epoch 43; Iter    30/   40] train: loss: 0.1550506
[Epoch 43] ogbg-molclintox: 0.667290 val loss: 12.403498
[Epoch 43] ogbg-molclintox: 0.634700 test loss: 10.259933
[Epoch 44; Iter    20/   40] train: loss: 0.0599086
[Epoch 44] ogbg-molclintox: 0.743907 val loss: 1.084837
[Epoch 44] ogbg-molclintox: 0.538815 test loss: 0.705014
[Epoch 45; Iter    10/   40] train: loss: 0.1377184
[Epoch 45; Iter    40/   40] train: loss: 0.0688606
[Epoch 45] ogbg-molclintox: 0.800509 val loss: 1.712406
[Epoch 45] ogbg-molclintox: 0.642159 test loss: 0.545080
[Epoch 46; Iter    30/   40] train: loss: 0.1765701
[Epoch 46] ogbg-molclintox: 0.485503 val loss: 4.391315
[Epoch 46] ogbg-molclintox: 0.583986 test loss: 0.922712
[Epoch 47; Iter    20/   40] train: loss: 0.1308232
[Epoch 47] ogbg-molclintox: 0.300332 val loss: 7.693885
[Epoch 47] ogbg-molclintox: 0.566012 test loss: 2.416551
[Epoch 48; Iter    10/   40] train: loss: 0.0424399
[Epoch 48; Iter    40/   40] train: loss: 0.0571027
[Epoch 48] ogbg-molclintox: 0.182659 val loss: 4.692340
[Epoch 48] ogbg-molclintox: 0.532431 test loss: 3.303463
[Epoch 49; Iter    30/   40] train: loss: 0.0087347
[Epoch 49] ogbg-molclintox: 0.691301 val loss: 1.035138
[Epoch 49] ogbg-molclintox: 0.637113 test loss: 1.212254
[Epoch 50; Iter    20/   40] train: loss: 0.1085695
[Epoch 50] ogbg-molclintox: 0.672003 val loss: 1.089342
[Epoch 50] ogbg-molclintox: 0.829312 test loss: 3.735264
[Epoch 51; Iter    10/   40] train: loss: 0.0205071
[Epoch 51; Iter    40/   40] train: loss: 0.1725701
[Epoch 51] ogbg-molclintox: 0.533702 val loss: 1.974754
[Epoch 51] ogbg-molclintox: 0.714639 test loss: 0.449175
[Epoch 52; Iter    30/   40] train: loss: 0.0206876
[Epoch 52] ogbg-molclintox: 0.597486 val loss: 2.011673
[Epoch 52] ogbg-molclintox: 0.737084 test loss: 1.210787
[Epoch 53; Iter    20/   40] train: loss: 0.0754851
[Epoch 53] ogbg-molclintox: 0.579617 val loss: 0.821536
[Epoch 53] ogbg-molclintox: 0.793424 test loss: 1.317738
[Epoch 54; Iter    10/   40] train: loss: 0.0572985
[Epoch 54; Iter    40/   40] train: loss: 0.0302776
[Epoch 54] ogbg-molclintox: 0.587095 val loss: 0.680594
[Epoch 54] ogbg-molclintox: 0.878730 test loss: 0.537032
[Epoch 55; Iter    30/   40] train: loss: 0.0081148
[Epoch 55] ogbg-molclintox: 0.632423 val loss: 0.474986
[Epoch 55] ogbg-molclintox: 0.772047 test loss: 0.575307
[Epoch 56; Iter    20/   40] train: loss: 0.0077420
[Epoch 56] ogbg-molclintox: 0.517818 val loss: 0.964322
[Epoch 56] ogbg-molclintox: 0.855306 test loss: 1.267884
[Epoch 57; Iter    10/   40] train: loss: 0.0300377
[Epoch 57; Iter    40/   40] train: loss: 0.0364874
[Epoch 57] ogbg-molclintox: 0.492158 val loss: 1.685305
[Epoch 57] ogbg-molclintox: 0.776092 test loss: 1.408106
[Epoch 58; Iter    30/   40] train: loss: 0.0221364
[Epoch 58] ogbg-molclintox: 0.666063 val loss: 0.378563
[Epoch 58] ogbg-molclintox: 0.806673 test loss: 0.433391
[Epoch 59; Iter    20/   40] train: loss: 0.0044476
[Epoch 59] ogbg-molclintox: 0.603741 val loss: 0.637832
[Epoch 59] ogbg-molclintox: 0.781004 test loss: 1.118334
[Epoch 60; Iter    10/   40] train: loss: 0.0093449
[Epoch 60; Iter    40/   40] train: loss: 0.0279541
[Epoch 60] ogbg-molclintox: 0.638404 val loss: 0.861054
[Epoch 60] ogbg-molclintox: 0.837168 test loss: 1.912253
[Epoch 61; Iter    30/   40] train: loss: 0.0133780
[Epoch 61] ogbg-molclintox: 0.481159 val loss: 1.203875
[Epoch 61] ogbg-molclintox: 0.519100 test loss: 1.735385
[Epoch 62; Iter    20/   40] train: loss: 0.0528668
[Epoch 62] ogbg-molclintox: 0.937491 val loss: 0.294294
[Epoch 62] ogbg-molclintox: 0.864125 test loss: 0.874346
[Epoch 63; Iter    10/   40] train: loss: 0.1150235
[Epoch 63; Iter    40/   40] train: loss: 0.1521246
[Epoch 63] ogbg-molclintox: 0.957532 val loss: 0.102942
[Epoch 63] ogbg-molclintox: 0.854245 test loss: 0.358891
[Epoch 64; Iter    30/   40] train: loss: 0.0145771
[Epoch 64] ogbg-molclintox: 0.892975 val loss: 2.440667
[Epoch 64] ogbg-molclintox: 0.794709 test loss: 2.493908
[Epoch 65; Iter    20/   40] train: loss: 0.0612430
[Epoch 65] ogbg-molclintox: 0.929051 val loss: 0.212701
[Epoch 65] ogbg-molclintox: 0.840828 test loss: 0.458940
[Epoch 66; Iter    10/   40] train: loss: 0.0258785
[Epoch 66; Iter    40/   40] train: loss: 0.0101832
[Epoch 66] ogbg-molclintox: 0.747703 val loss: 0.266222
[Epoch 66] ogbg-molclintox: 0.725774 test loss: 0.693657
[Epoch 67; Iter    30/   40] train: loss: 0.0235840
[Epoch 67] ogbg-molclintox: 0.922644 val loss: 0.492596
[Epoch 67] ogbg-molclintox: 0.794608 test loss: 1.015912
[Epoch 68; Iter    20/   40] train: loss: 0.0236167
[Epoch 68] ogbg-molclintox: 0.892750 val loss: 0.111841
[Epoch 68] ogbg-molclintox: 0.830310 test loss: 0.366839
[Epoch 69; Iter    10/   40] train: loss: 0.0025285
[Epoch 69; Iter    40/   40] train: loss: 0.0162499
[Epoch 69] ogbg-molclintox: 0.925153 val loss: 0.328596
[Epoch 69] ogbg-molclintox: 0.828136 test loss: 0.835951
[Epoch 70; Iter    30/   40] train: loss: 0.0561453
[Epoch 70] ogbg-molclintox: 0.870710 val loss: 0.144036
[Epoch 70] ogbg-molclintox: 0.810035 test loss: 0.574494
[Epoch 71; Iter    20/   40] train: loss: 0.0263614
[Epoch 71] ogbg-molclintox: 0.870372 val loss: 0.397300
[Epoch 71] ogbg-molclintox: 0.810360 test loss: 1.198519
[Epoch 72; Iter    10/   40] train: loss: 0.0101506
[Epoch 72; Iter    40/   40] train: loss: 0.0025690
[Epoch 72] ogbg-molclintox: 0.954710 val loss: 0.324903
[Epoch 72] ogbg-molclintox: 0.804350 test loss: 0.760340
[Epoch 73; Iter    30/   40] train: loss: 0.0901503
[Epoch 73] ogbg-molclintox: 0.932821 val loss: 0.326203
[Epoch 73] ogbg-molclintox: 0.782801 test loss: 1.050337
[Epoch 74; Iter    20/   40] train: loss: 0.0037907
[Epoch 74] ogbg-molclintox: 0.896471 val loss: 0.265507
[Epoch 74] ogbg-molclintox: 0.844026 test loss: 5.029696
[Epoch 75; Iter    10/   40] train: loss: 0.0078597
[Epoch 75; Iter    40/   40] train: loss: 0.0028492
[Epoch 75] ogbg-molclintox: 0.906873 val loss: 0.126453
[Epoch 75] ogbg-molclintox: 0.840003 test loss: 0.568399
[Epoch 76; Iter    30/   40] train: loss: 0.0132392
[Epoch 31] ogbg-molclintox: 0.668728 test loss: 0.300768
[Epoch 32; Iter    20/   40] train: loss: 0.1605505
[Epoch 32] ogbg-molclintox: 0.711465 val loss: 0.174936
[Epoch 32] ogbg-molclintox: 0.701543 test loss: 0.226441
[Epoch 33; Iter    10/   40] train: loss: 0.2351051
[Epoch 33; Iter    40/   40] train: loss: 0.8029189
[Epoch 33] ogbg-molclintox: 0.660269 val loss: 0.181106
[Epoch 33] ogbg-molclintox: 0.617675 test loss: 0.247583
[Epoch 34; Iter    30/   40] train: loss: 0.1974832
[Epoch 34] ogbg-molclintox: 0.663516 val loss: 0.200466
[Epoch 34] ogbg-molclintox: 0.540959 test loss: 0.308852
[Epoch 35; Iter    20/   40] train: loss: 0.2090967
[Epoch 35] ogbg-molclintox: 0.763186 val loss: 0.162597
[Epoch 35] ogbg-molclintox: 0.737406 test loss: 0.401416
[Epoch 36; Iter    10/   40] train: loss: 0.1811885
[Epoch 36; Iter    40/   40] train: loss: 0.4038281
[Epoch 36] ogbg-molclintox: 0.688265 val loss: 0.197143
[Epoch 36] ogbg-molclintox: 0.788587 test loss: 0.513080
[Epoch 37; Iter    30/   40] train: loss: 0.2404853
[Epoch 37] ogbg-molclintox: 0.801296 val loss: 0.145397
[Epoch 37] ogbg-molclintox: 0.734821 test loss: 2.308827
[Epoch 38; Iter    20/   40] train: loss: 0.1362762
[Epoch 38] ogbg-molclintox: 0.636770 val loss: 0.337412
[Epoch 38] ogbg-molclintox: 0.746576 test loss: 0.548103
[Epoch 39; Iter    10/   40] train: loss: 0.1362883
[Epoch 39; Iter    40/   40] train: loss: 0.0736461
[Epoch 39] ogbg-molclintox: 0.837470 val loss: 0.127394
[Epoch 39] ogbg-molclintox: 0.749650 test loss: 1.180473
[Epoch 40; Iter    30/   40] train: loss: 0.2810180
[Epoch 40] ogbg-molclintox: 0.837944 val loss: 0.107473
[Epoch 40] ogbg-molclintox: 0.799539 test loss: 0.439681
[Epoch 41; Iter    20/   40] train: loss: 0.0861602
[Epoch 41] ogbg-molclintox: 0.874069 val loss: 0.130131
[Epoch 41] ogbg-molclintox: 0.843715 test loss: 0.502637
[Epoch 42; Iter    10/   40] train: loss: 0.0653398
[Epoch 42; Iter    40/   40] train: loss: 0.1528659
[Epoch 42] ogbg-molclintox: 0.797937 val loss: 0.177029
[Epoch 42] ogbg-molclintox: 0.767213 test loss: 1.535021
[Epoch 43; Iter    30/   40] train: loss: 0.3202733
[Epoch 43] ogbg-molclintox: 0.841592 val loss: 1.278066
[Epoch 43] ogbg-molclintox: 0.781901 test loss: 0.836967
[Epoch 44; Iter    20/   40] train: loss: 0.0617146
[Epoch 44] ogbg-molclintox: 0.919886 val loss: 0.090120
[Epoch 44] ogbg-molclintox: 0.804421 test loss: 1.078472
[Epoch 45; Iter    10/   40] train: loss: 0.1191169
[Epoch 45; Iter    40/   40] train: loss: 0.1746559
[Epoch 45] ogbg-molclintox: 0.926914 val loss: 0.101424
[Epoch 45] ogbg-molclintox: 0.819014 test loss: 0.324445
[Epoch 46; Iter    30/   40] train: loss: 0.0866990
[Epoch 46] ogbg-molclintox: 0.981744 val loss: 0.080789
[Epoch 46] ogbg-molclintox: 0.776914 test loss: 0.228528
[Epoch 47; Iter    20/   40] train: loss: 0.0953922
[Epoch 47] ogbg-molclintox: 0.987251 val loss: 0.065883
[Epoch 47] ogbg-molclintox: 0.808634 test loss: 0.237767
[Epoch 48; Iter    10/   40] train: loss: 0.0259605
[Epoch 48; Iter    40/   40] train: loss: 0.0979283
[Epoch 48] ogbg-molclintox: 0.921295 val loss: 0.092641
[Epoch 48] ogbg-molclintox: 0.758088 test loss: 1.465826
[Epoch 49; Iter    30/   40] train: loss: 0.0733721
[Epoch 49] ogbg-molclintox: 0.983280 val loss: 0.061229
[Epoch 49] ogbg-molclintox: 0.778502 test loss: 0.667919
[Epoch 50; Iter    20/   40] train: loss: 0.0495013
[Epoch 50] ogbg-molclintox: 0.966560 val loss: 0.078549
[Epoch 50] ogbg-molclintox: 0.796214 test loss: 0.276825
[Epoch 51; Iter    10/   40] train: loss: 0.0705324
[Epoch 51; Iter    40/   40] train: loss: 0.0246617
[Epoch 51] ogbg-molclintox: 0.925129 val loss: 0.112178
[Epoch 51] ogbg-molclintox: 0.761674 test loss: 0.804390
[Epoch 52; Iter    30/   40] train: loss: 0.0528326
[Epoch 52] ogbg-molclintox: 0.946220 val loss: 0.097075
[Epoch 52] ogbg-molclintox: 0.727534 test loss: 0.603419
[Epoch 53; Iter    20/   40] train: loss: 0.0835248
[Epoch 53] ogbg-molclintox: 0.975176 val loss: 0.072356
[Epoch 53] ogbg-molclintox: 0.799950 test loss: 0.222766
[Epoch 54; Iter    10/   40] train: loss: 0.0498182
[Epoch 54; Iter    40/   40] train: loss: 0.0032027
[Epoch 54] ogbg-molclintox: 0.993320 val loss: 0.073799
[Epoch 54] ogbg-molclintox: 0.803812 test loss: 0.298880
[Epoch 55; Iter    30/   40] train: loss: 0.0321571
[Epoch 55] ogbg-molclintox: 0.930562 val loss: 0.091281
[Epoch 55] ogbg-molclintox: 0.753019 test loss: 0.279439
[Epoch 56; Iter    20/   40] train: loss: 0.0083381
[Epoch 56] ogbg-molclintox: 0.979397 val loss: 0.085340
[Epoch 56] ogbg-molclintox: 0.669536 test loss: 0.329087
[Epoch 57; Iter    10/   40] train: loss: 0.0517306
[Epoch 57; Iter    40/   40] train: loss: 0.0040116
[Epoch 57] ogbg-molclintox: 0.899705 val loss: 0.109321
[Epoch 57] ogbg-molclintox: 0.778502 test loss: 0.331347
[Epoch 58; Iter    30/   40] train: loss: 0.0165337
[Epoch 58] ogbg-molclintox: 0.975900 val loss: 0.080942
[Epoch 58] ogbg-molclintox: 0.788520 test loss: 0.284171
[Epoch 59; Iter    20/   40] train: loss: 0.0508646
[Epoch 59] ogbg-molclintox: 0.939540 val loss: 0.098383
[Epoch 59] ogbg-molclintox: 0.850492 test loss: 0.249948
[Epoch 60; Iter    10/   40] train: loss: 0.0054121
[Epoch 60; Iter    40/   40] train: loss: 0.0163601
[Epoch 60] ogbg-molclintox: 0.982331 val loss: 0.060576
[Epoch 60] ogbg-molclintox: 0.786947 test loss: 0.315160
[Epoch 61; Iter    30/   40] train: loss: 0.0098269
[Epoch 61] ogbg-molclintox: 0.971680 val loss: 0.079989
[Epoch 61] ogbg-molclintox: 0.800487 test loss: 0.368468
[Epoch 62; Iter    20/   40] train: loss: 0.0032879
[Epoch 62] ogbg-molclintox: 0.973441 val loss: 0.135052
[Epoch 62] ogbg-molclintox: 0.785109 test loss: 0.296424
[Epoch 63; Iter    10/   40] train: loss: 0.0374760
[Epoch 63; Iter    40/   40] train: loss: 0.0014907
[Epoch 63] ogbg-molclintox: 0.979559 val loss: 0.065879
[Epoch 63] ogbg-molclintox: 0.844060 test loss: 0.249520
[Epoch 64; Iter    30/   40] train: loss: 0.0064553
[Epoch 64] ogbg-molclintox: 0.974164 val loss: 0.108291
[Epoch 64] ogbg-molclintox: 0.772058 test loss: 0.401329
[Epoch 65; Iter    20/   40] train: loss: 0.0047098
[Epoch 65] ogbg-molclintox: 0.985828 val loss: 0.073572
[Epoch 65] ogbg-molclintox: 0.824860 test loss: 0.419236
[Epoch 66; Iter    10/   40] train: loss: 0.0617477
[Epoch 66; Iter    40/   40] train: loss: 0.0635842
[Epoch 66] ogbg-molclintox: 0.943722 val loss: 0.114545
[Epoch 66] ogbg-molclintox: 0.688448 test loss: 0.457273
[Epoch 67; Iter    30/   40] train: loss: 0.0032085
[Epoch 67] ogbg-molclintox: 0.908033 val loss: 0.126043
[Epoch 67] ogbg-molclintox: 0.826951 test loss: 0.395704
[Epoch 68; Iter    20/   40] train: loss: 0.0090865
[Epoch 68] ogbg-molclintox: 0.912267 val loss: 0.249577
[Epoch 68] ogbg-molclintox: 0.814969 test loss: 0.676793
[Epoch 69; Iter    10/   40] train: loss: 0.0034932
[Epoch 69; Iter    40/   40] train: loss: 0.0529036
[Epoch 69] ogbg-molclintox: 0.806989 val loss: 0.684364
[Epoch 69] ogbg-molclintox: 0.829525 test loss: 0.440774
[Epoch 70; Iter    30/   40] train: loss: 0.0213159
[Epoch 70] ogbg-molclintox: 0.960755 val loss: 0.865830
[Epoch 70] ogbg-molclintox: 0.794642 test loss: 0.422923
[Epoch 71; Iter    20/   40] train: loss: 0.0831615
[Epoch 71] ogbg-molclintox: 0.970281 val loss: 0.105117
[Epoch 71] ogbg-molclintox: 0.803890 test loss: 0.321944
[Epoch 72; Iter    10/   40] train: loss: 0.0056649
[Epoch 72; Iter    40/   40] train: loss: 0.0209212
[Epoch 72] ogbg-molclintox: 0.978810 val loss: 0.134477
[Epoch 72] ogbg-molclintox: 0.742927 test loss: 0.401873
[Epoch 73; Iter    30/   40] train: loss: 0.0020363
[Epoch 73] ogbg-molclintox: 0.980571 val loss: 0.071837
[Epoch 73] ogbg-molclintox: 0.777291 test loss: 0.397496
[Epoch 74; Iter    20/   40] train: loss: 0.0050915
[Epoch 74] ogbg-molclintox: 0.980321 val loss: 0.086856
[Epoch 74] ogbg-molclintox: 0.758379 test loss: 0.384428
[Epoch 75; Iter    10/   40] train: loss: 0.0197563
[Epoch 75; Iter    40/   40] train: loss: 0.0122063
[Epoch 75] ogbg-molclintox: 0.981270 val loss: 0.078792
[Epoch 75] ogbg-molclintox: 0.780351 test loss: 0.383435
[Epoch 76; Iter    30/   40] train: loss: 0.0028702
[Epoch 31] ogbg-molclintox: 0.395070 test loss: 5.910302
[Epoch 32; Iter    20/   40] train: loss: 0.1754952
[Epoch 32] ogbg-molclintox: 0.664865 val loss: 5.639470
[Epoch 32] ogbg-molclintox: 0.398454 test loss: 4.920491
[Epoch 33; Iter    10/   40] train: loss: 0.2143203
[Epoch 33; Iter    40/   40] train: loss: 0.8977098
[Epoch 33] ogbg-molclintox: 0.624183 val loss: 6.143864
[Epoch 33] ogbg-molclintox: 0.421490 test loss: 3.980447
[Epoch 34; Iter    30/   40] train: loss: 0.2272021
[Epoch 34] ogbg-molclintox: 0.647621 val loss: 5.462255
[Epoch 34] ogbg-molclintox: 0.465137 test loss: 4.019120
[Epoch 35; Iter    20/   40] train: loss: 0.2190171
[Epoch 35] ogbg-molclintox: 0.684407 val loss: 3.806822
[Epoch 35] ogbg-molclintox: 0.453819 test loss: 3.274745
[Epoch 36; Iter    10/   40] train: loss: 0.2281364
[Epoch 36; Iter    40/   40] train: loss: 0.2348818
[Epoch 36] ogbg-molclintox: 0.535751 val loss: 2.713708
[Epoch 36] ogbg-molclintox: 0.523586 test loss: 5.291101
[Epoch 37; Iter    30/   40] train: loss: 0.2506478
[Epoch 37] ogbg-molclintox: 0.666165 val loss: 6.459558
[Epoch 37] ogbg-molclintox: 0.563311 test loss: 2.876126
[Epoch 38; Iter    20/   40] train: loss: 0.2333837
[Epoch 38] ogbg-molclintox: 0.782791 val loss: 8.266826
[Epoch 38] ogbg-molclintox: 0.631816 test loss: 6.418033
[Epoch 39; Iter    10/   40] train: loss: 0.0677562
[Epoch 39; Iter    40/   40] train: loss: 0.0770747
[Epoch 39] ogbg-molclintox: 0.865442 val loss: 0.152943
[Epoch 39] ogbg-molclintox: 0.646246 test loss: 0.575699
[Epoch 40; Iter    30/   40] train: loss: 0.2291169
[Epoch 40] ogbg-molclintox: 0.850532 val loss: 0.132638
[Epoch 40] ogbg-molclintox: 0.703194 test loss: 3.018958
[Epoch 41; Iter    20/   40] train: loss: 0.1237365
[Epoch 41] ogbg-molclintox: 0.750936 val loss: 12.212733
[Epoch 41] ogbg-molclintox: 0.629766 test loss: 9.924317
[Epoch 42; Iter    10/   40] train: loss: 0.0577212
[Epoch 42; Iter    40/   40] train: loss: 0.1044835
[Epoch 42] ogbg-molclintox: 0.747689 val loss: 0.229484
[Epoch 42] ogbg-molclintox: 0.671179 test loss: 0.360235
[Epoch 43; Iter    30/   40] train: loss: 0.1897387
[Epoch 43] ogbg-molclintox: 0.853378 val loss: 2.594569
[Epoch 43] ogbg-molclintox: 0.666256 test loss: 13.006035
[Epoch 44; Iter    20/   40] train: loss: 0.1126191
[Epoch 44] ogbg-molclintox: 0.704237 val loss: 0.154678
[Epoch 44] ogbg-molclintox: 0.751637 test loss: 10.946948
[Epoch 45; Iter    10/   40] train: loss: 0.0648665
[Epoch 45; Iter    40/   40] train: loss: 0.0958235
[Epoch 45] ogbg-molclintox: 0.869037 val loss: 0.255531
[Epoch 45] ogbg-molclintox: 0.748828 test loss: 1.758837
[Epoch 46; Iter    30/   40] train: loss: 0.0385101
[Epoch 46] ogbg-molclintox: 0.781793 val loss: 1.139825
[Epoch 46] ogbg-molclintox: 0.674376 test loss: 2.553477
[Epoch 47; Iter    20/   40] train: loss: 0.0488956
[Epoch 47] ogbg-molclintox: 0.734303 val loss: 1.231387
[Epoch 47] ogbg-molclintox: 0.733749 test loss: 8.078791
[Epoch 48; Iter    10/   40] train: loss: 0.0358287
[Epoch 48; Iter    40/   40] train: loss: 0.2806294
[Epoch 48] ogbg-molclintox: 0.711265 val loss: 0.314536
[Epoch 48] ogbg-molclintox: 0.753946 test loss: 1.524016
[Epoch 49; Iter    30/   40] train: loss: 0.0870211
[Epoch 49] ogbg-molclintox: 0.736415 val loss: 0.333825
[Epoch 49] ogbg-molclintox: 0.800106 test loss: 1.044563
[Epoch 50; Iter    20/   40] train: loss: 0.0463182
[Epoch 50] ogbg-molclintox: 0.772038 val loss: 0.155549
[Epoch 50] ogbg-molclintox: 0.676087 test loss: 0.487613
[Epoch 51; Iter    10/   40] train: loss: 0.0175971
[Epoch 51; Iter    40/   40] train: loss: 0.0226869
[Epoch 51] ogbg-molclintox: 0.719931 val loss: 0.409042
[Epoch 51] ogbg-molclintox: 0.646952 test loss: 1.262251
[Epoch 52; Iter    30/   40] train: loss: 0.0706394
[Epoch 52] ogbg-molclintox: 0.665326 val loss: 1.669003
[Epoch 52] ogbg-molclintox: 0.654131 test loss: 2.401815
[Epoch 53; Iter    20/   40] train: loss: 0.0647351
[Epoch 53] ogbg-molclintox: 0.707681 val loss: 1.136261
[Epoch 53] ogbg-molclintox: 0.676655 test loss: 1.003670
[Epoch 54; Iter    10/   40] train: loss: 0.0631185
[Epoch 54; Iter    40/   40] train: loss: 0.0065282
[Epoch 54] ogbg-molclintox: 0.637803 val loss: 0.277847
[Epoch 54] ogbg-molclintox: 0.702507 test loss: 1.559089
[Epoch 55; Iter    30/   40] train: loss: 0.0160805
[Epoch 55] ogbg-molclintox: 0.614965 val loss: 1.320073
[Epoch 55] ogbg-molclintox: 0.583209 test loss: 2.440454
[Epoch 56; Iter    20/   40] train: loss: 0.0465098
[Epoch 56] ogbg-molclintox: 0.840942 val loss: 8.926431
[Epoch 56] ogbg-molclintox: 0.583859 test loss: 26.049181
[Epoch 57; Iter    10/   40] train: loss: 0.0162812
[Epoch 57; Iter    40/   40] train: loss: 0.0032147
[Epoch 57] ogbg-molclintox: 0.559464 val loss: 13.322578
[Epoch 57] ogbg-molclintox: 0.577263 test loss: 22.195156
[Epoch 58; Iter    30/   40] train: loss: 0.0177160
[Epoch 58] ogbg-molclintox: 0.514360 val loss: 18.164208
[Epoch 58] ogbg-molclintox: 0.439786 test loss: 12.911009
[Epoch 59; Iter    20/   40] train: loss: 0.0194404
[Epoch 59] ogbg-molclintox: 0.472153 val loss: 6.800526
[Epoch 59] ogbg-molclintox: 0.483551 test loss: 7.149803
[Epoch 60; Iter    10/   40] train: loss: 0.0126694
[Epoch 60; Iter    40/   40] train: loss: 0.0358238
[Epoch 60] ogbg-molclintox: 0.609374 val loss: 3.266299
[Epoch 60] ogbg-molclintox: 0.567727 test loss: 5.598362
[Epoch 61; Iter    30/   40] train: loss: 0.0056857
[Epoch 61] ogbg-molclintox: 0.729071 val loss: 2.032525
[Epoch 61] ogbg-molclintox: 0.593066 test loss: 3.857947
[Epoch 62; Iter    20/   40] train: loss: 0.0027700
[Epoch 62] ogbg-molclintox: 0.666411 val loss: 0.629241
[Epoch 62] ogbg-molclintox: 0.720320 test loss: 0.731217
[Epoch 63; Iter    10/   40] train: loss: 0.0847196
[Epoch 63; Iter    40/   40] train: loss: 0.0034871
[Epoch 63] ogbg-molclintox: 0.654376 val loss: 1.887990
[Epoch 63] ogbg-molclintox: 0.613088 test loss: 0.602383
[Epoch 64; Iter    30/   40] train: loss: 0.0122272
[Epoch 64] ogbg-molclintox: 0.639556 val loss: 2.108679
[Epoch 64] ogbg-molclintox: 0.660858 test loss: 1.260675
[Epoch 65; Iter    20/   40] train: loss: 0.0034544
[Epoch 65] ogbg-molclintox: 0.606591 val loss: 2.663195
[Epoch 65] ogbg-molclintox: 0.483907 test loss: 4.683398
[Epoch 66; Iter    10/   40] train: loss: 0.0130082
[Epoch 66; Iter    40/   40] train: loss: 0.0357880
[Epoch 66] ogbg-molclintox: 0.644227 val loss: 3.698819
[Epoch 66] ogbg-molclintox: 0.515123 test loss: 3.352320
[Epoch 67; Iter    30/   40] train: loss: 0.0028553
[Epoch 67] ogbg-molclintox: 0.627869 val loss: 3.315212
[Epoch 67] ogbg-molclintox: 0.590486 test loss: 2.338505
[Epoch 68; Iter    20/   40] train: loss: 0.0058682
[Epoch 68] ogbg-molclintox: 0.609747 val loss: 1.824834
[Epoch 68] ogbg-molclintox: 0.554888 test loss: 3.795734
[Epoch 69; Iter    10/   40] train: loss: 0.0197197
[Epoch 69; Iter    40/   40] train: loss: 0.2709654
[Epoch 69] ogbg-molclintox: 0.578394 val loss: 8.671098
[Epoch 69] ogbg-molclintox: 0.586142 test loss: 6.125891
[Epoch 70; Iter    30/   40] train: loss: 0.1091320
[Epoch 70] ogbg-molclintox: 0.831904 val loss: 0.200424
[Epoch 70] ogbg-molclintox: 0.730335 test loss: 0.452025
[Epoch 71; Iter    20/   40] train: loss: 0.0150957
[Epoch 71] ogbg-molclintox: 0.889591 val loss: 0.475764
[Epoch 71] ogbg-molclintox: 0.783066 test loss: 0.420506
[Epoch 72; Iter    10/   40] train: loss: 0.0343422
[Epoch 72; Iter    40/   40] train: loss: 0.0315728
[Epoch 72] ogbg-molclintox: 0.815271 val loss: 0.334926
[Epoch 72] ogbg-molclintox: 0.749676 test loss: 0.399753
[Epoch 73; Iter    30/   40] train: loss: 0.0040189
[Epoch 73] ogbg-molclintox: 0.898657 val loss: 0.658958
[Epoch 73] ogbg-molclintox: 0.778456 test loss: 0.538921
[Epoch 74; Iter    20/   40] train: loss: 0.0222063
[Epoch 74] ogbg-molclintox: 0.875257 val loss: 0.240227
[Epoch 74] ogbg-molclintox: 0.769126 test loss: 0.488099
[Epoch 75; Iter    10/   40] train: loss: 0.0509496
[Epoch 75; Iter    40/   40] train: loss: 0.0265338
[Epoch 75] ogbg-molclintox: 0.878866 val loss: 0.441945
[Epoch 75] ogbg-molclintox: 0.763866 test loss: 0.454291
[Epoch 76; Iter    30/   40] train: loss: 0.0024659
[Epoch 31] ogbg-molclintox: 0.658061 test loss: 0.238734
[Epoch 32; Iter    20/   40] train: loss: 0.1597704
[Epoch 32] ogbg-molclintox: 0.686519 val loss: 0.161562
[Epoch 32] ogbg-molclintox: 0.622893 test loss: 0.246291
[Epoch 33; Iter    10/   40] train: loss: 0.1888978
[Epoch 33; Iter    40/   40] train: loss: 0.6619499
[Epoch 33] ogbg-molclintox: 0.919984 val loss: 0.128793
[Epoch 33] ogbg-molclintox: 0.649540 test loss: 0.235353
[Epoch 34; Iter    30/   40] train: loss: 0.1590526
[Epoch 34] ogbg-molclintox: 0.843641 val loss: 0.158037
[Epoch 34] ogbg-molclintox: 0.571365 test loss: 0.252334
[Epoch 35; Iter    20/   40] train: loss: 0.1991692
[Epoch 35] ogbg-molclintox: 0.900379 val loss: 0.127453
[Epoch 35] ogbg-molclintox: 0.716085 test loss: 0.286899
[Epoch 36; Iter    10/   40] train: loss: 0.2026929
[Epoch 36; Iter    40/   40] train: loss: 0.3901300
[Epoch 36] ogbg-molclintox: 0.823772 val loss: 0.129895
[Epoch 36] ogbg-molclintox: 0.802740 test loss: 0.375494
[Epoch 37; Iter    30/   40] train: loss: 0.3608456
[Epoch 37] ogbg-molclintox: 0.745081 val loss: 0.267971
[Epoch 37] ogbg-molclintox: 0.690154 test loss: 0.303997
[Epoch 38; Iter    20/   40] train: loss: 0.2484218
[Epoch 38] ogbg-molclintox: 0.909382 val loss: 0.115348
[Epoch 38] ogbg-molclintox: 0.851571 test loss: 0.387369
[Epoch 39; Iter    10/   40] train: loss: 0.1476990
[Epoch 39; Iter    40/   40] train: loss: 0.0868082
[Epoch 39] ogbg-molclintox: 0.963176 val loss: 0.089893
[Epoch 39] ogbg-molclintox: 0.830085 test loss: 0.285033
[Epoch 40; Iter    30/   40] train: loss: 0.3455032
[Epoch 40] ogbg-molclintox: 0.951189 val loss: 0.126258
[Epoch 40] ogbg-molclintox: 0.843637 test loss: 4.070794
[Epoch 41; Iter    20/   40] train: loss: 0.3062618
[Epoch 41] ogbg-molclintox: 0.892824 val loss: 0.118912
[Epoch 41] ogbg-molclintox: 0.824150 test loss: 10.199541
[Epoch 42; Iter    10/   40] train: loss: 0.0548931
[Epoch 42; Iter    40/   40] train: loss: 0.1159932
[Epoch 42] ogbg-molclintox: 0.963513 val loss: 0.104910
[Epoch 42] ogbg-molclintox: 0.858855 test loss: 1.394793
[Epoch 43; Iter    30/   40] train: loss: 0.3637165
[Epoch 43] ogbg-molclintox: 0.981182 val loss: 0.079354
[Epoch 43] ogbg-molclintox: 0.813747 test loss: 0.212147
[Epoch 44; Iter    20/   40] train: loss: 0.0423213
[Epoch 44] ogbg-molclintox: 0.954686 val loss: 0.085833
[Epoch 44] ogbg-molclintox: 0.834030 test loss: 0.698293
[Epoch 45; Iter    10/   40] train: loss: 0.1148272
[Epoch 45; Iter    40/   40] train: loss: 0.1872550
[Epoch 45] ogbg-molclintox: 0.970369 val loss: 0.081192
[Epoch 45] ogbg-molclintox: 0.864988 test loss: 0.280829
[Epoch 46; Iter    30/   40] train: loss: 0.1078847
[Epoch 46] ogbg-molclintox: 0.994044 val loss: 0.061038
[Epoch 46] ogbg-molclintox: 0.845012 test loss: 0.777877
[Epoch 47; Iter    20/   40] train: loss: 0.2319885
[Epoch 47] ogbg-molclintox: 0.947992 val loss: 0.471213
[Epoch 47] ogbg-molclintox: 0.789214 test loss: 1.670370
[Epoch 48; Iter    10/   40] train: loss: 0.0835375
[Epoch 48; Iter    40/   40] train: loss: 0.1590162
[Epoch 48] ogbg-molclintox: 0.991921 val loss: 0.055470
[Epoch 48] ogbg-molclintox: 0.908698 test loss: 0.157288
[Epoch 49; Iter    30/   40] train: loss: 0.2940640
[Epoch 49] ogbg-molclintox: 0.982918 val loss: 0.135349
[Epoch 49] ogbg-molclintox: 0.875742 test loss: 2.414612
[Epoch 50; Iter    20/   40] train: loss: 0.1322891
[Epoch 50] ogbg-molclintox: 0.953674 val loss: 0.091873
[Epoch 50] ogbg-molclintox: 0.866497 test loss: 0.193484
[Epoch 51; Iter    10/   40] train: loss: 0.2113490
[Epoch 51; Iter    40/   40] train: loss: 0.0526865
[Epoch 51] ogbg-molclintox: 0.955009 val loss: 0.076663
[Epoch 51] ogbg-molclintox: 0.829522 test loss: 0.629023
[Epoch 52; Iter    30/   40] train: loss: 0.1114447
[Epoch 52] ogbg-molclintox: 0.852841 val loss: 0.141587
[Epoch 52] ogbg-molclintox: 0.797144 test loss: 0.231622
[Epoch 53; Iter    20/   40] train: loss: 0.1691435
[Epoch 53] ogbg-molclintox: 0.928450 val loss: 0.107432
[Epoch 53] ogbg-molclintox: 0.839853 test loss: 0.173134
[Epoch 54; Iter    10/   40] train: loss: 0.1805274
[Epoch 54; Iter    40/   40] train: loss: 0.0706381
[Epoch 54] ogbg-molclintox: 0.921158 val loss: 0.089850
[Epoch 54] ogbg-molclintox: 0.771621 test loss: 0.364212
[Epoch 55; Iter    30/   40] train: loss: 0.1604413
[Epoch 55] ogbg-molclintox: 0.967034 val loss: 0.074832
[Epoch 55] ogbg-molclintox: 0.848747 test loss: 0.156173
[Epoch 56; Iter    20/   40] train: loss: 0.2524031
[Epoch 56] ogbg-molclintox: 0.943996 val loss: 0.415555
[Epoch 56] ogbg-molclintox: 0.753131 test loss: 0.736700
[Epoch 57; Iter    10/   40] train: loss: 0.1397318
[Epoch 57; Iter    40/   40] train: loss: 0.1601826
[Epoch 57] ogbg-molclintox: 0.983417 val loss: 0.071644
[Epoch 57] ogbg-molclintox: 0.861963 test loss: 0.199222
[Epoch 58; Iter    30/   40] train: loss: 0.3044528
[Epoch 58] ogbg-molclintox: 0.980033 val loss: 0.059319
[Epoch 58] ogbg-molclintox: 0.836055 test loss: 3.194926
[Epoch 59; Iter    20/   40] train: loss: 0.1601881
[Epoch 59] ogbg-molclintox: 0.942647 val loss: 0.075402
[Epoch 59] ogbg-molclintox: 0.805814 test loss: 0.630591
[Epoch 60; Iter    10/   40] train: loss: 0.0493589
[Epoch 60; Iter    40/   40] train: loss: 0.0614789
[Epoch 60] ogbg-molclintox: 0.987862 val loss: 0.066679
[Epoch 60] ogbg-molclintox: 0.819037 test loss: 1.040840
[Epoch 61; Iter    30/   40] train: loss: 0.0722876
[Epoch 61] ogbg-molclintox: 0.988649 val loss: 0.062493
[Epoch 61] ogbg-molclintox: 0.853080 test loss: 2.760927
[Epoch 62; Iter    20/   40] train: loss: 0.0784342
[Epoch 62] ogbg-molclintox: 0.929149 val loss: 0.107573
[Epoch 62] ogbg-molclintox: 0.800338 test loss: 6.012286
[Epoch 63; Iter    10/   40] train: loss: 0.3172386
[Epoch 63; Iter    40/   40] train: loss: 0.0289400
[Epoch 63] ogbg-molclintox: 0.926777 val loss: 0.095265
[Epoch 63] ogbg-molclintox: 0.793417 test loss: 2.616411
[Epoch 64; Iter    30/   40] train: loss: 0.0239702
[Epoch 64] ogbg-molclintox: 0.979783 val loss: 0.069435
[Epoch 64] ogbg-molclintox: 0.858029 test loss: 11.336597
[Epoch 65; Iter    20/   40] train: loss: 0.0339122
[Epoch 65] ogbg-molclintox: 0.983979 val loss: 0.062067
[Epoch 65] ogbg-molclintox: 0.842412 test loss: 3.269318
[Epoch 66; Iter    10/   40] train: loss: 0.0363663
[Epoch 66; Iter    40/   40] train: loss: 0.2514281
[Epoch 66] ogbg-molclintox: 0.862930 val loss: 0.101097
[Epoch 66] ogbg-molclintox: 0.833283 test loss: 5.850610
[Epoch 67; Iter    30/   40] train: loss: 0.0755982
[Epoch 67] ogbg-molclintox: 0.976013 val loss: 0.083234
[Epoch 67] ogbg-molclintox: 0.762626 test loss: 9.203244
[Epoch 68; Iter    20/   40] train: loss: 0.0570368
[Epoch 68] ogbg-molclintox: 0.981157 val loss: 0.083220
[Epoch 68] ogbg-molclintox: 0.829171 test loss: 7.233569
[Epoch 69; Iter    10/   40] train: loss: 0.0221726
[Epoch 69; Iter    40/   40] train: loss: 0.0604074
[Epoch 69] ogbg-molclintox: 0.961777 val loss: 0.075215
[Epoch 69] ogbg-molclintox: 0.860177 test loss: 8.041461
[Epoch 70; Iter    30/   40] train: loss: 0.0667516
[Epoch 70] ogbg-molclintox: 0.974189 val loss: 0.077123
[Epoch 70] ogbg-molclintox: 0.811372 test loss: 8.327852
[Epoch 71; Iter    20/   40] train: loss: 0.0363693
[Epoch 71] ogbg-molclintox: 0.977686 val loss: 0.081420
[Epoch 71] ogbg-molclintox: 0.874655 test loss: 9.229429
[Epoch 72; Iter    10/   40] train: loss: 0.0231830
[Epoch 72; Iter    40/   40] train: loss: 0.0723072
[Epoch 72] ogbg-molclintox: 0.989486 val loss: 0.048978
[Epoch 72] ogbg-molclintox: 0.815619 test loss: 11.129584
[Epoch 73; Iter    30/   40] train: loss: 0.2160161
[Epoch 73] ogbg-molclintox: 0.964012 val loss: 0.115730
[Epoch 73] ogbg-molclintox: 0.857342 test loss: 28.975559
[Epoch 74; Iter    20/   40] train: loss: 0.0551755
[Epoch 74] ogbg-molclintox: 0.982830 val loss: 0.062307
[Epoch 74] ogbg-molclintox: 0.872843 test loss: 7.844583
[Epoch 75; Iter    10/   40] train: loss: 0.0423638
[Epoch 75; Iter    40/   40] train: loss: 0.0275981
[Epoch 75] ogbg-molclintox: 0.943708 val loss: 0.068395
[Epoch 75] ogbg-molclintox: 0.860002 test loss: 7.316435
[Epoch 76; Iter    30/   40] train: loss: 0.0091045
[Epoch 31] ogbg-molclintox: 0.717108 test loss: 0.215688
[Epoch 32; Iter    20/   40] train: loss: 0.2740614
[Epoch 32] ogbg-molclintox: 0.780654 val loss: 0.186595
[Epoch 32] ogbg-molclintox: 0.673013 test loss: 0.289068
[Epoch 33; Iter    10/   40] train: loss: 0.3586622
[Epoch 33; Iter    40/   40] train: loss: 0.2419899
[Epoch 33] ogbg-molclintox: 0.718870 val loss: 0.200923
[Epoch 33] ogbg-molclintox: 0.734096 test loss: 0.252353
[Epoch 34; Iter    30/   40] train: loss: 0.1287272
[Epoch 34] ogbg-molclintox: 0.832002 val loss: 0.137936
[Epoch 34] ogbg-molclintox: 0.655409 test loss: 0.248011
[Epoch 35; Iter    20/   40] train: loss: 0.1677677
[Epoch 35] ogbg-molclintox: 0.764936 val loss: 0.156285
[Epoch 35] ogbg-molclintox: 0.769286 test loss: 0.206387
[Epoch 36; Iter    10/   40] train: loss: 0.2273070
[Epoch 36; Iter    40/   40] train: loss: 0.4273088
[Epoch 36] ogbg-molclintox: 0.916625 val loss: 0.120932
[Epoch 36] ogbg-molclintox: 0.818357 test loss: 0.436308
[Epoch 37; Iter    30/   40] train: loss: 0.1884886
[Epoch 37] ogbg-molclintox: 0.811634 val loss: 0.371793
[Epoch 37] ogbg-molclintox: 0.790361 test loss: 0.423519
[Epoch 38; Iter    20/   40] train: loss: 0.2669347
[Epoch 38] ogbg-molclintox: 0.762648 val loss: 0.264398
[Epoch 38] ogbg-molclintox: 0.783480 test loss: 0.220255
[Epoch 39; Iter    10/   40] train: loss: 0.0656325
[Epoch 39; Iter    40/   40] train: loss: 0.0622509
[Epoch 39] ogbg-molclintox: 0.818540 val loss: 0.117339
[Epoch 39] ogbg-molclintox: 0.899891 test loss: 0.178112
[Epoch 40; Iter    30/   40] train: loss: 0.2063422
[Epoch 40] ogbg-molclintox: 0.940563 val loss: 0.158055
[Epoch 40] ogbg-molclintox: 0.728650 test loss: 0.314558
[Epoch 41; Iter    20/   40] train: loss: 0.1505130
[Epoch 41] ogbg-molclintox: 0.761949 val loss: 0.210856
[Epoch 41] ogbg-molclintox: 0.818816 test loss: 0.264117
[Epoch 42; Iter    10/   40] train: loss: 0.1201194
[Epoch 42; Iter    40/   40] train: loss: 0.0464816
[Epoch 42] ogbg-molclintox: 0.949453 val loss: 0.079316
[Epoch 42] ogbg-molclintox: 0.761528 test loss: 0.594917
[Epoch 43; Iter    30/   40] train: loss: 0.1866038
[Epoch 43] ogbg-molclintox: 0.870812 val loss: 0.132232
[Epoch 43] ogbg-molclintox: 0.712562 test loss: 0.253795
[Epoch 44; Iter    20/   40] train: loss: 0.1123304
[Epoch 44] ogbg-molclintox: 0.939389 val loss: 0.095635
[Epoch 44] ogbg-molclintox: 0.828285 test loss: 0.196463
[Epoch 45; Iter    10/   40] train: loss: 0.2555117
[Epoch 45; Iter    40/   40] train: loss: 0.2588549
[Epoch 45] ogbg-molclintox: 0.898418 val loss: 0.102521
[Epoch 45] ogbg-molclintox: 0.848784 test loss: 0.181039
[Epoch 46; Iter    30/   40] train: loss: 0.1631899
[Epoch 46] ogbg-molclintox: 0.970281 val loss: 0.148042
[Epoch 46] ogbg-molclintox: 0.871607 test loss: 0.418151
[Epoch 47; Iter    20/   40] train: loss: 0.0975863
[Epoch 47] ogbg-molclintox: 0.975089 val loss: 0.078218
[Epoch 47] ogbg-molclintox: 0.858679 test loss: 0.205280
[Epoch 48; Iter    10/   40] train: loss: 0.0798398
[Epoch 48; Iter    40/   40] train: loss: 0.1578911
[Epoch 48] ogbg-molclintox: 0.984791 val loss: 0.072698
[Epoch 48] ogbg-molclintox: 0.846999 test loss: 0.188528
[Epoch 49; Iter    30/   40] train: loss: 0.0994605
[Epoch 49] ogbg-molclintox: 0.925941 val loss: 0.128089
[Epoch 49] ogbg-molclintox: 0.811771 test loss: 0.557255
[Epoch 50; Iter    20/   40] train: loss: 0.0687682
[Epoch 50] ogbg-molclintox: 0.938901 val loss: 0.087276
[Epoch 50] ogbg-molclintox: 0.869810 test loss: 0.184117
[Epoch 51; Iter    10/   40] train: loss: 0.1368119
[Epoch 51; Iter    40/   40] train: loss: 0.5998988
[Epoch 51] ogbg-molclintox: 0.983779 val loss: 0.076315
[Epoch 51] ogbg-molclintox: 0.859729 test loss: 0.171519
[Epoch 52; Iter    30/   40] train: loss: 0.2288206
[Epoch 52] ogbg-molclintox: 0.946182 val loss: 0.090942
[Epoch 52] ogbg-molclintox: 0.831083 test loss: 0.195754
[Epoch 53; Iter    20/   40] train: loss: 0.0838677
[Epoch 53] ogbg-molclintox: 0.964213 val loss: 0.074506
[Epoch 53] ogbg-molclintox: 0.830059 test loss: 0.383046
[Epoch 54; Iter    10/   40] train: loss: 0.1268070
[Epoch 54; Iter    40/   40] train: loss: 0.1564885
[Epoch 54] ogbg-molclintox: 0.983392 val loss: 0.068091
[Epoch 54] ogbg-molclintox: 0.809325 test loss: 0.229008
[Epoch 55; Iter    30/   40] train: loss: 0.1035657
[Epoch 55] ogbg-molclintox: 0.874256 val loss: 0.121655
[Epoch 55] ogbg-molclintox: 0.816568 test loss: 0.913118
[Epoch 56; Iter    20/   40] train: loss: 0.0635706
[Epoch 56] ogbg-molclintox: 0.945806 val loss: 0.087341
[Epoch 56] ogbg-molclintox: 0.853084 test loss: 0.201874
[Epoch 57; Iter    10/   40] train: loss: 0.0681246
[Epoch 57; Iter    40/   40] train: loss: 0.0850952
[Epoch 57] ogbg-molclintox: 0.894223 val loss: 0.101197
[Epoch 57] ogbg-molclintox: 0.810360 test loss: 0.285745
[Epoch 58; Iter    30/   40] train: loss: 0.0578377
[Epoch 58] ogbg-molclintox: 0.974502 val loss: 0.105077
[Epoch 58] ogbg-molclintox: 0.850286 test loss: 0.274133
[Epoch 59; Iter    20/   40] train: loss: 0.0355681
[Epoch 59] ogbg-molclintox: 0.947092 val loss: 0.080031
[Epoch 59] ogbg-molclintox: 0.833133 test loss: 0.202409
[Epoch 60; Iter    10/   40] train: loss: 0.0418629
[Epoch 60; Iter    40/   40] train: loss: 0.0771397
[Epoch 60] ogbg-molclintox: 0.868637 val loss: 0.106654
[Epoch 60] ogbg-molclintox: 0.838355 test loss: 1.343063
[Epoch 61; Iter    30/   40] train: loss: 0.0857255
[Epoch 61] ogbg-molclintox: 0.826756 val loss: 0.131927
[Epoch 61] ogbg-molclintox: 0.831934 test loss: 0.756395
[Epoch 62; Iter    20/   40] train: loss: 0.0943573
[Epoch 62] ogbg-molclintox: 0.947630 val loss: 0.081197
[Epoch 62] ogbg-molclintox: 0.876594 test loss: 0.628903
[Epoch 63; Iter    10/   40] train: loss: 0.0877788
[Epoch 63; Iter    40/   40] train: loss: 0.2292525
[Epoch 63] ogbg-molclintox: 0.968208 val loss: 0.080522
[Epoch 63] ogbg-molclintox: 0.825827 test loss: 0.197944
[Epoch 64; Iter    30/   40] train: loss: 0.0410058
[Epoch 64] ogbg-molclintox: 0.947992 val loss: 0.108010
[Epoch 64] ogbg-molclintox: 0.876904 test loss: 1.312304
[Epoch 65; Iter    20/   40] train: loss: 0.1622224
[Epoch 65] ogbg-molclintox: 0.952275 val loss: 0.255577
[Epoch 65] ogbg-molclintox: 0.856643 test loss: 0.589770
[Epoch 66; Iter    10/   40] train: loss: 0.1031329
[Epoch 66; Iter    40/   40] train: loss: 0.0388227
[Epoch 66] ogbg-molclintox: 0.859271 val loss: 0.130621
[Epoch 66] ogbg-molclintox: 0.813632 test loss: 0.385627
[Epoch 67; Iter    30/   40] train: loss: 0.0253499
[Epoch 67] ogbg-molclintox: 0.954559 val loss: 0.083490
[Epoch 67] ogbg-molclintox: 0.890220 test loss: 0.438413
[Epoch 68; Iter    20/   40] train: loss: 0.0500474
[Epoch 68] ogbg-molclintox: 0.967396 val loss: 0.073811
[Epoch 68] ogbg-molclintox: 0.875555 test loss: 0.351644
[Epoch 69; Iter    10/   40] train: loss: 0.0247165
[Epoch 69; Iter    40/   40] train: loss: 0.0510603
[Epoch 69] ogbg-molclintox: 0.960266 val loss: 0.093726
[Epoch 69] ogbg-molclintox: 0.863401 test loss: 1.084745
[Epoch 70; Iter    30/   40] train: loss: 0.0938885
[Epoch 70] ogbg-molclintox: 0.936216 val loss: 0.084376
[Epoch 70] ogbg-molclintox: 0.881289 test loss: 0.214027
[Epoch 71; Iter    20/   40] train: loss: 0.0805146
[Epoch 71] ogbg-molclintox: 0.868661 val loss: 0.100163
[Epoch 71] ogbg-molclintox: 0.850211 test loss: 0.263000
[Epoch 72; Iter    10/   40] train: loss: 0.0106373
[Epoch 72; Iter    40/   40] train: loss: 0.0235821
[Epoch 72] ogbg-molclintox: 0.920982 val loss: 0.099868
[Epoch 72] ogbg-molclintox: 0.855893 test loss: 0.921968
[Epoch 73; Iter    30/   40] train: loss: 0.0817529
[Epoch 73] ogbg-molclintox: 0.918547 val loss: 0.137837
[Epoch 73] ogbg-molclintox: 0.848471 test loss: 0.398811
[Epoch 74; Iter    20/   40] train: loss: 0.0936829
[Epoch 74] ogbg-molclintox: 0.906047 val loss: 0.107097
[Epoch 74] ogbg-molclintox: 0.826511 test loss: 0.360058
[Epoch 75; Iter    10/   40] train: loss: 0.0731110
[Epoch 75; Iter    40/   40] train: loss: 0.0214946
[Epoch 75] ogbg-molclintox: 0.938402 val loss: 0.095702
[Epoch 75] ogbg-molclintox: 0.875805 test loss: 1.915787
[Epoch 76; Iter    30/   40] train: loss: 0.0480931
[Epoch 31] ogbg-molclintox: 0.689426 test loss: 0.489176
[Epoch 32; Iter    20/   40] train: loss: 0.1912041
[Epoch 32] ogbg-molclintox: 0.896921 val loss: 0.135131
[Epoch 32] ogbg-molclintox: 0.701442 test loss: 0.429953
[Epoch 33; Iter    10/   40] train: loss: 0.0918464
[Epoch 33; Iter    40/   40] train: loss: 0.3517769
[Epoch 33] ogbg-molclintox: 0.865930 val loss: 0.141238
[Epoch 33] ogbg-molclintox: 0.696945 test loss: 0.227643
[Epoch 34; Iter    30/   40] train: loss: 0.0688761
[Epoch 34] ogbg-molclintox: 0.884597 val loss: 0.146472
[Epoch 34] ogbg-molclintox: 0.659697 test loss: 0.352021
[Epoch 35; Iter    20/   40] train: loss: 0.2000411
[Epoch 35] ogbg-molclintox: 0.904687 val loss: 0.121694
[Epoch 35] ogbg-molclintox: 0.756934 test loss: 0.275174
[Epoch 36; Iter    10/   40] train: loss: 0.1438867
[Epoch 36; Iter    40/   40] train: loss: 0.2674505
[Epoch 36] ogbg-molclintox: 0.938665 val loss: 0.117676
[Epoch 36] ogbg-molclintox: 0.776753 test loss: 0.227476
[Epoch 37; Iter    30/   40] train: loss: 0.1837731
[Epoch 37] ogbg-molclintox: 0.886681 val loss: 0.579645
[Epoch 37] ogbg-molclintox: 0.701315 test loss: 2.172573
[Epoch 38; Iter    20/   40] train: loss: 0.0678248
[Epoch 38] ogbg-molclintox: 0.918473 val loss: 0.180657
[Epoch 38] ogbg-molclintox: 0.776541 test loss: 0.467712
[Epoch 39; Iter    10/   40] train: loss: 0.1687528
[Epoch 39; Iter    40/   40] train: loss: 0.0986435
[Epoch 39] ogbg-molclintox: 0.986214 val loss: 0.074819
[Epoch 39] ogbg-molclintox: 0.848594 test loss: 0.249214
[Epoch 40; Iter    30/   40] train: loss: 0.1205658
[Epoch 40] ogbg-molclintox: 0.936529 val loss: 0.093970
[Epoch 40] ogbg-molclintox: 0.840578 test loss: 0.223865
[Epoch 41; Iter    20/   40] train: loss: 0.0583589
[Epoch 41] ogbg-molclintox: 0.990772 val loss: 0.067378
[Epoch 41] ogbg-molclintox: 0.844676 test loss: 0.469258
[Epoch 42; Iter    10/   40] train: loss: 0.0891091
[Epoch 42; Iter    40/   40] train: loss: 0.0503768
[Epoch 42] ogbg-molclintox: 0.816080 val loss: 0.113418
[Epoch 42] ogbg-molclintox: 0.869471 test loss: 1.026036
[Epoch 43; Iter    30/   40] train: loss: 0.0675116
[Epoch 43] ogbg-molclintox: 0.944470 val loss: 0.169350
[Epoch 43] ogbg-molclintox: 0.852019 test loss: 0.230228
[Epoch 44; Iter    20/   40] train: loss: 0.0815777
[Epoch 44] ogbg-molclintox: 0.961303 val loss: 0.110210
[Epoch 44] ogbg-molclintox: 0.818054 test loss: 0.202825
[Epoch 45; Iter    10/   40] train: loss: 0.1558238
[Epoch 45; Iter    40/   40] train: loss: 0.0368975
[Epoch 45] ogbg-molclintox: 0.977549 val loss: 0.093874
[Epoch 45] ogbg-molclintox: 0.876452 test loss: 0.188333
[Epoch 46; Iter    30/   40] train: loss: 0.0485084
[Epoch 46] ogbg-molclintox: 0.992982 val loss: 0.052344
[Epoch 46] ogbg-molclintox: 0.783503 test loss: 0.255295
[Epoch 47; Iter    20/   40] train: loss: 0.1396208
[Epoch 47] ogbg-molclintox: 0.990298 val loss: 0.073918
[Epoch 47] ogbg-molclintox: 0.844149 test loss: 2.429794
[Epoch 48; Iter    10/   40] train: loss: 0.0649102
[Epoch 48; Iter    40/   40] train: loss: 0.1227954
[Epoch 48] ogbg-molclintox: 0.926851 val loss: 0.079566
[Epoch 48] ogbg-molclintox: 0.885286 test loss: 0.159843
[Epoch 49; Iter    30/   40] train: loss: 0.0332839
[Epoch 49] ogbg-molclintox: 0.912805 val loss: 0.147230
[Epoch 49] ogbg-molclintox: 0.829197 test loss: 0.197735
[Epoch 50; Iter    20/   40] train: loss: 0.1722583
[Epoch 50] ogbg-molclintox: 0.979871 val loss: 0.070819
[Epoch 50] ogbg-molclintox: 0.809373 test loss: 0.165151
[Epoch 51; Iter    10/   40] train: loss: 0.0738312
[Epoch 51; Iter    40/   40] train: loss: 0.0158995
[Epoch 51] ogbg-molclintox: 0.991471 val loss: 0.061775
[Epoch 51] ogbg-molclintox: 0.830896 test loss: 0.207857
[Epoch 52; Iter    30/   40] train: loss: 0.0652286
[Epoch 52] ogbg-molclintox: 0.987476 val loss: 0.074668
[Epoch 52] ogbg-molclintox: 0.845012 test loss: 0.171867
[Epoch 53; Iter    20/   40] train: loss: 0.0613991
[Epoch 53] ogbg-molclintox: 0.978160 val loss: 0.067328
[Epoch 53] ogbg-molclintox: 0.899241 test loss: 0.141519
[Epoch 54; Iter    10/   40] train: loss: 0.0453139
[Epoch 54; Iter    40/   40] train: loss: 0.0276824
[Epoch 54] ogbg-molclintox: 0.987363 val loss: 0.065324
[Epoch 54] ogbg-molclintox: 0.829522 test loss: 0.209015
[Epoch 55; Iter    30/   40] train: loss: 0.2308533
[Epoch 55] ogbg-molclintox: 0.980096 val loss: 0.080672
[Epoch 55] ogbg-molclintox: 0.823015 test loss: 0.239375
[Epoch 56; Iter    20/   40] train: loss: 0.1183325
[Epoch 56] ogbg-molclintox: 0.783901 val loss: 3.013709
[Epoch 56] ogbg-molclintox: 0.803079 test loss: 10.655856
[Epoch 57; Iter    10/   40] train: loss: 0.1322553
[Epoch 57; Iter    40/   40] train: loss: 0.0657151
[Epoch 57] ogbg-molclintox: 0.951664 val loss: 0.082845
[Epoch 57] ogbg-molclintox: 0.833556 test loss: 0.345018
[Epoch 58; Iter    30/   40] train: loss: 0.1804201
[Epoch 58] ogbg-molclintox: 0.994493 val loss: 0.052500
[Epoch 58] ogbg-molclintox: 0.876892 test loss: 0.151714
[Epoch 59; Iter    20/   40] train: loss: 0.0276787
[Epoch 59] ogbg-molclintox: 0.949228 val loss: 0.095193
[Epoch 59] ogbg-molclintox: 0.864387 test loss: 0.628881
[Epoch 60; Iter    10/   40] train: loss: 0.0715606
[Epoch 60; Iter    40/   40] train: loss: 0.3239653
[Epoch 60] ogbg-molclintox: 0.972580 val loss: 0.109865
[Epoch 60] ogbg-molclintox: 0.843540 test loss: 0.191855
[Epoch 61; Iter    30/   40] train: loss: 0.1645628
[Epoch 61] ogbg-molclintox: 0.982082 val loss: 0.078680
[Epoch 61] ogbg-molclintox: 0.793110 test loss: 0.207763
[Epoch 62; Iter    20/   40] train: loss: 0.0834197
[Epoch 62] ogbg-molclintox: 0.935594 val loss: 0.105185
[Epoch 62] ogbg-molclintox: 0.858104 test loss: 0.179912
[Epoch 63; Iter    10/   40] train: loss: 0.0447879
[Epoch 63; Iter    40/   40] train: loss: 0.0198451
[Epoch 63] ogbg-molclintox: 0.982556 val loss: 0.061125
[Epoch 63] ogbg-molclintox: 0.864275 test loss: 0.692050
[Epoch 64; Iter    30/   40] train: loss: 0.1119218
[Epoch 64] ogbg-molclintox: 0.981994 val loss: 0.062781
[Epoch 64] ogbg-molclintox: 0.859755 test loss: 0.197303
[Epoch 65; Iter    20/   40] train: loss: 0.0244974
[Epoch 65] ogbg-molclintox: 0.960055 val loss: 0.081155
[Epoch 65] ogbg-molclintox: 0.845912 test loss: 0.173623
[Epoch 66; Iter    10/   40] train: loss: 0.0729721
[Epoch 66; Iter    40/   40] train: loss: 0.0607047
[Epoch 66] ogbg-molclintox: 0.959630 val loss: 0.090249
[Epoch 66] ogbg-molclintox: 0.796882 test loss: 1.953375
[Epoch 67; Iter    30/   40] train: loss: 0.2446602
[Epoch 67] ogbg-molclintox: 0.972017 val loss: 0.084265
[Epoch 67] ogbg-molclintox: 0.817105 test loss: 0.505986
[Epoch 68; Iter    20/   40] train: loss: 0.1479662
[Epoch 68] ogbg-molclintox: 0.988649 val loss: 0.069099
[Epoch 68] ogbg-molclintox: 0.858967 test loss: 0.175330
[Epoch 69; Iter    10/   40] train: loss: 0.0620207
[Epoch 69; Iter    40/   40] train: loss: 0.1197691
[Epoch 69] ogbg-molclintox: 0.930572 val loss: 0.085346
[Epoch 69] ogbg-molclintox: 0.853920 test loss: 0.210605
[Epoch 70; Iter    30/   40] train: loss: 0.1118035
[Epoch 70] ogbg-molclintox: 0.984317 val loss: 0.076695
[Epoch 70] ogbg-molclintox: 0.855045 test loss: 0.177288
[Epoch 71; Iter    20/   40] train: loss: 0.1139642
[Epoch 71] ogbg-molclintox: 0.987926 val loss: 0.059626
[Epoch 71] ogbg-molclintox: 0.848037 test loss: 0.197739
[Epoch 72; Iter    10/   40] train: loss: 0.0116203
[Epoch 72; Iter    40/   40] train: loss: 0.0523706
[Epoch 72] ogbg-molclintox: 0.979871 val loss: 0.069510
[Epoch 72] ogbg-molclintox: 0.826051 test loss: 0.208243
[Epoch 73; Iter    30/   40] train: loss: 0.2063259
[Epoch 73] ogbg-molclintox: 0.995080 val loss: 0.049297
[Epoch 73] ogbg-molclintox: 0.886085 test loss: 0.144259
[Epoch 74; Iter    20/   40] train: loss: 0.0275275
[Epoch 74] ogbg-molclintox: 0.977162 val loss: 0.075624
[Epoch 74] ogbg-molclintox: 0.888573 test loss: 0.176274
[Epoch 75; Iter    10/   40] train: loss: 0.0975190
[Epoch 75; Iter    40/   40] train: loss: 0.0905788
[Epoch 75] ogbg-molclintox: 0.981495 val loss: 0.113300
[Epoch 75] ogbg-molclintox: 0.833746 test loss: 0.192823
[Epoch 76; Iter    30/   40] train: loss: 0.0701240
[Epoch 76] ogbg-molclintox: 0.881438 val loss: 0.144206
[Epoch 76] ogbg-molclintox: 0.778151 test loss: 0.310777
[Epoch 77; Iter    20/   40] train: loss: 0.0020584
[Epoch 77] ogbg-molclintox: 0.851006 val loss: 0.161495
[Epoch 77] ogbg-molclintox: 0.840071 test loss: 0.678333
[Epoch 78; Iter    10/   40] train: loss: 0.0011803
[Epoch 78; Iter    40/   40] train: loss: 0.0007528
[Epoch 78] ogbg-molclintox: 0.814994 val loss: 0.170396
[Epoch 78] ogbg-molclintox: 0.872089 test loss: 0.362183
[Epoch 79; Iter    30/   40] train: loss: 0.0159793
[Epoch 79] ogbg-molclintox: 0.852904 val loss: 0.183031
[Epoch 79] ogbg-molclintox: 0.879097 test loss: 1.038671
[Epoch 80; Iter    20/   40] train: loss: 0.0012951
[Epoch 80] ogbg-molclintox: 0.890466 val loss: 0.153638
[Epoch 80] ogbg-molclintox: 0.820210 test loss: 0.669958
[Epoch 81; Iter    10/   40] train: loss: 0.0106265
[Epoch 81; Iter    40/   40] train: loss: 0.0007059
[Epoch 81] ogbg-molclintox: 0.881874 val loss: 0.188454
[Epoch 81] ogbg-molclintox: 0.894437 test loss: 0.381410
[Epoch 82; Iter    30/   40] train: loss: 0.0036962
[Epoch 82] ogbg-molclintox: 0.876754 val loss: 0.189179
[Epoch 82] ogbg-molclintox: 0.886268 test loss: 1.107567
[Epoch 83; Iter    20/   40] train: loss: 0.0085387
[Epoch 83] ogbg-molclintox: 0.866577 val loss: 0.176932
[Epoch 83] ogbg-molclintox: 0.882320 test loss: 0.597930
[Epoch 84; Iter    10/   40] train: loss: 0.0014389
[Epoch 84; Iter    40/   40] train: loss: 0.0141488
[Epoch 84] ogbg-molclintox: 0.840092 val loss: 0.152415
[Epoch 84] ogbg-molclintox: 0.873901 test loss: 0.700189
[Epoch 85; Iter    30/   40] train: loss: 0.0015749
[Epoch 85] ogbg-molclintox: 0.883434 val loss: 0.163952
[Epoch 85] ogbg-molclintox: 0.864182 test loss: 0.777403
[Epoch 86; Iter    20/   40] train: loss: 0.0071434
[Epoch 86] ogbg-molclintox: 0.855863 val loss: 0.152205
[Epoch 86] ogbg-molclintox: 0.888342 test loss: 0.244511
[Epoch 87; Iter    10/   40] train: loss: 0.0020231
[Epoch 87; Iter    40/   40] train: loss: 0.0020677
[Epoch 87] ogbg-molclintox: 0.913416 val loss: 0.136216
[Epoch 87] ogbg-molclintox: 0.873688 test loss: 0.750969
[Epoch 88; Iter    30/   40] train: loss: 0.0042505
[Epoch 88] ogbg-molclintox: 0.886245 val loss: 0.154233
[Epoch 88] ogbg-molclintox: 0.898685 test loss: 0.482856
[Epoch 89; Iter    20/   40] train: loss: 0.0028980
[Epoch 89] ogbg-molclintox: 0.940313 val loss: 0.150266
[Epoch 89] ogbg-molclintox: 0.898636 test loss: 0.530420
[Epoch 90; Iter    10/   40] train: loss: 0.0015159
[Epoch 90; Iter    40/   40] train: loss: 0.0022708
[Epoch 90] ogbg-molclintox: 0.897821 val loss: 0.171308
[Epoch 90] ogbg-molclintox: 0.870378 test loss: 0.919716
[Epoch 91; Iter    30/   40] train: loss: 0.0022155
[Epoch 91] ogbg-molclintox: 0.906599 val loss: 0.166559
[Epoch 91] ogbg-molclintox: 0.882432 test loss: 0.823516
[Epoch 92; Iter    20/   40] train: loss: 0.0037680
[Epoch 92] ogbg-molclintox: 0.878904 val loss: 1.352037
[Epoch 92] ogbg-molclintox: 0.846581 test loss: 0.404362
[Epoch 93; Iter    10/   40] train: loss: 0.0014573
[Epoch 93; Iter    40/   40] train: loss: 0.0070454
[Epoch 93] ogbg-molclintox: 0.944059 val loss: 0.145875
[Epoch 93] ogbg-molclintox: 0.847956 test loss: 0.913056
[Epoch 94; Iter    30/   40] train: loss: 0.0018938
[Epoch 94] ogbg-molclintox: 0.942411 val loss: 0.149799
[Epoch 94] ogbg-molclintox: 0.844384 test loss: 0.684449
[Epoch 95; Iter    20/   40] train: loss: 0.0010482
[Epoch 95] ogbg-molclintox: 0.784189 val loss: 0.166985
[Epoch 95] ogbg-molclintox: 0.845957 test loss: 0.394447
[Epoch 96; Iter    10/   40] train: loss: 0.0025418
[Epoch 96; Iter    40/   40] train: loss: 0.0073351
[Epoch 96] ogbg-molclintox: 0.941311 val loss: 0.103667
[Epoch 96] ogbg-molclintox: 0.864869 test loss: 1.030228
[Epoch 97; Iter    30/   40] train: loss: 0.0018761
[Epoch 97] ogbg-molclintox: 0.892736 val loss: 0.129089
[Epoch 97] ogbg-molclintox: 0.881420 test loss: 0.205199
[Epoch 98; Iter    20/   40] train: loss: 0.0016520
[Epoch 98] ogbg-molclintox: 0.806114 val loss: 0.194301
[Epoch 98] ogbg-molclintox: 0.842009 test loss: 0.371818
[Epoch 99; Iter    10/   40] train: loss: 0.0046514
[Epoch 99; Iter    40/   40] train: loss: 0.0088312
[Epoch 99] ogbg-molclintox: 0.812471 val loss: 0.151730
[Epoch 99] ogbg-molclintox: 0.860035 test loss: 0.193012
[Epoch 100; Iter    30/   40] train: loss: 0.0038649
[Epoch 100] ogbg-molclintox: 0.925280 val loss: 0.129672
[Epoch 100] ogbg-molclintox: 0.829492 test loss: 0.213630
[Epoch 101; Iter    20/   40] train: loss: 0.0013203
[Epoch 101] ogbg-molclintox: 0.936543 val loss: 0.117587
[Epoch 101] ogbg-molclintox: 0.841284 test loss: 0.493134
[Epoch 102; Iter    10/   40] train: loss: 0.0005765
[Epoch 102; Iter    40/   40] train: loss: 0.0064405
[Epoch 102] ogbg-molclintox: 0.942274 val loss: 0.134822
[Epoch 102] ogbg-molclintox: 0.862034 test loss: 0.261091
[Epoch 103; Iter    30/   40] train: loss: 0.0007033
[Epoch 103] ogbg-molclintox: 0.926865 val loss: 0.130189
[Epoch 103] ogbg-molclintox: 0.855112 test loss: 1.020409
[Epoch 104; Iter    20/   40] train: loss: 0.0043486
[Epoch 104] ogbg-molclintox: 0.920459 val loss: 0.138477
[Epoch 104] ogbg-molclintox: 0.858672 test loss: 0.243305
[Epoch 105; Iter    10/   40] train: loss: 0.0026127
[Epoch 105; Iter    40/   40] train: loss: 0.0036533
[Epoch 105] ogbg-molclintox: 0.900854 val loss: 0.146491
[Epoch 105] ogbg-molclintox: 0.848180 test loss: 0.349331
[Epoch 106; Iter    30/   40] train: loss: 0.0031764
[Epoch 106] ogbg-molclintox: 0.891327 val loss: 0.141511
[Epoch 106] ogbg-molclintox: 0.850328 test loss: 0.681935
[Epoch 107; Iter    20/   40] train: loss: 0.0006276
[Epoch 107] ogbg-molclintox: 0.879551 val loss: 0.143953
[Epoch 107] ogbg-molclintox: 0.853263 test loss: 0.329361
[Epoch 108; Iter    10/   40] train: loss: 0.0014996
[Epoch 108; Iter    40/   40] train: loss: 0.0026224
[Epoch 108] ogbg-molclintox: 0.946881 val loss: 0.111935
[Epoch 108] ogbg-molclintox: 0.843357 test loss: 0.826226
[Epoch 109; Iter    30/   40] train: loss: 0.0007342
[Epoch 109] ogbg-molclintox: 0.920684 val loss: 0.143380
[Epoch 109] ogbg-molclintox: 0.854687 test loss: 0.850300
[Epoch 110; Iter    20/   40] train: loss: 0.0016577
[Epoch 110] ogbg-molclintox: 0.944896 val loss: 0.118936
[Epoch 110] ogbg-molclintox: 0.856861 test loss: 1.159797
[Epoch 111; Iter    10/   40] train: loss: 0.0021775
[Epoch 111; Iter    40/   40] train: loss: 0.0019847
[Epoch 111] ogbg-molclintox: 0.930997 val loss: 0.123725
[Epoch 111] ogbg-molclintox: 0.876310 test loss: 0.221500
[Epoch 112; Iter    30/   40] train: loss: 0.0043235
[Epoch 112] ogbg-molclintox: 0.922880 val loss: 0.124483
[Epoch 112] ogbg-molclintox: 0.872164 test loss: 0.761253
[Epoch 113; Iter    20/   40] train: loss: 0.0176600
[Epoch 113] ogbg-molclintox: 0.926738 val loss: 0.128548
[Epoch 113] ogbg-molclintox: 0.880908 test loss: 0.581411
[Epoch 114; Iter    10/   40] train: loss: 0.0004944
[Epoch 114; Iter    40/   40] train: loss: 0.0002912
[Epoch 114] ogbg-molclintox: 0.944558 val loss: 0.126624
[Epoch 114] ogbg-molclintox: 0.873625 test loss: 0.516222
[Epoch 115; Iter    30/   40] train: loss: 0.0006052
[Epoch 115] ogbg-molclintox: 0.942323 val loss: 0.126219
[Epoch 115] ogbg-molclintox: 0.876123 test loss: 0.850092
[Epoch 116; Iter    20/   40] train: loss: 0.0037193
[Epoch 116] ogbg-molclintox: 0.940925 val loss: 0.135285
[Epoch 116] ogbg-molclintox: 0.876885 test loss: 0.399671
[Epoch 117; Iter    10/   40] train: loss: 0.0005215
[Epoch 117; Iter    40/   40] train: loss: 0.0003237
[Epoch 117] ogbg-molclintox: 0.952613 val loss: 0.129957
[Epoch 117] ogbg-molclintox: 0.873113 test loss: 1.191887
[Epoch 118; Iter    30/   40] train: loss: 0.0007346
[Epoch 118] ogbg-molclintox: 0.942798 val loss: 0.129590
[Epoch 118] ogbg-molclintox: 0.874312 test loss: 0.366951
[Epoch 119; Iter    20/   40] train: loss: 0.0006139
[Epoch 119] ogbg-molclintox: 0.933507 val loss: 0.135139
[Epoch 119] ogbg-molclintox: 0.880109 test loss: 0.525773
[Epoch 120; Iter    10/   40] train: loss: 0.0003631
[Epoch 120; Iter    40/   40] train: loss: 0.0001950
[Epoch 120] ogbg-molclintox: 0.951439 val loss: 0.129059
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.880146 test loss: 1.053011
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 59.
Statistics on  val_best_checkpoint
mean_pred: 0.11814708262681961
std_pred: 7.969195365905762
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.8382025671190199
rocauc: 0.9811820808299682
ogbg-molclintox: 0.9811820808299682
OGBNanLabelBCEWithLogitsLoss: 0.12722363276407123
Statistics on  test
mean_pred: -0.21043120324611664
std_pred: 10.519033432006836
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6675730957386252
rocauc: 0.8690108782539187
ogbg-molclintox: 0.8690108782539187
OGBNanLabelBCEWithLogitsLoss: 1.3979510545730591
Statistics on  train
mean_pred: 0.2516159415245056
std_pred: 6.832364082336426
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9968634414317605
rocauc: 0.9996460721715072
ogbg-molclintox: 0.9996460721715072
OGBNanLabelBCEWithLogitsLoss: 0.01831738803884946
[Epoch 76] ogbg-molclintox: 0.893112 val loss: 0.282931
[Epoch 76] ogbg-molclintox: 0.712499 test loss: 0.885058
[Epoch 77; Iter    20/   40] train: loss: 0.0025505
[Epoch 77] ogbg-molclintox: 0.955308 val loss: 0.082087
[Epoch 77] ogbg-molclintox: 0.790783 test loss: 0.526568
[Epoch 78; Iter    10/   40] train: loss: 0.0155989
[Epoch 78; Iter    40/   40] train: loss: 0.2461827
[Epoch 78] ogbg-molclintox: 0.956745 val loss: 0.178342
[Epoch 78] ogbg-molclintox: 0.792045 test loss: 1.239427
[Epoch 79; Iter    30/   40] train: loss: 0.2058229
[Epoch 79] ogbg-molclintox: 0.905025 val loss: 0.127524
[Epoch 79] ogbg-molclintox: 0.799168 test loss: 1.045178
[Epoch 80; Iter    20/   40] train: loss: 0.0132119
[Epoch 80] ogbg-molclintox: 0.902252 val loss: 0.400343
[Epoch 80] ogbg-molclintox: 0.735448 test loss: 1.316863
[Epoch 81; Iter    10/   40] train: loss: 0.0149030
[Epoch 81; Iter    40/   40] train: loss: 0.0023658
[Epoch 81] ogbg-molclintox: 0.867414 val loss: 0.312650
[Epoch 81] ogbg-molclintox: 0.778434 test loss: 0.811088
[Epoch 82; Iter    30/   40] train: loss: 0.0111401
[Epoch 82] ogbg-molclintox: 0.889879 val loss: 5.185041
[Epoch 82] ogbg-molclintox: 0.791436 test loss: 2.630564
[Epoch 83; Iter    20/   40] train: loss: 0.0284918
[Epoch 83] ogbg-molclintox: 0.792592 val loss: 0.255286
[Epoch 83] ogbg-molclintox: 0.742119 test loss: 1.627855
[Epoch 84; Iter    10/   40] train: loss: 0.0043431
[Epoch 84; Iter    40/   40] train: loss: 0.1653347
[Epoch 84] ogbg-molclintox: 0.907597 val loss: 0.264651
[Epoch 84] ogbg-molclintox: 0.766900 test loss: 0.818090
[Epoch 85; Iter    30/   40] train: loss: 0.0053424
[Epoch 85] ogbg-molclintox: 0.923168 val loss: 1.151296
[Epoch 85] ogbg-molclintox: 0.751898 test loss: 2.007389
[Epoch 86; Iter    20/   40] train: loss: 0.0104066
[Epoch 86] ogbg-molclintox: 0.930773 val loss: 0.269505
[Epoch 86] ogbg-molclintox: 0.761692 test loss: 0.918544
[Epoch 87; Iter    10/   40] train: loss: 0.0121174
[Epoch 87; Iter    40/   40] train: loss: 0.0072296
[Epoch 87] ogbg-molclintox: 0.919672 val loss: 0.557657
[Epoch 87] ogbg-molclintox: 0.738997 test loss: 1.504849
[Epoch 88; Iter    30/   40] train: loss: 0.0195512
[Epoch 88] ogbg-molclintox: 0.827954 val loss: 0.147965
[Epoch 88] ogbg-molclintox: 0.762917 test loss: 0.528174
[Epoch 89; Iter    20/   40] train: loss: 0.0123318
[Epoch 89] ogbg-molclintox: 0.827118 val loss: 0.316847
[Epoch 89] ogbg-molclintox: 0.746505 test loss: 1.163855
[Epoch 90; Iter    10/   40] train: loss: 0.0049615
[Epoch 90; Iter    40/   40] train: loss: 0.0007743
[Epoch 90] ogbg-molclintox: 0.827142 val loss: 0.450241
[Epoch 90] ogbg-molclintox: 0.754162 test loss: 1.478075
[Epoch 91; Iter    30/   40] train: loss: 0.0019399
[Epoch 91] ogbg-molclintox: 0.790093 val loss: 0.178385
[Epoch 91] ogbg-molclintox: 0.763956 test loss: 0.568840
[Epoch 92; Iter    20/   40] train: loss: 0.0123013
[Epoch 92] ogbg-molclintox: 0.838268 val loss: 0.340751
[Epoch 92] ogbg-molclintox: 0.764968 test loss: 1.114670
[Epoch 93; Iter    10/   40] train: loss: 0.0028894
[Epoch 93; Iter    40/   40] train: loss: 0.0022538
[Epoch 93] ogbg-molclintox: 0.826042 val loss: 0.392450
[Epoch 93] ogbg-molclintox: 0.777746 test loss: 1.277021
[Epoch 94; Iter    30/   40] train: loss: 0.0008021
[Epoch 94] ogbg-molclintox: 0.810109 val loss: 0.163558
[Epoch 94] ogbg-molclintox: 0.781045 test loss: 0.540444
[Epoch 95; Iter    20/   40] train: loss: 0.0019323
[Epoch 95] ogbg-molclintox: 0.797736 val loss: 0.806184
[Epoch 95] ogbg-molclintox: 0.759821 test loss: 1.638499
[Epoch 96; Iter    10/   40] train: loss: 0.0149231
[Epoch 96; Iter    40/   40] train: loss: 0.0026464
[Epoch 96] ogbg-molclintox: 0.794015 val loss: 0.215833
[Epoch 96] ogbg-molclintox: 0.767041 test loss: 0.765273
[Epoch 97; Iter    30/   40] train: loss: 0.0009690
[Epoch 97] ogbg-molclintox: 0.773935 val loss: 0.850380
[Epoch 97] ogbg-molclintox: 0.745156 test loss: 1.605149
[Epoch 98; Iter    20/   40] train: loss: 0.0006531
[Epoch 98] ogbg-molclintox: 0.815929 val loss: 0.193716
[Epoch 98] ogbg-molclintox: 0.780780 test loss: 0.698494
[Epoch 99; Iter    10/   40] train: loss: 0.0043854
[Epoch 99; Iter    40/   40] train: loss: 0.0008212
[Epoch 99] ogbg-molclintox: 0.799659 val loss: 0.282129
[Epoch 99] ogbg-molclintox: 0.760870 test loss: 0.932949
[Epoch 100; Iter    30/   40] train: loss: 0.0005055
[Epoch 100] ogbg-molclintox: 0.770214 val loss: 0.299177
[Epoch 100] ogbg-molclintox: 0.750916 test loss: 0.839927
[Epoch 101; Iter    20/   40] train: loss: 0.0016631
[Epoch 101] ogbg-molclintox: 0.800021 val loss: 0.233656
[Epoch 101] ogbg-molclintox: 0.781545 test loss: 0.738416
[Epoch 102; Iter    10/   40] train: loss: 0.0009306
[Epoch 102; Iter    40/   40] train: loss: 0.0028099
[Epoch 102] ogbg-molclintox: 0.814618 val loss: 0.414767
[Epoch 102] ogbg-molclintox: 0.776510 test loss: 1.172113
[Epoch 103; Iter    30/   40] train: loss: 0.0004744
[Epoch 103] ogbg-molclintox: 0.836771 val loss: 0.337165
[Epoch 103] ogbg-molclintox: 0.789501 test loss: 1.141710
[Epoch 104; Iter    20/   40] train: loss: 0.0003591
[Epoch 104] ogbg-molclintox: 0.847060 val loss: 0.171810
[Epoch 104] ogbg-molclintox: 0.787440 test loss: 0.507667
[Epoch 105; Iter    10/   40] train: loss: 0.0013377
[Epoch 105; Iter    40/   40] train: loss: 0.0015756
[Epoch 105] ogbg-molclintox: 0.812207 val loss: 0.376874
[Epoch 105] ogbg-molclintox: 0.781243 test loss: 1.072845
[Epoch 106; Iter    30/   40] train: loss: 0.0013468
[Epoch 106] ogbg-molclintox: 0.834248 val loss: 0.602912
[Epoch 106] ogbg-molclintox: 0.776697 test loss: 1.431333
[Epoch 107; Iter    20/   40] train: loss: 0.0003893
[Epoch 107] ogbg-molclintox: 0.809660 val loss: 0.405304
[Epoch 107] ogbg-molclintox: 0.784604 test loss: 1.103445
[Epoch 108; Iter    10/   40] train: loss: 0.0004524
[Epoch 108; Iter    40/   40] train: loss: 0.0033944
[Epoch 108] ogbg-molclintox: 0.802617 val loss: 0.190718
[Epoch 108] ogbg-molclintox: 0.770052 test loss: 0.640787
[Epoch 109; Iter    30/   40] train: loss: 0.0017424
[Epoch 109] ogbg-molclintox: 0.817904 val loss: 0.600506
[Epoch 109] ogbg-molclintox: 0.757647 test loss: 1.297899
[Epoch 110; Iter    20/   40] train: loss: 0.0005407
[Epoch 110] ogbg-molclintox: 0.815616 val loss: 0.292325
[Epoch 110] ogbg-molclintox: 0.734828 test loss: 1.341818
[Epoch 111; Iter    10/   40] train: loss: 0.0008217
[Epoch 111; Iter    40/   40] train: loss: 0.0001997
[Epoch 111] ogbg-molclintox: 0.823994 val loss: 0.177324
[Epoch 111] ogbg-molclintox: 0.769054 test loss: 0.761237
[Epoch 112; Iter    30/   40] train: loss: 0.0032433
[Epoch 112] ogbg-molclintox: 0.831124 val loss: 0.175030
[Epoch 112] ogbg-molclintox: 0.787029 test loss: 0.770396
[Epoch 113; Iter    20/   40] train: loss: 0.0010770
[Epoch 113] ogbg-molclintox: 0.820023 val loss: 0.168152
[Epoch 113] ogbg-molclintox: 0.777885 test loss: 0.496160
[Epoch 114; Iter    10/   40] train: loss: 0.0019095
[Epoch 114; Iter    40/   40] train: loss: 0.0029900
[Epoch 114] ogbg-molclintox: 0.826454 val loss: 0.172771
[Epoch 114] ogbg-molclintox: 0.788990 test loss: 0.669099
[Epoch 115; Iter    30/   40] train: loss: 0.0012100
[Epoch 115] ogbg-molclintox: 0.842313 val loss: 0.153299
[Epoch 115] ogbg-molclintox: 0.785228 test loss: 0.638236
[Epoch 116; Iter    20/   40] train: loss: 0.0003130
[Epoch 116] ogbg-molclintox: 0.821084 val loss: 0.169610
[Epoch 116] ogbg-molclintox: 0.774687 test loss: 0.599977
[Epoch 117; Iter    10/   40] train: loss: 0.0004322
[Epoch 117; Iter    40/   40] train: loss: 0.0595619
[Epoch 117] ogbg-molclintox: 0.807161 val loss: 0.186096
[Epoch 117] ogbg-molclintox: 0.737510 test loss: 0.531774
[Epoch 118; Iter    30/   40] train: loss: 0.0005551
[Epoch 118] ogbg-molclintox: 0.778068 val loss: 0.372142
[Epoch 118] ogbg-molclintox: 0.712002 test loss: 1.166800
[Epoch 119; Iter    20/   40] train: loss: 0.0009774
[Epoch 119] ogbg-molclintox: 0.798559 val loss: 0.179597
[Epoch 119] ogbg-molclintox: 0.746990 test loss: 0.701248
[Epoch 120; Iter    10/   40] train: loss: 0.0082243
[Epoch 120; Iter    40/   40] train: loss: 0.0004657
[Epoch 120] ogbg-molclintox: 0.788245 val loss: 0.281014
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.749814 test loss: 0.914619
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 58.
Statistics on  val_best_checkpoint
mean_pred: 0.2829362452030182
std_pred: 6.166508674621582
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.8335833160267152
rocauc: 0.9767121376276306
ogbg-molclintox: 0.9767121376276306
OGBNanLabelBCEWithLogitsLoss: 0.1296955280471593
Statistics on  test
mean_pred: 0.1717216819524765
std_pred: 6.391592025756836
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6125690132281888
rocauc: 0.8011408264692593
ogbg-molclintox: 0.8011408264692593
OGBNanLabelBCEWithLogitsLoss: 1.0288349568843842
Statistics on  train
mean_pred: 0.1852634996175766
std_pred: 6.289520740509033
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.99552217480375
rocauc: 0.9990370348279947
ogbg-molclintox: 0.9990370348279947
OGBNanLabelBCEWithLogitsLoss: 0.030786290927790106
[Epoch 76] ogbg-molclintox: 0.907474 val loss: 0.448463
[Epoch 76] ogbg-molclintox: 0.743898 test loss: 2.823089
[Epoch 77; Iter    20/   40] train: loss: 0.0041767
[Epoch 77] ogbg-molclintox: 0.932322 val loss: 0.195944
[Epoch 77] ogbg-molclintox: 0.758802 test loss: 2.723028
[Epoch 78; Iter    10/   40] train: loss: 0.0210840
[Epoch 78; Iter    40/   40] train: loss: 0.0126962
[Epoch 78] ogbg-molclintox: 0.921059 val loss: 0.314052
[Epoch 78] ogbg-molclintox: 0.759138 test loss: 2.199357
[Epoch 79; Iter    30/   40] train: loss: 0.0014615
[Epoch 79] ogbg-molclintox: 0.920135 val loss: 0.214725
[Epoch 79] ogbg-molclintox: 0.763923 test loss: 2.156620
[Epoch 80; Iter    20/   40] train: loss: 0.0318738
[Epoch 80] ogbg-molclintox: 0.924718 val loss: 0.198453
[Epoch 80] ogbg-molclintox: 0.763161 test loss: 2.787200
[Epoch 81; Iter    10/   40] train: loss: 0.0016415
[Epoch 81; Iter    40/   40] train: loss: 0.0081948
[Epoch 81] ogbg-molclintox: 0.922145 val loss: 0.267217
[Epoch 81] ogbg-molclintox: 0.768308 test loss: 2.798732
[Epoch 82; Iter    30/   40] train: loss: 0.0217667
[Epoch 82] ogbg-molclintox: 0.905738 val loss: 0.268533
[Epoch 82] ogbg-molclintox: 0.738852 test loss: 2.438265
[Epoch 83; Iter    20/   40] train: loss: 0.0011531
[Epoch 83] ogbg-molclintox: 0.914341 val loss: 0.266652
[Epoch 83] ogbg-molclintox: 0.761226 test loss: 2.968089
[Epoch 84; Iter    10/   40] train: loss: 0.0175061
[Epoch 84; Iter    40/   40] train: loss: 0.0234099
[Epoch 84] ogbg-molclintox: 0.932083 val loss: 0.134324
[Epoch 84] ogbg-molclintox: 0.772256 test loss: 2.960138
[Epoch 85; Iter    30/   40] train: loss: 0.0035580
[Epoch 85] ogbg-molclintox: 0.932234 val loss: 0.289190
[Epoch 85] ogbg-molclintox: 0.764322 test loss: 3.112293
[Epoch 86; Iter    20/   40] train: loss: 0.0012220
[Epoch 86] ogbg-molclintox: 0.923319 val loss: 0.211340
[Epoch 86] ogbg-molclintox: 0.744111 test loss: 2.384334
[Epoch 87; Iter    10/   40] train: loss: 0.0019683
[Epoch 87; Iter    40/   40] train: loss: 0.0036408
[Epoch 87] ogbg-molclintox: 0.931760 val loss: 0.232125
[Epoch 87] ogbg-molclintox: 0.748358 test loss: 2.730346
[Epoch 88; Iter    30/   40] train: loss: 0.0044191
[Epoch 88] ogbg-molclintox: 0.936817 val loss: 0.149112
[Epoch 88] ogbg-molclintox: 0.757916 test loss: 2.616016
[Epoch 89; Iter    20/   40] train: loss: 0.0018968
[Epoch 89] ogbg-molclintox: 0.916438 val loss: 0.209564
[Epoch 89] ogbg-molclintox: 0.737903 test loss: 1.694859
[Epoch 90; Iter    10/   40] train: loss: 0.0078690
[Epoch 90; Iter    40/   40] train: loss: 0.0008419
[Epoch 90] ogbg-molclintox: 0.923418 val loss: 0.161846
[Epoch 90] ogbg-molclintox: 0.764236 test loss: 2.262863
[Epoch 91; Iter    30/   40] train: loss: 0.0013359
[Epoch 91] ogbg-molclintox: 0.930186 val loss: 0.193742
[Epoch 91] ogbg-molclintox: 0.764786 test loss: 2.638407
[Epoch 92; Iter    20/   40] train: loss: 0.0021006
[Epoch 92] ogbg-molclintox: 0.926489 val loss: 0.172903
[Epoch 92] ogbg-molclintox: 0.785561 test loss: 2.192830
[Epoch 93; Iter    10/   40] train: loss: 0.0016154
[Epoch 93; Iter    40/   40] train: loss: 0.0062006
[Epoch 93] ogbg-molclintox: 0.936616 val loss: 0.127301
[Epoch 93] ogbg-molclintox: 0.775491 test loss: 2.063194
[Epoch 94; Iter    30/   40] train: loss: 0.0006646
[Epoch 94] ogbg-molclintox: 0.934406 val loss: 0.170661
[Epoch 94] ogbg-molclintox: 0.773242 test loss: 2.141471
[Epoch 95; Iter    20/   40] train: loss: 0.0020508
[Epoch 95] ogbg-molclintox: 0.923418 val loss: 0.194537
[Epoch 95] ogbg-molclintox: 0.783962 test loss: 1.679967
[Epoch 96; Iter    10/   40] train: loss: 0.0014478
[Epoch 96; Iter    40/   40] train: loss: 0.0031017
[Epoch 96] ogbg-molclintox: 0.903563 val loss: 0.181811
[Epoch 96] ogbg-molclintox: 0.734530 test loss: 2.159775
[Epoch 97; Iter    30/   40] train: loss: 0.0042768
[Epoch 97] ogbg-molclintox: 0.927090 val loss: 0.219434
[Epoch 97] ogbg-molclintox: 0.745597 test loss: 2.368316
[Epoch 98; Iter    20/   40] train: loss: 0.0010945
[Epoch 98] ogbg-molclintox: 0.929662 val loss: 0.219377
[Epoch 98] ogbg-molclintox: 0.740588 test loss: 2.036744
[Epoch 99; Iter    10/   40] train: loss: 0.0035926
[Epoch 99; Iter    40/   40] train: loss: 0.0030335
[Epoch 99] ogbg-molclintox: 0.926503 val loss: 0.235459
[Epoch 99] ogbg-molclintox: 0.751245 test loss: 2.315286
[Epoch 100; Iter    30/   40] train: loss: 0.0046055
[Epoch 100] ogbg-molclintox: 0.926004 val loss: 0.255516
[Epoch 100] ogbg-molclintox: 0.733618 test loss: 2.838758
[Epoch 101; Iter    20/   40] train: loss: 0.0009292
[Epoch 101] ogbg-molclintox: 0.925666 val loss: 0.227087
[Epoch 101] ogbg-molclintox: 0.724549 test loss: 2.537787
[Epoch 102; Iter    10/   40] train: loss: 0.0135821
[Epoch 102; Iter    40/   40] train: loss: 0.0060595
[Epoch 102] ogbg-molclintox: 0.940788 val loss: 0.178775
[Epoch 102] ogbg-molclintox: 0.751746 test loss: 2.428640
[Epoch 103; Iter    30/   40] train: loss: 0.0019240
[Epoch 103] ogbg-molclintox: 0.942074 val loss: 0.211199
[Epoch 103] ogbg-molclintox: 0.751208 test loss: 2.295809
[Epoch 104; Iter    20/   40] train: loss: 0.0085950
[Epoch 104] ogbg-molclintox: 0.943722 val loss: 0.187817
[Epoch 104] ogbg-molclintox: 0.758391 test loss: 2.272377
[Epoch 105; Iter    10/   40] train: loss: 0.0011256
[Epoch 105; Iter    40/   40] train: loss: 0.0027464
[Epoch 105] ogbg-molclintox: 0.948480 val loss: 0.253933
[Epoch 105] ogbg-molclintox: 0.754767 test loss: 2.193369
[Epoch 106; Iter    30/   40] train: loss: 0.0006240
[Epoch 106] ogbg-molclintox: 0.952338 val loss: 0.190865
[Epoch 106] ogbg-molclintox: 0.750446 test loss: 2.120432
[Epoch 107; Iter    20/   40] train: loss: 0.0013489
[Epoch 107] ogbg-molclintox: 0.951052 val loss: 0.239339
[Epoch 107] ogbg-molclintox: 0.748421 test loss: 2.216557
[Epoch 108; Iter    10/   40] train: loss: 0.0006742
[Epoch 108; Iter    40/   40] train: loss: 0.0049885
[Epoch 108] ogbg-molclintox: 0.954549 val loss: 0.178881
[Epoch 108] ogbg-molclintox: 0.751645 test loss: 2.294266
[Epoch 109; Iter    30/   40] train: loss: 0.0011857
[Epoch 109] ogbg-molclintox: 0.956309 val loss: 0.153581
[Epoch 109] ogbg-molclintox: 0.740241 test loss: 2.564072
[Epoch 110; Iter    20/   40] train: loss: 0.0048015
[Epoch 110] ogbg-molclintox: 0.951614 val loss: 0.231378
[Epoch 110] ogbg-molclintox: 0.744525 test loss: 2.189199
[Epoch 111; Iter    10/   40] train: loss: 0.0018955
[Epoch 111; Iter    40/   40] train: loss: 0.0207255
[Epoch 111] ogbg-molclintox: 0.951727 val loss: 0.204384
[Epoch 111] ogbg-molclintox: 0.739016 test loss: 2.287568
[Epoch 112; Iter    30/   40] train: loss: 0.0523902
[Epoch 112] ogbg-molclintox: 0.948680 val loss: 0.312925
[Epoch 112] ogbg-molclintox: 0.748059 test loss: 2.303886
[Epoch 113; Iter    20/   40] train: loss: 0.0004217
[Epoch 113] ogbg-molclintox: 0.957820 val loss: 0.171509
[Epoch 113] ogbg-molclintox: 0.745261 test loss: 2.326450
[Epoch 114; Iter    10/   40] train: loss: 0.0087763
[Epoch 114; Iter    40/   40] train: loss: 0.0009035
[Epoch 114] ogbg-molclintox: 0.950177 val loss: 0.192825
[Epoch 114] ogbg-molclintox: 0.760841 test loss: 2.530992
[Epoch 115; Iter    30/   40] train: loss: 0.0007171
[Epoch 115] ogbg-molclintox: 0.950940 val loss: 0.234801
[Epoch 115] ogbg-molclintox: 0.745724 test loss: 2.623659
[Epoch 116; Iter    20/   40] train: loss: 0.0113067
[Epoch 116] ogbg-molclintox: 0.945370 val loss: 0.196553
[Epoch 116] ogbg-molclintox: 0.743125 test loss: 2.597744
[Epoch 117; Iter    10/   40] train: loss: 0.0159233
[Epoch 117; Iter    40/   40] train: loss: 0.0005598
[Epoch 117] ogbg-molclintox: 0.958544 val loss: 0.206730
[Epoch 117] ogbg-molclintox: 0.749546 test loss: 2.319247
[Epoch 118; Iter    30/   40] train: loss: 0.0015503
[Epoch 118] ogbg-molclintox: 0.954436 val loss: 0.266353
[Epoch 118] ogbg-molclintox: 0.755092 test loss: 1.631344
[Epoch 119; Iter    20/   40] train: loss: 0.0033094
[Epoch 119] ogbg-molclintox: 0.945995 val loss: 0.309011
[Epoch 119] ogbg-molclintox: 0.723787 test loss: 1.841758
[Epoch 120; Iter    10/   40] train: loss: 0.0011716
[Epoch 120; Iter    40/   40] train: loss: 0.0004142
[Epoch 120] ogbg-molclintox: 0.954549 val loss: 0.246714
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.732094 test loss: 2.385732
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: 0.22282755374908447
std_pred: 6.485463619232178
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.8631391425540054
rocauc: 0.9696945073705637
ogbg-molclintox: 0.9696945073705637
OGBNanLabelBCEWithLogitsLoss: 0.07707735722651705
Statistics on  test
mean_pred: 0.20160143077373505
std_pred: 5.705410003662109
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6606119830351038
rocauc: 0.8713568275814131
ogbg-molclintox: 0.8713568275814131
OGBNanLabelBCEWithLogitsLoss: 0.46625992804765704
Statistics on  train
mean_pred: 0.2235002964735031
std_pred: 5.115222454071045
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9594199864914313
rocauc: 0.9862884652410671
ogbg-molclintox: 0.9862884652410671
OGBNanLabelBCEWithLogitsLoss: 0.08954924270510674
[Epoch 76] ogbg-molclintox: 0.990660 val loss: 0.052483
[Epoch 76] ogbg-molclintox: 0.793218 test loss: 0.336754
[Epoch 77; Iter    20/   40] train: loss: 0.0014158
[Epoch 77] ogbg-molclintox: 0.992396 val loss: 0.052044
[Epoch 77] ogbg-molclintox: 0.815242 test loss: 0.385510
[Epoch 78; Iter    10/   40] train: loss: 0.0012931
[Epoch 78; Iter    40/   40] train: loss: 0.0008293
[Epoch 78] ogbg-molclintox: 0.994156 val loss: 0.051429
[Epoch 78] ogbg-molclintox: 0.814256 test loss: 0.367157
[Epoch 79; Iter    30/   40] train: loss: 0.0106425
[Epoch 79] ogbg-molclintox: 0.996029 val loss: 0.041272
[Epoch 79] ogbg-molclintox: 0.823112 test loss: 0.402657
[Epoch 80; Iter    20/   40] train: loss: 0.0011637
[Epoch 80] ogbg-molclintox: 0.991696 val loss: 0.049521
[Epoch 80] ogbg-molclintox: 0.791396 test loss: 0.395629
[Epoch 81; Iter    10/   40] train: loss: 0.0057136
[Epoch 81; Iter    40/   40] train: loss: 0.0013031
[Epoch 81] ogbg-molclintox: 0.991134 val loss: 0.157840
[Epoch 81] ogbg-molclintox: 0.838490 test loss: 0.534793
[Epoch 82; Iter    30/   40] train: loss: 0.0025829
[Epoch 82] ogbg-molclintox: 0.992396 val loss: 0.079971
[Epoch 82] ogbg-molclintox: 0.829484 test loss: 0.382171
[Epoch 83; Iter    20/   40] train: loss: 0.0086905
[Epoch 83] ogbg-molclintox: 0.978336 val loss: 0.066762
[Epoch 83] ogbg-molclintox: 0.821177 test loss: 0.349315
[Epoch 84; Iter    10/   40] train: loss: 0.0009273
[Epoch 84; Iter    40/   40] train: loss: 0.0062317
[Epoch 84] ogbg-molclintox: 0.978810 val loss: 0.077393
[Epoch 84] ogbg-molclintox: 0.825286 test loss: 0.442122
[Epoch 85; Iter    30/   40] train: loss: 0.0008645
[Epoch 85] ogbg-molclintox: 0.993095 val loss: 0.055505
[Epoch 85] ogbg-molclintox: 0.846159 test loss: 0.387481
[Epoch 86; Iter    20/   40] train: loss: 0.0020441
[Epoch 86] ogbg-molclintox: 0.993682 val loss: 0.059604
[Epoch 86] ogbg-molclintox: 0.838789 test loss: 0.416636
[Epoch 87; Iter    10/   40] train: loss: 0.0010471
[Epoch 87; Iter    40/   40] train: loss: 0.0042718
[Epoch 87] ogbg-molclintox: 0.996029 val loss: 0.043448
[Epoch 87] ogbg-molclintox: 0.824711 test loss: 0.394699
[Epoch 88; Iter    30/   40] train: loss: 0.0060106
[Epoch 88] ogbg-molclintox: 0.989236 val loss: 0.058170
[Epoch 88] ogbg-molclintox: 0.841650 test loss: 0.419348
[Epoch 89; Iter    20/   40] train: loss: 0.0026414
[Epoch 89] ogbg-molclintox: 0.989711 val loss: 0.068883
[Epoch 89] ogbg-molclintox: 0.869284 test loss: 0.392031
[Epoch 90; Iter    10/   40] train: loss: 0.0086901
[Epoch 90; Iter    40/   40] train: loss: 0.0005923
[Epoch 90] ogbg-molclintox: 0.969058 val loss: 0.087763
[Epoch 90] ogbg-molclintox: 0.856591 test loss: 0.313294
[Epoch 91; Iter    30/   40] train: loss: 0.0026136
[Epoch 91] ogbg-molclintox: 0.980209 val loss: 0.068204
[Epoch 91] ogbg-molclintox: 0.868047 test loss: 0.338930
[Epoch 92; Iter    20/   40] train: loss: 0.0009710
[Epoch 92] ogbg-molclintox: 0.984903 val loss: 0.073510
[Epoch 92] ogbg-molclintox: 0.853730 test loss: 0.356813
[Epoch 93; Iter    10/   40] train: loss: 0.0012232
[Epoch 93; Iter    40/   40] train: loss: 0.0056840
[Epoch 93] ogbg-molclintox: 0.987838 val loss: 0.067033
[Epoch 93] ogbg-molclintox: 0.851594 test loss: 0.425306
[Epoch 94; Iter    30/   40] train: loss: 0.0021174
[Epoch 94] ogbg-molclintox: 0.995105 val loss: 0.133666
[Epoch 94] ogbg-molclintox: 0.795617 test loss: 0.554129
[Epoch 95; Iter    20/   40] train: loss: 0.0005652
[Epoch 95] ogbg-molclintox: 0.996503 val loss: 0.052422
[Epoch 95] ogbg-molclintox: 0.796304 test loss: 0.422830
[Epoch 96; Iter    10/   40] train: loss: 0.0011798
[Epoch 96; Iter    40/   40] train: loss: 0.0206530
[Epoch 96] ogbg-molclintox: 0.989036 val loss: 0.132684
[Epoch 96] ogbg-molclintox: 0.786798 test loss: 0.493378
[Epoch 97; Iter    30/   40] train: loss: 0.0033493
[Epoch 97] ogbg-molclintox: 0.995105 val loss: 0.077197
[Epoch 97] ogbg-molclintox: 0.810744 test loss: 0.471121
[Epoch 98; Iter    20/   40] train: loss: 0.0011854
[Epoch 98] ogbg-molclintox: 0.992308 val loss: 0.102350
[Epoch 98] ogbg-molclintox: 0.813792 test loss: 0.477303
[Epoch 99; Iter    10/   40] train: loss: 0.0017607
[Epoch 99; Iter    40/   40] train: loss: 0.0045211
[Epoch 99] ogbg-molclintox: 0.995105 val loss: 0.059981
[Epoch 99] ogbg-molclintox: 0.821412 test loss: 0.435704
[Epoch 100; Iter    30/   40] train: loss: 0.0037881
[Epoch 100] ogbg-molclintox: 0.995105 val loss: 0.073110
[Epoch 100] ogbg-molclintox: 0.821625 test loss: 0.458145
[Epoch 101; Iter    20/   40] train: loss: 0.0005859
[Epoch 101] ogbg-molclintox: 0.995105 val loss: 0.065177
[Epoch 101] ogbg-molclintox: 0.812455 test loss: 0.457962
[Epoch 102; Iter    10/   40] train: loss: 0.0005968
[Epoch 102; Iter    40/   40] train: loss: 0.0016970
[Epoch 102] ogbg-molclintox: 0.993706 val loss: 0.093670
[Epoch 102] ogbg-molclintox: 0.811256 test loss: 0.491201
[Epoch 103; Iter    30/   40] train: loss: 0.0003502
[Epoch 103] ogbg-molclintox: 0.991721 val loss: 0.080493
[Epoch 103] ogbg-molclintox: 0.812567 test loss: 0.458565
[Epoch 104; Iter    20/   40] train: loss: 0.0021569
[Epoch 104] ogbg-molclintox: 0.994406 val loss: 0.069157
[Epoch 104] ogbg-molclintox: 0.819601 test loss: 0.445439
[Epoch 105; Iter    10/   40] train: loss: 0.0033395
[Epoch 105; Iter    40/   40] train: loss: 0.0041581
[Epoch 105] ogbg-molclintox: 0.995105 val loss: 0.076024
[Epoch 105] ogbg-molclintox: 0.812130 test loss: 0.475744
[Epoch 106; Iter    30/   40] train: loss: 0.0010495
[Epoch 106] ogbg-molclintox: 0.993007 val loss: 0.078205
[Epoch 106] ogbg-molclintox: 0.809982 test loss: 0.492730
[Epoch 107; Iter    20/   40] train: loss: 0.0021416
[Epoch 107] ogbg-molclintox: 0.993007 val loss: 0.060739
[Epoch 107] ogbg-molclintox: 0.809295 test loss: 0.480994
[Epoch 108; Iter    10/   40] train: loss: 0.0014305
[Epoch 108; Iter    40/   40] train: loss: 0.0082270
[Epoch 108] ogbg-molclintox: 0.994406 val loss: 0.064587
[Epoch 108] ogbg-molclintox: 0.808208 test loss: 0.535414
[Epoch 109; Iter    30/   40] train: loss: 0.0008687
[Epoch 109] ogbg-molclintox: 0.994630 val loss: 0.047842
[Epoch 109] ogbg-molclintox: 0.803210 test loss: 0.466854
[Epoch 110; Iter    20/   40] train: loss: 0.0008209
[Epoch 110] ogbg-molclintox: 0.996503 val loss: 0.050190
[Epoch 110] ogbg-molclintox: 0.807670 test loss: 0.457397
[Epoch 111; Iter    10/   40] train: loss: 0.0006237
[Epoch 111; Iter    40/   40] train: loss: 0.0013010
[Epoch 111] ogbg-molclintox: 0.996503 val loss: 0.045880
[Epoch 111] ogbg-molclintox: 0.808757 test loss: 0.446417
[Epoch 112; Iter    30/   40] train: loss: 0.0024048
[Epoch 112] ogbg-molclintox: 0.995105 val loss: 0.052822
[Epoch 112] ogbg-molclintox: 0.817939 test loss: 0.474044
[Epoch 113; Iter    20/   40] train: loss: 0.0151381
[Epoch 113] ogbg-molclintox: 0.993119 val loss: 0.089030
[Epoch 113] ogbg-molclintox: 0.826859 test loss: 0.566659
[Epoch 114; Iter    10/   40] train: loss: 0.0004175
[Epoch 114; Iter    40/   40] train: loss: 0.0004633
[Epoch 114] ogbg-molclintox: 0.994518 val loss: 0.060039
[Epoch 114] ogbg-molclintox: 0.821924 test loss: 0.497272
[Epoch 115; Iter    30/   40] train: loss: 0.0002381
[Epoch 115] ogbg-molclintox: 0.991833 val loss: 0.081324
[Epoch 115] ogbg-molclintox: 0.822212 test loss: 0.528811
[Epoch 116; Iter    20/   40] train: loss: 0.0034415
[Epoch 116] ogbg-molclintox: 0.993706 val loss: 0.062496
[Epoch 116] ogbg-molclintox: 0.820438 test loss: 0.477238
[Epoch 117; Iter    10/   40] train: loss: 0.0005372
[Epoch 117; Iter    40/   40] train: loss: 0.0003774
[Epoch 117] ogbg-molclintox: 0.993119 val loss: 0.084197
[Epoch 117] ogbg-molclintox: 0.821412 test loss: 0.522356
[Epoch 118; Iter    30/   40] train: loss: 0.0006021
[Epoch 118] ogbg-molclintox: 0.993232 val loss: 0.064135
[Epoch 118] ogbg-molclintox: 0.820800 test loss: 0.468281
[Epoch 119; Iter    20/   40] train: loss: 0.0004259
[Epoch 119] ogbg-molclintox: 0.995105 val loss: 0.067446
[Epoch 119] ogbg-molclintox: 0.826022 test loss: 0.485867
[Epoch 120; Iter    10/   40] train: loss: 0.0006049
[Epoch 120; Iter    40/   40] train: loss: 0.0001487
[Epoch 120] ogbg-molclintox: 0.994406 val loss: 0.067470
[Epoch 76] ogbg-molclintox: 0.865126 val loss: 0.132611
[Epoch 76] ogbg-molclintox: 0.845146 test loss: 0.243878
[Epoch 77; Iter    20/   40] train: loss: 0.0027100
[Epoch 77] ogbg-molclintox: 0.912327 val loss: 0.135365
[Epoch 77] ogbg-molclintox: 0.892816 test loss: 0.207918
[Epoch 78; Iter    10/   40] train: loss: 0.0170453
[Epoch 78; Iter    40/   40] train: loss: 0.1167884
[Epoch 78] ogbg-molclintox: 0.816603 val loss: 0.188022
[Epoch 78] ogbg-molclintox: 0.788747 test loss: 0.335936
[Epoch 79; Iter    30/   40] train: loss: 0.0372879
[Epoch 79] ogbg-molclintox: 0.860519 val loss: 0.161018
[Epoch 79] ogbg-molclintox: 0.852004 test loss: 0.366681
[Epoch 80; Iter    20/   40] train: loss: 0.0056954
[Epoch 80] ogbg-molclintox: 0.836869 val loss: 0.133252
[Epoch 80] ogbg-molclintox: 0.832431 test loss: 0.312894
[Epoch 81; Iter    10/   40] train: loss: 0.0085673
[Epoch 81; Iter    40/   40] train: loss: 0.0015033
[Epoch 81] ogbg-molclintox: 0.860519 val loss: 0.120424
[Epoch 81] ogbg-molclintox: 0.822798 test loss: 0.332640
[Epoch 82; Iter    30/   40] train: loss: 0.0422459
[Epoch 82] ogbg-molclintox: 0.855487 val loss: 0.128525
[Epoch 82] ogbg-molclintox: 0.829907 test loss: 0.293566
[Epoch 83; Iter    20/   40] train: loss: 0.0067242
[Epoch 83] ogbg-molclintox: 0.852078 val loss: 0.131913
[Epoch 83] ogbg-molclintox: 0.819325 test loss: 0.275287
[Epoch 84; Iter    10/   40] train: loss: 0.0018877
[Epoch 84; Iter    40/   40] train: loss: 0.0234309
[Epoch 84] ogbg-molclintox: 0.864852 val loss: 0.124371
[Epoch 84] ogbg-molclintox: 0.837926 test loss: 0.279267
[Epoch 85; Iter    30/   40] train: loss: 0.0009477
[Epoch 85] ogbg-molclintox: 0.856885 val loss: 0.139692
[Epoch 85] ogbg-molclintox: 0.839237 test loss: 0.273085
[Epoch 86; Iter    20/   40] train: loss: 0.0015226
[Epoch 86] ogbg-molclintox: 0.864739 val loss: 0.130485
[Epoch 86] ogbg-molclintox: 0.847145 test loss: 0.294217
[Epoch 87; Iter    10/   40] train: loss: 0.0018446
[Epoch 87; Iter    40/   40] train: loss: 0.0227960
[Epoch 87] ogbg-molclintox: 0.864989 val loss: 0.139978
[Epoch 87] ogbg-molclintox: 0.844246 test loss: 0.288107
[Epoch 88; Iter    30/   40] train: loss: 0.0101082
[Epoch 88] ogbg-molclintox: 0.858534 val loss: 0.139632
[Epoch 88] ogbg-molclintox: 0.841486 test loss: 0.255941
[Epoch 89; Iter    20/   40] train: loss: 0.0109906
[Epoch 89] ogbg-molclintox: 0.842400 val loss: 0.146390
[Epoch 89] ogbg-molclintox: 0.832917 test loss: 0.281313
[Epoch 90; Iter    10/   40] train: loss: 0.0031026
[Epoch 90; Iter    40/   40] train: loss: 0.0005122
[Epoch 90] ogbg-molclintox: 0.840078 val loss: 0.146762
[Epoch 90] ogbg-molclintox: 0.840250 test loss: 0.286171
[Epoch 91; Iter    30/   40] train: loss: 0.0012316
[Epoch 91] ogbg-molclintox: 0.847882 val loss: 0.158722
[Epoch 91] ogbg-molclintox: 0.832092 test loss: 0.273225
[Epoch 92; Iter    20/   40] train: loss: 0.0375612
[Epoch 92] ogbg-molclintox: 0.851541 val loss: 0.148719
[Epoch 92] ogbg-molclintox: 0.848269 test loss: 0.273229
[Epoch 93; Iter    10/   40] train: loss: 0.0044099
[Epoch 93; Iter    40/   40] train: loss: 0.0087159
[Epoch 93] ogbg-molclintox: 0.854088 val loss: 0.173684
[Epoch 93] ogbg-molclintox: 0.843959 test loss: 0.267040
[Epoch 94; Iter    30/   40] train: loss: 0.0006870
[Epoch 94] ogbg-molclintox: 0.835994 val loss: 0.158335
[Epoch 94] ogbg-molclintox: 0.849842 test loss: 0.253021
[Epoch 95; Iter    20/   40] train: loss: 0.0012486
[Epoch 95] ogbg-molclintox: 0.850616 val loss: 0.152330
[Epoch 95] ogbg-molclintox: 0.834490 test loss: 0.274936
[Epoch 96; Iter    10/   40] train: loss: 0.0062224
[Epoch 96; Iter    40/   40] train: loss: 0.0026616
[Epoch 96] ogbg-molclintox: 0.797610 val loss: 0.167555
[Epoch 96] ogbg-molclintox: 0.833253 test loss: 0.280749
[Epoch 97; Iter    30/   40] train: loss: 0.0008531
[Epoch 97] ogbg-molclintox: 0.806887 val loss: 0.174404
[Epoch 97] ogbg-molclintox: 0.824371 test loss: 0.262495
[Epoch 98; Iter    20/   40] train: loss: 0.0005373
[Epoch 98] ogbg-molclintox: 0.844822 val loss: 0.159116
[Epoch 98] ogbg-molclintox: 0.820411 test loss: 0.277019
[Epoch 99; Iter    10/   40] train: loss: 0.0027825
[Epoch 99; Iter    40/   40] train: loss: 0.0009506
[Epoch 99] ogbg-molclintox: 0.841800 val loss: 0.157655
[Epoch 99] ogbg-molclintox: 0.813527 test loss: 0.288046
[Epoch 100; Iter    30/   40] train: loss: 0.0005210
[Epoch 100] ogbg-molclintox: 0.848431 val loss: 0.159928
[Epoch 100] ogbg-molclintox: 0.840336 test loss: 0.271944
[Epoch 101; Iter    20/   40] train: loss: 0.0012648
[Epoch 101] ogbg-molclintox: 0.845721 val loss: 0.165624
[Epoch 101] ogbg-molclintox: 0.829817 test loss: 0.279392
[Epoch 102; Iter    10/   40] train: loss: 0.0008010
[Epoch 102; Iter    40/   40] train: loss: 0.0061462
[Epoch 102] ogbg-molclintox: 0.831960 val loss: 0.184865
[Epoch 102] ogbg-molclintox: 0.849943 test loss: 0.270420
[Epoch 103; Iter    30/   40] train: loss: 0.0005510
[Epoch 103] ogbg-molclintox: 0.828102 val loss: 0.175534
[Epoch 103] ogbg-molclintox: 0.859998 test loss: 0.260819
[Epoch 104; Iter    20/   40] train: loss: 0.0005995
[Epoch 104] ogbg-molclintox: 0.835706 val loss: 0.166486
[Epoch 104] ogbg-molclintox: 0.838961 test loss: 0.266504
[Epoch 105; Iter    10/   40] train: loss: 0.0010615
[Epoch 105; Iter    40/   40] train: loss: 0.0051113
[Epoch 105] ogbg-molclintox: 0.843536 val loss: 0.173085
[Epoch 105] ogbg-molclintox: 0.848856 test loss: 0.286000
[Epoch 106; Iter    30/   40] train: loss: 0.0011793
[Epoch 106] ogbg-molclintox: 0.847394 val loss: 0.159127
[Epoch 106] ogbg-molclintox: 0.858112 test loss: 0.278503
[Epoch 107; Iter    20/   40] train: loss: 0.0007353
[Epoch 107] ogbg-molclintox: 0.843536 val loss: 0.155976
[Epoch 107] ogbg-molclintox: 0.852890 test loss: 0.262498
[Epoch 108; Iter    10/   40] train: loss: 0.0004979
[Epoch 108; Iter    40/   40] train: loss: 0.0018760
[Epoch 108] ogbg-molclintox: 0.834782 val loss: 0.163022
[Epoch 108] ogbg-molclintox: 0.837288 test loss: 0.286896
[Epoch 109; Iter    30/   40] train: loss: 0.0010770
[Epoch 109] ogbg-molclintox: 0.843086 val loss: 0.170431
[Epoch 109] ogbg-molclintox: 0.839099 test loss: 0.292816
[Epoch 110; Iter    20/   40] train: loss: 0.0007775
[Epoch 110] ogbg-molclintox: 0.840738 val loss: 0.159820
[Epoch 110] ogbg-molclintox: 0.838812 test loss: 0.289392
[Epoch 111; Iter    10/   40] train: loss: 0.0012657
[Epoch 111; Iter    40/   40] train: loss: 0.0003892
[Epoch 111] ogbg-molclintox: 0.846108 val loss: 0.163596
[Epoch 111] ogbg-molclintox: 0.848393 test loss: 0.285537
[Epoch 112; Iter    30/   40] train: loss: 0.0004635
[Epoch 112] ogbg-molclintox: 0.845296 val loss: 0.167387
[Epoch 112] ogbg-molclintox: 0.841423 test loss: 0.302906
[Epoch 113; Iter    20/   40] train: loss: 0.0007902
[Epoch 113] ogbg-molclintox: 0.839902 val loss: 0.164291
[Epoch 113] ogbg-molclintox: 0.838412 test loss: 0.285797
[Epoch 114; Iter    10/   40] train: loss: 0.0007146
[Epoch 114; Iter    40/   40] train: loss: 0.0014111
[Epoch 114] ogbg-molclintox: 0.845721 val loss: 0.170552
[Epoch 114] ogbg-molclintox: 0.847294 test loss: 0.279380
[Epoch 115; Iter    30/   40] train: loss: 0.0049392
[Epoch 115] ogbg-molclintox: 0.838004 val loss: 0.168434
[Epoch 115] ogbg-molclintox: 0.849330 test loss: 0.282387
[Epoch 116; Iter    20/   40] train: loss: 0.0004242
[Epoch 116] ogbg-molclintox: 0.836630 val loss: 0.174333
[Epoch 116] ogbg-molclintox: 0.845046 test loss: 0.293772
[Epoch 117; Iter    10/   40] train: loss: 0.0002738
[Epoch 117; Iter    40/   40] train: loss: 0.0022413
[Epoch 117] ogbg-molclintox: 0.838029 val loss: 0.169980
[Epoch 117] ogbg-molclintox: 0.837687 test loss: 0.299033
[Epoch 118; Iter    30/   40] train: loss: 0.0002305
[Epoch 118] ogbg-molclintox: 0.829725 val loss: 0.168031
[Epoch 118] ogbg-molclintox: 0.841598 test loss: 0.284904
[Epoch 119; Iter    20/   40] train: loss: 0.0003158
[Epoch 119] ogbg-molclintox: 0.832435 val loss: 0.169617
[Epoch 119] ogbg-molclintox: 0.839499 test loss: 0.292846
[Epoch 120; Iter    10/   40] train: loss: 0.0042153
[Epoch 120; Iter    40/   40] train: loss: 0.0012214
[Epoch 120] ogbg-molclintox: 0.831373 val loss: 0.168657
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 76] ogbg-molclintox: 0.893924 val loss: 9.820108
[Epoch 76] ogbg-molclintox: 0.597175 test loss: 23.296767
[Epoch 77; Iter    20/   40] train: loss: 0.0417904
[Epoch 77] ogbg-molclintox: 0.710056 val loss: 13.882293
[Epoch 77] ogbg-molclintox: 0.658617 test loss: 33.625285
[Epoch 78; Iter    10/   40] train: loss: 0.0084211
[Epoch 78; Iter    40/   40] train: loss: 0.0145420
[Epoch 78] ogbg-molclintox: 0.563459 val loss: 8.943568
[Epoch 78] ogbg-molclintox: 0.594146 test loss: 13.546975
[Epoch 79; Iter    30/   40] train: loss: 0.0276664
[Epoch 79] ogbg-molclintox: 0.702287 val loss: 0.662811
[Epoch 79] ogbg-molclintox: 0.665516 test loss: 5.698299
[Epoch 80; Iter    20/   40] train: loss: 0.0022716
[Epoch 80] ogbg-molclintox: 0.774150 val loss: 0.345613
[Epoch 80] ogbg-molclintox: 0.655349 test loss: 1.933412
[Epoch 81; Iter    10/   40] train: loss: 0.0254562
[Epoch 81; Iter    40/   40] train: loss: 0.0031711
[Epoch 81] ogbg-molclintox: 0.667933 val loss: 0.325616
[Epoch 81] ogbg-molclintox: 0.626042 test loss: 3.941490
[Epoch 82; Iter    30/   40] train: loss: 0.0042218
[Epoch 82] ogbg-molclintox: 0.743844 val loss: 0.315134
[Epoch 82] ogbg-molclintox: 0.608743 test loss: 4.298795
[Epoch 83; Iter    20/   40] train: loss: 0.0395680
[Epoch 83] ogbg-molclintox: 0.694682 val loss: 0.331854
[Epoch 83] ogbg-molclintox: 0.648618 test loss: 4.378579
[Epoch 84; Iter    10/   40] train: loss: 0.0011519
[Epoch 84; Iter    40/   40] train: loss: 0.0070985
[Epoch 84] ogbg-molclintox: 0.673879 val loss: 0.342288
[Epoch 84] ogbg-molclintox: 0.643306 test loss: 4.390052
[Epoch 85; Iter    30/   40] train: loss: 0.0022153
[Epoch 85] ogbg-molclintox: 0.695357 val loss: 0.315672
[Epoch 85] ogbg-molclintox: 0.602935 test loss: 4.586215
[Epoch 86; Iter    20/   40] train: loss: 0.0014678
[Epoch 86] ogbg-molclintox: 0.716196 val loss: 0.337144
[Epoch 86] ogbg-molclintox: 0.631828 test loss: 3.945078
[Epoch 87; Iter    10/   40] train: loss: 0.0025215
[Epoch 87; Iter    40/   40] train: loss: 0.0021682
[Epoch 87] ogbg-molclintox: 0.723051 val loss: 0.302917
[Epoch 87] ogbg-molclintox: 0.628156 test loss: 3.753410
[Epoch 88; Iter    30/   40] train: loss: 0.0053685
[Epoch 88] ogbg-molclintox: 0.672867 val loss: 0.296666
[Epoch 88] ogbg-molclintox: 0.591927 test loss: 3.966111
[Epoch 89; Iter    20/   40] train: loss: 0.0050643
[Epoch 89] ogbg-molclintox: 0.640875 val loss: 0.334721
[Epoch 89] ogbg-molclintox: 0.616270 test loss: 2.662336
[Epoch 90; Iter    10/   40] train: loss: 0.0030356
[Epoch 90; Iter    40/   40] train: loss: 0.0004779
[Epoch 90] ogbg-molclintox: 0.611532 val loss: 0.314669
[Epoch 90] ogbg-molclintox: 0.631787 test loss: 3.673745
[Epoch 91; Iter    30/   40] train: loss: 0.0062863
[Epoch 91] ogbg-molclintox: 0.697255 val loss: 0.347178
[Epoch 91] ogbg-molclintox: 0.676274 test loss: 3.020493
[Epoch 92; Iter    20/   40] train: loss: 0.0026968
[Epoch 92] ogbg-molclintox: 0.733429 val loss: 0.355122
[Epoch 92] ogbg-molclintox: 0.708801 test loss: 4.468841
[Epoch 93; Iter    10/   40] train: loss: 0.0023120
[Epoch 93; Iter    40/   40] train: loss: 0.2561039
[Epoch 93] ogbg-molclintox: 0.606001 val loss: 3.153772
[Epoch 93] ogbg-molclintox: 0.492146 test loss: 15.197930
[Epoch 94; Iter    30/   40] train: loss: 0.0088187
[Epoch 94] ogbg-molclintox: 0.730080 val loss: 1.626058
[Epoch 94] ogbg-molclintox: 0.715001 test loss: 5.140618
[Epoch 95; Iter    20/   40] train: loss: 0.0006726
[Epoch 95] ogbg-molclintox: 0.812843 val loss: 0.309218
[Epoch 95] ogbg-molclintox: 0.673132 test loss: 3.133876
[Epoch 96; Iter    10/   40] train: loss: 0.0020278
[Epoch 96; Iter    40/   40] train: loss: 0.0125297
[Epoch 96] ogbg-molclintox: 0.717580 val loss: 0.235296
[Epoch 96] ogbg-molclintox: 0.666976 test loss: 3.405972
[Epoch 97; Iter    30/   40] train: loss: 0.0015681
[Epoch 97] ogbg-molclintox: 0.806174 val loss: 0.280216
[Epoch 97] ogbg-molclintox: 0.699514 test loss: 1.892835
[Epoch 98; Iter    20/   40] train: loss: 0.0075295
[Epoch 98] ogbg-molclintox: 0.838591 val loss: 0.260820
[Epoch 98] ogbg-molclintox: 0.716626 test loss: 1.828931
[Epoch 99; Iter    10/   40] train: loss: 0.0014464
[Epoch 99; Iter    40/   40] train: loss: 0.0090006
[Epoch 99] ogbg-molclintox: 0.834933 val loss: 0.276140
[Epoch 99] ogbg-molclintox: 0.709417 test loss: 2.802468
[Epoch 100; Iter    30/   40] train: loss: 0.0019602
[Epoch 100] ogbg-molclintox: 0.826903 val loss: 0.268277
[Epoch 100] ogbg-molclintox: 0.707418 test loss: 2.728121
[Epoch 101; Iter    20/   40] train: loss: 0.0019371
[Epoch 101] ogbg-molclintox: 0.820810 val loss: 0.281407
[Epoch 101] ogbg-molclintox: 0.695764 test loss: 2.973643
[Epoch 102; Iter    10/   40] train: loss: 0.0003597
[Epoch 102; Iter    40/   40] train: loss: 0.0015936
[Epoch 102] ogbg-molclintox: 0.806300 val loss: 0.276772
[Epoch 102] ogbg-molclintox: 0.725445 test loss: 2.728269
[Epoch 103; Iter    30/   40] train: loss: 0.0007557
[Epoch 103] ogbg-molclintox: 0.814854 val loss: 0.263736
[Epoch 103] ogbg-molclintox: 0.724982 test loss: 2.509734
[Epoch 104; Iter    20/   40] train: loss: 0.0047579
[Epoch 104] ogbg-molclintox: 0.791928 val loss: 0.281641
[Epoch 104] ogbg-molclintox: 0.701035 test loss: 2.882415
[Epoch 105; Iter    10/   40] train: loss: 0.0018934
[Epoch 105; Iter    40/   40] train: loss: 0.0034025
[Epoch 105] ogbg-molclintox: 0.805826 val loss: 0.269766
[Epoch 105] ogbg-molclintox: 0.712203 test loss: 2.717114
[Epoch 106; Iter    30/   40] train: loss: 0.0008519
[Epoch 106] ogbg-molclintox: 0.813255 val loss: 0.277005
[Epoch 106] ogbg-molclintox: 0.727256 test loss: 2.767276
[Epoch 107; Iter    20/   40] train: loss: 0.0010018
[Epoch 107] ogbg-molclintox: 0.811108 val loss: 0.273426
[Epoch 107] ogbg-molclintox: 0.712778 test loss: 3.181462
[Epoch 108; Iter    10/   40] train: loss: 0.0009463
[Epoch 108; Iter    40/   40] train: loss: 0.0066868
[Epoch 108] ogbg-molclintox: 0.642649 val loss: 1.052243
[Epoch 108] ogbg-molclintox: 0.591120 test loss: 6.356011
[Epoch 109; Iter    30/   40] train: loss: 0.0014065
[Epoch 109] ogbg-molclintox: 0.720553 val loss: 0.329789
[Epoch 109] ogbg-molclintox: 0.676625 test loss: 4.508470
[Epoch 110; Iter    20/   40] train: loss: 0.0012428
[Epoch 110] ogbg-molclintox: 0.737273 val loss: 0.342555
[Epoch 110] ogbg-molclintox: 0.711565 test loss: 3.350411
[Epoch 111; Iter    10/   40] train: loss: 0.0008910
[Epoch 111; Iter    40/   40] train: loss: 0.0035296
[Epoch 111] ogbg-molclintox: 0.719766 val loss: 0.342592
[Epoch 111] ogbg-molclintox: 0.693239 test loss: 3.929623
[Epoch 112; Iter    30/   40] train: loss: 0.0037386
[Epoch 112] ogbg-molclintox: 0.718592 val loss: 0.341158
[Epoch 112] ogbg-molclintox: 0.686632 test loss: 4.290854
[Epoch 113; Iter    20/   40] train: loss: 0.0220664
[Epoch 113] ogbg-molclintox: 0.759486 val loss: 0.332309
[Epoch 113] ogbg-molclintox: 0.711553 test loss: 4.184775
[Epoch 114; Iter    10/   40] train: loss: 0.0004504
[Epoch 114; Iter    40/   40] train: loss: 0.0002802
[Epoch 114] ogbg-molclintox: 0.742516 val loss: 0.348541
[Epoch 114] ogbg-molclintox: 0.697262 test loss: 4.266691
[Epoch 115; Iter    30/   40] train: loss: 0.0002866
[Epoch 115] ogbg-molclintox: 0.737308 val loss: 0.344366
[Epoch 115] ogbg-molclintox: 0.704195 test loss: 4.102097
[Epoch 116; Iter    20/   40] train: loss: 0.0019657
[Epoch 116] ogbg-molclintox: 0.730765 val loss: 0.344526
[Epoch 116] ogbg-molclintox: 0.698099 test loss: 4.008705
[Epoch 117; Iter    10/   40] train: loss: 0.0009192
[Epoch 117; Iter    40/   40] train: loss: 0.0002339
[Epoch 117] ogbg-molclintox: 0.740594 val loss: 0.337144
[Epoch 117] ogbg-molclintox: 0.688417 test loss: 4.175331
[Epoch 118; Iter    30/   40] train: loss: 0.0004781
[Epoch 118] ogbg-molclintox: 0.717243 val loss: 0.358912
[Epoch 118] ogbg-molclintox: 0.680185 test loss: 3.577011
[Epoch 119; Iter    20/   40] train: loss: 0.0004080
[Epoch 119] ogbg-molclintox: 0.724485 val loss: 0.354658
[Epoch 119] ogbg-molclintox: 0.677574 test loss: 2.838286
[Epoch 120; Iter    10/   40] train: loss: 0.0010988
[Epoch 120; Iter    40/   40] train: loss: 0.0003972
[Epoch 120] ogbg-molclintox: 0.715820 val loss: 0.353747
[Epoch 120] ogbg-molclintox: 0.848568 test loss: 0.280346
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 44.
Statistics on  val_best_checkpoint
mean_pred: 0.15190723538398743
std_pred: 4.139380931854248
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7796125772067034
rocauc: 0.9594052660954069
ogbg-molclintox: 0.9594052660954069
OGBNanLabelBCEWithLogitsLoss: 0.1284754926338792
Statistics on  test
mean_pred: 0.07034868001937866
std_pred: 5.948317050933838
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6138221937850582
rocauc: 0.7779037639453654
ogbg-molclintox: 0.7779037639453654
OGBNanLabelBCEWithLogitsLoss: 0.5827711880207062
Statistics on  train
mean_pred: 0.16469711065292358
std_pred: 5.328311443328857
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.878049509822792
rocauc: 0.9541971427315763
ogbg-molclintox: 0.9541971427315763
OGBNanLabelBCEWithLogitsLoss: 0.12212367146275938
[Epoch 76] ogbg-molclintox: 0.973528 val loss: 0.085965
[Epoch 76] ogbg-molclintox: 0.658319 test loss: 0.384091
[Epoch 77; Iter    20/   40] train: loss: 0.0284764
[Epoch 77] ogbg-molclintox: 0.976399 val loss: 0.069062
[Epoch 77] ogbg-molclintox: 0.738892 test loss: 0.384978
[Epoch 78; Iter    10/   40] train: loss: 0.0112251
[Epoch 78; Iter    40/   40] train: loss: 0.0034158
[Epoch 78] ogbg-molclintox: 0.983642 val loss: 0.069855
[Epoch 78] ogbg-molclintox: 0.762402 test loss: 0.360447
[Epoch 79; Iter    30/   40] train: loss: 0.0010169
[Epoch 79] ogbg-molclintox: 0.962926 val loss: 0.343632
[Epoch 79] ogbg-molclintox: 0.792845 test loss: 0.375145
[Epoch 80; Iter    20/   40] train: loss: 0.0076103
[Epoch 80] ogbg-molclintox: 0.983168 val loss: 0.075823
[Epoch 80] ogbg-molclintox: 0.784687 test loss: 0.326061
[Epoch 81; Iter    10/   40] train: loss: 0.0015456
[Epoch 81; Iter    40/   40] train: loss: 0.0114209
[Epoch 81] ogbg-molclintox: 0.862107 val loss: 0.120796
[Epoch 81] ogbg-molclintox: 0.780877 test loss: 0.490796
[Epoch 82; Iter    30/   40] train: loss: 0.0541321
[Epoch 82] ogbg-molclintox: 0.927800 val loss: 0.138410
[Epoch 82] ogbg-molclintox: 0.793110 test loss: 0.582375
[Epoch 83; Iter    20/   40] train: loss: 0.0354683
[Epoch 83] ogbg-molclintox: 0.913452 val loss: 0.119797
[Epoch 83] ogbg-molclintox: 0.832782 test loss: 1.342867
[Epoch 84; Iter    10/   40] train: loss: 0.0173699
[Epoch 84; Iter    40/   40] train: loss: 0.0714772
[Epoch 84] ogbg-molclintox: 0.925153 val loss: 0.101981
[Epoch 84] ogbg-molclintox: 0.802743 test loss: 0.407779
[Epoch 85; Iter    30/   40] train: loss: 0.0215550
[Epoch 85] ogbg-molclintox: 0.874069 val loss: 0.144437
[Epoch 85] ogbg-molclintox: 0.723805 test loss: 0.516347
[Epoch 86; Iter    20/   40] train: loss: 0.0155194
[Epoch 86] ogbg-molclintox: 0.957444 val loss: 0.111406
[Epoch 86] ogbg-molclintox: 0.849274 test loss: 0.415648
[Epoch 87; Iter    10/   40] train: loss: 0.0065554
[Epoch 87; Iter    40/   40] train: loss: 0.0276156
[Epoch 87] ogbg-molclintox: 0.921446 val loss: 0.146321
[Epoch 87] ogbg-molclintox: 0.783100 test loss: 0.387188
[Epoch 88; Iter    30/   40] train: loss: 0.0235990
[Epoch 88] ogbg-molclintox: 0.880342 val loss: 0.174386
[Epoch 88] ogbg-molclintox: 0.653022 test loss: 0.527769
[Epoch 89; Iter    20/   40] train: loss: 0.0072051
[Epoch 89] ogbg-molclintox: 0.964912 val loss: 0.081502
[Epoch 89] ogbg-molclintox: 0.746886 test loss: 0.396352
[Epoch 90; Iter    10/   40] train: loss: 0.0116854
[Epoch 90; Iter    40/   40] train: loss: 0.0008556
[Epoch 90] ogbg-molclintox: 0.968770 val loss: 0.093323
[Epoch 90] ogbg-molclintox: 0.733745 test loss: 0.423433
[Epoch 91; Iter    30/   40] train: loss: 0.0047067
[Epoch 91] ogbg-molclintox: 0.951228 val loss: 0.117226
[Epoch 91] ogbg-molclintox: 0.626217 test loss: 0.501364
[Epoch 92; Iter    20/   40] train: loss: 0.0021259
[Epoch 92] ogbg-molclintox: 0.975352 val loss: 0.069704
[Epoch 92] ogbg-molclintox: 0.750337 test loss: 0.591024
[Epoch 93; Iter    10/   40] train: loss: 0.0011251
[Epoch 93; Iter    40/   40] train: loss: 0.0026638
[Epoch 93] ogbg-molclintox: 0.794328 val loss: 0.223866
[Epoch 93] ogbg-molclintox: 0.721916 test loss: 0.471391
[Epoch 94; Iter    30/   40] train: loss: 0.0023818
[Epoch 94] ogbg-molclintox: 0.843314 val loss: 0.154039
[Epoch 94] ogbg-molclintox: 0.647639 test loss: 0.432911
[Epoch 95; Iter    20/   40] train: loss: 0.0035780
[Epoch 95] ogbg-molclintox: 0.838644 val loss: 0.164111
[Epoch 95] ogbg-molclintox: 0.778957 test loss: 0.396475
[Epoch 96; Iter    10/   40] train: loss: 0.0018618
[Epoch 96; Iter    40/   40] train: loss: 0.0080548
[Epoch 96] ogbg-molclintox: 0.831802 val loss: 0.175203
[Epoch 96] ogbg-molclintox: 0.628051 test loss: 0.555446
[Epoch 97; Iter    30/   40] train: loss: 0.0031380
[Epoch 97] ogbg-molclintox: 0.955659 val loss: 0.099966
[Epoch 97] ogbg-molclintox: 0.754144 test loss: 0.478792
[Epoch 98; Iter    20/   40] train: loss: 0.0006712
[Epoch 98] ogbg-molclintox: 0.890065 val loss: 0.124527
[Epoch 98] ogbg-molclintox: 0.783324 test loss: 0.465761
[Epoch 99; Iter    10/   40] train: loss: 0.0028528
[Epoch 99; Iter    40/   40] train: loss: 0.0016634
[Epoch 99] ogbg-molclintox: 0.903626 val loss: 0.117414
[Epoch 99] ogbg-molclintox: 0.712708 test loss: 0.500276
[Epoch 100; Iter    30/   40] train: loss: 0.0009924
[Epoch 100] ogbg-molclintox: 0.935731 val loss: 0.102635
[Epoch 100] ogbg-molclintox: 0.686811 test loss: 0.606260
[Epoch 101; Iter    20/   40] train: loss: 0.0015781
[Epoch 101] ogbg-molclintox: 0.907622 val loss: 0.087482
[Epoch 101] ogbg-molclintox: 0.767098 test loss: 0.471992
[Epoch 102; Iter    10/   40] train: loss: 0.0132944
[Epoch 102; Iter    40/   40] train: loss: 0.0068272
[Epoch 102] ogbg-molclintox: 0.914927 val loss: 0.099483
[Epoch 102] ogbg-molclintox: 0.693860 test loss: 0.480331
[Epoch 103; Iter    30/   40] train: loss: 0.0012449
[Epoch 103] ogbg-molclintox: 0.978873 val loss: 0.077848
[Epoch 103] ogbg-molclintox: 0.728661 test loss: 0.515841
[Epoch 104; Iter    20/   40] train: loss: 0.0041259
[Epoch 104] ogbg-molclintox: 0.973753 val loss: 0.091158
[Epoch 104] ogbg-molclintox: 0.665341 test loss: 0.536174
[Epoch 105; Iter    10/   40] train: loss: 0.0011449
[Epoch 105; Iter    40/   40] train: loss: 0.0075451
[Epoch 105] ogbg-molclintox: 0.842790 val loss: 0.163344
[Epoch 105] ogbg-molclintox: 0.822413 test loss: 0.431552
[Epoch 106; Iter    30/   40] train: loss: 0.0005291
[Epoch 106] ogbg-molclintox: 0.963415 val loss: 0.134543
[Epoch 106] ogbg-molclintox: 0.810207 test loss: 0.892203
[Epoch 107; Iter    20/   40] train: loss: 0.0039469
[Epoch 107] ogbg-molclintox: 0.971792 val loss: 0.087970
[Epoch 107] ogbg-molclintox: 0.825674 test loss: 0.623165
[Epoch 108; Iter    10/   40] train: loss: 0.0066012
[Epoch 108; Iter    40/   40] train: loss: 0.0176794
[Epoch 108] ogbg-molclintox: 0.954310 val loss: 0.098591
[Epoch 108] ogbg-molclintox: 0.820266 test loss: 2.967869
[Epoch 109; Iter    30/   40] train: loss: 0.0143337
[Epoch 109] ogbg-molclintox: 0.839332 val loss: 0.171362
[Epoch 109] ogbg-molclintox: 0.767986 test loss: 0.385991
[Epoch 110; Iter    20/   40] train: loss: 0.0425383
[Epoch 110] ogbg-molclintox: 0.786811 val loss: 0.215466
[Epoch 110] ogbg-molclintox: 0.784758 test loss: 0.436287
[Epoch 111; Iter    10/   40] train: loss: 0.0028506
[Epoch 111; Iter    40/   40] train: loss: 0.0060496
[Epoch 111] ogbg-molclintox: 0.854204 val loss: 0.184840
[Epoch 111] ogbg-molclintox: 0.785849 test loss: 0.443569
[Epoch 112; Iter    30/   40] train: loss: 0.0514719
[Epoch 112] ogbg-molclintox: 0.953962 val loss: 0.119139
[Epoch 112] ogbg-molclintox: 0.764550 test loss: 1.418566
[Epoch 113; Iter    20/   40] train: loss: 0.0016893
[Epoch 113] ogbg-molclintox: 0.899732 val loss: 0.181424
[Epoch 113] ogbg-molclintox: 0.738104 test loss: 0.678303
[Epoch 114; Iter    10/   40] train: loss: 0.0129426
[Epoch 114; Iter    40/   40] train: loss: 0.0000919
[Epoch 114] ogbg-molclintox: 0.907049 val loss: 0.170759
[Epoch 114] ogbg-molclintox: 0.835965 test loss: 0.392188
[Epoch 115; Iter    30/   40] train: loss: 0.0006526
[Epoch 115] ogbg-molclintox: 0.860048 val loss: 0.141163
[Epoch 115] ogbg-molclintox: 0.778240 test loss: 0.430997
[Epoch 116; Iter    20/   40] train: loss: 0.0011119
[Epoch 116] ogbg-molclintox: 0.824559 val loss: 0.177758
[Epoch 116] ogbg-molclintox: 0.803599 test loss: 0.407112
[Epoch 117; Iter    10/   40] train: loss: 0.0011200
[Epoch 117; Iter    40/   40] train: loss: 0.0011351
[Epoch 117] ogbg-molclintox: 0.820040 val loss: 0.174360
[Epoch 117] ogbg-molclintox: 0.770769 test loss: 0.513773
[Epoch 118; Iter    30/   40] train: loss: 0.0005373
[Epoch 118] ogbg-molclintox: 0.819952 val loss: 0.170773
[Epoch 118] ogbg-molclintox: 0.779663 test loss: 0.417816
[Epoch 119; Iter    20/   40] train: loss: 0.0016820
[Epoch 119] ogbg-molclintox: 0.860948 val loss: 0.144964
[Epoch 119] ogbg-molclintox: 0.786947 test loss: 0.400602
[Epoch 120; Iter    10/   40] train: loss: 0.0009181
[Epoch 120; Iter    40/   40] train: loss: 0.0001347
[Epoch 120] ogbg-molclintox: 0.859549 val loss: 0.149114
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.767759 test loss: 0.405828
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 54.
Statistics on  val_best_checkpoint
mean_pred: 0.0608077272772789
std_pred: 7.20548677444458
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.8941972993983482
rocauc: 0.9933197084605536
ogbg-molclintox: 0.9933197084605536
OGBNanLabelBCEWithLogitsLoss: 0.07379883237299509
Statistics on  test
mean_pred: 0.13499753177165985
std_pred: 7.8172607421875
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6334104437218884
rocauc: 0.803811733222118
ogbg-molclintox: 0.803811733222118
OGBNanLabelBCEWithLogitsLoss: 0.2988799139857292
Statistics on  train
mean_pred: 0.19053906202316284
std_pred: 6.2710957527160645
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9987101751569839
rocauc: 0.9987306784364445
ogbg-molclintox: 0.9987306784364445
OGBNanLabelBCEWithLogitsLoss: 0.028486515476834028
[Epoch 76] ogbg-molclintox: 0.921495 val loss: 0.179279
[Epoch 76] ogbg-molclintox: 0.798952 test loss: 0.670815
[Epoch 77; Iter    20/   40] train: loss: 0.0032859
[Epoch 77] ogbg-molclintox: 0.923632 val loss: 0.258111
[Epoch 77] ogbg-molclintox: 0.787922 test loss: 0.888364
[Epoch 78; Iter    10/   40] train: loss: 0.0036972
[Epoch 78; Iter    40/   40] train: loss: 0.0765776
[Epoch 78] ogbg-molclintox: 0.944235 val loss: 0.372613
[Epoch 78] ogbg-molclintox: 0.782113 test loss: 0.914928
[Epoch 79; Iter    30/   40] train: loss: 0.0776388
[Epoch 79] ogbg-molclintox: 0.928102 val loss: 0.221638
[Epoch 79] ogbg-molclintox: 0.803588 test loss: 1.000227
[Epoch 80; Iter    20/   40] train: loss: 0.0027107
[Epoch 80] ogbg-molclintox: 0.923045 val loss: 0.380817
[Epoch 80] ogbg-molclintox: 0.752134 test loss: 0.837586
[Epoch 81; Iter    10/   40] train: loss: 0.0037879
[Epoch 81; Iter    40/   40] train: loss: 0.0018890
[Epoch 81] ogbg-molclintox: 0.930038 val loss: 0.329079
[Epoch 81] ogbg-molclintox: 0.774968 test loss: 0.817497
[Epoch 82; Iter    30/   40] train: loss: 0.0264537
[Epoch 82] ogbg-molclintox: 0.919847 val loss: 0.234370
[Epoch 82] ogbg-molclintox: 0.807110 test loss: 0.958720
[Epoch 83; Iter    20/   40] train: loss: 0.0137091
[Epoch 83] ogbg-molclintox: 0.919134 val loss: 0.265865
[Epoch 83] ogbg-molclintox: 0.799703 test loss: 0.826321
[Epoch 84; Iter    10/   40] train: loss: 0.0016237
[Epoch 84; Iter    40/   40] train: loss: 0.0254020
[Epoch 84] ogbg-molclintox: 0.900727 val loss: 0.125186
[Epoch 84] ogbg-molclintox: 0.803363 test loss: 0.580144
[Epoch 85; Iter    30/   40] train: loss: 0.0010340
[Epoch 85] ogbg-molclintox: 0.932723 val loss: 0.411233
[Epoch 85] ogbg-molclintox: 0.768009 test loss: 1.005818
[Epoch 86; Iter    20/   40] train: loss: 0.0031151
[Epoch 86] ogbg-molclintox: 0.900253 val loss: 0.169941
[Epoch 86] ogbg-molclintox: 0.798567 test loss: 0.676873
[Epoch 87; Iter    10/   40] train: loss: 0.0053682
[Epoch 87; Iter    40/   40] train: loss: 0.0222463
[Epoch 87] ogbg-molclintox: 0.928762 val loss: 0.198983
[Epoch 87] ogbg-molclintox: 0.792882 test loss: 0.652418
[Epoch 88; Iter    30/   40] train: loss: 0.0141493
[Epoch 88] ogbg-molclintox: 0.909969 val loss: 0.214689
[Epoch 88] ogbg-molclintox: 0.773033 test loss: 0.570933
[Epoch 89; Iter    20/   40] train: loss: 0.0158491
[Epoch 89] ogbg-molclintox: 0.881161 val loss: 0.198402
[Epoch 89] ogbg-molclintox: 0.800017 test loss: 0.637773
[Epoch 90; Iter    10/   40] train: loss: 0.0098380
[Epoch 90; Iter    40/   40] train: loss: 0.0012285
[Epoch 90] ogbg-molclintox: 0.908072 val loss: 0.300253
[Epoch 90] ogbg-molclintox: 0.785075 test loss: 0.797597
[Epoch 91; Iter    30/   40] train: loss: 0.0013222
[Epoch 91] ogbg-molclintox: 0.891025 val loss: 0.240408
[Epoch 91] ogbg-molclintox: 0.795120 test loss: 0.718361
[Epoch 92; Iter    20/   40] train: loss: 0.0168501
[Epoch 92] ogbg-molclintox: 0.864539 val loss: 0.216154
[Epoch 92] ogbg-molclintox: 0.792471 test loss: 0.727454
[Epoch 93; Iter    10/   40] train: loss: 0.0041539
[Epoch 93; Iter    40/   40] train: loss: 0.0076111
[Epoch 93] ogbg-molclintox: 0.883245 val loss: 0.421190
[Epoch 93] ogbg-molclintox: 0.780877 test loss: 0.995521
[Epoch 94; Iter    30/   40] train: loss: 0.0008644
[Epoch 94] ogbg-molclintox: 0.857884 val loss: 0.376802
[Epoch 94] ogbg-molclintox: 0.771408 test loss: 0.798230
[Epoch 95; Iter    20/   40] train: loss: 0.0025333
[Epoch 95] ogbg-molclintox: 0.896946 val loss: 0.437895
[Epoch 95] ogbg-molclintox: 0.745575 test loss: 0.918250
[Epoch 96; Iter    10/   40] train: loss: 0.0157672
[Epoch 96; Iter    40/   40] train: loss: 0.0145025
[Epoch 96] ogbg-molclintox: 0.873068 val loss: 0.412726
[Epoch 96] ogbg-molclintox: 0.776305 test loss: 0.933347
[Epoch 97; Iter    30/   40] train: loss: 0.0009598
[Epoch 97] ogbg-molclintox: 0.862192 val loss: 0.320121
[Epoch 97] ogbg-molclintox: 0.795120 test loss: 0.706763
[Epoch 98; Iter    20/   40] train: loss: 0.0008814
[Epoch 98] ogbg-molclintox: 0.856973 val loss: 0.570449
[Epoch 98] ogbg-molclintox: 0.754906 test loss: 0.918491
[Epoch 99; Iter    10/   40] train: loss: 0.0031445
[Epoch 99; Iter    40/   40] train: loss: 0.0003589
[Epoch 99] ogbg-molclintox: 0.837294 val loss: 0.289666
[Epoch 99] ogbg-molclintox: 0.771486 test loss: 0.641467
[Epoch 100; Iter    30/   40] train: loss: 0.0012392
[Epoch 100] ogbg-molclintox: 0.885943 val loss: 0.501878
[Epoch 100] ogbg-molclintox: 0.785075 test loss: 0.932980
[Epoch 101; Iter    20/   40] train: loss: 0.0017784
[Epoch 101] ogbg-molclintox: 0.826495 val loss: 0.647348
[Epoch 101] ogbg-molclintox: 0.769051 test loss: 0.854354
[Epoch 102; Iter    10/   40] train: loss: 0.0026773
[Epoch 102; Iter    40/   40] train: loss: 0.0042554
[Epoch 102] ogbg-molclintox: 0.837958 val loss: 0.621431
[Epoch 102] ogbg-molclintox: 0.764042 test loss: 0.834084
[Epoch 103; Iter    30/   40] train: loss: 0.0006128
[Epoch 103] ogbg-molclintox: 0.840404 val loss: 0.425125
[Epoch 103] ogbg-molclintox: 0.774635 test loss: 0.805905
[Epoch 104; Iter    20/   40] train: loss: 0.0011290
[Epoch 104] ogbg-molclintox: 0.863481 val loss: 0.412823
[Epoch 104] ogbg-molclintox: 0.771710 test loss: 0.794926
[Epoch 105; Iter    10/   40] train: loss: 0.0009705
[Epoch 105; Iter    40/   40] train: loss: 0.0365051
[Epoch 105] ogbg-molclintox: 0.867751 val loss: 0.639378
[Epoch 105] ogbg-molclintox: 0.770373 test loss: 1.016471
[Epoch 106; Iter    30/   40] train: loss: 0.0015007
[Epoch 106] ogbg-molclintox: 0.917950 val loss: 1.047110
[Epoch 106] ogbg-molclintox: 0.772110 test loss: 1.535907
[Epoch 107; Iter    20/   40] train: loss: 0.0013078
[Epoch 107] ogbg-molclintox: 0.886383 val loss: 0.571827
[Epoch 107] ogbg-molclintox: 0.762279 test loss: 0.913517
[Epoch 108; Iter    10/   40] train: loss: 0.0007122
[Epoch 108; Iter    40/   40] train: loss: 0.0064272
[Epoch 108] ogbg-molclintox: 0.868577 val loss: 1.001361
[Epoch 108] ogbg-molclintox: 0.719670 test loss: 1.333339
[Epoch 109; Iter    30/   40] train: loss: 0.0008368
[Epoch 109] ogbg-molclintox: 0.872210 val loss: 0.922082
[Epoch 109] ogbg-molclintox: 0.737047 test loss: 1.310343
[Epoch 110; Iter    20/   40] train: loss: 0.0011245
[Epoch 110] ogbg-molclintox: 0.887194 val loss: 1.032989
[Epoch 110] ogbg-molclintox: 0.751898 test loss: 1.373752
[Epoch 111; Iter    10/   40] train: loss: 0.0014297
[Epoch 111; Iter    40/   40] train: loss: 0.0003832
[Epoch 111] ogbg-molclintox: 0.869487 val loss: 0.749996
[Epoch 111] ogbg-molclintox: 0.761842 test loss: 1.079314
[Epoch 112; Iter    30/   40] train: loss: 0.0008523
[Epoch 112] ogbg-molclintox: 0.872397 val loss: 0.786957
[Epoch 112] ogbg-molclintox: 0.759081 test loss: 1.173206
[Epoch 113; Iter    20/   40] train: loss: 0.0012563
[Epoch 113] ogbg-molclintox: 0.867164 val loss: 0.645444
[Epoch 113] ogbg-molclintox: 0.765865 test loss: 0.999741
[Epoch 114; Iter    10/   40] train: loss: 0.0017898
[Epoch 114; Iter    40/   40] train: loss: 0.0098731
[Epoch 114] ogbg-molclintox: 0.873096 val loss: 0.812212
[Epoch 114] ogbg-molclintox: 0.759406 test loss: 1.127708
[Epoch 115; Iter    30/   40] train: loss: 0.0050396
[Epoch 115] ogbg-molclintox: 0.865154 val loss: 0.857474
[Epoch 115] ogbg-molclintox: 0.753284 test loss: 1.126209
[Epoch 116; Iter    20/   40] train: loss: 0.0009199
[Epoch 116] ogbg-molclintox: 0.828228 val loss: 0.689316
[Epoch 116] ogbg-molclintox: 0.755059 test loss: 1.005161
[Epoch 117; Iter    10/   40] train: loss: 0.0009922
[Epoch 117; Iter    40/   40] train: loss: 0.0119581
[Epoch 117] ogbg-molclintox: 0.862069 val loss: 0.817336
[Epoch 117] ogbg-molclintox: 0.759843 test loss: 1.108292
[Epoch 118; Iter    30/   40] train: loss: 0.0004802
[Epoch 118] ogbg-molclintox: 0.804715 val loss: 0.516088
[Epoch 118] ogbg-molclintox: 0.783798 test loss: 0.742713
[Epoch 119; Iter    20/   40] train: loss: 0.0016972
[Epoch 119] ogbg-molclintox: 0.809748 val loss: 0.981058
[Epoch 119] ogbg-molclintox: 0.783249 test loss: 1.220906
[Epoch 120; Iter    10/   40] train: loss: 0.0093477
[Epoch 120; Iter    40/   40] train: loss: 0.0036198
[Epoch 120] ogbg-molclintox: 0.812882 val loss: 0.870781
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.05.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.05.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.05.yml --seed 6 --device cuda:1
All runs completed.
[Epoch 76] ogbg-molclintox: 0.891552 val loss: 0.491138
[Epoch 76] ogbg-molclintox: 0.749889 test loss: 0.532196
[Epoch 77; Iter    20/   40] train: loss: 0.0047059
[Epoch 77] ogbg-molclintox: 0.863794 val loss: 0.465738
[Epoch 77] ogbg-molclintox: 0.751036 test loss: 0.450869
[Epoch 78; Iter    10/   40] train: loss: 0.0525851
[Epoch 78; Iter    40/   40] train: loss: 0.0054983
[Epoch 78] ogbg-molclintox: 0.888544 val loss: 0.234867
[Epoch 78] ogbg-molclintox: 0.764064 test loss: 0.418043
[Epoch 79; Iter    30/   40] train: loss: 0.0014764
[Epoch 79] ogbg-molclintox: 0.721031 val loss: 0.628576
[Epoch 79] ogbg-molclintox: 0.754883 test loss: 0.365877
[Epoch 80; Iter    20/   40] train: loss: 0.0380483
[Epoch 80] ogbg-molclintox: 0.667037 val loss: 0.517208
[Epoch 80] ogbg-molclintox: 0.743617 test loss: 0.496478
[Epoch 81; Iter    10/   40] train: loss: 0.0177407
[Epoch 81; Iter    40/   40] train: loss: 0.0227953
[Epoch 81] ogbg-molclintox: 0.678774 val loss: 0.707255
[Epoch 81] ogbg-molclintox: 0.745216 test loss: 1.354001
[Epoch 82; Iter    30/   40] train: loss: 0.0516214
[Epoch 82] ogbg-molclintox: 0.847661 val loss: 0.251902
[Epoch 82] ogbg-molclintox: 0.721882 test loss: 3.316062
[Epoch 83; Iter    20/   40] train: loss: 0.0400352
[Epoch 83] ogbg-molclintox: 0.799760 val loss: 0.180661
[Epoch 83] ogbg-molclintox: 0.740506 test loss: 2.271927
[Epoch 84; Iter    10/   40] train: loss: 0.0379572
[Epoch 84; Iter    40/   40] train: loss: 0.0229777
[Epoch 84] ogbg-molclintox: 0.699978 val loss: 0.234694
[Epoch 84] ogbg-molclintox: 0.719782 test loss: 9.299866
[Epoch 85; Iter    30/   40] train: loss: 0.0090500
[Epoch 85] ogbg-molclintox: 0.727423 val loss: 0.421137
[Epoch 85] ogbg-molclintox: 0.737745 test loss: 13.262820
[Epoch 86; Iter    20/   40] train: loss: 0.0036715
[Epoch 86] ogbg-molclintox: 0.730832 val loss: 0.638182
[Epoch 86] ogbg-molclintox: 0.750401 test loss: 11.015295
[Epoch 87; Iter    10/   40] train: loss: 0.0055066
[Epoch 87; Iter    40/   40] train: loss: 0.0209423
[Epoch 87] ogbg-molclintox: 0.742182 val loss: 0.518965
[Epoch 87] ogbg-molclintox: 0.756859 test loss: 8.170150
[Epoch 88; Iter    30/   40] train: loss: 0.0102188
[Epoch 88] ogbg-molclintox: 0.730245 val loss: 0.439626
[Epoch 88] ogbg-molclintox: 0.755398 test loss: 6.848029
[Epoch 89; Iter    20/   40] train: loss: 0.0067681
[Epoch 89] ogbg-molclintox: 0.732954 val loss: 0.855901
[Epoch 89] ogbg-molclintox: 0.751626 test loss: 8.200809
[Epoch 90; Iter    10/   40] train: loss: 0.0274918
[Epoch 90; Iter    40/   40] train: loss: 0.0015172
[Epoch 90] ogbg-molclintox: 0.704234 val loss: 1.027382
[Epoch 90] ogbg-molclintox: 0.763818 test loss: 7.226469
[Epoch 91; Iter    30/   40] train: loss: 0.0021572
[Epoch 91] ogbg-molclintox: 0.689949 val loss: 1.352669
[Epoch 91] ogbg-molclintox: 0.677062 test loss: 7.783406
[Epoch 92; Iter    20/   40] train: loss: 0.0026493
[Epoch 92] ogbg-molclintox: 0.695930 val loss: 1.523622
[Epoch 92] ogbg-molclintox: 0.681996 test loss: 7.584983
[Epoch 93; Iter    10/   40] train: loss: 0.0022585
[Epoch 93; Iter    40/   40] train: loss: 0.0057132
[Epoch 93] ogbg-molclintox: 0.722777 val loss: 1.277304
[Epoch 93] ogbg-molclintox: 0.677024 test loss: 7.428067
[Epoch 94; Iter    30/   40] train: loss: 0.0013010
[Epoch 94] ogbg-molclintox: 0.679934 val loss: 0.916264
[Epoch 94] ogbg-molclintox: 0.746628 test loss: 7.468511
[Epoch 95; Iter    20/   40] train: loss: 0.0030499
[Epoch 95] ogbg-molclintox: 0.733703 val loss: 0.886619
[Epoch 95] ogbg-molclintox: 0.676412 test loss: 8.049185
[Epoch 96; Iter    10/   40] train: loss: 0.0021542
[Epoch 96; Iter    40/   40] train: loss: 0.0028335
[Epoch 96] ogbg-molclintox: 0.707442 val loss: 1.060037
[Epoch 96] ogbg-molclintox: 0.673439 test loss: 8.248264
[Epoch 97; Iter    30/   40] train: loss: 0.0015966
[Epoch 97] ogbg-molclintox: 0.715085 val loss: 0.699428
[Epoch 97] ogbg-molclintox: 0.741630 test loss: 7.130968
[Epoch 98; Iter    20/   40] train: loss: 0.0027994
[Epoch 98] ogbg-molclintox: 0.695294 val loss: 0.832352
[Epoch 98] ogbg-molclintox: 0.670379 test loss: 7.739718
[Epoch 99; Iter    10/   40] train: loss: 0.0118632
[Epoch 99; Iter    40/   40] train: loss: 0.0065597
[Epoch 99] ogbg-molclintox: 0.700688 val loss: 0.844434
[Epoch 99] ogbg-molclintox: 0.667668 test loss: 8.166369
[Epoch 100; Iter    30/   40] train: loss: 0.0028627
[Epoch 100] ogbg-molclintox: 0.666099 val loss: 0.706654
[Epoch 100] ogbg-molclintox: 0.675176 test loss: 9.037781
[Epoch 101; Iter    20/   40] train: loss: 0.0020113
[Epoch 101] ogbg-molclintox: 0.667385 val loss: 0.707036
[Epoch 101] ogbg-molclintox: 0.678336 test loss: 8.739194
[Epoch 102; Iter    10/   40] train: loss: 0.0113870
[Epoch 102; Iter    40/   40] train: loss: 0.0090345
[Epoch 102] ogbg-molclintox: 0.668446 val loss: 0.793114
[Epoch 102] ogbg-molclintox: 0.682870 test loss: 9.375033
[Epoch 103; Iter    30/   40] train: loss: 0.0087842
[Epoch 103] ogbg-molclintox: 0.669370 val loss: 0.391258
[Epoch 103] ogbg-molclintox: 0.748850 test loss: 7.030481
[Epoch 104; Iter    20/   40] train: loss: 0.0078371
[Epoch 104] ogbg-molclintox: 0.662065 val loss: 0.426534
[Epoch 104] ogbg-molclintox: 0.753023 test loss: 8.296485
[Epoch 105; Iter    10/   40] train: loss: 0.0021471
[Epoch 105; Iter    40/   40] train: loss: 0.0015924
[Epoch 105] ogbg-molclintox: 0.660954 val loss: 0.461941
[Epoch 105] ogbg-molclintox: 0.751499 test loss: 8.810026
[Epoch 106; Iter    30/   40] train: loss: 0.0010820
[Epoch 106] ogbg-molclintox: 0.848757 val loss: 0.164903
[Epoch 106] ogbg-molclintox: 0.739169 test loss: 8.852023
[Epoch 107; Iter    20/   40] train: loss: 0.0018269
[Epoch 107] ogbg-molclintox: 0.850743 val loss: 0.181730
[Epoch 107] ogbg-molclintox: 0.732886 test loss: 8.015119
[Epoch 108; Iter    10/   40] train: loss: 0.0008828
[Epoch 108; Iter    40/   40] train: loss: 0.0310618
[Epoch 108] ogbg-molclintox: 0.851442 val loss: 0.147185
[Epoch 108] ogbg-molclintox: 0.728415 test loss: 9.333701
[Epoch 109; Iter    30/   40] train: loss: 0.0021057
[Epoch 109] ogbg-molclintox: 0.868275 val loss: 0.175113
[Epoch 109] ogbg-molclintox: 0.744529 test loss: 8.261715
[Epoch 110; Iter    20/   40] train: loss: 0.0198677
[Epoch 110] ogbg-molclintox: 0.868137 val loss: 0.219278
[Epoch 110] ogbg-molclintox: 0.733498 test loss: 8.909088
[Epoch 111; Iter    10/   40] train: loss: 0.0048909
[Epoch 111; Iter    40/   40] train: loss: 0.0301159
[Epoch 111] ogbg-molclintox: 0.672554 val loss: 0.365017
[Epoch 111] ogbg-molclintox: 0.741343 test loss: 8.471388
[Epoch 112; Iter    30/   40] train: loss: 0.0818646
[Epoch 112] ogbg-molclintox: 0.677562 val loss: 0.606940
[Epoch 112] ogbg-molclintox: 0.678298 test loss: 9.972320
[Epoch 113; Iter    20/   40] train: loss: 0.0005948
[Epoch 113] ogbg-molclintox: 0.654348 val loss: 0.422380
[Epoch 113] ogbg-molclintox: 0.674862 test loss: 9.590680
[Epoch 114; Iter    10/   40] train: loss: 0.0049634
[Epoch 114; Iter    40/   40] train: loss: 0.0003814
[Epoch 114] ogbg-molclintox: 0.655159 val loss: 0.860188
[Epoch 114] ogbg-molclintox: 0.673924 test loss: 8.892653
[Epoch 115; Iter    30/   40] train: loss: 0.0009847
[Epoch 115] ogbg-molclintox: 0.652837 val loss: 0.799473
[Epoch 115] ogbg-molclintox: 0.674974 test loss: 10.104497
[Epoch 116; Iter    20/   40] train: loss: 0.0023261
[Epoch 116] ogbg-molclintox: 0.639300 val loss: 0.666043
[Epoch 116] ogbg-molclintox: 0.670252 test loss: 9.090291
[Epoch 117; Iter    10/   40] train: loss: 0.0167498
[Epoch 117; Iter    40/   40] train: loss: 0.0002630
[Epoch 117] ogbg-molclintox: 0.640474 val loss: 0.660738
[Epoch 117] ogbg-molclintox: 0.675549 test loss: 8.791790
[Epoch 118; Iter    30/   40] train: loss: 0.0033686
[Epoch 118] ogbg-molclintox: 0.653536 val loss: 0.672686
[Epoch 118] ogbg-molclintox: 0.676311 test loss: 9.349272
[Epoch 119; Iter    20/   40] train: loss: 0.0029136
[Epoch 119] ogbg-molclintox: 0.651301 val loss: 0.902667
[Epoch 119] ogbg-molclintox: 0.676098 test loss: 9.823566
[Epoch 120; Iter    10/   40] train: loss: 0.0009862
[Epoch 120; Iter    40/   40] train: loss: 0.0004293
[Epoch 120] ogbg-molclintox: 0.632757 val loss: 0.732186
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.768409 test loss: 1.057305
[Epoch 121; Iter    30/   40] train: loss: 0.0020101
[Epoch 121] ogbg-molclintox: 0.817777 val loss: 1.086152
[Epoch 121] ogbg-molclintox: 0.770471 test loss: 1.229105
[Epoch 122; Iter    20/   40] train: loss: 0.0004237
[Epoch 122] ogbg-molclintox: 0.843511 val loss: 1.585880
[Epoch 122] ogbg-molclintox: 0.772219 test loss: 1.969358
[Epoch 123; Iter    10/   40] train: loss: 0.0004315
[Epoch 123; Iter    40/   40] train: loss: 0.0059625
[Epoch 123] ogbg-molclintox: 0.832860 val loss: 0.856168
[Epoch 123] ogbg-molclintox: 0.774594 test loss: 1.171461
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 123 epochs. Best model checkpoint was in epoch 63.
Statistics on  val_best_checkpoint
mean_pred: 0.3436306118965149
std_pred: 5.982428073883057
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7866854866924129
rocauc: 0.9575322564759184
ogbg-molclintox: 0.9575322564759184
OGBNanLabelBCEWithLogitsLoss: 0.10294150392292067
Statistics on  test
mean_pred: 0.33508729934692383
std_pred: 4.096211910247803
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6304615916573586
rocauc: 0.8542452994126438
ogbg-molclintox: 0.8542452994126438
OGBNanLabelBCEWithLogitsLoss: 0.3588907152414322
Statistics on  train
mean_pred: 0.10401812940835953
std_pred: 6.9951300621032715
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9769928561368388
rocauc: 0.9923033417462969
ogbg-molclintox: 0.9923033417462969
OGBNanLabelBCEWithLogitsLoss: 0.055968396191019565
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.816915 test loss: 0.473581
[Epoch 121; Iter    30/   40] train: loss: 0.0006871
[Epoch 121] ogbg-molclintox: 0.992308 val loss: 0.095437
[Epoch 121] ogbg-molclintox: 0.816015 test loss: 0.508120
[Epoch 122; Iter    20/   40] train: loss: 0.0003550
[Epoch 122] ogbg-molclintox: 0.991471 val loss: 0.069121
[Epoch 122] ogbg-molclintox: 0.826097 test loss: 0.490166
[Epoch 123; Iter    10/   40] train: loss: 0.0006108
[Epoch 123; Iter    40/   40] train: loss: 0.0023249
[Epoch 123] ogbg-molclintox: 0.993931 val loss: 0.057852
[Epoch 123] ogbg-molclintox: 0.828595 test loss: 0.512321
[Epoch 124; Iter    30/   40] train: loss: 0.0003388
[Epoch 124] ogbg-molclintox: 0.993119 val loss: 0.093650
[Epoch 124] ogbg-molclintox: 0.826859 test loss: 0.576375
[Epoch 125; Iter    20/   40] train: loss: 0.0009205
[Epoch 125] ogbg-molclintox: 0.993706 val loss: 0.066169
[Epoch 125] ogbg-molclintox: 0.832006 test loss: 0.512838
[Epoch 126; Iter    10/   40] train: loss: 0.0002599
[Epoch 126; Iter    40/   40] train: loss: 0.0010569
[Epoch 126] ogbg-molclintox: 0.995804 val loss: 0.055826
[Epoch 126] ogbg-molclintox: 0.830881 test loss: 0.503161
[Epoch 127; Iter    30/   40] train: loss: 0.0007203
[Epoch 127] ogbg-molclintox: 0.994518 val loss: 0.055677
[Epoch 127] ogbg-molclintox: 0.826022 test loss: 0.485504
[Epoch 128; Iter    20/   40] train: loss: 0.0009991
[Epoch 128] ogbg-molclintox: 0.993819 val loss: 0.070131
[Epoch 128] ogbg-molclintox: 0.827908 test loss: 0.502232
[Epoch 129; Iter    10/   40] train: loss: 0.0003473
[Epoch 129; Iter    40/   40] train: loss: 0.0002518
[Epoch 129] ogbg-molclintox: 0.995217 val loss: 0.059876
[Epoch 129] ogbg-molclintox: 0.819776 test loss: 0.476514
[Epoch 130; Iter    30/   40] train: loss: 0.0002253
[Epoch 130] ogbg-molclintox: 0.994518 val loss: 0.064454
[Epoch 130] ogbg-molclintox: 0.822287 test loss: 0.508422
[Epoch 131; Iter    20/   40] train: loss: 0.0021437
[Epoch 131] ogbg-molclintox: 0.993819 val loss: 0.066895
[Epoch 131] ogbg-molclintox: 0.820288 test loss: 0.526737
[Epoch 132; Iter    10/   40] train: loss: 0.0001810
[Epoch 132; Iter    40/   40] train: loss: 0.0002074
[Epoch 132] ogbg-molclintox: 0.993819 val loss: 0.070212
[Epoch 132] ogbg-molclintox: 0.823411 test loss: 0.523175
[Epoch 133; Iter    30/   40] train: loss: 0.0005252
[Epoch 133] ogbg-molclintox: 0.992757 val loss: 0.053769
[Epoch 133] ogbg-molclintox: 0.819526 test loss: 0.474958
[Epoch 134; Iter    20/   40] train: loss: 0.0017717
[Epoch 134] ogbg-molclintox: 0.995217 val loss: 0.052972
[Epoch 134] ogbg-molclintox: 0.805747 test loss: 0.488058
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 134 epochs. Best model checkpoint was in epoch 74.
Statistics on  val_best_checkpoint
mean_pred: -0.22412434220314026
std_pred: 8.403342247009277
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.9999517723655654
rocauc: 0.9986013986013986
ogbg-molclintox: 0.9986013986013986
OGBNanLabelBCEWithLogitsLoss: 0.029730844497680663
Statistics on  test
mean_pred: -0.23606032133102417
std_pred: 6.539848327636719
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6169135054141298
rocauc: 0.8204636290967227
ogbg-molclintox: 0.8204636290967227
OGBNanLabelBCEWithLogitsLoss: 0.34349935576319696
Statistics on  train
mean_pred: 0.17505593597888947
std_pred: 7.916906833648682
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9997413371447683
rocauc: 0.9999646451487337
ogbg-molclintox: 0.9999646451487337
OGBNanLabelBCEWithLogitsLoss: 0.006907037588825915
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.1.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.1.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.1.yml --seed 6 --device cuda:2
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.669789 test loss: 8.214423
[Epoch 121; Iter    30/   40] train: loss: 0.0011039
[Epoch 121] ogbg-molclintox: 0.654822 val loss: 0.453937
[Epoch 121] ogbg-molclintox: 0.669464 test loss: 8.816964
[Epoch 122; Iter    20/   40] train: loss: 0.0049662
[Epoch 122] ogbg-molclintox: 0.648729 val loss: 0.478923
[Epoch 122] ogbg-molclintox: 0.669528 test loss: 10.117473
[Epoch 123; Iter    10/   40] train: loss: 0.0040373
[Epoch 123; Iter    40/   40] train: loss: 0.0003377
[Epoch 123] ogbg-molclintox: 0.680893 val loss: 0.283695
[Epoch 123] ogbg-molclintox: 0.750774 test loss: 8.432205
[Epoch 124; Iter    30/   40] train: loss: 0.0004222
[Epoch 124] ogbg-molclintox: 0.653086 val loss: 0.554089
[Epoch 124] ogbg-molclintox: 0.673125 test loss: 9.409897
[Epoch 125; Iter    20/   40] train: loss: 0.0004650
[Epoch 125] ogbg-molclintox: 0.644919 val loss: 0.381402
[Epoch 125] ogbg-molclintox: 0.708304 test loss: 10.213194
[Epoch 126; Iter    10/   40] train: loss: 0.0017033
[Epoch 126; Iter    40/   40] train: loss: 0.0121245
[Epoch 126] ogbg-molclintox: 0.633931 val loss: 0.443374
[Epoch 126] ogbg-molclintox: 0.671989 test loss: 9.062405
[Epoch 127; Iter    30/   40] train: loss: 0.0023731
[Epoch 127] ogbg-molclintox: 0.630772 val loss: 0.558874
[Epoch 127] ogbg-molclintox: 0.658897 test loss: 9.659257
[Epoch 128; Iter    20/   40] train: loss: 0.0032980
[Epoch 128] ogbg-molclintox: 0.648416 val loss: 0.526848
[Epoch 128] ogbg-molclintox: 0.663544 test loss: 7.859426
[Epoch 129; Iter    10/   40] train: loss: 0.0005298
[Epoch 129; Iter    40/   40] train: loss: 0.0133539
[Epoch 129] ogbg-molclintox: 0.645594 val loss: 0.436160
[Epoch 129] ogbg-molclintox: 0.668792 test loss: 9.419543
[Epoch 130; Iter    30/   40] train: loss: 0.0003580
[Epoch 130] ogbg-molclintox: 0.814667 val loss: 0.241463
[Epoch 130] ogbg-molclintox: 0.737282 test loss: 7.741722
[Epoch 131; Iter    20/   40] train: loss: 0.0002041
[Epoch 131] ogbg-molclintox: 0.801405 val loss: 0.206482
[Epoch 131] ogbg-molclintox: 0.738407 test loss: 9.208105
[Epoch 132; Iter    10/   40] train: loss: 0.0012855
[Epoch 132; Iter    40/   40] train: loss: 0.0017122
[Epoch 132] ogbg-molclintox: 0.796935 val loss: 0.229152
[Epoch 132] ogbg-molclintox: 0.738369 test loss: 9.658092
[Epoch 133; Iter    30/   40] train: loss: 0.0003316
[Epoch 133] ogbg-molclintox: 0.653311 val loss: 0.344374
[Epoch 133] ogbg-molclintox: 0.714187 test loss: 9.855907
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 133 epochs. Best model checkpoint was in epoch 73.
Statistics on  val_best_checkpoint
mean_pred: 1.1044251918792725
std_pred: 29.038171768188477
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.5938122262146017
rocauc: 0.8986572113332676
ogbg-molclintox: 0.8986572113332676
OGBNanLabelBCEWithLogitsLoss: 0.6589580744504928
Statistics on  test
mean_pred: 0.39441055059432983
std_pred: 3.980931282043457
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6154777331166521
rocauc: 0.7784563653425086
ogbg-molclintox: 0.7784563653425086
OGBNanLabelBCEWithLogitsLoss: 0.5389210850000381
Statistics on  train
mean_pred: 0.1314108818769455
std_pred: 7.941044330596924
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9980593651440208
rocauc: 0.9996953701494662
ogbg-molclintox: 0.9996953701494662
OGBNanLabelBCEWithLogitsLoss: 0.014001632470171898
[Epoch 120] ogbg-molclintox: 0.676124 test loss: 2.813061
[Epoch 121; Iter    30/   40] train: loss: 0.0005599
[Epoch 121] ogbg-molclintox: 0.720377 val loss: 0.345736
[Epoch 121] ogbg-molclintox: 0.686818 test loss: 3.008807
[Epoch 122; Iter    20/   40] train: loss: 0.0002517
[Epoch 122] ogbg-molclintox: 0.721913 val loss: 0.363771
[Epoch 122] ogbg-molclintox: 0.688043 test loss: 3.177159
[Epoch 123; Iter    10/   40] train: loss: 0.0007259
[Epoch 123; Iter    40/   40] train: loss: 0.0014823
[Epoch 123] ogbg-molclintox: 0.735112 val loss: 0.342895
[Epoch 123] ogbg-molclintox: 0.685119 test loss: 2.845909
[Epoch 124; Iter    30/   40] train: loss: 0.0002598
[Epoch 124] ogbg-molclintox: 0.722412 val loss: 0.338822
[Epoch 124] ogbg-molclintox: 0.688891 test loss: 2.943680
[Epoch 125; Iter    20/   40] train: loss: 0.0014971
[Epoch 125] ogbg-molclintox: 0.731229 val loss: 0.333938
[Epoch 125] ogbg-molclintox: 0.683995 test loss: 3.012594
[Epoch 126; Iter    10/   40] train: loss: 0.0004915
[Epoch 126; Iter    40/   40] train: loss: 0.0012421
[Epoch 126] ogbg-molclintox: 0.728256 val loss: 0.357325
[Epoch 126] ogbg-molclintox: 0.691290 test loss: 2.973491
[Epoch 127; Iter    30/   40] train: loss: 0.0006749
[Epoch 127] ogbg-molclintox: 0.727370 val loss: 0.339917
[Epoch 127] ogbg-molclintox: 0.681458 test loss: 2.981635
[Epoch 128; Iter    20/   40] train: loss: 0.0003836
[Epoch 128] ogbg-molclintox: 0.738022 val loss: 0.331994
[Epoch 128] ogbg-molclintox: 0.687954 test loss: 3.013063
[Epoch 129; Iter    10/   40] train: loss: 0.0002939
[Epoch 129; Iter    40/   40] train: loss: 0.0000550
[Epoch 129] ogbg-molclintox: 0.721077 val loss: 0.343025
[Epoch 129] ogbg-molclintox: 0.684943 test loss: 3.022149
[Epoch 130; Iter    30/   40] train: loss: 0.0001419
[Epoch 130] ogbg-molclintox: 0.724036 val loss: 0.341004
[Epoch 130] ogbg-molclintox: 0.685119 test loss: 2.898033
[Epoch 131; Iter    20/   40] train: loss: 0.0014935
[Epoch 131] ogbg-molclintox: 0.704631 val loss: 0.353710
[Epoch 131] ogbg-molclintox: 0.685082 test loss: 3.183066
[Epoch 132; Iter    10/   40] train: loss: 0.0001425
[Epoch 132; Iter    40/   40] train: loss: 0.0001294
[Epoch 132] ogbg-molclintox: 0.714196 val loss: 0.346233
[Epoch 132] ogbg-molclintox: 0.682358 test loss: 3.134043
[Epoch 133; Iter    30/   40] train: loss: 0.0004725
[Epoch 133] ogbg-molclintox: 0.699462 val loss: 0.365537
[Epoch 133] ogbg-molclintox: 0.682082 test loss: 3.104978
[Epoch 134; Iter    20/   40] train: loss: 0.0023258
[Epoch 134] ogbg-molclintox: 0.721576 val loss: 0.338253
[Epoch 134] ogbg-molclintox: 0.692238 test loss: 2.750152
[Epoch 135; Iter    10/   40] train: loss: 0.0012327
[Epoch 135; Iter    40/   40] train: loss: 0.0042124
[Epoch 135] ogbg-molclintox: 0.741406 val loss: 0.322989
[Epoch 135] ogbg-molclintox: 0.685556 test loss: 2.696939
[Epoch 136; Iter    30/   40] train: loss: 0.0002199
[Epoch 136] ogbg-molclintox: 0.752419 val loss: 0.338772
[Epoch 136] ogbg-molclintox: 0.685332 test loss: 2.472391
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 136 epochs. Best model checkpoint was in epoch 76.
Statistics on  val_best_checkpoint
mean_pred: -2.2361230850219727
std_pred: 71.77277374267578
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.6298478641242398
rocauc: 0.8939237992054894
ogbg-molclintox: 0.8939237992054894
OGBNanLabelBCEWithLogitsLoss: 9.820107823610305
Statistics on  test
mean_pred: -3.9157114028930664
std_pred: 99.12675476074219
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.5255867639868889
rocauc: 0.5971753032356724
ogbg-molclintox: 0.5971753032356724
OGBNanLabelBCEWithLogitsLoss: 23.29676682949066
Statistics on  train
mean_pred: 0.2271878570318222
std_pred: 16.39508819580078
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9563093614865551
rocauc: 0.9932274989850032
ogbg-molclintox: 0.9932274989850032
OGBNanLabelBCEWithLogitsLoss: 0.2916151991579682
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.2.yml --seed 4 --device cuda:3
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.2.yml --seed 5 --device cuda:3
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.2.yml --seed 6 --device cuda:3
All runs completed.
[Epoch 76] ogbg-molclintox: 0.978747 val loss: 0.063100
[Epoch 76] ogbg-molclintox: 0.834344 test loss: 11.543672
[Epoch 77; Iter    20/   40] train: loss: 0.0143761
[Epoch 77] ogbg-molclintox: 0.962027 val loss: 0.071818
[Epoch 77] ogbg-molclintox: 0.847559 test loss: 11.532219
[Epoch 78; Iter    10/   40] train: loss: 0.1430707
[Epoch 78; Iter    40/   40] train: loss: 0.0998539
[Epoch 78] ogbg-molclintox: 0.963450 val loss: 0.067118
[Epoch 78] ogbg-molclintox: 0.854832 test loss: 8.227569
[Epoch 79; Iter    30/   40] train: loss: 0.0277511
[Epoch 79] ogbg-molclintox: 0.976512 val loss: 0.068274
[Epoch 79] ogbg-molclintox: 0.840552 test loss: 10.256344
[Epoch 80; Iter    20/   40] train: loss: 0.0437458
[Epoch 80] ogbg-molclintox: 0.952187 val loss: 0.086016
[Epoch 80] ogbg-molclintox: 0.845486 test loss: 12.129324
[Epoch 81; Iter    10/   40] train: loss: 0.0612320
[Epoch 81; Iter    40/   40] train: loss: 0.0236313
[Epoch 81] ogbg-molclintox: 0.970081 val loss: 0.069446
[Epoch 81] ogbg-molclintox: 0.835793 test loss: 11.553594
[Epoch 82; Iter    30/   40] train: loss: 0.0363204
[Epoch 82] ogbg-molclintox: 0.970643 val loss: 0.083680
[Epoch 82] ogbg-molclintox: 0.826249 test loss: 12.316744
[Epoch 83; Iter    20/   40] train: loss: 0.0563784
[Epoch 83] ogbg-molclintox: 0.954647 val loss: 0.091423
[Epoch 83] ogbg-molclintox: 0.853394 test loss: 9.728644
[Epoch 84; Iter    10/   40] train: loss: 0.0179576
[Epoch 84; Iter    40/   40] train: loss: 0.2008066
[Epoch 84] ogbg-molclintox: 0.971705 val loss: 0.066654
[Epoch 84] ogbg-molclintox: 0.820841 test loss: 9.672703
[Epoch 85; Iter    30/   40] train: loss: 0.0078590
[Epoch 85] ogbg-molclintox: 0.949640 val loss: 0.087111
[Epoch 85] ogbg-molclintox: 0.828349 test loss: 12.506951
[Epoch 86; Iter    20/   40] train: loss: 0.0508348
[Epoch 86] ogbg-molclintox: 0.966335 val loss: 0.082679
[Epoch 86] ogbg-molclintox: 0.834333 test loss: 8.710867
[Epoch 87; Iter    10/   40] train: loss: 0.0675768
[Epoch 87; Iter    40/   40] train: loss: 0.0445418
[Epoch 87] ogbg-molclintox: 0.940387 val loss: 0.107853
[Epoch 87] ogbg-molclintox: 0.818140 test loss: 13.222213
[Epoch 88; Iter    30/   40] train: loss: 0.0248324
[Epoch 88] ogbg-molclintox: 0.967147 val loss: 0.076978
[Epoch 88] ogbg-molclintox: 0.873781 test loss: 8.210134
[Epoch 89; Iter    20/   40] train: loss: 0.0679428
[Epoch 89] ogbg-molclintox: 0.954647 val loss: 0.081219
[Epoch 89] ogbg-molclintox: 0.856154 test loss: 10.119705
[Epoch 90; Iter    10/   40] train: loss: 0.0679912
[Epoch 90; Iter    40/   40] train: loss: 0.1802697
[Epoch 90] ogbg-molclintox: 0.933956 val loss: 0.093945
[Epoch 90] ogbg-molclintox: 0.815432 test loss: 11.167751
[Epoch 91; Iter    30/   40] train: loss: 0.0483919
[Epoch 91] ogbg-molclintox: 0.943434 val loss: 0.084477
[Epoch 91] ogbg-molclintox: 0.824763 test loss: 11.132743
[Epoch 92; Iter    20/   40] train: loss: 0.1318894
[Epoch 92] ogbg-molclintox: 0.935042 val loss: 0.094074
[Epoch 92] ogbg-molclintox: 0.823265 test loss: 13.020151
[Epoch 93; Iter    10/   40] train: loss: 0.0221499
[Epoch 93; Iter    40/   40] train: loss: 0.0137743
[Epoch 93] ogbg-molclintox: 0.892037 val loss: 0.100006
[Epoch 93] ogbg-molclintox: 0.827064 test loss: 17.751087
[Epoch 94; Iter    30/   40] train: loss: 0.0531250
[Epoch 94] ogbg-molclintox: 0.955097 val loss: 0.078757
[Epoch 94] ogbg-molclintox: 0.822466 test loss: 13.785321
[Epoch 95; Iter    20/   40] train: loss: 0.0383247
[Epoch 95] ogbg-molclintox: 0.957444 val loss: 0.074410
[Epoch 95] ogbg-molclintox: 0.831509 test loss: 12.570924
[Epoch 96; Iter    10/   40] train: loss: 0.0291792
[Epoch 96; Iter    40/   40] train: loss: 0.0292911
[Epoch 96] ogbg-molclintox: 0.954960 val loss: 0.087941
[Epoch 96] ogbg-molclintox: 0.821166 test loss: 12.305048
[Epoch 97; Iter    30/   40] train: loss: 0.0059870
[Epoch 97] ogbg-molclintox: 0.976937 val loss: 0.067641
[Epoch 97] ogbg-molclintox: 0.849035 test loss: 10.114719
[Epoch 98; Iter    20/   40] train: loss: 0.0142331
[Epoch 98] ogbg-molclintox: 0.947380 val loss: 0.096556
[Epoch 98] ogbg-molclintox: 0.809261 test loss: 9.174938
[Epoch 99; Iter    10/   40] train: loss: 0.1054533
[Epoch 99; Iter    40/   40] train: loss: 0.0094167
[Epoch 99] ogbg-molclintox: 0.958168 val loss: 0.076225
[Epoch 99] ogbg-molclintox: 0.863714 test loss: 6.024874
[Epoch 100; Iter    30/   40] train: loss: 0.0125855
[Epoch 100] ogbg-molclintox: 0.907808 val loss: 0.093364
[Epoch 100] ogbg-molclintox: 0.818667 test loss: 6.285673
[Epoch 101; Iter    20/   40] train: loss: 0.0696681
[Epoch 101] ogbg-molclintox: 0.951014 val loss: 0.112839
[Epoch 101] ogbg-molclintox: 0.777706 test loss: 9.266826
[Epoch 102; Iter    10/   40] train: loss: 0.0791691
[Epoch 102; Iter    40/   40] train: loss: 0.1085736
[Epoch 102] ogbg-molclintox: 0.977798 val loss: 0.072413
[Epoch 102] ogbg-molclintox: 0.831722 test loss: 8.884023
[Epoch 103; Iter    30/   40] train: loss: 0.0683491
[Epoch 103] ogbg-molclintox: 0.940250 val loss: 0.100049
[Epoch 103] ogbg-molclintox: 0.809373 test loss: 9.564777
[Epoch 104; Iter    20/   40] train: loss: 0.0282249
[Epoch 104] ogbg-molclintox: 0.910992 val loss: 0.094479
[Epoch 104] ogbg-molclintox: 0.840204 test loss: 8.038538
[Epoch 105; Iter    10/   40] train: loss: 0.0365108
[Epoch 105; Iter    40/   40] train: loss: 0.0310168
[Epoch 105] ogbg-molclintox: 0.959792 val loss: 0.100225
[Epoch 105] ogbg-molclintox: 0.830310 test loss: 6.973873
[Epoch 106; Iter    30/   40] train: loss: 0.0954534
[Epoch 106] ogbg-molclintox: 0.964350 val loss: 0.080835
[Epoch 106] ogbg-molclintox: 0.835457 test loss: 8.889118
[Epoch 107; Iter    20/   40] train: loss: 0.0783731
[Epoch 107] ogbg-molclintox: 0.936754 val loss: 0.102544
[Epoch 107] ogbg-molclintox: 0.798967 test loss: 10.018181
[Epoch 108; Iter    10/   40] train: loss: 0.0063270
[Epoch 108; Iter    40/   40] train: loss: 0.0300641
[Epoch 108] ogbg-molclintox: 0.950539 val loss: 0.086634
[Epoch 108] ogbg-molclintox: 0.838692 test loss: 8.849476
[Epoch 109; Iter    30/   40] train: loss: 0.0749773
[Epoch 109] ogbg-molclintox: 0.938514 val loss: 0.099915
[Epoch 109] ogbg-molclintox: 0.843551 test loss: 10.439722
[Epoch 110; Iter    20/   40] train: loss: 0.0994495
[Epoch 110] ogbg-molclintox: 0.922381 val loss: 0.104779
[Epoch 110] ogbg-molclintox: 0.814196 test loss: 9.368322
[Epoch 111; Iter    10/   40] train: loss: 0.0777599
[Epoch 111; Iter    40/   40] train: loss: 0.1351593
[Epoch 111] ogbg-molclintox: 0.911280 val loss: 0.105910
[Epoch 111] ogbg-molclintox: 0.821341 test loss: 8.506058
[Epoch 112; Iter    30/   40] train: loss: 0.3128518
[Epoch 112] ogbg-molclintox: 0.947493 val loss: 0.104625
[Epoch 112] ogbg-molclintox: 0.817456 test loss: 9.686906
[Epoch 113; Iter    20/   40] train: loss: 0.0184425
[Epoch 113] ogbg-molclintox: 0.963988 val loss: 0.090897
[Epoch 113] ogbg-molclintox: 0.832345 test loss: 12.299093
[Epoch 114; Iter    10/   40] train: loss: 0.0947381
[Epoch 114; Iter    40/   40] train: loss: 0.0076867
[Epoch 114] ogbg-molclintox: 0.923442 val loss: 0.102080
[Epoch 114] ogbg-molclintox: 0.829185 test loss: 7.656518
[Epoch 115; Iter    30/   40] train: loss: 0.0176105
[Epoch 115] ogbg-molclintox: 0.946456 val loss: 0.101262
[Epoch 115] ogbg-molclintox: 0.812220 test loss: 7.838345
[Epoch 116; Iter    20/   40] train: loss: 0.0106166
[Epoch 116] ogbg-molclintox: 0.938289 val loss: 0.099928
[Epoch 116] ogbg-molclintox: 0.835132 test loss: 9.055467
[Epoch 117; Iter    10/   40] train: loss: 0.0492265
[Epoch 117; Iter    40/   40] train: loss: 0.0035504
[Epoch 117] ogbg-molclintox: 0.952862 val loss: 0.088164
[Epoch 117] ogbg-molclintox: 0.829936 test loss: 9.608577
[Epoch 118; Iter    30/   40] train: loss: 0.0919432
[Epoch 118] ogbg-molclintox: 0.953112 val loss: 0.081632
[Epoch 118] ogbg-molclintox: 0.842864 test loss: 6.415507
[Epoch 119; Iter    20/   40] train: loss: 0.0316655
[Epoch 119] ogbg-molclintox: 0.936978 val loss: 0.100385
[Epoch 119] ogbg-molclintox: 0.823153 test loss: 7.656600
[Epoch 120; Iter    10/   40] train: loss: 0.0252030
[Epoch 120; Iter    40/   40] train: loss: 0.0055089
[Epoch 120] ogbg-molclintox: 0.921906 val loss: 0.096694
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.845438 test loss: 7.353354
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: 0.19540517032146454
std_pred: 5.184990882873535
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.9651320854479764
rocauc: 0.9940436324239141
ogbg-molclintox: 0.9940436324239141
OGBNanLabelBCEWithLogitsLoss: 0.06103826453909278
Statistics on  test
mean_pred: 0.12358541041612625
std_pred: 8.4865083694458
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7009760114407944
rocauc: 0.8450118166336495
ogbg-molclintox: 0.8450118166336495
OGBNanLabelBCEWithLogitsLoss: 0.7778774037957191
Statistics on  train
mean_pred: 0.22917230427265167
std_pred: 5.351119518280029
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9186424503003301
rocauc: 0.9801855940033568
ogbg-molclintox: 0.9801855940033568
OGBNanLabelBCEWithLogitsLoss: 0.09840185306966305
[Epoch 76] ogbg-molclintox: 0.923667 val loss: 0.107496
[Epoch 76] ogbg-molclintox: 0.891456 test loss: 0.391885
[Epoch 77; Iter    20/   40] train: loss: 0.0341511
[Epoch 77] ogbg-molclintox: 0.940861 val loss: 0.089443
[Epoch 77] ogbg-molclintox: 0.873893 test loss: 1.970131
[Epoch 78; Iter    10/   40] train: loss: 0.0704227
[Epoch 78; Iter    40/   40] train: loss: 0.3365185
[Epoch 78] ogbg-molclintox: 0.825944 val loss: 0.129659
[Epoch 78] ogbg-molclintox: 0.854720 test loss: 3.113159
[Epoch 79; Iter    30/   40] train: loss: 0.1611588
[Epoch 79] ogbg-molclintox: 0.968932 val loss: 0.075558
[Epoch 79] ogbg-molclintox: 0.861514 test loss: 0.219742
[Epoch 80; Iter    20/   40] train: loss: 0.0586804
[Epoch 80] ogbg-molclintox: 0.866539 val loss: 0.134211
[Epoch 80] ogbg-molclintox: 0.835969 test loss: 0.201851
[Epoch 81; Iter    10/   40] train: loss: 0.1331829
[Epoch 81; Iter    40/   40] train: loss: 0.0401802
[Epoch 81] ogbg-molclintox: 0.899455 val loss: 0.106608
[Epoch 81] ogbg-molclintox: 0.858227 test loss: 0.169265
[Epoch 82; Iter    30/   40] train: loss: 0.0638601
[Epoch 82] ogbg-molclintox: 0.940387 val loss: 0.095377
[Epoch 82] ogbg-molclintox: 0.830847 test loss: 0.195816
[Epoch 83; Iter    20/   40] train: loss: 0.1205901
[Epoch 83] ogbg-molclintox: 0.816491 val loss: 0.443919
[Epoch 83] ogbg-molclintox: 0.801851 test loss: 0.214036
[Epoch 84; Iter    10/   40] train: loss: 0.0154416
[Epoch 84; Iter    40/   40] train: loss: 0.2135922
[Epoch 84] ogbg-molclintox: 0.928924 val loss: 0.103863
[Epoch 84] ogbg-molclintox: 0.850633 test loss: 0.208118
[Epoch 85; Iter    30/   40] train: loss: 0.0556174
[Epoch 85] ogbg-molclintox: 0.874006 val loss: 0.136016
[Epoch 85] ogbg-molclintox: 0.884038 test loss: 0.185397
[Epoch 86; Iter    20/   40] train: loss: 0.0583573
[Epoch 86] ogbg-molclintox: 0.951126 val loss: 0.120284
[Epoch 86] ogbg-molclintox: 0.865713 test loss: 0.182492
[Epoch 87; Iter    10/   40] train: loss: 0.0433425
[Epoch 87; Iter    40/   40] train: loss: 0.1019556
[Epoch 87] ogbg-molclintox: 0.898780 val loss: 0.122061
[Epoch 87] ogbg-molclintox: 0.866512 test loss: 0.195539
[Epoch 88; Iter    30/   40] train: loss: 0.1124741
[Epoch 88] ogbg-molclintox: 0.920308 val loss: 0.126924
[Epoch 88] ogbg-molclintox: 0.881065 test loss: 0.207831
[Epoch 89; Iter    20/   40] train: loss: 0.2648556
[Epoch 89] ogbg-molclintox: 0.941786 val loss: 0.102980
[Epoch 89] ogbg-molclintox: 0.875480 test loss: 0.207670
[Epoch 90; Iter    10/   40] train: loss: 0.1913759
[Epoch 90; Iter    40/   40] train: loss: 0.0463275
[Epoch 90] ogbg-molclintox: 0.911754 val loss: 0.127719
[Epoch 90] ogbg-molclintox: 0.844862 test loss: 0.191039
[Epoch 91; Iter    30/   40] train: loss: 0.0116284
[Epoch 91] ogbg-molclintox: 0.954060 val loss: 0.094465
[Epoch 91] ogbg-molclintox: 0.893331 test loss: 0.183598
[Epoch 92; Iter    20/   40] train: loss: 0.0914617
[Epoch 92] ogbg-molclintox: 0.901989 val loss: 0.098457
[Epoch 92] ogbg-molclintox: 0.908683 test loss: 0.140169
[Epoch 93; Iter    10/   40] train: loss: 0.0245720
[Epoch 93; Iter    40/   40] train: loss: 0.0286795
[Epoch 93] ogbg-molclintox: 0.921369 val loss: 0.141868
[Epoch 93] ogbg-molclintox: 0.887923 test loss: 0.172179
[Epoch 94; Iter    30/   40] train: loss: 0.0060633
[Epoch 94] ogbg-molclintox: 0.887753 val loss: 0.091512
[Epoch 94] ogbg-molclintox: 0.925149 test loss: 0.132746
[Epoch 95; Iter    20/   40] train: loss: 0.0620588
[Epoch 95] ogbg-molclintox: 0.920870 val loss: 0.151111
[Epoch 95] ogbg-molclintox: 0.889271 test loss: 0.160931
[Epoch 96; Iter    10/   40] train: loss: 0.0296699
[Epoch 96; Iter    40/   40] train: loss: 0.2049796
[Epoch 96] ogbg-molclintox: 0.922068 val loss: 0.092896
[Epoch 96] ogbg-molclintox: 0.910196 test loss: 0.189356
[Epoch 97; Iter    30/   40] train: loss: 0.0308068
[Epoch 97] ogbg-molclintox: 0.848220 val loss: 0.117481
[Epoch 97] ogbg-molclintox: 0.866822 test loss: 0.342555
[Epoch 98; Iter    20/   40] train: loss: 0.0511708
[Epoch 98] ogbg-molclintox: 0.931321 val loss: 0.092895
[Epoch 98] ogbg-molclintox: 0.889559 test loss: 0.253189
[Epoch 99; Iter    10/   40] train: loss: 0.1579965
[Epoch 99; Iter    40/   40] train: loss: 0.0182649
[Epoch 99] ogbg-molclintox: 0.891338 val loss: 0.107917
[Epoch 99] ogbg-molclintox: 0.854469 test loss: 0.462466
[Epoch 100; Iter    30/   40] train: loss: 0.0512200
[Epoch 100] ogbg-molclintox: 0.929174 val loss: 0.104339
[Epoch 100] ogbg-molclintox: 0.856517 test loss: 0.344731
[Epoch 101; Iter    20/   40] train: loss: 0.1188329
[Epoch 101] ogbg-molclintox: 0.887142 val loss: 0.115774
[Epoch 101] ogbg-molclintox: 0.886810 test loss: 0.311093
[Epoch 102; Iter    10/   40] train: loss: 0.0127097
[Epoch 102; Iter    40/   40] train: loss: 0.1415060
[Epoch 102] ogbg-molclintox: 0.927687 val loss: 0.097345
[Epoch 102] ogbg-molclintox: 0.876680 test loss: 0.328968
[Epoch 103; Iter    30/   40] train: loss: 0.0193503
[Epoch 103] ogbg-molclintox: 0.832561 val loss: 0.145397
[Epoch 103] ogbg-molclintox: 0.838729 test loss: 0.274544
[Epoch 104; Iter    20/   40] train: loss: 0.0335238
[Epoch 104] ogbg-molclintox: 0.894472 val loss: 0.116624
[Epoch 104] ogbg-molclintox: 0.854619 test loss: 0.502710
[Epoch 105; Iter    10/   40] train: loss: 0.0316200
[Epoch 105; Iter    40/   40] train: loss: 0.0117482
[Epoch 105] ogbg-molclintox: 0.933419 val loss: 0.095987
[Epoch 105] ogbg-molclintox: 0.897455 test loss: 2.630958
[Epoch 106; Iter    30/   40] train: loss: 0.0372837
[Epoch 106] ogbg-molclintox: 0.928049 val loss: 0.109142
[Epoch 106] ogbg-molclintox: 0.891370 test loss: 9.394664
[Epoch 107; Iter    20/   40] train: loss: 0.0814127
[Epoch 107] ogbg-molclintox: 0.952212 val loss: 0.094900
[Epoch 107] ogbg-molclintox: 0.886709 test loss: 9.827839
[Epoch 108; Iter    10/   40] train: loss: 0.0377677
[Epoch 108; Iter    40/   40] train: loss: 0.0071929
[Epoch 108] ogbg-molclintox: 0.858832 val loss: 0.128855
[Epoch 108] ogbg-molclintox: 0.812560 test loss: 7.948651
[Epoch 109; Iter    30/   40] train: loss: 0.0376717
[Epoch 109] ogbg-molclintox: 0.886404 val loss: 0.112005
[Epoch 109] ogbg-molclintox: 0.873605 test loss: 11.770721
[Epoch 110; Iter    20/   40] train: loss: 0.0434480
[Epoch 110] ogbg-molclintox: 0.948329 val loss: 0.100357
[Epoch 110] ogbg-molclintox: 0.873243 test loss: 11.961979
[Epoch 111; Iter    10/   40] train: loss: 0.0175563
[Epoch 111; Iter    40/   40] train: loss: 0.0020410
[Epoch 111] ogbg-molclintox: 0.951376 val loss: 0.102337
[Epoch 111] ogbg-molclintox: 0.876941 test loss: 11.507464
[Epoch 112; Iter    30/   40] train: loss: 0.0489308
[Epoch 112] ogbg-molclintox: 0.916024 val loss: 0.110151
[Epoch 112] ogbg-molclintox: 0.853618 test loss: 11.350308
[Epoch 113; Iter    20/   40] train: loss: 0.1073031
[Epoch 113] ogbg-molclintox: 0.926538 val loss: 0.107665
[Epoch 113] ogbg-molclintox: 0.860801 test loss: 11.072677
[Epoch 114; Iter    10/   40] train: loss: 0.0330196
[Epoch 114; Iter    40/   40] train: loss: 0.2322651
[Epoch 114] ogbg-molclintox: 0.950564 val loss: 0.099834
[Epoch 114] ogbg-molclintox: 0.870584 test loss: 11.769094
[Epoch 115; Iter    30/   40] train: loss: 0.0957641
[Epoch 115] ogbg-molclintox: 0.947879 val loss: 0.107132
[Epoch 115] ogbg-molclintox: 0.866385 test loss: 12.277618
[Epoch 116; Iter    20/   40] train: loss: 0.0468742
[Epoch 116] ogbg-molclintox: 0.932495 val loss: 0.115044
[Epoch 116] ogbg-molclintox: 0.846286 test loss: 11.856515
[Epoch 117; Iter    10/   40] train: loss: 0.0455975
[Epoch 117; Iter    40/   40] train: loss: 0.0425777
[Epoch 117] ogbg-molclintox: 0.933644 val loss: 0.106871
[Epoch 117] ogbg-molclintox: 0.862037 test loss: 10.725265
[Epoch 118; Iter    30/   40] train: loss: 0.0314282
[Epoch 118] ogbg-molclintox: 0.957919 val loss: 0.108742
[Epoch 118] ogbg-molclintox: 0.866774 test loss: 10.664590
[Epoch 119; Iter    20/   40] train: loss: 0.0613282
[Epoch 119] ogbg-molclintox: 0.919545 val loss: 0.112900
[Epoch 119] ogbg-molclintox: 0.872881 test loss: 10.181742
[Epoch 120; Iter    10/   40] train: loss: 0.1742932
[Epoch 120; Iter    40/   40] train: loss: 0.0047811
[Epoch 120] ogbg-molclintox: 0.952437 val loss: 0.107235
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.871133 test loss: 11.357682
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 48.
Statistics on  val_best_checkpoint
mean_pred: 0.2783963680267334
std_pred: 5.166340351104736
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.8807073123680711
rocauc: 0.9847910305656785
ogbg-molclintox: 0.9847910305656785
OGBNanLabelBCEWithLogitsLoss: 0.07269817553460597
Statistics on  test
mean_pred: 0.17041891813278198
std_pred: 4.505177974700928
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7321070611604619
rocauc: 0.8469989226010497
ogbg-molclintox: 0.8469989226010497
OGBNanLabelBCEWithLogitsLoss: 0.18852763921022414
Statistics on  train
mean_pred: 0.233964204788208
std_pred: 5.054538726806641
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.8928037736116436
rocauc: 0.9754555452311889
ogbg-molclintox: 0.9754555452311889
OGBNanLabelBCEWithLogitsLoss: 0.10597109799273312
[Epoch 76] ogbg-molclintox: 0.976013 val loss: 0.110689
[Epoch 76] ogbg-molclintox: 0.872496 test loss: 0.216498
[Epoch 77; Iter    20/   40] train: loss: 0.0132796
[Epoch 77] ogbg-molclintox: 0.951752 val loss: 0.085367
[Epoch 77] ogbg-molclintox: 0.873968 test loss: 0.167995
[Epoch 78; Iter    10/   40] train: loss: 0.0151824
[Epoch 78; Iter    40/   40] train: loss: 0.0058550
[Epoch 78] ogbg-molclintox: 0.975514 val loss: 0.079177
[Epoch 78] ogbg-molclintox: 0.853207 test loss: 0.174178
[Epoch 79; Iter    30/   40] train: loss: 0.1454252
[Epoch 79] ogbg-molclintox: 0.984566 val loss: 0.056063
[Epoch 79] ogbg-molclintox: 0.873546 test loss: 0.171889
[Epoch 80; Iter    20/   40] train: loss: 0.0772777
[Epoch 80] ogbg-molclintox: 0.977187 val loss: 0.083305
[Epoch 80] ogbg-molclintox: 0.862254 test loss: 0.196607
[Epoch 81; Iter    10/   40] train: loss: 0.0407098
[Epoch 81; Iter    40/   40] train: loss: 0.0145639
[Epoch 81] ogbg-molclintox: 0.911167 val loss: 0.078710
[Epoch 81] ogbg-molclintox: 0.858929 test loss: 0.178158
[Epoch 82; Iter    30/   40] train: loss: 0.0250318
[Epoch 82] ogbg-molclintox: 0.982219 val loss: 0.065017
[Epoch 82] ogbg-molclintox: 0.876030 test loss: 0.179610
[Epoch 83; Iter    20/   40] train: loss: 0.0229089
[Epoch 83] ogbg-molclintox: 0.964300 val loss: 0.080887
[Epoch 83] ogbg-molclintox: 0.855045 test loss: 0.181504
[Epoch 84; Iter    10/   40] train: loss: 0.0142985
[Epoch 84; Iter    40/   40] train: loss: 0.0087905
[Epoch 84] ogbg-molclintox: 0.933408 val loss: 0.097493
[Epoch 84] ogbg-molclintox: 0.866762 test loss: 0.186290
[Epoch 85; Iter    30/   40] train: loss: 0.0309263
[Epoch 85] ogbg-molclintox: 0.969245 val loss: 0.081905
[Epoch 85] ogbg-molclintox: 0.872358 test loss: 0.176514
[Epoch 86; Iter    20/   40] train: loss: 0.0398489
[Epoch 86] ogbg-molclintox: 0.968321 val loss: 0.081655
[Epoch 86] ogbg-molclintox: 0.878390 test loss: 0.183492
[Epoch 87; Iter    10/   40] train: loss: 0.1114142
[Epoch 87; Iter    40/   40] train: loss: 0.0210319
[Epoch 87] ogbg-molclintox: 0.971705 val loss: 0.077683
[Epoch 87] ogbg-molclintox: 0.902139 test loss: 0.158901
[Epoch 88; Iter    30/   40] train: loss: 0.0481329
[Epoch 88] ogbg-molclintox: 0.921931 val loss: 0.090420
[Epoch 88] ogbg-molclintox: 0.892607 test loss: 0.166977
[Epoch 89; Iter    20/   40] train: loss: 0.0552872
[Epoch 89] ogbg-molclintox: 0.860083 val loss: 0.102617
[Epoch 89] ogbg-molclintox: 0.873968 test loss: 0.172740
[Epoch 90; Iter    10/   40] train: loss: 0.0159495
[Epoch 90; Iter    40/   40] train: loss: 0.0094786
[Epoch 90] ogbg-molclintox: 0.946818 val loss: 0.086483
[Epoch 90] ogbg-molclintox: 0.864226 test loss: 0.182538
[Epoch 91; Iter    30/   40] train: loss: 0.0303319
[Epoch 91] ogbg-molclintox: 0.882559 val loss: 0.099368
[Epoch 91] ogbg-molclintox: 0.873669 test loss: 0.183228
[Epoch 92; Iter    20/   40] train: loss: 0.0320422
[Epoch 92] ogbg-molclintox: 0.971929 val loss: 0.086829
[Epoch 92] ogbg-molclintox: 0.869086 test loss: 0.185045
[Epoch 93; Iter    10/   40] train: loss: 0.0305402
[Epoch 93; Iter    40/   40] train: loss: 0.2085828
[Epoch 93] ogbg-molclintox: 0.945194 val loss: 0.088786
[Epoch 93] ogbg-molclintox: 0.887997 test loss: 0.162020
[Epoch 94; Iter    30/   40] train: loss: 0.0291844
[Epoch 94] ogbg-molclintox: 0.973103 val loss: 0.079847
[Epoch 94] ogbg-molclintox: 0.870109 test loss: 0.172368
[Epoch 95; Iter    20/   40] train: loss: 0.0072827
[Epoch 95] ogbg-molclintox: 0.925653 val loss: 0.096549
[Epoch 95] ogbg-molclintox: 0.851608 test loss: 0.187999
[Epoch 96; Iter    10/   40] train: loss: 0.0464585
[Epoch 96; Iter    40/   40] train: loss: 0.0526600
[Epoch 96] ogbg-molclintox: 0.930035 val loss: 0.100529
[Epoch 96] ogbg-molclintox: 0.872108 test loss: 0.178590
[Epoch 97; Iter    30/   40] train: loss: 0.0427565
[Epoch 97] ogbg-molclintox: 0.874568 val loss: 0.114299
[Epoch 97] ogbg-molclintox: 0.881588 test loss: 0.183393
[Epoch 98; Iter    20/   40] train: loss: 0.0873072
[Epoch 98] ogbg-molclintox: 0.900878 val loss: 0.118125
[Epoch 98] ogbg-molclintox: 0.859766 test loss: 0.190799
[Epoch 99; Iter    10/   40] train: loss: 0.0178421
[Epoch 99; Iter    40/   40] train: loss: 0.0383534
[Epoch 99] ogbg-molclintox: 0.879713 val loss: 0.108403
[Epoch 99] ogbg-molclintox: 0.876941 test loss: 0.178730
[Epoch 100; Iter    30/   40] train: loss: 0.0259426
[Epoch 100] ogbg-molclintox: 0.832389 val loss: 0.136339
[Epoch 100] ogbg-molclintox: 0.892043 test loss: 0.187384
[Epoch 101; Iter    20/   40] train: loss: 0.0263362
[Epoch 101] ogbg-molclintox: 0.939189 val loss: 0.094436
[Epoch 101] ogbg-molclintox: 0.877292 test loss: 0.180930
[Epoch 102; Iter    10/   40] train: loss: 0.0766971
[Epoch 102; Iter    40/   40] train: loss: 0.0072819
[Epoch 102] ogbg-molclintox: 0.857124 val loss: 0.125422
[Epoch 102] ogbg-molclintox: 0.877277 test loss: 0.188383
[Epoch 103; Iter    30/   40] train: loss: 0.0995157
[Epoch 103] ogbg-molclintox: 0.907822 val loss: 0.096773
[Epoch 103] ogbg-molclintox: 0.885185 test loss: 0.207477
[Epoch 104; Iter    20/   40] train: loss: 0.0290233
[Epoch 104] ogbg-molclintox: 0.821674 val loss: 0.148148
[Epoch 104] ogbg-molclintox: 0.888845 test loss: 0.189449
[Epoch 105; Iter    10/   40] train: loss: 0.0066780
[Epoch 105; Iter    40/   40] train: loss: 0.1790119
[Epoch 105] ogbg-molclintox: 0.907808 val loss: 0.108274
[Epoch 105] ogbg-molclintox: 0.845699 test loss: 0.198131
[Epoch 106; Iter    30/   40] train: loss: 0.1557377
[Epoch 106] ogbg-molclintox: 0.926865 val loss: 0.118383
[Epoch 106] ogbg-molclintox: 0.833907 test loss: 0.224235
[Epoch 107; Iter    20/   40] train: loss: 0.0394222
[Epoch 107] ogbg-molclintox: 0.945981 val loss: 0.102232
[Epoch 107] ogbg-molclintox: 0.871095 test loss: 0.189393
[Epoch 108; Iter    10/   40] train: loss: 0.0074851
[Epoch 108; Iter    40/   40] train: loss: 0.0157618
[Epoch 108] ogbg-molclintox: 0.803067 val loss: 0.149773
[Epoch 108] ogbg-molclintox: 0.772633 test loss: 0.243673
[Epoch 109; Iter    30/   40] train: loss: 0.0833574
[Epoch 109] ogbg-molclintox: 0.860832 val loss: 0.113132
[Epoch 109] ogbg-molclintox: 0.799404 test loss: 0.227117
[Epoch 110; Iter    20/   40] train: loss: 0.0469967
[Epoch 110] ogbg-molclintox: 0.879400 val loss: 0.124544
[Epoch 110] ogbg-molclintox: 0.796969 test loss: 0.238673
[Epoch 111; Iter    10/   40] train: loss: 0.0134680
[Epoch 111; Iter    40/   40] train: loss: 0.0229471
[Epoch 111] ogbg-molclintox: 0.873894 val loss: 0.116539
[Epoch 111] ogbg-molclintox: 0.857103 test loss: 0.217781
[Epoch 112; Iter    30/   40] train: loss: 0.0527645
[Epoch 112] ogbg-molclintox: 0.832800 val loss: 0.121162
[Epoch 112] ogbg-molclintox: 0.841176 test loss: 0.236450
[Epoch 113; Iter    20/   40] train: loss: 0.2810831
[Epoch 113] ogbg-molclintox: 0.871522 val loss: 0.113922
[Epoch 113] ogbg-molclintox: 0.828509 test loss: 0.223917
[Epoch 114; Iter    10/   40] train: loss: 0.0070589
[Epoch 114; Iter    40/   40] train: loss: 0.0024256
[Epoch 114] ogbg-molclintox: 0.866602 val loss: 0.108785
[Epoch 114] ogbg-molclintox: 0.848385 test loss: 0.218760
[Epoch 115; Iter    30/   40] train: loss: 0.0105079
[Epoch 115] ogbg-molclintox: 0.834536 val loss: 0.131050
[Epoch 115] ogbg-molclintox: 0.831109 test loss: 0.228866
[Epoch 116; Iter    20/   40] train: loss: 0.0538083
[Epoch 116] ogbg-molclintox: 0.821650 val loss: 0.129096
[Epoch 116] ogbg-molclintox: 0.841288 test loss: 0.221378
[Epoch 117; Iter    10/   40] train: loss: 0.0796648
[Epoch 117; Iter    40/   40] train: loss: 0.0037889
[Epoch 117] ogbg-molclintox: 0.841241 val loss: 0.127612
[Epoch 117] ogbg-molclintox: 0.857140 test loss: 0.209492
[Epoch 118; Iter    30/   40] train: loss: 0.0559258
[Epoch 118] ogbg-molclintox: 0.852068 val loss: 0.124437
[Epoch 118] ogbg-molclintox: 0.850182 test loss: 0.212374
[Epoch 119; Iter    20/   40] train: loss: 0.0257784
[Epoch 119] ogbg-molclintox: 0.822236 val loss: 0.129045
[Epoch 119] ogbg-molclintox: 0.867147 test loss: 0.206741
[Epoch 120; Iter    10/   40] train: loss: 0.0683343
[Epoch 120; Iter    40/   40] train: loss: 0.0027589
[Epoch 120] ogbg-molclintox: 0.822437 val loss: 0.126448
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.862075 test loss: 0.210532
[Epoch 121; Iter    30/   40] train: loss: 0.0094799
[Epoch 121] ogbg-molclintox: 0.791569 val loss: 0.134568
[Epoch 121] ogbg-molclintox: 0.848172 test loss: 0.221586
[Epoch 122; Iter    20/   40] train: loss: 0.0460349
[Epoch 122] ogbg-molclintox: 0.880113 val loss: 0.126951
[Epoch 122] ogbg-molclintox: 0.870382 test loss: 0.223822
[Epoch 123; Iter    10/   40] train: loss: 0.0574150
[Epoch 123; Iter    40/   40] train: loss: 0.0041022
[Epoch 123] ogbg-molclintox: 0.863755 val loss: 0.123221
[Epoch 123] ogbg-molclintox: 0.877666 test loss: 0.200682
[Epoch 124; Iter    30/   40] train: loss: 0.0546431
[Epoch 124] ogbg-molclintox: 0.854640 val loss: 0.118313
[Epoch 124] ogbg-molclintox: 0.864536 test loss: 0.196341
[Epoch 125; Iter    20/   40] train: loss: 0.0588305
[Epoch 125] ogbg-molclintox: 0.895010 val loss: 0.118694
[Epoch 125] ogbg-molclintox: 0.889058 test loss: 0.186713
[Epoch 126; Iter    10/   40] train: loss: 0.0538163
[Epoch 126; Iter    40/   40] train: loss: 0.0141129
[Epoch 126] ogbg-molclintox: 0.814070 val loss: 0.142077
[Epoch 126] ogbg-molclintox: 0.874129 test loss: 0.200543
[Epoch 127; Iter    30/   40] train: loss: 0.0163506
[Epoch 127] ogbg-molclintox: 0.852904 val loss: 0.132613
[Epoch 127] ogbg-molclintox: 0.893642 test loss: 0.199197
[Epoch 128; Iter    20/   40] train: loss: 0.0348097
[Epoch 128] ogbg-molclintox: 0.867227 val loss: 0.123164
[Epoch 128] ogbg-molclintox: 0.878540 test loss: 0.199064
[Epoch 129; Iter    10/   40] train: loss: 0.0579105
[Epoch 129; Iter    40/   40] train: loss: 0.0051225
[Epoch 129] ogbg-molclintox: 0.816094 val loss: 0.122337
[Epoch 129] ogbg-molclintox: 0.868432 test loss: 0.185437
[Epoch 130; Iter    30/   40] train: loss: 0.0385176
[Epoch 130] ogbg-molclintox: 0.849871 val loss: 0.123251
[Epoch 130] ogbg-molclintox: 0.873867 test loss: 0.208724
[Epoch 131; Iter    20/   40] train: loss: 0.0322375
[Epoch 131] ogbg-molclintox: 0.865730 val loss: 0.125960
[Epoch 131] ogbg-molclintox: 0.875865 test loss: 0.204268
[Epoch 132; Iter    10/   40] train: loss: 0.0143650
[Epoch 132; Iter    40/   40] train: loss: 0.0149451
[Epoch 132] ogbg-molclintox: 0.867853 val loss: 0.141855
[Epoch 132] ogbg-molclintox: 0.872817 test loss: 0.211137
[Epoch 133; Iter    30/   40] train: loss: 0.0206769
[Epoch 133] ogbg-molclintox: 0.808665 val loss: 0.140126
[Epoch 133] ogbg-molclintox: 0.867846 test loss: 0.209055
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 133 epochs. Best model checkpoint was in epoch 73.
Statistics on  val_best_checkpoint
mean_pred: 0.2794173061847687
std_pred: 6.4091477394104
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.9178084105094594
rocauc: 0.9950802718408353
ogbg-molclintox: 0.9950802718408353
OGBNanLabelBCEWithLogitsLoss: 0.04929745104163885
Statistics on  test
mean_pred: 0.24885603785514832
std_pred: 5.495881080627441
mean_targets: 0.5033783912658691
std_targets: 0.5008352994918823
prcauc: 0.7964773776639392
rocauc: 0.8860850450074723
ogbg-molclintox: 0.8860850450074723
OGBNanLabelBCEWithLogitsLoss: 0.14425852596759797
Statistics on  train
mean_pred: 0.29006728529930115
std_pred: 6.123788356781006
mean_targets: 0.5067738890647888
std_targets: 0.500059962272644
prcauc: 0.9592817469619508
rocauc: 0.9894498861006124
ogbg-molclintox: 0.9894498861006124
OGBNanLabelBCEWithLogitsLoss: 0.06633849752834067
Starting process for seed 4: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.0.yml --seed 4 --device cuda:0
Starting process for seed 5: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.0.yml --seed 5 --device cuda:0
Starting process for seed 6: python train.py --config configs_static_noise_experiments/3DInfomax/clintox/noise=0.0.yml --seed 6 --device cuda:0
All runs completed.
