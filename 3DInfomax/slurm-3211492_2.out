>>> Starting run for dataset: clintox
Running RANDOM configs_split_experiments/3DInfomax/clintox/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/3DInfomax/clintox/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/3DInfomax/clintox/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.7.yml --seed 6 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/3DInfomax/clintox/random/train_prop=0.8.yml --seed 6 --device cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.8/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.8_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.8
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6946481
[Epoch 1] ogbg-molclintox: 0.520475 val loss: 0.692659
[Epoch 1] ogbg-molclintox: 0.561812 test loss: 0.692574
[Epoch 2; Iter    20/   40] train: loss: 0.6950474
[Epoch 2] ogbg-molclintox: 0.441980 val loss: 0.693026
[Epoch 2] ogbg-molclintox: 0.559670 test loss: 0.692024
[Epoch 3; Iter    10/   40] train: loss: 0.6929202
[Epoch 3; Iter    40/   40] train: loss: 0.6925781
[Epoch 3] ogbg-molclintox: 0.429391 val loss: 0.692250
[Epoch 3] ogbg-molclintox: 0.556430 test loss: 0.690712
[Epoch 4; Iter    30/   40] train: loss: 0.6917993
[Epoch 4] ogbg-molclintox: 0.444725 val loss: 0.691436
[Epoch 4] ogbg-molclintox: 0.557975 test loss: 0.690357
[Epoch 5; Iter    20/   40] train: loss: 0.6914714
[Epoch 5] ogbg-molclintox: 0.433574 val loss: 0.691712
[Epoch 5] ogbg-molclintox: 0.552359 test loss: 0.690652
[Epoch 6; Iter    10/   40] train: loss: 0.6913416
[Epoch 6; Iter    40/   40] train: loss: 0.6904081
[Epoch 6] ogbg-molclintox: 0.425236 val loss: 0.689913
[Epoch 6] ogbg-molclintox: 0.536064 test loss: 0.688631
[Epoch 7; Iter    30/   40] train: loss: 0.6911379
[Epoch 7] ogbg-molclintox: 0.432203 val loss: 0.688876
[Epoch 7] ogbg-molclintox: 0.544413 test loss: 0.687574
[Epoch 8; Iter    20/   40] train: loss: 0.6888767
[Epoch 8] ogbg-molclintox: 0.422531 val loss: 0.688630
[Epoch 8] ogbg-molclintox: 0.543985 test loss: 0.687325
[Epoch 9; Iter    10/   40] train: loss: 0.6870486
[Epoch 9; Iter    40/   40] train: loss: 0.6893756
[Epoch 9] ogbg-molclintox: 0.439996 val loss: 0.686774
[Epoch 9] ogbg-molclintox: 0.542133 test loss: 0.685492
[Epoch 10; Iter    30/   40] train: loss: 0.6857030
[Epoch 10] ogbg-molclintox: 0.435666 val loss: 0.685090
[Epoch 10] ogbg-molclintox: 0.547870 test loss: 0.683985
[Epoch 11; Iter    20/   40] train: loss: 0.6883998
[Epoch 11] ogbg-molclintox: 0.434560 val loss: 0.685030
[Epoch 11] ogbg-molclintox: 0.533748 test loss: 0.683883
[Epoch 12; Iter    10/   40] train: loss: 0.6839571
[Epoch 12; Iter    40/   40] train: loss: 0.6820610
[Epoch 12] ogbg-molclintox: 0.436719 val loss: 0.681913
[Epoch 12] ogbg-molclintox: 0.550995 test loss: 0.680591
[Epoch 13; Iter    30/   40] train: loss: 0.6816373
[Epoch 13] ogbg-molclintox: 0.438665 val loss: 0.680462
[Epoch 13] ogbg-molclintox: 0.539768 test loss: 0.679199
[Epoch 14; Iter    20/   40] train: loss: 0.6806332
[Epoch 14] ogbg-molclintox: 0.450534 val loss: 0.679242
[Epoch 14] ogbg-molclintox: 0.560255 test loss: 0.678138
[Epoch 15; Iter    10/   40] train: loss: 0.6804968
[Epoch 15; Iter    40/   40] train: loss: 0.6757944
[Epoch 15] ogbg-molclintox: 0.454810 val loss: 0.677285
[Epoch 15] ogbg-molclintox: 0.558228 test loss: 0.676134
[Epoch 16; Iter    30/   40] train: loss: 0.6778730
[Epoch 16] ogbg-molclintox: 0.433055 val loss: 0.675381
[Epoch 16] ogbg-molclintox: 0.549324 test loss: 0.674230
[Epoch 17; Iter    20/   40] train: loss: 0.6742680
[Epoch 17] ogbg-molclintox: 0.436693 val loss: 0.673105
[Epoch 17] ogbg-molclintox: 0.546202 test loss: 0.671802
[Epoch 18; Iter    10/   40] train: loss: 0.6703202
[Epoch 18; Iter    40/   40] train: loss: 0.6606907
[Epoch 18] ogbg-molclintox: 0.609044 val loss: 0.652877
[Epoch 18] ogbg-molclintox: 0.611975 test loss: 0.656041
[Epoch 19; Iter    30/   40] train: loss: 0.6305677
[Epoch 19] ogbg-molclintox: 0.692969 val loss: 0.641757
[Epoch 19] ogbg-molclintox: 0.657370 test loss: 0.635854
[Epoch 20; Iter    20/   40] train: loss: 0.6060388
[Epoch 20] ogbg-molclintox: 0.700908 val loss: 0.565786
[Epoch 20] ogbg-molclintox: 0.715344 test loss: 0.571464
[Epoch 21; Iter    10/   40] train: loss: 0.5309904
[Epoch 21; Iter    40/   40] train: loss: 0.5534538
[Epoch 21] ogbg-molclintox: 0.601540 val loss: 0.533254
[Epoch 21] ogbg-molclintox: 0.685669 test loss: 0.535353
[Epoch 22; Iter    30/   40] train: loss: 0.4283875
[Epoch 22] ogbg-molclintox: 0.650287 val loss: 0.441726
[Epoch 22] ogbg-molclintox: 0.639128 test loss: 0.438674
[Epoch 23; Iter    20/   40] train: loss: 0.4103237
[Epoch 23] ogbg-molclintox: 0.691086 val loss: 0.347327
[Epoch 23] ogbg-molclintox: 0.647820 test loss: 0.338723
[Epoch 24; Iter    10/   40] train: loss: 0.3454192
[Epoch 24; Iter    40/   40] train: loss: 0.2243481
[Epoch 24] ogbg-molclintox: 0.742483 val loss: 0.369991
[Epoch 24] ogbg-molclintox: 0.617247 test loss: 0.718046
[Epoch 25; Iter    30/   40] train: loss: 0.2693487
[Epoch 25] ogbg-molclintox: 0.681363 val loss: 0.257908
[Epoch 25] ogbg-molclintox: 0.644280 test loss: 0.244894
[Epoch 26; Iter    20/   40] train: loss: 0.2049125
[Epoch 26] ogbg-molclintox: 0.642186 val loss: 0.266420
[Epoch 26] ogbg-molclintox: 0.600917 test loss: 0.262028
[Epoch 27; Iter    10/   40] train: loss: 0.1531730
[Epoch 27; Iter    40/   40] train: loss: 0.1421496
[Epoch 27] ogbg-molclintox: 0.764809 val loss: 0.237429
[Epoch 27] ogbg-molclintox: 0.689189 test loss: 0.234693
[Epoch 28; Iter    30/   40] train: loss: 0.2068757
[Epoch 28] ogbg-molclintox: 0.776481 val loss: 0.226370
[Epoch 28] ogbg-molclintox: 0.652918 test loss: 0.231271
[Epoch 29; Iter    20/   40] train: loss: 0.2448345
[Epoch 29] ogbg-molclintox: 0.736008 val loss: 0.238688
[Epoch 29] ogbg-molclintox: 0.559925 test loss: 0.237256
[Epoch 30; Iter    10/   40] train: loss: 0.2604188
[Epoch 30; Iter    40/   40] train: loss: 0.0747135
[Epoch 30] ogbg-molclintox: 0.784633 val loss: 0.227414
[Epoch 30] ogbg-molclintox: 0.706325 test loss: 0.222458
[Epoch 31; Iter    30/   40] train: loss: 0.1371336
[Epoch 31] ogbg-molclintox: 0.677089 val loss: 0.256118
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.8/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.8_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.8
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6932287
[Epoch 1] ogbg-molclintox: 0.497788 val loss: 0.693339
[Epoch 1] ogbg-molclintox: 0.423140 test loss: 0.693256
[Epoch 2; Iter    20/   40] train: loss: 0.6930359
[Epoch 2] ogbg-molclintox: 0.495219 val loss: 0.693306
[Epoch 2] ogbg-molclintox: 0.403860 test loss: 0.693319
[Epoch 3; Iter    10/   40] train: loss: 0.6914862
[Epoch 3; Iter    40/   40] train: loss: 0.6920955
[Epoch 3] ogbg-molclintox: 0.514189 val loss: 0.693472
[Epoch 3] ogbg-molclintox: 0.402490 test loss: 0.693678
[Epoch 4; Iter    30/   40] train: loss: 0.6936820
[Epoch 4] ogbg-molclintox: 0.519916 val loss: 0.693038
[Epoch 4] ogbg-molclintox: 0.396620 test loss: 0.693322
[Epoch 5; Iter    20/   40] train: loss: 0.6926210
[Epoch 5] ogbg-molclintox: 0.519490 val loss: 0.692755
[Epoch 5] ogbg-molclintox: 0.411967 test loss: 0.693001
[Epoch 6; Iter    10/   40] train: loss: 0.6907654
[Epoch 6; Iter    40/   40] train: loss: 0.6923172
[Epoch 6] ogbg-molclintox: 0.511537 val loss: 0.691180
[Epoch 6] ogbg-molclintox: 0.412311 test loss: 0.691294
[Epoch 7; Iter    30/   40] train: loss: 0.6909465
[Epoch 7] ogbg-molclintox: 0.512550 val loss: 0.691178
[Epoch 7] ogbg-molclintox: 0.402695 test loss: 0.691473
[Epoch 8; Iter    20/   40] train: loss: 0.6906418
[Epoch 8] ogbg-molclintox: 0.519531 val loss: 0.690780
[Epoch 8] ogbg-molclintox: 0.408764 test loss: 0.690905
[Epoch 9; Iter    10/   40] train: loss: 0.6897349
[Epoch 9; Iter    40/   40] train: loss: 0.6884502
[Epoch 9] ogbg-molclintox: 0.517932 val loss: 0.689387
[Epoch 9] ogbg-molclintox: 0.407606 test loss: 0.689593
[Epoch 10; Iter    30/   40] train: loss: 0.6891009
[Epoch 10] ogbg-molclintox: 0.526045 val loss: 0.688046
[Epoch 10] ogbg-molclintox: 0.415285 test loss: 0.688359
[Epoch 11; Iter    20/   40] train: loss: 0.6868211
[Epoch 11] ogbg-molclintox: 0.524873 val loss: 0.687080
[Epoch 11] ogbg-molclintox: 0.418730 test loss: 0.687310
[Epoch 12; Iter    10/   40] train: loss: 0.6857205
[Epoch 12; Iter    40/   40] train: loss: 0.6873477
[Epoch 12] ogbg-molclintox: 0.528163 val loss: 0.685487
[Epoch 12] ogbg-molclintox: 0.418640 test loss: 0.685764
[Epoch 13; Iter    30/   40] train: loss: 0.6821723
[Epoch 13] ogbg-molclintox: 0.522769 val loss: 0.684758
[Epoch 13] ogbg-molclintox: 0.407491 test loss: 0.684934
[Epoch 14; Iter    20/   40] train: loss: 0.6830710
[Epoch 14] ogbg-molclintox: 0.530308 val loss: 0.682757
[Epoch 14] ogbg-molclintox: 0.417614 test loss: 0.682913
[Epoch 15; Iter    10/   40] train: loss: 0.6821704
[Epoch 15; Iter    40/   40] train: loss: 0.6844633
[Epoch 15] ogbg-molclintox: 0.519930 val loss: 0.681615
[Epoch 15] ogbg-molclintox: 0.411841 test loss: 0.681953
[Epoch 16; Iter    30/   40] train: loss: 0.6804467
[Epoch 16] ogbg-molclintox: 0.528643 val loss: 0.680147
[Epoch 16] ogbg-molclintox: 0.412414 test loss: 0.680347
[Epoch 17; Iter    20/   40] train: loss: 0.6800866
[Epoch 17] ogbg-molclintox: 0.527949 val loss: 0.679123
[Epoch 17] ogbg-molclintox: 0.410604 test loss: 0.679347
[Epoch 18; Iter    10/   40] train: loss: 0.6756294
[Epoch 18; Iter    40/   40] train: loss: 0.6665373
[Epoch 18] ogbg-molclintox: 0.651712 val loss: 0.666961
[Epoch 18] ogbg-molclintox: 0.639616 test loss: 0.670653
[Epoch 19; Iter    30/   40] train: loss: 0.6374773
[Epoch 19] ogbg-molclintox: 0.686948 val loss: 0.630648
[Epoch 19] ogbg-molclintox: 0.746370 test loss: 0.640023
[Epoch 20; Iter    20/   40] train: loss: 0.5780882
[Epoch 20] ogbg-molclintox: 0.737939 val loss: 0.561615
[Epoch 20] ogbg-molclintox: 0.671999 test loss: 0.563525
[Epoch 21; Iter    10/   40] train: loss: 0.5422177
[Epoch 21; Iter    40/   40] train: loss: 0.4862680
[Epoch 21] ogbg-molclintox: 0.703383 val loss: 0.485263
[Epoch 21] ogbg-molclintox: 0.735173 test loss: 0.472983
[Epoch 22; Iter    30/   40] train: loss: 0.4633836
[Epoch 22] ogbg-molclintox: 0.665752 val loss: 0.388954
[Epoch 22] ogbg-molclintox: 0.713426 test loss: 0.372799
[Epoch 23; Iter    20/   40] train: loss: 0.3609744
[Epoch 23] ogbg-molclintox: 0.587568 val loss: 0.356036
[Epoch 23] ogbg-molclintox: 0.646192 test loss: 0.349542
[Epoch 24; Iter    10/   40] train: loss: 0.2788468
[Epoch 24; Iter    40/   40] train: loss: 0.2593811
[Epoch 24] ogbg-molclintox: 0.640336 val loss: 0.287086
[Epoch 24] ogbg-molclintox: 0.606706 test loss: 0.282917
[Epoch 25; Iter    30/   40] train: loss: 0.2891830
[Epoch 25] ogbg-molclintox: 0.702786 val loss: 0.258888
[Epoch 25] ogbg-molclintox: 0.696299 test loss: 0.254633
[Epoch 26; Iter    20/   40] train: loss: 0.1789794
[Epoch 26] ogbg-molclintox: 0.733787 val loss: 0.246188
[Epoch 26] ogbg-molclintox: 0.655090 test loss: 0.249208
[Epoch 27; Iter    10/   40] train: loss: 0.1184157
[Epoch 27; Iter    40/   40] train: loss: 0.4346969
[Epoch 27] ogbg-molclintox: 0.726672 val loss: 0.236004
[Epoch 27] ogbg-molclintox: 0.692287 test loss: 0.228447
[Epoch 28; Iter    30/   40] train: loss: 0.1712655
[Epoch 28] ogbg-molclintox: 0.715642 val loss: 0.246105
[Epoch 28] ogbg-molclintox: 0.654372 test loss: 0.240154
[Epoch 29; Iter    20/   40] train: loss: 0.1495953
[Epoch 29] ogbg-molclintox: 0.701734 val loss: 0.239494
[Epoch 29] ogbg-molclintox: 0.573414 test loss: 0.241818
[Epoch 30; Iter    10/   40] train: loss: 0.1673172
[Epoch 30; Iter    40/   40] train: loss: 0.1856735
[Epoch 30] ogbg-molclintox: 0.744469 val loss: 0.231202
[Epoch 30] ogbg-molclintox: 0.656761 test loss: 0.230932
[Epoch 31; Iter    30/   40] train: loss: 0.1800488
[Epoch 31] ogbg-molclintox: 0.732947 val loss: 0.249958
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.6/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.6_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.6
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6947833
[Epoch 1] ogbg-molclintox: 0.490126 val loss: 0.692495
[Epoch 1] ogbg-molclintox: 0.539728 test loss: 0.692439
[Epoch 2; Iter    30/   30] train: loss: 0.6871715
[Epoch 2] ogbg-molclintox: 0.504922 val loss: 0.692267
[Epoch 2] ogbg-molclintox: 0.518267 test loss: 0.692155
[Epoch 3; Iter    30/   30] train: loss: 0.6949972
[Epoch 3] ogbg-molclintox: 0.517369 val loss: 0.692240
[Epoch 3] ogbg-molclintox: 0.497339 test loss: 0.691975
[Epoch 4; Iter    30/   30] train: loss: 0.6903880
[Epoch 4] ogbg-molclintox: 0.517331 val loss: 0.691699
[Epoch 4] ogbg-molclintox: 0.489501 test loss: 0.691452
[Epoch 5; Iter    30/   30] train: loss: 0.6922063
[Epoch 5] ogbg-molclintox: 0.517443 val loss: 0.691027
[Epoch 5] ogbg-molclintox: 0.481335 test loss: 0.690896
[Epoch 6; Iter    30/   30] train: loss: 0.6918918
[Epoch 6] ogbg-molclintox: 0.518562 val loss: 0.690567
[Epoch 6] ogbg-molclintox: 0.493802 test loss: 0.690347
[Epoch 7; Iter    30/   30] train: loss: 0.6933255
[Epoch 7] ogbg-molclintox: 0.528026 val loss: 0.690209
[Epoch 7] ogbg-molclintox: 0.485374 test loss: 0.690103
[Epoch 8; Iter    30/   30] train: loss: 0.6917589
[Epoch 8] ogbg-molclintox: 0.524868 val loss: 0.689262
[Epoch 8] ogbg-molclintox: 0.485997 test loss: 0.689291
[Epoch 9; Iter    30/   30] train: loss: 0.6883560
[Epoch 9] ogbg-molclintox: 0.518812 val loss: 0.688631
[Epoch 9] ogbg-molclintox: 0.478604 test loss: 0.688605
[Epoch 10; Iter    30/   30] train: loss: 0.6891692
[Epoch 10] ogbg-molclintox: 0.517710 val loss: 0.687740
[Epoch 10] ogbg-molclintox: 0.485223 test loss: 0.687745
[Epoch 11; Iter    30/   30] train: loss: 0.6892118
[Epoch 11] ogbg-molclintox: 0.523427 val loss: 0.687356
[Epoch 11] ogbg-molclintox: 0.482605 test loss: 0.687361
[Epoch 12; Iter    30/   30] train: loss: 0.6889483
[Epoch 12] ogbg-molclintox: 0.528900 val loss: 0.686368
[Epoch 12] ogbg-molclintox: 0.485964 test loss: 0.686385
[Epoch 13; Iter    30/   30] train: loss: 0.6855593
[Epoch 13] ogbg-molclintox: 0.532450 val loss: 0.684992
[Epoch 13] ogbg-molclintox: 0.487752 test loss: 0.685156
[Epoch 14; Iter    30/   30] train: loss: 0.6873612
[Epoch 14] ogbg-molclintox: 0.527073 val loss: 0.684024
[Epoch 14] ogbg-molclintox: 0.481807 test loss: 0.684251
[Epoch 15; Iter    30/   30] train: loss: 0.6846468
[Epoch 15] ogbg-molclintox: 0.528577 val loss: 0.682071
[Epoch 15] ogbg-molclintox: 0.492387 test loss: 0.682324
[Epoch 16; Iter    30/   30] train: loss: 0.6819299
[Epoch 16] ogbg-molclintox: 0.532975 val loss: 0.681662
[Epoch 16] ogbg-molclintox: 0.491692 test loss: 0.681951
[Epoch 17; Iter    30/   30] train: loss: 0.6893194
[Epoch 17] ogbg-molclintox: 0.527076 val loss: 0.680370
[Epoch 17] ogbg-molclintox: 0.486617 test loss: 0.680757
[Epoch 18; Iter    30/   30] train: loss: 0.6865385
[Epoch 18] ogbg-molclintox: 0.541816 val loss: 0.679670
[Epoch 18] ogbg-molclintox: 0.492347 test loss: 0.680025
[Epoch 19; Iter    30/   30] train: loss: 0.6800990
[Epoch 19] ogbg-molclintox: 0.539150 val loss: 0.676847
[Epoch 19] ogbg-molclintox: 0.488544 test loss: 0.677433
[Epoch 20; Iter    30/   30] train: loss: 0.6760556
[Epoch 20] ogbg-molclintox: 0.534122 val loss: 0.675581
[Epoch 20] ogbg-molclintox: 0.494407 test loss: 0.676032
[Epoch 21; Iter    30/   30] train: loss: 0.6738567
[Epoch 21] ogbg-molclintox: 0.539572 val loss: 0.673942
[Epoch 21] ogbg-molclintox: 0.489612 test loss: 0.674638
[Epoch 22; Iter    30/   30] train: loss: 0.6720213
[Epoch 22] ogbg-molclintox: 0.543538 val loss: 0.672276
[Epoch 22] ogbg-molclintox: 0.481308 test loss: 0.673089
[Epoch 23; Iter    30/   30] train: loss: 0.6744650
[Epoch 23] ogbg-molclintox: 0.648776 val loss: 0.674434
[Epoch 23] ogbg-molclintox: 0.548346 test loss: 0.675846
[Epoch 24; Iter    30/   30] train: loss: 0.6567366
[Epoch 24] ogbg-molclintox: 0.703228 val loss: 0.633236
[Epoch 24] ogbg-molclintox: 0.659182 test loss: 0.636620
[Epoch 25; Iter    30/   30] train: loss: 0.6433797
[Epoch 25] ogbg-molclintox: 0.730878 val loss: 0.625662
[Epoch 25] ogbg-molclintox: 0.656205 test loss: 0.637694
[Epoch 26; Iter    30/   30] train: loss: 0.5656697
[Epoch 26] ogbg-molclintox: 0.710201 val loss: 0.573531
[Epoch 26] ogbg-molclintox: 0.629062 test loss: 0.581541
[Epoch 27; Iter    30/   30] train: loss: 0.5158758
[Epoch 27] ogbg-molclintox: 0.703294 val loss: 0.552140
[Epoch 27] ogbg-molclintox: 0.587069 test loss: 0.564686
[Epoch 28; Iter    30/   30] train: loss: 0.4874738
[Epoch 28] ogbg-molclintox: 0.729161 val loss: 0.484667
[Epoch 28] ogbg-molclintox: 0.570544 test loss: 0.516804
[Epoch 29; Iter    30/   30] train: loss: 0.4078944
[Epoch 29] ogbg-molclintox: 0.727496 val loss: 0.386775
[Epoch 29] ogbg-molclintox: 0.701587 test loss: 0.399229
[Epoch 30; Iter    30/   30] train: loss: 0.3510263
[Epoch 30] ogbg-molclintox: 0.738812 val loss: 0.361960
[Epoch 30] ogbg-molclintox: 0.659748 test loss: 0.387963
[Epoch 31; Iter    30/   30] train: loss: 0.3149135
[Epoch 31] ogbg-molclintox: 0.738847 val loss: 0.291376
[Epoch 31] ogbg-molclintox: 0.702470 test loss: 0.305962
[Epoch 32; Iter    30/   30] train: loss: 0.3379989
[Epoch 32] ogbg-molclintox: 0.763120 val loss: 0.323082
[Epoch 32] ogbg-molclintox: 0.664385 test loss: 0.310337
[Epoch 33; Iter    30/   30] train: loss: 0.2402467
[Epoch 33] ogbg-molclintox: 0.739703 val loss: 0.280335
[Epoch 33] ogbg-molclintox: 0.642805 test loss: 0.281406
[Epoch 34; Iter    30/   30] train: loss: 0.2303879
[Epoch 34] ogbg-molclintox: 0.764425 val loss: 0.249837
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.7/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.7_4_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.7
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6943936
[Epoch 1] ogbg-molclintox: 0.497670 val loss: 0.693118
[Epoch 1] ogbg-molclintox: 0.624444 test loss: 0.692982
[Epoch 2; Iter    25/   35] train: loss: 0.6938016
[Epoch 2] ogbg-molclintox: 0.485459 val loss: 0.692658
[Epoch 2] ogbg-molclintox: 0.584692 test loss: 0.692613
[Epoch 3; Iter    20/   35] train: loss: 0.6930981
[Epoch 3] ogbg-molclintox: 0.493701 val loss: 0.691538
[Epoch 3] ogbg-molclintox: 0.540739 test loss: 0.692008
[Epoch 4; Iter    15/   35] train: loss: 0.6929034
[Epoch 4] ogbg-molclintox: 0.493438 val loss: 0.691446
[Epoch 4] ogbg-molclintox: 0.543650 test loss: 0.691986
[Epoch 5; Iter    10/   35] train: loss: 0.6935970
[Epoch 5] ogbg-molclintox: 0.488577 val loss: 0.690839
[Epoch 5] ogbg-molclintox: 0.531682 test loss: 0.691379
[Epoch 6; Iter     5/   35] train: loss: 0.6917135
[Epoch 6; Iter    35/   35] train: loss: 0.6917470
[Epoch 6] ogbg-molclintox: 0.488015 val loss: 0.690488
[Epoch 6] ogbg-molclintox: 0.538647 test loss: 0.690949
[Epoch 7; Iter    30/   35] train: loss: 0.6905617
[Epoch 7] ogbg-molclintox: 0.494637 val loss: 0.689985
[Epoch 7] ogbg-molclintox: 0.544164 test loss: 0.690490
[Epoch 8; Iter    25/   35] train: loss: 0.6899460
[Epoch 8] ogbg-molclintox: 0.491743 val loss: 0.689144
[Epoch 8] ogbg-molclintox: 0.549449 test loss: 0.689743
[Epoch 9; Iter    20/   35] train: loss: 0.6904446
[Epoch 9] ogbg-molclintox: 0.491265 val loss: 0.688645
[Epoch 9] ogbg-molclintox: 0.542138 test loss: 0.689182
[Epoch 10; Iter    15/   35] train: loss: 0.6899855
[Epoch 10] ogbg-molclintox: 0.484275 val loss: 0.687123
[Epoch 10] ogbg-molclintox: 0.538721 test loss: 0.687743
[Epoch 11; Iter    10/   35] train: loss: 0.6897364
[Epoch 11] ogbg-molclintox: 0.488653 val loss: 0.685521
[Epoch 11] ogbg-molclintox: 0.544514 test loss: 0.686187
[Epoch 12; Iter     5/   35] train: loss: 0.6871659
[Epoch 12; Iter    35/   35] train: loss: 0.6846690
[Epoch 12] ogbg-molclintox: 0.502130 val loss: 0.685101
[Epoch 12] ogbg-molclintox: 0.560225 test loss: 0.685724
[Epoch 13; Iter    30/   35] train: loss: 0.6868905
[Epoch 13] ogbg-molclintox: 0.495555 val loss: 0.684043
[Epoch 13] ogbg-molclintox: 0.561661 test loss: 0.684665
[Epoch 14; Iter    25/   35] train: loss: 0.6864222
[Epoch 14] ogbg-molclintox: 0.488953 val loss: 0.681478
[Epoch 14] ogbg-molclintox: 0.543004 test loss: 0.682352
[Epoch 15; Iter    20/   35] train: loss: 0.6817729
[Epoch 15] ogbg-molclintox: 0.503866 val loss: 0.681264
[Epoch 15] ogbg-molclintox: 0.577801 test loss: 0.681745
[Epoch 16; Iter    15/   35] train: loss: 0.6814568
[Epoch 16] ogbg-molclintox: 0.490947 val loss: 0.679522
[Epoch 16] ogbg-molclintox: 0.562590 test loss: 0.680269
[Epoch 17; Iter    10/   35] train: loss: 0.6788859
[Epoch 17] ogbg-molclintox: 0.498974 val loss: 0.677200
[Epoch 17] ogbg-molclintox: 0.554574 test loss: 0.678144
[Epoch 18; Iter     5/   35] train: loss: 0.6809244
[Epoch 18; Iter    35/   35] train: loss: 0.6767094
[Epoch 18] ogbg-molclintox: 0.499802 val loss: 0.675989
[Epoch 18] ogbg-molclintox: 0.565713 test loss: 0.676824
[Epoch 19; Iter    30/   35] train: loss: 0.6770347
[Epoch 19] ogbg-molclintox: 0.497283 val loss: 0.673820
[Epoch 19] ogbg-molclintox: 0.562138 test loss: 0.674667
[Epoch 20; Iter    25/   35] train: loss: 0.6729700
[Epoch 20] ogbg-molclintox: 0.579235 val loss: 0.674708
[Epoch 20] ogbg-molclintox: 0.639757 test loss: 0.675359
[Epoch 21; Iter    20/   35] train: loss: 0.6637480
[Epoch 21] ogbg-molclintox: 0.661092 val loss: 0.643615
[Epoch 21] ogbg-molclintox: 0.700599 test loss: 0.644897
[Epoch 22; Iter    15/   35] train: loss: 0.6355599
[Epoch 22] ogbg-molclintox: 0.636340 val loss: 0.579237
[Epoch 22] ogbg-molclintox: 0.731045 test loss: 0.581134
[Epoch 23; Iter    10/   35] train: loss: 0.5934449
[Epoch 23] ogbg-molclintox: 0.687235 val loss: 0.557337
[Epoch 23] ogbg-molclintox: 0.743735 test loss: 0.563933
[Epoch 24; Iter     5/   35] train: loss: 0.5372539
[Epoch 24; Iter    35/   35] train: loss: 0.4663088
[Epoch 24] ogbg-molclintox: 0.642285 val loss: 0.476366
[Epoch 24] ogbg-molclintox: 0.649143 test loss: 0.495742
[Epoch 25; Iter    30/   35] train: loss: 0.4469788
[Epoch 25] ogbg-molclintox: 0.741397 val loss: 0.400082
[Epoch 25] ogbg-molclintox: 0.703608 test loss: 0.410488
[Epoch 26; Iter    25/   35] train: loss: 0.3961001
[Epoch 26] ogbg-molclintox: 0.747086 val loss: 0.320440
[Epoch 26] ogbg-molclintox: 0.683948 test loss: 0.331302
[Epoch 27; Iter    20/   35] train: loss: 0.3831821
[Epoch 27] ogbg-molclintox: 0.694063 val loss: 0.347582
[Epoch 27] ogbg-molclintox: 0.599049 test loss: 0.371734
[Epoch 28; Iter    15/   35] train: loss: 0.2784465
[Epoch 28] ogbg-molclintox: 0.660894 val loss: 0.288753
[Epoch 28] ogbg-molclintox: 0.725534 test loss: 0.275638
[Epoch 29; Iter    10/   35] train: loss: 0.1859384
[Epoch 29] ogbg-molclintox: 0.794357 val loss: 0.235081
[Epoch 29] ogbg-molclintox: 0.628465 test loss: 0.257939
[Epoch 30; Iter     5/   35] train: loss: 0.1982558
[Epoch 30; Iter    35/   35] train: loss: 0.1295772
[Epoch 30] ogbg-molclintox: 0.724760 val loss: 0.233408
[Epoch 30] ogbg-molclintox: 0.711900 test loss: 0.239035
[Epoch 31; Iter    30/   35] train: loss: 0.2240208
[Epoch 31] ogbg-molclintox: 0.672121 val loss: 0.257771
[Epoch 31] ogbg-molclintox: 0.645845 test loss: 0.279837
[Epoch 32; Iter    25/   35] train: loss: 0.3113709
[Epoch 32] ogbg-molclintox: 0.739918 val loss: 0.229690
[Epoch 32] ogbg-molclintox: 0.726030 test loss: 0.225123
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.6/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.6_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.6
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6929886
[Epoch 1] ogbg-molclintox: 0.553786 val loss: 0.693152
[Epoch 1] ogbg-molclintox: 0.604678 test loss: 0.693017
[Epoch 2; Iter    30/   30] train: loss: 0.6916717
[Epoch 2] ogbg-molclintox: 0.545764 val loss: 0.692922
[Epoch 2] ogbg-molclintox: 0.566450 test loss: 0.692792
[Epoch 3; Iter    30/   30] train: loss: 0.6928290
[Epoch 3] ogbg-molclintox: 0.502468 val loss: 0.692011
[Epoch 3] ogbg-molclintox: 0.535722 test loss: 0.692365
[Epoch 4; Iter    30/   30] train: loss: 0.6920111
[Epoch 4] ogbg-molclintox: 0.491661 val loss: 0.691303
[Epoch 4] ogbg-molclintox: 0.519726 test loss: 0.692054
[Epoch 5; Iter    30/   30] train: loss: 0.6929719
[Epoch 5] ogbg-molclintox: 0.496716 val loss: 0.691315
[Epoch 5] ogbg-molclintox: 0.530247 test loss: 0.691935
[Epoch 6; Iter    30/   30] train: loss: 0.6917245
[Epoch 6] ogbg-molclintox: 0.496898 val loss: 0.690703
[Epoch 6] ogbg-molclintox: 0.528311 test loss: 0.691369
[Epoch 7; Iter    30/   30] train: loss: 0.6921890
[Epoch 7] ogbg-molclintox: 0.494799 val loss: 0.690317
[Epoch 7] ogbg-molclintox: 0.534052 test loss: 0.690819
[Epoch 8; Iter    30/   30] train: loss: 0.6897926
[Epoch 8] ogbg-molclintox: 0.496958 val loss: 0.689737
[Epoch 8] ogbg-molclintox: 0.523084 test loss: 0.690523
[Epoch 9; Iter    30/   30] train: loss: 0.6893198
[Epoch 9] ogbg-molclintox: 0.499232 val loss: 0.688981
[Epoch 9] ogbg-molclintox: 0.525823 test loss: 0.689802
[Epoch 10; Iter    30/   30] train: loss: 0.6912422
[Epoch 10] ogbg-molclintox: 0.506550 val loss: 0.688842
[Epoch 10] ogbg-molclintox: 0.535680 test loss: 0.689565
[Epoch 11; Iter    30/   30] train: loss: 0.6898471
[Epoch 11] ogbg-molclintox: 0.492791 val loss: 0.687597
[Epoch 11] ogbg-molclintox: 0.536201 test loss: 0.688367
[Epoch 12; Iter    30/   30] train: loss: 0.6884848
[Epoch 12] ogbg-molclintox: 0.504144 val loss: 0.686579
[Epoch 12] ogbg-molclintox: 0.530771 test loss: 0.687551
[Epoch 13; Iter    30/   30] train: loss: 0.6855834
[Epoch 13] ogbg-molclintox: 0.500196 val loss: 0.685450
[Epoch 13] ogbg-molclintox: 0.535687 test loss: 0.686325
[Epoch 14; Iter    30/   30] train: loss: 0.6897434
[Epoch 14] ogbg-molclintox: 0.507944 val loss: 0.684874
[Epoch 14] ogbg-molclintox: 0.530049 test loss: 0.685940
[Epoch 15; Iter    30/   30] train: loss: 0.6847908
[Epoch 15] ogbg-molclintox: 0.516314 val loss: 0.683697
[Epoch 15] ogbg-molclintox: 0.549773 test loss: 0.684547
[Epoch 16; Iter    30/   30] train: loss: 0.6831307
[Epoch 16] ogbg-molclintox: 0.516338 val loss: 0.682139
[Epoch 16] ogbg-molclintox: 0.534526 test loss: 0.683219
[Epoch 17; Iter    30/   30] train: loss: 0.6847611
[Epoch 17] ogbg-molclintox: 0.516887 val loss: 0.680733
[Epoch 17] ogbg-molclintox: 0.528574 test loss: 0.681998
[Epoch 18; Iter    30/   30] train: loss: 0.6851180
[Epoch 18] ogbg-molclintox: 0.518900 val loss: 0.679892
[Epoch 18] ogbg-molclintox: 0.535195 test loss: 0.681065
[Epoch 19; Iter    30/   30] train: loss: 0.6781564
[Epoch 19] ogbg-molclintox: 0.527758 val loss: 0.678376
[Epoch 19] ogbg-molclintox: 0.544022 test loss: 0.679683
[Epoch 20; Iter    30/   30] train: loss: 0.6804460
[Epoch 20] ogbg-molclintox: 0.521649 val loss: 0.677051
[Epoch 20] ogbg-molclintox: 0.545801 test loss: 0.678420
[Epoch 21; Iter    30/   30] train: loss: 0.6775374
[Epoch 21] ogbg-molclintox: 0.534375 val loss: 0.675084
[Epoch 21] ogbg-molclintox: 0.541793 test loss: 0.676625
[Epoch 22; Iter    30/   30] train: loss: 0.6730914
[Epoch 22] ogbg-molclintox: 0.527150 val loss: 0.674024
[Epoch 22] ogbg-molclintox: 0.544014 test loss: 0.675502
[Epoch 23; Iter    30/   30] train: loss: 0.6740130
[Epoch 23] ogbg-molclintox: 0.657641 val loss: 0.671643
[Epoch 23] ogbg-molclintox: 0.557717 test loss: 0.673615
[Epoch 24; Iter    30/   30] train: loss: 0.6645778
[Epoch 24] ogbg-molclintox: 0.709252 val loss: 0.649610
[Epoch 24] ogbg-molclintox: 0.657562 test loss: 0.650983
[Epoch 25; Iter    30/   30] train: loss: 0.6320217
[Epoch 25] ogbg-molclintox: 0.796308 val loss: 0.637660
[Epoch 25] ogbg-molclintox: 0.727512 test loss: 0.638593
[Epoch 26; Iter    30/   30] train: loss: 0.5717944
[Epoch 26] ogbg-molclintox: 0.780205 val loss: 0.586574
[Epoch 26] ogbg-molclintox: 0.701908 test loss: 0.591693
[Epoch 27; Iter    30/   30] train: loss: 0.5250324
[Epoch 27] ogbg-molclintox: 0.779970 val loss: 0.531041
[Epoch 27] ogbg-molclintox: 0.688418 test loss: 0.540325
[Epoch 28; Iter    30/   30] train: loss: 0.4596103
[Epoch 28] ogbg-molclintox: 0.749029 val loss: 0.432088
[Epoch 28] ogbg-molclintox: 0.712727 test loss: 0.442133
[Epoch 29; Iter    30/   30] train: loss: 0.4033255
[Epoch 29] ogbg-molclintox: 0.717825 val loss: 0.410198
[Epoch 29] ogbg-molclintox: 0.579873 test loss: 0.431366
[Epoch 30; Iter    30/   30] train: loss: 0.3597713
[Epoch 30] ogbg-molclintox: 0.736585 val loss: 0.326020
[Epoch 30] ogbg-molclintox: 0.666052 test loss: 0.333170
[Epoch 31; Iter    30/   30] train: loss: 0.2651475
[Epoch 31] ogbg-molclintox: 0.766835 val loss: 0.451723
[Epoch 31] ogbg-molclintox: 0.677834 test loss: 0.540817
[Epoch 32; Iter    30/   30] train: loss: 0.2363617
[Epoch 32] ogbg-molclintox: 0.702887 val loss: 0.283545
[Epoch 32] ogbg-molclintox: 0.596183 test loss: 0.323689
[Epoch 33; Iter    30/   30] train: loss: 0.2734995
[Epoch 33] ogbg-molclintox: 0.695904 val loss: 0.291446
[Epoch 33] ogbg-molclintox: 0.583963 test loss: 0.295634
[Epoch 34; Iter    30/   30] train: loss: 0.1486709
[Epoch 34] ogbg-molclintox: 0.734624 val loss: 0.383380
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.7/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.7_5_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.7
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6920648
[Epoch 1] ogbg-molclintox: 0.571330 val loss: 0.693027
[Epoch 1] ogbg-molclintox: 0.433627 test loss: 0.693315
[Epoch 2; Iter    25/   35] train: loss: 0.6913174
[Epoch 2] ogbg-molclintox: 0.571191 val loss: 0.691654
[Epoch 2] ogbg-molclintox: 0.436113 test loss: 0.693191
[Epoch 3; Iter    20/   35] train: loss: 0.6914690
[Epoch 3] ogbg-molclintox: 0.568949 val loss: 0.691004
[Epoch 3] ogbg-molclintox: 0.431323 test loss: 0.693396
[Epoch 4; Iter    15/   35] train: loss: 0.6926383
[Epoch 4] ogbg-molclintox: 0.579957 val loss: 0.691356
[Epoch 4] ogbg-molclintox: 0.436854 test loss: 0.693728
[Epoch 5; Iter    10/   35] train: loss: 0.6927983
[Epoch 5] ogbg-molclintox: 0.559230 val loss: 0.689821
[Epoch 5] ogbg-molclintox: 0.437286 test loss: 0.692027
[Epoch 6; Iter     5/   35] train: loss: 0.6909255
[Epoch 6; Iter    35/   35] train: loss: 0.6915601
[Epoch 6] ogbg-molclintox: 0.565755 val loss: 0.689577
[Epoch 6] ogbg-molclintox: 0.443470 test loss: 0.691979
[Epoch 7; Iter    30/   35] train: loss: 0.6922519
[Epoch 7] ogbg-molclintox: 0.574590 val loss: 0.689579
[Epoch 7] ogbg-molclintox: 0.445181 test loss: 0.691802
[Epoch 8; Iter    25/   35] train: loss: 0.6904312
[Epoch 8] ogbg-molclintox: 0.570744 val loss: 0.688594
[Epoch 8] ogbg-molclintox: 0.444819 test loss: 0.691010
[Epoch 9; Iter    20/   35] train: loss: 0.6893589
[Epoch 9] ogbg-molclintox: 0.580816 val loss: 0.688824
[Epoch 9] ogbg-molclintox: 0.451182 test loss: 0.691027
[Epoch 10; Iter    15/   35] train: loss: 0.6902146
[Epoch 10] ogbg-molclintox: 0.578799 val loss: 0.687658
[Epoch 10] ogbg-molclintox: 0.436093 test loss: 0.690078
[Epoch 11; Iter    10/   35] train: loss: 0.6872297
[Epoch 11] ogbg-molclintox: 0.576354 val loss: 0.686328
[Epoch 11] ogbg-molclintox: 0.453833 test loss: 0.688636
[Epoch 12; Iter     5/   35] train: loss: 0.6882077
[Epoch 12; Iter    35/   35] train: loss: 0.6866746
[Epoch 12] ogbg-molclintox: 0.576745 val loss: 0.685250
[Epoch 12] ogbg-molclintox: 0.444883 test loss: 0.687527
[Epoch 13; Iter    30/   35] train: loss: 0.6859868
[Epoch 13] ogbg-molclintox: 0.572396 val loss: 0.684043
[Epoch 13] ogbg-molclintox: 0.453415 test loss: 0.686398
[Epoch 14; Iter    25/   35] train: loss: 0.6854683
[Epoch 14] ogbg-molclintox: 0.574431 val loss: 0.682846
[Epoch 14] ogbg-molclintox: 0.447502 test loss: 0.685526
[Epoch 15; Iter    20/   35] train: loss: 0.6845972
[Epoch 15] ogbg-molclintox: 0.581653 val loss: 0.682365
[Epoch 15] ogbg-molclintox: 0.447544 test loss: 0.684771
[Epoch 16; Iter    15/   35] train: loss: 0.6832056
[Epoch 16] ogbg-molclintox: 0.581858 val loss: 0.681080
[Epoch 16] ogbg-molclintox: 0.460321 test loss: 0.683632
[Epoch 17; Iter    10/   35] train: loss: 0.6814761
[Epoch 17] ogbg-molclintox: 0.586316 val loss: 0.679634
[Epoch 17] ogbg-molclintox: 0.449382 test loss: 0.682161
[Epoch 18; Iter     5/   35] train: loss: 0.6808828
[Epoch 18; Iter    35/   35] train: loss: 0.6772476
[Epoch 18] ogbg-molclintox: 0.581455 val loss: 0.678005
[Epoch 18] ogbg-molclintox: 0.446427 test loss: 0.680635
[Epoch 19; Iter    30/   35] train: loss: 0.6795844
[Epoch 19] ogbg-molclintox: 0.591224 val loss: 0.676779
[Epoch 19] ogbg-molclintox: 0.464858 test loss: 0.679293
[Epoch 20; Iter    25/   35] train: loss: 0.6820405
[Epoch 20] ogbg-molclintox: 0.611830 val loss: 0.677205
[Epoch 20] ogbg-molclintox: 0.594877 test loss: 0.679587
[Epoch 21; Iter    20/   35] train: loss: 0.6631695
[Epoch 21] ogbg-molclintox: 0.695849 val loss: 0.620290
[Epoch 21] ogbg-molclintox: 0.698552 test loss: 0.623436
[Epoch 22; Iter    15/   35] train: loss: 0.6284414
[Epoch 22] ogbg-molclintox: 0.757407 val loss: 0.586917
[Epoch 22] ogbg-molclintox: 0.709979 test loss: 0.593964
[Epoch 23; Iter    10/   35] train: loss: 0.5930483
[Epoch 23] ogbg-molclintox: 0.678387 val loss: 0.552111
[Epoch 23] ogbg-molclintox: 0.661858 test loss: 0.566900
[Epoch 24; Iter     5/   35] train: loss: 0.5450372
[Epoch 24; Iter    35/   35] train: loss: 0.4856624
[Epoch 24] ogbg-molclintox: 0.643495 val loss: 0.474570
[Epoch 24] ogbg-molclintox: 0.702001 test loss: 0.483065
[Epoch 25; Iter    30/   35] train: loss: 0.4202531
[Epoch 25] ogbg-molclintox: 0.756087 val loss: 0.358544
[Epoch 25] ogbg-molclintox: 0.634018 test loss: 0.385139
[Epoch 26; Iter    25/   35] train: loss: 0.3816035
[Epoch 26] ogbg-molclintox: 0.750908 val loss: 0.361674
[Epoch 26] ogbg-molclintox: 0.685922 test loss: 0.383858
[Epoch 27; Iter    20/   35] train: loss: 0.3598961
[Epoch 27] ogbg-molclintox: 0.728378 val loss: 0.335378
[Epoch 27] ogbg-molclintox: 0.676235 test loss: 0.304365
[Epoch 28; Iter    15/   35] train: loss: 0.3116875
[Epoch 28] ogbg-molclintox: 0.692963 val loss: 0.419411
[Epoch 28] ogbg-molclintox: 0.703777 test loss: 0.282107
[Epoch 29; Iter    10/   35] train: loss: 0.2627014
[Epoch 29] ogbg-molclintox: 0.762830 val loss: 0.292209
[Epoch 29] ogbg-molclintox: 0.619931 test loss: 0.299255
[Epoch 30; Iter     5/   35] train: loss: 0.3626059
[Epoch 30; Iter    35/   35] train: loss: 0.3054136
[Epoch 30] ogbg-molclintox: 0.630239 val loss: 0.257735
[Epoch 30] ogbg-molclintox: 0.679539 test loss: 0.239941
[Epoch 31; Iter    30/   35] train: loss: 0.2954261
[Epoch 31] ogbg-molclintox: 0.652558 val loss: 0.249375
[Epoch 31] ogbg-molclintox: 0.653777 test loss: 0.237457
[Epoch 32; Iter    25/   35] train: loss: 0.2542472
[Epoch 32] ogbg-molclintox: 0.750679 val loss: 0.242544
[Epoch 32] ogbg-molclintox: 0.686072 test loss: 0.247634
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.8/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.8_4_26-05_09-18-13
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.8
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6924706
[Epoch 1] ogbg-molclintox: 0.560424 val loss: 0.693061
[Epoch 1] ogbg-molclintox: 0.585919 test loss: 0.692943
[Epoch 2; Iter    20/   40] train: loss: 0.6923465
[Epoch 2] ogbg-molclintox: 0.547103 val loss: 0.693104
[Epoch 2] ogbg-molclintox: 0.583391 test loss: 0.692366
[Epoch 3; Iter    10/   40] train: loss: 0.6927047
[Epoch 3; Iter    40/   40] train: loss: 0.6931074
[Epoch 3] ogbg-molclintox: 0.533954 val loss: 0.692807
[Epoch 3] ogbg-molclintox: 0.548553 test loss: 0.692230
[Epoch 4; Iter    30/   40] train: loss: 0.6921254
[Epoch 4] ogbg-molclintox: 0.532422 val loss: 0.692635
[Epoch 4] ogbg-molclintox: 0.544740 test loss: 0.691971
[Epoch 5; Iter    20/   40] train: loss: 0.6917217
[Epoch 5] ogbg-molclintox: 0.525696 val loss: 0.692178
[Epoch 5] ogbg-molclintox: 0.510113 test loss: 0.691468
[Epoch 6; Iter    10/   40] train: loss: 0.6912804
[Epoch 6; Iter    40/   40] train: loss: 0.6905856
[Epoch 6] ogbg-molclintox: 0.534447 val loss: 0.691092
[Epoch 6] ogbg-molclintox: 0.533013 test loss: 0.690490
[Epoch 7; Iter    30/   40] train: loss: 0.6899758
[Epoch 7] ogbg-molclintox: 0.529133 val loss: 0.690153
[Epoch 7] ogbg-molclintox: 0.532020 test loss: 0.689596
[Epoch 8; Iter    20/   40] train: loss: 0.6892650
[Epoch 8] ogbg-molclintox: 0.526414 val loss: 0.688581
[Epoch 8] ogbg-molclintox: 0.534400 test loss: 0.687830
[Epoch 9; Iter    10/   40] train: loss: 0.6883821
[Epoch 9; Iter    40/   40] train: loss: 0.6872314
[Epoch 9] ogbg-molclintox: 0.527493 val loss: 0.687771
[Epoch 9] ogbg-molclintox: 0.523240 test loss: 0.687145
[Epoch 10; Iter    30/   40] train: loss: 0.6869738
[Epoch 10] ogbg-molclintox: 0.535473 val loss: 0.686849
[Epoch 10] ogbg-molclintox: 0.518775 test loss: 0.686303
[Epoch 11; Iter    20/   40] train: loss: 0.6856552
[Epoch 11] ogbg-molclintox: 0.539456 val loss: 0.685651
[Epoch 11] ogbg-molclintox: 0.552751 test loss: 0.684926
[Epoch 12; Iter    10/   40] train: loss: 0.6838041
[Epoch 12; Iter    40/   40] train: loss: 0.6838758
[Epoch 12] ogbg-molclintox: 0.553778 val loss: 0.684433
[Epoch 12] ogbg-molclintox: 0.558174 test loss: 0.683696
[Epoch 13; Iter    30/   40] train: loss: 0.6836172
[Epoch 13] ogbg-molclintox: 0.556176 val loss: 0.682579
[Epoch 13] ogbg-molclintox: 0.545084 test loss: 0.681906
[Epoch 14; Iter    20/   40] train: loss: 0.6806527
[Epoch 14] ogbg-molclintox: 0.549194 val loss: 0.681162
[Epoch 14] ogbg-molclintox: 0.554235 test loss: 0.680415
[Epoch 15; Iter    10/   40] train: loss: 0.6807681
[Epoch 15; Iter    40/   40] train: loss: 0.6796429
[Epoch 15] ogbg-molclintox: 0.556176 val loss: 0.679448
[Epoch 15] ogbg-molclintox: 0.547672 test loss: 0.678742
[Epoch 16; Iter    30/   40] train: loss: 0.6778875
[Epoch 16] ogbg-molclintox: 0.547691 val loss: 0.676969
[Epoch 16] ogbg-molclintox: 0.550839 test loss: 0.676055
[Epoch 17; Iter    20/   40] train: loss: 0.6750174
[Epoch 17] ogbg-molclintox: 0.553351 val loss: 0.675125
[Epoch 17] ogbg-molclintox: 0.560250 test loss: 0.674188
[Epoch 18; Iter    10/   40] train: loss: 0.6741679
[Epoch 18; Iter    40/   40] train: loss: 0.6561053
[Epoch 18] ogbg-molclintox: 0.662556 val loss: 0.667484
[Epoch 18] ogbg-molclintox: 0.679485 test loss: 0.672323
[Epoch 19; Iter    30/   40] train: loss: 0.6329444
[Epoch 19] ogbg-molclintox: 0.702561 val loss: 0.594124
[Epoch 19] ogbg-molclintox: 0.736021 test loss: 0.587042
[Epoch 20; Iter    20/   40] train: loss: 0.5941951
[Epoch 20] ogbg-molclintox: 0.699936 val loss: 0.584062
[Epoch 20] ogbg-molclintox: 0.696932 test loss: 0.575245
[Epoch 21; Iter    10/   40] train: loss: 0.5563325
[Epoch 21; Iter    40/   40] train: loss: 0.5865088
[Epoch 21] ogbg-molclintox: 0.683150 val loss: 0.485792
[Epoch 21] ogbg-molclintox: 0.753754 test loss: 0.484000
[Epoch 22; Iter    30/   40] train: loss: 0.4662794
[Epoch 22] ogbg-molclintox: 0.669444 val loss: 0.419253
[Epoch 22] ogbg-molclintox: 0.692746 test loss: 0.411683
[Epoch 23; Iter    20/   40] train: loss: 0.3964773
[Epoch 23] ogbg-molclintox: 0.701625 val loss: 0.335009
[Epoch 23] ogbg-molclintox: 0.712608 test loss: 0.329426
[Epoch 24; Iter    10/   40] train: loss: 0.3058076
[Epoch 24; Iter    40/   40] train: loss: 0.2391199
[Epoch 24] ogbg-molclintox: 0.695073 val loss: 0.314082
[Epoch 24] ogbg-molclintox: 0.688384 test loss: 0.308654
[Epoch 25; Iter    30/   40] train: loss: 0.2912980
[Epoch 25] ogbg-molclintox: 0.673743 val loss: 0.276302
[Epoch 25] ogbg-molclintox: 0.594293 test loss: 0.347293
[Epoch 26; Iter    20/   40] train: loss: 0.2375721
[Epoch 26] ogbg-molclintox: 0.653682 val loss: 0.272926
[Epoch 26] ogbg-molclintox: 0.623702 test loss: 0.259054
[Epoch 27; Iter    10/   40] train: loss: 0.3973346
[Epoch 27; Iter    40/   40] train: loss: 0.1961938
[Epoch 27] ogbg-molclintox: 0.753995 val loss: 0.236700
[Epoch 27] ogbg-molclintox: 0.676524 test loss: 0.228776
[Epoch 28; Iter    30/   40] train: loss: 0.1413924
[Epoch 28] ogbg-molclintox: 0.706118 val loss: 0.254746
[Epoch 28] ogbg-molclintox: 0.614985 test loss: 0.260755
[Epoch 29; Iter    20/   40] train: loss: 0.3773679
[Epoch 29] ogbg-molclintox: 0.715894 val loss: 0.240703
[Epoch 29] ogbg-molclintox: 0.653594 test loss: 0.235709
[Epoch 30; Iter    10/   40] train: loss: 0.2790593
[Epoch 30; Iter    40/   40] train: loss: 0.1008521
[Epoch 30] ogbg-molclintox: 0.690105 val loss: 0.254796
[Epoch 30] ogbg-molclintox: 0.573640 test loss: 0.267539
[Epoch 31; Iter    30/   40] train: loss: 0.1610565
[Epoch 31] ogbg-molclintox: 0.651270 val loss: 0.256645
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.7/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.7_6_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.7
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6948523
[Epoch 1] ogbg-molclintox: 0.480968 val loss: 0.692695
[Epoch 1] ogbg-molclintox: 0.546869 test loss: 0.692791
[Epoch 2; Iter    25/   35] train: loss: 0.6913998
[Epoch 2] ogbg-molclintox: 0.463566 val loss: 0.691847
[Epoch 2] ogbg-molclintox: 0.529637 test loss: 0.692110
[Epoch 3; Iter    20/   35] train: loss: 0.6941901
[Epoch 3] ogbg-molclintox: 0.437151 val loss: 0.690318
[Epoch 3] ogbg-molclintox: 0.525653 test loss: 0.690394
[Epoch 4; Iter    15/   35] train: loss: 0.6932070
[Epoch 4] ogbg-molclintox: 0.439726 val loss: 0.691557
[Epoch 4] ogbg-molclintox: 0.514669 test loss: 0.691492
[Epoch 5; Iter    10/   35] train: loss: 0.6928626
[Epoch 5] ogbg-molclintox: 0.441262 val loss: 0.691073
[Epoch 5] ogbg-molclintox: 0.528817 test loss: 0.690966
[Epoch 6; Iter     5/   35] train: loss: 0.6914685
[Epoch 6; Iter    35/   35] train: loss: 0.6910924
[Epoch 6] ogbg-molclintox: 0.442258 val loss: 0.690527
[Epoch 6] ogbg-molclintox: 0.513667 test loss: 0.690435
[Epoch 7; Iter    30/   35] train: loss: 0.6918975
[Epoch 7] ogbg-molclintox: 0.430675 val loss: 0.689652
[Epoch 7] ogbg-molclintox: 0.526620 test loss: 0.689612
[Epoch 8; Iter    25/   35] train: loss: 0.6910632
[Epoch 8] ogbg-molclintox: 0.454440 val loss: 0.689269
[Epoch 8] ogbg-molclintox: 0.518328 test loss: 0.689367
[Epoch 9; Iter    20/   35] train: loss: 0.6911536
[Epoch 9] ogbg-molclintox: 0.437188 val loss: 0.688343
[Epoch 9] ogbg-molclintox: 0.510706 test loss: 0.688284
[Epoch 10; Iter    15/   35] train: loss: 0.6894410
[Epoch 10] ogbg-molclintox: 0.443335 val loss: 0.686369
[Epoch 10] ogbg-molclintox: 0.513193 test loss: 0.686298
[Epoch 11; Iter    10/   35] train: loss: 0.6875235
[Epoch 11] ogbg-molclintox: 0.437369 val loss: 0.685444
[Epoch 11] ogbg-molclintox: 0.512147 test loss: 0.685393
[Epoch 12; Iter     5/   35] train: loss: 0.6866828
[Epoch 12; Iter    35/   35] train: loss: 0.6846194
[Epoch 12] ogbg-molclintox: 0.448852 val loss: 0.684760
[Epoch 12] ogbg-molclintox: 0.517068 test loss: 0.684841
[Epoch 13; Iter    30/   35] train: loss: 0.6839380
[Epoch 13] ogbg-molclintox: 0.440410 val loss: 0.683174
[Epoch 13] ogbg-molclintox: 0.532966 test loss: 0.683306
[Epoch 14; Iter    25/   35] train: loss: 0.6837147
[Epoch 14] ogbg-molclintox: 0.445240 val loss: 0.681601
[Epoch 14] ogbg-molclintox: 0.520634 test loss: 0.681684
[Epoch 15; Iter    20/   35] train: loss: 0.6809695
[Epoch 15] ogbg-molclintox: 0.445580 val loss: 0.681256
[Epoch 15] ogbg-molclintox: 0.516652 test loss: 0.681255
[Epoch 16; Iter    15/   35] train: loss: 0.6794401
[Epoch 16] ogbg-molclintox: 0.442672 val loss: 0.678846
[Epoch 16] ogbg-molclintox: 0.530220 test loss: 0.678987
[Epoch 17; Iter    10/   35] train: loss: 0.6805456
[Epoch 17] ogbg-molclintox: 0.444381 val loss: 0.676643
[Epoch 17] ogbg-molclintox: 0.521512 test loss: 0.676908
[Epoch 18; Iter     5/   35] train: loss: 0.6781323
[Epoch 18; Iter    35/   35] train: loss: 0.6739424
[Epoch 18] ogbg-molclintox: 0.440978 val loss: 0.675151
[Epoch 18] ogbg-molclintox: 0.519140 test loss: 0.675204
[Epoch 19; Iter    30/   35] train: loss: 0.6771454
[Epoch 19] ogbg-molclintox: 0.452564 val loss: 0.672678
[Epoch 19] ogbg-molclintox: 0.526135 test loss: 0.673046
[Epoch 20; Iter    25/   35] train: loss: 0.6743223
[Epoch 20] ogbg-molclintox: 0.529223 val loss: 0.676050
[Epoch 20] ogbg-molclintox: 0.602917 test loss: 0.676457
[Epoch 21; Iter    20/   35] train: loss: 0.6580225
[Epoch 21] ogbg-molclintox: 0.639157 val loss: 0.624060
[Epoch 21] ogbg-molclintox: 0.701040 test loss: 0.622946
[Epoch 22; Iter    15/   35] train: loss: 0.6272237
[Epoch 22] ogbg-molclintox: 0.778232 val loss: 0.664694
[Epoch 22] ogbg-molclintox: 0.656195 test loss: 0.676711
[Epoch 23; Iter    10/   35] train: loss: 0.5904033
[Epoch 23] ogbg-molclintox: 0.728507 val loss: 0.500448
[Epoch 23] ogbg-molclintox: 0.710947 test loss: 0.505721
[Epoch 24; Iter     5/   35] train: loss: 0.5434338
[Epoch 24; Iter    35/   35] train: loss: 0.4989075
[Epoch 24] ogbg-molclintox: 0.699426 val loss: 0.435360
[Epoch 24] ogbg-molclintox: 0.612688 test loss: 0.458225
[Epoch 25; Iter    30/   35] train: loss: 0.5004493
[Epoch 25] ogbg-molclintox: 0.664237 val loss: 0.393297
[Epoch 25] ogbg-molclintox: 0.721964 test loss: 0.398845
[Epoch 26; Iter    25/   35] train: loss: 0.3724964
[Epoch 26] ogbg-molclintox: 0.632106 val loss: 0.385891
[Epoch 26] ogbg-molclintox: 0.669850 test loss: 0.399278
[Epoch 27; Iter    20/   35] train: loss: 0.2875501
[Epoch 27] ogbg-molclintox: 0.665156 val loss: 0.295706
[Epoch 27] ogbg-molclintox: 0.657243 test loss: 0.312477
[Epoch 28; Iter    15/   35] train: loss: 0.3155344
[Epoch 28] ogbg-molclintox: 0.714027 val loss: 0.285294
[Epoch 28] ogbg-molclintox: 0.670651 test loss: 0.296591
[Epoch 29; Iter    10/   35] train: loss: 0.3476271
[Epoch 29] ogbg-molclintox: 0.676912 val loss: 0.380904
[Epoch 29] ogbg-molclintox: 0.711905 test loss: 0.239557
[Epoch 30; Iter     5/   35] train: loss: 0.1545881
[Epoch 30; Iter    35/   35] train: loss: 0.3797635
[Epoch 30] ogbg-molclintox: 0.787753 val loss: 0.238861
[Epoch 30] ogbg-molclintox: 0.685376 test loss: 0.275065
[Epoch 31; Iter    30/   35] train: loss: 0.2599442
[Epoch 31] ogbg-molclintox: 0.693662 val loss: 0.244091
[Epoch 31] ogbg-molclintox: 0.594372 test loss: 0.260091
[Epoch 32; Iter    25/   35] train: loss: 0.2571585
[Epoch 32] ogbg-molclintox: 0.674615 val loss: 0.245988
[Epoch 32] ogbg-molclintox: 0.716565 test loss: 0.226949
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/3DInfomax/clintox/random/train_prop=0.6/PNA_ogbg-molclintox_3DInfomax_clintox_random=0.6_5_26-05_09-18-12
config: <_io.TextIOWrapper name='configs_split_experiments/3DInfomax/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: 3DInfomax_clintox_random=0.6
logdir: runs/split/3DInfomax/clintox/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_3DInfomax_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6919538
[Epoch 1] ogbg-molclintox: 0.543061 val loss: 0.693287
[Epoch 1] ogbg-molclintox: 0.460417 test loss: 0.693473
[Epoch 2; Iter    30/   30] train: loss: 0.6932213
[Epoch 2] ogbg-molclintox: 0.544838 val loss: 0.692128
[Epoch 2] ogbg-molclintox: 0.459311 test loss: 0.693049
[Epoch 3; Iter    30/   30] train: loss: 0.6936542
[Epoch 3] ogbg-molclintox: 0.544703 val loss: 0.690995
[Epoch 3] ogbg-molclintox: 0.459054 test loss: 0.692722
[Epoch 4; Iter    30/   30] train: loss: 0.6917105
[Epoch 4] ogbg-molclintox: 0.552832 val loss: 0.691528
[Epoch 4] ogbg-molclintox: 0.474051 test loss: 0.693193
[Epoch 5; Iter    30/   30] train: loss: 0.6915679
[Epoch 5] ogbg-molclintox: 0.549140 val loss: 0.691174
[Epoch 5] ogbg-molclintox: 0.474271 test loss: 0.692800
[Epoch 6; Iter    30/   30] train: loss: 0.6900925
[Epoch 6] ogbg-molclintox: 0.547135 val loss: 0.690579
[Epoch 6] ogbg-molclintox: 0.474086 test loss: 0.692304
[Epoch 7; Iter    30/   30] train: loss: 0.6924736
[Epoch 7] ogbg-molclintox: 0.545607 val loss: 0.689946
[Epoch 7] ogbg-molclintox: 0.471464 test loss: 0.691739
[Epoch 8; Iter    30/   30] train: loss: 0.6896595
[Epoch 8] ogbg-molclintox: 0.554594 val loss: 0.689266
[Epoch 8] ogbg-molclintox: 0.471688 test loss: 0.691117
[Epoch 9; Iter    30/   30] train: loss: 0.6919470
[Epoch 9] ogbg-molclintox: 0.555252 val loss: 0.689391
[Epoch 9] ogbg-molclintox: 0.471264 test loss: 0.691208
[Epoch 10; Iter    30/   30] train: loss: 0.6880459
[Epoch 10] ogbg-molclintox: 0.546675 val loss: 0.688596
[Epoch 10] ogbg-molclintox: 0.473330 test loss: 0.690504
[Epoch 11; Iter    30/   30] train: loss: 0.6925985
[Epoch 11] ogbg-molclintox: 0.551151 val loss: 0.688119
[Epoch 11] ogbg-molclintox: 0.473995 test loss: 0.690015
[Epoch 12; Iter    30/   30] train: loss: 0.6883743
[Epoch 12] ogbg-molclintox: 0.558272 val loss: 0.687418
[Epoch 12] ogbg-molclintox: 0.471119 test loss: 0.689390
[Epoch 13; Iter    30/   30] train: loss: 0.6881576
[Epoch 13] ogbg-molclintox: 0.553873 val loss: 0.686212
[Epoch 13] ogbg-molclintox: 0.478731 test loss: 0.688192
[Epoch 14; Iter    30/   30] train: loss: 0.6876562
[Epoch 14] ogbg-molclintox: 0.556323 val loss: 0.685682
[Epoch 14] ogbg-molclintox: 0.479734 test loss: 0.687650
[Epoch 15; Iter    30/   30] train: loss: 0.6848500
[Epoch 15] ogbg-molclintox: 0.551527 val loss: 0.684856
[Epoch 15] ogbg-molclintox: 0.471257 test loss: 0.686846
[Epoch 16; Iter    30/   30] train: loss: 0.6846572
[Epoch 16] ogbg-molclintox: 0.549212 val loss: 0.683731
[Epoch 16] ogbg-molclintox: 0.474790 test loss: 0.685821
[Epoch 17; Iter    30/   30] train: loss: 0.6835220
[Epoch 17] ogbg-molclintox: 0.557780 val loss: 0.682650
[Epoch 17] ogbg-molclintox: 0.479421 test loss: 0.684786
[Epoch 18; Iter    30/   30] train: loss: 0.6838404
[Epoch 18] ogbg-molclintox: 0.566357 val loss: 0.681798
[Epoch 18] ogbg-molclintox: 0.480861 test loss: 0.683995
[Epoch 19; Iter    30/   30] train: loss: 0.6811141
[Epoch 19] ogbg-molclintox: 0.573277 val loss: 0.680817
[Epoch 19] ogbg-molclintox: 0.483149 test loss: 0.682950
[Epoch 20; Iter    30/   30] train: loss: 0.6808854
[Epoch 20] ogbg-molclintox: 0.571138 val loss: 0.679507
[Epoch 20] ogbg-molclintox: 0.479168 test loss: 0.681866
[Epoch 21; Iter    30/   30] train: loss: 0.6844889
[Epoch 21] ogbg-molclintox: 0.557379 val loss: 0.677442
[Epoch 21] ogbg-molclintox: 0.475900 test loss: 0.679704
[Epoch 22; Iter    30/   30] train: loss: 0.6770568
[Epoch 22] ogbg-molclintox: 0.563814 val loss: 0.677158
[Epoch 22] ogbg-molclintox: 0.479344 test loss: 0.679500
[Epoch 23; Iter    30/   30] train: loss: 0.6752220
[Epoch 23] ogbg-molclintox: 0.672527 val loss: 0.674534
[Epoch 23] ogbg-molclintox: 0.533127 test loss: 0.677086
[Epoch 24; Iter    30/   30] train: loss: 0.6521420
[Epoch 24] ogbg-molclintox: 0.695139 val loss: 0.645297
[Epoch 24] ogbg-molclintox: 0.659923 test loss: 0.648910
[Epoch 25; Iter    30/   30] train: loss: 0.6288518
[Epoch 25] ogbg-molclintox: 0.712589 val loss: 0.624034
[Epoch 25] ogbg-molclintox: 0.694653 test loss: 0.624875
[Epoch 26; Iter    30/   30] train: loss: 0.5723734
[Epoch 26] ogbg-molclintox: 0.752427 val loss: 0.594061
[Epoch 26] ogbg-molclintox: 0.687840 test loss: 0.595777
[Epoch 27; Iter    30/   30] train: loss: 0.5361419
[Epoch 27] ogbg-molclintox: 0.737575 val loss: 0.475097
[Epoch 27] ogbg-molclintox: 0.703255 test loss: 0.488554
[Epoch 28; Iter    30/   30] train: loss: 0.5250694
[Epoch 28] ogbg-molclintox: 0.760482 val loss: 0.535399
[Epoch 28] ogbg-molclintox: 0.680583 test loss: 0.546831
[Epoch 29; Iter    30/   30] train: loss: 0.4650386
[Epoch 29] ogbg-molclintox: 0.747471 val loss: 0.387229
[Epoch 29] ogbg-molclintox: 0.647475 test loss: 0.415837
[Epoch 30; Iter    30/   30] train: loss: 0.4537965
[Epoch 30] ogbg-molclintox: 0.741056 val loss: 0.446362
[Epoch 30] ogbg-molclintox: 0.645795 test loss: 0.471195
[Epoch 31; Iter    30/   30] train: loss: 0.3774278
[Epoch 31] ogbg-molclintox: 0.771982 val loss: 0.271935
[Epoch 31] ogbg-molclintox: 0.618074 test loss: 0.330426
[Epoch 32; Iter    30/   30] train: loss: 0.2536630
[Epoch 32] ogbg-molclintox: 0.751246 val loss: 0.269071
[Epoch 32] ogbg-molclintox: 0.603655 test loss: 0.320050
[Epoch 33; Iter    30/   30] train: loss: 0.1901857
[Epoch 33] ogbg-molclintox: 0.719045 val loss: 0.227261
[Epoch 33] ogbg-molclintox: 0.586512 test loss: 0.293900
[Epoch 34; Iter    30/   30] train: loss: 0.2717775
[Epoch 34] ogbg-molclintox: 0.769316 val loss: 0.200527
[Epoch 34] ogbg-molclintox: 0.576329 test loss: 0.333099
[Epoch 35; Iter    30/   30] train: loss: 0.3259457
[Epoch 35] ogbg-molclintox: 0.757220 val loss: 0.275332
[Epoch 35] ogbg-molclintox: 0.699266 test loss: 0.244194
[Epoch 36; Iter    30/   30] train: loss: 0.2003179
[Epoch 36] ogbg-molclintox: 0.752524 val loss: 0.284772
[Epoch 36] ogbg-molclintox: 0.632193 test loss: 0.265331
[Epoch 37; Iter    30/   30] train: loss: 0.1241270
[Epoch 37] ogbg-molclintox: 0.767975 val loss: 0.288342
[Epoch 37] ogbg-molclintox: 0.704240 test loss: 0.243305
[Epoch 38; Iter    30/   30] train: loss: 0.3158630
[Epoch 38] ogbg-molclintox: 0.816460 val loss: 0.281209
[Epoch 38] ogbg-molclintox: 0.685290 test loss: 0.237048
[Epoch 39; Iter    30/   30] train: loss: 0.0811868
[Epoch 39] ogbg-molclintox: 0.753699 val loss: 0.285219
[Epoch 39] ogbg-molclintox: 0.616175 test loss: 0.251937
[Epoch 40; Iter    30/   30] train: loss: 0.1773164
[Epoch 40] ogbg-molclintox: 0.747291 val loss: 0.346274
[Epoch 40] ogbg-molclintox: 0.642530 test loss: 0.288209
[Epoch 41; Iter    30/   30] train: loss: 0.0814304
[Epoch 41] ogbg-molclintox: 0.764397 val loss: 0.264994
[Epoch 41] ogbg-molclintox: 0.658731 test loss: 0.244538
[Epoch 42; Iter    30/   30] train: loss: 0.0843480
[Epoch 42] ogbg-molclintox: 0.740521 val loss: 0.287152
[Epoch 42] ogbg-molclintox: 0.599559 test loss: 0.271882
[Epoch 43; Iter    30/   30] train: loss: 0.0827507
[Epoch 43] ogbg-molclintox: 0.797416 val loss: 0.299323
[Epoch 43] ogbg-molclintox: 0.659063 test loss: 0.260630
[Epoch 44; Iter    30/   30] train: loss: 0.3993777
[Epoch 44] ogbg-molclintox: 0.790881 val loss: 0.282590
[Epoch 44] ogbg-molclintox: 0.655374 test loss: 0.244063
[Epoch 45; Iter    30/   30] train: loss: 0.1589945
[Epoch 45] ogbg-molclintox: 0.730101 val loss: 0.316816
[Epoch 45] ogbg-molclintox: 0.656231 test loss: 0.258377
[Epoch 46; Iter    30/   30] train: loss: 0.2567793
[Epoch 46] ogbg-molclintox: 0.752407 val loss: 0.337166
[Epoch 46] ogbg-molclintox: 0.643918 test loss: 0.345758
[Epoch 47; Iter    30/   30] train: loss: 0.3745204
[Epoch 47] ogbg-molclintox: 0.786022 val loss: 1.023390
[Epoch 47] ogbg-molclintox: 0.755000 test loss: 0.969089
[Epoch 48; Iter    30/   30] train: loss: 0.0957339
[Epoch 48] ogbg-molclintox: 0.667014 val loss: 0.918483
[Epoch 48] ogbg-molclintox: 0.670112 test loss: 0.748020
[Epoch 49; Iter    30/   30] train: loss: 0.2168884
[Epoch 49] ogbg-molclintox: 0.750731 val loss: 0.185088
[Epoch 49] ogbg-molclintox: 0.757809 test loss: 0.229386
[Epoch 50; Iter    30/   30] train: loss: 0.2544499
[Epoch 50] ogbg-molclintox: 0.848110 val loss: 0.188735
[Epoch 50] ogbg-molclintox: 0.815434 test loss: 0.227136
[Epoch 51; Iter    30/   30] train: loss: 0.4324771
[Epoch 51] ogbg-molclintox: 0.678919 val loss: 0.339893
[Epoch 51] ogbg-molclintox: 0.732407 test loss: 0.259836
[Epoch 52; Iter    30/   30] train: loss: 0.1395826
[Epoch 52] ogbg-molclintox: 0.720382 val loss: 0.282301
[Epoch 52] ogbg-molclintox: 0.743655 test loss: 0.256306
[Epoch 53; Iter    30/   30] train: loss: 0.1210524
[Epoch 53] ogbg-molclintox: 0.809289 val loss: 0.185246
[Epoch 53] ogbg-molclintox: 0.805763 test loss: 0.208701
[Epoch 54; Iter    30/   30] train: loss: 0.0649908
[Epoch 54] ogbg-molclintox: 0.798701 val loss: 0.307714
[Epoch 54] ogbg-molclintox: 0.823892 test loss: 0.247268
[Epoch 55; Iter    30/   30] train: loss: 0.2197800
[Epoch 55] ogbg-molclintox: 0.839642 val loss: 0.145028
[Epoch 55] ogbg-molclintox: 0.822431 test loss: 0.210785
[Epoch 56; Iter    30/   30] train: loss: 0.0705453
[Epoch 56] ogbg-molclintox: 0.748355 val loss: 0.357825
[Epoch 56] ogbg-molclintox: 0.764285 test loss: 0.307523
[Epoch 57; Iter    30/   30] train: loss: 0.0495722
[Epoch 57] ogbg-molclintox: 0.812760 val loss: 0.165993
[Epoch 57] ogbg-molclintox: 0.828363 test loss: 0.227749
[Epoch 58; Iter    30/   30] train: loss: 0.0886876
[Epoch 58] ogbg-molclintox: 0.780610 val loss: 1.423462
[Epoch 58] ogbg-molclintox: 0.790588 test loss: 0.304084
[Epoch 59; Iter    30/   30] train: loss: 0.1442823
[Epoch 59] ogbg-molclintox: 0.765389 val loss: 0.380706
[Epoch 59] ogbg-molclintox: 0.776528 test loss: 0.278940
[Epoch 60; Iter    30/   30] train: loss: 0.0842088
[Epoch 60] ogbg-molclintox: 0.847715 val loss: 0.267475
[Epoch 60] ogbg-molclintox: 0.842682 test loss: 0.240067
[Epoch 61; Iter    30/   30] train: loss: 0.2797341
[Epoch 61] ogbg-molclintox: 0.874834 val loss: 0.155691
[Epoch 61] ogbg-molclintox: 0.781618 test loss: 0.249194
[Epoch 62; Iter    30/   30] train: loss: 0.0691745
[Epoch 62] ogbg-molclintox: 0.804166 val loss: 0.212013
[Epoch 62] ogbg-molclintox: 0.775681 test loss: 0.272774
[Epoch 63; Iter    30/   30] train: loss: 0.1829465
[Epoch 63] ogbg-molclintox: 0.889984 val loss: 0.153233
[Epoch 63] ogbg-molclintox: 0.795245 test loss: 0.234197
[Epoch 64; Iter    30/   30] train: loss: 0.0253099
[Epoch 64] ogbg-molclintox: 0.815391 val loss: 0.181687
[Epoch 64] ogbg-molclintox: 0.808127 test loss: 0.225327
[Epoch 65; Iter    30/   30] train: loss: 0.0489953
[Epoch 65] ogbg-molclintox: 0.872683 val loss: 0.148806
[Epoch 65] ogbg-molclintox: 0.759278 test loss: 0.304528
[Epoch 66; Iter    30/   30] train: loss: 0.0139100
[Epoch 66] ogbg-molclintox: 0.733132 val loss: 0.246222
[Epoch 66] ogbg-molclintox: 0.705269 test loss: 0.270758
[Epoch 67; Iter    30/   30] train: loss: 0.2437741
[Epoch 67] ogbg-molclintox: 0.811576 val loss: 0.191568
[Epoch 67] ogbg-molclintox: 0.821670 test loss: 0.267103
[Epoch 68; Iter    30/   30] train: loss: 0.0979566
[Epoch 68] ogbg-molclintox: 0.844855 val loss: 0.171976
[Epoch 68] ogbg-molclintox: 0.794288 test loss: 0.270797
[Epoch 69; Iter    30/   30] train: loss: 0.0469800
[Epoch 69] ogbg-molclintox: 0.799594 val loss: 0.206764
[Epoch 69] ogbg-molclintox: 0.756489 test loss: 0.309729
[Epoch 70; Iter    30/   30] train: loss: 0.0267688
[Epoch 70] ogbg-molclintox: 0.829135 val loss: 0.199960
[Epoch 70] ogbg-molclintox: 0.762559 test loss: 0.341621
[Epoch 71; Iter    30/   30] train: loss: 0.0989511
[Epoch 71] ogbg-molclintox: 0.835504 val loss: 0.473872
[Epoch 71] ogbg-molclintox: 0.819025 test loss: 0.356383
[Epoch 72; Iter    30/   30] train: loss: 0.2712138
[Epoch 72] ogbg-molclintox: 0.860622 val loss: 0.263737
[Epoch 72] ogbg-molclintox: 0.809277 test loss: 0.246033
[Epoch 73; Iter    30/   30] train: loss: 0.2249978
[Epoch 73] ogbg-molclintox: 0.871214 val loss: 0.149036
[Epoch 73] ogbg-molclintox: 0.836766 test loss: 0.233404
[Epoch 74; Iter    30/   30] train: loss: 0.0423497
[Epoch 74] ogbg-molclintox: 0.834801 val loss: 0.477530
[Epoch 74] ogbg-molclintox: 0.794714 test loss: 0.345570
[Epoch 75; Iter    30/   30] train: loss: 0.0780709
[Epoch 75] ogbg-molclintox: 0.840196 val loss: 0.190866
[Epoch 75] ogbg-molclintox: 0.833848 test loss: 0.286468
[Epoch 76; Iter    30/   30] train: loss: 0.0047835
[Epoch 76] ogbg-molclintox: 0.776838 val loss: 0.246548
[Epoch 76] ogbg-molclintox: 0.830495 test loss: 0.243023
[Epoch 77; Iter    30/   30] train: loss: 0.0098168
[Epoch 77] ogbg-molclintox: 0.826967 val loss: 0.176404
[Epoch 77] ogbg-molclintox: 0.791479 test loss: 0.273382
[Epoch 78; Iter    30/   30] train: loss: 0.0553755
[Epoch 78] ogbg-molclintox: 0.807662 val loss: 0.194547
[Epoch 78] ogbg-molclintox: 0.789375 test loss: 0.291892
[Epoch 79; Iter    30/   30] train: loss: 0.2489941
[Epoch 79] ogbg-molclintox: 0.746897 val loss: 0.225038
[Epoch 79] ogbg-molclintox: 0.777005 test loss: 0.275901
[Epoch 80; Iter    30/   30] train: loss: 0.0106406
[Epoch 80] ogbg-molclintox: 0.852881 val loss: 0.158462
[Epoch 80] ogbg-molclintox: 0.835726 test loss: 0.255536
[Epoch 81; Iter    30/   30] train: loss: 0.0140972
[Epoch 81] ogbg-molclintox: 0.782362 val loss: 0.195503
[Epoch 81] ogbg-molclintox: 0.844846 test loss: 0.258983
[Epoch 82; Iter    30/   30] train: loss: 0.0082510
[Epoch 82] ogbg-molclintox: 0.788639 val loss: 0.198426
[Epoch 82] ogbg-molclintox: 0.780084 test loss: 0.332262
[Epoch 83; Iter    30/   30] train: loss: 0.2144697
[Epoch 83] ogbg-molclintox: 0.808631 val loss: 0.277278
[Epoch 83] ogbg-molclintox: 0.831073 test loss: 0.357263
[Epoch 31] ogbg-molclintox: 0.645299 test loss: 0.249249
[Epoch 32; Iter    20/   40] train: loss: 0.2142863
[Epoch 32] ogbg-molclintox: 0.729311 val loss: 0.244383
[Epoch 32] ogbg-molclintox: 0.623153 test loss: 0.257162
[Epoch 33; Iter    10/   40] train: loss: 0.1865291
[Epoch 33; Iter    40/   40] train: loss: 0.2984165
[Epoch 33] ogbg-molclintox: 0.711765 val loss: 0.245569
[Epoch 33] ogbg-molclintox: 0.650457 test loss: 0.262643
[Epoch 34; Iter    30/   40] train: loss: 0.1499415
[Epoch 34] ogbg-molclintox: 0.758351 val loss: 0.236496
[Epoch 34] ogbg-molclintox: 0.658534 test loss: 0.240510
[Epoch 35; Iter    20/   40] train: loss: 0.1647539
[Epoch 35] ogbg-molclintox: 0.781901 val loss: 0.226118
[Epoch 35] ogbg-molclintox: 0.726063 test loss: 0.222255
[Epoch 36; Iter    10/   40] train: loss: 0.1327337
[Epoch 36; Iter    40/   40] train: loss: 0.4366255
[Epoch 36] ogbg-molclintox: 0.834376 val loss: 0.205876
[Epoch 36] ogbg-molclintox: 0.750020 test loss: 0.244910
[Epoch 37; Iter    30/   40] train: loss: 0.2405515
[Epoch 37] ogbg-molclintox: 0.865361 val loss: 0.207329
[Epoch 37] ogbg-molclintox: 0.760148 test loss: 0.250400
[Epoch 38; Iter    20/   40] train: loss: 0.1214108
[Epoch 38] ogbg-molclintox: 0.877179 val loss: 0.258673
[Epoch 38] ogbg-molclintox: 0.724028 test loss: 0.225836
[Epoch 39; Iter    10/   40] train: loss: 0.0878434
[Epoch 39; Iter    40/   40] train: loss: 0.2660952
[Epoch 39] ogbg-molclintox: 0.732555 val loss: 0.351749
[Epoch 39] ogbg-molclintox: 0.703340 test loss: 0.299225
[Epoch 40; Iter    30/   40] train: loss: 0.1175561
[Epoch 40] ogbg-molclintox: 0.815191 val loss: 0.224931
[Epoch 40] ogbg-molclintox: 0.629782 test loss: 0.428598
[Epoch 41; Iter    20/   40] train: loss: 0.2712397
[Epoch 41] ogbg-molclintox: 0.935671 val loss: 0.174219
[Epoch 41] ogbg-molclintox: 0.777878 test loss: 0.218048
[Epoch 42; Iter    10/   40] train: loss: 0.1141959
[Epoch 42; Iter    40/   40] train: loss: 0.0719893
[Epoch 42] ogbg-molclintox: 0.926945 val loss: 0.176063
[Epoch 42] ogbg-molclintox: 0.715156 test loss: 0.269116
[Epoch 43; Iter    30/   40] train: loss: 0.0943492
[Epoch 43] ogbg-molclintox: 0.851536 val loss: 0.204565
[Epoch 43] ogbg-molclintox: 0.737838 test loss: 0.237581
[Epoch 44; Iter    20/   40] train: loss: 0.0783525
[Epoch 44] ogbg-molclintox: 0.925494 val loss: 0.149214
[Epoch 44] ogbg-molclintox: 0.782373 test loss: 0.197464
[Epoch 45; Iter    10/   40] train: loss: 0.0926726
[Epoch 45; Iter    40/   40] train: loss: 0.0829347
[Epoch 45] ogbg-molclintox: 0.825533 val loss: 0.233427
[Epoch 45] ogbg-molclintox: 0.704947 test loss: 0.260827
[Epoch 46; Iter    30/   40] train: loss: 0.0439006
[Epoch 46] ogbg-molclintox: 0.942197 val loss: 0.230299
[Epoch 46] ogbg-molclintox: 0.785612 test loss: 1.112427
[Epoch 47; Iter    20/   40] train: loss: 0.2501883
[Epoch 47] ogbg-molclintox: 0.894149 val loss: 0.199935
[Epoch 47] ogbg-molclintox: 0.758906 test loss: 0.259688
[Epoch 48; Iter    10/   40] train: loss: 0.0961785
[Epoch 48; Iter    40/   40] train: loss: 0.0632966
[Epoch 48] ogbg-molclintox: 0.932034 val loss: 0.167984
[Epoch 48] ogbg-molclintox: 0.782487 test loss: 0.226154
[Epoch 49; Iter    30/   40] train: loss: 0.0364438
[Epoch 49] ogbg-molclintox: 0.885664 val loss: 0.192468
[Epoch 49] ogbg-molclintox: 0.847604 test loss: 0.197788
[Epoch 50; Iter    20/   40] train: loss: 0.1726511
[Epoch 50] ogbg-molclintox: 0.898281 val loss: 0.183572
[Epoch 50] ogbg-molclintox: 0.756487 test loss: 0.262377
[Epoch 51; Iter    10/   40] train: loss: 0.0507686
[Epoch 51; Iter    40/   40] train: loss: 0.0510496
[Epoch 51] ogbg-molclintox: 0.888757 val loss: 0.193852
[Epoch 51] ogbg-molclintox: 0.670624 test loss: 0.322991
[Epoch 52; Iter    30/   40] train: loss: 0.0689754
[Epoch 52] ogbg-molclintox: 0.889876 val loss: 0.187496
[Epoch 52] ogbg-molclintox: 0.761195 test loss: 0.270005
[Epoch 53; Iter    20/   40] train: loss: 0.0106850
[Epoch 53] ogbg-molclintox: 0.823094 val loss: 0.268361
[Epoch 53] ogbg-molclintox: 0.787199 test loss: 0.270312
[Epoch 54; Iter    10/   40] train: loss: 0.0843811
[Epoch 54; Iter    40/   40] train: loss: 0.0355663
[Epoch 54] ogbg-molclintox: 0.892644 val loss: 0.180219
[Epoch 54] ogbg-molclintox: 0.777546 test loss: 0.262322
[Epoch 55; Iter    30/   40] train: loss: 0.0503619
[Epoch 55] ogbg-molclintox: 0.896428 val loss: 0.171582
[Epoch 55] ogbg-molclintox: 0.800260 test loss: 0.241272
[Epoch 56; Iter    20/   40] train: loss: 0.0243791
[Epoch 56] ogbg-molclintox: 0.915009 val loss: 0.161378
[Epoch 56] ogbg-molclintox: 0.800006 test loss: 0.244581
[Epoch 57; Iter    10/   40] train: loss: 0.0693908
[Epoch 57; Iter    40/   40] train: loss: 0.0549436
[Epoch 57] ogbg-molclintox: 0.918328 val loss: 0.194904
[Epoch 57] ogbg-molclintox: 0.682469 test loss: 0.318517
[Epoch 58; Iter    30/   40] train: loss: 0.0891318
[Epoch 58] ogbg-molclintox: 0.930609 val loss: 0.153704
[Epoch 58] ogbg-molclintox: 0.826891 test loss: 0.253787
[Epoch 59; Iter    20/   40] train: loss: 0.1132784
[Epoch 59] ogbg-molclintox: 0.895628 val loss: 1.771984
[Epoch 59] ogbg-molclintox: 0.738793 test loss: 2.653484
[Epoch 60; Iter    10/   40] train: loss: 0.0753348
[Epoch 60; Iter    40/   40] train: loss: 0.0128351
[Epoch 60] ogbg-molclintox: 0.939774 val loss: 0.164303
[Epoch 60] ogbg-molclintox: 0.782538 test loss: 0.266339
[Epoch 61; Iter    30/   40] train: loss: 0.0968376
[Epoch 61] ogbg-molclintox: 0.925457 val loss: 0.148460
[Epoch 61] ogbg-molclintox: 0.751763 test loss: 0.321069
[Epoch 62; Iter    20/   40] train: loss: 0.0366188
[Epoch 62] ogbg-molclintox: 0.952150 val loss: 0.149530
[Epoch 62] ogbg-molclintox: 0.853871 test loss: 0.251089
[Epoch 63; Iter    10/   40] train: loss: 0.1189508
[Epoch 63; Iter    40/   40] train: loss: 0.0201516
[Epoch 63] ogbg-molclintox: 0.914158 val loss: 0.171783
[Epoch 63] ogbg-molclintox: 0.751820 test loss: 0.273499
[Epoch 64; Iter    30/   40] train: loss: 0.0659807
[Epoch 64] ogbg-molclintox: 0.931608 val loss: 0.173308
[Epoch 64] ogbg-molclintox: 0.757102 test loss: 0.291842
[Epoch 65; Iter    20/   40] train: loss: 0.0092400
[Epoch 65] ogbg-molclintox: 0.945584 val loss: 0.140339
[Epoch 65] ogbg-molclintox: 0.833891 test loss: 0.243968
[Epoch 66; Iter    10/   40] train: loss: 0.0082989
[Epoch 66; Iter    40/   40] train: loss: 0.0124445
[Epoch 66] ogbg-molclintox: 0.917835 val loss: 0.196414
[Epoch 66] ogbg-molclintox: 0.837912 test loss: 0.295250
[Epoch 67; Iter    30/   40] train: loss: 0.0626336
[Epoch 67] ogbg-molclintox: 0.891271 val loss: 0.195660
[Epoch 67] ogbg-molclintox: 0.785742 test loss: 0.299364
[Epoch 68; Iter    20/   40] train: loss: 0.0450724
[Epoch 68] ogbg-molclintox: 0.925709 val loss: 0.161833
[Epoch 68] ogbg-molclintox: 0.805390 test loss: 0.264606
[Epoch 69; Iter    10/   40] train: loss: 0.0417594
[Epoch 69; Iter    40/   40] train: loss: 0.0112381
[Epoch 69] ogbg-molclintox: 0.935380 val loss: 0.149882
[Epoch 69] ogbg-molclintox: 0.785935 test loss: 0.286821
[Epoch 70; Iter    30/   40] train: loss: 0.0506431
[Epoch 70] ogbg-molclintox: 0.919658 val loss: 0.173833
[Epoch 70] ogbg-molclintox: 0.826507 test loss: 0.243216
[Epoch 71; Iter    20/   40] train: loss: 0.1202147
[Epoch 71] ogbg-molclintox: 0.930024 val loss: 0.151668
[Epoch 71] ogbg-molclintox: 0.802289 test loss: 0.256093
[Epoch 72; Iter    10/   40] train: loss: 0.0592030
[Epoch 72; Iter    40/   40] train: loss: 0.2255463
[Epoch 72] ogbg-molclintox: 0.924987 val loss: 0.193956
[Epoch 72] ogbg-molclintox: 0.811881 test loss: 0.315637
[Epoch 73; Iter    30/   40] train: loss: 0.0765047
[Epoch 73] ogbg-molclintox: 0.896308 val loss: 0.181524
[Epoch 73] ogbg-molclintox: 0.767484 test loss: 0.292198
[Epoch 74; Iter    20/   40] train: loss: 0.0093995
[Epoch 74] ogbg-molclintox: 0.947595 val loss: 0.164315
[Epoch 74] ogbg-molclintox: 0.777094 test loss: 0.294420
[Epoch 75; Iter    10/   40] train: loss: 0.0805273
[Epoch 75; Iter    40/   40] train: loss: 0.0086183
[Epoch 75] ogbg-molclintox: 0.927066 val loss: 0.173973
[Epoch 75] ogbg-molclintox: 0.797692 test loss: 0.298753
[Epoch 76; Iter    30/   40] train: loss: 0.0348225
[Epoch 33; Iter    20/   35] train: loss: 0.1245765
[Epoch 33] ogbg-molclintox: 0.723802 val loss: 0.240544
[Epoch 33] ogbg-molclintox: 0.663235 test loss: 0.232583
[Epoch 34; Iter    15/   35] train: loss: 0.3812425
[Epoch 34] ogbg-molclintox: 0.683756 val loss: 0.285991
[Epoch 34] ogbg-molclintox: 0.701857 test loss: 0.231128
[Epoch 35; Iter    10/   35] train: loss: 0.2125992
[Epoch 35] ogbg-molclintox: 0.660591 val loss: 0.249065
[Epoch 35] ogbg-molclintox: 0.690604 test loss: 0.233482
[Epoch 36; Iter     5/   35] train: loss: 0.0948146
[Epoch 36; Iter    35/   35] train: loss: 0.4124161
[Epoch 36] ogbg-molclintox: 0.712513 val loss: 0.224752
[Epoch 36] ogbg-molclintox: 0.691786 test loss: 0.234459
[Epoch 37; Iter    30/   35] train: loss: 0.3082221
[Epoch 37] ogbg-molclintox: 0.722287 val loss: 0.219422
[Epoch 37] ogbg-molclintox: 0.665131 test loss: 0.239621
[Epoch 38; Iter    25/   35] train: loss: 0.2749800
[Epoch 38] ogbg-molclintox: 0.672380 val loss: 0.222056
[Epoch 38] ogbg-molclintox: 0.681135 test loss: 0.228325
[Epoch 39; Iter    20/   35] train: loss: 0.2410280
[Epoch 39] ogbg-molclintox: 0.770363 val loss: 0.202366
[Epoch 39] ogbg-molclintox: 0.728430 test loss: 0.232602
[Epoch 40; Iter    15/   35] train: loss: 0.3153931
[Epoch 40] ogbg-molclintox: 0.727694 val loss: 0.222280
[Epoch 40] ogbg-molclintox: 0.724488 test loss: 0.229705
[Epoch 41; Iter    10/   35] train: loss: 0.1670840
[Epoch 41] ogbg-molclintox: 0.829123 val loss: 0.180606
[Epoch 41] ogbg-molclintox: 0.617976 test loss: 0.267117
[Epoch 42; Iter     5/   35] train: loss: 0.1025888
[Epoch 42; Iter    35/   35] train: loss: 0.2291465
[Epoch 42] ogbg-molclintox: 0.682268 val loss: 0.882384
[Epoch 42] ogbg-molclintox: 0.648897 test loss: 0.764071
[Epoch 43; Iter    30/   35] train: loss: 0.1992588
[Epoch 43] ogbg-molclintox: 0.848019 val loss: 0.452921
[Epoch 43] ogbg-molclintox: 0.768773 test loss: 0.256279
[Epoch 44; Iter    25/   35] train: loss: 0.2598252
[Epoch 44] ogbg-molclintox: 0.830779 val loss: 0.650093
[Epoch 44] ogbg-molclintox: 0.820809 test loss: 0.342432
[Epoch 45; Iter    20/   35] train: loss: 0.1148592
[Epoch 45] ogbg-molclintox: 0.876648 val loss: 0.172963
[Epoch 45] ogbg-molclintox: 0.800977 test loss: 0.215233
[Epoch 46; Iter    15/   35] train: loss: 0.1747006
[Epoch 46] ogbg-molclintox: 0.842537 val loss: 0.714880
[Epoch 46] ogbg-molclintox: 0.772210 test loss: 0.220971
[Epoch 47; Iter    10/   35] train: loss: 0.1729584
[Epoch 47] ogbg-molclintox: 0.884081 val loss: 0.307950
[Epoch 47] ogbg-molclintox: 0.742451 test loss: 0.248256
[Epoch 48; Iter     5/   35] train: loss: 0.1460326
[Epoch 48; Iter    35/   35] train: loss: 0.0837174
[Epoch 48] ogbg-molclintox: 0.540636 val loss: 0.376930
[Epoch 48] ogbg-molclintox: 0.641033 test loss: 0.347417
[Epoch 49; Iter    30/   35] train: loss: 0.1191934
[Epoch 49] ogbg-molclintox: 0.889157 val loss: 1.345950
[Epoch 49] ogbg-molclintox: 0.736426 test loss: 0.289934
[Epoch 50; Iter    25/   35] train: loss: 0.1174971
[Epoch 50] ogbg-molclintox: 0.914383 val loss: 0.531055
[Epoch 50] ogbg-molclintox: 0.781850 test loss: 0.218306
[Epoch 51; Iter    20/   35] train: loss: 0.0831136
[Epoch 51] ogbg-molclintox: 0.894205 val loss: 0.185676
[Epoch 51] ogbg-molclintox: 0.826240 test loss: 0.208902
[Epoch 52; Iter    15/   35] train: loss: 0.1644398
[Epoch 52] ogbg-molclintox: 0.931092 val loss: 0.137820
[Epoch 52] ogbg-molclintox: 0.789735 test loss: 0.218446
[Epoch 53; Iter    10/   35] train: loss: 0.0919810
[Epoch 53] ogbg-molclintox: 0.916241 val loss: 0.251020
[Epoch 53] ogbg-molclintox: 0.784362 test loss: 0.231724
[Epoch 54; Iter     5/   35] train: loss: 0.0510133
[Epoch 54; Iter    35/   35] train: loss: 0.0588038
[Epoch 54] ogbg-molclintox: 0.678287 val loss: 63.927190
[Epoch 54] ogbg-molclintox: 0.633959 test loss: 60.237039
[Epoch 55; Iter    30/   35] train: loss: 0.1194922
[Epoch 55] ogbg-molclintox: 0.919384 val loss: 0.136037
[Epoch 55] ogbg-molclintox: 0.794580 test loss: 0.214093
[Epoch 56; Iter    25/   35] train: loss: 0.2232271
[Epoch 56] ogbg-molclintox: 0.872286 val loss: 1.211862
[Epoch 56] ogbg-molclintox: 0.774884 test loss: 0.709882
[Epoch 57; Iter    20/   35] train: loss: 0.1533832
[Epoch 57] ogbg-molclintox: 0.932668 val loss: 0.152524
[Epoch 57] ogbg-molclintox: 0.850536 test loss: 0.224266
[Epoch 58; Iter    15/   35] train: loss: 0.1489140
[Epoch 58] ogbg-molclintox: 0.930430 val loss: 0.127488
[Epoch 58] ogbg-molclintox: 0.852981 test loss: 0.179111
[Epoch 59; Iter    10/   35] train: loss: 0.1109169
[Epoch 59] ogbg-molclintox: 0.917830 val loss: 1.278856
[Epoch 59] ogbg-molclintox: 0.828392 test loss: 0.192700
[Epoch 60; Iter     5/   35] train: loss: 0.2584770
[Epoch 60; Iter    35/   35] train: loss: 0.1403759
[Epoch 60] ogbg-molclintox: 0.949524 val loss: 0.686613
[Epoch 60] ogbg-molclintox: 0.827884 test loss: 0.244678
[Epoch 61; Iter    30/   35] train: loss: 0.0611493
[Epoch 61] ogbg-molclintox: 0.964185 val loss: 0.099974
[Epoch 61] ogbg-molclintox: 0.807282 test loss: 0.194656
[Epoch 62; Iter    25/   35] train: loss: 0.0783487
[Epoch 62] ogbg-molclintox: 0.919927 val loss: 0.386067
[Epoch 62] ogbg-molclintox: 0.822222 test loss: 0.185597
[Epoch 63; Iter    20/   35] train: loss: 0.1308622
[Epoch 63] ogbg-molclintox: 0.940280 val loss: 0.116881
[Epoch 63] ogbg-molclintox: 0.818861 test loss: 0.206448
[Epoch 64; Iter    15/   35] train: loss: 0.0413544
[Epoch 64] ogbg-molclintox: 0.902089 val loss: 0.147985
[Epoch 64] ogbg-molclintox: 0.820943 test loss: 0.216467
[Epoch 65; Iter    10/   35] train: loss: 0.3726929
[Epoch 65] ogbg-molclintox: 0.934695 val loss: 0.138850
[Epoch 65] ogbg-molclintox: 0.840246 test loss: 0.199356
[Epoch 66; Iter     5/   35] train: loss: 0.1430575
[Epoch 66; Iter    35/   35] train: loss: 0.5455483
[Epoch 66] ogbg-molclintox: 0.917128 val loss: 0.125858
[Epoch 66] ogbg-molclintox: 0.821395 test loss: 0.219849
[Epoch 67; Iter    30/   35] train: loss: 0.2946211
[Epoch 67] ogbg-molclintox: 0.937489 val loss: 0.120615
[Epoch 67] ogbg-molclintox: 0.856037 test loss: 0.188451
[Epoch 68; Iter    25/   35] train: loss: 0.0170402
[Epoch 68] ogbg-molclintox: 0.896532 val loss: 0.707042
[Epoch 68] ogbg-molclintox: 0.751167 test loss: 0.247426
[Epoch 69; Iter    20/   35] train: loss: 0.0984902
[Epoch 69] ogbg-molclintox: 0.938990 val loss: 0.123214
[Epoch 69] ogbg-molclintox: 0.815700 test loss: 0.223088
[Epoch 70; Iter    15/   35] train: loss: 0.0344229
[Epoch 70] ogbg-molclintox: 0.870723 val loss: 1.063493
[Epoch 70] ogbg-molclintox: 0.754096 test loss: 0.242037
[Epoch 71; Iter    10/   35] train: loss: 0.0292663
[Epoch 71] ogbg-molclintox: 0.895267 val loss: 0.165566
[Epoch 71] ogbg-molclintox: 0.799774 test loss: 0.252306
[Epoch 72; Iter     5/   35] train: loss: 0.0430428
[Epoch 72; Iter    35/   35] train: loss: 0.0462850
[Epoch 72] ogbg-molclintox: 0.907380 val loss: 0.910883
[Epoch 72] ogbg-molclintox: 0.827165 test loss: 0.213700
[Epoch 73; Iter    30/   35] train: loss: 0.0307645
[Epoch 73] ogbg-molclintox: 0.888964 val loss: 1.576163
[Epoch 73] ogbg-molclintox: 0.839338 test loss: 0.262332
[Epoch 74; Iter    25/   35] train: loss: 0.0965897
[Epoch 74] ogbg-molclintox: 0.882574 val loss: 0.165160
[Epoch 74] ogbg-molclintox: 0.798699 test loss: 0.242068
[Epoch 75; Iter    20/   35] train: loss: 0.1256068
[Epoch 75] ogbg-molclintox: 0.877703 val loss: 0.812660
[Epoch 75] ogbg-molclintox: 0.783773 test loss: 0.251304
[Epoch 76; Iter    15/   35] train: loss: 0.0393788
[Epoch 76] ogbg-molclintox: 0.904980 val loss: 1.075287
[Epoch 76] ogbg-molclintox: 0.844456 test loss: 0.254954
[Epoch 77; Iter    10/   35] train: loss: 0.0787592
[Epoch 77] ogbg-molclintox: 0.868815 val loss: 0.841359
[Epoch 77] ogbg-molclintox: 0.824311 test loss: 0.271223
[Epoch 78; Iter     5/   35] train: loss: 0.0468790
[Epoch 78; Iter    35/   35] train: loss: 0.2341912
[Epoch 78] ogbg-molclintox: 0.905420 val loss: 0.268966
[Epoch 78] ogbg-molclintox: 0.854067 test loss: 0.230302
[Epoch 79; Iter    30/   35] train: loss: 0.1034171
[Epoch 79] ogbg-molclintox: 0.884006 val loss: 0.723535
[Epoch 79] ogbg-molclintox: 0.819526 test loss: 0.231122
[Epoch 31] ogbg-molclintox: 0.616584 test loss: 0.245197
[Epoch 32; Iter    20/   40] train: loss: 0.1545664
[Epoch 32] ogbg-molclintox: 0.745282 val loss: 0.240885
[Epoch 32] ogbg-molclintox: 0.613320 test loss: 0.267092
[Epoch 33; Iter    10/   40] train: loss: 0.1687631
[Epoch 33; Iter    40/   40] train: loss: 0.0784280
[Epoch 33] ogbg-molclintox: 0.745482 val loss: 0.242371
[Epoch 33] ogbg-molclintox: 0.628413 test loss: 0.259485
[Epoch 34; Iter    30/   40] train: loss: 0.2326732
[Epoch 34] ogbg-molclintox: 0.721197 val loss: 0.250659
[Epoch 34] ogbg-molclintox: 0.577622 test loss: 0.264176
[Epoch 35; Iter    20/   40] train: loss: 0.0834696
[Epoch 35] ogbg-molclintox: 0.796184 val loss: 0.225496
[Epoch 35] ogbg-molclintox: 0.608482 test loss: 0.283515
[Epoch 36; Iter    10/   40] train: loss: 0.0989613
[Epoch 36; Iter    40/   40] train: loss: 0.1232435
[Epoch 36] ogbg-molclintox: 0.834749 val loss: 0.224063
[Epoch 36] ogbg-molclintox: 0.823757 test loss: 0.215615
[Epoch 37; Iter    30/   40] train: loss: 0.3035106
[Epoch 37] ogbg-molclintox: 0.907922 val loss: 0.163388
[Epoch 37] ogbg-molclintox: 0.715245 test loss: 0.241497
[Epoch 38; Iter    20/   40] train: loss: 0.1929902
[Epoch 38] ogbg-molclintox: 0.869674 val loss: 0.306260
[Epoch 38] ogbg-molclintox: 0.790933 test loss: 0.207070
[Epoch 39; Iter    10/   40] train: loss: 0.2579923
[Epoch 39; Iter    40/   40] train: loss: 0.6034256
[Epoch 39] ogbg-molclintox: 0.868996 val loss: 0.199143
[Epoch 39] ogbg-molclintox: 0.775496 test loss: 0.285850
[Epoch 40; Iter    30/   40] train: loss: 0.0997723
[Epoch 40] ogbg-molclintox: 0.878120 val loss: 0.186590
[Epoch 40] ogbg-molclintox: 0.830658 test loss: 0.203260
[Epoch 41; Iter    20/   40] train: loss: 0.1374815
[Epoch 41] ogbg-molclintox: 0.861204 val loss: 0.194822
[Epoch 41] ogbg-molclintox: 0.672368 test loss: 0.251467
[Epoch 42; Iter    10/   40] train: loss: 0.0446096
[Epoch 42; Iter    40/   40] train: loss: 0.0723276
[Epoch 42] ogbg-molclintox: 0.916263 val loss: 0.548227
[Epoch 42] ogbg-molclintox: 0.760890 test loss: 0.229534
[Epoch 43; Iter    30/   40] train: loss: 0.1576617
[Epoch 43] ogbg-molclintox: 0.940640 val loss: 0.185989
[Epoch 43] ogbg-molclintox: 0.852714 test loss: 0.202147
[Epoch 44; Iter    20/   40] train: loss: 0.0810419
[Epoch 44] ogbg-molclintox: 0.886154 val loss: 0.182892
[Epoch 44] ogbg-molclintox: 0.799988 test loss: 0.197810
[Epoch 45; Iter    10/   40] train: loss: 0.2624613
[Epoch 45; Iter    40/   40] train: loss: 0.1336999
[Epoch 45] ogbg-molclintox: 0.916474 val loss: 0.143754
[Epoch 45] ogbg-molclintox: 0.847396 test loss: 0.188150
[Epoch 46; Iter    30/   40] train: loss: 0.1855413
[Epoch 46] ogbg-molclintox: 0.883038 val loss: 0.200629
[Epoch 46] ogbg-molclintox: 0.817006 test loss: 0.223800
[Epoch 47; Iter    20/   40] train: loss: 0.0666195
[Epoch 47] ogbg-molclintox: 0.899731 val loss: 0.162149
[Epoch 47] ogbg-molclintox: 0.830327 test loss: 0.195379
[Epoch 48; Iter    10/   40] train: loss: 0.0464417
[Epoch 48; Iter    40/   40] train: loss: 0.1758678
[Epoch 48] ogbg-molclintox: 0.911599 val loss: 0.180740
[Epoch 48] ogbg-molclintox: 0.856897 test loss: 0.213530
[Epoch 49; Iter    30/   40] train: loss: 0.0844775
[Epoch 49] ogbg-molclintox: 0.911735 val loss: 0.167946
[Epoch 49] ogbg-molclintox: 0.742144 test loss: 0.280885
[Epoch 50; Iter    20/   40] train: loss: 0.1988435
[Epoch 50] ogbg-molclintox: 0.924535 val loss: 0.193853
[Epoch 50] ogbg-molclintox: 0.815619 test loss: 0.263340
[Epoch 51; Iter    10/   40] train: loss: 0.1118098
[Epoch 51; Iter    40/   40] train: loss: 0.0148791
[Epoch 51] ogbg-molclintox: 0.944397 val loss: 0.151233
[Epoch 51] ogbg-molclintox: 0.812916 test loss: 0.204451
[Epoch 52; Iter    30/   40] train: loss: 0.0708872
[Epoch 52] ogbg-molclintox: 0.902221 val loss: 0.216151
[Epoch 52] ogbg-molclintox: 0.813758 test loss: 0.305653
[Epoch 53; Iter    20/   40] train: loss: 0.1453127
[Epoch 53] ogbg-molclintox: 0.925413 val loss: 0.162648
[Epoch 53] ogbg-molclintox: 0.810913 test loss: 0.209915
[Epoch 54; Iter    10/   40] train: loss: 0.0700348
[Epoch 54; Iter    40/   40] train: loss: 0.0982791
[Epoch 54] ogbg-molclintox: 0.904460 val loss: 0.165489
[Epoch 54] ogbg-molclintox: 0.787905 test loss: 0.221332
[Epoch 55; Iter    30/   40] train: loss: 0.0378064
[Epoch 55] ogbg-molclintox: 0.896572 val loss: 0.202406
[Epoch 55] ogbg-molclintox: 0.774660 test loss: 0.280322
[Epoch 56; Iter    20/   40] train: loss: 0.0116227
[Epoch 56] ogbg-molclintox: 0.941614 val loss: 0.159569
[Epoch 56] ogbg-molclintox: 0.802262 test loss: 0.261268
[Epoch 57; Iter    10/   40] train: loss: 0.1030051
[Epoch 57; Iter    40/   40] train: loss: 0.0140167
[Epoch 57] ogbg-molclintox: 0.934273 val loss: 0.166145
[Epoch 57] ogbg-molclintox: 0.810720 test loss: 0.304290
[Epoch 58; Iter    30/   40] train: loss: 0.0203734
[Epoch 58] ogbg-molclintox: 0.894457 val loss: 0.191444
[Epoch 58] ogbg-molclintox: 0.781957 test loss: 0.295995
[Epoch 59; Iter    20/   40] train: loss: 0.0455213
[Epoch 59] ogbg-molclintox: 0.941827 val loss: 0.164073
[Epoch 59] ogbg-molclintox: 0.773197 test loss: 0.265573
[Epoch 60; Iter    10/   40] train: loss: 0.0583184
[Epoch 60; Iter    40/   40] train: loss: 0.1480211
[Epoch 60] ogbg-molclintox: 0.886025 val loss: 0.177944
[Epoch 60] ogbg-molclintox: 0.778337 test loss: 0.272653
[Epoch 61; Iter    30/   40] train: loss: 0.1207265
[Epoch 61] ogbg-molclintox: 0.936684 val loss: 0.165379
[Epoch 61] ogbg-molclintox: 0.751739 test loss: 0.315965
[Epoch 62; Iter    20/   40] train: loss: 0.1499813
[Epoch 62] ogbg-molclintox: 0.938830 val loss: 0.173691
[Epoch 62] ogbg-molclintox: 0.805031 test loss: 0.270592
[Epoch 63; Iter    10/   40] train: loss: 0.1098732
[Epoch 63; Iter    40/   40] train: loss: 0.0806051
[Epoch 63] ogbg-molclintox: 0.900238 val loss: 0.197493
[Epoch 63] ogbg-molclintox: 0.771394 test loss: 0.283328
[Epoch 64; Iter    30/   40] train: loss: 0.0195002
[Epoch 64] ogbg-molclintox: 0.884531 val loss: 0.194434
[Epoch 64] ogbg-molclintox: 0.808754 test loss: 0.282626
[Epoch 65; Iter    20/   40] train: loss: 0.0406195
[Epoch 65] ogbg-molclintox: 0.913956 val loss: 0.181174
[Epoch 65] ogbg-molclintox: 0.789404 test loss: 0.253716
[Epoch 66; Iter    10/   40] train: loss: 0.0588876
[Epoch 66; Iter    40/   40] train: loss: 0.1748221
[Epoch 66] ogbg-molclintox: 0.905591 val loss: 0.198649
[Epoch 66] ogbg-molclintox: 0.800730 test loss: 0.268132
[Epoch 67; Iter    30/   40] train: loss: 0.0676624
[Epoch 67] ogbg-molclintox: 0.919193 val loss: 0.198009
[Epoch 67] ogbg-molclintox: 0.834181 test loss: 0.234795
[Epoch 68; Iter    20/   40] train: loss: 0.0434973
[Epoch 68] ogbg-molclintox: 0.905275 val loss: 0.177034
[Epoch 68] ogbg-molclintox: 0.708642 test loss: 0.309861
[Epoch 69; Iter    10/   40] train: loss: 0.0724561
[Epoch 69; Iter    40/   40] train: loss: 0.0927925
[Epoch 69] ogbg-molclintox: 0.910787 val loss: 0.168652
[Epoch 69] ogbg-molclintox: 0.813489 test loss: 0.227401
[Epoch 70; Iter    30/   40] train: loss: 0.0573987
[Epoch 70] ogbg-molclintox: 0.899785 val loss: 0.202657
[Epoch 70] ogbg-molclintox: 0.774856 test loss: 0.275946
[Epoch 71; Iter    20/   40] train: loss: 0.0201422
[Epoch 71] ogbg-molclintox: 0.909760 val loss: 0.208499
[Epoch 71] ogbg-molclintox: 0.826297 test loss: 0.246671
[Epoch 72; Iter    10/   40] train: loss: 0.0101521
[Epoch 72; Iter    40/   40] train: loss: 0.0337601
[Epoch 72] ogbg-molclintox: 0.915009 val loss: 0.182386
[Epoch 72] ogbg-molclintox: 0.853576 test loss: 0.251949
[Epoch 73; Iter    30/   40] train: loss: 0.0539372
[Epoch 73] ogbg-molclintox: 0.931382 val loss: 0.164600
[Epoch 73] ogbg-molclintox: 0.745031 test loss: 0.284074
[Epoch 74; Iter    20/   40] train: loss: 0.0108607
[Epoch 74] ogbg-molclintox: 0.920740 val loss: 0.190177
[Epoch 74] ogbg-molclintox: 0.700106 test loss: 0.316214
[Epoch 75; Iter    10/   40] train: loss: 0.0434302
[Epoch 75; Iter    40/   40] train: loss: 0.1002951
[Epoch 75] ogbg-molclintox: 0.922791 val loss: 0.183512
[Epoch 75] ogbg-molclintox: 0.717981 test loss: 0.309086
[Epoch 76; Iter    30/   40] train: loss: 0.0210157
[Epoch 33; Iter    20/   35] train: loss: 0.1584867
[Epoch 33] ogbg-molclintox: 0.692429 val loss: 0.257253
[Epoch 33] ogbg-molclintox: 0.690345 test loss: 0.256994
[Epoch 34; Iter    15/   35] train: loss: 0.2754562
[Epoch 34] ogbg-molclintox: 0.676935 val loss: 0.268312
[Epoch 34] ogbg-molclintox: 0.660090 test loss: 0.266459
[Epoch 35; Iter    10/   35] train: loss: 0.2335734
[Epoch 35] ogbg-molclintox: 0.769398 val loss: 0.242077
[Epoch 35] ogbg-molclintox: 0.719059 test loss: 0.238407
[Epoch 36; Iter     5/   35] train: loss: 0.2001215
[Epoch 36; Iter    35/   35] train: loss: 0.4850268
[Epoch 36] ogbg-molclintox: 0.685748 val loss: 0.273493
[Epoch 36] ogbg-molclintox: 0.721131 test loss: 0.248376
[Epoch 37; Iter    30/   35] train: loss: 0.1470302
[Epoch 37] ogbg-molclintox: 0.685061 val loss: 0.313577
[Epoch 37] ogbg-molclintox: 0.739018 test loss: 0.219693
[Epoch 38; Iter    25/   35] train: loss: 0.2320993
[Epoch 38] ogbg-molclintox: 0.696788 val loss: 0.308467
[Epoch 38] ogbg-molclintox: 0.674950 test loss: 0.236217
[Epoch 39; Iter    20/   35] train: loss: 0.2353986
[Epoch 39] ogbg-molclintox: 0.758934 val loss: 0.229294
[Epoch 39] ogbg-molclintox: 0.655577 test loss: 0.246683
[Epoch 40; Iter    15/   35] train: loss: 0.0955921
[Epoch 40] ogbg-molclintox: 0.747959 val loss: 0.214129
[Epoch 40] ogbg-molclintox: 0.756809 test loss: 0.229770
[Epoch 41; Iter    10/   35] train: loss: 0.2377347
[Epoch 41] ogbg-molclintox: 0.795904 val loss: 0.171720
[Epoch 41] ogbg-molclintox: 0.660104 test loss: 0.264211
[Epoch 42; Iter     5/   35] train: loss: 0.1285887
[Epoch 42; Iter    35/   35] train: loss: 0.1519675
[Epoch 42] ogbg-molclintox: 0.928744 val loss: 0.232692
[Epoch 42] ogbg-molclintox: 0.778897 test loss: 0.211555
[Epoch 43; Iter    30/   35] train: loss: 0.2034965
[Epoch 43] ogbg-molclintox: 0.818119 val loss: 3.273496
[Epoch 43] ogbg-molclintox: 0.786504 test loss: 0.539252
[Epoch 44; Iter    25/   35] train: loss: 0.1187732
[Epoch 44] ogbg-molclintox: 0.908127 val loss: 0.284706
[Epoch 44] ogbg-molclintox: 0.773273 test loss: 0.236526
[Epoch 45; Iter    20/   35] train: loss: 0.1672288
[Epoch 45] ogbg-molclintox: 0.909013 val loss: 0.297059
[Epoch 45] ogbg-molclintox: 0.828149 test loss: 0.207326
[Epoch 46; Iter    15/   35] train: loss: 0.1192446
[Epoch 46] ogbg-molclintox: 0.828412 val loss: 0.503988
[Epoch 46] ogbg-molclintox: 0.821302 test loss: 0.214587
[Epoch 47; Iter    10/   35] train: loss: 0.1794890
[Epoch 47] ogbg-molclintox: 0.842310 val loss: 0.264808
[Epoch 47] ogbg-molclintox: 0.804966 test loss: 0.208235
[Epoch 48; Iter     5/   35] train: loss: 0.2479385
[Epoch 48; Iter    35/   35] train: loss: 0.0814037
[Epoch 48] ogbg-molclintox: 0.882967 val loss: 0.269754
[Epoch 48] ogbg-molclintox: 0.841337 test loss: 0.194122
[Epoch 49; Iter    30/   35] train: loss: 0.0534295
[Epoch 49] ogbg-molclintox: 0.918074 val loss: 0.314894
[Epoch 49] ogbg-molclintox: 0.846944 test loss: 0.177594
[Epoch 50; Iter    25/   35] train: loss: 0.0845017
[Epoch 50] ogbg-molclintox: 0.880560 val loss: 0.363481
[Epoch 50] ogbg-molclintox: 0.778209 test loss: 0.213429
[Epoch 51; Iter    20/   35] train: loss: 0.1630400
[Epoch 51] ogbg-molclintox: 0.822966 val loss: 0.269491
[Epoch 51] ogbg-molclintox: 0.805913 test loss: 0.211374
[Epoch 52; Iter    15/   35] train: loss: 0.0905546
[Epoch 52] ogbg-molclintox: 0.895258 val loss: 0.671921
[Epoch 52] ogbg-molclintox: 0.782015 test loss: 0.224129
[Epoch 53; Iter    10/   35] train: loss: 0.0589651
[Epoch 53] ogbg-molclintox: 0.874972 val loss: 0.256735
[Epoch 53] ogbg-molclintox: 0.797762 test loss: 0.246431
[Epoch 54; Iter     5/   35] train: loss: 0.0262909
[Epoch 54; Iter    35/   35] train: loss: 0.1321693
[Epoch 54] ogbg-molclintox: 0.927315 val loss: 0.160246
[Epoch 54] ogbg-molclintox: 0.805811 test loss: 0.209335
[Epoch 55; Iter    30/   35] train: loss: 0.1564021
[Epoch 55] ogbg-molclintox: 0.908311 val loss: 0.156280
[Epoch 55] ogbg-molclintox: 0.831582 test loss: 0.375699
[Epoch 56; Iter    25/   35] train: loss: 0.0376761
[Epoch 56] ogbg-molclintox: 0.827980 val loss: 0.290868
[Epoch 56] ogbg-molclintox: 0.719192 test loss: 0.321762
[Epoch 57; Iter    20/   35] train: loss: 0.0304081
[Epoch 57] ogbg-molclintox: 0.920503 val loss: 0.142737
[Epoch 57] ogbg-molclintox: 0.783351 test loss: 0.257844
[Epoch 58; Iter    15/   35] train: loss: 0.0247299
[Epoch 58] ogbg-molclintox: 0.873817 val loss: 0.826958
[Epoch 58] ogbg-molclintox: 0.811199 test loss: 0.228408
[Epoch 59; Iter    10/   35] train: loss: 0.0480171
[Epoch 59] ogbg-molclintox: 0.912626 val loss: 0.213310
[Epoch 59] ogbg-molclintox: 0.794529 test loss: 0.259175
[Epoch 60; Iter     5/   35] train: loss: 0.0661529
[Epoch 60; Iter    35/   35] train: loss: 0.0356147
[Epoch 60] ogbg-molclintox: 0.894984 val loss: 0.299018
[Epoch 60] ogbg-molclintox: 0.764464 test loss: 0.274824
[Epoch 61; Iter    30/   35] train: loss: 0.0667222
[Epoch 61] ogbg-molclintox: 0.918299 val loss: 0.225387
[Epoch 61] ogbg-molclintox: 0.813669 test loss: 0.261042
[Epoch 62; Iter    25/   35] train: loss: 0.1353524
[Epoch 62] ogbg-molclintox: 0.872150 val loss: 0.205056
[Epoch 62] ogbg-molclintox: 0.756333 test loss: 0.317017
[Epoch 63; Iter    20/   35] train: loss: 0.1397670
[Epoch 63] ogbg-molclintox: 0.916291 val loss: 0.301869
[Epoch 63] ogbg-molclintox: 0.766099 test loss: 0.259713
[Epoch 64; Iter    15/   35] train: loss: 0.0779172
[Epoch 64] ogbg-molclintox: 0.912935 val loss: 0.163471
[Epoch 64] ogbg-molclintox: 0.785743 test loss: 0.283424
[Epoch 65; Iter    10/   35] train: loss: 0.0409720
[Epoch 65] ogbg-molclintox: 0.912079 val loss: 0.154561
[Epoch 65] ogbg-molclintox: 0.829687 test loss: 0.234280
[Epoch 66; Iter     5/   35] train: loss: 0.0319640
[Epoch 66; Iter    35/   35] train: loss: 0.0315478
[Epoch 66] ogbg-molclintox: 0.923260 val loss: 0.193708
[Epoch 66] ogbg-molclintox: 0.839459 test loss: 0.258656
[Epoch 67; Iter    30/   35] train: loss: 0.0126431
[Epoch 67] ogbg-molclintox: 0.862788 val loss: 0.221010
[Epoch 67] ogbg-molclintox: 0.764831 test loss: 0.296691
[Epoch 68; Iter    25/   35] train: loss: 0.0373926
[Epoch 68] ogbg-molclintox: 0.920812 val loss: 0.326336
[Epoch 68] ogbg-molclintox: 0.745547 test loss: 0.296993
[Epoch 69; Iter    20/   35] train: loss: 0.0482570
[Epoch 69] ogbg-molclintox: 0.909594 val loss: 0.203884
[Epoch 69] ogbg-molclintox: 0.809083 test loss: 0.262953
[Epoch 70; Iter    15/   35] train: loss: 0.0189991
[Epoch 70] ogbg-molclintox: 0.886327 val loss: 0.200569
[Epoch 70] ogbg-molclintox: 0.759936 test loss: 0.281232
[Epoch 71; Iter    10/   35] train: loss: 0.0261775
[Epoch 71] ogbg-molclintox: 0.898309 val loss: 0.163958
[Epoch 71] ogbg-molclintox: 0.766006 test loss: 0.302269
[Epoch 72; Iter     5/   35] train: loss: 0.0093825
[Epoch 72; Iter    35/   35] train: loss: 0.0310801
[Epoch 72] ogbg-molclintox: 0.934885 val loss: 0.147530
[Epoch 72] ogbg-molclintox: 0.776961 test loss: 0.319058
[Epoch 73; Iter    30/   35] train: loss: 0.0112616
[Epoch 73] ogbg-molclintox: 0.852625 val loss: 0.222041
[Epoch 73] ogbg-molclintox: 0.793205 test loss: 0.321910
[Epoch 74; Iter    25/   35] train: loss: 0.0981308
[Epoch 74] ogbg-molclintox: 0.900026 val loss: 0.188849
[Epoch 74] ogbg-molclintox: 0.775162 test loss: 0.287254
[Epoch 75; Iter    20/   35] train: loss: 0.0535728
[Epoch 75] ogbg-molclintox: 0.889074 val loss: 0.190260
[Epoch 75] ogbg-molclintox: 0.829376 test loss: 0.301423
[Epoch 76; Iter    15/   35] train: loss: 0.1723312
[Epoch 76] ogbg-molclintox: 0.898740 val loss: 0.165907
[Epoch 76] ogbg-molclintox: 0.782616 test loss: 0.293273
[Epoch 77; Iter    10/   35] train: loss: 0.0867733
[Epoch 77] ogbg-molclintox: 0.888209 val loss: 0.182419
[Epoch 77] ogbg-molclintox: 0.719386 test loss: 0.308681
[Epoch 78; Iter     5/   35] train: loss: 0.1039147
[Epoch 78; Iter    35/   35] train: loss: 0.0149514
[Epoch 78] ogbg-molclintox: 0.867102 val loss: 0.189850
[Epoch 78] ogbg-molclintox: 0.780613 test loss: 0.291789
[Epoch 79; Iter    30/   35] train: loss: 0.0659938
[Epoch 79] ogbg-molclintox: 0.863084 val loss: 0.181861
[Epoch 79] ogbg-molclintox: 0.762473 test loss: 0.317733
[Epoch 31] ogbg-molclintox: 0.645046 test loss: 0.253684
[Epoch 32; Iter    20/   40] train: loss: 0.1254311
[Epoch 32] ogbg-molclintox: 0.727112 val loss: 0.244247
[Epoch 32] ogbg-molclintox: 0.675016 test loss: 0.239235
[Epoch 33; Iter    10/   40] train: loss: 0.2045143
[Epoch 33; Iter    40/   40] train: loss: 0.1749703
[Epoch 33] ogbg-molclintox: 0.734822 val loss: 0.226919
[Epoch 33] ogbg-molclintox: 0.657695 test loss: 0.232371
[Epoch 34; Iter    30/   40] train: loss: 0.1837237
[Epoch 34] ogbg-molclintox: 0.758416 val loss: 0.243434
[Epoch 34] ogbg-molclintox: 0.661159 test loss: 0.242593
[Epoch 35; Iter    20/   40] train: loss: 0.2209332
[Epoch 35] ogbg-molclintox: 0.734126 val loss: 0.266278
[Epoch 35] ogbg-molclintox: 0.550218 test loss: 0.298243
[Epoch 36; Iter    10/   40] train: loss: 0.1192236
[Epoch 36; Iter    40/   40] train: loss: 0.1726652
[Epoch 36] ogbg-molclintox: 0.778958 val loss: 0.249221
[Epoch 36] ogbg-molclintox: 0.737559 test loss: 0.252418
[Epoch 37; Iter    30/   40] train: loss: 0.3209021
[Epoch 37] ogbg-molclintox: 0.855516 val loss: 0.204632
[Epoch 37] ogbg-molclintox: 0.808576 test loss: 0.197681
[Epoch 38; Iter    20/   40] train: loss: 0.1623909
[Epoch 38] ogbg-molclintox: 0.761940 val loss: 6.541470
[Epoch 38] ogbg-molclintox: 0.802492 test loss: 4.972364
[Epoch 39; Iter    10/   40] train: loss: 0.0636872
[Epoch 39; Iter    40/   40] train: loss: 0.0578643
[Epoch 39] ogbg-molclintox: 0.878693 val loss: 0.262165
[Epoch 39] ogbg-molclintox: 0.840705 test loss: 0.306185
[Epoch 40; Iter    30/   40] train: loss: 0.1895440
[Epoch 40] ogbg-molclintox: 0.860501 val loss: 0.192611
[Epoch 40] ogbg-molclintox: 0.593310 test loss: 0.272675
[Epoch 41; Iter    20/   40] train: loss: 0.2079817
[Epoch 41] ogbg-molclintox: 0.897519 val loss: 0.178232
[Epoch 41] ogbg-molclintox: 0.834495 test loss: 0.200851
[Epoch 42; Iter    10/   40] train: loss: 0.2077098
[Epoch 42; Iter    40/   40] train: loss: 0.1014510
[Epoch 42] ogbg-molclintox: 0.897667 val loss: 0.171667
[Epoch 42] ogbg-molclintox: 0.830450 test loss: 0.198170
[Epoch 43; Iter    30/   40] train: loss: 0.2075745
[Epoch 43] ogbg-molclintox: 0.906126 val loss: 0.185878
[Epoch 43] ogbg-molclintox: 0.808156 test loss: 0.217676
[Epoch 44; Iter    20/   40] train: loss: 0.0352485
[Epoch 44] ogbg-molclintox: 0.939229 val loss: 0.146927
[Epoch 44] ogbg-molclintox: 0.784759 test loss: 0.228334
[Epoch 45; Iter    10/   40] train: loss: 0.0703785
[Epoch 45; Iter    40/   40] train: loss: 0.3632882
[Epoch 45] ogbg-molclintox: 0.847214 val loss: 0.220535
[Epoch 45] ogbg-molclintox: 0.789099 test loss: 0.214641
[Epoch 46; Iter    30/   40] train: loss: 0.1027626
[Epoch 46] ogbg-molclintox: 0.885409 val loss: 0.220774
[Epoch 46] ogbg-molclintox: 0.789262 test loss: 0.232648
[Epoch 47; Iter    20/   40] train: loss: 0.1931848
[Epoch 47] ogbg-molclintox: 0.839187 val loss: 0.235257
[Epoch 47] ogbg-molclintox: 0.599050 test loss: 0.293165
[Epoch 48; Iter    10/   40] train: loss: 0.0596253
[Epoch 48; Iter    40/   40] train: loss: 0.0192681
[Epoch 48] ogbg-molclintox: 0.925667 val loss: 0.167686
[Epoch 48] ogbg-molclintox: 0.858037 test loss: 0.209100
[Epoch 49; Iter    30/   40] train: loss: 0.0253956
[Epoch 49] ogbg-molclintox: 0.934872 val loss: 0.153063
[Epoch 49] ogbg-molclintox: 0.798703 test loss: 0.211344
[Epoch 50; Iter    20/   40] train: loss: 0.1418388
[Epoch 50] ogbg-molclintox: 0.951951 val loss: 0.151075
[Epoch 50] ogbg-molclintox: 0.776711 test loss: 0.289683
[Epoch 51; Iter    10/   40] train: loss: 0.0767197
[Epoch 51; Iter    40/   40] train: loss: 0.0651168
[Epoch 51] ogbg-molclintox: 0.887541 val loss: 0.183874
[Epoch 51] ogbg-molclintox: 0.809764 test loss: 0.230688
[Epoch 52; Iter    30/   40] train: loss: 0.0219637
[Epoch 52] ogbg-molclintox: 0.947316 val loss: 0.114116
[Epoch 52] ogbg-molclintox: 0.708859 test loss: 0.248899
[Epoch 53; Iter    20/   40] train: loss: 0.0937501
[Epoch 53] ogbg-molclintox: 0.934486 val loss: 0.158623
[Epoch 53] ogbg-molclintox: 0.809664 test loss: 0.236175
[Epoch 54; Iter    10/   40] train: loss: 0.1214519
[Epoch 54; Iter    40/   40] train: loss: 0.2000916
[Epoch 54] ogbg-molclintox: 0.823715 val loss: 0.228855
[Epoch 54] ogbg-molclintox: 0.788388 test loss: 0.236199
[Epoch 55; Iter    30/   40] train: loss: 0.0933087
[Epoch 55] ogbg-molclintox: 0.925561 val loss: 0.143590
[Epoch 55] ogbg-molclintox: 0.846940 test loss: 0.222180
[Epoch 56; Iter    20/   40] train: loss: 0.0281945
[Epoch 56] ogbg-molclintox: 0.956920 val loss: 0.119734
[Epoch 56] ogbg-molclintox: 0.785678 test loss: 0.234082
[Epoch 57; Iter    10/   40] train: loss: 0.0627553
[Epoch 57; Iter    40/   40] train: loss: 0.0577043
[Epoch 57] ogbg-molclintox: 0.916981 val loss: 0.176117
[Epoch 57] ogbg-molclintox: 0.840346 test loss: 0.222699
[Epoch 58; Iter    30/   40] train: loss: 0.0166136
[Epoch 58] ogbg-molclintox: 0.941066 val loss: 0.136807
[Epoch 58] ogbg-molclintox: 0.860912 test loss: 0.190276
[Epoch 59; Iter    20/   40] train: loss: 0.0340569
[Epoch 59] ogbg-molclintox: 0.910973 val loss: 0.175604
[Epoch 59] ogbg-molclintox: 0.842500 test loss: 0.210064
[Epoch 60; Iter    10/   40] train: loss: 0.0819261
[Epoch 60; Iter    40/   40] train: loss: 0.0472324
[Epoch 60] ogbg-molclintox: 0.891456 val loss: 0.150693
[Epoch 60] ogbg-molclintox: 0.857467 test loss: 0.208115
[Epoch 61; Iter    30/   40] train: loss: 0.0934083
[Epoch 61] ogbg-molclintox: 0.910561 val loss: 0.175964
[Epoch 61] ogbg-molclintox: 0.828444 test loss: 0.240989
[Epoch 62; Iter    20/   40] train: loss: 0.1041678
[Epoch 62] ogbg-molclintox: 0.873125 val loss: 0.209811
[Epoch 62] ogbg-molclintox: 0.847610 test loss: 0.317524
[Epoch 63; Iter    10/   40] train: loss: 0.0754840
[Epoch 63; Iter    40/   40] train: loss: 0.0061492
[Epoch 63] ogbg-molclintox: 0.924508 val loss: 0.177038
[Epoch 63] ogbg-molclintox: 0.837999 test loss: 0.224673
[Epoch 64; Iter    30/   40] train: loss: 0.1080638
[Epoch 64] ogbg-molclintox: 0.906005 val loss: 0.167771
[Epoch 64] ogbg-molclintox: 0.899979 test loss: 0.182916
[Epoch 65; Iter    20/   40] train: loss: 0.2292163
[Epoch 65] ogbg-molclintox: 0.885290 val loss: 0.190751
[Epoch 65] ogbg-molclintox: 0.827690 test loss: 0.223650
[Epoch 66; Iter    10/   40] train: loss: 0.0257002
[Epoch 66; Iter    40/   40] train: loss: 0.0204580
[Epoch 66] ogbg-molclintox: 0.905964 val loss: 0.158859
[Epoch 66] ogbg-molclintox: 0.842880 test loss: 0.229794
[Epoch 67; Iter    30/   40] train: loss: 0.0200208
[Epoch 67] ogbg-molclintox: 0.875791 val loss: 0.182327
[Epoch 67] ogbg-molclintox: 0.881875 test loss: 0.210605
[Epoch 68; Iter    20/   40] train: loss: 0.0162505
[Epoch 68] ogbg-molclintox: 0.891403 val loss: 0.177810
[Epoch 68] ogbg-molclintox: 0.894399 test loss: 0.171856
[Epoch 69; Iter    10/   40] train: loss: 0.0422991
[Epoch 69; Iter    40/   40] train: loss: 0.0295034
[Epoch 69] ogbg-molclintox: 0.935752 val loss: 0.159634
[Epoch 69] ogbg-molclintox: 0.860212 test loss: 0.246306
[Epoch 70; Iter    30/   40] train: loss: 0.1778547
[Epoch 70] ogbg-molclintox: 0.917434 val loss: 0.155501
[Epoch 70] ogbg-molclintox: 0.847462 test loss: 0.222050
[Epoch 71; Iter    20/   40] train: loss: 0.1618051
[Epoch 71] ogbg-molclintox: 0.926348 val loss: 0.151014
[Epoch 71] ogbg-molclintox: 0.805275 test loss: 0.254797
[Epoch 72; Iter    10/   40] train: loss: 0.2440675
[Epoch 72; Iter    40/   40] train: loss: 0.0114719
[Epoch 72] ogbg-molclintox: 0.939589 val loss: 0.157517
[Epoch 72] ogbg-molclintox: 0.892335 test loss: 0.208641
[Epoch 73; Iter    30/   40] train: loss: 0.0563694
[Epoch 73] ogbg-molclintox: 0.907311 val loss: 0.184681
[Epoch 73] ogbg-molclintox: 0.825385 test loss: 0.254249
[Epoch 74; Iter    20/   40] train: loss: 0.0862102
[Epoch 74] ogbg-molclintox: 0.867920 val loss: 0.182997
[Epoch 74] ogbg-molclintox: 0.736000 test loss: 0.291844
[Epoch 75; Iter    10/   40] train: loss: 0.0157932
[Epoch 75; Iter    40/   40] train: loss: 0.0212830
[Epoch 75] ogbg-molclintox: 0.885787 val loss: 0.205700
[Epoch 75] ogbg-molclintox: 0.805385 test loss: 0.288106
[Epoch 76; Iter    30/   40] train: loss: 0.1102661
[Epoch 34] ogbg-molclintox: 0.643563 test loss: 0.256416
[Epoch 35; Iter    30/   30] train: loss: 0.1651665
[Epoch 35] ogbg-molclintox: 0.740128 val loss: 0.237221
[Epoch 35] ogbg-molclintox: 0.622342 test loss: 0.277513
[Epoch 36; Iter    30/   30] train: loss: 0.1138252
[Epoch 36] ogbg-molclintox: 0.716723 val loss: 0.202218
[Epoch 36] ogbg-molclintox: 0.587255 test loss: 0.260968
[Epoch 37; Iter    30/   30] train: loss: 0.4586663
[Epoch 37] ogbg-molclintox: 0.774619 val loss: 0.188810
[Epoch 37] ogbg-molclintox: 0.652265 test loss: 0.250513
[Epoch 38; Iter    30/   30] train: loss: 0.1095007
[Epoch 38] ogbg-molclintox: 0.767637 val loss: 0.223645
[Epoch 38] ogbg-molclintox: 0.645420 test loss: 0.262425
[Epoch 39; Iter    30/   30] train: loss: 0.4563256
[Epoch 39] ogbg-molclintox: 0.738142 val loss: 0.217721
[Epoch 39] ogbg-molclintox: 0.625728 test loss: 0.265716
[Epoch 40; Iter    30/   30] train: loss: 0.3541728
[Epoch 40] ogbg-molclintox: 0.748098 val loss: 0.241167
[Epoch 40] ogbg-molclintox: 0.689569 test loss: 0.268079
[Epoch 41; Iter    30/   30] train: loss: 0.0638697
[Epoch 41] ogbg-molclintox: 0.859885 val loss: 0.188029
[Epoch 41] ogbg-molclintox: 0.675617 test loss: 0.244521
[Epoch 42; Iter    30/   30] train: loss: 0.3049655
[Epoch 42] ogbg-molclintox: 0.690841 val loss: 0.265442
[Epoch 42] ogbg-molclintox: 0.640229 test loss: 0.282790
[Epoch 43; Iter    30/   30] train: loss: 0.2318169
[Epoch 43] ogbg-molclintox: 0.736569 val loss: 0.209014
[Epoch 43] ogbg-molclintox: 0.666600 test loss: 0.267801
[Epoch 44; Iter    30/   30] train: loss: 0.1596775
[Epoch 44] ogbg-molclintox: 0.764649 val loss: 0.214317
[Epoch 44] ogbg-molclintox: 0.636272 test loss: 0.254163
[Epoch 45; Iter    30/   30] train: loss: 0.0864544
[Epoch 45] ogbg-molclintox: 0.792283 val loss: 0.222303
[Epoch 45] ogbg-molclintox: 0.597576 test loss: 0.272928
[Epoch 46; Iter    30/   30] train: loss: 0.1085007
[Epoch 46] ogbg-molclintox: 0.801228 val loss: 0.326055
[Epoch 46] ogbg-molclintox: 0.699375 test loss: 0.259618
[Epoch 47; Iter    30/   30] train: loss: 0.1432258
[Epoch 47] ogbg-molclintox: 0.765499 val loss: 0.435029
[Epoch 47] ogbg-molclintox: 0.658291 test loss: 0.295595
[Epoch 48; Iter    30/   30] train: loss: 0.0713260
[Epoch 48] ogbg-molclintox: 0.802216 val loss: 0.612661
[Epoch 48] ogbg-molclintox: 0.806432 test loss: 0.233827
[Epoch 49; Iter    30/   30] train: loss: 0.1905023
[Epoch 49] ogbg-molclintox: 0.828154 val loss: 0.845714
[Epoch 49] ogbg-molclintox: 0.552742 test loss: 1.341784
[Epoch 50; Iter    30/   30] train: loss: 0.1577512
[Epoch 50] ogbg-molclintox: 0.848682 val loss: 1.873156
[Epoch 50] ogbg-molclintox: 0.798991 test loss: 0.257589
[Epoch 51; Iter    30/   30] train: loss: 0.1918400
[Epoch 51] ogbg-molclintox: 0.833392 val loss: 0.301430
[Epoch 51] ogbg-molclintox: 0.788871 test loss: 0.322558
[Epoch 52; Iter    30/   30] train: loss: 0.1818237
[Epoch 52] ogbg-molclintox: 0.841161 val loss: 0.203984
[Epoch 52] ogbg-molclintox: 0.852789 test loss: 0.183581
[Epoch 53; Iter    30/   30] train: loss: 0.0953138
[Epoch 53] ogbg-molclintox: 0.796599 val loss: 0.366238
[Epoch 53] ogbg-molclintox: 0.834438 test loss: 0.258743
[Epoch 54; Iter    30/   30] train: loss: 0.0801164
[Epoch 54] ogbg-molclintox: 0.864234 val loss: 0.177543
[Epoch 54] ogbg-molclintox: 0.833970 test loss: 0.207521
[Epoch 55; Iter    30/   30] train: loss: 0.2074699
[Epoch 55] ogbg-molclintox: 0.788704 val loss: 0.240822
[Epoch 55] ogbg-molclintox: 0.801576 test loss: 0.210657
[Epoch 56; Iter    30/   30] train: loss: 0.1972190
[Epoch 56] ogbg-molclintox: 0.787973 val loss: 0.959460
[Epoch 56] ogbg-molclintox: 0.813790 test loss: 0.302572
[Epoch 57; Iter    30/   30] train: loss: 0.1112285
[Epoch 57] ogbg-molclintox: 0.819883 val loss: 0.320140
[Epoch 57] ogbg-molclintox: 0.862129 test loss: 0.187479
[Epoch 58; Iter    30/   30] train: loss: 0.2253461
[Epoch 58] ogbg-molclintox: 0.803616 val loss: 0.195256
[Epoch 58] ogbg-molclintox: 0.859712 test loss: 0.178053
[Epoch 59; Iter    30/   30] train: loss: 0.0720112
[Epoch 59] ogbg-molclintox: 0.881832 val loss: 0.153138
[Epoch 59] ogbg-molclintox: 0.865079 test loss: 0.185166
[Epoch 60; Iter    30/   30] train: loss: 0.2187423
[Epoch 60] ogbg-molclintox: 0.846826 val loss: 0.200880
[Epoch 60] ogbg-molclintox: 0.849065 test loss: 0.232376
[Epoch 61; Iter    30/   30] train: loss: 0.0155955
[Epoch 61] ogbg-molclintox: 0.881516 val loss: 0.132913
[Epoch 61] ogbg-molclintox: 0.859763 test loss: 0.201076
[Epoch 62; Iter    30/   30] train: loss: 0.1110908
[Epoch 62] ogbg-molclintox: 0.792699 val loss: 1.303139
[Epoch 62] ogbg-molclintox: 0.849447 test loss: 0.230306
[Epoch 63; Iter    30/   30] train: loss: 0.0935684
[Epoch 63] ogbg-molclintox: 0.810793 val loss: 1.267671
[Epoch 63] ogbg-molclintox: 0.840900 test loss: 0.285204
[Epoch 64; Iter    30/   30] train: loss: 0.0762599
[Epoch 64] ogbg-molclintox: 0.867989 val loss: 1.110472
[Epoch 64] ogbg-molclintox: 0.779964 test loss: 0.376866
[Epoch 65; Iter    30/   30] train: loss: 0.1453241
[Epoch 65] ogbg-molclintox: 0.845858 val loss: 0.182931
[Epoch 65] ogbg-molclintox: 0.892893 test loss: 0.181381
[Epoch 66; Iter    30/   30] train: loss: 0.0174849
[Epoch 66] ogbg-molclintox: 0.880371 val loss: 0.625174
[Epoch 66] ogbg-molclintox: 0.824158 test loss: 0.277880
[Epoch 67; Iter    30/   30] train: loss: 0.0849632
[Epoch 67] ogbg-molclintox: 0.879489 val loss: 0.544896
[Epoch 67] ogbg-molclintox: 0.824737 test loss: 0.221548
[Epoch 68; Iter    30/   30] train: loss: 0.1089266
[Epoch 68] ogbg-molclintox: 0.873899 val loss: 0.479569
[Epoch 68] ogbg-molclintox: 0.857231 test loss: 0.236699
[Epoch 69; Iter    30/   30] train: loss: 0.0993957
[Epoch 69] ogbg-molclintox: 0.889995 val loss: 0.386523
[Epoch 69] ogbg-molclintox: 0.859276 test loss: 0.246876
[Epoch 70; Iter    30/   30] train: loss: 0.0634087
[Epoch 70] ogbg-molclintox: 0.874922 val loss: 1.241005
[Epoch 70] ogbg-molclintox: 0.803862 test loss: 0.252021
[Epoch 71; Iter    30/   30] train: loss: 0.0956532
[Epoch 71] ogbg-molclintox: 0.868538 val loss: 2.736758
[Epoch 71] ogbg-molclintox: 0.812999 test loss: 0.257294
[Epoch 72; Iter    30/   30] train: loss: 0.0203390
[Epoch 72] ogbg-molclintox: 0.801782 val loss: 1.905071
[Epoch 72] ogbg-molclintox: 0.775827 test loss: 0.252703
[Epoch 73; Iter    30/   30] train: loss: 0.1388748
[Epoch 73] ogbg-molclintox: 0.850358 val loss: 2.226504
[Epoch 73] ogbg-molclintox: 0.801296 test loss: 0.257216
[Epoch 74; Iter    30/   30] train: loss: 0.0101529
[Epoch 74] ogbg-molclintox: 0.814246 val loss: 1.578008
[Epoch 74] ogbg-molclintox: 0.815093 test loss: 0.291641
[Epoch 75; Iter    30/   30] train: loss: 0.0078751
[Epoch 75] ogbg-molclintox: 0.871079 val loss: 0.412547
[Epoch 75] ogbg-molclintox: 0.859523 test loss: 0.274170
[Epoch 76; Iter    30/   30] train: loss: 0.0114631
[Epoch 76] ogbg-molclintox: 0.837850 val loss: 1.452783
[Epoch 76] ogbg-molclintox: 0.789638 test loss: 0.290278
[Epoch 77; Iter    30/   30] train: loss: 0.1944773
[Epoch 77] ogbg-molclintox: 0.857200 val loss: 2.213550
[Epoch 77] ogbg-molclintox: 0.834570 test loss: 0.247062
[Epoch 78; Iter    30/   30] train: loss: 0.0119740
[Epoch 78] ogbg-molclintox: 0.834124 val loss: 0.207187
[Epoch 78] ogbg-molclintox: 0.861585 test loss: 0.218283
[Epoch 79; Iter    30/   30] train: loss: 0.1106198
[Epoch 79] ogbg-molclintox: 0.834761 val loss: 0.334372
[Epoch 79] ogbg-molclintox: 0.807562 test loss: 0.249847
[Epoch 80; Iter    30/   30] train: loss: 0.1267096
[Epoch 80] ogbg-molclintox: 0.750230 val loss: 1.334956
[Epoch 80] ogbg-molclintox: 0.766892 test loss: 0.285873
[Epoch 81; Iter    30/   30] train: loss: 0.1802638
[Epoch 81] ogbg-molclintox: 0.818428 val loss: 0.634085
[Epoch 81] ogbg-molclintox: 0.777397 test loss: 0.255012
[Epoch 82; Iter    30/   30] train: loss: 0.0052544
[Epoch 82] ogbg-molclintox: 0.849756 val loss: 0.407325
[Epoch 82] ogbg-molclintox: 0.837938 test loss: 0.218042
[Epoch 83; Iter    30/   30] train: loss: 0.0109574
[Epoch 83] ogbg-molclintox: 0.836610 val loss: 0.225579
[Epoch 83] ogbg-molclintox: 0.779392 test loss: 0.269000
[Epoch 33; Iter    20/   35] train: loss: 0.1691200
[Epoch 33] ogbg-molclintox: 0.720362 val loss: 0.256787
[Epoch 33] ogbg-molclintox: 0.713267 test loss: 0.228322
[Epoch 34; Iter    15/   35] train: loss: 0.2973523
[Epoch 34] ogbg-molclintox: 0.810007 val loss: 0.263466
[Epoch 34] ogbg-molclintox: 0.622287 test loss: 0.255871
[Epoch 35; Iter    10/   35] train: loss: 0.0993582
[Epoch 35] ogbg-molclintox: 0.816834 val loss: 0.263218
[Epoch 35] ogbg-molclintox: 0.623461 test loss: 0.242773
[Epoch 36; Iter     5/   35] train: loss: 0.1784561
[Epoch 36; Iter    35/   35] train: loss: 0.1564045
[Epoch 36] ogbg-molclintox: 0.772733 val loss: 0.268149
[Epoch 36] ogbg-molclintox: 0.673417 test loss: 0.231369
[Epoch 37; Iter    30/   35] train: loss: 0.3612477
[Epoch 37] ogbg-molclintox: 0.712866 val loss: 0.510633
[Epoch 37] ogbg-molclintox: 0.702433 test loss: 0.280423
[Epoch 38; Iter    25/   35] train: loss: 0.1788397
[Epoch 38] ogbg-molclintox: 0.728869 val loss: 0.270902
[Epoch 38] ogbg-molclintox: 0.682592 test loss: 0.242876
[Epoch 39; Iter    20/   35] train: loss: 0.2382268
[Epoch 39] ogbg-molclintox: 0.673847 val loss: 0.310880
[Epoch 39] ogbg-molclintox: 0.685389 test loss: 0.243304
[Epoch 40; Iter    15/   35] train: loss: 0.1598907
[Epoch 40] ogbg-molclintox: 0.728170 val loss: 0.293138
[Epoch 40] ogbg-molclintox: 0.757397 test loss: 0.370579
[Epoch 41; Iter    10/   35] train: loss: 0.1590940
[Epoch 41] ogbg-molclintox: 0.670640 val loss: 0.672333
[Epoch 41] ogbg-molclintox: 0.631182 test loss: 0.455285
[Epoch 42; Iter     5/   35] train: loss: 0.1235298
[Epoch 42; Iter    35/   35] train: loss: 0.3140638
[Epoch 42] ogbg-molclintox: 0.816528 val loss: 0.390053
[Epoch 42] ogbg-molclintox: 0.700477 test loss: 0.547156
[Epoch 43; Iter    30/   35] train: loss: 0.0739394
[Epoch 43] ogbg-molclintox: 0.754681 val loss: 1.400169
[Epoch 43] ogbg-molclintox: 0.695182 test loss: 0.854465
[Epoch 44; Iter    25/   35] train: loss: 0.2156335
[Epoch 44] ogbg-molclintox: 0.838909 val loss: 0.200516
[Epoch 44] ogbg-molclintox: 0.813580 test loss: 0.194996
[Epoch 45; Iter    20/   35] train: loss: 0.0629923
[Epoch 45] ogbg-molclintox: 0.855274 val loss: 0.329242
[Epoch 45] ogbg-molclintox: 0.828594 test loss: 0.186685
[Epoch 46; Iter    15/   35] train: loss: 0.2779061
[Epoch 46] ogbg-molclintox: 0.687190 val loss: 1.616640
[Epoch 46] ogbg-molclintox: 0.544237 test loss: 3.742803
[Epoch 47; Iter    10/   35] train: loss: 0.2166938
[Epoch 47] ogbg-molclintox: 0.861690 val loss: 0.275745
[Epoch 47] ogbg-molclintox: 0.789546 test loss: 0.354754
[Epoch 48; Iter     5/   35] train: loss: 0.1228184
[Epoch 48; Iter    35/   35] train: loss: 0.2678142
[Epoch 48] ogbg-molclintox: 0.908395 val loss: 0.184138
[Epoch 48] ogbg-molclintox: 0.816980 test loss: 0.191281
[Epoch 49; Iter    30/   35] train: loss: 0.1195399
[Epoch 49] ogbg-molclintox: 0.916100 val loss: 0.214415
[Epoch 49] ogbg-molclintox: 0.811408 test loss: 0.197226
[Epoch 50; Iter    25/   35] train: loss: 0.1049351
[Epoch 50] ogbg-molclintox: 0.895839 val loss: 0.471599
[Epoch 50] ogbg-molclintox: 0.833444 test loss: 0.254413
[Epoch 51; Iter    20/   35] train: loss: 0.0918467
[Epoch 51] ogbg-molclintox: 0.901005 val loss: 0.349663
[Epoch 51] ogbg-molclintox: 0.846970 test loss: 0.172903
[Epoch 52; Iter    15/   35] train: loss: 0.0443797
[Epoch 52] ogbg-molclintox: 0.900671 val loss: 0.299717
[Epoch 52] ogbg-molclintox: 0.854926 test loss: 0.232854
[Epoch 53; Iter    10/   35] train: loss: 0.0540537
[Epoch 53] ogbg-molclintox: 0.868699 val loss: 0.151670
[Epoch 53] ogbg-molclintox: 0.792037 test loss: 0.224004
[Epoch 54; Iter     5/   35] train: loss: 0.1928376
[Epoch 54; Iter    35/   35] train: loss: 0.1186368
[Epoch 54] ogbg-molclintox: 0.893354 val loss: 0.246348
[Epoch 54] ogbg-molclintox: 0.788342 test loss: 0.227370
[Epoch 55; Iter    30/   35] train: loss: 0.0740420
[Epoch 55] ogbg-molclintox: 0.837557 val loss: 0.222557
[Epoch 55] ogbg-molclintox: 0.808627 test loss: 0.238554
[Epoch 56; Iter    25/   35] train: loss: 0.0550934
[Epoch 56] ogbg-molclintox: 0.887375 val loss: 0.152969
[Epoch 56] ogbg-molclintox: 0.741874 test loss: 0.254429
[Epoch 57; Iter    20/   35] train: loss: 0.0953522
[Epoch 57] ogbg-molclintox: 0.925650 val loss: 0.119808
[Epoch 57] ogbg-molclintox: 0.826460 test loss: 0.205665
[Epoch 58; Iter    15/   35] train: loss: 0.0509995
[Epoch 58] ogbg-molclintox: 0.931776 val loss: 0.117188
[Epoch 58] ogbg-molclintox: 0.807533 test loss: 0.222180
[Epoch 59; Iter    10/   35] train: loss: 0.1098083
[Epoch 59] ogbg-molclintox: 0.917515 val loss: 0.118177
[Epoch 59] ogbg-molclintox: 0.818416 test loss: 0.220521
[Epoch 60; Iter     5/   35] train: loss: 0.0666761
[Epoch 60; Iter    35/   35] train: loss: 0.1691960
[Epoch 60] ogbg-molclintox: 0.956149 val loss: 0.108047
[Epoch 60] ogbg-molclintox: 0.853158 test loss: 0.212786
[Epoch 61; Iter    30/   35] train: loss: 0.1052783
[Epoch 61] ogbg-molclintox: 0.925223 val loss: 0.129441
[Epoch 61] ogbg-molclintox: 0.827478 test loss: 0.247021
[Epoch 62; Iter    25/   35] train: loss: 0.0415291
[Epoch 62] ogbg-molclintox: 0.947161 val loss: 0.118325
[Epoch 62] ogbg-molclintox: 0.798849 test loss: 0.240226
[Epoch 63; Iter    20/   35] train: loss: 0.0588861
[Epoch 63] ogbg-molclintox: 0.917143 val loss: 0.121087
[Epoch 63] ogbg-molclintox: 0.804991 test loss: 0.244913
[Epoch 64; Iter    15/   35] train: loss: 0.0337131
[Epoch 64] ogbg-molclintox: 0.899239 val loss: 0.124963
[Epoch 64] ogbg-molclintox: 0.827009 test loss: 0.245272
[Epoch 65; Iter    10/   35] train: loss: 0.0859314
[Epoch 65] ogbg-molclintox: 0.916990 val loss: 0.740647
[Epoch 65] ogbg-molclintox: 0.799561 test loss: 0.277256
[Epoch 66; Iter     5/   35] train: loss: 0.0653825
[Epoch 66; Iter    35/   35] train: loss: 0.1262743
[Epoch 66] ogbg-molclintox: 0.913990 val loss: 0.129317
[Epoch 66] ogbg-molclintox: 0.785318 test loss: 0.236173
[Epoch 67; Iter    30/   35] train: loss: 0.1508473
[Epoch 67] ogbg-molclintox: 0.949968 val loss: 0.123011
[Epoch 67] ogbg-molclintox: 0.777111 test loss: 0.248918
[Epoch 68; Iter    25/   35] train: loss: 0.0278427
[Epoch 68] ogbg-molclintox: 0.925101 val loss: 0.123211
[Epoch 68] ogbg-molclintox: 0.799311 test loss: 0.245152
[Epoch 69; Iter    20/   35] train: loss: 0.1121885
[Epoch 69] ogbg-molclintox: 0.925451 val loss: 0.145672
[Epoch 69] ogbg-molclintox: 0.818191 test loss: 0.286872
[Epoch 70; Iter    15/   35] train: loss: 0.0759211
[Epoch 70] ogbg-molclintox: 0.930527 val loss: 0.132824
[Epoch 70] ogbg-molclintox: 0.810852 test loss: 0.246252
[Epoch 71; Iter    10/   35] train: loss: 0.0363493
[Epoch 71] ogbg-molclintox: 0.922397 val loss: 0.165649
[Epoch 71] ogbg-molclintox: 0.806776 test loss: 0.311366
[Epoch 72; Iter     5/   35] train: loss: 0.0143659
[Epoch 72; Iter    35/   35] train: loss: 0.0054772
[Epoch 72] ogbg-molclintox: 0.907252 val loss: 0.319107
[Epoch 72] ogbg-molclintox: 0.789378 test loss: 0.346328
[Epoch 73; Iter    30/   35] train: loss: 0.0668378
[Epoch 73] ogbg-molclintox: 0.905180 val loss: 0.162573
[Epoch 73] ogbg-molclintox: 0.801572 test loss: 0.265712
[Epoch 74; Iter    25/   35] train: loss: 0.0808656
[Epoch 74] ogbg-molclintox: 0.848236 val loss: 0.175466
[Epoch 74] ogbg-molclintox: 0.800055 test loss: 0.266265
[Epoch 75; Iter    20/   35] train: loss: 0.0321788
[Epoch 75] ogbg-molclintox: 0.930402 val loss: 0.151712
[Epoch 75] ogbg-molclintox: 0.771400 test loss: 0.286904
[Epoch 76; Iter    15/   35] train: loss: 0.1185638
[Epoch 76] ogbg-molclintox: 0.898202 val loss: 0.265091
[Epoch 76] ogbg-molclintox: 0.779550 test loss: 0.279615
[Epoch 77; Iter    10/   35] train: loss: 0.0411194
[Epoch 77] ogbg-molclintox: 0.866505 val loss: 0.237211
[Epoch 77] ogbg-molclintox: 0.749324 test loss: 0.292635
[Epoch 78; Iter     5/   35] train: loss: 0.0359058
[Epoch 78; Iter    35/   35] train: loss: 0.0193568
[Epoch 78] ogbg-molclintox: 0.908299 val loss: 0.180920
[Epoch 78] ogbg-molclintox: 0.774990 test loss: 0.312834
[Epoch 79; Iter    30/   35] train: loss: 0.0145682
[Epoch 79] ogbg-molclintox: 0.785749 val loss: 0.192811
[Epoch 79] ogbg-molclintox: 0.711454 test loss: 0.314626
[Epoch 34] ogbg-molclintox: 0.687848 test loss: 0.261266
[Epoch 35; Iter    30/   30] train: loss: 0.2895623
[Epoch 35] ogbg-molclintox: 0.723722 val loss: 0.258637
[Epoch 35] ogbg-molclintox: 0.627795 test loss: 0.273441
[Epoch 36; Iter    30/   30] train: loss: 0.3453519
[Epoch 36] ogbg-molclintox: 0.781585 val loss: 0.172067
[Epoch 36] ogbg-molclintox: 0.675508 test loss: 0.239567
[Epoch 37; Iter    30/   30] train: loss: 0.3016369
[Epoch 37] ogbg-molclintox: 0.782751 val loss: 0.194233
[Epoch 37] ogbg-molclintox: 0.734528 test loss: 0.234953
[Epoch 38; Iter    30/   30] train: loss: 0.1499421
[Epoch 38] ogbg-molclintox: 0.743825 val loss: 0.242334
[Epoch 38] ogbg-molclintox: 0.642032 test loss: 0.273491
[Epoch 39; Iter    30/   30] train: loss: 0.2493957
[Epoch 39] ogbg-molclintox: 0.780533 val loss: 0.182557
[Epoch 39] ogbg-molclintox: 0.668565 test loss: 0.243519
[Epoch 40; Iter    30/   30] train: loss: 0.2268895
[Epoch 40] ogbg-molclintox: 0.717626 val loss: 0.242034
[Epoch 40] ogbg-molclintox: 0.647610 test loss: 0.262822
[Epoch 41; Iter    30/   30] train: loss: 0.2058095
[Epoch 41] ogbg-molclintox: 0.770337 val loss: 0.249432
[Epoch 41] ogbg-molclintox: 0.697033 test loss: 0.241696
[Epoch 42; Iter    30/   30] train: loss: 0.0930115
[Epoch 42] ogbg-molclintox: 0.736549 val loss: 0.227202
[Epoch 42] ogbg-molclintox: 0.691531 test loss: 0.239986
[Epoch 43; Iter    30/   30] train: loss: 0.2042656
[Epoch 43] ogbg-molclintox: 0.841711 val loss: 0.221489
[Epoch 43] ogbg-molclintox: 0.707203 test loss: 0.248398
[Epoch 44; Iter    30/   30] train: loss: 0.0828791
[Epoch 44] ogbg-molclintox: 0.754199 val loss: 0.223795
[Epoch 44] ogbg-molclintox: 0.677284 test loss: 0.258242
[Epoch 45; Iter    30/   30] train: loss: 0.1706963
[Epoch 45] ogbg-molclintox: 0.758123 val loss: 0.250990
[Epoch 45] ogbg-molclintox: 0.685272 test loss: 0.247352
[Epoch 46; Iter    30/   30] train: loss: 0.0889843
[Epoch 46] ogbg-molclintox: 0.850873 val loss: 0.190093
[Epoch 46] ogbg-molclintox: 0.711532 test loss: 0.248354
[Epoch 47; Iter    30/   30] train: loss: 0.1772719
[Epoch 47] ogbg-molclintox: 0.853621 val loss: 0.203126
[Epoch 47] ogbg-molclintox: 0.824723 test loss: 0.223292
[Epoch 48; Iter    30/   30] train: loss: 0.5180023
[Epoch 48] ogbg-molclintox: 0.769833 val loss: 0.347569
[Epoch 48] ogbg-molclintox: 0.752787 test loss: 0.245261
[Epoch 49; Iter    30/   30] train: loss: 0.0451205
[Epoch 49] ogbg-molclintox: 0.808971 val loss: 1.071387
[Epoch 49] ogbg-molclintox: 0.704331 test loss: 0.785616
[Epoch 50; Iter    30/   30] train: loss: 0.2362027
[Epoch 50] ogbg-molclintox: 0.782442 val loss: 0.340367
[Epoch 50] ogbg-molclintox: 0.763027 test loss: 0.305040
[Epoch 51; Iter    30/   30] train: loss: 0.1754018
[Epoch 51] ogbg-molclintox: 0.871836 val loss: 0.141757
[Epoch 51] ogbg-molclintox: 0.807860 test loss: 0.223244
[Epoch 52; Iter    30/   30] train: loss: 0.3599336
[Epoch 52] ogbg-molclintox: 0.818570 val loss: 0.801301
[Epoch 52] ogbg-molclintox: 0.824838 test loss: 0.289904
[Epoch 53; Iter    30/   30] train: loss: 0.2263472
[Epoch 53] ogbg-molclintox: 0.702785 val loss: 0.256903
[Epoch 53] ogbg-molclintox: 0.701394 test loss: 0.276419
[Epoch 54; Iter    30/   30] train: loss: 0.0951151
[Epoch 54] ogbg-molclintox: 0.861503 val loss: 0.214673
[Epoch 54] ogbg-molclintox: 0.764304 test loss: 0.215633
[Epoch 55; Iter    30/   30] train: loss: 0.1440940
[Epoch 55] ogbg-molclintox: 0.875337 val loss: 0.968456
[Epoch 55] ogbg-molclintox: 0.851367 test loss: 0.211041
[Epoch 56; Iter    30/   30] train: loss: 0.1026635
[Epoch 56] ogbg-molclintox: 0.887527 val loss: 0.122767
[Epoch 56] ogbg-molclintox: 0.829461 test loss: 0.200359
[Epoch 57; Iter    30/   30] train: loss: 0.1319846
[Epoch 57] ogbg-molclintox: 0.850635 val loss: 3.356491
[Epoch 57] ogbg-molclintox: 0.837981 test loss: 0.389352
[Epoch 58; Iter    30/   30] train: loss: 0.5171008
[Epoch 58] ogbg-molclintox: 0.891197 val loss: 0.548915
[Epoch 58] ogbg-molclintox: 0.874457 test loss: 0.272688
[Epoch 59; Iter    30/   30] train: loss: 0.1754618
[Epoch 59] ogbg-molclintox: 0.894578 val loss: 0.842477
[Epoch 59] ogbg-molclintox: 0.847655 test loss: 0.540337
[Epoch 60; Iter    30/   30] train: loss: 0.1405264
[Epoch 60] ogbg-molclintox: 0.831911 val loss: 0.472985
[Epoch 60] ogbg-molclintox: 0.835768 test loss: 0.215370
[Epoch 61; Iter    30/   30] train: loss: 0.0623360
[Epoch 61] ogbg-molclintox: 0.865931 val loss: 0.140665
[Epoch 61] ogbg-molclintox: 0.797377 test loss: 0.228363
[Epoch 62; Iter    30/   30] train: loss: 0.0861200
[Epoch 62] ogbg-molclintox: 0.830758 val loss: 0.210272
[Epoch 62] ogbg-molclintox: 0.829146 test loss: 0.237566
[Epoch 63; Iter    30/   30] train: loss: 0.0820923
[Epoch 63] ogbg-molclintox: 0.820434 val loss: 0.155097
[Epoch 63] ogbg-molclintox: 0.803022 test loss: 0.216687
[Epoch 64; Iter    30/   30] train: loss: 0.0744170
[Epoch 64] ogbg-molclintox: 0.842391 val loss: 0.176876
[Epoch 64] ogbg-molclintox: 0.839326 test loss: 0.236060
[Epoch 65; Iter    30/   30] train: loss: 0.0165377
[Epoch 65] ogbg-molclintox: 0.830823 val loss: 0.662878
[Epoch 65] ogbg-molclintox: 0.798622 test loss: 0.243611
[Epoch 66; Iter    30/   30] train: loss: 0.1311597
[Epoch 66] ogbg-molclintox: 0.871730 val loss: 0.409265
[Epoch 66] ogbg-molclintox: 0.851467 test loss: 0.196933
[Epoch 67; Iter    30/   30] train: loss: 0.0822338
[Epoch 67] ogbg-molclintox: 0.858817 val loss: 0.309613
[Epoch 67] ogbg-molclintox: 0.857495 test loss: 0.321626
[Epoch 68; Iter    30/   30] train: loss: 0.0962229
[Epoch 68] ogbg-molclintox: 0.839181 val loss: 0.736239
[Epoch 68] ogbg-molclintox: 0.801869 test loss: 0.235838
[Epoch 69; Iter    30/   30] train: loss: 0.0182473
[Epoch 69] ogbg-molclintox: 0.804929 val loss: 0.173076
[Epoch 69] ogbg-molclintox: 0.800001 test loss: 0.252700
[Epoch 70; Iter    30/   30] train: loss: 0.0469351
[Epoch 70] ogbg-molclintox: 0.883316 val loss: 0.256699
[Epoch 70] ogbg-molclintox: 0.844042 test loss: 0.273521
[Epoch 71; Iter    30/   30] train: loss: 0.0093007
[Epoch 71] ogbg-molclintox: 0.846506 val loss: 0.224059
[Epoch 71] ogbg-molclintox: 0.810241 test loss: 0.260001
[Epoch 72; Iter    30/   30] train: loss: 0.0823021
[Epoch 72] ogbg-molclintox: 0.784400 val loss: 0.414861
[Epoch 72] ogbg-molclintox: 0.799740 test loss: 0.244287
[Epoch 73; Iter    30/   30] train: loss: 0.0118512
[Epoch 73] ogbg-molclintox: 0.753263 val loss: 0.332018
[Epoch 73] ogbg-molclintox: 0.797247 test loss: 0.275547
[Epoch 74; Iter    30/   30] train: loss: 0.0196721
[Epoch 74] ogbg-molclintox: 0.718266 val loss: 0.252083
[Epoch 74] ogbg-molclintox: 0.762669 test loss: 0.296732
[Epoch 75; Iter    30/   30] train: loss: 0.0505696
[Epoch 75] ogbg-molclintox: 0.854562 val loss: 0.180242
[Epoch 75] ogbg-molclintox: 0.841620 test loss: 0.239727
[Epoch 76; Iter    30/   30] train: loss: 0.1071990
[Epoch 76] ogbg-molclintox: 0.858560 val loss: 0.175932
[Epoch 76] ogbg-molclintox: 0.847150 test loss: 0.235553
[Epoch 77; Iter    30/   30] train: loss: 0.0430246
[Epoch 77] ogbg-molclintox: 0.791130 val loss: 0.590272
[Epoch 77] ogbg-molclintox: 0.822903 test loss: 0.302570
[Epoch 78; Iter    30/   30] train: loss: 0.0452002
[Epoch 78] ogbg-molclintox: 0.773915 val loss: 0.252722
[Epoch 78] ogbg-molclintox: 0.783609 test loss: 0.272324
[Epoch 79; Iter    30/   30] train: loss: 0.0290622
[Epoch 79] ogbg-molclintox: 0.757919 val loss: 0.245830
[Epoch 79] ogbg-molclintox: 0.799536 test loss: 0.294509
[Epoch 80; Iter    30/   30] train: loss: 0.0074493
[Epoch 80] ogbg-molclintox: 0.817834 val loss: 0.184437
[Epoch 80] ogbg-molclintox: 0.817494 test loss: 0.268851
[Epoch 81; Iter    30/   30] train: loss: 0.0039415
[Epoch 81] ogbg-molclintox: 0.820692 val loss: 0.207489
[Epoch 81] ogbg-molclintox: 0.832290 test loss: 0.260388
[Epoch 82; Iter    30/   30] train: loss: 0.0262675
[Epoch 82] ogbg-molclintox: 0.840341 val loss: 0.212407
[Epoch 82] ogbg-molclintox: 0.831577 test loss: 0.245712
[Epoch 83; Iter    30/   30] train: loss: 0.0389942
[Epoch 83] ogbg-molclintox: 0.789023 val loss: 0.230633
[Epoch 83] ogbg-molclintox: 0.831740 test loss: 0.297441
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.2031816
[Epoch 84] ogbg-molclintox: 0.759146 val loss: 0.753498
[Epoch 84] ogbg-molclintox: 0.854627 test loss: 0.249114
[Epoch 85; Iter    30/   30] train: loss: 0.0405798
[Epoch 85] ogbg-molclintox: 0.829586 val loss: 0.185659
[Epoch 85] ogbg-molclintox: 0.801699 test loss: 0.292154
[Epoch 86; Iter    30/   30] train: loss: 0.0100981
[Epoch 86] ogbg-molclintox: 0.819122 val loss: 0.199879
[Epoch 86] ogbg-molclintox: 0.818810 test loss: 0.277380
[Epoch 87; Iter    30/   30] train: loss: 0.0145207
[Epoch 87] ogbg-molclintox: 0.805671 val loss: 0.203380
[Epoch 87] ogbg-molclintox: 0.829872 test loss: 0.262909
[Epoch 88; Iter    30/   30] train: loss: 0.0100247
[Epoch 88] ogbg-molclintox: 0.822929 val loss: 0.233609
[Epoch 88] ogbg-molclintox: 0.870399 test loss: 0.250693
[Epoch 89; Iter    30/   30] train: loss: 0.1323846
[Epoch 89] ogbg-molclintox: 0.778327 val loss: 0.206589
[Epoch 89] ogbg-molclintox: 0.833148 test loss: 0.270954
[Epoch 90; Iter    30/   30] train: loss: 0.0116557
[Epoch 90] ogbg-molclintox: 0.842573 val loss: 0.225795
[Epoch 90] ogbg-molclintox: 0.866567 test loss: 0.251554
[Epoch 91; Iter    30/   30] train: loss: 0.0077605
[Epoch 91] ogbg-molclintox: 0.813845 val loss: 0.220322
[Epoch 91] ogbg-molclintox: 0.810915 test loss: 0.286826
[Epoch 92; Iter    30/   30] train: loss: 0.1905156
[Epoch 92] ogbg-molclintox: 0.828553 val loss: 0.196502
[Epoch 92] ogbg-molclintox: 0.895564 test loss: 0.218359
[Epoch 93; Iter    30/   30] train: loss: 0.0131434
[Epoch 93] ogbg-molclintox: 0.852831 val loss: 0.188057
[Epoch 93] ogbg-molclintox: 0.867326 test loss: 0.244690
[Epoch 94; Iter    30/   30] train: loss: 0.0259533
[Epoch 94] ogbg-molclintox: 0.829990 val loss: 0.223445
[Epoch 94] ogbg-molclintox: 0.809123 test loss: 0.388333
[Epoch 95; Iter    30/   30] train: loss: 0.0105154
[Epoch 95] ogbg-molclintox: 0.822835 val loss: 0.246309
[Epoch 95] ogbg-molclintox: 0.839511 test loss: 0.307615
[Epoch 96; Iter    30/   30] train: loss: 0.0080206
[Epoch 96] ogbg-molclintox: 0.837069 val loss: 0.263878
[Epoch 96] ogbg-molclintox: 0.833261 test loss: 0.295302
[Epoch 97; Iter    30/   30] train: loss: 0.0063588
[Epoch 97] ogbg-molclintox: 0.813161 val loss: 0.246476
[Epoch 97] ogbg-molclintox: 0.784370 test loss: 0.361381
[Epoch 98; Iter    30/   30] train: loss: 0.1177495
[Epoch 98] ogbg-molclintox: 0.834619 val loss: 0.246541
[Epoch 98] ogbg-molclintox: 0.840161 test loss: 0.284790
[Epoch 99; Iter    30/   30] train: loss: 0.0086319
[Epoch 99] ogbg-molclintox: 0.806726 val loss: 0.236268
[Epoch 99] ogbg-molclintox: 0.835719 test loss: 0.269745
[Epoch 100; Iter    30/   30] train: loss: 0.1524303
[Epoch 100] ogbg-molclintox: 0.788449 val loss: 0.305024
[Epoch 100] ogbg-molclintox: 0.805789 test loss: 0.340693
[Epoch 101; Iter    30/   30] train: loss: 0.0238333
[Epoch 101] ogbg-molclintox: 0.756873 val loss: 0.269046
[Epoch 101] ogbg-molclintox: 0.823072 test loss: 0.288453
[Epoch 102; Iter    30/   30] train: loss: 0.0075450
[Epoch 102] ogbg-molclintox: 0.786484 val loss: 0.235314
[Epoch 102] ogbg-molclintox: 0.830585 test loss: 0.271419
[Epoch 103; Iter    30/   30] train: loss: 0.0248859
[Epoch 103] ogbg-molclintox: 0.791716 val loss: 0.233707
[Epoch 103] ogbg-molclintox: 0.824497 test loss: 0.289080
[Epoch 104; Iter    30/   30] train: loss: 0.0029907
[Epoch 104] ogbg-molclintox: 0.768263 val loss: 0.274355
[Epoch 104] ogbg-molclintox: 0.822058 test loss: 0.274770
[Epoch 105; Iter    30/   30] train: loss: 0.1474700
[Epoch 105] ogbg-molclintox: 0.763820 val loss: 0.248187
[Epoch 105] ogbg-molclintox: 0.805247 test loss: 0.323364
[Epoch 106; Iter    30/   30] train: loss: 0.0070441
[Epoch 106] ogbg-molclintox: 0.757675 val loss: 0.255588
[Epoch 106] ogbg-molclintox: 0.822345 test loss: 0.276868
[Epoch 107; Iter    30/   30] train: loss: 0.0116490
[Epoch 107] ogbg-molclintox: 0.793479 val loss: 0.268741
[Epoch 107] ogbg-molclintox: 0.817595 test loss: 0.312157
[Epoch 108; Iter    30/   30] train: loss: 0.0183227
[Epoch 108] ogbg-molclintox: 0.744767 val loss: 0.266156
[Epoch 108] ogbg-molclintox: 0.794126 test loss: 0.321934
[Epoch 109; Iter    30/   30] train: loss: 0.0056842
[Epoch 109] ogbg-molclintox: 0.734857 val loss: 0.279443
[Epoch 109] ogbg-molclintox: 0.819633 test loss: 0.321166
[Epoch 110; Iter    30/   30] train: loss: 0.0535467
[Epoch 110] ogbg-molclintox: 0.764704 val loss: 0.253103
[Epoch 110] ogbg-molclintox: 0.826117 test loss: 0.316221
[Epoch 111; Iter    30/   30] train: loss: 0.0058152
[Epoch 111] ogbg-molclintox: 0.774981 val loss: 0.273105
[Epoch 111] ogbg-molclintox: 0.818261 test loss: 0.326218
[Epoch 112; Iter    30/   30] train: loss: 0.0094359
[Epoch 112] ogbg-molclintox: 0.747711 val loss: 0.274782
[Epoch 112] ogbg-molclintox: 0.826056 test loss: 0.313759
[Epoch 113; Iter    30/   30] train: loss: 0.0032241
[Epoch 113] ogbg-molclintox: 0.716114 val loss: 0.275793
[Epoch 113] ogbg-molclintox: 0.769742 test loss: 0.355117
[Epoch 114; Iter    30/   30] train: loss: 0.0065053
[Epoch 114] ogbg-molclintox: 0.736609 val loss: 0.273880
[Epoch 114] ogbg-molclintox: 0.807841 test loss: 0.320778
[Epoch 115; Iter    30/   30] train: loss: 0.1339553
[Epoch 115] ogbg-molclintox: 0.734315 val loss: 0.293911
[Epoch 115] ogbg-molclintox: 0.829395 test loss: 0.318920
[Epoch 116; Iter    30/   30] train: loss: 0.0016181
[Epoch 116] ogbg-molclintox: 0.724750 val loss: 0.279155
[Epoch 116] ogbg-molclintox: 0.802544 test loss: 0.322715
[Epoch 117; Iter    30/   30] train: loss: 0.0541510
[Epoch 117] ogbg-molclintox: 0.721469 val loss: 0.289861
[Epoch 117] ogbg-molclintox: 0.796120 test loss: 0.329952
[Epoch 118; Iter    30/   30] train: loss: 0.0271371
[Epoch 118] ogbg-molclintox: 0.756969 val loss: 0.270418
[Epoch 118] ogbg-molclintox: 0.809546 test loss: 0.325207
[Epoch 119; Iter    30/   30] train: loss: 0.0014100
[Epoch 119] ogbg-molclintox: 0.775106 val loss: 0.259144
[Epoch 119] ogbg-molclintox: 0.825924 test loss: 0.323816
[Epoch 120; Iter    30/   30] train: loss: 0.0145664
[Epoch 120] ogbg-molclintox: 0.782581 val loss: 0.264834
[Epoch 120] ogbg-molclintox: 0.860772 test loss: 0.298208
[Epoch 121; Iter    30/   30] train: loss: 0.0639497
[Epoch 121] ogbg-molclintox: 0.687310 val loss: 0.366123
[Epoch 121] ogbg-molclintox: 0.764213 test loss: 0.318688
[Epoch 122; Iter    30/   30] train: loss: 0.0022823
[Epoch 122] ogbg-molclintox: 0.764337 val loss: 0.299638
[Epoch 122] ogbg-molclintox: 0.841814 test loss: 0.284477
[Epoch 123; Iter    30/   30] train: loss: 0.0023975
[Epoch 123] ogbg-molclintox: 0.733264 val loss: 0.289214
[Epoch 123] ogbg-molclintox: 0.802351 test loss: 0.348516
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 123 epochs. Best model checkpoint was in epoch 63.
Statistics on  val_best_checkpoint
mean_pred: 0.19331127405166626
std_pred: 5.378854751586914
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.6878785658264247
rocauc: 0.8899835941443714
ogbg-molclintox: 0.8899835941443714
OGBNanLabelBCEWithLogitsLoss: 0.1532330121845007
Statistics on  test
mean_pred: 0.18512944877147675
std_pred: 5.3053178787231445
mean_targets: 0.5101351737976074
std_targets: 0.5003200173377991
prcauc: 0.6588345065169429
rocauc: 0.7952448394037372
ogbg-molclintox: 0.7952448394037372
OGBNanLabelBCEWithLogitsLoss: 0.23419713526964187
Statistics on  train
mean_pred: 0.17702336609363556
std_pred: 5.479407787322998
mean_targets: 0.5050790309906006
std_targets: 0.5001153349876404
prcauc: 0.9619528305094316
rocauc: 0.994270449781496
ogbg-molclintox: 0.994270449781496
OGBNanLabelBCEWithLogitsLoss: 0.06332756988704205
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.0658229
[Epoch 84] ogbg-molclintox: 0.841447 val loss: 0.266226
[Epoch 84] ogbg-molclintox: 0.804007 test loss: 0.271243
[Epoch 85; Iter    30/   30] train: loss: 0.1169599
[Epoch 85] ogbg-molclintox: 0.705908 val loss: 0.333004
[Epoch 85] ogbg-molclintox: 0.769556 test loss: 0.307275
[Epoch 86; Iter    30/   30] train: loss: 0.0139798
[Epoch 86] ogbg-molclintox: 0.754191 val loss: 0.291818
[Epoch 86] ogbg-molclintox: 0.806565 test loss: 0.281169
[Epoch 87; Iter    30/   30] train: loss: 0.0101809
[Epoch 87] ogbg-molclintox: 0.775671 val loss: 0.246979
[Epoch 87] ogbg-molclintox: 0.829409 test loss: 0.242274
[Epoch 88; Iter    30/   30] train: loss: 0.0255521
[Epoch 88] ogbg-molclintox: 0.758133 val loss: 0.205610
[Epoch 88] ogbg-molclintox: 0.784411 test loss: 0.271760
[Epoch 89; Iter    30/   30] train: loss: 0.0531470
[Epoch 89] ogbg-molclintox: 0.752881 val loss: 0.445695
[Epoch 89] ogbg-molclintox: 0.785817 test loss: 0.303865
[Epoch 90; Iter    30/   30] train: loss: 0.0730061
[Epoch 90] ogbg-molclintox: 0.774605 val loss: 0.228445
[Epoch 90] ogbg-molclintox: 0.831812 test loss: 0.245910
[Epoch 91; Iter    30/   30] train: loss: 0.0268504
[Epoch 91] ogbg-molclintox: 0.734508 val loss: 0.395156
[Epoch 91] ogbg-molclintox: 0.800314 test loss: 0.352869
[Epoch 92; Iter    30/   30] train: loss: 0.0251548
[Epoch 92] ogbg-molclintox: 0.713930 val loss: 0.275628
[Epoch 92] ogbg-molclintox: 0.801199 test loss: 0.275947
[Epoch 93; Iter    30/   30] train: loss: 0.2625732
[Epoch 93] ogbg-molclintox: 0.714788 val loss: 0.421717
[Epoch 93] ogbg-molclintox: 0.750545 test loss: 0.349419
[Epoch 94; Iter    30/   30] train: loss: 0.0106346
[Epoch 94] ogbg-molclintox: 0.832509 val loss: 0.249333
[Epoch 94] ogbg-molclintox: 0.824267 test loss: 0.284072
[Epoch 95; Iter    30/   30] train: loss: 0.0408813
[Epoch 95] ogbg-molclintox: 0.750904 val loss: 0.229191
[Epoch 95] ogbg-molclintox: 0.769775 test loss: 0.298034
[Epoch 96; Iter    30/   30] train: loss: 0.0332622
[Epoch 96] ogbg-molclintox: 0.810414 val loss: 0.307585
[Epoch 96] ogbg-molclintox: 0.840912 test loss: 0.279006
[Epoch 97; Iter    30/   30] train: loss: 0.0086928
[Epoch 97] ogbg-molclintox: 0.780195 val loss: 0.283293
[Epoch 97] ogbg-molclintox: 0.794520 test loss: 0.303459
[Epoch 98; Iter    30/   30] train: loss: 0.0280746
[Epoch 98] ogbg-molclintox: 0.804742 val loss: 0.777295
[Epoch 98] ogbg-molclintox: 0.862668 test loss: 0.248898
[Epoch 99; Iter    30/   30] train: loss: 0.0042942
[Epoch 99] ogbg-molclintox: 0.748920 val loss: 0.282718
[Epoch 99] ogbg-molclintox: 0.822052 test loss: 0.269617
[Epoch 100; Iter    30/   30] train: loss: 0.0145677
[Epoch 100] ogbg-molclintox: 0.748896 val loss: 0.290811
[Epoch 100] ogbg-molclintox: 0.786583 test loss: 0.335577
[Epoch 101; Iter    30/   30] train: loss: 0.0572261
[Epoch 101] ogbg-molclintox: 0.772651 val loss: 0.900910
[Epoch 101] ogbg-molclintox: 0.844178 test loss: 0.273714
[Epoch 102; Iter    30/   30] train: loss: 0.0094332
[Epoch 102] ogbg-molclintox: 0.733909 val loss: 0.899857
[Epoch 102] ogbg-molclintox: 0.814036 test loss: 0.283920
[Epoch 103; Iter    30/   30] train: loss: 0.1496438
[Epoch 103] ogbg-molclintox: 0.776793 val loss: 0.251250
[Epoch 103] ogbg-molclintox: 0.838389 test loss: 0.278252
[Epoch 104; Iter    30/   30] train: loss: 0.0028331
[Epoch 104] ogbg-molclintox: 0.770833 val loss: 0.604916
[Epoch 104] ogbg-molclintox: 0.837404 test loss: 0.291679
[Epoch 105; Iter    30/   30] train: loss: 0.0103820
[Epoch 105] ogbg-molclintox: 0.772704 val loss: 1.364883
[Epoch 105] ogbg-molclintox: 0.844459 test loss: 0.283028
[Epoch 106; Iter    30/   30] train: loss: 0.0032832
[Epoch 106] ogbg-molclintox: 0.708727 val loss: 1.989613
[Epoch 106] ogbg-molclintox: 0.787711 test loss: 0.314659
[Epoch 107; Iter    30/   30] train: loss: 0.0092523
[Epoch 107] ogbg-molclintox: 0.775386 val loss: 1.149404
[Epoch 107] ogbg-molclintox: 0.830902 test loss: 0.281613
[Epoch 108; Iter    30/   30] train: loss: 0.0024810
[Epoch 108] ogbg-molclintox: 0.785958 val loss: 0.233735
[Epoch 108] ogbg-molclintox: 0.813153 test loss: 0.276563
[Epoch 109; Iter    30/   30] train: loss: 0.0081294
[Epoch 109] ogbg-molclintox: 0.714842 val loss: 0.977041
[Epoch 109] ogbg-molclintox: 0.781929 test loss: 0.314199
[Epoch 110; Iter    30/   30] train: loss: 0.0268232
[Epoch 110] ogbg-molclintox: 0.738994 val loss: 0.439968
[Epoch 110] ogbg-molclintox: 0.828831 test loss: 0.280367
[Epoch 111; Iter    30/   30] train: loss: 0.0673660
[Epoch 111] ogbg-molclintox: 0.759887 val loss: 0.539670
[Epoch 111] ogbg-molclintox: 0.812724 test loss: 0.297557
[Epoch 112; Iter    30/   30] train: loss: 0.0158119
[Epoch 112] ogbg-molclintox: 0.759687 val loss: 0.791110
[Epoch 112] ogbg-molclintox: 0.820627 test loss: 0.310256
[Epoch 113; Iter    30/   30] train: loss: 0.0145522
[Epoch 113] ogbg-molclintox: 0.719951 val loss: 0.826752
[Epoch 113] ogbg-molclintox: 0.800382 test loss: 0.312735
[Epoch 114; Iter    30/   30] train: loss: 0.0014775
[Epoch 114] ogbg-molclintox: 0.738298 val loss: 0.796966
[Epoch 114] ogbg-molclintox: 0.815486 test loss: 0.299312
[Epoch 115; Iter    30/   30] train: loss: 0.0110681
[Epoch 115] ogbg-molclintox: 0.738385 val loss: 0.698569
[Epoch 115] ogbg-molclintox: 0.806788 test loss: 0.333854
[Epoch 116; Iter    30/   30] train: loss: 0.0089978
[Epoch 116] ogbg-molclintox: 0.738899 val loss: 0.958052
[Epoch 116] ogbg-molclintox: 0.819396 test loss: 0.309457
[Epoch 117; Iter    30/   30] train: loss: 0.1503103
[Epoch 117] ogbg-molclintox: 0.703581 val loss: 0.832226
[Epoch 117] ogbg-molclintox: 0.811794 test loss: 0.320956
[Epoch 118; Iter    30/   30] train: loss: 0.0046263
[Epoch 118] ogbg-molclintox: 0.727333 val loss: 0.942106
[Epoch 118] ogbg-molclintox: 0.792786 test loss: 0.338981
[Epoch 119; Iter    30/   30] train: loss: 0.0050805
[Epoch 119] ogbg-molclintox: 0.754984 val loss: 1.161415
[Epoch 119] ogbg-molclintox: 0.816862 test loss: 0.328995
[Epoch 120; Iter    30/   30] train: loss: 0.0647228
[Epoch 120] ogbg-molclintox: 0.734789 val loss: 0.998877
[Epoch 120] ogbg-molclintox: 0.815294 test loss: 0.323631
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 59.
Statistics on  val_best_checkpoint
mean_pred: 0.09187211841344833
std_pred: 8.99603271484375
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.6496997270119016
rocauc: 0.894577654383308
ogbg-molclintox: 0.894577654383308
OGBNanLabelBCEWithLogitsLoss: 0.8424769949167967
Statistics on  test
mean_pred: 0.1098063588142395
std_pred: 6.487865924835205
mean_targets: 0.5101351737976074
std_targets: 0.5003200173377991
prcauc: 0.638896106673559
rocauc: 0.8476545111517473
ogbg-molclintox: 0.8476545111517473
OGBNanLabelBCEWithLogitsLoss: 0.5403365530073643
Statistics on  train
mean_pred: 0.12469467520713806
std_pred: 5.411755084991455
mean_targets: 0.5050790309906006
std_targets: 0.5001153349876404
prcauc: 0.9503580326616322
rocauc: 0.9912040840366264
ogbg-molclintox: 0.9912040840366264
OGBNanLabelBCEWithLogitsLoss: 0.08072431938101848
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 80; Iter    25/   35] train: loss: 0.1088835
[Epoch 80] ogbg-molclintox: 0.860976 val loss: 0.894636
[Epoch 80] ogbg-molclintox: 0.791644 test loss: 0.288138
[Epoch 81; Iter    20/   35] train: loss: 0.0752622
[Epoch 81] ogbg-molclintox: 0.917084 val loss: 0.683772
[Epoch 81] ogbg-molclintox: 0.836617 test loss: 0.247239
[Epoch 82; Iter    15/   35] train: loss: 0.0110459
[Epoch 82] ogbg-molclintox: 0.902929 val loss: 1.175379
[Epoch 82] ogbg-molclintox: 0.835526 test loss: 0.257593
[Epoch 83; Iter    10/   35] train: loss: 0.0352365
[Epoch 83] ogbg-molclintox: 0.888224 val loss: 2.359221
[Epoch 83] ogbg-molclintox: 0.802477 test loss: 0.293784
[Epoch 84; Iter     5/   35] train: loss: 0.0105481
[Epoch 84; Iter    35/   35] train: loss: 0.0176560
[Epoch 84] ogbg-molclintox: 0.898458 val loss: 0.507988
[Epoch 84] ogbg-molclintox: 0.834907 test loss: 0.299739
[Epoch 85; Iter    30/   35] train: loss: 0.0300415
[Epoch 85] ogbg-molclintox: 0.898333 val loss: 1.794339
[Epoch 85] ogbg-molclintox: 0.852065 test loss: 0.261623
[Epoch 86; Iter    25/   35] train: loss: 0.0770954
[Epoch 86] ogbg-molclintox: 0.895071 val loss: 0.676681
[Epoch 86] ogbg-molclintox: 0.848947 test loss: 0.282815
[Epoch 87; Iter    20/   35] train: loss: 0.0366341
[Epoch 87] ogbg-molclintox: 0.867492 val loss: 0.241317
[Epoch 87] ogbg-molclintox: 0.788669 test loss: 0.306812
[Epoch 88; Iter    15/   35] train: loss: 0.0354552
[Epoch 88] ogbg-molclintox: 0.867167 val loss: 0.749366
[Epoch 88] ogbg-molclintox: 0.817091 test loss: 0.283073
[Epoch 89; Iter    10/   35] train: loss: 0.0194158
[Epoch 89] ogbg-molclintox: 0.895892 val loss: 0.809124
[Epoch 89] ogbg-molclintox: 0.823129 test loss: 0.292559
[Epoch 90; Iter     5/   35] train: loss: 0.0244351
[Epoch 90; Iter    35/   35] train: loss: 0.1374241
[Epoch 90] ogbg-molclintox: 0.860093 val loss: 0.289117
[Epoch 90] ogbg-molclintox: 0.805499 test loss: 0.361954
[Epoch 91; Iter    30/   35] train: loss: 0.0212275
[Epoch 91] ogbg-molclintox: 0.890863 val loss: 0.201893
[Epoch 91] ogbg-molclintox: 0.840516 test loss: 0.296072
[Epoch 92; Iter    25/   35] train: loss: 0.0695740
[Epoch 92] ogbg-molclintox: 0.894297 val loss: 0.252660
[Epoch 92] ogbg-molclintox: 0.832641 test loss: 0.323189
[Epoch 93; Iter    20/   35] train: loss: 0.0442615
[Epoch 93] ogbg-molclintox: 0.898471 val loss: 0.592854
[Epoch 93] ogbg-molclintox: 0.792812 test loss: 0.326446
[Epoch 94; Iter    15/   35] train: loss: 0.0790263
[Epoch 94] ogbg-molclintox: 0.857561 val loss: 0.221972
[Epoch 94] ogbg-molclintox: 0.761594 test loss: 0.378262
[Epoch 95; Iter    10/   35] train: loss: 0.0453641
[Epoch 95] ogbg-molclintox: 0.909779 val loss: 0.195415
[Epoch 95] ogbg-molclintox: 0.808889 test loss: 0.321592
[Epoch 96; Iter     5/   35] train: loss: 0.0111391
[Epoch 96; Iter    35/   35] train: loss: 0.0030011
[Epoch 96] ogbg-molclintox: 0.910019 val loss: 0.649138
[Epoch 96] ogbg-molclintox: 0.804391 test loss: 0.322834
[Epoch 97; Iter    30/   35] train: loss: 0.0402874
[Epoch 97] ogbg-molclintox: 0.898212 val loss: 1.101636
[Epoch 97] ogbg-molclintox: 0.788389 test loss: 0.322663
[Epoch 98; Iter    25/   35] train: loss: 0.2670842
[Epoch 98] ogbg-molclintox: 0.926665 val loss: 0.407960
[Epoch 98] ogbg-molclintox: 0.817624 test loss: 0.310267
[Epoch 99; Iter    20/   35] train: loss: 0.0208851
[Epoch 99] ogbg-molclintox: 0.864249 val loss: 0.871676
[Epoch 99] ogbg-molclintox: 0.683855 test loss: 0.357368
[Epoch 100; Iter    15/   35] train: loss: 0.0127022
[Epoch 100] ogbg-molclintox: 0.900241 val loss: 0.421565
[Epoch 100] ogbg-molclintox: 0.812093 test loss: 0.358064
[Epoch 101; Iter    10/   35] train: loss: 0.0292295
[Epoch 101] ogbg-molclintox: 0.888225 val loss: 0.908274
[Epoch 101] ogbg-molclintox: 0.799762 test loss: 0.337830
[Epoch 102; Iter     5/   35] train: loss: 0.0475319
[Epoch 102; Iter    35/   35] train: loss: 0.0137754
[Epoch 102] ogbg-molclintox: 0.884925 val loss: 0.821853
[Epoch 102] ogbg-molclintox: 0.756839 test loss: 0.391619
[Epoch 103; Iter    30/   35] train: loss: 0.0038903
[Epoch 103] ogbg-molclintox: 0.881781 val loss: 0.633076
[Epoch 103] ogbg-molclintox: 0.772939 test loss: 0.316894
[Epoch 104; Iter    25/   35] train: loss: 0.0144028
[Epoch 104] ogbg-molclintox: 0.882393 val loss: 0.401199
[Epoch 104] ogbg-molclintox: 0.829346 test loss: 0.397045
[Epoch 105; Iter    20/   35] train: loss: 0.0438019
[Epoch 105] ogbg-molclintox: 0.916388 val loss: 0.271295
[Epoch 105] ogbg-molclintox: 0.864341 test loss: 0.308074
[Epoch 106; Iter    15/   35] train: loss: 0.0180150
[Epoch 106] ogbg-molclintox: 0.915826 val loss: 0.347808
[Epoch 106] ogbg-molclintox: 0.860715 test loss: 0.319837
[Epoch 107; Iter    10/   35] train: loss: 0.0226792
[Epoch 107] ogbg-molclintox: 0.914424 val loss: 0.262526
[Epoch 107] ogbg-molclintox: 0.834437 test loss: 0.326374
[Epoch 108; Iter     5/   35] train: loss: 0.0080685
[Epoch 108; Iter    35/   35] train: loss: 0.0681345
[Epoch 108] ogbg-molclintox: 0.899635 val loss: 1.331523
[Epoch 108] ogbg-molclintox: 0.793443 test loss: 0.409490
[Epoch 109; Iter    30/   35] train: loss: 0.0250593
[Epoch 109] ogbg-molclintox: 0.892933 val loss: 1.323229
[Epoch 109] ogbg-molclintox: 0.805692 test loss: 0.339598
[Epoch 110; Iter    25/   35] train: loss: 0.0053853
[Epoch 110] ogbg-molclintox: 0.861288 val loss: 1.307528
[Epoch 110] ogbg-molclintox: 0.819856 test loss: 0.402464
[Epoch 111; Iter    20/   35] train: loss: 0.0060870
[Epoch 111] ogbg-molclintox: 0.866203 val loss: 0.762846
[Epoch 111] ogbg-molclintox: 0.803465 test loss: 0.357468
[Epoch 112; Iter    15/   35] train: loss: 0.0110957
[Epoch 112] ogbg-molclintox: 0.882924 val loss: 0.974428
[Epoch 112] ogbg-molclintox: 0.824527 test loss: 0.333081
[Epoch 113; Iter    10/   35] train: loss: 0.0105597
[Epoch 113] ogbg-molclintox: 0.872053 val loss: 0.587964
[Epoch 113] ogbg-molclintox: 0.820750 test loss: 0.346810
[Epoch 114; Iter     5/   35] train: loss: 0.0775575
[Epoch 114; Iter    35/   35] train: loss: 0.0118431
[Epoch 114] ogbg-molclintox: 0.885209 val loss: 0.294229
[Epoch 114] ogbg-molclintox: 0.819813 test loss: 0.341341
[Epoch 115; Iter    30/   35] train: loss: 0.0173446
[Epoch 115] ogbg-molclintox: 0.891696 val loss: 0.255062
[Epoch 115] ogbg-molclintox: 0.816996 test loss: 0.346577
[Epoch 116; Iter    25/   35] train: loss: 0.0096088
[Epoch 116] ogbg-molclintox: 0.874005 val loss: 0.322927
[Epoch 116] ogbg-molclintox: 0.807790 test loss: 0.363562
[Epoch 117; Iter    20/   35] train: loss: 0.0034977
[Epoch 117] ogbg-molclintox: 0.849800 val loss: 0.383181
[Epoch 117] ogbg-molclintox: 0.790335 test loss: 0.372101
[Epoch 118; Iter    15/   35] train: loss: 0.0634585
[Epoch 118] ogbg-molclintox: 0.864795 val loss: 0.280167
[Epoch 118] ogbg-molclintox: 0.809421 test loss: 0.364158
[Epoch 119; Iter    10/   35] train: loss: 0.0062230
[Epoch 119] ogbg-molclintox: 0.869400 val loss: 0.653223
[Epoch 119] ogbg-molclintox: 0.826416 test loss: 0.348420
[Epoch 120; Iter     5/   35] train: loss: 0.0546110
[Epoch 120; Iter    35/   35] train: loss: 0.0041792
[Epoch 120] ogbg-molclintox: 0.884657 val loss: 0.247237
[Epoch 120] ogbg-molclintox: 0.817845 test loss: 0.375953
[Epoch 121; Iter    30/   35] train: loss: 0.0021733
[Epoch 121] ogbg-molclintox: 0.866646 val loss: 0.597935
[Epoch 121] ogbg-molclintox: 0.772905 test loss: 0.386647
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 121 epochs. Best model checkpoint was in epoch 61.
Statistics on  val_best_checkpoint
mean_pred: 0.2151566743850708
std_pred: 4.81891393661499
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.8732706673310047
rocauc: 0.9641847341047578
ogbg-molclintox: 0.9641847341047578
OGBNanLabelBCEWithLogitsLoss: 0.09997421316802502
Statistics on  test
mean_pred: 0.20502042770385742
std_pred: 4.79175329208374
mean_targets: 0.5090090036392212
std_targets: 0.5004827976226807
prcauc: 0.6559656905610844
rocauc: 0.8072816217675067
ogbg-molclintox: 0.8072816217675067
OGBNanLabelBCEWithLogitsLoss: 0.19465575693175197
Statistics on  train
mean_pred: 0.20111365616321564
std_pred: 4.876176834106445
mean_targets: 0.5053243041038513
std_targets: 0.5000926852226257
prcauc: 0.9404984544651731
rocauc: 0.9840994813362658
ogbg-molclintox: 0.9840994813362658
OGBNanLabelBCEWithLogitsLoss: 0.08863487845020634
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.0917888
[Epoch 84] ogbg-molclintox: 0.813966 val loss: 0.327234
[Epoch 84] ogbg-molclintox: 0.803848 test loss: 0.258876
[Epoch 85; Iter    30/   30] train: loss: 0.0928056
[Epoch 85] ogbg-molclintox: 0.784016 val loss: 0.263179
[Epoch 85] ogbg-molclintox: 0.791680 test loss: 0.298991
[Epoch 86; Iter    30/   30] train: loss: 0.0808870
[Epoch 86] ogbg-molclintox: 0.808951 val loss: 0.252953
[Epoch 86] ogbg-molclintox: 0.821180 test loss: 0.292684
[Epoch 87; Iter    30/   30] train: loss: 0.0057324
[Epoch 87] ogbg-molclintox: 0.772298 val loss: 1.497021
[Epoch 87] ogbg-molclintox: 0.782816 test loss: 0.279461
[Epoch 88; Iter    30/   30] train: loss: 0.0209160
[Epoch 88] ogbg-molclintox: 0.797035 val loss: 0.807936
[Epoch 88] ogbg-molclintox: 0.762532 test loss: 0.326805
[Epoch 89; Iter    30/   30] train: loss: 0.0057309
[Epoch 89] ogbg-molclintox: 0.743921 val loss: 0.357372
[Epoch 89] ogbg-molclintox: 0.771489 test loss: 0.274857
[Epoch 90; Iter    30/   30] train: loss: 0.2518289
[Epoch 90] ogbg-molclintox: 0.847154 val loss: 0.983933
[Epoch 90] ogbg-molclintox: 0.835403 test loss: 0.252392
[Epoch 91; Iter    30/   30] train: loss: 0.0248998
[Epoch 91] ogbg-molclintox: 0.816589 val loss: 0.543118
[Epoch 91] ogbg-molclintox: 0.877120 test loss: 0.212459
[Epoch 92; Iter    30/   30] train: loss: 0.0139998
[Epoch 92] ogbg-molclintox: 0.813700 val loss: 0.490463
[Epoch 92] ogbg-molclintox: 0.842525 test loss: 0.303401
[Epoch 93; Iter    30/   30] train: loss: 0.0171431
[Epoch 93] ogbg-molclintox: 0.831309 val loss: 0.589545
[Epoch 93] ogbg-molclintox: 0.834921 test loss: 0.283612
[Epoch 94; Iter    30/   30] train: loss: 0.0467434
[Epoch 94] ogbg-molclintox: 0.813546 val loss: 0.402065
[Epoch 94] ogbg-molclintox: 0.803736 test loss: 0.289546
[Epoch 95; Iter    30/   30] train: loss: 0.0798160
[Epoch 95] ogbg-molclintox: 0.806994 val loss: 0.329764
[Epoch 95] ogbg-molclintox: 0.822143 test loss: 0.285757
[Epoch 96; Iter    30/   30] train: loss: 0.0709455
[Epoch 96] ogbg-molclintox: 0.807366 val loss: 0.704067
[Epoch 96] ogbg-molclintox: 0.799801 test loss: 0.290272
[Epoch 97; Iter    30/   30] train: loss: 0.0028321
[Epoch 97] ogbg-molclintox: 0.793779 val loss: 0.601620
[Epoch 97] ogbg-molclintox: 0.815110 test loss: 0.279980
[Epoch 98; Iter    30/   30] train: loss: 0.0799830
[Epoch 98] ogbg-molclintox: 0.791408 val loss: 0.809573
[Epoch 98] ogbg-molclintox: 0.833356 test loss: 0.265877
[Epoch 99; Iter    30/   30] train: loss: 0.0696569
[Epoch 99] ogbg-molclintox: 0.781386 val loss: 0.225046
[Epoch 99] ogbg-molclintox: 0.779446 test loss: 0.306260
[Epoch 100; Iter    30/   30] train: loss: 0.0038736
[Epoch 100] ogbg-molclintox: 0.793892 val loss: 0.672695
[Epoch 100] ogbg-molclintox: 0.826749 test loss: 0.295551
[Epoch 101; Iter    30/   30] train: loss: 0.0959601
[Epoch 101] ogbg-molclintox: 0.806294 val loss: 0.629487
[Epoch 101] ogbg-molclintox: 0.848158 test loss: 0.258618
[Epoch 102; Iter    30/   30] train: loss: 0.2174108
[Epoch 102] ogbg-molclintox: 0.824122 val loss: 0.220656
[Epoch 102] ogbg-molclintox: 0.832595 test loss: 0.281415
[Epoch 103; Iter    30/   30] train: loss: 0.0733311
[Epoch 103] ogbg-molclintox: 0.747186 val loss: 0.651458
[Epoch 103] ogbg-molclintox: 0.804886 test loss: 0.296147
[Epoch 104; Iter    30/   30] train: loss: 0.0416030
[Epoch 104] ogbg-molclintox: 0.759127 val loss: 0.552530
[Epoch 104] ogbg-molclintox: 0.771839 test loss: 0.376117
[Epoch 105; Iter    30/   30] train: loss: 0.0732644
[Epoch 105] ogbg-molclintox: 0.723382 val loss: 0.605788
[Epoch 105] ogbg-molclintox: 0.790882 test loss: 0.302943
[Epoch 106; Iter    30/   30] train: loss: 0.0307061
[Epoch 106] ogbg-molclintox: 0.832240 val loss: 0.258189
[Epoch 106] ogbg-molclintox: 0.795061 test loss: 0.275219
[Epoch 107; Iter    30/   30] train: loss: 0.0065726
[Epoch 107] ogbg-molclintox: 0.812175 val loss: 0.395463
[Epoch 107] ogbg-molclintox: 0.833628 test loss: 0.274802
[Epoch 108; Iter    30/   30] train: loss: 0.0123376
[Epoch 108] ogbg-molclintox: 0.784891 val loss: 0.274207
[Epoch 108] ogbg-molclintox: 0.809939 test loss: 0.308161
[Epoch 109; Iter    30/   30] train: loss: 0.0135217
[Epoch 109] ogbg-molclintox: 0.773090 val loss: 0.640430
[Epoch 109] ogbg-molclintox: 0.786588 test loss: 0.325274
[Epoch 110; Iter    30/   30] train: loss: 0.0035005
[Epoch 110] ogbg-molclintox: 0.783184 val loss: 0.490001
[Epoch 110] ogbg-molclintox: 0.783755 test loss: 0.340324
[Epoch 111; Iter    30/   30] train: loss: 0.0030828
[Epoch 111] ogbg-molclintox: 0.776826 val loss: 0.344794
[Epoch 111] ogbg-molclintox: 0.794196 test loss: 0.291551
[Epoch 112; Iter    30/   30] train: loss: 0.0016759
[Epoch 112] ogbg-molclintox: 0.791739 val loss: 0.353906
[Epoch 112] ogbg-molclintox: 0.808366 test loss: 0.310624
[Epoch 113; Iter    30/   30] train: loss: 0.0021378
[Epoch 113] ogbg-molclintox: 0.797610 val loss: 1.276025
[Epoch 113] ogbg-molclintox: 0.822152 test loss: 0.286322
[Epoch 114; Iter    30/   30] train: loss: 0.0011947
[Epoch 114] ogbg-molclintox: 0.748044 val loss: 0.512395
[Epoch 114] ogbg-molclintox: 0.798188 test loss: 0.315398
[Epoch 115; Iter    30/   30] train: loss: 0.0606649
[Epoch 115] ogbg-molclintox: 0.756408 val loss: 0.469588
[Epoch 115] ogbg-molclintox: 0.822904 test loss: 0.282232
[Epoch 116; Iter    30/   30] train: loss: 0.0586993
[Epoch 116] ogbg-molclintox: 0.769763 val loss: 0.712822
[Epoch 116] ogbg-molclintox: 0.798416 test loss: 0.343061
[Epoch 117; Iter    30/   30] train: loss: 0.0084979
[Epoch 117] ogbg-molclintox: 0.763890 val loss: 0.392732
[Epoch 117] ogbg-molclintox: 0.842108 test loss: 0.295574
[Epoch 118; Iter    30/   30] train: loss: 0.0045793
[Epoch 118] ogbg-molclintox: 0.745041 val loss: 0.609219
[Epoch 118] ogbg-molclintox: 0.791614 test loss: 0.306708
[Epoch 119; Iter    30/   30] train: loss: 0.0423778
[Epoch 119] ogbg-molclintox: 0.699689 val loss: 0.302265
[Epoch 119] ogbg-molclintox: 0.774754 test loss: 0.329334
[Epoch 120; Iter    30/   30] train: loss: 0.0094517
[Epoch 120] ogbg-molclintox: 0.814748 val loss: 0.264952
[Epoch 120] ogbg-molclintox: 0.858368 test loss: 0.271357
[Epoch 121; Iter    30/   30] train: loss: 0.0157569
[Epoch 121] ogbg-molclintox: 0.802306 val loss: 0.326937
[Epoch 121] ogbg-molclintox: 0.833428 test loss: 0.330443
[Epoch 122; Iter    30/   30] train: loss: 0.0031306
[Epoch 122] ogbg-molclintox: 0.703323 val loss: 0.283463
[Epoch 122] ogbg-molclintox: 0.794033 test loss: 0.342701
[Epoch 123; Iter    30/   30] train: loss: 0.1055909
[Epoch 123] ogbg-molclintox: 0.799906 val loss: 0.239233
[Epoch 123] ogbg-molclintox: 0.841910 test loss: 0.269740
[Epoch 124; Iter    30/   30] train: loss: 0.0040870
[Epoch 124] ogbg-molclintox: 0.707376 val loss: 0.916223
[Epoch 124] ogbg-molclintox: 0.793067 test loss: 0.294050
[Epoch 125; Iter    30/   30] train: loss: 0.0114493
[Epoch 125] ogbg-molclintox: 0.718038 val loss: 0.334641
[Epoch 125] ogbg-molclintox: 0.827685 test loss: 0.307085
[Epoch 126; Iter    30/   30] train: loss: 0.0449846
[Epoch 126] ogbg-molclintox: 0.786148 val loss: 0.346703
[Epoch 126] ogbg-molclintox: 0.780169 test loss: 0.345732
[Epoch 127; Iter    30/   30] train: loss: 0.0736743
[Epoch 127] ogbg-molclintox: 0.779108 val loss: 0.252016
[Epoch 127] ogbg-molclintox: 0.872248 test loss: 0.256054
[Epoch 128; Iter    30/   30] train: loss: 0.0488234
[Epoch 128] ogbg-molclintox: 0.799685 val loss: 0.440357
[Epoch 128] ogbg-molclintox: 0.855335 test loss: 0.562095
[Epoch 129; Iter    30/   30] train: loss: 0.2543620
[Epoch 129] ogbg-molclintox: 0.814885 val loss: 0.388609
[Epoch 129] ogbg-molclintox: 0.883664 test loss: 0.303134
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 129 epochs. Best model checkpoint was in epoch 69.
Statistics on  val_best_checkpoint
mean_pred: 0.1573951095342636
std_pred: 6.816168785095215
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.6672780861923117
rocauc: 0.8899945313814572
ogbg-molclintox: 0.8899945313814572
OGBNanLabelBCEWithLogitsLoss: 0.3865229917690158
Statistics on  test
mean_pred: 0.16913501918315887
std_pred: 5.941636562347412
mean_targets: 0.5101351737976074
std_targets: 0.5003200173377991
prcauc: 0.6907368995775092
rocauc: 0.8592763354127928
ogbg-molclintox: 0.8592763354127928
OGBNanLabelBCEWithLogitsLoss: 0.24687626883387565
Statistics on  train
mean_pred: 0.1609053611755371
std_pred: 6.067757606506348
mean_targets: 0.5050790309906006
std_targets: 0.5001153349876404
prcauc: 0.9787562488423736
rocauc: 0.9968647726050388
ogbg-molclintox: 0.9968647726050388
OGBNanLabelBCEWithLogitsLoss: 0.04582062461413443
All runs completed.
[Epoch 76] ogbg-molclintox: 0.888490 val loss: 0.171743
[Epoch 76] ogbg-molclintox: 0.795958 test loss: 0.284154
[Epoch 77; Iter    20/   40] train: loss: 0.0603694
[Epoch 77] ogbg-molclintox: 0.922871 val loss: 0.178538
[Epoch 77] ogbg-molclintox: 0.831460 test loss: 0.264007
[Epoch 78; Iter    10/   40] train: loss: 0.0669460
[Epoch 78; Iter    40/   40] train: loss: 0.0125240
[Epoch 78] ogbg-molclintox: 0.930157 val loss: 0.175463
[Epoch 78] ogbg-molclintox: 0.794739 test loss: 0.282339
[Epoch 79; Iter    30/   40] train: loss: 0.0120972
[Epoch 79] ogbg-molclintox: 0.879150 val loss: 0.200596
[Epoch 79] ogbg-molclintox: 0.812777 test loss: 0.289655
[Epoch 80; Iter    20/   40] train: loss: 0.0060845
[Epoch 80] ogbg-molclintox: 0.917314 val loss: 0.171170
[Epoch 80] ogbg-molclintox: 0.816957 test loss: 0.265585
[Epoch 81; Iter    10/   40] train: loss: 0.0461259
[Epoch 81; Iter    40/   40] train: loss: 0.0071808
[Epoch 81] ogbg-molclintox: 0.900411 val loss: 0.177480
[Epoch 81] ogbg-molclintox: 0.829439 test loss: 0.272621
[Epoch 82; Iter    30/   40] train: loss: 0.1127756
[Epoch 82] ogbg-molclintox: 0.911361 val loss: 0.186449
[Epoch 82] ogbg-molclintox: 0.807031 test loss: 0.293658
[Epoch 83; Iter    20/   40] train: loss: 0.0355309
[Epoch 83] ogbg-molclintox: 0.917648 val loss: 0.172214
[Epoch 83] ogbg-molclintox: 0.769046 test loss: 0.303049
[Epoch 84; Iter    10/   40] train: loss: 0.0108984
[Epoch 84; Iter    40/   40] train: loss: 0.0130799
[Epoch 84] ogbg-molclintox: 0.897760 val loss: 0.191401
[Epoch 84] ogbg-molclintox: 0.767692 test loss: 0.311404
[Epoch 85; Iter    30/   40] train: loss: 0.0266305
[Epoch 85] ogbg-molclintox: 0.932768 val loss: 0.174515
[Epoch 85] ogbg-molclintox: 0.804910 test loss: 0.285599
[Epoch 86; Iter    20/   40] train: loss: 0.0365295
[Epoch 86] ogbg-molclintox: 0.924670 val loss: 0.173298
[Epoch 86] ogbg-molclintox: 0.746043 test loss: 0.315632
[Epoch 87; Iter    10/   40] train: loss: 0.0433693
[Epoch 87; Iter    40/   40] train: loss: 0.0385948
[Epoch 87] ogbg-molclintox: 0.917530 val loss: 0.164816
[Epoch 87] ogbg-molclintox: 0.777389 test loss: 0.296824
[Epoch 88; Iter    30/   40] train: loss: 0.0029820
[Epoch 88] ogbg-molclintox: 0.902678 val loss: 0.185606
[Epoch 88] ogbg-molclintox: 0.718629 test loss: 0.326151
[Epoch 89; Iter    20/   40] train: loss: 0.0038181
[Epoch 89] ogbg-molclintox: 0.917356 val loss: 0.176712
[Epoch 89] ogbg-molclintox: 0.754157 test loss: 0.311039
[Epoch 90; Iter    10/   40] train: loss: 0.0438842
[Epoch 90; Iter    40/   40] train: loss: 0.0054090
[Epoch 90] ogbg-molclintox: 0.920046 val loss: 0.182169
[Epoch 90] ogbg-molclintox: 0.750740 test loss: 0.339268
[Epoch 91; Iter    30/   40] train: loss: 0.0546964
[Epoch 91] ogbg-molclintox: 0.890460 val loss: 0.196480
[Epoch 91] ogbg-molclintox: 0.744219 test loss: 0.326305
[Epoch 92; Iter    20/   40] train: loss: 0.0418856
[Epoch 92] ogbg-molclintox: 0.911560 val loss: 0.178618
[Epoch 92] ogbg-molclintox: 0.800750 test loss: 0.291597
[Epoch 93; Iter    10/   40] train: loss: 0.0051216
[Epoch 93; Iter    40/   40] train: loss: 0.0030930
[Epoch 93] ogbg-molclintox: 0.898440 val loss: 0.182324
[Epoch 93] ogbg-molclintox: 0.743389 test loss: 0.329587
[Epoch 94; Iter    30/   40] train: loss: 0.0196253
[Epoch 94] ogbg-molclintox: 0.934060 val loss: 0.177625
[Epoch 94] ogbg-molclintox: 0.720616 test loss: 0.321540
[Epoch 95; Iter    20/   40] train: loss: 0.0119256
[Epoch 95] ogbg-molclintox: 0.921180 val loss: 0.178023
[Epoch 95] ogbg-molclintox: 0.716200 test loss: 0.357792
[Epoch 96; Iter    10/   40] train: loss: 0.0553671
[Epoch 96; Iter    40/   40] train: loss: 0.1076316
[Epoch 96] ogbg-molclintox: 0.916810 val loss: 0.177766
[Epoch 96] ogbg-molclintox: 0.697077 test loss: 0.347905
[Epoch 97; Iter    30/   40] train: loss: 0.0790403
[Epoch 97] ogbg-molclintox: 0.920686 val loss: 0.199547
[Epoch 97] ogbg-molclintox: 0.707552 test loss: 0.358467
[Epoch 98; Iter    20/   40] train: loss: 0.0296681
[Epoch 98] ogbg-molclintox: 0.915504 val loss: 0.199148
[Epoch 98] ogbg-molclintox: 0.745776 test loss: 0.345045
[Epoch 99; Iter    10/   40] train: loss: 0.0027406
[Epoch 99; Iter    40/   40] train: loss: 0.0943659
[Epoch 99] ogbg-molclintox: 0.930116 val loss: 0.196545
[Epoch 99] ogbg-molclintox: 0.790387 test loss: 0.315152
[Epoch 100; Iter    30/   40] train: loss: 0.0092304
[Epoch 100] ogbg-molclintox: 0.927253 val loss: 0.188813
[Epoch 100] ogbg-molclintox: 0.736383 test loss: 0.342896
[Epoch 101; Iter    20/   40] train: loss: 0.0035392
[Epoch 101] ogbg-molclintox: 0.899627 val loss: 0.172325
[Epoch 101] ogbg-molclintox: 0.750744 test loss: 0.329688
[Epoch 102; Iter    10/   40] train: loss: 0.0044702
[Epoch 102; Iter    40/   40] train: loss: 0.0033061
[Epoch 102] ogbg-molclintox: 0.917835 val loss: 0.201629
[Epoch 102] ogbg-molclintox: 0.813145 test loss: 0.290466
[Epoch 103; Iter    30/   40] train: loss: 0.0204384
[Epoch 103] ogbg-molclintox: 0.918182 val loss: 0.189545
[Epoch 103] ogbg-molclintox: 0.773571 test loss: 0.293073
[Epoch 104; Iter    20/   40] train: loss: 0.0021587
[Epoch 104] ogbg-molclintox: 0.949206 val loss: 0.183409
[Epoch 104] ogbg-molclintox: 0.770488 test loss: 0.325564
[Epoch 105; Iter    10/   40] train: loss: 0.0583563
[Epoch 105; Iter    40/   40] train: loss: 0.0033832
[Epoch 105] ogbg-molclintox: 0.915623 val loss: 0.211828
[Epoch 105] ogbg-molclintox: 0.827129 test loss: 0.318044
[Epoch 106; Iter    30/   40] train: loss: 0.0334998
[Epoch 106] ogbg-molclintox: 0.935259 val loss: 0.197617
[Epoch 106] ogbg-molclintox: 0.761861 test loss: 0.327081
[Epoch 107; Iter    20/   40] train: loss: 0.0035938
[Epoch 107] ogbg-molclintox: 0.939881 val loss: 0.201202
[Epoch 107] ogbg-molclintox: 0.749181 test loss: 0.338994
[Epoch 108; Iter    10/   40] train: loss: 0.0152962
[Epoch 108; Iter    40/   40] train: loss: 0.4293302
[Epoch 108] ogbg-molclintox: 0.938069 val loss: 0.181959
[Epoch 108] ogbg-molclintox: 0.749500 test loss: 0.328684
[Epoch 109; Iter    30/   40] train: loss: 0.0442027
[Epoch 109] ogbg-molclintox: 0.945850 val loss: 0.164229
[Epoch 109] ogbg-molclintox: 0.720272 test loss: 0.341838
[Epoch 110; Iter    20/   40] train: loss: 0.0110780
[Epoch 110] ogbg-molclintox: 0.951204 val loss: 0.179216
[Epoch 110] ogbg-molclintox: 0.738919 test loss: 0.361780
[Epoch 111; Iter    10/   40] train: loss: 0.0112388
[Epoch 111; Iter    40/   40] train: loss: 0.0043233
[Epoch 111] ogbg-molclintox: 0.950484 val loss: 0.183136
[Epoch 111] ogbg-molclintox: 0.782505 test loss: 0.324935
[Epoch 112; Iter    30/   40] train: loss: 0.0171860
[Epoch 112] ogbg-molclintox: 0.940908 val loss: 0.184214
[Epoch 112] ogbg-molclintox: 0.745863 test loss: 0.345627
[Epoch 113; Iter    20/   40] train: loss: 0.0014977
[Epoch 113] ogbg-molclintox: 0.947435 val loss: 0.175219
[Epoch 113] ogbg-molclintox: 0.741513 test loss: 0.340816
[Epoch 114; Iter    10/   40] train: loss: 0.0027985
[Epoch 114; Iter    40/   40] train: loss: 0.1525212
[Epoch 114] ogbg-molclintox: 0.962461 val loss: 0.165045
[Epoch 114] ogbg-molclintox: 0.735058 test loss: 0.354320
[Epoch 115; Iter    30/   40] train: loss: 0.0018950
[Epoch 115] ogbg-molclintox: 0.948461 val loss: 0.160938
[Epoch 115] ogbg-molclintox: 0.698929 test loss: 0.383243
[Epoch 116; Iter    20/   40] train: loss: 0.0812979
[Epoch 116] ogbg-molclintox: 0.945290 val loss: 0.178608
[Epoch 116] ogbg-molclintox: 0.719470 test loss: 0.364285
[Epoch 117; Iter    10/   40] train: loss: 0.0322856
[Epoch 117; Iter    40/   40] train: loss: 0.0127123
[Epoch 117] ogbg-molclintox: 0.946250 val loss: 0.183147
[Epoch 117] ogbg-molclintox: 0.742988 test loss: 0.357939
[Epoch 118; Iter    30/   40] train: loss: 0.0704210
[Epoch 118] ogbg-molclintox: 0.948274 val loss: 0.174110
[Epoch 118] ogbg-molclintox: 0.725527 test loss: 0.355028
[Epoch 119; Iter    20/   40] train: loss: 0.0014746
[Epoch 119] ogbg-molclintox: 0.950632 val loss: 0.173890
[Epoch 119] ogbg-molclintox: 0.756758 test loss: 0.348086
[Epoch 120; Iter    10/   40] train: loss: 0.0189719
[Epoch 120; Iter    40/   40] train: loss: 0.0027519
[Epoch 120] ogbg-molclintox: 0.941534 val loss: 0.182479
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 76] ogbg-molclintox: 0.940467 val loss: 0.182236
[Epoch 76] ogbg-molclintox: 0.760221 test loss: 0.298158
[Epoch 77; Iter    20/   40] train: loss: 0.0591513
[Epoch 77] ogbg-molclintox: 0.896722 val loss: 0.206206
[Epoch 77] ogbg-molclintox: 0.712394 test loss: 0.333981
[Epoch 78; Iter    10/   40] train: loss: 0.0053202
[Epoch 78; Iter    40/   40] train: loss: 0.0042302
[Epoch 78] ogbg-molclintox: 0.912067 val loss: 0.197630
[Epoch 78] ogbg-molclintox: 0.773939 test loss: 0.290234
[Epoch 79; Iter    30/   40] train: loss: 0.0921697
[Epoch 79] ogbg-molclintox: 0.928785 val loss: 0.196847
[Epoch 79] ogbg-molclintox: 0.738299 test loss: 0.319138
[Epoch 80; Iter    20/   40] train: loss: 0.0549854
[Epoch 80] ogbg-molclintox: 0.933194 val loss: 0.173828
[Epoch 80] ogbg-molclintox: 0.795277 test loss: 0.271449
[Epoch 81; Iter    10/   40] train: loss: 0.0882468
[Epoch 81; Iter    40/   40] train: loss: 0.0230291
[Epoch 81] ogbg-molclintox: 0.913986 val loss: 0.202878
[Epoch 81] ogbg-molclintox: 0.771948 test loss: 0.310386
[Epoch 82; Iter    30/   40] train: loss: 0.0278311
[Epoch 82] ogbg-molclintox: 0.933914 val loss: 0.195090
[Epoch 82] ogbg-molclintox: 0.768697 test loss: 0.326655
[Epoch 83; Iter    20/   40] train: loss: 0.0454920
[Epoch 83] ogbg-molclintox: 0.937430 val loss: 0.177093
[Epoch 83] ogbg-molclintox: 0.764932 test loss: 0.305629
[Epoch 84; Iter    10/   40] train: loss: 0.0449440
[Epoch 84; Iter    40/   40] train: loss: 0.0378050
[Epoch 84] ogbg-molclintox: 0.908337 val loss: 0.202264
[Epoch 84] ogbg-molclintox: 0.731542 test loss: 0.328488
[Epoch 85; Iter    30/   40] train: loss: 0.0445022
[Epoch 85] ogbg-molclintox: 0.926227 val loss: 0.190248
[Epoch 85] ogbg-molclintox: 0.767822 test loss: 0.323184
[Epoch 86; Iter    20/   40] train: loss: 0.0456798
[Epoch 86] ogbg-molclintox: 0.888289 val loss: 0.241776
[Epoch 86] ogbg-molclintox: 0.742196 test loss: 0.361619
[Epoch 87; Iter    10/   40] train: loss: 0.1541327
[Epoch 87; Iter    40/   40] train: loss: 0.0531509
[Epoch 87] ogbg-molclintox: 0.924163 val loss: 0.181986
[Epoch 87] ogbg-molclintox: 0.740872 test loss: 0.299799
[Epoch 88; Iter    30/   40] train: loss: 0.0038957
[Epoch 88] ogbg-molclintox: 0.933087 val loss: 0.206673
[Epoch 88] ogbg-molclintox: 0.828366 test loss: 0.300445
[Epoch 89; Iter    20/   40] train: loss: 0.1043338
[Epoch 89] ogbg-molclintox: 0.901397 val loss: 0.215745
[Epoch 89] ogbg-molclintox: 0.750527 test loss: 0.311859
[Epoch 90; Iter    10/   40] train: loss: 0.0478700
[Epoch 90; Iter    40/   40] train: loss: 0.0111051
[Epoch 90] ogbg-molclintox: 0.903141 val loss: 0.220966
[Epoch 90] ogbg-molclintox: 0.764800 test loss: 0.295576
[Epoch 91; Iter    30/   40] train: loss: 0.0097785
[Epoch 91] ogbg-molclintox: 0.896295 val loss: 0.234525
[Epoch 91] ogbg-molclintox: 0.730239 test loss: 0.327956
[Epoch 92; Iter    20/   40] train: loss: 0.0034020
[Epoch 92] ogbg-molclintox: 0.925107 val loss: 0.193710
[Epoch 92] ogbg-molclintox: 0.785944 test loss: 0.307506
[Epoch 93; Iter    10/   40] train: loss: 0.0069370
[Epoch 93; Iter    40/   40] train: loss: 0.0022349
[Epoch 93] ogbg-molclintox: 0.910843 val loss: 0.211417
[Epoch 93] ogbg-molclintox: 0.742337 test loss: 0.350683
[Epoch 94; Iter    30/   40] train: loss: 0.2102582
[Epoch 94] ogbg-molclintox: 0.924202 val loss: 0.207943
[Epoch 94] ogbg-molclintox: 0.757711 test loss: 0.343570
[Epoch 95; Iter    20/   40] train: loss: 0.0146196
[Epoch 95] ogbg-molclintox: 0.913454 val loss: 0.189387
[Epoch 95] ogbg-molclintox: 0.720418 test loss: 0.349160
[Epoch 96; Iter    10/   40] train: loss: 0.0675416
[Epoch 96; Iter    40/   40] train: loss: 0.1419693
[Epoch 96] ogbg-molclintox: 0.934074 val loss: 0.190506
[Epoch 96] ogbg-molclintox: 0.812874 test loss: 0.313317
[Epoch 97; Iter    30/   40] train: loss: 0.0689766
[Epoch 97] ogbg-molclintox: 0.944850 val loss: 0.185782
[Epoch 97] ogbg-molclintox: 0.828918 test loss: 0.301352
[Epoch 98; Iter    20/   40] train: loss: 0.0074285
[Epoch 98] ogbg-molclintox: 0.923043 val loss: 0.202339
[Epoch 98] ogbg-molclintox: 0.786822 test loss: 0.304430
[Epoch 99; Iter    10/   40] train: loss: 0.0768520
[Epoch 99; Iter    40/   40] train: loss: 0.0032338
[Epoch 99] ogbg-molclintox: 0.914958 val loss: 0.215980
[Epoch 99] ogbg-molclintox: 0.738546 test loss: 0.334722
[Epoch 100; Iter    30/   40] train: loss: 0.0102248
[Epoch 100] ogbg-molclintox: 0.932741 val loss: 0.196544
[Epoch 100] ogbg-molclintox: 0.763569 test loss: 0.332635
[Epoch 101; Iter    20/   40] train: loss: 0.0024092
[Epoch 101] ogbg-molclintox: 0.909297 val loss: 0.205487
[Epoch 101] ogbg-molclintox: 0.717932 test loss: 0.340950
[Epoch 102; Iter    10/   40] train: loss: 0.0041325
[Epoch 102; Iter    40/   40] train: loss: 0.0018493
[Epoch 102] ogbg-molclintox: 0.915637 val loss: 0.217109
[Epoch 102] ogbg-molclintox: 0.725714 test loss: 0.357617
[Epoch 103; Iter    30/   40] train: loss: 0.0089169
[Epoch 103] ogbg-molclintox: 0.928919 val loss: 0.196310
[Epoch 103] ogbg-molclintox: 0.772153 test loss: 0.326686
[Epoch 104; Iter    20/   40] train: loss: 0.0068037
[Epoch 104] ogbg-molclintox: 0.928079 val loss: 0.203119
[Epoch 104] ogbg-molclintox: 0.790462 test loss: 0.322962
[Epoch 105; Iter    10/   40] train: loss: 0.0148842
[Epoch 105; Iter    40/   40] train: loss: 0.0047359
[Epoch 105] ogbg-molclintox: 0.924122 val loss: 0.204023
[Epoch 105] ogbg-molclintox: 0.769819 test loss: 0.316928
[Epoch 106; Iter    30/   40] train: loss: 0.0026172
[Epoch 106] ogbg-molclintox: 0.931423 val loss: 0.217501
[Epoch 106] ogbg-molclintox: 0.795337 test loss: 0.345237
[Epoch 107; Iter    20/   40] train: loss: 0.0066797
[Epoch 107] ogbg-molclintox: 0.953442 val loss: 0.178557
[Epoch 107] ogbg-molclintox: 0.788406 test loss: 0.295191
[Epoch 108; Iter    10/   40] train: loss: 0.0452967
[Epoch 108; Iter    40/   40] train: loss: 0.0087130
[Epoch 108] ogbg-molclintox: 0.942080 val loss: 0.181231
[Epoch 108] ogbg-molclintox: 0.746986 test loss: 0.336513
[Epoch 109; Iter    30/   40] train: loss: 0.0046390
[Epoch 109] ogbg-molclintox: 0.935086 val loss: 0.204340
[Epoch 109] ogbg-molclintox: 0.794544 test loss: 0.339867
[Epoch 110; Iter    20/   40] train: loss: 0.1570038
[Epoch 110] ogbg-molclintox: 0.928720 val loss: 0.181265
[Epoch 110] ogbg-molclintox: 0.803005 test loss: 0.300200
[Epoch 111; Iter    10/   40] train: loss: 0.0334594
[Epoch 111; Iter    40/   40] train: loss: 0.2848282
[Epoch 111] ogbg-molclintox: 0.938603 val loss: 0.218329
[Epoch 111] ogbg-molclintox: 0.800235 test loss: 0.352877
[Epoch 112; Iter    30/   40] train: loss: 0.0110896
[Epoch 112] ogbg-molclintox: 0.934407 val loss: 0.214109
[Epoch 112] ogbg-molclintox: 0.765711 test loss: 0.337591
[Epoch 113; Iter    20/   40] train: loss: 0.0264850
[Epoch 113] ogbg-molclintox: 0.911109 val loss: 0.228933
[Epoch 113] ogbg-molclintox: 0.755923 test loss: 0.342478
[Epoch 114; Iter    10/   40] train: loss: 0.0174392
[Epoch 114; Iter    40/   40] train: loss: 0.0067747
[Epoch 114] ogbg-molclintox: 0.934314 val loss: 0.227601
[Epoch 114] ogbg-molclintox: 0.765375 test loss: 0.345901
[Epoch 115; Iter    30/   40] train: loss: 0.0602116
[Epoch 115] ogbg-molclintox: 0.922591 val loss: 0.249511
[Epoch 115] ogbg-molclintox: 0.756794 test loss: 0.341744
[Epoch 116; Iter    20/   40] train: loss: 0.0294495
[Epoch 116] ogbg-molclintox: 0.910962 val loss: 0.243354
[Epoch 116] ogbg-molclintox: 0.742612 test loss: 0.356965
[Epoch 117; Iter    10/   40] train: loss: 0.0642634
[Epoch 117; Iter    40/   40] train: loss: 0.1762405
[Epoch 117] ogbg-molclintox: 0.927133 val loss: 0.232325
[Epoch 117] ogbg-molclintox: 0.750454 test loss: 0.353080
[Epoch 118; Iter    30/   40] train: loss: 0.0223070
[Epoch 118] ogbg-molclintox: 0.932849 val loss: 0.219549
[Epoch 118] ogbg-molclintox: 0.737466 test loss: 0.352242
[Epoch 119; Iter    20/   40] train: loss: 0.0022113
[Epoch 119] ogbg-molclintox: 0.934766 val loss: 0.218585
[Epoch 119] ogbg-molclintox: 0.771770 test loss: 0.323892
[Epoch 120; Iter    10/   40] train: loss: 0.0315094
[Epoch 120; Iter    40/   40] train: loss: 0.0025931
[Epoch 120] ogbg-molclintox: 0.932688 val loss: 0.215509
[Epoch 80; Iter    25/   35] train: loss: 0.1323032
[Epoch 80] ogbg-molclintox: 0.897519 val loss: 0.178577
[Epoch 80] ogbg-molclintox: 0.820743 test loss: 0.281519
[Epoch 81; Iter    20/   35] train: loss: 0.2291396
[Epoch 81] ogbg-molclintox: 0.847364 val loss: 0.173706
[Epoch 81] ogbg-molclintox: 0.807881 test loss: 0.274328
[Epoch 82; Iter    15/   35] train: loss: 0.0193997
[Epoch 82] ogbg-molclintox: 0.923202 val loss: 1.660319
[Epoch 82] ogbg-molclintox: 0.815589 test loss: 0.284543
[Epoch 83; Iter    10/   35] train: loss: 0.0420286
[Epoch 83] ogbg-molclintox: 0.907696 val loss: 1.866986
[Epoch 83] ogbg-molclintox: 0.755789 test loss: 0.303126
[Epoch 84; Iter     5/   35] train: loss: 0.0093241
[Epoch 84; Iter    35/   35] train: loss: 0.0075477
[Epoch 84] ogbg-molclintox: 0.888817 val loss: 1.520925
[Epoch 84] ogbg-molclintox: 0.775580 test loss: 0.286305
[Epoch 85; Iter    30/   35] train: loss: 0.0101881
[Epoch 85] ogbg-molclintox: 0.871963 val loss: 1.164378
[Epoch 85] ogbg-molclintox: 0.764048 test loss: 0.361751
[Epoch 86; Iter    25/   35] train: loss: 0.0087321
[Epoch 86] ogbg-molclintox: 0.888278 val loss: 0.304661
[Epoch 86] ogbg-molclintox: 0.799706 test loss: 0.351964
[Epoch 87; Iter    20/   35] train: loss: 0.0574847
[Epoch 87] ogbg-molclintox: 0.894815 val loss: 0.221819
[Epoch 87] ogbg-molclintox: 0.827076 test loss: 0.305877
[Epoch 88; Iter    15/   35] train: loss: 0.0535507
[Epoch 88] ogbg-molclintox: 0.879037 val loss: 1.090499
[Epoch 88] ogbg-molclintox: 0.826192 test loss: 0.295682
[Epoch 89; Iter    10/   35] train: loss: 0.0052577
[Epoch 89] ogbg-molclintox: 0.884366 val loss: 0.269665
[Epoch 89] ogbg-molclintox: 0.828941 test loss: 0.306140
[Epoch 90; Iter     5/   35] train: loss: 0.0159422
[Epoch 90; Iter    35/   35] train: loss: 0.0564776
[Epoch 90] ogbg-molclintox: 0.847036 val loss: 3.055696
[Epoch 90] ogbg-molclintox: 0.723012 test loss: 0.363523
[Epoch 91; Iter    30/   35] train: loss: 0.0210569
[Epoch 91] ogbg-molclintox: 0.892673 val loss: 0.163958
[Epoch 91] ogbg-molclintox: 0.768561 test loss: 0.305851
[Epoch 92; Iter    25/   35] train: loss: 0.0511181
[Epoch 92] ogbg-molclintox: 0.885269 val loss: 0.201691
[Epoch 92] ogbg-molclintox: 0.809109 test loss: 0.349238
[Epoch 93; Iter    20/   35] train: loss: 0.0487973
[Epoch 93] ogbg-molclintox: 0.876479 val loss: 0.675990
[Epoch 93] ogbg-molclintox: 0.805091 test loss: 0.311260
[Epoch 94; Iter    15/   35] train: loss: 0.0537011
[Epoch 94] ogbg-molclintox: 0.912644 val loss: 0.169532
[Epoch 94] ogbg-molclintox: 0.793306 test loss: 0.314116
[Epoch 95; Iter    10/   35] train: loss: 0.0097020
[Epoch 95] ogbg-molclintox: 0.936072 val loss: 0.140735
[Epoch 95] ogbg-molclintox: 0.742957 test loss: 0.302225
[Epoch 96; Iter     5/   35] train: loss: 0.0074317
[Epoch 96; Iter    35/   35] train: loss: 0.0392864
[Epoch 96] ogbg-molclintox: 0.922900 val loss: 0.153230
[Epoch 96] ogbg-molclintox: 0.816455 test loss: 0.344076
[Epoch 97; Iter    30/   35] train: loss: 0.0268045
[Epoch 97] ogbg-molclintox: 0.877632 val loss: 0.218573
[Epoch 97] ogbg-molclintox: 0.783724 test loss: 0.363800
[Epoch 98; Iter    25/   35] train: loss: 0.0263026
[Epoch 98] ogbg-molclintox: 0.922244 val loss: 0.146775
[Epoch 98] ogbg-molclintox: 0.802809 test loss: 0.302795
[Epoch 99; Iter    20/   35] train: loss: 0.0183393
[Epoch 99] ogbg-molclintox: 0.918014 val loss: 0.185346
[Epoch 99] ogbg-molclintox: 0.786908 test loss: 0.338997
[Epoch 100; Iter    15/   35] train: loss: 0.1061231
[Epoch 100] ogbg-molclintox: 0.904649 val loss: 0.159596
[Epoch 100] ogbg-molclintox: 0.815474 test loss: 0.273648
[Epoch 101; Iter    10/   35] train: loss: 0.0322667
[Epoch 101] ogbg-molclintox: 0.894015 val loss: 0.190299
[Epoch 101] ogbg-molclintox: 0.759214 test loss: 0.369419
[Epoch 102; Iter     5/   35] train: loss: 0.0168974
[Epoch 102; Iter    35/   35] train: loss: 0.0044310
[Epoch 102] ogbg-molclintox: 0.848098 val loss: 0.198477
[Epoch 102] ogbg-molclintox: 0.801256 test loss: 0.327604
[Epoch 103; Iter    30/   35] train: loss: 0.0051809
[Epoch 103] ogbg-molclintox: 0.881913 val loss: 0.226273
[Epoch 103] ogbg-molclintox: 0.778213 test loss: 0.345533
[Epoch 104; Iter    25/   35] train: loss: 0.0128836
[Epoch 104] ogbg-molclintox: 0.870036 val loss: 0.251994
[Epoch 104] ogbg-molclintox: 0.760497 test loss: 0.393511
[Epoch 105; Iter    20/   35] train: loss: 0.0040400
[Epoch 105] ogbg-molclintox: 0.888968 val loss: 0.219470
[Epoch 105] ogbg-molclintox: 0.795785 test loss: 0.316522
[Epoch 106; Iter    15/   35] train: loss: 0.0034975
[Epoch 106] ogbg-molclintox: 0.866065 val loss: 0.202908
[Epoch 106] ogbg-molclintox: 0.761812 test loss: 0.339907
[Epoch 107; Iter    10/   35] train: loss: 0.0382357
[Epoch 107] ogbg-molclintox: 0.884984 val loss: 0.203190
[Epoch 107] ogbg-molclintox: 0.760559 test loss: 0.342339
[Epoch 108; Iter     5/   35] train: loss: 0.1019061
[Epoch 108; Iter    35/   35] train: loss: 0.1005571
[Epoch 108] ogbg-molclintox: 0.901143 val loss: 0.197407
[Epoch 108] ogbg-molclintox: 0.784344 test loss: 0.341109
[Epoch 109; Iter    30/   35] train: loss: 0.0273079
[Epoch 109] ogbg-molclintox: 0.898821 val loss: 0.195066
[Epoch 109] ogbg-molclintox: 0.799450 test loss: 0.323427
[Epoch 110; Iter    25/   35] train: loss: 0.0123906
[Epoch 110] ogbg-molclintox: 0.898693 val loss: 0.369243
[Epoch 110] ogbg-molclintox: 0.810231 test loss: 0.319907
[Epoch 111; Iter    20/   35] train: loss: 0.0414514
[Epoch 111] ogbg-molclintox: 0.869846 val loss: 0.607469
[Epoch 111] ogbg-molclintox: 0.762278 test loss: 0.362406
[Epoch 112; Iter    15/   35] train: loss: 0.0055716
[Epoch 112] ogbg-molclintox: 0.844879 val loss: 0.249370
[Epoch 112] ogbg-molclintox: 0.775549 test loss: 0.355734
[Epoch 113; Iter    10/   35] train: loss: 0.0034983
[Epoch 113] ogbg-molclintox: 0.847767 val loss: 0.246951
[Epoch 113] ogbg-molclintox: 0.759857 test loss: 0.381196
[Epoch 114; Iter     5/   35] train: loss: 0.0687431
[Epoch 114; Iter    35/   35] train: loss: 0.0022679
[Epoch 114] ogbg-molclintox: 0.856868 val loss: 0.315763
[Epoch 114] ogbg-molclintox: 0.711809 test loss: 0.396217
[Epoch 115; Iter    30/   35] train: loss: 0.0305471
[Epoch 115] ogbg-molclintox: 0.863233 val loss: 0.327766
[Epoch 115] ogbg-molclintox: 0.756361 test loss: 0.390598
[Epoch 116; Iter    25/   35] train: loss: 0.1164790
[Epoch 116] ogbg-molclintox: 0.871145 val loss: 0.252204
[Epoch 116] ogbg-molclintox: 0.767650 test loss: 0.397267
[Epoch 117; Iter    20/   35] train: loss: 0.0032972
[Epoch 117] ogbg-molclintox: 0.896819 val loss: 0.320296
[Epoch 117] ogbg-molclintox: 0.775899 test loss: 0.373127
[Epoch 118; Iter    15/   35] train: loss: 0.0550691
[Epoch 118] ogbg-molclintox: 0.904069 val loss: 0.224486
[Epoch 118] ogbg-molclintox: 0.791244 test loss: 0.358178
[Epoch 119; Iter    10/   35] train: loss: 0.0475520
[Epoch 119] ogbg-molclintox: 0.889826 val loss: 0.225704
[Epoch 119] ogbg-molclintox: 0.754797 test loss: 0.385409
[Epoch 120; Iter     5/   35] train: loss: 0.0958346
[Epoch 120; Iter    35/   35] train: loss: 0.0347170
[Epoch 120] ogbg-molclintox: 0.910135 val loss: 0.203643
[Epoch 120] ogbg-molclintox: 0.752794 test loss: 0.390636
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 60.
Statistics on  val_best_checkpoint
mean_pred: 0.23684123158454895
std_pred: 5.35341215133667
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.8476105024969269
rocauc: 0.9561488570671035
ogbg-molclintox: 0.9561488570671035
OGBNanLabelBCEWithLogitsLoss: 0.10804690280929208
Statistics on  test
mean_pred: 0.22698503732681274
std_pred: 5.511448383331299
mean_targets: 0.5090090036392212
std_targets: 0.5004827976226807
prcauc: 0.6659782780778181
rocauc: 0.8531579619257345
ogbg-molclintox: 0.8531579619257345
OGBNanLabelBCEWithLogitsLoss: 0.21278550941497087
Statistics on  train
mean_pred: 0.2302769422531128
std_pred: 5.745325565338135
mean_targets: 0.5053243041038513
std_targets: 0.5000926852226257
prcauc: 0.953106665860183
rocauc: 0.9883951749822005
ogbg-molclintox: 0.9883951749822005
OGBNanLabelBCEWithLogitsLoss: 0.07694967894681863
[Epoch 80; Iter    25/   35] train: loss: 0.0451933
[Epoch 80] ogbg-molclintox: 0.883230 val loss: 0.160886
[Epoch 80] ogbg-molclintox: 0.769439 test loss: 0.300095
[Epoch 81; Iter    20/   35] train: loss: 0.0118313
[Epoch 81] ogbg-molclintox: 0.856918 val loss: 0.171195
[Epoch 81] ogbg-molclintox: 0.762513 test loss: 0.312398
[Epoch 82; Iter    15/   35] train: loss: 0.1006318
[Epoch 82] ogbg-molclintox: 0.845092 val loss: 0.196097
[Epoch 82] ogbg-molclintox: 0.781387 test loss: 0.315515
[Epoch 83; Iter    10/   35] train: loss: 0.0088131
[Epoch 83] ogbg-molclintox: 0.873833 val loss: 0.180041
[Epoch 83] ogbg-molclintox: 0.769386 test loss: 0.311447
[Epoch 84; Iter     5/   35] train: loss: 0.0513498
[Epoch 84; Iter    35/   35] train: loss: 0.0055545
[Epoch 84] ogbg-molclintox: 0.884478 val loss: 0.214406
[Epoch 84] ogbg-molclintox: 0.839848 test loss: 0.306200
[Epoch 85; Iter    30/   35] train: loss: 0.0731203
[Epoch 85] ogbg-molclintox: 0.847042 val loss: 0.203925
[Epoch 85] ogbg-molclintox: 0.814806 test loss: 0.301721
[Epoch 86; Iter    25/   35] train: loss: 0.0346174
[Epoch 86] ogbg-molclintox: 0.861660 val loss: 0.203362
[Epoch 86] ogbg-molclintox: 0.768146 test loss: 0.320426
[Epoch 87; Iter    20/   35] train: loss: 0.0399682
[Epoch 87] ogbg-molclintox: 0.847542 val loss: 0.196073
[Epoch 87] ogbg-molclintox: 0.802193 test loss: 0.295978
[Epoch 88; Iter    15/   35] train: loss: 0.0286672
[Epoch 88] ogbg-molclintox: 0.862032 val loss: 0.208080
[Epoch 88] ogbg-molclintox: 0.793860 test loss: 0.318225
[Epoch 89; Iter    10/   35] train: loss: 0.0400546
[Epoch 89] ogbg-molclintox: 0.855285 val loss: 0.205278
[Epoch 89] ogbg-molclintox: 0.776485 test loss: 0.314188
[Epoch 90; Iter     5/   35] train: loss: 0.0181955
[Epoch 90; Iter    35/   35] train: loss: 0.0063918
[Epoch 90] ogbg-molclintox: 0.855756 val loss: 0.211700
[Epoch 90] ogbg-molclintox: 0.795590 test loss: 0.314557
[Epoch 91; Iter    30/   35] train: loss: 0.1858480
[Epoch 91] ogbg-molclintox: 0.858311 val loss: 0.206796
[Epoch 91] ogbg-molclintox: 0.772367 test loss: 0.335759
[Epoch 92; Iter    25/   35] train: loss: 0.1580801
[Epoch 92] ogbg-molclintox: 0.873445 val loss: 0.193527
[Epoch 92] ogbg-molclintox: 0.825178 test loss: 0.296250
[Epoch 93; Iter    20/   35] train: loss: 0.0230106
[Epoch 93] ogbg-molclintox: 0.899854 val loss: 0.166329
[Epoch 93] ogbg-molclintox: 0.769307 test loss: 0.315213
[Epoch 94; Iter    15/   35] train: loss: 0.0876294
[Epoch 94] ogbg-molclintox: 0.876592 val loss: 0.192803
[Epoch 94] ogbg-molclintox: 0.803327 test loss: 0.286096
[Epoch 95; Iter    10/   35] train: loss: 0.0040489
[Epoch 95] ogbg-molclintox: 0.857620 val loss: 0.185161
[Epoch 95] ogbg-molclintox: 0.819946 test loss: 0.300526
[Epoch 96; Iter     5/   35] train: loss: 0.0224303
[Epoch 96; Iter    35/   35] train: loss: 0.0094027
[Epoch 96] ogbg-molclintox: 0.877716 val loss: 0.214147
[Epoch 96] ogbg-molclintox: 0.820095 test loss: 0.332384
[Epoch 97; Iter    30/   35] train: loss: 0.0273167
[Epoch 97] ogbg-molclintox: 0.857067 val loss: 0.223290
[Epoch 97] ogbg-molclintox: 0.799549 test loss: 0.328533
[Epoch 98; Iter    25/   35] train: loss: 0.0055469
[Epoch 98] ogbg-molclintox: 0.848263 val loss: 0.195984
[Epoch 98] ogbg-molclintox: 0.806605 test loss: 0.296791
[Epoch 99; Iter    20/   35] train: loss: 0.0067540
[Epoch 99] ogbg-molclintox: 0.880439 val loss: 0.192836
[Epoch 99] ogbg-molclintox: 0.783813 test loss: 0.300050
[Epoch 100; Iter    15/   35] train: loss: 0.0233572
[Epoch 100] ogbg-molclintox: 0.849494 val loss: 0.217569
[Epoch 100] ogbg-molclintox: 0.763964 test loss: 0.362067
[Epoch 101; Iter    10/   35] train: loss: 0.0036391
[Epoch 101] ogbg-molclintox: 0.892499 val loss: 0.214546
[Epoch 101] ogbg-molclintox: 0.802660 test loss: 0.327777
[Epoch 102; Iter     5/   35] train: loss: 0.0666762
[Epoch 102; Iter    35/   35] train: loss: 0.0104322
[Epoch 102] ogbg-molclintox: 0.807887 val loss: 0.203870
[Epoch 102] ogbg-molclintox: 0.766459 test loss: 0.302372
[Epoch 103; Iter    30/   35] train: loss: 0.1039876
[Epoch 103] ogbg-molclintox: 0.879006 val loss: 0.213864
[Epoch 103] ogbg-molclintox: 0.781573 test loss: 0.350818
[Epoch 104; Iter    25/   35] train: loss: 0.0269555
[Epoch 104] ogbg-molclintox: 0.852216 val loss: 0.218532
[Epoch 104] ogbg-molclintox: 0.759933 test loss: 0.370759
[Epoch 105; Iter    20/   35] train: loss: 0.0300436
[Epoch 105] ogbg-molclintox: 0.797663 val loss: 0.208836
[Epoch 105] ogbg-molclintox: 0.738633 test loss: 0.324753
[Epoch 106; Iter    15/   35] train: loss: 0.0982967
[Epoch 106] ogbg-molclintox: 0.892736 val loss: 0.216819
[Epoch 106] ogbg-molclintox: 0.778105 test loss: 0.383551
[Epoch 107; Iter    10/   35] train: loss: 0.0032876
[Epoch 107] ogbg-molclintox: 0.829654 val loss: 0.224419
[Epoch 107] ogbg-molclintox: 0.771911 test loss: 0.354541
[Epoch 108; Iter     5/   35] train: loss: 0.0470977
[Epoch 108; Iter    35/   35] train: loss: 0.0037938
[Epoch 108] ogbg-molclintox: 0.865744 val loss: 0.183022
[Epoch 108] ogbg-molclintox: 0.756626 test loss: 0.333531
[Epoch 109; Iter    30/   35] train: loss: 0.0788669
[Epoch 109] ogbg-molclintox: 0.873882 val loss: 0.176229
[Epoch 109] ogbg-molclintox: 0.725012 test loss: 0.341790
[Epoch 110; Iter    25/   35] train: loss: 0.0132082
[Epoch 110] ogbg-molclintox: 0.885518 val loss: 0.197057
[Epoch 110] ogbg-molclintox: 0.752460 test loss: 0.353333
[Epoch 111; Iter    20/   35] train: loss: 0.0382053
[Epoch 111] ogbg-molclintox: 0.865597 val loss: 0.195451
[Epoch 111] ogbg-molclintox: 0.778680 test loss: 0.342635
[Epoch 112; Iter    15/   35] train: loss: 0.0181118
[Epoch 112] ogbg-molclintox: 0.890336 val loss: 0.192245
[Epoch 112] ogbg-molclintox: 0.791999 test loss: 0.351070
[Epoch 113; Iter    10/   35] train: loss: 0.0214213
[Epoch 113] ogbg-molclintox: 0.879971 val loss: 0.205159
[Epoch 113] ogbg-molclintox: 0.759283 test loss: 0.319278
[Epoch 114; Iter     5/   35] train: loss: 0.1008880
[Epoch 114; Iter    35/   35] train: loss: 0.0029271
[Epoch 114] ogbg-molclintox: 0.822601 val loss: 0.233451
[Epoch 114] ogbg-molclintox: 0.736261 test loss: 0.357034
[Epoch 115; Iter    30/   35] train: loss: 0.0826926
[Epoch 115] ogbg-molclintox: 0.883168 val loss: 0.223509
[Epoch 115] ogbg-molclintox: 0.734603 test loss: 0.393921
[Epoch 116; Iter    25/   35] train: loss: 0.0119540
[Epoch 116] ogbg-molclintox: 0.868707 val loss: 0.219456
[Epoch 116] ogbg-molclintox: 0.740274 test loss: 0.359563
[Epoch 117; Iter    20/   35] train: loss: 0.0440818
[Epoch 117] ogbg-molclintox: 0.892268 val loss: 0.217364
[Epoch 117] ogbg-molclintox: 0.759629 test loss: 0.362964
[Epoch 118; Iter    15/   35] train: loss: 0.0047793
[Epoch 118] ogbg-molclintox: 0.870414 val loss: 0.216338
[Epoch 118] ogbg-molclintox: 0.751774 test loss: 0.370382
[Epoch 119; Iter    10/   35] train: loss: 0.0430358
[Epoch 119] ogbg-molclintox: 0.894943 val loss: 0.206892
[Epoch 119] ogbg-molclintox: 0.825325 test loss: 0.330235
[Epoch 120; Iter     5/   35] train: loss: 0.0281372
[Epoch 120; Iter    35/   35] train: loss: 0.0057704
[Epoch 120] ogbg-molclintox: 0.871214 val loss: 0.219408
[Epoch 120] ogbg-molclintox: 0.803194 test loss: 0.340441
[Epoch 121; Iter    30/   35] train: loss: 0.1269826
[Epoch 121] ogbg-molclintox: 0.861878 val loss: 0.230315
[Epoch 121] ogbg-molclintox: 0.764645 test loss: 0.349748
[Epoch 122; Iter    25/   35] train: loss: 0.0379071
[Epoch 122] ogbg-molclintox: 0.888574 val loss: 0.218995
[Epoch 122] ogbg-molclintox: 0.777127 test loss: 0.374826
[Epoch 123; Iter    20/   35] train: loss: 0.0434029
[Epoch 123] ogbg-molclintox: 0.885499 val loss: 0.264670
[Epoch 123] ogbg-molclintox: 0.760267 test loss: 0.375187
[Epoch 124; Iter    15/   35] train: loss: 0.0030591
[Epoch 124] ogbg-molclintox: 0.839766 val loss: 0.210314
[Epoch 124] ogbg-molclintox: 0.729056 test loss: 0.339758
[Epoch 125; Iter    10/   35] train: loss: 0.0728616
[Epoch 125] ogbg-molclintox: 0.858594 val loss: 0.287727
[Epoch 125] ogbg-molclintox: 0.789183 test loss: 0.363363
[Epoch 126; Iter     5/   35] train: loss: 0.0222801
[Epoch 126; Iter    35/   35] train: loss: 0.0029693
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 126] ogbg-molclintox: 0.857376 val loss: 0.226735
[Epoch 126] ogbg-molclintox: 0.767656 test loss: 0.362888
[Epoch 127; Iter    30/   35] train: loss: 0.0730109
[Epoch 127] ogbg-molclintox: 0.838066 val loss: 0.286249
[Epoch 127] ogbg-molclintox: 0.823192 test loss: 0.328657
[Epoch 128; Iter    25/   35] train: loss: 0.0176917
[Epoch 128] ogbg-molclintox: 0.907344 val loss: 0.198302
[Epoch 128] ogbg-molclintox: 0.797769 test loss: 0.370962
[Epoch 129; Iter    20/   35] train: loss: 0.0429988
[Epoch 129] ogbg-molclintox: 0.880235 val loss: 0.207418
[Epoch 129] ogbg-molclintox: 0.807292 test loss: 0.342758
[Epoch 130; Iter    15/   35] train: loss: 0.0533592
[Epoch 130] ogbg-molclintox: 0.855525 val loss: 0.244676
[Epoch 130] ogbg-molclintox: 0.758664 test loss: 0.398498
[Epoch 131; Iter    10/   35] train: loss: 0.0024313
[Epoch 131] ogbg-molclintox: 0.901349 val loss: 0.237821
[Epoch 131] ogbg-molclintox: 0.797329 test loss: 0.375908
[Epoch 132; Iter     5/   35] train: loss: 0.0329987
[Epoch 132; Iter    35/   35] train: loss: 0.0582683
[Epoch 132] ogbg-molclintox: 0.884569 val loss: 0.218934
[Epoch 132] ogbg-molclintox: 0.763637 test loss: 0.379532
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 132 epochs. Best model checkpoint was in epoch 72.
Statistics on  val_best_checkpoint
mean_pred: 0.2064715325832367
std_pred: 7.010376453399658
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.8037684383301213
rocauc: 0.9348854640620043
ogbg-molclintox: 0.9348854640620043
OGBNanLabelBCEWithLogitsLoss: 0.14753020752687007
Statistics on  test
mean_pred: 0.19429858028888702
std_pred: 7.107813835144043
mean_targets: 0.5090090036392212
std_targets: 0.5004827976226807
prcauc: 0.6425437051621906
rocauc: 0.7769605527075134
ogbg-molclintox: 0.7769605527075134
OGBNanLabelBCEWithLogitsLoss: 0.3190575847402215
Statistics on  train
mean_pred: 0.193891704082489
std_pred: 7.349209785461426
mean_targets: 0.5053243041038513
std_targets: 0.5000926852226257
prcauc: 0.9682328790869725
rocauc: 0.9969995385818792
ogbg-molclintox: 0.9969995385818792
OGBNanLabelBCEWithLogitsLoss: 0.06261301635365402
All runs completed.
[Epoch 76] ogbg-molclintox: 0.894310 val loss: 0.189458
[Epoch 76] ogbg-molclintox: 0.841673 test loss: 0.268563
[Epoch 77; Iter    20/   40] train: loss: 0.0397754
[Epoch 77] ogbg-molclintox: 0.865788 val loss: 0.196015
[Epoch 77] ogbg-molclintox: 0.788031 test loss: 0.270706
[Epoch 78; Iter    10/   40] train: loss: 0.0118513
[Epoch 78; Iter    40/   40] train: loss: 0.0119450
[Epoch 78] ogbg-molclintox: 0.892498 val loss: 0.237415
[Epoch 78] ogbg-molclintox: 0.781075 test loss: 0.303597
[Epoch 79; Iter    30/   40] train: loss: 0.0090815
[Epoch 79] ogbg-molclintox: 0.894628 val loss: 0.168814
[Epoch 79] ogbg-molclintox: 0.846482 test loss: 0.257271
[Epoch 80; Iter    20/   40] train: loss: 0.0114406
[Epoch 80] ogbg-molclintox: 0.839985 val loss: 0.206557
[Epoch 80] ogbg-molclintox: 0.844282 test loss: 0.279361
[Epoch 81; Iter    10/   40] train: loss: 0.0525773
[Epoch 81; Iter    40/   40] train: loss: 0.1031422
[Epoch 81] ogbg-molclintox: 0.852786 val loss: 0.217022
[Epoch 81] ogbg-molclintox: 0.835894 test loss: 0.295344
[Epoch 82; Iter    30/   40] train: loss: 0.1078707
[Epoch 82] ogbg-molclintox: 0.876408 val loss: 0.176036
[Epoch 82] ogbg-molclintox: 0.833113 test loss: 0.265133
[Epoch 83; Iter    20/   40] train: loss: 0.0625851
[Epoch 83] ogbg-molclintox: 0.881428 val loss: 0.186235
[Epoch 83] ogbg-molclintox: 0.818291 test loss: 0.263422
[Epoch 84; Iter    10/   40] train: loss: 0.0576366
[Epoch 84; Iter    40/   40] train: loss: 0.0039502
[Epoch 84] ogbg-molclintox: 0.858449 val loss: 0.190450
[Epoch 84] ogbg-molclintox: 0.832184 test loss: 0.274206
[Epoch 85; Iter    30/   40] train: loss: 0.0113783
[Epoch 85] ogbg-molclintox: 0.874181 val loss: 0.203008
[Epoch 85] ogbg-molclintox: 0.858004 test loss: 0.264589
[Epoch 86; Iter    20/   40] train: loss: 0.1443416
[Epoch 86] ogbg-molclintox: 0.859209 val loss: 0.184490
[Epoch 86] ogbg-molclintox: 0.819847 test loss: 0.286152
[Epoch 87; Iter    10/   40] train: loss: 0.0143861
[Epoch 87; Iter    40/   40] train: loss: 0.0559845
[Epoch 87] ogbg-molclintox: 0.858075 val loss: 0.200759
[Epoch 87] ogbg-molclintox: 0.824046 test loss: 0.284716
[Epoch 88; Iter    30/   40] train: loss: 0.0640231
[Epoch 88] ogbg-molclintox: 0.844701 val loss: 0.186398
[Epoch 88] ogbg-molclintox: 0.782058 test loss: 0.304251
[Epoch 89; Iter    20/   40] train: loss: 0.0330610
[Epoch 89] ogbg-molclintox: 0.850643 val loss: 0.203918
[Epoch 89] ogbg-molclintox: 0.818978 test loss: 0.309090
[Epoch 90; Iter    10/   40] train: loss: 0.0700104
[Epoch 90; Iter    40/   40] train: loss: 0.0063476
[Epoch 90] ogbg-molclintox: 0.835110 val loss: 0.199086
[Epoch 90] ogbg-molclintox: 0.846795 test loss: 0.279512
[Epoch 91; Iter    30/   40] train: loss: 0.0077402
[Epoch 91] ogbg-molclintox: 0.863868 val loss: 0.190006
[Epoch 91] ogbg-molclintox: 0.861641 test loss: 0.246063
[Epoch 92; Iter    20/   40] train: loss: 0.0097593
[Epoch 92] ogbg-molclintox: 0.869106 val loss: 0.196541
[Epoch 92] ogbg-molclintox: 0.838047 test loss: 0.316230
[Epoch 93; Iter    10/   40] train: loss: 0.0843698
[Epoch 93; Iter    40/   40] train: loss: 0.0080244
[Epoch 93] ogbg-molclintox: 0.866881 val loss: 0.189228
[Epoch 93] ogbg-molclintox: 0.840183 test loss: 0.290886
[Epoch 94; Iter    30/   40] train: loss: 0.1263848
[Epoch 94] ogbg-molclintox: 0.873327 val loss: 0.213961
[Epoch 94] ogbg-molclintox: 0.877230 test loss: 0.255140
[Epoch 95; Iter    20/   40] train: loss: 0.0384144
[Epoch 95] ogbg-molclintox: 0.892269 val loss: 0.199207
[Epoch 95] ogbg-molclintox: 0.853081 test loss: 0.267570
[Epoch 96; Iter    10/   40] train: loss: 0.0809553
[Epoch 96; Iter    40/   40] train: loss: 0.5456214
[Epoch 96] ogbg-molclintox: 0.878308 val loss: 0.194613
[Epoch 96] ogbg-molclintox: 0.808783 test loss: 0.263445
[Epoch 97; Iter    30/   40] train: loss: 0.0469834
[Epoch 97] ogbg-molclintox: 0.906871 val loss: 0.188041
[Epoch 97] ogbg-molclintox: 0.812228 test loss: 0.256077
[Epoch 98; Iter    20/   40] train: loss: 0.0160161
[Epoch 98] ogbg-molclintox: 0.857117 val loss: 0.210270
[Epoch 98] ogbg-molclintox: 0.794788 test loss: 0.315824
[Epoch 99; Iter    10/   40] train: loss: 0.0516244
[Epoch 99; Iter    40/   40] train: loss: 0.0218362
[Epoch 99] ogbg-molclintox: 0.893470 val loss: 0.222999
[Epoch 99] ogbg-molclintox: 0.817983 test loss: 0.302897
[Epoch 100; Iter    30/   40] train: loss: 0.0560044
[Epoch 100] ogbg-molclintox: 0.866856 val loss: 0.202999
[Epoch 100] ogbg-molclintox: 0.744843 test loss: 0.320429
[Epoch 101; Iter    20/   40] train: loss: 0.0304917
[Epoch 101] ogbg-molclintox: 0.883080 val loss: 0.193737
[Epoch 101] ogbg-molclintox: 0.805314 test loss: 0.286504
[Epoch 102; Iter    10/   40] train: loss: 0.0985943
[Epoch 102; Iter    40/   40] train: loss: 0.0124290
[Epoch 102] ogbg-molclintox: 0.872943 val loss: 0.184636
[Epoch 102] ogbg-molclintox: 0.800669 test loss: 0.294548
[Epoch 103; Iter    30/   40] train: loss: 0.0563176
[Epoch 103] ogbg-molclintox: 0.887608 val loss: 0.192760
[Epoch 103] ogbg-molclintox: 0.819603 test loss: 0.299562
[Epoch 104; Iter    20/   40] train: loss: 0.0451202
[Epoch 104] ogbg-molclintox: 0.880310 val loss: 0.204097
[Epoch 104] ogbg-molclintox: 0.763143 test loss: 0.307543
[Epoch 105; Iter    10/   40] train: loss: 0.0533918
[Epoch 105; Iter    40/   40] train: loss: 0.0082754
[Epoch 105] ogbg-molclintox: 0.881775 val loss: 0.203984
[Epoch 105] ogbg-molclintox: 0.752523 test loss: 0.328496
[Epoch 106; Iter    30/   40] train: loss: 0.0398746
[Epoch 106] ogbg-molclintox: 0.890246 val loss: 0.206374
[Epoch 106] ogbg-molclintox: 0.807227 test loss: 0.297304
[Epoch 107; Iter    20/   40] train: loss: 0.0912156
[Epoch 107] ogbg-molclintox: 0.877898 val loss: 0.222780
[Epoch 107] ogbg-molclintox: 0.766006 test loss: 0.339024
[Epoch 108; Iter    10/   40] train: loss: 0.0071440
[Epoch 108; Iter    40/   40] train: loss: 0.0054082
[Epoch 108] ogbg-molclintox: 0.878338 val loss: 0.209755
[Epoch 108] ogbg-molclintox: 0.771658 test loss: 0.318508
[Epoch 109; Iter    30/   40] train: loss: 0.0677087
[Epoch 109] ogbg-molclintox: 0.904673 val loss: 0.191638
[Epoch 109] ogbg-molclintox: 0.794751 test loss: 0.306249
[Epoch 110; Iter    20/   40] train: loss: 0.0047396
[Epoch 110] ogbg-molclintox: 0.882988 val loss: 0.208768
[Epoch 110] ogbg-molclintox: 0.740910 test loss: 0.329809
[Epoch 111; Iter    10/   40] train: loss: 0.0032561
[Epoch 111; Iter    40/   40] train: loss: 0.0032959
[Epoch 111] ogbg-molclintox: 0.879751 val loss: 0.188074
[Epoch 111] ogbg-molclintox: 0.787898 test loss: 0.312415
[Epoch 112; Iter    30/   40] train: loss: 0.0411148
[Epoch 112] ogbg-molclintox: 0.886356 val loss: 0.192680
[Epoch 112] ogbg-molclintox: 0.806666 test loss: 0.297127
[Epoch 113; Iter    20/   40] train: loss: 0.0058548
[Epoch 113] ogbg-molclintox: 0.886957 val loss: 0.197691
[Epoch 113] ogbg-molclintox: 0.773178 test loss: 0.329391
[Epoch 114; Iter    10/   40] train: loss: 0.0995081
[Epoch 114; Iter    40/   40] train: loss: 0.0083159
[Epoch 114] ogbg-molclintox: 0.904487 val loss: 0.195313
[Epoch 114] ogbg-molclintox: 0.787072 test loss: 0.319158
[Epoch 115; Iter    30/   40] train: loss: 0.0021342
[Epoch 115] ogbg-molclintox: 0.868453 val loss: 0.201267
[Epoch 115] ogbg-molclintox: 0.744523 test loss: 0.335723
[Epoch 116; Iter    20/   40] train: loss: 0.0352453
[Epoch 116] ogbg-molclintox: 0.901435 val loss: 0.204892
[Epoch 116] ogbg-molclintox: 0.795529 test loss: 0.305550
[Epoch 117; Iter    10/   40] train: loss: 0.0273647
[Epoch 117; Iter    40/   40] train: loss: 0.3548000
[Epoch 117] ogbg-molclintox: 0.876206 val loss: 0.222372
[Epoch 117] ogbg-molclintox: 0.789672 test loss: 0.320085
[Epoch 118; Iter    30/   40] train: loss: 0.0049147
[Epoch 118] ogbg-molclintox: 0.875339 val loss: 0.206820
[Epoch 118] ogbg-molclintox: 0.815763 test loss: 0.299303
[Epoch 119; Iter    20/   40] train: loss: 0.0043575
[Epoch 119] ogbg-molclintox: 0.869186 val loss: 0.192408
[Epoch 119] ogbg-molclintox: 0.806756 test loss: 0.319625
[Epoch 120; Iter    10/   40] train: loss: 0.0267737
[Epoch 120; Iter    40/   40] train: loss: 0.0067772
[Epoch 120] ogbg-molclintox: 0.875179 val loss: 0.207002
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.773239 test loss: 0.332888
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 56.
Statistics on  val_best_checkpoint
mean_pred: 0.19848674535751343
std_pred: 5.483551025390625
mean_targets: 0.5101351737976074
std_targets: 0.5007438659667969
prcauc: 0.8442687279316171
rocauc: 0.9569197583109983
ogbg-molclintox: 0.9569197583109983
OGBNanLabelBCEWithLogitsLoss: 0.11973419785499573
Statistics on  test
mean_pred: 0.19552557170391083
std_pred: 5.451364517211914
mean_targets: 0.5101351737976074
std_targets: 0.5007438063621521
prcauc: 0.6630495062614543
rocauc: 0.785678441084463
ogbg-molclintox: 0.785678441084463
OGBNanLabelBCEWithLogitsLoss: 0.2340819537639618
Statistics on  train
mean_pred: 0.20606553554534912
std_pred: 5.660032749176025
mean_targets: 0.5050804018974304
std_targets: 0.5000800490379333
prcauc: 0.943555434348169
rocauc: 0.9879049514644287
ogbg-molclintox: 0.9879049514644287
OGBNanLabelBCEWithLogitsLoss: 0.0769019525963813
[Epoch 120] ogbg-molclintox: 0.735109 test loss: 0.360245
[Epoch 121; Iter    30/   40] train: loss: 0.0079202
[Epoch 121] ogbg-molclintox: 0.942693 val loss: 0.203614
[Epoch 121] ogbg-molclintox: 0.725539 test loss: 0.360525
[Epoch 122; Iter    20/   40] train: loss: 0.0204001
[Epoch 122] ogbg-molclintox: 0.940948 val loss: 0.197212
[Epoch 122] ogbg-molclintox: 0.727861 test loss: 0.370182
[Epoch 123; Iter    10/   40] train: loss: 0.0192896
[Epoch 123; Iter    40/   40] train: loss: 0.0024463
[Epoch 123] ogbg-molclintox: 0.937152 val loss: 0.190085
[Epoch 123] ogbg-molclintox: 0.704099 test loss: 0.393024
[Epoch 124; Iter    30/   40] train: loss: 0.0783331
[Epoch 124] ogbg-molclintox: 0.931716 val loss: 0.202607
[Epoch 124] ogbg-molclintox: 0.713190 test loss: 0.386869
[Epoch 125; Iter    20/   40] train: loss: 0.0147624
[Epoch 125] ogbg-molclintox: 0.938284 val loss: 0.185621
[Epoch 125] ogbg-molclintox: 0.698875 test loss: 0.374573
[Epoch 126; Iter    10/   40] train: loss: 0.0284701
[Epoch 126; Iter    40/   40] train: loss: 0.0096334
[Epoch 126] ogbg-molclintox: 0.920567 val loss: 0.208222
[Epoch 126] ogbg-molclintox: 0.723421 test loss: 0.359424
[Epoch 127; Iter    30/   40] train: loss: 0.0306557
[Epoch 127] ogbg-molclintox: 0.914959 val loss: 0.203576
[Epoch 127] ogbg-molclintox: 0.687934 test loss: 0.409087
[Epoch 128; Iter    20/   40] train: loss: 0.0085415
[Epoch 128] ogbg-molclintox: 0.923870 val loss: 0.204084
[Epoch 128] ogbg-molclintox: 0.700841 test loss: 0.381629
[Epoch 129; Iter    10/   40] train: loss: 0.0030315
[Epoch 129; Iter    40/   40] train: loss: 0.0041877
[Epoch 129] ogbg-molclintox: 0.943572 val loss: 0.197793
[Epoch 129] ogbg-molclintox: 0.725834 test loss: 0.378558
[Epoch 130; Iter    30/   40] train: loss: 0.0081370
[Epoch 130] ogbg-molclintox: 0.922233 val loss: 0.199375
[Epoch 130] ogbg-molclintox: 0.693029 test loss: 0.420217
[Epoch 131; Iter    20/   40] train: loss: 0.0646563
[Epoch 131] ogbg-molclintox: 0.942387 val loss: 0.190590
[Epoch 131] ogbg-molclintox: 0.708168 test loss: 0.400781
[Epoch 132; Iter    10/   40] train: loss: 0.0460306
[Epoch 132; Iter    40/   40] train: loss: 0.0015980
[Epoch 132] ogbg-molclintox: 0.943519 val loss: 0.188754
[Epoch 132] ogbg-molclintox: 0.729188 test loss: 0.390462
[Epoch 133; Iter    30/   40] train: loss: 0.0015670
[Epoch 133] ogbg-molclintox: 0.940029 val loss: 0.183209
[Epoch 133] ogbg-molclintox: 0.717069 test loss: 0.400399
[Epoch 134; Iter    20/   40] train: loss: 0.0035409
[Epoch 134] ogbg-molclintox: 0.940802 val loss: 0.190110
[Epoch 134] ogbg-molclintox: 0.700304 test loss: 0.408871
[Epoch 135; Iter    10/   40] train: loss: 0.0371806
[Epoch 135; Iter    40/   40] train: loss: 0.0568594
[Epoch 135] ogbg-molclintox: 0.950299 val loss: 0.185461
[Epoch 135] ogbg-molclintox: 0.731408 test loss: 0.395616
[Epoch 136; Iter    30/   40] train: loss: 0.0211347
[Epoch 136] ogbg-molclintox: 0.940615 val loss: 0.188800
[Epoch 136] ogbg-molclintox: 0.726968 test loss: 0.382543
[Epoch 137; Iter    20/   40] train: loss: 0.0255847
[Epoch 137] ogbg-molclintox: 0.932343 val loss: 0.192438
[Epoch 137] ogbg-molclintox: 0.715078 test loss: 0.397813
[Epoch 138; Iter    10/   40] train: loss: 0.0037469
[Epoch 138; Iter    40/   40] train: loss: 0.0377157
[Epoch 138] ogbg-molclintox: 0.946743 val loss: 0.197247
[Epoch 138] ogbg-molclintox: 0.717370 test loss: 0.395504
[Epoch 139; Iter    30/   40] train: loss: 0.1093602
[Epoch 139] ogbg-molclintox: 0.935220 val loss: 0.196779
[Epoch 139] ogbg-molclintox: 0.721394 test loss: 0.395156
[Epoch 140; Iter    20/   40] train: loss: 0.0019533
[Epoch 140] ogbg-molclintox: 0.949194 val loss: 0.203966
[Epoch 140] ogbg-molclintox: 0.707733 test loss: 0.389007
[Epoch 141; Iter    10/   40] train: loss: 0.0173007
[Epoch 141; Iter    40/   40] train: loss: 0.0027443
[Epoch 141] ogbg-molclintox: 0.942973 val loss: 0.196193
[Epoch 141] ogbg-molclintox: 0.697616 test loss: 0.397813
[Epoch 142; Iter    30/   40] train: loss: 0.0205418
[Epoch 142] ogbg-molclintox: 0.947449 val loss: 0.184818
[Epoch 142] ogbg-molclintox: 0.719506 test loss: 0.381425
[Epoch 143; Iter    20/   40] train: loss: 0.0125713
[Epoch 143] ogbg-molclintox: 0.930625 val loss: 0.198717
[Epoch 143] ogbg-molclintox: 0.689192 test loss: 0.411743
[Epoch 144; Iter    10/   40] train: loss: 0.0029712
[Epoch 144; Iter    40/   40] train: loss: 0.0079317
[Epoch 144] ogbg-molclintox: 0.944624 val loss: 0.206978
[Epoch 144] ogbg-molclintox: 0.692691 test loss: 0.405117
[Epoch 145; Iter    30/   40] train: loss: 0.0880367
[Epoch 145] ogbg-molclintox: 0.939936 val loss: 0.208622
[Epoch 145] ogbg-molclintox: 0.682484 test loss: 0.398435
[Epoch 146; Iter    20/   40] train: loss: 0.0200677
[Epoch 146] ogbg-molclintox: 0.936965 val loss: 0.201284
[Epoch 146] ogbg-molclintox: 0.682345 test loss: 0.401292
[Epoch 147; Iter    10/   40] train: loss: 0.0016376
[Epoch 147; Iter    40/   40] train: loss: 0.0787617
[Epoch 147] ogbg-molclintox: 0.946010 val loss: 0.198483
[Epoch 147] ogbg-molclintox: 0.660509 test loss: 0.430571
[Epoch 148; Iter    30/   40] train: loss: 0.0614414
[Epoch 148] ogbg-molclintox: 0.942453 val loss: 0.194941
[Epoch 148] ogbg-molclintox: 0.681132 test loss: 0.418110
[Epoch 149; Iter    20/   40] train: loss: 0.0029770
[Epoch 149] ogbg-molclintox: 0.948554 val loss: 0.191264
[Epoch 149] ogbg-molclintox: 0.691134 test loss: 0.398625
[Epoch 150; Iter    10/   40] train: loss: 0.0288500
[Epoch 150; Iter    40/   40] train: loss: 0.0073253
[Epoch 150] ogbg-molclintox: 0.934607 val loss: 0.195346
[Epoch 150] ogbg-molclintox: 0.701550 test loss: 0.406801
[Epoch 151; Iter    30/   40] train: loss: 0.0035275
[Epoch 151] ogbg-molclintox: 0.937978 val loss: 0.202064
[Epoch 151] ogbg-molclintox: 0.699924 test loss: 0.403463
[Epoch 152; Iter    20/   40] train: loss: 0.0292794
[Epoch 152] ogbg-molclintox: 0.944198 val loss: 0.202822
[Epoch 152] ogbg-molclintox: 0.704551 test loss: 0.397231
[Epoch 153; Iter    10/   40] train: loss: 0.0062650
[Epoch 153; Iter    40/   40] train: loss: 0.0041792
[Epoch 153] ogbg-molclintox: 0.936379 val loss: 0.204867
[Epoch 153] ogbg-molclintox: 0.714005 test loss: 0.398325
[Epoch 154; Iter    30/   40] train: loss: 0.0258165
[Epoch 154] ogbg-molclintox: 0.937578 val loss: 0.202030
[Epoch 154] ogbg-molclintox: 0.710138 test loss: 0.399033
[Epoch 155; Iter    20/   40] train: loss: 0.0093577
[Epoch 155] ogbg-molclintox: 0.941108 val loss: 0.206530
[Epoch 155] ogbg-molclintox: 0.700009 test loss: 0.406166
[Epoch 156; Iter    10/   40] train: loss: 0.1035613
[Epoch 156; Iter    40/   40] train: loss: 0.0042535
[Epoch 156] ogbg-molclintox: 0.942973 val loss: 0.196056
[Epoch 156] ogbg-molclintox: 0.735478 test loss: 0.377487
[Epoch 157; Iter    30/   40] train: loss: 0.0620232
[Epoch 157] ogbg-molclintox: 0.936192 val loss: 0.202123
[Epoch 157] ogbg-molclintox: 0.723090 test loss: 0.395832
[Epoch 158; Iter    20/   40] train: loss: 0.0023949
[Epoch 158] ogbg-molclintox: 0.938217 val loss: 0.197616
[Epoch 158] ogbg-molclintox: 0.716647 test loss: 0.393347
[Epoch 159; Iter    10/   40] train: loss: 0.0016730
[Epoch 159; Iter    40/   40] train: loss: 0.0018830
[Epoch 159] ogbg-molclintox: 0.936805 val loss: 0.212039
[Epoch 159] ogbg-molclintox: 0.728103 test loss: 0.392631
[Epoch 160; Iter    30/   40] train: loss: 0.0012802
[Epoch 160] ogbg-molclintox: 0.942013 val loss: 0.195579
[Epoch 160] ogbg-molclintox: 0.727427 test loss: 0.392763
[Epoch 161; Iter    20/   40] train: loss: 0.0141967
[Epoch 161] ogbg-molclintox: 0.950166 val loss: 0.188569
[Epoch 161] ogbg-molclintox: 0.735324 test loss: 0.380860
[Epoch 162; Iter    10/   40] train: loss: 0.0530439
[Epoch 162; Iter    40/   40] train: loss: 0.0153520
[Epoch 162] ogbg-molclintox: 0.945331 val loss: 0.191965
[Epoch 162] ogbg-molclintox: 0.725231 test loss: 0.390395
[Epoch 163; Iter    30/   40] train: loss: 0.0018816
[Epoch 163] ogbg-molclintox: 0.944438 val loss: 0.186552
[Epoch 163] ogbg-molclintox: 0.712858 test loss: 0.412984
[Epoch 164; Iter    20/   40] train: loss: 0.0643915
[Epoch 164] ogbg-molclintox: 0.946769 val loss: 0.199263
[Epoch 164] ogbg-molclintox: 0.709926 test loss: 0.423588
[Epoch 120] ogbg-molclintox: 0.745930 test loss: 0.363862
[Epoch 121; Iter    30/   40] train: loss: 0.0012461
[Epoch 121] ogbg-molclintox: 0.927015 val loss: 0.201959
[Epoch 121] ogbg-molclintox: 0.683842 test loss: 0.357395
[Epoch 122; Iter    20/   40] train: loss: 0.0182232
[Epoch 122] ogbg-molclintox: 0.936365 val loss: 0.219195
[Epoch 122] ogbg-molclintox: 0.759207 test loss: 0.353548
[Epoch 123; Iter    10/   40] train: loss: 0.0024556
[Epoch 123; Iter    40/   40] train: loss: 0.0273408
[Epoch 123] ogbg-molclintox: 0.945264 val loss: 0.194330
[Epoch 123] ogbg-molclintox: 0.718379 test loss: 0.359012
[Epoch 124; Iter    30/   40] train: loss: 0.1324564
[Epoch 124] ogbg-molclintox: 0.937099 val loss: 0.211277
[Epoch 124] ogbg-molclintox: 0.716726 test loss: 0.363854
[Epoch 125; Iter    20/   40] train: loss: 0.0022072
[Epoch 125] ogbg-molclintox: 0.931877 val loss: 0.202987
[Epoch 125] ogbg-molclintox: 0.711284 test loss: 0.368405
[Epoch 126; Iter    10/   40] train: loss: 0.0485312
[Epoch 126; Iter    40/   40] train: loss: 0.0031251
[Epoch 126] ogbg-molclintox: 0.934101 val loss: 0.218482
[Epoch 126] ogbg-molclintox: 0.731584 test loss: 0.375255
[Epoch 127; Iter    30/   40] train: loss: 0.0157791
[Epoch 127] ogbg-molclintox: 0.932169 val loss: 0.221525
[Epoch 127] ogbg-molclintox: 0.720484 test loss: 0.373590
[Epoch 128; Iter    20/   40] train: loss: 0.0009398
[Epoch 128] ogbg-molclintox: 0.926161 val loss: 0.219700
[Epoch 128] ogbg-molclintox: 0.710252 test loss: 0.374125
[Epoch 129; Iter    10/   40] train: loss: 0.0476621
[Epoch 129; Iter    40/   40] train: loss: 0.0035218
[Epoch 129] ogbg-molclintox: 0.935912 val loss: 0.226613
[Epoch 129] ogbg-molclintox: 0.740380 test loss: 0.383830
[Epoch 130; Iter    30/   40] train: loss: 0.0027103
[Epoch 130] ogbg-molclintox: 0.922272 val loss: 0.218454
[Epoch 130] ogbg-molclintox: 0.724846 test loss: 0.376562
[Epoch 131; Iter    20/   40] train: loss: 0.0026174
[Epoch 131] ogbg-molclintox: 0.937310 val loss: 0.214328
[Epoch 131] ogbg-molclintox: 0.746153 test loss: 0.365481
[Epoch 132; Iter    10/   40] train: loss: 0.0050437
[Epoch 132; Iter    40/   40] train: loss: 0.0936612
[Epoch 132] ogbg-molclintox: 0.942985 val loss: 0.211764
[Epoch 132] ogbg-molclintox: 0.725479 test loss: 0.375249
[Epoch 133; Iter    30/   40] train: loss: 0.0962118
[Epoch 133] ogbg-molclintox: 0.936858 val loss: 0.208289
[Epoch 133] ogbg-molclintox: 0.748463 test loss: 0.360959
[Epoch 134; Iter    20/   40] train: loss: 0.0448631
[Epoch 134] ogbg-molclintox: 0.941520 val loss: 0.210195
[Epoch 134] ogbg-molclintox: 0.755913 test loss: 0.362381
[Epoch 135; Iter    10/   40] train: loss: 0.0047459
[Epoch 135; Iter    40/   40] train: loss: 0.0574925
[Epoch 135] ogbg-molclintox: 0.935939 val loss: 0.210209
[Epoch 135] ogbg-molclintox: 0.749839 test loss: 0.366121
[Epoch 136; Iter    30/   40] train: loss: 0.0315845
[Epoch 136] ogbg-molclintox: 0.936765 val loss: 0.209165
[Epoch 136] ogbg-molclintox: 0.731889 test loss: 0.364476
[Epoch 137; Iter    20/   40] train: loss: 0.0034155
[Epoch 137] ogbg-molclintox: 0.923164 val loss: 0.215118
[Epoch 137] ogbg-molclintox: 0.712177 test loss: 0.386458
[Epoch 138; Iter    10/   40] train: loss: 0.0138820
[Epoch 138; Iter    40/   40] train: loss: 0.0038346
[Epoch 138] ogbg-molclintox: 0.938057 val loss: 0.210907
[Epoch 138] ogbg-molclintox: 0.742141 test loss: 0.340554
[Epoch 139; Iter    30/   40] train: loss: 0.0016642
[Epoch 139] ogbg-molclintox: 0.942346 val loss: 0.213979
[Epoch 139] ogbg-molclintox: 0.771652 test loss: 0.350671
[Epoch 140; Iter    20/   40] train: loss: 0.0511204
[Epoch 140] ogbg-molclintox: 0.924256 val loss: 0.221968
[Epoch 140] ogbg-molclintox: 0.755467 test loss: 0.369261
[Epoch 141; Iter    10/   40] train: loss: 0.0357096
[Epoch 141; Iter    40/   40] train: loss: 0.0361484
[Epoch 141] ogbg-molclintox: 0.937418 val loss: 0.216175
[Epoch 141] ogbg-molclintox: 0.736036 test loss: 0.368447
[Epoch 142; Iter    30/   40] train: loss: 0.0766065
[Epoch 142] ogbg-molclintox: 0.933474 val loss: 0.219765
[Epoch 142] ogbg-molclintox: 0.729835 test loss: 0.362112
[Epoch 143; Iter    20/   40] train: loss: 0.0886225
[Epoch 143] ogbg-molclintox: 0.943292 val loss: 0.221385
[Epoch 143] ogbg-molclintox: 0.702790 test loss: 0.394816
[Epoch 144; Iter    10/   40] train: loss: 0.0105442
[Epoch 144; Iter    40/   40] train: loss: 0.0016852
[Epoch 144] ogbg-molclintox: 0.932076 val loss: 0.221028
[Epoch 144] ogbg-molclintox: 0.710355 test loss: 0.382994
[Epoch 145; Iter    30/   40] train: loss: 0.0045135
[Epoch 145] ogbg-molclintox: 0.926654 val loss: 0.229289
[Epoch 145] ogbg-molclintox: 0.697457 test loss: 0.395541
[Epoch 146; Iter    20/   40] train: loss: 0.0020935
[Epoch 146] ogbg-molclintox: 0.929864 val loss: 0.233010
[Epoch 146] ogbg-molclintox: 0.706349 test loss: 0.391610
[Epoch 147; Iter    10/   40] train: loss: 0.0011722
[Epoch 147; Iter    40/   40] train: loss: 0.0054903
[Epoch 147] ogbg-molclintox: 0.934101 val loss: 0.224853
[Epoch 147] ogbg-molclintox: 0.696347 test loss: 0.386184
[Epoch 148; Iter    30/   40] train: loss: 0.0673947
[Epoch 148] ogbg-molclintox: 0.936391 val loss: 0.234783
[Epoch 148] ogbg-molclintox: 0.725997 test loss: 0.410925
[Epoch 149; Iter    20/   40] train: loss: 0.0431111
[Epoch 149] ogbg-molclintox: 0.932502 val loss: 0.236392
[Epoch 149] ogbg-molclintox: 0.671547 test loss: 0.413290
[Epoch 150; Iter    10/   40] train: loss: 0.0044287
[Epoch 150; Iter    40/   40] train: loss: 0.0044694
[Epoch 150] ogbg-molclintox: 0.940161 val loss: 0.224388
[Epoch 150] ogbg-molclintox: 0.698305 test loss: 0.397716
[Epoch 151; Iter    30/   40] train: loss: 0.0171942
[Epoch 151] ogbg-molclintox: 0.938536 val loss: 0.225157
[Epoch 151] ogbg-molclintox: 0.712677 test loss: 0.390682
[Epoch 152; Iter    20/   40] train: loss: 0.0279672
[Epoch 152] ogbg-molclintox: 0.927933 val loss: 0.232316
[Epoch 152] ogbg-molclintox: 0.692179 test loss: 0.398923
[Epoch 153; Iter    10/   40] train: loss: 0.0026849
[Epoch 153; Iter    40/   40] train: loss: 0.0019699
[Epoch 153] ogbg-molclintox: 0.932169 val loss: 0.230635
[Epoch 153] ogbg-molclintox: 0.704147 test loss: 0.401949
[Epoch 154; Iter    30/   40] train: loss: 0.0436211
[Epoch 154] ogbg-molclintox: 0.936551 val loss: 0.226782
[Epoch 154] ogbg-molclintox: 0.703707 test loss: 0.404136
[Epoch 155; Iter    20/   40] train: loss: 0.0210627
[Epoch 155] ogbg-molclintox: 0.931769 val loss: 0.235963
[Epoch 155] ogbg-molclintox: 0.681413 test loss: 0.416123
[Epoch 156; Iter    10/   40] train: loss: 0.0020070
[Epoch 156; Iter    40/   40] train: loss: 0.0027277
[Epoch 156] ogbg-molclintox: 0.933208 val loss: 0.234853
[Epoch 156] ogbg-molclintox: 0.702570 test loss: 0.411838
[Epoch 157; Iter    30/   40] train: loss: 0.0067375
[Epoch 157] ogbg-molclintox: 0.928825 val loss: 0.243355
[Epoch 157] ogbg-molclintox: 0.696408 test loss: 0.418518
[Epoch 158; Iter    20/   40] train: loss: 0.0320290
[Epoch 158] ogbg-molclintox: 0.924416 val loss: 0.228317
[Epoch 158] ogbg-molclintox: 0.699852 test loss: 0.407606
[Epoch 159; Iter    10/   40] train: loss: 0.0425623
[Epoch 159; Iter    40/   40] train: loss: 0.0014511
[Epoch 159] ogbg-molclintox: 0.931223 val loss: 0.225994
[Epoch 159] ogbg-molclintox: 0.716780 test loss: 0.394729
[Epoch 160; Iter    30/   40] train: loss: 0.0298604
[Epoch 160] ogbg-molclintox: 0.926348 val loss: 0.228164
[Epoch 160] ogbg-molclintox: 0.723766 test loss: 0.401479
[Epoch 161; Iter    20/   40] train: loss: 0.0089001
[Epoch 161] ogbg-molclintox: 0.927413 val loss: 0.230527
[Epoch 161] ogbg-molclintox: 0.728839 test loss: 0.392017
[Epoch 162; Iter    10/   40] train: loss: 0.0236552
[Epoch 162; Iter    40/   40] train: loss: 0.0886489
[Epoch 162] ogbg-molclintox: 0.928572 val loss: 0.228322
[Epoch 162] ogbg-molclintox: 0.732067 test loss: 0.385840
[Epoch 163; Iter    30/   40] train: loss: 0.0012735
[Epoch 163] ogbg-molclintox: 0.933301 val loss: 0.226758
[Epoch 163] ogbg-molclintox: 0.718180 test loss: 0.391417
[Epoch 164; Iter    20/   40] train: loss: 0.0114389
[Epoch 164] ogbg-molclintox: 0.936338 val loss: 0.224801
[Epoch 164] ogbg-molclintox: 0.735041 test loss: 0.387664
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 165; Iter    10/   40] train: loss: 0.0018063
[Epoch 165; Iter    40/   40] train: loss: 0.0118717
[Epoch 165] ogbg-molclintox: 0.935113 val loss: 0.227926
[Epoch 165] ogbg-molclintox: 0.748729 test loss: 0.378705
[Epoch 166; Iter    30/   40] train: loss: 0.0590694
[Epoch 166] ogbg-molclintox: 0.929931 val loss: 0.220995
[Epoch 166] ogbg-molclintox: 0.732181 test loss: 0.389525
[Epoch 167; Iter    20/   40] train: loss: 0.0536343
[Epoch 167] ogbg-molclintox: 0.933887 val loss: 0.227945
[Epoch 167] ogbg-molclintox: 0.731940 test loss: 0.394106
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 167 epochs. Best model checkpoint was in epoch 107.
Statistics on  val_best_checkpoint
mean_pred: 0.2695152759552002
std_pred: 7.159238338470459
mean_targets: 0.5101351737976074
std_targets: 0.5007438659667969
prcauc: 0.801825866620139
rocauc: 0.953442393144308
ogbg-molclintox: 0.953442393144308
OGBNanLabelBCEWithLogitsLoss: 0.17855651453137397
Statistics on  test
mean_pred: 0.23802505433559418
std_pred: 6.967879772186279
mean_targets: 0.5101351737976074
std_targets: 0.5007438063621521
prcauc: 0.6785863380183659
rocauc: 0.7884055953170916
ogbg-molclintox: 0.7884055953170916
OGBNanLabelBCEWithLogitsLoss: 0.2951913267374039
Statistics on  train
mean_pred: 0.2629960775375366
std_pred: 7.210867881774902
mean_targets: 0.5050804018974304
std_targets: 0.5000800490379333
prcauc: 0.9945744593937637
rocauc: 0.9988708622837836
ogbg-molclintox: 0.9988708622837836
OGBNanLabelBCEWithLogitsLoss: 0.023043146132840774
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 165; Iter    10/   40] train: loss: 0.0015730
[Epoch 165; Iter    40/   40] train: loss: 0.0062394
[Epoch 165] ogbg-molclintox: 0.951671 val loss: 0.198223
[Epoch 165] ogbg-molclintox: 0.717440 test loss: 0.400238
[Epoch 166; Iter    30/   40] train: loss: 0.0027521
[Epoch 166] ogbg-molclintox: 0.947901 val loss: 0.191664
[Epoch 166] ogbg-molclintox: 0.718384 test loss: 0.395859
[Epoch 167; Iter    20/   40] train: loss: 0.0255762
[Epoch 167] ogbg-molclintox: 0.947195 val loss: 0.186814
[Epoch 167] ogbg-molclintox: 0.715717 test loss: 0.403628
[Epoch 168; Iter    10/   40] train: loss: 0.0359534
[Epoch 168; Iter    40/   40] train: loss: 0.0090638
[Epoch 168] ogbg-molclintox: 0.947662 val loss: 0.192361
[Epoch 168] ogbg-molclintox: 0.712478 test loss: 0.410893
[Epoch 169; Iter    30/   40] train: loss: 0.0009061
[Epoch 169] ogbg-molclintox: 0.946316 val loss: 0.191446
[Epoch 169] ogbg-molclintox: 0.718281 test loss: 0.395124
[Epoch 170; Iter    20/   40] train: loss: 0.0019760
[Epoch 170] ogbg-molclintox: 0.942853 val loss: 0.194340
[Epoch 170] ogbg-molclintox: 0.711429 test loss: 0.399681
[Epoch 171; Iter    10/   40] train: loss: 0.0102452
[Epoch 171; Iter    40/   40] train: loss: 0.0635571
[Epoch 171] ogbg-molclintox: 0.942786 val loss: 0.190442
[Epoch 171] ogbg-molclintox: 0.714562 test loss: 0.410330
[Epoch 172; Iter    30/   40] train: loss: 0.0025149
[Epoch 172] ogbg-molclintox: 0.947595 val loss: 0.198901
[Epoch 172] ogbg-molclintox: 0.710505 test loss: 0.413436
[Epoch 173; Iter    20/   40] train: loss: 0.0008161
[Epoch 173] ogbg-molclintox: 0.942573 val loss: 0.200948
[Epoch 173] ogbg-molclintox: 0.702385 test loss: 0.415610
[Epoch 174; Iter    10/   40] train: loss: 0.0257651
[Epoch 174; Iter    40/   40] train: loss: 0.0022232
[Epoch 174] ogbg-molclintox: 0.946582 val loss: 0.195821
[Epoch 174] ogbg-molclintox: 0.701607 test loss: 0.413347
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 174 epochs. Best model checkpoint was in epoch 114.
Statistics on  val_best_checkpoint
mean_pred: 0.24900715053081512
std_pred: 7.455382823944092
mean_targets: 0.5101351737976074
std_targets: 0.5007438659667969
prcauc: 0.8480423427991165
rocauc: 0.9624609136220436
ogbg-molclintox: 0.9624609136220436
OGBNanLabelBCEWithLogitsLoss: 0.16504466719925404
Statistics on  test
mean_pred: 0.26324063539505005
std_pred: 7.729283332824707
mean_targets: 0.5101351737976074
std_targets: 0.5007438063621521
prcauc: 0.6805229350533898
rocauc: 0.7350581216229026
ogbg-molclintox: 0.7350581216229026
OGBNanLabelBCEWithLogitsLoss: 0.3543199524283409
Statistics on  train
mean_pred: 0.2562851309776306
std_pred: 7.657311916351318
mean_targets: 0.5050804018974304
std_targets: 0.5000800490379333
prcauc: 0.9939423935205849
rocauc: 0.9988326458389356
ogbg-molclintox: 0.9988326458389356
OGBNanLabelBCEWithLogitsLoss: 0.021587079839082434
All runs completed.
