>>> Starting run for dataset: clintox
Running RANDOM configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml on cuda:0
Running RANDOM configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml on cuda:1
Running RANDOM configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml --seed 6 --device cuda:1
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.8/PNA_ogbg-molclintox_GraphCL_clintox_random=0.8_5_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.8
logdir: runs/split/GraphCL/clintox/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6939538
[Epoch 1] ogbg-molclintox: 0.483944 val loss: 0.693128
[Epoch 1] ogbg-molclintox: 0.482179 test loss: 0.693366
[Epoch 2; Iter    20/   40] train: loss: 0.6929414
[Epoch 2] ogbg-molclintox: 0.489634 val loss: 0.693148
[Epoch 2] ogbg-molclintox: 0.472177 test loss: 0.693835
[Epoch 3; Iter    10/   40] train: loss: 0.6928035
[Epoch 3; Iter    40/   40] train: loss: 0.6929012
[Epoch 3] ogbg-molclintox: 0.485972 val loss: 0.693172
[Epoch 3] ogbg-molclintox: 0.462368 test loss: 0.694040
[Epoch 4; Iter    30/   40] train: loss: 0.6937736
[Epoch 4] ogbg-molclintox: 0.484586 val loss: 0.692584
[Epoch 4] ogbg-molclintox: 0.461245 test loss: 0.693486
[Epoch 5; Iter    20/   40] train: loss: 0.6928896
[Epoch 5] ogbg-molclintox: 0.489435 val loss: 0.692102
[Epoch 5] ogbg-molclintox: 0.461119 test loss: 0.692972
[Epoch 6; Iter    10/   40] train: loss: 0.6911948
[Epoch 6; Iter    40/   40] train: loss: 0.6925873
[Epoch 6] ogbg-molclintox: 0.481536 val loss: 0.691289
[Epoch 6] ogbg-molclintox: 0.465534 test loss: 0.692240
[Epoch 7; Iter    30/   40] train: loss: 0.6906635
[Epoch 7] ogbg-molclintox: 0.487105 val loss: 0.690955
[Epoch 7] ogbg-molclintox: 0.467218 test loss: 0.691868
[Epoch 8; Iter    20/   40] train: loss: 0.6899452
[Epoch 8] ogbg-molclintox: 0.505089 val loss: 0.689900
[Epoch 8] ogbg-molclintox: 0.474016 test loss: 0.690809
[Epoch 9; Iter    10/   40] train: loss: 0.6897000
[Epoch 9; Iter    40/   40] train: loss: 0.6884021
[Epoch 9] ogbg-molclintox: 0.489729 val loss: 0.689338
[Epoch 9] ogbg-molclintox: 0.473594 test loss: 0.690214
[Epoch 10; Iter    30/   40] train: loss: 0.6858788
[Epoch 10] ogbg-molclintox: 0.500932 val loss: 0.688071
[Epoch 10] ogbg-molclintox: 0.464449 test loss: 0.688982
[Epoch 11; Iter    20/   40] train: loss: 0.6860239
[Epoch 11] ogbg-molclintox: 0.491167 val loss: 0.687218
[Epoch 11] ogbg-molclintox: 0.476556 test loss: 0.688099
[Epoch 12; Iter    10/   40] train: loss: 0.6857347
[Epoch 12; Iter    40/   40] train: loss: 0.6842384
[Epoch 12] ogbg-molclintox: 0.496509 val loss: 0.685119
[Epoch 12] ogbg-molclintox: 0.492139 test loss: 0.686046
[Epoch 13; Iter    30/   40] train: loss: 0.6832786
[Epoch 13] ogbg-molclintox: 0.489915 val loss: 0.685008
[Epoch 13] ogbg-molclintox: 0.476888 test loss: 0.685866
[Epoch 14; Iter    20/   40] train: loss: 0.6829433
[Epoch 14] ogbg-molclintox: 0.493939 val loss: 0.682986
[Epoch 14] ogbg-molclintox: 0.477666 test loss: 0.683874
[Epoch 15; Iter    10/   40] train: loss: 0.6826453
[Epoch 15; Iter    40/   40] train: loss: 0.6857769
[Epoch 15] ogbg-molclintox: 0.493486 val loss: 0.681421
[Epoch 15] ogbg-molclintox: 0.480562 test loss: 0.682327
[Epoch 16; Iter    30/   40] train: loss: 0.6807623
[Epoch 16] ogbg-molclintox: 0.496509 val loss: 0.680169
[Epoch 16] ogbg-molclintox: 0.487192 test loss: 0.681033
[Epoch 17; Iter    20/   40] train: loss: 0.6797625
[Epoch 17] ogbg-molclintox: 0.499254 val loss: 0.678382
[Epoch 17] ogbg-molclintox: 0.483801 test loss: 0.679209
[Epoch 18; Iter    10/   40] train: loss: 0.6756529
[Epoch 18; Iter    40/   40] train: loss: 0.6603218
[Epoch 18] ogbg-molclintox: 0.695898 val loss: 0.687146
[Epoch 18] ogbg-molclintox: 0.641485 test loss: 0.688550
[Epoch 19; Iter    30/   40] train: loss: 0.6375937
[Epoch 19] ogbg-molclintox: 0.807533 val loss: 0.582614
[Epoch 19] ogbg-molclintox: 0.721594 test loss: 0.596377
[Epoch 20; Iter    20/   40] train: loss: 0.5793634
[Epoch 20] ogbg-molclintox: 0.908162 val loss: 0.544431
[Epoch 20] ogbg-molclintox: 0.738147 test loss: 0.556683
[Epoch 21; Iter    10/   40] train: loss: 0.5360961
[Epoch 21; Iter    40/   40] train: loss: 0.4749138
[Epoch 21] ogbg-molclintox: 0.889472 val loss: 0.428567
[Epoch 21] ogbg-molclintox: 0.737851 test loss: 0.446566
[Epoch 22; Iter    30/   40] train: loss: 0.4556606
[Epoch 22] ogbg-molclintox: 0.779582 val loss: 0.454857
[Epoch 22] ogbg-molclintox: 0.659379 test loss: 0.488851
[Epoch 23; Iter    20/   40] train: loss: 0.3600092
[Epoch 23] ogbg-molclintox: 0.846127 val loss: 0.319724
[Epoch 23] ogbg-molclintox: 0.690990 test loss: 0.344416
[Epoch 24; Iter    10/   40] train: loss: 0.2757050
[Epoch 24; Iter    40/   40] train: loss: 0.3516679
[Epoch 24] ogbg-molclintox: 0.867545 val loss: 0.242952
[Epoch 24] ogbg-molclintox: 0.664736 test loss: 0.265467
[Epoch 25; Iter    30/   40] train: loss: 0.2755344
[Epoch 25] ogbg-molclintox: 0.903140 val loss: 0.216481
[Epoch 25] ogbg-molclintox: 0.810469 test loss: 0.227970
[Epoch 26; Iter    20/   40] train: loss: 0.1683889
[Epoch 26] ogbg-molclintox: 0.932687 val loss: 0.195828
[Epoch 26] ogbg-molclintox: 0.798081 test loss: 0.215807
[Epoch 27; Iter    10/   40] train: loss: 0.1186060
[Epoch 27; Iter    40/   40] train: loss: 0.3808987
[Epoch 27] ogbg-molclintox: 0.904860 val loss: 0.208498
[Epoch 27] ogbg-molclintox: 0.753223 test loss: 0.224664
[Epoch 28; Iter    30/   40] train: loss: 0.1358717
[Epoch 28] ogbg-molclintox: 0.852082 val loss: 0.201541
[Epoch 28] ogbg-molclintox: 0.714925 test loss: 0.229145
[Epoch 29; Iter    20/   40] train: loss: 0.1615106
[Epoch 29] ogbg-molclintox: 0.866122 val loss: 0.195726
[Epoch 29] ogbg-molclintox: 0.752240 test loss: 0.222982
[Epoch 30; Iter    10/   40] train: loss: 0.1308805
[Epoch 30; Iter    40/   40] train: loss: 0.1990899
[Epoch 30] ogbg-molclintox: 0.921564 val loss: 0.179477
[Epoch 30] ogbg-molclintox: 0.756541 test loss: 0.218274
[Epoch 31; Iter    30/   40] train: loss: 0.1733576
[Epoch 31] ogbg-molclintox: 0.919140 val loss: 0.182421
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.8/PNA_ogbg-molclintox_GraphCL_clintox_random=0.8_6_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.8
logdir: runs/split/GraphCL/clintox/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6948159
[Epoch 1] ogbg-molclintox: 0.515938 val loss: 0.691972
[Epoch 1] ogbg-molclintox: 0.453685 test loss: 0.692795
[Epoch 2; Iter    20/   40] train: loss: 0.6935070
[Epoch 2] ogbg-molclintox: 0.553690 val loss: 0.691397
[Epoch 2] ogbg-molclintox: 0.451253 test loss: 0.693054
[Epoch 3; Iter    10/   40] train: loss: 0.6929153
[Epoch 3; Iter    40/   40] train: loss: 0.6926970
[Epoch 3] ogbg-molclintox: 0.569237 val loss: 0.691382
[Epoch 3] ogbg-molclintox: 0.449636 test loss: 0.692679
[Epoch 4; Iter    30/   40] train: loss: 0.6921946
[Epoch 4] ogbg-molclintox: 0.559046 val loss: 0.689525
[Epoch 4] ogbg-molclintox: 0.442439 test loss: 0.691071
[Epoch 5; Iter    20/   40] train: loss: 0.6933192
[Epoch 5] ogbg-molclintox: 0.562110 val loss: 0.689993
[Epoch 5] ogbg-molclintox: 0.447887 test loss: 0.691263
[Epoch 6; Iter    10/   40] train: loss: 0.6938995
[Epoch 6; Iter    40/   40] train: loss: 0.6919587
[Epoch 6] ogbg-molclintox: 0.556195 val loss: 0.688675
[Epoch 6] ogbg-molclintox: 0.444454 test loss: 0.689885
[Epoch 7; Iter    30/   40] train: loss: 0.6903229
[Epoch 7] ogbg-molclintox: 0.553371 val loss: 0.687446
[Epoch 7] ogbg-molclintox: 0.442886 test loss: 0.688930
[Epoch 8; Iter    20/   40] train: loss: 0.6889400
[Epoch 8] ogbg-molclintox: 0.574433 val loss: 0.687837
[Epoch 8] ogbg-molclintox: 0.445130 test loss: 0.688940
[Epoch 9; Iter    10/   40] train: loss: 0.6873439
[Epoch 9; Iter    40/   40] train: loss: 0.6881154
[Epoch 9] ogbg-molclintox: 0.555530 val loss: 0.684912
[Epoch 9] ogbg-molclintox: 0.443652 test loss: 0.686220
[Epoch 10; Iter    30/   40] train: loss: 0.6868325
[Epoch 10] ogbg-molclintox: 0.565774 val loss: 0.684517
[Epoch 10] ogbg-molclintox: 0.445335 test loss: 0.685864
[Epoch 11; Iter    20/   40] train: loss: 0.6868557
[Epoch 11] ogbg-molclintox: 0.555716 val loss: 0.682424
[Epoch 11] ogbg-molclintox: 0.444243 test loss: 0.683782
[Epoch 12; Iter    10/   40] train: loss: 0.6860372
[Epoch 12; Iter    40/   40] train: loss: 0.6843064
[Epoch 12] ogbg-molclintox: 0.568772 val loss: 0.680848
[Epoch 12] ogbg-molclintox: 0.449443 test loss: 0.682008
[Epoch 13; Iter    30/   40] train: loss: 0.6842630
[Epoch 13] ogbg-molclintox: 0.567360 val loss: 0.678835
[Epoch 13] ogbg-molclintox: 0.449902 test loss: 0.679963
[Epoch 14; Iter    20/   40] train: loss: 0.6821042
[Epoch 14] ogbg-molclintox: 0.570850 val loss: 0.678354
[Epoch 14] ogbg-molclintox: 0.450336 test loss: 0.679299
[Epoch 15; Iter    10/   40] train: loss: 0.6812012
[Epoch 15; Iter    40/   40] train: loss: 0.6758235
[Epoch 15] ogbg-molclintox: 0.569466 val loss: 0.677053
[Epoch 15] ogbg-molclintox: 0.452248 test loss: 0.677884
[Epoch 16; Iter    30/   40] train: loss: 0.6764941
[Epoch 16] ogbg-molclintox: 0.568173 val loss: 0.674008
[Epoch 16] ogbg-molclintox: 0.452568 test loss: 0.674971
[Epoch 17; Iter    20/   40] train: loss: 0.6736500
[Epoch 17] ogbg-molclintox: 0.586411 val loss: 0.671993
[Epoch 17] ogbg-molclintox: 0.461665 test loss: 0.672846
[Epoch 18; Iter    10/   40] train: loss: 0.6703832
[Epoch 18; Iter    40/   40] train: loss: 0.6695425
[Epoch 18] ogbg-molclintox: 0.672533 val loss: 0.645719
[Epoch 18] ogbg-molclintox: 0.581745 test loss: 0.649820
[Epoch 19; Iter    30/   40] train: loss: 0.6298910
[Epoch 19] ogbg-molclintox: 0.847164 val loss: 0.605318
[Epoch 19] ogbg-molclintox: 0.704539 test loss: 0.621872
[Epoch 20; Iter    20/   40] train: loss: 0.6060765
[Epoch 20] ogbg-molclintox: 0.855438 val loss: 0.601974
[Epoch 20] ogbg-molclintox: 0.649847 test loss: 0.634080
[Epoch 21; Iter    10/   40] train: loss: 0.5259871
[Epoch 21; Iter    40/   40] train: loss: 0.5263920
[Epoch 21] ogbg-molclintox: 0.904100 val loss: 0.468013
[Epoch 21] ogbg-molclintox: 0.753633 test loss: 0.497549
[Epoch 22; Iter    30/   40] train: loss: 0.4188975
[Epoch 22] ogbg-molclintox: 0.845034 val loss: 0.445084
[Epoch 22] ogbg-molclintox: 0.712653 test loss: 0.464859
[Epoch 23; Iter    20/   40] train: loss: 0.3825892
[Epoch 23] ogbg-molclintox: 0.927357 val loss: 0.317089
[Epoch 23] ogbg-molclintox: 0.828227 test loss: 0.330033
[Epoch 24; Iter    10/   40] train: loss: 0.3422710
[Epoch 24; Iter    40/   40] train: loss: 0.2248852
[Epoch 24] ogbg-molclintox: 0.917221 val loss: 0.269571
[Epoch 24] ogbg-molclintox: 0.795312 test loss: 0.293038
[Epoch 25; Iter    30/   40] train: loss: 0.2889006
[Epoch 25] ogbg-molclintox: 0.867571 val loss: 0.226652
[Epoch 25] ogbg-molclintox: 0.808591 test loss: 0.230019
[Epoch 26; Iter    20/   40] train: loss: 0.1886672
[Epoch 26] ogbg-molclintox: 0.927998 val loss: 0.206894
[Epoch 26] ogbg-molclintox: 0.804958 test loss: 0.224627
[Epoch 27; Iter    10/   40] train: loss: 0.1739454
[Epoch 27; Iter    40/   40] train: loss: 0.1467246
[Epoch 27] ogbg-molclintox: 0.901090 val loss: 0.241719
[Epoch 27] ogbg-molclintox: 0.722215 test loss: 0.275709
[Epoch 28; Iter    30/   40] train: loss: 0.1819365
[Epoch 28] ogbg-molclintox: 0.928584 val loss: 0.182447
[Epoch 28] ogbg-molclintox: 0.763207 test loss: 0.216373
[Epoch 29; Iter    20/   40] train: loss: 0.2224100
[Epoch 29] ogbg-molclintox: 0.879044 val loss: 0.202694
[Epoch 29] ogbg-molclintox: 0.735870 test loss: 0.232587
[Epoch 30; Iter    10/   40] train: loss: 0.2501534
[Epoch 30; Iter    40/   40] train: loss: 0.0959477
[Epoch 30] ogbg-molclintox: 0.919846 val loss: 0.175879
[Epoch 30] ogbg-molclintox: 0.803574 test loss: 0.206922
[Epoch 31; Iter    30/   40] train: loss: 0.1107182
[Epoch 31] ogbg-molclintox: 0.926760 val loss: 0.170125
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.7/PNA_ogbg-molclintox_GraphCL_clintox_random=0.7_4_26-05_09-40-07
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.7
logdir: runs/split/GraphCL/clintox/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6924596
[Epoch 1] ogbg-molclintox: 0.534736 val loss: 0.693044
[Epoch 1] ogbg-molclintox: 0.501157 test loss: 0.693059
[Epoch 2; Iter    25/   35] train: loss: 0.6926534
[Epoch 2] ogbg-molclintox: 0.522750 val loss: 0.692465
[Epoch 2] ogbg-molclintox: 0.502228 test loss: 0.692503
[Epoch 3; Iter    20/   35] train: loss: 0.6930229
[Epoch 3] ogbg-molclintox: 0.523705 val loss: 0.692085
[Epoch 3] ogbg-molclintox: 0.521826 test loss: 0.691810
[Epoch 4; Iter    15/   35] train: loss: 0.6932816
[Epoch 4] ogbg-molclintox: 0.523258 val loss: 0.692184
[Epoch 4] ogbg-molclintox: 0.506754 test loss: 0.692034
[Epoch 5; Iter    10/   35] train: loss: 0.6940373
[Epoch 5] ogbg-molclintox: 0.526783 val loss: 0.691360
[Epoch 5] ogbg-molclintox: 0.517940 test loss: 0.691153
[Epoch 6; Iter     5/   35] train: loss: 0.6917152
[Epoch 6; Iter    35/   35] train: loss: 0.6919735
[Epoch 6] ogbg-molclintox: 0.530442 val loss: 0.690863
[Epoch 6] ogbg-molclintox: 0.517513 test loss: 0.690625
[Epoch 7; Iter    30/   35] train: loss: 0.6912555
[Epoch 7] ogbg-molclintox: 0.527713 val loss: 0.690819
[Epoch 7] ogbg-molclintox: 0.517706 test loss: 0.690608
[Epoch 8; Iter    25/   35] train: loss: 0.6914126
[Epoch 8] ogbg-molclintox: 0.524990 val loss: 0.689625
[Epoch 8] ogbg-molclintox: 0.512397 test loss: 0.689504
[Epoch 9; Iter    20/   35] train: loss: 0.6889780
[Epoch 9] ogbg-molclintox: 0.521650 val loss: 0.688644
[Epoch 9] ogbg-molclintox: 0.514816 test loss: 0.688488
[Epoch 10; Iter    15/   35] train: loss: 0.6886296
[Epoch 10] ogbg-molclintox: 0.535347 val loss: 0.687579
[Epoch 10] ogbg-molclintox: 0.521705 test loss: 0.687542
[Epoch 11; Iter    10/   35] train: loss: 0.6877925
[Epoch 11] ogbg-molclintox: 0.544741 val loss: 0.686108
[Epoch 11] ogbg-molclintox: 0.522678 test loss: 0.685944
[Epoch 12; Iter     5/   35] train: loss: 0.6878964
[Epoch 12; Iter    35/   35] train: loss: 0.6855303
[Epoch 12] ogbg-molclintox: 0.540398 val loss: 0.685302
[Epoch 12] ogbg-molclintox: 0.518594 test loss: 0.685213
[Epoch 13; Iter    30/   35] train: loss: 0.6878111
[Epoch 13] ogbg-molclintox: 0.547919 val loss: 0.683972
[Epoch 13] ogbg-molclintox: 0.525525 test loss: 0.683860
[Epoch 14; Iter    25/   35] train: loss: 0.6855491
[Epoch 14] ogbg-molclintox: 0.552693 val loss: 0.682404
[Epoch 14] ogbg-molclintox: 0.530253 test loss: 0.682381
[Epoch 15; Iter    20/   35] train: loss: 0.6817786
[Epoch 15] ogbg-molclintox: 0.556611 val loss: 0.681797
[Epoch 15] ogbg-molclintox: 0.531592 test loss: 0.681673
[Epoch 16; Iter    15/   35] train: loss: 0.6812351
[Epoch 16] ogbg-molclintox: 0.556333 val loss: 0.679900
[Epoch 16] ogbg-molclintox: 0.521038 test loss: 0.680047
[Epoch 17; Iter    10/   35] train: loss: 0.6787716
[Epoch 17] ogbg-molclintox: 0.554484 val loss: 0.677937
[Epoch 17] ogbg-molclintox: 0.526542 test loss: 0.678080
[Epoch 18; Iter     5/   35] train: loss: 0.6801142
[Epoch 18; Iter    35/   35] train: loss: 0.6785434
[Epoch 18] ogbg-molclintox: 0.569770 val loss: 0.676393
[Epoch 18] ogbg-molclintox: 0.533845 test loss: 0.676511
[Epoch 19; Iter    30/   35] train: loss: 0.6770627
[Epoch 19] ogbg-molclintox: 0.566508 val loss: 0.674995
[Epoch 19] ogbg-molclintox: 0.537559 test loss: 0.675048
[Epoch 20; Iter    25/   35] train: loss: 0.6731452
[Epoch 20] ogbg-molclintox: 0.667834 val loss: 0.672425
[Epoch 20] ogbg-molclintox: 0.652486 test loss: 0.674404
[Epoch 21; Iter    20/   35] train: loss: 0.6604497
[Epoch 21] ogbg-molclintox: 0.740545 val loss: 0.641049
[Epoch 21] ogbg-molclintox: 0.711548 test loss: 0.644318
[Epoch 22; Iter    15/   35] train: loss: 0.6324486
[Epoch 22] ogbg-molclintox: 0.767672 val loss: 0.578303
[Epoch 22] ogbg-molclintox: 0.754505 test loss: 0.586882
[Epoch 23; Iter    10/   35] train: loss: 0.5904067
[Epoch 23] ogbg-molclintox: 0.856418 val loss: 0.521238
[Epoch 23] ogbg-molclintox: 0.757563 test loss: 0.538902
[Epoch 24; Iter     5/   35] train: loss: 0.5369068
[Epoch 24; Iter    35/   35] train: loss: 0.4867036
[Epoch 24] ogbg-molclintox: 0.781700 val loss: 0.487363
[Epoch 24] ogbg-molclintox: 0.708765 test loss: 0.512144
[Epoch 25; Iter    30/   35] train: loss: 0.4374111
[Epoch 25] ogbg-molclintox: 0.785991 val loss: 0.427937
[Epoch 25] ogbg-molclintox: 0.734246 test loss: 0.430416
[Epoch 26; Iter    25/   35] train: loss: 0.3908710
[Epoch 26] ogbg-molclintox: 0.866051 val loss: 0.325471
[Epoch 26] ogbg-molclintox: 0.780993 test loss: 0.342283
[Epoch 27; Iter    20/   35] train: loss: 0.3651855
[Epoch 27] ogbg-molclintox: 0.818411 val loss: 0.282339
[Epoch 27] ogbg-molclintox: 0.711844 test loss: 0.311002
[Epoch 28; Iter    15/   35] train: loss: 0.2834003
[Epoch 28] ogbg-molclintox: 0.894514 val loss: 0.259071
[Epoch 28] ogbg-molclintox: 0.753339 test loss: 0.280976
[Epoch 29; Iter    10/   35] train: loss: 0.1806623
[Epoch 29] ogbg-molclintox: 0.850224 val loss: 0.229864
[Epoch 29] ogbg-molclintox: 0.746840 test loss: 0.258485
[Epoch 30; Iter     5/   35] train: loss: 0.1984996
[Epoch 30; Iter    35/   35] train: loss: 0.1486446
[Epoch 30] ogbg-molclintox: 0.896304 val loss: 0.222435
[Epoch 30] ogbg-molclintox: 0.781871 test loss: 0.253282
[Epoch 31; Iter    30/   35] train: loss: 0.2061088
[Epoch 31] ogbg-molclintox: 0.858997 val loss: 0.200188
[Epoch 31] ogbg-molclintox: 0.755861 test loss: 0.239571
[Epoch 32; Iter    25/   35] train: loss: 0.2769920
[Epoch 32] ogbg-molclintox: 0.921361 val loss: 0.176997
[Epoch 32] ogbg-molclintox: 0.799152 test loss: 0.215715
[Epoch 33; Iter    20/   35] train: loss: 0.1016700
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.6/PNA_ogbg-molclintox_GraphCL_clintox_random=0.6_5_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.6
logdir: runs/split/GraphCL/clintox/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6943949
[Epoch 1] ogbg-molclintox: 0.465551 val loss: 0.693193
[Epoch 1] ogbg-molclintox: 0.482986 test loss: 0.693217
[Epoch 2; Iter    30/   30] train: loss: 0.6911585
[Epoch 2] ogbg-molclintox: 0.479494 val loss: 0.692962
[Epoch 2] ogbg-molclintox: 0.492878 test loss: 0.693375
[Epoch 3; Iter    30/   30] train: loss: 0.6934375
[Epoch 3] ogbg-molclintox: 0.501840 val loss: 0.692269
[Epoch 3] ogbg-molclintox: 0.487704 test loss: 0.693222
[Epoch 4; Iter    30/   30] train: loss: 0.6919125
[Epoch 4] ogbg-molclintox: 0.511069 val loss: 0.692361
[Epoch 4] ogbg-molclintox: 0.484518 test loss: 0.693458
[Epoch 5; Iter    30/   30] train: loss: 0.6924133
[Epoch 5] ogbg-molclintox: 0.512171 val loss: 0.691948
[Epoch 5] ogbg-molclintox: 0.487941 test loss: 0.693032
[Epoch 6; Iter    30/   30] train: loss: 0.6916101
[Epoch 6] ogbg-molclintox: 0.507717 val loss: 0.691105
[Epoch 6] ogbg-molclintox: 0.488053 test loss: 0.692269
[Epoch 7; Iter    30/   30] train: loss: 0.6916285
[Epoch 7] ogbg-molclintox: 0.512488 val loss: 0.691182
[Epoch 7] ogbg-molclintox: 0.493443 test loss: 0.692320
[Epoch 8; Iter    30/   30] train: loss: 0.6893245
[Epoch 8] ogbg-molclintox: 0.508368 val loss: 0.690606
[Epoch 8] ogbg-molclintox: 0.487882 test loss: 0.691798
[Epoch 9; Iter    30/   30] train: loss: 0.6916779
[Epoch 9] ogbg-molclintox: 0.510076 val loss: 0.689637
[Epoch 9] ogbg-molclintox: 0.488315 test loss: 0.690857
[Epoch 10; Iter    30/   30] train: loss: 0.6898124
[Epoch 10] ogbg-molclintox: 0.515304 val loss: 0.689100
[Epoch 10] ogbg-molclintox: 0.489216 test loss: 0.690465
[Epoch 11; Iter    30/   30] train: loss: 0.6904230
[Epoch 11] ogbg-molclintox: 0.510074 val loss: 0.688508
[Epoch 11] ogbg-molclintox: 0.492288 test loss: 0.689791
[Epoch 12; Iter    30/   30] train: loss: 0.6883496
[Epoch 12] ogbg-molclintox: 0.513215 val loss: 0.687496
[Epoch 12] ogbg-molclintox: 0.485750 test loss: 0.688913
[Epoch 13; Iter    30/   30] train: loss: 0.6888112
[Epoch 13] ogbg-molclintox: 0.513612 val loss: 0.686664
[Epoch 13] ogbg-molclintox: 0.491745 test loss: 0.688062
[Epoch 14; Iter    30/   30] train: loss: 0.6882302
[Epoch 14] ogbg-molclintox: 0.517845 val loss: 0.686256
[Epoch 14] ogbg-molclintox: 0.486768 test loss: 0.687824
[Epoch 15; Iter    30/   30] train: loss: 0.6835864
[Epoch 15] ogbg-molclintox: 0.514411 val loss: 0.685339
[Epoch 15] ogbg-molclintox: 0.490027 test loss: 0.686845
[Epoch 16; Iter    30/   30] train: loss: 0.6846826
[Epoch 16] ogbg-molclintox: 0.520815 val loss: 0.684188
[Epoch 16] ogbg-molclintox: 0.492862 test loss: 0.685817
[Epoch 17; Iter    30/   30] train: loss: 0.6837499
[Epoch 17] ogbg-molclintox: 0.519486 val loss: 0.683085
[Epoch 17] ogbg-molclintox: 0.496095 test loss: 0.684822
[Epoch 18; Iter    30/   30] train: loss: 0.6833066
[Epoch 18] ogbg-molclintox: 0.525150 val loss: 0.682418
[Epoch 18] ogbg-molclintox: 0.489920 test loss: 0.684299
[Epoch 19; Iter    30/   30] train: loss: 0.6811544
[Epoch 19] ogbg-molclintox: 0.524549 val loss: 0.680884
[Epoch 19] ogbg-molclintox: 0.493146 test loss: 0.682774
[Epoch 20; Iter    30/   30] train: loss: 0.6815035
[Epoch 20] ogbg-molclintox: 0.523311 val loss: 0.679424
[Epoch 20] ogbg-molclintox: 0.492228 test loss: 0.681428
[Epoch 21; Iter    30/   30] train: loss: 0.6843925
[Epoch 21] ogbg-molclintox: 0.528007 val loss: 0.678242
[Epoch 21] ogbg-molclintox: 0.492415 test loss: 0.680301
[Epoch 22; Iter    30/   30] train: loss: 0.6770429
[Epoch 22] ogbg-molclintox: 0.528712 val loss: 0.677210
[Epoch 22] ogbg-molclintox: 0.491738 test loss: 0.679418
[Epoch 23; Iter    30/   30] train: loss: 0.6766433
[Epoch 23] ogbg-molclintox: 0.631370 val loss: 0.676115
[Epoch 23] ogbg-molclintox: 0.603121 test loss: 0.678729
[Epoch 24; Iter    30/   30] train: loss: 0.6652586
[Epoch 24] ogbg-molclintox: 0.690609 val loss: 0.646749
[Epoch 24] ogbg-molclintox: 0.622119 test loss: 0.655753
[Epoch 25; Iter    30/   30] train: loss: 0.6298357
[Epoch 25] ogbg-molclintox: 0.753593 val loss: 0.606150
[Epoch 25] ogbg-molclintox: 0.701959 test loss: 0.617291
[Epoch 26; Iter    30/   30] train: loss: 0.5695807
[Epoch 26] ogbg-molclintox: 0.789503 val loss: 0.582312
[Epoch 26] ogbg-molclintox: 0.745663 test loss: 0.592514
[Epoch 27; Iter    30/   30] train: loss: 0.5329029
[Epoch 27] ogbg-molclintox: 0.851601 val loss: 0.464991
[Epoch 27] ogbg-molclintox: 0.835267 test loss: 0.473251
[Epoch 28; Iter    30/   30] train: loss: 0.4570586
[Epoch 28] ogbg-molclintox: 0.870684 val loss: 0.505904
[Epoch 28] ogbg-molclintox: 0.812630 test loss: 0.516962
[Epoch 29; Iter    30/   30] train: loss: 0.4310862
[Epoch 29] ogbg-molclintox: 0.842296 val loss: 0.359408
[Epoch 29] ogbg-molclintox: 0.811567 test loss: 0.382881
[Epoch 30; Iter    30/   30] train: loss: 0.4044843
[Epoch 30] ogbg-molclintox: 0.882391 val loss: 0.384689
[Epoch 30] ogbg-molclintox: 0.807556 test loss: 0.402815
[Epoch 31; Iter    30/   30] train: loss: 0.3789767
[Epoch 31] ogbg-molclintox: 0.801750 val loss: 0.271581
[Epoch 31] ogbg-molclintox: 0.765200 test loss: 0.308367
[Epoch 32; Iter    30/   30] train: loss: 0.2203977
[Epoch 32] ogbg-molclintox: 0.866554 val loss: 0.208519
[Epoch 32] ogbg-molclintox: 0.861669 test loss: 0.241987
[Epoch 33; Iter    30/   30] train: loss: 0.1821494
[Epoch 33] ogbg-molclintox: 0.795671 val loss: 0.202104
[Epoch 33] ogbg-molclintox: 0.782156 test loss: 0.245906
[Epoch 34; Iter    30/   30] train: loss: 0.2492421
[Epoch 34] ogbg-molclintox: 0.834094 val loss: 0.194461
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.8/PNA_ogbg-molclintox_GraphCL_clintox_random=0.8_4_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.8
logdir: runs/split/GraphCL/clintox/random/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/   40] train: loss: 0.6939337
[Epoch 1] ogbg-molclintox: 0.544530 val loss: 0.692806
[Epoch 1] ogbg-molclintox: 0.519411 test loss: 0.692968
[Epoch 2; Iter    20/   40] train: loss: 0.6929772
[Epoch 2] ogbg-molclintox: 0.535868 val loss: 0.692168
[Epoch 2] ogbg-molclintox: 0.540206 test loss: 0.692597
[Epoch 3; Iter    10/   40] train: loss: 0.6942297
[Epoch 3; Iter    40/   40] train: loss: 0.6928920
[Epoch 3] ogbg-molclintox: 0.521692 val loss: 0.691417
[Epoch 3] ogbg-molclintox: 0.544453 test loss: 0.692123
[Epoch 4; Iter    30/   40] train: loss: 0.6920100
[Epoch 4] ogbg-molclintox: 0.528168 val loss: 0.691406
[Epoch 4] ogbg-molclintox: 0.550220 test loss: 0.691906
[Epoch 5; Iter    20/   40] train: loss: 0.6912211
[Epoch 5] ogbg-molclintox: 0.525502 val loss: 0.690347
[Epoch 5] ogbg-molclintox: 0.560988 test loss: 0.690873
[Epoch 6; Iter    10/   40] train: loss: 0.6907828
[Epoch 6; Iter    40/   40] train: loss: 0.6905506
[Epoch 6] ogbg-molclintox: 0.522972 val loss: 0.689856
[Epoch 6] ogbg-molclintox: 0.553194 test loss: 0.690372
[Epoch 7; Iter    30/   40] train: loss: 0.6904207
[Epoch 7] ogbg-molclintox: 0.527994 val loss: 0.689256
[Epoch 7] ogbg-molclintox: 0.555884 test loss: 0.689645
[Epoch 8; Iter    20/   40] train: loss: 0.6899489
[Epoch 8] ogbg-molclintox: 0.531538 val loss: 0.688286
[Epoch 8] ogbg-molclintox: 0.560107 test loss: 0.688689
[Epoch 9; Iter    10/   40] train: loss: 0.6899433
[Epoch 9; Iter    40/   40] train: loss: 0.6872671
[Epoch 9] ogbg-molclintox: 0.545566 val loss: 0.686817
[Epoch 9] ogbg-molclintox: 0.552211 test loss: 0.687398
[Epoch 10; Iter    30/   40] train: loss: 0.6870906
[Epoch 10] ogbg-molclintox: 0.533029 val loss: 0.685672
[Epoch 10] ogbg-molclintox: 0.551354 test loss: 0.686251
[Epoch 11; Iter    20/   40] train: loss: 0.6852155
[Epoch 11] ogbg-molclintox: 0.539930 val loss: 0.684081
[Epoch 11] ogbg-molclintox: 0.560970 test loss: 0.684573
[Epoch 12; Iter    10/   40] train: loss: 0.6846348
[Epoch 12; Iter    40/   40] train: loss: 0.6862974
[Epoch 12] ogbg-molclintox: 0.559153 val loss: 0.683360
[Epoch 12] ogbg-molclintox: 0.549773 test loss: 0.683722
[Epoch 13; Iter    30/   40] train: loss: 0.6833839
[Epoch 13] ogbg-molclintox: 0.538625 val loss: 0.681162
[Epoch 13] ogbg-molclintox: 0.550220 test loss: 0.681360
[Epoch 14; Iter    20/   40] train: loss: 0.6811811
[Epoch 14] ogbg-molclintox: 0.553160 val loss: 0.679678
[Epoch 14] ogbg-molclintox: 0.560747 test loss: 0.679886
[Epoch 15; Iter    10/   40] train: loss: 0.6810223
[Epoch 15; Iter    40/   40] train: loss: 0.6780828
[Epoch 15] ogbg-molclintox: 0.542928 val loss: 0.677897
[Epoch 15] ogbg-molclintox: 0.567153 test loss: 0.678165
[Epoch 16; Iter    30/   40] train: loss: 0.6773713
[Epoch 16] ogbg-molclintox: 0.567413 val loss: 0.676394
[Epoch 16] ogbg-molclintox: 0.558629 test loss: 0.676660
[Epoch 17; Iter    20/   40] train: loss: 0.6748694
[Epoch 17] ogbg-molclintox: 0.559713 val loss: 0.674083
[Epoch 17] ogbg-molclintox: 0.561078 test loss: 0.674198
[Epoch 18; Iter    10/   40] train: loss: 0.6730936
[Epoch 18; Iter    40/   40] train: loss: 0.6605854
[Epoch 18] ogbg-molclintox: 0.675783 val loss: 0.677823
[Epoch 18] ogbg-molclintox: 0.624359 test loss: 0.681342
[Epoch 19; Iter    30/   40] train: loss: 0.6342812
[Epoch 19] ogbg-molclintox: 0.815286 val loss: 0.578333
[Epoch 19] ogbg-molclintox: 0.752993 test loss: 0.586632
[Epoch 20; Iter    20/   40] train: loss: 0.5914561
[Epoch 20] ogbg-molclintox: 0.855290 val loss: 0.545682
[Epoch 20] ogbg-molclintox: 0.747431 test loss: 0.562901
[Epoch 21; Iter    10/   40] train: loss: 0.5381044
[Epoch 21; Iter    40/   40] train: loss: 0.5726997
[Epoch 21] ogbg-molclintox: 0.877857 val loss: 0.494151
[Epoch 21] ogbg-molclintox: 0.733309 test loss: 0.507076
[Epoch 22; Iter    30/   40] train: loss: 0.4394750
[Epoch 22] ogbg-molclintox: 0.864123 val loss: 0.339027
[Epoch 22] ogbg-molclintox: 0.755250 test loss: 0.360349
[Epoch 23; Iter    20/   40] train: loss: 0.3782018
[Epoch 23] ogbg-molclintox: 0.898919 val loss: 0.371168
[Epoch 23] ogbg-molclintox: 0.741767 test loss: 0.389840
[Epoch 24; Iter    10/   40] train: loss: 0.3134274
[Epoch 24; Iter    40/   40] train: loss: 0.2420462
[Epoch 24] ogbg-molclintox: 0.930396 val loss: 0.230984
[Epoch 24] ogbg-molclintox: 0.815534 test loss: 0.245611
[Epoch 25; Iter    30/   40] train: loss: 0.2703169
[Epoch 25] ogbg-molclintox: 0.916676 val loss: 0.237082
[Epoch 25] ogbg-molclintox: 0.805095 test loss: 0.266716
[Epoch 26; Iter    20/   40] train: loss: 0.2184308
[Epoch 26] ogbg-molclintox: 0.905473 val loss: 0.226059
[Epoch 26] ogbg-molclintox: 0.724610 test loss: 0.263438
[Epoch 27; Iter    10/   40] train: loss: 0.3877699
[Epoch 27; Iter    40/   40] train: loss: 0.1694276
[Epoch 27] ogbg-molclintox: 0.933007 val loss: 0.192615
[Epoch 27] ogbg-molclintox: 0.823455 test loss: 0.212253
[Epoch 28; Iter    30/   40] train: loss: 0.1511199
[Epoch 28] ogbg-molclintox: 0.860168 val loss: 0.201654
[Epoch 28] ogbg-molclintox: 0.726511 test loss: 0.227100
[Epoch 29; Iter    20/   40] train: loss: 0.3852637
[Epoch 29] ogbg-molclintox: 0.819550 val loss: 0.210646
[Epoch 29] ogbg-molclintox: 0.660749 test loss: 0.241215
[Epoch 30; Iter    10/   40] train: loss: 0.3171668
[Epoch 30; Iter    40/   40] train: loss: 0.0896938
[Epoch 30] ogbg-molclintox: 0.877885 val loss: 0.195261
[Epoch 30] ogbg-molclintox: 0.700115 test loss: 0.228777
[Epoch 31; Iter    30/   40] train: loss: 0.1201605
[Epoch 31] ogbg-molclintox: 0.932168 val loss: 0.196712
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.6/PNA_ogbg-molclintox_GraphCL_clintox_random=0.6_4_26-05_09-40-07
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.6
logdir: runs/split/GraphCL/clintox/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6926510
[Epoch 1] ogbg-molclintox: 0.445089 val loss: 0.693336
[Epoch 1] ogbg-molclintox: 0.528055 test loss: 0.693099
[Epoch 2; Iter    30/   30] train: loss: 0.6925676
[Epoch 2] ogbg-molclintox: 0.420353 val loss: 0.693182
[Epoch 2] ogbg-molclintox: 0.534868 test loss: 0.692438
[Epoch 3; Iter    30/   30] train: loss: 0.6928513
[Epoch 3] ogbg-molclintox: 0.424711 val loss: 0.693283
[Epoch 3] ogbg-molclintox: 0.542990 test loss: 0.692232
[Epoch 4; Iter    30/   30] train: loss: 0.6921172
[Epoch 4] ogbg-molclintox: 0.426744 val loss: 0.693259
[Epoch 4] ogbg-molclintox: 0.533926 test loss: 0.692222
[Epoch 5; Iter    30/   30] train: loss: 0.6927811
[Epoch 5] ogbg-molclintox: 0.430657 val loss: 0.692606
[Epoch 5] ogbg-molclintox: 0.540492 test loss: 0.691525
[Epoch 6; Iter    30/   30] train: loss: 0.6917250
[Epoch 6] ogbg-molclintox: 0.428694 val loss: 0.692477
[Epoch 6] ogbg-molclintox: 0.538625 test loss: 0.691400
[Epoch 7; Iter    30/   30] train: loss: 0.6925792
[Epoch 7] ogbg-molclintox: 0.437560 val loss: 0.691714
[Epoch 7] ogbg-molclintox: 0.540755 test loss: 0.690613
[Epoch 8; Iter    30/   30] train: loss: 0.6915971
[Epoch 8] ogbg-molclintox: 0.430585 val loss: 0.691052
[Epoch 8] ogbg-molclintox: 0.530704 test loss: 0.690091
[Epoch 9; Iter    30/   30] train: loss: 0.6896117
[Epoch 9] ogbg-molclintox: 0.435042 val loss: 0.690640
[Epoch 9] ogbg-molclintox: 0.539076 test loss: 0.689669
[Epoch 10; Iter    30/   30] train: loss: 0.6889240
[Epoch 10] ogbg-molclintox: 0.446850 val loss: 0.689422
[Epoch 10] ogbg-molclintox: 0.543248 test loss: 0.688533
[Epoch 11; Iter    30/   30] train: loss: 0.6873059
[Epoch 11] ogbg-molclintox: 0.445772 val loss: 0.688463
[Epoch 11] ogbg-molclintox: 0.549434 test loss: 0.687587
[Epoch 12; Iter    30/   30] train: loss: 0.6885934
[Epoch 12] ogbg-molclintox: 0.443247 val loss: 0.687764
[Epoch 12] ogbg-molclintox: 0.541378 test loss: 0.687073
[Epoch 13; Iter    30/   30] train: loss: 0.6874036
[Epoch 13] ogbg-molclintox: 0.456242 val loss: 0.686736
[Epoch 13] ogbg-molclintox: 0.542399 test loss: 0.686148
[Epoch 14; Iter    30/   30] train: loss: 0.6878742
[Epoch 14] ogbg-molclintox: 0.456593 val loss: 0.685681
[Epoch 14] ogbg-molclintox: 0.539227 test loss: 0.685142
[Epoch 15; Iter    30/   30] train: loss: 0.6854929
[Epoch 15] ogbg-molclintox: 0.463770 val loss: 0.684565
[Epoch 15] ogbg-molclintox: 0.545547 test loss: 0.684087
[Epoch 16; Iter    30/   30] train: loss: 0.6824688
[Epoch 16] ogbg-molclintox: 0.463973 val loss: 0.683262
[Epoch 16] ogbg-molclintox: 0.552856 test loss: 0.682868
[Epoch 17; Iter    30/   30] train: loss: 0.6844900
[Epoch 17] ogbg-molclintox: 0.466038 val loss: 0.682038
[Epoch 17] ogbg-molclintox: 0.545237 test loss: 0.681845
[Epoch 18; Iter    30/   30] train: loss: 0.6830730
[Epoch 18] ogbg-molclintox: 0.470188 val loss: 0.680653
[Epoch 18] ogbg-molclintox: 0.550205 test loss: 0.680494
[Epoch 19; Iter    30/   30] train: loss: 0.6781785
[Epoch 19] ogbg-molclintox: 0.470608 val loss: 0.679752
[Epoch 19] ogbg-molclintox: 0.553068 test loss: 0.679838
[Epoch 20; Iter    30/   30] train: loss: 0.6791903
[Epoch 20] ogbg-molclintox: 0.478998 val loss: 0.677809
[Epoch 20] ogbg-molclintox: 0.554969 test loss: 0.677893
[Epoch 21; Iter    30/   30] train: loss: 0.6774160
[Epoch 21] ogbg-molclintox: 0.486723 val loss: 0.676103
[Epoch 21] ogbg-molclintox: 0.555850 test loss: 0.676308
[Epoch 22; Iter    30/   30] train: loss: 0.6730893
[Epoch 22] ogbg-molclintox: 0.490269 val loss: 0.674924
[Epoch 22] ogbg-molclintox: 0.554887 test loss: 0.675205
[Epoch 23; Iter    30/   30] train: loss: 0.6753039
[Epoch 23] ogbg-molclintox: 0.612174 val loss: 0.672091
[Epoch 23] ogbg-molclintox: 0.581159 test loss: 0.673852
[Epoch 24; Iter    30/   30] train: loss: 0.6569563
[Epoch 24] ogbg-molclintox: 0.732632 val loss: 0.648332
[Epoch 24] ogbg-molclintox: 0.704691 test loss: 0.653089
[Epoch 25; Iter    30/   30] train: loss: 0.6304641
[Epoch 25] ogbg-molclintox: 0.837810 val loss: 0.650332
[Epoch 25] ogbg-molclintox: 0.760098 test loss: 0.648890
[Epoch 26; Iter    30/   30] train: loss: 0.5594557
[Epoch 26] ogbg-molclintox: 0.809035 val loss: 0.556366
[Epoch 26] ogbg-molclintox: 0.747122 test loss: 0.574336
[Epoch 27; Iter    30/   30] train: loss: 0.5272877
[Epoch 27] ogbg-molclintox: 0.821738 val loss: 0.508816
[Epoch 27] ogbg-molclintox: 0.829720 test loss: 0.509560
[Epoch 28; Iter    30/   30] train: loss: 0.4688393
[Epoch 28] ogbg-molclintox: 0.777016 val loss: 0.419418
[Epoch 28] ogbg-molclintox: 0.782793 test loss: 0.438667
[Epoch 29; Iter    30/   30] train: loss: 0.3918725
[Epoch 29] ogbg-molclintox: 0.836597 val loss: 0.437259
[Epoch 29] ogbg-molclintox: 0.761843 test loss: 0.459609
[Epoch 30; Iter    30/   30] train: loss: 0.3590471
[Epoch 30] ogbg-molclintox: 0.796557 val loss: 0.338216
[Epoch 30] ogbg-molclintox: 0.808270 test loss: 0.365185
[Epoch 31; Iter    30/   30] train: loss: 0.3038306
[Epoch 31] ogbg-molclintox: 0.831760 val loss: 0.327559
[Epoch 31] ogbg-molclintox: 0.818379 test loss: 0.353806
[Epoch 32; Iter    30/   30] train: loss: 0.2361138
[Epoch 32] ogbg-molclintox: 0.895890 val loss: 0.284951
[Epoch 32] ogbg-molclintox: 0.829709 test loss: 0.309326
[Epoch 33; Iter    30/   30] train: loss: 0.2906492
[Epoch 33] ogbg-molclintox: 0.744880 val loss: 0.218765
[Epoch 33] ogbg-molclintox: 0.674378 test loss: 0.274021
[Epoch 34; Iter    30/   30] train: loss: 0.1735387
[Epoch 34] ogbg-molclintox: 0.825999 val loss: 0.221794
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.7/PNA_ogbg-molclintox_GraphCL_clintox_random=0.7_5_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.7
logdir: runs/split/GraphCL/clintox/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6927400
[Epoch 1] ogbg-molclintox: 0.458358 val loss: 0.693270
[Epoch 1] ogbg-molclintox: 0.511068 test loss: 0.693214
[Epoch 2; Iter    25/   35] train: loss: 0.6919385
[Epoch 2] ogbg-molclintox: 0.479619 val loss: 0.693517
[Epoch 2] ogbg-molclintox: 0.518803 test loss: 0.693593
[Epoch 3; Iter    20/   35] train: loss: 0.6911297
[Epoch 3] ogbg-molclintox: 0.483091 val loss: 0.693183
[Epoch 3] ogbg-molclintox: 0.516377 test loss: 0.693464
[Epoch 4; Iter    15/   35] train: loss: 0.6925671
[Epoch 4] ogbg-molclintox: 0.476354 val loss: 0.692528
[Epoch 4] ogbg-molclintox: 0.509916 test loss: 0.692836
[Epoch 5; Iter    10/   35] train: loss: 0.6925056
[Epoch 5] ogbg-molclintox: 0.475186 val loss: 0.691735
[Epoch 5] ogbg-molclintox: 0.512545 test loss: 0.692125
[Epoch 6; Iter     5/   35] train: loss: 0.6916096
[Epoch 6; Iter    35/   35] train: loss: 0.6915948
[Epoch 6] ogbg-molclintox: 0.478508 val loss: 0.691664
[Epoch 6] ogbg-molclintox: 0.518303 test loss: 0.692062
[Epoch 7; Iter    30/   35] train: loss: 0.6913463
[Epoch 7] ogbg-molclintox: 0.475539 val loss: 0.691254
[Epoch 7] ogbg-molclintox: 0.515852 test loss: 0.691448
[Epoch 8; Iter    25/   35] train: loss: 0.6917493
[Epoch 8] ogbg-molclintox: 0.477562 val loss: 0.690339
[Epoch 8] ogbg-molclintox: 0.513252 test loss: 0.690685
[Epoch 9; Iter    20/   35] train: loss: 0.6891418
[Epoch 9] ogbg-molclintox: 0.480921 val loss: 0.690246
[Epoch 9] ogbg-molclintox: 0.518301 test loss: 0.690578
[Epoch 10; Iter    15/   35] train: loss: 0.6895577
[Epoch 10] ogbg-molclintox: 0.481724 val loss: 0.689407
[Epoch 10] ogbg-molclintox: 0.515451 test loss: 0.689819
[Epoch 11; Iter    10/   35] train: loss: 0.6892622
[Epoch 11] ogbg-molclintox: 0.486335 val loss: 0.688064
[Epoch 11] ogbg-molclintox: 0.526470 test loss: 0.688521
[Epoch 12; Iter     5/   35] train: loss: 0.6882226
[Epoch 12; Iter    35/   35] train: loss: 0.6866511
[Epoch 12] ogbg-molclintox: 0.480104 val loss: 0.687199
[Epoch 12] ogbg-molclintox: 0.518936 test loss: 0.687542
[Epoch 13; Iter    30/   35] train: loss: 0.6858510
[Epoch 13] ogbg-molclintox: 0.486722 val loss: 0.686430
[Epoch 13] ogbg-molclintox: 0.521175 test loss: 0.686921
[Epoch 14; Iter    25/   35] train: loss: 0.6855575
[Epoch 14] ogbg-molclintox: 0.489900 val loss: 0.685405
[Epoch 14] ogbg-molclintox: 0.521369 test loss: 0.685930
[Epoch 15; Iter    20/   35] train: loss: 0.6820197
[Epoch 15] ogbg-molclintox: 0.487671 val loss: 0.684101
[Epoch 15] ogbg-molclintox: 0.523575 test loss: 0.684614
[Epoch 16; Iter    15/   35] train: loss: 0.6840090
[Epoch 16] ogbg-molclintox: 0.488146 val loss: 0.682412
[Epoch 16] ogbg-molclintox: 0.522172 test loss: 0.683061
[Epoch 17; Iter    10/   35] train: loss: 0.6824463
[Epoch 17] ogbg-molclintox: 0.493728 val loss: 0.681553
[Epoch 17] ogbg-molclintox: 0.523260 test loss: 0.682223
[Epoch 18; Iter     5/   35] train: loss: 0.6812292
[Epoch 18; Iter    35/   35] train: loss: 0.6769408
[Epoch 18] ogbg-molclintox: 0.494764 val loss: 0.680209
[Epoch 18] ogbg-molclintox: 0.523197 test loss: 0.680823
[Epoch 19; Iter    30/   35] train: loss: 0.6794562
[Epoch 19] ogbg-molclintox: 0.490856 val loss: 0.678745
[Epoch 19] ogbg-molclintox: 0.527828 test loss: 0.679499
[Epoch 20; Iter    25/   35] train: loss: 0.6825219
[Epoch 20] ogbg-molclintox: 0.639793 val loss: 0.672862
[Epoch 20] ogbg-molclintox: 0.685734 test loss: 0.673288
[Epoch 21; Iter    20/   35] train: loss: 0.6627309
[Epoch 21] ogbg-molclintox: 0.748656 val loss: 0.649882
[Epoch 21] ogbg-molclintox: 0.706916 test loss: 0.653991
[Epoch 22; Iter    15/   35] train: loss: 0.6274340
[Epoch 22] ogbg-molclintox: 0.782486 val loss: 0.575777
[Epoch 22] ogbg-molclintox: 0.745929 test loss: 0.578415
[Epoch 23; Iter    10/   35] train: loss: 0.5875480
[Epoch 23] ogbg-molclintox: 0.854928 val loss: 0.518456
[Epoch 23] ogbg-molclintox: 0.766282 test loss: 0.530926
[Epoch 24; Iter     5/   35] train: loss: 0.5495838
[Epoch 24; Iter    35/   35] train: loss: 0.4359613
[Epoch 24] ogbg-molclintox: 0.843714 val loss: 0.465076
[Epoch 24] ogbg-molclintox: 0.745010 test loss: 0.485787
[Epoch 25; Iter    30/   35] train: loss: 0.4024941
[Epoch 25] ogbg-molclintox: 0.903303 val loss: 0.331488
[Epoch 25] ogbg-molclintox: 0.824291 test loss: 0.348244
[Epoch 26; Iter    25/   35] train: loss: 0.3570140
[Epoch 26] ogbg-molclintox: 0.855631 val loss: 0.253150
[Epoch 26] ogbg-molclintox: 0.758214 test loss: 0.276656
[Epoch 27; Iter    20/   35] train: loss: 0.3653599
[Epoch 27] ogbg-molclintox: 0.873697 val loss: 0.271976
[Epoch 27] ogbg-molclintox: 0.774364 test loss: 0.285623
[Epoch 28; Iter    15/   35] train: loss: 0.2885932
[Epoch 28] ogbg-molclintox: 0.848803 val loss: 0.252575
[Epoch 28] ogbg-molclintox: 0.779616 test loss: 0.276615
[Epoch 29; Iter    10/   35] train: loss: 0.2403037
[Epoch 29] ogbg-molclintox: 0.901973 val loss: 0.222113
[Epoch 29] ogbg-molclintox: 0.792062 test loss: 0.251329
[Epoch 30; Iter     5/   35] train: loss: 0.3227200
[Epoch 30; Iter    35/   35] train: loss: 0.3160594
[Epoch 30] ogbg-molclintox: 0.876994 val loss: 0.202413
[Epoch 30] ogbg-molclintox: 0.780216 test loss: 0.229703
[Epoch 31; Iter    30/   35] train: loss: 0.3147247
[Epoch 31] ogbg-molclintox: 0.821898 val loss: 0.191918
[Epoch 31] ogbg-molclintox: 0.726463 test loss: 0.232134
[Epoch 32; Iter    25/   35] train: loss: 0.2396459
[Epoch 32] ogbg-molclintox: 0.929540 val loss: 0.169643
[Epoch 32] ogbg-molclintox: 0.805945 test loss: 0.210940
[Epoch 33; Iter    20/   35] train: loss: 0.1699260
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.6/PNA_ogbg-molclintox_GraphCL_clintox_random=0.6_6_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.6
logdir: runs/split/GraphCL/clintox/random/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/   30] train: loss: 0.6944885
[Epoch 1] ogbg-molclintox: 0.456089 val loss: 0.692220
[Epoch 1] ogbg-molclintox: 0.483141 test loss: 0.692378
[Epoch 2; Iter    30/   30] train: loss: 0.6921912
[Epoch 2] ogbg-molclintox: 0.437621 val loss: 0.690835
[Epoch 2] ogbg-molclintox: 0.485908 test loss: 0.691115
[Epoch 3; Iter    30/   30] train: loss: 0.6928647
[Epoch 3] ogbg-molclintox: 0.429357 val loss: 0.691697
[Epoch 3] ogbg-molclintox: 0.493176 test loss: 0.691780
[Epoch 4; Iter    30/   30] train: loss: 0.6905674
[Epoch 4] ogbg-molclintox: 0.425482 val loss: 0.690612
[Epoch 4] ogbg-molclintox: 0.489799 test loss: 0.690837
[Epoch 5; Iter    30/   30] train: loss: 0.6921868
[Epoch 5] ogbg-molclintox: 0.430209 val loss: 0.689311
[Epoch 5] ogbg-molclintox: 0.495336 test loss: 0.689488
[Epoch 6; Iter    30/   30] train: loss: 0.6920914
[Epoch 6] ogbg-molclintox: 0.425153 val loss: 0.690153
[Epoch 6] ogbg-molclintox: 0.491321 test loss: 0.690359
[Epoch 7; Iter    30/   30] train: loss: 0.6933661
[Epoch 7] ogbg-molclintox: 0.430447 val loss: 0.689671
[Epoch 7] ogbg-molclintox: 0.497781 test loss: 0.689860
[Epoch 8; Iter    30/   30] train: loss: 0.6921408
[Epoch 8] ogbg-molclintox: 0.423793 val loss: 0.688658
[Epoch 8] ogbg-molclintox: 0.499416 test loss: 0.688851
[Epoch 9; Iter    30/   30] train: loss: 0.6904866
[Epoch 9] ogbg-molclintox: 0.434369 val loss: 0.687698
[Epoch 9] ogbg-molclintox: 0.494228 test loss: 0.688079
[Epoch 10; Iter    30/   30] train: loss: 0.6892426
[Epoch 10] ogbg-molclintox: 0.434319 val loss: 0.687063
[Epoch 10] ogbg-molclintox: 0.497983 test loss: 0.687474
[Epoch 11; Iter    30/   30] train: loss: 0.6909161
[Epoch 11] ogbg-molclintox: 0.437618 val loss: 0.686751
[Epoch 11] ogbg-molclintox: 0.494498 test loss: 0.687203
[Epoch 12; Iter    30/   30] train: loss: 0.6887357
[Epoch 12] ogbg-molclintox: 0.434284 val loss: 0.685078
[Epoch 12] ogbg-molclintox: 0.495360 test loss: 0.685560
[Epoch 13; Iter    30/   30] train: loss: 0.6856912
[Epoch 13] ogbg-molclintox: 0.435278 val loss: 0.683888
[Epoch 13] ogbg-molclintox: 0.495348 test loss: 0.684490
[Epoch 14; Iter    30/   30] train: loss: 0.6861019
[Epoch 14] ogbg-molclintox: 0.444099 val loss: 0.682478
[Epoch 14] ogbg-molclintox: 0.491026 test loss: 0.683244
[Epoch 15; Iter    30/   30] train: loss: 0.6871463
[Epoch 15] ogbg-molclintox: 0.450145 val loss: 0.681119
[Epoch 15] ogbg-molclintox: 0.501240 test loss: 0.681958
[Epoch 16; Iter    30/   30] train: loss: 0.6819797
[Epoch 16] ogbg-molclintox: 0.446421 val loss: 0.680160
[Epoch 16] ogbg-molclintox: 0.497698 test loss: 0.680993
[Epoch 17; Iter    30/   30] train: loss: 0.6939043
[Epoch 17] ogbg-molclintox: 0.445437 val loss: 0.679830
[Epoch 17] ogbg-molclintox: 0.501669 test loss: 0.680609
[Epoch 18; Iter    30/   30] train: loss: 0.6853001
[Epoch 18] ogbg-molclintox: 0.456339 val loss: 0.679147
[Epoch 18] ogbg-molclintox: 0.510043 test loss: 0.680053
[Epoch 19; Iter    30/   30] train: loss: 0.6825261
[Epoch 19] ogbg-molclintox: 0.461508 val loss: 0.675743
[Epoch 19] ogbg-molclintox: 0.502512 test loss: 0.676983
[Epoch 20; Iter    30/   30] train: loss: 0.6770541
[Epoch 20] ogbg-molclintox: 0.465186 val loss: 0.674475
[Epoch 20] ogbg-molclintox: 0.506674 test loss: 0.675660
[Epoch 21; Iter    30/   30] train: loss: 0.6739130
[Epoch 21] ogbg-molclintox: 0.469800 val loss: 0.672551
[Epoch 21] ogbg-molclintox: 0.502033 test loss: 0.673979
[Epoch 22; Iter    30/   30] train: loss: 0.6721067
[Epoch 22] ogbg-molclintox: 0.468982 val loss: 0.671463
[Epoch 22] ogbg-molclintox: 0.502760 test loss: 0.672914
[Epoch 23; Iter    30/   30] train: loss: 0.6736417
[Epoch 23] ogbg-molclintox: 0.631654 val loss: 0.673508
[Epoch 23] ogbg-molclintox: 0.561403 test loss: 0.676114
[Epoch 24; Iter    30/   30] train: loss: 0.6550820
[Epoch 24] ogbg-molclintox: 0.733274 val loss: 0.627542
[Epoch 24] ogbg-molclintox: 0.690970 test loss: 0.634649
[Epoch 25; Iter    30/   30] train: loss: 0.6428035
[Epoch 25] ogbg-molclintox: 0.760951 val loss: 0.603669
[Epoch 25] ogbg-molclintox: 0.744136 test loss: 0.612025
[Epoch 26; Iter    30/   30] train: loss: 0.5547044
[Epoch 26] ogbg-molclintox: 0.742559 val loss: 0.553695
[Epoch 26] ogbg-molclintox: 0.694694 test loss: 0.572580
[Epoch 27; Iter    30/   30] train: loss: 0.4995417
[Epoch 27] ogbg-molclintox: 0.758852 val loss: 0.474895
[Epoch 27] ogbg-molclintox: 0.745847 test loss: 0.492959
[Epoch 28; Iter    30/   30] train: loss: 0.4749804
[Epoch 28] ogbg-molclintox: 0.815169 val loss: 0.510342
[Epoch 28] ogbg-molclintox: 0.741134 test loss: 0.525929
[Epoch 29; Iter    30/   30] train: loss: 0.3767053
[Epoch 29] ogbg-molclintox: 0.833076 val loss: 0.343238
[Epoch 29] ogbg-molclintox: 0.850700 test loss: 0.361234
[Epoch 30; Iter    30/   30] train: loss: 0.3451578
[Epoch 30] ogbg-molclintox: 0.886310 val loss: 0.274542
[Epoch 30] ogbg-molclintox: 0.829949 test loss: 0.306506
[Epoch 31; Iter    30/   30] train: loss: 0.2889362
[Epoch 31] ogbg-molclintox: 0.779673 val loss: 0.247984
[Epoch 31] ogbg-molclintox: 0.823067 test loss: 0.274572
[Epoch 32; Iter    30/   30] train: loss: 0.3194297
[Epoch 32] ogbg-molclintox: 0.862398 val loss: 0.228753
[Epoch 32] ogbg-molclintox: 0.855722 test loss: 0.260937
[Epoch 33; Iter    30/   30] train: loss: 0.2260381
[Epoch 33] ogbg-molclintox: 0.845619 val loss: 0.215079
[Epoch 33] ogbg-molclintox: 0.751606 test loss: 0.261374
[Epoch 34; Iter    30/   30] train: loss: 0.1913710
[Epoch 34] ogbg-molclintox: 0.783642 val loss: 0.220427
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/clintox/random/train_prop=0.7/PNA_ogbg-molclintox_GraphCL_clintox_random=0.7_6_26-05_09-40-08
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/clintox/random/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_clintox_random=0.7
logdir: runs/split/GraphCL/clintox/random/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-molclintox
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-molclintox
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 2
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: True
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/   35] train: loss: 0.6963204
[Epoch 1] ogbg-molclintox: 0.499481 val loss: 0.692149
[Epoch 1] ogbg-molclintox: 0.456795 test loss: 0.692783
[Epoch 2; Iter    25/   35] train: loss: 0.6921481
[Epoch 2] ogbg-molclintox: 0.496047 val loss: 0.690592
[Epoch 2] ogbg-molclintox: 0.448694 test loss: 0.692262
[Epoch 3; Iter    20/   35] train: loss: 0.6943997
[Epoch 3] ogbg-molclintox: 0.486487 val loss: 0.689954
[Epoch 3] ogbg-molclintox: 0.440604 test loss: 0.691613
[Epoch 4; Iter    15/   35] train: loss: 0.6940733
[Epoch 4] ogbg-molclintox: 0.495575 val loss: 0.689673
[Epoch 4] ogbg-molclintox: 0.442878 test loss: 0.691378
[Epoch 5; Iter    10/   35] train: loss: 0.6915022
[Epoch 5] ogbg-molclintox: 0.494323 val loss: 0.689761
[Epoch 5] ogbg-molclintox: 0.443145 test loss: 0.691493
[Epoch 6; Iter     5/   35] train: loss: 0.6908042
[Epoch 6; Iter    35/   35] train: loss: 0.6911550
[Epoch 6] ogbg-molclintox: 0.491348 val loss: 0.689067
[Epoch 6] ogbg-molclintox: 0.443088 test loss: 0.690719
[Epoch 7; Iter    30/   35] train: loss: 0.6898725
[Epoch 7] ogbg-molclintox: 0.493798 val loss: 0.688139
[Epoch 7] ogbg-molclintox: 0.446906 test loss: 0.689813
[Epoch 8; Iter    25/   35] train: loss: 0.6924613
[Epoch 8] ogbg-molclintox: 0.492809 val loss: 0.687400
[Epoch 8] ogbg-molclintox: 0.450184 test loss: 0.688978
[Epoch 9; Iter    20/   35] train: loss: 0.6901209
[Epoch 9] ogbg-molclintox: 0.502809 val loss: 0.686526
[Epoch 9] ogbg-molclintox: 0.448585 test loss: 0.688245
[Epoch 10; Iter    15/   35] train: loss: 0.6901210
[Epoch 10] ogbg-molclintox: 0.496768 val loss: 0.684735
[Epoch 10] ogbg-molclintox: 0.441156 test loss: 0.686579
[Epoch 11; Iter    10/   35] train: loss: 0.6907550
[Epoch 11] ogbg-molclintox: 0.497464 val loss: 0.684865
[Epoch 11] ogbg-molclintox: 0.444066 test loss: 0.686597
[Epoch 12; Iter     5/   35] train: loss: 0.6877856
[Epoch 12; Iter    35/   35] train: loss: 0.6846449
[Epoch 12] ogbg-molclintox: 0.501089 val loss: 0.683504
[Epoch 12] ogbg-molclintox: 0.444625 test loss: 0.685251
[Epoch 13; Iter    30/   35] train: loss: 0.6835814
[Epoch 13] ogbg-molclintox: 0.505768 val loss: 0.681537
[Epoch 13] ogbg-molclintox: 0.447723 test loss: 0.683309
[Epoch 14; Iter    25/   35] train: loss: 0.6829231
[Epoch 14] ogbg-molclintox: 0.507704 val loss: 0.680080
[Epoch 14] ogbg-molclintox: 0.446169 test loss: 0.681859
[Epoch 15; Iter    20/   35] train: loss: 0.6821135
[Epoch 15] ogbg-molclintox: 0.500608 val loss: 0.679547
[Epoch 15] ogbg-molclintox: 0.439789 test loss: 0.681251
[Epoch 16; Iter    15/   35] train: loss: 0.6801771
[Epoch 16] ogbg-molclintox: 0.506646 val loss: 0.677617
[Epoch 16] ogbg-molclintox: 0.457503 test loss: 0.679356
[Epoch 17; Iter    10/   35] train: loss: 0.6802377
[Epoch 17] ogbg-molclintox: 0.518048 val loss: 0.675094
[Epoch 17] ogbg-molclintox: 0.459720 test loss: 0.677010
[Epoch 18; Iter     5/   35] train: loss: 0.6772132
[Epoch 18; Iter    35/   35] train: loss: 0.6739658
[Epoch 18] ogbg-molclintox: 0.515815 val loss: 0.673390
[Epoch 18] ogbg-molclintox: 0.450742 test loss: 0.675367
[Epoch 19; Iter    30/   35] train: loss: 0.6809057
[Epoch 19] ogbg-molclintox: 0.523083 val loss: 0.671509
[Epoch 19] ogbg-molclintox: 0.462193 test loss: 0.673413
[Epoch 20; Iter    25/   35] train: loss: 0.6744161
[Epoch 20] ogbg-molclintox: 0.654355 val loss: 0.675942
[Epoch 20] ogbg-molclintox: 0.589445 test loss: 0.680028
[Epoch 21; Iter    20/   35] train: loss: 0.6565809
[Epoch 21] ogbg-molclintox: 0.724420 val loss: 0.609530
[Epoch 21] ogbg-molclintox: 0.695609 test loss: 0.615570
[Epoch 22; Iter    15/   35] train: loss: 0.6221653
[Epoch 22] ogbg-molclintox: 0.811523 val loss: 0.621676
[Epoch 22] ogbg-molclintox: 0.732416 test loss: 0.626200
[Epoch 23; Iter    10/   35] train: loss: 0.5819887
[Epoch 23] ogbg-molclintox: 0.791473 val loss: 0.496799
[Epoch 23] ogbg-molclintox: 0.742560 test loss: 0.512163
[Epoch 24; Iter     5/   35] train: loss: 0.5406575
[Epoch 24; Iter    35/   35] train: loss: 0.4807512
[Epoch 24] ogbg-molclintox: 0.840717 val loss: 0.427587
[Epoch 24] ogbg-molclintox: 0.772259 test loss: 0.444638
[Epoch 25; Iter    30/   35] train: loss: 0.4514409
[Epoch 25] ogbg-molclintox: 0.815172 val loss: 0.390320
[Epoch 25] ogbg-molclintox: 0.782844 test loss: 0.395305
[Epoch 26; Iter    25/   35] train: loss: 0.3745084
[Epoch 26] ogbg-molclintox: 0.875867 val loss: 0.320100
[Epoch 26] ogbg-molclintox: 0.801488 test loss: 0.333167
[Epoch 27; Iter    20/   35] train: loss: 0.2961831
[Epoch 27] ogbg-molclintox: 0.789211 val loss: 0.332924
[Epoch 27] ogbg-molclintox: 0.743205 test loss: 0.353053
[Epoch 28; Iter    15/   35] train: loss: 0.3246581
[Epoch 28] ogbg-molclintox: 0.866945 val loss: 0.250670
[Epoch 28] ogbg-molclintox: 0.782092 test loss: 0.275198
[Epoch 29; Iter    10/   35] train: loss: 0.3078331
[Epoch 29] ogbg-molclintox: 0.895005 val loss: 0.225121
[Epoch 29] ogbg-molclintox: 0.781970 test loss: 0.251869
[Epoch 30; Iter     5/   35] train: loss: 0.1562678
[Epoch 30; Iter    35/   35] train: loss: 0.3404109
[Epoch 30] ogbg-molclintox: 0.913062 val loss: 0.194266
[Epoch 30] ogbg-molclintox: 0.803809 test loss: 0.223956
[Epoch 31; Iter    30/   35] train: loss: 0.2042863
[Epoch 31] ogbg-molclintox: 0.887269 val loss: 0.205499
[Epoch 31] ogbg-molclintox: 0.746965 test loss: 0.260758
[Epoch 32; Iter    25/   35] train: loss: 0.1604075
[Epoch 32] ogbg-molclintox: 0.923081 val loss: 0.196372
[Epoch 32] ogbg-molclintox: 0.770212 test loss: 0.240038
[Epoch 33; Iter    20/   35] train: loss: 0.2020631
[Epoch 31] ogbg-molclintox: 0.765970 test loss: 0.222234
[Epoch 32; Iter    20/   40] train: loss: 0.1120529
[Epoch 32] ogbg-molclintox: 0.922749 val loss: 0.183102
[Epoch 32] ogbg-molclintox: 0.752626 test loss: 0.231058
[Epoch 33; Iter    10/   40] train: loss: 0.1995917
[Epoch 33; Iter    40/   40] train: loss: 0.2095027
[Epoch 33] ogbg-molclintox: 0.915011 val loss: 0.175263
[Epoch 33] ogbg-molclintox: 0.734546 test loss: 0.222367
[Epoch 34; Iter    30/   40] train: loss: 0.2082575
[Epoch 34] ogbg-molclintox: 0.881615 val loss: 0.192566
[Epoch 34] ogbg-molclintox: 0.752231 test loss: 0.238782
[Epoch 35; Iter    20/   40] train: loss: 0.1797906
[Epoch 35] ogbg-molclintox: 0.906070 val loss: 0.174531
[Epoch 35] ogbg-molclintox: 0.780207 test loss: 0.214847
[Epoch 36; Iter    10/   40] train: loss: 0.1312005
[Epoch 36; Iter    40/   40] train: loss: 0.1754310
[Epoch 36] ogbg-molclintox: 0.921233 val loss: 0.159187
[Epoch 36] ogbg-molclintox: 0.770277 test loss: 0.219017
[Epoch 37; Iter    30/   40] train: loss: 0.2562529
[Epoch 37] ogbg-molclintox: 0.954680 val loss: 0.128710
[Epoch 37] ogbg-molclintox: 0.813362 test loss: 0.187320
[Epoch 38; Iter    20/   40] train: loss: 0.1387617
[Epoch 38] ogbg-molclintox: 0.925480 val loss: 0.145422
[Epoch 38] ogbg-molclintox: 0.766145 test loss: 0.202271
[Epoch 39; Iter    10/   40] train: loss: 0.0677861
[Epoch 39; Iter    40/   40] train: loss: 0.0884110
[Epoch 39] ogbg-molclintox: 0.900781 val loss: 0.258525
[Epoch 39] ogbg-molclintox: 0.796000 test loss: 0.254095
[Epoch 40; Iter    30/   40] train: loss: 0.1690355
[Epoch 40] ogbg-molclintox: 0.936178 val loss: 0.143129
[Epoch 40] ogbg-molclintox: 0.780207 test loss: 0.202163
[Epoch 41; Iter    20/   40] train: loss: 0.2167047
[Epoch 41] ogbg-molclintox: 0.865533 val loss: 0.188059
[Epoch 41] ogbg-molclintox: 0.810979 test loss: 0.206387
[Epoch 42; Iter    10/   40] train: loss: 0.2143563
[Epoch 42; Iter    40/   40] train: loss: 0.1616356
[Epoch 42] ogbg-molclintox: 0.947181 val loss: 0.135671
[Epoch 42] ogbg-molclintox: 0.758363 test loss: 0.273190
[Epoch 43; Iter    30/   40] train: loss: 0.2007283
[Epoch 43] ogbg-molclintox: 0.847620 val loss: 0.211208
[Epoch 43] ogbg-molclintox: 0.648906 test loss: 0.275112
[Epoch 44; Iter    20/   40] train: loss: 0.0658045
[Epoch 44] ogbg-molclintox: 0.910134 val loss: 0.186182
[Epoch 44] ogbg-molclintox: 0.748535 test loss: 0.258431
[Epoch 45; Iter    10/   40] train: loss: 0.1424879
[Epoch 45; Iter    40/   40] train: loss: 0.2209724
[Epoch 45] ogbg-molclintox: 0.922563 val loss: 0.153911
[Epoch 45] ogbg-molclintox: 0.811323 test loss: 0.209406
[Epoch 46; Iter    30/   40] train: loss: 0.1270092
[Epoch 46] ogbg-molclintox: 0.910201 val loss: 0.171749
[Epoch 46] ogbg-molclintox: 0.798099 test loss: 0.789106
[Epoch 47; Iter    20/   40] train: loss: 0.2138236
[Epoch 47] ogbg-molclintox: 0.704171 val loss: 15.080433
[Epoch 47] ogbg-molclintox: 0.734976 test loss: 18.245978
[Epoch 48; Iter    10/   40] train: loss: 0.0288176
[Epoch 48; Iter    40/   40] train: loss: 0.0751675
[Epoch 48] ogbg-molclintox: 0.884838 val loss: 0.489042
[Epoch 48] ogbg-molclintox: 0.775393 test loss: 0.228760
[Epoch 49; Iter    30/   40] train: loss: 0.0435892
[Epoch 49] ogbg-molclintox: 0.888020 val loss: 0.185072
[Epoch 49] ogbg-molclintox: 0.727279 test loss: 0.252797
[Epoch 50; Iter    20/   40] train: loss: 0.0728465
[Epoch 50] ogbg-molclintox: 0.920286 val loss: 0.161862
[Epoch 50] ogbg-molclintox: 0.796963 test loss: 0.231815
[Epoch 51; Iter    10/   40] train: loss: 0.0884511
[Epoch 51; Iter    40/   40] train: loss: 0.1532697
[Epoch 51] ogbg-molclintox: 0.921631 val loss: 0.145795
[Epoch 51] ogbg-molclintox: 0.744880 test loss: 0.258555
[Epoch 52; Iter    30/   40] train: loss: 0.0530767
[Epoch 52] ogbg-molclintox: 0.922923 val loss: 0.160142
[Epoch 52] ogbg-molclintox: 0.729017 test loss: 0.248271
[Epoch 53; Iter    20/   40] train: loss: 0.1530774
[Epoch 53] ogbg-molclintox: 0.912051 val loss: 0.170235
[Epoch 53] ogbg-molclintox: 0.747151 test loss: 0.236291
[Epoch 54; Iter    10/   40] train: loss: 0.1198631
[Epoch 54; Iter    40/   40] train: loss: 0.2825545
[Epoch 54] ogbg-molclintox: 0.928225 val loss: 0.179307
[Epoch 54] ogbg-molclintox: 0.791968 test loss: 0.240316
[Epoch 55; Iter    30/   40] train: loss: 0.1227244
[Epoch 55] ogbg-molclintox: 0.927545 val loss: 0.167110
[Epoch 55] ogbg-molclintox: 0.742883 test loss: 0.250776
[Epoch 56; Iter    20/   40] train: loss: 0.0253586
[Epoch 56] ogbg-molclintox: 0.930595 val loss: 0.188584
[Epoch 56] ogbg-molclintox: 0.723255 test loss: 0.278477
[Epoch 57; Iter    10/   40] train: loss: 0.0935736
[Epoch 57; Iter    40/   40] train: loss: 0.1497301
[Epoch 57] ogbg-molclintox: 0.877562 val loss: 2.083915
[Epoch 57] ogbg-molclintox: 0.688641 test loss: 2.739875
[Epoch 58; Iter    30/   40] train: loss: 0.0526492
[Epoch 58] ogbg-molclintox: 0.907056 val loss: 0.255590
[Epoch 58] ogbg-molclintox: 0.799011 test loss: 0.429111
[Epoch 59; Iter    20/   40] train: loss: 0.0415302
[Epoch 59] ogbg-molclintox: 0.932833 val loss: 0.177963
[Epoch 59] ogbg-molclintox: 0.769848 test loss: 0.266948
[Epoch 60; Iter    10/   40] train: loss: 0.0635719
[Epoch 60; Iter    40/   40] train: loss: 0.0877953
[Epoch 60] ogbg-molclintox: 0.938816 val loss: 0.149526
[Epoch 60] ogbg-molclintox: 0.790438 test loss: 0.223140
[Epoch 61; Iter    30/   40] train: loss: 0.0826066
[Epoch 61] ogbg-molclintox: 0.929370 val loss: 0.197326
[Epoch 61] ogbg-molclintox: 0.745775 test loss: 0.289222
[Epoch 62; Iter    20/   40] train: loss: 0.1052243
[Epoch 62] ogbg-molclintox: 0.944317 val loss: 0.151847
[Epoch 62] ogbg-molclintox: 0.819564 test loss: 0.224770
[Epoch 63; Iter    10/   40] train: loss: 0.0890949
[Epoch 63; Iter    40/   40] train: loss: 0.0354510
[Epoch 63] ogbg-molclintox: 0.907005 val loss: 0.197930
[Epoch 63] ogbg-molclintox: 0.731044 test loss: 0.275926
[Epoch 64; Iter    30/   40] train: loss: 0.0475742
[Epoch 64] ogbg-molclintox: 0.946741 val loss: 0.181429
[Epoch 64] ogbg-molclintox: 0.790951 test loss: 0.270109
[Epoch 65; Iter    20/   40] train: loss: 0.1689609
[Epoch 65] ogbg-molclintox: 0.896614 val loss: 0.205163
[Epoch 65] ogbg-molclintox: 0.704512 test loss: 0.302364
[Epoch 66; Iter    10/   40] train: loss: 0.0282292
[Epoch 66; Iter    40/   40] train: loss: 0.0155555
[Epoch 66] ogbg-molclintox: 0.914557 val loss: 0.193152
[Epoch 66] ogbg-molclintox: 0.768829 test loss: 0.284779
[Epoch 67; Iter    30/   40] train: loss: 0.0192478
[Epoch 67] ogbg-molclintox: 0.923429 val loss: 0.191137
[Epoch 67] ogbg-molclintox: 0.774771 test loss: 0.282243
[Epoch 68; Iter    20/   40] train: loss: 0.0131695
[Epoch 68] ogbg-molclintox: 0.935286 val loss: 0.172993
[Epoch 68] ogbg-molclintox: 0.760917 test loss: 0.286565
[Epoch 69; Iter    10/   40] train: loss: 0.0991275
[Epoch 69; Iter    40/   40] train: loss: 0.0068095
[Epoch 69] ogbg-molclintox: 0.913585 val loss: 0.194985
[Epoch 69] ogbg-molclintox: 0.705685 test loss: 0.322454
[Epoch 70; Iter    30/   40] train: loss: 0.1567643
[Epoch 70] ogbg-molclintox: 0.944635 val loss: 0.162980
[Epoch 70] ogbg-molclintox: 0.776156 test loss: 0.274396
[Epoch 71; Iter    20/   40] train: loss: 0.0626866
[Epoch 71] ogbg-molclintox: 0.920418 val loss: 0.172637
[Epoch 71] ogbg-molclintox: 0.714080 test loss: 0.295859
[Epoch 72; Iter    10/   40] train: loss: 0.1624804
[Epoch 72; Iter    40/   40] train: loss: 0.0349917
[Epoch 72] ogbg-molclintox: 0.901700 val loss: 0.217743
[Epoch 72] ogbg-molclintox: 0.828063 test loss: 0.267027
[Epoch 73; Iter    30/   40] train: loss: 0.0553856
[Epoch 73] ogbg-molclintox: 0.894683 val loss: 0.203381
[Epoch 73] ogbg-molclintox: 0.679890 test loss: 0.346116
[Epoch 74; Iter    20/   40] train: loss: 0.0703326
[Epoch 74] ogbg-molclintox: 0.946169 val loss: 0.174219
[Epoch 74] ogbg-molclintox: 0.693837 test loss: 0.337231
[Epoch 75; Iter    10/   40] train: loss: 0.0044900
[Epoch 75; Iter    40/   40] train: loss: 0.0624971
[Epoch 75] ogbg-molclintox: 0.936311 val loss: 0.193190
[Epoch 75] ogbg-molclintox: 0.756390 test loss: 0.317809
[Epoch 76; Iter    30/   40] train: loss: 0.0409496
[Epoch 31] ogbg-molclintox: 0.770868 test loss: 0.210470
[Epoch 32; Iter    20/   40] train: loss: 0.2408983
[Epoch 32] ogbg-molclintox: 0.885558 val loss: 0.190998
[Epoch 32] ogbg-molclintox: 0.750376 test loss: 0.235339
[Epoch 33; Iter    10/   40] train: loss: 0.2004174
[Epoch 33; Iter    40/   40] train: loss: 0.2668172
[Epoch 33] ogbg-molclintox: 0.865256 val loss: 0.195323
[Epoch 33] ogbg-molclintox: 0.723413 test loss: 0.291960
[Epoch 34; Iter    30/   40] train: loss: 0.1189393
[Epoch 34] ogbg-molclintox: 0.947674 val loss: 0.157505
[Epoch 34] ogbg-molclintox: 0.765855 test loss: 0.540099
[Epoch 35; Iter    20/   40] train: loss: 0.1414398
[Epoch 35] ogbg-molclintox: 0.890593 val loss: 0.183261
[Epoch 35] ogbg-molclintox: 0.796827 test loss: 0.275100
[Epoch 36; Iter    10/   40] train: loss: 0.1301996
[Epoch 36; Iter    40/   40] train: loss: 0.4441414
[Epoch 36] ogbg-molclintox: 0.884986 val loss: 0.312715
[Epoch 36] ogbg-molclintox: 0.729871 test loss: 0.339756
[Epoch 37; Iter    30/   40] train: loss: 0.1701958
[Epoch 37] ogbg-molclintox: 0.913639 val loss: 0.169183
[Epoch 37] ogbg-molclintox: 0.825289 test loss: 0.218249
[Epoch 38; Iter    20/   40] train: loss: 0.1245525
[Epoch 38] ogbg-molclintox: 0.905844 val loss: 0.183194
[Epoch 38] ogbg-molclintox: 0.772386 test loss: 0.220454
[Epoch 39; Iter    10/   40] train: loss: 0.1087232
[Epoch 39; Iter    40/   40] train: loss: 0.2682528
[Epoch 39] ogbg-molclintox: 0.911412 val loss: 0.157906
[Epoch 39] ogbg-molclintox: 0.834223 test loss: 0.180149
[Epoch 40; Iter    30/   40] train: loss: 0.0943842
[Epoch 40] ogbg-molclintox: 0.917194 val loss: 0.164055
[Epoch 40] ogbg-molclintox: 0.760413 test loss: 0.224890
[Epoch 41; Iter    20/   40] train: loss: 0.2955928
[Epoch 41] ogbg-molclintox: 0.831006 val loss: 1.791633
[Epoch 41] ogbg-molclintox: 0.740398 test loss: 3.206040
[Epoch 42; Iter    10/   40] train: loss: 0.1442896
[Epoch 42; Iter    40/   40] train: loss: 0.0880703
[Epoch 42] ogbg-molclintox: 0.892123 val loss: 0.179375
[Epoch 42] ogbg-molclintox: 0.798242 test loss: 0.200441
[Epoch 43; Iter    30/   40] train: loss: 0.0887635
[Epoch 43] ogbg-molclintox: 0.902050 val loss: 0.157551
[Epoch 43] ogbg-molclintox: 0.730197 test loss: 0.238058
[Epoch 44; Iter    20/   40] train: loss: 0.1267300
[Epoch 44] ogbg-molclintox: 0.897508 val loss: 0.147376
[Epoch 44] ogbg-molclintox: 0.836721 test loss: 0.188591
[Epoch 45; Iter    10/   40] train: loss: 0.0901931
[Epoch 45; Iter    40/   40] train: loss: 0.0629931
[Epoch 45] ogbg-molclintox: 0.869761 val loss: 0.194777
[Epoch 45] ogbg-molclintox: 0.735855 test loss: 0.242239
[Epoch 46; Iter    30/   40] train: loss: 0.0584102
[Epoch 46] ogbg-molclintox: 0.900452 val loss: 0.176661
[Epoch 46] ogbg-molclintox: 0.781236 test loss: 0.228240
[Epoch 47; Iter    20/   40] train: loss: 0.2665818
[Epoch 47] ogbg-molclintox: 0.923444 val loss: 0.162108
[Epoch 47] ogbg-molclintox: 0.802506 test loss: 0.232350
[Epoch 48; Iter    10/   40] train: loss: 0.1439485
[Epoch 48; Iter    40/   40] train: loss: 0.0541618
[Epoch 48] ogbg-molclintox: 0.892389 val loss: 0.166306
[Epoch 48] ogbg-molclintox: 0.789008 test loss: 0.217892
[Epoch 49; Iter    30/   40] train: loss: 0.0302035
[Epoch 49] ogbg-molclintox: 0.923231 val loss: 0.140286
[Epoch 49] ogbg-molclintox: 0.867940 test loss: 0.182841
[Epoch 50; Iter    20/   40] train: loss: 0.1479884
[Epoch 50] ogbg-molclintox: 0.929079 val loss: 0.154573
[Epoch 50] ogbg-molclintox: 0.774171 test loss: 0.239389
[Epoch 51; Iter    10/   40] train: loss: 0.0842791
[Epoch 51; Iter    40/   40] train: loss: 0.0321831
[Epoch 51] ogbg-molclintox: 0.917783 val loss: 0.153077
[Epoch 51] ogbg-molclintox: 0.771466 test loss: 0.295022
[Epoch 52; Iter    30/   40] train: loss: 0.1609992
[Epoch 52] ogbg-molclintox: 0.931304 val loss: 0.173800
[Epoch 52] ogbg-molclintox: 0.781673 test loss: 0.251551
[Epoch 53; Iter    20/   40] train: loss: 0.0212899
[Epoch 53] ogbg-molclintox: 0.899813 val loss: 0.160487
[Epoch 53] ogbg-molclintox: 0.808889 test loss: 0.238997
[Epoch 54; Iter    10/   40] train: loss: 0.1077371
[Epoch 54; Iter    40/   40] train: loss: 0.0549254
[Epoch 54] ogbg-molclintox: 0.925693 val loss: 0.137587
[Epoch 54] ogbg-molclintox: 0.829554 test loss: 0.197433
[Epoch 55; Iter    30/   40] train: loss: 0.0177120
[Epoch 55] ogbg-molclintox: 0.926640 val loss: 0.153827
[Epoch 55] ogbg-molclintox: 0.783000 test loss: 0.255073
[Epoch 56; Iter    20/   40] train: loss: 0.0293056
[Epoch 56] ogbg-molclintox: 0.916357 val loss: 0.148192
[Epoch 56] ogbg-molclintox: 0.771912 test loss: 0.253588
[Epoch 57; Iter    10/   40] train: loss: 0.0374018
[Epoch 57; Iter    40/   40] train: loss: 0.0972573
[Epoch 57] ogbg-molclintox: 0.926147 val loss: 0.169451
[Epoch 57] ogbg-molclintox: 0.719555 test loss: 0.294701
[Epoch 58; Iter    30/   40] train: loss: 0.0910494
[Epoch 58] ogbg-molclintox: 0.948540 val loss: 0.115672
[Epoch 58] ogbg-molclintox: 0.740464 test loss: 0.273304
[Epoch 59; Iter    20/   40] train: loss: 0.1040742
[Epoch 59] ogbg-molclintox: 0.928093 val loss: 0.171617
[Epoch 59] ogbg-molclintox: 0.791216 test loss: 0.284822
[Epoch 60; Iter    10/   40] train: loss: 0.1064989
[Epoch 60; Iter    40/   40] train: loss: 0.0210388
[Epoch 60] ogbg-molclintox: 0.960823 val loss: 0.128184
[Epoch 60] ogbg-molclintox: 0.837405 test loss: 0.243447
[Epoch 61; Iter    30/   40] train: loss: 0.1219898
[Epoch 61] ogbg-molclintox: 0.936299 val loss: 0.139308
[Epoch 61] ogbg-molclintox: 0.786571 test loss: 0.243838
[Epoch 62; Iter    20/   40] train: loss: 0.1265010
[Epoch 62] ogbg-molclintox: 0.933794 val loss: 0.150942
[Epoch 62] ogbg-molclintox: 0.842681 test loss: 0.235244
[Epoch 63; Iter    10/   40] train: loss: 0.2384790
[Epoch 63; Iter    40/   40] train: loss: 0.0615965
[Epoch 63] ogbg-molclintox: 0.947021 val loss: 0.146087
[Epoch 63] ogbg-molclintox: 0.669580 test loss: 0.305090
[Epoch 64; Iter    30/   40] train: loss: 0.0998685
[Epoch 64] ogbg-molclintox: 0.958332 val loss: 0.125038
[Epoch 64] ogbg-molclintox: 0.680746 test loss: 0.340001
[Epoch 65; Iter    20/   40] train: loss: 0.0241603
[Epoch 65] ogbg-molclintox: 0.939229 val loss: 0.135897
[Epoch 65] ogbg-molclintox: 0.739145 test loss: 0.288341
[Epoch 66; Iter    10/   40] train: loss: 0.0198658
[Epoch 66; Iter    40/   40] train: loss: 0.0042702
[Epoch 66] ogbg-molclintox: 0.937845 val loss: 0.188956
[Epoch 66] ogbg-molclintox: 0.823657 test loss: 0.246192
[Epoch 67; Iter    30/   40] train: loss: 0.0980812
[Epoch 67] ogbg-molclintox: 0.921751 val loss: 0.162870
[Epoch 67] ogbg-molclintox: 0.781570 test loss: 0.267106
[Epoch 68; Iter    20/   40] train: loss: 0.0706211
[Epoch 68] ogbg-molclintox: 0.907006 val loss: 0.185020
[Epoch 68] ogbg-molclintox: 0.691105 test loss: 0.319292
[Epoch 69; Iter    10/   40] train: loss: 0.0787545
[Epoch 69; Iter    40/   40] train: loss: 0.0424452
[Epoch 69] ogbg-molclintox: 0.912933 val loss: 0.215164
[Epoch 69] ogbg-molclintox: 0.760908 test loss: 0.288826
[Epoch 70; Iter    30/   40] train: loss: 0.0244911
[Epoch 70] ogbg-molclintox: 0.918207 val loss: 0.173889
[Epoch 70] ogbg-molclintox: 0.737598 test loss: 0.327333
[Epoch 71; Iter    20/   40] train: loss: 0.1103791
[Epoch 71] ogbg-molclintox: 0.947528 val loss: 0.152749
[Epoch 71] ogbg-molclintox: 0.736428 test loss: 0.288463
[Epoch 72; Iter    10/   40] train: loss: 0.0772361
[Epoch 72; Iter    40/   40] train: loss: 0.0340223
[Epoch 72] ogbg-molclintox: 0.938936 val loss: 0.166007
[Epoch 72] ogbg-molclintox: 0.733897 test loss: 0.318795
[Epoch 73; Iter    30/   40] train: loss: 0.0367330
[Epoch 73] ogbg-molclintox: 0.951951 val loss: 0.147239
[Epoch 73] ogbg-molclintox: 0.748333 test loss: 0.305056
[Epoch 74; Iter    20/   40] train: loss: 0.0267868
[Epoch 74] ogbg-molclintox: 0.950819 val loss: 0.135504
[Epoch 74] ogbg-molclintox: 0.719633 test loss: 0.319795
[Epoch 75; Iter    10/   40] train: loss: 0.0323873
[Epoch 75; Iter    40/   40] train: loss: 0.0182392
[Epoch 75] ogbg-molclintox: 0.956120 val loss: 0.134436
[Epoch 75] ogbg-molclintox: 0.755732 test loss: 0.297585
[Epoch 76; Iter    30/   40] train: loss: 0.0366532
[Epoch 31] ogbg-molclintox: 0.794278 test loss: 0.220764
[Epoch 32; Iter    20/   40] train: loss: 0.1592909
[Epoch 32] ogbg-molclintox: 0.852242 val loss: 0.204721
[Epoch 32] ogbg-molclintox: 0.667819 test loss: 0.252912
[Epoch 33; Iter    10/   40] train: loss: 0.1372785
[Epoch 33; Iter    40/   40] train: loss: 0.0650344
[Epoch 33] ogbg-molclintox: 0.933353 val loss: 0.172477
[Epoch 33] ogbg-molclintox: 0.808083 test loss: 0.204265
[Epoch 34; Iter    30/   40] train: loss: 0.1862058
[Epoch 34] ogbg-molclintox: 0.908777 val loss: 0.173274
[Epoch 34] ogbg-molclintox: 0.778850 test loss: 0.211895
[Epoch 35; Iter    20/   40] train: loss: 0.0851701
[Epoch 35] ogbg-molclintox: 0.883800 val loss: 0.181118
[Epoch 35] ogbg-molclintox: 0.767711 test loss: 0.227231
[Epoch 36; Iter    10/   40] train: loss: 0.0818842
[Epoch 36; Iter    40/   40] train: loss: 0.0753535
[Epoch 36] ogbg-molclintox: 0.894162 val loss: 0.191181
[Epoch 36] ogbg-molclintox: 0.823594 test loss: 0.355717
[Epoch 37; Iter    30/   40] train: loss: 0.2092107
[Epoch 37] ogbg-molclintox: 0.913983 val loss: 0.170391
[Epoch 37] ogbg-molclintox: 0.753277 test loss: 0.218066
[Epoch 38; Iter    20/   40] train: loss: 0.2257793
[Epoch 38] ogbg-molclintox: 0.883464 val loss: 0.246911
[Epoch 38] ogbg-molclintox: 0.832588 test loss: 0.235492
[Epoch 39; Iter    10/   40] train: loss: 0.4342058
[Epoch 39; Iter    40/   40] train: loss: 0.5530729
[Epoch 39] ogbg-molclintox: 0.896812 val loss: 0.182303
[Epoch 39] ogbg-molclintox: 0.839170 test loss: 0.193266
[Epoch 40; Iter    30/   40] train: loss: 0.1287738
[Epoch 40] ogbg-molclintox: 0.848813 val loss: 0.193703
[Epoch 40] ogbg-molclintox: 0.799620 test loss: 0.208719
[Epoch 41; Iter    20/   40] train: loss: 0.1164113
[Epoch 41] ogbg-molclintox: 0.864640 val loss: 0.209580
[Epoch 41] ogbg-molclintox: 0.748529 test loss: 0.236939
[Epoch 42; Iter    10/   40] train: loss: 0.0788059
[Epoch 42; Iter    40/   40] train: loss: 0.0719445
[Epoch 42] ogbg-molclintox: 0.885781 val loss: 0.188267
[Epoch 42] ogbg-molclintox: 0.761795 test loss: 0.230755
[Epoch 43; Iter    30/   40] train: loss: 0.1796625
[Epoch 43] ogbg-molclintox: 0.881451 val loss: 0.179496
[Epoch 43] ogbg-molclintox: 0.742316 test loss: 0.223849
[Epoch 44; Iter    20/   40] train: loss: 0.0855469
[Epoch 44] ogbg-molclintox: 0.900118 val loss: 0.169030
[Epoch 44] ogbg-molclintox: 0.867367 test loss: 0.169016
[Epoch 45; Iter    10/   40] train: loss: 0.2573861
[Epoch 45; Iter    40/   40] train: loss: 0.0759928
[Epoch 45] ogbg-molclintox: 0.905563 val loss: 0.169207
[Epoch 45] ogbg-molclintox: 0.849329 test loss: 0.193354
[Epoch 46; Iter    30/   40] train: loss: 0.2000203
[Epoch 46] ogbg-molclintox: 0.949514 val loss: 0.140757
[Epoch 46] ogbg-molclintox: 0.827243 test loss: 0.200116
[Epoch 47; Iter    20/   40] train: loss: 0.0861347
[Epoch 47] ogbg-molclintox: 0.907269 val loss: 0.187025
[Epoch 47] ogbg-molclintox: 0.842783 test loss: 0.178999
[Epoch 48; Iter    10/   40] train: loss: 0.1586872
[Epoch 48; Iter    40/   40] train: loss: 0.0617421
[Epoch 48] ogbg-molclintox: 0.894893 val loss: 0.179142
[Epoch 48] ogbg-molclintox: 0.828821 test loss: 0.199473
[Epoch 49; Iter    30/   40] train: loss: 0.1942427
[Epoch 49] ogbg-molclintox: 0.868305 val loss: 0.198612
[Epoch 49] ogbg-molclintox: 0.751470 test loss: 0.260737
[Epoch 50; Iter    20/   40] train: loss: 0.1579391
[Epoch 50] ogbg-molclintox: 0.906351 val loss: 0.211498
[Epoch 50] ogbg-molclintox: 0.806334 test loss: 0.253133
[Epoch 51; Iter    10/   40] train: loss: 0.0653552
[Epoch 51; Iter    40/   40] train: loss: 0.0577405
[Epoch 51] ogbg-molclintox: 0.887809 val loss: 0.170777
[Epoch 51] ogbg-molclintox: 0.670968 test loss: 0.248596
[Epoch 52; Iter    30/   40] train: loss: 0.1569464
[Epoch 52] ogbg-molclintox: 0.921217 val loss: 0.147721
[Epoch 52] ogbg-molclintox: 0.827391 test loss: 0.187328
[Epoch 53; Iter    20/   40] train: loss: 0.1907704
[Epoch 53] ogbg-molclintox: 0.917115 val loss: 0.157126
[Epoch 53] ogbg-molclintox: 0.812994 test loss: 0.222756
[Epoch 54; Iter    10/   40] train: loss: 0.1752120
[Epoch 54; Iter    40/   40] train: loss: 0.2055314
[Epoch 54] ogbg-molclintox: 0.906098 val loss: 0.149387
[Epoch 54] ogbg-molclintox: 0.693174 test loss: 0.474385
[Epoch 55; Iter    30/   40] train: loss: 0.1279363
[Epoch 55] ogbg-molclintox: 0.857020 val loss: 0.235410
[Epoch 55] ogbg-molclintox: 0.652743 test loss: 0.326034
[Epoch 56; Iter    20/   40] train: loss: 0.0417993
[Epoch 56] ogbg-molclintox: 0.928864 val loss: 0.148542
[Epoch 56] ogbg-molclintox: 0.796115 test loss: 0.234460
[Epoch 57; Iter    10/   40] train: loss: 0.1490276
[Epoch 57; Iter    40/   40] train: loss: 0.3116043
[Epoch 57] ogbg-molclintox: 0.923309 val loss: 0.160761
[Epoch 57] ogbg-molclintox: 0.727768 test loss: 0.268835
[Epoch 58; Iter    30/   40] train: loss: 0.0420823
[Epoch 58] ogbg-molclintox: 0.844138 val loss: 0.218042
[Epoch 58] ogbg-molclintox: 0.666931 test loss: 0.337514
[Epoch 59; Iter    20/   40] train: loss: 0.0856625
[Epoch 59] ogbg-molclintox: 0.949086 val loss: 0.149030
[Epoch 59] ogbg-molclintox: 0.740011 test loss: 0.492794
[Epoch 60; Iter    10/   40] train: loss: 0.0775163
[Epoch 60; Iter    40/   40] train: loss: 0.1692864
[Epoch 60] ogbg-molclintox: 0.896389 val loss: 0.167352
[Epoch 60] ogbg-molclintox: 0.724794 test loss: 0.289765
[Epoch 61; Iter    30/   40] train: loss: 0.1263482
[Epoch 61] ogbg-molclintox: 0.864772 val loss: 0.231325
[Epoch 61] ogbg-molclintox: 0.737149 test loss: 0.276689
[Epoch 62; Iter    20/   40] train: loss: 0.2457280
[Epoch 62] ogbg-molclintox: 0.909563 val loss: 0.180511
[Epoch 62] ogbg-molclintox: 0.706011 test loss: 0.317163
[Epoch 63; Iter    10/   40] train: loss: 0.1230195
[Epoch 63; Iter    40/   40] train: loss: 0.0245991
[Epoch 63] ogbg-molclintox: 0.884439 val loss: 0.186049
[Epoch 63] ogbg-molclintox: 0.647465 test loss: 0.345791
[Epoch 64; Iter    30/   40] train: loss: 0.0550860
[Epoch 64] ogbg-molclintox: 0.928850 val loss: 0.173799
[Epoch 64] ogbg-molclintox: 0.687949 test loss: 0.307786
[Epoch 65; Iter    20/   40] train: loss: 0.0491196
[Epoch 65] ogbg-molclintox: 0.922614 val loss: 0.171879
[Epoch 65] ogbg-molclintox: 0.726395 test loss: 0.284022
[Epoch 66; Iter    10/   40] train: loss: 0.0733891
[Epoch 66; Iter    40/   40] train: loss: 0.1469090
[Epoch 66] ogbg-molclintox: 0.911984 val loss: 0.162642
[Epoch 66] ogbg-molclintox: 0.701861 test loss: 0.303350
[Epoch 67; Iter    30/   40] train: loss: 0.1184663
[Epoch 67] ogbg-molclintox: 0.866531 val loss: 0.225404
[Epoch 67] ogbg-molclintox: 0.718405 test loss: 0.271297
[Epoch 68; Iter    20/   40] train: loss: 0.0440838
[Epoch 68] ogbg-molclintox: 0.942866 val loss: 0.143951
[Epoch 68] ogbg-molclintox: 0.626866 test loss: 0.485311
[Epoch 69; Iter    10/   40] train: loss: 0.1161894
[Epoch 69; Iter    40/   40] train: loss: 0.1116184
[Epoch 69] ogbg-molclintox: 0.941665 val loss: 0.166466
[Epoch 69] ogbg-molclintox: 0.653141 test loss: 1.313874
[Epoch 70; Iter    30/   40] train: loss: 0.1304632
[Epoch 70] ogbg-molclintox: 0.930063 val loss: 0.174852
[Epoch 70] ogbg-molclintox: 0.635996 test loss: 2.290005
[Epoch 71; Iter    20/   40] train: loss: 0.0520128
[Epoch 71] ogbg-molclintox: 0.918432 val loss: 0.197292
[Epoch 71] ogbg-molclintox: 0.676394 test loss: 0.401716
[Epoch 72; Iter    10/   40] train: loss: 0.0286490
[Epoch 72; Iter    40/   40] train: loss: 0.0154865
[Epoch 72] ogbg-molclintox: 0.947926 val loss: 0.171019
[Epoch 72] ogbg-molclintox: 0.693530 test loss: 1.249120
[Epoch 73; Iter    30/   40] train: loss: 0.0717761
[Epoch 73] ogbg-molclintox: 0.925054 val loss: 0.174326
[Epoch 73] ogbg-molclintox: 0.707630 test loss: 0.402283
[Epoch 74; Iter    20/   40] train: loss: 0.0350303
[Epoch 74] ogbg-molclintox: 0.906739 val loss: 0.178992
[Epoch 74] ogbg-molclintox: 0.614191 test loss: 0.515912
[Epoch 75; Iter    10/   40] train: loss: 0.1099578
[Epoch 75; Iter    40/   40] train: loss: 0.0373485
[Epoch 75] ogbg-molclintox: 0.935233 val loss: 0.157411
[Epoch 75] ogbg-molclintox: 0.644484 test loss: 1.461022
[Epoch 76; Iter    30/   40] train: loss: 0.0219305
[Epoch 34] ogbg-molclintox: 0.857007 test loss: 0.228033
[Epoch 35; Iter    30/   30] train: loss: 0.1630807
[Epoch 35] ogbg-molclintox: 0.770954 val loss: 0.183494
[Epoch 35] ogbg-molclintox: 0.751975 test loss: 0.231190
[Epoch 36; Iter    30/   30] train: loss: 0.1186107
[Epoch 36] ogbg-molclintox: 0.862135 val loss: 0.164860
[Epoch 36] ogbg-molclintox: 0.813235 test loss: 0.217565
[Epoch 37; Iter    30/   30] train: loss: 0.3420190
[Epoch 37] ogbg-molclintox: 0.821386 val loss: 0.171650
[Epoch 37] ogbg-molclintox: 0.821862 test loss: 0.217189
[Epoch 38; Iter    30/   30] train: loss: 0.1341496
[Epoch 38] ogbg-molclintox: 0.887171 val loss: 0.158850
[Epoch 38] ogbg-molclintox: 0.821616 test loss: 0.218135
[Epoch 39; Iter    30/   30] train: loss: 0.4638395
[Epoch 39] ogbg-molclintox: 0.768222 val loss: 0.178756
[Epoch 39] ogbg-molclintox: 0.728576 test loss: 0.249789
[Epoch 40; Iter    30/   30] train: loss: 0.2926388
[Epoch 40] ogbg-molclintox: 0.836609 val loss: 0.181814
[Epoch 40] ogbg-molclintox: 0.794523 test loss: 0.237273
[Epoch 41; Iter    30/   30] train: loss: 0.0753329
[Epoch 41] ogbg-molclintox: 0.901951 val loss: 0.145234
[Epoch 41] ogbg-molclintox: 0.832321 test loss: 0.207689
[Epoch 42; Iter    30/   30] train: loss: 0.3128605
[Epoch 42] ogbg-molclintox: 0.887306 val loss: 0.177659
[Epoch 42] ogbg-molclintox: 0.788898 test loss: 0.243544
[Epoch 43; Iter    30/   30] train: loss: 0.3155543
[Epoch 43] ogbg-molclintox: 0.872454 val loss: 0.144508
[Epoch 43] ogbg-molclintox: 0.787945 test loss: 0.214585
[Epoch 44; Iter    30/   30] train: loss: 0.2952260
[Epoch 44] ogbg-molclintox: 0.881721 val loss: 0.141943
[Epoch 44] ogbg-molclintox: 0.819638 test loss: 0.202438
[Epoch 45; Iter    30/   30] train: loss: 0.0734468
[Epoch 45] ogbg-molclintox: 0.891639 val loss: 0.130785
[Epoch 45] ogbg-molclintox: 0.835466 test loss: 0.205805
[Epoch 46; Iter    30/   30] train: loss: 0.1118282
[Epoch 46] ogbg-molclintox: 0.874002 val loss: 0.157562
[Epoch 46] ogbg-molclintox: 0.872097 test loss: 0.197128
[Epoch 47; Iter    30/   30] train: loss: 0.1396902
[Epoch 47] ogbg-molclintox: 0.832412 val loss: 0.193877
[Epoch 47] ogbg-molclintox: 0.807917 test loss: 0.249719
[Epoch 48; Iter    30/   30] train: loss: 0.0751102
[Epoch 48] ogbg-molclintox: 0.807666 val loss: 0.184613
[Epoch 48] ogbg-molclintox: 0.824031 test loss: 0.235405
[Epoch 49; Iter    30/   30] train: loss: 0.1290985
[Epoch 49] ogbg-molclintox: 0.886668 val loss: 0.158202
[Epoch 49] ogbg-molclintox: 0.837157 test loss: 0.220862
[Epoch 50; Iter    30/   30] train: loss: 0.1699758
[Epoch 50] ogbg-molclintox: 0.887845 val loss: 0.171419
[Epoch 50] ogbg-molclintox: 0.847545 test loss: 0.225102
[Epoch 51; Iter    30/   30] train: loss: 0.3066661
[Epoch 51] ogbg-molclintox: 0.897670 val loss: 0.204802
[Epoch 51] ogbg-molclintox: 0.861065 test loss: 0.252786
[Epoch 52; Iter    30/   30] train: loss: 0.1614154
[Epoch 52] ogbg-molclintox: 0.928439 val loss: 0.116355
[Epoch 52] ogbg-molclintox: 0.889631 test loss: 0.177992
[Epoch 53; Iter    30/   30] train: loss: 0.1002231
[Epoch 53] ogbg-molclintox: 0.881344 val loss: 0.129242
[Epoch 53] ogbg-molclintox: 0.886410 test loss: 0.185079
[Epoch 54; Iter    30/   30] train: loss: 0.1430713
[Epoch 54] ogbg-molclintox: 0.880201 val loss: 0.132286
[Epoch 54] ogbg-molclintox: 0.852174 test loss: 0.255650
[Epoch 55; Iter    30/   30] train: loss: 0.1569214
[Epoch 55] ogbg-molclintox: 0.836651 val loss: 0.208424
[Epoch 55] ogbg-molclintox: 0.835621 test loss: 0.227179
[Epoch 56; Iter    30/   30] train: loss: 0.1201302
[Epoch 56] ogbg-molclintox: 0.794175 val loss: 0.151361
[Epoch 56] ogbg-molclintox: 0.848690 test loss: 0.191381
[Epoch 57; Iter    30/   30] train: loss: 0.1341913
[Epoch 57] ogbg-molclintox: 0.787439 val loss: 0.191562
[Epoch 57] ogbg-molclintox: 0.810343 test loss: 0.282856
[Epoch 58; Iter    30/   30] train: loss: 0.1029254
[Epoch 58] ogbg-molclintox: 0.910709 val loss: 0.121783
[Epoch 58] ogbg-molclintox: 0.888977 test loss: 0.181692
[Epoch 59; Iter    30/   30] train: loss: 0.1898852
[Epoch 59] ogbg-molclintox: 0.825375 val loss: 0.152167
[Epoch 59] ogbg-molclintox: 0.878099 test loss: 0.184902
[Epoch 60; Iter    30/   30] train: loss: 0.1132471
[Epoch 60] ogbg-molclintox: 0.870054 val loss: 0.127541
[Epoch 60] ogbg-molclintox: 0.882839 test loss: 0.175725
[Epoch 61; Iter    30/   30] train: loss: 0.1090800
[Epoch 61] ogbg-molclintox: 0.876580 val loss: 0.151487
[Epoch 61] ogbg-molclintox: 0.859587 test loss: 0.195445
[Epoch 62; Iter    30/   30] train: loss: 0.1196983
[Epoch 62] ogbg-molclintox: 0.843621 val loss: 0.181729
[Epoch 62] ogbg-molclintox: 0.880564 test loss: 0.199416
[Epoch 63; Iter    30/   30] train: loss: 0.0913791
[Epoch 63] ogbg-molclintox: 0.832736 val loss: 0.153847
[Epoch 63] ogbg-molclintox: 0.833125 test loss: 0.227633
[Epoch 64; Iter    30/   30] train: loss: 0.0249191
[Epoch 64] ogbg-molclintox: 0.752993 val loss: 0.186790
[Epoch 64] ogbg-molclintox: 0.772437 test loss: 0.268945
[Epoch 65; Iter    30/   30] train: loss: 0.2842676
[Epoch 65] ogbg-molclintox: 0.822559 val loss: 0.163731
[Epoch 65] ogbg-molclintox: 0.907441 test loss: 0.193326
[Epoch 66; Iter    30/   30] train: loss: 0.0395803
[Epoch 66] ogbg-molclintox: 0.866679 val loss: 0.531486
[Epoch 66] ogbg-molclintox: 0.897281 test loss: 0.183100
[Epoch 67; Iter    30/   30] train: loss: 0.0419831
[Epoch 67] ogbg-molclintox: 0.854031 val loss: 0.145959
[Epoch 67] ogbg-molclintox: 0.850178 test loss: 0.203434
[Epoch 68; Iter    30/   30] train: loss: 0.2119567
[Epoch 68] ogbg-molclintox: 0.818349 val loss: 0.154930
[Epoch 68] ogbg-molclintox: 0.858650 test loss: 0.205186
[Epoch 69; Iter    30/   30] train: loss: 0.0510006
[Epoch 69] ogbg-molclintox: 0.877376 val loss: 0.169756
[Epoch 69] ogbg-molclintox: 0.889490 test loss: 0.219320
[Epoch 70; Iter    30/   30] train: loss: 0.0404181
[Epoch 70] ogbg-molclintox: 0.845550 val loss: 0.161393
[Epoch 70] ogbg-molclintox: 0.814165 test loss: 0.246976
[Epoch 71; Iter    30/   30] train: loss: 0.0763604
[Epoch 71] ogbg-molclintox: 0.853813 val loss: 0.212000
[Epoch 71] ogbg-molclintox: 0.845447 test loss: 0.291185
[Epoch 72; Iter    30/   30] train: loss: 0.0415589
[Epoch 72] ogbg-molclintox: 0.737029 val loss: 0.214555
[Epoch 72] ogbg-molclintox: 0.810142 test loss: 0.257250
[Epoch 73; Iter    30/   30] train: loss: 0.0648951
[Epoch 73] ogbg-molclintox: 0.795264 val loss: 0.219435
[Epoch 73] ogbg-molclintox: 0.864449 test loss: 0.243896
[Epoch 74; Iter    30/   30] train: loss: 0.0029735
[Epoch 74] ogbg-molclintox: 0.786408 val loss: 0.221901
[Epoch 74] ogbg-molclintox: 0.808002 test loss: 0.296314
[Epoch 75; Iter    30/   30] train: loss: 0.0322953
[Epoch 75] ogbg-molclintox: 0.846780 val loss: 0.164192
[Epoch 75] ogbg-molclintox: 0.793010 test loss: 0.322245
[Epoch 76; Iter    30/   30] train: loss: 0.0261006
[Epoch 76] ogbg-molclintox: 0.855688 val loss: 0.179448
[Epoch 76] ogbg-molclintox: 0.894880 test loss: 0.207696
[Epoch 77; Iter    30/   30] train: loss: 0.1063943
[Epoch 77] ogbg-molclintox: 0.846583 val loss: 0.180822
[Epoch 77] ogbg-molclintox: 0.857706 test loss: 0.247398
[Epoch 78; Iter    30/   30] train: loss: 0.0149553
[Epoch 78] ogbg-molclintox: 0.797340 val loss: 0.185808
[Epoch 78] ogbg-molclintox: 0.847202 test loss: 0.247375
[Epoch 79; Iter    30/   30] train: loss: 0.1907354
[Epoch 79] ogbg-molclintox: 0.726905 val loss: 0.233844
[Epoch 79] ogbg-molclintox: 0.814908 test loss: 0.266079
[Epoch 80; Iter    30/   30] train: loss: 0.1045268
[Epoch 80] ogbg-molclintox: 0.783259 val loss: 0.232857
[Epoch 80] ogbg-molclintox: 0.840435 test loss: 0.263492
[Epoch 81; Iter    30/   30] train: loss: 0.2136556
[Epoch 81] ogbg-molclintox: 0.836761 val loss: 0.195836
[Epoch 81] ogbg-molclintox: 0.871791 test loss: 0.251714
[Epoch 82; Iter    30/   30] train: loss: 0.0128033
[Epoch 82] ogbg-molclintox: 0.881119 val loss: 0.164405
[Epoch 82] ogbg-molclintox: 0.880404 test loss: 0.221236
[Epoch 83; Iter    30/   30] train: loss: 0.0164269
[Epoch 83] ogbg-molclintox: 0.853750 val loss: 0.152346
[Epoch 83] ogbg-molclintox: 0.819625 test loss: 0.263518
[Epoch 33] ogbg-molclintox: 0.893997 val loss: 0.170398
[Epoch 33] ogbg-molclintox: 0.793815 test loss: 0.217768
[Epoch 34; Iter    15/   35] train: loss: 0.2574505
[Epoch 34] ogbg-molclintox: 0.889826 val loss: 0.168969
[Epoch 34] ogbg-molclintox: 0.785427 test loss: 0.213708
[Epoch 35; Iter    10/   35] train: loss: 0.2271061
[Epoch 35] ogbg-molclintox: 0.926837 val loss: 0.157826
[Epoch 35] ogbg-molclintox: 0.785362 test loss: 0.215012
[Epoch 36; Iter     5/   35] train: loss: 0.1891300
[Epoch 36; Iter    35/   35] train: loss: 0.3224572
[Epoch 36] ogbg-molclintox: 0.900309 val loss: 0.173224
[Epoch 36] ogbg-molclintox: 0.796040 test loss: 0.222738
[Epoch 37; Iter    30/   35] train: loss: 0.1199854
[Epoch 37] ogbg-molclintox: 0.930517 val loss: 0.149593
[Epoch 37] ogbg-molclintox: 0.817245 test loss: 0.203142
[Epoch 38; Iter    25/   35] train: loss: 0.2502991
[Epoch 38] ogbg-molclintox: 0.917683 val loss: 0.154041
[Epoch 38] ogbg-molclintox: 0.758787 test loss: 0.242495
[Epoch 39; Iter    20/   35] train: loss: 0.2087400
[Epoch 39] ogbg-molclintox: 0.942397 val loss: 0.137836
[Epoch 39] ogbg-molclintox: 0.822095 test loss: 0.202751
[Epoch 40; Iter    15/   35] train: loss: 0.0899501
[Epoch 40] ogbg-molclintox: 0.925151 val loss: 0.142610
[Epoch 40] ogbg-molclintox: 0.852048 test loss: 0.192572
[Epoch 41; Iter    10/   35] train: loss: 0.2479936
[Epoch 41] ogbg-molclintox: 0.842956 val loss: 0.374514
[Epoch 41] ogbg-molclintox: 0.742287 test loss: 0.438492
[Epoch 42; Iter     5/   35] train: loss: 0.0866083
[Epoch 42; Iter    35/   35] train: loss: 0.0957246
[Epoch 42] ogbg-molclintox: 0.923327 val loss: 0.145159
[Epoch 42] ogbg-molclintox: 0.846501 test loss: 0.187210
[Epoch 43; Iter    30/   35] train: loss: 0.2370445
[Epoch 43] ogbg-molclintox: 0.928676 val loss: 0.126245
[Epoch 43] ogbg-molclintox: 0.846858 test loss: 0.190402
[Epoch 44; Iter    25/   35] train: loss: 0.0805343
[Epoch 44] ogbg-molclintox: 0.939284 val loss: 0.134563
[Epoch 44] ogbg-molclintox: 0.861697 test loss: 0.192168
[Epoch 45; Iter    20/   35] train: loss: 0.1472310
[Epoch 45] ogbg-molclintox: 0.935412 val loss: 0.138994
[Epoch 45] ogbg-molclintox: 0.818532 test loss: 0.236746
[Epoch 46; Iter    15/   35] train: loss: 0.1117407
[Epoch 46] ogbg-molclintox: 0.882814 val loss: 0.146871
[Epoch 46] ogbg-molclintox: 0.746617 test loss: 0.217811
[Epoch 47; Iter    10/   35] train: loss: 0.1321258
[Epoch 47] ogbg-molclintox: 0.870331 val loss: 0.166580
[Epoch 47] ogbg-molclintox: 0.719346 test loss: 0.238005
[Epoch 48; Iter     5/   35] train: loss: 0.2307847
[Epoch 48; Iter    35/   35] train: loss: 0.0638440
[Epoch 48] ogbg-molclintox: 0.915494 val loss: 0.138937
[Epoch 48] ogbg-molclintox: 0.790144 test loss: 0.224711
[Epoch 49; Iter    30/   35] train: loss: 0.0459769
[Epoch 49] ogbg-molclintox: 0.949871 val loss: 0.128298
[Epoch 49] ogbg-molclintox: 0.827852 test loss: 0.214448
[Epoch 50; Iter    25/   35] train: loss: 0.0697596
[Epoch 50] ogbg-molclintox: 0.911570 val loss: 0.128412
[Epoch 50] ogbg-molclintox: 0.818916 test loss: 0.210241
[Epoch 51; Iter    20/   35] train: loss: 0.1612505
[Epoch 51] ogbg-molclintox: 0.900031 val loss: 0.146428
[Epoch 51] ogbg-molclintox: 0.849028 test loss: 0.210426
[Epoch 52; Iter    15/   35] train: loss: 0.0903392
[Epoch 52] ogbg-molclintox: 0.919078 val loss: 0.155055
[Epoch 52] ogbg-molclintox: 0.795591 test loss: 0.216575
[Epoch 53; Iter    10/   35] train: loss: 0.0558734
[Epoch 53] ogbg-molclintox: 0.893788 val loss: 1.477417
[Epoch 53] ogbg-molclintox: 0.785468 test loss: 0.245713
[Epoch 54; Iter     5/   35] train: loss: 0.0432715
[Epoch 54; Iter    35/   35] train: loss: 0.1113206
[Epoch 54] ogbg-molclintox: 0.895470 val loss: 1.673779
[Epoch 54] ogbg-molclintox: 0.808803 test loss: 4.224666
[Epoch 55; Iter    30/   35] train: loss: 0.1515190
[Epoch 55] ogbg-molclintox: 0.872574 val loss: 0.185246
[Epoch 55] ogbg-molclintox: 0.768324 test loss: 0.277406
[Epoch 56; Iter    25/   35] train: loss: 0.0402415
[Epoch 56] ogbg-molclintox: 0.905710 val loss: 0.177330
[Epoch 56] ogbg-molclintox: 0.840790 test loss: 0.216361
[Epoch 57; Iter    20/   35] train: loss: 0.0253940
[Epoch 57] ogbg-molclintox: 0.863741 val loss: 1.227363
[Epoch 57] ogbg-molclintox: 0.762244 test loss: 0.249417
[Epoch 58; Iter    15/   35] train: loss: 0.0357634
[Epoch 58] ogbg-molclintox: 0.910384 val loss: 0.148869
[Epoch 58] ogbg-molclintox: 0.771919 test loss: 0.264753
[Epoch 59; Iter    10/   35] train: loss: 0.0976055
[Epoch 59] ogbg-molclintox: 0.864962 val loss: 0.183262
[Epoch 59] ogbg-molclintox: 0.725825 test loss: 0.277011
[Epoch 60; Iter     5/   35] train: loss: 0.0539727
[Epoch 60; Iter    35/   35] train: loss: 0.0417600
[Epoch 60] ogbg-molclintox: 0.900813 val loss: 0.155370
[Epoch 60] ogbg-molclintox: 0.772929 test loss: 0.266754
[Epoch 61; Iter    30/   35] train: loss: 0.0661724
[Epoch 61] ogbg-molclintox: 0.932097 val loss: 0.144668
[Epoch 61] ogbg-molclintox: 0.833573 test loss: 0.259665
[Epoch 62; Iter    25/   35] train: loss: 0.1500779
[Epoch 62] ogbg-molclintox: 0.898776 val loss: 0.228531
[Epoch 62] ogbg-molclintox: 0.801916 test loss: 0.259094
[Epoch 63; Iter    20/   35] train: loss: 0.2096198
[Epoch 63] ogbg-molclintox: 0.918566 val loss: 0.162644
[Epoch 63] ogbg-molclintox: 0.788924 test loss: 0.284355
[Epoch 64; Iter    15/   35] train: loss: 0.0871949
[Epoch 64] ogbg-molclintox: 0.936583 val loss: 0.176899
[Epoch 64] ogbg-molclintox: 0.798632 test loss: 0.261097
[Epoch 65; Iter    10/   35] train: loss: 0.0796068
[Epoch 65] ogbg-molclintox: 0.923425 val loss: 0.130962
[Epoch 65] ogbg-molclintox: 0.797698 test loss: 0.240806
[Epoch 66; Iter     5/   35] train: loss: 0.0423553
[Epoch 66; Iter    35/   35] train: loss: 0.1487015
[Epoch 66] ogbg-molclintox: 0.914674 val loss: 0.143883
[Epoch 66] ogbg-molclintox: 0.844326 test loss: 0.233927
[Epoch 67; Iter    30/   35] train: loss: 0.0306420
[Epoch 67] ogbg-molclintox: 0.881597 val loss: 0.154522
[Epoch 67] ogbg-molclintox: 0.781897 test loss: 0.247864
[Epoch 68; Iter    25/   35] train: loss: 0.0381401
[Epoch 68] ogbg-molclintox: 0.863499 val loss: 0.194416
[Epoch 68] ogbg-molclintox: 0.709676 test loss: 0.309565
[Epoch 69; Iter    20/   35] train: loss: 0.0490556
[Epoch 69] ogbg-molclintox: 0.883460 val loss: 0.186872
[Epoch 69] ogbg-molclintox: 0.804787 test loss: 0.488641
[Epoch 70; Iter    15/   35] train: loss: 0.0302159
[Epoch 70] ogbg-molclintox: 0.888202 val loss: 0.176926
[Epoch 70] ogbg-molclintox: 0.784367 test loss: 0.479770
[Epoch 71; Iter    10/   35] train: loss: 0.0115111
[Epoch 71] ogbg-molclintox: 0.877438 val loss: 0.345754
[Epoch 71] ogbg-molclintox: 0.811081 test loss: 0.411099
[Epoch 72; Iter     5/   35] train: loss: 0.0138493
[Epoch 72; Iter    35/   35] train: loss: 0.0252553
[Epoch 72] ogbg-molclintox: 0.861865 val loss: 0.226109
[Epoch 72] ogbg-molclintox: 0.822139 test loss: 0.351776
[Epoch 73; Iter    30/   35] train: loss: 0.0152649
[Epoch 73] ogbg-molclintox: 0.877563 val loss: 0.228782
[Epoch 73] ogbg-molclintox: 0.803917 test loss: 0.346032
[Epoch 74; Iter    25/   35] train: loss: 0.0446531
[Epoch 74] ogbg-molclintox: 0.845504 val loss: 0.213605
[Epoch 74] ogbg-molclintox: 0.812948 test loss: 0.325465
[Epoch 75; Iter    20/   35] train: loss: 0.1096527
[Epoch 75] ogbg-molclintox: 0.846639 val loss: 0.482384
[Epoch 75] ogbg-molclintox: 0.848702 test loss: 0.433741
[Epoch 76; Iter    15/   35] train: loss: 0.1714646
[Epoch 76] ogbg-molclintox: 0.883804 val loss: 0.237417
[Epoch 76] ogbg-molclintox: 0.849565 test loss: 0.375362
[Epoch 77; Iter    10/   35] train: loss: 0.0897974
[Epoch 77] ogbg-molclintox: 0.844857 val loss: 0.320507
[Epoch 77] ogbg-molclintox: 0.809797 test loss: 0.335292
[Epoch 78; Iter     5/   35] train: loss: 0.1078799
[Epoch 78; Iter    35/   35] train: loss: 0.0150813
[Epoch 78] ogbg-molclintox: 0.808630 val loss: 0.266717
[Epoch 78] ogbg-molclintox: 0.759022 test loss: 0.364875
[Epoch 79; Iter    30/   35] train: loss: 0.0826425
[Epoch 79] ogbg-molclintox: 0.851361 val loss: 0.231464
[Epoch 79] ogbg-molclintox: 0.799140 test loss: 0.304217
[Epoch 80; Iter    25/   35] train: loss: 0.0369330
[Epoch 33] ogbg-molclintox: 0.827405 val loss: 0.196206
[Epoch 33] ogbg-molclintox: 0.716676 test loss: 0.242827
[Epoch 34; Iter    15/   35] train: loss: 0.2645515
[Epoch 34] ogbg-molclintox: 0.891287 val loss: 0.163349
[Epoch 34] ogbg-molclintox: 0.763908 test loss: 0.214759
[Epoch 35; Iter    10/   35] train: loss: 0.1149651
[Epoch 35] ogbg-molclintox: 0.864160 val loss: 0.168052
[Epoch 35] ogbg-molclintox: 0.784261 test loss: 0.219156
[Epoch 36; Iter     5/   35] train: loss: 0.1898839
[Epoch 36; Iter    35/   35] train: loss: 0.1389333
[Epoch 36] ogbg-molclintox: 0.905676 val loss: 0.167893
[Epoch 36] ogbg-molclintox: 0.805696 test loss: 0.204152
[Epoch 37; Iter    30/   35] train: loss: 0.2704129
[Epoch 37] ogbg-molclintox: 0.869106 val loss: 0.174081
[Epoch 37] ogbg-molclintox: 0.794035 test loss: 0.229299
[Epoch 38; Iter    25/   35] train: loss: 0.1519062
[Epoch 38] ogbg-molclintox: 0.893010 val loss: 0.162602
[Epoch 38] ogbg-molclintox: 0.798765 test loss: 0.217612
[Epoch 39; Iter    20/   35] train: loss: 0.2015216
[Epoch 39] ogbg-molclintox: 0.927736 val loss: 0.145365
[Epoch 39] ogbg-molclintox: 0.811858 test loss: 0.205608
[Epoch 40; Iter    15/   35] train: loss: 0.1422722
[Epoch 40] ogbg-molclintox: 0.828086 val loss: 0.248645
[Epoch 40] ogbg-molclintox: 0.722454 test loss: 0.312595
[Epoch 41; Iter    10/   35] train: loss: 0.1149993
[Epoch 41] ogbg-molclintox: 0.935375 val loss: 0.135325
[Epoch 41] ogbg-molclintox: 0.807756 test loss: 0.203922
[Epoch 42; Iter     5/   35] train: loss: 0.1359647
[Epoch 42; Iter    35/   35] train: loss: 0.1488395
[Epoch 42] ogbg-molclintox: 0.884862 val loss: 0.148573
[Epoch 42] ogbg-molclintox: 0.828267 test loss: 0.207652
[Epoch 43; Iter    30/   35] train: loss: 0.1019092
[Epoch 43] ogbg-molclintox: 0.875168 val loss: 0.424329
[Epoch 43] ogbg-molclintox: 0.881610 test loss: 0.353123
[Epoch 44; Iter    25/   35] train: loss: 0.1770692
[Epoch 44] ogbg-molclintox: 0.871587 val loss: 0.216326
[Epoch 44] ogbg-molclintox: 0.820921 test loss: 0.255869
[Epoch 45; Iter    20/   35] train: loss: 0.0787992
[Epoch 45] ogbg-molclintox: 0.889916 val loss: 0.168244
[Epoch 45] ogbg-molclintox: 0.814600 test loss: 0.201050
[Epoch 46; Iter    15/   35] train: loss: 0.2631358
[Epoch 46] ogbg-molclintox: 0.889576 val loss: 0.167316
[Epoch 46] ogbg-molclintox: 0.879242 test loss: 0.198453
[Epoch 47; Iter    10/   35] train: loss: 0.1249811
[Epoch 47] ogbg-molclintox: 0.904421 val loss: 0.142374
[Epoch 47] ogbg-molclintox: 0.840187 test loss: 0.181829
[Epoch 48; Iter     5/   35] train: loss: 0.0794732
[Epoch 48; Iter    35/   35] train: loss: 0.2140618
[Epoch 48] ogbg-molclintox: 0.936365 val loss: 0.127436
[Epoch 48] ogbg-molclintox: 0.832387 test loss: 0.198472
[Epoch 49; Iter    30/   35] train: loss: 0.0983865
[Epoch 49] ogbg-molclintox: 0.887178 val loss: 0.154193
[Epoch 49] ogbg-molclintox: 0.825669 test loss: 0.229652
[Epoch 50; Iter    25/   35] train: loss: 0.0755791
[Epoch 50] ogbg-molclintox: 0.920752 val loss: 0.123621
[Epoch 50] ogbg-molclintox: 0.876974 test loss: 0.196726
[Epoch 51; Iter    20/   35] train: loss: 0.0652128
[Epoch 51] ogbg-molclintox: 0.843551 val loss: 0.196361
[Epoch 51] ogbg-molclintox: 0.802121 test loss: 0.242132
[Epoch 52; Iter    15/   35] train: loss: 0.0449635
[Epoch 52] ogbg-molclintox: 0.857763 val loss: 0.157958
[Epoch 52] ogbg-molclintox: 0.816469 test loss: 0.232040
[Epoch 53; Iter    10/   35] train: loss: 0.0397658
[Epoch 53] ogbg-molclintox: 0.860170 val loss: 0.186907
[Epoch 53] ogbg-molclintox: 0.874985 test loss: 0.208880
[Epoch 54; Iter     5/   35] train: loss: 0.1388103
[Epoch 54; Iter    35/   35] train: loss: 0.0795383
[Epoch 54] ogbg-molclintox: 0.892836 val loss: 0.169032
[Epoch 54] ogbg-molclintox: 0.832987 test loss: 0.212926
[Epoch 55; Iter    30/   35] train: loss: 0.0322834
[Epoch 55] ogbg-molclintox: 0.938454 val loss: 0.136128
[Epoch 55] ogbg-molclintox: 0.840785 test loss: 0.228942
[Epoch 56; Iter    25/   35] train: loss: 0.0190019
[Epoch 56] ogbg-molclintox: 0.864797 val loss: 0.214761
[Epoch 56] ogbg-molclintox: 0.826629 test loss: 0.237430
[Epoch 57; Iter    20/   35] train: loss: 0.0972793
[Epoch 57] ogbg-molclintox: 0.934742 val loss: 0.137371
[Epoch 57] ogbg-molclintox: 0.787671 test loss: 0.277790
[Epoch 58; Iter    15/   35] train: loss: 0.0484720
[Epoch 58] ogbg-molclintox: 0.881037 val loss: 0.150931
[Epoch 58] ogbg-molclintox: 0.796989 test loss: 0.207373
[Epoch 59; Iter    10/   35] train: loss: 0.0375342
[Epoch 59] ogbg-molclintox: 0.888793 val loss: 0.171129
[Epoch 59] ogbg-molclintox: 0.797018 test loss: 0.240252
[Epoch 60; Iter     5/   35] train: loss: 0.0705777
[Epoch 60; Iter    35/   35] train: loss: 0.1194176
[Epoch 60] ogbg-molclintox: 0.950392 val loss: 0.130479
[Epoch 60] ogbg-molclintox: 0.858322 test loss: 0.214837
[Epoch 61; Iter    30/   35] train: loss: 0.0808276
[Epoch 61] ogbg-molclintox: 0.888400 val loss: 0.199222
[Epoch 61] ogbg-molclintox: 0.766165 test loss: 0.280615
[Epoch 62; Iter    25/   35] train: loss: 0.0286220
[Epoch 62] ogbg-molclintox: 0.938532 val loss: 0.133919
[Epoch 62] ogbg-molclintox: 0.829324 test loss: 0.253936
[Epoch 63; Iter    20/   35] train: loss: 0.0535046
[Epoch 63] ogbg-molclintox: 0.889729 val loss: 0.143199
[Epoch 63] ogbg-molclintox: 0.818260 test loss: 0.246442
[Epoch 64; Iter    15/   35] train: loss: 0.0205433
[Epoch 64] ogbg-molclintox: 0.875244 val loss: 0.186046
[Epoch 64] ogbg-molclintox: 0.760490 test loss: 0.302876
[Epoch 65; Iter    10/   35] train: loss: 0.0625377
[Epoch 65] ogbg-molclintox: 0.926197 val loss: 0.145502
[Epoch 65] ogbg-molclintox: 0.858178 test loss: 0.419309
[Epoch 66; Iter     5/   35] train: loss: 0.0883919
[Epoch 66; Iter    35/   35] train: loss: 0.0431625
[Epoch 66] ogbg-molclintox: 0.900242 val loss: 0.169242
[Epoch 66] ogbg-molclintox: 0.774292 test loss: 0.270491
[Epoch 67; Iter    30/   35] train: loss: 0.0696505
[Epoch 67] ogbg-molclintox: 0.908315 val loss: 0.140289
[Epoch 67] ogbg-molclintox: 0.757996 test loss: 0.282269
[Epoch 68; Iter    25/   35] train: loss: 0.0409290
[Epoch 68] ogbg-molclintox: 0.935716 val loss: 0.124534
[Epoch 68] ogbg-molclintox: 0.826916 test loss: 0.234186
[Epoch 69; Iter    20/   35] train: loss: 0.0581164
[Epoch 69] ogbg-molclintox: 0.886212 val loss: 0.186322
[Epoch 69] ogbg-molclintox: 0.790303 test loss: 0.305238
[Epoch 70; Iter    15/   35] train: loss: 0.0520335
[Epoch 70] ogbg-molclintox: 0.931994 val loss: 0.165513
[Epoch 70] ogbg-molclintox: 0.822339 test loss: 0.278866
[Epoch 71; Iter    10/   35] train: loss: 0.0321212
[Epoch 71] ogbg-molclintox: 0.887506 val loss: 0.169828
[Epoch 71] ogbg-molclintox: 0.856529 test loss: 0.252453
[Epoch 72; Iter     5/   35] train: loss: 0.0096772
[Epoch 72; Iter    35/   35] train: loss: 0.0112400
[Epoch 72] ogbg-molclintox: 0.918723 val loss: 0.159416
[Epoch 72] ogbg-molclintox: 0.800815 test loss: 0.282296
[Epoch 73; Iter    30/   35] train: loss: 0.0948920
[Epoch 73] ogbg-molclintox: 0.918748 val loss: 0.168416
[Epoch 73] ogbg-molclintox: 0.802231 test loss: 0.302154
[Epoch 74; Iter    25/   35] train: loss: 0.1125750
[Epoch 74] ogbg-molclintox: 0.842916 val loss: 0.221856
[Epoch 74] ogbg-molclintox: 0.737633 test loss: 0.290969
[Epoch 75; Iter    20/   35] train: loss: 0.0456511
[Epoch 75] ogbg-molclintox: 0.847960 val loss: 2.173846
[Epoch 75] ogbg-molclintox: 0.678771 test loss: 0.331927
[Epoch 76; Iter    15/   35] train: loss: 0.0717929
[Epoch 76] ogbg-molclintox: 0.924374 val loss: 0.873929
[Epoch 76] ogbg-molclintox: 0.760559 test loss: 0.286819
[Epoch 77; Iter    10/   35] train: loss: 0.0495496
[Epoch 77] ogbg-molclintox: 0.902086 val loss: 1.478379
[Epoch 77] ogbg-molclintox: 0.774273 test loss: 0.294731
[Epoch 78; Iter     5/   35] train: loss: 0.0480852
[Epoch 78; Iter    35/   35] train: loss: 0.0105513
[Epoch 78] ogbg-molclintox: 0.901696 val loss: 0.194034
[Epoch 78] ogbg-molclintox: 0.826241 test loss: 0.301469
[Epoch 79; Iter    30/   35] train: loss: 0.0098813
[Epoch 79] ogbg-molclintox: 0.810769 val loss: 0.210431
[Epoch 79] ogbg-molclintox: 0.783646 test loss: 0.267350
[Epoch 80; Iter    25/   35] train: loss: 0.2723169
[Epoch 33] ogbg-molclintox: 0.900959 val loss: 0.170900
[Epoch 33] ogbg-molclintox: 0.822288 test loss: 0.213317
[Epoch 34; Iter    15/   35] train: loss: 0.3310768
[Epoch 34] ogbg-molclintox: 0.926134 val loss: 0.154524
[Epoch 34] ogbg-molclintox: 0.816088 test loss: 0.207022
[Epoch 35; Iter    10/   35] train: loss: 0.2509376
[Epoch 35] ogbg-molclintox: 0.925588 val loss: 0.160064
[Epoch 35] ogbg-molclintox: 0.824789 test loss: 0.205431
[Epoch 36; Iter     5/   35] train: loss: 0.0915288
[Epoch 36; Iter    35/   35] train: loss: 0.3863913
[Epoch 36] ogbg-molclintox: 0.938091 val loss: 0.156907
[Epoch 36] ogbg-molclintox: 0.791650 test loss: 0.216778
[Epoch 37; Iter    30/   35] train: loss: 0.2750750
[Epoch 37] ogbg-molclintox: 0.925347 val loss: 0.158653
[Epoch 37] ogbg-molclintox: 0.782908 test loss: 0.213475
[Epoch 38; Iter    25/   35] train: loss: 0.3687510
[Epoch 38] ogbg-molclintox: 0.924386 val loss: 0.150407
[Epoch 38] ogbg-molclintox: 0.810651 test loss: 0.202704
[Epoch 39; Iter    20/   35] train: loss: 0.2506168
[Epoch 39] ogbg-molclintox: 0.923780 val loss: 0.155564
[Epoch 39] ogbg-molclintox: 0.789512 test loss: 0.204867
[Epoch 40; Iter    15/   35] train: loss: 0.3026203
[Epoch 40] ogbg-molclintox: 0.919946 val loss: 0.143627
[Epoch 40] ogbg-molclintox: 0.841130 test loss: 0.190888
[Epoch 41; Iter    10/   35] train: loss: 0.1356130
[Epoch 41] ogbg-molclintox: 0.911826 val loss: 0.161993
[Epoch 41] ogbg-molclintox: 0.806800 test loss: 0.238598
[Epoch 42; Iter     5/   35] train: loss: 0.0737616
[Epoch 42; Iter    35/   35] train: loss: 0.1431078
[Epoch 42] ogbg-molclintox: 0.787622 val loss: 0.350897
[Epoch 42] ogbg-molclintox: 0.702823 test loss: 0.354153
[Epoch 43; Iter    30/   35] train: loss: 0.1527971
[Epoch 43] ogbg-molclintox: 0.821676 val loss: 2.387147
[Epoch 43] ogbg-molclintox: 0.653565 test loss: 0.387584
[Epoch 44; Iter    25/   35] train: loss: 0.3060050
[Epoch 44] ogbg-molclintox: 0.919287 val loss: 0.160769
[Epoch 44] ogbg-molclintox: 0.864413 test loss: 0.189208
[Epoch 45; Iter    20/   35] train: loss: 0.1230442
[Epoch 45] ogbg-molclintox: 0.915794 val loss: 0.139760
[Epoch 45] ogbg-molclintox: 0.878224 test loss: 0.168648
[Epoch 46; Iter    15/   35] train: loss: 0.2340547
[Epoch 46] ogbg-molclintox: 0.851531 val loss: 0.185730
[Epoch 46] ogbg-molclintox: 0.801028 test loss: 0.258457
[Epoch 47; Iter    10/   35] train: loss: 0.1026414
[Epoch 47] ogbg-molclintox: 0.861075 val loss: 0.202010
[Epoch 47] ogbg-molclintox: 0.765907 test loss: 0.275423
[Epoch 48; Iter     5/   35] train: loss: 0.1257434
[Epoch 48; Iter    35/   35] train: loss: 0.0692882
[Epoch 48] ogbg-molclintox: 0.908673 val loss: 0.152577
[Epoch 48] ogbg-molclintox: 0.808272 test loss: 0.204055
[Epoch 49; Iter    30/   35] train: loss: 0.1554234
[Epoch 49] ogbg-molclintox: 0.902538 val loss: 0.434494
[Epoch 49] ogbg-molclintox: 0.807363 test loss: 0.251238
[Epoch 50; Iter    25/   35] train: loss: 0.0643545
[Epoch 50] ogbg-molclintox: 0.936893 val loss: 0.123251
[Epoch 50] ogbg-molclintox: 0.821097 test loss: 0.202094
[Epoch 51; Iter    20/   35] train: loss: 0.0465660
[Epoch 51] ogbg-molclintox: 0.922969 val loss: 0.142817
[Epoch 51] ogbg-molclintox: 0.864951 test loss: 0.194280
[Epoch 52; Iter    15/   35] train: loss: 0.1858903
[Epoch 52] ogbg-molclintox: 0.909688 val loss: 0.146175
[Epoch 52] ogbg-molclintox: 0.805854 test loss: 0.212746
[Epoch 53; Iter    10/   35] train: loss: 0.1015879
[Epoch 53] ogbg-molclintox: 0.922697 val loss: 0.144716
[Epoch 53] ogbg-molclintox: 0.829617 test loss: 0.228317
[Epoch 54; Iter     5/   35] train: loss: 0.0292091
[Epoch 54; Iter    35/   35] train: loss: 0.0311327
[Epoch 54] ogbg-molclintox: 0.909217 val loss: 0.132161
[Epoch 54] ogbg-molclintox: 0.791758 test loss: 0.222992
[Epoch 55; Iter    30/   35] train: loss: 0.1183229
[Epoch 55] ogbg-molclintox: 0.910765 val loss: 0.154991
[Epoch 55] ogbg-molclintox: 0.801377 test loss: 0.245943
[Epoch 56; Iter    25/   35] train: loss: 0.1377941
[Epoch 56] ogbg-molclintox: 0.925026 val loss: 0.152029
[Epoch 56] ogbg-molclintox: 0.831103 test loss: 0.235070
[Epoch 57; Iter    20/   35] train: loss: 0.1585273
[Epoch 57] ogbg-molclintox: 0.949065 val loss: 0.131010
[Epoch 57] ogbg-molclintox: 0.803967 test loss: 0.267318
[Epoch 58; Iter    15/   35] train: loss: 0.0811733
[Epoch 58] ogbg-molclintox: 0.935098 val loss: 0.128619
[Epoch 58] ogbg-molclintox: 0.830733 test loss: 0.248303
[Epoch 59; Iter    10/   35] train: loss: 0.0257689
[Epoch 59] ogbg-molclintox: 0.920834 val loss: 0.139293
[Epoch 59] ogbg-molclintox: 0.820583 test loss: 0.258082
[Epoch 60; Iter     5/   35] train: loss: 0.1394671
[Epoch 60; Iter    35/   35] train: loss: 0.1174713
[Epoch 60] ogbg-molclintox: 0.895829 val loss: 0.177425
[Epoch 60] ogbg-molclintox: 0.777056 test loss: 0.260363
[Epoch 61; Iter    30/   35] train: loss: 0.0401551
[Epoch 61] ogbg-molclintox: 0.888471 val loss: 0.167090
[Epoch 61] ogbg-molclintox: 0.806033 test loss: 0.244854
[Epoch 62; Iter    25/   35] train: loss: 0.0677014
[Epoch 62] ogbg-molclintox: 0.889161 val loss: 0.168930
[Epoch 62] ogbg-molclintox: 0.766203 test loss: 0.285733
[Epoch 63; Iter    20/   35] train: loss: 0.0348796
[Epoch 63] ogbg-molclintox: 0.889036 val loss: 0.179615
[Epoch 63] ogbg-molclintox: 0.807362 test loss: 0.262264
[Epoch 64; Iter    15/   35] train: loss: 0.0552996
[Epoch 64] ogbg-molclintox: 0.897462 val loss: 0.175945
[Epoch 64] ogbg-molclintox: 0.762806 test loss: 0.280251
[Epoch 65; Iter    10/   35] train: loss: 0.2619600
[Epoch 65] ogbg-molclintox: 0.894103 val loss: 0.166626
[Epoch 65] ogbg-molclintox: 0.847123 test loss: 0.225924
[Epoch 66; Iter     5/   35] train: loss: 0.0839765
[Epoch 66; Iter    35/   35] train: loss: 0.3087157
[Epoch 66] ogbg-molclintox: 0.907837 val loss: 0.219332
[Epoch 66] ogbg-molclintox: 0.815339 test loss: 0.285234
[Epoch 67; Iter    30/   35] train: loss: 0.1596333
[Epoch 67] ogbg-molclintox: 0.899526 val loss: 0.174096
[Epoch 67] ogbg-molclintox: 0.846575 test loss: 0.245634
[Epoch 68; Iter    25/   35] train: loss: 0.0077506
[Epoch 68] ogbg-molclintox: 0.830708 val loss: 0.170138
[Epoch 68] ogbg-molclintox: 0.762154 test loss: 0.231553
[Epoch 69; Iter    20/   35] train: loss: 0.0734678
[Epoch 69] ogbg-molclintox: 0.864831 val loss: 0.192816
[Epoch 69] ogbg-molclintox: 0.817976 test loss: 0.260923
[Epoch 70; Iter    15/   35] train: loss: 0.0431046
[Epoch 70] ogbg-molclintox: 0.916334 val loss: 0.152481
[Epoch 70] ogbg-molclintox: 0.783187 test loss: 0.270616
[Epoch 71; Iter    10/   35] train: loss: 0.0148781
[Epoch 71] ogbg-molclintox: 0.922747 val loss: 0.151670
[Epoch 71] ogbg-molclintox: 0.799951 test loss: 0.279198
[Epoch 72; Iter     5/   35] train: loss: 0.0130798
[Epoch 72; Iter    35/   35] train: loss: 0.1066412
[Epoch 72] ogbg-molclintox: 0.888352 val loss: 0.152157
[Epoch 72] ogbg-molclintox: 0.726204 test loss: 0.298715
[Epoch 73; Iter    30/   35] train: loss: 0.0248225
[Epoch 73] ogbg-molclintox: 0.903176 val loss: 0.181973
[Epoch 73] ogbg-molclintox: 0.762635 test loss: 0.295841
[Epoch 74; Iter    25/   35] train: loss: 0.0576071
[Epoch 74] ogbg-molclintox: 0.902829 val loss: 0.161292
[Epoch 74] ogbg-molclintox: 0.811218 test loss: 0.284868
[Epoch 75; Iter    20/   35] train: loss: 0.1013076
[Epoch 75] ogbg-molclintox: 0.926484 val loss: 0.167988
[Epoch 75] ogbg-molclintox: 0.868738 test loss: 0.254828
[Epoch 76; Iter    15/   35] train: loss: 0.0565821
[Epoch 76] ogbg-molclintox: 0.912934 val loss: 0.176826
[Epoch 76] ogbg-molclintox: 0.858779 test loss: 0.274119
[Epoch 77; Iter    10/   35] train: loss: 0.0629705
[Epoch 77] ogbg-molclintox: 0.906151 val loss: 0.190276
[Epoch 77] ogbg-molclintox: 0.774461 test loss: 0.319953
[Epoch 78; Iter     5/   35] train: loss: 0.0323973
[Epoch 78; Iter    35/   35] train: loss: 0.0874461
[Epoch 78] ogbg-molclintox: 0.885836 val loss: 0.208455
[Epoch 78] ogbg-molclintox: 0.800075 test loss: 0.312615
[Epoch 79; Iter    30/   35] train: loss: 0.0532429
[Epoch 79] ogbg-molclintox: 0.903553 val loss: 0.196015
[Epoch 79] ogbg-molclintox: 0.768788 test loss: 0.316660
[Epoch 80; Iter    25/   35] train: loss: 0.0122544
[Epoch 34] ogbg-molclintox: 0.795463 test loss: 0.260258
[Epoch 35; Iter    30/   30] train: loss: 0.4040065
[Epoch 35] ogbg-molclintox: 0.855556 val loss: 0.183874
[Epoch 35] ogbg-molclintox: 0.851390 test loss: 0.216765
[Epoch 36; Iter    30/   30] train: loss: 0.1026780
[Epoch 36] ogbg-molclintox: 0.841929 val loss: 0.150261
[Epoch 36] ogbg-molclintox: 0.825864 test loss: 0.204405
[Epoch 37; Iter    30/   30] train: loss: 0.1259996
[Epoch 37] ogbg-molclintox: 0.884637 val loss: 0.155734
[Epoch 37] ogbg-molclintox: 0.829605 test loss: 0.206861
[Epoch 38; Iter    30/   30] train: loss: 0.3134759
[Epoch 38] ogbg-molclintox: 0.909859 val loss: 0.147554
[Epoch 38] ogbg-molclintox: 0.849952 test loss: 0.193285
[Epoch 39; Iter    30/   30] train: loss: 0.1075876
[Epoch 39] ogbg-molclintox: 0.853000 val loss: 0.149586
[Epoch 39] ogbg-molclintox: 0.825915 test loss: 0.202400
[Epoch 40; Iter    30/   30] train: loss: 0.1315256
[Epoch 40] ogbg-molclintox: 0.886943 val loss: 0.176491
[Epoch 40] ogbg-molclintox: 0.800797 test loss: 0.228774
[Epoch 41; Iter    30/   30] train: loss: 0.1161033
[Epoch 41] ogbg-molclintox: 0.920433 val loss: 0.126082
[Epoch 41] ogbg-molclintox: 0.870803 test loss: 0.186402
[Epoch 42; Iter    30/   30] train: loss: 0.0800457
[Epoch 42] ogbg-molclintox: 0.899863 val loss: 0.142401
[Epoch 42] ogbg-molclintox: 0.862373 test loss: 0.194593
[Epoch 43; Iter    30/   30] train: loss: 0.1274008
[Epoch 43] ogbg-molclintox: 0.903665 val loss: 0.176756
[Epoch 43] ogbg-molclintox: 0.836270 test loss: 0.226131
[Epoch 44; Iter    30/   30] train: loss: 0.4141003
[Epoch 44] ogbg-molclintox: 0.879456 val loss: 0.140523
[Epoch 44] ogbg-molclintox: 0.849389 test loss: 0.199116
[Epoch 45; Iter    30/   30] train: loss: 0.1117763
[Epoch 45] ogbg-molclintox: 0.915429 val loss: 0.125206
[Epoch 45] ogbg-molclintox: 0.881052 test loss: 0.184091
[Epoch 46; Iter    30/   30] train: loss: 0.2858588
[Epoch 46] ogbg-molclintox: 0.819478 val loss: 0.155688
[Epoch 46] ogbg-molclintox: 0.802197 test loss: 0.216924
[Epoch 47; Iter    30/   30] train: loss: 0.3115261
[Epoch 47] ogbg-molclintox: 0.887549 val loss: 0.138635
[Epoch 47] ogbg-molclintox: 0.843962 test loss: 0.199845
[Epoch 48; Iter    30/   30] train: loss: 0.1362442
[Epoch 48] ogbg-molclintox: 0.867592 val loss: 0.136766
[Epoch 48] ogbg-molclintox: 0.872606 test loss: 0.176351
[Epoch 49; Iter    30/   30] train: loss: 0.2209165
[Epoch 49] ogbg-molclintox: 0.907203 val loss: 0.133098
[Epoch 49] ogbg-molclintox: 0.875891 test loss: 0.204013
[Epoch 50; Iter    30/   30] train: loss: 0.2303262
[Epoch 50] ogbg-molclintox: 0.902256 val loss: 0.255002
[Epoch 50] ogbg-molclintox: 0.882539 test loss: 0.329051
[Epoch 51; Iter    30/   30] train: loss: 0.2984610
[Epoch 51] ogbg-molclintox: 0.895728 val loss: 0.159536
[Epoch 51] ogbg-molclintox: 0.869865 test loss: 0.185438
[Epoch 52; Iter    30/   30] train: loss: 0.1116350
[Epoch 52] ogbg-molclintox: 0.786471 val loss: 0.156324
[Epoch 52] ogbg-molclintox: 0.821104 test loss: 0.219890
[Epoch 53; Iter    30/   30] train: loss: 0.0992113
[Epoch 53] ogbg-molclintox: 0.865753 val loss: 0.135707
[Epoch 53] ogbg-molclintox: 0.786604 test loss: 0.230386
[Epoch 54; Iter    30/   30] train: loss: 0.0852419
[Epoch 54] ogbg-molclintox: 0.873595 val loss: 0.415577
[Epoch 54] ogbg-molclintox: 0.828946 test loss: 0.476329
[Epoch 55; Iter    30/   30] train: loss: 0.1021174
[Epoch 55] ogbg-molclintox: 0.906503 val loss: 0.169759
[Epoch 55] ogbg-molclintox: 0.849940 test loss: 0.192953
[Epoch 56; Iter    30/   30] train: loss: 0.0423941
[Epoch 56] ogbg-molclintox: 0.794716 val loss: 0.175109
[Epoch 56] ogbg-molclintox: 0.798874 test loss: 0.253169
[Epoch 57; Iter    30/   30] train: loss: 0.0637037
[Epoch 57] ogbg-molclintox: 0.866881 val loss: 0.139085
[Epoch 57] ogbg-molclintox: 0.841683 test loss: 0.220456
[Epoch 58; Iter    30/   30] train: loss: 0.1573220
[Epoch 58] ogbg-molclintox: 0.891188 val loss: 0.150242
[Epoch 58] ogbg-molclintox: 0.887251 test loss: 0.207449
[Epoch 59; Iter    30/   30] train: loss: 0.0580744
[Epoch 59] ogbg-molclintox: 0.875602 val loss: 0.290707
[Epoch 59] ogbg-molclintox: 0.821700 test loss: 0.208118
[Epoch 60; Iter    30/   30] train: loss: 0.0364245
[Epoch 60] ogbg-molclintox: 0.894477 val loss: 0.434108
[Epoch 60] ogbg-molclintox: 0.791344 test loss: 0.279316
[Epoch 61; Iter    30/   30] train: loss: 0.2228811
[Epoch 61] ogbg-molclintox: 0.913863 val loss: 0.184020
[Epoch 61] ogbg-molclintox: 0.866463 test loss: 0.243355
[Epoch 62; Iter    30/   30] train: loss: 0.0812309
[Epoch 62] ogbg-molclintox: 0.847398 val loss: 0.482703
[Epoch 62] ogbg-molclintox: 0.840221 test loss: 0.198146
[Epoch 63; Iter    30/   30] train: loss: 0.0857376
[Epoch 63] ogbg-molclintox: 0.913671 val loss: 0.128759
[Epoch 63] ogbg-molclintox: 0.837170 test loss: 0.209803
[Epoch 64; Iter    30/   30] train: loss: 0.0634105
[Epoch 64] ogbg-molclintox: 0.839708 val loss: 0.160771
[Epoch 64] ogbg-molclintox: 0.859294 test loss: 0.191720
[Epoch 65; Iter    30/   30] train: loss: 0.2175634
[Epoch 65] ogbg-molclintox: 0.908412 val loss: 0.134080
[Epoch 65] ogbg-molclintox: 0.859977 test loss: 0.243363
[Epoch 66; Iter    30/   30] train: loss: 0.0613743
[Epoch 66] ogbg-molclintox: 0.853199 val loss: 0.218960
[Epoch 66] ogbg-molclintox: 0.837042 test loss: 0.229392
[Epoch 67; Iter    30/   30] train: loss: 0.3738680
[Epoch 67] ogbg-molclintox: 0.905179 val loss: 0.173034
[Epoch 67] ogbg-molclintox: 0.817059 test loss: 0.290917
[Epoch 68; Iter    30/   30] train: loss: 0.1104526
[Epoch 68] ogbg-molclintox: 0.886921 val loss: 0.143222
[Epoch 68] ogbg-molclintox: 0.826080 test loss: 0.226247
[Epoch 69; Iter    30/   30] train: loss: 0.0578275
[Epoch 69] ogbg-molclintox: 0.844938 val loss: 0.152326
[Epoch 69] ogbg-molclintox: 0.780125 test loss: 0.297413
[Epoch 70; Iter    30/   30] train: loss: 0.0464570
[Epoch 70] ogbg-molclintox: 0.844201 val loss: 0.160821
[Epoch 70] ogbg-molclintox: 0.811274 test loss: 0.231865
[Epoch 71; Iter    30/   30] train: loss: 0.1032580
[Epoch 71] ogbg-molclintox: 0.901161 val loss: 0.151083
[Epoch 71] ogbg-molclintox: 0.831650 test loss: 0.247380
[Epoch 72; Iter    30/   30] train: loss: 0.4061723
[Epoch 72] ogbg-molclintox: 0.873407 val loss: 0.152629
[Epoch 72] ogbg-molclintox: 0.839508 test loss: 0.221244
[Epoch 73; Iter    30/   30] train: loss: 0.1341040
[Epoch 73] ogbg-molclintox: 0.903757 val loss: 0.150438
[Epoch 73] ogbg-molclintox: 0.854794 test loss: 0.255991
[Epoch 74; Iter    30/   30] train: loss: 0.0644993
[Epoch 74] ogbg-molclintox: 0.869604 val loss: 0.180137
[Epoch 74] ogbg-molclintox: 0.836789 test loss: 0.226362
[Epoch 75; Iter    30/   30] train: loss: 0.1191388
[Epoch 75] ogbg-molclintox: 0.895420 val loss: 0.171812
[Epoch 75] ogbg-molclintox: 0.837598 test loss: 0.280467
[Epoch 76; Iter    30/   30] train: loss: 0.0208092
[Epoch 76] ogbg-molclintox: 0.863401 val loss: 0.175613
[Epoch 76] ogbg-molclintox: 0.830837 test loss: 0.237830
[Epoch 77; Iter    30/   30] train: loss: 0.0143219
[Epoch 77] ogbg-molclintox: 0.852981 val loss: 0.170972
[Epoch 77] ogbg-molclintox: 0.788943 test loss: 0.305067
[Epoch 78; Iter    30/   30] train: loss: 0.0633514
[Epoch 78] ogbg-molclintox: 0.868598 val loss: 0.176702
[Epoch 78] ogbg-molclintox: 0.819841 test loss: 0.312390
[Epoch 79; Iter    30/   30] train: loss: 0.1743945
[Epoch 79] ogbg-molclintox: 0.830568 val loss: 0.149925
[Epoch 79] ogbg-molclintox: 0.825970 test loss: 0.265225
[Epoch 80; Iter    30/   30] train: loss: 0.0576760
[Epoch 80] ogbg-molclintox: 0.882607 val loss: 0.166175
[Epoch 80] ogbg-molclintox: 0.813201 test loss: 0.270859
[Epoch 81; Iter    30/   30] train: loss: 0.0128713
[Epoch 81] ogbg-molclintox: 0.865412 val loss: 0.175922
[Epoch 81] ogbg-molclintox: 0.855866 test loss: 0.254690
[Epoch 82; Iter    30/   30] train: loss: 0.0161975
[Epoch 82] ogbg-molclintox: 0.778103 val loss: 0.226519
[Epoch 82] ogbg-molclintox: 0.823243 test loss: 0.251050
[Epoch 83; Iter    30/   30] train: loss: 0.1533579
[Epoch 83] ogbg-molclintox: 0.823164 val loss: 0.210898
[Epoch 83] ogbg-molclintox: 0.811095 test loss: 0.304830
[Epoch 34] ogbg-molclintox: 0.766418 test loss: 0.262996
[Epoch 35; Iter    30/   30] train: loss: 0.2018135
[Epoch 35] ogbg-molclintox: 0.900007 val loss: 0.185016
[Epoch 35] ogbg-molclintox: 0.853175 test loss: 0.222084
[Epoch 36; Iter    30/   30] train: loss: 0.2655526
[Epoch 36] ogbg-molclintox: 0.909581 val loss: 0.161986
[Epoch 36] ogbg-molclintox: 0.857328 test loss: 0.211776
[Epoch 37; Iter    30/   30] train: loss: 0.2524115
[Epoch 37] ogbg-molclintox: 0.860321 val loss: 0.161340
[Epoch 37] ogbg-molclintox: 0.822076 test loss: 0.214614
[Epoch 38; Iter    30/   30] train: loss: 0.1183044
[Epoch 38] ogbg-molclintox: 0.863682 val loss: 0.149910
[Epoch 38] ogbg-molclintox: 0.835549 test loss: 0.201858
[Epoch 39; Iter    30/   30] train: loss: 0.2115225
[Epoch 39] ogbg-molclintox: 0.863438 val loss: 0.206646
[Epoch 39] ogbg-molclintox: 0.792475 test loss: 0.254411
[Epoch 40; Iter    30/   30] train: loss: 0.1261573
[Epoch 40] ogbg-molclintox: 0.889336 val loss: 0.139348
[Epoch 40] ogbg-molclintox: 0.823956 test loss: 0.201601
[Epoch 41; Iter    30/   30] train: loss: 0.1119754
[Epoch 41] ogbg-molclintox: 0.897356 val loss: 0.137634
[Epoch 41] ogbg-molclintox: 0.851013 test loss: 0.194484
[Epoch 42; Iter    30/   30] train: loss: 0.0944158
[Epoch 42] ogbg-molclintox: 0.860265 val loss: 0.148600
[Epoch 42] ogbg-molclintox: 0.828494 test loss: 0.201985
[Epoch 43; Iter    30/   30] train: loss: 0.1271299
[Epoch 43] ogbg-molclintox: 0.897077 val loss: 0.143334
[Epoch 43] ogbg-molclintox: 0.838301 test loss: 0.196663
[Epoch 44; Iter    30/   30] train: loss: 0.1506230
[Epoch 44] ogbg-molclintox: 0.837167 val loss: 0.166519
[Epoch 44] ogbg-molclintox: 0.795683 test loss: 0.233848
[Epoch 45; Iter    30/   30] train: loss: 0.1728381
[Epoch 45] ogbg-molclintox: 0.904048 val loss: 0.132191
[Epoch 45] ogbg-molclintox: 0.848835 test loss: 0.190376
[Epoch 46; Iter    30/   30] train: loss: 0.0718788
[Epoch 46] ogbg-molclintox: 0.881307 val loss: 0.137018
[Epoch 46] ogbg-molclintox: 0.835227 test loss: 0.217151
[Epoch 47; Iter    30/   30] train: loss: 0.2901019
[Epoch 47] ogbg-molclintox: 0.924404 val loss: 0.142418
[Epoch 47] ogbg-molclintox: 0.851953 test loss: 0.198102
[Epoch 48; Iter    30/   30] train: loss: 0.4100999
[Epoch 48] ogbg-molclintox: 0.894117 val loss: 0.126342
[Epoch 48] ogbg-molclintox: 0.889155 test loss: 0.173902
[Epoch 49; Iter    30/   30] train: loss: 0.0576722
[Epoch 49] ogbg-molclintox: 0.781750 val loss: 0.232236
[Epoch 49] ogbg-molclintox: 0.858173 test loss: 0.211396
[Epoch 50; Iter    30/   30] train: loss: 0.2237423
[Epoch 50] ogbg-molclintox: 0.857582 val loss: 0.143062
[Epoch 50] ogbg-molclintox: 0.880307 test loss: 0.196240
[Epoch 51; Iter    30/   30] train: loss: 0.1365755
[Epoch 51] ogbg-molclintox: 0.898754 val loss: 0.150025
[Epoch 51] ogbg-molclintox: 0.895386 test loss: 0.187866
[Epoch 52; Iter    30/   30] train: loss: 0.1481995
[Epoch 52] ogbg-molclintox: 0.877529 val loss: 0.128629
[Epoch 52] ogbg-molclintox: 0.902236 test loss: 0.168418
[Epoch 53; Iter    30/   30] train: loss: 0.1216648
[Epoch 53] ogbg-molclintox: 0.858052 val loss: 0.136819
[Epoch 53] ogbg-molclintox: 0.838142 test loss: 0.263919
[Epoch 54; Iter    30/   30] train: loss: 0.0939447
[Epoch 54] ogbg-molclintox: 0.752262 val loss: 0.183474
[Epoch 54] ogbg-molclintox: 0.842563 test loss: 0.187051
[Epoch 55; Iter    30/   30] train: loss: 0.0701190
[Epoch 55] ogbg-molclintox: 0.897847 val loss: 0.114685
[Epoch 55] ogbg-molclintox: 0.900919 test loss: 0.161086
[Epoch 56; Iter    30/   30] train: loss: 0.0907838
[Epoch 56] ogbg-molclintox: 0.886750 val loss: 0.157852
[Epoch 56] ogbg-molclintox: 0.895332 test loss: 0.180742
[Epoch 57; Iter    30/   30] train: loss: 0.1399004
[Epoch 57] ogbg-molclintox: 0.905580 val loss: 0.164850
[Epoch 57] ogbg-molclintox: 0.871965 test loss: 0.218228
[Epoch 58; Iter    30/   30] train: loss: 0.2528191
[Epoch 58] ogbg-molclintox: 0.891711 val loss: 0.121718
[Epoch 58] ogbg-molclintox: 0.881801 test loss: 0.181417
[Epoch 59; Iter    30/   30] train: loss: 0.0879027
[Epoch 59] ogbg-molclintox: 0.897469 val loss: 0.202436
[Epoch 59] ogbg-molclintox: 0.887204 test loss: 0.235131
[Epoch 60; Iter    30/   30] train: loss: 0.1024636
[Epoch 60] ogbg-molclintox: 0.846672 val loss: 0.151721
[Epoch 60] ogbg-molclintox: 0.852422 test loss: 0.186094
[Epoch 61; Iter    30/   30] train: loss: 0.0820734
[Epoch 61] ogbg-molclintox: 0.895094 val loss: 0.142560
[Epoch 61] ogbg-molclintox: 0.858000 test loss: 0.229947
[Epoch 62; Iter    30/   30] train: loss: 0.0838101
[Epoch 62] ogbg-molclintox: 0.785631 val loss: 0.187689
[Epoch 62] ogbg-molclintox: 0.831197 test loss: 0.245485
[Epoch 63; Iter    30/   30] train: loss: 0.1838244
[Epoch 63] ogbg-molclintox: 0.774253 val loss: 0.172726
[Epoch 63] ogbg-molclintox: 0.779177 test loss: 0.226164
[Epoch 64; Iter    30/   30] train: loss: 0.0739021
[Epoch 64] ogbg-molclintox: 0.864989 val loss: 0.171686
[Epoch 64] ogbg-molclintox: 0.856808 test loss: 0.220668
[Epoch 65; Iter    30/   30] train: loss: 0.0121628
[Epoch 65] ogbg-molclintox: 0.864788 val loss: 0.148106
[Epoch 65] ogbg-molclintox: 0.823582 test loss: 0.222221
[Epoch 66; Iter    30/   30] train: loss: 0.1836696
[Epoch 66] ogbg-molclintox: 0.887172 val loss: 0.146032
[Epoch 66] ogbg-molclintox: 0.825806 test loss: 0.230733
[Epoch 67; Iter    30/   30] train: loss: 0.0863373
[Epoch 67] ogbg-molclintox: 0.876041 val loss: 0.195363
[Epoch 67] ogbg-molclintox: 0.866594 test loss: 0.229757
[Epoch 68; Iter    30/   30] train: loss: 0.1053946
[Epoch 68] ogbg-molclintox: 0.887767 val loss: 0.189056
[Epoch 68] ogbg-molclintox: 0.867070 test loss: 0.232403
[Epoch 69; Iter    30/   30] train: loss: 0.0082602
[Epoch 69] ogbg-molclintox: 0.853165 val loss: 0.160273
[Epoch 69] ogbg-molclintox: 0.888457 test loss: 0.200722
[Epoch 70; Iter    30/   30] train: loss: 0.0404070
[Epoch 70] ogbg-molclintox: 0.857680 val loss: 0.216949
[Epoch 70] ogbg-molclintox: 0.848975 test loss: 0.242466
[Epoch 71; Iter    30/   30] train: loss: 0.0067696
[Epoch 71] ogbg-molclintox: 0.878812 val loss: 0.151905
[Epoch 71] ogbg-molclintox: 0.859057 test loss: 0.212681
[Epoch 72; Iter    30/   30] train: loss: 0.1469409
[Epoch 72] ogbg-molclintox: 0.871270 val loss: 0.165721
[Epoch 72] ogbg-molclintox: 0.858922 test loss: 0.231085
[Epoch 73; Iter    30/   30] train: loss: 0.1295138
[Epoch 73] ogbg-molclintox: 0.850657 val loss: 0.214029
[Epoch 73] ogbg-molclintox: 0.881641 test loss: 0.219993
[Epoch 74; Iter    30/   30] train: loss: 0.0272570
[Epoch 74] ogbg-molclintox: 0.851854 val loss: 0.169630
[Epoch 74] ogbg-molclintox: 0.835442 test loss: 0.262726
[Epoch 75; Iter    30/   30] train: loss: 0.1328375
[Epoch 75] ogbg-molclintox: 0.824348 val loss: 0.225092
[Epoch 75] ogbg-molclintox: 0.861631 test loss: 0.264386
[Epoch 76; Iter    30/   30] train: loss: 0.1199023
[Epoch 76] ogbg-molclintox: 0.863215 val loss: 0.181656
[Epoch 76] ogbg-molclintox: 0.837518 test loss: 0.238646
[Epoch 77; Iter    30/   30] train: loss: 0.1164989
[Epoch 77] ogbg-molclintox: 0.824998 val loss: 0.220114
[Epoch 77] ogbg-molclintox: 0.833130 test loss: 0.281949
[Epoch 78; Iter    30/   30] train: loss: 0.0130024
[Epoch 78] ogbg-molclintox: 0.801659 val loss: 0.182454
[Epoch 78] ogbg-molclintox: 0.799889 test loss: 0.263227
[Epoch 79; Iter    30/   30] train: loss: 0.0476241
[Epoch 79] ogbg-molclintox: 0.804253 val loss: 0.194155
[Epoch 79] ogbg-molclintox: 0.852712 test loss: 0.240000
[Epoch 80; Iter    30/   30] train: loss: 0.0053367
[Epoch 80] ogbg-molclintox: 0.817469 val loss: 0.167217
[Epoch 80] ogbg-molclintox: 0.827186 test loss: 0.236689
[Epoch 81; Iter    30/   30] train: loss: 0.0070215
[Epoch 81] ogbg-molclintox: 0.849579 val loss: 0.197937
[Epoch 81] ogbg-molclintox: 0.882386 test loss: 0.221500
[Epoch 82; Iter    30/   30] train: loss: 0.0090466
[Epoch 82] ogbg-molclintox: 0.806996 val loss: 0.210082
[Epoch 82] ogbg-molclintox: 0.839266 test loss: 0.255290
[Epoch 83; Iter    30/   30] train: loss: 0.0487556
[Epoch 83] ogbg-molclintox: 0.856030 val loss: 0.169648
[Epoch 83] ogbg-molclintox: 0.878405 test loss: 0.228058
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.0645911
[Epoch 84] ogbg-molclintox: 0.836744 val loss: 1.635832
[Epoch 84] ogbg-molclintox: 0.818224 test loss: 1.058662
[Epoch 85; Iter    30/   30] train: loss: 0.1645536
[Epoch 85] ogbg-molclintox: 0.662416 val loss: 0.255872
[Epoch 85] ogbg-molclintox: 0.737447 test loss: 0.355934
[Epoch 86; Iter    30/   30] train: loss: 0.0813751
[Epoch 86] ogbg-molclintox: 0.762362 val loss: 0.234731
[Epoch 86] ogbg-molclintox: 0.857301 test loss: 0.241810
[Epoch 87; Iter    30/   30] train: loss: 0.0103813
[Epoch 87] ogbg-molclintox: 0.860500 val loss: 0.208044
[Epoch 87] ogbg-molclintox: 0.848584 test loss: 0.266767
[Epoch 88; Iter    30/   30] train: loss: 0.0470801
[Epoch 88] ogbg-molclintox: 0.721298 val loss: 0.244599
[Epoch 88] ogbg-molclintox: 0.829996 test loss: 0.290489
[Epoch 89; Iter    30/   30] train: loss: 0.0106078
[Epoch 89] ogbg-molclintox: 0.859961 val loss: 0.187962
[Epoch 89] ogbg-molclintox: 0.824888 test loss: 0.286359
[Epoch 90; Iter    30/   30] train: loss: 0.2376174
[Epoch 90] ogbg-molclintox: 0.798279 val loss: 0.210480
[Epoch 90] ogbg-molclintox: 0.874169 test loss: 0.229827
[Epoch 91; Iter    30/   30] train: loss: 0.0350506
[Epoch 91] ogbg-molclintox: 0.830310 val loss: 0.198883
[Epoch 91] ogbg-molclintox: 0.860653 test loss: 0.247576
[Epoch 92; Iter    30/   30] train: loss: 0.0120082
[Epoch 92] ogbg-molclintox: 0.737037 val loss: 0.254776
[Epoch 92] ogbg-molclintox: 0.797125 test loss: 0.324826
[Epoch 93; Iter    30/   30] train: loss: 0.0067360
[Epoch 93] ogbg-molclintox: 0.805452 val loss: 0.248388
[Epoch 93] ogbg-molclintox: 0.826933 test loss: 0.298212
[Epoch 94; Iter    30/   30] train: loss: 0.0783037
[Epoch 94] ogbg-molclintox: 0.765356 val loss: 0.217037
[Epoch 94] ogbg-molclintox: 0.821724 test loss: 0.256356
[Epoch 95; Iter    30/   30] train: loss: 0.1560065
[Epoch 95] ogbg-molclintox: 0.818785 val loss: 0.198924
[Epoch 95] ogbg-molclintox: 0.824858 test loss: 0.294473
[Epoch 96; Iter    30/   30] train: loss: 0.0207652
[Epoch 96] ogbg-molclintox: 0.820152 val loss: 0.217786
[Epoch 96] ogbg-molclintox: 0.827190 test loss: 0.303861
[Epoch 97; Iter    30/   30] train: loss: 0.0057615
[Epoch 97] ogbg-molclintox: 0.811033 val loss: 0.201849
[Epoch 97] ogbg-molclintox: 0.857296 test loss: 0.240453
[Epoch 98; Iter    30/   30] train: loss: 0.0196968
[Epoch 98] ogbg-molclintox: 0.762329 val loss: 0.254279
[Epoch 98] ogbg-molclintox: 0.849729 test loss: 0.288350
[Epoch 99; Iter    30/   30] train: loss: 0.0389185
[Epoch 99] ogbg-molclintox: 0.841957 val loss: 0.213099
[Epoch 99] ogbg-molclintox: 0.802895 test loss: 0.299873
[Epoch 100; Iter    30/   30] train: loss: 0.0044943
[Epoch 100] ogbg-molclintox: 0.804039 val loss: 0.224058
[Epoch 100] ogbg-molclintox: 0.837293 test loss: 0.302062
[Epoch 101; Iter    30/   30] train: loss: 0.1054386
[Epoch 101] ogbg-molclintox: 0.665015 val loss: 0.359298
[Epoch 101] ogbg-molclintox: 0.831712 test loss: 0.339214
[Epoch 102; Iter    30/   30] train: loss: 0.1677875
[Epoch 102] ogbg-molclintox: 0.804480 val loss: 0.217877
[Epoch 102] ogbg-molclintox: 0.817849 test loss: 0.305664
[Epoch 103; Iter    30/   30] train: loss: 0.0828395
[Epoch 103] ogbg-molclintox: 0.801338 val loss: 0.213656
[Epoch 103] ogbg-molclintox: 0.833026 test loss: 0.282229
[Epoch 104; Iter    30/   30] train: loss: 0.0620252
[Epoch 104] ogbg-molclintox: 0.820486 val loss: 0.251043
[Epoch 104] ogbg-molclintox: 0.840320 test loss: 0.385745
[Epoch 105; Iter    30/   30] train: loss: 0.0197864
[Epoch 105] ogbg-molclintox: 0.799078 val loss: 0.198191
[Epoch 105] ogbg-molclintox: 0.811003 test loss: 0.283315
[Epoch 106; Iter    30/   30] train: loss: 0.0415547
[Epoch 106] ogbg-molclintox: 0.798383 val loss: 0.221777
[Epoch 106] ogbg-molclintox: 0.841129 test loss: 0.267965
[Epoch 107; Iter    30/   30] train: loss: 0.0075880
[Epoch 107] ogbg-molclintox: 0.797230 val loss: 0.234488
[Epoch 107] ogbg-molclintox: 0.832677 test loss: 0.312905
[Epoch 108; Iter    30/   30] train: loss: 0.0045914
[Epoch 108] ogbg-molclintox: 0.780789 val loss: 0.277085
[Epoch 108] ogbg-molclintox: 0.853405 test loss: 0.282760
[Epoch 109; Iter    30/   30] train: loss: 0.0299234
[Epoch 109] ogbg-molclintox: 0.830204 val loss: 0.218103
[Epoch 109] ogbg-molclintox: 0.845531 test loss: 0.297229
[Epoch 110; Iter    30/   30] train: loss: 0.0063750
[Epoch 110] ogbg-molclintox: 0.819074 val loss: 0.211610
[Epoch 110] ogbg-molclintox: 0.819386 test loss: 0.359218
[Epoch 111; Iter    30/   30] train: loss: 0.0063574
[Epoch 111] ogbg-molclintox: 0.806251 val loss: 0.233953
[Epoch 111] ogbg-molclintox: 0.820656 test loss: 0.299924
[Epoch 112; Iter    30/   30] train: loss: 0.0025040
[Epoch 112] ogbg-molclintox: 0.811089 val loss: 0.229678
[Epoch 112] ogbg-molclintox: 0.837424 test loss: 0.297004
[Epoch 113; Iter    30/   30] train: loss: 0.0004941
[Epoch 113] ogbg-molclintox: 0.778347 val loss: 0.264152
[Epoch 113] ogbg-molclintox: 0.842049 test loss: 0.307752
[Epoch 114; Iter    30/   30] train: loss: 0.0014829
[Epoch 114] ogbg-molclintox: 0.785825 val loss: 0.255900
[Epoch 114] ogbg-molclintox: 0.833820 test loss: 0.309782
[Epoch 115; Iter    30/   30] train: loss: 0.0414959
[Epoch 115] ogbg-molclintox: 0.779757 val loss: 0.252697
[Epoch 115] ogbg-molclintox: 0.837017 test loss: 0.296641
[Epoch 116; Iter    30/   30] train: loss: 0.0239354
[Epoch 116] ogbg-molclintox: 0.792717 val loss: 0.265932
[Epoch 116] ogbg-molclintox: 0.824540 test loss: 0.330806
[Epoch 117; Iter    30/   30] train: loss: 0.0045842
[Epoch 117] ogbg-molclintox: 0.787119 val loss: 0.262135
[Epoch 117] ogbg-molclintox: 0.836816 test loss: 0.320328
[Epoch 118; Iter    30/   30] train: loss: 0.0051290
[Epoch 118] ogbg-molclintox: 0.770001 val loss: 0.273681
[Epoch 118] ogbg-molclintox: 0.814159 test loss: 0.330785
[Epoch 119; Iter    30/   30] train: loss: 0.0495816
[Epoch 119] ogbg-molclintox: 0.764984 val loss: 0.268317
[Epoch 119] ogbg-molclintox: 0.838979 test loss: 0.320005
[Epoch 120; Iter    30/   30] train: loss: 0.0019866
[Epoch 120] ogbg-molclintox: 0.781138 val loss: 0.257693
[Epoch 120] ogbg-molclintox: 0.870782 test loss: 0.294869
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 52.
Statistics on  val_best_checkpoint
mean_pred: 0.09345674514770508
std_pred: 5.043857574462891
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.7180790100757402
rocauc: 0.9284389197375063
ogbg-molclintox: 0.9284389197375063
OGBNanLabelBCEWithLogitsLoss: 0.11635522805154323
Statistics on  test
mean_pred: 0.09452906250953674
std_pred: 5.0742011070251465
mean_targets: 0.5101351737976074
std_targets: 0.5003200173377991
prcauc: 0.7002211738290192
rocauc: 0.8896314522500481
ogbg-molclintox: 0.8896314522500481
OGBNanLabelBCEWithLogitsLoss: 0.17799181658774615
Statistics on  train
mean_pred: 0.09159840643405914
std_pred: 5.137046813964844
mean_targets: 0.5050790309906006
std_targets: 0.5001153349876404
prcauc: 0.8912620793819306
rocauc: 0.9641694871445177
ogbg-molclintox: 0.9641694871445177
OGBNanLabelBCEWithLogitsLoss: 0.1253753736615181
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 84; Iter    30/   30] train: loss: 0.1779241
[Epoch 84] ogbg-molclintox: 0.871878 val loss: 0.189666
[Epoch 84] ogbg-molclintox: 0.838385 test loss: 0.292763
[Epoch 85; Iter    30/   30] train: loss: 0.0760516
[Epoch 85] ogbg-molclintox: 0.840133 val loss: 0.179271
[Epoch 85] ogbg-molclintox: 0.840796 test loss: 0.255782
[Epoch 86; Iter    30/   30] train: loss: 0.0182075
[Epoch 86] ogbg-molclintox: 0.867075 val loss: 0.173767
[Epoch 86] ogbg-molclintox: 0.826447 test loss: 0.251591
[Epoch 87; Iter    30/   30] train: loss: 0.0142059
[Epoch 87] ogbg-molclintox: 0.811543 val loss: 0.181294
[Epoch 87] ogbg-molclintox: 0.796013 test loss: 0.293771
[Epoch 88; Iter    30/   30] train: loss: 0.0306758
[Epoch 88] ogbg-molclintox: 0.852232 val loss: 0.226801
[Epoch 88] ogbg-molclintox: 0.854073 test loss: 0.311664
[Epoch 89; Iter    30/   30] train: loss: 0.1459397
[Epoch 89] ogbg-molclintox: 0.823328 val loss: 0.188239
[Epoch 89] ogbg-molclintox: 0.836908 test loss: 0.258756
[Epoch 90; Iter    30/   30] train: loss: 0.0657734
[Epoch 90] ogbg-molclintox: 0.844307 val loss: 0.224139
[Epoch 90] ogbg-molclintox: 0.846764 test loss: 0.309996
[Epoch 91; Iter    30/   30] train: loss: 0.0073614
[Epoch 91] ogbg-molclintox: 0.758314 val loss: 0.267776
[Epoch 91] ogbg-molclintox: 0.789152 test loss: 0.291526
[Epoch 92; Iter    30/   30] train: loss: 0.1180433
[Epoch 92] ogbg-molclintox: 0.876398 val loss: 0.196503
[Epoch 92] ogbg-molclintox: 0.851322 test loss: 0.260043
[Epoch 93; Iter    30/   30] train: loss: 0.0105680
[Epoch 93] ogbg-molclintox: 0.849425 val loss: 0.177460
[Epoch 93] ogbg-molclintox: 0.825823 test loss: 0.291149
[Epoch 94; Iter    30/   30] train: loss: 0.0044829
[Epoch 94] ogbg-molclintox: 0.801150 val loss: 0.277040
[Epoch 94] ogbg-molclintox: 0.776398 test loss: 0.368858
[Epoch 95; Iter    30/   30] train: loss: 0.0272452
[Epoch 95] ogbg-molclintox: 0.854335 val loss: 0.196784
[Epoch 95] ogbg-molclintox: 0.861609 test loss: 0.289486
[Epoch 96; Iter    30/   30] train: loss: 0.0052980
[Epoch 96] ogbg-molclintox: 0.848012 val loss: 0.199443
[Epoch 96] ogbg-molclintox: 0.861202 test loss: 0.296216
[Epoch 97; Iter    30/   30] train: loss: 0.0148046
[Epoch 97] ogbg-molclintox: 0.859339 val loss: 0.186253
[Epoch 97] ogbg-molclintox: 0.803657 test loss: 0.367328
[Epoch 98; Iter    30/   30] train: loss: 0.1328653
[Epoch 98] ogbg-molclintox: 0.853983 val loss: 0.182859
[Epoch 98] ogbg-molclintox: 0.808132 test loss: 0.315379
[Epoch 99; Iter    30/   30] train: loss: 0.0109395
[Epoch 99] ogbg-molclintox: 0.805476 val loss: 0.273682
[Epoch 99] ogbg-molclintox: 0.805357 test loss: 0.372008
[Epoch 100; Iter    30/   30] train: loss: 0.3023671
[Epoch 100] ogbg-molclintox: 0.837803 val loss: 0.276028
[Epoch 100] ogbg-molclintox: 0.790727 test loss: 0.342286
[Epoch 101; Iter    30/   30] train: loss: 0.0837111
[Epoch 101] ogbg-molclintox: 0.830195 val loss: 0.204463
[Epoch 101] ogbg-molclintox: 0.812079 test loss: 0.438878
[Epoch 102; Iter    30/   30] train: loss: 0.0566671
[Epoch 102] ogbg-molclintox: 0.820890 val loss: 0.285614
[Epoch 102] ogbg-molclintox: 0.789347 test loss: 0.292364
[Epoch 103; Iter    30/   30] train: loss: 0.0408642
[Epoch 103] ogbg-molclintox: 0.833587 val loss: 0.365001
[Epoch 103] ogbg-molclintox: 0.812175 test loss: 0.281912
[Epoch 104; Iter    30/   30] train: loss: 0.0045354
[Epoch 104] ogbg-molclintox: 0.756976 val loss: 0.309925
[Epoch 104] ogbg-molclintox: 0.757823 test loss: 0.324931
[Epoch 105; Iter    30/   30] train: loss: 0.2391441
[Epoch 105] ogbg-molclintox: 0.831150 val loss: 0.262686
[Epoch 105] ogbg-molclintox: 0.796570 test loss: 0.335572
[Epoch 106; Iter    30/   30] train: loss: 0.0306461
[Epoch 106] ogbg-molclintox: 0.826774 val loss: 0.485638
[Epoch 106] ogbg-molclintox: 0.819061 test loss: 0.293736
[Epoch 107; Iter    30/   30] train: loss: 0.0131338
[Epoch 107] ogbg-molclintox: 0.825940 val loss: 0.343119
[Epoch 107] ogbg-molclintox: 0.805788 test loss: 0.343486
[Epoch 108; Iter    30/   30] train: loss: 0.0584226
[Epoch 108] ogbg-molclintox: 0.804526 val loss: 0.506449
[Epoch 108] ogbg-molclintox: 0.809160 test loss: 0.400612
[Epoch 109; Iter    30/   30] train: loss: 0.0085531
[Epoch 109] ogbg-molclintox: 0.772627 val loss: 0.251070
[Epoch 109] ogbg-molclintox: 0.807995 test loss: 0.335878
[Epoch 110; Iter    30/   30] train: loss: 0.1232240
[Epoch 110] ogbg-molclintox: 0.844557 val loss: 0.201711
[Epoch 110] ogbg-molclintox: 0.871279 test loss: 0.270310
[Epoch 111; Iter    30/   30] train: loss: 0.0190428
[Epoch 111] ogbg-molclintox: 0.736869 val loss: 0.270944
[Epoch 111] ogbg-molclintox: 0.790011 test loss: 0.313957
[Epoch 112; Iter    30/   30] train: loss: 0.0098496
[Epoch 112] ogbg-molclintox: 0.809195 val loss: 0.258724
[Epoch 112] ogbg-molclintox: 0.849598 test loss: 0.303894
[Epoch 113; Iter    30/   30] train: loss: 0.0050297
[Epoch 113] ogbg-molclintox: 0.822401 val loss: 0.204160
[Epoch 113] ogbg-molclintox: 0.829803 test loss: 0.292746
[Epoch 114; Iter    30/   30] train: loss: 0.0069876
[Epoch 114] ogbg-molclintox: 0.813258 val loss: 0.234124
[Epoch 114] ogbg-molclintox: 0.834975 test loss: 0.302292
[Epoch 115; Iter    30/   30] train: loss: 0.1085104
[Epoch 115] ogbg-molclintox: 0.773257 val loss: 0.269278
[Epoch 115] ogbg-molclintox: 0.794886 test loss: 0.331082
[Epoch 116; Iter    30/   30] train: loss: 0.0027548
[Epoch 116] ogbg-molclintox: 0.821090 val loss: 0.244455
[Epoch 116] ogbg-molclintox: 0.828075 test loss: 0.311393
[Epoch 117; Iter    30/   30] train: loss: 0.0784464
[Epoch 117] ogbg-molclintox: 0.729911 val loss: 0.344730
[Epoch 117] ogbg-molclintox: 0.740932 test loss: 0.402615
[Epoch 118; Iter    30/   30] train: loss: 0.0248907
[Epoch 118] ogbg-molclintox: 0.790292 val loss: 0.461471
[Epoch 118] ogbg-molclintox: 0.787190 test loss: 0.540621
[Epoch 119; Iter    30/   30] train: loss: 0.0029331
[Epoch 119] ogbg-molclintox: 0.786608 val loss: 0.295143
[Epoch 119] ogbg-molclintox: 0.762844 test loss: 0.434005
[Epoch 120; Iter    30/   30] train: loss: 0.0096890
[Epoch 120] ogbg-molclintox: 0.809878 val loss: 0.312431
[Epoch 120] ogbg-molclintox: 0.779799 test loss: 0.370335
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 41.
Statistics on  val_best_checkpoint
mean_pred: 0.051125045865774155
std_pred: 3.8210790157318115
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.693674502587857
rocauc: 0.9204330725222951
ogbg-molclintox: 0.9204330725222951
OGBNanLabelBCEWithLogitsLoss: 0.12608239986002445
Statistics on  test
mean_pred: 0.050887394696474075
std_pred: 3.8204054832458496
mean_targets: 0.5101351737976074
std_targets: 0.5003200173377991
prcauc: 0.6732348644223284
rocauc: 0.8708034945556602
ogbg-molclintox: 0.8708034945556602
OGBNanLabelBCEWithLogitsLoss: 0.18640249632298947
Statistics on  train
mean_pred: 0.048091623932123184
std_pred: 3.8206655979156494
mean_targets: 0.5050790309906006
std_targets: 0.5001153349876404
prcauc: 0.8421736761685157
rocauc: 0.9475743569009246
ogbg-molclintox: 0.9475743569009246
OGBNanLabelBCEWithLogitsLoss: 0.16713260697821777
[Epoch 84; Iter    30/   30] train: loss: 0.0966237
[Epoch 84] ogbg-molclintox: 0.784270 val loss: 0.198610
[Epoch 84] ogbg-molclintox: 0.801330 test loss: 0.248937
[Epoch 85; Iter    30/   30] train: loss: 0.0546215
[Epoch 85] ogbg-molclintox: 0.794209 val loss: 0.236597
[Epoch 85] ogbg-molclintox: 0.824348 test loss: 0.277352
[Epoch 86; Iter    30/   30] train: loss: 0.0203191
[Epoch 86] ogbg-molclintox: 0.807306 val loss: 0.204607
[Epoch 86] ogbg-molclintox: 0.852802 test loss: 0.235007
[Epoch 87; Iter    30/   30] train: loss: 0.0193665
[Epoch 87] ogbg-molclintox: 0.807138 val loss: 0.195899
[Epoch 87] ogbg-molclintox: 0.880224 test loss: 0.245021
[Epoch 88; Iter    30/   30] train: loss: 0.0383849
[Epoch 88] ogbg-molclintox: 0.811469 val loss: 0.180060
[Epoch 88] ogbg-molclintox: 0.854236 test loss: 0.227321
[Epoch 89; Iter    30/   30] train: loss: 0.0553467
[Epoch 89] ogbg-molclintox: 0.784743 val loss: 0.226503
[Epoch 89] ogbg-molclintox: 0.884369 test loss: 0.251991
[Epoch 90; Iter    30/   30] train: loss: 0.0696143
[Epoch 90] ogbg-molclintox: 0.795556 val loss: 0.209796
[Epoch 90] ogbg-molclintox: 0.884983 test loss: 0.223444
[Epoch 91; Iter    30/   30] train: loss: 0.0247837
[Epoch 91] ogbg-molclintox: 0.815379 val loss: 0.207037
[Epoch 91] ogbg-molclintox: 0.887218 test loss: 0.232141
[Epoch 92; Iter    30/   30] train: loss: 0.0248045
[Epoch 92] ogbg-molclintox: 0.789123 val loss: 0.218347
[Epoch 92] ogbg-molclintox: 0.887038 test loss: 0.235392
[Epoch 93; Iter    30/   30] train: loss: 0.1377013
[Epoch 93] ogbg-molclintox: 0.797561 val loss: 0.219098
[Epoch 93] ogbg-molclintox: 0.876169 test loss: 0.249786
[Epoch 94; Iter    30/   30] train: loss: 0.0079631
[Epoch 94] ogbg-molclintox: 0.819465 val loss: 0.199450
[Epoch 94] ogbg-molclintox: 0.877871 test loss: 0.253476
[Epoch 95; Iter    30/   30] train: loss: 0.0093502
[Epoch 95] ogbg-molclintox: 0.796877 val loss: 0.212855
[Epoch 95] ogbg-molclintox: 0.868084 test loss: 0.241327
[Epoch 96; Iter    30/   30] train: loss: 0.0395108
[Epoch 96] ogbg-molclintox: 0.798004 val loss: 0.225704
[Epoch 96] ogbg-molclintox: 0.887696 test loss: 0.259978
[Epoch 97; Iter    30/   30] train: loss: 0.0063322
[Epoch 97] ogbg-molclintox: 0.791636 val loss: 0.219822
[Epoch 97] ogbg-molclintox: 0.862795 test loss: 0.262939
[Epoch 98; Iter    30/   30] train: loss: 0.0163622
[Epoch 98] ogbg-molclintox: 0.799966 val loss: 0.225402
[Epoch 98] ogbg-molclintox: 0.875168 test loss: 0.255060
[Epoch 99; Iter    30/   30] train: loss: 0.0043020
[Epoch 99] ogbg-molclintox: 0.797127 val loss: 0.219008
[Epoch 99] ogbg-molclintox: 0.877264 test loss: 0.248794
[Epoch 100; Iter    30/   30] train: loss: 0.0244126
[Epoch 100] ogbg-molclintox: 0.805684 val loss: 0.234150
[Epoch 100] ogbg-molclintox: 0.871042 test loss: 0.257791
[Epoch 101; Iter    30/   30] train: loss: 0.0553825
[Epoch 101] ogbg-molclintox: 0.821606 val loss: 0.208682
[Epoch 101] ogbg-molclintox: 0.863241 test loss: 0.260187
[Epoch 102; Iter    30/   30] train: loss: 0.0027215
[Epoch 102] ogbg-molclintox: 0.816165 val loss: 0.208884
[Epoch 102] ogbg-molclintox: 0.886080 test loss: 0.249987
[Epoch 103; Iter    30/   30] train: loss: 0.2339814
[Epoch 103] ogbg-molclintox: 0.767315 val loss: 0.243666
[Epoch 103] ogbg-molclintox: 0.858402 test loss: 0.274987
[Epoch 104; Iter    30/   30] train: loss: 0.0052562
[Epoch 104] ogbg-molclintox: 0.787232 val loss: 0.232520
[Epoch 104] ogbg-molclintox: 0.885243 test loss: 0.248577
[Epoch 105; Iter    30/   30] train: loss: 0.0110416
[Epoch 105] ogbg-molclintox: 0.793829 val loss: 0.229659
[Epoch 105] ogbg-molclintox: 0.875266 test loss: 0.250798
[Epoch 106; Iter    30/   30] train: loss: 0.0049551
[Epoch 106] ogbg-molclintox: 0.773591 val loss: 0.216497
[Epoch 106] ogbg-molclintox: 0.863346 test loss: 0.241782
[Epoch 107; Iter    30/   30] train: loss: 0.0036296
[Epoch 107] ogbg-molclintox: 0.800645 val loss: 0.216294
[Epoch 107] ogbg-molclintox: 0.874664 test loss: 0.265507
[Epoch 108; Iter    30/   30] train: loss: 0.0034412
[Epoch 108] ogbg-molclintox: 0.797262 val loss: 0.217197
[Epoch 108] ogbg-molclintox: 0.822995 test loss: 0.273129
[Epoch 109; Iter    30/   30] train: loss: 0.0057497
[Epoch 109] ogbg-molclintox: 0.759173 val loss: 0.242223
[Epoch 109] ogbg-molclintox: 0.834040 test loss: 0.284459
[Epoch 110; Iter    30/   30] train: loss: 0.0134194
[Epoch 110] ogbg-molclintox: 0.788080 val loss: 0.215878
[Epoch 110] ogbg-molclintox: 0.854835 test loss: 0.259499
[Epoch 111; Iter    30/   30] train: loss: 0.0674386
[Epoch 111] ogbg-molclintox: 0.810542 val loss: 0.219471
[Epoch 111] ogbg-molclintox: 0.888524 test loss: 0.251208
[Epoch 112; Iter    30/   30] train: loss: 0.0148018
[Epoch 112] ogbg-molclintox: 0.812272 val loss: 0.237758
[Epoch 112] ogbg-molclintox: 0.883797 test loss: 0.272901
[Epoch 113; Iter    30/   30] train: loss: 0.0056693
[Epoch 113] ogbg-molclintox: 0.763944 val loss: 0.247961
[Epoch 113] ogbg-molclintox: 0.856620 test loss: 0.260663
[Epoch 114; Iter    30/   30] train: loss: 0.0039053
[Epoch 114] ogbg-molclintox: 0.794626 val loss: 0.227858
[Epoch 114] ogbg-molclintox: 0.881572 test loss: 0.268423
[Epoch 115; Iter    30/   30] train: loss: 0.0092904
[Epoch 115] ogbg-molclintox: 0.779038 val loss: 0.250391
[Epoch 115] ogbg-molclintox: 0.879591 test loss: 0.276551
[Epoch 116; Iter    30/   30] train: loss: 0.0047943
[Epoch 116] ogbg-molclintox: 0.791080 val loss: 0.239611
[Epoch 116] ogbg-molclintox: 0.890285 test loss: 0.252419
[Epoch 117; Iter    30/   30] train: loss: 0.0989710
[Epoch 117] ogbg-molclintox: 0.754286 val loss: 0.247135
[Epoch 117] ogbg-molclintox: 0.871789 test loss: 0.272390
[Epoch 118; Iter    30/   30] train: loss: 0.0072482
[Epoch 118] ogbg-molclintox: 0.761764 val loss: 0.237102
[Epoch 118] ogbg-molclintox: 0.843310 test loss: 0.282949
[Epoch 119; Iter    30/   30] train: loss: 0.0110254
[Epoch 119] ogbg-molclintox: 0.809776 val loss: 0.249038
[Epoch 119] ogbg-molclintox: 0.883000 test loss: 0.284915
[Epoch 120; Iter    30/   30] train: loss: 0.0495422
[Epoch 120] ogbg-molclintox: 0.762886 val loss: 0.237040
[Epoch 120] ogbg-molclintox: 0.839824 test loss: 0.260273
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 47.
Statistics on  val_best_checkpoint
mean_pred: 0.07365363091230392
std_pred: 3.9287750720977783
mean_targets: 0.505084753036499
std_targets: 0.5003983974456787
prcauc: 0.736494640332023
rocauc: 0.924404341241797
ogbg-molclintox: 0.924404341241797
OGBNanLabelBCEWithLogitsLoss: 0.14241780042648317
Statistics on  test
mean_pred: 0.07338213175535202
std_pred: 3.8580427169799805
mean_targets: 0.5101351737976074
std_targets: 0.5003200173377991
prcauc: 0.7342527047403103
rocauc: 0.8519534256684657
ogbg-molclintox: 0.8519534256684657
OGBNanLabelBCEWithLogitsLoss: 0.19810151532292367
Statistics on  train
mean_pred: 0.07436031848192215
std_pred: 4.006802558898926
mean_targets: 0.5050790309906006
std_targets: 0.5001153349876404
prcauc: 0.9099782045201166
rocauc: 0.9746786974531735
ogbg-molclintox: 0.9746786974531735
OGBNanLabelBCEWithLogitsLoss: 0.11737111533681552
All runs completed.
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 80] ogbg-molclintox: 0.915717 val loss: 0.167922
[Epoch 80] ogbg-molclintox: 0.840702 test loss: 0.288157
[Epoch 81; Iter    20/   35] train: loss: 0.1701662
[Epoch 81] ogbg-molclintox: 0.888618 val loss: 0.207266
[Epoch 81] ogbg-molclintox: 0.821879 test loss: 0.316099
[Epoch 82; Iter    15/   35] train: loss: 0.0176395
[Epoch 82] ogbg-molclintox: 0.875194 val loss: 0.203065
[Epoch 82] ogbg-molclintox: 0.856530 test loss: 0.283335
[Epoch 83; Iter    10/   35] train: loss: 0.0290054
[Epoch 83] ogbg-molclintox: 0.896995 val loss: 0.201998
[Epoch 83] ogbg-molclintox: 0.780810 test loss: 0.548571
[Epoch 84; Iter     5/   35] train: loss: 0.0107190
[Epoch 84; Iter    35/   35] train: loss: 0.0114891
[Epoch 84] ogbg-molclintox: 0.901621 val loss: 0.174068
[Epoch 84] ogbg-molclintox: 0.820959 test loss: 0.278938
[Epoch 85; Iter    30/   35] train: loss: 0.0056752
[Epoch 85] ogbg-molclintox: 0.861304 val loss: 0.196350
[Epoch 85] ogbg-molclintox: 0.792246 test loss: 0.329293
[Epoch 86; Iter    25/   35] train: loss: 0.0076006
[Epoch 86] ogbg-molclintox: 0.908480 val loss: 0.201387
[Epoch 86] ogbg-molclintox: 0.856373 test loss: 0.293899
[Epoch 87; Iter    20/   35] train: loss: 0.0767702
[Epoch 87] ogbg-molclintox: 0.892576 val loss: 0.203209
[Epoch 87] ogbg-molclintox: 0.823194 test loss: 0.301942
[Epoch 88; Iter    15/   35] train: loss: 0.0119368
[Epoch 88] ogbg-molclintox: 0.855759 val loss: 0.224504
[Epoch 88] ogbg-molclintox: 0.806893 test loss: 0.289147
[Epoch 89; Iter    10/   35] train: loss: 0.0077550
[Epoch 89] ogbg-molclintox: 0.886005 val loss: 0.200690
[Epoch 89] ogbg-molclintox: 0.828838 test loss: 0.330564
[Epoch 90; Iter     5/   35] train: loss: 0.0076691
[Epoch 90; Iter    35/   35] train: loss: 0.0402889
[Epoch 90] ogbg-molclintox: 0.825763 val loss: 0.249892
[Epoch 90] ogbg-molclintox: 0.798239 test loss: 0.358263
[Epoch 91; Iter    30/   35] train: loss: 0.0053452
[Epoch 91] ogbg-molclintox: 0.867951 val loss: 0.812587
[Epoch 91] ogbg-molclintox: 0.805810 test loss: 1.719465
[Epoch 92; Iter    25/   35] train: loss: 0.0310674
[Epoch 92] ogbg-molclintox: 0.881413 val loss: 0.464127
[Epoch 92] ogbg-molclintox: 0.801075 test loss: 0.349202
[Epoch 93; Iter    20/   35] train: loss: 0.0251660
[Epoch 93] ogbg-molclintox: 0.860364 val loss: 0.500933
[Epoch 93] ogbg-molclintox: 0.835845 test loss: 0.314587
[Epoch 94; Iter    15/   35] train: loss: 0.0948865
[Epoch 94] ogbg-molclintox: 0.870314 val loss: 0.210185
[Epoch 94] ogbg-molclintox: 0.818152 test loss: 0.283938
[Epoch 95; Iter    10/   35] train: loss: 0.0104162
[Epoch 95] ogbg-molclintox: 0.930677 val loss: 0.156502
[Epoch 95] ogbg-molclintox: 0.780846 test loss: 0.299450
[Epoch 96; Iter     5/   35] train: loss: 0.0079328
[Epoch 96; Iter    35/   35] train: loss: 0.0104154
[Epoch 96] ogbg-molclintox: 0.892014 val loss: 0.323036
[Epoch 96] ogbg-molclintox: 0.842150 test loss: 0.356631
[Epoch 97; Iter    30/   35] train: loss: 0.0475076
[Epoch 97] ogbg-molclintox: 0.884878 val loss: 0.206752
[Epoch 97] ogbg-molclintox: 0.812803 test loss: 0.350684
[Epoch 98; Iter    25/   35] train: loss: 0.0395388
[Epoch 98] ogbg-molclintox: 0.892742 val loss: 0.209019
[Epoch 98] ogbg-molclintox: 0.830454 test loss: 0.310178
[Epoch 99; Iter    20/   35] train: loss: 0.0050486
[Epoch 99] ogbg-molclintox: 0.899457 val loss: 0.202050
[Epoch 99] ogbg-molclintox: 0.813294 test loss: 0.319028
[Epoch 100; Iter    15/   35] train: loss: 0.1548791
[Epoch 100] ogbg-molclintox: 0.836790 val loss: 0.240282
[Epoch 100] ogbg-molclintox: 0.788651 test loss: 0.331316
[Epoch 101; Iter    10/   35] train: loss: 0.0071104
[Epoch 101] ogbg-molclintox: 0.888661 val loss: 0.195489
[Epoch 101] ogbg-molclintox: 0.800421 test loss: 0.298850
[Epoch 102; Iter     5/   35] train: loss: 0.0077251
[Epoch 102; Iter    35/   35] train: loss: 0.0032716
[Epoch 102] ogbg-molclintox: 0.862035 val loss: 0.207363
[Epoch 102] ogbg-molclintox: 0.770852 test loss: 0.333330
[Epoch 103; Iter    30/   35] train: loss: 0.0054450
[Epoch 103] ogbg-molclintox: 0.906910 val loss: 0.186729
[Epoch 103] ogbg-molclintox: 0.783185 test loss: 0.326639
[Epoch 104; Iter    25/   35] train: loss: 0.0082642
[Epoch 104] ogbg-molclintox: 0.892471 val loss: 0.226874
[Epoch 104] ogbg-molclintox: 0.832157 test loss: 0.335854
[Epoch 105; Iter    20/   35] train: loss: 0.0062319
[Epoch 105] ogbg-molclintox: 0.866577 val loss: 0.216015
[Epoch 105] ogbg-molclintox: 0.819393 test loss: 0.302570
[Epoch 106; Iter    15/   35] train: loss: 0.0021565
[Epoch 106] ogbg-molclintox: 0.884610 val loss: 0.216247
[Epoch 106] ogbg-molclintox: 0.819884 test loss: 0.337217
[Epoch 107; Iter    10/   35] train: loss: 0.0452417
[Epoch 107] ogbg-molclintox: 0.868700 val loss: 0.230952
[Epoch 107] ogbg-molclintox: 0.810521 test loss: 0.342917
[Epoch 108; Iter     5/   35] train: loss: 0.1158232
[Epoch 108; Iter    35/   35] train: loss: 0.0770559
[Epoch 108] ogbg-molclintox: 0.882365 val loss: 0.223550
[Epoch 108] ogbg-molclintox: 0.823427 test loss: 0.332278
[Epoch 109; Iter    30/   35] train: loss: 0.0312227
[Epoch 109] ogbg-molclintox: 0.894912 val loss: 0.210536
[Epoch 109] ogbg-molclintox: 0.834960 test loss: 0.317500
[Epoch 110; Iter    25/   35] train: loss: 0.0181553
[Epoch 110] ogbg-molclintox: 0.911071 val loss: 0.210805
[Epoch 110] ogbg-molclintox: 0.847702 test loss: 0.321543
[Epoch 111; Iter    20/   35] train: loss: 0.0250458
[Epoch 111] ogbg-molclintox: 0.835713 val loss: 0.244107
[Epoch 111] ogbg-molclintox: 0.787394 test loss: 0.353889
[Epoch 112; Iter    15/   35] train: loss: 0.0053959
[Epoch 112] ogbg-molclintox: 0.855466 val loss: 0.276745
[Epoch 112] ogbg-molclintox: 0.823833 test loss: 0.350335
[Epoch 113; Iter    10/   35] train: loss: 0.0037236
[Epoch 113] ogbg-molclintox: 0.877348 val loss: 0.245161
[Epoch 113] ogbg-molclintox: 0.835550 test loss: 0.336431
[Epoch 114; Iter     5/   35] train: loss: 0.0598846
[Epoch 114; Iter    35/   35] train: loss: 0.0017650
[Epoch 114] ogbg-molclintox: 0.869568 val loss: 0.239933
[Epoch 114] ogbg-molclintox: 0.806428 test loss: 0.355885
[Epoch 115; Iter    30/   35] train: loss: 0.0129903
[Epoch 115] ogbg-molclintox: 0.884173 val loss: 0.235265
[Epoch 115] ogbg-molclintox: 0.817238 test loss: 0.352253
[Epoch 116; Iter    25/   35] train: loss: 0.1393108
[Epoch 116] ogbg-molclintox: 0.886286 val loss: 0.246267
[Epoch 116] ogbg-molclintox: 0.855227 test loss: 0.359887
[Epoch 117; Iter    20/   35] train: loss: 0.0055943
[Epoch 117] ogbg-molclintox: 0.870348 val loss: 0.240702
[Epoch 117] ogbg-molclintox: 0.851978 test loss: 0.336840
[Epoch 118; Iter    15/   35] train: loss: 0.0168494
[Epoch 118] ogbg-molclintox: 0.878715 val loss: 0.264055
[Epoch 118] ogbg-molclintox: 0.823776 test loss: 0.387082
[Epoch 119; Iter    10/   35] train: loss: 0.0447835
[Epoch 119] ogbg-molclintox: 0.868013 val loss: 0.246040
[Epoch 119] ogbg-molclintox: 0.795922 test loss: 0.379682
[Epoch 120; Iter     5/   35] train: loss: 0.0701197
[Epoch 120; Iter    35/   35] train: loss: 0.0047236
[Epoch 120] ogbg-molclintox: 0.893289 val loss: 0.235112
[Epoch 120] ogbg-molclintox: 0.813427 test loss: 0.375783
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 60.
Statistics on  val_best_checkpoint
mean_pred: 0.3397037386894226
std_pred: 34.02587890625
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.820550352748243
rocauc: 0.9503920250365747
ogbg-molclintox: 0.9503920250365747
OGBNanLabelBCEWithLogitsLoss: 0.130478800740093
Statistics on  test
mean_pred: 0.1926039159297943
std_pred: 5.497100353240967
mean_targets: 0.5090090036392212
std_targets: 0.5004827976226807
prcauc: 0.6689923883616986
rocauc: 0.8583220070753556
ogbg-molclintox: 0.8583220070753556
OGBNanLabelBCEWithLogitsLoss: 0.21483662072569132
Statistics on  train
mean_pred: 0.19216009974479675
std_pred: 5.589077949523926
mean_targets: 0.5053243041038513
std_targets: 0.5000926852226257
prcauc: 0.9659719840787443
rocauc: 0.991447773587
ogbg-molclintox: 0.991447773587
OGBNanLabelBCEWithLogitsLoss: 0.07023903759462492
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 80] ogbg-molclintox: 0.869284 val loss: 0.196719
[Epoch 80] ogbg-molclintox: 0.800140 test loss: 0.346356
[Epoch 81; Iter    20/   35] train: loss: 0.0143126
[Epoch 81] ogbg-molclintox: 0.841476 val loss: 0.213877
[Epoch 81] ogbg-molclintox: 0.765703 test loss: 0.383181
[Epoch 82; Iter    15/   35] train: loss: 0.1457468
[Epoch 82] ogbg-molclintox: 0.776034 val loss: 0.236877
[Epoch 82] ogbg-molclintox: 0.780548 test loss: 0.383365
[Epoch 83; Iter    10/   35] train: loss: 0.0075131
[Epoch 83] ogbg-molclintox: 0.868809 val loss: 0.211523
[Epoch 83] ogbg-molclintox: 0.788500 test loss: 0.523164
[Epoch 84; Iter     5/   35] train: loss: 0.0461140
[Epoch 84; Iter    35/   35] train: loss: 0.0210383
[Epoch 84] ogbg-molclintox: 0.866192 val loss: 0.244861
[Epoch 84] ogbg-molclintox: 0.812793 test loss: 0.526174
[Epoch 85; Iter    30/   35] train: loss: 0.0514158
[Epoch 85] ogbg-molclintox: 0.907312 val loss: 0.212352
[Epoch 85] ogbg-molclintox: 0.867150 test loss: 0.392765
[Epoch 86; Iter    25/   35] train: loss: 0.0979597
[Epoch 86] ogbg-molclintox: 0.836763 val loss: 0.247627
[Epoch 86] ogbg-molclintox: 0.715968 test loss: 0.376653
[Epoch 87; Iter    20/   35] train: loss: 0.0265230
[Epoch 87] ogbg-molclintox: 0.829375 val loss: 0.310049
[Epoch 87] ogbg-molclintox: 0.777347 test loss: 0.414349
[Epoch 88; Iter    15/   35] train: loss: 0.0543586
[Epoch 88] ogbg-molclintox: 0.840883 val loss: 0.263544
[Epoch 88] ogbg-molclintox: 0.768741 test loss: 0.549648
[Epoch 89; Iter    10/   35] train: loss: 0.0771420
[Epoch 89] ogbg-molclintox: 0.863062 val loss: 0.223950
[Epoch 89] ogbg-molclintox: 0.730660 test loss: 0.441873
[Epoch 90; Iter     5/   35] train: loss: 0.0313697
[Epoch 90; Iter    35/   35] train: loss: 0.0091744
[Epoch 90] ogbg-molclintox: 0.874148 val loss: 0.342007
[Epoch 90] ogbg-molclintox: 0.796680 test loss: 0.486682
[Epoch 91; Iter    30/   35] train: loss: 0.1964250
[Epoch 91] ogbg-molclintox: 0.839294 val loss: 0.248045
[Epoch 91] ogbg-molclintox: 0.748032 test loss: 0.402978
[Epoch 92; Iter    25/   35] train: loss: 0.1841135
[Epoch 92] ogbg-molclintox: 0.896479 val loss: 0.192145
[Epoch 92] ogbg-molclintox: 0.821642 test loss: 0.320682
[Epoch 93; Iter    20/   35] train: loss: 0.0231097
[Epoch 93] ogbg-molclintox: 0.835332 val loss: 0.220885
[Epoch 93] ogbg-molclintox: 0.731650 test loss: 0.352196
[Epoch 94; Iter    15/   35] train: loss: 0.1167683
[Epoch 94] ogbg-molclintox: 0.829366 val loss: 0.212402
[Epoch 94] ogbg-molclintox: 0.728730 test loss: 0.334506
[Epoch 95; Iter    10/   35] train: loss: 0.0083070
[Epoch 95] ogbg-molclintox: 0.888368 val loss: 0.183966
[Epoch 95] ogbg-molclintox: 0.781787 test loss: 0.373766
[Epoch 96; Iter     5/   35] train: loss: 0.0295122
[Epoch 96; Iter    35/   35] train: loss: 0.0066377
[Epoch 96] ogbg-molclintox: 0.869121 val loss: 0.245078
[Epoch 96] ogbg-molclintox: 0.759542 test loss: 0.412913
[Epoch 97; Iter    30/   35] train: loss: 0.0442550
[Epoch 97] ogbg-molclintox: 0.869368 val loss: 0.232530
[Epoch 97] ogbg-molclintox: 0.809909 test loss: 0.371697
[Epoch 98; Iter    25/   35] train: loss: 0.0165489
[Epoch 98] ogbg-molclintox: 0.854907 val loss: 0.219326
[Epoch 98] ogbg-molclintox: 0.781182 test loss: 0.400007
[Epoch 99; Iter    20/   35] train: loss: 0.0086865
[Epoch 99] ogbg-molclintox: 0.851345 val loss: 0.294138
[Epoch 99] ogbg-molclintox: 0.788076 test loss: 0.502563
[Epoch 100; Iter    15/   35] train: loss: 0.0089839
[Epoch 100] ogbg-molclintox: 0.835127 val loss: 0.344261
[Epoch 100] ogbg-molclintox: 0.732035 test loss: 0.487930
[Epoch 101; Iter    10/   35] train: loss: 0.0073915
[Epoch 101] ogbg-molclintox: 0.885527 val loss: 0.270934
[Epoch 101] ogbg-molclintox: 0.813520 test loss: 0.333579
[Epoch 102; Iter     5/   35] train: loss: 0.0704987
[Epoch 102; Iter    35/   35] train: loss: 0.0077334
[Epoch 102] ogbg-molclintox: 0.797338 val loss: 1.789761
[Epoch 102] ogbg-molclintox: 0.733807 test loss: 0.359173
[Epoch 103; Iter    30/   35] train: loss: 0.0798972
[Epoch 103] ogbg-molclintox: 0.839341 val loss: 0.578841
[Epoch 103] ogbg-molclintox: 0.746112 test loss: 0.381079
[Epoch 104; Iter    25/   35] train: loss: 0.0281080
[Epoch 104] ogbg-molclintox: 0.871201 val loss: 0.240944
[Epoch 104] ogbg-molclintox: 0.806691 test loss: 0.358437
[Epoch 105; Iter    20/   35] train: loss: 0.0366031
[Epoch 105] ogbg-molclintox: 0.888687 val loss: 0.201036
[Epoch 105] ogbg-molclintox: 0.742417 test loss: 0.334526
[Epoch 106; Iter    15/   35] train: loss: 0.0948974
[Epoch 106] ogbg-molclintox: 0.873652 val loss: 0.241484
[Epoch 106] ogbg-molclintox: 0.800908 test loss: 0.325650
[Epoch 107; Iter    10/   35] train: loss: 0.0037693
[Epoch 107] ogbg-molclintox: 0.806117 val loss: 0.303355
[Epoch 107] ogbg-molclintox: 0.719313 test loss: 0.409740
[Epoch 108; Iter     5/   35] train: loss: 0.1270739
[Epoch 108; Iter    35/   35] train: loss: 0.0049030
[Epoch 108] ogbg-molclintox: 0.899083 val loss: 0.183557
[Epoch 108] ogbg-molclintox: 0.790933 test loss: 0.343682
[Epoch 109; Iter    30/   35] train: loss: 0.0768152
[Epoch 109] ogbg-molclintox: 0.801453 val loss: 0.274823
[Epoch 109] ogbg-molclintox: 0.756039 test loss: 0.355023
[Epoch 110; Iter    25/   35] train: loss: 0.0164953
[Epoch 110] ogbg-molclintox: 0.839032 val loss: 0.420158
[Epoch 110] ogbg-molclintox: 0.759505 test loss: 0.366746
[Epoch 111; Iter    20/   35] train: loss: 0.0330445
[Epoch 111] ogbg-molclintox: 0.828280 val loss: 0.559583
[Epoch 111] ogbg-molclintox: 0.740535 test loss: 0.362845
[Epoch 112; Iter    15/   35] train: loss: 0.0026657
[Epoch 112] ogbg-molclintox: 0.819648 val loss: 0.434060
[Epoch 112] ogbg-molclintox: 0.751848 test loss: 0.388124
[Epoch 113; Iter    10/   35] train: loss: 0.0205430
[Epoch 113] ogbg-molclintox: 0.835982 val loss: 0.773227
[Epoch 113] ogbg-molclintox: 0.762247 test loss: 0.358212
[Epoch 114; Iter     5/   35] train: loss: 0.1150030
[Epoch 114; Iter    35/   35] train: loss: 0.0014250
[Epoch 114] ogbg-molclintox: 0.823147 val loss: 0.885560
[Epoch 114] ogbg-molclintox: 0.762896 test loss: 0.368594
[Epoch 115; Iter    30/   35] train: loss: 0.0691184
[Epoch 115] ogbg-molclintox: 0.835511 val loss: 0.481152
[Epoch 115] ogbg-molclintox: 0.748659 test loss: 0.405271
[Epoch 116; Iter    25/   35] train: loss: 0.0034191
[Epoch 116] ogbg-molclintox: 0.834902 val loss: 0.294088
[Epoch 116] ogbg-molclintox: 0.752059 test loss: 0.384299
[Epoch 117; Iter    20/   35] train: loss: 0.0712964
[Epoch 117] ogbg-molclintox: 0.835111 val loss: 0.876682
[Epoch 117] ogbg-molclintox: 0.749790 test loss: 0.383956
[Epoch 118; Iter    15/   35] train: loss: 0.0048605
[Epoch 118] ogbg-molclintox: 0.826207 val loss: 1.121729
[Epoch 118] ogbg-molclintox: 0.763768 test loss: 0.379135
[Epoch 119; Iter    10/   35] train: loss: 0.0068894
[Epoch 119] ogbg-molclintox: 0.839737 val loss: 0.767743
[Epoch 119] ogbg-molclintox: 0.749432 test loss: 0.376230
[Epoch 120; Iter     5/   35] train: loss: 0.0195382
[Epoch 120; Iter    35/   35] train: loss: 0.0025101
[Epoch 120] ogbg-molclintox: 0.832014 val loss: 0.595702
[Epoch 120] ogbg-molclintox: 0.802167 test loss: 0.369475
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 49.
Statistics on  val_best_checkpoint
mean_pred: 0.11661109328269958
std_pred: 4.395028114318848
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.8366540570774645
rocauc: 0.9498705530251739
ogbg-molclintox: 0.9498705530251739
OGBNanLabelBCEWithLogitsLoss: 0.1282984665594995
Statistics on  test
mean_pred: 0.10497581213712692
std_pred: 3.819155693054199
mean_targets: 0.5090090036392212
std_targets: 0.5004827976226807
prcauc: 0.666520641175314
rocauc: 0.8278517366813267
ogbg-molclintox: 0.8278517366813267
OGBNanLabelBCEWithLogitsLoss: 0.21444813907146454
Statistics on  train
mean_pred: 0.10434635728597641
std_pred: 4.012094497680664
mean_targets: 0.5053243041038513
std_targets: 0.5000926852226257
prcauc: 0.9215848864814273
rocauc: 0.9846397669653365
ogbg-molclintox: 0.9846397669653365
OGBNanLabelBCEWithLogitsLoss: 0.10254681152956827
[Epoch 80] ogbg-molclintox: 0.885262 val loss: 0.199700
[Epoch 80] ogbg-molclintox: 0.775418 test loss: 0.315600
[Epoch 81; Iter    20/   35] train: loss: 0.0918500
[Epoch 81] ogbg-molclintox: 0.914206 val loss: 0.189425
[Epoch 81] ogbg-molclintox: 0.795176 test loss: 0.287723
[Epoch 82; Iter    15/   35] train: loss: 0.0119290
[Epoch 82] ogbg-molclintox: 0.878499 val loss: 0.217438
[Epoch 82] ogbg-molclintox: 0.809818 test loss: 0.283516
[Epoch 83; Iter    10/   35] train: loss: 0.0311941
[Epoch 83] ogbg-molclintox: 0.908635 val loss: 0.167278
[Epoch 83] ogbg-molclintox: 0.712160 test loss: 0.304663
[Epoch 84; Iter     5/   35] train: loss: 0.0411390
[Epoch 84; Iter    35/   35] train: loss: 0.0126547
[Epoch 84] ogbg-molclintox: 0.929581 val loss: 0.179158
[Epoch 84] ogbg-molclintox: 0.798292 test loss: 0.338427
[Epoch 85; Iter    30/   35] train: loss: 0.0233473
[Epoch 85] ogbg-molclintox: 0.921804 val loss: 0.204921
[Epoch 85] ogbg-molclintox: 0.806101 test loss: 0.316209
[Epoch 86; Iter    25/   35] train: loss: 0.0762039
[Epoch 86] ogbg-molclintox: 0.912907 val loss: 0.210047
[Epoch 86] ogbg-molclintox: 0.765672 test loss: 0.326848
[Epoch 87; Iter    20/   35] train: loss: 0.0739409
[Epoch 87] ogbg-molclintox: 0.910877 val loss: 0.172242
[Epoch 87] ogbg-molclintox: 0.788363 test loss: 0.307359
[Epoch 88; Iter    15/   35] train: loss: 0.0625588
[Epoch 88] ogbg-molclintox: 0.882998 val loss: 0.226283
[Epoch 88] ogbg-molclintox: 0.763117 test loss: 0.310554
[Epoch 89; Iter    10/   35] train: loss: 0.0332208
[Epoch 89] ogbg-molclintox: 0.922266 val loss: 0.180799
[Epoch 89] ogbg-molclintox: 0.782373 test loss: 0.315709
[Epoch 90; Iter     5/   35] train: loss: 0.0083278
[Epoch 90; Iter    35/   35] train: loss: 0.1758873
[Epoch 90] ogbg-molclintox: 0.889789 val loss: 0.219595
[Epoch 90] ogbg-molclintox: 0.751752 test loss: 0.351496
[Epoch 91; Iter    30/   35] train: loss: 0.0457351
[Epoch 91] ogbg-molclintox: 0.921280 val loss: 0.195555
[Epoch 91] ogbg-molclintox: 0.807259 test loss: 0.294175
[Epoch 92; Iter    25/   35] train: loss: 0.0752427
[Epoch 92] ogbg-molclintox: 0.921589 val loss: 0.195549
[Epoch 92] ogbg-molclintox: 0.793129 test loss: 0.306541
[Epoch 93; Iter    20/   35] train: loss: 0.0394750
[Epoch 93] ogbg-molclintox: 0.914177 val loss: 0.200223
[Epoch 93] ogbg-molclintox: 0.725166 test loss: 0.366477
[Epoch 94; Iter    15/   35] train: loss: 0.1010768
[Epoch 94] ogbg-molclintox: 0.913556 val loss: 0.189318
[Epoch 94] ogbg-molclintox: 0.779790 test loss: 0.329337
[Epoch 95; Iter    10/   35] train: loss: 0.0660231
[Epoch 95] ogbg-molclintox: 0.924598 val loss: 0.188285
[Epoch 95] ogbg-molclintox: 0.770337 test loss: 0.338025
[Epoch 96; Iter     5/   35] train: loss: 0.0047754
[Epoch 96; Iter    35/   35] train: loss: 0.0022319
[Epoch 96] ogbg-molclintox: 0.914377 val loss: 0.227573
[Epoch 96] ogbg-molclintox: 0.777555 test loss: 0.342651
[Epoch 97; Iter    30/   35] train: loss: 0.0216354
[Epoch 97] ogbg-molclintox: 0.907674 val loss: 0.223206
[Epoch 97] ogbg-molclintox: 0.751318 test loss: 0.362254
[Epoch 98; Iter    25/   35] train: loss: 0.1636846
[Epoch 98] ogbg-molclintox: 0.920181 val loss: 0.224919
[Epoch 98] ogbg-molclintox: 0.768222 test loss: 0.364910
[Epoch 99; Iter    20/   35] train: loss: 0.0325309
[Epoch 99] ogbg-molclintox: 0.881163 val loss: 0.248262
[Epoch 99] ogbg-molclintox: 0.712810 test loss: 0.357009
[Epoch 100; Iter    15/   35] train: loss: 0.0085514
[Epoch 100] ogbg-molclintox: 0.917221 val loss: 0.216130
[Epoch 100] ogbg-molclintox: 0.768320 test loss: 0.371388
[Epoch 101; Iter    10/   35] train: loss: 0.0105526
[Epoch 101] ogbg-molclintox: 0.879517 val loss: 0.244535
[Epoch 101] ogbg-molclintox: 0.726365 test loss: 0.355892
[Epoch 102; Iter     5/   35] train: loss: 0.0558862
[Epoch 102; Iter    35/   35] train: loss: 0.0062145
[Epoch 102] ogbg-molclintox: 0.877029 val loss: 0.242835
[Epoch 102] ogbg-molclintox: 0.727351 test loss: 0.362455
[Epoch 103; Iter    30/   35] train: loss: 0.0027436
[Epoch 103] ogbg-molclintox: 0.883251 val loss: 0.235222
[Epoch 103] ogbg-molclintox: 0.748604 test loss: 0.378190
[Epoch 104; Iter    25/   35] train: loss: 0.0057614
[Epoch 104] ogbg-molclintox: 0.895199 val loss: 0.224304
[Epoch 104] ogbg-molclintox: 0.783195 test loss: 0.367166
[Epoch 105; Iter    20/   35] train: loss: 0.0220366
[Epoch 105] ogbg-molclintox: 0.881178 val loss: 0.258938
[Epoch 105] ogbg-molclintox: 0.776782 test loss: 0.365879
[Epoch 106; Iter    15/   35] train: loss: 0.0252848
[Epoch 106] ogbg-molclintox: 0.901249 val loss: 0.226888
[Epoch 106] ogbg-molclintox: 0.766935 test loss: 0.343576
[Epoch 107; Iter    10/   35] train: loss: 0.0226054
[Epoch 107] ogbg-molclintox: 0.922454 val loss: 0.208192
[Epoch 107] ogbg-molclintox: 0.774515 test loss: 0.374472
[Epoch 108; Iter     5/   35] train: loss: 0.0098964
[Epoch 108; Iter    35/   35] train: loss: 0.0667926
[Epoch 108] ogbg-molclintox: 0.913815 val loss: 0.222166
[Epoch 108] ogbg-molclintox: 0.763099 test loss: 0.365768
[Epoch 109; Iter    30/   35] train: loss: 0.0083048
[Epoch 109] ogbg-molclintox: 0.892224 val loss: 0.257332
[Epoch 109] ogbg-molclintox: 0.781591 test loss: 0.371083
[Epoch 110; Iter    25/   35] train: loss: 0.0053750
[Epoch 110] ogbg-molclintox: 0.881138 val loss: 0.237787
[Epoch 110] ogbg-molclintox: 0.768197 test loss: 0.360662
[Epoch 111; Iter    20/   35] train: loss: 0.0040772
[Epoch 111] ogbg-molclintox: 0.885065 val loss: 0.242105
[Epoch 111] ogbg-molclintox: 0.716040 test loss: 0.424240
[Epoch 112; Iter    15/   35] train: loss: 0.0093340
[Epoch 112] ogbg-molclintox: 0.900366 val loss: 0.213813
[Epoch 112] ogbg-molclintox: 0.719861 test loss: 0.379553
[Epoch 113; Iter    10/   35] train: loss: 0.0024964
[Epoch 113] ogbg-molclintox: 0.879858 val loss: 0.267891
[Epoch 113] ogbg-molclintox: 0.770028 test loss: 0.397047
[Epoch 114; Iter     5/   35] train: loss: 0.0532626
[Epoch 114; Iter    35/   35] train: loss: 0.0110419
[Epoch 114] ogbg-molclintox: 0.911005 val loss: 0.231228
[Epoch 114] ogbg-molclintox: 0.797666 test loss: 0.367003
[Epoch 115; Iter    30/   35] train: loss: 0.0144705
[Epoch 115] ogbg-molclintox: 0.832019 val loss: 0.263252
[Epoch 115] ogbg-molclintox: 0.746022 test loss: 0.367638
[Epoch 116; Iter    25/   35] train: loss: 0.0037187
[Epoch 116] ogbg-molclintox: 0.904518 val loss: 0.217752
[Epoch 116] ogbg-molclintox: 0.771921 test loss: 0.380364
[Epoch 117; Iter    20/   35] train: loss: 0.0027912
[Epoch 117] ogbg-molclintox: 0.862724 val loss: 0.237465
[Epoch 117] ogbg-molclintox: 0.779014 test loss: 0.372647
[Epoch 118; Iter    15/   35] train: loss: 0.0746778
[Epoch 118] ogbg-molclintox: 0.893544 val loss: 0.195524
[Epoch 118] ogbg-molclintox: 0.776292 test loss: 0.384463
[Epoch 119; Iter    10/   35] train: loss: 0.0068946
[Epoch 119] ogbg-molclintox: 0.913066 val loss: 0.202236
[Epoch 119] ogbg-molclintox: 0.777291 test loss: 0.374393
[Epoch 120; Iter     5/   35] train: loss: 0.0763012
[Epoch 120; Iter    35/   35] train: loss: 0.0033201
[Epoch 120] ogbg-molclintox: 0.902154 val loss: 0.245015
[Epoch 120] ogbg-molclintox: 0.761889 test loss: 0.400957
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 57.
Statistics on  val_best_checkpoint
mean_pred: 0.1562996804714203
std_pred: 5.406397819519043
mean_targets: 0.5067567825317383
std_targets: 0.500518262386322
prcauc: 0.854233656317789
rocauc: 0.9490653008129311
ogbg-molclintox: 0.9490653008129311
OGBNanLabelBCEWithLogitsLoss: 0.13100983202457428
Statistics on  test
mean_pred: 0.1550828069448471
std_pred: 5.349381446838379
mean_targets: 0.5090090036392212
std_targets: 0.5004827976226807
prcauc: 0.6479339680960888
rocauc: 0.8039665145166897
ogbg-molclintox: 0.8039665145166897
OGBNanLabelBCEWithLogitsLoss: 0.26731777377426624
Statistics on  train
mean_pred: 0.15403273701667786
std_pred: 5.530667781829834
mean_targets: 0.5053243041038513
std_targets: 0.5000926852226257
prcauc: 0.9617534174049842
rocauc: 0.9912535299201076
ogbg-molclintox: 0.9912535299201076
OGBNanLabelBCEWithLogitsLoss: 0.08196097660277571
All runs completed.
[Epoch 76] ogbg-molclintox: 0.950139 val loss: 0.143975
[Epoch 76] ogbg-molclintox: 0.705287 test loss: 0.315758
[Epoch 77; Iter    20/   40] train: loss: 0.0267774
[Epoch 77] ogbg-molclintox: 0.948234 val loss: 0.147512
[Epoch 77] ogbg-molclintox: 0.739625 test loss: 0.307285
[Epoch 78; Iter    10/   40] train: loss: 0.0872592
[Epoch 78; Iter    40/   40] train: loss: 0.0176308
[Epoch 78] ogbg-molclintox: 0.954761 val loss: 0.147736
[Epoch 78] ogbg-molclintox: 0.789922 test loss: 0.292097
[Epoch 79; Iter    30/   40] train: loss: 0.0324156
[Epoch 79] ogbg-molclintox: 0.950192 val loss: 0.142008
[Epoch 79] ogbg-molclintox: 0.793680 test loss: 0.291010
[Epoch 80; Iter    20/   40] train: loss: 0.0287565
[Epoch 80] ogbg-molclintox: 0.962288 val loss: 0.125864
[Epoch 80] ogbg-molclintox: 0.761698 test loss: 0.288974
[Epoch 81; Iter    10/   40] train: loss: 0.0673974
[Epoch 81; Iter    40/   40] train: loss: 0.0173055
[Epoch 81] ogbg-molclintox: 0.960383 val loss: 0.135874
[Epoch 81] ogbg-molclintox: 0.775763 test loss: 0.297116
[Epoch 82; Iter    30/   40] train: loss: 0.1113416
[Epoch 82] ogbg-molclintox: 0.958291 val loss: 0.138323
[Epoch 82] ogbg-molclintox: 0.765116 test loss: 0.304333
[Epoch 83; Iter    20/   40] train: loss: 0.0415257
[Epoch 83] ogbg-molclintox: 0.950125 val loss: 0.151300
[Epoch 83] ogbg-molclintox: 0.757563 test loss: 0.321664
[Epoch 84; Iter    10/   40] train: loss: 0.0297280
[Epoch 84; Iter    40/   40] train: loss: 0.0362413
[Epoch 84] ogbg-molclintox: 0.963646 val loss: 0.135609
[Epoch 84] ogbg-molclintox: 0.753883 test loss: 0.310247
[Epoch 85; Iter    30/   40] train: loss: 0.0252397
[Epoch 85] ogbg-molclintox: 0.949579 val loss: 0.180978
[Epoch 85] ogbg-molclintox: 0.726576 test loss: 0.342185
[Epoch 86; Iter    20/   40] train: loss: 0.0355757
[Epoch 86] ogbg-molclintox: 0.950673 val loss: 0.136566
[Epoch 86] ogbg-molclintox: 0.757454 test loss: 0.318393
[Epoch 87; Iter    10/   40] train: loss: 0.0706174
[Epoch 87; Iter    40/   40] train: loss: 0.0549128
[Epoch 87] ogbg-molclintox: 0.941508 val loss: 0.142205
[Epoch 87] ogbg-molclintox: 0.717675 test loss: 0.331960
[Epoch 88; Iter    30/   40] train: loss: 0.0166345
[Epoch 88] ogbg-molclintox: 0.946570 val loss: 0.152973
[Epoch 88] ogbg-molclintox: 0.709368 test loss: 0.327184
[Epoch 89; Iter    20/   40] train: loss: 0.0058526
[Epoch 89] ogbg-molclintox: 0.955907 val loss: 0.143809
[Epoch 89] ogbg-molclintox: 0.686559 test loss: 0.363953
[Epoch 90; Iter    10/   40] train: loss: 0.0309359
[Epoch 90; Iter    40/   40] train: loss: 0.0086019
[Epoch 90] ogbg-molclintox: 0.941348 val loss: 0.160078
[Epoch 90] ogbg-molclintox: 0.749310 test loss: 0.370535
[Epoch 91; Iter    30/   40] train: loss: 0.0678621
[Epoch 91] ogbg-molclintox: 0.949100 val loss: 0.165774
[Epoch 91] ogbg-molclintox: 0.721955 test loss: 0.352466
[Epoch 92; Iter    20/   40] train: loss: 0.0760795
[Epoch 92] ogbg-molclintox: 0.954002 val loss: 0.139383
[Epoch 92] ogbg-molclintox: 0.701776 test loss: 0.348361
[Epoch 93; Iter    10/   40] train: loss: 0.0127652
[Epoch 93; Iter    40/   40] train: loss: 0.0019949
[Epoch 93] ogbg-molclintox: 0.940402 val loss: 0.151850
[Epoch 93] ogbg-molclintox: 0.761946 test loss: 0.324736
[Epoch 94; Iter    30/   40] train: loss: 0.0385116
[Epoch 94] ogbg-molclintox: 0.957053 val loss: 0.143595
[Epoch 94] ogbg-molclintox: 0.657252 test loss: 0.311464
[Epoch 95; Iter    20/   40] train: loss: 0.0360030
[Epoch 95] ogbg-molclintox: 0.949687 val loss: 0.157952
[Epoch 95] ogbg-molclintox: 0.746934 test loss: 0.351008
[Epoch 96; Iter    10/   40] train: loss: 0.0574581
[Epoch 96; Iter    40/   40] train: loss: 0.0470287
[Epoch 96] ogbg-molclintox: 0.963913 val loss: 0.150251
[Epoch 96] ogbg-molclintox: 0.740038 test loss: 0.322837
[Epoch 97; Iter    30/   40] train: loss: 0.0953458
[Epoch 97] ogbg-molclintox: 0.963713 val loss: 0.159817
[Epoch 97] ogbg-molclintox: 0.731945 test loss: 0.369829
[Epoch 98; Iter    20/   40] train: loss: 0.0215156
[Epoch 98] ogbg-molclintox: 0.966178 val loss: 0.151606
[Epoch 98] ogbg-molclintox: 0.710499 test loss: 0.363484
[Epoch 99; Iter    10/   40] train: loss: 0.0110010
[Epoch 99; Iter    40/   40] train: loss: 0.1127288
[Epoch 99] ogbg-molclintox: 0.960130 val loss: 0.152420
[Epoch 99] ogbg-molclintox: 0.679063 test loss: 0.359678
[Epoch 100; Iter    30/   40] train: loss: 0.0060316
[Epoch 100] ogbg-molclintox: 0.952444 val loss: 0.166512
[Epoch 100] ogbg-molclintox: 0.710970 test loss: 0.366171
[Epoch 101; Iter    20/   40] train: loss: 0.0069674
[Epoch 101] ogbg-molclintox: 0.951405 val loss: 0.151151
[Epoch 101] ogbg-molclintox: 0.681172 test loss: 0.358859
[Epoch 102; Iter    10/   40] train: loss: 0.0058118
[Epoch 102; Iter    40/   40] train: loss: 0.0014605
[Epoch 102] ogbg-molclintox: 0.965005 val loss: 0.148836
[Epoch 102] ogbg-molclintox: 0.697005 test loss: 0.355755
[Epoch 103; Iter    30/   40] train: loss: 0.0242116
[Epoch 103] ogbg-molclintox: 0.950699 val loss: 0.168029
[Epoch 103] ogbg-molclintox: 0.685060 test loss: 0.369101
[Epoch 104; Iter    20/   40] train: loss: 0.0021702
[Epoch 104] ogbg-molclintox: 0.960783 val loss: 0.149404
[Epoch 104] ogbg-molclintox: 0.689964 test loss: 0.376326
[Epoch 105; Iter    10/   40] train: loss: 0.0727228
[Epoch 105; Iter    40/   40] train: loss: 0.0024700
[Epoch 105] ogbg-molclintox: 0.963234 val loss: 0.148832
[Epoch 105] ogbg-molclintox: 0.752423 test loss: 0.341429
[Epoch 106; Iter    30/   40] train: loss: 0.0368880
[Epoch 106] ogbg-molclintox: 0.958851 val loss: 0.156939
[Epoch 106] ogbg-molclintox: 0.687816 test loss: 0.359706
[Epoch 107; Iter    20/   40] train: loss: 0.0041108
[Epoch 107] ogbg-molclintox: 0.953669 val loss: 0.166458
[Epoch 107] ogbg-molclintox: 0.714671 test loss: 0.377694
[Epoch 108; Iter    10/   40] train: loss: 0.0070670
[Epoch 108; Iter    40/   40] train: loss: 0.2622510
[Epoch 108] ogbg-molclintox: 0.964885 val loss: 0.143583
[Epoch 108] ogbg-molclintox: 0.694552 test loss: 0.348994
[Epoch 109; Iter    30/   40] train: loss: 0.0740508
[Epoch 109] ogbg-molclintox: 0.954842 val loss: 0.142372
[Epoch 109] ogbg-molclintox: 0.674035 test loss: 0.371349
[Epoch 110; Iter    20/   40] train: loss: 0.0142799
[Epoch 110] ogbg-molclintox: 0.953110 val loss: 0.155638
[Epoch 110] ogbg-molclintox: 0.660091 test loss: 0.374924
[Epoch 111; Iter    10/   40] train: loss: 0.0164464
[Epoch 111; Iter    40/   40] train: loss: 0.0074758
[Epoch 111] ogbg-molclintox: 0.957279 val loss: 0.160699
[Epoch 111] ogbg-molclintox: 0.739269 test loss: 0.368376
[Epoch 112; Iter    30/   40] train: loss: 0.0223039
[Epoch 112] ogbg-molclintox: 0.958624 val loss: 0.159094
[Epoch 112] ogbg-molclintox: 0.680951 test loss: 0.369099
[Epoch 113; Iter    20/   40] train: loss: 0.0032724
[Epoch 113] ogbg-molclintox: 0.950965 val loss: 0.152366
[Epoch 113] ogbg-molclintox: 0.696893 test loss: 0.359242
[Epoch 114; Iter    10/   40] train: loss: 0.0036487
[Epoch 114; Iter    40/   40] train: loss: 0.2405798
[Epoch 114] ogbg-molclintox: 0.966391 val loss: 0.147921
[Epoch 114] ogbg-molclintox: 0.697831 test loss: 0.379038
[Epoch 115; Iter    30/   40] train: loss: 0.0042577
[Epoch 115] ogbg-molclintox: 0.952044 val loss: 0.153155
[Epoch 115] ogbg-molclintox: 0.707555 test loss: 0.378791
[Epoch 116; Iter    20/   40] train: loss: 0.1038834
[Epoch 116] ogbg-molclintox: 0.957305 val loss: 0.162809
[Epoch 116] ogbg-molclintox: 0.745896 test loss: 0.354227
[Epoch 117; Iter    10/   40] train: loss: 0.0193290
[Epoch 117; Iter    40/   40] train: loss: 0.0191366
[Epoch 117] ogbg-molclintox: 0.944172 val loss: 0.179441
[Epoch 117] ogbg-molclintox: 0.721677 test loss: 0.378104
[Epoch 118; Iter    30/   40] train: loss: 0.0822844
[Epoch 118] ogbg-molclintox: 0.947781 val loss: 0.163321
[Epoch 118] ogbg-molclintox: 0.706994 test loss: 0.366883
[Epoch 119; Iter    20/   40] train: loss: 0.0023066
[Epoch 119] ogbg-molclintox: 0.941908 val loss: 0.161779
[Epoch 119] ogbg-molclintox: 0.637957 test loss: 0.404108
[Epoch 120; Iter    10/   40] train: loss: 0.0317226
[Epoch 120; Iter    40/   40] train: loss: 0.0044559
[Epoch 120] ogbg-molclintox: 0.944172 val loss: 0.156387
[Epoch 76] ogbg-molclintox: 0.944570 val loss: 0.183849
[Epoch 76] ogbg-molclintox: 0.712158 test loss: 0.329002
[Epoch 77; Iter    20/   40] train: loss: 0.0313867
[Epoch 77] ogbg-molclintox: 0.937351 val loss: 0.170261
[Epoch 77] ogbg-molclintox: 0.711959 test loss: 0.319942
[Epoch 78; Iter    10/   40] train: loss: 0.0051447
[Epoch 78; Iter    40/   40] train: loss: 0.0249522
[Epoch 78] ogbg-molclintox: 0.943931 val loss: 0.188108
[Epoch 78] ogbg-molclintox: 0.707667 test loss: 0.344509
[Epoch 79; Iter    30/   40] train: loss: 0.0072287
[Epoch 79] ogbg-molclintox: 0.942959 val loss: 0.186158
[Epoch 79] ogbg-molclintox: 0.763050 test loss: 0.333558
[Epoch 80; Iter    20/   40] train: loss: 0.0093646
[Epoch 80] ogbg-molclintox: 0.932220 val loss: 0.188474
[Epoch 80] ogbg-molclintox: 0.779000 test loss: 0.305681
[Epoch 81; Iter    10/   40] train: loss: 0.0236817
[Epoch 81; Iter    40/   40] train: loss: 0.2011618
[Epoch 81] ogbg-molclintox: 0.936937 val loss: 0.188248
[Epoch 81] ogbg-molclintox: 0.698183 test loss: 0.330095
[Epoch 82; Iter    30/   40] train: loss: 0.0535552
[Epoch 82] ogbg-molclintox: 0.938110 val loss: 0.186076
[Epoch 82] ogbg-molclintox: 0.765605 test loss: 0.303433
[Epoch 83; Iter    20/   40] train: loss: 0.0447218
[Epoch 83] ogbg-molclintox: 0.936297 val loss: 0.184062
[Epoch 83] ogbg-molclintox: 0.758773 test loss: 0.305894
[Epoch 84; Iter    10/   40] train: loss: 0.0402049
[Epoch 84; Iter    40/   40] train: loss: 0.0057843
[Epoch 84] ogbg-molclintox: 0.925654 val loss: 0.205179
[Epoch 84] ogbg-molclintox: 0.747006 test loss: 0.325033
[Epoch 85; Iter    30/   40] train: loss: 0.0084835
[Epoch 85] ogbg-molclintox: 0.948206 val loss: 0.185813
[Epoch 85] ogbg-molclintox: 0.755931 test loss: 0.297845
[Epoch 86; Iter    20/   40] train: loss: 0.1611386
[Epoch 86] ogbg-molclintox: 0.925269 val loss: 0.226865
[Epoch 86] ogbg-molclintox: 0.662174 test loss: 0.373248
[Epoch 87; Iter    10/   40] train: loss: 0.0123552
[Epoch 87; Iter    40/   40] train: loss: 0.0983193
[Epoch 87] ogbg-molclintox: 0.918435 val loss: 0.200797
[Epoch 87] ogbg-molclintox: 0.678731 test loss: 0.369513
[Epoch 88; Iter    30/   40] train: loss: 0.0370796
[Epoch 88] ogbg-molclintox: 0.936724 val loss: 0.176849
[Epoch 88] ogbg-molclintox: 0.740723 test loss: 0.319121
[Epoch 89; Iter    20/   40] train: loss: 0.0074564
[Epoch 89] ogbg-molclintox: 0.924748 val loss: 0.242834
[Epoch 89] ogbg-molclintox: 0.769275 test loss: 0.357015
[Epoch 90; Iter    10/   40] train: loss: 0.0647382
[Epoch 90; Iter    40/   40] train: loss: 0.0071593
[Epoch 90] ogbg-molclintox: 0.917370 val loss: 0.217143
[Epoch 90] ogbg-molclintox: 0.732250 test loss: 0.335790
[Epoch 91; Iter    30/   40] train: loss: 0.0064339
[Epoch 91] ogbg-molclintox: 0.944156 val loss: 0.203910
[Epoch 91] ogbg-molclintox: 0.734177 test loss: 0.343609
[Epoch 92; Iter    20/   40] train: loss: 0.0150867
[Epoch 92] ogbg-molclintox: 0.922816 val loss: 0.231319
[Epoch 92] ogbg-molclintox: 0.773166 test loss: 0.326301
[Epoch 93; Iter    10/   40] train: loss: 0.0828000
[Epoch 93; Iter    40/   40] train: loss: 0.0072628
[Epoch 93] ogbg-molclintox: 0.923790 val loss: 0.209634
[Epoch 93] ogbg-molclintox: 0.743676 test loss: 0.338079
[Epoch 94; Iter    30/   40] train: loss: 0.1726923
[Epoch 94] ogbg-molclintox: 0.913424 val loss: 0.219521
[Epoch 94] ogbg-molclintox: 0.718625 test loss: 0.348121
[Epoch 95; Iter    20/   40] train: loss: 0.0635687
[Epoch 95] ogbg-molclintox: 0.920832 val loss: 0.219462
[Epoch 95] ogbg-molclintox: 0.741782 test loss: 0.336667
[Epoch 96; Iter    10/   40] train: loss: 0.0698294
[Epoch 96; Iter    40/   40] train: loss: 0.3638182
[Epoch 96] ogbg-molclintox: 0.924707 val loss: 0.221712
[Epoch 96] ogbg-molclintox: 0.767463 test loss: 0.332137
[Epoch 97; Iter    30/   40] train: loss: 0.0987989
[Epoch 97] ogbg-molclintox: 0.944463 val loss: 0.172378
[Epoch 97] ogbg-molclintox: 0.763008 test loss: 0.294458
[Epoch 98; Iter    20/   40] train: loss: 0.0163715
[Epoch 98] ogbg-molclintox: 0.925241 val loss: 0.187085
[Epoch 98] ogbg-molclintox: 0.693252 test loss: 0.344950
[Epoch 99; Iter    10/   40] train: loss: 0.0736680
[Epoch 99; Iter    40/   40] train: loss: 0.0092900
[Epoch 99] ogbg-molclintox: 0.934951 val loss: 0.199115
[Epoch 99] ogbg-molclintox: 0.724757 test loss: 0.380420
[Epoch 100; Iter    30/   40] train: loss: 0.0259114
[Epoch 100] ogbg-molclintox: 0.948446 val loss: 0.194298
[Epoch 100] ogbg-molclintox: 0.700057 test loss: 0.356971
[Epoch 101; Iter    20/   40] train: loss: 0.0206806
[Epoch 101] ogbg-molclintox: 0.956492 val loss: 0.177049
[Epoch 101] ogbg-molclintox: 0.725707 test loss: 0.342888
[Epoch 102; Iter    10/   40] train: loss: 0.0698779
[Epoch 102; Iter    40/   40] train: loss: 0.0824467
[Epoch 102] ogbg-molclintox: 0.954534 val loss: 0.177598
[Epoch 102] ogbg-molclintox: 0.733821 test loss: 0.338409
[Epoch 103; Iter    30/   40] train: loss: 0.0500068
[Epoch 103] ogbg-molclintox: 0.943943 val loss: 0.207529
[Epoch 103] ogbg-molclintox: 0.730708 test loss: 0.347026
[Epoch 104; Iter    20/   40] train: loss: 0.0360722
[Epoch 104] ogbg-molclintox: 0.953189 val loss: 0.182963
[Epoch 104] ogbg-molclintox: 0.706174 test loss: 0.358255
[Epoch 105; Iter    10/   40] train: loss: 0.0400920
[Epoch 105; Iter    40/   40] train: loss: 0.0183097
[Epoch 105] ogbg-molclintox: 0.949685 val loss: 0.200686
[Epoch 105] ogbg-molclintox: 0.729228 test loss: 0.363079
[Epoch 106; Iter    30/   40] train: loss: 0.0396912
[Epoch 106] ogbg-molclintox: 0.945676 val loss: 0.203214
[Epoch 106] ogbg-molclintox: 0.713051 test loss: 0.364437
[Epoch 107; Iter    20/   40] train: loss: 0.0886605
[Epoch 107] ogbg-molclintox: 0.947275 val loss: 0.195891
[Epoch 107] ogbg-molclintox: 0.716369 test loss: 0.348087
[Epoch 108; Iter    10/   40] train: loss: 0.0090819
[Epoch 108; Iter    40/   40] train: loss: 0.0011565
[Epoch 108] ogbg-molclintox: 0.945063 val loss: 0.188198
[Epoch 108] ogbg-molclintox: 0.716586 test loss: 0.365779
[Epoch 109; Iter    30/   40] train: loss: 0.0544256
[Epoch 109] ogbg-molclintox: 0.947354 val loss: 0.204811
[Epoch 109] ogbg-molclintox: 0.720969 test loss: 0.365444
[Epoch 110; Iter    20/   40] train: loss: 0.0032448
[Epoch 110] ogbg-molclintox: 0.958917 val loss: 0.187219
[Epoch 110] ogbg-molclintox: 0.678891 test loss: 0.366065
[Epoch 111; Iter    10/   40] train: loss: 0.0024951
[Epoch 111; Iter    40/   40] train: loss: 0.0085321
[Epoch 111] ogbg-molclintox: 0.948247 val loss: 0.204878
[Epoch 111] ogbg-molclintox: 0.686004 test loss: 0.371022
[Epoch 112; Iter    30/   40] train: loss: 0.0257732
[Epoch 112] ogbg-molclintox: 0.944503 val loss: 0.191114
[Epoch 112] ogbg-molclintox: 0.752842 test loss: 0.344814
[Epoch 113; Iter    20/   40] train: loss: 0.0091153
[Epoch 113] ogbg-molclintox: 0.950578 val loss: 0.196759
[Epoch 113] ogbg-molclintox: 0.754055 test loss: 0.348381
[Epoch 114; Iter    10/   40] train: loss: 0.0779046
[Epoch 114; Iter    40/   40] train: loss: 0.0056275
[Epoch 114] ogbg-molclintox: 0.955973 val loss: 0.194962
[Epoch 114] ogbg-molclintox: 0.721126 test loss: 0.366299
[Epoch 115; Iter    30/   40] train: loss: 0.0018209
[Epoch 115] ogbg-molclintox: 0.950271 val loss: 0.196721
[Epoch 115] ogbg-molclintox: 0.701849 test loss: 0.369688
[Epoch 116; Iter    20/   40] train: loss: 0.0378361
[Epoch 116] ogbg-molclintox: 0.952536 val loss: 0.193742
[Epoch 116] ogbg-molclintox: 0.722133 test loss: 0.338406
[Epoch 117; Iter    10/   40] train: loss: 0.0234021
[Epoch 117; Iter    40/   40] train: loss: 0.2234763
[Epoch 117] ogbg-molclintox: 0.948340 val loss: 0.211090
[Epoch 117] ogbg-molclintox: 0.721943 test loss: 0.356066
[Epoch 118; Iter    30/   40] train: loss: 0.0055286
[Epoch 118] ogbg-molclintox: 0.942158 val loss: 0.204671
[Epoch 118] ogbg-molclintox: 0.755943 test loss: 0.339551
[Epoch 119; Iter    20/   40] train: loss: 0.0089788
[Epoch 119] ogbg-molclintox: 0.954374 val loss: 0.194886
[Epoch 119] ogbg-molclintox: 0.729381 test loss: 0.364928
[Epoch 120; Iter    10/   40] train: loss: 0.0048678
[Epoch 120; Iter    40/   40] train: loss: 0.0072986
[Epoch 120] ogbg-molclintox: 0.961035 val loss: 0.186126
[Epoch 76] ogbg-molclintox: 0.928384 val loss: 0.207424
[Epoch 76] ogbg-molclintox: 0.717286 test loss: 1.707094
[Epoch 77; Iter    20/   40] train: loss: 0.0851658
[Epoch 77] ogbg-molclintox: 0.908445 val loss: 0.184609
[Epoch 77] ogbg-molclintox: 0.660742 test loss: 1.182572
[Epoch 78; Iter    10/   40] train: loss: 0.0171881
[Epoch 78; Iter    40/   40] train: loss: 0.0094991
[Epoch 78] ogbg-molclintox: 0.935326 val loss: 0.157283
[Epoch 78] ogbg-molclintox: 0.653337 test loss: 1.107605
[Epoch 79; Iter    30/   40] train: loss: 0.0992636
[Epoch 79] ogbg-molclintox: 0.902859 val loss: 0.204265
[Epoch 79] ogbg-molclintox: 0.651777 test loss: 0.719673
[Epoch 80; Iter    20/   40] train: loss: 0.0799408
[Epoch 80] ogbg-molclintox: 0.928664 val loss: 0.181485
[Epoch 80] ogbg-molclintox: 0.635454 test loss: 1.844674
[Epoch 81; Iter    10/   40] train: loss: 0.1083020
[Epoch 81; Iter    40/   40] train: loss: 0.0825725
[Epoch 81] ogbg-molclintox: 0.940401 val loss: 0.166860
[Epoch 81] ogbg-molclintox: 0.731058 test loss: 0.466433
[Epoch 82; Iter    30/   40] train: loss: 0.0837591
[Epoch 82] ogbg-molclintox: 0.918659 val loss: 0.215739
[Epoch 82] ogbg-molclintox: 0.700039 test loss: 0.707302
[Epoch 83; Iter    20/   40] train: loss: 0.1119382
[Epoch 83] ogbg-molclintox: 0.945516 val loss: 0.145766
[Epoch 83] ogbg-molclintox: 0.675799 test loss: 1.870738
[Epoch 84; Iter    10/   40] train: loss: 0.0310018
[Epoch 84; Iter    40/   40] train: loss: 0.0759696
[Epoch 84] ogbg-molclintox: 0.912131 val loss: 0.176298
[Epoch 84] ogbg-molclintox: 0.647413 test loss: 0.343958
[Epoch 85; Iter    30/   40] train: loss: 0.0533862
[Epoch 85] ogbg-molclintox: 0.927000 val loss: 0.174777
[Epoch 85] ogbg-molclintox: 0.631055 test loss: 0.664081
[Epoch 86; Iter    20/   40] train: loss: 0.0744145
[Epoch 86] ogbg-molclintox: 0.922751 val loss: 0.180732
[Epoch 86] ogbg-molclintox: 0.673821 test loss: 1.502823
[Epoch 87; Iter    10/   40] train: loss: 0.1779092
[Epoch 87; Iter    40/   40] train: loss: 0.0782378
[Epoch 87] ogbg-molclintox: 0.943411 val loss: 0.160310
[Epoch 87] ogbg-molclintox: 0.657243 test loss: 0.427620
[Epoch 88; Iter    30/   40] train: loss: 0.0157385
[Epoch 88] ogbg-molclintox: 0.939374 val loss: 0.179728
[Epoch 88] ogbg-molclintox: 0.717600 test loss: 0.472846
[Epoch 89; Iter    20/   40] train: loss: 0.1267464
[Epoch 89] ogbg-molclintox: 0.934886 val loss: 0.180934
[Epoch 89] ogbg-molclintox: 0.642692 test loss: 1.417735
[Epoch 90; Iter    10/   40] train: loss: 0.0505705
[Epoch 90; Iter    40/   40] train: loss: 0.0109914
[Epoch 90] ogbg-molclintox: 0.942957 val loss: 0.173273
[Epoch 90] ogbg-molclintox: 0.668096 test loss: 0.934555
[Epoch 91; Iter    30/   40] train: loss: 0.0134547
[Epoch 91] ogbg-molclintox: 0.925267 val loss: 0.194680
[Epoch 91] ogbg-molclintox: 0.614722 test loss: 1.722417
[Epoch 92; Iter    20/   40] train: loss: 0.0075955
[Epoch 92] ogbg-molclintox: 0.928517 val loss: 0.197544
[Epoch 92] ogbg-molclintox: 0.676219 test loss: 2.171310
[Epoch 93; Iter    10/   40] train: loss: 0.0081997
[Epoch 93; Iter    40/   40] train: loss: 0.0227299
[Epoch 93] ogbg-molclintox: 0.934366 val loss: 0.187648
[Epoch 93] ogbg-molclintox: 0.701797 test loss: 1.381465
[Epoch 94; Iter    30/   40] train: loss: 0.2166667
[Epoch 94] ogbg-molclintox: 0.922908 val loss: 0.229906
[Epoch 94] ogbg-molclintox: 0.672228 test loss: 1.705891
[Epoch 95; Iter    20/   40] train: loss: 0.0213936
[Epoch 95] ogbg-molclintox: 0.928211 val loss: 0.205956
[Epoch 95] ogbg-molclintox: 0.640484 test loss: 1.678110
[Epoch 96; Iter    10/   40] train: loss: 0.1272832
[Epoch 96; Iter    40/   40] train: loss: 0.2021417
[Epoch 96] ogbg-molclintox: 0.922550 val loss: 0.204498
[Epoch 96] ogbg-molclintox: 0.690773 test loss: 1.483796
[Epoch 97; Iter    30/   40] train: loss: 0.1168367
[Epoch 97] ogbg-molclintox: 0.933645 val loss: 0.205554
[Epoch 97] ogbg-molclintox: 0.641335 test loss: 1.561388
[Epoch 98; Iter    20/   40] train: loss: 0.0086658
[Epoch 98] ogbg-molclintox: 0.925107 val loss: 0.202154
[Epoch 98] ogbg-molclintox: 0.649332 test loss: 1.484720
[Epoch 99; Iter    10/   40] train: loss: 0.0680680
[Epoch 99; Iter    40/   40] train: loss: 0.0031703
[Epoch 99] ogbg-molclintox: 0.916608 val loss: 0.222053
[Epoch 99] ogbg-molclintox: 0.617108 test loss: 1.173870
[Epoch 100; Iter    30/   40] train: loss: 0.0295071
[Epoch 100] ogbg-molclintox: 0.937776 val loss: 0.205877
[Epoch 100] ogbg-molclintox: 0.659276 test loss: 0.667755
[Epoch 101; Iter    20/   40] train: loss: 0.0036655
[Epoch 101] ogbg-molclintox: 0.936298 val loss: 0.190320
[Epoch 101] ogbg-molclintox: 0.612349 test loss: 1.098919
[Epoch 102; Iter    10/   40] train: loss: 0.0274558
[Epoch 102; Iter    40/   40] train: loss: 0.0056175
[Epoch 102] ogbg-molclintox: 0.911373 val loss: 0.199205
[Epoch 102] ogbg-molclintox: 0.637387 test loss: 1.296307
[Epoch 103; Iter    30/   40] train: loss: 0.0065031
[Epoch 103] ogbg-molclintox: 0.939228 val loss: 0.183595
[Epoch 103] ogbg-molclintox: 0.669589 test loss: 1.220054
[Epoch 104; Iter    20/   40] train: loss: 0.0047817
[Epoch 104] ogbg-molclintox: 0.936363 val loss: 0.199836
[Epoch 104] ogbg-molclintox: 0.684535 test loss: 2.233151
[Epoch 105; Iter    10/   40] train: loss: 0.0095627
[Epoch 105; Iter    40/   40] train: loss: 0.0046081
[Epoch 105] ogbg-molclintox: 0.937869 val loss: 0.192506
[Epoch 105] ogbg-molclintox: 0.645661 test loss: 2.139940
[Epoch 106; Iter    30/   40] train: loss: 0.0028267
[Epoch 106] ogbg-molclintox: 0.913692 val loss: 0.233380
[Epoch 106] ogbg-molclintox: 0.694640 test loss: 2.660875
[Epoch 107; Iter    20/   40] train: loss: 0.0054826
[Epoch 107] ogbg-molclintox: 0.937069 val loss: 0.184716
[Epoch 107] ogbg-molclintox: 0.600331 test loss: 1.789383
[Epoch 108; Iter    10/   40] train: loss: 0.0483062
[Epoch 108; Iter    40/   40] train: loss: 0.0227040
[Epoch 108] ogbg-molclintox: 0.908496 val loss: 0.218363
[Epoch 108] ogbg-molclintox: 0.651609 test loss: 2.372888
[Epoch 109; Iter    30/   40] train: loss: 0.0108075
[Epoch 109] ogbg-molclintox: 0.918927 val loss: 0.218914
[Epoch 109] ogbg-molclintox: 0.698443 test loss: 0.645309
[Epoch 110; Iter    20/   40] train: loss: 0.1537587
[Epoch 110] ogbg-molclintox: 0.945222 val loss: 0.186494
[Epoch 110] ogbg-molclintox: 0.661925 test loss: 0.408560
[Epoch 111; Iter    10/   40] train: loss: 0.0277205
[Epoch 111; Iter    40/   40] train: loss: 0.3386300
[Epoch 111] ogbg-molclintox: 0.924110 val loss: 0.209515
[Epoch 111] ogbg-molclintox: 0.694000 test loss: 0.451776
[Epoch 112; Iter    30/   40] train: loss: 0.0122842
[Epoch 112] ogbg-molclintox: 0.926507 val loss: 0.219105
[Epoch 112] ogbg-molclintox: 0.658483 test loss: 0.704262
[Epoch 113; Iter    20/   40] train: loss: 0.0409335
[Epoch 113] ogbg-molclintox: 0.919207 val loss: 0.222285
[Epoch 113] ogbg-molclintox: 0.611570 test loss: 0.579494
[Epoch 114; Iter    10/   40] train: loss: 0.0232063
[Epoch 114; Iter    40/   40] train: loss: 0.0160496
[Epoch 114] ogbg-molclintox: 0.931049 val loss: 0.209587
[Epoch 114] ogbg-molclintox: 0.638573 test loss: 1.083973
[Epoch 115; Iter    30/   40] train: loss: 0.0709459
[Epoch 115] ogbg-molclintox: 0.925241 val loss: 0.226880
[Epoch 115] ogbg-molclintox: 0.599004 test loss: 1.766941
[Epoch 116; Iter    20/   40] train: loss: 0.0192067
[Epoch 116] ogbg-molclintox: 0.926214 val loss: 0.226368
[Epoch 116] ogbg-molclintox: 0.617377 test loss: 0.943075
[Epoch 117; Iter    10/   40] train: loss: 0.0369447
[Epoch 117; Iter    40/   40] train: loss: 0.1241206
[Epoch 117] ogbg-molclintox: 0.934606 val loss: 0.206016
[Epoch 117] ogbg-molclintox: 0.659107 test loss: 1.669787
[Epoch 118; Iter    30/   40] train: loss: 0.0251705
[Epoch 118] ogbg-molclintox: 0.929558 val loss: 0.222100
[Epoch 118] ogbg-molclintox: 0.655192 test loss: 1.553051
[Epoch 119; Iter    20/   40] train: loss: 0.0027268
[Epoch 119] ogbg-molclintox: 0.936071 val loss: 0.215966
[Epoch 119] ogbg-molclintox: 0.659020 test loss: 1.658598
[Epoch 120; Iter    10/   40] train: loss: 0.0232815
[Epoch 120; Iter    40/   40] train: loss: 0.0031431
[Epoch 120] ogbg-molclintox: 0.931928 val loss: 0.231572
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 120] ogbg-molclintox: 0.650462 test loss: 1.616434
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: 0.13444173336029053
std_pred: 5.12003231048584
mean_targets: 0.5101351737976074
std_targets: 0.5007438659667969
prcauc: 0.7877763182897052
rocauc: 0.949513918277143
ogbg-molclintox: 0.949513918277143
OGBNanLabelBCEWithLogitsLoss: 0.14075749665498732
Statistics on  test
mean_pred: 0.1331041306257248
std_pred: 4.485386848449707
mean_targets: 0.5101351737976074
std_targets: 0.5007438063621521
prcauc: 0.645870488188946
rocauc: 0.8272433998483268
ogbg-molclintox: 0.8272433998483268
OGBNanLabelBCEWithLogitsLoss: 0.2001163214445114
Statistics on  train
mean_pred: 0.12903092801570892
std_pred: 5.6208600997924805
mean_targets: 0.5050804018974304
std_targets: 0.5000800490379333
prcauc: 0.7868148102558482
rocauc: 0.9369376730377585
ogbg-molclintox: 0.9369376730377585
OGBNanLabelBCEWithLogitsLoss: 0.26052915686741474
[Epoch 120] ogbg-molclintox: 0.697577 test loss: 0.384688
[Epoch 121; Iter    30/   40] train: loss: 0.0079435
[Epoch 121] ogbg-molclintox: 0.946396 val loss: 0.184586
[Epoch 121] ogbg-molclintox: 0.703903 test loss: 0.384950
[Epoch 122; Iter    20/   40] train: loss: 0.0365750
[Epoch 122] ogbg-molclintox: 0.941187 val loss: 0.190715
[Epoch 122] ogbg-molclintox: 0.719445 test loss: 0.380887
[Epoch 123; Iter    10/   40] train: loss: 0.0231131
[Epoch 123; Iter    40/   40] train: loss: 0.0035829
[Epoch 123] ogbg-molclintox: 0.944184 val loss: 0.194851
[Epoch 123] ogbg-molclintox: 0.715560 test loss: 0.370124
[Epoch 124; Iter    30/   40] train: loss: 0.1393840
[Epoch 124] ogbg-molclintox: 0.947528 val loss: 0.179923
[Epoch 124] ogbg-molclintox: 0.710592 test loss: 0.372013
[Epoch 125; Iter    20/   40] train: loss: 0.0204536
[Epoch 125] ogbg-molclintox: 0.944677 val loss: 0.178965
[Epoch 125] ogbg-molclintox: 0.682447 test loss: 0.381394
[Epoch 126; Iter    10/   40] train: loss: 0.0249753
[Epoch 126; Iter    40/   40] train: loss: 0.0028707
[Epoch 126] ogbg-molclintox: 0.943799 val loss: 0.180011
[Epoch 126] ogbg-molclintox: 0.675564 test loss: 0.392611
[Epoch 127; Iter    30/   40] train: loss: 0.0235638
[Epoch 127] ogbg-molclintox: 0.943026 val loss: 0.181890
[Epoch 127] ogbg-molclintox: 0.663330 test loss: 0.402719
[Epoch 128; Iter    20/   40] train: loss: 0.0186581
[Epoch 128] ogbg-molclintox: 0.946769 val loss: 0.186344
[Epoch 128] ogbg-molclintox: 0.686447 test loss: 0.389933
[Epoch 129; Iter    10/   40] train: loss: 0.0039882
[Epoch 129; Iter    40/   40] train: loss: 0.0022338
[Epoch 129] ogbg-molclintox: 0.946089 val loss: 0.185108
[Epoch 129] ogbg-molclintox: 0.703000 test loss: 0.379001
[Epoch 130; Iter    30/   40] train: loss: 0.0114036
[Epoch 130] ogbg-molclintox: 0.942293 val loss: 0.186940
[Epoch 130] ogbg-molclintox: 0.664434 test loss: 0.400290
[Epoch 131; Iter    20/   40] train: loss: 0.0791580
[Epoch 131] ogbg-molclintox: 0.946609 val loss: 0.184765
[Epoch 131] ogbg-molclintox: 0.672617 test loss: 0.401775
[Epoch 132; Iter    10/   40] train: loss: 0.0683797
[Epoch 132; Iter    40/   40] train: loss: 0.0006537
[Epoch 132] ogbg-molclintox: 0.949486 val loss: 0.188017
[Epoch 132] ogbg-molclintox: 0.706801 test loss: 0.407552
[Epoch 133; Iter    30/   40] train: loss: 0.0035270
[Epoch 133] ogbg-molclintox: 0.942253 val loss: 0.181303
[Epoch 133] ogbg-molclintox: 0.665975 test loss: 0.405504
[Epoch 134; Iter    20/   40] train: loss: 0.0036487
[Epoch 134] ogbg-molclintox: 0.937978 val loss: 0.188670
[Epoch 134] ogbg-molclintox: 0.679838 test loss: 0.412068
[Epoch 135; Iter    10/   40] train: loss: 0.0183304
[Epoch 135; Iter    40/   40] train: loss: 0.1399454
[Epoch 135] ogbg-molclintox: 0.945544 val loss: 0.184864
[Epoch 135] ogbg-molclintox: 0.709250 test loss: 0.398519
[Epoch 136; Iter    30/   40] train: loss: 0.0181331
[Epoch 136] ogbg-molclintox: 0.947382 val loss: 0.190929
[Epoch 136] ogbg-molclintox: 0.695480 test loss: 0.386197
[Epoch 137; Iter    20/   40] train: loss: 0.0412050
[Epoch 137] ogbg-molclintox: 0.944038 val loss: 0.184599
[Epoch 137] ogbg-molclintox: 0.686172 test loss: 0.409138
[Epoch 138; Iter    10/   40] train: loss: 0.0027672
[Epoch 138; Iter    40/   40] train: loss: 0.0549809
[Epoch 138] ogbg-molclintox: 0.947049 val loss: 0.191694
[Epoch 138] ogbg-molclintox: 0.720006 test loss: 0.377455
[Epoch 139; Iter    30/   40] train: loss: 0.1133453
[Epoch 139] ogbg-molclintox: 0.952164 val loss: 0.189002
[Epoch 139] ogbg-molclintox: 0.752589 test loss: 0.377545
[Epoch 140; Iter    20/   40] train: loss: 0.0070561
[Epoch 140] ogbg-molclintox: 0.953150 val loss: 0.192893
[Epoch 140] ogbg-molclintox: 0.681750 test loss: 0.368371
[Epoch 141; Iter    10/   40] train: loss: 0.0304261
[Epoch 141; Iter    40/   40] train: loss: 0.0071461
[Epoch 141] ogbg-molclintox: 0.951551 val loss: 0.184864
[Epoch 141] ogbg-molclintox: 0.704466 test loss: 0.378936
[Epoch 142; Iter    30/   40] train: loss: 0.0197945
[Epoch 142] ogbg-molclintox: 0.946796 val loss: 0.198454
[Epoch 142] ogbg-molclintox: 0.700811 test loss: 0.402123
[Epoch 143; Iter    20/   40] train: loss: 0.0105265
[Epoch 143] ogbg-molclintox: 0.940855 val loss: 0.202554
[Epoch 143] ogbg-molclintox: 0.669393 test loss: 0.402946
[Epoch 144; Iter    10/   40] train: loss: 0.0054899
[Epoch 144; Iter    40/   40] train: loss: 0.0122422
[Epoch 144] ogbg-molclintox: 0.953576 val loss: 0.191928
[Epoch 144] ogbg-molclintox: 0.682568 test loss: 0.396196
[Epoch 145; Iter    30/   40] train: loss: 0.1129516
[Epoch 145] ogbg-molclintox: 0.953696 val loss: 0.191193
[Epoch 145] ogbg-molclintox: 0.698585 test loss: 0.393297
[Epoch 146; Iter    20/   40] train: loss: 0.0339050
[Epoch 146] ogbg-molclintox: 0.949526 val loss: 0.188671
[Epoch 146] ogbg-molclintox: 0.678816 test loss: 0.389375
[Epoch 147; Iter    10/   40] train: loss: 0.0044427
[Epoch 147; Iter    40/   40] train: loss: 0.0886821
[Epoch 147] ogbg-molclintox: 0.956853 val loss: 0.171591
[Epoch 147] ogbg-molclintox: 0.715361 test loss: 0.387575
[Epoch 148; Iter    30/   40] train: loss: 0.0668759
[Epoch 148] ogbg-molclintox: 0.950232 val loss: 0.175692
[Epoch 148] ogbg-molclintox: 0.669881 test loss: 0.402631
[Epoch 149; Iter    20/   40] train: loss: 0.0064913
[Epoch 149] ogbg-molclintox: 0.951924 val loss: 0.161282
[Epoch 149] ogbg-molclintox: 0.693318 test loss: 0.388266
[Epoch 150; Iter    10/   40] train: loss: 0.0238660
[Epoch 150; Iter    40/   40] train: loss: 0.0167900
[Epoch 150] ogbg-molclintox: 0.950326 val loss: 0.171218
[Epoch 150] ogbg-molclintox: 0.698638 test loss: 0.391719
[Epoch 151; Iter    30/   40] train: loss: 0.0041367
[Epoch 151] ogbg-molclintox: 0.947169 val loss: 0.177464
[Epoch 151] ogbg-molclintox: 0.691972 test loss: 0.390856
[Epoch 152; Iter    20/   40] train: loss: 0.0189443
[Epoch 152] ogbg-molclintox: 0.952138 val loss: 0.176107
[Epoch 152] ogbg-molclintox: 0.694799 test loss: 0.394241
[Epoch 153; Iter    10/   40] train: loss: 0.0088535
[Epoch 153; Iter    40/   40] train: loss: 0.0050128
[Epoch 153] ogbg-molclintox: 0.956853 val loss: 0.171077
[Epoch 153] ogbg-molclintox: 0.687014 test loss: 0.389039
[Epoch 154; Iter    30/   40] train: loss: 0.0465871
[Epoch 154] ogbg-molclintox: 0.951645 val loss: 0.182995
[Epoch 154] ogbg-molclintox: 0.703688 test loss: 0.394616
[Epoch 155; Iter    20/   40] train: loss: 0.0170060
[Epoch 155] ogbg-molclintox: 0.948887 val loss: 0.193009
[Epoch 155] ogbg-molclintox: 0.706330 test loss: 0.390405
[Epoch 156; Iter    10/   40] train: loss: 0.0819693
[Epoch 156; Iter    40/   40] train: loss: 0.0052181
[Epoch 156] ogbg-molclintox: 0.949500 val loss: 0.180613
[Epoch 156] ogbg-molclintox: 0.703733 test loss: 0.389662
[Epoch 157; Iter    30/   40] train: loss: 0.0622664
[Epoch 157] ogbg-molclintox: 0.952657 val loss: 0.169033
[Epoch 157] ogbg-molclintox: 0.711826 test loss: 0.383693
[Epoch 158; Iter    20/   40] train: loss: 0.0031738
[Epoch 158] ogbg-molclintox: 0.946862 val loss: 0.176533
[Epoch 158] ogbg-molclintox: 0.719430 test loss: 0.382491
[Epoch 159; Iter    10/   40] train: loss: 0.0036719
[Epoch 159; Iter    40/   40] train: loss: 0.0037792
[Epoch 159] ogbg-molclintox: 0.951458 val loss: 0.184111
[Epoch 159] ogbg-molclintox: 0.713781 test loss: 0.388930
[Epoch 160; Iter    30/   40] train: loss: 0.0017086
[Epoch 160] ogbg-molclintox: 0.950019 val loss: 0.172376
[Epoch 160] ogbg-molclintox: 0.708225 test loss: 0.395132
[Epoch 161; Iter    20/   40] train: loss: 0.0169458
[Epoch 161] ogbg-molclintox: 0.956120 val loss: 0.168276
[Epoch 161] ogbg-molclintox: 0.742249 test loss: 0.373350
[Epoch 162; Iter    10/   40] train: loss: 0.0764440
[Epoch 162; Iter    40/   40] train: loss: 0.0074385
[Epoch 162] ogbg-molclintox: 0.946716 val loss: 0.173388
[Epoch 162] ogbg-molclintox: 0.703791 test loss: 0.388695
[Epoch 163; Iter    30/   40] train: loss: 0.0041078
[Epoch 163] ogbg-molclintox: 0.949007 val loss: 0.176919
[Epoch 163] ogbg-molclintox: 0.716121 test loss: 0.397339
[Epoch 164; Iter    20/   40] train: loss: 0.0758991
[Epoch 164] ogbg-molclintox: 0.950299 val loss: 0.184611
[Epoch 164] ogbg-molclintox: 0.702681 test loss: 0.410308
[Epoch 120] ogbg-molclintox: 0.691732 test loss: 0.374792
[Epoch 121; Iter    30/   40] train: loss: 0.0864422
[Epoch 121] ogbg-molclintox: 0.953162 val loss: 0.192950
[Epoch 121] ogbg-molclintox: 0.688000 test loss: 0.361522
[Epoch 122; Iter    20/   40] train: loss: 0.0212351
[Epoch 122] ogbg-molclintox: 0.949072 val loss: 0.191558
[Epoch 122] ogbg-molclintox: 0.711079 test loss: 0.358059
[Epoch 123; Iter    10/   40] train: loss: 0.0060513
[Epoch 123; Iter    40/   40] train: loss: 0.0109009
[Epoch 123] ogbg-molclintox: 0.941985 val loss: 0.194318
[Epoch 123] ogbg-molclintox: 0.736078 test loss: 0.344520
[Epoch 124; Iter    30/   40] train: loss: 0.0032029
[Epoch 124] ogbg-molclintox: 0.943265 val loss: 0.191351
[Epoch 124] ogbg-molclintox: 0.716502 test loss: 0.353002
[Epoch 125; Iter    20/   40] train: loss: 0.0166378
[Epoch 125] ogbg-molclintox: 0.935300 val loss: 0.202777
[Epoch 125] ogbg-molclintox: 0.705420 test loss: 0.362108
[Epoch 126; Iter    10/   40] train: loss: 0.0116734
[Epoch 126; Iter    40/   40] train: loss: 0.1147969
[Epoch 126] ogbg-molclintox: 0.942679 val loss: 0.210104
[Epoch 126] ogbg-molclintox: 0.702998 test loss: 0.379732
[Epoch 127; Iter    30/   40] train: loss: 0.0062542
[Epoch 127] ogbg-molclintox: 0.940721 val loss: 0.206218
[Epoch 127] ogbg-molclintox: 0.718076 test loss: 0.370028
[Epoch 128; Iter    20/   40] train: loss: 0.0536814
[Epoch 128] ogbg-molclintox: 0.950645 val loss: 0.200555
[Epoch 128] ogbg-molclintox: 0.691560 test loss: 0.371764
[Epoch 129; Iter    10/   40] train: loss: 0.0204364
[Epoch 129; Iter    40/   40] train: loss: 0.0277659
[Epoch 129] ogbg-molclintox: 0.948100 val loss: 0.195598
[Epoch 129] ogbg-molclintox: 0.709956 test loss: 0.363647
[Epoch 130; Iter    30/   40] train: loss: 0.0073419
[Epoch 130] ogbg-molclintox: 0.944517 val loss: 0.209887
[Epoch 130] ogbg-molclintox: 0.704515 test loss: 0.367178
[Epoch 131; Iter    20/   40] train: loss: 0.0123681
[Epoch 131] ogbg-molclintox: 0.935726 val loss: 0.207443
[Epoch 131] ogbg-molclintox: 0.684625 test loss: 0.379323
[Epoch 132; Iter    10/   40] train: loss: 0.0421271
[Epoch 132; Iter    40/   40] train: loss: 0.1452704
[Epoch 132] ogbg-molclintox: 0.936152 val loss: 0.199603
[Epoch 132] ogbg-molclintox: 0.689192 test loss: 0.375401
[Epoch 133; Iter    30/   40] train: loss: 0.0029753
[Epoch 133] ogbg-molclintox: 0.942439 val loss: 0.208283
[Epoch 133] ogbg-molclintox: 0.676433 test loss: 0.392943
[Epoch 134; Iter    20/   40] train: loss: 0.0032793
[Epoch 134] ogbg-molclintox: 0.945103 val loss: 0.204444
[Epoch 134] ogbg-molclintox: 0.708406 test loss: 0.361405
[Epoch 135; Iter    10/   40] train: loss: 0.0159417
[Epoch 135; Iter    40/   40] train: loss: 0.0053371
[Epoch 135] ogbg-molclintox: 0.943691 val loss: 0.203963
[Epoch 135] ogbg-molclintox: 0.718101 test loss: 0.370475
[Epoch 136; Iter    30/   40] train: loss: 0.0043685
[Epoch 136] ogbg-molclintox: 0.940108 val loss: 0.206942
[Epoch 136] ogbg-molclintox: 0.711733 test loss: 0.378921
[Epoch 137; Iter    20/   40] train: loss: 0.0019325
[Epoch 137] ogbg-molclintox: 0.934340 val loss: 0.205663
[Epoch 137] ogbg-molclintox: 0.727542 test loss: 0.359276
[Epoch 138; Iter    10/   40] train: loss: 0.0042475
[Epoch 138; Iter    40/   40] train: loss: 0.0476143
[Epoch 138] ogbg-molclintox: 0.941480 val loss: 0.215215
[Epoch 138] ogbg-molclintox: 0.710650 test loss: 0.371300
[Epoch 139; Iter    30/   40] train: loss: 0.0048404
[Epoch 139] ogbg-molclintox: 0.947275 val loss: 0.213873
[Epoch 139] ogbg-molclintox: 0.718625 test loss: 0.364709
[Epoch 140; Iter    20/   40] train: loss: 0.0633265
[Epoch 140] ogbg-molclintox: 0.941786 val loss: 0.219859
[Epoch 140] ogbg-molclintox: 0.722541 test loss: 0.373383
[Epoch 141; Iter    10/   40] train: loss: 0.0726312
[Epoch 141; Iter    40/   40] train: loss: 0.0029178
[Epoch 141] ogbg-molclintox: 0.938816 val loss: 0.206666
[Epoch 141] ogbg-molclintox: 0.697318 test loss: 0.374645
[Epoch 142; Iter    30/   40] train: loss: 0.0049098
[Epoch 142] ogbg-molclintox: 0.940494 val loss: 0.228292
[Epoch 142] ogbg-molclintox: 0.713866 test loss: 0.379394
[Epoch 143; Iter    20/   40] train: loss: 0.0026857
[Epoch 143] ogbg-molclintox: 0.939055 val loss: 0.227777
[Epoch 143] ogbg-molclintox: 0.727300 test loss: 0.377122
[Epoch 144; Iter    10/   40] train: loss: 0.0175318
[Epoch 144; Iter    40/   40] train: loss: 0.0886164
[Epoch 144] ogbg-molclintox: 0.942492 val loss: 0.217659
[Epoch 144] ogbg-molclintox: 0.708560 test loss: 0.378756
[Epoch 145; Iter    30/   40] train: loss: 0.0400651
[Epoch 145] ogbg-molclintox: 0.940534 val loss: 0.231983
[Epoch 145] ogbg-molclintox: 0.721841 test loss: 0.389460
[Epoch 146; Iter    20/   40] train: loss: 0.1112137
[Epoch 146] ogbg-molclintox: 0.935659 val loss: 0.227273
[Epoch 146] ogbg-molclintox: 0.721648 test loss: 0.382213
[Epoch 147; Iter    10/   40] train: loss: 0.0895405
[Epoch 147; Iter    40/   40] train: loss: 0.0020307
[Epoch 147] ogbg-molclintox: 0.939429 val loss: 0.225975
[Epoch 147] ogbg-molclintox: 0.727020 test loss: 0.375950
[Epoch 148; Iter    30/   40] train: loss: 0.0384657
[Epoch 148] ogbg-molclintox: 0.939548 val loss: 0.216810
[Epoch 148] ogbg-molclintox: 0.731843 test loss: 0.373826
[Epoch 149; Iter    20/   40] train: loss: 0.0285217
[Epoch 149] ogbg-molclintox: 0.939335 val loss: 0.217463
[Epoch 149] ogbg-molclintox: 0.724073 test loss: 0.386001
[Epoch 150; Iter    10/   40] train: loss: 0.0354755
[Epoch 150; Iter    40/   40] train: loss: 0.0045522
[Epoch 150] ogbg-molclintox: 0.937576 val loss: 0.230987
[Epoch 150] ogbg-molclintox: 0.721418 test loss: 0.382294
[Epoch 151; Iter    30/   40] train: loss: 0.0435283
[Epoch 151] ogbg-molclintox: 0.930650 val loss: 0.226237
[Epoch 151] ogbg-molclintox: 0.684580 test loss: 0.399918
[Epoch 152; Iter    20/   40] train: loss: 0.0977426
[Epoch 152] ogbg-molclintox: 0.939788 val loss: 0.232879
[Epoch 152] ogbg-molclintox: 0.706077 test loss: 0.399301
[Epoch 153; Iter    10/   40] train: loss: 0.0035861
[Epoch 153; Iter    40/   40] train: loss: 0.0117898
[Epoch 153] ogbg-molclintox: 0.934646 val loss: 0.228603
[Epoch 153] ogbg-molclintox: 0.685020 test loss: 0.402709
[Epoch 154; Iter    30/   40] train: loss: 0.0019390
[Epoch 154] ogbg-molclintox: 0.936272 val loss: 0.226386
[Epoch 154] ogbg-molclintox: 0.692649 test loss: 0.401834
[Epoch 155; Iter    20/   40] train: loss: 0.0625251
[Epoch 155] ogbg-molclintox: 0.943079 val loss: 0.229516
[Epoch 155] ogbg-molclintox: 0.704527 test loss: 0.408444
[Epoch 156; Iter    10/   40] train: loss: 0.0589791
[Epoch 156; Iter    40/   40] train: loss: 0.0069401
[Epoch 156] ogbg-molclintox: 0.938270 val loss: 0.221642
[Epoch 156] ogbg-molclintox: 0.694971 test loss: 0.406845
[Epoch 157; Iter    30/   40] train: loss: 0.0157165
[Epoch 157] ogbg-molclintox: 0.938763 val loss: 0.221577
[Epoch 157] ogbg-molclintox: 0.696528 test loss: 0.410175
[Epoch 158; Iter    20/   40] train: loss: 0.0028124
[Epoch 158] ogbg-molclintox: 0.936525 val loss: 0.228611
[Epoch 158] ogbg-molclintox: 0.701849 test loss: 0.403342
[Epoch 159; Iter    10/   40] train: loss: 0.0376144
[Epoch 159; Iter    40/   40] train: loss: 0.0019790
[Epoch 159] ogbg-molclintox: 0.944704 val loss: 0.225750
[Epoch 159] ogbg-molclintox: 0.696829 test loss: 0.399041
[Epoch 160; Iter    30/   40] train: loss: 0.0047165
[Epoch 160] ogbg-molclintox: 0.944184 val loss: 0.221493
[Epoch 160] ogbg-molclintox: 0.710155 test loss: 0.397882
[Epoch 161; Iter    20/   40] train: loss: 0.0204225
[Epoch 161] ogbg-molclintox: 0.948127 val loss: 0.222163
[Epoch 161] ogbg-molclintox: 0.727505 test loss: 0.394821
[Epoch 162; Iter    10/   40] train: loss: 0.0485008
[Epoch 162; Iter    40/   40] train: loss: 0.0482014
[Epoch 162] ogbg-molclintox: 0.948380 val loss: 0.211543
[Epoch 162] ogbg-molclintox: 0.707411 test loss: 0.399182
[Epoch 163; Iter    30/   40] train: loss: 0.0033075
[Epoch 163] ogbg-molclintox: 0.945556 val loss: 0.220760
[Epoch 163] ogbg-molclintox: 0.727276 test loss: 0.387192
[Epoch 164; Iter    20/   40] train: loss: 0.0675035
[Epoch 164] ogbg-molclintox: 0.945836 val loss: 0.224324
[Epoch 164] ogbg-molclintox: 0.731065 test loss: 0.391560
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 165; Iter    10/   40] train: loss: 0.0020333
[Epoch 165; Iter    40/   40] train: loss: 0.0032241
[Epoch 165] ogbg-molclintox: 0.950419 val loss: 0.178881
[Epoch 165] ogbg-molclintox: 0.682025 test loss: 0.405120
[Epoch 166; Iter    30/   40] train: loss: 0.0031609
[Epoch 166] ogbg-molclintox: 0.949287 val loss: 0.176740
[Epoch 166] ogbg-molclintox: 0.700002 test loss: 0.399826
[Epoch 167; Iter    20/   40] train: loss: 0.0357383
[Epoch 167] ogbg-molclintox: 0.946676 val loss: 0.182635
[Epoch 167] ogbg-molclintox: 0.704913 test loss: 0.399207
[Epoch 168; Iter    10/   40] train: loss: 0.0527117
[Epoch 168; Iter    40/   40] train: loss: 0.0070971
[Epoch 168] ogbg-molclintox: 0.948181 val loss: 0.189975
[Epoch 168] ogbg-molclintox: 0.706113 test loss: 0.409305
[Epoch 169; Iter    30/   40] train: loss: 0.0014755
[Epoch 169] ogbg-molclintox: 0.945331 val loss: 0.178244
[Epoch 169] ogbg-molclintox: 0.680469 test loss: 0.404006
[Epoch 170; Iter    20/   40] train: loss: 0.0036974
[Epoch 170] ogbg-molclintox: 0.945331 val loss: 0.190809
[Epoch 170] ogbg-molclintox: 0.662926 test loss: 0.412179
[Epoch 171; Iter    10/   40] train: loss: 0.0110641
[Epoch 171; Iter    40/   40] train: loss: 0.0796356
[Epoch 171] ogbg-molclintox: 0.946183 val loss: 0.186845
[Epoch 171] ogbg-molclintox: 0.691237 test loss: 0.411453
[Epoch 172; Iter    30/   40] train: loss: 0.0051270
[Epoch 172] ogbg-molclintox: 0.948208 val loss: 0.190621
[Epoch 172] ogbg-molclintox: 0.706355 test loss: 0.403514
[Epoch 173; Iter    20/   40] train: loss: 0.0016970
[Epoch 173] ogbg-molclintox: 0.944411 val loss: 0.187678
[Epoch 173] ogbg-molclintox: 0.684927 test loss: 0.403476
[Epoch 174; Iter    10/   40] train: loss: 0.0257397
[Epoch 174; Iter    40/   40] train: loss: 0.0043618
[Epoch 174] ogbg-molclintox: 0.944411 val loss: 0.189716
[Epoch 174] ogbg-molclintox: 0.700434 test loss: 0.402372
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 174 epochs. Best model checkpoint was in epoch 114.
Statistics on  val_best_checkpoint
mean_pred: 0.28400975465774536
std_pred: 6.980011463165283
mean_targets: 0.5101351737976074
std_targets: 0.5007438659667969
prcauc: 0.839318962972839
rocauc: 0.9663908579019137
ogbg-molclintox: 0.9663908579019137
OGBNanLabelBCEWithLogitsLoss: 0.1479211613535881
Statistics on  test
mean_pred: 0.30665621161460876
std_pred: 7.082864284515381
mean_targets: 0.5101351737976074
std_targets: 0.5007438063621521
prcauc: 0.6513676010546701
rocauc: 0.6978306593041995
ogbg-molclintox: 0.6978306593041995
OGBNanLabelBCEWithLogitsLoss: 0.3790376901626587
Statistics on  train
mean_pred: 0.29399415850639343
std_pred: 7.693812847137451
mean_targets: 0.5050804018974304
std_targets: 0.5000800490379333
prcauc: 0.9916843874196037
rocauc: 0.998446719479023
ogbg-molclintox: 0.998446719479023
OGBNanLabelBCEWithLogitsLoss: 0.025759405133430845
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 165; Iter    10/   40] train: loss: 0.0050732
[Epoch 165; Iter    40/   40] train: loss: 0.0406457
[Epoch 165] ogbg-molclintox: 0.941746 val loss: 0.218112
[Epoch 165] ogbg-molclintox: 0.738605 test loss: 0.380236
[Epoch 166; Iter    30/   40] train: loss: 0.0398353
[Epoch 166] ogbg-molclintox: 0.942892 val loss: 0.216173
[Epoch 166] ogbg-molclintox: 0.728525 test loss: 0.378393
[Epoch 167; Iter    20/   40] train: loss: 0.0733395
[Epoch 167] ogbg-molclintox: 0.939362 val loss: 0.225445
[Epoch 167] ogbg-molclintox: 0.725732 test loss: 0.385506
[Epoch 168; Iter    10/   40] train: loss: 0.0030592
[Epoch 168; Iter    40/   40] train: loss: 0.0030434
[Epoch 168] ogbg-molclintox: 0.941880 val loss: 0.223004
[Epoch 168] ogbg-molclintox: 0.712207 test loss: 0.391797
[Epoch 169; Iter    30/   40] train: loss: 0.0035673
[Epoch 169] ogbg-molclintox: 0.943132 val loss: 0.221053
[Epoch 169] ogbg-molclintox: 0.709124 test loss: 0.400571
[Epoch 170; Iter    20/   40] train: loss: 0.0017372
[Epoch 170] ogbg-molclintox: 0.939055 val loss: 0.225435
[Epoch 170] ogbg-molclintox: 0.712041 test loss: 0.401154
[Epoch 171; Iter    10/   40] train: loss: 0.0330760
[Epoch 171; Iter    40/   40] train: loss: 0.0276803
[Epoch 171] ogbg-molclintox: 0.927693 val loss: 0.224116
[Epoch 171] ogbg-molclintox: 0.722119 test loss: 0.387232
[Epoch 172; Iter    30/   40] train: loss: 0.0034459
[Epoch 172] ogbg-molclintox: 0.939429 val loss: 0.228408
[Epoch 172] ogbg-molclintox: 0.731752 test loss: 0.385497
[Epoch 173; Iter    20/   40] train: loss: 0.0043576
[Epoch 173] ogbg-molclintox: 0.933208 val loss: 0.221430
[Epoch 173] ogbg-molclintox: 0.717871 test loss: 0.392259
[Epoch 174; Iter    10/   40] train: loss: 0.0170328
[Epoch 174; Iter    40/   40] train: loss: 0.0011161
[Epoch 174] ogbg-molclintox: 0.939282 val loss: 0.220541
[Epoch 174] ogbg-molclintox: 0.711429 test loss: 0.392416
[Epoch 175; Iter    30/   40] train: loss: 0.0023864
[Epoch 175] ogbg-molclintox: 0.936738 val loss: 0.216952
[Epoch 175] ogbg-molclintox: 0.699538 test loss: 0.399570
[Epoch 176; Iter    20/   40] train: loss: 0.0270311
[Epoch 176] ogbg-molclintox: 0.939469 val loss: 0.215754
[Epoch 176] ogbg-molclintox: 0.703761 test loss: 0.398707
[Epoch 177; Iter    10/   40] train: loss: 0.0556725
[Epoch 177; Iter    40/   40] train: loss: 0.0096578
[Epoch 177] ogbg-molclintox: 0.942866 val loss: 0.214306
[Epoch 177] ogbg-molclintox: 0.720538 test loss: 0.383458
[Epoch 178; Iter    30/   40] train: loss: 0.0018504
[Epoch 178] ogbg-molclintox: 0.945103 val loss: 0.217085
[Epoch 178] ogbg-molclintox: 0.716110 test loss: 0.386846
[Epoch 179; Iter    20/   40] train: loss: 0.0247395
[Epoch 179] ogbg-molclintox: 0.945810 val loss: 0.218167
[Epoch 179] ogbg-molclintox: 0.711459 test loss: 0.394782
[Epoch 180; Iter    10/   40] train: loss: 0.0053514
[Epoch 180; Iter    40/   40] train: loss: 0.0024222
[Epoch 180] ogbg-molclintox: 0.943478 val loss: 0.221371
[Epoch 180] ogbg-molclintox: 0.720116 test loss: 0.392030
Early stopping criterion based on -ogbg-molclintox- that should be max reached after 180 epochs. Best model checkpoint was in epoch 120.
Statistics on  val_best_checkpoint
mean_pred: 0.369255393743515
std_pred: 7.1540913581848145
mean_targets: 0.5101351737976074
std_targets: 0.5007438659667969
prcauc: 0.7904779984914234
rocauc: 0.9610348485917148
ogbg-molclintox: 0.9610348485917148
OGBNanLabelBCEWithLogitsLoss: 0.18612593039870262
Statistics on  test
mean_pred: 0.40056347846984863
std_pred: 7.342581272125244
mean_targets: 0.5101351737976074
std_targets: 0.5007438063621521
prcauc: 0.6434521118459535
rocauc: 0.6917317399753531
ogbg-molclintox: 0.6917317399753531
OGBNanLabelBCEWithLogitsLoss: 0.3747915536165237
Statistics on  train
mean_pred: 0.3554438650608063
std_pred: 7.4648756980896
mean_targets: 0.5050804018974304
std_targets: 0.5000800490379333
prcauc: 0.9911100345129642
rocauc: 0.9988643424845794
ogbg-molclintox: 0.9988643424845794
OGBNanLabelBCEWithLogitsLoss: 0.021979320477112197
All runs completed.
