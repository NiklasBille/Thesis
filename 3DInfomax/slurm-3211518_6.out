>>> Starting run for dataset: tox21
Running SCAFF configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.6.yml on cuda:0
Running SCAFF configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.7.yml on cuda:1
Running SCAFF configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.8.yml on cuda:2
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.6.yml --seed 4 --device cuda:0
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.7.yml --seed 4 --device cuda:1
Starting process for seed 4: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.8.yml --seed 4 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.6.yml --seed 5 --device cuda:0
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.8.yml --seed 5 --device cuda:2
Starting process for seed 5: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.7.yml --seed 5 --device cuda:1
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.6.yml --seed 6 --device cuda:0
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.8.yml --seed 6 --device cuda:2
Starting process for seed 6: python train.py --config configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.7.yml --seed 6 --device cuda:1
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.6.
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/home/users/u102845/.local/lib/python3.9/site-packages/ogb/graphproppred/dataset.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_dict = torch.load(pre_processed_file_path, 'rb')
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/workspace/train.py:223: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrain_checkpoint, map_location=device)
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/conda/envs/3DInfomax/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[ Using Seed :  6  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.8/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.8_6_26-05_10-04-59
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.8
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6922127
[Epoch 1; Iter    60/  209] train: loss: 0.6928524
[Epoch 1; Iter    90/  209] train: loss: 0.6915375
[Epoch 1; Iter   120/  209] train: loss: 0.6925225
[Epoch 1; Iter   150/  209] train: loss: 0.6921127
[Epoch 1; Iter   180/  209] train: loss: 0.6922696
[Epoch 1] ogbg-moltox21: 0.512113 val loss: 0.693809
[Epoch 1] ogbg-moltox21: 0.516141 test loss: 0.693827
[Epoch 2; Iter     1/  209] train: loss: 0.6923199
[Epoch 2; Iter    31/  209] train: loss: 0.6914638
[Epoch 2; Iter    61/  209] train: loss: 0.6915285
[Epoch 2; Iter    91/  209] train: loss: 0.6910518
[Epoch 2; Iter   121/  209] train: loss: 0.6913453
[Epoch 2; Iter   151/  209] train: loss: 0.6911838
[Epoch 2; Iter   181/  209] train: loss: 0.6907817
[Epoch 2] ogbg-moltox21: 0.516011 val loss: 0.692696
[Epoch 2] ogbg-moltox21: 0.518969 test loss: 0.692779
[Epoch 3; Iter     2/  209] train: loss: 0.6907580
[Epoch 3; Iter    32/  209] train: loss: 0.6901095
[Epoch 3; Iter    62/  209] train: loss: 0.6904997
[Epoch 3; Iter    92/  209] train: loss: 0.6897749
[Epoch 3; Iter   122/  209] train: loss: 0.6894065
[Epoch 3; Iter   152/  209] train: loss: 0.6888785
[Epoch 3; Iter   182/  209] train: loss: 0.6880506
[Epoch 3] ogbg-moltox21: 0.521126 val loss: 0.690990
[Epoch 3] ogbg-moltox21: 0.523207 test loss: 0.691106
[Epoch 4; Iter     3/  209] train: loss: 0.6867489
[Epoch 4; Iter    33/  209] train: loss: 0.6882828
[Epoch 4; Iter    63/  209] train: loss: 0.6871916
[Epoch 4; Iter    93/  209] train: loss: 0.6826128
[Epoch 4; Iter   123/  209] train: loss: 0.6591492
[Epoch 4; Iter   153/  209] train: loss: 0.6244155
[Epoch 4; Iter   183/  209] train: loss: 0.6199212
[Epoch 4] ogbg-moltox21: 0.693792 val loss: 0.714371
[Epoch 4] ogbg-moltox21: 0.670754 test loss: 0.717872
[Epoch 5; Iter     4/  209] train: loss: 0.5404229
[Epoch 5; Iter    34/  209] train: loss: 0.4817697
[Epoch 5; Iter    64/  209] train: loss: 0.4193895
[Epoch 5; Iter    94/  209] train: loss: 0.3926287
[Epoch 5; Iter   124/  209] train: loss: 0.3492918
[Epoch 5; Iter   154/  209] train: loss: 0.2838778
[Epoch 5; Iter   184/  209] train: loss: 0.2301665
[Epoch 5] ogbg-moltox21: 0.713291 val loss: 0.310429
[Epoch 5] ogbg-moltox21: 0.688656 test loss: 0.316785
[Epoch 6; Iter     5/  209] train: loss: 0.2098856
[Epoch 6; Iter    35/  209] train: loss: 0.1653824
[Epoch 6; Iter    65/  209] train: loss: 0.1881145
[Epoch 6; Iter    95/  209] train: loss: 0.2066678
[Epoch 6; Iter   125/  209] train: loss: 0.1546907
[Epoch 6; Iter   155/  209] train: loss: 0.2086152
[Epoch 6; Iter   185/  209] train: loss: 0.1752985
[Epoch 6] ogbg-moltox21: 0.712669 val loss: 0.273542
[Epoch 6] ogbg-moltox21: 0.706720 test loss: 0.278564
[Epoch 7; Iter     6/  209] train: loss: 0.1629451
[Epoch 7; Iter    36/  209] train: loss: 0.2424981
[Epoch 7; Iter    66/  209] train: loss: 0.1582917
[Epoch 7; Iter    96/  209] train: loss: 0.2376407
[Epoch 7; Iter   126/  209] train: loss: 0.1741127
[Epoch 7; Iter   156/  209] train: loss: 0.2312238
[Epoch 7; Iter   186/  209] train: loss: 0.2245636
[Epoch 7] ogbg-moltox21: 0.745329 val loss: 0.311519
[Epoch 7] ogbg-moltox21: 0.706244 test loss: 0.310481
[Epoch 8; Iter     7/  209] train: loss: 0.1817769
[Epoch 8; Iter    37/  209] train: loss: 0.2224823
[Epoch 8; Iter    67/  209] train: loss: 0.1540713
[Epoch 8; Iter    97/  209] train: loss: 0.2647148
[Epoch 8; Iter   127/  209] train: loss: 0.2692756
[Epoch 8; Iter   157/  209] train: loss: 0.1812462
[Epoch 8; Iter   187/  209] train: loss: 0.2384749
[Epoch 8] ogbg-moltox21: 0.735776 val loss: 0.292614
[Epoch 8] ogbg-moltox21: 0.693061 test loss: 0.298521
[Epoch 9; Iter     8/  209] train: loss: 0.2452450
[Epoch 9; Iter    38/  209] train: loss: 0.1833333
[Epoch 9; Iter    68/  209] train: loss: 0.1593675
[Epoch 9; Iter    98/  209] train: loss: 0.2732981
[Epoch 9; Iter   128/  209] train: loss: 0.2128541
[Epoch 9; Iter   158/  209] train: loss: 0.1710173
[Epoch 9; Iter   188/  209] train: loss: 0.1688803
[Epoch 9] ogbg-moltox21: 0.673865 val loss: 0.323986
[Epoch 9] ogbg-moltox21: 0.674192 test loss: 0.312673
[Epoch 10; Iter     9/  209] train: loss: 0.2144847
[Epoch 10; Iter    39/  209] train: loss: 0.1840178
[Epoch 10; Iter    69/  209] train: loss: 0.1865500
[Epoch 10; Iter    99/  209] train: loss: 0.1649740
[Epoch 10; Iter   129/  209] train: loss: 0.1544321
[Epoch 10; Iter   159/  209] train: loss: 0.1190250
[Epoch 10; Iter   189/  209] train: loss: 0.1705356
[Epoch 10] ogbg-moltox21: 0.746458 val loss: 0.277480
[Epoch 10] ogbg-moltox21: 0.688494 test loss: 0.297549
[Epoch 11; Iter    10/  209] train: loss: 0.2168321
[Epoch 11; Iter    40/  209] train: loss: 0.2256817
[Epoch 11; Iter    70/  209] train: loss: 0.2076673
[Epoch 11; Iter   100/  209] train: loss: 0.2568990
[Epoch 11; Iter   130/  209] train: loss: 0.1929624
[Epoch 11; Iter   160/  209] train: loss: 0.1859512
[Epoch 11; Iter   190/  209] train: loss: 0.1435591
[Epoch 11] ogbg-moltox21: 0.786081 val loss: 0.754816
[Epoch 11] ogbg-moltox21: 0.699905 test loss: 0.572044
[Epoch 12; Iter    11/  209] train: loss: 0.1246083
[Epoch 12; Iter    41/  209] train: loss: 0.2777481
[Epoch 12; Iter    71/  209] train: loss: 0.1644553
[Epoch 12; Iter   101/  209] train: loss: 0.2031347
[Epoch 12; Iter   131/  209] train: loss: 0.1900952
[Epoch 12; Iter   161/  209] train: loss: 0.2194532
[Epoch 12; Iter   191/  209] train: loss: 0.1444472
[Epoch 12] ogbg-moltox21: 0.789755 val loss: 0.248817
[Epoch 12] ogbg-moltox21: 0.720601 test loss: 0.274838
[ Using Seed :  5  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.8/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.8_5_26-05_10-05-00
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.8
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6925769
[Epoch 1; Iter    60/  209] train: loss: 0.6934115
[Epoch 1; Iter    90/  209] train: loss: 0.6918342
[Epoch 1; Iter   120/  209] train: loss: 0.6921923
[Epoch 1; Iter   150/  209] train: loss: 0.6927478
[Epoch 1; Iter   180/  209] train: loss: 0.6925935
[Epoch 1] ogbg-moltox21: 0.516602 val loss: 0.692146
[Epoch 1] ogbg-moltox21: 0.491652 test loss: 0.692197
[Epoch 2; Iter     1/  209] train: loss: 0.6920728
[Epoch 2; Iter    31/  209] train: loss: 0.6930675
[Epoch 2; Iter    61/  209] train: loss: 0.6914427
[Epoch 2; Iter    91/  209] train: loss: 0.6918743
[Epoch 2; Iter   121/  209] train: loss: 0.6910730
[Epoch 2; Iter   151/  209] train: loss: 0.6905196
[Epoch 2; Iter   181/  209] train: loss: 0.6907665
[Epoch 2] ogbg-moltox21: 0.525036 val loss: 0.690667
[Epoch 2] ogbg-moltox21: 0.497612 test loss: 0.690749
[Epoch 3; Iter     2/  209] train: loss: 0.6900764
[Epoch 3; Iter    32/  209] train: loss: 0.6899894
[Epoch 3; Iter    62/  209] train: loss: 0.6898114
[Epoch 3; Iter    92/  209] train: loss: 0.6890856
[Epoch 3; Iter   122/  209] train: loss: 0.6884488
[Epoch 3; Iter   152/  209] train: loss: 0.6892733
[Epoch 3; Iter   182/  209] train: loss: 0.6876254
[Epoch 3] ogbg-moltox21: 0.529574 val loss: 0.688181
[Epoch 3] ogbg-moltox21: 0.499922 test loss: 0.688333
[Epoch 4; Iter     3/  209] train: loss: 0.6888004
[Epoch 4; Iter    33/  209] train: loss: 0.6865941
[Epoch 4; Iter    63/  209] train: loss: 0.6861590
[Epoch 4; Iter    93/  209] train: loss: 0.6794155
[Epoch 4; Iter   123/  209] train: loss: 0.6586559
[Epoch 4; Iter   153/  209] train: loss: 0.6249622
[Epoch 4; Iter   183/  209] train: loss: 0.5890962
[Epoch 4] ogbg-moltox21: 0.646006 val loss: 0.640774
[Epoch 4] ogbg-moltox21: 0.658710 test loss: 0.638694
[Epoch 5; Iter     4/  209] train: loss: 0.5337171
[Epoch 5; Iter    34/  209] train: loss: 0.4720433
[Epoch 5; Iter    64/  209] train: loss: 0.4131840
[Epoch 5; Iter    94/  209] train: loss: 0.3521744
[Epoch 5; Iter   124/  209] train: loss: 0.3071619
[Epoch 5; Iter   154/  209] train: loss: 0.3111199
[Epoch 5; Iter   184/  209] train: loss: 0.2566398
[Epoch 5] ogbg-moltox21: 0.683670 val loss: 0.320903
[Epoch 5] ogbg-moltox21: 0.665804 test loss: 0.322122
[Epoch 6; Iter     5/  209] train: loss: 0.2771541
[Epoch 6; Iter    35/  209] train: loss: 0.2205903
[Epoch 6; Iter    65/  209] train: loss: 0.2392009
[Epoch 6; Iter    95/  209] train: loss: 0.1584488
[Epoch 6; Iter   125/  209] train: loss: 0.2611514
[Epoch 6; Iter   155/  209] train: loss: 0.2319890
[Epoch 6; Iter   185/  209] train: loss: 0.1752612
[Epoch 6] ogbg-moltox21: 0.677662 val loss: 0.295081
[Epoch 6] ogbg-moltox21: 0.648006 test loss: 0.302197
[Epoch 7; Iter     6/  209] train: loss: 0.1589395
[Epoch 7; Iter    36/  209] train: loss: 0.1550723
[Epoch 7; Iter    66/  209] train: loss: 0.2141547
[Epoch 7; Iter    96/  209] train: loss: 0.2497334
[Epoch 7; Iter   126/  209] train: loss: 0.3212533
[Epoch 7; Iter   156/  209] train: loss: 0.1722968
[Epoch 7; Iter   186/  209] train: loss: 0.1802453
[Epoch 7] ogbg-moltox21: 0.691444 val loss: 0.343391
[Epoch 7] ogbg-moltox21: 0.685579 test loss: 0.335893
[Epoch 8; Iter     7/  209] train: loss: 0.2276868
[Epoch 8; Iter    37/  209] train: loss: 0.1566515
[Epoch 8; Iter    67/  209] train: loss: 0.1423099
[Epoch 8; Iter    97/  209] train: loss: 0.2030294
[Epoch 8; Iter   127/  209] train: loss: 0.2497001
[Epoch 8; Iter   157/  209] train: loss: 0.1095153
[Epoch 8; Iter   187/  209] train: loss: 0.3161566
[Epoch 8] ogbg-moltox21: 0.692829 val loss: 0.491732
[Epoch 8] ogbg-moltox21: 0.690583 test loss: 0.463035
[Epoch 9; Iter     8/  209] train: loss: 0.1837315
[Epoch 9; Iter    38/  209] train: loss: 0.2256686
[Epoch 9; Iter    68/  209] train: loss: 0.0942934
[Epoch 9; Iter    98/  209] train: loss: 0.1947921
[Epoch 9; Iter   128/  209] train: loss: 0.2194395
[Epoch 9; Iter   158/  209] train: loss: 0.1464103
[Epoch 9; Iter   188/  209] train: loss: 0.2136557
[Epoch 9] ogbg-moltox21: 0.743749 val loss: 0.267746
[Epoch 9] ogbg-moltox21: 0.717549 test loss: 0.272200
[Epoch 10; Iter     9/  209] train: loss: 0.1515135
[Epoch 10; Iter    39/  209] train: loss: 0.2367504
[Epoch 10; Iter    69/  209] train: loss: 0.2838928
[Epoch 10; Iter    99/  209] train: loss: 0.1677250
[Epoch 10; Iter   129/  209] train: loss: 0.1837388
[Epoch 10; Iter   159/  209] train: loss: 0.2430761
[Epoch 10; Iter   189/  209] train: loss: 0.1744719
[Epoch 10] ogbg-moltox21: 0.717703 val loss: 0.281105
[Epoch 10] ogbg-moltox21: 0.694031 test loss: 0.285349
[Epoch 11; Iter    10/  209] train: loss: 0.2081070
[Epoch 11; Iter    40/  209] train: loss: 0.1994221
[Epoch 11; Iter    70/  209] train: loss: 0.1423335
[Epoch 11; Iter   100/  209] train: loss: 0.1840357
[Epoch 11; Iter   130/  209] train: loss: 0.2092510
[Epoch 11; Iter   160/  209] train: loss: 0.2230725
[Epoch 11; Iter   190/  209] train: loss: 0.1882197
[Epoch 11] ogbg-moltox21: 0.753667 val loss: 0.266719
[Epoch 11] ogbg-moltox21: 0.731627 test loss: 0.282757
[Epoch 12; Iter    11/  209] train: loss: 0.2055283
[Epoch 12; Iter    41/  209] train: loss: 0.2294356
[Epoch 12; Iter    71/  209] train: loss: 0.1891649
[Epoch 12; Iter   101/  209] train: loss: 0.1499263
[Epoch 12; Iter   131/  209] train: loss: 0.2608311
[Epoch 12; Iter   161/  209] train: loss: 0.2131430
[Epoch 12; Iter   191/  209] train: loss: 0.2417375
[Epoch 12] ogbg-moltox21: 0.772704 val loss: 0.257672
[Epoch 12] ogbg-moltox21: 0.740866 test loss: 0.281989
[ Using Seed :  4  ]
using device:  cuda:2
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.8/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.8_4_26-05_10-05-00
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.8.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.8
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.8
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:2
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.8
[Epoch 1; Iter    30/  209] train: loss: 0.6930513
[Epoch 1; Iter    60/  209] train: loss: 0.6932298
[Epoch 1; Iter    90/  209] train: loss: 0.6928320
[Epoch 1; Iter   120/  209] train: loss: 0.6937398
[Epoch 1; Iter   150/  209] train: loss: 0.6926974
[Epoch 1; Iter   180/  209] train: loss: 0.6927426
[Epoch 1] ogbg-moltox21: 0.488268 val loss: 0.691392
[Epoch 1] ogbg-moltox21: 0.515376 test loss: 0.691490
[Epoch 2; Iter     1/  209] train: loss: 0.6913806
[Epoch 2; Iter    31/  209] train: loss: 0.6927036
[Epoch 2; Iter    61/  209] train: loss: 0.6921554
[Epoch 2; Iter    91/  209] train: loss: 0.6918639
[Epoch 2; Iter   121/  209] train: loss: 0.6923195
[Epoch 2; Iter   151/  209] train: loss: 0.6915021
[Epoch 2; Iter   181/  209] train: loss: 0.6912195
[Epoch 2] ogbg-moltox21: 0.487954 val loss: 0.690391
[Epoch 2] ogbg-moltox21: 0.515316 test loss: 0.690534
[Epoch 3; Iter     2/  209] train: loss: 0.6905911
[Epoch 3; Iter    32/  209] train: loss: 0.6898279
[Epoch 3; Iter    62/  209] train: loss: 0.6909522
[Epoch 3; Iter    92/  209] train: loss: 0.6900539
[Epoch 3; Iter   122/  209] train: loss: 0.6891491
[Epoch 3; Iter   152/  209] train: loss: 0.6885039
[Epoch 3; Iter   182/  209] train: loss: 0.6881315
[Epoch 3] ogbg-moltox21: 0.492307 val loss: 0.687908
[Epoch 3] ogbg-moltox21: 0.518842 test loss: 0.688071
[Epoch 4; Iter     3/  209] train: loss: 0.6881874
[Epoch 4; Iter    33/  209] train: loss: 0.6875826
[Epoch 4; Iter    63/  209] train: loss: 0.6875308
[Epoch 4; Iter    93/  209] train: loss: 0.6810486
[Epoch 4; Iter   123/  209] train: loss: 0.6593581
[Epoch 4; Iter   153/  209] train: loss: 0.6309950
[Epoch 4; Iter   183/  209] train: loss: 0.5847374
[Epoch 4] ogbg-moltox21: 0.685408 val loss: 0.696322
[Epoch 4] ogbg-moltox21: 0.661513 test loss: 0.695340
[Epoch 5; Iter     4/  209] train: loss: 0.5290123
[Epoch 5; Iter    34/  209] train: loss: 0.4660520
[Epoch 5; Iter    64/  209] train: loss: 0.4400271
[Epoch 5; Iter    94/  209] train: loss: 0.3741885
[Epoch 5; Iter   124/  209] train: loss: 0.3899929
[Epoch 5; Iter   154/  209] train: loss: 0.2379459
[Epoch 5; Iter   184/  209] train: loss: 0.2301288
[Epoch 5] ogbg-moltox21: 0.702141 val loss: 0.316147
[Epoch 5] ogbg-moltox21: 0.680764 test loss: 0.319559
[Epoch 6; Iter     5/  209] train: loss: 0.2132916
[Epoch 6; Iter    35/  209] train: loss: 0.2173021
[Epoch 6; Iter    65/  209] train: loss: 0.2234228
[Epoch 6; Iter    95/  209] train: loss: 0.2333672
[Epoch 6; Iter   125/  209] train: loss: 0.3127131
[Epoch 6; Iter   155/  209] train: loss: 0.2447008
[Epoch 6; Iter   185/  209] train: loss: 0.2563261
[Epoch 6] ogbg-moltox21: 0.724703 val loss: 0.280399
[Epoch 6] ogbg-moltox21: 0.709127 test loss: 0.277245
[Epoch 7; Iter     6/  209] train: loss: 0.3061304
[Epoch 7; Iter    36/  209] train: loss: 0.1934687
[Epoch 7; Iter    66/  209] train: loss: 0.2573374
[Epoch 7; Iter    96/  209] train: loss: 0.2074975
[Epoch 7; Iter   126/  209] train: loss: 0.1844997
[Epoch 7; Iter   156/  209] train: loss: 0.2152909
[Epoch 7; Iter   186/  209] train: loss: 0.1924327
[Epoch 7] ogbg-moltox21: 0.752449 val loss: 0.311196
[Epoch 7] ogbg-moltox21: 0.718256 test loss: 0.319943
[Epoch 8; Iter     7/  209] train: loss: 0.1337785
[Epoch 8; Iter    37/  209] train: loss: 0.2328913
[Epoch 8; Iter    67/  209] train: loss: 0.2834444
[Epoch 8; Iter    97/  209] train: loss: 0.1800573
[Epoch 8; Iter   127/  209] train: loss: 0.2857223
[Epoch 8; Iter   157/  209] train: loss: 0.1556678
[Epoch 8; Iter   187/  209] train: loss: 0.2231929
[Epoch 8] ogbg-moltox21: 0.731762 val loss: 0.275037
[Epoch 8] ogbg-moltox21: 0.692827 test loss: 0.279796
[Epoch 9; Iter     8/  209] train: loss: 0.2571332
[Epoch 9; Iter    38/  209] train: loss: 0.1517459
[Epoch 9; Iter    68/  209] train: loss: 0.2265967
[Epoch 9; Iter    98/  209] train: loss: 0.1989620
[Epoch 9; Iter   128/  209] train: loss: 0.1728555
[Epoch 9; Iter   158/  209] train: loss: 0.1884810
[Epoch 9; Iter   188/  209] train: loss: 0.2536185
[Epoch 9] ogbg-moltox21: 0.772529 val loss: 0.262384
[Epoch 9] ogbg-moltox21: 0.727804 test loss: 0.275599
[Epoch 10; Iter     9/  209] train: loss: 0.2259904
[Epoch 10; Iter    39/  209] train: loss: 0.2066337
[Epoch 10; Iter    69/  209] train: loss: 0.1989910
[Epoch 10; Iter    99/  209] train: loss: 0.2152107
[Epoch 10; Iter   129/  209] train: loss: 0.2188326
[Epoch 10; Iter   159/  209] train: loss: 0.1823864
[Epoch 10; Iter   189/  209] train: loss: 0.2186593
[Epoch 10] ogbg-moltox21: 0.640810 val loss: 3.213034
[Epoch 10] ogbg-moltox21: 0.572733 test loss: 3.139734
[Epoch 11; Iter    10/  209] train: loss: 0.2187484
[Epoch 11; Iter    40/  209] train: loss: 0.1812762
[Epoch 11; Iter    70/  209] train: loss: 0.1762019
[Epoch 11; Iter   100/  209] train: loss: 0.3332092
[Epoch 11; Iter   130/  209] train: loss: 0.1879229
[Epoch 11; Iter   160/  209] train: loss: 0.2412698
[Epoch 11; Iter   190/  209] train: loss: 0.1637310
[Epoch 11] ogbg-moltox21: 0.745639 val loss: 0.266882
[Epoch 11] ogbg-moltox21: 0.723345 test loss: 0.268262
[Epoch 12; Iter    11/  209] train: loss: 0.1891798
[Epoch 12; Iter    41/  209] train: loss: 0.1069884
[Epoch 12; Iter    71/  209] train: loss: 0.3170941
[Epoch 12; Iter   101/  209] train: loss: 0.1750933
[Epoch 12; Iter   131/  209] train: loss: 0.2111291
[Epoch 12; Iter   161/  209] train: loss: 0.1671594
[Epoch 12; Iter   191/  209] train: loss: 0.1094209
[Epoch 12] ogbg-moltox21: 0.776992 val loss: 0.253405
[Epoch 12] ogbg-moltox21: 0.723077 test loss: 0.269813
[ Using Seed :  5  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.7/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.7_5_26-05_10-04-59
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.7
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6927716
[Epoch 1; Iter    60/  183] train: loss: 0.6928294
[Epoch 1; Iter    90/  183] train: loss: 0.6926784
[Epoch 1; Iter   120/  183] train: loss: 0.6924860
[Epoch 1; Iter   150/  183] train: loss: 0.6925661
[Epoch 1; Iter   180/  183] train: loss: 0.6930479
[Epoch 1] ogbg-moltox21: 0.513870 val loss: 0.691753
[Epoch 1] ogbg-moltox21: 0.502688 test loss: 0.691986
[Epoch 2; Iter    27/  183] train: loss: 0.6912633
[Epoch 2; Iter    57/  183] train: loss: 0.6917918
[Epoch 2; Iter    87/  183] train: loss: 0.6924124
[Epoch 2; Iter   117/  183] train: loss: 0.6916838
[Epoch 2; Iter   147/  183] train: loss: 0.6914250
[Epoch 2; Iter   177/  183] train: loss: 0.6913751
[Epoch 2] ogbg-moltox21: 0.514787 val loss: 0.690407
[Epoch 2] ogbg-moltox21: 0.502333 test loss: 0.690659
[Epoch 3; Iter    24/  183] train: loss: 0.6904994
[Epoch 3; Iter    54/  183] train: loss: 0.6909302
[Epoch 3; Iter    84/  183] train: loss: 0.6901060
[Epoch 3; Iter   114/  183] train: loss: 0.6900698
[Epoch 3; Iter   144/  183] train: loss: 0.6888561
[Epoch 3; Iter   174/  183] train: loss: 0.6893667
[Epoch 3] ogbg-moltox21: 0.517575 val loss: 0.688737
[Epoch 3] ogbg-moltox21: 0.506687 test loss: 0.689052
[Epoch 4; Iter    21/  183] train: loss: 0.6884579
[Epoch 4; Iter    51/  183] train: loss: 0.6868330
[Epoch 4; Iter    81/  183] train: loss: 0.6871158
[Epoch 4; Iter   111/  183] train: loss: 0.6872618
[Epoch 4; Iter   141/  183] train: loss: 0.6864325
[Epoch 4; Iter   171/  183] train: loss: 0.6809000
[Epoch 4] ogbg-moltox21: 0.643962 val loss: 0.711579
[Epoch 4] ogbg-moltox21: 0.641718 test loss: 0.713200
[Epoch 5; Iter    18/  183] train: loss: 0.6617095
[Epoch 5; Iter    48/  183] train: loss: 0.6256161
[Epoch 5; Iter    78/  183] train: loss: 0.5815840
[Epoch 5; Iter   108/  183] train: loss: 0.5551366
[Epoch 5; Iter   138/  183] train: loss: 0.4760071
[Epoch 5; Iter   168/  183] train: loss: 0.4184674
[Epoch 5] ogbg-moltox21: 0.695392 val loss: 0.527630
[Epoch 5] ogbg-moltox21: 0.681994 test loss: 0.536394
[Epoch 6; Iter    15/  183] train: loss: 0.3654048
[Epoch 6; Iter    45/  183] train: loss: 0.3344929
[Epoch 6; Iter    75/  183] train: loss: 0.3123980
[Epoch 6; Iter   105/  183] train: loss: 0.2290611
[Epoch 6; Iter   135/  183] train: loss: 0.1778822
[Epoch 6; Iter   165/  183] train: loss: 0.1767095
[Epoch 6] ogbg-moltox21: 0.706184 val loss: 0.319262
[Epoch 6] ogbg-moltox21: 0.708265 test loss: 0.331297
[Epoch 7; Iter    12/  183] train: loss: 0.2265518
[Epoch 7; Iter    42/  183] train: loss: 0.2278421
[Epoch 7; Iter    72/  183] train: loss: 0.1941756
[Epoch 7; Iter   102/  183] train: loss: 0.2107483
[Epoch 7; Iter   132/  183] train: loss: 0.1374450
[Epoch 7; Iter   162/  183] train: loss: 0.1733254
[Epoch 7] ogbg-moltox21: 0.707807 val loss: 0.359593
[Epoch 7] ogbg-moltox21: 0.689227 test loss: 0.359344
[Epoch 8; Iter     9/  183] train: loss: 0.2701574
[Epoch 8; Iter    39/  183] train: loss: 0.2300097
[Epoch 8; Iter    69/  183] train: loss: 0.2059633
[Epoch 8; Iter    99/  183] train: loss: 0.1851430
[Epoch 8; Iter   129/  183] train: loss: 0.2563748
[Epoch 8; Iter   159/  183] train: loss: 0.1546014
[Epoch 8] ogbg-moltox21: 0.715897 val loss: 0.347539
[Epoch 8] ogbg-moltox21: 0.708329 test loss: 0.337760
[Epoch 9; Iter     6/  183] train: loss: 0.1173388
[Epoch 9; Iter    36/  183] train: loss: 0.1471221
[Epoch 9; Iter    66/  183] train: loss: 0.2157846
[Epoch 9; Iter    96/  183] train: loss: 0.1693316
[Epoch 9; Iter   126/  183] train: loss: 0.1608513
[Epoch 9; Iter   156/  183] train: loss: 0.1963865
[Epoch 9] ogbg-moltox21: 0.711359 val loss: 0.442015
[Epoch 9] ogbg-moltox21: 0.694024 test loss: 0.466846
[Epoch 10; Iter     3/  183] train: loss: 0.2056414
[Epoch 10; Iter    33/  183] train: loss: 0.2441633
[Epoch 10; Iter    63/  183] train: loss: 0.1691614
[Epoch 10; Iter    93/  183] train: loss: 0.2193032
[Epoch 10; Iter   123/  183] train: loss: 0.2113523
[Epoch 10; Iter   153/  183] train: loss: 0.1260925
[Epoch 10; Iter   183/  183] train: loss: 0.1821086
[Epoch 10] ogbg-moltox21: 0.714747 val loss: 0.334884
[Epoch 10] ogbg-moltox21: 0.689363 test loss: 0.335307
[Epoch 11; Iter    30/  183] train: loss: 0.1328121
[Epoch 11; Iter    60/  183] train: loss: 0.2443533
[Epoch 11; Iter    90/  183] train: loss: 0.1933247
[Epoch 11; Iter   120/  183] train: loss: 0.1817500
[Epoch 11; Iter   150/  183] train: loss: 0.2127640
[Epoch 11; Iter   180/  183] train: loss: 0.2625844
[Epoch 11] ogbg-moltox21: 0.719665 val loss: 0.339732
[Epoch 11] ogbg-moltox21: 0.720590 test loss: 0.327342
[Epoch 12; Iter    27/  183] train: loss: 0.1077364
[Epoch 12; Iter    57/  183] train: loss: 0.2124250
[Epoch 12; Iter    87/  183] train: loss: 0.1090007
[Epoch 12; Iter   117/  183] train: loss: 0.1597616
[Epoch 12; Iter   147/  183] train: loss: 0.1931220
[Epoch 12; Iter   177/  183] train: loss: 0.1879762
[Epoch 12] ogbg-moltox21: 0.733633 val loss: 0.297791
[Epoch 12] ogbg-moltox21: 0.722722 test loss: 0.293177
[Epoch 13; Iter    24/  183] train: loss: 0.0979885
[Epoch 13; Iter    54/  183] train: loss: 0.3286984
[Epoch 13; Iter    84/  183] train: loss: 0.2394609
[Epoch 13; Iter   114/  183] train: loss: 0.1589676
[Epoch 13; Iter   144/  183] train: loss: 0.1642162
[Epoch 13; Iter   174/  183] train: loss: 0.1633887
[Epoch 13] ogbg-moltox21: 0.738781 val loss: 0.287653
[Epoch 13] ogbg-moltox21: 0.738066 test loss: 0.287848
[Epoch 14; Iter    21/  183] train: loss: 0.1223306
[Epoch 14; Iter    51/  183] train: loss: 0.1923018
[ Using Seed :  4  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.7/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.7_4_26-05_10-05-00
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.7
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6934789
[Epoch 1; Iter    60/  183] train: loss: 0.6931792
[Epoch 1; Iter    90/  183] train: loss: 0.6929236
[Epoch 1; Iter   120/  183] train: loss: 0.6930624
[Epoch 1; Iter   150/  183] train: loss: 0.6927115
[Epoch 1; Iter   180/  183] train: loss: 0.6928344
[Epoch 1] ogbg-moltox21: 0.491758 val loss: 0.691237
[Epoch 1] ogbg-moltox21: 0.490907 test loss: 0.691501
[Epoch 2; Iter    27/  183] train: loss: 0.6923031
[Epoch 2; Iter    57/  183] train: loss: 0.6927411
[Epoch 2; Iter    87/  183] train: loss: 0.6919899
[Epoch 2; Iter   117/  183] train: loss: 0.6921450
[Epoch 2; Iter   147/  183] train: loss: 0.6916752
[Epoch 2; Iter   177/  183] train: loss: 0.6909996
[Epoch 2] ogbg-moltox21: 0.496391 val loss: 0.690500
[Epoch 2] ogbg-moltox21: 0.496806 test loss: 0.690743
[Epoch 3; Iter    24/  183] train: loss: 0.6914089
[Epoch 3; Iter    54/  183] train: loss: 0.6905456
[Epoch 3; Iter    84/  183] train: loss: 0.6902992
[Epoch 3; Iter   114/  183] train: loss: 0.6902140
[Epoch 3; Iter   144/  183] train: loss: 0.6893569
[Epoch 3; Iter   174/  183] train: loss: 0.6893305
[Epoch 3] ogbg-moltox21: 0.495192 val loss: 0.688509
[Epoch 3] ogbg-moltox21: 0.497751 test loss: 0.688709
[Epoch 4; Iter    21/  183] train: loss: 0.6890116
[Epoch 4; Iter    51/  183] train: loss: 0.6890537
[Epoch 4; Iter    81/  183] train: loss: 0.6878815
[Epoch 4; Iter   111/  183] train: loss: 0.6879454
[Epoch 4; Iter   141/  183] train: loss: 0.6869687
[Epoch 4; Iter   171/  183] train: loss: 0.6826376
[Epoch 4] ogbg-moltox21: 0.628760 val loss: 0.703284
[Epoch 4] ogbg-moltox21: 0.624905 test loss: 0.704459
[Epoch 5; Iter    18/  183] train: loss: 0.6617450
[Epoch 5; Iter    48/  183] train: loss: 0.6188642
[Epoch 5; Iter    78/  183] train: loss: 0.5738474
[Epoch 5; Iter   108/  183] train: loss: 0.5250589
[Epoch 5; Iter   138/  183] train: loss: 0.4727872
[Epoch 5; Iter   168/  183] train: loss: 0.4024554
[Epoch 5] ogbg-moltox21: 0.699815 val loss: 0.500604
[Epoch 5] ogbg-moltox21: 0.694407 test loss: 0.499484
[Epoch 6; Iter    15/  183] train: loss: 0.3576183
[Epoch 6; Iter    45/  183] train: loss: 0.2958531
[Epoch 6; Iter    75/  183] train: loss: 0.3094313
[Epoch 6; Iter   105/  183] train: loss: 0.2288514
[Epoch 6; Iter   135/  183] train: loss: 0.1954935
[Epoch 6; Iter   165/  183] train: loss: 0.2069646
[Epoch 6] ogbg-moltox21: 0.716663 val loss: 0.296268
[Epoch 6] ogbg-moltox21: 0.719004 test loss: 0.288297
[Epoch 7; Iter    12/  183] train: loss: 0.1879802
[Epoch 7; Iter    42/  183] train: loss: 0.1611675
[Epoch 7; Iter    72/  183] train: loss: 0.1977266
[Epoch 7; Iter   102/  183] train: loss: 0.2189856
[Epoch 7; Iter   132/  183] train: loss: 0.1997900
[Epoch 7; Iter   162/  183] train: loss: 0.1705304
[Epoch 7] ogbg-moltox21: 0.710845 val loss: 0.295919
[Epoch 7] ogbg-moltox21: 0.715055 test loss: 0.291697
[Epoch 8; Iter     9/  183] train: loss: 0.1480391
[Epoch 8; Iter    39/  183] train: loss: 0.1434406
[Epoch 8; Iter    69/  183] train: loss: 0.1459889
[Epoch 8; Iter    99/  183] train: loss: 0.1801273
[Epoch 8; Iter   129/  183] train: loss: 0.1388682
[Epoch 8; Iter   159/  183] train: loss: 0.2082282
[Epoch 8] ogbg-moltox21: 0.648909 val loss: 0.411856
[Epoch 8] ogbg-moltox21: 0.655123 test loss: 0.378631
[Epoch 9; Iter     6/  183] train: loss: 0.1566232
[Epoch 9; Iter    36/  183] train: loss: 0.1926213
[Epoch 9; Iter    66/  183] train: loss: 0.1945999
[Epoch 9; Iter    96/  183] train: loss: 0.1388234
[Epoch 9; Iter   126/  183] train: loss: 0.1542217
[Epoch 9; Iter   156/  183] train: loss: 0.2818675
[Epoch 9] ogbg-moltox21: 0.711737 val loss: 0.294518
[Epoch 9] ogbg-moltox21: 0.713699 test loss: 0.307845
[Epoch 10; Iter     3/  183] train: loss: 0.2108085
[Epoch 10; Iter    33/  183] train: loss: 0.2652071
[Epoch 10; Iter    63/  183] train: loss: 0.2815836
[Epoch 10; Iter    93/  183] train: loss: 0.2367148
[Epoch 10; Iter   123/  183] train: loss: 0.2327659
[Epoch 10; Iter   153/  183] train: loss: 0.2299040
[Epoch 10; Iter   183/  183] train: loss: 0.1364359
[Epoch 10] ogbg-moltox21: 0.687066 val loss: 0.338653
[Epoch 10] ogbg-moltox21: 0.692289 test loss: 0.341052
[Epoch 11; Iter    30/  183] train: loss: 0.1556828
[Epoch 11; Iter    60/  183] train: loss: 0.2232743
[Epoch 11; Iter    90/  183] train: loss: 0.1942154
[Epoch 11; Iter   120/  183] train: loss: 0.1728763
[Epoch 11; Iter   150/  183] train: loss: 0.1737695
[Epoch 11; Iter   180/  183] train: loss: 0.1986993
[Epoch 11] ogbg-moltox21: 0.686861 val loss: 0.344444
[Epoch 11] ogbg-moltox21: 0.702034 test loss: 0.339168
[Epoch 12; Iter    27/  183] train: loss: 0.2162856
[Epoch 12; Iter    57/  183] train: loss: 0.2212881
[Epoch 12; Iter    87/  183] train: loss: 0.2442267
[Epoch 12; Iter   117/  183] train: loss: 0.2196796
[Epoch 12; Iter   147/  183] train: loss: 0.1443923
[Epoch 12; Iter   177/  183] train: loss: 0.1972089
[Epoch 12] ogbg-moltox21: 0.681451 val loss: 0.609146
[Epoch 12] ogbg-moltox21: 0.702360 test loss: 0.630987
[Epoch 13; Iter    24/  183] train: loss: 0.2295446
[Epoch 13; Iter    54/  183] train: loss: 0.1773240
[Epoch 13; Iter    84/  183] train: loss: 0.1476281
[Epoch 13; Iter   114/  183] train: loss: 0.1514782
[Epoch 13; Iter   144/  183] train: loss: 0.2288585
[Epoch 13; Iter   174/  183] train: loss: 0.1079865
[Epoch 13] ogbg-moltox21: 0.721281 val loss: 0.448316
[Epoch 13] ogbg-moltox21: 0.725569 test loss: 0.502976
[Epoch 14; Iter    21/  183] train: loss: 0.1772803
[Epoch 14; Iter    51/  183] train: loss: 0.1808056
[ Using Seed :  6  ]
using device:  cuda:1
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.7/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.7_6_26-05_10-04-59
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.7.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.7
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.7
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:1
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.7
[Epoch 1; Iter    30/  183] train: loss: 0.6930105
[Epoch 1; Iter    60/  183] train: loss: 0.6925939
[Epoch 1; Iter    90/  183] train: loss: 0.6926879
[Epoch 1; Iter   120/  183] train: loss: 0.6926961
[Epoch 1; Iter   150/  183] train: loss: 0.6921043
[Epoch 1; Iter   180/  183] train: loss: 0.6930373
[Epoch 1] ogbg-moltox21: 0.532392 val loss: 0.694392
[Epoch 1] ogbg-moltox21: 0.503488 test loss: 0.694755
[Epoch 2; Iter    27/  183] train: loss: 0.6926634
[Epoch 2; Iter    57/  183] train: loss: 0.6911483
[Epoch 2; Iter    87/  183] train: loss: 0.6917193
[Epoch 2; Iter   117/  183] train: loss: 0.6919207
[Epoch 2; Iter   147/  183] train: loss: 0.6922578
[Epoch 2; Iter   177/  183] train: loss: 0.6913055
[Epoch 2] ogbg-moltox21: 0.536440 val loss: 0.692914
[Epoch 2] ogbg-moltox21: 0.509325 test loss: 0.693286
[Epoch 3; Iter    24/  183] train: loss: 0.6911997
[Epoch 3; Iter    54/  183] train: loss: 0.6915900
[Epoch 3; Iter    84/  183] train: loss: 0.6897926
[Epoch 3; Iter   114/  183] train: loss: 0.6905002
[Epoch 3; Iter   144/  183] train: loss: 0.6892679
[Epoch 3; Iter   174/  183] train: loss: 0.6889567
[Epoch 3] ogbg-moltox21: 0.540367 val loss: 0.691426
[Epoch 3] ogbg-moltox21: 0.514849 test loss: 0.691828
[Epoch 4; Iter    21/  183] train: loss: 0.6879158
[Epoch 4; Iter    51/  183] train: loss: 0.6886124
[Epoch 4; Iter    81/  183] train: loss: 0.6890834
[Epoch 4; Iter   111/  183] train: loss: 0.6875712
[Epoch 4; Iter   141/  183] train: loss: 0.6875635
[Epoch 4; Iter   171/  183] train: loss: 0.6817732
[Epoch 4] ogbg-moltox21: 0.628603 val loss: 0.718296
[Epoch 4] ogbg-moltox21: 0.620241 test loss: 0.719999
[Epoch 5; Iter    18/  183] train: loss: 0.6560866
[Epoch 5; Iter    48/  183] train: loss: 0.6163286
[Epoch 5; Iter    78/  183] train: loss: 0.6035376
[Epoch 5; Iter   108/  183] train: loss: 0.5543370
[Epoch 5; Iter   138/  183] train: loss: 0.4832341
[Epoch 5; Iter   168/  183] train: loss: 0.4174315
[Epoch 5] ogbg-moltox21: 0.692513 val loss: 0.512060
[Epoch 5] ogbg-moltox21: 0.683403 test loss: 0.512735
[Epoch 6; Iter    15/  183] train: loss: 0.3967792
[Epoch 6; Iter    45/  183] train: loss: 0.3310176
[Epoch 6; Iter    75/  183] train: loss: 0.2635969
[Epoch 6; Iter   105/  183] train: loss: 0.2448012
[Epoch 6; Iter   135/  183] train: loss: 0.2023622
[Epoch 6; Iter   165/  183] train: loss: 0.2167948
[Epoch 6] ogbg-moltox21: 0.685901 val loss: 0.290678
[Epoch 6] ogbg-moltox21: 0.693353 test loss: 0.286355
[Epoch 7; Iter    12/  183] train: loss: 0.2504337
[Epoch 7; Iter    42/  183] train: loss: 0.1594229
[Epoch 7; Iter    72/  183] train: loss: 0.1604160
[Epoch 7; Iter   102/  183] train: loss: 0.1852090
[Epoch 7; Iter   132/  183] train: loss: 0.1467859
[Epoch 7; Iter   162/  183] train: loss: 0.1514842
[Epoch 7] ogbg-moltox21: 0.704125 val loss: 0.309137
[Epoch 7] ogbg-moltox21: 0.704823 test loss: 0.307960
[Epoch 8; Iter     9/  183] train: loss: 0.2139989
[Epoch 8; Iter    39/  183] train: loss: 0.2702753
[Epoch 8; Iter    69/  183] train: loss: 0.2209274
[Epoch 8; Iter    99/  183] train: loss: 0.1485839
[Epoch 8; Iter   129/  183] train: loss: 0.1442713
[Epoch 8; Iter   159/  183] train: loss: 0.2557306
[Epoch 8] ogbg-moltox21: 0.696066 val loss: 0.293398
[Epoch 8] ogbg-moltox21: 0.704880 test loss: 0.295392
[Epoch 9; Iter     6/  183] train: loss: 0.2870480
[Epoch 9; Iter    36/  183] train: loss: 0.2068470
[Epoch 9; Iter    66/  183] train: loss: 0.2236630
[Epoch 9; Iter    96/  183] train: loss: 0.1103519
[Epoch 9; Iter   126/  183] train: loss: 0.2766078
[Epoch 9; Iter   156/  183] train: loss: 0.1926551
[Epoch 9] ogbg-moltox21: 0.668472 val loss: 1.042167
[Epoch 9] ogbg-moltox21: 0.658199 test loss: 1.446025
[Epoch 10; Iter     3/  183] train: loss: 0.1635855
[Epoch 10; Iter    33/  183] train: loss: 0.1417915
[Epoch 10; Iter    63/  183] train: loss: 0.1833213
[Epoch 10; Iter    93/  183] train: loss: 0.1094367
[Epoch 10; Iter   123/  183] train: loss: 0.2091371
[Epoch 10; Iter   153/  183] train: loss: 0.1685090
[Epoch 10; Iter   183/  183] train: loss: 0.1211836
[Epoch 10] ogbg-moltox21: 0.719557 val loss: 0.374324
[Epoch 10] ogbg-moltox21: 0.721216 test loss: 0.420981
[Epoch 11; Iter    30/  183] train: loss: 0.1430576
[Epoch 11; Iter    60/  183] train: loss: 0.2616311
[Epoch 11; Iter    90/  183] train: loss: 0.1707962
[Epoch 11; Iter   120/  183] train: loss: 0.1603221
[Epoch 11; Iter   150/  183] train: loss: 0.1760877
[Epoch 11; Iter   180/  183] train: loss: 0.2066001
[Epoch 11] ogbg-moltox21: 0.692480 val loss: 0.357730
[Epoch 11] ogbg-moltox21: 0.700043 test loss: 0.338616
[Epoch 12; Iter    27/  183] train: loss: 0.1973225
[Epoch 12; Iter    57/  183] train: loss: 0.2170519
[Epoch 12; Iter    87/  183] train: loss: 0.1849882
[Epoch 12; Iter   117/  183] train: loss: 0.1571466
[Epoch 12; Iter   147/  183] train: loss: 0.1877821
[Epoch 12; Iter   177/  183] train: loss: 0.1775066
[Epoch 12] ogbg-moltox21: 0.707668 val loss: 0.307963
[Epoch 12] ogbg-moltox21: 0.707567 test loss: 0.311808
[Epoch 13; Iter    24/  183] train: loss: 0.1967410
[Epoch 13; Iter    54/  183] train: loss: 0.1830759
[Epoch 13; Iter    84/  183] train: loss: 0.2105001
[Epoch 13; Iter   114/  183] train: loss: 0.2042267
[Epoch 13; Iter   144/  183] train: loss: 0.1368909
[Epoch 13; Iter   174/  183] train: loss: 0.1924834
[Epoch 13] ogbg-moltox21: 0.731787 val loss: 0.461045
[Epoch 13] ogbg-moltox21: 0.738986 test loss: 0.609844
[Epoch 14; Iter    21/  183] train: loss: 0.0916280
[Epoch 14; Iter    51/  183] train: loss: 0.1928434
[ Using Seed :  4  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.6/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.6_4_26-05_10-05-00
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.6
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 4
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6928430
[Epoch 1; Iter    60/  157] train: loss: 0.6928548
[Epoch 1; Iter    90/  157] train: loss: 0.6924021
[Epoch 1; Iter   120/  157] train: loss: 0.6929682
[Epoch 1; Iter   150/  157] train: loss: 0.6933116
[Epoch 1] ogbg-moltox21: 0.480853 val loss: 0.692277
[Epoch 1] ogbg-moltox21: 0.492292 test loss: 0.692057
[Epoch 2; Iter    23/  157] train: loss: 0.6926363
[Epoch 2; Iter    53/  157] train: loss: 0.6915945
[Epoch 2; Iter    83/  157] train: loss: 0.6918229
[Epoch 2; Iter   113/  157] train: loss: 0.6915249
[Epoch 2; Iter   143/  157] train: loss: 0.6916851
[Epoch 2] ogbg-moltox21: 0.482136 val loss: 0.691738
[Epoch 2] ogbg-moltox21: 0.492897 test loss: 0.691702
[Epoch 3; Iter    16/  157] train: loss: 0.6915507
[Epoch 3; Iter    46/  157] train: loss: 0.6920668
[Epoch 3; Iter    76/  157] train: loss: 0.6910974
[Epoch 3; Iter   106/  157] train: loss: 0.6904048
[Epoch 3; Iter   136/  157] train: loss: 0.6904013
[Epoch 3] ogbg-moltox21: 0.482928 val loss: 0.690098
[Epoch 3] ogbg-moltox21: 0.495512 test loss: 0.689959
[Epoch 4; Iter     9/  157] train: loss: 0.6896379
[Epoch 4; Iter    39/  157] train: loss: 0.6895530
[Epoch 4; Iter    69/  157] train: loss: 0.6891848
[Epoch 4; Iter    99/  157] train: loss: 0.6888499
[Epoch 4; Iter   129/  157] train: loss: 0.6884327
[Epoch 4] ogbg-moltox21: 0.483792 val loss: 0.688573
[Epoch 4] ogbg-moltox21: 0.496129 test loss: 0.688632
[Epoch 5; Iter     2/  157] train: loss: 0.6877643
[Epoch 5; Iter    32/  157] train: loss: 0.6881082
[Epoch 5; Iter    62/  157] train: loss: 0.6865726
[Epoch 5; Iter    92/  157] train: loss: 0.6816539
[Epoch 5; Iter   122/  157] train: loss: 0.6619361
[Epoch 5; Iter   152/  157] train: loss: 0.6044933
[Epoch 5] ogbg-moltox21: 0.652247 val loss: 0.835865
[Epoch 5] ogbg-moltox21: 0.628441 test loss: 0.906048
[Epoch 6; Iter    25/  157] train: loss: 0.5695015
[Epoch 6; Iter    55/  157] train: loss: 0.5261365
[Epoch 6; Iter    85/  157] train: loss: 0.4596088
[Epoch 6; Iter   115/  157] train: loss: 0.4081021
[Epoch 6; Iter   145/  157] train: loss: 0.3460399
[Epoch 6] ogbg-moltox21: 0.662117 val loss: 0.620448
[Epoch 6] ogbg-moltox21: 0.651485 test loss: 0.720287
[Epoch 7; Iter    18/  157] train: loss: 0.3356931
[Epoch 7; Iter    48/  157] train: loss: 0.2752300
[Epoch 7; Iter    78/  157] train: loss: 0.2438907
[Epoch 7; Iter   108/  157] train: loss: 0.1995567
[Epoch 7; Iter   138/  157] train: loss: 0.1829931
[Epoch 7] ogbg-moltox21: 0.713412 val loss: 0.314178
[Epoch 7] ogbg-moltox21: 0.719741 test loss: 0.328508
[Epoch 8; Iter    11/  157] train: loss: 0.2361582
[Epoch 8; Iter    41/  157] train: loss: 0.2051497
[Epoch 8; Iter    71/  157] train: loss: 0.1720196
[Epoch 8; Iter   101/  157] train: loss: 0.1597801
[Epoch 8; Iter   131/  157] train: loss: 0.1258861
[Epoch 8] ogbg-moltox21: 0.706201 val loss: 0.403371
[Epoch 8] ogbg-moltox21: 0.705118 test loss: 0.460678
[Epoch 9; Iter     4/  157] train: loss: 0.2205112
[Epoch 9; Iter    34/  157] train: loss: 0.1855584
[Epoch 9; Iter    64/  157] train: loss: 0.2286197
[Epoch 9; Iter    94/  157] train: loss: 0.1666368
[Epoch 9; Iter   124/  157] train: loss: 0.1988010
[Epoch 9; Iter   154/  157] train: loss: 0.1685696
[Epoch 9] ogbg-moltox21: 0.730691 val loss: 0.586409
[Epoch 9] ogbg-moltox21: 0.713562 test loss: 0.762430
[Epoch 10; Iter    27/  157] train: loss: 0.1508471
[Epoch 10; Iter    57/  157] train: loss: 0.1755683
[Epoch 10; Iter    87/  157] train: loss: 0.1371706
[Epoch 10; Iter   117/  157] train: loss: 0.2324457
[Epoch 10; Iter   147/  157] train: loss: 0.2943481
[Epoch 10] ogbg-moltox21: 0.678179 val loss: 0.762890
[Epoch 10] ogbg-moltox21: 0.672783 test loss: 1.132925
[Epoch 11; Iter    20/  157] train: loss: 0.1939379
[Epoch 11; Iter    50/  157] train: loss: 0.1955096
[Epoch 11; Iter    80/  157] train: loss: 0.2119143
[Epoch 11; Iter   110/  157] train: loss: 0.1882197
[Epoch 11; Iter   140/  157] train: loss: 0.1378274
[Epoch 11] ogbg-moltox21: 0.699162 val loss: 0.334306
[Epoch 11] ogbg-moltox21: 0.677471 test loss: 0.365262
[Epoch 12; Iter    13/  157] train: loss: 0.2213931
[Epoch 12; Iter    43/  157] train: loss: 0.1864568
[Epoch 12; Iter    73/  157] train: loss: 0.1667020
[Epoch 12; Iter   103/  157] train: loss: 0.1071183
[Epoch 12; Iter   133/  157] train: loss: 0.2806037
[Epoch 12] ogbg-moltox21: 0.700324 val loss: 0.586494
[Epoch 12] ogbg-moltox21: 0.705668 test loss: 0.632990
[Epoch 13; Iter     6/  157] train: loss: 0.1746801
[Epoch 13; Iter    36/  157] train: loss: 0.2818992
[Epoch 13; Iter    66/  157] train: loss: 0.1508105
[Epoch 13; Iter    96/  157] train: loss: 0.1659027
[Epoch 13; Iter   126/  157] train: loss: 0.1336429
[Epoch 13; Iter   156/  157] train: loss: 0.2848176
[Epoch 13] ogbg-moltox21: 0.712116 val loss: 0.394511
[Epoch 13] ogbg-moltox21: 0.686639 test loss: 0.502970
[Epoch 14; Iter    29/  157] train: loss: 0.2147909
[Epoch 14; Iter    59/  157] train: loss: 0.1095249
[Epoch 14; Iter    89/  157] train: loss: 0.2019200
[Epoch 14; Iter   119/  157] train: loss: 0.2217368
[Epoch 14; Iter   149/  157] train: loss: 0.1865522
[Epoch 14] ogbg-moltox21: 0.746940 val loss: 0.485611
[Epoch 14] ogbg-moltox21: 0.721080 test loss: 0.571106
[Epoch 15; Iter    22/  157] train: loss: 0.1310480
[Epoch 15; Iter    52/  157] train: loss: 0.1990227
[Epoch 15; Iter    82/  157] train: loss: 0.1476140
[Epoch 15; Iter   112/  157] train: loss: 0.1320519
[Epoch 15; Iter   142/  157] train: loss: 0.1485017
[Epoch 15] ogbg-moltox21: 0.753306 val loss: 0.498862
[ Using Seed :  5  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.6/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.6_5_26-05_10-05-00
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.6
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 5
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6927258
[Epoch 1; Iter    60/  157] train: loss: 0.6935993
[Epoch 1; Iter    90/  157] train: loss: 0.6926110
[Epoch 1; Iter   120/  157] train: loss: 0.6934284
[Epoch 1; Iter   150/  157] train: loss: 0.6925095
[Epoch 1] ogbg-moltox21: 0.500236 val loss: 0.691673
[Epoch 1] ogbg-moltox21: 0.502625 test loss: 0.690916
[Epoch 2; Iter    23/  157] train: loss: 0.6931972
[Epoch 2; Iter    53/  157] train: loss: 0.6934764
[Epoch 2; Iter    83/  157] train: loss: 0.6921703
[Epoch 2; Iter   113/  157] train: loss: 0.6915453
[Epoch 2; Iter   143/  157] train: loss: 0.6913396
[Epoch 2] ogbg-moltox21: 0.498415 val loss: 0.691263
[Epoch 2] ogbg-moltox21: 0.500354 test loss: 0.690621
[Epoch 3; Iter    16/  157] train: loss: 0.6913747
[Epoch 3; Iter    46/  157] train: loss: 0.6908430
[Epoch 3; Iter    76/  157] train: loss: 0.6907727
[Epoch 3; Iter   106/  157] train: loss: 0.6910582
[Epoch 3; Iter   136/  157] train: loss: 0.6908777
[Epoch 3] ogbg-moltox21: 0.498051 val loss: 0.689967
[Epoch 3] ogbg-moltox21: 0.500047 test loss: 0.689268
[Epoch 4; Iter     9/  157] train: loss: 0.6897256
[Epoch 4; Iter    39/  157] train: loss: 0.6891270
[Epoch 4; Iter    69/  157] train: loss: 0.6883003
[Epoch 4; Iter    99/  157] train: loss: 0.6883266
[Epoch 4; Iter   129/  157] train: loss: 0.6882930
[Epoch 4] ogbg-moltox21: 0.504253 val loss: 0.687977
[Epoch 4] ogbg-moltox21: 0.506811 test loss: 0.687434
[Epoch 5; Iter     2/  157] train: loss: 0.6868629
[Epoch 5; Iter    32/  157] train: loss: 0.6864952
[Epoch 5; Iter    62/  157] train: loss: 0.6856943
[Epoch 5; Iter    92/  157] train: loss: 0.6809827
[Epoch 5; Iter   122/  157] train: loss: 0.6544695
[Epoch 5; Iter   152/  157] train: loss: 0.6233074
[Epoch 5] ogbg-moltox21: 0.660626 val loss: 0.765364
[Epoch 5] ogbg-moltox21: 0.632703 test loss: 0.815407
[Epoch 6; Iter    25/  157] train: loss: 0.5664833
[Epoch 6; Iter    55/  157] train: loss: 0.5096132
[Epoch 6; Iter    85/  157] train: loss: 0.4640965
[Epoch 6; Iter   115/  157] train: loss: 0.3990959
[Epoch 6; Iter   145/  157] train: loss: 0.3449055
[Epoch 6] ogbg-moltox21: 0.676541 val loss: 0.463215
[Epoch 6] ogbg-moltox21: 0.664264 test loss: 0.502949
[Epoch 7; Iter    18/  157] train: loss: 0.3080463
[Epoch 7; Iter    48/  157] train: loss: 0.2887072
[Epoch 7; Iter    78/  157] train: loss: 0.2893829
[Epoch 7; Iter   108/  157] train: loss: 0.2711475
[Epoch 7; Iter   138/  157] train: loss: 0.1945002
[Epoch 7] ogbg-moltox21: 0.670170 val loss: 0.398425
[Epoch 7] ogbg-moltox21: 0.654376 test loss: 0.445549
[Epoch 8; Iter    11/  157] train: loss: 0.2217223
[Epoch 8; Iter    41/  157] train: loss: 0.1393265
[Epoch 8; Iter    71/  157] train: loss: 0.1774477
[Epoch 8; Iter   101/  157] train: loss: 0.3274204
[Epoch 8; Iter   131/  157] train: loss: 0.2372295
[Epoch 8] ogbg-moltox21: 0.689247 val loss: 0.356868
[Epoch 8] ogbg-moltox21: 0.679774 test loss: 0.408300
[Epoch 9; Iter     4/  157] train: loss: 0.1822500
[Epoch 9; Iter    34/  157] train: loss: 0.2227053
[Epoch 9; Iter    64/  157] train: loss: 0.1879701
[Epoch 9; Iter    94/  157] train: loss: 0.2580422
[Epoch 9; Iter   124/  157] train: loss: 0.1680137
[Epoch 9; Iter   154/  157] train: loss: 0.1698944
[Epoch 9] ogbg-moltox21: 0.716873 val loss: 0.306066
[Epoch 9] ogbg-moltox21: 0.706205 test loss: 0.326486
[Epoch 10; Iter    27/  157] train: loss: 0.0955502
[Epoch 10; Iter    57/  157] train: loss: 0.1380439
[Epoch 10; Iter    87/  157] train: loss: 0.1487218
[Epoch 10; Iter   117/  157] train: loss: 0.1427702
[Epoch 10; Iter   147/  157] train: loss: 0.1454153
[Epoch 10] ogbg-moltox21: 0.737190 val loss: 0.358558
[Epoch 10] ogbg-moltox21: 0.718916 test loss: 0.434979
[Epoch 11; Iter    20/  157] train: loss: 0.1094173
[Epoch 11; Iter    50/  157] train: loss: 0.1674482
[Epoch 11; Iter    80/  157] train: loss: 0.2078187
[Epoch 11; Iter   110/  157] train: loss: 0.1717256
[Epoch 11; Iter   140/  157] train: loss: 0.3070317
[Epoch 11] ogbg-moltox21: 0.657163 val loss: 0.410169
[Epoch 11] ogbg-moltox21: 0.635342 test loss: 0.842986
[Epoch 12; Iter    13/  157] train: loss: 0.2443209
[Epoch 12; Iter    43/  157] train: loss: 0.2435454
[Epoch 12; Iter    73/  157] train: loss: 0.1654940
[Epoch 12; Iter   103/  157] train: loss: 0.1665082
[Epoch 12; Iter   133/  157] train: loss: 0.1473999
[Epoch 12] ogbg-moltox21: 0.717502 val loss: 0.357200
[Epoch 12] ogbg-moltox21: 0.688236 test loss: 0.433750
[Epoch 13; Iter     6/  157] train: loss: 0.1735308
[Epoch 13; Iter    36/  157] train: loss: 0.2447665
[Epoch 13; Iter    66/  157] train: loss: 0.1893478
[Epoch 13; Iter    96/  157] train: loss: 0.2001599
[Epoch 13; Iter   126/  157] train: loss: 0.3018044
[Epoch 13; Iter   156/  157] train: loss: 0.1575618
[Epoch 13] ogbg-moltox21: 0.692782 val loss: 0.465718
[Epoch 13] ogbg-moltox21: 0.683149 test loss: 0.527279
[Epoch 14; Iter    29/  157] train: loss: 0.2117667
[Epoch 14; Iter    59/  157] train: loss: 0.1235380
[Epoch 14; Iter    89/  157] train: loss: 0.1143982
[Epoch 14; Iter   119/  157] train: loss: 0.1904052
[Epoch 14; Iter   149/  157] train: loss: 0.1485279
[Epoch 14] ogbg-moltox21: 0.725063 val loss: 0.322780
[Epoch 14] ogbg-moltox21: 0.716196 test loss: 0.349985
[Epoch 15; Iter    22/  157] train: loss: 0.1425514
[Epoch 15; Iter    52/  157] train: loss: 0.1187379
[Epoch 15; Iter    82/  157] train: loss: 0.1653292
[Epoch 15; Iter   112/  157] train: loss: 0.1239660
[Epoch 15; Iter   142/  157] train: loss: 0.3156421
[Epoch 15] ogbg-moltox21: 0.740895 val loss: 0.341206
[ Using Seed :  6  ]
using device:  cuda:0
Log directory:  runs/split/GraphCL/tox21/scaff/train_prop=0.6/PNA_ogbg-moltox21_GraphCL_tox21_scaff=0.6_6_26-05_10-05-00
config: <_io.TextIOWrapper name='configs_split_experiments/GraphCL/tox21/scaff/train_prop=0.6.yml' mode='r' encoding='UTF-8'>
experiment_name: GraphCL_tox21_scaff=0.6
logdir: runs/split/GraphCL/tox21/scaff/train_prop=0.6
num_epochs: 1000
batch_size: 30
patience: 60
minimum_epochs: 120
dataset: ogbg-moltox21
num_train: -1
seed: 6
num_val: None
multiple_seeds: [4, 5, 6]
seed_data: 123
loss_func: OGBNanLabelBCEWithLogitsLoss
critic_loss: MSELoss
optimizer: Adam
optimizer_params/lr: 0.001
lr_scheduler: WarmUpWrapper
lr_scheduler_params/warmup_steps: [700, 700, 350]
lr_scheduler_params/interpolation: linear
lr_scheduler_params/wrapped_scheduler: ReduceLROnPlateau
lr_scheduler_params/factor: 0.5
lr_scheduler_params/patience: 25
lr_scheduler_params/min_lr: 1e-06
lr_scheduler_params/mode: min
lr_scheduler_params/verbose: True
scheduler_step_per_batch: False
log_iterations: 30
expensive_log_iterations: 100
eval_per_epochs: 0
linear_probing_samples: 500
num_conformers: 3
metrics: ['prcauc', 'rocauc']
main_metric: ogbg-moltox21
main_metric_goal: max
val_per_batch: False
tensorboard_functions: []
checkpoint: None
pretrain_checkpoint: runs/PNA_graphcl_drugs_smaller/best_checkpoint.pt
transfer_layers: ['gnn.']
frozen_layers: []
exclude_from_transfer: []
transferred_lr: None
num_epochs_local_only: 1
required_data: ['dgl_graph', 'targets']
collate_function: graph_collate
use_e_features: True
targets: []
device: cuda:0
dist_embedding: False
num_radial: 6
models_to_save: []
model_type: PNA
model_parameters/target_dim: 12
model_parameters/hidden_dim: 50
model_parameters/mid_batch_norm: True
model_parameters/last_batch_norm: True
model_parameters/readout_batchnorm: True
model_parameters/batch_norm_momentum: 0.1
model_parameters/readout_hidden_dim: 50
model_parameters/readout_layers: 2
model_parameters/dropout: 0.0
model_parameters/propagation_depth: 3
model_parameters/aggregators: ['mean', 'max', 'min', 'std']
model_parameters/scalers: ['identity', 'amplification', 'attenuation']
model_parameters/readout_aggregators: ['min', 'max', 'mean', 'sum']
model_parameters/pretrans_layers: 2
model_parameters/posttrans_layers: 1
model_parameters/residual: True
model3d_type: None
model3d_parameters: None
critic_type: None
critic_parameters: None
trainer: contrastive
train_sampler: None
eval_on_test: True
force_random_split: False
reuse_pre_train_data: False
transfer_3d: False
noise_level: 0.0
dynamic_noise: True
train_prop: 0.6
[Epoch 1; Iter    30/  157] train: loss: 0.6928593
[Epoch 1; Iter    60/  157] train: loss: 0.6928688
[Epoch 1; Iter    90/  157] train: loss: 0.6926201
[Epoch 1; Iter   120/  157] train: loss: 0.6929472
[Epoch 1; Iter   150/  157] train: loss: 0.6932623
[Epoch 1] ogbg-moltox21: 0.513154 val loss: 0.694324
[Epoch 1] ogbg-moltox21: 0.509023 test loss: 0.694554
[Epoch 2; Iter    23/  157] train: loss: 0.6926489
[Epoch 2; Iter    53/  157] train: loss: 0.6916127
[Epoch 2; Iter    83/  157] train: loss: 0.6920572
[Epoch 2; Iter   113/  157] train: loss: 0.6922416
[Epoch 2; Iter   143/  157] train: loss: 0.6911851
[Epoch 2] ogbg-moltox21: 0.515567 val loss: 0.693734
[Epoch 2] ogbg-moltox21: 0.510968 test loss: 0.694051
[Epoch 3; Iter    16/  157] train: loss: 0.6911917
[Epoch 3; Iter    46/  157] train: loss: 0.6915451
[Epoch 3; Iter    76/  157] train: loss: 0.6914856
[Epoch 3; Iter   106/  157] train: loss: 0.6907485
[Epoch 3; Iter   136/  157] train: loss: 0.6905252
[Epoch 3] ogbg-moltox21: 0.520429 val loss: 0.692376
[Epoch 3] ogbg-moltox21: 0.516640 test loss: 0.692696
[Epoch 4; Iter     9/  157] train: loss: 0.6898187
[Epoch 4; Iter    39/  157] train: loss: 0.6895611
[Epoch 4; Iter    69/  157] train: loss: 0.6883878
[Epoch 4; Iter    99/  157] train: loss: 0.6889939
[Epoch 4; Iter   129/  157] train: loss: 0.6876505
[Epoch 4] ogbg-moltox21: 0.528056 val loss: 0.690740
[Epoch 4] ogbg-moltox21: 0.524039 test loss: 0.691306
[Epoch 5; Iter     2/  157] train: loss: 0.6870012
[Epoch 5; Iter    32/  157] train: loss: 0.6870107
[Epoch 5; Iter    62/  157] train: loss: 0.6867996
[Epoch 5; Iter    92/  157] train: loss: 0.6810789
[Epoch 5; Iter   122/  157] train: loss: 0.6647608
[Epoch 5; Iter   152/  157] train: loss: 0.6134236
[Epoch 5] ogbg-moltox21: 0.664685 val loss: 0.840746
[Epoch 5] ogbg-moltox21: 0.643482 test loss: 0.922967
[Epoch 6; Iter    25/  157] train: loss: 0.5793952
[Epoch 6; Iter    55/  157] train: loss: 0.5555711
[Epoch 6; Iter    85/  157] train: loss: 0.4771757
[Epoch 6; Iter   115/  157] train: loss: 0.4303185
[Epoch 6; Iter   145/  157] train: loss: 0.3509886
[Epoch 6] ogbg-moltox21: 0.645365 val loss: 0.572455
[Epoch 6] ogbg-moltox21: 0.628174 test loss: 0.660089
[Epoch 7; Iter    18/  157] train: loss: 0.2990667
[Epoch 7; Iter    48/  157] train: loss: 0.2545654
[Epoch 7; Iter    78/  157] train: loss: 0.2215379
[Epoch 7; Iter   108/  157] train: loss: 0.2330438
[Epoch 7; Iter   138/  157] train: loss: 0.1903914
[Epoch 7] ogbg-moltox21: 0.689770 val loss: 0.417366
[Epoch 7] ogbg-moltox21: 0.680693 test loss: 0.467094
[Epoch 8; Iter    11/  157] train: loss: 0.1759014
[Epoch 8; Iter    41/  157] train: loss: 0.1462580
[Epoch 8; Iter    71/  157] train: loss: 0.2474151
[Epoch 8; Iter   101/  157] train: loss: 0.1692497
[Epoch 8; Iter   131/  157] train: loss: 0.1688503
[Epoch 8] ogbg-moltox21: 0.669915 val loss: 0.440490
[Epoch 8] ogbg-moltox21: 0.666709 test loss: 0.504062
[Epoch 9; Iter     4/  157] train: loss: 0.1365913
[Epoch 9; Iter    34/  157] train: loss: 0.1975129
[Epoch 9; Iter    64/  157] train: loss: 0.1802022
[Epoch 9; Iter    94/  157] train: loss: 0.2338585
[Epoch 9; Iter   124/  157] train: loss: 0.2441023
[Epoch 9; Iter   154/  157] train: loss: 0.2073180
[Epoch 9] ogbg-moltox21: 0.680457 val loss: 0.413176
[Epoch 9] ogbg-moltox21: 0.674706 test loss: 0.513306
[Epoch 10; Iter    27/  157] train: loss: 0.2260129
[Epoch 10; Iter    57/  157] train: loss: 0.1990182
[Epoch 10; Iter    87/  157] train: loss: 0.1197291
[Epoch 10; Iter   117/  157] train: loss: 0.1476569
[Epoch 10; Iter   147/  157] train: loss: 0.1587970
[Epoch 10] ogbg-moltox21: 0.671768 val loss: 0.364648
[Epoch 10] ogbg-moltox21: 0.678065 test loss: 0.423132
[Epoch 11; Iter    20/  157] train: loss: 0.1496610
[Epoch 11; Iter    50/  157] train: loss: 0.1195850
[Epoch 11; Iter    80/  157] train: loss: 0.1544841
[Epoch 11; Iter   110/  157] train: loss: 0.2124379
[Epoch 11; Iter   140/  157] train: loss: 0.2237995
[Epoch 11] ogbg-moltox21: 0.716430 val loss: 0.506322
[Epoch 11] ogbg-moltox21: 0.704392 test loss: 0.554672
[Epoch 12; Iter    13/  157] train: loss: 0.2359117
[Epoch 12; Iter    43/  157] train: loss: 0.1522515
[Epoch 12; Iter    73/  157] train: loss: 0.2405458
[Epoch 12; Iter   103/  157] train: loss: 0.1998267
[Epoch 12; Iter   133/  157] train: loss: 0.1749656
[Epoch 12] ogbg-moltox21: 0.707141 val loss: 0.410350
[Epoch 12] ogbg-moltox21: 0.684004 test loss: 0.493526
[Epoch 13; Iter     6/  157] train: loss: 0.1367736
[Epoch 13; Iter    36/  157] train: loss: 0.1326092
[Epoch 13; Iter    66/  157] train: loss: 0.1478510
[Epoch 13; Iter    96/  157] train: loss: 0.1421776
[Epoch 13; Iter   126/  157] train: loss: 0.1788007
[Epoch 13; Iter   156/  157] train: loss: 0.2563906
[Epoch 13] ogbg-moltox21: 0.750498 val loss: 0.313285
[Epoch 13] ogbg-moltox21: 0.749930 test loss: 0.348898
[Epoch 14; Iter    29/  157] train: loss: 0.1510167
[Epoch 14; Iter    59/  157] train: loss: 0.2230027
[Epoch 14; Iter    89/  157] train: loss: 0.1705275
[Epoch 14; Iter   119/  157] train: loss: 0.1015994
[Epoch 14; Iter   149/  157] train: loss: 0.1208206
[Epoch 14] ogbg-moltox21: 0.762264 val loss: 0.331695
[Epoch 14] ogbg-moltox21: 0.744573 test loss: 0.383670
[Epoch 15; Iter    22/  157] train: loss: 0.1044661
[Epoch 15; Iter    52/  157] train: loss: 0.1196057
[Epoch 15; Iter    82/  157] train: loss: 0.1219756
[Epoch 15; Iter   112/  157] train: loss: 0.1626022
[Epoch 15; Iter   142/  157] train: loss: 0.1566177
[Epoch 15] ogbg-moltox21: 0.754520 val loss: 0.380394
[Epoch 13; Iter    12/  209] train: loss: 0.1781314
[Epoch 13; Iter    42/  209] train: loss: 0.1568458
[Epoch 13; Iter    72/  209] train: loss: 0.2725166
[Epoch 13; Iter   102/  209] train: loss: 0.1565006
[Epoch 13; Iter   132/  209] train: loss: 0.2724932
[Epoch 13; Iter   162/  209] train: loss: 0.2579219
[Epoch 13; Iter   192/  209] train: loss: 0.2103973
[Epoch 13] ogbg-moltox21: 0.712558 val loss: 0.280407
[Epoch 13] ogbg-moltox21: 0.694653 test loss: 0.283176
[Epoch 14; Iter    13/  209] train: loss: 0.2255031
[Epoch 14; Iter    43/  209] train: loss: 0.2135728
[Epoch 14; Iter    73/  209] train: loss: 0.1848388
[Epoch 14; Iter   103/  209] train: loss: 0.1915527
[Epoch 14; Iter   133/  209] train: loss: 0.2836677
[Epoch 14; Iter   163/  209] train: loss: 0.2068438
[Epoch 14; Iter   193/  209] train: loss: 0.2140688
[Epoch 14] ogbg-moltox21: 0.772646 val loss: 0.250047
[Epoch 14] ogbg-moltox21: 0.726323 test loss: 0.262708
[Epoch 15; Iter    14/  209] train: loss: 0.1617270
[Epoch 15; Iter    44/  209] train: loss: 0.2575290
[Epoch 15; Iter    74/  209] train: loss: 0.1698848
[Epoch 15; Iter   104/  209] train: loss: 0.2246681
[Epoch 15; Iter   134/  209] train: loss: 0.1605118
[Epoch 15; Iter   164/  209] train: loss: 0.1699156
[Epoch 15; Iter   194/  209] train: loss: 0.2418436
[Epoch 15] ogbg-moltox21: 0.777147 val loss: 0.253775
[Epoch 15] ogbg-moltox21: 0.728171 test loss: 0.269917
[Epoch 16; Iter    15/  209] train: loss: 0.2011107
[Epoch 16; Iter    45/  209] train: loss: 0.1578066
[Epoch 16; Iter    75/  209] train: loss: 0.2192963
[Epoch 16; Iter   105/  209] train: loss: 0.1751503
[Epoch 16; Iter   135/  209] train: loss: 0.1919432
[Epoch 16; Iter   165/  209] train: loss: 0.2271641
[Epoch 16; Iter   195/  209] train: loss: 0.2019295
[Epoch 16] ogbg-moltox21: 0.775025 val loss: 0.253139
[Epoch 16] ogbg-moltox21: 0.744427 test loss: 0.282687
[Epoch 17; Iter    16/  209] train: loss: 0.1684951
[Epoch 17; Iter    46/  209] train: loss: 0.1334866
[Epoch 17; Iter    76/  209] train: loss: 0.1354406
[Epoch 17; Iter   106/  209] train: loss: 0.2074128
[Epoch 17; Iter   136/  209] train: loss: 0.1501041
[Epoch 17; Iter   166/  209] train: loss: 0.1684007
[Epoch 17; Iter   196/  209] train: loss: 0.1348186
[Epoch 17] ogbg-moltox21: 0.788268 val loss: 0.315147
[Epoch 17] ogbg-moltox21: 0.739815 test loss: 0.266444
[Epoch 18; Iter    17/  209] train: loss: 0.1151810
[Epoch 18; Iter    47/  209] train: loss: 0.1980544
[Epoch 18; Iter    77/  209] train: loss: 0.2532641
[Epoch 18; Iter   107/  209] train: loss: 0.2744066
[Epoch 18; Iter   137/  209] train: loss: 0.1761190
[Epoch 18; Iter   167/  209] train: loss: 0.1592117
[Epoch 18; Iter   197/  209] train: loss: 0.1229423
[Epoch 18] ogbg-moltox21: 0.770470 val loss: 0.302130
[Epoch 18] ogbg-moltox21: 0.746197 test loss: 0.262546
[Epoch 19; Iter    18/  209] train: loss: 0.3043181
[Epoch 19; Iter    48/  209] train: loss: 0.1662158
[Epoch 19; Iter    78/  209] train: loss: 0.1444727
[Epoch 19; Iter   108/  209] train: loss: 0.1534289
[Epoch 19; Iter   138/  209] train: loss: 0.1189674
[Epoch 19; Iter   168/  209] train: loss: 0.1885221
[Epoch 19; Iter   198/  209] train: loss: 0.2785493
[Epoch 19] ogbg-moltox21: 0.790321 val loss: 0.246091
[Epoch 19] ogbg-moltox21: 0.752551 test loss: 0.261039
[Epoch 20; Iter    19/  209] train: loss: 0.2096740
[Epoch 20; Iter    49/  209] train: loss: 0.2506377
[Epoch 20; Iter    79/  209] train: loss: 0.0947395
[Epoch 20; Iter   109/  209] train: loss: 0.1265204
[Epoch 20; Iter   139/  209] train: loss: 0.2459880
[Epoch 20; Iter   169/  209] train: loss: 0.2301650
[Epoch 20; Iter   199/  209] train: loss: 0.1293201
[Epoch 20] ogbg-moltox21: 0.783261 val loss: 0.242862
[Epoch 20] ogbg-moltox21: 0.734103 test loss: 0.266898
[Epoch 21; Iter    20/  209] train: loss: 0.1520030
[Epoch 21; Iter    50/  209] train: loss: 0.2260173
[Epoch 21; Iter    80/  209] train: loss: 0.1754070
[Epoch 21; Iter   110/  209] train: loss: 0.0944986
[Epoch 21; Iter   140/  209] train: loss: 0.2490490
[Epoch 21; Iter   170/  209] train: loss: 0.3389242
[Epoch 21; Iter   200/  209] train: loss: 0.1732703
[Epoch 21] ogbg-moltox21: 0.762740 val loss: 0.253475
[Epoch 21] ogbg-moltox21: 0.733123 test loss: 0.275892
[Epoch 22; Iter    21/  209] train: loss: 0.1536474
[Epoch 22; Iter    51/  209] train: loss: 0.0847549
[Epoch 22; Iter    81/  209] train: loss: 0.1274685
[Epoch 22; Iter   111/  209] train: loss: 0.1239204
[Epoch 22; Iter   141/  209] train: loss: 0.1738831
[Epoch 22; Iter   171/  209] train: loss: 0.1070210
[Epoch 22; Iter   201/  209] train: loss: 0.1089680
[Epoch 22] ogbg-moltox21: 0.800989 val loss: 0.284319
[Epoch 22] ogbg-moltox21: 0.743770 test loss: 0.287542
[Epoch 23; Iter    22/  209] train: loss: 0.1940092
[Epoch 23; Iter    52/  209] train: loss: 0.1759520
[Epoch 23; Iter    82/  209] train: loss: 0.1422903
[Epoch 23; Iter   112/  209] train: loss: 0.1468157
[Epoch 23; Iter   142/  209] train: loss: 0.1590240
[Epoch 23; Iter   172/  209] train: loss: 0.1508810
[Epoch 23; Iter   202/  209] train: loss: 0.1413846
[Epoch 23] ogbg-moltox21: 0.797963 val loss: 0.237318
[Epoch 23] ogbg-moltox21: 0.755415 test loss: 0.258068
[Epoch 24; Iter    23/  209] train: loss: 0.2434499
[Epoch 24; Iter    53/  209] train: loss: 0.1191920
[Epoch 24; Iter    83/  209] train: loss: 0.2041170
[Epoch 24; Iter   113/  209] train: loss: 0.1334229
[Epoch 24; Iter   143/  209] train: loss: 0.0891013
[Epoch 24; Iter   173/  209] train: loss: 0.1248048
[Epoch 24; Iter   203/  209] train: loss: 0.1757288
[Epoch 24] ogbg-moltox21: 0.777312 val loss: 0.250855
[Epoch 24] ogbg-moltox21: 0.738547 test loss: 0.268887
[Epoch 25; Iter    24/  209] train: loss: 0.1354853
[Epoch 25; Iter    54/  209] train: loss: 0.2683455
[Epoch 25; Iter    84/  209] train: loss: 0.1454856
[Epoch 25; Iter   114/  209] train: loss: 0.1693705
[Epoch 25; Iter   144/  209] train: loss: 0.1597880
[Epoch 25; Iter   174/  209] train: loss: 0.1839339
[Epoch 25; Iter   204/  209] train: loss: 0.2463391
[Epoch 25] ogbg-moltox21: 0.801644 val loss: 0.240732
[Epoch 25] ogbg-moltox21: 0.758672 test loss: 0.327044
[Epoch 26; Iter    25/  209] train: loss: 0.1906810
[Epoch 26; Iter    55/  209] train: loss: 0.2600664
[Epoch 26; Iter    85/  209] train: loss: 0.1933201
[Epoch 26; Iter   115/  209] train: loss: 0.1044946
[Epoch 26; Iter   145/  209] train: loss: 0.1666370
[Epoch 26; Iter   175/  209] train: loss: 0.1058966
[Epoch 26; Iter   205/  209] train: loss: 0.2017062
[Epoch 26] ogbg-moltox21: 0.789617 val loss: 0.262226
[Epoch 26] ogbg-moltox21: 0.742963 test loss: 0.361714
[Epoch 27; Iter    26/  209] train: loss: 0.1352930
[Epoch 27; Iter    56/  209] train: loss: 0.2699141
[Epoch 27; Iter    86/  209] train: loss: 0.1857464
[Epoch 27; Iter   116/  209] train: loss: 0.1636292
[Epoch 27; Iter   146/  209] train: loss: 0.1656982
[Epoch 27; Iter   176/  209] train: loss: 0.1251913
[Epoch 27; Iter   206/  209] train: loss: 0.1826591
[Epoch 27] ogbg-moltox21: 0.789609 val loss: 0.275735
[Epoch 27] ogbg-moltox21: 0.752964 test loss: 0.279035
[Epoch 28; Iter    27/  209] train: loss: 0.1235764
[Epoch 28; Iter    57/  209] train: loss: 0.1383883
[Epoch 28; Iter    87/  209] train: loss: 0.1454117
[Epoch 28; Iter   117/  209] train: loss: 0.1523133
[Epoch 28; Iter   147/  209] train: loss: 0.1543234
[Epoch 28; Iter   177/  209] train: loss: 0.1506144
[Epoch 28; Iter   207/  209] train: loss: 0.1325373
[Epoch 28] ogbg-moltox21: 0.790257 val loss: 0.238196
[Epoch 28] ogbg-moltox21: 0.766265 test loss: 0.252996
[Epoch 29; Iter    28/  209] train: loss: 0.1437657
[Epoch 29; Iter    58/  209] train: loss: 0.1418872
[Epoch 29; Iter    88/  209] train: loss: 0.1710959
[Epoch 29; Iter   118/  209] train: loss: 0.2147026
[Epoch 29; Iter   148/  209] train: loss: 0.1947326
[Epoch 29; Iter   178/  209] train: loss: 0.1121670
[Epoch 29; Iter   208/  209] train: loss: 0.1131031
[Epoch 29] ogbg-moltox21: 0.791624 val loss: 0.245960
[Epoch 29] ogbg-moltox21: 0.752122 test loss: 0.259679
[Epoch 30; Iter    29/  209] train: loss: 0.1698518
[Epoch 30; Iter    59/  209] train: loss: 0.1237844
[Epoch 13; Iter    12/  209] train: loss: 0.2124941
[Epoch 13; Iter    42/  209] train: loss: 0.2032512
[Epoch 13; Iter    72/  209] train: loss: 0.2201566
[Epoch 13; Iter   102/  209] train: loss: 0.1695312
[Epoch 13; Iter   132/  209] train: loss: 0.1354659
[Epoch 13; Iter   162/  209] train: loss: 0.1985505
[Epoch 13; Iter   192/  209] train: loss: 0.1848035
[Epoch 13] ogbg-moltox21: 0.776385 val loss: 0.300946
[Epoch 13] ogbg-moltox21: 0.712848 test loss: 0.304763
[Epoch 14; Iter    13/  209] train: loss: 0.1801577
[Epoch 14; Iter    43/  209] train: loss: 0.1823854
[Epoch 14; Iter    73/  209] train: loss: 0.2197323
[Epoch 14; Iter   103/  209] train: loss: 0.1647605
[Epoch 14; Iter   133/  209] train: loss: 0.2152443
[Epoch 14; Iter   163/  209] train: loss: 0.1685762
[Epoch 14; Iter   193/  209] train: loss: 0.2475535
[Epoch 14] ogbg-moltox21: 0.781989 val loss: 0.258829
[Epoch 14] ogbg-moltox21: 0.735960 test loss: 0.279318
[Epoch 15; Iter    14/  209] train: loss: 0.2145008
[Epoch 15; Iter    44/  209] train: loss: 0.1726928
[Epoch 15; Iter    74/  209] train: loss: 0.1398020
[Epoch 15; Iter   104/  209] train: loss: 0.2283903
[Epoch 15; Iter   134/  209] train: loss: 0.1779999
[Epoch 15; Iter   164/  209] train: loss: 0.1354841
[Epoch 15; Iter   194/  209] train: loss: 0.1787256
[Epoch 15] ogbg-moltox21: 0.775911 val loss: 0.273232
[Epoch 15] ogbg-moltox21: 0.726246 test loss: 0.295170
[Epoch 16; Iter    15/  209] train: loss: 0.1414902
[Epoch 16; Iter    45/  209] train: loss: 0.2050663
[Epoch 16; Iter    75/  209] train: loss: 0.2186190
[Epoch 16; Iter   105/  209] train: loss: 0.2468792
[Epoch 16; Iter   135/  209] train: loss: 0.1856182
[Epoch 16; Iter   165/  209] train: loss: 0.1225044
[Epoch 16; Iter   195/  209] train: loss: 0.1540132
[Epoch 16] ogbg-moltox21: 0.702732 val loss: 0.547388
[Epoch 16] ogbg-moltox21: 0.646467 test loss: 0.595012
[Epoch 17; Iter    16/  209] train: loss: 0.2058726
[Epoch 17; Iter    46/  209] train: loss: 0.2782422
[Epoch 17; Iter    76/  209] train: loss: 0.1713716
[Epoch 17; Iter   106/  209] train: loss: 0.2302945
[Epoch 17; Iter   136/  209] train: loss: 0.0955434
[Epoch 17; Iter   166/  209] train: loss: 0.1753909
[Epoch 17; Iter   196/  209] train: loss: 0.2113056
[Epoch 17] ogbg-moltox21: 0.787242 val loss: 0.254818
[Epoch 17] ogbg-moltox21: 0.714783 test loss: 0.281328
[Epoch 18; Iter    17/  209] train: loss: 0.1835150
[Epoch 18; Iter    47/  209] train: loss: 0.1299756
[Epoch 18; Iter    77/  209] train: loss: 0.2133037
[Epoch 18; Iter   107/  209] train: loss: 0.2828603
[Epoch 18; Iter   137/  209] train: loss: 0.1224743
[Epoch 18; Iter   167/  209] train: loss: 0.1332506
[Epoch 18; Iter   197/  209] train: loss: 0.1270457
[Epoch 18] ogbg-moltox21: 0.783133 val loss: 0.250750
[Epoch 18] ogbg-moltox21: 0.710644 test loss: 0.272382
[Epoch 19; Iter    18/  209] train: loss: 0.1597707
[Epoch 19; Iter    48/  209] train: loss: 0.1274651
[Epoch 19; Iter    78/  209] train: loss: 0.1984486
[Epoch 19; Iter   108/  209] train: loss: 0.2011110
[Epoch 19; Iter   138/  209] train: loss: 0.2066234
[Epoch 19; Iter   168/  209] train: loss: 0.2028846
[Epoch 19; Iter   198/  209] train: loss: 0.1413933
[Epoch 19] ogbg-moltox21: 0.785883 val loss: 0.245212
[Epoch 19] ogbg-moltox21: 0.728059 test loss: 0.264925
[Epoch 20; Iter    19/  209] train: loss: 0.2427099
[Epoch 20; Iter    49/  209] train: loss: 0.1442236
[Epoch 20; Iter    79/  209] train: loss: 0.1466081
[Epoch 20; Iter   109/  209] train: loss: 0.1193611
[Epoch 20; Iter   139/  209] train: loss: 0.1768823
[Epoch 20; Iter   169/  209] train: loss: 0.1989746
[Epoch 20; Iter   199/  209] train: loss: 0.1797587
[Epoch 20] ogbg-moltox21: 0.789185 val loss: 0.246791
[Epoch 20] ogbg-moltox21: 0.732149 test loss: 0.267060
[Epoch 21; Iter    20/  209] train: loss: 0.1750567
[Epoch 21; Iter    50/  209] train: loss: 0.2131898
[Epoch 21; Iter    80/  209] train: loss: 0.1686680
[Epoch 21; Iter   110/  209] train: loss: 0.3204890
[Epoch 21; Iter   140/  209] train: loss: 0.1770877
[Epoch 21; Iter   170/  209] train: loss: 0.2111057
[Epoch 21; Iter   200/  209] train: loss: 0.1618318
[Epoch 21] ogbg-moltox21: 0.788725 val loss: 0.248389
[Epoch 21] ogbg-moltox21: 0.740440 test loss: 0.268058
[Epoch 22; Iter    21/  209] train: loss: 0.1048351
[Epoch 22; Iter    51/  209] train: loss: 0.1978688
[Epoch 22; Iter    81/  209] train: loss: 0.1512091
[Epoch 22; Iter   111/  209] train: loss: 0.2299613
[Epoch 22; Iter   141/  209] train: loss: 0.1344929
[Epoch 22; Iter   171/  209] train: loss: 0.1859725
[Epoch 22; Iter   201/  209] train: loss: 0.1836115
[Epoch 22] ogbg-moltox21: 0.803621 val loss: 0.242655
[Epoch 22] ogbg-moltox21: 0.733521 test loss: 0.269085
[Epoch 23; Iter    22/  209] train: loss: 0.1289339
[Epoch 23; Iter    52/  209] train: loss: 0.1313218
[Epoch 23; Iter    82/  209] train: loss: 0.1365864
[Epoch 23; Iter   112/  209] train: loss: 0.1717336
[Epoch 23; Iter   142/  209] train: loss: 0.1723115
[Epoch 23; Iter   172/  209] train: loss: 0.1692409
[Epoch 23; Iter   202/  209] train: loss: 0.1393210
[Epoch 23] ogbg-moltox21: 0.793276 val loss: 0.247322
[Epoch 23] ogbg-moltox21: 0.743447 test loss: 0.261675
[Epoch 24; Iter    23/  209] train: loss: 0.1429068
[Epoch 24; Iter    53/  209] train: loss: 0.2013603
[Epoch 24; Iter    83/  209] train: loss: 0.2119121
[Epoch 24; Iter   113/  209] train: loss: 0.1165531
[Epoch 24; Iter   143/  209] train: loss: 0.1599568
[Epoch 24; Iter   173/  209] train: loss: 0.1622986
[Epoch 24; Iter   203/  209] train: loss: 0.2064712
[Epoch 24] ogbg-moltox21: 0.775349 val loss: 0.257825
[Epoch 24] ogbg-moltox21: 0.736700 test loss: 0.288541
[Epoch 25; Iter    24/  209] train: loss: 0.1617498
[Epoch 25; Iter    54/  209] train: loss: 0.1315373
[Epoch 25; Iter    84/  209] train: loss: 0.1093886
[Epoch 25; Iter   114/  209] train: loss: 0.1720314
[Epoch 25; Iter   144/  209] train: loss: 0.2225095
[Epoch 25; Iter   174/  209] train: loss: 0.1500755
[Epoch 25; Iter   204/  209] train: loss: 0.1492472
[Epoch 25] ogbg-moltox21: 0.770665 val loss: 0.296518
[Epoch 25] ogbg-moltox21: 0.734559 test loss: 0.309805
[Epoch 26; Iter    25/  209] train: loss: 0.1428914
[Epoch 26; Iter    55/  209] train: loss: 0.2052346
[Epoch 26; Iter    85/  209] train: loss: 0.2392906
[Epoch 26; Iter   115/  209] train: loss: 0.1880104
[Epoch 26; Iter   145/  209] train: loss: 0.1422995
[Epoch 26; Iter   175/  209] train: loss: 0.1630445
[Epoch 26; Iter   205/  209] train: loss: 0.1358940
[Epoch 26] ogbg-moltox21: 0.788058 val loss: 0.240778
[Epoch 26] ogbg-moltox21: 0.747993 test loss: 0.258518
[Epoch 27; Iter    26/  209] train: loss: 0.1925090
[Epoch 27; Iter    56/  209] train: loss: 0.0917547
[Epoch 27; Iter    86/  209] train: loss: 0.1809839
[Epoch 27; Iter   116/  209] train: loss: 0.1292967
[Epoch 27; Iter   146/  209] train: loss: 0.1726704
[Epoch 27; Iter   176/  209] train: loss: 0.2001472
[Epoch 27; Iter   206/  209] train: loss: 0.1544758
[Epoch 27] ogbg-moltox21: 0.802895 val loss: 0.265236
[Epoch 27] ogbg-moltox21: 0.749521 test loss: 0.287847
[Epoch 28; Iter    27/  209] train: loss: 0.1165190
[Epoch 28; Iter    57/  209] train: loss: 0.2441442
[Epoch 28; Iter    87/  209] train: loss: 0.1908395
[Epoch 28; Iter   117/  209] train: loss: 0.1401522
[Epoch 28; Iter   147/  209] train: loss: 0.1867532
[Epoch 28; Iter   177/  209] train: loss: 0.1973914
[Epoch 28; Iter   207/  209] train: loss: 0.1269789
[Epoch 28] ogbg-moltox21: 0.800009 val loss: 0.263547
[Epoch 28] ogbg-moltox21: 0.741556 test loss: 0.277882
[Epoch 29; Iter    28/  209] train: loss: 0.1198539
[Epoch 29; Iter    58/  209] train: loss: 0.1390663
[Epoch 29; Iter    88/  209] train: loss: 0.1291973
[Epoch 29; Iter   118/  209] train: loss: 0.2079228
[Epoch 29; Iter   148/  209] train: loss: 0.1273738
[Epoch 29; Iter   178/  209] train: loss: 0.1041414
[Epoch 29; Iter   208/  209] train: loss: 0.1276153
[Epoch 29] ogbg-moltox21: 0.790989 val loss: 0.300820
[Epoch 29] ogbg-moltox21: 0.740868 test loss: 0.316833
[Epoch 30; Iter    29/  209] train: loss: 0.1571800
[Epoch 30; Iter    59/  209] train: loss: 0.1307319
[Epoch 13; Iter    12/  209] train: loss: 0.1622983
[Epoch 13; Iter    42/  209] train: loss: 0.1648276
[Epoch 13; Iter    72/  209] train: loss: 0.1682443
[Epoch 13; Iter   102/  209] train: loss: 0.2007984
[Epoch 13; Iter   132/  209] train: loss: 0.1656102
[Epoch 13; Iter   162/  209] train: loss: 0.2557010
[Epoch 13; Iter   192/  209] train: loss: 0.1998644
[Epoch 13] ogbg-moltox21: 0.779999 val loss: 0.293391
[Epoch 13] ogbg-moltox21: 0.728225 test loss: 0.266540
[Epoch 14; Iter    13/  209] train: loss: 0.1111431
[Epoch 14; Iter    43/  209] train: loss: 0.1644047
[Epoch 14; Iter    73/  209] train: loss: 0.1596328
[Epoch 14; Iter   103/  209] train: loss: 0.2642346
[Epoch 14; Iter   133/  209] train: loss: 0.1998206
[Epoch 14; Iter   163/  209] train: loss: 0.2257109
[Epoch 14; Iter   193/  209] train: loss: 0.2157197
[Epoch 14] ogbg-moltox21: 0.766883 val loss: 0.263388
[Epoch 14] ogbg-moltox21: 0.722399 test loss: 0.272271
[Epoch 15; Iter    14/  209] train: loss: 0.1174744
[Epoch 15; Iter    44/  209] train: loss: 0.1396252
[Epoch 15; Iter    74/  209] train: loss: 0.2016697
[Epoch 15; Iter   104/  209] train: loss: 0.1500491
[Epoch 15; Iter   134/  209] train: loss: 0.1381647
[Epoch 15; Iter   164/  209] train: loss: 0.1412951
[Epoch 15; Iter   194/  209] train: loss: 0.1614808
[Epoch 15] ogbg-moltox21: 0.788025 val loss: 0.252123
[Epoch 15] ogbg-moltox21: 0.742591 test loss: 0.264551
[Epoch 16; Iter    15/  209] train: loss: 0.1413804
[Epoch 16; Iter    45/  209] train: loss: 0.1939676
[Epoch 16; Iter    75/  209] train: loss: 0.2960038
[Epoch 16; Iter   105/  209] train: loss: 0.2594443
[Epoch 16; Iter   135/  209] train: loss: 0.2536795
[Epoch 16; Iter   165/  209] train: loss: 0.2975694
[Epoch 16; Iter   195/  209] train: loss: 0.1925218
[Epoch 16] ogbg-moltox21: 0.782255 val loss: 0.248736
[Epoch 16] ogbg-moltox21: 0.729689 test loss: 0.260825
[Epoch 17; Iter    16/  209] train: loss: 0.1856985
[Epoch 17; Iter    46/  209] train: loss: 0.2318552
[Epoch 17; Iter    76/  209] train: loss: 0.2275069
[Epoch 17; Iter   106/  209] train: loss: 0.1769681
[Epoch 17; Iter   136/  209] train: loss: 0.3313431
[Epoch 17; Iter   166/  209] train: loss: 0.2248583
[Epoch 17; Iter   196/  209] train: loss: 0.1798210
[Epoch 17] ogbg-moltox21: 0.758377 val loss: 0.256527
[Epoch 17] ogbg-moltox21: 0.702363 test loss: 0.273281
[Epoch 18; Iter    17/  209] train: loss: 0.1450660
[Epoch 18; Iter    47/  209] train: loss: 0.1319758
[Epoch 18; Iter    77/  209] train: loss: 0.2242170
[Epoch 18; Iter   107/  209] train: loss: 0.1511947
[Epoch 18; Iter   137/  209] train: loss: 0.1210005
[Epoch 18; Iter   167/  209] train: loss: 0.1491300
[Epoch 18; Iter   197/  209] train: loss: 0.1865116
[Epoch 18] ogbg-moltox21: 0.770144 val loss: 0.261721
[Epoch 18] ogbg-moltox21: 0.742383 test loss: 0.267501
[Epoch 19; Iter    18/  209] train: loss: 0.1442399
[Epoch 19; Iter    48/  209] train: loss: 0.1139817
[Epoch 19; Iter    78/  209] train: loss: 0.2596974
[Epoch 19; Iter   108/  209] train: loss: 0.1572493
[Epoch 19; Iter   138/  209] train: loss: 0.1880471
[Epoch 19; Iter   168/  209] train: loss: 0.1848975
[Epoch 19; Iter   198/  209] train: loss: 0.2429120
[Epoch 19] ogbg-moltox21: 0.784983 val loss: 0.252566
[Epoch 19] ogbg-moltox21: 0.748295 test loss: 0.270713
[Epoch 20; Iter    19/  209] train: loss: 0.1920281
[Epoch 20; Iter    49/  209] train: loss: 0.1393978
[Epoch 20; Iter    79/  209] train: loss: 0.1698354
[Epoch 20; Iter   109/  209] train: loss: 0.1715406
[Epoch 20; Iter   139/  209] train: loss: 0.1469318
[Epoch 20; Iter   169/  209] train: loss: 0.1982461
[Epoch 20; Iter   199/  209] train: loss: 0.2426530
[Epoch 20] ogbg-moltox21: 0.806506 val loss: 0.250057
[Epoch 20] ogbg-moltox21: 0.741834 test loss: 0.269657
[Epoch 21; Iter    20/  209] train: loss: 0.1658893
[Epoch 21; Iter    50/  209] train: loss: 0.2044123
[Epoch 21; Iter    80/  209] train: loss: 0.1481004
[Epoch 21; Iter   110/  209] train: loss: 0.1854311
[Epoch 21; Iter   140/  209] train: loss: 0.1062775
[Epoch 21; Iter   170/  209] train: loss: 0.1404371
[Epoch 21; Iter   200/  209] train: loss: 0.1179708
[Epoch 21] ogbg-moltox21: 0.795907 val loss: 0.253462
[Epoch 21] ogbg-moltox21: 0.757315 test loss: 0.265914
[Epoch 22; Iter    21/  209] train: loss: 0.2055972
[Epoch 22; Iter    51/  209] train: loss: 0.1798846
[Epoch 22; Iter    81/  209] train: loss: 0.0997849
[Epoch 22; Iter   111/  209] train: loss: 0.1491325
[Epoch 22; Iter   141/  209] train: loss: 0.1347250
[Epoch 22; Iter   171/  209] train: loss: 0.2274567
[Epoch 22; Iter   201/  209] train: loss: 0.2129643
[Epoch 22] ogbg-moltox21: 0.787300 val loss: 0.259967
[Epoch 22] ogbg-moltox21: 0.739077 test loss: 0.276356
[Epoch 23; Iter    22/  209] train: loss: 0.1287715
[Epoch 23; Iter    52/  209] train: loss: 0.1909658
[Epoch 23; Iter    82/  209] train: loss: 0.1535776
[Epoch 23; Iter   112/  209] train: loss: 0.1487743
[Epoch 23; Iter   142/  209] train: loss: 0.1652012
[Epoch 23; Iter   172/  209] train: loss: 0.1900658
[Epoch 23; Iter   202/  209] train: loss: 0.1940032
[Epoch 23] ogbg-moltox21: 0.791840 val loss: 0.253042
[Epoch 23] ogbg-moltox21: 0.751282 test loss: 0.264198
[Epoch 24; Iter    23/  209] train: loss: 0.1983234
[Epoch 24; Iter    53/  209] train: loss: 0.2094938
[Epoch 24; Iter    83/  209] train: loss: 0.2221638
[Epoch 24; Iter   113/  209] train: loss: 0.1249840
[Epoch 24; Iter   143/  209] train: loss: 0.1498859
[Epoch 24; Iter   173/  209] train: loss: 0.1089647
[Epoch 24; Iter   203/  209] train: loss: 0.2016530
[Epoch 24] ogbg-moltox21: 0.772277 val loss: 0.271366
[Epoch 24] ogbg-moltox21: 0.731854 test loss: 0.286774
[Epoch 25; Iter    24/  209] train: loss: 0.1916971
[Epoch 25; Iter    54/  209] train: loss: 0.2179223
[Epoch 25; Iter    84/  209] train: loss: 0.1217584
[Epoch 25; Iter   114/  209] train: loss: 0.2106150
[Epoch 25; Iter   144/  209] train: loss: 0.1153094
[Epoch 25; Iter   174/  209] train: loss: 0.1965014
[Epoch 25; Iter   204/  209] train: loss: 0.0991352
[Epoch 25] ogbg-moltox21: 0.799360 val loss: 0.244753
[Epoch 25] ogbg-moltox21: 0.745685 test loss: 0.259434
[Epoch 26; Iter    25/  209] train: loss: 0.1126786
[Epoch 26; Iter    55/  209] train: loss: 0.1415238
[Epoch 26; Iter    85/  209] train: loss: 0.2008780
[Epoch 26; Iter   115/  209] train: loss: 0.1180523
[Epoch 26; Iter   145/  209] train: loss: 0.1433345
[Epoch 26; Iter   175/  209] train: loss: 0.1416907
[Epoch 26; Iter   205/  209] train: loss: 0.2653222
[Epoch 26] ogbg-moltox21: 0.783313 val loss: 0.261742
[Epoch 26] ogbg-moltox21: 0.736431 test loss: 0.269950
[Epoch 27; Iter    26/  209] train: loss: 0.1542247
[Epoch 27; Iter    56/  209] train: loss: 0.0904267
[Epoch 27; Iter    86/  209] train: loss: 0.1580571
[Epoch 27; Iter   116/  209] train: loss: 0.2070246
[Epoch 27; Iter   146/  209] train: loss: 0.1202319
[Epoch 27; Iter   176/  209] train: loss: 0.2318589
[Epoch 27; Iter   206/  209] train: loss: 0.1965995
[Epoch 27] ogbg-moltox21: 0.794165 val loss: 0.240084
[Epoch 27] ogbg-moltox21: 0.751818 test loss: 0.254570
[Epoch 28; Iter    27/  209] train: loss: 0.2170020
[Epoch 28; Iter    57/  209] train: loss: 0.0817956
[Epoch 28; Iter    87/  209] train: loss: 0.1633205
[Epoch 28; Iter   117/  209] train: loss: 0.2008232
[Epoch 28; Iter   147/  209] train: loss: 0.2335551
[Epoch 28; Iter   177/  209] train: loss: 0.1949121
[Epoch 28; Iter   207/  209] train: loss: 0.0984830
[Epoch 28] ogbg-moltox21: 0.793845 val loss: 0.244094
[Epoch 28] ogbg-moltox21: 0.756252 test loss: 0.259424
[Epoch 29; Iter    28/  209] train: loss: 0.1759720
[Epoch 29; Iter    58/  209] train: loss: 0.1288874
[Epoch 29; Iter    88/  209] train: loss: 0.1769748
[Epoch 29; Iter   118/  209] train: loss: 0.1138399
[Epoch 29; Iter   148/  209] train: loss: 0.2103940
[Epoch 29; Iter   178/  209] train: loss: 0.1563746
[Epoch 29; Iter   208/  209] train: loss: 0.2084673
[Epoch 29] ogbg-moltox21: 0.797581 val loss: 0.235381
[Epoch 29] ogbg-moltox21: 0.755795 test loss: 0.253547
[Epoch 30; Iter    29/  209] train: loss: 0.1270831
[Epoch 30; Iter    59/  209] train: loss: 0.1908381
[Epoch 14; Iter    81/  183] train: loss: 0.1887542
[Epoch 14; Iter   111/  183] train: loss: 0.2235179
[Epoch 14; Iter   141/  183] train: loss: 0.1730535
[Epoch 14; Iter   171/  183] train: loss: 0.1727685
[Epoch 14] ogbg-moltox21: 0.734104 val loss: 0.325747
[Epoch 14] ogbg-moltox21: 0.733827 test loss: 0.352899
[Epoch 15; Iter    18/  183] train: loss: 0.1768053
[Epoch 15; Iter    48/  183] train: loss: 0.2217393
[Epoch 15; Iter    78/  183] train: loss: 0.1641684
[Epoch 15; Iter   108/  183] train: loss: 0.1253909
[Epoch 15; Iter   138/  183] train: loss: 0.1737258
[Epoch 15; Iter   168/  183] train: loss: 0.2128699
[Epoch 15] ogbg-moltox21: 0.752710 val loss: 0.339213
[Epoch 15] ogbg-moltox21: 0.738317 test loss: 0.327190
[Epoch 16; Iter    15/  183] train: loss: 0.1660775
[Epoch 16; Iter    45/  183] train: loss: 0.1741486
[Epoch 16; Iter    75/  183] train: loss: 0.1406352
[Epoch 16; Iter   105/  183] train: loss: 0.1342729
[Epoch 16; Iter   135/  183] train: loss: 0.1746356
[Epoch 16; Iter   165/  183] train: loss: 0.1573106
[Epoch 16] ogbg-moltox21: 0.741773 val loss: 0.313433
[Epoch 16] ogbg-moltox21: 0.741387 test loss: 0.305164
[Epoch 17; Iter    12/  183] train: loss: 0.2422481
[Epoch 17; Iter    42/  183] train: loss: 0.1338101
[Epoch 17; Iter    72/  183] train: loss: 0.1451993
[Epoch 17; Iter   102/  183] train: loss: 0.1968030
[Epoch 17; Iter   132/  183] train: loss: 0.1993614
[Epoch 17; Iter   162/  183] train: loss: 0.1523458
[Epoch 17] ogbg-moltox21: 0.751830 val loss: 0.297958
[Epoch 17] ogbg-moltox21: 0.756320 test loss: 0.291921
[Epoch 18; Iter     9/  183] train: loss: 0.1586443
[Epoch 18; Iter    39/  183] train: loss: 0.1177785
[Epoch 18; Iter    69/  183] train: loss: 0.1052884
[Epoch 18; Iter    99/  183] train: loss: 0.1769272
[Epoch 18; Iter   129/  183] train: loss: 0.1023276
[Epoch 18; Iter   159/  183] train: loss: 0.1282295
[Epoch 18] ogbg-moltox21: 0.741355 val loss: 0.301797
[Epoch 18] ogbg-moltox21: 0.754821 test loss: 0.290838
[Epoch 19; Iter     6/  183] train: loss: 0.1606072
[Epoch 19; Iter    36/  183] train: loss: 0.1492676
[Epoch 19; Iter    66/  183] train: loss: 0.1954939
[Epoch 19; Iter    96/  183] train: loss: 0.1206721
[Epoch 19; Iter   126/  183] train: loss: 0.2917963
[Epoch 19; Iter   156/  183] train: loss: 0.1266559
[Epoch 19] ogbg-moltox21: 0.710227 val loss: 0.320888
[Epoch 19] ogbg-moltox21: 0.701391 test loss: 0.325064
[Epoch 20; Iter     3/  183] train: loss: 0.1553079
[Epoch 20; Iter    33/  183] train: loss: 0.3224862
[Epoch 20; Iter    63/  183] train: loss: 0.2808000
[Epoch 20; Iter    93/  183] train: loss: 0.1703194
[Epoch 20; Iter   123/  183] train: loss: 0.1881679
[Epoch 20; Iter   153/  183] train: loss: 0.2356635
[Epoch 20; Iter   183/  183] train: loss: 0.1342259
[Epoch 20] ogbg-moltox21: 0.752650 val loss: 0.290780
[Epoch 20] ogbg-moltox21: 0.746669 test loss: 0.301789
[Epoch 21; Iter    30/  183] train: loss: 0.1549490
[Epoch 21; Iter    60/  183] train: loss: 0.2364419
[Epoch 21; Iter    90/  183] train: loss: 0.2367542
[Epoch 21; Iter   120/  183] train: loss: 0.1057674
[Epoch 21; Iter   150/  183] train: loss: 0.1654572
[Epoch 21; Iter   180/  183] train: loss: 0.0950378
[Epoch 21] ogbg-moltox21: 0.747589 val loss: 0.284328
[Epoch 21] ogbg-moltox21: 0.746796 test loss: 0.294908
[Epoch 22; Iter    27/  183] train: loss: 0.1759992
[Epoch 22; Iter    57/  183] train: loss: 0.2138992
[Epoch 22; Iter    87/  183] train: loss: 0.1366363
[Epoch 22; Iter   117/  183] train: loss: 0.1825311
[Epoch 22; Iter   147/  183] train: loss: 0.1319983
[Epoch 22; Iter   177/  183] train: loss: 0.1693183
[Epoch 22] ogbg-moltox21: 0.731776 val loss: 0.273196
[Epoch 22] ogbg-moltox21: 0.734762 test loss: 0.275654
[Epoch 23; Iter    24/  183] train: loss: 0.1480266
[Epoch 23; Iter    54/  183] train: loss: 0.1795023
[Epoch 23; Iter    84/  183] train: loss: 0.1465518
[Epoch 23; Iter   114/  183] train: loss: 0.1740380
[Epoch 23; Iter   144/  183] train: loss: 0.1873167
[Epoch 23; Iter   174/  183] train: loss: 0.1718933
[Epoch 23] ogbg-moltox21: 0.747463 val loss: 0.284761
[Epoch 23] ogbg-moltox21: 0.748621 test loss: 0.291226
[Epoch 24; Iter    21/  183] train: loss: 0.1084444
[Epoch 24; Iter    51/  183] train: loss: 0.1984961
[Epoch 24; Iter    81/  183] train: loss: 0.1322805
[Epoch 24; Iter   111/  183] train: loss: 0.1705789
[Epoch 24; Iter   141/  183] train: loss: 0.1580037
[Epoch 24; Iter   171/  183] train: loss: 0.1424309
[Epoch 24] ogbg-moltox21: 0.745132 val loss: 0.282274
[Epoch 24] ogbg-moltox21: 0.750555 test loss: 0.288066
[Epoch 25; Iter    18/  183] train: loss: 0.0796083
[Epoch 25; Iter    48/  183] train: loss: 0.1079064
[Epoch 25; Iter    78/  183] train: loss: 0.1956542
[Epoch 25; Iter   108/  183] train: loss: 0.1219834
[Epoch 25; Iter   138/  183] train: loss: 0.1827948
[Epoch 25; Iter   168/  183] train: loss: 0.1522175
[Epoch 25] ogbg-moltox21: 0.751776 val loss: 0.297811
[Epoch 25] ogbg-moltox21: 0.738987 test loss: 0.288352
[Epoch 26; Iter    15/  183] train: loss: 0.1255266
[Epoch 26; Iter    45/  183] train: loss: 0.1810871
[Epoch 26; Iter    75/  183] train: loss: 0.1556944
[Epoch 26; Iter   105/  183] train: loss: 0.1612708
[Epoch 26; Iter   135/  183] train: loss: 0.2335759
[Epoch 26; Iter   165/  183] train: loss: 0.2081853
[Epoch 26] ogbg-moltox21: 0.754888 val loss: 0.276498
[Epoch 26] ogbg-moltox21: 0.747203 test loss: 0.278072
[Epoch 27; Iter    12/  183] train: loss: 0.1804847
[Epoch 27; Iter    42/  183] train: loss: 0.3351240
[Epoch 27; Iter    72/  183] train: loss: 0.1274805
[Epoch 27; Iter   102/  183] train: loss: 0.1163322
[Epoch 27; Iter   132/  183] train: loss: 0.1450728
[Epoch 27; Iter   162/  183] train: loss: 0.1804149
[Epoch 27] ogbg-moltox21: 0.754069 val loss: 0.284580
[Epoch 27] ogbg-moltox21: 0.750609 test loss: 0.289423
[Epoch 28; Iter     9/  183] train: loss: 0.1376810
[Epoch 28; Iter    39/  183] train: loss: 0.1847651
[Epoch 28; Iter    69/  183] train: loss: 0.1979513
[Epoch 28; Iter    99/  183] train: loss: 0.2445372
[Epoch 28; Iter   129/  183] train: loss: 0.1238251
[Epoch 28; Iter   159/  183] train: loss: 0.1712402
[Epoch 28] ogbg-moltox21: 0.758668 val loss: 0.277512
[Epoch 28] ogbg-moltox21: 0.758089 test loss: 0.282908
[Epoch 29; Iter     6/  183] train: loss: 0.1521126
[Epoch 29; Iter    36/  183] train: loss: 0.1897989
[Epoch 29; Iter    66/  183] train: loss: 0.1494089
[Epoch 29; Iter    96/  183] train: loss: 0.1386927
[Epoch 29; Iter   126/  183] train: loss: 0.1218682
[Epoch 29; Iter   156/  183] train: loss: 0.1179290
[Epoch 29] ogbg-moltox21: 0.757017 val loss: 0.301302
[Epoch 29] ogbg-moltox21: 0.749753 test loss: 0.315329
[Epoch 30; Iter     3/  183] train: loss: 0.2418628
[Epoch 30; Iter    33/  183] train: loss: 0.1432529
[Epoch 30; Iter    63/  183] train: loss: 0.1075921
[Epoch 30; Iter    93/  183] train: loss: 0.1180541
[Epoch 30; Iter   123/  183] train: loss: 0.1333594
[Epoch 30; Iter   153/  183] train: loss: 0.1466230
[Epoch 30; Iter   183/  183] train: loss: 0.1845310
[Epoch 30] ogbg-moltox21: 0.758857 val loss: 0.272218
[Epoch 30] ogbg-moltox21: 0.749640 test loss: 0.276864
[Epoch 31; Iter    30/  183] train: loss: 0.1670687
[Epoch 31; Iter    60/  183] train: loss: 0.1148795
[Epoch 31; Iter    90/  183] train: loss: 0.1281929
[Epoch 31; Iter   120/  183] train: loss: 0.1404868
[Epoch 31; Iter   150/  183] train: loss: 0.2417566
[Epoch 31; Iter   180/  183] train: loss: 0.1844707
[Epoch 31] ogbg-moltox21: 0.762632 val loss: 0.268251
[Epoch 31] ogbg-moltox21: 0.756961 test loss: 0.276041
[Epoch 32; Iter    27/  183] train: loss: 0.1579334
[Epoch 32; Iter    57/  183] train: loss: 0.1307909
[Epoch 32; Iter    87/  183] train: loss: 0.1238640
[Epoch 32; Iter   117/  183] train: loss: 0.1508387
[Epoch 32; Iter   147/  183] train: loss: 0.1009934
[Epoch 32; Iter   177/  183] train: loss: 0.1726688
[Epoch 32] ogbg-moltox21: 0.770082 val loss: 0.298163
[Epoch 32] ogbg-moltox21: 0.757313 test loss: 0.328055
[Epoch 33; Iter    24/  183] train: loss: 0.2128899
[Epoch 33; Iter    54/  183] train: loss: 0.1361380
[Epoch 33; Iter    84/  183] train: loss: 0.1265215
[Epoch 14; Iter    81/  183] train: loss: 0.1699451
[Epoch 14; Iter   111/  183] train: loss: 0.2601115
[Epoch 14; Iter   141/  183] train: loss: 0.2763681
[Epoch 14; Iter   171/  183] train: loss: 0.1606446
[Epoch 14] ogbg-moltox21: 0.748651 val loss: 0.362887
[Epoch 14] ogbg-moltox21: 0.736138 test loss: 0.368354
[Epoch 15; Iter    18/  183] train: loss: 0.1772596
[Epoch 15; Iter    48/  183] train: loss: 0.1872945
[Epoch 15; Iter    78/  183] train: loss: 0.1822762
[Epoch 15; Iter   108/  183] train: loss: 0.1490474
[Epoch 15; Iter   138/  183] train: loss: 0.1338096
[Epoch 15; Iter   168/  183] train: loss: 0.2453560
[Epoch 15] ogbg-moltox21: 0.740012 val loss: 0.346614
[Epoch 15] ogbg-moltox21: 0.722286 test loss: 0.347227
[Epoch 16; Iter    15/  183] train: loss: 0.2570141
[Epoch 16; Iter    45/  183] train: loss: 0.2194076
[Epoch 16; Iter    75/  183] train: loss: 0.1504496
[Epoch 16; Iter   105/  183] train: loss: 0.2379084
[Epoch 16; Iter   135/  183] train: loss: 0.2556728
[Epoch 16; Iter   165/  183] train: loss: 0.1687303
[Epoch 16] ogbg-moltox21: 0.727860 val loss: 1.311332
[Epoch 16] ogbg-moltox21: 0.715025 test loss: 1.953943
[Epoch 17; Iter    12/  183] train: loss: 0.1278231
[Epoch 17; Iter    42/  183] train: loss: 0.1074947
[Epoch 17; Iter    72/  183] train: loss: 0.1455131
[Epoch 17; Iter   102/  183] train: loss: 0.2261601
[Epoch 17; Iter   132/  183] train: loss: 0.1923124
[Epoch 17; Iter   162/  183] train: loss: 0.1146254
[Epoch 17] ogbg-moltox21: 0.740824 val loss: 0.283893
[Epoch 17] ogbg-moltox21: 0.726553 test loss: 0.299859
[Epoch 18; Iter     9/  183] train: loss: 0.2290917
[Epoch 18; Iter    39/  183] train: loss: 0.2242500
[Epoch 18; Iter    69/  183] train: loss: 0.1494087
[Epoch 18; Iter    99/  183] train: loss: 0.1376468
[Epoch 18; Iter   129/  183] train: loss: 0.1278214
[Epoch 18; Iter   159/  183] train: loss: 0.1265293
[Epoch 18] ogbg-moltox21: 0.746063 val loss: 0.302527
[Epoch 18] ogbg-moltox21: 0.727697 test loss: 0.320207
[Epoch 19; Iter     6/  183] train: loss: 0.1775414
[Epoch 19; Iter    36/  183] train: loss: 0.1581039
[Epoch 19; Iter    66/  183] train: loss: 0.1721271
[Epoch 19; Iter    96/  183] train: loss: 0.1580393
[Epoch 19; Iter   126/  183] train: loss: 0.1558762
[Epoch 19; Iter   156/  183] train: loss: 0.2071503
[Epoch 19] ogbg-moltox21: 0.711852 val loss: 0.402817
[Epoch 19] ogbg-moltox21: 0.717760 test loss: 0.391514
[Epoch 20; Iter     3/  183] train: loss: 0.1774192
[Epoch 20; Iter    33/  183] train: loss: 0.1716309
[Epoch 20; Iter    63/  183] train: loss: 0.1087265
[Epoch 20; Iter    93/  183] train: loss: 0.1208003
[Epoch 20; Iter   123/  183] train: loss: 0.2871449
[Epoch 20; Iter   153/  183] train: loss: 0.1173623
[Epoch 20; Iter   183/  183] train: loss: 0.1692893
[Epoch 20] ogbg-moltox21: 0.751008 val loss: 0.304610
[Epoch 20] ogbg-moltox21: 0.727686 test loss: 0.310273
[Epoch 21; Iter    30/  183] train: loss: 0.1688275
[Epoch 21; Iter    60/  183] train: loss: 0.0935991
[Epoch 21; Iter    90/  183] train: loss: 0.1466475
[Epoch 21; Iter   120/  183] train: loss: 0.1044102
[Epoch 21; Iter   150/  183] train: loss: 0.2338479
[Epoch 21; Iter   180/  183] train: loss: 0.1714036
[Epoch 21] ogbg-moltox21: 0.754360 val loss: 0.288222
[Epoch 21] ogbg-moltox21: 0.734844 test loss: 0.300988
[Epoch 22; Iter    27/  183] train: loss: 0.2491236
[Epoch 22; Iter    57/  183] train: loss: 0.0897076
[Epoch 22; Iter    87/  183] train: loss: 0.1323179
[Epoch 22; Iter   117/  183] train: loss: 0.1566086
[Epoch 22; Iter   147/  183] train: loss: 0.1426951
[Epoch 22; Iter   177/  183] train: loss: 0.2430504
[Epoch 22] ogbg-moltox21: 0.746044 val loss: 0.298234
[Epoch 22] ogbg-moltox21: 0.733245 test loss: 0.310247
[Epoch 23; Iter    24/  183] train: loss: 0.1187343
[Epoch 23; Iter    54/  183] train: loss: 0.1132720
[Epoch 23; Iter    84/  183] train: loss: 0.1297807
[Epoch 23; Iter   114/  183] train: loss: 0.1458297
[Epoch 23; Iter   144/  183] train: loss: 0.1937697
[Epoch 23; Iter   174/  183] train: loss: 0.0830614
[Epoch 23] ogbg-moltox21: 0.739548 val loss: 0.308053
[Epoch 23] ogbg-moltox21: 0.743286 test loss: 0.308371
[Epoch 24; Iter    21/  183] train: loss: 0.1619446
[Epoch 24; Iter    51/  183] train: loss: 0.0701944
[Epoch 24; Iter    81/  183] train: loss: 0.1079989
[Epoch 24; Iter   111/  183] train: loss: 0.1176950
[Epoch 24; Iter   141/  183] train: loss: 0.1621905
[Epoch 24; Iter   171/  183] train: loss: 0.1171549
[Epoch 24] ogbg-moltox21: 0.740504 val loss: 0.308410
[Epoch 24] ogbg-moltox21: 0.741625 test loss: 0.309053
[Epoch 25; Iter    18/  183] train: loss: 0.2550392
[Epoch 25; Iter    48/  183] train: loss: 0.1056811
[Epoch 25; Iter    78/  183] train: loss: 0.1138707
[Epoch 25; Iter   108/  183] train: loss: 0.1645650
[Epoch 25; Iter   138/  183] train: loss: 0.1830989
[Epoch 25; Iter   168/  183] train: loss: 0.1845546
[Epoch 25] ogbg-moltox21: 0.768516 val loss: 0.283109
[Epoch 25] ogbg-moltox21: 0.749236 test loss: 0.299484
[Epoch 26; Iter    15/  183] train: loss: 0.2988788
[Epoch 26; Iter    45/  183] train: loss: 0.1613110
[Epoch 26; Iter    75/  183] train: loss: 0.1260482
[Epoch 26; Iter   105/  183] train: loss: 0.1688276
[Epoch 26; Iter   135/  183] train: loss: 0.1197330
[Epoch 26; Iter   165/  183] train: loss: 0.1454797
[Epoch 26] ogbg-moltox21: 0.755468 val loss: 0.299112
[Epoch 26] ogbg-moltox21: 0.737719 test loss: 0.335646
[Epoch 27; Iter    12/  183] train: loss: 0.1790780
[Epoch 27; Iter    42/  183] train: loss: 0.1094673
[Epoch 27; Iter    72/  183] train: loss: 0.1270387
[Epoch 27; Iter   102/  183] train: loss: 0.1567905
[Epoch 27; Iter   132/  183] train: loss: 0.1440717
[Epoch 27; Iter   162/  183] train: loss: 0.1982958
[Epoch 27] ogbg-moltox21: 0.728470 val loss: 0.325377
[Epoch 27] ogbg-moltox21: 0.718986 test loss: 0.369932
[Epoch 28; Iter     9/  183] train: loss: 0.0893903
[Epoch 28; Iter    39/  183] train: loss: 0.1445705
[Epoch 28; Iter    69/  183] train: loss: 0.0902341
[Epoch 28; Iter    99/  183] train: loss: 0.1151811
[Epoch 28; Iter   129/  183] train: loss: 0.3100170
[Epoch 28; Iter   159/  183] train: loss: 0.1426380
[Epoch 28] ogbg-moltox21: 0.745958 val loss: 0.319118
[Epoch 28] ogbg-moltox21: 0.739201 test loss: 0.413372
[Epoch 29; Iter     6/  183] train: loss: 0.0972517
[Epoch 29; Iter    36/  183] train: loss: 0.1401372
[Epoch 29; Iter    66/  183] train: loss: 0.1940996
[Epoch 29; Iter    96/  183] train: loss: 0.1301575
[Epoch 29; Iter   126/  183] train: loss: 0.1355298
[Epoch 29; Iter   156/  183] train: loss: 0.2753284
[Epoch 29] ogbg-moltox21: 0.753192 val loss: 0.296049
[Epoch 29] ogbg-moltox21: 0.742729 test loss: 0.307441
[Epoch 30; Iter     3/  183] train: loss: 0.2005864
[Epoch 30; Iter    33/  183] train: loss: 0.1258455
[Epoch 30; Iter    63/  183] train: loss: 0.1915627
[Epoch 30; Iter    93/  183] train: loss: 0.1691194
[Epoch 30; Iter   123/  183] train: loss: 0.1458449
[Epoch 30; Iter   153/  183] train: loss: 0.2157495
[Epoch 30; Iter   183/  183] train: loss: 0.1442079
[Epoch 30] ogbg-moltox21: 0.760752 val loss: 0.299299
[Epoch 30] ogbg-moltox21: 0.729771 test loss: 0.364672
[Epoch 31; Iter    30/  183] train: loss: 0.2204056
[Epoch 31; Iter    60/  183] train: loss: 0.1794889
[Epoch 31; Iter    90/  183] train: loss: 0.1120929
[Epoch 31; Iter   120/  183] train: loss: 0.1765803
[Epoch 31; Iter   150/  183] train: loss: 0.1556177
[Epoch 31; Iter   180/  183] train: loss: 0.1747587
[Epoch 31] ogbg-moltox21: 0.753670 val loss: 0.286176
[Epoch 31] ogbg-moltox21: 0.731098 test loss: 0.353150
[Epoch 32; Iter    27/  183] train: loss: 0.1201507
[Epoch 32; Iter    57/  183] train: loss: 0.1366522
[Epoch 32; Iter    87/  183] train: loss: 0.1768921
[Epoch 32; Iter   117/  183] train: loss: 0.1311001
[Epoch 32; Iter   147/  183] train: loss: 0.1117801
[Epoch 32; Iter   177/  183] train: loss: 0.1839347
[Epoch 32] ogbg-moltox21: 0.761171 val loss: 0.299920
[Epoch 32] ogbg-moltox21: 0.752949 test loss: 0.305166
[Epoch 33; Iter    24/  183] train: loss: 0.1753529
[Epoch 33; Iter    54/  183] train: loss: 0.1451504
[Epoch 33; Iter    84/  183] train: loss: 0.1958110
[Epoch 14; Iter    81/  183] train: loss: 0.1798260
[Epoch 14; Iter   111/  183] train: loss: 0.2341019
[Epoch 14; Iter   141/  183] train: loss: 0.2016750
[Epoch 14; Iter   171/  183] train: loss: 0.2096528
[Epoch 14] ogbg-moltox21: 0.697592 val loss: 0.281790
[Epoch 14] ogbg-moltox21: 0.707227 test loss: 0.284060
[Epoch 15; Iter    18/  183] train: loss: 0.1706967
[Epoch 15; Iter    48/  183] train: loss: 0.2069059
[Epoch 15; Iter    78/  183] train: loss: 0.1347230
[Epoch 15; Iter   108/  183] train: loss: 0.1371602
[Epoch 15; Iter   138/  183] train: loss: 0.1056743
[Epoch 15; Iter   168/  183] train: loss: 0.1387659
[Epoch 15] ogbg-moltox21: 0.729620 val loss: 0.279150
[Epoch 15] ogbg-moltox21: 0.729827 test loss: 0.279043
[Epoch 16; Iter    15/  183] train: loss: 0.1561425
[Epoch 16; Iter    45/  183] train: loss: 0.1977938
[Epoch 16; Iter    75/  183] train: loss: 0.1551504
[Epoch 16; Iter   105/  183] train: loss: 0.1972878
[Epoch 16; Iter   135/  183] train: loss: 0.1249602
[Epoch 16; Iter   165/  183] train: loss: 0.2156374
[Epoch 16] ogbg-moltox21: 0.726123 val loss: 0.282001
[Epoch 16] ogbg-moltox21: 0.729686 test loss: 0.282966
[Epoch 17; Iter    12/  183] train: loss: 0.2583269
[Epoch 17; Iter    42/  183] train: loss: 0.2050503
[Epoch 17; Iter    72/  183] train: loss: 0.1864455
[Epoch 17; Iter   102/  183] train: loss: 0.1536888
[Epoch 17; Iter   132/  183] train: loss: 0.1290295
[Epoch 17; Iter   162/  183] train: loss: 0.1028952
[Epoch 17] ogbg-moltox21: 0.734415 val loss: 0.301617
[Epoch 17] ogbg-moltox21: 0.737720 test loss: 0.302414
[Epoch 18; Iter     9/  183] train: loss: 0.1541395
[Epoch 18; Iter    39/  183] train: loss: 0.2151788
[Epoch 18; Iter    69/  183] train: loss: 0.1492372
[Epoch 18; Iter    99/  183] train: loss: 0.1955202
[Epoch 18; Iter   129/  183] train: loss: 0.0990402
[Epoch 18; Iter   159/  183] train: loss: 0.2222469
[Epoch 18] ogbg-moltox21: 0.719397 val loss: 0.420416
[Epoch 18] ogbg-moltox21: 0.717122 test loss: 0.449479
[Epoch 19; Iter     6/  183] train: loss: 0.1010562
[Epoch 19; Iter    36/  183] train: loss: 0.1902944
[Epoch 19; Iter    66/  183] train: loss: 0.1133123
[Epoch 19; Iter    96/  183] train: loss: 0.2236939
[Epoch 19; Iter   126/  183] train: loss: 0.1182681
[Epoch 19; Iter   156/  183] train: loss: 0.1405136
[Epoch 19] ogbg-moltox21: 0.747622 val loss: 0.289035
[Epoch 19] ogbg-moltox21: 0.743264 test loss: 0.282942
[Epoch 20; Iter     3/  183] train: loss: 0.1235360
[Epoch 20; Iter    33/  183] train: loss: 0.1860375
[Epoch 20; Iter    63/  183] train: loss: 0.1246746
[Epoch 20; Iter    93/  183] train: loss: 0.2561721
[Epoch 20; Iter   123/  183] train: loss: 0.2090635
[Epoch 20; Iter   153/  183] train: loss: 0.1542017
[Epoch 20; Iter   183/  183] train: loss: 0.1340692
[Epoch 20] ogbg-moltox21: 0.755762 val loss: 0.279472
[Epoch 20] ogbg-moltox21: 0.753098 test loss: 0.279360
[Epoch 21; Iter    30/  183] train: loss: 0.1069381
[Epoch 21; Iter    60/  183] train: loss: 0.1917990
[Epoch 21; Iter    90/  183] train: loss: 0.1757026
[Epoch 21; Iter   120/  183] train: loss: 0.1504650
[Epoch 21; Iter   150/  183] train: loss: 0.1414247
[Epoch 21; Iter   180/  183] train: loss: 0.1043839
[Epoch 21] ogbg-moltox21: 0.758031 val loss: 0.285606
[Epoch 21] ogbg-moltox21: 0.746983 test loss: 0.291243
[Epoch 22; Iter    27/  183] train: loss: 0.1460339
[Epoch 22; Iter    57/  183] train: loss: 0.1553674
[Epoch 22; Iter    87/  183] train: loss: 0.1289864
[Epoch 22; Iter   117/  183] train: loss: 0.1183708
[Epoch 22; Iter   147/  183] train: loss: 0.1699407
[Epoch 22; Iter   177/  183] train: loss: 0.1256137
[Epoch 22] ogbg-moltox21: 0.760943 val loss: 0.287293
[Epoch 22] ogbg-moltox21: 0.748511 test loss: 0.283434
[Epoch 23; Iter    24/  183] train: loss: 0.2069602
[Epoch 23; Iter    54/  183] train: loss: 0.2037716
[Epoch 23; Iter    84/  183] train: loss: 0.1724206
[Epoch 23; Iter   114/  183] train: loss: 0.2120776
[Epoch 23; Iter   144/  183] train: loss: 0.1351439
[Epoch 23; Iter   174/  183] train: loss: 0.0864248
[Epoch 23] ogbg-moltox21: 0.758814 val loss: 0.380397
[Epoch 23] ogbg-moltox21: 0.744369 test loss: 0.276322
[Epoch 24; Iter    21/  183] train: loss: 0.1372694
[Epoch 24; Iter    51/  183] train: loss: 0.1595486
[Epoch 24; Iter    81/  183] train: loss: 0.0759734
[Epoch 24; Iter   111/  183] train: loss: 0.2004705
[Epoch 24; Iter   141/  183] train: loss: 0.2337777
[Epoch 24; Iter   171/  183] train: loss: 0.1149608
[Epoch 24] ogbg-moltox21: 0.758134 val loss: 0.269876
[Epoch 24] ogbg-moltox21: 0.745765 test loss: 0.282750
[Epoch 25; Iter    18/  183] train: loss: 0.2240243
[Epoch 25; Iter    48/  183] train: loss: 0.1834886
[Epoch 25; Iter    78/  183] train: loss: 0.1464037
[Epoch 25; Iter   108/  183] train: loss: 0.1210342
[Epoch 25; Iter   138/  183] train: loss: 0.1122171
[Epoch 25; Iter   168/  183] train: loss: 0.1458671
[Epoch 25] ogbg-moltox21: 0.757846 val loss: 0.272223
[Epoch 25] ogbg-moltox21: 0.747696 test loss: 0.287336
[Epoch 26; Iter    15/  183] train: loss: 0.1239389
[Epoch 26; Iter    45/  183] train: loss: 0.0861304
[Epoch 26; Iter    75/  183] train: loss: 0.1189028
[Epoch 26; Iter   105/  183] train: loss: 0.1611142
[Epoch 26; Iter   135/  183] train: loss: 0.1688986
[Epoch 26; Iter   165/  183] train: loss: 0.1483263
[Epoch 26] ogbg-moltox21: 0.756072 val loss: 0.268030
[Epoch 26] ogbg-moltox21: 0.738208 test loss: 0.276818
[Epoch 27; Iter    12/  183] train: loss: 0.1466511
[Epoch 27; Iter    42/  183] train: loss: 0.1237003
[Epoch 27; Iter    72/  183] train: loss: 0.1746675
[Epoch 27; Iter   102/  183] train: loss: 0.1490317
[Epoch 27; Iter   132/  183] train: loss: 0.1153123
[Epoch 27; Iter   162/  183] train: loss: 0.1077935
[Epoch 27] ogbg-moltox21: 0.759540 val loss: 0.330023
[Epoch 27] ogbg-moltox21: 0.746051 test loss: 0.401913
[Epoch 28; Iter     9/  183] train: loss: 0.1659882
[Epoch 28; Iter    39/  183] train: loss: 0.1263367
[Epoch 28; Iter    69/  183] train: loss: 0.1322438
[Epoch 28; Iter    99/  183] train: loss: 0.2268609
[Epoch 28; Iter   129/  183] train: loss: 0.1505381
[Epoch 28; Iter   159/  183] train: loss: 0.1428551
[Epoch 28] ogbg-moltox21: 0.758393 val loss: 0.276159
[Epoch 28] ogbg-moltox21: 0.745108 test loss: 0.282530
[Epoch 29; Iter     6/  183] train: loss: 0.1162636
[Epoch 29; Iter    36/  183] train: loss: 0.1711384
[Epoch 29; Iter    66/  183] train: loss: 0.1434563
[Epoch 29; Iter    96/  183] train: loss: 0.3177869
[Epoch 29; Iter   126/  183] train: loss: 0.1770099
[Epoch 29; Iter   156/  183] train: loss: 0.1905148
[Epoch 29] ogbg-moltox21: 0.763401 val loss: 0.267577
[Epoch 29] ogbg-moltox21: 0.751295 test loss: 0.277547
[Epoch 30; Iter     3/  183] train: loss: 0.1323596
[Epoch 30; Iter    33/  183] train: loss: 0.1591360
[Epoch 30; Iter    63/  183] train: loss: 0.1035519
[Epoch 30; Iter    93/  183] train: loss: 0.1263943
[Epoch 30; Iter   123/  183] train: loss: 0.1358199
[Epoch 30; Iter   153/  183] train: loss: 0.1944215
[Epoch 30; Iter   183/  183] train: loss: 0.1306249
[Epoch 30] ogbg-moltox21: 0.761522 val loss: 0.277665
[Epoch 30] ogbg-moltox21: 0.742871 test loss: 0.295059
[Epoch 31; Iter    30/  183] train: loss: 0.1472195
[Epoch 31; Iter    60/  183] train: loss: 0.2112506
[Epoch 31; Iter    90/  183] train: loss: 0.1325786
[Epoch 31; Iter   120/  183] train: loss: 0.2811672
[Epoch 31; Iter   150/  183] train: loss: 0.2370156
[Epoch 31; Iter   180/  183] train: loss: 0.1609153
[Epoch 31] ogbg-moltox21: 0.763996 val loss: 0.268119
[Epoch 31] ogbg-moltox21: 0.752917 test loss: 0.279922
[Epoch 32; Iter    27/  183] train: loss: 0.1225033
[Epoch 32; Iter    57/  183] train: loss: 0.1013272
[Epoch 32; Iter    87/  183] train: loss: 0.1611696
[Epoch 32; Iter   117/  183] train: loss: 0.2619544
[Epoch 32; Iter   147/  183] train: loss: 0.1791864
[Epoch 32; Iter   177/  183] train: loss: 0.1377060
[Epoch 32] ogbg-moltox21: 0.769512 val loss: 0.262005
[Epoch 32] ogbg-moltox21: 0.745183 test loss: 0.281863
[Epoch 33; Iter    24/  183] train: loss: 0.1648214
[Epoch 33; Iter    54/  183] train: loss: 0.0864334
[Epoch 33; Iter    84/  183] train: loss: 0.1217940
[Epoch 15] ogbg-moltox21: 0.720727 test loss: 0.365430
[Epoch 16; Iter    15/  157] train: loss: 0.1843676
[Epoch 16; Iter    45/  157] train: loss: 0.1375252
[Epoch 16; Iter    75/  157] train: loss: 0.0965034
[Epoch 16; Iter   105/  157] train: loss: 0.1730841
[Epoch 16; Iter   135/  157] train: loss: 0.2016215
[Epoch 16] ogbg-moltox21: 0.753042 val loss: 0.347498
[Epoch 16] ogbg-moltox21: 0.733673 test loss: 0.376299
[Epoch 17; Iter     8/  157] train: loss: 0.1380032
[Epoch 17; Iter    38/  157] train: loss: 0.2344684
[Epoch 17; Iter    68/  157] train: loss: 0.1157091
[Epoch 17; Iter    98/  157] train: loss: 0.1446964
[Epoch 17; Iter   128/  157] train: loss: 0.1489549
[Epoch 17] ogbg-moltox21: 0.759454 val loss: 0.351514
[Epoch 17] ogbg-moltox21: 0.744876 test loss: 0.340265
[Epoch 18; Iter     1/  157] train: loss: 0.1318074
[Epoch 18; Iter    31/  157] train: loss: 0.1432925
[Epoch 18; Iter    61/  157] train: loss: 0.1914609
[Epoch 18; Iter    91/  157] train: loss: 0.1553312
[Epoch 18; Iter   121/  157] train: loss: 0.1085890
[Epoch 18; Iter   151/  157] train: loss: 0.2289685
[Epoch 18] ogbg-moltox21: 0.748032 val loss: 0.378630
[Epoch 18] ogbg-moltox21: 0.730903 test loss: 0.367236
[Epoch 19; Iter    24/  157] train: loss: 0.1530526
[Epoch 19; Iter    54/  157] train: loss: 0.2424624
[Epoch 19; Iter    84/  157] train: loss: 0.1642300
[Epoch 19; Iter   114/  157] train: loss: 0.1783988
[Epoch 19; Iter   144/  157] train: loss: 0.1022360
[Epoch 19] ogbg-moltox21: 0.759623 val loss: 0.384004
[Epoch 19] ogbg-moltox21: 0.739126 test loss: 0.458988
[Epoch 20; Iter    17/  157] train: loss: 0.1550837
[Epoch 20; Iter    47/  157] train: loss: 0.1059312
[Epoch 20; Iter    77/  157] train: loss: 0.1644077
[Epoch 20; Iter   107/  157] train: loss: 0.1462729
[Epoch 20; Iter   137/  157] train: loss: 0.1600624
[Epoch 20] ogbg-moltox21: 0.745626 val loss: 0.307694
[Epoch 20] ogbg-moltox21: 0.741757 test loss: 0.318550
[Epoch 21; Iter    10/  157] train: loss: 0.1145424
[Epoch 21; Iter    40/  157] train: loss: 0.1991350
[Epoch 21; Iter    70/  157] train: loss: 0.1777061
[Epoch 21; Iter   100/  157] train: loss: 0.1429435
[Epoch 21; Iter   130/  157] train: loss: 0.1565231
[Epoch 21] ogbg-moltox21: 0.760300 val loss: 0.316449
[Epoch 21] ogbg-moltox21: 0.750945 test loss: 0.344982
[Epoch 22; Iter     3/  157] train: loss: 0.1437488
[Epoch 22; Iter    33/  157] train: loss: 0.2148494
[Epoch 22; Iter    63/  157] train: loss: 0.1596839
[Epoch 22; Iter    93/  157] train: loss: 0.1429783
[Epoch 22; Iter   123/  157] train: loss: 0.1224749
[Epoch 22; Iter   153/  157] train: loss: 0.1704068
[Epoch 22] ogbg-moltox21: 0.764227 val loss: 0.294276
[Epoch 22] ogbg-moltox21: 0.756335 test loss: 0.317624
[Epoch 23; Iter    26/  157] train: loss: 0.1662109
[Epoch 23; Iter    56/  157] train: loss: 0.1171271
[Epoch 23; Iter    86/  157] train: loss: 0.1306242
[Epoch 23; Iter   116/  157] train: loss: 0.2269794
[Epoch 23; Iter   146/  157] train: loss: 0.1145966
[Epoch 23] ogbg-moltox21: 0.730186 val loss: 0.294249
[Epoch 23] ogbg-moltox21: 0.723235 test loss: 0.302288
[Epoch 24; Iter    19/  157] train: loss: 0.1616184
[Epoch 24; Iter    49/  157] train: loss: 0.1597279
[Epoch 24; Iter    79/  157] train: loss: 0.1436862
[Epoch 24; Iter   109/  157] train: loss: 0.0975110
[Epoch 24; Iter   139/  157] train: loss: 0.2048268
[Epoch 24] ogbg-moltox21: 0.766854 val loss: 0.322635
[Epoch 24] ogbg-moltox21: 0.750511 test loss: 0.390106
[Epoch 25; Iter    12/  157] train: loss: 0.1216942
[Epoch 25; Iter    42/  157] train: loss: 0.1568380
[Epoch 25; Iter    72/  157] train: loss: 0.2444250
[Epoch 25; Iter   102/  157] train: loss: 0.1840248
[Epoch 25; Iter   132/  157] train: loss: 0.1193955
[Epoch 25] ogbg-moltox21: 0.729446 val loss: 0.394274
[Epoch 25] ogbg-moltox21: 0.722744 test loss: 0.374946
[Epoch 26; Iter     5/  157] train: loss: 0.1761349
[Epoch 26; Iter    35/  157] train: loss: 0.2054581
[Epoch 26; Iter    65/  157] train: loss: 0.1335211
[Epoch 26; Iter    95/  157] train: loss: 0.1569823
[Epoch 26; Iter   125/  157] train: loss: 0.2744268
[Epoch 26; Iter   155/  157] train: loss: 0.1841413
[Epoch 26] ogbg-moltox21: 0.758692 val loss: 0.424676
[Epoch 26] ogbg-moltox21: 0.751634 test loss: 0.405935
[Epoch 27; Iter    28/  157] train: loss: 0.1354208
[Epoch 27; Iter    58/  157] train: loss: 0.1144894
[Epoch 27; Iter    88/  157] train: loss: 0.1276145
[Epoch 27; Iter   118/  157] train: loss: 0.1929263
[Epoch 27; Iter   148/  157] train: loss: 0.2038610
[Epoch 27] ogbg-moltox21: 0.754433 val loss: 0.370116
[Epoch 27] ogbg-moltox21: 0.739160 test loss: 0.350758
[Epoch 28; Iter    21/  157] train: loss: 0.1681894
[Epoch 28; Iter    51/  157] train: loss: 0.2151919
[Epoch 28; Iter    81/  157] train: loss: 0.1230211
[Epoch 28; Iter   111/  157] train: loss: 0.1308976
[Epoch 28; Iter   141/  157] train: loss: 0.1962151
[Epoch 28] ogbg-moltox21: 0.764722 val loss: 0.480039
[Epoch 28] ogbg-moltox21: 0.745327 test loss: 0.353878
[Epoch 29; Iter    14/  157] train: loss: 0.1635690
[Epoch 29; Iter    44/  157] train: loss: 0.1085205
[Epoch 29; Iter    74/  157] train: loss: 0.1446896
[Epoch 29; Iter   104/  157] train: loss: 0.1708577
[Epoch 29; Iter   134/  157] train: loss: 0.1568094
[Epoch 29] ogbg-moltox21: 0.760540 val loss: 0.475367
[Epoch 29] ogbg-moltox21: 0.740452 test loss: 0.931863
[Epoch 30; Iter     7/  157] train: loss: 0.1445410
[Epoch 30; Iter    37/  157] train: loss: 0.1218125
[Epoch 30; Iter    67/  157] train: loss: 0.1356671
[Epoch 30; Iter    97/  157] train: loss: 0.1445059
[Epoch 30; Iter   127/  157] train: loss: 0.1545524
[Epoch 30; Iter   157/  157] train: loss: 0.2024908
[Epoch 30] ogbg-moltox21: 0.754508 val loss: 0.415303
[Epoch 30] ogbg-moltox21: 0.746236 test loss: 0.615534
[Epoch 31; Iter    30/  157] train: loss: 0.1703945
[Epoch 31; Iter    60/  157] train: loss: 0.0747764
[Epoch 31; Iter    90/  157] train: loss: 0.1676735
[Epoch 31; Iter   120/  157] train: loss: 0.1444329
[Epoch 31; Iter   150/  157] train: loss: 0.1411567
[Epoch 31] ogbg-moltox21: 0.763090 val loss: 0.514426
[Epoch 31] ogbg-moltox21: 0.753073 test loss: 0.379977
[Epoch 32; Iter    23/  157] train: loss: 0.1314397
[Epoch 32; Iter    53/  157] train: loss: 0.0954866
[Epoch 32; Iter    83/  157] train: loss: 0.1879574
[Epoch 32; Iter   113/  157] train: loss: 0.1156965
[Epoch 32; Iter   143/  157] train: loss: 0.2213604
[Epoch 32] ogbg-moltox21: 0.771170 val loss: 0.325154
[Epoch 32] ogbg-moltox21: 0.746381 test loss: 0.667044
[Epoch 33; Iter    16/  157] train: loss: 0.1383967
[Epoch 33; Iter    46/  157] train: loss: 0.1093758
[Epoch 33; Iter    76/  157] train: loss: 0.1503165
[Epoch 33; Iter   106/  157] train: loss: 0.1531851
[Epoch 33; Iter   136/  157] train: loss: 0.1623890
[Epoch 33] ogbg-moltox21: 0.769692 val loss: 0.332693
[Epoch 33] ogbg-moltox21: 0.757154 test loss: 0.922801
[Epoch 34; Iter     9/  157] train: loss: 0.1254755
[Epoch 34; Iter    39/  157] train: loss: 0.1466064
[Epoch 34; Iter    69/  157] train: loss: 0.1215936
[Epoch 34; Iter    99/  157] train: loss: 0.1687070
[Epoch 34; Iter   129/  157] train: loss: 0.0978270
[Epoch 34] ogbg-moltox21: 0.772127 val loss: 0.445502
[Epoch 34] ogbg-moltox21: 0.753165 test loss: 0.382768
[Epoch 35; Iter     2/  157] train: loss: 0.1155060
[Epoch 35; Iter    32/  157] train: loss: 0.1396300
[Epoch 35; Iter    62/  157] train: loss: 0.0890643
[Epoch 35; Iter    92/  157] train: loss: 0.1335735
[Epoch 35; Iter   122/  157] train: loss: 0.1254535
[Epoch 35; Iter   152/  157] train: loss: 0.1675743
[Epoch 35] ogbg-moltox21: 0.778643 val loss: 0.381678
[Epoch 35] ogbg-moltox21: 0.754082 test loss: 0.514496
[Epoch 36; Iter    25/  157] train: loss: 0.1491889
[Epoch 36; Iter    55/  157] train: loss: 0.1196952
[Epoch 36; Iter    85/  157] train: loss: 0.1252600
[Epoch 36; Iter   115/  157] train: loss: 0.1330606
[Epoch 36; Iter   145/  157] train: loss: 0.1105163
[Epoch 36] ogbg-moltox21: 0.759938 val loss: 0.314870
[Epoch 36] ogbg-moltox21: 0.746126 test loss: 0.370590
[Epoch 37; Iter    18/  157] train: loss: 0.1519948
[Epoch 37; Iter    48/  157] train: loss: 0.1284493
[Epoch 15] ogbg-moltox21: 0.721515 test loss: 0.731801
[Epoch 16; Iter    15/  157] train: loss: 0.1327564
[Epoch 16; Iter    45/  157] train: loss: 0.2021635
[Epoch 16; Iter    75/  157] train: loss: 0.1200745
[Epoch 16; Iter   105/  157] train: loss: 0.1648905
[Epoch 16; Iter   135/  157] train: loss: 0.1269674
[Epoch 16] ogbg-moltox21: 0.745369 val loss: 0.430870
[Epoch 16] ogbg-moltox21: 0.720065 test loss: 0.598094
[Epoch 17; Iter     8/  157] train: loss: 0.2571541
[Epoch 17; Iter    38/  157] train: loss: 0.1306164
[Epoch 17; Iter    68/  157] train: loss: 0.1053009
[Epoch 17; Iter    98/  157] train: loss: 0.1417980
[Epoch 17; Iter   128/  157] train: loss: 0.1670592
[Epoch 17] ogbg-moltox21: 0.734757 val loss: 0.877200
[Epoch 17] ogbg-moltox21: 0.717406 test loss: 1.194348
[Epoch 18; Iter     1/  157] train: loss: 0.1926186
[Epoch 18; Iter    31/  157] train: loss: 0.2058182
[Epoch 18; Iter    61/  157] train: loss: 0.1662548
[Epoch 18; Iter    91/  157] train: loss: 0.1091455
[Epoch 18; Iter   121/  157] train: loss: 0.0879400
[Epoch 18; Iter   151/  157] train: loss: 0.2238253
[Epoch 18] ogbg-moltox21: 0.716810 val loss: 10.793718
[Epoch 18] ogbg-moltox21: 0.691761 test loss: 10.613733
[Epoch 19; Iter    24/  157] train: loss: 0.2119394
[Epoch 19; Iter    54/  157] train: loss: 0.1541599
[Epoch 19; Iter    84/  157] train: loss: 0.1332099
[Epoch 19; Iter   114/  157] train: loss: 0.1867879
[Epoch 19; Iter   144/  157] train: loss: 0.2219061
[Epoch 19] ogbg-moltox21: 0.749458 val loss: 0.543070
[Epoch 19] ogbg-moltox21: 0.714529 test loss: 0.643294
[Epoch 20; Iter    17/  157] train: loss: 0.1954670
[Epoch 20; Iter    47/  157] train: loss: 0.1435974
[Epoch 20; Iter    77/  157] train: loss: 0.1703426
[Epoch 20; Iter   107/  157] train: loss: 0.1371314
[Epoch 20; Iter   137/  157] train: loss: 0.1165445
[Epoch 20] ogbg-moltox21: 0.764040 val loss: 0.312625
[Epoch 20] ogbg-moltox21: 0.745086 test loss: 0.335992
[Epoch 21; Iter    10/  157] train: loss: 0.1609711
[Epoch 21; Iter    40/  157] train: loss: 0.1133176
[Epoch 21; Iter    70/  157] train: loss: 0.1691743
[Epoch 21; Iter   100/  157] train: loss: 0.1442442
[Epoch 21; Iter   130/  157] train: loss: 0.0993393
[Epoch 21] ogbg-moltox21: 0.749736 val loss: 0.366047
[Epoch 21] ogbg-moltox21: 0.725562 test loss: 0.438261
[Epoch 22; Iter     3/  157] train: loss: 0.2270644
[Epoch 22; Iter    33/  157] train: loss: 0.1062508
[Epoch 22; Iter    63/  157] train: loss: 0.1430960
[Epoch 22; Iter    93/  157] train: loss: 0.1958778
[Epoch 22; Iter   123/  157] train: loss: 0.1409180
[Epoch 22; Iter   153/  157] train: loss: 0.1387601
[Epoch 22] ogbg-moltox21: 0.762873 val loss: 0.359841
[Epoch 22] ogbg-moltox21: 0.727123 test loss: 0.428524
[Epoch 23; Iter    26/  157] train: loss: 0.1816758
[Epoch 23; Iter    56/  157] train: loss: 0.0757996
[Epoch 23; Iter    86/  157] train: loss: 0.1459237
[Epoch 23; Iter   116/  157] train: loss: 0.2016546
[Epoch 23; Iter   146/  157] train: loss: 0.0929957
[Epoch 23] ogbg-moltox21: 0.768253 val loss: 0.391411
[Epoch 23] ogbg-moltox21: 0.741237 test loss: 0.338923
[Epoch 24; Iter    19/  157] train: loss: 0.0858440
[Epoch 24; Iter    49/  157] train: loss: 0.1191193
[Epoch 24; Iter    79/  157] train: loss: 0.1751920
[Epoch 24; Iter   109/  157] train: loss: 0.1460421
[Epoch 24; Iter   139/  157] train: loss: 0.1480663
[Epoch 24] ogbg-moltox21: 0.777840 val loss: 0.494389
[Epoch 24] ogbg-moltox21: 0.734502 test loss: 0.714902
[Epoch 25; Iter    12/  157] train: loss: 0.1594128
[Epoch 25; Iter    42/  157] train: loss: 0.1883234
[Epoch 25; Iter    72/  157] train: loss: 0.1174073
[Epoch 25; Iter   102/  157] train: loss: 0.1273507
[Epoch 25; Iter   132/  157] train: loss: 0.2617534
[Epoch 25] ogbg-moltox21: 0.767898 val loss: 0.666802
[Epoch 25] ogbg-moltox21: 0.731460 test loss: 0.626771
[Epoch 26; Iter     5/  157] train: loss: 0.1851844
[Epoch 26; Iter    35/  157] train: loss: 0.1514281
[Epoch 26; Iter    65/  157] train: loss: 0.1906340
[Epoch 26; Iter    95/  157] train: loss: 0.1520902
[Epoch 26; Iter   125/  157] train: loss: 0.1450441
[Epoch 26; Iter   155/  157] train: loss: 0.0918459
[Epoch 26] ogbg-moltox21: 0.756371 val loss: 0.391832
[Epoch 26] ogbg-moltox21: 0.728626 test loss: 0.443654
[Epoch 27; Iter    28/  157] train: loss: 0.1758537
[Epoch 27; Iter    58/  157] train: loss: 0.1518429
[Epoch 27; Iter    88/  157] train: loss: 0.0870109
[Epoch 27; Iter   118/  157] train: loss: 0.1684760
[Epoch 27; Iter   148/  157] train: loss: 0.1897035
[Epoch 27] ogbg-moltox21: 0.777476 val loss: 0.372602
[Epoch 27] ogbg-moltox21: 0.743737 test loss: 0.421175
[Epoch 28; Iter    21/  157] train: loss: 0.2327836
[Epoch 28; Iter    51/  157] train: loss: 0.1793852
[Epoch 28; Iter    81/  157] train: loss: 0.1666472
[Epoch 28; Iter   111/  157] train: loss: 0.1340627
[Epoch 28; Iter   141/  157] train: loss: 0.1351493
[Epoch 28] ogbg-moltox21: 0.762380 val loss: 0.328842
[Epoch 28] ogbg-moltox21: 0.740026 test loss: 0.646564
[Epoch 29; Iter    14/  157] train: loss: 0.1417014
[Epoch 29; Iter    44/  157] train: loss: 0.1358489
[Epoch 29; Iter    74/  157] train: loss: 0.1532091
[Epoch 29; Iter   104/  157] train: loss: 0.1180219
[Epoch 29; Iter   134/  157] train: loss: 0.1511702
[Epoch 29] ogbg-moltox21: 0.753341 val loss: 2.994155
[Epoch 29] ogbg-moltox21: 0.737020 test loss: 4.423782
[Epoch 30; Iter     7/  157] train: loss: 0.1927372
[Epoch 30; Iter    37/  157] train: loss: 0.1383704
[Epoch 30; Iter    67/  157] train: loss: 0.1217445
[Epoch 30; Iter    97/  157] train: loss: 0.1577309
[Epoch 30; Iter   127/  157] train: loss: 0.1060319
[Epoch 30; Iter   157/  157] train: loss: 0.1794890
[Epoch 30] ogbg-moltox21: 0.774963 val loss: 0.471899
[Epoch 30] ogbg-moltox21: 0.739999 test loss: 1.165257
[Epoch 31; Iter    30/  157] train: loss: 0.2321112
[Epoch 31; Iter    60/  157] train: loss: 0.0892083
[Epoch 31; Iter    90/  157] train: loss: 0.1589541
[Epoch 31; Iter   120/  157] train: loss: 0.1190905
[Epoch 31; Iter   150/  157] train: loss: 0.1306485
[Epoch 31] ogbg-moltox21: 0.767713 val loss: 0.330001
[Epoch 31] ogbg-moltox21: 0.745887 test loss: 0.355449
[Epoch 32; Iter    23/  157] train: loss: 0.1010214
[Epoch 32; Iter    53/  157] train: loss: 0.1096512
[Epoch 32; Iter    83/  157] train: loss: 0.2009069
[Epoch 32; Iter   113/  157] train: loss: 0.1365570
[Epoch 32; Iter   143/  157] train: loss: 0.1515868
[Epoch 32] ogbg-moltox21: 0.765086 val loss: 0.510918
[Epoch 32] ogbg-moltox21: 0.751178 test loss: 1.430819
[Epoch 33; Iter    16/  157] train: loss: 0.1419979
[Epoch 33; Iter    46/  157] train: loss: 0.1153946
[Epoch 33; Iter    76/  157] train: loss: 0.1026401
[Epoch 33; Iter   106/  157] train: loss: 0.1686264
[Epoch 33; Iter   136/  157] train: loss: 0.1644659
[Epoch 33] ogbg-moltox21: 0.783170 val loss: 0.320928
[Epoch 33] ogbg-moltox21: 0.744019 test loss: 0.388289
[Epoch 34; Iter     9/  157] train: loss: 0.1430683
[Epoch 34; Iter    39/  157] train: loss: 0.0656323
[Epoch 34; Iter    69/  157] train: loss: 0.1274792
[Epoch 34; Iter    99/  157] train: loss: 0.1361906
[Epoch 34; Iter   129/  157] train: loss: 0.0855130
[Epoch 34] ogbg-moltox21: 0.770050 val loss: 0.326876
[Epoch 34] ogbg-moltox21: 0.745519 test loss: 0.413731
[Epoch 35; Iter     2/  157] train: loss: 0.1384043
[Epoch 35; Iter    32/  157] train: loss: 0.1012588
[Epoch 35; Iter    62/  157] train: loss: 0.1364771
[Epoch 35; Iter    92/  157] train: loss: 0.0765027
[Epoch 35; Iter   122/  157] train: loss: 0.1455407
[Epoch 35; Iter   152/  157] train: loss: 0.1136461
[Epoch 35] ogbg-moltox21: 0.761108 val loss: 0.348847
[Epoch 35] ogbg-moltox21: 0.740743 test loss: 0.415445
[Epoch 36; Iter    25/  157] train: loss: 0.1697881
[Epoch 36; Iter    55/  157] train: loss: 0.1626183
[Epoch 36; Iter    85/  157] train: loss: 0.1139997
[Epoch 36; Iter   115/  157] train: loss: 0.1119176
[Epoch 36; Iter   145/  157] train: loss: 0.1200980
[Epoch 36] ogbg-moltox21: 0.779546 val loss: 0.312144
[Epoch 36] ogbg-moltox21: 0.752260 test loss: 0.532430
[Epoch 37; Iter    18/  157] train: loss: 0.1360850
[Epoch 37; Iter    48/  157] train: loss: 0.1401043
[Epoch 15] ogbg-moltox21: 0.736192 test loss: 0.409912
[Epoch 16; Iter    15/  157] train: loss: 0.1715807
[Epoch 16; Iter    45/  157] train: loss: 0.2120203
[Epoch 16; Iter    75/  157] train: loss: 0.1690667
[Epoch 16; Iter   105/  157] train: loss: 0.0973446
[Epoch 16; Iter   135/  157] train: loss: 0.1185502
[Epoch 16] ogbg-moltox21: 0.767473 val loss: 0.502010
[Epoch 16] ogbg-moltox21: 0.741177 test loss: 0.538565
[Epoch 17; Iter     8/  157] train: loss: 0.1690242
[Epoch 17; Iter    38/  157] train: loss: 0.1567748
[Epoch 17; Iter    68/  157] train: loss: 0.1248154
[Epoch 17; Iter    98/  157] train: loss: 0.1792492
[Epoch 17; Iter   128/  157] train: loss: 0.1932367
[Epoch 17] ogbg-moltox21: 0.768318 val loss: 0.569011
[Epoch 17] ogbg-moltox21: 0.742845 test loss: 0.673760
[Epoch 18; Iter     1/  157] train: loss: 0.1722170
[Epoch 18; Iter    31/  157] train: loss: 0.1171209
[Epoch 18; Iter    61/  157] train: loss: 0.1034051
[Epoch 18; Iter    91/  157] train: loss: 0.1057798
[Epoch 18; Iter   121/  157] train: loss: 0.1016170
[Epoch 18; Iter   151/  157] train: loss: 0.1198002
[Epoch 18] ogbg-moltox21: 0.758450 val loss: 0.354895
[Epoch 18] ogbg-moltox21: 0.734111 test loss: 0.389277
[Epoch 19; Iter    24/  157] train: loss: 0.1519510
[Epoch 19; Iter    54/  157] train: loss: 0.1262323
[Epoch 19; Iter    84/  157] train: loss: 0.2510500
[Epoch 19; Iter   114/  157] train: loss: 0.1844369
[Epoch 19; Iter   144/  157] train: loss: 0.1171992
[Epoch 19] ogbg-moltox21: 0.757556 val loss: 0.372571
[Epoch 19] ogbg-moltox21: 0.743865 test loss: 0.396398
[Epoch 20; Iter    17/  157] train: loss: 0.1386465
[Epoch 20; Iter    47/  157] train: loss: 0.1951064
[Epoch 20; Iter    77/  157] train: loss: 0.1450238
[Epoch 20; Iter   107/  157] train: loss: 0.1568390
[Epoch 20; Iter   137/  157] train: loss: 0.1373464
[Epoch 20] ogbg-moltox21: 0.753858 val loss: 0.349635
[Epoch 20] ogbg-moltox21: 0.743951 test loss: 0.366193
[Epoch 21; Iter    10/  157] train: loss: 0.1467105
[Epoch 21; Iter    40/  157] train: loss: 0.1483406
[Epoch 21; Iter    70/  157] train: loss: 0.1768986
[Epoch 21; Iter   100/  157] train: loss: 0.1981915
[Epoch 21; Iter   130/  157] train: loss: 0.1498631
[Epoch 21] ogbg-moltox21: 0.756847 val loss: 0.308499
[Epoch 21] ogbg-moltox21: 0.739257 test loss: 0.335685
[Epoch 22; Iter     3/  157] train: loss: 0.2429785
[Epoch 22; Iter    33/  157] train: loss: 0.1023953
[Epoch 22; Iter    63/  157] train: loss: 0.2340837
[Epoch 22; Iter    93/  157] train: loss: 0.1233293
[Epoch 22; Iter   123/  157] train: loss: 0.1162488
[Epoch 22; Iter   153/  157] train: loss: 0.0941790
[Epoch 22] ogbg-moltox21: 0.767382 val loss: 0.301012
[Epoch 22] ogbg-moltox21: 0.744530 test loss: 0.326634
[Epoch 23; Iter    26/  157] train: loss: 0.1606509
[Epoch 23; Iter    56/  157] train: loss: 0.1240539
[Epoch 23; Iter    86/  157] train: loss: 0.1278710
[Epoch 23; Iter   116/  157] train: loss: 0.1853457
[Epoch 23; Iter   146/  157] train: loss: 0.2805283
[Epoch 23] ogbg-moltox21: 0.763059 val loss: 0.318077
[Epoch 23] ogbg-moltox21: 0.745318 test loss: 0.336363
[Epoch 24; Iter    19/  157] train: loss: 0.1637604
[Epoch 24; Iter    49/  157] train: loss: 0.1962805
[Epoch 24; Iter    79/  157] train: loss: 0.1407977
[Epoch 24; Iter   109/  157] train: loss: 0.1686710
[Epoch 24; Iter   139/  157] train: loss: 0.1846935
[Epoch 24] ogbg-moltox21: 0.756455 val loss: 0.334029
[Epoch 24] ogbg-moltox21: 0.735765 test loss: 0.359025
[Epoch 25; Iter    12/  157] train: loss: 0.1101221
[Epoch 25; Iter    42/  157] train: loss: 0.1169136
[Epoch 25; Iter    72/  157] train: loss: 0.1258282
[Epoch 25; Iter   102/  157] train: loss: 0.0643173
[Epoch 25; Iter   132/  157] train: loss: 0.1565107
[Epoch 25] ogbg-moltox21: 0.772139 val loss: 0.294632
[Epoch 25] ogbg-moltox21: 0.754951 test loss: 0.329167
[Epoch 26; Iter     5/  157] train: loss: 0.0976178
[Epoch 26; Iter    35/  157] train: loss: 0.1649946
[Epoch 26; Iter    65/  157] train: loss: 0.1765363
[Epoch 26; Iter    95/  157] train: loss: 0.1688753
[Epoch 26; Iter   125/  157] train: loss: 0.1086855
[Epoch 26; Iter   155/  157] train: loss: 0.1136350
[Epoch 26] ogbg-moltox21: 0.760711 val loss: 0.324162
[Epoch 26] ogbg-moltox21: 0.747055 test loss: 0.333128
[Epoch 27; Iter    28/  157] train: loss: 0.1241763
[Epoch 27; Iter    58/  157] train: loss: 0.2091317
[Epoch 27; Iter    88/  157] train: loss: 0.2230251
[Epoch 27; Iter   118/  157] train: loss: 0.1321498
[Epoch 27; Iter   148/  157] train: loss: 0.1064537
[Epoch 27] ogbg-moltox21: 0.758332 val loss: 0.294707
[Epoch 27] ogbg-moltox21: 0.741790 test loss: 0.795453
[Epoch 28; Iter    21/  157] train: loss: 0.0978779
[Epoch 28; Iter    51/  157] train: loss: 0.2015619
[Epoch 28; Iter    81/  157] train: loss: 0.1618872
[Epoch 28; Iter   111/  157] train: loss: 0.1824739
[Epoch 28; Iter   141/  157] train: loss: 0.0959007
[Epoch 28] ogbg-moltox21: 0.768066 val loss: 0.327287
[Epoch 28] ogbg-moltox21: 0.751725 test loss: 0.367442
[Epoch 29; Iter    14/  157] train: loss: 0.1242534
[Epoch 29; Iter    44/  157] train: loss: 0.1270202
[Epoch 29; Iter    74/  157] train: loss: 0.1500998
[Epoch 29; Iter   104/  157] train: loss: 0.1083501
[Epoch 29; Iter   134/  157] train: loss: 0.1664993
[Epoch 29] ogbg-moltox21: 0.770613 val loss: 0.346200
[Epoch 29] ogbg-moltox21: 0.757953 test loss: 0.389088
[Epoch 30; Iter     7/  157] train: loss: 0.1073507
[Epoch 30; Iter    37/  157] train: loss: 0.2608933
[Epoch 30; Iter    67/  157] train: loss: 0.1334665
[Epoch 30; Iter    97/  157] train: loss: 0.1330703
[Epoch 30; Iter   127/  157] train: loss: 0.0985527
[Epoch 30; Iter   157/  157] train: loss: 0.0747797
[Epoch 30] ogbg-moltox21: 0.769492 val loss: 0.397066
[Epoch 30] ogbg-moltox21: 0.745275 test loss: 0.502577
[Epoch 31; Iter    30/  157] train: loss: 0.1838078
[Epoch 31; Iter    60/  157] train: loss: 0.1126371
[Epoch 31; Iter    90/  157] train: loss: 0.1745806
[Epoch 31; Iter   120/  157] train: loss: 0.1447566
[Epoch 31; Iter   150/  157] train: loss: 0.1354116
[Epoch 31] ogbg-moltox21: 0.759058 val loss: 0.304014
[Epoch 31] ogbg-moltox21: 0.732372 test loss: 0.321450
[Epoch 32; Iter    23/  157] train: loss: 0.1890180
[Epoch 32; Iter    53/  157] train: loss: 0.0616044
[Epoch 32; Iter    83/  157] train: loss: 0.1395772
[Epoch 32; Iter   113/  157] train: loss: 0.2117563
[Epoch 32; Iter   143/  157] train: loss: 0.1526986
[Epoch 32] ogbg-moltox21: 0.753917 val loss: 0.312932
[Epoch 32] ogbg-moltox21: 0.748960 test loss: 0.311596
[Epoch 33; Iter    16/  157] train: loss: 0.1198560
[Epoch 33; Iter    46/  157] train: loss: 0.1601196
[Epoch 33; Iter    76/  157] train: loss: 0.1754699
[Epoch 33; Iter   106/  157] train: loss: 0.0793747
[Epoch 33; Iter   136/  157] train: loss: 0.1402063
[Epoch 33] ogbg-moltox21: 0.755455 val loss: 0.362150
[Epoch 33] ogbg-moltox21: 0.745459 test loss: 0.313212
[Epoch 34; Iter     9/  157] train: loss: 0.0879804
[Epoch 34; Iter    39/  157] train: loss: 0.0923479
[Epoch 34; Iter    69/  157] train: loss: 0.1157326
[Epoch 34; Iter    99/  157] train: loss: 0.1385291
[Epoch 34; Iter   129/  157] train: loss: 0.1630899
[Epoch 34] ogbg-moltox21: 0.758391 val loss: 0.307086
[Epoch 34] ogbg-moltox21: 0.744425 test loss: 0.314979
[Epoch 35; Iter     2/  157] train: loss: 0.1889665
[Epoch 35; Iter    32/  157] train: loss: 0.1623508
[Epoch 35; Iter    62/  157] train: loss: 0.1012074
[Epoch 35; Iter    92/  157] train: loss: 0.1016844
[Epoch 35; Iter   122/  157] train: loss: 0.1143842
[Epoch 35; Iter   152/  157] train: loss: 0.1332500
[Epoch 35] ogbg-moltox21: 0.757849 val loss: 0.306167
[Epoch 35] ogbg-moltox21: 0.745907 test loss: 0.316486
[Epoch 36; Iter    25/  157] train: loss: 0.0753566
[Epoch 36; Iter    55/  157] train: loss: 0.0997748
[Epoch 36; Iter    85/  157] train: loss: 0.0569609
[Epoch 36; Iter   115/  157] train: loss: 0.0876388
[Epoch 36; Iter   145/  157] train: loss: 0.1107286
[Epoch 36] ogbg-moltox21: 0.761584 val loss: 0.313728
[Epoch 36] ogbg-moltox21: 0.748567 test loss: 0.321859
[Epoch 37; Iter    18/  157] train: loss: 0.0715626
[Epoch 37; Iter    48/  157] train: loss: 0.1437554
[Epoch 30; Iter    89/  209] train: loss: 0.1224147
[Epoch 30; Iter   119/  209] train: loss: 0.1457242
[Epoch 30; Iter   149/  209] train: loss: 0.2123370
[Epoch 30; Iter   179/  209] train: loss: 0.1155644
[Epoch 30; Iter   209/  209] train: loss: 0.2364495
[Epoch 30] ogbg-moltox21: 0.795221 val loss: 0.243492
[Epoch 30] ogbg-moltox21: 0.752620 test loss: 0.260026
[Epoch 31; Iter    30/  209] train: loss: 0.1633060
[Epoch 31; Iter    60/  209] train: loss: 0.1735555
[Epoch 31; Iter    90/  209] train: loss: 0.1861417
[Epoch 31; Iter   120/  209] train: loss: 0.1230997
[Epoch 31; Iter   150/  209] train: loss: 0.1044679
[Epoch 31; Iter   180/  209] train: loss: 0.2074080
[Epoch 31] ogbg-moltox21: 0.803291 val loss: 0.242818
[Epoch 31] ogbg-moltox21: 0.758521 test loss: 0.261727
[Epoch 32; Iter     1/  209] train: loss: 0.2137122
[Epoch 32; Iter    31/  209] train: loss: 0.1272694
[Epoch 32; Iter    61/  209] train: loss: 0.0855184
[Epoch 32; Iter    91/  209] train: loss: 0.1849321
[Epoch 32; Iter   121/  209] train: loss: 0.1684620
[Epoch 32; Iter   151/  209] train: loss: 0.2568490
[Epoch 32; Iter   181/  209] train: loss: 0.2006419
[Epoch 32] ogbg-moltox21: 0.785766 val loss: 0.252279
[Epoch 32] ogbg-moltox21: 0.762879 test loss: 0.268826
[Epoch 33; Iter     2/  209] train: loss: 0.1103980
[Epoch 33; Iter    32/  209] train: loss: 0.1191845
[Epoch 33; Iter    62/  209] train: loss: 0.1195129
[Epoch 33; Iter    92/  209] train: loss: 0.1196826
[Epoch 33; Iter   122/  209] train: loss: 0.1522615
[Epoch 33; Iter   152/  209] train: loss: 0.2223448
[Epoch 33; Iter   182/  209] train: loss: 0.2293432
[Epoch 33] ogbg-moltox21: 0.793481 val loss: 0.252815
[Epoch 33] ogbg-moltox21: 0.766240 test loss: 0.266886
[Epoch 34; Iter     3/  209] train: loss: 0.1015419
[Epoch 34; Iter    33/  209] train: loss: 0.1620918
[Epoch 34; Iter    63/  209] train: loss: 0.1648026
[Epoch 34; Iter    93/  209] train: loss: 0.0863155
[Epoch 34; Iter   123/  209] train: loss: 0.1461048
[Epoch 34; Iter   153/  209] train: loss: 0.1059206
[Epoch 34; Iter   183/  209] train: loss: 0.1421909
[Epoch 34] ogbg-moltox21: 0.800997 val loss: 0.247254
[Epoch 34] ogbg-moltox21: 0.759805 test loss: 0.265579
[Epoch 35; Iter     4/  209] train: loss: 0.1803083
[Epoch 35; Iter    34/  209] train: loss: 0.1339176
[Epoch 35; Iter    64/  209] train: loss: 0.1522807
[Epoch 35; Iter    94/  209] train: loss: 0.1911875
[Epoch 35; Iter   124/  209] train: loss: 0.2190392
[Epoch 35; Iter   154/  209] train: loss: 0.1809826
[Epoch 35; Iter   184/  209] train: loss: 0.1261663
[Epoch 35] ogbg-moltox21: 0.801757 val loss: 0.246833
[Epoch 35] ogbg-moltox21: 0.753363 test loss: 0.305454
[Epoch 36; Iter     5/  209] train: loss: 0.1350143
[Epoch 36; Iter    35/  209] train: loss: 0.1117993
[Epoch 36; Iter    65/  209] train: loss: 0.1929459
[Epoch 36; Iter    95/  209] train: loss: 0.1268607
[Epoch 36; Iter   125/  209] train: loss: 0.2407677
[Epoch 36; Iter   155/  209] train: loss: 0.1250998
[Epoch 36; Iter   185/  209] train: loss: 0.1520507
[Epoch 36] ogbg-moltox21: 0.802230 val loss: 0.268866
[Epoch 36] ogbg-moltox21: 0.765827 test loss: 0.323468
[Epoch 37; Iter     6/  209] train: loss: 0.0805647
[Epoch 37; Iter    36/  209] train: loss: 0.1613425
[Epoch 37; Iter    66/  209] train: loss: 0.1349742
[Epoch 37; Iter    96/  209] train: loss: 0.1611369
[Epoch 37; Iter   126/  209] train: loss: 0.0884457
[Epoch 37; Iter   156/  209] train: loss: 0.0954600
[Epoch 37; Iter   186/  209] train: loss: 0.1421354
[Epoch 37] ogbg-moltox21: 0.773612 val loss: 0.253793
[Epoch 37] ogbg-moltox21: 0.740695 test loss: 0.319187
[Epoch 38; Iter     7/  209] train: loss: 0.1383151
[Epoch 38; Iter    37/  209] train: loss: 0.1600878
[Epoch 38; Iter    67/  209] train: loss: 0.1124929
[Epoch 38; Iter    97/  209] train: loss: 0.1369359
[Epoch 38; Iter   127/  209] train: loss: 0.1579656
[Epoch 38; Iter   157/  209] train: loss: 0.1103786
[Epoch 38; Iter   187/  209] train: loss: 0.1299660
[Epoch 38] ogbg-moltox21: 0.788689 val loss: 0.251544
[Epoch 38] ogbg-moltox21: 0.756913 test loss: 0.268213
[Epoch 39; Iter     8/  209] train: loss: 0.1548382
[Epoch 39; Iter    38/  209] train: loss: 0.1489869
[Epoch 39; Iter    68/  209] train: loss: 0.1646644
[Epoch 39; Iter    98/  209] train: loss: 0.1384147
[Epoch 39; Iter   128/  209] train: loss: 0.0977937
[Epoch 39; Iter   158/  209] train: loss: 0.1322260
[Epoch 39; Iter   188/  209] train: loss: 0.0897976
[Epoch 39] ogbg-moltox21: 0.789759 val loss: 0.262248
[Epoch 39] ogbg-moltox21: 0.746624 test loss: 0.291233
[Epoch 40; Iter     9/  209] train: loss: 0.1652956
[Epoch 40; Iter    39/  209] train: loss: 0.3048211
[Epoch 40; Iter    69/  209] train: loss: 0.1096555
[Epoch 40; Iter    99/  209] train: loss: 0.1079138
[Epoch 40; Iter   129/  209] train: loss: 0.1310809
[Epoch 40; Iter   159/  209] train: loss: 0.1136202
[Epoch 40; Iter   189/  209] train: loss: 0.1471188
[Epoch 40] ogbg-moltox21: 0.800627 val loss: 0.247586
[Epoch 40] ogbg-moltox21: 0.758975 test loss: 0.268543
[Epoch 41; Iter    10/  209] train: loss: 0.1123801
[Epoch 41; Iter    40/  209] train: loss: 0.0773277
[Epoch 41; Iter    70/  209] train: loss: 0.0930680
[Epoch 41; Iter   100/  209] train: loss: 0.1237271
[Epoch 41; Iter   130/  209] train: loss: 0.1460051
[Epoch 41; Iter   160/  209] train: loss: 0.1550782
[Epoch 41; Iter   190/  209] train: loss: 0.1203188
[Epoch 41] ogbg-moltox21: 0.797558 val loss: 0.246320
[Epoch 41] ogbg-moltox21: 0.761329 test loss: 0.270052
[Epoch 42; Iter    11/  209] train: loss: 0.0958586
[Epoch 42; Iter    41/  209] train: loss: 0.1259599
[Epoch 42; Iter    71/  209] train: loss: 0.0987325
[Epoch 42; Iter   101/  209] train: loss: 0.1011397
[Epoch 42; Iter   131/  209] train: loss: 0.1579317
[Epoch 42; Iter   161/  209] train: loss: 0.1133389
[Epoch 42; Iter   191/  209] train: loss: 0.1124027
[Epoch 42] ogbg-moltox21: 0.792708 val loss: 0.249122
[Epoch 42] ogbg-moltox21: 0.749595 test loss: 0.274751
[Epoch 43; Iter    12/  209] train: loss: 0.1172036
[Epoch 43; Iter    42/  209] train: loss: 0.1316524
[Epoch 43; Iter    72/  209] train: loss: 0.1348281
[Epoch 43; Iter   102/  209] train: loss: 0.1689749
[Epoch 43; Iter   132/  209] train: loss: 0.1241916
[Epoch 43; Iter   162/  209] train: loss: 0.1180764
[Epoch 43; Iter   192/  209] train: loss: 0.1177044
[Epoch 43] ogbg-moltox21: 0.787615 val loss: 0.252893
[Epoch 43] ogbg-moltox21: 0.756155 test loss: 0.273916
[Epoch 44; Iter    13/  209] train: loss: 0.1395439
[Epoch 44; Iter    43/  209] train: loss: 0.1414660
[Epoch 44; Iter    73/  209] train: loss: 0.1127993
[Epoch 44; Iter   103/  209] train: loss: 0.1061898
[Epoch 44; Iter   133/  209] train: loss: 0.1217894
[Epoch 44; Iter   163/  209] train: loss: 0.1297831
[Epoch 44; Iter   193/  209] train: loss: 0.1026212
[Epoch 44] ogbg-moltox21: 0.791461 val loss: 0.252652
[Epoch 44] ogbg-moltox21: 0.765601 test loss: 0.271763
[Epoch 45; Iter    14/  209] train: loss: 0.1301605
[Epoch 45; Iter    44/  209] train: loss: 0.1253755
[Epoch 45; Iter    74/  209] train: loss: 0.1474719
[Epoch 45; Iter   104/  209] train: loss: 0.1284124
[Epoch 45; Iter   134/  209] train: loss: 0.1677926
[Epoch 45; Iter   164/  209] train: loss: 0.0852560
[Epoch 45; Iter   194/  209] train: loss: 0.1399619
[Epoch 45] ogbg-moltox21: 0.795779 val loss: 0.254290
[Epoch 45] ogbg-moltox21: 0.764819 test loss: 0.270159
[Epoch 46; Iter    15/  209] train: loss: 0.0961325
[Epoch 46; Iter    45/  209] train: loss: 0.1461239
[Epoch 46; Iter    75/  209] train: loss: 0.1821452
[Epoch 46; Iter   105/  209] train: loss: 0.1492317
[Epoch 46; Iter   135/  209] train: loss: 0.1714189
[Epoch 46; Iter   165/  209] train: loss: 0.0603805
[Epoch 46; Iter   195/  209] train: loss: 0.1028215
[Epoch 46] ogbg-moltox21: 0.792971 val loss: 0.257440
[Epoch 46] ogbg-moltox21: 0.760101 test loss: 0.273213
[Epoch 47; Iter    16/  209] train: loss: 0.0863658
[Epoch 47; Iter    46/  209] train: loss: 0.1244077
[Epoch 47; Iter    76/  209] train: loss: 0.1276679
[Epoch 47; Iter   106/  209] train: loss: 0.1730247
[Epoch 47; Iter   136/  209] train: loss: 0.1167646
[Epoch 30; Iter    89/  209] train: loss: 0.1477000
[Epoch 30; Iter   119/  209] train: loss: 0.1644742
[Epoch 30; Iter   149/  209] train: loss: 0.1568861
[Epoch 30; Iter   179/  209] train: loss: 0.2283808
[Epoch 30; Iter   209/  209] train: loss: 0.1115657
[Epoch 30] ogbg-moltox21: 0.812446 val loss: 0.247302
[Epoch 30] ogbg-moltox21: 0.758561 test loss: 0.268800
[Epoch 31; Iter    30/  209] train: loss: 0.1021949
[Epoch 31; Iter    60/  209] train: loss: 0.1120013
[Epoch 31; Iter    90/  209] train: loss: 0.1534823
[Epoch 31; Iter   120/  209] train: loss: 0.1218826
[Epoch 31; Iter   150/  209] train: loss: 0.1438671
[Epoch 31; Iter   180/  209] train: loss: 0.2005885
[Epoch 31] ogbg-moltox21: 0.791315 val loss: 0.261778
[Epoch 31] ogbg-moltox21: 0.742307 test loss: 0.375516
[Epoch 32; Iter     1/  209] train: loss: 0.1648425
[Epoch 32; Iter    31/  209] train: loss: 0.1122508
[Epoch 32; Iter    61/  209] train: loss: 0.2057685
[Epoch 32; Iter    91/  209] train: loss: 0.1748234
[Epoch 32; Iter   121/  209] train: loss: 0.1934103
[Epoch 32; Iter   151/  209] train: loss: 0.1892139
[Epoch 32; Iter   181/  209] train: loss: 0.2644940
[Epoch 32] ogbg-moltox21: 0.792068 val loss: 0.253185
[Epoch 32] ogbg-moltox21: 0.755249 test loss: 0.269233
[Epoch 33; Iter     2/  209] train: loss: 0.1455433
[Epoch 33; Iter    32/  209] train: loss: 0.1187417
[Epoch 33; Iter    62/  209] train: loss: 0.1533946
[Epoch 33; Iter    92/  209] train: loss: 0.1639631
[Epoch 33; Iter   122/  209] train: loss: 0.0907349
[Epoch 33; Iter   152/  209] train: loss: 0.1077293
[Epoch 33; Iter   182/  209] train: loss: 0.1181713
[Epoch 33] ogbg-moltox21: 0.802245 val loss: 0.245780
[Epoch 33] ogbg-moltox21: 0.753814 test loss: 0.262470
[Epoch 34; Iter     3/  209] train: loss: 0.0939306
[Epoch 34; Iter    33/  209] train: loss: 0.1280762
[Epoch 34; Iter    63/  209] train: loss: 0.1509240
[Epoch 34; Iter    93/  209] train: loss: 0.1784656
[Epoch 34; Iter   123/  209] train: loss: 0.1047645
[Epoch 34; Iter   153/  209] train: loss: 0.1581388
[Epoch 34; Iter   183/  209] train: loss: 0.1258428
[Epoch 34] ogbg-moltox21: 0.798142 val loss: 0.249818
[Epoch 34] ogbg-moltox21: 0.756526 test loss: 0.286471
[Epoch 35; Iter     4/  209] train: loss: 0.1785123
[Epoch 35; Iter    34/  209] train: loss: 0.1757457
[Epoch 35; Iter    64/  209] train: loss: 0.1594818
[Epoch 35; Iter    94/  209] train: loss: 0.1283702
[Epoch 35; Iter   124/  209] train: loss: 0.1476903
[Epoch 35; Iter   154/  209] train: loss: 0.1288017
[Epoch 35; Iter   184/  209] train: loss: 0.2088730
[Epoch 35] ogbg-moltox21: 0.802437 val loss: 0.265658
[Epoch 35] ogbg-moltox21: 0.762003 test loss: 0.285887
[Epoch 36; Iter     5/  209] train: loss: 0.1519642
[Epoch 36; Iter    35/  209] train: loss: 0.1980737
[Epoch 36; Iter    65/  209] train: loss: 0.1420926
[Epoch 36; Iter    95/  209] train: loss: 0.1799313
[Epoch 36; Iter   125/  209] train: loss: 0.1865780
[Epoch 36; Iter   155/  209] train: loss: 0.1265157
[Epoch 36; Iter   185/  209] train: loss: 0.1475448
[Epoch 36] ogbg-moltox21: 0.799650 val loss: 0.259137
[Epoch 36] ogbg-moltox21: 0.763441 test loss: 0.285244
[Epoch 37; Iter     6/  209] train: loss: 0.1182235
[Epoch 37; Iter    36/  209] train: loss: 0.1716320
[Epoch 37; Iter    66/  209] train: loss: 0.1708413
[Epoch 37; Iter    96/  209] train: loss: 0.1259496
[Epoch 37; Iter   126/  209] train: loss: 0.1638982
[Epoch 37; Iter   156/  209] train: loss: 0.1211989
[Epoch 37; Iter   186/  209] train: loss: 0.1408956
[Epoch 37] ogbg-moltox21: 0.800737 val loss: 0.244096
[Epoch 37] ogbg-moltox21: 0.757711 test loss: 0.277542
[Epoch 38; Iter     7/  209] train: loss: 0.2102100
[Epoch 38; Iter    37/  209] train: loss: 0.1729636
[Epoch 38; Iter    67/  209] train: loss: 0.1120211
[Epoch 38; Iter    97/  209] train: loss: 0.1124964
[Epoch 38; Iter   127/  209] train: loss: 0.0916187
[Epoch 38; Iter   157/  209] train: loss: 0.1278631
[Epoch 38; Iter   187/  209] train: loss: 0.1126699
[Epoch 38] ogbg-moltox21: 0.800115 val loss: 0.324640
[Epoch 38] ogbg-moltox21: 0.760361 test loss: 0.397851
[Epoch 39; Iter     8/  209] train: loss: 0.1472326
[Epoch 39; Iter    38/  209] train: loss: 0.1032637
[Epoch 39; Iter    68/  209] train: loss: 0.1408696
[Epoch 39; Iter    98/  209] train: loss: 0.1398710
[Epoch 39; Iter   128/  209] train: loss: 0.1220746
[Epoch 39; Iter   158/  209] train: loss: 0.1439468
[Epoch 39; Iter   188/  209] train: loss: 0.1218626
[Epoch 39] ogbg-moltox21: 0.802279 val loss: 0.252607
[Epoch 39] ogbg-moltox21: 0.755638 test loss: 0.270801
[Epoch 40; Iter     9/  209] train: loss: 0.0968417
[Epoch 40; Iter    39/  209] train: loss: 0.1052817
[Epoch 40; Iter    69/  209] train: loss: 0.1475676
[Epoch 40; Iter    99/  209] train: loss: 0.1505210
[Epoch 40; Iter   129/  209] train: loss: 0.0968151
[Epoch 40; Iter   159/  209] train: loss: 0.1193765
[Epoch 40; Iter   189/  209] train: loss: 0.1975942
[Epoch 40] ogbg-moltox21: 0.798319 val loss: 0.323584
[Epoch 40] ogbg-moltox21: 0.760680 test loss: 0.385298
[Epoch 41; Iter    10/  209] train: loss: 0.1062868
[Epoch 41; Iter    40/  209] train: loss: 0.1650251
[Epoch 41; Iter    70/  209] train: loss: 0.1197105
[Epoch 41; Iter   100/  209] train: loss: 0.2052442
[Epoch 41; Iter   130/  209] train: loss: 0.1374611
[Epoch 41; Iter   160/  209] train: loss: 0.1564444
[Epoch 41; Iter   190/  209] train: loss: 0.1126876
[Epoch 41] ogbg-moltox21: 0.799662 val loss: 0.279054
[Epoch 41] ogbg-moltox21: 0.760629 test loss: 0.326068
[Epoch 42; Iter    11/  209] train: loss: 0.1259931
[Epoch 42; Iter    41/  209] train: loss: 0.0958461
[Epoch 42; Iter    71/  209] train: loss: 0.0975739
[Epoch 42; Iter   101/  209] train: loss: 0.1929215
[Epoch 42; Iter   131/  209] train: loss: 0.1510225
[Epoch 42; Iter   161/  209] train: loss: 0.0853753
[Epoch 42; Iter   191/  209] train: loss: 0.0577312
[Epoch 42] ogbg-moltox21: 0.792565 val loss: 0.271661
[Epoch 42] ogbg-moltox21: 0.760012 test loss: 0.310370
[Epoch 43; Iter    12/  209] train: loss: 0.1273579
[Epoch 43; Iter    42/  209] train: loss: 0.0983548
[Epoch 43; Iter    72/  209] train: loss: 0.1837264
[Epoch 43; Iter   102/  209] train: loss: 0.1702045
[Epoch 43; Iter   132/  209] train: loss: 0.1593043
[Epoch 43; Iter   162/  209] train: loss: 0.1181340
[Epoch 43; Iter   192/  209] train: loss: 0.0900279
[Epoch 43] ogbg-moltox21: 0.798487 val loss: 0.269388
[Epoch 43] ogbg-moltox21: 0.767647 test loss: 0.297506
[Epoch 44; Iter    13/  209] train: loss: 0.0955341
[Epoch 44; Iter    43/  209] train: loss: 0.0888018
[Epoch 44; Iter    73/  209] train: loss: 0.0733832
[Epoch 44; Iter   103/  209] train: loss: 0.2106149
[Epoch 44; Iter   133/  209] train: loss: 0.1313561
[Epoch 44; Iter   163/  209] train: loss: 0.1094604
[Epoch 44; Iter   193/  209] train: loss: 0.1449910
[Epoch 44] ogbg-moltox21: 0.801411 val loss: 0.252781
[Epoch 44] ogbg-moltox21: 0.768386 test loss: 0.270889
[Epoch 45; Iter    14/  209] train: loss: 0.1186268
[Epoch 45; Iter    44/  209] train: loss: 0.1436605
[Epoch 45; Iter    74/  209] train: loss: 0.1006786
[Epoch 45; Iter   104/  209] train: loss: 0.1253514
[Epoch 45; Iter   134/  209] train: loss: 0.1387887
[Epoch 45; Iter   164/  209] train: loss: 0.1025059
[Epoch 45; Iter   194/  209] train: loss: 0.1610576
[Epoch 45] ogbg-moltox21: 0.797691 val loss: 0.266141
[Epoch 45] ogbg-moltox21: 0.760907 test loss: 0.282778
[Epoch 46; Iter    15/  209] train: loss: 0.0840534
[Epoch 46; Iter    45/  209] train: loss: 0.1755820
[Epoch 46; Iter    75/  209] train: loss: 0.1206893
[Epoch 46; Iter   105/  209] train: loss: 0.0879574
[Epoch 46; Iter   135/  209] train: loss: 0.1754207
[Epoch 46; Iter   165/  209] train: loss: 0.0736303
[Epoch 46; Iter   195/  209] train: loss: 0.1599055
[Epoch 46] ogbg-moltox21: 0.797542 val loss: 0.393736
[Epoch 46] ogbg-moltox21: 0.773938 test loss: 0.509603
[Epoch 47; Iter    16/  209] train: loss: 0.0941715
[Epoch 47; Iter    46/  209] train: loss: 0.0857592
[Epoch 47; Iter    76/  209] train: loss: 0.1160773
[Epoch 47; Iter   106/  209] train: loss: 0.0807716
[Epoch 47; Iter   136/  209] train: loss: 0.1483069
[Epoch 30; Iter    89/  209] train: loss: 0.1950374
[Epoch 30; Iter   119/  209] train: loss: 0.1329285
[Epoch 30; Iter   149/  209] train: loss: 0.1643902
[Epoch 30; Iter   179/  209] train: loss: 0.1333665
[Epoch 30; Iter   209/  209] train: loss: 0.1109126
[Epoch 30] ogbg-moltox21: 0.802584 val loss: 0.245035
[Epoch 30] ogbg-moltox21: 0.749584 test loss: 0.265102
[Epoch 31; Iter    30/  209] train: loss: 0.1808579
[Epoch 31; Iter    60/  209] train: loss: 0.1767810
[Epoch 31; Iter    90/  209] train: loss: 0.0984000
[Epoch 31; Iter   120/  209] train: loss: 0.1289428
[Epoch 31; Iter   150/  209] train: loss: 0.1465364
[Epoch 31; Iter   180/  209] train: loss: 0.1649605
[Epoch 31] ogbg-moltox21: 0.794252 val loss: 0.248160
[Epoch 31] ogbg-moltox21: 0.743828 test loss: 0.266214
[Epoch 32; Iter     1/  209] train: loss: 0.1697904
[Epoch 32; Iter    31/  209] train: loss: 0.1870783
[Epoch 32; Iter    61/  209] train: loss: 0.1356433
[Epoch 32; Iter    91/  209] train: loss: 0.0914631
[Epoch 32; Iter   121/  209] train: loss: 0.1609940
[Epoch 32; Iter   151/  209] train: loss: 0.1164473
[Epoch 32; Iter   181/  209] train: loss: 0.1445033
[Epoch 32] ogbg-moltox21: 0.808603 val loss: 0.238874
[Epoch 32] ogbg-moltox21: 0.761830 test loss: 0.256590
[Epoch 33; Iter     2/  209] train: loss: 0.1560691
[Epoch 33; Iter    32/  209] train: loss: 0.1778641
[Epoch 33; Iter    62/  209] train: loss: 0.2021190
[Epoch 33; Iter    92/  209] train: loss: 0.2235446
[Epoch 33; Iter   122/  209] train: loss: 0.2204451
[Epoch 33; Iter   152/  209] train: loss: 0.1269699
[Epoch 33; Iter   182/  209] train: loss: 0.1243128
[Epoch 33] ogbg-moltox21: 0.783664 val loss: 0.246638
[Epoch 33] ogbg-moltox21: 0.741283 test loss: 0.257604
[Epoch 34; Iter     3/  209] train: loss: 0.1514002
[Epoch 34; Iter    33/  209] train: loss: 0.2021028
[Epoch 34; Iter    63/  209] train: loss: 0.1456101
[Epoch 34; Iter    93/  209] train: loss: 0.1799064
[Epoch 34; Iter   123/  209] train: loss: 0.1230356
[Epoch 34; Iter   153/  209] train: loss: 0.2628301
[Epoch 34; Iter   183/  209] train: loss: 0.0977787
[Epoch 34] ogbg-moltox21: 0.802505 val loss: 0.246242
[Epoch 34] ogbg-moltox21: 0.765535 test loss: 0.260036
[Epoch 35; Iter     4/  209] train: loss: 0.1525503
[Epoch 35; Iter    34/  209] train: loss: 0.1069411
[Epoch 35; Iter    64/  209] train: loss: 0.1587112
[Epoch 35; Iter    94/  209] train: loss: 0.1096599
[Epoch 35; Iter   124/  209] train: loss: 0.3301362
[Epoch 35; Iter   154/  209] train: loss: 0.1952478
[Epoch 35; Iter   184/  209] train: loss: 0.2117538
[Epoch 35] ogbg-moltox21: 0.796995 val loss: 0.257787
[Epoch 35] ogbg-moltox21: 0.757967 test loss: 0.274796
[Epoch 36; Iter     5/  209] train: loss: 0.1494745
[Epoch 36; Iter    35/  209] train: loss: 0.0859538
[Epoch 36; Iter    65/  209] train: loss: 0.0869069
[Epoch 36; Iter    95/  209] train: loss: 0.1401533
[Epoch 36; Iter   125/  209] train: loss: 0.1967318
[Epoch 36; Iter   155/  209] train: loss: 0.1555033
[Epoch 36; Iter   185/  209] train: loss: 0.1188706
[Epoch 36] ogbg-moltox21: 0.800151 val loss: 0.247913
[Epoch 36] ogbg-moltox21: 0.758006 test loss: 0.265263
[Epoch 37; Iter     6/  209] train: loss: 0.1154333
[Epoch 37; Iter    36/  209] train: loss: 0.2062608
[Epoch 37; Iter    66/  209] train: loss: 0.1161181
[Epoch 37; Iter    96/  209] train: loss: 0.1292591
[Epoch 37; Iter   126/  209] train: loss: 0.1400245
[Epoch 37; Iter   156/  209] train: loss: 0.1545921
[Epoch 37; Iter   186/  209] train: loss: 0.1700966
[Epoch 37] ogbg-moltox21: 0.793306 val loss: 0.243670
[Epoch 37] ogbg-moltox21: 0.763988 test loss: 0.255226
[Epoch 38; Iter     7/  209] train: loss: 0.1430785
[Epoch 38; Iter    37/  209] train: loss: 0.1125011
[Epoch 38; Iter    67/  209] train: loss: 0.0999240
[Epoch 38; Iter    97/  209] train: loss: 0.1475637
[Epoch 38; Iter   127/  209] train: loss: 0.2005658
[Epoch 38; Iter   157/  209] train: loss: 0.1439097
[Epoch 38; Iter   187/  209] train: loss: 0.2206721
[Epoch 38] ogbg-moltox21: 0.800432 val loss: 0.240360
[Epoch 38] ogbg-moltox21: 0.763396 test loss: 0.254655
[Epoch 39; Iter     8/  209] train: loss: 0.1110658
[Epoch 39; Iter    38/  209] train: loss: 0.1031342
[Epoch 39; Iter    68/  209] train: loss: 0.1165551
[Epoch 39; Iter    98/  209] train: loss: 0.1316621
[Epoch 39; Iter   128/  209] train: loss: 0.2249385
[Epoch 39; Iter   158/  209] train: loss: 0.1341032
[Epoch 39; Iter   188/  209] train: loss: 0.0899588
[Epoch 39] ogbg-moltox21: 0.808200 val loss: 0.243940
[Epoch 39] ogbg-moltox21: 0.759981 test loss: 0.263288
[Epoch 40; Iter     9/  209] train: loss: 0.1314216
[Epoch 40; Iter    39/  209] train: loss: 0.1443600
[Epoch 40; Iter    69/  209] train: loss: 0.1712291
[Epoch 40; Iter    99/  209] train: loss: 0.1328151
[Epoch 40; Iter   129/  209] train: loss: 0.0872918
[Epoch 40; Iter   159/  209] train: loss: 0.1589024
[Epoch 40; Iter   189/  209] train: loss: 0.1679071
[Epoch 40] ogbg-moltox21: 0.802199 val loss: 0.244851
[Epoch 40] ogbg-moltox21: 0.758307 test loss: 0.263013
[Epoch 41; Iter    10/  209] train: loss: 0.0892836
[Epoch 41; Iter    40/  209] train: loss: 0.1723720
[Epoch 41; Iter    70/  209] train: loss: 0.0750336
[Epoch 41; Iter   100/  209] train: loss: 0.1408062
[Epoch 41; Iter   130/  209] train: loss: 0.2458893
[Epoch 41; Iter   160/  209] train: loss: 0.1922338
[Epoch 41; Iter   190/  209] train: loss: 0.2060825
[Epoch 41] ogbg-moltox21: 0.798120 val loss: 0.245836
[Epoch 41] ogbg-moltox21: 0.763292 test loss: 0.259824
[Epoch 42; Iter    11/  209] train: loss: 0.1441340
[Epoch 42; Iter    41/  209] train: loss: 0.1015227
[Epoch 42; Iter    71/  209] train: loss: 0.1445870
[Epoch 42; Iter   101/  209] train: loss: 0.1170244
[Epoch 42; Iter   131/  209] train: loss: 0.1002911
[Epoch 42; Iter   161/  209] train: loss: 0.1452514
[Epoch 42; Iter   191/  209] train: loss: 0.1129788
[Epoch 42] ogbg-moltox21: 0.807228 val loss: 0.238886
[Epoch 42] ogbg-moltox21: 0.761104 test loss: 0.259852
[Epoch 43; Iter    12/  209] train: loss: 0.1001011
[Epoch 43; Iter    42/  209] train: loss: 0.1223054
[Epoch 43; Iter    72/  209] train: loss: 0.1133027
[Epoch 43; Iter   102/  209] train: loss: 0.1324799
[Epoch 43; Iter   132/  209] train: loss: 0.1211797
[Epoch 43; Iter   162/  209] train: loss: 0.0798351
[Epoch 43; Iter   192/  209] train: loss: 0.1046491
[Epoch 43] ogbg-moltox21: 0.799054 val loss: 0.253880
[Epoch 43] ogbg-moltox21: 0.750713 test loss: 0.271269
[Epoch 44; Iter    13/  209] train: loss: 0.1137097
[Epoch 44; Iter    43/  209] train: loss: 0.1228677
[Epoch 44; Iter    73/  209] train: loss: 0.0857305
[Epoch 44; Iter   103/  209] train: loss: 0.1709096
[Epoch 44; Iter   133/  209] train: loss: 0.1474401
[Epoch 44; Iter   163/  209] train: loss: 0.1192385
[Epoch 44; Iter   193/  209] train: loss: 0.1312309
[Epoch 44] ogbg-moltox21: 0.807471 val loss: 0.253394
[Epoch 44] ogbg-moltox21: 0.761147 test loss: 0.273004
[Epoch 45; Iter    14/  209] train: loss: 0.1230652
[Epoch 45; Iter    44/  209] train: loss: 0.1266724
[Epoch 45; Iter    74/  209] train: loss: 0.1572965
[Epoch 45; Iter   104/  209] train: loss: 0.1297867
[Epoch 45; Iter   134/  209] train: loss: 0.0760897
[Epoch 45; Iter   164/  209] train: loss: 0.1227237
[Epoch 45; Iter   194/  209] train: loss: 0.1171053
[Epoch 45] ogbg-moltox21: 0.808223 val loss: 0.244593
[Epoch 45] ogbg-moltox21: 0.769280 test loss: 0.265185
[Epoch 46; Iter    15/  209] train: loss: 0.1071134
[Epoch 46; Iter    45/  209] train: loss: 0.1218822
[Epoch 46; Iter    75/  209] train: loss: 0.1317247
[Epoch 46; Iter   105/  209] train: loss: 0.1520549
[Epoch 46; Iter   135/  209] train: loss: 0.1656185
[Epoch 46; Iter   165/  209] train: loss: 0.2337572
[Epoch 46; Iter   195/  209] train: loss: 0.1815055
[Epoch 46] ogbg-moltox21: 0.802181 val loss: 0.254345
[Epoch 46] ogbg-moltox21: 0.759460 test loss: 0.274789
[Epoch 47; Iter    16/  209] train: loss: 0.1051305
[Epoch 47; Iter    46/  209] train: loss: 0.0965150
[Epoch 47; Iter    76/  209] train: loss: 0.2031133
[Epoch 47; Iter   106/  209] train: loss: 0.1469428
[Epoch 47; Iter   136/  209] train: loss: 0.1532522
[Epoch 33; Iter   114/  183] train: loss: 0.1459114
[Epoch 33; Iter   144/  183] train: loss: 0.1449182
[Epoch 33; Iter   174/  183] train: loss: 0.2159584
[Epoch 33] ogbg-moltox21: 0.750966 val loss: 0.304634
[Epoch 33] ogbg-moltox21: 0.743024 test loss: 0.317483
[Epoch 34; Iter    21/  183] train: loss: 0.1433119
[Epoch 34; Iter    51/  183] train: loss: 0.1801417
[Epoch 34; Iter    81/  183] train: loss: 0.1010102
[Epoch 34; Iter   111/  183] train: loss: 0.1122145
[Epoch 34; Iter   141/  183] train: loss: 0.1567271
[Epoch 34; Iter   171/  183] train: loss: 0.1383985
[Epoch 34] ogbg-moltox21: 0.762679 val loss: 0.278583
[Epoch 34] ogbg-moltox21: 0.742895 test loss: 0.292691
[Epoch 35; Iter    18/  183] train: loss: 0.1691246
[Epoch 35; Iter    48/  183] train: loss: 0.1432328
[Epoch 35; Iter    78/  183] train: loss: 0.1414193
[Epoch 35; Iter   108/  183] train: loss: 0.1524610
[Epoch 35; Iter   138/  183] train: loss: 0.1532203
[Epoch 35; Iter   168/  183] train: loss: 0.0447624
[Epoch 35] ogbg-moltox21: 0.760528 val loss: 0.284105
[Epoch 35] ogbg-moltox21: 0.736299 test loss: 0.301599
[Epoch 36; Iter    15/  183] train: loss: 0.0999011
[Epoch 36; Iter    45/  183] train: loss: 0.1820076
[Epoch 36; Iter    75/  183] train: loss: 0.1417904
[Epoch 36; Iter   105/  183] train: loss: 0.1256629
[Epoch 36; Iter   135/  183] train: loss: 0.1187027
[Epoch 36; Iter   165/  183] train: loss: 0.0736107
[Epoch 36] ogbg-moltox21: 0.774620 val loss: 0.303411
[Epoch 36] ogbg-moltox21: 0.740051 test loss: 0.334385
[Epoch 37; Iter    12/  183] train: loss: 0.1452283
[Epoch 37; Iter    42/  183] train: loss: 0.1067632
[Epoch 37; Iter    72/  183] train: loss: 0.1036980
[Epoch 37; Iter   102/  183] train: loss: 0.1197682
[Epoch 37; Iter   132/  183] train: loss: 0.1657799
[Epoch 37; Iter   162/  183] train: loss: 0.1462816
[Epoch 37] ogbg-moltox21: 0.757567 val loss: 0.291001
[Epoch 37] ogbg-moltox21: 0.739117 test loss: 0.306430
[Epoch 38; Iter     9/  183] train: loss: 0.1999961
[Epoch 38; Iter    39/  183] train: loss: 0.1186239
[Epoch 38; Iter    69/  183] train: loss: 0.1765495
[Epoch 38; Iter    99/  183] train: loss: 0.1514765
[Epoch 38; Iter   129/  183] train: loss: 0.0735618
[Epoch 38; Iter   159/  183] train: loss: 0.1084041
[Epoch 38] ogbg-moltox21: 0.760825 val loss: 0.304033
[Epoch 38] ogbg-moltox21: 0.736342 test loss: 0.316124
[Epoch 39; Iter     6/  183] train: loss: 0.1346664
[Epoch 39; Iter    36/  183] train: loss: 0.1442875
[Epoch 39; Iter    66/  183] train: loss: 0.1414082
[Epoch 39; Iter    96/  183] train: loss: 0.1184848
[Epoch 39; Iter   126/  183] train: loss: 0.1594702
[Epoch 39; Iter   156/  183] train: loss: 0.0760637
[Epoch 39] ogbg-moltox21: 0.766125 val loss: 0.287575
[Epoch 39] ogbg-moltox21: 0.740986 test loss: 0.306303
[Epoch 40; Iter     3/  183] train: loss: 0.1195319
[Epoch 40; Iter    33/  183] train: loss: 0.0805183
[Epoch 40; Iter    63/  183] train: loss: 0.0997312
[Epoch 40; Iter    93/  183] train: loss: 0.0974597
[Epoch 40; Iter   123/  183] train: loss: 0.1029195
[Epoch 40; Iter   153/  183] train: loss: 0.1365453
[Epoch 40; Iter   183/  183] train: loss: 0.0606770
[Epoch 40] ogbg-moltox21: 0.766804 val loss: 0.284820
[Epoch 40] ogbg-moltox21: 0.738223 test loss: 0.299414
[Epoch 41; Iter    30/  183] train: loss: 0.1822600
[Epoch 41; Iter    60/  183] train: loss: 0.1143424
[Epoch 41; Iter    90/  183] train: loss: 0.1232849
[Epoch 41; Iter   120/  183] train: loss: 0.1170570
[Epoch 41; Iter   150/  183] train: loss: 0.1494862
[Epoch 41; Iter   180/  183] train: loss: 0.0864524
[Epoch 41] ogbg-moltox21: 0.763569 val loss: 0.294796
[Epoch 41] ogbg-moltox21: 0.731827 test loss: 0.309324
[Epoch 42; Iter    27/  183] train: loss: 0.1022030
[Epoch 42; Iter    57/  183] train: loss: 0.1010356
[Epoch 42; Iter    87/  183] train: loss: 0.1051814
[Epoch 42; Iter   117/  183] train: loss: 0.1431278
[Epoch 42; Iter   147/  183] train: loss: 0.0556669
[Epoch 42; Iter   177/  183] train: loss: 0.1407015
[Epoch 42] ogbg-moltox21: 0.765119 val loss: 0.284928
[Epoch 42] ogbg-moltox21: 0.738383 test loss: 0.305535
[Epoch 43; Iter    24/  183] train: loss: 0.1101961
[Epoch 43; Iter    54/  183] train: loss: 0.0923236
[Epoch 43; Iter    84/  183] train: loss: 0.0821144
[Epoch 43; Iter   114/  183] train: loss: 0.1010048
[Epoch 43; Iter   144/  183] train: loss: 0.0700596
[Epoch 43; Iter   174/  183] train: loss: 0.0612270
[Epoch 43] ogbg-moltox21: 0.769590 val loss: 0.291174
[Epoch 43] ogbg-moltox21: 0.733135 test loss: 0.311714
[Epoch 44; Iter    21/  183] train: loss: 0.0864818
[Epoch 44; Iter    51/  183] train: loss: 0.0860652
[Epoch 44; Iter    81/  183] train: loss: 0.1558322
[Epoch 44; Iter   111/  183] train: loss: 0.1681383
[Epoch 44; Iter   141/  183] train: loss: 0.1874235
[Epoch 44; Iter   171/  183] train: loss: 0.1460483
[Epoch 44] ogbg-moltox21: 0.762517 val loss: 0.298402
[Epoch 44] ogbg-moltox21: 0.737428 test loss: 0.321113
[Epoch 45; Iter    18/  183] train: loss: 0.1485346
[Epoch 45; Iter    48/  183] train: loss: 0.1888342
[Epoch 45; Iter    78/  183] train: loss: 0.0784927
[Epoch 45; Iter   108/  183] train: loss: 0.1157849
[Epoch 45; Iter   138/  183] train: loss: 0.1058899
[Epoch 45; Iter   168/  183] train: loss: 0.1270954
[Epoch 45] ogbg-moltox21: 0.764661 val loss: 0.303621
[Epoch 45] ogbg-moltox21: 0.737816 test loss: 0.326065
[Epoch 46; Iter    15/  183] train: loss: 0.0640836
[Epoch 46; Iter    45/  183] train: loss: 0.0784317
[Epoch 46; Iter    75/  183] train: loss: 0.1417584
[Epoch 46; Iter   105/  183] train: loss: 0.1190613
[Epoch 46; Iter   135/  183] train: loss: 0.1518970
[Epoch 46; Iter   165/  183] train: loss: 0.1412266
[Epoch 46] ogbg-moltox21: 0.760629 val loss: 0.296606
[Epoch 46] ogbg-moltox21: 0.734560 test loss: 0.317050
[Epoch 47; Iter    12/  183] train: loss: 0.1047339
[Epoch 47; Iter    42/  183] train: loss: 0.1217326
[Epoch 47; Iter    72/  183] train: loss: 0.0918817
[Epoch 47; Iter   102/  183] train: loss: 0.1120126
[Epoch 47; Iter   132/  183] train: loss: 0.1366965
[Epoch 47; Iter   162/  183] train: loss: 0.1250353
[Epoch 47] ogbg-moltox21: 0.775787 val loss: 0.302629
[Epoch 47] ogbg-moltox21: 0.739868 test loss: 0.328586
[Epoch 48; Iter     9/  183] train: loss: 0.1606236
[Epoch 48; Iter    39/  183] train: loss: 0.1225593
[Epoch 48; Iter    69/  183] train: loss: 0.1047553
[Epoch 48; Iter    99/  183] train: loss: 0.1168548
[Epoch 48; Iter   129/  183] train: loss: 0.2227318
[Epoch 48; Iter   159/  183] train: loss: 0.1671395
[Epoch 48] ogbg-moltox21: 0.758196 val loss: 0.295604
[Epoch 48] ogbg-moltox21: 0.731929 test loss: 0.319020
[Epoch 49; Iter     6/  183] train: loss: 0.1163445
[Epoch 49; Iter    36/  183] train: loss: 0.1102461
[Epoch 49; Iter    66/  183] train: loss: 0.0846704
[Epoch 49; Iter    96/  183] train: loss: 0.0983921
[Epoch 49; Iter   126/  183] train: loss: 0.1089226
[Epoch 49; Iter   156/  183] train: loss: 0.1416071
[Epoch 49] ogbg-moltox21: 0.759365 val loss: 0.305758
[Epoch 49] ogbg-moltox21: 0.737947 test loss: 0.328386
[Epoch 50; Iter     3/  183] train: loss: 0.1004778
[Epoch 50; Iter    33/  183] train: loss: 0.1326675
[Epoch 50; Iter    63/  183] train: loss: 0.0867346
[Epoch 50; Iter    93/  183] train: loss: 0.0624541
[Epoch 50; Iter   123/  183] train: loss: 0.0947173
[Epoch 50; Iter   153/  183] train: loss: 0.1465041
[Epoch 50; Iter   183/  183] train: loss: 0.1484322
[Epoch 50] ogbg-moltox21: 0.758436 val loss: 0.306151
[Epoch 50] ogbg-moltox21: 0.732267 test loss: 0.327030
[Epoch 51; Iter    30/  183] train: loss: 0.0579895
[Epoch 51; Iter    60/  183] train: loss: 0.0815790
[Epoch 51; Iter    90/  183] train: loss: 0.1381863
[Epoch 51; Iter   120/  183] train: loss: 0.1272677
[Epoch 51; Iter   150/  183] train: loss: 0.1139026
[Epoch 51; Iter   180/  183] train: loss: 0.1934379
[Epoch 51] ogbg-moltox21: 0.762207 val loss: 0.306177
[Epoch 51] ogbg-moltox21: 0.735798 test loss: 0.327074
[Epoch 52; Iter    27/  183] train: loss: 0.1155899
[Epoch 52; Iter    57/  183] train: loss: 0.1347114
[Epoch 52; Iter    87/  183] train: loss: 0.0661361
[Epoch 52; Iter   117/  183] train: loss: 0.1598256
[Epoch 33; Iter   114/  183] train: loss: 0.2107412
[Epoch 33; Iter   144/  183] train: loss: 0.1001561
[Epoch 33; Iter   174/  183] train: loss: 0.1513233
[Epoch 33] ogbg-moltox21: 0.760831 val loss: 0.313505
[Epoch 33] ogbg-moltox21: 0.746780 test loss: 0.335231
[Epoch 34; Iter    21/  183] train: loss: 0.1184820
[Epoch 34; Iter    51/  183] train: loss: 0.1517088
[Epoch 34; Iter    81/  183] train: loss: 0.1346750
[Epoch 34; Iter   111/  183] train: loss: 0.1928555
[Epoch 34; Iter   141/  183] train: loss: 0.1898520
[Epoch 34; Iter   171/  183] train: loss: 0.1798328
[Epoch 34] ogbg-moltox21: 0.762842 val loss: 0.285905
[Epoch 34] ogbg-moltox21: 0.749507 test loss: 0.296360
[Epoch 35; Iter    18/  183] train: loss: 0.1863422
[Epoch 35; Iter    48/  183] train: loss: 0.1743334
[Epoch 35; Iter    78/  183] train: loss: 0.1411142
[Epoch 35; Iter   108/  183] train: loss: 0.1708172
[Epoch 35; Iter   138/  183] train: loss: 0.0956335
[Epoch 35; Iter   168/  183] train: loss: 0.1105285
[Epoch 35] ogbg-moltox21: 0.772322 val loss: 0.270075
[Epoch 35] ogbg-moltox21: 0.740427 test loss: 0.287085
[Epoch 36; Iter    15/  183] train: loss: 0.1485182
[Epoch 36; Iter    45/  183] train: loss: 0.1239911
[Epoch 36; Iter    75/  183] train: loss: 0.1344234
[Epoch 36; Iter   105/  183] train: loss: 0.1982142
[Epoch 36; Iter   135/  183] train: loss: 0.1247358
[Epoch 36; Iter   165/  183] train: loss: 0.1309271
[Epoch 36] ogbg-moltox21: 0.761463 val loss: 0.270492
[Epoch 36] ogbg-moltox21: 0.743711 test loss: 0.288215
[Epoch 37; Iter    12/  183] train: loss: 0.1856040
[Epoch 37; Iter    42/  183] train: loss: 0.1030749
[Epoch 37; Iter    72/  183] train: loss: 0.1731056
[Epoch 37; Iter   102/  183] train: loss: 0.1325660
[Epoch 37; Iter   132/  183] train: loss: 0.1638892
[Epoch 37; Iter   162/  183] train: loss: 0.1123875
[Epoch 37] ogbg-moltox21: 0.778479 val loss: 0.268287
[Epoch 37] ogbg-moltox21: 0.758167 test loss: 0.283969
[Epoch 38; Iter     9/  183] train: loss: 0.1713495
[Epoch 38; Iter    39/  183] train: loss: 0.1788041
[Epoch 38; Iter    69/  183] train: loss: 0.1323785
[Epoch 38; Iter    99/  183] train: loss: 0.1541588
[Epoch 38; Iter   129/  183] train: loss: 0.0908722
[Epoch 38; Iter   159/  183] train: loss: 0.1506665
[Epoch 38] ogbg-moltox21: 0.766824 val loss: 0.266074
[Epoch 38] ogbg-moltox21: 0.737295 test loss: 0.302215
[Epoch 39; Iter     6/  183] train: loss: 0.1975307
[Epoch 39; Iter    36/  183] train: loss: 0.1392754
[Epoch 39; Iter    66/  183] train: loss: 0.1407329
[Epoch 39; Iter    96/  183] train: loss: 0.1153977
[Epoch 39; Iter   126/  183] train: loss: 0.1630906
[Epoch 39; Iter   156/  183] train: loss: 0.2013551
[Epoch 39] ogbg-moltox21: 0.773129 val loss: 0.269157
[Epoch 39] ogbg-moltox21: 0.745830 test loss: 0.295659
[Epoch 40; Iter     3/  183] train: loss: 0.1724644
[Epoch 40; Iter    33/  183] train: loss: 0.1019571
[Epoch 40; Iter    63/  183] train: loss: 0.1154609
[Epoch 40; Iter    93/  183] train: loss: 0.1387364
[Epoch 40; Iter   123/  183] train: loss: 0.2011903
[Epoch 40; Iter   153/  183] train: loss: 0.1647705
[Epoch 40; Iter   183/  183] train: loss: 0.0656223
[Epoch 40] ogbg-moltox21: 0.769417 val loss: 0.272613
[Epoch 40] ogbg-moltox21: 0.752944 test loss: 0.282930
[Epoch 41; Iter    30/  183] train: loss: 0.1927016
[Epoch 41; Iter    60/  183] train: loss: 0.1610062
[Epoch 41; Iter    90/  183] train: loss: 0.1062766
[Epoch 41; Iter   120/  183] train: loss: 0.2075722
[Epoch 41; Iter   150/  183] train: loss: 0.1208039
[Epoch 41; Iter   180/  183] train: loss: 0.0953446
[Epoch 41] ogbg-moltox21: 0.761231 val loss: 0.296516
[Epoch 41] ogbg-moltox21: 0.734681 test loss: 0.309971
[Epoch 42; Iter    27/  183] train: loss: 0.2378643
[Epoch 42; Iter    57/  183] train: loss: 0.2211614
[Epoch 42; Iter    87/  183] train: loss: 0.1290353
[Epoch 42; Iter   117/  183] train: loss: 0.1053634
[Epoch 42; Iter   147/  183] train: loss: 0.1346756
[Epoch 42; Iter   177/  183] train: loss: 0.1453258
[Epoch 42] ogbg-moltox21: 0.775080 val loss: 0.262453
[Epoch 42] ogbg-moltox21: 0.749214 test loss: 0.281877
[Epoch 43; Iter    24/  183] train: loss: 0.1050765
[Epoch 43; Iter    54/  183] train: loss: 0.1832151
[Epoch 43; Iter    84/  183] train: loss: 0.1848236
[Epoch 43; Iter   114/  183] train: loss: 0.0879646
[Epoch 43; Iter   144/  183] train: loss: 0.0856072
[Epoch 43; Iter   174/  183] train: loss: 0.0989525
[Epoch 43] ogbg-moltox21: 0.775629 val loss: 0.279651
[Epoch 43] ogbg-moltox21: 0.745004 test loss: 0.303778
[Epoch 44; Iter    21/  183] train: loss: 0.1859781
[Epoch 44; Iter    51/  183] train: loss: 0.1659964
[Epoch 44; Iter    81/  183] train: loss: 0.1691312
[Epoch 44; Iter   111/  183] train: loss: 0.1387739
[Epoch 44; Iter   141/  183] train: loss: 0.1473939
[Epoch 44; Iter   171/  183] train: loss: 0.1770526
[Epoch 44] ogbg-moltox21: 0.773455 val loss: 0.273140
[Epoch 44] ogbg-moltox21: 0.736907 test loss: 0.301428
[Epoch 45; Iter    18/  183] train: loss: 0.1684277
[Epoch 45; Iter    48/  183] train: loss: 0.0843125
[Epoch 45; Iter    78/  183] train: loss: 0.1402618
[Epoch 45; Iter   108/  183] train: loss: 0.1070166
[Epoch 45; Iter   138/  183] train: loss: 0.1042539
[Epoch 45; Iter   168/  183] train: loss: 0.1668308
[Epoch 45] ogbg-moltox21: 0.770302 val loss: 0.261822
[Epoch 45] ogbg-moltox21: 0.751024 test loss: 0.281434
[Epoch 46; Iter    15/  183] train: loss: 0.1033910
[Epoch 46; Iter    45/  183] train: loss: 0.0887411
[Epoch 46; Iter    75/  183] train: loss: 0.1140353
[Epoch 46; Iter   105/  183] train: loss: 0.0805288
[Epoch 46; Iter   135/  183] train: loss: 0.0760310
[Epoch 46; Iter   165/  183] train: loss: 0.1074655
[Epoch 46] ogbg-moltox21: 0.779464 val loss: 0.275900
[Epoch 46] ogbg-moltox21: 0.750486 test loss: 0.295613
[Epoch 47; Iter    12/  183] train: loss: 0.1137979
[Epoch 47; Iter    42/  183] train: loss: 0.1369339
[Epoch 47; Iter    72/  183] train: loss: 0.0745002
[Epoch 47; Iter   102/  183] train: loss: 0.1258266
[Epoch 47; Iter   132/  183] train: loss: 0.0997588
[Epoch 47; Iter   162/  183] train: loss: 0.1174785
[Epoch 47] ogbg-moltox21: 0.775943 val loss: 0.277054
[Epoch 47] ogbg-moltox21: 0.742792 test loss: 0.302041
[Epoch 48; Iter     9/  183] train: loss: 0.1429972
[Epoch 48; Iter    39/  183] train: loss: 0.0859799
[Epoch 48; Iter    69/  183] train: loss: 0.1229839
[Epoch 48; Iter    99/  183] train: loss: 0.1012390
[Epoch 48; Iter   129/  183] train: loss: 0.1022329
[Epoch 48; Iter   159/  183] train: loss: 0.1171595
[Epoch 48] ogbg-moltox21: 0.775997 val loss: 0.267102
[Epoch 48] ogbg-moltox21: 0.744720 test loss: 0.287194
[Epoch 49; Iter     6/  183] train: loss: 0.0703483
[Epoch 49; Iter    36/  183] train: loss: 0.1054127
[Epoch 49; Iter    66/  183] train: loss: 0.1155480
[Epoch 49; Iter    96/  183] train: loss: 0.1047941
[Epoch 49; Iter   126/  183] train: loss: 0.1532982
[Epoch 49; Iter   156/  183] train: loss: 0.1290605
[Epoch 49] ogbg-moltox21: 0.768562 val loss: 0.277187
[Epoch 49] ogbg-moltox21: 0.738265 test loss: 0.327626
[Epoch 50; Iter     3/  183] train: loss: 0.0640243
[Epoch 50; Iter    33/  183] train: loss: 0.0866818
[Epoch 50; Iter    63/  183] train: loss: 0.1281863
[Epoch 50; Iter    93/  183] train: loss: 0.0963593
[Epoch 50; Iter   123/  183] train: loss: 0.1364550
[Epoch 50; Iter   153/  183] train: loss: 0.0798973
[Epoch 50; Iter   183/  183] train: loss: 0.0811076
[Epoch 50] ogbg-moltox21: 0.773712 val loss: 0.276088
[Epoch 50] ogbg-moltox21: 0.747544 test loss: 0.360918
[Epoch 51; Iter    30/  183] train: loss: 0.1191418
[Epoch 51; Iter    60/  183] train: loss: 0.1358931
[Epoch 51; Iter    90/  183] train: loss: 0.2424147
[Epoch 51; Iter   120/  183] train: loss: 0.0923427
[Epoch 51; Iter   150/  183] train: loss: 0.1204494
[Epoch 51; Iter   180/  183] train: loss: 0.0962876
[Epoch 51] ogbg-moltox21: 0.777063 val loss: 0.269293
[Epoch 51] ogbg-moltox21: 0.745796 test loss: 0.292741
[Epoch 52; Iter    27/  183] train: loss: 0.0867841
[Epoch 52; Iter    57/  183] train: loss: 0.0793938
[Epoch 52; Iter    87/  183] train: loss: 0.0912483
[Epoch 52; Iter   117/  183] train: loss: 0.1281242
[Epoch 33; Iter   114/  183] train: loss: 0.1279150
[Epoch 33; Iter   144/  183] train: loss: 0.1483319
[Epoch 33; Iter   174/  183] train: loss: 0.1111978
[Epoch 33] ogbg-moltox21: 0.757747 val loss: 0.269065
[Epoch 33] ogbg-moltox21: 0.748322 test loss: 0.279288
[Epoch 34; Iter    21/  183] train: loss: 0.0908109
[Epoch 34; Iter    51/  183] train: loss: 0.1042194
[Epoch 34; Iter    81/  183] train: loss: 0.1117725
[Epoch 34; Iter   111/  183] train: loss: 0.0986321
[Epoch 34; Iter   141/  183] train: loss: 0.1505240
[Epoch 34; Iter   171/  183] train: loss: 0.1653305
[Epoch 34] ogbg-moltox21: 0.763328 val loss: 0.280837
[Epoch 34] ogbg-moltox21: 0.742458 test loss: 0.289051
[Epoch 35; Iter    18/  183] train: loss: 0.0956805
[Epoch 35; Iter    48/  183] train: loss: 0.1470885
[Epoch 35; Iter    78/  183] train: loss: 0.2688888
[Epoch 35; Iter   108/  183] train: loss: 0.1466452
[Epoch 35; Iter   138/  183] train: loss: 0.1193428
[Epoch 35; Iter   168/  183] train: loss: 0.1287711
[Epoch 35] ogbg-moltox21: 0.763594 val loss: 0.283814
[Epoch 35] ogbg-moltox21: 0.748383 test loss: 0.295680
[Epoch 36; Iter    15/  183] train: loss: 0.0805127
[Epoch 36; Iter    45/  183] train: loss: 0.1363683
[Epoch 36; Iter    75/  183] train: loss: 0.1021654
[Epoch 36; Iter   105/  183] train: loss: 0.1818142
[Epoch 36; Iter   135/  183] train: loss: 0.0961983
[Epoch 36; Iter   165/  183] train: loss: 0.1324228
[Epoch 36] ogbg-moltox21: 0.741245 val loss: 0.290968
[Epoch 36] ogbg-moltox21: 0.715974 test loss: 0.311651
[Epoch 37; Iter    12/  183] train: loss: 0.1427900
[Epoch 37; Iter    42/  183] train: loss: 0.0709742
[Epoch 37; Iter    72/  183] train: loss: 0.2003744
[Epoch 37; Iter   102/  183] train: loss: 0.1642478
[Epoch 37; Iter   132/  183] train: loss: 0.1254794
[Epoch 37; Iter   162/  183] train: loss: 0.0957144
[Epoch 37] ogbg-moltox21: 0.768043 val loss: 0.270808
[Epoch 37] ogbg-moltox21: 0.742686 test loss: 0.288288
[Epoch 38; Iter     9/  183] train: loss: 0.1515088
[Epoch 38; Iter    39/  183] train: loss: 0.1454462
[Epoch 38; Iter    69/  183] train: loss: 0.0997440
[Epoch 38; Iter    99/  183] train: loss: 0.0985131
[Epoch 38; Iter   129/  183] train: loss: 0.0771314
[Epoch 38; Iter   159/  183] train: loss: 0.1492385
[Epoch 38] ogbg-moltox21: 0.759665 val loss: 0.287271
[Epoch 38] ogbg-moltox21: 0.739824 test loss: 0.283926
[Epoch 39; Iter     6/  183] train: loss: 0.1355875
[Epoch 39; Iter    36/  183] train: loss: 0.1380500
[Epoch 39; Iter    66/  183] train: loss: 0.1032557
[Epoch 39; Iter    96/  183] train: loss: 0.0902211
[Epoch 39; Iter   126/  183] train: loss: 0.1056409
[Epoch 39; Iter   156/  183] train: loss: 0.1436383
[Epoch 39] ogbg-moltox21: 0.760461 val loss: 0.272433
[Epoch 39] ogbg-moltox21: 0.741354 test loss: 0.285261
[Epoch 40; Iter     3/  183] train: loss: 0.1531062
[Epoch 40; Iter    33/  183] train: loss: 0.0734217
[Epoch 40; Iter    63/  183] train: loss: 0.0689045
[Epoch 40; Iter    93/  183] train: loss: 0.1257764
[Epoch 40; Iter   123/  183] train: loss: 0.1402999
[Epoch 40; Iter   153/  183] train: loss: 0.1257420
[Epoch 40; Iter   183/  183] train: loss: 0.1558421
[Epoch 40] ogbg-moltox21: 0.760002 val loss: 0.280615
[Epoch 40] ogbg-moltox21: 0.746110 test loss: 0.288762
[Epoch 41; Iter    30/  183] train: loss: 0.1670864
[Epoch 41; Iter    60/  183] train: loss: 0.0663031
[Epoch 41; Iter    90/  183] train: loss: 0.1061822
[Epoch 41; Iter   120/  183] train: loss: 0.1337075
[Epoch 41; Iter   150/  183] train: loss: 0.2456177
[Epoch 41; Iter   180/  183] train: loss: 0.0796724
[Epoch 41] ogbg-moltox21: 0.749630 val loss: 0.292219
[Epoch 41] ogbg-moltox21: 0.732618 test loss: 0.302539
[Epoch 42; Iter    27/  183] train: loss: 0.0664935
[Epoch 42; Iter    57/  183] train: loss: 0.0916553
[Epoch 42; Iter    87/  183] train: loss: 0.1277137
[Epoch 42; Iter   117/  183] train: loss: 0.1296935
[Epoch 42; Iter   147/  183] train: loss: 0.1116250
[Epoch 42; Iter   177/  183] train: loss: 0.1087496
[Epoch 42] ogbg-moltox21: 0.751347 val loss: 0.290665
[Epoch 42] ogbg-moltox21: 0.736151 test loss: 0.300473
[Epoch 43; Iter    24/  183] train: loss: 0.1369765
[Epoch 43; Iter    54/  183] train: loss: 0.1499040
[Epoch 43; Iter    84/  183] train: loss: 0.1322271
[Epoch 43; Iter   114/  183] train: loss: 0.1194022
[Epoch 43; Iter   144/  183] train: loss: 0.0978717
[Epoch 43; Iter   174/  183] train: loss: 0.1243965
[Epoch 43] ogbg-moltox21: 0.759025 val loss: 0.283026
[Epoch 43] ogbg-moltox21: 0.738670 test loss: 0.298241
[Epoch 44; Iter    21/  183] train: loss: 0.1200313
[Epoch 44; Iter    51/  183] train: loss: 0.0967805
[Epoch 44; Iter    81/  183] train: loss: 0.0911718
[Epoch 44; Iter   111/  183] train: loss: 0.0954627
[Epoch 44; Iter   141/  183] train: loss: 0.1146795
[Epoch 44; Iter   171/  183] train: loss: 0.1146634
[Epoch 44] ogbg-moltox21: 0.755605 val loss: 0.317472
[Epoch 44] ogbg-moltox21: 0.745081 test loss: 0.296611
[Epoch 45; Iter    18/  183] train: loss: 0.1355630
[Epoch 45; Iter    48/  183] train: loss: 0.0822420
[Epoch 45; Iter    78/  183] train: loss: 0.1007034
[Epoch 45; Iter   108/  183] train: loss: 0.1113769
[Epoch 45; Iter   138/  183] train: loss: 0.1233962
[Epoch 45; Iter   168/  183] train: loss: 0.0726495
[Epoch 45] ogbg-moltox21: 0.750830 val loss: 0.312610
[Epoch 45] ogbg-moltox21: 0.730138 test loss: 0.308783
[Epoch 46; Iter    15/  183] train: loss: 0.1071244
[Epoch 46; Iter    45/  183] train: loss: 0.1446712
[Epoch 46; Iter    75/  183] train: loss: 0.2305420
[Epoch 46; Iter   105/  183] train: loss: 0.1162803
[Epoch 46; Iter   135/  183] train: loss: 0.1734542
[Epoch 46; Iter   165/  183] train: loss: 0.1127587
[Epoch 46] ogbg-moltox21: 0.746601 val loss: 0.293146
[Epoch 46] ogbg-moltox21: 0.736329 test loss: 0.303657
[Epoch 47; Iter    12/  183] train: loss: 0.1091931
[Epoch 47; Iter    42/  183] train: loss: 0.0987203
[Epoch 47; Iter    72/  183] train: loss: 0.1295000
[Epoch 47; Iter   102/  183] train: loss: 0.1375655
[Epoch 47; Iter   132/  183] train: loss: 0.1487899
[Epoch 47; Iter   162/  183] train: loss: 0.0644321
[Epoch 47] ogbg-moltox21: 0.740182 val loss: 0.297015
[Epoch 47] ogbg-moltox21: 0.728363 test loss: 0.305990
[Epoch 48; Iter     9/  183] train: loss: 0.0887718
[Epoch 48; Iter    39/  183] train: loss: 0.1600324
[Epoch 48; Iter    69/  183] train: loss: 0.1140201
[Epoch 48; Iter    99/  183] train: loss: 0.1073785
[Epoch 48; Iter   129/  183] train: loss: 0.1356835
[Epoch 48; Iter   159/  183] train: loss: 0.0720679
[Epoch 48] ogbg-moltox21: 0.750433 val loss: 0.303468
[Epoch 48] ogbg-moltox21: 0.739004 test loss: 0.314211
[Epoch 49; Iter     6/  183] train: loss: 0.1005079
[Epoch 49; Iter    36/  183] train: loss: 0.1278129
[Epoch 49; Iter    66/  183] train: loss: 0.0897007
[Epoch 49; Iter    96/  183] train: loss: 0.2417551
[Epoch 49; Iter   126/  183] train: loss: 0.1041630
[Epoch 49; Iter   156/  183] train: loss: 0.1405024
[Epoch 49] ogbg-moltox21: 0.737152 val loss: 0.317417
[Epoch 49] ogbg-moltox21: 0.723284 test loss: 0.322175
[Epoch 50; Iter     3/  183] train: loss: 0.1030498
[Epoch 50; Iter    33/  183] train: loss: 0.0927968
[Epoch 50; Iter    63/  183] train: loss: 0.0936076
[Epoch 50; Iter    93/  183] train: loss: 0.1453762
[Epoch 50; Iter   123/  183] train: loss: 0.1098669
[Epoch 50; Iter   153/  183] train: loss: 0.0953749
[Epoch 50; Iter   183/  183] train: loss: 0.1244378
[Epoch 50] ogbg-moltox21: 0.748529 val loss: 0.295622
[Epoch 50] ogbg-moltox21: 0.737835 test loss: 0.306738
[Epoch 51; Iter    30/  183] train: loss: 0.1227099
[Epoch 51; Iter    60/  183] train: loss: 0.0893233
[Epoch 51; Iter    90/  183] train: loss: 0.1196150
[Epoch 51; Iter   120/  183] train: loss: 0.0838599
[Epoch 51; Iter   150/  183] train: loss: 0.0984046
[Epoch 51; Iter   180/  183] train: loss: 0.0699133
[Epoch 51] ogbg-moltox21: 0.748937 val loss: 0.307938
[Epoch 51] ogbg-moltox21: 0.736812 test loss: 0.315956
[Epoch 52; Iter    27/  183] train: loss: 0.0623808
[Epoch 52; Iter    57/  183] train: loss: 0.0501050
[Epoch 52; Iter    87/  183] train: loss: 0.1504381
[Epoch 52; Iter   117/  183] train: loss: 0.0721379
[Epoch 37; Iter    78/  157] train: loss: 0.1700130
[Epoch 37; Iter   108/  157] train: loss: 0.0914138
[Epoch 37; Iter   138/  157] train: loss: 0.1010715
[Epoch 37] ogbg-moltox21: 0.758959 val loss: 0.304387
[Epoch 37] ogbg-moltox21: 0.742377 test loss: 0.334548
[Epoch 38; Iter    11/  157] train: loss: 0.0863596
[Epoch 38; Iter    41/  157] train: loss: 0.1530191
[Epoch 38; Iter    71/  157] train: loss: 0.0707762
[Epoch 38; Iter   101/  157] train: loss: 0.1228018
[Epoch 38; Iter   131/  157] train: loss: 0.1975429
[Epoch 38] ogbg-moltox21: 0.747173 val loss: 0.321780
[Epoch 38] ogbg-moltox21: 0.731814 test loss: 0.541180
[Epoch 39; Iter     4/  157] train: loss: 0.1589339
[Epoch 39; Iter    34/  157] train: loss: 0.1367952
[Epoch 39; Iter    64/  157] train: loss: 0.1612370
[Epoch 39; Iter    94/  157] train: loss: 0.1504971
[Epoch 39; Iter   124/  157] train: loss: 0.1241385
[Epoch 39; Iter   154/  157] train: loss: 0.1255204
[Epoch 39] ogbg-moltox21: 0.754878 val loss: 0.305276
[Epoch 39] ogbg-moltox21: 0.744271 test loss: 0.320301
[Epoch 40; Iter    27/  157] train: loss: 0.1099648
[Epoch 40; Iter    57/  157] train: loss: 0.1120041
[Epoch 40; Iter    87/  157] train: loss: 0.1097807
[Epoch 40; Iter   117/  157] train: loss: 0.2156785
[Epoch 40; Iter   147/  157] train: loss: 0.1072540
[Epoch 40] ogbg-moltox21: 0.762568 val loss: 0.305533
[Epoch 40] ogbg-moltox21: 0.751118 test loss: 0.549433
[Epoch 41; Iter    20/  157] train: loss: 0.2333228
[Epoch 41; Iter    50/  157] train: loss: 0.1082872
[Epoch 41; Iter    80/  157] train: loss: 0.1287542
[Epoch 41; Iter   110/  157] train: loss: 0.1766085
[Epoch 41; Iter   140/  157] train: loss: 0.0863338
[Epoch 41] ogbg-moltox21: 0.762961 val loss: 0.320764
[Epoch 41] ogbg-moltox21: 0.751811 test loss: 0.490871
[Epoch 42; Iter    13/  157] train: loss: 0.1205971
[Epoch 42; Iter    43/  157] train: loss: 0.0976236
[Epoch 42; Iter    73/  157] train: loss: 0.0984959
[Epoch 42; Iter   103/  157] train: loss: 0.1512557
[Epoch 42; Iter   133/  157] train: loss: 0.0849961
[Epoch 42] ogbg-moltox21: 0.765797 val loss: 0.300623
[Epoch 42] ogbg-moltox21: 0.754572 test loss: 0.431837
[Epoch 43; Iter     6/  157] train: loss: 0.1063368
[Epoch 43; Iter    36/  157] train: loss: 0.1013730
[Epoch 43; Iter    66/  157] train: loss: 0.1336928
[Epoch 43; Iter    96/  157] train: loss: 0.1310100
[Epoch 43; Iter   126/  157] train: loss: 0.0835407
[Epoch 43; Iter   156/  157] train: loss: 0.1247360
[Epoch 43] ogbg-moltox21: 0.770002 val loss: 0.329939
[Epoch 43] ogbg-moltox21: 0.755802 test loss: 0.351714
[Epoch 44; Iter    29/  157] train: loss: 0.1373082
[Epoch 44; Iter    59/  157] train: loss: 0.1445485
[Epoch 44; Iter    89/  157] train: loss: 0.1207275
[Epoch 44; Iter   119/  157] train: loss: 0.1156320
[Epoch 44; Iter   149/  157] train: loss: 0.1025689
[Epoch 44] ogbg-moltox21: 0.759871 val loss: 0.311507
[Epoch 44] ogbg-moltox21: 0.746579 test loss: 0.429526
[Epoch 45; Iter    22/  157] train: loss: 0.0876759
[Epoch 45; Iter    52/  157] train: loss: 0.1570626
[Epoch 45; Iter    82/  157] train: loss: 0.2468875
[Epoch 45; Iter   112/  157] train: loss: 0.1553972
[Epoch 45; Iter   142/  157] train: loss: 0.1487028
[Epoch 45] ogbg-moltox21: 0.758499 val loss: 0.323126
[Epoch 45] ogbg-moltox21: 0.753114 test loss: 0.593564
[Epoch 46; Iter    15/  157] train: loss: 0.1385935
[Epoch 46; Iter    45/  157] train: loss: 0.1566185
[Epoch 46; Iter    75/  157] train: loss: 0.0989435
[Epoch 46; Iter   105/  157] train: loss: 0.1123672
[Epoch 46; Iter   135/  157] train: loss: 0.1126624
[Epoch 46] ogbg-moltox21: 0.765289 val loss: 0.335529
[Epoch 46] ogbg-moltox21: 0.755829 test loss: 0.619517
[Epoch 47; Iter     8/  157] train: loss: 0.1418662
[Epoch 47; Iter    38/  157] train: loss: 0.0904935
[Epoch 47; Iter    68/  157] train: loss: 0.0820869
[Epoch 47; Iter    98/  157] train: loss: 0.0979495
[Epoch 47; Iter   128/  157] train: loss: 0.1394222
[Epoch 47] ogbg-moltox21: 0.754447 val loss: 0.327521
[Epoch 47] ogbg-moltox21: 0.753448 test loss: 0.701128
[Epoch 48; Iter     1/  157] train: loss: 0.1329938
[Epoch 48; Iter    31/  157] train: loss: 0.1719617
[Epoch 48; Iter    61/  157] train: loss: 0.1946504
[Epoch 48; Iter    91/  157] train: loss: 0.0820955
[Epoch 48; Iter   121/  157] train: loss: 0.1626516
[Epoch 48; Iter   151/  157] train: loss: 0.1390059
[Epoch 48] ogbg-moltox21: 0.760557 val loss: 0.319364
[Epoch 48] ogbg-moltox21: 0.749869 test loss: 0.442344
[Epoch 49; Iter    24/  157] train: loss: 0.0850795
[Epoch 49; Iter    54/  157] train: loss: 0.1169709
[Epoch 49; Iter    84/  157] train: loss: 0.1052296
[Epoch 49; Iter   114/  157] train: loss: 0.0856660
[Epoch 49; Iter   144/  157] train: loss: 0.1091187
[Epoch 49] ogbg-moltox21: 0.755151 val loss: 0.340263
[Epoch 49] ogbg-moltox21: 0.751702 test loss: 0.508914
[Epoch 50; Iter    17/  157] train: loss: 0.0552983
[Epoch 50; Iter    47/  157] train: loss: 0.1141416
[Epoch 50; Iter    77/  157] train: loss: 0.1094735
[Epoch 50; Iter   107/  157] train: loss: 0.1123184
[Epoch 50; Iter   137/  157] train: loss: 0.1234009
[Epoch 50] ogbg-moltox21: 0.746838 val loss: 0.325095
[Epoch 50] ogbg-moltox21: 0.736027 test loss: 0.434643
[Epoch 51; Iter    10/  157] train: loss: 0.1321490
[Epoch 51; Iter    40/  157] train: loss: 0.0924129
[Epoch 51; Iter    70/  157] train: loss: 0.0980858
[Epoch 51; Iter   100/  157] train: loss: 0.0753052
[Epoch 51; Iter   130/  157] train: loss: 0.2179531
[Epoch 51] ogbg-moltox21: 0.757371 val loss: 0.334630
[Epoch 51] ogbg-moltox21: 0.747107 test loss: 0.537686
[Epoch 52; Iter     3/  157] train: loss: 0.1383255
[Epoch 52; Iter    33/  157] train: loss: 0.0807350
[Epoch 52; Iter    63/  157] train: loss: 0.1517688
[Epoch 52; Iter    93/  157] train: loss: 0.1019364
[Epoch 52; Iter   123/  157] train: loss: 0.1377899
[Epoch 52; Iter   153/  157] train: loss: 0.1290951
[Epoch 52] ogbg-moltox21: 0.744661 val loss: 0.349524
[Epoch 52] ogbg-moltox21: 0.736895 test loss: 0.547411
[Epoch 53; Iter    26/  157] train: loss: 0.0935103
[Epoch 53; Iter    56/  157] train: loss: 0.1064952
[Epoch 53; Iter    86/  157] train: loss: 0.0801280
[Epoch 53; Iter   116/  157] train: loss: 0.1205679
[Epoch 53; Iter   146/  157] train: loss: 0.1083740
[Epoch 53] ogbg-moltox21: 0.759080 val loss: 0.339110
[Epoch 53] ogbg-moltox21: 0.749199 test loss: 1.079907
[Epoch 54; Iter    19/  157] train: loss: 0.1387609
[Epoch 54; Iter    49/  157] train: loss: 0.0686411
[Epoch 54; Iter    79/  157] train: loss: 0.1493222
[Epoch 54; Iter   109/  157] train: loss: 0.1360314
[Epoch 54; Iter   139/  157] train: loss: 0.0940640
[Epoch 54] ogbg-moltox21: 0.744085 val loss: 0.370481
[Epoch 54] ogbg-moltox21: 0.741228 test loss: 1.106242
[Epoch 55; Iter    12/  157] train: loss: 0.1397347
[Epoch 55; Iter    42/  157] train: loss: 0.1204977
[Epoch 55; Iter    72/  157] train: loss: 0.0912576
[Epoch 55; Iter   102/  157] train: loss: 0.0632576
[Epoch 55; Iter   132/  157] train: loss: 0.1287363
[Epoch 55] ogbg-moltox21: 0.748273 val loss: 0.356110
[Epoch 55] ogbg-moltox21: 0.743579 test loss: 0.656178
[Epoch 56; Iter     5/  157] train: loss: 0.0697741
[Epoch 56; Iter    35/  157] train: loss: 0.1120704
[Epoch 56; Iter    65/  157] train: loss: 0.0810238
[Epoch 56; Iter    95/  157] train: loss: 0.0734757
[Epoch 56; Iter   125/  157] train: loss: 0.1366746
[Epoch 56; Iter   155/  157] train: loss: 0.1245622
[Epoch 56] ogbg-moltox21: 0.746882 val loss: 0.334338
[Epoch 56] ogbg-moltox21: 0.742083 test loss: 0.522214
[Epoch 57; Iter    28/  157] train: loss: 0.0947393
[Epoch 57; Iter    58/  157] train: loss: 0.0935011
[Epoch 57; Iter    88/  157] train: loss: 0.0913294
[Epoch 57; Iter   118/  157] train: loss: 0.0978190
[Epoch 57; Iter   148/  157] train: loss: 0.1358126
[Epoch 57] ogbg-moltox21: 0.744748 val loss: 0.347630
[Epoch 57] ogbg-moltox21: 0.736310 test loss: 0.427664
[Epoch 58; Iter    21/  157] train: loss: 0.0858429
[Epoch 58; Iter    51/  157] train: loss: 0.1095643
[Epoch 58; Iter    81/  157] train: loss: 0.0693857
[Epoch 58; Iter   111/  157] train: loss: 0.0758974
[Epoch 58; Iter   141/  157] train: loss: 0.0773989
[Epoch 37; Iter    78/  157] train: loss: 0.1185380
[Epoch 37; Iter   108/  157] train: loss: 0.1675849
[Epoch 37; Iter   138/  157] train: loss: 0.0587214
[Epoch 37] ogbg-moltox21: 0.754950 val loss: 0.361130
[Epoch 37] ogbg-moltox21: 0.737788 test loss: 0.376531
[Epoch 38; Iter    11/  157] train: loss: 0.1906954
[Epoch 38; Iter    41/  157] train: loss: 0.1171174
[Epoch 38; Iter    71/  157] train: loss: 0.1338174
[Epoch 38; Iter   101/  157] train: loss: 0.1383167
[Epoch 38; Iter   131/  157] train: loss: 0.1596953
[Epoch 38] ogbg-moltox21: 0.777499 val loss: 0.321112
[Epoch 38] ogbg-moltox21: 0.743783 test loss: 0.374097
[Epoch 39; Iter     4/  157] train: loss: 0.1460100
[Epoch 39; Iter    34/  157] train: loss: 0.0920640
[Epoch 39; Iter    64/  157] train: loss: 0.0995178
[Epoch 39; Iter    94/  157] train: loss: 0.1615258
[Epoch 39; Iter   124/  157] train: loss: 0.1003363
[Epoch 39; Iter   154/  157] train: loss: 0.0952698
[Epoch 39] ogbg-moltox21: 0.780115 val loss: 0.329536
[Epoch 39] ogbg-moltox21: 0.756311 test loss: 0.417364
[Epoch 40; Iter    27/  157] train: loss: 0.1148402
[Epoch 40; Iter    57/  157] train: loss: 0.1186470
[Epoch 40; Iter    87/  157] train: loss: 0.0863277
[Epoch 40; Iter   117/  157] train: loss: 0.1065699
[Epoch 40; Iter   147/  157] train: loss: 0.0903254
[Epoch 40] ogbg-moltox21: 0.791626 val loss: 0.304770
[Epoch 40] ogbg-moltox21: 0.761051 test loss: 0.475725
[Epoch 41; Iter    20/  157] train: loss: 0.0963515
[Epoch 41; Iter    50/  157] train: loss: 0.0881543
[Epoch 41; Iter    80/  157] train: loss: 0.1089249
[Epoch 41; Iter   110/  157] train: loss: 0.1669839
[Epoch 41; Iter   140/  157] train: loss: 0.1765520
[Epoch 41] ogbg-moltox21: 0.785108 val loss: 0.333038
[Epoch 41] ogbg-moltox21: 0.759100 test loss: 0.367098
[Epoch 42; Iter    13/  157] train: loss: 0.0652400
[Epoch 42; Iter    43/  157] train: loss: 0.0982562
[Epoch 42; Iter    73/  157] train: loss: 0.0816522
[Epoch 42; Iter   103/  157] train: loss: 0.1073096
[Epoch 42; Iter   133/  157] train: loss: 0.0920193
[Epoch 42] ogbg-moltox21: 0.772084 val loss: 0.333215
[Epoch 42] ogbg-moltox21: 0.743844 test loss: 0.594557
[Epoch 43; Iter     6/  157] train: loss: 0.1155518
[Epoch 43; Iter    36/  157] train: loss: 0.1319155
[Epoch 43; Iter    66/  157] train: loss: 0.1193655
[Epoch 43; Iter    96/  157] train: loss: 0.1882900
[Epoch 43; Iter   126/  157] train: loss: 0.0934933
[Epoch 43; Iter   156/  157] train: loss: 0.1256857
[Epoch 43] ogbg-moltox21: 0.771252 val loss: 0.329218
[Epoch 43] ogbg-moltox21: 0.749767 test loss: 0.351325
[Epoch 44; Iter    29/  157] train: loss: 0.1102558
[Epoch 44; Iter    59/  157] train: loss: 0.1398228
[Epoch 44; Iter    89/  157] train: loss: 0.0956922
[Epoch 44; Iter   119/  157] train: loss: 0.1174883
[Epoch 44; Iter   149/  157] train: loss: 0.1037255
[Epoch 44] ogbg-moltox21: 0.776062 val loss: 0.329923
[Epoch 44] ogbg-moltox21: 0.751302 test loss: 0.355269
[Epoch 45; Iter    22/  157] train: loss: 0.0982843
[Epoch 45; Iter    52/  157] train: loss: 0.1189591
[Epoch 45; Iter    82/  157] train: loss: 0.1294326
[Epoch 45; Iter   112/  157] train: loss: 0.1011852
[Epoch 45; Iter   142/  157] train: loss: 0.0896864
[Epoch 45] ogbg-moltox21: 0.757642 val loss: 0.329918
[Epoch 45] ogbg-moltox21: 0.728987 test loss: 0.358476
[Epoch 46; Iter    15/  157] train: loss: 0.1031047
[Epoch 46; Iter    45/  157] train: loss: 0.1245748
[Epoch 46; Iter    75/  157] train: loss: 0.0998807
[Epoch 46; Iter   105/  157] train: loss: 0.0921179
[Epoch 46; Iter   135/  157] train: loss: 0.0968192
[Epoch 46] ogbg-moltox21: 0.752234 val loss: 0.327649
[Epoch 46] ogbg-moltox21: 0.725714 test loss: 0.696196
[Epoch 47; Iter     8/  157] train: loss: 0.1553152
[Epoch 47; Iter    38/  157] train: loss: 0.0605040
[Epoch 47; Iter    68/  157] train: loss: 0.1919437
[Epoch 47; Iter    98/  157] train: loss: 0.1141246
[Epoch 47; Iter   128/  157] train: loss: 0.0915114
[Epoch 47] ogbg-moltox21: 0.766701 val loss: 0.338902
[Epoch 47] ogbg-moltox21: 0.745325 test loss: 0.487486
[Epoch 48; Iter     1/  157] train: loss: 0.0976971
[Epoch 48; Iter    31/  157] train: loss: 0.1292986
[Epoch 48; Iter    61/  157] train: loss: 0.1169038
[Epoch 48; Iter    91/  157] train: loss: 0.1260439
[Epoch 48; Iter   121/  157] train: loss: 0.0933603
[Epoch 48; Iter   151/  157] train: loss: 0.0744727
[Epoch 48] ogbg-moltox21: 0.766653 val loss: 0.360360
[Epoch 48] ogbg-moltox21: 0.733455 test loss: 0.398130
[Epoch 49; Iter    24/  157] train: loss: 0.0855972
[Epoch 49; Iter    54/  157] train: loss: 0.1064803
[Epoch 49; Iter    84/  157] train: loss: 0.0624054
[Epoch 49; Iter   114/  157] train: loss: 0.1209431
[Epoch 49; Iter   144/  157] train: loss: 0.0869775
[Epoch 49] ogbg-moltox21: 0.762803 val loss: 0.337222
[Epoch 49] ogbg-moltox21: 0.736567 test loss: 0.345117
[Epoch 50; Iter    17/  157] train: loss: 0.0817578
[Epoch 50; Iter    47/  157] train: loss: 0.0943251
[Epoch 50; Iter    77/  157] train: loss: 0.0579549
[Epoch 50; Iter   107/  157] train: loss: 0.0935849
[Epoch 50; Iter   137/  157] train: loss: 0.1199210
[Epoch 50] ogbg-moltox21: 0.765840 val loss: 0.311989
[Epoch 50] ogbg-moltox21: 0.746038 test loss: 0.326784
[Epoch 51; Iter    10/  157] train: loss: 0.0968849
[Epoch 51; Iter    40/  157] train: loss: 0.1051333
[Epoch 51; Iter    70/  157] train: loss: 0.1012643
[Epoch 51; Iter   100/  157] train: loss: 0.1019726
[Epoch 51; Iter   130/  157] train: loss: 0.0890004
[Epoch 51] ogbg-moltox21: 0.777390 val loss: 0.338555
[Epoch 51] ogbg-moltox21: 0.745296 test loss: 0.437508
[Epoch 52; Iter     3/  157] train: loss: 0.0980331
[Epoch 52; Iter    33/  157] train: loss: 0.0576873
[Epoch 52; Iter    63/  157] train: loss: 0.0842472
[Epoch 52; Iter    93/  157] train: loss: 0.0767080
[Epoch 52; Iter   123/  157] train: loss: 0.0800116
[Epoch 52; Iter   153/  157] train: loss: 0.0891728
[Epoch 52] ogbg-moltox21: 0.770527 val loss: 0.335865
[Epoch 52] ogbg-moltox21: 0.738260 test loss: 0.373335
[Epoch 53; Iter    26/  157] train: loss: 0.1173261
[Epoch 53; Iter    56/  157] train: loss: 0.1171539
[Epoch 53; Iter    86/  157] train: loss: 0.0874389
[Epoch 53; Iter   116/  157] train: loss: 0.1026990
[Epoch 53; Iter   146/  157] train: loss: 0.1126615
[Epoch 53] ogbg-moltox21: 0.760908 val loss: 0.327358
[Epoch 53] ogbg-moltox21: 0.742977 test loss: 0.344555
[Epoch 54; Iter    19/  157] train: loss: 0.0436988
[Epoch 54; Iter    49/  157] train: loss: 0.0836840
[Epoch 54; Iter    79/  157] train: loss: 0.1115404
[Epoch 54; Iter   109/  157] train: loss: 0.0567389
[Epoch 54; Iter   139/  157] train: loss: 0.1157291
[Epoch 54] ogbg-moltox21: 0.769901 val loss: 0.360714
[Epoch 54] ogbg-moltox21: 0.752026 test loss: 0.378001
[Epoch 55; Iter    12/  157] train: loss: 0.1139700
[Epoch 55; Iter    42/  157] train: loss: 0.1420179
[Epoch 55; Iter    72/  157] train: loss: 0.0983691
[Epoch 55; Iter   102/  157] train: loss: 0.1331800
[Epoch 55; Iter   132/  157] train: loss: 0.1178368
[Epoch 55] ogbg-moltox21: 0.769646 val loss: 0.342626
[Epoch 55] ogbg-moltox21: 0.739314 test loss: 0.354305
[Epoch 56; Iter     5/  157] train: loss: 0.1226232
[Epoch 56; Iter    35/  157] train: loss: 0.0630357
[Epoch 56; Iter    65/  157] train: loss: 0.0799956
[Epoch 56; Iter    95/  157] train: loss: 0.0526080
[Epoch 56; Iter   125/  157] train: loss: 0.1176547
[Epoch 56; Iter   155/  157] train: loss: 0.0892387
[Epoch 56] ogbg-moltox21: 0.753035 val loss: 0.383274
[Epoch 56] ogbg-moltox21: 0.727643 test loss: 0.499946
[Epoch 57; Iter    28/  157] train: loss: 0.0725087
[Epoch 57; Iter    58/  157] train: loss: 0.0952227
[Epoch 57; Iter    88/  157] train: loss: 0.1108321
[Epoch 57; Iter   118/  157] train: loss: 0.0425761
[Epoch 57; Iter   148/  157] train: loss: 0.0870232
[Epoch 57] ogbg-moltox21: 0.753201 val loss: 0.425376
[Epoch 57] ogbg-moltox21: 0.728803 test loss: 0.508366
[Epoch 58; Iter    21/  157] train: loss: 0.1028677
[Epoch 58; Iter    51/  157] train: loss: 0.0627035
[Epoch 58; Iter    81/  157] train: loss: 0.1128870
[Epoch 58; Iter   111/  157] train: loss: 0.1105589
[Epoch 58; Iter   141/  157] train: loss: 0.0549642
[Epoch 37; Iter    78/  157] train: loss: 0.1091562
[Epoch 37; Iter   108/  157] train: loss: 0.2123787
[Epoch 37; Iter   138/  157] train: loss: 0.1735426
[Epoch 37] ogbg-moltox21: 0.750499 val loss: 0.322680
[Epoch 37] ogbg-moltox21: 0.744812 test loss: 0.319218
[Epoch 38; Iter    11/  157] train: loss: 0.1589920
[Epoch 38; Iter    41/  157] train: loss: 0.0857896
[Epoch 38; Iter    71/  157] train: loss: 0.1054100
[Epoch 38; Iter   101/  157] train: loss: 0.1715088
[Epoch 38; Iter   131/  157] train: loss: 0.2057825
[Epoch 38] ogbg-moltox21: 0.752857 val loss: 0.331564
[Epoch 38] ogbg-moltox21: 0.744537 test loss: 0.336375
[Epoch 39; Iter     4/  157] train: loss: 0.1657628
[Epoch 39; Iter    34/  157] train: loss: 0.1557581
[Epoch 39; Iter    64/  157] train: loss: 0.1464578
[Epoch 39; Iter    94/  157] train: loss: 0.1692383
[Epoch 39; Iter   124/  157] train: loss: 0.1346203
[Epoch 39; Iter   154/  157] train: loss: 0.1565284
[Epoch 39] ogbg-moltox21: 0.766134 val loss: 0.322216
[Epoch 39] ogbg-moltox21: 0.751201 test loss: 0.323522
[Epoch 40; Iter    27/  157] train: loss: 0.1421857
[Epoch 40; Iter    57/  157] train: loss: 0.1403100
[Epoch 40; Iter    87/  157] train: loss: 0.1897882
[Epoch 40; Iter   117/  157] train: loss: 0.1645988
[Epoch 40; Iter   147/  157] train: loss: 0.1167677
[Epoch 40] ogbg-moltox21: 0.748903 val loss: 0.369224
[Epoch 40] ogbg-moltox21: 0.734600 test loss: 0.356077
[Epoch 41; Iter    20/  157] train: loss: 0.1198718
[Epoch 41; Iter    50/  157] train: loss: 0.0901445
[Epoch 41; Iter    80/  157] train: loss: 0.0572393
[Epoch 41; Iter   110/  157] train: loss: 0.1359116
[Epoch 41; Iter   140/  157] train: loss: 0.0853107
[Epoch 41] ogbg-moltox21: 0.763976 val loss: 0.368162
[Epoch 41] ogbg-moltox21: 0.747760 test loss: 0.372055
[Epoch 42; Iter    13/  157] train: loss: 0.1457177
[Epoch 42; Iter    43/  157] train: loss: 0.1110047
[Epoch 42; Iter    73/  157] train: loss: 0.1833642
[Epoch 42; Iter   103/  157] train: loss: 0.0961405
[Epoch 42; Iter   133/  157] train: loss: 0.1039008
[Epoch 42] ogbg-moltox21: 0.764587 val loss: 0.323906
[Epoch 42] ogbg-moltox21: 0.752965 test loss: 0.324919
[Epoch 43; Iter     6/  157] train: loss: 0.0877150
[Epoch 43; Iter    36/  157] train: loss: 0.1528982
[Epoch 43; Iter    66/  157] train: loss: 0.0982175
[Epoch 43; Iter    96/  157] train: loss: 0.1161685
[Epoch 43; Iter   126/  157] train: loss: 0.1612596
[Epoch 43; Iter   156/  157] train: loss: 0.1271100
[Epoch 43] ogbg-moltox21: 0.759068 val loss: 0.514243
[Epoch 43] ogbg-moltox21: 0.747101 test loss: 0.340042
[Epoch 44; Iter    29/  157] train: loss: 0.1117777
[Epoch 44; Iter    59/  157] train: loss: 0.0945794
[Epoch 44; Iter    89/  157] train: loss: 0.1583216
[Epoch 44; Iter   119/  157] train: loss: 0.1823290
[Epoch 44; Iter   149/  157] train: loss: 0.0901617
[Epoch 44] ogbg-moltox21: 0.741472 val loss: 0.322648
[Epoch 44] ogbg-moltox21: 0.735204 test loss: 0.317429
[Epoch 45; Iter    22/  157] train: loss: 0.0993564
[Epoch 45; Iter    52/  157] train: loss: 0.0923743
[Epoch 45; Iter    82/  157] train: loss: 0.0972658
[Epoch 45; Iter   112/  157] train: loss: 0.1530641
[Epoch 45; Iter   142/  157] train: loss: 0.0870427
[Epoch 45] ogbg-moltox21: 0.757771 val loss: 0.409323
[Epoch 45] ogbg-moltox21: 0.745686 test loss: 0.338280
[Epoch 46; Iter    15/  157] train: loss: 0.1215493
[Epoch 46; Iter    45/  157] train: loss: 0.0725396
[Epoch 46; Iter    75/  157] train: loss: 0.1125770
[Epoch 46; Iter   105/  157] train: loss: 0.1109124
[Epoch 46; Iter   135/  157] train: loss: 0.0955766
[Epoch 46] ogbg-moltox21: 0.757684 val loss: 0.365395
[Epoch 46] ogbg-moltox21: 0.744326 test loss: 0.326867
[Epoch 47; Iter     8/  157] train: loss: 0.1826356
[Epoch 47; Iter    38/  157] train: loss: 0.1053916
[Epoch 47; Iter    68/  157] train: loss: 0.1089148
[Epoch 47; Iter    98/  157] train: loss: 0.0813124
[Epoch 47; Iter   128/  157] train: loss: 0.0846820
[Epoch 47] ogbg-moltox21: 0.754558 val loss: 0.383648
[Epoch 47] ogbg-moltox21: 0.739187 test loss: 0.335518
[Epoch 48; Iter     1/  157] train: loss: 0.0890941
[Epoch 48; Iter    31/  157] train: loss: 0.0859507
[Epoch 48; Iter    61/  157] train: loss: 0.1045978
[Epoch 48; Iter    91/  157] train: loss: 0.0806152
[Epoch 48; Iter   121/  157] train: loss: 0.1572023
[Epoch 48; Iter   151/  157] train: loss: 0.0830534
[Epoch 48] ogbg-moltox21: 0.763253 val loss: 0.339491
[Epoch 48] ogbg-moltox21: 0.748930 test loss: 0.335904
[Epoch 49; Iter    24/  157] train: loss: 0.1123662
[Epoch 49; Iter    54/  157] train: loss: 0.0764535
[Epoch 49; Iter    84/  157] train: loss: 0.1207291
[Epoch 49; Iter   114/  157] train: loss: 0.1066559
[Epoch 49; Iter   144/  157] train: loss: 0.0648755
[Epoch 49] ogbg-moltox21: 0.754981 val loss: 0.548853
[Epoch 49] ogbg-moltox21: 0.746396 test loss: 0.327480
[Epoch 50; Iter    17/  157] train: loss: 0.0968300
[Epoch 50; Iter    47/  157] train: loss: 0.1067551
[Epoch 50; Iter    77/  157] train: loss: 0.1294984
[Epoch 50; Iter   107/  157] train: loss: 0.1082919
[Epoch 50; Iter   137/  157] train: loss: 0.1495529
[Epoch 50] ogbg-moltox21: 0.753789 val loss: 0.431461
[Epoch 50] ogbg-moltox21: 0.733638 test loss: 0.355390
[Epoch 51; Iter    10/  157] train: loss: 0.1090698
[Epoch 51; Iter    40/  157] train: loss: 0.0741564
[Epoch 51; Iter    70/  157] train: loss: 0.1025518
[Epoch 51; Iter   100/  157] train: loss: 0.0845227
[Epoch 51; Iter   130/  157] train: loss: 0.1388082
[Epoch 51] ogbg-moltox21: 0.754710 val loss: 0.354720
[Epoch 51] ogbg-moltox21: 0.738209 test loss: 0.313961
[Epoch 52; Iter     3/  157] train: loss: 0.1180370
[Epoch 52; Iter    33/  157] train: loss: 0.0889115
[Epoch 52; Iter    63/  157] train: loss: 0.1015778
[Epoch 52; Iter    93/  157] train: loss: 0.1341597
[Epoch 52; Iter   123/  157] train: loss: 0.1547118
[Epoch 52; Iter   153/  157] train: loss: 0.1385824
[Epoch 52] ogbg-moltox21: 0.746797 val loss: 0.402881
[Epoch 52] ogbg-moltox21: 0.730664 test loss: 0.327439
[Epoch 53; Iter    26/  157] train: loss: 0.2683199
[Epoch 53; Iter    56/  157] train: loss: 0.0631256
[Epoch 53; Iter    86/  157] train: loss: 0.1218616
[Epoch 53; Iter   116/  157] train: loss: 0.1360292
[Epoch 53; Iter   146/  157] train: loss: 0.0687194
[Epoch 53] ogbg-moltox21: 0.749150 val loss: 0.507532
[Epoch 53] ogbg-moltox21: 0.738449 test loss: 0.337253
[Epoch 54; Iter    19/  157] train: loss: 0.0917392
[Epoch 54; Iter    49/  157] train: loss: 0.1128898
[Epoch 54; Iter    79/  157] train: loss: 0.1354458
[Epoch 54; Iter   109/  157] train: loss: 0.1100709
[Epoch 54; Iter   139/  157] train: loss: 0.1070816
[Epoch 54] ogbg-moltox21: 0.746971 val loss: 0.436110
[Epoch 54] ogbg-moltox21: 0.730792 test loss: 0.343595
[Epoch 55; Iter    12/  157] train: loss: 0.1123630
[Epoch 55; Iter    42/  157] train: loss: 0.1527593
[Epoch 55; Iter    72/  157] train: loss: 0.0718291
[Epoch 55; Iter   102/  157] train: loss: 0.1213951
[Epoch 55; Iter   132/  157] train: loss: 0.0968994
[Epoch 55] ogbg-moltox21: 0.750480 val loss: 0.348274
[Epoch 55] ogbg-moltox21: 0.731544 test loss: 0.335327
[Epoch 56; Iter     5/  157] train: loss: 0.0730118
[Epoch 56; Iter    35/  157] train: loss: 0.0971462
[Epoch 56; Iter    65/  157] train: loss: 0.1036644
[Epoch 56; Iter    95/  157] train: loss: 0.0639433
[Epoch 56; Iter   125/  157] train: loss: 0.0739006
[Epoch 56; Iter   155/  157] train: loss: 0.1131963
[Epoch 56] ogbg-moltox21: 0.750522 val loss: 0.362779
[Epoch 56] ogbg-moltox21: 0.730532 test loss: 0.363399
[Epoch 57; Iter    28/  157] train: loss: 0.1012116
[Epoch 57; Iter    58/  157] train: loss: 0.1294754
[Epoch 57; Iter    88/  157] train: loss: 0.0693548
[Epoch 57; Iter   118/  157] train: loss: 0.1318236
[Epoch 57; Iter   148/  157] train: loss: 0.0840840
[Epoch 57] ogbg-moltox21: 0.758158 val loss: 0.366445
[Epoch 57] ogbg-moltox21: 0.741001 test loss: 0.371067
[Epoch 58; Iter    21/  157] train: loss: 0.1436630
[Epoch 58; Iter    51/  157] train: loss: 0.1186364
[Epoch 58; Iter    81/  157] train: loss: 0.0628191
[Epoch 58; Iter   111/  157] train: loss: 0.0504320
[Epoch 58; Iter   141/  157] train: loss: 0.0959443
[Epoch 47; Iter   166/  209] train: loss: 0.1247554
[Epoch 47; Iter   196/  209] train: loss: 0.0947461
[Epoch 47] ogbg-moltox21: 0.794285 val loss: 0.258325
[Epoch 47] ogbg-moltox21: 0.761934 test loss: 0.274004
[Epoch 48; Iter    17/  209] train: loss: 0.1616188
[Epoch 48; Iter    47/  209] train: loss: 0.1134106
[Epoch 48; Iter    77/  209] train: loss: 0.1310697
[Epoch 48; Iter   107/  209] train: loss: 0.1234487
[Epoch 48; Iter   137/  209] train: loss: 0.1463749
[Epoch 48; Iter   167/  209] train: loss: 0.1611100
[Epoch 48; Iter   197/  209] train: loss: 0.1108677
[Epoch 48] ogbg-moltox21: 0.800149 val loss: 0.259583
[Epoch 48] ogbg-moltox21: 0.766959 test loss: 0.278882
[Epoch 49; Iter    18/  209] train: loss: 0.1026259
[Epoch 49; Iter    48/  209] train: loss: 0.0820967
[Epoch 49; Iter    78/  209] train: loss: 0.1018353
[Epoch 49; Iter   108/  209] train: loss: 0.1064309
[Epoch 49; Iter   138/  209] train: loss: 0.1328312
[Epoch 49; Iter   168/  209] train: loss: 0.1616674
[Epoch 49; Iter   198/  209] train: loss: 0.1394102
[Epoch 49] ogbg-moltox21: 0.791482 val loss: 0.256008
[Epoch 49] ogbg-moltox21: 0.754013 test loss: 0.279370
[Epoch 50; Iter    19/  209] train: loss: 0.1945646
[Epoch 50; Iter    49/  209] train: loss: 0.0726315
[Epoch 50; Iter    79/  209] train: loss: 0.0899358
[Epoch 50; Iter   109/  209] train: loss: 0.1218607
[Epoch 50; Iter   139/  209] train: loss: 0.0860796
[Epoch 50; Iter   169/  209] train: loss: 0.0867175
[Epoch 50; Iter   199/  209] train: loss: 0.0715370
[Epoch 50] ogbg-moltox21: 0.798981 val loss: 0.258995
[Epoch 50] ogbg-moltox21: 0.755125 test loss: 0.278629
[Epoch 51; Iter    20/  209] train: loss: 0.1411200
[Epoch 51; Iter    50/  209] train: loss: 0.1055000
[Epoch 51; Iter    80/  209] train: loss: 0.0724384
[Epoch 51; Iter   110/  209] train: loss: 0.0830922
[Epoch 51; Iter   140/  209] train: loss: 0.1236017
[Epoch 51; Iter   170/  209] train: loss: 0.1238120
[Epoch 51; Iter   200/  209] train: loss: 0.1282129
[Epoch 51] ogbg-moltox21: 0.799517 val loss: 0.260779
[Epoch 51] ogbg-moltox21: 0.760814 test loss: 0.285446
[Epoch 52; Iter    21/  209] train: loss: 0.1246748
[Epoch 52; Iter    51/  209] train: loss: 0.1093812
[Epoch 52; Iter    81/  209] train: loss: 0.1643715
[Epoch 52; Iter   111/  209] train: loss: 0.1595833
[Epoch 52; Iter   141/  209] train: loss: 0.0925660
[Epoch 52; Iter   171/  209] train: loss: 0.1002057
[Epoch 52; Iter   201/  209] train: loss: 0.1336611
[Epoch 52] ogbg-moltox21: 0.792068 val loss: 0.265335
[Epoch 52] ogbg-moltox21: 0.754123 test loss: 0.283191
[Epoch 53; Iter    22/  209] train: loss: 0.1125186
[Epoch 53; Iter    52/  209] train: loss: 0.0884290
[Epoch 53; Iter    82/  209] train: loss: 0.1308524
[Epoch 53; Iter   112/  209] train: loss: 0.0848740
[Epoch 53; Iter   142/  209] train: loss: 0.0792607
[Epoch 53; Iter   172/  209] train: loss: 0.1119487
[Epoch 53; Iter   202/  209] train: loss: 0.1020775
[Epoch 53] ogbg-moltox21: 0.781654 val loss: 0.269366
[Epoch 53] ogbg-moltox21: 0.747137 test loss: 0.289811
[Epoch 54; Iter    23/  209] train: loss: 0.1063977
[Epoch 54; Iter    53/  209] train: loss: 0.1343933
[Epoch 54; Iter    83/  209] train: loss: 0.0891018
[Epoch 54; Iter   113/  209] train: loss: 0.1072244
[Epoch 54; Iter   143/  209] train: loss: 0.1332627
[Epoch 54; Iter   173/  209] train: loss: 0.1374802
[Epoch 54; Iter   203/  209] train: loss: 0.1124232
[Epoch 54] ogbg-moltox21: 0.792564 val loss: 0.274174
[Epoch 54] ogbg-moltox21: 0.751276 test loss: 0.292015
[Epoch 55; Iter    24/  209] train: loss: 0.1030609
[Epoch 55; Iter    54/  209] train: loss: 0.1019890
[Epoch 55; Iter    84/  209] train: loss: 0.1168526
[Epoch 55; Iter   114/  209] train: loss: 0.1290234
[Epoch 55; Iter   144/  209] train: loss: 0.1430221
[Epoch 55; Iter   174/  209] train: loss: 0.1016130
[Epoch 55; Iter   204/  209] train: loss: 0.0720824
[Epoch 55] ogbg-moltox21: 0.784165 val loss: 0.276879
[Epoch 55] ogbg-moltox21: 0.743418 test loss: 0.301863
[Epoch 56; Iter    25/  209] train: loss: 0.1419020
[Epoch 56; Iter    55/  209] train: loss: 0.1149282
[Epoch 56; Iter    85/  209] train: loss: 0.1003136
[Epoch 56; Iter   115/  209] train: loss: 0.1269504
[Epoch 56; Iter   145/  209] train: loss: 0.1504386
[Epoch 56; Iter   175/  209] train: loss: 0.1360828
[Epoch 56; Iter   205/  209] train: loss: 0.0930049
[Epoch 56] ogbg-moltox21: 0.785092 val loss: 0.284085
[Epoch 56] ogbg-moltox21: 0.760860 test loss: 0.297937
[Epoch 57; Iter    26/  209] train: loss: 0.0810087
[Epoch 57; Iter    56/  209] train: loss: 0.1344152
[Epoch 57; Iter    86/  209] train: loss: 0.1528144
[Epoch 57; Iter   116/  209] train: loss: 0.0464303
[Epoch 57; Iter   146/  209] train: loss: 0.0880145
[Epoch 57; Iter   176/  209] train: loss: 0.1808199
[Epoch 57; Iter   206/  209] train: loss: 0.1484459
[Epoch 57] ogbg-moltox21: 0.791056 val loss: 0.271228
[Epoch 57] ogbg-moltox21: 0.750635 test loss: 0.299893
[Epoch 58; Iter    27/  209] train: loss: 0.0889210
[Epoch 58; Iter    57/  209] train: loss: 0.0587472
[Epoch 58; Iter    87/  209] train: loss: 0.1355461
[Epoch 58; Iter   117/  209] train: loss: 0.0636747
[Epoch 58; Iter   147/  209] train: loss: 0.0836216
[Epoch 58; Iter   177/  209] train: loss: 0.0794847
[Epoch 58; Iter   207/  209] train: loss: 0.1096053
[Epoch 58] ogbg-moltox21: 0.793479 val loss: 0.282588
[Epoch 58] ogbg-moltox21: 0.748705 test loss: 0.304709
[Epoch 59; Iter    28/  209] train: loss: 0.1763225
[Epoch 59; Iter    58/  209] train: loss: 0.1634491
[Epoch 59; Iter    88/  209] train: loss: 0.1098707
[Epoch 59; Iter   118/  209] train: loss: 0.0921515
[Epoch 59; Iter   148/  209] train: loss: 0.1200300
[Epoch 59; Iter   178/  209] train: loss: 0.1469053
[Epoch 59; Iter   208/  209] train: loss: 0.1331240
[Epoch 59] ogbg-moltox21: 0.781692 val loss: 0.273777
[Epoch 59] ogbg-moltox21: 0.746795 test loss: 0.296244
[Epoch 60; Iter    29/  209] train: loss: 0.0970290
[Epoch 60; Iter    59/  209] train: loss: 0.0630239
[Epoch 60; Iter    89/  209] train: loss: 0.0758814
[Epoch 60; Iter   119/  209] train: loss: 0.1070068
[Epoch 60; Iter   149/  209] train: loss: 0.1034948
[Epoch 60; Iter   179/  209] train: loss: 0.0955141
[Epoch 60; Iter   209/  209] train: loss: 0.1936533
[Epoch 60] ogbg-moltox21: 0.787391 val loss: 0.285404
[Epoch 60] ogbg-moltox21: 0.745870 test loss: 0.311771
[Epoch 61; Iter    30/  209] train: loss: 0.1084253
[Epoch 61; Iter    60/  209] train: loss: 0.1083430
[Epoch 61; Iter    90/  209] train: loss: 0.0756442
[Epoch 61; Iter   120/  209] train: loss: 0.1148922
[Epoch 61; Iter   150/  209] train: loss: 0.1367266
[Epoch 61; Iter   180/  209] train: loss: 0.1145673
[Epoch 61] ogbg-moltox21: 0.783601 val loss: 0.299311
[Epoch 61] ogbg-moltox21: 0.736391 test loss: 0.329875
[Epoch 62; Iter     1/  209] train: loss: 0.0932567
[Epoch 62; Iter    31/  209] train: loss: 0.0948118
[Epoch 62; Iter    61/  209] train: loss: 0.0844309
[Epoch 62; Iter    91/  209] train: loss: 0.1300767
[Epoch 62; Iter   121/  209] train: loss: 0.0988833
[Epoch 62; Iter   151/  209] train: loss: 0.1225337
[Epoch 62; Iter   181/  209] train: loss: 0.1197695
[Epoch 62] ogbg-moltox21: 0.782283 val loss: 0.283086
[Epoch 62] ogbg-moltox21: 0.739893 test loss: 0.316116
[Epoch 63; Iter     2/  209] train: loss: 0.1179197
[Epoch 63; Iter    32/  209] train: loss: 0.1986160
[Epoch 63; Iter    62/  209] train: loss: 0.1084091
[Epoch 63; Iter    92/  209] train: loss: 0.0764371
[Epoch 63; Iter   122/  209] train: loss: 0.1152202
[Epoch 63; Iter   152/  209] train: loss: 0.1018760
[Epoch 63; Iter   182/  209] train: loss: 0.0708698
[Epoch 63] ogbg-moltox21: 0.779873 val loss: 0.295105
[Epoch 63] ogbg-moltox21: 0.743608 test loss: 0.320320
[Epoch 64; Iter     3/  209] train: loss: 0.0821141
[Epoch 64; Iter    33/  209] train: loss: 0.1028473
[Epoch 64; Iter    63/  209] train: loss: 0.1176662
[Epoch 64; Iter    93/  209] train: loss: 0.0733822
[Epoch 64; Iter   123/  209] train: loss: 0.1518519
[Epoch 64; Iter   153/  209] train: loss: 0.1950446
[Epoch 64; Iter   183/  209] train: loss: 0.1026371
[Epoch 64] ogbg-moltox21: 0.789605 val loss: 0.294816
[Epoch 47; Iter   166/  209] train: loss: 0.1137387
[Epoch 47; Iter   196/  209] train: loss: 0.1423750
[Epoch 47] ogbg-moltox21: 0.792572 val loss: 0.249177
[Epoch 47] ogbg-moltox21: 0.757933 test loss: 0.263954
[Epoch 48; Iter    17/  209] train: loss: 0.1120187
[Epoch 48; Iter    47/  209] train: loss: 0.1335494
[Epoch 48; Iter    77/  209] train: loss: 0.1142477
[Epoch 48; Iter   107/  209] train: loss: 0.0809634
[Epoch 48; Iter   137/  209] train: loss: 0.1734364
[Epoch 48; Iter   167/  209] train: loss: 0.1196777
[Epoch 48; Iter   197/  209] train: loss: 0.0688173
[Epoch 48] ogbg-moltox21: 0.801981 val loss: 0.251584
[Epoch 48] ogbg-moltox21: 0.761762 test loss: 0.267952
[Epoch 49; Iter    18/  209] train: loss: 0.1182378
[Epoch 49; Iter    48/  209] train: loss: 0.1143518
[Epoch 49; Iter    78/  209] train: loss: 0.1605288
[Epoch 49; Iter   108/  209] train: loss: 0.1791905
[Epoch 49; Iter   138/  209] train: loss: 0.1044399
[Epoch 49; Iter   168/  209] train: loss: 0.1145616
[Epoch 49; Iter   198/  209] train: loss: 0.1823270
[Epoch 49] ogbg-moltox21: 0.796756 val loss: 0.271725
[Epoch 49] ogbg-moltox21: 0.759843 test loss: 0.283663
[Epoch 50; Iter    19/  209] train: loss: 0.0983291
[Epoch 50; Iter    49/  209] train: loss: 0.1187318
[Epoch 50; Iter    79/  209] train: loss: 0.0935309
[Epoch 50; Iter   109/  209] train: loss: 0.1311110
[Epoch 50; Iter   139/  209] train: loss: 0.1600639
[Epoch 50; Iter   169/  209] train: loss: 0.1152149
[Epoch 50; Iter   199/  209] train: loss: 0.1439957
[Epoch 50] ogbg-moltox21: 0.797975 val loss: 0.251801
[Epoch 50] ogbg-moltox21: 0.751411 test loss: 0.271885
[Epoch 51; Iter    20/  209] train: loss: 0.1200497
[Epoch 51; Iter    50/  209] train: loss: 0.1606304
[Epoch 51; Iter    80/  209] train: loss: 0.0783325
[Epoch 51; Iter   110/  209] train: loss: 0.1232741
[Epoch 51; Iter   140/  209] train: loss: 0.1403126
[Epoch 51; Iter   170/  209] train: loss: 0.1419874
[Epoch 51; Iter   200/  209] train: loss: 0.1507840
[Epoch 51] ogbg-moltox21: 0.795001 val loss: 0.260484
[Epoch 51] ogbg-moltox21: 0.764764 test loss: 0.276222
[Epoch 52; Iter    21/  209] train: loss: 0.1021592
[Epoch 52; Iter    51/  209] train: loss: 0.1150521
[Epoch 52; Iter    81/  209] train: loss: 0.1138158
[Epoch 52; Iter   111/  209] train: loss: 0.1133675
[Epoch 52; Iter   141/  209] train: loss: 0.0683706
[Epoch 52; Iter   171/  209] train: loss: 0.1513376
[Epoch 52; Iter   201/  209] train: loss: 0.0934363
[Epoch 52] ogbg-moltox21: 0.805234 val loss: 0.261844
[Epoch 52] ogbg-moltox21: 0.753744 test loss: 0.288356
[Epoch 53; Iter    22/  209] train: loss: 0.1254078
[Epoch 53; Iter    52/  209] train: loss: 0.1460659
[Epoch 53; Iter    82/  209] train: loss: 0.0659577
[Epoch 53; Iter   112/  209] train: loss: 0.1866011
[Epoch 53; Iter   142/  209] train: loss: 0.1256967
[Epoch 53; Iter   172/  209] train: loss: 0.0849802
[Epoch 53; Iter   202/  209] train: loss: 0.1318101
[Epoch 53] ogbg-moltox21: 0.804704 val loss: 0.252194
[Epoch 53] ogbg-moltox21: 0.754306 test loss: 0.275425
[Epoch 54; Iter    23/  209] train: loss: 0.1395939
[Epoch 54; Iter    53/  209] train: loss: 0.0840251
[Epoch 54; Iter    83/  209] train: loss: 0.0879550
[Epoch 54; Iter   113/  209] train: loss: 0.0891511
[Epoch 54; Iter   143/  209] train: loss: 0.1835766
[Epoch 54; Iter   173/  209] train: loss: 0.1006122
[Epoch 54; Iter   203/  209] train: loss: 0.1561936
[Epoch 54] ogbg-moltox21: 0.799963 val loss: 0.257773
[Epoch 54] ogbg-moltox21: 0.756670 test loss: 0.271154
[Epoch 55; Iter    24/  209] train: loss: 0.1032270
[Epoch 55; Iter    54/  209] train: loss: 0.1079574
[Epoch 55; Iter    84/  209] train: loss: 0.1211628
[Epoch 55; Iter   114/  209] train: loss: 0.0851304
[Epoch 55; Iter   144/  209] train: loss: 0.1334883
[Epoch 55; Iter   174/  209] train: loss: 0.1572275
[Epoch 55; Iter   204/  209] train: loss: 0.0977513
[Epoch 55] ogbg-moltox21: 0.800777 val loss: 0.258367
[Epoch 55] ogbg-moltox21: 0.766817 test loss: 0.269489
[Epoch 56; Iter    25/  209] train: loss: 0.1526307
[Epoch 56; Iter    55/  209] train: loss: 0.1255544
[Epoch 56; Iter    85/  209] train: loss: 0.1386022
[Epoch 56; Iter   115/  209] train: loss: 0.1117283
[Epoch 56; Iter   145/  209] train: loss: 0.0933305
[Epoch 56; Iter   175/  209] train: loss: 0.0747995
[Epoch 56; Iter   205/  209] train: loss: 0.1154257
[Epoch 56] ogbg-moltox21: 0.797266 val loss: 0.255107
[Epoch 56] ogbg-moltox21: 0.762555 test loss: 0.273504
[Epoch 57; Iter    26/  209] train: loss: 0.0675808
[Epoch 57; Iter    56/  209] train: loss: 0.0940124
[Epoch 57; Iter    86/  209] train: loss: 0.1440952
[Epoch 57; Iter   116/  209] train: loss: 0.0768694
[Epoch 57; Iter   146/  209] train: loss: 0.1180681
[Epoch 57; Iter   176/  209] train: loss: 0.1130180
[Epoch 57; Iter   206/  209] train: loss: 0.1035222
[Epoch 57] ogbg-moltox21: 0.789435 val loss: 0.275184
[Epoch 57] ogbg-moltox21: 0.753827 test loss: 0.301566
[Epoch 58; Iter    27/  209] train: loss: 0.1117142
[Epoch 58; Iter    57/  209] train: loss: 0.0913930
[Epoch 58; Iter    87/  209] train: loss: 0.1001210
[Epoch 58; Iter   117/  209] train: loss: 0.0953195
[Epoch 58; Iter   147/  209] train: loss: 0.1203426
[Epoch 58; Iter   177/  209] train: loss: 0.1059474
[Epoch 58; Iter   207/  209] train: loss: 0.0819014
[Epoch 58] ogbg-moltox21: 0.790525 val loss: 0.265300
[Epoch 58] ogbg-moltox21: 0.751967 test loss: 0.281804
[Epoch 59; Iter    28/  209] train: loss: 0.0992327
[Epoch 59; Iter    58/  209] train: loss: 0.0816407
[Epoch 59; Iter    88/  209] train: loss: 0.1483413
[Epoch 59; Iter   118/  209] train: loss: 0.1404247
[Epoch 59; Iter   148/  209] train: loss: 0.1385026
[Epoch 59; Iter   178/  209] train: loss: 0.0618189
[Epoch 59; Iter   208/  209] train: loss: 0.1174094
[Epoch 59] ogbg-moltox21: 0.798039 val loss: 0.276963
[Epoch 59] ogbg-moltox21: 0.764962 test loss: 0.286082
[Epoch 60; Iter    29/  209] train: loss: 0.1441683
[Epoch 60; Iter    59/  209] train: loss: 0.0901906
[Epoch 60; Iter    89/  209] train: loss: 0.0730303
[Epoch 60; Iter   119/  209] train: loss: 0.1238561
[Epoch 60; Iter   149/  209] train: loss: 0.1209468
[Epoch 60; Iter   179/  209] train: loss: 0.2153251
[Epoch 60; Iter   209/  209] train: loss: 0.1152999
[Epoch 60] ogbg-moltox21: 0.794750 val loss: 0.267134
[Epoch 60] ogbg-moltox21: 0.759564 test loss: 0.284203
[Epoch 61; Iter    30/  209] train: loss: 0.0896512
[Epoch 61; Iter    60/  209] train: loss: 0.1131461
[Epoch 61; Iter    90/  209] train: loss: 0.1830376
[Epoch 61; Iter   120/  209] train: loss: 0.1086389
[Epoch 61; Iter   150/  209] train: loss: 0.1095622
[Epoch 61; Iter   180/  209] train: loss: 0.0954863
[Epoch 61] ogbg-moltox21: 0.795562 val loss: 0.269113
[Epoch 61] ogbg-moltox21: 0.760639 test loss: 0.289266
[Epoch 62; Iter     1/  209] train: loss: 0.0650493
[Epoch 62; Iter    31/  209] train: loss: 0.0867330
[Epoch 62; Iter    61/  209] train: loss: 0.0959015
[Epoch 62; Iter    91/  209] train: loss: 0.0871279
[Epoch 62; Iter   121/  209] train: loss: 0.1535941
[Epoch 62; Iter   151/  209] train: loss: 0.0776808
[Epoch 62; Iter   181/  209] train: loss: 0.1004841
[Epoch 62] ogbg-moltox21: 0.794520 val loss: 0.266487
[Epoch 62] ogbg-moltox21: 0.748139 test loss: 0.293122
[Epoch 63; Iter     2/  209] train: loss: 0.0995338
[Epoch 63; Iter    32/  209] train: loss: 0.1425606
[Epoch 63; Iter    62/  209] train: loss: 0.0827945
[Epoch 63; Iter    92/  209] train: loss: 0.0908979
[Epoch 63; Iter   122/  209] train: loss: 0.1021537
[Epoch 63; Iter   152/  209] train: loss: 0.0997436
[Epoch 63; Iter   182/  209] train: loss: 0.0992925
[Epoch 63] ogbg-moltox21: 0.792011 val loss: 0.276702
[Epoch 63] ogbg-moltox21: 0.758943 test loss: 0.289561
[Epoch 64; Iter     3/  209] train: loss: 0.0759877
[Epoch 64; Iter    33/  209] train: loss: 0.0923801
[Epoch 64; Iter    63/  209] train: loss: 0.0978626
[Epoch 64; Iter    93/  209] train: loss: 0.0864033
[Epoch 64; Iter   123/  209] train: loss: 0.1224849
[Epoch 64; Iter   153/  209] train: loss: 0.0812825
[Epoch 64; Iter   183/  209] train: loss: 0.1093712
[Epoch 64] ogbg-moltox21: 0.788955 val loss: 0.271465
[Epoch 47; Iter   166/  209] train: loss: 0.0749846
[Epoch 47; Iter   196/  209] train: loss: 0.1562106
[Epoch 47] ogbg-moltox21: 0.796670 val loss: 0.252888
[Epoch 47] ogbg-moltox21: 0.766682 test loss: 0.265848
[Epoch 48; Iter    17/  209] train: loss: 0.1601429
[Epoch 48; Iter    47/  209] train: loss: 0.1161615
[Epoch 48; Iter    77/  209] train: loss: 0.1381131
[Epoch 48; Iter   107/  209] train: loss: 0.1449893
[Epoch 48; Iter   137/  209] train: loss: 0.1485489
[Epoch 48; Iter   167/  209] train: loss: 0.1172305
[Epoch 48; Iter   197/  209] train: loss: 0.0942169
[Epoch 48] ogbg-moltox21: 0.802051 val loss: 0.257548
[Epoch 48] ogbg-moltox21: 0.772026 test loss: 0.271512
[Epoch 49; Iter    18/  209] train: loss: 0.1630658
[Epoch 49; Iter    48/  209] train: loss: 0.1418868
[Epoch 49; Iter    78/  209] train: loss: 0.0845249
[Epoch 49; Iter   108/  209] train: loss: 0.0807628
[Epoch 49; Iter   138/  209] train: loss: 0.1338396
[Epoch 49; Iter   168/  209] train: loss: 0.1789716
[Epoch 49; Iter   198/  209] train: loss: 0.1222323
[Epoch 49] ogbg-moltox21: 0.790473 val loss: 0.263697
[Epoch 49] ogbg-moltox21: 0.763484 test loss: 0.272184
[Epoch 50; Iter    19/  209] train: loss: 0.1231716
[Epoch 50; Iter    49/  209] train: loss: 0.0903154
[Epoch 50; Iter    79/  209] train: loss: 0.1639350
[Epoch 50; Iter   109/  209] train: loss: 0.1434245
[Epoch 50; Iter   139/  209] train: loss: 0.1074981
[Epoch 50; Iter   169/  209] train: loss: 0.1110453
[Epoch 50; Iter   199/  209] train: loss: 0.1592904
[Epoch 50] ogbg-moltox21: 0.799926 val loss: 0.256974
[Epoch 50] ogbg-moltox21: 0.771758 test loss: 0.264580
[Epoch 51; Iter    20/  209] train: loss: 0.1226407
[Epoch 51; Iter    50/  209] train: loss: 0.1078256
[Epoch 51; Iter    80/  209] train: loss: 0.0783533
[Epoch 51; Iter   110/  209] train: loss: 0.1569154
[Epoch 51; Iter   140/  209] train: loss: 0.1689419
[Epoch 51; Iter   170/  209] train: loss: 0.1568357
[Epoch 51; Iter   200/  209] train: loss: 0.0707461
[Epoch 51] ogbg-moltox21: 0.789104 val loss: 0.271364
[Epoch 51] ogbg-moltox21: 0.766185 test loss: 0.279986
[Epoch 52; Iter    21/  209] train: loss: 0.1629350
[Epoch 52; Iter    51/  209] train: loss: 0.0955402
[Epoch 52; Iter    81/  209] train: loss: 0.1057242
[Epoch 52; Iter   111/  209] train: loss: 0.1392273
[Epoch 52; Iter   141/  209] train: loss: 0.0858879
[Epoch 52; Iter   171/  209] train: loss: 0.1060015
[Epoch 52; Iter   201/  209] train: loss: 0.1740113
[Epoch 52] ogbg-moltox21: 0.801121 val loss: 0.263348
[Epoch 52] ogbg-moltox21: 0.779511 test loss: 0.270989
[Epoch 53; Iter    22/  209] train: loss: 0.1025965
[Epoch 53; Iter    52/  209] train: loss: 0.0925927
[Epoch 53; Iter    82/  209] train: loss: 0.1645389
[Epoch 53; Iter   112/  209] train: loss: 0.0743422
[Epoch 53; Iter   142/  209] train: loss: 0.1049977
[Epoch 53; Iter   172/  209] train: loss: 0.1183515
[Epoch 53; Iter   202/  209] train: loss: 0.1731521
[Epoch 53] ogbg-moltox21: 0.799791 val loss: 0.271337
[Epoch 53] ogbg-moltox21: 0.772987 test loss: 0.288853
[Epoch 54; Iter    23/  209] train: loss: 0.1041216
[Epoch 54; Iter    53/  209] train: loss: 0.0903605
[Epoch 54; Iter    83/  209] train: loss: 0.1104095
[Epoch 54; Iter   113/  209] train: loss: 0.1431894
[Epoch 54; Iter   143/  209] train: loss: 0.1471011
[Epoch 54; Iter   173/  209] train: loss: 0.1344637
[Epoch 54; Iter   203/  209] train: loss: 0.0946545
[Epoch 54] ogbg-moltox21: 0.790218 val loss: 0.283350
[Epoch 54] ogbg-moltox21: 0.766988 test loss: 0.288627
[Epoch 55; Iter    24/  209] train: loss: 0.0918364
[Epoch 55; Iter    54/  209] train: loss: 0.0933632
[Epoch 55; Iter    84/  209] train: loss: 0.0877763
[Epoch 55; Iter   114/  209] train: loss: 0.1233264
[Epoch 55; Iter   144/  209] train: loss: 0.0953674
[Epoch 55; Iter   174/  209] train: loss: 0.0870247
[Epoch 55; Iter   204/  209] train: loss: 0.0649903
[Epoch 55] ogbg-moltox21: 0.784050 val loss: 0.272266
[Epoch 55] ogbg-moltox21: 0.775751 test loss: 0.276199
[Epoch 56; Iter    25/  209] train: loss: 0.1471756
[Epoch 56; Iter    55/  209] train: loss: 0.0895719
[Epoch 56; Iter    85/  209] train: loss: 0.1053852
[Epoch 56; Iter   115/  209] train: loss: 0.0893493
[Epoch 56; Iter   145/  209] train: loss: 0.0461742
[Epoch 56; Iter   175/  209] train: loss: 0.1096080
[Epoch 56; Iter   205/  209] train: loss: 0.1309292
[Epoch 56] ogbg-moltox21: 0.789865 val loss: 0.280520
[Epoch 56] ogbg-moltox21: 0.770244 test loss: 0.297590
[Epoch 57; Iter    26/  209] train: loss: 0.1202179
[Epoch 57; Iter    56/  209] train: loss: 0.1236680
[Epoch 57; Iter    86/  209] train: loss: 0.1542256
[Epoch 57; Iter   116/  209] train: loss: 0.0932014
[Epoch 57; Iter   146/  209] train: loss: 0.1364357
[Epoch 57; Iter   176/  209] train: loss: 0.1346852
[Epoch 57; Iter   206/  209] train: loss: 0.1083331
[Epoch 57] ogbg-moltox21: 0.793685 val loss: 0.283326
[Epoch 57] ogbg-moltox21: 0.773700 test loss: 0.289168
[Epoch 58; Iter    27/  209] train: loss: 0.0978794
[Epoch 58; Iter    57/  209] train: loss: 0.0572169
[Epoch 58; Iter    87/  209] train: loss: 0.0987532
[Epoch 58; Iter   117/  209] train: loss: 0.1354851
[Epoch 58; Iter   147/  209] train: loss: 0.1015423
[Epoch 58; Iter   177/  209] train: loss: 0.0832051
[Epoch 58; Iter   207/  209] train: loss: 0.1214055
[Epoch 58] ogbg-moltox21: 0.787912 val loss: 0.278715
[Epoch 58] ogbg-moltox21: 0.771079 test loss: 0.289250
[Epoch 59; Iter    28/  209] train: loss: 0.1371959
[Epoch 59; Iter    58/  209] train: loss: 0.0761793
[Epoch 59; Iter    88/  209] train: loss: 0.1086374
[Epoch 59; Iter   118/  209] train: loss: 0.0724959
[Epoch 59; Iter   148/  209] train: loss: 0.1636084
[Epoch 59; Iter   178/  209] train: loss: 0.1249985
[Epoch 59; Iter   208/  209] train: loss: 0.1011601
[Epoch 59] ogbg-moltox21: 0.798760 val loss: 0.269924
[Epoch 59] ogbg-moltox21: 0.777536 test loss: 0.283098
[Epoch 60; Iter    29/  209] train: loss: 0.0801022
[Epoch 60; Iter    59/  209] train: loss: 0.0707713
[Epoch 60; Iter    89/  209] train: loss: 0.1139976
[Epoch 60; Iter   119/  209] train: loss: 0.1006480
[Epoch 60; Iter   149/  209] train: loss: 0.1019732
[Epoch 60; Iter   179/  209] train: loss: 0.0925014
[Epoch 60; Iter   209/  209] train: loss: 0.1117259
[Epoch 60] ogbg-moltox21: 0.784998 val loss: 0.275501
[Epoch 60] ogbg-moltox21: 0.764458 test loss: 0.289208
[Epoch 61; Iter    30/  209] train: loss: 0.0977165
[Epoch 61; Iter    60/  209] train: loss: 0.1241033
[Epoch 61; Iter    90/  209] train: loss: 0.1438774
[Epoch 61; Iter   120/  209] train: loss: 0.0882875
[Epoch 61; Iter   150/  209] train: loss: 0.1809478
[Epoch 61; Iter   180/  209] train: loss: 0.1674892
[Epoch 61] ogbg-moltox21: 0.786408 val loss: 0.309560
[Epoch 61] ogbg-moltox21: 0.769546 test loss: 0.296693
[Epoch 62; Iter     1/  209] train: loss: 0.1440432
[Epoch 62; Iter    31/  209] train: loss: 0.0602954
[Epoch 62; Iter    61/  209] train: loss: 0.0551077
[Epoch 62; Iter    91/  209] train: loss: 0.1120326
[Epoch 62; Iter   121/  209] train: loss: 0.1135693
[Epoch 62; Iter   151/  209] train: loss: 0.0698829
[Epoch 62; Iter   181/  209] train: loss: 0.0734346
[Epoch 62] ogbg-moltox21: 0.798827 val loss: 0.271863
[Epoch 62] ogbg-moltox21: 0.779236 test loss: 0.280240
[Epoch 63; Iter     2/  209] train: loss: 0.1007599
[Epoch 63; Iter    32/  209] train: loss: 0.1196746
[Epoch 63; Iter    62/  209] train: loss: 0.0855590
[Epoch 63; Iter    92/  209] train: loss: 0.1022096
[Epoch 63; Iter   122/  209] train: loss: 0.0908536
[Epoch 63; Iter   152/  209] train: loss: 0.0777135
[Epoch 63; Iter   182/  209] train: loss: 0.0694356
[Epoch 63] ogbg-moltox21: 0.793949 val loss: 0.290231
[Epoch 63] ogbg-moltox21: 0.771522 test loss: 0.303780
[Epoch 64; Iter     3/  209] train: loss: 0.1224229
[Epoch 64; Iter    33/  209] train: loss: 0.1008731
[Epoch 64; Iter    63/  209] train: loss: 0.0969410
[Epoch 64; Iter    93/  209] train: loss: 0.0973246
[Epoch 64; Iter   123/  209] train: loss: 0.1323050
[Epoch 64; Iter   153/  209] train: loss: 0.0900481
[Epoch 64; Iter   183/  209] train: loss: 0.1549830
[Epoch 64] ogbg-moltox21: 0.788340 val loss: 0.298017
[Epoch 52; Iter   147/  183] train: loss: 0.0812914
[Epoch 52; Iter   177/  183] train: loss: 0.1030511
[Epoch 52] ogbg-moltox21: 0.777338 val loss: 0.274905
[Epoch 52] ogbg-moltox21: 0.744321 test loss: 0.312235
[Epoch 53; Iter    24/  183] train: loss: 0.0825948
[Epoch 53; Iter    54/  183] train: loss: 0.1088395
[Epoch 53; Iter    84/  183] train: loss: 0.0794644
[Epoch 53; Iter   114/  183] train: loss: 0.1437358
[Epoch 53; Iter   144/  183] train: loss: 0.0652610
[Epoch 53; Iter   174/  183] train: loss: 0.1143167
[Epoch 53] ogbg-moltox21: 0.773543 val loss: 0.287455
[Epoch 53] ogbg-moltox21: 0.739227 test loss: 0.312252
[Epoch 54; Iter    21/  183] train: loss: 0.0983002
[Epoch 54; Iter    51/  183] train: loss: 0.1205932
[Epoch 54; Iter    81/  183] train: loss: 0.1206890
[Epoch 54; Iter   111/  183] train: loss: 0.1626703
[Epoch 54; Iter   141/  183] train: loss: 0.0845963
[Epoch 54; Iter   171/  183] train: loss: 0.0955991
[Epoch 54] ogbg-moltox21: 0.765197 val loss: 0.288322
[Epoch 54] ogbg-moltox21: 0.733371 test loss: 0.313244
[Epoch 55; Iter    18/  183] train: loss: 0.0902892
[Epoch 55; Iter    48/  183] train: loss: 0.1326983
[Epoch 55; Iter    78/  183] train: loss: 0.1123665
[Epoch 55; Iter   108/  183] train: loss: 0.1397701
[Epoch 55; Iter   138/  183] train: loss: 0.1305694
[Epoch 55; Iter   168/  183] train: loss: 0.1093811
[Epoch 55] ogbg-moltox21: 0.767405 val loss: 0.284991
[Epoch 55] ogbg-moltox21: 0.736867 test loss: 0.307860
[Epoch 56; Iter    15/  183] train: loss: 0.0833583
[Epoch 56; Iter    45/  183] train: loss: 0.1030982
[Epoch 56; Iter    75/  183] train: loss: 0.0471383
[Epoch 56; Iter   105/  183] train: loss: 0.1566868
[Epoch 56; Iter   135/  183] train: loss: 0.0809475
[Epoch 56; Iter   165/  183] train: loss: 0.1238683
[Epoch 56] ogbg-moltox21: 0.763468 val loss: 0.292946
[Epoch 56] ogbg-moltox21: 0.734089 test loss: 0.320247
[Epoch 57; Iter    12/  183] train: loss: 0.1141878
[Epoch 57; Iter    42/  183] train: loss: 0.1667486
[Epoch 57; Iter    72/  183] train: loss: 0.0882059
[Epoch 57; Iter   102/  183] train: loss: 0.0970011
[Epoch 57; Iter   132/  183] train: loss: 0.1318202
[Epoch 57; Iter   162/  183] train: loss: 0.1501344
[Epoch 57] ogbg-moltox21: 0.770359 val loss: 0.302492
[Epoch 57] ogbg-moltox21: 0.740900 test loss: 0.327049
[Epoch 58; Iter     9/  183] train: loss: 0.1127766
[Epoch 58; Iter    39/  183] train: loss: 0.1492915
[Epoch 58; Iter    69/  183] train: loss: 0.1038881
[Epoch 58; Iter    99/  183] train: loss: 0.1016456
[Epoch 58; Iter   129/  183] train: loss: 0.1261729
[Epoch 58; Iter   159/  183] train: loss: 0.1516418
[Epoch 58] ogbg-moltox21: 0.757143 val loss: 0.294950
[Epoch 58] ogbg-moltox21: 0.732037 test loss: 0.315656
[Epoch 59; Iter     6/  183] train: loss: 0.1535614
[Epoch 59; Iter    36/  183] train: loss: 0.1599590
[Epoch 59; Iter    66/  183] train: loss: 0.1369824
[Epoch 59; Iter    96/  183] train: loss: 0.0524352
[Epoch 59; Iter   126/  183] train: loss: 0.1569028
[Epoch 59; Iter   156/  183] train: loss: 0.1188324
[Epoch 59] ogbg-moltox21: 0.765405 val loss: 0.290265
[Epoch 59] ogbg-moltox21: 0.728018 test loss: 0.321327
[Epoch 60; Iter     3/  183] train: loss: 0.0702252
[Epoch 60; Iter    33/  183] train: loss: 0.1141264
[Epoch 60; Iter    63/  183] train: loss: 0.1230954
[Epoch 60; Iter    93/  183] train: loss: 0.0856850
[Epoch 60; Iter   123/  183] train: loss: 0.1447641
[Epoch 60; Iter   153/  183] train: loss: 0.1360067
[Epoch 60; Iter   183/  183] train: loss: 0.1195042
[Epoch 60] ogbg-moltox21: 0.763576 val loss: 0.289837
[Epoch 60] ogbg-moltox21: 0.739877 test loss: 0.310836
[Epoch 61; Iter    30/  183] train: loss: 0.1578547
[Epoch 61; Iter    60/  183] train: loss: 0.1307213
[Epoch 61; Iter    90/  183] train: loss: 0.0571950
[Epoch 61; Iter   120/  183] train: loss: 0.0986801
[Epoch 61; Iter   150/  183] train: loss: 0.1009364
[Epoch 61; Iter   180/  183] train: loss: 0.0989762
[Epoch 61] ogbg-moltox21: 0.767302 val loss: 0.300821
[Epoch 61] ogbg-moltox21: 0.733943 test loss: 0.323729
[Epoch 62; Iter    27/  183] train: loss: 0.0946062
[Epoch 62; Iter    57/  183] train: loss: 0.0861120
[Epoch 62; Iter    87/  183] train: loss: 0.0620001
[Epoch 62; Iter   117/  183] train: loss: 0.1123421
[Epoch 62; Iter   147/  183] train: loss: 0.1124757
[Epoch 62; Iter   177/  183] train: loss: 0.1248332
[Epoch 62] ogbg-moltox21: 0.764457 val loss: 0.294863
[Epoch 62] ogbg-moltox21: 0.730138 test loss: 0.321692
[Epoch 63; Iter    24/  183] train: loss: 0.0965593
[Epoch 63; Iter    54/  183] train: loss: 0.0880545
[Epoch 63; Iter    84/  183] train: loss: 0.1537237
[Epoch 63; Iter   114/  183] train: loss: 0.1135540
[Epoch 63; Iter   144/  183] train: loss: 0.0859472
[Epoch 63; Iter   174/  183] train: loss: 0.0913140
[Epoch 63] ogbg-moltox21: 0.764860 val loss: 0.302584
[Epoch 63] ogbg-moltox21: 0.733143 test loss: 0.329619
[Epoch 64; Iter    21/  183] train: loss: 0.1257489
[Epoch 64; Iter    51/  183] train: loss: 0.1081217
[Epoch 64; Iter    81/  183] train: loss: 0.0654510
[Epoch 64; Iter   111/  183] train: loss: 0.0814530
[Epoch 64; Iter   141/  183] train: loss: 0.1507325
[Epoch 64; Iter   171/  183] train: loss: 0.1181130
[Epoch 64] ogbg-moltox21: 0.757647 val loss: 0.314436
[Epoch 64] ogbg-moltox21: 0.731690 test loss: 0.342793
[Epoch 65; Iter    18/  183] train: loss: 0.1032730
[Epoch 65; Iter    48/  183] train: loss: 0.1130158
[Epoch 65; Iter    78/  183] train: loss: 0.0894264
[Epoch 65; Iter   108/  183] train: loss: 0.0517697
[Epoch 65; Iter   138/  183] train: loss: 0.0750949
[Epoch 65; Iter   168/  183] train: loss: 0.0716916
[Epoch 65] ogbg-moltox21: 0.758576 val loss: 0.299399
[Epoch 65] ogbg-moltox21: 0.735393 test loss: 0.345513
[Epoch 66; Iter    15/  183] train: loss: 0.0996568
[Epoch 66; Iter    45/  183] train: loss: 0.1543734
[Epoch 66; Iter    75/  183] train: loss: 0.1424384
[Epoch 66; Iter   105/  183] train: loss: 0.0852002
[Epoch 66; Iter   135/  183] train: loss: 0.0499138
[Epoch 66; Iter   165/  183] train: loss: 0.1334660
[Epoch 66] ogbg-moltox21: 0.755843 val loss: 0.322825
[Epoch 66] ogbg-moltox21: 0.740171 test loss: 0.358199
[Epoch 67; Iter    12/  183] train: loss: 0.0945299
[Epoch 67; Iter    42/  183] train: loss: 0.1229669
[Epoch 67; Iter    72/  183] train: loss: 0.0792850
[Epoch 67; Iter   102/  183] train: loss: 0.0744338
[Epoch 67; Iter   132/  183] train: loss: 0.0929191
[Epoch 67; Iter   162/  183] train: loss: 0.0943311
[Epoch 67] ogbg-moltox21: 0.758323 val loss: 0.304850
[Epoch 67] ogbg-moltox21: 0.727437 test loss: 0.335310
[Epoch 68; Iter     9/  183] train: loss: 0.1312106
[Epoch 68; Iter    39/  183] train: loss: 0.0880899
[Epoch 68; Iter    69/  183] train: loss: 0.1396849
[Epoch 68; Iter    99/  183] train: loss: 0.0847597
[Epoch 68; Iter   129/  183] train: loss: 0.1048683
[Epoch 68; Iter   159/  183] train: loss: 0.1081438
[Epoch 68] ogbg-moltox21: 0.758224 val loss: 0.312167
[Epoch 68] ogbg-moltox21: 0.732991 test loss: 0.381992
[Epoch 69; Iter     6/  183] train: loss: 0.0828422
[Epoch 69; Iter    36/  183] train: loss: 0.0961607
[Epoch 69; Iter    66/  183] train: loss: 0.0688948
[Epoch 69; Iter    96/  183] train: loss: 0.0482784
[Epoch 69; Iter   126/  183] train: loss: 0.1038919
[Epoch 69; Iter   156/  183] train: loss: 0.1179290
[Epoch 69] ogbg-moltox21: 0.754111 val loss: 0.330021
[Epoch 69] ogbg-moltox21: 0.723561 test loss: 0.365250
[Epoch 70; Iter     3/  183] train: loss: 0.0932916
[Epoch 70; Iter    33/  183] train: loss: 0.0803600
[Epoch 70; Iter    63/  183] train: loss: 0.1161594
[Epoch 70; Iter    93/  183] train: loss: 0.1446542
[Epoch 70; Iter   123/  183] train: loss: 0.0627522
[Epoch 70; Iter   153/  183] train: loss: 0.0968425
[Epoch 70; Iter   183/  183] train: loss: 0.0636835
[Epoch 70] ogbg-moltox21: 0.759421 val loss: 0.314721
[Epoch 70] ogbg-moltox21: 0.736262 test loss: 0.342068
[Epoch 71; Iter    30/  183] train: loss: 0.2055915
[Epoch 71; Iter    60/  183] train: loss: 0.0906946
[Epoch 71; Iter    90/  183] train: loss: 0.0844124
[Epoch 71; Iter   120/  183] train: loss: 0.1104956
[Epoch 71; Iter   150/  183] train: loss: 0.0979674
[Epoch 52; Iter   147/  183] train: loss: 0.1005036
[Epoch 52; Iter   177/  183] train: loss: 0.1448036
[Epoch 52] ogbg-moltox21: 0.760921 val loss: 0.296552
[Epoch 52] ogbg-moltox21: 0.744354 test loss: 0.322799
[Epoch 53; Iter    24/  183] train: loss: 0.1210646
[Epoch 53; Iter    54/  183] train: loss: 0.1189479
[Epoch 53; Iter    84/  183] train: loss: 0.1147341
[Epoch 53; Iter   114/  183] train: loss: 0.0908475
[Epoch 53; Iter   144/  183] train: loss: 0.1479934
[Epoch 53; Iter   174/  183] train: loss: 0.0976116
[Epoch 53] ogbg-moltox21: 0.746509 val loss: 0.308069
[Epoch 53] ogbg-moltox21: 0.722510 test loss: 0.332267
[Epoch 54; Iter    21/  183] train: loss: 0.0569238
[Epoch 54; Iter    51/  183] train: loss: 0.1381667
[Epoch 54; Iter    81/  183] train: loss: 0.0793020
[Epoch 54; Iter   111/  183] train: loss: 0.1515705
[Epoch 54; Iter   141/  183] train: loss: 0.0807156
[Epoch 54; Iter   171/  183] train: loss: 0.0574965
[Epoch 54] ogbg-moltox21: 0.758558 val loss: 0.309482
[Epoch 54] ogbg-moltox21: 0.734273 test loss: 0.336368
[Epoch 55; Iter    18/  183] train: loss: 0.0844343
[Epoch 55; Iter    48/  183] train: loss: 0.1506494
[Epoch 55; Iter    78/  183] train: loss: 0.0731080
[Epoch 55; Iter   108/  183] train: loss: 0.1237869
[Epoch 55; Iter   138/  183] train: loss: 0.1524020
[Epoch 55; Iter   168/  183] train: loss: 0.1574535
[Epoch 55] ogbg-moltox21: 0.750347 val loss: 0.327979
[Epoch 55] ogbg-moltox21: 0.732099 test loss: 0.341928
[Epoch 56; Iter    15/  183] train: loss: 0.0804547
[Epoch 56; Iter    45/  183] train: loss: 0.1540418
[Epoch 56; Iter    75/  183] train: loss: 0.0571248
[Epoch 56; Iter   105/  183] train: loss: 0.0838171
[Epoch 56; Iter   135/  183] train: loss: 0.0915144
[Epoch 56; Iter   165/  183] train: loss: 0.0832528
[Epoch 56] ogbg-moltox21: 0.749752 val loss: 0.313190
[Epoch 56] ogbg-moltox21: 0.736047 test loss: 0.332955
[Epoch 57; Iter    12/  183] train: loss: 0.1311288
[Epoch 57; Iter    42/  183] train: loss: 0.0758064
[Epoch 57; Iter    72/  183] train: loss: 0.1148263
[Epoch 57; Iter   102/  183] train: loss: 0.0889016
[Epoch 57; Iter   132/  183] train: loss: 0.1007873
[Epoch 57; Iter   162/  183] train: loss: 0.1071220
[Epoch 57] ogbg-moltox21: 0.740548 val loss: 0.369179
[Epoch 57] ogbg-moltox21: 0.722151 test loss: 0.366960
[Epoch 58; Iter     9/  183] train: loss: 0.0610137
[Epoch 58; Iter    39/  183] train: loss: 0.1102013
[Epoch 58; Iter    69/  183] train: loss: 0.0774731
[Epoch 58; Iter    99/  183] train: loss: 0.0946309
[Epoch 58; Iter   129/  183] train: loss: 0.0983275
[Epoch 58; Iter   159/  183] train: loss: 0.0789259
[Epoch 58] ogbg-moltox21: 0.742070 val loss: 0.364258
[Epoch 58] ogbg-moltox21: 0.729361 test loss: 0.358822
[Epoch 59; Iter     6/  183] train: loss: 0.1062811
[Epoch 59; Iter    36/  183] train: loss: 0.0922702
[Epoch 59; Iter    66/  183] train: loss: 0.1324109
[Epoch 59; Iter    96/  183] train: loss: 0.0752652
[Epoch 59; Iter   126/  183] train: loss: 0.0845843
[Epoch 59; Iter   156/  183] train: loss: 0.0694563
[Epoch 59] ogbg-moltox21: 0.749774 val loss: 0.340290
[Epoch 59] ogbg-moltox21: 0.733386 test loss: 0.358722
[Epoch 60; Iter     3/  183] train: loss: 0.1211859
[Epoch 60; Iter    33/  183] train: loss: 0.0987210
[Epoch 60; Iter    63/  183] train: loss: 0.1144911
[Epoch 60; Iter    93/  183] train: loss: 0.1425599
[Epoch 60; Iter   123/  183] train: loss: 0.1109636
[Epoch 60; Iter   153/  183] train: loss: 0.1353535
[Epoch 60; Iter   183/  183] train: loss: 0.0777088
[Epoch 60] ogbg-moltox21: 0.740327 val loss: 0.328633
[Epoch 60] ogbg-moltox21: 0.725336 test loss: 0.340774
[Epoch 61; Iter    30/  183] train: loss: 0.1372881
[Epoch 61; Iter    60/  183] train: loss: 0.1003374
[Epoch 61; Iter    90/  183] train: loss: 0.0665283
[Epoch 61; Iter   120/  183] train: loss: 0.0729340
[Epoch 61; Iter   150/  183] train: loss: 0.1328227
[Epoch 61; Iter   180/  183] train: loss: 0.0632098
[Epoch 61] ogbg-moltox21: 0.739314 val loss: 0.351655
[Epoch 61] ogbg-moltox21: 0.722635 test loss: 0.357985
[Epoch 62; Iter    27/  183] train: loss: 0.0760204
[Epoch 62; Iter    57/  183] train: loss: 0.0774187
[Epoch 62; Iter    87/  183] train: loss: 0.0615962
[Epoch 62; Iter   117/  183] train: loss: 0.0650867
[Epoch 62; Iter   147/  183] train: loss: 0.1086273
[Epoch 62; Iter   177/  183] train: loss: 0.1217833
[Epoch 62] ogbg-moltox21: 0.740978 val loss: 0.349205
[Epoch 62] ogbg-moltox21: 0.726229 test loss: 0.362559
[Epoch 63; Iter    24/  183] train: loss: 0.0899056
[Epoch 63; Iter    54/  183] train: loss: 0.1027481
[Epoch 63; Iter    84/  183] train: loss: 0.1295456
[Epoch 63; Iter   114/  183] train: loss: 0.1533432
[Epoch 63; Iter   144/  183] train: loss: 0.0768907
[Epoch 63; Iter   174/  183] train: loss: 0.1040356
[Epoch 63] ogbg-moltox21: 0.758292 val loss: 0.376936
[Epoch 63] ogbg-moltox21: 0.731953 test loss: 0.380900
[Epoch 64; Iter    21/  183] train: loss: 0.0829693
[Epoch 64; Iter    51/  183] train: loss: 0.0807078
[Epoch 64; Iter    81/  183] train: loss: 0.0868229
[Epoch 64; Iter   111/  183] train: loss: 0.1266434
[Epoch 64; Iter   141/  183] train: loss: 0.0784976
[Epoch 64; Iter   171/  183] train: loss: 0.1693808
[Epoch 64] ogbg-moltox21: 0.742696 val loss: 0.354667
[Epoch 64] ogbg-moltox21: 0.725404 test loss: 0.363398
[Epoch 65; Iter    18/  183] train: loss: 0.0826638
[Epoch 65; Iter    48/  183] train: loss: 0.0729763
[Epoch 65; Iter    78/  183] train: loss: 0.0560742
[Epoch 65; Iter   108/  183] train: loss: 0.0932359
[Epoch 65; Iter   138/  183] train: loss: 0.0441868
[Epoch 65; Iter   168/  183] train: loss: 0.0516777
[Epoch 65] ogbg-moltox21: 0.745225 val loss: 0.439037
[Epoch 65] ogbg-moltox21: 0.721709 test loss: 0.408695
[Epoch 66; Iter    15/  183] train: loss: 0.0949019
[Epoch 66; Iter    45/  183] train: loss: 0.0944799
[Epoch 66; Iter    75/  183] train: loss: 0.0742649
[Epoch 66; Iter   105/  183] train: loss: 0.0953328
[Epoch 66; Iter   135/  183] train: loss: 0.1203437
[Epoch 66; Iter   165/  183] train: loss: 0.0965050
[Epoch 66] ogbg-moltox21: 0.739818 val loss: 0.340318
[Epoch 66] ogbg-moltox21: 0.723871 test loss: 0.356982
[Epoch 67; Iter    12/  183] train: loss: 0.0660260
[Epoch 67; Iter    42/  183] train: loss: 0.0702769
[Epoch 67; Iter    72/  183] train: loss: 0.0692144
[Epoch 67; Iter   102/  183] train: loss: 0.1119924
[Epoch 67; Iter   132/  183] train: loss: 0.0861400
[Epoch 67; Iter   162/  183] train: loss: 0.1018741
[Epoch 67] ogbg-moltox21: 0.746032 val loss: 0.402569
[Epoch 67] ogbg-moltox21: 0.717168 test loss: 0.398493
[Epoch 68; Iter     9/  183] train: loss: 0.0707767
[Epoch 68; Iter    39/  183] train: loss: 0.0730904
[Epoch 68; Iter    69/  183] train: loss: 0.1349560
[Epoch 68; Iter    99/  183] train: loss: 0.0626538
[Epoch 68; Iter   129/  183] train: loss: 0.1050096
[Epoch 68; Iter   159/  183] train: loss: 0.0618467
[Epoch 68] ogbg-moltox21: 0.747612 val loss: 0.381420
[Epoch 68] ogbg-moltox21: 0.722024 test loss: 0.392236
[Epoch 69; Iter     6/  183] train: loss: 0.0658474
[Epoch 69; Iter    36/  183] train: loss: 0.0461216
[Epoch 69; Iter    66/  183] train: loss: 0.0471575
[Epoch 69; Iter    96/  183] train: loss: 0.0706547
[Epoch 69; Iter   126/  183] train: loss: 0.0585641
[Epoch 69; Iter   156/  183] train: loss: 0.0813061
[Epoch 69] ogbg-moltox21: 0.741570 val loss: 0.352613
[Epoch 69] ogbg-moltox21: 0.715616 test loss: 0.371937
[Epoch 70; Iter     3/  183] train: loss: 0.0664231
[Epoch 70; Iter    33/  183] train: loss: 0.0745378
[Epoch 70; Iter    63/  183] train: loss: 0.1115022
[Epoch 70; Iter    93/  183] train: loss: 0.0542025
[Epoch 70; Iter   123/  183] train: loss: 0.0988344
[Epoch 70; Iter   153/  183] train: loss: 0.0662052
[Epoch 70; Iter   183/  183] train: loss: 0.1134621
[Epoch 70] ogbg-moltox21: 0.744000 val loss: 0.365465
[Epoch 70] ogbg-moltox21: 0.718939 test loss: 0.385809
[Epoch 71; Iter    30/  183] train: loss: 0.1239882
[Epoch 71; Iter    60/  183] train: loss: 0.0901720
[Epoch 71; Iter    90/  183] train: loss: 0.0841783
[Epoch 71; Iter   120/  183] train: loss: 0.0791825
[Epoch 71; Iter   150/  183] train: loss: 0.0729836
[Epoch 52; Iter   147/  183] train: loss: 0.0921696
[Epoch 52; Iter   177/  183] train: loss: 0.0615636
[Epoch 52] ogbg-moltox21: 0.744170 val loss: 0.323635
[Epoch 52] ogbg-moltox21: 0.735540 test loss: 0.326499
[Epoch 53; Iter    24/  183] train: loss: 0.1075872
[Epoch 53; Iter    54/  183] train: loss: 0.0967980
[Epoch 53; Iter    84/  183] train: loss: 0.1161445
[Epoch 53; Iter   114/  183] train: loss: 0.0891673
[Epoch 53; Iter   144/  183] train: loss: 0.1085585
[Epoch 53; Iter   174/  183] train: loss: 0.0908551
[Epoch 53] ogbg-moltox21: 0.753495 val loss: 0.297967
[Epoch 53] ogbg-moltox21: 0.740349 test loss: 0.310656
[Epoch 54; Iter    21/  183] train: loss: 0.0758068
[Epoch 54; Iter    51/  183] train: loss: 0.0774545
[Epoch 54; Iter    81/  183] train: loss: 0.0720171
[Epoch 54; Iter   111/  183] train: loss: 0.0919079
[Epoch 54; Iter   141/  183] train: loss: 0.1435856
[Epoch 54; Iter   171/  183] train: loss: 0.1492958
[Epoch 54] ogbg-moltox21: 0.732957 val loss: 0.303051
[Epoch 54] ogbg-moltox21: 0.719325 test loss: 0.315291
[Epoch 55; Iter    18/  183] train: loss: 0.1369663
[Epoch 55; Iter    48/  183] train: loss: 0.1032491
[Epoch 55; Iter    78/  183] train: loss: 0.1429089
[Epoch 55; Iter   108/  183] train: loss: 0.1027913
[Epoch 55; Iter   138/  183] train: loss: 0.0776624
[Epoch 55; Iter   168/  183] train: loss: 0.0634431
[Epoch 55] ogbg-moltox21: 0.742404 val loss: 0.324473
[Epoch 55] ogbg-moltox21: 0.731136 test loss: 0.328148
[Epoch 56; Iter    15/  183] train: loss: 0.1304070
[Epoch 56; Iter    45/  183] train: loss: 0.1041885
[Epoch 56; Iter    75/  183] train: loss: 0.1029358
[Epoch 56; Iter   105/  183] train: loss: 0.0841750
[Epoch 56; Iter   135/  183] train: loss: 0.0985611
[Epoch 56; Iter   165/  183] train: loss: 0.1032392
[Epoch 56] ogbg-moltox21: 0.742969 val loss: 0.321922
[Epoch 56] ogbg-moltox21: 0.727064 test loss: 0.334146
[Epoch 57; Iter    12/  183] train: loss: 0.0551951
[Epoch 57; Iter    42/  183] train: loss: 0.1050929
[Epoch 57; Iter    72/  183] train: loss: 0.1087568
[Epoch 57; Iter   102/  183] train: loss: 0.1213913
[Epoch 57; Iter   132/  183] train: loss: 0.0843086
[Epoch 57; Iter   162/  183] train: loss: 0.0767894
[Epoch 57] ogbg-moltox21: 0.743195 val loss: 0.304939
[Epoch 57] ogbg-moltox21: 0.750827 test loss: 0.308258
[Epoch 58; Iter     9/  183] train: loss: 0.0755849
[Epoch 58; Iter    39/  183] train: loss: 0.0924315
[Epoch 58; Iter    69/  183] train: loss: 0.0730232
[Epoch 58; Iter    99/  183] train: loss: 0.1005360
[Epoch 58; Iter   129/  183] train: loss: 0.0612258
[Epoch 58; Iter   159/  183] train: loss: 0.0824477
[Epoch 58] ogbg-moltox21: 0.757348 val loss: 0.329610
[Epoch 58] ogbg-moltox21: 0.739202 test loss: 0.344785
[Epoch 59; Iter     6/  183] train: loss: 0.0952270
[Epoch 59; Iter    36/  183] train: loss: 0.1186167
[Epoch 59; Iter    66/  183] train: loss: 0.1079435
[Epoch 59; Iter    96/  183] train: loss: 0.1242877
[Epoch 59; Iter   126/  183] train: loss: 0.0966446
[Epoch 59; Iter   156/  183] train: loss: 0.0911505
[Epoch 59] ogbg-moltox21: 0.741984 val loss: 0.324942
[Epoch 59] ogbg-moltox21: 0.733727 test loss: 0.339959
[Epoch 60; Iter     3/  183] train: loss: 0.0535557
[Epoch 60; Iter    33/  183] train: loss: 0.0570210
[Epoch 60; Iter    63/  183] train: loss: 0.0488609
[Epoch 60; Iter    93/  183] train: loss: 0.0696123
[Epoch 60; Iter   123/  183] train: loss: 0.0696432
[Epoch 60; Iter   153/  183] train: loss: 0.0532031
[Epoch 60; Iter   183/  183] train: loss: 0.1153745
[Epoch 60] ogbg-moltox21: 0.738299 val loss: 0.328617
[Epoch 60] ogbg-moltox21: 0.735570 test loss: 0.336951
[Epoch 61; Iter    30/  183] train: loss: 0.0621238
[Epoch 61; Iter    60/  183] train: loss: 0.0717318
[Epoch 61; Iter    90/  183] train: loss: 0.0874631
[Epoch 61; Iter   120/  183] train: loss: 0.1293863
[Epoch 61; Iter   150/  183] train: loss: 0.0493047
[Epoch 61; Iter   180/  183] train: loss: 0.0984526
[Epoch 61] ogbg-moltox21: 0.739845 val loss: 0.336643
[Epoch 61] ogbg-moltox21: 0.731677 test loss: 0.352015
[Epoch 62; Iter    27/  183] train: loss: 0.0993239
[Epoch 62; Iter    57/  183] train: loss: 0.1420381
[Epoch 62; Iter    87/  183] train: loss: 0.0621269
[Epoch 62; Iter   117/  183] train: loss: 0.0903330
[Epoch 62; Iter   147/  183] train: loss: 0.0931080
[Epoch 62; Iter   177/  183] train: loss: 0.0566251
[Epoch 62] ogbg-moltox21: 0.746760 val loss: 0.323155
[Epoch 62] ogbg-moltox21: 0.736280 test loss: 0.339085
[Epoch 63; Iter    24/  183] train: loss: 0.1121238
[Epoch 63; Iter    54/  183] train: loss: 0.0997920
[Epoch 63; Iter    84/  183] train: loss: 0.1010561
[Epoch 63; Iter   114/  183] train: loss: 0.0905022
[Epoch 63; Iter   144/  183] train: loss: 0.1301759
[Epoch 63; Iter   174/  183] train: loss: 0.0549457
[Epoch 63] ogbg-moltox21: 0.748819 val loss: 0.326566
[Epoch 63] ogbg-moltox21: 0.732324 test loss: 0.346494
[Epoch 64; Iter    21/  183] train: loss: 0.0663589
[Epoch 64; Iter    51/  183] train: loss: 0.1091136
[Epoch 64; Iter    81/  183] train: loss: 0.0712811
[Epoch 64; Iter   111/  183] train: loss: 0.1011259
[Epoch 64; Iter   141/  183] train: loss: 0.1184760
[Epoch 64; Iter   171/  183] train: loss: 0.0846091
[Epoch 64] ogbg-moltox21: 0.746366 val loss: 0.382541
[Epoch 64] ogbg-moltox21: 0.737540 test loss: 0.366572
[Epoch 65; Iter    18/  183] train: loss: 0.1189046
[Epoch 65; Iter    48/  183] train: loss: 0.0773245
[Epoch 65; Iter    78/  183] train: loss: 0.0836833
[Epoch 65; Iter   108/  183] train: loss: 0.0880175
[Epoch 65; Iter   138/  183] train: loss: 0.0649807
[Epoch 65; Iter   168/  183] train: loss: 0.0510927
[Epoch 65] ogbg-moltox21: 0.742168 val loss: 0.335775
[Epoch 65] ogbg-moltox21: 0.735657 test loss: 0.352053
[Epoch 66; Iter    15/  183] train: loss: 0.0835197
[Epoch 66; Iter    45/  183] train: loss: 0.0818600
[Epoch 66; Iter    75/  183] train: loss: 0.1155223
[Epoch 66; Iter   105/  183] train: loss: 0.0763488
[Epoch 66; Iter   135/  183] train: loss: 0.0804059
[Epoch 66; Iter   165/  183] train: loss: 0.0825325
[Epoch 66] ogbg-moltox21: 0.735336 val loss: 0.343262
[Epoch 66] ogbg-moltox21: 0.738332 test loss: 0.349574
[Epoch 67; Iter    12/  183] train: loss: 0.0768543
[Epoch 67; Iter    42/  183] train: loss: 0.0581561
[Epoch 67; Iter    72/  183] train: loss: 0.0708369
[Epoch 67; Iter   102/  183] train: loss: 0.0841205
[Epoch 67; Iter   132/  183] train: loss: 0.0667786
[Epoch 67; Iter   162/  183] train: loss: 0.0904929
[Epoch 67] ogbg-moltox21: 0.731156 val loss: 0.343908
[Epoch 67] ogbg-moltox21: 0.734633 test loss: 0.349734
[Epoch 68; Iter     9/  183] train: loss: 0.0387701
[Epoch 68; Iter    39/  183] train: loss: 0.0932226
[Epoch 68; Iter    69/  183] train: loss: 0.0714028
[Epoch 68; Iter    99/  183] train: loss: 0.0851474
[Epoch 68; Iter   129/  183] train: loss: 0.0956675
[Epoch 68; Iter   159/  183] train: loss: 0.0589175
[Epoch 68] ogbg-moltox21: 0.735201 val loss: 0.496519
[Epoch 68] ogbg-moltox21: 0.724268 test loss: 0.701188
[Epoch 69; Iter     6/  183] train: loss: 0.0547678
[Epoch 69; Iter    36/  183] train: loss: 0.0509117
[Epoch 69; Iter    66/  183] train: loss: 0.0796960
[Epoch 69; Iter    96/  183] train: loss: 0.1180179
[Epoch 69; Iter   126/  183] train: loss: 0.1268703
[Epoch 69; Iter   156/  183] train: loss: 0.1146325
[Epoch 69] ogbg-moltox21: 0.741438 val loss: 0.340602
[Epoch 69] ogbg-moltox21: 0.740157 test loss: 0.350933
[Epoch 70; Iter     3/  183] train: loss: 0.0648171
[Epoch 70; Iter    33/  183] train: loss: 0.0671348
[Epoch 70; Iter    63/  183] train: loss: 0.0578136
[Epoch 70; Iter    93/  183] train: loss: 0.0848809
[Epoch 70; Iter   123/  183] train: loss: 0.1058744
[Epoch 70; Iter   153/  183] train: loss: 0.0666600
[Epoch 70; Iter   183/  183] train: loss: 0.0473757
[Epoch 70] ogbg-moltox21: 0.736873 val loss: 0.347064
[Epoch 70] ogbg-moltox21: 0.731209 test loss: 0.362248
[Epoch 71; Iter    30/  183] train: loss: 0.0670095
[Epoch 71; Iter    60/  183] train: loss: 0.0656153
[Epoch 71; Iter    90/  183] train: loss: 0.0539542
[Epoch 71; Iter   120/  183] train: loss: 0.0730870
[Epoch 71; Iter   150/  183] train: loss: 0.0962470
[Epoch 58] ogbg-moltox21: 0.750839 val loss: 0.356850
[Epoch 58] ogbg-moltox21: 0.742816 test loss: 0.867967
[Epoch 59; Iter    14/  157] train: loss: 0.1203251
[Epoch 59; Iter    44/  157] train: loss: 0.1323001
[Epoch 59; Iter    74/  157] train: loss: 0.1479704
[Epoch 59; Iter   104/  157] train: loss: 0.1400330
[Epoch 59; Iter   134/  157] train: loss: 0.0715261
[Epoch 59] ogbg-moltox21: 0.741557 val loss: 0.337070
[Epoch 59] ogbg-moltox21: 0.732264 test loss: 0.980459
[Epoch 60; Iter     7/  157] train: loss: 0.0699300
[Epoch 60; Iter    37/  157] train: loss: 0.0884378
[Epoch 60; Iter    67/  157] train: loss: 0.0989607
[Epoch 60; Iter    97/  157] train: loss: 0.0855988
[Epoch 60; Iter   127/  157] train: loss: 0.0983503
[Epoch 60; Iter   157/  157] train: loss: 0.1209105
[Epoch 60] ogbg-moltox21: 0.737695 val loss: 0.386233
[Epoch 60] ogbg-moltox21: 0.731191 test loss: 1.372207
[Epoch 61; Iter    30/  157] train: loss: 0.0860270
[Epoch 61; Iter    60/  157] train: loss: 0.0469858
[Epoch 61; Iter    90/  157] train: loss: 0.0741083
[Epoch 61; Iter   120/  157] train: loss: 0.1028321
[Epoch 61; Iter   150/  157] train: loss: 0.1646542
[Epoch 61] ogbg-moltox21: 0.758987 val loss: 0.377168
[Epoch 61] ogbg-moltox21: 0.747807 test loss: 0.771695
[Epoch 62; Iter    23/  157] train: loss: 0.0993359
[Epoch 62; Iter    53/  157] train: loss: 0.1334864
[Epoch 62; Iter    83/  157] train: loss: 0.1412483
[Epoch 62; Iter   113/  157] train: loss: 0.0870102
[Epoch 62; Iter   143/  157] train: loss: 0.0831163
[Epoch 62] ogbg-moltox21: 0.732170 val loss: 0.337097
[Epoch 62] ogbg-moltox21: 0.730726 test loss: 1.163269
[Epoch 63; Iter    16/  157] train: loss: 0.0755289
[Epoch 63; Iter    46/  157] train: loss: 0.0929051
[Epoch 63; Iter    76/  157] train: loss: 0.1236098
[Epoch 63; Iter   106/  157] train: loss: 0.1224863
[Epoch 63; Iter   136/  157] train: loss: 0.0692631
[Epoch 63] ogbg-moltox21: 0.748875 val loss: 0.343874
[Epoch 63] ogbg-moltox21: 0.742087 test loss: 0.914617
[Epoch 64; Iter     9/  157] train: loss: 0.0709037
[Epoch 64; Iter    39/  157] train: loss: 0.0665655
[Epoch 64; Iter    69/  157] train: loss: 0.0906014
[Epoch 64; Iter    99/  157] train: loss: 0.1190814
[Epoch 64; Iter   129/  157] train: loss: 0.1783937
[Epoch 64] ogbg-moltox21: 0.741514 val loss: 0.357315
[Epoch 64] ogbg-moltox21: 0.734313 test loss: 1.181814
[Epoch 65; Iter     2/  157] train: loss: 0.0979201
[Epoch 65; Iter    32/  157] train: loss: 0.0748306
[Epoch 65; Iter    62/  157] train: loss: 0.1012615
[Epoch 65; Iter    92/  157] train: loss: 0.1127577
[Epoch 65; Iter   122/  157] train: loss: 0.0883175
[Epoch 65; Iter   152/  157] train: loss: 0.1080490
[Epoch 65] ogbg-moltox21: 0.741942 val loss: 0.364388
[Epoch 65] ogbg-moltox21: 0.735075 test loss: 1.260491
[Epoch 66; Iter    25/  157] train: loss: 0.1047329
[Epoch 66; Iter    55/  157] train: loss: 0.0500454
[Epoch 66; Iter    85/  157] train: loss: 0.1015638
[Epoch 66; Iter   115/  157] train: loss: 0.1167153
[Epoch 66; Iter   145/  157] train: loss: 0.0918992
[Epoch 66] ogbg-moltox21: 0.743502 val loss: 0.355886
[Epoch 66] ogbg-moltox21: 0.737147 test loss: 0.877471
[Epoch 67; Iter    18/  157] train: loss: 0.0856606
[Epoch 67; Iter    48/  157] train: loss: 0.0783324
[Epoch 67; Iter    78/  157] train: loss: 0.1014236
[Epoch 67; Iter   108/  157] train: loss: 0.0685132
[Epoch 67; Iter   138/  157] train: loss: 0.0698435
[Epoch 67] ogbg-moltox21: 0.745416 val loss: 0.368235
[Epoch 67] ogbg-moltox21: 0.736324 test loss: 1.156218
[Epoch 68; Iter    11/  157] train: loss: 0.0947714
[Epoch 68; Iter    41/  157] train: loss: 0.1080585
[Epoch 68; Iter    71/  157] train: loss: 0.0961105
[Epoch 68; Iter   101/  157] train: loss: 0.0542742
[Epoch 68; Iter   131/  157] train: loss: 0.0798282
[Epoch 68] ogbg-moltox21: 0.741982 val loss: 0.361401
[Epoch 68] ogbg-moltox21: 0.733817 test loss: 1.141145
[Epoch 69; Iter     4/  157] train: loss: 0.0867727
[Epoch 69; Iter    34/  157] train: loss: 0.1303195
[Epoch 69; Iter    64/  157] train: loss: 0.0473831
[Epoch 69; Iter    94/  157] train: loss: 0.0998995
[Epoch 69; Iter   124/  157] train: loss: 0.1043536
[Epoch 69; Iter   154/  157] train: loss: 0.1100539
[Epoch 69] ogbg-moltox21: 0.749676 val loss: 0.369647
[Epoch 69] ogbg-moltox21: 0.741430 test loss: 1.122120
[Epoch 70; Iter    27/  157] train: loss: 0.0559303
[Epoch 70; Iter    57/  157] train: loss: 0.0687269
[Epoch 70; Iter    87/  157] train: loss: 0.0621398
[Epoch 70; Iter   117/  157] train: loss: 0.0695817
[Epoch 70; Iter   147/  157] train: loss: 0.1602002
[Epoch 70] ogbg-moltox21: 0.737293 val loss: 0.364979
[Epoch 70] ogbg-moltox21: 0.733366 test loss: 1.046332
[Epoch 71; Iter    20/  157] train: loss: 0.0839663
[Epoch 71; Iter    50/  157] train: loss: 0.0578740
[Epoch 71; Iter    80/  157] train: loss: 0.0805573
[Epoch 71; Iter   110/  157] train: loss: 0.0896586
[Epoch 71; Iter   140/  157] train: loss: 0.0707242
[Epoch 71] ogbg-moltox21: 0.742008 val loss: 0.373722
[Epoch 71] ogbg-moltox21: 0.736596 test loss: 0.950339
[Epoch 72; Iter    13/  157] train: loss: 0.1019863
[Epoch 72; Iter    43/  157] train: loss: 0.0628404
[Epoch 72; Iter    73/  157] train: loss: 0.1114581
[Epoch 72; Iter   103/  157] train: loss: 0.0758209
[Epoch 72; Iter   133/  157] train: loss: 0.0820232
[Epoch 72] ogbg-moltox21: 0.739480 val loss: 0.358607
[Epoch 72] ogbg-moltox21: 0.727670 test loss: 0.914155
[Epoch 73; Iter     6/  157] train: loss: 0.0471119
[Epoch 73; Iter    36/  157] train: loss: 0.0697661
[Epoch 73; Iter    66/  157] train: loss: 0.0743736
[Epoch 73; Iter    96/  157] train: loss: 0.0641330
[Epoch 73; Iter   126/  157] train: loss: 0.1196670
[Epoch 73; Iter   156/  157] train: loss: 0.1313691
[Epoch 73] ogbg-moltox21: 0.727989 val loss: 0.372788
[Epoch 73] ogbg-moltox21: 0.723800 test loss: 1.107162
[Epoch 74; Iter    29/  157] train: loss: 0.0784641
[Epoch 74; Iter    59/  157] train: loss: 0.0728961
[Epoch 74; Iter    89/  157] train: loss: 0.0888270
[Epoch 74; Iter   119/  157] train: loss: 0.1069669
[Epoch 74; Iter   149/  157] train: loss: 0.0775222
[Epoch 74] ogbg-moltox21: 0.733452 val loss: 0.382136
[Epoch 74] ogbg-moltox21: 0.731946 test loss: 0.996495
[Epoch 75; Iter    22/  157] train: loss: 0.0504484
[Epoch 75; Iter    52/  157] train: loss: 0.0743110
[Epoch 75; Iter    82/  157] train: loss: 0.0658565
[Epoch 75; Iter   112/  157] train: loss: 0.0769435
[Epoch 75; Iter   142/  157] train: loss: 0.0588894
[Epoch 75] ogbg-moltox21: 0.734007 val loss: 0.400327
[Epoch 75] ogbg-moltox21: 0.727801 test loss: 0.960248
[Epoch 76; Iter    15/  157] train: loss: 0.0566423
[Epoch 76; Iter    45/  157] train: loss: 0.0512404
[Epoch 76; Iter    75/  157] train: loss: 0.0790701
[Epoch 76; Iter   105/  157] train: loss: 0.1563292
[Epoch 76; Iter   135/  157] train: loss: 0.0907859
[Epoch 76] ogbg-moltox21: 0.725650 val loss: 0.392208
[Epoch 76] ogbg-moltox21: 0.725283 test loss: 0.399332
[Epoch 77; Iter     8/  157] train: loss: 0.0651242
[Epoch 77; Iter    38/  157] train: loss: 0.0399013
[Epoch 77; Iter    68/  157] train: loss: 0.0999788
[Epoch 77; Iter    98/  157] train: loss: 0.0920318
[Epoch 77; Iter   128/  157] train: loss: 0.0772181
[Epoch 77] ogbg-moltox21: 0.731856 val loss: 0.395443
[Epoch 77] ogbg-moltox21: 0.723193 test loss: 0.403760
[Epoch 78; Iter     1/  157] train: loss: 0.1033052
[Epoch 78; Iter    31/  157] train: loss: 0.0843795
[Epoch 78; Iter    61/  157] train: loss: 0.1054859
[Epoch 78; Iter    91/  157] train: loss: 0.0883023
[Epoch 78; Iter   121/  157] train: loss: 0.0469061
[Epoch 78; Iter   151/  157] train: loss: 0.0738607
[Epoch 78] ogbg-moltox21: 0.727226 val loss: 0.392369
[Epoch 78] ogbg-moltox21: 0.727555 test loss: 0.404612
[Epoch 79; Iter    24/  157] train: loss: 0.0605921
[Epoch 79; Iter    54/  157] train: loss: 0.0521780
[Epoch 79; Iter    84/  157] train: loss: 0.0708284
[Epoch 79; Iter   114/  157] train: loss: 0.0912884
[Epoch 79; Iter   144/  157] train: loss: 0.0917475
[Epoch 79] ogbg-moltox21: 0.733003 val loss: 0.404227
[Epoch 79] ogbg-moltox21: 0.727169 test loss: 0.409804
[Epoch 80; Iter    17/  157] train: loss: 0.0958377
[Epoch 58] ogbg-moltox21: 0.759535 val loss: 0.402350
[Epoch 58] ogbg-moltox21: 0.723668 test loss: 0.523000
[Epoch 59; Iter    14/  157] train: loss: 0.0825086
[Epoch 59; Iter    44/  157] train: loss: 0.1078206
[Epoch 59; Iter    74/  157] train: loss: 0.0769108
[Epoch 59; Iter   104/  157] train: loss: 0.1144806
[Epoch 59; Iter   134/  157] train: loss: 0.1383964
[Epoch 59] ogbg-moltox21: 0.756629 val loss: 0.452502
[Epoch 59] ogbg-moltox21: 0.732961 test loss: 0.424718
[Epoch 60; Iter     7/  157] train: loss: 0.1163718
[Epoch 60; Iter    37/  157] train: loss: 0.0819481
[Epoch 60; Iter    67/  157] train: loss: 0.0758502
[Epoch 60; Iter    97/  157] train: loss: 0.0720910
[Epoch 60; Iter   127/  157] train: loss: 0.0679984
[Epoch 60; Iter   157/  157] train: loss: 0.1173947
[Epoch 60] ogbg-moltox21: 0.756646 val loss: 0.400138
[Epoch 60] ogbg-moltox21: 0.739225 test loss: 0.390363
[Epoch 61; Iter    30/  157] train: loss: 0.1362633
[Epoch 61; Iter    60/  157] train: loss: 0.0911595
[Epoch 61; Iter    90/  157] train: loss: 0.0679550
[Epoch 61; Iter   120/  157] train: loss: 0.0676763
[Epoch 61; Iter   150/  157] train: loss: 0.0692568
[Epoch 61] ogbg-moltox21: 0.764482 val loss: 0.337840
[Epoch 61] ogbg-moltox21: 0.743205 test loss: 0.360243
[Epoch 62; Iter    23/  157] train: loss: 0.1218036
[Epoch 62; Iter    53/  157] train: loss: 0.0729872
[Epoch 62; Iter    83/  157] train: loss: 0.1048511
[Epoch 62; Iter   113/  157] train: loss: 0.0968986
[Epoch 62; Iter   143/  157] train: loss: 0.1816581
[Epoch 62] ogbg-moltox21: 0.759472 val loss: 0.342629
[Epoch 62] ogbg-moltox21: 0.746846 test loss: 0.355706
[Epoch 63; Iter    16/  157] train: loss: 0.1127755
[Epoch 63; Iter    46/  157] train: loss: 0.0598118
[Epoch 63; Iter    76/  157] train: loss: 0.0598837
[Epoch 63; Iter   106/  157] train: loss: 0.0681678
[Epoch 63; Iter   136/  157] train: loss: 0.0811030
[Epoch 63] ogbg-moltox21: 0.749745 val loss: 0.446509
[Epoch 63] ogbg-moltox21: 0.735305 test loss: 0.376871
[Epoch 64; Iter     9/  157] train: loss: 0.0821608
[Epoch 64; Iter    39/  157] train: loss: 0.0730692
[Epoch 64; Iter    69/  157] train: loss: 0.1202682
[Epoch 64; Iter    99/  157] train: loss: 0.0649755
[Epoch 64; Iter   129/  157] train: loss: 0.0793309
[Epoch 64] ogbg-moltox21: 0.752479 val loss: 0.335643
[Epoch 64] ogbg-moltox21: 0.733646 test loss: 0.352577
[Epoch 65; Iter     2/  157] train: loss: 0.1141389
[Epoch 65; Iter    32/  157] train: loss: 0.0407444
[Epoch 65; Iter    62/  157] train: loss: 0.0651155
[Epoch 65; Iter    92/  157] train: loss: 0.1074153
[Epoch 65; Iter   122/  157] train: loss: 0.0943085
[Epoch 65; Iter   152/  157] train: loss: 0.1015407
[Epoch 65] ogbg-moltox21: 0.754357 val loss: 0.338777
[Epoch 65] ogbg-moltox21: 0.741529 test loss: 0.344777
[Epoch 66; Iter    25/  157] train: loss: 0.0946850
[Epoch 66; Iter    55/  157] train: loss: 0.0917815
[Epoch 66; Iter    85/  157] train: loss: 0.0939508
[Epoch 66; Iter   115/  157] train: loss: 0.1115055
[Epoch 66; Iter   145/  157] train: loss: 0.0680756
[Epoch 66] ogbg-moltox21: 0.750927 val loss: 0.353899
[Epoch 66] ogbg-moltox21: 0.738243 test loss: 0.372823
[Epoch 67; Iter    18/  157] train: loss: 0.1083085
[Epoch 67; Iter    48/  157] train: loss: 0.0815457
[Epoch 67; Iter    78/  157] train: loss: 0.0910337
[Epoch 67; Iter   108/  157] train: loss: 0.1568032
[Epoch 67; Iter   138/  157] train: loss: 0.0921394
[Epoch 67] ogbg-moltox21: 0.745524 val loss: 0.396485
[Epoch 67] ogbg-moltox21: 0.731023 test loss: 0.369342
[Epoch 68; Iter    11/  157] train: loss: 0.0828912
[Epoch 68; Iter    41/  157] train: loss: 0.0773371
[Epoch 68; Iter    71/  157] train: loss: 0.0958644
[Epoch 68; Iter   101/  157] train: loss: 0.0663272
[Epoch 68; Iter   131/  157] train: loss: 0.0689176
[Epoch 68] ogbg-moltox21: 0.752346 val loss: 0.359461
[Epoch 68] ogbg-moltox21: 0.735637 test loss: 0.420453
[Epoch 69; Iter     4/  157] train: loss: 0.0744266
[Epoch 69; Iter    34/  157] train: loss: 0.1072517
[Epoch 69; Iter    64/  157] train: loss: 0.0358639
[Epoch 69; Iter    94/  157] train: loss: 0.0599495
[Epoch 69; Iter   124/  157] train: loss: 0.1177782
[Epoch 69; Iter   154/  157] train: loss: 0.0539302
[Epoch 69] ogbg-moltox21: 0.741737 val loss: 0.376289
[Epoch 69] ogbg-moltox21: 0.733848 test loss: 0.385469
[Epoch 70; Iter    27/  157] train: loss: 0.0601523
[Epoch 70; Iter    57/  157] train: loss: 0.1031933
[Epoch 70; Iter    87/  157] train: loss: 0.0589719
[Epoch 70; Iter   117/  157] train: loss: 0.0793086
[Epoch 70; Iter   147/  157] train: loss: 0.0960952
[Epoch 70] ogbg-moltox21: 0.751324 val loss: 0.349126
[Epoch 70] ogbg-moltox21: 0.735806 test loss: 0.361552
[Epoch 71; Iter    20/  157] train: loss: 0.0599795
[Epoch 71; Iter    50/  157] train: loss: 0.0479452
[Epoch 71; Iter    80/  157] train: loss: 0.0588760
[Epoch 71; Iter   110/  157] train: loss: 0.1031934
[Epoch 71; Iter   140/  157] train: loss: 0.0840215
[Epoch 71] ogbg-moltox21: 0.747223 val loss: 0.400403
[Epoch 71] ogbg-moltox21: 0.732281 test loss: 0.395466
[Epoch 72; Iter    13/  157] train: loss: 0.0441888
[Epoch 72; Iter    43/  157] train: loss: 0.0870946
[Epoch 72; Iter    73/  157] train: loss: 0.0623748
[Epoch 72; Iter   103/  157] train: loss: 0.1132175
[Epoch 72; Iter   133/  157] train: loss: 0.1024031
[Epoch 72] ogbg-moltox21: 0.744827 val loss: 0.407989
[Epoch 72] ogbg-moltox21: 0.734809 test loss: 0.409653
[Epoch 73; Iter     6/  157] train: loss: 0.0905356
[Epoch 73; Iter    36/  157] train: loss: 0.0851529
[Epoch 73; Iter    66/  157] train: loss: 0.0711927
[Epoch 73; Iter    96/  157] train: loss: 0.0686914
[Epoch 73; Iter   126/  157] train: loss: 0.1290075
[Epoch 73; Iter   156/  157] train: loss: 0.0661660
[Epoch 73] ogbg-moltox21: 0.744767 val loss: 0.360309
[Epoch 73] ogbg-moltox21: 0.729829 test loss: 0.373276
[Epoch 74; Iter    29/  157] train: loss: 0.0639205
[Epoch 74; Iter    59/  157] train: loss: 0.0800173
[Epoch 74; Iter    89/  157] train: loss: 0.0616184
[Epoch 74; Iter   119/  157] train: loss: 0.1026831
[Epoch 74; Iter   149/  157] train: loss: 0.0721730
[Epoch 74] ogbg-moltox21: 0.739505 val loss: 0.375525
[Epoch 74] ogbg-moltox21: 0.730803 test loss: 0.396310
[Epoch 75; Iter    22/  157] train: loss: 0.1005042
[Epoch 75; Iter    52/  157] train: loss: 0.0562757
[Epoch 75; Iter    82/  157] train: loss: 0.0857008
[Epoch 75; Iter   112/  157] train: loss: 0.1408128
[Epoch 75; Iter   142/  157] train: loss: 0.1032356
[Epoch 75] ogbg-moltox21: 0.744005 val loss: 0.388059
[Epoch 75] ogbg-moltox21: 0.731812 test loss: 0.398987
[Epoch 76; Iter    15/  157] train: loss: 0.0747603
[Epoch 76; Iter    45/  157] train: loss: 0.0761524
[Epoch 76; Iter    75/  157] train: loss: 0.0782677
[Epoch 76; Iter   105/  157] train: loss: 0.0670052
[Epoch 76; Iter   135/  157] train: loss: 0.1182865
[Epoch 76] ogbg-moltox21: 0.734547 val loss: 0.421271
[Epoch 76] ogbg-moltox21: 0.727497 test loss: 0.408338
[Epoch 77; Iter     8/  157] train: loss: 0.0444671
[Epoch 77; Iter    38/  157] train: loss: 0.1232081
[Epoch 77; Iter    68/  157] train: loss: 0.0556982
[Epoch 77; Iter    98/  157] train: loss: 0.0967710
[Epoch 77; Iter   128/  157] train: loss: 0.0436019
[Epoch 77] ogbg-moltox21: 0.738851 val loss: 0.381886
[Epoch 77] ogbg-moltox21: 0.725163 test loss: 0.389226
[Epoch 78; Iter     1/  157] train: loss: 0.0511889
[Epoch 78; Iter    31/  157] train: loss: 0.1153280
[Epoch 78; Iter    61/  157] train: loss: 0.0689622
[Epoch 78; Iter    91/  157] train: loss: 0.0471092
[Epoch 78; Iter   121/  157] train: loss: 0.0464232
[Epoch 78; Iter   151/  157] train: loss: 0.0625370
[Epoch 78] ogbg-moltox21: 0.733468 val loss: 0.398927
[Epoch 78] ogbg-moltox21: 0.715410 test loss: 0.425316
[Epoch 79; Iter    24/  157] train: loss: 0.0785521
[Epoch 79; Iter    54/  157] train: loss: 0.0755455
[Epoch 79; Iter    84/  157] train: loss: 0.0858156
[Epoch 79; Iter   114/  157] train: loss: 0.0637755
[Epoch 79; Iter   144/  157] train: loss: 0.0765482
[Epoch 79] ogbg-moltox21: 0.733318 val loss: 0.403885
[Epoch 79] ogbg-moltox21: 0.720276 test loss: 0.411405
[Epoch 80; Iter    17/  157] train: loss: 0.0593051
[Epoch 58] ogbg-moltox21: 0.751565 val loss: 0.369807
[Epoch 58] ogbg-moltox21: 0.728156 test loss: 0.366264
[Epoch 59; Iter    14/  157] train: loss: 0.0863605
[Epoch 59; Iter    44/  157] train: loss: 0.1441506
[Epoch 59; Iter    74/  157] train: loss: 0.1371429
[Epoch 59; Iter   104/  157] train: loss: 0.0926655
[Epoch 59; Iter   134/  157] train: loss: 0.1026812
[Epoch 59] ogbg-moltox21: 0.752505 val loss: 0.527571
[Epoch 59] ogbg-moltox21: 0.730431 test loss: 0.351094
[Epoch 60; Iter     7/  157] train: loss: 0.0965992
[Epoch 60; Iter    37/  157] train: loss: 0.0811937
[Epoch 60; Iter    67/  157] train: loss: 0.0908450
[Epoch 60; Iter    97/  157] train: loss: 0.1028478
[Epoch 60; Iter   127/  157] train: loss: 0.0923973
[Epoch 60; Iter   157/  157] train: loss: 0.0872118
[Epoch 60] ogbg-moltox21: 0.746858 val loss: 0.521628
[Epoch 60] ogbg-moltox21: 0.727668 test loss: 0.351599
[Epoch 61; Iter    30/  157] train: loss: 0.0753944
[Epoch 61; Iter    60/  157] train: loss: 0.1023729
[Epoch 61; Iter    90/  157] train: loss: 0.0511910
[Epoch 61; Iter   120/  157] train: loss: 0.1001960
[Epoch 61; Iter   150/  157] train: loss: 0.0827458
[Epoch 61] ogbg-moltox21: 0.739320 val loss: 0.425845
[Epoch 61] ogbg-moltox21: 0.729792 test loss: 0.352050
[Epoch 62; Iter    23/  157] train: loss: 0.1297626
[Epoch 62; Iter    53/  157] train: loss: 0.0567090
[Epoch 62; Iter    83/  157] train: loss: 0.1029407
[Epoch 62; Iter   113/  157] train: loss: 0.0707296
[Epoch 62; Iter   143/  157] train: loss: 0.0543676
[Epoch 62] ogbg-moltox21: 0.744143 val loss: 0.543666
[Epoch 62] ogbg-moltox21: 0.732404 test loss: 0.356452
[Epoch 63; Iter    16/  157] train: loss: 0.0937377
[Epoch 63; Iter    46/  157] train: loss: 0.0782537
[Epoch 63; Iter    76/  157] train: loss: 0.0704454
[Epoch 63; Iter   106/  157] train: loss: 0.0533647
[Epoch 63; Iter   136/  157] train: loss: 0.0837765
[Epoch 63] ogbg-moltox21: 0.732843 val loss: 0.529897
[Epoch 63] ogbg-moltox21: 0.713329 test loss: 0.342721
[Epoch 64; Iter     9/  157] train: loss: 0.0655739
[Epoch 64; Iter    39/  157] train: loss: 0.0458306
[Epoch 64; Iter    69/  157] train: loss: 0.1570910
[Epoch 64; Iter    99/  157] train: loss: 0.1271365
[Epoch 64; Iter   129/  157] train: loss: 0.0398649
[Epoch 64] ogbg-moltox21: 0.732158 val loss: 0.367819
[Epoch 64] ogbg-moltox21: 0.708914 test loss: 0.360955
[Epoch 65; Iter     2/  157] train: loss: 0.0886853
[Epoch 65; Iter    32/  157] train: loss: 0.0730304
[Epoch 65; Iter    62/  157] train: loss: 0.0756212
[Epoch 65; Iter    92/  157] train: loss: 0.1054042
[Epoch 65; Iter   122/  157] train: loss: 0.0688945
[Epoch 65; Iter   152/  157] train: loss: 0.1048929
[Epoch 65] ogbg-moltox21: 0.734484 val loss: 0.396310
[Epoch 65] ogbg-moltox21: 0.719816 test loss: 0.353932
[Epoch 66; Iter    25/  157] train: loss: 0.0902179
[Epoch 66; Iter    55/  157] train: loss: 0.0701047
[Epoch 66; Iter    85/  157] train: loss: 0.0830847
[Epoch 66; Iter   115/  157] train: loss: 0.0416559
[Epoch 66; Iter   145/  157] train: loss: 0.0690857
[Epoch 66] ogbg-moltox21: 0.740894 val loss: 0.518628
[Epoch 66] ogbg-moltox21: 0.724294 test loss: 0.367369
[Epoch 67; Iter    18/  157] train: loss: 0.0561591
[Epoch 67; Iter    48/  157] train: loss: 0.0744551
[Epoch 67; Iter    78/  157] train: loss: 0.1258451
[Epoch 67; Iter   108/  157] train: loss: 0.0861432
[Epoch 67; Iter   138/  157] train: loss: 0.1070682
[Epoch 67] ogbg-moltox21: 0.739574 val loss: 0.358192
[Epoch 67] ogbg-moltox21: 0.724475 test loss: 0.349882
[Epoch 68; Iter    11/  157] train: loss: 0.0928412
[Epoch 68; Iter    41/  157] train: loss: 0.0630246
[Epoch 68; Iter    71/  157] train: loss: 0.0940825
[Epoch 68; Iter   101/  157] train: loss: 0.0890176
[Epoch 68; Iter   131/  157] train: loss: 0.0720899
[Epoch 68] ogbg-moltox21: 0.739513 val loss: 0.551219
[Epoch 68] ogbg-moltox21: 0.725551 test loss: 0.365020
[Epoch 69; Iter     4/  157] train: loss: 0.0371966
[Epoch 69; Iter    34/  157] train: loss: 0.0794951
[Epoch 69; Iter    64/  157] train: loss: 0.0666610
[Epoch 69; Iter    94/  157] train: loss: 0.1083616
[Epoch 69; Iter   124/  157] train: loss: 0.0780934
[Epoch 69; Iter   154/  157] train: loss: 0.0721447
[Epoch 69] ogbg-moltox21: 0.739528 val loss: 0.367867
[Epoch 69] ogbg-moltox21: 0.722752 test loss: 0.360764
[Epoch 70; Iter    27/  157] train: loss: 0.0663736
[Epoch 70; Iter    57/  157] train: loss: 0.0531035
[Epoch 70; Iter    87/  157] train: loss: 0.0735305
[Epoch 70; Iter   117/  157] train: loss: 0.0807359
[Epoch 70; Iter   147/  157] train: loss: 0.0689841
[Epoch 70] ogbg-moltox21: 0.731847 val loss: 0.603917
[Epoch 70] ogbg-moltox21: 0.717767 test loss: 0.384645
[Epoch 71; Iter    20/  157] train: loss: 0.1052274
[Epoch 71; Iter    50/  157] train: loss: 0.0682254
[Epoch 71; Iter    80/  157] train: loss: 0.0436356
[Epoch 71; Iter   110/  157] train: loss: 0.0887920
[Epoch 71; Iter   140/  157] train: loss: 0.0448197
[Epoch 71] ogbg-moltox21: 0.740060 val loss: 0.476044
[Epoch 71] ogbg-moltox21: 0.721217 test loss: 0.382957
[Epoch 72; Iter    13/  157] train: loss: 0.0818651
[Epoch 72; Iter    43/  157] train: loss: 0.0665804
[Epoch 72; Iter    73/  157] train: loss: 0.0629050
[Epoch 72; Iter   103/  157] train: loss: 0.0934630
[Epoch 72; Iter   133/  157] train: loss: 0.1334141
[Epoch 72] ogbg-moltox21: 0.741567 val loss: 0.379553
[Epoch 72] ogbg-moltox21: 0.722924 test loss: 0.382234
[Epoch 73; Iter     6/  157] train: loss: 0.0852173
[Epoch 73; Iter    36/  157] train: loss: 0.0607605
[Epoch 73; Iter    66/  157] train: loss: 0.0552803
[Epoch 73; Iter    96/  157] train: loss: 0.0765949
[Epoch 73; Iter   126/  157] train: loss: 0.0591744
[Epoch 73; Iter   156/  157] train: loss: 0.0520512
[Epoch 73] ogbg-moltox21: 0.733986 val loss: 0.568284
[Epoch 73] ogbg-moltox21: 0.722984 test loss: 0.383662
[Epoch 74; Iter    29/  157] train: loss: 0.0400523
[Epoch 74; Iter    59/  157] train: loss: 0.0610358
[Epoch 74; Iter    89/  157] train: loss: 0.0361749
[Epoch 74; Iter   119/  157] train: loss: 0.0604023
[Epoch 74; Iter   149/  157] train: loss: 0.0589109
[Epoch 74] ogbg-moltox21: 0.730461 val loss: 0.683515
[Epoch 74] ogbg-moltox21: 0.716947 test loss: 0.417967
[Epoch 75; Iter    22/  157] train: loss: 0.0272537
[Epoch 75; Iter    52/  157] train: loss: 0.0787938
[Epoch 75; Iter    82/  157] train: loss: 0.0543793
[Epoch 75; Iter   112/  157] train: loss: 0.0704759
[Epoch 75; Iter   142/  157] train: loss: 0.0522629
[Epoch 75] ogbg-moltox21: 0.729683 val loss: 0.479605
[Epoch 75] ogbg-moltox21: 0.718363 test loss: 0.383863
[Epoch 76; Iter    15/  157] train: loss: 0.0388127
[Epoch 76; Iter    45/  157] train: loss: 0.0491691
[Epoch 76; Iter    75/  157] train: loss: 0.0825383
[Epoch 76; Iter   105/  157] train: loss: 0.0750041
[Epoch 76; Iter   135/  157] train: loss: 0.0726162
[Epoch 76] ogbg-moltox21: 0.737441 val loss: 0.593546
[Epoch 76] ogbg-moltox21: 0.717692 test loss: 0.399683
[Epoch 77; Iter     8/  157] train: loss: 0.0540639
[Epoch 77; Iter    38/  157] train: loss: 0.0472404
[Epoch 77; Iter    68/  157] train: loss: 0.0545151
[Epoch 77; Iter    98/  157] train: loss: 0.0445708
[Epoch 77; Iter   128/  157] train: loss: 0.0597936
[Epoch 77] ogbg-moltox21: 0.736419 val loss: 0.527351
[Epoch 77] ogbg-moltox21: 0.718632 test loss: 0.408778
[Epoch 78; Iter     1/  157] train: loss: 0.0582891
[Epoch 78; Iter    31/  157] train: loss: 0.0606046
[Epoch 78; Iter    61/  157] train: loss: 0.0596849
[Epoch 78; Iter    91/  157] train: loss: 0.0574115
[Epoch 78; Iter   121/  157] train: loss: 0.0769126
[Epoch 78; Iter   151/  157] train: loss: 0.0678827
[Epoch 78] ogbg-moltox21: 0.737560 val loss: 0.420432
[Epoch 78] ogbg-moltox21: 0.718868 test loss: 0.391352
[Epoch 79; Iter    24/  157] train: loss: 0.0708899
[Epoch 79; Iter    54/  157] train: loss: 0.0757012
[Epoch 79; Iter    84/  157] train: loss: 0.0578607
[Epoch 79; Iter   114/  157] train: loss: 0.0933556
[Epoch 79; Iter   144/  157] train: loss: 0.0815965
[Epoch 79] ogbg-moltox21: 0.731545 val loss: 0.590139
[Epoch 79] ogbg-moltox21: 0.714930 test loss: 0.424620
[Epoch 80; Iter    17/  157] train: loss: 0.0349764
[Epoch 64] ogbg-moltox21: 0.746399 test loss: 0.323469
[Epoch 65; Iter     4/  209] train: loss: 0.0997154
[Epoch 65; Iter    34/  209] train: loss: 0.1132022
[Epoch 65; Iter    64/  209] train: loss: 0.0993785
[Epoch 65; Iter    94/  209] train: loss: 0.1353499
[Epoch 65; Iter   124/  209] train: loss: 0.1836767
[Epoch 65; Iter   154/  209] train: loss: 0.0568825
[Epoch 65; Iter   184/  209] train: loss: 0.1016164
[Epoch 65] ogbg-moltox21: 0.792473 val loss: 0.287148
[Epoch 65] ogbg-moltox21: 0.754288 test loss: 0.312749
[Epoch 66; Iter     5/  209] train: loss: 0.1174975
[Epoch 66; Iter    35/  209] train: loss: 0.0871820
[Epoch 66; Iter    65/  209] train: loss: 0.0549857
[Epoch 66; Iter    95/  209] train: loss: 0.0676143
[Epoch 66; Iter   125/  209] train: loss: 0.1484127
[Epoch 66; Iter   155/  209] train: loss: 0.1008180
[Epoch 66; Iter   185/  209] train: loss: 0.0842371
[Epoch 66] ogbg-moltox21: 0.783102 val loss: 0.285286
[Epoch 66] ogbg-moltox21: 0.754295 test loss: 0.311179
[Epoch 67; Iter     6/  209] train: loss: 0.0767290
[Epoch 67; Iter    36/  209] train: loss: 0.0691107
[Epoch 67; Iter    66/  209] train: loss: 0.0673464
[Epoch 67; Iter    96/  209] train: loss: 0.0770824
[Epoch 67; Iter   126/  209] train: loss: 0.1243457
[Epoch 67; Iter   156/  209] train: loss: 0.1146289
[Epoch 67; Iter   186/  209] train: loss: 0.1161471
[Epoch 67] ogbg-moltox21: 0.788611 val loss: 0.293205
[Epoch 67] ogbg-moltox21: 0.754288 test loss: 0.317846
[Epoch 68; Iter     7/  209] train: loss: 0.0676781
[Epoch 68; Iter    37/  209] train: loss: 0.0750926
[Epoch 68; Iter    67/  209] train: loss: 0.0917404
[Epoch 68; Iter    97/  209] train: loss: 0.0996570
[Epoch 68; Iter   127/  209] train: loss: 0.1063825
[Epoch 68; Iter   157/  209] train: loss: 0.0872022
[Epoch 68; Iter   187/  209] train: loss: 0.0903237
[Epoch 68] ogbg-moltox21: 0.790795 val loss: 0.302736
[Epoch 68] ogbg-moltox21: 0.760183 test loss: 0.323250
[Epoch 69; Iter     8/  209] train: loss: 0.0775772
[Epoch 69; Iter    38/  209] train: loss: 0.0574333
[Epoch 69; Iter    68/  209] train: loss: 0.0695618
[Epoch 69; Iter    98/  209] train: loss: 0.0902067
[Epoch 69; Iter   128/  209] train: loss: 0.1026157
[Epoch 69; Iter   158/  209] train: loss: 0.1616921
[Epoch 69; Iter   188/  209] train: loss: 0.0778985
[Epoch 69] ogbg-moltox21: 0.784479 val loss: 0.303402
[Epoch 69] ogbg-moltox21: 0.756397 test loss: 0.327082
[Epoch 70; Iter     9/  209] train: loss: 0.0809763
[Epoch 70; Iter    39/  209] train: loss: 0.0869696
[Epoch 70; Iter    69/  209] train: loss: 0.0765678
[Epoch 70; Iter    99/  209] train: loss: 0.0567788
[Epoch 70; Iter   129/  209] train: loss: 0.1161402
[Epoch 70; Iter   159/  209] train: loss: 0.1157206
[Epoch 70; Iter   189/  209] train: loss: 0.0962108
[Epoch 70] ogbg-moltox21: 0.780984 val loss: 0.304945
[Epoch 70] ogbg-moltox21: 0.756637 test loss: 0.325458
[Epoch 71; Iter    10/  209] train: loss: 0.0650197
[Epoch 71; Iter    40/  209] train: loss: 0.0871762
[Epoch 71; Iter    70/  209] train: loss: 0.1066309
[Epoch 71; Iter   100/  209] train: loss: 0.0849112
[Epoch 71; Iter   130/  209] train: loss: 0.1127116
[Epoch 71; Iter   160/  209] train: loss: 0.0790514
[Epoch 71; Iter   190/  209] train: loss: 0.0934868
[Epoch 71] ogbg-moltox21: 0.786328 val loss: 0.302827
[Epoch 71] ogbg-moltox21: 0.753261 test loss: 0.327653
[Epoch 72; Iter    11/  209] train: loss: 0.1287740
[Epoch 72; Iter    41/  209] train: loss: 0.0852048
[Epoch 72; Iter    71/  209] train: loss: 0.1083862
[Epoch 72; Iter   101/  209] train: loss: 0.0585781
[Epoch 72; Iter   131/  209] train: loss: 0.1025632
[Epoch 72; Iter   161/  209] train: loss: 0.0775665
[Epoch 72; Iter   191/  209] train: loss: 0.1011406
[Epoch 72] ogbg-moltox21: 0.779044 val loss: 0.309024
[Epoch 72] ogbg-moltox21: 0.749072 test loss: 0.334926
[Epoch 73; Iter    12/  209] train: loss: 0.0749827
[Epoch 73; Iter    42/  209] train: loss: 0.0667474
[Epoch 73; Iter    72/  209] train: loss: 0.0898505
[Epoch 73; Iter   102/  209] train: loss: 0.0747183
[Epoch 73; Iter   132/  209] train: loss: 0.1031322
[Epoch 73; Iter   162/  209] train: loss: 0.1234500
[Epoch 73; Iter   192/  209] train: loss: 0.1361378
[Epoch 73] ogbg-moltox21: 0.784090 val loss: 0.313816
[Epoch 73] ogbg-moltox21: 0.749500 test loss: 0.338103
[Epoch 74; Iter    13/  209] train: loss: 0.1335998
[Epoch 74; Iter    43/  209] train: loss: 0.0946149
[Epoch 74; Iter    73/  209] train: loss: 0.1045331
[Epoch 74; Iter   103/  209] train: loss: 0.0548866
[Epoch 74; Iter   133/  209] train: loss: 0.1415004
[Epoch 74; Iter   163/  209] train: loss: 0.0945833
[Epoch 74; Iter   193/  209] train: loss: 0.1338191
[Epoch 74] ogbg-moltox21: 0.777901 val loss: 0.319890
[Epoch 74] ogbg-moltox21: 0.748062 test loss: 0.344566
[Epoch 75; Iter    14/  209] train: loss: 0.0571887
[Epoch 75; Iter    44/  209] train: loss: 0.1055290
[Epoch 75; Iter    74/  209] train: loss: 0.0977580
[Epoch 75; Iter   104/  209] train: loss: 0.1078808
[Epoch 75; Iter   134/  209] train: loss: 0.0717943
[Epoch 75; Iter   164/  209] train: loss: 0.1075590
[Epoch 75; Iter   194/  209] train: loss: 0.0537301
[Epoch 75] ogbg-moltox21: 0.778079 val loss: 0.325275
[Epoch 75] ogbg-moltox21: 0.742807 test loss: 0.345941
[Epoch 76; Iter    15/  209] train: loss: 0.0682229
[Epoch 76; Iter    45/  209] train: loss: 0.0725312
[Epoch 76; Iter    75/  209] train: loss: 0.0894898
[Epoch 76; Iter   105/  209] train: loss: 0.0797956
[Epoch 76; Iter   135/  209] train: loss: 0.1255530
[Epoch 76; Iter   165/  209] train: loss: 0.0614755
[Epoch 76; Iter   195/  209] train: loss: 0.0777269
[Epoch 76] ogbg-moltox21: 0.778890 val loss: 0.320053
[Epoch 76] ogbg-moltox21: 0.753676 test loss: 0.349406
[Epoch 77; Iter    16/  209] train: loss: 0.0952116
[Epoch 77; Iter    46/  209] train: loss: 0.0660486
[Epoch 77; Iter    76/  209] train: loss: 0.0561037
[Epoch 77; Iter   106/  209] train: loss: 0.0951093
[Epoch 77; Iter   136/  209] train: loss: 0.1049268
[Epoch 77; Iter   166/  209] train: loss: 0.0949037
[Epoch 77; Iter   196/  209] train: loss: 0.1197780
[Epoch 77] ogbg-moltox21: 0.780680 val loss: 0.314099
[Epoch 77] ogbg-moltox21: 0.748719 test loss: 0.342929
[Epoch 78; Iter    17/  209] train: loss: 0.0479707
[Epoch 78; Iter    47/  209] train: loss: 0.0568461
[Epoch 78; Iter    77/  209] train: loss: 0.0661269
[Epoch 78; Iter   107/  209] train: loss: 0.0590220
[Epoch 78; Iter   137/  209] train: loss: 0.0458856
[Epoch 78; Iter   167/  209] train: loss: 0.0882349
[Epoch 78; Iter   197/  209] train: loss: 0.0773118
[Epoch 78] ogbg-moltox21: 0.784143 val loss: 0.321805
[Epoch 78] ogbg-moltox21: 0.748186 test loss: 0.347566
[Epoch 79; Iter    18/  209] train: loss: 0.0588850
[Epoch 79; Iter    48/  209] train: loss: 0.0741968
[Epoch 79; Iter    78/  209] train: loss: 0.0937565
[Epoch 79; Iter   108/  209] train: loss: 0.0801119
[Epoch 79; Iter   138/  209] train: loss: 0.0594431
[Epoch 79; Iter   168/  209] train: loss: 0.0858400
[Epoch 79; Iter   198/  209] train: loss: 0.0488722
[Epoch 79] ogbg-moltox21: 0.771879 val loss: 0.322312
[Epoch 79] ogbg-moltox21: 0.743665 test loss: 0.354821
[Epoch 80; Iter    19/  209] train: loss: 0.0671048
[Epoch 80; Iter    49/  209] train: loss: 0.0928551
[Epoch 80; Iter    79/  209] train: loss: 0.0476695
[Epoch 80; Iter   109/  209] train: loss: 0.0827222
[Epoch 80; Iter   139/  209] train: loss: 0.0530785
[Epoch 80; Iter   169/  209] train: loss: 0.0802910
[Epoch 80; Iter   199/  209] train: loss: 0.1391534
[Epoch 80] ogbg-moltox21: 0.779522 val loss: 0.333606
[Epoch 80] ogbg-moltox21: 0.750829 test loss: 0.363225
[Epoch 81; Iter    20/  209] train: loss: 0.1028610
[Epoch 81; Iter    50/  209] train: loss: 0.0693557
[Epoch 81; Iter    80/  209] train: loss: 0.0893275
[Epoch 81; Iter   110/  209] train: loss: 0.0938047
[Epoch 81; Iter   140/  209] train: loss: 0.1488461
[Epoch 81; Iter   170/  209] train: loss: 0.1012971
[Epoch 81; Iter   200/  209] train: loss: 0.0604008
[Epoch 81] ogbg-moltox21: 0.785379 val loss: 0.334051
[Epoch 81] ogbg-moltox21: 0.744596 test loss: 0.368324
[Epoch 82; Iter    21/  209] train: loss: 0.0664215
[Epoch 64] ogbg-moltox21: 0.757825 test loss: 0.285396
[Epoch 65; Iter     4/  209] train: loss: 0.0840775
[Epoch 65; Iter    34/  209] train: loss: 0.0589088
[Epoch 65; Iter    64/  209] train: loss: 0.1051222
[Epoch 65; Iter    94/  209] train: loss: 0.1095036
[Epoch 65; Iter   124/  209] train: loss: 0.1077058
[Epoch 65; Iter   154/  209] train: loss: 0.1243718
[Epoch 65; Iter   184/  209] train: loss: 0.1358284
[Epoch 65] ogbg-moltox21: 0.794812 val loss: 0.274181
[Epoch 65] ogbg-moltox21: 0.761799 test loss: 0.289289
[Epoch 66; Iter     5/  209] train: loss: 0.0874579
[Epoch 66; Iter    35/  209] train: loss: 0.0657366
[Epoch 66; Iter    65/  209] train: loss: 0.0924138
[Epoch 66; Iter    95/  209] train: loss: 0.0879692
[Epoch 66; Iter   125/  209] train: loss: 0.0898246
[Epoch 66; Iter   155/  209] train: loss: 0.0874360
[Epoch 66; Iter   185/  209] train: loss: 0.0570118
[Epoch 66] ogbg-moltox21: 0.797451 val loss: 0.285176
[Epoch 66] ogbg-moltox21: 0.759634 test loss: 0.298506
[Epoch 67; Iter     6/  209] train: loss: 0.1194090
[Epoch 67; Iter    36/  209] train: loss: 0.1241570
[Epoch 67; Iter    66/  209] train: loss: 0.1119860
[Epoch 67; Iter    96/  209] train: loss: 0.0773443
[Epoch 67; Iter   126/  209] train: loss: 0.0563201
[Epoch 67; Iter   156/  209] train: loss: 0.0777467
[Epoch 67; Iter   186/  209] train: loss: 0.0905894
[Epoch 67] ogbg-moltox21: 0.782806 val loss: 0.291121
[Epoch 67] ogbg-moltox21: 0.752952 test loss: 0.301359
[Epoch 68; Iter     7/  209] train: loss: 0.1052166
[Epoch 68; Iter    37/  209] train: loss: 0.1092834
[Epoch 68; Iter    67/  209] train: loss: 0.1141135
[Epoch 68; Iter    97/  209] train: loss: 0.0790499
[Epoch 68; Iter   127/  209] train: loss: 0.1006432
[Epoch 68; Iter   157/  209] train: loss: 0.0690693
[Epoch 68; Iter   187/  209] train: loss: 0.0608569
[Epoch 68] ogbg-moltox21: 0.788805 val loss: 0.285026
[Epoch 68] ogbg-moltox21: 0.762005 test loss: 0.297789
[Epoch 69; Iter     8/  209] train: loss: 0.1011483
[Epoch 69; Iter    38/  209] train: loss: 0.0685707
[Epoch 69; Iter    68/  209] train: loss: 0.1045329
[Epoch 69; Iter    98/  209] train: loss: 0.0614107
[Epoch 69; Iter   128/  209] train: loss: 0.0745731
[Epoch 69; Iter   158/  209] train: loss: 0.0841849
[Epoch 69; Iter   188/  209] train: loss: 0.0843571
[Epoch 69] ogbg-moltox21: 0.796858 val loss: 0.282105
[Epoch 69] ogbg-moltox21: 0.758745 test loss: 0.299705
[Epoch 70; Iter     9/  209] train: loss: 0.1100840
[Epoch 70; Iter    39/  209] train: loss: 0.0579002
[Epoch 70; Iter    69/  209] train: loss: 0.1429666
[Epoch 70; Iter    99/  209] train: loss: 0.1029134
[Epoch 70; Iter   129/  209] train: loss: 0.0941054
[Epoch 70; Iter   159/  209] train: loss: 0.1121222
[Epoch 70; Iter   189/  209] train: loss: 0.0947382
[Epoch 70] ogbg-moltox21: 0.784352 val loss: 0.290633
[Epoch 70] ogbg-moltox21: 0.756629 test loss: 0.304777
[Epoch 71; Iter    10/  209] train: loss: 0.0962383
[Epoch 71; Iter    40/  209] train: loss: 0.1070649
[Epoch 71; Iter    70/  209] train: loss: 0.1108689
[Epoch 71; Iter   100/  209] train: loss: 0.1030807
[Epoch 71; Iter   130/  209] train: loss: 0.0670896
[Epoch 71; Iter   160/  209] train: loss: 0.0789992
[Epoch 71; Iter   190/  209] train: loss: 0.1037902
[Epoch 71] ogbg-moltox21: 0.778685 val loss: 0.298084
[Epoch 71] ogbg-moltox21: 0.754349 test loss: 0.308463
[Epoch 72; Iter    11/  209] train: loss: 0.1026693
[Epoch 72; Iter    41/  209] train: loss: 0.1167380
[Epoch 72; Iter    71/  209] train: loss: 0.1352474
[Epoch 72; Iter   101/  209] train: loss: 0.0741142
[Epoch 72; Iter   131/  209] train: loss: 0.1210393
[Epoch 72; Iter   161/  209] train: loss: 0.1247765
[Epoch 72; Iter   191/  209] train: loss: 0.0730821
[Epoch 72] ogbg-moltox21: 0.785080 val loss: 0.295449
[Epoch 72] ogbg-moltox21: 0.752211 test loss: 0.308552
[Epoch 73; Iter    12/  209] train: loss: 0.0944663
[Epoch 73; Iter    42/  209] train: loss: 0.0749312
[Epoch 73; Iter    72/  209] train: loss: 0.0741624
[Epoch 73; Iter   102/  209] train: loss: 0.0897731
[Epoch 73; Iter   132/  209] train: loss: 0.1118567
[Epoch 73; Iter   162/  209] train: loss: 0.0444035
[Epoch 73; Iter   192/  209] train: loss: 0.1009211
[Epoch 73] ogbg-moltox21: 0.785776 val loss: 0.305805
[Epoch 73] ogbg-moltox21: 0.756119 test loss: 0.321126
[Epoch 74; Iter    13/  209] train: loss: 0.0896161
[Epoch 74; Iter    43/  209] train: loss: 0.1107091
[Epoch 74; Iter    73/  209] train: loss: 0.0864902
[Epoch 74; Iter   103/  209] train: loss: 0.0809481
[Epoch 74; Iter   133/  209] train: loss: 0.0770059
[Epoch 74; Iter   163/  209] train: loss: 0.0606410
[Epoch 74; Iter   193/  209] train: loss: 0.0948112
[Epoch 74] ogbg-moltox21: 0.782826 val loss: 0.301474
[Epoch 74] ogbg-moltox21: 0.754247 test loss: 0.312116
[Epoch 75; Iter    14/  209] train: loss: 0.0562010
[Epoch 75; Iter    44/  209] train: loss: 0.1276693
[Epoch 75; Iter    74/  209] train: loss: 0.0881927
[Epoch 75; Iter   104/  209] train: loss: 0.0999934
[Epoch 75; Iter   134/  209] train: loss: 0.0638464
[Epoch 75; Iter   164/  209] train: loss: 0.0784110
[Epoch 75; Iter   194/  209] train: loss: 0.0844556
[Epoch 75] ogbg-moltox21: 0.779880 val loss: 0.307675
[Epoch 75] ogbg-moltox21: 0.756938 test loss: 0.322285
[Epoch 76; Iter    15/  209] train: loss: 0.1303268
[Epoch 76; Iter    45/  209] train: loss: 0.0546288
[Epoch 76; Iter    75/  209] train: loss: 0.0732944
[Epoch 76; Iter   105/  209] train: loss: 0.0683055
[Epoch 76; Iter   135/  209] train: loss: 0.0721842
[Epoch 76; Iter   165/  209] train: loss: 0.0703562
[Epoch 76; Iter   195/  209] train: loss: 0.0849935
[Epoch 76] ogbg-moltox21: 0.776240 val loss: 0.309318
[Epoch 76] ogbg-moltox21: 0.749077 test loss: 0.326972
[Epoch 77; Iter    16/  209] train: loss: 0.1068430
[Epoch 77; Iter    46/  209] train: loss: 0.1023484
[Epoch 77; Iter    76/  209] train: loss: 0.0682937
[Epoch 77; Iter   106/  209] train: loss: 0.0670656
[Epoch 77; Iter   136/  209] train: loss: 0.1250524
[Epoch 77; Iter   166/  209] train: loss: 0.0927442
[Epoch 77; Iter   196/  209] train: loss: 0.0956762
[Epoch 77] ogbg-moltox21: 0.775231 val loss: 0.315858
[Epoch 77] ogbg-moltox21: 0.749892 test loss: 0.327115
[Epoch 78; Iter    17/  209] train: loss: 0.0512324
[Epoch 78; Iter    47/  209] train: loss: 0.0815684
[Epoch 78; Iter    77/  209] train: loss: 0.0785332
[Epoch 78; Iter   107/  209] train: loss: 0.1149389
[Epoch 78; Iter   137/  209] train: loss: 0.0948211
[Epoch 78; Iter   167/  209] train: loss: 0.1569668
[Epoch 78; Iter   197/  209] train: loss: 0.0678259
[Epoch 78] ogbg-moltox21: 0.786033 val loss: 0.312839
[Epoch 78] ogbg-moltox21: 0.748389 test loss: 0.331743
[Epoch 79; Iter    18/  209] train: loss: 0.1561453
[Epoch 79; Iter    48/  209] train: loss: 0.0816758
[Epoch 79; Iter    78/  209] train: loss: 0.0447278
[Epoch 79; Iter   108/  209] train: loss: 0.0701105
[Epoch 79; Iter   138/  209] train: loss: 0.0774279
[Epoch 79; Iter   168/  209] train: loss: 0.0917956
[Epoch 79; Iter   198/  209] train: loss: 0.0683121
[Epoch 79] ogbg-moltox21: 0.782678 val loss: 0.318255
[Epoch 79] ogbg-moltox21: 0.747738 test loss: 0.334562
[Epoch 80; Iter    19/  209] train: loss: 0.1500098
[Epoch 80; Iter    49/  209] train: loss: 0.0862720
[Epoch 80; Iter    79/  209] train: loss: 0.0377129
[Epoch 80; Iter   109/  209] train: loss: 0.0603257
[Epoch 80; Iter   139/  209] train: loss: 0.0573037
[Epoch 80; Iter   169/  209] train: loss: 0.1277293
[Epoch 80; Iter   199/  209] train: loss: 0.0826935
[Epoch 80] ogbg-moltox21: 0.777915 val loss: 0.311926
[Epoch 80] ogbg-moltox21: 0.744722 test loss: 0.326556
[Epoch 81; Iter    20/  209] train: loss: 0.0800008
[Epoch 81; Iter    50/  209] train: loss: 0.0589289
[Epoch 81; Iter    80/  209] train: loss: 0.1098764
[Epoch 81; Iter   110/  209] train: loss: 0.0701606
[Epoch 81; Iter   140/  209] train: loss: 0.0955315
[Epoch 81; Iter   170/  209] train: loss: 0.0687575
[Epoch 81; Iter   200/  209] train: loss: 0.0859965
[Epoch 81] ogbg-moltox21: 0.779723 val loss: 0.323146
[Epoch 81] ogbg-moltox21: 0.745527 test loss: 0.331584
[Epoch 82; Iter    21/  209] train: loss: 0.0613019
[Epoch 64] ogbg-moltox21: 0.772163 test loss: 0.298392
[Epoch 65; Iter     4/  209] train: loss: 0.0811621
[Epoch 65; Iter    34/  209] train: loss: 0.1150599
[Epoch 65; Iter    64/  209] train: loss: 0.0925080
[Epoch 65; Iter    94/  209] train: loss: 0.0717239
[Epoch 65; Iter   124/  209] train: loss: 0.0827449
[Epoch 65; Iter   154/  209] train: loss: 0.0815150
[Epoch 65; Iter   184/  209] train: loss: 0.1074177
[Epoch 65] ogbg-moltox21: 0.788779 val loss: 0.294938
[Epoch 65] ogbg-moltox21: 0.774823 test loss: 0.301889
[Epoch 66; Iter     5/  209] train: loss: 0.0648482
[Epoch 66; Iter    35/  209] train: loss: 0.1053273
[Epoch 66; Iter    65/  209] train: loss: 0.0846441
[Epoch 66; Iter    95/  209] train: loss: 0.1005673
[Epoch 66; Iter   125/  209] train: loss: 0.0904093
[Epoch 66; Iter   155/  209] train: loss: 0.1049762
[Epoch 66; Iter   185/  209] train: loss: 0.0888275
[Epoch 66] ogbg-moltox21: 0.782372 val loss: 0.311347
[Epoch 66] ogbg-moltox21: 0.764461 test loss: 0.319119
[Epoch 67; Iter     6/  209] train: loss: 0.0636739
[Epoch 67; Iter    36/  209] train: loss: 0.0596301
[Epoch 67; Iter    66/  209] train: loss: 0.0943289
[Epoch 67; Iter    96/  209] train: loss: 0.0910291
[Epoch 67; Iter   126/  209] train: loss: 0.0713055
[Epoch 67; Iter   156/  209] train: loss: 0.0667171
[Epoch 67; Iter   186/  209] train: loss: 0.1008963
[Epoch 67] ogbg-moltox21: 0.781841 val loss: 0.295038
[Epoch 67] ogbg-moltox21: 0.765225 test loss: 0.300710
[Epoch 68; Iter     7/  209] train: loss: 0.0492189
[Epoch 68; Iter    37/  209] train: loss: 0.0648641
[Epoch 68; Iter    67/  209] train: loss: 0.1533103
[Epoch 68; Iter    97/  209] train: loss: 0.0800820
[Epoch 68; Iter   127/  209] train: loss: 0.0725459
[Epoch 68; Iter   157/  209] train: loss: 0.0914698
[Epoch 68; Iter   187/  209] train: loss: 0.0991542
[Epoch 68] ogbg-moltox21: 0.780700 val loss: 0.296471
[Epoch 68] ogbg-moltox21: 0.768601 test loss: 0.309338
[Epoch 69; Iter     8/  209] train: loss: 0.0990219
[Epoch 69; Iter    38/  209] train: loss: 0.0787109
[Epoch 69; Iter    68/  209] train: loss: 0.0613195
[Epoch 69; Iter    98/  209] train: loss: 0.0854767
[Epoch 69; Iter   128/  209] train: loss: 0.1164204
[Epoch 69; Iter   158/  209] train: loss: 0.0855528
[Epoch 69; Iter   188/  209] train: loss: 0.1180691
[Epoch 69] ogbg-moltox21: 0.776939 val loss: 0.304117
[Epoch 69] ogbg-moltox21: 0.767529 test loss: 0.309697
[Epoch 70; Iter     9/  209] train: loss: 0.1074903
[Epoch 70; Iter    39/  209] train: loss: 0.1236578
[Epoch 70; Iter    69/  209] train: loss: 0.1080669
[Epoch 70; Iter    99/  209] train: loss: 0.1328303
[Epoch 70; Iter   129/  209] train: loss: 0.0861978
[Epoch 70; Iter   159/  209] train: loss: 0.0795206
[Epoch 70; Iter   189/  209] train: loss: 0.0884275
[Epoch 70] ogbg-moltox21: 0.772663 val loss: 0.312869
[Epoch 70] ogbg-moltox21: 0.756808 test loss: 0.317951
[Epoch 71; Iter    10/  209] train: loss: 0.0888337
[Epoch 71; Iter    40/  209] train: loss: 0.0937945
[Epoch 71; Iter    70/  209] train: loss: 0.0662974
[Epoch 71; Iter   100/  209] train: loss: 0.1342110
[Epoch 71; Iter   130/  209] train: loss: 0.0968272
[Epoch 71; Iter   160/  209] train: loss: 0.0674646
[Epoch 71; Iter   190/  209] train: loss: 0.1115573
[Epoch 71] ogbg-moltox21: 0.780256 val loss: 0.305270
[Epoch 71] ogbg-moltox21: 0.769133 test loss: 0.310960
[Epoch 72; Iter    11/  209] train: loss: 0.0966053
[Epoch 72; Iter    41/  209] train: loss: 0.0631169
[Epoch 72; Iter    71/  209] train: loss: 0.0635919
[Epoch 72; Iter   101/  209] train: loss: 0.0875588
[Epoch 72; Iter   131/  209] train: loss: 0.0807547
[Epoch 72; Iter   161/  209] train: loss: 0.1239404
[Epoch 72; Iter   191/  209] train: loss: 0.1256282
[Epoch 72] ogbg-moltox21: 0.782070 val loss: 0.311283
[Epoch 72] ogbg-moltox21: 0.768669 test loss: 0.322917
[Epoch 73; Iter    12/  209] train: loss: 0.0653535
[Epoch 73; Iter    42/  209] train: loss: 0.0875355
[Epoch 73; Iter    72/  209] train: loss: 0.0856852
[Epoch 73; Iter   102/  209] train: loss: 0.0664119
[Epoch 73; Iter   132/  209] train: loss: 0.0987883
[Epoch 73; Iter   162/  209] train: loss: 0.0716350
[Epoch 73; Iter   192/  209] train: loss: 0.0686661
[Epoch 73] ogbg-moltox21: 0.782474 val loss: 0.314070
[Epoch 73] ogbg-moltox21: 0.767795 test loss: 0.323235
[Epoch 74; Iter    13/  209] train: loss: 0.0651105
[Epoch 74; Iter    43/  209] train: loss: 0.0909328
[Epoch 74; Iter    73/  209] train: loss: 0.1481095
[Epoch 74; Iter   103/  209] train: loss: 0.0831550
[Epoch 74; Iter   133/  209] train: loss: 0.0721669
[Epoch 74; Iter   163/  209] train: loss: 0.1410436
[Epoch 74; Iter   193/  209] train: loss: 0.1156828
[Epoch 74] ogbg-moltox21: 0.776115 val loss: 0.319749
[Epoch 74] ogbg-moltox21: 0.761247 test loss: 0.325645
[Epoch 75; Iter    14/  209] train: loss: 0.0686630
[Epoch 75; Iter    44/  209] train: loss: 0.0491833
[Epoch 75; Iter    74/  209] train: loss: 0.0777270
[Epoch 75; Iter   104/  209] train: loss: 0.1262566
[Epoch 75; Iter   134/  209] train: loss: 0.0978206
[Epoch 75; Iter   164/  209] train: loss: 0.0677631
[Epoch 75; Iter   194/  209] train: loss: 0.0999787
[Epoch 75] ogbg-moltox21: 0.777337 val loss: 0.324757
[Epoch 75] ogbg-moltox21: 0.766743 test loss: 0.327121
[Epoch 76; Iter    15/  209] train: loss: 0.0896992
[Epoch 76; Iter    45/  209] train: loss: 0.0903970
[Epoch 76; Iter    75/  209] train: loss: 0.0926845
[Epoch 76; Iter   105/  209] train: loss: 0.1290367
[Epoch 76; Iter   135/  209] train: loss: 0.0879259
[Epoch 76; Iter   165/  209] train: loss: 0.0973170
[Epoch 76; Iter   195/  209] train: loss: 0.0488307
[Epoch 76] ogbg-moltox21: 0.780516 val loss: 0.331467
[Epoch 76] ogbg-moltox21: 0.773702 test loss: 0.325907
[Epoch 77; Iter    16/  209] train: loss: 0.0384178
[Epoch 77; Iter    46/  209] train: loss: 0.0679878
[Epoch 77; Iter    76/  209] train: loss: 0.0640521
[Epoch 77; Iter   106/  209] train: loss: 0.0963613
[Epoch 77; Iter   136/  209] train: loss: 0.0920012
[Epoch 77; Iter   166/  209] train: loss: 0.1193934
[Epoch 77; Iter   196/  209] train: loss: 0.0493553
[Epoch 77] ogbg-moltox21: 0.776379 val loss: 0.325245
[Epoch 77] ogbg-moltox21: 0.768507 test loss: 0.328341
[Epoch 78; Iter    17/  209] train: loss: 0.1426908
[Epoch 78; Iter    47/  209] train: loss: 0.0700928
[Epoch 78; Iter    77/  209] train: loss: 0.1744438
[Epoch 78; Iter   107/  209] train: loss: 0.1202051
[Epoch 78; Iter   137/  209] train: loss: 0.0671909
[Epoch 78; Iter   167/  209] train: loss: 0.0865481
[Epoch 78; Iter   197/  209] train: loss: 0.0709208
[Epoch 78] ogbg-moltox21: 0.770653 val loss: 0.317771
[Epoch 78] ogbg-moltox21: 0.772989 test loss: 0.318480
[Epoch 79; Iter    18/  209] train: loss: 0.0816251
[Epoch 79; Iter    48/  209] train: loss: 0.1031811
[Epoch 79; Iter    78/  209] train: loss: 0.1381235
[Epoch 79; Iter   108/  209] train: loss: 0.0773794
[Epoch 79; Iter   138/  209] train: loss: 0.0745377
[Epoch 79; Iter   168/  209] train: loss: 0.0854273
[Epoch 79; Iter   198/  209] train: loss: 0.0402447
[Epoch 79] ogbg-moltox21: 0.776150 val loss: 0.324918
[Epoch 79] ogbg-moltox21: 0.767777 test loss: 0.326454
[Epoch 80; Iter    19/  209] train: loss: 0.0768287
[Epoch 80; Iter    49/  209] train: loss: 0.0621777
[Epoch 80; Iter    79/  209] train: loss: 0.1604195
[Epoch 80; Iter   109/  209] train: loss: 0.0692630
[Epoch 80; Iter   139/  209] train: loss: 0.0699807
[Epoch 80; Iter   169/  209] train: loss: 0.0468337
[Epoch 80; Iter   199/  209] train: loss: 0.0806893
[Epoch 80] ogbg-moltox21: 0.773117 val loss: 0.328717
[Epoch 80] ogbg-moltox21: 0.764947 test loss: 0.323554
[Epoch 81; Iter    20/  209] train: loss: 0.0556744
[Epoch 81; Iter    50/  209] train: loss: 0.0853332
[Epoch 81; Iter    80/  209] train: loss: 0.0691710
[Epoch 81; Iter   110/  209] train: loss: 0.0867031
[Epoch 81; Iter   140/  209] train: loss: 0.0465706
[Epoch 81; Iter   170/  209] train: loss: 0.0717552
[Epoch 81; Iter   200/  209] train: loss: 0.0689805
[Epoch 81] ogbg-moltox21: 0.764952 val loss: 0.689778
[Epoch 81] ogbg-moltox21: 0.762327 test loss: 0.466765
[Epoch 82; Iter    21/  209] train: loss: 0.0682491
[Epoch 71; Iter   180/  183] train: loss: 0.1142744
[Epoch 71] ogbg-moltox21: 0.740585 val loss: 0.370509
[Epoch 71] ogbg-moltox21: 0.719863 test loss: 0.391124
[Epoch 72; Iter    27/  183] train: loss: 0.0372454
[Epoch 72; Iter    57/  183] train: loss: 0.1180182
[Epoch 72; Iter    87/  183] train: loss: 0.0861029
[Epoch 72; Iter   117/  183] train: loss: 0.0893137
[Epoch 72; Iter   147/  183] train: loss: 0.0989946
[Epoch 72; Iter   177/  183] train: loss: 0.0917986
[Epoch 72] ogbg-moltox21: 0.734323 val loss: 0.354291
[Epoch 72] ogbg-moltox21: 0.716373 test loss: 0.382947
[Epoch 73; Iter    24/  183] train: loss: 0.0684830
[Epoch 73; Iter    54/  183] train: loss: 0.0717205
[Epoch 73; Iter    84/  183] train: loss: 0.0862616
[Epoch 73; Iter   114/  183] train: loss: 0.0671398
[Epoch 73; Iter   144/  183] train: loss: 0.0550056
[Epoch 73; Iter   174/  183] train: loss: 0.0806976
[Epoch 73] ogbg-moltox21: 0.743549 val loss: 0.346779
[Epoch 73] ogbg-moltox21: 0.715759 test loss: 0.380399
[Epoch 74; Iter    21/  183] train: loss: 0.0865425
[Epoch 74; Iter    51/  183] train: loss: 0.0820378
[Epoch 74; Iter    81/  183] train: loss: 0.0740881
[Epoch 74; Iter   111/  183] train: loss: 0.0578526
[Epoch 74; Iter   141/  183] train: loss: 0.0745971
[Epoch 74; Iter   171/  183] train: loss: 0.0895097
[Epoch 74] ogbg-moltox21: 0.741749 val loss: 0.354221
[Epoch 74] ogbg-moltox21: 0.715501 test loss: 0.384598
[Epoch 75; Iter    18/  183] train: loss: 0.0820869
[Epoch 75; Iter    48/  183] train: loss: 0.0448215
[Epoch 75; Iter    78/  183] train: loss: 0.0326692
[Epoch 75; Iter   108/  183] train: loss: 0.0792197
[Epoch 75; Iter   138/  183] train: loss: 0.0895376
[Epoch 75; Iter   168/  183] train: loss: 0.0760269
[Epoch 75] ogbg-moltox21: 0.736040 val loss: 0.360991
[Epoch 75] ogbg-moltox21: 0.713183 test loss: 0.394632
[Epoch 76; Iter    15/  183] train: loss: 0.1703310
[Epoch 76; Iter    45/  183] train: loss: 0.0726317
[Epoch 76; Iter    75/  183] train: loss: 0.0962761
[Epoch 76; Iter   105/  183] train: loss: 0.0922743
[Epoch 76; Iter   135/  183] train: loss: 0.0418345
[Epoch 76; Iter   165/  183] train: loss: 0.0980952
[Epoch 76] ogbg-moltox21: 0.745507 val loss: 0.388626
[Epoch 76] ogbg-moltox21: 0.720344 test loss: 0.415909
[Epoch 77; Iter    12/  183] train: loss: 0.0775258
[Epoch 77; Iter    42/  183] train: loss: 0.0584129
[Epoch 77; Iter    72/  183] train: loss: 0.0533613
[Epoch 77; Iter   102/  183] train: loss: 0.0596293
[Epoch 77; Iter   132/  183] train: loss: 0.1175032
[Epoch 77; Iter   162/  183] train: loss: 0.0836755
[Epoch 77] ogbg-moltox21: 0.737644 val loss: 0.382215
[Epoch 77] ogbg-moltox21: 0.717673 test loss: 0.415222
[Epoch 78; Iter     9/  183] train: loss: 0.0650997
[Epoch 78; Iter    39/  183] train: loss: 0.1019004
[Epoch 78; Iter    69/  183] train: loss: 0.0274327
[Epoch 78; Iter    99/  183] train: loss: 0.0790090
[Epoch 78; Iter   129/  183] train: loss: 0.0587565
[Epoch 78; Iter   159/  183] train: loss: 0.0415428
[Epoch 78] ogbg-moltox21: 0.732291 val loss: 0.382036
[Epoch 78] ogbg-moltox21: 0.708818 test loss: 0.390772
[Epoch 79; Iter     6/  183] train: loss: 0.0586591
[Epoch 79; Iter    36/  183] train: loss: 0.0747280
[Epoch 79; Iter    66/  183] train: loss: 0.1167120
[Epoch 79; Iter    96/  183] train: loss: 0.0644989
[Epoch 79; Iter   126/  183] train: loss: 0.0755064
[Epoch 79; Iter   156/  183] train: loss: 0.0742793
[Epoch 79] ogbg-moltox21: 0.724354 val loss: 0.375940
[Epoch 79] ogbg-moltox21: 0.703061 test loss: 0.408408
[Epoch 80; Iter     3/  183] train: loss: 0.0447918
[Epoch 80; Iter    33/  183] train: loss: 0.0834222
[Epoch 80; Iter    63/  183] train: loss: 0.0697068
[Epoch 80; Iter    93/  183] train: loss: 0.0700940
[Epoch 80; Iter   123/  183] train: loss: 0.0720568
[Epoch 80; Iter   153/  183] train: loss: 0.1065456
[Epoch 80; Iter   183/  183] train: loss: 0.0516678
[Epoch 80] ogbg-moltox21: 0.735901 val loss: 0.382373
[Epoch 80] ogbg-moltox21: 0.708301 test loss: 0.419430
[Epoch 81; Iter    30/  183] train: loss: 0.0795951
[Epoch 81; Iter    60/  183] train: loss: 0.0427387
[Epoch 81; Iter    90/  183] train: loss: 0.1091396
[Epoch 81; Iter   120/  183] train: loss: 0.0654422
[Epoch 81; Iter   150/  183] train: loss: 0.0626869
[Epoch 81; Iter   180/  183] train: loss: 0.0902177
[Epoch 81] ogbg-moltox21: 0.735180 val loss: 0.392871
[Epoch 81] ogbg-moltox21: 0.708032 test loss: 0.426505
[Epoch 82; Iter    27/  183] train: loss: 0.1508859
[Epoch 82; Iter    57/  183] train: loss: 0.0316780
[Epoch 82; Iter    87/  183] train: loss: 0.0492669
[Epoch 82; Iter   117/  183] train: loss: 0.0942937
[Epoch 82; Iter   147/  183] train: loss: 0.0617770
[Epoch 82; Iter   177/  183] train: loss: 0.0371662
[Epoch 82] ogbg-moltox21: 0.732417 val loss: 0.386691
[Epoch 82] ogbg-moltox21: 0.713919 test loss: 0.414091
[Epoch 83; Iter    24/  183] train: loss: 0.0365431
[Epoch 83; Iter    54/  183] train: loss: 0.0584932
[Epoch 83; Iter    84/  183] train: loss: 0.0560460
[Epoch 83; Iter   114/  183] train: loss: 0.0735673
[Epoch 83; Iter   144/  183] train: loss: 0.0541518
[Epoch 83; Iter   174/  183] train: loss: 0.0647225
[Epoch 83] ogbg-moltox21: 0.736426 val loss: 0.402244
[Epoch 83] ogbg-moltox21: 0.712504 test loss: 0.422915
[Epoch 84; Iter    21/  183] train: loss: 0.0812340
[Epoch 84; Iter    51/  183] train: loss: 0.0819389
[Epoch 84; Iter    81/  183] train: loss: 0.0307896
[Epoch 84; Iter   111/  183] train: loss: 0.0850229
[Epoch 84; Iter   141/  183] train: loss: 0.0604046
[Epoch 84; Iter   171/  183] train: loss: 0.1042337
[Epoch 84] ogbg-moltox21: 0.735464 val loss: 0.377553
[Epoch 84] ogbg-moltox21: 0.709457 test loss: 0.415814
[Epoch 85; Iter    18/  183] train: loss: 0.0459309
[Epoch 85; Iter    48/  183] train: loss: 0.0391961
[Epoch 85; Iter    78/  183] train: loss: 0.0782710
[Epoch 85; Iter   108/  183] train: loss: 0.0495473
[Epoch 85; Iter   138/  183] train: loss: 0.1049918
[Epoch 85; Iter   168/  183] train: loss: 0.0593713
[Epoch 85] ogbg-moltox21: 0.736630 val loss: 0.371996
[Epoch 85] ogbg-moltox21: 0.715365 test loss: 0.407534
[Epoch 86; Iter    15/  183] train: loss: 0.0639901
[Epoch 86; Iter    45/  183] train: loss: 0.0734882
[Epoch 86; Iter    75/  183] train: loss: 0.0552398
[Epoch 86; Iter   105/  183] train: loss: 0.0465549
[Epoch 86; Iter   135/  183] train: loss: 0.0344265
[Epoch 86; Iter   165/  183] train: loss: 0.0425109
[Epoch 86] ogbg-moltox21: 0.738966 val loss: 0.391149
[Epoch 86] ogbg-moltox21: 0.714636 test loss: 0.430343
[Epoch 87; Iter    12/  183] train: loss: 0.0888313
[Epoch 87; Iter    42/  183] train: loss: 0.0792692
[Epoch 87; Iter    72/  183] train: loss: 0.0632912
[Epoch 87; Iter   102/  183] train: loss: 0.0822555
[Epoch 87; Iter   132/  183] train: loss: 0.0575369
[Epoch 87; Iter   162/  183] train: loss: 0.0461845
[Epoch 87] ogbg-moltox21: 0.736928 val loss: 0.399718
[Epoch 87] ogbg-moltox21: 0.712972 test loss: 0.440709
[Epoch 88; Iter     9/  183] train: loss: 0.0769874
[Epoch 88; Iter    39/  183] train: loss: 0.0830036
[Epoch 88; Iter    69/  183] train: loss: 0.0597054
[Epoch 88; Iter    99/  183] train: loss: 0.0405549
[Epoch 88; Iter   129/  183] train: loss: 0.0429076
[Epoch 88; Iter   159/  183] train: loss: 0.0384295
[Epoch 88] ogbg-moltox21: 0.735228 val loss: 0.399064
[Epoch 88] ogbg-moltox21: 0.713634 test loss: 0.439181
[Epoch 89; Iter     6/  183] train: loss: 0.0901233
[Epoch 89; Iter    36/  183] train: loss: 0.0605844
[Epoch 89; Iter    66/  183] train: loss: 0.0533554
[Epoch 89; Iter    96/  183] train: loss: 0.0427396
[Epoch 89; Iter   126/  183] train: loss: 0.0331811
[Epoch 89; Iter   156/  183] train: loss: 0.0621694
[Epoch 89] ogbg-moltox21: 0.737111 val loss: 0.417209
[Epoch 89] ogbg-moltox21: 0.709655 test loss: 0.452509
[Epoch 90; Iter     3/  183] train: loss: 0.0413866
[Epoch 90; Iter    33/  183] train: loss: 0.0513900
[Epoch 90; Iter    63/  183] train: loss: 0.0472199
[Epoch 90; Iter    93/  183] train: loss: 0.0609788
[Epoch 90; Iter   123/  183] train: loss: 0.0535496
[Epoch 90; Iter   153/  183] train: loss: 0.0919727
[Epoch 90; Iter   183/  183] train: loss: 0.1253172
[Epoch 71; Iter   180/  183] train: loss: 0.1315546
[Epoch 71] ogbg-moltox21: 0.755019 val loss: 0.329764
[Epoch 71] ogbg-moltox21: 0.732253 test loss: 0.383658
[Epoch 72; Iter    27/  183] train: loss: 0.1093294
[Epoch 72; Iter    57/  183] train: loss: 0.0730351
[Epoch 72; Iter    87/  183] train: loss: 0.0732322
[Epoch 72; Iter   117/  183] train: loss: 0.1402864
[Epoch 72; Iter   147/  183] train: loss: 0.0989483
[Epoch 72; Iter   177/  183] train: loss: 0.0727522
[Epoch 72] ogbg-moltox21: 0.750513 val loss: 0.328026
[Epoch 72] ogbg-moltox21: 0.732178 test loss: 0.365647
[Epoch 73; Iter    24/  183] train: loss: 0.1082049
[Epoch 73; Iter    54/  183] train: loss: 0.1061676
[Epoch 73; Iter    84/  183] train: loss: 0.0662205
[Epoch 73; Iter   114/  183] train: loss: 0.0983520
[Epoch 73; Iter   144/  183] train: loss: 0.0621108
[Epoch 73; Iter   174/  183] train: loss: 0.1084840
[Epoch 73] ogbg-moltox21: 0.753600 val loss: 0.325781
[Epoch 73] ogbg-moltox21: 0.727249 test loss: 0.361214
[Epoch 74; Iter    21/  183] train: loss: 0.0705004
[Epoch 74; Iter    51/  183] train: loss: 0.0700259
[Epoch 74; Iter    81/  183] train: loss: 0.0589491
[Epoch 74; Iter   111/  183] train: loss: 0.1638146
[Epoch 74; Iter   141/  183] train: loss: 0.0516331
[Epoch 74; Iter   171/  183] train: loss: 0.0972216
[Epoch 74] ogbg-moltox21: 0.750221 val loss: 0.323181
[Epoch 74] ogbg-moltox21: 0.721493 test loss: 0.367628
[Epoch 75; Iter    18/  183] train: loss: 0.0507185
[Epoch 75; Iter    48/  183] train: loss: 0.0789849
[Epoch 75; Iter    78/  183] train: loss: 0.0772115
[Epoch 75; Iter   108/  183] train: loss: 0.0813974
[Epoch 75; Iter   138/  183] train: loss: 0.0827071
[Epoch 75; Iter   168/  183] train: loss: 0.1357806
[Epoch 75] ogbg-moltox21: 0.749846 val loss: 0.331892
[Epoch 75] ogbg-moltox21: 0.723241 test loss: 0.361360
[Epoch 76; Iter    15/  183] train: loss: 0.0445749
[Epoch 76; Iter    45/  183] train: loss: 0.0953938
[Epoch 76; Iter    75/  183] train: loss: 0.0735934
[Epoch 76; Iter   105/  183] train: loss: 0.0724426
[Epoch 76; Iter   135/  183] train: loss: 0.0518069
[Epoch 76; Iter   165/  183] train: loss: 0.0688744
[Epoch 76] ogbg-moltox21: 0.746270 val loss: 0.333056
[Epoch 76] ogbg-moltox21: 0.716256 test loss: 0.360331
[Epoch 77; Iter    12/  183] train: loss: 0.0956253
[Epoch 77; Iter    42/  183] train: loss: 0.0964977
[Epoch 77; Iter    72/  183] train: loss: 0.0647650
[Epoch 77; Iter   102/  183] train: loss: 0.0900843
[Epoch 77; Iter   132/  183] train: loss: 0.1466301
[Epoch 77; Iter   162/  183] train: loss: 0.0521701
[Epoch 77] ogbg-moltox21: 0.748737 val loss: 0.335111
[Epoch 77] ogbg-moltox21: 0.727365 test loss: 0.354044
[Epoch 78; Iter     9/  183] train: loss: 0.0482690
[Epoch 78; Iter    39/  183] train: loss: 0.0583775
[Epoch 78; Iter    69/  183] train: loss: 0.0895121
[Epoch 78; Iter    99/  183] train: loss: 0.0496690
[Epoch 78; Iter   129/  183] train: loss: 0.0813073
[Epoch 78; Iter   159/  183] train: loss: 0.0638579
[Epoch 78] ogbg-moltox21: 0.744258 val loss: 0.342164
[Epoch 78] ogbg-moltox21: 0.722432 test loss: 0.427545
[Epoch 79; Iter     6/  183] train: loss: 0.0521986
[Epoch 79; Iter    36/  183] train: loss: 0.1066173
[Epoch 79; Iter    66/  183] train: loss: 0.0715937
[Epoch 79; Iter    96/  183] train: loss: 0.0898644
[Epoch 79; Iter   126/  183] train: loss: 0.0696610
[Epoch 79; Iter   156/  183] train: loss: 0.0630655
[Epoch 79] ogbg-moltox21: 0.753033 val loss: 0.337825
[Epoch 79] ogbg-moltox21: 0.731378 test loss: 0.364669
[Epoch 80; Iter     3/  183] train: loss: 0.0358902
[Epoch 80; Iter    33/  183] train: loss: 0.0639200
[Epoch 80; Iter    63/  183] train: loss: 0.0397912
[Epoch 80; Iter    93/  183] train: loss: 0.0530163
[Epoch 80; Iter   123/  183] train: loss: 0.0539583
[Epoch 80; Iter   153/  183] train: loss: 0.0783747
[Epoch 80; Iter   183/  183] train: loss: 0.0519963
[Epoch 80] ogbg-moltox21: 0.747446 val loss: 0.341433
[Epoch 80] ogbg-moltox21: 0.722965 test loss: 0.373932
[Epoch 81; Iter    30/  183] train: loss: 0.0644086
[Epoch 81; Iter    60/  183] train: loss: 0.0597460
[Epoch 81; Iter    90/  183] train: loss: 0.0848745
[Epoch 81; Iter   120/  183] train: loss: 0.0704860
[Epoch 81; Iter   150/  183] train: loss: 0.0555867
[Epoch 81; Iter   180/  183] train: loss: 0.1218476
[Epoch 81] ogbg-moltox21: 0.743133 val loss: 0.342962
[Epoch 81] ogbg-moltox21: 0.722830 test loss: 0.373060
[Epoch 82; Iter    27/  183] train: loss: 0.0507995
[Epoch 82; Iter    57/  183] train: loss: 0.0580080
[Epoch 82; Iter    87/  183] train: loss: 0.1039151
[Epoch 82; Iter   117/  183] train: loss: 0.0756001
[Epoch 82; Iter   147/  183] train: loss: 0.0458055
[Epoch 82; Iter   177/  183] train: loss: 0.0517473
[Epoch 82] ogbg-moltox21: 0.746478 val loss: 0.346007
[Epoch 82] ogbg-moltox21: 0.723220 test loss: 0.405833
[Epoch 83; Iter    24/  183] train: loss: 0.0754171
[Epoch 83; Iter    54/  183] train: loss: 0.0444462
[Epoch 83; Iter    84/  183] train: loss: 0.0896308
[Epoch 83; Iter   114/  183] train: loss: 0.1261794
[Epoch 83; Iter   144/  183] train: loss: 0.0604791
[Epoch 83; Iter   174/  183] train: loss: 0.0698521
[Epoch 83] ogbg-moltox21: 0.744065 val loss: 0.355161
[Epoch 83] ogbg-moltox21: 0.723744 test loss: 0.378249
[Epoch 84; Iter    21/  183] train: loss: 0.0585479
[Epoch 84; Iter    51/  183] train: loss: 0.0586755
[Epoch 84; Iter    81/  183] train: loss: 0.1050124
[Epoch 84; Iter   111/  183] train: loss: 0.0540540
[Epoch 84; Iter   141/  183] train: loss: 0.1157772
[Epoch 84; Iter   171/  183] train: loss: 0.1155006
[Epoch 84] ogbg-moltox21: 0.743341 val loss: 0.357522
[Epoch 84] ogbg-moltox21: 0.718406 test loss: 0.382360
[Epoch 85; Iter    18/  183] train: loss: 0.0586998
[Epoch 85; Iter    48/  183] train: loss: 0.0727978
[Epoch 85; Iter    78/  183] train: loss: 0.0671225
[Epoch 85; Iter   108/  183] train: loss: 0.0940649
[Epoch 85; Iter   138/  183] train: loss: 0.0669870
[Epoch 85; Iter   168/  183] train: loss: 0.0818288
[Epoch 85] ogbg-moltox21: 0.740998 val loss: 0.360156
[Epoch 85] ogbg-moltox21: 0.721899 test loss: 0.397913
[Epoch 86; Iter    15/  183] train: loss: 0.0555283
[Epoch 86; Iter    45/  183] train: loss: 0.0982735
[Epoch 86; Iter    75/  183] train: loss: 0.0642579
[Epoch 86; Iter   105/  183] train: loss: 0.1077641
[Epoch 86; Iter   135/  183] train: loss: 0.0443874
[Epoch 86; Iter   165/  183] train: loss: 0.0637510
[Epoch 86] ogbg-moltox21: 0.745765 val loss: 0.366862
[Epoch 86] ogbg-moltox21: 0.725091 test loss: 0.389103
[Epoch 87; Iter    12/  183] train: loss: 0.0473856
[Epoch 87; Iter    42/  183] train: loss: 0.0439114
[Epoch 87; Iter    72/  183] train: loss: 0.0880934
[Epoch 87; Iter   102/  183] train: loss: 0.0378033
[Epoch 87; Iter   132/  183] train: loss: 0.0602939
[Epoch 87; Iter   162/  183] train: loss: 0.0890521
[Epoch 87] ogbg-moltox21: 0.740239 val loss: 0.352114
[Epoch 87] ogbg-moltox21: 0.716319 test loss: 0.378632
[Epoch 88; Iter     9/  183] train: loss: 0.0746634
[Epoch 88; Iter    39/  183] train: loss: 0.0663006
[Epoch 88; Iter    69/  183] train: loss: 0.0755904
[Epoch 88; Iter    99/  183] train: loss: 0.0547296
[Epoch 88; Iter   129/  183] train: loss: 0.0962096
[Epoch 88; Iter   159/  183] train: loss: 0.0557004
[Epoch 88] ogbg-moltox21: 0.746190 val loss: 0.366783
[Epoch 88] ogbg-moltox21: 0.722407 test loss: 0.393699
[Epoch 89; Iter     6/  183] train: loss: 0.0514489
[Epoch 89; Iter    36/  183] train: loss: 0.0451249
[Epoch 89; Iter    66/  183] train: loss: 0.0506246
[Epoch 89; Iter    96/  183] train: loss: 0.0872800
[Epoch 89; Iter   126/  183] train: loss: 0.0864411
[Epoch 89; Iter   156/  183] train: loss: 0.0878254
[Epoch 89] ogbg-moltox21: 0.745202 val loss: 0.365890
[Epoch 89] ogbg-moltox21: 0.724329 test loss: 0.391037
[Epoch 90; Iter     3/  183] train: loss: 0.0686218
[Epoch 90; Iter    33/  183] train: loss: 0.0735220
[Epoch 90; Iter    63/  183] train: loss: 0.1117778
[Epoch 90; Iter    93/  183] train: loss: 0.0680596
[Epoch 90; Iter   123/  183] train: loss: 0.0700974
[Epoch 90; Iter   153/  183] train: loss: 0.0748451
[Epoch 90; Iter   183/  183] train: loss: 0.0352146
[Epoch 71; Iter   180/  183] train: loss: 0.0956902
[Epoch 71] ogbg-moltox21: 0.731481 val loss: 0.531590
[Epoch 71] ogbg-moltox21: 0.734292 test loss: 0.710041
[Epoch 72; Iter    27/  183] train: loss: 0.0582255
[Epoch 72; Iter    57/  183] train: loss: 0.0965022
[Epoch 72; Iter    87/  183] train: loss: 0.1389677
[Epoch 72; Iter   117/  183] train: loss: 0.0675587
[Epoch 72; Iter   147/  183] train: loss: 0.0690688
[Epoch 72; Iter   177/  183] train: loss: 0.1302167
[Epoch 72] ogbg-moltox21: 0.738629 val loss: 0.361039
[Epoch 72] ogbg-moltox21: 0.735430 test loss: 0.371988
[Epoch 73; Iter    24/  183] train: loss: 0.0543140
[Epoch 73; Iter    54/  183] train: loss: 0.0884344
[Epoch 73; Iter    84/  183] train: loss: 0.1405937
[Epoch 73; Iter   114/  183] train: loss: 0.0730171
[Epoch 73; Iter   144/  183] train: loss: 0.0734834
[Epoch 73; Iter   174/  183] train: loss: 0.1055257
[Epoch 73] ogbg-moltox21: 0.740227 val loss: 0.415915
[Epoch 73] ogbg-moltox21: 0.732425 test loss: 0.564473
[Epoch 74; Iter    21/  183] train: loss: 0.0356324
[Epoch 74; Iter    51/  183] train: loss: 0.0853300
[Epoch 74; Iter    81/  183] train: loss: 0.0686173
[Epoch 74; Iter   111/  183] train: loss: 0.0721232
[Epoch 74; Iter   141/  183] train: loss: 0.0679634
[Epoch 74; Iter   171/  183] train: loss: 0.1190424
[Epoch 74] ogbg-moltox21: 0.735494 val loss: 0.440340
[Epoch 74] ogbg-moltox21: 0.735001 test loss: 0.583670
[Epoch 75; Iter    18/  183] train: loss: 0.0808758
[Epoch 75; Iter    48/  183] train: loss: 0.0576324
[Epoch 75; Iter    78/  183] train: loss: 0.0631964
[Epoch 75; Iter   108/  183] train: loss: 0.0484011
[Epoch 75; Iter   138/  183] train: loss: 0.0616694
[Epoch 75; Iter   168/  183] train: loss: 0.0706550
[Epoch 75] ogbg-moltox21: 0.734302 val loss: 0.408058
[Epoch 75] ogbg-moltox21: 0.721752 test loss: 0.555248
[Epoch 76; Iter    15/  183] train: loss: 0.0976411
[Epoch 76; Iter    45/  183] train: loss: 0.0782200
[Epoch 76; Iter    75/  183] train: loss: 0.0675655
[Epoch 76; Iter   105/  183] train: loss: 0.0572492
[Epoch 76; Iter   135/  183] train: loss: 0.0715648
[Epoch 76; Iter   165/  183] train: loss: 0.0544735
[Epoch 76] ogbg-moltox21: 0.722700 val loss: 0.515471
[Epoch 76] ogbg-moltox21: 0.724187 test loss: 0.677256
[Epoch 77; Iter    12/  183] train: loss: 0.0618887
[Epoch 77; Iter    42/  183] train: loss: 0.0588469
[Epoch 77; Iter    72/  183] train: loss: 0.0724104
[Epoch 77; Iter   102/  183] train: loss: 0.1000135
[Epoch 77; Iter   132/  183] train: loss: 0.0736400
[Epoch 77; Iter   162/  183] train: loss: 0.0408203
[Epoch 77] ogbg-moltox21: 0.733729 val loss: 0.363841
[Epoch 77] ogbg-moltox21: 0.738947 test loss: 0.367704
[Epoch 78; Iter     9/  183] train: loss: 0.0560288
[Epoch 78; Iter    39/  183] train: loss: 0.0739329
[Epoch 78; Iter    69/  183] train: loss: 0.0746793
[Epoch 78; Iter    99/  183] train: loss: 0.0974930
[Epoch 78; Iter   129/  183] train: loss: 0.0616359
[Epoch 78; Iter   159/  183] train: loss: 0.0635381
[Epoch 78] ogbg-moltox21: 0.726208 val loss: 0.498823
[Epoch 78] ogbg-moltox21: 0.733698 test loss: 0.651845
[Epoch 79; Iter     6/  183] train: loss: 0.0993078
[Epoch 79; Iter    36/  183] train: loss: 0.0860171
[Epoch 79; Iter    66/  183] train: loss: 0.0811197
[Epoch 79; Iter    96/  183] train: loss: 0.0584040
[Epoch 79; Iter   126/  183] train: loss: 0.0898874
[Epoch 79; Iter   156/  183] train: loss: 0.0572901
[Epoch 79] ogbg-moltox21: 0.725743 val loss: 0.479127
[Epoch 79] ogbg-moltox21: 0.728521 test loss: 0.624254
[Epoch 80; Iter     3/  183] train: loss: 0.0952385
[Epoch 80; Iter    33/  183] train: loss: 0.0607824
[Epoch 80; Iter    63/  183] train: loss: 0.0630135
[Epoch 80; Iter    93/  183] train: loss: 0.0723771
[Epoch 80; Iter   123/  183] train: loss: 0.0867729
[Epoch 80; Iter   153/  183] train: loss: 0.0607200
[Epoch 80; Iter   183/  183] train: loss: 0.0653767
[Epoch 80] ogbg-moltox21: 0.718816 val loss: 0.411669
[Epoch 80] ogbg-moltox21: 0.727436 test loss: 0.534724
[Epoch 81; Iter    30/  183] train: loss: 0.0471717
[Epoch 81; Iter    60/  183] train: loss: 0.1148564
[Epoch 81; Iter    90/  183] train: loss: 0.1362022
[Epoch 81; Iter   120/  183] train: loss: 0.0358329
[Epoch 81; Iter   150/  183] train: loss: 0.0547095
[Epoch 81; Iter   180/  183] train: loss: 0.0884412
[Epoch 81] ogbg-moltox21: 0.733944 val loss: 0.429848
[Epoch 81] ogbg-moltox21: 0.732532 test loss: 0.566084
[Epoch 82; Iter    27/  183] train: loss: 0.0718029
[Epoch 82; Iter    57/  183] train: loss: 0.1098643
[Epoch 82; Iter    87/  183] train: loss: 0.0726136
[Epoch 82; Iter   117/  183] train: loss: 0.0706326
[Epoch 82; Iter   147/  183] train: loss: 0.0521522
[Epoch 82; Iter   177/  183] train: loss: 0.1164665
[Epoch 82] ogbg-moltox21: 0.728314 val loss: 0.766012
[Epoch 82] ogbg-moltox21: 0.727309 test loss: 1.176484
[Epoch 83; Iter    24/  183] train: loss: 0.0573027
[Epoch 83; Iter    54/  183] train: loss: 0.1657186
[Epoch 83; Iter    84/  183] train: loss: 0.0622575
[Epoch 83; Iter   114/  183] train: loss: 0.0340177
[Epoch 83; Iter   144/  183] train: loss: 0.0638151
[Epoch 83; Iter   174/  183] train: loss: 0.0523830
[Epoch 83] ogbg-moltox21: 0.720724 val loss: 0.862977
[Epoch 83] ogbg-moltox21: 0.728994 test loss: 1.373585
[Epoch 84; Iter    21/  183] train: loss: 0.0821870
[Epoch 84; Iter    51/  183] train: loss: 0.1096588
[Epoch 84; Iter    81/  183] train: loss: 0.0921752
[Epoch 84; Iter   111/  183] train: loss: 0.0414239
[Epoch 84; Iter   141/  183] train: loss: 0.0900584
[Epoch 84; Iter   171/  183] train: loss: 0.0537913
[Epoch 84] ogbg-moltox21: 0.738318 val loss: 0.581411
[Epoch 84] ogbg-moltox21: 0.733743 test loss: 0.803589
[Epoch 85; Iter    18/  183] train: loss: 0.0522864
[Epoch 85; Iter    48/  183] train: loss: 0.0632403
[Epoch 85; Iter    78/  183] train: loss: 0.1450028
[Epoch 85; Iter   108/  183] train: loss: 0.0612687
[Epoch 85; Iter   138/  183] train: loss: 0.0529962
[Epoch 85; Iter   168/  183] train: loss: 0.0736423
[Epoch 85] ogbg-moltox21: 0.733885 val loss: 0.405939
[Epoch 85] ogbg-moltox21: 0.728843 test loss: 0.523166
[Epoch 86; Iter    15/  183] train: loss: 0.0665562
[Epoch 86; Iter    45/  183] train: loss: 0.0917505
[Epoch 86; Iter    75/  183] train: loss: 0.0531293
[Epoch 86; Iter   105/  183] train: loss: 0.0523896
[Epoch 86; Iter   135/  183] train: loss: 0.0787224
[Epoch 86; Iter   165/  183] train: loss: 0.0639382
[Epoch 86] ogbg-moltox21: 0.730011 val loss: 0.608950
[Epoch 86] ogbg-moltox21: 0.724835 test loss: 0.859433
[Epoch 87; Iter    12/  183] train: loss: 0.0627533
[Epoch 87; Iter    42/  183] train: loss: 0.0499180
[Epoch 87; Iter    72/  183] train: loss: 0.0389117
[Epoch 87; Iter   102/  183] train: loss: 0.0522625
[Epoch 87; Iter   132/  183] train: loss: 0.0670532
[Epoch 87; Iter   162/  183] train: loss: 0.0890062
[Epoch 87] ogbg-moltox21: 0.721858 val loss: 0.476692
[Epoch 87] ogbg-moltox21: 0.721041 test loss: 0.631161
[Epoch 88; Iter     9/  183] train: loss: 0.0374943
[Epoch 88; Iter    39/  183] train: loss: 0.0749025
[Epoch 88; Iter    69/  183] train: loss: 0.1078773
[Epoch 88; Iter    99/  183] train: loss: 0.0592732
[Epoch 88; Iter   129/  183] train: loss: 0.0718097
[Epoch 88; Iter   159/  183] train: loss: 0.0599641
[Epoch 88] ogbg-moltox21: 0.723682 val loss: 0.491963
[Epoch 88] ogbg-moltox21: 0.719419 test loss: 0.641023
[Epoch 89; Iter     6/  183] train: loss: 0.0876605
[Epoch 89; Iter    36/  183] train: loss: 0.0572762
[Epoch 89; Iter    66/  183] train: loss: 0.0363400
[Epoch 89; Iter    96/  183] train: loss: 0.0290679
[Epoch 89; Iter   126/  183] train: loss: 0.1022171
[Epoch 89; Iter   156/  183] train: loss: 0.0928061
[Epoch 89] ogbg-moltox21: 0.719006 val loss: 0.538646
[Epoch 89] ogbg-moltox21: 0.719308 test loss: 0.719933
[Epoch 90; Iter     3/  183] train: loss: 0.0595740
[Epoch 90; Iter    33/  183] train: loss: 0.0535614
[Epoch 90; Iter    63/  183] train: loss: 0.0591694
[Epoch 90; Iter    93/  183] train: loss: 0.0696592
[Epoch 90; Iter   123/  183] train: loss: 0.0210465
[Epoch 90; Iter   153/  183] train: loss: 0.1484657
[Epoch 90; Iter   183/  183] train: loss: 0.1075424
[Epoch 80; Iter    47/  157] train: loss: 0.0566205
[Epoch 80; Iter    77/  157] train: loss: 0.0592352
[Epoch 80; Iter   107/  157] train: loss: 0.0734363
[Epoch 80; Iter   137/  157] train: loss: 0.0539238
[Epoch 80] ogbg-moltox21: 0.732578 val loss: 0.396628
[Epoch 80] ogbg-moltox21: 0.723368 test loss: 0.404730
[Epoch 81; Iter    10/  157] train: loss: 0.0693108
[Epoch 81; Iter    40/  157] train: loss: 0.0650390
[Epoch 81; Iter    70/  157] train: loss: 0.0715808
[Epoch 81; Iter   100/  157] train: loss: 0.0579856
[Epoch 81; Iter   130/  157] train: loss: 0.0945320
[Epoch 81] ogbg-moltox21: 0.728182 val loss: 0.393459
[Epoch 81] ogbg-moltox21: 0.727273 test loss: 0.403342
[Epoch 82; Iter     3/  157] train: loss: 0.1083488
[Epoch 82; Iter    33/  157] train: loss: 0.0605032
[Epoch 82; Iter    63/  157] train: loss: 0.1175543
[Epoch 82; Iter    93/  157] train: loss: 0.0850734
[Epoch 82; Iter   123/  157] train: loss: 0.0788484
[Epoch 82; Iter   153/  157] train: loss: 0.0875620
[Epoch 82] ogbg-moltox21: 0.724117 val loss: 0.393777
[Epoch 82] ogbg-moltox21: 0.724565 test loss: 0.398033
[Epoch 83; Iter    26/  157] train: loss: 0.0889380
[Epoch 83; Iter    56/  157] train: loss: 0.1448470
[Epoch 83; Iter    86/  157] train: loss: 0.0381865
[Epoch 83; Iter   116/  157] train: loss: 0.0719702
[Epoch 83; Iter   146/  157] train: loss: 0.0482350
[Epoch 83] ogbg-moltox21: 0.736703 val loss: 0.399701
[Epoch 83] ogbg-moltox21: 0.727453 test loss: 0.411142
[Epoch 84; Iter    19/  157] train: loss: 0.0452501
[Epoch 84; Iter    49/  157] train: loss: 0.0691667
[Epoch 84; Iter    79/  157] train: loss: 0.0962435
[Epoch 84; Iter   109/  157] train: loss: 0.0710872
[Epoch 84; Iter   139/  157] train: loss: 0.0622306
[Epoch 84] ogbg-moltox21: 0.733331 val loss: 0.403490
[Epoch 84] ogbg-moltox21: 0.728366 test loss: 0.404389
[Epoch 85; Iter    12/  157] train: loss: 0.0580716
[Epoch 85; Iter    42/  157] train: loss: 0.0421507
[Epoch 85; Iter    72/  157] train: loss: 0.1244739
[Epoch 85; Iter   102/  157] train: loss: 0.0596299
[Epoch 85; Iter   132/  157] train: loss: 0.0689155
[Epoch 85] ogbg-moltox21: 0.721109 val loss: 0.421995
[Epoch 85] ogbg-moltox21: 0.720235 test loss: 0.430031
[Epoch 86; Iter     5/  157] train: loss: 0.0763893
[Epoch 86; Iter    35/  157] train: loss: 0.0711715
[Epoch 86; Iter    65/  157] train: loss: 0.0760241
[Epoch 86; Iter    95/  157] train: loss: 0.0417098
[Epoch 86; Iter   125/  157] train: loss: 0.0485620
[Epoch 86; Iter   155/  157] train: loss: 0.0485457
[Epoch 86] ogbg-moltox21: 0.726198 val loss: 0.402452
[Epoch 86] ogbg-moltox21: 0.726619 test loss: 0.400351
[Epoch 87; Iter    28/  157] train: loss: 0.0564736
[Epoch 87; Iter    58/  157] train: loss: 0.0584154
[Epoch 87; Iter    88/  157] train: loss: 0.0466396
[Epoch 87; Iter   118/  157] train: loss: 0.0796199
[Epoch 87; Iter   148/  157] train: loss: 0.0897502
[Epoch 87] ogbg-moltox21: 0.731227 val loss: 0.408386
[Epoch 87] ogbg-moltox21: 0.721411 test loss: 0.416510
[Epoch 88; Iter    21/  157] train: loss: 0.0643506
[Epoch 88; Iter    51/  157] train: loss: 0.0968449
[Epoch 88; Iter    81/  157] train: loss: 0.0429044
[Epoch 88; Iter   111/  157] train: loss: 0.0790138
[Epoch 88; Iter   141/  157] train: loss: 0.0898262
[Epoch 88] ogbg-moltox21: 0.725487 val loss: 0.433125
[Epoch 88] ogbg-moltox21: 0.716899 test loss: 0.450330
[Epoch 89; Iter    14/  157] train: loss: 0.0454264
[Epoch 89; Iter    44/  157] train: loss: 0.1058864
[Epoch 89; Iter    74/  157] train: loss: 0.1084173
[Epoch 89; Iter   104/  157] train: loss: 0.0598023
[Epoch 89; Iter   134/  157] train: loss: 0.0904610
[Epoch 89] ogbg-moltox21: 0.726651 val loss: 0.421068
[Epoch 89] ogbg-moltox21: 0.722049 test loss: 0.431940
[Epoch 90; Iter     7/  157] train: loss: 0.0520976
[Epoch 90; Iter    37/  157] train: loss: 0.0591762
[Epoch 90; Iter    67/  157] train: loss: 0.0329988
[Epoch 90; Iter    97/  157] train: loss: 0.0659234
[Epoch 90; Iter   127/  157] train: loss: 0.0859748
[Epoch 90; Iter   157/  157] train: loss: 0.0352020
[Epoch 90] ogbg-moltox21: 0.726544 val loss: 0.427016
[Epoch 90] ogbg-moltox21: 0.724847 test loss: 0.433714
[Epoch 91; Iter    30/  157] train: loss: 0.0455094
[Epoch 91; Iter    60/  157] train: loss: 0.0695595
[Epoch 91; Iter    90/  157] train: loss: 0.1319659
[Epoch 91; Iter   120/  157] train: loss: 0.0666594
[Epoch 91; Iter   150/  157] train: loss: 0.1011427
[Epoch 91] ogbg-moltox21: 0.726628 val loss: 0.415344
[Epoch 91] ogbg-moltox21: 0.723723 test loss: 0.422382
[Epoch 92; Iter    23/  157] train: loss: 0.0357577
[Epoch 92; Iter    53/  157] train: loss: 0.0680015
[Epoch 92; Iter    83/  157] train: loss: 0.0719540
[Epoch 92; Iter   113/  157] train: loss: 0.0774223
[Epoch 92; Iter   143/  157] train: loss: 0.0669547
[Epoch 92] ogbg-moltox21: 0.730814 val loss: 0.419764
[Epoch 92] ogbg-moltox21: 0.724736 test loss: 0.429428
[Epoch 93; Iter    16/  157] train: loss: 0.0851587
[Epoch 93; Iter    46/  157] train: loss: 0.0775203
[Epoch 93; Iter    76/  157] train: loss: 0.0613924
[Epoch 93; Iter   106/  157] train: loss: 0.0517719
[Epoch 93; Iter   136/  157] train: loss: 0.0686064
[Epoch 93] ogbg-moltox21: 0.727274 val loss: 0.414721
[Epoch 93] ogbg-moltox21: 0.723818 test loss: 0.418290
[Epoch 94; Iter     9/  157] train: loss: 0.0762964
[Epoch 94; Iter    39/  157] train: loss: 0.0504571
[Epoch 94; Iter    69/  157] train: loss: 0.0433949
[Epoch 94; Iter    99/  157] train: loss: 0.0470852
[Epoch 94; Iter   129/  157] train: loss: 0.0907427
[Epoch 94] ogbg-moltox21: 0.727112 val loss: 0.422927
[Epoch 94] ogbg-moltox21: 0.724206 test loss: 0.429986
[Epoch 95; Iter     2/  157] train: loss: 0.0408046
[Epoch 95; Iter    32/  157] train: loss: 0.0713106
[Epoch 95; Iter    62/  157] train: loss: 0.0774670
[Epoch 95; Iter    92/  157] train: loss: 0.0374729
[Epoch 95; Iter   122/  157] train: loss: 0.0263667
[Epoch 95; Iter   152/  157] train: loss: 0.0456715
[Epoch 95] ogbg-moltox21: 0.727461 val loss: 0.427528
[Epoch 95] ogbg-moltox21: 0.725988 test loss: 0.435765
[Epoch 96; Iter    25/  157] train: loss: 0.0566318
[Epoch 96; Iter    55/  157] train: loss: 0.0463206
[Epoch 96; Iter    85/  157] train: loss: 0.0559594
[Epoch 96; Iter   115/  157] train: loss: 0.0340827
[Epoch 96; Iter   145/  157] train: loss: 0.0595335
[Epoch 96] ogbg-moltox21: 0.726757 val loss: 0.433357
[Epoch 96] ogbg-moltox21: 0.723703 test loss: 0.439418
[Epoch 97; Iter    18/  157] train: loss: 0.0569420
[Epoch 97; Iter    48/  157] train: loss: 0.0370876
[Epoch 97; Iter    78/  157] train: loss: 0.0690213
[Epoch 97; Iter   108/  157] train: loss: 0.0425993
[Epoch 97; Iter   138/  157] train: loss: 0.0576108
[Epoch 97] ogbg-moltox21: 0.723773 val loss: 0.429603
[Epoch 97] ogbg-moltox21: 0.723298 test loss: 0.427478
[Epoch 98; Iter    11/  157] train: loss: 0.0658498
[Epoch 98; Iter    41/  157] train: loss: 0.0981091
[Epoch 98; Iter    71/  157] train: loss: 0.0462564
[Epoch 98; Iter   101/  157] train: loss: 0.0998336
[Epoch 98; Iter   131/  157] train: loss: 0.0325471
[Epoch 98] ogbg-moltox21: 0.729355 val loss: 0.435658
[Epoch 98] ogbg-moltox21: 0.726975 test loss: 0.442366
[Epoch 99; Iter     4/  157] train: loss: 0.0826853
[Epoch 99; Iter    34/  157] train: loss: 0.0475590
[Epoch 99; Iter    64/  157] train: loss: 0.0866668
[Epoch 99; Iter    94/  157] train: loss: 0.0612549
[Epoch 99; Iter   124/  157] train: loss: 0.0506044
[Epoch 99; Iter   154/  157] train: loss: 0.0454410
[Epoch 99] ogbg-moltox21: 0.717086 val loss: 0.448397
[Epoch 99] ogbg-moltox21: 0.716965 test loss: 0.448719
[Epoch 100; Iter    27/  157] train: loss: 0.0637880
[Epoch 100; Iter    57/  157] train: loss: 0.0462859
[Epoch 100; Iter    87/  157] train: loss: 0.0875623
[Epoch 100; Iter   117/  157] train: loss: 0.0428083
[Epoch 100; Iter   147/  157] train: loss: 0.0384263
[Epoch 100] ogbg-moltox21: 0.717293 val loss: 0.443337
[Epoch 100] ogbg-moltox21: 0.713537 test loss: 0.448979
[Epoch 101; Iter    20/  157] train: loss: 0.0649637
[Epoch 101; Iter    50/  157] train: loss: 0.0710531
[Epoch 101; Iter    80/  157] train: loss: 0.0470013
[Epoch 101; Iter   110/  157] train: loss: 0.0381595
[Epoch 80; Iter    47/  157] train: loss: 0.0502625
[Epoch 80; Iter    77/  157] train: loss: 0.0778202
[Epoch 80; Iter   107/  157] train: loss: 0.0666916
[Epoch 80; Iter   137/  157] train: loss: 0.0585971
[Epoch 80] ogbg-moltox21: 0.725333 val loss: 0.397409
[Epoch 80] ogbg-moltox21: 0.710494 test loss: 0.408852
[Epoch 81; Iter    10/  157] train: loss: 0.0470100
[Epoch 81; Iter    40/  157] train: loss: 0.0740629
[Epoch 81; Iter    70/  157] train: loss: 0.0697053
[Epoch 81; Iter   100/  157] train: loss: 0.0904192
[Epoch 81; Iter   130/  157] train: loss: 0.0413566
[Epoch 81] ogbg-moltox21: 0.730883 val loss: 0.409282
[Epoch 81] ogbg-moltox21: 0.723560 test loss: 0.428754
[Epoch 82; Iter     3/  157] train: loss: 0.0430140
[Epoch 82; Iter    33/  157] train: loss: 0.0710025
[Epoch 82; Iter    63/  157] train: loss: 0.1088904
[Epoch 82; Iter    93/  157] train: loss: 0.0799284
[Epoch 82; Iter   123/  157] train: loss: 0.0634603
[Epoch 82; Iter   153/  157] train: loss: 0.0971434
[Epoch 82] ogbg-moltox21: 0.733247 val loss: 0.425008
[Epoch 82] ogbg-moltox21: 0.727131 test loss: 0.415861
[Epoch 83; Iter    26/  157] train: loss: 0.0596862
[Epoch 83; Iter    56/  157] train: loss: 0.0693385
[Epoch 83; Iter    86/  157] train: loss: 0.0748774
[Epoch 83; Iter   116/  157] train: loss: 0.0711351
[Epoch 83; Iter   146/  157] train: loss: 0.0713558
[Epoch 83] ogbg-moltox21: 0.728319 val loss: 0.384657
[Epoch 83] ogbg-moltox21: 0.726855 test loss: 0.384028
[Epoch 84; Iter    19/  157] train: loss: 0.0508921
[Epoch 84; Iter    49/  157] train: loss: 0.0665505
[Epoch 84; Iter    79/  157] train: loss: 0.0909322
[Epoch 84; Iter   109/  157] train: loss: 0.1032112
[Epoch 84; Iter   139/  157] train: loss: 0.0934432
[Epoch 84] ogbg-moltox21: 0.738592 val loss: 0.409199
[Epoch 84] ogbg-moltox21: 0.726158 test loss: 0.430119
[Epoch 85; Iter    12/  157] train: loss: 0.0474509
[Epoch 85; Iter    42/  157] train: loss: 0.0716825
[Epoch 85; Iter    72/  157] train: loss: 0.0661643
[Epoch 85; Iter   102/  157] train: loss: 0.0840670
[Epoch 85; Iter   132/  157] train: loss: 0.0529971
[Epoch 85] ogbg-moltox21: 0.728428 val loss: 0.432050
[Epoch 85] ogbg-moltox21: 0.723022 test loss: 0.433356
[Epoch 86; Iter     5/  157] train: loss: 0.0342188
[Epoch 86; Iter    35/  157] train: loss: 0.0769447
[Epoch 86; Iter    65/  157] train: loss: 0.1223812
[Epoch 86; Iter    95/  157] train: loss: 0.0614025
[Epoch 86; Iter   125/  157] train: loss: 0.0828002
[Epoch 86; Iter   155/  157] train: loss: 0.0980984
[Epoch 86] ogbg-moltox21: 0.725296 val loss: 0.412291
[Epoch 86] ogbg-moltox21: 0.721802 test loss: 0.427435
[Epoch 87; Iter    28/  157] train: loss: 0.0394085
[Epoch 87; Iter    58/  157] train: loss: 0.0778280
[Epoch 87; Iter    88/  157] train: loss: 0.1283686
[Epoch 87; Iter   118/  157] train: loss: 0.0774223
[Epoch 87; Iter   148/  157] train: loss: 0.0382306
[Epoch 87] ogbg-moltox21: 0.723077 val loss: 0.411472
[Epoch 87] ogbg-moltox21: 0.723607 test loss: 0.418226
[Epoch 88; Iter    21/  157] train: loss: 0.0589626
[Epoch 88; Iter    51/  157] train: loss: 0.0917439
[Epoch 88; Iter    81/  157] train: loss: 0.0519347
[Epoch 88; Iter   111/  157] train: loss: 0.0841249
[Epoch 88; Iter   141/  157] train: loss: 0.0399619
[Epoch 88] ogbg-moltox21: 0.724079 val loss: 0.419137
[Epoch 88] ogbg-moltox21: 0.714410 test loss: 0.429342
[Epoch 89; Iter    14/  157] train: loss: 0.0385244
[Epoch 89; Iter    44/  157] train: loss: 0.0694137
[Epoch 89; Iter    74/  157] train: loss: 0.0423621
[Epoch 89; Iter   104/  157] train: loss: 0.0517448
[Epoch 89; Iter   134/  157] train: loss: 0.0576259
[Epoch 89] ogbg-moltox21: 0.728019 val loss: 0.422517
[Epoch 89] ogbg-moltox21: 0.714725 test loss: 0.424745
[Epoch 90; Iter     7/  157] train: loss: 0.0497923
[Epoch 90; Iter    37/  157] train: loss: 0.0524700
[Epoch 90; Iter    67/  157] train: loss: 0.0775447
[Epoch 90; Iter    97/  157] train: loss: 0.0416597
[Epoch 90; Iter   127/  157] train: loss: 0.0636353
[Epoch 90; Iter   157/  157] train: loss: 0.1615963
[Epoch 90] ogbg-moltox21: 0.730190 val loss: 0.559458
[Epoch 90] ogbg-moltox21: 0.715319 test loss: 0.433043
[Epoch 91; Iter    30/  157] train: loss: 0.0624962
[Epoch 91; Iter    60/  157] train: loss: 0.0366129
[Epoch 91; Iter    90/  157] train: loss: 0.0549941
[Epoch 91; Iter   120/  157] train: loss: 0.0595811
[Epoch 91; Iter   150/  157] train: loss: 0.0789977
[Epoch 91] ogbg-moltox21: 0.729253 val loss: 0.434708
[Epoch 91] ogbg-moltox21: 0.720256 test loss: 0.417437
[Epoch 92; Iter    23/  157] train: loss: 0.0340328
[Epoch 92; Iter    53/  157] train: loss: 0.0597117
[Epoch 92; Iter    83/  157] train: loss: 0.0771570
[Epoch 92; Iter   113/  157] train: loss: 0.0523970
[Epoch 92; Iter   143/  157] train: loss: 0.0744315
[Epoch 92] ogbg-moltox21: 0.721425 val loss: 0.434726
[Epoch 92] ogbg-moltox21: 0.717495 test loss: 0.426561
[Epoch 93; Iter    16/  157] train: loss: 0.0645368
[Epoch 93; Iter    46/  157] train: loss: 0.0554000
[Epoch 93; Iter    76/  157] train: loss: 0.0869335
[Epoch 93; Iter   106/  157] train: loss: 0.0759871
[Epoch 93; Iter   136/  157] train: loss: 0.0693859
[Epoch 93] ogbg-moltox21: 0.729168 val loss: 0.415591
[Epoch 93] ogbg-moltox21: 0.719299 test loss: 0.425863
[Epoch 94; Iter     9/  157] train: loss: 0.0492341
[Epoch 94; Iter    39/  157] train: loss: 0.0453082
[Epoch 94; Iter    69/  157] train: loss: 0.0586702
[Epoch 94; Iter    99/  157] train: loss: 0.0493212
[Epoch 94; Iter   129/  157] train: loss: 0.0480533
[Epoch 94] ogbg-moltox21: 0.719638 val loss: 0.423990
[Epoch 94] ogbg-moltox21: 0.716151 test loss: 0.413972
[Epoch 95; Iter     2/  157] train: loss: 0.0579548
[Epoch 95; Iter    32/  157] train: loss: 0.0728522
[Epoch 95; Iter    62/  157] train: loss: 0.0415928
[Epoch 95; Iter    92/  157] train: loss: 0.0709970
[Epoch 95; Iter   122/  157] train: loss: 0.0636858
[Epoch 95; Iter   152/  157] train: loss: 0.0489183
[Epoch 95] ogbg-moltox21: 0.723441 val loss: 0.438335
[Epoch 95] ogbg-moltox21: 0.718939 test loss: 0.441521
[Epoch 96; Iter    25/  157] train: loss: 0.0442215
[Epoch 96; Iter    55/  157] train: loss: 0.0552900
[Epoch 96; Iter    85/  157] train: loss: 0.0376831
[Epoch 96; Iter   115/  157] train: loss: 0.0360997
[Epoch 96; Iter   145/  157] train: loss: 0.0499800
[Epoch 96] ogbg-moltox21: 0.716446 val loss: 0.446165
[Epoch 96] ogbg-moltox21: 0.711474 test loss: 0.448357
[Epoch 97; Iter    18/  157] train: loss: 0.0601208
[Epoch 97; Iter    48/  157] train: loss: 0.0476293
[Epoch 97; Iter    78/  157] train: loss: 0.0380265
[Epoch 97; Iter   108/  157] train: loss: 0.0310138
[Epoch 97; Iter   138/  157] train: loss: 0.1071235
[Epoch 97] ogbg-moltox21: 0.727549 val loss: 0.436341
[Epoch 97] ogbg-moltox21: 0.718389 test loss: 0.445643
[Epoch 98; Iter    11/  157] train: loss: 0.0620574
[Epoch 98; Iter    41/  157] train: loss: 0.0465571
[Epoch 98; Iter    71/  157] train: loss: 0.0507583
[Epoch 98; Iter   101/  157] train: loss: 0.0675839
[Epoch 98; Iter   131/  157] train: loss: 0.0499443
[Epoch 98] ogbg-moltox21: 0.720607 val loss: 0.449777
[Epoch 98] ogbg-moltox21: 0.714330 test loss: 0.467272
[Epoch 99; Iter     4/  157] train: loss: 0.0307132
[Epoch 99; Iter    34/  157] train: loss: 0.0742719
[Epoch 99; Iter    64/  157] train: loss: 0.0492224
[Epoch 99; Iter    94/  157] train: loss: 0.0651050
[Epoch 99; Iter   124/  157] train: loss: 0.0465655
[Epoch 99; Iter   154/  157] train: loss: 0.0852069
[Epoch 99] ogbg-moltox21: 0.719177 val loss: 0.480781
[Epoch 99] ogbg-moltox21: 0.716584 test loss: 0.449012
[Epoch 100; Iter    27/  157] train: loss: 0.0347806
[Epoch 100; Iter    57/  157] train: loss: 0.0857073
[Epoch 100; Iter    87/  157] train: loss: 0.0954786
[Epoch 100; Iter   117/  157] train: loss: 0.0403086
[Epoch 100; Iter   147/  157] train: loss: 0.0861007
[Epoch 100] ogbg-moltox21: 0.720569 val loss: 0.435099
[Epoch 100] ogbg-moltox21: 0.713691 test loss: 0.443958
[Epoch 101; Iter    20/  157] train: loss: 0.0498049
[Epoch 101; Iter    50/  157] train: loss: 0.0428685
[Epoch 101; Iter    80/  157] train: loss: 0.0478877
[Epoch 101; Iter   110/  157] train: loss: 0.0496097
[Epoch 80; Iter    47/  157] train: loss: 0.0703894
[Epoch 80; Iter    77/  157] train: loss: 0.0316706
[Epoch 80; Iter   107/  157] train: loss: 0.0743656
[Epoch 80; Iter   137/  157] train: loss: 0.1654099
[Epoch 80] ogbg-moltox21: 0.735691 val loss: 0.419292
[Epoch 80] ogbg-moltox21: 0.719689 test loss: 0.395258
[Epoch 81; Iter    10/  157] train: loss: 0.0304402
[Epoch 81; Iter    40/  157] train: loss: 0.0377752
[Epoch 81; Iter    70/  157] train: loss: 0.0764586
[Epoch 81; Iter   100/  157] train: loss: 0.0584474
[Epoch 81; Iter   130/  157] train: loss: 0.1122150
[Epoch 81] ogbg-moltox21: 0.732049 val loss: 0.679806
[Epoch 81] ogbg-moltox21: 0.719224 test loss: 0.418496
[Epoch 82; Iter     3/  157] train: loss: 0.0540531
[Epoch 82; Iter    33/  157] train: loss: 0.0339433
[Epoch 82; Iter    63/  157] train: loss: 0.0485905
[Epoch 82; Iter    93/  157] train: loss: 0.0859886
[Epoch 82; Iter   123/  157] train: loss: 0.0658751
[Epoch 82; Iter   153/  157] train: loss: 0.0449789
[Epoch 82] ogbg-moltox21: 0.734778 val loss: 0.402437
[Epoch 82] ogbg-moltox21: 0.718345 test loss: 0.399646
[Epoch 83; Iter    26/  157] train: loss: 0.0966782
[Epoch 83; Iter    56/  157] train: loss: 0.0471183
[Epoch 83; Iter    86/  157] train: loss: 0.0341517
[Epoch 83; Iter   116/  157] train: loss: 0.1055879
[Epoch 83; Iter   146/  157] train: loss: 0.0554227
[Epoch 83] ogbg-moltox21: 0.731474 val loss: 0.491076
[Epoch 83] ogbg-moltox21: 0.716755 test loss: 0.413467
[Epoch 84; Iter    19/  157] train: loss: 0.0663060
[Epoch 84; Iter    49/  157] train: loss: 0.1549241
[Epoch 84; Iter    79/  157] train: loss: 0.0516629
[Epoch 84; Iter   109/  157] train: loss: 0.0465526
[Epoch 84; Iter   139/  157] train: loss: 0.0557837
[Epoch 84] ogbg-moltox21: 0.738838 val loss: 0.394546
[Epoch 84] ogbg-moltox21: 0.716115 test loss: 0.391397
[Epoch 85; Iter    12/  157] train: loss: 0.0557336
[Epoch 85; Iter    42/  157] train: loss: 0.0519999
[Epoch 85; Iter    72/  157] train: loss: 0.0643379
[Epoch 85; Iter   102/  157] train: loss: 0.0761212
[Epoch 85; Iter   132/  157] train: loss: 0.0410113
[Epoch 85] ogbg-moltox21: 0.734856 val loss: 0.503518
[Epoch 85] ogbg-moltox21: 0.719629 test loss: 0.418242
[Epoch 86; Iter     5/  157] train: loss: 0.0567043
[Epoch 86; Iter    35/  157] train: loss: 0.0931791
[Epoch 86; Iter    65/  157] train: loss: 0.0588606
[Epoch 86; Iter    95/  157] train: loss: 0.0626887
[Epoch 86; Iter   125/  157] train: loss: 0.0472972
[Epoch 86; Iter   155/  157] train: loss: 0.0768826
[Epoch 86] ogbg-moltox21: 0.735008 val loss: 0.428770
[Epoch 86] ogbg-moltox21: 0.722130 test loss: 0.429609
[Epoch 87; Iter    28/  157] train: loss: 0.0667867
[Epoch 87; Iter    58/  157] train: loss: 0.0476203
[Epoch 87; Iter    88/  157] train: loss: 0.0747412
[Epoch 87; Iter   118/  157] train: loss: 0.1059835
[Epoch 87; Iter   148/  157] train: loss: 0.0581741
[Epoch 87] ogbg-moltox21: 0.735733 val loss: 0.409349
[Epoch 87] ogbg-moltox21: 0.723004 test loss: 0.410656
[Epoch 88; Iter    21/  157] train: loss: 0.0540860
[Epoch 88; Iter    51/  157] train: loss: 0.0512149
[Epoch 88; Iter    81/  157] train: loss: 0.0750420
[Epoch 88; Iter   111/  157] train: loss: 0.0876767
[Epoch 88; Iter   141/  157] train: loss: 0.0344237
[Epoch 88] ogbg-moltox21: 0.733141 val loss: 0.476283
[Epoch 88] ogbg-moltox21: 0.715512 test loss: 0.434446
[Epoch 89; Iter    14/  157] train: loss: 0.0386336
[Epoch 89; Iter    44/  157] train: loss: 0.0629801
[Epoch 89; Iter    74/  157] train: loss: 0.0645755
[Epoch 89; Iter   104/  157] train: loss: 0.0538868
[Epoch 89; Iter   134/  157] train: loss: 0.0403784
[Epoch 89] ogbg-moltox21: 0.741807 val loss: 0.576592
[Epoch 89] ogbg-moltox21: 0.722271 test loss: 0.425303
[Epoch 90; Iter     7/  157] train: loss: 0.0446777
[Epoch 90; Iter    37/  157] train: loss: 0.0528652
[Epoch 90; Iter    67/  157] train: loss: 0.0718514
[Epoch 90; Iter    97/  157] train: loss: 0.0456331
[Epoch 90; Iter   127/  157] train: loss: 0.0543641
[Epoch 90; Iter   157/  157] train: loss: 0.0758067
[Epoch 90] ogbg-moltox21: 0.732022 val loss: 0.586897
[Epoch 90] ogbg-moltox21: 0.720728 test loss: 0.406838
[Epoch 91; Iter    30/  157] train: loss: 0.0601382
[Epoch 91; Iter    60/  157] train: loss: 0.0463371
[Epoch 91; Iter    90/  157] train: loss: 0.0452478
[Epoch 91; Iter   120/  157] train: loss: 0.0431939
[Epoch 91; Iter   150/  157] train: loss: 0.0637937
[Epoch 91] ogbg-moltox21: 0.733234 val loss: 0.604594
[Epoch 91] ogbg-moltox21: 0.714589 test loss: 0.423007
[Epoch 92; Iter    23/  157] train: loss: 0.0434396
[Epoch 92; Iter    53/  157] train: loss: 0.0431347
[Epoch 92; Iter    83/  157] train: loss: 0.0707865
[Epoch 92; Iter   113/  157] train: loss: 0.0535361
[Epoch 92; Iter   143/  157] train: loss: 0.0373868
[Epoch 92] ogbg-moltox21: 0.731850 val loss: 0.608972
[Epoch 92] ogbg-moltox21: 0.712995 test loss: 0.451797
[Epoch 93; Iter    16/  157] train: loss: 0.0464135
[Epoch 93; Iter    46/  157] train: loss: 0.0572248
[Epoch 93; Iter    76/  157] train: loss: 0.0374530
[Epoch 93; Iter   106/  157] train: loss: 0.0494198
[Epoch 93; Iter   136/  157] train: loss: 0.0455392
[Epoch 93] ogbg-moltox21: 0.730042 val loss: 0.564285
[Epoch 93] ogbg-moltox21: 0.716651 test loss: 0.448415
[Epoch 94; Iter     9/  157] train: loss: 0.0552356
[Epoch 94; Iter    39/  157] train: loss: 0.0243764
[Epoch 94; Iter    69/  157] train: loss: 0.0438749
[Epoch 94; Iter    99/  157] train: loss: 0.0734034
[Epoch 94; Iter   129/  157] train: loss: 0.0433810
[Epoch 94] ogbg-moltox21: 0.729970 val loss: 0.434736
[Epoch 94] ogbg-moltox21: 0.715558 test loss: 0.433595
[Epoch 95; Iter     2/  157] train: loss: 0.0433081
[Epoch 95; Iter    32/  157] train: loss: 0.0475706
[Epoch 95; Iter    62/  157] train: loss: 0.0500237
[Epoch 95; Iter    92/  157] train: loss: 0.0646023
[Epoch 95; Iter   122/  157] train: loss: 0.0577248
[Epoch 95; Iter   152/  157] train: loss: 0.0523759
[Epoch 95] ogbg-moltox21: 0.730527 val loss: 0.618422
[Epoch 95] ogbg-moltox21: 0.715201 test loss: 0.442640
[Epoch 96; Iter    25/  157] train: loss: 0.0447636
[Epoch 96; Iter    55/  157] train: loss: 0.0547147
[Epoch 96; Iter    85/  157] train: loss: 0.0479594
[Epoch 96; Iter   115/  157] train: loss: 0.0488270
[Epoch 96; Iter   145/  157] train: loss: 0.0618632
[Epoch 96] ogbg-moltox21: 0.726875 val loss: 0.586619
[Epoch 96] ogbg-moltox21: 0.714380 test loss: 0.434978
[Epoch 97; Iter    18/  157] train: loss: 0.0586862
[Epoch 97; Iter    48/  157] train: loss: 0.0935227
[Epoch 97; Iter    78/  157] train: loss: 0.0393985
[Epoch 97; Iter   108/  157] train: loss: 0.0399432
[Epoch 97; Iter   138/  157] train: loss: 0.0460545
[Epoch 97] ogbg-moltox21: 0.729312 val loss: 0.479640
[Epoch 97] ogbg-moltox21: 0.718489 test loss: 0.438845
[Epoch 98; Iter    11/  157] train: loss: 0.0534438
[Epoch 98; Iter    41/  157] train: loss: 0.0285394
[Epoch 98; Iter    71/  157] train: loss: 0.0334481
[Epoch 98; Iter   101/  157] train: loss: 0.0251034
[Epoch 98; Iter   131/  157] train: loss: 0.0291459
[Epoch 98] ogbg-moltox21: 0.731202 val loss: 0.432922
[Epoch 98] ogbg-moltox21: 0.717122 test loss: 0.425408
[Epoch 99; Iter     4/  157] train: loss: 0.0236374
[Epoch 99; Iter    34/  157] train: loss: 0.0191092
[Epoch 99; Iter    64/  157] train: loss: 0.0512744
[Epoch 99; Iter    94/  157] train: loss: 0.0247718
[Epoch 99; Iter   124/  157] train: loss: 0.0652307
[Epoch 99; Iter   154/  157] train: loss: 0.0407587
[Epoch 99] ogbg-moltox21: 0.731624 val loss: 0.639796
[Epoch 99] ogbg-moltox21: 0.716325 test loss: 0.443439
[Epoch 100; Iter    27/  157] train: loss: 0.0499873
[Epoch 100; Iter    57/  157] train: loss: 0.0443733
[Epoch 100; Iter    87/  157] train: loss: 0.0678307
[Epoch 100; Iter   117/  157] train: loss: 0.0279138
[Epoch 100; Iter   147/  157] train: loss: 0.0438394
[Epoch 100] ogbg-moltox21: 0.732195 val loss: 0.495401
[Epoch 100] ogbg-moltox21: 0.720676 test loss: 0.438869
[Epoch 101; Iter    20/  157] train: loss: 0.0535071
[Epoch 101; Iter    50/  157] train: loss: 0.0471016
[Epoch 101; Iter    80/  157] train: loss: 0.0553488
[Epoch 101; Iter   110/  157] train: loss: 0.0733759
[Epoch 82; Iter    51/  209] train: loss: 0.0725430
[Epoch 82; Iter    81/  209] train: loss: 0.1001963
[Epoch 82; Iter   111/  209] train: loss: 0.0640790
[Epoch 82; Iter   141/  209] train: loss: 0.0810324
[Epoch 82; Iter   171/  209] train: loss: 0.0459613
[Epoch 82; Iter   201/  209] train: loss: 0.0798600
[Epoch 82] ogbg-moltox21: 0.776220 val loss: 0.338951
[Epoch 82] ogbg-moltox21: 0.749628 test loss: 0.367478
[Epoch 83; Iter    22/  209] train: loss: 0.0973993
[Epoch 83; Iter    52/  209] train: loss: 0.1233302
[Epoch 83; Iter    82/  209] train: loss: 0.0570335
[Epoch 83; Iter   112/  209] train: loss: 0.0839100
[Epoch 83; Iter   142/  209] train: loss: 0.1435740
[Epoch 83; Iter   172/  209] train: loss: 0.0749003
[Epoch 83; Iter   202/  209] train: loss: 0.1121935
[Epoch 83] ogbg-moltox21: 0.781361 val loss: 0.340148
[Epoch 83] ogbg-moltox21: 0.749689 test loss: 0.363355
[Epoch 84; Iter    23/  209] train: loss: 0.0738801
[Epoch 84; Iter    53/  209] train: loss: 0.0684646
[Epoch 84; Iter    83/  209] train: loss: 0.0694140
[Epoch 84; Iter   113/  209] train: loss: 0.0757102
[Epoch 84; Iter   143/  209] train: loss: 0.0747226
[Epoch 84; Iter   173/  209] train: loss: 0.0785628
[Epoch 84; Iter   203/  209] train: loss: 0.0960058
[Epoch 84] ogbg-moltox21: 0.769940 val loss: 0.341672
[Epoch 84] ogbg-moltox21: 0.747655 test loss: 0.369646
[Epoch 85; Iter    24/  209] train: loss: 0.0693527
[Epoch 85; Iter    54/  209] train: loss: 0.1054951
[Epoch 85; Iter    84/  209] train: loss: 0.0577356
[Epoch 85; Iter   114/  209] train: loss: 0.1157345
[Epoch 85; Iter   144/  209] train: loss: 0.1212536
[Epoch 85; Iter   174/  209] train: loss: 0.0508360
[Epoch 85; Iter   204/  209] train: loss: 0.0794405
[Epoch 85] ogbg-moltox21: 0.772469 val loss: 0.342305
[Epoch 85] ogbg-moltox21: 0.744684 test loss: 0.361814
[Epoch 86; Iter    25/  209] train: loss: 0.0513361
[Epoch 86; Iter    55/  209] train: loss: 0.0634019
[Epoch 86; Iter    85/  209] train: loss: 0.0831763
[Epoch 86; Iter   115/  209] train: loss: 0.0877816
[Epoch 86; Iter   145/  209] train: loss: 0.0815408
[Epoch 86; Iter   175/  209] train: loss: 0.0718493
[Epoch 86; Iter   205/  209] train: loss: 0.0680002
[Epoch 86] ogbg-moltox21: 0.771605 val loss: 0.343459
[Epoch 86] ogbg-moltox21: 0.746402 test loss: 0.372777
[Epoch 87; Iter    26/  209] train: loss: 0.0463718
[Epoch 87; Iter    56/  209] train: loss: 0.0710163
[Epoch 87; Iter    86/  209] train: loss: 0.0767013
[Epoch 87; Iter   116/  209] train: loss: 0.0657540
[Epoch 87; Iter   146/  209] train: loss: 0.1248367
[Epoch 87; Iter   176/  209] train: loss: 0.0611162
[Epoch 87; Iter   206/  209] train: loss: 0.0935860
[Epoch 87] ogbg-moltox21: 0.773232 val loss: 0.345482
[Epoch 87] ogbg-moltox21: 0.748620 test loss: 0.372243
[Epoch 88; Iter    27/  209] train: loss: 0.0616939
[Epoch 88; Iter    57/  209] train: loss: 0.0832247
[Epoch 88; Iter    87/  209] train: loss: 0.0772208
[Epoch 88; Iter   117/  209] train: loss: 0.0803495
[Epoch 88; Iter   147/  209] train: loss: 0.0559605
[Epoch 88; Iter   177/  209] train: loss: 0.0794011
[Epoch 88; Iter   207/  209] train: loss: 0.0555957
[Epoch 88] ogbg-moltox21: 0.769948 val loss: 0.352331
[Epoch 88] ogbg-moltox21: 0.736323 test loss: 0.376895
[Epoch 89; Iter    28/  209] train: loss: 0.0422733
[Epoch 89; Iter    58/  209] train: loss: 0.0922243
[Epoch 89; Iter    88/  209] train: loss: 0.0560595
[Epoch 89; Iter   118/  209] train: loss: 0.0616500
[Epoch 89; Iter   148/  209] train: loss: 0.0847750
[Epoch 89; Iter   178/  209] train: loss: 0.0685400
[Epoch 89; Iter   208/  209] train: loss: 0.0726958
[Epoch 89] ogbg-moltox21: 0.770875 val loss: 0.351931
[Epoch 89] ogbg-moltox21: 0.743543 test loss: 0.386681
[Epoch 90; Iter    29/  209] train: loss: 0.0756674
[Epoch 90; Iter    59/  209] train: loss: 0.0668129
[Epoch 90; Iter    89/  209] train: loss: 0.0656482
[Epoch 90; Iter   119/  209] train: loss: 0.1430505
[Epoch 90; Iter   149/  209] train: loss: 0.0913606
[Epoch 90; Iter   179/  209] train: loss: 0.0764447
[Epoch 90; Iter   209/  209] train: loss: 0.0462351
[Epoch 90] ogbg-moltox21: 0.768265 val loss: 0.366032
[Epoch 90] ogbg-moltox21: 0.741995 test loss: 0.395670
[Epoch 91; Iter    30/  209] train: loss: 0.0629349
[Epoch 91; Iter    60/  209] train: loss: 0.0525088
[Epoch 91; Iter    90/  209] train: loss: 0.0765087
[Epoch 91; Iter   120/  209] train: loss: 0.0695508
[Epoch 91; Iter   150/  209] train: loss: 0.1078240
[Epoch 91; Iter   180/  209] train: loss: 0.0546276
[Epoch 91] ogbg-moltox21: 0.771477 val loss: 0.362664
[Epoch 91] ogbg-moltox21: 0.742825 test loss: 0.382549
[Epoch 92; Iter     1/  209] train: loss: 0.0526578
[Epoch 92; Iter    31/  209] train: loss: 0.0541139
[Epoch 92; Iter    61/  209] train: loss: 0.0419573
[Epoch 92; Iter    91/  209] train: loss: 0.0610373
[Epoch 92; Iter   121/  209] train: loss: 0.0493302
[Epoch 92; Iter   151/  209] train: loss: 0.0474447
[Epoch 92; Iter   181/  209] train: loss: 0.0427838
[Epoch 92] ogbg-moltox21: 0.770400 val loss: 0.360758
[Epoch 92] ogbg-moltox21: 0.747257 test loss: 0.388154
[Epoch 93; Iter     2/  209] train: loss: 0.0538744
[Epoch 93; Iter    32/  209] train: loss: 0.0781176
[Epoch 93; Iter    62/  209] train: loss: 0.0490459
[Epoch 93; Iter    92/  209] train: loss: 0.0692576
[Epoch 93; Iter   122/  209] train: loss: 0.0800414
[Epoch 93; Iter   152/  209] train: loss: 0.0685561
[Epoch 93; Iter   182/  209] train: loss: 0.0589779
[Epoch 93] ogbg-moltox21: 0.774056 val loss: 0.364039
[Epoch 93] ogbg-moltox21: 0.743491 test loss: 0.400879
[Epoch 94; Iter     3/  209] train: loss: 0.0563149
[Epoch 94; Iter    33/  209] train: loss: 0.0563041
[Epoch 94; Iter    63/  209] train: loss: 0.0464282
[Epoch 94; Iter    93/  209] train: loss: 0.0561782
[Epoch 94; Iter   123/  209] train: loss: 0.0660813
[Epoch 94; Iter   153/  209] train: loss: 0.0593694
[Epoch 94; Iter   183/  209] train: loss: 0.0473421
[Epoch 94] ogbg-moltox21: 0.774343 val loss: 0.359076
[Epoch 94] ogbg-moltox21: 0.750329 test loss: 0.387163
[Epoch 95; Iter     4/  209] train: loss: 0.0513791
[Epoch 95; Iter    34/  209] train: loss: 0.0511821
[Epoch 95; Iter    64/  209] train: loss: 0.0502498
[Epoch 95; Iter    94/  209] train: loss: 0.0746909
[Epoch 95; Iter   124/  209] train: loss: 0.0470968
[Epoch 95; Iter   154/  209] train: loss: 0.0817909
[Epoch 95; Iter   184/  209] train: loss: 0.0447591
[Epoch 95] ogbg-moltox21: 0.773014 val loss: 0.376653
[Epoch 95] ogbg-moltox21: 0.747772 test loss: 0.395782
[Epoch 96; Iter     5/  209] train: loss: 0.0560915
[Epoch 96; Iter    35/  209] train: loss: 0.0737975
[Epoch 96; Iter    65/  209] train: loss: 0.0966553
[Epoch 96; Iter    95/  209] train: loss: 0.0361057
[Epoch 96; Iter   125/  209] train: loss: 0.0651964
[Epoch 96; Iter   155/  209] train: loss: 0.0508195
[Epoch 96; Iter   185/  209] train: loss: 0.0830435
[Epoch 96] ogbg-moltox21: 0.768653 val loss: 0.373980
[Epoch 96] ogbg-moltox21: 0.744707 test loss: 0.391925
[Epoch 97; Iter     6/  209] train: loss: 0.0653689
[Epoch 97; Iter    36/  209] train: loss: 0.0700904
[Epoch 97; Iter    66/  209] train: loss: 0.0760252
[Epoch 97; Iter    96/  209] train: loss: 0.0680145
[Epoch 97; Iter   126/  209] train: loss: 0.0509728
[Epoch 97; Iter   156/  209] train: loss: 0.0404661
[Epoch 97; Iter   186/  209] train: loss: 0.0623405
[Epoch 97] ogbg-moltox21: 0.771743 val loss: 0.379014
[Epoch 97] ogbg-moltox21: 0.748438 test loss: 0.396348
[Epoch 98; Iter     7/  209] train: loss: 0.0646457
[Epoch 98; Iter    37/  209] train: loss: 0.0321255
[Epoch 98; Iter    67/  209] train: loss: 0.1140417
[Epoch 98; Iter    97/  209] train: loss: 0.0405468
[Epoch 98; Iter   127/  209] train: loss: 0.0749172
[Epoch 98; Iter   157/  209] train: loss: 0.0620930
[Epoch 98; Iter   187/  209] train: loss: 0.0882907
[Epoch 98] ogbg-moltox21: 0.772868 val loss: 0.365500
[Epoch 98] ogbg-moltox21: 0.743836 test loss: 0.393989
[Epoch 99; Iter     8/  209] train: loss: 0.0756473
[Epoch 99; Iter    38/  209] train: loss: 0.0470370
[Epoch 99; Iter    68/  209] train: loss: 0.0526681
[Epoch 99; Iter    98/  209] train: loss: 0.0418819
[Epoch 82; Iter    51/  209] train: loss: 0.0518330
[Epoch 82; Iter    81/  209] train: loss: 0.0476690
[Epoch 82; Iter   111/  209] train: loss: 0.1599765
[Epoch 82; Iter   141/  209] train: loss: 0.0550101
[Epoch 82; Iter   171/  209] train: loss: 0.0671384
[Epoch 82; Iter   201/  209] train: loss: 0.0738497
[Epoch 82] ogbg-moltox21: 0.788189 val loss: 0.315955
[Epoch 82] ogbg-moltox21: 0.751015 test loss: 0.327963
[Epoch 83; Iter    22/  209] train: loss: 0.0590824
[Epoch 83; Iter    52/  209] train: loss: 0.1308418
[Epoch 83; Iter    82/  209] train: loss: 0.1105067
[Epoch 83; Iter   112/  209] train: loss: 0.0853672
[Epoch 83; Iter   142/  209] train: loss: 0.1270580
[Epoch 83; Iter   172/  209] train: loss: 0.0808368
[Epoch 83; Iter   202/  209] train: loss: 0.0645604
[Epoch 83] ogbg-moltox21: 0.783868 val loss: 0.327448
[Epoch 83] ogbg-moltox21: 0.750983 test loss: 0.337339
[Epoch 84; Iter    23/  209] train: loss: 0.0657102
[Epoch 84; Iter    53/  209] train: loss: 0.0422946
[Epoch 84; Iter    83/  209] train: loss: 0.0647622
[Epoch 84; Iter   113/  209] train: loss: 0.1379002
[Epoch 84; Iter   143/  209] train: loss: 0.0896059
[Epoch 84; Iter   173/  209] train: loss: 0.0939557
[Epoch 84; Iter   203/  209] train: loss: 0.0343904
[Epoch 84] ogbg-moltox21: 0.779321 val loss: 0.324879
[Epoch 84] ogbg-moltox21: 0.745414 test loss: 0.341391
[Epoch 85; Iter    24/  209] train: loss: 0.0627158
[Epoch 85; Iter    54/  209] train: loss: 0.0638127
[Epoch 85; Iter    84/  209] train: loss: 0.0898075
[Epoch 85; Iter   114/  209] train: loss: 0.1315756
[Epoch 85; Iter   144/  209] train: loss: 0.0586398
[Epoch 85; Iter   174/  209] train: loss: 0.1127436
[Epoch 85; Iter   204/  209] train: loss: 0.0840095
[Epoch 85] ogbg-moltox21: 0.777012 val loss: 0.335624
[Epoch 85] ogbg-moltox21: 0.742050 test loss: 0.340411
[Epoch 86; Iter    25/  209] train: loss: 0.0936177
[Epoch 86; Iter    55/  209] train: loss: 0.0596717
[Epoch 86; Iter    85/  209] train: loss: 0.0903697
[Epoch 86; Iter   115/  209] train: loss: 0.0786409
[Epoch 86; Iter   145/  209] train: loss: 0.0731367
[Epoch 86; Iter   175/  209] train: loss: 0.0795867
[Epoch 86; Iter   205/  209] train: loss: 0.1527187
[Epoch 86] ogbg-moltox21: 0.780803 val loss: 0.327317
[Epoch 86] ogbg-moltox21: 0.750491 test loss: 0.332872
[Epoch 87; Iter    26/  209] train: loss: 0.0635654
[Epoch 87; Iter    56/  209] train: loss: 0.0668658
[Epoch 87; Iter    86/  209] train: loss: 0.0512393
[Epoch 87; Iter   116/  209] train: loss: 0.0802464
[Epoch 87; Iter   146/  209] train: loss: 0.0651133
[Epoch 87; Iter   176/  209] train: loss: 0.0336154
[Epoch 87; Iter   206/  209] train: loss: 0.0485437
[Epoch 87] ogbg-moltox21: 0.783752 val loss: 0.335244
[Epoch 87] ogbg-moltox21: 0.742765 test loss: 0.348378
[Epoch 88; Iter    27/  209] train: loss: 0.0855775
[Epoch 88; Iter    57/  209] train: loss: 0.0695783
[Epoch 88; Iter    87/  209] train: loss: 0.0558653
[Epoch 88; Iter   117/  209] train: loss: 0.0685085
[Epoch 88; Iter   147/  209] train: loss: 0.0637626
[Epoch 88; Iter   177/  209] train: loss: 0.0920168
[Epoch 88; Iter   207/  209] train: loss: 0.0684332
[Epoch 88] ogbg-moltox21: 0.776500 val loss: 0.336723
[Epoch 88] ogbg-moltox21: 0.747132 test loss: 0.350569
[Epoch 89; Iter    28/  209] train: loss: 0.0561511
[Epoch 89; Iter    58/  209] train: loss: 0.1159890
[Epoch 89; Iter    88/  209] train: loss: 0.0911083
[Epoch 89; Iter   118/  209] train: loss: 0.0470615
[Epoch 89; Iter   148/  209] train: loss: 0.0801573
[Epoch 89; Iter   178/  209] train: loss: 0.1104171
[Epoch 89; Iter   208/  209] train: loss: 0.0864963
[Epoch 89] ogbg-moltox21: 0.776442 val loss: 0.332175
[Epoch 89] ogbg-moltox21: 0.739200 test loss: 0.350582
[Epoch 90; Iter    29/  209] train: loss: 0.0583174
[Epoch 90; Iter    59/  209] train: loss: 0.0476267
[Epoch 90; Iter    89/  209] train: loss: 0.0748224
[Epoch 90; Iter   119/  209] train: loss: 0.0549550
[Epoch 90; Iter   149/  209] train: loss: 0.0741767
[Epoch 90; Iter   179/  209] train: loss: 0.0503927
[Epoch 90; Iter   209/  209] train: loss: 0.1470942
[Epoch 90] ogbg-moltox21: 0.771295 val loss: 0.331325
[Epoch 90] ogbg-moltox21: 0.744373 test loss: 0.340460
[Epoch 91; Iter    30/  209] train: loss: 0.0605622
[Epoch 91; Iter    60/  209] train: loss: 0.0452064
[Epoch 91; Iter    90/  209] train: loss: 0.0846332
[Epoch 91; Iter   120/  209] train: loss: 0.0470399
[Epoch 91; Iter   150/  209] train: loss: 0.1021818
[Epoch 91; Iter   180/  209] train: loss: 0.0548551
[Epoch 91] ogbg-moltox21: 0.775725 val loss: 0.337135
[Epoch 91] ogbg-moltox21: 0.740098 test loss: 0.351973
[Epoch 92; Iter     1/  209] train: loss: 0.0443281
[Epoch 92; Iter    31/  209] train: loss: 0.0638357
[Epoch 92; Iter    61/  209] train: loss: 0.0759757
[Epoch 92; Iter    91/  209] train: loss: 0.0517408
[Epoch 92; Iter   121/  209] train: loss: 0.0353424
[Epoch 92; Iter   151/  209] train: loss: 0.0613080
[Epoch 92; Iter   181/  209] train: loss: 0.0384340
[Epoch 92] ogbg-moltox21: 0.769797 val loss: 0.339034
[Epoch 92] ogbg-moltox21: 0.742851 test loss: 0.349440
[Epoch 93; Iter     2/  209] train: loss: 0.1162302
[Epoch 93; Iter    32/  209] train: loss: 0.0463293
[Epoch 93; Iter    62/  209] train: loss: 0.0801323
[Epoch 93; Iter    92/  209] train: loss: 0.0805728
[Epoch 93; Iter   122/  209] train: loss: 0.0827856
[Epoch 93; Iter   152/  209] train: loss: 0.0779268
[Epoch 93; Iter   182/  209] train: loss: 0.0523720
[Epoch 93] ogbg-moltox21: 0.773161 val loss: 0.336966
[Epoch 93] ogbg-moltox21: 0.739066 test loss: 0.366017
[Epoch 94; Iter     3/  209] train: loss: 0.0640316
[Epoch 94; Iter    33/  209] train: loss: 0.0920387
[Epoch 94; Iter    63/  209] train: loss: 0.0660039
[Epoch 94; Iter    93/  209] train: loss: 0.0553020
[Epoch 94; Iter   123/  209] train: loss: 0.1022975
[Epoch 94; Iter   153/  209] train: loss: 0.0616077
[Epoch 94; Iter   183/  209] train: loss: 0.0619468
[Epoch 94] ogbg-moltox21: 0.772905 val loss: 0.338361
[Epoch 94] ogbg-moltox21: 0.744057 test loss: 0.346809
[Epoch 95; Iter     4/  209] train: loss: 0.0480378
[Epoch 95; Iter    34/  209] train: loss: 0.1066636
[Epoch 95; Iter    64/  209] train: loss: 0.0605906
[Epoch 95; Iter    94/  209] train: loss: 0.0963643
[Epoch 95; Iter   124/  209] train: loss: 0.0673929
[Epoch 95; Iter   154/  209] train: loss: 0.0860415
[Epoch 95; Iter   184/  209] train: loss: 0.0814834
[Epoch 95] ogbg-moltox21: 0.774998 val loss: 0.350161
[Epoch 95] ogbg-moltox21: 0.737927 test loss: 0.369768
[Epoch 96; Iter     5/  209] train: loss: 0.0810947
[Epoch 96; Iter    35/  209] train: loss: 0.0490266
[Epoch 96; Iter    65/  209] train: loss: 0.0833511
[Epoch 96; Iter    95/  209] train: loss: 0.0506777
[Epoch 96; Iter   125/  209] train: loss: 0.0229500
[Epoch 96; Iter   155/  209] train: loss: 0.0615081
[Epoch 96; Iter   185/  209] train: loss: 0.0534667
[Epoch 96] ogbg-moltox21: 0.771032 val loss: 0.351044
[Epoch 96] ogbg-moltox21: 0.736577 test loss: 0.359026
[Epoch 97; Iter     6/  209] train: loss: 0.0692640
[Epoch 97; Iter    36/  209] train: loss: 0.0450672
[Epoch 97; Iter    66/  209] train: loss: 0.0853652
[Epoch 97; Iter    96/  209] train: loss: 0.0519153
[Epoch 97; Iter   126/  209] train: loss: 0.0540393
[Epoch 97; Iter   156/  209] train: loss: 0.0732790
[Epoch 97; Iter   186/  209] train: loss: 0.0437284
[Epoch 97] ogbg-moltox21: 0.772319 val loss: 0.347580
[Epoch 97] ogbg-moltox21: 0.740779 test loss: 0.357629
[Epoch 98; Iter     7/  209] train: loss: 0.0634156
[Epoch 98; Iter    37/  209] train: loss: 0.0411833
[Epoch 98; Iter    67/  209] train: loss: 0.0577797
[Epoch 98; Iter    97/  209] train: loss: 0.0986756
[Epoch 98; Iter   127/  209] train: loss: 0.0912767
[Epoch 98; Iter   157/  209] train: loss: 0.0648699
[Epoch 98; Iter   187/  209] train: loss: 0.0615620
[Epoch 98] ogbg-moltox21: 0.767680 val loss: 0.348170
[Epoch 98] ogbg-moltox21: 0.735895 test loss: 0.359837
[Epoch 99; Iter     8/  209] train: loss: 0.1213911
[Epoch 99; Iter    38/  209] train: loss: 0.0709353
[Epoch 99; Iter    68/  209] train: loss: 0.0988458
[Epoch 99; Iter    98/  209] train: loss: 0.1081656
[Epoch 82; Iter    51/  209] train: loss: 0.0711572
[Epoch 82; Iter    81/  209] train: loss: 0.0434579
[Epoch 82; Iter   111/  209] train: loss: 0.0784980
[Epoch 82; Iter   141/  209] train: loss: 0.0816679
[Epoch 82; Iter   171/  209] train: loss: 0.0948126
[Epoch 82; Iter   201/  209] train: loss: 0.1848710
[Epoch 82] ogbg-moltox21: 0.760621 val loss: 0.355336
[Epoch 82] ogbg-moltox21: 0.758880 test loss: 0.350897
[Epoch 83; Iter    22/  209] train: loss: 0.0736081
[Epoch 83; Iter    52/  209] train: loss: 0.0785977
[Epoch 83; Iter    82/  209] train: loss: 0.1155188
[Epoch 83; Iter   112/  209] train: loss: 0.0890214
[Epoch 83; Iter   142/  209] train: loss: 0.0829242
[Epoch 83; Iter   172/  209] train: loss: 0.1184005
[Epoch 83; Iter   202/  209] train: loss: 0.0798765
[Epoch 83] ogbg-moltox21: 0.768831 val loss: 0.356080
[Epoch 83] ogbg-moltox21: 0.765064 test loss: 0.349203
[Epoch 84; Iter    23/  209] train: loss: 0.0789064
[Epoch 84; Iter    53/  209] train: loss: 0.0841754
[Epoch 84; Iter    83/  209] train: loss: 0.0714088
[Epoch 84; Iter   113/  209] train: loss: 0.0434340
[Epoch 84; Iter   143/  209] train: loss: 0.0909617
[Epoch 84; Iter   173/  209] train: loss: 0.0660131
[Epoch 84; Iter   203/  209] train: loss: 0.0908091
[Epoch 84] ogbg-moltox21: 0.770165 val loss: 0.361159
[Epoch 84] ogbg-moltox21: 0.761193 test loss: 0.359068
[Epoch 85; Iter    24/  209] train: loss: 0.0680845
[Epoch 85; Iter    54/  209] train: loss: 0.1835221
[Epoch 85; Iter    84/  209] train: loss: 0.0710378
[Epoch 85; Iter   114/  209] train: loss: 0.0749328
[Epoch 85; Iter   144/  209] train: loss: 0.0631102
[Epoch 85; Iter   174/  209] train: loss: 0.1010808
[Epoch 85; Iter   204/  209] train: loss: 0.0648942
[Epoch 85] ogbg-moltox21: 0.780570 val loss: 0.344903
[Epoch 85] ogbg-moltox21: 0.766428 test loss: 0.351404
[Epoch 86; Iter    25/  209] train: loss: 0.0673084
[Epoch 86; Iter    55/  209] train: loss: 0.0848231
[Epoch 86; Iter    85/  209] train: loss: 0.0787998
[Epoch 86; Iter   115/  209] train: loss: 0.0677288
[Epoch 86; Iter   145/  209] train: loss: 0.1369975
[Epoch 86; Iter   175/  209] train: loss: 0.0990342
[Epoch 86; Iter   205/  209] train: loss: 0.0971326
[Epoch 86] ogbg-moltox21: 0.772697 val loss: 0.345940
[Epoch 86] ogbg-moltox21: 0.766738 test loss: 0.338644
[Epoch 87; Iter    26/  209] train: loss: 0.0520504
[Epoch 87; Iter    56/  209] train: loss: 0.1006585
[Epoch 87; Iter    86/  209] train: loss: 0.0796932
[Epoch 87; Iter   116/  209] train: loss: 0.1183368
[Epoch 87; Iter   146/  209] train: loss: 0.0602777
[Epoch 87; Iter   176/  209] train: loss: 0.0940713
[Epoch 87; Iter   206/  209] train: loss: 0.1339129
[Epoch 87] ogbg-moltox21: 0.768448 val loss: 0.379090
[Epoch 87] ogbg-moltox21: 0.762905 test loss: 0.367524
[Epoch 88; Iter    27/  209] train: loss: 0.0646465
[Epoch 88; Iter    57/  209] train: loss: 0.0713324
[Epoch 88; Iter    87/  209] train: loss: 0.0747978
[Epoch 88; Iter   117/  209] train: loss: 0.0430574
[Epoch 88; Iter   147/  209] train: loss: 0.0853402
[Epoch 88; Iter   177/  209] train: loss: 0.0842308
[Epoch 88; Iter   207/  209] train: loss: 0.0875187
[Epoch 88] ogbg-moltox21: 0.770446 val loss: 0.369161
[Epoch 88] ogbg-moltox21: 0.764896 test loss: 0.358944
[Epoch 89; Iter    28/  209] train: loss: 0.0495570
[Epoch 89; Iter    58/  209] train: loss: 0.0635186
[Epoch 89; Iter    88/  209] train: loss: 0.0885821
[Epoch 89; Iter   118/  209] train: loss: 0.0531914
[Epoch 89; Iter   148/  209] train: loss: 0.0580038
[Epoch 89; Iter   178/  209] train: loss: 0.0701002
[Epoch 89; Iter   208/  209] train: loss: 0.0378547
[Epoch 89] ogbg-moltox21: 0.773501 val loss: 0.358735
[Epoch 89] ogbg-moltox21: 0.769806 test loss: 0.350213
[Epoch 90; Iter    29/  209] train: loss: 0.0531718
[Epoch 90; Iter    59/  209] train: loss: 0.0625147
[Epoch 90; Iter    89/  209] train: loss: 0.0530312
[Epoch 90; Iter   119/  209] train: loss: 0.0609180
[Epoch 90; Iter   149/  209] train: loss: 0.0317723
[Epoch 90; Iter   179/  209] train: loss: 0.0559687
[Epoch 90; Iter   209/  209] train: loss: 0.0450224
[Epoch 90] ogbg-moltox21: 0.775727 val loss: 0.367094
[Epoch 90] ogbg-moltox21: 0.764655 test loss: 0.356152
[Epoch 91; Iter    30/  209] train: loss: 0.0939408
[Epoch 91; Iter    60/  209] train: loss: 0.0643748
[Epoch 91; Iter    90/  209] train: loss: 0.1514179
[Epoch 91; Iter   120/  209] train: loss: 0.0897457
[Epoch 91; Iter   150/  209] train: loss: 0.0876110
[Epoch 91; Iter   180/  209] train: loss: 0.1257544
[Epoch 91] ogbg-moltox21: 0.770116 val loss: 0.375591
[Epoch 91] ogbg-moltox21: 0.763245 test loss: 0.369126
[Epoch 92; Iter     1/  209] train: loss: 0.0766895
[Epoch 92; Iter    31/  209] train: loss: 0.0613683
[Epoch 92; Iter    61/  209] train: loss: 0.0588911
[Epoch 92; Iter    91/  209] train: loss: 0.0535021
[Epoch 92; Iter   121/  209] train: loss: 0.0719875
[Epoch 92; Iter   151/  209] train: loss: 0.0519172
[Epoch 92; Iter   181/  209] train: loss: 0.0463073
[Epoch 92] ogbg-moltox21: 0.769365 val loss: 0.366910
[Epoch 92] ogbg-moltox21: 0.761249 test loss: 0.368965
[Epoch 93; Iter     2/  209] train: loss: 0.0908396
[Epoch 93; Iter    32/  209] train: loss: 0.1230486
[Epoch 93; Iter    62/  209] train: loss: 0.0336001
[Epoch 93; Iter    92/  209] train: loss: 0.0770092
[Epoch 93; Iter   122/  209] train: loss: 0.0336309
[Epoch 93; Iter   152/  209] train: loss: 0.0478208
[Epoch 93; Iter   182/  209] train: loss: 0.0431744
[Epoch 93] ogbg-moltox21: 0.765115 val loss: 0.370447
[Epoch 93] ogbg-moltox21: 0.763088 test loss: 0.362778
[Epoch 94; Iter     3/  209] train: loss: 0.0417955
[Epoch 94; Iter    33/  209] train: loss: 0.0497940
[Epoch 94; Iter    63/  209] train: loss: 0.0605540
[Epoch 94; Iter    93/  209] train: loss: 0.0550969
[Epoch 94; Iter   123/  209] train: loss: 0.0518866
[Epoch 94; Iter   153/  209] train: loss: 0.0703200
[Epoch 94; Iter   183/  209] train: loss: 0.0963699
[Epoch 94] ogbg-moltox21: 0.769960 val loss: 0.375084
[Epoch 94] ogbg-moltox21: 0.758171 test loss: 0.368723
[Epoch 95; Iter     4/  209] train: loss: 0.0990727
[Epoch 95; Iter    34/  209] train: loss: 0.0564624
[Epoch 95; Iter    64/  209] train: loss: 0.1001489
[Epoch 95; Iter    94/  209] train: loss: 0.0458311
[Epoch 95; Iter   124/  209] train: loss: 0.0771546
[Epoch 95; Iter   154/  209] train: loss: 0.0627012
[Epoch 95; Iter   184/  209] train: loss: 0.1037417
[Epoch 95] ogbg-moltox21: 0.764414 val loss: 0.367282
[Epoch 95] ogbg-moltox21: 0.764678 test loss: 0.361745
[Epoch 96; Iter     5/  209] train: loss: 0.0441501
[Epoch 96; Iter    35/  209] train: loss: 0.0620599
[Epoch 96; Iter    65/  209] train: loss: 0.0761012
[Epoch 96; Iter    95/  209] train: loss: 0.0818494
[Epoch 96; Iter   125/  209] train: loss: 0.0749135
[Epoch 96; Iter   155/  209] train: loss: 0.0813397
[Epoch 96; Iter   185/  209] train: loss: 0.0623023
[Epoch 96] ogbg-moltox21: 0.765500 val loss: 0.374000
[Epoch 96] ogbg-moltox21: 0.763245 test loss: 0.363665
[Epoch 97; Iter     6/  209] train: loss: 0.0833505
[Epoch 97; Iter    36/  209] train: loss: 0.0719781
[Epoch 97; Iter    66/  209] train: loss: 0.0872677
[Epoch 97; Iter    96/  209] train: loss: 0.0609012
[Epoch 97; Iter   126/  209] train: loss: 0.0553727
[Epoch 97; Iter   156/  209] train: loss: 0.1249456
[Epoch 97; Iter   186/  209] train: loss: 0.0471672
[Epoch 97] ogbg-moltox21: 0.767167 val loss: 0.397149
[Epoch 97] ogbg-moltox21: 0.760779 test loss: 0.378257
[Epoch 98; Iter     7/  209] train: loss: 0.0362921
[Epoch 98; Iter    37/  209] train: loss: 0.0752675
[Epoch 98; Iter    67/  209] train: loss: 0.0562631
[Epoch 98; Iter    97/  209] train: loss: 0.1216699
[Epoch 98; Iter   127/  209] train: loss: 0.0395624
[Epoch 98; Iter   157/  209] train: loss: 0.0647686
[Epoch 98; Iter   187/  209] train: loss: 0.0643078
[Epoch 98] ogbg-moltox21: 0.766037 val loss: 0.377391
[Epoch 98] ogbg-moltox21: 0.760057 test loss: 0.369645
[Epoch 99; Iter     8/  209] train: loss: 0.0400948
[Epoch 99; Iter    38/  209] train: loss: 0.0372867
[Epoch 99; Iter    68/  209] train: loss: 0.0750146
[Epoch 99; Iter    98/  209] train: loss: 0.0636882
[Epoch 90] ogbg-moltox21: 0.740807 val loss: 0.367005
[Epoch 90] ogbg-moltox21: 0.719495 test loss: 0.394514
[Epoch 91; Iter    30/  183] train: loss: 0.0823828
[Epoch 91; Iter    60/  183] train: loss: 0.0625672
[Epoch 91; Iter    90/  183] train: loss: 0.0746835
[Epoch 91; Iter   120/  183] train: loss: 0.0380272
[Epoch 91; Iter   150/  183] train: loss: 0.0571218
[Epoch 91; Iter   180/  183] train: loss: 0.0508601
[Epoch 91] ogbg-moltox21: 0.736426 val loss: 0.382210
[Epoch 91] ogbg-moltox21: 0.723267 test loss: 0.417551
[Epoch 92; Iter    27/  183] train: loss: 0.0642564
[Epoch 92; Iter    57/  183] train: loss: 0.0712136
[Epoch 92; Iter    87/  183] train: loss: 0.0555328
[Epoch 92; Iter   117/  183] train: loss: 0.0326201
[Epoch 92; Iter   147/  183] train: loss: 0.1150335
[Epoch 92; Iter   177/  183] train: loss: 0.0658104
[Epoch 92] ogbg-moltox21: 0.735512 val loss: 0.384449
[Epoch 92] ogbg-moltox21: 0.717320 test loss: 0.407842
[Epoch 93; Iter    24/  183] train: loss: 0.0528444
[Epoch 93; Iter    54/  183] train: loss: 0.1175284
[Epoch 93; Iter    84/  183] train: loss: 0.0634729
[Epoch 93; Iter   114/  183] train: loss: 0.0836803
[Epoch 93; Iter   144/  183] train: loss: 0.0783534
[Epoch 93; Iter   174/  183] train: loss: 0.0791351
[Epoch 93] ogbg-moltox21: 0.737765 val loss: 0.382310
[Epoch 93] ogbg-moltox21: 0.719367 test loss: 0.419117
[Epoch 94; Iter    21/  183] train: loss: 0.0762121
[Epoch 94; Iter    51/  183] train: loss: 0.0903304
[Epoch 94; Iter    81/  183] train: loss: 0.0759409
[Epoch 94; Iter   111/  183] train: loss: 0.0566497
[Epoch 94; Iter   141/  183] train: loss: 0.0624629
[Epoch 94; Iter   171/  183] train: loss: 0.0471387
[Epoch 94] ogbg-moltox21: 0.745809 val loss: 0.379121
[Epoch 94] ogbg-moltox21: 0.724148 test loss: 0.405129
[Epoch 95; Iter    18/  183] train: loss: 0.0862467
[Epoch 95; Iter    48/  183] train: loss: 0.0796989
[Epoch 95; Iter    78/  183] train: loss: 0.0624742
[Epoch 95; Iter   108/  183] train: loss: 0.0518601
[Epoch 95; Iter   138/  183] train: loss: 0.0568556
[Epoch 95; Iter   168/  183] train: loss: 0.0719045
[Epoch 95] ogbg-moltox21: 0.739181 val loss: 0.382808
[Epoch 95] ogbg-moltox21: 0.722722 test loss: 0.403577
[Epoch 96; Iter    15/  183] train: loss: 0.0945703
[Epoch 96; Iter    45/  183] train: loss: 0.0829890
[Epoch 96; Iter    75/  183] train: loss: 0.0571950
[Epoch 96; Iter   105/  183] train: loss: 0.0697939
[Epoch 96; Iter   135/  183] train: loss: 0.0628610
[Epoch 96; Iter   165/  183] train: loss: 0.0524552
[Epoch 96] ogbg-moltox21: 0.748161 val loss: 0.395726
[Epoch 96] ogbg-moltox21: 0.722605 test loss: 0.423141
[Epoch 97; Iter    12/  183] train: loss: 0.0536453
[Epoch 97; Iter    42/  183] train: loss: 0.0712870
[Epoch 97; Iter    72/  183] train: loss: 0.0505866
[Epoch 97; Iter   102/  183] train: loss: 0.1554733
[Epoch 97; Iter   132/  183] train: loss: 0.0445257
[Epoch 97; Iter   162/  183] train: loss: 0.0561018
[Epoch 97] ogbg-moltox21: 0.743279 val loss: 0.379554
[Epoch 97] ogbg-moltox21: 0.714486 test loss: 0.412298
[Epoch 98; Iter     9/  183] train: loss: 0.0886108
[Epoch 98; Iter    39/  183] train: loss: 0.0702867
[Epoch 98; Iter    69/  183] train: loss: 0.0729592
[Epoch 98; Iter    99/  183] train: loss: 0.0551191
[Epoch 98; Iter   129/  183] train: loss: 0.0634871
[Epoch 98; Iter   159/  183] train: loss: 0.0869268
[Epoch 98] ogbg-moltox21: 0.743291 val loss: 0.382327
[Epoch 98] ogbg-moltox21: 0.719688 test loss: 0.410260
[Epoch 99; Iter     6/  183] train: loss: 0.0474782
[Epoch 99; Iter    36/  183] train: loss: 0.0740762
[Epoch 99; Iter    66/  183] train: loss: 0.0638450
[Epoch 99; Iter    96/  183] train: loss: 0.0524637
[Epoch 99; Iter   126/  183] train: loss: 0.0678219
[Epoch 99; Iter   156/  183] train: loss: 0.0395163
[Epoch 99] ogbg-moltox21: 0.738643 val loss: 0.392915
[Epoch 99] ogbg-moltox21: 0.718530 test loss: 0.417294
[Epoch 100; Iter     3/  183] train: loss: 0.0373818
[Epoch 100; Iter    33/  183] train: loss: 0.0456555
[Epoch 100; Iter    63/  183] train: loss: 0.0517851
[Epoch 100; Iter    93/  183] train: loss: 0.0506941
[Epoch 100; Iter   123/  183] train: loss: 0.0346208
[Epoch 100; Iter   153/  183] train: loss: 0.0519418
[Epoch 100; Iter   183/  183] train: loss: 0.0372471
[Epoch 100] ogbg-moltox21: 0.740161 val loss: 0.387007
[Epoch 100] ogbg-moltox21: 0.716199 test loss: 0.411769
[Epoch 101; Iter    30/  183] train: loss: 0.0453445
[Epoch 101; Iter    60/  183] train: loss: 0.0692707
[Epoch 101; Iter    90/  183] train: loss: 0.0596424
[Epoch 101; Iter   120/  183] train: loss: 0.0681558
[Epoch 101; Iter   150/  183] train: loss: 0.0512715
[Epoch 101; Iter   180/  183] train: loss: 0.0654579
[Epoch 101] ogbg-moltox21: 0.739729 val loss: 0.393168
[Epoch 101] ogbg-moltox21: 0.713175 test loss: 0.423077
[Epoch 102; Iter    27/  183] train: loss: 0.0768610
[Epoch 102; Iter    57/  183] train: loss: 0.0558087
[Epoch 102; Iter    87/  183] train: loss: 0.0632895
[Epoch 102; Iter   117/  183] train: loss: 0.0366994
[Epoch 102; Iter   147/  183] train: loss: 0.1064130
[Epoch 102; Iter   177/  183] train: loss: 0.0551480
[Epoch 102] ogbg-moltox21: 0.743356 val loss: 0.393528
[Epoch 102] ogbg-moltox21: 0.716138 test loss: 0.422576
[Epoch 103; Iter    24/  183] train: loss: 0.0552057
[Epoch 103; Iter    54/  183] train: loss: 0.0800966
[Epoch 103; Iter    84/  183] train: loss: 0.0612176
[Epoch 103; Iter   114/  183] train: loss: 0.0491408
[Epoch 103; Iter   144/  183] train: loss: 0.0352674
[Epoch 103; Iter   174/  183] train: loss: 0.0289707
[Epoch 103] ogbg-moltox21: 0.739928 val loss: 0.396217
[Epoch 103] ogbg-moltox21: 0.715755 test loss: 0.420371
[Epoch 104; Iter    21/  183] train: loss: 0.0599850
[Epoch 104; Iter    51/  183] train: loss: 0.0616377
[Epoch 104; Iter    81/  183] train: loss: 0.0344633
[Epoch 104; Iter   111/  183] train: loss: 0.0437177
[Epoch 104; Iter   141/  183] train: loss: 0.0872437
[Epoch 104; Iter   171/  183] train: loss: 0.0610133
[Epoch 104] ogbg-moltox21: 0.737305 val loss: 0.409168
[Epoch 104] ogbg-moltox21: 0.712683 test loss: 0.435106
[Epoch 105; Iter    18/  183] train: loss: 0.0904726
[Epoch 105; Iter    48/  183] train: loss: 0.0545181
[Epoch 105; Iter    78/  183] train: loss: 0.0691097
[Epoch 105; Iter   108/  183] train: loss: 0.0378523
[Epoch 105; Iter   138/  183] train: loss: 0.0461787
[Epoch 105; Iter   168/  183] train: loss: 0.0331486
[Epoch 105] ogbg-moltox21: 0.742630 val loss: 0.397797
[Epoch 105] ogbg-moltox21: 0.719919 test loss: 0.426251
[Epoch 106; Iter    15/  183] train: loss: 0.0965164
[Epoch 106; Iter    45/  183] train: loss: 0.0863372
[Epoch 106; Iter    75/  183] train: loss: 0.0580234
[Epoch 106; Iter   105/  183] train: loss: 0.0506852
[Epoch 106; Iter   135/  183] train: loss: 0.0531485
[Epoch 106; Iter   165/  183] train: loss: 0.0388872
[Epoch 106] ogbg-moltox21: 0.734923 val loss: 0.411941
[Epoch 106] ogbg-moltox21: 0.712282 test loss: 0.438920
[Epoch 107; Iter    12/  183] train: loss: 0.0357356
[Epoch 107; Iter    42/  183] train: loss: 0.0367766
[Epoch 107; Iter    72/  183] train: loss: 0.0644174
[Epoch 107; Iter   102/  183] train: loss: 0.0391589
[Epoch 107; Iter   132/  183] train: loss: 0.0819837
[Epoch 107; Iter   162/  183] train: loss: 0.0509300
[Epoch 107] ogbg-moltox21: 0.738772 val loss: 0.402468
[Epoch 107] ogbg-moltox21: 0.717143 test loss: 0.427309
[Epoch 108; Iter     9/  183] train: loss: 0.0504474
[Epoch 108; Iter    39/  183] train: loss: 0.0373017
[Epoch 108; Iter    69/  183] train: loss: 0.0373197
[Epoch 108; Iter    99/  183] train: loss: 0.0449599
[Epoch 108; Iter   129/  183] train: loss: 0.0320563
[Epoch 108; Iter   159/  183] train: loss: 0.0663411
[Epoch 108] ogbg-moltox21: 0.734821 val loss: 0.407100
[Epoch 108] ogbg-moltox21: 0.714639 test loss: 0.436856
[Epoch 109; Iter     6/  183] train: loss: 0.0684022
[Epoch 109; Iter    36/  183] train: loss: 0.0410784
[Epoch 109; Iter    66/  183] train: loss: 0.0731786
[Epoch 109; Iter    96/  183] train: loss: 0.0283729
[Epoch 109; Iter   126/  183] train: loss: 0.0794837
[Epoch 109; Iter   156/  183] train: loss: 0.0520024
[Epoch 109] ogbg-moltox21: 0.731673 val loss: 0.412395
[Epoch 90] ogbg-moltox21: 0.719175 val loss: 0.404288
[Epoch 90] ogbg-moltox21: 0.700434 test loss: 0.434816
[Epoch 91; Iter    30/  183] train: loss: 0.0505714
[Epoch 91; Iter    60/  183] train: loss: 0.0524791
[Epoch 91; Iter    90/  183] train: loss: 0.0439472
[Epoch 91; Iter   120/  183] train: loss: 0.0367780
[Epoch 91; Iter   150/  183] train: loss: 0.0657041
[Epoch 91; Iter   180/  183] train: loss: 0.0328418
[Epoch 91] ogbg-moltox21: 0.735529 val loss: 0.434306
[Epoch 91] ogbg-moltox21: 0.712125 test loss: 0.430023
[Epoch 92; Iter    27/  183] train: loss: 0.0423093
[Epoch 92; Iter    57/  183] train: loss: 0.0872186
[Epoch 92; Iter    87/  183] train: loss: 0.0863044
[Epoch 92; Iter   117/  183] train: loss: 0.0941338
[Epoch 92; Iter   147/  183] train: loss: 0.0593424
[Epoch 92; Iter   177/  183] train: loss: 0.0701862
[Epoch 92] ogbg-moltox21: 0.735897 val loss: 0.406162
[Epoch 92] ogbg-moltox21: 0.710627 test loss: 0.443287
[Epoch 93; Iter    24/  183] train: loss: 0.0377688
[Epoch 93; Iter    54/  183] train: loss: 0.0511538
[Epoch 93; Iter    84/  183] train: loss: 0.0550956
[Epoch 93; Iter   114/  183] train: loss: 0.0585186
[Epoch 93; Iter   144/  183] train: loss: 0.0513763
[Epoch 93; Iter   174/  183] train: loss: 0.0897957
[Epoch 93] ogbg-moltox21: 0.739133 val loss: 0.403718
[Epoch 93] ogbg-moltox21: 0.714866 test loss: 0.438558
[Epoch 94; Iter    21/  183] train: loss: 0.0780026
[Epoch 94; Iter    51/  183] train: loss: 0.0456964
[Epoch 94; Iter    81/  183] train: loss: 0.0365202
[Epoch 94; Iter   111/  183] train: loss: 0.0880432
[Epoch 94; Iter   141/  183] train: loss: 0.0590977
[Epoch 94; Iter   171/  183] train: loss: 0.0755711
[Epoch 94] ogbg-moltox21: 0.732696 val loss: 0.437133
[Epoch 94] ogbg-moltox21: 0.710516 test loss: 0.461920
[Epoch 95; Iter    18/  183] train: loss: 0.0367982
[Epoch 95; Iter    48/  183] train: loss: 0.0901675
[Epoch 95; Iter    78/  183] train: loss: 0.0769590
[Epoch 95; Iter   108/  183] train: loss: 0.0572783
[Epoch 95; Iter   138/  183] train: loss: 0.0580218
[Epoch 95; Iter   168/  183] train: loss: 0.0578854
[Epoch 95] ogbg-moltox21: 0.726837 val loss: 0.414564
[Epoch 95] ogbg-moltox21: 0.707746 test loss: 0.453710
[Epoch 96; Iter    15/  183] train: loss: 0.0418872
[Epoch 96; Iter    45/  183] train: loss: 0.0480218
[Epoch 96; Iter    75/  183] train: loss: 0.0550876
[Epoch 96; Iter   105/  183] train: loss: 0.0860045
[Epoch 96; Iter   135/  183] train: loss: 0.0303316
[Epoch 96; Iter   165/  183] train: loss: 0.0458711
[Epoch 96] ogbg-moltox21: 0.736490 val loss: 0.471532
[Epoch 96] ogbg-moltox21: 0.711256 test loss: 0.462200
[Epoch 97; Iter    12/  183] train: loss: 0.0675923
[Epoch 97; Iter    42/  183] train: loss: 0.0634935
[Epoch 97; Iter    72/  183] train: loss: 0.0478808
[Epoch 97; Iter   102/  183] train: loss: 0.0885531
[Epoch 97; Iter   132/  183] train: loss: 0.0540284
[Epoch 97; Iter   162/  183] train: loss: 0.0448589
[Epoch 97] ogbg-moltox21: 0.736701 val loss: 0.497692
[Epoch 97] ogbg-moltox21: 0.713411 test loss: 0.482900
[Epoch 98; Iter     9/  183] train: loss: 0.0715333
[Epoch 98; Iter    39/  183] train: loss: 0.0613734
[Epoch 98; Iter    69/  183] train: loss: 0.0630112
[Epoch 98; Iter    99/  183] train: loss: 0.0568899
[Epoch 98; Iter   129/  183] train: loss: 0.0355391
[Epoch 98; Iter   159/  183] train: loss: 0.0446008
[Epoch 98] ogbg-moltox21: 0.735945 val loss: 0.423602
[Epoch 98] ogbg-moltox21: 0.711593 test loss: 0.462605
[Epoch 99; Iter     6/  183] train: loss: 0.0519425
[Epoch 99; Iter    36/  183] train: loss: 0.0611396
[Epoch 99; Iter    66/  183] train: loss: 0.0477490
[Epoch 99; Iter    96/  183] train: loss: 0.0372768
[Epoch 99; Iter   126/  183] train: loss: 0.0372568
[Epoch 99; Iter   156/  183] train: loss: 0.0570626
[Epoch 99] ogbg-moltox21: 0.728290 val loss: 0.423989
[Epoch 99] ogbg-moltox21: 0.704519 test loss: 0.470657
[Epoch 100; Iter     3/  183] train: loss: 0.0427383
[Epoch 100; Iter    33/  183] train: loss: 0.0392182
[Epoch 100; Iter    63/  183] train: loss: 0.0465591
[Epoch 100; Iter    93/  183] train: loss: 0.0271064
[Epoch 100; Iter   123/  183] train: loss: 0.0837375
[Epoch 100; Iter   153/  183] train: loss: 0.0502420
[Epoch 100; Iter   183/  183] train: loss: 0.0854305
[Epoch 100] ogbg-moltox21: 0.730509 val loss: 0.423910
[Epoch 100] ogbg-moltox21: 0.707252 test loss: 0.471285
[Epoch 101; Iter    30/  183] train: loss: 0.0301822
[Epoch 101; Iter    60/  183] train: loss: 0.0498012
[Epoch 101; Iter    90/  183] train: loss: 0.0625773
[Epoch 101; Iter   120/  183] train: loss: 0.0339252
[Epoch 101; Iter   150/  183] train: loss: 0.1007235
[Epoch 101; Iter   180/  183] train: loss: 0.0634154
[Epoch 101] ogbg-moltox21: 0.732566 val loss: 0.475060
[Epoch 101] ogbg-moltox21: 0.701924 test loss: 0.486943
[Epoch 102; Iter    27/  183] train: loss: 0.0767363
[Epoch 102; Iter    57/  183] train: loss: 0.0405157
[Epoch 102; Iter    87/  183] train: loss: 0.0399912
[Epoch 102; Iter   117/  183] train: loss: 0.0682677
[Epoch 102; Iter   147/  183] train: loss: 0.0596429
[Epoch 102; Iter   177/  183] train: loss: 0.0776020
[Epoch 102] ogbg-moltox21: 0.737166 val loss: 0.455704
[Epoch 102] ogbg-moltox21: 0.708239 test loss: 0.480476
[Epoch 103; Iter    24/  183] train: loss: 0.0689419
[Epoch 103; Iter    54/  183] train: loss: 0.0651262
[Epoch 103; Iter    84/  183] train: loss: 0.0412898
[Epoch 103; Iter   114/  183] train: loss: 0.0269924
[Epoch 103; Iter   144/  183] train: loss: 0.0608851
[Epoch 103; Iter   174/  183] train: loss: 0.0359152
[Epoch 103] ogbg-moltox21: 0.732726 val loss: 0.417145
[Epoch 103] ogbg-moltox21: 0.702876 test loss: 0.462468
[Epoch 104; Iter    21/  183] train: loss: 0.0530444
[Epoch 104; Iter    51/  183] train: loss: 0.0503356
[Epoch 104; Iter    81/  183] train: loss: 0.0473827
[Epoch 104; Iter   111/  183] train: loss: 0.0359096
[Epoch 104; Iter   141/  183] train: loss: 0.0709205
[Epoch 104; Iter   171/  183] train: loss: 0.0544290
[Epoch 104] ogbg-moltox21: 0.738394 val loss: 0.428912
[Epoch 104] ogbg-moltox21: 0.706991 test loss: 0.477220
[Epoch 105; Iter    18/  183] train: loss: 0.0236971
[Epoch 105; Iter    48/  183] train: loss: 0.0421246
[Epoch 105; Iter    78/  183] train: loss: 0.0415884
[Epoch 105; Iter   108/  183] train: loss: 0.0598033
[Epoch 105; Iter   138/  183] train: loss: 0.0731301
[Epoch 105; Iter   168/  183] train: loss: 0.0431749
[Epoch 105] ogbg-moltox21: 0.733789 val loss: 0.425625
[Epoch 105] ogbg-moltox21: 0.703114 test loss: 0.470701
[Epoch 106; Iter    15/  183] train: loss: 0.0481437
[Epoch 106; Iter    45/  183] train: loss: 0.0626855
[Epoch 106; Iter    75/  183] train: loss: 0.0545082
[Epoch 106; Iter   105/  183] train: loss: 0.0658758
[Epoch 106; Iter   135/  183] train: loss: 0.0894023
[Epoch 106; Iter   165/  183] train: loss: 0.0378146
[Epoch 106] ogbg-moltox21: 0.740167 val loss: 0.426604
[Epoch 106] ogbg-moltox21: 0.706786 test loss: 0.482126
[Epoch 107; Iter    12/  183] train: loss: 0.0352300
[Epoch 107; Iter    42/  183] train: loss: 0.0315764
[Epoch 107; Iter    72/  183] train: loss: 0.0600933
[Epoch 107; Iter   102/  183] train: loss: 0.0483171
[Epoch 107; Iter   132/  183] train: loss: 0.0631960
[Epoch 107; Iter   162/  183] train: loss: 0.0282700
[Epoch 107] ogbg-moltox21: 0.733285 val loss: 0.531038
[Epoch 107] ogbg-moltox21: 0.706066 test loss: 0.513762
[Epoch 108; Iter     9/  183] train: loss: 0.0545216
[Epoch 108; Iter    39/  183] train: loss: 0.0430615
[Epoch 108; Iter    69/  183] train: loss: 0.0536276
[Epoch 108; Iter    99/  183] train: loss: 0.0675927
[Epoch 108; Iter   129/  183] train: loss: 0.0480658
[Epoch 108; Iter   159/  183] train: loss: 0.0450460
[Epoch 108] ogbg-moltox21: 0.732540 val loss: 0.432341
[Epoch 108] ogbg-moltox21: 0.701785 test loss: 0.487178
[Epoch 109; Iter     6/  183] train: loss: 0.0678967
[Epoch 109; Iter    36/  183] train: loss: 0.0487120
[Epoch 109; Iter    66/  183] train: loss: 0.0261026
[Epoch 109; Iter    96/  183] train: loss: 0.0363250
[Epoch 109; Iter   126/  183] train: loss: 0.0613563
[Epoch 109; Iter   156/  183] train: loss: 0.0452263
[Epoch 109] ogbg-moltox21: 0.722511 val loss: 0.430408
[Epoch 90] ogbg-moltox21: 0.725074 val loss: 0.477890
[Epoch 90] ogbg-moltox21: 0.722831 test loss: 0.602858
[Epoch 91; Iter    30/  183] train: loss: 0.0497152
[Epoch 91; Iter    60/  183] train: loss: 0.0461205
[Epoch 91; Iter    90/  183] train: loss: 0.0326904
[Epoch 91; Iter   120/  183] train: loss: 0.0901056
[Epoch 91; Iter   150/  183] train: loss: 0.0698547
[Epoch 91; Iter   180/  183] train: loss: 0.0637918
[Epoch 91] ogbg-moltox21: 0.727817 val loss: 0.493896
[Epoch 91] ogbg-moltox21: 0.727052 test loss: 0.647264
[Epoch 92; Iter    27/  183] train: loss: 0.0710606
[Epoch 92; Iter    57/  183] train: loss: 0.0381784
[Epoch 92; Iter    87/  183] train: loss: 0.0401074
[Epoch 92; Iter   117/  183] train: loss: 0.0516545
[Epoch 92; Iter   147/  183] train: loss: 0.0467556
[Epoch 92; Iter   177/  183] train: loss: 0.0354928
[Epoch 92] ogbg-moltox21: 0.728246 val loss: 0.400821
[Epoch 92] ogbg-moltox21: 0.722965 test loss: 0.476990
[Epoch 93; Iter    24/  183] train: loss: 0.1097895
[Epoch 93; Iter    54/  183] train: loss: 0.0647893
[Epoch 93; Iter    84/  183] train: loss: 0.0545282
[Epoch 93; Iter   114/  183] train: loss: 0.0823077
[Epoch 93; Iter   144/  183] train: loss: 0.0364137
[Epoch 93; Iter   174/  183] train: loss: 0.0660231
[Epoch 93] ogbg-moltox21: 0.722124 val loss: 0.414391
[Epoch 93] ogbg-moltox21: 0.722441 test loss: 0.534549
[Epoch 94; Iter    21/  183] train: loss: 0.1014021
[Epoch 94; Iter    51/  183] train: loss: 0.0770074
[Epoch 94; Iter    81/  183] train: loss: 0.0182207
[Epoch 94; Iter   111/  183] train: loss: 0.0683505
[Epoch 94; Iter   141/  183] train: loss: 0.0548648
[Epoch 94; Iter   171/  183] train: loss: 0.0650299
[Epoch 94] ogbg-moltox21: 0.724640 val loss: 0.461615
[Epoch 94] ogbg-moltox21: 0.724949 test loss: 0.604472
[Epoch 95; Iter    18/  183] train: loss: 0.0484748
[Epoch 95; Iter    48/  183] train: loss: 0.0453580
[Epoch 95; Iter    78/  183] train: loss: 0.0546332
[Epoch 95; Iter   108/  183] train: loss: 0.0476914
[Epoch 95; Iter   138/  183] train: loss: 0.0561649
[Epoch 95; Iter   168/  183] train: loss: 0.0508347
[Epoch 95] ogbg-moltox21: 0.722586 val loss: 0.707571
[Epoch 95] ogbg-moltox21: 0.716322 test loss: 1.033542
[Epoch 96; Iter    15/  183] train: loss: 0.0514570
[Epoch 96; Iter    45/  183] train: loss: 0.0629370
[Epoch 96; Iter    75/  183] train: loss: 0.0480761
[Epoch 96; Iter   105/  183] train: loss: 0.0635970
[Epoch 96; Iter   135/  183] train: loss: 0.0518766
[Epoch 96; Iter   165/  183] train: loss: 0.0552095
[Epoch 96] ogbg-moltox21: 0.724166 val loss: 0.716351
[Epoch 96] ogbg-moltox21: 0.719260 test loss: 1.061610
[Epoch 97; Iter    12/  183] train: loss: 0.0543689
[Epoch 97; Iter    42/  183] train: loss: 0.0686862
[Epoch 97; Iter    72/  183] train: loss: 0.0706712
[Epoch 97; Iter   102/  183] train: loss: 0.0419896
[Epoch 97; Iter   132/  183] train: loss: 0.0625872
[Epoch 97; Iter   162/  183] train: loss: 0.0508275
[Epoch 97] ogbg-moltox21: 0.723867 val loss: 0.769702
[Epoch 97] ogbg-moltox21: 0.715115 test loss: 1.154905
[Epoch 98; Iter     9/  183] train: loss: 0.0411582
[Epoch 98; Iter    39/  183] train: loss: 0.0343336
[Epoch 98; Iter    69/  183] train: loss: 0.0748728
[Epoch 98; Iter    99/  183] train: loss: 0.0622539
[Epoch 98; Iter   129/  183] train: loss: 0.0885869
[Epoch 98; Iter   159/  183] train: loss: 0.0327365
[Epoch 98] ogbg-moltox21: 0.716122 val loss: 0.761842
[Epoch 98] ogbg-moltox21: 0.715392 test loss: 1.127944
[Epoch 99; Iter     6/  183] train: loss: 0.0734536
[Epoch 99; Iter    36/  183] train: loss: 0.0268277
[Epoch 99; Iter    66/  183] train: loss: 0.0395546
[Epoch 99; Iter    96/  183] train: loss: 0.0520036
[Epoch 99; Iter   126/  183] train: loss: 0.0602148
[Epoch 99; Iter   156/  183] train: loss: 0.0511599
[Epoch 99] ogbg-moltox21: 0.712247 val loss: 0.712344
[Epoch 99] ogbg-moltox21: 0.710435 test loss: 1.007264
[Epoch 100; Iter     3/  183] train: loss: 0.0535158
[Epoch 100; Iter    33/  183] train: loss: 0.0671065
[Epoch 100; Iter    63/  183] train: loss: 0.0835773
[Epoch 100; Iter    93/  183] train: loss: 0.0591350
[Epoch 100; Iter   123/  183] train: loss: 0.0273245
[Epoch 100; Iter   153/  183] train: loss: 0.0522473
[Epoch 100; Iter   183/  183] train: loss: 0.0503976
[Epoch 100] ogbg-moltox21: 0.719773 val loss: 0.698286
[Epoch 100] ogbg-moltox21: 0.718750 test loss: 1.003908
[Epoch 101; Iter    30/  183] train: loss: 0.0399193
[Epoch 101; Iter    60/  183] train: loss: 0.0650235
[Epoch 101; Iter    90/  183] train: loss: 0.0531457
[Epoch 101; Iter   120/  183] train: loss: 0.0445287
[Epoch 101; Iter   150/  183] train: loss: 0.0371075
[Epoch 101; Iter   180/  183] train: loss: 0.0423862
[Epoch 101] ogbg-moltox21: 0.722712 val loss: 0.605166
[Epoch 101] ogbg-moltox21: 0.723899 test loss: 0.809158
[Epoch 102; Iter    27/  183] train: loss: 0.0263060
[Epoch 102; Iter    57/  183] train: loss: 0.0627293
[Epoch 102; Iter    87/  183] train: loss: 0.0255331
[Epoch 102; Iter   117/  183] train: loss: 0.0715622
[Epoch 102; Iter   147/  183] train: loss: 0.0490027
[Epoch 102; Iter   177/  183] train: loss: 0.0928571
[Epoch 102] ogbg-moltox21: 0.724838 val loss: 0.621381
[Epoch 102] ogbg-moltox21: 0.720263 test loss: 0.857490
[Epoch 103; Iter    24/  183] train: loss: 0.0329615
[Epoch 103; Iter    54/  183] train: loss: 0.0529402
[Epoch 103; Iter    84/  183] train: loss: 0.0642335
[Epoch 103; Iter   114/  183] train: loss: 0.0550527
[Epoch 103; Iter   144/  183] train: loss: 0.0710641
[Epoch 103; Iter   174/  183] train: loss: 0.0374478
[Epoch 103] ogbg-moltox21: 0.719554 val loss: 0.588538
[Epoch 103] ogbg-moltox21: 0.718494 test loss: 0.773533
[Epoch 104; Iter    21/  183] train: loss: 0.0465431
[Epoch 104; Iter    51/  183] train: loss: 0.0388699
[Epoch 104; Iter    81/  183] train: loss: 0.0641893
[Epoch 104; Iter   111/  183] train: loss: 0.0732437
[Epoch 104; Iter   141/  183] train: loss: 0.0834070
[Epoch 104; Iter   171/  183] train: loss: 0.0347662
[Epoch 104] ogbg-moltox21: 0.718774 val loss: 0.633489
[Epoch 104] ogbg-moltox21: 0.718216 test loss: 0.855009
[Epoch 105; Iter    18/  183] train: loss: 0.0647965
[Epoch 105; Iter    48/  183] train: loss: 0.0906099
[Epoch 105; Iter    78/  183] train: loss: 0.0312122
[Epoch 105; Iter   108/  183] train: loss: 0.0410100
[Epoch 105; Iter   138/  183] train: loss: 0.0629434
[Epoch 105; Iter   168/  183] train: loss: 0.0258696
[Epoch 105] ogbg-moltox21: 0.723338 val loss: 0.555092
[Epoch 105] ogbg-moltox21: 0.719718 test loss: 0.726856
[Epoch 106; Iter    15/  183] train: loss: 0.0561323
[Epoch 106; Iter    45/  183] train: loss: 0.0431436
[Epoch 106; Iter    75/  183] train: loss: 0.0493758
[Epoch 106; Iter   105/  183] train: loss: 0.0896874
[Epoch 106; Iter   135/  183] train: loss: 0.0360695
[Epoch 106; Iter   165/  183] train: loss: 0.0379064
[Epoch 106] ogbg-moltox21: 0.717975 val loss: 0.837088
[Epoch 106] ogbg-moltox21: 0.713438 test loss: 1.271255
[Epoch 107; Iter    12/  183] train: loss: 0.0584915
[Epoch 107; Iter    42/  183] train: loss: 0.0563602
[Epoch 107; Iter    72/  183] train: loss: 0.0867228
[Epoch 107; Iter   102/  183] train: loss: 0.0356574
[Epoch 107; Iter   132/  183] train: loss: 0.0520685
[Epoch 107; Iter   162/  183] train: loss: 0.0705904
[Epoch 107] ogbg-moltox21: 0.723076 val loss: 0.888104
[Epoch 107] ogbg-moltox21: 0.718874 test loss: 1.389052
[Epoch 108; Iter     9/  183] train: loss: 0.0301616
[Epoch 108; Iter    39/  183] train: loss: 0.0514309
[Epoch 108; Iter    69/  183] train: loss: 0.0659873
[Epoch 108; Iter    99/  183] train: loss: 0.0438877
[Epoch 108; Iter   129/  183] train: loss: 0.0400089
[Epoch 108; Iter   159/  183] train: loss: 0.0419199
[Epoch 108] ogbg-moltox21: 0.719014 val loss: 0.629051
[Epoch 108] ogbg-moltox21: 0.719000 test loss: 0.846015
[Epoch 109; Iter     6/  183] train: loss: 0.0363861
[Epoch 109; Iter    36/  183] train: loss: 0.0314404
[Epoch 109; Iter    66/  183] train: loss: 0.0325235
[Epoch 109; Iter    96/  183] train: loss: 0.0736456
[Epoch 109; Iter   126/  183] train: loss: 0.0359304
[Epoch 109; Iter   156/  183] train: loss: 0.0395560
[Epoch 109] ogbg-moltox21: 0.717087 val loss: 0.697834
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0697640
[Epoch 101] ogbg-moltox21: 0.721144 val loss: 0.443842
[Epoch 101] ogbg-moltox21: 0.721168 test loss: 0.450353
[Epoch 102; Iter    13/  157] train: loss: 0.0451249
[Epoch 102; Iter    43/  157] train: loss: 0.0686694
[Epoch 102; Iter    73/  157] train: loss: 0.0410100
[Epoch 102; Iter   103/  157] train: loss: 0.0791062
[Epoch 102; Iter   133/  157] train: loss: 0.0592265
[Epoch 102] ogbg-moltox21: 0.723257 val loss: 0.441229
[Epoch 102] ogbg-moltox21: 0.719543 test loss: 0.450229
[Epoch 103; Iter     6/  157] train: loss: 0.0356247
[Epoch 103; Iter    36/  157] train: loss: 0.0377662
[Epoch 103; Iter    66/  157] train: loss: 0.0533324
[Epoch 103; Iter    96/  157] train: loss: 0.0627385
[Epoch 103; Iter   126/  157] train: loss: 0.0713755
[Epoch 103; Iter   156/  157] train: loss: 0.0522134
[Epoch 103] ogbg-moltox21: 0.722188 val loss: 0.457858
[Epoch 103] ogbg-moltox21: 0.719614 test loss: 0.476022
[Epoch 104; Iter    29/  157] train: loss: 0.0917104
[Epoch 104; Iter    59/  157] train: loss: 0.0561345
[Epoch 104; Iter    89/  157] train: loss: 0.0364935
[Epoch 104; Iter   119/  157] train: loss: 0.0565153
[Epoch 104; Iter   149/  157] train: loss: 0.0455434
[Epoch 104] ogbg-moltox21: 0.724609 val loss: 0.456491
[Epoch 104] ogbg-moltox21: 0.722942 test loss: 0.467353
[Epoch 105; Iter    22/  157] train: loss: 0.0412012
[Epoch 105; Iter    52/  157] train: loss: 0.0789784
[Epoch 105; Iter    82/  157] train: loss: 0.0756209
[Epoch 105; Iter   112/  157] train: loss: 0.0415641
[Epoch 105; Iter   142/  157] train: loss: 0.0811233
[Epoch 105] ogbg-moltox21: 0.720345 val loss: 0.455746
[Epoch 105] ogbg-moltox21: 0.718310 test loss: 0.452031
[Epoch 106; Iter    15/  157] train: loss: 0.0776659
[Epoch 106; Iter    45/  157] train: loss: 0.0296769
[Epoch 106; Iter    75/  157] train: loss: 0.0568313
[Epoch 106; Iter   105/  157] train: loss: 0.0377671
[Epoch 106; Iter   135/  157] train: loss: 0.0201895
[Epoch 106] ogbg-moltox21: 0.720105 val loss: 0.462524
[Epoch 106] ogbg-moltox21: 0.714311 test loss: 0.468845
[Epoch 107; Iter     8/  157] train: loss: 0.0353227
[Epoch 107; Iter    38/  157] train: loss: 0.0707741
[Epoch 107; Iter    68/  157] train: loss: 0.0307566
[Epoch 107; Iter    98/  157] train: loss: 0.0500029
[Epoch 107; Iter   128/  157] train: loss: 0.0647682
[Epoch 107] ogbg-moltox21: 0.718021 val loss: 0.462533
[Epoch 107] ogbg-moltox21: 0.715537 test loss: 0.473851
[Epoch 108; Iter     1/  157] train: loss: 0.0420663
[Epoch 108; Iter    31/  157] train: loss: 0.0479338
[Epoch 108; Iter    61/  157] train: loss: 0.0815392
[Epoch 108; Iter    91/  157] train: loss: 0.0455301
[Epoch 108; Iter   121/  157] train: loss: 0.0539656
[Epoch 108; Iter   151/  157] train: loss: 0.0498430
[Epoch 108] ogbg-moltox21: 0.716933 val loss: 0.470265
[Epoch 108] ogbg-moltox21: 0.715434 test loss: 0.481529
[Epoch 109; Iter    24/  157] train: loss: 0.0388878
[Epoch 109; Iter    54/  157] train: loss: 0.1180066
[Epoch 109; Iter    84/  157] train: loss: 0.0653104
[Epoch 109; Iter   114/  157] train: loss: 0.0625024
[Epoch 109; Iter   144/  157] train: loss: 0.0542990
[Epoch 109] ogbg-moltox21: 0.727146 val loss: 0.460459
[Epoch 109] ogbg-moltox21: 0.721360 test loss: 0.471807
[Epoch 110; Iter    17/  157] train: loss: 0.0297618
[Epoch 110; Iter    47/  157] train: loss: 0.0520387
[Epoch 110; Iter    77/  157] train: loss: 0.1034002
[Epoch 110; Iter   107/  157] train: loss: 0.0937355
[Epoch 110; Iter   137/  157] train: loss: 0.0431209
[Epoch 110] ogbg-moltox21: 0.718194 val loss: 0.457226
[Epoch 110] ogbg-moltox21: 0.710774 test loss: 0.468883
[Epoch 111; Iter    10/  157] train: loss: 0.0571332
[Epoch 111; Iter    40/  157] train: loss: 0.0477622
[Epoch 111; Iter    70/  157] train: loss: 0.0560815
[Epoch 111; Iter   100/  157] train: loss: 0.0847123
[Epoch 111; Iter   130/  157] train: loss: 0.1310053
[Epoch 111] ogbg-moltox21: 0.722055 val loss: 0.469786
[Epoch 111] ogbg-moltox21: 0.714458 test loss: 0.490761
[Epoch 112; Iter     3/  157] train: loss: 0.0531515
[Epoch 112; Iter    33/  157] train: loss: 0.0303807
[Epoch 112; Iter    63/  157] train: loss: 0.0846642
[Epoch 112; Iter    93/  157] train: loss: 0.0660330
[Epoch 112; Iter   123/  157] train: loss: 0.0577680
[Epoch 112; Iter   153/  157] train: loss: 0.0436113
[Epoch 112] ogbg-moltox21: 0.726684 val loss: 0.466491
[Epoch 112] ogbg-moltox21: 0.721756 test loss: 0.469766
[Epoch 113; Iter    26/  157] train: loss: 0.0372323
[Epoch 113; Iter    56/  157] train: loss: 0.0443573
[Epoch 113; Iter    86/  157] train: loss: 0.0782454
[Epoch 113; Iter   116/  157] train: loss: 0.0787203
[Epoch 113; Iter   146/  157] train: loss: 0.0709850
[Epoch 113] ogbg-moltox21: 0.721149 val loss: 0.465856
[Epoch 113] ogbg-moltox21: 0.716076 test loss: 0.479914
[Epoch 114; Iter    19/  157] train: loss: 0.0357229
[Epoch 114; Iter    49/  157] train: loss: 0.0470850
[Epoch 114; Iter    79/  157] train: loss: 0.0345787
[Epoch 114; Iter   109/  157] train: loss: 0.0544207
[Epoch 114; Iter   139/  157] train: loss: 0.0724460
[Epoch 114] ogbg-moltox21: 0.717803 val loss: 0.461975
[Epoch 114] ogbg-moltox21: 0.715536 test loss: 0.471486
[Epoch 115; Iter    12/  157] train: loss: 0.0624155
[Epoch 115; Iter    42/  157] train: loss: 0.0494348
[Epoch 115; Iter    72/  157] train: loss: 0.0446045
[Epoch 115; Iter   102/  157] train: loss: 0.0763375
[Epoch 115; Iter   132/  157] train: loss: 0.0395676
[Epoch 115] ogbg-moltox21: 0.719635 val loss: 0.468055
[Epoch 115] ogbg-moltox21: 0.717048 test loss: 0.472723
[Epoch 116; Iter     5/  157] train: loss: 0.0344210
[Epoch 116; Iter    35/  157] train: loss: 0.0504092
[Epoch 116; Iter    65/  157] train: loss: 0.0343617
[Epoch 116; Iter    95/  157] train: loss: 0.0455022
[Epoch 116; Iter   125/  157] train: loss: 0.0460479
[Epoch 116; Iter   155/  157] train: loss: 0.0573804
[Epoch 116] ogbg-moltox21: 0.725473 val loss: 0.475113
[Epoch 116] ogbg-moltox21: 0.722441 test loss: 0.482789
[Epoch 117; Iter    28/  157] train: loss: 0.0539728
[Epoch 117; Iter    58/  157] train: loss: 0.0706391
[Epoch 117; Iter    88/  157] train: loss: 0.0464961
[Epoch 117; Iter   118/  157] train: loss: 0.0522767
[Epoch 117; Iter   148/  157] train: loss: 0.0910554
[Epoch 117] ogbg-moltox21: 0.726146 val loss: 0.485725
[Epoch 117] ogbg-moltox21: 0.721481 test loss: 0.502062
[Epoch 118; Iter    21/  157] train: loss: 0.0495460
[Epoch 118; Iter    51/  157] train: loss: 0.0467684
[Epoch 118; Iter    81/  157] train: loss: 0.0458618
[Epoch 118; Iter   111/  157] train: loss: 0.0411571
[Epoch 118; Iter   141/  157] train: loss: 0.0441636
[Epoch 118] ogbg-moltox21: 0.720975 val loss: 0.489127
[Epoch 118] ogbg-moltox21: 0.715882 test loss: 0.500220
[Epoch 119; Iter    14/  157] train: loss: 0.0531823
[Epoch 119; Iter    44/  157] train: loss: 0.0471950
[Epoch 119; Iter    74/  157] train: loss: 0.0363329
[Epoch 119; Iter   104/  157] train: loss: 0.0702206
[Epoch 119; Iter   134/  157] train: loss: 0.0333315
[Epoch 119] ogbg-moltox21: 0.723474 val loss: 0.471628
[Epoch 119] ogbg-moltox21: 0.718031 test loss: 0.482476
[Epoch 120; Iter     7/  157] train: loss: 0.0458669
[Epoch 120; Iter    37/  157] train: loss: 0.0878319
[Epoch 120; Iter    67/  157] train: loss: 0.0475679
[Epoch 120; Iter    97/  157] train: loss: 0.0834168
[Epoch 120; Iter   127/  157] train: loss: 0.0723496
[Epoch 120; Iter   157/  157] train: loss: 0.0512740
[Epoch 120] ogbg-moltox21: 0.721126 val loss: 0.469551
[Epoch 120] ogbg-moltox21: 0.713313 test loss: 0.485656
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 35.
Statistics on  val_best_checkpoint
mean_pred: -3.2786850929260254
std_pred: 7.091544151306152
mean_targets: nan
std_targets: nan
prcauc: 0.3140355378904837
rocauc: 0.778642969882958
ogbg-moltox21: 0.778642969882958
OGBNanLabelBCEWithLogitsLoss: 0.38167763164020935
Statistics on  test
mean_pred: -3.2051031589508057
std_pred: 4.5689826011657715
mean_targets: nan
std_targets: nan
prcauc: 0.2737985045437287
rocauc: 0.7540815313952517
ogbg-moltox21: 0.7540815313952517
[Epoch 101; Iter   140/  157] train: loss: 0.0203682
[Epoch 101] ogbg-moltox21: 0.724672 val loss: 0.443111
[Epoch 101] ogbg-moltox21: 0.713284 test loss: 0.458897
[Epoch 102; Iter    13/  157] train: loss: 0.0631665
[Epoch 102; Iter    43/  157] train: loss: 0.1208227
[Epoch 102; Iter    73/  157] train: loss: 0.0510533
[Epoch 102; Iter   103/  157] train: loss: 0.0549644
[Epoch 102; Iter   133/  157] train: loss: 0.0549279
[Epoch 102] ogbg-moltox21: 0.721082 val loss: 0.466299
[Epoch 102] ogbg-moltox21: 0.713094 test loss: 0.470109
[Epoch 103; Iter     6/  157] train: loss: 0.0811643
[Epoch 103; Iter    36/  157] train: loss: 0.0500268
[Epoch 103; Iter    66/  157] train: loss: 0.1142151
[Epoch 103; Iter    96/  157] train: loss: 0.0433698
[Epoch 103; Iter   126/  157] train: loss: 0.0381810
[Epoch 103; Iter   156/  157] train: loss: 0.0641580
[Epoch 103] ogbg-moltox21: 0.713547 val loss: 0.450748
[Epoch 103] ogbg-moltox21: 0.705540 test loss: 0.464162
[Epoch 104; Iter    29/  157] train: loss: 0.0739306
[Epoch 104; Iter    59/  157] train: loss: 0.0293736
[Epoch 104; Iter    89/  157] train: loss: 0.0492494
[Epoch 104; Iter   119/  157] train: loss: 0.0512198
[Epoch 104; Iter   149/  157] train: loss: 0.0502818
[Epoch 104] ogbg-moltox21: 0.714898 val loss: 0.469174
[Epoch 104] ogbg-moltox21: 0.706381 test loss: 0.480547
[Epoch 105; Iter    22/  157] train: loss: 0.0395892
[Epoch 105; Iter    52/  157] train: loss: 0.0487466
[Epoch 105; Iter    82/  157] train: loss: 0.0662517
[Epoch 105; Iter   112/  157] train: loss: 0.0466691
[Epoch 105; Iter   142/  157] train: loss: 0.0627750
[Epoch 105] ogbg-moltox21: 0.713430 val loss: 0.453035
[Epoch 105] ogbg-moltox21: 0.704398 test loss: 0.458034
[Epoch 106; Iter    15/  157] train: loss: 0.0689797
[Epoch 106; Iter    45/  157] train: loss: 0.0614954
[Epoch 106; Iter    75/  157] train: loss: 0.0397830
[Epoch 106; Iter   105/  157] train: loss: 0.0425676
[Epoch 106; Iter   135/  157] train: loss: 0.0550865
[Epoch 106] ogbg-moltox21: 0.716384 val loss: 0.457572
[Epoch 106] ogbg-moltox21: 0.709533 test loss: 0.465736
[Epoch 107; Iter     8/  157] train: loss: 0.0427791
[Epoch 107; Iter    38/  157] train: loss: 0.0536578
[Epoch 107; Iter    68/  157] train: loss: 0.0404980
[Epoch 107; Iter    98/  157] train: loss: 0.0528474
[Epoch 107; Iter   128/  157] train: loss: 0.0326172
[Epoch 107] ogbg-moltox21: 0.719950 val loss: 0.470314
[Epoch 107] ogbg-moltox21: 0.713832 test loss: 0.491396
[Epoch 108; Iter     1/  157] train: loss: 0.0383333
[Epoch 108; Iter    31/  157] train: loss: 0.0534555
[Epoch 108; Iter    61/  157] train: loss: 0.0428091
[Epoch 108; Iter    91/  157] train: loss: 0.0229468
[Epoch 108; Iter   121/  157] train: loss: 0.1070317
[Epoch 108; Iter   151/  157] train: loss: 0.0472053
[Epoch 108] ogbg-moltox21: 0.714351 val loss: 0.504244
[Epoch 108] ogbg-moltox21: 0.710113 test loss: 0.470994
[Epoch 109; Iter    24/  157] train: loss: 0.0585812
[Epoch 109; Iter    54/  157] train: loss: 0.0215367
[Epoch 109; Iter    84/  157] train: loss: 0.0453470
[Epoch 109; Iter   114/  157] train: loss: 0.0383541
[Epoch 109; Iter   144/  157] train: loss: 0.0499050
[Epoch 109] ogbg-moltox21: 0.717122 val loss: 0.460985
[Epoch 109] ogbg-moltox21: 0.707571 test loss: 0.463370
[Epoch 110; Iter    17/  157] train: loss: 0.0452935
[Epoch 110; Iter    47/  157] train: loss: 0.1009415
[Epoch 110; Iter    77/  157] train: loss: 0.0244627
[Epoch 110; Iter   107/  157] train: loss: 0.0536972
[Epoch 110; Iter   137/  157] train: loss: 0.0385028
[Epoch 110] ogbg-moltox21: 0.713845 val loss: 0.490635
[Epoch 110] ogbg-moltox21: 0.708341 test loss: 0.475719
[Epoch 111; Iter    10/  157] train: loss: 0.0363040
[Epoch 111; Iter    40/  157] train: loss: 0.0338727
[Epoch 111; Iter    70/  157] train: loss: 0.0501188
[Epoch 111; Iter   100/  157] train: loss: 0.0323297
[Epoch 111; Iter   130/  157] train: loss: 0.0533646
[Epoch 111] ogbg-moltox21: 0.715074 val loss: 0.481759
[Epoch 111] ogbg-moltox21: 0.707974 test loss: 0.479596
[Epoch 112; Iter     3/  157] train: loss: 0.0327610
[Epoch 112; Iter    33/  157] train: loss: 0.0620486
[Epoch 112; Iter    63/  157] train: loss: 0.0498632
[Epoch 112; Iter    93/  157] train: loss: 0.0380537
[Epoch 112; Iter   123/  157] train: loss: 0.0427578
[Epoch 112; Iter   153/  157] train: loss: 0.0690112
[Epoch 112] ogbg-moltox21: 0.711214 val loss: 0.546789
[Epoch 112] ogbg-moltox21: 0.705376 test loss: 0.510608
[Epoch 113; Iter    26/  157] train: loss: 0.0512386
[Epoch 113; Iter    56/  157] train: loss: 0.0500763
[Epoch 113; Iter    86/  157] train: loss: 0.0555817
[Epoch 113; Iter   116/  157] train: loss: 0.0608140
[Epoch 113; Iter   146/  157] train: loss: 0.0499292
[Epoch 113] ogbg-moltox21: 0.711304 val loss: 0.477449
[Epoch 113] ogbg-moltox21: 0.703381 test loss: 0.464966
[Epoch 114; Iter    19/  157] train: loss: 0.0545034
[Epoch 114; Iter    49/  157] train: loss: 0.0514046
[Epoch 114; Iter    79/  157] train: loss: 0.0464924
[Epoch 114; Iter   109/  157] train: loss: 0.0646830
[Epoch 114; Iter   139/  157] train: loss: 0.0336827
[Epoch 114] ogbg-moltox21: 0.713474 val loss: 0.475530
[Epoch 114] ogbg-moltox21: 0.705846 test loss: 0.488161
[Epoch 115; Iter    12/  157] train: loss: 0.0440353
[Epoch 115; Iter    42/  157] train: loss: 0.0315679
[Epoch 115; Iter    72/  157] train: loss: 0.0491919
[Epoch 115; Iter   102/  157] train: loss: 0.0630504
[Epoch 115; Iter   132/  157] train: loss: 0.0388048
[Epoch 115] ogbg-moltox21: 0.711774 val loss: 0.560974
[Epoch 115] ogbg-moltox21: 0.700717 test loss: 0.482642
[Epoch 116; Iter     5/  157] train: loss: 0.0320482
[Epoch 116; Iter    35/  157] train: loss: 0.0461731
[Epoch 116; Iter    65/  157] train: loss: 0.0418503
[Epoch 116; Iter    95/  157] train: loss: 0.0963307
[Epoch 116; Iter   125/  157] train: loss: 0.0879914
[Epoch 116; Iter   155/  157] train: loss: 0.0279144
[Epoch 116] ogbg-moltox21: 0.707059 val loss: 0.480499
[Epoch 116] ogbg-moltox21: 0.696330 test loss: 0.492345
[Epoch 117; Iter    28/  157] train: loss: 0.0300673
[Epoch 117; Iter    58/  157] train: loss: 0.0270988
[Epoch 117; Iter    88/  157] train: loss: 0.0184964
[Epoch 117; Iter   118/  157] train: loss: 0.0309321
[Epoch 117; Iter   148/  157] train: loss: 0.0345493
[Epoch 117] ogbg-moltox21: 0.710735 val loss: 0.585017
[Epoch 117] ogbg-moltox21: 0.704222 test loss: 0.498245
[Epoch 118; Iter    21/  157] train: loss: 0.0387890
[Epoch 118; Iter    51/  157] train: loss: 0.0283054
[Epoch 118; Iter    81/  157] train: loss: 0.0546577
[Epoch 118; Iter   111/  157] train: loss: 0.0319651
[Epoch 118; Iter   141/  157] train: loss: 0.0356159
[Epoch 118] ogbg-moltox21: 0.710118 val loss: 0.520862
[Epoch 118] ogbg-moltox21: 0.705304 test loss: 0.493143
[Epoch 119; Iter    14/  157] train: loss: 0.0238121
[Epoch 119; Iter    44/  157] train: loss: 0.0557283
[Epoch 119; Iter    74/  157] train: loss: 0.0222215
[Epoch 119; Iter   104/  157] train: loss: 0.0588017
[Epoch 119; Iter   134/  157] train: loss: 0.0779993
[Epoch 119] ogbg-moltox21: 0.713017 val loss: 0.488953
[Epoch 119] ogbg-moltox21: 0.705632 test loss: 0.495250
[Epoch 120; Iter     7/  157] train: loss: 0.0749275
[Epoch 120; Iter    37/  157] train: loss: 0.0336743
[Epoch 120; Iter    67/  157] train: loss: 0.0495619
[Epoch 120; Iter    97/  157] train: loss: 0.0479576
[Epoch 120; Iter   127/  157] train: loss: 0.0520698
[Epoch 120; Iter   157/  157] train: loss: 0.0326639
[Epoch 120] ogbg-moltox21: 0.711148 val loss: 0.498559
[Epoch 120] ogbg-moltox21: 0.705248 test loss: 0.506321
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 40.
Statistics on  val_best_checkpoint
mean_pred: -3.3127503395080566
std_pred: 2.4342153072357178
mean_targets: nan
std_targets: nan
prcauc: 0.3206598871866792
rocauc: 0.791625613663645
ogbg-moltox21: 0.791625613663645
OGBNanLabelBCEWithLogitsLoss: 0.30477011681727645
Statistics on  test
mean_pred: -3.0105841159820557
std_pred: 5.252148151397705
mean_targets: nan
std_targets: nan
prcauc: 0.27042798654420624
rocauc: 0.7610507565283782
ogbg-moltox21: 0.7610507565283782
OGBNanLabelBCEWithLogitsLoss: 0.5144959106197897
Statistics on  train
mean_pred: -4.094477653503418
std_pred: 2.801074981689453
mean_targets: nan
std_targets: nan
prcauc: 0.5624522369235229
rocauc: 0.911908280206663
ogbg-moltox21: 0.911908280206663
OGBNanLabelBCEWithLogitsLoss: 0.14197659967051948
OGBNanLabelBCEWithLogitsLoss: 0.47572491831093466
Statistics on  train
mean_pred: -4.2921319007873535
std_pred: 3.158281087875366
mean_targets: nan
std_targets: nan
prcauc: 0.633855978051195
rocauc: 0.9320369299086125
ogbg-moltox21: 0.9320369299086125
OGBNanLabelBCEWithLogitsLoss: 0.14789670943074926
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 101; Iter   140/  157] train: loss: 0.0805982
[Epoch 101] ogbg-moltox21: 0.733454 val loss: 0.455470
[Epoch 101] ogbg-moltox21: 0.716635 test loss: 0.441445
[Epoch 102; Iter    13/  157] train: loss: 0.0590006
[Epoch 102; Iter    43/  157] train: loss: 0.0391454
[Epoch 102; Iter    73/  157] train: loss: 0.0501947
[Epoch 102; Iter   103/  157] train: loss: 0.0443540
[Epoch 102; Iter   133/  157] train: loss: 0.0619207
[Epoch 102] ogbg-moltox21: 0.729622 val loss: 0.470167
[Epoch 102] ogbg-moltox21: 0.714312 test loss: 0.439171
[Epoch 103; Iter     6/  157] train: loss: 0.0477463
[Epoch 103; Iter    36/  157] train: loss: 0.0550295
[Epoch 103; Iter    66/  157] train: loss: 0.0578247
[Epoch 103; Iter    96/  157] train: loss: 0.0279186
[Epoch 103; Iter   126/  157] train: loss: 0.0332269
[Epoch 103; Iter   156/  157] train: loss: 0.0534795
[Epoch 103] ogbg-moltox21: 0.729736 val loss: 0.453216
[Epoch 103] ogbg-moltox21: 0.714571 test loss: 0.442226
[Epoch 104; Iter    29/  157] train: loss: 0.0357370
[Epoch 104; Iter    59/  157] train: loss: 0.0302301
[Epoch 104; Iter    89/  157] train: loss: 0.0311048
[Epoch 104; Iter   119/  157] train: loss: 0.0410682
[Epoch 104; Iter   149/  157] train: loss: 0.0274691
[Epoch 104] ogbg-moltox21: 0.727035 val loss: 0.456282
[Epoch 104] ogbg-moltox21: 0.714926 test loss: 0.452248
[Epoch 105; Iter    22/  157] train: loss: 0.0345436
[Epoch 105; Iter    52/  157] train: loss: 0.0647052
[Epoch 105; Iter    82/  157] train: loss: 0.0298145
[Epoch 105; Iter   112/  157] train: loss: 0.0390084
[Epoch 105; Iter   142/  157] train: loss: 0.0570109
[Epoch 105] ogbg-moltox21: 0.731491 val loss: 0.452996
[Epoch 105] ogbg-moltox21: 0.716940 test loss: 0.439722
[Epoch 106; Iter    15/  157] train: loss: 0.0486544
[Epoch 106; Iter    45/  157] train: loss: 0.0495040
[Epoch 106; Iter    75/  157] train: loss: 0.0368066
[Epoch 106; Iter   105/  157] train: loss: 0.0407441
[Epoch 106; Iter   135/  157] train: loss: 0.0336782
[Epoch 106] ogbg-moltox21: 0.729735 val loss: 0.635009
[Epoch 106] ogbg-moltox21: 0.713750 test loss: 0.450271
[Epoch 107; Iter     8/  157] train: loss: 0.0425238
[Epoch 107; Iter    38/  157] train: loss: 0.0362750
[Epoch 107; Iter    68/  157] train: loss: 0.0305603
[Epoch 107; Iter    98/  157] train: loss: 0.0602635
[Epoch 107; Iter   128/  157] train: loss: 0.0291666
[Epoch 107] ogbg-moltox21: 0.730300 val loss: 0.456730
[Epoch 107] ogbg-moltox21: 0.714664 test loss: 0.458213
[Epoch 108; Iter     1/  157] train: loss: 0.0502855
[Epoch 108; Iter    31/  157] train: loss: 0.0276889
[Epoch 108; Iter    61/  157] train: loss: 0.0443061
[Epoch 108; Iter    91/  157] train: loss: 0.0225820
[Epoch 108; Iter   121/  157] train: loss: 0.0790867
[Epoch 108; Iter   151/  157] train: loss: 0.0494599
[Epoch 108] ogbg-moltox21: 0.731821 val loss: 0.469395
[Epoch 108] ogbg-moltox21: 0.716842 test loss: 0.437138
[Epoch 109; Iter    24/  157] train: loss: 0.0626268
[Epoch 109; Iter    54/  157] train: loss: 0.0457485
[Epoch 109; Iter    84/  157] train: loss: 0.0495191
[Epoch 109; Iter   114/  157] train: loss: 0.0441227
[Epoch 109; Iter   144/  157] train: loss: 0.0445968
[Epoch 109] ogbg-moltox21: 0.727455 val loss: 0.641833
[Epoch 109] ogbg-moltox21: 0.713176 test loss: 0.460693
[Epoch 110; Iter    17/  157] train: loss: 0.0490065
[Epoch 110; Iter    47/  157] train: loss: 0.0566668
[Epoch 110; Iter    77/  157] train: loss: 0.0370668
[Epoch 110; Iter   107/  157] train: loss: 0.0734625
[Epoch 110; Iter   137/  157] train: loss: 0.0771397
[Epoch 110] ogbg-moltox21: 0.726962 val loss: 0.515899
[Epoch 110] ogbg-moltox21: 0.712243 test loss: 0.457911
[Epoch 111; Iter    10/  157] train: loss: 0.0175659
[Epoch 111; Iter    40/  157] train: loss: 0.0290514
[Epoch 111; Iter    70/  157] train: loss: 0.0462292
[Epoch 111; Iter   100/  157] train: loss: 0.0626864
[Epoch 111; Iter   130/  157] train: loss: 0.0362307
[Epoch 111] ogbg-moltox21: 0.722975 val loss: 0.676601
[Epoch 111] ogbg-moltox21: 0.709503 test loss: 0.470402
[Epoch 112; Iter     3/  157] train: loss: 0.0337336
[Epoch 112; Iter    33/  157] train: loss: 0.0549299
[Epoch 112; Iter    63/  157] train: loss: 0.0252966
[Epoch 112; Iter    93/  157] train: loss: 0.0546075
[Epoch 112; Iter   123/  157] train: loss: 0.0290172
[Epoch 112; Iter   153/  157] train: loss: 0.0549311
[Epoch 112] ogbg-moltox21: 0.725051 val loss: 0.516339
[Epoch 112] ogbg-moltox21: 0.715775 test loss: 0.444700
[Epoch 113; Iter    26/  157] train: loss: 0.0828809
[Epoch 113; Iter    56/  157] train: loss: 0.0426838
[Epoch 113; Iter    86/  157] train: loss: 0.0744874
[Epoch 113; Iter   116/  157] train: loss: 0.0308758
[Epoch 113; Iter   146/  157] train: loss: 0.0717511
[Epoch 113] ogbg-moltox21: 0.727371 val loss: 0.710963
[Epoch 113] ogbg-moltox21: 0.715229 test loss: 0.497747
[Epoch 114; Iter    19/  157] train: loss: 0.0529630
[Epoch 114; Iter    49/  157] train: loss: 0.0883782
[Epoch 114; Iter    79/  157] train: loss: 0.0272517
[Epoch 114; Iter   109/  157] train: loss: 0.0279144
[Epoch 114; Iter   139/  157] train: loss: 0.0267836
[Epoch 114] ogbg-moltox21: 0.734454 val loss: 0.447808
[Epoch 114] ogbg-moltox21: 0.716010 test loss: 0.445767
[Epoch 115; Iter    12/  157] train: loss: 0.0324118
[Epoch 115; Iter    42/  157] train: loss: 0.0565468
[Epoch 115; Iter    72/  157] train: loss: 0.0609223
[Epoch 115; Iter   102/  157] train: loss: 0.0684018
[Epoch 115; Iter   132/  157] train: loss: 0.0440491
[Epoch 115] ogbg-moltox21: 0.723452 val loss: 0.471354
[Epoch 115] ogbg-moltox21: 0.710393 test loss: 0.459124
[Epoch 116; Iter     5/  157] train: loss: 0.0268309
[Epoch 116; Iter    35/  157] train: loss: 0.0379834
[Epoch 116; Iter    65/  157] train: loss: 0.0364061
[Epoch 116; Iter    95/  157] train: loss: 0.0471058
[Epoch 116; Iter   125/  157] train: loss: 0.0413149
[Epoch 116; Iter   155/  157] train: loss: 0.0361207
[Epoch 116] ogbg-moltox21: 0.727922 val loss: 0.455118
[Epoch 116] ogbg-moltox21: 0.710951 test loss: 0.457714
[Epoch 117; Iter    28/  157] train: loss: 0.0497256
[Epoch 117; Iter    58/  157] train: loss: 0.0897292
[Epoch 117; Iter    88/  157] train: loss: 0.0720080
[Epoch 117; Iter   118/  157] train: loss: 0.0696537
[Epoch 117; Iter   148/  157] train: loss: 0.0598462
[Epoch 117] ogbg-moltox21: 0.727643 val loss: 0.465591
[Epoch 117] ogbg-moltox21: 0.713618 test loss: 0.454008
[Epoch 118; Iter    21/  157] train: loss: 0.0455425
[Epoch 118; Iter    51/  157] train: loss: 0.0443814
[Epoch 118; Iter    81/  157] train: loss: 0.0392600
[Epoch 118; Iter   111/  157] train: loss: 0.0500935
[Epoch 118; Iter   141/  157] train: loss: 0.0506712
[Epoch 118] ogbg-moltox21: 0.725433 val loss: 0.503961
[Epoch 118] ogbg-moltox21: 0.713008 test loss: 0.451563
[Epoch 119; Iter    14/  157] train: loss: 0.0312766
[Epoch 119; Iter    44/  157] train: loss: 0.0482673
[Epoch 119; Iter    74/  157] train: loss: 0.0231413
[Epoch 119; Iter   104/  157] train: loss: 0.0591811
[Epoch 119; Iter   134/  157] train: loss: 0.0415890
[Epoch 119] ogbg-moltox21: 0.724525 val loss: 0.679826
[Epoch 119] ogbg-moltox21: 0.710781 test loss: 0.467627
[Epoch 120; Iter     7/  157] train: loss: 0.0343017
[Epoch 120; Iter    37/  157] train: loss: 0.0427862
[Epoch 120; Iter    67/  157] train: loss: 0.0397119
[Epoch 120; Iter    97/  157] train: loss: 0.0247589
[Epoch 120; Iter   127/  157] train: loss: 0.0408617
[Epoch 120; Iter   157/  157] train: loss: 0.0703143
[Epoch 120] ogbg-moltox21: 0.726406 val loss: 0.633566
[Epoch 120] ogbg-moltox21: 0.710586 test loss: 0.478116
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 25.
Statistics on  val_best_checkpoint
mean_pred: -2.928868532180786
std_pred: 2.224808692932129
mean_targets: nan
std_targets: nan
prcauc: 0.3119510540158185
rocauc: 0.7721393524735761
ogbg-moltox21: 0.7721393524735761
OGBNanLabelBCEWithLogitsLoss: 0.29463195280646376
Statistics on  test
mean_pred: -2.7416088581085205
std_pred: 2.3237082958221436
mean_targets: nan
std_targets: nan
prcauc: 0.27420435950973515
rocauc: 0.7549505068662407
ogbg-moltox21: 0.7549505068662407
OGBNanLabelBCEWithLogitsLoss: 0.3291673520404213
Statistics on  train
mean_pred: -3.9550278186798096
std_pred: 2.056199073791504
mean_targets: nan
std_targets: nan
prcauc: 0.5307881325331293
rocauc: 0.8979163189061198
ogbg-moltox21: 0.8979163189061198
OGBNanLabelBCEWithLogitsLoss: 0.14144211471270604
All runs completed.
[Epoch 99; Iter   128/  209] train: loss: 0.0441263
[Epoch 99; Iter   158/  209] train: loss: 0.0556908
[Epoch 99; Iter   188/  209] train: loss: 0.0675666
[Epoch 99] ogbg-moltox21: 0.771362 val loss: 0.375980
[Epoch 99] ogbg-moltox21: 0.742347 test loss: 0.406782
[Epoch 100; Iter     9/  209] train: loss: 0.0463792
[Epoch 100; Iter    39/  209] train: loss: 0.0560691
[Epoch 100; Iter    69/  209] train: loss: 0.0996337
[Epoch 100; Iter    99/  209] train: loss: 0.0576895
[Epoch 100; Iter   129/  209] train: loss: 0.0498974
[Epoch 100; Iter   159/  209] train: loss: 0.0344322
[Epoch 100; Iter   189/  209] train: loss: 0.0482664
[Epoch 100] ogbg-moltox21: 0.773850 val loss: 0.373836
[Epoch 100] ogbg-moltox21: 0.745053 test loss: 0.402341
[Epoch 101; Iter    10/  209] train: loss: 0.0887212
[Epoch 101; Iter    40/  209] train: loss: 0.0456000
[Epoch 101; Iter    70/  209] train: loss: 0.0590708
[Epoch 101; Iter   100/  209] train: loss: 0.0459037
[Epoch 101; Iter   130/  209] train: loss: 0.0560848
[Epoch 101; Iter   160/  209] train: loss: 0.0790376
[Epoch 101; Iter   190/  209] train: loss: 0.0612523
[Epoch 101] ogbg-moltox21: 0.777634 val loss: 0.377150
[Epoch 101] ogbg-moltox21: 0.747896 test loss: 0.410043
[Epoch 102; Iter    11/  209] train: loss: 0.0374726
[Epoch 102; Iter    41/  209] train: loss: 0.0651359
[Epoch 102; Iter    71/  209] train: loss: 0.0734626
[Epoch 102; Iter   101/  209] train: loss: 0.0797047
[Epoch 102; Iter   131/  209] train: loss: 0.0477794
[Epoch 102; Iter   161/  209] train: loss: 0.0800012
[Epoch 102; Iter   191/  209] train: loss: 0.0545298
[Epoch 102] ogbg-moltox21: 0.770457 val loss: 0.376718
[Epoch 102] ogbg-moltox21: 0.744835 test loss: 0.404013
[Epoch 103; Iter    12/  209] train: loss: 0.0470392
[Epoch 103; Iter    42/  209] train: loss: 0.0569607
[Epoch 103; Iter    72/  209] train: loss: 0.0584774
[Epoch 103; Iter   102/  209] train: loss: 0.0395738
[Epoch 103; Iter   132/  209] train: loss: 0.0916698
[Epoch 103; Iter   162/  209] train: loss: 0.0646775
[Epoch 103; Iter   192/  209] train: loss: 0.0894912
[Epoch 103] ogbg-moltox21: 0.770065 val loss: 0.393506
[Epoch 103] ogbg-moltox21: 0.742894 test loss: 0.423611
[Epoch 104; Iter    13/  209] train: loss: 0.1038368
[Epoch 104; Iter    43/  209] train: loss: 0.0497360
[Epoch 104; Iter    73/  209] train: loss: 0.0507033
[Epoch 104; Iter   103/  209] train: loss: 0.0671088
[Epoch 104; Iter   133/  209] train: loss: 0.0501683
[Epoch 104; Iter   163/  209] train: loss: 0.1236537
[Epoch 104; Iter   193/  209] train: loss: 0.0516699
[Epoch 104] ogbg-moltox21: 0.769666 val loss: 0.387526
[Epoch 104] ogbg-moltox21: 0.746841 test loss: 0.430868
[Epoch 105; Iter    14/  209] train: loss: 0.0361839
[Epoch 105; Iter    44/  209] train: loss: 0.0619164
[Epoch 105; Iter    74/  209] train: loss: 0.0635683
[Epoch 105; Iter   104/  209] train: loss: 0.0597692
[Epoch 105; Iter   134/  209] train: loss: 0.0335892
[Epoch 105; Iter   164/  209] train: loss: 0.1066915
[Epoch 105; Iter   194/  209] train: loss: 0.0636868
[Epoch 105] ogbg-moltox21: 0.768559 val loss: 0.373784
[Epoch 105] ogbg-moltox21: 0.748083 test loss: 0.403156
[Epoch 106; Iter    15/  209] train: loss: 0.0434563
[Epoch 106; Iter    45/  209] train: loss: 0.0441010
[Epoch 106; Iter    75/  209] train: loss: 0.0525239
[Epoch 106; Iter   105/  209] train: loss: 0.0647810
[Epoch 106; Iter   135/  209] train: loss: 0.0609816
[Epoch 106; Iter   165/  209] train: loss: 0.0596300
[Epoch 106; Iter   195/  209] train: loss: 0.0399477
[Epoch 106] ogbg-moltox21: 0.769267 val loss: 0.386608
[Epoch 106] ogbg-moltox21: 0.747822 test loss: 0.418260
[Epoch 107; Iter    16/  209] train: loss: 0.0591182
[Epoch 107; Iter    46/  209] train: loss: 0.0681483
[Epoch 107; Iter    76/  209] train: loss: 0.0435285
[Epoch 107; Iter   106/  209] train: loss: 0.0737525
[Epoch 107; Iter   136/  209] train: loss: 0.0564752
[Epoch 107; Iter   166/  209] train: loss: 0.0522679
[Epoch 107; Iter   196/  209] train: loss: 0.0736990
[Epoch 107] ogbg-moltox21: 0.768918 val loss: 0.391328
[Epoch 107] ogbg-moltox21: 0.743029 test loss: 0.425352
[Epoch 108; Iter    17/  209] train: loss: 0.0449586
[Epoch 108; Iter    47/  209] train: loss: 0.0533151
[Epoch 108; Iter    77/  209] train: loss: 0.0547003
[Epoch 108; Iter   107/  209] train: loss: 0.0643482
[Epoch 108; Iter   137/  209] train: loss: 0.0618367
[Epoch 108; Iter   167/  209] train: loss: 0.0541999
[Epoch 108; Iter   197/  209] train: loss: 0.0650458
[Epoch 108] ogbg-moltox21: 0.766125 val loss: 0.388035
[Epoch 108] ogbg-moltox21: 0.735836 test loss: 0.444097
[Epoch 109; Iter    18/  209] train: loss: 0.0343476
[Epoch 109; Iter    48/  209] train: loss: 0.0459751
[Epoch 109; Iter    78/  209] train: loss: 0.0360144
[Epoch 109; Iter   108/  209] train: loss: 0.0790827
[Epoch 109; Iter   138/  209] train: loss: 0.0610106
[Epoch 109; Iter   168/  209] train: loss: 0.0862281
[Epoch 109; Iter   198/  209] train: loss: 0.0508916
[Epoch 109] ogbg-moltox21: 0.770647 val loss: 0.384400
[Epoch 109] ogbg-moltox21: 0.740018 test loss: 0.439492
[Epoch 110; Iter    19/  209] train: loss: 0.0637634
[Epoch 110; Iter    49/  209] train: loss: 0.0535110
[Epoch 110; Iter    79/  209] train: loss: 0.0800962
[Epoch 110; Iter   109/  209] train: loss: 0.0443691
[Epoch 110; Iter   139/  209] train: loss: 0.0755055
[Epoch 110; Iter   169/  209] train: loss: 0.0711369
[Epoch 110; Iter   199/  209] train: loss: 0.0744185
[Epoch 110] ogbg-moltox21: 0.769882 val loss: 0.396889
[Epoch 110] ogbg-moltox21: 0.737801 test loss: 0.482174
[Epoch 111; Iter    20/  209] train: loss: 0.0828247
[Epoch 111; Iter    50/  209] train: loss: 0.0708097
[Epoch 111; Iter    80/  209] train: loss: 0.0639625
[Epoch 111; Iter   110/  209] train: loss: 0.0460609
[Epoch 111; Iter   140/  209] train: loss: 0.0924375
[Epoch 111; Iter   170/  209] train: loss: 0.0481960
[Epoch 111; Iter   200/  209] train: loss: 0.0544476
[Epoch 111] ogbg-moltox21: 0.768777 val loss: 0.405410
[Epoch 111] ogbg-moltox21: 0.741358 test loss: 0.444089
[Epoch 112; Iter    21/  209] train: loss: 0.0585522
[Epoch 112; Iter    51/  209] train: loss: 0.1014652
[Epoch 112; Iter    81/  209] train: loss: 0.0540382
[Epoch 112; Iter   111/  209] train: loss: 0.0440389
[Epoch 112; Iter   141/  209] train: loss: 0.0361991
[Epoch 112; Iter   171/  209] train: loss: 0.0511475
[Epoch 112; Iter   201/  209] train: loss: 0.0432682
[Epoch 112] ogbg-moltox21: 0.767769 val loss: 0.397750
[Epoch 112] ogbg-moltox21: 0.741814 test loss: 0.424808
[Epoch 113; Iter    22/  209] train: loss: 0.0709133
[Epoch 113; Iter    52/  209] train: loss: 0.0773340
[Epoch 113; Iter    82/  209] train: loss: 0.0752798
[Epoch 113; Iter   112/  209] train: loss: 0.0777504
[Epoch 113; Iter   142/  209] train: loss: 0.0873265
[Epoch 113; Iter   172/  209] train: loss: 0.0938323
[Epoch 113; Iter   202/  209] train: loss: 0.0642778
[Epoch 113] ogbg-moltox21: 0.766212 val loss: 0.393024
[Epoch 113] ogbg-moltox21: 0.742743 test loss: 0.426144
[Epoch 114; Iter    23/  209] train: loss: 0.0535347
[Epoch 114; Iter    53/  209] train: loss: 0.0310354
[Epoch 114; Iter    83/  209] train: loss: 0.0536493
[Epoch 114; Iter   113/  209] train: loss: 0.0513067
[Epoch 114; Iter   143/  209] train: loss: 0.0625342
[Epoch 114; Iter   173/  209] train: loss: 0.0544604
[Epoch 114; Iter   203/  209] train: loss: 0.0700343
[Epoch 114] ogbg-moltox21: 0.766613 val loss: 0.397102
[Epoch 114] ogbg-moltox21: 0.741606 test loss: 0.431012
[Epoch 115; Iter    24/  209] train: loss: 0.0655766
[Epoch 115; Iter    54/  209] train: loss: 0.0834379
[Epoch 115; Iter    84/  209] train: loss: 0.0809078
[Epoch 115; Iter   114/  209] train: loss: 0.0468533
[Epoch 115; Iter   144/  209] train: loss: 0.0754743
[Epoch 115; Iter   174/  209] train: loss: 0.0949403
[Epoch 115; Iter   204/  209] train: loss: 0.0579465
[Epoch 115] ogbg-moltox21: 0.767767 val loss: 0.396692
[Epoch 115] ogbg-moltox21: 0.738398 test loss: 0.435728
[Epoch 116; Iter    25/  209] train: loss: 0.1182524
[Epoch 116; Iter    55/  209] train: loss: 0.0424018
[Epoch 116; Iter    85/  209] train: loss: 0.0417413
[Epoch 116; Iter   115/  209] train: loss: 0.0353635
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 109] ogbg-moltox21: 0.713904 test loss: 0.433534
[Epoch 110; Iter     3/  183] train: loss: 0.0446293
[Epoch 110; Iter    33/  183] train: loss: 0.1139466
[Epoch 110; Iter    63/  183] train: loss: 0.0343214
[Epoch 110; Iter    93/  183] train: loss: 0.0570236
[Epoch 110; Iter   123/  183] train: loss: 0.0222367
[Epoch 110; Iter   153/  183] train: loss: 0.0821146
[Epoch 110; Iter   183/  183] train: loss: 0.0437779
[Epoch 110] ogbg-moltox21: 0.731275 val loss: 0.414843
[Epoch 110] ogbg-moltox21: 0.712713 test loss: 0.445900
[Epoch 111; Iter    30/  183] train: loss: 0.0472866
[Epoch 111; Iter    60/  183] train: loss: 0.0311241
[Epoch 111; Iter    90/  183] train: loss: 0.0468769
[Epoch 111; Iter   120/  183] train: loss: 0.0545366
[Epoch 111; Iter   150/  183] train: loss: 0.0538308
[Epoch 111; Iter   180/  183] train: loss: 0.0733308
[Epoch 111] ogbg-moltox21: 0.734134 val loss: 0.416677
[Epoch 111] ogbg-moltox21: 0.715760 test loss: 0.443278
[Epoch 112; Iter    27/  183] train: loss: 0.0529271
[Epoch 112; Iter    57/  183] train: loss: 0.0315156
[Epoch 112; Iter    87/  183] train: loss: 0.0546325
[Epoch 112; Iter   117/  183] train: loss: 0.0783365
[Epoch 112; Iter   147/  183] train: loss: 0.0302508
[Epoch 112; Iter   177/  183] train: loss: 0.0408138
[Epoch 112] ogbg-moltox21: 0.732620 val loss: 0.416130
[Epoch 112] ogbg-moltox21: 0.711221 test loss: 0.440849
[Epoch 113; Iter    24/  183] train: loss: 0.1063280
[Epoch 113; Iter    54/  183] train: loss: 0.0472951
[Epoch 113; Iter    84/  183] train: loss: 0.0513648
[Epoch 113; Iter   114/  183] train: loss: 0.0564343
[Epoch 113; Iter   144/  183] train: loss: 0.0630881
[Epoch 113; Iter   174/  183] train: loss: 0.0472824
[Epoch 113] ogbg-moltox21: 0.733785 val loss: 0.418143
[Epoch 113] ogbg-moltox21: 0.713178 test loss: 0.438908
[Epoch 114; Iter    21/  183] train: loss: 0.0475035
[Epoch 114; Iter    51/  183] train: loss: 0.0514222
[Epoch 114; Iter    81/  183] train: loss: 0.0311209
[Epoch 114; Iter   111/  183] train: loss: 0.0321113
[Epoch 114; Iter   141/  183] train: loss: 0.0700578
[Epoch 114; Iter   171/  183] train: loss: 0.0548401
[Epoch 114] ogbg-moltox21: 0.730956 val loss: 0.418934
[Epoch 114] ogbg-moltox21: 0.714465 test loss: 0.439843
[Epoch 115; Iter    18/  183] train: loss: 0.0500805
[Epoch 115; Iter    48/  183] train: loss: 0.0474193
[Epoch 115; Iter    78/  183] train: loss: 0.0519163
[Epoch 115; Iter   108/  183] train: loss: 0.0633084
[Epoch 115; Iter   138/  183] train: loss: 0.0339921
[Epoch 115; Iter   168/  183] train: loss: 0.0462045
[Epoch 115] ogbg-moltox21: 0.729876 val loss: 0.432558
[Epoch 115] ogbg-moltox21: 0.713067 test loss: 0.456079
[Epoch 116; Iter    15/  183] train: loss: 0.0306791
[Epoch 116; Iter    45/  183] train: loss: 0.0475436
[Epoch 116; Iter    75/  183] train: loss: 0.0690736
[Epoch 116; Iter   105/  183] train: loss: 0.0721998
[Epoch 116; Iter   135/  183] train: loss: 0.0365364
[Epoch 116; Iter   165/  183] train: loss: 0.0533822
[Epoch 116] ogbg-moltox21: 0.732647 val loss: 0.429157
[Epoch 116] ogbg-moltox21: 0.705895 test loss: 0.457950
[Epoch 117; Iter    12/  183] train: loss: 0.0407025
[Epoch 117; Iter    42/  183] train: loss: 0.0434102
[Epoch 117; Iter    72/  183] train: loss: 0.0576954
[Epoch 117; Iter   102/  183] train: loss: 0.0313905
[Epoch 117; Iter   132/  183] train: loss: 0.0768694
[Epoch 117; Iter   162/  183] train: loss: 0.0868939
[Epoch 117] ogbg-moltox21: 0.731488 val loss: 0.427050
[Epoch 117] ogbg-moltox21: 0.712081 test loss: 0.448858
[Epoch 118; Iter     9/  183] train: loss: 0.0350871
[Epoch 118; Iter    39/  183] train: loss: 0.0425959
[Epoch 118; Iter    69/  183] train: loss: 0.0354447
[Epoch 118; Iter    99/  183] train: loss: 0.0452856
[Epoch 118; Iter   129/  183] train: loss: 0.0377708
[Epoch 118; Iter   159/  183] train: loss: 0.0721364
[Epoch 118] ogbg-moltox21: 0.733907 val loss: 0.431146
[Epoch 118] ogbg-moltox21: 0.707961 test loss: 0.453810
[Epoch 119; Iter     6/  183] train: loss: 0.0358271
[Epoch 119; Iter    36/  183] train: loss: 0.0240675
[Epoch 119; Iter    66/  183] train: loss: 0.0469746
[Epoch 119; Iter    96/  183] train: loss: 0.0353984
[Epoch 119; Iter   126/  183] train: loss: 0.0636668
[Epoch 119; Iter   156/  183] train: loss: 0.0501911
[Epoch 119] ogbg-moltox21: 0.736001 val loss: 0.440244
[Epoch 119] ogbg-moltox21: 0.715410 test loss: 0.467637
[Epoch 120; Iter     3/  183] train: loss: 0.0478573
[Epoch 120; Iter    33/  183] train: loss: 0.0372877
[Epoch 120; Iter    63/  183] train: loss: 0.0526062
[Epoch 120; Iter    93/  183] train: loss: 0.0453084
[Epoch 120; Iter   123/  183] train: loss: 0.0529893
[Epoch 120; Iter   153/  183] train: loss: 0.0541267
[Epoch 120; Iter   183/  183] train: loss: 0.0355506
[Epoch 120] ogbg-moltox21: 0.733358 val loss: 0.432396
[Epoch 120] ogbg-moltox21: 0.714517 test loss: 0.452747
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 46.
Statistics on  val_best_checkpoint
mean_pred: -3.527470588684082
std_pred: 2.522080659866333
mean_targets: nan
std_targets: nan
prcauc: 0.3523970923031949
rocauc: 0.7794639425456396
ogbg-moltox21: 0.7794639425456396
OGBNanLabelBCEWithLogitsLoss: 0.27589989081025124
Statistics on  test
mean_pred: -3.520409345626831
std_pred: 2.695678234100342
mean_targets: nan
std_targets: nan
prcauc: 0.3390419454546507
rocauc: 0.7504863236210335
ogbg-moltox21: 0.7504863236210335
OGBNanLabelBCEWithLogitsLoss: 0.2956128128804266
Statistics on  train
mean_pred: -4.318912029266357
std_pred: 2.652463674545288
mean_targets: nan
std_targets: nan
prcauc: 0.7037654484322361
rocauc: 0.9387729754780647
ogbg-moltox21: 0.9387729754780647
OGBNanLabelBCEWithLogitsLoss: 0.11696615355099485
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 99; Iter   128/  209] train: loss: 0.0441587
[Epoch 99; Iter   158/  209] train: loss: 0.0627399
[Epoch 99; Iter   188/  209] train: loss: 0.0769472
[Epoch 99] ogbg-moltox21: 0.776178 val loss: 0.351517
[Epoch 99] ogbg-moltox21: 0.742465 test loss: 0.367470
[Epoch 100; Iter     9/  209] train: loss: 0.0665328
[Epoch 100; Iter    39/  209] train: loss: 0.0700250
[Epoch 100; Iter    69/  209] train: loss: 0.0937028
[Epoch 100; Iter    99/  209] train: loss: 0.0551070
[Epoch 100; Iter   129/  209] train: loss: 0.0803414
[Epoch 100; Iter   159/  209] train: loss: 0.0755508
[Epoch 100; Iter   189/  209] train: loss: 0.0714462
[Epoch 100] ogbg-moltox21: 0.770807 val loss: 0.351826
[Epoch 100] ogbg-moltox21: 0.737420 test loss: 0.381128
[Epoch 101; Iter    10/  209] train: loss: 0.0491738
[Epoch 101; Iter    40/  209] train: loss: 0.0902198
[Epoch 101; Iter    70/  209] train: loss: 0.0587606
[Epoch 101; Iter   100/  209] train: loss: 0.0595682
[Epoch 101; Iter   130/  209] train: loss: 0.0351642
[Epoch 101; Iter   160/  209] train: loss: 0.0305823
[Epoch 101; Iter   190/  209] train: loss: 0.0501512
[Epoch 101] ogbg-moltox21: 0.776588 val loss: 0.354394
[Epoch 101] ogbg-moltox21: 0.742926 test loss: 0.362100
[Epoch 102; Iter    11/  209] train: loss: 0.0516402
[Epoch 102; Iter    41/  209] train: loss: 0.0699681
[Epoch 102; Iter    71/  209] train: loss: 0.0343964
[Epoch 102; Iter   101/  209] train: loss: 0.0377688
[Epoch 102; Iter   131/  209] train: loss: 0.1119954
[Epoch 102; Iter   161/  209] train: loss: 0.0882464
[Epoch 102; Iter   191/  209] train: loss: 0.0452086
[Epoch 102] ogbg-moltox21: 0.776204 val loss: 0.353580
[Epoch 102] ogbg-moltox21: 0.744462 test loss: 0.379462
[Epoch 103; Iter    12/  209] train: loss: 0.0724503
[Epoch 103; Iter    42/  209] train: loss: 0.0566988
[Epoch 103; Iter    72/  209] train: loss: 0.0467517
[Epoch 103; Iter   102/  209] train: loss: 0.0472732
[Epoch 103; Iter   132/  209] train: loss: 0.0838247
[Epoch 103; Iter   162/  209] train: loss: 0.0553860
[Epoch 103; Iter   192/  209] train: loss: 0.0788756
[Epoch 103] ogbg-moltox21: 0.771232 val loss: 0.363657
[Epoch 103] ogbg-moltox21: 0.744469 test loss: 0.366643
[Epoch 104; Iter    13/  209] train: loss: 0.0512921
[Epoch 104; Iter    43/  209] train: loss: 0.0788246
[Epoch 104; Iter    73/  209] train: loss: 0.0410033
[Epoch 104; Iter   103/  209] train: loss: 0.0462980
[Epoch 104; Iter   133/  209] train: loss: 0.0613716
[Epoch 104; Iter   163/  209] train: loss: 0.0570497
[Epoch 104; Iter   193/  209] train: loss: 0.0852459
[Epoch 104] ogbg-moltox21: 0.771616 val loss: 0.369172
[Epoch 104] ogbg-moltox21: 0.741447 test loss: 0.376700
[Epoch 105; Iter    14/  209] train: loss: 0.0714449
[Epoch 105; Iter    44/  209] train: loss: 0.0994097
[Epoch 105; Iter    74/  209] train: loss: 0.0683637
[Epoch 105; Iter   104/  209] train: loss: 0.0392043
[Epoch 105; Iter   134/  209] train: loss: 0.0490029
[Epoch 105; Iter   164/  209] train: loss: 0.0526523
[Epoch 105; Iter   194/  209] train: loss: 0.0445407
[Epoch 105] ogbg-moltox21: 0.770840 val loss: 0.362975
[Epoch 105] ogbg-moltox21: 0.744286 test loss: 0.379416
[Epoch 106; Iter    15/  209] train: loss: 0.0434420
[Epoch 106; Iter    45/  209] train: loss: 0.0663174
[Epoch 106; Iter    75/  209] train: loss: 0.0509695
[Epoch 106; Iter   105/  209] train: loss: 0.1568085
[Epoch 106; Iter   135/  209] train: loss: 0.0526438
[Epoch 106; Iter   165/  209] train: loss: 0.0671387
[Epoch 106; Iter   195/  209] train: loss: 0.0360240
[Epoch 106] ogbg-moltox21: 0.767412 val loss: 0.365813
[Epoch 106] ogbg-moltox21: 0.743226 test loss: 0.369688
[Epoch 107; Iter    16/  209] train: loss: 0.0809484
[Epoch 107; Iter    46/  209] train: loss: 0.1061852
[Epoch 107; Iter    76/  209] train: loss: 0.0646984
[Epoch 107; Iter   106/  209] train: loss: 0.0417491
[Epoch 107; Iter   136/  209] train: loss: 0.0745104
[Epoch 107; Iter   166/  209] train: loss: 0.0628205
[Epoch 107; Iter   196/  209] train: loss: 0.0641983
[Epoch 107] ogbg-moltox21: 0.772561 val loss: 0.368446
[Epoch 107] ogbg-moltox21: 0.739839 test loss: 0.378215
[Epoch 108; Iter    17/  209] train: loss: 0.0750799
[Epoch 108; Iter    47/  209] train: loss: 0.0545920
[Epoch 108; Iter    77/  209] train: loss: 0.0657970
[Epoch 108; Iter   107/  209] train: loss: 0.1046040
[Epoch 108; Iter   137/  209] train: loss: 0.0483420
[Epoch 108; Iter   167/  209] train: loss: 0.0767315
[Epoch 108; Iter   197/  209] train: loss: 0.0752937
[Epoch 108] ogbg-moltox21: 0.765423 val loss: 0.366687
[Epoch 108] ogbg-moltox21: 0.741562 test loss: 0.375099
[Epoch 109; Iter    18/  209] train: loss: 0.0832451
[Epoch 109; Iter    48/  209] train: loss: 0.0617771
[Epoch 109; Iter    78/  209] train: loss: 0.0492008
[Epoch 109; Iter   108/  209] train: loss: 0.0794780
[Epoch 109; Iter   138/  209] train: loss: 0.0758737
[Epoch 109; Iter   168/  209] train: loss: 0.0750958
[Epoch 109; Iter   198/  209] train: loss: 0.0617084
[Epoch 109] ogbg-moltox21: 0.771835 val loss: 0.376174
[Epoch 109] ogbg-moltox21: 0.741809 test loss: 0.385484
[Epoch 110; Iter    19/  209] train: loss: 0.0706138
[Epoch 110; Iter    49/  209] train: loss: 0.0508039
[Epoch 110; Iter    79/  209] train: loss: 0.0688825
[Epoch 110; Iter   109/  209] train: loss: 0.0640657
[Epoch 110; Iter   139/  209] train: loss: 0.1005582
[Epoch 110; Iter   169/  209] train: loss: 0.0378611
[Epoch 110; Iter   199/  209] train: loss: 0.0677829
[Epoch 110] ogbg-moltox21: 0.767812 val loss: 0.364369
[Epoch 110] ogbg-moltox21: 0.738238 test loss: 0.373624
[Epoch 111; Iter    20/  209] train: loss: 0.1053819
[Epoch 111; Iter    50/  209] train: loss: 0.0405529
[Epoch 111; Iter    80/  209] train: loss: 0.0602944
[Epoch 111; Iter   110/  209] train: loss: 0.0905235
[Epoch 111; Iter   140/  209] train: loss: 0.0514609
[Epoch 111; Iter   170/  209] train: loss: 0.1106434
[Epoch 111; Iter   200/  209] train: loss: 0.0401308
[Epoch 111] ogbg-moltox21: 0.772097 val loss: 0.383042
[Epoch 111] ogbg-moltox21: 0.740234 test loss: 0.386578
[Epoch 112; Iter    21/  209] train: loss: 0.0575232
[Epoch 112; Iter    51/  209] train: loss: 0.0562587
[Epoch 112; Iter    81/  209] train: loss: 0.0557764
[Epoch 112; Iter   111/  209] train: loss: 0.0802493
[Epoch 112; Iter   141/  209] train: loss: 0.0411451
[Epoch 112; Iter   171/  209] train: loss: 0.0624177
[Epoch 112; Iter   201/  209] train: loss: 0.0604410
[Epoch 112] ogbg-moltox21: 0.769305 val loss: 0.373119
[Epoch 112] ogbg-moltox21: 0.736616 test loss: 0.398562
[Epoch 113; Iter    22/  209] train: loss: 0.0979690
[Epoch 113; Iter    52/  209] train: loss: 0.0478530
[Epoch 113; Iter    82/  209] train: loss: 0.0761964
[Epoch 113; Iter   112/  209] train: loss: 0.0744827
[Epoch 113; Iter   142/  209] train: loss: 0.0823886
[Epoch 113; Iter   172/  209] train: loss: 0.0610171
[Epoch 113; Iter   202/  209] train: loss: 0.0601926
[Epoch 113] ogbg-moltox21: 0.764225 val loss: 0.376083
[Epoch 113] ogbg-moltox21: 0.731179 test loss: 0.391229
[Epoch 114; Iter    23/  209] train: loss: 0.1390830
[Epoch 114; Iter    53/  209] train: loss: 0.0525924
[Epoch 114; Iter    83/  209] train: loss: 0.0761394
[Epoch 114; Iter   113/  209] train: loss: 0.0428763
[Epoch 114; Iter   143/  209] train: loss: 0.0623476
[Epoch 114; Iter   173/  209] train: loss: 0.0404544
[Epoch 114; Iter   203/  209] train: loss: 0.0735969
[Epoch 114] ogbg-moltox21: 0.766422 val loss: 0.377389
[Epoch 114] ogbg-moltox21: 0.738371 test loss: 0.389625
[Epoch 115; Iter    24/  209] train: loss: 0.0653644
[Epoch 115; Iter    54/  209] train: loss: 0.0416708
[Epoch 115; Iter    84/  209] train: loss: 0.0697174
[Epoch 115; Iter   114/  209] train: loss: 0.0322115
[Epoch 115; Iter   144/  209] train: loss: 0.0371240
[Epoch 115; Iter   174/  209] train: loss: 0.0755565
[Epoch 115; Iter   204/  209] train: loss: 0.0272353
[Epoch 115] ogbg-moltox21: 0.769461 val loss: 0.372841
[Epoch 115] ogbg-moltox21: 0.741883 test loss: 0.386638
[Epoch 116; Iter    25/  209] train: loss: 0.0697116
[Epoch 116; Iter    55/  209] train: loss: 0.0458352
[Epoch 116; Iter    85/  209] train: loss: 0.0555013
[Epoch 116; Iter   115/  209] train: loss: 0.0452338
[Epoch 109] ogbg-moltox21: 0.700601 test loss: 0.474277
[Epoch 110; Iter     3/  183] train: loss: 0.0426543
[Epoch 110; Iter    33/  183] train: loss: 0.0812378
[Epoch 110; Iter    63/  183] train: loss: 0.0371580
[Epoch 110; Iter    93/  183] train: loss: 0.0336545
[Epoch 110; Iter   123/  183] train: loss: 0.0273559
[Epoch 110; Iter   153/  183] train: loss: 0.0292540
[Epoch 110; Iter   183/  183] train: loss: 0.0610966
[Epoch 110] ogbg-moltox21: 0.731227 val loss: 0.443752
[Epoch 110] ogbg-moltox21: 0.707835 test loss: 0.492358
[Epoch 111; Iter    30/  183] train: loss: 0.0318055
[Epoch 111; Iter    60/  183] train: loss: 0.0544818
[Epoch 111; Iter    90/  183] train: loss: 0.0431823
[Epoch 111; Iter   120/  183] train: loss: 0.0247842
[Epoch 111; Iter   150/  183] train: loss: 0.0438310
[Epoch 111; Iter   180/  183] train: loss: 0.0460953
[Epoch 111] ogbg-moltox21: 0.733165 val loss: 0.449875
[Epoch 111] ogbg-moltox21: 0.704993 test loss: 0.506019
[Epoch 112; Iter    27/  183] train: loss: 0.0578110
[Epoch 112; Iter    57/  183] train: loss: 0.0385808
[Epoch 112; Iter    87/  183] train: loss: 0.0385313
[Epoch 112; Iter   117/  183] train: loss: 0.0290526
[Epoch 112; Iter   147/  183] train: loss: 0.0547497
[Epoch 112; Iter   177/  183] train: loss: 0.0616595
[Epoch 112] ogbg-moltox21: 0.727332 val loss: 0.436463
[Epoch 112] ogbg-moltox21: 0.702502 test loss: 0.489683
[Epoch 113; Iter    24/  183] train: loss: 0.0709417
[Epoch 113; Iter    54/  183] train: loss: 0.0373659
[Epoch 113; Iter    84/  183] train: loss: 0.0281573
[Epoch 113; Iter   114/  183] train: loss: 0.0355665
[Epoch 113; Iter   144/  183] train: loss: 0.0371212
[Epoch 113; Iter   174/  183] train: loss: 0.0501071
[Epoch 113] ogbg-moltox21: 0.730334 val loss: 0.435069
[Epoch 113] ogbg-moltox21: 0.704869 test loss: 0.482847
[Epoch 114; Iter    21/  183] train: loss: 0.0694814
[Epoch 114; Iter    51/  183] train: loss: 0.0451118
[Epoch 114; Iter    81/  183] train: loss: 0.0475362
[Epoch 114; Iter   111/  183] train: loss: 0.0311076
[Epoch 114; Iter   141/  183] train: loss: 0.0545093
[Epoch 114; Iter   171/  183] train: loss: 0.0804892
[Epoch 114] ogbg-moltox21: 0.733284 val loss: 0.451943
[Epoch 114] ogbg-moltox21: 0.705019 test loss: 0.506792
[Epoch 115; Iter    18/  183] train: loss: 0.0360125
[Epoch 115; Iter    48/  183] train: loss: 0.0343415
[Epoch 115; Iter    78/  183] train: loss: 0.0412286
[Epoch 115; Iter   108/  183] train: loss: 0.0518414
[Epoch 115; Iter   138/  183] train: loss: 0.0666083
[Epoch 115; Iter   168/  183] train: loss: 0.0615308
[Epoch 115] ogbg-moltox21: 0.729046 val loss: 0.455104
[Epoch 115] ogbg-moltox21: 0.702221 test loss: 0.495644
[Epoch 116; Iter    15/  183] train: loss: 0.0260857
[Epoch 116; Iter    45/  183] train: loss: 0.0540784
[Epoch 116; Iter    75/  183] train: loss: 0.0722779
[Epoch 116; Iter   105/  183] train: loss: 0.0816885
[Epoch 116; Iter   135/  183] train: loss: 0.0274954
[Epoch 116; Iter   165/  183] train: loss: 0.0405838
[Epoch 116] ogbg-moltox21: 0.733250 val loss: 0.462231
[Epoch 116] ogbg-moltox21: 0.700751 test loss: 0.526660
[Epoch 117; Iter    12/  183] train: loss: 0.0384081
[Epoch 117; Iter    42/  183] train: loss: 0.0183336
[Epoch 117; Iter    72/  183] train: loss: 0.0393987
[Epoch 117; Iter   102/  183] train: loss: 0.0436305
[Epoch 117; Iter   132/  183] train: loss: 0.0349110
[Epoch 117; Iter   162/  183] train: loss: 0.0467293
[Epoch 117] ogbg-moltox21: 0.730427 val loss: 0.466906
[Epoch 117] ogbg-moltox21: 0.702476 test loss: 0.515931
[Epoch 118; Iter     9/  183] train: loss: 0.0459760
[Epoch 118; Iter    39/  183] train: loss: 0.0483329
[Epoch 118; Iter    69/  183] train: loss: 0.0403955
[Epoch 118; Iter    99/  183] train: loss: 0.0350851
[Epoch 118; Iter   129/  183] train: loss: 0.0634701
[Epoch 118; Iter   159/  183] train: loss: 0.0526667
[Epoch 118] ogbg-moltox21: 0.730919 val loss: 0.451684
[Epoch 118] ogbg-moltox21: 0.704079 test loss: 0.507822
[Epoch 119; Iter     6/  183] train: loss: 0.0477791
[Epoch 119; Iter    36/  183] train: loss: 0.0274253
[Epoch 119; Iter    66/  183] train: loss: 0.0326671
[Epoch 119; Iter    96/  183] train: loss: 0.0452493
[Epoch 119; Iter   126/  183] train: loss: 0.0536961
[Epoch 119; Iter   156/  183] train: loss: 0.0620348
[Epoch 119] ogbg-moltox21: 0.729614 val loss: 0.452515
[Epoch 119] ogbg-moltox21: 0.700018 test loss: 0.500872
[Epoch 120; Iter     3/  183] train: loss: 0.0346627
[Epoch 120; Iter    33/  183] train: loss: 0.0543444
[Epoch 120; Iter    63/  183] train: loss: 0.0327442
[Epoch 120; Iter    93/  183] train: loss: 0.0341449
[Epoch 120; Iter   123/  183] train: loss: 0.0247474
[Epoch 120; Iter   153/  183] train: loss: 0.0561232
[Epoch 120; Iter   183/  183] train: loss: 0.0534258
[Epoch 120] ogbg-moltox21: 0.730243 val loss: 0.449040
[Epoch 120] ogbg-moltox21: 0.705175 test loss: 0.496552
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 47.
Statistics on  val_best_checkpoint
mean_pred: -3.6113953590393066
std_pred: 2.8158321380615234
mean_targets: nan
std_targets: nan
prcauc: 0.3289733955952888
rocauc: 0.7757866826631693
ogbg-moltox21: 0.7757866826631693
OGBNanLabelBCEWithLogitsLoss: 0.3026292407885194
Statistics on  test
mean_pred: -3.488130807876587
std_pred: 2.8480660915374756
mean_targets: nan
std_targets: nan
prcauc: 0.3163959032370302
rocauc: 0.7398676613911196
ogbg-moltox21: 0.7398676613911196
OGBNanLabelBCEWithLogitsLoss: 0.32858622958883643
Statistics on  train
mean_pred: -4.570222854614258
std_pred: 2.9011447429656982
mean_targets: nan
std_targets: nan
prcauc: 0.7499011170589736
rocauc: 0.9529861782555923
ogbg-moltox21: 0.9529861782555923
OGBNanLabelBCEWithLogitsLoss: 0.10262167850723032
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 109] ogbg-moltox21: 0.715380 test loss: 0.987516
[Epoch 110; Iter     3/  183] train: loss: 0.0439093
[Epoch 110; Iter    33/  183] train: loss: 0.0270444
[Epoch 110; Iter    63/  183] train: loss: 0.0505759
[Epoch 110; Iter    93/  183] train: loss: 0.0494842
[Epoch 110; Iter   123/  183] train: loss: 0.0514794
[Epoch 110; Iter   153/  183] train: loss: 0.0449016
[Epoch 110; Iter   183/  183] train: loss: 0.0386876
[Epoch 110] ogbg-moltox21: 0.715322 val loss: 0.661444
[Epoch 110] ogbg-moltox21: 0.715990 test loss: 0.912955
[Epoch 111; Iter    30/  183] train: loss: 0.0402626
[Epoch 111; Iter    60/  183] train: loss: 0.0434610
[Epoch 111; Iter    90/  183] train: loss: 0.0312675
[Epoch 111; Iter   120/  183] train: loss: 0.0403537
[Epoch 111; Iter   150/  183] train: loss: 0.0474396
[Epoch 111; Iter   180/  183] train: loss: 0.0855475
[Epoch 111] ogbg-moltox21: 0.719860 val loss: 0.653574
[Epoch 111] ogbg-moltox21: 0.716448 test loss: 0.895950
[Epoch 112; Iter    27/  183] train: loss: 0.0529726
[Epoch 112; Iter    57/  183] train: loss: 0.0564430
[Epoch 112; Iter    87/  183] train: loss: 0.0578298
[Epoch 112; Iter   117/  183] train: loss: 0.0382635
[Epoch 112; Iter   147/  183] train: loss: 0.0373963
[Epoch 112; Iter   177/  183] train: loss: 0.0356024
[Epoch 112] ogbg-moltox21: 0.722007 val loss: 0.739147
[Epoch 112] ogbg-moltox21: 0.721842 test loss: 1.068747
[Epoch 113; Iter    24/  183] train: loss: 0.0443262
[Epoch 113; Iter    54/  183] train: loss: 0.0627918
[Epoch 113; Iter    84/  183] train: loss: 0.0366144
[Epoch 113; Iter   114/  183] train: loss: 0.0721914
[Epoch 113; Iter   144/  183] train: loss: 0.0384364
[Epoch 113; Iter   174/  183] train: loss: 0.0706618
[Epoch 113] ogbg-moltox21: 0.714189 val loss: 0.843633
[Epoch 113] ogbg-moltox21: 0.718027 test loss: 1.256444
[Epoch 114; Iter    21/  183] train: loss: 0.0452195
[Epoch 114; Iter    51/  183] train: loss: 0.0270182
[Epoch 114; Iter    81/  183] train: loss: 0.0504391
[Epoch 114; Iter   111/  183] train: loss: 0.0477926
[Epoch 114; Iter   141/  183] train: loss: 0.0513469
[Epoch 114; Iter   171/  183] train: loss: 0.0386100
[Epoch 114] ogbg-moltox21: 0.711990 val loss: 0.912173
[Epoch 114] ogbg-moltox21: 0.717739 test loss: 1.402933
[Epoch 115; Iter    18/  183] train: loss: 0.0336775
[Epoch 115; Iter    48/  183] train: loss: 0.0446955
[Epoch 115; Iter    78/  183] train: loss: 0.0666147
[Epoch 115; Iter   108/  183] train: loss: 0.0606426
[Epoch 115; Iter   138/  183] train: loss: 0.0505773
[Epoch 115; Iter   168/  183] train: loss: 0.0235077
[Epoch 115] ogbg-moltox21: 0.717278 val loss: 0.787289
[Epoch 115] ogbg-moltox21: 0.715758 test loss: 1.165651
[Epoch 116; Iter    15/  183] train: loss: 0.0346936
[Epoch 116; Iter    45/  183] train: loss: 0.0382866
[Epoch 116; Iter    75/  183] train: loss: 0.0483838
[Epoch 116; Iter   105/  183] train: loss: 0.0165270
[Epoch 116; Iter   135/  183] train: loss: 0.0432244
[Epoch 116; Iter   165/  183] train: loss: 0.0587683
[Epoch 116] ogbg-moltox21: 0.717550 val loss: 0.789049
[Epoch 116] ogbg-moltox21: 0.718507 test loss: 1.176521
[Epoch 117; Iter    12/  183] train: loss: 0.0298866
[Epoch 117; Iter    42/  183] train: loss: 0.0356938
[Epoch 117; Iter    72/  183] train: loss: 0.0363211
[Epoch 117; Iter   102/  183] train: loss: 0.0636519
[Epoch 117; Iter   132/  183] train: loss: 0.0372626
[Epoch 117; Iter   162/  183] train: loss: 0.0476101
[Epoch 117] ogbg-moltox21: 0.719820 val loss: 0.848873
[Epoch 117] ogbg-moltox21: 0.719304 test loss: 1.295833
[Epoch 118; Iter     9/  183] train: loss: 0.0561803
[Epoch 118; Iter    39/  183] train: loss: 0.0418214
[Epoch 118; Iter    69/  183] train: loss: 0.0628386
[Epoch 118; Iter    99/  183] train: loss: 0.0966332
[Epoch 118; Iter   129/  183] train: loss: 0.0330498
[Epoch 118; Iter   159/  183] train: loss: 0.0403088
[Epoch 118] ogbg-moltox21: 0.719289 val loss: 0.780790
[Epoch 118] ogbg-moltox21: 0.718807 test loss: 1.154129
[Epoch 119; Iter     6/  183] train: loss: 0.0605415
[Epoch 119; Iter    36/  183] train: loss: 0.0232512
[Epoch 119; Iter    66/  183] train: loss: 0.0379345
[Epoch 119; Iter    96/  183] train: loss: 0.0395543
[Epoch 119; Iter   126/  183] train: loss: 0.0257825
[Epoch 119; Iter   156/  183] train: loss: 0.0359800
[Epoch 119] ogbg-moltox21: 0.719045 val loss: 0.969782
[Epoch 119] ogbg-moltox21: 0.720846 test loss: 1.519086
[Epoch 120; Iter     3/  183] train: loss: 0.0581184
[Epoch 120; Iter    33/  183] train: loss: 0.0372174
[Epoch 120; Iter    63/  183] train: loss: 0.0427573
[Epoch 120; Iter    93/  183] train: loss: 0.0457638
[Epoch 120; Iter   123/  183] train: loss: 0.0490278
[Epoch 120; Iter   153/  183] train: loss: 0.0339404
[Epoch 120; Iter   183/  183] train: loss: 0.0302996
[Epoch 120] ogbg-moltox21: 0.717981 val loss: 0.769562
[Epoch 120] ogbg-moltox21: 0.718899 test loss: 1.117686
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 32.
Statistics on  val_best_checkpoint
mean_pred: -3.0634608268737793
std_pred: 2.0992422103881836
mean_targets: nan
std_targets: nan
prcauc: 0.3562505627666918
rocauc: 0.7695124307391373
ogbg-moltox21: 0.7695124307391373
OGBNanLabelBCEWithLogitsLoss: 0.26200512405484916
Statistics on  test
mean_pred: -2.9525389671325684
std_pred: 2.1852595806121826
mean_targets: nan
std_targets: nan
prcauc: 0.33243691269759934
rocauc: 0.7451827947473991
ogbg-moltox21: 0.7451827947473991
OGBNanLabelBCEWithLogitsLoss: 0.28186343489214777
Statistics on  train
mean_pred: -3.834709405899048
std_pred: 2.1625540256500244
mean_targets: nan
std_targets: nan
prcauc: 0.6146627317369658
rocauc: 0.9146742677553686
ogbg-moltox21: 0.9146742677553686
OGBNanLabelBCEWithLogitsLoss: 0.134434309284218
All runs completed.
[Epoch 99; Iter   128/  209] train: loss: 0.0591169
[Epoch 99; Iter   158/  209] train: loss: 0.1019996
[Epoch 99; Iter   188/  209] train: loss: 0.0359723
[Epoch 99] ogbg-moltox21: 0.766608 val loss: 0.376704
[Epoch 99] ogbg-moltox21: 0.760912 test loss: 0.369379
[Epoch 100; Iter     9/  209] train: loss: 0.0650032
[Epoch 100; Iter    39/  209] train: loss: 0.0816758
[Epoch 100; Iter    69/  209] train: loss: 0.0636692
[Epoch 100; Iter    99/  209] train: loss: 0.1240366
[Epoch 100; Iter   129/  209] train: loss: 0.1071423
[Epoch 100; Iter   159/  209] train: loss: 0.0785143
[Epoch 100; Iter   189/  209] train: loss: 0.0545183
[Epoch 100] ogbg-moltox21: 0.764357 val loss: 0.375303
[Epoch 100] ogbg-moltox21: 0.757832 test loss: 0.369746
[Epoch 101; Iter    10/  209] train: loss: 0.0477725
[Epoch 101; Iter    40/  209] train: loss: 0.0463722
[Epoch 101; Iter    70/  209] train: loss: 0.0795989
[Epoch 101; Iter   100/  209] train: loss: 0.0788683
[Epoch 101; Iter   130/  209] train: loss: 0.0630960
[Epoch 101; Iter   160/  209] train: loss: 0.0686456
[Epoch 101; Iter   190/  209] train: loss: 0.0504540
[Epoch 101] ogbg-moltox21: 0.764346 val loss: 0.389323
[Epoch 101] ogbg-moltox21: 0.753841 test loss: 0.376646
[Epoch 102; Iter    11/  209] train: loss: 0.0631009
[Epoch 102; Iter    41/  209] train: loss: 0.0607256
[Epoch 102; Iter    71/  209] train: loss: 0.0416654
[Epoch 102; Iter   101/  209] train: loss: 0.0494663
[Epoch 102; Iter   131/  209] train: loss: 0.0803184
[Epoch 102; Iter   161/  209] train: loss: 0.0997620
[Epoch 102; Iter   191/  209] train: loss: 0.0966171
[Epoch 102] ogbg-moltox21: 0.768637 val loss: 0.374520
[Epoch 102] ogbg-moltox21: 0.758476 test loss: 0.369414
[Epoch 103; Iter    12/  209] train: loss: 0.0550865
[Epoch 103; Iter    42/  209] train: loss: 0.0511544
[Epoch 103; Iter    72/  209] train: loss: 0.0537305
[Epoch 103; Iter   102/  209] train: loss: 0.0399553
[Epoch 103; Iter   132/  209] train: loss: 0.0774472
[Epoch 103; Iter   162/  209] train: loss: 0.1531529
[Epoch 103; Iter   192/  209] train: loss: 0.0597090
[Epoch 103] ogbg-moltox21: 0.769011 val loss: 0.378876
[Epoch 103] ogbg-moltox21: 0.758175 test loss: 0.376350
[Epoch 104; Iter    13/  209] train: loss: 0.0627678
[Epoch 104; Iter    43/  209] train: loss: 0.0756791
[Epoch 104; Iter    73/  209] train: loss: 0.0506393
[Epoch 104; Iter   103/  209] train: loss: 0.0788967
[Epoch 104; Iter   133/  209] train: loss: 0.0418640
[Epoch 104; Iter   163/  209] train: loss: 0.0948277
[Epoch 104; Iter   193/  209] train: loss: 0.0484490
[Epoch 104] ogbg-moltox21: 0.766885 val loss: 0.385599
[Epoch 104] ogbg-moltox21: 0.760416 test loss: 0.377094
[Epoch 105; Iter    14/  209] train: loss: 0.0625590
[Epoch 105; Iter    44/  209] train: loss: 0.0316041
[Epoch 105; Iter    74/  209] train: loss: 0.0550877
[Epoch 105; Iter   104/  209] train: loss: 0.0559800
[Epoch 105; Iter   134/  209] train: loss: 0.0473708
[Epoch 105; Iter   164/  209] train: loss: 0.0361824
[Epoch 105; Iter   194/  209] train: loss: 0.0294159
[Epoch 105] ogbg-moltox21: 0.763796 val loss: 0.397204
[Epoch 105] ogbg-moltox21: 0.757064 test loss: 0.387095
[Epoch 106; Iter    15/  209] train: loss: 0.0633689
[Epoch 106; Iter    45/  209] train: loss: 0.0429216
[Epoch 106; Iter    75/  209] train: loss: 0.0825706
[Epoch 106; Iter   105/  209] train: loss: 0.0483992
[Epoch 106; Iter   135/  209] train: loss: 0.0482110
[Epoch 106; Iter   165/  209] train: loss: 0.0461953
[Epoch 106; Iter   195/  209] train: loss: 0.0427769
[Epoch 106] ogbg-moltox21: 0.764322 val loss: 0.392447
[Epoch 106] ogbg-moltox21: 0.752279 test loss: 0.389501
[Epoch 107; Iter    16/  209] train: loss: 0.0358564
[Epoch 107; Iter    46/  209] train: loss: 0.0567690
[Epoch 107; Iter    76/  209] train: loss: 0.1238311
[Epoch 107; Iter   106/  209] train: loss: 0.0572983
[Epoch 107; Iter   136/  209] train: loss: 0.0446369
[Epoch 107; Iter   166/  209] train: loss: 0.0698043
[Epoch 107; Iter   196/  209] train: loss: 0.0467722
[Epoch 107] ogbg-moltox21: 0.757996 val loss: 0.399376
[Epoch 107] ogbg-moltox21: 0.748800 test loss: 0.398188
[Epoch 108; Iter    17/  209] train: loss: 0.0614040
[Epoch 108; Iter    47/  209] train: loss: 0.0982926
[Epoch 108; Iter    77/  209] train: loss: 0.0823819
[Epoch 108; Iter   107/  209] train: loss: 0.0783566
[Epoch 108; Iter   137/  209] train: loss: 0.0501519
[Epoch 108; Iter   167/  209] train: loss: 0.0323332
[Epoch 108; Iter   197/  209] train: loss: 0.0883680
[Epoch 108] ogbg-moltox21: 0.760275 val loss: 0.412528
[Epoch 108] ogbg-moltox21: 0.749237 test loss: 0.401610
[Epoch 109; Iter    18/  209] train: loss: 0.0290564
[Epoch 109; Iter    48/  209] train: loss: 0.0613499
[Epoch 109; Iter    78/  209] train: loss: 0.0489124
[Epoch 109; Iter   108/  209] train: loss: 0.0795978
[Epoch 109; Iter   138/  209] train: loss: 0.0502514
[Epoch 109; Iter   168/  209] train: loss: 0.0506764
[Epoch 109; Iter   198/  209] train: loss: 0.0505854
[Epoch 109] ogbg-moltox21: 0.760700 val loss: 0.399186
[Epoch 109] ogbg-moltox21: 0.749216 test loss: 0.398892
[Epoch 110; Iter    19/  209] train: loss: 0.0423668
[Epoch 110; Iter    49/  209] train: loss: 0.0934837
[Epoch 110; Iter    79/  209] train: loss: 0.0448398
[Epoch 110; Iter   109/  209] train: loss: 0.0492747
[Epoch 110; Iter   139/  209] train: loss: 0.0695533
[Epoch 110; Iter   169/  209] train: loss: 0.0410819
[Epoch 110; Iter   199/  209] train: loss: 0.0592592
[Epoch 110] ogbg-moltox21: 0.761566 val loss: 0.402405
[Epoch 110] ogbg-moltox21: 0.745629 test loss: 0.407648
[Epoch 111; Iter    20/  209] train: loss: 0.0613416
[Epoch 111; Iter    50/  209] train: loss: 0.0552694
[Epoch 111; Iter    80/  209] train: loss: 0.0450261
[Epoch 111; Iter   110/  209] train: loss: 0.0349975
[Epoch 111; Iter   140/  209] train: loss: 0.0746524
[Epoch 111; Iter   170/  209] train: loss: 0.0627106
[Epoch 111; Iter   200/  209] train: loss: 0.0496114
[Epoch 111] ogbg-moltox21: 0.767294 val loss: 0.402675
[Epoch 111] ogbg-moltox21: 0.751114 test loss: 0.397240
[Epoch 112; Iter    21/  209] train: loss: 0.0627171
[Epoch 112; Iter    51/  209] train: loss: 0.0509792
[Epoch 112; Iter    81/  209] train: loss: 0.0453791
[Epoch 112; Iter   111/  209] train: loss: 0.0612628
[Epoch 112; Iter   141/  209] train: loss: 0.0786124
[Epoch 112; Iter   171/  209] train: loss: 0.0724016
[Epoch 112; Iter   201/  209] train: loss: 0.0769618
[Epoch 112] ogbg-moltox21: 0.762196 val loss: 0.430617
[Epoch 112] ogbg-moltox21: 0.754827 test loss: 0.411088
[Epoch 113; Iter    22/  209] train: loss: 0.0775208
[Epoch 113; Iter    52/  209] train: loss: 0.0563148
[Epoch 113; Iter    82/  209] train: loss: 0.0509295
[Epoch 113; Iter   112/  209] train: loss: 0.0362219
[Epoch 113; Iter   142/  209] train: loss: 0.0463965
[Epoch 113; Iter   172/  209] train: loss: 0.0446432
[Epoch 113; Iter   202/  209] train: loss: 0.0619291
[Epoch 113] ogbg-moltox21: 0.764961 val loss: 0.394667
[Epoch 113] ogbg-moltox21: 0.756033 test loss: 0.391478
[Epoch 114; Iter    23/  209] train: loss: 0.0450695
[Epoch 114; Iter    53/  209] train: loss: 0.0505537
[Epoch 114; Iter    83/  209] train: loss: 0.0662534
[Epoch 114; Iter   113/  209] train: loss: 0.0629902
[Epoch 114; Iter   143/  209] train: loss: 0.0762014
[Epoch 114; Iter   173/  209] train: loss: 0.0338065
[Epoch 114; Iter   203/  209] train: loss: 0.0616339
[Epoch 114] ogbg-moltox21: 0.759250 val loss: 0.424181
[Epoch 114] ogbg-moltox21: 0.755074 test loss: 0.407442
[Epoch 115; Iter    24/  209] train: loss: 0.0413686
[Epoch 115; Iter    54/  209] train: loss: 0.0497549
[Epoch 115; Iter    84/  209] train: loss: 0.0804903
[Epoch 115; Iter   114/  209] train: loss: 0.0642007
[Epoch 115; Iter   144/  209] train: loss: 0.0527186
[Epoch 115; Iter   174/  209] train: loss: 0.0463554
[Epoch 115; Iter   204/  209] train: loss: 0.1020568
[Epoch 115] ogbg-moltox21: 0.759783 val loss: 0.409682
[Epoch 115] ogbg-moltox21: 0.753963 test loss: 0.401032
[Epoch 116; Iter    25/  209] train: loss: 0.0271598
[Epoch 116; Iter    55/  209] train: loss: 0.0482095
[Epoch 116; Iter    85/  209] train: loss: 0.0718165
[Epoch 116; Iter   115/  209] train: loss: 0.0372269
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0329239
[Epoch 116; Iter   175/  209] train: loss: 0.0918690
[Epoch 116; Iter   205/  209] train: loss: 0.0561115
[Epoch 116] ogbg-moltox21: 0.770098 val loss: 0.395892
[Epoch 116] ogbg-moltox21: 0.740898 test loss: 0.430816
[Epoch 117; Iter    26/  209] train: loss: 0.0500250
[Epoch 117; Iter    56/  209] train: loss: 0.0433741
[Epoch 117; Iter    86/  209] train: loss: 0.0353029
[Epoch 117; Iter   116/  209] train: loss: 0.0523505
[Epoch 117; Iter   146/  209] train: loss: 0.0427154
[Epoch 117; Iter   176/  209] train: loss: 0.0757991
[Epoch 117; Iter   206/  209] train: loss: 0.0583443
[Epoch 117] ogbg-moltox21: 0.771765 val loss: 0.391881
[Epoch 117] ogbg-moltox21: 0.733926 test loss: 0.430355
[Epoch 118; Iter    27/  209] train: loss: 0.0480694
[Epoch 118; Iter    57/  209] train: loss: 0.0360633
[Epoch 118; Iter    87/  209] train: loss: 0.0857075
[Epoch 118; Iter   117/  209] train: loss: 0.0405781
[Epoch 118; Iter   147/  209] train: loss: 0.0742883
[Epoch 118; Iter   177/  209] train: loss: 0.0411938
[Epoch 118; Iter   207/  209] train: loss: 0.0401109
[Epoch 118] ogbg-moltox21: 0.770593 val loss: 0.406027
[Epoch 118] ogbg-moltox21: 0.742171 test loss: 0.429512
[Epoch 119; Iter    28/  209] train: loss: 0.0681023
[Epoch 119; Iter    58/  209] train: loss: 0.0735594
[Epoch 119; Iter    88/  209] train: loss: 0.0410595
[Epoch 119; Iter   118/  209] train: loss: 0.0809080
[Epoch 119; Iter   148/  209] train: loss: 0.0811838
[Epoch 119; Iter   178/  209] train: loss: 0.0494129
[Epoch 119; Iter   208/  209] train: loss: 0.0466192
[Epoch 119] ogbg-moltox21: 0.771512 val loss: 0.399084
[Epoch 119] ogbg-moltox21: 0.740298 test loss: 0.437619
[Epoch 120; Iter    29/  209] train: loss: 0.0481324
[Epoch 120; Iter    59/  209] train: loss: 0.0508017
[Epoch 120; Iter    89/  209] train: loss: 0.0342197
[Epoch 120; Iter   119/  209] train: loss: 0.0599956
[Epoch 120; Iter   149/  209] train: loss: 0.0550511
[Epoch 120; Iter   179/  209] train: loss: 0.0814690
[Epoch 120; Iter   209/  209] train: loss: 0.0758549
[Epoch 120] ogbg-moltox21: 0.773045 val loss: 0.402878
[Epoch 120] ogbg-moltox21: 0.741513 test loss: 0.438784
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 31.
Statistics on  val_best_checkpoint
mean_pred: -3.153897523880005
std_pred: 1.8536348342895508
mean_targets: nan
std_targets: nan
prcauc: 0.3833430494226157
rocauc: 0.8032908387856055
ogbg-moltox21: 0.8032908387856055
OGBNanLabelBCEWithLogitsLoss: 0.2428183693576742
Statistics on  test
mean_pred: -3.1378397941589355
std_pred: 1.8840110301971436
mean_targets: nan
std_targets: nan
prcauc: 0.34272393997526
rocauc: 0.758521247656596
ogbg-moltox21: 0.758521247656596
OGBNanLabelBCEWithLogitsLoss: 0.2617266398889047
Statistics on  train
mean_pred: -4.008512020111084
std_pred: 5.325438976287842
mean_targets: nan
std_targets: nan
prcauc: 0.5245900607300837
rocauc: 0.8982866538869735
ogbg-moltox21: 0.8982866538869735
OGBNanLabelBCEWithLogitsLoss: 0.19861018137213146
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0636148
[Epoch 116; Iter   175/  209] train: loss: 0.0254003
[Epoch 116; Iter   205/  209] train: loss: 0.0865069
[Epoch 116] ogbg-moltox21: 0.769673 val loss: 0.374271
[Epoch 116] ogbg-moltox21: 0.739233 test loss: 0.396382
[Epoch 117; Iter    26/  209] train: loss: 0.0419580
[Epoch 117; Iter    56/  209] train: loss: 0.0272058
[Epoch 117; Iter    86/  209] train: loss: 0.0326828
[Epoch 117; Iter   116/  209] train: loss: 0.0336984
[Epoch 117; Iter   146/  209] train: loss: 0.0552012
[Epoch 117; Iter   176/  209] train: loss: 0.0691631
[Epoch 117; Iter   206/  209] train: loss: 0.0480585
[Epoch 117] ogbg-moltox21: 0.767767 val loss: 0.375417
[Epoch 117] ogbg-moltox21: 0.736312 test loss: 0.392297
[Epoch 118; Iter    27/  209] train: loss: 0.0579534
[Epoch 118; Iter    57/  209] train: loss: 0.0379110
[Epoch 118; Iter    87/  209] train: loss: 0.0348226
[Epoch 118; Iter   117/  209] train: loss: 0.0556704
[Epoch 118; Iter   147/  209] train: loss: 0.0836798
[Epoch 118; Iter   177/  209] train: loss: 0.0380445
[Epoch 118; Iter   207/  209] train: loss: 0.0426165
[Epoch 118] ogbg-moltox21: 0.768169 val loss: 0.381282
[Epoch 118] ogbg-moltox21: 0.737875 test loss: 0.414883
[Epoch 119; Iter    28/  209] train: loss: 0.0659995
[Epoch 119; Iter    58/  209] train: loss: 0.0556386
[Epoch 119; Iter    88/  209] train: loss: 0.0482107
[Epoch 119; Iter   118/  209] train: loss: 0.0576377
[Epoch 119; Iter   148/  209] train: loss: 0.0428298
[Epoch 119; Iter   178/  209] train: loss: 0.0653933
[Epoch 119; Iter   208/  209] train: loss: 0.0467145
[Epoch 119] ogbg-moltox21: 0.768487 val loss: 0.378340
[Epoch 119] ogbg-moltox21: 0.737721 test loss: 0.395341
[Epoch 120; Iter    29/  209] train: loss: 0.0335128
[Epoch 120; Iter    59/  209] train: loss: 0.0485315
[Epoch 120; Iter    89/  209] train: loss: 0.0484893
[Epoch 120; Iter   119/  209] train: loss: 0.0610164
[Epoch 120; Iter   149/  209] train: loss: 0.0463972
[Epoch 120; Iter   179/  209] train: loss: 0.0392446
[Epoch 120; Iter   209/  209] train: loss: 0.0401385
[Epoch 120] ogbg-moltox21: 0.764510 val loss: 0.377462
[Epoch 120] ogbg-moltox21: 0.737062 test loss: 0.388442
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 32.
Statistics on  val_best_checkpoint
mean_pred: -3.076075792312622
std_pred: 1.8424298763275146
mean_targets: nan
std_targets: nan
prcauc: 0.3932349957890809
rocauc: 0.8086034209448673
ogbg-moltox21: 0.8086034209448673
OGBNanLabelBCEWithLogitsLoss: 0.2388738344113032
Statistics on  test
mean_pred: -3.0839362144470215
std_pred: 1.8378304243087769
mean_targets: nan
std_targets: nan
prcauc: 0.35599012898542354
rocauc: 0.7618302115620171
ogbg-moltox21: 0.7618302115620171
OGBNanLabelBCEWithLogitsLoss: 0.25658995575375027
Statistics on  train
mean_pred: -3.8454396724700928
std_pred: 1.9855694770812988
mean_targets: nan
std_targets: nan
prcauc: 0.565158952582576
rocauc: 0.8976330347502354
ogbg-moltox21: 0.8976330347502354
OGBNanLabelBCEWithLogitsLoss: 0.149294966715945
/workspace/trainer/trainer.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(self.writer.log_dir, 'best_checkpoint.pt'), map_location=self.device)
[Epoch 116; Iter   145/  209] train: loss: 0.0511157
[Epoch 116; Iter   175/  209] train: loss: 0.0409860
[Epoch 116; Iter   205/  209] train: loss: 0.0583154
[Epoch 116] ogbg-moltox21: 0.764984 val loss: 0.416583
[Epoch 116] ogbg-moltox21: 0.754663 test loss: 0.408387
[Epoch 117; Iter    26/  209] train: loss: 0.0559214
[Epoch 117; Iter    56/  209] train: loss: 0.0343312
[Epoch 117; Iter    86/  209] train: loss: 0.0419309
[Epoch 117; Iter   116/  209] train: loss: 0.0790503
[Epoch 117; Iter   146/  209] train: loss: 0.0328962
[Epoch 117; Iter   176/  209] train: loss: 0.0413019
[Epoch 117; Iter   206/  209] train: loss: 0.0355018
[Epoch 117] ogbg-moltox21: 0.760678 val loss: 0.418472
[Epoch 117] ogbg-moltox21: 0.753993 test loss: 0.404937
[Epoch 118; Iter    27/  209] train: loss: 0.0517397
[Epoch 118; Iter    57/  209] train: loss: 0.0937427
[Epoch 118; Iter    87/  209] train: loss: 0.0644285
[Epoch 118; Iter   117/  209] train: loss: 0.0547261
[Epoch 118; Iter   147/  209] train: loss: 0.0524779
[Epoch 118; Iter   177/  209] train: loss: 0.0415096
[Epoch 118; Iter   207/  209] train: loss: 0.0440609
[Epoch 118] ogbg-moltox21: 0.758990 val loss: 0.428124
[Epoch 118] ogbg-moltox21: 0.754324 test loss: 0.412267
[Epoch 119; Iter    28/  209] train: loss: 0.0642106
[Epoch 119; Iter    58/  209] train: loss: 0.0790412
[Epoch 119; Iter    88/  209] train: loss: 0.0704587
[Epoch 119; Iter   118/  209] train: loss: 0.0352011
[Epoch 119; Iter   148/  209] train: loss: 0.0411411
[Epoch 119; Iter   178/  209] train: loss: 0.0570783
[Epoch 119; Iter   208/  209] train: loss: 0.0274233
[Epoch 119] ogbg-moltox21: 0.758999 val loss: 0.432299
[Epoch 119] ogbg-moltox21: 0.753224 test loss: 0.419015
[Epoch 120; Iter    29/  209] train: loss: 0.0673558
[Epoch 120; Iter    59/  209] train: loss: 0.0394293
[Epoch 120; Iter    89/  209] train: loss: 0.0577982
[Epoch 120; Iter   119/  209] train: loss: 0.0544343
[Epoch 120; Iter   149/  209] train: loss: 0.1487872
[Epoch 120; Iter   179/  209] train: loss: 0.0564059
[Epoch 120; Iter   209/  209] train: loss: 0.0306185
[Epoch 120] ogbg-moltox21: 0.761880 val loss: 0.430468
[Epoch 120] ogbg-moltox21: 0.754986 test loss: 0.414475
Early stopping criterion based on -ogbg-moltox21- that should be max reached after 120 epochs. Best model checkpoint was in epoch 30.
Statistics on  val_best_checkpoint
mean_pred: -3.0236010551452637
std_pred: 2.0374960899353027
mean_targets: nan
std_targets: nan
prcauc: 0.3837829910980109
rocauc: 0.8124456708584313
ogbg-moltox21: 0.8124456708584313
OGBNanLabelBCEWithLogitsLoss: 0.24730173967502736
Statistics on  test
mean_pred: -3.0742950439453125
std_pred: 2.0911715030670166
mean_targets: nan
std_targets: nan
prcauc: 0.3458601124270224
rocauc: 0.758560892370744
ogbg-moltox21: 0.758560892370744
OGBNanLabelBCEWithLogitsLoss: 0.2687999015605008
Statistics on  train
mean_pred: -3.577279567718506
std_pred: 3.209411382675171
mean_targets: nan
std_targets: nan
prcauc: 0.5486655023614448
rocauc: 0.8956772802549802
ogbg-moltox21: 0.8956772802549802
OGBNanLabelBCEWithLogitsLoss: 0.166879425743265
All runs completed.
