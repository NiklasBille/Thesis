{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_csv_results_reg(predict_path, csv_path):\n",
    "    \"\"\"\n",
    "    Construct both mean aggregated df and regular df of smi_name, predict value and target value for a regression task.\n",
    "    Aggregation is based on smi_name.\n",
    "    \"\"\"\n",
    "    predict = pd.read_pickle(predict_path)\n",
    "    smi_list, predict_list, target_list = [], [], []\n",
    "    for batch in predict:\n",
    "        sz = batch[\"bsz\"]\n",
    "        for i in range(sz):\n",
    "            yhat = batch[\"predict\"][i].cpu()\n",
    "            y = batch[\"target\"][i].cpu()\n",
    "            \n",
    "            smi_list.append(batch[\"smi_name\"][i])\n",
    "            predict_list.append(yhat.detach().item())\n",
    "            target_list.append(y.detach().item())\n",
    "            \n",
    "    predict_df = pd.DataFrame({\"SMILES\": smi_list, \"predict\": predict_list, \"target\": target_list})\n",
    "    predict_df_agg = predict_df.groupby(\"SMILES\").mean()\n",
    "\n",
    "    predict_df.to_csv(csv_path,index=False)\n",
    "    predict_df_agg.to_csv(csv_path.replace(\"test\", \"test_agg\"),index=False)\n",
    "\n",
    "    return predict_df, predict_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m predict_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/Uni-Mol/unimol/results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test.out.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/Uni-Mol/unimol/results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test.out.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mget_csv_results_cf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36mget_csv_results_cf\u001b[0;34m(predict_path, csv_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu() \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m sys\u001b[38;5;241m.\u001b[39mexit()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#for i in range(sz):\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#    \u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#    prob = batch[\"prob\"][i].cpu()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#predict_list.append(yhat.detach().item())\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#target_list.append(y.detach().item())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:575\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    568\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    569\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_base.py:118\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     y_true_c \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    117\u001b[0m     y_score_c \u001b[38;5;241m=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m--> 118\u001b[0m     score[c] \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Average the results\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:337\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    342\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "def get_csv_results_cf(predict_path, csv_path):\n",
    "    predict = pd.read_pickle(predict_path)\n",
    "    smi_list, prob_list, target_list = [], [], []\n",
    "\n",
    "    atoms_counter = 0\n",
    "    for batch in predict:\n",
    "        sz = batch[\"bsz\"]\n",
    "\n",
    "        y = batch[\"target\"].cpu().reshape_as(batch[\"prob\"].cpu())\n",
    "        y_hat = batch[\"prob\"].cpu() \n",
    "        print(y)\n",
    "        roc_auc_score(y, y_hat)\n",
    "        \n",
    "        \n",
    "        sys.exit()\n",
    "        #for i in range(sz):\n",
    "        #    \n",
    "        #    prob = batch[\"prob\"][i].cpu()\n",
    "        #    t = batch[\"target\"][i].cpu()\n",
    "        #    print(roc_auc_score(t, prob))\n",
    "        #    sys.exit()\n",
    "\n",
    "            #smi_list.append(batch[\"smi_name\"][i])\n",
    "            #predict_list.append(yhat.detach().item())\n",
    "            #target_list.append(y.detach().item())\n",
    "        \n",
    "        atoms_counter += sz\n",
    "\n",
    "            \n",
    "dataset = \"clintox\"\n",
    "predict_path = f\"/workspace/Uni-Mol/unimol/results/{dataset}_test.out.pkl\"\n",
    "csv_path = f\"/workspace/Uni-Mol/unimol/results/{dataset}_test.out.csv\"\n",
    "get_csv_results_cf(predict_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freesolv32bit RMSE: 1.86\n",
      "freesolv32bit Aggregated RMSE: 1.845\n",
      "freesolv32bit_grad RMSE: 1.655\n",
      "freesolv32bit_grad Aggregated RMSE: 1.619\n"
     ]
    }
   ],
   "source": [
    "#datasets = [\"freesolv_no_hydrogen\", \"esol\", \"lipo\", \"qm7_no_hydrogen\"]\n",
    "#datasets = [\"freesolv_no_hydrogen\", \"freesolv_no_hydrogen2\"]\n",
    "#datasets = [\"freesolv\", \"freesolv2\", \"freesolv3\"]\n",
    "datasets = [\"freesolv32bit\", \"freesolv32bit_grad\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    predict_path = f\"/workspace/Uni-Mol/unimol/results/{dataset}_test.out.pkl\"\n",
    "    csv_path = f\"/workspace/Uni-Mol/unimol/results/{dataset}_test.out.csv\"\n",
    "    predict_df, predict_df_agg = get_csv_results_reg(predict_path, csv_path)\n",
    "    if dataset not in [\"qm7\", \"qm7_no_hydrogen\"] : \n",
    "        print(f\"{dataset} RMSE: {sqrt(((predict_df['predict'] - predict_df['target']) ** 2).mean()):.4}\")\n",
    "        print(f\"{dataset} Aggregated RMSE: {sqrt(((predict_df_agg['predict'] - predict_df_agg['target']) ** 2).mean()):.4}\")\n",
    "    else:\n",
    "        print(f\"{dataset} MAE: {np.abs(predict_df['predict'] - predict_df['target']).mean():.4}\")\n",
    "        print(f\"{dataset} Aggregated MAE: {np.abs(predict_df_agg['predict'] - predict_df_agg['target']).mean():.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0)]\n"
     ]
    }
   ],
   "source": [
    "import lmdb\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "def read_lmdb(lmdb_path):\n",
    "    env = lmdb.open(\n",
    "        lmdb_path,\n",
    "        subdir=False,\n",
    "        readonly=True,\n",
    "        lock=False,\n",
    "        readahead=False,\n",
    "        meminit=False,\n",
    "        max_readers=256,\n",
    "    )\n",
    "    txn = env.begin()\n",
    "    keys = list(txn.cursor().iternext(values=False))\n",
    "\n",
    "    targets = []\n",
    "    smi = []\n",
    "    #print(f\"#atoms: {len(keys)}\")\n",
    "    for idx in keys:\n",
    "        datapoint_pickled = txn.get(idx)\n",
    "        data = pickle.loads(datapoint_pickled)\n",
    "        targets.append(data[\"target\"])\n",
    "        smi.append(data['smi'])\n",
    "    \n",
    "    return targets, smi\n",
    "    \n",
    "        \n",
    "\n",
    "path = \"/workspace/Uni-Mol/unimol/data/molecular_property_prediction/clintox/test.lmdb\"\n",
    "targets, smi = read_lmdb(path)\n",
    "\n",
    "print(targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
